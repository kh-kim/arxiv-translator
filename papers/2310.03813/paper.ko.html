<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# 인기 기반 통합 및 커리큘럼 가열을 통한 정확한 Cold-start 번들 권장 사항\n' +
      '\n' +
      'Hyunsik Jeon\n' +
      '\n' +
      '샌디에이고\n' +
      '\n' +
      '미국 샌디에이고\n' +
      '\n' +
      'Jong-eun Lee\n' +
      '\n' +
      '서울대학교 전기공학부\n' +
      '\n' +
      '서울\n' +
      '\n' +
      'Jeongin Yun\n' +
      '\n' +
      '서울대학교 전기공학부\n' +
      '\n' +
      '서울\n' +
      '\n' +
      'U Kang\n' +
      '\n' +
      '서울대학교 전기공학부\n' +
      '\n' +
      '서울\n' +
      '\n' +
      '###### Abstract.\n' +
      '\n' +
      '사용자에게 콜드 스타트 번들을 정확하게 추천할 수 있는 방법은 무엇입니까? 다양한 마케팅 목적을 위해 새로운 번들이 지속적으로 생성되기 때문에 번들 추천의 콜드 스타트 문제는 실제 시나리오에서 매우 중요하다. 그 중요성에도 불구하고, 콜드 스타트 번들 추천을 다룬 이전 연구는 없다. 또한 콜드 스타트 아이템 추천을 위한 기존 방법은 인기 없는 번들일지라도 이력 정보에 과도하게 의존하여 번들 상호 작용의 고도로 편향된 분포의 주요 문제를 해결하지 못한다. 본 연구에서는 콜드 스타트 번들 추천을 위한 정확한 접근 방법인 CoHeat(Popularity-based Coalescence and Curriculum Heating)를 제안한다. CoHeat는 사용자-묶음 관계를 추정할 때 번들의 인기도에 기초하여 번들의 과거 및 소속 정보를 모두 통합함으로써 번들 상호작용의 고도로 치우친 분포를 다룬다. 또한, CoHeat는 교육과정 학습과 대조적 학습을 활용하여 잠재 표상을 효과적으로 학습한다. CoHeat는 콜드 스타트 번들 추천에서 우수한 성능을 보여 최고의 경쟁사에 비해 최대 193% 더 높은 nDCG@20을 달성합니다.\n' +
      '\n' +
      'cold-start bundle recommendation; curriculum learning; contrastive learning +\n' +
      '각주 † : 저널 : 정보 시스템 추천 시스템\n' +
      '\n' +
      '+\n' +
      '각주 † : 저널 : 정보 시스템 추천 시스템\n' +
      '\n' +
      '## 1. Introduction\n' +
      '\n' +
      '- 사용자에게 콜드 스타트 번들을 정확하게 추천할 수 있는 방법은 무엇입니까?_ 번들 추천은 제공자가 원스톱 편의성으로 사용자에게 아이템을 제공할 수 있게 해주기 때문에 학계 및 산업계 모두에서 상당한 주목을 받고 있다(Kang et al., 2018). 특히, 사용자에게 새로운 번들을 추천하는 것(즉, 콜드 스타트 번들 추천)은 다양한 마케팅 목적을 위해 새로운 번들이 끊임없이 생성되기 때문에 실용적인 시나리오에서 중요하다(Kang et al., 2018).\n' +
      '\n' +
      '최근, 번들 추천은 매트릭스 인수분해-기반 접근법(Chen et al., 2018; He et al., 2018; He et al., 2018) 및 그래프 학습-기반 접근법(Chen et al., 2018; He et al., 2018; He et al., 2018)을 통해 발전을 보았다. 그러나 모든 번들이 사용자와의 과거 상호 작용을 갖는 웜 시작 설정을 위해 개발되었습니다. 결과적으로, 특정 번들에 이력 상호 작용이 없는 콜드 스타트 설정에서 효과적으로 수행하지 못한다. 이는 웜-스타트 방법이 번들 표현을 학습하기 위해 이력 정보에 크게 의존하기 때문이다. 한편, 아이템 추천에서 콜드 스타트 문제는 행동 표현을 콘텐츠 표현과 정렬하는 데 중점을 두고 광범위하게 연구되었다. 예를 들어, 생성 방법들은 평균 제곱 오차(Krizhevsky et al., 2015) 및 적대적 손실(Chen et al., 2018)을 사용하여 아이템 행동 표현들의 생성을 모델링하는 것을 목표로 하였다. 드롭아웃 기반 방법들(Krizhevsky et al., 2015; Li et al., 2017)은 트레이닝 단계에서 행동 임베딩을 랜덤하게 드롭함으로써 행동 정보에 대한 견고성을 강화하는 것을 목표로 하였다. 보다 최근에, 대조적 학습 기반 방법들(Wang et al., 2018; He et al., 2018)은 아이템들의 행동 분포와 콘텐츠 정보 사이의 불일치를 감소시킴으로써 우수한 성능을 보여주었다. 그러나 그림 0(a)와 같이 번들 추천에서 중추적인 측면인 상호 작용의 편향된 분포를 명시적으로 고려한 기존 작업은 없다. 비인기 번들의 경우, 불충분한 이력 정보로부터의 거동 표현들을 콘텐츠 표현들과 정렬하는 것은 내재된 편향들을 증폭시키고 의미 있는 표현들을 학습하는 것을 어렵게 한다; 이는 콜드-스타트 설정에서의 성능을 향상시키기 위해 웜-스타트 설정에서의 성능을 희생시키는 결과를 초래한다(도 2 참조).\n' +
      '\n' +
      '본 논문에서는 콜드 스타트 번들을 추천하기 위한 정확한 방법인 CoHeat(Popularity-based Coalescence and Curriculum Heating)를 제안한다. CoHeat는 히스토리 뷰와 소속 뷰의 두 가지 별개의 그래프 기반 뷰를 사용하여 사용자와 번들의 표현을 구성한다. 이력-뷰 그래프는 사용자와 번들 사이의 이력 상호작용에 기초하는 반면, 소속-뷰 그래프는 번들 소속에 뿌리를 둔 정보를 캡처한다. 극도로 왜곡된 분포를 처리하기 위해 CoHeat는 예측에서 두 보기를 전략적으로 활용하며, 더 풍부한 정보를 제공하기 때문에 덜 인기 있는 번들에 대한 소속 관점을 강조한다.\n' +
      '\n' +
      '도 1. (a) 실제 데이터세트에서 번들 상호작용의 극단적으로 치우친 분포(데이터 통계는 표 1에 요약되어 있음). (b-c) 인기 없는 번들의 경우, 히스토리-뷰는 불충분한 정보를 제공하고, 소속-뷰는 충분한 정보를 제공한다.\n' +
      '\n' +
      '희소 히스토리 뷰는 그림 0(b) 및 0(c)에 나와 있다. 또한, 코히트는 콜드 스타트 번들에 사용되는 소속관 표현을 효과적으로 학습하기 위해 훈련 초점을 히스토리 뷰에서 소속관으로 점진적으로 전환하는 커리큘럼 학습 접근법을 활용한다. CoHeat는 두 뷰의 표현을 효과적으로 정렬하기 위해 대조적 학습 접근법을 추가로 활용한다.\n' +
      '\n' +
      '우리의 기여는 다음과 같이 요약됩니다.\n' +
      '\n' +
      '* **문제.** 우리가 아는 한, 이것은 실제 시나리오에서 중요한 영향을 미치는 도전적인 문제인 번들 권장 사항의 Cold-start 문제를 해결하는 첫 번째 작업입니다.\n' +
      '* **방법.** 콜드 스타트 번들 추천을 위한 정확한 방법인 CoHeat를 제안합니다. CoHeat는 그들의 소속에 따라 콜드 스타트 번들을 정확하게 추천하기 위해 상호 작용의 극도로 치우친 분포를 효과적으로 처리한다.\n' +
      '* **실험.** CoHeat가 Cold-start 번들 권장 사항에서 최상의 경쟁자에 비해 최대 193% 더 높은 nDCG@20을 달성하는 최신 성능을 제공한다는 것을 실험적으로 보여줍니다 (그림 2 참조).\n' +
      '\n' +
      '## 2. Preliminaries\n' +
      '\n' +
      '### Problem Definition\n' +
      '\n' +
      '콜드 스타트 번들 추천의 문제는 다음과 같이 정의된다. \\(\\mathcal{U}\\), \\(\\mathcal{B}\\), \\(\\mathcal{I}\\)을 각각 사용자 집합, 번들 집합, 아이템 집합으로 한다. 번들 중 \\(\\mathcal{B}_{w}\\subset\\mathcal{B}\\)은 사용자와 적어도 하나의 역사적 상호작용이 있는 warm-start 번들을 의미하고, \\(\\mathcal{B}_{c}=\\mathcal{B}\\setminus\\mathcal{B}_{w}\\)은 사용자와 아무런 역사적 상호작용이 없는 cold-start 번들을 의미한다. 관찰된 사용자-묶음 상호작용, 사용자-항목 상호작용, 묶음-항목 소속은 각각 \\(\\mathcal{X}=\\{(u,b)|u\\in\\mathcal{U},b\\in\\mathcal{B}_{w}\\}\\), \\(\\mathcal{Y}=\\{(u,i)|u\\in\\mathcal{U},i\\in I\\}\\), \\(\\mathcal{Z}=\\{(b,i)|b\\in\\mathcal{B},i\\in I\\}\\)으로 정의된다. 본 논문에서는 \\(\\{\\mathcal{X},\\mathcal{Y},\\mathcal{Z}\\}\\)을 주어 각 사용자들에게 \\(\\mathcal{B}\\)의 \\(k\\) 번들을 추천하는 것을 목표로 한다 \\(u\\in\\mathcal{U}\\). 주어진 상호작용은 따뜻한 번들에 대해서만 관찰되지만 목적은 사용자에게 차가운 번들 또한 추천하는 것을 포함한다.\n' +
      '\n' +
      '콜드 스타트 번들 추천에 있어서 전통적인 번들 추천에 비해 중요한 문제는 사용자 \\(u\\in\\mathcal{U}\\)와 콜드 스타트 번들 \\(b\\in\\mathcal{B}_{c}\\) 사이의 관계를 정확하게 예측하는 것이다. 따라서 콜드 스타트 번들의 소속 정보를 이용하여 콜드 스타트 번들의 표현을 효과적으로 추정하는 것이 문제의 해결의 핵심이다.\n' +
      '\n' +
      '### Curriculum Learning\n' +
      '\n' +
      '인간 학습에서 영감을 받은 커리큘럼 학습은 작업 순서를 랜덤화하는 표준 접근법과는 달리, 더 간단한 작업으로부터 더 복잡한 작업으로 훈련을 구조화한다(Bang et al., 2019; Chen et al., 2020). 그 효과는 컴퓨터 비전(Zhu et al., 2019; Wang et al., 2020), 자연어 처리(Liu et al., 2019; Wang et al., 2020), 로보틱스(Liu et al., 2019; Wang et al., 2020), 및 추천 시스템(Chen et al., 2020; Chen et al., 2020)을 포함하는 다양한 도메인에서 입증되었다.\n' +
      '\n' +
      '이 연구에서는 사용자-묶음 관계의 학습 과정을 향상시키기 위해 커리큘럼 학습을 활용한다. 우리는 보다 간단한 히스토리 뷰 임베딩에 초점을 맞추어 시작한 다음 복잡한 소속 뷰 임베딩으로 점진적으로 주의를 전환한다. 이 전략은 역사적 상호 작용에서 협력 신호를 직접 포착하는 역사관 임베딩 학습의 용이성에서 비롯된다. 이에 비해 소속관 임베딩은 소속항목의 표현에 의존하기 때문에 더욱 복잡하다.\n' +
      '\n' +
      '### Contrastive Learning\n' +
      '\n' +
      '대비 학습은 유사 데이터 샘플과 유사하지 않은 데이터 샘플을 구별하여 의미 있는 임베딩을 학습하는 것을 목표로 한다. 컴퓨터 비전(Zhu et al., 2019; Wang et al., 2020), 자연어 처리(Liu et al., 2019; Wang et al., 2020), 및 추천 시스템(Chen et al., 2020; Wang et al., 2020)을 포함하는 다양한 연구 분야에 걸쳐 일관되게 우수한 성능을 입증하였다. 구체적으로, CrossCBR(Liu et al., 2019)은 최근 히스토리-뷰와 소속-뷰 사이의 InfNoCE(Wang et al., 2020)를 이용하여 사용자와 번들의 임베딩을 정규화하여 번들 추천에서 좋은 성능을 달성하였다.\n' +
      '\n' +
      '그러나 CrossCBR은 두 뷰를 예측에서 동일하게 처리하면서 정렬합니다. 이와는 대조적으로, 본 연구는 번들 인기도에 기초하여 이러한 뷰의 가중치를 적응적으로 조정하여 보다 유익한 뷰로부터의 정보 전달을 용이하게 한다.\n' +
      '\n' +
      '그림 2. Youshu, NetEase, iFashion의 세 가지 실제 데이터 세트에서 CoHeat와 경쟁사 간의 성능 비교. 모든 실험에 대해 Recall@20을 통해 성능을 평가한다. 우리는 콜드 스타트 방법을 주황색으로, 웜 스타트 방법을 빨간색으로 표시한다. CoHeat는 추운 환경 및 따뜻한 환경 모두에서 기존 방법보다 우수한 성능을 보여주며 경쟁사를 능가하는 데 주목할 만한 이점이 있다.\n' +
      '\n' +
      '더 희박한 상대에게. 추가적으로, 우리의 대조적 학습 접근법에서, 정렬 및 균일성 손실을 활용한다(Krizhevsky et al., 2014). 이는, 대조적 학습의 핵심 관점을 직접적으로 최적화하기 때문에, 다양한 애플리케이션(Krizhevsky 등, 2014; Krizhevsky 등, 2014)에서 InfoNCE를 능가하는 것으로 나타났다.\n' +
      '\n' +
      '## 3. 제안된 방법\n' +
      '\n' +
      '### Overview\n' +
      '\n' +
      '콜드 스타트 번들 추천에서 높은 성능을 달성하기 위해 다음과 같은 문제를 해결합니다.\n' +
      '\n' +
      '1. **매우 왜곡된 상호 작용 처리** 이전 작업은 번들에 희소한 상호 작용이 있는 경우 신뢰할 수 없는 기록 보기 표현에 과도하게 의존합니다. 우리는 어떻게 고도로 왜곡된 상호 작용으로부터 표상을 효과적으로 배울 수 있을까?\n' +
      '2. **소속 뷰 표현을 효과적으로 학습 합니다.* * 소속 뷰에서 제공 하는 충분한 정보에도 불구하고 묶음의 여러 항목은 이러한 표현의 학습을 복잡하게 만듭니다. 우리는 어떻게 소속관 표현을 효과적으로 배울 수 있을까?\n' +
      '3. **두 뷰 표현 간의 간격을 좁힙니다.* * 소속만 사용 하 여 콜드 번들의 향후 상호 작용을 추정 하기 때문에 기록 뷰와 소속 뷰를 정렬 하는 것이 중요 합니다. 우리는 어떻게 이 두 관점 표상을 효과적으로 조화시킬 수 있을까?\n' +
      '\n' +
      '이러한 문제를 해결하기 위해 우리는 다음과 같은 주요 아이디어로 CoHeat(인기 기반 통합 및 커리큘럼 난방)를 제안한다.\n' +
      '\n' +
      '1. **인기 기반 통합.** 사용자와 번들 간의 점수에 대해 덜 인기 있는 번들이 소속 뷰 점수에 더 많이 의존하고 히스토리 뷰 점수에 덜 의존하는 두 뷰 점수의 통합을 제안합니다.\n' +
      '2. **교육과정 가열.** 처음에는 히스토리 뷰를 사용하여 표상을 훈련하는 데 초점을 맞추고 점차 초점을 소속 뷰로 전환하는 교육과정 학습 접근 방식을 제안합니다.\n' +
      '3. **표현 정렬 및 균일성.** 기록 보기 및 소속 보기 표현을 효과적으로 조정 하기 위해 표현 정렬 및 균일성 접근법을 활용 합니다.\n' +
      '\n' +
      '도 3은 CoHeat의 개략적인 예시를 도시한다. 사용자-번들 상호작용, 사용자-항목 상호작용 및 번들-항목 소속이 주어지면, CoHeat는 두 개의 그래프 기반 뷰를 형성한다. 그리고 번들 인기도를 기반으로 두 뷰의 점수를 합쳐서 사용자 번들 점수를 예측한다. 훈련 중 CoHeat는 초기에 역사관을 우선시하여 교육과정 난방을 통해 점진적으로 소속관으로 전환한다. CoHeat는 또한 두 뷰를 규칙화하기 위해 정렬 및 균일성 손실을 이용한다.\n' +
      '\n' +
      '### 두 개의 그래프 기반 뷰\n' +
      '\n' +
      '번들 추천의 목적은 사용자의 잠재 표상을 학습하여 사용자와 번들 간의 관계를 추정하는 것이다. 우리는 주어진 사용자-번들 상호작용, 사용자-항목 상호작용 및 번들-항목 소속을 완전히 활용하기 위해 사용자와 번들의 그래프 기반 표현을 활용한다. 우리는 히스토리-뷰 및 소속-뷰 그래프를 구성하고 LightGCN(Hu et al., 2017)을 사용하여 사용자 및 번들의 임베딩을 획득한다(Hu et al., 2018).\n' +
      '\n' +
      '**기록 보기 표현 및 점수.** 기록 보기에서는 사용자와 번들 간의 동작 신호를 캡처하는 것을 목표로 합니다. 구체적으로 사용자-번들 상호작용을 이용하여 이분 그래프를 구성하고, LightGCN을 이용하여 이력 정보를 전파한다.\n' +
      '\n' +
      '도 3. CoHeat 개요(자세한 내용은 섹션 3 참조).\n' +
      '\n' +
      'LightGCN의 \\(k\\)\'번째 층은 다음과 같이 계산된다:\n' +
      '\n' +
      '\\sum_{b\\in\\mathcal{N}_{u}\\frac{1}{\\sqrt{|\\mathcal{N}_{u}|}\\sqrt{|\\mathcal{N}_{b}|}\\,\\mathbf{h}_{b}^{(k-1)}, \\\\mathbf{h}_{b}^{(k-1)}&=\\sum_{u\\in\\mathcal{N}_{b}} \\frac{1}{\\sqrt{|\\mathcal{N}_{b}|}\\sqrt{|\\mathcal{N}_{u}|}\\,\\mathbf{h}_{u}^{(k -1)},\\end{split} \\tag{1}\\]\n' +
      '\n' +
      '여기서, \\(\\mathbf{h}_{u}^{(k)},\\mathbf{h}_{b}^{(k)}\\in\\mathbb{R}^{d}\\)는 각각 \\(k\\)\'번째 계층에서 사용자 \\(u\\)와 번들 \\(b\\)의 임베딩이고, \\(\\mathcal{N}_{u}\\)과 \\(\\mathcal{N}_{b}\\)은 각각 사용자-번들 그래프에서 사용자 \\(u\\)\' 이웃과 번들 \\(b\\)\' 이웃의 집합이다. \\ (\\mathbf{h}_{u}^{(0)},\\mathbf{h}_{b}^{(0)}\\in\\mathbb{R}^{d}\\)는 모델의 학습 전에 무작위로 초기화된다. 사용자 \\(u\\)와 번들 \\(b\\)의 히스토리 뷰 표현들은 다음과 같이 하위 계층에 더 중점을 두는 가중치 접근법으로 모든 계층에서 임베딩을 집계함으로써 얻어진다.\n' +
      '\n' +
      '\\[\\mathbf{h}_{u}=\\sum_{k=0}^{K}\\frac{1}{k+1}\\mathbf{h}_{u}^{(k)},\\mathbf{h}_{b }=\\sum_{k=0}^{K}\\frac{1}{k+1}\\mathbf{h}_{b}^{(k)}, \\tag{2}\\]\n' +
      '\n' +
      '여기서, \\(\\mathbf{h}_{u},\\mathbf{h}_{b}\\in\\mathbb{R}^{d}\\)는 각각 사용자 \\(u\\)와 번들 \\(b\\)의 히스토리뷰 임베딩이고, \\(K\\)은 마지막 계층을 나타낸다. 마지막으로 사용자 \\(u\\)와 번들 \\(b\\) 사이의 히스토리뷰 점수를 \\(\\mathbf{h}_{ub}=\\mathbf{h}_{u}^{\\mathrm{T}}\\mathbf{h}_{b}\\)으로 정의한다.\n' +
      '\n' +
      '**소속 보기 표시 및 점수.** 소속 보기에서는 항목 소속의 관점에서 사용자와 번들 간의 관계를 학습하는 것을 목표로 합니다. 구체적으로 사용자-아이템 상호작용을 이용하여 이분 그래프를 구성하고, 다른 LightGCN을 이용하여 이력 정보를 전파한다. 그리고 소속된 아이템들의 표현을 종합하여 번들 표현을 얻는다. LightGCN의 \\(k\\)\'번째 계층은 다음과 같이 계산된다.\n' +
      '\n' +
      '\\mathcal{N}_{u}^{(k)}&=\\sum_{i\\in \\mathcal{N}_{u}^{\\prime}|}\\sqrt{|\\mathcal{N}_{ i}|}\\,\\mathbf{a}_{i}^{(k-1)},\\\\ \\mathbf{a}_{i}^{(k)}&=\\sum_{u\\in\\mathcal{N}_{i}} \\frac{1}{\\sqrt{|\\mathcal{N}_{i}|}\\,\\mathbf{a}_{u}^{(k-1)},\\end{split} \\tag{3}\\]\n' +
      '\n' +
      '여기서, \\(\\mathbf{a}_{u}^{(k)},\\mathbf{a}_{i}^{(k)}\\in\\mathbb{R}^{d}\\)는 각각 \\(k\\)\'번째 계층에서 사용자 \\(u\\)와 항목 \\(i\\)의 임베딩이고, \\(\\mathcal{N}_{u}^{\\prime}\\)과 \\(\\mathcal{N}_{i}\\)은 각각 사용자-항목 그래프에서 사용자 \\(u\\)\'이웃과 항목 \\(i\\)\'이웃의 집합이다. \\ (\\mathbf{a}_{u}^{(0)},\\mathbf{a}_{i}^{(0)}\\in\\mathbb{R}^{d}\\)는 훈련 전에 무작위로 초기화된다. 사용자 \\(u\\) 및 항목 \\(i\\)의 소속-뷰 표현들은 모든 계층으로부터 임베딩들을 다음과 같이 가중 접근법으로 집계함으로써 얻어진다:\n' +
      '\n' +
      '\\[\\begin{split}\\mathbf{a}_{u}=\\sum_{k=0}^{K}\\frac{1}{k+1}\\mathbf{a }_{u}^{(k)},\\mathbf{a}_{i}=\\sum_{k=0}^{K}\\frac{1}{k+1}\\mathbf{a}_{i}^{(k)}, \\end{split} \\tag{4}\\]\n' +
      '\n' +
      '여기서, \\(\\mathbf{a}_{u},\\mathbf{a}_{i}\\in\\mathbb{R}^{d}\\)는 각각 사용자 \\(u\\)와 항목 \\(i\\)의 소속뷰 임베딩이고, \\(K\\)은 마지막 계층을 나타낸다. 그리고 평균 풀링을 통해 번들 \\(b\\)의 소속-관 표현을 얻는다. \\(\\mathbf{a}_{b}=\\frac{1}{|\\mathcal{N}_{b}|}\\sum_{i\\in\\mathcal{N}_{b}}\\mathbf{a}_{i}\\), 여기서 \\(\\mathcal{N}_{b}^{\\prime}\\)은 번들 \\(b\\)의 소속 항목 집합이다. 마지막으로 사용자 \\(u\\)와 번들 \\(b\\) 사이의 소속-관점 점수를 \\(a_{ub}=\\mathbf{a}_{u}^{\\mathrm{T}}\\mathbf{a}_{b}\\)으로 정의한다.\n' +
      '\n' +
      '### Popularity-based Coalescence\n' +
      '\n' +
      '사용자에게 번들을 추천하기 위해, 본 논문의 목적은 사용자 \\(u\\)와 번들 \\(b\\) 사이의 최종 점수 \\(\\hat{y}_{ub}\\in\\mathbb{R}\\)을 두 개의 별개의 관점에서 도출된 점수 \\(h_{ub}\\)과 \\(a_{ub}\\)을 이용하여 추정하는 것이다. 그러나 실제 데이터 세트는 그림 0(a)와 같이 사용자와 번들 간의 상호 작용의 극도로 치우친 분포를 처리하는 고유한 문제를 제시한다. 두 뷰 모두 유익한 정보이지만 그림 0(b)와 같이 상호 작용이 충분하지 않기 때문에 많은 인기 없는 번들이 히스토리 뷰에서 과소 표현된다. 대조적으로, 그것들은 종종 그림 0(c)에 묘사된 바와 같이 소속-관점에서 충분히 표현된다. CrossCBR에서와 같이 두 뷰에 대한 균일한 가중치 전략은 특히 인기 없는 번들에 대해 히스토리 뷰 고유의 편향을 증폭시킬 위험이 있다. 이 곤경은 히스토리 뷰 데이터가 없는 콜드 스타트 번들에 대해 더욱 악화된다.\n' +
      '\n' +
      '이 문제를 해결하기 위해, 우리는 사용자-묶음 관계 점수 \\(\\hat{y}_{ub}\\)에 대한 두 가지 원하는 속성을 제안한다.\n' +
      '\n' +
      '속성 1_ (History-view 영향 완화): 번들의 상호 작용 수가 감소함에 따라, 즉 \\(n_{b}<n_{b^{\\prime}}\\)이 번들의 상호 작용 수 \\(b\\)인 경우 \\(\\frac{\\partial\\hat{y}_{ub}}{\\partial h_{ub}}<\\frac{\\partial\\hat{y}_{ub^{\\prime}}}}{\\partial h_{ub^{\\prime}}}\\)의 영향을 완화해야 한다.\n' +
      '\n' +
      '속성 2_(소속-관점 영향 증폭): 소속-관점의 영향은 번들의 상호작용 수가 감소함에 따라 증폭되어야 한다. 즉, \\(n_{b}<n_{b^{\\prime}}\\)이 번들의 상호작용 수 \\(b\\)인 경우 \\(\\frac{\\partial\\hat{y}_{ub}}{\\partial h_{ub}}>\\frac{\\partial\\hat{y}_{ub^{\\prime}}}{\\partial u_{ub^{\\prime}}}\\)이다.\n' +
      '\n' +
      '속성 1과 속성 2는 번들 대중성을 기반으로 한 역사관과 소속관 점수 사이의 균형 잡힌 상호 작용을 달성하는 데 중요하다. 특히, 그들은 덜 인기 있는 묶음에 대한 역사관보다 소속관에 대한 강조를 강화한다.\n' +
      '\n' +
      '본 논문에서는 번들 인기도를 기반으로 두 개의 점수 \\(h_{ub}\\)와 \\(a_{ub}\\)에 가중치를 부여하여 원하는 두 속성을 만족하는 사용자-번들 관계 점수 \\(\\hat{y}_{ub}\\)을 다음과 같이 제안한다.\n' +
      '\n' +
      '\\[\\hat{y}_{ub}=\\gamma_{b}h_{ub}+(1-\\gamma_{b})a_{ub}, \\tag{5}\\]\n' +
      '\n' +
      '여기서 다음 소절에서 정의되는 \\(\\gamma_{b}\\in[0,1]\\)은 \\(n_{b}>n_{b^{\\prime}}\\)일 경우 \\(\\gamma_{b}>\\gamma_{b^{\\prime}}\\)과 같은 가중계수를 나타낸다. \\(\\gamma_{b}\\)의 값이 작을수록(즉, \\(n_{b}\\)의 값이 작을수록) 점수 \\(\\hat{y}_{ub}\\)는 소속-관점 점수 \\(a_{ub}\\)의 영향을 많이 받는다. 우리는 렘마스 3.1과 3.2에서 식 (5)가 원하는 성질을 모두 만족한다는 것을 보여준다.\n' +
      '\n' +
      '**Lemma 3.1**.: _식 (5)는 속성 1._을 만족합니다.\n' +
      '\n' +
      '(\\frac{\\partial\\hat{y}_{ub}}{\\partial h_{ub}}=\\gamma_{b}\\). 따라서 \\(\\frac{\\partial\\hat{y}_{ub}}{\\partial h_{ub}}<\\frac{\\partial\\hat{y}_{ub^{\\prime}}}}{\\partial h_{ub^{\\prime}}}\\)\\(n_{b}<n_{b^{\\prime}}\\)인 경우 \\(\\gamma_{b}<\\gamma_{b^{\\prime}}\\)이기 때문이다.\n' +
      '\n' +
      '**Lemma 3.2**.: _식 (5)는 속성 2._를 만족합니다.\n' +
      '\n' +
      '(\\frac{\\partial\\hat{y}_{ub}}{\\partial a_{ub}}=1-\\gamma_{b}\\). 따라서 \\(n_{b}<n_{b^{\\prime}}\\)일 경우 \\(1-\\gamma_{b}>1-\\gamma_{b^{\\prime}}\\)이므로 \\(\\frac{\\partial\\hat{y}_{ub}}{\\partial a_{ub}}>\\frac{\\partial\\hat{y}_{ub^{\\prime} }}{\\partial a_{ub^{\\prime}}}\\)이다.\n' +
      '\n' +
      '### Curriculum Heating\n' +
      '\n' +
      '소속관이 제공하는 풍부한 정보에도 불구하고 묶음의 여러 항목은 소속관 표상의 학습을 복잡하게 만든다. 이러한 어려움은 번들의 정확한 표현이 모든 연관된 아이템들에 대한 잘 표현된 임베딩을 필요로 하기 때문에 발생한다. 다른 한편으로 역사관 표상은 비교적 배우기 쉽다. 이러한 단순성은 번들의 복잡한 구성을 이해하기보다는 각 번들의 역사적 특성을 단일 임베딩으로 캡슐화하기 때문에 발생한다.\n' +
      '\n' +
      '따라서 우리는 처음에 역사관 표상을 훈련하는 데 초점을 맞춘 교육과정 학습 접근법을 활용하여 식 (5)를 수정하고 점차적으로 초점을 다음과 같이 소속관 표상으로 전환한다.\n' +
      '\n' +
      '\\[\\hat{g}_{ub}^{(t)}=Y_{b}^{(t)}h_{ub}+(1-Y_{b}^{(t)})a_{ub}, \\tag{6}\\]\n' +
      '\n' +
      '여기서 \\(\\hat{g}_{ub}^{(t)}\\in\\mathbb{R}\\)는 epoch \\(t\\)에서 사용자 \\(u\\)와 번들 \\(b\\) 간의 추정 관계 점수입니다. \\ (Y_{b}^{(t)}\\in\\mathbb{R}\\)는 \\(Y_{b}^{(t)}=\\tanh\\left(\\frac{n_{b}}{\\hat{y}^{(t)}}\\right)\\)로 정의되며, 여기서 \\(n_{b}\\)은 번들의 상호작용 수 \\(b\\), \\(\\hat{y}^{(t)}>0\\)은 epoch \\(t\\)에서의 온도이다. \\(Y_{b}^{(t)}\\)는 \\([0,1]\\) 간격 내에 있습니다. \\(\\frac{n_{b}}{\\hat{y}^{(t)}}\\geq 0\\) 때문입니다. 그런 다음, 다음과 같이 온도 \\(\\hat{y}^{(t)}\\)를 최대 온도까지 점진적으로 상승시킵니다.\n' +
      '\n' +
      '\\[\\hat{y}^{(t)}=e^{t/T},t\\cdot 0\\to T, \\tag{7}\\]\n' +
      '\n' +
      '여기서 \\(t,T\\in\\mathbb{R}\\)은 훈련 과정의 전류와 최대 epoch이고, \\(\\epsilon>1\\)은 최대 온도의 하이퍼파라미터이다. 훈련 초기에는 \\(t\\)이 작기 때문에 \\(Y_{b}^{(t)}\\)이 크다. 그 결과, 점수 \\(\\hat{y}_{ub}^{(t)}\\)는 \\(a_{ub}\\)보다 \\(h_{ub}\\)에 더 많이 의존한다. 그러나 훈련이 진행됨에 따라 \\(t\\)이 증가하면 \\(Y_{b}^{(t)}\\)이 감소하여 강조점이 \\(h_{ub}\\)에서 \\(a_{ub}\\)으로 이동하게 된다. 이 가열 메커니즘은 인기에 관계없이 모든 번들에 적용됩니다. 나아가 우리는 렘마스 3.3과 3.4에서 식 (6)이 여전히 원하는 두 성질을 만족한다는 것을 보여준다.\n' +
      '\n' +
      '**Lemma 3.3**.: _식 (6)은 속성 1._을 충족합니다.\n' +
      '\n' +
      '(\\frac{\\partial\\hat{g}_{ub}^{(t)}}{\\partial h_{ub}}=\\tanh\\left(\\frac{n_{b}}{ \\hat{y}^{(t)}}\\right)\\). 따라서 \\(\\frac{\\partial\\hat{g}_{ub}^{(t)}}{\\partial h_{ub}}<\\frac{\\partial\\hat{g}_{ub ^{(t)}}^{(t)}}{\\partial h_{ub^{\\prime}}}\\)의 경우 \\(n_{b}<n_{b^{\\prime}}\\)의 경우 \\(\\hat{y}^{(t)}\\)은 epoch\\(t\\)에서 모든 다발에 대해 동일하고 \\(tanh(\\cdot)\\)은 증가하는 함수이다.\n' +
      '\n' +
      '**Lemma 3.4**.: _식 (6)은 속성 2._를 충족합니다.\n' +
      '\n' +
      '(\\frac{\\partial\\hat{g}_{ub}^{(t)}}{\\partial h_{ub}}=1-\\tanh\\left(\\frac{n_{b}}{ \\hat{y}^{(t)}}\\right)\\). 따라서 \\(\\frac{\\partial\\hat{g}_{ub}^{(t)}}{\\partial a_{ub}}\\geq\\frac{\\partial\\hat{g}_{ ub^{\\prime}}^{(t)}}{\\partial a_{ub^{\\prime}}}\\)\\(n_{b}<n_{b^{\\prime}}\\)인 경우 \\(\\hat{y}^{(t)}\\)은 epoch\\(t\\)에서 모든 다발에 대해 동일하고 \\(1-tanh(\\cdot)\\)는 감소하는 함수이다.\n' +
      '\n' +
      '### 표현 정렬 및 균일성\n' +
      '\n' +
      '역사관과 소속관은 별개의 표상을 캡처하도록 제작되지만, 특히 소속관 표상에만 기초하여 콜드 번들의 미래 상호작용을 예측할 때 두 관점을 정렬하는 것이 필수적이다. 이를 위해, 우리는 두 관점을 조화시키는 대조적 학습 기반 접근법을 이용한다. 구체적으로, 두 뷰의 표현을 위한 정규화로서 정렬 및 균일성 손실(Srivastava et al., 2015)을 사용한다. 먼저 두 뷰의 임베딩을 다음과 같이 정규화합니다. \\(l_{2}\\)-\n' +
      '\n' +
      '\\[\\hat{\\mathbf{h}}_{u}=\\frac{\\mathbf{h}_{u}}{\\|\\mathbf{h}_{u}\\|_{2}},\\hat{ \\mathbf{a}}_{u}=\\frac{\\mathbf{a}_{u}}{\\|\\mathbf{a}_{u}\\|_{2}},\\hat{\\mathbf{h} _{b}=\\frac{\\mathbf{h}_{b}}{\\|\\mathbf{h}_{b}\\|_{2}},\\hat{\\mathbf{a}_{b}=\\frac {\\mathbf{a}_{b}}{\\|\\mathbf{a}_{b}\\|_{2}}, \\tag{8}\\}\n' +
      '\n' +
      '여기서, \\(\\mathbf{h}_{u},\\mathbf{h}_{b}\\in\\mathbb{R}^{d}\\)는 각각 사용자 \\(u\\)와 번들 \\(b\\)의 히스토리뷰 표현이고, \\(\\mathbf{a}_{u},\\mathbf{a}_{b}\\in\\mathbb{R}^{d}\\)는 각각 사용자 \\(u\\)와 번들 \\(b\\)의 소속뷰 표현이다. 그런 다음, 다음과 같이 정렬 손실을 정의한다:\n' +
      '\n' +
      '\\[l_{align}=\\mathop{\\mathbb{E}}_{u\\text{-}puser}\\|\\hat{\\mathbf{h}}_{u}-\\hat{ \\mathbf{a}}_{u}\\|_{2}^{2}+\\mathop{\\mathbb{E}}_{b\\text{-}pbundle}\\|\\hat{ \\mathbf{h}}_{b}-\\hat{\\mathbf{a}}_{b}\\|_{2}^{2}, \\tag{9}\\]\n' +
      '\n' +
      '여기서 \\(p_{user}\\)과 \\(p_{bundle}\\)은 각각 사용자와 번들의 분포이다. 선형 손실은 각 사용자 및 번들에 대해 두 뷰의 임베딩을 서로 가깝게 만듭니다. 또한 다음과 같이 균일성 손실을 정의한다:\n' +
      '\n' +
      '\\[l_{uniform} =\\log\\mathop{\\mathbb{E}}_{u\\text{-}puser}e^{-2\\|\\hat{\\mathbf{h}}_{u^{\\prime}}\\|_{2}^{2}}\\] \\[+\\log\\mathop{\\mathbb{E}}_{u}-\\hat{\\mathbf{a}}_{u^{\\prime}}\\|_{2}^{2}}\\] \\[+\\log\\mathop{\\mathbb{E}}_{b\\text{,}b^{\\prime}\\hat{\\mathbf{h}}_{b}-\\hat{\\mathbf{h}}_{b^{\\prime}}\\|_{2}^{2}}\\[+\\log\\mathop{\\mathbb{E}}_{pbundle}e^{-2\\|\\hat{\\mathbf{h}}_{b^{\\prime}}\\mathop{\\mathbb{E}}_{b^{\\prime}}\\hat{\\mathbf{a}}_{b^{\\\n' +
      '\n' +
      '여기서 \\(u^{\\prime}\\) 및 \\(b^{\\prime}\\)은 각각 \\(u\\) 및 \\(b\\)과 구별되는 사용자 및 번들을 나타낸다. 균일성 손실은 공간을 가로질러 그들을 산란시킴으로써 상이한 사용자들(또는 번들들)에 대한 별개의 표현들을 보장한다. 마지막으로, 두 뷰에 대한 대비 손실을 다음과 같이 정의한다:\n' +
      '\n' +
      '\\[\\mathcal{L}_{AU}=l_{align}+l_{uniform}. \\tag{11}\\]\n' +
      '\n' +
      '### 목적 함수 및 훈련\n' +
      '\n' +
      '사용자-번들 관계를 효과적으로 학습하기 위해, 그 강력성으로 인해 가장 널리 사용되는 손실인 BPR(Bayesian Personalize Ranking) 손실(Kang et al., 2017)을 다음과 같이 활용한다:\n' +
      '\n' +
      '\\[\\mathcal{L}_{BPR}^{(t)}=\\mathop{\\mathbb{E}}_{(u,b^{\\prime},b^{\\prime})\\text{-}p _{data}}-\\ln\\sigma(\\hat{y}_{ub^{\\prime}}^{(t)}-\\hat{y}_{ub^{\\prime}}^{(t)}), \\tag{12}\\]\n' +
      '\n' +
      '여기서, \\(p_{data}\\)은 사용자-번들 상호작용의 데이터 분포이며, \\(u\\)은 사용자를 나타내고, \\(b^{+}\\)은 양의 번들을 나타내고, \\(b^{-}\\)은 음의 번들을 나타낸다. 최종 목적 함수를 다음과 같이 정의합니다.\n' +
      '\n' +
      '\\[\\mathcal{L}^{(t)}=\\mathcal{L}_{BPR}^{(t)}+\\lambda_{1}\\mathcal{L}_{AU}+\\lambda_{2} \\|\\theta\\|_{2}, \\tag{13}\\]\n' +
      '\n' +
      '여기서 \\(\\lambda_{1},\\lambda_{2}\\in\\mathbb{R}\\)은 항에 대한 하이퍼파라미터의 균형을 이루고, \\(\\theta\\)은 CoHeat의 훈련 가능한 파라미터를 나타낸다. 분포 \\(p_{user}\\)과 \\(p_{bundle}\\)의 경우 전체 데이터 집합이 아닌 \\(p_{data}\\)의 훈련 배치에서 샘플을 선택하는 배치 내 샘플링을 사용한다. 이러한 접근법은 선행 연구들(Srivastava et al., 2015; Wang et al., 2016)에서 트레이닝 편향을 완화하기 위해 경험적으로 입증되었다. 모든 파라미터는 최적화를 통해 종단간 방식으로 최적화된다. 또한, 성능 강건성을 향상시키기 위해 훈련하는 동안 에지 드롭아웃(Kang et al., 2017; Wang et al., 2016)을 채택한다.\n' +
      '\n' +
      '## 4. Experiments\n' +
      '\n' +
      '이 절에서는 다음과 같은 질문에 답하기 위해 실험을 수행한다.\n' +
      '\n' +
      '1. **콜드 시작 방법과의 비교.** CoHeat가 번들 권장 사항에서 다른 콜드 시작 방법에 비해 우수한 성능을 나타내나요?\n' +
      '2. **웜 시작 방법과의 비교** CoHeat는 콜드 시작 번들 권장 방법이기는 하지만 기준선과 비교하여 웜 시작 번들 권장 사항에서 유사한 성능을 나타내나요?\n' +
      '3. **절제 연구.** CoHeat의 주요 아이디어는 성능에 어떻게 영향을 미칩니까?\n' +
      '4. **최대 온도의 영향** 임계 하이퍼 매개 변수인 최대 온도 \\(\\epsilon\\)가 CoHeat 성능에 어떻게 영향을 미칩니까?\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:6]\n' +
      '\n' +
      '웜 시작 시나리오의 기준선입니다. 이는 CoHeat가 사용자 번들 상호작용의 극도로 치우친 분포를 처리함으로써 히스토리 뷰와 소속 뷰 모두에서 표현을 효과적으로 학습한다는 것을 나타낸다. 기준선의 경우 SGL, SimGCL, LightGCL 및 CrossCBR에서 예시된 대로 대조 학습을 사용할 때 성능이 향상된다. 또한 LightGCN, SGL, SimGCL, LightGCL, BundleNet, BGCN 및 CrossCBR과 같은 그래프 기반 모델이 다른 비그래프 기반 모델보다 우수하다. 이러한 관찰에 비추어 CoHeat는 전략적으로 그래프 기반 모델링 접근법을 활용하고 대조 학습의 힘을 활용한다. 따라서 CoHeat는 다양한 시나리오에서 가장 높은 성능을 강력하게 달성할 수 있습니다.\n' +
      '\n' +
      '### Ablation Study (Q3)\n' +
      '\n' +
      '표 4는 CoHeat를 CoHeat-_PC_, CoHeat-_CH_ 및 CoHeat-_AU_의 세 가지 변형과 비교하는 절제 연구를 제공한다. 이 연구는 우리 작업의 주요 초점인 콜드 스타트 시나리오에서 수행된다. CoHeat-_PC_에서는 식 (5)의 \\(\\gamma_{b}^{(t)}\\) 값을 상수 0.5로 설정하여 인기 기반 통합의 영향을 제거한다. CoHeat-_CH_의 경우 반교육과정 학습 전략을 활용한다. 식 (7)의 온도는 \\(t:T\\~0\\)으로 정의하여 소속관으로 학습 과정을 시작하고 점차 히스토리관으로 초점을 이동시킨다. CoHeat-_AU_의 경우 식 (13)에서 \\(\\mathcal{L}_{AU}\\)을 생략하여 두 뷰 사이의 대조적 학습을 제외한다. 표에서 볼 수 있듯이 CoHeat는 모든 변형을 일관되게 능가하며, 이는 모든 주요 아이디어가 성능을 개선하는 데 도움이 된다는 것을 확인합니다. 특히 CoHeat-_PC_는 콜드 스타트 번들 추천에 내재된 극단적 왜도를 다룰 때 속성 1과 2를 만족시키는 것의 중요성을 정당화하는 심각한 성능 저하를 보인다.\n' +
      '\n' +
      '### 최대 온도 (Q4)의 영향\n' +
      '\n' +
      '식 (7)의 최대 온도 \\(\\epsilon\\)은 인기 기반 합체와 커리큘럼 난방 모두에 직접적인 영향을 미치기 때문에 CoHeat의 가장 영향력 있는 하이퍼파라미터이다. 따라서, 우리는 그림 4와 같이 저온 시동 시나리오에서 \\(\\epsilon\\)이 실제 데이터 세트에 미치는 영향을 분석한다. 그림에서 볼 수 있듯이 CoHeat는 소속 뷰의 표현이 충분히 학습되지 않았기 때문에 극저온에 대해 낮은 성능을 보인다. 극한 고온의 경우 교육과정의 속도가 너무 빨라 두 견해의 표상을 충분히 학습할 수 없기 때문에 성능이 저하된다. 그 결과, 모든 데이터셋에 대해 \\(\\epsilon\\)을 \\(10^{4}\\)으로 설정하는 것이 가장 좋은 성능을 보였다.\n' +
      '\n' +
      '## 5. 관련 작업\n' +
      '\n' +
      '**번들 권장 사항.** 본 연구는 번들 권장 사항의 콜드 스타트 문제에 중점을 둡니다. 이전의 작업들은 그들의 모델링 구조에 기초하여 분류될 수 있다 : 매트릭스 인수분해-기반 모델들(Krizhevsky et al., 2014; He et al., 2015; He et al., 2016) 및 그래프 학습-기반 모델들(Krizhevsky et al., 2014; He et al., 2015; He et al., 2016; He et al., 2017). 이러한 방법은 모든 번들이 과거 상호 작용을 가지고 있다는 가정 하에 작동하여 콜드 스타트 문제를 해결하는 데 적합하지 않다. 그러나 실제 시나리오에서는 매일 새 번들이 도입되어 고유한 콜드 스타트 도전이 발생합니다. 우리의 작업은 현장에 미칠 잠재적 영향을 인식하여 이 중요하지만 간과된 문제를 해결한다.\n' +
      '\n' +
      '**콜드 스타트 권장 사항.** 추천 시스템의 오랜 도전인 콜드 스타트 문제는 사용자와 아직 상호 작용하지 않은 콜드 스타트 항목을 추천하는 데 중점을 둡니다. 기존 작업은 크게 생성 방식(Krizhevsky et al., 2014; He et al., 2015; He et al., 2016; He et al., 2017), 탈락 기반 방식(Krizhevsky et al., 2014; He et al., 2015; He et al., 2016), 메타 학습 방식(He et al., 2016), 제약 기반 방식(Krizhevsky et al., 2014; He et al., 2015; He et al., 2017)으로 구분된다. 그러나 이러한 선행 연구는 번들 추천에서 중요한 요소인 상호 작용의 고도로 왜곡된 분포를 명시적으로 다루지 않았다. 따라서 본 연구는 훈련 중 왜곡된 분포를 효과적으로 고려함으로써 콜드 스타트 번들 추천에서 이러한 방법보다 우수하다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c|c c|c c} \\hline \\hline \\multirow{3}{*}{**Model**} & \\multicolumn{2}{c|}{**Youshu**} & \\multicolumn{2}{c|}{**NetEase**} & \\multicolumn{2}{c}{**iFashion**} \\\\  & Recall & nDCG & Recall & nDCG & Recall & nDCG \\\\  & @20 & @20 & @20 & @20 & @20 & @20 & @20 \\\\ \\hline MFBPR (He et al., 2016) &.1959 &.1117 &.0355 &.0181 &.0752 &.0542 \\\\ LightGCN (He et al., 2016) &.2286 &.1344 &.0496 &.0254 &.0837 &.0612 \\\\ SGL (He et al., 2016) &.2568 &.1527 &.0687 &.0368 &.0933 &.0690 \\\\ SimGCL (He et al., 2016) &.2691 &.1593 &.0710 &.0377 &.0919 &.0677 \\\\ LightGCL (He et al., 2016) &.2712 &.1607 &.0722 &.0388 &.0943 &.0686 \\\\ \\hline DAM (He et al., 2016) &.2082 &.1198 &.0411 &.0210 &.0629 &.0450 \\\\ BundlesNet (He et al., 2016) &.1895 &.1125 &.0391 &.0201 &.0626 &.0447 \\\\ BGCN (Krizhevsky et al., 2014) &.2347 &.1345 &.0491 &.0258 &.0733 &.0531 \\\\ CrossCBR (He et al., 2016) &.2776 &.1641 &.0791 &.0433 &.1133 &.0875 \\\\ \\hline\n' +
      '**CoHeat (ours)** & **.2804** & **.1646** & **.0847** & **.0455** & **.1156** & **.0876** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3. 세 개의 실제 데이터 세트에 대한 CoHeat 및 베이스라인 웜-스타트 방법의 성능 비교.\n' +
      '\n' +
      '그림 4. 최대 온도 \\(\\epsilon\\)의 영향.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c c|c c|c c} \\hline \\hline \\multirow{3}{*}{**Model**} & \\multicolumn{2}{c|}{**Youshu**} & \\multicolumn{2}{c|}{**NetEase**} & \\multicolumn{2}{c}{**iFashion**} \\\\  & Recall & nDCG & Recall & nDCG & Recall & nDCG \\\\  & @20 & @20 & @20 & @20 & @20 & @20 \\\\ \\hline MFBPR (He et al., 2016) &.1959 &.1117 &.0355 &.0181 &.0752 &.0542 \\\\ LightGCN (He et al., 2016) &.2286 &.1344 &.0496 &.0254 &.0837 &.0612 \\\\ SGL (He et al., 2016) &.2568 &.1527 &.0687 &.0368 &.0933 &.0690 \\\\ SimGCL (He et al., 2016) &.2691 &.1593 &.0710 &.0377 &.0919 &.0677 \\\\ LightGCL (He et al., 2016) &.2712 &.1607 &.0722 &.0388 &.0943 &.0686 \\\\ \\hline DAM (He et al., 2016) &.2082 &.1198 &.0411 &.0210 &.0629 &.0450 \\\\ BundlesNet (He et al., 2016) &.1895 &.1125 &.0391 &.0201 &.0626 &.0447 \\\\ BGCN (Krizhevsky et al., 2014) &.2347 &.1345 &.0491 &.0258 &.0733 &.0531 \\\\ CrossCBR (He et al., 2016) &.2776 &.1641 &.0791 &.0433 &.1133 &.0875 \\\\ \\hline\n' +
      '**CoHeat (ours)** & **.2804** & **.1646** & **.0847** & **.0455** & **.1156** & **.0876** \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4. 우리의 주요 목표인 저온 시동 시나리오에서 CoHeat의 절제 연구.\n' +
      '\n' +
      '[MISSING_PAGE_FAIL:8]\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>