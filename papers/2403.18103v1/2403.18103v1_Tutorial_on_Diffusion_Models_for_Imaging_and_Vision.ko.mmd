# 영상 및 시각의 확산 모델에 대한 자습서

Stanley Chan

웨스트 라파예트, 퍼듀 대학교, 전기 및 컴퓨터 공학부, 47907.

Email: stanchan@purdue.edu.

###### Abstract

최근 몇 년 동안 생성 도구의 놀라운 성장은 텍스트-이미지 생성 및 텍스트-비디오 생성에서 많은 흥미로운 응용 프로그램에 힘을 실어주었다. 이러한 생성 도구의 기본 원리는 이전 접근법에서 어렵다고 간주되었던 일부 단점을 극복한 특정 샘플링 메커니즘인 _확산_의 개념이다. 이 자습서의 목표는 확산 모델의 기본 개념을 논의하는 것이다. 이 튜토리얼의 대상 고객은 확산 모델에 대한 연구를 수행하거나 다른 문제를 해결하기 위해 이러한 모델을 적용하는 데 관심이 있는 학부 및 대학원생을 포함한다.

###### Contents

*1 기본 사항: Variational Auto-Encoder (VAE)
	* 1.1 VAE 설정
	* 1.2 증거 하한
	* 1.3 훈련 VAE
	* 1.4 손실함수
	* 1.5 VAE와의 추론
* 2 DDPM(Denoising Diffusion Probabilistic Model)
	* 2.1 빌딩 블록
	* 2.2 마법 스칼라 \(\sqrt{\alpha_{t}}\) 및 \(1-\alpha_{t}\)
	* 2.3 분포 \(q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{0})\)
	* 2.4 증거 하한
	* 2.5 일관성 용어 다시 쓰기
	* 2.6 \(q_{\mathbf{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\)의 유도
	* 2.7 Training and Inference
	* 잡음 벡터에 기반한 2.8 도출
	* 2.9 InDI(Direct Denoising)에 의한 Inversion
* 3 Score-Matching Langevin Dynamics (SMLD)
	* 3.1 Langevin Dynamics
	* 3.2(Stein's) 점수함수
	* 3.3 스코어 매칭 기법
*4 확률미분방정식(SDE)
	* 4.1 자극 실시예
	* 4.2 SDE에서의 순방향 및 역방향 반복
	* 4.3 DDPM에 대한 확률적 미분방정식
	* 4.4 SMLD에 대한 확률적 미분방정식
	* 4.5 Solving SDE
* 5 결론: Variational Auto-Encoder (VAE)

### VAE Setting

오래 전, 멀리 떨어진 은하계에서 우리는 잠재 코드로부터 이미지를 생성하는 발전기를 만들고자 합니다. 가장 간단한(그리고 아마도 가장 고전적인) 접근법은 아래에 표시된 인코더-디코더 쌍을 고려하는 것이다. 이를 VAE(variational autoencoder) [1, 2, 3]이라고 합니다.

오토인코더는 입력변수 \(\mathbf{x}\)와 잠재변수 \(\mathbf{z}\)를 갖는다. 주제를 이해하기 위해 우리는 \(\mathbf{x}\)를 아름다운 이미지로, \(\mathbf{z}\)를 어떤 고차원 공간에 사는 일종의 벡터로 취급한다.

**예제**. 이미지의 잠재된 표현을 얻는 것은 외계인이 아니다. JPEG 압축(공룡이라 할 수 있는) 시대에 우리는 이산 코사인 변환(DCT) 기반 \(\boldsymbol{\varphi}_{n}\)을 사용하여 이미지의 기본 이미지/패치를 인코딩한다. 계수벡터 \(\mathbf{z}=[z_{1},\ldots,z_{N}]^{T}\)는 \(z_{n}=\langle\boldsymbol{\varphi}_{n},\mathbf{x}\rangle\)를 밑면에 투영하여 구한다. 따라서 이미지 \(\mathbf{x}\)를 주면 계수 벡터 \(\mathbf{z}\)를 반환합니다. \(\mathbf{z}\)로부터 우리는 이미지를 복원(즉, 디코딩)하기 위해 역변환을 할 수 있다. 따라서 계수벡터 \(\mathbf{z}\)는 잠재코드이다. 인코더는 DCT 변환이고, 디코더는 역 DCT 변환이다.

변수라는 이름은 \(\mathbf{x}\)와 \(\mathbf{z}\)를 설명하기 위해 확률 분포를 사용하는 요인에서 비롯된다. \(\mathbf{x}\)를 \(\mathbf{z}\)로 변환하는 결정론적 절차에 의존하는 대신, 우리는 분포 \(p(\mathbf{x})\)가 원하는 분포 \(p(\mathbf{z})\)에 매핑될 수 있고, \(p(\mathbf{x})\)로 거꾸로 갈 수 있는지 확인하는 데 더 관심이 있다. 분포 설정 때문에 몇 가지 분포를 고려해야 합니다.

* \(p(\mathbf{x})\): \(\mathbf{x}\)의 분포. 그것은 결코 알려져 있지 않다. 그걸 알았다면 억만장자가 됐을 거야 확산 모델의 전체 은하는 \(p(\mathbf{x})\)\에서 샘플을 추출하는 방법을 찾는 것이다.
* \(p(\mathbf{z})\): 잠재변수의 분포. 우리는 모두 게으르기 때문에, 단지 0-평균 단위-분산 가우시안 \(p(\mathbf{z})=\mathcal{N}(0,\mathbf{I})\)로 만들자.
* \(p(\mathbf{z}|\mathbf{x})\): 주어진 \(\mathbf{x}\)에서 \(\mathbf{z}\)의 가능성을 알려주는 **인코더** 와 연결된 조건부 분포입니다. 우리는 그것에 접근할 수 없습니다. \ (p(\mathbf{z}|\mathbf{x})\) 자체는 인코더가 _아니요. 그러나 인코더는 \(p(\mathbf{z}|\mathbf{x})\)와 일관되게 동작하도록 무언가를 해야 합니다.
* \(p(\mathbf{x}|\mathbf{z})\): 주어진 \(\mathbf{z}\)를 얻을 사후 확률을 알려주는 **디코더** 와 관련된 조건부 분포입니다. 다시 말하지만, 우리는 그것에 접근할 수 없습니다.

위의 네 가지 분포는 너무 신비롭지 않다. 여기 그 아이디어를 설명할 수 있는 다소 사소하지만 교육적인 예가 있다.

**예제**. 확률변수 \(\mathbf{X}\)와 잠재변수 \(z\in\{1,\ldots,K\}\)가 클러스터 동일성을 나타내는 가우시안 혼합 모델에 따라 분포된 \(k=1,\ldots,K\)에 대해 \(p_{Z}(k)=\mathbb{P}[Z=k]=\pi_{k}\)를 고려한다. 우리는 \(\sum_{k=1}^{K}\pi_{k}=1\)을 가정한다. 그런 다음 \(k\) 번째 클러스터만 봐야 한다고 하면 \(Z\)가 주어진 \(\mathbf{X}\)의 조건부 분포는 다음과 같다.

\[p_{\mathbf{x}|Z}(\mathbf{x}|k)=\mathcal{N}(\mathbf{x}\,|\,\boldsymbol{\mu}_{k },\sigma_{k}^{2}\mathbf{I}).\] \(\mathbf{x}\)의 한계분포는 총확률의 법칙을 이용하여 구할 수 있으며, 이는 우리에게 주어진 것이다.

\[p_{\mathbf{X}}(\mathbf{x})=\sum_{k=1}^{K}p_{\mathbf{X}|Z}(\mathbf{x}|k)p_{Z}(k)= \sum_{k=1}^{K}\pi_{k}\mathcal{N}(\mathbf{x}\,|\,\boldsymbol{\mu}_{k},\sigma_{k}^{2}\mathbf{I}). \tag{1}\

따라서, \(p_{\mathbf{X}}(\mathbf{x})\)로 시작하는 경우, 모든 샘플 \(\mathbf{x}\sim p_{\mathbf{X}}(\mathbf{x})\)에 대해 잠재 코드가 \(z\in\{1,\ldots,K\}\) 분포를 갖는 \(z\sim p_{Z}(k)\)가 되도록 인코더가 마법 인코더를 구축하기 위한 설계 질문이다.

인코더와 디코더가 어떻게 작동하는지 설명하기 위해 평균과 분산이 알려져 있고 고정되어 있다고 가정하자. 그렇지 않으면 EM 알고리즘을 통해 평균과 분산을 추정해야 한다. 그것은 할 수 있지만 지루한 방정식은 이 삽화의 목적을 무너뜨릴 것이다.

**인코더**: \(\mathbf{x}\)에서 \(z\)를 어떻게 얻습니까? 이것은 인코더에서 \(p_{\mathbf{X}}(\mathbf{x})\)와 \(p_{Z}(k)\)를 알기 때문에 쉽다. 클래스 \(z\in\{1,2\}\)가 두 개뿐이라고 상상해 보십시오. 효과적으로 당신은 단지 표본 \(\mathbf{x}\)이 어디에 속해야 하는지에 대한 이진 결정을 내리고 있을 뿐이다. 이진 결정을 할 수 있는 방법은 여러 가지가 있다. maximum-a-posteriori를 좋아하면 확인할 수 있습니다.

\[p_{Z|\mathbf{X}}(1|\mathbf{x})\gtrless_{\text{class }2}^{\text{class }1}p_{Z|\mathbf{X}}(2|\mathbf{x}),\]

그리고 이것은 당신에게 간단한 결정 규칙을 반환할 것입니다. 당신은 우리에게 \(\mathbf{x}\), 우리는 당신에게 \(z\in\{1,2\}\)를 알려준다.

**디코더**: 디코더 쪽에서 잠재 코드 \(z\in\{1,\ldots,K\}\)가 주어지면 마법 디코더는 \(p_{\mathbf{X}|Z}(\mathbf{x}|k)=\mathcal{N}(\mathbf{x}\,|\,\boldsymbol{\mu}_{k},\sigma_{k}^{2}\mathbf{I})\에서 가져온 샘플 \(\mathbf{x}\)만 반환하면 됩니다. 다른 \(z\)는 \(K\) 혼합물 성분 중 하나를 제공합니다. 만약 우리가 충분한 표본을 가지고 있다면, 전체 분포는 가우시안 혼합을 따를 것이다.

당신 같은 똑똑한 독자들은 분명히 불평할 것입니다: "당신의 예는 아주 사소한 비현실적입니다." 걱정하지 마세요. 이해해요 물론 삶은 알려진 평균과 알려진 분산을 가진 가우시안 혼합 모델보다 훨씬 더 어렵다. 그러나 우리가 깨달은 한가지는 우리가 마법의 인코더와 디코더를 찾으려면 두 개의 조건부 분포를 찾을 수 있는 방법이 있어야 한다는 것이다. 하지만, 그들은 둘 다 고차원적인 생물이다. 그래서 우리가 더 의미 있는 말을 하기 위해서는 더 어려운 문제에 개념을 일반화할 수 있도록 추가 구조를 부과해야 합니다.

VAE의 문헌에서 사람들은 다음 두 가지 대리 분포를 고려할 아이디어를 고안한다.

* \(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})\): \(p(\mathbf{z}|\mathbf{x})\에 대한 프록시입니다. 우리는 그것을 가우시안처럼 만들 것이다. 왜 가우시안이죠? 별 이유 없어 아마도 우리는 그저 평범한(일명 게으른) 인간일 것이다.
* \(p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})\): \(p(\mathbf{x}|\mathbf{z})\에 대한 프록시입니다. 믿거나 말거나, 우리는 가우시안으로도 만들 것입니다. 그러나 이 가우시안 의 역할은 가우시안 \(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})\와는 약간 다르다. 우리는 가우시안 \(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})\)에 대한 평균과 분산을 _추정할 필요가 있지만, 가우시안 \(p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})\)에 대한 어떤 것도 추정할 필요가 없다. 대신에, 우리는 \(\mathbf{z}\)를 \(\mathbf{x}\)로 바꾸기 위해 디코더 신경망이 필요할 것이다. 가우시안 \(p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})\)은 생성된 이미지 \(\mathbf{x}\)가 얼마나 좋은지 알려주기 위해 사용될 것이다.

입력 \(\mathbf{x}\)과 잠재 \(\mathbf{z}\) 및 조건부 분포의 관계를 그림 1에 요약하였다. 두 개의 노드 \(\mathbf{x}\)와 \(\mathbf{z}\)가 있다. "정방향" 관계는 \(p(\mathbf{z}|\mathbf{x})\)로 지정되고(및 \(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})\))로 근사되는 반면, "역방향" 관계는 \(p(\mathbf{x}|\mathbf{z})\)로 지정되고(및 \(p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})\))로 근사되는 것이다.

그림 1: 변분 오토인코더에서 변수 \(\mathbf{x}\)와 \(\mathbf{z}\)는 조건부 분포 \(p(\mathbf{x}|\mathbf{z})\)와 \(p(\mathbf{z}|\mathbf{x})\)로 연결된다. 이를 위해 두 가지 프록시 분포 \(p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})\)와 \(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})\)를 각각 도입한다.

**예제**. 또 다른 사소한 예를 고려할 때이다. 우리가 랜덤 변수 \(\mathbf{x}\)와 잠재 변수 \(\mathbf{z}\)가 있다고 가정하면,

\[\mathbf{x} \sim\mathcal{N}(\mathbf{x}\,|\,\mu,\sigma^{2}),\] \[\mathbf{z} \sim\mathcal{N}(\mathbf{z}\,|\,0,1) \]\]

우리의 목표는 VAE를 건설하는 것이다. (뭐라고?!) 이 문제는 \(\mathbf{z}=(\mathbf{x}-\mu)/\sigma\)와 \(\mathbf{x}=\boldsymbol{\mu}+\sigma\mathbf{z}\)의 사소한 해결책을 가지고 있습니다. 당신이 절대적으로 옳습니다. 그러나 우리의 도출을 따라 VAE 프레임워크가 타당한지 확인하십시오.

VAE를 구축함으로써, 우리는 두 개의 매핑 "인코드"와 "디코드"를 구축하고자 한다는 것을 의미한다. 단순화를 위해, 두 매핑이 모두 어파인 변환이라고 가정하자:

\[\mathbf{z} =\text{encode}(\mathbf{x})=a\mathbf{x}+b,\qquad\text{so That} \quad\boldsymbol{\phi}=[a,b],\] \[\mathbf{x} =\text{decode}(\mathbf{z})=c\mathbf{z}+d,\qquad\text{so That} \quad\boldsymbol{\theta}=[c,d]\]

우리는 너무 게을러서 결합 분포 \(p(\mathbf{x},\mathbf{z})\), 조건 분포 \(p(\mathbf{x}|\mathbf{z})\) 및 \(p(\mathbf{z}|\mathbf{x})\를 찾을 수 없다. 그러나 프록시 분포 \(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})\)와 \(p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})\)를 구성할 수 있다. 우리는 \(q_{\boldsymbol{\phi}}\)와 \(p_{\boldsymbol{\theta}}\)가 어떻게 생겼을지를 _선택할 자유가 있기 때문에 다음 두 개의 Gaussians를 생각해 보는 것은 어떨까?

\[q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})=\mathcal{N}(\mathbf{z}\,\,|\,a\mathbf{x}+b,1),\] \[p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})=\mathcal{N}(\mathbf{x}\,\,|\,c\mathbf{z}+d,c)}(\]\]

이 두 가우스시안의 선택은 신비롭지 않다. \(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})\): \(\mathbf{x}\)가 주어지면, 물론 우리는 인코더가 우리가 선택한 구조에 따라 분포를 인코딩하기를 원한다. 인코더 구조는 \(a\mathbf{x}+b\)이므로, \(q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})\)에 대한 자연스러운 선택은 평균 \(a\mathbf{x}+b\)를 갖는 것이다. 인코딩된 샘플 \(\mathbf{z}\)이 단위 분산이어야 한다는 것을 알고 있기 때문에 분산은 \(1\)로 선택된다. 마찬가지로, \(p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})\)에 대해: \(\mathbf{z}\)가 주어지면 디코더는 \(c\mathbf{z}+d\)의 형태를 취해야 하는데, 이는 우리가 디코더를 설정하는 방식이기 때문이다. 분산은 우리가 알아내야 할 매개변수인 \(c\)이다.

이 예제를 계속하기 전에 잠시 멈춥니다. 우리는 수학적 도구를 소개하고자 한다.

### 증거 하한

이 두 가지 프록시 분포를 사용하여 인코더와 디코더를 결정하는 목표를 달성하려면 어떻게 해야 합니까? 만약 \(\boldsymbol{\phi}\)와 \(\boldsymbol{\theta}\)를 최적화 변수로 취급한다면, 훈련 샘플을 통해 \(\boldsymbol{\phi}\)와 \(\boldsymbol{\theta}\)를 최적화할 수 있도록 목적함수(또는 손실함수)가 필요하다. 이를 위해 \(\boldsymbol{\phi}\)와 \(\boldsymbol{\theta}\)의 손실함수를 설정해야 한다. 여기서 우리가 사용하는 손실함수를 Evidence Lower BOund(ELBO)[1]이라 한다:

\[\text{ELBO}(\mathbf{x})\stackrel{{\text{def}}}{{=}}\mathbb{E}_{q_{ \boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})}\left[\log\frac{p(\mathbf{x},\mathbf{ z})}{q_{\boldsymbol{\phi}}(\mathbf{z}|\mathbf{x})}\right]. \tag{2}\

어떻게 사람들이 이 손실 함수를 생각해 낼 수 있는지 당신은 확실히 어리둥절합니다! ELBO가 무엇을 의미하고 어떻게 파생되는지 보자.

한 마디로, ELBO는 사전 분포 \(\log p(\mathbf{x})\)에 대한 **하한** 이므로 다음을 보여줄 수 있습니다.

\mathbf{x})}\left[\log\frac{p( \mathbf{x}|\mathbf{x})}\left[\log\frac{p( \mathbf{x}|\mathbf{x})}\right]+\mathbb{D}_{ \text{KL}}(q_{\phi}(\mathbf{z}|\mathbf{x})}(q_{\phi}(\mathbf{z}|\mathbf{x})}\tag{3}\] \[\geq\mathbb{E}_{q_{\phi}(\mathbf{z}|\mathbf{x})}\left[\log\frac{p( \mathbf{x}|\mathbf{x})}\left[\log\frac{p( \mathbf{x}|\mathbf{x})}\right] \[\stackrel{{\text{def}}}{{=}}}\text

여기서 부등식은 KL 발산이 항상 음이 아니라는 사실에서 비롯된다. 따라서 ELBO는 \(\log p(\mathbf{x})\)에 대한 유효한 하한이다. 우리는 \(\log p(\mathbf{x})\)에 접근할 수 없기 때문에, 만약 우리가 어떻게든 ELBO에 접근할 수 있고 ELBO가 좋은 하한값이라면, 우리는 효과적으로 ELBO를 최대화하여 금본위제인 \(\log p(\mathbf{x})\)를 최대화하는 목표를 달성할 수 있다. 이제, 문제는 하한선이 얼마나 좋은가이다. 식 및 그림 2에서 볼 수 있듯이, 우리의 프록시 \(q_{\phi}(\mathbf{z}|\mathbf{x})\)가 참 분포 \(p(\mathbf{z}|\mathbf{x})\)와 정확히 일치할 때 부등식은 등식이 될 것이다. 따라서 게임의 일부는 \(q_{\phi}(\mathbf{z}|\mathbf{x})\)가 \(p(\mathbf{z}|\mathbf{x})\)에 가깝도록 하는 것입니다.

**Eqn의 증명** (3). 여기서의 전체 요령은 우리의 마법의 프록시 \(q_{\phi}(\mathbf{z}|\mathbf{x})\)를 사용하여 \(p(\mathbf{x})\) 주변을 찌르고 경계를 유도하는 것이다.

\mathbf{x}) =\log p(\mathbf{x})\times\underbrace{\int q_{\phi}(\mathbf{x})d\mathbf{z}_{=1}\] multiply \[1\] \[=\int\underbrace{\log p(\mathbf{x})}_{\text{some constant wrt }\mathbf{z}}\times\underbrace{q_{\phi}(\mathbf{z}|\mathbf{x})}_{\text{distribution in }\mathbf{z}}d\mathbf{z}\] move \[\log p(\mathbf{x})\] into integral \[=\mathbb{E}_{q_{\phi}(\mathbf{z}|\mathbf{x})}[\log p(\mathbf{x})], \tag{4}\]

여기서 마지막 등식은 임의의 랜덤 변수 \(Z\)와 스칼라 \(a\)에 대해 \(\int a\times p_{Z}(z)dz=\mathbb{E}[a]\)라는 흥미로운 사실이다. 물론 \(\mathbb{E}[a]=a\).

우리는 이미 \(\mathbb{E}_{q_{\phi}(\mathbf{z}|\mathbf{x})}[\cdot]\를 얻었다. 몇 걸음만 더 가면 돼 \(p(\mathbf{x},\mathbf{z})=p(\mathbf{z}|\mathbf{x})p(\mathbf{x}):\

\mathbf{z}|\mathbf{x})}\left[\log\frac{p(\mathbf{z}|\mathbf{x})}{p(\mathbf{z}|\mathbf{x})}[\log\frac{p(\mathbf{z}|\mathbf{x})}\right]\] 베이즈 Theorem \[=\mathbb{E}_{q_{\phi}(\mathbf{z}|\mathbf{x})}{p(\mathbf{z}|\mathbf{x})}\left[ \log\frac{p(\mathbf{z}|\mathbf{x})}\left[ \log\frac{p(\mathbf{z}|\mathbf{x})}\mathbf{x})}\left[ \log\frac{p(\mathbf{x}}_{q_{\phi}(\mathbf{z}|\

여기서 우리는 첫 번째 항이 정확히 ELBO인 반면, 두 번째 항은 정확히 KL 발산이라는 것을 인식한다. Eqn (5)와 Eqn (3)을 비교하면, 우리는 삶이 좋다는 것을 안다.

이제 ELBO가 있습니다. 그러나 이 ELBO는 \(p(\mathbf{x},\mathbf{z})\), 우리가 접근할 수 없는 것을 포함하기 때문에 여전히 유용하지 않다. 그래서, 우리는 조금 더 많은 것들을 할 필요가 있다. ELBO를 좀 더 자세히 살펴보자

\mathbf{x})}\left[\log\frac{p(\mathbf{x}|\mathbf{x})}{q_{\mathbff{\phi}}(\mathbf{x})}\left[\log\frac{p(\mathbf{x}|\mathbf{x})}{q_{\mathbff{\phi}}(\mathbf{x})}\right] p(\mathbf{x}|\mathbf{x})}\left[\log\frac{p(\mathbf{x}|\mathbf{x})}{q_{\mathbff{\phi}}(\mathbf{x})}\right] definition \[=\mathbb{E}_{q_{\mathbff{\phi}}(\mathbf{x}|\mathbf{x})}\left[\log\frac{p(\mathbf{x}|\mathbf{x})}

여기서 우리는 접근하기 어려운 \(p(\mathbf{x}|\mathbf{z})\)를 프록시 \(p_{\mathbf{\theta}}}(\mathbf{x}|\mathbf{z})\)로 몰래 대체했다. 이것은 아름다운 결과이다. 우리는 아주 이해하기 쉬운 것을 보여줬습니다.

[\operatorname{ELBO}(\mathbf{x})=\underbrace{\mathbb{E}_{q_{\mathbff{\phi}(\mathbf{z}|\mathbf{x})}^{\text{ a Gaussian}}}[\log\overbrace{p_{\phi}(\mathbf{x}|\mathbf{x})}^{\text{ a Gaussian}}\parallel\overbrace{p(\mathbf{z})}^{\text{ $\mathbf{\theta}$}(\mathbf{z})}\right)}_{\text{How good your decoder is}}}. \tag{6}\

식 (6)에는 두 개의 항이 있다:

* **재구성**. 첫 번째 항은 _디코더_ 에 대한 것입니다. 우리는 잠재 \(\mathbf{z}\)를 디코더에 공급하면 디코더가 좋은 이미지를 생성하기를 원한다(물론!). 따라서 _maximize_\(\log p_{\mathbf{\theta}}(\mathbf{x}|\mathbf{z})\). 우리가 이미지를 관찰할 가능성을 최대화하기 위해 모델 모수를 찾고자 하는 최대 우도와 유사하다. 여기서의 기대치는 샘플 \(\mathbf{z}\)(\(\mathbf{x}\)에 대해 취해진다.) 샘플 \(\mathbf{z}\)이 디코더의 품질을 평가하는 데 사용되기 때문에 이것은 놀랄 일이 아니다. 임의의 잡음 벡터가 아니라 의미 있는 잠재 벡터이다. 따라서 \(\mathbf{z}\)는 \(q_{\phi}(\mathbf{z}|\mathbf{x})\로부터 샘플링될 필요가 있다.
* **이전 일치** 입니다. 두 번째 항은 _인코더_ 에 대한 KL 발산입니다. 우리는 인코더가 \(\mathbf{x}\)를 잠재 벡터 \(\mathbf{z}\)로 바꾸어 잠재 벡터가 (지연) 분포 \(\mathcal{N}(0,\mathbf{I})\)의 선택을 따르도록 한다. 좀 더 일반화하기 위해 \(p(\mathbf{z})\)를 목표 분포로 쓴다. KL은 거리이기 때문에 (두 분포가 더 유사해질 때 증가하는) 두 분포가 더 유사해질 때 증가하도록 음의 부호를 앞에 둘 필요가 있다.

**예제**. 우리의 사소한 가우스 예를 계속해보자. 우리는 우리의 이전 파생에서 알고 있습니다.

\[q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x}) =\mathcal{N}(\mathbf{z}\mid a\mathbf{x}+b,1),\] \[p_{\mathbf{\theta}}(\mathbf{x}|\mathbf{z}) =\mathcal{N}(\mathbf{x}\mid c\mathbf{z}+d,c)}.\]

\(\mathbf{\theta}\)와 \(\mathbf{\phi}\)를 결정하기 위해서는 사전 정합 오차를 최소화하고 복원항을 최대화해야 한다. 사전 매칭의 경우, 우리는 그것이

\[\mathbb{D}_{\mathrm{KL}}(q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x})\|p(\mathbf{z}) )=\mathbb{D}_{\mathrm{KL}}\left(\mathcal{N}(\mathbf{z}\mid a\mathbf{x}+b,1) \parallel\mathcal{N}(\mathbf{z}\mid 0,1)\right)\]

\(\mathbb{E}[\mathbf{x}]=\mu\)와 \(\mathrm{Var}[\mathbf{x}]=\sigma^{2}\)이므로, \(a=\frac{1}{\sigma}\)와 \(b=-\frac{\mu}{\sigma}\)에서 KL-발산은 최소화된다. \(a\mathbf{x}+b=\frac{\kappa-\mu}{\sigma}\). 그리고 \(\mathbb{E}[a\mathbf{x}+b]=0\), \(\mathrm{Var}[a\mathbf{x}+b]=1\)이 된다. 재구성 항의 경우 다음을 알고 있습니다.

\[\mathbb{E}_{q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x})}[\log p_{\mathbf{\theta}}(\mathbf{ x}|\mathbf{z})]=\mathbb{E}_{q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x})}\left[-\frac{(c \mathbf{z}+d-\mu)^{2}}{2c^{2}}}\right]\]

\(\mathbb{E}[\mathbf{z}]=0\) 및 \(\mathrm{Var}[\mathbf{z}]=1\)이므로, \(c=\sigma\) 및 \(d=\mu\)일 때 항이 최대가 된다.

결론적으로, 인코더 및 디코더 파라미터들은

\[\mathbf{z} =\text{encode}(\mathbf{x})=\frac{\mathbf{x}-\mu}{\sigma},\] \[\mathbf{x} =\text{decode}(\mathbf{z})=\sigma\mathbf{z}+\mu,\]

그것은 상당히 이해하기 쉽다.

재구성 항과 사전 매칭 항은 그림 3에 나와 있다. 두 경우 모두, 그리고 훈련 동안, 우리는 \(\mathbf{z}\)와 \(\mathbf{x}\) 모두에 액세스할 수 있다고 가정하며, 여기서 \(\mathbf{z}\)는 \(q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x})\에서 샘플링될 필요가 있다. 그런 다음 복원을 위해 \(\mathbf{\theta}\)를 추정하여 \(p_{\mathbf{\theta}}(\mathbf{x}|\mathbf{z})\)를 최대화한다. 사전 매칭을 위해 KL 발산을 최소화하기 위해 \(\mathbf{\phi}\)를 찾는다. \(\mathbf{\phi}\)를 업데이트하면 분포 \(q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x})\)가 변경되기 때문에 최적화가 어려울 수 있습니다.

### Training VAE

이제 우리는 ELBO의 의미를 이해했으니, VAE를 훈련하는 방법에 대해 논의할 수 있습니다. VAE를 훈련하기 위해서는 진리쌍 \((\mathbf{x},\mathbf{z})\)이 필요하다. 우리는 \(\mathbf{x}\); 데이터 세트의 이미지만 얻을 수 있습니다. 그러나 그에 상응하여 \(\mathbf{z}\)는 무엇이어야 하는가?

**인코더** 에 대해 설명 합니다. 분포 \(q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x})\)로부터 \(\mathbf{z}\)가 생성됨을 알 수 있다. 또한 \(q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x})\)가 가우시안임을 알 수 있다. 이 가우시안에는 평균 \(\mathbf{\mu}\)과 공분산 행렬 \(\sigma^{2}\mathbf{I}\)이 있다고 가정하자 (Ha! 우리의 게으름 다시! 우리는 일반적인 공분산 행렬을 사용하지 않고 등분산을 가정한다).

입력영상으로부터 \(\mathbf{\mu}\)과 \(\sigma^{2}\)을 결정하는 것이 까다로운 부분이다. 단서가 떨어지면 걱정하지 마 다크사이드 오브 더 포스에 오신 걸 환영합니다 We construct the deep neural network(s) such to

\[\mathbf{\mu} =\underbrace{\mathbf{\mu}_{\mathbf{\phi}}_{\text{neural network}}( \mathbf{x})\] \[\sigma^{2} =\underbrace{\sigma^{2}_{\mathbf{\phi}}}_{\text{neural network}}( \mathbf{x})\]

따라서, 샘플 \(\mathbf{z}^{(\ell)}\)(여기서, \(\ell\)은 트레이닝 세트 내의 \(\ell\)번째 트레이닝 샘플을 나타냄) 가우시안 분포로부터 샘플링될 수 있다.

\[\mathbf{z}^{(\ell)} \sim\underbrace{\mathcal{N}(\mathbf{z}\mid\mathbf{\mu}_{\mathbff{\phi}}( \mathbf{x}^{(\ell)}),\sigma^{2}_{\mathbf{\phi}(\mathbf{x}^{(\ell)})\mathbf{I})}_ {q_{\mathbff{\phi}}(\mathbf{z}|\mathbf{x}^{(\ell)})},\qquad\text{여기서 }\mathbf{\mu}_{\mathbff{\phi}}, \sigma^{2}_{\mathbf{\phi}}\text{는 }\mathbf{x}의 함수이다. \tag{7}\

이 아이디어는 그림 4에 요약되어 있으며, 여기서 우리는 신경망을 사용하여 가우시안 파라미터를 추정하고 가우시안으로부터 샘플을 추출합니다. \(\mathbf{\mu}_{\mathbf{\phi}}(\mathbf{x}^{(\ell)})\)와 \(\sigma^{2}_{\mathbf{\phi}}(\mathbf{x}^{(\ell)})\)는 \(\mathbf{x}^{(\ell)}\)의 함수이다. 따라서, 다른 \(\mathbf{x}^{(\ell)}\)에 대해 우리는 다른 가우시안(Gaussian)을 가질 것이다.

그림 3: 변분 오토인코더를 위한 ELBO에서 재구성 항과 사전 매칭 항을 해석한다.

**비고**. 임의의 고차원 가우시안 \(\mathbf{x}\sim\mathcal{N}(\mathbf{x}|\boldsymbol{\mu},\boldsymbol{\Sigma})\)에 대해, 샘플링 프로세스는 백색 잡음의 변환을 통해 수행될 수 있다.

\[\mathbf{x}=\boldsymbol{\mu}+\boldsymbol{\Sigma}^{\frac{1}{2}}\mathbf{w}, \tag{8}\]

여기서 \(\mathbf{w}\sim\mathcal{N}(0,\mathbf{I})\). 하프 행렬 \(\boldsymbol{\Sigma}^{\frac{1}{2}}}\)은 고유 분해 또는 촐레스키 인수분해를 통해 얻을 수 있다. 대각 행렬 \(\boldsymbol{\Sigma}=\sigma^{2}\mathbf{I}\)의 경우 위의 값은 다음과 같습니다.

\[\mathbf{x}=\boldsymbol{\mu}+\sigma\mathbf{w},\qquad\text{where}\;\mathbf{w} \sim\mathcal{N}(0,\mathbf{I}). \tag{9}\]

**디코더** 에 대해 설명 합니다. 디코더는 신경망을 통해 구현된다. 표기 단순화를 위해 \(\text{decode}_{\boldsymbol{\theta}}\)로 정의하자. 여기서 \(\boldsymbol{\theta}\)는 네트워크 매개 변수를 나타낸다. 디코더 네트워크의 작업은 잠재 변수 \(\mathbf{z}\)를 취하여 이미지를 생성하는 것이다 \(\widehat{\mathbf{x}}\):

\[\widehat{\mathbf{x}}=\text{decode}_{\boldsymbol{\theta}}(\mathbf{z}). \tag{10}\]

이제, 디코딩된 이미지 \(\widehat{\mathbf{x}}\)와 그라운드 트루스 이미지 \(\mathbf{x}\) 사이의 오차가 가우시안이라고 한 번 더 (미친) 가정해보자. (잠깐, 가우시안 다시?!) 우리는 그렇게 가정한다.

\[(\widehat{\mathbf{x}}-\mathbf{x})\sim\mathcal{N}(0,\sigma_{\text{dec}}^{2}), \qquad\text{for some}\;\sigma_{\text{dec}}^{2}).\]

그 다음, 분포 \(p_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z})\)는 다음과 같다.

\mathbf{x}\,\text{decode}_{\boldsymbol{\theta}}(\mathbf{x}|\mathbf{z}) =\log\mathcal{N}(\mathbf{x}\,\,\text{decode}_{\boldsymbol{\theta}}(\mathbf{z}),\sigma_{\text{dec}}^{2}\mathbf{I})\] \[=\log\frac{1}{\sqrt{(2\pi\sigma_{\text{dec}}^{2})^{D}}}}\exp\left\{ -\frac{\|\mathbff{x}-\text{decode}_{\boldsymbol{\theta}}(\mathbf{z})\|^{2}}{2 \sigma_{\text{dec}}^{2}}}\;\;-\;\underbrace{\log\sqrt{(2 \pi\sigma_{\text{dec}}^{2}

여기서, \(D\)는 \(\mathbf{x}\)의 치수이다. 이 방정식은 ELBO에서 우도항의 최대화는 말 그대로 디코딩된 영상과 그라운드 트루스 사이의 \(\ell_{2}\) 손실일 뿐이라고 말한다. 그 아이디어는 그림 5에 나와 있다.

도 5: VAE 디코더의 구현. 신경망을 이용하여 잠재벡터 \(\mathbf{z}\)를 취하여 이미지를 생성한다 \(\widehat{\mathbf{x}\) 우리가 가우시안 분포를 가정하면 로그 우도는 우리에게 2차 방정식을 줄 것이다.

### Loss Function

일단 인코더와 디코더의 구조를 이해하면 손실 함수를 쉽게 이해할 수 있다. 우리는 몬테카를로 시뮬레이션을 통해 기대치를 근사화한다:

\[\mathbb{E}_{q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x})}[\log p_{\mathbf{\theta}}(\mathbf{x}|\mathbf{z})]\approx\frac{1}{L}\sum_{\ell=1}^{L}\log p_{\mathbf{\theta}}(\mathbf{ x}^{\ell}|\mathbf{z}^{(\ell)}),\qquad\mathbff{z}^{(\ell)}\sim q_{\mathbf{\phi}}( \mathbf{z}|\mathbf{x}^{(\ell)}),\]

여기서 \(\mathbf{x}^{(\ell)}\)는 훈련 세트에서 \(\ell\)번째 샘플이고, \(\mathbf{z}^{(\ell)}\)는 \(\mathbf{z}^{(\ell)}\sim q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x}^{(\ell)})\에서 샘플링된다. 분포 \(q_{\mathbf{\theta}\)는 \(q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x}^{(\ell)})=\mathcal{N}(\mathbf{z}|\mathbf{\mu}_{\mathbf{\phi}}(\mathbf{x}^{(\ell)}),\sigma_{\mathbf{\phi}}^{2}(\mathbf{x}^{(\ell)}) \mathbf{I})\이다.

**VAE의 훈련 손실**:

\[\operatorname*{argmax}_{\mathbf{\phi},\mathbf{\theta}}\left\{\frac{1}{L}\sum_{\ell=1} ^{L}\log p_{\mathbf{\theta}}(\mathbf{x}^{(\ell)}|\mathbf{z}^{(\ell)})-\mathbb{D}_ {\text{KL}}}(q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x}^{(\ell)})\|p(\mathbf{z})) \right\}, \tag{12}\

여기서 \(\{\mathbf{x}^{(\ell)}\}_{\ell=1}^{L}\)은 학습 데이터 세트의 그라운드 트루스 이미지이고, \(\mathbf{z}^{(\ell)}\)은 Eqn(7)에서 샘플링된다.

KL 발산 항에서 \(\mathbf{z}\)는 두 분포 사이의 KL 발산을 측정하기 때문에 \(\ell\)에 의존하지 않는다. 여기서 변수 \(\mathbf{z}\)는 더미이다.

마지막으로 우리가 명확히 해야 할 한 가지는 KL 발산이다. \(q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x}^{(\ell)})=\mathcal{N}(\mathbf{z}|\mathbf{\mu}_{\mathbf{\phi}}(\mathbf{x}^{(\ell)}),\sigma_{\mathbf{\phi}}^{2}(\mathbf{x}^{(\ell)})\mathbf{I})\)와 \(p(\mathbf{z})=\mathcal{N}(0,\mathbf{I})\이므로, 우리는 본질적으로 두 개의 가우스 분포를 얻고 있다. 위키피디아에 가면 두 개의 \(d\)-차원 가우시안 분포 \(\mathcal{N}(\mathbf{\mu}_{0},\mathbf{\Sigma}_{0})\)와 \(\mathcal{N}(\mathbf{\mu}_{1},\mathbf{\Sigma}_{1})\)에 대한 KL 발산을 볼 수 있다.

\[\mathbb{D}_{\text{KL}}(\mathcal{N}(\mathbf{\mu}_{0},\mathbf{\Sigma}_{0}),\mathcal{N}(\mathbf{\mu}_{1},\mathbf{\Sigma}_{1}))=\frac{1}{2}\left(\text{Tr}(\mathbf{\Sigma}_{1}^{-1}\mathbf{\Sigma}_{0})-d+(\mathbf{\mu}_{1}-\mathbf{\mu}_{0})^{T}\mathbf{\Sigma}_{1}^{-1}(\mathbf{ \mu}_{1}-\mathbf{\mu}_{0})+\log\frac{\text{det}\mathbf{\Sigma}_{1}}{\text{det}\mathbf{ \Sigma}_{0}}}\right). \tag{13}\

우리의 분포를 \(\mathbf{\mu}_{0}=\mathbf{\mu}_{\mathbf{\phi}}(\mathbf{x}^{(\ell)})\), \(\mathbf{\Sigma}_{0}=\sigma_{\mathbf{\phi}}^{2}(\mathbf{x}^{(\ell)})\mathbf{I}\), \(\mathbf{\mu}_{1}=0\), \(\mathbf{\Sigma}_{1}=\mathbf{I}\)를 고려하여 대입하면 KL 발산이 분석적인 식을 가지고 있음을 알 수 있다.

\[\mathbb{D}_{\text{KL}}(q_{\mathbf{\phi}}(\mathbf{z}|\mathbf{x}^{(\ell)})\parallel p(\mathbf{z}))=\frac{1}{2}\left((\sigma_{\mathbf{\phi}}^{2}(\mathbf{x}^{(\ell)}))^{ d}+\mathbf{\mu}_{\mathbf{\phi}}(\mathbf{x}^{(\ell)})^{T}\mathbf{\mu}_{\mathbf{\phi}}(\mathbf{x}^{(\ell)})-d\log(\sigma_{\mathbf{\phi}}^{2}(\mathbf{x}^{(\ell)}))\right), \tag{14}\

여기서, \(d\)는 벡터 \(\mathbf{z}\)의 차원이다. 따라서, 전체 손실 함수 Eqn(12)는 미분 가능하다. 따라서, 우리는 기울기를 역전파함으로써 인코더와 디코더를 종단간으로 훈련시킬 수 있다.

### VAE를 사용한 추론

추론을 위해 잠재 벡터 \(\mathbf{z}\)( \(p(\mathbf{z})=\mathcal{N}(0,\mathbf{I})\))를 디코더 디코드 \({}_{\mathbf{\theta}}\)에 던지고 이미지를 얻을 수 있다 \(\mathbf{x}\). 바로 그거야; 그림 6을 봐.

### 축하합니다! 우린 끝났어 이건 VAE에 관한 거야

더 읽고 싶으시면 Kingma와 Welling [1]의 튜토리얼을 적극 권장합니다. [2]에서 더 짧은 자습서를 찾을 수 있습니다. 구글에서 VAE 튜토리얼 PyTorch를 입력하면 수천 개가 아닌 수백 개의 프로그래밍 튜토리얼과 비디오를 찾을 수 있습니다.

그림 6: VAE를 사용하여 이미지를 생성하는 것은 디코더를 통해 잠재 노이즈 코드 \(\mathbf{z}\)를 보내는 것만큼 간단하다.

## 2 DDPM(Denoising Diffusion Probabilistic Model)

본 절에서는 Ho et al. [4]의 DDPM에 대해 논하고자 한다. 온라인에서 수천 개의 자습서로 인해 혼란스럽다면 DDPM이 그렇게 복잡하지 않으니 안심하십시오. 다음 요약만 이해하면 됩니다.

확산 모델은 전체의 어셈블리가 인코더-디코더 구조를 제공하는 _증가적_ 업데이트입니다. 한 상태에서 다른 상태로의 전환은 데노아에 의해 실현된다.

왜 증가하죠? 거대한 우주선의 방향을 돌리는 것과 같습니다. 원하는 방향으로 천천히 배를 돌려야 합니다. 그렇지 않으면 통제력을 잃게 됩니다. 당신의 삶, 당신의 회사 인사, 당신의 대학 행정, 당신의 배우자, 당신의 자녀, 그리고 당신의 삶의 모든 것에 동일한 원칙이 적용된다. “한 번에 1인치씩 구부려!” (신용: 전자 이미징 2023에서 이 발언을 한 세르히오 고마).

확산 모델의 구조를 이하에 나타낸다. 이를 **변수 확산 모델**[5]이라고 합니다. 변분 확산 모델은 상태 \(\mathbf{x}_{0},\mathbf{x}_{1},\ldots,\mathbf{x}_{T}\):

* \(\mathbf{x}_{0}\): VAE의 \(\mathbf{x}\)와 동일한 원본 이미지입니다.
* \(\mathbf{x}_{T}\): VAE의 \(\mathbf{z}\)와 동일한 잠재 변수이다. 우리는 모두 게으르기 때문에 \(\mathbf{x}_{T}\sim\mathcal{N}(0,\mathbf{I})\)\를 원한다.
* \(\mathbf{x}_{1},\ldots,\mathbf{x}_{T-1}\): 이들은 중간 상태들이다. 잠재 변수이기도 하지만 흰색 가우시안도 아닙니다.

변분 확산 모델의 구조는 그림 7과 같다. 순방향 경로와 역방향 경로는 단일 단계 변분 오토인코더의 경로와 유사하다. 차이점은 인코더와 디코더가 동일한 입력-출력 차원을 갖는다는 것이다. 모든 순방향 빌딩 블록들의 조립은 인코더를 줄 것이고, 모든 역방향 빌딩 블록들의 조립은 디코더를 줄 것이다.

### Building Blocks

**전환 블록** \(t\) 번째 전환 블록은 \(\mathbf{x}_{t-1}\), \(\mathbf{x}_{t}\) 및 \(\mathbf{x}_{t+1}\의 세 가지 상태로 구성됩니다. 그림 8과 같이 상태 \(\mathbf{x}_{t}\)로 가는 두 가지 가능한 경로가 있다.

* \(\mathbf{x}_{t-1}\)에서 \(\mathbf{x}_{t}\)로 이동하는 순방향 전환입니다. 연관된 전이 분포는 \(p(\mathbf{x}_{t}|\mathbf{x}_{t-1})\)이다. 쉽게 말해, \(\mathbf{x}_{t-1}\)를 말하면, \(p(\mathbf{x}_{t}|\mathbf{x}_{t-1})\)에 따라 \(\mathbf{x}_{t}\)를 말할 수 있다. 그러나 VAE와 마찬가지로 전이 분포 \(p(\mathbf{x}_{t}|\mathbf{x}_{t-1})\)에 액세스할 수 없습니다. 하지만 이건 괜찮아 우리 같은 게으른 사람들은

그림 7: Variational diffusion model. 이 모델에서 입력영상은 \(\mathbf{x}_{0}\)이고 백색잡음은 \(\mathbf{x}_{T}\)이다. 중간 변수(또는 상태) \(\mathbf{x}_{1},\ldots,\mathbf{x}_{T-1}\)는 잠재 변수이다. VAE에서 \(\mathbf{x}_{t-1}\)에서 \(\mathbf{x}_{t}\)로의 전이는 순방향 단계(인코더)와 유사하지만, VAE에서 \(\mathbf{x}_{t}\)에서 \(\mathbf{x}_{t-1}\)로의 전이는 역방향 단계(디코더)와 유사하다. 그러나, 여기서 인코더/디코더의 입력 차원과 출력 차원은 동일하다는 점에 유의한다.

가우스 \(q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{t-1})\로 근사할 것이다. 우리는 나중에 정확한 형태 \(q_{\mathbf{\phi}}\)에 대해 논의할 것이지만, 그것은 단지 일부 가우시안일 뿐이다.
* 역전이는 \(\mathbf{x}_{t+1}\)에서 \(\mathbf{x}_{t}\)로 이동합니다. 다시 말하지만, 우리는 \(p(\mathbf{x}_{t+1}|\mathbf{x}_{t})\)를 결코 알지 못하지만, 괜찮습니다. 우리는 또 다른 가우시안 \(p_{\mathbf{\theta}}(\mathbf{x}_{t+1}|\mathbf{x}_{t})\)을 사용하여 참 분포를 근사하지만, 그 평균은 신경망에 의해 추정될 필요가 있다.

**초기 블록** 변분 확산 모델의 초기 블록은 상태 \(\mathbf{x}_{0}\)에 중점을 둡니다. 모든 문제는 \(\mathbf{x}_{0}\)에서 시작되기 때문에 \(\mathbf{x}_{1}\)에서 \(\mathbf{x}_{0}\)로 역전이할 뿐 \(\mathbf{x}_{-1}\)에서 \(\mathbf{x}_{0}\)로 가는 문제는 없다. 그러므로 우리는 \(p(\mathbf{x}_{0}|\mathbf{x}_{1})\에 대해서만 걱정하면 된다. 그러나 \(p(\mathbf{x}_{0}|\mathbf{x}_{1})\)는 접근할 수 없기 때문에 가우시안 \(p_{\mathbf{\theta}}(\mathbf{x}_{0}|\mathbf{x}_{1})\)로 근사하여 신경망을 통해 평균을 계산한다. 예시는 도 9를 참조한다.

**최종 블록**. 최종 블록은 상태 \(\mathbf{x}_{T}\)에 초점을 맞춘다. \(\mathbf{x}_{T}\)는 백색 가우시안 잡음 벡터인 최종 잠재 변수임을 기억하라. 최종 블록이기 때문에 \(\mathbf{x}_{T-1}\)에서 \(\mathbf{x}_{T}\)로 순방향 천이만 있을 뿐 \(\mathbf{x}_{T+1}\)에서 \(\mathbf{x}_{T}\)와 같은 것은 없다. 순방향 천이는 가우시안인 \(q_{\mathbf{\phi}}(\mathbf{x}_{T}|\mathbf{x}_{T-1})\)로 근사된다. 예시는 도 10을 참조한다.

**전환 배포 이해**. 더 진행하기 전에 전이 분포 \(q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{t-1})\)에 대해 약간 우회해야 한다. 우리는 그것이 가우시안이라는 것을 안다. 그러나 우리는 여전히 그것의 공식적인 정의와 이 정의의 기원을 알아야 합니다.

그림 10: 변분 확산 모델의 최종 블록은 노드 \(\mathbf{x}_{T}\)에 초점을 맞춘다. 시간 \(t=T\) 이후에는 상태가 없기 때문에 \(\mathbf{x}_{T-1}\)에서 \(\mathbf{x}_{T}\)로 순방향 천이만 한다.

그림 9: 변분 확산 모델의 초기 블록은 노드 \(\mathbf{x}_{0}\)에 초점을 맞춘다. 시간 \(t=0\) 이전에는 상태가 없기 때문에 우리는 \(\mathbf{x}_{1}\)에서 \(\mathbf{x}_{0}\)로 역전이할 뿐이다.

**천이 분포 \(q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{t-1})\)**. 디노이징 확산 확률 모델에서 전이 분포 \(q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{t-1})\)는 다음과 같이 정의된다.

\[q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{t-1})\stackrel{{\rm def}}{{{= }}\mathcal{N}(\mathbf{x}_{t}\,|\,\sqrt{\alpha_{t}}\mathbf{x}_{t-1},(1-\alpha_{t})\mathbf{I}). \tag{15}\

즉 평균은 \(\sqrt{\alpha_{t}}\mathbf{x}_{t-1}\)이고 분산은 \(1-\alpha_{t}\)이다. 스케일링 인자 \(\sqrt{\alpha_{t}}\)의 선택은 분산 크기가 많은 반복 후에 폭발하고 사라지지 않도록 보존되도록 하는 것이다.

**예제**. 가우시안 혼합 모델을 고려하자.

\[\mathbf{x}_{0}\sim p_{0}(\mathbf{x})=\pi_{1}\mathcal{N}(\mathbf{x}|\mu_{1}, \sigma_{1}^{2})+\pi_{2}\mathcal{N}(\mathbf{x}|\mu_{2},\sigma_{2}^{2}).\]

천이 확률이 주어진다면, 우리는

\[\mathbf{x}_{t}=\sqrt{\alpha_{t}}\mathbf{x}_{t-1}+\sqrt{(1-\alpha_{t})}\mathbf{ \epsilon},\qquad\text{where}\;\;\mathbf{\epsilon}\sim\mathcal{N}(0,\mathbf{I}).\]

혼합 모델의 경우, \(t=1,2,\ldots,T\)에 대한 알고리즘을 통해 \(\mathbf{x}_{t}\)의 확률 분포가 재귀적으로 계산될 수 있음을 보여주는 것은 어렵지 않다:

\[p_{t}(\mathbf{x})= \pi_{1}\mathcal{N}(\mathbf{x}|\sqrt{\alpha_{t}}\mu_{1,t-1},\alpha _{t}\sigma_{1,t-1}^{2}+(1-\alpha_{t}))\] \[+ \pi_{2}\mathcal{N}(\mathbf{x}|\sqrt{\alpha_{t}}\mu_{2,t-1},\alpha _{t}\sigma_{2,t-1}^{2}+(1-\alpha_{t})), \tag{16}\]

여기서, \(\mu_{1,t-1}\)는 \(t-1\)에서의 평균이고, \(\mu_{1,0}=\mu_{1}\)는 초기 평균이다. 유사하게, \(\sigma_{1,t-1}^{2}\)는 \(t-1\)에서의 분산이고, \(\sigma_{1,0}^{2}=\sigma_{1}^{2}\)는 초기 분산이다.

아래 그림에서는 \(\pi_{1}=0.3\), \(\pi_{2}=0.7\), \(\mu_{1}=-2\), \(\mu_{2}=2\), \(\sigma_{1}=0.2\), \(\sigma_{2}=1\)의 예를 보여 준다. 속도는 모든 \(t\)에 대해 \(\alpha_{t}=0.97\)로 정의된다. 우리는 다른 \(t\)에 대한 확률 분포 함수를 플로팅한다.

**비고**. 우리가 Eqn (16)에서 혼합물 모형의 확률 밀도를 어떻게 유도하는지 이해하려는 사람들에게 우리는 간단한 유도를 보여줄 수 있다. 혼합 모형 고려

\[p(\mathbf{x})=\sum_{k=1}^{K}\pi_{k}\underbrace{\mathcal{N}(\mathbf{x}|\mu_{k },\sigma_{k}^{2}\mathbf{I})}_{p(\mathbf{x}|k)}.\]

새로운 변수 \(\mathbf{y}=\sqrt{\alpha}\mathbf{x}+\sqrt{1-\alpha}\mathbf{\epsilon}\)를 고려한다면, 여기서 \(\mathbf{\epsilon}\sim\mathcal{N}(0,\mathbf{I})\)는 총 확률의 법칙을 이용하여 \(\mathbf{y}\)의 분포를 유도할 수 있다:

\[p(\mathbf{y})=\sum_{k=1}^{K}p(\mathbf{y}|k)p(k)=\sum_{k=1}^{K}\pi_{k}p( \mathbf{y}|k).\] \(\mathbf{y}|k\)는 가우시안 랜덤 변수 \(\mathbf{x}\)와 다른 가우시안 랜덤 변수 \(\boldsymbol{\epsilon}\)의 선형 조합이기 때문에, 합 \(\mathbf{y}\)은 가우시안으로서 유지될 것이다. 상기 평균은,

\[\mathbb{E}[\mathbf{y}|k] =\sqrt{\alpha}\mathbb{E}[\mathbf{x}|k]+\sqrt{1-\alpha}\mathbb{E}[ \boldsymbol{\epsilon}]=\sqrt{\alpha}\mu_{k}\] \[\text{Var}[\mathbf{y}|k] =\alpha\text{Var}[\mathbf{x}|k]+(1-\alpha)\text{Var}[\boldsymbol{\epsilon}]=\alpha\sigma_{k}^{2}+(1-\alpha)\]\]

따라서 \(p(\mathbf{y}|k)=\mathcal{N}(\mathbf{y}|\sqrt{\alpha}\mu_{k},\alpha\sigma_{k}^{ 2}+(1-\alpha))\). 이로써 도출이 완료된다.

### 마법 스칼라 \(\sqrt{\alpha_{t}}\) 및 \(1-\alpha_{t}\)

당신은 지니(디노이징 확산의 저자)가 위의 전이 확률에 대한 마법의 스칼라 \(\sqrt{\alpha}_{t}\)와 \((1-\alpha_{t})\)를 어떻게 생각해내는지 궁금할 것이다. 이를 명확하게 하기 위해 두 개의 관련 없는 스칼라 \(a\in\mathbb{R}\)와 \(b\in\mathbb{R}\)로 시작하고 전이 분포를 다음과 같이 정의한다.

\[q_{\boldsymbol{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{t-1})=\mathcal{N}(\mathbf{x} _{t}\,|\,a\mathbf{x}_{t-1},b^{2}\mathbf{I}). \tag{17}\

다음은 경험칙입니다.

**왜 \(\sqrt{\alpha_{t}}\) 및 \(1-\alpha_{t}\)**

우리는 \(t\)가 충분히 클 때 \(\mathbf{x}_{t}\)의 분포가 \(\mathcal{N}(0,\mathbf{I})\)가 되도록 \(a\)와 \(b\)를 선택하고자 한다. 정답은 \(a=\sqrt{\alpha}\)와 \(b=\sqrt{1-\alpha}\)인 것으로 나타났다.

**증명**. 우리는 \(a=\sqrt{\alpha}\)와 \(b=\sqrt{1-\alpha}\)를 보여 주고자 한다. Eqn(17)에 도시된 분포에 대해, 등가 샘플링 단계는:

\[\mathbf{x}_{t}=a\mathbf{x}_{t-1}+b\boldsymbol{\epsilon}_{t-1},\qquad\text{ where}\qquad\boldsymbol{\epsilon}_{t-1}\sim\mathcal{N}(0,\mathbf{I}). \tag{18}\

이를 생각해보자: 랜덤 변수 \(X\sim\mathcal{N}(\mu,\sigma^{2})\)가 있는 경우, 이 가우시안으로부터 \(X\)를 그리는 것은 \(X=\mu+\sigma\eta\) 여기서 \(\eta\sim\mathcal{N}(0,1)\)를 정의함으로써 동등하게 달성될 수 있다.

우리는 그것을 보여주기 위해 재귀할 수 있다.

[=a(a\mathbf{x}_{t-2}+b\boldsymbol{\epsilon}_{t-1}\] \[=a(a\mathbf{x}_{t-1}+b\boldsymbol{\epsilon}_{t-2})+b\boldsymbol{\epsilon}_{t-1}\] (치환 \[=\vdots\] \[=a^{2}\mathbf{x}_{t-2}+ab\boldsymbol{\epsilon}_{t-2}+b \boldsymbol{\epsilon}_{t-1}\] (재군 용어) \[=a^{t}\mathbf{x}_{0}+b\underbrace{\left[\boldsymbol{\epsilon}_{t-1}+a\boldsymbol{\epsilon}_{t-2}+a^{2}+a^{t-3}+a^{2}+boldsymbol{\epsilon}_{

위의 유한 합은 독립적인 가우시안 확률 변수의 합이다. 평균 벡터 \(\mathbb{E}[\mathbf{w}_{t}]\)는 모든 사람이 0의 평균을 갖기 때문에 0으로 유지된다. 상기 공분산 행렬(0-평균 벡터의 경우)은,

\[\text{Cov}[\boldsymbol{\epsilon}_{t}]\stackrel{{\text{def}}}}{{=}}\mathbf{w}_{t}]\text{Cov}(\boldsymbol{\epsilon}_{t-1})+a^{2}\text{Cov}( \boldsymbol{\epsilon}_{t-2})+\ldots+(a^{t-1})^{2}\text{Cov}(\boldsymbol{ \epsilon}_{0}))\] \[=b^{2}(1+a^{2}+a^{4}+\ldots+a^{2(t-1)})\mathbf{I}\] \[=b^{2}\cdot\frac{1-a^{2t-1}}{1-a^{2}}\mathbf{I}}] \[=b^{2}\cdot\frac{1-a^{2}}}\mathbf{

(t\to\infty\), 임의의 \(0<a<1\)에 대한 \(a^{t}\to0\). 따라서, \(t=\infty\)일 때의 한계에서는,

\[\lim_{t\to\infty}\text{Cov}[\mathbf{w}_{t}]=\frac{b^{2}}{1-a^{2}}\mathbf{I}.\] 따라서 \(\lim_{t\to\infty}\text{Cov}[\mathbf{w}_{t}]=\mathbf{I}\)(\(\mathbf{x}_{t}\) 분포가 \(\mathcal{N}(0,\mathbf{I})\)에 접근하면 \(b=\sqrt{1-a^{2}}\). 이제 \(a=\sqrt{\alpha}\), \(b=\sqrt{1-\alpha}\)로 하자. 이것이 우리에게 줄 것입니다

\[\mathbf{x}_{t}=\sqrt{\alpha}\mathbf{x}_{t-1}+\sqrt{1-\alpha}\mathbf{\epsilon}_{t-1}. \tag{20}\]

또는 등가적으로 \(q_{\mathbf{\phi}}(\mathbf{x}|\mathbf{x}_{t-1})=\mathcal{N}(\mathbf{x}_{t}\,|\, \sqrt{\alpha}\mathbf{x}_{t-1},(1-\alpha)\mathbf{I})\이다. 스케줄러를 선호하는 경우 \(\alpha\)를 \(\alpha_{t}\)로 대체할 수 있습니다.

### Distribution \(q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{0})\)

마법의 스칼라에 대한 이해를 바탕으로 분포 \(q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{0})\)에 대해 이야기할 수 있다. 즉, \(\mathbf{x}_{t}\)가 주어진 경우 어떻게 분포될 것인지를 알고자 한다.

**조건부 분포 \(q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{0})\)**. 조건부 분포 \(q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{0})\)는 다음과 같이 주어진다.

\[q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{0})=\mathcal{N}(\mathbf{x}_{t}\,|\, \sqrt{\overline{\alpha}_{t}}\mathbff{x}_{0},\ \ (1-\overline{\alpha}_{t})\mathbf{I}), \tag{21}\

where \(\overline{\alpha}_{t}=\prod_{i=1}^{t}\alpha_{i}\).

**증명**. 이 경우에 대한 이유를 알아보기 위해 우리는 재귀화를 다시 할 수 있지만 이번에는 \(\sqrt{\alpha_{t}}\mathbf{x}_{t-1}\)와 \((1-\alpha_{t})\mathbf{I}\)를 각각 평균과 공분산으로 사용한다. 이것이 우리에게 줄 것입니다

\[\mathbf{x}_{t} =\sqrt{\alpha_{t}}(\sqrt{\alpha_{t-1}}\mathbf{x}_{t-2}+\sqrt{1-\alpha_{t-1}}\mathbf{\epsilon}_{t-1}})+\sqrt{1-\alpha_{t}}\mathbf{\epsilon}_{t-1}\] \[=\sqrt{\alpha_{t}\alpha_{t-1}}\mathbf{x}_{t-2}+\underbrace{\sqrt{ \alpha_{t}}\sqrt{1-\alpha_{t-1}}\mathbf{\epsilon}_{t-1}}}\tag{22}\]

그러므로, 우리는 두 개의 가우시안들의 합을 가지고 있다. 그러나 두 개의 가우시안들의 합이 가우시안이므로, 우리는 그 새로운 공분산을 계산할 수 있다(평균이 0으로 남아 있기 때문이다). 상기 새로운 공분산은,

\[\mathbb{E}[\mathbf{w}_{1}\mathbf{w}_{1}^{T}] =[(\sqrt{\alpha_{t}\sqrt{1-\alpha_{t-1})^{2}+(\sqrt{1-\alpha_{t})^{2}]\mathbf{I}\] \[=[\alpha_{t}(1-\alpha_{t-1})+1-\alpha_{t}]\mathbf{I}=[1-\alpha_{t} \alpha_{t-1}]\mathbf{I}]\]

Eqn (22)로 돌아가서, 우리는 재귀가 \(\mathbf{x}_{t-2}\)와 잡음 벡터 \(\mathbf{\epsilon}_{t-2}\)의 선형 조합이 되도록 갱신된다는 것을 보여줄 수 있다:

\[\mathbf{x}_{t} =\sqrt{\alpha_{t}\alpha_{t-1}}\mathbf{x}_{t-3}+\sqrt{1-\alpha_{t-1}\alpha_{t-2}}\mathbf{\epsilon}_{t-3}\] \[=\vdots\] \[=\sqrt{\prod_{i=1}^{t}\alpha_{i}}\mathbf{x}_{t-3}+\sqrt{1-\alpha_{t-1}\alpha_{t-2}}\mathbf{\epsilon}_{t-3}\] \[=\sqrt{\prod_{i=1}^{t}\alpha_{i}}\mathbf{x}_{0}+\sqrt{1-\prod_{i=1}^{t}\alpha_{i}}\mathbf{\epsilon}_{0}}\epsilon}_{0}. \tag{23}\

따라서 \(\overline{\alpha}_{t}=\prod_{i=1}^{t}\alpha_{i}\)를 정의하면 다음과 같은 결과를 얻을 수 있다.

\[\mathbf{x}_{t}=\sqrt{\overline{\alpha}_{t}}\mathbf{x}_{0}+\sqrt{1-\overline{ \alpha}_{t}}\mathbf{\epsilon}_{0}. \tag{24}\]

즉, 분포 \(q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{0})\)는

\[\mathbf{x}_{t}\sim q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{0})=\mathcal{N}( \mathbf{x}_{t}\,|\,\sqrt{\overline{\alpha}_{t}}\mathbff{x}_{0},\ \(1-\overline{\alpha}_{t})\mathbf{I}). \tag{25}\

새로운 분포 \(q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{0})\)의 효용성은 사슬 \(\mathbf{x}_{0}\to\mathbf{x}_{1}\to\ldots\to\mathbf{x}_{T-1}\to\mathbf{x}_{T}\)에 비해 한 번의 순방향 확산 단계이다. 순방향 확산 모델의 모든 단계에서 우리는 \(\mathbf{x}_{0}\)을 이미 알고 있고 모든 서브시퀀스 전이들이 가우시안이라고 가정하기 때문에 임의의 \(t\)에 대해 즉시 \(\mathbf{x}_{t}\)을 알 것이다. 상황은 도 11로부터 이해될 수 있다.

**예제**. \(\mathbf{x}\sim p_{0}(\mathbf{x})=\sum_{k=1}^{K}\pi_{k}\mathcal{N}(\mathbf{x}| \boldsymbol{\mu}_{k},\sigma_{k}^{2}\mathbf{I})\)와 같은 가우시안 혼합 모델의 경우, 시간 \(t\)에서의 분포는 다음과 같다.

\[p_{t}(\mathbf{x}) =\sum_{k=1}^{K}\pi_{k}\mathcal{N}(\mathbf{x}\mid\sqrt{\overline{ \alpha}_{t}}\boldsymbol{\mu}_{k},(1-\overline{\alpha}_{t})\mathbf{I}+ \overline{\alpha}_{t}\sigma_{k}^{2}\mathbf{I}) \tag{26}\] \[=\sum_{k=1}^{K}\pi_{k}\mathcal{N}(\mathbf{x}\mid\sqrt{\alpha^{t}} \boldsymbol{\mu}_{k},(1-\alpha^{t})\mathbf{I}+\alpha^{t}\sigma_{k}^{2}\mathbf{ I}),\qquad\text{if}\ \ \alpha_{t}=\alpha\text{so so}\ \ \overline{\alpha}

확률분포 \(p_{t}\)가 시간에 따라 어떻게 진화하는지 궁금하다면 우리는 그림 12에서 분포의 궤적을 보여준다. 우리가 \(t=0\)에 있을 때, 초기 분포는 두 개의 가우시안들의 혼합물임을 알 수 있다. 우리는 Eqn (26)에서 정의된 전이를 따라 가면서 분포가 점차 단일 가우시안 \(\mathcal{N}(0,1)\)이 됨을 알 수 있다.

같은 그림에서 우리는 랜덤 샘플 \(\mathbf{x}_{t}\)의 몇 개의 순간 궤적을 시간의 함수 \(t\)로 오버레이하여 보여준다. 샘플을 생성하는 데 사용한 방정식은

\[\mathbf{x}_{t}=\sqrt{\alpha_{t}}\mathbf{x}_{t-1}+\sqrt{1-\alpha_{t}} \boldsymbol{\epsilon}_{t-1},\qquad\boldsymbol{\epsilon}\sim\mathcal{N}(0, \mathbf{I}).\]

보다시피, \(\mathbf{x}_{t}\)의 궤적은 분포 \(p_{t}(\mathbf{x})\)를 다소 따른다.

### 증거 하한

이제 변분 확산 모델의 구조를 이해했으니, 우리는 ELBO를 적어서 모델을 훈련시킬 수 있다. 상기 변동 확산 모델을 위한 ELBO는

그림 12: 확률 분포를 \(\mathcal{N}(0,1)\)로 이동시키기 위해 진행함에 따라 가우시안 혼합물의 궤적도.

\mathbf{x}_{T-1})\|p(\mathbf{x}_{T-1})\|p(\mathbf{x}_{T})\Big{[}\underbrace{\mathbf{E}_{q_{\mathbf{\theta}}(\mathbf{x}_{t}|\mathbf{x}_{t-1})\mathbf{x}_{0})}_{\text{{{}\underbrace{\Big{[}\mathbf{E}_{q_{\mathbf{\theta}}(\mathbf{x}_{t-1})\mathbf{x}_{t+1})\Big{}}_{\text{{{}\mathbf{x}_{0})}\Big{[}\mathbf{E}_{q_{\mathbf{\theta}}(\mathbf{x}_{t-1})\mathbf{x}_{t+1})\Big{}}_{\text{

우리는 이 ELBO의 의미를 해석할 수 있다. 여기서 ELBO는 세 가지 구성요소로 구성된다:

* **재구성**. 재구성 용어는 초기 블록을 기반으로 한다. 우리는 log-likelihood \(p_{\mathbf{\theta}}(\mathbf{x}_{0}|\mathbf{x}_{1})\)를 사용하여 \(p_{\mathbf{\theta}}\)와 연관된 신경망이 잠재 변수 \(\mathbf{x}_{1}\)로부터 이미지 \(\mathbf{x}_{0}\)를 얼마나 잘 복구할 수 있는지를 측정한다. 예상은 \(\mathbf{x}_{1}|\mathbf{x}_{0})\)를 생성하는 분포인 \(q_{\mathbf{\phi}}(\mathbf{x}_{1}|\mathbf{x}_{0})\)에서 가져온 샘플에 대해 취해진다. 만약 여러분이 왜 우리가 \(q_{\mathbf{\phi}}(\mathbf{x}_{1}|\mathbf{x}_{0})\에서 샘플을 추출하고자 하는지에 대해 어리둥절하다면, 샘플 \(\mathbf{x}_{1}\)이 어디에서 와야 하는지에 대해 생각해 보세요. 샘플 \(\mathbf{x}_{1}\)은 하늘에서 나오지 않는다. 이들은 중간 잠재변수이므로 순방향 전이 \(q_{\mathbf{\phi}}(\mathbf{x}_{1}|\mathbf{x}_{0})\)에 의해 _생성된다. 따라서 우리는 \(q_{\mathbf{\phi}}(\mathbf{x}_{1}|\mathbf{x}_{0})\에서 샘플을 생성해야 한다. KL 발산을 이용하여 \(q_{\mathbf{\phi}}(\mathbf{x}_{T}|\mathbf{x}_{T-1})\)와 \(p(\mathbf{x}_{T})\)의 차이를 측정한다. 첫 번째 분포 \(q_{\mathbf{\phi}}(\mathbf{x}_{T}|\mathbf{x}_{T-1})\)는 \(\mathbf{x}_{T-1}\)에서 \(\mathbf{x}_{T}\)로의 순방향 전이이다. 이것이 \(\mathbf{x}_{T}\)가 생성되는 방법이다. 두 번째 분포는 \(p(\mathbf{x}_{T})\)이다. 우리의 게으름 때문에, \(p(\mathbf{x}_{T})\)는 \(\mathcal{N}(0,\mathbf{I})\)이다. 우리는 \(q_{\mathbf{\phi}}(\mathbf{x}_{T}|\mathbf{x}_{T-1})\)가 가능한 한 \(\mathcal{N}(0,\mathbf{I})\)에 근접하기를 원한다. 이 샘플들은 \(q_{\mathbf{\phi}}(\mathbf{x}_{T-1}|\mathbf{x}_{0})\)로부터 추출되는 \(\mathbf{x}_{T-1}\)이다. \(q_{\mathbf{\phi}}(\mathbf{x}_{T-1}|\mathbf{x}_{0})\)는 순방향 샘플 생성 과정을 제공하기 때문이다.
* **일관성**. 일관성 항은 전이 블록을 기반으로 합니다. 두 가지 방법이 있습니다. 순방향 전이는 분포 \(q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{t-1})\)에 의해 결정되는 반면 역방향 전이는 신경망 \(p_{\mathbf{\theta}}(\mathbf{x}_{t}|\mathbf{x}_{t+1})\)에 의해 결정된다. 일관성 항은 KL 발산을 사용하여 편차를 측정합니다. 접합분포 \(q_{\mathbf{\phi}}(\mathbf{x}_{t-1},\mathbf{x}_{t+1})\)에서 추출한 샘플 \((\mathbf{x}_{t-1},\mathbf{x}_{t+1})\)에 대한 기대치를 구한다. 오, \(q_{\mathbf{\phi}}(\mathbf{x}_{t-1},\mathbf{x}_{t+1}|\mathbf{x}_{0})\)는? 걱정 마 곧 처리하겠습니다.

현재, 우리는 이 공식이 실행될 준비가 되지 않았기 때문에 훈련과 추론을 건너뛸 것이다. 한 가지 묘기를 더 논의한 다음 구현에 대해 이야기할 것입니다.

**Eqn의 증명** (27). 다음 표기를 정의해 보자. \(\mathbf{x}_{0:T}=\{\mathbf{x}_{0},\dots,\mathbf{x}_{T}\}\)는 \(t=0\)에서 \(t=T\)까지의 모든 상태 변수의 집합을 의미한다. 우리는 또한 사전 분포 \(p(\mathbf{x})\)가 이미지 \(\mathbf{x}_{0}\)에 대한 분포임을 상기한다. 따라서 \(p(\mathbf{x}_{0})\)와 같다. 이것들을 염두에 두고 우리는 그것을 보여줄 수 있습니다.

\mathbf{x}_{1:T}|\mathbf{x}_{0})\log\int p(\mathbf{x}_{1:T}|\mathbf{x}_{0})\log\int p(\mathbf{x}_{0})\log\int p(\mathbf{x}_{1:T}|\mathbf{x}_{0})\log\int p(\mathbf{x}_{0:T})}{q_{\mathbf{\phi}}(\mathbf{x}_{1:T}|\mathbf{x}_{0})} \right]d\mathbf{x}_{1:T}|\mathbf{x}_{1:T}|\mathbf{x}_{0})\log\mathbb{E}_{q_{\mathbf{\phi}}(\mathbf{x}_{1:T}|\mathbf{x}_{0})\log\mathbf{x}_{1

이제, 우리는 임의의 랜덤 변수 \(X\)와 임의의 오목 함수 \(f\)에 대해 \(f(\mathbb{E}[X])\geq\mathbb{E}[f(X)]\라고 하는 젠슨의 부등식을 사용할 필요가 있다. 그 \(f(\cdot)=\log(\cdot)\)를 인식함으로써, 우리는 그것을 증명할 수 있다.

\[\log p(\mathbf{x}) =\log\mathbb{E}_{q_{\mathbf{\phi}}(\mathbf{x}_{1:T}|\mathbf{x}_{0:T})} \left[\frac{p(\mathbf{x}_{0:T})}{q_{\mathbf{\phi}}(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\right]\] \[\geq\mathbb{E}_{q_{\mathbf{\phi}}(\mathbf{x}_{1:T}|\mathbf{x}_{0})} \left[\log\frac{p(\mathbf{x}_{0:T})}{q_{\mathbf{\phi}}(\mathbf{x}_{1:T}|\mathbf{x}_{0})} \left[\log\frac{p(\mathbf

\(p(\mathbf{x}_{0:T})\)를 자세히 살펴보자. 그림 8을 살펴보면, 우리가 \(p(\mathbf{x}_{0:T})\)를 분리하려면 \(\mathbf{x}_{t-1}|\mathbf{x}_{t}\)에 대한 컨디셔닝을 해야 한다는 것을 알 수 있다. 이렇게 하면...

\[p(\mathbf{x}_{0:T})=p(\mathbf{x}_{T})\prod_{t=1}^{T}p(\mathbf{x}_{t-1}| \mathbf{x}_{t})=p(\mathbf{x}_{T})p(\mathbf{x}_{0}|\mathbf{x}_{1})\prod_{t=2}^{T}p(\mathbf{x}_{t-1}|\mathbf{x}_{t}}\tag{29}\]

\(q_{\mathbf{\phi}}(\mathbf{x}_{1:T}|\mathbf{x}_{0})\)에 대해, 그림 8은 우리가 \(\mathbf{x}_{t}|\mathbf{x}_{t-1}\에 대한 컨디셔닝을 할 필요가 있음을 시사한다. 그러나 순차적인 관계로 인해 우리는 쓸 수 있다.

\[q_{\mathbf{\phi}}(\mathbf{x}_{1:T}|\mathbf{x}_{0})=\prod_{t=1}^{T}q_{\mathbf{\phi}}( \mathbf{x}_{t}|\mathbf{x}_{t-1})=q_{\mathbf{\phi}}(\mathbf{x}_{T}|\mathbf{x}_{T-1})\prod_{t=1}^{T-1}q_{\mathbff{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{t-1})\tag{30}\

Eqn(29) 및 Eqn(30)을 Eqn(28)에 다시 대입하면, 우리는 다음을 보여줄 수 있다.

\mathbf{x}_{0})}\left[\log\frac{p(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\left[\log\frac{p(\mathbf{x}_{0})}{q_{\mathbf{\phi}(\mathbf{x}_{0})}\prod_{t=2}^{T-1}q_{\mathbff{\phi}(\mathbf{x}_{t}|\mathbf{x}_{t-1})}\right]\] \[=\mathbb{E}_{q_{\mathbff{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{1})}\prod_{t=1}^{T-1}q_{\mathbff{\phi}(\mathbf{x}_{t}|\mathbf{x}_{1})}\prod_{t=1}^{T-1}p(

위의 첫 번째 항은 두 가지 예상으로 더 분해될 수 있다.

\[\mathbb{E}_{q_{\mathbff{\phi}}(\mathbf{x}_{T})}\left[\log\frac{p( \mathbf{x}_{1:T}|\mathbf{x}_{T})p(\mathbf{x}_{1}|\mathbf{x}_{T-1})}\right]=\underbrace{\mathbb{E}_{q_{\mathbff{\phi}}(\mathbf{x}_{1:T}|\mathbf{x}_{1})\bigg{]}}_{ \text{Reconstruction}}+\underbrace{\mathbb{E}_{q_{\mathbff{\phi}}(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\left[\log\frac{p(\mathbf{x}_{T})}{q_{\mathbf{\phi}}(\mathbf{

재구성 용어는 다음과 같이 단순화할 수 있다.

\[\mathbb{E}_{q_{\mathbff{\phi}}(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\bigg{[}\log p( \mathbf{x}_{0}|\mathbf{x}_{1})\bigg{]}=\mathbb{E}_{q_{\mathbff{\phi}}(\mathbf{x}_{1}|\mathbf{x}_{0})}\bigg{[}\log p(\mathbf{x}_{0}|\mathbf{x}_{1})\bigg{]},\

여기에서 우리는 컨디셔닝 \(\mathbf{x}_{1:T}|\mathbf{x}_{0}\)이 \(\mathbf{x}_{1}|\mathbf{x}_{0}\)과 동등하다는 사실을 사용했다.

상기 Prior Matching 용어는,

(\mathbf{x}_{T})\|p(\mathbf{x}_{T})\right)\bigg{[}\mathbb{D}_{\text{KL}}\left(q_{\mathbf{\phi}}(\mathbf{x}_{T})\|p(\mathbf{x}_{T})\bigg{[}\mathbf{x}_{T})}\left[\log\frac{p(\mathbf{x}_{T})}{q_{\mathbf{\phi}(\mathbf{x}_{T})}(\mathbf{x}_{T})}{q_{\mathbff{\phi}(\mathbf{x}_{T})}(\mathbf{x}_{T})}\right] \[=-\mathbb{E}_{q_{\mathbff{\phi}}(\mathbf{x}_{T}}_{T}}(\mathbf{

마지막으로 제품 용어를 살펴봅니다. 보여줄 수 있어

\mathbf{x}_{t}|\mathbf{x}_{t+1})}\left[\log\prod_{t=1}^{T-1}\frac{p(\mathbf{x}_{t}|\mathbf{x}_{t+1})}\left[\log\frac{p(\mathbf{x}_{t}|\mathbf{x}_{t+1})}\right]}\left[\log\frac{p(\mathbf{x}_{t}|\mathbf{x}_{t+1})}\mathbf{x}_{t+1})}\right]\] \[=\sum_{t=1}^{T-1}\mathbf{p(\mathbf{x}_{t}|\mathbf{x}_{t+1})}\mathbf{x}_{t+1})}\right]\] \[=-\underbrace{\sum_{t=1}^{T-1}\mathbb

\(p(\mathbf{x}_{0}|\mathbf{x}_{1})\)를 \(p_{\mathbf{\theta}}(\mathbf{x}_{0}|\mathbf{x}_{1})\) 및 \(p(\mathbf{x}_{t}|\mathbf{x}_{t+1})\)를 \(p_{\mathbf{\theta}}(\mathbf{x}_{t}|\mathbf{x}_{t+1})\)로 대체함으로써, 우리는 수행된다.

### 일관성 용어 다시 쓰기

위 변동확산모델의 악몽은 조인트 분포로부터 샘플 \((\mathbf{x}_{t-1},\mathbf{x}_{t+1})\) \(q_{\mathbf{\phi}}(\mathbf{x}_{t-1},\mathbf{x}_{t+1}|\mathbf{x}_{0})\)을 추출해야 한다는 것이다. 우리는 \(q_{\mathbf{\phi}}(\mathbf{x}_{t-1},\mathbf{x}_{t+1}|\mathbf{x}_{0})\)가 무엇인지 모른다! 물론 가우시안이지만, 여전히 우리는 미래의 샘플 \(\mathbf{x}_{t+1}\)을 사용하여 현재 샘플 \(\mathbf{x}_{t}\)을 그릴 필요가 있다. 이것은 이상하고 재미가 없다.

일관성 항을 조사한 결과, \(q_{\mathbf{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{t-1})\)과 \(p_{\mathbf{\theta}}(\mathbf{x}_{t}|\mathbf{x}_{t+1})\)이 서로 반대 방향으로 움직이는 것을 알 수 있었다. 따라서 \(\mathbf{x}_{t-1}\)와 \(\mathbf{x}_{t+1}\)를 사용하는 것은 불가피하다. 우리가 질문해야 할 질문은 우리가 일관성을 확인할 수 있는 동안 서로 다른 두 방향을 다룰 필요가 없도록 무언가를 생각해낼 수 있는가이다.

자, 여기 베이즈 정리라고 불리는 간단한 요령이 있습니다.

\[q(\mathbf{x}_{t}|\mathbf{x}_{t-1}|\mathbf{x}_{t-1})=\frac{q(\mathbf{x}_{t})q(\mathbf{x}_{t-1})}{q(\mathbf{x}_{t-1})}\quad\stackrel{{\text{ condition on }\mathbf{x}_{t}|\mathbf{x}_{t}|\mathbf{x}_{t-1}},\mathbf{x}_{0})=\frac{q(\mathbf{x}_{t-1}|\mathbf{x}_{t}|\mathbf{x}_{0})=\frac{q(\mathbf{x}_{t-1}|\mathbf{x}_{t}|\mathbf{x}_{0})}{q(\mathbf{x}_{t}|\mathbf{x}_{

이러한 조절 순서의 변화에 따라 조건 변수 \(\mathbf{x}_{t}|\mathbf{x}_{t-1},\mathbf{x}_{0})\)를 하나 더 추가하여 \(q(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\)를 \(q(\mathbf{x}_{0})\)로 전환할 수 있다. 도 13에 도시된 바와 같이, 방향 \(q(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\)은 이제 \(p_{\mathbf{\theta}}(\mathbf{x}_{t-1}|\mathbf{x}_{t})\)와 평행하다. 따라서, 일관성 항을 다시 쓰려면, 자연적인 옵션은 \(q_{\mathbf{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\)와 \(p_{\mathbf{\theta}}(\mathbf{x}_{t-1}|\mathbf{x}_{t})\) 사이의 KL 발산을 계산하는 것이다.

만약 우리가 몇 가지 (지루한) 대수적 도함수를 통과한다면, 우리는 ELBO가 지금이라는 것을 보여줄 수 있다:

그림 13: Eqn (31)에서 Bayes 정리를 고려하면, 우리는 \(p_{\mathbf{\theta}}(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\)와 평행한 방향을 갖는 분포 \(q_{\mathbf{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{t})\)를 정의할 수 있다.

변분 확산 모델을 위한 ELBO는

\mathbf{x}_{0})\Big{[}\underbrace{\mathbb{D}_{\text{KL}}\Big{(}q_{\mathbf{\phi}( \mathbf{x}_{t}|\mathbf{x}_{0})}\Big{(}q_{\mathbf{\phi}( \mathbf{x}_{1}|\mathbf{x}_{0})}_{\text{new prior matching}}\] \[\qquad-\sum_{t=2}^{T}\mathbf{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})}\Big{(}q_{\mathbf{\phi}}(\mathbf{x}_{1}|\mathbf{x}_{0})}\Big{(}q_{\mathbf{\phi}}(\mathbf{x}_{1}|\mathbf

세 가지 해석을 빨리 해봅시다.

* **재구성**. 새로운 재구성 용어는 이전과 동일합니다. 우리는 여전히 로그 가능성을 최대화하고 있다.
* **이전 일치** 입니다. 새로운 사전 매칭은 \(q_{\mathbf{\phi}}(\mathbf{x}_{T}|\mathbf{x}_{0})\)와 \(p(\mathbf{x}_{T})\) 사이의 KL 발산으로 단순화된다. 그 변화는 우리가 \(\mathbf{x}_{0}\)를 조건으로 하고 있기 때문이다. 따라서, \(q_{\mathbf{\phi}}(\mathbf{x}_{T-1}|\mathbf{x}_{0})\)로부터 샘플을 추출하고 기대치를 취할 필요가 없다.
* **일관성**. 새로운 일관성 항은 이전 항과 두 가지 면에서 다르다. 먼저 실행 인덱스 \(t\)는 \(t=2\)에서 시작되고 \(t=T\)에서 종료됩니다. 이전에는 \(t=1\)에서 \(t=T-1\)까지였다. 이에 수반되는 분포 매칭은 이제 \(q_{\mathbf{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\)와 \(p_{\mathbf{\theta}}(\mathbf{x}_{t-1}|\mathbf{x}_{t})\ 사이에 있다. 따라서, 순방향 전이를 역전이와 일치시키기 위해 요청하는 대신, 우리는 \(q_{\mathbf{\phi}}\)를 사용하여 역방향 전이를 구성하고 이를 \(p_{\mathbf{\theta}}\)와 일치시키기 위해 사용한다.

**Eqn의 증명** (32). 우리는 그것을 보여줌으로써 Eqn(28)로 시작한다.

\mathbf{x}_{0})}\left[\log\frac{p(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\left[\log\frac{p(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\prod_{t=2}^{T}q_{\mathbff{\phi}}(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\left[\log\frac{p(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\prod_{t=2}^{T}q_{\mathbff{\phi}}(\mathbf{x}_{t}|\mathbf{x}_{0})}\left[\log\frac{p(\mathbf{x}_{0})}{q_{\mathbff{\phi}}(\mathbf{

두 번째 임기를 생각해 봅시다.

\mathbf{x}_{t-1}|\mathbf{x}_{t})}{q_{\mathbff{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{t})}{q_{\mathbff{phi}}(\mathbf{x}_{t})}{q_{\mathbff{p(\mathbf{x}_{t-1}|\mathbf{x}_{t})}{q_{\mathbff{ \phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{0})}\times\prod_{t=2}^{T}\frac{p(\mathbf{x}_{t-1}|\mathbf{x}_{t})}{q_{\mathbff{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{0})}{q_{\mathbf

여기서 마지막 방정식은 임의의 수열 \(a_{1},\ldots,a_{T}\)에 대해 \(\ldots\times\frac{a_{T-1}}{a_{T}}=\frac{a_{1}}{a_{T}}\)이라는 사실을 이용한다. Eqn (33)으로 돌아가면, 우리는 그것을 볼 수 있다.

\mathbf{x}_{0})}\left[\log\frac{p(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\left[\log\frac{p(\mathbf{x}_{0})p(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\mathbf{x}_{1}|\mathbf{x}_{0})}{q_{\mathbff{\phi}}(\mathbf{x}_{1}|\mathbf{x}_{0})}+\log\frac{q_{\mathbff{\phi}}(\mathbf{x}_{1}|\mathbf{x}_{0})}{q_{\mathbff{\phi}}(\mathbf{x}_{1}|\mathbf{x}_{0})}{q_{\mathbff{\phi}}(\mathbf{

여기에서 우리는 임의의 양의 상수 \(a\), \(b\), \(c\)에 대해 \(\log\frac{a}{b}+\log\frac{b}{c}=\log\frac{a}{c}\)이므로 분자와 분모에서 \(q_{\mathbf{\phi}}(\mathbf{x}_{1}|\mathbf{x}_{0})\)를 취소했다. 이것이 우리에게 줄 것입니다

\mathbf{x}_{0})}\left[\log\frac{p(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\left[\log\frac{p(\mathbf{x}_{0})}{q_{\mathbff{\phi}}(\mathbf{x}_{0})}\left[\log\frac{p(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\mathbf{x}_{0})}\left[\log\frac{p(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\mathbf{x}_{0})}\left[\log\frac{p(\mathbf{x}_{1:T}|\mathbf{x}_{0})}\mathbf{x}_{0})}\left[\log\frac{p(\mathbf

마지막 항은

\mathbf{x}_{t-1}|\mathbf{x}_{t})}\left[ \log\prod_{t=2}^{T}\frac{p(\mathbf{x}_{t-1}|\mathbf{x}_{t})}{q_{\mathbf{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{t})}\log\frac{p(\mathbf{x}_{t-1}|\mathbf{x}_{0})}\mathbb{D}_{\text{KL}}(=-\underbrace{\sum_{t=2}\mathbb{E}_{q_{\mathbff{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{t})}\mathbf{x}_{0})}\mathbf{x}_{t}}(\mathbf{x}_{t-1}|\mathbf{

마지막으로 \(p(\mathbf{x}_{t-1}|\mathbf{x}_{t})\)를 \(p_{\mathbf{\theta}}(\mathbf{x}_{t-1}|\mathbf{x}_{t})\)로, \(p(\mathbf{x}_{0}|\mathbf{x}_{1})\)를 \(p_{\mathbf{\theta}}(\mathbf{x}_{0}|\mathbf{x}_{1})\)로 대체한다. 됐어!

### \(q_{\mathbf{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\)

이제 우리는 변분 확산 모델을 위한 새로운 ELBO를 알고 있으므로, 그것의 핵심 구성 요소인 \(q_{\mathbf{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\에 대해 논의하는 데 시간을 보내야 한다. 간단히 말해서, 우리가 보여주고 싶은 것은

* \(q_{\mathbf{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\)는 생각보다 미치지 않습니다. 그것은 여전히 가우시안이다.
* 가우시안이기 때문에 평균과 공분산을 완전히 특징으로 한다. \[q_{\mathbf{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})=\mathcal{N}( \mathbf{x}_{t-1}\,|\,\bigtriangledown\!\mathbf{x}_{t}+\bigtriangleup\!\mathbf{x}_{0},\bigtriangleup\!\mathbff{I}),\] (34) for some magic scalars \(\bigtriangledown\!\) , \(\bigtriangleup\) 및 \(\bigtriangleup\)이 아래에 정의됩니다.

분포 \(q_{\mathbf{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\)의 형태를 취한다.

\[q_{\mathbf{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})=\mathcal{N}( \mathbf{x}_{t-1}\,|\,\mathbf{\mu}_{q}(\mathbf{x}_{t},\mathbf{x}_{0}),\mathbf{\Sigma}_{q}(t)), \tag{35}\

where

\mathbf{x}_{t}+\frac{(1-\alpha_{t})\sqrt{\overline{\alpha}_{t}}\mathbf{x}_{0} \tag{36}\] \[\mathbf{\Sigma}_{q}(t) =\frac{(1-\overline{\alpha}_{t}}}{1-\overline{\alpha}_{t}}\mathbf{x}_{0} \tag{37}\]}{1-\overline{\alpha}_{t}}\mathbf{I}\stackrel{{\text{def}}}{{=}}\sigma_{q}^{2}(t)\mathbf{I}}\tag{37}\]

Eqn(35)의 흥미로운 부분은 \(q_{\mathbf{\phi}}(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\)이 \(\mathbf{x}_{t}\)와 \(\mathbf{x}_{0}\)로 완전히 특징지어진다는 것이다. 평균과 분산을 추정하는 데 필요한 신경망이 없습니다! (당신은 이것을 VAE에서 비교할 수 있습니다.

[MISSING_PAGE_FAIL:21]

* 주어진 \(\mathbf{x}_{t}\sim q(\mathbf{x}_{t}|\mathbf{x}_{0})\)는 \(\log p_{\boldsymbol{\theta}}(\mathbf{x}_{0}|\mathbf{x}_{1})\)로 계산할 수 있으며, 이는 \(\log\mathcal{N}(\mathbf{x}_{0}|\boldsymbol{\mu}_{\boldsymbol{\theta}}( \mathbf{x}_{1}),\sigma_{q}^{2}(1)\mathbf{I})\이다. 따라서 \(\mathbf{x}_{1}\)을 아는 즉시 네트워크 \(\boldsymbol{\mu}_{\boldsymbol{\theta}}(\mathbf{x}_{1})\)에 전송하여 평균 추정치를 반환할 수 있다. 그런 다음 평균 추정치를 사용하여 우도를 계산합니다.

더 내려가기 전에, Eqn(35)이 어떻게 결정되었는지 논의함으로써 이야기를 완성하자.

**Eqn의 증명** (35). Eqn(31)에 명시된 베이즈 정리를 이용하면 다음과 같은 Gaussians의 곱을 평가하면 \(q(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\)을 구할 수 있다.

\[q(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})=\frac{\mathcal{N}(\mathbf{x}_{t}|\sqrt{\alpha_{t}}\mathbff{x}_{t-1}|\sqrt{\alpha_{t-1}},(1-\overline{\alpha}_{t-1}\mathbff{I}))}{ \mathcal{N}(\mathbf{x}_{t}|\sqrt{\alpha_{t}}\mathbff{x}_{0}}. \tag{44}\]

단순화를 위해 우리는 벡터를 스칼라로 취급할 것이다. 그러면 위의 가우시안 산물이 될 것이다.

\[q(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})\propto\exp\left\frac{( \mathbf{x}_{t}-\sqrt{\alpha}_{t}\mathbff{x}_{t-1})^{2}}+\frac{(\mathbf{x}_{t-1}-\sqrt{\overline{\alpha}_{t-1}}z)^{2}}}{2(1-\overline{\alpha} _{t-1})}-\frac{(\mathbf{x}_{t}-\sqrt{\overline{\alpha}_{t}}\mathbff{x}_{0})^{2}}{2(1-\overline{\alpha}_{t})}\right\}. \tag{45}\]

우리는 다음과 같은 매핑을 고려한다:

\[x =\mathbf{x}_{t}, a=\alpha_{t}\] \[y =\mathbf{x}_{t-1}, b=\overline{\alpha}_{t-1}\] \[z =\mathbf{x}_{0}, c=\overline{\alpha}_{t}}.\]

2차 함수를 고려

\[f(y)=\frac{(x-\sqrt{a}y)^{2}}{2(1-a)}+\frac{(y-\sqrt{b}z)^{2}}{2(1-b)}-\frac{( x-\sqrt{c}z)^{2}}{2(1-c)}. \tag{46}\]

우리는 항을 어떻게 재배열하든 결과 함수는 2차 방정식으로 남아 있다는 것을 안다. \(f(y)\)의 최소값은 결과 가우시안 평균이다. 그래서 우리는 \(f\)의 도함수를 계산할 수 있고 그것을 보여줄 수 있다.

\[f^{\prime}(y)=\frac{1-ab}{(1-a)(1-b)}y-\left(\frac{\sqrt{a}}{1-a}x+\frac{\sqrt {b}}{1-b}z\right).\]

설정 \(f^{\prime}(y)=0\) 수율

\[y=\frac{(1-b)\sqrt{a}}{1-ab}x+\frac{(1-a)\sqrt{b}}{1-ab}z. \tag{47}\]

우리는 \(ab=\alpha_{t}\overline{\alpha}_{t-1}=\overline{\alpha}_{t}\)에 주목한다. 그래서

\[\boldsymbol{\mu}_{q}(\mathbf{x}_{t},\mathbf{x}_{0})=\frac{(1-\overline{\alpha}_{t-1})\sqrt{\alpha}_{t}}}{1-\overline{\alpha}_{t}}\mathbf{x}_{t}+\frac{(1- \alpha_{t})\sqrt{\alpha_{t-1}}}}{1-\overline{\alpha}_{t}}\mathbf{x}_{0}. \tag{48}\]

마찬가지로 분산에 대해서도 곡률 \(f^{\prime\prime}(y)\)을 확인할 수 있다. 우리는 쉽게 보여줄 수 있어

\[f^{\prime\prime}(y)=\frac{1-ab}{(1-a)(1-b)}=\frac{1-\overline{\alpha}_{t}}{(1- \alpha_{t})(1-\sqrt{\overline{\alpha}_{t-1}})}.\]

상호 작용을 하면

\[\boldsymbol{\Sigma}_{q}(t)=\frac{(1-\alpha_{t})(1-\sqrt{\overline{\alpha}_{t-1}})}{1-\overline{\alpha}_{t}}\mathbff{I}. \tag{49}\]

### Training and Inference

Eqn (43)의 ELBO는 이러한 손실을 어떻게든 최소화할 수 있는 네트워크 \(\mathbf{\mu}_{\mathbf{\theta}}\)를 찾아야 함을 시사한다:

\[\frac{1}{2\sigma_{q}^{2}(t)}\|\underbrace{\mathbf{\mu}_{q}(\mathbf{x}_{t},\mathbf{x}_{0})}_{\text{known}}-\underbrace{\mathbf{\mu}_{\mathbf{\theta}}(\mathbf{x}_{t})}_{ \text{network}}}\|^{2}. \tag{50}\]

그러나 "디노이징" 개념은 어디에서 비롯됩니까?

이를 보기 위해 우리는 Eqn(36)에서 다음과 같이 회상한다.

\[\mathbf{\mu}_{q}(\mathbf{x}_{t},\mathbf{x}_{0})=\frac{(1-\overline{\alpha}_{t}}}{1-\overline{\alpha}_{t}}\mathbf{x}_{t}+\frac{(1-\alpha_{t})\sqrt{\overline{\alpha}_{t-1}}}{1-\overline{\alpha}_{t}}\mathbf{x}_{0}. \tag{51}\]

\(\mathbf{\mu}_{\mathbf{\theta}}\)는 우리의 _design_이기 때문에 더 편리한 것으로 정의할 수 없는 이유는 없다. 그래서 여기 옵션이 있습니다.

\[\overline{\alpha}_{t-1})\overset{ \text{def}}{=}\frac{(1-\overline{\alpha}_{t}}\sqrt{\alpha}_{t}}\mathbff{x}_{t}+\frac{(1-\alpha_{t})\sqrt{\overline{\alpha}_{t-1}}}{1-\overline{\alpha}_{t}}\underbrace{\widehat{\mathbff{x}}_{\mathbff{\theta}}( \mathbf{x}_{t})}_{\text{a network}}}. \tag{52}\

Eqn(51)과 Eqn(52)을 Eqn(50)에 대입하면

[\frac{1}{2\sigma_{q}^{2}(t)}\left\|\frac{(1-\alpha_{t})\sqrt{ \overline{\alpha}_{t}}(\widehat{\mathbf{x}}_{\mathbf{ \theta}}(\mathbf{x}_{t})-\mathbf{x}_{0})\right\|^{2}\] \[=\frac{1}{2\sigma_{q}^{2}(t)}\frac{(1-\alpha_{t})\frac{(1-\alpha_{t})\left\|\widehat{\mathbf{x}_{\mathbf{ \theta}}(\mathbf{x}_{t})-\mathbf{x}_{0})\right\|^{2}\] \[=\frac{1}{2\sigma_{q}^{2}(t)}\frac{(1-\alpha_{t})\

따라서 ELBO를 단순화할 수 있다.

\mathbf{x}_{0})}\Big{[}\frac{1}{2\sigma_{q}^{2}(t)}\frac{(1-\overline{\alpha}_{t})^{2} \overline{\alpha}_{t-1}}}{(1-\overline{\alpha}_{t})^{2}\mathbf{x}_{0})}[\log p_{\mathbf{ \theta}(\mathbf{x}_{t}|\mathbf{x}_{1})}[\log p_{\mathbf{ \theta}}(\mathbf{x}_{t})\|^{2} \Big{]}\\sum_{t=2}^{T}\mathbb{E}_{q(\mathbf{x}_{t})}[\mathbf{x}_{0}}\mathbf{x}_{0})}[\log p_{\mathbf{ \theta}(\mathbf{x}_{t}

첫 번째 항은

\mathbf{1}\left\|\frac{(1-\overline{\alpha}_{0})\mathbf{I})\propto-\frac{1}{2\sigma_{q}^{2}(1)}\mathbf{0}|\mathbf{I})\propto-\frac{1}{2\sigma_{q}^{2}(1)}\|\mathbf{mu}_{\mathbf{\theta}(\mathbf{x}_{1})-\mathbf{x}_{0}|^{2} \text{definition}\] \[=-\frac{1}{2\sigma_{q}^{2}(1)}\left\|\frac{1-\overline{\alpha}_{1}}\mathbf{x}_{1})\sqrt{\alpha}_{1}+\frac{(1-\alpha_{1})}{1-\overline{\alpha}_{1}}\mathbf{x}_{

Eqn(54)을 Eqn(53)에 대입하면 ELBO는 다음과 같이 단순화된다.

\text{ELBO}_{\mathbf{\theta}=-\sum_{t=1}^{T}\mathbb{E}_{q(\mathbf{x}_{t}|\mathbf{x}_{0})}\Big{[}\frac{1}{2\sigma_{q}^{2}(t)}\frac{(1-\alpha_{t})}\overline{ \alpha}_{t-1}}{(1-\overline{\alpha}_{t})^{2}}\left\|\widehat{\mathbf{x}}_{ \mathbf{\theta}}(\mathbf{x}_{t})-\mathbf{x}_{0}\right\|^{2}\Big{]}.\]

따라서, 신경망의 학습은 단순 손실 함수로 귀결된다:

디노이징 확산 확률 모델에 대한 **손실 함수** 입니다.

(1-\alpha_{t})^{2}\overline{\alpha}_{t-1}}{(1- \overline{\alpha}_{t})^{2}}\mathbb{E}_{q(\mathbf{x}_{t}|\mathbf{x}_{0})}\Big{[} \left\|\widehat{\mathbf{x}}_{\mathbf{\theta}^{*}=\operatorname*{argmin}_{\mathbf{\theta}}\sum_{t=1}^{T}\sigma_{q}^{2}(t)}\mathbf{x}_{0})}\Big{[} \left\|\widehat{\mathbf{x}}_{\mathbf{\theta}}}(\mathbf{x}_{t})-\mathbf{x}_{0}\right\|^{2}\Big{]}. \tag{55}\ Eqn(55)에 정의된 손실 함수는 매우 직관적이다. 특정 \(\mathbf{x}_{t}\)에 대한 주요 관심 주제인 상수와 기대를 무시하는 것은

\[\operatorname*{argmin}_{\boldsymbol{\theta}}\ \ \left\lVert\widehat{\mathbf{x}}_{ \boldsymbol{\theta}}(\mathbf{x}_{t})-\mathbf{x}_{0}\right\rVert^{2}.\]

이것은 잡음제거된 영상 \(\widehat{\mathbf{x}}_{\boldsymbol{\theta}})\(\widehat{\mathbf{x}}_{\boldsymbol{\theta}})\(\mathbf{x}_{t})\)이 ground truth \(\mathbf{x}_{0}\)에 가까울 수 있도록 네트워크 \(\widehat{\mathbf{x}_{0}\)를 찾아야 하기 때문에 잡음제거 문제일 뿐이다. 전형적인 데노이스가 아닌 이유는

* \(\mathbb{E}_{q(\mathbf{x}_{t}|\mathbf{x}_{0})}\): 임의의 잡음이 있는 이미지를 노이즈 제거하려고 하지 않습니다. 대신에, 우리는 \[\mathbf{x}_{t}\sim q(\mathbf{x}_{t}|\mathbf{x}_{0}) =\mathcal{N}(\mathbf{x}_{t}\,|\,\sqrt{\widehat{\alpha}_{t}} \mathbf{x}_{0},\\(1-\overline{\alpha}_{t})\mathbf{I})\] \[=\sqrt{\overline{\alpha}_{t}}\mathbf{x}_{0}+\sqrt{(1-\overline{ \alpha}_{t})}\mathbf{z},\qquad\mathbf{z}\sim\mathcal{N}(0,\mathbf{I}})\]을 선택한다. \] 여기서, "조심스럽다"는 것은 이미지에 주입되는 잡음의 양이 주의 깊게 조절된다는 것을 의미했다.
* \(\frac{1}{2\sigma_{q}^{2}(t)}\frac{(1-\alpha_{t})^{2}\overline{\alpha}_{t}-1}{ (1-\overline{\alpha}_{t})^{2}}\): 모든 단계에서 노이즈 손실을 동일하게 가중하지 않는다. 대신에, 각각의 디노이징 손실에 대한 상대적인 강조를 제어하는 스케줄러가 있다. 그러나, 단순화를 위해, 우리는 이것들을 떨어뜨릴 수 있다. 그것은 사소한 영향을 끼친다.
* \(\sum_{t=1}^{T}\): 합계는 균일 분포 \(t\sim\text{Uniform}[1,T]\)로 대체될 수 있다.

**거부 확산 확률 모델 교육**. (Version: Predict image) For every image \(\mathbf{x}_{0}\) in your training dataset:

* 수렴할 때까지 다음 단계를 반복합니다.
* 랜덤 타임 스탬프 \(t\sim\text{Uniform}[1,T]\)를 선택합니다.
* 샘플 \(\mathbf{x}_{t}\sim\mathcal{N}(\mathbf{x}_{t}\,|\,\sqrt{\overline{\alpha}_{t}} \mathbf{x}_{0},\(1-\overline{\alpha}_{t})\mathbf{I})\), 즉 \[\mathbf{x}_{t}=\overline{\alpha}_{t}\mathbf{x}_{0}+\sqrt{(1-\overline{ \alpha}_{t})}\mathbf{z},\qquad\mathbf{z}\sim\mathcal{N}(0,\mathbf{I}).\]
* \[\nabla_{\boldsymbol{\theta}}\left\lVert\widehat{\mathbf{x}}_{\boldsymbol{ \theta}}(\mathbf{x}_{t})-\mathbf{x}_{0}\right\rVert^{2}}\

다른 신경망을 훈련하는 것처럼 일괄적으로 이것을 할 수 있습니다. 여기서는 **모든** 노이즈 조건에 대해 **하나의** 노이즈 제거 네트워크 \(\widehat{\mathbf{x}}_{\boldsymbol{\theta}}\)를 교육합니다.

일단 denoiser \(\widehat{\mathbf{x}}_{\boldsymbol{\theta}}\)가 학습되면 추론에 적용할 수 있다. 추론은 상태 \(\mathbf{x}_{T},\mathbf{x}_{T-1},\ldots,\mathbf{x}_{1}\)에 대한 분포 \(p_{\boldsymbol{\theta}}(\mathbf{x}_{t-1}|\mathbf{x}_{t})\)로부터 이미지를 샘플링하는 것이다. 그 반대이기 때문에

도 14: 순방향 샘플링 프로세스. 정방향 샘플링 프로세스는 원래 일련의 작업이다. 그러나 가우시안(Gaussian)을 가정하면 샘플링 과정을 1단계 데이터 생성으로 단순화할 수 있다.

확산 프로세스, 우리는 그것을 통해 재귀적으로 할 필요가 있다:

\,\,\mathbf{I})\] \[=\frac{(1-\overline{\alpha}_{t-1}\,|\,\boldsymbol{\mu}_{\boldsymbol{\theta}}(\mathbf{x}_{t-1}\,|\,\boldsymbol{\mu}_{\boldsymbol{\theta}}(\mathbf{x}_{t}),\sigma_{q}^{2}(t)\mathbf{I})\] \[=\boldsymbol{\mu}_{\boldsymbol{\theta}}(\mathbf{x}_{t})+\sigma_{q}^{2}(t)\mathbf{z},\qquad\qquad\text{where}\quad\mathbf{z}_{t}}\mathbf{1- \overline{\alpha}_{t}}+\frac{(1-\alpha_{t})\sqrt{\overline{

이는 다음과 같은 추론 알고리즘으로 이어진다.

**거절 확산 확률 모델에 대한 추론**. (버전: 예측 영상)

* 백색 잡음 벡터 \(\mathbf{x}_{T}\sim\mathcal{N}(0,\mathbf{I})\)를 제공합니다.
* \(t=T,T-1,\ldots,1\)에 대해 다음을 반복합니다.
* 학습된 denoiser를 사용하여 \(\widehat{\mathbf{x}}_{\boldsymbol{\theta}}(\mathbf{x}_{t})\)을 계산합니다.
* \[\mathbf{x}_{t-1}=\frac{(1-\overline{\alpha}_{t-1})\sqrt{\alpha}_{t}}}{1- \overline{\alpha}_{t}}\mathbf{x}_{t}+\frac{(1-\alpha_{t})\sqrt{\overline{ \alpha}_{t-1}}}{1-\overline{\alpha}_{t}}\widehat{\mathbf{x}}_{\boldsymbol{ \theta}}(\mathbf{x}_{t})+\sigma_{q}(t)\mathbf{z}\sim\mathcal{ N}(0,\mathbf{I}).\] (56)

### 잡음 벡터 기반 유도

노이즈 제거 문헌에 익숙하다면 신호 대신 잡음을 예측하는 레지듀 형태의 알고리즘을 알고 있을 것이다. 우리가 배울 수 있는 디노이징 확산에도 같은 정신이 적용된다.

도 16: 디노이징 확산 확률 모델의 추론.

도 15: 디노이징 확산 확률 모델의 트레이닝. 동일한 신경망 \(\widehat{\mathbf{x}}_{\boldsymbol{\theta}}\)에 대해 잡음 입력 \(\mathbf{x}_{t}\)을 네트워크로 전송한다. 손실 기울기는 네트워크를 업데이트하기 위해 역전파된다. 노이즈 이미지는 임의적이지 않습니다. 이들은 순방향 샘플링 프로세스에 따라 생성된다.

소음을 예측합니다. 이것이 왜 그런지를 알기 위해, 우리는 Eqn(24)을 고려한다. 우리가 얻을 조건을 다시 조정하면

\[\mathbf{x}_{t} =\sqrt{\overline{\alpha}_{t}}\mathbf{x}_{0}+\sqrt{1-\overline{ \alpha}_{t}}\mathbf{\epsilon}_{0}\] \[\Rightarrow \mathbf{x}_{0} =\frac{\mathbf{x}_{t}-\sqrt{1-\overline{\alpha}_{t}}\mathbf{\epsilon}_{0}}{\sqrt{\overline{\alpha}_{t}}}}.\]

이를 \(\mathbf{\mu}_{q}(\mathbf{x}_{t},\mathbf{x}_{0})\)에 대입하면 다음과 같은 것을 보일 수 있다.

\mathbf{x}_{t}+\sqrt{\overline{\alpha}_{t}}\] \[=\frac{\sqrt{\alpha}_{t}}(1-\overline{\alpha}_{t-1})\mathbf{x}_{t}+\sqrt{\overline{\alpha}_{t-1}}(1-\alpha_{t})\cdot\frac{\mathbf{x}_{t}+\sqrt{\overline{\alpha}_{t-1}}(1-\alpha_{t})\cdot\frac{\mathbf{x}_{t}+\sqrt{\overline{\alpha}_{t}}}}}{1-\overline{\alpha}_{t}}}}{1-\overline{\alpha}_{t}}}{1-\mathbff{x}_{t}+\sqrt{\overline{\alpha}_{t}}}}{1-\overline{\alpha}_{t}}}}{1-\overline{\alpha}_{t}

따라서, 우리가 평균 추정량 \(\mathbf{\mu}_{\mathbf{\theta}}\)을 _설계_할 수 있다면, 우리는 그것을 양식에 맞게 자유롭게 선택할 수 있다:

\[\mathbf{\mu}_{\mathbf{\theta}}(\mathbf{x}_{t})=\frac{1}{\sqrt{\alpha_{t}}}\mathbff{x}_{t}-\frac{1-\overline{\alpha}_{t}}\sqrt{\alpha_{t}}}\widehat {\mathbf{\epsilon}}_{\mathbf{\theta}}(\mathbf{x}_{t}). \tag{58}\]

Eqn(57)과 Eqn(58)을 Eqn(50)에 대입하면 새로운 ELBO를 얻을 수 있다.

\[\text{ELBO}_{\mathbff{\theta}}=-\sum_{t=1}^{T}\mathbb{E}_{q(\mathbf{x}_{t}| \mathbf{x}_{0})}\frac{(1-\alpha_{t})}\overline{\alpha}_{t-1}}{(1-\overline{\alpha}_{t})^{2}}\left\|\widehat{\mathbf{ \epsilon}}_{\mathbf{\theta}}(\mathbf{x}_{t})-\mathbf{\epsilon}_{0}\right\|^{2}\Big{]}.\]

따라서 \(\mathbf{x}_{t}\)를 주면 예측 노이즈 \(\widehat{\mathbf{\epsilon}}_{\mathbf{\theta}}(\mathbf{x}_{t})\)를 반환합니다. 이것은 우리에게 대안적인 교육 계획을 제공할 것입니다.

**거부 확산 확률 모델 교육** (버전 예측 잡음). 훈련 데이터 세트의 모든 이미지 \(\mathbf{x}_{0}\)에 대해:

* 수렴할 때까지 다음 단계를 반복합니다.
* 랜덤 타임 스탬프 \(t\sim\text{Uniform}[1,T]\)를 선택합니다.
* 샘플 \(\mathbf{x}_{t}\sim\mathcal{N}(\mathbf{x}_{t}\,|\,\sqrt{\overline{\alpha}_{t}} \mathbf{x}_{0},\,\,\,\,(1-\overline{\alpha}_{t})\mathbf{I})\), 즉 \[\mathbf{x}_{t}=\sqrt{\overline{\alpha}_{t}}\mathbf{x}_{0}+\sqrt{(1- \overline{\alpha}_{t})}\mathbf{z},\qquad\mathbf{z}\sim\mathcal{N}(0,\mathbf{ I}).\]
* \[\nabla_{\mathbf{\theta}}\left\|\widehat{\mathbf{\epsilon}}_{\mathbf{\theta}}(\mathbf{x}_{t})-\mathbf{\epsilon}_{0}\right\|^{2}\]에서 기울기 하강 단계를 취합니다.

결과적으로, 추론 단계는 다음을 통해 도출될 수 있다.

\,\mathbf{x}_{t-1}\,|\,\mathbff{\mu}_{\mathbf{\theta}}(\mathbf{ x}_{t}),\sigma_{q}^{2}(t)\mathbf{I})\] \[=\mathbf{\mu}_{\mathbf{\theta}}(\mathbf{x}_{t})+\sigma_{q}^{2}(t)\mathbf{z}\] \[=\frac{1}{\sqrt{\alpha_{t}}}\mathbff{x}_{t}-\frac{1-\overline{\alpha}_{t}}\sqrt{\alpha}}}\widehat{\mathbf{\epsilon}}(\mathbf{x}_{t}}{\sqrt{1-\overline{\alpha}_{t}}\sqrt{\alpha}}}\widehat{\mathbff{\epsilon}}_{\mathbff{\theta}

여기서 정리하면

**디노이징 확산 확률 모델에 대한 추론**. (Version Predict noise)

당신은 우리에게 백색 잡음 벡터 \({\bf x}_{T}\sim\mathcal{N}(0,{\bf I})\)를 준다.

\(t=T,T-1,\ldots,1\)에 대해 다음을 반복합니다.

학습된 denoiser를 이용하여 \(\widehat{\bf x}_{\boldsymbol{\theta}}({\bf x}_{t})\)을 계산한다.

에 따른 업데이트

\[{\bf x}_{t-1}=\frac{1}{\sqrt{\alpha_{t}}}\left({\bf x}_{t}-\frac{1-\alpha_{t}}}{ \sqrt{1-\overline{\alpha}_{t}}}\widehat{\boldsymbol{\varepsilon}}_{\boldsymbol{\theta}}({\bf x}_{t})\right)+\sigma_{q}(t){\bf z},\qquad{\bf z}\sim\mathcal{N}(0,{\bf I}).\]

### InDI(Direct Denoising)에 의한 Inversion

DDPM 방정식을 살펴보면, 업데이트 Eqn(56)이 다음과 같은 형태를 취하는 것을 볼 것이다:

\[{\bf x}_{t-1}=\left(\text{something}\right)\cdot{\bf x}_{t}+\left(\text{something else}\right)\cdot\text{denoise}({\bf x}_{t})+\text{noise}. \tag{59}\]

즉, \((t-1)\)-번째 추정치는 현재 추정치 \({\bf x}_{t}\), 노이즈 제거 버전 \(\text{denoise}({\bf x}_{t})\) 및 노이즈 항의 세 가지 항의 선형 조합이다. 현재 추정치와 잡음항은 이해하기 쉽다. 근데 '데노이즈'가 뭐야? 델브라시오와 밀란파르[6]의 흥미로운 논문은 생성 확산 모델을 순수한 잡음 제거 관점에서 살펴보았다. 알고 보니, 이 놀랍도록 단순한 관점은 다른 더 발전된 확산 모델과 몇 가지 좋은 측면에서 일치한다.

** \(\text{denoise}({\bf x}_{t})\)** 는 무엇인가요? 노이즈 제거는 노이즈가 많은 영상에서 노이즈를 제거하는 일반적인 절차이다. 통계 신호 처리의 좋은 옛날에 표준 교과서 문제는 백색 잡음에 대한 최적의 데노이저를 도출하는 것이다. 관측 모형이 주어지면

\[{\bf y}={\bf x}+\boldsymbol{\epsilon},\qquad\text{where}\;\;\boldsymbol{ \epsilon}\sim\mathcal{N}(0,{\bf I}),\]

평균 제곱 오차가 최소화되도록 추정기 \(g(\cdot)\)를 구성할 수 있습니까?

우리는 이 고전 문제에 대한 해의 도출은 어떤 확률 교과서, 예를 들어 [7장 8장]에서 찾을 수 있기 때문에 건너뛸 것이다. 상기 솔루션은,

\[\text{denoise}({\bf y}) =\underset{g}{\text{argmin}}\;\;\mathbb{E}_{{\bf x},{\bf y}}[\|g ({\bf y})-{\bf x}\|^{2}]\] \[=\text{some\;magical\;step}\] \[=\mathbb{E}[{\bf x}|{\bf y}]. \tag{60}\]

그래서 우리의 문제로 돌아가면: 만약 우리가 그렇게 가정한다면

\[{\bf x}_{t}={\bf x}_{t-1}+\boldsymbol{\epsilon}_{t-1},\qquad\text{where}\; \boldsymbol{\epsilon}_{t-1}\sim\mathcal{N}(0,{\bf I}),\]

그렇다면 명백히 데노아저는 사후 분포의 조건부 기대치이다:

\[\text{denoise}({\bf x}_{t})=\mathbb{E}[{\bf x}_{t-1}|{\bf x}_{t}]. \tag{61}\]

따라서 분포 \(p_{\boldsymbol{\theta}}({\bf x}_{t-1}|{\bf x}_{t})\)가 주어지면 최적 디노이저는 이 분포의 조건부 기대값일 뿐이다. 이러한 데노아저를 **최소 평균 제곱 오차** (MMSE) 데노아저라고 합니다. MMSE 데노아저는 "최상의" 데노아저가 아닙니다. 평균 제곱 오차와 관련하여 최적의 데노아저일 뿐입니다. 평균 제곱 오차는 결코 이미지 품질에 대한 좋은 메트릭이 아니기 때문에 MSE를 최소화하는 것이 반드시 더 나은 이미지를 제공하는 것은 아니다. 그럼에도 불구하고 사람들은 도출하기 쉽기 때문에 MMSE 데노아저를 좋아한다.

**증분 노이즈 제거 단계**. MMSE 디노이저가 사후 분포의 조건부 기대치와 동일하다는 것을 이해하면 증분 디노이징을 이해할 수 있습니다. 작동 방식은 이렇습니다. 깨끗한 이미지 \({\bf x}_{0}\)와 노이즈 이미지 \({\bf y}\)가 있다고 가정하자. 우리의 목표는 간단한 방정식을 통해 \({\bf x}_{0}\)와 \({\bf y}\)의 선형 조합을 형성하는 것이다.

\[{\bf x}_{t}=(1-t){\bf x}_{0}+t{\bf y},\qquad 0\leq t\leq 1. \tag{62}\]

이제 시간 \(t\) 이전의 작은 단계 \(\tau\)를 고려하십시오. [6]에 의해 나타난 다음 결과는 몇 가지 유용한 유틸리티를 제공한다:Let \(0\leq\tau<t\leq 1\), and suppose \(\mathbf{x}_{t}=(1-t)\mathbf{x}_{0}+t\mathbf{y}\), then the hold that

\[\mathbb{E}[\mathbf{x}_{t-\tau}|\mathbf{x}_{t}]=\Big{(}1-\frac{\tau}{t}\Big{)} \underbrace{\mathbf{x}_{t}}_{\text{current estimate}}\quad+\qquad\frac{\tau}{t} \quad\underbrace{\mathbb{E}[\mathbf{x}_{0}|\mathbf{x}_{t}]}_{\text{denoised}}. \tag{63}\

만약 \(\widehat{\mathbf{x}}_{t-\tau}\)를 좌변으로 정의하면, \(\mathbf{x}_{t}\)를 \(\widehat{\mathbf{x}}_{t}\)로 치환하고, \(\mathbb{E}[\mathbf{x}_{0}|\mathbf{x}_{t}]\)를 \(\text{denoise}(\widehat{\mathbf{x}}_{t})\)로 쓰면, 위의 식은 다음과 같다.

\[\widehat{\mathbf{x}}_{t-\tau}=\Big{(}1-\frac{\tau}{t}\Big{)}\cdot\widehat{ \mathbf{x}}_{t}+\frac{\tau}{t}\text{denoise}(\widehat{\mathbf{x}}_{t}), \tag{64}\]

여기서 \(\tau\)는 시간의 작은 단계이다.

Eqn(64)은 **추론** 단계를 제공합니다. 데노이저를 말하고 노이즈가 있는 이미지 \(\mathbf{y}\)로 시작한다고 가정하면 Eqn(64)을 반복적으로 적용하여 이미지 \(\widehat{\mathbf{x}}_{t-1}\), \(\widehat{\mathbf{x}}_{t-2}\),..., \(\widehat{\mathbf{x}}_{0}\)를 검색할 수 있다.

**교육**. 반복 스킴의 학습은 \(\text{denoise}(\mathbf{x}_{t})\)\를 생성하는 denoiser를 필요로 한다. 이를 위해 우리는 신경망 \(\text{denoise}_{\boldsymbol{\theta}}\)(여기서 \(\boldsymbol{\theta}\)는 네트워크 가중치를 나타냄)을 훈련시킬 수 있다:

\[\underset{\boldsymbol{\theta}}{\text{minimize}}\ \ \mathbb{E}_{\mathbf{x}, \mathbf{y}}\mathbb{E}_{t\sim\text{uniform}}\Big{[}\|\text{denoise}_{ \boldsymbol{\theta}}(\mathbf{x}_{t})-\mathbf{x}\|^{2}\Big{]}. \tag{65}\

여기서, 분포 "\(t\sim\) 균일"은 시간 단계 \(t\)가 주어진 분포로부터 균일하게 그려지는 것을 특정한다. 따라서 우리는 모든 시간 단계 \(t\)에 대해 하나의 데노이저를 훈련하고 있다. 기대 \((\mathbf{x},\mathbf{y})\)는 일반적으로 훈련 데이터 세트에서 노이즈와 깨끗한 이미지 쌍을 사용할 때 충족됩니다. 훈련 후, 우리는 Eqn(64)을 통해 증분 업데이트를 수행할 수 있다.

**디노이징 점수 일치 연결**. 우리는 아직 스코어-매칭(다음 섹션에서 제시될 것임)에 대해 논의하지 않았지만, 위의 반복적 디노이징 절차에 대한 흥미로운 사실은 그것이 스코어-매칭 디노이징과 관련이 있다는 것이다. 높은 수준에서 반복을 다시 쓸 수 있습니다.

\[\mathbf{x}_{t-\tau} =\Big{(}1-\frac{\tau}{t}\Big{)}\cdot\mathbf{x}_{t}+\frac{\tau}{t}\text{denoise}(\mathbf{x}_{t})\] \[\우측 \mathbf{x}_{t}+\mathbf{x}_{t-\tau}}{\tau} =\frac{\tau}{t}\text{denoise}(\mathbf{x}_{t})\] \[\우측 \frac{\mathbf{x}_{t}+\mathbf{x}_{t-\tau}}{\tau} =\frac{\mathbf{x}_{t}-\text{denoise}(\mathbf{x}_{t})}{t}\] \[\우측 \frac{x}_{t}-\text{denoise}(\mathbf{x}_{t

이것은 상미분 방정식(ODE)이다. 우리가 \(\mathbf{x}_{t}=\mathbf{x}+t\boldsymbol{\epsilon}\)을 \(\mathbf{x}_{t}\)의 잡음 레벨이 \(\sigma_{t}^{2}=t^{2}\sigma^{2}\)이 되도록 하면, 우리는 몇 가지 결과를 문헌에서 사용할 수 있음을 보여준다.

[\@@cite[cite]{[\@@bibref{}{Song et al.}{}]})\] \[=-t\sigma^{2}\nabla_{\mathbff{x}_{t}}\log p_{t}(\mathbf{x}_{t}) (\text{ODE defined by Song et al. \@@cite[cite]{[\@@bibref{}{}{}]})\] \[=-t\sigma^{2}\nabla_{\mathbff{x}_{t}}\log p_{t}(\mathbf{x}_{t}) (\sigma_{t}=t\sigma)\] \[\approx-t\sigma^{2}\frac{\mathbff{x}-\text{denoise}(\mathbf{x}_{t})}{t^{2}} (\text{Approximation proposed to Vincent \@@cite[cite]{[\@@bibref{

따라서, 증분 디노이징 반복은 적어도 ODE에 의해 결정된 제한 경우에 디노이징 스코어-매칭과 동등하다.

**추계적 단계 추가**. 위의 점진적 잡음 제거 반복은 확률적 섭동을 포함할 수 있다. 추론 단계에서는 잡음 레벨 \(\{\sigma_{t}\mid 0\leq t\leq 1\}\)의 시퀀스를 정의하고 정의할 수 있다.

\[\widehat{\mathbf{x}}_{t-\tau}=\Big{(}1-\frac{\tau}{t}\Big{)}\cdot\widehat{ \mathbf{x}}_{t}+\frac{\tau}{t}\text{denoise}(\widehat{\mathbf{x}}_{t})+(t- \tau)\sqrt{\sigma_{t-\tau}^{2}-\sigma_{t}^{2}}\boldsymbol{\epsilon},\qquad \boldsymbol{\epsilon}\sim\mathcal{N}(0,\mathbf{I}). \tag{66}\\ 또는 훈련을 통해 데노이저를 훈련할 수 있다.

\[\underset{\boldsymbol{\theta}}{\text{minimize}}\ \ \mathbb{E}_{(\mathbf{x}, \mathbf{y})}\mathbb{E}_{t\sim\text{uniform}}\mathbb{E}_{\boldsymbol{\epsilon}} \left[\|\text{denoise}(\mathbf{x}_{t})-\mathbf{x}\|^{2}\right], \tag{67}\

여기서 \(\mathbf{x}_{t}=(1-t)\mathbf{x}+t\mathbf{y}+\sqrt{t}\sigma_{t}\boldsymbol{ \epsilon}\).

### 축하합니다! 우린 끝났어 이것은 모두 DDPM에 관한 것이다.

DDPM의 문헌은 빠르게 폭발하고 있다. Sohl-Dickstein et al. [10]과 Ho et al. [4]의 원 논문은 주제를 이해하기 위해 반드시 읽어야 하는 것이다. 보다 "사용자 친화적인" 버전의 경우 Luo의 자습서가 매우 유용하다는 것을 발견했습니다[11]. 일부 후속 연구는 송 외[12]의 노이즈 제거 확산 암묵적 모델을 포함하여 많이 인용된다. 애플리케이션 측면에서, 사람들은 다양한 이미지 합성 애플리케이션, 예를 들어 [13, 14]을 위해 DDPM을 사용해 왔다.

Score-Matching Langevin Dynamics (SMLD)

점수 기반 생성 모델[8]은 원하는 분포로부터 데이터를 생성하기 위한 대안적인 접근법이다. 랭뱅 다이내믹스, (스타인) 스코어 함수, 스코어 매칭 손실 등 몇 가지 핵심 요소가 있다. 본 절에서는 이러한 주제들을 하나씩 살펴보도록 하겠다.

### Langevin Dynamics

우리 논의의 흥미로운 출발점은 랭뱅 역학이다. 그것은 생성 모델과 아무 관련이 없는 것처럼 보일 매우 물리학적인 주제이다. 하지만 걱정하지 마세요. 사실, 그들은 좋은 방식으로 관련이 있다.

물리학을 제대로 알려주는 대신 랭뱅 역학이 분포에서 표본을 추출하는 데 어떻게 사용될 수 있는지에 대해 이야기해 봅시다. 분포 \(p(\mathbf{x})\)가 주어졌다고 가정하고 \(p(\mathbf{x})\)로부터 표본을 추출하고자 한다고 가정하자. 랭뱅 역학은 다음 식에 따라 표본을 그릴 수 있는 반복 절차이다.

알려진 분포에서 샘플링하기 위한 **Langevin dynamics** \(p(\mathbf{x})\)는 \(t=1,\ldots,T\)에 대한 반복 절차입니다.

\[\mathbf{x}_{t+1}=\mathbf{x}_{t}+\tau\nabla_{\mathbf{x}}\log p(\mathbf{x}_{t}) +\sqrt{2\tau}\mathbf{z},\qquad\mathbf{z}\sim\mathcal{N}(0,\mathbf{I}), \tag{68}\)

여기서 \(\tau\)는 사용자가 제어할 수 있는 스텝 크기이고, \(\mathbf{x}_{0}\)는 백색 잡음이다.

여러분은 궁금할지도 모릅니다. 이 신비한 방정식은 도대체 무엇에 관한 것일까요? 여기 짧고 빠른 답변이 있습니다. 끝에서 노이즈 용어 \(\sqrt{2\tau}\mathbf{z}\)를 무시하면 Eqn(68)의 랑게빈 역학 방정식은 말 그대로 **구배 하강'입니다. 하강 방향 \(\nabla_{\mathbf{x}}\log p(\mathbf{x})\)는 \(\mathbf{x}_{t}\)가 분포 \(p(\mathbf{x})\)에 수렴하도록 신중하게 선택된다. Langevin 역학 방정식이 무엇인지 설명하지 않고 10분 동안 중얼거리는 유튜브 동영상을 보면 다음과 같이 부드럽게 말할 수 있습니다.

잡음 용어가 없으면 랭뱅 역학은 _is_ **gradient descent** 입니다.

분포 \(p(\mathbf{x})\)를 고려합니다. 이 분포의 형태가 정의되고 모형 모수가 정의되자마자 고정된다. 예를 들어 가우시안을 선택하면 평균과 분산을 지정하면 가우시안의 모양과 위치가 고정된다. 값 \(p(\mathbf{x})\)는 데이터 포인트에서 평가된 확률 밀도 \(\mathbf{x}\)에 불과하다. 따라서 하나의 \(\mathbf{x}\)에서 다른 \(\mathbf{x}^{\prime}\)로 이동하면 우리는 하나의 값 \(p(\mathbf{x})\)에서 다른 값 \(p(\mathbf{x}^{\prime})\)으로 이동하게 된다. 가우시안 기본 모양은 변경되지 않습니다.

우리가 \(\mathbb{R}^{d}\)의 임의의 위치로 시작한다고 가정하자. 우리는 그것을 분포의 정점(들)으로 옮기고 싶다. 피크는 확률이 가장 높은 곳이기 때문에 특별한 장소이다. 따라서 표본 \(\mathbf{x}\)이 분포 \(p(\mathbf{x})\)에서 추출된다고 하면, \(\mathbf{x}\)에 대한 "최적의" 위치는 \(p(\mathbf{x})\)가 최대가 된다. \(p(\mathbf{x})\)가 다수의 국소 최소값을 갖는다면, 이들 중 어느 하나라도 괜찮을 것이다. 따라서 자연스럽게 샘플링의 목표는 최적화를 해결하는 것과 동일합니다.

\[\mathbf{x}^{*}=\underset{\mathbf{x}}{\operatorname{argmax}}\ \log p(\mathbf{x}).\]

이것이 최대우도 추정이 아니라는 점을 다시 강조합니다. 최대우도에서 데이터 점 \(\mathbf{x}\)은 고정되지만 모델 매개변수는 변경됩니다. 여기서, 모델 파라미터는 고정되어 있지만 데이터 포인트는 변화하고 있다. 아래 표는 차이점을 요약한 것이다.

\begin{tabular}{c l l} \hline Problem & Sampling & Maximum Likelihood \\ Optimization target & A sample \(\mathbf{x}\) & Model parameter \(\boldsymbol{\theta}\) \\ Formulation & \(\mathbf{x}^{*}=\underset{\mathbf{x}}{\operatorname{argmax}}\ \log p(\mathbf{x};\boldsymbol{\theta})\) & \(\boldsymbol{\theta}^{*}=\underset{\boldsymbol{\theta}}{\operatorname{argmax}}\ \log p(\mathbf{x};\boldsymbol{\theta})\) \\ \hline \end{tabular}

최적화는 여러 가지 방법으로 해결할 수 있다. 가장 저렴한 방법은 물론 경사 하강이다. \(\log p(\mathbf{x})\)에 대해, 우리는 경사 하강 단계가

\[\mathbf{x}_{t+1}=\mathbf{x}_{t}+\tau\nabla_{\mathbf{x}}\log p(\mathbf{x}_{t}),\]

\(\mathbf{x}_{t+1}=\mathbf{x}_{t}+\tau\nabla_{\mathbf{x}}\log p(\mathbf{x}_{t})\), 여기서 \(\nabla_{\mathbf{x}}\log p(\mathbf{x}_{t})\)는 \(\mathbf{x}_{t}\)에서 평가된 \(\log p(\mathbf{x})\)의 기울기를 나타내고, \(\tau\)는 스텝 크기이다. 여기서 우리는 최대화 문제를 풀기 때문에 일반적인 "\(-\)" 대신에 "\(+\)"를 사용한다.

**예제**. 가우시안 분포 \(p(x)=\mathcal{N}(x\,|\,\mu,\sigma^{2})\)를 고려하면, 우리는 Langevin 동역학 방정식이란 것을 쉽게 보여줄 수 있다.

\[x_{t+1} =x_{t}+\tau\cdot\nabla_{x}\log\left\{\frac{1}{\sqrt{2\pi\sigma^{2}}}e^{-\frac{(\sigma-\mu)^{2}}{2\sigma^{2}}}\right\}+\sqrt{2\tau}z\] \[=x_{t}-\tau\cdot\frac{x_{t}-\mu}{\sigma^{2}}+\sqrt{2\tau}z, z\sim\mathcal{N}(0,1)\]

**예제**. 가우스 혼합물 \(p(x)=\pi_{1}\mathcal{N}(x\,|\,\mu_{1},\sigma_{1}^{2})+\pi_{2}\mathcal{N}(x\,|\,\mu_{2},\sigma_{2}^{2})\를 고려한다. 우리는 \(\nabla_{x}\log p(x)\)를 수치적으로 계산할 수 있다. 시연을 위해 \(\pi_{1}=0.6\) \ (\mu_{1}=2\), \(\sigma_{1}=0.5\), \(\pi_{2}=0.4\), \(\mu_{2}=-2\), \(\sigma_{2}=0.2\). 우리는 \(x_{0}=0\)를 초기화한다. 우리는 \(\tau=0.05\)을 선택한다. 우리는 \(T=500\) 시간 동안 위의 기울기 하강 반복을 실행하고, \(t=1,\dots,T\)에 대한 값 \(p(x_{t})\)의 궤적을 플로팅한다. 아래 그림에서 볼 수 있듯이, 시퀀스 \(\{x_{1},x_{2},\dots,x_{T}\}\)는 단순히 가우시안 모양을 따라 피크 중 하나로 올라간다.

더 흥미로운 것은 우리가 잡음 용어를 추가할 때이다. 수열 \(x_{t}\)은 피크에 착지하는 대신, 피크 주위를 이동하고 피크 근처 어딘가에서 마무리한다. 우리가 정점에 가까울수록, 우리는 거기서 멈출 확률이 높아진다.

도 17은 샘플 궤적에 대한 흥미로운 설명을 도시한다. 임의의 위치에서 시작하여, 데이터 포인트 \(\mathbf{x}_{t}\)는 랭뱅 동역학 방정식에 따라 랜덤 워크를 수행할 것이다. 임의 보행의 방향이 완전히 임의적인 것은 아니다. 모든 단계에서 일정 수준의 무작위성이 있는 동안 미리 정의된 드리프트가 있다. 드리프트는 \(\nabla_{\mathbf{x}}\log p(\mathbf{x})\)에 의해 결정되며, 여기서 랜덤성은 \(\mathbf{z}\)에서 나온다.

위의 예에서 볼 수 있듯이 노이즈 항의 추가는 실제로 기울기 하강을 **확률적 기울기 하강** 으로 변경합니다. 결정론적 최적을 위해 촬영하는 대신 확률적

도 17: Langevin 다이내믹스를 이용한 샘플 진화의 궤적. 우리는 더 나은 시각화를 위해 가우시안 혼합물의 두 가지 모드를 다른 색상으로 채색했다. 여기서의 설정은 스텝 사이즈가 \(\tau=0.001\)인 것을 제외하고는 위의 예와 동일하다.

기울어진 하강이 언덕을 마구잡이로 올라간다. 우리는 일정한 스텝 크기 \(\sqrt{2\tau}\)를 사용하기 때문에, 최종 해는 단지 피크 주변에서 진동할 것이다. 그래서 우리는 Langevin 동역학 방정식을 다음과 같이 요약할 수 있다.

\[\boxed{Langevin dynamics _is_\textbf{stochastic gradient descent}.}\]

그런데 왜 우리는 기울기 하강 대신 확률적 기울기 하강을 하려는 것일까? 핵심은 우리가 최적화 문제를 푸는 데 관심이 없다는 것이다. 대신 배포에서 _샘플링_ 에 더 관심이 있습니다. 랜덤 노이즈를 경사 하강 단계에 도입하여 목적 함수의 궤적을 따라가는 표본을 무작위로 선택하고 목적 함수가 있는 곳에 머무르지 않는다. 우리가 정상에 가까우면 좌우로 약간 움직일 것이다. 만약 우리가 피크에서 멀리 떨어져 있다면, 기울기 방향은 우리를 피크 쪽으로 끌어당길 것이다. 피크 주위의 곡률이 날카롭다면, 우리는 대부분의 정상 상태점 \(\textbf{x}_{T}\)을 거기에 집중시킬 것이다. 봉우리 주변의 곡률이 평평하다면 우리는 주변에 퍼질 것이다. 따라서, 균등하게 분포된 위치에서 확률적 경사 하강 알고리즘을 반복적으로 초기화함으로써, 우리는 결국 우리가 지정한 분포를 따를 샘플들을 수집할 것이다.

\[\boxed{\textbf{Example}. 가우스 혼합물 \(p(x)=\pi_{1}\mathcal{N}(x\,|\,\mu_{1},\sigma_{1}^{2})+\pi_{2}\mathcal{N}(x\,|\,\mu_{2},\sigma_{2}^{2})\를 고려한다. 우리는 \(\nabla_{x}\log p(x)\)를 수치적으로 계산할 수 있다. 시연을 위해 \(\pi_{1}=0.6\) \ (\mu_{1}=2\), \(\sigma_{1}=0.5\), \(\pi_{2}=0.4\), \(\mu_{2}=-2\), \(\sigma_{2}=0.2\). 우리는 \(M=10000\) 균일하게 분포된 샘플 \(x_{0}\sim\text{Uniform}[-3,3]\)을 초기화한다고 가정하자. 우리는 \(t=100\) 단계에 대해 Langevin 업데이트를 실행합니다. 생성된 샘플의 히스토그램은 아래 그림에 나와 있다.

\[\boxed{\textbf{Remark: Origin of Langevin Dynamics}. 랭뱅 역학이라는 이름은 물론 우리의 "해킹" 관점에서 비롯된 것이 아니다. 물리학으로 시작하죠 힘 **F** 를 질량 \(m\) 및 속도 \(\textbf{v}(t)\)와 관련시키는 기본 뉴턴 방정식을 고려하십시오. 뉴턴의 두 번째 법칙은

\[\underbrace{\textbf{F}}_{\text{force}}=\underbrace{m}_{\text{mass}}\cdot \underbrace{\frac{d\textbf{v}(t)}{dt}}_{\text{acceleration}}. \tag{69}\]

주어진 힘 **F**, 우리는 또한 그것이 퍼텐셜 에너지 \(U(\textbf{x})\) via와 관련이 있음을 알고 있다.

\[\underbrace{\textbf{F}}_{\text{force}}=\nabla_{\textbf{x}}\underbrace{U( \textbf{x})}_{\text{energy}}. \tag{70}\]

랭뱅 역학의 무작위성은 브라운 운동에서 비롯된다. 분자 한 봉지가 돌아다니고 있다고 상상해 보세요. 이들의 모션은 브라운 모션 모델에 따라 기술될 수 있다:

\[\frac{d\textbf{v}(t)}{dt}=-\frac{\lambda}{m}\textbf{v}(t)+\frac{1}{m}\mathbf{ \eta},\qquad\text{where}\ \mathbf{\eta}\sim\mathcal{N}(0,\sigma^{2}\textbf{I}). \tag{71}\

따라서 Eqn(71)을 Eqn(69)에 대입하여 Eqn(70)과 동일시하면 다음과 같다.

\[-\nabla_{\textbf{x}}U(\textbf{x})=-\lambda\textbf{v}(t)+\mathbf{\eta}\quad \Rightarrow\quad\textbf{v}(t)=-\frac{1}{\lambda}\nabla_{\textbf{x}}U(\textbf{ x})+\frac{1}{\lambda}\mathbf{\eta}}.\] 이는 등가적으로 다음과 같이 표기할 수 있다.

\[\frac{d\mathbff{x}}{dt}=-\frac{1}{\lambda}\nabla_{\mathbff{x}}U(\mathbf{x})+\frac{ \sigma}{\lambda}\mathbf{z},\qquad\text{where}\;\;\mathbff{z}\sim\mathcal{N}(0, \mathbf{I}). \tag{72}\}

우리가 \(\tau=\frac{dt}{\lambda}\)를 두고 위의 미분방정식을 이산화하면, 우리는 얻을 것이다.

\[\mathbf{x}_{t+1}=\mathbf{x}_{t}-\tau\nabla_{\mathbf{x}}U(\mathbf{x}_{t})+ \sigma\tau\mathbf{z}_{t}. \tag{73}\]

따라서 에너지 잠재력을 식별하는 것은 여전히 남아 있다. 우리의 확률분포함수 \(p(\mathbf{x})\)에 대한 매우 합리적인 (그리고 게으른) 선택은 형태를 갖는 볼츠만 분포이다.

\[p(\mathbf{x})=\frac{1}{Z}\exp\left\{-U(\mathbf{x})\right\}.\]

따라서, 즉시...

\[\nabla_{\mathbff{x}}\log p(\mathbf{x})=\nabla_{\mathbff{x}}\Big{\{}-U(\mathbf{x})-\log Z\Big{\}}=-\nabla_{\mathbff{x}}U(\mathbf{x}). \tag{74}\

Eqn(74)을 Eqn(73)에 대입하면 \(\mathbf{x}_{t+1}=\mathbf{x}_{t}+\tau\nabla_{\mathbf{x}}\log p(\mathbf{x})+ \sigma\tau\mathbf{z}\). 마지막으로, 우리가 _choose_\(\sigma=\sqrt{2/\tau}\)(특별한 이유 없이)를 선택하면, 우리는 얻을 것이다.

\[\mathbf{x}_{t+1}=\mathbf{x}_{t}+\tau\nabla_{\mathbf{x}}\log p(\mathbf{x}_{t})+\sqrt{2\tau}\mathbf{z}_{t}. \tag{75}\]

### (Stein's) 점수 함수

Langevin 동역학 방정식의 두 번째 성분은 기울기 \(\nabla_{\mathbf{x}}\log p(\mathbf{x})\)이다. 다음과 같이 표시되는 **Stein's score 함수** 라는 공식 이름이 있습니다.

\[\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x})\stackrel{{\text{ def}}}}{{=}}\nabla_{\mathbf{x}}\log p_{\boldsymbol{\theta}}(\mathbf{x}). \tag{76}\]

스타인의 점수 함수와 다음과 같이 정의된 **일반 점수 함수** 를 혼동하지 않도록 주의해야 합니다.

\[\mathbf{s}_{\mathbf{x}}(\boldsymbol{\theta})\stackrel{{\text{ def}}}}{{=}}\nabla_{\boldsymbol{\theta}}\log p_{\boldsymbol{\theta}}(\mathbf{x}). \tag{77}\]

일반 점수 함수는 로그 우도의 기울기(wrt \(\boldsymbol{\theta}\))이다. 이와는 대조적으로, 스타인의 점수 함수는 데이터 포인트 \(\mathbf{x}\)의 구배 wrt이다. 최대 우도 추정은 보통 점수 함수를 사용하는 반면 랭뱅 역학은 스타인의 점수 함수를 사용한다. 그러나 확산 문헌의 대부분의 사람들은 스타인의 점수 함수를 점수 함수로 부르므로 우리는 이 문화를 따른다.

랭뱅 역학에서 "점수 함수"는 스타인의 점수 함수로 더 정확하게 알려져 있다.

점수 함수를 이해하는 방법은 데이터 \(\mathbf{x}\)에 대한 기울기임을 기억하는 것이다. 임의의 고차원 분포 \(p(\mathbf{x})\), 그래디언트는 우리에게 벡터장을 줄 것이다

\[\nabla_{\mathbff{x}}\log p(\mathbf{x})=\text{a 벡터 필드}=\left[\frac{ \partial\log p(\mathbf{x})}{\partial x},\;\;\frac{\partial\log p(\mathbf{x})} {\partial y}\right]^{T} \tag{78}\]

두 가지 예를 생각해 봅시다.

**예제**. 만약 \(p(x)\)가 \(p(x)=\frac{1}{\sqrt{2\pi\sigma^{2}}}e^{-\frac{(x-\mu)^{2}}{2\sigma^{2}}}}}\인 가우시안이라면,

\[s(x)=\nabla_{x}\log p(x)=-\frac{(x-\mu)}{\sigma^{2}}.\]

[MISSING_PAGE_FAIL:34]

### 점수 매칭 기술

Langevin 역학에서 가장 어려운 문제는 \(p(\mathbf{x})\)에 접근할 수 없기 때문에 \(\nabla_{\mathbf{x}}p(\mathbf{x})\)를 구하는 방법이다. (Stein's) 점수 함수의 정의를 떠올려 보자.

\[\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x})\stackrel{{\mathrm{def}}}{{=}}}\nabla_{\mathbf{x}}p(\mathbf{x}), \tag{79}\]

여기서는 \(\mathbf{s}_{\boldsymbol{\theta}}\)가 네트워크를 통해 구현될 것임을 나타내기 위해 첨자 \(\boldsymbol{\theta}\)를 넣는다. 위 방정식의 오른쪽은 알려져 있지 않기 때문에, 우리는 그것을 근사화하기 위한 몇 가지 값싸고 더러운 방법이 필요하다. 이 절에서는 두 가지 근사치에 대해 간략하게 논의한다.

**명시적 점수 일치** 데이터세트 \(\mathcal{X}=\{\mathbf{x}_{1},\ldots,\mathbf{x}_{M}\}\)가 주어졌다고 가정하자. 사람들이 생각해 낸 해는 분포를 정의하여 고전적인 커널 밀도 추정을 고려하는 것이다.

\[q(\mathbf{x})=\frac{1}{M}\sum_{m=1}^{M}\frac{1}{h}K\left(\frac{\mathbf{x}- \mathbf{x}_{m}}{h}\right), \tag{80}\]

여기서 \(h\)는 커널 함수 \(K(\cdot)\)에 대한 일부 하이퍼파라미터이고 \(\mathbf{x}_{m}\)는 훈련 세트에서 \(m\) 번째 샘플이다. 그림 20은 커널 밀도 추정의 개념을 보여준다. 왼쪽 그림에서 우리는 서로 다른 데이터 포인트 \(\mathbf{x}_{m}\)를 중심으로 여러 개의 커널 \(K(\cdot)\)을 보여준다. 이 모든 개별 커널의 합은 전체 커널 밀도 추정 \(q(\mathbf{x})\)를 제공한다. 오른쪽은 실제 히스토그램과 해당 커널 밀도 추정치를 보여준다. 우리는 \(q(\mathbf{x})\)가 기껏해야 알려져 있지 않은 실제 데이터 분포 \(p(\mathbf{x})\)에 근사한다는 점을 지적한다.

\(q(\mathbf{x})\)는 접근할 수 없는 \(p(\mathbf{x})\)에 근사하므로, \(q(\mathbf{x})\)를 기반으로 \(\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x})\)를 학습할 수 있다. 이것은 네트워크를 훈련시키는 데 사용될 수 있는 손실 함수의 다음과 같은 정의로 이어진다.

**명시적 점수 일치** 손실은 다음과 같습니다.

\[J_{\mathrm{ESM}}(\boldsymbol{\theta})\stackrel{{\mathrm{def}}}{{= }}\mathbb{E}_{q(\mathbf{x})}\|\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x})- \nabla_{\mathbff{x}}\log q(\mathbf{x})\|^{2} \tag{81}\]

커널 밀도 추정을 대입하면 손실이 있음을 알 수 있다.

\[J_{\mathrm{ESM}}(\boldsymbol{\theta}) \stackrel{{\mathrm{def}}}}{{=}}\mathbb{E}_{q(\mathbf{ x})}\|\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x})-\nabla_{\mathbf{x}_{m}_{h}\right)\|^{2}\left[\frac{1}{M}\sum_{m=1}^{M}\frac{1}{m}\sum_{m=1}^{M}\theta}}(\mathbf{x})-\nabla_{\mathbf{x}_{m}_{h}\log q(\mathbf{x})\|^{2}\frac{1}{M}\sum_{m=1}^{M}\frac{1}{m}\m}\boldsymbol{\theta}}(\mathbf{x

그래서 우리는 네트워크를 훈련하는 데 사용할 수 있는 손실 함수를 유도했다. 네트워크 \(\mathbf{s}_{\boldsymbol{\theta}}\)를 훈련시키면, 우리는 그것을 랑게빈 역학 방정식으로 대체하여 재귀를 구할 수 있다:

\[\mathbf{x}_{t+1}=\mathbf{x}_{t}+\tau\mathbf{s}_{\boldsymbol{\theta}}(\mathbf{x}_{t})+\sqrt{2\tau}\mathbf{z}. \tag{83}\]

그림 20: 커널 밀도 추정의 그림.

명시적 점수 매칭의 문제는 커널 밀도 추정이 참 분포의 상당히 열악한 비모수 추정이라는 것이다. 특히 표본 수가 제한적이고 표본이 고차원 공간에 존재할 경우 커널 밀도 추정 성능이 떨어질 수 있다.

**점수 일치 제거** 명시적 점수 매칭의 잠재적인 단점들을 고려하여, 이제 우리는 디노이징 점수 매칭(DSM)으로 알려진 보다 대중적인 점수 매칭을 소개한다. DSM에서 손실 함수는 다음과 같이 정의된다.

\[J_{\text{DSM}}(\mathbf{\theta})\stackrel{{\text{def}}}{{=}}\mathbb{E}_{q(\mathbf{x},\mathbf{x}^{\prime})}\left[\frac{1}{2}\left\|\mathbf{s}_{\mathbf{ \theta}}}(\mathbf{x})-\nabla_{\mathbff{x}}q(\mathbf{x}|\mathbf{x}^{\prime}) \right\|^{2}\right] \tag{84}\

여기서 중요한 차이점은 분포 \(q(\mathbf{x})\)를 조건부 분포 \(q(\mathbf{x}|\mathbf{x}^{\prime})\)로 대체한다는 것이다. 전자는 예를 들어 커널 밀도 추정을 통한 근사치를 필요로 하는 반면 후자는 그렇지 않다. 예를 들어 설명하면 다음과 같다.

\(\mathbf{x}|\mathbf{x}^{\prime})=\mathcal{N}(\mathbf{x}\mid\mathbff{x}^{\prime },\sigma^{2})\인 특수한 경우에는 \(\mathbf{x}=\mathbf{x}^{\prime}+\sigma\mathbf{z}\)로 할 수 있다. 이것이 우리에게 줄 것입니다

\[\nabla_{\mathbf{x}}\log q(\mathbf{x}|\mathbf{x}}\log\frac{1}{(\sqrt{2\pi\sigma^{2}})^{d}} \exp\left\{-\frac{\|\mathbf{x}-\mathbf{x}^{\prime}\|^{2}}{2\sigma^{2}}\right\}\] \[=\nabla_{\mathbf{x}}\left\{-\frac{\|\mathbf{x}-\mathbf{x}^{\prime}\|^{2}}{2\sigma^{2}}}\log(\sqrt{2\pi\sigma^{2}})^{d}\right\}\] \[=-\frac{\mathbff{x}-\mathbf{x}^{\prime}}{\sigma^{2}}}=-\frac{ \mathbf{z}}{\sigma^{2}}

그 결과, 상기 디노이징 스코어 매칭의 손실 함수는

\[J_{\text{DSM}}_{q(\mathbf{x },\mathbf{x}^{\prime})}\left[\frac{1}{2}\left\|\mathbff{s}_{\mathbf{\theta}}( \mathbf{x}},\mathbf{s}_{\mathbf{\theta}}( \mathbf{x}}))-\nabla_{\mathbf{x}}q(\mathbf{x}}_{q(\mathbf{x}^{\prime})\right\|^{2}\right]\] \[=\mathbb{E}_{q(\mathbf{x}^{\prime})}\left[\frac{1}{2}\left\|\mathbf{s}_{\mathbf{\theta}}(\mathbf{x}+\sigma\mathbf{z})+\frac{\mathbf{ z}}{\sigma^{2}}\right\]\

더미 변수 \(\mathbf{x}^{\prime}\)를 \(\mathbf{x}\)로 대체하고, 훈련 데이터 셋이 주어졌을 때 \(q(\mathbf{x})\)에서 샘플링을 \(p(\mathbf{x})\)에서 샘플링으로 대체할 수 있다면 다음과 같은 결론을 내릴 수 있다.

**디노이징 점수 일치**에는 다음과 같이 정의된 손실 함수가 있습니다.

\[J_{\text{DSM}}(\mathbf{\theta})=\mathbb{E}_{p(\mathbf{x})}\left[\frac{1}{2}\left\| \mathbf{s}_{\mathbf{\theta}}(\mathbf{x}+\sigma\mathbf{z})+\frac{\mathbf{z}}{\sigma ^{2}}\right\|^{2}\right] \tag{85}\]

Eqn(85)의 아름다움은 그것이 매우 해석 가능하다는 것이다. 수량 \(\mathbf{x}+\sigma\mathbf{z}\)은 깨끗한 이미지에 노이즈 \(\sigma\mathbf{z}\)를 효과적으로 추가한다 \(\mathbf{x}\). 점수함수 \(\mathbf{s}_{\mathbf{\theta}}\)는 이 잡음이 있는 영상을 촬영하여 잡음 \(\frac{\mathbf{z}}{\sigma^{2}}\)을 예측한다. 노이즈를 예측하는 것은 노이즈 제거와 동일하며, 이는 노이즈 제거된 이미지와 예측된 노이즈가 노이즈 관찰을 제공하기 때문이다. 따라서, Eqn(85)는 _디노이징_ 단계이다. 도 21은 점수 함수 \(\mathbf{s}_{\mathbf{\theta}}(\mathbf{x})\)의 트레이닝 절차를 예시한다.

네트워크 \(\mathbf{s}_{\mathbf{\theta}}\)는 잡음을 추정하기 위해 훈련된다.

그림 21: 디노이징 스코어 매칭을 위한 \(\mathbf{s}_{\mathbf{\theta}}\)의 트레이닝. 네트워크 \(\mathbf{s}_{\mathbf{\theta}}\)는 잡음을 추정하기 위해 훈련된다.

**트레이닝** 단계는 다음과 같이 간단히 설명할 수 있습니다. 교육 데이터 세트 \(\{\mathbf{x}^{(\ell)}\}_{\ell=1}^{L}\), 네트워크 \(\mathbf{\theta}\)를 목표로 훈련합니다.

\qquad\text{where}\ \ \mathbf{z}^{(\ell)}\sim\mathcal{N}(0,\mathbf{I}). \tag{86}\

여기서 더 큰 질문은 왜 Eqn(84)이 애초에 말이 되는가이다. 이는 명시적 스코어 매칭 손실과 디노이징 스코어 매칭 손실 사이의 동등성을 통해 답변될 필요가 있다.

**정리** [Vincent [9]] 최대 상수 \(C\)에 대해 변수 \(\mathbf{\theta}\)에 독립적입니다.

\[J_{\text{DSM}}(\mathbf{\theta})=J_{\text{ESM}}(\mathbf{\theta})+C. \tag{87}\]

명시적 점수 매칭과 노이즈 제거 점수 매칭 사이의 동등성은 주요 발견이다. 아래의 증명은 빈센트 2011의 원작을 바탕으로 한다.

**Eqn의 증명** (87) 다음과 같이 표시되는 명시적 점수 일치 손실 함수부터 시작합니다.

\mathbf{x}) \[J_{\text{ESM}}(\mathbf{\theta}) =\mathbb{E}_{q(\mathbf{x})}\left[\frac{1}{2}\left\|\mathbf{s}_{ \mathbf{\theta}}(\mathbf{x})-\nabla_{\mathbf{s}_{ \mathbf{\theta}}(\mathbf{x})\right\|^{2}\right]\] \[=\mathbb{E}_{q(\mathbf{x})}\Big{[}\frac{1}{2}\left\|\mathbf{s}_{ \mathbf{\theta}}(\mathbf{x})\right\|^{2}-\mathbff{s}_{\mathbf{\theta}}(\mathbf{x})^{T }\nabla_{\mathbf{x}}\log q(\mathbf

두 번째 용어를 확대해보겠습니다. 보여줄 수 있어

\mathbf{x})}\left[\mathbf{s}_{\mathbf{\theta}}(\mathbf{x})^{T}\nabla_{\mathbf{x}}\log q(\mathbf{x})\right] \[=\int\left(\mathbf{s}_{\mathbf{\theta}}(\mathbf{x})^{T}\nabla_{ \mathbf{x}}q(\mathbf{x})\right)q(\mathbf{x})d\mathbf{x},\ \ \text{(expectation)}\] \[=\int\mathbf{s}_{\mathbf{\theta}}(\mathbf{x})d\mathbf{x}}(\mathbf{x})\right)q(\mathbf{x})d\mathbf{x},\ \ \text{(gradient)}\] \[=\int\mathbf{s

다음으로, \(q(\mathbf{x})=\int q(\mathbf{x}^{\prime})q(\mathbf{x}|\mathbf{x}^{\prime})d \mathbf{x}^{\prime}\를 리콜하여 컨디셔닝을 고려한다. 이것이 우리에게 줄 것입니다

[=\int\mathbf{s}_{\mathbff{\theta}}(\mathbf{x}^{\prime})^{T}\left(\int\mathbf{s}_{\mathbff{\theta}}(\mathbf{x})^{T}\left(\int q(\mathbf{x}^{\prime})\mathbf{x}}q(\mathbf{x}|\mathbf{x}^{\prime})\nabla_{\mathbff{x}}q(\mathbf{x}|\mathbf{x}^{\prime}) \times\frac{q(\mathbf{x}|\mathbf{x}^{\prime})}{q(\mathbf{x}|\mathbf{x}^{\prime})}d\mathbf{x} \text{(move gradient)}\] \[=\int\mathbf{s}_{\mathbff{s}_{\mathbf 따라서 이 결과를 ESM의 정의로 다시 대입하면 다음과 같은 결과를 얻을 수 있다.

\[J_{\text{ESM}}(\mathbf{\theta})=\mathbb{E}_{q(\mathbf{x})}\Big{[}\frac{1}{2}\left\| \mathbf{s}_{\mathbf{\theta}}(\mathbf{x})\right\|^{2}\Big{]}-\mathbb{E}_{q(\mathbf{x },\mathbf{x}^{\prime})}\left[\mathbf{s}_{\mathbf{\theta}}(\mathbf{x})^{T}\nabla_{ \mathbf{x}}\log q(\mathbf{x}|\mathbf{x}^{\prime})\right]+C_{1}}.\]

이를 DSM의 정의와 비교하면 다음과 같은 사실을 알 수 있다.

\mathbf{s}_{mathbf{\theta}}(\mathbf{s}_{mathbf{\theta}}(\mathbf{x})\mathbf{s}_{mathbf{\theta}}(\mathbf{x})\mathbf{s}_{mathbf{\theta}}(\mathbf{x})\mathbf{s}_{mathbf{\theta}}(\mathbf{x})\mathbf{s}_{mathbf{\theta}}(\mathbf{x})\mathbf{s}_{mathbf{\theta}}(\mathbf{x})\mathbf{s}_{mathbf{\theta}}(\mathbf{x})\mathbf{s}_{mathbf{\theta}}(\mathbf{x})\mathbf{s}_{mathbf{\theta}}(\mathbf{x})\mathbf{s}_{mathbf{x}

따라서, 우리는 결론적으로

\[J_{\text{DSM}}(\mathbf{\theta})=J_{\text{ESM}}(\mathbf{\theta})-C_{1}+C_{2}.\]

**추론** 의 경우 점수 추정기 \(\mathbf{s}_{\mathbf{\theta}}\)를 이미 학습했다고 가정합니다. 이미지를 생성하기 위해 \(t=1,\ldots,T\)에 대해 다음과 같은 절차를 수행한다:

\[\mathbf{x}_{t+1}=\mathbf{x}_{t}+\tau\mathbf{s}_{\mathbf{\theta}}(\mathbf{x}_{t})+ \sqrt{2\tau}\mathbf{z}_{t},\qquad\text{where}\quad\mathbf{z}_{t}\sim\mathcal{ N}(0,\mathbf{I}). \tag{88}\]

### 축하합니다! 우린 끝났어 이것은 모두 점수 기반 생성 모델에 관한 것입니다.

점수 매칭에 대한 추가 판독은 빈센트의 기술 보고서[9]부터 시작해야 한다. 최근 문헌에서 매우 인기 있는 논문은 Song과 Ermon[15], 그들의 후속 작업[16], [8]이다. 실제로, 스코어 함수를 트레이닝하는 것은 노이즈 레벨들의 시퀀스를 고려함으로써 노이즈 스케줄을 필요로 한다. 다음 절에서 SDE를 폭발하는 분산을 설명할 때 이에 대해 간략히 논의할 것이다.

확률적 미분방정식(SDE)

지금까지 우리는 DDPM과 SMLD 관점을 통해 확산 반복을 유도했다. 이 절에서는 미분방정식의 렌즈를 통해 세 번째 관점을 소개하고자 한다. 왜 우리의 반복적인 계획들이 갑자기 복잡한 미분 방정식이 되는지는 분명하지 않을 수 있다. 따라서 방정식을 도출하기 전에 미분 방정식이 우리와 어떻게 관련될 수 있는지에 대해 간략하게 논의해야 한다.

### Motivating Examples

**예제 1. 단순 1차 ODE**. 재귀에 의해 정의된 반복을 갖는 이산 시간 알고리즘이 주어진다고 상상해 보자:

\[\mathbf{x}_{i}=\left(1-\frac{\beta\Delta t}{2}\right)\mathbf{x}_{i-1},\qquad \text{for}\;\;i=1,2,\ldots,N, \tag{89}\]

초매개 변수 \(\beta\) 및 단계 크기 매개 변수 \(\Delta t\)의 경우입니다. 이 재귀는 복잡하지 않습니다. \(\mathbf{x}_{i-1}\), \(\mathbf{x}_{i}\)를 업데이트하고 반환합니다.

연속시간함수 \(\mathbf{x}_{i}=\mathbf{x}(\frac{i}{N})\), \(\Delta t=\frac{1}{N}\), \(t\in\{0,\frac{1}{N},\ldots,\frac{N-1}{N}\)의 이산화 기법을 가정하면, 우리는 다음과 같이 재기입할 수 있다.

\[\mathbf{x}(t+\Delta t)=\left(1-\frac{\beta\Delta t}{2}\right)\mathbf{x}(t).\]

조건을 다시 조정하면

\[\frac{\mathbf{x}(t+\Delta t)-\mathbf{x}(t)}{\Delta t}=-\frac{\beta}{2} \mathbf{x}(t),\]

여기서, \(\Delta t\to 0\일 때 한계에서, 우리는 이산 방정식을 상미분 방정식(ODE)으로 쓸 수 있다)

\[\frac{d\mathbf{x}(t)}{dt}=-\frac{\beta}{2}\mathbf{x}(t). \tag{90}\]

그뿐만 아니라, 우리는 해가 주어지는 ODE에 대한 분석적 해를 풀 수 있다.

\[\mathbf{x}(t)=e^{-\frac{\beta}{2}t}. \tag{91}\]

만약 당신이 우리를 믿지 않는다면, Eqn(91)을 Eqn(90)으로 대체하면 당신은 평등이 성립한다는 것을 보여줄 수 있다.

ODE의 힘은 그것이 우리에게 분석적인 해결책을 제공한다는 것이다. 반복 계획(수백에서 수천 번의 반복이 소요됨)에 의존하는 대신 분석 솔루션은 _any_ 시간 \(t\)에서 솔루션의 동작을 정확하게 알려줍니다. 이 사실을 증명하기 위해, 우리는 알고리즘으로 정의된 해 \(\mathbf{x}_{1},\mathbf{x}_{2},\ldots,\mathbf{x}_{i},\ldots,\mathbf{x}_{N}\)의 궤적을 아래 그림에서 보여준다. 여기서, \(\Delta t=0.1\)을 선택한다. 같은 그림에서 우리는 임의의 \(t\)에 대해 연속시간 해 \(\mathbf{x}(t)=\exp\{-\beta t/2\}\)를 직접 그린다. 보시다시피, 해석적 해는 반복 스킴에 의해 예측된 궤적과 정확히 동일하다.

이 동기 부여 사례에서 우리가 관찰하는 것은 두 가지 흥미로운 사실입니다.

* 이산 시간 반복 방식은 연속 시간 상미분 방정식으로 작성될 수 있다.

[MISSING_PAGE_FAIL:40]

우리는 \(t\gets t+\Delta t\)를 가정하여 \(\mathbf{x}\)를 \(\mathbf{x}+\Delta\mathbf{x}\)로 업데이트하기 때문에 이것을 **정방향** 방정식으로 부른다.

이제 일련의 반복 \(i=N,N-1,\ldots,2,1\)을 고려하십시오. 반복의 진행이 Eqn(95)를 따른다고 하면 시간 역전 반복은 다음과 같다.

\[\text{(역)}\qquad\qquad\qquad\qquad\qquad\mathbf{x}_{i-1}= \mathbf{x}_{i}-\Delta\mathbf{x}_{i} \approx\mathbf{x}_{i}+d\mathbf{x}\] \[=\mathbf{x}_{i}+\beta\nabla f(\mathbf{x}_{i})dt\] \[\approx\mathbf{x}_{i}+\beta_{i}\nabla f(\mathbf{x}_{i})\]\]\

진행 방향을 반전할 때 부호 변화에 주목하라. 이를 **역** 방정식이라고 합니다.

### SDE의 순방향 및 역방향 반복

확산에 대한 미분 방정식의 개념은 위의 경사 하강 알고리즘과 그리 멀지 않다. 경사 하강 알고리즘에 잡음항 \(\mathbf{z}_{t}\sim\mathcal{N}(0,\mathbf{I})\)을 도입하면 ODE는 확률적 미분방정식(SDE)이 된다. 이를 보기 위해 우리는 \(\mathbf{x}(t)\)를 \(0\leq t\leq 1\)에 대한 연속 함수로 정의함으로써 동일한 이산화 방식을 따른다. 간격 \([0,1]\)이 시퀀스 \(\{\frac{i}{N}\,|\,i=0,\ldots,N-1\}\)로 분할될 수 있도록 간격에 \(N\) 단계가 있다고 가정하자. 이산화를 통해 \(\mathbf{x}_{i}=\mathbf{x}(\frac{i}{N})\)와 \(\mathbf{x}_{i-1}=\mathbf{x}(\frac{i-1}{N})\를 얻을 수 있다. 간격 단계는 \(\Delta t=\frac{1}{N}\)이고, 모든 \(t\)의 집합은 \(t\in\{0,\frac{1}{N},\ldots,\frac{N-1}{N}\}\)이다. 이러한 정의를 사용하여 쓸 수 있습니다.

\[\mathbf{x}_{i} =\mathbf{x}_{i-1}-\tau\nabla f(\mathbf{x}_{i-1})+\mathbf{z}_{i-1}\] \[\implies\quad\mathbf{x}(t+\Delta t) =\mathbf{x}(t)-\tau\nabla f(\mathbf{x}(t))+\mathbf{z}(t)\]\]

이제 아주 작은 \(\Delta t\)에 대해 \(\mathbf{z}(t)=\mathbf{w}(t+\Delta t)-\mathbf{w}(t)\approx\frac{d\mathbf{w}(t)}{dt}\Delta t\)가 되도록 랜덤 프로세스 \(\mathbf{w}(t)\를 정의해 보자. 계산에서는 위너 프로세스인 \(\mathbf{z}(t)\)을 적분하여 이러한 \(\mathbf{w}(t)\)을 생성할 수 있다. \(\mathbf{w}(t)\)가 정의된 상태에서, 우리는 쓸 수 있다

\[\mathbf{x}(t+\Delta t) =\mathbf{x}(t)-\tau\nabla f(\mathbf{x}(t))+\mathbf{x}(t)\] \[\implies\quad\mathbf{x}(t)+\mathbf{x}(t) = -\tau\nabla f(\mathbf{x}(t))+\mathbf{w}(t+\Delta t)-\mathbf{w}(t)\] \[\implies\quad\quad\quad\quad\mathbf{x} = -\tau\nabla f(\mathbf{x})dt+d\mathbf{w}}.\]

위의 방정식은 SDE의 일반적인 형태를 나타낸다. 이를 정리하면 다음과 같다.

**Forward Diffusion**.

\[d\mathbf{x}=\underbrace{\mathbf{f}(\mathbf{x},t)}_{\text{drift}}\,dt+ \underbrace{g(t)}_{\text{diffusion}}d\mathbf{w}. \tag{96}\]

두 용어 \(\mathbf{f}(\mathbf{x},t)\)와 \(g(t)\)는 물리적 의미를 가지고 있다. 드래프트 계수는 벡터 값 함수 \(\mathbf{f}(\mathbf{x},t)\)로 임의의 효과가 없을 때 닫힌 계의 분자가 어떻게 움직이는지를 정의한다. 경사 하강 알고리즘의 경우 드리프트는 목적 함수의 음의 기울기에 의해 정의된다. 즉, 우리는 해 궤적이 목표의 기울기를 따르기를 원한다.

확산 계수 \(g(t)\)는 분자가 한 위치에서 다른 위치로 무작위로 걷는 방법을 설명하는 스칼라 함수이다. 함수 \(g(t)\)는 랜덤 이동이 얼마나 강한지를 결정한다.

**예제**. 방정식을 고려

\[d\mathbf{x}=ad\mathbf{w},\]

여기서 \(a=0.05\). 상기 반복 방식은 다음과 같이 작성될 수 있다.

\[\mathbf{x}_{i}-\mathbf{x}_{i-1}=a\underbrace{(\mathbf{w}_{i}-\mathbf{w}_{i-1})}_{\text{d}\in\mathbf{z}_{i-1}\sim\mathcal{N}(0,\mathbf{I})}\quad\Rightarrow \quad\mathbf{x}_{i}=\mathbf{x}_{i-1}+a\mathbf{z}_{i}}.\]

우리는 함수 \(\mathbf{x}_{i}\)를 아래와 같이 그릴 수 있다. 초기점 \(\mathbf{x}_{0}=0\)은 빨간색으로 표시되어 프로세스가 시간적으로 전진하고 있음을 나타냅니다.

**비고**. 보시다시피 차분 \(d\mathbf{w}=\mathbf{w}_{i}-\mathbf{w}_{i-1}\)은 백색 가우시안 벡터인 위너 과정으로 정의된다. 개별 \(\mathbf{w}_{i}\)는 가우시안인 것이 아니라, 차이 \(\mathbf{w}_{i}-\mathbf{w}_{i-1}\)는 가우시안이다.

**예제**. 방정식을 고려

\[d\mathbf{x}=-\frac{\alpha}{2}\mathbf{x}dt+\beta d\mathbf{w},\]

여기서 \(\alpha=1\) 및 \(\beta=0.1\). 이 수식은 다음과 같이 쓸 수 있다.

\[\mathbf{x}_{i}-\mathbf{x}_{i-1}+\beta \underbrace{(\mathbf{x}_{i-1})}_{\stackrel{{\text{ def}}}{{=}}\mathbf{z}_{i-1}=-\frac{\alpha}{2}\mathbf{x}_{i-1}\sim\mathcal{N}(0,\mathbf{I})}\quad\Rightarrow \quad\mathbf{x}_{i}=\left(1-\frac{\alpha}{2}\right)\mathbf{x}_{i-1}+\beta \mathbf{z}_{i-1}}}.\

우리는 함수 \(\mathbf{x}_{i}\)를 아래와 같이 그릴 수 있다.

확산 방정식의 역 방향은 시간적으로 뒤로 이동하는 것이다. Anderson[17]에 따른 역방향-시간 SDE는 다음과 같이 주어진다.

**Reverse SDE**.

\[d\mathbf{x}=\underbrace{[\mathbf{f}(\mathbf{x},t)-g(t)^{2}\underbrace{\nabla _{\mathbf{x}}\log p_{t}(\mathbf{x})}_{\text{\rm{점수 함수}}}]\;dt}_{\text{\rm{역-시간 확산}}}+\underbrace{g(t)d\overline{\mathbf{w}}}_{\text{\rm{역-시간 확산}}}, \tag{97}\]

여기서 \(p_{t}(\mathbf{x})\)는 시간 \(t\)에서 \(\mathbf{x}\)의 확률 분포이고, \(\overline{\mathbf{w}}\)는 시간이 뒤로 흐를 때 위너 과정이다.

**예제**. 역확산 방정식을 고려

\[d\mathbf{x}=ad\overline{\mathbf{w}}. \tag{98}\]

우리는 이산 시간 재귀법을 다음과 같이 쓸 수 있다. For \(i=N,N-1,\ldots,1\) do

\[\mathbf{x}_{i-1}=\mathbf{x}_{i}+a\underbrace{(\mathbf{w}_{i-1}-\mathbf{w}_{i})}_{\stackrel{{\mathbf{w}_{i}}}{{=}}\mathbf{z}_{i}}=\mathbf{x}_{i}+a\mathbf{z}_{i},\quad\mathbf{z}_{i}\sim\mathcal{N}(0,\mathbf{I}).\]

아래 그림에서 우리는 이 역시간 과정의 궤적을 보여준다. 빨간색으로 표시된 초기 점은 \(\mathbf{x}_{N}\)에 있습니다. 이 과정은 \(\mathbf{x}_{0}\)로 역추적된다.

### DDPM에 대한 확률적 차분 방정식

DDPM과 SDE 사이의 연결을 도출하기 위해 이산 시간 DDPM 반복을 고려한다. \(i=1,2,\ldots,N\):

\[\mathbf{x}_{i}=\sqrt{1-\beta_{i}}\mathbf{x}_{i-1}+\sqrt{\beta_{i}}\mathbf{z}_{i-1},\qquad\mathbf{z}_{i-1}\sim\mathcal{N}(0,\mathbf{I}). \tag{99}\

우리는 이 방정식이 아래의 순방향 SDE 방정식으로부터 유도될 수 있음을 보여줄 수 있다.

**DDPM** 의 순방향 샘플링 방정식은 SDE via로 쓸 수 있습니다.

\[d\mathbf{x}=\underbrace{-\frac{\beta(t)}{2}\;\mathbf{x}\;dt}_{=\mathbf{f}( \mathbf{x},t)}+\underbrace{\sqrt{\beta(t)}}_{=g(t)}d\mathbf{w}. \tag{100}\]

이를 위해 스텝 크기 \(\Delta t=\frac{1}{N}\)를 정의하고, 보조 잡음 수준 \(\{\overline{\beta}_{i}\}_{i=1}^{N}\)을 고려하였다. 여기서 \(\beta_{i}=\frac{\overline{\beta}_{i}{N}\). 그럼

\[\beta_{i}=\underbrace{\beta\left(\frac{i}{N}\right)}_{\overline{\beta}_{i}} \cdot\frac{1}{N}=\beta(t+\Delta t)\Delta t,\]

여기서 \(N\to\infty\)에서 \(0\leq t\leq 1\)에 대한 연속시간 함수인 \(\overline{\beta}_{i}\equiv\to\beta(t)\)를 가정한다. 유사하게, 우리는 정의한다

\[\mathbf{x}_{i}=\mathbf{x}\left(\frac{i}{N}\right)=\mathbf{x}(t+\Delta t), \quad\mathbf{z}_{i}=\mathbf{z}\left(\frac{i}{N}\right)=\mathbf{z}(t+\Delta t).\]

따라서 우리는

\mathbf{x}(t+\Delta t)+\sqrt{ \beta(t+\Delta t)\cdot\Delta t}(t+\Delta t) \approx\left(1-\frac{1}{2}\beta(t+\Delta t)\cdot\Delta t\right) \;\mathbf{x}(t+\Delta t)+\sqrt{\beta(t+\Delta t)\cdot\mathbf{z}_{i-1}}\] \[\우측 \mathbf{x}_{i} =\sqrt{1-\overline{\frac{\beta}{N}}\mathbf{x}_{i-1}+\sqrt{\frac{z}_{ i-1}}\] \[\우측 \mathbf{x}_{i} =\sqrt{1-\beta(t+\Delta t)\mathbf{z}_{i-1}}\mathbf{z}_{i-1}

따라서, \(\Delta t\to 0\)와 같이, 우리는

\[d\mathbf{x}=-\frac{1}{2}\beta(t)\mathbf{x}dt+\sqrt{\beta(t)}\;d\mathbf{w}. \tag{101}\]

따라서 DDPM 포워드 업데이트 반복이 SDE로 동등하게 작성될 수 있음을 보였다.

DDPM 순방향 업데이트 반복을 SDE로 작성할 수 있다는 것은 SDE를 풀어서 DDPM 추정치를 결정할 수 있다는 것을 의미한다. 즉, 적절하게 정의된 SDE 솔버를 위해, 우리는 SDE를 솔버 안으로 던질 수 있다. 적절하게 선택된 솔루션이 반환하는 솔루션은 DDPM입니다.

[MISSING_PAGE_FAIL:44]

[MISSING_PAGE_FAIL:45]

**SMLD** 의 순방향 샘플링 방정식은 SDE via로 쓸 수 있습니다.

\[d{\bf x}=\sqrt{\frac{d[\sigma(t)^{2}]}{dt}}\;d{\bf w}. \tag{105}\]

이것을 Eqn(96)으로 매핑하면, 우리는 그것이

\[{\bf f}({\bf x},t)=0,\qquad\mbox{ 및}\qquad g(t)=\sqrt{\frac{d[\sigma(t)^{2}]}{ dt}}.\]

결과적으로, 우리가 역 방정식 Eqn(97)을 쓰면, 우리는 가져야 한다.

\[d{\bf x} =[{\bf f}({\bf x},t)-g(t)^{2}\nabla_{\bf x}\log p_{t}({\bf x})]\; dt\;+\;g(t)d{\bf\bar{w}}\] \[=-\left(\frac{d[\sigma(t)^{2}]}{dt}\nabla_{\bf x}\log p_{t}({\bf x}(t))\right)dt+\sqrt{\frac{d[\sigma(t)^{2}]}{dt}}\;d{\bf\bar{w}}}}.\]

이것은 우리에게 다음과 같은 역수식을 줄 것이다:

**SMLD** 의 역 샘플링 방정식은 SDE via로 쓸 수 있습니다.

\[d{\bf x}=-\left(\frac{d[\sigma(t)^{2}]}{dt}\nabla_{\bf x}\log p_{t}({\bf x}(t) )\right)dt+\sqrt{\frac{d[\sigma(t)^{2}]}{dt}}\;d{\bf\bar{w}}. \tag{106}\]

이산시간 반복을 위해 먼저 \(\alpha(t)=\frac{d[\sigma(t)^{2}]}{dt}\)를 정의한다. 그런 다음 DDPM 경우와 동일한 이산화 설정 세트를 사용하여 다음을 보여줄 수 있다.

\Big{(}\alpha(t)\nabla_{\bf x}\log p_{t}({\bf x})\Big{)}\Delta t -\sqrt{\alpha(t)\Delta t}\;{\bf z}(t)\] \[\우측 bf x}(t) ={\bf x}(t+\Delta t)+\alpha(t)\Delta t\nabla_{\bf x} x}\log p_{t}({ \bf x})+\sqrt{\alpha(t)\Delta t}\;{\bf z}(t)\] \[\우측 bf x}_{i-1} ={\bf x}+\alpha_{i}\nabla_{\bf x}\log p_{i}({\bf x}_{i})+ \sqrt{\alpha(t)\Delta t}\;{\bf z}(t)\] \[\우측 bf x}_{i-1} ={\bf x}_{i

이는 SMLD 역갱신 방정식과 동일하다. Song and Ermon [8]은 SDE를 **variance exploding**(VE) SDE라고 불렀습니다.

### Solving SDE

이 부분에서는 미분방정식이 어떻게 수치적으로 풀리는지에 대해 간단히 논의한다. 논의를 조금 더 쉽게 하기 위해, 우리는 ODE에 초점을 맞출 것이다. 다음 ODE 고려

\[\frac{d{\bf x}(t)}{dt}={\bf f}({\bf x}(t),t) \tag{108}\]

ODE가 스칼라 ODE인 경우 ODE는 \(\frac{dx(t)}{dt}=f(x(t),t)\이다.

**오일러 방법**. 오일러 방법은 ODE를 해결하기 위한 1차 수치 방법이다. 주어진 \(\frac{dx(t)}{dt}=f(x(t),t)\) 및 \(x(t_{0})=x_{0}\), 오일러 방법은 \(i=0,1,\ldots,N-1\)에 대한 반복 방식을 통해 문제를 해결한다.

\[x_{i+1}=x_{i}+\alpha\cdot f(x_{i},t_{i}),\qquad 0,1,\ldots,N-1,\]

여기서, \(\alpha\)는 스텝 사이즈이다. 간단한 예를 생각해 보자.

**예제**. [18, 실시예 2.2] 이하의 ODE를 고려

\[\frac{dx(t)}{dt}=\frac{x(t)+t^{2}-2}{t+1}.\]

우리가 스텝 크기 \(\alpha\)를 갖는 오일러 방법을 적용한다면, 반복은 형태를 취할 것이다.

\[x_{i+1}=x_{i}+\alpha\cdot f(x_{i},t_{i})=x_{i}+\alpha\cdot\frac{(x_{i}+t_{i}^{2 }-2)}{t_{i}+1}.\]

**RK(Runge-Kutta) 메서드**. 또 다른 대중적으로 사용되는 ODE 해결 방법은 Runge-Kutta(RK) 방법이다. 기존의 RK-4 알고리즘은 반복을 통해 ODE를 해결한다.

\[x_{i+1}=x_{i}+\frac{\alpha}{6}\cdot\Big{(}k_{1}+2k_{2}+2k_{3}+k_{4}\Big{)}, \qquad i=1,2,\ldots,N,\

여기서, 수량 \(k_{1}\), \(k_{2}\), \(k_{3}\) 및 \(k_{4}\)은 다음과 같이 정의된다.

\[k_{1} =f(x_{i},t_{i}),\] \[k_{2} =f\left(x_{i}+\alpha\tfrac{k_{1}}{2},\ t_{i}+\tfrac{\alpha}{2} \right),\] \[k_{3} =f\left(x_{i}+\alpha\tfrac{k_{2}}{2},\ t_{i}+\tfrac{\alpha}{2} \right),\] \[k_{4} =f\left(x_{i}+\alphak_{3},\ t_{i}+\alpha\right).\]

자세한 내용은 [18]과 같은 수법 교재를 참고할 수 있다.

**예측자 수정자 알고리즘**. 상이한 수치 솔버는 근사의 오차의 관점에서 상이한 거동을 갖기 때문에, ODE(또는 SDE)를 기성 수치 솔버로 던지는 것은 다양한 정도의 오차를 초래할 것이다[19]. 그러나 우리가 역확산 방정식을 구체적으로 해결하려고 한다면 그림 22와 같이 적절한 보정을 하기 위해 수치 ODE/SDE 해결기 이외의 기술을 사용하는 것이 가능하다.

DDPM을 예로 들어보자. DDPM에서 역확산 방정식은 다음과 같다.

\[\mathbf{x}_{i-1}=\tfrac{1}{\sqrt{1-\beta_{i}}}\Big{[}\mathbf{x}_{i}+\tfrac{ \beta_{i}}{2}\nabla_{\mathbff{x}}\log p_{i}(\mathbf{x}_{i})\Big{]}+\sqrt{ \beta_{i}}\mathbff{z}_{i}.\]

우리는 역확산을 위한 오일러 방법으로 고려할 수 있다. 그러나, 점수함수 \(\mathbf{s}_{\boldsymbol{\theta}}}(\mathbf{x}_{i},i)\)를 이미 학습시킨 경우, 점수 매칭 방정식을 실행할 수 있다.

\[\mathbf{x}_{i-1}=\mathbf{x}_{i}+\epsilon_{i}\mathbf{s}_{\boldsymbol{\theta}}( \mathbf{x}_{i},i)+\sqrt{2\epsilon_{i}}\mathbf{z}_{i},\]

를 \(M\)회 반복하여 보정한다. 알고리즘 4.5는 아이디어를 요약합니다. (우리가 점수 함수를 추정치로 대체했다는 점에 유의하라.)

SMLD 알고리즘의 경우, 두 방정식은 다음과 같다:

\[\mathbf{x}_{i-1} =\mathbf{x}_{i}+(\sigma_{i-1}^{2})\mathbf{s}_{ \boldsymbol{\theta}}(\mathbf{x}_{i},\sigma_{i})+\sqrt{\sigma_{i}^{2}-\sigma_{ i-1}^{2}}\mathbf{z}\] 예측, \[\mathbf{x}_{i-1} =\mathbf{x}_{i}+\epsilon_{i}\nabla_{\mathbff{x}}\mathbf{s}_{ \boldsymbol{\theta}}(\mathbf{x}_{i},\sigma_{i})+\sqrt{\epsilon_{i}}\:\mathbf{ z}\] 보정.

우리는 보정 반복을 몇 번 반복함으로써 DDPM의 예측-보정 알고리즘의 경우와 같이 이들을 짝지을 수 있다.

도 22: 예측 및 보정 알고리즘.

**SDE 솔버를 가속** 합니다. 일반 ODE 솔루션은 ODE를 해결하는 데 사용할 수 있지만 우리가 접하는 정방향 및 역방향 확산 방정식은 매우 특별한다. 사실, 그들은...의 형태를 취한다.

\[\frac{d\mathbf{x}(t)}{dt}=\mathbf{a}(t)\mathbf{x}(t)+\mathbf{b}(t), \qquad\mathbff{x}(t_{0})=\mathbf{x}_{0}, \tag{111}\

함수 선택 \(\mathbf{a}(t)\) 및 \(\mathbf{b}(t)\)에 대해 초기 조건 \(\mathbf{x}(t_{0})=\mathbf{x}_{0}\). 이것은 복잡한 ODE가 아니다. 그것은 단지 1차 ODE일 뿐이다. [20]에서 Lu 등은 ODE의 특수한 구조(이들은 반선형 구조라고 함) 때문에, \(\mathbf{a}(t)\mathbf{x}(t)\)와 \(\mathbf{b}(t)\)를 별도로 취급하는 것이 가능하다는 것을 관찰했다. 우리는 일이 어떻게 돌아가는지 이해하기 위해 아래에 나와 있는 교과서 결과를 사용한다.

**정리** [상수의 변형]([21, 정리 1.2.3])입니다. 범위 \([s,t]\)에 대한 ODE를 고려합니다.

\[\frac{dx(t)}{dt}=a(t)x(t)+b(t),\qquad\text{where}\;\;x(t_{0})=x_{0}. \tag{112}\]

해는 다음과 같이 주어진다.

\[x(t)=x_{0}e^{A(t)}+e^{A(t)}\int_{t_{0}}^{t}e^{-A(\tau)}b(\tau)d\tau. \tag{113}\]

where \(A(t)=\int_{t_{0}}^{t}a(\tau)d\tau\).

**알고리즘 1** DDPM을 위한 예측 수정 알고리즘입니다.

우리는 그것을 알아차림으로써 위의 두 번째 항을 더 단순화할 수 있다.

\[e^{A(t)-A(\tau)}=e^{\int_{t_{0}}^{t}a(r)dr-\int_{t_{0}}^{\tau}a(r)dr}=e^{\int_ {\tau}^{t}a(r)dr}.\]

[20]에 제시된 바와 같은 특히 흥미로운 것은 [8]로부터 유도된 역확산 방정식이었다:

\[\frac{d\mathbf{x}(t)}{dt}=f(t)\mathbf{x}(t)+\frac{g^{2}(t)}{2\sigma(t)} \boldsymbol{\epsilon_{\theta}}(\mathbf{x}(t),t),\qquad\mathbff{x}(t)\sim\mathcal{ N}(0,\widehat{\sigma}^{2}\mathbf{I}),\]

여기서 \(f(t)=\frac{d\log\alpha(t)}{dt}\), \(g^{2}(t)=\frac{d\sigma(t)^{2}}{dt}-2\frac{d\log\alpha(t)}{dt}\sigma(t)^{2}\). 상수 정리의 변화를 이용하여, 우리는 시간 \(t\)에서 ODE를 공식으로 정확하게 풀 수 있다.

\[\mathbf{x}(t)=e^{\int_{s}^{t}f(\tau)d\tau}\mathbf{x}(s)+\int_{s}^{t}\left(e^ {\int_{\tau}^{t}f(\tau)dr}\frac{g^{2}(\tau)}{2\sigma(\tau)}\boldsymbol{ \epsilon_{\theta}}(\mathbf{x}(\tau),\tau)\right)d\tau.\]

그런 다음 \(\lambda_{t}=\log\alpha(t)/\sigma(t)\)를 정의하고 [20]에 설명된 추가 단순화로 이 방정식을 단순화할 수 있다.

\[\mathbf{x}(t)=\frac{\alpha(t)}{\alpha(s)}\mathbf{x}(s)-\alpha(t)\int_{s}^{t} \left(\frac{d\lambda_{\tau}}{d\tau}\right)\frac{\sigma(\tau)}{\alpha(\tau)} \boldsymbol{\epsilon_{\theta}}(\mathbf{x}(tau))d\tau.\] 이 방정식을 평가하기 위해서는 오른쪽에 표시된 적분을 위한 수치적분기를 실행하기만 하면 된다. 물론, 간결함을 위해 건너뛰어야 할 ODE를 해결하기 위한 다른 수치 가속 방법이 있다.

### 축하합니다! 우린 끝났어 이건 SDE에 관한 거야

여러분 중 몇몇은 궁금할지도 모릅니다: 왜 우리는 반복적인 계획을 미분 방정식에 매핑하기를 원하나요? 몇 가지 이유가 있는데, 일부는 합법적인 반면 일부는 추측적이다.

* 여러 확산 모델을 동일한 SDE 프레임워크로 통합하면 알고리즘을 비교할 수 있습니다. 경우에 따라 확률적 샘플링 문헌뿐만 아니라 SDE 문헌에서 아이디어를 차용하여 수치 스킴을 개선할 수 있다. 예를 들어, [8]의 예측자-보정자 스킴은 마르코프 체인 몬테 카를로와 결합된 하이브리드 SDE 솔버였다.
* [22]와 같은 일부 논문에 따라 확산 반복을 SDE에 매핑하면 더 많은 디자인 유연성을 제공합니다.
* 컨텍스트 확산 알고리즘 외부에서 일반적인 확률적 경사 하강 알고리즘에는 Fokker-Planck 방정식과 같은 해당 SDE가 있습니다. 사람들은 추정치의 한계 분포를 정확히 닫힌 형태로 이론적으로 분석하는 방법을 입증했다. 이것은 잘 정의된 제한 분포를 분석하는 수단으로 무작위 알고리즘을 분석하는 어려움을 완화한다.

## 5 Conclusion

이 자습서는 최근 문헌에서 확산 기반 생성 모델의 개발을 뒷받침하는 몇 가지 기본 개념을 다룬다. 문헌의 순전한 양(그리고 빠르게 확장됨)을 감안할 때 파이썬 데모를 재활용하는 대신 근본적인 아이디어를 설명하는 것이 특히 중요하다는 것을 알게 된다. 이 자습서를 쓰면서 배운 몇 가지 교훈은 다음과 같습니다.

* 동일한 확산 아이디어는 VAE, DDPM, SMLD 및 SDE와 같은 여러 관점에서 독립적으로 도출될 수 있다. 어떤 사람들은 다르게 주장할 수 있지만, 한 사람이 다른 사람보다 더 우월한/열등한 이유는 특별한 이유가 없다.
* 노이즈 제거 확산이 작동하는 주요 이유는 GAN 및 VAE 시대에 실현되지 않은 작은 증가 때문이다.
* 반복적인 노이즈 제거는 현재 최첨단이지만 접근 방식 자체는 궁극적인 솔루션으로 보이지 않습니다. 인간은 순수한 잡음으로부터 이미지를 생성하지 않는다. 또한 확산 모델의 작은 증가 특성으로 인해 상황을 개선하기 위해 지식 증류에 대한 일부 노력이 있었지만 속도는 계속해서 주요 장애물이 될 것이다.
* 비가우시안에서 노이즈를 생성하는 것과 관련된 일부 질문에는 정당화가 필요할 수 있습니다. 가우시안 분포를 도입하는 전체 이유가 유도를 더 쉽게 하기 위해서라면, 왜 우리는 우리의 삶을 더 어렵게 만들어 다른 종류의 잡음으로 전환해야 하는가?
* 역 문제에 확산 모델을 쉽게 적용할 수 있습니다. Plug-and-Play ADMM 알고리즘과 같은 기존의 역해법들에 대해, 우리는 명시적 확산 샘플러로 데노아저를 대체할 수 있다. 사람들은 이 접근법을 기반으로 개선된 이미지 복원 결과를 입증했다.

## References

* [1] D. P. Kingma and M. Welling, "An introduction to variational autoencoders," _Foundations and Trends in Machine Learning_, vol. 12, no. 4, pp. 307-392, 2019. [https://arxiv.org/abs/1906.02691](https://arxiv.org/abs/1906.02691).
* [2] C. Doersch, "Tutorial on variational autoencoders," 2016. [https://arxiv.org/abs/1606.05908](https://arxiv.org/abs/1606.05908).
* [3] D. P. Kingma and M. Welling, "Auto-encoding variational Bayes," in _ICLR_, 2014. [https://openreview.net/forum?id=33X9fd2-9FyZd](https://openreview.net/forum?id=33X9fd2-9FyZd).
* [4] J. Ho, A. Jain, and P. Abbeel, "Denoising diffusion probabilistic models," in _NeurIPS_, 2020. [https://arxiv.org/abs/2006.11239](https://arxiv.org/abs/2006.11239).
* [5] D. P. Kingma, T. Salimans, B. Poole, and J. Ho, "Variational diffusion models," in _NeurIPS_, 2021. [https://arxiv.org/abs/2107.00630](https://arxiv.org/abs/2107.00630).
* [6] M. Delbracio and P. Milanfar, "Inversion by direct iteration: An alternative to denoising diffusion for image restoration," _Transactions on Machine Learning Research_, 2023. [https://openreview.net/forum?id=VmyFF51L3F](https://openreview.net/forum?id=VmyFF51L3F).
* [7] S. H. Chan, _Introduction to Probability for Data Science_. Michigan Publishing, 2021. [https://probability4datascience.com/](https://probability4datascience.com/).
* [8] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and B. Poole, "Score-based generative modeling through stochastic differential equations," in _ICLR_, 2021. [https://openreview.net/forum?id=PxTIG12RRHS](https://openreview.net/forum?id=PxTIG12RRHS).
* [9] P. Vincent, "A connection between score matching and denoising autoencoders," _Neural Computation_, vol. 23, no. 7, pp. 1661-1674, 2011. [https://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf](https://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf).
* [10] J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, and S. Ganguli, "Deep unsupervised learning using nonequilibrium thermodynamics," in _ICML_, vol. 37, pp. 2256-2265, 2015. [https://arxiv.org/abs/1503.03585](https://arxiv.org/abs/1503.03585).
* [11] C. Luo, "Understanding diffusion models: A unified perspective," 2022. [https://arxiv.org/abs/2208.11970](https://arxiv.org/abs/2208.11970).
* [12] J. Song, C. Meng, and S. Ermon, "Denoising diffusion implicit models," in _ICLR_, 2023. [https://openreview.net/forum?id=St1giarCHLP](https://openreview.net/forum?id=St1giarCHLP).
* [13] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer, "High-resolution image synthesis with latent diffusion models," in _CVPR_, pp. 10684-10695, 2022. [https://arxiv.org/abs/2112.10752](https://arxiv.org/abs/2112.10752).
* [14] C. Saharia, W. Chan, S. Saxena, L. Li, J. Whang, E. L. Denton, K. Ghasemipour, R. Gontijo Lopes, B. Karagol Ayan, T. Salimans, J. Ho, D. J. Fleet, and M. Norouzi, "Photorealistic text-to-image diffusion models with deep language understanding," in _NeurIPS_, vol. 35, pp. 36479-36494, 2022. [https://arxiv.org/abs/2205.11487](https://arxiv.org/abs/2205.11487).
* [15] Y. Song and S. Ermon, "Generative modeling by estimating gradients of the data distribution," in _NeurIPS_, 2019. [https://arxiv.org/abs/1907.05600](https://arxiv.org/abs/1907.05600).
* [16] Y. Song and S. Ermon, "Improved techniques for training score-based generative models," in _NeurIPS_, 2020. [https://arxiv.org/abs/2006.09011](https://arxiv.org/abs/2006.09011).
* [17] B. Anderson, "Reverse-time diffusion equation models," _Stochastic Process. Appl._, vol. 12, pp. 313-326, May 1982. [https://www.sciencedirect.com/science/article/pii/0304414982900515](https://www.sciencedirect.com/science/article/pii/0304414982900515).
* [18] K. Atkinson, W. Han, and D. Stewart, _Numerical solution of ordinary differential equations_. Wiley, 2009. [https://homepage.math.uiowa.edu/~atkinson/papers/NAODE_Book.pdf](https://homepage.math.uiowa.edu/~atkinson/papers/NAODE_Book.pdf).
** [19] T. 카라스 아탈라, T. Aila, S. 레인, 2022 _NeurIPS_ 의 "확산 기반 생성 모델의 설계 공간을 설명 합니다. [https://arxiv.org/abs/2206.00364](https://arxiv.org/abs/2206.00364).
* [20] C. Lu, Y. Zhou, F. Bao, J. Chen, C. Li, and J. Zhu, "DPM-Solver: A fast ODE solver for diffusion probabilistic model sampling in around 10 steps," in _NeurIPS_, 2022. [https://arxiv.org/abs/2206.00927](https://arxiv.org/abs/2206.00927).
* [21] G. Nagy, "MTH 235 differential equations," 2024. [https://users.math.msu.edu/users/gnagy/teaching/ade.pdf](https://users.math.msu.edu/users/gnagy/teaching/ade.pdf).
* [22] M. S. Albergo, N. M. Boffi, and E. Vanden-Eijnden, "Stochastic interpolants: A unifying framework for flows and diffusions." [https://arxiv.org/abs/2303.08797](https://arxiv.org/abs/2303.08797).
