<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# SaulLM-7B: 법을 위한 선구적인 대형 언어 모델\n' +
      '\n' +
      '피에르 콜롬보\\({}^{1,2,}\\) 텔모 페소아 피레스\\({}^{1,}\\) 말릭 부디아프\\({}^{1,}\\)1\n' +
      '\n' +
      '**Dominic Culver\\({}^{1,*}\\) Rui Melo\\({}^{1,}\\)1 Caio Corro\\({}^{3}\\) Andre F. T. Martins\\({}^{4}\\) Fabrizio Esposito\\({}^{5}\\) Vera Lucia Raposo\\({}^{5}\\) Sofia Morgado\\({}^{1}\\) Michael Desa\\({}^{1}\\)**\n' +
      '\n' +
      '뉴욕, 파리, 리스본 등\n' +
      '\n' +
      'Universite Paris-Saclay, CentraleSupelec, MICS\n' +
      '\n' +
      'Sorbonne Universite, CNRS, ISIR, Paris\n' +
      '\n' +
      '({}^{4}\\) Instituto Superior Tecnico, Universityidade de Lisboa\n' +
      '\n' +
      '리스보아 NOVA 법학전문대학원\n' +
      '\n' +
      'firstname@equall.ai\n' +
      '\n' +
      'Equal contribution.\n' +
      '\n' +
      '각주 1: 동등 기여도.\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '본 논문에서는 법률 영역에 맞춘 대규모 언어 모델(LLM)인 SaulLM-7B를 소개한다. 70억 개의 매개변수를 사용하여 SaulLM-7B는 법률 텍스트 이해 및 생성을 위해 명시적으로 설계된 최초의 LLM이다. 미스트라트 7B 아키텍처를 기반으로 사울LM-7B는 300억 개 이상의 토큰의 영국 법률 코퍼스에서 훈련된다. SaulLM-7B는 법률 문서를 이해하고 처리하는 데 있어 최첨단 기술을 보여준다. 또한, 법률 작업에서 SaulLM-7B의 성능을 더욱 향상시키기 위해 법률 데이터 세트를 활용하는 새로운 교수 미세 조정 방법을 제시한다. SaulLM-7B는 MIT 라이센스에 따라 출시된다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '인공지능의 빠르게 진화하는 풍경에서, 큰 언어 모델(LLM)[1, 1, 2, 3, 4, 5, 6, 7, 8]의 응용 프로그램은 _예:_ 번역[22], 의료용[23], 코드 생성[19, 20]과 같은 다양한 도메인에 걸쳐 큰 발전을 목격했다. 자연어 처리에서 기계 번역에 이르기까지, 이 모델들은 인간과 같은 텍스트를 이해하고 생성하는 데 탁월한 능력을 보여주었다[24, 25, 26]. 그러나, 이 변형 기술의 완전한 이점을 아직 경험하지 못한 한 분야는 법 영역이다[10, 11]. 법조인들이 점점 더 확장되는 복잡한 문서 양에 씨름하면서, 법률 자료를 탐색하고 해석하는 데 도움을 줄 수 있는 전용 LLM에 대한 필요성이 증가하고 있다[23, 22, 25].\n' +
      '\n' +
      '이 논문에서 우리는 공개적으로 이용 가능한 최초의 법적 LLM을 개발하기 위한 선구적인 이니셔티브를 제시한다. 독특한 구문 및 전문 어휘로 특징지어지는 법률 텍스트는 뚜렷한 언어적 과제를 제시한다[13, 26]. 우리의 접근법은 미국, 캐나다, 영국, 유럽과 같은 영어권 관할 구역에서 전용 법률 코퍼스를 사용하는 광범위한 사전 훈련[15, 22]에 초점을 맞춘다. 우리 팀과 이전 문헌[26]에서 긁어낸 크고 다양한 법률 데이터 세트에서 사전 교육을 활용하면 LLM인 SaulLM-7B는 법률 문서의 복잡성을 이해할 뿐만 아니라 법률 담론의 진화하는 특성에 적응하는 것을 목표로 한다.\n' +
      '\n' +
      '법률 실무자의 요구에 집중하고 전담 법률 코퍼라에 대한 사전 교육의 힘을 활용함으로써 우리의 작업은 법률 영역의 고유한 요구를 충족하기 위한 중요한 단계를 나타낸다. 법학을 위한 첫 번째 LLM을 도입하면 법률 전문가들에게 권한을 부여할 뿐만 아니라 인공지능과 법 공동체의 교차점에서 추가 혁신을 촉진하여 법률 언어 이해와 적용에 상당한 기여를 할 것으로 기대한다[12]. 이 작업의 기여도를 요약하면 다음과 같다.\n' +
      '\n' +
      '기여 1: 법률 LLM 패밀리 이 논문에서는 법률 도메인 내에서 직면하는 독특한 문제를 해결하기 위해 세심하게 제작된 법률 언어 모델 모음인 SaulLM-7B의 패밀리를 소개한다. 우리는 법률 텍스트에 특별히 맞춘 70억 개의 매개 변수 언어 모델인 SaulLM-7B를 공개한다. 전문화된 훈련 요법으로 SaulLM-7B는 일반 모델에 비해 법률 언어의 뉘앙스에 대한 우수한 이해도를 보여준다. 또한 다양한 법적 작업 1에서 미스트랄 또는 라마와 같은 기존 모델을 능가하도록 신중하게 설계된 명령어 조정 변형인 SaulLM-7B-Instruct를 출시한다.\n' +
      '\n' +
      '각주 1: 모델은 [https://huggingface.co/Equall](https://huggingface.co/Equall)에서 사용할 수 있습니다.\n' +
      '\n' +
      '기여 2: 법적 LLMs에 대한 개선된 평가 프로토콜, 동시에, 우리는 언어 모델의 법적 숙련도를 더 잘 측정하고 정교하게 만들기 위해 만들어진 법률 벤치-인스트럭션, 법률 벤치 구하 등(2022, 2023)2를 소개한다. 법적 맥락에서 모델의 능력을 더욱 풍부하게 하기 위해 특히 국제법, 전문 법률 3 및 법학에 초점을 맞춘 인기 있는 MMLU 벤치마크 헨드릭 등(2020)의 법적 과제도 평가 프로토콜에 포함한다.\n' +
      '\n' +
      '각주 3: 여기서는 Hendrycks et al.(2020)에서 정의한 "전문법칙"이라는 용어를 사용한다.\n' +
      '\n' +
      '기여 3: 모델, 평가 코드 및 라이선스. 광범위한 채택을 촉진하고 혁신을 촉진하기 위해 우리는 MIT 라이선스에 따른 평가 코드뿐만 아니라 SaulLM-7B 및 SaulLM-7B 지침을 출시한다. 이 개방형 라이선스 접근법은 법적 영역 및 그 너머의 광범위한 상업적 및 연구 노력에 대한 협력 개발 및 채택을 장려한다.\n' +
      '\n' +
      '## 2 SaulLM-7B: 언어 모델의 법적 기능 확장\n' +
      '\n' +
      '개방형 대규모 언어 모델은 Pythia Biderman et al.(2023)과 같은 7천만 개의 매개변수 모델에서 Falcon Almazrouei et al.(2023)과 같은 1,800억 개의 매개변수 모델에 이르기까지 백본에 사용할 수 있다. 본 연구에서는 미스트랄 7B 모델(Mistral 7B model)과 벤치마크와 장 등(2023)의 작업에서 높은 성능을 달성하는 70억 원 규모의 파라미터 오픈소스 모델을 선택하였다.\n' +
      '\n' +
      '그림 1에 표시된 우리의 방법론은 아래에서 설명하는 2단계 프로세스를 포함한다.\n' +
      '\n' +
      '### 미스트랄의 법적 능력 향상\n' +
      '\n' +
      '일반 모델 Touvron et al. (2023); Taylor et al. (2022); Zhang et al. (2022); Gu and Dao (2023); Almazrouei et al. (2023); Zhang et al. (2024); Faysse et al. (2024)는 훈련 중에 법률 데이터에 대한 일부 노출을 얻지만 일반적으로 전체 데이터의 작은 부분만 나타낸다. 법률 업무에 대한 성과를 높이기 위한 간단한 방법은 법률 데이터에 초점을 맞춘 추가 교육을 수행하는 것이다. 특히 디코더 모델에 초점을 맞춘 이 접근법은 의학 Chen 등(2023); Ji 등(2023), 번역 Xu 등(2023); Wu 등(2024) 및 코딩 Roziere 등(2023)과 같은 다양한 분야에서 성공적으로 사용되었다. 이 접근법의 주요 장점은 훈련 데이터의 특정 특성으로부터의 확장성과 독립성이다. 도메인 적응에 대한 다른 연구에서는 사전 텍스트 작업을 통해 언어 모델을 전문화하려고 시도했다. 그러나, 이러한 노력들은 종종 더 작은-스케일 접근법들 Niklaus 및 Giofre (2023), 계산적으로 비싼 Vu 등 (2020); Lu 등 (2023), 또는 확장성이 부족한 Cheng 등 (2023); Cui 등 (2023); Nishida 등 (2019).\n' +
      '\n' +
      '이러한 이유로 웹에서 대규모 법률 코퍼스를 사용할 수 있을 뿐만 아니라 _지속적인 사전 교육_ 에 중점을 두기로 결정했습니다. 다양한 법률 콘텐츠 리포지토리에서 제공하는 고품질 데이터 세트를 세심하게 선별합니다. Penedo et al. (2023)과 중복제거 Mou et al. (2023); Kocetkov et al. (2023)의 엄격한 필터링 후, 우리는 지속적인 사전 훈련을 위한 강력한 기반 역할을 하는 300억 토큰의 코퍼스를 갖게 된다.\n' +
      '\n' +
      '### 법적 명령 개선\n' +
      '\n' +
      '사용자 요청 및 대화 상호 작용을 지원하기 위해 LLM은 일반적으로 감독된 대화 쌍에 대한 훈련을 포함하는 중요한 프로세스인 명령어 튜닝을 거친다. 이 단계는 사용자 쿼리 Wang 등 (2023); Wei 등 (2021); Chung 등 (2022); Faysse 등 (2023); Ding 등 (2023); Wang 등 (2023).\n' +
      '\n' +
      '범용 언어 모델의 경우, 다양성과 수업의 질은 Cao et al.(2023); Zhou et al.(2023)이 매우 중요하다. 그러나 전문화된 도메인에서는 성능을 향상시키기 위해 작업별 및 전문화된 프롬프트를 통합하는 것이 중요하다. 우리의 지침 미세 조정 단계는 \\(2\\) 핵심 구성 요소, 즉 일반(즉, 비법) 및 법적 지침을 포함한다. 전자는 명령에 대한 모델의 이해와 후속을 향상시키는 데 도움이 되며 코딩, 수학, 일반 대화와 같은 다양한 영역의 데이터를 포함한다. 후자의 경우 법률 질문 응답 및 요약 등을 포함하여 법률 도메인의 뉘앙스에 맞춘 광범위한 데이터 세트를 사용한다. 우리의 모델 SaulLM-7B-Instruct는 교수 데이터에 대한 이러한 적절한 미세 조정을 통해 법적 복잡성을 파악할 수 있으며 광범위한 관련 작업에서 탁월하다.\n' +
      '\n' +
      '**비고**.: _많은 일반적인 LLM Tunstall 등(2023)에는 모델을 인간 선호도와 정렬하는 추가 단계가 포함되어 있습니다. Rafailov 등(2023); Munos 등(2023); von Werra 등(2020). 우리의 경우 초기 실험에서 성능의 유의미한 향상이 나타나지 않았으므로 본 논문을 위해 이 방법을 추구하지 않기로 결정했다._\n' +
      '\n' +
      '## 3 Data\n' +
      '\n' +
      '이 섹션에서는 데이터 수집 및 청소 계획에 대해 설명합니다.\n' +
      '\n' +
      '### 법적 사전 훈련 Corpora\n' +
      '\n' +
      '과학, 의학 등의 분야와 달리 법률 지형은 국가 및 관할 지역에 따라 크게 달라지며, 이는 관습법 대 민법 헨더슨 등(2022)과 같이 현지법뿐만 아니라 법률 전통에서도 차이를 반영한다. 따라서 우리는 영어가 전 세계적으로 법적 맥락에서 널리 사용되기 때문에 영어에 중점을 두고 다양한 관할 구역에서 법률 텍스트를 수집했다. 우리의 컬렉션에는 다양한 법적 시스템을 다루는 미국 Tuggener 등(2020), 유럽 Chalkidis 등(2019), 호주 Butler(2023)의 데이터가 포함된다. 이 철저한 큐레이션 과정과 공격적인 청소(섹션 3.1.2 참조)를 통해 300억 토큰의 코퍼스를 얻게 되어 지역 전반에 걸친 법률 언어의 복잡성을 포착하게 됩니다.\n' +
      '\n' +
      '#### 3.1.1 Dataset Composition\n' +
      '\n' +
      '법적 출처 우리는 Pile Gao et al.(2020) 및 MultiLegal Pile Niklaus et al.(2023)의 FreeLaw 하위 집합과 웹에서 공개적으로 사용 가능한 출처에서 긁어낸 데이터와 같은 이전에 사용 가능한 데이터 세트를 모두 결합한다. 우리는 표 1에 다양한 데이터 출처를 나열한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c} \\hline \\hline Name & Tokens \\\\ \\hline FreeLaw4  & \\(15\\)B \\\\ EDGAR5  & \\(5\\)B \\\\ English MultiLegal Pile6  & \\(5\\)B \\\\ English EuroParl Koehn (2005) & \\(6\\)B \\\\ GovInfo7  & \\(11\\)B \\\\ Law Stack Exchange8  & \\(19\\)M \\\\ Commercial Open Australian Legal Corpus9  & \\(0.5\\)B \\\\ EU Legislation10  & \\(315\\)M \\\\ UK Legislation11  & \\(190\\)M \\\\ Court Transcripts12  & \\(350\\)M \\\\ UPSTO13  & \\(4.7\\)B \\\\ Total & \\(94\\)B \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: **법적 사전 훈련 데이터의 원본** 이러한 원본에는 노이즈 및 심하게 중복된 문서가 포함되어 있으며, 필터링 및 중복 제거되어 300억 토큰 데이터 세트가 생성됩니다.\n' +
      '\n' +
      '그림 1: **SaulLM-7B를 구성하기 위한 절차** 다시 보기 데이터 및 지침 데이터 세트로 보강된 법적 데이터 세트에 의존합니다. 미세 조정을 위해 법률 지침으로 미세 조정 데이터 세트를 더욱 풍부하게 합니다.\n' +
      '\n' +
      '서로 다른 소스 간에 상당한 중복이 있으며 섹션 3.1.2에 설명된 매우 공격적인 청소 및 중복 제거 단계를 실행합니다.\n' +
      '\n' +
      'Replay SourcesTo reduce catastrophic forgetting McCloskey and Cohen (1989) during continue pretraining, we incorporate data from the prior training distribution, following Chen et al. (2023); Sun et al. (2020). 그러나 미스트랄에 대한 학습 데이터는 공개되지 않았기 때문에, 우리는 최종 학습 믹스의 대략 \\(2\\%\\)로 구성된 Wikipedia, StackExchange 및 GitHub에서 일반적으로 사용 가능한 "일반" 데이터를 소개한다. 이들 데이터셋은 SlimPajama Shen et al. (2023); Computer (2023); Soboleva et al. (2023).\n' +
      '\n' +
      '교육 자료 또한 사전 교육 중에 대화 데이터를 포함하는 것이 유익하다는 것을 발견했다. 이것은 신경망 기계 번역의 최근 발전에 영감을 받은 것으로, 번역에서 LLM의 강력한 능력은 훈련 코퍼스 Anil 등(2023); Briakou 등(2023)에 우발적인 병렬 데이터가 존재하기 때문이라는 점을 강조한다. 특히 Super Natural Instruction Wang et al.(2022)과 FLAN Collection Longpre et al.(2023)이 프리트레이닝 중에 포함되어 있음을 의미한다.\n' +
      '\n' +
      '#### 3.1.2 데이터 정리\n' +
      '\n' +
      '수집된 데이터의 상당 부분은 PDF 파일에 있거나 PDF14에서 추출된 텍스트이다. 이는 텍스트가 i) 문장의 중간에 있는 페이지 번호; ii) 줄 번호; iii) 정규화되지 않은 유니코드 문자; iv) 텍스트의 끊어진 줄; v) 반복되는 문자: 새로운 줄, 대시 등; vi) 다른 아티팩트를 포함하는 일부 아티팩트를 갖는다는 것을 의미한다. 우리는 데이터를 필터링하기 위해 규칙과 휴리스틱의 조합을 사용하여 이러한 문제를 해결했다.\n' +
      '\n' +
      '각주 14: PDF 파일에서 텍스트 추출을 위해 Poppler를 사용했다.\n' +
      '\n' +
      '텍스트 정규화 유니코드 데이터 파이썬 패키지를 통해 사용할 수 있는 모든 유니코드를 NFKC 방법으로 정규화합니다.\n' +
      '\n' +
      'Elazar et al. (2023)에 이어 규칙 필터를 사용하여 데이터 세트에서 가장 일반적인 10-gram을 찾았고 대부분 반복되는 문자인 원하지 않는 문자를 제거하기 위해 정규식을 사용했다. 구체적으로, 원본 데이터에서 상위 \\(10\\) 10-그램의 \\(8\\)은 반복되는 문자, 예를 들어, "- - -"," 또는 "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 과 이상한 문자, 즉 인코딩 문제였다. 또한 반복되는 공백(공간, 새 줄 및 탭)과 파이프라인을 통과한 HTML 태그를 제거했다.\n' +
      '\n' +
      '당혹도 필터링 신중하게 검사된 법률 데이터의 작은 하위 집합에 대해 KenLM 모델 헤필드(2011)를 훈련하고 높은 당혹도 문단을 필터링하는 데 사용했다. 이것은 데이터에 존재하는 대부분의 "이상한" 유니코드 시퀀스뿐만 아니라 비영어 텍스트를 제거했다. 우리는 표 2의 필터링된 데이터에서 가장 일반적인 \\(10\\)-그램 중 일부를 보여준다.\n' +
      '\n' +
      '#### 3.1.3 데이터 중복 제거\n' +
      '\n' +
      'Kocetkov et al. (2023)에 의해 영감을 받은 Lee et al. (2021)은 Mou et al. (2023)을 사용하여 학습 데이터에서 중복 및 거의 중복을 제거했으며 기본 매개변수와 함께 이후 고품질 텍스트의 대략 \\(30\\)B 토큰으로 남겨졌다.\n' +
      '\n' +
      '### 명령 Finetuning Mixs\n' +
      '\n' +
      '명령어 미세 조정은 서로 다른 작업에 걸쳐 미리 훈련된 디코더 모델에서 최상의 성능을 얻기 위해 중요하다. 우리는 일반 지침과 법률 지침을 혼합하여 모델을 교육하여 법률 전문 지식을 중심으로 지침을 잘 이해하고 따르도록 훈련한다.\n' +
      '\n' +
      '일반 지침에 관해서는 4가지 주요 출처에서 수집합니다.\n' +
      '\n' +
      '1. **SlimOrca** FLAN 컬렉션의 이 하위 집합은 일반 지침을 포함하여 다양한 작업에 대한 집중된 리소스를 제공합니다. Mukherjee 등(2023); Lian 등(2023).\n' +
      '2. **Meta Math Question Answering Instructions** 수학적 탐구를 위해 설계된 이 데이터 세트15는 수학 기반 자연어 처리 Yu 등(2023)에서 연구를 용이하게 하는 다양한 수학적 질문을 제공합니다. 각주 15: 메타수학/메타수학QA에서 액세스 가능\n' +
      '3. **UltraChat의 일반 대화** 다양한 대화 컨텍스트를 캡처합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c} \\hline \\hline Common 10-grams \\\\ \\hline have been obvious to one of ordinary skill in the \\\\ before the effective filing date of the claimed invention to \\\\ rejected under 35 U.S.C. 103 as being unpatentable over \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: **사전 훈련 데이터 세트에서 가장 일반적인 10-그램입니다.** 이 GPT 파생 데이터 세트는 자연 언어 이해 및 생성 시스템 Ding 등(2023)을 향상시키는 데 기여합니다.\n' +
      '4. **Code Instructions from Glaive Code Assistant v216** 코드에 대한 Training is shown to increase the reasoning ability of models Ma et al.(2023)\n' +
      '\n' +
      '각주 16: [https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v2](https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v2)에서 사용할 수 있습니다.\n' +
      '\n' +
      '이 모든 데이터를 세심하게 필터링, 중복 제거 및 선별하여 \\(600\\)K 지침으로 구성된 정제된 데이터 세트를 생성했다.\n' +
      '\n' +
      '법률 지침 구축 우리는 여러 법률 문서 유형 Ding 등(2023)에 걸쳐 기본 법적 역량을 다루는 포괄적인 대화를 종합적으로 생성한다. Mistral-7B 지침을 활용하여 메타데이터로 증강된 법률 텍스트를 일관된 대화로 변환합니다. 방법론은 \\(3\\) 미리 정의된 턴들과의 대화를 개시하는 것을 포함한다: (1) 사용자가 법률 문서와 관련된 요청을 아티큘레이션하고, (2) 어시스턴트가 메타데이터(예를 들어, 문서 유형, 날짜, 판사의 이름)를 리프레이징함으로써 응답하고, (3) 사용자가 어시스턴트에게 그의 추론을 상세히 설명하라고 프롬프트한다. 이후, 일련의 회전을 통해 대화를 확장하며, 여기서 사용자 모델은 어시스턴트의 추론을 파악하기 위해 점진적으로 더 구체적인 질문을 제기한다. 동시에, 어시스턴트 모델은 심층적인 통찰력을 제공합니다. 예시적 예가 그림 2에 나와 있다. 특히, 우리는 기존 벤치마크에서 테스트 세트를 제외하도록 보장한다.\n' +
      '\n' +
      '## 4 법률 지식 평가\n' +
      '\n' +
      '모델의 법적 능력을 평가하기 위해 \\(3\\) 벤치마크를 사용하였으며, (i) \\(5\\) 유형의 법적 문서에 대한 백본들의 복잡성을 비교하고, (ii) 보다 심층적인 평가를 위해 LegalBench-Instruct와 LegalBench를 개선하며, (iii) 추가적인 통찰력을 위해 MMLU의 법적 섹션에 의존한다.\n' +
      '\n' +
      '당혹도 측정 법적 문서에 대한 백본의 적응성을 평가하기 위해 _계약, 사법 결정, 의견 텍스트 및 입법_의 네 가지 고유한 법적 영역에 걸쳐 있는 벤치마크 데이터 세트를 사용하여 당혹도를 평가한다. 데이터 세트가 최신 상태이며 LLM 데이터에서 수집 차단 날짜 이후에 원본이 되도록 합니다. 구체적으로, 계약 데이터는 EDGAR(2024년 1/4분기), 2023년 10월 이후에 발표된 ICSID 법원 판결의 법적 결정, 입법은 2023년 10월 이후 하원 또는 상원에 제출된 미국 법률안에 초점을 맞추고, 정당 제출은 2023년 10월 이후에 제출된 텍사스 브리핑을 포함한다.\n' +
      '\n' +
      '조사하는 동안 우리는 법률 벤치의 원래 프롬프트에서 상당한 한계를 발견했다. 명령어 준수, 특히 포맷 처리 시 오픈 소스 LLM이 직면하는 어려움과 결합된 이러한 프롬프트의 복잡한 특성은 (정확도로 측정한 바와 같이) 성능의 상당한 저하를 초래한다. 생성된 문장은 종종 장황하고 구문 분석하기가 어려워 리걸벤치를 현재 형태로 너무 엄격하게 만들고 작업에 대한 개선을 정확하게 측정하지 못한다.\n' +
      '\n' +
      '예를 들어 일부 작업에서는 모델이 예측하는 첫 번째 단어에 의해 성능이 평가되며 이 단어는 _예/아니오_일 것으로 예상됩니다. 이는 응답이 다소 장황하다면 인간이 정답으로 분류하더라도 오답으로 계산된다는 것을 의미한다. 이러한 단점을 개선하기 위해 1) 산만한 소수의 샷 예제를 제거하고 2) 모델이 태그를 생성하기 위한 특정 명령으로 결론을 내림으로써 프롬프트를 개선한다(표 3 참조).\n' +
      '\n' +
      'Massive Multitask Language Understanding (MMLU) The MMLU benchmark Hendrycks et al. (2020) has widely employed to gauge\n' +
      '\n' +
      '그림 2: **메타데이터가 있는 데이터 집합을 대화로 바꿉니다.* * Reddit 게시물 분류의 예를 들어 레이블이 지정된 예제 {_My employer fired me because...that is legal?_, _“employment”_}를 바꿉니다. 우리는 질의응답을 자연스러운 대화로 재구성함으로써 대화의 처음 세 바퀴를 하드 코딩한다. 그런 다음 진행 중인 대화에서 관련 질문을 계속 생성하는 것이 작업인 _사용자_ 모델(파란색 점선)과 답변을 제공하는 _보조자_ 모델을 사용하여 대화를 완료합니다. *보조* 및 *사용자* 모델은 모두 미스트랄-7B 명령입니다.\n' +
      '\n' +
      'LLM의 성능 향상 우리의 연구에서 우리는 국제법, 전문법 및 판례와 같은 특정 주제에 초점을 맞추어 법적 영역에 분석을 집중한다. 이러한 작업은 각각 \\(120\\), \\(1500\\) 및 \\(110\\) 예제를 포함합니다.\n' +
      '\n' +
      '### Metrics\n' +
      '\n' +
      '우리는 원래 LegalBench Guha et al. (2023) 논문과 동일한 메트릭을 사용한다: 균형 잡힌 정확도. 균형 잡힌 정확도를 통해 두 벤치마크에 제시된 것과 같은 더 나은 불균형 분류 작업을 처리할 수 있다. 우리는 또한 MMLU의 법적 작업에 균형 잡힌 정확성을 사용한다. 달리 언급되지 않는 한, 이 섹션 전체에 걸쳐 보고된 임의의 점수는 균형 잡힌 정확도를 지칭한다.\n' +
      '\n' +
      '## 5 실험 설정\n' +
      '\n' +
      '### Baselines\n' +
      '\n' +
      'SaulLM-7B 계열을 다른 최첨단 \\(7\\)B 및 \\(13\\)B 오픈 소스 모델과 비교한다. 구체적으로, Mistral-7B Jiang et al. (2023): Mistral-7B-Instruct-v0.1, Mistral-7B-Instruct-v0.2, 및 zephyr-7b-beta17을 포함한다. 또한 Llama2 Touvron et al. (2023) 패밀리, 보다 구체적으로 Llama2-7b-Chatand Llama2-13b-Chat를 평가한다.\n' +
      '\n' +
      '각주 17: [https://huggingface.co/HuggingFaceH4/zephyr-7b-beta](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta)\n' +
      '\n' +
      '### Implementation Details\n' +
      '\n' +
      '코드베이스는 오픈소스 프레임워크인 Shoeybi et al. (2019); Wolf et al. (2019); Lhoest et al. (2021) utilizing DeepSpeed (level 3) with Flash attention Dao et al. (2022); Dao (2023). PyTorch Paszke 등(2019)에 구축되었으며, 당사 모델은 Huggingface 허브에서 사용할 수 있습니다.\n' +
      '\n' +
      'ComputeContinuous preraining은 \\(256\\) MI250 AMD GPU를 활용한다. 명령어 미세 조정을 위해 16 MI250에 걸쳐 워크로드 분산이 발생한다. 평가 절차는 단일 MI250에 대해 원활하게 수행된다.\n' +
      '\n' +
      '## 6 Results\n' +
      '\n' +
      '이 섹션에서는 주요 실험 결과와 결과에 대해 논의한다.\n' +
      '\n' +
      '### LegalBench-Instruct\n' +
      '\n' +
      '그림 3과 4는 법률 벤치 지침에 대한 우리의 결과를 요약한다. 아래에서 논의하는 \\(3\\) 주요 테이크아웃이 있습니다.\n' +
      '\n' +
      '그림 3: **LegalBench-Instruct에서 기본 모델의 성능**. 흥미롭게도 지침이 미세 조정되지는 않았지만 SaulLM-7B는 SaulLM-7B의 초기 체크포인트(미스트랄-7B)를 포함한 다른 기본 모델과 비교하여 벤치마크에서 인상적인 개선을 달성할 수 있습니다.**\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{p{227.6pt}} \\hline \\hline\n' +
      '**Original Prompt** \\\\ \\hline The Telemarketing Sales Rule is provided by 16 C.F.R. \\$ 310.3(a)(1) \\\\ and 16 C.F.R. \\$ 310.3(a)(2). \\\\ \\hline \\hline\n' +
      '**Question:** Acme Toys is a telemarketter subject to the Telemarketing Sales Rule. Acme Toys told a customer that is fribhes cost $10 each, when in fact the fribhes cost $12 each. The customer agreed to the sale and was charged $12. Is this a violation of the Telemarketing Sales Rule? \\\\ \\hline\n' +
      '**Answer:** Yes \\\\ \\hline\n' +
      '**Question:** Acme Toys is a telemarketter subject to the Telemarketing Sales Rule. Acme Toys told a customer that is fribhes cost $10 each, when in fact the fribhes did cost $10, but Acme Toys did not disclose that shipping would cost an additional $5. The customer agreed to the sale. Is this a violation of the Telemarketing Sales Sales Rule? \\\\ \\hline\n' +
      '**Answer:** No \\\\ \\hline\n' +
      '**Question:** Acme Industrial Products is a telemarketter subject to the Telemarketing Sales Rule. Acme Industrial Products told a customer that is would sell them 4 brooms for $10 and that shipping would be $5. Then, the customer agreed to the sale. Is this a violation of the Telemarketing Sales Sales Rule? \\\\ \\hline\n' +
      '**Answer:** No \\\\ \\hline\n' +
      '**Question:** \\{text\\} \\\\ \\hline\n' +
      '**Dataset Prompt (Ours)** \\\\ \\hline The Telemarketing Sales Rule is provided by 16 C.F.R. \\$ 310.3(a)(1) and 16 C.F.R. \\$ 310.3(a)(2). \\\\ Answer the following question: \\{text\\} \\\\ _Answer by only capturing “Yes” or “No”_ \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: **LegalBench-Instruct의 예입니다. 7B 크기의 LLM을 산만하게 하는 것으로 밝혀짐에 따라 리걸벤치에서 몇 가지 짧은 예를 제거하여 수동으로 오타를 선별하고 수정했다. 법적 지속 사전 훈련은 제안된 지속 사전 훈련의 영향을 분석하는 것으로 시작하여 상당한 개선을 가져온다. 그림 3에서 볼 수 있듯이 SaulLM-7B는 강력한 독립형 모델이다. 3.1.1 서브섹션에서 언급한 바와 같이, 훈련 전 데이터 내의 명령어들의 통합에 의해 그 성능이 크게 기인한다고 추측한다. 그럼에도 불구하고, 전용 명령어 미세 조정 단계가 없더라도 SaulLM-7B는 Llama2-7B-chat (\\(0.38\\) v.s. \\(0.39\\))과 동등하게 수행된다는 점에 여전히 주목한다. 더 중요한 것은 SaulLM-7B가 강력한 법적 능력을 가진 IFT 모델을 구축하기 위한 강력한 기반 모델 역할을 한다는 것이다. 일반 명령 미세 조정과 결합하면 그림 4에서 볼 수 있듯이 최상의 오픈 소스 명령 모델 Mistral-7B-Instruct-v0.1에 대해 \\(0.59\\), 즉 \\(4\\) 절대 개선 지점을 강력하게 달성한다.\n' +
      '\n' +
      'II. 법률 명령 미세 조정은 그림 2에서 볼 수 있듯이 일반 및 법률 명령(SaulLM-7B-Instruct) 모두에서 SaulLM-7B를 미세 조정하면 LegalBench-Instruct 벤치마크에서 평균 점수 \\(0.61\\), 즉 최상의 오픈 소스 명령 모델에 비해 \\(11\\)% 상대적 개선으로 새로운 최첨단 기술을 확립한다(그림 5). 마지막으로 DPO 정렬 모델은 명령 조정 대응 작업을 과소 수행하는 경향이 있으며, 이는 일반 정렬이 LegalBench-Instruct에 존재하는 것과 같은 분배 외 작업에 적합하지 않다는 사실로 설명될 수 있다. 현재 작업의 범위를 벗어났지만 흥미로운 연구 방향은 법적 특정 DPO가 어떻게 도움이 될 수 있는지 탐구하는 것이다.\n' +
      '\n' +
      'III. 아직 상당한 개선의 여지가 있다. 다음으로, 우리는 원래의 법률 벤치(LegalBench)를 따른다.\n' +
      '\n' +
      '그림 4: **기본 모델의 영향** 기본 모델 SaulLM-7B에서 지침 미세 조정을 시작하는 것은 미스트랄-7B에 비해 눈에 띄는 개선을 가져온다. 실제로, (법적 없이) 일반적인 IFT 믹스에서도 SaulLM-7B(Gen.)는 Mistral-Instruct 대응물을 크게 능가한다. IFT 믹스에 법적 지침을 추가하면 결과가 더욱 향상됩니다.\n' +
      '\n' +
      '그림 5: **LegalBench-Instruct에 대한 지시 모델 비교**. SaulLM-7B-Intstruct는 최고의 미스트랄-Intstruct 모델을 상당한 6개의 절대 포인트만큼 능가하면서 최첨단 기술을 확립한다.\n' +
      '\n' +
      '분류학[14]은 SaulLM-7B-Intstruct의 수행에 대한 보다 세분화된 이해를 얻기 위해, \\(5\\) 핵심 법적 능력: 이슈 스포팅, 규칙-리콜, 해석, 수사학 이해, 규칙-결론으로 작업을 분할한다. 결과는 흥미로운 경향을 보여준다(그림 7). SaulLM-7B-Instruct는 가장 법적 전문성이 필요한 4가지 영역, 즉 이슈, 규칙, 해석 및 이해에 대해 최고의 비법적 경쟁자 Mistral-7B-Instruct-v0.1보다 분명한 우수한 성능을 보여준다. 반면, 결론 과제에서는 미스트랄-7B-인스트럭션-v0.1에 미치지 못하며, 이는 흥미롭게도 실제 법률 지식보다 훨씬 더 순수한 연역적 추론이 필요하다. 우리는 수학 데이터 세트를 포함하지만 이에 국한되지 않는 더 많은 연역적 추론 내용으로 사전 훈련 및 미세 조정 말뭉치를 보강하면 격차를 줄이고 SaulLM-7B-Instruct의 잠재력을 완전히 풀 수 있다고 추측한다.\n' +
      '\n' +
      '### 법적 MMLU에 대한 결과\n' +
      '\n' +
      'LegalBench-Instruct에 대한 우리의 관찰을 확인하기 위해 그림 6에 표시된 Legal-MMLU에 대한 결과를 분석한다. 다시, SaulLM-7B-Intstruct는 세 가지 작업에 걸쳐 최상의 7B 오픈 소스 경쟁자에 대해 \\(3\\)와 \\(4\\) 절대 포인트 사이의 갭으로 비법적 명령 조정 모델에 대해 일관된 우월성을 나타내며, SaulM-7B-Intstruct가 법적 워크플로우에 맞춘 모델을 구축하는 강력한 기반이라는 추가 증거를 제공한다.\n' +
      '\n' +
      '### Perplexity Analysis\n' +
      '\n' +
      'SaulLM-7B 백본의 법적 영역에 대한 적응을 평가하기 위해 계약, 법적 결정, 입법 및 당사자 제출의 4가지 문서 유형에 걸쳐 복잡성 점수를 제시한다. 결과는 그림 8을 참조하십시오. 우리의 모델 SaulLM-7B는 분산 감소와 함께 더 낮은 평균 복잡도 점수를 나타내어 모든 범주에서 미스트랄-7B를 일관되게 능가한다. 흥미롭게도 라마2-7B는 특히 입법 문서에서 더 낮은 복잡성을 보여주며, 이는 미스트랄-7B에 비해 관련 말뭉치에서 잠재적으로 더 높은 비율의 입법 텍스트를 시사한다.\n' +
      '\n' +
      '전반적으로, 미스트랄-7B와 비교하여, 우리 모델은 라마2-7B와 비교할 때 법적 말뭉치 전체에서 3%, 11%의 중간 복잡도 감소를 보여준다.\n' +
      '\n' +
      '7 Conclusion & Future Perspectives\n' +
      '\n' +
      '본 논문에서는 7B 모델과 비교하여 최신 성능을 제공하는 오픈 소스 디코더 모델인 SaulLM-7B를 법 영역 내에 소개한다. 우리의 접근법은 합성 데이터 세트에 대한 지침 미세 조정과 함께 법률 데이터를 미세 조정하는 것을 수반한다. 또한, 정제된 버전의 LegalBench를 제공하고 복잡도 측정을 위한 새로운 문서 세트를 도입하여 기여합니다. MIT 라이선스로 출시되는 저희 모델이 오픈소스 생태계와 커뮤니티에 기여하기를 바랍니다.\n' +
      '\n' +
      '그림 8: **사전 훈련된 백본에 대한 법률 문서의 복잡성** SaulLM-7B 지침은 대부분의 유형의 법률 문서에서 사전 훈련된 다른 백본보다 우수하지만 입법에서는 Llama2-7B보다 우수합니다. SaulLM-7B-Instruct는 Mistral-7B에 비해 \\(5.5\\)%, Llama2-7B에 비해 \\(9.20\\)%, \\(10.8\\)% 감소된 \\(8.69\\)의 중간 복잡도를 나타내며, \\(9.74\\)의 중간 복잡도를 나타낸다.\n' +
      '\n' +
      '그림 7: **작업별 성능 분류** SaulLM-7B-Instruct는 대부분 법적 특정 지식이 필요한 작업에 대해 일반 명령 모델을 능가하지만 결론 작업에 대해 미스트랄-Instruct를 능가하므로 더 많은 연역적 추론이 필요합니다.\n' +
      '\n' +
      '## Acknowledgments\n' +
      '\n' +
      '우리는 GENCI가 그들의 최첨단 컴퓨팅 자원에 대한 접근을 관대하게 허락해 준 것에 감사한다. 우리의 모델 SaulLM-7B는 장자이에 대한 초기 실험을 통해 ADASTRA에 대해 훈련되었다. HPC 자원의 활용은 장제이 보조금 101838, 103256, 103298과 아다스트라 보조금 C1615122, CAD14770, CAD15031을 통해 가능했다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Achiam 등(2023) Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. _ arXiv preprint arXiv:2303.08774_.\n' +
      '* Aletras 등(2016) Nikolaos Aletras, Dimitrios Tsarapatsanis, Daniel Preotiuc-Pietro, and Vasileios Lampos. 2016. 유럽 인권 법원의 사법 결정을 예측하는 것: 자연어 처리 관점. _ PeerJ computer science_, 2:e93.\n' +
      '* Almazrorouei et al. (2023) Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Hesslow, Julien Launay, Quentin Malartic, Daniele Mazzotta, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023. The falcon series of open language models.\n' +
      '* Anil 등(2023) Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. 2023. Palm 2 technical report. _ arXiv preprint arXiv:2305.10403_.\n' +
      '*바이 외 (2023) 진제 바이, 슈아이 바이, 윤페이 추, 즈위 추이, 카이 당, 샤오동 덩, 양판, 원빈 거, 유한, 페이 황, 비위안 후이, 뤄지, 메이 리, 준양 린, 런지 린, 다이헝 류, 가오 류, 첸광 루, 케밍 루, 지안 마, 루이 멘, 싱장런, 쑤안청런, 쑹쑹쑹, 쑹쑹쑹쑹, 쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹쑹 2023. Qwen 기술 보고서.\n' +
      '* Biderman 등(2023) Stella Biderman, Hailey Schoelkopf, Quentin Gregory Anthony, Herbie Bradley, Kyle O\'Brien, Eric Hallahan, Mohammad Afah Khan, Shivanshu Purohit, USVSN Sai Prashanth, Edward Raff, et al. 2023. Pythia: A suite for analyzing large language models across training and scaling. [국제 기계 학습 회의]에서 2397-2430 페이지, PMLR.\n' +
      '* Briakou 등(2023) Eleftheria Briakou, Colin Cherry, and George Foster. 2023. 건초더미에서 바늘 찾기: 손바닥의 번역 능력에서 부수적인 이중 언어 사용의 역할에 대해 _ arXiv preprint arXiv:2305.10266_.\n' +
      '* Butler (2023) Umar Butler. 2023호주의 법률 코퍼스를 열어요\n' +
      '* Cao et al.(2023) Yihan Cao, Yanbin Kang, and Lichao Sun. 2023. 명령어 마이닝: 대용량 언어 모델에 대한 고품질 명령어 데이터 선택 _ arXiv preprint arXiv:2307.06290_.\n' +
      '* Chalkidis 등(2019) Ilias Chalkidis, Ion Androutsopoulos, and Nikolaos Aletras. 2019. Neural legal judgment prediction in English. _ arXiv preprint arXiv:1906.02059_.\n' +
      '* Chalkidis 등(2020) Ilias Chalkidis, Manos Fergadiots, Prodromos Malakasiotis, Nikolaos Aletras, and Ion Androutsopoulos. 2020년 로스쿨을 졸업한 머펫들 arXiv preprint arXiv:2010.02559_.\n' +
      '* Chen 등(2023) Zeming Chen, Alejandro Hernandez Cano, Angelika Romanou, Antoine Bonnet, Kyle Matoba, Francesco Salvi, Matteo Pagliardini, Simin Fan, Andreas Kopf, Amrikeivan Mohtashami, et al. 2023. Meditron-70b: Scaling medical pretraining for large language models. _ arXiv preprint arXiv:2311.16079_.\n' +
      '*Cheng et al.(2023) Daixuan Cheng, Shaohan Huang, and Furu Wei. 2023. 읽기 이해 기능을 통해 대용량 언어 모델을 적용합니다. _ arXiv preprint arXiv:2309.09530_.\n' +
      '* Chung et al.(2022) Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022. Scaling instruction-finetuned language models. _ arXiv preprint arXiv:2210.11416_.\n' +
      '* Computer (2023)Together Computer. 2023. Redpajama: 대규모 언어 모델을 훈련하기 위한 오픈 데이터 세트입니다.\n' +
      '* Cui et al. (2023) Jiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and Li Yuan. 2023. Chatlaw: Open-source legal large language model with integrated external knowledge base. _ arXiv preprint arXiv:2306.16092_.\n' +
      '* Dao(2023) Tri Dao. 2023. Flashattention-2: 더 나은 병렬 처리 및 작업 분할로 더 빠른 주의 arXiv preprint arXiv:2307.08691_.\n' +
      '* Dao et al.(2022) Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Re. 2022. Flashattention: io-awareness로 빠르고 메모리 효율적인 정확한 주의력. _ Advances in Neural Information Processing Systems_, 35:16344-16359.\n' +
      '* Ding 등 (2023) Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong Sun, and Bowen Zhou. 2023. 고품질 교육 대화를 확장하여 채팅 언어 모델을 향상시킵니다. _ arXiv preprint arXiv:2305.14233_.\n' +
      '* Elazar et al. (2023) Yanai Elazar, Akshita Bhagia, Ian Magnusson, Abhilasha Ravichander, Dustin Schwenk, Alane Suhr, Pete Walsh, Dirk Groeneveld, Luca Soldaini, Sameer Singh, Hanna Hajishirzi, Noah A. Smith, and Jesse Dodge. 2023. 내 빅 데이터에 무엇이 있나요?Manuel Faysse, Patrick Fernandes, Nuno Guerreiro, Antonio Loison, Duarte Alves, Caio Corro, Nicolas Boizard, Joao Alves, Ricardo Rei, Pedro Martins, et al. 2024. Croissantllm: 진정한 이중 언어 프랑스-영어 언어 모델. _ arXiv preprint arXiv:2402.00786_.\n' +
      '* Faysse et al. (2023) Manuel Faysse, Gautier Viaud, Celine Hudelot, and Pierre Colombo. 2023. Invisiting instruction fine-tuned model evaluation to guide industrial applications. 2023년 자연 언어 처리의 경험적 방법에 관한 회의의 회보에서. 계산 언어학 협회\n' +
      '* Gao 등(2020) Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. 2020. The pile: 800gb dataset of various text for language modeling.\n' +
      '* Gu and Dao (2023) Albert Gu and Tri Dao. 2023. Mamba: 선택적 상태 공간을 갖는 선형-시간 시퀀스 모델링 _ arXiv preprint arXiv:2312.00752_.\n' +
      '* Guha et al. (2022) Neel Guha, Daniel E Ho, Julian Nyarko, and Christopher Re. 2022년 법률 벤치마크: 법적 추론을 위한 협력 벤치마크를 프로토타입화합니다. _ arXiv preprint arXiv:2209.06120_.\n' +
      '* Guha et al. (2023) Neel Guha, Julian Nyarko, Daniel E Ho, Christopher Re, Adam Chilton, Aditya Narayana, Alex Chohlas-Wood, Austin Peters, Brandon Waldon, Daniel N Rockmore, et al. 2023. Legalbench: A collaboratively built benchmark for measuring legal reasoning in large language models _ arXiv preprint arXiv:2308.11462_.\n' +
      '* Gururangan 등(2020) Suchin Gururangan, Ana Marasovic, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, and Noah A Smith. 2020. 사전 교육을 멈추지 마십시오. 언어 모델을 도메인 및 작업에 적용합니다. _ arXiv preprint arXiv:2004.10964_.\n' +
      '* Gutierrez-Fandino 등(2021) Asier Gutierrez-Fandino, Jordi Armengol-Estape, Aitor Gonzalez-Agirre, and Marta Villegas. 2021. 스페인어 법률 언어 모델 및 말뭉치. _ arXiv preprint arXiv:2110.12201_.\n' +
      '* Heafield (2011) Kenneth Heafield. 2011. KenLM: Faster and smaller language model queries. 《통계 기계 번역에 관한 제6차 워크숍》에서 스코틀랜드 에든버러의 187-197쪽이다. 계산 언어학 협회\n' +
      '* Henderson et al.(2022) Peter Henderson, Mark Krass, Lucia Zheng, Neel Guha, Christopher D Manning, Dan Jurafsky, and Daniel Ho. 2022. 법률 파일: 법률에서 책임 있는 데이터 필터링과 256gb 오픈 소스 법률 데이터 세트를 학습합니다. _ Neural Information Processing Systems_, 35:29217-29234에서의 진보.\n' +
      '* Hendrycks 등(2020) Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020. 대용량 멀티태스킹 언어 이해도 측정. _ arXiv preprint arXiv:2009.03300_.\n' +
      '* Islam 등(2023) Niful Islam, Debopom Sutradhar, Humaira Noor, Jarin Tasnim Raya, Monowara Tabassum Maisha, and Dewan Md Farid. 2023. 기계 학습을 사용하여 인간 생성 텍스트와 채팅 생성 텍스트를 구별하는 단계 _ arXiv preprint arXiv:2306.01761_.\n' +
      '* Ji et al. (2023) Shaoxiong Ji, Tianlin Zhang, Kailai Yang, Sophia Ananiadou, Erik Cambria, and Jorg Tiedemann. 2023. 도메인별 언어 모델 사전 훈련을 계속하여 정신 건강의 긴 맥락을 포착합니다. _ arXiv preprint arXiv:2304.10447_.\n' +
      '* Jiang et al.(2023) Albert Q. 장, 알렉산드르 사블레이롤, 아서 멘쉬, 크리스 뱀포드, 데벤드라 싱 채플롯, 디에고 드 라스 카사스, 플로리안 브레산드, 지안나 랭글, 기욤 람플, 루실라 사울니에, 렐리오 레나르 라부드, 마리 앤 라쇼, 피에르 스톡, 테벤 르 스카오, 티보 라브릴, 토마스 왕, 티모티 라크루아, 윌리엄 엘 세이드. 2023. 미스트랄 7b.\n' +
      '* Jiang et al.(2024) Albert Q. 장, 알렉산드르 사블라롤레스, 앙투안 루, 아서 멘쉬, 블랑슈 사바리, 크리스 뱀포드, 데벤드라 싱 채플롯, 디에고 드 라스 카사스, 엠마 부 한나, 플로리안 브레산드, 지아나 렝야엘, 기욤 부르, 기욤 람플, 엘리오 레나르 라부드, 루실레 사울니에, 마리안 라쇼, 피에르 스톡, 산딥 수브라만안, 소피아 양, 시몬 안토니악, 테벤 르 스카오, 테오필레 거베트, 티보 라브릴, 토마스 왕, 티모티 라크루아, 윌리엄 엘 세이드. 2024. 전문가들의 혼합물.\n' +
      '* Katz et al. (2023) Daniel Martin Katz, Michael James Bommarito, Shang Gao, and Pablo Arredondo. 2023. Gpt-4는 변호사 시험에 합격합니다. _ SSRN 4389233_에서 사용할 수 있습니다.\n' +
      '* Koetkov 등(2023) Denis Koetkov, Raymond Li, Loubna Ben Allal, Jia LI, Chenghao Mou, Yacine Jernite, Margaret Mitchell, Carlos Munoz Ferrandis, Sean Hughes, Thomas Wolf, Dzmitry Bahdanau, Leandro Von Werra, and Harm de Vries. 2023. 스택: 허용 라이선스 소스 코드 3TB. _ Machine Learning Research에 대한 트랜잭션_.\n' +
      '* Koehn(2005) Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. <기계번역 서밋 X: 논문>의 79-86 페이지, 태국 푸켓.\n' +
      '* Lee et al.(2021) Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and Nicholas Carlini. 2021. 학습 데이터를 복제하면 언어 모델이 더 좋아집니다. _ arXiv preprint arXiv:2107.06499_.\n' +
      '* Lhoest 등(2021) Quentin Lhoest, Albert Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil, Julien Chaumond, Mariama Drame, Julien Plu, Lewis Tunstall, et al. 2021. Datasets: A community library for natural language processing _ arXiv preprint arXiv:2109.02846_.\n' +
      '* Li et al.(2020) Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Koetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poiri, Joao Monteiro, Oleh Shliazhko, Nicolas Gontier, Ming-Ho Yee, Logesh Kumar Obolkov, Ziruo Wang, Rudra Murthy, Jason Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Manhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Bhattacharyya, Manhao Yu, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger 2023. 스타코더: 출처가 여러분과 함께하기를!\n' +
      '* Lian 등(2023) Wing Lian, Guan Wang, Bleys Goodson, Eugene Pentland, Austin Cook, Chanvichet Vong, and "Teknium". 2023. Slimorca: gpt-4 확장 플란 추론 추적의 열린 데이터 세트, 검증.\n' +
      '* Licari and Comande (2022) Daniele Licari and Giovanni Comande. 2022. 이탈리아 법-버트: 이탈리아 법을 위한 사전 훈련된 변압기 언어 모델. {CEUR Workshop Proceedings (Ed.), The Knowledge Management for Law Workshop (KM4LAW)]_\n' +
      '* Longpre 등(2023) Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay, Denny Zhou, Quoc V Le, Barrett Zoph, Jason Wei, et al. 2023. The flan collection: Designing data and methods for effective instruction tuning _ arXiv preprint arXiv:2301.13688_.\n' +
      '* Lu et al. (2023) Keming Lu, Peter Potash, Xihui Lin, Yuwen Sun, Zihan Qian, Zheng Yuan, Tristan Naumann, Tianxi Cai, and Junwei Lu. 2023. 도메인 적응을 위한 신속한 판별 언어 모델. 제5회 임상 자연어 처리 워크샵의 회보 247-258페이지입니다.\n' +
      '* Ma et al. (2023) Yingwei Ma, Yue Liu, Yue Yu, Yuanliang Zhang, Yu Jiang, Changjian Wang, and Shanshan Li. 2023. 코드 데이터는 어느 훈련 단계에서 l1ms 추론에 도움이 됩니까?\n' +
      '* Martin 등(2024) Lauren Martin, Nick Whitehouse, Stephanie Yiu, Lizzie Catterson, and Rivindu Perera. 2024. Gpt를 불러 대형 언어 모델을 변호사와 비교하는 것이 좋습니다. _ arXiv preprint arXiv:2401.16212_.\n' +
      '* McCloskey and Cohen (1989) Michael McCloskey and Neal J. Cohen. 1989. Catastrophic interference in connectionist networks: The sequential learning problem. 《학습과 동기의 심리학》 24쪽, 109-165쪽, 학술지》\n' +
      '* Mitchell 등(2023) Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D Manning, and Chelsea Finn. 2023. Detectgpt: 확률 곡률을 이용한 제로샷 머신 생성 텍스트 검출 _ arXiv preprint arXiv:2301.11305_.\n' +
      '* Mou et al.(2023) Chenghao Mou, Chris Ha, Kenneth Enevoldsen, and Peiyuan Liu. 2023. Chenghaomou/text-dedup: Reference snapshot.\n' +
      '* Mukherjee 등(2023) Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. 2023. Orca: gpt-4의 복잡한 설명 흔적으로부터 점진적인 학습.\n' +
      '* Munos 등(2023) Remi Munos, Michal Valko, Daniele Calandriello, Mohammad Gheshlaghi Azar, Mark Rowland, Zhaohan Daniel Guo, Yunhao Tang, Matthieu Geist, Thomas Mesnard, Andrea Michi, et al. 2023. Nash learning from human feedback. _ arXiv preprint arXiv:2312.00886_.\n' +
      '* Niklaus et al. (2021) Joel Niklaus, Ilias Chalkidis, and Matthias Sturmer. 2021. 스위스-판단-예측: 다국어 법률 판단 예측 벤치마크. _ arXiv preprint arXiv:2110.00806_.\n' +
      '* Niklaus and Giofre (2022) Joel Niklaus and Daniele Giofre. 2022년 예산 연장자: 처음부터 소타 법률 언어 모델을 저렴하게 사전 훈련할 수 있습니까? _ arXiv preprint arXiv:2211.17135_.\n' +
      '* Niklaus and Giofre (2023) Joel Niklaus and Daniele Giofre. 2023. 우리는 처음부터 예산으로 소타 법률 언어 모델을 미리 훈련시킬 수 있습니까? 계산 언어학 협회\n' +
      '* Niklaus et al. (2023) Joel Niklaus, Veton Matoshi, Matthias Sturmer, Ilias Chalkidis, and Daniel E. Ho. 2023. Multilegalpile: 689gb 다국어 법률 코퍼스.\n' +
      '* Nishida et al.(2019) Kosuke Nishida, Kyosuke Nishida, Itsumi Saito, Hisako Asano, and Junji Tomita. 2019. Unsupervised domain adaptation of language models for reading comprehension. _ arXiv preprint arXiv:1911.10768_.\n' +
      '* Paszke 등(2019) Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. 2019. Pytorch: An imperative style, high-performance deep learning library. _ 신경 정보 처리 시스템의 진보_, 32.\n' +
      '* Penedo et al. (2023) Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. 2023. 매 11m에 대한 정제된 웹 데이터 세트: 웹 데이터 및 웹 데이터만으로 큐레이트된 말뭉치를 능가합니다. _ arXiv preprint arXiv:2306.01116_.\n' +
      '* Prakken (2013) Henry Prakken. 2013. _논리적인 도구 법적 논증을 모델링하기 위한 도구: 법률에서 불합리한 추론에 대한 연구_, 32권 스프링어 사이언스 & 비즈니스 미디어.\n' +
      '*Radford et al. (2022) Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. 2022. 대규모 약한 감독을 통한 강건한 음성 인식.\n' +
      '* Rafailov et al. (2023) Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D Manning, and Chelsea Finn. 2023. 직접 선호도 최적화: 언어 모델은 비밀리에 보상 모델입니다. _ arXiv preprint arXiv:2305.18290_.\n' +
      '* Roziere et al.(2023) Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jeremy Rapin, et al. 2023. Code llama: Open foundation models for code _ arXiv preprint arXiv:2308.12950_.\n' +
      '* Savelka et al. (2023) Jaromir Savelka, Kevin D Ashley, Morgan A Gray, Hannes Westermann, and Huihui Xu. 2023. 확장된 대형 언어 모델(gpt-4)로 법적 개념을 설명합니다. _ arXiv preprint arXiv:2306.09525_.\n' +
      '* De Scao 등(2022) Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel Hesslow, Roman Castagne, Alexandra Sasha Luccioni, Francois Yvon, Matthias Galle, et al. 2022. Bloom: A 176b-parameter open-access multilingual language model. _ arXiv preprint arXiv:2211.05100_.\n' +
      '* Shen et al. (2023) Zhiqiang Shen, Tianhua Tao, Liqun Ma, Willie Neiswanger, Joel Hestness, Natalia Vassilieva, Daria Soboleva, and Eric Xing. 2023. Slimpajama-dc: llvm 훈련에 대한 데이터 조합을 이해합니다. _ arXiv preprint arXiv:2309.10818_.\n' +
      '* Shoeybi et al. (2019) Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. 2019. 메가트론-lm: 모델 병렬성을 사용하여 수십억 개의 매개 변수 언어 모델을 학습합니다. _ arXiv preprint arXiv:1909.08053_.\n' +
      '* Soboleva et al. (2023) Daria Soboleva, Faisal Al-Khateeb, Robert Myers, Jacob R Steeves, Joel Hestness, and Nolan Dey. 2023. Slimpajama: 627b token clean and deduplicated version of redrojama.\n' +
      '* Sun et al.(2020) Jingyuan Sun, Shaonan Wang, Jiajun Zhang, and Chengqing Zong. 2020. 지속적인 언어 학습을 위한 증류 및 재생. 계산 언어학에 관한 제28차 국제 회의의 회의록 3569-3579쪽입니다.\n' +
      '* Taylor et al.(2022) Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic. 2022. Galactica: 과학을 위한 대형 언어 모델. _ arXiv preprint arXiv:2211.09085_.\n' +
      '* Touvron 등(2023a) Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023a. 라마: 개방적이고 효율적인 기초 언어 모델입니다. _ arXiv preprint arXiv:2302.13971_.\n' +
      '* 투브론 외 (2020) 우고 투브론, 루이 마틴, 케빈 스톤, 피터 알버트, 암자드 알마하리, 야스민 바바이, 니콜라이 바슐리코프, 수미 바트라, 프라지왈 바바, 슈루티 보살레, 단 비켈, 루카스 블레처, 크리스티안 칸톤 페러, 모야 첸, 기옌 쿠쿠룰, 다비드 에시부우, 주드 페르난데스, 제레미 푸, 웨닌 푸, 주드 페르난데스, 제르티아 가오, 사가하르 호세이니, 루이 호우, 하칸 이난, 마르신 카다스, 빅토르 케르케즈, 마디안 하바사, 이사벨 클루만, 아르템 고레네프, 신시아 가오, 베다누즈, 사그하르 호세이니, 루이 호우, 하칸 이난, 마르신 카다스, 빅토르 케르케즈, 마디안 카다스, 마디안 라쇼, 사그하르 호세이니, 제냐 리, 다이애나 리스코비치, 잉하이 루, 2023b. 라마 2: 오픈 파운데이션과 미세 조정된 채팅 모델입니다.\n' +
      '* Tuggener et al.(2020) Don Tuggener, Pius Von Daniken, Thomas Peetz, and Mark Cieliebak. 2020. Ledgar: A large-scale multi-label corpus for text classification of legal provisions in contract. 1235-1241 페이지의 12번째 언어 자원 및 평가 회의 회보입니다.\n' +
      '* Tunstall 등(2023) Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazzeen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clementine Fourrier, Nathan Habib, et al. 2023. Zephyr: Direct distillation of lm alignment. _ arXiv preprint arXiv:2310.16944_.\n' +
      '* von Werra et al.(2020) Leandro von Werra, Younes Belkada, Lewis Tunstall, Edward Beeching, Tristan Thrush, Nathan Lambert, and Shengyi Huang. 2020. Trl: Transformer reinforcement learning. [https://github.com/huggingface/trl] (https://github.com/huggingface/trl).\n' +
      '* Vu et al.(2020) Thuy-Trang Vu, Dinh Phung, and Gholamreza Haffari. 2020. 적대적으로 훈련된 언어 모델을 사용한 효과적인 비지도 도메인 적응입니다. _ arXiv preprint arXiv:2010.01739_.\n' +
      '* Wang et al. (2023) Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi Raghavich Chandu, David Wadden, Kelsey MacMillan, Noah A Smith, Iz Beltagy, et al. 2023a. 낙타는 어디까지 갈 수 있나요? 오픈 리소스에서 명령어 튜닝 상태를 탐색합니다. _ arXiv preprint arXiv:2306.04751_.\n' +
      '* Wang et al. (2023) Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023b. 자체 지침: 언어 모델을 자체 생성 지침과 정렬합니다.\n' +
      '* Wang et al.(2022) Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. 2022. Super-natural instructions: Generalization via declative instructions on 1600+ nlp tasks. _ arXiv preprint arXiv:2204.07705_.\n' +
      '* Weber-Wulff et al. (2023) Debora Weber-Wulff, Alla Anohina-Naumeca, Sonja Bjelobaba, Tomas Foltynek, Jean Guerrero-Dib, Olumide Popoola, Petr Sigut, and Loma Waddington. 2023. 테스팅 of detection tools for ai-generated text. _ International Journal for Educational Integrity_, 19(1):26.\n' +
      '\n' +
      'Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, Quoc V Le. 2021. 파인튜닝 언어 모델은 제로샷 학습자입니다. _ arXiv preprint arXiv:2109.01652_.\n' +
      '* Wolf 등(2019) Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, et al. 2019. Huggingface\'s Transformers: State-of-the-the-art natural language processing _ arXiv preprint arXiv:1910.03771_.\n' +
      '* Wu 등 (2024) Minghao Wu, Thuy-Trang Vu, Lizhen Qu, George Foster, and Gholamreza Haffari. 2024. 문서 수준 기계 번역에 대 언어 모델을 적용합니다. _ arXiv preprint arXiv:2401.06468_.\n' +
      '* Xiao et al.(2021) Chaojun Xiao, Xueyu Hu, Zhiyuan Liu, Cunchao Tu, and Maosong Sun. 2021. Lawformer: 중국 법률 장문 문서에 대한 사전 훈련된 언어 모델입니다. _ AI Open_, 2:79-84.\n' +
      '*Xu et al.(2023) Haoran Xu, Young Jin Kim, Amr Sharaf, and Hany Hassan Awadalla. 2023. 기계 번역의 패러다임 전환: 대형 언어 모델의 번역 성능을 향상시킵니다. _ arXiv preprint arXiv:2309.11674_.\n' +
      '*Yao et al.(2021) Yunzhi Yao, Shaohan Huang, Wenhui Wang, Li Dong, and Furu Wei. 2021. Adapt-and-distill: 도메인에 대한 작고 빠르고 효과적인 사전 훈련 언어 모델 개발 _ arXiv preprint arXiv:2106.13474_.\n' +
      '* Yu et al. (2023) Longhui Yu, Weisen Jang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023. 메타매스: 대용량 언어 모델에 대한 자신의 수학적 질문을 부트스트랩합니다. _ arXiv preprint arXiv:2309.12284_.\n' +
      '* Zhang 등(2024) Peiyuan Zhang, Guangtao Zeng, Tianduo Wang, and Wei Lu. 2024. Tinyllama: 오픈소스 소형 언어 모델. _ arXiv preprint arXiv:2401.02385_.\n' +
      '* Zhang 등(2022) Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022. Opt: Open pre-trained transformer language models. _ arXiv preprint arXiv:2205.01068_.\n' +
      '* Zhou 등(2023) Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. 2023. Lima: Less is more for alignment _ arXiv preprint arXiv:2305.11206_.\n' +
      '* Zhou et al.(2021)\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>