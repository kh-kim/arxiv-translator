<html lang="en" data-theme="light"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>SaulLM-7B: A pioneering Large Language Model for Law</title>
<!--Generated on Thu Mar  7 06:39:35 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css">
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2403.03883v2/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2403.03883v2">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <span class="color-scheme-icon" aria-label="Light mode"></span>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="#myForm" onclick="event.preventDefault(); var modal = document.getElementById('myForm'); modal.style.display = 'block'; bugReportState.setInitiateWay('Header');">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2403.03883v2">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2403.03883v2" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
          <span class="color-scheme-icon"></span>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S1" title="1 Introduction ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S1.SS0.SSS0.Px1" title="Contribution 1: A family of legal LLMs. ‣ 1 Introduction ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Contribution 1: A family of legal LLMs.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S1.SS0.SSS0.Px2" title="Contribution 2: An improved evaluation protocol for legal LLMs. ‣ 1 Introduction ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Contribution 2: An improved evaluation protocol for legal LLMs.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S1.SS0.SSS0.Px3" title="Contribution 3: Model, Evaluation Code &amp; Licensing. ‣ 1 Introduction ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Contribution 3: Model, Evaluation Code &amp; Licensing.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S2" title="2 SaulLM-7B: Extending the legal capabilities of Language Models ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span><span class="ltx_text ltx_font_typewriter">SaulLM-7B</span>: Extending the legal capabilities of Language Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S2.SS1" title="2.1 Enhancing Mistral’s Legal Capabilities ‣ 2 SaulLM-7B: Extending the legal capabilities of Language Models ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Enhancing Mistral’s Legal Capabilities</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S2.SS2" title="2.2 Improving Legal Instruction Following ‣ 2 SaulLM-7B: Extending the legal capabilities of Language Models ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Improving Legal Instruction Following</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3" title="3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Data</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1" title="3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Legal Pretraining Corpora</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS1" title="3.1.1 Dataset Composition ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Dataset Composition</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS1.Px1" title="Legal Sources ‣ 3.1.1 Dataset Composition ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Legal Sources</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS1.Px2" title="Replay Sources ‣ 3.1.1 Dataset Composition ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Replay Sources</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS1.Px3" title="Instruction Sources ‣ 3.1.1 Dataset Composition ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Instruction Sources</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS2" title="3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Data Cleaning</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS2.Px1" title="Text Normalization ‣ 3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Text Normalization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS2.Px2" title="Rule filters ‣ 3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Rule filters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS2.Px3" title="Perplexity filtering ‣ 3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Perplexity filtering</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS3" title="3.1.3 Data Deduplication ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.3 </span>Data Deduplication</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS2" title="3.2 Instruction Finetuning Mixes ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Instruction Finetuning Mixes</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS2.SSS0.Px1" title="General Instructions ‣ 3.2 Instruction Finetuning Mixes ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">General Instructions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS2.SSS0.Px2" title="Legal Instruction Construction ‣ 3.2 Instruction Finetuning Mixes ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Legal Instruction Construction</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S4" title="4 Evaluation of Legal Knowledge ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Evaluation of Legal Knowledge</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S4.SS0.SSS0.Px1" title="Perplexity Measurement ‣ 4 Evaluation of Legal Knowledge ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Perplexity Measurement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S4.SS0.SSS0.Px2" title="Massive Multitask Language Understanding (MMLU) ‣ 4 Evaluation of Legal Knowledge ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Massive Multitask Language Understanding (MMLU)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S4.SS1" title="4.1 Metrics ‣ 4 Evaluation of Legal Knowledge ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S5" title="5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experimental Setting</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S5.SS1" title="5.1 Baselines ‣ 5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Baselines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S5.SS2" title="5.2 Implementation Details ‣ 5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Implementation Details</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S5.SS2.SSS0.Px1" title="Codebase ‣ 5.2 Implementation Details ‣ 5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Codebase</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S5.SS2.SSS0.Px2" title="Compute ‣ 5.2 Implementation Details ‣ 5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Compute</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6" title="6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.SS1" title="6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>LegalBench-Instruct</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.SS1.SSS0.Px1" title="I. Legal continued pretraining brings significant improvements ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">I. Legal continued pretraining brings significant improvements</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.SS1.SSS0.Px2" title="II. Legal instruction finetuning further boosts the results ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">II. Legal instruction finetuning further boosts the results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.SS1.SSS0.Px3" title="III. There is still room for significant improvement. ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">III. There is still room for significant improvement.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.SS2" title="6.2 Results on Legal-MMLU ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Results on Legal-MMLU</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.SS3" title="6.3 Perplexity Analysis ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Perplexity Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S7" title="7 Conclusion &amp; Future Perspectives ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion &amp; Future Perspectives</span></a></li>
</ol></nav>

<div class="ltx_page_content">
<div aria-label="Conversion errors have been found" class="package-alerts ltx_document" role="status">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewBox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: inconsolata</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><div class="section" id="target-section"><div id="license-tr">License: CC BY 4.0</div><div id="watermark-tr">arXiv:2403.03883v2 [cs.CL] 07 Mar 2024</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">
<span class="ltx_text ltx_font_typewriter" id="id17.id1">SaulLM-7B</span>: A pioneering Large Language Model for Law</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pierre Colombo<math alttext="{}^{1,2,*}" class="ltx_Math" display="inline" id="id1.1.m1.3"><semantics id="id1.1.m1.3a"><msup id="id1.1.m1.3.3" xref="id1.1.m1.3.3.cmml"><mi id="id1.1.m1.3.3a" xref="id1.1.m1.3.3.cmml"></mi><mrow id="id1.1.m1.3.3.3.5" xref="id1.1.m1.3.3.3.4.cmml"><mn id="id1.1.m1.1.1.1.1" xref="id1.1.m1.1.1.1.1.cmml">1</mn><mo id="id1.1.m1.3.3.3.5.1" xref="id1.1.m1.3.3.3.4.cmml">,</mo><mn id="id1.1.m1.2.2.2.2" xref="id1.1.m1.2.2.2.2.cmml">2</mn><mo id="id1.1.m1.3.3.3.5.2" rspace="0em" xref="id1.1.m1.3.3.3.4.cmml">,</mo><mo id="id1.1.m1.3.3.3.3" lspace="0em" xref="id1.1.m1.3.3.3.3.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="id1.1.m1.3b"><apply id="id1.1.m1.3.3.cmml" xref="id1.1.m1.3.3"><list id="id1.1.m1.3.3.3.4.cmml" xref="id1.1.m1.3.3.3.5"><cn id="id1.1.m1.1.1.1.1.cmml" type="integer" xref="id1.1.m1.1.1.1.1">1</cn><cn id="id1.1.m1.2.2.2.2.cmml" type="integer" xref="id1.1.m1.2.2.2.2">2</cn><times id="id1.1.m1.3.3.3.3.cmml" xref="id1.1.m1.3.3.3.3"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.3c">{}^{1,2,*}</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.3d">start_FLOATSUPERSCRIPT 1 , 2 , * end_FLOATSUPERSCRIPT</annotation></semantics></math>  Telmo Pessoa Pires<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="id2.2.m2.2"><semantics id="id2.2.m2.2a"><msup id="id2.2.m2.2.2" xref="id2.2.m2.2.2.cmml"><mi id="id2.2.m2.2.2a" xref="id2.2.m2.2.2.cmml"></mi><mrow id="id2.2.m2.2.2.2.4" xref="id2.2.m2.2.2.2.3.cmml"><mn id="id2.2.m2.1.1.1.1" xref="id2.2.m2.1.1.1.1.cmml">1</mn><mo id="id2.2.m2.2.2.2.4.1" rspace="0em" xref="id2.2.m2.2.2.2.3.cmml">,</mo><mo id="id2.2.m2.2.2.2.2" lspace="0em" xref="id2.2.m2.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="id2.2.m2.2b"><apply id="id2.2.m2.2.2.cmml" xref="id2.2.m2.2.2"><list id="id2.2.m2.2.2.2.3.cmml" xref="id2.2.m2.2.2.2.4"><cn id="id2.2.m2.1.1.1.1.cmml" type="integer" xref="id2.2.m2.1.1.1.1">1</cn><times id="id2.2.m2.2.2.2.2.cmml" xref="id2.2.m2.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math>  Malik Boudiaf<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="id3.3.m3.2"><semantics id="id3.3.m3.2a"><msup id="id3.3.m3.2.2" xref="id3.3.m3.2.2.cmml"><mi id="id3.3.m3.2.2a" xref="id3.3.m3.2.2.cmml"></mi><mrow id="id3.3.m3.2.2.2.4" xref="id3.3.m3.2.2.2.3.cmml"><mn id="id3.3.m3.1.1.1.1" xref="id3.3.m3.1.1.1.1.cmml">1</mn><mo id="id3.3.m3.2.2.2.4.1" rspace="0em" xref="id3.3.m3.2.2.2.3.cmml">,</mo><mo id="id3.3.m3.2.2.2.2" lspace="0em" xref="id3.3.m3.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="id3.3.m3.2b"><apply id="id3.3.m3.2.2.cmml" xref="id3.3.m3.2.2"><list id="id3.3.m3.2.2.2.3.cmml" xref="id3.3.m3.2.2.2.4"><cn id="id3.3.m3.1.1.1.1.cmml" type="integer" xref="id3.3.m3.1.1.1.1">1</cn><times id="id3.3.m3.2.2.2.2.cmml" xref="id3.3.m3.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.3.m3.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="id3.3.m3.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math>
<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="id4.4.1">Dominic Culver<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="id4.4.1.m1.2"><semantics id="id4.4.1.m1.2a"><msup id="id4.4.1.m1.2.2" xref="id4.4.1.m1.2.2.cmml"><mi id="id4.4.1.m1.2.2a" xref="id4.4.1.m1.2.2.cmml"></mi><mrow id="id4.4.1.m1.2.2.2.4" xref="id4.4.1.m1.2.2.2.3.cmml"><mn id="id4.4.1.m1.1.1.1.1" mathvariant="normal" xref="id4.4.1.m1.1.1.1.1.cmml">1</mn><mo id="id4.4.1.m1.2.2.2.4.1" mathvariant="normal" rspace="0em" xref="id4.4.1.m1.2.2.2.3.cmml">,</mo><mo id="id4.4.1.m1.2.2.2.2" lspace="0em" mathvariant="normal" xref="id4.4.1.m1.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="id4.4.1.m1.2b"><apply id="id4.4.1.m1.2.2.cmml" xref="id4.4.1.m1.2.2"><list id="id4.4.1.m1.2.2.2.3.cmml" xref="id4.4.1.m1.2.2.2.4"><cn id="id4.4.1.m1.1.1.1.1.cmml" type="integer" xref="id4.4.1.m1.1.1.1.1">1</cn><times id="id4.4.1.m1.2.2.2.2.cmml" xref="id4.4.1.m1.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="id4.4.1.m1.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="id4.4.1.m1.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id5.5.2">Rui Melo<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="id5.5.2.m1.2"><semantics id="id5.5.2.m1.2a"><msup id="id5.5.2.m1.2.2" xref="id5.5.2.m1.2.2.cmml"><mi id="id5.5.2.m1.2.2a" xref="id5.5.2.m1.2.2.cmml"></mi><mrow id="id5.5.2.m1.2.2.2.4" xref="id5.5.2.m1.2.2.2.3.cmml"><mn id="id5.5.2.m1.1.1.1.1" mathvariant="normal" xref="id5.5.2.m1.1.1.1.1.cmml">1</mn><mo id="id5.5.2.m1.2.2.2.4.1" mathvariant="normal" rspace="0em" xref="id5.5.2.m1.2.2.2.3.cmml">,</mo><mo id="id5.5.2.m1.2.2.2.2" lspace="0em" mathvariant="normal" xref="id5.5.2.m1.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="id5.5.2.m1.2b"><apply id="id5.5.2.m1.2.2.cmml" xref="id5.5.2.m1.2.2"><list id="id5.5.2.m1.2.2.2.3.cmml" xref="id5.5.2.m1.2.2.2.4"><cn id="id5.5.2.m1.1.1.1.1.cmml" type="integer" xref="id5.5.2.m1.1.1.1.1">1</cn><times id="id5.5.2.m1.2.2.2.2.cmml" xref="id5.5.2.m1.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="id5.5.2.m1.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="id5.5.2.m1.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id6.6.3">Caio Corro<math alttext="{}^{3}" class="ltx_Math" display="inline" id="id6.6.3.m1.1"><semantics id="id6.6.3.m1.1a"><msup id="id6.6.3.m1.1.1" xref="id6.6.3.m1.1.1.cmml"><mi id="id6.6.3.m1.1.1a" xref="id6.6.3.m1.1.1.cmml"></mi><mn id="id6.6.3.m1.1.1.1" mathvariant="normal" xref="id6.6.3.m1.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="id6.6.3.m1.1b"><apply id="id6.6.3.m1.1.1.cmml" xref="id6.6.3.m1.1.1"><cn id="id6.6.3.m1.1.1.1.cmml" type="integer" xref="id6.6.3.m1.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id6.6.3.m1.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="id6.6.3.m1.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id7.7.4">André F. T. Martins<math alttext="{}^{4}" class="ltx_Math" display="inline" id="id7.7.4.m1.1"><semantics id="id7.7.4.m1.1a"><msup id="id7.7.4.m1.1.1" xref="id7.7.4.m1.1.1.cmml"><mi id="id7.7.4.m1.1.1a" xref="id7.7.4.m1.1.1.cmml"></mi><mn id="id7.7.4.m1.1.1.1" mathvariant="normal" xref="id7.7.4.m1.1.1.1.cmml">4</mn></msup><annotation-xml encoding="MathML-Content" id="id7.7.4.m1.1b"><apply id="id7.7.4.m1.1.1.cmml" xref="id7.7.4.m1.1.1"><cn id="id7.7.4.m1.1.1.1.cmml" type="integer" xref="id7.7.4.m1.1.1.1">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id7.7.4.m1.1c">{}^{4}</annotation><annotation encoding="application/x-llamapun" id="id7.7.4.m1.1d">start_FLOATSUPERSCRIPT 4 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>
<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="id8.8.5">Fabrizio Esposito<math alttext="{}^{5}" class="ltx_Math" display="inline" id="id8.8.5.m1.1"><semantics id="id8.8.5.m1.1a"><msup id="id8.8.5.m1.1.1" xref="id8.8.5.m1.1.1.cmml"><mi id="id8.8.5.m1.1.1a" xref="id8.8.5.m1.1.1.cmml"></mi><mn id="id8.8.5.m1.1.1.1" mathvariant="normal" xref="id8.8.5.m1.1.1.1.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="id8.8.5.m1.1b"><apply id="id8.8.5.m1.1.1.cmml" xref="id8.8.5.m1.1.1"><cn id="id8.8.5.m1.1.1.1.cmml" type="integer" xref="id8.8.5.m1.1.1.1">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id8.8.5.m1.1c">{}^{5}</annotation><annotation encoding="application/x-llamapun" id="id8.8.5.m1.1d">start_FLOATSUPERSCRIPT 5 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id9.9.6">Vera Lúcia Raposo<math alttext="{}^{5}" class="ltx_Math" display="inline" id="id9.9.6.m1.1"><semantics id="id9.9.6.m1.1a"><msup id="id9.9.6.m1.1.1" xref="id9.9.6.m1.1.1.cmml"><mi id="id9.9.6.m1.1.1a" xref="id9.9.6.m1.1.1.cmml"></mi><mn id="id9.9.6.m1.1.1.1" mathvariant="normal" xref="id9.9.6.m1.1.1.1.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="id9.9.6.m1.1b"><apply id="id9.9.6.m1.1.1.cmml" xref="id9.9.6.m1.1.1"><cn id="id9.9.6.m1.1.1.1.cmml" type="integer" xref="id9.9.6.m1.1.1.1">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id9.9.6.m1.1c">{}^{5}</annotation><annotation encoding="application/x-llamapun" id="id9.9.6.m1.1d">start_FLOATSUPERSCRIPT 5 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id10.10.7">Sofia Morgado<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id10.10.7.m1.1"><semantics id="id10.10.7.m1.1a"><msup id="id10.10.7.m1.1.1" xref="id10.10.7.m1.1.1.cmml"><mi id="id10.10.7.m1.1.1a" xref="id10.10.7.m1.1.1.cmml"></mi><mn id="id10.10.7.m1.1.1.1" mathvariant="normal" xref="id10.10.7.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id10.10.7.m1.1b"><apply id="id10.10.7.m1.1.1.cmml" xref="id10.10.7.m1.1.1"><cn id="id10.10.7.m1.1.1.1.cmml" type="integer" xref="id10.10.7.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id10.10.7.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id10.10.7.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id11.11.8">Michael Desa<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id11.11.8.m1.1"><semantics id="id11.11.8.m1.1a"><msup id="id11.11.8.m1.1.1" xref="id11.11.8.m1.1.1.cmml"><mi id="id11.11.8.m1.1.1a" xref="id11.11.8.m1.1.1.cmml"></mi><mn id="id11.11.8.m1.1.1.1" mathvariant="normal" xref="id11.11.8.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id11.11.8.m1.1b"><apply id="id11.11.8.m1.1.1.cmml" xref="id11.11.8.m1.1.1"><cn id="id11.11.8.m1.1.1.1.cmml" type="integer" xref="id11.11.8.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id11.11.8.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id11.11.8.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>
<br class="ltx_break"><math alttext="{}^{1}" class="ltx_Math" display="inline" id="id12.12.m4.1"><semantics id="id12.12.m4.1a"><msup id="id12.12.m4.1.1" xref="id12.12.m4.1.1.cmml"><mi id="id12.12.m4.1.1a" xref="id12.12.m4.1.1.cmml"></mi><mn id="id12.12.m4.1.1.1" xref="id12.12.m4.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id12.12.m4.1b"><apply id="id12.12.m4.1.1.cmml" xref="id12.12.m4.1.1"><cn id="id12.12.m4.1.1.1.cmml" type="integer" xref="id12.12.m4.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id12.12.m4.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id12.12.m4.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math>Equall.ai, New York, Paris, Lisbon 
<br class="ltx_break"><math alttext="{}^{2}" class="ltx_Math" display="inline" id="id13.13.m5.1"><semantics id="id13.13.m5.1a"><msup id="id13.13.m5.1.1" xref="id13.13.m5.1.1.cmml"><mi id="id13.13.m5.1.1a" xref="id13.13.m5.1.1.cmml"></mi><mn id="id13.13.m5.1.1.1" xref="id13.13.m5.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id13.13.m5.1b"><apply id="id13.13.m5.1.1.cmml" xref="id13.13.m5.1.1"><cn id="id13.13.m5.1.1.1.cmml" type="integer" xref="id13.13.m5.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id13.13.m5.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id13.13.m5.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>MICS, CentraleSupélec, Université Paris-Saclay
<br class="ltx_break"><math alttext="{}^{3}" class="ltx_Math" display="inline" id="id14.14.m6.1"><semantics id="id14.14.m6.1a"><msup id="id14.14.m6.1.1" xref="id14.14.m6.1.1.cmml"><mi id="id14.14.m6.1.1a" xref="id14.14.m6.1.1.cmml"></mi><mn id="id14.14.m6.1.1.1" xref="id14.14.m6.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="id14.14.m6.1b"><apply id="id14.14.m6.1.1.cmml" xref="id14.14.m6.1.1"><cn id="id14.14.m6.1.1.1.cmml" type="integer" xref="id14.14.m6.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id14.14.m6.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="id14.14.m6.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math>Sorbonne Université, CNRS, ISIR, Paris
<br class="ltx_break"><math alttext="{}^{4}" class="ltx_Math" display="inline" id="id15.15.m7.1"><semantics id="id15.15.m7.1a"><msup id="id15.15.m7.1.1" xref="id15.15.m7.1.1.cmml"><mi id="id15.15.m7.1.1a" xref="id15.15.m7.1.1.cmml"></mi><mn id="id15.15.m7.1.1.1" xref="id15.15.m7.1.1.1.cmml">4</mn></msup><annotation-xml encoding="MathML-Content" id="id15.15.m7.1b"><apply id="id15.15.m7.1.1.cmml" xref="id15.15.m7.1.1"><cn id="id15.15.m7.1.1.1.cmml" type="integer" xref="id15.15.m7.1.1.1">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id15.15.m7.1c">{}^{4}</annotation><annotation encoding="application/x-llamapun" id="id15.15.m7.1d">start_FLOATSUPERSCRIPT 4 end_FLOATSUPERSCRIPT</annotation></semantics></math>Instituto Superior Técnico, Universidade de Lisboa
<br class="ltx_break"><math alttext="{}^{5}" class="ltx_Math" display="inline" id="id16.16.m8.1"><semantics id="id16.16.m8.1a"><msup id="id16.16.m8.1.1" xref="id16.16.m8.1.1.cmml"><mi id="id16.16.m8.1.1a" xref="id16.16.m8.1.1.cmml"></mi><mn id="id16.16.m8.1.1.1" xref="id16.16.m8.1.1.1.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="id16.16.m8.1b"><apply id="id16.16.m8.1.1.cmml" xref="id16.16.m8.1.1"><cn id="id16.16.m8.1.1.1.cmml" type="integer" xref="id16.16.m8.1.1.1">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id16.16.m8.1c">{}^{5}</annotation><annotation encoding="application/x-llamapun" id="id16.16.m8.1d">start_FLOATSUPERSCRIPT 5 end_FLOATSUPERSCRIPT</annotation></semantics></math> NOVA School of Law, Lisboa 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id18.17.id1">firstname@equall.ai</span>
</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id19.id1">In this paper, we introduce <span class="ltx_text ltx_font_typewriter" id="id19.id1.1">SaulLM-7B</span>, a large language model (LLM) tailored for the legal domain. With 7 billion parameters, <span class="ltx_text ltx_font_typewriter" id="id19.id1.2">SaulLM-7B</span> is the first LLM designed explicitly for legal text comprehension and generation. Leveraging the Mistral 7B architecture as its foundation, <span class="ltx_text ltx_font_typewriter" id="id19.id1.3">SaulLM-7B</span> is trained on an English legal corpus of over 30 billion tokens. <span class="ltx_text ltx_font_typewriter" id="id19.id1.4">SaulLM-7B</span> exhibits state-of-the-art proficiency in understanding and processing legal documents. Additionally, we present a novel instructional fine-tuning method that leverages legal datasets to further enhance <span class="ltx_text ltx_font_typewriter" id="id19.id1.5">SaulLM-7B</span>’s performance in legal tasks. <span class="ltx_text ltx_font_typewriter" id="id19.id1.6">SaulLM-7B</span> is released under the MIT License.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<p class="ltx_p ltx_align_center ltx_align_bottom" id="p1.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.1">SaulLM-7B</span><span class="ltx_text ltx_font_bold" id="p1.1.2">: A pioneering Large Language Model for Law</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="p2">
<br class="ltx_break">
<p class="ltx_p" id="p2.16"><span class="ltx_text" id="p2.16.16" style="width:433.6pt;"><span class="ltx_text" id="p2.16.16.16" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p2.16.16.16.16">
<span class="ltx_tbody">
<span class="ltx_tr" id="p2.3.3.3.3.3">
<span class="ltx_td ltx_align_center" id="p2.3.3.3.3.3.3"><span class="ltx_text ltx_font_bold" id="p2.3.3.3.3.3.3.3">Pierre Colombo<math alttext="{}^{1,2,*}" class="ltx_Math" display="inline" id="p2.1.1.1.1.1.1.1.m1.3"><semantics id="p2.1.1.1.1.1.1.1.m1.3a"><msup id="p2.1.1.1.1.1.1.1.m1.3.3" xref="p2.1.1.1.1.1.1.1.m1.3.3.cmml"><mi id="p2.1.1.1.1.1.1.1.m1.3.3a" xref="p2.1.1.1.1.1.1.1.m1.3.3.cmml"></mi><mrow id="p2.1.1.1.1.1.1.1.m1.3.3.3.5" xref="p2.1.1.1.1.1.1.1.m1.3.3.3.4.cmml"><mn id="p2.1.1.1.1.1.1.1.m1.1.1.1.1" mathvariant="normal" xref="p2.1.1.1.1.1.1.1.m1.1.1.1.1.cmml">1</mn><mo id="p2.1.1.1.1.1.1.1.m1.3.3.3.5.1" mathvariant="normal" xref="p2.1.1.1.1.1.1.1.m1.3.3.3.4.cmml">,</mo><mn id="p2.1.1.1.1.1.1.1.m1.2.2.2.2" mathvariant="normal" xref="p2.1.1.1.1.1.1.1.m1.2.2.2.2.cmml">2</mn><mo id="p2.1.1.1.1.1.1.1.m1.3.3.3.5.2" mathvariant="normal" rspace="0em" xref="p2.1.1.1.1.1.1.1.m1.3.3.3.4.cmml">,</mo><mo id="p2.1.1.1.1.1.1.1.m1.3.3.3.3" lspace="0em" mathvariant="normal" xref="p2.1.1.1.1.1.1.1.m1.3.3.3.3.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p2.1.1.1.1.1.1.1.m1.3b"><apply id="p2.1.1.1.1.1.1.1.m1.3.3.cmml" xref="p2.1.1.1.1.1.1.1.m1.3.3"><list id="p2.1.1.1.1.1.1.1.m1.3.3.3.4.cmml" xref="p2.1.1.1.1.1.1.1.m1.3.3.3.5"><cn id="p2.1.1.1.1.1.1.1.m1.1.1.1.1.cmml" type="integer" xref="p2.1.1.1.1.1.1.1.m1.1.1.1.1">1</cn><cn id="p2.1.1.1.1.1.1.1.m1.2.2.2.2.cmml" type="integer" xref="p2.1.1.1.1.1.1.1.m1.2.2.2.2">2</cn><times id="p2.1.1.1.1.1.1.1.m1.3.3.3.3.cmml" xref="p2.1.1.1.1.1.1.1.m1.3.3.3.3"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.1.1.1.1.1.1.1.m1.3c">{}^{1,2,*}</annotation><annotation encoding="application/x-llamapun" id="p2.1.1.1.1.1.1.1.m1.3d">start_FLOATSUPERSCRIPT 1 , 2 , * end_FLOATSUPERSCRIPT</annotation></semantics></math>  Telmo Pessoa Pires<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="p2.2.2.2.2.2.2.2.m2.2"><semantics id="p2.2.2.2.2.2.2.2.m2.2a"><msup id="p2.2.2.2.2.2.2.2.m2.2.2" xref="p2.2.2.2.2.2.2.2.m2.2.2.cmml"><mi id="p2.2.2.2.2.2.2.2.m2.2.2a" xref="p2.2.2.2.2.2.2.2.m2.2.2.cmml"></mi><mrow id="p2.2.2.2.2.2.2.2.m2.2.2.2.4" xref="p2.2.2.2.2.2.2.2.m2.2.2.2.3.cmml"><mn id="p2.2.2.2.2.2.2.2.m2.1.1.1.1" mathvariant="normal" xref="p2.2.2.2.2.2.2.2.m2.1.1.1.1.cmml">1</mn><mo id="p2.2.2.2.2.2.2.2.m2.2.2.2.4.1" mathvariant="normal" rspace="0em" xref="p2.2.2.2.2.2.2.2.m2.2.2.2.3.cmml">,</mo><mo id="p2.2.2.2.2.2.2.2.m2.2.2.2.2" lspace="0em" mathvariant="normal" xref="p2.2.2.2.2.2.2.2.m2.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p2.2.2.2.2.2.2.2.m2.2b"><apply id="p2.2.2.2.2.2.2.2.m2.2.2.cmml" xref="p2.2.2.2.2.2.2.2.m2.2.2"><list id="p2.2.2.2.2.2.2.2.m2.2.2.2.3.cmml" xref="p2.2.2.2.2.2.2.2.m2.2.2.2.4"><cn id="p2.2.2.2.2.2.2.2.m2.1.1.1.1.cmml" type="integer" xref="p2.2.2.2.2.2.2.2.m2.1.1.1.1">1</cn><times id="p2.2.2.2.2.2.2.2.m2.2.2.2.2.cmml" xref="p2.2.2.2.2.2.2.2.m2.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.2.2.2.2.2.2.2.m2.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="p2.2.2.2.2.2.2.2.m2.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math>  Malik Boudiaf<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="p2.3.3.3.3.3.3.3.m3.2"><semantics id="p2.3.3.3.3.3.3.3.m3.2a"><msup id="p2.3.3.3.3.3.3.3.m3.2.2" xref="p2.3.3.3.3.3.3.3.m3.2.2.cmml"><mi id="p2.3.3.3.3.3.3.3.m3.2.2a" xref="p2.3.3.3.3.3.3.3.m3.2.2.cmml"></mi><mrow id="p2.3.3.3.3.3.3.3.m3.2.2.2.4" xref="p2.3.3.3.3.3.3.3.m3.2.2.2.3.cmml"><mn id="p2.3.3.3.3.3.3.3.m3.1.1.1.1" mathvariant="normal" xref="p2.3.3.3.3.3.3.3.m3.1.1.1.1.cmml">1</mn><mo id="p2.3.3.3.3.3.3.3.m3.2.2.2.4.1" mathvariant="normal" rspace="0em" xref="p2.3.3.3.3.3.3.3.m3.2.2.2.3.cmml">,</mo><mo id="p2.3.3.3.3.3.3.3.m3.2.2.2.2" lspace="0em" mathvariant="normal" xref="p2.3.3.3.3.3.3.3.m3.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p2.3.3.3.3.3.3.3.m3.2b"><apply id="p2.3.3.3.3.3.3.3.m3.2.2.cmml" xref="p2.3.3.3.3.3.3.3.m3.2.2"><list id="p2.3.3.3.3.3.3.3.m3.2.2.2.3.cmml" xref="p2.3.3.3.3.3.3.3.m3.2.2.2.4"><cn id="p2.3.3.3.3.3.3.3.m3.1.1.1.1.cmml" type="integer" xref="p2.3.3.3.3.3.3.3.m3.1.1.1.1">1</cn><times id="p2.3.3.3.3.3.3.3.m3.2.2.2.2.cmml" xref="p2.3.3.3.3.3.3.3.m3.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.3.3.3.3.3.3.3.m3.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="p2.3.3.3.3.3.3.3.m3.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span></span>
<span class="ltx_tr" id="p2.7.7.7.7.7">
<span class="ltx_td ltx_align_center" id="p2.7.7.7.7.7.4"><span class="ltx_text ltx_font_bold" id="p2.4.4.4.4.4.1.1">Dominic Culver<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="p2.4.4.4.4.4.1.1.m1.2"><semantics id="p2.4.4.4.4.4.1.1.m1.2a"><msup id="p2.4.4.4.4.4.1.1.m1.2.2" xref="p2.4.4.4.4.4.1.1.m1.2.2.cmml"><mi id="p2.4.4.4.4.4.1.1.m1.2.2a" xref="p2.4.4.4.4.4.1.1.m1.2.2.cmml"></mi><mrow id="p2.4.4.4.4.4.1.1.m1.2.2.2.4" xref="p2.4.4.4.4.4.1.1.m1.2.2.2.3.cmml"><mn id="p2.4.4.4.4.4.1.1.m1.1.1.1.1" mathvariant="normal" xref="p2.4.4.4.4.4.1.1.m1.1.1.1.1.cmml">1</mn><mo id="p2.4.4.4.4.4.1.1.m1.2.2.2.4.1" mathvariant="normal" rspace="0em" xref="p2.4.4.4.4.4.1.1.m1.2.2.2.3.cmml">,</mo><mo id="p2.4.4.4.4.4.1.1.m1.2.2.2.2" lspace="0em" mathvariant="normal" xref="p2.4.4.4.4.4.1.1.m1.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p2.4.4.4.4.4.1.1.m1.2b"><apply id="p2.4.4.4.4.4.1.1.m1.2.2.cmml" xref="p2.4.4.4.4.4.1.1.m1.2.2"><list id="p2.4.4.4.4.4.1.1.m1.2.2.2.3.cmml" xref="p2.4.4.4.4.4.1.1.m1.2.2.2.4"><cn id="p2.4.4.4.4.4.1.1.m1.1.1.1.1.cmml" type="integer" xref="p2.4.4.4.4.4.1.1.m1.1.1.1.1">1</cn><times id="p2.4.4.4.4.4.1.1.m1.2.2.2.2.cmml" xref="p2.4.4.4.4.4.1.1.m1.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.4.4.4.4.4.1.1.m1.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="p2.4.4.4.4.4.1.1.m1.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="p2.5.5.5.5.5.2.2">Rui Melo<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="p2.5.5.5.5.5.2.2.m1.2"><semantics id="p2.5.5.5.5.5.2.2.m1.2a"><msup id="p2.5.5.5.5.5.2.2.m1.2.2" xref="p2.5.5.5.5.5.2.2.m1.2.2.cmml"><mi id="p2.5.5.5.5.5.2.2.m1.2.2a" xref="p2.5.5.5.5.5.2.2.m1.2.2.cmml"></mi><mrow id="p2.5.5.5.5.5.2.2.m1.2.2.2.4" xref="p2.5.5.5.5.5.2.2.m1.2.2.2.3.cmml"><mn id="p2.5.5.5.5.5.2.2.m1.1.1.1.1" mathvariant="normal" xref="p2.5.5.5.5.5.2.2.m1.1.1.1.1.cmml">1</mn><mo id="p2.5.5.5.5.5.2.2.m1.2.2.2.4.1" mathvariant="normal" rspace="0em" xref="p2.5.5.5.5.5.2.2.m1.2.2.2.3.cmml">,</mo><mo id="p2.5.5.5.5.5.2.2.m1.2.2.2.2" lspace="0em" mathvariant="normal" xref="p2.5.5.5.5.5.2.2.m1.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p2.5.5.5.5.5.2.2.m1.2b"><apply id="p2.5.5.5.5.5.2.2.m1.2.2.cmml" xref="p2.5.5.5.5.5.2.2.m1.2.2"><list id="p2.5.5.5.5.5.2.2.m1.2.2.2.3.cmml" xref="p2.5.5.5.5.5.2.2.m1.2.2.2.4"><cn id="p2.5.5.5.5.5.2.2.m1.1.1.1.1.cmml" type="integer" xref="p2.5.5.5.5.5.2.2.m1.1.1.1.1">1</cn><times id="p2.5.5.5.5.5.2.2.m1.2.2.2.2.cmml" xref="p2.5.5.5.5.5.2.2.m1.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.5.5.5.5.5.2.2.m1.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="p2.5.5.5.5.5.2.2.m1.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="p2.6.6.6.6.6.3.3">Caio Corro<math alttext="{}^{3}" class="ltx_Math" display="inline" id="p2.6.6.6.6.6.3.3.m1.1"><semantics id="p2.6.6.6.6.6.3.3.m1.1a"><msup id="p2.6.6.6.6.6.3.3.m1.1.1" xref="p2.6.6.6.6.6.3.3.m1.1.1.cmml"><mi id="p2.6.6.6.6.6.3.3.m1.1.1a" xref="p2.6.6.6.6.6.3.3.m1.1.1.cmml"></mi><mn id="p2.6.6.6.6.6.3.3.m1.1.1.1" mathvariant="normal" xref="p2.6.6.6.6.6.3.3.m1.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="p2.6.6.6.6.6.3.3.m1.1b"><apply id="p2.6.6.6.6.6.3.3.m1.1.1.cmml" xref="p2.6.6.6.6.6.3.3.m1.1.1"><cn id="p2.6.6.6.6.6.3.3.m1.1.1.1.cmml" type="integer" xref="p2.6.6.6.6.6.3.3.m1.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.6.6.6.6.6.3.3.m1.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="p2.6.6.6.6.6.3.3.m1.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="p2.7.7.7.7.7.4.4">André F. T. Martins<math alttext="{}^{4}" class="ltx_Math" display="inline" id="p2.7.7.7.7.7.4.4.m1.1"><semantics id="p2.7.7.7.7.7.4.4.m1.1a"><msup id="p2.7.7.7.7.7.4.4.m1.1.1" xref="p2.7.7.7.7.7.4.4.m1.1.1.cmml"><mi id="p2.7.7.7.7.7.4.4.m1.1.1a" xref="p2.7.7.7.7.7.4.4.m1.1.1.cmml"></mi><mn id="p2.7.7.7.7.7.4.4.m1.1.1.1" mathvariant="normal" xref="p2.7.7.7.7.7.4.4.m1.1.1.1.cmml">4</mn></msup><annotation-xml encoding="MathML-Content" id="p2.7.7.7.7.7.4.4.m1.1b"><apply id="p2.7.7.7.7.7.4.4.m1.1.1.cmml" xref="p2.7.7.7.7.7.4.4.m1.1.1"><cn id="p2.7.7.7.7.7.4.4.m1.1.1.1.cmml" type="integer" xref="p2.7.7.7.7.7.4.4.m1.1.1.1">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.7.7.7.7.7.4.4.m1.1c">{}^{4}</annotation><annotation encoding="application/x-llamapun" id="p2.7.7.7.7.7.4.4.m1.1d">start_FLOATSUPERSCRIPT 4 end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span></span>
<span class="ltx_tr" id="p2.11.11.11.11.11">
<span class="ltx_td ltx_align_center" id="p2.11.11.11.11.11.4"><span class="ltx_text ltx_font_bold" id="p2.8.8.8.8.8.1.1">Fabrizio Esposito<math alttext="{}^{5}" class="ltx_Math" display="inline" id="p2.8.8.8.8.8.1.1.m1.1"><semantics id="p2.8.8.8.8.8.1.1.m1.1a"><msup id="p2.8.8.8.8.8.1.1.m1.1.1" xref="p2.8.8.8.8.8.1.1.m1.1.1.cmml"><mi id="p2.8.8.8.8.8.1.1.m1.1.1a" xref="p2.8.8.8.8.8.1.1.m1.1.1.cmml"></mi><mn id="p2.8.8.8.8.8.1.1.m1.1.1.1" mathvariant="normal" xref="p2.8.8.8.8.8.1.1.m1.1.1.1.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="p2.8.8.8.8.8.1.1.m1.1b"><apply id="p2.8.8.8.8.8.1.1.m1.1.1.cmml" xref="p2.8.8.8.8.8.1.1.m1.1.1"><cn id="p2.8.8.8.8.8.1.1.m1.1.1.1.cmml" type="integer" xref="p2.8.8.8.8.8.1.1.m1.1.1.1">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.8.8.8.8.8.1.1.m1.1c">{}^{5}</annotation><annotation encoding="application/x-llamapun" id="p2.8.8.8.8.8.1.1.m1.1d">start_FLOATSUPERSCRIPT 5 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="p2.9.9.9.9.9.2.2">Vera Lúcia Raposo<math alttext="{}^{5}" class="ltx_Math" display="inline" id="p2.9.9.9.9.9.2.2.m1.1"><semantics id="p2.9.9.9.9.9.2.2.m1.1a"><msup id="p2.9.9.9.9.9.2.2.m1.1.1" xref="p2.9.9.9.9.9.2.2.m1.1.1.cmml"><mi id="p2.9.9.9.9.9.2.2.m1.1.1a" xref="p2.9.9.9.9.9.2.2.m1.1.1.cmml"></mi><mn id="p2.9.9.9.9.9.2.2.m1.1.1.1" mathvariant="normal" xref="p2.9.9.9.9.9.2.2.m1.1.1.1.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="p2.9.9.9.9.9.2.2.m1.1b"><apply id="p2.9.9.9.9.9.2.2.m1.1.1.cmml" xref="p2.9.9.9.9.9.2.2.m1.1.1"><cn id="p2.9.9.9.9.9.2.2.m1.1.1.1.cmml" type="integer" xref="p2.9.9.9.9.9.2.2.m1.1.1.1">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.9.9.9.9.9.2.2.m1.1c">{}^{5}</annotation><annotation encoding="application/x-llamapun" id="p2.9.9.9.9.9.2.2.m1.1d">start_FLOATSUPERSCRIPT 5 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="p2.10.10.10.10.10.3.3">Sofia Morgado<math alttext="{}^{1}" class="ltx_Math" display="inline" id="p2.10.10.10.10.10.3.3.m1.1"><semantics id="p2.10.10.10.10.10.3.3.m1.1a"><msup id="p2.10.10.10.10.10.3.3.m1.1.1" xref="p2.10.10.10.10.10.3.3.m1.1.1.cmml"><mi id="p2.10.10.10.10.10.3.3.m1.1.1a" xref="p2.10.10.10.10.10.3.3.m1.1.1.cmml"></mi><mn id="p2.10.10.10.10.10.3.3.m1.1.1.1" mathvariant="normal" xref="p2.10.10.10.10.10.3.3.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="p2.10.10.10.10.10.3.3.m1.1b"><apply id="p2.10.10.10.10.10.3.3.m1.1.1.cmml" xref="p2.10.10.10.10.10.3.3.m1.1.1"><cn id="p2.10.10.10.10.10.3.3.m1.1.1.1.cmml" type="integer" xref="p2.10.10.10.10.10.3.3.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.10.10.10.10.10.3.3.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="p2.10.10.10.10.10.3.3.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="p2.11.11.11.11.11.4.4">Michael Desa<math alttext="{}^{1}" class="ltx_Math" display="inline" id="p2.11.11.11.11.11.4.4.m1.1"><semantics id="p2.11.11.11.11.11.4.4.m1.1a"><msup id="p2.11.11.11.11.11.4.4.m1.1.1" xref="p2.11.11.11.11.11.4.4.m1.1.1.cmml"><mi id="p2.11.11.11.11.11.4.4.m1.1.1a" xref="p2.11.11.11.11.11.4.4.m1.1.1.cmml"></mi><mn id="p2.11.11.11.11.11.4.4.m1.1.1.1" mathvariant="normal" xref="p2.11.11.11.11.11.4.4.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="p2.11.11.11.11.11.4.4.m1.1b"><apply id="p2.11.11.11.11.11.4.4.m1.1.1.cmml" xref="p2.11.11.11.11.11.4.4.m1.1.1"><cn id="p2.11.11.11.11.11.4.4.m1.1.1.1.cmml" type="integer" xref="p2.11.11.11.11.11.4.4.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.11.11.11.11.11.4.4.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="p2.11.11.11.11.11.4.4.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span></span>
<span class="ltx_tr" id="p2.12.12.12.12.12">
<span class="ltx_td ltx_align_center" id="p2.12.12.12.12.12.1"><math alttext="{}^{1}" class="ltx_Math" display="inline" id="p2.12.12.12.12.12.1.m1.1"><semantics id="p2.12.12.12.12.12.1.m1.1a"><msup id="p2.12.12.12.12.12.1.m1.1.1" xref="p2.12.12.12.12.12.1.m1.1.1.cmml"><mi id="p2.12.12.12.12.12.1.m1.1.1a" xref="p2.12.12.12.12.12.1.m1.1.1.cmml"></mi><mn id="p2.12.12.12.12.12.1.m1.1.1.1" xref="p2.12.12.12.12.12.1.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="p2.12.12.12.12.12.1.m1.1b"><apply id="p2.12.12.12.12.12.1.m1.1.1.cmml" xref="p2.12.12.12.12.12.1.m1.1.1"><cn id="p2.12.12.12.12.12.1.m1.1.1.1.cmml" type="integer" xref="p2.12.12.12.12.12.1.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.12.12.12.12.12.1.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="p2.12.12.12.12.12.1.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math>Equall.ai, New York, Paris, Lisbon</span></span>
<span class="ltx_tr" id="p2.13.13.13.13.13">
<span class="ltx_td ltx_align_center" id="p2.13.13.13.13.13.1"><math alttext="{}^{2}" class="ltx_Math" display="inline" id="p2.13.13.13.13.13.1.m1.1"><semantics id="p2.13.13.13.13.13.1.m1.1a"><msup id="p2.13.13.13.13.13.1.m1.1.1" xref="p2.13.13.13.13.13.1.m1.1.1.cmml"><mi id="p2.13.13.13.13.13.1.m1.1.1a" xref="p2.13.13.13.13.13.1.m1.1.1.cmml"></mi><mn id="p2.13.13.13.13.13.1.m1.1.1.1" xref="p2.13.13.13.13.13.1.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p2.13.13.13.13.13.1.m1.1b"><apply id="p2.13.13.13.13.13.1.m1.1.1.cmml" xref="p2.13.13.13.13.13.1.m1.1.1"><cn id="p2.13.13.13.13.13.1.m1.1.1.1.cmml" type="integer" xref="p2.13.13.13.13.13.1.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.13.13.13.13.13.1.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p2.13.13.13.13.13.1.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>MICS, CentraleSupélec, Université Paris-Saclay</span></span>
<span class="ltx_tr" id="p2.14.14.14.14.14">
<span class="ltx_td ltx_align_center" id="p2.14.14.14.14.14.1"><math alttext="{}^{3}" class="ltx_Math" display="inline" id="p2.14.14.14.14.14.1.m1.1"><semantics id="p2.14.14.14.14.14.1.m1.1a"><msup id="p2.14.14.14.14.14.1.m1.1.1" xref="p2.14.14.14.14.14.1.m1.1.1.cmml"><mi id="p2.14.14.14.14.14.1.m1.1.1a" xref="p2.14.14.14.14.14.1.m1.1.1.cmml"></mi><mn id="p2.14.14.14.14.14.1.m1.1.1.1" xref="p2.14.14.14.14.14.1.m1.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="p2.14.14.14.14.14.1.m1.1b"><apply id="p2.14.14.14.14.14.1.m1.1.1.cmml" xref="p2.14.14.14.14.14.1.m1.1.1"><cn id="p2.14.14.14.14.14.1.m1.1.1.1.cmml" type="integer" xref="p2.14.14.14.14.14.1.m1.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.14.14.14.14.14.1.m1.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="p2.14.14.14.14.14.1.m1.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math>Sorbonne Université, CNRS, ISIR, Paris</span></span>
<span class="ltx_tr" id="p2.15.15.15.15.15">
<span class="ltx_td ltx_align_center" id="p2.15.15.15.15.15.1"><math alttext="{}^{4}" class="ltx_Math" display="inline" id="p2.15.15.15.15.15.1.m1.1"><semantics id="p2.15.15.15.15.15.1.m1.1a"><msup id="p2.15.15.15.15.15.1.m1.1.1" xref="p2.15.15.15.15.15.1.m1.1.1.cmml"><mi id="p2.15.15.15.15.15.1.m1.1.1a" xref="p2.15.15.15.15.15.1.m1.1.1.cmml"></mi><mn id="p2.15.15.15.15.15.1.m1.1.1.1" xref="p2.15.15.15.15.15.1.m1.1.1.1.cmml">4</mn></msup><annotation-xml encoding="MathML-Content" id="p2.15.15.15.15.15.1.m1.1b"><apply id="p2.15.15.15.15.15.1.m1.1.1.cmml" xref="p2.15.15.15.15.15.1.m1.1.1"><cn id="p2.15.15.15.15.15.1.m1.1.1.1.cmml" type="integer" xref="p2.15.15.15.15.15.1.m1.1.1.1">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.15.15.15.15.15.1.m1.1c">{}^{4}</annotation><annotation encoding="application/x-llamapun" id="p2.15.15.15.15.15.1.m1.1d">start_FLOATSUPERSCRIPT 4 end_FLOATSUPERSCRIPT</annotation></semantics></math>Instituto Superior Técnico, Universidade de Lisboa</span></span>
<span class="ltx_tr" id="p2.16.16.16.16.16">
<span class="ltx_td ltx_align_center" id="p2.16.16.16.16.16.1"><math alttext="{}^{5}" class="ltx_Math" display="inline" id="p2.16.16.16.16.16.1.m1.1"><semantics id="p2.16.16.16.16.16.1.m1.1a"><msup id="p2.16.16.16.16.16.1.m1.1.1" xref="p2.16.16.16.16.16.1.m1.1.1.cmml"><mi id="p2.16.16.16.16.16.1.m1.1.1a" xref="p2.16.16.16.16.16.1.m1.1.1.cmml"></mi><mn id="p2.16.16.16.16.16.1.m1.1.1.1" xref="p2.16.16.16.16.16.1.m1.1.1.1.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="p2.16.16.16.16.16.1.m1.1b"><apply id="p2.16.16.16.16.16.1.m1.1.1.cmml" xref="p2.16.16.16.16.16.1.m1.1.1"><cn id="p2.16.16.16.16.16.1.m1.1.1.1.cmml" type="integer" xref="p2.16.16.16.16.16.1.m1.1.1.1">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.16.16.16.16.16.1.m1.1c">{}^{5}</annotation><annotation encoding="application/x-llamapun" id="p2.16.16.16.16.16.1.m1.1d">start_FLOATSUPERSCRIPT 5 end_FLOATSUPERSCRIPT</annotation></semantics></math> NOVA School of Law, Lisboa</span></span>
<span class="ltx_tr" id="p2.16.16.16.16.17.1">
<span class="ltx_td ltx_align_center" id="p2.16.16.16.16.17.1.1"><span class="ltx_text ltx_font_typewriter" id="p2.16.16.16.16.17.1.1.1">firstname@equall.ai</span></span></span>
</span>
</span></span> </span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">*</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">*</sup><span class="ltx_note_type">footnotetext: </span>Equal contribution.</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">In the rapidly evolving landscape of artificial intelligence, the applications of large language models (LLMs) <cite class="ltx_cite ltx_citemacro_cite">Achiam et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib1" title="">2023</a>); Scao et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib65" title="">2022</a>); Penedo et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib59" title="">2023</a>); Touvron et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib71" title="">2023a</a>); Jiang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib34" title="">2023</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib35" title="">2024</a>); Touvron et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib72" title="">2023b</a>); Bai et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib5" title="">2023</a>)</cite> have witnessed large advancements across various domains, like <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">e.g.</span>&nbsp;translation <cite class="ltx_cite ltx_citemacro_cite">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib85" title="">2023</a>)</cite>, medical <cite class="ltx_cite ltx_citemacro_cite">Chen et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib12" title="">2023</a>)</cite>, and code generation <cite class="ltx_cite ltx_citemacro_cite">Roziere et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib63" title="">2023</a>); Li et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib41" title="">2023</a>)</cite>. From natural language processing to machine translation, these models have exhibited exceptional capabilities in understanding and generating human-like text <cite class="ltx_cite ltx_citemacro_cite">Weber-Wulff et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib80" title="">2023</a>); Islam et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib32" title="">2023</a>); Mitchell et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib49" title="">2023</a>)</cite>.
However, one field that has yet to experience the full benefit of this transformative technology is the legal domain <cite class="ltx_cite ltx_citemacro_cite">Martin et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib47" title="">2024</a>); Licari and Comandè (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib43" title="">2022</a>)</cite>. As legal professionals grapple with an ever-expanding volume of complex documents, there is a growing need for a dedicated LLM that can help navigate and interpret legal material <cite class="ltx_cite ltx_citemacro_cite">Savelka et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib64" title="">2023</a>); Katz et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib36" title="">2023</a>); Xiao et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib84" title="">2021</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In this paper, we present a pioneering initiative to develop the first legal LLM publicly available.
Legal text, characterized by its unique syntax and specialized vocabulary presents a distinct linguistic challenge <cite class="ltx_cite ltx_citemacro_cite">Chalkidis et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib11" title="">2020</a>); Niklaus et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib53" title="">2021</a>)</cite>.
Our approach focuses on extensive pretraining <cite class="ltx_cite ltx_citemacro_cite">Gururangan et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib27" title="">2020</a>); Yao et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib86" title="">2021</a>)</cite> using dedicated legal corpora from English-speaking jurisdictions such as the USA, Canada, the UK, and Europe <cite class="ltx_cite ltx_citemacro_cite">Aletras et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib2" title="">2016</a>); Gutiérrez-Fandiño et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib28" title="">2021</a>)</cite>.
Leveraging the pretraining on a large and diverse legal dataset, both scraped by our team as well as from previous literature <cite class="ltx_cite ltx_citemacro_citep">(Niklaus and Giofré, <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib54" title="">2022</a>)</cite>, our LLM, <span class="ltx_text ltx_font_typewriter" id="S1.p2.1.1">SaulLM-7B</span>, aims not only to comprehend the complexities of legal documents but also to adapt to the evolving nature of legal discourse.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">By focusing on the needs of legal practitioners and harnessing the power of pretraining on dedicated legal corpora, our work represents an important step towards fulfilling the unique demands of the legal domain. We anticipate that introducing the first LLM for law will not only empower legal professionals but also catalyze further innovation at the intersection of artificial intelligence and the legal community - making a significant contribution to legal language understanding and application <cite class="ltx_cite ltx_citemacro_cite">Prakken (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib60" title="">2013</a>)</cite>. We summarize the contributions of this work as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S1.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Contribution 1: A family of legal LLMs.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S1.SS0.SSS0.Px1.p1.1">In this paper, we introduce the <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px1.p1.1.1">SaulLM-7B</span>’s family, a collection of Legal Language Models meticulously crafted to tackle the distinctive challenges encountered within the legal domain. We unveil <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px1.p1.1.2">SaulLM-7B</span>, a 7-billion-parameter language model specifically tailored to legal text. With its specialized training regimen, <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px1.p1.1.3">SaulLM-7B</span> demonstrates a superior understanding of the nuances in legal language compared to generic models. Furthermore, we release <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px1.p1.1.4">SaulLM-7B-Instruct</span>, an instruction-tuned variant, carefully engineered to outperform existing models such as <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px1.p1.1.5">Mistral</span> or <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px1.p1.1.6">Llama</span> on a variety of legal tasks<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Model is available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/Equall" title="">https://huggingface.co/Equall</a>.</span></span></span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S1.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Contribution 2: An improved evaluation protocol for legal LLMs.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S1.SS0.SSS0.Px2.p1.1">Concurrently, we introduce LegalBench-Instruct, a supplemental iteration of LegalBench <cite class="ltx_cite ltx_citemacro_cite">Guha et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib25" title="">2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib26" title="">2023</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Dataset is processed and available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/Equall" title="">https://huggingface.co/Equall</a></span></span></span>, crafted to better gauge and refine the legal proficiency of language models, which we hope will contribute to future advancements into research in the legal domain. To further enrich the models’ capabilities in legal contexts, we also include the legal tasks of the popular MMLU benchmark <cite class="ltx_cite ltx_citemacro_cite">Hendrycks et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib31" title="">2020</a>)</cite> in our evaluation protocol, particularly focusing on international law, professional law<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>We use the term “professional law” here as defined in <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib31" title="">2020</a>)</cite></span></span></span> and jurisprudence.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="254" id="S1.F1.g1" src="x1.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text ltx_font_bold" id="S1.F1.2.1">Procedure for constructing <span class="ltx_text ltx_font_typewriter" id="S1.F1.2.1.1">SaulLM-7B</span></span>. We rely on legal datasets augmented with replay data, and instructions datasets. For fine-tuning we enrich our instruction finetuning dataset further with legal instructions.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S1.SS0.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Contribution 3: Model, Evaluation Code &amp; Licensing.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S1.SS0.SSS0.Px3.p1.1">To foster widespread adoption and promote innovation, we release <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px3.p1.1.1">SaulLM-7B</span> and <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px3.p1.1.2">SaulLM-7B-Instruct</span>, as well as our evaluation code under the MIT License. This open licensing approach encourages collaborative development and adoption into a wide array of commercial and research endeavors within the legal domain and beyond.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span><span class="ltx_text ltx_font_typewriter" id="S2.1.1">SaulLM-7B</span>: Extending the legal capabilities of Language Models</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.4">A wide range of open-source large language models is available for the backbone, spanning from <math alttext="70" class="ltx_Math" display="inline" id="S2.p1.1.m1.1"><semantics id="S2.p1.1.m1.1a"><mn id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">70</mn><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><cn id="S2.p1.1.m1.1.1.cmml" type="integer" xref="S2.p1.1.m1.1.1">70</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">70</annotation><annotation encoding="application/x-llamapun" id="S2.p1.1.m1.1d">70</annotation></semantics></math> million parameter models like Pythia <cite class="ltx_cite ltx_citemacro_citep">(Biderman et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib6" title="">2023</a>)</cite> to <math alttext="180" class="ltx_Math" display="inline" id="S2.p1.2.m2.1"><semantics id="S2.p1.2.m2.1a"><mn id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">180</mn><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><cn id="S2.p1.2.m2.1.1.cmml" type="integer" xref="S2.p1.2.m2.1.1">180</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">180</annotation><annotation encoding="application/x-llamapun" id="S2.p1.2.m2.1d">180</annotation></semantics></math> billion parameter models like Falcon <cite class="ltx_cite ltx_citemacro_citep">(Almazrouei et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib3" title="">2023</a>)</cite>. In this work, we choose the Mistral <math alttext="7" class="ltx_Math" display="inline" id="S2.p1.3.m3.1"><semantics id="S2.p1.3.m3.1a"><mn id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><cn id="S2.p1.3.m3.1.1.cmml" type="integer" xref="S2.p1.3.m3.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">7</annotation><annotation encoding="application/x-llamapun" id="S2.p1.3.m3.1d">7</annotation></semantics></math>B model, a <math alttext="7" class="ltx_Math" display="inline" id="S2.p1.4.m4.1"><semantics id="S2.p1.4.m4.1a"><mn id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><cn id="S2.p1.4.m4.1.1.cmml" type="integer" xref="S2.p1.4.m4.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">7</annotation><annotation encoding="application/x-llamapun" id="S2.p1.4.m4.1d">7</annotation></semantics></math> billion parameter open-source model that achieves high performance across benchmarks and tasks <cite class="ltx_cite ltx_citemacro_citep">(Jiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib34" title="">2023</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Our methodology, shown in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2403.03883v2#S1.F1" title="Figure 1 ‣ Contribution 2: An improved evaluation protocol for legal LLMs. ‣ 1 Introduction ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure&nbsp;1</span></a> involves a two-step process that we describe below.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Enhancing Mistral’s Legal Capabilities</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">While generic models <cite class="ltx_cite ltx_citemacro_cite">Touvron et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib71" title="">2023a</a>); Taylor et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib70" title="">2022</a>); Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib89" title="">2022</a>); Gu and Dao (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib24" title="">2023</a>); Almazrouei et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib3" title="">2023</a>); Zhang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib88" title="">2024</a>); Faysse et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib21" title="">2024</a>)</cite> gain some exposure to legal data during their training, it typically only represents a minor fraction of the overall data. A straightforward method to enhance performance for legal tasks is to perform additional training focusing on legal data. This approach, particularly focused on decoder models, has been successfully used in various fields such as medicine <cite class="ltx_cite ltx_citemacro_cite">Chen et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib12" title="">2023</a>); Ji et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib33" title="">2023</a>)</cite>, translation <cite class="ltx_cite ltx_citemacro_cite">Xu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib85" title="">2023</a>); Wu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib83" title="">2024</a>)</cite>, and coding <cite class="ltx_cite ltx_citemacro_cite">Roziere et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib63" title="">2023</a>)</cite>.
The key advantage of this approach is its scalability and independence from the specific characteristics of the training data.
Other research on domain adaptation has attempted to specialize language models via pretext tasks. However, these efforts often rely on smaller-scale approaches <cite class="ltx_cite ltx_citemacro_cite">Niklaus and Giofré (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib55" title="">2023</a>)</cite>, are computationally expensive <cite class="ltx_cite ltx_citemacro_cite">Vu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib76" title="">2020</a>); Lu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib45" title="">2023</a>)</cite>, or lack scalability <cite class="ltx_cite ltx_citemacro_cite">Cheng et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib13" title="">2023</a>); Cui et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib16" title="">2023</a>); Nishida et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib57" title="">2019</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">For these reasons, as well as the availability of large-scale legal corpora from the web, we chose to focus on <em class="ltx_emph ltx_font_italic" id="S2.SS1.p2.1.1">continued pretraining</em>.
We meticulously curate a high-quality dataset sourced from diverse legal content repositories. After rigorous filtering
<cite class="ltx_cite ltx_citemacro_citep">(Penedo et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib59" title="">2023</a>)</cite> and deduplication <cite class="ltx_cite ltx_citemacro_citep">(Mou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib50" title="">2023</a>; Kocetkov et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib37" title="">2023</a>)</cite>, we end up with a corpus of <math alttext="30" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.1"><semantics id="S2.SS1.p2.1.m1.1a"><mn id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><cn id="S2.SS1.p2.1.m1.1.1.cmml" type="integer" xref="S2.SS1.p2.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">30</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.1d">30</annotation></semantics></math> billion tokens, which serves as a robust foundation for continued pretraining.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Improving Legal Instruction Following</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">To support user requests and conversational interaction, LLMs typically undergo instruction tuning, a critical process involving training on supervised conversational pairs. This step is essential for crafting a versatile model, adept at addressing user queries <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib77" title="">2023a</a>); Wei et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib81" title="">2021</a>); Chung et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib14" title="">2022</a>); Faysse et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib22" title="">2023</a>); Ding et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib19" title="">2023</a>); Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib78" title="">2023b</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">For general-purpose language models, diversity and quality of instruction are crucial <cite class="ltx_cite ltx_citemacro_cite">Cao et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib9" title="">2023</a>); Zhou et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib90" title="">2023</a>)</cite>. However, in specialized domains it is crucial to incorporate task-specific and specialized prompts to enhance performance. Our instruction fine-tuning stage involves <math alttext="2" class="ltx_Math" display="inline" id="S2.SS2.p2.1.m1.1"><semantics id="S2.SS2.p2.1.m1.1a"><mn id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><cn id="S2.SS2.p2.1.m1.1.1.cmml" type="integer" xref="S2.SS2.p2.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">2</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.1.m1.1d">2</annotation></semantics></math> key components: generic (ie, non-legal) and legal instructions. The former help enhance the model’s understanding and following of commands, and includes data from diverse domains such as coding, mathematics, and general conversations. For the latter we employ an extensive collection of datasets tailored to the nuances of legal domains, covering legal question answering and summarization, among others.
Through this meticulous fine-tuning on instructional data, our model, <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p2.1.1">SaulLM-7B-Instruct</span>, is able to grasp legal intricacies and excels in a wide range of associated tasks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_theorem ltx_theorem_remark" id="Thmremarkx1">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span class="ltx_text ltx_font_bold" id="Thmremarkx1.1.1.1">Remark</span></span><span class="ltx_text ltx_font_bold" id="Thmremarkx1.2.2">.</span>
</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Thmremarkx1.p1">
<p class="ltx_p" id="Thmremarkx1.p1.1"><span class="ltx_text ltx_font_italic" id="Thmremarkx1.p1.1.1">It’s worth noting that many common LLMs <cite class="ltx_cite ltx_citemacro_cite">Tunstall et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib74" title="">2023</a>)</cite> include an additional step of to align the model with human preference <cite class="ltx_cite ltx_citemacro_cite">Rafailov et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib62" title="">2023</a>); Munos et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib52" title="">2023</a>); von Werra et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib75" title="">2020</a>)</cite>. In our case, early experiments did not show any meaningful improvement in performance and so we opted to not pursue this avenue for the present paper.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section we describe our data collection and cleaning schemes.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Legal Pretraining Corpora</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Unlike fields such as science and medicine, the legal landscape varies significantly across countries and jurisdictions, reflecting differences not only in local laws but also in legal traditions, like common law versus civil law <cite class="ltx_cite ltx_citemacro_cite">Henderson et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib30" title="">2022</a>)</cite>. Thus, we gathered legal texts from various jurisdictions, with a primary focus on the English language due to its widespread use in legal contexts worldwide. Our collection includes data from the U.S. <cite class="ltx_cite ltx_citemacro_cite">Tuggener et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib73" title="">2020</a>)</cite>, Europe <cite class="ltx_cite ltx_citemacro_cite">Chalkidis et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib10" title="">2019</a>)</cite>, and Australia <cite class="ltx_cite ltx_citemacro_cite">Butler (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib8" title="">2023</a>)</cite>, covering a diverse range of legal systems. Through this thorough curation process and aggressive cleaning (see <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS2" title="3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.2</span></a>), we end up with a corpus of 30 billion tokens, capturing the intricacies of legal language across regions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Dataset Composition</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S3.SS1.SSS1.Px1">
<h5 class="ltx_title ltx_title_paragraph">Legal Sources</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS1.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.Px1.p1.1">We combine both previously available datasets, such as the FreeLaw subset from The Pile <cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib23" title="">2020</a>)</cite> and MultiLegal Pile <cite class="ltx_cite ltx_citemacro_citep">(Niklaus et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib56" title="">2023</a>)</cite>, as well as data scraped from publicly available sources on the Web. We list the different sources of data in <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.T1" title="Table 1 ‣ Legal Sources ‣ 3.1.1 Dataset Composition ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T1.11">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.11.12.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T1.11.12.1.1">Name</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.11.12.1.2">Tokens</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.1.2">FreeLaw<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>We used the subset from The Pile <cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib23" title="">2020</a>)</cite>.</span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.1">
<math alttext="15" class="ltx_Math" display="inline" id="S3.T1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.m1.1a"><mn id="S3.T1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.m1.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.m1.1b"><cn id="S3.T1.1.1.1.m1.1.1.cmml" type="integer" xref="S3.T1.1.1.1.m1.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.m1.1c">15</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.m1.1d">15</annotation></semantics></math>B</td>
</tr>
<tr class="ltx_tr" id="S3.T1.11.13.2">
<td class="ltx_td ltx_align_left" id="S3.T1.11.13.2.1">EDGAR<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.sec.gov/edgar" title="">https://www.sec.gov/edgar</a></span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.11.13.2.2">5B</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.2">
<td class="ltx_td ltx_align_left" id="S3.T1.2.2.2">English MultiLegal Pile<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>We limited ourselves to the commercially-licensed subset: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/joelniklaus/Multi_Legal_Pile_Commercial" title="">https://huggingface.co/datasets/joelniklaus/Multi_Legal_Pile_Commercial</a></span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.2.2.1">
<math alttext="50" class="ltx_Math" display="inline" id="S3.T1.2.2.1.m1.1"><semantics id="S3.T1.2.2.1.m1.1a"><mn id="S3.T1.2.2.1.m1.1.1" xref="S3.T1.2.2.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.1.m1.1b"><cn id="S3.T1.2.2.1.m1.1.1.cmml" type="integer" xref="S3.T1.2.2.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.1.m1.1c">50</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.2.1.m1.1d">50</annotation></semantics></math>B</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.3">
<td class="ltx_td ltx_align_left" id="S3.T1.3.3.2">English EuroParl <cite class="ltx_cite ltx_citemacro_citep">(Koehn, <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib38" title="">2005</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.3.1">
<math alttext="6" class="ltx_Math" display="inline" id="S3.T1.3.3.1.m1.1"><semantics id="S3.T1.3.3.1.m1.1a"><mn id="S3.T1.3.3.1.m1.1.1" xref="S3.T1.3.3.1.m1.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.1.m1.1b"><cn id="S3.T1.3.3.1.m1.1.1.cmml" type="integer" xref="S3.T1.3.3.1.m1.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.1.m1.1c">6</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.3.1.m1.1d">6</annotation></semantics></math>B</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.4">
<td class="ltx_td ltx_align_left" id="S3.T1.4.4.2">GovInfo<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.govinfo.gov/" title="">https://www.govinfo.gov/</a></span></span></span> Statutes, Opinions &amp; Codes</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.4.1">
<math alttext="11" class="ltx_Math" display="inline" id="S3.T1.4.4.1.m1.1"><semantics id="S3.T1.4.4.1.m1.1a"><mn id="S3.T1.4.4.1.m1.1.1" xref="S3.T1.4.4.1.m1.1.1.cmml">11</mn><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.1.m1.1b"><cn id="S3.T1.4.4.1.m1.1.1.cmml" type="integer" xref="S3.T1.4.4.1.m1.1.1">11</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.1.m1.1c">11</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.4.1.m1.1d">11</annotation></semantics></math>B</td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.5">
<td class="ltx_td ltx_align_left" id="S3.T1.5.5.2">Law Stack Exchange<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/ymoslem/Law-StackExchange" title="">https://huggingface.co/datasets/ymoslem/Law-StackExchange</a></span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.5.5.1">
<math alttext="19" class="ltx_Math" display="inline" id="S3.T1.5.5.1.m1.1"><semantics id="S3.T1.5.5.1.m1.1a"><mn id="S3.T1.5.5.1.m1.1.1" xref="S3.T1.5.5.1.m1.1.1.cmml">19</mn><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.1.m1.1b"><cn id="S3.T1.5.5.1.m1.1.1.cmml" type="integer" xref="S3.T1.5.5.1.m1.1.1">19</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.1.m1.1c">19</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.5.1.m1.1d">19</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6">
<td class="ltx_td ltx_align_left" id="S3.T1.6.6.2">Commercial Open Australian Legal Corpus<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/umarbutler/open-australian-legal-corpus-creator" title="">https://github.com/umarbutler/open-australian-legal-corpus-creator</a></span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.6.1">
<math alttext="0.5" class="ltx_Math" display="inline" id="S3.T1.6.6.1.m1.1"><semantics id="S3.T1.6.6.1.m1.1a"><mn id="S3.T1.6.6.1.m1.1.1" xref="S3.T1.6.6.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.1.m1.1b"><cn id="S3.T1.6.6.1.m1.1.1.cmml" type="float" xref="S3.T1.6.6.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.1.m1.1c">0.5</annotation><annotation encoding="application/x-llamapun" id="S3.T1.6.6.1.m1.1d">0.5</annotation></semantics></math>B</td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.7">
<td class="ltx_td ltx_align_left" id="S3.T1.7.7.2">EU Legislation<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>Scraped from <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://eur-lex.europa.eu/homepage.html" title="">https://eur-lex.europa.eu/homepage.html</a></span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.1">
<math alttext="315" class="ltx_Math" display="inline" id="S3.T1.7.7.1.m1.1"><semantics id="S3.T1.7.7.1.m1.1a"><mn id="S3.T1.7.7.1.m1.1.1" xref="S3.T1.7.7.1.m1.1.1.cmml">315</mn><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.1.m1.1b"><cn id="S3.T1.7.7.1.m1.1.1.cmml" type="integer" xref="S3.T1.7.7.1.m1.1.1">315</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.1.m1.1c">315</annotation><annotation encoding="application/x-llamapun" id="S3.T1.7.7.1.m1.1d">315</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.8">
<td class="ltx_td ltx_align_left" id="S3.T1.8.8.2">UK Legislation<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.legislation.gov.uk/" title="">https://www.legislation.gov.uk/</a></span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.1">
<math alttext="190" class="ltx_Math" display="inline" id="S3.T1.8.8.1.m1.1"><semantics id="S3.T1.8.8.1.m1.1a"><mn id="S3.T1.8.8.1.m1.1.1" xref="S3.T1.8.8.1.m1.1.1.cmml">190</mn><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.1.m1.1b"><cn id="S3.T1.8.8.1.m1.1.1.cmml" type="integer" xref="S3.T1.8.8.1.m1.1.1">190</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.1.m1.1c">190</annotation><annotation encoding="application/x-llamapun" id="S3.T1.8.8.1.m1.1d">190</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S3.T1.9.9">
<td class="ltx_td ltx_align_left" id="S3.T1.9.9.2">Court Transcripts<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>Obtained from CourtListener: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.courtlistener.com/" title="">https://www.courtlistener.com/</a>. We use Whisper <cite class="ltx_cite ltx_citemacro_citep">(Radford et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib61" title="">2022</a>)</cite> to transcribe the audio files.</span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.9.9.1">
<math alttext="350" class="ltx_Math" display="inline" id="S3.T1.9.9.1.m1.1"><semantics id="S3.T1.9.9.1.m1.1a"><mn id="S3.T1.9.9.1.m1.1.1" xref="S3.T1.9.9.1.m1.1.1.cmml">350</mn><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.1.m1.1b"><cn id="S3.T1.9.9.1.m1.1.1.cmml" type="integer" xref="S3.T1.9.9.1.m1.1.1">350</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.1.m1.1c">350</annotation><annotation encoding="application/x-llamapun" id="S3.T1.9.9.1.m1.1d">350</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S3.T1.10.10">
<td class="ltx_td ltx_align_left" id="S3.T1.10.10.2">UPSTO<span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://bulkdata.uspto.gov/" title="">https://bulkdata.uspto.gov/</a></span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.10.10.1">
<math alttext="4.7" class="ltx_Math" display="inline" id="S3.T1.10.10.1.m1.1"><semantics id="S3.T1.10.10.1.m1.1a"><mn id="S3.T1.10.10.1.m1.1.1" xref="S3.T1.10.10.1.m1.1.1.cmml">4.7</mn><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.1.m1.1b"><cn id="S3.T1.10.10.1.m1.1.1.cmml" type="float" xref="S3.T1.10.10.1.m1.1.1">4.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.1.m1.1c">4.7</annotation><annotation encoding="application/x-llamapun" id="S3.T1.10.10.1.m1.1d">4.7</annotation></semantics></math>B</td>
</tr>
<tr class="ltx_tr" id="S3.T1.11.11">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.11.11.2">Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.11.11.1">
<math alttext="94" class="ltx_Math" display="inline" id="S3.T1.11.11.1.m1.1"><semantics id="S3.T1.11.11.1.m1.1a"><mn id="S3.T1.11.11.1.m1.1.1" xref="S3.T1.11.11.1.m1.1.1.cmml">94</mn><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.1.m1.1b"><cn id="S3.T1.11.11.1.m1.1.1.cmml" type="integer" xref="S3.T1.11.11.1.m1.1.1">94</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.1.m1.1c">94</annotation><annotation encoding="application/x-llamapun" id="S3.T1.11.11.1.m1.1d">94</annotation></semantics></math>B</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span><span class="ltx_text ltx_font_bold" id="S3.T1.13.1">Sources of Legal Pretraining Data.</span> These sources contain noise and heavily duplicated documents, which we filtered and deduplicated, resulting in a 30 billion tokens dataset.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS1.Px1.p2">
<p class="ltx_p" id="S3.SS1.SSS1.Px1.p2.1">There is quite a lot of overlap between the different sources, and we run very aggressive cleaning and deduplication steps, described in <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS2" title="3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.2</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS1.Px2">
<h5 class="ltx_title ltx_title_paragraph">Replay Sources</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS1.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS1.Px2.p1.1">To reduce the risk of catastrophic forgetting <cite class="ltx_cite ltx_citemacro_citep">(McCloskey and Cohen, <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib48" title="">1989</a>)</cite> during continued pretraining, we incorporate data from the prior training distribution, following prior literature <cite class="ltx_cite ltx_citemacro_cite">Chen et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib12" title="">2023</a>); Sun et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib69" title="">2020</a>)</cite>. However, since the training data for Mistral is undisclosed, we introduce commonly available “general” data from Wikipedia, StackExchange, and GitHub, comprising roughly <math alttext="2\%" class="ltx_Math" display="inline" id="S3.SS1.SSS1.Px2.p1.1.m1.1"><semantics id="S3.SS1.SSS1.Px2.p1.1.m1.1a"><mrow id="S3.SS1.SSS1.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.cmml"><mn id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.2" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.2.cmml">2</mn><mo id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.1" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px2.p1.1.m1.1b"><apply id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1"><csymbol cd="latexml" id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.1">percent</csymbol><cn id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.2.cmml" type="integer" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.2">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px2.p1.1.m1.1c">2\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.Px2.p1.1.m1.1d">2 %</annotation></semantics></math> of the final training mix. These datasets are sampled from SlimPajama <cite class="ltx_cite ltx_citemacro_cite">Shen et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib66" title="">2023</a>); Computer (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib15" title="">2023</a>); Soboleva et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib68" title="">2023</a>)</cite>.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS1.Px3">
<h5 class="ltx_title ltx_title_paragraph">Instruction Sources</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS1.Px3.p1">
<p class="ltx_p" id="S3.SS1.SSS1.Px3.p1.1">Additionally, we found it beneficial to include conversational data during pretraining. This is inspired by recent advances in neural machine translation, which highlight that the robust capabilities of LLMs in translation are due to the existence of accidental parallel data in the training corpus <cite class="ltx_cite ltx_citemacro_cite">Anil et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib4" title="">2023</a>); Briakou et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib7" title="">2023</a>)</cite>. Specifically, this means that we include the Super Natural Instruction <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib79" title="">2022</a>)</cite> and FLAN collection <cite class="ltx_cite ltx_citemacro_cite">Longpre et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib44" title="">2023</a>)</cite> during pretraining.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Data Cleaning</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">A significant fraction of the collected data is either in PDF files or is text extracted from PDFs<span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span>We used <a class="ltx_ref ltx_href" href="https://poppler.freedesktop.org/" title="">Poppler</a> for text extraction from PDF files.</span></span></span>. This means that the text has some artifacts, including i) page numbers in the middle of sentences; ii) line numbers; iii) non-normalized unicode characters; iv) broken lines of text; v) repeated characters: new lines, dashes, etc; vi) other artifacts. We addressed these issues using a combination of rules and heuristics to filter the data.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S3.SS1.SSS2.Px1">
<h5 class="ltx_title ltx_title_paragraph">Text Normalization</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS2.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS2.Px1.p1.1">We normalize all unicode with the NFKC method, available through the <span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS2.Px1.p1.1.1">unicodedata</span> Python package.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS2.Px2">
<h5 class="ltx_title ltx_title_paragraph">Rule filters</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS2.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.Px2.p1.2">Following <cite class="ltx_cite ltx_citemacro_citet">Elazar et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib20" title="">2023</a>)</cite>, we found the most common 10-grams in our dataset and used regular expressions to remove the undesired ones, which were mostly repeated characters. Concretely, <math alttext="8" class="ltx_Math" display="inline" id="S3.SS1.SSS2.Px2.p1.1.m1.1"><semantics id="S3.SS1.SSS2.Px2.p1.1.m1.1a"><mn id="S3.SS1.SSS2.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS2.Px2.p1.1.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.Px2.p1.1.m1.1b"><cn id="S3.SS1.SSS2.Px2.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS1.SSS2.Px2.p1.1.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.Px2.p1.1.m1.1c">8</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.Px2.p1.1.m1.1d">8</annotation></semantics></math> of the top <math alttext="10" class="ltx_Math" display="inline" id="S3.SS1.SSS2.Px2.p1.2.m2.1"><semantics id="S3.SS1.SSS2.Px2.p1.2.m2.1a"><mn id="S3.SS1.SSS2.Px2.p1.2.m2.1.1" xref="S3.SS1.SSS2.Px2.p1.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.Px2.p1.2.m2.1b"><cn id="S3.SS1.SSS2.Px2.p1.2.m2.1.1.cmml" type="integer" xref="S3.SS1.SSS2.Px2.p1.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.Px2.p1.2.m2.1c">10</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.Px2.p1.2.m2.1d">10</annotation></semantics></math> 10-grams in the original data were repeated characters, eg: “<span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS2.Px2.p1.2.1">- - - - - - - - - -</span>”, “<span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS2.Px2.p1.2.2">. . . . . . . . . .</span>”, or “<span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS2.Px2.p1.2.3">* * * * * * * * * *</span>”, and weird characters, ie encoding issues. Additionally, we removed repeated whitespace (spaces, new lines, and tabs), as well as any HTML tag that made it through our pipeline.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS2.Px3">
<h5 class="ltx_title ltx_title_paragraph">Perplexity filtering</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS2.Px3.p1">
<p class="ltx_p" id="S3.SS1.SSS2.Px3.p1.1">We trained a KenLM model <cite class="ltx_cite ltx_citemacro_citep">(Heafield, <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib29" title="">2011</a>)</cite> on a small subset of carefully inspected legal data, and used it to filter any high perplexity paragraph. This removed non-English text as well as most of the “weird” unicode sequences present in the data. We show some of the most common <math alttext="10" class="ltx_Math" display="inline" id="S3.SS1.SSS2.Px3.p1.1.m1.1"><semantics id="S3.SS1.SSS2.Px3.p1.1.m1.1a"><mn id="S3.SS1.SSS2.Px3.p1.1.m1.1.1" xref="S3.SS1.SSS2.Px3.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.Px3.p1.1.m1.1b"><cn id="S3.SS1.SSS2.Px3.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS1.SSS2.Px3.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.Px3.p1.1.m1.1c">10</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.Px3.p1.1.m1.1d">10</annotation></semantics></math>-grams in the filtered data on <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.T2" title="Table 2 ‣ Perplexity filtering ‣ 3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1">Common 10-grams</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.2.1.1"><span class="ltx_text ltx_font_typewriter" id="S3.T2.1.2.1.1.1">have been obvious to one of ordinary skill in the</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.3.2">
<td class="ltx_td ltx_align_center" id="S3.T2.1.3.2.1"><span class="ltx_text ltx_font_typewriter" id="S3.T2.1.3.2.1.1">before the effective filing date of the claimed invention to</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.4.3.1"><span class="ltx_text ltx_font_typewriter" id="S3.T2.1.4.3.1.1">rejected under 35 U.S.C . 103 as being unpatentable over</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span><span class="ltx_text ltx_font_bold" id="S3.T2.3.1">Most common 10-grams</span> in the pretraining dataset.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>Data Deduplication</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS3.p1">
<p class="ltx_p" id="S3.SS1.SSS3.p1.1">Inspired by <cite class="ltx_cite ltx_citemacro_citet">Kocetkov et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib37" title="">2023</a>); Lee et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib39" title="">2021</a>)</cite>, we removed duplicates and near-duplicates from the training data using <cite class="ltx_cite ltx_citemacro_citet">Mou et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib50" title="">2023</a>)</cite>, with default parameters, after which we were left with roughly <math alttext="30" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.1.m1.1"><semantics id="S3.SS1.SSS3.p1.1.m1.1a"><mn id="S3.SS1.SSS3.p1.1.m1.1.1" xref="S3.SS1.SSS3.p1.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.1.m1.1b"><cn id="S3.SS1.SSS3.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS1.SSS3.p1.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.1.m1.1c">30</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.1.m1.1d">30</annotation></semantics></math>B tokens of high-quality text.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Instruction Finetuning Mixes</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Instruction fine-tuning is crucial for getting the best performance out of the pre-trained decoder models across different tasks. We use a mix of general and legal instructions to train the model to understand and follow instructions well, with a focus on legal expertise.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">General Instructions</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.1">When it comes to general instructions, we gather them from four primary sources:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">SlimOrca</span> This subset of the FLAN collection comprises generic instructions, offering a focused resource for various tasks <cite class="ltx_cite ltx_citemacro_cite">Mukherjee et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib51" title="">2023</a>); Lian et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib42" title="">2023</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">Meta Math Question Answering Instructions</span> Designed for mathematical inquiry, this dataset<span class="ltx_note ltx_role_footnote" id="footnote15"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span>Accessible at <a class="ltx_ref ltx_url ltx_font_typewriter" href="meta-math/MetaMathQA" title="">meta-math/MetaMathQA</a></span></span></span> presents a range of mathematical questions, facilitating research in math-based natural language processing <cite class="ltx_cite ltx_citemacro_cite">Yu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib87" title="">2023</a>)</cite>.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">General Conversations from UltraChat</span> Capturing diverse conversational contexts, this GPT-derived dataset contributes to enhancing natural language understanding and generation systems <cite class="ltx_cite ltx_citemacro_cite">Ding et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib19" title="">2023</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i4.p1.1.1">Code Instructions from Glaive Code Assistant v2<span class="ltx_note ltx_role_footnote" id="footnote16"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote16.1.1.1">16</span></span><span class="ltx_text ltx_font_medium" id="footnote16.9">Available at </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v2" title="">https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v2</a></span></span></span></span> Training on code has been shown to increase the reasoning ability of models <cite class="ltx_cite ltx_citemacro_citep">(Ma et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib46" title="">2023</a>)</cite></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p2.1">We meticulously filter, deduplicate, and curate all this data, resulting in a refined dataset comprising <math alttext="600" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p2.1.m1.1"><semantics id="S3.SS2.SSS0.Px1.p2.1.m1.1a"><mn id="S3.SS2.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.cmml">600</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.1.m1.1b"><cn id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.cmml" type="integer" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1">600</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.1.m1.1c">600</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px1.p2.1.m1.1d">600</annotation></semantics></math>K instructions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Legal Instruction Construction</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.1">We synthetically generate comprehensive conversations addressing fundamental legal competencies across multiple legal document types <cite class="ltx_cite ltx_citemacro_cite">Ding et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib19" title="">2023</a>)</cite>. We leverage a <span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS0.Px2.p1.1.1">Mistral-7B-instruct</span> to transform legal texts augmented with metadata into coherent conversations.
The methodology involves initiating the conversation with <math alttext="3" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.1.m1.1"><semantics id="S3.SS2.SSS0.Px2.p1.1.m1.1a"><mn id="S3.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.1.m1.1b"><cn id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px2.p1.1.m1.1d">3</annotation></semantics></math> predefined turns: (1) the user articulates a request related to the legal document, (2) the assistant responds by rephrasing the metadata (e.g., document type, date, name of a judge), and (3) the user prompts the assistant to elaborate on its reasoning. Subsequently, we extend the conversation through a series of turns, where a user model progressively poses more specific questions to grasp the assistant’s reasoning. Simultaneously, an assistant model provides in-depth insights. An illustrative example is presented in <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.F2" title="Figure 2 ‣ Legal Instruction Construction ‣ 3.2 Instruction Finetuning Mixes ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>. Notably, we ensure the exclusion of the test set from existing benchmarks.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="598" id="S3.F2.g1" src="x2.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text ltx_font_bold" id="S3.F2.9.1">Turning dataset with metadata into a conversation.</span> Taking the example of Reddit post classification, we turn a labeled example {"<span class="ltx_text ltx_font_italic" id="S3.F2.10.2">My employer fired me because …Is it legal?</span>", "<span class="ltx_text ltx_font_italic" id="S3.F2.11.3">employment</span>" }, we hard-code the first three turns of the conversation by simply reformulating the query and answer as a natural conversation. We then complete the conversation using a <span class="ltx_text ltx_font_italic" id="S3.F2.12.4">user</span> model(blue dashed), whose task is to continue generating relevant questions from the ongoing conversation, and an <span class="ltx_text ltx_font_italic" id="S3.F2.13.5">assistant</span> model that provides answers. Both <span class="ltx_text ltx_font_italic" id="S3.F2.14.6">assistant</span> and <span class="ltx_text ltx_font_italic" id="S3.F2.15.7">user</span> models are <span class="ltx_text ltx_font_typewriter" id="S3.F2.16.8">Mistral-7B-instruct</span>.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation of Legal Knowledge</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.2">To evaluate the model’s legal abilities, we use <math alttext="3" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><cn id="S4.p1.1.m1.1.1.cmml" type="integer" xref="S4.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">3</annotation></semantics></math> benchmarks (i) we compare the perplexity of the backbones on <math alttext="5" class="ltx_Math" display="inline" id="S4.p1.2.m2.1"><semantics id="S4.p1.2.m2.1a"><mn id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><cn id="S4.p1.2.m2.1.1.cmml" type="integer" xref="S4.p1.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">5</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m2.1d">5</annotation></semantics></math> types of legal documents, (ii) we enhance LegalBench with LegalBench-Instruct for deeper evaluation, (iii) we rely on the legal section of MMLU for additional insights.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Perplexity Measurement</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">To evaluate the adaptability of the backbones to legal documents, we assess perplexity using benchmark datasets spanning four distinct legal domains: <em class="ltx_emph ltx_font_italic" id="S4.SS0.SSS0.Px1.p1.1.1">contracts, judicial decisions, opinion text, and legislation</em>. We ensure that the datasets are up-to-date, and sourced after the collection cut-off date from LLM data. Specifically, contract data is sourced from EDGAR (first quarter of 2024), legal decisions from ICSID court decisions published after October 2023, legislation focuses on US bills submitted before the House or Senate after October 2023, and party submissions include Texas briefs submitted after October 2023.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p2.1">During our investigations, we found a significant limitation in the original prompts of LegalBench. The complex nature of these prompts, combined with the challenges encountered by open source LLMs in adhering to instructions - particularly in handling formatting - leads to a substantial drop in performance (as measured by accuracy). The generated sentences are often verbose and difficult to parse, rendering LegalBench in its current form too stringent and failing to accurately gauge improvement on the task.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p3.1">For example, in some of the tasks, performance is evaluated by the first word the model predicts, and this word is expected to be a <em class="ltx_emph ltx_font_italic" id="S4.SS0.SSS0.Px1.p3.1.1">Yes/No</em>. This means that if the response is a bit verbose it will be counted as incorrect, even if a human would classify it as a correct answer. To remedy this shortcoming, we refine the prompts by 1) removing distracting few-shot examples and 2) concluding with a specific instruction for the model to generate tags (see <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S4.T3" title="Table 3 ‣ Perplexity Measurement ‣ 4 Evaluation of Legal Knowledge ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a>).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.1.1">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1" style="width:199.2pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S4.T3.1.1.1.1.1">Original Prompt</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.2.1">
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T3.1.2.1.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.2.1.1.1">The Telemarketing Sales Rule is provided by 16 C.F.R. § 310.3(a)(1) and 16 C.F.R. § 310.3(a)(2).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.3.2">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.3.2.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.3.2.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.1.1.1">Question:</span> Acme Toys is a telemarketer subject to the Telemarketing Sales Rule. Acme Toys told a customer that its frisbees cost $10 each, when in fact the frisbees cost $12 each. The customer agreed to the sale and was charged $12. Is this a violation of the Telemarketing Sales Rule?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.4.3">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.4.3.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.4.3.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.4.3.1.1.1">Answer:</span> Yes</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.5.4">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.5.4.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.5.4.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.5.4.1.1.1">Question:</span> Acme Toys is a telemarketer subject to the Telemarketing Sales Rule. Acme Toys told a customer that its frisbees cost $10 each, when in fact the frisbees did cost $10, but Acme Toys did not disclose that shipping would cost an additional $5. The customer agreed to the sale. Is this a violation of the Telemarketing Sales Rule?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.6.5">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.6.5.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.6.5.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.6.5.1.1.1">Answer:</span> Yes</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.7.6">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.7.6.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.7.6.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.7.6.1.1.1">Question:</span> Acme Industrial Products is a telemarketer subject to the Telemarketing Sales Rule. Acme Industrial Products told a customer that its brooms cost $12 each, and the brooms did in fact cost $12. The customer agreed to the sale. Is this a violation of the Telemarketing Sales Rule?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.8.7">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.8.7.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.8.7.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.8.7.1.1.1">Answer:</span> No</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.9.8">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.9.8.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.9.8.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.9.8.1.1.1">Question:</span> Acme Industrial Products is a telemarketer subject to the Telemarketing Sales Rule. Acme Industrial Products told a customer that it would sell them 4 brooms for $10 and that shipping would be $5. Then, the customer agreed to the sale. Is this a violation of the Telemarketing Sales Rule?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.10.9">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.10.9.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.10.9.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.10.9.1.1.1">Answer:</span> No</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.11.10">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.11.10.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.11.10.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.11.10.1.1.1">Question:</span> {text}</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.12.11">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.12.11.1" style="width:199.2pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S4.T3.1.12.11.1.1">Answer:</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.13.12">
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T3.1.13.12.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.13.12.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.13.12.1.1.1">Curated Prompt</span> (Ours)</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.14.13">
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S4.T3.1.14.13.1" style="width:199.2pt;">
<div class="ltx_block ltx_align_top" id="S4.T3.1.14.13.1.1">
<p class="ltx_p" id="S4.T3.1.14.13.1.1.1">The Telemarketing Sales Rule is provided by 16 C.F.R. § 310.3(a)(1) and 16 C.F.R. § 310.3(a)(2).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="S4.T3.1.14.13.1.1.2">Answer the following question: {text}</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="S4.T3.1.14.13.1.1.3"><span class="ltx_text ltx_font_italic" id="S4.T3.1.14.13.1.1.3.1">Answer by only outputting "Yes" or "No"</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span><span class="ltx_text ltx_font_bold" id="S4.T3.3.1">Example from LegalBench-Instruct</span>. We manually curated and corrected typos, removing a few short examples from LegalBench as they were found to distract LLMs of size 7B.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Massive Multitask Language Understanding (MMLU)</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.3">The MMLU benchmark <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib31" title="">2020</a>)</cite> has been widely employed to gauge the advances in LLM performance. In our study, we center our analysis on the legal domain, with a specific focus on:
<span class="ltx_text ltx_font_italic" id="S4.SS0.SSS0.Px2.p1.3.1">international law</span>, <span class="ltx_text ltx_font_italic" id="S4.SS0.SSS0.Px2.p1.3.2">professional law</span>, and <span class="ltx_text ltx_font_italic" id="S4.SS0.SSS0.Px2.p1.3.3">jurisprudence</span>. Those tasks respectively contain <math alttext="120" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS0.SSS0.Px2.p1.1.m1.1a"><mn id="S4.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">120</mn><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.1.m1.1b"><cn id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1">120</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.1.m1.1c">120</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.1.m1.1d">120</annotation></semantics></math>, <math alttext="1500" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.2.m2.1"><semantics id="S4.SS0.SSS0.Px2.p1.2.m2.1a"><mn id="S4.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">1500</mn><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.2.m2.1b"><cn id="S4.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" type="integer" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1">1500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.2.m2.1c">1500</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.2.m2.1d">1500</annotation></semantics></math>, and <math alttext="110" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.3.m3.1"><semantics id="S4.SS0.SSS0.Px2.p1.3.m3.1a"><mn id="S4.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS0.SSS0.Px2.p1.3.m3.1.1.cmml">110</mn><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.3.m3.1b"><cn id="S4.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" type="integer" xref="S4.SS0.SSS0.Px2.p1.3.m3.1.1">110</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.3.m3.1c">110</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.3.m3.1d">110</annotation></semantics></math> examples.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Metrics</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We use the same metric as the original LegalBench <cite class="ltx_cite ltx_citemacro_cite">Guha et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib26" title="">2023</a>)</cite> paper: balanced accuracy. Balanced accuracy allows for handling better-imbalanced classification tasks, such as the ones presented in both benchmarks. We also use balanced accuracy for the legal tasks of MMLU. Unless otherwise noted, any score reported throughout this section refers to the balanced accuracy.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Setting</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="747" id="S5.F3.g1" src="x3.png" width="747">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span class="ltx_text ltx_font_bold" id="S5.F3.4.1">Performance of base models on LegalBench-Instruct.</span> Interestingly, although not instruction fine-tuned, <span class="ltx_text ltx_font_typewriter" id="S5.F3.5.2">SaulLM-7B</span> is still able to achieve impressive improvements on the benchmark, compared to other base models, including <span class="ltx_text ltx_font_typewriter" id="S5.F3.6.3">SaulLM-7B</span>’s initial checkpoint (Mistral-7B).</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Baselines</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.2">We compare the <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.2.1">SaulLM-7B</span> family to other state-of-the-art <math alttext="7" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><mn id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><cn id="S5.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S5.SS1.p1.1.m1.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">7</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">7</annotation></semantics></math>B and <math alttext="13" class="ltx_Math" display="inline" id="S5.SS1.p1.2.m2.1"><semantics id="S5.SS1.p1.2.m2.1a"><mn id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">13</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><cn id="S5.SS1.p1.2.m2.1.1.cmml" type="integer" xref="S5.SS1.p1.2.m2.1.1">13</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">13</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.2.m2.1d">13</annotation></semantics></math>B open-source models. Concretely, we include the following instruction and DPO finetuned variants of Mistral-7B <cite class="ltx_cite ltx_citemacro_citep">(Jiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib34" title="">2023</a>)</cite>: <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.2.2">Mistral-7B-Instruct-v0.1</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.2.3">Mistral-7B-Instruct-v0.2</span>
, as well as <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.2.4">zephyr-7b-beta<span class="ltx_note ltx_role_footnote" id="footnote17"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote17.1.1.1">17</span></span><a class="ltx_ref ltx_url" href="https://huggingface.co/HuggingFaceH4/zephyr-7b-beta" title="">https://huggingface.co/HuggingFaceH4/zephyr-7b-beta</a></span></span></span></span>. We also evaluate the Llama2 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib71" title="">2023a</a>)</cite> family, more specifically <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.2.5">Llama2-7b-Chat</span>and <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.2.6">Llama2-13b-Chat</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Implementation Details</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Codebase</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p1.1">Our codebase relies on open-source frameworks <cite class="ltx_cite ltx_citemacro_cite">Shoeybi et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib67" title="">2019</a>); Wolf et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib82" title="">2019</a>); Lhoest et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib40" title="">2021</a>)</cite> utilizing DeepSpeed (level 3) with Flash attention <cite class="ltx_cite ltx_citemacro_cite">Dao et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib18" title="">2022</a>); Dao (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib17" title="">2023</a>)</cite>. It is built on PyTorch <cite class="ltx_cite ltx_citemacro_cite">Paszke et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib58" title="">2019</a>)</cite>, and our models are available on the Huggingface hub.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Compute</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px2.p1.1">Continuous pretraining utilizes <math alttext="256" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px2.p1.1.m1.1"><semantics id="S5.SS2.SSS0.Px2.p1.1.m1.1a"><mn id="S5.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.1.m1.1b"><cn id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" type="integer" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.1.m1.1c">256</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px2.p1.1.m1.1d">256</annotation></semantics></math> MI250 AMD GPUs. For instruction fine-tuning, workload distribution occurs across 16 MI250. Evaluation procedures are seamlessly conducted on a single MI250.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this section, we discuss our main experimental findings and results.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>LegalBench-Instruct</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S5.F3" title="Figure 3 ‣ 5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figures</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a> and&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.F4" title="Figure 4 ‣ I. Legal continued pretraining brings significant improvements ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">4</span></a> summarize our results on LegalBench-Instruct. There are <math alttext="3" class="ltx_Math" display="inline" id="S6.SS1.p1.1.m1.1"><semantics id="S6.SS1.p1.1.m1.1a"><mn id="S6.SS1.p1.1.m1.1.1" xref="S6.SS1.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.1.m1.1b"><cn id="S6.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S6.SS1.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.p1.1.m1.1d">3</annotation></semantics></math> main takeaways, which we discuss below.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S6.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">I. Legal continued pretraining brings significant improvements</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS1.SSS0.Px1.p1.4">We start by analyzing the impact of our proposed continued pretraining. As seen on <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S5.F3" title="Figure 3 ‣ 5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a>, <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px1.p1.4.1">SaulLM-7B</span> is a strong standalone model. We speculate that its strong performance is largely due to the integration of instructions in the pre-training data, as mentioned in <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS1" title="3.1.1 Dataset Composition ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">subsubsection&nbsp;3.1.1</span></a>. Nevertheless, we still note that even without a dedicated instruction fine-tuning stage, <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px1.p1.4.2">SaulLM-7B</span> performs on par with <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px1.p1.4.3">Llama2-7B-chat</span> (<math alttext="0.38" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="S6.SS1.SSS0.Px1.p1.1.m1.1a"><mn id="S6.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S6.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">0.38</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.1.m1.1b"><cn id="S6.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" type="float" xref="S6.SS1.SSS0.Px1.p1.1.m1.1.1">0.38</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.1.m1.1c">0.38</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px1.p1.1.m1.1d">0.38</annotation></semantics></math> v.s. <math alttext="0.39" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px1.p1.2.m2.1"><semantics id="S6.SS1.SSS0.Px1.p1.2.m2.1a"><mn id="S6.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S6.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">0.39</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.2.m2.1b"><cn id="S6.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" type="float" xref="S6.SS1.SSS0.Px1.p1.2.m2.1.1">0.39</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.2.m2.1c">0.39</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px1.p1.2.m2.1d">0.39</annotation></semantics></math>). More importantly, <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px1.p1.4.4">SaulLM-7B</span> serves as a strong base model for building IFT models with strong legal capabilities. When combined with Generic instruction finetuning, as seen on <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.F4" title="Figure 4 ‣ I. Legal continued pretraining brings significant improvements ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">4</span></a>, it achieves a strong average of <math alttext="0.59" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px1.p1.3.m3.1"><semantics id="S6.SS1.SSS0.Px1.p1.3.m3.1a"><mn id="S6.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S6.SS1.SSS0.Px1.p1.3.m3.1.1.cmml">0.59</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.3.m3.1b"><cn id="S6.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" type="float" xref="S6.SS1.SSS0.Px1.p1.3.m3.1.1">0.59</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.3.m3.1c">0.59</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px1.p1.3.m3.1d">0.59</annotation></semantics></math>, i.e. <math alttext="4" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px1.p1.4.m4.1"><semantics id="S6.SS1.SSS0.Px1.p1.4.m4.1a"><mn id="S6.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S6.SS1.SSS0.Px1.p1.4.m4.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.4.m4.1b"><cn id="S6.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" type="integer" xref="S6.SS1.SSS0.Px1.p1.4.m4.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.4.m4.1c">4</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px1.p1.4.m4.1d">4</annotation></semantics></math> absolute points of improvement with respect to the best open-source instruct model <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px1.p1.4.5">Mistral-7B-Instruct-v0.1</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S6.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="465" id="S6.F4.g1" src="x4.png" width="581">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span class="ltx_text ltx_font_bold" id="S6.F4.4.1">Influence of the base model.</span> Starting the instruction finetuning from our base model <span class="ltx_text ltx_font_typewriter" id="S6.F4.5.2">SaulLM-7B</span> brings noticeable improvements compared to the Mistral-7B. Indeed, even with a generic IFT mix (without legal), <span class="ltx_text ltx_font_typewriter" id="S6.F4.6.3">SaulLM-7B</span> (Gen.) outperforms its Mistral-Instruct counterpart significantly. Adding legal instructions to the IFT mix further boosts the results.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S6.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">II. Legal instruction finetuning further boosts the results</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS1.SSS0.Px2.p1.2">As seen on <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.F2" title="Figure 2 ‣ Legal Instruction Construction ‣ 3.2 Instruction Finetuning Mixes ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>, finetuning <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px2.p1.2.1">SaulLM-7B</span> on both general and legal instructions (<span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px2.p1.2.2">SaulLM-7B-Instruct</span>) establishes a new state-of-the-art on the LegalBench-Instruct benchmark, with an average score of <math alttext="0.61" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px2.p1.1.m1.1"><semantics id="S6.SS1.SSS0.Px2.p1.1.m1.1a"><mn id="S6.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S6.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">0.61</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p1.1.m1.1b"><cn id="S6.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" type="float" xref="S6.SS1.SSS0.Px2.p1.1.m1.1.1">0.61</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p1.1.m1.1c">0.61</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px2.p1.1.m1.1d">0.61</annotation></semantics></math>, i.e. an <math alttext="11" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px2.p1.2.m2.1"><semantics id="S6.SS1.SSS0.Px2.p1.2.m2.1a"><mn id="S6.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S6.SS1.SSS0.Px2.p1.2.m2.1.1.cmml">11</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p1.2.m2.1b"><cn id="S6.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" type="integer" xref="S6.SS1.SSS0.Px2.p1.2.m2.1.1">11</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p1.2.m2.1c">11</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px2.p1.2.m2.1d">11</annotation></semantics></math>% relative improvement compared to the best open-source instruct model (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.F5" title="Figure 5 ‣ II. Legal instruction finetuning further boosts the results ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">5</span></a>.
Finally, DPO-aligned models tend to underperform their instruction-tuned counterparts, which could be explained by the fact that generic alignment is not suited for out-of-distribution tasks, such as the ones present in LegalBench-Instruct. Although beyond the scope of the present work, an interesting research direction would be to explore how legal-specific DPO can help.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S6.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="553" id="S6.F5.g1" src="x5.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span class="ltx_text ltx_font_bold" id="S6.F5.3.1">Comparison of instruct models on LegalBench-Instruct</span>. <span class="ltx_text ltx_font_typewriter" id="S6.F5.4.2">SaulLM-7B-Instruct</span> establishes the state-of-the-art, outperforming the best Mistral-Instruct model by a significant 6 absolute points.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S6.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1328" id="S6.F6.g1" src="x6.png" width="498">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span class="ltx_text ltx_font_bold" id="S6.F6.4.1">Instruct models on Legal-MMLU.</span> Echoing finding on LegalBench-Instruct, <span class="ltx_text ltx_font_typewriter" id="S6.F6.5.2">SaulLM-7B-Instruct</span> displays superior performance on all three tasks of Legal-MMLU, with an average absolute improvement of 5 points with respect to <span class="ltx_text ltx_font_typewriter" id="S6.F6.6.3">Mistral-7B-Instruct-v0.1</span>. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S6.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">III. There is still room for significant improvement.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S6.SS1.SSS0.Px3.p1.1">Next, we follow the original LegalBench taxonomy <cite class="ltx_cite ltx_citemacro_citep">(Guha et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib26" title="">2023</a>)</cite> to gain a more granular understanding of <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px3.p1.1.1">SaulLM-7B-Instruct</span>’s performance, by partitioning the tasks into <math alttext="5" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px3.p1.1.m1.1"><semantics id="S6.SS1.SSS0.Px3.p1.1.m1.1a"><mn id="S6.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S6.SS1.SSS0.Px3.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px3.p1.1.m1.1b"><cn id="S6.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" type="integer" xref="S6.SS1.SSS0.Px3.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px3.p1.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px3.p1.1.m1.1d">5</annotation></semantics></math> core legal abilities: <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.2">Issue Spotting</span>, <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.3">Rule-Recall</span>, <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.4">Interpretation</span>, <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.5">Rhetoric Understanding</span>, and <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.6">Rule-Conclusion</span>. Results show an interesting trend (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.F7" title="Figure 7 ‣ III. There is still room for significant improvement. ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">7</span></a>): <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px3.p1.1.7">SaulLM-7B-Instruct</span> shows clear superior performance over the best non-legal competitor <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px3.p1.1.8">Mistral-7B-Instruct-v0.1</span> on the four areas that require the most legal expertise, i.e. <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.9">Issue</span>, <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.10">Rule</span>, <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.11">Interpretation</span> and <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.12">Understanding</span>. On the other hand, it falls short of <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px3.p1.1.13">Mistral-7B-Instruct-v0.1</span> on the <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.14">Conclusion</span> tasks, which interestingly require much more pure deductive reasoning than actual legal knowledge. We speculate that augmenting our pretraining and fine-tuning corpora with more deductive reasoning content, including but not limited to mathematics datasets could reduce the gap and fully unlock the potential of <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px3.p1.1.15">SaulLM-7B-Instruct</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S6.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="627" id="S6.F7.g1" src="x7.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span class="ltx_text ltx_font_bold" id="S6.F7.3.1">Per-task performance breakdown.</span> <span class="ltx_text ltx_font_typewriter" id="S6.F7.4.2">SaulLM-7B-Instruct</span> largely outperforms generic Instruct models on tasks that most require legal-specific knowledge, but is outperformed by Mistral-Instruct on the conclusion tasks, which necessitates more deductive reasoning.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Results on Legal-MMLU</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.2">To confirm our observations on LegalBench-Instruct, we analyze the results on Legal-MMLU shown in <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.F6" title="Figure 6 ‣ II. Legal instruction finetuning further boosts the results ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">6</span></a>. Again, <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p1.2.1">SaulLM-7B-Instruct</span> exhibits consistent superiority over non-legal instruction-tuned models, with a gap between <math alttext="3" class="ltx_Math" display="inline" id="S6.SS2.p1.1.m1.1"><semantics id="S6.SS2.p1.1.m1.1a"><mn id="S6.SS2.p1.1.m1.1.1" xref="S6.SS2.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.1.m1.1b"><cn id="S6.SS2.p1.1.m1.1.1.cmml" type="integer" xref="S6.SS2.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p1.1.m1.1d">3</annotation></semantics></math> and <math alttext="4" class="ltx_Math" display="inline" id="S6.SS2.p1.2.m2.1"><semantics id="S6.SS2.p1.2.m2.1a"><mn id="S6.SS2.p1.2.m2.1.1" xref="S6.SS2.p1.2.m2.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.2.m2.1b"><cn id="S6.SS2.p1.2.m2.1.1.cmml" type="integer" xref="S6.SS2.p1.2.m2.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.2.m2.1c">4</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p1.2.m2.1d">4</annotation></semantics></math> absolute points to the best 7B open-source competitor across the three tasks, providing additional evidence that <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p1.2.2">SaulLM-7B-Instruct</span> is as a strong foundation to build models tailored to legal workflows.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S6.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="622" id="S6.F8.g1" src="x8.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span><span class="ltx_text ltx_font_bold" id="S6.F8.17.1">Perplexity on legal documents for pretrained backbones.</span> <span class="ltx_text ltx_font_typewriter" id="S6.F8.18.2">SaulLM-7B-Instruct</span> outperforms other pretrained backbones on most types of legal documents, but is outperformed by <span class="ltx_text ltx_font_typewriter" id="S6.F8.19.3">Llama2-7b</span> on Legislation.
<span class="ltx_text ltx_font_typewriter" id="S6.F8.20.4">SaulLM-7B-Instruct</span> exhibits a median perplexity of <math alttext="8.69" class="ltx_Math" display="inline" id="S6.F8.6.m1.1"><semantics id="S6.F8.6.m1.1b"><mn id="S6.F8.6.m1.1.1" xref="S6.F8.6.m1.1.1.cmml">8.69</mn><annotation-xml encoding="MathML-Content" id="S6.F8.6.m1.1c"><cn id="S6.F8.6.m1.1.1.cmml" type="float" xref="S6.F8.6.m1.1.1">8.69</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.6.m1.1d">8.69</annotation><annotation encoding="application/x-llamapun" id="S6.F8.6.m1.1e">8.69</annotation></semantics></math>, having a reduction of <math alttext="5.5" class="ltx_Math" display="inline" id="S6.F8.7.m2.1"><semantics id="S6.F8.7.m2.1b"><mn id="S6.F8.7.m2.1.1" xref="S6.F8.7.m2.1.1.cmml">5.5</mn><annotation-xml encoding="MathML-Content" id="S6.F8.7.m2.1c"><cn id="S6.F8.7.m2.1.1.cmml" type="float" xref="S6.F8.7.m2.1.1">5.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.7.m2.1d">5.5</annotation><annotation encoding="application/x-llamapun" id="S6.F8.7.m2.1e">5.5</annotation></semantics></math> percent compared to <span class="ltx_text ltx_font_typewriter" id="S6.F8.21.5">Mistral-7B</span>, <math alttext="9.20" class="ltx_Math" display="inline" id="S6.F8.8.m3.1"><semantics id="S6.F8.8.m3.1b"><mn id="S6.F8.8.m3.1.1" xref="S6.F8.8.m3.1.1.cmml">9.20</mn><annotation-xml encoding="MathML-Content" id="S6.F8.8.m3.1c"><cn id="S6.F8.8.m3.1.1.cmml" type="float" xref="S6.F8.8.m3.1.1">9.20</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.8.m3.1d">9.20</annotation><annotation encoding="application/x-llamapun" id="S6.F8.8.m3.1e">9.20</annotation></semantics></math>, and <math alttext="10.8" class="ltx_Math" display="inline" id="S6.F8.9.m4.1"><semantics id="S6.F8.9.m4.1b"><mn id="S6.F8.9.m4.1.1" xref="S6.F8.9.m4.1.1.cmml">10.8</mn><annotation-xml encoding="MathML-Content" id="S6.F8.9.m4.1c"><cn id="S6.F8.9.m4.1.1.cmml" type="float" xref="S6.F8.9.m4.1.1">10.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.9.m4.1d">10.8</annotation><annotation encoding="application/x-llamapun" id="S6.F8.9.m4.1e">10.8</annotation></semantics></math> percent compared to <span class="ltx_text ltx_font_typewriter" id="S6.F8.22.6">Llama2-7B</span>, with a median perplexity of <math alttext="9.74" class="ltx_Math" display="inline" id="S6.F8.10.m5.1"><semantics id="S6.F8.10.m5.1b"><mn id="S6.F8.10.m5.1.1" xref="S6.F8.10.m5.1.1.cmml">9.74</mn><annotation-xml encoding="MathML-Content" id="S6.F8.10.m5.1c"><cn id="S6.F8.10.m5.1.1.cmml" type="float" xref="S6.F8.10.m5.1.1">9.74</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.10.m5.1d">9.74</annotation><annotation encoding="application/x-llamapun" id="S6.F8.10.m5.1e">9.74</annotation></semantics></math>.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Perplexity Analysis</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">To assess the adaptation of <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.1.1">SaulLM-7B</span> backbone to the legal domain, we present perplexity scores across four document types: contracts, legal decisions, legislation, and party submissions. Refer to <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2403.03883v2#S6.F8" title="Figure 8 ‣ 6.2 Results on Legal-MMLU ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure&nbsp;8</span></a> for the results. Our model, <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.1.2">SaulLM-7B</span>, consistently outperforms <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.1.3">Mistral-7B</span> across all categories, exhibiting lower average perplexity scores with reduced variance. Interestingly, <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.1.4">Llama2-7B</span> demonstrates lower perplexity specifically in legislation documents, suggesting a potentially higher proportion of legislative text in the pertaining corpora compared to <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.1.5">Mistral-7B</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1">Overall, compared to <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p2.1.1">Mistral-7B</span>, our model shows a median perplexity reduction of 3 percent across legal corpora and 11 percent when compared to <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p2.1.2">Llama2-7B</span>.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion &amp; Future Perspectives</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In this paper, we introduce <span class="ltx_text ltx_font_typewriter" id="S7.p1.1.1">SaulLM-7B</span>, an open-source decoder model delivering state-of-the-art performance, compared to 7B models, within the legal domain. Our approach entails fine-tuning legal data alongside instruction fine-tuning on synthetic datasets. Additionally, we contribute by providing a cleaned version of LegalBench and introducing a new set of documents for perplexity measurement. We hope that our model, which is released under the MIT license, will contribute to the open-source ecosystem and the community.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">We thank GENCI for generously granting us access to their cutting-edge computing resources. Our model, <span class="ltx_text ltx_font_typewriter" id="Sx1.p1.1.1">SaulLM-7B</span>, has been trained on ADASTRA, with initial experimentation conducted on Jeanzay. The utilization of HPC resources was made possible through the Jeanzay grants 101838, 103256, and 103298, as well as the Adastra grants C1615122, CAD14770, and CAD15031.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia&nbsp;Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08774</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aletras et&nbsp;al. (2016)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Nikolaos Aletras, Dimitrios Tsarapatsanis, Daniel Preoţiuc-Pietro, and Vasileios Lampos. 2016.

</span>
<span class="ltx_bibblock">Predicting judicial decisions of the european court of human rights: A natural language processing perspective.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">PeerJ computer science</em>, 2:e93.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Almazrouei et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Mérouane Debbah, Étienne Goffinet, Daniel Hesslow, Julien Launay, Quentin Malartic, Daniele Mazzotta, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2311.16867" title="">The falcon series of open language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rohan Anil, Andrew&nbsp;M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Palm 2 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2305.10403</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu&nbsp;Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An&nbsp;Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2309.16609" title="">Qwen technical report</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biderman et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Stella Biderman, Hailey Schoelkopf, Quentin&nbsp;Gregory Anthony, Herbie Bradley, Kyle O’Brien, Eric Hallahan, Mohammad&nbsp;Aflah Khan, Shivanshu Purohit, USVSN&nbsp;Sai Prashanth, Edward Raff, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Pythia: A suite for analyzing large language models across training and scaling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">International Conference on Machine Learning</em>, pages 2397–2430. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Briakou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Eleftheria Briakou, Colin Cherry, and George Foster. 2023.

</span>
<span class="ltx_bibblock">Searching for needles in a haystack: On the role of incidental bilingualism in palm’s translation capability.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2305.10266</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Butler (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Umar Butler. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.57967/hf/1306" title="">Open australian legal corpus</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yihan Cao, Yanbin Kang, and Lichao Sun. 2023.

</span>
<span class="ltx_bibblock">Instruction mining: High-quality instruction data selection for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2307.06290</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chalkidis et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ilias Chalkidis, Ion Androutsopoulos, and Nikolaos Aletras. 2019.

</span>
<span class="ltx_bibblock">Neural legal judgment prediction in english.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:1906.02059</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chalkidis et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ilias Chalkidis, Manos Fergadiotis, Prodromos Malakasiotis, Nikolaos Aletras, and Ion Androutsopoulos. 2020.

</span>
<span class="ltx_bibblock">Legal-bert: The muppets straight out of law school.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2010.02559</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zeming Chen, Alejandro&nbsp;Hernández Cano, Angelika Romanou, Antoine Bonnet, Kyle Matoba, Francesco Salvi, Matteo Pagliardini, Simin Fan, Andreas Köpf, Amirkeivan Mohtashami, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Meditron-70b: Scaling medical pretraining for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2311.16079</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Daixuan Cheng, Shaohan Huang, and Furu Wei. 2023.

</span>
<span class="ltx_bibblock">Adapting large language models via reading comprehension.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2309.09530</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hyung&nbsp;Won Chung, Le&nbsp;Hou, Shayne Longpre, Barret Zoph, Yi&nbsp;Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2210.11416</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Computer (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Together Computer. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://github.com/togethercomputer/RedPajama-Data" title="">Redpajama: an open dataset for training large language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and Li&nbsp;Yuan. 2023.

</span>
<span class="ltx_bibblock">Chatlaw: Open-source legal large language model with integrated external knowledge bases.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2306.16092</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dao (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tri Dao. 2023.

</span>
<span class="ltx_bibblock">Flashattention-2: Faster attention with better parallelism and work partitioning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2307.08691</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dao et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. 2022.

</span>
<span class="ltx_bibblock">Flashattention: Fast and memory-efficient exact attention with io-awareness.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Advances in Neural Information Processing Systems</em>, 35:16344–16359.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong Sun, and Bowen Zhou. 2023.

</span>
<span class="ltx_bibblock">Enhancing chat language models by scaling high-quality instructional conversations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2305.14233</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elazar et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yanai Elazar, Akshita Bhagia, Ian Magnusson, Abhilasha Ravichander, Dustin Schwenk, Alane Suhr, Pete Walsh, Dirk Groeneveld, Luca Soldaini, Sameer Singh, Hanna Hajishirzi, Noah&nbsp;A. Smith, and Jesse Dodge. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.20707" title="">What’s in my big data?</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Faysse et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Manuel Faysse, Patrick Fernandes, Nuno Guerreiro, António Loison, Duarte Alves, Caio Corro, Nicolas Boizard, João Alves, Ricardo Rei, Pedro Martins, et&nbsp;al. 2024.

</span>
<span class="ltx_bibblock">Croissantllm: A truly bilingual french-english language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2402.00786</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Faysse et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Manuel Faysse, Gautier Viaud, Céline Hudelot, and Pierre Colombo. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.559" title="">Revisiting instruction fine-tuned model evaluation to guide industrial applications</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2101.00027" title="">The pile: An 800gb dataset of diverse text for language modeling</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu and Dao (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Albert Gu and Tri Dao. 2023.

</span>
<span class="ltx_bibblock">Mamba: Linear-time sequence modeling with selective state spaces.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:2312.00752</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guha et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Neel Guha, Daniel&nbsp;E Ho, Julian Nyarko, and Christopher Ré. 2022.

</span>
<span class="ltx_bibblock">Legalbench: Prototyping a collaborative benchmark for legal reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2209.06120</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guha et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Neel Guha, Julian Nyarko, Daniel&nbsp;E Ho, Christopher Ré, Adam Chilton, Aditya Narayana, Alex Chohlas-Wood, Austin Peters, Brandon Waldon, Daniel&nbsp;N Rockmore, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Legalbench: A collaboratively built benchmark for measuring legal reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2308.11462</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gururangan et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz&nbsp;Beltagy, Doug Downey, and Noah&nbsp;A Smith. 2020.

</span>
<span class="ltx_bibblock">Don’t stop pretraining: Adapt language models to domains and tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2004.10964</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gutiérrez-Fandiño et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Asier Gutiérrez-Fandiño, Jordi Armengol-Estapé, Aitor Gonzalez-Agirre, and Marta Villegas. 2021.

</span>
<span class="ltx_bibblock">Spanish legalese language model and corpora.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2110.12201</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heafield (2011)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kenneth Heafield. 2011.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/W11-2123" title="">KenLM: Faster and smaller language model queries</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the Sixth Workshop on Statistical Machine Translation</em>, pages 187–197, Edinburgh, Scotland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Henderson et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Peter Henderson, Mark Krass, Lucia Zheng, Neel Guha, Christopher&nbsp;D Manning, Dan Jurafsky, and Daniel Ho. 2022.

</span>
<span class="ltx_bibblock">Pile of law: Learning responsible data filtering from the law and a 256gb open-source legal dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Advances in Neural Information Processing Systems</em>, 35:29217–29234.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2009.03300</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Islam et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Niful Islam, Debopom Sutradhar, Humaira Noor, Jarin&nbsp;Tasnim Raya, Monowara&nbsp;Tabassum Maisha, and Dewan&nbsp;Md Farid. 2023.

</span>
<span class="ltx_bibblock">Distinguishing human generated text from chatgpt generated text using machine learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2306.01761</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shaoxiong Ji, Tianlin Zhang, Kailai Yang, Sophia Ananiadou, Erik Cambria, and Jörg Tiedemann. 2023.

</span>
<span class="ltx_bibblock">Domain-specific continued pretraining of language models for capturing long context in mental health.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2304.10447</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Albert&nbsp;Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio&nbsp;Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven&nbsp;Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William&nbsp;El Sayed. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.06825" title="">Mistral 7b</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Albert&nbsp;Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Emma&nbsp;Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio&nbsp;Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven&nbsp;Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William&nbsp;El Sayed. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2401.04088" title="">Mixtral of experts</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Katz et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Daniel&nbsp;Martin Katz, Michael&nbsp;James Bommarito, Shang Gao, and Pablo Arredondo. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 passes the bar exam.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Available at SSRN 4389233</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocetkov et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Denis Kocetkov, Raymond Li, Loubna&nbsp;Ben allal, Jia LI, Chenghao Mou, Yacine Jernite, Margaret Mitchell, Carlos&nbsp;Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Dzmitry Bahdanau, Leandro&nbsp;Von Werra, and Harm de&nbsp;Vries. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=pxpbTdUEpD" title="">The stack: 3 TB of permissively licensed source code</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Transactions on Machine Learning Research</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koehn (2005)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Philipp Koehn. 2005.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2005.mtsummit-papers.11" title="">Europarl: A parallel corpus for statistical machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of Machine Translation Summit X: Papers</em>, pages 79–86, Phuket, Thailand.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and Nicholas Carlini. 2021.

</span>
<span class="ltx_bibblock">Deduplicating training data makes language models better.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2107.06499</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lhoest et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Quentin Lhoest, Albert&nbsp;Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil, Julien Chaumond, Mariama Drame, Julien Plu, Lewis Tunstall, et&nbsp;al. 2021.

</span>
<span class="ltx_bibblock">Datasets: A community library for natural language processing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2109.02846</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Raymond Li, Loubna&nbsp;Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry&nbsp;Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh&nbsp;Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva&nbsp;Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn&nbsp;Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos&nbsp;Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von
Werra, and Harm de&nbsp;Vries. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2305.06161" title="">Starcoder: may the source be with you!</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lian et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wing Lian, Guan Wang, Bleys Goodson, Eugene Pentland, Austin Cook, Chanvichet Vong, and "Teknium". 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://https://huggingface.co/Open-Orca/SlimOrca" title="">Slimorca: An open dataset of gpt-4 augmented flan reasoning traces, with verification</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Licari and Comandè (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Daniele Licari and Giovanni Comandè. 2022.

</span>
<span class="ltx_bibblock">Italian-legal-bert: A pre-trained transformer language model for italian law.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">CEUR Workshop Proceedings (Ed.), The Knowledge Management for Law Workshop (KM4LAW)</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longpre et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shayne Longpre, Le&nbsp;Hou, Tu&nbsp;Vu, Albert Webson, Hyung&nbsp;Won Chung, Yi&nbsp;Tay, Denny Zhou, Quoc&nbsp;V Le, Barret Zoph, Jason Wei, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">The flan collection: Designing data and methods for effective instruction tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:2301.13688</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Keming Lu, Peter Potash, Xihui Lin, Yuwen Sun, Zihan Qian, Zheng Yuan, Tristan Naumann, Tianxi Cai, and Junwei Lu. 2023.

</span>
<span class="ltx_bibblock">Prompt discriminative language models for domain adaptation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Proceedings of the 5th Clinical Natural Language Processing Workshop</em>, pages 247–258.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yingwei Ma, Yue Liu, Yue Yu, Yuanliang Zhang, Yu&nbsp;Jiang, Changjian Wang, and Shanshan Li. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2309.16298" title="">At which training stage does code data help llms reasoning?</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martin et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lauren Martin, Nick Whitehouse, Stephanie Yiu, Lizzie Catterson, and Rivindu Perera. 2024.

</span>
<span class="ltx_bibblock">Better call gpt, comparing large language models against lawyers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">arXiv preprint arXiv:2401.16212</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCloskey and Cohen (1989)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Michael McCloskey and Neal&nbsp;J. Cohen. 1989.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/https://doi.org/10.1016/S0079-7421(08)60536-8" title="">Catastrophic interference in connectionist networks: The sequential learning problem</a>.

</span>
<span class="ltx_bibblock">volume&nbsp;24 of <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Psychology of Learning and Motivation</em>, pages 109–165. Academic Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher&nbsp;D Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock">Detectgpt: Zero-shot machine-generated text detection using probability curvature.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">arXiv preprint arXiv:2301.11305</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chenghao Mou, Chris Ha, Kenneth Enevoldsen, and Peiyuan Liu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.5281/zenodo.8364980" title="">Chenghaomou/text-dedup: Reference snapshot</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mukherjee et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2306.02707" title="">Orca: Progressive learning from complex explanation traces of gpt-4</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Munos et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rémi Munos, Michal Valko, Daniele Calandriello, Mohammad&nbsp;Gheshlaghi Azar, Mark Rowland, Zhaohan&nbsp;Daniel Guo, Yunhao Tang, Matthieu Geist, Thomas Mesnard, Andrea Michi, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Nash learning from human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">arXiv preprint arXiv:2312.00886</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niklaus et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joel Niklaus, Ilias Chalkidis, and Matthias Stürmer. 2021.

</span>
<span class="ltx_bibblock">Swiss-judgment-prediction: A multilingual legal judgment prediction benchmark.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">arXiv preprint arXiv:2110.00806</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niklaus and Giofré (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joel Niklaus and Daniele Giofré. 2022.

</span>
<span class="ltx_bibblock">Budgetlongformer: Can we cheaply pretrain a sota legal language model from scratch?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">arXiv preprint arXiv:2211.17135</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niklaus and Giofré (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joel Niklaus and Daniele Giofré. 2023.

</span>
<span class="ltx_bibblock">Can we pretrain a sota legal language model on a budget from scratch?

</span>
<span class="ltx_bibblock">Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niklaus et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joel Niklaus, Veton Matoshi, Matthias Stürmer, Ilias Chalkidis, and Daniel&nbsp;E. Ho. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2306.02069" title="">Multilegalpile: A 689gb multilingual legal corpus</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nishida et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kosuke Nishida, Kyosuke Nishida, Itsumi Saito, Hisako Asano, and Junji Tomita. 2019.

</span>
<span class="ltx_bibblock">Unsupervised domain adaptation of language models for reading comprehension.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">arXiv preprint arXiv:1911.10768</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paszke et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et&nbsp;al. 2019.

</span>
<span class="ltx_bibblock">Pytorch: An imperative style, high-performance deep learning library.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Advances in neural information processing systems</em>, 32.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Penedo et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. 2023.

</span>
<span class="ltx_bibblock">The refinedweb dataset for falcon llm: Outperforming curated corpora with web data, and web data only.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">arXiv preprint arXiv:2306.01116</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prakken (2013)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Henry Prakken. 2013.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">Logical tools for modelling legal argument: a study of defeasible reasoning in law</em>, volume&nbsp;32.

</span>
<span class="ltx_bibblock">Springer Science &amp; Business Media.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alec Radford, Jong&nbsp;Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2212.04356" title="">Robust speech recognition via large-scale weak supervision</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher&nbsp;D Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">arXiv preprint arXiv:2305.18290</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roziere et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing&nbsp;Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Code llama: Open foundation models for code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">arXiv preprint arXiv:2308.12950</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Savelka et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jaromir Savelka, Kevin&nbsp;D Ashley, Morgan&nbsp;A Gray, Hannes Westermann, and Huihui Xu. 2023.

</span>
<span class="ltx_bibblock">Explaining legal concepts with augmented large language models (gpt-4).

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">arXiv preprint arXiv:2306.09525</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scao et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Teven&nbsp;Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra&nbsp;Sasha Luccioni, François Yvon, Matthias Gallé, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Bloom: A 176b-parameter open-access multilingual language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">arXiv preprint arXiv:2211.05100</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhiqiang Shen, Tianhua Tao, Liqun Ma, Willie Neiswanger, Joel Hestness, Natalia Vassilieva, Daria Soboleva, and Eric Xing. 2023.

</span>
<span class="ltx_bibblock">Slimpajama-dc: Understanding data combinations for llm training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">arXiv preprint arXiv:2309.10818</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shoeybi et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. 2019.

</span>
<span class="ltx_bibblock">Megatron-lm: Training multi-billion parameter language models using model parallelism.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">arXiv preprint arXiv:1909.08053</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soboleva et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Daria Soboleva, Faisal Al-Khateeb, Robert Myers, Jacob&nbsp;R Steeves, Joel Hestness, and Nolan Dey. 2023.

</span>
<span class="ltx_bibblock">Slimpajama: A 627b token cleaned and deduplicated version of redpajama.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jingyuan Sun, Shaonan Wang, Jiajun Zhang, and Chengqing Zong. 2020.

</span>
<span class="ltx_bibblock">Distill and replay for continual language learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">Proceedings of the 28th international conference on computational linguistics</em>, pages 3569–3579.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taylor et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic. 2022.

</span>
<span class="ltx_bibblock">Galactica: A large language model for science.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">arXiv preprint arXiv:2211.09085</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et&nbsp;al. 2023a.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">arXiv preprint arXiv:2302.13971</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian&nbsp;Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit&nbsp;Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric&nbsp;Michael Smith, Ranjan Subramanian, Xiaoqing&nbsp;Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian&nbsp;Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas
Scialom. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2307.09288" title="">Llama 2: Open foundation and fine-tuned chat models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tuggener et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Don Tuggener, Pius Von&nbsp;Däniken, Thomas Peetz, and Mark Cieliebak. 2020.

</span>
<span class="ltx_bibblock">Ledgar: A large-scale multi-label corpus for text classification of legal provisions in contracts.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">Proceedings of the Twelfth Language Resources and Evaluation Conference</em>, pages 1235–1241.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tunstall et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Zephyr: Direct distillation of lm alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">arXiv preprint arXiv:2310.16944</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">von Werra et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Leandro von Werra, Younes Belkada, Lewis Tunstall, Edward Beeching, Tristan Thrush, Nathan Lambert, and Shengyi Huang. 2020.

</span>
<span class="ltx_bibblock">Trl: Transformer reinforcement learning.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/huggingface/trl" title="">https://github.com/huggingface/trl</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vu et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Thuy-Trang Vu, Dinh Phung, and Gholamreza Haffari. 2020.

</span>
<span class="ltx_bibblock">Effective unsupervised domain adaptation with adversarially trained language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">arXiv preprint arXiv:2010.01739</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi&nbsp;Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah&nbsp;A Smith, Iz&nbsp;Beltagy, et&nbsp;al. 2023a.

</span>
<span class="ltx_bibblock">How far can camels go? exploring the state of instruction tuning on open resources.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">arXiv preprint arXiv:2306.04751</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah&nbsp;A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2212.10560" title="">Self-instruct: Aligning language models with self-generated instructions</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut&nbsp;Selvan Dhanasekaran, Atharva Naik, David Stap, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">arXiv preprint arXiv:2204.07705</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weber-Wulff et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Debora Weber-Wulff, Alla Anohina-Naumeca, Sonja Bjelobaba, Tomáš Foltỳnek, Jean Guerrero-Dib, Olumide Popoola, Petr Šigut, and Lorna Waddington. 2023.

</span>
<span class="ltx_bibblock">Testing of detection tools for ai-generated text.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">International Journal for Educational Integrity</em>, 19(1):26.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent&nbsp;Y Zhao, Kelvin Guu, Adams&nbsp;Wei Yu, Brian Lester, Nan Du, Andrew&nbsp;M Dai, and Quoc&nbsp;V Le. 2021.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">arXiv preprint arXiv:2109.01652</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wolf et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et&nbsp;al. 2019.

</span>
<span class="ltx_bibblock">Huggingface’s transformers: State-of-the-art natural language processing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">arXiv preprint arXiv:1910.03771</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Minghao Wu, Thuy-Trang Vu, Lizhen Qu, George Foster, and Gholamreza Haffari. 2024.

</span>
<span class="ltx_bibblock">Adapting large language models for document-level machine translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib83.1.1">arXiv preprint arXiv:2401.06468</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chaojun Xiao, Xueyu Hu, Zhiyuan Liu, Cunchao Tu, and Maosong Sun. 2021.

</span>
<span class="ltx_bibblock">Lawformer: A pre-trained language model for chinese legal long documents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">AI Open</em>, 2:79–84.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Haoran Xu, Young&nbsp;Jin Kim, Amr Sharaf, and Hany&nbsp;Hassan Awadalla. 2023.

</span>
<span class="ltx_bibblock">A paradigm shift in machine translation: Boosting translation performance of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">arXiv preprint arXiv:2309.11674</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yunzhi Yao, Shaohan Huang, Wenhui Wang, Li&nbsp;Dong, and Furu Wei. 2021.

</span>
<span class="ltx_bibblock">Adapt-and-distill: Developing small, fast and effective pretrained language models for domains.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">arXiv preprint arXiv:2106.13474</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu&nbsp;Zhang, James&nbsp;T Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023.

</span>
<span class="ltx_bibblock">Metamath: Bootstrap your own mathematical questions for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib87.1.1">arXiv preprint arXiv:2309.12284</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Peiyuan Zhang, Guangtao Zeng, Tianduo Wang, and Wei Lu. 2024.

</span>
<span class="ltx_bibblock">Tinyllama: An open-source small language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib88.1.1">arXiv preprint arXiv:2401.02385</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi&nbsp;Victoria Lin, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Opt: Open pre-trained transformer language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">arXiv preprint arXiv:2205.01068</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">arXiv preprint arXiv:2305.11206</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>

</div>


<div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated on Wed Dec 14 18:01:44 2022 by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button></body></html>