<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2403.03883] SaulLM-7B: A pioneering Large Language Model for Law</title><meta property="og:description" content="In this paper, we introduce SaulLM-7B, a large language model (LLM) tailored for the legal domain. With 7 billion parameters, SaulLM-7B is the first LLM designed explicitly for legal text comprehension and generation. …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SaulLM-7B: A pioneering Large Language Model for Law">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="SaulLM-7B: A pioneering Large Language Model for Law">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2403.03883">

<!--Generated on Fri Apr  5 16:15:12 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">
<span id="id17.id1" class="ltx_text ltx_font_typewriter">SaulLM-7B</span>: A pioneering Large Language Model for Law</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pierre Colombo<sup id="id18.17.id1" class="ltx_sup"><span id="id18.17.id1.1" class="ltx_text ltx_font_italic">1,2,∗</span></sup>  Telmo Pessoa Pires<sup id="id19.18.id2" class="ltx_sup"><span id="id19.18.id2.1" class="ltx_text ltx_font_italic">1,∗</span></sup>  Malik Boudiaf<sup id="id20.19.id3" class="ltx_sup"><span id="id20.19.id3.1" class="ltx_text ltx_font_italic">1,∗</span></sup> 
<br class="ltx_break"><span id="id4.4.1" class="ltx_text ltx_font_bold">Dominic Culver<sup id="id4.4.1.1" class="ltx_sup"><span id="id4.4.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,∗</span></sup></span>  <span id="id5.5.2" class="ltx_text ltx_font_bold">Rui Melo<sup id="id5.5.2.1" class="ltx_sup"><span id="id5.5.2.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,∗</span></sup></span>  <span id="id6.6.3" class="ltx_text ltx_font_bold">Caio Corro<sup id="id6.6.3.1" class="ltx_sup"><span id="id6.6.3.1.1" class="ltx_text ltx_font_medium">3</span></sup></span>  <span id="id7.7.4" class="ltx_text ltx_font_bold">André F. T. Martins<sup id="id7.7.4.1" class="ltx_sup"><span id="id7.7.4.1.1" class="ltx_text ltx_font_medium">4</span></sup></span> 
<br class="ltx_break"><span id="id8.8.5" class="ltx_text ltx_font_bold">Fabrizio Esposito<sup id="id8.8.5.1" class="ltx_sup"><span id="id8.8.5.1.1" class="ltx_text ltx_font_medium">5</span></sup></span>  <span id="id9.9.6" class="ltx_text ltx_font_bold">Vera Lúcia Raposo<sup id="id9.9.6.1" class="ltx_sup"><span id="id9.9.6.1.1" class="ltx_text ltx_font_medium">5</span></sup></span>  <span id="id10.10.7" class="ltx_text ltx_font_bold">Sofia Morgado<sup id="id10.10.7.1" class="ltx_sup"><span id="id10.10.7.1.1" class="ltx_text ltx_font_medium">1</span></sup></span>  <span id="id11.11.8" class="ltx_text ltx_font_bold">Michael Desa<sup id="id11.11.8.1" class="ltx_sup"><span id="id11.11.8.1.1" class="ltx_text ltx_font_medium">1</span></sup></span> 
<br class="ltx_break"><sup id="id21.20.id4" class="ltx_sup">1</sup>Equall.ai, New York, Paris, Lisbon 
<br class="ltx_break"><sup id="id22.21.id5" class="ltx_sup">2</sup>MICS, CentraleSupélec, Université Paris-Saclay
<br class="ltx_break"><sup id="id23.22.id6" class="ltx_sup">3</sup>Sorbonne Université, CNRS, ISIR, Paris
<br class="ltx_break"><sup id="id24.23.id7" class="ltx_sup">4</sup>Instituto Superior Técnico, Universidade de Lisboa
<br class="ltx_break"><sup id="id25.24.id8" class="ltx_sup">5</sup> NOVA School of Law, Lisboa 
<br class="ltx_break"><span id="id26.25.id9" class="ltx_text ltx_font_typewriter">firstname@equall.ai</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id27.id1" class="ltx_p">In this paper, we introduce <span id="id27.id1.1" class="ltx_text ltx_font_typewriter">SaulLM-7B</span>, a large language model (LLM) tailored for the legal domain. With 7 billion parameters, <span id="id27.id1.2" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> is the first LLM designed explicitly for legal text comprehension and generation. Leveraging the Mistral 7B architecture as its foundation, <span id="id27.id1.3" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> is trained on an English legal corpus of over 30 billion tokens. <span id="id27.id1.4" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> exhibits state-of-the-art proficiency in understanding and processing legal documents. Additionally, we present a novel instructional fine-tuning method that leverages legal datasets to further enhance <span id="id27.id1.5" class="ltx_text ltx_font_typewriter">SaulLM-7B</span>’s performance in legal tasks. <span id="id27.id1.6" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> is released under the MIT License.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<div id="p1.16" class="ltx_block ltx_align_bottom">
<p id="p1.16.17" class="ltx_p"><span id="p1.16.17.1" class="ltx_text ltx_font_typewriter">SaulLM-7B</span><span id="p1.16.17.2" class="ltx_text ltx_font_bold">: A pioneering Large Language Model for Law</span></p>
<br class="ltx_break ltx_centering">
<p id="p1.16.16" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.16.16.16" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.16.16.16.16" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p1.3.3.3.3.3" class="ltx_tr">
<span id="p1.3.3.3.3.3.3" class="ltx_td ltx_align_center"><span id="p1.3.3.3.3.3.3.3" class="ltx_text ltx_font_bold">Pierre Colombo<sup id="p1.3.3.3.3.3.3.3.1" class="ltx_sup"><span id="p1.3.3.3.3.3.3.3.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,2,∗</span></sup>  Telmo Pessoa Pires<sup id="p1.3.3.3.3.3.3.3.2" class="ltx_sup"><span id="p1.3.3.3.3.3.3.3.2.1" class="ltx_text ltx_font_medium ltx_font_italic">1,∗</span></sup>  Malik Boudiaf<sup id="p1.3.3.3.3.3.3.3.3" class="ltx_sup"><span id="p1.3.3.3.3.3.3.3.3.1" class="ltx_text ltx_font_medium ltx_font_italic">1,∗</span></sup></span></span></span>
<span id="p1.7.7.7.7.7" class="ltx_tr">
<span id="p1.7.7.7.7.7.4" class="ltx_td ltx_align_center"><span id="p1.4.4.4.4.4.1.1" class="ltx_text ltx_font_bold">Dominic Culver<sup id="p1.4.4.4.4.4.1.1.1" class="ltx_sup"><span id="p1.4.4.4.4.4.1.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,∗</span></sup></span>  <span id="p1.5.5.5.5.5.2.2" class="ltx_text ltx_font_bold">Rui Melo<sup id="p1.5.5.5.5.5.2.2.1" class="ltx_sup"><span id="p1.5.5.5.5.5.2.2.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1,∗</span></sup></span>  <span id="p1.6.6.6.6.6.3.3" class="ltx_text ltx_font_bold">Caio Corro<sup id="p1.6.6.6.6.6.3.3.1" class="ltx_sup"><span id="p1.6.6.6.6.6.3.3.1.1" class="ltx_text ltx_font_medium">3</span></sup></span>  <span id="p1.7.7.7.7.7.4.4" class="ltx_text ltx_font_bold">André F. T. Martins<sup id="p1.7.7.7.7.7.4.4.1" class="ltx_sup"><span id="p1.7.7.7.7.7.4.4.1.1" class="ltx_text ltx_font_medium">4</span></sup></span></span></span>
<span id="p1.11.11.11.11.11" class="ltx_tr">
<span id="p1.11.11.11.11.11.4" class="ltx_td ltx_align_center"><span id="p1.8.8.8.8.8.1.1" class="ltx_text ltx_font_bold">Fabrizio Esposito<sup id="p1.8.8.8.8.8.1.1.1" class="ltx_sup"><span id="p1.8.8.8.8.8.1.1.1.1" class="ltx_text ltx_font_medium">5</span></sup></span>  <span id="p1.9.9.9.9.9.2.2" class="ltx_text ltx_font_bold">Vera Lúcia Raposo<sup id="p1.9.9.9.9.9.2.2.1" class="ltx_sup"><span id="p1.9.9.9.9.9.2.2.1.1" class="ltx_text ltx_font_medium">5</span></sup></span>  <span id="p1.10.10.10.10.10.3.3" class="ltx_text ltx_font_bold">Sofia Morgado<sup id="p1.10.10.10.10.10.3.3.1" class="ltx_sup"><span id="p1.10.10.10.10.10.3.3.1.1" class="ltx_text ltx_font_medium">1</span></sup></span>  <span id="p1.11.11.11.11.11.4.4" class="ltx_text ltx_font_bold">Michael Desa<sup id="p1.11.11.11.11.11.4.4.1" class="ltx_sup"><span id="p1.11.11.11.11.11.4.4.1.1" class="ltx_text ltx_font_medium">1</span></sup></span></span></span>
<span id="p1.12.12.12.12.12" class="ltx_tr">
<span id="p1.12.12.12.12.12.1" class="ltx_td ltx_align_center"><sup id="p1.12.12.12.12.12.1.1" class="ltx_sup">1</sup>Equall.ai, New York, Paris, Lisbon</span></span>
<span id="p1.13.13.13.13.13" class="ltx_tr">
<span id="p1.13.13.13.13.13.1" class="ltx_td ltx_align_center"><sup id="p1.13.13.13.13.13.1.1" class="ltx_sup">2</sup>MICS, CentraleSupélec, Université Paris-Saclay</span></span>
<span id="p1.14.14.14.14.14" class="ltx_tr">
<span id="p1.14.14.14.14.14.1" class="ltx_td ltx_align_center"><sup id="p1.14.14.14.14.14.1.1" class="ltx_sup">3</sup>Sorbonne Université, CNRS, ISIR, Paris</span></span>
<span id="p1.15.15.15.15.15" class="ltx_tr">
<span id="p1.15.15.15.15.15.1" class="ltx_td ltx_align_center"><sup id="p1.15.15.15.15.15.1.1" class="ltx_sup">4</sup>Instituto Superior Técnico, Universidade de Lisboa</span></span>
<span id="p1.16.16.16.16.16" class="ltx_tr">
<span id="p1.16.16.16.16.16.1" class="ltx_td ltx_align_center"><sup id="p1.16.16.16.16.16.1.1" class="ltx_sup">5</sup> NOVA School of Law, Lisboa</span></span>
<span id="p1.16.16.16.16.17.1" class="ltx_tr">
<span id="p1.16.16.16.16.17.1.1" class="ltx_td ltx_align_center"><span id="p1.16.16.16.16.17.1.1.1" class="ltx_text ltx_font_typewriter">firstname@equall.ai</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">*</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">*</sup><span class="ltx_note_type">footnotetext: </span>Equal contribution.</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In the rapidly evolving landscape of artificial intelligence, the applications of large language models (LLMs) <cite class="ltx_cite ltx_citemacro_cite">Achiam et&nbsp;al. (<a href="#bib.bib1" title="" class="ltx_ref">2023</a>); Scao et&nbsp;al. (<a href="#bib.bib65" title="" class="ltx_ref">2022</a>); Penedo et&nbsp;al. (<a href="#bib.bib59" title="" class="ltx_ref">2023</a>); Touvron et&nbsp;al. (<a href="#bib.bib71" title="" class="ltx_ref">2023a</a>); Jiang et&nbsp;al. (<a href="#bib.bib34" title="" class="ltx_ref">2023</a>, <a href="#bib.bib35" title="" class="ltx_ref">2024</a>); Touvron et&nbsp;al. (<a href="#bib.bib72" title="" class="ltx_ref">2023b</a>); Bai et&nbsp;al. (<a href="#bib.bib5" title="" class="ltx_ref">2023</a>)</cite> have witnessed large advancements across various domains, like <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">e.g.</span>&nbsp;translation <cite class="ltx_cite ltx_citemacro_cite">Xu et&nbsp;al. (<a href="#bib.bib85" title="" class="ltx_ref">2023</a>)</cite>, medical <cite class="ltx_cite ltx_citemacro_cite">Chen et&nbsp;al. (<a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite>, and code generation <cite class="ltx_cite ltx_citemacro_cite">Roziere et&nbsp;al. (<a href="#bib.bib63" title="" class="ltx_ref">2023</a>); Li et&nbsp;al. (<a href="#bib.bib41" title="" class="ltx_ref">2023</a>)</cite>. From natural language processing to machine translation, these models have exhibited exceptional capabilities in understanding and generating human-like text <cite class="ltx_cite ltx_citemacro_cite">Weber-Wulff et&nbsp;al. (<a href="#bib.bib80" title="" class="ltx_ref">2023</a>); Islam et&nbsp;al. (<a href="#bib.bib32" title="" class="ltx_ref">2023</a>); Mitchell et&nbsp;al. (<a href="#bib.bib49" title="" class="ltx_ref">2023</a>)</cite>.
However, one field that has yet to experience the full benefit of this transformative technology is the legal domain <cite class="ltx_cite ltx_citemacro_cite">Martin et&nbsp;al. (<a href="#bib.bib47" title="" class="ltx_ref">2024</a>); Licari and Comandè (<a href="#bib.bib43" title="" class="ltx_ref">2022</a>)</cite>. As legal professionals grapple with an ever-expanding volume of complex documents, there is a growing need for a dedicated LLM that can help navigate and interpret legal material <cite class="ltx_cite ltx_citemacro_cite">Savelka et&nbsp;al. (<a href="#bib.bib64" title="" class="ltx_ref">2023</a>); Katz et&nbsp;al. (<a href="#bib.bib36" title="" class="ltx_ref">2023</a>); Xiao et&nbsp;al. (<a href="#bib.bib84" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this paper, we present a pioneering initiative to develop the first legal LLM publicly available.
Legal text, characterized by its unique syntax and specialized vocabulary presents a distinct linguistic challenge <cite class="ltx_cite ltx_citemacro_cite">Chalkidis et&nbsp;al. (<a href="#bib.bib11" title="" class="ltx_ref">2020</a>); Niklaus et&nbsp;al. (<a href="#bib.bib53" title="" class="ltx_ref">2021</a>)</cite>.
Our approach focuses on extensive pretraining <cite class="ltx_cite ltx_citemacro_cite">Gururangan et&nbsp;al. (<a href="#bib.bib27" title="" class="ltx_ref">2020</a>); Yao et&nbsp;al. (<a href="#bib.bib86" title="" class="ltx_ref">2021</a>)</cite> using dedicated legal corpora from English-speaking jurisdictions such as the USA, Canada, the UK, and Europe <cite class="ltx_cite ltx_citemacro_cite">Aletras et&nbsp;al. (<a href="#bib.bib2" title="" class="ltx_ref">2016</a>); Gutiérrez-Fandiño et&nbsp;al. (<a href="#bib.bib28" title="" class="ltx_ref">2021</a>)</cite>.
Leveraging the pretraining on a large and diverse legal dataset, both scraped by our team as well as from previous literature <cite class="ltx_cite ltx_citemacro_citep">(Niklaus and Giofré, <a href="#bib.bib54" title="" class="ltx_ref">2022</a>)</cite>, our LLM, <span id="S1.p2.1.1" class="ltx_text ltx_font_typewriter">SaulLM-7B</span>, aims not only to comprehend the complexities of legal documents but also to adapt to the evolving nature of legal discourse.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">By focusing on the needs of legal practitioners and harnessing the power of pretraining on dedicated legal corpora, our work represents an important step towards fulfilling the unique demands of the legal domain. We anticipate that introducing the first LLM for law will not only empower legal professionals but also catalyze further innovation at the intersection of artificial intelligence and the legal community - making a significant contribution to legal language understanding and application <cite class="ltx_cite ltx_citemacro_cite">Prakken (<a href="#bib.bib60" title="" class="ltx_ref">2013</a>)</cite>. We summarize the contributions of this work as follows:</p>
</div>
<section id="S1.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Contribution 1: A family of legal LLMs.</h5>

<div id="S1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px1.p1.1" class="ltx_p">In this paper, we introduce the <span id="S1.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_typewriter">SaulLM-7B</span>’s family, a collection of Legal Language Models meticulously crafted to tackle the distinctive challenges encountered within the legal domain. We unveil <span id="S1.SS0.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_typewriter">SaulLM-7B</span>, a 7-billion-parameter language model specifically tailored to legal text. With its specialized training regimen, <span id="S1.SS0.SSS0.Px1.p1.1.3" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> demonstrates a superior understanding of the nuances in legal language compared to generic models. Furthermore, we release <span id="S1.SS0.SSS0.Px1.p1.1.4" class="ltx_text ltx_font_typewriter">SaulLM-7B-Instruct</span>, an instruction-tuned variant, carefully engineered to outperform existing models such as <span id="S1.SS0.SSS0.Px1.p1.1.5" class="ltx_text ltx_font_typewriter">Mistral</span> or <span id="S1.SS0.SSS0.Px1.p1.1.6" class="ltx_text ltx_font_typewriter">Llama</span> on a variety of legal tasks<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Model is available at <a target="_blank" href="https://huggingface.co/Equall" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/Equall</a>.</span></span></span>.</p>
</div>
</section>
<section id="S1.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Contribution 2: An improved evaluation protocol for legal LLMs.</h5>

<div id="S1.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px2.p1.1" class="ltx_p">Concurrently, we introduce LegalBench-Instruct, a supplemental iteration of LegalBench <cite class="ltx_cite ltx_citemacro_cite">Guha et&nbsp;al. (<a href="#bib.bib25" title="" class="ltx_ref">2022</a>, <a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite><span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Dataset is processed and available at <a target="_blank" href="https://huggingface.co/Equall" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/Equall</a></span></span></span>, crafted to better gauge and refine the legal proficiency of language models, which we hope will contribute to future advancements into research in the legal domain. To further enrich the models’ capabilities in legal contexts, we also include the legal tasks of the popular MMLU benchmark <cite class="ltx_cite ltx_citemacro_cite">Hendrycks et&nbsp;al. (<a href="#bib.bib31" title="" class="ltx_ref">2020</a>)</cite> in our evaluation protocol, particularly focusing on international law, professional law<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>We use the term “professional law” here as defined in <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et&nbsp;al., <a href="#bib.bib31" title="" class="ltx_ref">2020</a>)</cite></span></span></span> and jurisprudence.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2403.03883/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="141" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span id="S1.F1.2.1" class="ltx_text ltx_font_bold">Procedure for constructing <span id="S1.F1.2.1.1" class="ltx_text ltx_font_typewriter">SaulLM-7B</span></span>. We rely on legal datasets augmented with replay data, and instructions datasets. For fine-tuning we enrich our instruction finetuning dataset further with legal instructions.</figcaption>
</figure>
</section>
<section id="S1.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Contribution 3: Model, Evaluation Code &amp; Licensing.</h5>

<div id="S1.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S1.SS0.SSS0.Px3.p1.1" class="ltx_p">To foster widespread adoption and promote innovation, we release <span id="S1.SS0.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> and <span id="S1.SS0.SSS0.Px3.p1.1.2" class="ltx_text ltx_font_typewriter">SaulLM-7B-Instruct</span>, as well as our evaluation code under the MIT License. This open licensing approach encourages collaborative development and adoption into a wide array of commercial and research endeavors within the legal domain and beyond.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span><span id="S2.1.1" class="ltx_text ltx_font_typewriter">SaulLM-7B</span>: Extending the legal capabilities of Language Models</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.4" class="ltx_p">A wide range of open-source large language models is available for the backbone, spanning from <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="70" display="inline"><semantics id="S2.p1.1.m1.1a"><mn id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">70</mn><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><cn type="integer" id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">70</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">70</annotation></semantics></math> million parameter models like Pythia <cite class="ltx_cite ltx_citemacro_citep">(Biderman et&nbsp;al., <a href="#bib.bib6" title="" class="ltx_ref">2023</a>)</cite> to <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="180" display="inline"><semantics id="S2.p1.2.m2.1a"><mn id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">180</mn><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><cn type="integer" id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">180</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">180</annotation></semantics></math> billion parameter models like Falcon <cite class="ltx_cite ltx_citemacro_citep">(Almazrouei et&nbsp;al., <a href="#bib.bib3" title="" class="ltx_ref">2023</a>)</cite>. In this work, we choose the Mistral <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="7" display="inline"><semantics id="S2.p1.3.m3.1a"><mn id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><cn type="integer" id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">7</annotation></semantics></math>B model, a <math id="S2.p1.4.m4.1" class="ltx_Math" alttext="7" display="inline"><semantics id="S2.p1.4.m4.1a"><mn id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><cn type="integer" id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">7</annotation></semantics></math> billion parameter open-source model that achieves high performance across benchmarks and tasks <cite class="ltx_cite ltx_citemacro_citep">(Jiang et&nbsp;al., <a href="#bib.bib34" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Our methodology, shown in <a href="#S1.F1" title="Figure 1 ‣ Contribution 2: An improved evaluation protocol for legal LLMs. ‣ 1 Introduction ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure&nbsp;1</span></a> involves a two-step process that we describe below.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Enhancing Mistral’s Legal Capabilities</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">While generic models <cite class="ltx_cite ltx_citemacro_cite">Touvron et&nbsp;al. (<a href="#bib.bib71" title="" class="ltx_ref">2023a</a>); Taylor et&nbsp;al. (<a href="#bib.bib70" title="" class="ltx_ref">2022</a>); Zhang et&nbsp;al. (<a href="#bib.bib89" title="" class="ltx_ref">2022</a>); Gu and Dao (<a href="#bib.bib24" title="" class="ltx_ref">2023</a>); Almazrouei et&nbsp;al. (<a href="#bib.bib3" title="" class="ltx_ref">2023</a>); Zhang et&nbsp;al. (<a href="#bib.bib88" title="" class="ltx_ref">2024</a>); Faysse et&nbsp;al. (<a href="#bib.bib21" title="" class="ltx_ref">2024</a>)</cite> gain some exposure to legal data during their training, it typically only represents a minor fraction of the overall data. A straightforward method to enhance performance for legal tasks is to perform additional training focusing on legal data. This approach, particularly focused on decoder models, has been successfully used in various fields such as medicine <cite class="ltx_cite ltx_citemacro_cite">Chen et&nbsp;al. (<a href="#bib.bib12" title="" class="ltx_ref">2023</a>); Ji et&nbsp;al. (<a href="#bib.bib33" title="" class="ltx_ref">2023</a>)</cite>, translation <cite class="ltx_cite ltx_citemacro_cite">Xu et&nbsp;al. (<a href="#bib.bib85" title="" class="ltx_ref">2023</a>); Wu et&nbsp;al. (<a href="#bib.bib83" title="" class="ltx_ref">2024</a>)</cite>, and coding <cite class="ltx_cite ltx_citemacro_cite">Roziere et&nbsp;al. (<a href="#bib.bib63" title="" class="ltx_ref">2023</a>)</cite>.
The key advantage of this approach is its scalability and independence from the specific characteristics of the training data.
Other research on domain adaptation has attempted to specialize language models via pretext tasks. However, these efforts often rely on smaller-scale approaches <cite class="ltx_cite ltx_citemacro_cite">Niklaus and Giofré (<a href="#bib.bib55" title="" class="ltx_ref">2023</a>)</cite>, are computationally expensive <cite class="ltx_cite ltx_citemacro_cite">Vu et&nbsp;al. (<a href="#bib.bib76" title="" class="ltx_ref">2020</a>); Lu et&nbsp;al. (<a href="#bib.bib45" title="" class="ltx_ref">2023</a>)</cite>, or lack scalability <cite class="ltx_cite ltx_citemacro_cite">Cheng et&nbsp;al. (<a href="#bib.bib13" title="" class="ltx_ref">2023</a>); Cui et&nbsp;al. (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>); Nishida et&nbsp;al. (<a href="#bib.bib57" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">For these reasons, as well as the availability of large-scale legal corpora from the web, we chose to focus on <em id="S2.SS1.p2.1.1" class="ltx_emph ltx_font_italic">continued pretraining</em>.
We meticulously curate a high-quality dataset sourced from diverse legal content repositories. After rigorous filtering
<cite class="ltx_cite ltx_citemacro_citep">(Penedo et&nbsp;al., <a href="#bib.bib59" title="" class="ltx_ref">2023</a>)</cite> and deduplication <cite class="ltx_cite ltx_citemacro_citep">(Mou et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023</a>; Kocetkov et&nbsp;al., <a href="#bib.bib37" title="" class="ltx_ref">2023</a>)</cite>, we end up with a corpus of <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><mn id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><cn type="integer" id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">30</annotation></semantics></math> billion tokens, which serves as a robust foundation for continued pretraining.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Improving Legal Instruction Following</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">To support user requests and conversational interaction, LLMs typically undergo instruction tuning, a critical process involving training on supervised conversational pairs. This step is essential for crafting a versatile model, adept at addressing user queries <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib77" title="" class="ltx_ref">2023a</a>); Wei et&nbsp;al. (<a href="#bib.bib81" title="" class="ltx_ref">2021</a>); Chung et&nbsp;al. (<a href="#bib.bib14" title="" class="ltx_ref">2022</a>); Faysse et&nbsp;al. (<a href="#bib.bib22" title="" class="ltx_ref">2023</a>); Ding et&nbsp;al. (<a href="#bib.bib19" title="" class="ltx_ref">2023</a>); Wang et&nbsp;al. (<a href="#bib.bib78" title="" class="ltx_ref">2023b</a>)</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">For general-purpose language models, diversity and quality of instruction are crucial <cite class="ltx_cite ltx_citemacro_cite">Cao et&nbsp;al. (<a href="#bib.bib9" title="" class="ltx_ref">2023</a>); Zhou et&nbsp;al. (<a href="#bib.bib90" title="" class="ltx_ref">2023</a>)</cite>. However, in specialized domains it is crucial to incorporate task-specific and specialized prompts to enhance performance. Our instruction fine-tuning stage involves <math id="S2.SS2.p2.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S2.SS2.p2.1.m1.1a"><mn id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><cn type="integer" id="S2.SS2.p2.1.m1.1.1.cmml" xref="S2.SS2.p2.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">2</annotation></semantics></math> key components: generic (ie, non-legal) and legal instructions. The former help enhance the model’s understanding and following of commands, and includes data from diverse domains such as coding, mathematics, and general conversations. For the latter we employ an extensive collection of datasets tailored to the nuances of legal domains, covering legal question answering and summarization, among others.
Through this meticulous fine-tuning on instructional data, our model, <span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_typewriter">SaulLM-7B-Instruct</span>, is able to grasp legal intricacies and excels in a wide range of associated tasks.</p>
</div>
<div id="Thmremarkx1" class="ltx_theorem ltx_theorem_remark">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmremarkx1.1.1.1" class="ltx_text ltx_font_bold">Remark</span></span><span id="Thmremarkx1.2.2" class="ltx_text ltx_font_bold">.</span>
</h6>
<div id="Thmremarkx1.p1" class="ltx_para">
<p id="Thmremarkx1.p1.1" class="ltx_p"><span id="Thmremarkx1.p1.1.1" class="ltx_text ltx_font_italic">It’s worth noting that many common LLMs <cite class="ltx_cite ltx_citemacro_cite">Tunstall et&nbsp;al. (<a href="#bib.bib74" title="" class="ltx_ref">2023</a>)</cite> include an additional step of to align the model with human preference <cite class="ltx_cite ltx_citemacro_cite">Rafailov et&nbsp;al. (<a href="#bib.bib62" title="" class="ltx_ref">2023</a>); Munos et&nbsp;al. (<a href="#bib.bib52" title="" class="ltx_ref">2023</a>); von Werra et&nbsp;al. (<a href="#bib.bib75" title="" class="ltx_ref">2020</a>)</cite>. In our case, early experiments did not show any meaningful improvement in performance and so we opted to not pursue this avenue for the present paper.</span></p>
</div>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section we describe our data collection and cleaning schemes.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Legal Pretraining Corpora</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Unlike fields such as science and medicine, the legal landscape varies significantly across countries and jurisdictions, reflecting differences not only in local laws but also in legal traditions, like common law versus civil law <cite class="ltx_cite ltx_citemacro_cite">Henderson et&nbsp;al. (<a href="#bib.bib30" title="" class="ltx_ref">2022</a>)</cite>. Thus, we gathered legal texts from various jurisdictions, with a primary focus on the English language due to its widespread use in legal contexts worldwide. Our collection includes data from the U.S. <cite class="ltx_cite ltx_citemacro_cite">Tuggener et&nbsp;al. (<a href="#bib.bib73" title="" class="ltx_ref">2020</a>)</cite>, Europe <cite class="ltx_cite ltx_citemacro_cite">Chalkidis et&nbsp;al. (<a href="#bib.bib10" title="" class="ltx_ref">2019</a>)</cite>, and Australia <cite class="ltx_cite ltx_citemacro_cite">Butler (<a href="#bib.bib8" title="" class="ltx_ref">2023</a>)</cite>, covering a diverse range of legal systems. Through this thorough curation process and aggressive cleaning (see <a href="#S3.SS1.SSS2" title="3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.2</span></a>), we end up with a corpus of 30 billion tokens, capturing the intricacies of legal language across regions.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Dataset Composition</h4>

<section id="S3.SS1.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Legal Sources</h5>

<div id="S3.SS1.SSS1.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.Px1.p1.1" class="ltx_p">We combine both previously available datasets, such as the FreeLaw subset from The Pile <cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a href="#bib.bib23" title="" class="ltx_ref">2020</a>)</cite> and MultiLegal Pile <cite class="ltx_cite ltx_citemacro_citep">(Niklaus et&nbsp;al., <a href="#bib.bib56" title="" class="ltx_ref">2023</a>)</cite>, as well as data scraped from publicly available sources on the Web. We list the different sources of data in <a href="#S3.T1" title="In Legal Sources ‣ 3.1.1 Dataset Composition ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.11" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.11.12.1" class="ltx_tr">
<td id="S3.T1.11.12.1.1" class="ltx_td ltx_align_left ltx_border_tt">Name</td>
<td id="S3.T1.11.12.1.2" class="ltx_td ltx_align_center ltx_border_tt">Tokens</td>
</tr>
<tr id="S3.T1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.2" class="ltx_td ltx_align_left ltx_border_t">FreeLaw<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>We used the subset from The Pile <cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a href="#bib.bib23" title="" class="ltx_ref">2020</a>)</cite>.</span></span></span>
</td>
<td id="S3.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">
<math id="S3.T1.1.1.1.m1.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S3.T1.1.1.1.m1.1a"><mn id="S3.T1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.m1.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.m1.1b"><cn type="integer" id="S3.T1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.m1.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.m1.1c">15</annotation></semantics></math>B</td>
</tr>
<tr id="S3.T1.11.13.2" class="ltx_tr">
<td id="S3.T1.11.13.2.1" class="ltx_td ltx_align_left">EDGAR<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://www.sec.gov/edgar" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.sec.gov/edgar</a></span></span></span>
</td>
<td id="S3.T1.11.13.2.2" class="ltx_td ltx_align_center">5B</td>
</tr>
<tr id="S3.T1.2.2" class="ltx_tr">
<td id="S3.T1.2.2.2" class="ltx_td ltx_align_left">English MultiLegal Pile<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>We limited ourselves to the commercially-licensed subset: <a target="_blank" href="https://huggingface.co/datasets/joelniklaus/Multi_Legal_Pile_Commercial" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/datasets/joelniklaus/Multi_Legal_Pile_Commercial</a></span></span></span>
</td>
<td id="S3.T1.2.2.1" class="ltx_td ltx_align_center">
<math id="S3.T1.2.2.1.m1.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S3.T1.2.2.1.m1.1a"><mn id="S3.T1.2.2.1.m1.1.1" xref="S3.T1.2.2.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.1.m1.1b"><cn type="integer" id="S3.T1.2.2.1.m1.1.1.cmml" xref="S3.T1.2.2.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.1.m1.1c">50</annotation></semantics></math>B</td>
</tr>
<tr id="S3.T1.3.3" class="ltx_tr">
<td id="S3.T1.3.3.2" class="ltx_td ltx_align_left">English EuroParl <cite class="ltx_cite ltx_citemacro_citep">(Koehn, <a href="#bib.bib38" title="" class="ltx_ref">2005</a>)</cite>
</td>
<td id="S3.T1.3.3.1" class="ltx_td ltx_align_center">
<math id="S3.T1.3.3.1.m1.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S3.T1.3.3.1.m1.1a"><mn id="S3.T1.3.3.1.m1.1.1" xref="S3.T1.3.3.1.m1.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.1.m1.1b"><cn type="integer" id="S3.T1.3.3.1.m1.1.1.cmml" xref="S3.T1.3.3.1.m1.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.1.m1.1c">6</annotation></semantics></math>B</td>
</tr>
<tr id="S3.T1.4.4" class="ltx_tr">
<td id="S3.T1.4.4.2" class="ltx_td ltx_align_left">GovInfo<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://www.govinfo.gov/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.govinfo.gov/</a></span></span></span> Statutes, Opinions &amp; Codes</td>
<td id="S3.T1.4.4.1" class="ltx_td ltx_align_center">
<math id="S3.T1.4.4.1.m1.1" class="ltx_Math" alttext="11" display="inline"><semantics id="S3.T1.4.4.1.m1.1a"><mn id="S3.T1.4.4.1.m1.1.1" xref="S3.T1.4.4.1.m1.1.1.cmml">11</mn><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.1.m1.1b"><cn type="integer" id="S3.T1.4.4.1.m1.1.1.cmml" xref="S3.T1.4.4.1.m1.1.1">11</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.1.m1.1c">11</annotation></semantics></math>B</td>
</tr>
<tr id="S3.T1.5.5" class="ltx_tr">
<td id="S3.T1.5.5.2" class="ltx_td ltx_align_left">Law Stack Exchange<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a target="_blank" href="https://huggingface.co/datasets/ymoslem/Law-StackExchange" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/datasets/ymoslem/Law-StackExchange</a></span></span></span>
</td>
<td id="S3.T1.5.5.1" class="ltx_td ltx_align_center">
<math id="S3.T1.5.5.1.m1.1" class="ltx_Math" alttext="19" display="inline"><semantics id="S3.T1.5.5.1.m1.1a"><mn id="S3.T1.5.5.1.m1.1.1" xref="S3.T1.5.5.1.m1.1.1.cmml">19</mn><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.1.m1.1b"><cn type="integer" id="S3.T1.5.5.1.m1.1.1.cmml" xref="S3.T1.5.5.1.m1.1.1">19</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.1.m1.1c">19</annotation></semantics></math>M</td>
</tr>
<tr id="S3.T1.6.6" class="ltx_tr">
<td id="S3.T1.6.6.2" class="ltx_td ltx_align_left">Commercial Open Australian Legal Corpus<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a target="_blank" href="https://github.com/umarbutler/open-australian-legal-corpus-creator" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/umarbutler/open-australian-legal-corpus-creator</a></span></span></span>
</td>
<td id="S3.T1.6.6.1" class="ltx_td ltx_align_center">
<math id="S3.T1.6.6.1.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S3.T1.6.6.1.m1.1a"><mn id="S3.T1.6.6.1.m1.1.1" xref="S3.T1.6.6.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.1.m1.1b"><cn type="float" id="S3.T1.6.6.1.m1.1.1.cmml" xref="S3.T1.6.6.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.1.m1.1c">0.5</annotation></semantics></math>B</td>
</tr>
<tr id="S3.T1.7.7" class="ltx_tr">
<td id="S3.T1.7.7.2" class="ltx_td ltx_align_left">EU Legislation<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>Scraped from <a target="_blank" href="https://eur-lex.europa.eu/homepage.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://eur-lex.europa.eu/homepage.html</a></span></span></span>
</td>
<td id="S3.T1.7.7.1" class="ltx_td ltx_align_center">
<math id="S3.T1.7.7.1.m1.1" class="ltx_Math" alttext="315" display="inline"><semantics id="S3.T1.7.7.1.m1.1a"><mn id="S3.T1.7.7.1.m1.1.1" xref="S3.T1.7.7.1.m1.1.1.cmml">315</mn><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.1.m1.1b"><cn type="integer" id="S3.T1.7.7.1.m1.1.1.cmml" xref="S3.T1.7.7.1.m1.1.1">315</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.1.m1.1c">315</annotation></semantics></math>M</td>
</tr>
<tr id="S3.T1.8.8" class="ltx_tr">
<td id="S3.T1.8.8.2" class="ltx_td ltx_align_left">UK Legislation<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a target="_blank" href="https://www.legislation.gov.uk/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.legislation.gov.uk/</a></span></span></span>
</td>
<td id="S3.T1.8.8.1" class="ltx_td ltx_align_center">
<math id="S3.T1.8.8.1.m1.1" class="ltx_Math" alttext="190" display="inline"><semantics id="S3.T1.8.8.1.m1.1a"><mn id="S3.T1.8.8.1.m1.1.1" xref="S3.T1.8.8.1.m1.1.1.cmml">190</mn><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.1.m1.1b"><cn type="integer" id="S3.T1.8.8.1.m1.1.1.cmml" xref="S3.T1.8.8.1.m1.1.1">190</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.1.m1.1c">190</annotation></semantics></math>M</td>
</tr>
<tr id="S3.T1.9.9" class="ltx_tr">
<td id="S3.T1.9.9.2" class="ltx_td ltx_align_left">Court Transcripts<span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>Obtained from CourtListener: <a target="_blank" href="https://www.courtlistener.com/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.courtlistener.com/</a>. We use Whisper <cite class="ltx_cite ltx_citemacro_citep">(Radford et&nbsp;al., <a href="#bib.bib61" title="" class="ltx_ref">2022</a>)</cite> to transcribe the audio files.</span></span></span>
</td>
<td id="S3.T1.9.9.1" class="ltx_td ltx_align_center">
<math id="S3.T1.9.9.1.m1.1" class="ltx_Math" alttext="350" display="inline"><semantics id="S3.T1.9.9.1.m1.1a"><mn id="S3.T1.9.9.1.m1.1.1" xref="S3.T1.9.9.1.m1.1.1.cmml">350</mn><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.1.m1.1b"><cn type="integer" id="S3.T1.9.9.1.m1.1.1.cmml" xref="S3.T1.9.9.1.m1.1.1">350</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.1.m1.1c">350</annotation></semantics></math>M</td>
</tr>
<tr id="S3.T1.10.10" class="ltx_tr">
<td id="S3.T1.10.10.2" class="ltx_td ltx_align_left">UPSTO<span id="footnote13" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a target="_blank" href="https://bulkdata.uspto.gov/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://bulkdata.uspto.gov/</a></span></span></span>
</td>
<td id="S3.T1.10.10.1" class="ltx_td ltx_align_center">
<math id="S3.T1.10.10.1.m1.1" class="ltx_Math" alttext="4.7" display="inline"><semantics id="S3.T1.10.10.1.m1.1a"><mn id="S3.T1.10.10.1.m1.1.1" xref="S3.T1.10.10.1.m1.1.1.cmml">4.7</mn><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.1.m1.1b"><cn type="float" id="S3.T1.10.10.1.m1.1.1.cmml" xref="S3.T1.10.10.1.m1.1.1">4.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.1.m1.1c">4.7</annotation></semantics></math>B</td>
</tr>
<tr id="S3.T1.11.11" class="ltx_tr">
<td id="S3.T1.11.11.2" class="ltx_td ltx_align_left ltx_border_bb">Total</td>
<td id="S3.T1.11.11.1" class="ltx_td ltx_align_center ltx_border_bb">
<math id="S3.T1.11.11.1.m1.1" class="ltx_Math" alttext="94" display="inline"><semantics id="S3.T1.11.11.1.m1.1a"><mn id="S3.T1.11.11.1.m1.1.1" xref="S3.T1.11.11.1.m1.1.1.cmml">94</mn><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.1.m1.1b"><cn type="integer" id="S3.T1.11.11.1.m1.1.1.cmml" xref="S3.T1.11.11.1.m1.1.1">94</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.1.m1.1c">94</annotation></semantics></math>B</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span><span id="S3.T1.13.1" class="ltx_text ltx_font_bold">Sources of Legal Pretraining Data.</span> These sources contain noise and heavily duplicated documents, which we filtered and deduplicated, resulting in a 30 billion tokens dataset.</figcaption>
</figure>
<div id="S3.SS1.SSS1.Px1.p2" class="ltx_para">
<p id="S3.SS1.SSS1.Px1.p2.1" class="ltx_p">There is quite a lot of overlap between the different sources, and we run very aggressive cleaning and deduplication steps, described in <a href="#S3.SS1.SSS2" title="3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.1.2</span></a>.</p>
</div>
</section>
<section id="S3.SS1.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Replay Sources</h5>

<div id="S3.SS1.SSS1.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS1.Px2.p1.1" class="ltx_p">To reduce the risk of catastrophic forgetting <cite class="ltx_cite ltx_citemacro_citep">(McCloskey and Cohen, <a href="#bib.bib48" title="" class="ltx_ref">1989</a>)</cite> during continued pretraining, we incorporate data from the prior training distribution, following prior literature <cite class="ltx_cite ltx_citemacro_cite">Chen et&nbsp;al. (<a href="#bib.bib12" title="" class="ltx_ref">2023</a>); Sun et&nbsp;al. (<a href="#bib.bib69" title="" class="ltx_ref">2020</a>)</cite>. However, since the training data for Mistral is undisclosed, we introduce commonly available “general” data from Wikipedia, StackExchange, and GitHub, comprising roughly <math id="S3.SS1.SSS1.Px2.p1.1.m1.1" class="ltx_Math" alttext="2\%" display="inline"><semantics id="S3.SS1.SSS1.Px2.p1.1.m1.1a"><mrow id="S3.SS1.SSS1.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.cmml"><mn id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.2" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.2.cmml">2</mn><mo id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.1" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px2.p1.1.m1.1b"><apply id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1"><csymbol cd="latexml" id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.2">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px2.p1.1.m1.1c">2\%</annotation></semantics></math> of the final training mix. These datasets are sampled from SlimPajama <cite class="ltx_cite ltx_citemacro_cite">Shen et&nbsp;al. (<a href="#bib.bib66" title="" class="ltx_ref">2023</a>); Computer (<a href="#bib.bib15" title="" class="ltx_ref">2023</a>); Soboleva et&nbsp;al. (<a href="#bib.bib68" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</section>
<section id="S3.SS1.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Instruction Sources</h5>

<div id="S3.SS1.SSS1.Px3.p1" class="ltx_para">
<p id="S3.SS1.SSS1.Px3.p1.1" class="ltx_p">Additionally, we found it beneficial to include conversational data during pretraining. This is inspired by recent advances in neural machine translation, which highlight that the robust capabilities of LLMs in translation are due to the existence of accidental parallel data in the training corpus <cite class="ltx_cite ltx_citemacro_cite">Anil et&nbsp;al. (<a href="#bib.bib4" title="" class="ltx_ref">2023</a>); Briakou et&nbsp;al. (<a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite>. Specifically, this means that we include the Super Natural Instruction <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib79" title="" class="ltx_ref">2022</a>)</cite> and FLAN collection <cite class="ltx_cite ltx_citemacro_cite">Longpre et&nbsp;al. (<a href="#bib.bib44" title="" class="ltx_ref">2023</a>)</cite> during pretraining.</p>
</div>
</section>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Data Cleaning</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">A significant fraction of the collected data is either in PDF files or is text extracted from PDFs<span id="footnote14" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span>We used <a target="_blank" href="https://poppler.freedesktop.org/" title="" class="ltx_ref ltx_href">Poppler</a> for text extraction from PDF files.</span></span></span>. This means that the text has some artifacts, including i) page numbers in the middle of sentences; ii) line numbers; iii) non-normalized unicode characters; iv) broken lines of text; v) repeated characters: new lines, dashes, etc; vi) other artifacts. We addressed these issues using a combination of rules and heuristics to filter the data.</p>
</div>
<section id="S3.SS1.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Text Normalization</h5>

<div id="S3.SS1.SSS2.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS2.Px1.p1.1" class="ltx_p">We normalize all unicode with the NFKC method, available through the <span id="S3.SS1.SSS2.Px1.p1.1.1" class="ltx_text ltx_font_typewriter">unicodedata</span> Python package.</p>
</div>
</section>
<section id="S3.SS1.SSS2.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Rule filters</h5>

<div id="S3.SS1.SSS2.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.Px2.p1.2" class="ltx_p">Following <cite class="ltx_cite ltx_citemacro_citet">Elazar et&nbsp;al. (<a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite>, we found the most common 10-grams in our dataset and used regular expressions to remove the undesired ones, which were mostly repeated characters. Concretely, <math id="S3.SS1.SSS2.Px2.p1.1.m1.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S3.SS1.SSS2.Px2.p1.1.m1.1a"><mn id="S3.SS1.SSS2.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS2.Px2.p1.1.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.Px2.p1.1.m1.1b"><cn type="integer" id="S3.SS1.SSS2.Px2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS2.Px2.p1.1.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.Px2.p1.1.m1.1c">8</annotation></semantics></math> of the top <math id="S3.SS1.SSS2.Px2.p1.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.SS1.SSS2.Px2.p1.2.m2.1a"><mn id="S3.SS1.SSS2.Px2.p1.2.m2.1.1" xref="S3.SS1.SSS2.Px2.p1.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.Px2.p1.2.m2.1b"><cn type="integer" id="S3.SS1.SSS2.Px2.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS2.Px2.p1.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.Px2.p1.2.m2.1c">10</annotation></semantics></math> 10-grams in the original data were repeated characters, eg: “<span id="S3.SS1.SSS2.Px2.p1.2.1" class="ltx_text ltx_font_typewriter">- - - - - - - - - -</span>”, “<span id="S3.SS1.SSS2.Px2.p1.2.2" class="ltx_text ltx_font_typewriter">. . . . . . . . . .</span>”, or “<span id="S3.SS1.SSS2.Px2.p1.2.3" class="ltx_text ltx_font_typewriter">* * * * * * * * * *</span>”, and weird characters, ie encoding issues. Additionally, we removed repeated whitespace (spaces, new lines, and tabs), as well as any HTML tag that made it through our pipeline.</p>
</div>
</section>
<section id="S3.SS1.SSS2.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Perplexity filtering</h5>

<div id="S3.SS1.SSS2.Px3.p1" class="ltx_para">
<p id="S3.SS1.SSS2.Px3.p1.1" class="ltx_p">We trained a KenLM model <cite class="ltx_cite ltx_citemacro_citep">(Heafield, <a href="#bib.bib29" title="" class="ltx_ref">2011</a>)</cite> on a small subset of carefully inspected legal data, and used it to filter any high perplexity paragraph. This removed non-English text as well as most of the “weird” unicode sequences present in the data. We show some of the most common <math id="S3.SS1.SSS2.Px3.p1.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.SS1.SSS2.Px3.p1.1.m1.1a"><mn id="S3.SS1.SSS2.Px3.p1.1.m1.1.1" xref="S3.SS1.SSS2.Px3.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.Px3.p1.1.m1.1b"><cn type="integer" id="S3.SS1.SSS2.Px3.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS2.Px3.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.Px3.p1.1.m1.1c">10</annotation></semantics></math>-grams in the filtered data on <a href="#S3.T2" title="In Perplexity filtering ‣ 3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Common 10-grams</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.2.1" class="ltx_tr">
<td id="S3.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.1.2.1.1.1" class="ltx_text ltx_font_typewriter">have been obvious to one of ordinary skill in the</span></td>
</tr>
<tr id="S3.T2.1.3.2" class="ltx_tr">
<td id="S3.T2.1.3.2.1" class="ltx_td ltx_align_center"><span id="S3.T2.1.3.2.1.1" class="ltx_text ltx_font_typewriter">before the effective filing date of the claimed invention to</span></td>
</tr>
<tr id="S3.T2.1.4.3" class="ltx_tr">
<td id="S3.T2.1.4.3.1" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.1.4.3.1.1" class="ltx_text ltx_font_typewriter">rejected under 35 U.S.C . 103 as being unpatentable over</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span><span id="S3.T2.3.1" class="ltx_text ltx_font_bold">Most common 10-grams</span> in the pretraining dataset.</figcaption>
</figure>
</section>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>Data Deduplication</h4>

<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p id="S3.SS1.SSS3.p1.1" class="ltx_p">Inspired by <cite class="ltx_cite ltx_citemacro_citet">Kocetkov et&nbsp;al. (<a href="#bib.bib37" title="" class="ltx_ref">2023</a>); Lee et&nbsp;al. (<a href="#bib.bib39" title="" class="ltx_ref">2021</a>)</cite>, we removed duplicates and near-duplicates from the training data using <cite class="ltx_cite ltx_citemacro_citet">Mou et&nbsp;al. (<a href="#bib.bib50" title="" class="ltx_ref">2023</a>)</cite>, with default parameters, after which we were left with roughly <math id="S3.SS1.SSS3.p1.1.m1.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S3.SS1.SSS3.p1.1.m1.1a"><mn id="S3.SS1.SSS3.p1.1.m1.1.1" xref="S3.SS1.SSS3.p1.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.1.m1.1b"><cn type="integer" id="S3.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p1.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.1.m1.1c">30</annotation></semantics></math>B tokens of high-quality text.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Instruction Finetuning Mixes</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Instruction fine-tuning is crucial for getting the best performance out of the pre-trained decoder models across different tasks. We use a mix of general and legal instructions to train the model to understand and follow instructions well, with a focus on legal expertise.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">General Instructions</h5>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">When it comes to general instructions, we gather them from four primary sources:</p>
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">SlimOrca</span> This subset of the FLAN collection comprises generic instructions, offering a focused resource for various tasks <cite class="ltx_cite ltx_citemacro_cite">Mukherjee et&nbsp;al. (<a href="#bib.bib51" title="" class="ltx_ref">2023</a>); Lian et&nbsp;al. (<a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Meta Math Question Answering Instructions</span> Designed for mathematical inquiry, this dataset<span id="footnote15" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span>Accessible at <a href="meta-math/MetaMathQA" title="" class="ltx_ref ltx_url ltx_font_typewriter">meta-math/MetaMathQA</a></span></span></span> presents a range of mathematical questions, facilitating research in math-based natural language processing <cite class="ltx_cite ltx_citemacro_cite">Yu et&nbsp;al. (<a href="#bib.bib87" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">General Conversations from UltraChat</span> Capturing diverse conversational contexts, this GPT-derived dataset contributes to enhancing natural language understanding and generation systems <cite class="ltx_cite ltx_citemacro_cite">Ding et&nbsp;al. (<a href="#bib.bib19" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p"><span id="S3.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Code Instructions from Glaive Code Assistant v2<span id="footnote16" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note"><span id="footnote16.1.1.1" class="ltx_text ltx_font_medium">16</span></span><span id="footnote16.9" class="ltx_text ltx_font_medium">Available at </span><a target="_blank" href="https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v2" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v2</a></span></span></span></span> Training on code has been shown to increase the reasoning ability of models <cite class="ltx_cite ltx_citemacro_citep">(Ma et&nbsp;al., <a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite></p>
</div>
</li>
</ol>
</div>
<div id="S3.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p2.1" class="ltx_p">We meticulously filter, deduplicate, and curate all this data, resulting in a refined dataset comprising <math id="S3.SS2.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="600" display="inline"><semantics id="S3.SS2.SSS0.Px1.p2.1.m1.1a"><mn id="S3.SS2.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.cmml">600</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.1.m1.1b"><cn type="integer" id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1">600</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.1.m1.1c">600</annotation></semantics></math>K instructions.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Legal Instruction Construction</h5>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">We synthetically generate comprehensive conversations addressing fundamental legal competencies across multiple legal document types <cite class="ltx_cite ltx_citemacro_cite">Ding et&nbsp;al. (<a href="#bib.bib19" title="" class="ltx_ref">2023</a>)</cite>. We leverage a <span id="S3.SS2.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_typewriter">Mistral-7B-instruct</span> to transform legal texts augmented with metadata into coherent conversations.
The methodology involves initiating the conversation with <math id="S3.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.SS2.SSS0.Px2.p1.1.m1.1a"><mn id="S3.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.1.m1.1b"><cn type="integer" id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.1.m1.1c">3</annotation></semantics></math> predefined turns: (1) the user articulates a request related to the legal document, (2) the assistant responds by rephrasing the metadata (e.g., document type, date, name of a judge), and (3) the user prompts the assistant to elaborate on its reasoning. Subsequently, we extend the conversation through a series of turns, where a user model progressively poses more specific questions to grasp the assistant’s reasoning. Simultaneously, an assistant model provides in-depth insights. An illustrative example is presented in <a href="#S3.F2" title="In Legal Instruction Construction ‣ 3.2 Instruction Finetuning Mixes ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>. Notably, we ensure the exclusion of the test set from existing benchmarks.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2403.03883/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="332" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S3.F2.9.1" class="ltx_text ltx_font_bold">Turning dataset with metadata into a conversation.</span> Taking the example of Reddit post classification, we turn a labeled example {"<span id="S3.F2.10.2" class="ltx_text ltx_font_italic">My employer fired me because …Is it legal?</span>", "<span id="S3.F2.11.3" class="ltx_text ltx_font_italic">employment</span>" }, we hard-code the first three turns of the conversation by simply reformulating the query and answer as a natural conversation. We then complete the conversation using a <span id="S3.F2.12.4" class="ltx_text ltx_font_italic">user</span> model(blue dashed), whose task is to continue generating relevant questions from the ongoing conversation, and an <span id="S3.F2.13.5" class="ltx_text ltx_font_italic">assistant</span> model that provides answers. Both <span id="S3.F2.14.6" class="ltx_text ltx_font_italic">assistant</span> and <span id="S3.F2.15.7" class="ltx_text ltx_font_italic">user</span> models are <span id="S3.F2.16.8" class="ltx_text ltx_font_typewriter">Mistral-7B-instruct</span>.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation of Legal Knowledge</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.2" class="ltx_p">To evaluate the model’s legal abilities, we use <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S4.p1.1.m1.1a"><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><cn type="integer" id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">3</annotation></semantics></math> benchmarks (i) we compare the perplexity of the backbones on <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S4.p1.2.m2.1a"><mn id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><cn type="integer" id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">5</annotation></semantics></math> types of legal documents, (ii) we enhance LegalBench with LegalBench-Instruct for deeper evaluation, (iii) we rely on the legal section of MMLU for additional insights.</p>
</div>
<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Perplexity Measurement</h5>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p1.1" class="ltx_p">To evaluate the adaptability of the backbones to legal documents, we assess perplexity using benchmark datasets spanning four distinct legal domains: <em id="S4.SS0.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">contracts, judicial decisions, opinion text, and legislation</em>. We ensure that the datasets are up-to-date, and sourced after the collection cut-off date from LLM data. Specifically, contract data is sourced from EDGAR (first quarter of 2024), legal decisions from ICSID court decisions published after October 2023, legislation focuses on US bills submitted before the House or Senate after October 2023, and party submissions include Texas briefs submitted after October 2023.</p>
</div>
<div id="S4.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p2.1" class="ltx_p">During our investigations, we found a significant limitation in the original prompts of LegalBench. The complex nature of these prompts, combined with the challenges encountered by open source LLMs in adhering to instructions - particularly in handling formatting - leads to a substantial drop in performance (as measured by accuracy). The generated sentences are often verbose and difficult to parse, rendering LegalBench in its current form too stringent and failing to accurately gauge improvement on the task.</p>
</div>
<div id="S4.SS0.SSS0.Px1.p3" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p3.1" class="ltx_p">For example, in some of the tasks, performance is evaluated by the first word the model predicts, and this word is expected to be a <em id="S4.SS0.SSS0.Px1.p3.1.1" class="ltx_emph ltx_font_italic">Yes/No</em>. This means that if the response is a bit verbose it will be counted as incorrect, even if a human would classify it as a correct answer. To remedy this shortcoming, we refine the prompts by 1) removing distracting few-shot examples and 2) concluding with a specific instruction for the model to generate tags (see <a href="#S4.T3" title="In Perplexity Measurement ‣ 4 Evaluation of Legal Knowledge ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<figure id="S4.T3" class="ltx_table">
<table id="S4.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T3.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.1.1.1.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Original Prompt</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.2.1" class="ltx_tr">
<td id="S4.T3.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.2.1.1.1.1" class="ltx_p" style="width:199.2pt;">The Telemarketing Sales Rule is provided by 16 C.F.R. § 310.3(a)(1) and 16 C.F.R. § 310.3(a)(2).</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.3.2" class="ltx_tr">
<td id="S4.T3.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.3.2.1.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.3.2.1.1.1.1" class="ltx_text ltx_font_bold">Question:</span> Acme Toys is a telemarketer subject to the Telemarketing Sales Rule. Acme Toys told a customer that its frisbees cost $10 each, when in fact the frisbees cost $12 each. The customer agreed to the sale and was charged $12. Is this a violation of the Telemarketing Sales Rule?</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.4.3" class="ltx_tr">
<td id="S4.T3.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.4.3.1.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.4.3.1.1.1.1" class="ltx_text ltx_font_bold">Answer:</span> Yes</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.5.4" class="ltx_tr">
<td id="S4.T3.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.5.4.1.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.5.4.1.1.1.1" class="ltx_text ltx_font_bold">Question:</span> Acme Toys is a telemarketer subject to the Telemarketing Sales Rule. Acme Toys told a customer that its frisbees cost $10 each, when in fact the frisbees did cost $10, but Acme Toys did not disclose that shipping would cost an additional $5. The customer agreed to the sale. Is this a violation of the Telemarketing Sales Rule?</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.6.5" class="ltx_tr">
<td id="S4.T3.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.6.5.1.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.6.5.1.1.1.1" class="ltx_text ltx_font_bold">Answer:</span> Yes</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.7.6" class="ltx_tr">
<td id="S4.T3.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.7.6.1.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.7.6.1.1.1.1" class="ltx_text ltx_font_bold">Question:</span> Acme Industrial Products is a telemarketer subject to the Telemarketing Sales Rule. Acme Industrial Products told a customer that its brooms cost $12 each, and the brooms did in fact cost $12. The customer agreed to the sale. Is this a violation of the Telemarketing Sales Rule?</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.8.7" class="ltx_tr">
<td id="S4.T3.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.8.7.1.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.8.7.1.1.1.1" class="ltx_text ltx_font_bold">Answer:</span> No</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.9.8" class="ltx_tr">
<td id="S4.T3.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.9.8.1.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.9.8.1.1.1.1" class="ltx_text ltx_font_bold">Question:</span> Acme Industrial Products is a telemarketer subject to the Telemarketing Sales Rule. Acme Industrial Products told a customer that it would sell them 4 brooms for $10 and that shipping would be $5. Then, the customer agreed to the sale. Is this a violation of the Telemarketing Sales Rule?</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.10.9" class="ltx_tr">
<td id="S4.T3.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.10.9.1.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.10.9.1.1.1.1" class="ltx_text ltx_font_bold">Answer:</span> No</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.11.10" class="ltx_tr">
<td id="S4.T3.1.11.10.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.11.10.1.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.11.10.1.1.1.1" class="ltx_text ltx_font_bold">Question:</span> {text}</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.12.11" class="ltx_tr">
<td id="S4.T3.1.12.11.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S4.T3.1.12.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.12.11.1.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.12.11.1.1.1.1" class="ltx_text ltx_font_bold">Answer:</span></span>
</span>
</td>
</tr>
<tr id="S4.T3.1.13.12" class="ltx_tr">
<td id="S4.T3.1.13.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S4.T3.1.13.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.13.12.1.1.1" class="ltx_p" style="width:199.2pt;"><span id="S4.T3.1.13.12.1.1.1.1" class="ltx_text ltx_font_bold">Curated Prompt</span> (Ours)</span>
</span>
</td>
</tr>
<tr id="S4.T3.1.14.13" class="ltx_tr">
<td id="S4.T3.1.14.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S4.T3.1.14.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.1.14.13.1.1.1" class="ltx_p" style="width:199.2pt;">The Telemarketing Sales Rule is provided by 16 C.F.R. § 310.3(a)(1) and 16 C.F.R. § 310.3(a)(2).</span>
<span id="S4.T3.1.14.13.1.1.2" class="ltx_p">Answer the following question: {text}</span>
<span id="S4.T3.1.14.13.1.1.3" class="ltx_p"><span id="S4.T3.1.14.13.1.1.3.1" class="ltx_text ltx_font_italic">Answer by only outputting "Yes" or "No"</span></span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span><span id="S4.T3.3.1" class="ltx_text ltx_font_bold">Example from LegalBench-Instruct</span>. We manually curated and corrected typos, removing a few short examples from LegalBench as they were found to distract LLMs of size 7B.</figcaption>
</figure>
</section>
<section id="S4.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Massive Multitask Language Understanding (MMLU)</h5>

<div id="S4.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p1.3" class="ltx_p">The MMLU benchmark <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et&nbsp;al., <a href="#bib.bib31" title="" class="ltx_ref">2020</a>)</cite> has been widely employed to gauge the advances in LLM performance. In our study, we center our analysis on the legal domain, with a specific focus on:
<span id="S4.SS0.SSS0.Px2.p1.3.1" class="ltx_text ltx_font_italic">international law</span>, <span id="S4.SS0.SSS0.Px2.p1.3.2" class="ltx_text ltx_font_italic">professional law</span>, and <span id="S4.SS0.SSS0.Px2.p1.3.3" class="ltx_text ltx_font_italic">jurisprudence</span>. Those tasks respectively contain <math id="S4.SS0.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="120" display="inline"><semantics id="S4.SS0.SSS0.Px2.p1.1.m1.1a"><mn id="S4.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">120</mn><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.1.m1.1b"><cn type="integer" id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1">120</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.1.m1.1c">120</annotation></semantics></math>, <math id="S4.SS0.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="1500" display="inline"><semantics id="S4.SS0.SSS0.Px2.p1.2.m2.1a"><mn id="S4.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">1500</mn><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.2.m2.1b"><cn type="integer" id="S4.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1">1500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.2.m2.1c">1500</annotation></semantics></math>, and <math id="S4.SS0.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="110" display="inline"><semantics id="S4.SS0.SSS0.Px2.p1.3.m3.1a"><mn id="S4.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS0.SSS0.Px2.p1.3.m3.1.1.cmml">110</mn><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.3.m3.1b"><cn type="integer" id="S4.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S4.SS0.SSS0.Px2.p1.3.m3.1.1">110</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.3.m3.1c">110</annotation></semantics></math> examples.</p>
</div>
</section>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Metrics</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We use the same metric as the original LegalBench <cite class="ltx_cite ltx_citemacro_cite">Guha et&nbsp;al. (<a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite> paper: balanced accuracy. Balanced accuracy allows for handling better-imbalanced classification tasks, such as the ones presented in both benchmarks. We also use balanced accuracy for the legal tasks of MMLU. Unless otherwise noted, any score reported throughout this section refers to the balanced accuracy.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Setting</h2>

<figure id="S5.F3" class="ltx_figure"><img src="/html/2403.03883/assets/x3.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="415" height="415" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span id="S5.F3.4.1" class="ltx_text ltx_font_bold">Performance of base models on LegalBench-Instruct.</span> Interestingly, although not instruction fine-tuned, <span id="S5.F3.5.2" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> is still able to achieve impressive improvements on the benchmark, compared to other base models, including <span id="S5.F3.6.3" class="ltx_text ltx_font_typewriter">SaulLM-7B</span>’s initial checkpoint (Mistral-7B).</figcaption>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Baselines</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.2" class="ltx_p">We compare the <span id="S5.SS1.p1.2.1" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> family to other state-of-the-art <math id="S5.SS1.p1.1.m1.1" class="ltx_Math" alttext="7" display="inline"><semantics id="S5.SS1.p1.1.m1.1a"><mn id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><cn type="integer" id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">7</annotation></semantics></math>B and <math id="S5.SS1.p1.2.m2.1" class="ltx_Math" alttext="13" display="inline"><semantics id="S5.SS1.p1.2.m2.1a"><mn id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">13</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><cn type="integer" id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">13</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">13</annotation></semantics></math>B open-source models. Concretely, we include the following instruction and DPO finetuned variants of Mistral-7B <cite class="ltx_cite ltx_citemacro_citep">(Jiang et&nbsp;al., <a href="#bib.bib34" title="" class="ltx_ref">2023</a>)</cite>: <span id="S5.SS1.p1.2.2" class="ltx_text ltx_font_typewriter">Mistral-7B-Instruct-v0.1</span>, <span id="S5.SS1.p1.2.3" class="ltx_text ltx_font_typewriter">Mistral-7B-Instruct-v0.2</span>
, as well as <span id="S5.SS1.p1.2.4" class="ltx_text ltx_font_typewriter">zephyr-7b-beta<span id="footnote17" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note"><span id="footnote17.1.1.1" class="ltx_text ltx_font_serif">17</span></span><a target="_blank" href="https://huggingface.co/HuggingFaceH4/zephyr-7b-beta" title="" class="ltx_ref ltx_url">https://huggingface.co/HuggingFaceH4/zephyr-7b-beta</a></span></span></span></span>. We also evaluate the Llama2 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al., <a href="#bib.bib71" title="" class="ltx_ref">2023a</a>)</cite> family, more specifically <span id="S5.SS1.p1.2.5" class="ltx_text ltx_font_typewriter">Llama2-7b-Chat</span>and <span id="S5.SS1.p1.2.6" class="ltx_text ltx_font_typewriter">Llama2-13b-Chat</span>.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Implementation Details</h3>

<section id="S5.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Codebase</h5>

<div id="S5.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p1.1" class="ltx_p">Our codebase relies on open-source frameworks <cite class="ltx_cite ltx_citemacro_cite">Shoeybi et&nbsp;al. (<a href="#bib.bib67" title="" class="ltx_ref">2019</a>); Wolf et&nbsp;al. (<a href="#bib.bib82" title="" class="ltx_ref">2019</a>); Lhoest et&nbsp;al. (<a href="#bib.bib40" title="" class="ltx_ref">2021</a>)</cite> utilizing DeepSpeed (level 3) with Flash attention <cite class="ltx_cite ltx_citemacro_cite">Dao et&nbsp;al. (<a href="#bib.bib18" title="" class="ltx_ref">2022</a>); Dao (<a href="#bib.bib17" title="" class="ltx_ref">2023</a>)</cite>. It is built on PyTorch <cite class="ltx_cite ltx_citemacro_cite">Paszke et&nbsp;al. (<a href="#bib.bib58" title="" class="ltx_ref">2019</a>)</cite>, and our models are available on the Huggingface hub.</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Compute</h5>

<div id="S5.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px2.p1.1" class="ltx_p">Continuous pretraining utilizes <math id="S5.SS2.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="256" display="inline"><semantics id="S5.SS2.SSS0.Px2.p1.1.m1.1a"><mn id="S5.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.1.m1.1b"><cn type="integer" id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.1.m1.1c">256</annotation></semantics></math> MI250 AMD GPUs. For instruction fine-tuning, workload distribution occurs across 16 MI250. Evaluation procedures are seamlessly conducted on a single MI250.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Results</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this section, we discuss our main experimental findings and results.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>LegalBench-Instruct</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p"><a href="#S5.F3" title="In 5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figures</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a> and&nbsp;<a href="#S6.F4" title="Figure 4 ‣ I. Legal continued pretraining brings significant improvements ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> summarize our results on LegalBench-Instruct. There are <math id="S6.SS1.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS1.p1.1.m1.1a"><mn id="S6.SS1.p1.1.m1.1.1" xref="S6.SS1.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.1.m1.1b"><cn type="integer" id="S6.SS1.p1.1.m1.1.1.cmml" xref="S6.SS1.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.1.m1.1c">3</annotation></semantics></math> main takeaways, which we discuss below.</p>
</div>
<section id="S6.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">I. Legal continued pretraining brings significant improvements</h5>

<div id="S6.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px1.p1.4" class="ltx_p">We start by analyzing the impact of our proposed continued pretraining. As seen on <a href="#S5.F3" title="In 5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a>, <span id="S6.SS1.SSS0.Px1.p1.4.1" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> is a strong standalone model. We speculate that its strong performance is largely due to the integration of instructions in the pre-training data, as mentioned in <a href="#S3.SS1.SSS1" title="3.1.1 Dataset Composition ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">subsubsection&nbsp;3.1.1</span></a>. Nevertheless, we still note that even without a dedicated instruction fine-tuning stage, <span id="S6.SS1.SSS0.Px1.p1.4.2" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> performs on par with <span id="S6.SS1.SSS0.Px1.p1.4.3" class="ltx_text ltx_font_typewriter">Llama2-7B-chat</span> (<math id="S6.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="0.38" display="inline"><semantics id="S6.SS1.SSS0.Px1.p1.1.m1.1a"><mn id="S6.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S6.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">0.38</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.1.m1.1b"><cn type="float" id="S6.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px1.p1.1.m1.1.1">0.38</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.1.m1.1c">0.38</annotation></semantics></math> v.s. <math id="S6.SS1.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="0.39" display="inline"><semantics id="S6.SS1.SSS0.Px1.p1.2.m2.1a"><mn id="S6.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S6.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">0.39</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.2.m2.1b"><cn type="float" id="S6.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S6.SS1.SSS0.Px1.p1.2.m2.1.1">0.39</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.2.m2.1c">0.39</annotation></semantics></math>). More importantly, <span id="S6.SS1.SSS0.Px1.p1.4.4" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> serves as a strong base model for building IFT models with strong legal capabilities. When combined with Generic instruction finetuning, as seen on <a href="#S6.F4" title="In I. Legal continued pretraining brings significant improvements ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">4</span></a>, it achieves a strong average of <math id="S6.SS1.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="0.59" display="inline"><semantics id="S6.SS1.SSS0.Px1.p1.3.m3.1a"><mn id="S6.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S6.SS1.SSS0.Px1.p1.3.m3.1.1.cmml">0.59</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.3.m3.1b"><cn type="float" id="S6.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S6.SS1.SSS0.Px1.p1.3.m3.1.1">0.59</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.3.m3.1c">0.59</annotation></semantics></math>, i.e. <math id="S6.SS1.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S6.SS1.SSS0.Px1.p1.4.m4.1a"><mn id="S6.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S6.SS1.SSS0.Px1.p1.4.m4.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.4.m4.1b"><cn type="integer" id="S6.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S6.SS1.SSS0.Px1.p1.4.m4.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.4.m4.1c">4</annotation></semantics></math> absolute points of improvement with respect to the best open-source instruct model <span id="S6.SS1.SSS0.Px1.p1.4.5" class="ltx_text ltx_font_typewriter">Mistral-7B-Instruct-v0.1</span>.</p>
</div>
<figure id="S6.F4" class="ltx_figure"><img src="/html/2403.03883/assets/x4.png" id="S6.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="322" height="258" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span id="S6.F4.4.1" class="ltx_text ltx_font_bold">Influence of the base model.</span> Starting the instruction finetuning from our base model <span id="S6.F4.5.2" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> brings noticeable improvements compared to the Mistral-7B. Indeed, even with a generic IFT mix (without legal), <span id="S6.F4.6.3" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> (Gen.) outperforms its Mistral-Instruct counterpart significantly. Adding legal instructions to the IFT mix further boosts the results.</figcaption>
</figure>
</section>
<section id="S6.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">II. Legal instruction finetuning further boosts the results</h5>

<div id="S6.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px2.p1.2" class="ltx_p">As seen on <a href="#S3.F2" title="In Legal Instruction Construction ‣ 3.2 Instruction Finetuning Mixes ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>, finetuning <span id="S6.SS1.SSS0.Px2.p1.2.1" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> on both general and legal instructions (<span id="S6.SS1.SSS0.Px2.p1.2.2" class="ltx_text ltx_font_typewriter">SaulLM-7B-Instruct</span>) establishes a new state-of-the-art on the LegalBench-Instruct benchmark, with an average score of <math id="S6.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="0.61" display="inline"><semantics id="S6.SS1.SSS0.Px2.p1.1.m1.1a"><mn id="S6.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S6.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">0.61</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p1.1.m1.1b"><cn type="float" id="S6.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px2.p1.1.m1.1.1">0.61</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p1.1.m1.1c">0.61</annotation></semantics></math>, i.e. an <math id="S6.SS1.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="11" display="inline"><semantics id="S6.SS1.SSS0.Px2.p1.2.m2.1a"><mn id="S6.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S6.SS1.SSS0.Px2.p1.2.m2.1.1.cmml">11</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p1.2.m2.1b"><cn type="integer" id="S6.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S6.SS1.SSS0.Px2.p1.2.m2.1.1">11</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p1.2.m2.1c">11</annotation></semantics></math>% relative improvement compared to the best open-source instruct model (<a href="#S6.F5" title="In II. Legal instruction finetuning further boosts the results ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">5</span></a>.
Finally, DPO-aligned models tend to underperform their instruction-tuned counterparts, which could be explained by the fact that generic alignment is not suited for out-of-distribution tasks, such as the ones present in LegalBench-Instruct. Although beyond the scope of the present work, an interesting research direction would be to explore how legal-specific DPO can help.
</p>
</div>
<figure id="S6.F5" class="ltx_figure"><img src="/html/2403.03883/assets/x5.png" id="S6.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span id="S6.F5.3.1" class="ltx_text ltx_font_bold">Comparison of instruct models on LegalBench-Instruct</span>. <span id="S6.F5.4.2" class="ltx_text ltx_font_typewriter">SaulLM-7B-Instruct</span> establishes the state-of-the-art, outperforming the best Mistral-Instruct model by a significant 6 absolute points.</figcaption>
</figure>
<figure id="S6.F6" class="ltx_figure"><img src="/html/2403.03883/assets/x6.png" id="S6.F6.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="276" height="738" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span id="S6.F6.4.1" class="ltx_text ltx_font_bold">Instruct models on Legal-MMLU.</span> Echoing finding on LegalBench-Instruct, <span id="S6.F6.5.2" class="ltx_text ltx_font_typewriter">SaulLM-7B-Instruct</span> displays superior performance on all three tasks of Legal-MMLU, with an average absolute improvement of 5 points with respect to <span id="S6.F6.6.3" class="ltx_text ltx_font_typewriter">Mistral-7B-Instruct-v0.1</span>. </figcaption>
</figure>
</section>
<section id="S6.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">III. There is still room for significant improvement.</h5>

<div id="S6.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS1.SSS0.Px3.p1.1" class="ltx_p">Next, we follow the original LegalBench taxonomy <cite class="ltx_cite ltx_citemacro_citep">(Guha et&nbsp;al., <a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite> to gain a more granular understanding of <span id="S6.SS1.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_typewriter">SaulLM-7B-Instruct</span>’s performance, by partitioning the tasks into <math id="S6.SS1.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S6.SS1.SSS0.Px3.p1.1.m1.1a"><mn id="S6.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S6.SS1.SSS0.Px3.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px3.p1.1.m1.1b"><cn type="integer" id="S6.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S6.SS1.SSS0.Px3.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px3.p1.1.m1.1c">5</annotation></semantics></math> core legal abilities: <span id="S6.SS1.SSS0.Px3.p1.1.2" class="ltx_text ltx_font_smallcaps">Issue Spotting</span>, <span id="S6.SS1.SSS0.Px3.p1.1.3" class="ltx_text ltx_font_smallcaps">Rule-Recall</span>, <span id="S6.SS1.SSS0.Px3.p1.1.4" class="ltx_text ltx_font_smallcaps">Interpretation</span>, <span id="S6.SS1.SSS0.Px3.p1.1.5" class="ltx_text ltx_font_smallcaps">Rhetoric Understanding</span>, and <span id="S6.SS1.SSS0.Px3.p1.1.6" class="ltx_text ltx_font_smallcaps">Rule-Conclusion</span>. Results show an interesting trend (<a href="#S6.F7" title="In III. There is still room for significant improvement. ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">7</span></a>): <span id="S6.SS1.SSS0.Px3.p1.1.7" class="ltx_text ltx_font_typewriter">SaulLM-7B-Instruct</span> shows clear superior performance over the best non-legal competitor <span id="S6.SS1.SSS0.Px3.p1.1.8" class="ltx_text ltx_font_typewriter">Mistral-7B-Instruct-v0.1</span> on the four areas that require the most legal expertise, i.e. <span id="S6.SS1.SSS0.Px3.p1.1.9" class="ltx_text ltx_font_smallcaps">Issue</span>, <span id="S6.SS1.SSS0.Px3.p1.1.10" class="ltx_text ltx_font_smallcaps">Rule</span>, <span id="S6.SS1.SSS0.Px3.p1.1.11" class="ltx_text ltx_font_smallcaps">Interpretation</span> and <span id="S6.SS1.SSS0.Px3.p1.1.12" class="ltx_text ltx_font_smallcaps">Understanding</span>. On the other hand, it falls short of <span id="S6.SS1.SSS0.Px3.p1.1.13" class="ltx_text ltx_font_typewriter">Mistral-7B-Instruct-v0.1</span> on the <span id="S6.SS1.SSS0.Px3.p1.1.14" class="ltx_text ltx_font_smallcaps">Conclusion</span> tasks, which interestingly require much more pure deductive reasoning than actual legal knowledge. We speculate that augmenting our pretraining and fine-tuning corpora with more deductive reasoning content, including but not limited to mathematics datasets could reduce the gap and fully unlock the potential of <span id="S6.SS1.SSS0.Px3.p1.1.15" class="ltx_text ltx_font_typewriter">SaulLM-7B-Instruct</span>.</p>
</div>
<figure id="S6.F7" class="ltx_figure"><img src="/html/2403.03883/assets/x7.png" id="S6.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="348" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span id="S6.F7.3.1" class="ltx_text ltx_font_bold">Per-task performance breakdown.</span> <span id="S6.F7.4.2" class="ltx_text ltx_font_typewriter">SaulLM-7B-Instruct</span> largely outperforms generic Instruct models on tasks that most require legal-specific knowledge, but is outperformed by Mistral-Instruct on the conclusion tasks, which necessitates more deductive reasoning.</figcaption>
</figure>
</section>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Results on Legal-MMLU</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.2" class="ltx_p">To confirm our observations on LegalBench-Instruct, we analyze the results on Legal-MMLU shown in <a href="#S6.F6" title="In II. Legal instruction finetuning further boosts the results ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">6</span></a>. Again, <span id="S6.SS2.p1.2.1" class="ltx_text ltx_font_typewriter">SaulLM-7B-Instruct</span> exhibits consistent superiority over non-legal instruction-tuned models, with a gap between <math id="S6.SS2.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S6.SS2.p1.1.m1.1a"><mn id="S6.SS2.p1.1.m1.1.1" xref="S6.SS2.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.1.m1.1b"><cn type="integer" id="S6.SS2.p1.1.m1.1.1.cmml" xref="S6.SS2.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.1.m1.1c">3</annotation></semantics></math> and <math id="S6.SS2.p1.2.m2.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S6.SS2.p1.2.m2.1a"><mn id="S6.SS2.p1.2.m2.1.1" xref="S6.SS2.p1.2.m2.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.2.m2.1b"><cn type="integer" id="S6.SS2.p1.2.m2.1.1.cmml" xref="S6.SS2.p1.2.m2.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.2.m2.1c">4</annotation></semantics></math> absolute points to the best 7B open-source competitor across the three tasks, providing additional evidence that <span id="S6.SS2.p1.2.2" class="ltx_text ltx_font_typewriter">SaulLM-7B-Instruct</span> is as a strong foundation to build models tailored to legal workflows.</p>
</div>
<figure id="S6.F8" class="ltx_figure"><img src="/html/2403.03883/assets/x8.png" id="S6.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span><span id="S6.F8.17.1" class="ltx_text ltx_font_bold">Perplexity on legal documents for pretrained backbones.</span> <span id="S6.F8.18.2" class="ltx_text ltx_font_typewriter">SaulLM-7B-Instruct</span> outperforms other pretrained backbones on most types of legal documents, but is outperformed by <span id="S6.F8.19.3" class="ltx_text ltx_font_typewriter">Llama2-7b</span> on Legislation.
<span id="S6.F8.20.4" class="ltx_text ltx_font_typewriter">SaulLM-7B-Instruct</span> exhibits a median perplexity of <math id="S6.F8.6.m1.1" class="ltx_Math" alttext="8.69" display="inline"><semantics id="S6.F8.6.m1.1b"><mn id="S6.F8.6.m1.1.1" xref="S6.F8.6.m1.1.1.cmml">8.69</mn><annotation-xml encoding="MathML-Content" id="S6.F8.6.m1.1c"><cn type="float" id="S6.F8.6.m1.1.1.cmml" xref="S6.F8.6.m1.1.1">8.69</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.6.m1.1d">8.69</annotation></semantics></math>, having a reduction of <math id="S6.F8.7.m2.1" class="ltx_Math" alttext="5.5" display="inline"><semantics id="S6.F8.7.m2.1b"><mn id="S6.F8.7.m2.1.1" xref="S6.F8.7.m2.1.1.cmml">5.5</mn><annotation-xml encoding="MathML-Content" id="S6.F8.7.m2.1c"><cn type="float" id="S6.F8.7.m2.1.1.cmml" xref="S6.F8.7.m2.1.1">5.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.7.m2.1d">5.5</annotation></semantics></math> percent compared to <span id="S6.F8.21.5" class="ltx_text ltx_font_typewriter">Mistral-7B</span>, <math id="S6.F8.8.m3.1" class="ltx_Math" alttext="9.20" display="inline"><semantics id="S6.F8.8.m3.1b"><mn id="S6.F8.8.m3.1.1" xref="S6.F8.8.m3.1.1.cmml">9.20</mn><annotation-xml encoding="MathML-Content" id="S6.F8.8.m3.1c"><cn type="float" id="S6.F8.8.m3.1.1.cmml" xref="S6.F8.8.m3.1.1">9.20</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.8.m3.1d">9.20</annotation></semantics></math>, and <math id="S6.F8.9.m4.1" class="ltx_Math" alttext="10.8" display="inline"><semantics id="S6.F8.9.m4.1b"><mn id="S6.F8.9.m4.1.1" xref="S6.F8.9.m4.1.1.cmml">10.8</mn><annotation-xml encoding="MathML-Content" id="S6.F8.9.m4.1c"><cn type="float" id="S6.F8.9.m4.1.1.cmml" xref="S6.F8.9.m4.1.1">10.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.9.m4.1d">10.8</annotation></semantics></math> percent compared to <span id="S6.F8.22.6" class="ltx_text ltx_font_typewriter">Llama2-7B</span>, with a median perplexity of <math id="S6.F8.10.m5.1" class="ltx_Math" alttext="9.74" display="inline"><semantics id="S6.F8.10.m5.1b"><mn id="S6.F8.10.m5.1.1" xref="S6.F8.10.m5.1.1.cmml">9.74</mn><annotation-xml encoding="MathML-Content" id="S6.F8.10.m5.1c"><cn type="float" id="S6.F8.10.m5.1.1.cmml" xref="S6.F8.10.m5.1.1">9.74</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.10.m5.1d">9.74</annotation></semantics></math>.
</figcaption>
</figure>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Perplexity Analysis</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">To assess the adaptation of <span id="S6.SS3.p1.1.1" class="ltx_text ltx_font_typewriter">SaulLM-7B</span> backbone to the legal domain, we present perplexity scores across four document types: contracts, legal decisions, legislation, and party submissions. Refer to <a href="#S6.F8" title="Figure 8 ‣ 6.2 Results on Legal-MMLU ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure&nbsp;8</span></a> for the results. Our model, <span id="S6.SS3.p1.1.2" class="ltx_text ltx_font_typewriter">SaulLM-7B</span>, consistently outperforms <span id="S6.SS3.p1.1.3" class="ltx_text ltx_font_typewriter">Mistral-7B</span> across all categories, exhibiting lower average perplexity scores with reduced variance. Interestingly, <span id="S6.SS3.p1.1.4" class="ltx_text ltx_font_typewriter">Llama2-7B</span> demonstrates lower perplexity specifically in legislation documents, suggesting a potentially higher proportion of legislative text in the pertaining corpora compared to <span id="S6.SS3.p1.1.5" class="ltx_text ltx_font_typewriter">Mistral-7B</span>.</p>
</div>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.1" class="ltx_p">Overall, compared to <span id="S6.SS3.p2.1.1" class="ltx_text ltx_font_typewriter">Mistral-7B</span>, our model shows a median perplexity reduction of 3 percent across legal corpora and 11 percent when compared to <span id="S6.SS3.p2.1.2" class="ltx_text ltx_font_typewriter">Llama2-7B</span>.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion &amp; Future Perspectives</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this paper, we introduce <span id="S7.p1.1.1" class="ltx_text ltx_font_typewriter">SaulLM-7B</span>, an open-source decoder model delivering state-of-the-art performance, compared to 7B models, within the legal domain. Our approach entails fine-tuning legal data alongside instruction fine-tuning on synthetic datasets. Additionally, we contribute by providing a cleaned version of LegalBench and introducing a new set of documents for perplexity measurement. We hope that our model, which is released under the MIT license, will contribute to the open-source ecosystem and the community.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">We thank GENCI for generously granting us access to their cutting-edge computing resources. Our model, <span id="Sx1.p1.1.1" class="ltx_text ltx_font_typewriter">SaulLM-7B</span>, has been trained on ADASTRA, with initial experimentation conducted on Jeanzay. The utilization of HPC resources was made possible through the Jeanzay grants 101838, 103256, and 103298, as well as the Adastra grants C1615122, CAD14770, and CAD15031.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia&nbsp;Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.08774</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aletras et&nbsp;al. (2016)</span>
<span class="ltx_bibblock">
Nikolaos Aletras, Dimitrios Tsarapatsanis, Daniel Preoţiuc-Pietro, and Vasileios Lampos. 2016.

</span>
<span class="ltx_bibblock">Predicting judicial decisions of the european court of human rights: A natural language processing perspective.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">PeerJ computer science</em>, 2:e93.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Almazrouei et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Mérouane Debbah, Étienne Goffinet, Daniel Hesslow, Julien Launay, Quentin Malartic, Daniele Mazzotta, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2311.16867" title="" class="ltx_ref ltx_href">The falcon series of open language models</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rohan Anil, Andrew&nbsp;M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Palm 2 technical report.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.10403</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu&nbsp;Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An&nbsp;Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2309.16609" title="" class="ltx_ref ltx_href">Qwen technical report</a>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biderman et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Stella Biderman, Hailey Schoelkopf, Quentin&nbsp;Gregory Anthony, Herbie Bradley, Kyle O’Brien, Eric Hallahan, Mohammad&nbsp;Aflah Khan, Shivanshu Purohit, USVSN&nbsp;Sai Prashanth, Edward Raff, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Pythia: A suite for analyzing large language models across training and scaling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages 2397–2430. PMLR.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Briakou et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Eleftheria Briakou, Colin Cherry, and George Foster. 2023.

</span>
<span class="ltx_bibblock">Searching for needles in a haystack: On the role of incidental bilingualism in palm’s translation capability.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.10266</em>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Butler (2023)</span>
<span class="ltx_bibblock">
Umar Butler. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.57967/hf/1306" title="" class="ltx_ref ltx_href">Open australian legal corpus</a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yihan Cao, Yanbin Kang, and Lichao Sun. 2023.

</span>
<span class="ltx_bibblock">Instruction mining: High-quality instruction data selection for large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.06290</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chalkidis et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Ilias Chalkidis, Ion Androutsopoulos, and Nikolaos Aletras. 2019.

</span>
<span class="ltx_bibblock">Neural legal judgment prediction in english.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.02059</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chalkidis et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Ilias Chalkidis, Manos Fergadiotis, Prodromos Malakasiotis, Nikolaos Aletras, and Ion Androutsopoulos. 2020.

</span>
<span class="ltx_bibblock">Legal-bert: The muppets straight out of law school.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.02559</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zeming Chen, Alejandro&nbsp;Hernández Cano, Angelika Romanou, Antoine Bonnet, Kyle Matoba, Francesco Salvi, Matteo Pagliardini, Simin Fan, Andreas Köpf, Amirkeivan Mohtashami, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Meditron-70b: Scaling medical pretraining for large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.16079</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Daixuan Cheng, Shaohan Huang, and Furu Wei. 2023.

</span>
<span class="ltx_bibblock">Adapting large language models via reading comprehension.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.09530</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Hyung&nbsp;Won Chung, Le&nbsp;Hou, Shayne Longpre, Barret Zoph, Yi&nbsp;Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.11416</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Computer (2023)</span>
<span class="ltx_bibblock">
Together Computer. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/togethercomputer/RedPajama-Data" title="" class="ltx_ref ltx_href">Redpajama: an open dataset for training large language models</a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Jiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and Li&nbsp;Yuan. 2023.

</span>
<span class="ltx_bibblock">Chatlaw: Open-source legal large language model with integrated external knowledge bases.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.16092</em>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dao (2023)</span>
<span class="ltx_bibblock">
Tri Dao. 2023.

</span>
<span class="ltx_bibblock">Flashattention-2: Faster attention with better parallelism and work partitioning.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.08691</em>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dao et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. 2022.

</span>
<span class="ltx_bibblock">Flashattention: Fast and memory-efficient exact attention with io-awareness.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 35:16344–16359.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong Sun, and Bowen Zhou. 2023.

</span>
<span class="ltx_bibblock">Enhancing chat language models by scaling high-quality instructional conversations.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.14233</em>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elazar et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yanai Elazar, Akshita Bhagia, Ian Magnusson, Abhilasha Ravichander, Dustin Schwenk, Alane Suhr, Pete Walsh, Dirk Groeneveld, Luca Soldaini, Sameer Singh, Hanna Hajishirzi, Noah&nbsp;A. Smith, and Jesse Dodge. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2310.20707" title="" class="ltx_ref ltx_href">What’s in my big data?</a>

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Faysse et&nbsp;al. (2024)</span>
<span class="ltx_bibblock">
Manuel Faysse, Patrick Fernandes, Nuno Guerreiro, António Loison, Duarte Alves, Caio Corro, Nicolas Boizard, João Alves, Ricardo Rei, Pedro Martins, et&nbsp;al. 2024.

</span>
<span class="ltx_bibblock">Croissantllm: A truly bilingual french-english language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2402.00786</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Faysse et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Manuel Faysse, Gautier Viaud, Céline Hudelot, and Pierre Colombo. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-main.559" title="" class="ltx_ref ltx_href">Revisiting instruction fine-tuned model evaluation to guide industrial applications</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2101.00027" title="" class="ltx_ref ltx_href">The pile: An 800gb dataset of diverse text for language modeling</a>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu and Dao (2023)</span>
<span class="ltx_bibblock">
Albert Gu and Tri Dao. 2023.

</span>
<span class="ltx_bibblock">Mamba: Linear-time sequence modeling with selective state spaces.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.00752</em>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guha et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Neel Guha, Daniel&nbsp;E Ho, Julian Nyarko, and Christopher Ré. 2022.

</span>
<span class="ltx_bibblock">Legalbench: Prototyping a collaborative benchmark for legal reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2209.06120</em>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guha et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Neel Guha, Julian Nyarko, Daniel&nbsp;E Ho, Christopher Ré, Adam Chilton, Aditya Narayana, Alex Chohlas-Wood, Austin Peters, Brandon Waldon, Daniel&nbsp;N Rockmore, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Legalbench: A collaboratively built benchmark for measuring legal reasoning in large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.11462</em>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gururangan et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz&nbsp;Beltagy, Doug Downey, and Noah&nbsp;A Smith. 2020.

</span>
<span class="ltx_bibblock">Don’t stop pretraining: Adapt language models to domains and tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.10964</em>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gutiérrez-Fandiño et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Asier Gutiérrez-Fandiño, Jordi Armengol-Estapé, Aitor Gonzalez-Agirre, and Marta Villegas. 2021.

</span>
<span class="ltx_bibblock">Spanish legalese language model and corpora.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.12201</em>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heafield (2011)</span>
<span class="ltx_bibblock">
Kenneth Heafield. 2011.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/W11-2123" title="" class="ltx_ref ltx_href">KenLM: Faster and smaller language model queries</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Sixth Workshop on Statistical Machine Translation</em>, pages 187–197, Edinburgh, Scotland. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Henderson et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Peter Henderson, Mark Krass, Lucia Zheng, Neel Guha, Christopher&nbsp;D Manning, Dan Jurafsky, and Daniel Ho. 2022.

</span>
<span class="ltx_bibblock">Pile of law: Learning responsible data filtering from the law and a 256gb open-source legal dataset.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 35:29217–29234.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.03300</em>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Islam et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Niful Islam, Debopom Sutradhar, Humaira Noor, Jarin&nbsp;Tasnim Raya, Monowara&nbsp;Tabassum Maisha, and Dewan&nbsp;Md Farid. 2023.

</span>
<span class="ltx_bibblock">Distinguishing human generated text from chatgpt generated text using machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.01761</em>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Shaoxiong Ji, Tianlin Zhang, Kailai Yang, Sophia Ananiadou, Erik Cambria, and Jörg Tiedemann. 2023.

</span>
<span class="ltx_bibblock">Domain-specific continued pretraining of language models for capturing long context in mental health.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.10447</em>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Albert&nbsp;Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio&nbsp;Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven&nbsp;Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William&nbsp;El Sayed. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2310.06825" title="" class="ltx_ref ltx_href">Mistral 7b</a>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2024)</span>
<span class="ltx_bibblock">
Albert&nbsp;Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Emma&nbsp;Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio&nbsp;Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven&nbsp;Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William&nbsp;El Sayed. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2401.04088" title="" class="ltx_ref ltx_href">Mixtral of experts</a>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Katz et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Daniel&nbsp;Martin Katz, Michael&nbsp;James Bommarito, Shang Gao, and Pablo Arredondo. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 passes the bar exam.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Available at SSRN 4389233</em>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocetkov et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Denis Kocetkov, Raymond Li, Loubna&nbsp;Ben allal, Jia LI, Chenghao Mou, Yacine Jernite, Margaret Mitchell, Carlos&nbsp;Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Dzmitry Bahdanau, Leandro&nbsp;Von Werra, and Harm de&nbsp;Vries. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=pxpbTdUEpD" title="" class="ltx_ref ltx_href">The stack: 3 TB of permissively licensed source code</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Transactions on Machine Learning Research</em>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koehn (2005)</span>
<span class="ltx_bibblock">
Philipp Koehn. 2005.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2005.mtsummit-papers.11" title="" class="ltx_ref ltx_href">Europarl: A parallel corpus for statistical machine translation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of Machine Translation Summit X: Papers</em>, pages 79–86, Phuket, Thailand.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and Nicholas Carlini. 2021.

</span>
<span class="ltx_bibblock">Deduplicating training data makes language models better.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.06499</em>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lhoest et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Quentin Lhoest, Albert&nbsp;Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil, Julien Chaumond, Mariama Drame, Julien Plu, Lewis Tunstall, et&nbsp;al. 2021.

</span>
<span class="ltx_bibblock">Datasets: A community library for natural language processing.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.02846</em>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Raymond Li, Loubna&nbsp;Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry&nbsp;Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh&nbsp;Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva&nbsp;Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn&nbsp;Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos&nbsp;Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von
Werra, and Harm de&nbsp;Vries. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2305.06161" title="" class="ltx_ref ltx_href">Starcoder: may the source be with you!</a>

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lian et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Wing Lian, Guan Wang, Bleys Goodson, Eugene Pentland, Austin Cook, Chanvichet Vong, and "Teknium". 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://https://huggingface.co/Open-Orca/SlimOrca" title="" class="ltx_ref ltx_href">Slimorca: An open dataset of gpt-4 augmented flan reasoning traces, with verification</a>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Licari and Comandè (2022)</span>
<span class="ltx_bibblock">
Daniele Licari and Giovanni Comandè. 2022.

</span>
<span class="ltx_bibblock">Italian-legal-bert: A pre-trained transformer language model for italian law.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">CEUR Workshop Proceedings (Ed.), The Knowledge Management for Law Workshop (KM4LAW)</em>.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longpre et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Shayne Longpre, Le&nbsp;Hou, Tu&nbsp;Vu, Albert Webson, Hyung&nbsp;Won Chung, Yi&nbsp;Tay, Denny Zhou, Quoc&nbsp;V Le, Barret Zoph, Jason Wei, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">The flan collection: Designing data and methods for effective instruction tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.13688</em>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Keming Lu, Peter Potash, Xihui Lin, Yuwen Sun, Zihan Qian, Zheng Yuan, Tristan Naumann, Tianxi Cai, and Junwei Lu. 2023.

</span>
<span class="ltx_bibblock">Prompt discriminative language models for domain adaptation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 5th Clinical Natural Language Processing Workshop</em>, pages 247–258.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yingwei Ma, Yue Liu, Yue Yu, Yuanliang Zhang, Yu&nbsp;Jiang, Changjian Wang, and Shanshan Li. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2309.16298" title="" class="ltx_ref ltx_href">At which training stage does code data help llms reasoning?</a>

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martin et&nbsp;al. (2024)</span>
<span class="ltx_bibblock">
Lauren Martin, Nick Whitehouse, Stephanie Yiu, Lizzie Catterson, and Rivindu Perera. 2024.

</span>
<span class="ltx_bibblock">Better call gpt, comparing large language models against lawyers.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.16212</em>.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCloskey and Cohen (1989)</span>
<span class="ltx_bibblock">
Michael McCloskey and Neal&nbsp;J. Cohen. 1989.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/https://doi.org/10.1016/S0079-7421(08)60536-8" title="" class="ltx_ref ltx_href">Catastrophic interference in connectionist networks: The sequential learning problem</a>.

</span>
<span class="ltx_bibblock">volume&nbsp;24 of <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Psychology of Learning and Motivation</em>, pages 109–165. Academic Press.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher&nbsp;D Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock">Detectgpt: Zero-shot machine-generated text detection using probability curvature.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.11305</em>.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mou et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chenghao Mou, Chris Ha, Kenneth Enevoldsen, and Peiyuan Liu. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.5281/zenodo.8364980" title="" class="ltx_ref ltx_href">Chenghaomou/text-dedup: Reference snapshot</a>.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mukherjee et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2306.02707" title="" class="ltx_ref ltx_href">Orca: Progressive learning from complex explanation traces of gpt-4</a>.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Munos et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rémi Munos, Michal Valko, Daniele Calandriello, Mohammad&nbsp;Gheshlaghi Azar, Mark Rowland, Zhaohan&nbsp;Daniel Guo, Yunhao Tang, Matthieu Geist, Thomas Mesnard, Andrea Michi, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Nash learning from human feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.00886</em>.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niklaus et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Joel Niklaus, Ilias Chalkidis, and Matthias Stürmer. 2021.

</span>
<span class="ltx_bibblock">Swiss-judgment-prediction: A multilingual legal judgment prediction benchmark.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.00806</em>.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niklaus and Giofré (2022)</span>
<span class="ltx_bibblock">
Joel Niklaus and Daniele Giofré. 2022.

</span>
<span class="ltx_bibblock">Budgetlongformer: Can we cheaply pretrain a sota legal language model from scratch?

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.17135</em>.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niklaus and Giofré (2023)</span>
<span class="ltx_bibblock">
Joel Niklaus and Daniele Giofré. 2023.

</span>
<span class="ltx_bibblock">Can we pretrain a sota legal language model on a budget from scratch?

</span>
<span class="ltx_bibblock">Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niklaus et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Joel Niklaus, Veton Matoshi, Matthias Stürmer, Ilias Chalkidis, and Daniel&nbsp;E. Ho. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2306.02069" title="" class="ltx_ref ltx_href">Multilegalpile: A 689gb multilingual legal corpus</a>.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nishida et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Kosuke Nishida, Kyosuke Nishida, Itsumi Saito, Hisako Asano, and Junji Tomita. 2019.

</span>
<span class="ltx_bibblock">Unsupervised domain adaptation of language models for reading comprehension.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.10768</em>.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paszke et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et&nbsp;al. 2019.

</span>
<span class="ltx_bibblock">Pytorch: An imperative style, high-performance deep learning library.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 32.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Penedo et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. 2023.

</span>
<span class="ltx_bibblock">The refinedweb dataset for falcon llm: Outperforming curated corpora with web data, and web data only.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.01116</em>.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prakken (2013)</span>
<span class="ltx_bibblock">
Henry Prakken. 2013.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Logical tools for modelling legal argument: a study of defeasible reasoning in law</em>, volume&nbsp;32.

</span>
<span class="ltx_bibblock">Springer Science &amp; Business Media.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Alec Radford, Jong&nbsp;Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2212.04356" title="" class="ltx_ref ltx_href">Robust speech recognition via large-scale weak supervision</a>.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher&nbsp;D Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.18290</em>.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roziere et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing&nbsp;Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Code llama: Open foundation models for code.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.12950</em>.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Savelka et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Jaromir Savelka, Kevin&nbsp;D Ashley, Morgan&nbsp;A Gray, Hannes Westermann, and Huihui Xu. 2023.

</span>
<span class="ltx_bibblock">Explaining legal concepts with augmented large language models (gpt-4).

</span>
<span class="ltx_bibblock"><em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.09525</em>.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scao et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Teven&nbsp;Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra&nbsp;Sasha Luccioni, François Yvon, Matthias Gallé, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Bloom: A 176b-parameter open-access multilingual language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.05100</em>.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhiqiang Shen, Tianhua Tao, Liqun Ma, Willie Neiswanger, Joel Hestness, Natalia Vassilieva, Daria Soboleva, and Eric Xing. 2023.

</span>
<span class="ltx_bibblock">Slimpajama-dc: Understanding data combinations for llm training.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.10818</em>.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shoeybi et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. 2019.

</span>
<span class="ltx_bibblock">Megatron-lm: Training multi-billion parameter language models using model parallelism.

</span>
<span class="ltx_bibblock"><em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.08053</em>.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soboleva et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Daria Soboleva, Faisal Al-Khateeb, Robert Myers, Jacob&nbsp;R Steeves, Joel Hestness, and Nolan Dey. 2023.

</span>
<span class="ltx_bibblock">Slimpajama: A 627b token cleaned and deduplicated version of redpajama.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Jingyuan Sun, Shaonan Wang, Jiajun Zhang, and Chengqing Zong. 2020.

</span>
<span class="ltx_bibblock">Distill and replay for continual language learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th international conference on computational linguistics</em>, pages 3569–3579.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taylor et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic. 2022.

</span>
<span class="ltx_bibblock">Galactica: A large language model for science.

</span>
<span class="ltx_bibblock"><em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.09085</em>.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et&nbsp;al. 2023a.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.13971</em>.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian&nbsp;Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit&nbsp;Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric&nbsp;Michael Smith, Ranjan Subramanian, Xiaoqing&nbsp;Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian&nbsp;Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas
Scialom. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2307.09288" title="" class="ltx_ref ltx_href">Llama 2: Open foundation and fine-tuned chat models</a>.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tuggener et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Don Tuggener, Pius Von&nbsp;Däniken, Thomas Peetz, and Mark Cieliebak. 2020.

</span>
<span class="ltx_bibblock">Ledgar: A large-scale multi-label corpus for text classification of legal provisions in contracts.

</span>
<span class="ltx_bibblock">In <em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Twelfth Language Resources and Evaluation Conference</em>, pages 1235–1241.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tunstall et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Zephyr: Direct distillation of lm alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.16944</em>.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">von Werra et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Leandro von Werra, Younes Belkada, Lewis Tunstall, Edward Beeching, Tristan Thrush, Nathan Lambert, and Shengyi Huang. 2020.

</span>
<span class="ltx_bibblock">Trl: Transformer reinforcement learning.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/huggingface/trl" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/huggingface/trl</a>.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vu et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Thuy-Trang Vu, Dinh Phung, and Gholamreza Haffari. 2020.

</span>
<span class="ltx_bibblock">Effective unsupervised domain adaptation with adversarially trained language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.01739</em>.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi&nbsp;Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah&nbsp;A Smith, Iz&nbsp;Beltagy, et&nbsp;al. 2023a.

</span>
<span class="ltx_bibblock">How far can camels go? exploring the state of instruction tuning on open resources.

</span>
<span class="ltx_bibblock"><em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.04751</em>.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah&nbsp;A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2212.10560" title="" class="ltx_ref ltx_href">Self-instruct: Aligning language models with self-generated instructions</a>.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut&nbsp;Selvan Dhanasekaran, Atharva Naik, David Stap, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.07705</em>.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weber-Wulff et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Debora Weber-Wulff, Alla Anohina-Naumeca, Sonja Bjelobaba, Tomáš Foltỳnek, Jean Guerrero-Dib, Olumide Popoola, Petr Šigut, and Lorna Waddington. 2023.

</span>
<span class="ltx_bibblock">Testing of detection tools for ai-generated text.

</span>
<span class="ltx_bibblock"><em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">International Journal for Educational Integrity</em>, 19(1):26.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent&nbsp;Y Zhao, Kelvin Guu, Adams&nbsp;Wei Yu, Brian Lester, Nan Du, Andrew&nbsp;M Dai, and Quoc&nbsp;V Le. 2021.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.01652</em>.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wolf et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et&nbsp;al. 2019.

</span>
<span class="ltx_bibblock">Huggingface’s transformers: State-of-the-art natural language processing.

</span>
<span class="ltx_bibblock"><em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.03771</em>.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2024)</span>
<span class="ltx_bibblock">
Minghao Wu, Thuy-Trang Vu, Lizhen Qu, George Foster, and Gholamreza Haffari. 2024.

</span>
<span class="ltx_bibblock">Adapting large language models for document-level machine translation.

</span>
<span class="ltx_bibblock"><em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.06468</em>.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Chaojun Xiao, Xueyu Hu, Zhiyuan Liu, Cunchao Tu, and Maosong Sun. 2021.

</span>
<span class="ltx_bibblock">Lawformer: A pre-trained language model for chinese legal long documents.

</span>
<span class="ltx_bibblock"><em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">AI Open</em>, 2:79–84.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Haoran Xu, Young&nbsp;Jin Kim, Amr Sharaf, and Hany&nbsp;Hassan Awadalla. 2023.

</span>
<span class="ltx_bibblock">A paradigm shift in machine translation: Boosting translation performance of large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.11674</em>.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Yunzhi Yao, Shaohan Huang, Wenhui Wang, Li&nbsp;Dong, and Furu Wei. 2021.

</span>
<span class="ltx_bibblock">Adapt-and-distill: Developing small, fast and effective pretrained language models for domains.

</span>
<span class="ltx_bibblock"><em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.13474</em>.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu&nbsp;Zhang, James&nbsp;T Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023.

</span>
<span class="ltx_bibblock">Metamath: Bootstrap your own mathematical questions for large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.12284</em>.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2024)</span>
<span class="ltx_bibblock">
Peiyuan Zhang, Guangtao Zeng, Tianduo Wang, and Wei Lu. 2024.

</span>
<span class="ltx_bibblock">Tinyllama: An open-source small language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.02385</em>.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi&nbsp;Victoria Lin, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Opt: Open pre-trained transformer language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.01068</em>.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.11206</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2403.03881" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2403.03883" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2403.03883">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2403.03883" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2403.03884" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Apr  5 16:15:12 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>