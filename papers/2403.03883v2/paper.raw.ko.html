<html lang="en" data-theme="light"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>SaulLM-7B: A pioneering Large Language Model for Law</title>
<!--Generated on Thu Mar  7 06:39:35 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/addons.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="https://arxiv.org/html/2403.03883v2/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2403.03883v2">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <span class="color-scheme-icon" aria-label="Light mode"></span>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="#myForm" onclick="event.preventDefault(); var modal = document.getElementById('myForm'); modal.style.display = 'block'; bugReportState.setInitiateWay('Header');">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2403.03883v2">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2403.03883v2" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
          <span class="color-scheme-icon"></span>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC mobile collapse" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S1" title="1 Introduction ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S1.SS0.SSS0.Px1" title="Contribution 1: A family of legal LLMs. ‣ 1 Introduction ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Contribution 1: A family of legal LLMs.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S1.SS0.SSS0.Px2" title="Contribution 2: An improved evaluation protocol for legal LLMs. ‣ 1 Introduction ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Contribution 2: An improved evaluation protocol for legal LLMs.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S1.SS0.SSS0.Px3" title="Contribution 3: Model, Evaluation Code &amp; Licensing. ‣ 1 Introduction ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Contribution 3: Model, Evaluation Code &amp; Licensing.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S2" title="2 SaulLM-7B: Extending the legal capabilities of Language Models ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span><span class="ltx_text ltx_font_typewriter">SaulLM-7B</span>: Extending the legal capabilities of Language Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S2.SS1" title="2.1 Enhancing Mistral’s Legal Capabilities ‣ 2 SaulLM-7B: Extending the legal capabilities of Language Models ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Enhancing Mistral’s Legal Capabilities</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S2.SS2" title="2.2 Improving Legal Instruction Following ‣ 2 SaulLM-7B: Extending the legal capabilities of Language Models ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Improving Legal Instruction Following</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3" title="3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Data</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1" title="3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Legal Pretraining Corpora</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS1" title="3.1.1 Dataset Composition ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Dataset Composition</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS1.Px1" title="Legal Sources ‣ 3.1.1 Dataset Composition ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Legal Sources</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS1.Px2" title="Replay Sources ‣ 3.1.1 Dataset Composition ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Replay Sources</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS1.Px3" title="Instruction Sources ‣ 3.1.1 Dataset Composition ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Instruction Sources</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS2" title="3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Data Cleaning</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS2.Px1" title="Text Normalization ‣ 3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Text Normalization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS2.Px2" title="Rule filters ‣ 3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Rule filters</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS2.Px3" title="Perplexity filtering ‣ 3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Perplexity filtering</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS3" title="3.1.3 Data Deduplication ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.3 </span>Data Deduplication</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS2" title="3.2 Instruction Finetuning Mixes ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Instruction Finetuning Mixes</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS2.SSS0.Px1" title="General Instructions ‣ 3.2 Instruction Finetuning Mixes ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">General Instructions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS2.SSS0.Px2" title="Legal Instruction Construction ‣ 3.2 Instruction Finetuning Mixes ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Legal Instruction Construction</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S4" title="4 Evaluation of Legal Knowledge ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Evaluation of Legal Knowledge</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S4.SS0.SSS0.Px1" title="Perplexity Measurement ‣ 4 Evaluation of Legal Knowledge ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Perplexity Measurement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S4.SS0.SSS0.Px2" title="Massive Multitask Language Understanding (MMLU) ‣ 4 Evaluation of Legal Knowledge ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Massive Multitask Language Understanding (MMLU)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S4.SS1" title="4.1 Metrics ‣ 4 Evaluation of Legal Knowledge ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S5" title="5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experimental Setting</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S5.SS1" title="5.1 Baselines ‣ 5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Baselines</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S5.SS2" title="5.2 Implementation Details ‣ 5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Implementation Details</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S5.SS2.SSS0.Px1" title="Codebase ‣ 5.2 Implementation Details ‣ 5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Codebase</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S5.SS2.SSS0.Px2" title="Compute ‣ 5.2 Implementation Details ‣ 5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">Compute</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6" title="6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.SS1" title="6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>LegalBench-Instruct</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.SS1.SSS0.Px1" title="I. Legal continued pretraining brings significant improvements ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">I. Legal continued pretraining brings significant improvements</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.SS1.SSS0.Px2" title="II. Legal instruction finetuning further boosts the results ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">II. Legal instruction finetuning further boosts the results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.SS1.SSS0.Px3" title="III. There is still room for significant improvement. ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title">III. There is still room for significant improvement.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.SS2" title="6.2 Results on Legal-MMLU ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Results on Legal-MMLU</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.SS3" title="6.3 Perplexity Analysis ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Perplexity Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S7" title="7 Conclusion &amp; Future Perspectives ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion &amp; Future Perspectives</span></a></li>
</ol></nav>

<div class="ltx_page_content">
<div aria-label="Conversion errors have been found" class="package-alerts ltx_document" role="status">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewBox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: inconsolata</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><div class="section" id="target-section"><div id="license-tr">License: CC BY 4.0</div><div id="watermark-tr">arXiv:2403.03883v2 [cs.CL] 07 Mar 2024</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">
<span class="ltx_text ltx_font_typewriter" id="id17.id1">SaulLM-7B</span>: A pioneering Large Language Model for Law</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pierre Colombo<math alttext="{}^{1,2,*}" class="ltx_Math" display="inline" id="id1.1.m1.3"><semantics id="id1.1.m1.3a"><msup id="id1.1.m1.3.3" xref="id1.1.m1.3.3.cmml"><mi id="id1.1.m1.3.3a" xref="id1.1.m1.3.3.cmml"></mi><mrow id="id1.1.m1.3.3.3.5" xref="id1.1.m1.3.3.3.4.cmml"><mn id="id1.1.m1.1.1.1.1" xref="id1.1.m1.1.1.1.1.cmml">1</mn><mo id="id1.1.m1.3.3.3.5.1" xref="id1.1.m1.3.3.3.4.cmml">,</mo><mn id="id1.1.m1.2.2.2.2" xref="id1.1.m1.2.2.2.2.cmml">2</mn><mo id="id1.1.m1.3.3.3.5.2" rspace="0em" xref="id1.1.m1.3.3.3.4.cmml">,</mo><mo id="id1.1.m1.3.3.3.3" lspace="0em" xref="id1.1.m1.3.3.3.3.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="id1.1.m1.3b"><apply id="id1.1.m1.3.3.cmml" xref="id1.1.m1.3.3"><list id="id1.1.m1.3.3.3.4.cmml" xref="id1.1.m1.3.3.3.5"><cn id="id1.1.m1.1.1.1.1.cmml" type="integer" xref="id1.1.m1.1.1.1.1">1</cn><cn id="id1.1.m1.2.2.2.2.cmml" type="integer" xref="id1.1.m1.2.2.2.2">2</cn><times id="id1.1.m1.3.3.3.3.cmml" xref="id1.1.m1.3.3.3.3"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.3c">{}^{1,2,*}</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.3d">start_FLOATSUPERSCRIPT 1 , 2 , * end_FLOATSUPERSCRIPT</annotation></semantics></math>  Telmo Pessoa Pires<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="id2.2.m2.2"><semantics id="id2.2.m2.2a"><msup id="id2.2.m2.2.2" xref="id2.2.m2.2.2.cmml"><mi id="id2.2.m2.2.2a" xref="id2.2.m2.2.2.cmml"></mi><mrow id="id2.2.m2.2.2.2.4" xref="id2.2.m2.2.2.2.3.cmml"><mn id="id2.2.m2.1.1.1.1" xref="id2.2.m2.1.1.1.1.cmml">1</mn><mo id="id2.2.m2.2.2.2.4.1" rspace="0em" xref="id2.2.m2.2.2.2.3.cmml">,</mo><mo id="id2.2.m2.2.2.2.2" lspace="0em" xref="id2.2.m2.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="id2.2.m2.2b"><apply id="id2.2.m2.2.2.cmml" xref="id2.2.m2.2.2"><list id="id2.2.m2.2.2.2.3.cmml" xref="id2.2.m2.2.2.2.4"><cn id="id2.2.m2.1.1.1.1.cmml" type="integer" xref="id2.2.m2.1.1.1.1">1</cn><times id="id2.2.m2.2.2.2.2.cmml" xref="id2.2.m2.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math>  Malik Boudiaf<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="id3.3.m3.2"><semantics id="id3.3.m3.2a"><msup id="id3.3.m3.2.2" xref="id3.3.m3.2.2.cmml"><mi id="id3.3.m3.2.2a" xref="id3.3.m3.2.2.cmml"></mi><mrow id="id3.3.m3.2.2.2.4" xref="id3.3.m3.2.2.2.3.cmml"><mn id="id3.3.m3.1.1.1.1" xref="id3.3.m3.1.1.1.1.cmml">1</mn><mo id="id3.3.m3.2.2.2.4.1" rspace="0em" xref="id3.3.m3.2.2.2.3.cmml">,</mo><mo id="id3.3.m3.2.2.2.2" lspace="0em" xref="id3.3.m3.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="id3.3.m3.2b"><apply id="id3.3.m3.2.2.cmml" xref="id3.3.m3.2.2"><list id="id3.3.m3.2.2.2.3.cmml" xref="id3.3.m3.2.2.2.4"><cn id="id3.3.m3.1.1.1.1.cmml" type="integer" xref="id3.3.m3.1.1.1.1">1</cn><times id="id3.3.m3.2.2.2.2.cmml" xref="id3.3.m3.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.3.m3.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="id3.3.m3.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math>
<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="id4.4.1">Dominic Culver<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="id4.4.1.m1.2"><semantics id="id4.4.1.m1.2a"><msup id="id4.4.1.m1.2.2" xref="id4.4.1.m1.2.2.cmml"><mi id="id4.4.1.m1.2.2a" xref="id4.4.1.m1.2.2.cmml"></mi><mrow id="id4.4.1.m1.2.2.2.4" xref="id4.4.1.m1.2.2.2.3.cmml"><mn id="id4.4.1.m1.1.1.1.1" mathvariant="normal" xref="id4.4.1.m1.1.1.1.1.cmml">1</mn><mo id="id4.4.1.m1.2.2.2.4.1" mathvariant="normal" rspace="0em" xref="id4.4.1.m1.2.2.2.3.cmml">,</mo><mo id="id4.4.1.m1.2.2.2.2" lspace="0em" mathvariant="normal" xref="id4.4.1.m1.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="id4.4.1.m1.2b"><apply id="id4.4.1.m1.2.2.cmml" xref="id4.4.1.m1.2.2"><list id="id4.4.1.m1.2.2.2.3.cmml" xref="id4.4.1.m1.2.2.2.4"><cn id="id4.4.1.m1.1.1.1.1.cmml" type="integer" xref="id4.4.1.m1.1.1.1.1">1</cn><times id="id4.4.1.m1.2.2.2.2.cmml" xref="id4.4.1.m1.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="id4.4.1.m1.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="id4.4.1.m1.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id5.5.2">Rui Melo<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="id5.5.2.m1.2"><semantics id="id5.5.2.m1.2a"><msup id="id5.5.2.m1.2.2" xref="id5.5.2.m1.2.2.cmml"><mi id="id5.5.2.m1.2.2a" xref="id5.5.2.m1.2.2.cmml"></mi><mrow id="id5.5.2.m1.2.2.2.4" xref="id5.5.2.m1.2.2.2.3.cmml"><mn id="id5.5.2.m1.1.1.1.1" mathvariant="normal" xref="id5.5.2.m1.1.1.1.1.cmml">1</mn><mo id="id5.5.2.m1.2.2.2.4.1" mathvariant="normal" rspace="0em" xref="id5.5.2.m1.2.2.2.3.cmml">,</mo><mo id="id5.5.2.m1.2.2.2.2" lspace="0em" mathvariant="normal" xref="id5.5.2.m1.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="id5.5.2.m1.2b"><apply id="id5.5.2.m1.2.2.cmml" xref="id5.5.2.m1.2.2"><list id="id5.5.2.m1.2.2.2.3.cmml" xref="id5.5.2.m1.2.2.2.4"><cn id="id5.5.2.m1.1.1.1.1.cmml" type="integer" xref="id5.5.2.m1.1.1.1.1">1</cn><times id="id5.5.2.m1.2.2.2.2.cmml" xref="id5.5.2.m1.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="id5.5.2.m1.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="id5.5.2.m1.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id6.6.3">Caio Corro<math alttext="{}^{3}" class="ltx_Math" display="inline" id="id6.6.3.m1.1"><semantics id="id6.6.3.m1.1a"><msup id="id6.6.3.m1.1.1" xref="id6.6.3.m1.1.1.cmml"><mi id="id6.6.3.m1.1.1a" xref="id6.6.3.m1.1.1.cmml"></mi><mn id="id6.6.3.m1.1.1.1" mathvariant="normal" xref="id6.6.3.m1.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="id6.6.3.m1.1b"><apply id="id6.6.3.m1.1.1.cmml" xref="id6.6.3.m1.1.1"><cn id="id6.6.3.m1.1.1.1.cmml" type="integer" xref="id6.6.3.m1.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id6.6.3.m1.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="id6.6.3.m1.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id7.7.4">André F. T. Martins<math alttext="{}^{4}" class="ltx_Math" display="inline" id="id7.7.4.m1.1"><semantics id="id7.7.4.m1.1a"><msup id="id7.7.4.m1.1.1" xref="id7.7.4.m1.1.1.cmml"><mi id="id7.7.4.m1.1.1a" xref="id7.7.4.m1.1.1.cmml"></mi><mn id="id7.7.4.m1.1.1.1" mathvariant="normal" xref="id7.7.4.m1.1.1.1.cmml">4</mn></msup><annotation-xml encoding="MathML-Content" id="id7.7.4.m1.1b"><apply id="id7.7.4.m1.1.1.cmml" xref="id7.7.4.m1.1.1"><cn id="id7.7.4.m1.1.1.1.cmml" type="integer" xref="id7.7.4.m1.1.1.1">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id7.7.4.m1.1c">{}^{4}</annotation><annotation encoding="application/x-llamapun" id="id7.7.4.m1.1d">start_FLOATSUPERSCRIPT 4 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>
<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="id8.8.5">Fabrizio Esposito<math alttext="{}^{5}" class="ltx_Math" display="inline" id="id8.8.5.m1.1"><semantics id="id8.8.5.m1.1a"><msup id="id8.8.5.m1.1.1" xref="id8.8.5.m1.1.1.cmml"><mi id="id8.8.5.m1.1.1a" xref="id8.8.5.m1.1.1.cmml"></mi><mn id="id8.8.5.m1.1.1.1" mathvariant="normal" xref="id8.8.5.m1.1.1.1.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="id8.8.5.m1.1b"><apply id="id8.8.5.m1.1.1.cmml" xref="id8.8.5.m1.1.1"><cn id="id8.8.5.m1.1.1.1.cmml" type="integer" xref="id8.8.5.m1.1.1.1">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id8.8.5.m1.1c">{}^{5}</annotation><annotation encoding="application/x-llamapun" id="id8.8.5.m1.1d">start_FLOATSUPERSCRIPT 5 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id9.9.6">Vera Lúcia Raposo<math alttext="{}^{5}" class="ltx_Math" display="inline" id="id9.9.6.m1.1"><semantics id="id9.9.6.m1.1a"><msup id="id9.9.6.m1.1.1" xref="id9.9.6.m1.1.1.cmml"><mi id="id9.9.6.m1.1.1a" xref="id9.9.6.m1.1.1.cmml"></mi><mn id="id9.9.6.m1.1.1.1" mathvariant="normal" xref="id9.9.6.m1.1.1.1.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="id9.9.6.m1.1b"><apply id="id9.9.6.m1.1.1.cmml" xref="id9.9.6.m1.1.1"><cn id="id9.9.6.m1.1.1.1.cmml" type="integer" xref="id9.9.6.m1.1.1.1">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id9.9.6.m1.1c">{}^{5}</annotation><annotation encoding="application/x-llamapun" id="id9.9.6.m1.1d">start_FLOATSUPERSCRIPT 5 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id10.10.7">Sofia Morgado<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id10.10.7.m1.1"><semantics id="id10.10.7.m1.1a"><msup id="id10.10.7.m1.1.1" xref="id10.10.7.m1.1.1.cmml"><mi id="id10.10.7.m1.1.1a" xref="id10.10.7.m1.1.1.cmml"></mi><mn id="id10.10.7.m1.1.1.1" mathvariant="normal" xref="id10.10.7.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id10.10.7.m1.1b"><apply id="id10.10.7.m1.1.1.cmml" xref="id10.10.7.m1.1.1"><cn id="id10.10.7.m1.1.1.1.cmml" type="integer" xref="id10.10.7.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id10.10.7.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id10.10.7.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="id11.11.8">Michael Desa<math alttext="{}^{1}" class="ltx_Math" display="inline" id="id11.11.8.m1.1"><semantics id="id11.11.8.m1.1a"><msup id="id11.11.8.m1.1.1" xref="id11.11.8.m1.1.1.cmml"><mi id="id11.11.8.m1.1.1a" xref="id11.11.8.m1.1.1.cmml"></mi><mn id="id11.11.8.m1.1.1.1" mathvariant="normal" xref="id11.11.8.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id11.11.8.m1.1b"><apply id="id11.11.8.m1.1.1.cmml" xref="id11.11.8.m1.1.1"><cn id="id11.11.8.m1.1.1.1.cmml" type="integer" xref="id11.11.8.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id11.11.8.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id11.11.8.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>
<br class="ltx_break"><math alttext="{}^{1}" class="ltx_Math" display="inline" id="id12.12.m4.1"><semantics id="id12.12.m4.1a"><msup id="id12.12.m4.1.1" xref="id12.12.m4.1.1.cmml"><mi id="id12.12.m4.1.1a" xref="id12.12.m4.1.1.cmml"></mi><mn id="id12.12.m4.1.1.1" xref="id12.12.m4.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="id12.12.m4.1b"><apply id="id12.12.m4.1.1.cmml" xref="id12.12.m4.1.1"><cn id="id12.12.m4.1.1.1.cmml" type="integer" xref="id12.12.m4.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id12.12.m4.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="id12.12.m4.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math>Equall.ai, New York, Paris, Lisbon 
<br class="ltx_break"><math alttext="{}^{2}" class="ltx_Math" display="inline" id="id13.13.m5.1"><semantics id="id13.13.m5.1a"><msup id="id13.13.m5.1.1" xref="id13.13.m5.1.1.cmml"><mi id="id13.13.m5.1.1a" xref="id13.13.m5.1.1.cmml"></mi><mn id="id13.13.m5.1.1.1" xref="id13.13.m5.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="id13.13.m5.1b"><apply id="id13.13.m5.1.1.cmml" xref="id13.13.m5.1.1"><cn id="id13.13.m5.1.1.1.cmml" type="integer" xref="id13.13.m5.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id13.13.m5.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="id13.13.m5.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>MICS, CentraleSupélec, Université Paris-Saclay
<br class="ltx_break"><math alttext="{}^{3}" class="ltx_Math" display="inline" id="id14.14.m6.1"><semantics id="id14.14.m6.1a"><msup id="id14.14.m6.1.1" xref="id14.14.m6.1.1.cmml"><mi id="id14.14.m6.1.1a" xref="id14.14.m6.1.1.cmml"></mi><mn id="id14.14.m6.1.1.1" xref="id14.14.m6.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="id14.14.m6.1b"><apply id="id14.14.m6.1.1.cmml" xref="id14.14.m6.1.1"><cn id="id14.14.m6.1.1.1.cmml" type="integer" xref="id14.14.m6.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id14.14.m6.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="id14.14.m6.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math>Sorbonne Université, CNRS, ISIR, Paris
<br class="ltx_break"><math alttext="{}^{4}" class="ltx_Math" display="inline" id="id15.15.m7.1"><semantics id="id15.15.m7.1a"><msup id="id15.15.m7.1.1" xref="id15.15.m7.1.1.cmml"><mi id="id15.15.m7.1.1a" xref="id15.15.m7.1.1.cmml"></mi><mn id="id15.15.m7.1.1.1" xref="id15.15.m7.1.1.1.cmml">4</mn></msup><annotation-xml encoding="MathML-Content" id="id15.15.m7.1b"><apply id="id15.15.m7.1.1.cmml" xref="id15.15.m7.1.1"><cn id="id15.15.m7.1.1.1.cmml" type="integer" xref="id15.15.m7.1.1.1">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id15.15.m7.1c">{}^{4}</annotation><annotation encoding="application/x-llamapun" id="id15.15.m7.1d">start_FLOATSUPERSCRIPT 4 end_FLOATSUPERSCRIPT</annotation></semantics></math>Instituto Superior Técnico, Universidade de Lisboa
<br class="ltx_break"><math alttext="{}^{5}" class="ltx_Math" display="inline" id="id16.16.m8.1"><semantics id="id16.16.m8.1a"><msup id="id16.16.m8.1.1" xref="id16.16.m8.1.1.cmml"><mi id="id16.16.m8.1.1a" xref="id16.16.m8.1.1.cmml"></mi><mn id="id16.16.m8.1.1.1" xref="id16.16.m8.1.1.1.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="id16.16.m8.1b"><apply id="id16.16.m8.1.1.cmml" xref="id16.16.m8.1.1"><cn id="id16.16.m8.1.1.1.cmml" type="integer" xref="id16.16.m8.1.1.1">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id16.16.m8.1c">{}^{5}</annotation><annotation encoding="application/x-llamapun" id="id16.16.m8.1d">start_FLOATSUPERSCRIPT 5 end_FLOATSUPERSCRIPT</annotation></semantics></math> NOVA School of Law, Lisboa 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id18.17.id1">firstname@equall.ai</span>
</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id19.id1">본 논문에서는 법률 도메인에 맞는 대용량 언어 모델(LLM)인 <span class="ltx_text ltx_font_typewriter" id="id19.id1.1">SaulLM-7B</span>을 소개한다. 70억 개의 매개 변수를 사용하여 <span class="ltx_text ltx_font_typewriter" id="id19.id1.2">SaulLM-7B</span>은 법률 텍스트 이해 및 생성을 위해 명시적으로 설계된 최초의 LLM입니다. Mistral 7B 아키텍처를 기반으로 하는 <span class="ltx_text ltx_font_typewriter" id="id19.id1.3">SaulLM-7B</span>은 300억 개 이상의 토큰의 영국 법률 코퍼스에서 훈련됩니다. <span class="ltx_text ltx_font_typewriter" id="id19.id1.4">SaulLM-7B</span>은 법률 문서의 이해와 처리에 대한 최신 기술을 보여줍니다. 또한 법률 데이터 세트를 활용하여 법률 작업에서 <span class="ltx_text ltx_font_typewriter" id="id19.id1.5">SaulLM-7B</span>의 성능을 더욱 향상시키는 새로운 지침 미세 조정 방법을 제시한다. <span class="ltx_text ltx_font_typewriter" id="id19.id1.6">SaulLM-7B</span> is released under the MIT License.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<p class="ltx_p ltx_align_center ltx_align_bottom" id="p1.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.1">SaulLM-7B</span><span class="ltx_text ltx_font_bold" id="p1.1.2">: A pioneering Large Language Model for Law</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="p2">
<br class="ltx_break">
<p class="ltx_p" id="p2.16"><span class="ltx_text" id="p2.16.16" style="width:433.6pt;"><span class="ltx_text" id="p2.16.16.16" style="width:0.0pt;"> <span class="ltx_tabular ltx_align_top" id="p2.16.16.16.16"> <span class="ltx_tbody"> <span class="ltx_tr" id="p2.3.3.3.3.3"> <span class="ltx_td ltx_align_center" id="p2.3.3.3.3.3.3"><span class="ltx_text ltx_font_bold" id="p2.3.3.3.3.3.3.3">Pierre Colombo<math alttext="{}^{1,2,*}" class="ltx_Math" display="inline" id="p2.1.1.1.1.1.1.1.m1.3"><semantics id="p2.1.1.1.1.1.1.1.m1.3a"><msup id="p2.1.1.1.1.1.1.1.m1.3.3" xref="p2.1.1.1.1.1.1.1.m1.3.3.cmml"><mi id="p2.1.1.1.1.1.1.1.m1.3.3a" xref="p2.1.1.1.1.1.1.1.m1.3.3.cmml"></mi><mrow id="p2.1.1.1.1.1.1.1.m1.3.3.3.5" xref="p2.1.1.1.1.1.1.1.m1.3.3.3.4.cmml"><mn id="p2.1.1.1.1.1.1.1.m1.1.1.1.1" mathvariant="normal" xref="p2.1.1.1.1.1.1.1.m1.1.1.1.1.cmml">1</mn><mo id="p2.1.1.1.1.1.1.1.m1.3.3.3.5.1" mathvariant="normal" xref="p2.1.1.1.1.1.1.1.m1.3.3.3.4.cmml">,</mo><mn id="p2.1.1.1.1.1.1.1.m1.2.2.2.2" mathvariant="normal" xref="p2.1.1.1.1.1.1.1.m1.2.2.2.2.cmml">2</mn><mo id="p2.1.1.1.1.1.1.1.m1.3.3.3.5.2" mathvariant="normal" rspace="0em" xref="p2.1.1.1.1.1.1.1.m1.3.3.3.4.cmml">,</mo><mo id="p2.1.1.1.1.1.1.1.m1.3.3.3.3" lspace="0em" mathvariant="normal" xref="p2.1.1.1.1.1.1.1.m1.3.3.3.3.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p2.1.1.1.1.1.1.1.m1.3b"><apply id="p2.1.1.1.1.1.1.1.m1.3.3.cmml" xref="p2.1.1.1.1.1.1.1.m1.3.3"><list id="p2.1.1.1.1.1.1.1.m1.3.3.3.4.cmml" xref="p2.1.1.1.1.1.1.1.m1.3.3.3.5"><cn id="p2.1.1.1.1.1.1.1.m1.1.1.1.1.cmml" type="integer" xref="p2.1.1.1.1.1.1.1.m1.1.1.1.1">1</cn><cn id="p2.1.1.1.1.1.1.1.m1.2.2.2.2.cmml" type="integer" xref="p2.1.1.1.1.1.1.1.m1.2.2.2.2">2</cn><times id="p2.1.1.1.1.1.1.1.m1.3.3.3.3.cmml" xref="p2.1.1.1.1.1.1.1.m1.3.3.3.3"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.1.1.1.1.1.1.1.m1.3c">{}^{1,2,*}</annotation><annotation encoding="application/x-llamapun" id="p2.1.1.1.1.1.1.1.m1.3d">start_FLOATSUPERSCRIPT 1 , 2 , * end_FLOATSUPERSCRIPT</annotation></semantics></math>  Telmo Pessoa Pires<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="p2.2.2.2.2.2.2.2.m2.2"><semantics id="p2.2.2.2.2.2.2.2.m2.2a"><msup id="p2.2.2.2.2.2.2.2.m2.2.2" xref="p2.2.2.2.2.2.2.2.m2.2.2.cmml"><mi id="p2.2.2.2.2.2.2.2.m2.2.2a" xref="p2.2.2.2.2.2.2.2.m2.2.2.cmml"></mi><mrow id="p2.2.2.2.2.2.2.2.m2.2.2.2.4" xref="p2.2.2.2.2.2.2.2.m2.2.2.2.3.cmml"><mn id="p2.2.2.2.2.2.2.2.m2.1.1.1.1" mathvariant="normal" xref="p2.2.2.2.2.2.2.2.m2.1.1.1.1.cmml">1</mn><mo id="p2.2.2.2.2.2.2.2.m2.2.2.2.4.1" mathvariant="normal" rspace="0em" xref="p2.2.2.2.2.2.2.2.m2.2.2.2.3.cmml">,</mo><mo id="p2.2.2.2.2.2.2.2.m2.2.2.2.2" lspace="0em" mathvariant="normal" xref="p2.2.2.2.2.2.2.2.m2.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p2.2.2.2.2.2.2.2.m2.2b"><apply id="p2.2.2.2.2.2.2.2.m2.2.2.cmml" xref="p2.2.2.2.2.2.2.2.m2.2.2"><list id="p2.2.2.2.2.2.2.2.m2.2.2.2.3.cmml" xref="p2.2.2.2.2.2.2.2.m2.2.2.2.4"><cn id="p2.2.2.2.2.2.2.2.m2.1.1.1.1.cmml" type="integer" xref="p2.2.2.2.2.2.2.2.m2.1.1.1.1">1</cn><times id="p2.2.2.2.2.2.2.2.m2.2.2.2.2.cmml" xref="p2.2.2.2.2.2.2.2.m2.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.2.2.2.2.2.2.2.m2.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="p2.2.2.2.2.2.2.2.m2.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math>  Malik Boudiaf<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="p2.3.3.3.3.3.3.3.m3.2"><semantics id="p2.3.3.3.3.3.3.3.m3.2a"><msup id="p2.3.3.3.3.3.3.3.m3.2.2" xref="p2.3.3.3.3.3.3.3.m3.2.2.cmml"><mi id="p2.3.3.3.3.3.3.3.m3.2.2a" xref="p2.3.3.3.3.3.3.3.m3.2.2.cmml"></mi><mrow id="p2.3.3.3.3.3.3.3.m3.2.2.2.4" xref="p2.3.3.3.3.3.3.3.m3.2.2.2.3.cmml"><mn id="p2.3.3.3.3.3.3.3.m3.1.1.1.1" mathvariant="normal" xref="p2.3.3.3.3.3.3.3.m3.1.1.1.1.cmml">1</mn><mo id="p2.3.3.3.3.3.3.3.m3.2.2.2.4.1" mathvariant="normal" rspace="0em" xref="p2.3.3.3.3.3.3.3.m3.2.2.2.3.cmml">,</mo><mo id="p2.3.3.3.3.3.3.3.m3.2.2.2.2" lspace="0em" mathvariant="normal" xref="p2.3.3.3.3.3.3.3.m3.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p2.3.3.3.3.3.3.3.m3.2b"><apply id="p2.3.3.3.3.3.3.3.m3.2.2.cmml" xref="p2.3.3.3.3.3.3.3.m3.2.2"><list id="p2.3.3.3.3.3.3.3.m3.2.2.2.3.cmml" xref="p2.3.3.3.3.3.3.3.m3.2.2.2.4"><cn id="p2.3.3.3.3.3.3.3.m3.1.1.1.1.cmml" type="integer" xref="p2.3.3.3.3.3.3.3.m3.1.1.1.1">1</cn><times id="p2.3.3.3.3.3.3.3.m3.2.2.2.2.cmml" xref="p2.3.3.3.3.3.3.3.m3.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.3.3.3.3.3.3.3.m3.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="p2.3.3.3.3.3.3.3.m3.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span></span> <span class="ltx_tr" id="p2.7.7.7.7.7"> <span class="ltx_td ltx_align_center" id="p2.7.7.7.7.7.4"><span class="ltx_text ltx_font_bold" id="p2.4.4.4.4.4.1.1">Dominic Culver<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="p2.4.4.4.4.4.1.1.m1.2"><semantics id="p2.4.4.4.4.4.1.1.m1.2a"><msup id="p2.4.4.4.4.4.1.1.m1.2.2" xref="p2.4.4.4.4.4.1.1.m1.2.2.cmml"><mi id="p2.4.4.4.4.4.1.1.m1.2.2a" xref="p2.4.4.4.4.4.1.1.m1.2.2.cmml"></mi><mrow id="p2.4.4.4.4.4.1.1.m1.2.2.2.4" xref="p2.4.4.4.4.4.1.1.m1.2.2.2.3.cmml"><mn id="p2.4.4.4.4.4.1.1.m1.1.1.1.1" mathvariant="normal" xref="p2.4.4.4.4.4.1.1.m1.1.1.1.1.cmml">1</mn><mo id="p2.4.4.4.4.4.1.1.m1.2.2.2.4.1" mathvariant="normal" rspace="0em" xref="p2.4.4.4.4.4.1.1.m1.2.2.2.3.cmml">,</mo><mo id="p2.4.4.4.4.4.1.1.m1.2.2.2.2" lspace="0em" mathvariant="normal" xref="p2.4.4.4.4.4.1.1.m1.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p2.4.4.4.4.4.1.1.m1.2b"><apply id="p2.4.4.4.4.4.1.1.m1.2.2.cmml" xref="p2.4.4.4.4.4.1.1.m1.2.2"><list id="p2.4.4.4.4.4.1.1.m1.2.2.2.3.cmml" xref="p2.4.4.4.4.4.1.1.m1.2.2.2.4"><cn id="p2.4.4.4.4.4.1.1.m1.1.1.1.1.cmml" type="integer" xref="p2.4.4.4.4.4.1.1.m1.1.1.1.1">1</cn><times id="p2.4.4.4.4.4.1.1.m1.2.2.2.2.cmml" xref="p2.4.4.4.4.4.1.1.m1.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.4.4.4.4.4.1.1.m1.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="p2.4.4.4.4.4.1.1.m1.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="p2.5.5.5.5.5.2.2">Rui Melo<math alttext="{}^{1,*}" class="ltx_Math" display="inline" id="p2.5.5.5.5.5.2.2.m1.2"><semantics id="p2.5.5.5.5.5.2.2.m1.2a"><msup id="p2.5.5.5.5.5.2.2.m1.2.2" xref="p2.5.5.5.5.5.2.2.m1.2.2.cmml"><mi id="p2.5.5.5.5.5.2.2.m1.2.2a" xref="p2.5.5.5.5.5.2.2.m1.2.2.cmml"></mi><mrow id="p2.5.5.5.5.5.2.2.m1.2.2.2.4" xref="p2.5.5.5.5.5.2.2.m1.2.2.2.3.cmml"><mn id="p2.5.5.5.5.5.2.2.m1.1.1.1.1" mathvariant="normal" xref="p2.5.5.5.5.5.2.2.m1.1.1.1.1.cmml">1</mn><mo id="p2.5.5.5.5.5.2.2.m1.2.2.2.4.1" mathvariant="normal" rspace="0em" xref="p2.5.5.5.5.5.2.2.m1.2.2.2.3.cmml">,</mo><mo id="p2.5.5.5.5.5.2.2.m1.2.2.2.2" lspace="0em" mathvariant="normal" xref="p2.5.5.5.5.5.2.2.m1.2.2.2.2.cmml">*</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p2.5.5.5.5.5.2.2.m1.2b"><apply id="p2.5.5.5.5.5.2.2.m1.2.2.cmml" xref="p2.5.5.5.5.5.2.2.m1.2.2"><list id="p2.5.5.5.5.5.2.2.m1.2.2.2.3.cmml" xref="p2.5.5.5.5.5.2.2.m1.2.2.2.4"><cn id="p2.5.5.5.5.5.2.2.m1.1.1.1.1.cmml" type="integer" xref="p2.5.5.5.5.5.2.2.m1.1.1.1.1">1</cn><times id="p2.5.5.5.5.5.2.2.m1.2.2.2.2.cmml" xref="p2.5.5.5.5.5.2.2.m1.2.2.2.2"></times></list></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.5.5.5.5.5.2.2.m1.2c">{}^{1,*}</annotation><annotation encoding="application/x-llamapun" id="p2.5.5.5.5.5.2.2.m1.2d">start_FLOATSUPERSCRIPT 1 , * end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="p2.6.6.6.6.6.3.3">Caio Corro<math alttext="{}^{3}" class="ltx_Math" display="inline" id="p2.6.6.6.6.6.3.3.m1.1"><semantics id="p2.6.6.6.6.6.3.3.m1.1a"><msup id="p2.6.6.6.6.6.3.3.m1.1.1" xref="p2.6.6.6.6.6.3.3.m1.1.1.cmml"><mi id="p2.6.6.6.6.6.3.3.m1.1.1a" xref="p2.6.6.6.6.6.3.3.m1.1.1.cmml"></mi><mn id="p2.6.6.6.6.6.3.3.m1.1.1.1" mathvariant="normal" xref="p2.6.6.6.6.6.3.3.m1.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="p2.6.6.6.6.6.3.3.m1.1b"><apply id="p2.6.6.6.6.6.3.3.m1.1.1.cmml" xref="p2.6.6.6.6.6.3.3.m1.1.1"><cn id="p2.6.6.6.6.6.3.3.m1.1.1.1.cmml" type="integer" xref="p2.6.6.6.6.6.3.3.m1.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.6.6.6.6.6.3.3.m1.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="p2.6.6.6.6.6.3.3.m1.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="p2.7.7.7.7.7.4.4">André F. T. Martins<math alttext="{}^{4}" class="ltx_Math" display="inline" id="p2.7.7.7.7.7.4.4.m1.1"><semantics id="p2.7.7.7.7.7.4.4.m1.1a"><msup id="p2.7.7.7.7.7.4.4.m1.1.1" xref="p2.7.7.7.7.7.4.4.m1.1.1.cmml"><mi id="p2.7.7.7.7.7.4.4.m1.1.1a" xref="p2.7.7.7.7.7.4.4.m1.1.1.cmml"></mi><mn id="p2.7.7.7.7.7.4.4.m1.1.1.1" mathvariant="normal" xref="p2.7.7.7.7.7.4.4.m1.1.1.1.cmml">4</mn></msup><annotation-xml encoding="MathML-Content" id="p2.7.7.7.7.7.4.4.m1.1b"><apply id="p2.7.7.7.7.7.4.4.m1.1.1.cmml" xref="p2.7.7.7.7.7.4.4.m1.1.1"><cn id="p2.7.7.7.7.7.4.4.m1.1.1.1.cmml" type="integer" xref="p2.7.7.7.7.7.4.4.m1.1.1.1">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.7.7.7.7.7.4.4.m1.1c">{}^{4}</annotation><annotation encoding="application/x-llamapun" id="p2.7.7.7.7.7.4.4.m1.1d">start_FLOATSUPERSCRIPT 4 end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span></span> <span class="ltx_tr" id="p2.11.11.11.11.11"> <span class="ltx_td ltx_align_center" id="p2.11.11.11.11.11.4"><span class="ltx_text ltx_font_bold" id="p2.8.8.8.8.8.1.1">Fabrizio Esposito<math alttext="{}^{5}" class="ltx_Math" display="inline" id="p2.8.8.8.8.8.1.1.m1.1"><semantics id="p2.8.8.8.8.8.1.1.m1.1a"><msup id="p2.8.8.8.8.8.1.1.m1.1.1" xref="p2.8.8.8.8.8.1.1.m1.1.1.cmml"><mi id="p2.8.8.8.8.8.1.1.m1.1.1a" xref="p2.8.8.8.8.8.1.1.m1.1.1.cmml"></mi><mn id="p2.8.8.8.8.8.1.1.m1.1.1.1" mathvariant="normal" xref="p2.8.8.8.8.8.1.1.m1.1.1.1.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="p2.8.8.8.8.8.1.1.m1.1b"><apply id="p2.8.8.8.8.8.1.1.m1.1.1.cmml" xref="p2.8.8.8.8.8.1.1.m1.1.1"><cn id="p2.8.8.8.8.8.1.1.m1.1.1.1.cmml" type="integer" xref="p2.8.8.8.8.8.1.1.m1.1.1.1">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.8.8.8.8.8.1.1.m1.1c">{}^{5}</annotation><annotation encoding="application/x-llamapun" id="p2.8.8.8.8.8.1.1.m1.1d">start_FLOATSUPERSCRIPT 5 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="p2.9.9.9.9.9.2.2">Vera Lúcia Raposo<math alttext="{}^{5}" class="ltx_Math" display="inline" id="p2.9.9.9.9.9.2.2.m1.1"><semantics id="p2.9.9.9.9.9.2.2.m1.1a"><msup id="p2.9.9.9.9.9.2.2.m1.1.1" xref="p2.9.9.9.9.9.2.2.m1.1.1.cmml"><mi id="p2.9.9.9.9.9.2.2.m1.1.1a" xref="p2.9.9.9.9.9.2.2.m1.1.1.cmml"></mi><mn id="p2.9.9.9.9.9.2.2.m1.1.1.1" mathvariant="normal" xref="p2.9.9.9.9.9.2.2.m1.1.1.1.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="p2.9.9.9.9.9.2.2.m1.1b"><apply id="p2.9.9.9.9.9.2.2.m1.1.1.cmml" xref="p2.9.9.9.9.9.2.2.m1.1.1"><cn id="p2.9.9.9.9.9.2.2.m1.1.1.1.cmml" type="integer" xref="p2.9.9.9.9.9.2.2.m1.1.1.1">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.9.9.9.9.9.2.2.m1.1c">{}^{5}</annotation><annotation encoding="application/x-llamapun" id="p2.9.9.9.9.9.2.2.m1.1d">start_FLOATSUPERSCRIPT 5 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="p2.10.10.10.10.10.3.3">Sofia Morgado<math alttext="{}^{1}" class="ltx_Math" display="inline" id="p2.10.10.10.10.10.3.3.m1.1"><semantics id="p2.10.10.10.10.10.3.3.m1.1a"><msup id="p2.10.10.10.10.10.3.3.m1.1.1" xref="p2.10.10.10.10.10.3.3.m1.1.1.cmml"><mi id="p2.10.10.10.10.10.3.3.m1.1.1a" xref="p2.10.10.10.10.10.3.3.m1.1.1.cmml"></mi><mn id="p2.10.10.10.10.10.3.3.m1.1.1.1" mathvariant="normal" xref="p2.10.10.10.10.10.3.3.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="p2.10.10.10.10.10.3.3.m1.1b"><apply id="p2.10.10.10.10.10.3.3.m1.1.1.cmml" xref="p2.10.10.10.10.10.3.3.m1.1.1"><cn id="p2.10.10.10.10.10.3.3.m1.1.1.1.cmml" type="integer" xref="p2.10.10.10.10.10.3.3.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.10.10.10.10.10.3.3.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="p2.10.10.10.10.10.3.3.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math></span>  <span class="ltx_text ltx_font_bold" id="p2.11.11.11.11.11.4.4">Michael Desa<math alttext="{}^{1}" class="ltx_Math" display="inline" id="p2.11.11.11.11.11.4.4.m1.1"><semantics id="p2.11.11.11.11.11.4.4.m1.1a"><msup id="p2.11.11.11.11.11.4.4.m1.1.1" xref="p2.11.11.11.11.11.4.4.m1.1.1.cmml"><mi id="p2.11.11.11.11.11.4.4.m1.1.1a" xref="p2.11.11.11.11.11.4.4.m1.1.1.cmml"></mi><mn id="p2.11.11.11.11.11.4.4.m1.1.1.1" mathvariant="normal" xref="p2.11.11.11.11.11.4.4.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="p2.11.11.11.11.11.4.4.m1.1b"><apply id="p2.11.11.11.11.11.4.4.m1.1.1.cmml" xref="p2.11.11.11.11.11.4.4.m1.1.1"><cn id="p2.11.11.11.11.11.4.4.m1.1.1.1.cmml" type="integer" xref="p2.11.11.11.11.11.4.4.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.11.11.11.11.11.4.4.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="p2.11.11.11.11.11.4.4.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span></span> <span class="ltx_tr" id="p2.12.12.12.12.12"> <span class="ltx_td ltx_align_center" id="p2.12.12.12.12.12.1"><math alttext="{}^{1}" class="ltx_Math" display="inline" id="p2.12.12.12.12.12.1.m1.1"><semantics id="p2.12.12.12.12.12.1.m1.1a"><msup id="p2.12.12.12.12.12.1.m1.1.1" xref="p2.12.12.12.12.12.1.m1.1.1.cmml"><mi id="p2.12.12.12.12.12.1.m1.1.1a" xref="p2.12.12.12.12.12.1.m1.1.1.cmml"></mi><mn id="p2.12.12.12.12.12.1.m1.1.1.1" xref="p2.12.12.12.12.12.1.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="p2.12.12.12.12.12.1.m1.1b"><apply id="p2.12.12.12.12.12.1.m1.1.1.cmml" xref="p2.12.12.12.12.12.1.m1.1.1"><cn id="p2.12.12.12.12.12.1.m1.1.1.1.cmml" type="integer" xref="p2.12.12.12.12.12.1.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.12.12.12.12.12.1.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="p2.12.12.12.12.12.1.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math>Equall.ai, New York, Paris, Lisbon</span></span> <span class="ltx_tr" id="p2.13.13.13.13.13"> <span class="ltx_td ltx_align_center" id="p2.13.13.13.13.13.1"><math alttext="{}^{2}" class="ltx_Math" display="inline" id="p2.13.13.13.13.13.1.m1.1"><semantics id="p2.13.13.13.13.13.1.m1.1a"><msup id="p2.13.13.13.13.13.1.m1.1.1" xref="p2.13.13.13.13.13.1.m1.1.1.cmml"><mi id="p2.13.13.13.13.13.1.m1.1.1a" xref="p2.13.13.13.13.13.1.m1.1.1.cmml"></mi><mn id="p2.13.13.13.13.13.1.m1.1.1.1" xref="p2.13.13.13.13.13.1.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p2.13.13.13.13.13.1.m1.1b"><apply id="p2.13.13.13.13.13.1.m1.1.1.cmml" xref="p2.13.13.13.13.13.1.m1.1.1"><cn id="p2.13.13.13.13.13.1.m1.1.1.1.cmml" type="integer" xref="p2.13.13.13.13.13.1.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.13.13.13.13.13.1.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p2.13.13.13.13.13.1.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>MICS, CentraleSupélec, Université Paris-Saclay</span></span> <span class="ltx_tr" id="p2.14.14.14.14.14"> <span class="ltx_td ltx_align_center" id="p2.14.14.14.14.14.1"><math alttext="{}^{3}" class="ltx_Math" display="inline" id="p2.14.14.14.14.14.1.m1.1"><semantics id="p2.14.14.14.14.14.1.m1.1a"><msup id="p2.14.14.14.14.14.1.m1.1.1" xref="p2.14.14.14.14.14.1.m1.1.1.cmml"><mi id="p2.14.14.14.14.14.1.m1.1.1a" xref="p2.14.14.14.14.14.1.m1.1.1.cmml"></mi><mn id="p2.14.14.14.14.14.1.m1.1.1.1" xref="p2.14.14.14.14.14.1.m1.1.1.1.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="p2.14.14.14.14.14.1.m1.1b"><apply id="p2.14.14.14.14.14.1.m1.1.1.cmml" xref="p2.14.14.14.14.14.1.m1.1.1"><cn id="p2.14.14.14.14.14.1.m1.1.1.1.cmml" type="integer" xref="p2.14.14.14.14.14.1.m1.1.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.14.14.14.14.14.1.m1.1c">{}^{3}</annotation><annotation encoding="application/x-llamapun" id="p2.14.14.14.14.14.1.m1.1d">start_FLOATSUPERSCRIPT 3 end_FLOATSUPERSCRIPT</annotation></semantics></math>Sorbonne Université, CNRS, ISIR, Paris</span></span> <span class="ltx_tr" id="p2.15.15.15.15.15"> <span class="ltx_td ltx_align_center" id="p2.15.15.15.15.15.1"><math alttext="{}^{4}" class="ltx_Math" display="inline" id="p2.15.15.15.15.15.1.m1.1"><semantics id="p2.15.15.15.15.15.1.m1.1a"><msup id="p2.15.15.15.15.15.1.m1.1.1" xref="p2.15.15.15.15.15.1.m1.1.1.cmml"><mi id="p2.15.15.15.15.15.1.m1.1.1a" xref="p2.15.15.15.15.15.1.m1.1.1.cmml"></mi><mn id="p2.15.15.15.15.15.1.m1.1.1.1" xref="p2.15.15.15.15.15.1.m1.1.1.1.cmml">4</mn></msup><annotation-xml encoding="MathML-Content" id="p2.15.15.15.15.15.1.m1.1b"><apply id="p2.15.15.15.15.15.1.m1.1.1.cmml" xref="p2.15.15.15.15.15.1.m1.1.1"><cn id="p2.15.15.15.15.15.1.m1.1.1.1.cmml" type="integer" xref="p2.15.15.15.15.15.1.m1.1.1.1">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.15.15.15.15.15.1.m1.1c">{}^{4}</annotation><annotation encoding="application/x-llamapun" id="p2.15.15.15.15.15.1.m1.1d">start_FLOATSUPERSCRIPT 4 end_FLOATSUPERSCRIPT</annotation></semantics></math>Instituto Superior Técnico, Universidade de Lisboa</span></span> <span class="ltx_tr" id="p2.16.16.16.16.16"> <span class="ltx_td ltx_align_center" id="p2.16.16.16.16.16.1"><math alttext="{}^{5}" class="ltx_Math" display="inline" id="p2.16.16.16.16.16.1.m1.1"><semantics id="p2.16.16.16.16.16.1.m1.1a"><msup id="p2.16.16.16.16.16.1.m1.1.1" xref="p2.16.16.16.16.16.1.m1.1.1.cmml"><mi id="p2.16.16.16.16.16.1.m1.1.1a" xref="p2.16.16.16.16.16.1.m1.1.1.cmml"></mi><mn id="p2.16.16.16.16.16.1.m1.1.1.1" xref="p2.16.16.16.16.16.1.m1.1.1.1.cmml">5</mn></msup><annotation-xml encoding="MathML-Content" id="p2.16.16.16.16.16.1.m1.1b"><apply id="p2.16.16.16.16.16.1.m1.1.1.cmml" xref="p2.16.16.16.16.16.1.m1.1.1"><cn id="p2.16.16.16.16.16.1.m1.1.1.1.cmml" type="integer" xref="p2.16.16.16.16.16.1.m1.1.1.1">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p2.16.16.16.16.16.1.m1.1c">{}^{5}</annotation><annotation encoding="application/x-llamapun" id="p2.16.16.16.16.16.1.m1.1d">start_FLOATSUPERSCRIPT 5 end_FLOATSUPERSCRIPT</annotation></semantics></math> NOVA School of Law, Lisboa</span></span> <span class="ltx_tr" id="p2.16.16.16.16.17.1"> <span class="ltx_td ltx_align_center" id="p2.16.16.16.16.17.1.1"><span class="ltx_text ltx_font_typewriter" id="p2.16.16.16.16.17.1.1.1">firstname@equall.ai</span></span></span> </span> </span></span> </span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">*</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">*</sup><span class="ltx_note_type">footnotetext: </span>Equal contribution.</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">인공지능의 빠르게 진화하는 풍경에서, 대형 언어 모델(LLMs) <cite class="ltx_cite ltx_citemacro_cite">Achiam et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib1" title="">2023</a>); Scao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib65" title="">2022</a>); Penedo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib59" title="">2023</a>); Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib71" title="">2023a</a>); Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib34" title="">2023</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib35" title="">2024</a>); Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib72" title="">2023b</a>); Bai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib5" title="">2023</a>)</cite>의 애플리케이션은 <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">e.g.</span>>번역 <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib85" title="">2023</a>)</cite>, 의료용 <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib12" title="">2023</a>)</cite>, 코드 생성 <cite class="ltx_cite ltx_citemacro_cite">Roziere et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib63" title="">2023</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib41" title="">2023</a>)</cite>와 같이 다양한 도메인에 걸쳐 큰 발전을 목격했다. 자연어 처리부터 기계 번역까지 이 모델들은 인간과 같은 텍스트 <cite class="ltx_cite ltx_citemacro_cite">Weber-Wulff et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib80" title="">2023</a>); Islam et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib32" title="">2023</a>); Mitchell et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib49" title="">2023</a>)</cite>를 이해하고 생성하는 데 탁월한 능력을 발휘했다. 그러나 이 변형 기술의 완전한 이점을 아직 경험하지 못한 한 분야는 법적 영역 <cite class="ltx_cite ltx_citemacro_cite">Martin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib47" title="">2024</a>); Licari and Comandè (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib43" title="">2022</a>)</cite>이다. 법조인들이 점점 더 확장되는 복잡한 문서의 양과 씨름하면서, 법률 자료 <cite class="ltx_cite ltx_citemacro_cite">Savelka et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib64" title="">2023</a>); Katz et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib36" title="">2023</a>); Xiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib84" title="">2021</a>)</cite>를 탐색하고 해석하는 데 도움을 줄 수 있는 전용 LLM에 대한 필요성이 커지고 있다.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">이 논문에서 우리는 공개적으로 이용 가능한 최초의 법적 LLM을 개발하기 위한 선구적인 이니셔티브를 제시한다. 독특한 구문 및 전문 어휘로 특징지어지는 법률 텍스트는 뚜렷한 언어적 도전 <cite class="ltx_cite ltx_citemacro_cite">Chalkidis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib11" title="">2020</a>); Niklaus et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib53" title="">2021</a>)</cite>를 제시한다. 우리의 접근법은 미국, 캐나다, 영국 및 유럽과 같은 영어권 관할 구역에서 전용 법률 코퍼스를 사용하여 광범위한 사전 훈련 <cite class="ltx_cite ltx_citemacro_cite">Gururangan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib27" title="">2020</a>); Yao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib86" title="">2021</a>)</cite>에 중점을 둔다. 우리 팀과 이전 문헌 <cite class="ltx_cite ltx_citemacro_citep">(Niklaus and Giofré, <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib54" title="">2022</a>)</cite>, 우리의 LLM, <span class="ltx_text ltx_font_typewriter" id="S1.p2.1.1">SaulLM-7B</span>은 법률 문서의 복잡성을 이해할 뿐만 아니라 법률 담론의 진화하는 특성에 적응하는 것을 목표로 한다.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">법률 실무자의 요구에 집중하고 전담 법률 코퍼라에 대한 사전 교육의 힘을 활용함으로써 우리의 작업은 법률 영역의 고유한 요구를 충족하기 위한 중요한 단계를 나타낸다. 법학을 위한 첫 번째 LLM을 도입하면 법률 전문가에게 권한을 부여할 뿐만 아니라 인공지능과 법 커뮤니티의 교차점에서 추가 혁신을 촉진할 것으로 예상한다. - 법률 언어 이해 및 적용 <cite class="ltx_cite ltx_citemacro_cite">Prakken (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib60" title="">2013</a>)</cite>에 상당한 기여를 한다. 이 작업의 기여도를 요약하면 다음과 같다.</p>
</div>
<section class="ltx_paragraph" id="S1.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Contribution 1: A family of legal LLMs.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S1.SS0.SSS0.Px1.p1.1">본 논문에서는 <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px1.p1.1.1">SaulLM-7B</span>의 패밀리, 법률 도메인 내에서 직면하는 독특한 문제를 해결하기 위해 세심하게 조작된 법률 언어 모델의 컬렉션을 소개합니다. 법률 텍스트에 특별히 맞춘 70억 개의 매개 변수 언어 모델인 <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px1.p1.1.2">SaulLM-7B</span>을 공개합니다. 전문화된 교육 요법으로 <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px1.p1.1.3">SaulLM-7B</span>은 일반 모델에 비해 법률 언어의 뉘앙스에 대한 우수한 이해도를 보여준다. 또한, <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px1.p1.1.4">SaulLM-7B-Instruct</span>은 다양한 법적 작업에서 <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px1.p1.1.5">Mistral</span> 또는 <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px1.p1.1.6">Llama</span>과 같은 기존 모델을 능가하도록 신중하게 조작되었습니다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S1.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Contribution 2: An improved evaluation protocol for legal LLMs.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S1.SS0.SSS0.Px2.p1.1">동시에, 우리는 언어 모델의 법적 숙련도를 더 잘 측정하고 개선하기 위해 고안된 LegalBench <cite class="ltx_cite ltx_citemacro_cite">Guha et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib25" title="">2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib26" title="">2023</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Dataset is processed and available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/Equall" title="">https://huggingface.co/Equall</a></span></span></span>의 보충 반복인 LegalBench-Instruct를 소개하며, 이는 향후 법 영역 연구에 기여할 것으로 기대한다. 법적 맥락에서 모델의 능력을 더욱 풍부하게 하기 위해 특히 국제법, 전문법<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>We use the term “professional law” here as defined in <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib31" title="">2020</a>)</cite></span></span></span> 및 법학에 중점을 둔 평가 프로토콜에 인기 있는 MMLU 벤치마크 <cite class="ltx_cite ltx_citemacro_cite">Hendrycks et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib31" title="">2020</a>)</cite>의 법적 과제도 포함한다.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="254" id="S1.F1.g1" src="https://arxiv.org/html/2403.03883v2/x1.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 1:</span><span class="ltx_text ltx_font_bold" id="S1.F1.2.1">Procedure for constructing <span class="ltx_text ltx_font_typewriter" id="S1.F1.2.1.1">SaulLM-7B</span></span>. 우리는 재생 데이터 및 지침 데이터 세트로 강화된 법적 데이터 세트에 의존한다. 미세 조정을 위해 법률 지침으로 미세 조정 데이터 세트를 더욱 풍부하게 합니다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S1.SS0.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Contribution 3: Model, Evaluation Code &amp; Licensing.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S1.SS0.SSS0.Px3.p1.1">광범위한 채택을 촉진하고 혁신을 촉진하기 위해 <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px3.p1.1.1">SaulLM-7B</span> 및 <span class="ltx_text ltx_font_typewriter" id="S1.SS0.SSS0.Px3.p1.1.2">SaulLM-7B-Instruct</span>과 MIT 라이선스 아래의 평가 코드를 릴리스합니다. 이 개방형 라이선스 접근법은 법적 영역 및 그 너머의 광범위한 상업적 및 연구 노력에 대한 협력 개발 및 채택을 장려한다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span><span class="ltx_text ltx_font_typewriter" id="S2.1.1">SaulLM-7B</span>: Extending the legal capabilities of Language Models</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.4">피티아 <cite class="ltx_cite ltx_citemacro_citep">(Biderman et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib6" title="">2023</a>)</cite>와 같은 <math alttext="70" class="ltx_Math" display="inline" id="S2.p1.1.m1.1"><semantics id="S2.p1.1.m1.1a"><mn id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">70</mn><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><cn id="S2.p1.1.m1.1.1.cmml" type="integer" xref="S2.p1.1.m1.1.1">70</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">70</annotation><annotation encoding="application/x-llamapun" id="S2.p1.1.m1.1d">70</annotation></semantics></math> 백만 개의 매개 변수 모델에서 팔콘 <cite class="ltx_cite ltx_citemacro_citep">(Almazrouei et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib3" title="">2023</a>)</cite>와 같은 <math alttext="180" class="ltx_Math" display="inline" id="S2.p1.2.m2.1"><semantics id="S2.p1.2.m2.1a"><mn id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">180</mn><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><cn id="S2.p1.2.m2.1.1.cmml" type="integer" xref="S2.p1.2.m2.1.1">180</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">180</annotation><annotation encoding="application/x-llamapun" id="S2.p1.2.m2.1d">180</annotation></semantics></math> billion 개의 매개 변수 모델에 이르기까지 광범위한 오픈 소스 대규모 언어 모델을 백본에 사용할 수 있습니다. 이 연구에서 우리는 벤치마크와 작업 <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib34" title="">2023</a>)</cite>에 걸쳐 높은 성능을 달성하는 미스트랄 <math alttext="7" class="ltx_Math" display="inline" id="S2.p1.3.m3.1"><semantics id="S2.p1.3.m3.1a"><mn id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><cn id="S2.p1.3.m3.1.1.cmml" type="integer" xref="S2.p1.3.m3.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">7</annotation><annotation encoding="application/x-llamapun" id="S2.p1.3.m3.1d">7</annotation></semantics></math>B 모델, <math alttext="7" class="ltx_Math" display="inline" id="S2.p1.4.m4.1"><semantics id="S2.p1.4.m4.1a"><mn id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><cn id="S2.p1.4.m4.1.1.cmml" type="integer" xref="S2.p1.4.m4.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">7</annotation><annotation encoding="application/x-llamapun" id="S2.p1.4.m4.1d">7</annotation></semantics></math> billion 파라미터 오픈 소스 모델을 선택한다.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2403.03883v2#S1.F1" title="Figure 1 ‣ Contribution 2: An improved evaluation protocol for legal LLMs. ‣ 1 Introduction ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>에 표시된 우리의 방법론은 아래에서 설명하는 2단계 프로세스를 포함한다.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Enhancing Mistral’s Legal Capabilities</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">일반 모델 <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib71" title="">2023a</a>); Taylor et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib70" title="">2022</a>); Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib89" title="">2022</a>); Gu and Dao (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib24" title="">2023</a>); Almazrouei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib3" title="">2023</a>); Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib88" title="">2024</a>); Faysse et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib21" title="">2024</a>)</cite>는 훈련 중에 법률 데이터에 대한 일부 노출을 얻지만 일반적으로 전체 데이터의 일부만 나타냅니다. 법률 업무에 대한 성과를 높이기 위한 간단한 방법은 법률 데이터에 초점을 맞춘 추가 교육을 수행하는 것이다. 특히 디코더 모델에 초점을 맞춘 이 접근법은 의학 <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib12" title="">2023</a>); Ji et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib33" title="">2023</a>)</cite>, 번역 <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib85" title="">2023</a>); Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib83" title="">2024</a>)</cite>, 코딩 <cite class="ltx_cite ltx_citemacro_cite">Roziere et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib63" title="">2023</a>)</cite>와 같은 다양한 분야에서 성공적으로 사용되었다. 이 접근법의 주요 장점은 훈련 데이터의 특정 특성으로부터의 확장성과 독립성이다. 도메인 적응에 대한 다른 연구에서는 사전 텍스트 작업을 통해 언어 모델을 전문화하려고 시도했다. 그러나 이러한 노력은 종종 더 작은 규모의 접근법 <cite class="ltx_cite ltx_citemacro_cite">Niklaus and Giofré (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib55" title="">2023</a>)</cite>에 의존하며, 계산적으로 비싼 <cite class="ltx_cite ltx_citemacro_cite">Vu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib76" title="">2020</a>); Lu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib45" title="">2023</a>)</cite>이거나 확장성 <cite class="ltx_cite ltx_citemacro_cite">Cheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib13" title="">2023</a>); Cui et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib16" title="">2023</a>); Nishida et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib57" title="">2019</a>)</cite>가 부족하다.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">이러한 이유로 웹에서 대규모 법률 코퍼라의 가용성뿐만 아니라 <em class="ltx_emph ltx_font_italic" id="S2.SS1.p2.1.1">continued pretraining</em>에 초점을 맞추기로 결정했다. 다양한 법률 콘텐츠 리포지토리에서 제공하는 고품질 데이터 세트를 세심하게 선별합니다. <cite class="ltx_cite ltx_citemacro_citep">(Penedo et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib59" title="">2023</a>)</cite> 및 중복 제거 <cite class="ltx_cite ltx_citemacro_citep">(Mou et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib50" title="">2023</a>; Kocetkov et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib37" title="">2023</a>)</cite>를 엄격하게 필터링한 후, 우리는 <math alttext="30" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.1"><semantics id="S2.SS1.p2.1.m1.1a"><mn id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><cn id="S2.SS1.p2.1.m1.1.1.cmml" type="integer" xref="S2.SS1.p2.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">30</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.1d">30</annotation></semantics></math> billion 토큰의 코퍼스를 갖게 되며, 이는 지속적인 사전 훈련을 위한 강력한 기초 역할을 한다.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Improving Legal Instruction Following</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">사용자 요청 및 대화 상호 작용을 지원하기 위해 LLM은 일반적으로 감독된 대화 쌍에 대한 훈련을 포함하는 중요한 프로세스인 명령어 튜닝을 거친다. 이 단계는 사용자 쿼리 <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib77" title="">2023a</a>); Wei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib81" title="">2021</a>); Chung et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib14" title="">2022</a>); Faysse et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib22" title="">2023</a>); Ding et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib19" title="">2023</a>); Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib78" title="">2023b</a>)</cite>를 처리하는 데 능숙한 다용도 모델을 만드는 데 필수적이다.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">범용 언어 모델의 경우, 수업의 다양성과 품질은 중요한 <cite class="ltx_cite ltx_citemacro_cite">Cao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib9" title="">2023</a>); Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib90" title="">2023</a>)</cite>이다. 그러나 전문화된 도메인에서는 성능을 향상시키기 위해 작업별 및 전문화된 프롬프트를 통합하는 것이 중요하다. 우리의 명령 미세 조정 단계는 <math alttext="2" class="ltx_Math" display="inline" id="S2.SS2.p2.1.m1.1"><semantics id="S2.SS2.p2.1.m1.1a"><mn id="S2.SS2.p2.1.m1.1.1" xref="S2.SS2.p2.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.p2.1.m1.1b"><cn id="S2.SS2.p2.1.m1.1.1.cmml" type="integer" xref="S2.SS2.p2.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p2.1.m1.1c">2</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p2.1.m1.1d">2</annotation></semantics></math> 핵심 구성 요소: 일반(즉, 비법률) 및 법률 명령을 포함한다. 전자는 모델의 명령에 대한 이해와 후속을 향상시키는 데 도움이 되며 코딩, 수학, 일반 대화와 같은 다양한 영역의 데이터를 포함한다. 후자의 경우 법률 질문 응답 및 요약 등을 포함하여 법률 도메인의 뉘앙스에 맞춘 광범위한 데이터 세트를 사용한다. 이 세심한 수업 데이터 미세 조정을 통해 우리의 모델인 <span class="ltx_text ltx_font_typewriter" id="S2.SS2.p2.1.1">SaulLM-7B-Instruct</span>은 광범위한 관련 작업에서 법적 복잡성을 파악할 수 있고 뛰어나다.</p>
</div>
<div class="ltx_theorem ltx_theorem_remark" id="Thmremarkx1">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span class="ltx_text ltx_font_bold" id="Thmremarkx1.1.1.1">Remark</span></span><span class="ltx_text ltx_font_bold" id="Thmremarkx1.2.2">.</span>
</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Thmremarkx1.p1">
<p class="ltx_p" id="Thmremarkx1.p1.1"><span class="ltx_text ltx_font_italic" id="Thmremarkx1.p1.1.1">많은 일반적인 LLMs <cite class="ltx_cite ltx_citemacro_cite">Tunstall et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib74" title="">2023</a>)</cite>는 모델을 인간 선호도 <cite class="ltx_cite ltx_citemacro_cite">Rafailov et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib62" title="">2023</a>); Munos et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib52" title="">2023</a>); von Werra et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib75" title="">2020</a>)</cite>와 정렬하는 추가 단계를 포함한다는 점에 주목할 필요가 있다. 우리의 경우 초기 실험에서 성능의 유의미한 향상이 나타나지 않았기 때문에 본 논문을 위해 이 방법을 추구하지 않기로 결정했다. </span></p>
</div>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">이 섹션에서는 데이터 수집 및 청소 계획에 대해 설명합니다.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Legal Pretraining Corpora</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">과학, 의학 등의 분야와 달리 법적 지형은 국가 및 관할 지역에 따라 크게 달라지며, 관습법 대 민법 <cite class="ltx_cite ltx_citemacro_cite">Henderson et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib30" title="">2022</a>)</cite>와 같이 현지법뿐만 아니라 법적 전통에서도 차이를 반영한다. 따라서 우리는 영어가 전 세계적으로 법적 맥락에서 널리 사용되기 때문에 영어에 중점을 두고 다양한 관할 구역에서 법률 텍스트를 수집했다. 우리의 컬렉션은 다양한 법률 시스템을 다루는 미국 <cite class="ltx_cite ltx_citemacro_cite">Tuggener et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib73" title="">2020</a>)</cite>, 유럽 <cite class="ltx_cite ltx_citemacro_cite">Chalkidis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib10" title="">2019</a>)</cite>, 호주 <cite class="ltx_cite ltx_citemacro_cite">Butler (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib8" title="">2023</a>)</cite>의 데이터를 포함한다. 이 철저한 큐레이션 과정과 공격적인 청소(<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS2" title="3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.1.2</span></a> 참조)를 통해 우리는 300억 토큰의 코퍼스로 끝나 지역에 걸친 법률 언어의 복잡성을 포착한다.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Dataset Composition</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S3.SS1.SSS1.Px1">
<h5 class="ltx_title ltx_title_paragraph">Legal Sources</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS1.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.Px1.p1.1">Pile <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib23" title="">2020</a>)</cite> 및 MultiLegal Pile <cite class="ltx_cite ltx_citemacro_citep">(Niklaus et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib56" title="">2023</a>)</cite>의 FreeLaw 하위 집합과 같은 이전에 사용 가능한 데이터 세트와 웹에서 공개적으로 사용 가능한 소스에서 긁어낸 데이터를 모두 결합합니다. <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.T1" title="Table 1 ‣ Legal Sources ‣ 3.1.1 Dataset Composition ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a>에 서로 다른 데이터 소스를 나열한다.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T1.11">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.11.12.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T1.11.12.1.1">Name</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.11.12.1.2">Tokens</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T1.1.1.2">FreeLaw<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>We used the subset from The Pile <cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib23" title="">2020</a>)</cite>.</span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.1">
<math alttext="15" class="ltx_Math" display="inline" id="S3.T1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.m1.1a"><mn id="S3.T1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.m1.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.m1.1b"><cn id="S3.T1.1.1.1.m1.1.1.cmml" type="integer" xref="S3.T1.1.1.1.m1.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.m1.1c">15</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.m1.1d">15</annotation></semantics></math>B</td>
</tr>
<tr class="ltx_tr" id="S3.T1.11.13.2">
<td class="ltx_td ltx_align_left" id="S3.T1.11.13.2.1">EDGAR<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.sec.gov/edgar" title="">https://www.sec.gov/edgar</a></span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.11.13.2.2">5B</td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.2">
<td class="ltx_td ltx_align_left" id="S3.T1.2.2.2">English MultiLegal Pile<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>We limited ourselves to the commercially-licensed subset: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/joelniklaus/Multi_Legal_Pile_Commercial" title="">https://huggingface.co/datasets/joelniklaus/Multi_Legal_Pile_Commercial</a></span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.2.2.1">
<math alttext="50" class="ltx_Math" display="inline" id="S3.T1.2.2.1.m1.1"><semantics id="S3.T1.2.2.1.m1.1a"><mn id="S3.T1.2.2.1.m1.1.1" xref="S3.T1.2.2.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.1.m1.1b"><cn id="S3.T1.2.2.1.m1.1.1.cmml" type="integer" xref="S3.T1.2.2.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.1.m1.1c">50</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.2.1.m1.1d">50</annotation></semantics></math>B</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.3">
<td class="ltx_td ltx_align_left" id="S3.T1.3.3.2">English EuroParl <cite class="ltx_cite ltx_citemacro_citep">(Koehn, <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib38" title="">2005</a>)</cite>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.3.3.1">
<math alttext="6" class="ltx_Math" display="inline" id="S3.T1.3.3.1.m1.1"><semantics id="S3.T1.3.3.1.m1.1a"><mn id="S3.T1.3.3.1.m1.1.1" xref="S3.T1.3.3.1.m1.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.1.m1.1b"><cn id="S3.T1.3.3.1.m1.1.1.cmml" type="integer" xref="S3.T1.3.3.1.m1.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.1.m1.1c">6</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.3.1.m1.1d">6</annotation></semantics></math>B</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.4">
<td class="ltx_td ltx_align_left" id="S3.T1.4.4.2">GovInfo<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.govinfo.gov/" title="">https://www.govinfo.gov/</a></span></span></span> Statutes, Opinions &amp; Codes</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.4.1">
<math alttext="11" class="ltx_Math" display="inline" id="S3.T1.4.4.1.m1.1"><semantics id="S3.T1.4.4.1.m1.1a"><mn id="S3.T1.4.4.1.m1.1.1" xref="S3.T1.4.4.1.m1.1.1.cmml">11</mn><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.1.m1.1b"><cn id="S3.T1.4.4.1.m1.1.1.cmml" type="integer" xref="S3.T1.4.4.1.m1.1.1">11</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.1.m1.1c">11</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.4.1.m1.1d">11</annotation></semantics></math>B</td>
</tr>
<tr class="ltx_tr" id="S3.T1.5.5">
<td class="ltx_td ltx_align_left" id="S3.T1.5.5.2">Law Stack Exchange<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/ymoslem/Law-StackExchange" title="">https://huggingface.co/datasets/ymoslem/Law-StackExchange</a></span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.5.5.1">
<math alttext="19" class="ltx_Math" display="inline" id="S3.T1.5.5.1.m1.1"><semantics id="S3.T1.5.5.1.m1.1a"><mn id="S3.T1.5.5.1.m1.1.1" xref="S3.T1.5.5.1.m1.1.1.cmml">19</mn><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.1.m1.1b"><cn id="S3.T1.5.5.1.m1.1.1.cmml" type="integer" xref="S3.T1.5.5.1.m1.1.1">19</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.1.m1.1c">19</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.5.1.m1.1d">19</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6">
<td class="ltx_td ltx_align_left" id="S3.T1.6.6.2">Commercial Open Australian Legal Corpus<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/umarbutler/open-australian-legal-corpus-creator" title="">https://github.com/umarbutler/open-australian-legal-corpus-creator</a></span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.6.6.1">
<math alttext="0.5" class="ltx_Math" display="inline" id="S3.T1.6.6.1.m1.1"><semantics id="S3.T1.6.6.1.m1.1a"><mn id="S3.T1.6.6.1.m1.1.1" xref="S3.T1.6.6.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.1.m1.1b"><cn id="S3.T1.6.6.1.m1.1.1.cmml" type="float" xref="S3.T1.6.6.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.1.m1.1c">0.5</annotation><annotation encoding="application/x-llamapun" id="S3.T1.6.6.1.m1.1d">0.5</annotation></semantics></math>B</td>
</tr>
<tr class="ltx_tr" id="S3.T1.7.7">
<td class="ltx_td ltx_align_left" id="S3.T1.7.7.2">EU Legislation<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>Scraped from <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://eur-lex.europa.eu/homepage.html" title="">https://eur-lex.europa.eu/homepage.html</a></span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.7.7.1">
<math alttext="315" class="ltx_Math" display="inline" id="S3.T1.7.7.1.m1.1"><semantics id="S3.T1.7.7.1.m1.1a"><mn id="S3.T1.7.7.1.m1.1.1" xref="S3.T1.7.7.1.m1.1.1.cmml">315</mn><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.1.m1.1b"><cn id="S3.T1.7.7.1.m1.1.1.cmml" type="integer" xref="S3.T1.7.7.1.m1.1.1">315</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.1.m1.1c">315</annotation><annotation encoding="application/x-llamapun" id="S3.T1.7.7.1.m1.1d">315</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.8">
<td class="ltx_td ltx_align_left" id="S3.T1.8.8.2">UK Legislation<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.legislation.gov.uk/" title="">https://www.legislation.gov.uk/</a></span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.8.8.1">
<math alttext="190" class="ltx_Math" display="inline" id="S3.T1.8.8.1.m1.1"><semantics id="S3.T1.8.8.1.m1.1a"><mn id="S3.T1.8.8.1.m1.1.1" xref="S3.T1.8.8.1.m1.1.1.cmml">190</mn><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.1.m1.1b"><cn id="S3.T1.8.8.1.m1.1.1.cmml" type="integer" xref="S3.T1.8.8.1.m1.1.1">190</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.1.m1.1c">190</annotation><annotation encoding="application/x-llamapun" id="S3.T1.8.8.1.m1.1d">190</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S3.T1.9.9">
<td class="ltx_td ltx_align_left" id="S3.T1.9.9.2">Court Transcripts<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>Obtained from CourtListener: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.courtlistener.com/" title="">https://www.courtlistener.com/</a>. We use Whisper <cite class="ltx_cite ltx_citemacro_citep">(Radford et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib61" title="">2022</a>)</cite> to transcribe the audio files.</span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.9.9.1">
<math alttext="350" class="ltx_Math" display="inline" id="S3.T1.9.9.1.m1.1"><semantics id="S3.T1.9.9.1.m1.1a"><mn id="S3.T1.9.9.1.m1.1.1" xref="S3.T1.9.9.1.m1.1.1.cmml">350</mn><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.1.m1.1b"><cn id="S3.T1.9.9.1.m1.1.1.cmml" type="integer" xref="S3.T1.9.9.1.m1.1.1">350</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.1.m1.1c">350</annotation><annotation encoding="application/x-llamapun" id="S3.T1.9.9.1.m1.1d">350</annotation></semantics></math>M</td>
</tr>
<tr class="ltx_tr" id="S3.T1.10.10">
<td class="ltx_td ltx_align_left" id="S3.T1.10.10.2">UPSTO<span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://bulkdata.uspto.gov/" title="">https://bulkdata.uspto.gov/</a></span></span></span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T1.10.10.1">
<math alttext="4.7" class="ltx_Math" display="inline" id="S3.T1.10.10.1.m1.1"><semantics id="S3.T1.10.10.1.m1.1a"><mn id="S3.T1.10.10.1.m1.1.1" xref="S3.T1.10.10.1.m1.1.1.cmml">4.7</mn><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.1.m1.1b"><cn id="S3.T1.10.10.1.m1.1.1.cmml" type="float" xref="S3.T1.10.10.1.m1.1.1">4.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.1.m1.1c">4.7</annotation><annotation encoding="application/x-llamapun" id="S3.T1.10.10.1.m1.1d">4.7</annotation></semantics></math>B</td>
</tr>
<tr class="ltx_tr" id="S3.T1.11.11">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T1.11.11.2">Total</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.11.11.1">
<math alttext="94" class="ltx_Math" display="inline" id="S3.T1.11.11.1.m1.1"><semantics id="S3.T1.11.11.1.m1.1a"><mn id="S3.T1.11.11.1.m1.1.1" xref="S3.T1.11.11.1.m1.1.1.cmml">94</mn><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.1.m1.1b"><cn id="S3.T1.11.11.1.m1.1.1.cmml" type="integer" xref="S3.T1.11.11.1.m1.1.1">94</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.1.m1.1c">94</annotation><annotation encoding="application/x-llamapun" id="S3.T1.11.11.1.m1.1d">94</annotation></semantics></math>B</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 1:</span><span class="ltx_text ltx_font_bold" id="S3.T1.13.1">Sources of Legal Pretraining Data. </span> 이러한 원본에는 노이즈와 심하게 중복된 문서가 포함되어 있으며, 필터링 및 중복 제거되어 300억 토큰 데이터 세트가 생성됩니다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS1.Px1.p2">
<p class="ltx_p" id="S3.SS1.SSS1.Px1.p2.1">서로 다른 소스 간에 상당한 중복이 있으며 <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS2" title="3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.1.2</span></a>에 설명된 매우 공격적인 청소 및 중복 제거 단계를 실행합니다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS1.Px2">
<h5 class="ltx_title ltx_title_paragraph">Replay Sources</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS1.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS1.Px2.p1.1">계속된 사전 훈련 동안 치명적인 망각의 위험을 줄이기 위해 선행 문헌 <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib12" title="">2023</a>); Sun et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib69" title="">2020</a>)</cite>에 따라 사전 훈련 분포의 데이터를 통합한다. 그러나, 미스트랄에 대한 트레이닝 데이터는 공개되지 않았기 때문에, 최종 트레이닝 믹스의 대략 <math alttext="2\%" class="ltx_Math" display="inline" id="S3.SS1.SSS1.Px2.p1.1.m1.1"><semantics id="S3.SS1.SSS1.Px2.p1.1.m1.1a"><mrow id="S3.SS1.SSS1.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.cmml"><mn id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.2" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.2.cmml">2</mn><mo id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.1" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px2.p1.1.m1.1b"><apply id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1"><csymbol cd="latexml" id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.1">percent</csymbol><cn id="S3.SS1.SSS1.Px2.p1.1.m1.1.1.2.cmml" type="integer" xref="S3.SS1.SSS1.Px2.p1.1.m1.1.1.2">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px2.p1.1.m1.1c">2\%</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.Px2.p1.1.m1.1d">2 %</annotation></semantics></math>를 포함하는, Wikipedia, StackExchange 및 GitHub로부터 일반적으로 이용가능한 "일반" 데이터를 소개한다. 이러한 데이터 세트는 SlimPajama <cite class="ltx_cite ltx_citemacro_cite">Shen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib66" title="">2023</a>); Computer (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib15" title="">2023</a>); Soboleva et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib68" title="">2023</a>)</cite>에서 샘플링된다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS1.Px3">
<h5 class="ltx_title ltx_title_paragraph">Instruction Sources</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS1.Px3.p1">
<p class="ltx_p" id="S3.SS1.SSS1.Px3.p1.1">또한 사전 훈련 중에 대화 데이터를 포함하는 것이 유익하다는 것을 발견했다. 이것은 최근 신경 기계 번역의 발전에 영감을 받았으며, 번역에서 LLM의 강력한 능력은 훈련 말뭉치 <cite class="ltx_cite ltx_citemacro_cite">Anil et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib4" title="">2023</a>); Briakou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib7" title="">2023</a>)</cite>에 우발적인 병렬 데이터가 존재하기 때문이라는 점을 강조한다. 구체적으로, 이는 프리트레이닝 동안 Super Natural Instruction <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib79" title="">2022</a>)</cite>와 FLAN collection <cite class="ltx_cite ltx_citemacro_cite">Longpre et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib44" title="">2023</a>)</cite>를 포함한다는 것을 의미한다.</p>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Data Cleaning</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">수집된 데이터의 상당 부분은 PDF 파일에 있거나 PDF<span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span>We used <a class="ltx_ref ltx_href" href="https://poppler.freedesktop.org/" title="">Poppler</a> for text extraction from PDF files.</span></span></span>에서 추출된 텍스트이다. 이것은 텍스트가 문장의 중간에 i) 페이지 번호들; ii) 라인 번호들; iii) 비정규화된 유니코드 문자들; iv) 텍스트의 파선 라인들; v) 반복되는 문자들: 새로운 라인들, 대시들 등; vi) 다른 아티팩트들을 포함하는 일부 아티팩트들을 갖는다는 것을 의미한다. 우리는 데이터를 필터링하기 위해 규칙과 휴리스틱의 조합을 사용하여 이러한 문제를 해결했다.</p>
</div>
<section class="ltx_paragraph" id="S3.SS1.SSS2.Px1">
<h5 class="ltx_title ltx_title_paragraph">Text Normalization</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS2.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS2.Px1.p1.1">우리는 <span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS2.Px1.p1.1.1">unicodedata</span> Python 패키지를 통해 사용할 수 있는 모든 유니코드를 NFKC 방법으로 정규화한다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS2.Px2">
<h5 class="ltx_title ltx_title_paragraph">Rule filters</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS2.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.Px2.p1.2"><cite class="ltx_cite ltx_citemacro_citet">Elazar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib20" title="">2023</a>)</cite>에 이어 데이터 세트에서 가장 일반적인 10-gram을 찾았고 대부분 반복되는 문자인 원하지 않는 문자를 제거하기 위해 정규식을 사용했다. 구체적으로, 원본 데이터에서 상위 <math alttext="10" class="ltx_Math" display="inline" id="S3.SS1.SSS2.Px2.p1.2.m2.1"><semantics id="S3.SS1.SSS2.Px2.p1.2.m2.1a"><mn id="S3.SS1.SSS2.Px2.p1.2.m2.1.1" xref="S3.SS1.SSS2.Px2.p1.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.Px2.p1.2.m2.1b"><cn id="S3.SS1.SSS2.Px2.p1.2.m2.1.1.cmml" type="integer" xref="S3.SS1.SSS2.Px2.p1.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.Px2.p1.2.m2.1c">10</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.Px2.p1.2.m2.1d">10</annotation></semantics></math>의 <math alttext="8" class="ltx_Math" display="inline" id="S3.SS1.SSS2.Px2.p1.1.m1.1"><semantics id="S3.SS1.SSS2.Px2.p1.1.m1.1a"><mn id="S3.SS1.SSS2.Px2.p1.1.m1.1.1" xref="S3.SS1.SSS2.Px2.p1.1.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.Px2.p1.1.m1.1b"><cn id="S3.SS1.SSS2.Px2.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS1.SSS2.Px2.p1.1.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.Px2.p1.1.m1.1c">8</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.Px2.p1.1.m1.1d">8</annotation></semantics></math> 10-grams가 반복되는 문자, 예를 들어, “<span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS2.Px2.p1.2.1"> - - - - - -</span>”, “<span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS2.Px2.p1.2.2">........................................................................................................................ </span>”, 또는 “<span class="ltx_text ltx_font_typewriter" id="S3.SS1.SSS2.Px2.p1.2.3">*******</span>”, 및 이상한 문자, 즉 인코딩 문제. 또한 반복되는 공백(공간, 새 줄 및 탭)과 파이프라인을 통과한 HTML 태그를 제거했다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS2.Px3">
<h5 class="ltx_title ltx_title_paragraph">Perplexity filtering</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS2.Px3.p1">
<p class="ltx_p" id="S3.SS1.SSS2.Px3.p1.1">우리는 신중하게 검사된 법률 데이터의 작은 하위 집합에 대해 KenLM 모델 <cite class="ltx_cite ltx_citemacro_citep">(Heafield, <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib29" title="">2011</a>)</cite>를 훈련하고 높은 복잡도 문단을 필터링하는 데 사용했다. 이것은 데이터에 존재하는 대부분의 "이상한" 유니코드 시퀀스뿐만 아니라 비영어 텍스트를 제거했다. <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.T2" title="Table 2 ‣ Perplexity filtering ‣ 3.1.2 Data Cleaning ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">2</span></a>의 필터링된 데이터에서 가장 일반적인 <math alttext="10" class="ltx_Math" display="inline" id="S3.SS1.SSS2.Px3.p1.1.m1.1"><semantics id="S3.SS1.SSS2.Px3.p1.1.m1.1a"><mn id="S3.SS1.SSS2.Px3.p1.1.m1.1.1" xref="S3.SS1.SSS2.Px3.p1.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.Px3.p1.1.m1.1b"><cn id="S3.SS1.SSS2.Px3.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS1.SSS2.Px3.p1.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.Px3.p1.1.m1.1c">10</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.Px3.p1.1.m1.1d">10</annotation></semantics></math>-grams 중 일부를 보여준다.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T2.1.1.1.1">Common 10-grams</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.1.2.1.1"><span class="ltx_text ltx_font_typewriter" id="S3.T2.1.2.1.1.1">have been obvious to one of ordinary skill in the</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.3.2">
<td class="ltx_td ltx_align_center" id="S3.T2.1.3.2.1"><span class="ltx_text ltx_font_typewriter" id="S3.T2.1.3.2.1.1">before the effective filing date of the claimed invention to</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.1.4.3.1"><span class="ltx_text ltx_font_typewriter" id="S3.T2.1.4.3.1.1">rejected under 35 U.S.C . 103 as being unpatentable over</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 2:</span><span class="ltx_text ltx_font_bold" id="S3.T2.3.1">Most common 10-grams</span> in the pretraining dataset.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>Data Deduplication</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS3.p1">
<p class="ltx_p" id="S3.SS1.SSS3.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Kocetkov et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib37" title="">2023</a>); Lee et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib39" title="">2021</a>)</cite>에서 영감을 받아 기본 매개 변수를 사용하여 <cite class="ltx_cite ltx_citemacro_citet">Mou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib50" title="">2023</a>)</cite>를 사용하여 학습 데이터에서 중복 및 거의 중복을 제거한 후 고품질 텍스트의 대략 <math alttext="30" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p1.1.m1.1"><semantics id="S3.SS1.SSS3.p1.1.m1.1a"><mn id="S3.SS1.SSS3.p1.1.m1.1.1" xref="S3.SS1.SSS3.p1.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p1.1.m1.1b"><cn id="S3.SS1.SSS3.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS1.SSS3.p1.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p1.1.m1.1c">30</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p1.1.m1.1d">30</annotation></semantics></math>B 토큰으로 남겨두었다.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Instruction Finetuning Mixes</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">명령어 미세 조정은 서로 다른 작업에 걸쳐 미리 훈련된 디코더 모델에서 최상의 성능을 얻기 위해 중요하다. 우리는 일반 지침과 법률 지침을 혼합하여 모델을 교육하여 법률 전문 지식을 중심으로 지침을 잘 이해하고 따르도록 훈련한다.</p>
</div>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">General Instructions</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.1">일반적인 지침과 관련하여, 우리는 네 가지 주요 출처에서 그것들을 수집합니다.</p>
<ol class="ltx_enumerate" id="S3.I1">
<li class="ltx_item" id="S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S3.I1.i1.p1">
<p class="ltx_p" id="S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i1.p1.1.1">SlimOrca</span> FLAN 컬렉션의 이 서브세트는 일반 명령어를 포함하며, 다양한 작업에 대한 집중된 리소스를 제공합니다. <cite class="ltx_cite ltx_citemacro_cite">Mukherjee et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib51" title="">2023</a>); Lian et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib42" title="">2023</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S3.I1.i2.p1">
<p class="ltx_p" id="S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i2.p1.1.1">Meta Math Question Answering Instructions</span> Designed for mathematical inquiry, this dataset<span class="ltx_note ltx_role_footnote" id="footnote15"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span>Accessible at <a class="ltx_ref ltx_url ltx_font_typewriter" href="meta-math/MetaMathQA" title="">meta-math/MetaMathQA</a></span></span></span> presents a range of mathematical questions, facilitating research in math-based natural language processing <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib87" title="">2023</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S3.I1.i3.p1">
<p class="ltx_p" id="S3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i3.p1.1.1">General Conversations from UltraChat</span> Capturing various conversational context, this GPT-derived dataset contribute to enhance natural language understanding and generation systems <cite class="ltx_cite ltx_citemacro_cite">Ding et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib19" title="">2023</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S3.I1.i4.p1">
<p class="ltx_p" id="S3.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I1.i4.p1.1.1">Code Instructions from Glaive Code Assistant v2<span class="ltx_note ltx_role_footnote" id="footnote16"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnote16.1.1.1">16</span></span><span class="ltx_text ltx_font_medium" id="footnote16.9">Available at </span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v2" title="">https://huggingface.co/datasets/glaiveai/glaive-code-assistant-v2</a></span></span></span></span> Training on code has been shown to increase the reasoning ability of models <cite class="ltx_cite ltx_citemacro_citep">(Ma et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib46" title="">2023</a>)</cite></p>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S3.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p2.1">이 모든 데이터를 세심하게 필터링, 중복 제거 및 큐레이트하여 <math alttext="600" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px1.p2.1.m1.1"><semantics id="S3.SS2.SSS0.Px1.p2.1.m1.1a"><mn id="S3.SS2.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1.cmml">600</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px1.p2.1.m1.1b"><cn id="S3.SS2.SSS0.Px1.p2.1.m1.1.1.cmml" type="integer" xref="S3.SS2.SSS0.Px1.p2.1.m1.1.1">600</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px1.p2.1.m1.1c">600</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px1.p2.1.m1.1d">600</annotation></semantics></math>K 명령어로 구성된 정제된 데이터 세트를 생성한다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Legal Instruction Construction</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.1">우리는 여러 법률 문서 유형 <cite class="ltx_cite ltx_citemacro_cite">Ding et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib19" title="">2023</a>)</cite>에 걸쳐 기본 법률 역량을 다루는 포괄적인 대화를 종합적으로 생성한다. 우리는 <span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS0.Px2.p1.1.1">Mistral-7B-instruct</span>을 활용하여 메타데이터로 증강된 법률 텍스트를 코히런트 대화로 변환합니다. 방법론은 <math alttext="3" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.1.m1.1"><semantics id="S3.SS2.SSS0.Px2.p1.1.m1.1a"><mn id="S3.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.1.m1.1b"><cn id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px2.p1.1.m1.1d">3</annotation></semantics></math> 미리 정의된 턴들과 대화를 개시하는 것을 포함한다: (1) 사용자가 법률 문서와 관련된 요청을 아티큘레이션하고, (2) 어시스턴트가 메타데이터(예를 들어, 문서 유형, 날짜, 판사의 이름)를 리프레이징함으로써 응답하고, (3) 사용자가 어시스턴트에게 자신의 추론을 자세히 설명하라고 프롬프트한다. 그 후, 우리는 일련의 회전을 통해 대화를 확장하며, 여기서 사용자 모델은 어시스턴트의 추론을 파악하기 위해 점진적으로 더 구체적인 질문을 제기한다. 동시에, 어시스턴트 모델은 심층적인 통찰력을 제공합니다. 예시적인 예가 <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.F2" title="Figure 2 ‣ Legal Instruction Construction ‣ 3.2 Instruction Finetuning Mixes ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2</span></a>에 제시된다. 특히, 기존 벤치마크에서 테스트 세트를 제외합니다.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="598" id="S3.F2.g1" src="https://arxiv.org/html/2403.03883v2/x2.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 2:</span><span class="ltx_text ltx_font_bold" id="S3.F2.9.1">Turning dataset with metadata into a conversation. </span> Reddit post 분류의 예를 들어 레이블이 지정된 예제 {"<span class="ltx_text ltx_font_italic" id="S3.F2.10.2">My employer fired me because …Is legal?</span>", "<span class="ltx_text ltx_font_italic" id="S3.F2.11.3">employment</span>" }, 우리는 단순히 질의와 답변을 자연스러운 대화로 재구성함으로써 대화의 처음 세 턴을 하드 코딩합니다. 그런 다음 진행 중인 대화에서 관련 질문을 계속 생성하는 작업이 작업인 <span class="ltx_text ltx_font_italic" id="S3.F2.12.4">user</span> 모델(blue dashed)과 답변을 제공하는 <span class="ltx_text ltx_font_italic" id="S3.F2.13.5">assistant</span> 모델을 사용하여 대화를 완료합니다. <span class="ltx_text ltx_font_italic" id="S3.F2.14.6">assistant</span> 및 <span class="ltx_text ltx_font_italic" id="S3.F2.15.7">user</span> 모델은 모두 <span class="ltx_text ltx_font_typewriter" id="S3.F2.16.8">Mistral-7B-instruct</span>이다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Evaluation of Legal Knowledge</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.2">모델의 법적 능력을 평가하기 위해 <math alttext="3" class="ltx_Math" display="inline" id="S4.p1.1.m1.1"><semantics id="S4.p1.1.m1.1a"><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><cn id="S4.p1.1.m1.1.1.cmml" type="integer" xref="S4.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">3</annotation></semantics></math> 벤치마크를 사용한다 (i) <math alttext="5" class="ltx_Math" display="inline" id="S4.p1.2.m2.1"><semantics id="S4.p1.2.m2.1a"><mn id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><cn id="S4.p1.2.m2.1.1.cmml" type="integer" xref="S4.p1.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">5</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m2.1d">5</annotation></semantics></math> 유형의 법적 문서에 대한 백본들의 복잡성을 비교한다 (ii) 보다 심층적인 평가를 위해 LegalBench-Instruct로 LegalBench를 강화한다 (iii) 추가적인 통찰을 위해 MMLU의 법적 섹션에 의존한다.</p>
</div>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Perplexity Measurement</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">법적 문서에 대한 백본의 적응성을 평가하기 위해 4개의 고유한 법적 도메인에 걸쳐 있는 벤치마크 데이터 세트를 사용하여 복잡성을 평가한다: <em class="ltx_emph ltx_font_italic" id="S4.SS0.SSS0.Px1.p1.1.1">계약, 사법 결정, 의견 텍스트 및 법률</em>. 데이터 세트가 최신 상태이며 LLM 데이터에서 수집 차단 날짜 이후에 원본이 되도록 합니다. 구체적으로, 계약 데이터는 EDGAR(2024년 1/4분기), 2023년 10월 이후에 발표된 ICSID 법원 판결의 법적 결정, 입법은 2023년 10월 이후 하원 또는 상원에 제출된 미국 법률안에 초점을 맞추고, 정당 제출은 2023년 10월 이후에 제출된 텍사스 브리핑을 포함한다.</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p2.1">조사하는 동안 우리는 법률 벤치의 원래 프롬프트에서 상당한 한계를 발견했다. 명령어 준수, 특히 포맷 처리 시 오픈 소스 LLM이 직면하는 어려움과 결합된 이러한 프롬프트의 복잡한 특성은 (정확도로 측정한 바와 같이) 성능의 상당한 저하를 초래한다. 생성된 문장은 종종 장황하고 구문 분석하기가 어려워 리걸벤치를 현재 형태로 너무 엄격하게 만들고 작업에 대한 개선을 정확하게 측정하지 못한다.</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p3.1">예를 들어, 일부 태스크에서 성능은 모델이 예측하는 첫 번째 단어에 의해 평가되며, 이 단어는 <em class="ltx_emph ltx_font_italic" id="S4.SS0.SSS0.Px1.p3.1.1">Yes/No</em>일 것으로 예상된다. 이는 응답이 다소 장황하다면 인간이 정답으로 분류하더라도 오답으로 계산된다는 것을 의미한다. 이러한 단점을 개선하기 위해, 우리는 프롬프트를 1) 산만한 소수의 샷 예제를 제거하고 2) 모델이 태그를 생성하기 위한 특정 명령으로 마무리한다(<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S4.T3" title="Table 3 ‣ Perplexity Measurement ‣ 4 Evaluation of Legal Knowledge ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a> 참조).</p>
</div>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.1.1">
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1" style="width:199.2pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S4.T3.1.1.1.1.1">Original Prompt</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.2.1">
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T3.1.2.1.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.2.1.1.1">The Telemarketing Sales Rule is provided by 16 C.F.R. § 310.3(a)(1) and 16 C.F.R. § 310.3(a)(2).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.3.2">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.3.2.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.3.2.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.3.2.1.1.1">Question:</span> Acme Toys is a telemarketer subject to the Telemarketing Sales Rule. Acme Toys told a customer that its frisbees cost $10 each, when in fact the frisbees cost $12 each. The customer agreed to the sale and was charged $12. Is this a violation of the Telemarketing Sales Rule?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.4.3">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.4.3.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.4.3.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.4.3.1.1.1">Answer:</span> Yes</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.5.4">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.5.4.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.5.4.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.5.4.1.1.1">Question:</span> Acme Toys is a telemarketer subject to the Telemarketing Sales Rule. Acme Toys told a customer that its frisbees cost $10 each, when in fact the frisbees did cost $10, but Acme Toys did not disclose that shipping would cost an additional $5. The customer agreed to the sale. Is this a violation of the Telemarketing Sales Rule?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.6.5">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.6.5.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.6.5.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.6.5.1.1.1">Answer:</span> Yes</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.7.6">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.7.6.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.7.6.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.7.6.1.1.1">Question:</span> Acme Industrial Products is a telemarketer subject to the Telemarketing Sales Rule. Acme Industrial Products told a customer that its brooms cost $12 each, and the brooms did in fact cost $12. The customer agreed to the sale. Is this a violation of the Telemarketing Sales Rule?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.8.7">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.8.7.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.8.7.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.8.7.1.1.1">Answer:</span> No</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.9.8">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.9.8.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.9.8.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.9.8.1.1.1">Question:</span> Acme Industrial Products is a telemarketer subject to the Telemarketing Sales Rule. Acme Industrial Products told a customer that it would sell them 4 brooms for $10 and that shipping would be $5. Then, the customer agreed to the sale. Is this a violation of the Telemarketing Sales Rule?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.10.9">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.10.9.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.10.9.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.10.9.1.1.1">Answer:</span> No</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.11.10">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.11.10.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.11.10.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.11.10.1.1.1">Question:</span> {text}</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.12.11">
<td class="ltx_td ltx_align_justify" id="S4.T3.1.12.11.1" style="width:199.2pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="S4.T3.1.12.11.1.1">Answer:</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.13.12">
<td class="ltx_td ltx_align_justify ltx_border_t" id="S4.T3.1.13.12.1" style="width:199.2pt;">
<p class="ltx_p ltx_align_top" id="S4.T3.1.13.12.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.13.12.1.1.1">Curated Prompt</span> (Ours)</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.14.13">
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S4.T3.1.14.13.1" style="width:199.2pt;">
<div class="ltx_block ltx_align_top" id="S4.T3.1.14.13.1.1">
<p class="ltx_p" id="S4.T3.1.14.13.1.1.1">텔레마케팅 판매 규칙은 16 C.F.R. § 310.3(a)(1) 및 16 C.F.R. § 310.3(a)(2)에 의해 제공된다.</p>
<p class="ltx_p" id="S4.T3.1.14.13.1.1.2">다음 질문에 답하세요: {text}</p>
<p class="ltx_p" id="S4.T3.1.14.13.1.1.3"><span class="ltx_text ltx_font_italic" id="S4.T3.1.14.13.1.1.3.1">Answer by output "Yes" or "No"</span></p>
</div>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3:</span><span class="ltx_text ltx_font_bold" id="S4.T3.3.1">Example from LegalBench-Instruct</span>. 7B 크기의 LLM을 산만하게 하는 것으로 밝혀짐에 따라 리걸벤치에서 몇 가지 짧은 예를 제거하여 수동으로 오타를 선별하고 수정했다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Massive Multitask Language Understanding (MMLU)</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.3">MLU 벤치마크 <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib31" title="">2020</a>)</cite>는 LLM 성능의 향상을 측정하기 위해 널리 사용되었다. 본 연구에서는 <span class="ltx_text ltx_font_italic" id="S4.SS0.SSS0.Px2.p1.3.1">international law</span>, <span class="ltx_text ltx_font_italic" id="S4.SS0.SSS0.Px2.p1.3.2">professional law</span>, <span class="ltx_text ltx_font_italic" id="S4.SS0.SSS0.Px2.p1.3.3">jurisprudence</span>에 초점을 맞추어 법률 도메인에 분석을 집중합니다. 이들 태스크는 각각 <math alttext="120" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS0.SSS0.Px2.p1.1.m1.1a"><mn id="S4.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">120</mn><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.1.m1.1b"><cn id="S4.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS0.SSS0.Px2.p1.1.m1.1.1">120</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.1.m1.1c">120</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.1.m1.1d">120</annotation></semantics></math>, <math alttext="1500" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.2.m2.1"><semantics id="S4.SS0.SSS0.Px2.p1.2.m2.1a"><mn id="S4.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">1500</mn><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.2.m2.1b"><cn id="S4.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" type="integer" xref="S4.SS0.SSS0.Px2.p1.2.m2.1.1">1500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.2.m2.1c">1500</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.2.m2.1d">1500</annotation></semantics></math>, <math alttext="110" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px2.p1.3.m3.1"><semantics id="S4.SS0.SSS0.Px2.p1.3.m3.1a"><mn id="S4.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS0.SSS0.Px2.p1.3.m3.1.1.cmml">110</mn><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p1.3.m3.1b"><cn id="S4.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" type="integer" xref="S4.SS0.SSS0.Px2.p1.3.m3.1.1">110</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p1.3.m3.1c">110</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px2.p1.3.m3.1d">110</annotation></semantics></math>의 예를 포함한다.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Metrics</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">우리는 원래 LegalBench <cite class="ltx_cite ltx_citemacro_cite">Guha et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib26" title="">2023</a>)</cite> 논문과 동일한 메트릭을 사용한다: 균형 잡힌 정확도. 균형 잡힌 정확도를 통해 두 벤치마크에 제시된 것과 같은 더 나은 불균형 분류 작업을 처리할 수 있다. 우리는 또한 MMLU의 법적 작업에 균형 잡힌 정확성을 사용한다. 달리 언급되지 않는 한, 이 섹션 전체에 걸쳐 보고된 임의의 점수는 균형 잡힌 정확도를 지칭한다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Setting</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="747" id="S5.F3.g1" src="https://arxiv.org/html/2403.03883v2/x3.png" width="747">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3:</span><span class="ltx_text ltx_font_bold" id="S5.F3.4.1">Performance of base models on LegalBench-Instruct. </span> 흥미롭게도, 명령어 미세 조정은 아니지만, <span class="ltx_text ltx_font_typewriter" id="S5.F3.5.2">SaulLM-7B</span>은 <span class="ltx_text ltx_font_typewriter" id="S5.F3.6.3">SaulLM-7B</span>의 초기 체크포인트(Mistral-7B)를 포함한 다른 기본 모델과 비교하여 벤치마크에서 인상적인 개선을 여전히 달성할 수 있다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Baselines</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.2"><span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.2.1">SaulLM-7B</span> 패밀리를 다른 최첨단 <math alttext="7" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><mn id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><cn id="S5.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S5.SS1.p1.1.m1.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">7</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">7</annotation></semantics></math>B 및 <math alttext="13" class="ltx_Math" display="inline" id="S5.SS1.p1.2.m2.1"><semantics id="S5.SS1.p1.2.m2.1a"><mn id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml">13</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><cn id="S5.SS1.p1.2.m2.1.1.cmml" type="integer" xref="S5.SS1.p1.2.m2.1.1">13</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">13</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.2.m2.1d">13</annotation></semantics></math>B 오픈 소스 모델과 비교한다. 구체적으로, 다음과 같은 명령어와 DPO finetuned variants of Mistral-7B <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib34" title="">2023</a>)</cite>: <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.2.2">Mistral-7B-Instruct-v0.1</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.2.3">Mistral-7B-Instruct-v0.2</span> 뿐만 아니라 <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.2.4">zephyr-7b-beta<span class="ltx_note ltx_role_footnote" id="footnote17"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_serif" id="footnote17.1.1.1">17</span></span><a class="ltx_ref ltx_url" href="https://huggingface.co/HuggingFaceH4/zephyr-7b-beta" title="">https://huggingface.co/HuggingFaceH4/zephyr-7b-beta</a></span></span></span></span>도 포함한다. 또한 Llama2 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib71" title="">2023a</a>)</cite> 패밀리, 보다 구체적으로 <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.2.5">Llama2-7b-Chat</span> 및 <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p1.2.6">Llama2-13b-Chat</span>을 평가한다.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Implementation Details</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Codebase</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p1.1">우리의 코드베이스는 플래시 어텐션 <cite class="ltx_cite ltx_citemacro_cite">Dao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib18" title="">2022</a>); Dao (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib17" title="">2023</a>)</cite>와 함께 DeepSpeed(level 3)를 활용하는 오픈 소스 프레임워크 <cite class="ltx_cite ltx_citemacro_cite">Shoeybi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib67" title="">2019</a>); Wolf et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib82" title="">2019</a>); Lhoest et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib40" title="">2021</a>)</cite>에 의존한다. PyTorch <cite class="ltx_cite ltx_citemacro_cite">Paszke et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#bib.bib58" title="">2019</a>)</cite>에 구축되었으며, 당사 모델은 Huggingface 허브에서 사용할 수 있습니다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Compute</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px2.p1.1">연속 프리트레이닝은 <math alttext="256" class="ltx_Math" display="inline" id="S5.SS2.SSS0.Px2.p1.1.m1.1"><semantics id="S5.SS2.SSS0.Px2.p1.1.m1.1a"><mn id="S5.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="S5.SS2.SSS0.Px2.p1.1.m1.1b"><cn id="S5.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" type="integer" xref="S5.SS2.SSS0.Px2.p1.1.m1.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.SSS0.Px2.p1.1.m1.1c">256</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.SSS0.Px2.p1.1.m1.1d">256</annotation></semantics></math> MI250 AMD GPU를 활용한다. 명령어 미세 조정을 위해 16 MI250에 걸쳐 워크로드 분산이 발생한다. 평가 절차는 단일 MI250에 대해 원활하게 수행된다.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">이 섹션에서는 주요 실험 결과와 결과에 대해 논의한다.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>LegalBench-Instruct</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S5.F3" title="Figure 3 ‣ 5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figures</span> <span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.F4" title="Figure 4 ‣ I. Legal continued pretraining brings significant improvements ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">4</span></a> summarize our results on LegalBench-Instruct. <math alttext="3" class="ltx_Math" display="inline" id="S6.SS1.p1.1.m1.1"><semantics id="S6.SS1.p1.1.m1.1a"><mn id="S6.SS1.p1.1.m1.1.1" xref="S6.SS1.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.1.m1.1b"><cn id="S6.SS1.p1.1.m1.1.1.cmml" type="integer" xref="S6.SS1.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.p1.1.m1.1d">3</annotation></semantics></math> main takeaways가 있는데, 이하에서 설명한다.</p>
</div>
<section class="ltx_paragraph" id="S6.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">I. Legal continued pretraining brings significant improvements</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS1.SSS0.Px1.p1.4">우리는 제안된 지속적인 사전 훈련의 영향을 분석하는 것으로 시작한다. <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S5.F3" title="Figure 3 ‣ 5 Experimental Setting ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">3</span></a>에서 볼 수 있듯이 <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px1.p1.4.1">SaulLM-7B</span>은 강력한 독립 실행형 모델입니다. 우리는 그 강력한 성능이 <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2403.03883v2#S3.SS1.SSS1" title="3.1.1 Dataset Composition ‣ 3.1 Legal Pretraining Corpora ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">subsubsection 3.1.1</span></a>에서 언급한 바와 같이 사전 훈련 데이터에서 명령어의 통합에 크게 기인한다고 추측한다. 그럼에도 불구하고, 우리는 여전히 전용 명령어 미세 조정 스테이지가 없더라도, <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px1.p1.4.2">SaulLM-7B</span>은 <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px1.p1.4.3">Llama2-7B-chat</span> (<math alttext="0.38" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="S6.SS1.SSS0.Px1.p1.1.m1.1a"><mn id="S6.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S6.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">0.38</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.1.m1.1b"><cn id="S6.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" type="float" xref="S6.SS1.SSS0.Px1.p1.1.m1.1.1">0.38</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.1.m1.1c">0.38</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px1.p1.1.m1.1d">0.38</annotation></semantics></math> v.s. <math alttext="0.39" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px1.p1.2.m2.1"><semantics id="S6.SS1.SSS0.Px1.p1.2.m2.1a"><mn id="S6.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S6.SS1.SSS0.Px1.p1.2.m2.1.1.cmml">0.39</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.2.m2.1b"><cn id="S6.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" type="float" xref="S6.SS1.SSS0.Px1.p1.2.m2.1.1">0.39</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.2.m2.1c">0.39</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px1.p1.2.m2.1d">0.39</annotation></semantics></math>)와 동등한 성능을 발휘한다는 점에 유의한다. 더 중요한 것은 <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px1.p1.4.4">SaulLM-7B</span>은 강력한 법적 기능을 가진 IFT 모델을 구축하기 위한 강력한 기본 모델 역할을 한다는 것이다. Generic instruction finetuning과 결합하면 <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.F4" title="Figure 4 ‣ I. Legal continued pretraining brings significant improvements ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">4</span></a>에서 볼 수 있듯이 <math alttext="0.59" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px1.p1.3.m3.1"><semantics id="S6.SS1.SSS0.Px1.p1.3.m3.1a"><mn id="S6.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S6.SS1.SSS0.Px1.p1.3.m3.1.1.cmml">0.59</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.3.m3.1b"><cn id="S6.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" type="float" xref="S6.SS1.SSS0.Px1.p1.3.m3.1.1">0.59</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.3.m3.1c">0.59</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px1.p1.3.m3.1d">0.59</annotation></semantics></math>, 즉 <math alttext="4" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px1.p1.4.m4.1"><semantics id="S6.SS1.SSS0.Px1.p1.4.m4.1a"><mn id="S6.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S6.SS1.SSS0.Px1.p1.4.m4.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px1.p1.4.m4.1b"><cn id="S6.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" type="integer" xref="S6.SS1.SSS0.Px1.p1.4.m4.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px1.p1.4.m4.1c">4</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px1.p1.4.m4.1d">4</annotation></semantics></math> 최고의 오픈 소스 명령 모델 <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px1.p1.4.5">Mistral-7B-Instruct-v0.1</span>의 강력한 평균을 달성한다.</p>
</div>
<figure class="ltx_figure" id="S6.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="465" id="S6.F4.g1" src="https://arxiv.org/html/2403.03883v2/x4.png" width="581">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 4:</span><span class="ltx_text ltx_font_bold" id="S6.F4.4.1">기본 모델의 영향. </span> 기본 모델 <span class="ltx_text ltx_font_typewriter" id="S6.F4.5.2">SaulLM-7B</span>에서 명령어 finetuning 시작은 Mistral-7B에 비해 눈에 띄는 개선을 가져옵니다. 실제로, 일반 IFT 믹스(법률 없음)에서도 <span class="ltx_text ltx_font_typewriter" id="S6.F4.6.3">SaulLM-7B</span> (Gen.)은 Mistral-Instruct 대응물을 크게 능가합니다. IFT 믹스에 법적 지침을 추가하면 결과가 더욱 향상됩니다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S6.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">II. Legal instruction finetuning further boosts the results</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS1.SSS0.Px2.p1.2"><a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S3.F2" title="Figure 2 ‣ Legal Instruction Construction ‣ 3.2 Instruction Finetuning Mixes ‣ 3 Data ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2</span></a>, finetuning <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px2.p1.2.1">SaulLM-7B</span> on the general and legal instructions (<span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px2.p1.2.2">SaulLM-7B-Instruct</span>) establishes a new state-of-the-art on the LegalBench-Instruct benchmark, with a average score of <math alttext="0.61" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px2.p1.1.m1.1"><semantics id="S6.SS1.SSS0.Px2.p1.1.m1.1a"><mn id="S6.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S6.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">0.61</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p1.1.m1.1b"><cn id="S6.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" type="float" xref="S6.SS1.SSS0.Px2.p1.1.m1.1.1">0.61</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p1.1.m1.1c">0.61</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px2.p1.1.m1.1d">0.61</annotation></semantics></math>, 즉, a <math alttext="11" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px2.p1.2.m2.1"><semantics id="S6.SS1.SSS0.Px2.p1.2.m2.1a"><mn id="S6.SS1.SSS0.Px2.p1.2.m2.1.1" xref="S6.SS1.SSS0.Px2.p1.2.m2.1.1.cmml">11</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px2.p1.2.m2.1b"><cn id="S6.SS1.SSS0.Px2.p1.2.m2.1.1.cmml" type="integer" xref="S6.SS1.SSS0.Px2.p1.2.m2.1.1">11</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px2.p1.2.m2.1c">11</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px2.p1.2.m2.1d">11</annotation></semantics></math>% relative improvement compared to the best open-source instruct model (<a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.F5" title="Figure 5 ‣ II. Legal instruction finetuning further boosts the results ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">5</span></a>). 마지막으로, DPO 정렬 모델은 명령 조정 대응 모델을 저성능화하는 경향이 있으며, 이는 일반 정렬이 LegalBench-Instruct에 존재하는 것과 같은 배포 외 작업에 적합하지 않다는 사실로 설명될 수 있다. 현재 작업의 범위를 벗어났지만 흥미로운 연구 방향은 법적 특정 DPO가 어떻게 도움이 될 수 있는지 탐구하는 것이다.</p>
</div>
<figure class="ltx_figure" id="S6.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="553" id="S6.F5.g1" src="https://arxiv.org/html/2403.03883v2/x5.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 5:</span><span class="ltx_text ltx_font_bold" id="S6.F5.3.1">Comparison of instruct models on LegalBench-Instruct</span>. <span class="ltx_text ltx_font_typewriter" id="S6.F5.4.2">SaulLM-7B-Instruct</span> establishes the state-of-the-art, outperforming the best Mistral-Instruct model by a significant 6 absolute points.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S6.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_portrait" height="1328" id="S6.F6.g1" src="https://arxiv.org/html/2403.03883v2/x6.png" width="498">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 6:</span><span class="ltx_text ltx_font_bold" id="S6.F6.4.1">Instruct models on Legal-MMLU. </span> Echoing finding on LegalBench-Instruct, <span class="ltx_text ltx_font_typewriter" id="S6.F6.5.2">SaulLM-7B-Instruct</span>은 Legal-MMLU의 세 가지 작업 모두에서 우수한 성능을 표시하며, <span class="ltx_text ltx_font_typewriter" id="S6.F6.6.3">Mistral-7B-Instruct-v0.1</span>과 관련하여 평균 절대 개선이 5포인트입니다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S6.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">III. There is still room for significant improvement.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S6.SS1.SSS0.Px3.p1.1">다음으로, <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px3.p1.1.1">SaulLM-7B-Instruct</span>의 성능을 따라 작업을 <math alttext="5" class="ltx_Math" display="inline" id="S6.SS1.SSS0.Px3.p1.1.m1.1"><semantics id="S6.SS1.SSS0.Px3.p1.1.m1.1a"><mn id="S6.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S6.SS1.SSS0.Px3.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.SSS0.Px3.p1.1.m1.1b"><cn id="S6.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" type="integer" xref="S6.SS1.SSS0.Px3.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.SSS0.Px3.p1.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="S6.SS1.SSS0.Px3.p1.1.m1.1d">5</annotation></semantics></math> 핵심 법적 능력으로 분할함으로써 <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.2">Issue Spotting</span>, <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.3">Rule-Recall</span>, <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.4">Interpretation</span>, <span class="ltx_text ltx_font_smallcaps" id="S6. 결과는 가장 법적 전문 지식을 필요로 하는 네 가지 영역에서 <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px3.p1.1.7">SaulLM-7B-Instruct</span>은 최고의 비법적 경쟁자 <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px3.p1.1.8">Issue</span>, <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.9">Rule</span>, <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.10">Interpretation</span> 및 <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3 반면 <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px3.p1.1.13">Mistral-7B-Instruct-v0.1</span> <span class="ltx_text ltx_font_smallcaps" id="S6.SS1.SSS0.Px3.p1.1.14">Conclusion</span> 작업에는 미치지 못하며, 이는 흥미롭게도 실제 법률 지식보다 훨씬 더 순수한 연역적 추론이 필요하다. 우리는 수학 데이터 세트를 포함하지만 이에 국한되지 않는 더 많은 연역적 추론 내용으로 사전 훈련 및 미세 조정 말뭉치를 늘리면 격차를 줄이고 <span class="ltx_text ltx_font_typewriter" id="S6.SS1.SSS0.Px3.p1.1.15">SaulLM-7B-Instruct</span>의 잠재력을 완전히 풀 수 있다고 추측한다.</p>
</div>
<figure class="ltx_figure" id="S6.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="627" id="S6.F7.g1" src="https://arxiv.org/html/2403.03883v2/x7.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 7:</span><span class="ltx_text ltx_font_bold" id="S6.F7.3.1">Per-task performance breakdown. <span> <span class="ltx_text ltx_font_typewriter" id="S6.F7.4.2">SaulLM-7B-Instruct</span>은 일반 명령 모델을 크게 능가하지만 법적 특정 지식을 가장 필요로 하지만 결론 작업에 대해 Mistral-Instruct에 의해 능가하므로 더 많은 연역적 추론이 필요합니다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Results on Legal-MMLU</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.2">LegalBench-Instruct에 대한 관찰을 확인하기 위해 <a class="ltx_ref" href="https://arxiv.org/html/2403.03883v2#S6.F6" title="Figure 6 ‣ II. Legal instruction finetuning further boosts the results ‣ 6.1 LegalBench-Instruct ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">6</span></a>에 표시된 Legal-MMLU에 대한 결과를 분석한다. 다시, <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p1.2.1">SaulLM-7B-Instruct</span>은 <math alttext="3" class="ltx_Math" display="inline" id="S6.SS2.p1.1.m1.1"><semantics id="S6.SS2.p1.1.m1.1a"><mn id="S6.SS2.p1.1.m1.1.1" xref="S6.SS2.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.1.m1.1b"><cn id="S6.SS2.p1.1.m1.1.1.cmml" type="integer" xref="S6.SS2.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p1.1.m1.1d">3</annotation></semantics></math>와 <math alttext="4" class="ltx_Math" display="inline" id="S6.SS2.p1.2.m2.1"><semantics id="S6.SS2.p1.2.m2.1a"><mn id="S6.SS2.p1.2.m2.1.1" xref="S6.SS2.p1.2.m2.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.2.m2.1b"><cn id="S6.SS2.p1.2.m2.1.1.cmml" type="integer" xref="S6.SS2.p1.2.m2.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.2.m2.1c">4</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p1.2.m2.1d">4</annotation></semantics></math> 절대값 사이의 차이가 세 가지 작업에 걸쳐 최고의 7B 오픈 소스 경쟁자를 가리키며, <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p1.2.2">SaulLM-7B-Instruct</span>이 법적 워크플로에 맞춘 모델을 빌드하는 강력한 기반이라는 추가 증거를 제공합니다.</p>
</div>
<figure class="ltx_figure" id="S6.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="622" id="S6.F8.g1" src="https://arxiv.org/html/2403.03883v2/x8.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8:</span><span class="ltx_text ltx_font_bold" id="S6.F8.17.1">Perplexity on legal documents for prerained backbones. </span> <span class="ltx_text ltx_font_typewriter" id="S6.F8.18.2">SaulLM-7B-Instruct</span>은 대부분의 유형의 법률 문서에서 다른 사전 훈련된 백본을 능가하지만 <span class="ltx_text ltx_font_typewriter" id="S6.F8.19.3">Llama2-7b</span> on Legislation에 의해 능가한다.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span><span class="ltx_text ltx_font_bold" id="S6.F8.17.1">Perplexity on legal documents for pretrained backbones.</span> <span class="ltx_text ltx_font_typewriter" id="S6.F8.18.2">SaulLM-7B-Instruct</span> outperforms other pretrained backbones on most types of legal documents, but is outperformed by <span class="ltx_text ltx_font_typewriter" id="S6.F8.19.3">Llama2-7b</span> on Legislation.
<span class="ltx_text ltx_font_typewriter" id="S6.F8.20.4">SaulLM-7B-Instruct</span> exhibits a median perplexity of <math alttext="8.69" class="ltx_Math" display="inline" id="S6.F8.6.m1.1"><semantics id="S6.F8.6.m1.1b"><mn id="S6.F8.6.m1.1.1" xref="S6.F8.6.m1.1.1.cmml">8.69</mn><annotation-xml encoding="MathML-Content" id="S6.F8.6.m1.1c"><cn id="S6.F8.6.m1.1.1.cmml" type="float" xref="S6.F8.6.m1.1.1">8.69</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.6.m1.1d">8.69</annotation><annotation encoding="application/x-llamapun" id="S6.F8.6.m1.1e">8.69</annotation></semantics></math>, having a reduction of <math alttext="5.5" class="ltx_Math" display="inline" id="S6.F8.7.m2.1"><semantics id="S6.F8.7.m2.1b"><mn id="S6.F8.7.m2.1.1" xref="S6.F8.7.m2.1.1.cmml">5.5</mn><annotation-xml encoding="MathML-Content" id="S6.F8.7.m2.1c"><cn id="S6.F8.7.m2.1.1.cmml" type="float" xref="S6.F8.7.m2.1.1">5.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.7.m2.1d">5.5</annotation><annotation encoding="application/x-llamapun" id="S6.F8.7.m2.1e">5.5</annotation></semantics></math> percent compared to <span class="ltx_text ltx_font_typewriter" id="S6.F8.21.5">Mistral-7B</span>, <math alttext="9.20" class="ltx_Math" display="inline" id="S6.F8.8.m3.1"><semantics id="S6.F8.8.m3.1b"><mn id="S6.F8.8.m3.1.1" xref="S6.F8.8.m3.1.1.cmml">9.20</mn><annotation-xml encoding="MathML-Content" id="S6.F8.8.m3.1c"><cn id="S6.F8.8.m3.1.1.cmml" type="float" xref="S6.F8.8.m3.1.1">9.20</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.8.m3.1d">9.20</annotation><annotation encoding="application/x-llamapun" id="S6.F8.8.m3.1e">9.20</annotation></semantics></math>, and <math alttext="10.8" class="ltx_Math" display="inline" id="S6.F8.9.m4.1"><semantics id="S6.F8.9.m4.1b"><mn id="S6.F8.9.m4.1.1" xref="S6.F8.9.m4.1.1.cmml">10.8</mn><annotation-xml encoding="MathML-Content" id="S6.F8.9.m4.1c"><cn id="S6.F8.9.m4.1.1.cmml" type="float" xref="S6.F8.9.m4.1.1">10.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.9.m4.1d">10.8</annotation><annotation encoding="application/x-llamapun" id="S6.F8.9.m4.1e">10.8</annotation></semantics></math> percent compared to <span class="ltx_text ltx_font_typewriter" id="S6.F8.22.6">Llama2-7B</span>, with a median perplexity of <math alttext="9.74" class="ltx_Math" display="inline" id="S6.F8.10.m5.1"><semantics id="S6.F8.10.m5.1b"><mn id="S6.F8.10.m5.1.1" xref="S6.F8.10.m5.1.1.cmml">9.74</mn><annotation-xml encoding="MathML-Content" id="S6.F8.10.m5.1c"><cn id="S6.F8.10.m5.1.1.cmml" type="float" xref="S6.F8.10.m5.1.1">9.74</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.F8.10.m5.1d">9.74</annotation><annotation encoding="application/x-llamapun" id="S6.F8.10.m5.1e">9.74</annotation></semantics></math>.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Perplexity Analysis</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1"><span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.1.1">SaulLM-7B</span> 백본의 법적 도메인에 대한 적응을 평가하기 위해 계약, 법적 결정, 법률 및 당사자 제출의 4가지 문서 유형에 걸쳐 복잡성 점수를 제시한다. 결과는 <a class="ltx_ref ltx_refmacro_autoref" href="https://arxiv.org/html/2403.03883v2#S6.F8" title="Figure 8 ‣ 6.2 Results on Legal-MMLU ‣ 6 Results ‣ SaulLM-7B: A pioneering Large Language Model for Law"><span class="ltx_text ltx_ref_tag">Figure 8</span></a>를 참조한다. 우리의 모델인 <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.1.2">SaulLM-7B</span>은 모든 범주에서 <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.1.3">Mistral-7B</span>을 일관되게 능가하여 분산이 감소된 낮은 평균 복잡도 점수를 나타낸다. 흥미롭게도 <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.1.4">Llama2-7B</span>은 입법 문서에서 특히 더 낮은 복잡성을 보여주며, 이는 <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p1.1.5">Mistral-7B</span>에 비해 관련 말뭉치에서 입법 텍스트의 잠재적으로 더 높은 비율을 시사한다.</p>
</div>
<div class="ltx_para" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1">전반적으로 <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p2.1.1">Mistral-7B</span>과 비교할 때, 우리 모델은 <span class="ltx_text ltx_font_typewriter" id="S6.SS3.p2.1.2">Llama2-7B</span>과 비교할 때 법정 코퍼라 전체에서 3%의 중간 복잡도 감소와 11%의 중간 복잡도 감소를 보여준다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion &amp; Future Perspectives</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">본 논문에서는 법률 도메인 내에서 7B 모델과 비교하여 최신 성능을 제공하는 오픈 소스 디코더 모델인 <span class="ltx_text ltx_font_typewriter" id="S7.p1.1.1">SaulLM-7B</span>을 소개한다. 우리의 접근법은 합성 데이터 세트에 대한 지침 미세 조정과 함께 법률 데이터를 미세 조정하는 것을 수반한다. 또한, 정제된 버전의 LegalBench를 제공하고 복잡도 측정을 위한 새로운 문서 세트를 도입하여 기여합니다. MIT 라이선스로 출시되는 저희 모델이 오픈소스 생태계와 커뮤니티에 기여하기를 바랍니다.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">우리는 GENCI가 그들의 최첨단 컴퓨팅 자원에 대한 접근을 관대하게 허락해 준 것에 감사한다. 우리의 모델 <span class="ltx_text ltx_font_typewriter" id="Sx1.p1.1.1">SaulLM-7B</span>은 Jeanzay에 대해 수행된 초기 실험과 함께 ADASTRA에서 훈련되었다. HPC 자원의 활용은 장제이 보조금 101838, 103256, 103298과 아다스트라 보조금 C1615122, CAD14770, CAD15031을 통해 가능했다.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia&nbsp;Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2303.08774</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aletras et&nbsp;al. (2016)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Nikolaos Aletras, Dimitrios Tsarapatsanis, Daniel Preoţiuc-Pietro, and Vasileios Lampos. 2016.

</span>
<span class="ltx_bibblock">Predicting judicial decisions of the european court of human rights: A natural language processing perspective.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">PeerJ computer science</em>, 2:e93.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Almazrouei et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Mérouane Debbah, Étienne Goffinet, Daniel Hesslow, Julien Launay, Quentin Malartic, Daniele Mazzotta, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2311.16867" title="">The falcon series of open language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rohan Anil, Andrew&nbsp;M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Palm 2 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2305.10403</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu&nbsp;Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An&nbsp;Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2309.16609" title="">Qwen technical report</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biderman et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Stella Biderman, Hailey Schoelkopf, Quentin&nbsp;Gregory Anthony, Herbie Bradley, Kyle O’Brien, Eric Hallahan, Mohammad&nbsp;Aflah Khan, Shivanshu Purohit, USVSN&nbsp;Sai Prashanth, Edward Raff, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Pythia: A suite for analyzing large language models across training and scaling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">International Conference on Machine Learning</em>, pages 2397–2430. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Briakou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Eleftheria Briakou, Colin Cherry, and George Foster. 2023.

</span>
<span class="ltx_bibblock">Searching for needles in a haystack: On the role of incidental bilingualism in palm’s translation capability.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2305.10266</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Butler (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Umar Butler. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.57967/hf/1306" title="">Open australian legal corpus</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cao et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yihan Cao, Yanbin Kang, and Lichao Sun. 2023.

</span>
<span class="ltx_bibblock">Instruction mining: High-quality instruction data selection for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2307.06290</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chalkidis et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ilias Chalkidis, Ion Androutsopoulos, and Nikolaos Aletras. 2019.

</span>
<span class="ltx_bibblock">Neural legal judgment prediction in english.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:1906.02059</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chalkidis et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ilias Chalkidis, Manos Fergadiotis, Prodromos Malakasiotis, Nikolaos Aletras, and Ion Androutsopoulos. 2020.

</span>
<span class="ltx_bibblock">Legal-bert: The muppets straight out of law school.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2010.02559</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zeming Chen, Alejandro&nbsp;Hernández Cano, Angelika Romanou, Antoine Bonnet, Kyle Matoba, Francesco Salvi, Matteo Pagliardini, Simin Fan, Andreas Köpf, Amirkeivan Mohtashami, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Meditron-70b: Scaling medical pretraining for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2311.16079</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Daixuan Cheng, Shaohan Huang, and Furu Wei. 2023.

</span>
<span class="ltx_bibblock">Adapting large language models via reading comprehension.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2309.09530</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hyung&nbsp;Won Chung, Le&nbsp;Hou, Shayne Longpre, Barret Zoph, Yi&nbsp;Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2210.11416</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Computer (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Together Computer. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://github.com/togethercomputer/RedPajama-Data" title="">Redpajama: an open dataset for training large language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and Li&nbsp;Yuan. 2023.

</span>
<span class="ltx_bibblock">Chatlaw: Open-source legal large language model with integrated external knowledge bases.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2306.16092</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dao (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tri Dao. 2023.

</span>
<span class="ltx_bibblock">Flashattention-2: Faster attention with better parallelism and work partitioning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2307.08691</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dao et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tri Dao, Dan Fu, Stefano Ermon, Atri Rudra, and Christopher Ré. 2022.

</span>
<span class="ltx_bibblock">Flashattention: Fast and memory-efficient exact attention with io-awareness.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Advances in Neural Information Processing Systems</em>, 35:16344–16359.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong Sun, and Bowen Zhou. 2023.

</span>
<span class="ltx_bibblock">Enhancing chat language models by scaling high-quality instructional conversations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2305.14233</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elazar et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yanai Elazar, Akshita Bhagia, Ian Magnusson, Abhilasha Ravichander, Dustin Schwenk, Alane Suhr, Pete Walsh, Dirk Groeneveld, Luca Soldaini, Sameer Singh, Hanna Hajishirzi, Noah&nbsp;A. Smith, and Jesse Dodge. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.20707" title="">What’s in my big data?</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Faysse et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Manuel Faysse, Patrick Fernandes, Nuno Guerreiro, António Loison, Duarte Alves, Caio Corro, Nicolas Boizard, João Alves, Ricardo Rei, Pedro Martins, et&nbsp;al. 2024.

</span>
<span class="ltx_bibblock">Croissantllm: A truly bilingual french-english language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2402.00786</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Faysse et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Manuel Faysse, Gautier Viaud, Céline Hudelot, and Pierre Colombo. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.emnlp-main.559" title="">Revisiting instruction fine-tuned model evaluation to guide industrial applications</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. 2020.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2101.00027" title="">The pile: An 800gb dataset of diverse text for language modeling</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu and Dao (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Albert Gu and Tri Dao. 2023.

</span>
<span class="ltx_bibblock">Mamba: Linear-time sequence modeling with selective state spaces.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:2312.00752</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guha et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Neel Guha, Daniel&nbsp;E Ho, Julian Nyarko, and Christopher Ré. 2022.

</span>
<span class="ltx_bibblock">Legalbench: Prototyping a collaborative benchmark for legal reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2209.06120</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guha et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Neel Guha, Julian Nyarko, Daniel&nbsp;E Ho, Christopher Ré, Adam Chilton, Aditya Narayana, Alex Chohlas-Wood, Austin Peters, Brandon Waldon, Daniel&nbsp;N Rockmore, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Legalbench: A collaboratively built benchmark for measuring legal reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2308.11462</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gururangan et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz&nbsp;Beltagy, Doug Downey, and Noah&nbsp;A Smith. 2020.

</span>
<span class="ltx_bibblock">Don’t stop pretraining: Adapt language models to domains and tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2004.10964</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gutiérrez-Fandiño et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Asier Gutiérrez-Fandiño, Jordi Armengol-Estapé, Aitor Gonzalez-Agirre, and Marta Villegas. 2021.

</span>
<span class="ltx_bibblock">Spanish legalese language model and corpora.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2110.12201</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heafield (2011)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kenneth Heafield. 2011.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/W11-2123" title="">KenLM: Faster and smaller language model queries</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the Sixth Workshop on Statistical Machine Translation</em>, pages 187–197, Edinburgh, Scotland. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Henderson et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Peter Henderson, Mark Krass, Lucia Zheng, Neel Guha, Christopher&nbsp;D Manning, Dan Jurafsky, and Daniel Ho. 2022.

</span>
<span class="ltx_bibblock">Pile of law: Learning responsible data filtering from the law and a 256gb open-source legal dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Advances in Neural Information Processing Systems</em>, 35:29217–29234.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2020.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv preprint arXiv:2009.03300</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Islam et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Niful Islam, Debopom Sutradhar, Humaira Noor, Jarin&nbsp;Tasnim Raya, Monowara&nbsp;Tabassum Maisha, and Dewan&nbsp;Md Farid. 2023.

</span>
<span class="ltx_bibblock">Distinguishing human generated text from chatgpt generated text using machine learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2306.01761</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shaoxiong Ji, Tianlin Zhang, Kailai Yang, Sophia Ananiadou, Erik Cambria, and Jörg Tiedemann. 2023.

</span>
<span class="ltx_bibblock">Domain-specific continued pretraining of language models for capturing long context in mental health.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2304.10447</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Albert&nbsp;Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio&nbsp;Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven&nbsp;Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William&nbsp;El Sayed. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.06825" title="">Mistral 7b</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Albert&nbsp;Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Emma&nbsp;Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio&nbsp;Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven&nbsp;Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William&nbsp;El Sayed. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2401.04088" title="">Mixtral of experts</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Katz et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Daniel&nbsp;Martin Katz, Michael&nbsp;James Bommarito, Shang Gao, and Pablo Arredondo. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 passes the bar exam.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Available at SSRN 4389233</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kocetkov et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Denis Kocetkov, Raymond Li, Loubna&nbsp;Ben allal, Jia LI, Chenghao Mou, Yacine Jernite, Margaret Mitchell, Carlos&nbsp;Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Dzmitry Bahdanau, Leandro&nbsp;Von Werra, and Harm de&nbsp;Vries. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=pxpbTdUEpD" title="">The stack: 3 TB of permissively licensed source code</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Transactions on Machine Learning Research</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koehn (2005)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Philipp Koehn. 2005.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2005.mtsummit-papers.11" title="">Europarl: A parallel corpus for statistical machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of Machine Translation Summit X: Papers</em>, pages 79–86, Phuket, Thailand.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, and Nicholas Carlini. 2021.

</span>
<span class="ltx_bibblock">Deduplicating training data makes language models better.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">arXiv preprint arXiv:2107.06499</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lhoest et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Quentin Lhoest, Albert&nbsp;Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil, Julien Chaumond, Mariama Drame, Julien Plu, Lewis Tunstall, et&nbsp;al. 2021.

</span>
<span class="ltx_bibblock">Datasets: A community library for natural language processing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2109.02846</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Raymond Li, Loubna&nbsp;Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry&nbsp;Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh&nbsp;Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva&nbsp;Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn&nbsp;Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos&nbsp;Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von
Werra, and Harm de&nbsp;Vries. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2305.06161" title="">Starcoder: may the source be with you!</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lian et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wing Lian, Guan Wang, Bleys Goodson, Eugene Pentland, Austin Cook, Chanvichet Vong, and "Teknium". 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://https://huggingface.co/Open-Orca/SlimOrca" title="">Slimorca: An open dataset of gpt-4 augmented flan reasoning traces, with verification</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Licari and Comandè (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Daniele Licari and Giovanni Comandè. 2022.

</span>
<span class="ltx_bibblock">Italian-legal-bert: A pre-trained transformer language model for italian law.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">CEUR Workshop Proceedings (Ed.), The Knowledge Management for Law Workshop (KM4LAW)</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longpre et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shayne Longpre, Le&nbsp;Hou, Tu&nbsp;Vu, Albert Webson, Hyung&nbsp;Won Chung, Yi&nbsp;Tay, Denny Zhou, Quoc&nbsp;V Le, Barret Zoph, Jason Wei, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">The flan collection: Designing data and methods for effective instruction tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:2301.13688</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Keming Lu, Peter Potash, Xihui Lin, Yuwen Sun, Zihan Qian, Zheng Yuan, Tristan Naumann, Tianxi Cai, and Junwei Lu. 2023.

</span>
<span class="ltx_bibblock">Prompt discriminative language models for domain adaptation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Proceedings of the 5th Clinical Natural Language Processing Workshop</em>, pages 247–258.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yingwei Ma, Yue Liu, Yue Yu, Yuanliang Zhang, Yu&nbsp;Jiang, Changjian Wang, and Shanshan Li. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2309.16298" title="">At which training stage does code data help llms reasoning?</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martin et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lauren Martin, Nick Whitehouse, Stephanie Yiu, Lizzie Catterson, and Rivindu Perera. 2024.

</span>
<span class="ltx_bibblock">Better call gpt, comparing large language models against lawyers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">arXiv preprint arXiv:2401.16212</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCloskey and Cohen (1989)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Michael McCloskey and Neal&nbsp;J. Cohen. 1989.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/https://doi.org/10.1016/S0079-7421(08)60536-8" title="">Catastrophic interference in connectionist networks: The sequential learning problem</a>.

</span>
<span class="ltx_bibblock">volume&nbsp;24 of <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Psychology of Learning and Motivation</em>, pages 109–165. Academic Press.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher&nbsp;D Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock">Detectgpt: Zero-shot machine-generated text detection using probability curvature.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">arXiv preprint arXiv:2301.11305</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chenghao Mou, Chris Ha, Kenneth Enevoldsen, and Peiyuan Liu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.5281/zenodo.8364980" title="">Chenghaomou/text-dedup: Reference snapshot</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mukherjee et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, Hamid Palangi, and Ahmed Awadallah. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2306.02707" title="">Orca: Progressive learning from complex explanation traces of gpt-4</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Munos et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rémi Munos, Michal Valko, Daniele Calandriello, Mohammad&nbsp;Gheshlaghi Azar, Mark Rowland, Zhaohan&nbsp;Daniel Guo, Yunhao Tang, Matthieu Geist, Thomas Mesnard, Andrea Michi, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Nash learning from human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">arXiv preprint arXiv:2312.00886</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niklaus et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joel Niklaus, Ilias Chalkidis, and Matthias Stürmer. 2021.

</span>
<span class="ltx_bibblock">Swiss-judgment-prediction: A multilingual legal judgment prediction benchmark.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">arXiv preprint arXiv:2110.00806</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niklaus and Giofré (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joel Niklaus and Daniele Giofré. 2022.

</span>
<span class="ltx_bibblock">Budgetlongformer: Can we cheaply pretrain a sota legal language model from scratch?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">arXiv preprint arXiv:2211.17135</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niklaus and Giofré (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joel Niklaus and Daniele Giofré. 2023.

</span>
<span class="ltx_bibblock">Can we pretrain a sota legal language model on a budget from scratch?

</span>
<span class="ltx_bibblock">Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niklaus et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Joel Niklaus, Veton Matoshi, Matthias Stürmer, Ilias Chalkidis, and Daniel&nbsp;E. Ho. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2306.02069" title="">Multilegalpile: A 689gb multilingual legal corpus</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nishida et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kosuke Nishida, Kyosuke Nishida, Itsumi Saito, Hisako Asano, and Junji Tomita. 2019.

</span>
<span class="ltx_bibblock">Unsupervised domain adaptation of language models for reading comprehension.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">arXiv preprint arXiv:1911.10768</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paszke et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et&nbsp;al. 2019.

</span>
<span class="ltx_bibblock">Pytorch: An imperative style, high-performance deep learning library.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Advances in neural information processing systems</em>, 32.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Penedo et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. 2023.

</span>
<span class="ltx_bibblock">The refinedweb dataset for falcon llm: Outperforming curated corpora with web data, and web data only.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">arXiv preprint arXiv:2306.01116</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prakken (2013)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Henry Prakken. 2013.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">Logical tools for modelling legal argument: a study of defeasible reasoning in law</em>, volume&nbsp;32.

</span>
<span class="ltx_bibblock">Springer Science &amp; Business Media.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alec Radford, Jong&nbsp;Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2212.04356" title="">Robust speech recognition via large-scale weak supervision</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher&nbsp;D Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">arXiv preprint arXiv:2305.18290</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roziere et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing&nbsp;Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Code llama: Open foundation models for code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">arXiv preprint arXiv:2308.12950</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Savelka et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jaromir Savelka, Kevin&nbsp;D Ashley, Morgan&nbsp;A Gray, Hannes Westermann, and Huihui Xu. 2023.

</span>
<span class="ltx_bibblock">Explaining legal concepts with augmented large language models (gpt-4).

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">arXiv preprint arXiv:2306.09525</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scao et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Teven&nbsp;Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra&nbsp;Sasha Luccioni, François Yvon, Matthias Gallé, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Bloom: A 176b-parameter open-access multilingual language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">arXiv preprint arXiv:2211.05100</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhiqiang Shen, Tianhua Tao, Liqun Ma, Willie Neiswanger, Joel Hestness, Natalia Vassilieva, Daria Soboleva, and Eric Xing. 2023.

</span>
<span class="ltx_bibblock">Slimpajama-dc: Understanding data combinations for llm training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">arXiv preprint arXiv:2309.10818</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shoeybi et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. 2019.

</span>
<span class="ltx_bibblock">Megatron-lm: Training multi-billion parameter language models using model parallelism.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">arXiv preprint arXiv:1909.08053</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soboleva et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Daria Soboleva, Faisal Al-Khateeb, Robert Myers, Jacob&nbsp;R Steeves, Joel Hestness, and Nolan Dey. 2023.

</span>
<span class="ltx_bibblock">Slimpajama: A 627b token cleaned and deduplicated version of redpajama.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jingyuan Sun, Shaonan Wang, Jiajun Zhang, and Chengqing Zong. 2020.

</span>
<span class="ltx_bibblock">Distill and replay for continual language learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">Proceedings of the 28th international conference on computational linguistics</em>, pages 3569–3579.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taylor et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, Andrew Poulton, Viktor Kerkez, and Robert Stojnic. 2022.

</span>
<span class="ltx_bibblock">Galactica: A large language model for science.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">arXiv preprint arXiv:2211.09085</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et&nbsp;al. 2023a.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">arXiv preprint arXiv:2302.13971</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian&nbsp;Canton Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit&nbsp;Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric&nbsp;Michael Smith, Ranjan Subramanian, Xiaoqing&nbsp;Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian&nbsp;Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas
Scialom. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2307.09288" title="">Llama 2: Open foundation and fine-tuned chat models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tuggener et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Don Tuggener, Pius Von&nbsp;Däniken, Thomas Peetz, and Mark Cieliebak. 2020.

</span>
<span class="ltx_bibblock">Ledgar: A large-scale multi-label corpus for text classification of legal provisions in contracts.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">Proceedings of the Twelfth Language Resources and Evaluation Conference</em>, pages 1235–1241.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tunstall et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Zephyr: Direct distillation of lm alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">arXiv preprint arXiv:2310.16944</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">von Werra et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Leandro von Werra, Younes Belkada, Lewis Tunstall, Edward Beeching, Tristan Thrush, Nathan Lambert, and Shengyi Huang. 2020.

</span>
<span class="ltx_bibblock">Trl: Transformer reinforcement learning.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/huggingface/trl" title="">https://github.com/huggingface/trl</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vu et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Thuy-Trang Vu, Dinh Phung, and Gholamreza Haffari. 2020.

</span>
<span class="ltx_bibblock">Effective unsupervised domain adaptation with adversarially trained language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">arXiv preprint arXiv:2010.01739</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi&nbsp;Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah&nbsp;A Smith, Iz&nbsp;Beltagy, et&nbsp;al. 2023a.

</span>
<span class="ltx_bibblock">How far can camels go? exploring the state of instruction tuning on open resources.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">arXiv preprint arXiv:2306.04751</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah&nbsp;A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2212.10560" title="">Self-instruct: Aligning language models with self-generated instructions</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut&nbsp;Selvan Dhanasekaran, Atharva Naik, David Stap, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">arXiv preprint arXiv:2204.07705</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weber-Wulff et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Debora Weber-Wulff, Alla Anohina-Naumeca, Sonja Bjelobaba, Tomáš Foltỳnek, Jean Guerrero-Dib, Olumide Popoola, Petr Šigut, and Lorna Waddington. 2023.

</span>
<span class="ltx_bibblock">Testing of detection tools for ai-generated text.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">International Journal for Educational Integrity</em>, 19(1):26.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent&nbsp;Y Zhao, Kelvin Guu, Adams&nbsp;Wei Yu, Brian Lester, Nan Du, Andrew&nbsp;M Dai, and Quoc&nbsp;V Le. 2021.

</span>
<span class="ltx_bibblock">Finetuned language models are zero-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">arXiv preprint arXiv:2109.01652</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib82">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wolf et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et&nbsp;al. 2019.

</span>
<span class="ltx_bibblock">Huggingface’s transformers: State-of-the-art natural language processing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">arXiv preprint arXiv:1910.03771</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib83">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Minghao Wu, Thuy-Trang Vu, Lizhen Qu, George Foster, and Gholamreza Haffari. 2024.

</span>
<span class="ltx_bibblock">Adapting large language models for document-level machine translation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib83.1.1">arXiv preprint arXiv:2401.06468</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib84">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chaojun Xiao, Xueyu Hu, Zhiyuan Liu, Cunchao Tu, and Maosong Sun. 2021.

</span>
<span class="ltx_bibblock">Lawformer: A pre-trained language model for chinese legal long documents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">AI Open</em>, 2:79–84.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib85">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Haoran Xu, Young&nbsp;Jin Kim, Amr Sharaf, and Hany&nbsp;Hassan Awadalla. 2023.

</span>
<span class="ltx_bibblock">A paradigm shift in machine translation: Boosting translation performance of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">arXiv preprint arXiv:2309.11674</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib86">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yunzhi Yao, Shaohan Huang, Wenhui Wang, Li&nbsp;Dong, and Furu Wei. 2021.

</span>
<span class="ltx_bibblock">Adapt-and-distill: Developing small, fast and effective pretrained language models for domains.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">arXiv preprint arXiv:2106.13474</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib87">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu&nbsp;Zhang, James&nbsp;T Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023.

</span>
<span class="ltx_bibblock">Metamath: Bootstrap your own mathematical questions for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib87.1.1">arXiv preprint arXiv:2309.12284</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib88">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Peiyuan Zhang, Guangtao Zeng, Tianduo Wang, and Wei Lu. 2024.

</span>
<span class="ltx_bibblock">Tinyllama: An open-source small language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib88.1.1">arXiv preprint arXiv:2401.02385</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib89">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi&nbsp;Victoria Lin, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Opt: Open pre-trained transformer language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">arXiv preprint arXiv:2205.01068</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib90">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">arXiv preprint arXiv:2305.11206</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>

</div>


<div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated on Wed Dec 14 18:01:44 2022 by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button></body></html>