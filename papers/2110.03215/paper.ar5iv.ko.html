<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2110.03215] Towards Continual Knowledge Learning of Language Models</title><meta property="og:description" content="Large Language Models (LMs) are known to encode world knowledge in their parameters as they pretrain on a vast amount of web corpus, which is often utilized for performing knowledge-dependent downstream tasks such as q…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Towards Continual Knowledge Learning of Language Models">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Towards Continual Knowledge Learning of Language Models">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2110.03215">

<!--Generated on Wed Dec 14 17:43:02 2022 by LaTeXML (version 0.8.6) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.7.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.1.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Towards Continual Knowledge Learning of Language Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Joel Jang<sup id="id1.1.id1" class="ltx_sup">1</sup> Seonghyeon Ye<sup id="id2.2.id2" class="ltx_sup">1</sup>  Sohee Yang<sup id="id3.3.id3" class="ltx_sup">1</sup>  Joongbo Shin<sup id="id4.4.id4" class="ltx_sup">2</sup> 
<br class="ltx_break"><span id="id5.5.id5" class="ltx_text ltx_font_bold">Janghoon Han<sup id="id5.5.id5.1" class="ltx_sup">2</sup>  Gyeonghun Kim<sup id="id5.5.id5.2" class="ltx_sup">2</sup>  Stanley Jungkyu Choi<sup id="id5.5.id5.3" class="ltx_sup">2</sup>  Minjoon Seo<sup id="id5.5.id5.4" class="ltx_sup">1</sup></span> 
<br class="ltx_break"><sup id="id6.6.id6" class="ltx_sup">1</sup>KAIST AI <sup id="id7.7.id7" class="ltx_sup">2</sup>LG AI Research 
<br class="ltx_break"><span id="id8.8.id8" class="ltx_text ltx_font_typewriter">{joeljang,vano1205,sohee.yang,minjoon}@kaist.ac.kr</span> 
<br class="ltx_break"><span id="id9.9.id9" class="ltx_text ltx_font_typewriter">{jb.shin,janghoon.han,ghkayne.kim,stanleyjk.choi}@lgresearch.ai</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id10.id1">대용량 언어 모델(Large Language Models, LMs)은 방대한 양의 웹 코퍼스를 사전 훈련함에 따라 세계 지식을 매개변수에 인코딩하는 것으로 알려져 있으며, 이는 종종 질의 응답, 사실 확인 및 열린 대화와 같은 지식 의존적 다운스트림 작업을 수행하는 데 활용된다. 실제 시나리오에서 LMs에 저장된 세계 지식은 세계가 변화함에 따라 빠르게 구식이 될 수 있지만, 불변 지식을 보존하면서 치명적인 망각을 피하고 새로운 지식을 안정적으로 습득하는 것은 사소하지 않다. 커뮤니티를 지속적으로 변화하는 LMs의 더 나은 유지로 밀어붙이기 위해 우리는 연속 지식 학습(CKL)이라고 하는 새로운 연속 학습(CL) 문제를 공식화한다. 우리는 시간 불변 세계 지식의 보유, 오래된 지식의 업데이트 및 새로운 지식의 획득을 정량화하기 위해 새로운 벤치마크와 메트릭을 구성한다. 우리는 몇 가지 강력한 기준을 만들기 위해 문헌에서 적용 가능한 최근 방법을 채택한다. 광범위한 실험을 통해 CKL이 지식을 안정적으로 유지하고 동시에 학습하기 위해 매개변수 확장이 필요한 이전 CL 설정에서 해결되지 않은 고유한 문제를 나타냄을 발견했다. 지식 망각의 중요한 원인을 강조함으로써 CKL이 끊임없이 변화하는 LM을 더 잘 이해하고 훈련하는 데 도움이 되는 도전적이고 중요한 문제임을 보여준다. 우리의 결과를 재현하기 위한 벤치마크 데이터 세트, 모델 체크포인트 및 코드는 <a class="ltx_ref ltx_href" href="https://github.com/joeljang/continual-knowledge-learning" target="_blank" title="">this https URL</a>에서 사용할 수 있다.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.p1.1">최근 연구에 따르면 T5<cite class="ltx_cite ltx_citemacro_citep">(Raffel et al., <a class="ltx_ref" href="#bib.bib42" title="">2019</a>)</cite> 및 GPT-3<cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="#bib.bib2" title="">2020</a>)</cite>와 같은 대규모 언어 모델(LM)은 방대한 텍스트 <cite class="ltx_cite ltx_citemacro_citep">(Petroni et al., <a class="ltx_ref" href="#bib.bib37" title="">2019</a>)</cite>의 코퍼스에서 사전 훈련될 때 엄청난 양의 세계 지식을 매개변수에 저장할 수 있는 능력을 가지고 있다. 이러한 사전학습된 LMs들은 LAMA(LAnguage Model Analysis) 태스크<cite class="ltx_cite ltx_citemacro_citep">(Petroni et al., <a class="ltx_ref" href="#bib.bib37" title="">2019</a>)</cite>를 통해 어떠한 미세조정 없이 세계지식을 탐색할 때 지식베이스 역할을 할 수 있는 가능성을 보여주었으며, 슬롯충진을 통해 제로샷 방식으로 세계지식에 대한 LMs을 탐색해야 하며, 다양한 지식집중언어 태스크(KILT)<cite class="ltx_cite ltx_citemacro_citep">(Petroni et al., <a class="ltx_ref" href="#bib.bib38" title="">2021</a>)</cite>와 같은 질의응답, 지식가능한 오픈 다이얼로그에서 미세조정될 때 인코딩된 세계지식을 활용하는 유망한 결과를 보여주었다.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.p2.1">LMs에 저장된 세계 지식은 다양한 사용 사례를 가지고 있지만, 세계가 빠르게 변화함에 따라 빠르게 구식이 될 수 있으며 LMs는 이에 따라 내부 세계 지식을 자주 갱신해야 한다. 예를 들어, <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p2.1.1">new</span> "<span class="ltx_rule" style="width:28.5pt;height:0.3pt;background:black;display:inline-block;"></span><span class="ltx_text ltx_font_italic" id="S1.p2.1.2">won the US Election 2020</span> from the original T5 <cite class="ltx_cite ltx_citemacro_citep">(Raffel et al., <a class="ltx_ref" href="#bib.bib42" title="">2019</a>)</cite> from the C4 web corpus from April 2019.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>T5 was initially pretrained on the C4 dataset (about 750 GB), which is a cleansed dump of Common Crawl extracted from the web in April 2019.</span></span></span> 또한, 정보가 <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p2.1.3">updated</span>이었기 때문에 한 번 정확하다고 간주되었을 수 있는 정보는 더 이상 유효하지 않을 수 있습니다. 예를 들어, "<span class="ltx_text ltx_font_italic" id="S1.p2.1.4">Cristiano Ronaldo가 어떤 축구팀에서 뛰나요? 2021년 9월 <span class="ltx_text ltx_font_italic" id="S1.p2.1.5">Juventus</span>에서 <span class="ltx_text ltx_font_italic" id="S1.p2.1.6">Manchester United</span>으로 변경되었습니다. 한편, <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p2.1.7">time-invariant</span>과 같이 원본 말뭉치에서 학습한 정보는 "<span class="ltx_text ltx_font_italic" id="S1.p2.1.8">Barack Obama is born in Honolulu, Hawaii</span>이 LMs 내에서 변경되지 않아야 합니다.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.p3.1">중요함에도 불구하고 LM의 매개변수에 저장된 내부 세계 지식을 갱신하는 문제는 사소하지 않으며 다소 구체적인 설정에서만 탐구되었다. 예를 들어, 최근의 연구들은 개별 사실들 <cite class="ltx_cite ltx_citemacro_citep">(De Cao et al., <a class="ltx_ref" href="#bib.bib7" title="">2021</a>; Zhu et al., <a class="ltx_ref" href="#bib.bib59" title="">2020</a>; Dai et al., <a class="ltx_ref" href="#bib.bib5" title="">2021</a>)</cite>와 같은 특정 대상 지식을 수정하기 위해 제안되었다. <cite class="ltx_cite ltx_citemacro_citet">Dhingra et al. (<a class="ltx_ref" href="#bib.bib9" title="">2021</a>)</cite>는 텍스트와 타임스탬프를 공동으로 모델링하여 LMs를 시간적 지식베이스로 다루었다. 그러나 새로운 지식을 가진 코퍼스에 대한 지속적인 사전 훈련을 통해 LMs의 세계 지식을 보다 일반적이고 확장 가능한 방식으로 갱신하는 문제는 이전 연구에서 공식적으로 공식화되거나 탐색되지 않았다. 더욱이 커뮤니티는 새로운 정보에 대한 교육을 통해 LMs의 내부 지식이 어떻게 변화하는지를 체계적으로 연구하는 데 사용할 수 있는 벤치마크가 부족하다. 마지막으로, 규모에서 LMs의 지식을 효과적으로 갱신하기 위한 방법론은 아직 철저히 탐구되지 않았다.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="685" height="181" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 1:</span>Overview of the <span class="ltx_text ltx_font_smallcaps" id="S1.F1.16.1">Continual Knowledge Learning</span> benchmark. <span class="ltx_text ltx_font_smallcaps" id="S1.F1.17.2">InvariantLAMA</span>은 <span class="ltx_text ltx_font_italic" id="S1.F1.18.3">time-invariant</span> world knowledge gained from <math alttext="D_{0}" class="ltx_Math" display="inline" id="S1.F1.5.m1.1"><semantics id="S1.F1.5.m1.1b"><msub id="S1.F1.5.m1.1.1" xref="S1.F1.5.m1.1.1.cmml"><mi id="S1.F1.5.m1.1.1.2" xref="S1.F1.5.m1.1.1.2.cmml">D</mi><mn id="S1.F1.5.m1.1.1.3" xref="S1.F1.5.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S1.F1.5.m1.1c"><apply id="S1.F1.5.m1.1.1.cmml" xref="S1.F1.5.m1.1.1"><csymbol cd="ambiguous" id="S1.F1.5.m1.1.1.1.cmml" xref="S1.F1.5.m1.1.1">subscript</csymbol><ci id="S1.F1.5.m1.1.1.2.cmml" xref="S1.F1.5.m1.1.1.2">𝐷</ci><cn id="S1.F1.5.m1.1.1.3.cmml" type="integer" xref="S1.F1.5.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.5.m1.1d">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.5.m1.1e">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>이다. <span class="ltx_text ltx_font_smallcaps" id="S1.F1.19.4">UpdatedLAMA</span>은 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S1.F1.6.m2.1"><semantics id="S1.F1.6.m2.1b"><msub id="S1.F1.6.m2.1.1" xref="S1.F1.6.m2.1.1.cmml"><mi id="S1.F1.6.m2.1.1.2" xref="S1.F1.6.m2.1.1.2.cmml">D</mi><mn id="S1.F1.6.m2.1.1.3" xref="S1.F1.6.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S1.F1.6.m2.1c"><apply id="S1.F1.6.m2.1.1.cmml" xref="S1.F1.6.m2.1.1"><csymbol cd="ambiguous" id="S1.F1.6.m2.1.1.1.cmml" xref="S1.F1.6.m2.1.1">subscript</csymbol><ci id="S1.F1.6.m2.1.1.2.cmml" xref="S1.F1.6.m2.1.1.2">𝐷</ci><cn id="S1.F1.6.m2.1.1.3.cmml" type="integer" xref="S1.F1.6.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.6.m2.1d">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.6.m2.1e">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> →<math alttext="D_{1}" class="ltx_Math" display="inline" id="S1.F1.7.m3.1"><semantics id="S1.F1.7.m3.1b"><msub id="S1.F1.7.m3.1.1" xref="S1.F1.7.m3.1.1.cmml"><mi id="S1.F1.7.m3.1.1.2" xref="S1.F1.7.m3.1.1.2.cmml">D</mi><mn id="S1.F1.7.m3.1.1.3" xref="S1.F1.7.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S1.F1.7.m3.1c"><apply id="S1.F1.7.m3.1.1.cmml" xref="S1.F1.7.m3.1.1"><csymbol cd="ambiguous" id="S1.F1.7.m3.1.1.1.cmml" xref="S1.F1.7.m3.1.1">subscript</csymbol><ci id="S1.F1.7.m3.1.1.2.cmml" xref="S1.F1.7.m3.1.1.2">𝐷</ci><cn id="S1.F1.7.m3.1.1.3.cmml" type="integer" xref="S1.F1.7.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.7.m3.1d">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.7.m3.1e">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>로부터 <span class="ltx_text ltx_font_italic" id="S1.F1.20.5">update</span> of world knowledge from <math alttext="D_{0}" class="ltx_Math" display="inline" id="S1.F1.6.m2.1"><semantics id="S1.F1.6.m2.1b"><msub id="S1.F1.6.m2.1.1" xref="S1.F1.6.m2.1.1.cmml"><mi id="S1.F1.6.m2.1.1.2" xref="S1.F1.6.m2.1.1.2.cmml">D</mi><mn id="S1.F1.6.m2.1.1.3" xref="S1.F1.6.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S1.F1.6.m2.1c"><apply id="S1.F1.6.m2.1.1.cmml" xref="S1.F1.6.m2.1.1"><csymbol cd="ambiguous" id="S1.F1.6.m2.1.1.1.cmml" xref="S1.F1.6.m2.1.1">subscript</csymbol><ci id="S1.F1.6.m2.1.1.2.cmml" xref="S1.F1.6.m2.1.1.2">𝐷</ci><cn id="S1.F1.6.m2.1.1.3.cmml" type="integer" xref="S1.F1.6.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.6.m2.1d">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.6.m2.1e">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> →<math alttext="D_{1}" class="ltx_Math" display="inline" id="S1.F1.7.m3.1"><semantics id="S1.F1.7.m3.1b"><msub id="S1.F1.7.m3.1.1" xref="S1.F1.7.m3.1.1.cmml"><mi id="S1.F1.7.m3.1.1.2" xref="S1.F1.7.m3.1.1.2.cmml">D</mi><mn id="S1.F1.7.m3.1.1.3" xref="S1.F1.7.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S1.F1.7.m3.1c"><apply id="S1.F1.7.m3.1.1.cmml" xref="S1.F1.7.m3.1.1"><csymbol cd="ambiguous" id="S1.F1.7.m3.1.1.1.cmml" xref="S1.F1.7.m3.1.1">subscript</csymbol><ci id="S1.F1.7.m3.1.1.2.cmml" xref="S1.F1.7.m3.1.1.2">𝐷</ci><cn id="S1.F1.7.m3.1.1.3.cmml" type="integer" xref="S1.F1.7.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.7.m3.1d">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.7.m3.1e">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> <span class="ltx_text ltx_font_smallcaps" id="S1.F1.21.6">NewLAMA</span>은 <span class="ltx_text ltx_font_italic" id="S1.F1.22.7">new</span> world knowledge gained from <math alttext="D_{1}" class="ltx_Math" display="inline" id="S1.F1.8.m4.1"><semantics id="S1.F1.8.m4.1b"><msub id="S1.F1.8.m4.1.1" xref="S1.F1.8.m4.1.1.cmml"><mi id="S1.F1.8.m4.1.1.2" xref="S1.F1.8.m4.1.1.2.cmml">D</mi><mn id="S1.F1.8.m4.1.1.3" xref="S1.F1.8.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S1.F1.8.m4.1c"><apply id="S1.F1.8.m4.1.1.cmml" xref="S1.F1.8.m4.1.1"><csymbol cd="ambiguous" id="S1.F1.8.m4.1.1.1.cmml" xref="S1.F1.8.m4.1.1">subscript</csymbol><ci id="S1.F1.8.m4.1.1.2.cmml" xref="S1.F1.8.m4.1.1.2">𝐷</ci><cn id="S1.F1.8.m4.1.1.3.cmml" type="integer" xref="S1.F1.8.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.8.m4.1d">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S1.F1.8.m4.1e">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>를 측정하는데 사용된다.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.p4.1">본 논문에서는 <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.1">Continual Knowledge Learning (CKL)</span>이라는 새로운 Continual Learning (CL) 공식을 제안한다. 여기서 우리는 새로운 말뭉치에 대한 지속적인 사전 훈련을 통해 LM의 내부 세계 지식을 갱신하려고 시도한다. 세계 지식을 세 가지 주요 범주로 체계적으로 분류하고 CKL 동안 각각을 측정하기 위한 벤치마크 데이터 세트를 만듭니다. (1) <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.2">InvariantLAMA</span> <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p4.1.3">time-invariant</span> LMs에서 세계 지식은 잊혀지거나 변경되지 않아야 합니다. (2) <span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S1.p4.1.4">UpdatedLAMA</span> LMs에서 <span class="ltx_text ltx_font_bold ltx_font_italic" id="S1.p4.1.5">updated</span> 그리고 (3) <span class="ltx_text ltx_font_smallcaps" id=" 또한 <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.8">FUAR</span><span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.9">(<span class="ltx_text ltx_font_bold" id="S1.p4.1.9.1">F</span>orgotten / (<span class="ltx_text ltx_font_bold" id="S1.p4.1.9.2">U</span>pdated + <span class="ltx_text ltx_font_bold" id="S1.p4.1.9.3">A</span>cquired) <span class="ltx_text ltx_font_bold" id="S1.p4.1.9.4">R</span>atio)</span>이라는 새로운 메트릭을 제안하여 망각, 업데이트 및 지식 획득 간의 마지막으로, 이 벤치마크에 대한 현대 CL 방법을 구현하는 것을 생각할 수 있지만 CKL이 전통적인 CL 공식과 사소한 차이가 있고 CKL에 특정한 접근법이 필요함을 보여준다. 모델 아키텍처와 훈련 방법론 <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="#bib.bib3" title="">2020</a>; He et al., <a class="ltx_ref" href="#bib.bib17" title="">2021</a>; Hu et al., <a class="ltx_ref" href="#bib.bib19" title="">2021</a>; Wang et al., <a class="ltx_ref" href="#bib.bib52" title="">2021b</a>)</cite>를 사전 훈련 중에 얻은 지식의 망각을 완화하여 CKL 벤치마크의 기준선으로 설정할 수 있는 가능성을 보여준 문헌에서 찾고 비교한다.</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.p5.1">요약하면, LM의 내부 세계 지식을 갱신하는 문제는 실제 시나리오에서 필수적이지만 아직 공식화되거나 광범위하게 탐구되지 않았다. 따라서, 본 논문에서는:</p>
</div>
<div id="S1.p6" class="ltx_para ltx_noindent">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.I1.i1.p1.1">본 논문에서는 <span class="ltx_text ltx_font_smallcaps" id="S1.I1.i1.p1.1.1">Continual Knowledge Learning (CKL)</span>이라는 새로운 CL 공식을 제안하고, 새로운 지식을 포함하는 새로운 언어 모델링 코퍼스에 대한 지속적인 사전 훈련으로 얻은 세계 지식의 양과 망각의 양을 측정하기 위한 새로운 벤치마크를 구성한다.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.I1.i2.p1.1">우리는 문헌에서 CKL의 기본 기준이 되는 LM 아키텍처와 훈련 방법론을 탐색하고, 이를 CKL 방법으로 표시하고, 우리의 CKL 벤치마크에 대해 광범위한 실험을 수행한다. 기존 CL 문헌과 동일한 정규화, 리허설 및 매개변수 확장 방법으로 분류하고 잊혀진 지식과 업데이트되거나 획득된 지식 간의 트레이드오프를 측정하기 위해 제안하는 <span class="ltx_text ltx_font_smallcaps" id="S1.I1.i2.p1.1.1">FUAR</span>이라는 새로운 메트릭을 사용하여 각 유형의 방법의 효과를 비교한다.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.I1.i3.p1.1">지속적으로 변화하는 LM을 만들기 위해 CKL 벤치마크에서 광범위한 분석을 수행하고 중요한 과제 및 결과를 강조한다. 매개변수 확장 방법은 대부분의 실험에서 최선을 다했지만 메모리 비효율성의 한계를 가지고 있으며 지속적인 사전 훈련 동안 동일한 데이터를 반복적으로 보는 것은 망각의 중요한 원인이다. 또한, 새로운 지식의 망각과 학습의 균형을 맞추기 위해 학습률이 달라질 수 있고, CKL은 새로운 세계 지식을 얻은 후 이전 지식 집약적인 작업을 수행하는 데 도움이 될 수 있으며, CKL 방법은 성능의 다른 추세를 보여도 LM 아키텍처 간에 전이할 수 있다는 흥미로운 결과를 보여준다.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S1.p6.1">제안된 CKL 벤치마크의 개요는 그림 <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>에 나와 있다.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.p1.1">RAG( Retrieval-Augmented Generation) <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="#bib.bib28" title="">2020a</a>)</cite> 및 Blender Bot 2.0 <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="#bib.bib54" title="">2021</a>; Komeili et al., <a class="ltx_ref" href="#bib.bib23" title="">2021</a>)</cite>와 같은 외부 소스로부터 지식을 활용하는 언어 모델(LMs)은 추론 중 외부 소스를 업데이트하거나 최근 정보를 검색하기 위해 인터넷을 검색함으로써 변화하는 세계에 대처한다. 그러나 최근 연구에 따르면 이러한 메모리 증강 모델은 <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">hallucination</span>으로 고통 받고 있으며, 이는 추론 중 업데이트된 지식이 주어졌음에도 불구하고 잘못된 정보를 올바른 것처럼 제시한다는 것을 의미한다. <cite class="ltx_cite ltx_citemacro_citep">(Zhang &amp; Choi, <a class="ltx_ref" href="#bib.bib58" title="">2021</a>)</cite>는 LM 크기가 증가함에 따라 악화되어 암시적 매개 변수도 갱신되는 데 더 중요하다.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.p2.1">LLM의 내부 지식을 갱신하기 위해 전체 위키피디아의 최근 덤프와 같이 초기 사전 훈련 동안 사용된 것과 유사한 스케일의 새로 업데이트된 텍스트 코퍼스로 LM을 처음부터 사전 훈련하는 것을 고려할 수 있다. 그러나, 이 접근법은 계산상 까다롭고 또한 환경적으로 유해한 <cite class="ltx_cite ltx_citemacro_citep">(Patterson et al., <a class="ltx_ref" href="#bib.bib36" title="">2021</a>)</cite>이다. 또 다른 대안적인 접근법은 새로운 세계 지식을 포함하는 훨씬 더 작은 코퍼스에 대한 사전 훈련 프로세스를 계속하는 것이지만, 그러한 방법론은 모델이 새로운 지식을 획득함에 따라 이전에 학습된 지식을 잊어버리는 <span class="ltx_text ltx_font_italic" id="S2.p2.1.1">catastrophic forgetting</span> <cite class="ltx_cite ltx_citemacro_citep">(McCloskey &amp; Cohen, <a class="ltx_ref" href="#bib.bib35" title="">1989</a>; Kirkpatrick et al., <a class="ltx_ref" href="#bib.bib22" title="">2017</a>)</cite>로 고통받는 것으로 알려져 있다.</p>
</div>
<div id="S2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.p3.1"><cite class="ltx_cite ltx_citemacro_citet">Lazaridou et al. (<a class="ltx_ref" href="#bib.bib25" title="">2021</a>); Jin et al. (<a class="ltx_ref" href="#bib.bib20" title="">2021</a>)</cite>는 이 문제를 해결하기 위해 사전 Continual Learning (CL) 방법 <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a class="ltx_ref" href="#bib.bib46" title="">2020</a>; d’Autume et al., <a class="ltx_ref" href="#bib.bib6" title="">2019</a>)</cite>를 구현하는 것을 제안한다. 그러나, 전통적인 CL 방법을 적용하는 것이 부적절하게 만드는 전통적인 CL(Continual Knowledge Learning) 공식과 제안된 CKD(Continual Knowledge Learning) 공식 사이에는 자명한 차이가 있다는 점에 유의하는 것이 중요하다. 전통적인 CL에서 메서드는 크게 <span class="ltx_text ltx_font_italic" id="S2.p3.1.1">regularization</span>, <span class="ltx_text ltx_font_italic" id="S2.p3.1.2">rehearsal</span>, <span class="ltx_text ltx_font_italic" id="S2.p3.1.3">parameter-expansion</span> 메서드로 분류할 수 있다. (1) 정규화 방법들 <cite class="ltx_cite ltx_citemacro_citep">(Kirkpatrick et al., <a class="ltx_ref" href="#bib.bib22" title="">2017</a>)</cite>는 이전 작업들에 사용되는 중요한 파라미터들을 식별하는 것을 필요로 하지만, 정확히 어떻게 그리고 어디서 LM의 파라미터들에 지식이 저장되는지는 현재 <cite class="ltx_cite ltx_citemacro_citep">(Vig et al., <a class="ltx_ref" href="#bib.bib50" title="">2020</a>; De Cao et al., <a class="ltx_ref" href="#bib.bib7" title="">2021</a>)</cite>를 식별하고 로컬화하는 것이 매우 어렵다. (2) 사전 리허설 방법<cite class="ltx_cite ltx_citemacro_citep">(Lopez-Paz &amp; Ranzato, <a class="ltx_ref" href="#bib.bib34" title="">2017</a>)</cite>는 태스크의 모든 스트림을 한 번에 학습(다중 태스크 학습)하는 것을 성능 상한으로 간주하고 이러한 설정을 에피소드 메모리에 저장된 샘플로 복제하지만, 사전 훈련 말뭉치의 일부 샘플은 말뭉치의 전체 세계 지식을 나타낼 수 없다. 더욱이, LMs가 말뭉치의 흐름의 섞인 연결에서 사전 훈련된다면, 특히 전자의 말뭉치가 후자의 말뭉치보다 훨씬 더 큰 경우에, LMs가 최근의 말뭉치로부터 정확한, 최근의 정보를 획득할 것이라는 보장은 없으며, 이는 섹션 <a class="ltx_ref" href="#S5.SS1" title="5.1 Main Results ‣ 5 Experimental Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">5.1</span></a>의 실험에 의해 보여진다. (3) 마지막으로, 사전 파라미터-확장 방법들 <cite class="ltx_cite ltx_citemacro_citep">(Rusu et al., <a class="ltx_ref" href="#bib.bib44" title="">2016</a>; Yoon et al., <a class="ltx_ref" href="#bib.bib56" title="">2018</a>)</cite> focus on <em class="ltx_emph ltx_font_italic" id="S2.p3.1.4">learning a stream of different tasks via strong supervision</em>인 반면, CKL에서 focus on <em class="ltx_emph ltx_font_italic" id="S2.p3.1.5">constantly updating world knowledge from a stream of corpora via self-supervision</em>이다.</p>
</div>
<div id="S2.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.p4.1">이러한 근본적인 차이 때문에 위에서 언급한 현대 CL 방법 대신 CKL 방법으로 필요에 따라 각 방법을 수정하고 적응시키는 CKL <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="#bib.bib3" title="">2020</a>; He et al., <a class="ltx_ref" href="#bib.bib17" title="">2021</a>; Hu et al., <a class="ltx_ref" href="#bib.bib19" title="">2021</a>; Wang et al., <a class="ltx_ref" href="#bib.bib52" title="">2021b</a>)</cite>에 적합한 문헌의 방법론을 탐구한다. 마지막으로, 전통적인 CL 공식 중 일부는 <cite class="ltx_cite ltx_citemacro_citet">Prabhu et al. (<a class="ltx_ref" href="#bib.bib40" title="">2020</a>)</cite>에 의해 실제 시나리오에서 실질적인 중요성이 거의 없을 수 있다는 지적이 있었지만, CKL은 CL의 초기 동기에 훨씬 더 가깝다. 즉, "자연 지능의 기본 특성은 오래된 것에 대한 정보를 업데이트하면서 새로운 지식을 지속적으로 배우는 능력" <cite class="ltx_cite ltx_citemacro_citep">(Prabhu et al., <a class="ltx_ref" href="#bib.bib40" title="">2020</a>)</cite>이다. 전통적인 CL 방법과 CKL 방법이 근본적인 차이를 해결하는 방법에 관한 관련 작업의 세부 사항은 부록 <a class="ltx_ref" href="#A1" title="Appendix A Extension of Related Works ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">A</span></a>에 나와 있다.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Continual Knowledge Learning (CKL)</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.p1.1">이 절에서는 태스크의 공식화, 데이터 구성 프로세스, 그리고 이전 세계 지식을 잊는 것과 새로운 세계 지식의 업데이트 및 학습 사이의 트레이드오프를 측정하는 제안된 메트릭에 대해 설명한다.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Task Formulation</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p1.2">LMs의 내부 지식을 갱신하는 작업을 CL 공식 중 하나로 볼 때, 원래 말뭉치에 대한 사전 훈련은 <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.2.1">previous task</span>으로 간주할 수 있고, 새로운 말뭉치에 대한 계속된 사전 훈련은 <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.2.2">current task</span>으로 간주할 수 있다. 주 목적은 <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.2.3">time-invariant</span> 초기 사전 훈련을 통해 얻은 세계 지식을 유지하면서 효율적으로 <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.2.4">new</span> 및 <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.2.5">updated</sp 논문 전반에서 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><msub id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">D</mi><mn id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">𝐷</ci><cn id="S3.SS1.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>는 초기 사전 훈련에 사용된 말뭉치를 의미하고 <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">D</mi><mn id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">𝐷</ci><cn id="S3.SS1.p1.2.m2.1.1.3.cmml" type="integer" xref="S3.SS1.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>는 계속 사전 훈련에 사용된 새로운 말뭉치를 의미한다.</p>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">New Text Corpus for Language Modeling</h5>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.6">LM이 내부 지식을 갱신하기 위해서는 업데이트되고 새로운 정보가 있는 새로운 텍스트 코퍼스 <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS1.SSS0.Px1.p1.1.m1.1a"><msub id="S3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.1.m1.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>에서 지속적으로 사전 훈련되어야 한다. <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.2.m2.1"><semantics id="S3.SS1.SSS0.Px1.p1.2.m2.1a"><msub id="S3.SS1.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.2.m2.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.2.m2.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>는 이상적으로는 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.3.m3.1"><semantics id="S3.SS1.SSS0.Px1.p1.3.m3.1a"><msub id="S3.SS1.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.3.m3.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.3.m3.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>보다 훨씬 작아야 하는데, 큰 <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.4.m4.1"><semantics id="S3.SS1.SSS0.Px1.p1.4.m4.1a"><msub id="S3.SS1.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.4.m4.1b"><apply id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.4.m4.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.4.m4.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>가 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.5.m5.1"><semantics id="S3.SS1.SSS0.Px1.p1.5.m5.1a"><msub id="S3.SS1.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.5.m5.1b"><apply id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.5.m5.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.5.m5.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>의 크기에 걸맞게 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.5.m5.1"><semantics id="S3.SS1.SSS0.Px1.p1.5.m5.1a"><msub id="S3.SS1.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.5.m5.1b"><apply id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.5.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.5.m5.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.5.m5.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>는 처음부터 LMs를 사전 훈련하는 것과 유사한 막대한 계산 비용을 초래할 것이다. <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px1.p1.6.m6.1"><semantics id="S3.SS1.SSS0.Px1.p1.6.m6.1a"><msub id="S3.SS1.SSS0.Px1.p1.6.m6.1.1" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px1.p1.6.m6.1b"><apply id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px1.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px1.p1.6.m6.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px1.p1.6.m6.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>를 구성하기 위해 <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px1.p1.6.1">CC-RecentNews</span>을 만드는 웹에서 최근에 게시된 뉴스 기사를 크롤링합니다. <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</sup><span class="ltx_text ltx_font_smallcaps" id="footnote2.2">CC-RecentNews</span>은 221,779개의 기사(<span class="ltx_text" id="footnote2.1" style="position:relative; bottom:0.7pt;"><math alttext="\scriptstyle\sim" class="ltx_Math" display="inline" id="footnote2.1.1.m1.1"><semantics id="footnote2.1.1.m1.1b"><mo id="footnote2.1.1.m1.1.1" mathsize="70%" xref="footnote2.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="footnote2.1.1.m1.1c"><csymbol cd="latexml" id="footnote2.1.1.m1.1.1.cmml" xref="footnote2.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="footnote2.1.1.m1.1d">\scriptstyle\sim</annotation><annotation encoding="application/x-llamapun" id="footnote2.1.1.m1.1e">∼</annotation></semantics></math></span>168M tokens)로 구성되어 있으며, 이는 C4보다 약 750배 더 작은 것으로 추정되며, 초기에 T5 LM <cite class="ltx_cite ltx_citemacro_citep">(Raffel et al., <a class="ltx_ref" href="#bib.bib42" title="">2019</a>)</cite>를 사전 훈련하기 위해 사용되었던 4월 2019 Common Crawl 데이터셋(<a class="ltx_ref ltx_href" href="https://commoncrawl.org/" target="_blank" title="">https://commoncrawl.org/</a>)의 클렌징된 버전 </span></span></span></p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Probing LMs for World Knowledge</h5>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.1">세계지식에 대한 LMs 탐사를 위해 가장 널리 사용되는 작업은 LAMA(LAnguage Model Analysis) <cite class="ltx_cite ltx_citemacro_citep">(Petroni et al., <a class="ltx_ref" href="#bib.bib37" title="">2019</a>)</cite> 작업으로, 수동으로 정의된 템플릿을 사용하여 지식 소스 집합에서 생성된 클로즈 문장으로 구성된다. LM <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px2.p1.1.1">knows</span> a fact is successfully to predict a zero-shot manner in the cloze sentence,"<span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px2.p1.1.2">Dante is born in <span class="ltx_rule" style="width:28.5pt;height:0.3pt;background:black;display:inline-block;"></span></span>” as <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px2.p1.1.3">Florence</span>. LMs<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>Closed-book question answering (CBQA) <cite class="ltx_cite ltx_citemacro_citep">(Roberts et al., <a class="ltx_ref" href="#bib.bib43" title="">2020</a>)</cite> can also be considered as a task that measures the world knowledge of LMs through finetuning, but it has been pointed out that much of its performance increases are due to the test-train overlap <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="#bib.bib29" title="">2020b</a>; Wang et al., <a class="ltx_ref" href="#bib.bib51" title="">2021a</a>)</cite> in the datasets.</span></span></span>에 인코딩된 세계 지식을 측정하기 위한 다른 대안이 있을 수 있지만, 주요 데이터 세트를 LAMA 태스크로 구성하는 동시에 CBQA를 테스트하려는 사람들을 위해 해당 질문 쌍을 클로즈 문장에 추가로 제공한다.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Measuring Retention of Time-invariant World Knowledge</h5>

<div id="S3.SS1.SSS0.Px3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.SSS0.Px3.p1.5">우리는 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px3.p1.5.1">time-invariant</span> 세계 지식을 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p1.1.m1.1"><semantics id="S3.SS1.SSS0.Px3.p1.1.m1.1a"><msub id="S3.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.1.m1.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px3.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>의 정보와 충돌할 가능성이 없는 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p1.1.m1.1"><semantics id="S3.SS1.SSS0.Px3.p1.1.m1.1a"><msub id="S3.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px3.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.1.m1.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px3.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>에 존재하는 정보로 정의한다. 예를 들어, <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px3.p1.5.2">Barack Obama의birthplace</span>이 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p1.3.m3.1"><semantics id="S3.SS1.SSS0.Px3.p1.3.m3.1a"><msub id="S3.SS1.SSS0.Px3.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.2" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.3.m3.1b"><apply id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px3.p1.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.3.m3.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px3.p1.3.m3.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>에 존재하는 경우, <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p1.4.m4.1"><semantics id="S3.SS1.SSS0.Px3.p1.4.m4.1a"><msub id="S3.SS1.SSS0.Px3.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.2" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.4.m4.1b"><apply id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px3.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.4.m4.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px3.p1.4.m4.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>가 그 사실과 모순되는 정보를 포함할 가능성은 낮다. 또한 타임 스탬프가 고정된 인스턴스를 "<span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px3.p1.5.3">Cristiano Ronaldo played for <span class="ltx_rule" style="width:28.5pt;height:0.3pt;background:black;display:inline-block;"></span> in 2010.</span> as <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px3.p1.5.4">time-invariant</span>로 분류한다. 이러한 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px3.p1.5.5">time-invariant</span> 인스턴스는 LMs가 <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px3.p1.5.m5.1"><semantics id="S3.SS1.SSS0.Px3.p1.5.m5.1a"><msub id="S3.SS1.SSS0.Px3.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px3.p1.5.m5.1.1.cmml"><mi id="S3.SS1.SSS0.Px3.p1.5.m5.1.1.2" xref="S3.SS1.SSS0.Px3.p1.5.m5.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px3.p1.5.m5.1.1.3" xref="S3.SS1.SSS0.Px3.p1.5.m5.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px3.p1.5.m5.1b"><apply id="S3.SS1.SSS0.Px3.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px3.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px3.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px3.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px3.p1.5.m5.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px3.p1.5.m5.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px3.p1.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px3.p1.5.m5.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px3.p1.5.m5.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>에서 지속적으로 사전 훈련됨에 따라 변경되지 않아야 합니다. 계속된 사전 훈련 동안 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px3.p1.5.6">time-invariant</span> 정보가 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px3.p1.5.7">catastrophic forgetting</span>로 인해 손실되는 정도를 측정하기 위해 <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px3.p1.5.8">InvariantLAMA</span>, LAMA<cite class="ltx_cite ltx_citemacro_citep">(Petroni et al., <a class="ltx_ref" href="#bib.bib37" title="">2019</a>)</cite>의 하위 집합만 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px3.p1.5.9">time-invariant</span> 클로즈 문장 부록 <a class="ltx_ref" href="#A2.SS1" title="B.1 Time-invariant relations of LAMA ‣ Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">B.1</span></a>에 자세히 설명되어</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Measuring Update of Outdated World Knowledge</h5>

<div id="S3.SS1.SSS0.Px4.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.SSS0.Px4.p1.11">본 연구에서는 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px4.p1.11.1">outdated</span> 세계 지식을 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px4.p1.1.m1.1"><semantics id="S3.SS1.SSS0.Px4.p1.1.m1.1a"><msub id="S3.SS1.SSS0.Px4.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS0.Px4.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px4.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px4.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px4.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px4.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p1.1.m1.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px4.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>와 <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px4.p1.2.m2.1"><semantics id="S3.SS1.SSS0.Px4.p1.2.m2.1a"><msub id="S3.SS1.SSS0.Px4.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS0.Px4.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px4.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px4.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px4.p1.2.m2.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px4.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p1.2.m2.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px4.p1.2.m2.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> 사이에 상충되는 정보로 정의한다. 예를 들어, 미국의 대통령은 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px4.p1.11.2">Barack Obama</span> in <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px4.p1.3.m3.1"><semantics id="S3.SS1.SSS0.Px4.p1.3.m3.1a"><msub id="S3.SS1.SSS0.Px4.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px4.p1.3.m3.1.1.cmml"><mi id="S3.SS1.SSS0.Px4.p1.3.m3.1.1.2" xref="S3.SS1.SSS0.Px4.p1.3.m3.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px4.p1.3.m3.1.1.3" xref="S3.SS1.SSS0.Px4.p1.3.m3.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p1.3.m3.1b"><apply id="S3.SS1.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px4.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p1.3.m3.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px4.p1.3.m3.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px4.p1.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p1.3.m3.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px4.p1.3.m3.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> 및 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px4.p1.11.3">Joe Biden</span> in <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px4.p1.4.m4.1"><semantics id="S3.SS1.SSS0.Px4.p1.4.m4.1a"><msub id="S3.SS1.SSS0.Px4.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px4.p1.4.m4.1.1.cmml"><mi id="S3.SS1.SSS0.Px4.p1.4.m4.1.1.2" xref="S3.SS1.SSS0.Px4.p1.4.m4.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px4.p1.4.m4.1.1.3" xref="S3.SS1.SSS0.Px4.p1.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p1.4.m4.1b"><apply id="S3.SS1.SSS0.Px4.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px4.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p1.4.m4.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px4.p1.4.m4.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px4.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p1.4.m4.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px4.p1.4.m4.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>일 수 있다. 이 경우 LM은 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px4.p1.11.4">Joe Biden</span> as the US president. LM이 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px4.p1.5.m5.1"><semantics id="S3.SS1.SSS0.Px4.p1.5.m5.1a"><msub id="S3.SS1.SSS0.Px4.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px4.p1.5.m5.1.1.cmml"><mi id="S3.SS1.SSS0.Px4.p1.5.m5.1.1.2" xref="S3.SS1.SSS0.Px4.p1.5.m5.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px4.p1.5.m5.1.1.3" xref="S3.SS1.SSS0.Px4.p1.5.m5.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p1.5.m5.1b"><apply id="S3.SS1.SSS0.Px4.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px4.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p1.5.m5.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px4.p1.5.m5.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px4.p1.5.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p1.5.m5.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px4.p1.5.m5.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>와 <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px4.p1.6.m6.1"><semantics id="S3.SS1.SSS0.Px4.p1.6.m6.1a"><msub id="S3.SS1.SSS0.Px4.p1.6.m6.1.1" xref="S3.SS1.SSS0.Px4.p1.6.m6.1.1.cmml"><mi id="S3.SS1.SSS0.Px4.p1.6.m6.1.1.2" xref="S3.SS1.SSS0.Px4.p1.6.m6.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px4.p1.6.m6.1.1.3" xref="S3.SS1.SSS0.Px4.p1.6.m6.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p1.6.m6.1b"><apply id="S3.SS1.SSS0.Px4.p1.6.m6.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p1.6.m6.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px4.p1.6.m6.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p1.6.m6.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px4.p1.6.m6.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px4.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p1.6.m6.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px4.p1.6.m6.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> 모두에서 동시에 사전 훈련되는 경우, 특히 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px4.p1.8.m8.1"><semantics id="S3.SS1.SSS0.Px4.p1.8.m8.1a"><msub id="S3.SS1.SSS0.Px4.p1.8.m8.1.1" xref="S3.SS1.SSS0.Px4.p1.8.m8.1.1.cmml"><mi id="S3.SS1.SSS0.Px4.p1.8.m8.1.1.2" xref="S3.SS1.SSS0.Px4.p1.8.m8.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px4.p1.8.m8.1.1.3" xref="S3.SS1.SSS0.Px4.p1.8.m8.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p1.8.m8.1b"><apply id="S3.SS1.SSS0.Px4.p1.8.m8.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p1.8.m8.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.8.m8.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px4.p1.8.m8.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p1.8.m8.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px4.p1.8.m8.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px4.p1.8.m8.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p1.8.m8.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px4.p1.8.m8.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>가 <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px4.p1.9.m9.1"><semantics id="S3.SS1.SSS0.Px4.p1.9.m9.1a"><msub id="S3.SS1.SSS0.Px4.p1.9.m9.1.1" xref="S3.SS1.SSS0.Px4.p1.9.m9.1.1.cmml"><mi id="S3.SS1.SSS0.Px4.p1.9.m9.1.1.2" xref="S3.SS1.SSS0.Px4.p1.9.m9.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px4.p1.9.m9.1.1.3" xref="S3.SS1.SSS0.Px4.p1.9.m9.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p1.9.m9.1b"><apply id="S3.SS1.SSS0.Px4.p1.9.m9.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p1.9.m9.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.9.m9.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px4.p1.9.m9.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p1.9.m9.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px4.p1.9.m9.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px4.p1.9.m9.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p1.9.m9.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px4.p1.9.m9.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>보다 훨씬 큰 경우, LM이 <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px4.p1.7.m7.1"><semantics id="S3.SS1.SSS0.Px4.p1.7.m7.1a"><msub id="S3.SS1.SSS0.Px4.p1.7.m7.1.1" xref="S3.SS1.SSS0.Px4.p1.7.m7.1.1.cmml"><mi id="S3.SS1.SSS0.Px4.p1.7.m7.1.1.2" xref="S3.SS1.SSS0.Px4.p1.7.m7.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px4.p1.7.m7.1.1.3" xref="S3.SS1.SSS0.Px4.p1.7.m7.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p1.7.m7.1b"><apply id="S3.SS1.SSS0.Px4.p1.7.m7.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p1.7.m7.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px4.p1.7.m7.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p1.7.m7.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px4.p1.7.m7.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px4.p1.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p1.7.m7.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px4.p1.7.m7.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>로부터 정확한 최근 정보를 획득할 것이라는 보장은 없으며, 이는 CKL과 전통적인 CL 설정의 가장 큰 차이 중 하나이다. 구식 정보의 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px4.p1.11.5">update</span> 측정을 위해, 우리는 <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px4.p1.11.6">UpdatedLAMA</span>을 구성하며, 이는 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px4.p1.10.m10.1"><semantics id="S3.SS1.SSS0.Px4.p1.10.m10.1a"><msub id="S3.SS1.SSS0.Px4.p1.10.m10.1.1" xref="S3.SS1.SSS0.Px4.p1.10.m10.1.1.cmml"><mi id="S3.SS1.SSS0.Px4.p1.10.m10.1.1.2" xref="S3.SS1.SSS0.Px4.p1.10.m10.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px4.p1.10.m10.1.1.3" xref="S3.SS1.SSS0.Px4.p1.10.m10.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p1.10.m10.1b"><apply id="S3.SS1.SSS0.Px4.p1.10.m10.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p1.10.m10.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.10.m10.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px4.p1.10.m10.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p1.10.m10.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px4.p1.10.m10.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px4.p1.10.m10.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p1.10.m10.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px4.p1.10.m10.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>와 <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px4.p1.11.m11.1"><semantics id="S3.SS1.SSS0.Px4.p1.11.m11.1a"><msub id="S3.SS1.SSS0.Px4.p1.11.m11.1.1" xref="S3.SS1.SSS0.Px4.p1.11.m11.1.1.cmml"><mi id="S3.SS1.SSS0.Px4.p1.11.m11.1.1.2" xref="S3.SS1.SSS0.Px4.p1.11.m11.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px4.p1.11.m11.1.1.3" xref="S3.SS1.SSS0.Px4.p1.11.m11.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px4.p1.11.m11.1b"><apply id="S3.SS1.SSS0.Px4.p1.11.m11.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px4.p1.11.m11.1.1.1.cmml" xref="S3.SS1.SSS0.Px4.p1.11.m11.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px4.p1.11.m11.1.1.2.cmml" xref="S3.SS1.SSS0.Px4.p1.11.m11.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px4.p1.11.m11.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px4.p1.11.m11.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px4.p1.11.m11.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px4.p1.11.m11.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> 모두에서 답을 찾을 수 있지만 상충된다.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Measuring Acquisition of New World Knowledge</h5>

<div id="S3.SS1.SSS0.Px5.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.SSS0.Px5.p1.7"><span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px5.p1.7.1">new</span> world knowledge as the information as the <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px5.p1.1.m1.1"><semantics id="S3.SS1.SSS0.Px5.p1.1.m1.1a"><msub id="S3.SS1.SSS0.Px5.p1.1.m1.1.1" xref="S3.SS1.SSS0.Px5.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS0.Px5.p1.1.m1.1.1.2" xref="S3.SS1.SSS0.Px5.p1.1.m1.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px5.p1.1.m1.1.1.3" xref="S3.SS1.SSS0.Px5.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px5.p1.1.m1.1b"><apply id="S3.SS1.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS0.Px5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px5.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS0.Px5.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px5.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS0.Px5.p1.1.m1.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px5.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px5.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px5.p1.1.m1.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px5.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>에는 존재하지만 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px5.p1.2.m2.1"><semantics id="S3.SS1.SSS0.Px5.p1.2.m2.1a"><msub id="S3.SS1.SSS0.Px5.p1.2.m2.1.1" xref="S3.SS1.SSS0.Px5.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS0.Px5.p1.2.m2.1.1.2" xref="S3.SS1.SSS0.Px5.p1.2.m2.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px5.p1.2.m2.1.1.3" xref="S3.SS1.SSS0.Px5.p1.2.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px5.p1.2.m2.1b"><apply id="S3.SS1.SSS0.Px5.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS0.Px5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px5.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS0.Px5.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px5.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS0.Px5.p1.2.m2.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px5.p1.2.m2.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px5.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px5.p1.2.m2.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px5.p1.2.m2.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>에는 존재하지 않는다. <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px5.p1.7.2">new</span> <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px5.p1.3.m3.1"><semantics id="S3.SS1.SSS0.Px5.p1.3.m3.1a"><msub id="S3.SS1.SSS0.Px5.p1.3.m3.1.1" xref="S3.SS1.SSS0.Px5.p1.3.m3.1.1.cmml"><mi id="S3.SS1.SSS0.Px5.p1.3.m3.1.1.2" xref="S3.SS1.SSS0.Px5.p1.3.m3.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px5.p1.3.m3.1.1.3" xref="S3.SS1.SSS0.Px5.p1.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px5.p1.3.m3.1b"><apply id="S3.SS1.SSS0.Px5.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS0.Px5.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px5.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS0.Px5.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px5.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS0.Px5.p1.3.m3.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px5.p1.3.m3.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px5.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px5.p1.3.m3.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px5.p1.3.m3.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>에 대한 계속된 사전 훈련을 통해 획득한 지식을 측정하기 위해 <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px5.p1.7.3">NewLAMA</span>은 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px5.p1.7.4">new</span>의 지식을 <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px5.p1.4.m4.1"><semantics id="S3.SS1.SSS0.Px5.p1.4.m4.1a"><msub id="S3.SS1.SSS0.Px5.p1.4.m4.1.1" xref="S3.SS1.SSS0.Px5.p1.4.m4.1.1.cmml"><mi id="S3.SS1.SSS0.Px5.p1.4.m4.1.1.2" xref="S3.SS1.SSS0.Px5.p1.4.m4.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px5.p1.4.m4.1.1.3" xref="S3.SS1.SSS0.Px5.p1.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px5.p1.4.m4.1b"><apply id="S3.SS1.SSS0.Px5.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS0.Px5.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px5.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS0.Px5.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px5.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS0.Px5.p1.4.m4.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px5.p1.4.m4.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px5.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px5.p1.4.m4.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px5.p1.4.m4.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>에서 정확하게 대답해야 합니다. <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px5.p1.7.5">new world knowledge</span>: <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px5.p1.7.6">NewLAMA</span>은 각 인스턴스가 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px5.p1.5.m5.1"><semantics id="S3.SS1.SSS0.Px5.p1.5.m5.1a"><msub id="S3.SS1.SSS0.Px5.p1.5.m5.1.1" xref="S3.SS1.SSS0.Px5.p1.5.m5.1.1.cmml"><mi id="S3.SS1.SSS0.Px5.p1.5.m5.1.1.2" xref="S3.SS1.SSS0.Px5.p1.5.m5.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px5.p1.5.m5.1.1.3" xref="S3.SS1.SSS0.Px5.p1.5.m5.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px5.p1.5.m5.1b"><apply id="S3.SS1.SSS0.Px5.p1.5.m5.1.1.cmml" xref="S3.SS1.SSS0.Px5.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px5.p1.5.m5.1.1.1.cmml" xref="S3.SS1.SSS0.Px5.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px5.p1.5.m5.1.1.2.cmml" xref="S3.SS1.SSS0.Px5.p1.5.m5.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px5.p1.5.m5.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px5.p1.5.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px5.p1.5.m5.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px5.p1.5.m5.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px5.p1.6.m6.1"><semantics id="S3.SS1.SSS0.Px5.p1.6.m6.1a"><msub id="S3.SS1.SSS0.Px5.p1.6.m6.1.1" xref="S3.SS1.SSS0.Px5.p1.6.m6.1.1.cmml"><mi id="S3.SS1.SSS0.Px5.p1.6.m6.1.1.2" xref="S3.SS1.SSS0.Px5.p1.6.m6.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px5.p1.6.m6.1.1.3" xref="S3.SS1.SSS0.Px5.p1.6.m6.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px5.p1.6.m6.1b"><apply id="S3.SS1.SSS0.Px5.p1.6.m6.1.1.cmml" xref="S3.SS1.SSS0.Px5.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px5.p1.6.m6.1.1.1.cmml" xref="S3.SS1.SSS0.Px5.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px5.p1.6.m6.1.1.2.cmml" xref="S3.SS1.SSS0.Px5.p1.6.m6.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px5.p1.6.m6.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px5.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px5.p1.6.m6.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px5.p1.6.m6.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>, <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px5.p1.7.7">NewLAMA-Easy</span>는 각 인스턴스가 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px5.p1.7.8">new</span>의 엄격한 정의를 완벽하게 준수하지 않는 경우 생성 프로세스로 인해 세계 지식을 측정하지만 일반적으로 <math alttext="D_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS0.Px5.p1.7.m7.1"><semantics id="S3.SS1.SSS0.Px5.p1.7.m7.1a"><msub id="S3.SS1.SSS0.Px5.p1.7.m7.1.1" xref="S3.SS1.SSS0.Px5.p1.7.m7.1.1.cmml"><mi id="S3.SS1.SSS0.Px5.p1.7.m7.1.1.2" xref="S3.SS1.SSS0.Px5.p1.7.m7.1.1.2.cmml">D</mi><mn id="S3.SS1.SSS0.Px5.p1.7.m7.1.1.3" xref="S3.SS1.SSS0.Px5.p1.7.m7.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS0.Px5.p1.7.m7.1b"><apply id="S3.SS1.SSS0.Px5.p1.7.m7.1.1.cmml" xref="S3.SS1.SSS0.Px5.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS0.Px5.p1.7.m7.1.1.1.cmml" xref="S3.SS1.SSS0.Px5.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.SSS0.Px5.p1.7.m7.1.1.2.cmml" xref="S3.SS1.SSS0.Px5.p1.7.m7.1.1.2">𝐷</ci><cn id="S3.SS1.SSS0.Px5.p1.7.m7.1.1.3.cmml" type="integer" xref="S3.SS1.SSS0.Px5.p1.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS0.Px5.p1.7.m7.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS0.Px5.p1.7.m7.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px5.p1.7.9">NewLAMA-Easy</span>은 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px5.p1.7.10">easier</span>으로 간주할 수 있는데, 이는 각 인스턴스가 계속된 프리트레이닝 동안 보이는 데이터 분포와 유사하도록 구성되었기 때문이다.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Dataset Construction</h5>

<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1:</span>Dataset statistics. 입력 및 답변 길이는 해당 평균 토큰 길이입니다.</figcaption>
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="S3.T1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T1.1.1.2.1" class="ltx_text ltx_font_bold">Size</span></td>
<td id="S3.T1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T1.1.1.3.1" class="ltx_text ltx_font_bold">Input Length</span></td>
<td id="S3.T1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T1.1.1.4.1" class="ltx_text ltx_font_bold">Answer Length</span></td>
<td id="S3.T1.1.1.5" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T1.1.1.5.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="S3.T1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T1.1.1.6.1" class="ltx_text ltx_font_bold">Size</span></td>
<td id="S3.T1.1.1.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T1.1.1.7.1" class="ltx_text ltx_font_bold">Input Length</span></td>
<td id="S3.T1.1.1.8" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T1.1.1.8.1" class="ltx_text ltx_font_bold">Answer Length</span></td>
</tr>
<tr id="S3.T1.1.2" class="ltx_tr">
<td id="S3.T1.1.2.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T1.1.2.1.1" class="ltx_text ltx_font_smallcaps">InvariantLAMA</span></td>
<td id="S3.T1.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">17474</td>
<td id="S3.T1.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">11.9</td>
<td id="S3.T1.1.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">1.3</td>
<td id="S3.T1.1.2.5" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T1.1.2.5.1" class="ltx_text ltx_font_smallcaps">NewLAMA</span></td>
<td id="S3.T1.1.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">797</td>
<td id="S3.T1.1.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">14.7</td>
<td id="S3.T1.1.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">8.7</td>
</tr>
<tr id="S3.T1.1.3" class="ltx_tr">
<td id="S3.T1.1.3.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T1.1.3.1.1" class="ltx_text ltx_font_smallcaps">UpdatedLAMA</span></td>
<td id="S3.T1.1.3.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">924</td>
<td id="S3.T1.1.3.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">13.7</td>
<td id="S3.T1.1.3.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:3.0pt;padding-right:3.0pt;">9.4</td>
<td id="S3.T1.1.3.5" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S3.T1.1.3.5.1" class="ltx_text ltx_font_smallcaps">NewLAMA-Easy</span></td>
<td id="S3.T1.1.3.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">11177</td>
<td id="S3.T1.1.3.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">44.4</td>
<td id="S3.T1.1.3.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">6.1</td>
</tr>
</tbody></table>
</figure>
<div id="S3.SS1.SSS0.Px6.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.SSS0.Px6.p1.1">연속 프리트레이닝을 위한 데이터 <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px6.p1.1.1">CC-RecentNews</span>은 news-please <cite class="ltx_cite ltx_citemacro_citep">(Hamborg et al., <a class="ltx_ref" href="#bib.bib16" title="">2017</a>)</cite>를 사용하여 구성된다. <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px6.p1.1.2">InvariantLAMA</span>은 수동으로 28 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px6.p1.1.3">time-invariant</span> relations from T-Rex <cite class="ltx_cite ltx_citemacro_citep">(Elsahar et al., <a class="ltx_ref" href="#bib.bib11" title="">2018</a>)</cite>를 선택하여 구성한다. <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px6.p1.1.4">UpdatedLAMA</span> 및 <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px6.p1.1.5">NewLAMA</span>의 경우 Amazon Mechanical Turk (mturk)<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_href" href="https://www.mturk.com" target="_blank" title="">https://www.mturk.com</a></span></span></span> for crowd-sourcing Human Intelligent Tasks (HITs). 이 과정은 <cite class="ltx_cite ltx_citemacro_citet">Lewis et al. (<a class="ltx_ref" href="#bib.bib30" title="">2021</a>)</cite>에 소개된 모델에 의해 생성된 질문 목록에서 답변 가능한 질문을 선택하여 클로즈 문장으로 변환해야 한다. 또한 11명의 전문가를 별도로 고용하여 정확성을 확인하고 C4 데이터베이스를 검색하여 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px6.p1.1.6">updated</span> 및 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS0.Px6.p1.1.7">new</span>의 정의에 따라 각 인스턴스를 분류했습니다. <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px6.p1.1.8">NewLAMA-Easy</span>은 새로운 정보를 포함하는 기사로부터 선택된 문장이 마스킹되기 전에 탈맥락화되고 패러프레이즈된 <span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Decontextualization model from <cite class="ltx_cite ltx_citemacro_citet">Choi et al. (<a class="ltx_ref" href="#bib.bib4" title="">2021</a>)</cite> and back-translation model from <cite class="ltx_cite ltx_citemacro_citet">Tiedemann &amp; Thottingal (<a class="ltx_ref" href="#bib.bib48" title="">2020</a>)</cite> is used.</span></span></span>이 해당 질문으로 변환되는 2단계 mturk 프로세스를 통해 더 큰 스케일로 구성된다. 구축된 데이터 세트 통계는 표 <a class="ltx_ref" href="#S3.T1" title="Table 1 ‣ Dataset Construction ‣ 3.1 Task Formulation ‣ 3 Continual Knowledge Learning (CKL) ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">1</span></a>에 있습니다. 데이터 구성 파이프라인, 예제 및 보다 세밀한 통계에 대한 중요한 세부 정보는 부록 <a class="ltx_ref" href="#A2" title="Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">B</span></a>에 나와 있습니다.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Combined Metric for CKL</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p1.1">본 논문에서는 <span class="ltx_text ltx_font_bold ltx_font_smallcaps" id="S3.SS2.p1.1.1.1">FUAR</span><span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p1.1.1.2">F</span>orgotten / (<span class="ltx_text ltx_font_bold" id="S3.SS2.p1.1.2.2">U</span>pdated + <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.1.2.3">A</span>cquired) <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.1.2.3">R</span>atio)</span>은 잊힌 시간 불변 지식과 업데이트되거나 새로 획득한 지식 간의 trade-off를 사용하여 각 <span class="ltx_text" id="S3.SS2.p1.1.3">FUAR</span>은 상대적으로 <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.4">how many</span> time-invariant knowledge instances is forgotten to learn <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.5">one</span> new or updated knowledge instance. 우리는 먼저 <span class="ltx_text" id="S3.SS2.p1.1.6">FUAR</span>을 정의합니다.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p2.14"><math alttext="T" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_T</annotation></semantics></math>는 임의의 태스크이고, <math alttext="(D_{i})_{i=0}^{n}" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><msubsup id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mrow id="S3.SS2.p2.2.m2.1.1.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.1.1.1.cmml"><mo id="S3.SS2.p2.2.m2.1.1.1.1.1.2" stretchy="false" xref="S3.SS2.p2.2.m2.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p2.2.m2.1.1.1.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.1.1.1.1.2" xref="S3.SS2.p2.2.m2.1.1.1.1.1.1.2.cmml">D</mi><mi id="S3.SS2.p2.2.m2.1.1.1.1.1.1.3" xref="S3.SS2.p2.2.m2.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p2.2.m2.1.1.1.1.1.3" stretchy="false" xref="S3.SS2.p2.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow><mrow id="S3.SS2.p2.2.m2.1.1.1.3" xref="S3.SS2.p2.2.m2.1.1.1.3.cmml"><mi id="S3.SS2.p2.2.m2.1.1.1.3.2" xref="S3.SS2.p2.2.m2.1.1.1.3.2.cmml">i</mi><mo id="S3.SS2.p2.2.m2.1.1.1.3.1" xref="S3.SS2.p2.2.m2.1.1.1.3.1.cmml">=</mo><mn id="S3.SS2.p2.2.m2.1.1.1.3.3" xref="S3.SS2.p2.2.m2.1.1.1.3.3.cmml">0</mn></mrow><mi id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml">n</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1">subscript</csymbol><apply id="S3.SS2.p2.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1.1.2">𝐷</ci><ci id="S3.SS2.p2.2.m2.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS2.p2.2.m2.1.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.1.3"><eq id="S3.SS2.p2.2.m2.1.1.1.3.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1.3.1"></eq><ci id="S3.SS2.p2.2.m2.1.1.1.3.2.cmml" xref="S3.SS2.p2.2.m2.1.1.1.3.2">𝑖</ci><cn id="S3.SS2.p2.2.m2.1.1.1.3.3.cmml" type="integer" xref="S3.SS2.p2.2.m2.1.1.1.3.3">0</cn></apply></apply><ci id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">(D_{i})_{i=0}^{n}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">( italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT</annotation></semantics></math>는 LM 프리트레이닝에 사용되는 말뭉치의 시퀀스라고 하자, 여기서 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.1"><semantics id="S3.SS2.p2.3.m3.1a"><msub id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml">D</mi><mn id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">𝐷</ci><cn id="S3.SS2.p2.3.m3.1.1.3.cmml" type="integer" xref="S3.SS2.p2.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>는 초기 프리트레이닝 말뭉치이다. <math alttext="\text{Gap}(T,D_{a},D_{b})=Score(T)\text{\ of\ }LM_{a}-Score(T)\text{\ of\ }LM_{b}" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m4.5"><semantics id="S3.SS2.p2.4.m4.5a"><mrow id="S3.SS2.p2.4.m4.5.5" xref="S3.SS2.p2.4.m4.5.5.cmml"><mrow id="S3.SS2.p2.4.m4.5.5.2" xref="S3.SS2.p2.4.m4.5.5.2.cmml"><mtext id="S3.SS2.p2.4.m4.5.5.2.4" xref="S3.SS2.p2.4.m4.5.5.2.4a.cmml">Gap</mtext><mo id="S3.SS2.p2.4.m4.5.5.2.3" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.2.3.cmml"></mo><mrow id="S3.SS2.p2.4.m4.5.5.2.2.2" xref="S3.SS2.p2.4.m4.5.5.2.2.3.cmml"><mo id="S3.SS2.p2.4.m4.5.5.2.2.2.3" stretchy="false" xref="S3.SS2.p2.4.m4.5.5.2.2.3.cmml">(</mo><mi id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml">T</mi><mo id="S3.SS2.p2.4.m4.5.5.2.2.2.4" xref="S3.SS2.p2.4.m4.5.5.2.2.3.cmml">,</mo><msub id="S3.SS2.p2.4.m4.4.4.1.1.1.1" xref="S3.SS2.p2.4.m4.4.4.1.1.1.1.cmml"><mi id="S3.SS2.p2.4.m4.4.4.1.1.1.1.2" xref="S3.SS2.p2.4.m4.4.4.1.1.1.1.2.cmml">D</mi><mi id="S3.SS2.p2.4.m4.4.4.1.1.1.1.3" xref="S3.SS2.p2.4.m4.4.4.1.1.1.1.3.cmml">a</mi></msub><mo id="S3.SS2.p2.4.m4.5.5.2.2.2.5" xref="S3.SS2.p2.4.m4.5.5.2.2.3.cmml">,</mo><msub id="S3.SS2.p2.4.m4.5.5.2.2.2.2" xref="S3.SS2.p2.4.m4.5.5.2.2.2.2.cmml"><mi id="S3.SS2.p2.4.m4.5.5.2.2.2.2.2" xref="S3.SS2.p2.4.m4.5.5.2.2.2.2.2.cmml">D</mi><mi id="S3.SS2.p2.4.m4.5.5.2.2.2.2.3" xref="S3.SS2.p2.4.m4.5.5.2.2.2.2.3.cmml">b</mi></msub><mo id="S3.SS2.p2.4.m4.5.5.2.2.2.6" stretchy="false" xref="S3.SS2.p2.4.m4.5.5.2.2.3.cmml">)</mo></mrow></mrow><mo id="S3.SS2.p2.4.m4.5.5.3" xref="S3.SS2.p2.4.m4.5.5.3.cmml">=</mo><mrow id="S3.SS2.p2.4.m4.5.5.4" xref="S3.SS2.p2.4.m4.5.5.4.cmml"><mrow id="S3.SS2.p2.4.m4.5.5.4.2" xref="S3.SS2.p2.4.m4.5.5.4.2.cmml"><mi id="S3.SS2.p2.4.m4.5.5.4.2.2" xref="S3.SS2.p2.4.m4.5.5.4.2.2.cmml">S</mi><mo id="S3.SS2.p2.4.m4.5.5.4.2.1" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.2.1.cmml"></mo><mi id="S3.SS2.p2.4.m4.5.5.4.2.3" xref="S3.SS2.p2.4.m4.5.5.4.2.3.cmml">c</mi><mo id="S3.SS2.p2.4.m4.5.5.4.2.1a" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.2.1.cmml"></mo><mi id="S3.SS2.p2.4.m4.5.5.4.2.4" xref="S3.SS2.p2.4.m4.5.5.4.2.4.cmml">o</mi><mo id="S3.SS2.p2.4.m4.5.5.4.2.1b" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.2.1.cmml"></mo><mi id="S3.SS2.p2.4.m4.5.5.4.2.5" xref="S3.SS2.p2.4.m4.5.5.4.2.5.cmml">r</mi><mo id="S3.SS2.p2.4.m4.5.5.4.2.1c" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.2.1.cmml"></mo><mi id="S3.SS2.p2.4.m4.5.5.4.2.6" xref="S3.SS2.p2.4.m4.5.5.4.2.6.cmml">e</mi><mo id="S3.SS2.p2.4.m4.5.5.4.2.1d" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.2.1.cmml"></mo><mrow id="S3.SS2.p2.4.m4.5.5.4.2.7.2" xref="S3.SS2.p2.4.m4.5.5.4.2.cmml"><mo id="S3.SS2.p2.4.m4.5.5.4.2.7.2.1" stretchy="false" xref="S3.SS2.p2.4.m4.5.5.4.2.cmml">(</mo><mi id="S3.SS2.p2.4.m4.2.2" xref="S3.SS2.p2.4.m4.2.2.cmml">T</mi><mo id="S3.SS2.p2.4.m4.5.5.4.2.7.2.2" stretchy="false" xref="S3.SS2.p2.4.m4.5.5.4.2.cmml">)</mo></mrow><mo id="S3.SS2.p2.4.m4.5.5.4.2.1e" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.2.1.cmml"></mo><mtext id="S3.SS2.p2.4.m4.5.5.4.2.8" xref="S3.SS2.p2.4.m4.5.5.4.2.8a.cmml"> of </mtext><mo id="S3.SS2.p2.4.m4.5.5.4.2.1f" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.2.1.cmml"></mo><mi id="S3.SS2.p2.4.m4.5.5.4.2.9" xref="S3.SS2.p2.4.m4.5.5.4.2.9.cmml">L</mi><mo id="S3.SS2.p2.4.m4.5.5.4.2.1g" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.2.1.cmml"></mo><msub id="S3.SS2.p2.4.m4.5.5.4.2.10" xref="S3.SS2.p2.4.m4.5.5.4.2.10.cmml"><mi id="S3.SS2.p2.4.m4.5.5.4.2.10.2" xref="S3.SS2.p2.4.m4.5.5.4.2.10.2.cmml">M</mi><mi id="S3.SS2.p2.4.m4.5.5.4.2.10.3" xref="S3.SS2.p2.4.m4.5.5.4.2.10.3.cmml">a</mi></msub></mrow><mo id="S3.SS2.p2.4.m4.5.5.4.1" xref="S3.SS2.p2.4.m4.5.5.4.1.cmml">−</mo><mrow id="S3.SS2.p2.4.m4.5.5.4.3" xref="S3.SS2.p2.4.m4.5.5.4.3.cmml"><mi id="S3.SS2.p2.4.m4.5.5.4.3.2" xref="S3.SS2.p2.4.m4.5.5.4.3.2.cmml">S</mi><mo id="S3.SS2.p2.4.m4.5.5.4.3.1" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.3.1.cmml"></mo><mi id="S3.SS2.p2.4.m4.5.5.4.3.3" xref="S3.SS2.p2.4.m4.5.5.4.3.3.cmml">c</mi><mo id="S3.SS2.p2.4.m4.5.5.4.3.1a" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.3.1.cmml"></mo><mi id="S3.SS2.p2.4.m4.5.5.4.3.4" xref="S3.SS2.p2.4.m4.5.5.4.3.4.cmml">o</mi><mo id="S3.SS2.p2.4.m4.5.5.4.3.1b" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.3.1.cmml"></mo><mi id="S3.SS2.p2.4.m4.5.5.4.3.5" xref="S3.SS2.p2.4.m4.5.5.4.3.5.cmml">r</mi><mo id="S3.SS2.p2.4.m4.5.5.4.3.1c" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.3.1.cmml"></mo><mi id="S3.SS2.p2.4.m4.5.5.4.3.6" xref="S3.SS2.p2.4.m4.5.5.4.3.6.cmml">e</mi><mo id="S3.SS2.p2.4.m4.5.5.4.3.1d" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.3.1.cmml"></mo><mrow id="S3.SS2.p2.4.m4.5.5.4.3.7.2" xref="S3.SS2.p2.4.m4.5.5.4.3.cmml"><mo id="S3.SS2.p2.4.m4.5.5.4.3.7.2.1" stretchy="false" xref="S3.SS2.p2.4.m4.5.5.4.3.cmml">(</mo><mi id="S3.SS2.p2.4.m4.3.3" xref="S3.SS2.p2.4.m4.3.3.cmml">T</mi><mo id="S3.SS2.p2.4.m4.5.5.4.3.7.2.2" stretchy="false" xref="S3.SS2.p2.4.m4.5.5.4.3.cmml">)</mo></mrow><mo id="S3.SS2.p2.4.m4.5.5.4.3.1e" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.3.1.cmml"></mo><mtext id="S3.SS2.p2.4.m4.5.5.4.3.8" xref="S3.SS2.p2.4.m4.5.5.4.3.8a.cmml"> of </mtext><mo id="S3.SS2.p2.4.m4.5.5.4.3.1f" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.3.1.cmml"></mo><mi id="S3.SS2.p2.4.m4.5.5.4.3.9" xref="S3.SS2.p2.4.m4.5.5.4.3.9.cmml">L</mi><mo id="S3.SS2.p2.4.m4.5.5.4.3.1g" lspace="0px" rspace="0px" xref="S3.SS2.p2.4.m4.5.5.4.3.1.cmml"></mo><msub id="S3.SS2.p2.4.m4.5.5.4.3.10" xref="S3.SS2.p2.4.m4.5.5.4.3.10.cmml"><mi id="S3.SS2.p2.4.m4.5.5.4.3.10.2" xref="S3.SS2.p2.4.m4.5.5.4.3.10.2.cmml">M</mi><mi id="S3.SS2.p2.4.m4.5.5.4.3.10.3" xref="S3.SS2.p2.4.m4.5.5.4.3.10.3.cmml">b</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.5b"><apply id="S3.SS2.p2.4.m4.5.5.cmml" xref="S3.SS2.p2.4.m4.5.5"><eq id="S3.SS2.p2.4.m4.5.5.3.cmml" xref="S3.SS2.p2.4.m4.5.5.3"></eq><apply id="S3.SS2.p2.4.m4.5.5.2.cmml" xref="S3.SS2.p2.4.m4.5.5.2"><times id="S3.SS2.p2.4.m4.5.5.2.3.cmml" xref="S3.SS2.p2.4.m4.5.5.2.3"></times><ci id="S3.SS2.p2.4.m4.5.5.2.4a.cmml" xref="S3.SS2.p2.4.m4.5.5.2.4"><mtext id="S3.SS2.p2.4.m4.5.5.2.4.cmml" xref="S3.SS2.p2.4.m4.5.5.2.4">Gap</mtext></ci><vector id="S3.SS2.p2.4.m4.5.5.2.2.3.cmml" xref="S3.SS2.p2.4.m4.5.5.2.2.2"><ci id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1">𝑇</ci><apply id="S3.SS2.p2.4.m4.4.4.1.1.1.1.cmml" xref="S3.SS2.p2.4.m4.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.4.4.1.1.1.1.1.cmml" xref="S3.SS2.p2.4.m4.4.4.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.4.m4.4.4.1.1.1.1.2.cmml" xref="S3.SS2.p2.4.m4.4.4.1.1.1.1.2">𝐷</ci><ci id="S3.SS2.p2.4.m4.4.4.1.1.1.1.3.cmml" xref="S3.SS2.p2.4.m4.4.4.1.1.1.1.3">𝑎</ci></apply><apply id="S3.SS2.p2.4.m4.5.5.2.2.2.2.cmml" xref="S3.SS2.p2.4.m4.5.5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.5.5.2.2.2.2.1.cmml" xref="S3.SS2.p2.4.m4.5.5.2.2.2.2">subscript</csymbol><ci id="S3.SS2.p2.4.m4.5.5.2.2.2.2.2.cmml" xref="S3.SS2.p2.4.m4.5.5.2.2.2.2.2">𝐷</ci><ci id="S3.SS2.p2.4.m4.5.5.2.2.2.2.3.cmml" xref="S3.SS2.p2.4.m4.5.5.2.2.2.2.3">𝑏</ci></apply></vector></apply><apply id="S3.SS2.p2.4.m4.5.5.4.cmml" xref="S3.SS2.p2.4.m4.5.5.4"><minus id="S3.SS2.p2.4.m4.5.5.4.1.cmml" xref="S3.SS2.p2.4.m4.5.5.4.1"></minus><apply id="S3.SS2.p2.4.m4.5.5.4.2.cmml" xref="S3.SS2.p2.4.m4.5.5.4.2"><times id="S3.SS2.p2.4.m4.5.5.4.2.1.cmml" xref="S3.SS2.p2.4.m4.5.5.4.2.1"></times><ci id="S3.SS2.p2.4.m4.5.5.4.2.2.cmml" xref="S3.SS2.p2.4.m4.5.5.4.2.2">𝑆</ci><ci id="S3.SS2.p2.4.m4.5.5.4.2.3.cmml" xref="S3.SS2.p2.4.m4.5.5.4.2.3">𝑐</ci><ci id="S3.SS2.p2.4.m4.5.5.4.2.4.cmml" xref="S3.SS2.p2.4.m4.5.5.4.2.4">𝑜</ci><ci id="S3.SS2.p2.4.m4.5.5.4.2.5.cmml" xref="S3.SS2.p2.4.m4.5.5.4.2.5">𝑟</ci><ci id="S3.SS2.p2.4.m4.5.5.4.2.6.cmml" xref="S3.SS2.p2.4.m4.5.5.4.2.6">𝑒</ci><ci id="S3.SS2.p2.4.m4.2.2.cmml" xref="S3.SS2.p2.4.m4.2.2">𝑇</ci><ci id="S3.SS2.p2.4.m4.5.5.4.2.8a.cmml" xref="S3.SS2.p2.4.m4.5.5.4.2.8"><mtext id="S3.SS2.p2.4.m4.5.5.4.2.8.cmml" xref="S3.SS2.p2.4.m4.5.5.4.2.8"> of </mtext></ci><ci id="S3.SS2.p2.4.m4.5.5.4.2.9.cmml" xref="S3.SS2.p2.4.m4.5.5.4.2.9">𝐿</ci><apply id="S3.SS2.p2.4.m4.5.5.4.2.10.cmml" xref="S3.SS2.p2.4.m4.5.5.4.2.10"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.5.5.4.2.10.1.cmml" xref="S3.SS2.p2.4.m4.5.5.4.2.10">subscript</csymbol><ci id="S3.SS2.p2.4.m4.5.5.4.2.10.2.cmml" xref="S3.SS2.p2.4.m4.5.5.4.2.10.2">𝑀</ci><ci id="S3.SS2.p2.4.m4.5.5.4.2.10.3.cmml" xref="S3.SS2.p2.4.m4.5.5.4.2.10.3">𝑎</ci></apply></apply><apply id="S3.SS2.p2.4.m4.5.5.4.3.cmml" xref="S3.SS2.p2.4.m4.5.5.4.3"><times id="S3.SS2.p2.4.m4.5.5.4.3.1.cmml" xref="S3.SS2.p2.4.m4.5.5.4.3.1"></times><ci id="S3.SS2.p2.4.m4.5.5.4.3.2.cmml" xref="S3.SS2.p2.4.m4.5.5.4.3.2">𝑆</ci><ci id="S3.SS2.p2.4.m4.5.5.4.3.3.cmml" xref="S3.SS2.p2.4.m4.5.5.4.3.3">𝑐</ci><ci id="S3.SS2.p2.4.m4.5.5.4.3.4.cmml" xref="S3.SS2.p2.4.m4.5.5.4.3.4">𝑜</ci><ci id="S3.SS2.p2.4.m4.5.5.4.3.5.cmml" xref="S3.SS2.p2.4.m4.5.5.4.3.5">𝑟</ci><ci id="S3.SS2.p2.4.m4.5.5.4.3.6.cmml" xref="S3.SS2.p2.4.m4.5.5.4.3.6">𝑒</ci><ci id="S3.SS2.p2.4.m4.3.3.cmml" xref="S3.SS2.p2.4.m4.3.3">𝑇</ci><ci id="S3.SS2.p2.4.m4.5.5.4.3.8a.cmml" xref="S3.SS2.p2.4.m4.5.5.4.3.8"><mtext id="S3.SS2.p2.4.m4.5.5.4.3.8.cmml" xref="S3.SS2.p2.4.m4.5.5.4.3.8"> of </mtext></ci><ci id="S3.SS2.p2.4.m4.5.5.4.3.9.cmml" xref="S3.SS2.p2.4.m4.5.5.4.3.9">𝐿</ci><apply id="S3.SS2.p2.4.m4.5.5.4.3.10.cmml" xref="S3.SS2.p2.4.m4.5.5.4.3.10"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.5.5.4.3.10.1.cmml" xref="S3.SS2.p2.4.m4.5.5.4.3.10">subscript</csymbol><ci id="S3.SS2.p2.4.m4.5.5.4.3.10.2.cmml" xref="S3.SS2.p2.4.m4.5.5.4.3.10.2">𝑀</ci><ci id="S3.SS2.p2.4.m4.5.5.4.3.10.3.cmml" xref="S3.SS2.p2.4.m4.5.5.4.3.10.3">𝑏</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.5c">\text{Gap}(T,D_{a},D_{b})=Score(T)\text{\ of\ }LM_{a}-Score(T)\text{\ of\ }LM_{b}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m4.5d">Gap ( italic_T , italic_D start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT , italic_D start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT ) = italic_S italic_c italic_o italic_r italic_e ( italic_T ) of italic_L italic_M start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT - italic_S italic_c italic_o italic_r italic_e ( italic_T ) of italic_L italic_M start_POSTSUBSCRIPT italic_b end_POSTSUBSCRIPT</annotation></semantics></math>를 정의하며, 여기서 <math alttext="LM_{a}" class="ltx_Math" display="inline" id="S3.SS2.p2.5.m5.1"><semantics id="S3.SS2.p2.5.m5.1a"><mrow id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml"><mi id="S3.SS2.p2.5.m5.1.1.2" xref="S3.SS2.p2.5.m5.1.1.2.cmml">L</mi><mo id="S3.SS2.p2.5.m5.1.1.1" lspace="0px" rspace="0px" xref="S3.SS2.p2.5.m5.1.1.1.cmml"></mo><msub id="S3.SS2.p2.5.m5.1.1.3" xref="S3.SS2.p2.5.m5.1.1.3.cmml"><mi id="S3.SS2.p2.5.m5.1.1.3.2" xref="S3.SS2.p2.5.m5.1.1.3.2.cmml">M</mi><mi id="S3.SS2.p2.5.m5.1.1.3.3" xref="S3.SS2.p2.5.m5.1.1.3.3.cmml">a</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><apply id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1"><times id="S3.SS2.p2.5.m5.1.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1.1"></times><ci id="S3.SS2.p2.5.m5.1.1.2.cmml" xref="S3.SS2.p2.5.m5.1.1.2">𝐿</ci><apply id="S3.SS2.p2.5.m5.1.1.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.5.m5.1.1.3.1.cmml" xref="S3.SS2.p2.5.m5.1.1.3">subscript</csymbol><ci id="S3.SS2.p2.5.m5.1.1.3.2.cmml" xref="S3.SS2.p2.5.m5.1.1.3.2">𝑀</ci><ci id="S3.SS2.p2.5.m5.1.1.3.3.cmml" xref="S3.SS2.p2.5.m5.1.1.3.3">𝑎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">LM_{a}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.m5.1d">italic_L italic_M start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math>는 <math alttext="D_{a}" class="ltx_Math" display="inline" id="S3.SS2.p2.6.m6.1"><semantics id="S3.SS2.p2.6.m6.1a"><msub id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml"><mi id="S3.SS2.p2.6.m6.1.1.2" xref="S3.SS2.p2.6.m6.1.1.2.cmml">D</mi><mi id="S3.SS2.p2.6.m6.1.1.3" xref="S3.SS2.p2.6.m6.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><apply id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.6.m6.1.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p2.6.m6.1.1.2.cmml" xref="S3.SS2.p2.6.m6.1.1.2">𝐷</ci><ci id="S3.SS2.p2.6.m6.1.1.3.cmml" xref="S3.SS2.p2.6.m6.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">D_{a}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.6.m6.1d">italic_D start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math>에서 사전 훈련된 후의 LM을 나타낸다. 다음으로, <math alttext="\mathbb{T}^{F}=(T_{i}^{F})_{i=0}^{n-1}" class="ltx_Math" display="inline" id="S3.SS2.p2.7.m7.1"><semantics id="S3.SS2.p2.7.m7.1a"><mrow id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml"><msup id="S3.SS2.p2.7.m7.1.1.3" xref="S3.SS2.p2.7.m7.1.1.3.cmml"><mi id="S3.SS2.p2.7.m7.1.1.3.2" xref="S3.SS2.p2.7.m7.1.1.3.2.cmml">𝕋</mi><mi id="S3.SS2.p2.7.m7.1.1.3.3" xref="S3.SS2.p2.7.m7.1.1.3.3.cmml">F</mi></msup><mo id="S3.SS2.p2.7.m7.1.1.2" xref="S3.SS2.p2.7.m7.1.1.2.cmml">=</mo><msubsup id="S3.SS2.p2.7.m7.1.1.1" xref="S3.SS2.p2.7.m7.1.1.1.cmml"><mrow id="S3.SS2.p2.7.m7.1.1.1.1.1.1" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.cmml"><mo id="S3.SS2.p2.7.m7.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.cmml">(</mo><msubsup id="S3.SS2.p2.7.m7.1.1.1.1.1.1.1" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.2.2" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.2.2.cmml">T</mi><mi id="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.2.3" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.3" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.3.cmml">F</mi></msubsup><mo id="S3.SS2.p2.7.m7.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.cmml">)</mo></mrow><mrow id="S3.SS2.p2.7.m7.1.1.1.1.3" xref="S3.SS2.p2.7.m7.1.1.1.1.3.cmml"><mi id="S3.SS2.p2.7.m7.1.1.1.1.3.2" xref="S3.SS2.p2.7.m7.1.1.1.1.3.2.cmml">i</mi><mo id="S3.SS2.p2.7.m7.1.1.1.1.3.1" xref="S3.SS2.p2.7.m7.1.1.1.1.3.1.cmml">=</mo><mn id="S3.SS2.p2.7.m7.1.1.1.1.3.3" xref="S3.SS2.p2.7.m7.1.1.1.1.3.3.cmml">0</mn></mrow><mrow id="S3.SS2.p2.7.m7.1.1.1.3" xref="S3.SS2.p2.7.m7.1.1.1.3.cmml"><mi id="S3.SS2.p2.7.m7.1.1.1.3.2" xref="S3.SS2.p2.7.m7.1.1.1.3.2.cmml">n</mi><mo id="S3.SS2.p2.7.m7.1.1.1.3.1" xref="S3.SS2.p2.7.m7.1.1.1.3.1.cmml">−</mo><mn id="S3.SS2.p2.7.m7.1.1.1.3.3" xref="S3.SS2.p2.7.m7.1.1.1.3.3.cmml">1</mn></mrow></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.1b"><apply id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1"><eq id="S3.SS2.p2.7.m7.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1.2"></eq><apply id="S3.SS2.p2.7.m7.1.1.3.cmml" xref="S3.SS2.p2.7.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.3.1.cmml" xref="S3.SS2.p2.7.m7.1.1.3">superscript</csymbol><ci id="S3.SS2.p2.7.m7.1.1.3.2.cmml" xref="S3.SS2.p2.7.m7.1.1.3.2">𝕋</ci><ci id="S3.SS2.p2.7.m7.1.1.3.3.cmml" xref="S3.SS2.p2.7.m7.1.1.3.3">𝐹</ci></apply><apply id="S3.SS2.p2.7.m7.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1.1">superscript</csymbol><apply id="S3.SS2.p2.7.m7.1.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1.1">subscript</csymbol><apply id="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1">superscript</csymbol><apply id="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.2.2">𝑇</ci><ci id="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.1.1.1.3">𝐹</ci></apply><apply id="S3.SS2.p2.7.m7.1.1.1.1.3.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.3"><eq id="S3.SS2.p2.7.m7.1.1.1.1.3.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.3.1"></eq><ci id="S3.SS2.p2.7.m7.1.1.1.1.3.2.cmml" xref="S3.SS2.p2.7.m7.1.1.1.1.3.2">𝑖</ci><cn id="S3.SS2.p2.7.m7.1.1.1.1.3.3.cmml" type="integer" xref="S3.SS2.p2.7.m7.1.1.1.1.3.3">0</cn></apply></apply><apply id="S3.SS2.p2.7.m7.1.1.1.3.cmml" xref="S3.SS2.p2.7.m7.1.1.1.3"><minus id="S3.SS2.p2.7.m7.1.1.1.3.1.cmml" xref="S3.SS2.p2.7.m7.1.1.1.3.1"></minus><ci id="S3.SS2.p2.7.m7.1.1.1.3.2.cmml" xref="S3.SS2.p2.7.m7.1.1.1.3.2">𝑛</ci><cn id="S3.SS2.p2.7.m7.1.1.1.3.3.cmml" type="integer" xref="S3.SS2.p2.7.m7.1.1.1.3.3">1</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.1c">\mathbb{T}^{F}=(T_{i}^{F})_{i=0}^{n-1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.7.m7.1d">blackboard_T start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT = ( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT ) start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT</annotation></semantics></math>를 각 대응 말뭉치로부터 불변 지식의 망각을 측정하는 <math alttext="(D_{i})_{i=0}^{n-1}" class="ltx_Math" display="inline" id="S3.SS2.p2.8.m8.1"><semantics id="S3.SS2.p2.8.m8.1a"><msubsup id="S3.SS2.p2.8.m8.1.1" xref="S3.SS2.p2.8.m8.1.1.cmml"><mrow id="S3.SS2.p2.8.m8.1.1.1.1.1" xref="S3.SS2.p2.8.m8.1.1.1.1.1.1.cmml"><mo id="S3.SS2.p2.8.m8.1.1.1.1.1.2" stretchy="false" xref="S3.SS2.p2.8.m8.1.1.1.1.1.1.cmml">(</mo><msub id="S3.SS2.p2.8.m8.1.1.1.1.1.1" xref="S3.SS2.p2.8.m8.1.1.1.1.1.1.cmml"><mi id="S3.SS2.p2.8.m8.1.1.1.1.1.1.2" xref="S3.SS2.p2.8.m8.1.1.1.1.1.1.2.cmml">D</mi><mi id="S3.SS2.p2.8.m8.1.1.1.1.1.1.3" xref="S3.SS2.p2.8.m8.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS2.p2.8.m8.1.1.1.1.1.3" stretchy="false" xref="S3.SS2.p2.8.m8.1.1.1.1.1.1.cmml">)</mo></mrow><mrow id="S3.SS2.p2.8.m8.1.1.1.3" xref="S3.SS2.p2.8.m8.1.1.1.3.cmml"><mi id="S3.SS2.p2.8.m8.1.1.1.3.2" xref="S3.SS2.p2.8.m8.1.1.1.3.2.cmml">i</mi><mo id="S3.SS2.p2.8.m8.1.1.1.3.1" xref="S3.SS2.p2.8.m8.1.1.1.3.1.cmml">=</mo><mn id="S3.SS2.p2.8.m8.1.1.1.3.3" xref="S3.SS2.p2.8.m8.1.1.1.3.3.cmml">0</mn></mrow><mrow id="S3.SS2.p2.8.m8.1.1.3" xref="S3.SS2.p2.8.m8.1.1.3.cmml"><mi id="S3.SS2.p2.8.m8.1.1.3.2" xref="S3.SS2.p2.8.m8.1.1.3.2.cmml">n</mi><mo id="S3.SS2.p2.8.m8.1.1.3.1" xref="S3.SS2.p2.8.m8.1.1.3.1.cmml">−</mo><mn id="S3.SS2.p2.8.m8.1.1.3.3" xref="S3.SS2.p2.8.m8.1.1.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.8.m8.1b"><apply id="S3.SS2.p2.8.m8.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.1.1.2.cmml" xref="S3.SS2.p2.8.m8.1.1">superscript</csymbol><apply id="S3.SS2.p2.8.m8.1.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.1.1.1.2.cmml" xref="S3.SS2.p2.8.m8.1.1">subscript</csymbol><apply id="S3.SS2.p2.8.m8.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.8.m8.1.1.1.1.1.1.1.cmml" xref="S3.SS2.p2.8.m8.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.p2.8.m8.1.1.1.1.1.1.2.cmml" xref="S3.SS2.p2.8.m8.1.1.1.1.1.1.2">𝐷</ci><ci id="S3.SS2.p2.8.m8.1.1.1.1.1.1.3.cmml" xref="S3.SS2.p2.8.m8.1.1.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS2.p2.8.m8.1.1.1.3.cmml" xref="S3.SS2.p2.8.m8.1.1.1.3"><eq id="S3.SS2.p2.8.m8.1.1.1.3.1.cmml" xref="S3.SS2.p2.8.m8.1.1.1.3.1"></eq><ci id="S3.SS2.p2.8.m8.1.1.1.3.2.cmml" xref="S3.SS2.p2.8.m8.1.1.1.3.2">𝑖</ci><cn id="S3.SS2.p2.8.m8.1.1.1.3.3.cmml" type="integer" xref="S3.SS2.p2.8.m8.1.1.1.3.3">0</cn></apply></apply><apply id="S3.SS2.p2.8.m8.1.1.3.cmml" xref="S3.SS2.p2.8.m8.1.1.3"><minus id="S3.SS2.p2.8.m8.1.1.3.1.cmml" xref="S3.SS2.p2.8.m8.1.1.3.1"></minus><ci id="S3.SS2.p2.8.m8.1.1.3.2.cmml" xref="S3.SS2.p2.8.m8.1.1.3.2">𝑛</ci><cn id="S3.SS2.p2.8.m8.1.1.3.3.cmml" type="integer" xref="S3.SS2.p2.8.m8.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.8.m8.1c">(D_{i})_{i=0}^{n-1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.8.m8.1d">( italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT</annotation></semantics></math>로부터의 태스크의 시퀀스로 표기한다. 말뭉치 <math alttext="D_{i}" class="ltx_Math" display="inline" id="S3.SS2.p2.9.m9.1"><semantics id="S3.SS2.p2.9.m9.1a"><msub id="S3.SS2.p2.9.m9.1.1" xref="S3.SS2.p2.9.m9.1.1.cmml"><mi id="S3.SS2.p2.9.m9.1.1.2" xref="S3.SS2.p2.9.m9.1.1.2.cmml">D</mi><mi id="S3.SS2.p2.9.m9.1.1.3" xref="S3.SS2.p2.9.m9.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.9.m9.1b"><apply id="S3.SS2.p2.9.m9.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.9.m9.1.1.1.cmml" xref="S3.SS2.p2.9.m9.1.1">subscript</csymbol><ci id="S3.SS2.p2.9.m9.1.1.2.cmml" xref="S3.SS2.p2.9.m9.1.1.2">𝐷</ci><ci id="S3.SS2.p2.9.m9.1.1.3.cmml" xref="S3.SS2.p2.9.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.9.m9.1c">D_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.9.m9.1d">italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>로부터 이러한 작업이 없는 경우 <math alttext="T_{i}^{F}" class="ltx_Math" display="inline" id="S3.SS2.p2.10.m10.1"><semantics id="S3.SS2.p2.10.m10.1a"><msubsup id="S3.SS2.p2.10.m10.1.1" xref="S3.SS2.p2.10.m10.1.1.cmml"><mi id="S3.SS2.p2.10.m10.1.1.2.2" xref="S3.SS2.p2.10.m10.1.1.2.2.cmml">T</mi><mi id="S3.SS2.p2.10.m10.1.1.2.3" xref="S3.SS2.p2.10.m10.1.1.2.3.cmml">i</mi><mi id="S3.SS2.p2.10.m10.1.1.3" xref="S3.SS2.p2.10.m10.1.1.3.cmml">F</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.10.m10.1b"><apply id="S3.SS2.p2.10.m10.1.1.cmml" xref="S3.SS2.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m10.1.1.1.cmml" xref="S3.SS2.p2.10.m10.1.1">superscript</csymbol><apply id="S3.SS2.p2.10.m10.1.1.2.cmml" xref="S3.SS2.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.10.m10.1.1.2.1.cmml" xref="S3.SS2.p2.10.m10.1.1">subscript</csymbol><ci id="S3.SS2.p2.10.m10.1.1.2.2.cmml" xref="S3.SS2.p2.10.m10.1.1.2.2">𝑇</ci><ci id="S3.SS2.p2.10.m10.1.1.2.3.cmml" xref="S3.SS2.p2.10.m10.1.1.2.3">𝑖</ci></apply><ci id="S3.SS2.p2.10.m10.1.1.3.cmml" xref="S3.SS2.p2.10.m10.1.1.3">𝐹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.10.m10.1c">T_{i}^{F}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.10.m10.1d">italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT</annotation></semantics></math>의 값은 <math alttext="n.d." class="ltx_Math" display="inline" id="S3.SS2.p2.11.m11.3"><semantics id="S3.SS2.p2.11.m11.3a"><mrow id="S3.SS2.p2.11.m11.3.3.1"><mrow id="S3.SS2.p2.11.m11.3.3.1.1.2" xref="S3.SS2.p2.11.m11.3.3.1.1.1.cmml"><mi id="S3.SS2.p2.11.m11.1.1" xref="S3.SS2.p2.11.m11.1.1.cmml">n</mi><mo id="S3.SS2.p2.11.m11.3.3.1.1.2.1" lspace="0em" rspace="0.167em" xref="S3.SS2.p2.11.m11.3.3.1.1.1a.cmml">.</mo><mi id="S3.SS2.p2.11.m11.2.2" xref="S3.SS2.p2.11.m11.2.2.cmml">d</mi></mrow><mo id="S3.SS2.p2.11.m11.3.3.1.2" lspace="0em">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.11.m11.3b"><apply id="S3.SS2.p2.11.m11.3.3.1.1.1.cmml" xref="S3.SS2.p2.11.m11.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p2.11.m11.3.3.1.1.1a.cmml" xref="S3.SS2.p2.11.m11.3.3.1.1.2.1">formulae-sequence</csymbol><ci id="S3.SS2.p2.11.m11.1.1.cmml" xref="S3.SS2.p2.11.m11.1.1">𝑛</ci><ci id="S3.SS2.p2.11.m11.2.2.cmml" xref="S3.SS2.p2.11.m11.2.2">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.11.m11.3c">n.d.</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.11.m11.3d">italic_n . italic_d .</annotation></semantics></math>로 설정되며, 이는 <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.14.1">not defined</span>을 의미한다. 마찬가지로, <math alttext="T_{n}^{U}" class="ltx_Math" display="inline" id="S3.SS2.p2.12.m12.1"><semantics id="S3.SS2.p2.12.m12.1a"><msubsup id="S3.SS2.p2.12.m12.1.1" xref="S3.SS2.p2.12.m12.1.1.cmml"><mi id="S3.SS2.p2.12.m12.1.1.2.2" xref="S3.SS2.p2.12.m12.1.1.2.2.cmml">T</mi><mi id="S3.SS2.p2.12.m12.1.1.2.3" xref="S3.SS2.p2.12.m12.1.1.2.3.cmml">n</mi><mi id="S3.SS2.p2.12.m12.1.1.3" xref="S3.SS2.p2.12.m12.1.1.3.cmml">U</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.12.m12.1b"><apply id="S3.SS2.p2.12.m12.1.1.cmml" xref="S3.SS2.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.12.m12.1.1.1.cmml" xref="S3.SS2.p2.12.m12.1.1">superscript</csymbol><apply id="S3.SS2.p2.12.m12.1.1.2.cmml" xref="S3.SS2.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.12.m12.1.1.2.1.cmml" xref="S3.SS2.p2.12.m12.1.1">subscript</csymbol><ci id="S3.SS2.p2.12.m12.1.1.2.2.cmml" xref="S3.SS2.p2.12.m12.1.1.2.2">𝑇</ci><ci id="S3.SS2.p2.12.m12.1.1.2.3.cmml" xref="S3.SS2.p2.12.m12.1.1.2.3">𝑛</ci></apply><ci id="S3.SS2.p2.12.m12.1.1.3.cmml" xref="S3.SS2.p2.12.m12.1.1.3">𝑈</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.12.m12.1c">T_{n}^{U}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.12.m12.1d">italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_U end_POSTSUPERSCRIPT</annotation></semantics></math> 및 <math alttext="T_{n}^{A}" class="ltx_Math" display="inline" id="S3.SS2.p2.13.m13.1"><semantics id="S3.SS2.p2.13.m13.1a"><msubsup id="S3.SS2.p2.13.m13.1.1" xref="S3.SS2.p2.13.m13.1.1.cmml"><mi id="S3.SS2.p2.13.m13.1.1.2.2" xref="S3.SS2.p2.13.m13.1.1.2.2.cmml">T</mi><mi id="S3.SS2.p2.13.m13.1.1.2.3" xref="S3.SS2.p2.13.m13.1.1.2.3.cmml">n</mi><mi id="S3.SS2.p2.13.m13.1.1.3" xref="S3.SS2.p2.13.m13.1.1.3.cmml">A</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.13.m13.1b"><apply id="S3.SS2.p2.13.m13.1.1.cmml" xref="S3.SS2.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.13.m13.1.1.1.cmml" xref="S3.SS2.p2.13.m13.1.1">superscript</csymbol><apply id="S3.SS2.p2.13.m13.1.1.2.cmml" xref="S3.SS2.p2.13.m13.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.13.m13.1.1.2.1.cmml" xref="S3.SS2.p2.13.m13.1.1">subscript</csymbol><ci id="S3.SS2.p2.13.m13.1.1.2.2.cmml" xref="S3.SS2.p2.13.m13.1.1.2.2">𝑇</ci><ci id="S3.SS2.p2.13.m13.1.1.2.3.cmml" xref="S3.SS2.p2.13.m13.1.1.2.3">𝑛</ci></apply><ci id="S3.SS2.p2.13.m13.1.1.3.cmml" xref="S3.SS2.p2.13.m13.1.1.3">𝐴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.13.m13.1c">T_{n}^{A}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.13.m13.1d">italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT</annotation></semantics></math>를 각각 <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.14.2">update</span> 및 <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.14.3">acquisition</span>의 태스크로 표기한다. <span class="ltx_text" id="S3.SS2.p2.14.4">FUAR</span>을 다음과 같이 정의합니다.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.6" class="ltx_math_unparsed" alttext="\text{FUAR}(\mathbb{T}^{F},T_{n}^{U},T_{n}^{A})=\begin{cases}\dfrac{\sum\limits_{i=0}^{n-1}{\text{max}(0,\text{Gap}(T_{i}^{F},D_{i},D_{n}))\mathbbm{1}_{\{T_{i}^{F}\neq n.d.\}}}}{\sum\limits_{i=0}^{n-1}\{{\text{max}(0,\text{Gap}(T_{n}^{U},D_{n},D_{i}))}\mathbbm{1}_{\{T_{i}^{F}\neq n.d.\}}+{\text{max}(0,\text{Gap}(T_{n}^{A},D_{n},D_{i}))}\mathbbm{1}_{\{T_{i}^{F}\neq n.d.\}}\}},\\
\text{ if denominator}\ >0,\\
\textit{no gain,}\text{\ otherwise.}\\
\end{cases}" display="block"><semantics id="S3.E1.m1.6a"><mrow id="S3.E1.m1.6.6"><mrow id="S3.E1.m1.6.6.3"><mtext id="S3.E1.m1.6.6.3.5">FUAR</mtext><mo id="S3.E1.m1.6.6.3.4" lspace="0px" rspace="0px"></mo><mrow id="S3.E1.m1.6.6.3.3.3"><mo stretchy="false" id="S3.E1.m1.6.6.3.3.3.4">(</mo><msup id="S3.E1.m1.4.4.1.1.1.1"><mi id="S3.E1.m1.4.4.1.1.1.1.2">𝕋</mi><mi id="S3.E1.m1.4.4.1.1.1.1.3">F</mi></msup><mo id="S3.E1.m1.6.6.3.3.3.5">,</mo><msubsup id="S3.E1.m1.5.5.2.2.2.2"><mi id="S3.E1.m1.5.5.2.2.2.2.2.2">T</mi><mi id="S3.E1.m1.5.5.2.2.2.2.2.3">n</mi><mi id="S3.E1.m1.5.5.2.2.2.2.3">U</mi></msubsup><mo id="S3.E1.m1.6.6.3.3.3.6">,</mo><msubsup id="S3.E1.m1.6.6.3.3.3.3"><mi id="S3.E1.m1.6.6.3.3.3.3.2.2">T</mi><mi id="S3.E1.m1.6.6.3.3.3.3.2.3">n</mi><mi id="S3.E1.m1.6.6.3.3.3.3.3">A</mi></msubsup><mo stretchy="false" id="S3.E1.m1.6.6.3.3.3.7">)</mo></mrow></mrow><mo id="S3.E1.m1.6.6.4">=</mo><mrow id="S3.E1.m1.3.3"><mo id="S3.E1.m1.3.3.4">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S3.E1.m1.3.3.3"><mtr id="S3.E1.m1.3.3.3a"><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.3.3.3b"><mrow id="S3.E1.m1.1.1.1.1.1.1.10"><mfrac id="S3.E1.m1.1.1.1.1.1.1.8"><mrow id="S3.E1.m1.1.1.1.1.1.1.3.3"><munderover id="S3.E1.m1.1.1.1.1.1.1.3.3.4"><mo movablelimits="false" id="S3.E1.m1.1.1.1.1.1.1.3.3.4.2.2">∑</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.3.3.4.2.3"><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.4.2.3.2">i</mi><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.4.2.3.1">=</mo><mn id="S3.E1.m1.1.1.1.1.1.1.3.3.4.2.3.3">0</mn></mrow><mrow id="S3.E1.m1.1.1.1.1.1.1.3.3.4.3"><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.4.3.2">n</mi><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.4.3.1">−</mo><mn id="S3.E1.m1.1.1.1.1.1.1.3.3.4.3.3">1</mn></mrow></munderover><mrow id="S3.E1.m1.1.1.1.1.1.1.3.3.3"><mtext id="S3.E1.m1.1.1.1.1.1.1.3.3.3.3">max</mtext><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.3.2" lspace="0px" rspace="0px"></mo><mrow id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.2">(</mo><mn id="S3.E1.m1.1.1.1.1.1.1.2.2.2">0</mn><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.3">,</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1"><mtext id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.5">Gap</mtext><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.4" lspace="0px" rspace="0px"></mo><mrow id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.3.3"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.3.3.4">(</mo><msubsup id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.1.1.1"><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.1.1.1.2.2">T</mi><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.1.1.1.2.3">i</mi><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.1.1.1.3">F</mi></msubsup><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.3.3.5">,</mo><msub id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.2.2.2"><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.2.2.2.2">D</mi><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.2.2.2.3">i</mi></msub><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.3.3.6">,</mo><msub id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.3.3.3"><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.3.3.3.2">D</mi><mi id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.3.3.3.3">n</mi></msub><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.1.3.3.7">)</mo></mrow></mrow><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.3.3.3.1.1.4">)</mo></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.3.3.3.2a" lspace="0px" rspace="0px"></mo><msub id="S3.E1.m1.1.1.1.1.1.1.3.3.3.4"><mn id="S3.E1.m1.1.1.1.1.1.1.3.3.3.4.2">𝟙</mn><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.2">{</mo><msubsup id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3.2.2">T</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3.2.3">i</mi><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3">F</mi></msubsup><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.4">≠</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.5">n</mi><mo lspace="0em" rspace="0.167em" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.6">.</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.1">d</mi><mo lspace="0em" rspace="0.167em" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.7">.</mo><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.1.1.1.1.8">}</mo></mrow></msub></mrow></mrow><mrow id="S3.E1.m1.1.1.1.1.1.1.8.8"><munderover id="S3.E1.m1.1.1.1.1.1.1.8.8.6"><mo movablelimits="false" id="S3.E1.m1.1.1.1.1.1.1.8.8.6.2.2">∑</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.8.8.6.2.3"><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.6.2.3.2">i</mi><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.6.2.3.1">=</mo><mn id="S3.E1.m1.1.1.1.1.1.1.8.8.6.2.3.3">0</mn></mrow><mrow id="S3.E1.m1.1.1.1.1.1.1.8.8.6.3"><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.6.3.2">n</mi><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.6.3.1">−</mo><mn id="S3.E1.m1.1.1.1.1.1.1.8.8.6.3.3">1</mn></mrow></munderover><mrow id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1"><mo lspace="0em" stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.2">{</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1"><mrow id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1"><mtext id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.3">max</mtext><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.2" lspace="0px" rspace="0px"></mo><mrow id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.2">(</mo><mn id="S3.E1.m1.1.1.1.1.1.1.6.6.3">0</mn><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.3">,</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1"><mtext id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.5">Gap</mtext><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.4" lspace="0px" rspace="0px"></mo><mrow id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.3.3"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.3.3.4">(</mo><msubsup id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.1.1.1"><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.1.1.1.2.2">T</mi><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.1.1.1.2.3">n</mi><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.1.1.1.3">U</mi></msubsup><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.3.3.5">,</mo><msub id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.2.2.2"><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.2.2.2.2">D</mi><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.2.2.2.3">n</mi></msub><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.3.3.6">,</mo><msub id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.3.3.3"><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.3.3.3.2">D</mi><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.3.3.3.3">i</mi></msub><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.1.3.3.7">)</mo></mrow></mrow><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.1.1.4">)</mo></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.2a" lspace="0px" rspace="0px"></mo><msub id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.4"><mn id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.1.4.2">𝟙</mn><mrow id="S3.E1.m1.1.1.1.1.1.1.4.4.1.1"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.4.4.1.1.2">{</mo><msubsup id="S3.E1.m1.1.1.1.1.1.1.4.4.1.1.3"><mi id="S3.E1.m1.1.1.1.1.1.1.4.4.1.1.3.2.2">T</mi><mi id="S3.E1.m1.1.1.1.1.1.1.4.4.1.1.3.2.3">i</mi><mi id="S3.E1.m1.1.1.1.1.1.1.4.4.1.1.3.3">F</mi></msubsup><mo id="S3.E1.m1.1.1.1.1.1.1.4.4.1.1.4">≠</mo><mi id="S3.E1.m1.1.1.1.1.1.1.4.4.1.1.5">n</mi><mo lspace="0em" rspace="0.167em" id="S3.E1.m1.1.1.1.1.1.1.4.4.1.1.6">.</mo><mi id="S3.E1.m1.1.1.1.1.1.1.4.4.1.1.1">d</mi><mo lspace="0em" rspace="0.167em" id="S3.E1.m1.1.1.1.1.1.1.4.4.1.1.7">.</mo><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.4.4.1.1.8">}</mo></mrow></msub></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.3">+</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2"><mtext id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.3">max</mtext><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.2" lspace="0px" rspace="0px"></mo><mrow id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.2">(</mo><mn id="S3.E1.m1.1.1.1.1.1.1.7.7.4">0</mn><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.3">,</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1"><mtext id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.5">Gap</mtext><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.4" lspace="0px" rspace="0px"></mo><mrow id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.3.3"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.3.3.4">(</mo><msubsup id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.1.1.1"><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.1.1.1.2.2">T</mi><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.1.1.1.2.3">n</mi><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.1.1.1.3">A</mi></msubsup><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.3.3.5">,</mo><msub id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.2.2.2"><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.2.2.2.2">D</mi><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.2.2.2.3">n</mi></msub><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.3.3.6">,</mo><msub id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.3.3.3"><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.3.3.3.2">D</mi><mi id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.3.3.3.3">i</mi></msub><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.1.3.3.7">)</mo></mrow></mrow><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.1.1.4">)</mo></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.2a" lspace="0px" rspace="0px"></mo><msub id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.4"><mn id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.1.2.4.2">𝟙</mn><mrow id="S3.E1.m1.1.1.1.1.1.1.5.5.2.1"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.5.5.2.1.2">{</mo><msubsup id="S3.E1.m1.1.1.1.1.1.1.5.5.2.1.3"><mi id="S3.E1.m1.1.1.1.1.1.1.5.5.2.1.3.2.2">T</mi><mi id="S3.E1.m1.1.1.1.1.1.1.5.5.2.1.3.2.3">i</mi><mi id="S3.E1.m1.1.1.1.1.1.1.5.5.2.1.3.3">F</mi></msubsup><mo id="S3.E1.m1.1.1.1.1.1.1.5.5.2.1.4">≠</mo><mi id="S3.E1.m1.1.1.1.1.1.1.5.5.2.1.5">n</mi><mo lspace="0em" rspace="0.167em" id="S3.E1.m1.1.1.1.1.1.1.5.5.2.1.6">.</mo><mi id="S3.E1.m1.1.1.1.1.1.1.5.5.2.1.1">d</mi><mo lspace="0em" rspace="0.167em" id="S3.E1.m1.1.1.1.1.1.1.5.5.2.1.7">.</mo><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.5.5.2.1.8">}</mo></mrow></msub></mrow></mrow><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.8.8.5.1.3">}</mo></mrow></mrow></mfrac><mo id="S3.E1.m1.1.1.1.1.1.1.10.1">,</mo></mrow></mtd><mtd id="S3.E1.m1.3.3.3c"></mtd></mtr><mtr id="S3.E1.m1.3.3.3d"><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.3.3.3e"><mrow id="S3.E1.m1.2.2.2.2.1.1.1"><mrow id="S3.E1.m1.2.2.2.2.1.1.1.1"><mtext id="S3.E1.m1.2.2.2.2.1.1.1.1.2">&nbsp;if denominator</mtext><mo lspace="0.778em" id="S3.E1.m1.2.2.2.2.1.1.1.1.1">&gt;</mo><mn id="S3.E1.m1.2.2.2.2.1.1.1.1.3">0</mn></mrow><mo id="S3.E1.m1.2.2.2.2.1.1.1.2">,</mo></mrow></mtd><mtd id="S3.E1.m1.3.3.3f"></mtd></mtr><mtr id="S3.E1.m1.3.3.3g"><mtd class="ltx_align_left" columnalign="left" id="S3.E1.m1.3.3.3h"><mrow id="S3.E1.m1.3.3.3.3.1.1"><mtext mathvariant="italic" id="S3.E1.m1.3.3.3.3.1.1a">no gain,</mtext><mtext id="S3.E1.m1.3.3.3.3.1.1b">&nbsp;otherwise.</mtext></mrow></mtd><mtd id="S3.E1.m1.3.3.3i"></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex" id="S3.E1.m1.6b">\text{FUAR}(\mathbb{T}^{F},T_{n}^{U},T_{n}^{A})=\begin{cases}\dfrac{\sum\limits_{i=0}^{n-1}{\text{max}(0,\text{Gap}(T_{i}^{F},D_{i},D_{n}))\mathbbm{1}_{\{T_{i}^{F}\neq n.d.\}}}}{\sum\limits_{i=0}^{n-1}\{{\text{max}(0,\text{Gap}(T_{n}^{U},D_{n},D_{i}))}\mathbbm{1}_{\{T_{i}^{F}\neq n.d.\}}+{\text{max}(0,\text{Gap}(T_{n}^{A},D_{n},D_{i}))}\mathbbm{1}_{\{T_{i}^{F}\neq n.d.\}}\}},\\
\text{ if denominator}\ &gt;0,\\
\textit{no gain,}\text{\ otherwise.}\\
\end{cases}</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.6c">FUAR ( blackboard_T start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT , italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_U end_POSTSUPERSCRIPT , italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT ) = { start_ROW start_CELL divide start_ARG ∑ start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT max ( 0 , Gap ( italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT , italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_D start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) ) blackboard_1 start_POSTSUBSCRIPT { italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT ≠ italic_n . italic_d . } end_POSTSUBSCRIPT end_ARG start_ARG ∑ start_POSTSUBSCRIPT italic_i = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT { max ( 0 , Gap ( italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_U end_POSTSUPERSCRIPT , italic_D start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) blackboard_1 start_POSTSUBSCRIPT { italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT ≠ italic_n . italic_d . } end_POSTSUBSCRIPT + max ( 0 , Gap ( italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT , italic_D start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT , italic_D start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ) blackboard_1 start_POSTSUBSCRIPT { italic_T start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT ≠ italic_n . italic_d . } end_POSTSUBSCRIPT } end_ARG , end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL if denominator &gt; 0 , end_CELL start_CELL end_CELL end_ROW start_ROW start_CELL italic_no italic_gain, otherwise. end_CELL start_CELL end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.6">벤치마크 태스크 <math alttext="\mathbb{T}^{F}" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><msup id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">𝕋</mi><mi id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">F</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">𝕋</ci><ci id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">𝐹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\mathbb{T}^{F}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">blackboard_T start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="T_{n}^{U}" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><msubsup id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.2.2" xref="S3.SS2.p3.2.m2.1.1.2.2.cmml">T</mi><mi id="S3.SS2.p3.2.m2.1.1.2.3" xref="S3.SS2.p3.2.m2.1.1.2.3.cmml">n</mi><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">U</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.2.1.cmml" xref="S3.SS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.2.m2.1.1.2.2.cmml" xref="S3.SS2.p3.2.m2.1.1.2.2">𝑇</ci><ci id="S3.SS2.p3.2.m2.1.1.2.3.cmml" xref="S3.SS2.p3.2.m2.1.1.2.3">𝑛</ci></apply><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">𝑈</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">T_{n}^{U}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_U end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="T_{n}^{A}" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><msubsup id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2.2" xref="S3.SS2.p3.3.m3.1.1.2.2.cmml">T</mi><mi id="S3.SS2.p3.3.m3.1.1.2.3" xref="S3.SS2.p3.3.m3.1.1.2.3.cmml">n</mi><mi id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">A</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">superscript</csymbol><apply id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.3.m3.1.1.2.1.cmml" xref="S3.SS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p3.3.m3.1.1.2.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2.2">𝑇</ci><ci id="S3.SS2.p3.3.m3.1.1.2.3.cmml" xref="S3.SS2.p3.3.m3.1.1.2.3">𝑛</ci></apply><ci id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">𝐴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">T_{n}^{A}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT</annotation></semantics></math>의 선택은 각각의 실험 설정에 따라 다를 수 있다. <span class="ltx_text" id="S3.SS2.p3.6.1">FUAR</span> 값이 1.0인 동일한 trade-off 시나리오를 나타내며, 여기서 <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.6.2">one</span> <math alttext="\mathbb{T}^{F}" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><msup id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">𝕋</mi><mi id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml">F</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">𝕋</ci><ci id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3">𝐹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">\mathbb{T}^{F}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">blackboard_T start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT</annotation></semantics></math>의 time-invariant knowledge instance is forgotten on average to gain one new or updated knowledge instance of <math alttext="T_{n}^{U}" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><msubsup id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml"><mi id="S3.SS2.p3.5.m5.1.1.2.2" xref="S3.SS2.p3.5.m5.1.1.2.2.cmml">T</mi><mi id="S3.SS2.p3.5.m5.1.1.2.3" xref="S3.SS2.p3.5.m5.1.1.2.3.cmml">n</mi><mi id="S3.SS2.p3.5.m5.1.1.3" xref="S3.SS2.p3.5.m5.1.1.3.cmml">U</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">superscript</csymbol><apply id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.2.1.cmml" xref="S3.SS2.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.2.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2.2">𝑇</ci><ci id="S3.SS2.p3.5.m5.1.1.2.3.cmml" xref="S3.SS2.p3.5.m5.1.1.2.3">𝑛</ci></apply><ci id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3">𝑈</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">T_{n}^{U}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_U end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="T_{n}^{A}" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.1"><semantics id="S3.SS2.p3.6.m6.1a"><msubsup id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2.2" xref="S3.SS2.p3.6.m6.1.1.2.2.cmml">T</mi><mi id="S3.SS2.p3.6.m6.1.1.2.3" xref="S3.SS2.p3.6.m6.1.1.2.3.cmml">n</mi><mi id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml">A</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">superscript</csymbol><apply id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.2.1.cmml" xref="S3.SS2.p3.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.p3.6.m6.1.1.2.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2.2">𝑇</ci><ci id="S3.SS2.p3.6.m6.1.1.2.3.cmml" xref="S3.SS2.p3.6.m6.1.1.2.3">𝑛</ci></apply><ci id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3">𝐴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">T_{n}^{A}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m6.1d">italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT</annotation></semantics></math>. 분모에서 두 용어는 새로 얻은 지식과 업데이트된 지식이 정의에 의해 상호 배타적이기 때문에 합산된다. 값이 1보다 작으면 모델이 잊힌 지식의 양보다 더 많은 새로운 또는 업데이트된 지식을 얻는다는 것을 의미하므로 낮은 <span class="ltx_text" id="S3.SS2.p3.6.3">FUAR</span> 값을 나타내는 방법은 CKL에 적합한 것으로 간주할 수 있다. 값이 0이면 전혀 망각이 일어나지 않는 경우로서 성능의 상한이 된다. 분모가 0인 경우 <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.6.4">no gain</span>으로 경우를 나타내며 최악의 경우로 간주합니다. <span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>Each of the last two sentences means that we do not measure positive <span class="ltx_text ltx_font_italic" id="footnote6.1">backward</span> transfer and negative <span class="ltx_text ltx_font_italic" id="footnote6.2">forward</span> transfer, respectively. The latter in some cases actually do happen (shown in Appendix <a class="ltx_ref" href="#A7" title="Appendix G Exploring How CKL Methods Transfer Across LM Architectures ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">G</span></a>). Explanations about the backward and forward transfer are in Appendix <a class="ltx_ref" href="#A1.SS1" title="A.1 Traditional Continual Learning ‣ Appendix A Extension of Related Works ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</span></span></span></p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Setup</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.p1.2">우리는 인코더-디코더 모델인 T5 <cite class="ltx_cite ltx_citemacro_citep">(Raffel et al., <a class="ltx_ref" href="#bib.bib42" title="">2019</a>)</cite>, 큰 LM(<span class="ltx_text" id="S4.p1.1.1" style="position:relative; bottom:0.7pt;"><math alttext="\scriptstyle\sim" class="ltx_Math" display="inline" id="S4.p1.1.1.1.m1.1"><semantics id="S4.p1.1.1.1.m1.1a"><mo id="S4.p1.1.1.1.m1.1.1" mathsize="70%" xref="S4.p1.1.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S4.p1.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.p1.1.1.1.m1.1.1.cmml" xref="S4.p1.1.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.1.1.m1.1c">\scriptstyle\sim</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.1.1.m1.1d">∼</annotation></semantics></math></span> 737M params)을 사용하여 2019년 4월 C4 덤프와 2020년 5월 Wikipedia 덤프(thus <math alttext="D_{0}" class="ltx_Math" display="inline" id="S4.p1.2.m1.1"><semantics id="S4.p1.2.m1.1a"><msub id="S4.p1.2.m1.1.1" xref="S4.p1.2.m1.1.1.cmml"><mi id="S4.p1.2.m1.1.1.2" xref="S4.p1.2.m1.1.1.2.cmml">D</mi><mn id="S4.p1.2.m1.1.1.3" xref="S4.p1.2.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S4.p1.2.m1.1b"><apply id="S4.p1.2.m1.1.1.cmml" xref="S4.p1.2.m1.1.1"><csymbol cd="ambiguous" id="S4.p1.2.m1.1.1.1.cmml" xref="S4.p1.2.m1.1.1">subscript</csymbol><ci id="S4.p1.2.m1.1.1.2.cmml" xref="S4.p1.2.m1.1.1.2">𝐷</ci><cn id="S4.p1.2.m1.1.1.3.cmml" type="integer" xref="S4.p1.2.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m1.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m1.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> in our experiments)에서 처음 사전 훈련된 SSM(Salient span masking)을 사용하여 광범위한 실험을 수행했다. 사전 훈련, 연속 사전 훈련 및 평가 구성의 세부 사항은 부록 <a class="ltx_ref" href="#A3" title="Appendix C Experimental Configuration ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">C</span></a>에 있다. 다음 메서드를 CKL 벤치마크의 베이스라인으로 설정하고 <span class="ltx_text ltx_font_italic" id="S4.p1.2.2">regularization</span>, <span class="ltx_text ltx_font_italic" id="S4.p1.2.3">rehearsal</span>, <span class="ltx_text ltx_font_italic" id="S4.p1.2.4">parameter-expansion</span> 메서드로 분류합니다. 각 방법의 구현에 사용된 특정 하이퍼파라미터는 부록 <a class="ltx_ref" href="#A4" title="Appendix D Hyperparameters for Implementation of CKL Methods ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">D</span></a>에 자세히 설명되어 있다.</p>
</div>
<div id="S4.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.p2.1"><span class="ltx_text ltx_font_bold" id="S4.p2.1.1">Initial</span>은 계속된 사전 훈련 전에 LM을 평가하는 설정을 나타냅니다. 이 모델의 성능은 <span class="ltx_text ltx_font_italic" id="S4.p2.1.2">upper-bound</span> for <span class="ltx_text ltx_font_smallcaps" id="S4.p2.1.3">InvariantLAMA</span> and <span class="ltx_text ltx_font_italic" id="S4.p2.1.4">lower-bound</span> on <span class="ltx_text ltx_font_smallcaps" id="S4.p2.1.5">UpdatedLAMA</span> and <span class="ltx_text ltx_font_smallcaps" id="S4.p2.1.6">NewLAMA</span>로 간주할 수 있습니다.</p>
</div>
<div id="S4.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.p3.1"><span class="ltx_text ltx_font_bold" id="S4.p3.1.1">Vanilla</span>은 추가 사전 훈련의 특정 설정입니다. 여기서 도메인은 <span class="ltx_text ltx_font_italic" id="S4.p3.1.2">new</span> 지식이며 LM은 별도의 훈련 전략 없이 추가 사전 훈련됩니다.</p>
</div>
<div id="S4.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.p4.1"><span class="ltx_text ltx_font_bold" id="S4.p4.1.1">RecAdam</span> <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="#bib.bib3" title="">2020</a>)</cite>는 정규화 방법의 범주에 속한다. 기존의 정규화 방법(EWC<cite class="ltx_cite ltx_citemacro_citep">(Kirkpatrick et al., <a class="ltx_ref" href="#bib.bib22" title="">2017</a>)</cite>)보다 모델 파라미터들 사이에 더 강한 독립 가정을 두며, 초기 사전 학습 코퍼스에 접근하지 않고 지속적인 사전 학습 동안 모델 가중치를 정규화한다. 최적화기는 트레이닝이 진행됨에 따라 더 적은 정규화가 적용되도록 어닐링된다.</p>
</div>
<div id="S4.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.p5.1"><span class="ltx_text ltx_font_bold" id="S4.p5.1.1">Mix-Review</span> <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="#bib.bib17" title="">2021</a>)</cite>는 현재 시간 단계에서의 믹스 비율에 따라 초기 프리트레이닝 코퍼스에 대한 액세스를 가정하고 계속된 프리트레이닝 동안 초기 프리트레이닝 데이터의 랜덤 서브세트에서 믹스하는 리허설 방법의 범주에 속한다. 훈련이 진행됨에 따라 혼합 비율은 0을 향해 감쇠하여 각 반복에서 혼합된 원본 데이터의 양이 감소한다.</p>
</div>
<div id="S4.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.p6.1"><span class="ltx_text ltx_font_bold" id="S4.p6.1.1">LoRA</span> <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="#bib.bib19" title="">2021</a>)</cite>는 parameter-expansion 메소드의 범주에 속한다. LM의 원래 매개변수를 동결하고 지속적인 사전 훈련 동안 업데이트되는 각 계층에 훈련 가능한 순위 분해 행렬을 추가한다. <cite class="ltx_cite ltx_citemacro_citet">Hu et al. (<a class="ltx_ref" href="#bib.bib19" title="">2021</a>)</cite>는 디코더 전용 모델(GPT-2><cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="#bib.bib41" title="">2019</a>)</cite> & GPT-3><cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="#bib.bib2" title="">2020</a>)</cite>)로 이 방법을 구현하였고, 이를 T5-LoRA로 표기한 인코더-디코더 모델에 적용하였다.</p>
</div>
<div id="S4.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.p7.1"><span class="ltx_text ltx_font_bold" id="S4.p7.1.1">K-Adapter</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib52" title="">2021b</a>)</cite>는 계속되는 사전 훈련 동안 업데이트되는 <span class="ltx_text ltx_font_italic" id="S4.p7.1.2">k</span> 새로운 레이어의 수, 즉 <span class="ltx_text ltx_font_italic" id="S4.p7.1.3">adapters</span>을 추가하면서 LM의 원래 매개 변수를 동결하는 또 다른 매개 변수 확장 방법입니다. <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="#bib.bib52" title="">2021b</a>)</cite>는 <span class="ltx_text ltx_font_italic" id="S4.p7.1.4">factual</span> 및 <span class="ltx_text ltx_font_italic" id="S4.p7.1.5">linguistic</span> 인코더 전용 모델, BERT<cite class="ltx_cite ltx_citemacro_citep">(Devlin et al., <a class="ltx_ref" href="#bib.bib8" title="">2019</a>)</cite> & RoBERTa<cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="#bib.bib32" title="">2019</a>)</cite>를 성공적으로 주입한 반면, 인코더 디코더 모델, T5 및 디코더 전용 모델 GPT-2에도 적용했습니다.</p>
</div>
<div id="S4.p8" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.p8.1"><span class="ltx_text ltx_font_bold" id="S4.p8.1.1">Modular</span>은 계속된 사전 훈련 동안 업데이트되는 새롭고 무작위로 초기화된 인코더를 추가하면서 원래 사전 훈련된 인코더를 동결시키는 인코더-디코더 모델에 대해 특별히 새로 제안된 매개변수 확장 방법이다. 새로 추가된 인코더의 경우 원본 인코더와 디코더의 크기를 <span class="ltx_text ltx_font_italic" id="S4.p8.1.2">T5-small</span>으로 유지하면서 크기를 <span class="ltx_text ltx_font_italic" id="S4.p8.1.3">T5-large</span>으로 변경한다.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental Results</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.p1.2">이 절에서는 먼저 CKL 벤치마크에 대한 주요 실험 결과를 보여준다. 그런 다음, 지속적인 지식 학습의 여러 단계, 즉 CKL이 진정으로 끊임없이 변화하는 LM을 훈련하기 위해 필요하기 때문에, 우리는 여러 CKL 단계의 영향과 epoch, 말뭉치 크기 및 총 훈련 단계 수가 CKL에 어떻게 영향을 미치는지 탐구한다. 또한 부록 <a class="ltx_ref" href="#A5" title="Appendix E Exploring the Trade-off of Varying the Learning Rate for Continual Pretraining ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">E</span></a>에서 학습률이 CKL에 어떤 영향을 미치는지, <math alttext="D_{1}" class="ltx_Math" display="inline" id="S5.p1.1.m1.1"><semantics id="S5.p1.1.m1.1a"><msub id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mi id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml">D</mi><mn id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1">subscript</csymbol><ci id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">𝐷</ci><cn id="S5.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S5.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>에 대한 지속적인 사전 훈련이 부록 <a class="ltx_ref" href="#A6" title="Appendix F Exploring How Continually Pretraining on 𝐷₁ Affects KILT Tasks Which Requires Knowledge from 𝐷₀ ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">F</span></a>에서 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S5.p1.2.m2.1"><semantics id="S5.p1.2.m2.1a"><msub id="S5.p1.2.m2.1.1" xref="S5.p1.2.m2.1.1.cmml"><mi id="S5.p1.2.m2.1.1.2" xref="S5.p1.2.m2.1.1.2.cmml">D</mi><mn id="S5.p1.2.m2.1.1.3" xref="S5.p1.2.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.p1.2.m2.1b"><apply id="S5.p1.2.m2.1.1.cmml" xref="S5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.p1.2.m2.1.1.1.cmml" xref="S5.p1.2.m2.1.1">subscript</csymbol><ci id="S5.p1.2.m2.1.1.2.cmml" xref="S5.p1.2.m2.1.1.2">𝐷</ci><cn id="S5.p1.2.m2.1.1.3.cmml" type="integer" xref="S5.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.2.m2.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S5.p1.2.m2.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>의 지식을 필요로 하는 KILT 작업의 성능에 어떤 영향을 미치는지, 부록 <a class="ltx_ref" href="#A7" title="Appendix G Exploring How CKL Methods Transfer Across LM Architectures ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">G</span></a>에서 CKL 방법이 LM 아키텍처에 걸쳐 어떻게 전달되는지, 부록 <a class="ltx_ref" href="#A8" title="Appendix H Exploring the Prediction Change During Continual Pretraining ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">H</span></a>에서 CKL 동안 예측 출력이 어떻게 변화하는지를 탐구한다.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Main Results</h3>

<div id="S5.SS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.p1.2">표 <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.1 Main Results ‣ 5 Experimental Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>는 CKL 벤치마크에 대한 우리의 주요 실험 결과를 보여준다. 표 <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.1 Main Results ‣ 5 Experimental Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>에서는 정확한 일치(EM)만 보고되지만, 부록 <a class="ltx_ref" href="#A10" title="Appendix J Additional Analysis of Main Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">J</span></a>에서는 F1 점수와 k(<span class="ltx_text ltx_font_italic" id="S5.SS1.p1.2.1">P@k</span>, k=1,5,10,20,50,100)에서의 평균 정밀도를 보고한다. T5 모델은 원래 C4(약 1조 토큰 업데이트) 및 위키피디아에서 사전 훈련되며, 이는 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><msub id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml"><mi id="S5.SS1.p1.1.m1.1.1.2" xref="S5.SS1.p1.1.m1.1.1.2.cmml">D</mi><mn id="S5.SS1.p1.1.m1.1.1.3" xref="S5.SS1.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><apply id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.1.m1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.p1.1.m1.1.1.2.cmml" xref="S5.SS1.p1.1.m1.1.1.2">𝐷</ci><cn id="S5.SS1.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>로 간주된다. <span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content">7</sup><span class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>In this work, we see C4 and Wikipedia together as <math alttext="D_{0}" class="ltx_Math" display="inline" id="footnote7.m1.1"><semantics id="footnote7.m1.1b"><msub id="footnote7.m1.1.1" xref="footnote7.m1.1.1.cmml"><mi id="footnote7.m1.1.1.2" xref="footnote7.m1.1.1.2.cmml">D</mi><mn id="footnote7.m1.1.1.3" xref="footnote7.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="footnote7.m1.1c"><apply id="footnote7.m1.1.1.cmml" xref="footnote7.m1.1.1"><csymbol cd="ambiguous" id="footnote7.m1.1.1.1.cmml" xref="footnote7.m1.1.1">subscript</csymbol><ci id="footnote7.m1.1.1.2.cmml" xref="footnote7.m1.1.1.2">𝐷</ci><cn id="footnote7.m1.1.1.3.cmml" type="integer" xref="footnote7.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote7.m1.1d">D_{0}</annotation><annotation encoding="application/x-llamapun" id="footnote7.m1.1e">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> 왜냐하면 우리는 LMs 내의 지식이 이러한 두 코퍼러에 대한 트레이닝 사이에서 어떻게 변화하는지를 측정하지 않기 때문이다. </span></span></span> 그런 다음, 각 CKL 메소드를 사용하여 4개의 epoch(25k 글로벌 트레이닝 단계, 약 673백만 토큰 업데이트)에 대해 CC-RecentNews(corpus <math alttext="D_{1}" class="ltx_Math" display="inline" id="S5.SS1.p1.2.m2.1"><semantics id="S5.SS1.p1.2.m2.1a"><msub id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml"><mi id="S5.SS1.p1.2.m2.1.1.2" xref="S5.SS1.p1.2.m2.1.1.2.cmml">D</mi><mn id="S5.SS1.p1.2.m2.1.1.3" xref="S5.SS1.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><apply id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p1.2.m2.1.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS1.p1.2.m2.1.1.2.cmml" xref="S5.SS1.p1.2.m2.1.1.2">𝐷</ci><cn id="S5.SS1.p1.2.m2.1.1.3.cmml" type="integer" xref="S5.SS1.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.2.m2.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>)에서 지속적으로 사전 트레이닝하였다. IL, UL, NL, NLE 각각은 <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p1.2.2">InvariantLAMA</span>, <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p1.2.3">UpdatedLAMA</span>, <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p1.2.4">NewLAMA</span>, <span class="ltx_text ltx_font_smallcaps" id="S5.SS1.p1.2.5">NewLAMA-Easy</span>의 약자이다. 이 실험을 위한 설정에 대한 자세한 설명은 캡션에 포함되어 있습니다.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.p2.1">우리는 먼저 T5-MixReview를 제외한 모든 CKL 방법이 <span class="ltx_text" id="S5.SS1.p2.1.1">FUAR</span>에서 볼 수 있듯이 T5-Vanilla의 순진한 접근법을 사용하는 것보다 새로운 지식을 업데이트하고 획득하는 동안 시간 불변 지식을 덜 잊는 데 더 효과적임을 발견했다. 이 결과는 또한 CKL과 CL의 주요 차이점을 강조하며, CKL에서는 전통적인 CL 설정<cite class="ltx_cite ltx_citemacro_citep">(Prabhu et al., <a class="ltx_ref" href="#bib.bib40" title="">2020</a>; Bang et al., <a class="ltx_ref" href="#bib.bib1" title="">2021</a>)</cite>에서 리허설 방법이 강한 성능을 보이는 반면, UL과 NL의 성능에서 볼 수 있듯이 오래된 지식의 업데이트와 새로운 지식의 습득이 심각하게 억제되는 반면 IL의 성능에서 볼 수 있듯이 망각의 경쟁적인 완화는 보이지 않기 때문에 최악의 성능을 보인다. 다른 CKL 방법 중에서 매개변수 확장 방법이 더 나은 결과를 얻는 다소 일관된 경향을 관찰한다. UL, NL 및 NLE 모두에 대한 첫 번째 및 두 번째 최상의 결과는 모두 매개변수 확장 방법에서 나온 것이다. 한편, UL과 NL은 동일한 절차를 따라 구성되지만 UL과 NL의 EM 점수 사이에는 큰 차이가 있다. 우리는 부록 <a class="ltx_ref" href="#A9" title="Appendix I Exploring the Cause of the EM Gap Between UpdatedLAMA and NewLAMA ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">I</span></a>에서 이러한 차이의 근원을 분석한다.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.p3.1"><a class="ltx_ref" href="#A10.F9" title="Figure 9 ‣ Appendix J Additional Analysis of Main Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">9</span></a>는 각 태스크의 EM 점수가 가장 강건한 성능을 가진 CKL 방식인 T5-Kadapters와 T5-Vanilla로 어떻게 변화하는지를 <math alttext="D_{1}" class="ltx_Math" display="inline" id="S5.SS1.p3.1.m1.1"><semantics id="S5.SS1.p3.1.m1.1a"><msub id="S5.SS1.p3.1.m1.1.1" xref="S5.SS1.p3.1.m1.1.1.cmml"><mi id="S5.SS1.p3.1.m1.1.1.2" xref="S5.SS1.p3.1.m1.1.1.2.cmml">D</mi><mn id="S5.SS1.p3.1.m1.1.1.3" xref="S5.SS1.p3.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p3.1.m1.1b"><apply id="S5.SS1.p3.1.m1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p3.1.m1.1.1.1.cmml" xref="S5.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.p3.1.m1.1.1.2.cmml" xref="S5.SS1.p3.1.m1.1.1.2">𝐷</ci><cn id="S5.SS1.p3.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.p3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p3.1.m1.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p3.1.m1.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>에서 지속적으로 사전 훈련한다. 모든 작업에서 T5-Initial의 성능은 IL의 경우 상위 바운드로, UL, NL, NLE의 경우 하위 바운드로 간주될 수 있다. 우리의 주요 관찰과 일치하는 CKL은 <span class="ltx_text ltx_font_italic" id="S5.SS1.p3.1.1">time-invariant</span> 세계 지식을 상당히 보존하는 동시에 T5-Vanilla와 비교하여 업데이트 및 새로운 세계 지식을 획득하여 전반적인 트레이드오프를 완화할 수 있다.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 2:</span>Zero-shot probing performance on the CKL benchmark. 각 작업 및 메트릭에 대한 최상의 결과는 굵게 표시되고 두 번째 최상의 결과는 밑줄이 그어져 표시됩니다.</figcaption>
<table id="S5.T2.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S5.T2.2.2" class="ltx_tr">
<td id="S5.T2.2.2.3" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2">
<span id="S5.T2.2.2.3.1" class="ltx_text"></span><span id="S5.T2.2.2.3.2" class="ltx_text ltx_font_bold"> <span id="S5.T2.2.2.3.2.1" class="ltx_text">
<span id="S5.T2.2.2.3.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T2.2.2.3.2.1.1.1" class="ltx_tr">
<span id="S5.T2.2.2.3.2.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">Method</span></span>
</span></span> <span id="S5.T2.2.2.3.2.2" class="ltx_text"></span></span>
</td>
<td id="S5.T2.2.2.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2">
<span id="S5.T2.2.2.4.1" class="ltx_text"></span><span id="S5.T2.2.2.4.2" class="ltx_text ltx_font_bold"> <span id="S5.T2.2.2.4.2.1" class="ltx_text">
<span id="S5.T2.2.2.4.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T2.2.2.4.2.1.1.1" class="ltx_tr">
<span id="S5.T2.2.2.4.2.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"># of Params</span></span>
<span id="S5.T2.2.2.4.2.1.1.2" class="ltx_tr">
<span id="S5.T2.2.2.4.2.1.1.2.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">(Trainable / Total)</span></span>
</span></span> <span id="S5.T2.2.2.4.2.2" class="ltx_text"></span></span>
</td>
<td id="S5.T2.2.2.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.2.5.1" class="ltx_text ltx_font_bold">IL</span></td>
<td id="S5.T2.2.2.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.2.6.1" class="ltx_text ltx_font_bold">UL</span></td>
<td id="S5.T2.2.2.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.2.7.1" class="ltx_text ltx_font_bold">NL</span></td>
<td id="S5.T2.2.2.8" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.2.8.1" class="ltx_text ltx_font_bold">NLE</span></td>
<td id="S5.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2">
<span id="S5.T2.2.2.2.3" class="ltx_text"></span><span id="S5.T2.2.2.2.2" class="ltx_text ltx_font_bold"> <span id="S5.T2.2.2.2.2.2" class="ltx_text">
<span id="S5.T2.2.2.2.2.2.2.2" class="ltx_tabular ltx_align_middle">
<span id="S5.T2.2.2.2.2.2.2.2.3" class="ltx_tr">
<span id="S5.T2.2.2.2.2.2.2.2.3.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.2.2.2.2.2.2.3.1.1" class="ltx_text">FUAR</span></span></span>
<span id="S5.T2.2.2.2.2.2.2.2.2" class="ltx_tr">
<span id="S5.T2.2.2.2.2.2.2.2.2.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="S5.T2.1.1.1.1.1.1.1.1.1.m1.4" class="ltx_Math" alttext="\mathbf{{\left((IL),UL,NL\right)}}" display="inline"><semantics id="S5.T2.1.1.1.1.1.1.1.1.1.m1.4a"><mrow id="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.1" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml"><mo mathvariant="normal" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.1.2" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml">(</mo><mrow id="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.1.1.2" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml"><mo mathvariant="normal" stretchy="false" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.1.1.2.1" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml">(</mo><mi id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">𝐈𝐋</mi><mo mathvariant="normal" stretchy="false" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.1.1.2.2" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml">)</mo></mrow><mo mathvariant="normal" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.1.3" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml">,</mo><mi id="S5.T2.1.1.1.1.1.1.1.1.1.m1.2.2" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.2.2.cmml">𝐔𝐋</mi><mo mathvariant="normal" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.1.4" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml">,</mo><mi id="S5.T2.1.1.1.1.1.1.1.1.1.m1.3.3" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.3.3.cmml">𝐍𝐋</mi><mo mathvariant="normal" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.1.5" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.4b"><vector id="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.4.4.1"><ci id="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.1.1">𝐈𝐋</ci><ci id="S5.T2.1.1.1.1.1.1.1.1.1.m1.2.2.cmml" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.2.2">𝐔𝐋</ci><ci id="S5.T2.1.1.1.1.1.1.1.1.1.m1.3.3.cmml" xref="S5.T2.1.1.1.1.1.1.1.1.1.m1.3.3">𝐍𝐋</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.4c">\mathbf{{\left((IL),UL,NL\right)}}</annotation><annotation encoding="application/x-llamapun" id="S5.T2.1.1.1.1.1.1.1.1.1.m1.4d">( ( bold_IL ) , bold_UL , bold_NL )</annotation></semantics></math> <math id="S5.T2.2.2.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T2.2.2.2.2.2.2.2.2.2.m2.1a"><mo mathvariant="normal" stretchy="false" id="S5.T2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="S5.T2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T2.2.2.2.2.2.2.2.2.2.m2.1b"><ci id="S5.T2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S5.T2.2.2.2.2.2.2.2.2.2.m2.1.1">normal-↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.2.2.2.2.2.2.2.2.m2.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T2.2.2.2.2.2.2.2.2.2.m2.1d">↓</annotation></semantics></math></span></span>
</span></span> <span id="S5.T2.2.2.2.2.3" class="ltx_text"></span></span>
</td>
</tr>
<tr id="S5.T2.2.3" class="ltx_tr">
<td id="S5.T2.2.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">EM</td>
<td id="S5.T2.2.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">EM</td>
<td id="S5.T2.2.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">EM</td>
<td id="S5.T2.2.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">EM</td>
</tr>
<tr id="S5.T2.2.4" class="ltx_tr">
<td id="S5.T2.2.4.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Initial</td>
<td id="S5.T2.2.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">0M / 737M</td>
<td id="S5.T2.2.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.4.3.1" class="ltx_text ltx_font_bold">24.17</span></td>
<td id="S5.T2.2.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">1.62</td>
<td id="S5.T2.2.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">1.88</td>
<td id="S5.T2.2.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">10.32</td>
<td id="S5.T2.2.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">-</td>
</tr>
<tr id="S5.T2.2.5" class="ltx_tr">
<td id="S5.T2.2.5.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Vanilla</td>
<td id="S5.T2.2.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">737M / 737M</td>
<td id="S5.T2.2.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">12.89</td>
<td id="S5.T2.2.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">10.17</td>
<td id="S5.T2.2.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">3.77</td>
<td id="S5.T2.2.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">17.75</td>
<td id="S5.T2.2.5.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">1.08</td>
</tr>
<tr id="S5.T2.2.6" class="ltx_tr">
<td id="S5.T2.2.6.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-RecAdam</td>
<td id="S5.T2.2.6.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">737M / 737M</td>
<td id="S5.T2.2.6.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.20</td>
<td id="S5.T2.2.6.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.55</td>
<td id="S5.T2.2.6.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">4.02</td>
<td id="S5.T2.2.6.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.85</td>
<td id="S5.T2.2.6.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">0.84</td>
</tr>
<tr id="S5.T2.2.7" class="ltx_tr">
<td id="S5.T2.2.7.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-MixReview</td>
<td id="S5.T2.2.7.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">737M / 737M</td>
<td id="S5.T2.2.7.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.92</td>
<td id="S5.T2.2.7.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">6.49</td>
<td id="S5.T2.2.7.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">2.89</td>
<td id="S5.T2.2.7.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.86</td>
<td id="S5.T2.2.7.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1.74</td>
</tr>
<tr id="S5.T2.2.8" class="ltx_tr">
<td id="S5.T2.2.8.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-LoRA</td>
<td id="S5.T2.2.8.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">403M / 738M</td>
<td id="S5.T2.2.8.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.58</td>
<td id="S5.T2.2.8.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.8.4.1" class="ltx_text ltx_font_bold">12.77</span></td>
<td id="S5.T2.2.8.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">4.52</td>
<td id="S5.T2.2.8.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.8.6.1" class="ltx_text ltx_font_bold">19.56</span></td>
<td id="S5.T2.2.8.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">0.55</td>
</tr>
<tr id="S5.T2.2.9" class="ltx_tr">
<td id="S5.T2.2.9.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Kadapters (k=2)</td>
<td id="S5.T2.2.9.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">427M / 762M</td>
<td id="S5.T2.2.9.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.59</td>
<td id="S5.T2.2.9.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.34</td>
<td id="S5.T2.2.9.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.9.5.1" class="ltx_text ltx_font_bold">5.03</span></td>
<td id="S5.T2.2.9.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">18.75</td>
<td id="S5.T2.2.9.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.9.7.1" class="ltx_text ltx_framed_underline">0.33</span></td>
</tr>
<tr id="S5.T2.2.10" class="ltx_tr">
<td id="S5.T2.2.10.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Kadapters (k=3)</td>
<td id="S5.T2.2.10.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">440M / 775M</td>
<td id="S5.T2.2.10.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.76</td>
<td id="S5.T2.2.10.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.10.4.1" class="ltx_text ltx_framed_underline">12.66</span></td>
<td id="S5.T2.2.10.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">4.02</td>
<td id="S5.T2.2.10.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.00</td>
<td id="S5.T2.2.10.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.10.7.1" class="ltx_text ltx_framed_underline">0.33</span></td>
</tr>
<tr id="S5.T2.2.11" class="ltx_tr">
<td id="S5.T2.2.11.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Modular</td>
<td id="S5.T2.2.11.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">438M / 773M</td>
<td id="S5.T2.2.11.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.11.3.1" class="ltx_text ltx_framed_underline">20.29</span></td>
<td id="S5.T2.2.11.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.11.4.1" class="ltx_text ltx_framed_underline">12.66</span></td>
<td id="S5.T2.2.11.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.11.5.1" class="ltx_text ltx_framed_underline">4.65</span></td>
<td id="S5.T2.2.11.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.11.6.1" class="ltx_text ltx_framed_underline">19.24</span></td>
<td id="S5.T2.2.11.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="S5.T2.2.11.7.1" class="ltx_text ltx_font_bold">0.28</span></td>
</tr>
</tbody></table>
</figure>
<figure id="S5.F2" class="ltx_figure">
<div class="ltx_flex_figure">

<div class="ltx_flex_cell 
                  ltx_flex_size_1">
<figure id="S5.F2.1" class="ltx_figure ltx_flex_size_1 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x2.png" id="S5.F2.1.g1" class="ltx_graphics ltx_img_landscape" width="761" height="44" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell 
                  ltx_flex_size_4">
<figure id="S5.F1.sf1" class="ltx_figure ltx_flex_size_4 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x3.png" id="S5.F1.sf1.g1" class="ltx_graphics ltx_img_landscape" width="761" height="609" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a)</span><span class="ltx_text ltx_font_smallcaps" id="S5.F1.sf1.2.1">InvariantLAMA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell 
                  ltx_flex_size_4">
<figure id="S5.F1.sf2" class="ltx_figure ltx_flex_size_4 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x4.png" id="S5.F1.sf2.g1" class="ltx_graphics ltx_img_landscape" width="761" height="609" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b)</span><span class="ltx_text ltx_font_smallcaps" id="S5.F1.sf2.2.1">UpdatedLAMA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell 
                  ltx_flex_size_4">
<figure id="S5.F1.sf3" class="ltx_figure ltx_flex_size_4 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x5.png" id="S5.F1.sf3.g1" class="ltx_graphics ltx_img_landscape" width="761" height="607" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span><span id="S5.F1.sf3.2.1" class="ltx_text ltx_font_smallcaps">NewLAMA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell 
                  ltx_flex_size_4">
<figure id="S5.F1.sf4" class="ltx_figure ltx_flex_size_4 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x6.png" id="S5.F1.sf4.g1" class="ltx_graphics ltx_img_landscape" width="761" height="607" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d)</span><span class="ltx_text ltx_font_smallcaps" id="S5.F1.sf4.2.1">NewLAMA-Easy</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2:</span>Performance at each epoch during continue pretraining in the main experimental setting.</figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Exploring Multiple phases of CKL</h3>

<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 3: </span>T5 모델 이후의 Zero-shot 프로빙 성능은 <span class="ltx_text ltx_font_smallcaps" id="S5.T3.29.1">CC-RecentNews</span>의 서로 다른 하위 집합에 대해 지속적으로 사전 훈련됩니다. NLE와 IL은 각각 NewLAMA-Easy와 InvariantLAMA를 나타낸다. <a class="ltx_ref" href="#S5.SS2" title="5.2 Exploring Multiple phases of CKL ‣ 5 Experimental Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">5.2</span></a>절의 본문에서 설명하는 연속적 사전 훈련에 사용된 코퍼스에 따른 시나리오는 세 가지이다. 세 시나리오의 <span class="ltx_text" id="S5.T3.30.2">FUAR</span>은 다르게 계산되며, 해당 태스크는 <span class="ltx_text" id="S5.T3.31.3">FUAR</span>: <math alttext="\mathbb{T}^{F}" class="ltx_Math" display="inline" id="S5.T3.9.m1.1"><semantics id="S5.T3.9.m1.1b"><msup id="S5.T3.9.m1.1.1" xref="S5.T3.9.m1.1.1.cmml"><mi id="S5.T3.9.m1.1.1.2" xref="S5.T3.9.m1.1.1.2.cmml">𝕋</mi><mi id="S5.T3.9.m1.1.1.3" xref="S5.T3.9.m1.1.1.3.cmml">F</mi></msup><annotation-xml encoding="MathML-Content" id="S5.T3.9.m1.1c"><apply id="S5.T3.9.m1.1.1.cmml" xref="S5.T3.9.m1.1.1"><csymbol cd="ambiguous" id="S5.T3.9.m1.1.1.1.cmml" xref="S5.T3.9.m1.1.1">superscript</csymbol><ci id="S5.T3.9.m1.1.1.2.cmml" xref="S5.T3.9.m1.1.1.2">𝕋</ci><ci id="S5.T3.9.m1.1.1.3.cmml" xref="S5.T3.9.m1.1.1.3">𝐹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.9.m1.1d">\mathbb{T}^{F}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.9.m1.1e">blackboard_T start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="T_{n}^{U}" class="ltx_Math" display="inline" id="S5.T3.10.m2.1"><semantics id="S5.T3.10.m2.1b"><msubsup id="S5.T3.10.m2.1.1" xref="S5.T3.10.m2.1.1.cmml"><mi id="S5.T3.10.m2.1.1.2.2" xref="S5.T3.10.m2.1.1.2.2.cmml">T</mi><mi id="S5.T3.10.m2.1.1.2.3" xref="S5.T3.10.m2.1.1.2.3.cmml">n</mi><mi id="S5.T3.10.m2.1.1.3" xref="S5.T3.10.m2.1.1.3.cmml">U</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.T3.10.m2.1c"><apply id="S5.T3.10.m2.1.1.cmml" xref="S5.T3.10.m2.1.1"><csymbol cd="ambiguous" id="S5.T3.10.m2.1.1.1.cmml" xref="S5.T3.10.m2.1.1">superscript</csymbol><apply id="S5.T3.10.m2.1.1.2.cmml" xref="S5.T3.10.m2.1.1"><csymbol cd="ambiguous" id="S5.T3.10.m2.1.1.2.1.cmml" xref="S5.T3.10.m2.1.1">subscript</csymbol><ci id="S5.T3.10.m2.1.1.2.2.cmml" xref="S5.T3.10.m2.1.1.2.2">𝑇</ci><ci id="S5.T3.10.m2.1.1.2.3.cmml" xref="S5.T3.10.m2.1.1.2.3">𝑛</ci></apply><ci id="S5.T3.10.m2.1.1.3.cmml" xref="S5.T3.10.m2.1.1.3">𝑈</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.10.m2.1d">T_{n}^{U}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.10.m2.1e">italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_U end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="T_{n}^{A}" class="ltx_Math" display="inline" id="S5.T3.11.m3.1"><semantics id="S5.T3.11.m3.1b"><msubsup id="S5.T3.11.m3.1.1" xref="S5.T3.11.m3.1.1.cmml"><mi id="S5.T3.11.m3.1.1.2.2" xref="S5.T3.11.m3.1.1.2.2.cmml">T</mi><mi id="S5.T3.11.m3.1.1.2.3" xref="S5.T3.11.m3.1.1.2.3.cmml">n</mi><mi id="S5.T3.11.m3.1.1.3" xref="S5.T3.11.m3.1.1.3.cmml">A</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.T3.11.m3.1c"><apply id="S5.T3.11.m3.1.1.cmml" xref="S5.T3.11.m3.1.1"><csymbol cd="ambiguous" id="S5.T3.11.m3.1.1.1.cmml" xref="S5.T3.11.m3.1.1">superscript</csymbol><apply id="S5.T3.11.m3.1.1.2.cmml" xref="S5.T3.11.m3.1.1"><csymbol cd="ambiguous" id="S5.T3.11.m3.1.1.2.1.cmml" xref="S5.T3.11.m3.1.1">subscript</csymbol><ci id="S5.T3.11.m3.1.1.2.2.cmml" xref="S5.T3.11.m3.1.1.2.2">𝑇</ci><ci id="S5.T3.11.m3.1.1.2.3.cmml" xref="S5.T3.11.m3.1.1.2.3">𝑛</ci></apply><ci id="S5.T3.11.m3.1.1.3.cmml" xref="S5.T3.11.m3.1.1.3">𝐴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.11.m3.1d">T_{n}^{A}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.11.m3.1e">italic_T start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT</annotation></semantics></math>의 파라미터로서 표에 표시되어 있다. 이 설정에서, <math alttext="\mathbb{T}^{F}" class="ltx_Math" display="inline" id="S5.T3.12.m4.1"><semantics id="S5.T3.12.m4.1b"><msup id="S5.T3.12.m4.1.1" xref="S5.T3.12.m4.1.1.cmml"><mi id="S5.T3.12.m4.1.1.2" xref="S5.T3.12.m4.1.1.2.cmml">𝕋</mi><mi id="S5.T3.12.m4.1.1.3" xref="S5.T3.12.m4.1.1.3.cmml">F</mi></msup><annotation-xml encoding="MathML-Content" id="S5.T3.12.m4.1c"><apply id="S5.T3.12.m4.1.1.cmml" xref="S5.T3.12.m4.1.1"><csymbol cd="ambiguous" id="S5.T3.12.m4.1.1.1.cmml" xref="S5.T3.12.m4.1.1">superscript</csymbol><ci id="S5.T3.12.m4.1.1.2.cmml" xref="S5.T3.12.m4.1.1.2">𝕋</ci><ci id="S5.T3.12.m4.1.1.3.cmml" xref="S5.T3.12.m4.1.1.3">𝐹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.12.m4.1d">\mathbb{T}^{F}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.12.m4.1e">blackboard_T start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT</annotation></semantics></math>는 <math alttext="T_{0}^{F}" class="ltx_Math" display="inline" id="S5.T3.13.m5.1"><semantics id="S5.T3.13.m5.1b"><msubsup id="S5.T3.13.m5.1.1" xref="S5.T3.13.m5.1.1.cmml"><mi id="S5.T3.13.m5.1.1.2.2" xref="S5.T3.13.m5.1.1.2.2.cmml">T</mi><mn id="S5.T3.13.m5.1.1.2.3" xref="S5.T3.13.m5.1.1.2.3.cmml">0</mn><mi id="S5.T3.13.m5.1.1.3" xref="S5.T3.13.m5.1.1.3.cmml">F</mi></msubsup><annotation-xml encoding="MathML-Content" id="S5.T3.13.m5.1c"><apply id="S5.T3.13.m5.1.1.cmml" xref="S5.T3.13.m5.1.1"><csymbol cd="ambiguous" id="S5.T3.13.m5.1.1.1.cmml" xref="S5.T3.13.m5.1.1">superscript</csymbol><apply id="S5.T3.13.m5.1.1.2.cmml" xref="S5.T3.13.m5.1.1"><csymbol cd="ambiguous" id="S5.T3.13.m5.1.1.2.1.cmml" xref="S5.T3.13.m5.1.1">subscript</csymbol><ci id="S5.T3.13.m5.1.1.2.2.cmml" xref="S5.T3.13.m5.1.1.2.2">𝑇</ci><cn id="S5.T3.13.m5.1.1.2.3.cmml" type="integer" xref="S5.T3.13.m5.1.1.2.3">0</cn></apply><ci id="S5.T3.13.m5.1.1.3.cmml" xref="S5.T3.13.m5.1.1.3">𝐹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.13.m5.1d">T_{0}^{F}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.13.m5.1e">italic_T start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT</annotation></semantics></math>(IL)만이 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S5.T3.14.m6.1"><semantics id="S5.T3.14.m6.1b"><msub id="S5.T3.14.m6.1.1" xref="S5.T3.14.m6.1.1.cmml"><mi id="S5.T3.14.m6.1.1.2" xref="S5.T3.14.m6.1.1.2.cmml">D</mi><mn id="S5.T3.14.m6.1.1.3" xref="S5.T3.14.m6.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.T3.14.m6.1c"><apply id="S5.T3.14.m6.1.1.cmml" xref="S5.T3.14.m6.1.1"><csymbol cd="ambiguous" id="S5.T3.14.m6.1.1.1.cmml" xref="S5.T3.14.m6.1.1">subscript</csymbol><ci id="S5.T3.14.m6.1.1.2.cmml" xref="S5.T3.14.m6.1.1.2">𝐷</ci><cn id="S5.T3.14.m6.1.1.3.cmml" type="integer" xref="S5.T3.14.m6.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.14.m6.1d">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.14.m6.1e">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>로부터 손실된 시간 불변 정보를 측정하는 것으로 구성된다. <span class="ltx_text ltx_font_smallcaps" id="S5.T3.32.4">Small</span>의 경우, 균일한 가중치를 갖는 NLE<math alttext="{}_{\text{P1}}" class="ltx_Math" display="inline" id="S5.T3.15.m7.1"><semantics id="S5.T3.15.m7.1b"><msub id="S5.T3.15.m7.1.1" xref="S5.T3.15.m7.1.1.cmml"><mi id="S5.T3.15.m7.1.1b" xref="S5.T3.15.m7.1.1.cmml"></mi><mtext id="S5.T3.15.m7.1.1.1" xref="S5.T3.15.m7.1.1.1a.cmml">P1</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.15.m7.1c"><apply id="S5.T3.15.m7.1.1.cmml" xref="S5.T3.15.m7.1.1"><ci id="S5.T3.15.m7.1.1.1a.cmml" xref="S5.T3.15.m7.1.1.1"><mtext id="S5.T3.15.m7.1.1.1.cmml" mathsize="70%" xref="S5.T3.15.m7.1.1.1">P1</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.15.m7.1d">{}_{\text{P1}}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.15.m7.1e">start_FLOATSUBSCRIPT P1 end_FLOATSUBSCRIPT</annotation></semantics></math> 및 NLE<math alttext="{}_{\text{P2}}" class="ltx_Math" display="inline" id="S5.T3.16.m8.1"><semantics id="S5.T3.16.m8.1b"><msub id="S5.T3.16.m8.1.1" xref="S5.T3.16.m8.1.1.cmml"><mi id="S5.T3.16.m8.1.1b" xref="S5.T3.16.m8.1.1.cmml"></mi><mtext id="S5.T3.16.m8.1.1.1" xref="S5.T3.16.m8.1.1.1a.cmml">P2</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.16.m8.1c"><apply id="S5.T3.16.m8.1.1.cmml" xref="S5.T3.16.m8.1.1"><ci id="S5.T3.16.m8.1.1.1a.cmml" xref="S5.T3.16.m8.1.1.1"><mtext id="S5.T3.16.m8.1.1.1.cmml" mathsize="70%" xref="S5.T3.16.m8.1.1.1">P2</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.16.m8.1d">{}_{\text{P2}}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.16.m8.1e">start_FLOATSUBSCRIPT P2 end_FLOATSUBSCRIPT</annotation></semantics></math> 상의 갭의 가중합을 사용하여 NLE 상의 갭을 계산한다.</figcaption>
<table id="S5.T3.24" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S5.T3.18.2" class="ltx_tr">
<td id="S5.T3.18.2.3" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2">
<span id="S5.T3.18.2.3.1" class="ltx_text"></span><span id="S5.T3.18.2.3.2" class="ltx_text ltx_font_bold"> <span id="S5.T3.18.2.3.2.1" class="ltx_text">
<span id="S5.T3.18.2.3.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.18.2.3.2.1.1.1" class="ltx_tr">
<span id="S5.T3.18.2.3.2.1.1.1.1" class="ltx_td ltx_align_center">Corpus</span></span>
</span></span> <span id="S5.T3.18.2.3.2.2" class="ltx_text"></span></span>
</td>
<td id="S5.T3.18.2.4" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2">
<span id="S5.T3.18.2.4.1" class="ltx_text"></span><span id="S5.T3.18.2.4.2" class="ltx_text ltx_font_bold"> <span id="S5.T3.18.2.4.2.1" class="ltx_text">
<span id="S5.T3.18.2.4.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.18.2.4.2.1.1.1" class="ltx_tr">
<span id="S5.T3.18.2.4.2.1.1.1.1" class="ltx_td ltx_align_center">Method</span></span>
</span></span> <span id="S5.T3.18.2.4.2.2" class="ltx_text"></span></span>
</td>
<td id="S5.T3.18.2.5" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2">
<span id="S5.T3.18.2.5.1" class="ltx_text"></span><span id="S5.T3.18.2.5.2" class="ltx_text ltx_font_bold"> <span id="S5.T3.18.2.5.2.1" class="ltx_text">
<span id="S5.T3.18.2.5.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.18.2.5.2.1.1.1" class="ltx_tr">
<span id="S5.T3.18.2.5.2.1.1.1.1" class="ltx_td ltx_align_center"># of Params</span></span>
<span id="S5.T3.18.2.5.2.1.1.2" class="ltx_tr">
<span id="S5.T3.18.2.5.2.1.1.2.1" class="ltx_td ltx_align_center">(Trainable / Total)</span></span>
</span></span> <span id="S5.T3.18.2.5.2.2" class="ltx_text"></span></span>
</td>
<td id="S5.T3.18.2.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.18.2.6.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">IL</span></td>
<td id="S5.T3.17.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.17.1.1.1" class="ltx_text ltx_font_bold">NLE<math id="S5.T3.17.1.1.1.m1.1" class="ltx_Math" alttext="{}_{\textbf{P1}}" display="inline"><semantics id="S5.T3.17.1.1.1.m1.1a"><msub id="S5.T3.17.1.1.1.m1.1.1" xref="S5.T3.17.1.1.1.m1.1.1.cmml"><mi id="S5.T3.17.1.1.1.m1.1.1a" xref="S5.T3.17.1.1.1.m1.1.1.cmml"></mi><mtext id="S5.T3.17.1.1.1.m1.1.1.1" xref="S5.T3.17.1.1.1.m1.1.1.1a.cmml">𝐏𝟏</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.17.1.1.1.m1.1b"><apply id="S5.T3.17.1.1.1.m1.1.1.cmml" xref="S5.T3.17.1.1.1.m1.1.1"><ci id="S5.T3.17.1.1.1.m1.1.1.1a.cmml" xref="S5.T3.17.1.1.1.m1.1.1.1"><mtext mathsize="70%" id="S5.T3.17.1.1.1.m1.1.1.1.cmml" xref="S5.T3.17.1.1.1.m1.1.1.1">𝐏𝟏</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.17.1.1.1.m1.1c">{}_{\textbf{P1}}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.17.1.1.1.m1.1d">start_FLOATSUBSCRIPT P1 end_FLOATSUBSCRIPT</annotation></semantics></math></span></td>
<td id="S5.T3.18.2.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T3.18.2.2.1" class="ltx_text ltx_font_bold">NLE<math id="S5.T3.18.2.2.1.m1.1" class="ltx_Math" alttext="{}_{\textbf{P2}}" display="inline"><semantics id="S5.T3.18.2.2.1.m1.1a"><msub id="S5.T3.18.2.2.1.m1.1.1" xref="S5.T3.18.2.2.1.m1.1.1.cmml"><mi id="S5.T3.18.2.2.1.m1.1.1a" xref="S5.T3.18.2.2.1.m1.1.1.cmml"></mi><mtext id="S5.T3.18.2.2.1.m1.1.1.1" xref="S5.T3.18.2.2.1.m1.1.1.1a.cmml">𝐏𝟐</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T3.18.2.2.1.m1.1b"><apply id="S5.T3.18.2.2.1.m1.1.1.cmml" xref="S5.T3.18.2.2.1.m1.1.1"><ci id="S5.T3.18.2.2.1.m1.1.1.1a.cmml" xref="S5.T3.18.2.2.1.m1.1.1.1"><mtext mathsize="70%" id="S5.T3.18.2.2.1.m1.1.1.1.cmml" xref="S5.T3.18.2.2.1.m1.1.1.1">𝐏𝟐</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.18.2.2.1.m1.1c">{}_{\textbf{P2}}</annotation><annotation encoding="application/x-llamapun" id="S5.T3.18.2.2.1.m1.1d">start_FLOATSUBSCRIPT P2 end_FLOATSUBSCRIPT</annotation></semantics></math></span></td>
<td id="S5.T3.18.2.7" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="S5.T3.24.9" class="ltx_tr">
<td id="S5.T3.24.9.1" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S5.T3.24.9.2" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S5.T3.24.9.3" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S5.T3.24.9.4" class="ltx_td"></td>
</tr>
<tr id="S5.T3.24.10" class="ltx_tr">
<td id="S5.T3.24.10.1" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.10.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.10.3" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.10.4" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.10.5" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.10.6" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.10.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.24.10.7.1" class="ltx_text ltx_font_bold">FUAR</span></td>
</tr>
<tr id="S5.T3.20.4" class="ltx_tr">
<td id="S5.T3.20.4.3" class="ltx_td"></td>
<td id="S5.T3.20.4.4" class="ltx_td ltx_align_left">T5-Initial</td>
<td id="S5.T3.20.4.5" class="ltx_td ltx_align_center">0M / 737M</td>
<td id="S5.T3.20.4.6" class="ltx_td ltx_align_center"><span id="S5.T3.20.4.6.1" class="ltx_text ltx_font_bold">24.17</span></td>
<td id="S5.T3.20.4.7" class="ltx_td ltx_align_center">8.69</td>
<td id="S5.T3.20.4.8" class="ltx_td ltx_align_center">9.45</td>
<td id="S5.T3.20.4.2" class="ltx_td ltx_align_center">
<math id="S5.T3.19.3.1.m1.3" class="ltx_math_unparsed" alttext="\left((\mathbf{IL}),\bm{n.d.},\mathbf{NLE}\right)" display="inline"><semantics id="S5.T3.19.3.1.m1.3a"><mrow id="S5.T3.19.3.1.m1.3b"><mo id="S5.T3.19.3.1.m1.3.4">(</mo><mrow id="S5.T3.19.3.1.m1.3.5"><mo stretchy="false" id="S5.T3.19.3.1.m1.3.5.1">(</mo><mi id="S5.T3.19.3.1.m1.1.1">𝐈𝐋</mi><mo stretchy="false" id="S5.T3.19.3.1.m1.3.5.2">)</mo></mrow><mo id="S5.T3.19.3.1.m1.3.6">,</mo><mi id="S5.T3.19.3.1.m1.2.2">𝒏</mi><mo lspace="0em" mathvariant="bold" rspace="0.167em" id="S5.T3.19.3.1.m1.3.7">.</mo><mi id="S5.T3.19.3.1.m1.3.3">𝒅</mi><mo lspace="0em" mathvariant="bold" rspace="0.167em" id="S5.T3.19.3.1.m1.3.8">.</mo><mo id="S5.T3.19.3.1.m1.3.9">,</mo><mi id="S5.T3.19.3.1.m1.3.10">𝐍𝐋𝐄</mi><mo id="S5.T3.19.3.1.m1.3.11">)</mo></mrow><annotation encoding="application/x-tex" id="S5.T3.19.3.1.m1.3c">\left((\mathbf{IL}),\bm{n.d.},\mathbf{NLE}\right)</annotation><annotation encoding="application/x-llamapun" id="S5.T3.19.3.1.m1.3d">( ( bold_IL ) , bold_italic_n bold_. bold_italic_d bold_. , bold_NLE )</annotation></semantics></math> <math id="S5.T3.20.4.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.20.4.2.m2.1a"><mo stretchy="false" id="S5.T3.20.4.2.m2.1.1" xref="S5.T3.20.4.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T3.20.4.2.m2.1b"><ci id="S5.T3.20.4.2.m2.1.1.cmml" xref="S5.T3.20.4.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.20.4.2.m2.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.20.4.2.m2.1d">↓</annotation></semantics></math>
</td>
</tr>
<tr id="S5.T3.24.11" class="ltx_tr">
<td id="S5.T3.24.11.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S5.T3.24.11.1.1" class="ltx_text"><span id="S5.T3.24.11.1.1.1" class="ltx_text"></span> <span id="S5.T3.24.11.1.1.2" class="ltx_text">
<span id="S5.T3.24.11.1.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.24.11.1.1.2.1.1" class="ltx_tr">
<span id="S5.T3.24.11.1.1.2.1.1.1" class="ltx_td ltx_align_center"><span id="S5.T3.24.11.1.1.2.1.1.1.1" class="ltx_text ltx_font_smallcaps">Small</span></span></span>
<span id="S5.T3.24.11.1.1.2.1.2" class="ltx_tr">
<span id="S5.T3.24.11.1.1.2.1.2.1" class="ltx_td ltx_align_center">(<span id="S5.T3.24.11.1.1.2.1.2.1.1" class="ltx_text ltx_font_smallcaps">Small-P1</span></span></span>
<span id="S5.T3.24.11.1.1.2.1.3" class="ltx_tr">
<span id="S5.T3.24.11.1.1.2.1.3.1" class="ltx_td ltx_align_center">+ <span id="S5.T3.24.11.1.1.2.1.3.1.1" class="ltx_text ltx_font_smallcaps">Small-P2</span>)</span></span>
</span></span> <span id="S5.T3.24.11.1.1.3" class="ltx_text"></span></span></td>
<td id="S5.T3.24.11.2" class="ltx_td ltx_align_left ltx_border_t">T5-Vanilla</td>
<td id="S5.T3.24.11.3" class="ltx_td ltx_align_center ltx_border_t">737M / 737M</td>
<td id="S5.T3.24.11.4" class="ltx_td ltx_align_center ltx_border_t">11.86</td>
<td id="S5.T3.24.11.5" class="ltx_td ltx_align_center ltx_border_t">17.77</td>
<td id="S5.T3.24.11.6" class="ltx_td ltx_align_center ltx_border_t">16.42</td>
<td id="S5.T3.24.11.7" class="ltx_td ltx_align_center ltx_border_t">1.53</td>
</tr>
<tr id="S5.T3.24.12" class="ltx_tr">
<td id="S5.T3.24.12.1" class="ltx_td ltx_align_left">T5-RecAdam</td>
<td id="S5.T3.24.12.2" class="ltx_td ltx_align_center">737M / 737M</td>
<td id="S5.T3.24.12.3" class="ltx_td ltx_align_center">11.85</td>
<td id="S5.T3.24.12.4" class="ltx_td ltx_align_center">16.46</td>
<td id="S5.T3.24.12.5" class="ltx_td ltx_align_center">13.93</td>
<td id="S5.T3.24.12.6" class="ltx_td ltx_align_center">2.01</td>
</tr>
<tr id="S5.T3.24.13" class="ltx_tr">
<td id="S5.T3.24.13.1" class="ltx_td"></td>
<td id="S5.T3.24.13.2" class="ltx_td ltx_align_left">T5-MixReview</td>
<td id="S5.T3.24.13.3" class="ltx_td ltx_align_center">737M / 737M</td>
<td id="S5.T3.24.13.4" class="ltx_td ltx_align_center">14.36</td>
<td id="S5.T3.24.13.5" class="ltx_td ltx_align_center">14.18</td>
<td id="S5.T3.24.13.6" class="ltx_td ltx_align_center">13.93</td>
<td id="S5.T3.24.13.7" class="ltx_td ltx_align_center">1.97</td>
</tr>
<tr id="S5.T3.24.14" class="ltx_tr">
<td id="S5.T3.24.14.1" class="ltx_td"></td>
<td id="S5.T3.24.14.2" class="ltx_td ltx_align_left">T5-LoRA</td>
<td id="S5.T3.24.14.3" class="ltx_td ltx_align_center">403M / 738M</td>
<td id="S5.T3.24.14.4" class="ltx_td ltx_align_center">14.26</td>
<td id="S5.T3.24.14.5" class="ltx_td ltx_align_center"><span id="S5.T3.24.14.5.1" class="ltx_text ltx_framed_underline">20.60</span></td>
<td id="S5.T3.24.14.6" class="ltx_td ltx_align_center"><span id="S5.T3.24.14.6.1" class="ltx_text ltx_framed_underline">19.90</span></td>
<td id="S5.T3.24.14.7" class="ltx_td ltx_align_center">0.87</td>
</tr>
<tr id="S5.T3.24.15" class="ltx_tr">
<td id="S5.T3.24.15.1" class="ltx_td"></td>
<td id="S5.T3.24.15.2" class="ltx_td ltx_align_left">T5-Kadapters (k=2)</td>
<td id="S5.T3.24.15.3" class="ltx_td ltx_align_center">427M / 762M</td>
<td id="S5.T3.24.15.4" class="ltx_td ltx_align_center"><span id="S5.T3.24.15.4.1" class="ltx_text ltx_framed_underline">18.16</span></td>
<td id="S5.T3.24.15.5" class="ltx_td ltx_align_center">18.34</td>
<td id="S5.T3.24.15.6" class="ltx_td ltx_align_center">16.42</td>
<td id="S5.T3.24.15.7" class="ltx_td ltx_align_center"><span id="S5.T3.24.15.7.1" class="ltx_text ltx_framed_underline">0.72</span></td>
</tr>
<tr id="S5.T3.24.16" class="ltx_tr">
<td id="S5.T3.24.16.1" class="ltx_td"></td>
<td id="S5.T3.24.16.2" class="ltx_td ltx_align_left">T5-Kadapters (k=3)</td>
<td id="S5.T3.24.16.3" class="ltx_td ltx_align_center">440M / 775M</td>
<td id="S5.T3.24.16.4" class="ltx_td ltx_align_center">17.12</td>
<td id="S5.T3.24.16.5" class="ltx_td ltx_align_center"><span id="S5.T3.24.16.5.1" class="ltx_text ltx_font_bold">20.98</span></td>
<td id="S5.T3.24.16.6" class="ltx_td ltx_align_center"><span id="S5.T3.24.16.6.1" class="ltx_text ltx_font_bold">20.39</span></td>
<td id="S5.T3.24.16.7" class="ltx_td ltx_align_center"><span id="S5.T3.24.16.7.1" class="ltx_text ltx_font_bold">0.61</span></td>
</tr>
<tr id="S5.T3.24.17" class="ltx_tr">
<td id="S5.T3.24.17.1" class="ltx_td"></td>
<td id="S5.T3.24.17.2" class="ltx_td ltx_align_left">T5-Modular</td>
<td id="S5.T3.24.17.3" class="ltx_td ltx_align_center">438M / 773M</td>
<td id="S5.T3.24.17.4" class="ltx_td ltx_align_center">16.40</td>
<td id="S5.T3.24.17.5" class="ltx_td ltx_align_center">19.47</td>
<td id="S5.T3.24.17.6" class="ltx_td ltx_align_center"><span id="S5.T3.24.17.6.1" class="ltx_text ltx_framed_underline">19.90</span></td>
<td id="S5.T3.24.17.7" class="ltx_td ltx_align_center">0.73</td>
</tr>
<tr id="S5.T3.24.18" class="ltx_tr">
<td id="S5.T3.24.18.1" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.18.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.18.3" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.18.4" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.18.5" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.18.6" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.18.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.24.18.7.1" class="ltx_text ltx_font_bold">FUAR</span></td>
</tr>
<tr id="S5.T3.22.6" class="ltx_tr">
<td id="S5.T3.22.6.3" class="ltx_td"></td>
<td id="S5.T3.22.6.4" class="ltx_td ltx_align_left">T5-Initial</td>
<td id="S5.T3.22.6.5" class="ltx_td ltx_align_center">0M / 737M</td>
<td id="S5.T3.22.6.6" class="ltx_td ltx_align_center"><span id="S5.T3.22.6.6.1" class="ltx_text ltx_font_bold">24.17</span></td>
<td id="S5.T3.22.6.7" class="ltx_td ltx_align_center">8.69</td>
<td id="S5.T3.22.6.8" class="ltx_td ltx_align_center">9.45</td>
<td id="S5.T3.22.6.2" class="ltx_td ltx_align_center">
<math id="S5.T3.21.5.1.m1.3" class="ltx_math_unparsed" alttext="\left((\mathbf{IL}),\bm{n.d.},\mathbf{NLE_{P1}}\right)" display="inline"><semantics id="S5.T3.21.5.1.m1.3a"><mrow id="S5.T3.21.5.1.m1.3b"><mo id="S5.T3.21.5.1.m1.3.4">(</mo><mrow id="S5.T3.21.5.1.m1.3.5"><mo stretchy="false" id="S5.T3.21.5.1.m1.3.5.1">(</mo><mi id="S5.T3.21.5.1.m1.1.1">𝐈𝐋</mi><mo stretchy="false" id="S5.T3.21.5.1.m1.3.5.2">)</mo></mrow><mo id="S5.T3.21.5.1.m1.3.6">,</mo><mi id="S5.T3.21.5.1.m1.2.2">𝒏</mi><mo lspace="0em" mathvariant="bold" rspace="0.167em" id="S5.T3.21.5.1.m1.3.7">.</mo><mi id="S5.T3.21.5.1.m1.3.3">𝒅</mi><mo lspace="0em" mathvariant="bold" rspace="0.167em" id="S5.T3.21.5.1.m1.3.8">.</mo><mo id="S5.T3.21.5.1.m1.3.9">,</mo><msub id="S5.T3.21.5.1.m1.3.10"><mi id="S5.T3.21.5.1.m1.3.10.2">𝐍𝐋𝐄</mi><mi id="S5.T3.21.5.1.m1.3.10.3">𝐏𝟏</mi></msub><mo id="S5.T3.21.5.1.m1.3.11">)</mo></mrow><annotation encoding="application/x-tex" id="S5.T3.21.5.1.m1.3c">\left((\mathbf{IL}),\bm{n.d.},\mathbf{NLE_{P1}}\right)</annotation><annotation encoding="application/x-llamapun" id="S5.T3.21.5.1.m1.3d">( ( bold_IL ) , bold_italic_n bold_. bold_italic_d bold_. , bold_NLE start_POSTSUBSCRIPT bold_P1 end_POSTSUBSCRIPT )</annotation></semantics></math> <math id="S5.T3.22.6.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.22.6.2.m2.1a"><mo stretchy="false" id="S5.T3.22.6.2.m2.1.1" xref="S5.T3.22.6.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T3.22.6.2.m2.1b"><ci id="S5.T3.22.6.2.m2.1.1.cmml" xref="S5.T3.22.6.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.22.6.2.m2.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.22.6.2.m2.1d">↓</annotation></semantics></math>
</td>
</tr>
<tr id="S5.T3.24.19" class="ltx_tr">
<td id="S5.T3.24.19.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="7"><span id="S5.T3.24.19.1.1" class="ltx_text ltx_font_smallcaps">Small-P1</span></td>
<td id="S5.T3.24.19.2" class="ltx_td ltx_align_left ltx_border_t">T5-Vanilla</td>
<td id="S5.T3.24.19.3" class="ltx_td ltx_align_center ltx_border_t">737M / 737M</td>
<td id="S5.T3.24.19.4" class="ltx_td ltx_align_center ltx_border_t">9.68</td>
<td id="S5.T3.24.19.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.24.19.5.1" class="ltx_text ltx_framed_underline">20.60</span></td>
<td id="S5.T3.24.19.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.24.19.6.1" class="ltx_text ltx_font_italic">11.44</span></td>
<td id="S5.T3.24.19.7" class="ltx_td ltx_align_center ltx_border_t">1.22</td>
</tr>
<tr id="S5.T3.24.20" class="ltx_tr">
<td id="S5.T3.24.20.1" class="ltx_td ltx_align_left">T5-RecAdam</td>
<td id="S5.T3.24.20.2" class="ltx_td ltx_align_center">737M / 737M</td>
<td id="S5.T3.24.20.3" class="ltx_td ltx_align_center">11.78</td>
<td id="S5.T3.24.20.4" class="ltx_td ltx_align_center">20.42</td>
<td id="S5.T3.24.20.5" class="ltx_td ltx_align_center"><span id="S5.T3.24.20.5.1" class="ltx_text ltx_font_italic">11.94</span></td>
<td id="S5.T3.24.20.6" class="ltx_td ltx_align_center">1.06</td>
</tr>
<tr id="S5.T3.24.21" class="ltx_tr">
<td id="S5.T3.24.21.1" class="ltx_td ltx_align_left">T5-MixReview</td>
<td id="S5.T3.24.21.2" class="ltx_td ltx_align_center">737M / 737 M</td>
<td id="S5.T3.24.21.3" class="ltx_td ltx_align_center">16.13</td>
<td id="S5.T3.24.21.4" class="ltx_td ltx_align_center">15.88</td>
<td id="S5.T3.24.21.5" class="ltx_td ltx_align_center"><span id="S5.T3.24.21.5.1" class="ltx_text ltx_font_italic">11.94</span></td>
<td id="S5.T3.24.21.6" class="ltx_td ltx_align_center">1.12</td>
</tr>
<tr id="S5.T3.24.22" class="ltx_tr">
<td id="S5.T3.24.22.1" class="ltx_td ltx_align_left">T5-LoRA</td>
<td id="S5.T3.24.22.2" class="ltx_td ltx_align_center">403M / 738M</td>
<td id="S5.T3.24.22.3" class="ltx_td ltx_align_center">14.75</td>
<td id="S5.T3.24.22.4" class="ltx_td ltx_align_center"><span id="S5.T3.24.22.4.1" class="ltx_text ltx_font_bold">20.79</span></td>
<td id="S5.T3.24.22.5" class="ltx_td ltx_align_center"><span id="S5.T3.24.22.5.1" class="ltx_text ltx_font_italic">13.93</span></td>
<td id="S5.T3.24.22.6" class="ltx_td ltx_align_center">0.78</td>
</tr>
<tr id="S5.T3.24.23" class="ltx_tr">
<td id="S5.T3.24.23.1" class="ltx_td ltx_align_left">T5-Kadapters (k=2)</td>
<td id="S5.T3.24.23.2" class="ltx_td ltx_align_center">427M / 762M</td>
<td id="S5.T3.24.23.3" class="ltx_td ltx_align_center"><span id="S5.T3.24.23.3.1" class="ltx_text ltx_framed_underline">19.11</span></td>
<td id="S5.T3.24.23.4" class="ltx_td ltx_align_center"><span id="S5.T3.24.23.4.1" class="ltx_text ltx_framed_underline">20.60</span></td>
<td id="S5.T3.24.23.5" class="ltx_td ltx_align_center"><span id="S5.T3.24.23.5.1" class="ltx_text ltx_font_italic">10.95</span></td>
<td id="S5.T3.24.23.6" class="ltx_td ltx_align_center"><span id="S5.T3.24.23.6.1" class="ltx_text ltx_font_bold">0.42</span></td>
</tr>
<tr id="S5.T3.24.24" class="ltx_tr">
<td id="S5.T3.24.24.1" class="ltx_td ltx_align_left">T5-Kadapters (k=3)</td>
<td id="S5.T3.24.24.2" class="ltx_td ltx_align_center">440M / 775M</td>
<td id="S5.T3.24.24.3" class="ltx_td ltx_align_center">19.08</td>
<td id="S5.T3.24.24.4" class="ltx_td ltx_align_center">18.15</td>
<td id="S5.T3.24.24.5" class="ltx_td ltx_align_center"><span id="S5.T3.24.24.5.1" class="ltx_text ltx_font_italic">10.94</span></td>
<td id="S5.T3.24.24.6" class="ltx_td ltx_align_center"><span id="S5.T3.24.24.6.1" class="ltx_text ltx_framed_underline">0.54</span></td>
</tr>
<tr id="S5.T3.24.25" class="ltx_tr">
<td id="S5.T3.24.25.1" class="ltx_td ltx_align_left">T5-Modular</td>
<td id="S5.T3.24.25.2" class="ltx_td ltx_align_center">438M / 773M</td>
<td id="S5.T3.24.25.3" class="ltx_td ltx_align_center">17.08</td>
<td id="S5.T3.24.25.4" class="ltx_td ltx_align_center">18.90</td>
<td id="S5.T3.24.25.5" class="ltx_td ltx_align_center"><span id="S5.T3.24.25.5.1" class="ltx_text ltx_font_italic">11.94</span></td>
<td id="S5.T3.24.25.6" class="ltx_td ltx_align_center">0.69</td>
</tr>
<tr id="S5.T3.24.26" class="ltx_tr">
<td id="S5.T3.24.26.1" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.26.2" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.26.3" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.26.4" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.26.5" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.26.6" class="ltx_td ltx_border_t"></td>
<td id="S5.T3.24.26.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.24.26.7.1" class="ltx_text ltx_font_bold">FUAR</span></td>
</tr>
<tr id="S5.T3.24.8" class="ltx_tr">
<td id="S5.T3.24.8.3" class="ltx_td"></td>
<td id="S5.T3.24.8.4" class="ltx_td ltx_align_left">T5-Initial</td>
<td id="S5.T3.24.8.5" class="ltx_td ltx_align_center">0M / 737M</td>
<td id="S5.T3.24.8.6" class="ltx_td ltx_align_center"><span id="S5.T3.24.8.6.1" class="ltx_text ltx_font_bold">24.17</span></td>
<td id="S5.T3.24.8.7" class="ltx_td ltx_align_center">8.69</td>
<td id="S5.T3.24.8.8" class="ltx_td ltx_align_center">9.45</td>
<td id="S5.T3.24.8.2" class="ltx_td ltx_align_center">
<math id="S5.T3.23.7.1.m1.2" class="ltx_math_unparsed" alttext="\left((\mathbf{IL},\bm{n.d.}),\bm{n.d.},\mathbf{NLE_{P2}}\right)" display="inline"><semantics id="S5.T3.23.7.1.m1.2a"><mrow id="S5.T3.23.7.1.m1.2b"><mo id="S5.T3.23.7.1.m1.2.3">(</mo><mrow id="S5.T3.23.7.1.m1.2.4"><mo stretchy="false" id="S5.T3.23.7.1.m1.2.4.1">(</mo><mi id="S5.T3.23.7.1.m1.1.1">𝐈𝐋</mi><mo id="S5.T3.23.7.1.m1.2.4.2">,</mo><mi id="S5.T3.23.7.1.m1.2.2">𝒏</mi><mo lspace="0em" mathvariant="bold" rspace="0.167em" id="S5.T3.23.7.1.m1.2.4.3">.</mo><mi id="S5.T3.23.7.1.m1.2.4.4">𝒅</mi><mo lspace="0em" mathvariant="bold" rspace="0.167em" id="S5.T3.23.7.1.m1.2.4.5">.</mo><mo stretchy="false" id="S5.T3.23.7.1.m1.2.4.6">)</mo></mrow><mo id="S5.T3.23.7.1.m1.2.5">,</mo><mi id="S5.T3.23.7.1.m1.2.6">𝒏</mi><mo lspace="0em" mathvariant="bold" rspace="0.167em" id="S5.T3.23.7.1.m1.2.7">.</mo><mi id="S5.T3.23.7.1.m1.2.8">𝒅</mi><mo lspace="0em" mathvariant="bold" rspace="0.167em" id="S5.T3.23.7.1.m1.2.9">.</mo><mo id="S5.T3.23.7.1.m1.2.10">,</mo><msub id="S5.T3.23.7.1.m1.2.11"><mi id="S5.T3.23.7.1.m1.2.11.2">𝐍𝐋𝐄</mi><mi id="S5.T3.23.7.1.m1.2.11.3">𝐏𝟐</mi></msub><mo id="S5.T3.23.7.1.m1.2.12">)</mo></mrow><annotation encoding="application/x-tex" id="S5.T3.23.7.1.m1.2c">\left((\mathbf{IL},\bm{n.d.}),\bm{n.d.},\mathbf{NLE_{P2}}\right)</annotation><annotation encoding="application/x-llamapun" id="S5.T3.23.7.1.m1.2d">( ( bold_IL , bold_italic_n bold_. bold_italic_d bold_. ) , bold_italic_n bold_. bold_italic_d bold_. , bold_NLE start_POSTSUBSCRIPT bold_P2 end_POSTSUBSCRIPT )</annotation></semantics></math> <math id="S5.T3.24.8.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T3.24.8.2.m2.1a"><mo stretchy="false" id="S5.T3.24.8.2.m2.1.1" xref="S5.T3.24.8.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T3.24.8.2.m2.1b"><ci id="S5.T3.24.8.2.m2.1.1.cmml" xref="S5.T3.24.8.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.24.8.2.m2.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S5.T3.24.8.2.m2.1d">↓</annotation></semantics></math>
</td>
</tr>
<tr id="S5.T3.24.27" class="ltx_tr">
<td id="S5.T3.24.27.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="7">
<span id="S5.T3.24.27.1.1" class="ltx_text"></span> <span id="S5.T3.24.27.1.2" class="ltx_text">
<span id="S5.T3.24.27.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S5.T3.24.27.1.2.1.1" class="ltx_tr">
<span id="S5.T3.24.27.1.2.1.1.1" class="ltx_td ltx_align_center"><span id="S5.T3.24.27.1.2.1.1.1.1" class="ltx_text ltx_font_smallcaps">Small-P1</span>→</span></span>
<span id="S5.T3.24.27.1.2.1.2" class="ltx_tr">
<span id="S5.T3.24.27.1.2.1.2.1" class="ltx_td ltx_align_center"><span id="S5.T3.24.27.1.2.1.2.1.1" class="ltx_text ltx_font_smallcaps">Small-P2</span></span></span>
</span></span> <span id="S5.T3.24.27.1.3" class="ltx_text"></span>
</td>
<td id="S5.T3.24.27.2" class="ltx_td ltx_align_left ltx_border_t">T5-Vanilla</td>
<td id="S5.T3.24.27.3" class="ltx_td ltx_align_center ltx_border_t">737 M / 737 M</td>
<td id="S5.T3.24.27.4" class="ltx_td ltx_align_center ltx_border_t">9.40</td>
<td id="S5.T3.24.27.5" class="ltx_td ltx_align_center ltx_border_t">14.37</td>
<td id="S5.T3.24.27.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.24.27.6.1" class="ltx_text ltx_font_bold">23.38</span></td>
<td id="S5.T3.24.27.7" class="ltx_td ltx_align_center ltx_border_t">1.06</td>
</tr>
<tr id="S5.T3.24.28" class="ltx_tr">
<td id="S5.T3.24.28.1" class="ltx_td ltx_align_left">T5-RecAdam</td>
<td id="S5.T3.24.28.2" class="ltx_td ltx_align_center">737M / 737M</td>
<td id="S5.T3.24.28.3" class="ltx_td ltx_align_center">7.25</td>
<td id="S5.T3.24.28.4" class="ltx_td ltx_align_center">14.56</td>
<td id="S5.T3.24.28.5" class="ltx_td ltx_align_center">20.90</td>
<td id="S5.T3.24.28.6" class="ltx_td ltx_align_center">1.48</td>
</tr>
<tr id="S5.T3.24.29" class="ltx_tr">
<td id="S5.T3.24.29.1" class="ltx_td ltx_align_left">T5-MixReview</td>
<td id="S5.T3.24.29.2" class="ltx_td ltx_align_center">737M / 737M</td>
<td id="S5.T3.24.29.3" class="ltx_td ltx_align_center">13.20</td>
<td id="S5.T3.24.29.4" class="ltx_td ltx_align_center"><span id="S5.T3.24.29.4.1" class="ltx_text ltx_font_bold">17.20</span></td>
<td id="S5.T3.24.29.5" class="ltx_td ltx_align_center">16.92</td>
<td id="S5.T3.24.29.6" class="ltx_td ltx_align_center">1.47</td>
</tr>
<tr id="S5.T3.24.30" class="ltx_tr">
<td id="S5.T3.24.30.1" class="ltx_td ltx_align_left">T5-LoRA</td>
<td id="S5.T3.24.30.2" class="ltx_td ltx_align_center">404M / 740M</td>
<td id="S5.T3.24.30.3" class="ltx_td ltx_align_center">13.25</td>
<td id="S5.T3.24.30.4" class="ltx_td ltx_align_center"><span id="S5.T3.24.30.4.1" class="ltx_text ltx_framed_underline">16.07</span></td>
<td id="S5.T3.24.30.5" class="ltx_td ltx_align_center"><span id="S5.T3.24.30.5.1" class="ltx_text ltx_framed_underline">22.39</span></td>
<td id="S5.T3.24.30.6" class="ltx_td ltx_align_center">0.84</td>
</tr>
<tr id="S5.T3.24.31" class="ltx_tr">
<td id="S5.T3.24.31.1" class="ltx_td ltx_align_left">T5-Kadapters (k=2)</td>
<td id="S5.T3.24.31.2" class="ltx_td ltx_align_center">427M / 788M</td>
<td id="S5.T3.24.31.3" class="ltx_td ltx_align_center"><span id="S5.T3.24.31.3.1" class="ltx_text ltx_framed_underline">15.78</span></td>
<td id="S5.T3.24.31.4" class="ltx_td ltx_align_center"><span id="S5.T3.24.31.4.1" class="ltx_text ltx_framed_underline">16.07</span></td>
<td id="S5.T3.24.31.5" class="ltx_td ltx_align_center"><span id="S5.T3.24.31.5.1" class="ltx_text ltx_font_bold">23.38</span></td>
<td id="S5.T3.24.31.6" class="ltx_td ltx_align_center"><span id="S5.T3.24.31.6.1" class="ltx_text ltx_font_bold">0.60</span></td>
</tr>
<tr id="S5.T3.24.32" class="ltx_tr">
<td id="S5.T3.24.32.1" class="ltx_td ltx_align_left">T5-Kadapters (k=3)</td>
<td id="S5.T3.24.32.2" class="ltx_td ltx_align_center">440M / 813M</td>
<td id="S5.T3.24.32.3" class="ltx_td ltx_align_center">15.47</td>
<td id="S5.T3.24.32.4" class="ltx_td ltx_align_center">15.31</td>
<td id="S5.T3.24.32.5" class="ltx_td ltx_align_center">20.90</td>
<td id="S5.T3.24.32.6" class="ltx_td ltx_align_center"><span id="S5.T3.24.32.6.1" class="ltx_text ltx_framed_underline">0.76</span></td>
</tr>
<tr id="S5.T3.24.33" class="ltx_tr">
<td id="S5.T3.24.33.1" class="ltx_td ltx_align_left ltx_border_bb">T5-Modular</td>
<td id="S5.T3.24.33.2" class="ltx_td ltx_align_center ltx_border_bb">438M / 809M</td>
<td id="S5.T3.24.33.3" class="ltx_td ltx_align_center ltx_border_bb">14.66</td>
<td id="S5.T3.24.33.4" class="ltx_td ltx_align_center ltx_border_bb">15.31</td>
<td id="S5.T3.24.33.5" class="ltx_td ltx_align_center ltx_border_bb">20.40</td>
<td id="S5.T3.24.33.6" class="ltx_td ltx_align_center ltx_border_bb">0.87</td>
</tr>
</tbody></table>
</figure>
<div id="S5.SS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.p1.7">진정으로 끊임없이 변화하는 LM을 만들 수 있는 가능성을 보여주기 위해, 우리는 원본 말뭉치의 10%를 무작위로 샘플링한 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.1">CC-RecentNews-Small</span>로 표시된 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.2">Small</span>의 작은 변형인 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.3">CC-RecentNews</span>을 만들어 여러 CKL 단계의 효과를 탐구한다. 그런 다음 여러 CKL 단계가 필요한 설정을 시뮬레이션하기 위해 각 문서의 게시 날짜까지 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.4">CC-RecentNews-Small</span>을 두 개의 다른 분할로 분할하여 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.5">Small-P1</span> (05.2020 - 11.2020)) 및 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.6">Small-P2</span> (11.2020 - 04.2021)로 표시한다. NLE<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>We use <span class="ltx_text ltx_font_smallcaps" id="footnote8.1">NewLAMA-Easy</span> instead of <span class="ltx_text ltx_font_smallcaps" id="footnote8.2">NewLAMA</span> because the number of instances in NL corresponding to articles from <span class="ltx_text ltx_font_smallcaps" id="footnote8.3">Small</span> is too small for robust evaluation.</span></span></span>은 또한 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.7">Small-P1</span> 및 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.8">Small-P2</span>의 기사로부터 구성된 인스턴스로 각각 분할됩니다. T5에 대한 CKL 메소드가 IL에서 수행하는 방법을 비교합니다. NLE<math alttext="{}_{\text{P1}}" class="ltx_Math" display="inline" id="S5.SS2.p1.3.m3.1"><semantics id="S5.SS2.p1.3.m3.1a"><msub id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml"><mi id="S5.SS2.p1.3.m3.1.1a" xref="S5.SS2.p1.3.m3.1.1.cmml"></mi><mtext id="S5.SS2.p1.3.m3.1.1.1" xref="S5.SS2.p1.3.m3.1.1.1a.cmml">P1</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><apply id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1"><ci id="S5.SS2.p1.3.m3.1.1.1a.cmml" xref="S5.SS2.p1.3.m3.1.1.1"><mtext id="S5.SS2.p1.3.m3.1.1.1.cmml" mathsize="70%" xref="S5.SS2.p1.3.m3.1.1.1">P1</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">{}_{\text{P1}}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.3.m3.1d">start_FLOATSUBSCRIPT P1 end_FLOATSUBSCRIPT</annotation></semantics></math>와 NLE<math alttext="{}_{\text{P2}}" class="ltx_Math" display="inline" id="S5.SS2.p1.4.m4.1"><semantics id="S5.SS2.p1.4.m4.1a"><msub id="S5.SS2.p1.4.m4.1.1" xref="S5.SS2.p1.4.m4.1.1.cmml"><mi id="S5.SS2.p1.4.m4.1.1a" xref="S5.SS2.p1.4.m4.1.1.cmml"></mi><mtext id="S5.SS2.p1.4.m4.1.1.1" xref="S5.SS2.p1.4.m4.1.1.1a.cmml">P2</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m4.1b"><apply id="S5.SS2.p1.4.m4.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1"><ci id="S5.SS2.p1.4.m4.1.1.1a.cmml" xref="S5.SS2.p1.4.m4.1.1.1"><mtext id="S5.SS2.p1.4.m4.1.1.1.cmml" mathsize="70%" xref="S5.SS2.p1.4.m4.1.1.1">P2</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m4.1c">{}_{\text{P2}}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.4.m4.1d">start_FLOATSUBSCRIPT P2 end_FLOATSUBSCRIPT</annotation></semantics></math>는 각각 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.9">Small</span>에서 5k 단계(8 epochs) 동안, 그리고 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.10">Small-P1</span>에서 순차적으로 사전 훈련한 다음 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.11">Small-P2</span>에서 2.5k 단계(8 epochs) 동안 각각 수행합니다. 시나리오 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.12">Small-P1</span>→<span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.13">Small-P2</span> 두 CKL 위상이 있으며, 여기서 <math alttext="D_{0}" class="ltx_Math" display="inline" id="S5.SS2.p1.5.m5.1"><semantics id="S5.SS2.p1.5.m5.1a"><msub id="S5.SS2.p1.5.m5.1.1" xref="S5.SS2.p1.5.m5.1.1.cmml"><mi id="S5.SS2.p1.5.m5.1.1.2" xref="S5.SS2.p1.5.m5.1.1.2.cmml">D</mi><mn id="S5.SS2.p1.5.m5.1.1.3" xref="S5.SS2.p1.5.m5.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.5.m5.1b"><apply id="S5.SS2.p1.5.m5.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.5.m5.1.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1">subscript</csymbol><ci id="S5.SS2.p1.5.m5.1.1.2.cmml" xref="S5.SS2.p1.5.m5.1.1.2">𝐷</ci><cn id="S5.SS2.p1.5.m5.1.1.3.cmml" type="integer" xref="S5.SS2.p1.5.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.5.m5.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.5.m5.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>는 C4이고 Wikipedia이며, <math alttext="D_{1}" class="ltx_Math" display="inline" id="S5.SS2.p1.6.m6.1"><semantics id="S5.SS2.p1.6.m6.1a"><msub id="S5.SS2.p1.6.m6.1.1" xref="S5.SS2.p1.6.m6.1.1.cmml"><mi id="S5.SS2.p1.6.m6.1.1.2" xref="S5.SS2.p1.6.m6.1.1.2.cmml">D</mi><mn id="S5.SS2.p1.6.m6.1.1.3" xref="S5.SS2.p1.6.m6.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.6.m6.1b"><apply id="S5.SS2.p1.6.m6.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.6.m6.1.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1">subscript</csymbol><ci id="S5.SS2.p1.6.m6.1.1.2.cmml" xref="S5.SS2.p1.6.m6.1.1.2">𝐷</ci><cn id="S5.SS2.p1.6.m6.1.1.3.cmml" type="integer" xref="S5.SS2.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.6.m6.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.6.m6.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>는 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.14">Small-P1</span>, <math alttext="D_{2}" class="ltx_Math" display="inline" id="S5.SS2.p1.7.m7.1"><semantics id="S5.SS2.p1.7.m7.1a"><msub id="S5.SS2.p1.7.m7.1.1" xref="S5.SS2.p1.7.m7.1.1.cmml"><mi id="S5.SS2.p1.7.m7.1.1.2" xref="S5.SS2.p1.7.m7.1.1.2.cmml">D</mi><mn id="S5.SS2.p1.7.m7.1.1.3" xref="S5.SS2.p1.7.m7.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.7.m7.1b"><apply id="S5.SS2.p1.7.m7.1.1.cmml" xref="S5.SS2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.7.m7.1.1.1.cmml" xref="S5.SS2.p1.7.m7.1.1">subscript</csymbol><ci id="S5.SS2.p1.7.m7.1.1.2.cmml" xref="S5.SS2.p1.7.m7.1.1.2">𝐷</ci><cn id="S5.SS2.p1.7.m7.1.1.3.cmml" type="integer" xref="S5.SS2.p1.7.m7.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.7.m7.1c">D_{2}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.7.m7.1d">italic_D start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>는 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p1.7.15">Small-P2</span>이다. 나머지 구성은 주요 실험과 동일하게 설정된다.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.p2.1">두 시나리오의 IL에 대한 성능을 비교하면, <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p2.1.1">Small</span> 및 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p2.1.2">Small-P1</span>→<span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p2.1.3">Small-P2</span> 결과는 LMs가 동일한 수의 훈련 단계를 가짐에도 불구하고 여러 CKL 단계를 거치면서 더 많은 망각하기 쉽다는 것을 보여준다. 그 이유들 중 하나는 각각의 페이즈의 시작 시에 초기화되는 학습 레이트 스케줄링에 기인할 수 있다.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.p3.1">또한, 전반적으로 최상의 성능을 보였음에도 불구하고, 파라미터 확장 방법의 단점은 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p3.1.1">Small-P1</span>→<span class="ltx_text ltx_font_smallcaps" id="S5.SS2.p3.1.2">Small-P2</span> 설정에서도 강조되며, 업데이트의 모든 단계에서 새로운 파라미터를 추가해야 한다. 예를 들어, T5-Modular의 총 매개변수 수는 연속 사전 훈련 단계의 모든 라운드에서 36M 증가한다. 마찬가지로 많은 CKL 단계를 고려할 때 추가 연구해야 하는 새로운 문제가 발생한다. LMs는 계산 효율적인 방식으로 끊임없이 변화하는 세계에 대한 최신 세계 지식을 얻기 위해 실제 시나리오에서 소량의 데이터로 자주 업데이트되어야 한다는 점을 고려하면, 더 많은 업데이트 단계의 수에 따르는 망각의 양을 완화하기 위한 더 많은 연구가 필요하다.</p>
</div>
<section id="S5.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Effects of Epochs, Corpus Size, and Total Number of Training Steps in CKL on Forgetting</h5>

<figure id="S5.F3" class="ltx_figure">
<div class="ltx_flex_figure">

<div class="ltx_flex_cell 
                  ltx_flex_size_2">
<figure id="S5.F2.sf1" class="ltx_figure ltx_flex_size_2 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x7.png" id="S5.F2.sf1.g1" class="ltx_graphics ltx_img_landscape" width="761" height="346" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a)</span>T5-Vanilla</figcaption>
</figure>
</div>
<div class="ltx_flex_cell 
                  ltx_flex_size_2">
<figure id="S5.F2.sf2" class="ltx_figure ltx_flex_size_2 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x8.png" id="S5.F2.sf2.g1" class="ltx_graphics ltx_img_landscape" width="761" height="346" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b)</span>T5-Kadapters (k=2)</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 3:</span>Performance at each epoch on <span class="ltx_text ltx_font_smallcaps" id="S5.F3.6.1">InvariantLAMA</span> during continue pretraining in <span class="ltx_text ltx_font_smallcaps" id="S5.F3.7.2">Main</span>, <span class="ltx_text ltx_font_smallcaps" id="S5.F3.8.3">Small</span>, <span class="ltx_text ltx_font_smallcaps" id="S5.F3.9.4">Small-P1</span>→<span class="ltx_text ltx_font_smallcaps" id="S5.F3.10.5">Small-P2</span> scenarios. 각 마커는 각 지속적인 사전 훈련 에포크에서 결과를 나타낸다.</figcaption>
</figure>
<div id="S5.SS2.SSS0.Px1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p1.1">그림 <a class="ltx_ref" href="#S5.F3" title="Figure 3 ‣ Effects of Epochs, Corpus Size, and Total Number of Training Steps in CKL on Forgetting ‣ 5.2 Exploring Multiple phases of CKL ‣ 5 Experimental Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>는 표 <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.1 Main Results ‣ 5 Experimental Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">2</span></a> 및 <a class="ltx_ref" href="#S5.T3" title="Table 3 ‣ 5.2 Exploring Multiple phases of CKL ‣ 5 Experimental Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>와 다른 시나리오에서 계속된 사전 훈련 동안 T5-Vanilla 및 T5-Kadapters의 결과를 나타내며, 그래프의 각 점은 매 epoch 이후의 IL의 성능을 나타낸다. <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.SSS0.Px1.p1.1.1">Main</span> (4 epochs)와 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.SSS0.Px1.p1.1.2">Small</span> (8 epochs)를 비교하면 그림 <a class="ltx_ref" href="#S5.F3" title="Figure 3 ‣ Effects of Epochs, Corpus Size, and Total Number of Training Steps in CKL on Forgetting ‣ 5.2 Exploring Multiple phases of CKL ‣ 5 Experimental Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">3</span></a> (a) T5-Vanilla에서 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.SSS0.Px1.p1.1.3">Small</span>에서 더 많은 망각이 발생함을 알 수 있다. 이 현상은 <span class="ltx_text ltx_font_smallcaps" id="S5.SS2.SSS0.Px1.p1.1.4">Small-P1</span> (8 epochs)의 결과를 비교할 때 더욱 강조되며, 이는 10배 적은 수의 글로벌 트레이닝 단계에 대해 트레이닝되었음에도 불구하고 가장 많은 망각의 양을 보여준다. 그림 <a class="ltx_ref" href="#S5.F3" title="Figure 3 ‣ Effects of Epochs, Corpus Size, and Total Number of Training Steps in CKL on Forgetting ‣ 5.2 Exploring Multiple phases of CKL ‣ 5 Experimental Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">3</span></a> (b) T5-Kadapters에서 전반적인 하락이 훨씬 완화되지만, 우리는 계속된 사전 훈련 동안 동일한 데이터를 반복적으로 관찰하는 것이 망각을 유발하는 데 얼마나 중요한지를 보여주는 각 시나리오 간에 동일한 경향을 관찰한다.</p>
</div>
<div id="S5.SS2.SSS0.Px1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p2.1">결과는 <cite class="ltx_cite ltx_citemacro_citet">Lee et al. (<a class="ltx_ref" href="#bib.bib26" title="">2021</a>)</cite>의 결과와 일치하며, 이는 LMs가 효율성을 위해 덜 복제된 데이터에 대해 몇 개의 에폭으로 사전 훈련되어야 함을 시사한다. 우리는 그들의 발견에 추가적인 직관을 추가하고 중복 데이터로부터의 사전 훈련의 비효율성이 사전 훈련 코퍼스의 다소 긴 꼬리 지식을 망각함으로써 야기되었을 수 있다고 추측한다.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.p1.1">본 논문에서는 <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.1">Continual Knowledge Learning (CKL)</span>을 제안하며, 벤치마크 데이터셋과 메트릭을 구축하고, 끊임없이 변화하는 LM에 대한 지속적인 지식 학습을 위한 방법론을 탐구한다. 파라미터 확장 방법은 모든 실험 환경에서 가장 강력한 성능을 보여주며, 그럼에도 불구하고 심각한 메모리 비효율성을 가지고 있으며 동일한 데이터를 자주 보는 것이 망각의 중요한 원인임을 발견했다. 우리는 또한 향후 연구에 추가 탐색을 맡긴 몇 가지 다른 흥미로운 결과에 대해 논의한다. 이를 위해 커뮤니티가 끊임없이 변화하는 LM의 더 나은 설계를 위해 CKL을 탐색할 것을 제안한다.</p>
</div>
<section id="S6.SS0.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Acknowledgments</h4>

<div id="S6.SS0.SSSx1.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS0.SSSx1.p1.1">The authors would like to thank Sang-Woo Lee, Jinheon Baek, Miyoung Ko, Hyunji Lee, and Eunbi Choi for helpful discussions. This work was supported by Institute of Information &amp; communications Technology Planning &amp; Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2019-0-00075, Artificial Intelligence Graduate School Program (KAIST)). </p>저자들은 이상우, 백진헌, 고미영, 이현지, 최은비 등이 도움이 되는 토론에 감사드린다. 이 작업은 한국 정부(MSIT)의 자금 지원을 받는 정보통신기술기획평가원(IITP) 보조금(No. 2019-0-00075, 인공지능대학원과정(KAIST)</p>
</div>
</section>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bang et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Jihwan Bang, Heesu Kim, YoungJoon Yoo, Jung-Woo Ha, and Jonghyun Choi.

</span>
<span class="ltx_bibblock">Rainbow memory: Continual learning with a memory of diverse samples.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">CVPR</em>, 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Tom&nbsp;B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et&nbsp;al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2020.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Sanyuan Chen, Yutai Hou, Yiming Cui, Wanxiang Che, Ting Liu, and Xiangzhan Yu.

</span>
<span class="ltx_bibblock">Recall and learn: Fine-tuning deep pretrained language models with
less forgetting.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choi et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Eunsol Choi, Jennimaria Palomaki, Matthew Lamm, Tom Kwiatkowski, Dipanjan Das,
and Michael Collins.

</span>
<span class="ltx_bibblock">Decontextualization: Making sentences stand-alone.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">TACL</em>, 9:447–461, 2021.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Damai Dai, Li&nbsp;Dong, Y.&nbsp;Hao, Zhifang Sui, and Furu Wei.

</span>
<span class="ltx_bibblock">Knowledge neurons in pretrained transformers.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2104.08696, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">d’Autume et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Cyprien de&nbsp;Masson d’Autume, Sebastian Ruder, Lingpeng Kong, and Dani Yogatama.

</span>
<span class="ltx_bibblock">Episodic memory in lifelong language learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De&nbsp;Cao et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Nicola De&nbsp;Cao, Wilker Aziz, and Ivan Titov.

</span>
<span class="ltx_bibblock">Editing factual knowledge in language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">NAACL</em>, 2019.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhingra et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Bhuwan Dhingra, Jeremy&nbsp;R Cole, Julian&nbsp;Martin Eisenschlos, Daniel Gillick, Jacob
Eisenstein, and William&nbsp;W Cohen.

</span>
<span class="ltx_bibblock">Time-aware language models as temporal knowledge bases.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.15110</em>, 2021.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dinan et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason
Weston.

</span>
<span class="ltx_bibblock">Wizard of wikipedia: Knowledge-powered conversational agents.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elsahar et&nbsp;al. (2018)</span>
<span class="ltx_bibblock">
Hady Elsahar, Pavlos Vougiouklis, Arslen Remaci, Christophe Gravier, Jonathon
Hare, Elena Simperl, and Frederique Laforest.

</span>
<span class="ltx_bibblock">T-rex: A large scale alignment of natural language with knowledge
base triples.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">LREC</em>, 2018.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and
Michael Auli.

</span>
<span class="ltx_bibblock">Eli5: Long form question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">ACL</em>, 2019.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo &amp; Barbosa (2018)</span>
<span class="ltx_bibblock">
Zhaochen Guo and Denilson Barbosa.

</span>
<span class="ltx_bibblock">Robust named entity disambiguation with random walks.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Semantic Web</em>, 9(4):459–479, 2018.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gururangan et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Suchin Gururangan, Ana Marasović, Swabha Swayamdipta, Kyle Lo, Iz&nbsp;Beltagy,
Doug Downey, and Noah&nbsp;A Smith.

</span>
<span class="ltx_bibblock">Don’t stop pretraining: adapt language models to domains and tasks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">ACL</em>, 2020.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guu et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang.

</span>
<span class="ltx_bibblock">Realm: Retrieval-augmented language model pre-training.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">ICML</em>, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hamborg et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Felix Hamborg, Norman Meuschke, Corinna Breitinger, and Bela Gipp.

</span>
<span class="ltx_bibblock">news-please: A generic news crawler and extractor.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">15th International Symposium of Information Science (ISI
2017)</em>, pp.&nbsp; 218–223, 2017.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Tianxing He, Jun Liu, Kyunghyun Cho, Myle Ott, Bing Liu, James Glass, and
Fuchun Peng.

</span>
<span class="ltx_bibblock">Analyzing the forgetting problem in pretrain-finetuning of
open-domain dialogue response models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">EACL</em>, 2021.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoffart et&nbsp;al. (2011)</span>
<span class="ltx_bibblock">
Johannes Hoffart, Mohamed&nbsp;Amir Yosef, Ilaria Bordino, Hagen Fürstenau,
Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard
Weikum.

</span>
<span class="ltx_bibblock">Robust disambiguation of named entities in text.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 2011.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Edward&nbsp;J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
Wang, and Weizhu Chen.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.09685</em>, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Xisen Jin, Dejiao Zhang, Henghui Zhu, Wei Xiao, Shang-Wen Li, Xiaokai Wei,
Andrew Arnold, and Xiang Ren.

</span>
<span class="ltx_bibblock">Lifelong pretraining: Continually adapting language models to
emerging corpora.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.08534</em>, 2021.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Mandar Joshi, Eunsol Choi, Daniel&nbsp;S Weld, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Triviaqa: A large scale distantly supervised challenge dataset for
reading comprehension.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">ACL</em>, 2017.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirkpatrick et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume
Desjardins, Andrei&nbsp;A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka
Grabska-Barwinska, et&nbsp;al.

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting in neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the national academy of sciences</em>, 114(13):3521–3526, 2017.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Komeili et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Mojtaba Komeili, Kurt Shuster, and Jason Weston.

</span>
<span class="ltx_bibblock">Internet-augmented dialogue generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.07566</em>, 2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur
Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin,
Kenton Lee, et&nbsp;al.

</span>
<span class="ltx_bibblock">Natural questions: a benchmark for question answering research.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">TACL</em>, 7:453–466, 2019.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lazaridou et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Angeliki Lazaridou, Adhiguna Kuncoro, Elena Gribovskaya, Devang Agrawal, Adam
Liska, Tayfun Terzi, Mai Gimenez, Cyprien de&nbsp;Masson d’Autume, Sebastian
Ruder, Dani Yogatama, et&nbsp;al.

</span>
<span class="ltx_bibblock">Pitfalls of static language modelling.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.01951</em>, 2021.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck,
Chris Callison-Burch, and Nicholas Carlini.

</span>
<span class="ltx_bibblock">Deduplicating training data makes language models better.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.06499</em>, 2021.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Levy et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Omer Levy, Minjoon Seo, Eunsol Choi, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Zero-shot relation extraction via reading comprehension.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">CoNLL</em>, 2017.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2020a)</span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio Petroni, Vladimir
Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim
Rocktäschel, et&nbsp;al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2020a.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2020b)</span>
<span class="ltx_bibblock">
Patrick Lewis, Pontus Stenetorp, and Sebastian Riedel.

</span>
<span class="ltx_bibblock">Question and answer test-train overlap in open-domain question
answering datasets.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2008.02637</em>, 2020b.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Patrick Lewis, Yuxiang Wu, Linqing Liu, Pasquale Minervini, Heinrich
Küttler, Aleksandra Piktus, Pontus Stenetorp, and Sebastian Riedel.

</span>
<span class="ltx_bibblock">Paq: 65 million probably-asked questions and what you can do with
them.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">EACL</em>, 2021.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Yanyang Li, Ye&nbsp;Lin, Tong Xiao, and Jingbo Zhu.

</span>
<span class="ltx_bibblock">An efficient transformer decoder with compressed sub-layers.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2101.00542</em>, 2021.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.

</span>
<span class="ltx_bibblock">Roberta: A robustly optimized bert pretraining approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1907.11692</em>, 2019.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longpre et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Shayne Longpre, Kartik Perisetla, Anthony Chen, Nikhil Ramesh, Chris DuBois,
and Sameer Singh.

</span>
<span class="ltx_bibblock">Entity-based knowledge conflicts in question answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.05052</em>, 2021.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lopez-Paz &amp; Ranzato (2017)</span>
<span class="ltx_bibblock">
David Lopez-Paz and Marc’Aurelio Ranzato.

</span>
<span class="ltx_bibblock">Gradient episodic memory for continual learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2017.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCloskey &amp; Cohen (1989)</span>
<span class="ltx_bibblock">
Michael McCloskey and Neal&nbsp;J Cohen.

</span>
<span class="ltx_bibblock">Catastrophic interference in connectionist networks: The sequential
learning problem.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Psychology of learning and motivation</em>, 24:109–165,
1989.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patterson et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia,
Daniel Rothchild, David So, Maud Texier, and Jeff Dean.

</span>
<span class="ltx_bibblock">Carbon emissions and large neural network training.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.10350</em>, 2021.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Fabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu,
Alexander&nbsp;H Miller, and Sebastian Riedel.

</span>
<span class="ltx_bibblock">Language models as knowledge bases?

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 2019.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani,
Nicola De&nbsp;Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin, Jean
Maillard, et&nbsp;al.

</span>
<span class="ltx_bibblock">Kilt: a benchmark for knowledge intensive language tasks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">NAACL</em>, 2021.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Poerner et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Nina Poerner, Ulli Waltinger, and Hinrich Schütze.

</span>
<span class="ltx_bibblock">E-bert: Efficient-yet-effective entity embeddings for bert.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Findings of EMNLP</em>, 2019.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prabhu et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Ameya Prabhu, Philip&nbsp;HS Torr, and Puneet&nbsp;K Dokania.

</span>
<span class="ltx_bibblock">Gdumb: A simple approach that questions our progress in continual
learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">ECCV</em>, 2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">OpenAI blog</em>, 1(8):9, 2019.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J Liu.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text
transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.10683</em>, 2019.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roberts et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Adam Roberts, Colin Raffel, and Noam Shazeer.

</span>
<span class="ltx_bibblock">How much knowledge can you pack into the parameters of a language
model?

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 2020.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rusu et&nbsp;al. (2016)</span>
<span class="ltx_bibblock">
Andrei&nbsp;A Rusu, Neil&nbsp;C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James
Kirkpatrick, Koray Kavukcuoglu, Razvan Pascanu, and Raia Hadsell.

</span>
<span class="ltx_bibblock">Progressive neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1606.04671</em>, 2016.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shin et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Taylor Shin, Yasaman Razeghi, Robert L.&nbsp;Logan IV, Eric Wallace, and Sameer
Singh.

</span>
<span class="ltx_bibblock">AutoPrompt: Eliciting knowledge from language models with
automatically generated prompts.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 2020.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Fan-Keng Sun, Cheng-Hao Ho, and Hung-Yi Lee.

</span>
<span class="ltx_bibblock">Lamol: Language modeling for lifelong language learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2020.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thorne et&nbsp;al. (2018)</span>
<span class="ltx_bibblock">
James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal.

</span>
<span class="ltx_bibblock">Fever: a large-scale dataset for fact extraction and verification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">NAACL</em>, 2018.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tiedemann &amp; Thottingal (2020)</span>
<span class="ltx_bibblock">
Jörg Tiedemann and Santhosh Thottingal.

</span>
<span class="ltx_bibblock">OPUS-MT — Building open translation services for the World.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">EAMT</em>, Lisbon, Portugal, 2020.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Verga et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Pat Verga, Haitian Sun, Livio&nbsp;Baldini Soares, and William&nbsp;W Cohen.

</span>
<span class="ltx_bibblock">Facts as experts: Adaptable and interpretable neural memory over
symbolic knowledge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">NAACL</em>, 2021.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vig et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Jesse Vig, Sebastian Gehrmann, Yonatan Belinkov, Sharon Qian, Daniel Nevo,
Simas Sakenis, Jason Huang, Yaron Singer, and Stuart Shieber.

</span>
<span class="ltx_bibblock">Causal mediation analysis for interpreting neural nlp: The case of
gender bias.

</span>
<span class="ltx_bibblock">In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2020.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2021a)</span>
<span class="ltx_bibblock">
Cunxiang Wang, Pai Liu, and Yue Zhang.

</span>
<span class="ltx_bibblock">Can generative pre-trained language models serve as knowledge bases
for closed-book qa?

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">ACL</em>, 2021a.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2021b)</span>
<span class="ltx_bibblock">
Ruize Wang, Duyu Tang, Nan Duan, Zhongyu Wei, Xuanjing Huang, Cuihong Cao,
Daxin Jiang, Ming Zhou, et&nbsp;al.

</span>
<span class="ltx_bibblock">K-adapter: Infusing knowledge into pre-trained models with adapters.

</span>
<span class="ltx_bibblock">In <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Findings of ACL</em>, 2021b.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wolf et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe
Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
Plu, Canwen Xu, Teven&nbsp;Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
and Alexander&nbsp;M. Rush.

</span>
<span class="ltx_bibblock">Transformers: State-of-the-art natural language processing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">EMNLP System Demonstrations</em>, 2020.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Jing Xu, Arthur Szlam, and Jason Weston.

</span>
<span class="ltx_bibblock">Beyond goldfish memory: Long-term open-domain conversation.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.07567</em>, 2021.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2018)</span>
<span class="ltx_bibblock">
Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William&nbsp;W Cohen, Ruslan
Salakhutdinov, and Christopher&nbsp;D Manning.

</span>
<span class="ltx_bibblock">Hotpotqa: A dataset for diverse, explainable multi-hop question
answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 2018.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoon et&nbsp;al. (2018)</span>
<span class="ltx_bibblock">
Jaehong Yoon, Eunho Yang, Jeongtae Lee, and Sung&nbsp;Ju Hwang.

</span>
<span class="ltx_bibblock">Lifelong learning with dynamically expandable networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">ICLR</em>, 2018.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zellers et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi,
Franziska Roesner, and Yejin Choi.

</span>
<span class="ltx_bibblock">Defending against neural fake news.

</span>
<span class="ltx_bibblock">In <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2019.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang &amp; Choi (2021)</span>
<span class="ltx_bibblock">
Michael&nbsp;J.Q. Zhang and Eunsol Choi.

</span>
<span class="ltx_bibblock">SituatedQA: Incorporating extra-linguistic contexts into QA.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">EMNLP</em>, 2021.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Chen Zhu, Ankit&nbsp;Singh Rawat, Manzil Zaheer, Srinadh Bhojanapalli, Daliang Li,
Felix Yu, and Sanjiv Kumar.

</span>
<span class="ltx_bibblock">Modifying memories in transformer models.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.00363</em>, 2020.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Extension of Related Works</h2>

<div id="A1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.p1.1">섹션 <a class="ltx_ref" href="#S2" title="2 Related Work ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>에서 언급한 바와 같이, 이전의 CL 방법이 CKL 설정에 부적합하게 만드는 전통적인 CL 제형과 CKL 사이에는 근본적인 차이가 있다. 이 절에서는 이전의 전통적인 연속 학습 방법을 자세히 소개하고 CKL 벤치마크의 기준선으로 설정된 문헌의 방법과 CL 방법의 식별된 한계를 해결하는 방법을 탐색하고 LM이 변화하는 세계에 대처하도록 하는 대체 방법에 대한 설명을 제공한다.</p>
</div>
<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Traditional Continual Learning</h3>

<div id="A1.SS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS1.p1.1">전통적인 연속 학습(CL) 방법은 순차적으로 들어오는 작업 간의 전달의 두 가지 측면을 해결하는 데 중점을 둡니다: <span class="ltx_text ltx_font_italic" id="A1.SS1.p1.1.1">forward transfer</span> 및 <span class="ltx_text ltx_font_italic" id="A1.SS1.p1.1.2">backward transfer</span> <cite class="ltx_cite ltx_citemacro_citep">(Lopez-Paz &amp; Ranzato, <a class="ltx_ref" href="#bib.bib34" title="">2017</a>)</cite>. <span class="ltx_text ltx_font_italic" id="A1.SS1.p1.1.3">Forward transfer</span>은 과거 태스크가 현재 및 미래 태스크의 성능에 어떤 영향을 미치는지 나타낸다. <span class="ltx_text ltx_font_italic" id="A1.SS1.p1.1.4">Backward transfer</span>은 현재 또는 미래의 태스크가 이전 태스크의 성능에 어떤 영향을 미치는지 나타낸다. 일반적인 프리트레인-핀튠 접근법은 모델이 보다 일반적인 소스 태스크에서 사전 트레이닝된 후 타겟 태스크에서 더 나은 성능을 수행하는 <span class="ltx_text ltx_font_italic" id="A1.SS1.p1.1.5">positive forward transfer</span>의 인스턴스로 볼 수 있다. 더욱이, catastrophic forgetting은 이전 태스크들이 상이한 태스크들에 대한 지속적인 트레이닝으로 인해 성능을 겪는 <span class="ltx_text ltx_font_italic" id="A1.SS1.p1.1.6">negative backward transfer</span>의 인스턴스로 볼 수 있다. 이 두 가지 측면과 관련하여 CL 접근법은 정규화, 리허설 및 매개변수 확장 방법의 세 가지 주요 접근법으로 분류할 수 있다.</p>
</div>
<section id="A1.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Regularization</h5>

<div id="A1.SS1.SSS0.Px1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS1.SSS0.Px1.p1.1">EWC (Elastic Weight Consolidation) <cite class="ltx_cite ltx_citemacro_citep">(Kirkpatrick et al., <a class="ltx_ref" href="#bib.bib22" title="">2017</a>)</cite>는 현재 작업에 대해 훈련하는 동안 이전 작업의 중요한 매개 변수를 규칙화하여 이전 작업의 <span class="ltx_text ltx_font_italic" id="A1.SS1.SSS0.Px1.p1.1.1">the negative backward transfer</span>을 완화시키는 방법입니다. 중요한 파라미터들은 이전 태스크들의 트레이닝 동안 각 파라미터의 구배 업데이트 단계의 크기를 측정함으로써 계산된 피셔 정보 매트릭스를 통해 측정된다.</p>
</div>
</section>
<section id="A1.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Rehearsal</h5>

<div id="A1.SS1.SSS0.Px2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS1.SSS0.Px2.p1.1">GEM(Gradient Episodic Memory) <cite class="ltx_cite ltx_citemacro_citep">(Lopez-Paz &amp; Ranzato, <a class="ltx_ref" href="#bib.bib34" title="">2017</a>)</cite>는 <span class="ltx_text ltx_font_italic" id="A1.SS1.SSS0.Px2.p1.1.1">episodic memory</span>에 저장된 각 태스크의 샘플을 활용하는 첫 번째 리허설 방법 중 하나이며, <span class="ltx_text ltx_font_italic" id="A1.SS1.SSS0.Px2.p1.1.2">negative backward transfer</span>을 방지하고, <span class="ltx_text ltx_font_italic" id="A1.SS1.SSS0.Px2.p1.1.3">positive backward transfer</span>을 허용하기 위해 샘플의 손실과 관련하여 부등식 제약을 둔다. 경험 재생 및 로컬 적응 <cite class="ltx_cite ltx_citemacro_citep">(d’Autume et al., <a class="ltx_ref" href="#bib.bib6" title="">2019</a>)</cite> 잊어버림을 완화하기 위해 훈련 중에 이전 작업의 메모리에 저장된 샘플 재생과 같은 다른 방법.</p>
</div>
</section>
<section id="A1.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Parameter-expansion</h5>

<div id="A1.SS1.SSS0.Px3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS1.SSS0.Px3.p1.1">Progressive Neural Networks (PNN) <cite class="ltx_cite ltx_citemacro_citep">(Rusu et al., <a class="ltx_ref" href="#bib.bib44" title="">2016</a>)</cite>는 이전 매개 변수가 동결 된 각 새 작업에 대 한 새 매개 변수 집합을 도입 하 고 측면 연결을 통해 연결할 수 있는 가장 초기 매개 변수 확장/공유 접근 방식 중 하나입니다. 여기서 [span class="ltx_text ltx_font_italic" id="A1.SS1.SSS0.Px3.p1.1.1">positive forward transfer</span>. PNN은 일부 작업에서 <span class="ltx_text ltx_font_italic" id="A1.SS1.SSS0.Px3.p1.1.2">negative backward transfer</span>을 방지할 뿐만 아니라, <span class="ltx_text ltx_font_italic" id="A1.SS1.SSS0.Px3.p1.1.3">positive forward transfer</span> 측면에서 이전의 pretrain-finetune 접근법을 능가했다.</p>
</div>
</section>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>CKL Methods for Language Models</h3>

<div id="A1.SS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS2.p1.1">섹션 <a class="ltx_ref" href="#S2" title="2 Related Work ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>에서 언급한 바와 같이 CL 방법의 한계를 해결하여 CKL에 적용할 수 있는 문헌의 방법을 탐구한다. 또한 이러한 방법을 CL의 세 가지 주요 범주로 분류한다.</p>
</div>
<section id="A1.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Regularization</h5>

<div id="A1.SS2.SSS0.Px1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS2.SSS0.Px1.p1.1">정규화를 활용하는 대부분의 CL 방법은 이전 작업의 중요한 매개변수를 계산해야 하며, 이 경우 원본 텍스트 코퍼스에 대한 사전 훈련이다. 이러한 매개변수를 결정하는 것은 대부분에 의해 복제될 수 없는 대규모 사전 훈련이 필요하기 때문에 종종 비현실적이다. 또한 LM 파라미터에서 지식이 저장되는 방법과 위치는 현재 <cite class="ltx_cite ltx_citemacro_citep">(Vig et al., <a class="ltx_ref" href="#bib.bib50" title="">2020</a>; De Cao et al., <a class="ltx_ref" href="#bib.bib7" title="">2021</a>)</cite>를 식별하고 지역화하는 것이 매우 어렵다. RecAdam<cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="#bib.bib3" title="">2020</a>)</cite>는 EWC<cite class="ltx_cite ltx_citemacro_citep">(Kirkpatrick et al., <a class="ltx_ref" href="#bib.bib22" title="">2017</a>)</cite>와 동일한 훈련 목표를 더 강한 독립 가정으로 따라 이 한계를 극복하고 초기 사전 훈련 코퍼스에 액세스할 필요성을 제거하여 2차 페널티를 배치한다.</p>
</div>
</section>
<section id="A1.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Rehearsal</h5>

<div id="A1.SS2.SSS0.Px2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS2.SSS0.Px2.p1.1">큰 LMs는 보통 Common Crawl<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_href" href="https://commoncrawl.org/" target="_blank" title="">https://commoncrawl.org/</a></span></span></span>과 같은 방대한 양의 원시 텍스트 코퍼스에서 사전 훈련된다. 사전 훈련을 CL 작업으로 처리할 때 사전 훈련 말뭉치의 일부 샘플이 원래 사전 훈련 말뭉치의 전반적인 세계 지식을 나타낼 수 없기 때문에 이전 리허설 방법을 적용하려고 할 때 제한이 존재한다. Mix-Review <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="#bib.bib17" title="">2021</a>)</cite>는 트레이닝이 진행됨에 따라 타겟 태스크를 향해 어닐링되는 믹스 비율에 따라 프리트레이닝 코퍼스의 미세 조정 및 혼합 동안 프리트레이닝 코퍼스에 대한 액세스를 가정함으로써 더 작은 프리트레이닝 설정에서 예비 실험을 수행함으로써 이 문제를 해결한다. 믹스-리뷰는 멀티 태스크 학습의 온화한 버전으로 간주될 수 있다.</p>
</div>
</section>
<section id="A1.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Parameter-expansion</h5>

<div id="A1.SS2.SSS0.Px3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS2.SSS0.Px3.p1.1">K-Adapter <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib52" title="">2021b</a>)</cite>는 사실적 및 언어적 지식을 지속적으로 사전 훈련하고 세 가지 다른 지식 기반 다운스트림 태스크에서 성능을 향상시키기 위해 원래 매개 변수를 공유 및 동결하고 어댑터를 통해 새 매개 변수를 추가합니다. 보다 최근에 LoRA<cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="#bib.bib19" title="">2021</a>)</cite>는 원래 매개 변수를 동결시키고 Transformer 아키텍처의 각 계층에 훈련 가능한 순위 분해 행렬을 주입하여 훈련 가능한 매개 변수의 수와 계산 하드웨어 요구 사항을 크게 감소시키면서 온-파 또는 모든 매개 변수를 훈련하는 것보다 더 잘 수행한다. 두 방법 모두 원래 매개변수를 동결하면 치명적인 망각을 완화할 수 있다고 가정한다. 우리는 CKL 벤치마크에서 구현을 통해 가설을 테스트한다.</p>
</div>
</section>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Methods of Integrating World Knowledge with Language Models</h3>

<section id="A1.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Explicit Methods</h5>

<div id="A1.SS3.SSS0.Px1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS3.SSS0.Px1.p1.1">Facts-as-Experts <cite class="ltx_cite ltx_citemacro_citep">(Verga et al., <a class="ltx_ref" href="#bib.bib49" title="">2021</a>)</cite>는 추론 시간 동안 수정될 수 있는 외부 메모리에 키-값 쌍 형태의 엔티티의 표현을 저장한다. RAG<cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="#bib.bib28" title="">2020a</a>)</cite>는 Wikipedia의 dense vector index를 retriever로 접근하여, 세계의 변화에 따라 모델의 동작을 갱신하기 위한 index를 교환한다. 블렌더봇 2.0<cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="#bib.bib54" title="">2021</a>; Komeili et al., <a class="ltx_ref" href="#bib.bib23" title="">2021</a>)</cite>도 인터넷을 검색하여 최근 대화를 외부 장기 기억에 저장하는 명시적 방법 중 하나이다. 인덱스 교환, 명시적 엔티티-관계 지식 추가 또는 인터넷 검색과 같은 명시적 방법은 추론 중에 수동 개입이 필요하거나 검색이 필요한 작업에 구속된다. 본 논문에서는 암묵적인 방법에만 초점을 맞춘다.</p>
</div>
</section>
<section id="A1.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Implicit Methods</h5>

<div id="A1.SS3.SSS0.Px2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS3.SSS0.Px2.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Zhu et al. (<a class="ltx_ref" href="#bib.bib59" title="">2020</a>)</cite>는 수정되지 않은 사실들을 잊지 않고 특정 사실들을 명시적으로 수정하는 새로운 태스크를 제안했고 제약된 계층-와이즈 파인튜닝을 포함하여 비모수 메모리를 활용하지 않고 여러 벤치마크 접근법들을 제공했다. <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="#bib.bib52" title="">2021b</a>)</cite> 제안된 K-Adapter, 사전 훈련된 LMs의 냉동층에 어댑터를 추가하여 사실적 및 언어적 지식을 주입하고 다운스트림 태스크에 대한 성능을 향상시키는 방법. <cite class="ltx_cite ltx_citemacro_citet">Chen et al. (<a class="ltx_ref" href="#bib.bib3" title="">2020</a>)</cite>는 사전 훈련 코퍼스에 액세스할 필요 없이 대상 태스크에서 미세 조정하면서 사전 훈련 최적화를 시뮬레이션하여 GLUE 벤치마크에서 성능을 향상시키는 새로운 최적화기를 제안했다. <cite class="ltx_cite ltx_citemacro_citet">De Cao et al. (<a class="ltx_ref" href="#bib.bib7" title="">2021</a>)</cite>는 사실적 지식을 편집하기 위해 하이퍼 네트워크를 사용하는 것을 제안한다.</p>
</div>
<div id="A1.SS3.SSS0.Px2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A1.SS3.SSS0.Px2.p2.1">이러한 암시적 방법은 LMs의 암시적 파라미터로부터 지식을 주입하거나 수정하는 효율적인 방법임에도 불구하고, 모두 <span class="ltx_text ltx_font_italic" id="A1.SS3.SSS0.Px2.p2.1.1">cite idx=0></cite>의 경우와 같이 특정 지식</span>을 주입하거나 <span class="ltx_text ltx_font_italic" id="A1.SS3.SSS0.Px2.p2.1.2">past knowledge</span> <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al., <a class="ltx_ref" href="#bib.bib59" title="">2020</a>; De Cao et al., <a class="ltx_ref" href="#bib.bib7" title="">2021</a>)</cite>의 경우와 같이 수정한다. 우리가 아는 한 어떤 작업도 <span class="ltx_text ltx_font_italic" id="A1.SS3.SSS0.Px2.p2.1.3">catastrophic forgetting</span> <span class="ltx_text ltx_font_italic" id="A1.SS3.SSS0.Px2.p2.1.4">new</span> 세계 지식의 이득을 위해 새로운 텍스트 코퍼스에 대한 지속적인 사전 훈련 시 초기 사전 훈련에서 얻은 세계 지식의 <span>을 구체적으로 다루지 않았다.</p>
</div>
</section>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Dataset Construction</h2>

<figure id="A2.F4" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x9.png" id="A2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="753" height="458" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 4:</span>Dataset construction pipeline for (a) <span class="ltx_text ltx_font_smallcaps" id="A2.F4.4.1">UpdatedLAMA</span>, <span class="ltx_text ltx_font_smallcaps" id="A2.F4.5.2">NewLAMA</span>, and (b) <span class="ltx_text ltx_font_smallcaps" id="A2.F4.6.3">NewLAMA-Easy</span></figcaption>
</figure>
<div id="A2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A2.p1.1">이 섹션에서는 CKL에 사용되는 벤치마크 데이터 세트를 만들 때 겪는 데이터 세트 구성 프로세스에 대해 설명한다. 구축을 위해 Amazon Mechanical Turk (mturk)<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_href" href="https://www.mturk.com" target="_blank" title="">https://www.mturk.com</a></span></span></span>을 크라우드소싱 인간 지능 태스크(HITs)에 사용하고 C4 말뭉치를 광범위하게 검색해야 하는 주석을 위해 11명의 전문가를 별도로 고용한다. 또한, 데이터 구축 프로세스를 설정하고, 사후 검증 및 주석자에게 실시간 피드백을 통해 데이터의 품질을 보장하기 위한 주석 가이드라인을 작성한 전문가 3명 <span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>The first three authors of the paper.</span></span></span>도 추가하였다. mturk HIT에 사용되는 인터페이스는 부록 <a class="ltx_ref" href="#A2.SS2" title="B.2 Interfaces used for the construction of CKL benchmark ‣ Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">B.2</span></a>에서 제공된다.</p>
</div>
<section id="A2.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_smallcaps ltx_title_paragraph">CC-RecentNews</h5>

<div id="A2.SS0.SSS0.Px1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A2.SS0.SSS0.Px1.p1.2">먼저 <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px1.p1.2.1">CC-RecentNews</span>, 비교적 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px1.p1.2.2">new</span> knowledge as <math alttext="D_{1}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="A2.SS0.SSS0.Px1.p1.1.m1.1a"><msub id="A2.SS0.SSS0.Px1.p1.1.m1.1.1" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.2" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml">D</mi><mn id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.3" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px1.p1.1.m1.1b"><apply id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.2">𝐷</ci><cn id="A2.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px1.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px1.p1.1.m1.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px1.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>를 포함하는 새로운 텍스트 코퍼스를 구성한다. 우리는 2020년 5월부터 2021년 4월까지 발표된 221,779개의 뉴스 기사를 수집하기 위해 CC-NEWS <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="#bib.bib32" title="">2019</a>)</cite> 및 REALNEWS 데이터셋 <cite class="ltx_cite ltx_citemacro_citep">(Zellers et al., <a class="ltx_ref" href="#bib.bib57" title="">2019</a>)</cite>와 유사한 news-please <cite class="ltx_cite ltx_citemacro_citep">(Hamborg et al., <a class="ltx_ref" href="#bib.bib16" title="">2017</a>)</cite>를 사용한다. 2020년 5월 이전에 구축된 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px1.p1.2.m2.1"><semantics id="A2.SS0.SSS0.Px1.p1.2.m2.1a"><msub id="A2.SS0.SSS0.Px1.p1.2.m2.1.1" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.2" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml">D</mi><mn id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.3" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px1.p1.2.m2.1b"><apply id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.2">𝐷</ci><cn id="A2.SS0.SSS0.Px1.p1.2.m2.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px1.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px1.p1.2.m2.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px1.p1.2.m2.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>에서 초기에 사전 훈련된 LMs는 <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px1.p1.2.3">CC-RecentNews</span>에서 지속적으로 사전 훈련되어 상대적으로 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px1.p1.2.4">recent</span> 세계 지식을 얻을 수 있다.</p>
</div>
</section>
<section id="A2.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_smallcaps ltx_title_paragraph">InvariantLAMA</h5>

<div id="A2.SS0.SSS0.Px2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A2.SS0.SSS0.Px2.p1.1">우리는 <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px2.p1.1.1">InvariantLAMA</span>, LAMA<cite class="ltx_cite ltx_citemacro_citep">(Petroni et al., <a class="ltx_ref" href="#bib.bib37" title="">2019</a>)</cite> 태스크의 하위 집합인 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px2.p1.1.2">time-invariant</span> 지식을 CKL 동안 잊어버릴 수 있습니다. LAMA의 T-REx <cite class="ltx_cite ltx_citemacro_citep">(Elsahar et al., <a class="ltx_ref" href="#bib.bib11" title="">2018</a>)</cite> 하위 집합의 41개 관계 중 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px2.p1.1.3">time-invariant</span> 인스턴스의 전체 목록 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px2.p1.1.4">time-invariant</span> 관계는 부록 <a class="ltx_ref" href="#A2.SS1" title="B.1 Time-invariant relations of LAMA ‣ Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">B.1</span></a>에서 제공됩니다. 또한 클로즈 문장 자체에서 이러한 인스턴스에 대한 답변을 유추할 수 있기 때문에 <cite class="ltx_cite ltx_citemacro_citet">Poerner et al. (<a class="ltx_ref" href="#bib.bib39" title="">2019</a>)</cite>에 이어 답변이 주제와 겹치는 인스턴스를 제거한다. 마지막으로, 응답에 대한 예측을 위해 세계 지식이 필요한 인스턴스만 남겨두기 위해 답변이 비개체인 인스턴스를 제거한다.</p>
</div>
</section>
<section id="A2.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">
<span id="A2.SS0.SSS0.Px3.1.1" class="ltx_text ltx_font_smallcaps">UpdatedLAMA</span> and <span id="A2.SS0.SSS0.Px3.2.2" class="ltx_text ltx_font_smallcaps">NewLAMA</span>
</h5>

<div id="A2.SS0.SSS0.Px3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A2.SS0.SSS0.Px3.p1.4">CKL 동안 오래된 지식의 업데이트 및 새로운 지식의 획득을 측정하기 위해 <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px3.p1.4.1">UpdatedLAMA</span> 및 <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px3.p1.4.2">NewLAMA</span>을 구성합니다. <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px3.p1.4.3">UpdatedLAMA</span>은 지식 인스턴스가 변경된 세부 정보가 있는 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px3.p1.1.m1.1"><semantics id="A2.SS0.SSS0.Px3.p1.1.m1.1a"><msub id="A2.SS0.SSS0.Px3.p1.1.m1.1.1" xref="A2.SS0.SSS0.Px3.p1.1.m1.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p1.1.m1.1.1.2" xref="A2.SS0.SSS0.Px3.p1.1.m1.1.1.2.cmml">D</mi><mn id="A2.SS0.SSS0.Px3.p1.1.m1.1.1.3" xref="A2.SS0.SSS0.Px3.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.1.m1.1b"><apply id="A2.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.1.m1.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p1.1.m1.1.1.2">𝐷</ci><cn id="A2.SS0.SSS0.Px3.p1.1.m1.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px3.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.1.m1.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> 및 <math alttext="D_{1}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px3.p1.2.m2.1"><semantics id="A2.SS0.SSS0.Px3.p1.2.m2.1a"><msub id="A2.SS0.SSS0.Px3.p1.2.m2.1.1" xref="A2.SS0.SSS0.Px3.p1.2.m2.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p1.2.m2.1.1.2" xref="A2.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml">D</mi><mn id="A2.SS0.SSS0.Px3.p1.2.m2.1.1.3" xref="A2.SS0.SSS0.Px3.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.2.m2.1b"><apply id="A2.SS0.SSS0.Px3.p1.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.2.m2.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p1.2.m2.1.1.2">𝐷</ci><cn id="A2.SS0.SSS0.Px3.p1.2.m2.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px3.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.2.m2.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.2.m2.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> 모두에 존재하는 경우에만 업데이트가 필요한 지식으로 간주될 수 있다는 것이고, <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px3.p1.4.4">NewLAMA</span>은 지식이 <math alttext="D_{1}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px3.p1.3.m3.1"><semantics id="A2.SS0.SSS0.Px3.p1.3.m3.1a"><msub id="A2.SS0.SSS0.Px3.p1.3.m3.1.1" xref="A2.SS0.SSS0.Px3.p1.3.m3.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p1.3.m3.1.1.2" xref="A2.SS0.SSS0.Px3.p1.3.m3.1.1.2.cmml">D</mi><mn id="A2.SS0.SSS0.Px3.p1.3.m3.1.1.3" xref="A2.SS0.SSS0.Px3.p1.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.3.m3.1b"><apply id="A2.SS0.SSS0.Px3.p1.3.m3.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.3.m3.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p1.3.m3.1.1.2">𝐷</ci><cn id="A2.SS0.SSS0.Px3.p1.3.m3.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px3.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.3.m3.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.3.m3.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>에 있지만 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px3.p1.4.m4.1"><semantics id="A2.SS0.SSS0.Px3.p1.4.m4.1a"><msub id="A2.SS0.SSS0.Px3.p1.4.m4.1.1" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p1.4.m4.1.1.2" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1.2.cmml">D</mi><mn id="A2.SS0.SSS0.Px3.p1.4.m4.1.1.3" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.4.m4.1b"><apply id="A2.SS0.SSS0.Px3.p1.4.m4.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p1.4.m4.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p1.4.m4.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1.2">𝐷</ci><cn id="A2.SS0.SSS0.Px3.p1.4.m4.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.4.m4.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.4.m4.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>에는 없는 경우에만 새로운 것으로 간주될 수 있다는 것이다. 따라서 우리는 데이터 구축 프로세스를 신중하게 설정한다. <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px3.p1.4.5">UpdatedLAMA</span> 및 <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px3.p1.4.6">NewLAMA</span>의 단일 인스턴스 생성을 위한 파이프라인은 그림 <a class="ltx_ref" href="#A2.F4" title="Figure 4 ‣ Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">4</span></a> (a)와 같다. 각 잠재적 인스턴스는 <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px3.p1.4.7">CC-RecentNews</span>의 단일 아티클에서 시작하여 결국에는 (1) 버려지는 (2) <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px3.p1.4.8">UpdatedLAMA</span> 또는 (3) <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px3.p1.4.9">NewLAMA</span>에 추가됩니다. 그 절차는 다음과 같다:</p>
</div>
<div id="A2.SS0.SSS0.Px3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A2.SS0.SSS0.Px3.p2.5">(1) 먼저, <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px3.p2.5.1">CC-RecentNews</span>의 단일 뉴스 기사에서 PAQ 질문 생성기를 사용하여 Probably-Asked Questions <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="#bib.bib30" title="">2021</a>)</cite>의 목록을 생성한다. (2) PAQ 리스트 및 뉴스 기사는 크라우드소싱 작업자에게 주어져 가장 많은 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px3.p2.5.2">recent</span> 답변을 묻는 지식(<span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px3.p2.5.3">new answer</span>으로 표시됨)을 기사 내에서 찾을 수 있다. (3) 크라우드 소스 작업자에게 질문을 클로즈 문장으로 변환하도록 지시하여 미리 훈련된 T5 LM에 입력으로 주어질 수 있도록 한다. T5 LM의 예측은 질문과 클로즈 문장과 함께 저장된다. (4) 전문가 주석기는 질문의 품질을 보장하고 필요할 때마다 이를 수정하여 문장을 클로징하고, <math alttext="D_{0}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px3.p2.1.m1.1"><semantics id="A2.SS0.SSS0.Px3.p2.1.m1.1a"><msub id="A2.SS0.SSS0.Px3.p2.1.m1.1.1" xref="A2.SS0.SSS0.Px3.p2.1.m1.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p2.1.m1.1.1.2" xref="A2.SS0.SSS0.Px3.p2.1.m1.1.1.2.cmml">D</mi><mn id="A2.SS0.SSS0.Px3.p2.1.m1.1.1.3" xref="A2.SS0.SSS0.Px3.p2.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p2.1.m1.1b"><apply id="A2.SS0.SSS0.Px3.p2.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p2.1.m1.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.1.m1.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p2.1.m1.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p2.1.m1.1.1.2">𝐷</ci><cn id="A2.SS0.SSS0.Px3.p2.1.m1.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px3.p2.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p2.1.m1.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p2.1.m1.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> <span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>The expert annotators are instructed to use <a class="ltx_ref ltx_href" href="https://c4-search.apps.allenai.org/" target="_blank" title="">https://c4-search.apps.allenai.org/</a> for searching through the C4 corpus.</span></span></span>의 대표로 C4 코퍼스를 통해 검색하여 모델 예측이 맞는지 확인한다. 예측이 올바르고 예측이 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px3.p2.5.4">new answer</span>과 동일하지 않은 경우 다음 인스턴스는 세부 정보가 변경된 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px3.p2.2.m2.1"><semantics id="A2.SS0.SSS0.Px3.p2.2.m2.1a"><msub id="A2.SS0.SSS0.Px3.p2.2.m2.1.1" xref="A2.SS0.SSS0.Px3.p2.2.m2.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p2.2.m2.1.1.2" xref="A2.SS0.SSS0.Px3.p2.2.m2.1.1.2.cmml">D</mi><mn id="A2.SS0.SSS0.Px3.p2.2.m2.1.1.3" xref="A2.SS0.SSS0.Px3.p2.2.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p2.2.m2.1b"><apply id="A2.SS0.SSS0.Px3.p2.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p2.2.m2.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.2.m2.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p2.2.m2.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p2.2.m2.1.1.2">𝐷</ci><cn id="A2.SS0.SSS0.Px3.p2.2.m2.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px3.p2.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p2.2.m2.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p2.2.m2.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> 및 <math alttext="D_{1}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px3.p2.3.m3.1"><semantics id="A2.SS0.SSS0.Px3.p2.3.m3.1a"><msub id="A2.SS0.SSS0.Px3.p2.3.m3.1.1" xref="A2.SS0.SSS0.Px3.p2.3.m3.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p2.3.m3.1.1.2" xref="A2.SS0.SSS0.Px3.p2.3.m3.1.1.2.cmml">D</mi><mn id="A2.SS0.SSS0.Px3.p2.3.m3.1.1.3" xref="A2.SS0.SSS0.Px3.p2.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p2.3.m3.1b"><apply id="A2.SS0.SSS0.Px3.p2.3.m3.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p2.3.m3.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.3.m3.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p2.3.m3.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p2.3.m3.1.1.2">𝐷</ci><cn id="A2.SS0.SSS0.Px3.p2.3.m3.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px3.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p2.3.m3.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p2.3.m3.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> 모두에 존재해야 하므로 C4에서 발견된 증거 문서와 함께 <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px3.p2.5.5">UpdatedLAMA</span>에 추가됩니다. 동일한 경우 인스턴스가 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px3.p2.5.6">updated</span> 또는 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px3.p2.5.7">new</span> 모두 없기 때문에 (5) 마지막으로, 모델 예측이 잘못된 경우, 전문가 주석자는 C4에서 질문에 대한 대체 답변을 찾도록 요청받는다. 찾지 못한 경우, 인스턴스는 <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px3.p2.5.8">NewLAMA</span>에 추가된다. 질문에 대한 답변은 <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px3.p2.5.9">CC-RecentNews</span>(<math alttext="D_{1}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px3.p2.4.m4.1"><semantics id="A2.SS0.SSS0.Px3.p2.4.m4.1a"><msub id="A2.SS0.SSS0.Px3.p2.4.m4.1.1" xref="A2.SS0.SSS0.Px3.p2.4.m4.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p2.4.m4.1.1.2" xref="A2.SS0.SSS0.Px3.p2.4.m4.1.1.2.cmml">D</mi><mn id="A2.SS0.SSS0.Px3.p2.4.m4.1.1.3" xref="A2.SS0.SSS0.Px3.p2.4.m4.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p2.4.m4.1b"><apply id="A2.SS0.SSS0.Px3.p2.4.m4.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p2.4.m4.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.4.m4.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p2.4.m4.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p2.4.m4.1.1.2">𝐷</ci><cn id="A2.SS0.SSS0.Px3.p2.4.m4.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px3.p2.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p2.4.m4.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p2.4.m4.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>)의 기사에서만 찾을 수 있기 때문이다. 그러나 C4에서는 찾을 수 없다(<math alttext="D_{0}" class="ltx_Math" display="inline" id="A2.SS0.SSS0.Px3.p2.5.m5.1"><semantics id="A2.SS0.SSS0.Px3.p2.5.m5.1a"><msub id="A2.SS0.SSS0.Px3.p2.5.m5.1.1" xref="A2.SS0.SSS0.Px3.p2.5.m5.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p2.5.m5.1.1.2" xref="A2.SS0.SSS0.Px3.p2.5.m5.1.1.2.cmml">D</mi><mn id="A2.SS0.SSS0.Px3.p2.5.m5.1.1.3" xref="A2.SS0.SSS0.Px3.p2.5.m5.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p2.5.m5.1b"><apply id="A2.SS0.SSS0.Px3.p2.5.m5.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p2.5.m5.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.5.m5.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p2.5.m5.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p2.5.m5.1.1.2">𝐷</ci><cn id="A2.SS0.SSS0.Px3.p2.5.m5.1.1.3.cmml" type="integer" xref="A2.SS0.SSS0.Px3.p2.5.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p2.5.m5.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p2.5.m5.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>). 마찬가지로 C4에서 대체 답변이 발견되면 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px3.p2.5.10">new answer</span>과 동일한지 확인하고, 동일하지 않으면 <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px3.p2.5.11">UpdatedLAMA</span>에 인스턴스를 추가하고 그렇지 않으면 무시합니다.</p>
</div>
<div id="A2.SS0.SSS0.Px3.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A2.SS0.SSS0.Px3.p3.1">전체 프로세스에서 검증자는 데이터의 건전성을 확인하고 주석자의 작업에 대한 자세한 실시간 피드백을 제공한다.</p>
</div>
</section>
<section id="A2.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_font_smallcaps ltx_title_paragraph">NewLAMA-Easy</h5>

<div id="A2.SS0.SSS0.Px4.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A2.SS0.SSS0.Px4.p1.1"><span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px4.p1.1.1">NewLAMA</span>은 작업 공식에서 정의하는 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px4.p1.1.2">new knowledge</span>의 정확한 정의에 해당하지만 각 인스턴스는 전체 C4 데이터베이스에서 답변을 검색해야 하기 때문에 데이터 세트의 크기를 조정하는 것이 어려웠다. 대신 훨씬 더 큰 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px4.p1.1.3">easier</span> variant <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px4.p1.1.4">NewLAMA-Easy</span> 여기서 <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px4.p1.1.5">CC-RecentNews</span>에 대한 계속된 사전 훈련 동안 획득한 일반적인 새로운 지식을 테스트합니다. <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px4.p1.1.6">NewLAMA-Easy</span>은 그림 <a class="ltx_ref" href="#A2.F4" title="Figure 4 ‣ Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>(b)에 나와 있으며 다음 절차를 따릅니다.</p>
</div>
<div id="A2.SS0.SSS0.Px4.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A2.SS0.SSS0.Px4.p2.1">(1) 먼저, 크라우드소싱 작업자는 주어진 기사에 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px4.p2.1.1">new</span> 정보가 포함되어 있는지 여부를 분류하도록 지시받는다. (우리는 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px4.p2.1.2">new</span> as not likely to known before May 2020. 기사에 새로운 정보가 포함된 경우, 작업자는 문장에서 가능한 답변 후보 중 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px4.p2.1.3">recent</span> 정보와 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px4.p2.1.4">entity</span>을 가장 많이 포함하는 기사로부터 문장을 선택하도록 지시받고, 그렇지 않은 경우 기사를 폐기한다. 개체명 인식 모델을 통해 가능한 개체를 제공한다. (2) <cite class="ltx_cite ltx_citemacro_citet">Choi et al. (<a class="ltx_ref" href="#bib.bib4" title="">2021</a>)</cite>에서 제공하는 탈맥락화 모델을 통해 선택된 문장 <span class="ltx_text ltx_font_italic" id="A2.SS0.SSS0.Px4.p2.1.5">stand-alone</span>을 기사로부터 만든다. (3) 탈맥락화된 문장을 역번역 모델(en→de→en) <cite class="ltx_cite ltx_citemacro_citep">(Tiedemann &amp; Thottingal, <a class="ltx_ref" href="#bib.bib48" title="">2020</a>)</cite>에 의해 패러프레이징하고, 선택된 단어가 패러프레이징된 문장에 여전히 있는지 체크하고, 그렇지 않은 경우 문장은 버린다. (4) 다음으로, 문장에서 선택된 단어를 마스킹하고 두 명의 크라우드 소스 작업자에게 클로즈 문장을 질문으로 변환하고 질문에 대답한다. (5) 작업자 간에 응답이 일치할 뿐만 아니라 실제 선택된 단어에 해당하는 경우 <span class="ltx_text ltx_font_smallcaps" id="A2.SS0.SSS0.Px4.p2.1.6">NewLAMA-Easy</span>에 인스턴스를 추가합니다.</p>
</div>
<div id="A2.SS0.SSS0.Px4.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A2.SS0.SSS0.Px4.p3.1">mturk HIT에 사용되는 특정 인터페이스는 부록 <a class="ltx_ref" href="#A2.SS2" title="B.2 Interfaces used for the construction of CKL benchmark ‣ Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">B.2</span></a>에서 제공된다. 구축된 데이터 세트의 통계는 부록 <a class="ltx_ref" href="#A2.SS3" title="B.3 Dataset Statistics and Examples ‣ Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">B.3</span></a>에 있다.</p>
</div>
</section>
<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Time-invariant relations of LAMA</h3>

<div id="A2.SS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A2.SS1.p1.1">표 <a class="ltx_ref" href="#A2.T4" title="Table 4 ‣ B.1 Time-invariant relations of LAMA ‣ Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">4</span></a>는 <span class="ltx_text ltx_font_smallcaps" id="A2.SS1.p1.1.1">InvariantLAMA</span>의 28개의 시간-불변 관계의 목록을 보여준다. 우리는 44개의 원래 LAMA 관계를 수동으로 필터링하여 시간 불변 관계만 남긴다. "[X]는 [Y]에 대해 작동한다" 및 "[X]는 [Y]의 멤버이다"와 같은 템플릿은 다른 타임스탬프에 대해 대답이 변경될 수 있기 때문에 제외된다. 템플릿에서 [X]와 [Y]는 각각 주체 레이블과 객체 레이블을 의미한다. 주제만 포함된 템플릿이 주어지면 모델은 지식 탐사를 위해 객체 레이블[Y]을 예측해야 한다.</p>
</div>
<figure id="A2.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 4:</span><span class="ltx_text ltx_font_smallcaps" id="A2.T4.2.1">InvariantLAMA</span></figcaption>
<table id="A2.T4.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A2.T4.3.1" class="ltx_tr">
<td id="A2.T4.3.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="A2.T4.3.1.1.1" class="ltx_text ltx_font_bold">Relation</span></td>
<td id="A2.T4.3.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="A2.T4.3.1.2.1" class="ltx_text ltx_font_bold">Template ([X], [Y])</span></td>
<td id="A2.T4.3.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="A2.T4.3.1.3.1" class="ltx_text ltx_font_bold">Example</span></td>
</tr>
<tr id="A2.T4.3.2" class="ltx_tr">
<td id="A2.T4.3.2.1" class="ltx_td ltx_align_left ltx_border_t">P19</td>
<td id="A2.T4.3.2.2" class="ltx_td ltx_align_center ltx_border_t">[X] was born in [Y] .</td>
<td id="A2.T4.3.2.3" class="ltx_td ltx_align_center ltx_border_t">Taras Kuzio was born in Halifax .</td>
</tr>
<tr id="A2.T4.3.3" class="ltx_tr">
<td id="A2.T4.3.3.1" class="ltx_td ltx_align_left">P20</td>
<td id="A2.T4.3.3.2" class="ltx_td ltx_align_center">[X] died in [Y] .</td>
<td id="A2.T4.3.3.3" class="ltx_td ltx_align_center">Georgios Roilos died in Athens.</td>
</tr>
<tr id="A2.T4.3.4" class="ltx_tr">
<td id="A2.T4.3.4.1" class="ltx_td ltx_align_left">P279</td>
<td id="A2.T4.3.4.2" class="ltx_td ltx_align_center">[X] is a subclass of [Y].</td>
<td id="A2.T4.3.4.3" class="ltx_td ltx_align_center">Hutterite German is a subclass of Bavarian .</td>
</tr>
<tr id="A2.T4.3.5" class="ltx_tr">
<td id="A2.T4.3.5.1" class="ltx_td ltx_align_left">P37</td>
<td id="A2.T4.3.5.2" class="ltx_td ltx_align_center">The official language of [X] is [Y].</td>
<td id="A2.T4.3.5.3" class="ltx_td ltx_align_center">The official language of Azad Kashmir is English .</td>
</tr>
<tr id="A2.T4.3.6" class="ltx_tr">
<td id="A2.T4.3.6.1" class="ltx_td ltx_align_left">P449</td>
<td id="A2.T4.3.6.2" class="ltx_td ltx_align_center">[X] was originally aired on [Y] .</td>
<td id="A2.T4.3.6.3" class="ltx_td ltx_align_center">Microsoap was originally aired on BBC.</td>
</tr>
<tr id="A2.T4.3.7" class="ltx_tr">
<td id="A2.T4.3.7.1" class="ltx_td ltx_align_left">P47</td>
<td id="A2.T4.3.7.2" class="ltx_td ltx_align_center">[X] shares border with [Y] .</td>
<td id="A2.T4.3.7.3" class="ltx_td ltx_align_center">Illinois shares border with Kentucky .</td>
</tr>
<tr id="A2.T4.3.8" class="ltx_tr">
<td id="A2.T4.3.8.1" class="ltx_td ltx_align_left">P138</td>
<td id="A2.T4.3.8.2" class="ltx_td ltx_align_center">[X] is named after [Y] .</td>
<td id="A2.T4.3.8.3" class="ltx_td ltx_align_center">Logan International Airport is named after Boston .</td>
</tr>
<tr id="A2.T4.3.9" class="ltx_tr">
<td id="A2.T4.3.9.1" class="ltx_td ltx_align_left">P364</td>
<td id="A2.T4.3.9.2" class="ltx_td ltx_align_center">The original language of [X] is [Y] .</td>
<td id="A2.T4.3.9.3" class="ltx_td ltx_align_center">The original language of The Fatal Eggs is Russian .</td>
</tr>
<tr id="A2.T4.3.10" class="ltx_tr">
<td id="A2.T4.3.10.1" class="ltx_td ltx_align_left">P527</td>
<td id="A2.T4.3.10.2" class="ltx_td ltx_align_center">[X] consists of [Y] .</td>
<td id="A2.T4.3.10.3" class="ltx_td ltx_align_center">AIM alliance consists of Apple .</td>
</tr>
<tr id="A2.T4.3.11" class="ltx_tr">
<td id="A2.T4.3.11.1" class="ltx_td ltx_align_left">P176</td>
<td id="A2.T4.3.11.2" class="ltx_td ltx_align_center">[X] is produced by [Y] .</td>
<td id="A2.T4.3.11.3" class="ltx_td ltx_align_center">Alfa Romeo 155 is produced by Fiat .</td>
</tr>
<tr id="A2.T4.3.12" class="ltx_tr">
<td id="A2.T4.3.12.1" class="ltx_td ltx_align_left">P27</td>
<td id="A2.T4.3.12.2" class="ltx_td ltx_align_center">[X] is [Y] citizen .</td>
<td id="A2.T4.3.12.3" class="ltx_td ltx_align_center">Woodrow Lloyd is Canada citizen .</td>
</tr>
<tr id="A2.T4.3.13" class="ltx_tr">
<td id="A2.T4.3.13.1" class="ltx_td ltx_align_left">P407</td>
<td id="A2.T4.3.13.2" class="ltx_td ltx_align_center">[X] was written in [Y] .</td>
<td id="A2.T4.3.13.3" class="ltx_td ltx_align_center">France Culture was written in French .</td>
</tr>
<tr id="A2.T4.3.14" class="ltx_tr">
<td id="A2.T4.3.14.1" class="ltx_td ltx_align_left">P30</td>
<td id="A2.T4.3.14.2" class="ltx_td ltx_align_center">[X] is located in [Y] .</td>
<td id="A2.T4.3.14.3" class="ltx_td ltx_align_center">Lavoisier Island is located in Antarctica .</td>
</tr>
<tr id="A2.T4.3.15" class="ltx_tr">
<td id="A2.T4.3.15.1" class="ltx_td ltx_align_left">P178</td>
<td id="A2.T4.3.15.2" class="ltx_td ltx_align_center">[X] is developed by [Y].</td>
<td id="A2.T4.3.15.3" class="ltx_td ltx_align_center">Tizen is developed by Intel .</td>
</tr>
<tr id="A2.T4.3.16" class="ltx_tr">
<td id="A2.T4.3.16.1" class="ltx_td ltx_align_left">P1376</td>
<td id="A2.T4.3.16.2" class="ltx_td ltx_align_center">[X] is the capital of [Y],</td>
<td id="A2.T4.3.16.3" class="ltx_td ltx_align_center">London is the capital of England .</td>
</tr>
<tr id="A2.T4.3.17" class="ltx_tr">
<td id="A2.T4.3.17.1" class="ltx_td ltx_align_left">P131</td>
<td id="A2.T4.3.17.2" class="ltx_td ltx_align_center">[X] is located in [Y] .</td>
<td id="A2.T4.3.17.3" class="ltx_td ltx_align_center">Pershing County is located in Nevada .</td>
</tr>
<tr id="A2.T4.3.18" class="ltx_tr">
<td id="A2.T4.3.18.1" class="ltx_td ltx_align_left">P1412</td>
<td id="A2.T4.3.18.2" class="ltx_td ltx_align_center">[X] used to communicate in [Y].</td>
<td id="A2.T4.3.18.3" class="ltx_td ltx_align_center">Jacques Rivette used to communicate in French .</td>
</tr>
<tr id="A2.T4.3.19" class="ltx_tr">
<td id="A2.T4.3.19.1" class="ltx_td ltx_align_left">P17</td>
<td id="A2.T4.3.19.2" class="ltx_td ltx_align_center">[X] is located in [Y] .</td>
<td id="A2.T4.3.19.3" class="ltx_td ltx_align_center">Eibenstock is located in Germany .</td>
</tr>
<tr id="A2.T4.3.20" class="ltx_tr">
<td id="A2.T4.3.20.1" class="ltx_td ltx_align_left">P276</td>
<td id="A2.T4.3.20.2" class="ltx_td ltx_align_center">[X] is located in [Y] .</td>
<td id="A2.T4.3.20.3" class="ltx_td ltx_align_center">Delhi Technological University is located in India .</td>
</tr>
<tr id="A2.T4.3.21" class="ltx_tr">
<td id="A2.T4.3.21.1" class="ltx_td ltx_align_left">P937</td>
<td id="A2.T4.3.21.2" class="ltx_td ltx_align_center">[X] used to work in [Y].</td>
<td id="A2.T4.3.21.3" class="ltx_td ltx_align_center">Pierre Trudeau used to work in Ottawa .</td>
</tr>
<tr id="A2.T4.3.22" class="ltx_tr">
<td id="A2.T4.3.22.1" class="ltx_td ltx_align_left">P140</td>
<td id="A2.T4.3.22.2" class="ltx_td ltx_align_center">[X] is affiliated with the [Y] religion .</td>
<td id="A2.T4.3.22.3" class="ltx_td ltx_align_center">Emirate of Granada is affiliated with the Islam religion .</td>
</tr>
<tr id="A2.T4.3.23" class="ltx_tr">
<td id="A2.T4.3.23.1" class="ltx_td ltx_align_left">P103</td>
<td id="A2.T4.3.23.2" class="ltx_td ltx_align_center">The native language of [X] is [Y] .</td>
<td id="A2.T4.3.23.3" class="ltx_td ltx_align_center">The native language of Anastasy Vonsyatsky is Russian .</td>
</tr>
<tr id="A2.T4.3.24" class="ltx_tr">
<td id="A2.T4.3.24.1" class="ltx_td ltx_align_left">P190</td>
<td id="A2.T4.3.24.2" class="ltx_td ltx_align_center">[X] and [Y] are twin cities .</td>
<td id="A2.T4.3.24.3" class="ltx_td ltx_align_center">Beijing and Milan are twin cities .</td>
</tr>
<tr id="A2.T4.3.25" class="ltx_tr">
<td id="A2.T4.3.25.1" class="ltx_td ltx_align_left">P1001</td>
<td id="A2.T4.3.25.2" class="ltx_td ltx_align_center">[X] is a legal term in [Y] .</td>
<td id="A2.T4.3.25.3" class="ltx_td ltx_align_center">Surgeon General is a legal term in Canada .</td>
</tr>
<tr id="A2.T4.3.26" class="ltx_tr">
<td id="A2.T4.3.26.1" class="ltx_td ltx_align_left">P495</td>
<td id="A2.T4.3.26.2" class="ltx_td ltx_align_center">[X] was created in [Y] .</td>
<td id="A2.T4.3.26.3" class="ltx_td ltx_align_center">La Grande Vadrouille was created in France .</td>
</tr>
<tr id="A2.T4.3.27" class="ltx_tr">
<td id="A2.T4.3.27.1" class="ltx_td ltx_align_left">P36</td>
<td id="A2.T4.3.27.2" class="ltx_td ltx_align_center">The capital of [X] is [Y] .</td>
<td id="A2.T4.3.27.3" class="ltx_td ltx_align_center">The capital of Granville County is Oxford .</td>
</tr>
<tr id="A2.T4.3.28" class="ltx_tr">
<td id="A2.T4.3.28.1" class="ltx_td ltx_align_left">P740</td>
<td id="A2.T4.3.28.2" class="ltx_td ltx_align_center">[X] was founded in [Y].</td>
<td id="A2.T4.3.28.3" class="ltx_td ltx_align_center">Grimaldi Group was founded in Naples .</td>
</tr>
<tr id="A2.T4.3.29" class="ltx_tr">
<td id="A2.T4.3.29.1" class="ltx_td ltx_align_left ltx_border_bb">P361</td>
<td id="A2.T4.3.29.2" class="ltx_td ltx_align_center ltx_border_bb">[X] is part of [Y] .</td>
<td id="A2.T4.3.29.3" class="ltx_td ltx_align_center ltx_border_bb">Sinqa is part of Andes .</td>
</tr>
</tbody></table>
</figure>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Interfaces used for the construction of CKL benchmark</h3>

<div id="A2.SS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A2.SS2.p1.1"><span class="ltx_text ltx_font_smallcaps" id="A2.SS2.p1.1.1">UpdatedLAMA</span> 및 <span class="ltx_text ltx_font_smallcaps" id="A2.SS2.p1.1.2">NewLAMA</span>, <span class="ltx_text ltx_font_smallcaps" id="A2.SS2.p1.1.3">NewLAMA-Easy</span> 및 <span class="ltx_text ltx_font_smallcaps" id="A2.SS2.p1.1.4">NewLAMA-Easy</span>은 각각 그림 <a class="ltx_ref" href="#A2.F5" title="Figure 5 ‣ B.2 Interfaces used for the construction of CKL benchmark ‣ Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>, <a class="ltx_ref" href="#A2.F6" title="Figure 6 ‣ B.2 Interfaces used for the construction of CKL benchmark ‣ Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>, <a class="ltx_ref" href="#A2.F7" title="Figure 7 ‣ B.2 Interfaces used for the construction of CKL benchmark ‣ Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">7</span></a>에 나와 있다.</p>
</div>
<figure id="A2.F5" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/figures/interface1.png" id="A2.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="494" height="361" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 5:</span> <span class="ltx_text ltx_font_smallcaps" id="A2.F5.3.1">UpdatedLAMA</span> 및 <span class="ltx_text ltx_font_smallcaps" id="A2.F5.4.2">NewLAMA</span></figcaption>
</figure>
<figure id="A2.F6" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/figures/interface2.png" id="A2.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="494" height="175" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 6:</span><span class="ltx_text ltx_font_smallcaps" id="A2.F6.2.1">NewLAMA-Easy</span></figcaption>
</figure>
<figure id="A2.F7" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/figures/interface3.png" id="A2.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="494" height="191" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 7:</span>Second mturk interface used for construction of <span class="ltx_text ltx_font_smallcaps" id="A2.F7.2.1">NewLAMA-Easy</span></figcaption>
</figure>
</section>
<section id="A2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Dataset Statistics and Examples</h3>

<figure id="A2.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 5:</span>CKL 벤치마크 데이터 세트 통계</figcaption>
<table id="A2.T5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A2.T5.1.1" class="ltx_tr">
<td id="A2.T5.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="A2.T5.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="A2.T5.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="A2.T5.1.1.2.1" class="ltx_text ltx_font_bold">Size</span></td>
<td id="A2.T5.1.1.3" class="ltx_td ltx_align_center ltx_border_tt">
<span id="A2.T5.1.1.3.1" class="ltx_text ltx_font_bold">Avg. Input</span></td>
<td id="A2.T5.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">
<span id="A2.T5.1.1.4.1" class="ltx_text ltx_font_bold">Avg. Answer</span></td>
<td id="A2.T5.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2">
<span id="A2.T5.1.1.5.1" class="ltx_text ltx_font_bold">Answer Types</span></td>
</tr>
<tr id="A2.T5.1.2" class="ltx_tr">
<td id="A2.T5.1.2.1" class="ltx_td ltx_align_center">
<span id="A2.T5.1.2.1.1" class="ltx_text ltx_font_bold">Token #</span></td>
<td id="A2.T5.1.2.2" class="ltx_td ltx_align_center">
<span id="A2.T5.1.2.2.1" class="ltx_text ltx_font_bold">Token #</span></td>
</tr>
<tr id="A2.T5.1.3" class="ltx_tr">
<td id="A2.T5.1.3.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="A2.T5.1.3.1.1" class="ltx_text ltx_font_smallcaps">InvariantLAMA</span></td>
<td id="A2.T5.1.3.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="A2.T5.1.3.2.1" class="ltx_text">17474</span></td>
<td id="A2.T5.1.3.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="2">
<span id="A2.T5.1.3.3.1" class="ltx_text">11.9</span></td>
<td id="A2.T5.1.3.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="2">
<span id="A2.T5.1.3.4.1" class="ltx_text">1.3</span></td>
<td id="A2.T5.1.3.5" class="ltx_td ltx_align_left ltx_border_t">Geographical (54%), Language (14.9%), Nationalities (7.2%)</td>
</tr>
<tr id="A2.T5.1.4" class="ltx_tr">
<td id="A2.T5.1.4.1" class="ltx_td ltx_align_left">Person (6.3%), Location (5.7%), Organization (5.3%), etc. (6.6%)</td>
</tr>
<tr id="A2.T5.1.5" class="ltx_tr">
<td id="A2.T5.1.5.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="A2.T5.1.5.1.1" class="ltx_text ltx_font_smallcaps">UpdatedLAMA</span></td>
<td id="A2.T5.1.5.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="A2.T5.1.5.2.1" class="ltx_text">924</span></td>
<td id="A2.T5.1.5.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="2">
<span id="A2.T5.1.5.3.1" class="ltx_text">13.7</span></td>
<td id="A2.T5.1.5.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="2">
<span id="A2.T5.1.5.4.1" class="ltx_text">9.4</span></td>
<td id="A2.T5.1.5.5" class="ltx_td ltx_align_left ltx_border_t">Person (61.47%), Organization (8.3%), Geographical (6.6%),</td>
</tr>
<tr id="A2.T5.1.6" class="ltx_tr">
<td id="A2.T5.1.6.1" class="ltx_td ltx_align_left">Numerals (5.19%), Date (2.4%), etc. (16.04%)</td>
</tr>
<tr id="A2.T5.1.7" class="ltx_tr">
<td id="A2.T5.1.7.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="A2.T5.1.7.1.1" class="ltx_text ltx_font_smallcaps">NewLAMA</span></td>
<td id="A2.T5.1.7.2" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="A2.T5.1.7.2.1" class="ltx_text">797</span></td>
<td id="A2.T5.1.7.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="2">
<span id="A2.T5.1.7.3.1" class="ltx_text">14.7</span></td>
<td id="A2.T5.1.7.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="2">
<span id="A2.T5.1.7.4.1" class="ltx_text">8.7</span></td>
<td id="A2.T5.1.7.5" class="ltx_td ltx_align_left ltx_border_t">Person (59.7%), Organization (10.2%), Numerals (7.6%)</td>
</tr>
<tr id="A2.T5.1.8" class="ltx_tr">
<td id="A2.T5.1.8.1" class="ltx_td ltx_align_left">Date (5.3%), Geographical (4.8%), etc. (12.4%)</td>
</tr>
<tr id="A2.T5.1.9" class="ltx_tr">
<td id="A2.T5.1.9.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="2"><span id="A2.T5.1.9.1.1" class="ltx_text ltx_font_smallcaps">NewLAMA-Easy</span></td>
<td id="A2.T5.1.9.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="2"><span id="A2.T5.1.9.2.1" class="ltx_text">11177</span></td>
<td id="A2.T5.1.9.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="2">
<span id="A2.T5.1.9.3.1" class="ltx_text">44.4</span></td>
<td id="A2.T5.1.9.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="2">
<span id="A2.T5.1.9.4.1" class="ltx_text">6.1</span></td>
<td id="A2.T5.1.9.5" class="ltx_td ltx_align_left ltx_border_t">Person (48.5%), Organization (13%), Geographical (9.8%)</td>
</tr>
<tr id="A2.T5.1.10" class="ltx_tr">
<td id="A2.T5.1.10.1" class="ltx_td ltx_align_left ltx_border_bb">Date (5.5%), Nationalities (3.4%), Numerals (2.5%), etc. (17.3%)</td>
</tr>
</tbody></table>
</figure>
<figure id="A2.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 6:</span> <span class="ltx_text ltx_font_smallcaps" id="A2.T6.5.1">InvariantLAMA</span>, <span class="ltx_text ltx_font_smallcaps" id="A2.T6.6.2">UpdatedLAMA</span>, <span class="ltx_text ltx_font_smallcaps" id="A2.T6.7.3">NewLAMA</span>, <span class="ltx_text ltx_font_smallcaps" id="A2.T6.8.4">NewLAMA-Easy</span></figcaption>
<table id="A2.T6.9" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A2.T6.9.1" class="ltx_tr">
<td id="A2.T6.9.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="A2.T6.9.1.1.1" class="ltx_text ltx_font_bold">Task</span></td>
<td id="A2.T6.9.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span id="A2.T6.9.1.2.1" class="ltx_text ltx_font_bold">Input</span></td>
<td id="A2.T6.9.1.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="A2.T6.9.1.3.1" class="ltx_text ltx_font_bold">Output</span></td>
</tr>
<tr id="A2.T6.9.2" class="ltx_tr">
<td id="A2.T6.9.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="3"><span id="A2.T6.9.2.1.1" class="ltx_text ltx_font_smallcaps">InvariantLAMA</span></td>
<td id="A2.T6.9.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">iPod Touch is produced by <span class="ltx_rule" style="width:28.5pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span>.</td>
<td id="A2.T6.9.2.3" class="ltx_td ltx_align_left ltx_border_t">Apple</td>
</tr>
<tr id="A2.T6.9.3" class="ltx_tr">
<td id="A2.T6.9.3.1" class="ltx_td ltx_align_left ltx_border_r">The Sharon Cuneta Show was created in <span class="ltx_rule" style="width:28.5pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span>.</td>
<td id="A2.T6.9.3.2" class="ltx_td ltx_align_left">Philippines</td>
</tr>
<tr id="A2.T6.9.4" class="ltx_tr">
<td id="A2.T6.9.4.1" class="ltx_td ltx_align_left ltx_border_r">The native language of Lee Chang-dong is <span class="ltx_rule" style="width:28.5pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span>.</td>
<td id="A2.T6.9.4.2" class="ltx_td ltx_align_left">Korean</td>
</tr>
<tr id="A2.T6.9.5" class="ltx_tr">
<td id="A2.T6.9.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="6"><span id="A2.T6.9.5.1.1" class="ltx_text ltx_font_smallcaps">UpdatedLAMA</span></td>
<td id="A2.T6.9.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span class="ltx_rule" style="width:28.5pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> is the prime minister of England.</td>
<td id="A2.T6.9.5.3" class="ltx_td ltx_align_left ltx_border_t">Theresa May→</td>
</tr>
<tr id="A2.T6.9.6" class="ltx_tr">
<td id="A2.T6.9.6.1" class="ltx_td ltx_border_r"></td>
<td id="A2.T6.9.6.2" class="ltx_td ltx_align_left">Boris Johnson</td>
</tr>
<tr id="A2.T6.9.7" class="ltx_tr">
<td id="A2.T6.9.7.1" class="ltx_td ltx_align_left ltx_border_r">
<span class="ltx_rule" style="width:28.5pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> has the most passing yards in the NFL.</td>
<td id="A2.T6.9.7.2" class="ltx_td ltx_align_left">Brady Quinn→</td>
</tr>
<tr id="A2.T6.9.8" class="ltx_tr">
<td id="A2.T6.9.8.1" class="ltx_td ltx_border_r"></td>
<td id="A2.T6.9.8.2" class="ltx_td ltx_align_left">Jalen Guyton</td>
</tr>
<tr id="A2.T6.9.9" class="ltx_tr">
<td id="A2.T6.9.9.1" class="ltx_td ltx_align_left ltx_border_r">Bale has <span class="ltx_rule" style="width:28.5pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> champions league titles with</td>
<td id="A2.T6.9.9.2" class="ltx_td ltx_align_left" rowspan="2"><span id="A2.T6.9.9.2.1" class="ltx_text">3→4</span></td>
</tr>
<tr id="A2.T6.9.10" class="ltx_tr">
<td id="A2.T6.9.10.1" class="ltx_td ltx_align_left ltx_border_r">Real Madrid.</td>
</tr>
<tr id="A2.T6.9.11" class="ltx_tr">
<td id="A2.T6.9.11.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="4"><span id="A2.T6.9.11.1.1" class="ltx_text ltx_font_smallcaps">NewLAMA</span></td>
<td id="A2.T6.9.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Alicia Braga plays <span class="ltx_rule" style="width:28.5pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> in the New Mutant.</td>
<td id="A2.T6.9.11.3" class="ltx_td ltx_align_left ltx_border_t">Cecilia Reyes</td>
</tr>
<tr id="A2.T6.9.12" class="ltx_tr">
<td id="A2.T6.9.12.1" class="ltx_td ltx_align_left ltx_border_r">
<span class="ltx_rule" style="width:28.5pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> owns the rights to the Falcon and the</td>
<td id="A2.T6.9.12.2" class="ltx_td ltx_align_left" rowspan="2"><span id="A2.T6.9.12.2.1" class="ltx_text">Disney</span></td>
</tr>
<tr id="A2.T6.9.13" class="ltx_tr">
<td id="A2.T6.9.13.1" class="ltx_td ltx_align_left ltx_border_r">Winter Soldier.</td>
</tr>
<tr id="A2.T6.9.14" class="ltx_tr">
<td id="A2.T6.9.14.1" class="ltx_td ltx_align_left ltx_border_r">Tesla invested <span class="ltx_rule" style="width:28.5pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> in the digital currency bitcoin.</td>
<td id="A2.T6.9.14.2" class="ltx_td ltx_align_left">1.5 billion</td>
</tr>
<tr id="A2.T6.9.15" class="ltx_tr">
<td id="A2.T6.9.15.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" rowspan="5"><span id="A2.T6.9.15.1.1" class="ltx_text ltx_font_smallcaps">NewLAMA-Easy</span></td>
<td id="A2.T6.9.15.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">The decision of the two volleyball stars Bria and Cimone</td>
<td id="A2.T6.9.15.3" class="ltx_td ltx_align_left ltx_border_t" rowspan="3"><span id="A2.T6.9.15.3.1" class="ltx_text">Howard University</span></td>
</tr>
<tr id="A2.T6.9.16" class="ltx_tr">
<td id="A2.T6.9.16.1" class="ltx_td ltx_align_left ltx_border_r">Woodard to withdraw from the Power 5 School to study</td>
</tr>
<tr id="A2.T6.9.17" class="ltx_tr">
<td id="A2.T6.9.17.1" class="ltx_td ltx_align_left ltx_border_r">at <span class="ltx_rule" style="width:28.5pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> has become a national story.</td>
</tr>
<tr id="A2.T6.9.18" class="ltx_tr">
<td id="A2.T6.9.18.1" class="ltx_td ltx_align_left ltx_border_r">Allen Lazard is officially listed as questionable with a</td>
<td id="A2.T6.9.18.2" class="ltx_td ltx_align_left ltx_border_bb" rowspan="2"><span id="A2.T6.9.18.2.1" class="ltx_text">six</span></td>
</tr>
<tr id="A2.T6.9.19" class="ltx_tr">
<td id="A2.T6.9.19.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">nuclear injury after missing the last <span class="ltx_rule" style="width:28.5pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> games.</td>
</tr>
</tbody></table>
</figure>
<div id="A2.SS3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A2.SS3.p1.1">표 <a class="ltx_ref" href="#A2.T5" title="Table 5 ‣ B.3 Dataset Statistics and Examples ‣ Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>에서 CKL 벤치마크에 대한 데이터 통계를 보고한다. 구성된 각 데이터 세트의 크기, 평균 입력 토큰 길이, 평균 답변 토큰 길이 및 답변 유형을 측정한다. 고려해야 할 한 가지는 LAMA <cite class="ltx_cite ltx_citemacro_citep">(Petroni et al., <a class="ltx_ref" href="#bib.bib37" title="">2019</a>)</cite>에서 <span class="ltx_text ltx_font_smallcaps" id="A2.SS3.p1.1.1">InvariantLAMA</span>은 원래 단일 토큰 디코딩(1.3 with the T5-tokenizer)만을 위해 구성됩니다. 다중 토큰 디코딩에는 추가 조정 가능한 매개 변수(빔 크기, n-그램 반복 페널티 등)가 포함되기 때문입니다. 새로 구성된 데이터 세트 <span class="ltx_text ltx_font_smallcaps" id="A2.SS3.p1.1.2">UpdatedLAMA</span>, <span class="ltx_text ltx_font_smallcaps" id="A2.SS3.p1.1.3">NewLAMA</span> 및 <span class="ltx_text ltx_font_smallcaps" id="A2.SS3.p1.1.4">NewLAMA-Easy</span>는 <span class 또한, <span class="ltx_text ltx_font_smallcaps" id="A2.SS3.p1.1.6">NewLAMA-Easy</span>은 각 인스턴스를 만들기 위해 디컨텍스트화 및 역번역 프로세스가 적용되기 때문에 다른 데이터 세트와 다른 입력 분포(더 긴 입력 시퀀스)를 가지며, 이는 문장을 더 길게 만든다. 마지막으로 CKL 벤치마크 데이터 세트의 일부 예는 표 <a class="ltx_ref" href="#A2.T6" title="Table 6 ‣ B.3 Dataset Statistics and Examples ‣ Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">6</span></a>에 나와 있다.</p>
</div>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Experimental Configuration</h2>

<section id="A3.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pretraining Congifuration</h5>

<div id="A3.SS0.SSS0.Px1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A3.SS0.SSS0.Px1.p1.1">초기화는 C4(2019년 4월)에서 초기 사전 훈련된 T5와 위키피디아(2020년 5월)에서 두드러진 스팬 마스킹 <cite class="ltx_cite ltx_citemacro_citep">(Guu et al., <a class="ltx_ref" href="#bib.bib15" title="">2020</a>)</cite>로 지속적으로 사전 훈련된 T5를 활용한다. 우리는 <cite class="ltx_cite ltx_citemacro_citet">Wolf et al. (<a class="ltx_ref" href="#bib.bib53" title="">2020</a>)</cite>의 체크포인트를 사용한다. 또한 CKL 동안 SSM 목표를 수행하는 이유는 LMs가 "세계 지식을 필요로 하는 문제에 초점을 맞춘다" <cite class="ltx_cite ltx_citemacro_citep">(Guu et al., <a class="ltx_ref" href="#bib.bib15" title="">2020</a>; Roberts et al., <a class="ltx_ref" href="#bib.bib43" title="">2020</a>)</cite>를 돕는 것으로 나타났기 때문이다.</p>
</div>
</section>
<section id="A3.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Continual Pretraining Configurations</h5>

<div id="A3.SS0.SSS0.Px2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A3.SS0.SSS0.Px2.p1.1">입력 및 출력 시퀀스 길이는 350으로 고정된다. 다른 방법에 필요한 메모리 소모가 다양하기 때문에 동일한 수의 훈련 배치가 GPU에 로드될 수 없는 경우에 대해 기울기 축적을 사용하고 전역 배치 크기를 60으로 설정한다. 초기 학습률이 1e-3인 Adafactor 최적화기를 사용한다. 부록 <a class="ltx_ref" href="#A5" title="Appendix E Exploring the Trade-off of Varying the Learning Rate for Continual Pretraining ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">E</span></a>에서 이전 지식 유지와 새로운 지식 획득 사이의 트레이드오프에 대한 학습률 변동의 효과를 보여준다. 우리는 훈련의 처음 10%에 대해 학습률 워밍업을 사용하고 훈련이 끝날 때까지 학습률을 초기 학습률의 절반으로 선형 붕괴시킨다. 모든 실험에 대해 Mix-Review를 제외한 각 방법으로 훈련하기 위해 4개의 32GB V100 GPU를 사용하며, 여기서 16개의 32GB V100 GPU를 사용한다. 각각의 개별 CKL 태스크에 대한 평가에 사용되는 구성들의 세부사항들은 부록 <a class="ltx_ref" href="#A3.SS0.SSS0.Px3" title="Evaluation Configurations ‣ Appendix C Experimental Configuration ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">C</span></a>에 제공된다.</p>
</div>
</section>
<section id="A3.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Evaluation Configurations</h5>

<div id="A3.SS0.SSS0.Px3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A3.SS0.SSS0.Px3.p1.1">T5 기반 모델의 경우 모든 평가는 제로샷 방식으로 수행되며 단일 GPU로 처리된다. <span class="ltx_text ltx_font_smallcaps" id="A3.SS0.SSS0.Px3.p1.1.1">InvariantLAMA</span>의 경우 입력 및 출력 길이는 각각 25 및 4로 고정됩니다. <span class="ltx_text ltx_font_smallcaps" id="A3.SS0.SSS0.Px3.p1.1.2">UpdatedLAMA</span> 및 <span class="ltx_text ltx_font_smallcaps" id="A3.SS0.SSS0.Px3.p1.1.3">NewLAMA</span>의 경우 입력 및 출력 길이는 각각 50 및 10입니다. 마지막으로 입력 및 출력 길이는 <span class="ltx_text ltx_font_smallcaps" id="A3.SS0.SSS0.Px3.p1.1.4">NewLAMA-Easy</span>에 대해 각각 150 및 10입니다. 이 하이퍼파라미터의 근거는 표 <a class="ltx_ref" href="#A2.T5" title="Table 5 ‣ B.3 Dataset Statistics and Examples ‣ Appendix B Dataset Construction ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">5</span></a>의 평균 입력 및 답변 토큰을 기반으로 한다.</p>
</div>
<div id="A3.SS0.SSS0.Px3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A3.SS0.SSS0.Px3.p2.1">T5 모델과 달리 GPT-2 기반 모델은 평가를 위해 1 epoch에 대해 추가 <span class="ltx_text ltx_font_italic" id="A3.SS0.SSS0.Px3.p2.1.1">light-tuning</span>이 필요합니다. <span class="ltx_text ltx_font_smallcaps" id="A3.SS0.SSS0.Px3.p2.1.2">InvariantLAMA</span>의 경우 입력 및 출력 길이는 각각 50 및 3입니다. 학습 배치 크기는 32이고 학습률은 1e-3이다. 새로운 지식의 획득에 대한 평가를 위해 입력 길이와 출력 길이는 각각 100과 10이다. 훈련 배치 크기는 메모리 제약으로 인해 8이고 학습 속도는 1e-3이다. 두 튜닝 프로세스 모두에 대해 4개의 V100 32GB GPU가 사용된다. GPT-2 기반 모델의 자세한 결과와 논의는 부록 <a class="ltx_ref" href="#A7" title="Appendix G Exploring How CKL Methods Transfer Across LM Architectures ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">G</span></a>에 나와 있다.</p>
</div>
</section>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Hyperparameters for Implementation of CKL Methods</h2>

<div id="A4.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A4.p1.4"><span class="ltx_text ltx_font_bold" id="A4.p1.4.1">RecAdam</span> <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="#bib.bib3" title="">2020</a>)</cite> <cite class="ltx_cite ltx_citemacro_citet">Chen et al. (<a class="ltx_ref" href="#bib.bib3" title="">2020</a>)</cite>와 같은 하이퍼파라미터 설정을 최적화기에 사용한다: 2차 페널티 <math alttext="{\gamma}" class="ltx_Math" display="inline" id="A4.p1.1.m1.1"><semantics id="A4.p1.1.m1.1a"><mi id="A4.p1.1.m1.1.1" xref="A4.p1.1.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="A4.p1.1.m1.1b"><ci id="A4.p1.1.m1.1.1.cmml" xref="A4.p1.1.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.1.m1.1c">{\gamma}</annotation><annotation encoding="application/x-llamapun" id="A4.p1.1.m1.1d">italic_γ</annotation></semantics></math>의 계수를 5,000으로 설정하고, 어닐링 계수 <math alttext="{\lambda(t)}" class="ltx_Math" display="inline" id="A4.p1.4.m4.1"><semantics id="A4.p1.4.m4.1a"><mrow id="A4.p1.4.m4.1.2" xref="A4.p1.4.m4.1.2.cmml"><mi id="A4.p1.4.m4.1.2.2" xref="A4.p1.4.m4.1.2.2.cmml">λ</mi><mo id="A4.p1.4.m4.1.2.1" lspace="0px" rspace="0px" xref="A4.p1.4.m4.1.2.1.cmml"></mo><mrow id="A4.p1.4.m4.1.2.3.2" xref="A4.p1.4.m4.1.2.cmml"><mo id="A4.p1.4.m4.1.2.3.2.1" stretchy="false" xref="A4.p1.4.m4.1.2.cmml">(</mo><mi id="A4.p1.4.m4.1.1" xref="A4.p1.4.m4.1.1.cmml">t</mi><mo id="A4.p1.4.m4.1.2.3.2.2" stretchy="false" xref="A4.p1.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.p1.4.m4.1b"><apply id="A4.p1.4.m4.1.2.cmml" xref="A4.p1.4.m4.1.2"><times id="A4.p1.4.m4.1.2.1.cmml" xref="A4.p1.4.m4.1.2.1"></times><ci id="A4.p1.4.m4.1.2.2.cmml" xref="A4.p1.4.m4.1.2.2">𝜆</ci><ci id="A4.p1.4.m4.1.1.cmml" xref="A4.p1.4.m4.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.4.m4.1c">{\lambda(t)}</annotation><annotation encoding="application/x-llamapun" id="A4.p1.4.m4.1d">italic_λ ( italic_t )</annotation></semantics></math>에 대해 각각 100, 250, 500, 1,000과 0.05, 0.1, 0.2, 0.5, 1에서 가장 좋은 <math alttext="{t_{0}}" class="ltx_Math" display="inline" id="A4.p1.2.m2.1"><semantics id="A4.p1.2.m2.1a"><msub id="A4.p1.2.m2.1.1" xref="A4.p1.2.m2.1.1.cmml"><mi id="A4.p1.2.m2.1.1.2" xref="A4.p1.2.m2.1.1.2.cmml">t</mi><mn id="A4.p1.2.m2.1.1.3" xref="A4.p1.2.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A4.p1.2.m2.1b"><apply id="A4.p1.2.m2.1.1.cmml" xref="A4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A4.p1.2.m2.1.1.1.cmml" xref="A4.p1.2.m2.1.1">subscript</csymbol><ci id="A4.p1.2.m2.1.1.2.cmml" xref="A4.p1.2.m2.1.1.2">𝑡</ci><cn id="A4.p1.2.m2.1.1.3.cmml" type="integer" xref="A4.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.2.m2.1c">{t_{0}}</annotation><annotation encoding="application/x-llamapun" id="A4.p1.2.m2.1d">italic_t start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>와 <math alttext="{k}" class="ltx_Math" display="inline" id="A4.p1.3.m3.1"><semantics id="A4.p1.3.m3.1a"><mi id="A4.p1.3.m3.1.1" xref="A4.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A4.p1.3.m3.1b"><ci id="A4.p1.3.m3.1.1.cmml" xref="A4.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.3.m3.1c">{k}</annotation><annotation encoding="application/x-llamapun" id="A4.p1.3.m3.1d">italic_k</annotation></semantics></math>를 선택한다.</p>
</div>
<div id="A4.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A4.p2.1"><span class="ltx_text ltx_font_bold" id="A4.p2.1.1">Mix-Review</span> <cite class="ltx_cite ltx_citemacro_citep">(He et al., <a class="ltx_ref" href="#bib.bib17" title="">2021</a>)</cite> 영어 위키피디아 <span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a class="ltx_ref ltx_href" href="https://huggingface.co/datasets/wikipedia" target="_blank" title="">https://huggingface.co/datasets/wikipedia</a></span></span></span>을 사용하여 원본 프리트레이닝 코퍼스를 나타낸다. 믹스-디케이와 믹스-비율은 논문에서 가장 좋은 하이퍼파라미터 설정인 각각 4와 0.7로 설정된다.</p>
</div>
<div id="A4.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A4.p3.3"><span class="ltx_text ltx_font_bold" id="A4.p3.3.1">LoRA</span> <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="#bib.bib19" title="">2021</a>)</cite> 인코더-디코더 LM에 대한 인코더와 디코더 전용 LM에 대한 전체 모델만 동결합니다. 4의 최적 순위 <math alttext="{r}" class="ltx_Math" display="inline" id="A4.p3.1.m1.1"><semantics id="A4.p3.1.m1.1a"><mi id="A4.p3.1.m1.1.1" xref="A4.p3.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="A4.p3.1.m1.1b"><ci id="A4.p3.1.m1.1.1.cmml" xref="A4.p3.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.p3.1.m1.1c">{r}</annotation><annotation encoding="application/x-llamapun" id="A4.p3.1.m1.1d">italic_r</annotation></semantics></math>를 사용하고 자체 주의 모듈에서 <math alttext="{W_{q}}" class="ltx_Math" display="inline" id="A4.p3.2.m2.1"><semantics id="A4.p3.2.m2.1a"><msub id="A4.p3.2.m2.1.1" xref="A4.p3.2.m2.1.1.cmml"><mi id="A4.p3.2.m2.1.1.2" xref="A4.p3.2.m2.1.1.2.cmml">W</mi><mi id="A4.p3.2.m2.1.1.3" xref="A4.p3.2.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="A4.p3.2.m2.1b"><apply id="A4.p3.2.m2.1.1.cmml" xref="A4.p3.2.m2.1.1"><csymbol cd="ambiguous" id="A4.p3.2.m2.1.1.1.cmml" xref="A4.p3.2.m2.1.1">subscript</csymbol><ci id="A4.p3.2.m2.1.1.2.cmml" xref="A4.p3.2.m2.1.1.2">𝑊</ci><ci id="A4.p3.2.m2.1.1.3.cmml" xref="A4.p3.2.m2.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p3.2.m2.1c">{W_{q}}</annotation><annotation encoding="application/x-llamapun" id="A4.p3.2.m2.1d">italic_W start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math>와 <math alttext="{W_{v}}" class="ltx_Math" display="inline" id="A4.p3.3.m3.1"><semantics id="A4.p3.3.m3.1a"><msub id="A4.p3.3.m3.1.1" xref="A4.p3.3.m3.1.1.cmml"><mi id="A4.p3.3.m3.1.1.2" xref="A4.p3.3.m3.1.1.2.cmml">W</mi><mi id="A4.p3.3.m3.1.1.3" xref="A4.p3.3.m3.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="A4.p3.3.m3.1b"><apply id="A4.p3.3.m3.1.1.cmml" xref="A4.p3.3.m3.1.1"><csymbol cd="ambiguous" id="A4.p3.3.m3.1.1.1.cmml" xref="A4.p3.3.m3.1.1">subscript</csymbol><ci id="A4.p3.3.m3.1.1.2.cmml" xref="A4.p3.3.m3.1.1.2">𝑊</ci><ci id="A4.p3.3.m3.1.1.3.cmml" xref="A4.p3.3.m3.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p3.3.m3.1c">{W_{v}}</annotation><annotation encoding="application/x-llamapun" id="A4.p3.3.m3.1d">italic_W start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT</annotation></semantics></math>를 모두 적용하며, 이는 논문에서 가장 성능이 좋은 하이퍼파라미터 설정에 해당한다.</p>
</div>
<div id="A4.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A4.p4.1"><span class="ltx_text ltx_font_bold" id="A4.p4.1.1">K-Adapter</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib52" title="">2021b</a>)</cite> T5-LoRA와 마찬가지로 인코더-디코더 LM용 인코더와 GPT-2용 전체 모델을 동결한다. 파라미터 #의 증가 효과를 보기 위해 T5와 GPT-2 모두에 대해 <math alttext="{k}=2,3" class="ltx_Math" display="inline" id="A4.p4.1.m1.2"><semantics id="A4.p4.1.m1.2a"><mrow id="A4.p4.1.m1.2.3" xref="A4.p4.1.m1.2.3.cmml"><mi id="A4.p4.1.m1.2.3.2" xref="A4.p4.1.m1.2.3.2.cmml">k</mi><mo id="A4.p4.1.m1.2.3.1" xref="A4.p4.1.m1.2.3.1.cmml">=</mo><mrow id="A4.p4.1.m1.2.3.3.2" xref="A4.p4.1.m1.2.3.3.1.cmml"><mn id="A4.p4.1.m1.1.1" xref="A4.p4.1.m1.1.1.cmml">2</mn><mo id="A4.p4.1.m1.2.3.3.2.1" xref="A4.p4.1.m1.2.3.3.1.cmml">,</mo><mn id="A4.p4.1.m1.2.2" xref="A4.p4.1.m1.2.2.cmml">3</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.p4.1.m1.2b"><apply id="A4.p4.1.m1.2.3.cmml" xref="A4.p4.1.m1.2.3"><eq id="A4.p4.1.m1.2.3.1.cmml" xref="A4.p4.1.m1.2.3.1"></eq><ci id="A4.p4.1.m1.2.3.2.cmml" xref="A4.p4.1.m1.2.3.2">𝑘</ci><list id="A4.p4.1.m1.2.3.3.1.cmml" xref="A4.p4.1.m1.2.3.3.2"><cn id="A4.p4.1.m1.1.1.cmml" type="integer" xref="A4.p4.1.m1.1.1">2</cn><cn id="A4.p4.1.m1.2.2.cmml" type="integer" xref="A4.p4.1.m1.2.2">3</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p4.1.m1.2c">{k}=2,3</annotation><annotation encoding="application/x-llamapun" id="A4.p4.1.m1.2d">italic_k = 2 , 3</annotation></semantics></math>를 구현한다. 원본 논문에서와 달리, 우리는 업-프로젝션 및 다운-프로젝션 층의 필요성을 제거하면서, 원래의 LM으로부터 단일 변압기 층과 동일한 어댑터의 구성을 설정했다.</p>
</div>
<div id="A4.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A4.p5.1"><span class="ltx_text ltx_font_bold" id="A4.p5.1.1">Modular</span> 차원을 일치시키기 위해 두 인코더에서 숨겨진 상태 출력을 추가하기 전에 프로젝션 계층을 사용합니다.</p>
</div>
<div id="A4.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A4.p6.1"><span class="ltx_text ltx_font_bold" id="A4.p6.1.1">T5?</span> 파라미터 확장 방법의 경우 인코더가 입력 시퀀스에 적용되고 디코더가 출력 시퀀스에 적용되기 때문에 인코더에만 파라미터를 추가합니다. 계산 비용의 대부분은 <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="#bib.bib31" title="">2021</a>)</cite>에서 강조된 바와 같이 자동-회귀 방식으로 출력 시퀀스에 대한 디코더 컴퓨팅으로부터 나오기 때문에, 인코더에서 새롭게 추가된 파라미터들은 대략 최소의 추가적인 계산 비용을 가질 것으로 예상된다.</p>
</div>
<div id="A4.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A4.p7.1"><span class="ltx_text ltx_font_bold" id="A4.p7.1.1">T5?</span> K-Adapter and LoRA is initially proposed to freeze all the parameters except the newly added parameters. 그러나, 이 방법론을 T5에 적용할 때, 디코더의 파라미터를 언프리징하는 것이 전체 트레이드오프 측면에서 파라미터 확장 방법과 함께 사용될 때 더 나은 성능을 가져온다는 것을 경험적으로 보여주었다.</p>
</div>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Exploring the Trade-off of Varying the Learning Rate for Continual Pretraining</h2>

<figure id="A5.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 7:</span>T5-Vanilla 및 T5-Kadapters의Result는 다양한 학습률로 지속적으로 사전 훈련되었다. 실험은 <span class="ltx_text ltx_font_smallcaps" id="A5.T7.24.1">Small</span> 시나리오 in Table <a class="ltx_ref" href="#S5.T3" title="Table 3 ‣ 5.2 Exploring Multiple phases of CKL ‣ 5 Experimental Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>이므로 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A5.T7.9.m1.1"><semantics id="A5.T7.9.m1.1b"><msub id="A5.T7.9.m1.1.1" xref="A5.T7.9.m1.1.1.cmml"><mi id="A5.T7.9.m1.1.1.2" xref="A5.T7.9.m1.1.1.2.cmml">D</mi><mn id="A5.T7.9.m1.1.1.3" xref="A5.T7.9.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A5.T7.9.m1.1c"><apply id="A5.T7.9.m1.1.1.cmml" xref="A5.T7.9.m1.1.1"><csymbol cd="ambiguous" id="A5.T7.9.m1.1.1.1.cmml" xref="A5.T7.9.m1.1.1">subscript</csymbol><ci id="A5.T7.9.m1.1.1.2.cmml" xref="A5.T7.9.m1.1.1.2">𝐷</ci><cn id="A5.T7.9.m1.1.1.3.cmml" type="integer" xref="A5.T7.9.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.9.m1.1d">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A5.T7.9.m1.1e">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>는 C4(April 2019) 및 Wikipedia(May 2020)이고, <math alttext="D_{1}" class="ltx_Math" display="inline" id="A5.T7.10.m2.1"><semantics id="A5.T7.10.m2.1b"><msub id="A5.T7.10.m2.1.1" xref="A5.T7.10.m2.1.1.cmml"><mi id="A5.T7.10.m2.1.1.2" xref="A5.T7.10.m2.1.1.2.cmml">D</mi><mn id="A5.T7.10.m2.1.1.3" xref="A5.T7.10.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A5.T7.10.m2.1c"><apply id="A5.T7.10.m2.1.1.cmml" xref="A5.T7.10.m2.1.1"><csymbol cd="ambiguous" id="A5.T7.10.m2.1.1.1.cmml" xref="A5.T7.10.m2.1.1">subscript</csymbol><ci id="A5.T7.10.m2.1.1.2.cmml" xref="A5.T7.10.m2.1.1.2">𝐷</ci><cn id="A5.T7.10.m2.1.1.3.cmml" type="integer" xref="A5.T7.10.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.10.m2.1d">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A5.T7.10.m2.1e">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>는 <span class="ltx_text ltx_font_smallcaps" id="A5.T7.25.2">CC-RecentNews-Small</span>이다. IL 및 NLE 각각은 <span class="ltx_text ltx_font_smallcaps" id="A5.T7.26.3">InvariantLAMA</span> 및 <span class="ltx_text ltx_font_smallcaps" id="A5.T7.27.4">NewLAMA-Easy</span>의 약자이다. <span class="ltx_text" id="A5.T7.28.5">FUAR</span>의 파라미터는 각각 <math alttext="\mathbb{T}^{F}" class="ltx_Math" display="inline" id="A5.T7.11.m3.1"><semantics id="A5.T7.11.m3.1b"><msup id="A5.T7.11.m3.1.1" xref="A5.T7.11.m3.1.1.cmml"><mi id="A5.T7.11.m3.1.1.2" xref="A5.T7.11.m3.1.1.2.cmml">𝕋</mi><mi id="A5.T7.11.m3.1.1.3" xref="A5.T7.11.m3.1.1.3.cmml">F</mi></msup><annotation-xml encoding="MathML-Content" id="A5.T7.11.m3.1c"><apply id="A5.T7.11.m3.1.1.cmml" xref="A5.T7.11.m3.1.1"><csymbol cd="ambiguous" id="A5.T7.11.m3.1.1.1.cmml" xref="A5.T7.11.m3.1.1">superscript</csymbol><ci id="A5.T7.11.m3.1.1.2.cmml" xref="A5.T7.11.m3.1.1.2">𝕋</ci><ci id="A5.T7.11.m3.1.1.3.cmml" xref="A5.T7.11.m3.1.1.3">𝐹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.11.m3.1d">\mathbb{T}^{F}</annotation><annotation encoding="application/x-llamapun" id="A5.T7.11.m3.1e">blackboard_T start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="T_{1}^{U}" class="ltx_Math" display="inline" id="A5.T7.12.m4.1"><semantics id="A5.T7.12.m4.1b"><msubsup id="A5.T7.12.m4.1.1" xref="A5.T7.12.m4.1.1.cmml"><mi id="A5.T7.12.m4.1.1.2.2" xref="A5.T7.12.m4.1.1.2.2.cmml">T</mi><mn id="A5.T7.12.m4.1.1.2.3" xref="A5.T7.12.m4.1.1.2.3.cmml">1</mn><mi id="A5.T7.12.m4.1.1.3" xref="A5.T7.12.m4.1.1.3.cmml">U</mi></msubsup><annotation-xml encoding="MathML-Content" id="A5.T7.12.m4.1c"><apply id="A5.T7.12.m4.1.1.cmml" xref="A5.T7.12.m4.1.1"><csymbol cd="ambiguous" id="A5.T7.12.m4.1.1.1.cmml" xref="A5.T7.12.m4.1.1">superscript</csymbol><apply id="A5.T7.12.m4.1.1.2.cmml" xref="A5.T7.12.m4.1.1"><csymbol cd="ambiguous" id="A5.T7.12.m4.1.1.2.1.cmml" xref="A5.T7.12.m4.1.1">subscript</csymbol><ci id="A5.T7.12.m4.1.1.2.2.cmml" xref="A5.T7.12.m4.1.1.2.2">𝑇</ci><cn id="A5.T7.12.m4.1.1.2.3.cmml" type="integer" xref="A5.T7.12.m4.1.1.2.3">1</cn></apply><ci id="A5.T7.12.m4.1.1.3.cmml" xref="A5.T7.12.m4.1.1.3">𝑈</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.12.m4.1d">T_{1}^{U}</annotation><annotation encoding="application/x-llamapun" id="A5.T7.12.m4.1e">italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_U end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="T_{1}^{A}" class="ltx_Math" display="inline" id="A5.T7.13.m5.1"><semantics id="A5.T7.13.m5.1b"><msubsup id="A5.T7.13.m5.1.1" xref="A5.T7.13.m5.1.1.cmml"><mi id="A5.T7.13.m5.1.1.2.2" xref="A5.T7.13.m5.1.1.2.2.cmml">T</mi><mn id="A5.T7.13.m5.1.1.2.3" xref="A5.T7.13.m5.1.1.2.3.cmml">1</mn><mi id="A5.T7.13.m5.1.1.3" xref="A5.T7.13.m5.1.1.3.cmml">A</mi></msubsup><annotation-xml encoding="MathML-Content" id="A5.T7.13.m5.1c"><apply id="A5.T7.13.m5.1.1.cmml" xref="A5.T7.13.m5.1.1"><csymbol cd="ambiguous" id="A5.T7.13.m5.1.1.1.cmml" xref="A5.T7.13.m5.1.1">superscript</csymbol><apply id="A5.T7.13.m5.1.1.2.cmml" xref="A5.T7.13.m5.1.1"><csymbol cd="ambiguous" id="A5.T7.13.m5.1.1.2.1.cmml" xref="A5.T7.13.m5.1.1">subscript</csymbol><ci id="A5.T7.13.m5.1.1.2.2.cmml" xref="A5.T7.13.m5.1.1.2.2">𝑇</ci><cn id="A5.T7.13.m5.1.1.2.3.cmml" type="integer" xref="A5.T7.13.m5.1.1.2.3">1</cn></apply><ci id="A5.T7.13.m5.1.1.3.cmml" xref="A5.T7.13.m5.1.1.3">𝐴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.13.m5.1d">T_{1}^{A}</annotation><annotation encoding="application/x-llamapun" id="A5.T7.13.m5.1e">italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT</annotation></semantics></math>, 코퍼스 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A5.T7.14.m6.1"><semantics id="A5.T7.14.m6.1b"><msub id="A5.T7.14.m6.1.1" xref="A5.T7.14.m6.1.1.cmml"><mi id="A5.T7.14.m6.1.1.2" xref="A5.T7.14.m6.1.1.2.cmml">D</mi><mn id="A5.T7.14.m6.1.1.3" xref="A5.T7.14.m6.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A5.T7.14.m6.1c"><apply id="A5.T7.14.m6.1.1.cmml" xref="A5.T7.14.m6.1.1"><csymbol cd="ambiguous" id="A5.T7.14.m6.1.1.1.cmml" xref="A5.T7.14.m6.1.1">subscript</csymbol><ci id="A5.T7.14.m6.1.1.2.cmml" xref="A5.T7.14.m6.1.1.2">𝐷</ci><cn id="A5.T7.14.m6.1.1.3.cmml" type="integer" xref="A5.T7.14.m6.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.14.m6.1d">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A5.T7.14.m6.1e">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="D_{1}" class="ltx_Math" display="inline" id="A5.T7.15.m7.1"><semantics id="A5.T7.15.m7.1b"><msub id="A5.T7.15.m7.1.1" xref="A5.T7.15.m7.1.1.cmml"><mi id="A5.T7.15.m7.1.1.2" xref="A5.T7.15.m7.1.1.2.cmml">D</mi><mn id="A5.T7.15.m7.1.1.3" xref="A5.T7.15.m7.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A5.T7.15.m7.1c"><apply id="A5.T7.15.m7.1.1.cmml" xref="A5.T7.15.m7.1.1"><csymbol cd="ambiguous" id="A5.T7.15.m7.1.1.1.cmml" xref="A5.T7.15.m7.1.1">subscript</csymbol><ci id="A5.T7.15.m7.1.1.2.cmml" xref="A5.T7.15.m7.1.1.2">𝐷</ci><cn id="A5.T7.15.m7.1.1.3.cmml" type="integer" xref="A5.T7.15.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.15.m7.1d">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A5.T7.15.m7.1e">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="D_{1}" class="ltx_Math" display="inline" id="A5.T7.16.m8.1"><semantics id="A5.T7.16.m8.1b"><msub id="A5.T7.16.m8.1.1" xref="A5.T7.16.m8.1.1.cmml"><mi id="A5.T7.16.m8.1.1.2" xref="A5.T7.16.m8.1.1.2.cmml">D</mi><mn id="A5.T7.16.m8.1.1.3" xref="A5.T7.16.m8.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A5.T7.16.m8.1c"><apply id="A5.T7.16.m8.1.1.cmml" xref="A5.T7.16.m8.1.1"><csymbol cd="ambiguous" id="A5.T7.16.m8.1.1.1.cmml" xref="A5.T7.16.m8.1.1">subscript</csymbol><ci id="A5.T7.16.m8.1.1.2.cmml" xref="A5.T7.16.m8.1.1.2">𝐷</ci><cn id="A5.T7.16.m8.1.1.3.cmml" type="integer" xref="A5.T7.16.m8.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.16.m8.1d">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A5.T7.16.m8.1e">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>로부터 시간 불변 지식의 양을 측정하는 태스크이다.</figcaption>
<table id="A5.T7.18" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A5.T7.18.2" class="ltx_tr">
<td id="A5.T7.18.2.3" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2">
<span id="A5.T7.18.2.3.1" class="ltx_text"></span><span id="A5.T7.18.2.3.2" class="ltx_text ltx_font_bold"> <span id="A5.T7.18.2.3.2.1" class="ltx_text">
<span id="A5.T7.18.2.3.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="A5.T7.18.2.3.2.1.1.1" class="ltx_tr">
<span id="A5.T7.18.2.3.2.1.1.1.1" class="ltx_td ltx_align_center">Method</span></span>
</span></span> <span id="A5.T7.18.2.3.2.2" class="ltx_text"></span></span>
</td>
<td id="A5.T7.18.2.4" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2">
<span id="A5.T7.18.2.4.1" class="ltx_text"></span><span id="A5.T7.18.2.4.2" class="ltx_text ltx_font_bold"> <span id="A5.T7.18.2.4.2.1" class="ltx_text">
<span id="A5.T7.18.2.4.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="A5.T7.18.2.4.2.1.1.1" class="ltx_tr">
<span id="A5.T7.18.2.4.2.1.1.1.1" class="ltx_td ltx_align_center">Learning Rate</span></span>
</span></span> <span id="A5.T7.18.2.4.2.2" class="ltx_text"></span></span>
</td>
<td id="A5.T7.18.2.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="A5.T7.18.2.5.1" class="ltx_text ltx_font_bold">IL</span></td>
<td id="A5.T7.18.2.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="A5.T7.18.2.6.1" class="ltx_text ltx_font_bold">NLE</span></td>
<td id="A5.T7.18.2.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2">
<span id="A5.T7.18.2.2.3" class="ltx_text"></span><span id="A5.T7.18.2.2.2" class="ltx_text ltx_font_bold"> <span id="A5.T7.18.2.2.2.2" class="ltx_text">
<span id="A5.T7.18.2.2.2.2.2.2" class="ltx_tabular ltx_align_middle">
<span id="A5.T7.18.2.2.2.2.2.2.3" class="ltx_tr">
<span id="A5.T7.18.2.2.2.2.2.2.3.1" class="ltx_td ltx_align_center"><span id="A5.T7.18.2.2.2.2.2.2.3.1.1" class="ltx_text">FUAR</span></span></span>
<span id="A5.T7.18.2.2.2.2.2.2.2" class="ltx_tr">
<span id="A5.T7.18.2.2.2.2.2.2.2.2" class="ltx_td ltx_align_center"><math id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3" class="ltx_math_unparsed" alttext="\left((\mathbf{IL}),\bm{n.d.},\mathbf{NLE}\right)" display="inline"><semantics id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3a"><mrow id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3b"><mo mathvariant="normal" id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3.4">(</mo><mrow id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3.5"><mo mathvariant="normal" stretchy="false" id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3.5.1">(</mo><mi id="A5.T7.17.1.1.1.1.1.1.1.1.m1.1.1">𝐈𝐋</mi><mo mathvariant="normal" stretchy="false" id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3.5.2">)</mo></mrow><mo mathvariant="normal" id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3.6">,</mo><mi id="A5.T7.17.1.1.1.1.1.1.1.1.m1.2.2">n</mi><mo lspace="0em" mathvariant="bold" rspace="0.167em" id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3.7">.</mo><mi id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3.3">d</mi><mo lspace="0em" mathvariant="bold" rspace="0.167em" id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3.8">.</mo><mo mathvariant="normal" id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3.9">,</mo><mi id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3.10">𝐍𝐋𝐄</mi><mo mathvariant="normal" id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3.11">)</mo></mrow><annotation encoding="application/x-tex" id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3c">\left((\mathbf{IL}),\bm{n.d.},\mathbf{NLE}\right)</annotation><annotation encoding="application/x-llamapun" id="A5.T7.17.1.1.1.1.1.1.1.1.m1.3d">( ( bold_IL ) , bold_italic_n bold_. bold_italic_d bold_. , bold_NLE )</annotation></semantics></math> <math id="A5.T7.18.2.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A5.T7.18.2.2.2.2.2.2.2.2.m2.1a"><mo mathvariant="normal" stretchy="false" id="A5.T7.18.2.2.2.2.2.2.2.2.m2.1.1" xref="A5.T7.18.2.2.2.2.2.2.2.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A5.T7.18.2.2.2.2.2.2.2.2.m2.1b"><ci id="A5.T7.18.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="A5.T7.18.2.2.2.2.2.2.2.2.m2.1.1">normal-↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.18.2.2.2.2.2.2.2.2.m2.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A5.T7.18.2.2.2.2.2.2.2.2.m2.1d">↓</annotation></semantics></math></span></span>
</span></span> <span id="A5.T7.18.2.2.2.3" class="ltx_text"></span></span>
</td>
</tr>
<tr id="A5.T7.18.3" class="ltx_tr">
<td id="A5.T7.18.3.1" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="A5.T7.18.3.2" class="ltx_td ltx_align_center ltx_border_t">EM</td>
</tr>
<tr id="A5.T7.18.4" class="ltx_tr">
<td id="A5.T7.18.4.1" class="ltx_td ltx_align_left ltx_border_t">T5-Initial</td>
<td id="A5.T7.18.4.2" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="A5.T7.18.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T7.18.4.3.1" class="ltx_text ltx_font_bold">24.17</span></td>
<td id="A5.T7.18.4.4" class="ltx_td ltx_align_center ltx_border_t">8.9</td>
<td id="A5.T7.18.4.5" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="A5.T7.18.5" class="ltx_tr">
<td id="A5.T7.18.5.1" class="ltx_td ltx_align_left ltx_border_t">T5-Vanilla</td>
<td id="A5.T7.18.5.2" class="ltx_td ltx_align_center ltx_border_t">1e-05</td>
<td id="A5.T7.18.5.3" class="ltx_td ltx_align_center ltx_border_t">19.15</td>
<td id="A5.T7.18.5.4" class="ltx_td ltx_align_center ltx_border_t">13.56</td>
<td id="A5.T7.18.5.5" class="ltx_td ltx_align_center ltx_border_t">1.08</td>
</tr>
<tr id="A5.T7.18.6" class="ltx_tr">
<td id="A5.T7.18.6.1" class="ltx_td ltx_align_left">T5-Vanilla</td>
<td id="A5.T7.18.6.2" class="ltx_td ltx_align_center">1e-04</td>
<td id="A5.T7.18.6.3" class="ltx_td ltx_align_center">17.45</td>
<td id="A5.T7.18.6.4" class="ltx_td ltx_align_center">15.21</td>
<td id="A5.T7.18.6.5" class="ltx_td ltx_align_center">1.06</td>
</tr>
<tr id="A5.T7.18.7" class="ltx_tr">
<td id="A5.T7.18.7.1" class="ltx_td ltx_align_left">T5-Vanilla</td>
<td id="A5.T7.18.7.2" class="ltx_td ltx_align_center">5e-04</td>
<td id="A5.T7.18.7.3" class="ltx_td ltx_align_center">14.88</td>
<td id="A5.T7.18.7.4" class="ltx_td ltx_align_center">15.89</td>
<td id="A5.T7.18.7.5" class="ltx_td ltx_align_center">1.33</td>
</tr>
<tr id="A5.T7.18.8" class="ltx_tr">
<td id="A5.T7.18.8.1" class="ltx_td ltx_align_left">T5-Vanilla</td>
<td id="A5.T7.18.8.2" class="ltx_td ltx_align_center">1e-03</td>
<td id="A5.T7.18.8.3" class="ltx_td ltx_align_center">11.19</td>
<td id="A5.T7.18.8.4" class="ltx_td ltx_align_center"><span id="A5.T7.18.8.4.1" class="ltx_text ltx_framed_underline">18.77</span></td>
<td id="A5.T7.18.8.5" class="ltx_td ltx_align_center">1.32</td>
</tr>
<tr id="A5.T7.18.9" class="ltx_tr">
<td id="A5.T7.18.9.1" class="ltx_td ltx_align_left ltx_border_t">T5-Kadapters (k=2)</td>
<td id="A5.T7.18.9.2" class="ltx_td ltx_align_center ltx_border_t">1e-04</td>
<td id="A5.T7.18.9.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T7.18.9.3.1" class="ltx_text ltx_framed_underline">19.93</span></td>
<td id="A5.T7.18.9.4" class="ltx_td ltx_align_center ltx_border_t">14.93</td>
<td id="A5.T7.18.9.5" class="ltx_td ltx_align_center ltx_border_t"><span id="A5.T7.18.9.5.1" class="ltx_text ltx_font_bold">0.70</span></td>
</tr>
<tr id="A5.T7.18.10" class="ltx_tr">
<td id="A5.T7.18.10.1" class="ltx_td ltx_align_left ltx_border_bb">T5-Kadapters (k=2)</td>
<td id="A5.T7.18.10.2" class="ltx_td ltx_align_center ltx_border_bb">1e-03</td>
<td id="A5.T7.18.10.3" class="ltx_td ltx_align_center ltx_border_bb">16.46</td>
<td id="A5.T7.18.10.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A5.T7.18.10.4.1" class="ltx_text ltx_font_bold">19.59</span></td>
<td id="A5.T7.18.10.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="A5.T7.18.10.5.1" class="ltx_text ltx_framed_underline">0.72</span></td>
</tr>
</tbody></table>
</figure>
<div id="A5.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A5.p1.1">표 <a class="ltx_ref" href="#A5.T7" title="Table 7 ‣ Appendix E Exploring the Trade-off of Varying the Learning Rate for Continual Pretraining ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">7</span></a>는 지속적인 사전 훈련에 대한 학습률을 낮추면 원지식에 대한 망각이 줄어들 뿐만 아니라 새로운 지식에 대한 학습도 줄어든다는 것을 보여준다. 실험은 <span class="ltx_text ltx_font_smallcaps" id="A5.p1.1.1">Small</span> 시나리오 in Table <a class="ltx_ref" href="#S5.T3" title="Table 3 ‣ 5.2 Exploring Multiple phases of CKL ‣ 5 Experimental Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">3</span></a>에서 수행하였다.</p>
</div>
<div id="A5.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A5.p2.1">학습률이 다른 T5-Vanilla 모델 중 <span class="ltx_text" id="A5.p2.1.1">FUAR</span>을 비교해보면, <span class="ltx_text" id="A5.p2.1.2">FUAR</span>이 1e-4의 학습률이 가장 낮고, 낮은 학습률과 높은 학습률 모두에서 증가하므로 적절한 학습률을 선택하기 위한 경험칙이 없음을 알 수 있다. 우리는 최적의 학습률이 <math alttext="D_{1}" class="ltx_Math" display="inline" id="A5.p2.1.m1.1"><semantics id="A5.p2.1.m1.1a"><msub id="A5.p2.1.m1.1.1" xref="A5.p2.1.m1.1.1.cmml"><mi id="A5.p2.1.m1.1.1.2" xref="A5.p2.1.m1.1.1.2.cmml">D</mi><mn id="A5.p2.1.m1.1.1.3" xref="A5.p2.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A5.p2.1.m1.1b"><apply id="A5.p2.1.m1.1.1.cmml" xref="A5.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A5.p2.1.m1.1.1.1.cmml" xref="A5.p2.1.m1.1.1">subscript</csymbol><ci id="A5.p2.1.m1.1.1.2.cmml" xref="A5.p2.1.m1.1.1.2">𝐷</ci><cn id="A5.p2.1.m1.1.1.3.cmml" type="integer" xref="A5.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.p2.1.m1.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A5.p2.1.m1.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>의 코퍼스 크기와 LM의 모델 용량에 크게 의존한다고 가정한다. 또한 대부분의 실험에서 강건한 성능을 보이는 CKL 방법인 T5-Kadapters의 성능을 보고한다. T5-Kadapters를 적용하면 학습률의 값에 따라 효과 수준이 다르지만 동일한 학습률을 가진 T5-Vanilla 모델에서 <span class="ltx_text" id="A5.p2.1.3">FUAR</span>의 개선에서 볼 수 있듯이 망각과 새로운 지식 획득 사이의 트레이드오프를 일관되게 완화한다. 이 연구에서는 서로 다른 연속 사전 훈련 설정에 대한 최적의 학습률을 검색하는 것이 범위를 벗어날 수 있기 때문에 다양한 학습률 각각에 대해 광범위한 실험을 수행하지 않는다.</p>
</div>
</section>
<section id="A6" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Exploring How Continually Pretraining on <math id="A6.1.m1.1" class="ltx_Math" alttext="D_{1}" display="inline"><semantics id="A6.1.m1.1b"><msub id="A6.1.m1.1.1" xref="A6.1.m1.1.1.cmml"><mi id="A6.1.m1.1.1.2" xref="A6.1.m1.1.1.2.cmml">D</mi><mn id="A6.1.m1.1.1.3" xref="A6.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A6.1.m1.1c"><apply id="A6.1.m1.1.1.cmml" xref="A6.1.m1.1.1"><csymbol cd="ambiguous" id="A6.1.m1.1.1.1.cmml" xref="A6.1.m1.1.1">subscript</csymbol><ci id="A6.1.m1.1.1.2.cmml" xref="A6.1.m1.1.1.2">𝐷</ci><cn type="integer" id="A6.1.m1.1.1.3.cmml" xref="A6.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.1.m1.1d">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A6.1.m1.1e">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> Affects KILT Tasks Which Requires Knowledge from <math id="A6.2.m2.1" class="ltx_Math" alttext="D_{0}" display="inline"><semantics id="A6.2.m2.1b"><msub id="A6.2.m2.1.1" xref="A6.2.m2.1.1.cmml"><mi id="A6.2.m2.1.1.2" xref="A6.2.m2.1.1.2.cmml">D</mi><mn id="A6.2.m2.1.1.3" xref="A6.2.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A6.2.m2.1c"><apply id="A6.2.m2.1.1.cmml" xref="A6.2.m2.1.1"><csymbol cd="ambiguous" id="A6.2.m2.1.1.1.cmml" xref="A6.2.m2.1.1">subscript</csymbol><ci id="A6.2.m2.1.1.2.cmml" xref="A6.2.m2.1.1.2">𝐷</ci><cn type="integer" id="A6.2.m2.1.1.3.cmml" xref="A6.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.2.m2.1d">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A6.2.m2.1e">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>
</h2>

<figure id="A6.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8:</span>Dev performance on KILT benchmark datasets after finetuning. 각 모델은 4 epoch에 대한 <span class="ltx_text ltx_font_smallcaps" id="A6.T8.2.1">CC-RecentNews</span> 데이터 세트에서 지속적으로 훈련된 후 KILT의 트레인 세트에서 미세 조정됩니다.</figcaption>
<table id="A6.T8.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A6.T8.3.1" class="ltx_tr">
<td id="A6.T8.3.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="3">
<span id="A6.T8.3.1.1.1" class="ltx_text"></span><span id="A6.T8.3.1.1.2" class="ltx_text ltx_font_bold"> <span id="A6.T8.3.1.1.2.1" class="ltx_text">
<span id="A6.T8.3.1.1.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="A6.T8.3.1.1.2.1.1.1" class="ltx_tr">
<span id="A6.T8.3.1.1.2.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">Method</span></span>
</span></span> <span id="A6.T8.3.1.1.2.2" class="ltx_text"></span></span>
</td>
<td id="A6.T8.3.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">Fact Checking</td>
<td id="A6.T8.3.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="3">Entity Linking</td>
<td id="A6.T8.3.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="2">Slot-filling</td>
<td id="A6.T8.3.1.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="4">Open Domain QA</td>
<td id="A6.T8.3.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">Dialogue</td>
</tr>
<tr id="A6.T8.3.2" class="ltx_tr">
<td id="A6.T8.3.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.2.1.1" class="ltx_text ltx_font_bold">FEVER</span></td>
<td id="A6.T8.3.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.2.2.1" class="ltx_text ltx_font_bold">AY2</span></td>
<td id="A6.T8.3.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.2.3.1" class="ltx_text ltx_font_bold">WnWi</span></td>
<td id="A6.T8.3.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.2.4.1" class="ltx_text ltx_font_bold">WnCw</span></td>
<td id="A6.T8.3.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.2.5.1" class="ltx_text ltx_font_bold">T-REx</span></td>
<td id="A6.T8.3.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.2.6.1" class="ltx_text ltx_font_bold">zsRE</span></td>
<td id="A6.T8.3.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.2.7.1" class="ltx_text ltx_font_bold">NQ</span></td>
<td id="A6.T8.3.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.2.8.1" class="ltx_text ltx_font_bold">HoPo</span></td>
<td id="A6.T8.3.2.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.2.9.1" class="ltx_text ltx_font_bold">TQA</span></td>
<td id="A6.T8.3.2.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.2.10.1" class="ltx_text ltx_font_bold">ELI5</span></td>
<td id="A6.T8.3.2.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.2.11.1" class="ltx_text ltx_font_bold">WoW</span></td>
</tr>
<tr id="A6.T8.3.3" class="ltx_tr">
<td id="A6.T8.3.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">ACC</td>
<td id="A6.T8.3.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">ACC</td>
<td id="A6.T8.3.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">ACC</td>
<td id="A6.T8.3.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">ACC</td>
<td id="A6.T8.3.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">ACC</td>
<td id="A6.T8.3.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">ACC</td>
<td id="A6.T8.3.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">EM</td>
<td id="A6.T8.3.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">EM</td>
<td id="A6.T8.3.3.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">EM</td>
<td id="A6.T8.3.3.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Rouge</td>
<td id="A6.T8.3.3.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">F1</td>
</tr>
<tr id="A6.T8.3.4" class="ltx_tr">
<td id="A6.T8.3.4.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Initial</td>
<td id="A6.T8.3.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.4.2.1" class="ltx_text ltx_framed_underline">80.39</span></td>
<td id="A6.T8.3.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.4.3.1" class="ltx_text ltx_framed_underline">81.44</span></td>
<td id="A6.T8.3.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.4.4.1" class="ltx_text ltx_font_bold">50.47</span></td>
<td id="A6.T8.3.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.4.5.1" class="ltx_text ltx_font_bold">48.92</span></td>
<td id="A6.T8.3.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">44.64</td>
<td id="A6.T8.3.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.4.7.1" class="ltx_text ltx_font_bold">4.40</span></td>
<td id="A6.T8.3.4.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.4.8.1" class="ltx_text ltx_framed_underline">25.63</span></td>
<td id="A6.T8.3.4.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.4.9.1" class="ltx_text ltx_framed_underline">17.64</span></td>
<td id="A6.T8.3.4.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.4.10.1" class="ltx_text ltx_font_bold">28.38</span></td>
<td id="A6.T8.3.4.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">13.46</td>
<td id="A6.T8.3.4.12" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.4.12.1" class="ltx_text ltx_framed_underline">13.92</span></td>
</tr>
<tr id="A6.T8.3.5" class="ltx_tr">
<td id="A6.T8.3.5.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Vanilla</td>
<td id="A6.T8.3.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">78.02</td>
<td id="A6.T8.3.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">81.19</td>
<td id="A6.T8.3.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">48.17</td>
<td id="A6.T8.3.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">46.46</td>
<td id="A6.T8.3.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">44.08</td>
<td id="A6.T8.3.5.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">2.04</td>
<td id="A6.T8.3.5.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">24.93</td>
<td id="A6.T8.3.5.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">14.36</td>
<td id="A6.T8.3.5.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">26.51</td>
<td id="A6.T8.3.5.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">13.38</td>
<td id="A6.T8.3.5.12" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">13.07</td>
</tr>
<tr id="A6.T8.3.6" class="ltx_tr">
<td id="A6.T8.3.6.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-RecAdam</td>
<td id="A6.T8.3.6.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">77.83</td>
<td id="A6.T8.3.6.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.6.3.1" class="ltx_text ltx_framed_underline">81.44</span></td>
<td id="A6.T8.3.6.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">49.12</td>
<td id="A6.T8.3.6.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">47.01</td>
<td id="A6.T8.3.6.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">43.04</td>
<td id="A6.T8.3.6.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">2.58</td>
<td id="A6.T8.3.6.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">24.65</td>
<td id="A6.T8.3.6.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.86</td>
<td id="A6.T8.3.6.10" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.99</td>
<td id="A6.T8.3.6.11" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.71</td>
<td id="A6.T8.3.6.12" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.69</td>
</tr>
<tr id="A6.T8.3.7" class="ltx_tr">
<td id="A6.T8.3.7.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-MixReview</td>
<td id="A6.T8.3.7.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">77.17</td>
<td id="A6.T8.3.7.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">80.77</td>
<td id="A6.T8.3.7.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.7.4.1" class="ltx_text ltx_framed_underline">49.38</span></td>
<td id="A6.T8.3.7.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">46.22</td>
<td id="A6.T8.3.7.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">44.08</td>
<td id="A6.T8.3.7.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">2.47</td>
<td id="A6.T8.3.7.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.07</td>
<td id="A6.T8.3.7.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.57</td>
<td id="A6.T8.3.7.10" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">26.36</td>
<td id="A6.T8.3.7.11" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.57</td>
<td id="A6.T8.3.7.12" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.73</td>
</tr>
<tr id="A6.T8.3.8" class="ltx_tr">
<td id="A6.T8.3.8.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-LoRA</td>
<td id="A6.T8.3.8.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">79.89</td>
<td id="A6.T8.3.8.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.8.3.1" class="ltx_text ltx_framed_underline">81.44</span></td>
<td id="A6.T8.3.8.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">48.82</td>
<td id="A6.T8.3.8.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.8.5.1" class="ltx_text ltx_framed_underline">47.29</span></td>
<td id="A6.T8.3.8.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.8.6.1" class="ltx_text ltx_framed_underline">45.68</span></td>
<td id="A6.T8.3.8.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">3.01</td>
<td id="A6.T8.3.8.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.49</td>
<td id="A6.T8.3.8.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.71</td>
<td id="A6.T8.3.8.10" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">28.23</td>
<td id="A6.T8.3.8.11" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.42</td>
<td id="A6.T8.3.8.12" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.60</td>
</tr>
<tr id="A6.T8.3.9" class="ltx_tr">
<td id="A6.T8.3.9.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Kadapters (k=2)</td>
<td id="A6.T8.3.9.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">80.35</td>
<td id="A6.T8.3.9.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">80.94</td>
<td id="A6.T8.3.9.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">48.91</td>
<td id="A6.T8.3.9.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">46.65</td>
<td id="A6.T8.3.9.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">45.52</td>
<td id="A6.T8.3.9.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">3.33</td>
<td id="A6.T8.3.9.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.9.8.1" class="ltx_text ltx_font_bold">26.20</span></td>
<td id="A6.T8.3.9.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.57</td>
<td id="A6.T8.3.9.10" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">26.89</td>
<td id="A6.T8.3.9.11" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.15</td>
<td id="A6.T8.3.9.12" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">12.94</td>
</tr>
<tr id="A6.T8.3.10" class="ltx_tr">
<td id="A6.T8.3.10.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Kadapters (k=3)</td>
<td id="A6.T8.3.10.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">80.31</td>
<td id="A6.T8.3.10.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">80.52</td>
<td id="A6.T8.3.10.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">47.09</td>
<td id="A6.T8.3.10.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">46.26</td>
<td id="A6.T8.3.10.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">45.60</td>
<td id="A6.T8.3.10.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">3.12</td>
<td id="A6.T8.3.10.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">24.79</td>
<td id="A6.T8.3.10.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16.57</td>
<td id="A6.T8.3.10.10" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25.62</td>
<td id="A6.T8.3.10.11" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.10.11.1" class="ltx_text ltx_font_bold">13.82</span></td>
<td id="A6.T8.3.10.12" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.42</td>
</tr>
<tr id="A6.T8.3.11" class="ltx_tr">
<td id="A6.T8.3.11.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Modular</td>
<td id="A6.T8.3.11.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.11.2.1" class="ltx_text ltx_font_bold">80.54</span></td>
<td id="A6.T8.3.11.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.11.3.1" class="ltx_text ltx_font_bold">82.44</span></td>
<td id="A6.T8.3.11.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">48.44</td>
<td id="A6.T8.3.11.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">44.81</td>
<td id="A6.T8.3.11.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.11.6.1" class="ltx_text ltx_font_bold">48.16</span></td>
<td id="A6.T8.3.11.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.11.7.1" class="ltx_text ltx_framed_underline">3.44</span></td>
<td id="A6.T8.3.11.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">24.51</td>
<td id="A6.T8.3.11.9" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.11.9.1" class="ltx_text ltx_font_bold">18.43</span></td>
<td id="A6.T8.3.11.10" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.11.10.1" class="ltx_text ltx_framed_underline">28.31</span></td>
<td id="A6.T8.3.11.11" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.11.11.1" class="ltx_text ltx_framed_underline">13.72</span></td>
<td id="A6.T8.3.11.12" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T8.3.11.12.1" class="ltx_text ltx_font_bold">14.03</span></td>
</tr>
</tbody></table>
</figure>
<figure id="A6.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 9:</span>Hyperparameters and dataset details for all tasks for KILT.</figcaption>
<table id="A6.T9.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A6.T9.1.1" class="ltx_tr">
<td id="A6.T9.1.1.1" class="ltx_td ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="A6.T9.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">Fact Checking</td>
<td id="A6.T9.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="3">Entity Linking</td>
<td id="A6.T9.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="2">Slot-filling</td>
<td id="A6.T9.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" colspan="4">Open Domain QA</td>
<td id="A6.T9.1.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">Dialogue</td>
</tr>
<tr id="A6.T9.1.2" class="ltx_tr">
<td id="A6.T9.1.2.1" class="ltx_td" style="padding-left:3.0pt;padding-right:3.0pt;"></td>
<td id="A6.T9.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A6.T9.1.2.2.1" class="ltx_text ltx_font_bold">FEV</span></td>
<td id="A6.T9.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T9.1.2.3.1" class="ltx_text ltx_font_bold">AY2</span></td>
<td id="A6.T9.1.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T9.1.2.4.1" class="ltx_text ltx_font_bold">WnWi</span></td>
<td id="A6.T9.1.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A6.T9.1.2.5.1" class="ltx_text ltx_font_bold">WnCw</span></td>
<td id="A6.T9.1.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T9.1.2.6.1" class="ltx_text ltx_font_bold">T-REx</span></td>
<td id="A6.T9.1.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A6.T9.1.2.7.1" class="ltx_text ltx_font_bold">zsRE</span></td>
<td id="A6.T9.1.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T9.1.2.8.1" class="ltx_text ltx_font_bold">NQ</span></td>
<td id="A6.T9.1.2.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T9.1.2.9.1" class="ltx_text ltx_font_bold">HoPo</span></td>
<td id="A6.T9.1.2.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T9.1.2.10.1" class="ltx_text ltx_font_bold">TQA</span></td>
<td id="A6.T9.1.2.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A6.T9.1.2.11.1" class="ltx_text ltx_font_bold">ELI5</span></td>
<td id="A6.T9.1.2.12" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A6.T9.1.2.12.1" class="ltx_text ltx_font_bold">WoW</span></td>
</tr>
<tr id="A6.T9.1.3" class="ltx_tr">
<td id="A6.T9.1.3.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">Epoch</td>
<td id="A6.T9.1.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">5</td>
<td id="A6.T9.1.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">20</td>
<td id="A6.T9.1.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">-</td>
<td id="A6.T9.1.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">-</td>
<td id="A6.T9.1.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">9</td>
<td id="A6.T9.1.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">30</td>
<td id="A6.T9.1.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">45</td>
<td id="A6.T9.1.3.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">12</td>
<td id="A6.T9.1.3.10" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">50</td>
<td id="A6.T9.1.3.11" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">6</td>
<td id="A6.T9.1.3.12" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">8</td>
</tr>
<tr id="A6.T9.1.4" class="ltx_tr">
<td id="A6.T9.1.4.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">Input Seq</td>
<td id="A6.T9.1.4.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25</td>
<td id="A6.T9.1.4.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">768</td>
<td id="A6.T9.1.4.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">512</td>
<td id="A6.T9.1.4.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">2,048</td>
<td id="A6.T9.1.4.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25</td>
<td id="A6.T9.1.4.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25</td>
<td id="A6.T9.1.4.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">35</td>
<td id="A6.T9.1.4.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">50</td>
<td id="A6.T9.1.4.10" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">25</td>
<td id="A6.T9.1.4.11" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">35</td>
<td id="A6.T9.1.4.12" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">175</td>
</tr>
<tr id="A6.T9.1.5" class="ltx_tr">
<td id="A6.T9.1.5.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">Output Seq</td>
<td id="A6.T9.1.5.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">10</td>
<td id="A6.T9.1.5.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">6</td>
<td id="A6.T9.1.5.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">6</td>
<td id="A6.T9.1.5.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">6</td>
<td id="A6.T9.1.5.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">6</td>
<td id="A6.T9.1.5.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">6</td>
<td id="A6.T9.1.5.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">6</td>
<td id="A6.T9.1.5.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">8</td>
<td id="A6.T9.1.5.10" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">10</td>
<td id="A6.T9.1.5.11" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">350</td>
<td id="A6.T9.1.5.12" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">40</td>
</tr>
<tr id="A6.T9.1.6" class="ltx_tr">
<td id="A6.T9.1.6.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">LR</td>
<td id="A6.T9.1.6.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1e-4</td>
<td id="A6.T9.1.6.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1e-4</td>
<td id="A6.T9.1.6.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">-</td>
<td id="A6.T9.1.6.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">-</td>
<td id="A6.T9.1.6.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1e-3</td>
<td id="A6.T9.1.6.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1e-4</td>
<td id="A6.T9.1.6.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1e-3</td>
<td id="A6.T9.1.6.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1e-4</td>
<td id="A6.T9.1.6.10" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1e-3</td>
<td id="A6.T9.1.6.11" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1e-3</td>
<td id="A6.T9.1.6.12" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1e-4</td>
</tr>
<tr id="A6.T9.1.7" class="ltx_tr">
<td id="A6.T9.1.7.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">Batch Size</td>
<td id="A6.T9.1.7.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">128</td>
<td id="A6.T9.1.7.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">16</td>
<td id="A6.T9.1.7.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">128</td>
<td id="A6.T9.1.7.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">48</td>
<td id="A6.T9.1.7.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">512</td>
<td id="A6.T9.1.7.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">256</td>
<td id="A6.T9.1.7.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">256</td>
<td id="A6.T9.1.7.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">256</td>
<td id="A6.T9.1.7.10" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">128</td>
<td id="A6.T9.1.7.11" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">32</td>
<td id="A6.T9.1.7.12" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">64</td>
</tr>
<tr id="A6.T9.1.8" class="ltx_tr">
<td id="A6.T9.1.8.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">Train Size</td>
<td id="A6.T9.1.8.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">104,966</td>
<td id="A6.T9.1.8.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">18,395</td>
<td id="A6.T9.1.8.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">-</td>
<td id="A6.T9.1.8.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">-</td>
<td id="A6.T9.1.8.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">2,284,168</td>
<td id="A6.T9.1.8.7" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">147,909</td>
<td id="A6.T9.1.8.8" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">87,372</td>
<td id="A6.T9.1.8.9" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">88,869</td>
<td id="A6.T9.1.8.10" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">61,844</td>
<td id="A6.T9.1.8.11" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">272,634</td>
<td id="A6.T9.1.8.12" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">63,734</td>
</tr>
<tr id="A6.T9.1.9" class="ltx_tr">
<td id="A6.T9.1.9.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">Dev Size</td>
<td id="A6.T9.1.9.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">10,444</td>
<td id="A6.T9.1.9.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">4,784</td>
<td id="A6.T9.1.9.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">3,396</td>
<td id="A6.T9.1.9.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">5,599</td>
<td id="A6.T9.1.9.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">5,000</td>
<td id="A6.T9.1.9.7" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">3,724</td>
<td id="A6.T9.1.9.8" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">2,837</td>
<td id="A6.T9.1.9.9" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">5,600</td>
<td id="A6.T9.1.9.10" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">5,359</td>
<td id="A6.T9.1.9.11" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">1,507</td>
<td id="A6.T9.1.9.12" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">3,054</td>
</tr>
</tbody></table>
</figure>
<div id="A6.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A6.p1.4">CKL 벤치마크 외에도 표 <a class="ltx_ref" href="#A6.T8" title="Table 8 ‣ Appendix F Exploring How Continually Pretraining on 𝐷₁ Affects KILT Tasks Which Requires Knowledge from 𝐷₀ ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">8</span></a>에서 표 <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.1 Main Results ‣ 5 Experimental Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>의 연속 사전 훈련된 모델 각각을 미세 조정한 후 KILT <cite class="ltx_cite ltx_citemacro_citep">(Petroni et al., <a class="ltx_ref" href="#bib.bib38" title="">2021</a>)</cite>의 dev 집합에 대한 성능도 보여준다. KILT는 이전의 프리트레이닝 코퍼스 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A6.p1.1.m1.1"><semantics id="A6.p1.1.m1.1a"><msub id="A6.p1.1.m1.1.1" xref="A6.p1.1.m1.1.1.cmml"><mi id="A6.p1.1.m1.1.1.2" xref="A6.p1.1.m1.1.1.2.cmml">D</mi><mn id="A6.p1.1.m1.1.1.3" xref="A6.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A6.p1.1.m1.1b"><apply id="A6.p1.1.m1.1.1.cmml" xref="A6.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A6.p1.1.m1.1.1.1.cmml" xref="A6.p1.1.m1.1.1">subscript</csymbol><ci id="A6.p1.1.m1.1.1.2.cmml" xref="A6.p1.1.m1.1.1.2">𝐷</ci><cn id="A6.p1.1.m1.1.1.3.cmml" type="integer" xref="A6.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.1.m1.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A6.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>에 해당하는 위키피디아로부터 만들어지기 때문에, KILT에 대한 성능은 새로운 코퍼스 <math alttext="D_{1}" class="ltx_Math" display="inline" id="A6.p1.2.m2.1"><semantics id="A6.p1.2.m2.1a"><msub id="A6.p1.2.m2.1.1" xref="A6.p1.2.m2.1.1.cmml"><mi id="A6.p1.2.m2.1.1.2" xref="A6.p1.2.m2.1.1.2.cmml">D</mi><mn id="A6.p1.2.m2.1.1.3" xref="A6.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A6.p1.2.m2.1b"><apply id="A6.p1.2.m2.1.1.cmml" xref="A6.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A6.p1.2.m2.1.1.1.cmml" xref="A6.p1.2.m2.1.1">subscript</csymbol><ci id="A6.p1.2.m2.1.1.2.cmml" xref="A6.p1.2.m2.1.1.2">𝐷</ci><cn id="A6.p1.2.m2.1.1.3.cmml" type="integer" xref="A6.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.2.m2.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A6.p1.2.m2.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>에 대한 지속적인 프리트레이닝이 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A6.p1.4.m4.1"><semantics id="A6.p1.4.m4.1a"><msub id="A6.p1.4.m4.1.1" xref="A6.p1.4.m4.1.1.cmml"><mi id="A6.p1.4.m4.1.1.2" xref="A6.p1.4.m4.1.1.2.cmml">D</mi><mn id="A6.p1.4.m4.1.1.3" xref="A6.p1.4.m4.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A6.p1.4.m4.1b"><apply id="A6.p1.4.m4.1.1.cmml" xref="A6.p1.4.m4.1.1"><csymbol cd="ambiguous" id="A6.p1.4.m4.1.1.1.cmml" xref="A6.p1.4.m4.1.1">subscript</csymbol><ci id="A6.p1.4.m4.1.1.2.cmml" xref="A6.p1.4.m4.1.1.2">𝐷</ci><cn id="A6.p1.4.m4.1.1.3.cmml" type="integer" xref="A6.p1.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.4.m4.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A6.p1.4.m4.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>의 지식을 대신하여 파인튜닝이 이루어진다면 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A6.p1.3.m3.1"><semantics id="A6.p1.3.m3.1a"><msub id="A6.p1.3.m3.1.1" xref="A6.p1.3.m3.1.1.cmml"><mi id="A6.p1.3.m3.1.1.2" xref="A6.p1.3.m3.1.1.2.cmml">D</mi><mn id="A6.p1.3.m3.1.1.3" xref="A6.p1.3.m3.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A6.p1.3.m3.1b"><apply id="A6.p1.3.m3.1.1.cmml" xref="A6.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A6.p1.3.m3.1.1.1.cmml" xref="A6.p1.3.m3.1.1">subscript</csymbol><ci id="A6.p1.3.m3.1.1.2.cmml" xref="A6.p1.3.m3.1.1.2">𝐷</ci><cn id="A6.p1.3.m3.1.1.3.cmml" type="integer" xref="A6.p1.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.3.m3.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A6.p1.3.m3.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>로부터 얻은 지식에 대한 성능에 어떤 영향을 미치는지 측정한다.</p>
</div>
<section id="A6.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Configuration</h5>

<div id="A6.SS0.SSS0.Px1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A6.SS0.SSS0.Px1.p1.1">KILT <cite class="ltx_cite ltx_citemacro_citep">(Petroni et al., <a class="ltx_ref" href="#bib.bib38" title="">2021</a>)</cite>는 5개의 서로 다른 태스크와 11개의 데이터셋으로 구성되어 있다: Open-Domain Question Answering <cite class="ltx_cite ltx_citemacro_citep">(Joshi et al., <a class="ltx_ref" href="#bib.bib21" title="">2017</a>; Kwiatkowski et al., <a class="ltx_ref" href="#bib.bib24" title="">2019</a>; Fan et al., <a class="ltx_ref" href="#bib.bib12" title="">2019</a>; Yang et al., <a class="ltx_ref" href="#bib.bib55" title="">2018</a>)</cite>, Fact Checking <cite class="ltx_cite ltx_citemacro_citep">(Thorne et al., <a class="ltx_ref" href="#bib.bib47" title="">2018</a>)</cite>, Entity Linking <cite class="ltx_cite ltx_citemacro_citep">(Hoffart et al., <a class="ltx_ref" href="#bib.bib18" title="">2011</a>; Guo &amp; Barbosa, <a class="ltx_ref" href="#bib.bib13" title="">2018</a>)</cite>, Slot-filling <cite class="ltx_cite ltx_citemacro_citep">(Levy et al., <a class="ltx_ref" href="#bib.bib27" title="">2017</a>)</cite>, Knowledgeable Open Dialogue <cite class="ltx_cite ltx_citemacro_citep">(Dinan et al., <a class="ltx_ref" href="#bib.bib10" title="">2019</a>)</cite>. 각 작업에는 사전 훈련 시 사용되는 것과 다른 훈련 목표가 필요하기 때문에 추가 미세 조정이 필요하다. <cite class="ltx_cite ltx_citemacro_citet">Petroni et al. (<a class="ltx_ref" href="#bib.bib38" title="">2021</a>)</cite>에 의해 보고된 T5-base dev 성능과 일치하도록 각 개별 KILT 태스크의 훈련 epoch, 배치 크기, 입력 크기, 출력 크기 및 학습 속도와 같은 하이퍼파라미터를 검색한다. 확인된 구성들을 이용하여, 각 방법에 대해 연속적으로 미리 학습된 모델들을 초기화 체크포인트로 하여 모든 KILT 태스크들에 대한 실험을 수행한다. 평가 메트릭은 개별 출력에 대한 정확도(팩트 검사, 엔터티 연결, 슬롯 채우기), 짧은 출력을 가진 질문 응답 작업에 대한 정확한 일치(EM), ELI5에 대한 ROUGE-L(긴 출력을 가진 질문 응답 작업), 위키피디아의 마법사에 대한 F1 점수(대화)와 같다. 각 KILT 데이터 세트의 미세 조정에 사용된 데이터 통계 및 하이퍼파라미터는 표 <a class="ltx_ref" href="#A6.T9" title="Table 9 ‣ Appendix F Exploring How Continually Pretraining on 𝐷₁ Affects KILT Tasks Which Requires Knowledge from 𝐷₀ ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">9</span></a>에 보고되어 있다.</p>
</div>
</section>
<section id="A6.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Experimental Result</h5>

<div id="A6.SS0.SSS0.Px2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A6.SS0.SSS0.Px2.p1.1">먼저 열차 집합 <cite class="ltx_cite ltx_citemacro_citep">(Levy et al., <a class="ltx_ref" href="#bib.bib27" title="">2017</a>)</cite>의 84개 관계식과 중복되지 않도록 보장된 12개 관계식의 dev 집합에서 측정된 제로샷 관계 추출(zsRE)에 대한 성능에 초점을 맞춘다. 설정이 IL의 제로 샷 프로빙 설정과 유사하기 때문에 두 데이터 세트에 대한 결과의 경향은 유사하다. T5-바닐라의 성능은 IL에서 볼 수 있듯이 T5-Initial의 성능에서 절반으로 떨어지며 두 데이터 세트에 대해 가장 잘 수행되는 방법은 T5-Modular이다. 또한, CKL 벤치마크 결과와 일치하는 파라미터 확장 방법은 일반적으로 다른 방법보다 더 강한 성능을 보인다.</p>
</div>
<div id="A6.SS0.SSS0.Px2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A6.SS0.SSS0.Px2.p2.3">그러나 제로샷 방식으로 수행될 수 없는 다른 데이터세트의 경우, <math alttext="D_{1}" class="ltx_Math" display="inline" id="A6.SS0.SSS0.Px2.p2.1.m1.1"><semantics id="A6.SS0.SSS0.Px2.p2.1.m1.1a"><msub id="A6.SS0.SSS0.Px2.p2.1.m1.1.1" xref="A6.SS0.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="A6.SS0.SSS0.Px2.p2.1.m1.1.1.2" xref="A6.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml">D</mi><mn id="A6.SS0.SSS0.Px2.p2.1.m1.1.1.3" xref="A6.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A6.SS0.SSS0.Px2.p2.1.m1.1b"><apply id="A6.SS0.SSS0.Px2.p2.1.m1.1.1.cmml" xref="A6.SS0.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A6.SS0.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="A6.SS0.SSS0.Px2.p2.1.m1.1.1">subscript</csymbol><ci id="A6.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="A6.SS0.SSS0.Px2.p2.1.m1.1.1.2">𝐷</ci><cn id="A6.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml" type="integer" xref="A6.SS0.SSS0.Px2.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS0.SSS0.Px2.p2.1.m1.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A6.SS0.SSS0.Px2.p2.1.m1.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> 코퍼스에 대한 지속적인 사전 훈련의 중간 과정은 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A6.SS0.SSS0.Px2.p2.2.m2.1"><semantics id="A6.SS0.SSS0.Px2.p2.2.m2.1a"><msub id="A6.SS0.SSS0.Px2.p2.2.m2.1.1" xref="A6.SS0.SSS0.Px2.p2.2.m2.1.1.cmml"><mi id="A6.SS0.SSS0.Px2.p2.2.m2.1.1.2" xref="A6.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml">D</mi><mn id="A6.SS0.SSS0.Px2.p2.2.m2.1.1.3" xref="A6.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A6.SS0.SSS0.Px2.p2.2.m2.1b"><apply id="A6.SS0.SSS0.Px2.p2.2.m2.1.1.cmml" xref="A6.SS0.SSS0.Px2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="A6.SS0.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="A6.SS0.SSS0.Px2.p2.2.m2.1.1">subscript</csymbol><ci id="A6.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="A6.SS0.SSS0.Px2.p2.2.m2.1.1.2">𝐷</ci><cn id="A6.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml" type="integer" xref="A6.SS0.SSS0.Px2.p2.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS0.SSS0.Px2.p2.2.m2.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A6.SS0.SSS0.Px2.p2.2.m2.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>의 지식과 더 관련이 있음에도 불구하고 타겟 태스크에 대한 미세 조정에 그다지 해롭지 않은 것으로 보인다. 심지어 T5-바닐라조차도 적당한 성능을 보이며, 때로는 다른 CKL 기준선보다 더 나은 결과를 보인다. 한 가지 가설은 모델들이 미세 조정 과정을 통해 말뭉치 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A6.SS0.SSS0.Px2.p2.3.m3.1"><semantics id="A6.SS0.SSS0.Px2.p2.3.m3.1a"><msub id="A6.SS0.SSS0.Px2.p2.3.m3.1.1" xref="A6.SS0.SSS0.Px2.p2.3.m3.1.1.cmml"><mi id="A6.SS0.SSS0.Px2.p2.3.m3.1.1.2" xref="A6.SS0.SSS0.Px2.p2.3.m3.1.1.2.cmml">D</mi><mn id="A6.SS0.SSS0.Px2.p2.3.m3.1.1.3" xref="A6.SS0.SSS0.Px2.p2.3.m3.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A6.SS0.SSS0.Px2.p2.3.m3.1b"><apply id="A6.SS0.SSS0.Px2.p2.3.m3.1.1.cmml" xref="A6.SS0.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="A6.SS0.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="A6.SS0.SSS0.Px2.p2.3.m3.1.1">subscript</csymbol><ci id="A6.SS0.SSS0.Px2.p2.3.m3.1.1.2.cmml" xref="A6.SS0.SSS0.Px2.p2.3.m3.1.1.2">𝐷</ci><cn id="A6.SS0.SSS0.Px2.p2.3.m3.1.1.3.cmml" type="integer" xref="A6.SS0.SSS0.Px2.p2.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS0.SSS0.Px2.p2.3.m3.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A6.SS0.SSS0.Px2.p2.3.m3.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>로부터 원래의 지식을 되찾을 수 있었다는 것이다. 또한 테스트-트레인 오버랩 <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="#bib.bib29" title="">2020b</a>; Wang et al., <a class="ltx_ref" href="#bib.bib51" title="">2021a</a>)</cite>를 통해 일부 지식을 복구할 수 있었다.</p>
</div>
<div id="A6.SS0.SSS0.Px2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A6.SS0.SSS0.Px2.p3.1">더 놀라운 발견은 일부 매개변수 확장 방법의 성능이 T5-Initial의 성능보다 훨씬 높다는 것인데, 이는 T5-Initial이 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A6.SS0.SSS0.Px2.p3.1.m1.1"><semantics id="A6.SS0.SSS0.Px2.p3.1.m1.1a"><msub id="A6.SS0.SSS0.Px2.p3.1.m1.1.1" xref="A6.SS0.SSS0.Px2.p3.1.m1.1.1.cmml"><mi id="A6.SS0.SSS0.Px2.p3.1.m1.1.1.2" xref="A6.SS0.SSS0.Px2.p3.1.m1.1.1.2.cmml">D</mi><mn id="A6.SS0.SSS0.Px2.p3.1.m1.1.1.3" xref="A6.SS0.SSS0.Px2.p3.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A6.SS0.SSS0.Px2.p3.1.m1.1b"><apply id="A6.SS0.SSS0.Px2.p3.1.m1.1.1.cmml" xref="A6.SS0.SSS0.Px2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="A6.SS0.SSS0.Px2.p3.1.m1.1.1.1.cmml" xref="A6.SS0.SSS0.Px2.p3.1.m1.1.1">subscript</csymbol><ci id="A6.SS0.SSS0.Px2.p3.1.m1.1.1.2.cmml" xref="A6.SS0.SSS0.Px2.p3.1.m1.1.1.2">𝐷</ci><cn id="A6.SS0.SSS0.Px2.p3.1.m1.1.1.3.cmml" type="integer" xref="A6.SS0.SSS0.Px2.p3.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS0.SSS0.Px2.p3.1.m1.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A6.SS0.SSS0.Px2.p3.1.m1.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>의 지식을 대신하여만 훈련되기 때문에 KILT의 상한으로 간주된다. 예를 들어, T5-Modular는 11개 과제 중 6개 과제에서 T5-Initial보다 높은 점수를 보인다. 매개변수 확장 방법은 연속 사전 훈련 동안 모델이 새로 추가된 매개변수에 새로운 지식을 저장하도록 강제하기 때문에 한 가지 주의 깊은 추측은 이러한 LMs가 성능을 최대화하기 위해 미세 조정 동안 별도의 매개변수에 저장된 오래된 지식과 새로운 지식의 내부 표현을 결합하고 활용하는 것을 학습했다는 것이다.</p>
</div>
</section>
</section>
<section id="A7" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Exploring How CKL Methods Transfer Across LM Architectures</h2>

<div id="A7.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A7.p1.3">GPT-2 Large (<span class="ltx_text" id="A7.p1.1.1" style="position:relative; bottom:0.7pt;"><math alttext="\scriptstyle\sim" class="ltx_Math" display="inline" id="A7.p1.1.1.1.m1.1"><semantics id="A7.p1.1.1.1.m1.1a"><mo id="A7.p1.1.1.1.m1.1.1" mathsize="70%" xref="A7.p1.1.1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="A7.p1.1.1.1.m1.1b"><csymbol cd="latexml" id="A7.p1.1.1.1.m1.1.1.cmml" xref="A7.p1.1.1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A7.p1.1.1.1.m1.1c">\scriptstyle\sim</annotation><annotation encoding="application/x-llamapun" id="A7.p1.1.1.1.m1.1d">∼</annotation></semantics></math></span>774M params)  <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="#bib.bib41" title="">2019</a>)</cite> initially pretrained on WebText and Wikipedia<span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span>GPT-2 was initially pretrained on WebText (Dec 2019), which consists of 8 million documents with Wikipedia pages excluded. In order to measure the performance on <span class="ltx_text ltx_font_smallcaps" id="footnote14.1">InvariantLAMA</span> constructed from Wikipedia, we continually pretrain GPT-2 on a subset of Wikipedia (May 2020) for 14k global training steps before CKL.</span></span></span> (<math alttext="D_{0}" class="ltx_Math" display="inline" id="A7.p1.2.m1.1"><semantics id="A7.p1.2.m1.1a"><msub id="A7.p1.2.m1.1.1" xref="A7.p1.2.m1.1.1.cmml"><mi id="A7.p1.2.m1.1.1.2" xref="A7.p1.2.m1.1.1.2.cmml">D</mi><mn id="A7.p1.2.m1.1.1.3" xref="A7.p1.2.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A7.p1.2.m1.1b"><apply id="A7.p1.2.m1.1.1.cmml" xref="A7.p1.2.m1.1.1"><csymbol cd="ambiguous" id="A7.p1.2.m1.1.1.1.cmml" xref="A7.p1.2.m1.1.1">subscript</csymbol><ci id="A7.p1.2.m1.1.1.2.cmml" xref="A7.p1.2.m1.1.1.2">𝐷</ci><cn id="A7.p1.2.m1.1.1.3.cmml" type="integer" xref="A7.p1.2.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.p1.2.m1.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A7.p1.2.m1.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>) and continuously trained on <span class="ltx_text ltx_font_smallcaps" id="A7.p1.3.2">CC-RecentNews-Small</span>, 즉 <span class="ltx_text ltx_font_smallcaps" id="A7.p1.3.3">Small</span> (<math alttext="D_{1}" class="ltx_Math" display="inline" id="A7.p1.3.m2.1"><semantics id="A7.p1.3.m2.1a"><msub id="A7.p1.3.m2.1.1" xref="A7.p1.3.m2.1.1.cmml"><mi id="A7.p1.3.m2.1.1.2" xref="A7.p1.3.m2.1.1.2.cmml">D</mi><mn id="A7.p1.3.m2.1.1.3" xref="A7.p1.3.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A7.p1.3.m2.1b"><apply id="A7.p1.3.m2.1.1.cmml" xref="A7.p1.3.m2.1.1"><csymbol cd="ambiguous" id="A7.p1.3.m2.1.1.1.cmml" xref="A7.p1.3.m2.1.1">subscript</csymbol><ci id="A7.p1.3.m2.1.1.2.cmml" xref="A7.p1.3.m2.1.1.2">𝐷</ci><cn id="A7.p1.3.m2.1.1.3.cmml" type="integer" xref="A7.p1.3.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.p1.3.m2.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A7.p1.3.m2.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>) for 8 epoch. 지속적인 사전 훈련을 위해, 우리는 공통의 교사 강제 사전 훈련 목표를 사용한다. 계속된 사전 훈련 단계에 대한 초기 학습률은 경험적으로 1e-4로 선택된다(1e-3으로 학습률을 갖는 결과는 부록 <a class="ltx_ref" href="#A7.SS1" title="G.1 Failed GPT-2 experiments with Larger Learning Rate ‣ Appendix G Exploring How CKL Methods Transfer Across LM Architectures ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">G.1</span></a>에 나타나 있다). 계속된 사전 훈련 후, 평가 세트와 유사한 데이터의 작은 부분에서 단 하나의 에폭에 대해 모델을 미세 조정하기 위해 표시된 프로세스인 <span class="ltx_text ltx_font_italic" id="A7.p1.3.4">light-tuning</span>을 적용한다. 단일 에포크에 대한 훈련은 모델이 데이터의 입력-출력 형태에 거의 적응하지 않고 샘플 튜닝에 대한 지식을 학습하지 않도록 제한하여 <cite class="ltx_cite ltx_citemacro_citet">Lewis et al. (<a class="ltx_ref" href="#bib.bib29" title="">2020b</a>)</cite>에서 제안한 문제를 완화한다.</p>
</div>
<figure id="A7.T10" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 10: </span>Performance of decoder-only models initially prerained on Dec 2019 dump of Webtext and May 2020 dump of Wikipedia (<math alttext="D_{0}" class="ltx_Math" display="inline" id="A7.T10.9.m1.1"><semantics id="A7.T10.9.m1.1b"><msub id="A7.T10.9.m1.1.1" xref="A7.T10.9.m1.1.1.cmml"><mi id="A7.T10.9.m1.1.1.2" xref="A7.T10.9.m1.1.1.2.cmml">D</mi><mn id="A7.T10.9.m1.1.1.3" xref="A7.T10.9.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A7.T10.9.m1.1c"><apply id="A7.T10.9.m1.1.1.cmml" xref="A7.T10.9.m1.1.1"><csymbol cd="ambiguous" id="A7.T10.9.m1.1.1.1.cmml" xref="A7.T10.9.m1.1.1">subscript</csymbol><ci id="A7.T10.9.m1.1.1.2.cmml" xref="A7.T10.9.m1.1.1.2">𝐷</ci><cn id="A7.T10.9.m1.1.1.3.cmml" type="integer" xref="A7.T10.9.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T10.9.m1.1d">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A7.T10.9.m1.1e">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>) continually prerained on <span class="ltx_text ltx_font_smallcaps" id="A7.T10.23.1">CC-RecentNews-Small</span> (<math alttext="D_{1}" class="ltx_Math" display="inline" id="A7.T10.10.m2.1"><semantics id="A7.T10.10.m2.1b"><msub id="A7.T10.10.m2.1.1" xref="A7.T10.10.m2.1.1.cmml"><mi id="A7.T10.10.m2.1.1.2" xref="A7.T10.10.m2.1.1.2.cmml">D</mi><mn id="A7.T10.10.m2.1.1.3" xref="A7.T10.10.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A7.T10.10.m2.1c"><apply id="A7.T10.10.m2.1.1.cmml" xref="A7.T10.10.m2.1.1"><csymbol cd="ambiguous" id="A7.T10.10.m2.1.1.1.cmml" xref="A7.T10.10.m2.1.1">subscript</csymbol><ci id="A7.T10.10.m2.1.1.2.cmml" xref="A7.T10.10.m2.1.1.2">𝐷</ci><cn id="A7.T10.10.m2.1.1.3.cmml" type="integer" xref="A7.T10.10.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T10.10.m2.1d">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A7.T10.10.m2.1e">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>) for 8 epochs with 1e-4. Each IL and NQE는 각각 <span class="ltx_text ltx_font_smallcaps" id="A7.T10.24.2">InvariantLAMA</span> and <span class="ltx_text ltx_font_smallcaps" id="A7.T10.25.3">NewQuestions-Easy</span>을 의미한다. <span class="ltx_text" id="A7.T10.26.4">FUAR</span>의 파라미터는 각각 <math alttext="\mathbb{T}^{F}" class="ltx_Math" display="inline" id="A7.T10.11.m3.1"><semantics id="A7.T10.11.m3.1b"><msup id="A7.T10.11.m3.1.1" xref="A7.T10.11.m3.1.1.cmml"><mi id="A7.T10.11.m3.1.1.2" xref="A7.T10.11.m3.1.1.2.cmml">𝕋</mi><mi id="A7.T10.11.m3.1.1.3" xref="A7.T10.11.m3.1.1.3.cmml">F</mi></msup><annotation-xml encoding="MathML-Content" id="A7.T10.11.m3.1c"><apply id="A7.T10.11.m3.1.1.cmml" xref="A7.T10.11.m3.1.1"><csymbol cd="ambiguous" id="A7.T10.11.m3.1.1.1.cmml" xref="A7.T10.11.m3.1.1">superscript</csymbol><ci id="A7.T10.11.m3.1.1.2.cmml" xref="A7.T10.11.m3.1.1.2">𝕋</ci><ci id="A7.T10.11.m3.1.1.3.cmml" xref="A7.T10.11.m3.1.1.3">𝐹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T10.11.m3.1d">\mathbb{T}^{F}</annotation><annotation encoding="application/x-llamapun" id="A7.T10.11.m3.1e">blackboard_T start_POSTSUPERSCRIPT italic_F end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="T_{1}^{U}" class="ltx_Math" display="inline" id="A7.T10.12.m4.1"><semantics id="A7.T10.12.m4.1b"><msubsup id="A7.T10.12.m4.1.1" xref="A7.T10.12.m4.1.1.cmml"><mi id="A7.T10.12.m4.1.1.2.2" xref="A7.T10.12.m4.1.1.2.2.cmml">T</mi><mn id="A7.T10.12.m4.1.1.2.3" xref="A7.T10.12.m4.1.1.2.3.cmml">1</mn><mi id="A7.T10.12.m4.1.1.3" xref="A7.T10.12.m4.1.1.3.cmml">U</mi></msubsup><annotation-xml encoding="MathML-Content" id="A7.T10.12.m4.1c"><apply id="A7.T10.12.m4.1.1.cmml" xref="A7.T10.12.m4.1.1"><csymbol cd="ambiguous" id="A7.T10.12.m4.1.1.1.cmml" xref="A7.T10.12.m4.1.1">superscript</csymbol><apply id="A7.T10.12.m4.1.1.2.cmml" xref="A7.T10.12.m4.1.1"><csymbol cd="ambiguous" id="A7.T10.12.m4.1.1.2.1.cmml" xref="A7.T10.12.m4.1.1">subscript</csymbol><ci id="A7.T10.12.m4.1.1.2.2.cmml" xref="A7.T10.12.m4.1.1.2.2">𝑇</ci><cn id="A7.T10.12.m4.1.1.2.3.cmml" type="integer" xref="A7.T10.12.m4.1.1.2.3">1</cn></apply><ci id="A7.T10.12.m4.1.1.3.cmml" xref="A7.T10.12.m4.1.1.3">𝑈</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T10.12.m4.1d">T_{1}^{U}</annotation><annotation encoding="application/x-llamapun" id="A7.T10.12.m4.1e">italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_U end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="T_{1}^{A}" class="ltx_Math" display="inline" id="A7.T10.13.m5.1"><semantics id="A7.T10.13.m5.1b"><msubsup id="A7.T10.13.m5.1.1" xref="A7.T10.13.m5.1.1.cmml"><mi id="A7.T10.13.m5.1.1.2.2" xref="A7.T10.13.m5.1.1.2.2.cmml">T</mi><mn id="A7.T10.13.m5.1.1.2.3" xref="A7.T10.13.m5.1.1.2.3.cmml">1</mn><mi id="A7.T10.13.m5.1.1.3" xref="A7.T10.13.m5.1.1.3.cmml">A</mi></msubsup><annotation-xml encoding="MathML-Content" id="A7.T10.13.m5.1c"><apply id="A7.T10.13.m5.1.1.cmml" xref="A7.T10.13.m5.1.1"><csymbol cd="ambiguous" id="A7.T10.13.m5.1.1.1.cmml" xref="A7.T10.13.m5.1.1">superscript</csymbol><apply id="A7.T10.13.m5.1.1.2.cmml" xref="A7.T10.13.m5.1.1"><csymbol cd="ambiguous" id="A7.T10.13.m5.1.1.2.1.cmml" xref="A7.T10.13.m5.1.1">subscript</csymbol><ci id="A7.T10.13.m5.1.1.2.2.cmml" xref="A7.T10.13.m5.1.1.2.2">𝑇</ci><cn id="A7.T10.13.m5.1.1.2.3.cmml" type="integer" xref="A7.T10.13.m5.1.1.2.3">1</cn></apply><ci id="A7.T10.13.m5.1.1.3.cmml" xref="A7.T10.13.m5.1.1.3">𝐴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T10.13.m5.1d">T_{1}^{A}</annotation><annotation encoding="application/x-llamapun" id="A7.T10.13.m5.1e">italic_T start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_A end_POSTSUPERSCRIPT</annotation></semantics></math>, 코퍼스 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A7.T10.14.m6.1"><semantics id="A7.T10.14.m6.1b"><msub id="A7.T10.14.m6.1.1" xref="A7.T10.14.m6.1.1.cmml"><mi id="A7.T10.14.m6.1.1.2" xref="A7.T10.14.m6.1.1.2.cmml">D</mi><mn id="A7.T10.14.m6.1.1.3" xref="A7.T10.14.m6.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A7.T10.14.m6.1c"><apply id="A7.T10.14.m6.1.1.cmml" xref="A7.T10.14.m6.1.1"><csymbol cd="ambiguous" id="A7.T10.14.m6.1.1.1.cmml" xref="A7.T10.14.m6.1.1">subscript</csymbol><ci id="A7.T10.14.m6.1.1.2.cmml" xref="A7.T10.14.m6.1.1.2">𝐷</ci><cn id="A7.T10.14.m6.1.1.3.cmml" type="integer" xref="A7.T10.14.m6.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T10.14.m6.1d">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A7.T10.14.m6.1e">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="D_{1}" class="ltx_Math" display="inline" id="A7.T10.15.m7.1"><semantics id="A7.T10.15.m7.1b"><msub id="A7.T10.15.m7.1.1" xref="A7.T10.15.m7.1.1.cmml"><mi id="A7.T10.15.m7.1.1.2" xref="A7.T10.15.m7.1.1.2.cmml">D</mi><mn id="A7.T10.15.m7.1.1.3" xref="A7.T10.15.m7.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A7.T10.15.m7.1c"><apply id="A7.T10.15.m7.1.1.cmml" xref="A7.T10.15.m7.1.1"><csymbol cd="ambiguous" id="A7.T10.15.m7.1.1.1.cmml" xref="A7.T10.15.m7.1.1">subscript</csymbol><ci id="A7.T10.15.m7.1.1.2.cmml" xref="A7.T10.15.m7.1.1.2">𝐷</ci><cn id="A7.T10.15.m7.1.1.3.cmml" type="integer" xref="A7.T10.15.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T10.15.m7.1d">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A7.T10.15.m7.1e">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="D_{1}" class="ltx_Math" display="inline" id="A7.T10.16.m8.1"><semantics id="A7.T10.16.m8.1b"><msub id="A7.T10.16.m8.1.1" xref="A7.T10.16.m8.1.1.cmml"><mi id="A7.T10.16.m8.1.1.2" xref="A7.T10.16.m8.1.1.2.cmml">D</mi><mn id="A7.T10.16.m8.1.1.3" xref="A7.T10.16.m8.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A7.T10.16.m8.1c"><apply id="A7.T10.16.m8.1.1.cmml" xref="A7.T10.16.m8.1.1"><csymbol cd="ambiguous" id="A7.T10.16.m8.1.1.1.cmml" xref="A7.T10.16.m8.1.1">subscript</csymbol><ci id="A7.T10.16.m8.1.1.2.cmml" xref="A7.T10.16.m8.1.1.2">𝐷</ci><cn id="A7.T10.16.m8.1.1.3.cmml" type="integer" xref="A7.T10.16.m8.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T10.16.m8.1d">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A7.T10.16.m8.1e">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>로부터 시간 불변 지식의 양을 측정하는 태스크이다.</figcaption>
<table id="A7.T10.18" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A7.T10.18.2" class="ltx_tr">
<td id="A7.T10.18.2.3" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2">
<span id="A7.T10.18.2.3.1" class="ltx_text"></span><span id="A7.T10.18.2.3.2" class="ltx_text ltx_font_bold"> <span id="A7.T10.18.2.3.2.1" class="ltx_text">
<span id="A7.T10.18.2.3.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="A7.T10.18.2.3.2.1.1.1" class="ltx_tr">
<span id="A7.T10.18.2.3.2.1.1.1.1" class="ltx_td ltx_align_center">Method</span></span>
</span></span> <span id="A7.T10.18.2.3.2.2" class="ltx_text"></span></span>
</td>
<td id="A7.T10.18.2.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="A7.T10.18.2.4.1" class="ltx_text ltx_font_bold">IL</span></td>
<td id="A7.T10.18.2.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="A7.T10.18.2.5.1" class="ltx_text ltx_font_bold">NQE</span></td>
<td id="A7.T10.18.2.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2">
<span id="A7.T10.18.2.2.3" class="ltx_text"></span> <span id="A7.T10.18.2.2.2" class="ltx_text">
<span id="A7.T10.18.2.2.2.2.2" class="ltx_tabular ltx_align_middle">
<span id="A7.T10.18.2.2.2.2.2.3" class="ltx_tr">
<span id="A7.T10.18.2.2.2.2.2.3.1" class="ltx_td ltx_align_center"><span id="A7.T10.18.2.2.2.2.2.3.1.1" class="ltx_text ltx_font_bold">FUAR</span></span></span>
<span id="A7.T10.18.2.2.2.2.2.2" class="ltx_tr">
<span id="A7.T10.18.2.2.2.2.2.2.2" class="ltx_td ltx_align_center"><math id="A7.T10.17.1.1.1.1.1.1.1.m1.3" class="ltx_math_unparsed" alttext="\left((\mathbf{IL}),\bm{n.d.},\mathbf{NQE}\right)" display="inline"><semantics id="A7.T10.17.1.1.1.1.1.1.1.m1.3a"><mrow id="A7.T10.17.1.1.1.1.1.1.1.m1.3b"><mo id="A7.T10.17.1.1.1.1.1.1.1.m1.3.4">(</mo><mrow id="A7.T10.17.1.1.1.1.1.1.1.m1.3.5"><mo stretchy="false" id="A7.T10.17.1.1.1.1.1.1.1.m1.3.5.1">(</mo><mi id="A7.T10.17.1.1.1.1.1.1.1.m1.1.1">𝐈𝐋</mi><mo stretchy="false" id="A7.T10.17.1.1.1.1.1.1.1.m1.3.5.2">)</mo></mrow><mo id="A7.T10.17.1.1.1.1.1.1.1.m1.3.6">,</mo><mi id="A7.T10.17.1.1.1.1.1.1.1.m1.2.2">𝒏</mi><mo lspace="0em" mathvariant="bold" rspace="0.167em" id="A7.T10.17.1.1.1.1.1.1.1.m1.3.7">.</mo><mi id="A7.T10.17.1.1.1.1.1.1.1.m1.3.3">𝒅</mi><mo lspace="0em" mathvariant="bold" rspace="0.167em" id="A7.T10.17.1.1.1.1.1.1.1.m1.3.8">.</mo><mo id="A7.T10.17.1.1.1.1.1.1.1.m1.3.9">,</mo><mi id="A7.T10.17.1.1.1.1.1.1.1.m1.3.10">𝐍𝐐𝐄</mi><mo id="A7.T10.17.1.1.1.1.1.1.1.m1.3.11">)</mo></mrow><annotation encoding="application/x-tex" id="A7.T10.17.1.1.1.1.1.1.1.m1.3c">\left((\mathbf{IL}),\bm{n.d.},\mathbf{NQE}\right)</annotation><annotation encoding="application/x-llamapun" id="A7.T10.17.1.1.1.1.1.1.1.m1.3d">( ( bold_IL ) , bold_italic_n bold_. bold_italic_d bold_. , bold_NQE )</annotation></semantics></math> <math id="A7.T10.18.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A7.T10.18.2.2.2.2.2.2.2.m2.1a"><mo stretchy="false" id="A7.T10.18.2.2.2.2.2.2.2.m2.1.1" xref="A7.T10.18.2.2.2.2.2.2.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A7.T10.18.2.2.2.2.2.2.2.m2.1b"><ci id="A7.T10.18.2.2.2.2.2.2.2.m2.1.1.cmml" xref="A7.T10.18.2.2.2.2.2.2.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A7.T10.18.2.2.2.2.2.2.2.m2.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A7.T10.18.2.2.2.2.2.2.2.m2.1d">↓</annotation></semantics></math></span></span>
</span></span> <span id="A7.T10.18.2.2.4" class="ltx_text"></span>
</td>
</tr>
<tr id="A7.T10.18.3" class="ltx_tr">
<td id="A7.T10.18.3.1" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="A7.T10.18.3.2" class="ltx_td ltx_align_center ltx_border_t">EM</td>
</tr>
<tr id="A7.T10.18.4" class="ltx_tr">
<td id="A7.T10.18.4.1" class="ltx_td ltx_align_left ltx_border_t">GPT2-Initial</td>
<td id="A7.T10.18.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A7.T10.18.4.2.1" class="ltx_text ltx_framed_underline">38.11</span></td>
<td id="A7.T10.18.4.3" class="ltx_td ltx_align_center ltx_border_t">4.3</td>
<td id="A7.T10.18.4.4" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="A7.T10.18.5" class="ltx_tr">
<td id="A7.T10.18.5.1" class="ltx_td ltx_align_left ltx_border_t">GPT2-Vanilla</td>
<td id="A7.T10.18.5.2" class="ltx_td ltx_align_center ltx_border_t">35.88</td>
<td id="A7.T10.18.5.3" class="ltx_td ltx_align_center ltx_border_t">5.79</td>
<td id="A7.T10.18.5.4" class="ltx_td ltx_align_center ltx_border_t">1.58</td>
</tr>
<tr id="A7.T10.18.6" class="ltx_tr">
<td id="A7.T10.18.6.1" class="ltx_td ltx_align_left">GPT2-Recadam</td>
<td id="A7.T10.18.6.2" class="ltx_td ltx_align_center">35.50</td>
<td id="A7.T10.18.6.3" class="ltx_td ltx_align_center">5.79</td>
<td id="A7.T10.18.6.4" class="ltx_td ltx_align_center">1.84</td>
</tr>
<tr id="A7.T10.18.7" class="ltx_tr">
<td id="A7.T10.18.7.1" class="ltx_td ltx_align_left">GPT2-Mixreview</td>
<td id="A7.T10.18.7.2" class="ltx_td ltx_align_center"><span id="A7.T10.18.7.2.1" class="ltx_text ltx_font_bold">38.93</span></td>
<td id="A7.T10.18.7.3" class="ltx_td ltx_align_center">5.57</td>
<td id="A7.T10.18.7.4" class="ltx_td ltx_align_center"><span id="A7.T10.18.7.4.1" class="ltx_text ltx_font_bold">0</span></td>
</tr>
<tr id="A7.T10.18.8" class="ltx_tr">
<td id="A7.T10.18.8.1" class="ltx_td ltx_align_left">GPT2-Lora</td>
<td id="A7.T10.18.8.2" class="ltx_td ltx_align_center">37.99</td>
<td id="A7.T10.18.8.3" class="ltx_td ltx_align_center"><span id="A7.T10.18.8.3.1" class="ltx_text ltx_framed_underline">6.23</span></td>
<td id="A7.T10.18.8.4" class="ltx_td ltx_align_center"><span id="A7.T10.18.8.4.1" class="ltx_text ltx_framed_underline">0.06</span></td>
</tr>
<tr id="A7.T10.18.9" class="ltx_tr">
<td id="A7.T10.18.9.1" class="ltx_td ltx_align_left">GPT2-Kadapters (k=2)</td>
<td id="A7.T10.18.9.2" class="ltx_td ltx_align_center">37.85</td>
<td id="A7.T10.18.9.3" class="ltx_td ltx_align_center"><span id="A7.T10.18.9.3.1" class="ltx_text ltx_font_bold">6.34</span></td>
<td id="A7.T10.18.9.4" class="ltx_td ltx_align_center">0.13</td>
</tr>
<tr id="A7.T10.18.10" class="ltx_tr">
<td id="A7.T10.18.10.1" class="ltx_td ltx_align_left ltx_border_bb">GPT2-Kadapters (k=3)</td>
<td id="A7.T10.18.10.2" class="ltx_td ltx_align_center ltx_border_bb">38.03</td>
<td id="A7.T10.18.10.3" class="ltx_td ltx_align_center ltx_border_bb">5.79</td>
<td id="A7.T10.18.10.4" class="ltx_td ltx_align_center ltx_border_bb">0.06</td>
</tr>
</tbody></table>
</figure>
<div id="A7.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A7.p2.1">시간 불변 지식을 측정하기 위해 채울 슬롯의 대부분이 문장의 끝에 있기 때문에 InvariantLAMA(IL)를 사용한다. IL을 대신하여 라이트 튜닝을 위해 IL의 인스턴스와 유사한 분포를 갖는 <cite class="ltx_cite ltx_citemacro_citet">Shin et al. (<a class="ltx_ref" href="#bib.bib45" title="">2020</a>)</cite>의 추가 T-Rex 데이터를 사용한다. 이 중 IL과 동일한 <span class="ltx_text ltx_font_italic" id="A7.p2.1.1">time-invariant</span> 관계를 가진 5,000개의 인스턴스가 <span class="ltx_text ltx_font_italic" id="A7.p2.1.2">light-tuning</span>에 대해 무작위로 샘플링된다. 반면에, 채울 슬롯의 대부분이 문장의 끝에 있는 IL과 달리, 우리의 CKL 벤치마크에서 새로운 지식을 위한 LAMA 데이터 세트는 대부분 문장의 시작 부분에 슬롯을 가지고 있다. 따라서 우리는 <span class="ltx_text ltx_font_smallcaps" id="A7.p2.1.3">NewLAMA-Easy</span>, <span class="ltx_text ltx_font_smallcaps" id="A7.p2.1.4">NewQuestions-Easy</span> (NQE)의 해당 CBQA 데이터 세트를 사용하여 새로운 지식을 대략적으로 측정한다. <span class="ltx_note ltx_role_footnote" id="footnote15"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span>The QA version of UL, NL and NLE will be also released with the main CKL benchmark.</span></span></span> NQE를 대신하여 light-tuning의 경우, 테스트-트레인 중첩을 제거하기 위해 <span class="ltx_text ltx_font_smallcaps" id="A7.p2.1.5">CC-RecentNews</span>에서 구성되었지만 <span class="ltx_text ltx_font_smallcaps" id="A7.p2.1.6">CC-RecentNews-Small</span>에서 구성되지 않은 QA 쌍 세트에서 5,000개의 인스턴스가 샘플링됩니다.</p>
</div>
<div id="A7.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A7.p3.2">표 <a class="ltx_ref" href="#A7.T10" title="Table 10 ‣ Appendix G Exploring How CKL Methods Transfer Across LM Architectures ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">10</span></a>는 GPT-2 모델의 CKL 벤치마크 성능을 보여준다. 우리는 다른 무작위 종자를 사용하여 5회 실행 동안 평균한 결과를 보고한다. 표 <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.1 Main Results ‣ 5 Experimental Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>에서와 같이 파라미터 확장 방법은 IL과 NQE 모두에서 강력한 성능을 보여 낮은 <span class="ltx_text" id="A7.p3.2.1">FUAR</span>을 나타낸다. 이는 이러한 방법들이 인코더-디코더 모델뿐만 아니라 디코더 전용 모델에서도 효과적임을 보여준다. 표 <a class="ltx_ref" href="#A7.T10" title="Table 10 ‣ Appendix G Exploring How CKL Methods Transfer Across LM Architectures ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">10</span></a>의 흥미로운 결과 중 하나는 GPT2-MixReview가 IL에 대해 가장 잘 수행하고 초기 모델보다 성능이 훨씬 높아서 최고의 <span class="ltx_text" id="A7.p3.2.2">FUAR</span>이 0으로 생성되며 이는 망각이 전혀 발생하지 않았음을 의미한다. 계속된 사전 훈련 동안 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A7.p3.1.m1.1"><semantics id="A7.p3.1.m1.1a"><msub id="A7.p3.1.m1.1.1" xref="A7.p3.1.m1.1.1.cmml"><mi id="A7.p3.1.m1.1.1.2" xref="A7.p3.1.m1.1.1.2.cmml">D</mi><mn id="A7.p3.1.m1.1.1.3" xref="A7.p3.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A7.p3.1.m1.1b"><apply id="A7.p3.1.m1.1.1.cmml" xref="A7.p3.1.m1.1.1"><csymbol cd="ambiguous" id="A7.p3.1.m1.1.1.1.cmml" xref="A7.p3.1.m1.1.1">subscript</csymbol><ci id="A7.p3.1.m1.1.1.2.cmml" xref="A7.p3.1.m1.1.1.2">𝐷</ci><cn id="A7.p3.1.m1.1.1.3.cmml" type="integer" xref="A7.p3.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.p3.1.m1.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A7.p3.1.m1.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>의 샘플에 대한 액세스를 허용하는 GPT2-MixReview의 훈련 전략이 <span class="ltx_text ltx_font_italic" id="A7.p3.2.3">light-tuning</span> 단계 동안 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A7.p3.2.m2.1"><semantics id="A7.p3.2.m2.1a"><msub id="A7.p3.2.m2.1.1" xref="A7.p3.2.m2.1.1.cmml"><mi id="A7.p3.2.m2.1.1.2" xref="A7.p3.2.m2.1.1.2.cmml">D</mi><mn id="A7.p3.2.m2.1.1.3" xref="A7.p3.2.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A7.p3.2.m2.1b"><apply id="A7.p3.2.m2.1.1.cmml" xref="A7.p3.2.m2.1.1"><csymbol cd="ambiguous" id="A7.p3.2.m2.1.1.1.cmml" xref="A7.p3.2.m2.1.1">subscript</csymbol><ci id="A7.p3.2.m2.1.1.2.cmml" xref="A7.p3.2.m2.1.1.2">𝐷</ci><cn id="A7.p3.2.m2.1.1.3.cmml" type="integer" xref="A7.p3.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.p3.2.m2.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A7.p3.2.m2.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>의 지식에 대한 빠른 적응을 허용했을 것이라고 가정한다. GPT2-MixReview의 성능은 작은 튜닝 단계에서도 디코더 전용 모델에 대한 원래의 지식을 되찾을 수 있음을 시사한다.</p>
</div>
<div id="A7.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A7.p4.1">부호화기-복호화기 LM(T5)과 복호화기 전용 LM(GPT-2) 사이의 CKL 방법 간의 성능 불일치는 LM 아키텍처에만 있는 것이 아니라 학습률과 평가 방법(T5를 제로 샷 방식으로 평가하면서 GPT-2를 평가하기 위해 라이트 튜닝을 사용함)에 있을 수 있음을 강조하고자 한다. 우리는 GPT-2와 같은 끊임없이 변화하는 디코더 전용 LMs 훈련에 대한 추가 탐색을 향후 작업으로 남겨둔다.</p>
</div>
<section id="A7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.1 </span>Failed GPT-2 experiments with Larger Learning Rate</h3>

<div id="A7.SS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A7.SS1.p1.1">표 <a class="ltx_ref" href="#A7.T11" title="Table 11 ‣ G.1 Failed GPT-2 experiments with Larger Learning Rate ‣ Appendix G Exploring How CKL Methods Transfer Across LM Architectures ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">11</span></a>는 학습률이 1e-3인 8개의 epochs에 대해 <span class="ltx_text ltx_font_smallcaps" id="A7.SS1.p1.1.1">CC-RecentNews-Small</span>에서 지속적으로 사전 트레이닝된 GPT-2 모델의 CKL 벤치마크 결과를 보여준다. 이 표의 결과를 1e-4의 학습률이 지속적으로 사전 트레이닝된 모델에 대한 표 <a class="ltx_ref" href="#A7.T10" title="Table 10 ‣ Appendix G Exploring How CKL Methods Transfer Across LM Architectures ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">10</span></a>의 결과와 비교함으로써, 표 <a class="ltx_ref" href="#A7.T11" title="Table 11 ‣ G.1 Failed GPT-2 experiments with Larger Learning Rate ‣ Appendix G Exploring How CKL Methods Transfer Across LM Architectures ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">11</span></a>의 결과는 IL 및 NQE 모두에서 더 나쁜 성능을 보여준다. 부록 <a class="ltx_ref" href="#A5" title="Appendix E Exploring the Trade-off of Varying the Learning Rate for Continual Pretraining ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">E</span></a>와 달리 학습률을 높인다고 해서 새로운 지식을 더 잘 학습하는 것은 아니다. 대신, NQE 성능은 GPT2-Vanilla, GPT2-Recadam 및 GPT2-MixReview의 경우 GPT2-Initial보다 훨씬 더 나쁘다. <span class="ltx_text" id="A7.SS1.p1.1.2">FUAR</span>은 분모가 0의 값을 갖기 때문에 메트릭의 정의에 의해 이러한 경우에 대해 <span class="ltx_text ltx_font_italic" id="A7.SS1.p1.1.3">no gain</span>이다. 이것은 지속적인 사전 훈련을 위한 큰 학습률이 오래된 지식을 유지하거나 새로운 지식을 효과적으로 획득하지 못하는 실패로 이어질 수 있음을 보여준다. 파라미터 확장 방법의 경우, 디코더를 포함한 많은 파라미터들이 지속적인 트레이닝 과정에서 동결되기 때문에, 큰 학습률의 영향을 덜 받는 것으로 보인다.</p>
</div>
<figure id="A7.T11" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 11:</span>Dec 2019 dump of Webtext and May 2020 dump of Wikipedia (<math alttext="D_{0}" class="ltx_Math" display="inline" id="A7.T11.3.m1.1"><semantics id="A7.T11.3.m1.1b"><msub id="A7.T11.3.m1.1.1" xref="A7.T11.3.m1.1.1.cmml"><mi id="A7.T11.3.m1.1.1.2" xref="A7.T11.3.m1.1.1.2.cmml">D</mi><mn id="A7.T11.3.m1.1.1.3" xref="A7.T11.3.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A7.T11.3.m1.1c"><apply id="A7.T11.3.m1.1.1.cmml" xref="A7.T11.3.m1.1.1"><csymbol cd="ambiguous" id="A7.T11.3.m1.1.1.1.cmml" xref="A7.T11.3.m1.1.1">subscript</csymbol><ci id="A7.T11.3.m1.1.1.2.cmml" xref="A7.T11.3.m1.1.1.2">𝐷</ci><cn id="A7.T11.3.m1.1.1.3.cmml" type="integer" xref="A7.T11.3.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T11.3.m1.1d">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A7.T11.3.m1.1e">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>)에서 초기 사전 훈련된 디코더 전용 모델의 성능 <span class="ltx_text ltx_font_smallcaps" id="A7.T11.10.1">CC-RecentNews-Small</span> (<math alttext="D_{1}" class="ltx_Math" display="inline" id="A7.T11.4.m2.1"><semantics id="A7.T11.4.m2.1b"><msub id="A7.T11.4.m2.1.1" xref="A7.T11.4.m2.1.1.cmml"><mi id="A7.T11.4.m2.1.1.2" xref="A7.T11.4.m2.1.1.2.cmml">D</mi><mn id="A7.T11.4.m2.1.1.3" xref="A7.T11.4.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A7.T11.4.m2.1c"><apply id="A7.T11.4.m2.1.1.cmml" xref="A7.T11.4.m2.1.1"><csymbol cd="ambiguous" id="A7.T11.4.m2.1.1.1.cmml" xref="A7.T11.4.m2.1.1">subscript</csymbol><ci id="A7.T11.4.m2.1.1.2.cmml" xref="A7.T11.4.m2.1.1.2">𝐷</ci><cn id="A7.T11.4.m2.1.1.3.cmml" type="integer" xref="A7.T11.4.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A7.T11.4.m2.1d">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A7.T11.4.m2.1e">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>) for 8 epochs for 1e-3. 이들은 큰 학습률로 인해 결과에 실패하였다. IL 및 NQE 각각은 <span class="ltx_text ltx_font_smallcaps" id="A7.T11.11.2">InvariantLAMA</span> 및 <span class="ltx_text ltx_font_smallcaps" id="A7.T11.12.3">NewQuestions-Easy</span>의 약자이다.</figcaption>
<table id="A7.T11.6" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A7.T11.6.2" class="ltx_tr">
<td id="A7.T11.6.2.3" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2">
<span id="A7.T11.6.2.3.1" class="ltx_text"></span><span id="A7.T11.6.2.3.2" class="ltx_text ltx_font_bold"> <span id="A7.T11.6.2.3.2.1" class="ltx_text">
<span id="A7.T11.6.2.3.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="A7.T11.6.2.3.2.1.1.1" class="ltx_tr">
<span id="A7.T11.6.2.3.2.1.1.1.1" class="ltx_td ltx_align_center">Method</span></span>
</span></span> <span id="A7.T11.6.2.3.2.2" class="ltx_text"></span></span>
</td>
<td id="A7.T11.6.2.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="A7.T11.6.2.4.1" class="ltx_text ltx_font_bold">IL</span></td>
<td id="A7.T11.6.2.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="A7.T11.6.2.5.1" class="ltx_text ltx_font_bold">NQE</span></td>
<td id="A7.T11.6.2.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2">
<span id="A7.T11.6.2.2.3" class="ltx_text"></span> <span id="A7.T11.6.2.2.2" class="ltx_text">
<span id="A7.T11.6.2.2.2.2.2" class="ltx_tabular ltx_align_middle">
<span id="A7.T11.6.2.2.2.2.2.3" class="ltx_tr">
<span id="A7.T11.6.2.2.2.2.2.3.1" class="ltx_td ltx_align_center"><span id="A7.T11.6.2.2.2.2.2.3.1.1" class="ltx_text ltx_font_bold">FUAR</span></span></span>
<span id="A7.T11.6.2.2.2.2.2.2" class="ltx_tr">
<span id="A7.T11.6.2.2.2.2.2.2.2" class="ltx_td ltx_align_center"><math id="A7.T11.5.1.1.1.1.1.1.1.m1.3" class="ltx_math_unparsed" alttext="\left((\mathbf{IL}),\bm{n.d.},\mathbf{NQE}\right)" display="inline"><semantics id="A7.T11.5.1.1.1.1.1.1.1.m1.3a"><mrow id="A7.T11.5.1.1.1.1.1.1.1.m1.3b"><mo id="A7.T11.5.1.1.1.1.1.1.1.m1.3.4">(</mo><mrow id="A7.T11.5.1.1.1.1.1.1.1.m1.3.5"><mo stretchy="false" id="A7.T11.5.1.1.1.1.1.1.1.m1.3.5.1">(</mo><mi id="A7.T11.5.1.1.1.1.1.1.1.m1.1.1">𝐈𝐋</mi><mo stretchy="false" id="A7.T11.5.1.1.1.1.1.1.1.m1.3.5.2">)</mo></mrow><mo id="A7.T11.5.1.1.1.1.1.1.1.m1.3.6">,</mo><mi id="A7.T11.5.1.1.1.1.1.1.1.m1.2.2">𝒏</mi><mo lspace="0em" mathvariant="bold" rspace="0.167em" id="A7.T11.5.1.1.1.1.1.1.1.m1.3.7">.</mo><mi id="A7.T11.5.1.1.1.1.1.1.1.m1.3.3">𝒅</mi><mo lspace="0em" mathvariant="bold" rspace="0.167em" id="A7.T11.5.1.1.1.1.1.1.1.m1.3.8">.</mo><mo id="A7.T11.5.1.1.1.1.1.1.1.m1.3.9">,</mo><mi id="A7.T11.5.1.1.1.1.1.1.1.m1.3.10">𝐍𝐐𝐄</mi><mo id="A7.T11.5.1.1.1.1.1.1.1.m1.3.11">)</mo></mrow><annotation encoding="application/x-tex" id="A7.T11.5.1.1.1.1.1.1.1.m1.3c">\left((\mathbf{IL}),\bm{n.d.},\mathbf{NQE}\right)</annotation><annotation encoding="application/x-llamapun" id="A7.T11.5.1.1.1.1.1.1.1.m1.3d">( ( bold_IL ) , bold_italic_n bold_. bold_italic_d bold_. , bold_NQE )</annotation></semantics></math> <math id="A7.T11.6.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A7.T11.6.2.2.2.2.2.2.2.m2.1a"><mo stretchy="false" id="A7.T11.6.2.2.2.2.2.2.2.m2.1.1" xref="A7.T11.6.2.2.2.2.2.2.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A7.T11.6.2.2.2.2.2.2.2.m2.1b"><ci id="A7.T11.6.2.2.2.2.2.2.2.m2.1.1.cmml" xref="A7.T11.6.2.2.2.2.2.2.2.m2.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A7.T11.6.2.2.2.2.2.2.2.m2.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A7.T11.6.2.2.2.2.2.2.2.m2.1d">↓</annotation></semantics></math></span></span>
</span></span> <span id="A7.T11.6.2.2.4" class="ltx_text"></span>
</td>
</tr>
<tr id="A7.T11.6.3" class="ltx_tr">
<td id="A7.T11.6.3.1" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="A7.T11.6.3.2" class="ltx_td ltx_align_center ltx_border_t">EM</td>
</tr>
<tr id="A7.T11.6.4" class="ltx_tr">
<td id="A7.T11.6.4.1" class="ltx_td ltx_align_left ltx_border_t"><span id="A7.T11.6.4.1.1" class="ltx_text">GPT2-Initial</span></td>
<td id="A7.T11.6.4.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A7.T11.6.4.2.1" class="ltx_text ltx_font_bold">38.11</span></td>
<td id="A7.T11.6.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="A7.T11.6.4.3.1" class="ltx_text">4.37</span></td>
<td id="A7.T11.6.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A7.T11.6.4.4.1" class="ltx_text">-</span></td>
</tr>
<tr id="A7.T11.6.5" class="ltx_tr">
<td id="A7.T11.6.5.1" class="ltx_td ltx_align_left ltx_border_t">GPT2-Vanilla</td>
<td id="A7.T11.6.5.2" class="ltx_td ltx_align_center ltx_border_t">23.03</td>
<td id="A7.T11.6.5.3" class="ltx_td ltx_align_center ltx_border_t">1.64</td>
<td id="A7.T11.6.5.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A7.T11.6.5.4.1" class="ltx_text ltx_font_italic">no gain</span></td>
</tr>
<tr id="A7.T11.6.6" class="ltx_tr">
<td id="A7.T11.6.6.1" class="ltx_td ltx_align_left">GPT2-Recadam</td>
<td id="A7.T11.6.6.2" class="ltx_td ltx_align_center">25.38</td>
<td id="A7.T11.6.6.3" class="ltx_td ltx_align_center">2.73</td>
<td id="A7.T11.6.6.4" class="ltx_td ltx_align_center"><span id="A7.T11.6.6.4.1" class="ltx_text ltx_font_italic">no gain</span></td>
</tr>
<tr id="A7.T11.6.7" class="ltx_tr">
<td id="A7.T11.6.7.1" class="ltx_td ltx_align_left">GPT2-Mixreview</td>
<td id="A7.T11.6.7.2" class="ltx_td ltx_align_center">32.07</td>
<td id="A7.T11.6.7.3" class="ltx_td ltx_align_center">1.64</td>
<td id="A7.T11.6.7.4" class="ltx_td ltx_align_center"><span id="A7.T11.6.7.4.1" class="ltx_text ltx_font_italic">no gain</span></td>
</tr>
<tr id="A7.T11.6.8" class="ltx_tr">
<td id="A7.T11.6.8.1" class="ltx_td ltx_align_left">GPT2-Lora</td>
<td id="A7.T11.6.8.2" class="ltx_td ltx_align_center"><span id="A7.T11.6.8.2.1" class="ltx_text ltx_framed_underline">34.52</span></td>
<td id="A7.T11.6.8.3" class="ltx_td ltx_align_center">5.46</td>
<td id="A7.T11.6.8.4" class="ltx_td ltx_align_center">3.29</td>
</tr>
<tr id="A7.T11.6.9" class="ltx_tr">
<td id="A7.T11.6.9.1" class="ltx_td ltx_align_left">GPT2-Kadapters (k=2)</td>
<td id="A7.T11.6.9.2" class="ltx_td ltx_align_center">33.67</td>
<td id="A7.T11.6.9.3" class="ltx_td ltx_align_center"><span id="A7.T11.6.9.3.1" class="ltx_text ltx_framed_underline">6.01</span></td>
<td id="A7.T11.6.9.4" class="ltx_td ltx_align_center"><span id="A7.T11.6.9.4.1" class="ltx_text ltx_framed_underline">2.71</span></td>
</tr>
<tr id="A7.T11.6.10" class="ltx_tr">
<td id="A7.T11.6.10.1" class="ltx_td ltx_align_left ltx_border_bb">GPT2-Kadapters (k=3)</td>
<td id="A7.T11.6.10.2" class="ltx_td ltx_align_center ltx_border_bb">31.75</td>
<td id="A7.T11.6.10.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="A7.T11.6.10.3.1" class="ltx_text ltx_font_bold">7.65</span></td>
<td id="A7.T11.6.10.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="A7.T11.6.10.4.1" class="ltx_text ltx_font_bold">1.94</span></td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="A8" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix H </span>Exploring the Prediction Change During Continual Pretraining</h2>

<div id="A8.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A8.p1.1">표 <a class="ltx_ref" href="#A8.T12" title="Table 12 ‣ Appendix H Exploring the Prediction Change During Continual Pretraining ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">12</span></a>는 세 가지 지식 프로빙 작업에 대한 T5-Vanilla 및 T5-Modular의 예측 결과를 보여줍니다: <span class="ltx_text ltx_font_smallcaps" id="A8.p1.1.1">InvariantLAMA</span>, <span class="ltx_text ltx_font_smallcaps" id="A8.p1.1.2">UpdatedLAMA</span>, 및 <span class="ltx_text ltx_font_smallcaps" id="A8.p1.1.3">NewLAMA</span>. 우리는 각 모델에 대한 모든 훈련 에포크에 대한 예측을 보여준다. EM의 간격이 어디에서 오는지를 보기 위해 최종 예측에서 T5-Modular는 맞았지만 T5-Initial은 틀렸다는 예측에서 인스턴스를 선택한다.</p>
</div>
<figure id="A8.T12" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 12:</span>Continued Pretraininig 동안 Prediction Outputs 변경</figcaption>
<table id="A8.T12.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A8.T12.1.1" class="ltx_tr">
<td id="A8.T12.1.1.1" class="ltx_td ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"></td>
<td id="A8.T12.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A8.T12.1.1.2.1" class="ltx_text ltx_font_bold">Cloze Sentence</span></td>
<td id="A8.T12.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A8.T12.1.1.3.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="A8.T12.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A8.T12.1.1.4.1" class="ltx_text ltx_font_bold">Epoch 1</span></td>
<td id="A8.T12.1.1.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A8.T12.1.1.5.1" class="ltx_text ltx_font_bold">Epoch 2</span></td>
<td id="A8.T12.1.1.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A8.T12.1.1.6.1" class="ltx_text ltx_font_bold">Epoch 3</span></td>
<td id="A8.T12.1.1.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A8.T12.1.1.7.1" class="ltx_text ltx_font_bold">Epoch 4</span></td>
<td id="A8.T12.1.1.8" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A8.T12.1.1.8.1" class="ltx_text ltx_font_bold">Answer</span></td>
</tr>
<tr id="A8.T12.1.2" class="ltx_tr">
<td id="A8.T12.1.2.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="10"><span id="A8.T12.1.2.1.1" class="ltx_text ltx_font_bold">IL</span></td>
<td id="A8.T12.1.2.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.2.2.1" class="ltx_text">
<span id="A8.T12.1.2.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="A8.T12.1.2.2.1.1.1" class="ltx_tr">
<span id="A8.T12.1.2.2.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">The native language of</span></span>
<span id="A8.T12.1.2.2.1.1.2" class="ltx_tr">
<span id="A8.T12.1.2.2.1.1.2.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Yvonne Monlaur is <span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> .</span></span>
</span></span></td>
<td id="A8.T12.1.2.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">French</td>
<td id="A8.T12.1.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">French</td>
<td id="A8.T12.1.2.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Khmer</td>
<td id="A8.T12.1.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Malaya</td>
<td id="A8.T12.1.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.2.8.1" class="ltx_text">French</span></td>
</tr>
<tr id="A8.T12.1.3" class="ltx_tr">
<td id="A8.T12.1.3.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.3.2" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">French</td>
<td id="A8.T12.1.3.3" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">French</td>
<td id="A8.T12.1.3.4" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">French</td>
<td id="A8.T12.1.3.5" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">French</td>
</tr>
<tr id="A8.T12.1.4" class="ltx_tr">
<td id="A8.T12.1.4.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.4.1.1" class="ltx_text">Sonic Drift 2 is developed by <span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> .</span></td>
<td id="A8.T12.1.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Sonic D</td>
<td id="A8.T12.1.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Sonic the</td>
<td id="A8.T12.1.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Sonic Found</td>
<td id="A8.T12.1.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Sonic the</td>
<td id="A8.T12.1.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.4.7.1" class="ltx_text">Sega</span></td>
</tr>
<tr id="A8.T12.1.5" class="ltx_tr">
<td id="A8.T12.1.5.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.5.2" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Sonic R</td>
<td id="A8.T12.1.5.3" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Sega</td>
<td id="A8.T12.1.5.4" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Sega</td>
<td id="A8.T12.1.5.5" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Sega</td>
</tr>
<tr id="A8.T12.1.6" class="ltx_tr">
<td id="A8.T12.1.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.6.1.1" class="ltx_text">WebKit is developed by <span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> .</span></td>
<td id="A8.T12.1.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Microsoft</td>
<td id="A8.T12.1.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Google</td>
<td id="A8.T12.1.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">GitHub</td>
<td id="A8.T12.1.6.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Google</td>
<td id="A8.T12.1.6.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.6.7.1" class="ltx_text">Apple</span></td>
</tr>
<tr id="A8.T12.1.7" class="ltx_tr">
<td id="A8.T12.1.7.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.7.2" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Apple</td>
<td id="A8.T12.1.7.3" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Apple</td>
<td id="A8.T12.1.7.4" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Apple</td>
<td id="A8.T12.1.7.5" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Apple</td>
</tr>
<tr id="A8.T12.1.8" class="ltx_tr">
<td id="A8.T12.1.8.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.8.1.1" class="ltx_text">
<span id="A8.T12.1.8.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="A8.T12.1.8.1.1.1.1" class="ltx_tr">
<span id="A8.T12.1.8.1.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">The official language of Republic of</span></span>
<span id="A8.T12.1.8.1.1.1.2" class="ltx_tr">
<span id="A8.T12.1.8.1.1.1.2.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Ingushetia is <span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> .</span></span>
</span></span></td>
<td id="A8.T12.1.8.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.8.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Russian</td>
<td id="A8.T12.1.8.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">English</td>
<td id="A8.T12.1.8.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Kazakh</td>
<td id="A8.T12.1.8.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">English</td>
<td id="A8.T12.1.8.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.8.7.1" class="ltx_text">Russian</span></td>
</tr>
<tr id="A8.T12.1.9" class="ltx_tr">
<td id="A8.T12.1.9.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.9.2" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Russian</td>
<td id="A8.T12.1.9.3" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Russian</td>
<td id="A8.T12.1.9.4" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Russian</td>
<td id="A8.T12.1.9.5" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Russian</td>
</tr>
<tr id="A8.T12.1.10" class="ltx_tr">
<td id="A8.T12.1.10.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.10.1.1" class="ltx_text">The capital of Roman Empire is&nbsp;<span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> .</span></td>
<td id="A8.T12.1.10.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.10.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Rome</td>
<td id="A8.T12.1.10.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Rome</td>
<td id="A8.T12.1.10.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Constantino</td>
<td id="A8.T12.1.10.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Constantino</td>
<td id="A8.T12.1.10.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.10.7.1" class="ltx_text">Rome</span></td>
</tr>
<tr id="A8.T12.1.11" class="ltx_tr">
<td id="A8.T12.1.11.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.11.2" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Rome</td>
<td id="A8.T12.1.11.3" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Rome</td>
<td id="A8.T12.1.11.4" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Rome</td>
<td id="A8.T12.1.11.5" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Rome</td>
</tr>
<tr id="A8.T12.1.12" class="ltx_tr">
<td id="A8.T12.1.12.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="10"><span id="A8.T12.1.12.1.1" class="ltx_text ltx_font_bold">UL</span></td>
<td id="A8.T12.1.12.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.12.2.1" class="ltx_text">
<span id="A8.T12.1.12.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="A8.T12.1.12.2.1.1.1" class="ltx_tr">
<span id="A8.T12.1.12.2.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">The biggest exporter of crude oil</span></span>
<span id="A8.T12.1.12.2.1.1.2" class="ltx_tr">
<span id="A8.T12.1.12.2.1.1.2.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">to china is <span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> .</span></span>
</span></span></td>
<td id="A8.T12.1.12.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.12.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Saudi Arabia</td>
<td id="A8.T12.1.12.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Saudi Arabia</td>
<td id="A8.T12.1.12.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Saudi Arabia</td>
<td id="A8.T12.1.12.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Saudi Arabia</td>
<td id="A8.T12.1.12.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.12.8.1" class="ltx_text">
<span id="A8.T12.1.12.8.1.1" class="ltx_tabular ltx_align_middle">
<span id="A8.T12.1.12.8.1.1.1" class="ltx_tr">
<span id="A8.T12.1.12.8.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Saudi Arabia →</span></span>
<span id="A8.T12.1.12.8.1.1.2" class="ltx_tr">
<span id="A8.T12.1.12.8.1.1.2.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Russia</span></span>
</span></span></td>
</tr>
<tr id="A8.T12.1.13" class="ltx_tr">
<td id="A8.T12.1.13.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.13.2" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Russia</td>
<td id="A8.T12.1.13.3" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Saudi Arabia</td>
<td id="A8.T12.1.13.4" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Russia</td>
<td id="A8.T12.1.13.5" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Russia</td>
</tr>
<tr id="A8.T12.1.14" class="ltx_tr">
<td id="A8.T12.1.14.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.14.1.1" class="ltx_text">
<span id="A8.T12.1.14.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="A8.T12.1.14.1.1.1.1" class="ltx_tr">
<span id="A8.T12.1.14.1.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> is the head of</span></span>
<span id="A8.T12.1.14.1.1.1.2" class="ltx_tr">
<span id="A8.T12.1.14.1.1.1.2.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">the euro zone central bank</span></span>
</span></span></td>
<td id="A8.T12.1.14.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.14.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Mario Draghi</td>
<td id="A8.T12.1.14.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Yves Le Maire</td>
<td id="A8.T12.1.14.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Yves Dujarric</td>
<td id="A8.T12.1.14.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Mario Draghi</td>
<td id="A8.T12.1.14.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.14.7.1" class="ltx_text">
<span id="A8.T12.1.14.7.1.1" class="ltx_tabular ltx_align_middle">
<span id="A8.T12.1.14.7.1.1.1" class="ltx_tr">
<span id="A8.T12.1.14.7.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Mario Draghi →</span></span>
<span id="A8.T12.1.14.7.1.1.2" class="ltx_tr">
<span id="A8.T12.1.14.7.1.1.2.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Christine Lagarde</span></span>
</span></span></td>
</tr>
<tr id="A8.T12.1.15" class="ltx_tr">
<td id="A8.T12.1.15.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.15.2" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Mario Draghi</td>
<td id="A8.T12.1.15.3" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Christine Lagarde</td>
<td id="A8.T12.1.15.4" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Christine Lagarde</td>
<td id="A8.T12.1.15.5" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Christine Lagarde</td>
</tr>
<tr id="A8.T12.1.16" class="ltx_tr">
<td id="A8.T12.1.16.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.16.1.1" class="ltx_text">
<span id="A8.T12.1.16.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="A8.T12.1.16.1.1.1.1" class="ltx_tr">
<span id="A8.T12.1.16.1.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> is the manager of</span></span>
<span id="A8.T12.1.16.1.1.1.2" class="ltx_tr">
<span id="A8.T12.1.16.1.1.1.2.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">chelsea in the premier league</span></span>
</span></span></td>
<td id="A8.T12.1.16.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.16.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Mauricio Fernandez</td>
<td id="A8.T12.1.16.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Steve Bruce</td>
<td id="A8.T12.1.16.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Frank Lampard</td>
<td id="A8.T12.1.16.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Mikel Arteta</td>
<td id="A8.T12.1.16.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.16.7.1" class="ltx_text">
<span id="A8.T12.1.16.7.1.1" class="ltx_tabular ltx_align_middle">
<span id="A8.T12.1.16.7.1.1.1" class="ltx_tr">
<span id="A8.T12.1.16.7.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Luis Enrique →</span></span>
<span id="A8.T12.1.16.7.1.1.2" class="ltx_tr">
<span id="A8.T12.1.16.7.1.1.2.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Frank Lampard</span></span>
</span></span></td>
</tr>
<tr id="A8.T12.1.17" class="ltx_tr">
<td id="A8.T12.1.17.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.17.2" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Jose Mourinho</td>
<td id="A8.T12.1.17.3" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Jose Mourinho</td>
<td id="A8.T12.1.17.4" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Frank Lampard</td>
<td id="A8.T12.1.17.5" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Frank Lampard</td>
</tr>
<tr id="A8.T12.1.18" class="ltx_tr">
<td id="A8.T12.1.18.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.18.1.1" class="ltx_text"><span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> is the price for a flat in nottingham</span></td>
<td id="A8.T12.1.18.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.18.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">What</td>
<td id="A8.T12.1.18.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">999</td>
<td id="A8.T12.1.18.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">£1.25m</td>
<td id="A8.T12.1.18.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">£1.25m</td>
<td id="A8.T12.1.18.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.18.7.1" class="ltx_text">
<span id="A8.T12.1.18.7.1.1" class="ltx_tabular ltx_align_middle">
<span id="A8.T12.1.18.7.1.1.1" class="ltx_tr">
<span id="A8.T12.1.18.7.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">36,000 →</span></span>
<span id="A8.T12.1.18.7.1.1.2" class="ltx_tr">
<span id="A8.T12.1.18.7.1.1.2.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">40,000</span></span>
</span></span></td>
</tr>
<tr id="A8.T12.1.19" class="ltx_tr">
<td id="A8.T12.1.19.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.19.2" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">This</td>
<td id="A8.T12.1.19.3" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">30,000 pounds</td>
<td id="A8.T12.1.19.4" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">40,000 pounds</td>
<td id="A8.T12.1.19.5" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">40,000</td>
</tr>
<tr id="A8.T12.1.20" class="ltx_tr">
<td id="A8.T12.1.20.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.20.1.1" class="ltx_text">
<span id="A8.T12.1.20.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="A8.T12.1.20.1.1.1.1" class="ltx_tr">
<span id="A8.T12.1.20.1.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> was the governor of New York</span></span>
<span id="A8.T12.1.20.1.1.1.2" class="ltx_tr">
<span id="A8.T12.1.20.1.1.1.2.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">at the time this article was written</span></span>
</span></span></td>
<td id="A8.T12.1.20.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.20.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Andrew M. Cuomo</td>
<td id="A8.T12.1.20.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Cuomo</td>
<td id="A8.T12.1.20.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Andrew Cuomo</td>
<td id="A8.T12.1.20.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Franklin D. Roosevelt</td>
<td id="A8.T12.1.20.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.20.7.1" class="ltx_text">
<span id="A8.T12.1.20.7.1.1" class="ltx_tabular ltx_align_middle">
<span id="A8.T12.1.20.7.1.1.1" class="ltx_tr">
<span id="A8.T12.1.20.7.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Martin Van Buren →</span></span>
<span id="A8.T12.1.20.7.1.1.2" class="ltx_tr">
<span id="A8.T12.1.20.7.1.1.2.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Andrew Cuomo</span></span>
</span></span></td>
</tr>
<tr id="A8.T12.1.21" class="ltx_tr">
<td id="A8.T12.1.21.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.21.2" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Andrew Cuomo</td>
<td id="A8.T12.1.21.3" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Andrew Cuomo</td>
<td id="A8.T12.1.21.4" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Andrew M. Cuomo</td>
<td id="A8.T12.1.21.5" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Andrew Cuomo</td>
</tr>
<tr id="A8.T12.1.22" class="ltx_tr">
<td id="A8.T12.1.22.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="10"><span id="A8.T12.1.22.1.1" class="ltx_text ltx_font_bold">NL</span></td>
<td id="A8.T12.1.22.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.22.2.1" class="ltx_text">
<span id="A8.T12.1.22.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="A8.T12.1.22.2.1.1.1" class="ltx_tr">
<span id="A8.T12.1.22.2.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> is on the Bills all-pro team</span></span>
</span></span></td>
<td id="A8.T12.1.22.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.22.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Corey</td>
<td id="A8.T12.1.22.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Williams</td>
<td id="A8.T12.1.22.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Corey</td>
<td id="A8.T12.1.22.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Connor</td>
<td id="A8.T12.1.22.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.22.8.1" class="ltx_text">Williams</span></td>
</tr>
<tr id="A8.T12.1.23" class="ltx_tr">
<td id="A8.T12.1.23.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.23.2" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Williams</td>
<td id="A8.T12.1.23.3" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Williams</td>
<td id="A8.T12.1.23.4" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Williams</td>
<td id="A8.T12.1.23.5" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Williams</td>
</tr>
<tr id="A8.T12.1.24" class="ltx_tr">
<td id="A8.T12.1.24.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.24.1.1" class="ltx_text">
<span id="A8.T12.1.24.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="A8.T12.1.24.1.1.1.1" class="ltx_tr">
<span id="A8.T12.1.24.1.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> is the founder of the popular</span></span>
<span id="A8.T12.1.24.1.1.1.2" class="ltx_tr">
<span id="A8.T12.1.24.1.1.1.2.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">cryptocurrency bitcoin</span></span>
</span></span></td>
<td id="A8.T12.1.24.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.24.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Satoshi Nakamoto</td>
<td id="A8.T12.1.24.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Satoshi Nakamoto</td>
<td id="A8.T12.1.24.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Yuri</td>
<td id="A8.T12.1.24.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Xiaobo</td>
<td id="A8.T12.1.24.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.24.7.1" class="ltx_text">Satoshi Nakamoto</span></td>
</tr>
<tr id="A8.T12.1.25" class="ltx_tr">
<td id="A8.T12.1.25.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.25.2" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Vitalik Buterin</td>
<td id="A8.T12.1.25.3" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Satoshi Nakamoto</td>
<td id="A8.T12.1.25.4" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Satoshi Nakamoto</td>
<td id="A8.T12.1.25.5" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">Satoshi Nakamoto</td>
</tr>
<tr id="A8.T12.1.26" class="ltx_tr">
<td id="A8.T12.1.26.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.26.1.1" class="ltx_text">The bail for kyle rittenhouse is <span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> .</span></td>
<td id="A8.T12.1.26.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.26.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Rs. 1 crore</td>
<td id="A8.T12.1.26.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">a whopping $1 million</td>
<td id="A8.T12.1.26.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">$2 million</td>
<td id="A8.T12.1.26.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">$1 million</td>
<td id="A8.T12.1.26.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.26.7.1" class="ltx_text">$2 million</span></td>
</tr>
<tr id="A8.T12.1.27" class="ltx_tr">
<td id="A8.T12.1.27.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.27.2" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">$2 million</td>
<td id="A8.T12.1.27.3" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">$2 million</td>
<td id="A8.T12.1.27.4" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">$2 million</td>
<td id="A8.T12.1.27.5" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">$2 million</td>
</tr>
<tr id="A8.T12.1.28" class="ltx_tr">
<td id="A8.T12.1.28.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.28.1.1" class="ltx_text">
<span id="A8.T12.1.28.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="A8.T12.1.28.1.1.1.1" class="ltx_tr">
<span id="A8.T12.1.28.1.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">The las vegas raiders beat</span></span>
<span id="A8.T12.1.28.1.1.1.2" class="ltx_tr">
<span id="A8.T12.1.28.1.1.1.2.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> in the playoffs</span></span>
</span></span></td>
<td id="A8.T12.1.28.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.28.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">the Las Vegas Raiders</td>
<td id="A8.T12.1.28.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">the New Orleans Saints</td>
<td id="A8.T12.1.28.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">the Las Vegas Raiders</td>
<td id="A8.T12.1.28.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">the sacramento</td>
<td id="A8.T12.1.28.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.28.7.1" class="ltx_text">the New Orleans Saints</span></td>
</tr>
<tr id="A8.T12.1.29" class="ltx_tr">
<td id="A8.T12.1.29.1" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.29.2" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">the New Orleans Saints</td>
<td id="A8.T12.1.29.3" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">the Kansas City Chiefs</td>
<td id="A8.T12.1.29.4" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">the Kansas City Chiefs</td>
<td id="A8.T12.1.29.5" class="ltx_td ltx_align_center" style="padding-left:1.0pt;padding-right:1.0pt;">the New Orleans Saints</td>
</tr>
<tr id="A8.T12.1.30" class="ltx_tr">
<td id="A8.T12.1.30.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.30.1.1" class="ltx_text"><span class="ltx_rule" style="width:11.4pt;height:0.3pt;background:black;display:inline-block;">&nbsp;</span> is the host of ellen de generes show</span></td>
<td id="A8.T12.1.30.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">V</td>
<td id="A8.T12.1.30.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Yves</td>
<td id="A8.T12.1.30.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">samantha s</td>
<td id="A8.T12.1.30.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Norma</td>
<td id="A8.T12.1.30.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">Mike</td>
<td id="A8.T12.1.30.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;" rowspan="2"><span id="A8.T12.1.30.7.1" class="ltx_text">Ellen DeGeneres</span></td>
</tr>
<tr id="A8.T12.1.31" class="ltx_tr">
<td id="A8.T12.1.31.1" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:1.0pt;padding-right:1.0pt;">M</td>
<td id="A8.T12.1.31.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:1.0pt;padding-right:1.0pt;">Elise</td>
<td id="A8.T12.1.31.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:1.0pt;padding-right:1.0pt;">Ellen DeGeneres</td>
<td id="A8.T12.1.31.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:1.0pt;padding-right:1.0pt;">Ellen deGenes</td>
<td id="A8.T12.1.31.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:1.0pt;padding-right:1.0pt;">Ellen DeGeneres</td>
</tr>
</tbody></table>
</figure>
</section>
<section id="A9" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix I </span>Exploring the Cause of the EM Gap Between <span id="A9.1.1" class="ltx_text ltx_font_smallcaps">UpdatedLAMA</span> and <span id="A9.2.2" class="ltx_text ltx_font_smallcaps">NewLAMA</span>
</h2>

<figure id="A9.F8" class="ltx_figure">
<div class="ltx_flex_figure">

<div class="ltx_flex_cell 
                  ltx_flex_size_2">
<figure id="A9.F7.sf1" class="ltx_figure ltx_flex_size_2 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x10.png" id="A9.F7.sf1.g1" class="ltx_graphics ltx_img_square" width="761" height="732" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a)</span> 정확하게 예측된 인스턴스들의 그라운드 트루스 카테고리들의 구성</figcaption>
</figure>
</div>
<div class="ltx_flex_cell 
                  ltx_flex_size_2">
<figure id="A9.F7.sf2" class="ltx_figure ltx_flex_size_2 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x11.png" id="A9.F7.sf2.g1" class="ltx_graphics ltx_img_square" width="761" height="906" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b)</span>EM measured using instances from UL and NL with overlapping <span class="ltx_text ltx_font_italic" id="A9.F7.sf2.2.1">Person</span> type answers</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 8:</span>Analyzing the cause of the EM gap between <span class="ltx_text ltx_font_smallcaps" id="A9.F8.3.1">UpdatedLAMA</span> and <span class="ltx_text ltx_font_smallcaps" id="A9.F8.4.2">NewLAMA</span>.</figcaption>
</figure>
<div id="A9.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="A9.p1.7">주요 실험인 표 <a class="ltx_ref" href="#S5.T2" title="Table 2 ‣ 5.1 Main Results ‣ 5 Experimental Results ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">2</span></a>에서 볼 수 있듯이, 동일한 데이터 구성 프로세스를 거쳤음에도 불구하고 모든 방법에 걸쳐 <span class="ltx_text ltx_font_smallcaps" id="A9.p1.7.1">UpdatedLAMA</span> (UL)과 <span class="ltx_text ltx_font_smallcaps" id="A9.p1.7.2">NewLAMA</span> (NL)의 EM 사이에는 상당한 차이가 있다. 우리는 먼저 T5-Vanilla의 UL과 NL의 EM 점수를 각각 10.17과 3.77로 구성하는 답변 유형이 무엇인지 분석하여 인과관계를 분석하고자 한다. <a class="ltx_ref" href="#A9.F8" title="Figure 8 ‣ Appendix I Exploring the Cause of the EM Gap Between UpdatedLAMA and NewLAMA ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">8</span></a>a에 도시된 바와 같이, <span class="ltx_text ltx_font_italic" id="A9.p1.7.3">Person</span> type을 ground truth로 취하는 cloze 문장은 <span class="ltx_text ltx_font_italic" id="A9.p1.7.4">Person</span> type 답변은 전체 답변 유형 중 비슷한 비율을 차지함에도 불구하고 두 태스크의 EM을 대부분 구성한다(UL의 경우 61.46%, NL의 경우 59.7%). UL은 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A9.p1.1.m1.1"><semantics id="A9.p1.1.m1.1a"><msub id="A9.p1.1.m1.1.1" xref="A9.p1.1.m1.1.1.cmml"><mi id="A9.p1.1.m1.1.1.2" xref="A9.p1.1.m1.1.1.2.cmml">D</mi><mn id="A9.p1.1.m1.1.1.3" xref="A9.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A9.p1.1.m1.1b"><apply id="A9.p1.1.m1.1.1.cmml" xref="A9.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A9.p1.1.m1.1.1.1.cmml" xref="A9.p1.1.m1.1.1">subscript</csymbol><ci id="A9.p1.1.m1.1.1.2.cmml" xref="A9.p1.1.m1.1.1.2">𝐷</ci><cn id="A9.p1.1.m1.1.1.3.cmml" type="integer" xref="A9.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A9.p1.1.m1.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A9.p1.1.m1.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>로부터 정보의 갱신을 요구하는 프로브들로 구성되기 때문에, EM 갭이 그라운드 트루스의 역할을 하는 엔티티들의 각각의 코퍼스 내의 빈도의 차이에 기인한다고 추측할 수 있다. 예를 들어, 이러한 엔티티들은 <math alttext="D_{1}" class="ltx_Math" display="inline" id="A9.p1.3.m3.1"><semantics id="A9.p1.3.m3.1a"><msub id="A9.p1.3.m3.1.1" xref="A9.p1.3.m3.1.1.cmml"><mi id="A9.p1.3.m3.1.1.2" xref="A9.p1.3.m3.1.1.2.cmml">D</mi><mn id="A9.p1.3.m3.1.1.3" xref="A9.p1.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A9.p1.3.m3.1b"><apply id="A9.p1.3.m3.1.1.cmml" xref="A9.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A9.p1.3.m3.1.1.1.cmml" xref="A9.p1.3.m3.1.1">subscript</csymbol><ci id="A9.p1.3.m3.1.1.2.cmml" xref="A9.p1.3.m3.1.1.2">𝐷</ci><cn id="A9.p1.3.m3.1.1.3.cmml" type="integer" xref="A9.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A9.p1.3.m3.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A9.p1.3.m3.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>보다 코퍼스 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A9.p1.2.m2.1"><semantics id="A9.p1.2.m2.1a"><msub id="A9.p1.2.m2.1.1" xref="A9.p1.2.m2.1.1.cmml"><mi id="A9.p1.2.m2.1.1.2" xref="A9.p1.2.m2.1.1.2.cmml">D</mi><mn id="A9.p1.2.m2.1.1.3" xref="A9.p1.2.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A9.p1.2.m2.1b"><apply id="A9.p1.2.m2.1.1.cmml" xref="A9.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A9.p1.2.m2.1.1.1.cmml" xref="A9.p1.2.m2.1.1">subscript</csymbol><ci id="A9.p1.2.m2.1.1.2.cmml" xref="A9.p1.2.m2.1.1.2">𝐷</ci><cn id="A9.p1.2.m2.1.1.3.cmml" type="integer" xref="A9.p1.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A9.p1.2.m2.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A9.p1.2.m2.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>에서 더 많이 나타난다. EM 갭의 원인을 분석할 때 엔터티의 빈도의 영향을 제거하기 위해 중첩된 <span class="ltx_text ltx_font_italic" id="A9.p1.7.5">Person</span> type answer from UL and NL을 찾고 이들 엔터티 중 하나에 각각 쌍을 이루는 두 데이터 세트에 대해 67개의 프로빙 문장만 분석한다. 도 <a class="ltx_ref" href="#A9.F8" title="Figure 8 ‣ Appendix I Exploring the Cause of the EM Gap Between UpdatedLAMA and NewLAMA ‣ Towards Continual Knowledge Learning of Language Models"><span class="ltx_text ltx_ref_tag">8</span></a>b에 도시된 바와 같이, UL 상의 EM은 여전히 NL의 것보다 훨씬 높다. 이러한 인스턴스를 수동으로 분석하면, NL에 대한 프로빙 문장이 UL에 비해 상대적으로 더 많은 <span class="ltx_text ltx_font_italic" id="A9.p1.7.6">fine-grained</span> 지식을 요청한다는 것을 알 수 있는데, 이는 정의에 의한 UL의 인스턴스가 코퍼스 <math alttext="D_{0}" class="ltx_Math" display="inline" id="A9.p1.4.m4.1"><semantics id="A9.p1.4.m4.1a"><msub id="A9.p1.4.m4.1.1" xref="A9.p1.4.m4.1.1.cmml"><mi id="A9.p1.4.m4.1.1.2" xref="A9.p1.4.m4.1.1.2.cmml">D</mi><mn id="A9.p1.4.m4.1.1.3" xref="A9.p1.4.m4.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="A9.p1.4.m4.1b"><apply id="A9.p1.4.m4.1.1.cmml" xref="A9.p1.4.m4.1.1"><csymbol cd="ambiguous" id="A9.p1.4.m4.1.1.1.cmml" xref="A9.p1.4.m4.1.1">subscript</csymbol><ci id="A9.p1.4.m4.1.1.2.cmml" xref="A9.p1.4.m4.1.1.2">𝐷</ci><cn id="A9.p1.4.m4.1.1.3.cmml" type="integer" xref="A9.p1.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A9.p1.4.m4.1c">D_{0}</annotation><annotation encoding="application/x-llamapun" id="A9.p1.4.m4.1d">italic_D start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> 및 <math alttext="D_{1}" class="ltx_Math" display="inline" id="A9.p1.5.m5.1"><semantics id="A9.p1.5.m5.1a"><msub id="A9.p1.5.m5.1.1" xref="A9.p1.5.m5.1.1.cmml"><mi id="A9.p1.5.m5.1.1.2" xref="A9.p1.5.m5.1.1.2.cmml">D</mi><mn id="A9.p1.5.m5.1.1.3" xref="A9.p1.5.m5.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A9.p1.5.m5.1b"><apply id="A9.p1.5.m5.1.1.cmml" xref="A9.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A9.p1.5.m5.1.1.1.cmml" xref="A9.p1.5.m5.1.1">subscript</csymbol><ci id="A9.p1.5.m5.1.1.2.cmml" xref="A9.p1.5.m5.1.1.2">𝐷</ci><cn id="A9.p1.5.m5.1.1.3.cmml" type="integer" xref="A9.p1.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A9.p1.5.m5.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A9.p1.5.m5.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>에서 서로 다른 답변을 갖는 중첩된 클로즈 문장이기 때문에 자연스럽게 <span class="ltx_text ltx_font_italic" id="A9.p1.7.7">coarse-grained</span>이 된다. 예를 들어, UL 및 NL의 엔티티 "Tim Walz"에 대한 프로빙 문장은 각각 "<span class="ltx_rule" 스타일="width:28.5pt;height:0.3pt;background:black;display:inline-block;"></span> is the governor of Minnesota this year." 및 "<span class="ltx_rule" 스타일="width:28.5pt;height:0.3pt;background:black;display:inline-block;"></span> is the governor of Minnesota calling for the evacuation of St. Paul."이다. 따라서 우리는 EM 갭의 주요 원인이 <span class="ltx_text ltx_font_italic" id="A9.p1.7.8">coarse-grained</span> 지식을 필요로 하는 인스턴스들로 구성된 UL인 반면, <math alttext="D_{1}" class="ltx_Math" display="inline" id="A9.p1.6.m6.1"><semantics id="A9.p1.6.m6.1a"><msub id="A9.p1.6.m6.1.1" xref="A9.p1.6.m6.1.1.cmml"><mi id="A9.p1.6.m6.1.1.2" xref="A9.p1.6.m6.1.1.2.cmml">D</mi><mn id="A9.p1.6.m6.1.1.3" xref="A9.p1.6.m6.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A9.p1.6.m6.1b"><apply id="A9.p1.6.m6.1.1.cmml" xref="A9.p1.6.m6.1.1"><csymbol cd="ambiguous" id="A9.p1.6.m6.1.1.1.cmml" xref="A9.p1.6.m6.1.1">subscript</csymbol><ci id="A9.p1.6.m6.1.1.2.cmml" xref="A9.p1.6.m6.1.1.2">𝐷</ci><cn id="A9.p1.6.m6.1.1.3.cmml" type="integer" xref="A9.p1.6.m6.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A9.p1.6.m6.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A9.p1.6.m6.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>에서는 더 많이 나타났을 가능성이 있는 반면, <span class="ltx_text ltx_font_italic" id="A9.p1.7.9">fine-grained</span> 지식을 필요로 하는 인스턴스들로 구성된 NL은 <math alttext="D_{1}" class="ltx_Math" display="inline" id="A9.p1.7.m7.1"><semantics id="A9.p1.7.m7.1a"><msub id="A9.p1.7.m7.1.1" xref="A9.p1.7.m7.1.1.cmml"><mi id="A9.p1.7.m7.1.1.2" xref="A9.p1.7.m7.1.1.2.cmml">D</mi><mn id="A9.p1.7.m7.1.1.3" xref="A9.p1.7.m7.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A9.p1.7.m7.1b"><apply id="A9.p1.7.m7.1.1.cmml" xref="A9.p1.7.m7.1.1"><csymbol cd="ambiguous" id="A9.p1.7.m7.1.1.1.cmml" xref="A9.p1.7.m7.1.1">subscript</csymbol><ci id="A9.p1.7.m7.1.1.2.cmml" xref="A9.p1.7.m7.1.1.2">𝐷</ci><cn id="A9.p1.7.m7.1.1.3.cmml" type="integer" xref="A9.p1.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A9.p1.7.m7.1c">D_{1}</annotation><annotation encoding="application/x-llamapun" id="A9.p1.7.m7.1d">italic_D start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>에서는 더 적게 나타났을 것으로 예상된다.</p>
</div>
</section>
<section id="A10" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix J </span>Additional Analysis of Main Results</h2>

<figure id="A10.T13" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 13:</span>F1 Score of Main Results.</figcaption>
<table id="A10.T13.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A10.T13.2.2" class="ltx_tr">
<td id="A10.T13.2.2.3" class="ltx_td ltx_align_left ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2">
<span id="A10.T13.2.2.3.1" class="ltx_text"></span><span id="A10.T13.2.2.3.2" class="ltx_text ltx_font_bold"> <span id="A10.T13.2.2.3.2.1" class="ltx_text">
<span id="A10.T13.2.2.3.2.1.1" class="ltx_tabular ltx_align_middle">
<span id="A10.T13.2.2.3.2.1.1.1" class="ltx_tr">
<span id="A10.T13.2.2.3.2.1.1.1.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">Method</span></span>
</span></span> <span id="A10.T13.2.2.3.2.2" class="ltx_text"></span></span>
</td>
<td id="A10.T13.2.2.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.2.4.1" class="ltx_text ltx_font_bold">IL</span></td>
<td id="A10.T13.2.2.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.2.5.1" class="ltx_text ltx_font_bold">UL</span></td>
<td id="A10.T13.2.2.6" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.2.6.1" class="ltx_text ltx_font_bold">NL</span></td>
<td id="A10.T13.2.2.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.2.7.1" class="ltx_text ltx_font_bold">NLE</span></td>
<td id="A10.T13.2.2.2" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;" rowspan="2">
<span id="A10.T13.2.2.2.3" class="ltx_text"></span><span id="A10.T13.2.2.2.2" class="ltx_text ltx_font_bold"> <span id="A10.T13.2.2.2.2.2" class="ltx_text">
<span id="A10.T13.2.2.2.2.2.2.2" class="ltx_tabular ltx_align_middle">
<span id="A10.T13.2.2.2.2.2.2.2.3" class="ltx_tr">
<span id="A10.T13.2.2.2.2.2.2.2.3.1" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.2.2.2.2.2.2.3.1.1" class="ltx_text">FUAR</span></span></span>
<span id="A10.T13.2.2.2.2.2.2.2.2" class="ltx_tr">
<span id="A10.T13.2.2.2.2.2.2.2.2.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><math id="A10.T13.1.1.1.1.1.1.1.1.1.m1.4" class="ltx_Math" alttext="\mathbf{{\left((IL),UL,NL\right)}}" display="inline"><semantics id="A10.T13.1.1.1.1.1.1.1.1.1.m1.4a"><mrow id="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.1" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml"><mo mathvariant="normal" id="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.1.2" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml">(</mo><mrow id="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.1.1.2" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml"><mo mathvariant="normal" stretchy="false" id="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.1.1.2.1" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml">(</mo><mi id="A10.T13.1.1.1.1.1.1.1.1.1.m1.1.1" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">𝐈𝐋</mi><mo mathvariant="normal" stretchy="false" id="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.1.1.2.2" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml">)</mo></mrow><mo mathvariant="normal" id="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.1.3" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml">,</mo><mi id="A10.T13.1.1.1.1.1.1.1.1.1.m1.2.2" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.2.2.cmml">𝐔𝐋</mi><mo mathvariant="normal" id="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.1.4" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml">,</mo><mi id="A10.T13.1.1.1.1.1.1.1.1.1.m1.3.3" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.3.3.cmml">𝐍𝐋</mi><mo mathvariant="normal" id="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.1.5" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="A10.T13.1.1.1.1.1.1.1.1.1.m1.4b"><vector id="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.2.cmml" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.4.4.1"><ci id="A10.T13.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.1.1">𝐈𝐋</ci><ci id="A10.T13.1.1.1.1.1.1.1.1.1.m1.2.2.cmml" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.2.2">𝐔𝐋</ci><ci id="A10.T13.1.1.1.1.1.1.1.1.1.m1.3.3.cmml" xref="A10.T13.1.1.1.1.1.1.1.1.1.m1.3.3">𝐍𝐋</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="A10.T13.1.1.1.1.1.1.1.1.1.m1.4c">\mathbf{{\left((IL),UL,NL\right)}}</annotation><annotation encoding="application/x-llamapun" id="A10.T13.1.1.1.1.1.1.1.1.1.m1.4d">( ( bold_IL ) , bold_UL , bold_NL )</annotation></semantics></math> <math id="A10.T13.2.2.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A10.T13.2.2.2.2.2.2.2.2.2.m2.1a"><mo mathvariant="normal" stretchy="false" id="A10.T13.2.2.2.2.2.2.2.2.2.m2.1.1" xref="A10.T13.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A10.T13.2.2.2.2.2.2.2.2.2.m2.1b"><ci id="A10.T13.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="A10.T13.2.2.2.2.2.2.2.2.2.m2.1.1">normal-↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A10.T13.2.2.2.2.2.2.2.2.2.m2.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="A10.T13.2.2.2.2.2.2.2.2.2.m2.1d">↓</annotation></semantics></math></span></span>
</span></span> <span id="A10.T13.2.2.2.2.3" class="ltx_text"></span></span>
</td>
</tr>
<tr id="A10.T13.2.3" class="ltx_tr">
<td id="A10.T13.2.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">EM</td>
<td id="A10.T13.2.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">EM</td>
<td id="A10.T13.2.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">EM</td>
<td id="A10.T13.2.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">EM</td>
</tr>
<tr id="A10.T13.2.4" class="ltx_tr">
<td id="A10.T13.2.4.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Initial</td>
<td id="A10.T13.2.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.4.2.1" class="ltx_text ltx_font_bold">24.88</span></td>
<td id="A10.T13.2.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">2.62</td>
<td id="A10.T13.2.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">3.19</td>
<td id="A10.T13.2.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">14.49</td>
<td id="A10.T13.2.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">-</td>
</tr>
<tr id="A10.T13.2.5" class="ltx_tr">
<td id="A10.T13.2.5.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Vanilla</td>
<td id="A10.T13.2.5.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">13.11</td>
<td id="A10.T13.2.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">11.89</td>
<td id="A10.T13.2.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">5.84</td>
<td id="A10.T13.2.5.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">22.53</td>
<td id="A10.T13.2.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">0.68</td>
</tr>
<tr id="A10.T13.2.6" class="ltx_tr">
<td id="A10.T13.2.6.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-RecAdam</td>
<td id="A10.T13.2.6.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.39</td>
<td id="A10.T13.2.6.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.33</td>
<td id="A10.T13.2.6.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">6.15</td>
<td id="A10.T13.2.6.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">22.68</td>
<td id="A10.T13.2.6.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">0.57</td>
</tr>
<tr id="A10.T13.2.7" class="ltx_tr">
<td id="A10.T13.2.7.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-MixReview</td>
<td id="A10.T13.2.7.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">14.09</td>
<td id="A10.T13.2.7.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">8.11</td>
<td id="A10.T13.2.7.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">4.80</td>
<td id="A10.T13.2.7.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">18.89</td>
<td id="A10.T13.2.7.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">1.10</td>
</tr>
<tr id="A10.T13.2.8" class="ltx_tr">
<td id="A10.T13.2.8.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-LoRA</td>
<td id="A10.T13.2.8.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">17.04</td>
<td id="A10.T13.2.8.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.8.3.1" class="ltx_text ltx_font_bold">14.50</span></td>
<td id="A10.T13.2.8.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.8.4.1" class="ltx_text ltx_font_bold">7.45</span></td>
<td id="A10.T13.2.8.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.8.5.1" class="ltx_text ltx_font_bold">24.59</span></td>
<td id="A10.T13.2.8.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">0.36</td>
</tr>
<tr id="A10.T13.2.9" class="ltx_tr">
<td id="A10.T13.2.9.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Kadapters (k=2)</td>
<td id="A10.T13.2.9.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.88</td>
<td id="A10.T13.2.9.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">13.67</td>
<td id="A10.T13.2.9.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.9.4.1" class="ltx_text ltx_framed_underline">7.43</span></td>
<td id="A10.T13.2.9.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">24.04</td>
<td id="A10.T13.2.9.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">0.22</td>
</tr>
<tr id="A10.T13.2.10" class="ltx_tr">
<td id="A10.T13.2.10.1" class="ltx_td ltx_align_left" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Kadapters (k=3)</td>
<td id="A10.T13.2.10.2" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">19.91</td>
<td id="A10.T13.2.10.3" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.10.3.1" class="ltx_text ltx_framed_underline">14.31</span></td>
<td id="A10.T13.2.10.4" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">6.55</td>
<td id="A10.T13.2.10.5" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;">23.33</td>
<td id="A10.T13.2.10.6" class="ltx_td ltx_align_center" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.10.6.1" class="ltx_text ltx_framed_underline">0.21</span></td>
</tr>
<tr id="A10.T13.2.11" class="ltx_tr">
<td id="A10.T13.2.11.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">T5-Modular</td>
<td id="A10.T13.2.11.2" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.11.2.1" class="ltx_text ltx_framed_underline">21.35</span></td>
<td id="A10.T13.2.11.3" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">12.78</td>
<td id="A10.T13.2.11.4" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;">6.94</td>
<td id="A10.T13.2.11.5" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.11.5.1" class="ltx_text ltx_framed_underline">24.42</span></td>
<td id="A10.T13.2.11.6" class="ltx_td ltx_align_center ltx_border_bb" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A10.T13.2.11.6.1" class="ltx_text ltx_font_bold">0.17</span></td>
</tr>
</tbody></table>
</figure>
<figure id="A10.F9" class="ltx_figure">
<div class="ltx_flex_figure">

<div class="ltx_flex_cell 
                  ltx_flex_size_1">
<figure id="A10.F9.1" class="ltx_figure ltx_flex_size_1 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x12.png" id="A10.F9.1.g1" class="ltx_graphics ltx_img_landscape" width="761" height="51" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell 
                  ltx_flex_size_4">
<figure id="A10.F8.sf1" class="ltx_figure ltx_flex_size_4 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x13.png" id="A10.F8.sf1.g1" class="ltx_graphics ltx_img_landscape" width="761" height="456" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a)</span><span class="ltx_text ltx_font_smallcaps" id="A10.F8.sf1.2.1">InvariantLAMA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell 
                  ltx_flex_size_4">
<figure id="A10.F8.sf2" class="ltx_figure ltx_flex_size_4 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x14.png" id="A10.F8.sf2.g1" class="ltx_graphics ltx_img_landscape" width="761" height="456" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b)</span><span class="ltx_text ltx_font_smallcaps" id="A10.F8.sf2.2.1">UpdatedLAMA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell 
                  ltx_flex_size_4">
<figure id="A10.F8.sf3" class="ltx_figure ltx_flex_size_4 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x15.png" id="A10.F8.sf3.g1" class="ltx_graphics ltx_img_landscape" width="761" height="456" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span><span id="A10.F8.sf3.2.1" class="ltx_text ltx_font_smallcaps">NewLAMA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell 
                  ltx_flex_size_4">
<figure id="A10.F8.sf4" class="ltx_figure ltx_flex_size_4 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2110.03215/assets/x16.png" id="A10.F8.sf4.g1" class="ltx_graphics ltx_img_landscape" width="761" height="456" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(d)</span><span class="ltx_text ltx_font_smallcaps" id="A10.F8.sf4.2.1">NewLAMA-Easy</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9:</span>Mean P@k curve for CKL benchmark with varying k.</figcaption>
</figure>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2110.03214" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2110.03215" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2110.03215">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2110.03215" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2110.03217" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Dec 14 17:43:02 2022 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>