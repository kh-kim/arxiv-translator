<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2403.13187] Evolutionary Optimization of Model Merging Recipes</title><meta property="og:description" content="We present a novel application of evolutionary algorithms to automate the creation of powerful foundation models. While model merging has emerged as a promising approach for LLM development due to its cost-effectivenes…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Evolutionary Optimization of Model Merging Recipes">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Evolutionary Optimization of Model Merging Recipes">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2403.13187">

<!--Generated on Fri Apr  5 14:12:03 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Evolutionary Optimization of Model Merging Recipes</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Takuya Akiba, Makoto Shing, Yujin Tang, Qi Sun, David Ha
<br class="ltx_break">Sakana AI
<br class="ltx_break">Tokyo, Japan
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">{takiba,mkshing,yujintang,qisun,hadavid}@sakana.ai</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">We present a novel application of evolutionary algorithms to automate the creation of powerful foundation models. While model merging has emerged as a promising approach for LLM development due to its cost-effectiveness, it currently relies on human intuition and domain knowledge, limiting its potential. Here, we propose an evolutionary approach that overcomes this limitation by automatically discovering effective combinations of diverse open-source models, harnessing their collective intelligence without requiring extensive additional training data or compute. Our approach operates in both parameter space and data flow space, allowing for optimization beyond just the weights of the individual models. This approach even facilitates cross-domain merging, generating models like a Japanese LLM with Math reasoning capabilities. Surprisingly, our Japanese Math LLM achieved state-of-the-art performance on a variety of established Japanese LLM benchmarks, even surpassing models with significantly more parameters, despite not being explicitly trained for such tasks. Furthermore, a culturally-aware Japanese VLM generated through our approach demonstrates its effectiveness in describing Japanese culture-specific content, outperforming previous Japanese VLMs. This work not only contributes new state-of-the-art models back to the open-source community, but also introduces a new paradigm for automated model composition, paving the way for exploring alternative, efficient approaches to foundation model development.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><span id="footnote1.1" class="ltx_text ltx_font_typewriter">EvoLLM-JP</span>, <span id="footnote1.2" class="ltx_text ltx_font_typewriter">EvoVLM-JP</span> release: <a target="_blank" href="https://github.com/SakanaAI/evolutionary-model-merge" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/SakanaAI/evolutionary-model-merge</a></span></span></span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Model merging&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>, <a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>]</cite>, a recent development in the large language model (LLM) community, presents a novel paradigm shift. By strategically combining multiple LLMs into a single architecture, this exciting development has captured the attention of researchers due to its key advantage: it requires no additional training, making it an incredibly cost-effective approach for developing new models. This accessibility has fueled a surge in interest and experimentation with model merging. The Open LLM Leaderboard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite> is now dominated by merged models, showcasing its potential for democratizing foundation model development.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">However, model merging is considered by many to be a form of black art or alchemy, relying on the model maker’s intuition and instincts about model selection and merging recipes to create and refine a new model that performs well for a particular task. Furthermore, the model maker is often required to have some domain knowledge for the various different benchmark tasks.
Given the large diversity of open models and benchmarks in the community, human intuition can only go so far, and we believe a more systematic approach for discovering new model combinations will take things much further.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">We believe evolutionary algorithms will be able to discover more effective model merging solutions, and thus provide a path for automating the creation of more capable models.
As a step towards this direction, in this work, we show that evolution can be employed to discover novel and unintuitive ways to merge various models to produce new models with a new combined ability.
In this work, we present a methodology that leverages evolutionary algorithms to facilitate the merging of foundation models. Our approach is distinguished by its ability to navigate both parameter space (weights) and the data flow space (inference path), proposing a framework that integrates these two dimensions.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">This work makes several key contributions to the field of foundation model development:</p>
</div>
<div id="S1.p5" class="ltx_para">
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p"><span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Automated Model Composition</span>: We introduce <span id="S1.I1.i1.p1.1.2" class="ltx_text ltx_font_bold">Evolutionary Model Merge</span>, a general evolutionary method to automatically discover optimal combinations of diverse open-source models for creating new foundation models with user-specified capabilities. This approach harnesses the collective intelligence of existing open models, enabling the creation of powerful models without the need for extensive training data or compute.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p"><span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Cross-Domain Merging</span>: We demonstrate that our method can discover novel ways to merge models from disparate domains (e.g., non-English language and Math, non-English language and Vision), potentially exceeding the capabilities achievable through conventional human design strategies.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p"><span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">State-of-the-Art Performance</span>: We showcase the effectiveness of our method by automatically generating a Japanese LLM with Math reasoning capability and a Japanese Vision-Language Model (VLM). Notably, both models achieve state-of-the-art performance on various benchmarks, even without explicit optimization for those tasks.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p"><span id="S1.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">High Efficiency and Surprising Generalizability</span>: We observe that our 7B parameter LLM surpasses the performance of some previous 70B parameter Japanese LLMs on benchmark datasets, highlighting the high efficiency and surprising generalization capability of our approach. We believe this model can serve as a strong general-purpose Japanese LLM.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p"><span id="S1.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Culturally-Aware VLM</span>: The generated Japanese VLM achieves top results when tested on a domestically-sourced dataset of Japanese image-description pairs, demonstrating its ability to handle Japanese culture-specific content.</p>
</div>
</li>
</ol>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">We are committed to open science and are excited to open-sourcing our <span id="S1.p6.1.1" class="ltx_text ltx_font_typewriter">EvoLLM-JP</span> and <span id="S1.p6.1.2" class="ltx_text ltx_font_typewriter">EvoVLM-JP</span>, two state-of-the-art Japanese foundation models, to the community, enabling further research and development in the field. Our work challenges the conventional paradigm of expensive model development by demonstrating that our evolutionary-based method can produce competitive models without relying on gradient-based training. This paves the way for exploring alternative, potentially more efficient, approaches to foundation model development.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Related Work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Overview of Model Merging</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Model merging offers a novel approach to leverage the strengths of multiple pre-trained models. It allows us to combine task-specific models, each potentially fine-tuned for a particular downstream task, into a single unified model. This technique stands in contrast to traditional transfer learning, where a pre-trained model is further fine-tuned for a new task. While transfer learning offers advantages like improved performance and faster convergence, the resulting models are typically limited to single tasks. Model merging, on the other hand, strives to create a versatile and comprehensive model by combining the knowledge from multiple pre-trained models, potentially yielding a model capable of handling various tasks simultaneously.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">A simple method of merging multiple models is to average the weights of multiple models fine-tuned from the same base initial model. This <span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_italic">model soup</span> approach&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">49</span></a>]</cite> demonstrated significant improvements on relatively large image processing and image classification models. The work pointed to similarity between weighted model averaging leading to a flat local minima. Theoretical&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>, <a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>, <a href="#bib.bib38" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">38</span></a>, <a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>]</cite> and empirical studies dating back from the 1990s&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>, <a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>]</cite> demonstrated that flatter local optima generalize better to out-of-distribution shifts. More recent work&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">35</span></a>, <a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>]</cite> examined the theoretical properties and practical implications of weight averaging applied to larger generative models.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">Linear weight averaging not only works well for image processing and classification models, but is also effective for image generation models such as latent diffusion models. The release of Stable Diffusion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">40</span></a>]</cite> led to a variety of specialist fine-tunes of the model for a variety of different styles, from photorealism, to anime, to realistic painting styles. Popular open-source WebUIs&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite> enabled hobbyists to experiment with merging different models using linear or spherical linear interpolation (SLERP)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">48</span></a>]</cite> of weight parameters of distinct fine-tuned Stable Diffusion models. This has led to the discovery of merged models that combine strengths of specialized models into a single model.
For some time, the most popular Stable Diffusion models were neither the original base models nor the fine-tuned versions, but rather the merged models created by enthusiasts. This trend persists until the release of a more advanced base model, at which point the community’s cycle of fine-tuning and merging is renewed.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Merging Language Models</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Simple weight interpolation works well for merging image generation models that operate in a real valued latent and output space, but to our surprise, they also still work for merging language models under the right conditions, but have performance issues&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>. Recently, new methods have been proposed to address merging language models specifically. One method, Task Arithmetic&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite>, involves building <span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">task vectors</span> by subtracting pre-trained from fine-tuned model weights, enabling manipulation through arithmetic operations to steer the merged model’s behavior.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">A key problem of weight interpolation-based methods is that they neglect parameter interference, leading to performance degradation. A recent work&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite> identifies two key sources of interference: redundant parameter values and conflicting parameter signs across models, and proposes a method that addresses these issues to achieve improved merging performance. The proposed TIES-Merging method addresses information loss in existing merging methods by incorporating three steps: resetting minimal parameter changes, resolving sign conflicts, and merging only aligned parameters.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Another recent work&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite> proposes the DARE method goes further by zeroing out small differences between the fine-tuned model and the original base model, while amplifying the differences. In practice, DARE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite> is often used together with Task Arithmetic&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite> or TIES-Merging&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">Image generation model merging really took off in the community only after such methods were implemented in open-source toolkits&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite>. Similarly, language model merging really gained popularity after the implementation of <span id="S2.SS2.p4.1.1" class="ltx_text ltx_font_italic">mergekit</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>, <a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>]</cite>. This toolkit provides all of the popular <span id="S2.SS2.p4.1.2" class="ltx_text ltx_font_italic">recipes</span> for merging language models. In addition to simple linear and spherical interpolation, advanced recipes such as Task Arithmetic, TIES-Merging, DARE are also implemented, offering users the ability to experiment with combining these methods to work with fine-tunes of popular base models such as Mistral&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite>. With this toolkit, a large number of capable merged models are developed by the community, and most of the top models on the Open LLM Leaderboard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite> are gradually dominated by merged models produced by the community of language model enthusiasts.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p id="S2.SS2.p5.1" class="ltx_p">Mergekit also introduced an additional method, called <span id="S2.SS2.p5.1.1" class="ltx_text ltx_font_italic">Frankenmerging</span> which is not based on weight merging, but for the user to experiment with trying to stack different layers from multiple models to sequentially create a new model. This method has the advantage of not tying the user to one particular family of models with a fixed architecture for merging (e.g. Mistral-based models), but potentially creating <span id="S2.SS2.p5.1.2" class="ltx_text ltx_font_italic">new</span> architectures from merging entirely different models. It is noted that discovering new <span id="S2.SS2.p5.1.3" class="ltx_text ltx_font_italic">Frankenmerging</span> technique remains a challenge for the community, and requires much more trial and error to discover new recipes for this technique. To date, almost everyone uses a similar <span id="S2.SS2.p5.1.4" class="ltx_text ltx_font_italic">Frankenmerging</span> merge recipe, and there has been very little trial and error to improve upon it. The field remains highly under-explored, and we believe this is where evolution can help.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Connection to Evolutionary Neural Architecture Search</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Model merging holds significant potential and democratizes the model-building process, making it accessible to a broad range of participants. However, it heavily relies on intuition and domain knowledge. Human intuition, however, has its limits. With the growing diversity of open models and tasks, we need a more systematic approach. We believe evolutionary algorithms, inspired by natural selection, can unlock more effective merging solutions. These algorithms can explore a vast space of possibilities, discovering novel and counter-intuitive combinations that traditional methods and human intuition might miss.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">In deep learning, techniques such as Neural Architecture Search (NAS)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite> employed evolutionary techniques to discover new architectures&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">39</span></a>, <a href="#bib.bib45" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite> that might be non-intuitive for human designers to discover. However, NAS-methods consumed significant computational resources given how each candidate model architecture needed to be trained. Our approach aims to <span id="S2.SS3.p2.1.1" class="ltx_text ltx_font_italic">save</span> compute resources by discovering structures that take advantage of existing capabilities of existing Transformer blocks that had already consumed considerable resources to train in the first place.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">Pre-trained transformer blocks are akin to neural network components one can choose to mix and match using an evolutionary architecture search algorithm. However, unlike NAS, we do not need to train the model, and can evaluate the candidates right away. In a sense, our work resonates with the goals of earlier works of morphology search such as NEAT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">46</span></a>]</cite> and more recent work such as Weight Agnostic Neural Networks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>]</cite> which evolved neural network structures with certain task-specific inductive biases, without the need to train the weight parameters using gradient descent. Similarly, this was how NAS methods such as SMASH&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">46</span></a>]</cite> avoided costly inner-loop training through the application of a Hypernetwork&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite> to estimate the weights of architectural candidates.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p">In this work, we apply evolution to not only automate the optimization of model merging recipes in weight space, confined to a single architecture, but also explore applying evolution to optimize the stacking of layers from different models—a more involved approach that has the potential to create entirely novel neural architectures from existing building blocks. Unlike weight merging optimization which confine space of models to be merged together to fine-tuned descendents of the same parent base model, layer stacking optimization has no such constraints. Our work systematically explores the application of evolution applied in both parameter and layer space.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Our goal is to create a unified framework capable of automatically generating a merged model from a selection of foundation models, ensuring that the performance of this merged model surpasses that of any individual in the collection. Central to our approach is the application of evolutionary algorithms, which we employ to refine the intricacies involved in model merging. To systematically address this challenge, we first dissect the merging process into two distinct, orthogonal configuration spaces, analyzing their individual impacts. Building on this analysis, we then introduce a cohesive framework that seamlessly integrates these spaces. Figure&nbsp;<a href="#S3.F1" title="Figure 1 ‣ 3 Method ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> provides a schematic representation of our approach.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2403.13187/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="224" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span id="S3.F1.2.1" class="ltx_text ltx_font_bold">Overview of Evolutionary Model Merge</span>. Our approach encompasses (1) evolving the weights for mixing parameters at each layer in the parameter space (PS); (2) evolving layer permutations in the data flow space (DFS); and (3) an integrated strategy that combines both methods for merging in both PS and DFS. Notice that merging in the PS is not simple copying and stitching of the layers parameters, but also mixes the weights. This merging is akin to blending colors as illustrated here (e.g., red and blue becomes purple). Note that we translated the questions to English for the reader; the models operate on Japanese text.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Merging in the Parameter Space</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Model merging in the parameter space (PS) aims to integrate the weights of multiple foundational models into a unified entity with the same neural network architecture, yet outperforming the individual models. While various strategies for combining model parameters exist&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">35</span></a>, <a href="#bib.bib49" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">49</span></a>]</cite>, our approach leverages task vectors analysis to understand each model’s strengths, based on the specific tasks they are optimized for or excel in&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite>. Specifically, we enhance TIES-Merging with DARE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>, <a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite>, allowing for more granular, layer-wise merging (In this paper, by “layer” we mean the input/output embedding layers or a transformer block). We establish merging configuration parameters for sparsification and weight mixing at each layer, including input and output embeddings. These configurations are then optimized using an evolutionary algorithm, such as CMA-ES&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite>, for selected tasks, guided by critical task-specific metrics (e.g., accuracy for MGSM, ROUGE score for VQA).</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Merging in the Data Flow Space</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.4" class="ltx_p">Recent analysis and discoveries imply that knowledge is stored distributedly in language models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>, <a href="#bib.bib37" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">37</span></a>, <a href="#bib.bib36" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">36</span></a>]</cite>, suggesting simple yet novel model merging possibilities in the data flow space (DFS). Unlike merging in PS, model merging in DFS preserves the original weights of each layer intact. Instead, it optimizes the inference path that tokens follow as they traverse through the neural network. For example, after the <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">i</annotation></semantics></math>-th layer in model <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">A</annotation></semantics></math>, a token may be directed to the <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">j</annotation></semantics></math>-th layer in model <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">B</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.7" class="ltx_p">In our initial effort in this domain, we limit ourselves to serial connections and non-adaptive configurations, deferring the investigation of more flexible model merging to future work. Concretely, with a collection of <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">N</annotation></semantics></math> models and a budget <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">T</annotation></semantics></math>, our method searches for a sequence of layer indices <math id="S3.SS2.p2.3.m3.3" class="ltx_Math" alttext="L_{i,j}^{(t)}" display="inline"><semantics id="S3.SS2.p2.3.m3.3a"><msubsup id="S3.SS2.p2.3.m3.3.4" xref="S3.SS2.p2.3.m3.3.4.cmml"><mi id="S3.SS2.p2.3.m3.3.4.2.2" xref="S3.SS2.p2.3.m3.3.4.2.2.cmml">L</mi><mrow id="S3.SS2.p2.3.m3.2.2.2.4" xref="S3.SS2.p2.3.m3.2.2.2.3.cmml"><mi id="S3.SS2.p2.3.m3.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p2.3.m3.2.2.2.4.1" xref="S3.SS2.p2.3.m3.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p2.3.m3.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.cmml">j</mi></mrow><mrow id="S3.SS2.p2.3.m3.3.3.1.3" xref="S3.SS2.p2.3.m3.3.4.cmml"><mo stretchy="false" id="S3.SS2.p2.3.m3.3.3.1.3.1" xref="S3.SS2.p2.3.m3.3.4.cmml">(</mo><mi id="S3.SS2.p2.3.m3.3.3.1.1" xref="S3.SS2.p2.3.m3.3.3.1.1.cmml">t</mi><mo stretchy="false" id="S3.SS2.p2.3.m3.3.3.1.3.2" xref="S3.SS2.p2.3.m3.3.4.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.3b"><apply id="S3.SS2.p2.3.m3.3.4.cmml" xref="S3.SS2.p2.3.m3.3.4"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.3.4.1.cmml" xref="S3.SS2.p2.3.m3.3.4">superscript</csymbol><apply id="S3.SS2.p2.3.m3.3.4.2.cmml" xref="S3.SS2.p2.3.m3.3.4"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.3.4.2.1.cmml" xref="S3.SS2.p2.3.m3.3.4">subscript</csymbol><ci id="S3.SS2.p2.3.m3.3.4.2.2.cmml" xref="S3.SS2.p2.3.m3.3.4.2.2">𝐿</ci><list id="S3.SS2.p2.3.m3.2.2.2.3.cmml" xref="S3.SS2.p2.3.m3.2.2.2.4"><ci id="S3.SS2.p2.3.m3.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1">𝑖</ci><ci id="S3.SS2.p2.3.m3.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2">𝑗</ci></list></apply><ci id="S3.SS2.p2.3.m3.3.3.1.1.cmml" xref="S3.SS2.p2.3.m3.3.3.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.3c">L_{i,j}^{(t)}</annotation></semantics></math> that delineates the path all the tokens should follow for a specific task. Here <math id="S3.SS2.p2.4.m4.2" class="ltx_Math" alttext="L_{i,j}" display="inline"><semantics id="S3.SS2.p2.4.m4.2a"><msub id="S3.SS2.p2.4.m4.2.3" xref="S3.SS2.p2.4.m4.2.3.cmml"><mi id="S3.SS2.p2.4.m4.2.3.2" xref="S3.SS2.p2.4.m4.2.3.2.cmml">L</mi><mrow id="S3.SS2.p2.4.m4.2.2.2.4" xref="S3.SS2.p2.4.m4.2.2.2.3.cmml"><mi id="S3.SS2.p2.4.m4.1.1.1.1" xref="S3.SS2.p2.4.m4.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p2.4.m4.2.2.2.4.1" xref="S3.SS2.p2.4.m4.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p2.4.m4.2.2.2.2" xref="S3.SS2.p2.4.m4.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.2b"><apply id="S3.SS2.p2.4.m4.2.3.cmml" xref="S3.SS2.p2.4.m4.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.2.3.1.cmml" xref="S3.SS2.p2.4.m4.2.3">subscript</csymbol><ci id="S3.SS2.p2.4.m4.2.3.2.cmml" xref="S3.SS2.p2.4.m4.2.3.2">𝐿</ci><list id="S3.SS2.p2.4.m4.2.2.2.3.cmml" xref="S3.SS2.p2.4.m4.2.2.2.4"><ci id="S3.SS2.p2.4.m4.1.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1.1.1">𝑖</ci><ci id="S3.SS2.p2.4.m4.2.2.2.2.cmml" xref="S3.SS2.p2.4.m4.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.2c">L_{i,j}</annotation></semantics></math> denotes the <math id="S3.SS2.p2.5.m5.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS2.p2.5.m5.1a"><mi id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><ci id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">j</annotation></semantics></math>-th layer in the <math id="S3.SS2.p2.6.m6.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.p2.6.m6.1a"><mi id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><ci id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">i</annotation></semantics></math>-th model, with <math id="S3.SS2.p2.7.m7.2" class="ltx_Math" alttext="t\in[1,T]" display="inline"><semantics id="S3.SS2.p2.7.m7.2a"><mrow id="S3.SS2.p2.7.m7.2.3" xref="S3.SS2.p2.7.m7.2.3.cmml"><mi id="S3.SS2.p2.7.m7.2.3.2" xref="S3.SS2.p2.7.m7.2.3.2.cmml">t</mi><mo id="S3.SS2.p2.7.m7.2.3.1" xref="S3.SS2.p2.7.m7.2.3.1.cmml">∈</mo><mrow id="S3.SS2.p2.7.m7.2.3.3.2" xref="S3.SS2.p2.7.m7.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.p2.7.m7.2.3.3.2.1" xref="S3.SS2.p2.7.m7.2.3.3.1.cmml">[</mo><mn id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml">1</mn><mo id="S3.SS2.p2.7.m7.2.3.3.2.2" xref="S3.SS2.p2.7.m7.2.3.3.1.cmml">,</mo><mi id="S3.SS2.p2.7.m7.2.2" xref="S3.SS2.p2.7.m7.2.2.cmml">T</mi><mo stretchy="false" id="S3.SS2.p2.7.m7.2.3.3.2.3" xref="S3.SS2.p2.7.m7.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.2b"><apply id="S3.SS2.p2.7.m7.2.3.cmml" xref="S3.SS2.p2.7.m7.2.3"><in id="S3.SS2.p2.7.m7.2.3.1.cmml" xref="S3.SS2.p2.7.m7.2.3.1"></in><ci id="S3.SS2.p2.7.m7.2.3.2.cmml" xref="S3.SS2.p2.7.m7.2.3.2">𝑡</ci><interval closure="closed" id="S3.SS2.p2.7.m7.2.3.3.1.cmml" xref="S3.SS2.p2.7.m7.2.3.3.2"><cn type="integer" id="S3.SS2.p2.7.m7.1.1.cmml" xref="S3.SS2.p2.7.m7.1.1">1</cn><ci id="S3.SS2.p2.7.m7.2.2.cmml" xref="S3.SS2.p2.7.m7.2.2">𝑇</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.2c">t\in[1,T]</annotation></semantics></math> marking the step in the inference path.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.7" class="ltx_p">One can quickly imagine how large the search space is. Assuming the total number of layers across all models is <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">M</annotation></semantics></math>, the size of the search space is <math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="(M+1)^{T}" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><msup id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mrow id="S3.SS2.p3.2.m2.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.p3.2.m2.1.1.1.1.2" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.2.m2.1.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.2" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml">M</mi><mo id="S3.SS2.p3.2.m2.1.1.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.1.cmml">+</mo><mn id="S3.SS2.p3.2.m2.1.1.1.1.1.3" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="S3.SS2.p3.2.m2.1.1.1.1.3" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml">)</mo></mrow><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">T</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1"><plus id="S3.SS2.p3.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.1"></plus><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2">𝑀</ci><cn type="integer" id="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3">1</cn></apply><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">(M+1)^{T}</annotation></semantics></math>, here the extra one indicates the inclusion of a pass-through layer. Even with a modest setting of <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="M=64" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><mrow id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">M</mi><mo id="S3.SS2.p3.3.m3.1.1.1" xref="S3.SS2.p3.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><eq id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1"></eq><ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">𝑀</ci><cn type="integer" id="S3.SS2.p3.3.m3.1.1.3.cmml" xref="S3.SS2.p3.3.m3.1.1.3">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">M=64</annotation></semantics></math> (e.g., 2 models of 32 layers each) and <math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="T=60" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><mrow id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">T</mi><mo id="S3.SS2.p3.4.m4.1.1.1" xref="S3.SS2.p3.4.m4.1.1.1.cmml">=</mo><mn id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml">60</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><eq id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1"></eq><ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">𝑇</ci><cn type="integer" id="S3.SS2.p3.4.m4.1.1.3.cmml" xref="S3.SS2.p3.4.m4.1.1.3">60</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">T=60</annotation></semantics></math>, this setting translates to an astronomically large search space, a challenge even for a capable evolutionary search algorithm. Luckily, our preliminary studies indicated that certain layer arrangements, particularly repetitive or permuted sequences from earlier in the model, can adversely affect performance. Based on this, we modify our settings to include an indicator array <math id="S3.SS2.p3.5.m5.1" class="ltx_Math" alttext="\mathcal{I}" display="inline"><semantics id="S3.SS2.p3.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">\mathcal{I}</annotation></semantics></math> of size <math id="S3.SS2.p3.6.m6.1" class="ltx_Math" alttext="T=M\times r" display="inline"><semantics id="S3.SS2.p3.6.m6.1a"><mrow id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2.cmml">T</mi><mo id="S3.SS2.p3.6.m6.1.1.1" xref="S3.SS2.p3.6.m6.1.1.1.cmml">=</mo><mrow id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml"><mi id="S3.SS2.p3.6.m6.1.1.3.2" xref="S3.SS2.p3.6.m6.1.1.3.2.cmml">M</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.6.m6.1.1.3.1" xref="S3.SS2.p3.6.m6.1.1.3.1.cmml">×</mo><mi id="S3.SS2.p3.6.m6.1.1.3.3" xref="S3.SS2.p3.6.m6.1.1.3.3.cmml">r</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><eq id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1.1"></eq><ci id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">𝑇</ci><apply id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3"><times id="S3.SS2.p3.6.m6.1.1.3.1.cmml" xref="S3.SS2.p3.6.m6.1.1.3.1"></times><ci id="S3.SS2.p3.6.m6.1.1.3.2.cmml" xref="S3.SS2.p3.6.m6.1.1.3.2">𝑀</ci><ci id="S3.SS2.p3.6.m6.1.1.3.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">T=M\times r</annotation></semantics></math> in the evolutionary search space, here <math id="S3.SS2.p3.7.m7.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS2.p3.7.m7.1a"><mi id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><ci id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">r</annotation></semantics></math> is number of repetitions.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.6" class="ltx_p">Conceptually, we layout all the layers in sequential order (i.e., all layers in the <math id="S3.SS2.p4.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">i</annotation></semantics></math>-th model followed by those in the <math id="S3.SS2.p4.2.m2.1" class="ltx_Math" alttext="i+1" display="inline"><semantics id="S3.SS2.p4.2.m2.1a"><mrow id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2" xref="S3.SS2.p4.2.m2.1.1.2.cmml">i</mi><mo id="S3.SS2.p4.2.m2.1.1.1" xref="S3.SS2.p4.2.m2.1.1.1.cmml">+</mo><mn id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><plus id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1.1"></plus><ci id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2">𝑖</ci><cn type="integer" id="S3.SS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.p4.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">i+1</annotation></semantics></math>-th model) and repeat them <math id="S3.SS2.p4.3.m3.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS2.p4.3.m3.1a"><mi id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><ci id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">r</annotation></semantics></math> times, the indicator array then manages the inclusion/exclusion of layers. If <math id="S3.SS2.p4.4.m4.1" class="ltx_Math" alttext="\mathcal{I}_{i}>0" display="inline"><semantics id="S3.SS2.p4.4.m4.1a"><mrow id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml"><msub id="S3.SS2.p4.4.m4.1.1.2" xref="S3.SS2.p4.4.m4.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.4.m4.1.1.2.2" xref="S3.SS2.p4.4.m4.1.1.2.2.cmml">ℐ</mi><mi id="S3.SS2.p4.4.m4.1.1.2.3" xref="S3.SS2.p4.4.m4.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS2.p4.4.m4.1.1.1" xref="S3.SS2.p4.4.m4.1.1.1.cmml">&gt;</mo><mn id="S3.SS2.p4.4.m4.1.1.3" xref="S3.SS2.p4.4.m4.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><apply id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1"><gt id="S3.SS2.p4.4.m4.1.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1.1"></gt><apply id="S3.SS2.p4.4.m4.1.1.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.2.1.cmml" xref="S3.SS2.p4.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.p4.4.m4.1.1.2.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2.2">ℐ</ci><ci id="S3.SS2.p4.4.m4.1.1.2.3.cmml" xref="S3.SS2.p4.4.m4.1.1.2.3">𝑖</ci></apply><cn type="integer" id="S3.SS2.p4.4.m4.1.1.3.cmml" xref="S3.SS2.p4.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">\mathcal{I}_{i}&gt;0</annotation></semantics></math> we include the layer corresponding to index <math id="S3.SS2.p4.5.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.p4.5.m5.1a"><mi id="S3.SS2.p4.5.m5.1.1" xref="S3.SS2.p4.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m5.1b"><ci id="S3.SS2.p4.5.m5.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m5.1c">i</annotation></semantics></math> in the slots in the merged model, otherwise we exclude it. Consequently, our search space is reduced to <math id="S3.SS2.p4.6.m6.1" class="ltx_Math" alttext="2^{T}" display="inline"><semantics id="S3.SS2.p4.6.m6.1a"><msup id="S3.SS2.p4.6.m6.1.1" xref="S3.SS2.p4.6.m6.1.1.cmml"><mn id="S3.SS2.p4.6.m6.1.1.2" xref="S3.SS2.p4.6.m6.1.1.2.cmml">2</mn><mi id="S3.SS2.p4.6.m6.1.1.3" xref="S3.SS2.p4.6.m6.1.1.3.cmml">T</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.6.m6.1b"><apply id="S3.SS2.p4.6.m6.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.6.m6.1.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1">superscript</csymbol><cn type="integer" id="S3.SS2.p4.6.m6.1.1.2.cmml" xref="S3.SS2.p4.6.m6.1.1.2">2</cn><ci id="S3.SS2.p4.6.m6.1.1.3.cmml" xref="S3.SS2.p4.6.m6.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.6.m6.1c">2^{T}</annotation></semantics></math>, which is still large, but tractable for evolutionary search.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.5" class="ltx_p">In our search, we only optimize the data inference path inside the merged model and keep parameters in the models intact. In this setting, a layer may face an input whose distribution is different from what it is used to (from its original model), leading to unexpected outputs. For example, our preliminary studies show that swapping a pair of neighboring layers in a language model makes its performance drop. Although more theoretical studies are needed to model the distribution shift, empirically we find that appropriately scaling an input that wishes to go from layer <math id="S3.SS2.p5.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS2.p5.1.m1.1a"><mi id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">i</annotation></semantics></math> to <math id="S3.SS2.p5.2.m2.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS2.p5.2.m2.1a"><mi id="S3.SS2.p5.2.m2.1.1" xref="S3.SS2.p5.2.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.1b"><ci id="S3.SS2.p5.2.m2.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.1c">j</annotation></semantics></math> by <math id="S3.SS2.p5.3.m3.1" class="ltx_Math" alttext="W_{ij}" display="inline"><semantics id="S3.SS2.p5.3.m3.1a"><msub id="S3.SS2.p5.3.m3.1.1" xref="S3.SS2.p5.3.m3.1.1.cmml"><mi id="S3.SS2.p5.3.m3.1.1.2" xref="S3.SS2.p5.3.m3.1.1.2.cmml">W</mi><mrow id="S3.SS2.p5.3.m3.1.1.3" xref="S3.SS2.p5.3.m3.1.1.3.cmml"><mi id="S3.SS2.p5.3.m3.1.1.3.2" xref="S3.SS2.p5.3.m3.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p5.3.m3.1.1.3.1" xref="S3.SS2.p5.3.m3.1.1.3.1.cmml">​</mo><mi id="S3.SS2.p5.3.m3.1.1.3.3" xref="S3.SS2.p5.3.m3.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.3.m3.1b"><apply id="S3.SS2.p5.3.m3.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.3.m3.1.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p5.3.m3.1.1.2.cmml" xref="S3.SS2.p5.3.m3.1.1.2">𝑊</ci><apply id="S3.SS2.p5.3.m3.1.1.3.cmml" xref="S3.SS2.p5.3.m3.1.1.3"><times id="S3.SS2.p5.3.m3.1.1.3.1.cmml" xref="S3.SS2.p5.3.m3.1.1.3.1"></times><ci id="S3.SS2.p5.3.m3.1.1.3.2.cmml" xref="S3.SS2.p5.3.m3.1.1.3.2">𝑖</ci><ci id="S3.SS2.p5.3.m3.1.1.3.3.cmml" xref="S3.SS2.p5.3.m3.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.3.m3.1c">W_{ij}</annotation></semantics></math> help alleviate the problem. Here, <math id="S3.SS2.p5.4.m4.1" class="ltx_Math" alttext="W\in\mathcal{R}^{M\times M}" display="inline"><semantics id="S3.SS2.p5.4.m4.1a"><mrow id="S3.SS2.p5.4.m4.1.1" xref="S3.SS2.p5.4.m4.1.1.cmml"><mi id="S3.SS2.p5.4.m4.1.1.2" xref="S3.SS2.p5.4.m4.1.1.2.cmml">W</mi><mo id="S3.SS2.p5.4.m4.1.1.1" xref="S3.SS2.p5.4.m4.1.1.1.cmml">∈</mo><msup id="S3.SS2.p5.4.m4.1.1.3" xref="S3.SS2.p5.4.m4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p5.4.m4.1.1.3.2" xref="S3.SS2.p5.4.m4.1.1.3.2.cmml">ℛ</mi><mrow id="S3.SS2.p5.4.m4.1.1.3.3" xref="S3.SS2.p5.4.m4.1.1.3.3.cmml"><mi id="S3.SS2.p5.4.m4.1.1.3.3.2" xref="S3.SS2.p5.4.m4.1.1.3.3.2.cmml">M</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p5.4.m4.1.1.3.3.1" xref="S3.SS2.p5.4.m4.1.1.3.3.1.cmml">×</mo><mi id="S3.SS2.p5.4.m4.1.1.3.3.3" xref="S3.SS2.p5.4.m4.1.1.3.3.3.cmml">M</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.4.m4.1b"><apply id="S3.SS2.p5.4.m4.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1"><in id="S3.SS2.p5.4.m4.1.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1.1"></in><ci id="S3.SS2.p5.4.m4.1.1.2.cmml" xref="S3.SS2.p5.4.m4.1.1.2">𝑊</ci><apply id="S3.SS2.p5.4.m4.1.1.3.cmml" xref="S3.SS2.p5.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p5.4.m4.1.1.3.1.cmml" xref="S3.SS2.p5.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS2.p5.4.m4.1.1.3.2.cmml" xref="S3.SS2.p5.4.m4.1.1.3.2">ℛ</ci><apply id="S3.SS2.p5.4.m4.1.1.3.3.cmml" xref="S3.SS2.p5.4.m4.1.1.3.3"><times id="S3.SS2.p5.4.m4.1.1.3.3.1.cmml" xref="S3.SS2.p5.4.m4.1.1.3.3.1"></times><ci id="S3.SS2.p5.4.m4.1.1.3.3.2.cmml" xref="S3.SS2.p5.4.m4.1.1.3.3.2">𝑀</ci><ci id="S3.SS2.p5.4.m4.1.1.3.3.3.cmml" xref="S3.SS2.p5.4.m4.1.1.3.3.3">𝑀</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.4.m4.1c">W\in\mathcal{R}^{M\times M}</annotation></semantics></math> is a matrix that is also optimized by the evolutionary search together with the indicator array <math id="S3.SS2.p5.5.m5.1" class="ltx_Math" alttext="\mathcal{I}" display="inline"><semantics id="S3.SS2.p5.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p5.5.m5.1.1" xref="S3.SS2.p5.5.m5.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.5.m5.1b"><ci id="S3.SS2.p5.5.m5.1.1.cmml" xref="S3.SS2.p5.5.m5.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.5.m5.1c">\mathcal{I}</annotation></semantics></math>.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p id="S3.SS2.p6.6" class="ltx_p">The size of <math id="S3.SS2.p6.1.m1.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS2.p6.1.m1.1a"><mi id="S3.SS2.p6.1.m1.1.1" xref="S3.SS2.p6.1.m1.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.1.m1.1b"><ci id="S3.SS2.p6.1.m1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.1.m1.1c">W</annotation></semantics></math> grows quadratically with <math id="S3.SS2.p6.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS2.p6.2.m2.1a"><mi id="S3.SS2.p6.2.m2.1.1" xref="S3.SS2.p6.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.2.m2.1b"><ci id="S3.SS2.p6.2.m2.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.2.m2.1c">M</annotation></semantics></math>, for scenarios involving a large number of layers. An alternative approach to contain the search space size involves parameterizing <math id="S3.SS2.p6.3.m3.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS2.p6.3.m3.1a"><mi id="S3.SS2.p6.3.m3.1.1" xref="S3.SS2.p6.3.m3.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.3.m3.1b"><ci id="S3.SS2.p6.3.m3.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.3.m3.1c">W</annotation></semantics></math> with a neural network&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">41</span></a>, <a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>. We can instead evolve a feed-forward network to output the scaling weights conditioned on the layer and step indices: <math id="S3.SS2.p6.4.m4.3" class="ltx_Math" alttext="W_{ij}=\pi_{\theta}(i,j,t)" display="inline"><semantics id="S3.SS2.p6.4.m4.3a"><mrow id="S3.SS2.p6.4.m4.3.4" xref="S3.SS2.p6.4.m4.3.4.cmml"><msub id="S3.SS2.p6.4.m4.3.4.2" xref="S3.SS2.p6.4.m4.3.4.2.cmml"><mi id="S3.SS2.p6.4.m4.3.4.2.2" xref="S3.SS2.p6.4.m4.3.4.2.2.cmml">W</mi><mrow id="S3.SS2.p6.4.m4.3.4.2.3" xref="S3.SS2.p6.4.m4.3.4.2.3.cmml"><mi id="S3.SS2.p6.4.m4.3.4.2.3.2" xref="S3.SS2.p6.4.m4.3.4.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p6.4.m4.3.4.2.3.1" xref="S3.SS2.p6.4.m4.3.4.2.3.1.cmml">​</mo><mi id="S3.SS2.p6.4.m4.3.4.2.3.3" xref="S3.SS2.p6.4.m4.3.4.2.3.3.cmml">j</mi></mrow></msub><mo id="S3.SS2.p6.4.m4.3.4.1" xref="S3.SS2.p6.4.m4.3.4.1.cmml">=</mo><mrow id="S3.SS2.p6.4.m4.3.4.3" xref="S3.SS2.p6.4.m4.3.4.3.cmml"><msub id="S3.SS2.p6.4.m4.3.4.3.2" xref="S3.SS2.p6.4.m4.3.4.3.2.cmml"><mi id="S3.SS2.p6.4.m4.3.4.3.2.2" xref="S3.SS2.p6.4.m4.3.4.3.2.2.cmml">π</mi><mi id="S3.SS2.p6.4.m4.3.4.3.2.3" xref="S3.SS2.p6.4.m4.3.4.3.2.3.cmml">θ</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS2.p6.4.m4.3.4.3.1" xref="S3.SS2.p6.4.m4.3.4.3.1.cmml">​</mo><mrow id="S3.SS2.p6.4.m4.3.4.3.3.2" xref="S3.SS2.p6.4.m4.3.4.3.3.1.cmml"><mo stretchy="false" id="S3.SS2.p6.4.m4.3.4.3.3.2.1" xref="S3.SS2.p6.4.m4.3.4.3.3.1.cmml">(</mo><mi id="S3.SS2.p6.4.m4.1.1" xref="S3.SS2.p6.4.m4.1.1.cmml">i</mi><mo id="S3.SS2.p6.4.m4.3.4.3.3.2.2" xref="S3.SS2.p6.4.m4.3.4.3.3.1.cmml">,</mo><mi id="S3.SS2.p6.4.m4.2.2" xref="S3.SS2.p6.4.m4.2.2.cmml">j</mi><mo id="S3.SS2.p6.4.m4.3.4.3.3.2.3" xref="S3.SS2.p6.4.m4.3.4.3.3.1.cmml">,</mo><mi id="S3.SS2.p6.4.m4.3.3" xref="S3.SS2.p6.4.m4.3.3.cmml">t</mi><mo stretchy="false" id="S3.SS2.p6.4.m4.3.4.3.3.2.4" xref="S3.SS2.p6.4.m4.3.4.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.4.m4.3b"><apply id="S3.SS2.p6.4.m4.3.4.cmml" xref="S3.SS2.p6.4.m4.3.4"><eq id="S3.SS2.p6.4.m4.3.4.1.cmml" xref="S3.SS2.p6.4.m4.3.4.1"></eq><apply id="S3.SS2.p6.4.m4.3.4.2.cmml" xref="S3.SS2.p6.4.m4.3.4.2"><csymbol cd="ambiguous" id="S3.SS2.p6.4.m4.3.4.2.1.cmml" xref="S3.SS2.p6.4.m4.3.4.2">subscript</csymbol><ci id="S3.SS2.p6.4.m4.3.4.2.2.cmml" xref="S3.SS2.p6.4.m4.3.4.2.2">𝑊</ci><apply id="S3.SS2.p6.4.m4.3.4.2.3.cmml" xref="S3.SS2.p6.4.m4.3.4.2.3"><times id="S3.SS2.p6.4.m4.3.4.2.3.1.cmml" xref="S3.SS2.p6.4.m4.3.4.2.3.1"></times><ci id="S3.SS2.p6.4.m4.3.4.2.3.2.cmml" xref="S3.SS2.p6.4.m4.3.4.2.3.2">𝑖</ci><ci id="S3.SS2.p6.4.m4.3.4.2.3.3.cmml" xref="S3.SS2.p6.4.m4.3.4.2.3.3">𝑗</ci></apply></apply><apply id="S3.SS2.p6.4.m4.3.4.3.cmml" xref="S3.SS2.p6.4.m4.3.4.3"><times id="S3.SS2.p6.4.m4.3.4.3.1.cmml" xref="S3.SS2.p6.4.m4.3.4.3.1"></times><apply id="S3.SS2.p6.4.m4.3.4.3.2.cmml" xref="S3.SS2.p6.4.m4.3.4.3.2"><csymbol cd="ambiguous" id="S3.SS2.p6.4.m4.3.4.3.2.1.cmml" xref="S3.SS2.p6.4.m4.3.4.3.2">subscript</csymbol><ci id="S3.SS2.p6.4.m4.3.4.3.2.2.cmml" xref="S3.SS2.p6.4.m4.3.4.3.2.2">𝜋</ci><ci id="S3.SS2.p6.4.m4.3.4.3.2.3.cmml" xref="S3.SS2.p6.4.m4.3.4.3.2.3">𝜃</ci></apply><vector id="S3.SS2.p6.4.m4.3.4.3.3.1.cmml" xref="S3.SS2.p6.4.m4.3.4.3.3.2"><ci id="S3.SS2.p6.4.m4.1.1.cmml" xref="S3.SS2.p6.4.m4.1.1">𝑖</ci><ci id="S3.SS2.p6.4.m4.2.2.cmml" xref="S3.SS2.p6.4.m4.2.2">𝑗</ci><ci id="S3.SS2.p6.4.m4.3.3.cmml" xref="S3.SS2.p6.4.m4.3.3">𝑡</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.4.m4.3c">W_{ij}=\pi_{\theta}(i,j,t)</annotation></semantics></math> where <math id="S3.SS2.p6.5.m5.1" class="ltx_Math" alttext="\theta" display="inline"><semantics id="S3.SS2.p6.5.m5.1a"><mi id="S3.SS2.p6.5.m5.1.1" xref="S3.SS2.p6.5.m5.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.5.m5.1b"><ci id="S3.SS2.p6.5.m5.1.1.cmml" xref="S3.SS2.p6.5.m5.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.5.m5.1c">\theta</annotation></semantics></math>’s are the parameters to be evolved, whose size does not change when <math id="S3.SS2.p6.6.m6.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS2.p6.6.m6.1a"><mi id="S3.SS2.p6.6.m6.1.1" xref="S3.SS2.p6.6.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.6.m6.1b"><ci id="S3.SS2.p6.6.m6.1.1.cmml" xref="S3.SS2.p6.6.m6.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.6.m6.1c">M</annotation></semantics></math> grows.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Merging in Both Spaces</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Model merging in the PS and in the DFS are orthogonal approaches, however, it is straightforward to combine these disentangled methods and further boost the performance of a merged model. As we show in the rightmost illustration in Figure&nbsp;<a href="#S3.F1" title="Figure 1 ‣ 3 Method ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and in Section&nbsp;<a href="#S4.SS1" title="4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, it is possible to first apply PS merging to a collection of models, and then put back this merged model in the collection and apply DFS merging from this enlarged collection.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">This can be extremely helpful when one considers model merging with multiple objectives, wherein PS merging can be applied first to produce several merged models each of which targets one of the muliple objectives of interest, and then DFS merging is applied with multi-objective genetic algorithms such as NSGA-II&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite> to further expand the final model’s performance in relevant metrics.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Most merged models in the community optimize for a narrow set of tasks defined in The Open LLM Leaderboard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite>. Our motivation is for evolutionary search to discover novel ways to merge different models from vastly different domains (e.g., non-English language and Math, or non-English language and Vision) which might be difficult for human experts to discover effective merging solutions themselves. Furthermore, effectively merging models from very different domains can lead to models of wider real-world applicability and enable us to develop models beyond the large population of models that are optimized for the narrow range of tasks defined by a leaderboard.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">We demonstrate our Evolutionary Model Merge approach described in Section&nbsp;<a href="#S3" title="3 Method ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> by evolving a Japanese LLM capable of Math reasoning, and a Japanese VLM proficient in handling culturally-specific content.
Specifically, in Section&nbsp;<a href="#S4.SS1" title="4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, we apply evolution to merge a Japanese LLM with an English Math LLM to build a Japanese Math LLM, and in Section&nbsp;<a href="#S4.SS2" title="4.2 Evolving Japanese VLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, we apply evolution to merge a Japanese LLM with an English VLM to create a Japanese VLM.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Evolving Japanese Math LLM</h3>

<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Setup</h4>

<section id="S4.SS1.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Models</h5>

<div id="S4.SS1.SSS1.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.Px1.p1.1" class="ltx_p">To develop a model capable of solving math problems in Japanese, we apply evolutionary model merge on a set of source models containing a Japanese LLM and Math LLMs: <span id="S4.SS1.SSS1.Px1.p1.1.1" class="ltx_text ltx_font_typewriter">shisa-gamma-7b-v1</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>]</cite> (Japanese LLM), <span id="S4.SS1.SSS1.Px1.p1.1.2" class="ltx_text ltx_font_typewriter">WizardMath-7B-V1.1</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">34</span></a>]</cite> and <span id="S4.SS1.SSS1.Px1.p1.1.3" class="ltx_text ltx_font_typewriter">Abel-7B-002</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a>]</cite>. All these models are fine-tuned from <span id="S4.SS1.SSS1.Px1.p1.1.4" class="ltx_text ltx_font_typewriter">Mistral-7B-v0.1</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite>.</p>
</div>
</section>
<section id="S4.SS1.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Dataset</h5>

<div id="S4.SS1.SSS1.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS1.Px2.p1.1" class="ltx_p">For testing, we used the MGSM dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">42</span></a>]</cite>, a multilingual translation of a subset of the GSM8k dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite>. The Japanese test set of MGSM, consisting of 250 samples, was used for the final evaluation. We used a different dataset for evolutionary search to avoid overfitting the test set. Specifically, we translated the remaining 1069 samples (out of 1319 examples) of the GSM8k test set that were not included in the MGSM test set into Japanese.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>One may think that it is more natural to translate the GSM8k training set. However, in our preliminary efforts, this approach did not work well. Since open-source math models were trained on the GSM8k training set, we were unable to perform accurate evaluations.</span></span></span></p>
</div>
</section>
<section id="S4.SS1.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Evaluation</h5>

<div id="S4.SS1.SSS1.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS1.Px3.p1.1" class="ltx_p">We evaluated the ability to generate Japanese answers to Japanese math problems.
Therefore, we considered an answer correct if it met the following criteria: (1) the concluding numerical value must be correct, and (2) the reasoning text should be written in Japanese.</p>
</div>
<div id="S4.SS1.SSS1.Px3.p2" class="ltx_para">
<p id="S4.SS1.SSS1.Px3.p2.1" class="ltx_p">We treated the last numerical value appearing in the output as the answer. We needed to adopt this heuristic because we are merging multiple models that were trained in different formats, which made it difficult to correct the output format. This method appeared to extract the answers correctly in almost all cases. Additionally, to determine the language of the output, we utilized fasttext&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>, <a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>]</cite>. We used greedy sampling for generation and calculated the zero-shot pass@1 accuracy.</p>
</div>
</section>
<section id="S4.SS1.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Optimization</h5>

<div id="S4.SS1.SSS1.Px4.p1" class="ltx_para">
<p id="S4.SS1.SSS1.Px4.p1.2" class="ltx_p">For optimization in PS, we used the CMA-ES<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite> algorithm implemented in Optuna&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite> with default hyper-parameters. Specifically, we set all initial parameter values to 0.5, sigma to 1/6, and the population size to <math id="S4.SS1.SSS1.Px4.p1.1.m1.2" class="ltx_Math" alttext="4+\lfloor 3\ln(n_{\text{params}})\rfloor" display="inline"><semantics id="S4.SS1.SSS1.Px4.p1.1.m1.2a"><mrow id="S4.SS1.SSS1.Px4.p1.1.m1.2.2" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.cmml"><mn id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.3" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.3.cmml">4</mn><mo id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.2" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.2.cmml">+</mo><mrow id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.2.cmml"><mo stretchy="false" id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.2" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.2.1.cmml">⌊</mo><mrow id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.cmml"><mn id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.3" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.3.cmml">3</mn><mo lspace="0.167em" rspace="0em" id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.2" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.2.cmml">​</mo><mrow id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.2.cmml"><mi id="S4.SS1.SSS1.Px4.p1.1.m1.1.1" xref="S4.SS1.SSS1.Px4.p1.1.m1.1.1.cmml">ln</mi><mo id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1a" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.2.cmml">⁡</mo><mrow id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.2" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.2.cmml">(</mo><msub id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.2" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml">n</mi><mtext id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.3" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.3a.cmml">params</mtext></msub><mo stretchy="false" id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.3" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.3" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.2.1.cmml">⌋</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p1.1.m1.2b"><apply id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2"><plus id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.2.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.2"></plus><cn type="integer" id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.3.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.3">4</cn><apply id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.2.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1"><floor id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.2.1.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.2"></floor><apply id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1"><times id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.2.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.2"></times><cn type="integer" id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.3.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.3">3</cn><apply id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.2.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1"><ln id="S4.SS1.SSS1.Px4.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.1.1"></ln><apply id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.2">𝑛</ci><ci id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.3a.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.3"><mtext mathsize="70%" id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.3">params</mtext></ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p1.1.m1.2c">4+\lfloor 3\ln(n_{\text{params}})\rfloor</annotation></semantics></math>, where <math id="S4.SS1.SSS1.Px4.p1.2.m2.1" class="ltx_Math" alttext="n_{\text{params}}" display="inline"><semantics id="S4.SS1.SSS1.Px4.p1.2.m2.1a"><msub id="S4.SS1.SSS1.Px4.p1.2.m2.1.1" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1.cmml"><mi id="S4.SS1.SSS1.Px4.p1.2.m2.1.1.2" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1.2.cmml">n</mi><mtext id="S4.SS1.SSS1.Px4.p1.2.m2.1.1.3" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1.3a.cmml">params</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p1.2.m2.1b"><apply id="S4.SS1.SSS1.Px4.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.Px4.p1.2.m2.1.1.1.cmml" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.Px4.p1.2.m2.1.1.2.cmml" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1.2">𝑛</ci><ci id="S4.SS1.SSS1.Px4.p1.2.m2.1.1.3a.cmml" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1.3"><mtext mathsize="70%" id="S4.SS1.SSS1.Px4.p1.2.m2.1.1.3.cmml" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1.3">params</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p1.2.m2.1c">n_{\text{params}}</annotation></semantics></math> is the number of parameters to optimize.
The fitness value is defined as the accuracy for all 1069 training samples. Please note that this set is disjoint from MGSM’s test set.
The optimization was conducted for 1000 trials, and the best trial with respect to the training accuracy was chosen as the final model.
We decided to employ TIES-Merging&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite> with DARE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite> through preliminary experiments, and optimized its parameters.</p>
</div>
<div id="S4.SS1.SSS1.Px4.p2" class="ltx_para">
<p id="S4.SS1.SSS1.Px4.p2.10" class="ltx_p">In our DFS merging experiments, <math id="S4.SS1.SSS1.Px4.p2.1.m1.2" class="ltx_Math" alttext="M=64,r=3" display="inline"><semantics id="S4.SS1.SSS1.Px4.p2.1.m1.2a"><mrow id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.3.cmml"><mrow id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.cmml"><mi id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.2" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.2.cmml">M</mi><mo id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.1" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.3" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.3.cmml">64</mn></mrow><mo id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.3" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.3a.cmml">,</mo><mrow id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.cmml"><mi id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.2" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.2.cmml">r</mi><mo id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.1" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.1.cmml">=</mo><mn id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.3" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.3.cmml">3</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.1.m1.2b"><apply id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.3.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.3a.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1"><eq id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.1"></eq><ci id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.2">𝑀</ci><cn type="integer" id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.3">64</cn></apply><apply id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2"><eq id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.1.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.1"></eq><ci id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.2.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.2">𝑟</ci><cn type="integer" id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.3.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.1.m1.2c">M=64,r=3</annotation></semantics></math>, and consequently, <math id="S4.SS1.SSS1.Px4.p2.2.m2.1" class="ltx_Math" alttext="T=M\times r=192" display="inline"><semantics id="S4.SS1.SSS1.Px4.p2.2.m2.1a"><mrow id="S4.SS1.SSS1.Px4.p2.2.m2.1.1" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.cmml"><mi id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.2" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.2.cmml">T</mi><mo id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.3" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.3.cmml">=</mo><mrow id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.cmml"><mi id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.2" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.2.cmml">M</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.1" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.1.cmml">×</mo><mi id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.3" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.3.cmml">r</mi></mrow><mo id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.5" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.5.cmml">=</mo><mn id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.6" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.6.cmml">192</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.2.m2.1b"><apply id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1"><and id="S4.SS1.SSS1.Px4.p2.2.m2.1.1a.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1"></and><apply id="S4.SS1.SSS1.Px4.p2.2.m2.1.1b.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1"><eq id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.3.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.3"></eq><ci id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.2.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.2">𝑇</ci><apply id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4"><times id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.1.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.1"></times><ci id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.2.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.2">𝑀</ci><ci id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.3.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.3">𝑟</ci></apply></apply><apply id="S4.SS1.SSS1.Px4.p2.2.m2.1.1c.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1"><eq id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.5.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.5"></eq><share href="#S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.cmml" id="S4.SS1.SSS1.Px4.p2.2.m2.1.1d.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1"></share><cn type="integer" id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.6.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.6">192</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.2.m2.1c">T=M\times r=192</annotation></semantics></math>.
We kept the last 200 examples in the training data as our validation set and optimize on the rest of the data with a batch size of 200. We report the performance of the snapshot that achieved the highest accuracy in the validation set, and the test set is strictly isolated from the optimization process.
We adopted CMA-ES in EvoJAX&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">47</span></a>]</cite>, it optimized <math id="S4.SS1.SSS1.Px4.p2.3.m3.1" class="ltx_Math" alttext="\mathcal{I}" display="inline"><semantics id="S4.SS1.SSS1.Px4.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS1.Px4.p2.3.m3.1.1" xref="S4.SS1.SSS1.Px4.p2.3.m3.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.3.m3.1b"><ci id="S4.SS1.SSS1.Px4.p2.3.m3.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.3.m3.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.3.m3.1c">\mathcal{I}</annotation></semantics></math> and <math id="S4.SS1.SSS1.Px4.p2.4.m4.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S4.SS1.SSS1.Px4.p2.4.m4.1a"><mi id="S4.SS1.SSS1.Px4.p2.4.m4.1.1" xref="S4.SS1.SSS1.Px4.p2.4.m4.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.4.m4.1b"><ci id="S4.SS1.SSS1.Px4.p2.4.m4.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.4.m4.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.4.m4.1c">W</annotation></semantics></math> for a total of 100 generations with a popluation size of 128, and we used the default hyper-parameters.
We limited our DFS merging to two models <math id="S4.SS1.SSS1.Px4.p2.5.m5.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS1.SSS1.Px4.p2.5.m5.1a"><mi id="S4.SS1.SSS1.Px4.p2.5.m5.1.1" xref="S4.SS1.SSS1.Px4.p2.5.m5.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.5.m5.1b"><ci id="S4.SS1.SSS1.Px4.p2.5.m5.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.5.m5.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.5.m5.1c">A</annotation></semantics></math> and <math id="S4.SS1.SSS1.Px4.p2.6.m6.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S4.SS1.SSS1.Px4.p2.6.m6.1a"><mi id="S4.SS1.SSS1.Px4.p2.6.m6.1.1" xref="S4.SS1.SSS1.Px4.p2.6.m6.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.6.m6.1b"><ci id="S4.SS1.SSS1.Px4.p2.6.m6.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.6.m6.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.6.m6.1c">B</annotation></semantics></math> to ensure that the final model remains modest in size and can be run on a single GPU, but in principle, the methodology can scale to merging multiple models.
During the merging, model <math id="S4.SS1.SSS1.Px4.p2.7.m7.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS1.SSS1.Px4.p2.7.m7.1a"><mi id="S4.SS1.SSS1.Px4.p2.7.m7.1.1" xref="S4.SS1.SSS1.Px4.p2.7.m7.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.7.m7.1b"><ci id="S4.SS1.SSS1.Px4.p2.7.m7.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.7.m7.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.7.m7.1c">A</annotation></semantics></math>’s tokenizer, and input/output embeddings are utilized. Furthermore, to maintain compatibility with the embedding layers, we mandate that the initial and final transformer layers of model <math id="S4.SS1.SSS1.Px4.p2.8.m8.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS1.SSS1.Px4.p2.8.m8.1a"><mi id="S4.SS1.SSS1.Px4.p2.8.m8.1.1" xref="S4.SS1.SSS1.Px4.p2.8.m8.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.8.m8.1b"><ci id="S4.SS1.SSS1.Px4.p2.8.m8.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.8.m8.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.8.m8.1c">A</annotation></semantics></math> define the start and the end of the inference path. We initialized the indicator array <math id="S4.SS1.SSS1.Px4.p2.9.m9.1" class="ltx_Math" alttext="\mathcal{I}" display="inline"><semantics id="S4.SS1.SSS1.Px4.p2.9.m9.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS1.Px4.p2.9.m9.1.1" xref="S4.SS1.SSS1.Px4.p2.9.m9.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.9.m9.1b"><ci id="S4.SS1.SSS1.Px4.p2.9.m9.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.9.m9.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.9.m9.1c">\mathcal{I}</annotation></semantics></math> so that all layers in model <math id="S4.SS1.SSS1.Px4.p2.10.m10.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.SS1.SSS1.Px4.p2.10.m10.1a"><mi id="S4.SS1.SSS1.Px4.p2.10.m10.1.1" xref="S4.SS1.SSS1.Px4.p2.10.m10.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.10.m10.1b"><ci id="S4.SS1.SSS1.Px4.p2.10.m10.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.10.m10.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.10.m10.1c">A</annotation></semantics></math> are more likely to be included as initial hops in the inference path to shorten the search time.</p>
</div>
</section>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Results</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">Table&nbsp;<a href="#S4.T1" title="Table 1 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> summarizes the performance of the LLMs on Japanese Math and overall Japanese benchmark tasks. The MGSM-JA column reports the results from the MGSM test set, employing the previously described metrics. The Japanese language model (Model 1) demonstrates limited mathematical proficiency, while the Math models (Models 2 and 3), though mathematically adept, show insufficient command of the Japanese language. Consequently, all three models score low scores on the MGSM-JA, with accuracy at or below 30.0.</p>
</div>
<div id="S4.SS1.SSS2.p2" class="ltx_para">
<p id="S4.SS1.SSS2.p2.1" class="ltx_p">In contrast, our merged models (Models 4–6) manifest a substantial elevation in performance. Notably, the model merged in PS (Model 4) achieves an impressive score of 52.0, highlighting the remarkable potential in combining models with distinct expertises. The DFS-merged model (Model 5) also shows a performance enhancement, with an over 6 percent increase in accuracy compared to the source models. While the leap in performance is not as pronounced as with PS merging, it still proves to be a valid and orthogonal approach. Finally, our hybrid model (Model 6), which integrates both merging strategies, shows further enhancements on the task.</p>
</div>
<div id="S4.SS1.SSS2.p3" class="ltx_para">
<p id="S4.SS1.SSS2.p3.1" class="ltx_p">Figure&nbsp;<a href="#S4.F2" title="Figure 2 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> gives an overview of the five models’ “answer sheet” on the math problems. Our merged models retain the foundational knowledge in the source models, as evidenced by the similar score patterns on problems 1–15. Moreover, they exhibit emergent capabilities, successfully tackling problems that stumped the source models (e.g., problems 20–30). Evidently, by effectively integrating a Japanese LLM and mathematical models, we have succeeded in producing models that are proficient in both Japanese language understanding and mathematical problem-solving.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span><span id="S4.T1.7.1" class="ltx_text ltx_font_bold">Performance Comparison of the LLMs.</span> Models 1–3 are source models, Models 4–6 are our optimized merge models, and Models 7–11 are provided for reference. MGSM-JA measures math ability in Japanese, and JP-LMEH evaluates general Japanese language capabilities, with a detailed breakdown provided in Table&nbsp;<a href="#S4.T2" title="Table 2 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</figcaption>
<table id="S4.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.2.2" class="ltx_tr">
<th id="S4.T1.2.2.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.2.2.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Id.</span></th>
<th id="S4.T1.2.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.2.2.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Model</span></th>
<th id="S4.T1.2.2.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.2.2.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Type</span></th>
<th id="S4.T1.2.2.6" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.2.2.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Size</span></th>
<th id="S4.T1.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T1.1.1.1.2" class="ltx_text ltx_font_bold" style="font-size:90%;">MGSM-JA</span><span id="S4.T1.1.1.1.3" class="ltx_text" style="font-size:90%;"> </span><span id="S4.T1.1.1.1.1" class="ltx_text" style="font-size:80%;">(acc <math id="S4.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span>
</th>
<th id="S4.T1.2.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">
<span id="S4.T1.2.2.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">JP-LMEH</span><span id="S4.T1.2.2.2.3" class="ltx_text" style="font-size:90%;"> </span><span id="S4.T1.2.2.2.1" class="ltx_text" style="font-size:80%;">(avg <math id="S4.T1.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T1.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T1.2.2.2.1.m1.1.1" xref="S4.T1.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.1.m1.1b"><ci id="S4.T1.2.2.2.1.m1.1.1.cmml" xref="S4.T1.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math>)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.2.3.1" class="ltx_tr">
<td id="S4.T1.2.3.1.1" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T1.2.3.1.1.1" class="ltx_text" style="font-size:90%;">1</span></td>
<td id="S4.T1.2.3.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.2.3.1.2.1" class="ltx_text" style="font-size:90%;">Shisa Gamma 7B v1</span></td>
<td id="S4.T1.2.3.1.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.2.3.1.3.1" class="ltx_text" style="font-size:90%;">JA general</span></td>
<td id="S4.T1.2.3.1.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T1.2.3.1.4.1" class="ltx_text" style="font-size:90%;">7B</span></td>
<td id="S4.T1.2.3.1.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T1.2.3.1.5.1" class="ltx_text" style="font-size:90%;">9.6</span></td>
<td id="S4.T1.2.3.1.6" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T1.2.3.1.6.1" class="ltx_text" style="font-size:90%;">66.1</span></td>
</tr>
<tr id="S4.T1.2.4.2" class="ltx_tr">
<td id="S4.T1.2.4.2.1" class="ltx_td ltx_align_right"><span id="S4.T1.2.4.2.1.1" class="ltx_text" style="font-size:90%;">2</span></td>
<td id="S4.T1.2.4.2.2" class="ltx_td ltx_align_left"><span id="S4.T1.2.4.2.2.1" class="ltx_text" style="font-size:90%;">WizardMath 7B v1.1</span></td>
<td id="S4.T1.2.4.2.3" class="ltx_td ltx_align_left"><span id="S4.T1.2.4.2.3.1" class="ltx_text" style="font-size:90%;">EN math</span></td>
<td id="S4.T1.2.4.2.4" class="ltx_td ltx_align_right"><span id="S4.T1.2.4.2.4.1" class="ltx_text" style="font-size:90%;">7B</span></td>
<td id="S4.T1.2.4.2.5" class="ltx_td ltx_align_right"><span id="S4.T1.2.4.2.5.1" class="ltx_text" style="font-size:90%;">18.4</span></td>
<td id="S4.T1.2.4.2.6" class="ltx_td ltx_align_right"><span id="S4.T1.2.4.2.6.1" class="ltx_text" style="font-size:90%;">60.1</span></td>
</tr>
<tr id="S4.T1.2.5.3" class="ltx_tr">
<td id="S4.T1.2.5.3.1" class="ltx_td ltx_align_right"><span id="S4.T1.2.5.3.1.1" class="ltx_text" style="font-size:90%;">3</span></td>
<td id="S4.T1.2.5.3.2" class="ltx_td ltx_align_left"><span id="S4.T1.2.5.3.2.1" class="ltx_text" style="font-size:90%;">Abel 7B 002</span></td>
<td id="S4.T1.2.5.3.3" class="ltx_td ltx_align_left"><span id="S4.T1.2.5.3.3.1" class="ltx_text" style="font-size:90%;">EN math</span></td>
<td id="S4.T1.2.5.3.4" class="ltx_td ltx_align_right"><span id="S4.T1.2.5.3.4.1" class="ltx_text" style="font-size:90%;">7B</span></td>
<td id="S4.T1.2.5.3.5" class="ltx_td ltx_align_right"><span id="S4.T1.2.5.3.5.1" class="ltx_text" style="font-size:90%;">30.0</span></td>
<td id="S4.T1.2.5.3.6" class="ltx_td ltx_align_right"><span id="S4.T1.2.5.3.6.1" class="ltx_text" style="font-size:90%;">56.5</span></td>
</tr>
<tr id="S4.T1.2.6.4" class="ltx_tr">
<td id="S4.T1.2.6.4.1" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T1.2.6.4.1.1" class="ltx_text" style="font-size:90%;">4</span></td>
<td id="S4.T1.2.6.4.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.2.6.4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Ours (PS)</span></td>
<td id="S4.T1.2.6.4.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.2.6.4.3.1" class="ltx_text" style="font-size:90%;">1 + 2 + 3</span></td>
<td id="S4.T1.2.6.4.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T1.2.6.4.4.1" class="ltx_text" style="font-size:90%;">7B</span></td>
<td id="S4.T1.2.6.4.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T1.2.6.4.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">52.0</span></td>
<td id="S4.T1.2.6.4.6" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T1.2.6.4.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">70.5</span></td>
</tr>
<tr id="S4.T1.2.7.5" class="ltx_tr">
<td id="S4.T1.2.7.5.1" class="ltx_td ltx_align_right"><span id="S4.T1.2.7.5.1.1" class="ltx_text" style="font-size:90%;">5</span></td>
<td id="S4.T1.2.7.5.2" class="ltx_td ltx_align_left"><span id="S4.T1.2.7.5.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Ours (DFS)</span></td>
<td id="S4.T1.2.7.5.3" class="ltx_td ltx_align_left"><span id="S4.T1.2.7.5.3.1" class="ltx_text" style="font-size:90%;">3 + 1</span></td>
<td id="S4.T1.2.7.5.4" class="ltx_td ltx_align_right"><span id="S4.T1.2.7.5.4.1" class="ltx_text" style="font-size:90%;">10B</span></td>
<td id="S4.T1.2.7.5.5" class="ltx_td ltx_align_right"><span id="S4.T1.2.7.5.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">36.4</span></td>
<td id="S4.T1.2.7.5.6" class="ltx_td ltx_align_right"><span id="S4.T1.2.7.5.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">53.2</span></td>
</tr>
<tr id="S4.T1.2.8.6" class="ltx_tr">
<td id="S4.T1.2.8.6.1" class="ltx_td ltx_align_right"><span id="S4.T1.2.8.6.1.1" class="ltx_text" style="font-size:90%;">6</span></td>
<td id="S4.T1.2.8.6.2" class="ltx_td ltx_align_left"><span id="S4.T1.2.8.6.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Ours (PS+DFS)</span></td>
<td id="S4.T1.2.8.6.3" class="ltx_td ltx_align_left"><span id="S4.T1.2.8.6.3.1" class="ltx_text" style="font-size:90%;">4 + 1</span></td>
<td id="S4.T1.2.8.6.4" class="ltx_td ltx_align_right"><span id="S4.T1.2.8.6.4.1" class="ltx_text" style="font-size:90%;">10B</span></td>
<td id="S4.T1.2.8.6.5" class="ltx_td ltx_align_right"><span id="S4.T1.2.8.6.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">55.2</span></td>
<td id="S4.T1.2.8.6.6" class="ltx_td ltx_align_right"><span id="S4.T1.2.8.6.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">66.2</span></td>
</tr>
<tr id="S4.T1.2.9.7" class="ltx_tr">
<td id="S4.T1.2.9.7.1" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T1.2.9.7.1.1" class="ltx_text" style="font-size:90%;">7</span></td>
<td id="S4.T1.2.9.7.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.2.9.7.2.1" class="ltx_text" style="font-size:90%;">Llama 2 70B</span></td>
<td id="S4.T1.2.9.7.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T1.2.9.7.3.1" class="ltx_text" style="font-size:90%;">EN general</span></td>
<td id="S4.T1.2.9.7.4" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T1.2.9.7.4.1" class="ltx_text" style="font-size:90%;">70B</span></td>
<td id="S4.T1.2.9.7.5" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T1.2.9.7.5.1" class="ltx_text" style="font-size:90%;">18.0</span></td>
<td id="S4.T1.2.9.7.6" class="ltx_td ltx_align_right ltx_border_t"><span id="S4.T1.2.9.7.6.1" class="ltx_text" style="font-size:90%;">64.5</span></td>
</tr>
<tr id="S4.T1.2.10.8" class="ltx_tr">
<td id="S4.T1.2.10.8.1" class="ltx_td ltx_align_right"><span id="S4.T1.2.10.8.1.1" class="ltx_text" style="font-size:90%;">8</span></td>
<td id="S4.T1.2.10.8.2" class="ltx_td ltx_align_left"><span id="S4.T1.2.10.8.2.1" class="ltx_text" style="font-size:90%;">Japanese StableLM 70B</span></td>
<td id="S4.T1.2.10.8.3" class="ltx_td ltx_align_left"><span id="S4.T1.2.10.8.3.1" class="ltx_text" style="font-size:90%;">JA general</span></td>
<td id="S4.T1.2.10.8.4" class="ltx_td ltx_align_right"><span id="S4.T1.2.10.8.4.1" class="ltx_text" style="font-size:90%;">70B</span></td>
<td id="S4.T1.2.10.8.5" class="ltx_td ltx_align_right"><span id="S4.T1.2.10.8.5.1" class="ltx_text" style="font-size:90%;">17.2</span></td>
<td id="S4.T1.2.10.8.6" class="ltx_td ltx_align_right"><span id="S4.T1.2.10.8.6.1" class="ltx_text" style="font-size:90%;">68.3</span></td>
</tr>
<tr id="S4.T1.2.11.9" class="ltx_tr">
<td id="S4.T1.2.11.9.1" class="ltx_td ltx_align_right"><span id="S4.T1.2.11.9.1.1" class="ltx_text" style="font-size:90%;">9</span></td>
<td id="S4.T1.2.11.9.2" class="ltx_td ltx_align_left"><span id="S4.T1.2.11.9.2.1" class="ltx_text" style="font-size:90%;">Swallow 70B</span></td>
<td id="S4.T1.2.11.9.3" class="ltx_td ltx_align_left"><span id="S4.T1.2.11.9.3.1" class="ltx_text" style="font-size:90%;">JA general</span></td>
<td id="S4.T1.2.11.9.4" class="ltx_td ltx_align_right"><span id="S4.T1.2.11.9.4.1" class="ltx_text" style="font-size:90%;">70B</span></td>
<td id="S4.T1.2.11.9.5" class="ltx_td ltx_align_right"><span id="S4.T1.2.11.9.5.1" class="ltx_text" style="font-size:90%;">13.6</span></td>
<td id="S4.T1.2.11.9.6" class="ltx_td ltx_align_right"><span id="S4.T1.2.11.9.6.1" class="ltx_text" style="font-size:90%;">71.5</span></td>
</tr>
<tr id="S4.T1.2.12.10" class="ltx_tr">
<td id="S4.T1.2.12.10.1" class="ltx_td ltx_align_right"><span id="S4.T1.2.12.10.1.1" class="ltx_text" style="font-size:90%;">10</span></td>
<td id="S4.T1.2.12.10.2" class="ltx_td ltx_align_left"><span id="S4.T1.2.12.10.2.1" class="ltx_text" style="font-size:90%;">GPT-3.5</span></td>
<td id="S4.T1.2.12.10.3" class="ltx_td ltx_align_left"><span id="S4.T1.2.12.10.3.1" class="ltx_text" style="font-size:90%;">commercial</span></td>
<td id="S4.T1.2.12.10.4" class="ltx_td ltx_align_right"><span id="S4.T1.2.12.10.4.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T1.2.12.10.5" class="ltx_td ltx_align_right"><span id="S4.T1.2.12.10.5.1" class="ltx_text" style="font-size:90%;">50.4</span></td>
<td id="S4.T1.2.12.10.6" class="ltx_td ltx_align_right"><span id="S4.T1.2.12.10.6.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
<tr id="S4.T1.2.13.11" class="ltx_tr">
<td id="S4.T1.2.13.11.1" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T1.2.13.11.1.1" class="ltx_text" style="font-size:90%;">11</span></td>
<td id="S4.T1.2.13.11.2" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T1.2.13.11.2.1" class="ltx_text" style="font-size:90%;">GPT-4</span></td>
<td id="S4.T1.2.13.11.3" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T1.2.13.11.3.1" class="ltx_text" style="font-size:90%;">commercial</span></td>
<td id="S4.T1.2.13.11.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T1.2.13.11.4.1" class="ltx_text" style="font-size:90%;">-</span></td>
<td id="S4.T1.2.13.11.5" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T1.2.13.11.5.1" class="ltx_text" style="font-size:90%;">78.8</span></td>
<td id="S4.T1.2.13.11.6" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T1.2.13.11.6.1" class="ltx_text" style="font-size:90%;">-</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2403.13187/assets/x2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="115" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span id="S4.F2.2.1" class="ltx_text ltx_font_bold">Performance Overview.</span> The figure depicts the success of various models on the MGSM-JA task, with each of the 250 test problems represented along the x-axis by problem ID. Correct answers are indicated by colored markers at the corresponding positions.</figcaption>
</figure>
<div id="S4.SS1.SSS2.p4" class="ltx_para">
<p id="S4.SS1.SSS2.p4.1" class="ltx_p">Furthermore, Table&nbsp;<a href="#S4.T2" title="Table 2 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> presents the results of evaluating the general Japanese language ability using the Japanese Language Model Evaluation Harness (JP-LMEH) benchmark suite. This benchmark suite consists of nine tasks, and the average score across these tasks is widely used as an indicator of overall Japanese language proficiency. Our models achieve remarkably high scores of 70.5 and 66.2, surpassing the source models and even the previous state-of-the-art 70B parameter Japanese LLM (specifically, Japanese StableLM 70B), despite having only 7B to 10B parameters.</p>
</div>
<div id="S4.SS1.SSS2.p5" class="ltx_para">
<p id="S4.SS1.SSS2.p5.1" class="ltx_p">Compared to the source Japanese model (Shisa Gmma 7B v1), it is interesting to note that there is not only a significant improvement in the MGSM scores but also improvements in other tasks such as JSQuAD and JAQKET. It should be noted that the MGSM scores here do not match those in Table&nbsp;<a href="#S4.T1" title="Table 1 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, due to the differences in evaluation protocols (few-shot, prompting, etc.). Additional details are provided in Appendix&nbsp;<a href="#A1" title="Appendix A Evaluation Details ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>, including extensive comparisons with other models in Table&nbsp;<a href="#A1.T4" title="Table 4 ‣ Appendix A Evaluation Details ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S4.SS1.SSS2.p6" class="ltx_para">
<p id="S4.SS1.SSS2.p6.1" class="ltx_p">Moreover, Appendix&nbsp;<a href="#A3" title="Appendix C Case Study ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a> showcases intriguing examples that demonstrate the utility of our models merged using evolution. The merged models correctly answered questions that require both knowledge about Japanese-culture <span id="S4.SS1.SSS2.p6.1.1" class="ltx_text ltx_font_italic">and</span> Math ability. In contrast, even if such Japanese questions were translated into English and answered in English, English math models would likely fail to provide the correct answers as they may not be aware of Japanese culture-specific context in the questions.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span><span id="S4.T2.2.1" class="ltx_text ltx_font_bold">Breakdown of JP-LMEH Scores for Japanese Language Proficiency</span>. JP-LMEH (Japanese Language Model Evaluation Harness) is a benchmark suite consisting of 9 tasks, and the average score (Avg column) is used as an indicator of overall Japanese language proficiency. Full results are in Table&nbsp;<a href="#A1.T4" title="Table 4 ‣ Appendix A Evaluation Details ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a></figcaption>
<table id="S4.T2.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.3.1.1" class="ltx_tr">
<th id="S4.T2.3.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt" style="padding-left:2.5pt;padding-right:2.5pt;"></th>
<td id="S4.T2.3.1.1.2" class="ltx_td ltx_border_tt" style="padding-left:2.5pt;padding-right:2.5pt;"></td>
<td id="S4.T2.3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.5pt;padding-right:2.5pt;" colspan="10"><span id="S4.T2.3.1.1.3.1" class="ltx_text ltx_font_bold">JP Language Model Evaluation Harness</span></td>
</tr>
<tr id="S4.T2.3.2.2" class="ltx_tr">
<th id="S4.T2.3.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S4.T2.3.2.2.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<td id="S4.T2.3.2.2.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S4.T2.3.2.2.2.1" class="ltx_text ltx_font_bold">Size</span></td>
<td id="S4.T2.3.2.2.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">JComQA</td>
<td id="S4.T2.3.2.2.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">JNLI</td>
<td id="S4.T2.3.2.2.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">MARC</td>
<td id="S4.T2.3.2.2.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">JSQuAD</td>
<td id="S4.T2.3.2.2.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">JAQKET</td>
<td id="S4.T2.3.2.2.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">XLSum</td>
<td id="S4.T2.3.2.2.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">XWino</td>
<td id="S4.T2.3.2.2.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">MGSM</td>
<td id="S4.T2.3.2.2.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">JCoLA</td>
<td id="S4.T2.3.2.2.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S4.T2.3.2.2.12.1" class="ltx_text ltx_font_bold">Avg</span></td>
</tr>
<tr id="S4.T2.3.3.3" class="ltx_tr">
<th id="S4.T2.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">Shisa Gamma 7b v1</th>
<td id="S4.T2.3.3.3.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="S4.T2.3.3.3.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">91.2</td>
<td id="S4.T2.3.3.3.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">72.1</td>
<td id="S4.T2.3.3.3.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">94.6</td>
<td id="S4.T2.3.3.3.6" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">73.9</td>
<td id="S4.T2.3.3.3.7" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">68.0</td>
<td id="S4.T2.3.3.3.8" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">25.9</td>
<td id="S4.T2.3.3.3.9" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">80.5</td>
<td id="S4.T2.3.3.3.10" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">29.6</td>
<td id="S4.T2.3.3.3.11" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">58.7</td>
<td id="S4.T2.3.3.3.12" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">66.1</td>
</tr>
<tr id="S4.T2.3.4.4" class="ltx_tr">
<th id="S4.T2.3.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:2.5pt;padding-right:2.5pt;">WizardMath 7B V1.1</th>
<td id="S4.T2.3.4.4.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="S4.T2.3.4.4.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">74.7</td>
<td id="S4.T2.3.4.4.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">42.7</td>
<td id="S4.T2.3.4.4.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">90.4</td>
<td id="S4.T2.3.4.4.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">84.6</td>
<td id="S4.T2.3.4.4.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">68.5</td>
<td id="S4.T2.3.4.4.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">22.3</td>
<td id="S4.T2.3.4.4.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">69.8</td>
<td id="S4.T2.3.4.4.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">38.8</td>
<td id="S4.T2.3.4.4.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">48.9</td>
<td id="S4.T2.3.4.4.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">60.1</td>
</tr>
<tr id="S4.T2.3.5.5" class="ltx_tr">
<th id="S4.T2.3.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:2.5pt;padding-right:2.5pt;">Abel 7B 002</th>
<td id="S4.T2.3.5.5.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="S4.T2.3.5.5.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70.3</td>
<td id="S4.T2.3.5.5.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">51.8</td>
<td id="S4.T2.3.5.5.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">62.3</td>
<td id="S4.T2.3.5.5.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">83.8</td>
<td id="S4.T2.3.5.5.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">69.0</td>
<td id="S4.T2.3.5.5.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">22.5</td>
<td id="S4.T2.3.5.5.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">68.2</td>
<td id="S4.T2.3.5.5.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">28.0</td>
<td id="S4.T2.3.5.5.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">52.7</td>
<td id="S4.T2.3.5.5.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">56.5</td>
</tr>
<tr id="S4.T2.3.6.6" class="ltx_tr">
<th id="S4.T2.3.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S4.T2.3.6.6.1.1" class="ltx_text ltx_font_bold">Ours (PS)</span></th>
<td id="S4.T2.3.6.6.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="S4.T2.3.6.6.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">89.1</td>
<td id="S4.T2.3.6.6.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">65.7</td>
<td id="S4.T2.3.6.6.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">95.4</td>
<td id="S4.T2.3.6.6.6" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">89.5</td>
<td id="S4.T2.3.6.6.7" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">77.7</td>
<td id="S4.T2.3.6.6.8" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">25.5</td>
<td id="S4.T2.3.6.6.9" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">81.2</td>
<td id="S4.T2.3.6.6.10" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td id="S4.T2.3.6.6.11" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">60.5</td>
<td id="S4.T2.3.6.6.12" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S4.T2.3.6.6.12.1" class="ltx_text ltx_font_bold">70.5</span></td>
</tr>
<tr id="S4.T2.3.7.7" class="ltx_tr">
<th id="S4.T2.3.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S4.T2.3.7.7.1.1" class="ltx_text ltx_font_bold">Ours (DFS)</span></th>
<td id="S4.T2.3.7.7.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">10B</td>
<td id="S4.T2.3.7.7.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">67.7</td>
<td id="S4.T2.3.7.7.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">58.2</td>
<td id="S4.T2.3.7.7.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">53.5</td>
<td id="S4.T2.3.7.7.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">66.8</td>
<td id="S4.T2.3.7.7.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">54.3</td>
<td id="S4.T2.3.7.7.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">17.3</td>
<td id="S4.T2.3.7.7.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.6</td>
<td id="S4.T2.3.7.7.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">30.0</td>
<td id="S4.T2.3.7.7.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.6</td>
<td id="S4.T2.3.7.7.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S4.T2.3.7.7.12.1" class="ltx_text ltx_font_bold">53.2</span></td>
</tr>
<tr id="S4.T2.3.8.8" class="ltx_tr">
<th id="S4.T2.3.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S4.T2.3.8.8.1.1" class="ltx_text ltx_font_bold">Ours (PS+DFS)</span></th>
<td id="S4.T2.3.8.8.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">10B</td>
<td id="S4.T2.3.8.8.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">88.2</td>
<td id="S4.T2.3.8.8.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.3</td>
<td id="S4.T2.3.8.8.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">91.5</td>
<td id="S4.T2.3.8.8.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.6</td>
<td id="S4.T2.3.8.8.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">77.8</td>
<td id="S4.T2.3.8.8.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">23.2</td>
<td id="S4.T2.3.8.8.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">73.0</td>
<td id="S4.T2.3.8.8.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">40.0</td>
<td id="S4.T2.3.8.8.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">73.0</td>
<td id="S4.T2.3.8.8.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="S4.T2.3.8.8.12.1" class="ltx_text ltx_font_bold">66.2</span></td>
</tr>
<tr id="S4.T2.3.9.9" class="ltx_tr">
<th id="S4.T2.3.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">Llama 2 70B</th>
<td id="S4.T2.3.9.9.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td id="S4.T2.3.9.9.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">80.2</td>
<td id="S4.T2.3.9.9.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">53.4</td>
<td id="S4.T2.3.9.9.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">94.4</td>
<td id="S4.T2.3.9.9.6" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">91.6</td>
<td id="S4.T2.3.9.9.7" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">80.1</td>
<td id="S4.T2.3.9.9.8" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">21.8</td>
<td id="S4.T2.3.9.9.9" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">73.6</td>
<td id="S4.T2.3.9.9.10" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">30.4</td>
<td id="S4.T2.3.9.9.11" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">54.6</td>
<td id="S4.T2.3.9.9.12" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">64.5</td>
</tr>
<tr id="S4.T2.3.10.10" class="ltx_tr">
<th id="S4.T2.3.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="padding-left:2.5pt;padding-right:2.5pt;">Japanese Stable LM 70B</th>
<td id="S4.T2.3.10.10.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td id="S4.T2.3.10.10.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">91.2</td>
<td id="S4.T2.3.10.10.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.4</td>
<td id="S4.T2.3.10.10.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">92.9</td>
<td id="S4.T2.3.10.10.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">87.1</td>
<td id="S4.T2.3.10.10.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">88.4</td>
<td id="S4.T2.3.10.10.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">24.3</td>
<td id="S4.T2.3.10.10.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">82.0</td>
<td id="S4.T2.3.10.10.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">37.2</td>
<td id="S4.T2.3.10.10.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">61.7</td>
<td id="S4.T2.3.10.10.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">68.3</td>
</tr>
<tr id="S4.T2.3.11.11" class="ltx_tr">
<th id="S4.T2.3.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow 70B</th>
<td id="S4.T2.3.11.11.2" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td id="S4.T2.3.11.11.3" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">95.3</td>
<td id="S4.T2.3.11.11.4" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">57.2</td>
<td id="S4.T2.3.11.11.5" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">91.7</td>
<td id="S4.T2.3.11.11.6" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">94.1</td>
<td id="S4.T2.3.11.11.7" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">93.9</td>
<td id="S4.T2.3.11.11.8" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">23.1</td>
<td id="S4.T2.3.11.11.9" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">83.3</td>
<td id="S4.T2.3.11.11.10" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">45.2</td>
<td id="S4.T2.3.11.11.11" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">59.5</td>
<td id="S4.T2.3.11.11.12" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">71.5</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3 </span>Analysis</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">In our exploration of model merging in the parameter space, we experimented with diverse configurations, such as varying the assignment of merging parameters across different layer groups. However, due to a constrained dataset, we did not witness notable improvements in performance correlating with increase in configuration complexity. Consequently, we focused our reporting on a PS merged model (Model 4 in Table&nbsp;<a href="#S4.T1" title="Table 1 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) that adopts the simplest setting: considering each source model as a singular layer and allocating two DARE-TIES associated parameters to each for evolutionary merging. Figure&nbsp;<a href="#S4.F4" title="Figure 4 ‣ 4.1.3 Analysis ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the evolved parameter configuration post PS merging.</p>
</div>
<div id="S4.SS1.SSS3.p2" class="ltx_para">
<p id="S4.SS1.SSS3.p2.1" class="ltx_p">The CMA-ES optimization results reveals that all three models are important, as suggested by the uniformity of the optimized weighting values. The dominant density from the Japanese LLM suggests its critical contribution to solving the task. We conjecture that this may also be partially attributed to the Japanese LM’s larger amount of fine-tunings from the Mistral base model.
In line with the discussion in&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">51</span></a>, Section&nbsp;4.6]</cite>, the sparsification of DARE tends to degrade performance when applied to such extensively fine-tuned models. Our evolutionary search has seemingly managed to address this issue by increasing the density for the Japanese LM.</p>
</div>
<div id="S4.SS1.SSS3.p3" class="ltx_para">
<p id="S4.SS1.SSS3.p3.1" class="ltx_p">The parameter settings derived from our PS merging experiments align well with outcomes from our DFS merging efforts. By incorporating the PS-merged model into our pool of source models and applying DFS merging across all potential pairings, we observed optimal performance with the combination of the PS-merged model and the Japanese language mode (Model 6 in Table&nbsp;<a href="#S4.T1" title="Table 1 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). This finding echoes the significant influence of the Japanese language model, as indicated by its notable presence in Figure&nbsp;<a href="#S4.F4" title="Figure 4 ‣ 4.1.3 Analysis ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, and reaffirms the substantial promise of evolutionary model merging.</p>
</div>
<div id="S4.SS1.SSS3.p4" class="ltx_para">
<p id="S4.SS1.SSS3.p4.2" class="ltx_p">Figure&nbsp;<a href="#S4.F4" title="Figure 4 ‣ 4.1.3 Analysis ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> displays the evolution of the inference path, where our approach consistently recognized the value of initial steps, incorporating every layer from the first model (our PS-merged model), except for the last decoding layer and the embedding layer. As the process advanced, the method refined the selection to a smaller, more effective set of layers and strategically alternated between layers from both contributing models. Significantly, the scaling parameters <math id="S4.SS1.SSS3.p4.1.m1.1" class="ltx_Math" alttext="W_{ij}" display="inline"><semantics id="S4.SS1.SSS3.p4.1.m1.1a"><msub id="S4.SS1.SSS3.p4.1.m1.1.1" xref="S4.SS1.SSS3.p4.1.m1.1.1.cmml"><mi id="S4.SS1.SSS3.p4.1.m1.1.1.2" xref="S4.SS1.SSS3.p4.1.m1.1.1.2.cmml">W</mi><mrow id="S4.SS1.SSS3.p4.1.m1.1.1.3" xref="S4.SS1.SSS3.p4.1.m1.1.1.3.cmml"><mi id="S4.SS1.SSS3.p4.1.m1.1.1.3.2" xref="S4.SS1.SSS3.p4.1.m1.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS3.p4.1.m1.1.1.3.1" xref="S4.SS1.SSS3.p4.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS1.SSS3.p4.1.m1.1.1.3.3" xref="S4.SS1.SSS3.p4.1.m1.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.1.m1.1b"><apply id="S4.SS1.SSS3.p4.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS3.p4.1.m1.1.1.1.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.SSS3.p4.1.m1.1.1.2.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1.2">𝑊</ci><apply id="S4.SS1.SSS3.p4.1.m1.1.1.3.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1.3"><times id="S4.SS1.SSS3.p4.1.m1.1.1.3.1.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1.3.1"></times><ci id="S4.SS1.SSS3.p4.1.m1.1.1.3.2.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1.3.2">𝑖</ci><ci id="S4.SS1.SSS3.p4.1.m1.1.1.3.3.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.1.m1.1c">W_{ij}</annotation></semantics></math> emerged as crucial elements, our ablation studies revealed that eliminating them in the evolved model (e.g., by setting <math id="S4.SS1.SSS3.p4.2.m2.1" class="ltx_Math" alttext="W_{ij}=1" display="inline"><semantics id="S4.SS1.SSS3.p4.2.m2.1a"><mrow id="S4.SS1.SSS3.p4.2.m2.1.1" xref="S4.SS1.SSS3.p4.2.m2.1.1.cmml"><msub id="S4.SS1.SSS3.p4.2.m2.1.1.2" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.cmml"><mi id="S4.SS1.SSS3.p4.2.m2.1.1.2.2" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.2.cmml">W</mi><mrow id="S4.SS1.SSS3.p4.2.m2.1.1.2.3" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3.cmml"><mi id="S4.SS1.SSS3.p4.2.m2.1.1.2.3.2" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.SS1.SSS3.p4.2.m2.1.1.2.3.1" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3.1.cmml">​</mo><mi id="S4.SS1.SSS3.p4.2.m2.1.1.2.3.3" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3.3.cmml">j</mi></mrow></msub><mo id="S4.SS1.SSS3.p4.2.m2.1.1.1" xref="S4.SS1.SSS3.p4.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS3.p4.2.m2.1.1.3" xref="S4.SS1.SSS3.p4.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.2.m2.1b"><apply id="S4.SS1.SSS3.p4.2.m2.1.1.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1"><eq id="S4.SS1.SSS3.p4.2.m2.1.1.1.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.1"></eq><apply id="S4.SS1.SSS3.p4.2.m2.1.1.2.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.SSS3.p4.2.m2.1.1.2.1.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.2">subscript</csymbol><ci id="S4.SS1.SSS3.p4.2.m2.1.1.2.2.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.2">𝑊</ci><apply id="S4.SS1.SSS3.p4.2.m2.1.1.2.3.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3"><times id="S4.SS1.SSS3.p4.2.m2.1.1.2.3.1.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3.1"></times><ci id="S4.SS1.SSS3.p4.2.m2.1.1.2.3.2.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3.2">𝑖</ci><ci id="S4.SS1.SSS3.p4.2.m2.1.1.2.3.3.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3.3">𝑗</ci></apply></apply><cn type="integer" id="S4.SS1.SSS3.p4.2.m2.1.1.3.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.2.m2.1c">W_{ij}=1</annotation></semantics></math>) led to a performance decline exceeding 20 percent, highlighting their importance in the model’s efficacy.</p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" style="width:130.1pt;"><img src="/html/2403.13187/assets/x3.png" id="S4.F4.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="368" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span id="S4.F4.1.2.1" class="ltx_text ltx_font_bold">Evolved Configurations for PS merging.</span> Although the weights are similar across the three source models, the pronounced density from the Japanese LLM underscores its pivotal role in our merged model.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F4.18" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" style="width:294.9pt;"><img src="/html/2403.13187/assets/x4.png" id="S4.F4.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="153" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span id="S4.F4.12.10.2" class="ltx_text ltx_font_bold">Evolved Configurations for DFS Merging of models <math id="S4.F4.11.9.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.F4.11.9.1.m1.1b"><mi id="S4.F4.11.9.1.m1.1.1" xref="S4.F4.11.9.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.F4.11.9.1.m1.1c"><ci id="S4.F4.11.9.1.m1.1.1.cmml" xref="S4.F4.11.9.1.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.11.9.1.m1.1d">A</annotation></semantics></math> and <math id="S4.F4.12.10.2.m2.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S4.F4.12.10.2.m2.1b"><mi id="S4.F4.12.10.2.m2.1.1" xref="S4.F4.12.10.2.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.F4.12.10.2.m2.1c"><ci id="S4.F4.12.10.2.m2.1.1.cmml" xref="S4.F4.12.10.2.m2.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.12.10.2.m2.1d">B</annotation></semantics></math>.</span> The three figures depict the evolution of the inference path on the MGSM-JA task. The y-axis represents the layer index <math id="S4.F4.13.11.m1.2" class="ltx_Math" alttext="l\in[1,M]" display="inline"><semantics id="S4.F4.13.11.m1.2b"><mrow id="S4.F4.13.11.m1.2.3" xref="S4.F4.13.11.m1.2.3.cmml"><mi id="S4.F4.13.11.m1.2.3.2" xref="S4.F4.13.11.m1.2.3.2.cmml">l</mi><mo id="S4.F4.13.11.m1.2.3.1" xref="S4.F4.13.11.m1.2.3.1.cmml">∈</mo><mrow id="S4.F4.13.11.m1.2.3.3.2" xref="S4.F4.13.11.m1.2.3.3.1.cmml"><mo stretchy="false" id="S4.F4.13.11.m1.2.3.3.2.1" xref="S4.F4.13.11.m1.2.3.3.1.cmml">[</mo><mn id="S4.F4.13.11.m1.1.1" xref="S4.F4.13.11.m1.1.1.cmml">1</mn><mo id="S4.F4.13.11.m1.2.3.3.2.2" xref="S4.F4.13.11.m1.2.3.3.1.cmml">,</mo><mi id="S4.F4.13.11.m1.2.2" xref="S4.F4.13.11.m1.2.2.cmml">M</mi><mo stretchy="false" id="S4.F4.13.11.m1.2.3.3.2.3" xref="S4.F4.13.11.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.13.11.m1.2c"><apply id="S4.F4.13.11.m1.2.3.cmml" xref="S4.F4.13.11.m1.2.3"><in id="S4.F4.13.11.m1.2.3.1.cmml" xref="S4.F4.13.11.m1.2.3.1"></in><ci id="S4.F4.13.11.m1.2.3.2.cmml" xref="S4.F4.13.11.m1.2.3.2">𝑙</ci><interval closure="closed" id="S4.F4.13.11.m1.2.3.3.1.cmml" xref="S4.F4.13.11.m1.2.3.3.2"><cn type="integer" id="S4.F4.13.11.m1.1.1.cmml" xref="S4.F4.13.11.m1.1.1">1</cn><ci id="S4.F4.13.11.m1.2.2.cmml" xref="S4.F4.13.11.m1.2.2">𝑀</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.13.11.m1.2d">l\in[1,M]</annotation></semantics></math>, and the x-axis corresponds to the path index <math id="S4.F4.14.12.m2.2" class="ltx_Math" alttext="t\in[1,T]" display="inline"><semantics id="S4.F4.14.12.m2.2b"><mrow id="S4.F4.14.12.m2.2.3" xref="S4.F4.14.12.m2.2.3.cmml"><mi id="S4.F4.14.12.m2.2.3.2" xref="S4.F4.14.12.m2.2.3.2.cmml">t</mi><mo id="S4.F4.14.12.m2.2.3.1" xref="S4.F4.14.12.m2.2.3.1.cmml">∈</mo><mrow id="S4.F4.14.12.m2.2.3.3.2" xref="S4.F4.14.12.m2.2.3.3.1.cmml"><mo stretchy="false" id="S4.F4.14.12.m2.2.3.3.2.1" xref="S4.F4.14.12.m2.2.3.3.1.cmml">[</mo><mn id="S4.F4.14.12.m2.1.1" xref="S4.F4.14.12.m2.1.1.cmml">1</mn><mo id="S4.F4.14.12.m2.2.3.3.2.2" xref="S4.F4.14.12.m2.2.3.3.1.cmml">,</mo><mi id="S4.F4.14.12.m2.2.2" xref="S4.F4.14.12.m2.2.2.cmml">T</mi><mo stretchy="false" id="S4.F4.14.12.m2.2.3.3.2.3" xref="S4.F4.14.12.m2.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.14.12.m2.2c"><apply id="S4.F4.14.12.m2.2.3.cmml" xref="S4.F4.14.12.m2.2.3"><in id="S4.F4.14.12.m2.2.3.1.cmml" xref="S4.F4.14.12.m2.2.3.1"></in><ci id="S4.F4.14.12.m2.2.3.2.cmml" xref="S4.F4.14.12.m2.2.3.2">𝑡</ci><interval closure="closed" id="S4.F4.14.12.m2.2.3.3.1.cmml" xref="S4.F4.14.12.m2.2.3.3.2"><cn type="integer" id="S4.F4.14.12.m2.1.1.cmml" xref="S4.F4.14.12.m2.1.1">1</cn><ci id="S4.F4.14.12.m2.2.2.cmml" xref="S4.F4.14.12.m2.2.2">𝑇</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.14.12.m2.2d">t\in[1,T]</annotation></semantics></math>. Blue markers indicate path steps utilizing layers from model <math id="S4.F4.15.13.m3.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.F4.15.13.m3.1b"><mi id="S4.F4.15.13.m3.1.1" xref="S4.F4.15.13.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.F4.15.13.m3.1c"><ci id="S4.F4.15.13.m3.1.1.cmml" xref="S4.F4.15.13.m3.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.15.13.m3.1d">A</annotation></semantics></math>, and red markers denotes those from <math id="S4.F4.16.14.m4.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S4.F4.16.14.m4.1b"><mi id="S4.F4.16.14.m4.1.1" xref="S4.F4.16.14.m4.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.F4.16.14.m4.1c"><ci id="S4.F4.16.14.m4.1.1.cmml" xref="S4.F4.16.14.m4.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.16.14.m4.1d">B</annotation></semantics></math>. Marker size reflects the magnitude of the scaling factor <math id="S4.F4.17.15.m5.1" class="ltx_Math" alttext="W_{ij}" display="inline"><semantics id="S4.F4.17.15.m5.1b"><msub id="S4.F4.17.15.m5.1.1" xref="S4.F4.17.15.m5.1.1.cmml"><mi id="S4.F4.17.15.m5.1.1.2" xref="S4.F4.17.15.m5.1.1.2.cmml">W</mi><mrow id="S4.F4.17.15.m5.1.1.3" xref="S4.F4.17.15.m5.1.1.3.cmml"><mi id="S4.F4.17.15.m5.1.1.3.2" xref="S4.F4.17.15.m5.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S4.F4.17.15.m5.1.1.3.1" xref="S4.F4.17.15.m5.1.1.3.1.cmml">​</mo><mi id="S4.F4.17.15.m5.1.1.3.3" xref="S4.F4.17.15.m5.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.F4.17.15.m5.1c"><apply id="S4.F4.17.15.m5.1.1.cmml" xref="S4.F4.17.15.m5.1.1"><csymbol cd="ambiguous" id="S4.F4.17.15.m5.1.1.1.cmml" xref="S4.F4.17.15.m5.1.1">subscript</csymbol><ci id="S4.F4.17.15.m5.1.1.2.cmml" xref="S4.F4.17.15.m5.1.1.2">𝑊</ci><apply id="S4.F4.17.15.m5.1.1.3.cmml" xref="S4.F4.17.15.m5.1.1.3"><times id="S4.F4.17.15.m5.1.1.3.1.cmml" xref="S4.F4.17.15.m5.1.1.3.1"></times><ci id="S4.F4.17.15.m5.1.1.3.2.cmml" xref="S4.F4.17.15.m5.1.1.3.2">𝑖</ci><ci id="S4.F4.17.15.m5.1.1.3.3.cmml" xref="S4.F4.17.15.m5.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.17.15.m5.1d">W_{ij}</annotation></semantics></math>. The evolutionary search result includes most layers in <math id="S4.F4.18.16.m6.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.F4.18.16.m6.1b"><mi id="S4.F4.18.16.m6.1.1" xref="S4.F4.18.16.m6.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.F4.18.16.m6.1c"><ci id="S4.F4.18.16.m6.1.1.cmml" xref="S4.F4.18.16.m6.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.18.16.m6.1d">A</annotation></semantics></math> at an early stage and then alternates between layers from both models. This result is from our 10B model (PS+DFS).</figcaption>
</figure>
</div>
</div>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Evolving Japanese VLM</h3>

<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Multi-modality Extension</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p id="S4.SS2.SSS1.p1.1" class="ltx_p">We now extend our method to multi-modal models, and evolve a culturally-specific content aware Japanese VLM. VLMs have recently shown remarkable progress by applying the powerful instruction-following capabilities of pre-trained LLMs. The architecture of a VLM generally consists of three components: (1) A vision encoder to extract image features; (2) An LLM to generate text (for the purpose of describing an image); and (3) A projection network to map image features into the LLM’s embedding space&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>, <a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>, <a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>, <a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">31</span></a>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>. Crucially, the LLM component is initialized with powerful pre-trained LLMs for their text generation capabilities. During training, the projection network and optionally the LLM are trained on various vision-language datasets, while the vision encoder is fixed.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Setup</h4>

<section id="S4.SS2.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Models</h5>

<div id="S4.SS2.SSS2.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS2.Px1.p1.1" class="ltx_p">The LLM component inside a VLM can be regarded as a standalone LLM, with the extra capability of understanding visual <span id="S4.SS2.SSS2.Px1.p1.1.1" class="ltx_text ltx_font_italic">soft prompts</span>.
From this perspective, by fixing the vision encoder and the projection network and only focusing on the LLM component, it is straightforward to apply the methodologies detailed in Section&nbsp;<a href="#S3" title="3 Method ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> to produce a new LLM with expanded capabilities.</p>
</div>
<div id="S4.SS2.SSS2.Px1.p2" class="ltx_para">
<p id="S4.SS2.SSS2.Px1.p2.1" class="ltx_p">In this experiment, we merge a Japanese LLM and the LLM component in a VLM in the parameter space. We select <span id="S4.SS2.SSS2.Px1.p2.1.1" class="ltx_text ltx_font_typewriter">shisa-gamma-7b-v1</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>]</cite> as the Japanese LLM and <span id="S4.SS2.SSS2.Px1.p2.1.2" class="ltx_text ltx_font_typewriter">LLaVA-1.6-Mistral-7B</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>]</cite> as the VLM. Both models are fine-tunes of the <span id="S4.SS2.SSS2.Px1.p2.1.3" class="ltx_text ltx_font_typewriter">Mistral-7B-v0.1</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite> base model.</p>
</div>
</section>
<section id="S4.SS2.SSS2.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Dataset</h5>

<div id="S4.SS2.SSS2.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS2.Px2.p1.1" class="ltx_p">To the best of our knowledge, publically accessible Japanese VLM datasets are scarce. In response, we created a new open Japanese VLM benchmark and assessed our VLM on a widely recognized Japanese VQA dataset. Our new benchmark dataset consists of:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">JA-VG-VQA-500:</span> A 500-sample test set extracted from the Japanese Visual Genome VQA dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">43</span></a>]</cite>.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">JA-VLM-Bench-In-the-Wild:</span> A Japanese version of LLaVA-Bench-In-the-Wild&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">33</span></a>]</cite> . We compiled a rich collection of 42 images, accompanied by a total of 50 questions, featuring a variety of Japanese cultural elements and objects found in Japan. The QAs were crafted with the assistance of GPT-4V&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>]</cite> and underwent a human-in-the-loop filtering process to eliminate nonsensical outcomes. Compared to the JA-VG-VQA-500 dataset, our set poses more complex challenges, demanding more nuanced and detailed responses.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS2.SSS2.Px2.p2" class="ltx_para">
<p id="S4.SS2.SSS2.Px2.p2.1" class="ltx_p">We used another subset of the Japanese Visual Genome VQA dataset during the evolutionary search. This subset is not overlapped with examples in the JA-VG-VQA-500 dataset, to avoid leakage in the optimization process.</p>
</div>
</section>
<section id="S4.SS2.SSS2.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Evaluation</h5>

<div id="S4.SS2.SSS2.Px3.p1" class="ltx_para">
<p id="S4.SS2.SSS2.Px3.p1.1" class="ltx_p">We consider two baselines in our experiments: <span id="S4.SS2.SSS2.Px3.p1.1.1" class="ltx_text ltx_font_typewriter">LLaVA-1.6-Mistral-7B</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>]</cite>, one of our source models, and <span id="S4.SS2.SSS2.Px3.p1.1.2" class="ltx_text ltx_font_typewriter">Japanese Stable VLM</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">44</span></a>]</cite> a Japanese VLM trained from scratch on Japanese datasets.</p>
</div>
<div id="S4.SS2.SSS2.Px3.p2" class="ltx_para">
<p id="S4.SS2.SSS2.Px3.p2.1" class="ltx_p">All models adopt the same generation configurations, with deterministic decoding. We compute ROUGE-L with a Japanese language detector to replace non-Japanese responses with empty texts, resulting in a score of zero for non-Japanese responses. To be consistent with our LLM experiments in Section&nbsp;<a href="#S4.SS1" title="4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, we also employed fasttext&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>, <a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>]</cite> for this language detection task. However, we made an exception for cases where the ground-truth answer itself contains non-Japanese but commonly seen words in Japanese texts (e.g., a widely recognized acronym such as “UFO”). In these instances, non-Japanese responses from models are not converted to empty texts.</p>
</div>
</section>
<section id="S4.SS2.SSS2.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Optimization</h5>

<div id="S4.SS2.SSS2.Px4.p1" class="ltx_para">
<p id="S4.SS2.SSS2.Px4.p1.1" class="ltx_p">We use the identical settings as the earlier LLM PS-merging experiment in Section&nbsp;<a href="#S4.SS1" title="4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, and TIES-Merging with DARE for merging the source models in the parameter space.</p>
</div>
</section>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>Results</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p id="S4.SS2.SSS3.p1.1" class="ltx_p">Table&nbsp;<a href="#S4.T3" title="Table 3 ‣ 4.2.3 Results ‣ 4.2 Evolving Japanese VLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> compares the performance of our VLM with the baselines. Please note that the Japanese Stable VLM cannot be evaluated on JA-VG-VQA-500 because it was trained on this dataset.</p>
</div>
<div id="S4.SS2.SSS3.p2" class="ltx_para">
<p id="S4.SS2.SSS3.p2.1" class="ltx_p">Our VLM’s enhanced performance on the JA-VG-VQA-500 benchmark indicates its proficiency in Japanese, highlighting the successful integration of the source Japanese LLM with the LLM component of the original VLM through evolutionary merging. Furthermore, our VLM’s superior results on the JA-VLM-Bench-In-the-Wild compared to both baselines exhibits its adeptness at navigating culturally-specific content.</p>
</div>
<div id="S4.SS2.SSS3.p3" class="ltx_para">
<p id="S4.SS2.SSS3.p3.1" class="ltx_p">Besides the quantitative results in Table&nbsp;<a href="#S4.T3" title="Table 3 ‣ 4.2.3 Results ‣ 4.2 Evolving Japanese VLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we qualitatively compare our VLM with the baseline models in Appendix&nbsp;<a href="#A3" title="Appendix C Case Study ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a>. Our evolved model is able to handle Japanese culture-specific content remarkably well, generally producing more detailed responses with correct information.</p>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span><span id="S4.T3.4.1" class="ltx_text ltx_font_bold">Performance Comparison of the VLMs.</span> LLaVA 1.6 Mistral 7B is the source VLM and Japanese Stable VLM is an open-sourced Japanese VLM. While JA-VG-VQA-500 measures general VQA abilities in Japanese, JA-VLM-Bench-In-the-Wild evaluates the model’s handling of complex VQA tasks within Japanese cultural contexts.</figcaption>
<table id="S4.T3.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.2.3.1" class="ltx_tr">
<th id="S4.T3.2.3.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S4.T3.2.3.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.2.3.1.2.1" class="ltx_text ltx_font_bold">JA-VG-VQA-500</span></th>
<th id="S4.T3.2.3.1.3" class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt"><span id="S4.T3.2.3.1.3.1" class="ltx_text ltx_font_bold">JA-VLM-Bench-In-the-Wild</span></th>
</tr>
<tr id="S4.T3.2.2" class="ltx_tr">
<th id="S4.T3.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row"><span id="S4.T3.2.2.3.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S4.T3.1.1.1" class="ltx_td ltx_align_right ltx_th ltx_th_column"><span id="S4.T3.1.1.1.1" class="ltx_text" style="font-size:90%;">(ROUGE-L <math id="S4.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T3.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
<th id="S4.T3.2.2.2" class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column"><span id="S4.T3.2.2.2.1" class="ltx_text" style="font-size:90%;">(ROUGE-L <math id="S4.T3.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T3.2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T3.2.2.2.1.m1.1.1" xref="S4.T3.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.1.m1.1b"><ci id="S4.T3.2.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.2.4.1" class="ltx_tr">
<th id="S4.T3.2.4.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">LLaVA 1.6 Mistral 7B</th>
<td id="S4.T3.2.4.1.2" class="ltx_td ltx_align_right ltx_border_t">14.3</td>
<td id="S4.T3.2.4.1.3" class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t">41.1</td>
</tr>
<tr id="S4.T3.2.5.2" class="ltx_tr">
<th id="S4.T3.2.5.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Japanese Stable VLM</th>
<td id="S4.T3.2.5.2.2" class="ltx_td ltx_align_right">-</td>
<td id="S4.T3.2.5.2.3" class="ltx_td ltx_nopad_r ltx_align_right">40.5</td>
</tr>
<tr id="S4.T3.2.6.3" class="ltx_tr">
<th id="S4.T3.2.6.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t"><span id="S4.T3.2.6.3.1.1" class="ltx_text ltx_font_bold">Ours</span></th>
<td id="S4.T3.2.6.3.2" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t"><span id="S4.T3.2.6.3.2.1" class="ltx_text ltx_font_bold">19.7</span></td>
<td id="S4.T3.2.6.3.3" class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb ltx_border_t"><span id="S4.T3.2.6.3.3.1" class="ltx_text ltx_font_bold">51.2</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion and Future Work</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this report, we propose a general method that uses evolutionary techniques to efficiently discover the best ways to combine different models from the vast ocean of different open-source models with diverse capabilities. By working with the vast collective intelligence of existing open models, our method is able to automatically create new foundation models with desired capabilities specified by the user. We find that our approach is able to automatically discover novel ways to merge different models from vastly different domains (e.g., non-English language and Math, or non-English language and Vision), in non-trivial ways that might be difficult for human experts to discover themselves.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">To test our approach, we apply our method to automatically create a Japanese LLM capable of Math reasoning, and a culturally-specific content aware Japanese VLM. Surprisingly, we find that both models achieve state-of-the-art results on several LLM and Vision benchmarks, while not being explicitly optimized to be good at these benchmarks, attaining the top performance on a vast array of other Japanese LLM benchmarks, even exceeding the performance of some previous SOTA 70B parameter Japanese LLMs.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">With these promising initial results, we believe we are just scratching the surface of unlocking the full capabilities of evolutionary model merging, and this is the inception of a long-term development of applying evolutionary principles to foundation model development.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">Currently, we are already achieving promising results in applying evolutionary model merging to image diffusion models, enabling the creation of high performance cross-domain image generation models by merging existing building blocks in novel ways discovered by evolution.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">The method currently requires the user to select a set of source models to use as ingredients for evolutionary search. We believe it is also possible to leverage evolution to search for candidate source models from a vast population of existing models as well. In addition to model selection, we are also exploring using evolution to produce swarms of diverse foundation models each with its own niche and behaviors. This holds the potential of enabling the emergence of a collective intelligence consisting of a swarm of models capable of self-improvement by continuously producing new complementary internal models of the world through interaction.</p>
</div>
<div id="S5.p6" class="ltx_para">
<p id="S5.p6.1" class="ltx_p">Related to our work is an experiment, called Automerge&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>]</cite>, released at around the same time as this work. This interesting experiment works by selecting two random models from the top 20 models on the Open LLM Leaderboard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite> and randomly apply SLERP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">48</span></a>]</cite> or DARE-TIES&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">51</span></a>, <a href="#bib.bib50" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite> to create new models. Over time, some of these models will do well, or even better on the benchmark tasks that define this leaderboard, becoming part of the leaderboard. We predict this approach will lead to combinations of the merged models that overfit to the benchmark tasks defined on the leaderboard. The author acknowledged that the idea behind this project was less about creating better models, but more about getting more metrics to help derive a more principled approach to model merging.</p>
</div>
<div id="S5.p7" class="ltx_para">
<p id="S5.p7.1" class="ltx_p">Our work takes an orthogonal approach of optimizing for tasks outside of the domain specified by the original leaderboard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite>, rather than being confined by it. As we have shown, surprisingly, stepping away from optimizing for a particular benchmark occasionally results in even greater generalization to numerous other benchmark tasks that we had not intended to optimize for, and such emergent generalization might be the key to unlocking the next great advancements in AI.</p>
</div>
<div id="S5.p8" class="ltx_para">
<p id="S5.p8.1" class="ltx_p">The ability to evolve new models with new emergent capabilities, from a large variety of existing, diverse models with various capabilities have important implications. With the rising costs and resource requirement for training foundation models, by leveraging the rich variety of foundation models in the rich open-source ecosystem, large institutions or governments may consider the cheaper evolutionary approach for developing proof-of-concept prototype models quickly, before committing substantial capital or tapping into the nation’s resources to develop entirely custom models from scratch, if that is even needed at all.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We acknowledge that although our evolutionary model merging effectively integrates diverse expertise from the source models, it also inherits their limitations. For instance, we encountered instances where the merged models produced responses that lacked logical coherence. Additionally, this study does not encompass instruction fine-tuning or alignment, raising the potential for the models to yield outputs that may be factually flawed.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Author Contributions</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Takuya Akiba initiated the “Evolutionary Optimization of Model Merging Recipes” project, wrote the project design document, and initiated the parameter space model merging experiments, laying the groundwork for the methodology. Makoto Shing expanded the parameter space model merging to encompass vision-language models and diffusion models. Yujin Tang directed the efforts in data flow space model merging by incorporating ideas and methods inspired from the neural architecture search and morphology evolution literature, establishing foundational methods in this domain and in hybrid merging strategies. Qi Sun contributed to the implementation of our parameter space model merging framework and assisted in model evaluation. David Ha provided overarching guidance for the research project, offering technical insight, advice, feedback and writing.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.2.2.1" class="ltx_text" style="font-size:90%;">[1]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">        



</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.4.4.1" class="ltx_text" style="font-size:90%;">AI [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.6.1" class="ltx_text" style="font-size:90%;">
Open AI. 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.7.1" class="ltx_text" style="font-size:90%;">GPT-4V(ision) System Card.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib2.8.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://cdn.openai.com/papers/GPTV_System_Card.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://cdn.openai.com/papers/GPTV_System_Card.pdf</a><span id="bib.bib2.9.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.5.5.1" class="ltx_text" style="font-size:90%;">Akiba et&nbsp;al</span><span id="bib.bib3.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib3.7.7.3" class="ltx_text" style="font-size:90%;"> [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.9.1" class="ltx_text" style="font-size:90%;">
Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.10.1" class="ltx_text" style="font-size:90%;">Optuna: A Next-generation Hyperparameter Optimization Framework. In </span><em id="bib.bib3.11.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em><span id="bib.bib3.12.3" class="ltx_text" style="font-size:90%;"> (Anchorage, AK, USA) </span><em id="bib.bib3.13.4" class="ltx_emph ltx_font_italic" style="font-size:90%;">(KDD ’19)</em><span id="bib.bib3.14.5" class="ltx_text" style="font-size:90%;">. Association for Computing Machinery, New York, NY, USA, 2623–2631.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.15.1" class="ltx_text" style="font-size:90%;">

</span><a target="_blank" href="https://doi.org/10.1145/3292500.3330701" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://doi.org/10.1145/3292500.3330701</a><span id="bib.bib3.16.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.4.4.1" class="ltx_text" style="font-size:90%;">augmxnt [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.6.1" class="ltx_text" style="font-size:90%;">
augmxnt. 2023.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib4.7.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">shisa-gamma-7b</em><span id="bib.bib4.8.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.9.1" class="ltx_text" style="font-size:90%;">HuggingFace.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.10.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://hf.co/augmxnt/shisa-gamma-7b-v1" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://hf.co/augmxnt/shisa-gamma-7b-v1</a><span id="bib.bib4.11.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.4.4.1" class="ltx_text" style="font-size:90%;">AUTOMATIC1111 [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.6.1" class="ltx_text" style="font-size:90%;">
AUTOMATIC1111. 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.7.1" class="ltx_text" style="font-size:90%;">Stable Diffusion WebUI.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://github.com/AUTOMATIC1111/stable-diffusion-webui</a><span id="bib.bib5.8.1" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.5.5.1" class="ltx_text" style="font-size:90%;">Bai et&nbsp;al</span><span id="bib.bib6.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib6.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.9.1" class="ltx_text" style="font-size:90%;">
Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, and Jingren Zhou. 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.10.1" class="ltx_text" style="font-size:90%;">Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib6.11.1" class="ltx_text" style="font-size:90%;">arXiv:2308.12966&nbsp;[cs.CV]
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.5.5.1" class="ltx_text" style="font-size:90%;">Chern et&nbsp;al</span><span id="bib.bib7.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib7.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.9.1" class="ltx_text" style="font-size:90%;">
Ethan Chern, Haoyang Zou, Xuefeng Li, Jiewen Hu, Kehua Feng, Junlong Li, and Pengfei Liu. 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.10.1" class="ltx_text" style="font-size:90%;">Generative AI for Math: Abel.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/GAIR-NLP/abel" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://github.com/GAIR-NLP/abel</a><span id="bib.bib7.11.1" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.5.5.1" class="ltx_text" style="font-size:90%;">Cobbe et&nbsp;al</span><span id="bib.bib8.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib8.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.9.1" class="ltx_text" style="font-size:90%;">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.10.1" class="ltx_text" style="font-size:90%;">Training Verifiers to Solve Math Word Problems.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib8.11.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">CoRR</em><span id="bib.bib8.12.2" class="ltx_text" style="font-size:90%;"> abs/2110.14168 (2021).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.13.1" class="ltx_text" style="font-size:90%;">arXiv:2110.14168

</span><a target="_blank" href="https://arxiv.org/abs/2110.14168" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://arxiv.org/abs/2110.14168</a><span id="bib.bib8.14.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.5.5.1" class="ltx_text" style="font-size:90%;">Daheim et&nbsp;al</span><span id="bib.bib9.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib9.7.7.3" class="ltx_text" style="font-size:90%;"> [2024]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.9.1" class="ltx_text" style="font-size:90%;">
Nico Daheim, Thomas Möllenhoff, Edoardo Ponti, Iryna Gurevych, and Mohammad&nbsp;Emtiyaz Khan. 2024.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.10.1" class="ltx_text" style="font-size:90%;">Model Merging by Uncertainty-Based Gradient Matching. In </span><em id="bib.bib9.11.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">The Twelfth International Conference on Learning Representations</em><span id="bib.bib9.12.3" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.13.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://openreview.net/forum?id=D7KJmfEDQP" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://openreview.net/forum?id=D7KJmfEDQP</a><span id="bib.bib9.14.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.5.5.1" class="ltx_text" style="font-size:90%;">Dai et&nbsp;al</span><span id="bib.bib10.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib10.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.9.1" class="ltx_text" style="font-size:90%;">
Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng&nbsp;Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, and Steven Hoi. 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.10.1" class="ltx_text" style="font-size:90%;">InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib10.11.1" class="ltx_text" style="font-size:90%;">arXiv:2305.06500&nbsp;[cs.CV]
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.5.5.1" class="ltx_text" style="font-size:90%;">Deb et&nbsp;al</span><span id="bib.bib11.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib11.7.7.3" class="ltx_text" style="font-size:90%;"> [2002]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.9.1" class="ltx_text" style="font-size:90%;">
Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan. 2002.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.10.1" class="ltx_text" style="font-size:90%;">A fast and elitist multiobjective genetic algorithm: NSGA-II.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib11.11.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE transactions on evolutionary computation</em><span id="bib.bib11.12.2" class="ltx_text" style="font-size:90%;"> 6, 2 (2002), 182–197.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.4.4.1" class="ltx_text" style="font-size:90%;">Dziugaite and Roy [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.6.1" class="ltx_text" style="font-size:90%;">
Gintare&nbsp;Karolina Dziugaite and Daniel&nbsp;M Roy. 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.7.1" class="ltx_text" style="font-size:90%;">Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib12.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1703.11008</em><span id="bib.bib12.9.2" class="ltx_text" style="font-size:90%;"> (2017).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.4.4.1" class="ltx_text" style="font-size:90%;">Gaier and Ha [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.6.1" class="ltx_text" style="font-size:90%;">
Adam Gaier and David Ha. 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.7.1" class="ltx_text" style="font-size:90%;">Weight agnostic neural networks.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib13.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</em><span id="bib.bib13.9.2" class="ltx_text" style="font-size:90%;"> 32 (2019).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.5.5.1" class="ltx_text" style="font-size:90%;">Gao et&nbsp;al</span><span id="bib.bib14.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib14.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.9.1" class="ltx_text" style="font-size:90%;">
Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le&nbsp;Noac’h, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, and Andy Zou. 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.10.1" class="ltx_text" style="font-size:90%;">A framework for few-shot language model evaluation.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib14.11.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://doi.org/10.5281/zenodo.10256836" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://doi.org/10.5281/zenodo.10256836</a><span id="bib.bib14.12.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.5.5.1" class="ltx_text" style="font-size:90%;">Geva et&nbsp;al</span><span id="bib.bib15.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib15.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.9.1" class="ltx_text" style="font-size:90%;">
Mor Geva, Avi Caciularu, Kevin&nbsp;Ro Wang, and Yoav Goldberg. 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.10.1" class="ltx_text" style="font-size:90%;">Transformer feed-forward layers build predictions by promoting concepts in the vocabulary space.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib15.11.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2203.14680</em><span id="bib.bib15.12.2" class="ltx_text" style="font-size:90%;"> (2022).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.4.4.1" class="ltx_text" style="font-size:90%;">Goddard [2024]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.6.1" class="ltx_text" style="font-size:90%;">
Charles&nbsp;O. Goddard. 2024.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.7.1" class="ltx_text" style="font-size:90%;">mergekit.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib16.8.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://github.com/arcee-ai/mergekit" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://github.com/arcee-ai/mergekit</a><span id="bib.bib16.9.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.5.5.1" class="ltx_text" style="font-size:90%;">Ha et&nbsp;al</span><span id="bib.bib17.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib17.7.7.3" class="ltx_text" style="font-size:90%;"> [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.9.1" class="ltx_text" style="font-size:90%;">
David Ha, Andrew Dai, and Quoc&nbsp;V Le. 2016.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.10.1" class="ltx_text" style="font-size:90%;">Hypernetworks.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib17.11.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1609.09106</em><span id="bib.bib17.12.2" class="ltx_text" style="font-size:90%;"> (2016).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.4.4.1" class="ltx_text" style="font-size:90%;">Hansen [2006]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.6.1" class="ltx_text" style="font-size:90%;">
Nikolaus Hansen. 2006.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.7.1" class="ltx_text" style="font-size:90%;">The CMA evolution strategy: a comparing review.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib18.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Towards a new evolutionary computation: Advances in the estimation of distribution algorithms</em><span id="bib.bib18.9.2" class="ltx_text" style="font-size:90%;"> (2006), 75–102.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.4.4.1" class="ltx_text" style="font-size:90%;">Hochreiter and Schmidhuber [1994]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.6.1" class="ltx_text" style="font-size:90%;">
Sepp Hochreiter and Jürgen Schmidhuber. 1994.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.7.1" class="ltx_text" style="font-size:90%;">Simplifying neural nets by discovering flat minima.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib19.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</em><span id="bib.bib19.9.2" class="ltx_text" style="font-size:90%;"> 7 (1994).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.4.4.1" class="ltx_text" style="font-size:90%;">Hochreiter and Schmidhuber [1997]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.6.1" class="ltx_text" style="font-size:90%;">
Sepp Hochreiter and Jürgen Schmidhuber. 1997.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.7.1" class="ltx_text" style="font-size:90%;">Flat minima.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib20.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Neural computation</em><span id="bib.bib20.9.2" class="ltx_text" style="font-size:90%;"> 9, 1 (1997), 1–42.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.4.4.1" class="ltx_text" style="font-size:90%;">HuggingFace [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.6.1" class="ltx_text" style="font-size:90%;">
HuggingFace. 2023.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib21.7.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Open LLM Leaderboard</em><span id="bib.bib21.8.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.9.1" class="ltx_text" style="font-size:90%;">HuggingFace.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.10.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</a><span id="bib.bib21.11.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.5.5.1" class="ltx_text" style="font-size:90%;">Ilharco et&nbsp;al</span><span id="bib.bib22.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib22.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.9.1" class="ltx_text" style="font-size:90%;">
Gabriel Ilharco, Marco&nbsp;Tulio Ribeiro, Mitchell Wortsman, Suchin Gururangan, Ludwig Schmidt, Hannaneh Hajishirzi, and Ali Farhadi. 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.10.1" class="ltx_text" style="font-size:90%;">Editing models with task arithmetic.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib22.11.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2212.04089</em><span id="bib.bib22.12.2" class="ltx_text" style="font-size:90%;"> (2022).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.5.5.1" class="ltx_text" style="font-size:90%;">Jiang et&nbsp;al</span><span id="bib.bib23.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib23.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.9.1" class="ltx_text" style="font-size:90%;">
Albert&nbsp;Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio&nbsp;Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven&nbsp;Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William&nbsp;El Sayed. 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.10.1" class="ltx_text" style="font-size:90%;">Mistral 7B.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib23.11.1" class="ltx_text" style="font-size:90%;">arXiv:2310.06825&nbsp;[cs.CL]
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.5.5.1" class="ltx_text" style="font-size:90%;">Joulin et&nbsp;al</span><span id="bib.bib24.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib24.7.7.3" class="ltx_text" style="font-size:90%;"> [2016b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.9.1" class="ltx_text" style="font-size:90%;">
Armand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze, Hérve Jégou, and Tomas Mikolov. 2016b.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.10.1" class="ltx_text" style="font-size:90%;">FastText.zip: Compressing text classification models.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib24.11.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1612.03651</em><span id="bib.bib24.12.2" class="ltx_text" style="font-size:90%;"> (2016).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.5.5.1" class="ltx_text" style="font-size:90%;">Joulin et&nbsp;al</span><span id="bib.bib25.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib25.7.7.3" class="ltx_text" style="font-size:90%;"> [2016a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.9.1" class="ltx_text" style="font-size:90%;">
Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. 2016a.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.10.1" class="ltx_text" style="font-size:90%;">Bag of Tricks for Efficient Text Classification.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib25.11.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1607.01759</em><span id="bib.bib25.12.2" class="ltx_text" style="font-size:90%;"> (2016).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.5.5.1" class="ltx_text" style="font-size:90%;">Kaddour et&nbsp;al</span><span id="bib.bib26.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib26.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.9.1" class="ltx_text" style="font-size:90%;">
Jean Kaddour, Linqing Liu, Ricardo Silva, and Matt&nbsp;J Kusner. 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.10.1" class="ltx_text" style="font-size:90%;">When do flat minima optimizers work?
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib26.11.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib26.12.2" class="ltx_text" style="font-size:90%;"> 35 (2022), 16577–16595.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.5.5.1" class="ltx_text" style="font-size:90%;">Keskar et&nbsp;al</span><span id="bib.bib27.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib27.7.7.3" class="ltx_text" style="font-size:90%;"> [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.9.1" class="ltx_text" style="font-size:90%;">
Nitish&nbsp;Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak&nbsp;Peter Tang. 2017.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.10.1" class="ltx_text" style="font-size:90%;">On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima. In </span><em id="bib.bib27.11.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</em><span id="bib.bib27.12.3" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.13.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://openreview.net/forum?id=H1oyRlYgg" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://openreview.net/forum?id=H1oyRlYgg</a><span id="bib.bib27.14.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.4.4.1" class="ltx_text" style="font-size:90%;">Labonne [2024a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.6.1" class="ltx_text" style="font-size:90%;">
Maxime Labonne. 2024a.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.7.1" class="ltx_text" style="font-size:90%;">Automerger Experiment.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib28.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Tweet Thread</em><span id="bib.bib28.9.2" class="ltx_text" style="font-size:90%;"> (2024).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.10.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://twitter.com/maximelabonne/status/1767124527551549860" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://twitter.com/maximelabonne/status/1767124527551549860</a><span id="bib.bib28.11.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.4.4.1" class="ltx_text" style="font-size:90%;">Labonne [2024b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.6.1" class="ltx_text" style="font-size:90%;">
Maxime Labonne. 2024b.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.7.1" class="ltx_text" style="font-size:90%;">Merge Large Language Models with mergekit.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib29.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Hugging Face Blog</em><span id="bib.bib29.9.2" class="ltx_text" style="font-size:90%;"> (2024).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.10.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://huggingface.co/blog/mlabonne/merge-models" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://huggingface.co/blog/mlabonne/merge-models</a><span id="bib.bib29.11.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.5.5.1" class="ltx_text" style="font-size:90%;">Li et&nbsp;al</span><span id="bib.bib30.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib30.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.9.1" class="ltx_text" style="font-size:90%;">
Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.10.1" class="ltx_text" style="font-size:90%;">BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib30.11.1" class="ltx_text" style="font-size:90%;">arXiv:2301.12597&nbsp;[cs.CV]
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.5.5.1" class="ltx_text" style="font-size:90%;">Liu et&nbsp;al</span><span id="bib.bib31.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib31.7.7.3" class="ltx_text" style="font-size:90%;"> [2023a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.9.1" class="ltx_text" style="font-size:90%;">
Haotian Liu, Chunyuan Li, Yuheng Li, and Yong&nbsp;Jae Lee. 2023a.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.10.1" class="ltx_text" style="font-size:90%;">Improved Baselines with Visual Instruction Tuning.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib31.11.1" class="ltx_text" style="font-size:90%;">arXiv:2310.03744&nbsp;[cs.CV]
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.5.5.1" class="ltx_text" style="font-size:90%;">Liu et&nbsp;al</span><span id="bib.bib32.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib32.7.7.3" class="ltx_text" style="font-size:90%;"> [2024]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.9.1" class="ltx_text" style="font-size:90%;">
Haotian Liu, Chunyuan Li, Yuheng Li, Bo Li, Yuanhan Zhang, Sheng Shen, and Yong&nbsp;Jae Lee. 2024.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.10.1" class="ltx_text" style="font-size:90%;">LLaVA-NeXT: Improved reasoning, OCR, and world knowledge.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib32.11.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://llava-vl.github.io/blog/2024-01-30-llava-next/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://llava-vl.github.io/blog/2024-01-30-llava-next/</a><span id="bib.bib32.12.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib33.5.5.1" class="ltx_text" style="font-size:90%;">Liu et&nbsp;al</span><span id="bib.bib33.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib33.7.7.3" class="ltx_text" style="font-size:90%;"> [2023b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib33.9.1" class="ltx_text" style="font-size:90%;">
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong&nbsp;Jae Lee. 2023b.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.10.1" class="ltx_text" style="font-size:90%;">Visual Instruction Tuning.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib33.11.1" class="ltx_text" style="font-size:90%;">arXiv:2304.08485&nbsp;[cs.CV]
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib34.5.5.1" class="ltx_text" style="font-size:90%;">Luo et&nbsp;al</span><span id="bib.bib34.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib34.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib34.9.1" class="ltx_text" style="font-size:90%;">
Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang. 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.10.1" class="ltx_text" style="font-size:90%;">WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib34.11.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">CoRR</em><span id="bib.bib34.12.2" class="ltx_text" style="font-size:90%;"> abs/2308.09583 (2023).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.13.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://doi.org/10.48550/ARXIV.2308.09583" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://doi.org/10.48550/ARXIV.2308.09583</a><span id="bib.bib34.14.2" class="ltx_text" style="font-size:90%;">
arXiv:2308.09583
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib35.4.4.1" class="ltx_text" style="font-size:90%;">Matena and Raffel [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib35.6.1" class="ltx_text" style="font-size:90%;">
Michael&nbsp;S Matena and Colin&nbsp;A Raffel. 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.7.1" class="ltx_text" style="font-size:90%;">Merging models with fisher-weighted averaging.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib35.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib35.9.2" class="ltx_text" style="font-size:90%;"> 35 (2022), 17703–17716.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib36.5.5.1" class="ltx_text" style="font-size:90%;">Meng et&nbsp;al</span><span id="bib.bib36.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib36.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib36.9.1" class="ltx_text" style="font-size:90%;">
Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.10.1" class="ltx_text" style="font-size:90%;">Locating and editing factual associations in GPT.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib36.11.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib36.12.2" class="ltx_text" style="font-size:90%;"> 35 (2022), 17359–17372.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib37.4.4.1" class="ltx_text" style="font-size:90%;">nostalgebraist [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib37.6.1" class="ltx_text" style="font-size:90%;">
nostalgebraist. 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.7.1" class="ltx_text" style="font-size:90%;">Interpreting GPT: The Logit Lens.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens</a><span id="bib.bib37.8.1" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib37.9.1" class="ltx_text" style="font-size:90%;">Accessed: 2024-03-08.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib38.5.5.1" class="ltx_text" style="font-size:90%;">Petzka et&nbsp;al</span><span id="bib.bib38.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib38.7.7.3" class="ltx_text" style="font-size:90%;"> [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib38.9.1" class="ltx_text" style="font-size:90%;">
Henning Petzka, Michael Kamp, Linara Adilova, Cristian Sminchisescu, and Mario Boley. 2021.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.10.1" class="ltx_text" style="font-size:90%;">Relative Flatness and Generalization. In </span><em id="bib.bib38.11.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib38.12.3" class="ltx_text" style="font-size:90%;">, A.&nbsp;Beygelzimer, Y.&nbsp;Dauphin, P.&nbsp;Liang, and J.&nbsp;Wortman Vaughan (Eds.).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.13.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://openreview.net/forum?id=sygvo7ctb_" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://openreview.net/forum?id=sygvo7ctb_</a><span id="bib.bib38.14.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib39.5.5.1" class="ltx_text" style="font-size:90%;">Real et&nbsp;al</span><span id="bib.bib39.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib39.7.7.3" class="ltx_text" style="font-size:90%;"> [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib39.9.1" class="ltx_text" style="font-size:90%;">
Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc&nbsp;V Le. 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.10.1" class="ltx_text" style="font-size:90%;">Regularized evolution for image classifier architecture search. In </span><em id="bib.bib39.11.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the aaai conference on artificial intelligence</em><span id="bib.bib39.12.3" class="ltx_text" style="font-size:90%;">, Vol.&nbsp;33. 4780–4789.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib40.5.5.1" class="ltx_text" style="font-size:90%;">Rombach et&nbsp;al</span><span id="bib.bib40.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib40.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib40.9.1" class="ltx_text" style="font-size:90%;">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.10.1" class="ltx_text" style="font-size:90%;">High-resolution image synthesis with latent diffusion models. In </span><em id="bib.bib40.11.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span id="bib.bib40.12.3" class="ltx_text" style="font-size:90%;">. 10684–10695.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib41.4.4.1" class="ltx_text" style="font-size:90%;">Schmidhuber [1992]</span></span>
<span class="ltx_bibblock"><span id="bib.bib41.6.1" class="ltx_text" style="font-size:90%;">
Jürgen Schmidhuber. 1992.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.7.1" class="ltx_text" style="font-size:90%;">Learning to control fast-weight memories: An alternative to dynamic recurrent networks.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib41.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Neural Computation</em><span id="bib.bib41.9.2" class="ltx_text" style="font-size:90%;"> 4, 1 (1992), 131–139.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib42.5.5.1" class="ltx_text" style="font-size:90%;">Shi et&nbsp;al</span><span id="bib.bib42.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib42.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib42.9.1" class="ltx_text" style="font-size:90%;">
Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung&nbsp;Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei. 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.10.1" class="ltx_text" style="font-size:90%;">Language models are multilingual chain-of-thought reasoners. In </span><em id="bib.bib42.11.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em><span id="bib.bib42.12.3" class="ltx_text" style="font-size:90%;">. OpenReview.net.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.13.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://openreview.net/pdf?id=fR3wGCk-IXp" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://openreview.net/pdf?id=fR3wGCk-IXp</a><span id="bib.bib42.14.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib43.5.5.1" class="ltx_text" style="font-size:90%;">Shimizu et&nbsp;al</span><span id="bib.bib43.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib43.7.7.3" class="ltx_text" style="font-size:90%;"> [2018]</span></span>
<span class="ltx_bibblock"><span id="bib.bib43.9.1" class="ltx_text" style="font-size:90%;">
Nobuyuki Shimizu, Na Rong, and Takashi Miyazaki. 2018.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.10.1" class="ltx_text" style="font-size:90%;">Visual Question Answering Dataset for Bilingual Image Understanding: A Study of Cross-Lingual Transfer Using Attention Maps. In </span><em id="bib.bib43.11.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 27th International Conference on Computational Linguistics</em><span id="bib.bib43.12.3" class="ltx_text" style="font-size:90%;"> (Santa Fe, New Mexico, USA). Association for Computational Linguistics, 1918–1928.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.13.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="http://aclweb.org/anthology/C18-1163" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">http://aclweb.org/anthology/C18-1163</a><span id="bib.bib43.14.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib44.4.4.1" class="ltx_text" style="font-size:90%;">Shing and Akiba [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib44.6.1" class="ltx_text" style="font-size:90%;">
Makoto Shing and Takuya Akiba. 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.7.1" class="ltx_text" style="font-size:90%;">Japanese Stable VLM.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib44.8.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="https://huggingface.co/stabilityai/japanese-stable-vlm" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://huggingface.co/stabilityai/japanese-stable-vlm</a><span id="bib.bib44.9.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib45.5.5.1" class="ltx_text" style="font-size:90%;">So et&nbsp;al</span><span id="bib.bib45.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib45.7.7.3" class="ltx_text" style="font-size:90%;"> [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib45.9.1" class="ltx_text" style="font-size:90%;">
David So, Quoc Le, and Chen Liang. 2019.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.10.1" class="ltx_text" style="font-size:90%;">The evolved transformer. In </span><em id="bib.bib45.11.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International conference on machine learning</em><span id="bib.bib45.12.3" class="ltx_text" style="font-size:90%;">. PMLR, 5877–5886.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib46.4.4.1" class="ltx_text" style="font-size:90%;">Stanley and Miikkulainen [2002]</span></span>
<span class="ltx_bibblock"><span id="bib.bib46.6.1" class="ltx_text" style="font-size:90%;">
Kenneth&nbsp;O Stanley and Risto Miikkulainen. 2002.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.7.1" class="ltx_text" style="font-size:90%;">Evolving neural networks through augmenting topologies.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib46.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Evolutionary computation</em><span id="bib.bib46.9.2" class="ltx_text" style="font-size:90%;"> 10, 2 (2002), 99–127.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib47.5.5.1" class="ltx_text" style="font-size:90%;">Tang et&nbsp;al</span><span id="bib.bib47.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib47.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib47.9.1" class="ltx_text" style="font-size:90%;">
Yujin Tang, Yingtao Tian, and David Ha. 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.10.1" class="ltx_text" style="font-size:90%;">EvoJAX: Hardware-Accelerated Neuroevolution.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib47.11.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2202.05008</em><span id="bib.bib47.12.2" class="ltx_text" style="font-size:90%;"> (2022).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib48.4.4.1" class="ltx_text" style="font-size:90%;">White [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib48.6.1" class="ltx_text" style="font-size:90%;">
Tom White. 2016.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.7.1" class="ltx_text" style="font-size:90%;">Sampling generative networks.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib48.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1609.04468</em><span id="bib.bib48.9.2" class="ltx_text" style="font-size:90%;"> (2016).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib49.5.5.1" class="ltx_text" style="font-size:90%;">Wortsman et&nbsp;al</span><span id="bib.bib49.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib49.7.7.3" class="ltx_text" style="font-size:90%;"> [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib49.9.1" class="ltx_text" style="font-size:90%;">
Mitchell Wortsman, Gabriel Ilharco, Samir&nbsp;Ya Gadre, Rebecca Roelofs, Raphael Gontijo-Lopes, Ari&nbsp;S Morcos, Hongseok Namkoong, Ali Farhadi, Yair Carmon, Simon Kornblith, et&nbsp;al</span><span id="bib.bib49.10.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib49.11.3" class="ltx_text" style="font-size:90%;"> 2022.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.12.1" class="ltx_text" style="font-size:90%;">Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time. In </span><em id="bib.bib49.13.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</em><span id="bib.bib49.14.3" class="ltx_text" style="font-size:90%;">. PMLR, 23965–23998.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib50.5.5.1" class="ltx_text" style="font-size:90%;">Yadav et&nbsp;al</span><span id="bib.bib50.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib50.7.7.3" class="ltx_text" style="font-size:90%;"> [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib50.9.1" class="ltx_text" style="font-size:90%;">
Prateek Yadav, Derek Tam, Leshem Choshen, Colin&nbsp;A. Raffel, and Mohit Bansal. 2023.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.10.1" class="ltx_text" style="font-size:90%;">TIES-Merging: Resolving Interference When Merging Models. In </span><em id="bib.bib50.11.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023</em><span id="bib.bib50.12.3" class="ltx_text" style="font-size:90%;">, Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine (Eds.).
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.13.1" class="ltx_text" style="font-size:90%;">
</span><a target="_blank" href="http://papers.nips.cc/paper_files/paper/2023/hash/1644c9af28ab7916874f6fd6228a9bcf-Abstract-Conference.html" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">http://papers.nips.cc/paper_files/paper/2023/hash/1644c9af28ab7916874f6fd6228a9bcf-Abstract-Conference.html</a><span id="bib.bib50.14.2" class="ltx_text" style="font-size:90%;">
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib51.5.5.1" class="ltx_text" style="font-size:90%;">Yu et&nbsp;al</span><span id="bib.bib51.6.6.2" class="ltx_text" style="font-size:90%;">.</span><span id="bib.bib51.7.7.3" class="ltx_text" style="font-size:90%;"> [2024]</span></span>
<span class="ltx_bibblock"><span id="bib.bib51.9.1" class="ltx_text" style="font-size:90%;">
Le Yu, Bowen Yu, Haiyang Yu, Fei Huang, and Yongbin Li. 2024.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.10.1" class="ltx_text" style="font-size:90%;">Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span id="bib.bib51.11.1" class="ltx_text" style="font-size:90%;">arXiv:2311.03099&nbsp;[cs.CL]
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib52.4.4.1" class="ltx_text" style="font-size:90%;">Zoph and Le [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib52.6.1" class="ltx_text" style="font-size:90%;">
Barret Zoph and Quoc&nbsp;V Le. 2016.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.7.1" class="ltx_text" style="font-size:90%;">Neural architecture search with reinforcement learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib52.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1611.01578</em><span id="bib.bib52.9.2" class="ltx_text" style="font-size:90%;"> (2016).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Evaluation Details</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">In Table&nbsp;<a href="#S4.T1" title="Table 1 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, GPT-3.5 is <span id="A1.p1.1.1" class="ltx_text ltx_font_typewriter">gpt-3.5-turbo-0613</span>, GPT-4 is <span id="A1.p1.1.2" class="ltx_text ltx_font_typewriter">gpt-4-0125-preview</span>, Llama 2 70B is <span id="A1.p1.1.3" class="ltx_text ltx_font_typewriter">Llama-2-70b-chat</span>, Japanese Stable LM 70B is <span id="A1.p1.1.4" class="ltx_text ltx_font_typewriter">japanese-stablelm-instruct-beta-70b</span> and Swallow 70B is <span id="A1.p1.1.5" class="ltx_text ltx_font_typewriter">Swallow-70b-instruct-hf</span>.</p>
</div>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.1" class="ltx_p">For the evaluation using the Japanese LM Evaluation Harness, we utilized Stability AI Japan’s fork of lm-eval-harness<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable</a></span></span></span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite> and configured it according to their convention. This configuration is widely used and compatible with the results on their report<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://ja.stability.ai/blog/japanese-stable-lm-beta" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://ja.stability.ai/blog/japanese-stable-lm-beta</a></span></span></span> and Rinna leaderboards<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://rinnakk.github.io/research/benchmarks/lm/index.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://rinnakk.github.io/research/benchmarks/lm/index.html</a></span></span></span>, thus allowing direct comparison of scores with a large number of Japanese LLMs.</p>
</div>
<div id="A1.p3" class="ltx_para">
<p id="A1.p3.1" class="ltx_p">Table&nbsp;<a href="#A1.T4" title="Table 4 ‣ Appendix A Evaluation Details ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> is the full version of Table&nbsp;<a href="#S4.T2" title="Table 2 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, allowing for comparisons between our models and a wider range of models. Some of the numbers are from the Stability AI Japan report and the Rinna leaderboard. Despite having only 7B to 10B parameters, our models achieve higher scores than all existing &lt;70B parameters models and exhibit scores on par with the SOTA 70B models.</p>
</div>
<figure id="A1.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span><span id="A1.T4.2.1" class="ltx_text ltx_font_bold">Breakdown of JP-LMEH Scores for Japanese Language Proficiency (Full Version of Table&nbsp;<a href="#S4.T2" title="Table 2 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>)</span>. JP-LMEH (Japanese Language Model Evaluation Harness) is a benchmark suite consisting of 9 tasks, and the average score (Avg column) is used as an indicator of overall Japanese language proficiency.</figcaption>
<table id="A1.T4.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T4.3.1.1" class="ltx_tr">
<td id="A1.T4.3.1.1.1" class="ltx_td ltx_border_tt" style="padding-left:2.5pt;padding-right:2.5pt;"></td>
<td id="A1.T4.3.1.1.2" class="ltx_td ltx_border_tt" style="padding-left:2.5pt;padding-right:2.5pt;"></td>
<td id="A1.T4.3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" style="padding-left:2.5pt;padding-right:2.5pt;" colspan="10"><span id="A1.T4.3.1.1.3.1" class="ltx_text ltx_font_bold">JP Language Model Evaluation Harness</span></td>
</tr>
<tr id="A1.T4.3.2.2" class="ltx_tr">
<td id="A1.T4.3.2.2.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A1.T4.3.2.2.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="A1.T4.3.2.2.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A1.T4.3.2.2.2.1" class="ltx_text ltx_font_bold">Size</span></td>
<td id="A1.T4.3.2.2.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">JComQA</td>
<td id="A1.T4.3.2.2.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">JNLI</td>
<td id="A1.T4.3.2.2.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">MARC</td>
<td id="A1.T4.3.2.2.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">JSQuAD</td>
<td id="A1.T4.3.2.2.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">JAQKET</td>
<td id="A1.T4.3.2.2.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">XLSum</td>
<td id="A1.T4.3.2.2.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">XWino</td>
<td id="A1.T4.3.2.2.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">MGSM</td>
<td id="A1.T4.3.2.2.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">JCoLA</td>
<td id="A1.T4.3.2.2.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A1.T4.3.2.2.12.1" class="ltx_text ltx_font_bold">Avg</span></td>
</tr>
<tr id="A1.T4.3.3.3" class="ltx_tr">
<td id="A1.T4.3.3.3.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">shisa-gamma-7b-v1</td>
<td id="A1.T4.3.3.3.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.3.3.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">91.2</td>
<td id="A1.T4.3.3.3.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">72.1</td>
<td id="A1.T4.3.3.3.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">94.6</td>
<td id="A1.T4.3.3.3.6" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">73.9</td>
<td id="A1.T4.3.3.3.7" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">68.0</td>
<td id="A1.T4.3.3.3.8" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">25.9</td>
<td id="A1.T4.3.3.3.9" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">80.5</td>
<td id="A1.T4.3.3.3.10" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">29.6</td>
<td id="A1.T4.3.3.3.11" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">58.7</td>
<td id="A1.T4.3.3.3.12" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">66.1</td>
</tr>
<tr id="A1.T4.3.4.4" class="ltx_tr">
<td id="A1.T4.3.4.4.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">WizardMath-7B-V1.1</td>
<td id="A1.T4.3.4.4.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.4.4.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">74.7</td>
<td id="A1.T4.3.4.4.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">42.7</td>
<td id="A1.T4.3.4.4.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">90.4</td>
<td id="A1.T4.3.4.4.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">84.6</td>
<td id="A1.T4.3.4.4.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">68.5</td>
<td id="A1.T4.3.4.4.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">22.3</td>
<td id="A1.T4.3.4.4.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">69.8</td>
<td id="A1.T4.3.4.4.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">38.8</td>
<td id="A1.T4.3.4.4.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">48.9</td>
<td id="A1.T4.3.4.4.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">60.1</td>
</tr>
<tr id="A1.T4.3.5.5" class="ltx_tr">
<td id="A1.T4.3.5.5.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">Abel-7B-002</td>
<td id="A1.T4.3.5.5.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.5.5.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70.3</td>
<td id="A1.T4.3.5.5.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">51.8</td>
<td id="A1.T4.3.5.5.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">62.3</td>
<td id="A1.T4.3.5.5.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">83.8</td>
<td id="A1.T4.3.5.5.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">69.0</td>
<td id="A1.T4.3.5.5.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">22.5</td>
<td id="A1.T4.3.5.5.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">68.2</td>
<td id="A1.T4.3.5.5.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">28.0</td>
<td id="A1.T4.3.5.5.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">52.7</td>
<td id="A1.T4.3.5.5.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">56.5</td>
</tr>
<tr id="A1.T4.3.6.6" class="ltx_tr">
<td id="A1.T4.3.6.6.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A1.T4.3.6.6.1.1" class="ltx_text ltx_font_bold">Ours (PS)</span></td>
<td id="A1.T4.3.6.6.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.6.6.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">89.1</td>
<td id="A1.T4.3.6.6.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">65.7</td>
<td id="A1.T4.3.6.6.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">95.4</td>
<td id="A1.T4.3.6.6.6" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">89.5</td>
<td id="A1.T4.3.6.6.7" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">77.7</td>
<td id="A1.T4.3.6.6.8" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">25.5</td>
<td id="A1.T4.3.6.6.9" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">81.2</td>
<td id="A1.T4.3.6.6.10" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td id="A1.T4.3.6.6.11" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">60.5</td>
<td id="A1.T4.3.6.6.12" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A1.T4.3.6.6.12.1" class="ltx_text ltx_font_bold">70.5</span></td>
</tr>
<tr id="A1.T4.3.7.7" class="ltx_tr">
<td id="A1.T4.3.7.7.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A1.T4.3.7.7.1.1" class="ltx_text ltx_font_bold">Ours (DFS)</span></td>
<td id="A1.T4.3.7.7.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">10B</td>
<td id="A1.T4.3.7.7.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">67.7</td>
<td id="A1.T4.3.7.7.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">58.2</td>
<td id="A1.T4.3.7.7.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">53.5</td>
<td id="A1.T4.3.7.7.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">66.8</td>
<td id="A1.T4.3.7.7.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">54.3</td>
<td id="A1.T4.3.7.7.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">17.3</td>
<td id="A1.T4.3.7.7.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.6</td>
<td id="A1.T4.3.7.7.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">30.0</td>
<td id="A1.T4.3.7.7.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.6</td>
<td id="A1.T4.3.7.7.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A1.T4.3.7.7.12.1" class="ltx_text ltx_font_bold">53.2</span></td>
</tr>
<tr id="A1.T4.3.8.8" class="ltx_tr">
<td id="A1.T4.3.8.8.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A1.T4.3.8.8.1.1" class="ltx_text ltx_font_bold">Ours (PS+DFS)</span></td>
<td id="A1.T4.3.8.8.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">10B</td>
<td id="A1.T4.3.8.8.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">88.2</td>
<td id="A1.T4.3.8.8.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.3</td>
<td id="A1.T4.3.8.8.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">91.5</td>
<td id="A1.T4.3.8.8.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.6</td>
<td id="A1.T4.3.8.8.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">77.8</td>
<td id="A1.T4.3.8.8.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">23.2</td>
<td id="A1.T4.3.8.8.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">73.0</td>
<td id="A1.T4.3.8.8.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">40.0</td>
<td id="A1.T4.3.8.8.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">73.0</td>
<td id="A1.T4.3.8.8.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A1.T4.3.8.8.12.1" class="ltx_text ltx_font_bold">66.2</span></td>
</tr>
<tr id="A1.T4.3.9.9" class="ltx_tr">
<td id="A1.T4.3.9.9.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A1.T4.3.9.9.1.1" class="ltx_text ltx_font_bold">Ours (PS-A; see Appendix&nbsp;<a href="#A2" title="Appendix B Evolving for License Specific Open-Source Models ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>)</span></td>
<td id="A1.T4.3.9.9.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.9.9.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">87.0</td>
<td id="A1.T4.3.9.9.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">62.3</td>
<td id="A1.T4.3.9.9.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">91.9</td>
<td id="A1.T4.3.9.9.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">90.4</td>
<td id="A1.T4.3.9.9.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">77.4</td>
<td id="A1.T4.3.9.9.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">23.0</td>
<td id="A1.T4.3.9.9.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.9</td>
<td id="A1.T4.3.9.9.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">46.4</td>
<td id="A1.T4.3.9.9.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">63.6</td>
<td id="A1.T4.3.9.9.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;"><span id="A1.T4.3.9.9.12.1" class="ltx_text ltx_font_bold">69.0</span></td>
</tr>
<tr id="A1.T4.3.10.10" class="ltx_tr">
<td id="A1.T4.3.10.10.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-70b-instruct-hf</td>
<td id="A1.T4.3.10.10.2" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td id="A1.T4.3.10.10.3" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">95.3</td>
<td id="A1.T4.3.10.10.4" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">57.2</td>
<td id="A1.T4.3.10.10.5" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">91.7</td>
<td id="A1.T4.3.10.10.6" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">94.1</td>
<td id="A1.T4.3.10.10.7" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">93.9</td>
<td id="A1.T4.3.10.10.8" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">23.1</td>
<td id="A1.T4.3.10.10.9" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">83.3</td>
<td id="A1.T4.3.10.10.10" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">45.2</td>
<td id="A1.T4.3.10.10.11" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">59.5</td>
<td id="A1.T4.3.10.10.12" class="ltx_td ltx_align_right ltx_border_t" style="padding-left:2.5pt;padding-right:2.5pt;">71.5</td>
</tr>
<tr id="A1.T4.3.11.11" class="ltx_tr">
<td id="A1.T4.3.11.11.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-70b-hf</td>
<td id="A1.T4.3.11.11.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td id="A1.T4.3.11.11.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">94.8</td>
<td id="A1.T4.3.11.11.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">55.8</td>
<td id="A1.T4.3.11.11.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">87.8</td>
<td id="A1.T4.3.11.11.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.5</td>
<td id="A1.T4.3.11.11.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.8</td>
<td id="A1.T4.3.11.11.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">23.2</td>
<td id="A1.T4.3.11.11.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">83.7</td>
<td id="A1.T4.3.11.11.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">47.2</td>
<td id="A1.T4.3.11.11.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">60.7</td>
<td id="A1.T4.3.11.11.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">71.2</td>
</tr>
<tr id="A1.T4.3.12.12" class="ltx_tr">
<td id="A1.T4.3.12.12.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-base-beta-70b</td>
<td id="A1.T4.3.12.12.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td id="A1.T4.3.12.12.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.7</td>
<td id="A1.T4.3.12.12.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">45.2</td>
<td id="A1.T4.3.12.12.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">91.0</td>
<td id="A1.T4.3.12.12.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">94.2</td>
<td id="A1.T4.3.12.12.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">92.8</td>
<td id="A1.T4.3.12.12.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">25.4</td>
<td id="A1.T4.3.12.12.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">83.6</td>
<td id="A1.T4.3.12.12.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">41.2</td>
<td id="A1.T4.3.12.12.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">63.8</td>
<td id="A1.T4.3.12.12.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70.1</td>
</tr>
<tr id="A1.T4.3.13.13" class="ltx_tr">
<td id="A1.T4.3.13.13.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-14b-instruction</td>
<td id="A1.T4.3.13.13.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">14B</td>
<td id="A1.T4.3.13.13.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.7</td>
<td id="A1.T4.3.13.13.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">57.5</td>
<td id="A1.T4.3.13.13.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">90.0</td>
<td id="A1.T4.3.13.13.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.6</td>
<td id="A1.T4.3.13.13.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.0</td>
<td id="A1.T4.3.13.13.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">25.2</td>
<td id="A1.T4.3.13.13.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">77.4</td>
<td id="A1.T4.3.13.13.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">35.2</td>
<td id="A1.T4.3.13.13.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">67.3</td>
<td id="A1.T4.3.13.13.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">69.9</td>
</tr>
<tr id="A1.T4.3.14.14" class="ltx_tr">
<td id="A1.T4.3.14.14.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-instruct-beta-70b</td>
<td id="A1.T4.3.14.14.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td id="A1.T4.3.14.14.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">91.2</td>
<td id="A1.T4.3.14.14.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.4</td>
<td id="A1.T4.3.14.14.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">92.9</td>
<td id="A1.T4.3.14.14.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">87.1</td>
<td id="A1.T4.3.14.14.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">88.4</td>
<td id="A1.T4.3.14.14.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">24.3</td>
<td id="A1.T4.3.14.14.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">82.0</td>
<td id="A1.T4.3.14.14.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">37.2</td>
<td id="A1.T4.3.14.14.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">61.7</td>
<td id="A1.T4.3.14.14.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">68.3</td>
</tr>
<tr id="A1.T4.3.15.15" class="ltx_tr">
<td id="A1.T4.3.15.15.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-14b</td>
<td id="A1.T4.3.15.15.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">14B</td>
<td id="A1.T4.3.15.15.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.1</td>
<td id="A1.T4.3.15.15.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">41.7</td>
<td id="A1.T4.3.15.15.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">84.1</td>
<td id="A1.T4.3.15.15.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">94.2</td>
<td id="A1.T4.3.15.15.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">90.8</td>
<td id="A1.T4.3.15.15.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">21.3</td>
<td id="A1.T4.3.15.15.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.6</td>
<td id="A1.T4.3.15.15.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">37.6</td>
<td id="A1.T4.3.15.15.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.0</td>
<td id="A1.T4.3.15.15.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">67.4</td>
</tr>
<tr id="A1.T4.3.16.16" class="ltx_tr">
<td id="A1.T4.3.16.16.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">youri-7b-chat</td>
<td id="A1.T4.3.16.16.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.16.16.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">91.8</td>
<td id="A1.T4.3.16.16.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70.3</td>
<td id="A1.T4.3.16.16.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">96.7</td>
<td id="A1.T4.3.16.16.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">79.6</td>
<td id="A1.T4.3.16.16.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">83.7</td>
<td id="A1.T4.3.16.16.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">24.2</td>
<td id="A1.T4.3.16.16.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">80.9</td>
<td id="A1.T4.3.16.16.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">25.2</td>
<td id="A1.T4.3.16.16.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">53.8</td>
<td id="A1.T4.3.16.16.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">67.4</td>
</tr>
<tr id="A1.T4.3.17.17" class="ltx_tr">
<td id="A1.T4.3.17.17.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">Llama-2-70b-hf</td>
<td id="A1.T4.3.17.17.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td id="A1.T4.3.17.17.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.3</td>
<td id="A1.T4.3.17.17.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">53.0</td>
<td id="A1.T4.3.17.17.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70.4</td>
<td id="A1.T4.3.17.17.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.2</td>
<td id="A1.T4.3.17.17.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.5</td>
<td id="A1.T4.3.17.17.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">23.8</td>
<td id="A1.T4.3.17.17.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">79.8</td>
<td id="A1.T4.3.17.17.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">40.0</td>
<td id="A1.T4.3.17.17.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.4</td>
<td id="A1.T4.3.17.17.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">67.2</td>
</tr>
<tr id="A1.T4.3.18.18" class="ltx_tr">
<td id="A1.T4.3.18.18.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-7b-instruction</td>
<td id="A1.T4.3.18.18.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.18.18.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">88.0</td>
<td id="A1.T4.3.18.18.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">74.7</td>
<td id="A1.T4.3.18.18.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">92.3</td>
<td id="A1.T4.3.18.18.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">91.3</td>
<td id="A1.T4.3.18.18.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">82.5</td>
<td id="A1.T4.3.18.18.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">21.1</td>
<td id="A1.T4.3.18.18.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">76.8</td>
<td id="A1.T4.3.18.18.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">19.2</td>
<td id="A1.T4.3.18.18.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">53.8</td>
<td id="A1.T4.3.18.18.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">66.6</td>
</tr>
<tr id="A1.T4.3.19.19" class="ltx_tr">
<td id="A1.T4.3.19.19.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">youri-7b-instruction</td>
<td id="A1.T4.3.19.19.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.19.19.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">88.8</td>
<td id="A1.T4.3.19.19.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">63.6</td>
<td id="A1.T4.3.19.19.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.8</td>
<td id="A1.T4.3.19.19.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">92.2</td>
<td id="A1.T4.3.19.19.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">83.9</td>
<td id="A1.T4.3.19.19.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">24.7</td>
<td id="A1.T4.3.19.19.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.9</td>
<td id="A1.T4.3.19.19.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">17.2</td>
<td id="A1.T4.3.19.19.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">54.0</td>
<td id="A1.T4.3.19.19.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">66.3</td>
</tr>
<tr id="A1.T4.3.20.20" class="ltx_tr">
<td id="A1.T4.3.20.20.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">Qwen-14B</td>
<td id="A1.T4.3.20.20.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">14B</td>
<td id="A1.T4.3.20.20.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.5</td>
<td id="A1.T4.3.20.20.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.2</td>
<td id="A1.T4.3.20.20.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">76.7</td>
<td id="A1.T4.3.20.20.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.0</td>
<td id="A1.T4.3.20.20.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">79.5</td>
<td id="A1.T4.3.20.20.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">18.4</td>
<td id="A1.T4.3.20.20.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">71.6</td>
<td id="A1.T4.3.20.20.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">37.2</td>
<td id="A1.T4.3.20.20.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">61.0</td>
<td id="A1.T4.3.20.20.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.8</td>
</tr>
<tr id="A1.T4.3.21.21" class="ltx_tr">
<td id="A1.T4.3.21.21.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-MX-8x7b-NVE-v0.1</td>
<td id="A1.T4.3.21.21.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">47B</td>
<td id="A1.T4.3.21.21.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">92.0</td>
<td id="A1.T4.3.21.21.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">52.4</td>
<td id="A1.T4.3.21.21.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">59.8</td>
<td id="A1.T4.3.21.21.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.1</td>
<td id="A1.T4.3.21.21.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">91.9</td>
<td id="A1.T4.3.21.21.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">26.1</td>
<td id="A1.T4.3.21.21.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">72.9</td>
<td id="A1.T4.3.21.21.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">44.8</td>
<td id="A1.T4.3.21.21.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">59.2</td>
<td id="A1.T4.3.21.21.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.8</td>
</tr>
<tr id="A1.T4.3.22.22" class="ltx_tr">
<td id="A1.T4.3.22.22.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">youri-7b-chat-gptq</td>
<td id="A1.T4.3.22.22.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.22.22.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.5</td>
<td id="A1.T4.3.22.22.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">68.0</td>
<td id="A1.T4.3.22.22.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">96.0</td>
<td id="A1.T4.3.22.22.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">88.6</td>
<td id="A1.T4.3.22.22.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">79.7</td>
<td id="A1.T4.3.22.22.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">15.6</td>
<td id="A1.T4.3.22.22.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">79.1</td>
<td id="A1.T4.3.22.22.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">21.6</td>
<td id="A1.T4.3.22.22.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">53.8</td>
<td id="A1.T4.3.22.22.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.8</td>
</tr>
<tr id="A1.T4.3.23.23" class="ltx_tr">
<td id="A1.T4.3.23.23.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-7b-instruction-gguf</td>
<td id="A1.T4.3.23.23.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.23.23.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">87.9</td>
<td id="A1.T4.3.23.23.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">68.4</td>
<td id="A1.T4.3.23.23.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.6</td>
<td id="A1.T4.3.23.23.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.9</td>
<td id="A1.T4.3.23.23.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">79.8</td>
<td id="A1.T4.3.23.23.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">20.8</td>
<td id="A1.T4.3.23.23.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">77.3</td>
<td id="A1.T4.3.23.23.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">19.2</td>
<td id="A1.T4.3.23.23.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">55.3</td>
<td id="A1.T4.3.23.23.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.3</td>
</tr>
<tr id="A1.T4.3.24.24" class="ltx_tr">
<td id="A1.T4.3.24.24.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-14b-instruction-gguf</td>
<td id="A1.T4.3.24.24.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">14B</td>
<td id="A1.T4.3.24.24.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.3</td>
<td id="A1.T4.3.24.24.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">57.8</td>
<td id="A1.T4.3.24.24.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">51.7</td>
<td id="A1.T4.3.24.24.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">91.3</td>
<td id="A1.T4.3.24.24.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">86.2</td>
<td id="A1.T4.3.24.24.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">23.6</td>
<td id="A1.T4.3.24.24.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">77.4</td>
<td id="A1.T4.3.24.24.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">35.2</td>
<td id="A1.T4.3.24.24.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">68.7</td>
<td id="A1.T4.3.24.24.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.0</td>
</tr>
<tr id="A1.T4.3.25.25" class="ltx_tr">
<td id="A1.T4.3.25.25.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">Llama-2-70b-chat-hf</td>
<td id="A1.T4.3.25.25.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td id="A1.T4.3.25.25.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">80.2</td>
<td id="A1.T4.3.25.25.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">53.4</td>
<td id="A1.T4.3.25.25.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">94.4</td>
<td id="A1.T4.3.25.25.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">91.6</td>
<td id="A1.T4.3.25.25.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">80.1</td>
<td id="A1.T4.3.25.25.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">21.8</td>
<td id="A1.T4.3.25.25.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">73.6</td>
<td id="A1.T4.3.25.25.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">30.4</td>
<td id="A1.T4.3.25.25.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">54.6</td>
<td id="A1.T4.3.25.25.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">64.5</td>
</tr>
<tr id="A1.T4.3.26.26" class="ltx_tr">
<td id="A1.T4.3.26.26.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">youri-7b-instruction-gptq</td>
<td id="A1.T4.3.26.26.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.26.26.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">88.1</td>
<td id="A1.T4.3.26.26.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">62.0</td>
<td id="A1.T4.3.26.26.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.5</td>
<td id="A1.T4.3.26.26.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">90.6</td>
<td id="A1.T4.3.26.26.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">74.4</td>
<td id="A1.T4.3.26.26.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">15.3</td>
<td id="A1.T4.3.26.26.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.2</td>
<td id="A1.T4.3.26.26.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">15.2</td>
<td id="A1.T4.3.26.26.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">53.3</td>
<td id="A1.T4.3.26.26.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">63.4</td>
</tr>
<tr id="A1.T4.3.27.27" class="ltx_tr">
<td id="A1.T4.3.27.27.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-base-gamma-7b</td>
<td id="A1.T4.3.27.27.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.27.27.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.5</td>
<td id="A1.T4.3.27.27.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">37.6</td>
<td id="A1.T4.3.27.27.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">79.2</td>
<td id="A1.T4.3.27.27.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">90.6</td>
<td id="A1.T4.3.27.27.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.5</td>
<td id="A1.T4.3.27.27.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">22.9</td>
<td id="A1.T4.3.27.27.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">82.9</td>
<td id="A1.T4.3.27.27.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">20.8</td>
<td id="A1.T4.3.27.27.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">55.6</td>
<td id="A1.T4.3.27.27.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">63.2</td>
</tr>
<tr id="A1.T4.3.28.28" class="ltx_tr">
<td id="A1.T4.3.28.28.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-13b-instruct-hf</td>
<td id="A1.T4.3.28.28.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td id="A1.T4.3.28.28.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.0</td>
<td id="A1.T4.3.28.28.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">43.1</td>
<td id="A1.T4.3.28.28.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">74.1</td>
<td id="A1.T4.3.28.28.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">92.8</td>
<td id="A1.T4.3.28.28.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">92.5</td>
<td id="A1.T4.3.28.28.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">20.6</td>
<td id="A1.T4.3.28.28.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70.4</td>
<td id="A1.T4.3.28.28.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">24.0</td>
<td id="A1.T4.3.28.28.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">61.9</td>
<td id="A1.T4.3.28.28.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">63.2</td>
</tr>
<tr id="A1.T4.3.29.29" class="ltx_tr">
<td id="A1.T4.3.29.29.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-instruct-gamma-7b</td>
<td id="A1.T4.3.29.29.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.29.29.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">91.4</td>
<td id="A1.T4.3.29.29.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">40.7</td>
<td id="A1.T4.3.29.29.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">72.9</td>
<td id="A1.T4.3.29.29.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.9</td>
<td id="A1.T4.3.29.29.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">88.2</td>
<td id="A1.T4.3.29.29.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">22.8</td>
<td id="A1.T4.3.29.29.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">82.2</td>
<td id="A1.T4.3.29.29.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">17.2</td>
<td id="A1.T4.3.29.29.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">56.4</td>
<td id="A1.T4.3.29.29.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">62.4</td>
</tr>
<tr id="A1.T4.3.30.30" class="ltx_tr">
<td id="A1.T4.3.30.30.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-13b-hf</td>
<td id="A1.T4.3.30.30.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td id="A1.T4.3.30.30.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">86.0</td>
<td id="A1.T4.3.30.30.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">44.8</td>
<td id="A1.T4.3.30.30.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">74.5</td>
<td id="A1.T4.3.30.30.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">92.2</td>
<td id="A1.T4.3.30.30.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">92.2</td>
<td id="A1.T4.3.30.30.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">21.6</td>
<td id="A1.T4.3.30.30.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">71.4</td>
<td id="A1.T4.3.30.30.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">19.2</td>
<td id="A1.T4.3.30.30.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">59.5</td>
<td id="A1.T4.3.30.30.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">62.4</td>
</tr>
<tr id="A1.T4.3.31.31" class="ltx_tr">
<td id="A1.T4.3.31.31.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-14b-gguf</td>
<td id="A1.T4.3.31.31.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">14B</td>
<td id="A1.T4.3.31.31.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.0</td>
<td id="A1.T4.3.31.31.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">41.1</td>
<td id="A1.T4.3.31.31.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td id="A1.T4.3.31.31.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.0</td>
<td id="A1.T4.3.31.31.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">88.3</td>
<td id="A1.T4.3.31.31.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">22.2</td>
<td id="A1.T4.3.31.31.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">80.5</td>
<td id="A1.T4.3.31.31.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">32.4</td>
<td id="A1.T4.3.31.31.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">60.2</td>
<td id="A1.T4.3.31.31.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">62.3</td>
</tr>
<tr id="A1.T4.3.32.32" class="ltx_tr">
<td id="A1.T4.3.32.32.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-MS-7b-v0.1</td>
<td id="A1.T4.3.32.32.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.32.32.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">88.3</td>
<td id="A1.T4.3.32.32.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">35.8</td>
<td id="A1.T4.3.32.32.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">83.1</td>
<td id="A1.T4.3.32.32.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">90.3</td>
<td id="A1.T4.3.32.32.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.4</td>
<td id="A1.T4.3.32.32.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">20.7</td>
<td id="A1.T4.3.32.32.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">74.6</td>
<td id="A1.T4.3.32.32.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">22.4</td>
<td id="A1.T4.3.32.32.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">55.5</td>
<td id="A1.T4.3.32.32.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">62.2</td>
</tr>
<tr id="A1.T4.3.33.33" class="ltx_tr">
<td id="A1.T4.3.33.33.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-7b-instruct-hf</td>
<td id="A1.T4.3.33.33.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.33.33.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">86.8</td>
<td id="A1.T4.3.33.33.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">36.3</td>
<td id="A1.T4.3.33.33.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">94.2</td>
<td id="A1.T4.3.33.33.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">90.0</td>
<td id="A1.T4.3.33.33.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.4</td>
<td id="A1.T4.3.33.33.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">17.4</td>
<td id="A1.T4.3.33.33.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">76.8</td>
<td id="A1.T4.3.33.33.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">10.4</td>
<td id="A1.T4.3.33.33.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td id="A1.T4.3.33.33.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">61.2</td>
</tr>
<tr id="A1.T4.3.34.34" class="ltx_tr">
<td id="A1.T4.3.34.34.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0</td>
<td id="A1.T4.3.34.34.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td id="A1.T4.3.34.34.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">83.2</td>
<td id="A1.T4.3.34.34.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">74.5</td>
<td id="A1.T4.3.34.34.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">74.9</td>
<td id="A1.T4.3.34.34.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">94.0</td>
<td id="A1.T4.3.34.34.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">85.1</td>
<td id="A1.T4.3.34.34.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">9.6</td>
<td id="A1.T4.3.34.34.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">71.3</td>
<td id="A1.T4.3.34.34.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">3.2</td>
<td id="A1.T4.3.34.34.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.4</td>
<td id="A1.T4.3.34.34.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">60.7</td>
</tr>
<tr id="A1.T4.3.35.35" class="ltx_tr">
<td id="A1.T4.3.35.35.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-7b-hf</td>
<td id="A1.T4.3.35.35.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.35.35.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">80.2</td>
<td id="A1.T4.3.35.35.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">37.9</td>
<td id="A1.T4.3.35.35.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">93.1</td>
<td id="A1.T4.3.35.35.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.2</td>
<td id="A1.T4.3.35.35.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">90.1</td>
<td id="A1.T4.3.35.35.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">18.3</td>
<td id="A1.T4.3.35.35.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">76.6</td>
<td id="A1.T4.3.35.35.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">10.4</td>
<td id="A1.T4.3.35.35.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td id="A1.T4.3.35.35.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">60.7</td>
</tr>
<tr id="A1.T4.3.36.36" class="ltx_tr">
<td id="A1.T4.3.36.36.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-7b</td>
<td id="A1.T4.3.36.36.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.36.36.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">82.9</td>
<td id="A1.T4.3.36.36.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">38.6</td>
<td id="A1.T4.3.36.36.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">67.0</td>
<td id="A1.T4.3.36.36.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.8</td>
<td id="A1.T4.3.36.36.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">82.5</td>
<td id="A1.T4.3.36.36.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">16.9</td>
<td id="A1.T4.3.36.36.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">74.5</td>
<td id="A1.T4.3.36.36.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">16.0</td>
<td id="A1.T4.3.36.36.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">60.0</td>
<td id="A1.T4.3.36.36.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">58.7</td>
</tr>
<tr id="A1.T4.3.37.37" class="ltx_tr">
<td id="A1.T4.3.37.37.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-instruct-beta-7b</td>
<td id="A1.T4.3.37.37.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.37.37.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">81.9</td>
<td id="A1.T4.3.37.37.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">39.9</td>
<td id="A1.T4.3.37.37.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">88.3</td>
<td id="A1.T4.3.37.37.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">84.1</td>
<td id="A1.T4.3.37.37.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.2</td>
<td id="A1.T4.3.37.37.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">20.8</td>
<td id="A1.T4.3.37.37.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">75.7</td>
<td id="A1.T4.3.37.37.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">4.8</td>
<td id="A1.T4.3.37.37.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">51.7</td>
<td id="A1.T4.3.37.37.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">58.4</td>
</tr>
<tr id="A1.T4.3.38.38" class="ltx_tr">
<td id="A1.T4.3.38.38.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-base-beta-7b</td>
<td id="A1.T4.3.38.38.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.38.38.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">76.8</td>
<td id="A1.T4.3.38.38.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">38.0</td>
<td id="A1.T4.3.38.38.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">86.0</td>
<td id="A1.T4.3.38.38.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">87.1</td>
<td id="A1.T4.3.38.38.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">79.5</td>
<td id="A1.T4.3.38.38.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">21.9</td>
<td id="A1.T4.3.38.38.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">76.6</td>
<td id="A1.T4.3.38.38.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7.6</td>
<td id="A1.T4.3.38.38.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">49.2</td>
<td id="A1.T4.3.38.38.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">58.1</td>
</tr>
<tr id="A1.T4.3.39.39" class="ltx_tr">
<td id="A1.T4.3.39.39.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">Qwen-7B</td>
<td id="A1.T4.3.39.39.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.39.39.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">76.0</td>
<td id="A1.T4.3.39.39.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">46.9</td>
<td id="A1.T4.3.39.39.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">83.3</td>
<td id="A1.T4.3.39.39.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.7</td>
<td id="A1.T4.3.39.39.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">69.2</td>
<td id="A1.T4.3.39.39.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">13.8</td>
<td id="A1.T4.3.39.39.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">60.6</td>
<td id="A1.T4.3.39.39.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">22.0</td>
<td id="A1.T4.3.39.39.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">57.3</td>
<td id="A1.T4.3.39.39.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">57.6</td>
</tr>
<tr id="A1.T4.3.40.40" class="ltx_tr">
<td id="A1.T4.3.40.40.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">youri-7b-gptq</td>
<td id="A1.T4.3.40.40.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.40.40.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.9</td>
<td id="A1.T4.3.40.40.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">40.5</td>
<td id="A1.T4.3.40.40.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.2</td>
<td id="A1.T4.3.40.40.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">85.7</td>
<td id="A1.T4.3.40.40.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.1</td>
<td id="A1.T4.3.40.40.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">16.3</td>
<td id="A1.T4.3.40.40.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.3</td>
<td id="A1.T4.3.40.40.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">4.8</td>
<td id="A1.T4.3.40.40.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">54.0</td>
<td id="A1.T4.3.40.40.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">57.2</td>
</tr>
<tr id="A1.T4.3.41.41" class="ltx_tr">
<td id="A1.T4.3.41.41.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">youri-7b</td>
<td id="A1.T4.3.41.41.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.41.41.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">82.8</td>
<td id="A1.T4.3.41.41.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">35.9</td>
<td id="A1.T4.3.41.41.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">90.1</td>
<td id="A1.T4.3.41.41.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">57.2</td>
<td id="A1.T4.3.41.41.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">82.5</td>
<td id="A1.T4.3.41.41.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">20.5</td>
<td id="A1.T4.3.41.41.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.0</td>
<td id="A1.T4.3.41.41.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">6.8</td>
<td id="A1.T4.3.41.41.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">58.5</td>
<td id="A1.T4.3.41.41.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">56.9</td>
</tr>
<tr id="A1.T4.3.42.42" class="ltx_tr">
<td id="A1.T4.3.42.42.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">ELYZA-japanese-Llama-2-7b-instruct</td>
<td id="A1.T4.3.42.42.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.42.42.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">79.2</td>
<td id="A1.T4.3.42.42.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">38.8</td>
<td id="A1.T4.3.42.42.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">89.9</td>
<td id="A1.T4.3.42.42.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">83.2</td>
<td id="A1.T4.3.42.42.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">68.7</td>
<td id="A1.T4.3.42.42.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">16.8</td>
<td id="A1.T4.3.42.42.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">71.1</td>
<td id="A1.T4.3.42.42.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">11.2</td>
<td id="A1.T4.3.42.42.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.5</td>
<td id="A1.T4.3.42.42.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">56.6</td>
</tr>
<tr id="A1.T4.3.43.43" class="ltx_tr">
<td id="A1.T4.3.43.43.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">weblab-10b-instruction-sft</td>
<td id="A1.T4.3.43.43.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">10B</td>
<td id="A1.T4.3.43.43.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">63.6</td>
<td id="A1.T4.3.43.43.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">42.7</td>
<td id="A1.T4.3.43.43.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">86.4</td>
<td id="A1.T4.3.43.43.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">87.8</td>
<td id="A1.T4.3.43.43.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">73.9</td>
<td id="A1.T4.3.43.43.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">23.1</td>
<td id="A1.T4.3.43.43.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">72.4</td>
<td id="A1.T4.3.43.43.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">2.8</td>
<td id="A1.T4.3.43.43.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.5</td>
<td id="A1.T4.3.43.43.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">55.9</td>
</tr>
<tr id="A1.T4.3.44.44" class="ltx_tr">
<td id="A1.T4.3.44.44.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">Mistral-7B-v0.1</td>
<td id="A1.T4.3.44.44.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.44.44.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">74.0</td>
<td id="A1.T4.3.44.44.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">44.2</td>
<td id="A1.T4.3.44.44.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">63.3</td>
<td id="A1.T4.3.44.44.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">85.7</td>
<td id="A1.T4.3.44.44.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">69.8</td>
<td id="A1.T4.3.44.44.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">22.8</td>
<td id="A1.T4.3.44.44.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">69.9</td>
<td id="A1.T4.3.44.44.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">20.4</td>
<td id="A1.T4.3.44.44.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">51.1</td>
<td id="A1.T4.3.44.44.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">55.7</td>
</tr>
<tr id="A1.T4.3.45.45" class="ltx_tr">
<td id="A1.T4.3.45.45.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">ELYZA-japanese-Llama-2-7b</td>
<td id="A1.T4.3.45.45.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.45.45.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">75.2</td>
<td id="A1.T4.3.45.45.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">36.1</td>
<td id="A1.T4.3.45.45.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">87.3</td>
<td id="A1.T4.3.45.45.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">86.4</td>
<td id="A1.T4.3.45.45.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">68.0</td>
<td id="A1.T4.3.45.45.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">16.3</td>
<td id="A1.T4.3.45.45.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">72.0</td>
<td id="A1.T4.3.45.45.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">5.2</td>
<td id="A1.T4.3.45.45.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">53.1</td>
<td id="A1.T4.3.45.45.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">55.5</td>
</tr>
<tr id="A1.T4.3.46.46" class="ltx_tr">
<td id="A1.T4.3.46.46.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-7b-gguf</td>
<td id="A1.T4.3.46.46.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.46.46.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">82.3</td>
<td id="A1.T4.3.46.46.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">33.7</td>
<td id="A1.T4.3.46.46.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td id="A1.T4.3.46.46.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">86.8</td>
<td id="A1.T4.3.46.46.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">74.9</td>
<td id="A1.T4.3.46.46.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">19.9</td>
<td id="A1.T4.3.46.46.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.3</td>
<td id="A1.T4.3.46.46.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">13.6</td>
<td id="A1.T4.3.46.46.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">55.8</td>
<td id="A1.T4.3.46.46.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">55.0</td>
</tr>
<tr id="A1.T4.3.47.47" class="ltx_tr">
<td id="A1.T4.3.47.47.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-instruct-ja_vocab-beta-7b</td>
<td id="A1.T4.3.47.47.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.47.47.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">79.9</td>
<td id="A1.T4.3.47.47.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">39.2</td>
<td id="A1.T4.3.47.47.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">79.5</td>
<td id="A1.T4.3.47.47.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">82.0</td>
<td id="A1.T4.3.47.47.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.9</td>
<td id="A1.T4.3.47.47.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">9.9</td>
<td id="A1.T4.3.47.47.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">68.9</td>
<td id="A1.T4.3.47.47.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">6.0</td>
<td id="A1.T4.3.47.47.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">49.2</td>
<td id="A1.T4.3.47.47.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">54.8</td>
</tr>
<tr id="A1.T4.3.48.48" class="ltx_tr">
<td id="A1.T4.3.48.48.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-base-ja_vocab-beta-7b</td>
<td id="A1.T4.3.48.48.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.48.48.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">69.9</td>
<td id="A1.T4.3.48.48.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">38.8</td>
<td id="A1.T4.3.48.48.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">80.0</td>
<td id="A1.T4.3.48.48.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">83.8</td>
<td id="A1.T4.3.48.48.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">80.1</td>
<td id="A1.T4.3.48.48.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7.5</td>
<td id="A1.T4.3.48.48.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">72.5</td>
<td id="A1.T4.3.48.48.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">3.6</td>
<td id="A1.T4.3.48.48.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td id="A1.T4.3.48.48.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">54.0</td>
</tr>
<tr id="A1.T4.3.49.49" class="ltx_tr">
<td id="A1.T4.3.49.49.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">calm2-7b-chat</td>
<td id="A1.T4.3.49.49.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.49.49.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70.3</td>
<td id="A1.T4.3.49.49.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">33.7</td>
<td id="A1.T4.3.49.49.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">87.7</td>
<td id="A1.T4.3.49.49.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">82.6</td>
<td id="A1.T4.3.49.49.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">77.8</td>
<td id="A1.T4.3.49.49.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">5.4</td>
<td id="A1.T4.3.49.49.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70.9</td>
<td id="A1.T4.3.49.49.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">5.6</td>
<td id="A1.T4.3.49.49.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">51.9</td>
<td id="A1.T4.3.49.49.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">54.0</td>
</tr>
<tr id="A1.T4.3.50.50" class="ltx_tr">
<td id="A1.T4.3.50.50.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">stockmark-13b</td>
<td id="A1.T4.3.50.50.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td id="A1.T4.3.50.50.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70.7</td>
<td id="A1.T4.3.50.50.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">36.2</td>
<td id="A1.T4.3.50.50.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">56.5</td>
<td id="A1.T4.3.50.50.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">87.2</td>
<td id="A1.T4.3.50.50.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">87.3</td>
<td id="A1.T4.3.50.50.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7.7</td>
<td id="A1.T4.3.50.50.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">73.4</td>
<td id="A1.T4.3.50.50.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">9.6</td>
<td id="A1.T4.3.50.50.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td id="A1.T4.3.50.50.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">53.2</td>
</tr>
<tr id="A1.T4.3.51.51" class="ltx_tr">
<td id="A1.T4.3.51.51.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">Llama-2-7b-hf</td>
<td id="A1.T4.3.51.51.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.51.51.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.9</td>
<td id="A1.T4.3.51.51.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">35.1</td>
<td id="A1.T4.3.51.51.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">83.2</td>
<td id="A1.T4.3.51.51.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">82.7</td>
<td id="A1.T4.3.51.51.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70.6</td>
<td id="A1.T4.3.51.51.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">19.0</td>
<td id="A1.T4.3.51.51.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.2</td>
<td id="A1.T4.3.51.51.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">6.8</td>
<td id="A1.T4.3.51.51.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">47.1</td>
<td id="A1.T4.3.51.51.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">52.9</td>
</tr>
<tr id="A1.T4.3.52.52" class="ltx_tr">
<td id="A1.T4.3.52.52.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">calm2-7b</td>
<td id="A1.T4.3.52.52.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td id="A1.T4.3.52.52.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">58.2</td>
<td id="A1.T4.3.52.52.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">33.3</td>
<td id="A1.T4.3.52.52.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">81.2</td>
<td id="A1.T4.3.52.52.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">81.8</td>
<td id="A1.T4.3.52.52.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">81.9</td>
<td id="A1.T4.3.52.52.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">2.4</td>
<td id="A1.T4.3.52.52.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">73.0</td>
<td id="A1.T4.3.52.52.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">5.6</td>
<td id="A1.T4.3.52.52.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">53.3</td>
<td id="A1.T4.3.52.52.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">52.3</td>
</tr>
<tr id="A1.T4.3.53.53" class="ltx_tr">
<td id="A1.T4.3.53.53.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">plamo-13b</td>
<td id="A1.T4.3.53.53.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td id="A1.T4.3.53.53.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">54.5</td>
<td id="A1.T4.3.53.53.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">33.8</td>
<td id="A1.T4.3.53.53.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">85.0</td>
<td id="A1.T4.3.53.53.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.6</td>
<td id="A1.T4.3.53.53.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">74.5</td>
<td id="A1.T4.3.53.53.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">12.9</td>
<td id="A1.T4.3.53.53.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">70.5</td>
<td id="A1.T4.3.53.53.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">2.4</td>
<td id="A1.T4.3.53.53.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">54.5</td>
<td id="A1.T4.3.53.53.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">51.9</td>
</tr>
<tr id="A1.T4.3.54.54" class="ltx_tr">
<td id="A1.T4.3.54.54.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">weblab-10b</td>
<td id="A1.T4.3.54.54.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">10B</td>
<td id="A1.T4.3.54.54.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">44.0</td>
<td id="A1.T4.3.54.54.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">30.7</td>
<td id="A1.T4.3.54.54.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">64.0</td>
<td id="A1.T4.3.54.54.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">83.3</td>
<td id="A1.T4.3.54.54.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">74.6</td>
<td id="A1.T4.3.54.54.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">20.3</td>
<td id="A1.T4.3.54.54.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">71.4</td>
<td id="A1.T4.3.54.54.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">2.0</td>
<td id="A1.T4.3.54.54.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.8</td>
<td id="A1.T4.3.54.54.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">49.0</td>
</tr>
<tr id="A1.T4.3.55.55" class="ltx_tr">
<td id="A1.T4.3.55.55.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">llm-jp-13b-v1.0</td>
<td id="A1.T4.3.55.55.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td id="A1.T4.3.55.55.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">39.6</td>
<td id="A1.T4.3.55.55.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">35.0</td>
<td id="A1.T4.3.55.55.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">67.4</td>
<td id="A1.T4.3.55.55.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">79.3</td>
<td id="A1.T4.3.55.55.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">78.0</td>
<td id="A1.T4.3.55.55.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">10.9</td>
<td id="A1.T4.3.55.55.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">69.5</td>
<td id="A1.T4.3.55.55.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">2.0</td>
<td id="A1.T4.3.55.55.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">54.4</td>
<td id="A1.T4.3.55.55.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">48.5</td>
</tr>
<tr id="A1.T4.3.56.56" class="ltx_tr">
<td id="A1.T4.3.56.56.1" class="ltx_td ltx_align_left" style="padding-left:2.5pt;padding-right:2.5pt;">plamo-13b-instruct-nc</td>
<td id="A1.T4.3.56.56.2" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td id="A1.T4.3.56.56.3" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">45.8</td>
<td id="A1.T4.3.56.56.4" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">35.3</td>
<td id="A1.T4.3.56.56.5" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">91.6</td>
<td id="A1.T4.3.56.56.6" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">75.2</td>
<td id="A1.T4.3.56.56.7" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">63.5</td>
<td id="A1.T4.3.56.56.8" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">5.8</td>
<td id="A1.T4.3.56.56.9" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">65.2</td>
<td id="A1.T4.3.56.56.10" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">1.2</td>
<td id="A1.T4.3.56.56.11" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">50.6</td>
<td id="A1.T4.3.56.56.12" class="ltx_td ltx_align_right" style="padding-left:2.5pt;padding-right:2.5pt;">48.3</td>
</tr>
<tr id="A1.T4.3.57.57" class="ltx_tr">
<td id="A1.T4.3.57.57.1" class="ltx_td ltx_align_left ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">plamo-13b-instruct</td>
<td id="A1.T4.3.57.57.2" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td id="A1.T4.3.57.57.3" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">42.5</td>
<td id="A1.T4.3.57.57.4" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">34.9</td>
<td id="A1.T4.3.57.57.5" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">90.0</td>
<td id="A1.T4.3.57.57.6" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">77.3</td>
<td id="A1.T4.3.57.57.7" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">67.0</td>
<td id="A1.T4.3.57.57.8" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">5.4</td>
<td id="A1.T4.3.57.57.9" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">62.9</td>
<td id="A1.T4.3.57.57.10" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">2.0</td>
<td id="A1.T4.3.57.57.11" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td id="A1.T4.3.57.57.12" class="ltx_td ltx_align_right ltx_border_bb" style="padding-left:2.5pt;padding-right:2.5pt;">48.0</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Evolving for License Specific Open-Source Models</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">In the main section, our <span id="A2.p1.1.1" class="ltx_text ltx_font_typewriter">EvoLLM-JP</span> results were evolved using models found on HuggingFace. However, some of the models uses, in particular, <span id="A2.p1.1.2" class="ltx_text ltx_font_typewriter">WizardMath-7B-V1.1</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">34</span></a>]</cite> has been released under a Non-Commercial, Research-only, Microsoft License, which is not <span id="A2.p1.1.3" class="ltx_text ltx_font_italic">truly</span> open-source. Therefore, our release of <span id="A2.p1.1.4" class="ltx_text ltx_font_typewriter">EvoLLM-JP</span> is also released under a Non-Commercial, Research-only License to be consistent with the <span id="A2.p1.1.5" class="ltx_text ltx_font_typewriter">WizardMath-7B-V1.1</span> model.</p>
</div>
<div id="A2.p2" class="ltx_para">
<p id="A2.p2.1" class="ltx_p">As researchers who benefited from the open-source community, we would like for models that we release to also be under an open-source license. In the spirit of open-source, and to showcase the applicability of our method to tackle even challenging issues like model licenses. We have ran a similar experiment where we incorporated <span id="A2.p2.1.1" class="ltx_text ltx_font_italic">only</span> models that have been released under a true open-source license, such as MIT or Apache 2.0, and have produced a similar performing model called <span id="A2.p2.1.2" class="ltx_text ltx_font_typewriter">EvoLLM-JP-A</span>, which we will release under Apache 2.0.<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>This model will also be released on our GitHub: <a target="_blank" href="https://github.com/SakanaAI/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/SakanaAI/</a></span></span></span></p>
</div>
<div id="A2.p3" class="ltx_para">
<p id="A2.p3.1" class="ltx_p">Specifically, our <span id="A2.p3.1.1" class="ltx_text ltx_font_typewriter">EvoLLM-JP-A</span> is a merge of shisa-gamma-7b-v1, Arithmo2-Mistral-7B, and Abel-7B-002, all of which are under MIT or Apache 2.0 License.
The MGSM-JA score measured using the protocol described in Section&nbsp;<a href="#S4.SS1" title="4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a> is 52.4, and the Japanese Language Model Evaluation Harness score is 69.0.
We have included results of this Apache 2.0-licensed model for comparison in Table&nbsp;<a href="#A1.T4" title="Table 4 ‣ Appendix A Evaluation Details ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, which provides a more comprehensive comparison than Table&nbsp;<a href="#S4.T2" title="Table 2 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> in the main text.</p>
</div>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Case Study</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">Table&nbsp;<a href="#A3.T5" title="Table 5 ‣ Appendix C Case Study ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> provides an example of responses to a mathematical question by existing models and our model. By merging a Japanese language model, we not only improve our capability to understand and use Japanese in reading and writing but also expand our knowledge about Japan. This example requires both mathematical reasoning and Japanese-specific knowledge, specifically that Setsubun is the day before the beginning of spring (Risshun). Notably, only our merged model provides the correct answer. Even when the question is translated into English, the English math model <span id="A3.p1.1.1" class="ltx_text ltx_font_typewriter">WizardMath-7B-V1.1</span> fails to answer correctly, demonstrating that our merged model is superior to a combination of machine translation and an English math model.</p>
</div>
<div id="A3.p2" class="ltx_para">
<p id="A3.p2.1" class="ltx_p">It is worth noting that in Table&nbsp;<a href="#A3.T5" title="Table 5 ‣ Appendix C Case Study ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we also provide the answer from the general-purpose math model <span id="A3.p2.1.1" class="ltx_text ltx_font_typewriter">WizardMath-7B-V1.1</span> with the question translated into English. However, even with the translated question, <span id="A3.p2.1.2" class="ltx_text ltx_font_typewriter">WizardMath-7B-V1.1</span> fails to provide the correct answer. This highlights the fact that simply translating the question is not sufficient to solve the problem, as it also requires an understanding of the Japanese cultural context. Even if one were to consider a combination of machine translation and an English math model as an alternative approach, it would still fall short in capturing the nuances and context-specific knowledge required to answer the question correctly. This demonstrates the unique value of our merged model, which effectively combines mathematical reasoning capabilities with Japanese language understanding and cultural knowledge.</p>
</div>
<figure id="A3.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 5: </span><span id="A3.T5.4.1" class="ltx_text ltx_font_bold">Case Study of EvoLLM-JP-v1-7B</span>. This study presents the responses of the LLMs to a problem that demands both Japanese-specific knowledge and mathematical reasoning.</figcaption>
<table id="A3.T5.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A3.T5.5.1.1" class="ltx_tr">
<td id="A3.T5.5.1.1.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="2"><span id="A3.T5.5.1.1.1.1" class="ltx_text ltx_font_bold ltx_font_italic" style="font-size:70%;">Problem</span></td>
</tr>
<tr id="A3.T5.5.2.2" class="ltx_tr">
<td id="A3.T5.5.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T5.5.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.2.2.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T5.5.2.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">JA Instruction</span></span>
</span>
</td>
<td id="A3.T5.5.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T5.5.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.2.2.2.1.1" class="ltx_p" style="width:284.5pt;"><span id="A3.T5.5.2.2.2.1.1.1" class="ltx_text" style="font-size:70%;">去年の立春は2月3日でした。今年の立春は2月4日です。去年の節分の月、去年の節分の日、今年の節分の月、今年の節分の日を足し合わせると、いくつになりますか？</span></span>
</span>
</td>
</tr>
<tr id="A3.T5.5.3.3" class="ltx_tr">
<td id="A3.T5.5.3.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T5.5.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.3.3.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T5.5.3.3.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">EN Instruction</span></span>
</span>
</td>
<td id="A3.T5.5.3.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T5.5.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.3.3.2.1.1" class="ltx_p" style="width:284.5pt;"><span id="A3.T5.5.3.3.2.1.1.1" class="ltx_text" style="font-size:70%;">Last year, Risshun was on February 3rd. This year, it is on February 4th. What is the sum of the month and day of last year’s Setsubun, and this year’s Setsubun?</span></span>
</span>
</td>
</tr>
<tr id="A3.T5.5.4.4" class="ltx_tr">
<td id="A3.T5.5.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T5.5.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.4.4.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T5.5.4.4.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Ground Truth Answer</span></span>
</span>
</td>
<td id="A3.T5.5.4.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T5.5.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.4.4.2.1.1" class="ltx_p" style="width:284.5pt;"><span id="A3.T5.5.4.4.2.1.1.1" class="ltx_text" style="font-size:70%;">9</span></span>
</span>
</td>
</tr>
<tr id="A3.T5.5.5.5" class="ltx_tr">
<td id="A3.T5.5.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T5.5.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.5.5.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T5.5.5.5.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Note</span></span>
</span>
</td>
<td id="A3.T5.5.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T5.5.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.5.5.2.1.1" class="ltx_p" style="width:284.5pt;"><span id="A3.T5.5.5.5.2.1.1.1" class="ltx_text" style="font-size:70%;">Setsubun, the eve of the first day of spring, always falls on the day before Risshun, which marks the start of spring according to the lunar calendar. The date of Risshun can vary annually.</span></span>
</span>
</td>
</tr>
<tr id="A3.T5.5.6.6" class="ltx_tr">
<td id="A3.T5.5.6.6.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="2"><span id="A3.T5.5.6.6.1.1" class="ltx_text ltx_font_bold ltx_font_italic" style="font-size:70%;">Answers</span></td>
</tr>
<tr id="A3.T5.5.7.7" class="ltx_tr">
<td id="A3.T5.5.7.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T5.5.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.7.7.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T5.5.7.7.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">EvoLLM-JP-v1-7B</span><span id="A3.T5.5.7.7.1.1.1.2" class="ltx_text" style="font-size:70%;"></span></span>
<span id="A3.T5.5.7.7.1.1.2" class="ltx_p"><span id="A3.T5.5.7.7.1.1.2.1" class="ltx_text" style="font-size:70%;">JA Instruction</span></span>
</span>
</td>
<td id="A3.T5.5.7.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T5.5.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.7.7.2.1.1" class="ltx_p" style="width:284.5pt;"><span id="A3.T5.5.7.7.2.1.1.1" class="ltx_text" style="font-size:70%;">去年の立春は2月3日で、今年の立春は2月4日です。
去年の節分は立春の前日、つまり2月2日でした。
今年の節分は立春の前日、つまり2月3日です。
去年の節分の月は2月、去年の節分の日は2日で、合計は2 + 2 = 4です。
今年の節分の月は2月、今年の節分の日は3日で、合計は2 + 3 = 5です。
足し合わせると、4 + 5 = 9になります。</span></span>
<span id="A3.T5.5.7.7.2.1.2" class="ltx_p"><span id="A3.T5.5.7.7.2.1.2.1" class="ltx_text" style="font-size:70%;">#### 9</span></span>
<span id="A3.T5.5.7.7.2.1.3" class="ltx_p"><span id="A3.T5.5.7.7.2.1.3.1" class="ltx_text" style="font-size:70%;">The answer is: 9.</span></span>
</span>
</td>
</tr>
<tr id="A3.T5.5.8.8" class="ltx_tr">
<td id="A3.T5.5.8.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T5.5.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.8.8.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T5.5.8.8.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">shisa-gamma-7b</span><span id="A3.T5.5.8.8.1.1.1.2" class="ltx_text" style="font-size:70%;"></span></span>
<span id="A3.T5.5.8.8.1.1.2" class="ltx_p"><span id="A3.T5.5.8.8.1.1.2.1" class="ltx_text" style="font-size:70%;">JA Instruction</span></span>
</span>
</td>
<td id="A3.T5.5.8.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T5.5.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.8.8.2.1.1" class="ltx_p" style="width:284.5pt;"><span id="A3.T5.5.8.8.2.1.1.1" class="ltx_text" style="font-size:70%;">まず、去年の立春の日付を計算してみましょう。</span></span>
<span id="A3.T5.5.8.8.2.1.2" class="ltx_p"><span id="A3.T5.5.8.8.2.1.2.1" class="ltx_text" style="font-size:70%;">去年の立春の日付 = 2021年の2月3日</span></span>
<span id="A3.T5.5.8.8.2.1.3" class="ltx_p"><span id="A3.T5.5.8.8.2.1.3.1" class="ltx_text" style="font-size:70%;">次に、去年の節分の日付を計算してみましょう。</span></span>
<span id="A3.T5.5.8.8.2.1.4" class="ltx_p"><span id="A3.T5.5.8.8.2.1.4.1" class="ltx_text" style="font-size:70%;">去年の節分の日付 = 2021年の2月2日</span></span>
<span id="A3.T5.5.8.8.2.1.5" class="ltx_p"><span id="A3.T5.5.8.8.2.1.5.1" class="ltx_text" style="font-size:70%;">次に、今年の立春の日付を計算してみましょう。</span></span>
<span id="A3.T5.5.8.8.2.1.6" class="ltx_p"><span id="A3.T5.5.8.8.2.1.6.1" class="ltx_text" style="font-size:70%;">今年の立春の日付 = 2022年の2月4日</span></span>
<span id="A3.T5.5.8.8.2.1.7" class="ltx_p"><span id="A3.T5.5.8.8.2.1.7.1" class="ltx_text" style="font-size:70%;">次に、今年の節分の日付を計算してみましょう。</span></span>
<span id="A3.T5.5.8.8.2.1.8" class="ltx_p"><span id="A3.T5.5.8.8.2.1.8.1" class="ltx_text" style="font-size:70%;">今年の節分の日付 = 2022年の2月1日</span></span>
<span id="A3.T5.5.8.8.2.1.9" class="ltx_p"><span id="A3.T5.5.8.8.2.1.9.1" class="ltx_text" style="font-size:70%;">最後に、去年の節分の月と日、今年の節分の月と日を足し合わせてみましょう。</span></span>
<span id="A3.T5.5.8.8.2.1.10" class="ltx_p"><span id="A3.T5.5.8.8.2.1.10.1" class="ltx_text" style="font-size:70%;">去年の節分の月と日 = 2021年の2月2日
今年の節分の月と日 = 2022年の2月1日</span></span>
<span id="A3.T5.5.8.8.2.1.11" class="ltx_p"><span id="A3.T5.5.8.8.2.1.11.1" class="ltx_text" style="font-size:70%;">これで、足し合わせることができます。</span></span>
<span id="A3.T5.5.8.8.2.1.12" class="ltx_p"><span id="A3.T5.5.8.8.2.1.12.1" class="ltx_text" style="font-size:70%;">足し合わせた月と日 = 2021年の2月2日 + 2022年の2月1日 = 2023年の2月3日</span></span>
<span id="A3.T5.5.8.8.2.1.13" class="ltx_p"><span id="A3.T5.5.8.8.2.1.13.1" class="ltx_text" style="font-size:70%;">つまり、去年の節分の月と日、今年の節分の月と日を足し合わせると、2023年の2月3日になります。</span></span>
</span>
</td>
</tr>
<tr id="A3.T5.5.9.9" class="ltx_tr">
<td id="A3.T5.5.9.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T5.5.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.9.9.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T5.5.9.9.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">WizardMath-7B-V1.1</span><span id="A3.T5.5.9.9.1.1.1.2" class="ltx_text" style="font-size:70%;"></span></span>
<span id="A3.T5.5.9.9.1.1.2" class="ltx_p"><span id="A3.T5.5.9.9.1.1.2.1" class="ltx_text" style="font-size:70%;">JA Instruction</span></span>
</span>
</td>
<td id="A3.T5.5.9.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T5.5.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.9.9.2.1.1" class="ltx_p" style="width:284.5pt;"><span id="A3.T5.5.9.9.2.1.1.1" class="ltx_text" style="font-size:70%;">Step 1: Identify the dates for the given events.</span></span>
<span id="A3.T5.5.9.9.2.1.2" class="ltx_p"><span id="A3.T5.5.9.9.2.1.2.1" class="ltx_text" style="font-size:70%;">- Last year’s Setsubun (February 3)</span></span>
<span id="A3.T5.5.9.9.2.1.3" class="ltx_p"><span id="A3.T5.5.9.9.2.1.3.1" class="ltx_text" style="font-size:70%;">- This year’s Setsubun (February 4)</span></span>
<span id="A3.T5.5.9.9.2.1.4" class="ltx_p"><span id="A3.T5.5.9.9.2.1.4.1" class="ltx_text" style="font-size:70%;">Step 2: Determine the dates for the corresponding events in the previous and next years.</span></span>
<span id="A3.T5.5.9.9.2.1.5" class="ltx_p"><span id="A3.T5.5.9.9.2.1.5.1" class="ltx_text" style="font-size:70%;">- Last year’s Setsubun (February 3) falls on a Monday.</span></span>
<span id="A3.T5.5.9.9.2.1.6" class="ltx_p"><span id="A3.T5.5.9.9.2.1.6.1" class="ltx_text" style="font-size:70%;">- This year’s Setsubun (February 4) falls on a Tuesday.</span></span>
<span id="A3.T5.5.9.9.2.1.7" class="ltx_p"><span id="A3.T5.5.9.9.2.1.7.1" class="ltx_text" style="font-size:70%;">Step 3: Calculate the number of days between the corresponding events.</span></span>
<span id="A3.T5.5.9.9.2.1.8" class="ltx_p"><span id="A3.T5.5.9.9.2.1.8.1" class="ltx_text" style="font-size:70%;">- The number of days between last year’s and this year’s Setsubun is 1 day (Tuesday - Monday = 1 day).</span></span>
<span id="A3.T5.5.9.9.2.1.9" class="ltx_p"><span id="A3.T5.5.9.9.2.1.9.1" class="ltx_text" style="font-size:70%;">Step 4: Determine the dates for the corresponding events in the lunar calendar.</span></span>
<span id="A3.T5.5.9.9.2.1.10" class="ltx_p"><span id="A3.T5.5.9.9.2.1.10.1" class="ltx_text" style="font-size:70%;">- Last year’s Setsubun was on the 1st day of the 2nd month.</span></span>
<span id="A3.T5.5.9.9.2.1.11" class="ltx_p"><span id="A3.T5.5.9.9.2.1.11.1" class="ltx_text" style="font-size:70%;">- This year’s Setsubun will be on the 2nd day of the 2nd month.</span></span>
<span id="A3.T5.5.9.9.2.1.12" class="ltx_p"><span id="A3.T5.5.9.9.2.1.12.1" class="ltx_text" style="font-size:70%;">Step 5: Calculate the number of days between the corresponding events in the lunar calendar.</span></span>
<span id="A3.T5.5.9.9.2.1.13" class="ltx_p"><span id="A3.T5.5.9.9.2.1.13.1" class="ltx_text" style="font-size:70%;">- The number of days between last year’s and this year’s Setsubun in the lunar calendar is 1 day (2nd day - 1st day = 1 day).</span></span>
<span id="A3.T5.5.9.9.2.1.14" class="ltx_p"><span id="A3.T5.5.9.9.2.1.14.1" class="ltx_text" style="font-size:70%;">Step 6: Add the number of days between the corresponding events in both calendars.</span></span>
<span id="A3.T5.5.9.9.2.1.15" class="ltx_p"><span id="A3.T5.5.9.9.2.1.15.1" class="ltx_text" style="font-size:70%;">- The total number of days between last year’s and this year’s Setsubun is 1 (from the solar calendar) + 1 (from the lunar calendar) = 2 days.</span></span>
<span id="A3.T5.5.9.9.2.1.16" class="ltx_p"><span id="A3.T5.5.9.9.2.1.16.1" class="ltx_text" style="font-size:70%;">Step 7: Write the final answer.</span></span>
<span id="A3.T5.5.9.9.2.1.17" class="ltx_p"><span id="A3.T5.5.9.9.2.1.17.1" class="ltx_text" style="font-size:70%;">- The sum of the dates for the corresponding events is 2.</span></span>
<span id="A3.T5.5.9.9.2.1.18" class="ltx_p"><span id="A3.T5.5.9.9.2.1.18.1" class="ltx_text" style="font-size:70%;">The answer is: 2.</span></span>
</span>
</td>
</tr>
<tr id="A3.T5.5.10.10" class="ltx_tr">
<td id="A3.T5.5.10.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="A3.T5.5.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.10.10.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T5.5.10.10.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">WizardMath-7B-V1.1</span><span id="A3.T5.5.10.10.1.1.1.2" class="ltx_text" style="font-size:70%;"></span></span>
<span id="A3.T5.5.10.10.1.1.2" class="ltx_p"><span id="A3.T5.5.10.10.1.1.2.1" class="ltx_text" style="font-size:70%;">EN Instruction</span></span>
</span>
</td>
<td id="A3.T5.5.10.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="A3.T5.5.10.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T5.5.10.10.2.1.1" class="ltx_p" style="width:284.5pt;"><span id="A3.T5.5.10.10.2.1.1.1" class="ltx_text" style="font-size:70%;">We are given that last year, Risshun (the beginning of spring according to the lunisolar Japanese calendar) was on February 3rd, and this year it is on February 4th. We need to find the sum of the month and day of last year’s Setsubun, and this year’s Setsubun.</span></span>
<span id="A3.T5.5.10.10.2.1.2" class="ltx_p"><span id="A3.T5.5.10.10.2.1.2.1" class="ltx_text" style="font-size:70%;">Step 2: Identify the month and day of last year’s Setsubun.
Last year, Risshun was on February 3rd. So, the month is February (2) and the day is 3.</span></span>
<span id="A3.T5.5.10.10.2.1.3" class="ltx_p"><span id="A3.T5.5.10.10.2.1.3.1" class="ltx_text" style="font-size:70%;">Step 3: Identify the month and day of this year’s Setsubun.
This year, Risshun is on February 4th. So, the month is February (2) and the day is 4.</span></span>
<span id="A3.T5.5.10.10.2.1.4" class="ltx_p"><span id="A3.T5.5.10.10.2.1.4.1" class="ltx_text" style="font-size:70%;">Step 4: Calculate the sum of the month and day of last year’s and this year’s Setsubun.
The sum of the month and day of last year’s Setsubun is 2 + 3 = 5.
The sum of the month and day of this year’s Setsubun is 2 + 4 = 6.</span></span>
<span id="A3.T5.5.10.10.2.1.5" class="ltx_p"><span id="A3.T5.5.10.10.2.1.5.1" class="ltx_text" style="font-size:70%;">Step 5: Add the two sums together.
The total sum of the month and day of last year’s and this year’s Setsubun is 5 + 6 = 11.</span></span>
<span id="A3.T5.5.10.10.2.1.6" class="ltx_p"><span id="A3.T5.5.10.10.2.1.6.1" class="ltx_text" style="font-size:70%;">So, the sum of the month and day of last year’s Setsubun, and this year’s Setsubun is 11.</span></span>
<span id="A3.T5.5.10.10.2.1.7" class="ltx_p"><span id="A3.T5.5.10.10.2.1.7.1" class="ltx_text" style="font-size:70%;">The answer is: 11.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div id="A3.p3" class="ltx_para">
<p id="A3.p3.1" class="ltx_p">Additionally, Table&nbsp;<a href="#A3.T6" title="Table 6 ‣ Appendix C Case Study ‣ Evolutionary Optimization of Model Merging Recipes" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> provides the case studies for our VLM. We observe that our VLM successfully obtained knowledge of the Japanese LLM. In the 1st example, our VLM generates the correct answer (Koi-nobori) while the original VLM (<span id="A3.p3.1.1" class="ltx_text ltx_font_typewriter">LLaVA-1.6-Mistral-7B</span>) answers incorrectly. Compared to the Japanese VLM (JSVLM), our VLM generally describes the photo more precisely as the 2nd example of a deer. Also, we found that the original VLM hallucinates a lot in Japanese such that it answers the color of traffic light is green while our VLM answers correctly.</p>
</div>
<figure id="A3.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 6: </span><span id="A3.T6.6.1" class="ltx_text ltx_font_bold">Case Study of EvoVLM-JP</span>. This study presents the responses of the VLMs to questions that demand both Japanese-specific knowledge and VQA abilities.</figcaption>
<table id="A3.T6.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A3.T6.2.3.1" class="ltx_tr">
<td id="A3.T6.2.3.1.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="2"><span id="A3.T6.2.3.1.1.1" class="ltx_text ltx_font_bold ltx_font_italic" style="font-size:70%;">Example 1</span></td>
</tr>
<tr id="A3.T6.1.1" class="ltx_tr">
<td id="A3.T6.1.1.2" class="ltx_td ltx_align_top ltx_border_t"></td>
<td id="A3.T6.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T6.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.1.1.1.1.1" class="ltx_p" style="width:341.4pt;"><img src="/html/2403.13187/assets/figures/vlm-koinobori.jpg" id="A3.T6.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="118" height="89" alt="[Uncaptioned image]"></span>
</span>
</td>
</tr>
<tr id="A3.T6.2.4.2" class="ltx_tr">
<td id="A3.T6.2.4.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A3.T6.2.4.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.4.2.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T6.2.4.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">User</span></span>
</span>
</td>
<td id="A3.T6.2.4.2.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A3.T6.2.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.4.2.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.T6.2.4.2.2.1.1.1" class="ltx_text" style="font-size:70%;">この画像に映っている魚の形をした飾りは、日本では何と呼ばれていますか？</span></span>
<span id="A3.T6.2.4.2.2.1.2" class="ltx_p"><span id="A3.T6.2.4.2.2.1.2.1" class="ltx_text" style="font-size:70%;">(What is the fish-shaped decoration in this image called in Japan?)</span></span>
</span>
</td>
</tr>
<tr id="A3.T6.2.5.3" class="ltx_tr">
<td id="A3.T6.2.5.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T6.2.5.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.5.3.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T6.2.5.3.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">LLaVA-1.6-Mistral-7B</span></span>
</span>
</td>
<td id="A3.T6.2.5.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T6.2.5.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.5.3.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.T6.2.5.3.2.1.1.1" class="ltx_text" style="font-size:70%;">この画像に映っている魚の形をした飾りは、日本では「花魚」と呼ばれています。</span></span>
<span id="A3.T6.2.5.3.2.1.2" class="ltx_p"><span id="A3.T6.2.5.3.2.1.2.1" class="ltx_text" style="font-size:70%;">(The fish-shaped decoration in this image is called "hana-gyo" in Japan.)</span></span>
</span>
</td>
</tr>
<tr id="A3.T6.2.6.4" class="ltx_tr">
<td id="A3.T6.2.6.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T6.2.6.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.6.4.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T6.2.6.4.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Japanese Stable VLM</span></span>
</span>
</td>
<td id="A3.T6.2.6.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T6.2.6.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.6.4.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.T6.2.6.4.2.1.1.1" class="ltx_text" style="font-size:70%;">こいのぼり (Koi-nobori)</span></span>
</span>
</td>
</tr>
<tr id="A3.T6.2.7.5" class="ltx_tr">
<td id="A3.T6.2.7.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T6.2.7.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.7.5.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T6.2.7.5.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">EvoVLM-JP</span></span>
</span>
</td>
<td id="A3.T6.2.7.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T6.2.7.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.7.5.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.T6.2.7.5.2.1.1.1" class="ltx_text" style="font-size:70%;">この画像に映っている魚の形をした飾りは、日本では「鯉のぼり」と呼ばれています。</span></span>
<span id="A3.T6.2.7.5.2.1.2" class="ltx_p"><span id="A3.T6.2.7.5.2.1.2.1" class="ltx_text" style="font-size:70%;">(The fish-shaped decoration in this image is called "Koi-nobori" in Japan.)</span></span>
</span>
</td>
</tr>
<tr id="A3.T6.2.8.6" class="ltx_tr">
<td id="A3.T6.2.8.6.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="2"><span id="A3.T6.2.8.6.1.1" class="ltx_text ltx_font_bold ltx_font_italic" style="font-size:70%;">Example 2</span></td>
</tr>
<tr id="A3.T6.2.2" class="ltx_tr">
<td id="A3.T6.2.2.2" class="ltx_td ltx_align_top ltx_border_t"></td>
<td id="A3.T6.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T6.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.2.1.1.1" class="ltx_p" style="width:341.4pt;"><img src="/html/2403.13187/assets/figures/vlm-deer.jpg" id="A3.T6.2.2.1.1.1.g1" class="ltx_graphics ltx_img_portrait" width="118" height="177" alt="[Uncaptioned image]"></span>
</span>
</td>
</tr>
<tr id="A3.T6.2.9.7" class="ltx_tr">
<td id="A3.T6.2.9.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A3.T6.2.9.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.9.7.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T6.2.9.7.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">User</span></span>
</span>
</td>
<td id="A3.T6.2.9.7.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A3.T6.2.9.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.9.7.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.T6.2.9.7.2.1.1.1" class="ltx_text" style="font-size:70%;">写真を説明してください。</span></span>
<span id="A3.T6.2.9.7.2.1.2" class="ltx_p"><span id="A3.T6.2.9.7.2.1.2.1" class="ltx_text" style="font-size:70%;">(Please explain this photo.)</span></span>
</span>
</td>
</tr>
<tr id="A3.T6.2.10.8" class="ltx_tr">
<td id="A3.T6.2.10.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T6.2.10.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.10.8.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T6.2.10.8.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">LLaVA-1.6-Mistral-7B</span></span>
</span>
</td>
<td id="A3.T6.2.10.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T6.2.10.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.10.8.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.T6.2.10.8.2.1.1.1" class="ltx_text" style="font-size:70%;">この写真では、自然の中で小さな動物が歩いています。その動物は、犬のような外貌を持っていますが、実際には犬ではありません。この動物は、野生動物として知られていますが、具体的な種類はわかりません。 背景には、秋の季節になっていることがわかります。多くの樹木には、黄色い葉が落ちています。このような環境で、動物が歩いていることを見ることができます。 この写真では、動物が自然の中で活動していることを表現しています。同時に、秋の季節になっていることを伝えることもできます。</span></span>
<span id="A3.T6.2.10.8.2.1.2" class="ltx_p"><span id="A3.T6.2.10.8.2.1.2.1" class="ltx_text" style="font-size:70%;">(In this photo, a small animal is walking in nature. The animal has a canine-like appearance but is not actually a dog. This creature is known as a wild animal, but the specific species is unknown. In the background, it is evident that it is autumn. Many trees have yellow leaves falling. In such an environment, the animal can be seen walking. The photo depicts the animal being active in nature while also conveying that it is autumn.)</span></span>
</span>
</td>
</tr>
<tr id="A3.T6.2.11.9" class="ltx_tr">
<td id="A3.T6.2.11.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T6.2.11.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.11.9.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T6.2.11.9.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Japanese Stable VLM</span></span>
</span>
</td>
<td id="A3.T6.2.11.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.T6.2.11.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.11.9.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.T6.2.11.9.2.1.1.1" class="ltx_text" style="font-size:70%;">紅葉と鹿の写真です。</span></span>
<span id="A3.T6.2.11.9.2.1.2" class="ltx_p"><span id="A3.T6.2.11.9.2.1.2.1" class="ltx_text" style="font-size:70%;">(It’s a photo of autumn leaves and deer.)</span></span>
</span>
</td>
</tr>
<tr id="A3.T6.2.12.10" class="ltx_tr">
<td id="A3.T6.2.12.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="A3.T6.2.12.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.12.10.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.T6.2.12.10.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">EvoVLM-JP</span></span>
</span>
</td>
<td id="A3.T6.2.12.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="A3.T6.2.12.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T6.2.12.10.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.T6.2.12.10.2.1.1.1" class="ltx_text" style="font-size:70%;">この写真は、一匹の小さな鹿が落ち葉の上に立っている様子を捉えています。鹿は警戒しているようで、周囲を注意深く見回しています。背景には紅葉した木々が見え、秋の雰囲気が感じられます。</span></span>
<span id="A3.T6.2.12.10.2.1.2" class="ltx_p"><span id="A3.T6.2.12.10.2.1.2.1" class="ltx_text" style="font-size:70%;">(This photo captures a small deer standing on fallen leaves. The deer appears to be alert, carefully scanning its surroundings. In the background, you can see trees with autumn foliage, creating an atmosphere of autumn.)</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure id="A3.2" class="ltx_table">
<table id="A3.2.2" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A3.2.2.3.1" class="ltx_tr">
<td id="A3.2.2.3.1.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="2"><span id="A3.2.2.3.1.1.1" class="ltx_text ltx_font_bold ltx_font_italic" style="font-size:70%;">Example 3</span></td>
</tr>
<tr id="A3.1.1.1" class="ltx_tr">
<td id="A3.1.1.1.2" class="ltx_td ltx_align_top ltx_border_t"></td>
<td id="A3.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.1.1.1.1.1.1" class="ltx_p" style="width:341.4pt;"><img src="/html/2403.13187/assets/figures/vlm-japan-traffic-lights.jpg" id="A3.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="236" height="167" alt="[Uncaptioned image]"></span>
</span>
</td>
</tr>
<tr id="A3.2.2.4.2" class="ltx_tr">
<td id="A3.2.2.4.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A3.2.2.4.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.4.2.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.2.2.4.2.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">User</span></span>
</span>
</td>
<td id="A3.2.2.4.2.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A3.2.2.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.4.2.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.2.2.4.2.2.1.1.1" class="ltx_text" style="font-size:70%;">この信号機の色は何色ですか?</span></span>
<span id="A3.2.2.4.2.2.1.2" class="ltx_p"><span id="A3.2.2.4.2.2.1.2.1" class="ltx_text" style="font-size:70%;">(What color is this traffic light?)</span></span>
</span>
</td>
</tr>
<tr id="A3.2.2.5.3" class="ltx_tr">
<td id="A3.2.2.5.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.2.2.5.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.5.3.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.2.2.5.3.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">LLaVA-1.6-Mistral-7B</span></span>
</span>
</td>
<td id="A3.2.2.5.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.2.2.5.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.5.3.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.2.2.5.3.2.1.1.1" class="ltx_text" style="font-size:70%;">(A) この信号機の色は緑色です。
(The color of this traffic light is green.)</span></span>
<span id="A3.2.2.5.3.2.1.2" class="ltx_p"><span id="A3.2.2.5.3.2.1.2.1" class="ltx_text" style="font-size:70%;">(B) この信号機の色は緑色です。
(The color of this traffic light is green.)</span></span>
<span id="A3.2.2.5.3.2.1.3" class="ltx_p"><span id="A3.2.2.5.3.2.1.3.1" class="ltx_text" style="font-size:70%;">(C) この信号機の色は緑色です。
(The color of this traffic light is green.)</span></span>
</span>
</td>
</tr>
<tr id="A3.2.2.6.4" class="ltx_tr">
<td id="A3.2.2.6.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.2.2.6.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.6.4.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.2.2.6.4.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Japanese Stable VLM</span></span>
</span>
</td>
<td id="A3.2.2.6.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.2.2.6.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.6.4.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.2.2.6.4.2.1.1.1" class="ltx_text" style="font-size:70%;">(A) 緑色です。
(It is green.)</span></span>
<span id="A3.2.2.6.4.2.1.2" class="ltx_p"><span id="A3.2.2.6.4.2.1.2.1" class="ltx_text" style="font-size:70%;">(B) 緑と白です。
(It is green and white.)</span></span>
<span id="A3.2.2.6.4.2.1.3" class="ltx_p"><span id="A3.2.2.6.4.2.1.3.1" class="ltx_text" style="font-size:70%;">(C) 白色
(White)</span></span>
</span>
</td>
</tr>
<tr id="A3.2.2.7.5" class="ltx_tr">
<td id="A3.2.2.7.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.2.2.7.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.7.5.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.2.2.7.5.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">EvoVLM-JP</span></span>
</span>
</td>
<td id="A3.2.2.7.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.2.2.7.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.7.5.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.2.2.7.5.2.1.1.1" class="ltx_text" style="font-size:70%;">(A) この信号機の色は青です。
(The color of this traffic light is blue.)</span></span>
<span id="A3.2.2.7.5.2.1.2" class="ltx_p"><span id="A3.2.2.7.5.2.1.2.1" class="ltx_text" style="font-size:70%;">(B) この信号機の色は青です。
(The color of this traffic light is blue.)</span></span>
<span id="A3.2.2.7.5.2.1.3" class="ltx_p"><span id="A3.2.2.7.5.2.1.3.1" class="ltx_text" style="font-size:70%;">(C) この信号機の色は青です。
(The color of this traffic light is blue.)</span></span>
</span>
</td>
</tr>
<tr id="A3.2.2.8.6" class="ltx_tr">
<td id="A3.2.2.8.6.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" colspan="2"><span id="A3.2.2.8.6.1.1" class="ltx_text ltx_font_bold ltx_font_italic" style="font-size:70%;">Example 4</span></td>
</tr>
<tr id="A3.2.2.2" class="ltx_tr">
<td id="A3.2.2.2.2" class="ltx_td ltx_align_top ltx_border_t"></td>
<td id="A3.2.2.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.2.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.2.1.1.1" class="ltx_p" style="width:341.4pt;"><img src="/html/2403.13187/assets/figures/vlm-genbaku.jpg" id="A3.2.2.2.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="118" height="79" alt="[Uncaptioned image]"></span>
</span>
</td>
</tr>
<tr id="A3.2.2.9.7" class="ltx_tr">
<td id="A3.2.2.9.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A3.2.2.9.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.9.7.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.2.2.9.7.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">User</span></span>
</span>
</td>
<td id="A3.2.2.9.7.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="A3.2.2.9.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.9.7.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.2.2.9.7.2.1.1.1" class="ltx_text" style="font-size:70%;">この建物について教えてください。</span></span>
<span id="A3.2.2.9.7.2.1.2" class="ltx_p"><span id="A3.2.2.9.7.2.1.2.1" class="ltx_text" style="font-size:70%;">(Please explain this building.)</span></span>
</span>
</td>
</tr>
<tr id="A3.2.2.10.8" class="ltx_tr">
<td id="A3.2.2.10.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.2.2.10.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.10.8.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.2.2.10.8.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">LLaVA-1.6-Mistral-7B</span></span>
</span>
</td>
<td id="A3.2.2.10.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.2.2.10.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.10.8.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.2.2.10.8.2.1.1.1" class="ltx_text" style="font-size:70%;">この建物は、日本で位置しています。具体的には、東京都渋谷区にあります。この建物は、1945年8月15日に、第二次世界大戦中に日本軍によって攻撃され、完全に破壊されました。その後、1964年に再構築されました。 この建物は、「平和の塔」（Peace Tower）と呼ばれています。その名前は、この建物が再構築される際に決められた名前です。この建物は、平和を祈るために作られたものであり、国内外から多くの人々が訪れる場所です。</span></span>
<span id="A3.2.2.10.8.2.1.2" class="ltx_p"><span id="A3.2.2.10.8.2.1.2.1" class="ltx_text" style="font-size:70%;">(This building is located in Japan, specifically in Shibuya Ward, Tokyo. It was completely destroyed by the Japanese military during World War II on August 15, 1945. Subsequently, it was reconstructed in 1964. This building is called the "Peace Tower," a name decided upon during its reconstruction. It was created as a symbol of peace, and it is a place visited by many people from both within and outside the country to pray for peace.)</span></span>
</span>
</td>
</tr>
<tr id="A3.2.2.11.9" class="ltx_tr">
<td id="A3.2.2.11.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.2.2.11.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.11.9.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.2.2.11.9.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">Japanese Stable VLM</span></span>
</span>
</td>
<td id="A3.2.2.11.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="A3.2.2.11.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.11.9.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.2.2.11.9.2.1.1.1" class="ltx_text" style="font-size:70%;">原爆ドーム</span></span>
<span id="A3.2.2.11.9.2.1.2" class="ltx_p"><span id="A3.2.2.11.9.2.1.2.1" class="ltx_text" style="font-size:70%;">(Atomic Bomb Dome)</span></span>
</span>
</td>
</tr>
<tr id="A3.2.2.12.10" class="ltx_tr">
<td id="A3.2.2.12.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="A3.2.2.12.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.12.10.1.1.1" class="ltx_p" style="width:85.4pt;"><span id="A3.2.2.12.10.1.1.1.1" class="ltx_text ltx_font_bold" style="font-size:70%;">EvoVLM-JP</span></span>
</span>
</td>
<td id="A3.2.2.12.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="A3.2.2.12.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.2.2.12.10.2.1.1" class="ltx_p" style="width:341.4pt;"><span id="A3.2.2.12.10.2.1.1.1" class="ltx_text" style="font-size:70%;">この建物は、日本の広島市にある「原爆ドーム」です。 1945年8月6日、広島市に原子爆弾が投下されました。 この原子爆弾は、広島市の中心部にある「広島県産業奨励館」に直撃しました。 この奨励館は、現在は「原爆ドーム」と呼ばれています。 この原爆ドームは、原子爆弾の被害を受けた建物の中で、唯一残っている建物です。 この原爆ドームは、1996年に世界遺産に登録されました。</span></span>
<span id="A3.2.2.12.10.2.1.2" class="ltx_p"><span id="A3.2.2.12.10.2.1.2.1" class="ltx_text" style="font-size:70%;">(This building is the "Atomic Bomb Dome" located in Hiroshima City, Japan. On August 6, 1945, an atomic bomb was dropped on Hiroshima City. The bomb directly hit the "Hiroshima Prefectural Industrial Promotion Hall," located in the central part of Hiroshima City. This promotion hall is now known as the "Atomic Bomb Dome." It is the only building that remains standing among those damaged by the atomic bomb. The Atomic Bomb Dome was registered as a UNESCO World Heritage Site in 1996.)</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2403.13186" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2403.13187" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2403.13187">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2403.13187" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2403.13188" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Apr  5 14:12:03 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>