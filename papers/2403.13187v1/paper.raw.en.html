<html lang="en" data-theme="light"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>Evolutionary Optimization of Model Merging Recipes</title>
<!--Generated on Tue Mar 19 14:53:24 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css">
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2403.13187v1/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2403.13187v1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <span class="color-scheme-icon" aria-label="Light mode"></span>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="#myForm" onclick="event.preventDefault(); var modal = document.getElementById('myForm'); modal.style.display = 'block'; bugReportState.setInitiateWay('Header');">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2403.13187v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2403.13187v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
          <span class="color-scheme-icon"></span>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S1" title="1 Introduction ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S2" title="2 Background and Related Work ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background and Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S2.SS1" title="2.1 Overview of Model Merging ‣ 2 Background and Related Work ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Overview of Model Merging</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S2.SS2" title="2.2 Merging Language Models ‣ 2 Background and Related Work ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Merging Language Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S2.SS3" title="2.3 Connection to Evolutionary Neural Architecture Search ‣ 2 Background and Related Work ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Connection to Evolutionary Neural Architecture Search</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S3" title="3 Method ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S3.SS1" title="3.1 Merging in the Parameter Space ‣ 3 Method ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Merging in the Parameter Space</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S3.SS2" title="3.2 Merging in the Data Flow Space ‣ 3 Method ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Merging in the Data Flow Space</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S3.SS3" title="3.3 Merging in Both Spaces ‣ 3 Method ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Merging in Both Spaces</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4" title="4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS1" title="4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Evolving Japanese Math LLM</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS1.SSS1" title="4.1.1 Setup ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>Setup</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS1.SSS1.Px1" title="Source Models ‣ 4.1.1 Setup ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title">Source Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS1.SSS1.Px2" title="Dataset ‣ 4.1.1 Setup ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title">Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS1.SSS1.Px3" title="Evaluation ‣ 4.1.1 Setup ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title">Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS1.SSS1.Px4" title="Optimization ‣ 4.1.1 Setup ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title">Optimization</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS1.SSS2" title="4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS1.SSS3" title="4.1.3 Analysis ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.3 </span>Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS2" title="4.2 Evolving Japanese VLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Evolving Japanese VLM</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS2.SSS1" title="4.2.1 Multi-modality Extension ‣ 4.2 Evolving Japanese VLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Multi-modality Extension</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS2.SSS2" title="4.2.2 Setup ‣ 4.2 Evolving Japanese VLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>Setup</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS2.SSS2.Px1" title="Source Models ‣ 4.2.2 Setup ‣ 4.2 Evolving Japanese VLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title">Source Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS2.SSS2.Px2" title="Dataset ‣ 4.2.2 Setup ‣ 4.2 Evolving Japanese VLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title">Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS2.SSS2.Px3" title="Evaluation ‣ 4.2.2 Setup ‣ 4.2 Evolving Japanese VLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title">Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS2.SSS2.Px4" title="Optimization ‣ 4.2.2 Setup ‣ 4.2 Evolving Japanese VLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title">Optimization</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS2.SSS3" title="4.2.3 Results ‣ 4.2 Evolving Japanese VLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>Results</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S5" title="5 Discussion and Future Work ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion and Future Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S6" title="6 Limitations ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S7" title="7 Author Contributions ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Author Contributions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#A1" title="Appendix A Evaluation Details ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Evaluation Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#A2" title="Appendix B Evolving for License Specific Open-Source Models ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Evolving for License Specific Open-Source Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#A3" title="Appendix C Case Study ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Case Study</span></a></li>
</ol></nav>

<div class="ltx_page_content"><div class="section" id="target-section"><div id="license-tr">License: arXiv.org perpetual non-exclusive license</div><div id="watermark-tr">arXiv:2403.13187v1 [cs.NE] 19 Mar 2024</div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Evolutionary Optimization of Model Merging Recipes</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Takuya Akiba, Makoto Shing, Yujin Tang, Qi Sun, David Ha
<br class="ltx_break">Sakana AI
<br class="ltx_break">Tokyo, Japan
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">{takiba,mkshing,yujintang,qisun,hadavid}@sakana.ai</span>
<br class="ltx_break">
</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id2.id1">We present a novel application of evolutionary algorithms to automate the creation of powerful foundation models. While model merging has emerged as a promising approach for LLM development due to its cost-effectiveness, it currently relies on human intuition and domain knowledge, limiting its potential. Here, we propose an evolutionary approach that overcomes this limitation by automatically discovering effective combinations of diverse open-source models, harnessing their collective intelligence without requiring extensive additional training data or compute. Our approach operates in both parameter space and data flow space, allowing for optimization beyond just the weights of the individual models. This approach even facilitates cross-domain merging, generating models like a Japanese LLM with Math reasoning capabilities. Surprisingly, our Japanese Math LLM achieved state-of-the-art performance on a variety of established Japanese LLM benchmarks, even surpassing models with significantly more parameters, despite not being explicitly trained for such tasks. Furthermore, a culturally-aware Japanese VLM generated through our approach demonstrates its effectiveness in describing Japanese culture-specific content, outperforming previous Japanese VLMs. This work not only contributes new state-of-the-art models back to the open-source community, but also introduces a new paradigm for automated model composition, paving the way for exploring alternative, efficient approaches to foundation model development.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><span class="ltx_text ltx_font_typewriter" id="footnote1.1">EvoLLM-JP</span>, <span class="ltx_text ltx_font_typewriter" id="footnote1.2">EvoVLM-JP</span> release: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/SakanaAI/evolutionary-model-merge" title="">https://github.com/SakanaAI/evolutionary-model-merge</a></span></span></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Model merging&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">16</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib29" title=""><span class="ltx_text" style="font-size:90%;">29</span></a>]</cite>, a recent development in the large language model (LLM) community, presents a novel paradigm shift. By strategically combining multiple LLMs into a single architecture, this exciting development has captured the attention of researchers due to its key advantage: it requires no additional training, making it an incredibly cost-effective approach for developing new models. This accessibility has fueled a surge in interest and experimentation with model merging. The Open LLM Leaderboard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib21" title=""><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite> is now dominated by merged models, showcasing its potential for democratizing foundation model development.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">However, model merging is considered by many to be a form of black art or alchemy, relying on the model maker’s intuition and instincts about model selection and merging recipes to create and refine a new model that performs well for a particular task. Furthermore, the model maker is often required to have some domain knowledge for the various different benchmark tasks.
Given the large diversity of open models and benchmarks in the community, human intuition can only go so far, and we believe a more systematic approach for discovering new model combinations will take things much further.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">We believe evolutionary algorithms will be able to discover more effective model merging solutions, and thus provide a path for automating the creation of more capable models.
As a step towards this direction, in this work, we show that evolution can be employed to discover novel and unintuitive ways to merge various models to produce new models with a new combined ability.
In this work, we present a methodology that leverages evolutionary algorithms to facilitate the merging of foundation models. Our approach is distinguished by its ability to navigate both parameter space (weights) and the data flow space (inference path), proposing a framework that integrates these two dimensions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">This work makes several key contributions to the field of foundation model development:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p5">
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Automated Model Composition</span>: We introduce <span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.2">Evolutionary Model Merge</span>, a general evolutionary method to automatically discover optimal combinations of diverse open-source models for creating new foundation models with user-specified capabilities. This approach harnesses the collective intelligence of existing open models, enabling the creation of powerful models without the need for extensive training data or compute.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Cross-Domain Merging</span>: We demonstrate that our method can discover novel ways to merge models from disparate domains (e.g., non-English language and Math, non-English language and Vision), potentially exceeding the capabilities achievable through conventional human design strategies.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">State-of-the-Art Performance</span>: We showcase the effectiveness of our method by automatically generating a Japanese LLM with Math reasoning capability and a Japanese Vision-Language Model (VLM). Notably, both models achieve state-of-the-art performance on various benchmarks, even without explicit optimization for those tasks.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i4.p1.1.1">High Efficiency and Surprising Generalizability</span>: We observe that our 7B parameter LLM surpasses the performance of some previous 70B parameter Japanese LLMs on benchmark datasets, highlighting the high efficiency and surprising generalization capability of our approach. We believe this model can serve as a strong general-purpose Japanese LLM.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="S1.I1.i5.p1">
<p class="ltx_p" id="S1.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i5.p1.1.1">Culturally-Aware VLM</span>: The generated Japanese VLM achieves top results when tested on a domestically-sourced dataset of Japanese image-description pairs, demonstrating its ability to handle Japanese culture-specific content.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ol>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">We are committed to open science and are excited to open-sourcing our <span class="ltx_text ltx_font_typewriter" id="S1.p6.1.1">EvoLLM-JP</span> and <span class="ltx_text ltx_font_typewriter" id="S1.p6.1.2">EvoVLM-JP</span>, two state-of-the-art Japanese foundation models, to the community, enabling further research and development in the field. Our work challenges the conventional paradigm of expensive model development by demonstrating that our evolutionary-based method can produce competitive models without relying on gradient-based training. This paves the way for exploring alternative, potentially more efficient, approaches to foundation model development.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Related Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Overview of Model Merging</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Model merging offers a novel approach to leverage the strengths of multiple pre-trained models. It allows us to combine task-specific models, each potentially fine-tuned for a particular downstream task, into a single unified model. This technique stands in contrast to traditional transfer learning, where a pre-trained model is further fine-tuned for a new task. While transfer learning offers advantages like improved performance and faster convergence, the resulting models are typically limited to single tasks. Model merging, on the other hand, strives to create a versatile and comprehensive model by combining the knowledge from multiple pre-trained models, potentially yielding a model capable of handling various tasks simultaneously.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">A simple method of merging multiple models is to average the weights of multiple models fine-tuned from the same base initial model. This <span class="ltx_text ltx_font_italic" id="S2.SS1.p2.1.1">model soup</span> approach&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib49" title=""><span class="ltx_text" style="font-size:90%;">49</span></a>]</cite> demonstrated significant improvements on relatively large image processing and image classification models. The work pointed to similarity between weighted model averaging leading to a flat local minima. Theoretical&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib12" title=""><span class="ltx_text" style="font-size:90%;">12</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib26" title=""><span class="ltx_text" style="font-size:90%;">26</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib38" title=""><span class="ltx_text" style="font-size:90%;">38</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib27" title=""><span class="ltx_text" style="font-size:90%;">27</span></a>]</cite> and empirical studies dating back from the 1990s&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib19" title=""><span class="ltx_text" style="font-size:90%;">19</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib20" title=""><span class="ltx_text" style="font-size:90%;">20</span></a>]</cite> demonstrated that flatter local optima generalize better to out-of-distribution shifts. More recent work&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib35" title=""><span class="ltx_text" style="font-size:90%;">35</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib9" title=""><span class="ltx_text" style="font-size:90%;">9</span></a>]</cite> examined the theoretical properties and practical implications of weight averaging applied to larger generative models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">Linear weight averaging not only works well for image processing and classification models, but is also effective for image generation models such as latent diffusion models. The release of Stable Diffusion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib40" title=""><span class="ltx_text" style="font-size:90%;">40</span></a>]</cite> led to a variety of specialist fine-tunes of the model for a variety of different styles, from photorealism, to anime, to realistic painting styles. Popular open-source WebUIs&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite> enabled hobbyists to experiment with merging different models using linear or spherical linear interpolation (SLERP)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib48" title=""><span class="ltx_text" style="font-size:90%;">48</span></a>]</cite> of weight parameters of distinct fine-tuned Stable Diffusion models. This has led to the discovery of merged models that combine strengths of specialized models into a single model.
For some time, the most popular Stable Diffusion models were neither the original base models nor the fine-tuned versions, but rather the merged models created by enthusiasts. This trend persists until the release of a more advanced base model, at which point the community’s cycle of fine-tuning and merging is renewed.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Merging Language Models</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Simple weight interpolation works well for merging image generation models that operate in a real valued latent and output space, but to our surprise, they also still work for merging language models under the right conditions, but have performance issues&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>. Recently, new methods have been proposed to address merging language models specifically. One method, Task Arithmetic&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib22" title=""><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite>, involves building <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.1">task vectors</span> by subtracting pre-trained from fine-tuned model weights, enabling manipulation through arithmetic operations to steer the merged model’s behavior.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">A key problem of weight interpolation-based methods is that they neglect parameter interference, leading to performance degradation. A recent work&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite> identifies two key sources of interference: redundant parameter values and conflicting parameter signs across models, and proposes a method that addresses these issues to achieve improved merging performance. The proposed TIES-Merging method addresses information loss in existing merging methods by incorporating three steps: resetting minimal parameter changes, resolving sign conflicts, and merging only aligned parameters.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">Another recent work&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib51" title=""><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite> proposes the DARE method goes further by zeroing out small differences between the fine-tuned model and the original base model, while amplifying the differences. In practice, DARE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib51" title=""><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite> is often used together with Task Arithmetic&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib22" title=""><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite> or TIES-Merging&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">Image generation model merging really took off in the community only after such methods were implemented in open-source toolkits&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib5" title=""><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite>. Similarly, language model merging really gained popularity after the implementation of <span class="ltx_text ltx_font_italic" id="S2.SS2.p4.1.1">mergekit</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib16" title=""><span class="ltx_text" style="font-size:90%;">16</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib29" title=""><span class="ltx_text" style="font-size:90%;">29</span></a>]</cite>. This toolkit provides all of the popular <span class="ltx_text ltx_font_italic" id="S2.SS2.p4.1.2">recipes</span> for merging language models. In addition to simple linear and spherical interpolation, advanced recipes such as Task Arithmetic, TIES-Merging, DARE are also implemented, offering users the ability to experiment with combining these methods to work with fine-tunes of popular base models such as Mistral&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib23" title=""><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite>. With this toolkit, a large number of capable merged models are developed by the community, and most of the top models on the Open LLM Leaderboard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib21" title=""><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite> are gradually dominated by merged models produced by the community of language model enthusiasts.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS2.p5">
<p class="ltx_p" id="S2.SS2.p5.1">Mergekit also introduced an additional method, called <span class="ltx_text ltx_font_italic" id="S2.SS2.p5.1.1">Frankenmerging</span> which is not based on weight merging, but for the user to experiment with trying to stack different layers from multiple models to sequentially create a new model. This method has the advantage of not tying the user to one particular family of models with a fixed architecture for merging (e.g. Mistral-based models), but potentially creating <span class="ltx_text ltx_font_italic" id="S2.SS2.p5.1.2">new</span> architectures from merging entirely different models. It is noted that discovering new <span class="ltx_text ltx_font_italic" id="S2.SS2.p5.1.3">Frankenmerging</span> technique remains a challenge for the community, and requires much more trial and error to discover new recipes for this technique. To date, almost everyone uses a similar <span class="ltx_text ltx_font_italic" id="S2.SS2.p5.1.4">Frankenmerging</span> merge recipe, and there has been very little trial and error to improve upon it. The field remains highly under-explored, and we believe this is where evolution can help.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Connection to Evolutionary Neural Architecture Search</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Model merging holds significant potential and democratizes the model-building process, making it accessible to a broad range of participants. However, it heavily relies on intuition and domain knowledge. Human intuition, however, has its limits. With the growing diversity of open models and tasks, we need a more systematic approach. We believe evolutionary algorithms, inspired by natural selection, can unlock more effective merging solutions. These algorithms can explore a vast space of possibilities, discovering novel and counter-intuitive combinations that traditional methods and human intuition might miss.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">In deep learning, techniques such as Neural Architecture Search (NAS)&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib52" title=""><span class="ltx_text" style="font-size:90%;">52</span></a>]</cite> employed evolutionary techniques to discover new architectures&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib39" title=""><span class="ltx_text" style="font-size:90%;">39</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib45" title=""><span class="ltx_text" style="font-size:90%;">45</span></a>]</cite> that might be non-intuitive for human designers to discover. However, NAS-methods consumed significant computational resources given how each candidate model architecture needed to be trained. Our approach aims to <span class="ltx_text ltx_font_italic" id="S2.SS3.p2.1.1">save</span> compute resources by discovering structures that take advantage of existing capabilities of existing Transformer blocks that had already consumed considerable resources to train in the first place.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1">Pre-trained transformer blocks are akin to neural network components one can choose to mix and match using an evolutionary architecture search algorithm. However, unlike NAS, we do not need to train the model, and can evaluate the candidates right away. In a sense, our work resonates with the goals of earlier works of morphology search such as NEAT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib46" title=""><span class="ltx_text" style="font-size:90%;">46</span></a>]</cite> and more recent work such as Weight Agnostic Neural Networks&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib13" title=""><span class="ltx_text" style="font-size:90%;">13</span></a>]</cite> which evolved neural network structures with certain task-specific inductive biases, without the need to train the weight parameters using gradient descent. Similarly, this was how NAS methods such as SMASH&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib46" title=""><span class="ltx_text" style="font-size:90%;">46</span></a>]</cite> avoided costly inner-loop training through the application of a Hypernetwork&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib17" title=""><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite> to estimate the weights of architectural candidates.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.SS3.p4">
<p class="ltx_p" id="S2.SS3.p4.1">In this work, we apply evolution to not only automate the optimization of model merging recipes in weight space, confined to a single architecture, but also explore applying evolution to optimize the stacking of layers from different models—a more involved approach that has the potential to create entirely novel neural architectures from existing building blocks. Unlike weight merging optimization which confine space of models to be merged together to fine-tuned descendents of the same parent base model, layer stacking optimization has no such constraints. Our work systematically explores the application of evolution applied in both parameter and layer space.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Our goal is to create a unified framework capable of automatically generating a merged model from a selection of foundation models, ensuring that the performance of this merged model surpasses that of any individual in the collection. Central to our approach is the application of evolutionary algorithms, which we employ to refine the intricacies involved in model merging. To systematically address this challenge, we first dissect the merging process into two distinct, orthogonal configuration spaces, analyzing their individual impacts. Building on this analysis, we then introduce a cohesive framework that seamlessly integrates these spaces. Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S3.F1" title="Figure 1 ‣ 3 Method ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">1</span></a> provides a schematic representation of our approach.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="403" id="S3.F1.g1" src="x1.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text ltx_font_bold" id="S3.F1.2.1">Overview of Evolutionary Model Merge</span>. Our approach encompasses (1) evolving the weights for mixing parameters at each layer in the parameter space (PS); (2) evolving layer permutations in the data flow space (DFS); and (3) an integrated strategy that combines both methods for merging in both PS and DFS. Notice that merging in the PS is not simple copying and stitching of the layers parameters, but also mixes the weights. This merging is akin to blending colors as illustrated here (e.g., red and blue becomes purple). Note that we translated the questions to English for the reader; the models operate on Japanese text.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Merging in the Parameter Space</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Model merging in the parameter space (PS) aims to integrate the weights of multiple foundational models into a unified entity with the same neural network architecture, yet outperforming the individual models. While various strategies for combining model parameters exist&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib35" title=""><span class="ltx_text" style="font-size:90%;">35</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib49" title=""><span class="ltx_text" style="font-size:90%;">49</span></a>]</cite>, our approach leverages task vectors analysis to understand each model’s strengths, based on the specific tasks they are optimized for or excel in&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib22" title=""><span class="ltx_text" style="font-size:90%;">22</span></a>]</cite>. Specifically, we enhance TIES-Merging with DARE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib51" title=""><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite>, allowing for more granular, layer-wise merging (In this paper, by “layer” we mean the input/output embedding layers or a transformer block). We establish merging configuration parameters for sparsification and weight mixing at each layer, including input and output embeddings. These configurations are then optimized using an evolutionary algorithm, such as CMA-ES&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite>, for selected tasks, guided by critical task-specific metrics (e.g., accuracy for MGSM, ROUGE score for VQA).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Merging in the Data Flow Space</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.4">Recent analysis and discoveries imply that knowledge is stored distributedly in language models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib15" title=""><span class="ltx_text" style="font-size:90%;">15</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib37" title=""><span class="ltx_text" style="font-size:90%;">37</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib36" title=""><span class="ltx_text" style="font-size:90%;">36</span></a>]</cite>, suggesting simple yet novel model merging possibilities in the data flow space (DFS). Unlike merging in PS, model merging in DFS preserves the original weights of each layer intact. Instead, it optimizes the inference path that tokens follow as they traverse through the neural network. For example, after the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_i</annotation></semantics></math>-th layer in model <math alttext="A" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><mi id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">A</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_A</annotation></semantics></math>, a token may be directed to the <math alttext="j" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_j</annotation></semantics></math>-th layer in model <math alttext="B" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">B</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_B</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.7">In our initial effort in this domain, we limit ourselves to serial connections and non-adaptive configurations, deferring the investigation of more flexible model merging to future work. Concretely, with a collection of <math alttext="N" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><mi id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><ci id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">italic_N</annotation></semantics></math> models and a budget <math alttext="T" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><mi id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><ci id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">italic_T</annotation></semantics></math>, our method searches for a sequence of layer indices <math alttext="L_{i,j}^{(t)}" class="ltx_Math" display="inline" id="S3.SS2.p2.3.m3.3"><semantics id="S3.SS2.p2.3.m3.3a"><msubsup id="S3.SS2.p2.3.m3.3.4" xref="S3.SS2.p2.3.m3.3.4.cmml"><mi id="S3.SS2.p2.3.m3.3.4.2.2" xref="S3.SS2.p2.3.m3.3.4.2.2.cmml">L</mi><mrow id="S3.SS2.p2.3.m3.2.2.2.4" xref="S3.SS2.p2.3.m3.2.2.2.3.cmml"><mi id="S3.SS2.p2.3.m3.1.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p2.3.m3.2.2.2.4.1" xref="S3.SS2.p2.3.m3.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p2.3.m3.2.2.2.2" xref="S3.SS2.p2.3.m3.2.2.2.2.cmml">j</mi></mrow><mrow id="S3.SS2.p2.3.m3.3.3.1.3" xref="S3.SS2.p2.3.m3.3.4.cmml"><mo id="S3.SS2.p2.3.m3.3.3.1.3.1" stretchy="false" xref="S3.SS2.p2.3.m3.3.4.cmml">(</mo><mi id="S3.SS2.p2.3.m3.3.3.1.1" xref="S3.SS2.p2.3.m3.3.3.1.1.cmml">t</mi><mo id="S3.SS2.p2.3.m3.3.3.1.3.2" stretchy="false" xref="S3.SS2.p2.3.m3.3.4.cmml">)</mo></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.3b"><apply id="S3.SS2.p2.3.m3.3.4.cmml" xref="S3.SS2.p2.3.m3.3.4"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.3.4.1.cmml" xref="S3.SS2.p2.3.m3.3.4">superscript</csymbol><apply id="S3.SS2.p2.3.m3.3.4.2.cmml" xref="S3.SS2.p2.3.m3.3.4"><csymbol cd="ambiguous" id="S3.SS2.p2.3.m3.3.4.2.1.cmml" xref="S3.SS2.p2.3.m3.3.4">subscript</csymbol><ci id="S3.SS2.p2.3.m3.3.4.2.2.cmml" xref="S3.SS2.p2.3.m3.3.4.2.2">𝐿</ci><list id="S3.SS2.p2.3.m3.2.2.2.3.cmml" xref="S3.SS2.p2.3.m3.2.2.2.4"><ci id="S3.SS2.p2.3.m3.1.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1.1">𝑖</ci><ci id="S3.SS2.p2.3.m3.2.2.2.2.cmml" xref="S3.SS2.p2.3.m3.2.2.2.2">𝑗</ci></list></apply><ci id="S3.SS2.p2.3.m3.3.3.1.1.cmml" xref="S3.SS2.p2.3.m3.3.3.1.1">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.3c">L_{i,j}^{(t)}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.3.m3.3d">italic_L start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT</annotation></semantics></math> that delineates the path all the tokens should follow for a specific task. Here <math alttext="L_{i,j}" class="ltx_Math" display="inline" id="S3.SS2.p2.4.m4.2"><semantics id="S3.SS2.p2.4.m4.2a"><msub id="S3.SS2.p2.4.m4.2.3" xref="S3.SS2.p2.4.m4.2.3.cmml"><mi id="S3.SS2.p2.4.m4.2.3.2" xref="S3.SS2.p2.4.m4.2.3.2.cmml">L</mi><mrow id="S3.SS2.p2.4.m4.2.2.2.4" xref="S3.SS2.p2.4.m4.2.2.2.3.cmml"><mi id="S3.SS2.p2.4.m4.1.1.1.1" xref="S3.SS2.p2.4.m4.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p2.4.m4.2.2.2.4.1" xref="S3.SS2.p2.4.m4.2.2.2.3.cmml">,</mo><mi id="S3.SS2.p2.4.m4.2.2.2.2" xref="S3.SS2.p2.4.m4.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.2b"><apply id="S3.SS2.p2.4.m4.2.3.cmml" xref="S3.SS2.p2.4.m4.2.3"><csymbol cd="ambiguous" id="S3.SS2.p2.4.m4.2.3.1.cmml" xref="S3.SS2.p2.4.m4.2.3">subscript</csymbol><ci id="S3.SS2.p2.4.m4.2.3.2.cmml" xref="S3.SS2.p2.4.m4.2.3.2">𝐿</ci><list id="S3.SS2.p2.4.m4.2.2.2.3.cmml" xref="S3.SS2.p2.4.m4.2.2.2.4"><ci id="S3.SS2.p2.4.m4.1.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1.1.1">𝑖</ci><ci id="S3.SS2.p2.4.m4.2.2.2.2.cmml" xref="S3.SS2.p2.4.m4.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.2c">L_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.4.m4.2d">italic_L start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math> denotes the <math alttext="j" class="ltx_Math" display="inline" id="S3.SS2.p2.5.m5.1"><semantics id="S3.SS2.p2.5.m5.1a"><mi id="S3.SS2.p2.5.m5.1.1" xref="S3.SS2.p2.5.m5.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.5.m5.1b"><ci id="S3.SS2.p2.5.m5.1.1.cmml" xref="S3.SS2.p2.5.m5.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.5.m5.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.5.m5.1d">italic_j</annotation></semantics></math>-th layer in the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p2.6.m6.1"><semantics id="S3.SS2.p2.6.m6.1a"><mi id="S3.SS2.p2.6.m6.1.1" xref="S3.SS2.p2.6.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.6.m6.1b"><ci id="S3.SS2.p2.6.m6.1.1.cmml" xref="S3.SS2.p2.6.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.6.m6.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.6.m6.1d">italic_i</annotation></semantics></math>-th model, with <math alttext="t\in[1,T]" class="ltx_Math" display="inline" id="S3.SS2.p2.7.m7.2"><semantics id="S3.SS2.p2.7.m7.2a"><mrow id="S3.SS2.p2.7.m7.2.3" xref="S3.SS2.p2.7.m7.2.3.cmml"><mi id="S3.SS2.p2.7.m7.2.3.2" xref="S3.SS2.p2.7.m7.2.3.2.cmml">t</mi><mo id="S3.SS2.p2.7.m7.2.3.1" xref="S3.SS2.p2.7.m7.2.3.1.cmml">∈</mo><mrow id="S3.SS2.p2.7.m7.2.3.3.2" xref="S3.SS2.p2.7.m7.2.3.3.1.cmml"><mo id="S3.SS2.p2.7.m7.2.3.3.2.1" stretchy="false" xref="S3.SS2.p2.7.m7.2.3.3.1.cmml">[</mo><mn id="S3.SS2.p2.7.m7.1.1" xref="S3.SS2.p2.7.m7.1.1.cmml">1</mn><mo id="S3.SS2.p2.7.m7.2.3.3.2.2" xref="S3.SS2.p2.7.m7.2.3.3.1.cmml">,</mo><mi id="S3.SS2.p2.7.m7.2.2" xref="S3.SS2.p2.7.m7.2.2.cmml">T</mi><mo id="S3.SS2.p2.7.m7.2.3.3.2.3" stretchy="false" xref="S3.SS2.p2.7.m7.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.7.m7.2b"><apply id="S3.SS2.p2.7.m7.2.3.cmml" xref="S3.SS2.p2.7.m7.2.3"><in id="S3.SS2.p2.7.m7.2.3.1.cmml" xref="S3.SS2.p2.7.m7.2.3.1"></in><ci id="S3.SS2.p2.7.m7.2.3.2.cmml" xref="S3.SS2.p2.7.m7.2.3.2">𝑡</ci><interval closure="closed" id="S3.SS2.p2.7.m7.2.3.3.1.cmml" xref="S3.SS2.p2.7.m7.2.3.3.2"><cn id="S3.SS2.p2.7.m7.1.1.cmml" type="integer" xref="S3.SS2.p2.7.m7.1.1">1</cn><ci id="S3.SS2.p2.7.m7.2.2.cmml" xref="S3.SS2.p2.7.m7.2.2">𝑇</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.7.m7.2c">t\in[1,T]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.7.m7.2d">italic_t ∈ [ 1 , italic_T ]</annotation></semantics></math> marking the step in the inference path.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.7">One can quickly imagine how large the search space is. Assuming the total number of layers across all models is <math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><mi id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><ci id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_M</annotation></semantics></math>, the size of the search space is <math alttext="(M+1)^{T}" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><msup id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml"><mrow id="S3.SS2.p3.2.m2.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mo id="S3.SS2.p3.2.m2.1.1.1.1.2" stretchy="false" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.p3.2.m2.1.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.p3.2.m2.1.1.1.1.1.2" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml">M</mi><mo id="S3.SS2.p3.2.m2.1.1.1.1.1.1" xref="S3.SS2.p3.2.m2.1.1.1.1.1.1.cmml">+</mo><mn id="S3.SS2.p3.2.m2.1.1.1.1.1.3" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS2.p3.2.m2.1.1.1.1.3" stretchy="false" xref="S3.SS2.p3.2.m2.1.1.1.1.1.cmml">)</mo></mrow><mi id="S3.SS2.p3.2.m2.1.1.3" xref="S3.SS2.p3.2.m2.1.1.3.cmml">T</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><apply id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.2.m2.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1"><plus id="S3.SS2.p3.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.1"></plus><ci id="S3.SS2.p3.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.p3.2.m2.1.1.1.1.1.2">𝑀</ci><cn id="S3.SS2.p3.2.m2.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS2.p3.2.m2.1.1.1.1.1.3">1</cn></apply><ci id="S3.SS2.p3.2.m2.1.1.3.cmml" xref="S3.SS2.p3.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">(M+1)^{T}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">( italic_M + 1 ) start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT</annotation></semantics></math>, here the extra one indicates the inclusion of a pass-through layer. Even with a modest setting of <math alttext="M=64" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><mrow id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml"><mi id="S3.SS2.p3.3.m3.1.1.2" xref="S3.SS2.p3.3.m3.1.1.2.cmml">M</mi><mo id="S3.SS2.p3.3.m3.1.1.1" xref="S3.SS2.p3.3.m3.1.1.1.cmml">=</mo><mn id="S3.SS2.p3.3.m3.1.1.3" xref="S3.SS2.p3.3.m3.1.1.3.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><apply id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1"><eq id="S3.SS2.p3.3.m3.1.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1.1"></eq><ci id="S3.SS2.p3.3.m3.1.1.2.cmml" xref="S3.SS2.p3.3.m3.1.1.2">𝑀</ci><cn id="S3.SS2.p3.3.m3.1.1.3.cmml" type="integer" xref="S3.SS2.p3.3.m3.1.1.3">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">M=64</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_M = 64</annotation></semantics></math> (e.g., 2 models of 32 layers each) and <math alttext="T=60" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><mrow id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml"><mi id="S3.SS2.p3.4.m4.1.1.2" xref="S3.SS2.p3.4.m4.1.1.2.cmml">T</mi><mo id="S3.SS2.p3.4.m4.1.1.1" xref="S3.SS2.p3.4.m4.1.1.1.cmml">=</mo><mn id="S3.SS2.p3.4.m4.1.1.3" xref="S3.SS2.p3.4.m4.1.1.3.cmml">60</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><apply id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1"><eq id="S3.SS2.p3.4.m4.1.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1.1"></eq><ci id="S3.SS2.p3.4.m4.1.1.2.cmml" xref="S3.SS2.p3.4.m4.1.1.2">𝑇</ci><cn id="S3.SS2.p3.4.m4.1.1.3.cmml" type="integer" xref="S3.SS2.p3.4.m4.1.1.3">60</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">T=60</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">italic_T = 60</annotation></semantics></math>, this setting translates to an astronomically large search space, a challenge even for a capable evolutionary search algorithm. Luckily, our preliminary studies indicated that certain layer arrangements, particularly repetitive or permuted sequences from earlier in the model, can adversely affect performance. Based on this, we modify our settings to include an indicator array <math alttext="\mathcal{I}" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><ci id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">caligraphic_I</annotation></semantics></math> of size <math alttext="T=M\times r" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.1"><semantics id="S3.SS2.p3.6.m6.1a"><mrow id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2.cmml">T</mi><mo id="S3.SS2.p3.6.m6.1.1.1" xref="S3.SS2.p3.6.m6.1.1.1.cmml">=</mo><mrow id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml"><mi id="S3.SS2.p3.6.m6.1.1.3.2" xref="S3.SS2.p3.6.m6.1.1.3.2.cmml">M</mi><mo id="S3.SS2.p3.6.m6.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p3.6.m6.1.1.3.1.cmml">×</mo><mi id="S3.SS2.p3.6.m6.1.1.3.3" xref="S3.SS2.p3.6.m6.1.1.3.3.cmml">r</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><eq id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1.1"></eq><ci id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">𝑇</ci><apply id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3"><times id="S3.SS2.p3.6.m6.1.1.3.1.cmml" xref="S3.SS2.p3.6.m6.1.1.3.1"></times><ci id="S3.SS2.p3.6.m6.1.1.3.2.cmml" xref="S3.SS2.p3.6.m6.1.1.3.2">𝑀</ci><ci id="S3.SS2.p3.6.m6.1.1.3.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3.3">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">T=M\times r</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m6.1d">italic_T = italic_M × italic_r</annotation></semantics></math> in the evolutionary search space, here <math alttext="r" class="ltx_Math" display="inline" id="S3.SS2.p3.7.m7.1"><semantics id="S3.SS2.p3.7.m7.1a"><mi id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><ci id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">r</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.7.m7.1d">italic_r</annotation></semantics></math> is number of repetitions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.6">Conceptually, we layout all the layers in sequential order (i.e., all layers in the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.1"><semantics id="S3.SS2.p4.1.m1.1a"><mi id="S3.SS2.p4.1.m1.1.1" xref="S3.SS2.p4.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.1b"><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.1d">italic_i</annotation></semantics></math>-th model followed by those in the <math alttext="i+1" class="ltx_Math" display="inline" id="S3.SS2.p4.2.m2.1"><semantics id="S3.SS2.p4.2.m2.1a"><mrow id="S3.SS2.p4.2.m2.1.1" xref="S3.SS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.p4.2.m2.1.1.2" xref="S3.SS2.p4.2.m2.1.1.2.cmml">i</mi><mo id="S3.SS2.p4.2.m2.1.1.1" xref="S3.SS2.p4.2.m2.1.1.1.cmml">+</mo><mn id="S3.SS2.p4.2.m2.1.1.3" xref="S3.SS2.p4.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.2.m2.1b"><apply id="S3.SS2.p4.2.m2.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1"><plus id="S3.SS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.p4.2.m2.1.1.1"></plus><ci id="S3.SS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.p4.2.m2.1.1.2">𝑖</ci><cn id="S3.SS2.p4.2.m2.1.1.3.cmml" type="integer" xref="S3.SS2.p4.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.2.m2.1c">i+1</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.2.m2.1d">italic_i + 1</annotation></semantics></math>-th model) and repeat them <math alttext="r" class="ltx_Math" display="inline" id="S3.SS2.p4.3.m3.1"><semantics id="S3.SS2.p4.3.m3.1a"><mi id="S3.SS2.p4.3.m3.1.1" xref="S3.SS2.p4.3.m3.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.3.m3.1b"><ci id="S3.SS2.p4.3.m3.1.1.cmml" xref="S3.SS2.p4.3.m3.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.3.m3.1c">r</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.3.m3.1d">italic_r</annotation></semantics></math> times, the indicator array then manages the inclusion/exclusion of layers. If <math alttext="\mathcal{I}_{i}>0" class="ltx_Math" display="inline" id="S3.SS2.p4.4.m4.1"><semantics id="S3.SS2.p4.4.m4.1a"><mrow id="S3.SS2.p4.4.m4.1.1" xref="S3.SS2.p4.4.m4.1.1.cmml"><msub id="S3.SS2.p4.4.m4.1.1.2" xref="S3.SS2.p4.4.m4.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p4.4.m4.1.1.2.2" xref="S3.SS2.p4.4.m4.1.1.2.2.cmml">ℐ</mi><mi id="S3.SS2.p4.4.m4.1.1.2.3" xref="S3.SS2.p4.4.m4.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS2.p4.4.m4.1.1.1" xref="S3.SS2.p4.4.m4.1.1.1.cmml">&gt;</mo><mn id="S3.SS2.p4.4.m4.1.1.3" xref="S3.SS2.p4.4.m4.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.4.m4.1b"><apply id="S3.SS2.p4.4.m4.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1"><gt id="S3.SS2.p4.4.m4.1.1.1.cmml" xref="S3.SS2.p4.4.m4.1.1.1"></gt><apply id="S3.SS2.p4.4.m4.1.1.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p4.4.m4.1.1.2.1.cmml" xref="S3.SS2.p4.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.p4.4.m4.1.1.2.2.cmml" xref="S3.SS2.p4.4.m4.1.1.2.2">ℐ</ci><ci id="S3.SS2.p4.4.m4.1.1.2.3.cmml" xref="S3.SS2.p4.4.m4.1.1.2.3">𝑖</ci></apply><cn id="S3.SS2.p4.4.m4.1.1.3.cmml" type="integer" xref="S3.SS2.p4.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.4.m4.1c">\mathcal{I}_{i}&gt;0</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.4.m4.1d">caligraphic_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT &gt; 0</annotation></semantics></math> we include the layer corresponding to index <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p4.5.m5.1"><semantics id="S3.SS2.p4.5.m5.1a"><mi id="S3.SS2.p4.5.m5.1.1" xref="S3.SS2.p4.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.5.m5.1b"><ci id="S3.SS2.p4.5.m5.1.1.cmml" xref="S3.SS2.p4.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.5.m5.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.5.m5.1d">italic_i</annotation></semantics></math> in the slots in the merged model, otherwise we exclude it. Consequently, our search space is reduced to <math alttext="2^{T}" class="ltx_Math" display="inline" id="S3.SS2.p4.6.m6.1"><semantics id="S3.SS2.p4.6.m6.1a"><msup id="S3.SS2.p4.6.m6.1.1" xref="S3.SS2.p4.6.m6.1.1.cmml"><mn id="S3.SS2.p4.6.m6.1.1.2" xref="S3.SS2.p4.6.m6.1.1.2.cmml">2</mn><mi id="S3.SS2.p4.6.m6.1.1.3" xref="S3.SS2.p4.6.m6.1.1.3.cmml">T</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.6.m6.1b"><apply id="S3.SS2.p4.6.m6.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.6.m6.1.1.1.cmml" xref="S3.SS2.p4.6.m6.1.1">superscript</csymbol><cn id="S3.SS2.p4.6.m6.1.1.2.cmml" type="integer" xref="S3.SS2.p4.6.m6.1.1.2">2</cn><ci id="S3.SS2.p4.6.m6.1.1.3.cmml" xref="S3.SS2.p4.6.m6.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.6.m6.1c">2^{T}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.6.m6.1d">2 start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT</annotation></semantics></math>, which is still large, but tractable for evolutionary search.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.5">In our search, we only optimize the data inference path inside the merged model and keep parameters in the models intact. In this setting, a layer may face an input whose distribution is different from what it is used to (from its original model), leading to unexpected outputs. For example, our preliminary studies show that swapping a pair of neighboring layers in a language model makes its performance drop. Although more theoretical studies are needed to model the distribution shift, empirically we find that appropriately scaling an input that wishes to go from layer <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p5.1.m1.1"><semantics id="S3.SS2.p5.1.m1.1a"><mi id="S3.SS2.p5.1.m1.1.1" xref="S3.SS2.p5.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.1.m1.1b"><ci id="S3.SS2.p5.1.m1.1.1.cmml" xref="S3.SS2.p5.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.1.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.1.m1.1d">italic_i</annotation></semantics></math> to <math alttext="j" class="ltx_Math" display="inline" id="S3.SS2.p5.2.m2.1"><semantics id="S3.SS2.p5.2.m2.1a"><mi id="S3.SS2.p5.2.m2.1.1" xref="S3.SS2.p5.2.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.2.m2.1b"><ci id="S3.SS2.p5.2.m2.1.1.cmml" xref="S3.SS2.p5.2.m2.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.2.m2.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.2.m2.1d">italic_j</annotation></semantics></math> by <math alttext="W_{ij}" class="ltx_Math" display="inline" id="S3.SS2.p5.3.m3.1"><semantics id="S3.SS2.p5.3.m3.1a"><msub id="S3.SS2.p5.3.m3.1.1" xref="S3.SS2.p5.3.m3.1.1.cmml"><mi id="S3.SS2.p5.3.m3.1.1.2" xref="S3.SS2.p5.3.m3.1.1.2.cmml">W</mi><mrow id="S3.SS2.p5.3.m3.1.1.3" xref="S3.SS2.p5.3.m3.1.1.3.cmml"><mi id="S3.SS2.p5.3.m3.1.1.3.2" xref="S3.SS2.p5.3.m3.1.1.3.2.cmml">i</mi><mo id="S3.SS2.p5.3.m3.1.1.3.1" xref="S3.SS2.p5.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p5.3.m3.1.1.3.3" xref="S3.SS2.p5.3.m3.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.3.m3.1b"><apply id="S3.SS2.p5.3.m3.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p5.3.m3.1.1.1.cmml" xref="S3.SS2.p5.3.m3.1.1">subscript</csymbol><ci id="S3.SS2.p5.3.m3.1.1.2.cmml" xref="S3.SS2.p5.3.m3.1.1.2">𝑊</ci><apply id="S3.SS2.p5.3.m3.1.1.3.cmml" xref="S3.SS2.p5.3.m3.1.1.3"><times id="S3.SS2.p5.3.m3.1.1.3.1.cmml" xref="S3.SS2.p5.3.m3.1.1.3.1"></times><ci id="S3.SS2.p5.3.m3.1.1.3.2.cmml" xref="S3.SS2.p5.3.m3.1.1.3.2">𝑖</ci><ci id="S3.SS2.p5.3.m3.1.1.3.3.cmml" xref="S3.SS2.p5.3.m3.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.3.m3.1c">W_{ij}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.3.m3.1d">italic_W start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT</annotation></semantics></math> help alleviate the problem. Here, <math alttext="W\in\mathcal{R}^{M\times M}" class="ltx_Math" display="inline" id="S3.SS2.p5.4.m4.1"><semantics id="S3.SS2.p5.4.m4.1a"><mrow id="S3.SS2.p5.4.m4.1.1" xref="S3.SS2.p5.4.m4.1.1.cmml"><mi id="S3.SS2.p5.4.m4.1.1.2" xref="S3.SS2.p5.4.m4.1.1.2.cmml">W</mi><mo id="S3.SS2.p5.4.m4.1.1.1" xref="S3.SS2.p5.4.m4.1.1.1.cmml">∈</mo><msup id="S3.SS2.p5.4.m4.1.1.3" xref="S3.SS2.p5.4.m4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p5.4.m4.1.1.3.2" xref="S3.SS2.p5.4.m4.1.1.3.2.cmml">ℛ</mi><mrow id="S3.SS2.p5.4.m4.1.1.3.3" xref="S3.SS2.p5.4.m4.1.1.3.3.cmml"><mi id="S3.SS2.p5.4.m4.1.1.3.3.2" xref="S3.SS2.p5.4.m4.1.1.3.3.2.cmml">M</mi><mo id="S3.SS2.p5.4.m4.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.p5.4.m4.1.1.3.3.1.cmml">×</mo><mi id="S3.SS2.p5.4.m4.1.1.3.3.3" xref="S3.SS2.p5.4.m4.1.1.3.3.3.cmml">M</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.4.m4.1b"><apply id="S3.SS2.p5.4.m4.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1"><in id="S3.SS2.p5.4.m4.1.1.1.cmml" xref="S3.SS2.p5.4.m4.1.1.1"></in><ci id="S3.SS2.p5.4.m4.1.1.2.cmml" xref="S3.SS2.p5.4.m4.1.1.2">𝑊</ci><apply id="S3.SS2.p5.4.m4.1.1.3.cmml" xref="S3.SS2.p5.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.p5.4.m4.1.1.3.1.cmml" xref="S3.SS2.p5.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS2.p5.4.m4.1.1.3.2.cmml" xref="S3.SS2.p5.4.m4.1.1.3.2">ℛ</ci><apply id="S3.SS2.p5.4.m4.1.1.3.3.cmml" xref="S3.SS2.p5.4.m4.1.1.3.3"><times id="S3.SS2.p5.4.m4.1.1.3.3.1.cmml" xref="S3.SS2.p5.4.m4.1.1.3.3.1"></times><ci id="S3.SS2.p5.4.m4.1.1.3.3.2.cmml" xref="S3.SS2.p5.4.m4.1.1.3.3.2">𝑀</ci><ci id="S3.SS2.p5.4.m4.1.1.3.3.3.cmml" xref="S3.SS2.p5.4.m4.1.1.3.3.3">𝑀</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.4.m4.1c">W\in\mathcal{R}^{M\times M}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.4.m4.1d">italic_W ∈ caligraphic_R start_POSTSUPERSCRIPT italic_M × italic_M end_POSTSUPERSCRIPT</annotation></semantics></math> is a matrix that is also optimized by the evolutionary search together with the indicator array <math alttext="\mathcal{I}" class="ltx_Math" display="inline" id="S3.SS2.p5.5.m5.1"><semantics id="S3.SS2.p5.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p5.5.m5.1.1" xref="S3.SS2.p5.5.m5.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p5.5.m5.1b"><ci id="S3.SS2.p5.5.m5.1.1.cmml" xref="S3.SS2.p5.5.m5.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p5.5.m5.1c">\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p5.5.m5.1d">caligraphic_I</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.6">The size of <math alttext="W" class="ltx_Math" display="inline" id="S3.SS2.p6.1.m1.1"><semantics id="S3.SS2.p6.1.m1.1a"><mi id="S3.SS2.p6.1.m1.1.1" xref="S3.SS2.p6.1.m1.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.1.m1.1b"><ci id="S3.SS2.p6.1.m1.1.1.cmml" xref="S3.SS2.p6.1.m1.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.1.m1.1c">W</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.1.m1.1d">italic_W</annotation></semantics></math> grows quadratically with <math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.p6.2.m2.1"><semantics id="S3.SS2.p6.2.m2.1a"><mi id="S3.SS2.p6.2.m2.1.1" xref="S3.SS2.p6.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.2.m2.1b"><ci id="S3.SS2.p6.2.m2.1.1.cmml" xref="S3.SS2.p6.2.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.2.m2.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.2.m2.1d">italic_M</annotation></semantics></math>, for scenarios involving a large number of layers. An alternative approach to contain the search space size involves parameterizing <math alttext="W" class="ltx_Math" display="inline" id="S3.SS2.p6.3.m3.1"><semantics id="S3.SS2.p6.3.m3.1a"><mi id="S3.SS2.p6.3.m3.1.1" xref="S3.SS2.p6.3.m3.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.3.m3.1b"><ci id="S3.SS2.p6.3.m3.1.1.cmml" xref="S3.SS2.p6.3.m3.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.3.m3.1c">W</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.3.m3.1d">italic_W</annotation></semantics></math> with a neural network&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib41" title=""><span class="ltx_text" style="font-size:90%;">41</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib17" title=""><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite>. We can instead evolve a feed-forward network to output the scaling weights conditioned on the layer and step indices: <math alttext="W_{ij}=\pi_{\theta}(i,j,t)" class="ltx_Math" display="inline" id="S3.SS2.p6.4.m4.3"><semantics id="S3.SS2.p6.4.m4.3a"><mrow id="S3.SS2.p6.4.m4.3.4" xref="S3.SS2.p6.4.m4.3.4.cmml"><msub id="S3.SS2.p6.4.m4.3.4.2" xref="S3.SS2.p6.4.m4.3.4.2.cmml"><mi id="S3.SS2.p6.4.m4.3.4.2.2" xref="S3.SS2.p6.4.m4.3.4.2.2.cmml">W</mi><mrow id="S3.SS2.p6.4.m4.3.4.2.3" xref="S3.SS2.p6.4.m4.3.4.2.3.cmml"><mi id="S3.SS2.p6.4.m4.3.4.2.3.2" xref="S3.SS2.p6.4.m4.3.4.2.3.2.cmml">i</mi><mo id="S3.SS2.p6.4.m4.3.4.2.3.1" xref="S3.SS2.p6.4.m4.3.4.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p6.4.m4.3.4.2.3.3" xref="S3.SS2.p6.4.m4.3.4.2.3.3.cmml">j</mi></mrow></msub><mo id="S3.SS2.p6.4.m4.3.4.1" xref="S3.SS2.p6.4.m4.3.4.1.cmml">=</mo><mrow id="S3.SS2.p6.4.m4.3.4.3" xref="S3.SS2.p6.4.m4.3.4.3.cmml"><msub id="S3.SS2.p6.4.m4.3.4.3.2" xref="S3.SS2.p6.4.m4.3.4.3.2.cmml"><mi id="S3.SS2.p6.4.m4.3.4.3.2.2" xref="S3.SS2.p6.4.m4.3.4.3.2.2.cmml">π</mi><mi id="S3.SS2.p6.4.m4.3.4.3.2.3" xref="S3.SS2.p6.4.m4.3.4.3.2.3.cmml">θ</mi></msub><mo id="S3.SS2.p6.4.m4.3.4.3.1" xref="S3.SS2.p6.4.m4.3.4.3.1.cmml">⁢</mo><mrow id="S3.SS2.p6.4.m4.3.4.3.3.2" xref="S3.SS2.p6.4.m4.3.4.3.3.1.cmml"><mo id="S3.SS2.p6.4.m4.3.4.3.3.2.1" stretchy="false" xref="S3.SS2.p6.4.m4.3.4.3.3.1.cmml">(</mo><mi id="S3.SS2.p6.4.m4.1.1" xref="S3.SS2.p6.4.m4.1.1.cmml">i</mi><mo id="S3.SS2.p6.4.m4.3.4.3.3.2.2" xref="S3.SS2.p6.4.m4.3.4.3.3.1.cmml">,</mo><mi id="S3.SS2.p6.4.m4.2.2" xref="S3.SS2.p6.4.m4.2.2.cmml">j</mi><mo id="S3.SS2.p6.4.m4.3.4.3.3.2.3" xref="S3.SS2.p6.4.m4.3.4.3.3.1.cmml">,</mo><mi id="S3.SS2.p6.4.m4.3.3" xref="S3.SS2.p6.4.m4.3.3.cmml">t</mi><mo id="S3.SS2.p6.4.m4.3.4.3.3.2.4" stretchy="false" xref="S3.SS2.p6.4.m4.3.4.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.4.m4.3b"><apply id="S3.SS2.p6.4.m4.3.4.cmml" xref="S3.SS2.p6.4.m4.3.4"><eq id="S3.SS2.p6.4.m4.3.4.1.cmml" xref="S3.SS2.p6.4.m4.3.4.1"></eq><apply id="S3.SS2.p6.4.m4.3.4.2.cmml" xref="S3.SS2.p6.4.m4.3.4.2"><csymbol cd="ambiguous" id="S3.SS2.p6.4.m4.3.4.2.1.cmml" xref="S3.SS2.p6.4.m4.3.4.2">subscript</csymbol><ci id="S3.SS2.p6.4.m4.3.4.2.2.cmml" xref="S3.SS2.p6.4.m4.3.4.2.2">𝑊</ci><apply id="S3.SS2.p6.4.m4.3.4.2.3.cmml" xref="S3.SS2.p6.4.m4.3.4.2.3"><times id="S3.SS2.p6.4.m4.3.4.2.3.1.cmml" xref="S3.SS2.p6.4.m4.3.4.2.3.1"></times><ci id="S3.SS2.p6.4.m4.3.4.2.3.2.cmml" xref="S3.SS2.p6.4.m4.3.4.2.3.2">𝑖</ci><ci id="S3.SS2.p6.4.m4.3.4.2.3.3.cmml" xref="S3.SS2.p6.4.m4.3.4.2.3.3">𝑗</ci></apply></apply><apply id="S3.SS2.p6.4.m4.3.4.3.cmml" xref="S3.SS2.p6.4.m4.3.4.3"><times id="S3.SS2.p6.4.m4.3.4.3.1.cmml" xref="S3.SS2.p6.4.m4.3.4.3.1"></times><apply id="S3.SS2.p6.4.m4.3.4.3.2.cmml" xref="S3.SS2.p6.4.m4.3.4.3.2"><csymbol cd="ambiguous" id="S3.SS2.p6.4.m4.3.4.3.2.1.cmml" xref="S3.SS2.p6.4.m4.3.4.3.2">subscript</csymbol><ci id="S3.SS2.p6.4.m4.3.4.3.2.2.cmml" xref="S3.SS2.p6.4.m4.3.4.3.2.2">𝜋</ci><ci id="S3.SS2.p6.4.m4.3.4.3.2.3.cmml" xref="S3.SS2.p6.4.m4.3.4.3.2.3">𝜃</ci></apply><vector id="S3.SS2.p6.4.m4.3.4.3.3.1.cmml" xref="S3.SS2.p6.4.m4.3.4.3.3.2"><ci id="S3.SS2.p6.4.m4.1.1.cmml" xref="S3.SS2.p6.4.m4.1.1">𝑖</ci><ci id="S3.SS2.p6.4.m4.2.2.cmml" xref="S3.SS2.p6.4.m4.2.2">𝑗</ci><ci id="S3.SS2.p6.4.m4.3.3.cmml" xref="S3.SS2.p6.4.m4.3.3">𝑡</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.4.m4.3c">W_{ij}=\pi_{\theta}(i,j,t)</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.4.m4.3d">italic_W start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = italic_π start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_i , italic_j , italic_t )</annotation></semantics></math> where <math alttext="\theta" class="ltx_Math" display="inline" id="S3.SS2.p6.5.m5.1"><semantics id="S3.SS2.p6.5.m5.1a"><mi id="S3.SS2.p6.5.m5.1.1" xref="S3.SS2.p6.5.m5.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.5.m5.1b"><ci id="S3.SS2.p6.5.m5.1.1.cmml" xref="S3.SS2.p6.5.m5.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.5.m5.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.5.m5.1d">italic_θ</annotation></semantics></math>’s are the parameters to be evolved, whose size does not change when <math alttext="M" class="ltx_Math" display="inline" id="S3.SS2.p6.6.m6.1"><semantics id="S3.SS2.p6.6.m6.1a"><mi id="S3.SS2.p6.6.m6.1.1" xref="S3.SS2.p6.6.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p6.6.m6.1b"><ci id="S3.SS2.p6.6.m6.1.1.cmml" xref="S3.SS2.p6.6.m6.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p6.6.m6.1c">M</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p6.6.m6.1d">italic_M</annotation></semantics></math> grows.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Merging in Both Spaces</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Model merging in the PS and in the DFS are orthogonal approaches, however, it is straightforward to combine these disentangled methods and further boost the performance of a merged model. As we show in the rightmost illustration in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S3.F1" title="Figure 1 ‣ 3 Method ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">1</span></a> and in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS1" title="4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">4.1</span></a>, it is possible to first apply PS merging to a collection of models, and then put back this merged model in the collection and apply DFS merging from this enlarged collection.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">This can be extremely helpful when one considers model merging with multiple objectives, wherein PS merging can be applied first to produce several merged models each of which targets one of the muliple objectives of interest, and then DFS merging is applied with multi-objective genetic algorithms such as NSGA-II&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib11" title=""><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite> to further expand the final model’s performance in relevant metrics.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Most merged models in the community optimize for a narrow set of tasks defined in The Open LLM Leaderboard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib21" title=""><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite>. Our motivation is for evolutionary search to discover novel ways to merge different models from vastly different domains (e.g., non-English language and Math, or non-English language and Vision) which might be difficult for human experts to discover effective merging solutions themselves. Furthermore, effectively merging models from very different domains can lead to models of wider real-world applicability and enable us to develop models beyond the large population of models that are optimized for the narrow range of tasks defined by a leaderboard.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">We demonstrate our Evolutionary Model Merge approach described in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S3" title="3 Method ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">3</span></a> by evolving a Japanese LLM capable of Math reasoning, and a Japanese VLM proficient in handling culturally-specific content.
Specifically, in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS1" title="4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">4.1</span></a>, we apply evolution to merge a Japanese LLM with an English Math LLM to build a Japanese Math LLM, and in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS2" title="4.2 Evolving Japanese VLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">4.2</span></a>, we apply evolution to merge a Japanese LLM with an English VLM to create a Japanese VLM.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Evolving Japanese Math LLM</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsubsection" id="S4.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Setup</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S4.SS1.SSS1.Px1">
<h5 class="ltx_title ltx_title_paragraph">Source Models</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.SSS1.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS1.Px1.p1.1">To develop a model capable of solving math problems in Japanese, we apply evolutionary model merge on a set of source models containing a Japanese LLM and Math LLMs: <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS1.Px1.p1.1.1">shisa-gamma-7b-v1</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">4</span></a>]</cite> (Japanese LLM), <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS1.Px1.p1.1.2">WizardMath-7B-V1.1</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib34" title=""><span class="ltx_text" style="font-size:90%;">34</span></a>]</cite> and <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS1.Px1.p1.1.3">Abel-7B-002</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib7" title=""><span class="ltx_text" style="font-size:90%;">7</span></a>]</cite>. All these models are fine-tuned from <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS1.Px1.p1.1.4">Mistral-7B-v0.1</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib23" title=""><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS1.Px2">
<h5 class="ltx_title ltx_title_paragraph">Dataset</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.SSS1.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS1.Px2.p1.1">For testing, we used the MGSM dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib42" title=""><span class="ltx_text" style="font-size:90%;">42</span></a>]</cite>, a multilingual translation of a subset of the GSM8k dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib8" title=""><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite>. The Japanese test set of MGSM, consisting of 250 samples, was used for the final evaluation. We used a different dataset for evolutionary search to avoid overfitting the test set. Specifically, we translated the remaining 1069 samples (out of 1319 examples) of the GSM8k test set that were not included in the MGSM test set into Japanese.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>One may think that it is more natural to translate the GSM8k training set. However, in our preliminary efforts, this approach did not work well. Since open-source math models were trained on the GSM8k training set, we were unable to perform accurate evaluations.</span></span></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS1.Px3">
<h5 class="ltx_title ltx_title_paragraph">Evaluation</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.SSS1.Px3.p1">
<p class="ltx_p" id="S4.SS1.SSS1.Px3.p1.1">We evaluated the ability to generate Japanese answers to Japanese math problems.
Therefore, we considered an answer correct if it met the following criteria: (1) the concluding numerical value must be correct, and (2) the reasoning text should be written in Japanese.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.Px3.p2">
<p class="ltx_p" id="S4.SS1.SSS1.Px3.p2.1">We treated the last numerical value appearing in the output as the answer. We needed to adopt this heuristic because we are merging multiple models that were trained in different formats, which made it difficult to correct the output format. This method appeared to extract the answers correctly in almost all cases. Additionally, to determine the language of the output, we utilized fasttext&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib25" title=""><span class="ltx_text" style="font-size:90%;">25</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib24" title=""><span class="ltx_text" style="font-size:90%;">24</span></a>]</cite>. We used greedy sampling for generation and calculated the zero-shot pass@1 accuracy.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS1.Px4">
<h5 class="ltx_title ltx_title_paragraph">Optimization</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.SSS1.Px4.p1">
<p class="ltx_p" id="S4.SS1.SSS1.Px4.p1.2">For optimization in PS, we used the CMA-ES<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib18" title=""><span class="ltx_text" style="font-size:90%;">18</span></a>]</cite> algorithm implemented in Optuna&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib3" title=""><span class="ltx_text" style="font-size:90%;">3</span></a>]</cite> with default hyper-parameters. Specifically, we set all initial parameter values to 0.5, sigma to 1/6, and the population size to <math alttext="4+\lfloor 3\ln(n_{\text{params}})\rfloor" class="ltx_Math" display="inline" id="S4.SS1.SSS1.Px4.p1.1.m1.2"><semantics id="S4.SS1.SSS1.Px4.p1.1.m1.2a"><mrow id="S4.SS1.SSS1.Px4.p1.1.m1.2.2" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.cmml"><mn id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.3" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.3.cmml">4</mn><mo id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.2" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.2.cmml">+</mo><mrow id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.2.cmml"><mo id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.2" stretchy="false" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.2.1.cmml">⌊</mo><mrow id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.cmml"><mn id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.3" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.3.cmml">3</mn><mo id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.2" lspace="0.167em" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.2.cmml">⁢</mo><mrow id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.2.cmml"><mi id="S4.SS1.SSS1.Px4.p1.1.m1.1.1" xref="S4.SS1.SSS1.Px4.p1.1.m1.1.1.cmml">ln</mi><mo id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1a" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.2.cmml">⁡</mo><mrow id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.2.cmml"><mo id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.2" stretchy="false" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.2.cmml">(</mo><msub id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml"><mi id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.2" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml">n</mi><mtext id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.3" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.3a.cmml">params</mtext></msub><mo id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.3" stretchy="false" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.3" stretchy="false" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.2.1.cmml">⌋</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p1.1.m1.2b"><apply id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2"><plus id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.2.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.2"></plus><cn id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.3.cmml" type="integer" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.3">4</cn><apply id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.2.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1"><floor id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.2.1.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.2"></floor><apply id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1"><times id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.2.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.2"></times><cn id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.3">3</cn><apply id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.2.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1"><ln id="S4.SS1.SSS1.Px4.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.1.1"></ln><apply id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.2">𝑛</ci><ci id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.3a.cmml" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.3"><mtext id="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.3.cmml" mathsize="70%" xref="S4.SS1.SSS1.Px4.p1.1.m1.2.2.1.1.1.1.1.1.1.3">params</mtext></ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p1.1.m1.2c">4+\lfloor 3\ln(n_{\text{params}})\rfloor</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.Px4.p1.1.m1.2d">4 + ⌊ 3 roman_ln ( italic_n start_POSTSUBSCRIPT params end_POSTSUBSCRIPT ) ⌋</annotation></semantics></math>, where <math alttext="n_{\text{params}}" class="ltx_Math" display="inline" id="S4.SS1.SSS1.Px4.p1.2.m2.1"><semantics id="S4.SS1.SSS1.Px4.p1.2.m2.1a"><msub id="S4.SS1.SSS1.Px4.p1.2.m2.1.1" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1.cmml"><mi id="S4.SS1.SSS1.Px4.p1.2.m2.1.1.2" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1.2.cmml">n</mi><mtext id="S4.SS1.SSS1.Px4.p1.2.m2.1.1.3" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1.3a.cmml">params</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p1.2.m2.1b"><apply id="S4.SS1.SSS1.Px4.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS1.Px4.p1.2.m2.1.1.1.cmml" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.SSS1.Px4.p1.2.m2.1.1.2.cmml" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1.2">𝑛</ci><ci id="S4.SS1.SSS1.Px4.p1.2.m2.1.1.3a.cmml" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1.3"><mtext id="S4.SS1.SSS1.Px4.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S4.SS1.SSS1.Px4.p1.2.m2.1.1.3">params</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p1.2.m2.1c">n_{\text{params}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.Px4.p1.2.m2.1d">italic_n start_POSTSUBSCRIPT params end_POSTSUBSCRIPT</annotation></semantics></math> is the number of parameters to optimize.
The fitness value is defined as the accuracy for all 1069 training samples. Please note that this set is disjoint from MGSM’s test set.
The optimization was conducted for 1000 trials, and the best trial with respect to the training accuracy was chosen as the final model.
We decided to employ TIES-Merging&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite> with DARE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib51" title=""><span class="ltx_text" style="font-size:90%;">51</span></a>]</cite> through preliminary experiments, and optimized its parameters.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.SSS1.Px4.p2">
<p class="ltx_p" id="S4.SS1.SSS1.Px4.p2.10">In our DFS merging experiments, <math alttext="M=64,r=3" class="ltx_Math" display="inline" id="S4.SS1.SSS1.Px4.p2.1.m1.2"><semantics id="S4.SS1.SSS1.Px4.p2.1.m1.2a"><mrow id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.3.cmml"><mrow id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.cmml"><mi id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.2" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.2.cmml">M</mi><mo id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.1" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.3" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.3.cmml">64</mn></mrow><mo id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.3" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.3a.cmml">,</mo><mrow id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.cmml"><mi id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.2" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.2.cmml">r</mi><mo id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.1" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.1.cmml">=</mo><mn id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.3" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.3.cmml">3</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.1.m1.2b"><apply id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.3.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.3a.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1"><eq id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.1"></eq><ci id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.2">𝑀</ci><cn id="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.3.cmml" type="integer" xref="S4.SS1.SSS1.Px4.p2.1.m1.1.1.1.1.3">64</cn></apply><apply id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2"><eq id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.1.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.1"></eq><ci id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.2.cmml" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.2">𝑟</ci><cn id="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.3.cmml" type="integer" xref="S4.SS1.SSS1.Px4.p2.1.m1.2.2.2.2.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.1.m1.2c">M=64,r=3</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.Px4.p2.1.m1.2d">italic_M = 64 , italic_r = 3</annotation></semantics></math>, and consequently, <math alttext="T=M\times r=192" class="ltx_Math" display="inline" id="S4.SS1.SSS1.Px4.p2.2.m2.1"><semantics id="S4.SS1.SSS1.Px4.p2.2.m2.1a"><mrow id="S4.SS1.SSS1.Px4.p2.2.m2.1.1" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.cmml"><mi id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.2" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.2.cmml">T</mi><mo id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.3" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.3.cmml">=</mo><mrow id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.cmml"><mi id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.2" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.2.cmml">M</mi><mo id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.1" lspace="0.222em" rspace="0.222em" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.1.cmml">×</mo><mi id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.3" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.3.cmml">r</mi></mrow><mo id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.5" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.5.cmml">=</mo><mn id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.6" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.6.cmml">192</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.2.m2.1b"><apply id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1"><and id="S4.SS1.SSS1.Px4.p2.2.m2.1.1a.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1"></and><apply id="S4.SS1.SSS1.Px4.p2.2.m2.1.1b.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1"><eq id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.3.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.3"></eq><ci id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.2.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.2">𝑇</ci><apply id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4"><times id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.1.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.1"></times><ci id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.2.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.2">𝑀</ci><ci id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.3.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.3">𝑟</ci></apply></apply><apply id="S4.SS1.SSS1.Px4.p2.2.m2.1.1c.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1"><eq id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.5.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.5"></eq><share href="#S4.SS1.SSS1.Px4.p2.2.m2.1.1.4.cmml" id="S4.SS1.SSS1.Px4.p2.2.m2.1.1d.cmml" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1"></share><cn id="S4.SS1.SSS1.Px4.p2.2.m2.1.1.6.cmml" type="integer" xref="S4.SS1.SSS1.Px4.p2.2.m2.1.1.6">192</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.2.m2.1c">T=M\times r=192</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.Px4.p2.2.m2.1d">italic_T = italic_M × italic_r = 192</annotation></semantics></math>.
We kept the last 200 examples in the training data as our validation set and optimize on the rest of the data with a batch size of 200. We report the performance of the snapshot that achieved the highest accuracy in the validation set, and the test set is strictly isolated from the optimization process.
We adopted CMA-ES in EvoJAX&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib47" title=""><span class="ltx_text" style="font-size:90%;">47</span></a>]</cite>, it optimized <math alttext="\mathcal{I}" class="ltx_Math" display="inline" id="S4.SS1.SSS1.Px4.p2.3.m3.1"><semantics id="S4.SS1.SSS1.Px4.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS1.Px4.p2.3.m3.1.1" xref="S4.SS1.SSS1.Px4.p2.3.m3.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.3.m3.1b"><ci id="S4.SS1.SSS1.Px4.p2.3.m3.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.3.m3.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.3.m3.1c">\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.Px4.p2.3.m3.1d">caligraphic_I</annotation></semantics></math> and <math alttext="W" class="ltx_Math" display="inline" id="S4.SS1.SSS1.Px4.p2.4.m4.1"><semantics id="S4.SS1.SSS1.Px4.p2.4.m4.1a"><mi id="S4.SS1.SSS1.Px4.p2.4.m4.1.1" xref="S4.SS1.SSS1.Px4.p2.4.m4.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.4.m4.1b"><ci id="S4.SS1.SSS1.Px4.p2.4.m4.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.4.m4.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.4.m4.1c">W</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.Px4.p2.4.m4.1d">italic_W</annotation></semantics></math> for a total of 100 generations with a popluation size of 128, and we used the default hyper-parameters.
We limited our DFS merging to two models <math alttext="A" class="ltx_Math" display="inline" id="S4.SS1.SSS1.Px4.p2.5.m5.1"><semantics id="S4.SS1.SSS1.Px4.p2.5.m5.1a"><mi id="S4.SS1.SSS1.Px4.p2.5.m5.1.1" xref="S4.SS1.SSS1.Px4.p2.5.m5.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.5.m5.1b"><ci id="S4.SS1.SSS1.Px4.p2.5.m5.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.5.m5.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.5.m5.1c">A</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.Px4.p2.5.m5.1d">italic_A</annotation></semantics></math> and <math alttext="B" class="ltx_Math" display="inline" id="S4.SS1.SSS1.Px4.p2.6.m6.1"><semantics id="S4.SS1.SSS1.Px4.p2.6.m6.1a"><mi id="S4.SS1.SSS1.Px4.p2.6.m6.1.1" xref="S4.SS1.SSS1.Px4.p2.6.m6.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.6.m6.1b"><ci id="S4.SS1.SSS1.Px4.p2.6.m6.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.6.m6.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.6.m6.1c">B</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.Px4.p2.6.m6.1d">italic_B</annotation></semantics></math> to ensure that the final model remains modest in size and can be run on a single GPU, but in principle, the methodology can scale to merging multiple models.
During the merging, model <math alttext="A" class="ltx_Math" display="inline" id="S4.SS1.SSS1.Px4.p2.7.m7.1"><semantics id="S4.SS1.SSS1.Px4.p2.7.m7.1a"><mi id="S4.SS1.SSS1.Px4.p2.7.m7.1.1" xref="S4.SS1.SSS1.Px4.p2.7.m7.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.7.m7.1b"><ci id="S4.SS1.SSS1.Px4.p2.7.m7.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.7.m7.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.7.m7.1c">A</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.Px4.p2.7.m7.1d">italic_A</annotation></semantics></math>’s tokenizer, and input/output embeddings are utilized. Furthermore, to maintain compatibility with the embedding layers, we mandate that the initial and final transformer layers of model <math alttext="A" class="ltx_Math" display="inline" id="S4.SS1.SSS1.Px4.p2.8.m8.1"><semantics id="S4.SS1.SSS1.Px4.p2.8.m8.1a"><mi id="S4.SS1.SSS1.Px4.p2.8.m8.1.1" xref="S4.SS1.SSS1.Px4.p2.8.m8.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.8.m8.1b"><ci id="S4.SS1.SSS1.Px4.p2.8.m8.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.8.m8.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.8.m8.1c">A</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.Px4.p2.8.m8.1d">italic_A</annotation></semantics></math> define the start and the end of the inference path. We initialized the indicator array <math alttext="\mathcal{I}" class="ltx_Math" display="inline" id="S4.SS1.SSS1.Px4.p2.9.m9.1"><semantics id="S4.SS1.SSS1.Px4.p2.9.m9.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS1.Px4.p2.9.m9.1.1" xref="S4.SS1.SSS1.Px4.p2.9.m9.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.9.m9.1b"><ci id="S4.SS1.SSS1.Px4.p2.9.m9.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.9.m9.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.9.m9.1c">\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.Px4.p2.9.m9.1d">caligraphic_I</annotation></semantics></math> so that all layers in model <math alttext="A" class="ltx_Math" display="inline" id="S4.SS1.SSS1.Px4.p2.10.m10.1"><semantics id="S4.SS1.SSS1.Px4.p2.10.m10.1a"><mi id="S4.SS1.SSS1.Px4.p2.10.m10.1.1" xref="S4.SS1.SSS1.Px4.p2.10.m10.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.Px4.p2.10.m10.1b"><ci id="S4.SS1.SSS1.Px4.p2.10.m10.1.1.cmml" xref="S4.SS1.SSS1.Px4.p2.10.m10.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.Px4.p2.10.m10.1c">A</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.Px4.p2.10.m10.1d">italic_A</annotation></semantics></math> are more likely to be included as initial hops in the inference path to shorten the search time.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Results</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.SSS2.p1">
<p class="ltx_p" id="S4.SS1.SSS2.p1.1">Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.T1" title="Table 1 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">1</span></a> summarizes the performance of the LLMs on Japanese Math and overall Japanese benchmark tasks. The MGSM-JA column reports the results from the MGSM test set, employing the previously described metrics. The Japanese language model (Model 1) demonstrates limited mathematical proficiency, while the Math models (Models 2 and 3), though mathematically adept, show insufficient command of the Japanese language. Consequently, all three models score low scores on the MGSM-JA, with accuracy at or below 30.0.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p2">
<p class="ltx_p" id="S4.SS1.SSS2.p2.1">In contrast, our merged models (Models 4–6) manifest a substantial elevation in performance. Notably, the model merged in PS (Model 4) achieves an impressive score of 52.0, highlighting the remarkable potential in combining models with distinct expertises. The DFS-merged model (Model 5) also shows a performance enhancement, with an over 6 percent increase in accuracy compared to the source models. While the leap in performance is not as pronounced as with PS merging, it still proves to be a valid and orthogonal approach. Finally, our hybrid model (Model 6), which integrates both merging strategies, shows further enhancements on the task.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p3">
<p class="ltx_p" id="S4.SS1.SSS2.p3.1">Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.F2" title="Figure 2 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">2</span></a> gives an overview of the five models’ “answer sheet” on the math problems. Our merged models retain the foundational knowledge in the source models, as evidenced by the similar score patterns on problems 1–15. Moreover, they exhibit emergent capabilities, successfully tackling problems that stumped the source models (e.g., problems 20–30). Evidently, by effectively integrating a Japanese LLM and mathematical models, we have succeeded in producing models that are proficient in both Japanese language understanding and mathematical problem-solving.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span><span class="ltx_text ltx_font_bold" id="S4.T1.7.1">Performance Comparison of the LLMs.</span> Models 1–3 are source models, Models 4–6 are our optimized merge models, and Models 7–11 are provided for reference. MGSM-JA measures math ability in Japanese, and JP-LMEH evaluates general Japanese language capabilities, with a detailed breakdown provided in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.T2" title="Table 2 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">2</span></a>.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.2.2">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T1.2.2.3"><span class="ltx_text ltx_font_bold" id="S4.T1.2.2.3.1" style="font-size:90%;">Id.</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T1.2.2.4"><span class="ltx_text ltx_font_bold" id="S4.T1.2.2.4.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T1.2.2.5"><span class="ltx_text ltx_font_bold" id="S4.T1.2.2.5.1" style="font-size:90%;">Type</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T1.2.2.6"><span class="ltx_text ltx_font_bold" id="S4.T1.2.2.6.1" style="font-size:90%;">Size</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T1.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T1.1.1.1.2" style="font-size:90%;">MGSM-JA</span><span class="ltx_text" id="S4.T1.1.1.1.3" style="font-size:90%;"> </span><span class="ltx_text" id="S4.T1.1.1.1.1" style="font-size:80%;">(acc <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.1.m1.1d">↑</annotation></semantics></math>)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T1.2.2.2">
<span class="ltx_text ltx_font_bold" id="S4.T1.2.2.2.2" style="font-size:90%;">JP-LMEH</span><span class="ltx_text" id="S4.T1.2.2.2.3" style="font-size:90%;"> </span><span class="ltx_text" id="S4.T1.2.2.2.1" style="font-size:80%;">(avg <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.2.2.2.1.m1.1"><semantics id="S4.T1.2.2.2.1.m1.1a"><mo id="S4.T1.2.2.2.1.m1.1.1" stretchy="false" xref="S4.T1.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.1.m1.1b"><ci id="S4.T1.2.2.2.1.m1.1.1.cmml" xref="S4.T1.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.2.1.m1.1d">↑</annotation></semantics></math>)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.2.3.1">
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.3.1.1"><span class="ltx_text" id="S4.T1.2.3.1.1.1" style="font-size:90%;">1</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.2.3.1.2"><span class="ltx_text" id="S4.T1.2.3.1.2.1" style="font-size:90%;">Shisa Gamma 7B v1</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.2.3.1.3"><span class="ltx_text" id="S4.T1.2.3.1.3.1" style="font-size:90%;">JA general</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.3.1.4"><span class="ltx_text" id="S4.T1.2.3.1.4.1" style="font-size:90%;">7B</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.3.1.5"><span class="ltx_text" id="S4.T1.2.3.1.5.1" style="font-size:90%;">9.6</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.3.1.6"><span class="ltx_text" id="S4.T1.2.3.1.6.1" style="font-size:90%;">66.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.4.2">
<td class="ltx_td ltx_align_right" id="S4.T1.2.4.2.1"><span class="ltx_text" id="S4.T1.2.4.2.1.1" style="font-size:90%;">2</span></td>
<td class="ltx_td ltx_align_left" id="S4.T1.2.4.2.2"><span class="ltx_text" id="S4.T1.2.4.2.2.1" style="font-size:90%;">WizardMath 7B v1.1</span></td>
<td class="ltx_td ltx_align_left" id="S4.T1.2.4.2.3"><span class="ltx_text" id="S4.T1.2.4.2.3.1" style="font-size:90%;">EN math</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.4.2.4"><span class="ltx_text" id="S4.T1.2.4.2.4.1" style="font-size:90%;">7B</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.4.2.5"><span class="ltx_text" id="S4.T1.2.4.2.5.1" style="font-size:90%;">18.4</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.4.2.6"><span class="ltx_text" id="S4.T1.2.4.2.6.1" style="font-size:90%;">60.1</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.5.3">
<td class="ltx_td ltx_align_right" id="S4.T1.2.5.3.1"><span class="ltx_text" id="S4.T1.2.5.3.1.1" style="font-size:90%;">3</span></td>
<td class="ltx_td ltx_align_left" id="S4.T1.2.5.3.2"><span class="ltx_text" id="S4.T1.2.5.3.2.1" style="font-size:90%;">Abel 7B 002</span></td>
<td class="ltx_td ltx_align_left" id="S4.T1.2.5.3.3"><span class="ltx_text" id="S4.T1.2.5.3.3.1" style="font-size:90%;">EN math</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.5.3.4"><span class="ltx_text" id="S4.T1.2.5.3.4.1" style="font-size:90%;">7B</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.5.3.5"><span class="ltx_text" id="S4.T1.2.5.3.5.1" style="font-size:90%;">30.0</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.5.3.6"><span class="ltx_text" id="S4.T1.2.5.3.6.1" style="font-size:90%;">56.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.6.4">
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.6.4.1"><span class="ltx_text" id="S4.T1.2.6.4.1.1" style="font-size:90%;">4</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.2.6.4.2"><span class="ltx_text ltx_font_bold" id="S4.T1.2.6.4.2.1" style="font-size:90%;">Ours (PS)</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.2.6.4.3"><span class="ltx_text" id="S4.T1.2.6.4.3.1" style="font-size:90%;">1 + 2 + 3</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.6.4.4"><span class="ltx_text" id="S4.T1.2.6.4.4.1" style="font-size:90%;">7B</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.6.4.5"><span class="ltx_text ltx_font_bold" id="S4.T1.2.6.4.5.1" style="font-size:90%;">52.0</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.6.4.6"><span class="ltx_text ltx_font_bold" id="S4.T1.2.6.4.6.1" style="font-size:90%;">70.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.7.5">
<td class="ltx_td ltx_align_right" id="S4.T1.2.7.5.1"><span class="ltx_text" id="S4.T1.2.7.5.1.1" style="font-size:90%;">5</span></td>
<td class="ltx_td ltx_align_left" id="S4.T1.2.7.5.2"><span class="ltx_text ltx_font_bold" id="S4.T1.2.7.5.2.1" style="font-size:90%;">Ours (DFS)</span></td>
<td class="ltx_td ltx_align_left" id="S4.T1.2.7.5.3"><span class="ltx_text" id="S4.T1.2.7.5.3.1" style="font-size:90%;">3 + 1</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.7.5.4"><span class="ltx_text" id="S4.T1.2.7.5.4.1" style="font-size:90%;">10B</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.7.5.5"><span class="ltx_text ltx_font_bold" id="S4.T1.2.7.5.5.1" style="font-size:90%;">36.4</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.7.5.6"><span class="ltx_text ltx_font_bold" id="S4.T1.2.7.5.6.1" style="font-size:90%;">53.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.8.6">
<td class="ltx_td ltx_align_right" id="S4.T1.2.8.6.1"><span class="ltx_text" id="S4.T1.2.8.6.1.1" style="font-size:90%;">6</span></td>
<td class="ltx_td ltx_align_left" id="S4.T1.2.8.6.2"><span class="ltx_text ltx_font_bold" id="S4.T1.2.8.6.2.1" style="font-size:90%;">Ours (PS+DFS)</span></td>
<td class="ltx_td ltx_align_left" id="S4.T1.2.8.6.3"><span class="ltx_text" id="S4.T1.2.8.6.3.1" style="font-size:90%;">4 + 1</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.8.6.4"><span class="ltx_text" id="S4.T1.2.8.6.4.1" style="font-size:90%;">10B</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.8.6.5"><span class="ltx_text ltx_font_bold" id="S4.T1.2.8.6.5.1" style="font-size:90%;">55.2</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.8.6.6"><span class="ltx_text ltx_font_bold" id="S4.T1.2.8.6.6.1" style="font-size:90%;">66.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.9.7">
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.9.7.1"><span class="ltx_text" id="S4.T1.2.9.7.1.1" style="font-size:90%;">7</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.2.9.7.2"><span class="ltx_text" id="S4.T1.2.9.7.2.1" style="font-size:90%;">Llama 2 70B</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T1.2.9.7.3"><span class="ltx_text" id="S4.T1.2.9.7.3.1" style="font-size:90%;">EN general</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.9.7.4"><span class="ltx_text" id="S4.T1.2.9.7.4.1" style="font-size:90%;">70B</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.9.7.5"><span class="ltx_text" id="S4.T1.2.9.7.5.1" style="font-size:90%;">18.0</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T1.2.9.7.6"><span class="ltx_text" id="S4.T1.2.9.7.6.1" style="font-size:90%;">64.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.10.8">
<td class="ltx_td ltx_align_right" id="S4.T1.2.10.8.1"><span class="ltx_text" id="S4.T1.2.10.8.1.1" style="font-size:90%;">8</span></td>
<td class="ltx_td ltx_align_left" id="S4.T1.2.10.8.2"><span class="ltx_text" id="S4.T1.2.10.8.2.1" style="font-size:90%;">Japanese StableLM 70B</span></td>
<td class="ltx_td ltx_align_left" id="S4.T1.2.10.8.3"><span class="ltx_text" id="S4.T1.2.10.8.3.1" style="font-size:90%;">JA general</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.10.8.4"><span class="ltx_text" id="S4.T1.2.10.8.4.1" style="font-size:90%;">70B</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.10.8.5"><span class="ltx_text" id="S4.T1.2.10.8.5.1" style="font-size:90%;">17.2</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.10.8.6"><span class="ltx_text" id="S4.T1.2.10.8.6.1" style="font-size:90%;">68.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.11.9">
<td class="ltx_td ltx_align_right" id="S4.T1.2.11.9.1"><span class="ltx_text" id="S4.T1.2.11.9.1.1" style="font-size:90%;">9</span></td>
<td class="ltx_td ltx_align_left" id="S4.T1.2.11.9.2"><span class="ltx_text" id="S4.T1.2.11.9.2.1" style="font-size:90%;">Swallow 70B</span></td>
<td class="ltx_td ltx_align_left" id="S4.T1.2.11.9.3"><span class="ltx_text" id="S4.T1.2.11.9.3.1" style="font-size:90%;">JA general</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.11.9.4"><span class="ltx_text" id="S4.T1.2.11.9.4.1" style="font-size:90%;">70B</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.11.9.5"><span class="ltx_text" id="S4.T1.2.11.9.5.1" style="font-size:90%;">13.6</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.11.9.6"><span class="ltx_text" id="S4.T1.2.11.9.6.1" style="font-size:90%;">71.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.12.10">
<td class="ltx_td ltx_align_right" id="S4.T1.2.12.10.1"><span class="ltx_text" id="S4.T1.2.12.10.1.1" style="font-size:90%;">10</span></td>
<td class="ltx_td ltx_align_left" id="S4.T1.2.12.10.2"><span class="ltx_text" id="S4.T1.2.12.10.2.1" style="font-size:90%;">GPT-3.5</span></td>
<td class="ltx_td ltx_align_left" id="S4.T1.2.12.10.3"><span class="ltx_text" id="S4.T1.2.12.10.3.1" style="font-size:90%;">commercial</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.12.10.4"><span class="ltx_text" id="S4.T1.2.12.10.4.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.12.10.5"><span class="ltx_text" id="S4.T1.2.12.10.5.1" style="font-size:90%;">50.4</span></td>
<td class="ltx_td ltx_align_right" id="S4.T1.2.12.10.6"><span class="ltx_text" id="S4.T1.2.12.10.6.1" style="font-size:90%;">-</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.2.13.11">
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.2.13.11.1"><span class="ltx_text" id="S4.T1.2.13.11.1.1" style="font-size:90%;">11</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.2.13.11.2"><span class="ltx_text" id="S4.T1.2.13.11.2.1" style="font-size:90%;">GPT-4</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T1.2.13.11.3"><span class="ltx_text" id="S4.T1.2.13.11.3.1" style="font-size:90%;">commercial</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.2.13.11.4"><span class="ltx_text" id="S4.T1.2.13.11.4.1" style="font-size:90%;">-</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.2.13.11.5"><span class="ltx_text" id="S4.T1.2.13.11.5.1" style="font-size:90%;">78.8</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T1.2.13.11.6"><span class="ltx_text" id="S4.T1.2.13.11.6.1" style="font-size:90%;">-</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="207" id="S4.F2.g1" src="x2.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text ltx_font_bold" id="S4.F2.2.1">Performance Overview.</span> The figure depicts the success of various models on the MGSM-JA task, with each of the 250 test problems represented along the x-axis by problem ID. Correct answers are indicated by colored markers at the corresponding positions.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.SSS2.p4">
<p class="ltx_p" id="S4.SS1.SSS2.p4.1">Furthermore, Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.T2" title="Table 2 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">2</span></a> presents the results of evaluating the general Japanese language ability using the Japanese Language Model Evaluation Harness (JP-LMEH) benchmark suite. This benchmark suite consists of nine tasks, and the average score across these tasks is widely used as an indicator of overall Japanese language proficiency. Our models achieve remarkably high scores of 70.5 and 66.2, surpassing the source models and even the previous state-of-the-art 70B parameter Japanese LLM (specifically, Japanese StableLM 70B), despite having only 7B to 10B parameters.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p5">
<p class="ltx_p" id="S4.SS1.SSS2.p5.1">Compared to the source Japanese model (Shisa Gmma 7B v1), it is interesting to note that there is not only a significant improvement in the MGSM scores but also improvements in other tasks such as JSQuAD and JAQKET. It should be noted that the MGSM scores here do not match those in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.T1" title="Table 1 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">1</span></a>, due to the differences in evaluation protocols (few-shot, prompting, etc.). Additional details are provided in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#A1" title="Appendix A Evaluation Details ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">A</span></a>, including extensive comparisons with other models in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#A1.T4" title="Table 4 ‣ Appendix A Evaluation Details ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">4</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.SSS2.p6">
<p class="ltx_p" id="S4.SS1.SSS2.p6.1">Moreover, Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#A3" title="Appendix C Case Study ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">C</span></a> showcases intriguing examples that demonstrate the utility of our models merged using evolution. The merged models correctly answered questions that require both knowledge about Japanese-culture <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS2.p6.1.1">and</span> Math ability. In contrast, even if such Japanese questions were translated into English and answered in English, English math models would likely fail to provide the correct answers as they may not be aware of Japanese culture-specific context in the questions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span><span class="ltx_text ltx_font_bold" id="S4.T2.2.1">Breakdown of JP-LMEH Scores for Japanese Language Proficiency</span>. JP-LMEH (Japanese Language Model Evaluation Harness) is a benchmark suite consisting of 9 tasks, and the average score (Avg column) is used as an indicator of overall Japanese language proficiency. Full results are in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#A1.T4" title="Table 4 ‣ Appendix A Evaluation Details ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">4</span></a></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.3.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T2.3.1.1.1" style="padding-left:2.5pt;padding-right:2.5pt;"></th>
<td class="ltx_td ltx_border_tt" id="S4.T2.3.1.1.2" style="padding-left:2.5pt;padding-right:2.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="10" id="S4.T2.3.1.1.3" style="padding-left:2.5pt;padding-right:2.5pt;">
<span class="ltx_text ltx_font_bold" id="S4.T2.3.1.1.3.1">JP Language Model Evaluation Harness</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.2.2.1" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.2.2.1.1">Model</span></th>
<td class="ltx_td ltx_align_right" id="S4.T2.3.2.2.2" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.2.2.2.1">Size</span></td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.2.2.3" style="padding-left:2.5pt;padding-right:2.5pt;">JComQA</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.2.2.4" style="padding-left:2.5pt;padding-right:2.5pt;">JNLI</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.2.2.5" style="padding-left:2.5pt;padding-right:2.5pt;">MARC</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.2.2.6" style="padding-left:2.5pt;padding-right:2.5pt;">JSQuAD</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.2.2.7" style="padding-left:2.5pt;padding-right:2.5pt;">JAQKET</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.2.2.8" style="padding-left:2.5pt;padding-right:2.5pt;">XLSum</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.2.2.9" style="padding-left:2.5pt;padding-right:2.5pt;">XWino</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.2.2.10" style="padding-left:2.5pt;padding-right:2.5pt;">MGSM</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.2.2.11" style="padding-left:2.5pt;padding-right:2.5pt;">JCoLA</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.2.2.12" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.2.2.12.1">Avg</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.3.3.1" style="padding-left:2.5pt;padding-right:2.5pt;">Shisa Gamma 7b v1</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.3.3.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.3.3.3" style="padding-left:2.5pt;padding-right:2.5pt;">91.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.3.3.4" style="padding-left:2.5pt;padding-right:2.5pt;">72.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.3.3.5" style="padding-left:2.5pt;padding-right:2.5pt;">94.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.3.3.6" style="padding-left:2.5pt;padding-right:2.5pt;">73.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.3.3.7" style="padding-left:2.5pt;padding-right:2.5pt;">68.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.3.3.8" style="padding-left:2.5pt;padding-right:2.5pt;">25.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.3.3.9" style="padding-left:2.5pt;padding-right:2.5pt;">80.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.3.3.10" style="padding-left:2.5pt;padding-right:2.5pt;">29.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.3.3.11" style="padding-left:2.5pt;padding-right:2.5pt;">58.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.3.3.12" style="padding-left:2.5pt;padding-right:2.5pt;">66.1</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.4.4.1" style="padding-left:2.5pt;padding-right:2.5pt;">WizardMath 7B V1.1</th>
<td class="ltx_td ltx_align_right" id="S4.T2.3.4.4.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.4.4.3" style="padding-left:2.5pt;padding-right:2.5pt;">74.7</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.4.4.4" style="padding-left:2.5pt;padding-right:2.5pt;">42.7</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.4.4.5" style="padding-left:2.5pt;padding-right:2.5pt;">90.4</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.4.4.6" style="padding-left:2.5pt;padding-right:2.5pt;">84.6</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.4.4.7" style="padding-left:2.5pt;padding-right:2.5pt;">68.5</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.4.4.8" style="padding-left:2.5pt;padding-right:2.5pt;">22.3</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.4.4.9" style="padding-left:2.5pt;padding-right:2.5pt;">69.8</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.4.4.10" style="padding-left:2.5pt;padding-right:2.5pt;">38.8</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.4.4.11" style="padding-left:2.5pt;padding-right:2.5pt;">48.9</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.4.4.12" style="padding-left:2.5pt;padding-right:2.5pt;">60.1</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.5.5.1" style="padding-left:2.5pt;padding-right:2.5pt;">Abel 7B 002</th>
<td class="ltx_td ltx_align_right" id="S4.T2.3.5.5.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.5.5.3" style="padding-left:2.5pt;padding-right:2.5pt;">70.3</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.5.5.4" style="padding-left:2.5pt;padding-right:2.5pt;">51.8</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.5.5.5" style="padding-left:2.5pt;padding-right:2.5pt;">62.3</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.5.5.6" style="padding-left:2.5pt;padding-right:2.5pt;">83.8</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.5.5.7" style="padding-left:2.5pt;padding-right:2.5pt;">69.0</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.5.5.8" style="padding-left:2.5pt;padding-right:2.5pt;">22.5</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.5.5.9" style="padding-left:2.5pt;padding-right:2.5pt;">68.2</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.5.5.10" style="padding-left:2.5pt;padding-right:2.5pt;">28.0</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.5.5.11" style="padding-left:2.5pt;padding-right:2.5pt;">52.7</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.5.5.12" style="padding-left:2.5pt;padding-right:2.5pt;">56.5</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.6.6.1" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.6.6.1.1">Ours (PS)</span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.6.6.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.6.6.3" style="padding-left:2.5pt;padding-right:2.5pt;">89.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.6.6.4" style="padding-left:2.5pt;padding-right:2.5pt;">65.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.6.6.5" style="padding-left:2.5pt;padding-right:2.5pt;">95.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.6.6.6" style="padding-left:2.5pt;padding-right:2.5pt;">89.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.6.6.7" style="padding-left:2.5pt;padding-right:2.5pt;">77.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.6.6.8" style="padding-left:2.5pt;padding-right:2.5pt;">25.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.6.6.9" style="padding-left:2.5pt;padding-right:2.5pt;">81.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.6.6.10" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.6.6.11" style="padding-left:2.5pt;padding-right:2.5pt;">60.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.6.6.12" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.6.6.12.1">70.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.7.7.1" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.7.7.1.1">Ours (DFS)</span></th>
<td class="ltx_td ltx_align_right" id="S4.T2.3.7.7.2" style="padding-left:2.5pt;padding-right:2.5pt;">10B</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.7.7.3" style="padding-left:2.5pt;padding-right:2.5pt;">67.7</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.7.7.4" style="padding-left:2.5pt;padding-right:2.5pt;">58.2</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.7.7.5" style="padding-left:2.5pt;padding-right:2.5pt;">53.5</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.7.7.6" style="padding-left:2.5pt;padding-right:2.5pt;">66.8</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.7.7.7" style="padding-left:2.5pt;padding-right:2.5pt;">54.3</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.7.7.8" style="padding-left:2.5pt;padding-right:2.5pt;">17.3</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.7.7.9" style="padding-left:2.5pt;padding-right:2.5pt;">65.6</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.7.7.10" style="padding-left:2.5pt;padding-right:2.5pt;">30.0</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.7.7.11" style="padding-left:2.5pt;padding-right:2.5pt;">65.6</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.7.7.12" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.7.7.12.1">53.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.8.8.1" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.8.8.1.1">Ours (PS+DFS)</span></th>
<td class="ltx_td ltx_align_right" id="S4.T2.3.8.8.2" style="padding-left:2.5pt;padding-right:2.5pt;">10B</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.8.8.3" style="padding-left:2.5pt;padding-right:2.5pt;">88.2</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.8.8.4" style="padding-left:2.5pt;padding-right:2.5pt;">50.3</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.8.8.5" style="padding-left:2.5pt;padding-right:2.5pt;">91.5</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.8.8.6" style="padding-left:2.5pt;padding-right:2.5pt;">78.6</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.8.8.7" style="padding-left:2.5pt;padding-right:2.5pt;">77.8</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.8.8.8" style="padding-left:2.5pt;padding-right:2.5pt;">23.2</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.8.8.9" style="padding-left:2.5pt;padding-right:2.5pt;">73.0</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.8.8.10" style="padding-left:2.5pt;padding-right:2.5pt;">40.0</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.8.8.11" style="padding-left:2.5pt;padding-right:2.5pt;">73.0</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.8.8.12" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="S4.T2.3.8.8.12.1">66.2</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.3.9.9.1" style="padding-left:2.5pt;padding-right:2.5pt;">Llama 2 70B</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.9.9.2" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.9.9.3" style="padding-left:2.5pt;padding-right:2.5pt;">80.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.9.9.4" style="padding-left:2.5pt;padding-right:2.5pt;">53.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.9.9.5" style="padding-left:2.5pt;padding-right:2.5pt;">94.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.9.9.6" style="padding-left:2.5pt;padding-right:2.5pt;">91.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.9.9.7" style="padding-left:2.5pt;padding-right:2.5pt;">80.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.9.9.8" style="padding-left:2.5pt;padding-right:2.5pt;">21.8</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.9.9.9" style="padding-left:2.5pt;padding-right:2.5pt;">73.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.9.9.10" style="padding-left:2.5pt;padding-right:2.5pt;">30.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.9.9.11" style="padding-left:2.5pt;padding-right:2.5pt;">54.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.3.9.9.12" style="padding-left:2.5pt;padding-right:2.5pt;">64.5</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.3.10.10.1" style="padding-left:2.5pt;padding-right:2.5pt;">Japanese Stable LM 70B</th>
<td class="ltx_td ltx_align_right" id="S4.T2.3.10.10.2" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.10.10.3" style="padding-left:2.5pt;padding-right:2.5pt;">91.2</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.10.10.4" style="padding-left:2.5pt;padding-right:2.5pt;">50.4</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.10.10.5" style="padding-left:2.5pt;padding-right:2.5pt;">92.9</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.10.10.6" style="padding-left:2.5pt;padding-right:2.5pt;">87.1</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.10.10.7" style="padding-left:2.5pt;padding-right:2.5pt;">88.4</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.10.10.8" style="padding-left:2.5pt;padding-right:2.5pt;">24.3</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.10.10.9" style="padding-left:2.5pt;padding-right:2.5pt;">82.0</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.10.10.10" style="padding-left:2.5pt;padding-right:2.5pt;">37.2</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.10.10.11" style="padding-left:2.5pt;padding-right:2.5pt;">61.7</td>
<td class="ltx_td ltx_align_right" id="S4.T2.3.10.10.12" style="padding-left:2.5pt;padding-right:2.5pt;">68.3</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T2.3.11.11.1" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow 70B</th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.3.11.11.2" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.3.11.11.3" style="padding-left:2.5pt;padding-right:2.5pt;">95.3</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.3.11.11.4" style="padding-left:2.5pt;padding-right:2.5pt;">57.2</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.3.11.11.5" style="padding-left:2.5pt;padding-right:2.5pt;">91.7</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.3.11.11.6" style="padding-left:2.5pt;padding-right:2.5pt;">94.1</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.3.11.11.7" style="padding-left:2.5pt;padding-right:2.5pt;">93.9</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.3.11.11.8" style="padding-left:2.5pt;padding-right:2.5pt;">23.1</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.3.11.11.9" style="padding-left:2.5pt;padding-right:2.5pt;">83.3</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.3.11.11.10" style="padding-left:2.5pt;padding-right:2.5pt;">45.2</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.3.11.11.11" style="padding-left:2.5pt;padding-right:2.5pt;">59.5</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.3.11.11.12" style="padding-left:2.5pt;padding-right:2.5pt;">71.5</td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsubsection" id="S4.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3 </span>Analysis</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.SSS3.p1">
<p class="ltx_p" id="S4.SS1.SSS3.p1.1">In our exploration of model merging in the parameter space, we experimented with diverse configurations, such as varying the assignment of merging parameters across different layer groups. However, due to a constrained dataset, we did not witness notable improvements in performance correlating with increase in configuration complexity. Consequently, we focused our reporting on a PS merged model (Model 4 in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.T1" title="Table 1 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">1</span></a>) that adopts the simplest setting: considering each source model as a singular layer and allocating two DARE-TIES associated parameters to each for evolutionary merging. Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.F4" title="Figure 4 ‣ 4.1.3 Analysis ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the evolved parameter configuration post PS merging.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p2">
<p class="ltx_p" id="S4.SS1.SSS3.p2.1">The CMA-ES optimization results reveals that all three models are important, as suggested by the uniformity of the optimized weighting values. The dominant density from the Japanese LLM suggests its critical contribution to solving the task. We conjecture that this may also be partially attributed to the Japanese LM’s larger amount of fine-tunings from the Mistral base model.
In line with the discussion in&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib51" title=""><span class="ltx_text" style="font-size:90%;">51</span></a>, Section&nbsp;4.6]</cite>, the sparsification of DARE tends to degrade performance when applied to such extensively fine-tuned models. Our evolutionary search has seemingly managed to address this issue by increasing the density for the Japanese LM.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p3">
<p class="ltx_p" id="S4.SS1.SSS3.p3.1">The parameter settings derived from our PS merging experiments align well with outcomes from our DFS merging efforts. By incorporating the PS-merged model into our pool of source models and applying DFS merging across all potential pairings, we observed optimal performance with the combination of the PS-merged model and the Japanese language mode (Model 6 in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.T1" title="Table 1 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">1</span></a>). This finding echoes the significant influence of the Japanese language model, as indicated by its notable presence in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.F4" title="Figure 4 ‣ 4.1.3 Analysis ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">4</span></a>, and reaffirms the substantial promise of evolutionary model merging.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.SSS3.p4">
<p class="ltx_p" id="S4.SS1.SSS3.p4.2">Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.F4" title="Figure 4 ‣ 4.1.3 Analysis ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">4</span></a> displays the evolution of the inference path, where our approach consistently recognized the value of initial steps, incorporating every layer from the first model (our PS-merged model), except for the last decoding layer and the embedding layer. As the process advanced, the method refined the selection to a smaller, more effective set of layers and strategically alternated between layers from both contributing models. Significantly, the scaling parameters <math alttext="W_{ij}" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.1.m1.1"><semantics id="S4.SS1.SSS3.p4.1.m1.1a"><msub id="S4.SS1.SSS3.p4.1.m1.1.1" xref="S4.SS1.SSS3.p4.1.m1.1.1.cmml"><mi id="S4.SS1.SSS3.p4.1.m1.1.1.2" xref="S4.SS1.SSS3.p4.1.m1.1.1.2.cmml">W</mi><mrow id="S4.SS1.SSS3.p4.1.m1.1.1.3" xref="S4.SS1.SSS3.p4.1.m1.1.1.3.cmml"><mi id="S4.SS1.SSS3.p4.1.m1.1.1.3.2" xref="S4.SS1.SSS3.p4.1.m1.1.1.3.2.cmml">i</mi><mo id="S4.SS1.SSS3.p4.1.m1.1.1.3.1" xref="S4.SS1.SSS3.p4.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS1.SSS3.p4.1.m1.1.1.3.3" xref="S4.SS1.SSS3.p4.1.m1.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.1.m1.1b"><apply id="S4.SS1.SSS3.p4.1.m1.1.1.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS3.p4.1.m1.1.1.1.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.SSS3.p4.1.m1.1.1.2.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1.2">𝑊</ci><apply id="S4.SS1.SSS3.p4.1.m1.1.1.3.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1.3"><times id="S4.SS1.SSS3.p4.1.m1.1.1.3.1.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1.3.1"></times><ci id="S4.SS1.SSS3.p4.1.m1.1.1.3.2.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1.3.2">𝑖</ci><ci id="S4.SS1.SSS3.p4.1.m1.1.1.3.3.cmml" xref="S4.SS1.SSS3.p4.1.m1.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.1.m1.1c">W_{ij}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.1.m1.1d">italic_W start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT</annotation></semantics></math> emerged as crucial elements, our ablation studies revealed that eliminating them in the evolved model (e.g., by setting <math alttext="W_{ij}=1" class="ltx_Math" display="inline" id="S4.SS1.SSS3.p4.2.m2.1"><semantics id="S4.SS1.SSS3.p4.2.m2.1a"><mrow id="S4.SS1.SSS3.p4.2.m2.1.1" xref="S4.SS1.SSS3.p4.2.m2.1.1.cmml"><msub id="S4.SS1.SSS3.p4.2.m2.1.1.2" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.cmml"><mi id="S4.SS1.SSS3.p4.2.m2.1.1.2.2" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.2.cmml">W</mi><mrow id="S4.SS1.SSS3.p4.2.m2.1.1.2.3" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3.cmml"><mi id="S4.SS1.SSS3.p4.2.m2.1.1.2.3.2" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3.2.cmml">i</mi><mo id="S4.SS1.SSS3.p4.2.m2.1.1.2.3.1" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3.1.cmml">⁢</mo><mi id="S4.SS1.SSS3.p4.2.m2.1.1.2.3.3" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3.3.cmml">j</mi></mrow></msub><mo id="S4.SS1.SSS3.p4.2.m2.1.1.1" xref="S4.SS1.SSS3.p4.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS3.p4.2.m2.1.1.3" xref="S4.SS1.SSS3.p4.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS3.p4.2.m2.1b"><apply id="S4.SS1.SSS3.p4.2.m2.1.1.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1"><eq id="S4.SS1.SSS3.p4.2.m2.1.1.1.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.1"></eq><apply id="S4.SS1.SSS3.p4.2.m2.1.1.2.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.SSS3.p4.2.m2.1.1.2.1.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.2">subscript</csymbol><ci id="S4.SS1.SSS3.p4.2.m2.1.1.2.2.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.2">𝑊</ci><apply id="S4.SS1.SSS3.p4.2.m2.1.1.2.3.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3"><times id="S4.SS1.SSS3.p4.2.m2.1.1.2.3.1.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3.1"></times><ci id="S4.SS1.SSS3.p4.2.m2.1.1.2.3.2.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3.2">𝑖</ci><ci id="S4.SS1.SSS3.p4.2.m2.1.1.2.3.3.cmml" xref="S4.SS1.SSS3.p4.2.m2.1.1.2.3.3">𝑗</ci></apply></apply><cn id="S4.SS1.SSS3.p4.2.m2.1.1.3.cmml" type="integer" xref="S4.SS1.SSS3.p4.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS3.p4.2.m2.1c">W_{ij}=1</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS3.p4.2.m2.1d">italic_W start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT = 1</annotation></semantics></math>) led to a performance decline exceeding 20 percent, highlighting their importance in the model’s efficacy.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span class="ltx_text ltx_font_bold" id="S4.F4.20.1">Evolved Configurations for PS merging.</span> Although the weights are similar across the three source models, the pronounced density from the Japanese LLM underscores its pivotal role in our merged model.</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><span class="ltx_inline-para ltx_minipage ltx_flex_size_2 ltx_align_center ltx_align_bottom" id="S4.F4.1" style="width:130.1pt;">
<span class="ltx_para" id="S4.F4.1.p1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="664" id="S4.F4.1.p1.g1" src="x3.png" width="830">
</span></span></div>
<div class="ltx_flex_cell ltx_flex_size_2"><span class="ltx_inline-para ltx_minipage ltx_flex_size_2 ltx_align_center ltx_align_bottom" id="S4.F4.2" style="width:294.9pt;">
<span class="ltx_para" id="S4.F4.2.p1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="277" id="S4.F4.2.p1.g1" src="x4.png" width="830">
</span></span></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span class="ltx_text ltx_font_bold" id="S4.F4.20.1">Evolved Configurations for PS merging.</span> Although the weights are similar across the three source models, the pronounced density from the Japanese LLM underscores its pivotal role in our merged model.</figcaption>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span class="ltx_text ltx_font_bold" id="S4.F4.12.2">Evolved Configurations for DFS Merging of models <math alttext="A" class="ltx_Math" display="inline" id="S4.F4.11.1.m1.1"><semantics id="S4.F4.11.1.m1.1a"><mi id="S4.F4.11.1.m1.1.1" xref="S4.F4.11.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.F4.11.1.m1.1b"><ci id="S4.F4.11.1.m1.1.1.cmml" xref="S4.F4.11.1.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.11.1.m1.1c">A</annotation><annotation encoding="application/x-llamapun" id="S4.F4.11.1.m1.1d">italic_A</annotation></semantics></math> and <math alttext="B" class="ltx_Math" display="inline" id="S4.F4.12.2.m2.1"><semantics id="S4.F4.12.2.m2.1a"><mi id="S4.F4.12.2.m2.1.1" xref="S4.F4.12.2.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.F4.12.2.m2.1b"><ci id="S4.F4.12.2.m2.1.1.cmml" xref="S4.F4.12.2.m2.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.12.2.m2.1c">B</annotation><annotation encoding="application/x-llamapun" id="S4.F4.12.2.m2.1d">italic_B</annotation></semantics></math>.</span> The three figures depict the evolution of the inference path on the MGSM-JA task. The y-axis represents the layer index <math alttext="l\in[1,M]" class="ltx_Math" display="inline" id="S4.F4.13.m1.2"><semantics id="S4.F4.13.m1.2a"><mrow id="S4.F4.13.m1.2.3" xref="S4.F4.13.m1.2.3.cmml"><mi id="S4.F4.13.m1.2.3.2" xref="S4.F4.13.m1.2.3.2.cmml">l</mi><mo id="S4.F4.13.m1.2.3.1" xref="S4.F4.13.m1.2.3.1.cmml">∈</mo><mrow id="S4.F4.13.m1.2.3.3.2" xref="S4.F4.13.m1.2.3.3.1.cmml"><mo id="S4.F4.13.m1.2.3.3.2.1" stretchy="false" xref="S4.F4.13.m1.2.3.3.1.cmml">[</mo><mn id="S4.F4.13.m1.1.1" xref="S4.F4.13.m1.1.1.cmml">1</mn><mo id="S4.F4.13.m1.2.3.3.2.2" xref="S4.F4.13.m1.2.3.3.1.cmml">,</mo><mi id="S4.F4.13.m1.2.2" xref="S4.F4.13.m1.2.2.cmml">M</mi><mo id="S4.F4.13.m1.2.3.3.2.3" stretchy="false" xref="S4.F4.13.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.13.m1.2b"><apply id="S4.F4.13.m1.2.3.cmml" xref="S4.F4.13.m1.2.3"><in id="S4.F4.13.m1.2.3.1.cmml" xref="S4.F4.13.m1.2.3.1"></in><ci id="S4.F4.13.m1.2.3.2.cmml" xref="S4.F4.13.m1.2.3.2">𝑙</ci><interval closure="closed" id="S4.F4.13.m1.2.3.3.1.cmml" xref="S4.F4.13.m1.2.3.3.2"><cn id="S4.F4.13.m1.1.1.cmml" type="integer" xref="S4.F4.13.m1.1.1">1</cn><ci id="S4.F4.13.m1.2.2.cmml" xref="S4.F4.13.m1.2.2">𝑀</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.13.m1.2c">l\in[1,M]</annotation><annotation encoding="application/x-llamapun" id="S4.F4.13.m1.2d">italic_l ∈ [ 1 , italic_M ]</annotation></semantics></math>, and the x-axis corresponds to the path index <math alttext="t\in[1,T]" class="ltx_Math" display="inline" id="S4.F4.14.m2.2"><semantics id="S4.F4.14.m2.2a"><mrow id="S4.F4.14.m2.2.3" xref="S4.F4.14.m2.2.3.cmml"><mi id="S4.F4.14.m2.2.3.2" xref="S4.F4.14.m2.2.3.2.cmml">t</mi><mo id="S4.F4.14.m2.2.3.1" xref="S4.F4.14.m2.2.3.1.cmml">∈</mo><mrow id="S4.F4.14.m2.2.3.3.2" xref="S4.F4.14.m2.2.3.3.1.cmml"><mo id="S4.F4.14.m2.2.3.3.2.1" stretchy="false" xref="S4.F4.14.m2.2.3.3.1.cmml">[</mo><mn id="S4.F4.14.m2.1.1" xref="S4.F4.14.m2.1.1.cmml">1</mn><mo id="S4.F4.14.m2.2.3.3.2.2" xref="S4.F4.14.m2.2.3.3.1.cmml">,</mo><mi id="S4.F4.14.m2.2.2" xref="S4.F4.14.m2.2.2.cmml">T</mi><mo id="S4.F4.14.m2.2.3.3.2.3" stretchy="false" xref="S4.F4.14.m2.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.F4.14.m2.2b"><apply id="S4.F4.14.m2.2.3.cmml" xref="S4.F4.14.m2.2.3"><in id="S4.F4.14.m2.2.3.1.cmml" xref="S4.F4.14.m2.2.3.1"></in><ci id="S4.F4.14.m2.2.3.2.cmml" xref="S4.F4.14.m2.2.3.2">𝑡</ci><interval closure="closed" id="S4.F4.14.m2.2.3.3.1.cmml" xref="S4.F4.14.m2.2.3.3.2"><cn id="S4.F4.14.m2.1.1.cmml" type="integer" xref="S4.F4.14.m2.1.1">1</cn><ci id="S4.F4.14.m2.2.2.cmml" xref="S4.F4.14.m2.2.2">𝑇</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.14.m2.2c">t\in[1,T]</annotation><annotation encoding="application/x-llamapun" id="S4.F4.14.m2.2d">italic_t ∈ [ 1 , italic_T ]</annotation></semantics></math>. Blue markers indicate path steps utilizing layers from model <math alttext="A" class="ltx_Math" display="inline" id="S4.F4.15.m3.1"><semantics id="S4.F4.15.m3.1a"><mi id="S4.F4.15.m3.1.1" xref="S4.F4.15.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.F4.15.m3.1b"><ci id="S4.F4.15.m3.1.1.cmml" xref="S4.F4.15.m3.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.15.m3.1c">A</annotation><annotation encoding="application/x-llamapun" id="S4.F4.15.m3.1d">italic_A</annotation></semantics></math>, and red markers denotes those from <math alttext="B" class="ltx_Math" display="inline" id="S4.F4.16.m4.1"><semantics id="S4.F4.16.m4.1a"><mi id="S4.F4.16.m4.1.1" xref="S4.F4.16.m4.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S4.F4.16.m4.1b"><ci id="S4.F4.16.m4.1.1.cmml" xref="S4.F4.16.m4.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.16.m4.1c">B</annotation><annotation encoding="application/x-llamapun" id="S4.F4.16.m4.1d">italic_B</annotation></semantics></math>. Marker size reflects the magnitude of the scaling factor <math alttext="W_{ij}" class="ltx_Math" display="inline" id="S4.F4.17.m5.1"><semantics id="S4.F4.17.m5.1a"><msub id="S4.F4.17.m5.1.1" xref="S4.F4.17.m5.1.1.cmml"><mi id="S4.F4.17.m5.1.1.2" xref="S4.F4.17.m5.1.1.2.cmml">W</mi><mrow id="S4.F4.17.m5.1.1.3" xref="S4.F4.17.m5.1.1.3.cmml"><mi id="S4.F4.17.m5.1.1.3.2" xref="S4.F4.17.m5.1.1.3.2.cmml">i</mi><mo id="S4.F4.17.m5.1.1.3.1" xref="S4.F4.17.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.F4.17.m5.1.1.3.3" xref="S4.F4.17.m5.1.1.3.3.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.F4.17.m5.1b"><apply id="S4.F4.17.m5.1.1.cmml" xref="S4.F4.17.m5.1.1"><csymbol cd="ambiguous" id="S4.F4.17.m5.1.1.1.cmml" xref="S4.F4.17.m5.1.1">subscript</csymbol><ci id="S4.F4.17.m5.1.1.2.cmml" xref="S4.F4.17.m5.1.1.2">𝑊</ci><apply id="S4.F4.17.m5.1.1.3.cmml" xref="S4.F4.17.m5.1.1.3"><times id="S4.F4.17.m5.1.1.3.1.cmml" xref="S4.F4.17.m5.1.1.3.1"></times><ci id="S4.F4.17.m5.1.1.3.2.cmml" xref="S4.F4.17.m5.1.1.3.2">𝑖</ci><ci id="S4.F4.17.m5.1.1.3.3.cmml" xref="S4.F4.17.m5.1.1.3.3">𝑗</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.17.m5.1c">W_{ij}</annotation><annotation encoding="application/x-llamapun" id="S4.F4.17.m5.1d">italic_W start_POSTSUBSCRIPT italic_i italic_j end_POSTSUBSCRIPT</annotation></semantics></math>. The evolutionary search result includes most layers in <math alttext="A" class="ltx_Math" display="inline" id="S4.F4.18.m6.1"><semantics id="S4.F4.18.m6.1a"><mi id="S4.F4.18.m6.1.1" xref="S4.F4.18.m6.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.F4.18.m6.1b"><ci id="S4.F4.18.m6.1.1.cmml" xref="S4.F4.18.m6.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.18.m6.1c">A</annotation><annotation encoding="application/x-llamapun" id="S4.F4.18.m6.1d">italic_A</annotation></semantics></math> at an early stage and then alternates between layers from both models. This result is from our 10B model (PS+DFS).</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Evolving Japanese VLM</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1 </span>Multi-modality Extension</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">We now extend our method to multi-modal models, and evolve a culturally-specific content aware Japanese VLM. VLMs have recently shown remarkable progress by applying the powerful instruction-following capabilities of pre-trained LLMs. The architecture of a VLM generally consists of three components: (1) A vision encoder to extract image features; (2) An LLM to generate text (for the purpose of describing an image); and (3) A projection network to map image features into the LLM’s embedding space&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib30" title=""><span class="ltx_text" style="font-size:90%;">30</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib10" title=""><span class="ltx_text" style="font-size:90%;">10</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">33</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib31" title=""><span class="ltx_text" style="font-size:90%;">31</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib6" title=""><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>. Crucially, the LLM component is initialized with powerful pre-trained LLMs for their text generation capabilities. During training, the projection network and optionally the LLM are trained on various vision-language datasets, while the vision encoder is fixed.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.2 </span>Setup</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S4.SS2.SSS2.Px1">
<h5 class="ltx_title ltx_title_paragraph">Source Models</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS2.Px1.p1">
<p class="ltx_p" id="S4.SS2.SSS2.Px1.p1.1">The LLM component inside a VLM can be regarded as a standalone LLM, with the extra capability of understanding visual <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS2.Px1.p1.1.1">soft prompts</span>.
From this perspective, by fixing the vision encoder and the projection network and only focusing on the LLM component, it is straightforward to apply the methodologies detailed in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S3" title="3 Method ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">3</span></a> to produce a new LLM with expanded capabilities.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.Px1.p2">
<p class="ltx_p" id="S4.SS2.SSS2.Px1.p2.1">In this experiment, we merge a Japanese LLM and the LLM component in a VLM in the parameter space. We select <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS2.Px1.p2.1.1">shisa-gamma-7b-v1</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib4" title=""><span class="ltx_text" style="font-size:90%;">4</span></a>]</cite> as the Japanese LLM and <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS2.Px1.p2.1.2">LLaVA-1.6-Mistral-7B</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">32</span></a>]</cite> as the VLM. Both models are fine-tunes of the <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS2.Px1.p2.1.3">Mistral-7B-v0.1</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib23" title=""><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite> base model.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS2.Px2">
<h5 class="ltx_title ltx_title_paragraph">Dataset</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS2.Px2.p1">
<p class="ltx_p" id="S4.SS2.SSS2.Px2.p1.1">To the best of our knowledge, publically accessible Japanese VLM datasets are scarce. In response, we created a new open Japanese VLM benchmark and assessed our VLM on a widely recognized Japanese VQA dataset. Our new benchmark dataset consists of:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">JA-VG-VQA-500:</span> A 500-sample test set extracted from the Japanese Visual Genome VQA dataset&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib43" title=""><span class="ltx_text" style="font-size:90%;">43</span></a>]</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">JA-VLM-Bench-In-the-Wild:</span> A Japanese version of LLaVA-Bench-In-the-Wild&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib33" title=""><span class="ltx_text" style="font-size:90%;">33</span></a>]</cite> . We compiled a rich collection of 42 images, accompanied by a total of 50 questions, featuring a variety of Japanese cultural elements and objects found in Japan. The QAs were crafted with the assistance of GPT-4V&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib2" title=""><span class="ltx_text" style="font-size:90%;">2</span></a>]</cite> and underwent a human-in-the-loop filtering process to eliminate nonsensical outcomes. Compared to the JA-VG-VQA-500 dataset, our set poses more complex challenges, demanding more nuanced and detailed responses.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.Px2.p2">
<p class="ltx_p" id="S4.SS2.SSS2.Px2.p2.1">We used another subset of the Japanese Visual Genome VQA dataset during the evolutionary search. This subset is not overlapped with examples in the JA-VG-VQA-500 dataset, to avoid leakage in the optimization process.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS2.Px3">
<h5 class="ltx_title ltx_title_paragraph">Evaluation</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS2.Px3.p1">
<p class="ltx_p" id="S4.SS2.SSS2.Px3.p1.1">We consider two baselines in our experiments: <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS2.Px3.p1.1.1">LLaVA-1.6-Mistral-7B</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib32" title=""><span class="ltx_text" style="font-size:90%;">32</span></a>]</cite>, one of our source models, and <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS2.Px3.p1.1.2">Japanese Stable VLM</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib44" title=""><span class="ltx_text" style="font-size:90%;">44</span></a>]</cite> a Japanese VLM trained from scratch on Japanese datasets.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.SSS2.Px3.p2">
<p class="ltx_p" id="S4.SS2.SSS2.Px3.p2.1">All models adopt the same generation configurations, with deterministic decoding. We compute ROUGE-L with a Japanese language detector to replace non-Japanese responses with empty texts, resulting in a score of zero for non-Japanese responses. To be consistent with our LLM experiments in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS1" title="4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">4.1</span></a>, we also employed fasttext&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib25" title=""><span class="ltx_text" style="font-size:90%;">25</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib24" title=""><span class="ltx_text" style="font-size:90%;">24</span></a>]</cite> for this language detection task. However, we made an exception for cases where the ground-truth answer itself contains non-Japanese but commonly seen words in Japanese texts (e.g., a widely recognized acronym such as “UFO”). In these instances, non-Japanese responses from models are not converted to empty texts. </p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS2.Px4">
<h5 class="ltx_title ltx_title_paragraph">Optimization</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS2.Px4.p1">
<p class="ltx_p" id="S4.SS2.SSS2.Px4.p1.1">We use the identical settings as the earlier LLM PS-merging experiment in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS1" title="4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">4.1</span></a>, and TIES-Merging with DARE for merging the source models in the parameter space.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsubsection" id="S4.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.3 </span>Results</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.SSS3.p1">
<p class="ltx_p" id="S4.SS2.SSS3.p1.1">Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.T3" title="Table 3 ‣ 4.2.3 Results ‣ 4.2 Evolving Japanese VLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">3</span></a> compares the performance of our VLM with the baselines. Please note that the Japanese Stable VLM cannot be evaluated on JA-VG-VQA-500 because it was trained on this dataset.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.SSS3.p2">
<p class="ltx_p" id="S4.SS2.SSS3.p2.1">Our VLM’s enhanced performance on the JA-VG-VQA-500 benchmark indicates its proficiency in Japanese, highlighting the successful integration of the source Japanese LLM with the LLM component of the original VLM through evolutionary merging. Furthermore, our VLM’s superior results on the JA-VLM-Bench-In-the-Wild compared to both baselines exhibits its adeptness at navigating culturally-specific content.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.SSS3.p3">
<p class="ltx_p" id="S4.SS2.SSS3.p3.1">Besides the quantitative results in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.T3" title="Table 3 ‣ 4.2.3 Results ‣ 4.2 Evolving Japanese VLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">3</span></a>, we qualitatively compare our VLM with the baseline models in Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#A3" title="Appendix C Case Study ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">C</span></a>. Our evolved model is able to handle Japanese culture-specific content remarkably well, generally producing more detailed responses with correct information.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span><span class="ltx_text ltx_font_bold" id="S4.T3.4.1">Performance Comparison of the VLMs.</span> LLaVA 1.6 Mistral 7B is the source VLM and Japanese Stable VLM is an open-sourced Japanese VLM. While JA-VG-VQA-500 measures general VQA abilities in Japanese, JA-VLM-Bench-In-the-Wild evaluates the model’s handling of complex VQA tasks within Japanese cultural contexts.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.2.3.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T3.2.3.1.1"></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T3.2.3.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.2.3.1.2.1">JA-VG-VQA-500</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T3.2.3.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.2.3.1.3.1">JA-VLM-Bench-In-the-Wild</span></th>
</tr>
<tr class="ltx_tr" id="S4.T3.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S4.T3.2.2.3"><span class="ltx_text ltx_font_bold" id="S4.T3.2.2.3.1">Model</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T3.1.1.1"><span class="ltx_text" id="S4.T3.1.1.1.1" style="font-size:90%;">(ROUGE-L <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.1.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T3.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.1.m1.1d">↑</annotation></semantics></math>)</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T3.2.2.2"><span class="ltx_text" id="S4.T3.2.2.2.1" style="font-size:90%;">(ROUGE-L <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.2.2.2.1.m1.1"><semantics id="S4.T3.2.2.2.1.m1.1a"><mo id="S4.T3.2.2.2.1.m1.1.1" stretchy="false" xref="S4.T3.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.1.m1.1b"><ci id="S4.T3.2.2.2.1.m1.1.1.cmml" xref="S4.T3.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.2.1.m1.1d">↑</annotation></semantics></math>)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.2.4.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.2.4.1.1">LLaVA 1.6 Mistral 7B</th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.2.4.1.2">14.3</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.2.4.1.3">41.1</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.5.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.2.5.2.1">Japanese Stable VLM</th>
<td class="ltx_td ltx_align_right" id="S4.T3.2.5.2.2">-</td>
<td class="ltx_td ltx_align_right" id="S4.T3.2.5.2.3">40.5</td>
</tr>
<tr class="ltx_tr" id="S4.T3.2.6.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T3.2.6.3.1"><span class="ltx_text ltx_font_bold" id="S4.T3.2.6.3.1.1">Ours</span></th>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S4.T3.2.6.3.2"><span class="ltx_text ltx_font_bold" id="S4.T3.2.6.3.2.1">19.7</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S4.T3.2.6.3.3"><span class="ltx_text ltx_font_bold" id="S4.T3.2.6.3.3.1">51.2</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion and Future Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this report, we propose a general method that uses evolutionary techniques to efficiently discover the best ways to combine different models from the vast ocean of different open-source models with diverse capabilities. By working with the vast collective intelligence of existing open models, our method is able to automatically create new foundation models with desired capabilities specified by the user. We find that our approach is able to automatically discover novel ways to merge different models from vastly different domains (e.g., non-English language and Math, or non-English language and Vision), in non-trivial ways that might be difficult for human experts to discover themselves.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">To test our approach, we apply our method to automatically create a Japanese LLM capable of Math reasoning, and a culturally-specific content aware Japanese VLM. Surprisingly, we find that both models achieve state-of-the-art results on several LLM and Vision benchmarks, while not being explicitly optimized to be good at these benchmarks, attaining the top performance on a vast array of other Japanese LLM benchmarks, even exceeding the performance of some previous SOTA 70B parameter Japanese LLMs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">With these promising initial results, we believe we are just scratching the surface of unlocking the full capabilities of evolutionary model merging, and this is the inception of a long-term development of applying evolutionary principles to foundation model development.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.1">Currently, we are already achieving promising results in applying evolutionary model merging to image diffusion models, enabling the creation of high performance cross-domain image generation models by merging existing building blocks in novel ways discovered by evolution.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p5">
<p class="ltx_p" id="S5.p5.1">The method currently requires the user to select a set of source models to use as ingredients for evolutionary search. We believe it is also possible to leverage evolution to search for candidate source models from a vast population of existing models as well. In addition to model selection, we are also exploring using evolution to produce swarms of diverse foundation models each with its own niche and behaviors. This holds the potential of enabling the emergence of a collective intelligence consisting of a swarm of models capable of self-improvement by continuously producing new complementary internal models of the world through interaction.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p6">
<p class="ltx_p" id="S5.p6.1">Related to our work is an experiment, called Automerge&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib28" title=""><span class="ltx_text" style="font-size:90%;">28</span></a>]</cite>, released at around the same time as this work. This interesting experiment works by selecting two random models from the top 20 models on the Open LLM Leaderboard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib21" title=""><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite> and randomly apply SLERP&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib48" title=""><span class="ltx_text" style="font-size:90%;">48</span></a>]</cite> or DARE-TIES&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib51" title=""><span class="ltx_text" style="font-size:90%;">51</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib50" title=""><span class="ltx_text" style="font-size:90%;">50</span></a>]</cite> to create new models. Over time, some of these models will do well, or even better on the benchmark tasks that define this leaderboard, becoming part of the leaderboard. We predict this approach will lead to combinations of the merged models that overfit to the benchmark tasks defined on the leaderboard. The author acknowledged that the idea behind this project was less about creating better models, but more about getting more metrics to help derive a more principled approach to model merging.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p7">
<p class="ltx_p" id="S5.p7.1">Our work takes an orthogonal approach of optimizing for tasks outside of the domain specified by the original leaderboard&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib21" title=""><span class="ltx_text" style="font-size:90%;">21</span></a>]</cite>, rather than being confined by it. As we have shown, surprisingly, stepping away from optimizing for a particular benchmark occasionally results in even greater generalization to numerous other benchmark tasks that we had not intended to optimize for, and such emergent generalization might be the key to unlocking the next great advancements in AI.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p8">
<p class="ltx_p" id="S5.p8.1">The ability to evolve new models with new emergent capabilities, from a large variety of existing, diverse models with various capabilities have important implications. With the rising costs and resource requirement for training foundation models, by leveraging the rich variety of foundation models in the rich open-source ecosystem, large institutions or governments may consider the cheaper evolutionary approach for developing proof-of-concept prototype models quickly, before committing substantial capital or tapping into the nation’s resources to develop entirely custom models from scratch, if that is even needed at all.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Limitations</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">We acknowledge that although our evolutionary model merging effectively integrates diverse expertise from the source models, it also inherits their limitations. For instance, we encountered instances where the merged models produced responses that lacked logical coherence. Additionally, this study does not encompass instruction fine-tuning or alignment, raising the potential for the models to yield outputs that may be factually flawed.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Author Contributions</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">Takuya Akiba initiated the “Evolutionary Optimization of Model Merging Recipes” project, wrote the project design document, and initiated the parameter space model merging experiments, laying the groundwork for the methodology. Makoto Shing expanded the parameter space model merging to encompass vision-language models and diffusion models. Yujin Tang directed the efforts in data flow space model merging by incorporating ideas and methods inspired from the neural architecture search and morphology evolution literature, establishing foundational methods in this domain and in hybrid merging strategies. Qi Sun contributed to the implementation of our parameter space model merging framework and assisted in model evaluation. David Ha provided overarching guidance for the research project, offering technical insight, advice, feedback and writing.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib1.2.2.1" style="font-size:90%;">[1]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib1.3.1" style="font-size:90%;"> </span><span class="ltx_text" id="bib.bib1.4.2" style="font-size:90%;"> </span><span class="ltx_text" id="bib.bib1.5.3" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib2.4.4.1" style="font-size:90%;">AI [2023]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.6.1" style="font-size:90%;">
Open AI. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.7.1" style="font-size:90%;">GPT-4V(ision) System Card.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib2.8.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cdn.openai.com/papers/GPTV_System_Card.pdf" style="font-size:90%;" title="">https://cdn.openai.com/papers/GPTV_System_Card.pdf</a><span class="ltx_text" id="bib.bib2.9.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib3.5.5.1" style="font-size:90%;">Akiba et&nbsp;al</span><span class="ltx_text" id="bib.bib3.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib3.7.7.3" style="font-size:90%;"> [2019]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.9.1" style="font-size:90%;">
Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. 2019.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.10.1" style="font-size:90%;">Optuna: A Next-generation Hyperparameter Optimization Framework. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib3.11.2" style="font-size:90%;">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em><span class="ltx_text" id="bib.bib3.12.3" style="font-size:90%;"> (Anchorage, AK, USA) </span><em class="ltx_emph ltx_font_italic" id="bib.bib3.13.4" style="font-size:90%;">(KDD ’19)</em><span class="ltx_text" id="bib.bib3.14.5" style="font-size:90%;">. Association for Computing Machinery, New York, NY, USA, 2623–2631.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib3.15.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3292500.3330701" style="font-size:90%;" title="">https://doi.org/10.1145/3292500.3330701</a><span class="ltx_text" id="bib.bib3.16.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib4.4.4.1" style="font-size:90%;">augmxnt [2023]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.6.1" style="font-size:90%;">
augmxnt. 2023.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.7.1" style="font-size:90%;">shisa-gamma-7b</em><span class="ltx_text" id="bib.bib4.8.2" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.9.1" style="font-size:90%;">HuggingFace.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib4.10.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hf.co/augmxnt/shisa-gamma-7b-v1" style="font-size:90%;" title="">https://hf.co/augmxnt/shisa-gamma-7b-v1</a><span class="ltx_text" id="bib.bib4.11.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib5.4.4.1" style="font-size:90%;">AUTOMATIC1111 [2022]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.6.1" style="font-size:90%;">
AUTOMATIC1111. 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib5.7.1" style="font-size:90%;">Stable Diffusion WebUI.
</span>
</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" style="font-size:90%;" title="">https://github.com/AUTOMATIC1111/stable-diffusion-webui</a><span class="ltx_text" id="bib.bib5.8.1" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib6.5.5.1" style="font-size:90%;">Bai et&nbsp;al</span><span class="ltx_text" id="bib.bib6.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib6.7.7.3" style="font-size:90%;"> [2023]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.9.1" style="font-size:90%;">
Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, and Jingren Zhou. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.10.1" style="font-size:90%;">Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib6.11.1" style="font-size:90%;">arXiv:2308.12966&nbsp;[cs.CV]
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib7.5.5.1" style="font-size:90%;">Chern et&nbsp;al</span><span class="ltx_text" id="bib.bib7.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib7.7.7.3" style="font-size:90%;"> [2023]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.9.1" style="font-size:90%;">
Ethan Chern, Haoyang Zou, Xuefeng Li, Jiewen Hu, Kehua Feng, Junlong Li, and Pengfei Liu. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib7.10.1" style="font-size:90%;">Generative AI for Math: Abel.
</span>
</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/GAIR-NLP/abel" style="font-size:90%;" title="">https://github.com/GAIR-NLP/abel</a><span class="ltx_text" id="bib.bib7.11.1" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib8.5.5.1" style="font-size:90%;">Cobbe et&nbsp;al</span><span class="ltx_text" id="bib.bib8.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib8.7.7.3" style="font-size:90%;"> [2021]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.9.1" style="font-size:90%;">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.10.1" style="font-size:90%;">Training Verifiers to Solve Math Word Problems.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.11.1" style="font-size:90%;">CoRR</em><span class="ltx_text" id="bib.bib8.12.2" style="font-size:90%;"> abs/2110.14168 (2021).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib8.13.1" style="font-size:90%;">arXiv:2110.14168

</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2110.14168" style="font-size:90%;" title="">https://arxiv.org/abs/2110.14168</a><span class="ltx_text" id="bib.bib8.14.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib9.5.5.1" style="font-size:90%;">Daheim et&nbsp;al</span><span class="ltx_text" id="bib.bib9.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib9.7.7.3" style="font-size:90%;"> [2024]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.9.1" style="font-size:90%;">
Nico Daheim, Thomas Möllenhoff, Edoardo Ponti, Iryna Gurevych, and Mohammad&nbsp;Emtiyaz Khan. 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.10.1" style="font-size:90%;">Model Merging by Uncertainty-Based Gradient Matching. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib9.11.2" style="font-size:90%;">The Twelfth International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib9.12.3" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib9.13.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=D7KJmfEDQP" style="font-size:90%;" title="">https://openreview.net/forum?id=D7KJmfEDQP</a><span class="ltx_text" id="bib.bib9.14.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib10.5.5.1" style="font-size:90%;">Dai et&nbsp;al</span><span class="ltx_text" id="bib.bib10.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib10.7.7.3" style="font-size:90%;"> [2023]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.9.1" style="font-size:90%;">
Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng&nbsp;Huat Tiong, Junqi Zhao, Weisheng Wang, Boyang Li, Pascale Fung, and Steven Hoi. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.10.1" style="font-size:90%;">InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib10.11.1" style="font-size:90%;">arXiv:2305.06500&nbsp;[cs.CV]
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib11.5.5.1" style="font-size:90%;">Deb et&nbsp;al</span><span class="ltx_text" id="bib.bib11.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib11.7.7.3" style="font-size:90%;"> [2002]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.9.1" style="font-size:90%;">
Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyarivan. 2002.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib11.10.1" style="font-size:90%;">A fast and elitist multiobjective genetic algorithm: NSGA-II.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.11.1" style="font-size:90%;">IEEE transactions on evolutionary computation</em><span class="ltx_text" id="bib.bib11.12.2" style="font-size:90%;"> 6, 2 (2002), 182–197.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib12.4.4.1" style="font-size:90%;">Dziugaite and Roy [2017]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.6.1" style="font-size:90%;">
Gintare&nbsp;Karolina Dziugaite and Daniel&nbsp;M Roy. 2017.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib12.7.1" style="font-size:90%;">Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.8.1" style="font-size:90%;">arXiv preprint arXiv:1703.11008</em><span class="ltx_text" id="bib.bib12.9.2" style="font-size:90%;"> (2017).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib13.4.4.1" style="font-size:90%;">Gaier and Ha [2019]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.6.1" style="font-size:90%;">
Adam Gaier and David Ha. 2019.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib13.7.1" style="font-size:90%;">Weight agnostic neural networks.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.8.1" style="font-size:90%;">Advances in neural information processing systems</em><span class="ltx_text" id="bib.bib13.9.2" style="font-size:90%;"> 32 (2019).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib14.5.5.1" style="font-size:90%;">Gao et&nbsp;al</span><span class="ltx_text" id="bib.bib14.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib14.7.7.3" style="font-size:90%;"> [2023]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.9.1" style="font-size:90%;">
Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le&nbsp;Noac’h, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, and Andy Zou. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.10.1" style="font-size:90%;">A framework for few-shot language model evaluation.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib14.11.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.5281/zenodo.10256836" style="font-size:90%;" title="">https://doi.org/10.5281/zenodo.10256836</a><span class="ltx_text" id="bib.bib14.12.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib15.5.5.1" style="font-size:90%;">Geva et&nbsp;al</span><span class="ltx_text" id="bib.bib15.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib15.7.7.3" style="font-size:90%;"> [2022]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.9.1" style="font-size:90%;">
Mor Geva, Avi Caciularu, Kevin&nbsp;Ro Wang, and Yoav Goldberg. 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib15.10.1" style="font-size:90%;">Transformer feed-forward layers build predictions by promoting concepts in the vocabulary space.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.11.1" style="font-size:90%;">arXiv preprint arXiv:2203.14680</em><span class="ltx_text" id="bib.bib15.12.2" style="font-size:90%;"> (2022).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib16.4.4.1" style="font-size:90%;">Goddard [2024]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.6.1" style="font-size:90%;">
Charles&nbsp;O. Goddard. 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.7.1" style="font-size:90%;">mergekit.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib16.8.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/arcee-ai/mergekit" style="font-size:90%;" title="">https://github.com/arcee-ai/mergekit</a><span class="ltx_text" id="bib.bib16.9.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib17.5.5.1" style="font-size:90%;">Ha et&nbsp;al</span><span class="ltx_text" id="bib.bib17.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib17.7.7.3" style="font-size:90%;"> [2016]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.9.1" style="font-size:90%;">
David Ha, Andrew Dai, and Quoc&nbsp;V Le. 2016.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib17.10.1" style="font-size:90%;">Hypernetworks.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.11.1" style="font-size:90%;">arXiv preprint arXiv:1609.09106</em><span class="ltx_text" id="bib.bib17.12.2" style="font-size:90%;"> (2016).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib18.4.4.1" style="font-size:90%;">Hansen [2006]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.6.1" style="font-size:90%;">
Nikolaus Hansen. 2006.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib18.7.1" style="font-size:90%;">The CMA evolution strategy: a comparing review.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.8.1" style="font-size:90%;">Towards a new evolutionary computation: Advances in the estimation of distribution algorithms</em><span class="ltx_text" id="bib.bib18.9.2" style="font-size:90%;"> (2006), 75–102.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib19.4.4.1" style="font-size:90%;">Hochreiter and Schmidhuber [1994]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.6.1" style="font-size:90%;">
Sepp Hochreiter and Jürgen Schmidhuber. 1994.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib19.7.1" style="font-size:90%;">Simplifying neural nets by discovering flat minima.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.8.1" style="font-size:90%;">Advances in neural information processing systems</em><span class="ltx_text" id="bib.bib19.9.2" style="font-size:90%;"> 7 (1994).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib20.4.4.1" style="font-size:90%;">Hochreiter and Schmidhuber [1997]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.6.1" style="font-size:90%;">
Sepp Hochreiter and Jürgen Schmidhuber. 1997.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib20.7.1" style="font-size:90%;">Flat minima.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.8.1" style="font-size:90%;">Neural computation</em><span class="ltx_text" id="bib.bib20.9.2" style="font-size:90%;"> 9, 1 (1997), 1–42.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib21.4.4.1" style="font-size:90%;">HuggingFace [2023]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.6.1" style="font-size:90%;">
HuggingFace. 2023.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.7.1" style="font-size:90%;">Open LLM Leaderboard</em><span class="ltx_text" id="bib.bib21.8.2" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.9.1" style="font-size:90%;">HuggingFace.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib21.10.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" style="font-size:90%;" title="">https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</a><span class="ltx_text" id="bib.bib21.11.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib22.5.5.1" style="font-size:90%;">Ilharco et&nbsp;al</span><span class="ltx_text" id="bib.bib22.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib22.7.7.3" style="font-size:90%;"> [2022]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.9.1" style="font-size:90%;">
Gabriel Ilharco, Marco&nbsp;Tulio Ribeiro, Mitchell Wortsman, Suchin Gururangan, Ludwig Schmidt, Hannaneh Hajishirzi, and Ali Farhadi. 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib22.10.1" style="font-size:90%;">Editing models with task arithmetic.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.11.1" style="font-size:90%;">arXiv preprint arXiv:2212.04089</em><span class="ltx_text" id="bib.bib22.12.2" style="font-size:90%;"> (2022).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib23.5.5.1" style="font-size:90%;">Jiang et&nbsp;al</span><span class="ltx_text" id="bib.bib23.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib23.7.7.3" style="font-size:90%;"> [2023]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.9.1" style="font-size:90%;">
Albert&nbsp;Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio&nbsp;Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven&nbsp;Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William&nbsp;El Sayed. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.10.1" style="font-size:90%;">Mistral 7B.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib23.11.1" style="font-size:90%;">arXiv:2310.06825&nbsp;[cs.CL]
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib24.5.5.1" style="font-size:90%;">Joulin et&nbsp;al</span><span class="ltx_text" id="bib.bib24.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib24.7.7.3" style="font-size:90%;"> [2016b]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.9.1" style="font-size:90%;">
Armand Joulin, Edouard Grave, Piotr Bojanowski, Matthijs Douze, Hérve Jégou, and Tomas Mikolov. 2016b.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib24.10.1" style="font-size:90%;">FastText.zip: Compressing text classification models.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.11.1" style="font-size:90%;">arXiv preprint arXiv:1612.03651</em><span class="ltx_text" id="bib.bib24.12.2" style="font-size:90%;"> (2016).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib25.5.5.1" style="font-size:90%;">Joulin et&nbsp;al</span><span class="ltx_text" id="bib.bib25.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib25.7.7.3" style="font-size:90%;"> [2016a]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.9.1" style="font-size:90%;">
Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. 2016a.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib25.10.1" style="font-size:90%;">Bag of Tricks for Efficient Text Classification.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.11.1" style="font-size:90%;">arXiv preprint arXiv:1607.01759</em><span class="ltx_text" id="bib.bib25.12.2" style="font-size:90%;"> (2016).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib26.5.5.1" style="font-size:90%;">Kaddour et&nbsp;al</span><span class="ltx_text" id="bib.bib26.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib26.7.7.3" style="font-size:90%;"> [2022]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.9.1" style="font-size:90%;">
Jean Kaddour, Linqing Liu, Ricardo Silva, and Matt&nbsp;J Kusner. 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib26.10.1" style="font-size:90%;">When do flat minima optimizers work?
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.11.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib26.12.2" style="font-size:90%;"> 35 (2022), 16577–16595.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib27.5.5.1" style="font-size:90%;">Keskar et&nbsp;al</span><span class="ltx_text" id="bib.bib27.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib27.7.7.3" style="font-size:90%;"> [2017]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.9.1" style="font-size:90%;">
</span><span class="ltx_text" id="bib.bib27.10.2" style="font-size:90%;">Nitish&nbsp;Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak&nbsp;Peter Tang. 2017.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.11.1" style="font-size:90%;">On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib27.12.2" style="font-size:90%;">International Conference on Learning Representations</em><span class="ltx_text" id="bib.bib27.13.3" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib27.14.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=H1oyRlYgg" style="font-size:90%;" title="">https://openreview.net/forum?id=H1oyRlYgg</a><span class="ltx_text" id="bib.bib27.15.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib28.4.4.1" style="font-size:90%;">Labonne [2024a]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.6.1" style="font-size:90%;">
Maxime Labonne. 2024a.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.7.1" style="font-size:90%;">Automerger Experiment.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.8.1" style="font-size:90%;">Tweet Thread</em><span class="ltx_text" id="bib.bib28.9.2" style="font-size:90%;"> (2024).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib28.10.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://twitter.com/maximelabonne/status/1767124527551549860" style="font-size:90%;" title="">https://twitter.com/maximelabonne/status/1767124527551549860</a><span class="ltx_text" id="bib.bib28.11.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib29.4.4.1" style="font-size:90%;">Labonne [2024b]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.6.1" style="font-size:90%;">
Maxime Labonne. 2024b.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.7.1" style="font-size:90%;">Merge Large Language Models with mergekit.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.8.1" style="font-size:90%;">Hugging Face Blog</em><span class="ltx_text" id="bib.bib29.9.2" style="font-size:90%;"> (2024).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib29.10.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/blog/mlabonne/merge-models" style="font-size:90%;" title="">https://huggingface.co/blog/mlabonne/merge-models</a><span class="ltx_text" id="bib.bib29.11.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib30.5.5.1" style="font-size:90%;">Li et&nbsp;al</span><span class="ltx_text" id="bib.bib30.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib30.7.7.3" style="font-size:90%;"> [2023]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.9.1" style="font-size:90%;">
Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.10.1" style="font-size:90%;">BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib30.11.1" style="font-size:90%;">arXiv:2301.12597&nbsp;[cs.CV]
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib31.5.5.1" style="font-size:90%;">Liu et&nbsp;al</span><span class="ltx_text" id="bib.bib31.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib31.7.7.3" style="font-size:90%;"> [2023a]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.9.1" style="font-size:90%;">
Haotian Liu, Chunyuan Li, Yuheng Li, and Yong&nbsp;Jae Lee. 2023a.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.10.1" style="font-size:90%;">Improved Baselines with Visual Instruction Tuning.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib31.11.1" style="font-size:90%;">arXiv:2310.03744&nbsp;[cs.CV]
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib32.5.5.1" style="font-size:90%;">Liu et&nbsp;al</span><span class="ltx_text" id="bib.bib32.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib32.7.7.3" style="font-size:90%;"> [2024]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.9.1" style="font-size:90%;">
Haotian Liu, Chunyuan Li, Yuheng Li, Bo Li, Yuanhan Zhang, Sheng Shen, and Yong&nbsp;Jae Lee. 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.10.1" style="font-size:90%;">LLaVA-NeXT: Improved reasoning, OCR, and world knowledge.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib32.11.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://llava-vl.github.io/blog/2024-01-30-llava-next/" style="font-size:90%;" title="">https://llava-vl.github.io/blog/2024-01-30-llava-next/</a><span class="ltx_text" id="bib.bib32.12.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib33.5.5.1" style="font-size:90%;">Liu et&nbsp;al</span><span class="ltx_text" id="bib.bib33.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib33.7.7.3" style="font-size:90%;"> [2023b]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.9.1" style="font-size:90%;">
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong&nbsp;Jae Lee. 2023b.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.10.1" style="font-size:90%;">Visual Instruction Tuning.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib33.11.1" style="font-size:90%;">arXiv:2304.08485&nbsp;[cs.CV]
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib34.5.5.1" style="font-size:90%;">Luo et&nbsp;al</span><span class="ltx_text" id="bib.bib34.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib34.7.7.3" style="font-size:90%;"> [2023]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.9.1" style="font-size:90%;">
Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.10.1" style="font-size:90%;">WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.11.1" style="font-size:90%;">CoRR</em><span class="ltx_text" id="bib.bib34.12.2" style="font-size:90%;"> abs/2308.09583 (2023).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib34.13.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.48550/ARXIV.2308.09583" style="font-size:90%;" title="">https://doi.org/10.48550/ARXIV.2308.09583</a><span class="ltx_text" id="bib.bib34.14.2" style="font-size:90%;">
arXiv:2308.09583
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib35.4.4.1" style="font-size:90%;">Matena and Raffel [2022]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.6.1" style="font-size:90%;">
Michael&nbsp;S Matena and Colin&nbsp;A Raffel. 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib35.7.1" style="font-size:90%;">Merging models with fisher-weighted averaging.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.8.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib35.9.2" style="font-size:90%;"> 35 (2022), 17703–17716.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib36.5.5.1" style="font-size:90%;">Meng et&nbsp;al</span><span class="ltx_text" id="bib.bib36.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib36.7.7.3" style="font-size:90%;"> [2022]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.9.1" style="font-size:90%;">
Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib36.10.1" style="font-size:90%;">Locating and editing factual associations in GPT.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.11.1" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib36.12.2" style="font-size:90%;"> 35 (2022), 17359–17372.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib37.4.4.1" style="font-size:90%;">nostalgebraist [2021]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.6.1" style="font-size:90%;">
nostalgebraist. 2021.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.7.1" style="font-size:90%;">Interpreting GPT: The Logit Lens.
</span>
</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens" style="font-size:90%;" title="">https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens</a><span class="ltx_text" id="bib.bib37.8.1" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib37.9.1" style="font-size:90%;">Accessed: 2024-03-08.
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib38.5.5.1" style="font-size:90%;">Petzka et&nbsp;al</span><span class="ltx_text" id="bib.bib38.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib38.7.7.3" style="font-size:90%;"> [2021]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.9.1" style="font-size:90%;">
Henning Petzka, Michael Kamp, Linara Adilova, Cristian Sminchisescu, and Mario Boley. 2021.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.10.1" style="font-size:90%;">Relative Flatness and Generalization. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib38.11.2" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span class="ltx_text" id="bib.bib38.12.3" style="font-size:90%;">, A.&nbsp;Beygelzimer, Y.&nbsp;Dauphin, P.&nbsp;Liang, and J.&nbsp;Wortman Vaughan (Eds.).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib38.13.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=sygvo7ctb_" style="font-size:90%;" title="">https://openreview.net/forum?id=sygvo7ctb_</a><span class="ltx_text" id="bib.bib38.14.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib39.5.5.1" style="font-size:90%;">Real et&nbsp;al</span><span class="ltx_text" id="bib.bib39.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib39.7.7.3" style="font-size:90%;"> [2019]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.9.1" style="font-size:90%;">
Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc&nbsp;V Le. 2019.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib39.10.1" style="font-size:90%;">Regularized evolution for image classifier architecture search. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib39.11.2" style="font-size:90%;">Proceedings of the aaai conference on artificial intelligence</em><span class="ltx_text" id="bib.bib39.12.3" style="font-size:90%;">, Vol.&nbsp;33. 4780–4789.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib40.5.5.1" style="font-size:90%;">Rombach et&nbsp;al</span><span class="ltx_text" id="bib.bib40.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib40.7.7.3" style="font-size:90%;"> [2022]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.9.1" style="font-size:90%;">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer. 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib40.10.1" style="font-size:90%;">High-resolution image synthesis with latent diffusion models. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib40.11.2" style="font-size:90%;">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em><span class="ltx_text" id="bib.bib40.12.3" style="font-size:90%;">. 10684–10695.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib41.4.4.1" style="font-size:90%;">Schmidhuber [1992]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.6.1" style="font-size:90%;">
Jürgen Schmidhuber. 1992.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib41.7.1" style="font-size:90%;">Learning to control fast-weight memories: An alternative to dynamic recurrent networks.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.8.1" style="font-size:90%;">Neural Computation</em><span class="ltx_text" id="bib.bib41.9.2" style="font-size:90%;"> 4, 1 (1992), 131–139.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib42.5.5.1" style="font-size:90%;">Shi et&nbsp;al</span><span class="ltx_text" id="bib.bib42.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib42.7.7.3" style="font-size:90%;"> [2023]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.9.1" style="font-size:90%;">
Freda Shi, Mirac Suzgun, Markus Freitag, Xuezhi Wang, Suraj Srivats, Soroush Vosoughi, Hyung&nbsp;Won Chung, Yi Tay, Sebastian Ruder, Denny Zhou, Dipanjan Das, and Jason Wei. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.10.1" style="font-size:90%;">Language models are multilingual chain-of-thought reasoners. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib42.11.2" style="font-size:90%;">The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023</em><span class="ltx_text" id="bib.bib42.12.3" style="font-size:90%;">. OpenReview.net.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib42.13.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/pdf?id=fR3wGCk-IXp" style="font-size:90%;" title="">https://openreview.net/pdf?id=fR3wGCk-IXp</a><span class="ltx_text" id="bib.bib42.14.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib43.5.5.1" style="font-size:90%;">Shimizu et&nbsp;al</span><span class="ltx_text" id="bib.bib43.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib43.7.7.3" style="font-size:90%;"> [2018]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.9.1" style="font-size:90%;">
Nobuyuki Shimizu, Na Rong, and Takashi Miyazaki. 2018.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.10.1" style="font-size:90%;">Visual Question Answering Dataset for Bilingual Image Understanding: A Study of Cross-Lingual Transfer Using Attention Maps. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib43.11.2" style="font-size:90%;">Proceedings of the 27th International Conference on Computational Linguistics</em><span class="ltx_text" id="bib.bib43.12.3" style="font-size:90%;"> (Santa Fe, New Mexico, USA). Association for Computational Linguistics, 1918–1928.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib43.13.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="http://aclweb.org/anthology/C18-1163" style="font-size:90%;" title="">http://aclweb.org/anthology/C18-1163</a><span class="ltx_text" id="bib.bib43.14.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib44.4.4.1" style="font-size:90%;">Shing and Akiba [2023]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.6.1" style="font-size:90%;">
Makoto Shing and Takuya Akiba. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.7.1" style="font-size:90%;">Japanese Stable VLM.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib44.8.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/stabilityai/japanese-stable-vlm" style="font-size:90%;" title="">https://huggingface.co/stabilityai/japanese-stable-vlm</a><span class="ltx_text" id="bib.bib44.9.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib45.5.5.1" style="font-size:90%;">So et&nbsp;al</span><span class="ltx_text" id="bib.bib45.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib45.7.7.3" style="font-size:90%;"> [2019]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.9.1" style="font-size:90%;">
David So, Quoc Le, and Chen Liang. 2019.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib45.10.1" style="font-size:90%;">The evolved transformer. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib45.11.2" style="font-size:90%;">International conference on machine learning</em><span class="ltx_text" id="bib.bib45.12.3" style="font-size:90%;">. PMLR, 5877–5886.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib46.4.4.1" style="font-size:90%;">Stanley and Miikkulainen [2002]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.6.1" style="font-size:90%;">
Kenneth&nbsp;O Stanley and Risto Miikkulainen. 2002.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib46.7.1" style="font-size:90%;">Evolving neural networks through augmenting topologies.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.8.1" style="font-size:90%;">Evolutionary computation</em><span class="ltx_text" id="bib.bib46.9.2" style="font-size:90%;"> 10, 2 (2002), 99–127.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib47.5.5.1" style="font-size:90%;">Tang et&nbsp;al</span><span class="ltx_text" id="bib.bib47.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib47.7.7.3" style="font-size:90%;"> [2022]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.9.1" style="font-size:90%;">
Yujin Tang, Yingtao Tian, and David Ha. 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib47.10.1" style="font-size:90%;">EvoJAX: Hardware-Accelerated Neuroevolution.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.11.1" style="font-size:90%;">arXiv preprint arXiv:2202.05008</em><span class="ltx_text" id="bib.bib47.12.2" style="font-size:90%;"> (2022).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib48.4.4.1" style="font-size:90%;">White [2016]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.6.1" style="font-size:90%;">
Tom White. 2016.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib48.7.1" style="font-size:90%;">Sampling generative networks.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.8.1" style="font-size:90%;">arXiv preprint arXiv:1609.04468</em><span class="ltx_text" id="bib.bib48.9.2" style="font-size:90%;"> (2016).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib49.5.5.1" style="font-size:90%;">Wortsman et&nbsp;al</span><span class="ltx_text" id="bib.bib49.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib49.7.7.3" style="font-size:90%;"> [2022]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.9.1" style="font-size:90%;">
Mitchell Wortsman, Gabriel Ilharco, Samir&nbsp;Ya Gadre, Rebecca Roelofs, Raphael Gontijo-Lopes, Ari&nbsp;S Morcos, Hongseok Namkoong, Ali Farhadi, Yair Carmon, Simon Kornblith, et&nbsp;al</span><span class="ltx_text" id="bib.bib49.10.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib49.11.3" style="font-size:90%;"> 2022.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib49.12.1" style="font-size:90%;">Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib49.13.2" style="font-size:90%;">International Conference on Machine Learning</em><span class="ltx_text" id="bib.bib49.14.3" style="font-size:90%;">. PMLR, 23965–23998.
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib50.5.5.1" style="font-size:90%;">Yadav et&nbsp;al</span><span class="ltx_text" id="bib.bib50.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib50.7.7.3" style="font-size:90%;"> [2023]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.9.1" style="font-size:90%;">
Prateek Yadav, Derek Tam, Leshem Choshen, Colin&nbsp;A. Raffel, and Mohit Bansal. 2023.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.10.1" style="font-size:90%;">TIES-Merging: Resolving Interference When Merging Models. In </span><em class="ltx_emph ltx_font_italic" id="bib.bib50.11.2" style="font-size:90%;">Advances in Neural Information Processing Systems 36: Annual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023</em><span class="ltx_text" id="bib.bib50.12.3" style="font-size:90%;">, Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine (Eds.).
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib50.13.1" style="font-size:90%;">
</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="http://papers.nips.cc/paper_files/paper/2023/hash/1644c9af28ab7916874f6fd6228a9bcf-Abstract-Conference.html" style="font-size:90%;" title="">http://papers.nips.cc/paper_files/paper/2023/hash/1644c9af28ab7916874f6fd6228a9bcf-Abstract-Conference.html</a><span class="ltx_text" id="bib.bib50.14.2" style="font-size:90%;">
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib51.5.5.1" style="font-size:90%;">Yu et&nbsp;al</span><span class="ltx_text" id="bib.bib51.6.6.2" style="font-size:90%;">.</span><span class="ltx_text" id="bib.bib51.7.7.3" style="font-size:90%;"> [2024]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.9.1" style="font-size:90%;">
Le Yu, Bowen Yu, Haiyang Yu, Fei Huang, and Yongbin Li. 2024.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.10.1" style="font-size:90%;">Language Models are Super Mario: Absorbing Abilities from Homologous Models as a Free Lunch.
</span>
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib51.11.1" style="font-size:90%;">arXiv:2311.03099&nbsp;[cs.CL]
</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span class="ltx_text" id="bib.bib52.4.4.1" style="font-size:90%;">Zoph and Le [2016]</span><button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.6.1" style="font-size:90%;">
Barret Zoph and Quoc&nbsp;V Le. 2016.
</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text" id="bib.bib52.7.1" style="font-size:90%;">Neural architecture search with reinforcement learning.
</span>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.8.1" style="font-size:90%;">arXiv preprint arXiv:1611.01578</em><span class="ltx_text" id="bib.bib52.9.2" style="font-size:90%;"> (2016).
</span>
</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Evaluation Details</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">In Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.T1" title="Table 1 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">1</span></a>, GPT-3.5 is <span class="ltx_text ltx_font_typewriter" id="A1.p1.1.1">gpt-3.5-turbo-0613</span>, GPT-4 is <span class="ltx_text ltx_font_typewriter" id="A1.p1.1.2">gpt-4-0125-preview</span>, Llama 2 70B is <span class="ltx_text ltx_font_typewriter" id="A1.p1.1.3">Llama-2-70b-chat</span>, Japanese Stable LM 70B is <span class="ltx_text ltx_font_typewriter" id="A1.p1.1.4">japanese-stablelm-instruct-beta-70b</span> and Swallow 70B is <span class="ltx_text ltx_font_typewriter" id="A1.p1.1.5">Swallow-70b-instruct-hf</span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.p2">
<p class="ltx_p" id="A1.p2.1">For the evaluation using the Japanese LM Evaluation Harness, we utilized Stability AI Japan’s fork of lm-eval-harness<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable" title="">https://github.com/Stability-AI/lm-evaluation-harness/tree/jp-stable</a></span></span></span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib14" title=""><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite> and configured it according to their convention. This configuration is widely used and compatible with the results on their report<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ja.stability.ai/blog/japanese-stable-lm-beta" title="">https://ja.stability.ai/blog/japanese-stable-lm-beta</a></span></span></span> and Rinna leaderboards<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://rinnakk.github.io/research/benchmarks/lm/index.html" title="">https://rinnakk.github.io/research/benchmarks/lm/index.html</a></span></span></span>, thus allowing direct comparison of scores with a large number of Japanese LLMs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A1.p3">
<p class="ltx_p" id="A1.p3.1">Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#A1.T4" title="Table 4 ‣ Appendix A Evaluation Details ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">4</span></a> is the full version of Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.T2" title="Table 2 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">2</span></a>, allowing for comparisons between our models and a wider range of models. Some of the numbers are from the Stability AI Japan report and the Rinna leaderboard. Despite having only 7B to 10B parameters, our models achieve higher scores than all existing &lt;70B parameters models and exhibit scores on par with the SOTA 70B models.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A1.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span><span class="ltx_text ltx_font_bold" id="A1.T4.2.1">Breakdown of JP-LMEH Scores for Japanese Language Proficiency (Full Version of Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.T2" title="Table 2 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">2</span></a>)</span>. JP-LMEH (Japanese Language Model Evaluation Harness) is a benchmark suite consisting of 9 tasks, and the average score (Avg column) is used as an indicator of overall Japanese language proficiency.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T4.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T4.3.1.1">
<td class="ltx_td ltx_border_tt" id="A1.T4.3.1.1.1" style="padding-left:2.5pt;padding-right:2.5pt;"></td>
<td class="ltx_td ltx_border_tt" id="A1.T4.3.1.1.2" style="padding-left:2.5pt;padding-right:2.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="10" id="A1.T4.3.1.1.3" style="padding-left:2.5pt;padding-right:2.5pt;">
<span class="ltx_text ltx_font_bold" id="A1.T4.3.1.1.3.1">JP Language Model Evaluation Harness</span></td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.2.2">
<td class="ltx_td ltx_align_left" id="A1.T4.3.2.2.1" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.3.2.2.1.1">Model</span></td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.2.2.2" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.3.2.2.2.1">Size</span></td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.2.2.3" style="padding-left:2.5pt;padding-right:2.5pt;">JComQA</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.2.2.4" style="padding-left:2.5pt;padding-right:2.5pt;">JNLI</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.2.2.5" style="padding-left:2.5pt;padding-right:2.5pt;">MARC</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.2.2.6" style="padding-left:2.5pt;padding-right:2.5pt;">JSQuAD</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.2.2.7" style="padding-left:2.5pt;padding-right:2.5pt;">JAQKET</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.2.2.8" style="padding-left:2.5pt;padding-right:2.5pt;">XLSum</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.2.2.9" style="padding-left:2.5pt;padding-right:2.5pt;">XWino</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.2.2.10" style="padding-left:2.5pt;padding-right:2.5pt;">MGSM</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.2.2.11" style="padding-left:2.5pt;padding-right:2.5pt;">JCoLA</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.2.2.12" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.3.2.2.12.1">Avg</span></td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.3.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T4.3.3.3.1" style="padding-left:2.5pt;padding-right:2.5pt;">shisa-gamma-7b-v1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.3.3.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.3.3.3" style="padding-left:2.5pt;padding-right:2.5pt;">91.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.3.3.4" style="padding-left:2.5pt;padding-right:2.5pt;">72.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.3.3.5" style="padding-left:2.5pt;padding-right:2.5pt;">94.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.3.3.6" style="padding-left:2.5pt;padding-right:2.5pt;">73.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.3.3.7" style="padding-left:2.5pt;padding-right:2.5pt;">68.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.3.3.8" style="padding-left:2.5pt;padding-right:2.5pt;">25.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.3.3.9" style="padding-left:2.5pt;padding-right:2.5pt;">80.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.3.3.10" style="padding-left:2.5pt;padding-right:2.5pt;">29.6</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.3.3.11" style="padding-left:2.5pt;padding-right:2.5pt;">58.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.3.3.12" style="padding-left:2.5pt;padding-right:2.5pt;">66.1</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.4.4">
<td class="ltx_td ltx_align_left" id="A1.T4.3.4.4.1" style="padding-left:2.5pt;padding-right:2.5pt;">WizardMath-7B-V1.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.4.4.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.4.4.3" style="padding-left:2.5pt;padding-right:2.5pt;">74.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.4.4.4" style="padding-left:2.5pt;padding-right:2.5pt;">42.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.4.4.5" style="padding-left:2.5pt;padding-right:2.5pt;">90.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.4.4.6" style="padding-left:2.5pt;padding-right:2.5pt;">84.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.4.4.7" style="padding-left:2.5pt;padding-right:2.5pt;">68.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.4.4.8" style="padding-left:2.5pt;padding-right:2.5pt;">22.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.4.4.9" style="padding-left:2.5pt;padding-right:2.5pt;">69.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.4.4.10" style="padding-left:2.5pt;padding-right:2.5pt;">38.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.4.4.11" style="padding-left:2.5pt;padding-right:2.5pt;">48.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.4.4.12" style="padding-left:2.5pt;padding-right:2.5pt;">60.1</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.5.5">
<td class="ltx_td ltx_align_left" id="A1.T4.3.5.5.1" style="padding-left:2.5pt;padding-right:2.5pt;">Abel-7B-002</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.5.5.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.5.5.3" style="padding-left:2.5pt;padding-right:2.5pt;">70.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.5.5.4" style="padding-left:2.5pt;padding-right:2.5pt;">51.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.5.5.5" style="padding-left:2.5pt;padding-right:2.5pt;">62.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.5.5.6" style="padding-left:2.5pt;padding-right:2.5pt;">83.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.5.5.7" style="padding-left:2.5pt;padding-right:2.5pt;">69.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.5.5.8" style="padding-left:2.5pt;padding-right:2.5pt;">22.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.5.5.9" style="padding-left:2.5pt;padding-right:2.5pt;">68.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.5.5.10" style="padding-left:2.5pt;padding-right:2.5pt;">28.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.5.5.11" style="padding-left:2.5pt;padding-right:2.5pt;">52.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.5.5.12" style="padding-left:2.5pt;padding-right:2.5pt;">56.5</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.6.6">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T4.3.6.6.1" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.3.6.6.1.1">Ours (PS)</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.6.6.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.6.6.3" style="padding-left:2.5pt;padding-right:2.5pt;">89.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.6.6.4" style="padding-left:2.5pt;padding-right:2.5pt;">65.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.6.6.5" style="padding-left:2.5pt;padding-right:2.5pt;">95.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.6.6.6" style="padding-left:2.5pt;padding-right:2.5pt;">89.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.6.6.7" style="padding-left:2.5pt;padding-right:2.5pt;">77.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.6.6.8" style="padding-left:2.5pt;padding-right:2.5pt;">25.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.6.6.9" style="padding-left:2.5pt;padding-right:2.5pt;">81.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.6.6.10" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.6.6.11" style="padding-left:2.5pt;padding-right:2.5pt;">60.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.6.6.12" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.3.6.6.12.1">70.5</span></td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.7.7">
<td class="ltx_td ltx_align_left" id="A1.T4.3.7.7.1" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.3.7.7.1.1">Ours (DFS)</span></td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.7.7.2" style="padding-left:2.5pt;padding-right:2.5pt;">10B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.7.7.3" style="padding-left:2.5pt;padding-right:2.5pt;">67.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.7.7.4" style="padding-left:2.5pt;padding-right:2.5pt;">58.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.7.7.5" style="padding-left:2.5pt;padding-right:2.5pt;">53.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.7.7.6" style="padding-left:2.5pt;padding-right:2.5pt;">66.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.7.7.7" style="padding-left:2.5pt;padding-right:2.5pt;">54.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.7.7.8" style="padding-left:2.5pt;padding-right:2.5pt;">17.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.7.7.9" style="padding-left:2.5pt;padding-right:2.5pt;">65.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.7.7.10" style="padding-left:2.5pt;padding-right:2.5pt;">30.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.7.7.11" style="padding-left:2.5pt;padding-right:2.5pt;">65.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.7.7.12" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.3.7.7.12.1">53.2</span></td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.8.8">
<td class="ltx_td ltx_align_left" id="A1.T4.3.8.8.1" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.3.8.8.1.1">Ours (PS+DFS)</span></td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.8.8.2" style="padding-left:2.5pt;padding-right:2.5pt;">10B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.8.8.3" style="padding-left:2.5pt;padding-right:2.5pt;">88.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.8.8.4" style="padding-left:2.5pt;padding-right:2.5pt;">50.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.8.8.5" style="padding-left:2.5pt;padding-right:2.5pt;">91.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.8.8.6" style="padding-left:2.5pt;padding-right:2.5pt;">78.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.8.8.7" style="padding-left:2.5pt;padding-right:2.5pt;">77.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.8.8.8" style="padding-left:2.5pt;padding-right:2.5pt;">23.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.8.8.9" style="padding-left:2.5pt;padding-right:2.5pt;">73.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.8.8.10" style="padding-left:2.5pt;padding-right:2.5pt;">40.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.8.8.11" style="padding-left:2.5pt;padding-right:2.5pt;">73.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.8.8.12" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.3.8.8.12.1">66.2</span></td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.9.9">
<td class="ltx_td ltx_align_left" id="A1.T4.3.9.9.1" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.3.9.9.1.1">Ours (PS-A; see Appendix&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#A2" title="Appendix B Evolving for License Specific Open-Source Models ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">B</span></a>)</span></td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.9.9.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.9.9.3" style="padding-left:2.5pt;padding-right:2.5pt;">87.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.9.9.4" style="padding-left:2.5pt;padding-right:2.5pt;">62.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.9.9.5" style="padding-left:2.5pt;padding-right:2.5pt;">91.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.9.9.6" style="padding-left:2.5pt;padding-right:2.5pt;">90.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.9.9.7" style="padding-left:2.5pt;padding-right:2.5pt;">77.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.9.9.8" style="padding-left:2.5pt;padding-right:2.5pt;">23.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.9.9.9" style="padding-left:2.5pt;padding-right:2.5pt;">78.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.9.9.10" style="padding-left:2.5pt;padding-right:2.5pt;">46.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.9.9.11" style="padding-left:2.5pt;padding-right:2.5pt;">63.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.9.9.12" style="padding-left:2.5pt;padding-right:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.3.9.9.12.1">69.0</span></td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.10.10">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T4.3.10.10.1" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-70b-instruct-hf</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.10.10.2" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.10.10.3" style="padding-left:2.5pt;padding-right:2.5pt;">95.3</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.10.10.4" style="padding-left:2.5pt;padding-right:2.5pt;">57.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.10.10.5" style="padding-left:2.5pt;padding-right:2.5pt;">91.7</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.10.10.6" style="padding-left:2.5pt;padding-right:2.5pt;">94.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.10.10.7" style="padding-left:2.5pt;padding-right:2.5pt;">93.9</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.10.10.8" style="padding-left:2.5pt;padding-right:2.5pt;">23.1</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.10.10.9" style="padding-left:2.5pt;padding-right:2.5pt;">83.3</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.10.10.10" style="padding-left:2.5pt;padding-right:2.5pt;">45.2</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.10.10.11" style="padding-left:2.5pt;padding-right:2.5pt;">59.5</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.3.10.10.12" style="padding-left:2.5pt;padding-right:2.5pt;">71.5</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.11.11">
<td class="ltx_td ltx_align_left" id="A1.T4.3.11.11.1" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-70b-hf</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.11.11.2" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.11.11.3" style="padding-left:2.5pt;padding-right:2.5pt;">94.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.11.11.4" style="padding-left:2.5pt;padding-right:2.5pt;">55.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.11.11.5" style="padding-left:2.5pt;padding-right:2.5pt;">87.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.11.11.6" style="padding-left:2.5pt;padding-right:2.5pt;">93.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.11.11.7" style="padding-left:2.5pt;padding-right:2.5pt;">93.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.11.11.8" style="padding-left:2.5pt;padding-right:2.5pt;">23.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.11.11.9" style="padding-left:2.5pt;padding-right:2.5pt;">83.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.11.11.10" style="padding-left:2.5pt;padding-right:2.5pt;">47.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.11.11.11" style="padding-left:2.5pt;padding-right:2.5pt;">60.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.11.11.12" style="padding-left:2.5pt;padding-right:2.5pt;">71.2</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.12.12">
<td class="ltx_td ltx_align_left" id="A1.T4.3.12.12.1" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-base-beta-70b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.12.12.2" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.12.12.3" style="padding-left:2.5pt;padding-right:2.5pt;">93.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.12.12.4" style="padding-left:2.5pt;padding-right:2.5pt;">45.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.12.12.5" style="padding-left:2.5pt;padding-right:2.5pt;">91.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.12.12.6" style="padding-left:2.5pt;padding-right:2.5pt;">94.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.12.12.7" style="padding-left:2.5pt;padding-right:2.5pt;">92.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.12.12.8" style="padding-left:2.5pt;padding-right:2.5pt;">25.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.12.12.9" style="padding-left:2.5pt;padding-right:2.5pt;">83.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.12.12.10" style="padding-left:2.5pt;padding-right:2.5pt;">41.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.12.12.11" style="padding-left:2.5pt;padding-right:2.5pt;">63.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.12.12.12" style="padding-left:2.5pt;padding-right:2.5pt;">70.1</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.13.13">
<td class="ltx_td ltx_align_left" id="A1.T4.3.13.13.1" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-14b-instruction</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.13.13.2" style="padding-left:2.5pt;padding-right:2.5pt;">14B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.13.13.3" style="padding-left:2.5pt;padding-right:2.5pt;">93.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.13.13.4" style="padding-left:2.5pt;padding-right:2.5pt;">57.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.13.13.5" style="padding-left:2.5pt;padding-right:2.5pt;">90.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.13.13.6" style="padding-left:2.5pt;padding-right:2.5pt;">93.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.13.13.7" style="padding-left:2.5pt;padding-right:2.5pt;">89.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.13.13.8" style="padding-left:2.5pt;padding-right:2.5pt;">25.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.13.13.9" style="padding-left:2.5pt;padding-right:2.5pt;">77.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.13.13.10" style="padding-left:2.5pt;padding-right:2.5pt;">35.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.13.13.11" style="padding-left:2.5pt;padding-right:2.5pt;">67.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.13.13.12" style="padding-left:2.5pt;padding-right:2.5pt;">69.9</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.14.14">
<td class="ltx_td ltx_align_left" id="A1.T4.3.14.14.1" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-instruct-beta-70b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.14.14.2" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.14.14.3" style="padding-left:2.5pt;padding-right:2.5pt;">91.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.14.14.4" style="padding-left:2.5pt;padding-right:2.5pt;">50.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.14.14.5" style="padding-left:2.5pt;padding-right:2.5pt;">92.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.14.14.6" style="padding-left:2.5pt;padding-right:2.5pt;">87.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.14.14.7" style="padding-left:2.5pt;padding-right:2.5pt;">88.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.14.14.8" style="padding-left:2.5pt;padding-right:2.5pt;">24.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.14.14.9" style="padding-left:2.5pt;padding-right:2.5pt;">82.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.14.14.10" style="padding-left:2.5pt;padding-right:2.5pt;">37.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.14.14.11" style="padding-left:2.5pt;padding-right:2.5pt;">61.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.14.14.12" style="padding-left:2.5pt;padding-right:2.5pt;">68.3</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.15.15">
<td class="ltx_td ltx_align_left" id="A1.T4.3.15.15.1" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-14b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.15.15.2" style="padding-left:2.5pt;padding-right:2.5pt;">14B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.15.15.3" style="padding-left:2.5pt;padding-right:2.5pt;">93.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.15.15.4" style="padding-left:2.5pt;padding-right:2.5pt;">41.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.15.15.5" style="padding-left:2.5pt;padding-right:2.5pt;">84.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.15.15.6" style="padding-left:2.5pt;padding-right:2.5pt;">94.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.15.15.7" style="padding-left:2.5pt;padding-right:2.5pt;">90.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.15.15.8" style="padding-left:2.5pt;padding-right:2.5pt;">21.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.15.15.9" style="padding-left:2.5pt;padding-right:2.5pt;">78.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.15.15.10" style="padding-left:2.5pt;padding-right:2.5pt;">37.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.15.15.11" style="padding-left:2.5pt;padding-right:2.5pt;">65.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.15.15.12" style="padding-left:2.5pt;padding-right:2.5pt;">67.4</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.16.16">
<td class="ltx_td ltx_align_left" id="A1.T4.3.16.16.1" style="padding-left:2.5pt;padding-right:2.5pt;">youri-7b-chat</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.16.16.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.16.16.3" style="padding-left:2.5pt;padding-right:2.5pt;">91.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.16.16.4" style="padding-left:2.5pt;padding-right:2.5pt;">70.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.16.16.5" style="padding-left:2.5pt;padding-right:2.5pt;">96.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.16.16.6" style="padding-left:2.5pt;padding-right:2.5pt;">79.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.16.16.7" style="padding-left:2.5pt;padding-right:2.5pt;">83.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.16.16.8" style="padding-left:2.5pt;padding-right:2.5pt;">24.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.16.16.9" style="padding-left:2.5pt;padding-right:2.5pt;">80.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.16.16.10" style="padding-left:2.5pt;padding-right:2.5pt;">25.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.16.16.11" style="padding-left:2.5pt;padding-right:2.5pt;">53.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.16.16.12" style="padding-left:2.5pt;padding-right:2.5pt;">67.4</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.17.17">
<td class="ltx_td ltx_align_left" id="A1.T4.3.17.17.1" style="padding-left:2.5pt;padding-right:2.5pt;">Llama-2-70b-hf</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.17.17.2" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.17.17.3" style="padding-left:2.5pt;padding-right:2.5pt;">89.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.17.17.4" style="padding-left:2.5pt;padding-right:2.5pt;">53.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.17.17.5" style="padding-left:2.5pt;padding-right:2.5pt;">70.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.17.17.6" style="padding-left:2.5pt;padding-right:2.5pt;">93.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.17.17.7" style="padding-left:2.5pt;padding-right:2.5pt;">89.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.17.17.8" style="padding-left:2.5pt;padding-right:2.5pt;">23.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.17.17.9" style="padding-left:2.5pt;padding-right:2.5pt;">79.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.17.17.10" style="padding-left:2.5pt;padding-right:2.5pt;">40.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.17.17.11" style="padding-left:2.5pt;padding-right:2.5pt;">65.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.17.17.12" style="padding-left:2.5pt;padding-right:2.5pt;">67.2</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.18.18">
<td class="ltx_td ltx_align_left" id="A1.T4.3.18.18.1" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-7b-instruction</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.18.18.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.18.18.3" style="padding-left:2.5pt;padding-right:2.5pt;">88.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.18.18.4" style="padding-left:2.5pt;padding-right:2.5pt;">74.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.18.18.5" style="padding-left:2.5pt;padding-right:2.5pt;">92.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.18.18.6" style="padding-left:2.5pt;padding-right:2.5pt;">91.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.18.18.7" style="padding-left:2.5pt;padding-right:2.5pt;">82.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.18.18.8" style="padding-left:2.5pt;padding-right:2.5pt;">21.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.18.18.9" style="padding-left:2.5pt;padding-right:2.5pt;">76.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.18.18.10" style="padding-left:2.5pt;padding-right:2.5pt;">19.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.18.18.11" style="padding-left:2.5pt;padding-right:2.5pt;">53.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.18.18.12" style="padding-left:2.5pt;padding-right:2.5pt;">66.6</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.19.19">
<td class="ltx_td ltx_align_left" id="A1.T4.3.19.19.1" style="padding-left:2.5pt;padding-right:2.5pt;">youri-7b-instruction</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.19.19.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.19.19.3" style="padding-left:2.5pt;padding-right:2.5pt;">88.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.19.19.4" style="padding-left:2.5pt;padding-right:2.5pt;">63.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.19.19.5" style="padding-left:2.5pt;padding-right:2.5pt;">93.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.19.19.6" style="padding-left:2.5pt;padding-right:2.5pt;">92.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.19.19.7" style="padding-left:2.5pt;padding-right:2.5pt;">83.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.19.19.8" style="padding-left:2.5pt;padding-right:2.5pt;">24.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.19.19.9" style="padding-left:2.5pt;padding-right:2.5pt;">78.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.19.19.10" style="padding-left:2.5pt;padding-right:2.5pt;">17.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.19.19.11" style="padding-left:2.5pt;padding-right:2.5pt;">54.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.19.19.12" style="padding-left:2.5pt;padding-right:2.5pt;">66.3</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.20.20">
<td class="ltx_td ltx_align_left" id="A1.T4.3.20.20.1" style="padding-left:2.5pt;padding-right:2.5pt;">Qwen-14B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.20.20.2" style="padding-left:2.5pt;padding-right:2.5pt;">14B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.20.20.3" style="padding-left:2.5pt;padding-right:2.5pt;">89.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.20.20.4" style="padding-left:2.5pt;padding-right:2.5pt;">65.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.20.20.5" style="padding-left:2.5pt;padding-right:2.5pt;">76.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.20.20.6" style="padding-left:2.5pt;padding-right:2.5pt;">93.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.20.20.7" style="padding-left:2.5pt;padding-right:2.5pt;">79.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.20.20.8" style="padding-left:2.5pt;padding-right:2.5pt;">18.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.20.20.9" style="padding-left:2.5pt;padding-right:2.5pt;">71.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.20.20.10" style="padding-left:2.5pt;padding-right:2.5pt;">37.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.20.20.11" style="padding-left:2.5pt;padding-right:2.5pt;">61.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.20.20.12" style="padding-left:2.5pt;padding-right:2.5pt;">65.8</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.21.21">
<td class="ltx_td ltx_align_left" id="A1.T4.3.21.21.1" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-MX-8x7b-NVE-v0.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.21.21.2" style="padding-left:2.5pt;padding-right:2.5pt;">47B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.21.21.3" style="padding-left:2.5pt;padding-right:2.5pt;">92.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.21.21.4" style="padding-left:2.5pt;padding-right:2.5pt;">52.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.21.21.5" style="padding-left:2.5pt;padding-right:2.5pt;">59.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.21.21.6" style="padding-left:2.5pt;padding-right:2.5pt;">93.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.21.21.7" style="padding-left:2.5pt;padding-right:2.5pt;">91.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.21.21.8" style="padding-left:2.5pt;padding-right:2.5pt;">26.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.21.21.9" style="padding-left:2.5pt;padding-right:2.5pt;">72.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.21.21.10" style="padding-left:2.5pt;padding-right:2.5pt;">44.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.21.21.11" style="padding-left:2.5pt;padding-right:2.5pt;">59.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.21.21.12" style="padding-left:2.5pt;padding-right:2.5pt;">65.8</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.22.22">
<td class="ltx_td ltx_align_left" id="A1.T4.3.22.22.1" style="padding-left:2.5pt;padding-right:2.5pt;">youri-7b-chat-gptq</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.22.22.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.22.22.3" style="padding-left:2.5pt;padding-right:2.5pt;">89.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.22.22.4" style="padding-left:2.5pt;padding-right:2.5pt;">68.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.22.22.5" style="padding-left:2.5pt;padding-right:2.5pt;">96.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.22.22.6" style="padding-left:2.5pt;padding-right:2.5pt;">88.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.22.22.7" style="padding-left:2.5pt;padding-right:2.5pt;">79.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.22.22.8" style="padding-left:2.5pt;padding-right:2.5pt;">15.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.22.22.9" style="padding-left:2.5pt;padding-right:2.5pt;">79.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.22.22.10" style="padding-left:2.5pt;padding-right:2.5pt;">21.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.22.22.11" style="padding-left:2.5pt;padding-right:2.5pt;">53.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.22.22.12" style="padding-left:2.5pt;padding-right:2.5pt;">65.8</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.23.23">
<td class="ltx_td ltx_align_left" id="A1.T4.3.23.23.1" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-7b-instruction-gguf</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.23.23.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.23.23.3" style="padding-left:2.5pt;padding-right:2.5pt;">87.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.23.23.4" style="padding-left:2.5pt;padding-right:2.5pt;">68.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.23.23.5" style="padding-left:2.5pt;padding-right:2.5pt;">89.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.23.23.6" style="padding-left:2.5pt;padding-right:2.5pt;">89.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.23.23.7" style="padding-left:2.5pt;padding-right:2.5pt;">79.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.23.23.8" style="padding-left:2.5pt;padding-right:2.5pt;">20.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.23.23.9" style="padding-left:2.5pt;padding-right:2.5pt;">77.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.23.23.10" style="padding-left:2.5pt;padding-right:2.5pt;">19.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.23.23.11" style="padding-left:2.5pt;padding-right:2.5pt;">55.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.23.23.12" style="padding-left:2.5pt;padding-right:2.5pt;">65.3</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.24.24">
<td class="ltx_td ltx_align_left" id="A1.T4.3.24.24.1" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-14b-instruction-gguf</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.24.24.2" style="padding-left:2.5pt;padding-right:2.5pt;">14B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.24.24.3" style="padding-left:2.5pt;padding-right:2.5pt;">93.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.24.24.4" style="padding-left:2.5pt;padding-right:2.5pt;">57.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.24.24.5" style="padding-left:2.5pt;padding-right:2.5pt;">51.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.24.24.6" style="padding-left:2.5pt;padding-right:2.5pt;">91.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.24.24.7" style="padding-left:2.5pt;padding-right:2.5pt;">86.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.24.24.8" style="padding-left:2.5pt;padding-right:2.5pt;">23.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.24.24.9" style="padding-left:2.5pt;padding-right:2.5pt;">77.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.24.24.10" style="padding-left:2.5pt;padding-right:2.5pt;">35.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.24.24.11" style="padding-left:2.5pt;padding-right:2.5pt;">68.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.24.24.12" style="padding-left:2.5pt;padding-right:2.5pt;">65.0</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.25.25">
<td class="ltx_td ltx_align_left" id="A1.T4.3.25.25.1" style="padding-left:2.5pt;padding-right:2.5pt;">Llama-2-70b-chat-hf</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.25.25.2" style="padding-left:2.5pt;padding-right:2.5pt;">70B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.25.25.3" style="padding-left:2.5pt;padding-right:2.5pt;">80.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.25.25.4" style="padding-left:2.5pt;padding-right:2.5pt;">53.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.25.25.5" style="padding-left:2.5pt;padding-right:2.5pt;">94.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.25.25.6" style="padding-left:2.5pt;padding-right:2.5pt;">91.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.25.25.7" style="padding-left:2.5pt;padding-right:2.5pt;">80.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.25.25.8" style="padding-left:2.5pt;padding-right:2.5pt;">21.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.25.25.9" style="padding-left:2.5pt;padding-right:2.5pt;">73.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.25.25.10" style="padding-left:2.5pt;padding-right:2.5pt;">30.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.25.25.11" style="padding-left:2.5pt;padding-right:2.5pt;">54.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.25.25.12" style="padding-left:2.5pt;padding-right:2.5pt;">64.5</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.26.26">
<td class="ltx_td ltx_align_left" id="A1.T4.3.26.26.1" style="padding-left:2.5pt;padding-right:2.5pt;">youri-7b-instruction-gptq</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.26.26.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.26.26.3" style="padding-left:2.5pt;padding-right:2.5pt;">88.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.26.26.4" style="padding-left:2.5pt;padding-right:2.5pt;">62.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.26.26.5" style="padding-left:2.5pt;padding-right:2.5pt;">93.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.26.26.6" style="padding-left:2.5pt;padding-right:2.5pt;">90.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.26.26.7" style="padding-left:2.5pt;padding-right:2.5pt;">74.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.26.26.8" style="padding-left:2.5pt;padding-right:2.5pt;">15.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.26.26.9" style="padding-left:2.5pt;padding-right:2.5pt;">78.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.26.26.10" style="padding-left:2.5pt;padding-right:2.5pt;">15.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.26.26.11" style="padding-left:2.5pt;padding-right:2.5pt;">53.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.26.26.12" style="padding-left:2.5pt;padding-right:2.5pt;">63.4</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.27.27">
<td class="ltx_td ltx_align_left" id="A1.T4.3.27.27.1" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-base-gamma-7b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.27.27.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.27.27.3" style="padding-left:2.5pt;padding-right:2.5pt;">89.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.27.27.4" style="padding-left:2.5pt;padding-right:2.5pt;">37.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.27.27.5" style="padding-left:2.5pt;padding-right:2.5pt;">79.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.27.27.6" style="padding-left:2.5pt;padding-right:2.5pt;">90.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.27.27.7" style="padding-left:2.5pt;padding-right:2.5pt;">89.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.27.27.8" style="padding-left:2.5pt;padding-right:2.5pt;">22.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.27.27.9" style="padding-left:2.5pt;padding-right:2.5pt;">82.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.27.27.10" style="padding-left:2.5pt;padding-right:2.5pt;">20.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.27.27.11" style="padding-left:2.5pt;padding-right:2.5pt;">55.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.27.27.12" style="padding-left:2.5pt;padding-right:2.5pt;">63.2</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.28.28">
<td class="ltx_td ltx_align_left" id="A1.T4.3.28.28.1" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-13b-instruct-hf</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.28.28.2" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.28.28.3" style="padding-left:2.5pt;padding-right:2.5pt;">89.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.28.28.4" style="padding-left:2.5pt;padding-right:2.5pt;">43.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.28.28.5" style="padding-left:2.5pt;padding-right:2.5pt;">74.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.28.28.6" style="padding-left:2.5pt;padding-right:2.5pt;">92.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.28.28.7" style="padding-left:2.5pt;padding-right:2.5pt;">92.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.28.28.8" style="padding-left:2.5pt;padding-right:2.5pt;">20.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.28.28.9" style="padding-left:2.5pt;padding-right:2.5pt;">70.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.28.28.10" style="padding-left:2.5pt;padding-right:2.5pt;">24.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.28.28.11" style="padding-left:2.5pt;padding-right:2.5pt;">61.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.28.28.12" style="padding-left:2.5pt;padding-right:2.5pt;">63.2</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.29.29">
<td class="ltx_td ltx_align_left" id="A1.T4.3.29.29.1" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-instruct-gamma-7b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.29.29.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.29.29.3" style="padding-left:2.5pt;padding-right:2.5pt;">91.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.29.29.4" style="padding-left:2.5pt;padding-right:2.5pt;">40.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.29.29.5" style="padding-left:2.5pt;padding-right:2.5pt;">72.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.29.29.6" style="padding-left:2.5pt;padding-right:2.5pt;">89.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.29.29.7" style="padding-left:2.5pt;padding-right:2.5pt;">88.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.29.29.8" style="padding-left:2.5pt;padding-right:2.5pt;">22.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.29.29.9" style="padding-left:2.5pt;padding-right:2.5pt;">82.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.29.29.10" style="padding-left:2.5pt;padding-right:2.5pt;">17.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.29.29.11" style="padding-left:2.5pt;padding-right:2.5pt;">56.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.29.29.12" style="padding-left:2.5pt;padding-right:2.5pt;">62.4</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.30.30">
<td class="ltx_td ltx_align_left" id="A1.T4.3.30.30.1" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-13b-hf</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.30.30.2" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.30.30.3" style="padding-left:2.5pt;padding-right:2.5pt;">86.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.30.30.4" style="padding-left:2.5pt;padding-right:2.5pt;">44.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.30.30.5" style="padding-left:2.5pt;padding-right:2.5pt;">74.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.30.30.6" style="padding-left:2.5pt;padding-right:2.5pt;">92.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.30.30.7" style="padding-left:2.5pt;padding-right:2.5pt;">92.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.30.30.8" style="padding-left:2.5pt;padding-right:2.5pt;">21.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.30.30.9" style="padding-left:2.5pt;padding-right:2.5pt;">71.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.30.30.10" style="padding-left:2.5pt;padding-right:2.5pt;">19.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.30.30.11" style="padding-left:2.5pt;padding-right:2.5pt;">59.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.30.30.12" style="padding-left:2.5pt;padding-right:2.5pt;">62.4</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.31.31">
<td class="ltx_td ltx_align_left" id="A1.T4.3.31.31.1" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-14b-gguf</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.31.31.2" style="padding-left:2.5pt;padding-right:2.5pt;">14B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.31.31.3" style="padding-left:2.5pt;padding-right:2.5pt;">93.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.31.31.4" style="padding-left:2.5pt;padding-right:2.5pt;">41.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.31.31.5" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.31.31.6" style="padding-left:2.5pt;padding-right:2.5pt;">93.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.31.31.7" style="padding-left:2.5pt;padding-right:2.5pt;">88.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.31.31.8" style="padding-left:2.5pt;padding-right:2.5pt;">22.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.31.31.9" style="padding-left:2.5pt;padding-right:2.5pt;">80.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.31.31.10" style="padding-left:2.5pt;padding-right:2.5pt;">32.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.31.31.11" style="padding-left:2.5pt;padding-right:2.5pt;">60.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.31.31.12" style="padding-left:2.5pt;padding-right:2.5pt;">62.3</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.32.32">
<td class="ltx_td ltx_align_left" id="A1.T4.3.32.32.1" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-MS-7b-v0.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.32.32.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.32.32.3" style="padding-left:2.5pt;padding-right:2.5pt;">88.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.32.32.4" style="padding-left:2.5pt;padding-right:2.5pt;">35.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.32.32.5" style="padding-left:2.5pt;padding-right:2.5pt;">83.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.32.32.6" style="padding-left:2.5pt;padding-right:2.5pt;">90.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.32.32.7" style="padding-left:2.5pt;padding-right:2.5pt;">89.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.32.32.8" style="padding-left:2.5pt;padding-right:2.5pt;">20.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.32.32.9" style="padding-left:2.5pt;padding-right:2.5pt;">74.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.32.32.10" style="padding-left:2.5pt;padding-right:2.5pt;">22.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.32.32.11" style="padding-left:2.5pt;padding-right:2.5pt;">55.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.32.32.12" style="padding-left:2.5pt;padding-right:2.5pt;">62.2</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.33.33">
<td class="ltx_td ltx_align_left" id="A1.T4.3.33.33.1" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-7b-instruct-hf</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.33.33.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.33.33.3" style="padding-left:2.5pt;padding-right:2.5pt;">86.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.33.33.4" style="padding-left:2.5pt;padding-right:2.5pt;">36.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.33.33.5" style="padding-left:2.5pt;padding-right:2.5pt;">94.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.33.33.6" style="padding-left:2.5pt;padding-right:2.5pt;">90.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.33.33.7" style="padding-left:2.5pt;padding-right:2.5pt;">89.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.33.33.8" style="padding-left:2.5pt;padding-right:2.5pt;">17.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.33.33.9" style="padding-left:2.5pt;padding-right:2.5pt;">76.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.33.33.10" style="padding-left:2.5pt;padding-right:2.5pt;">10.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.33.33.11" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.33.33.12" style="padding-left:2.5pt;padding-right:2.5pt;">61.2</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.34.34">
<td class="ltx_td ltx_align_left" id="A1.T4.3.34.34.1" style="padding-left:2.5pt;padding-right:2.5pt;">llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.34.34.2" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.34.34.3" style="padding-left:2.5pt;padding-right:2.5pt;">83.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.34.34.4" style="padding-left:2.5pt;padding-right:2.5pt;">74.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.34.34.5" style="padding-left:2.5pt;padding-right:2.5pt;">74.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.34.34.6" style="padding-left:2.5pt;padding-right:2.5pt;">94.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.34.34.7" style="padding-left:2.5pt;padding-right:2.5pt;">85.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.34.34.8" style="padding-left:2.5pt;padding-right:2.5pt;">9.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.34.34.9" style="padding-left:2.5pt;padding-right:2.5pt;">71.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.34.34.10" style="padding-left:2.5pt;padding-right:2.5pt;">3.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.34.34.11" style="padding-left:2.5pt;padding-right:2.5pt;">50.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.34.34.12" style="padding-left:2.5pt;padding-right:2.5pt;">60.7</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.35.35">
<td class="ltx_td ltx_align_left" id="A1.T4.3.35.35.1" style="padding-left:2.5pt;padding-right:2.5pt;">Swallow-7b-hf</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.35.35.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.35.35.3" style="padding-left:2.5pt;padding-right:2.5pt;">80.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.35.35.4" style="padding-left:2.5pt;padding-right:2.5pt;">37.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.35.35.5" style="padding-left:2.5pt;padding-right:2.5pt;">93.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.35.35.6" style="padding-left:2.5pt;padding-right:2.5pt;">89.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.35.35.7" style="padding-left:2.5pt;padding-right:2.5pt;">90.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.35.35.8" style="padding-left:2.5pt;padding-right:2.5pt;">18.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.35.35.9" style="padding-left:2.5pt;padding-right:2.5pt;">76.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.35.35.10" style="padding-left:2.5pt;padding-right:2.5pt;">10.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.35.35.11" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.35.35.12" style="padding-left:2.5pt;padding-right:2.5pt;">60.7</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.36.36">
<td class="ltx_td ltx_align_left" id="A1.T4.3.36.36.1" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-7b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.36.36.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.36.36.3" style="padding-left:2.5pt;padding-right:2.5pt;">82.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.36.36.4" style="padding-left:2.5pt;padding-right:2.5pt;">38.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.36.36.5" style="padding-left:2.5pt;padding-right:2.5pt;">67.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.36.36.6" style="padding-left:2.5pt;padding-right:2.5pt;">89.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.36.36.7" style="padding-left:2.5pt;padding-right:2.5pt;">82.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.36.36.8" style="padding-left:2.5pt;padding-right:2.5pt;">16.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.36.36.9" style="padding-left:2.5pt;padding-right:2.5pt;">74.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.36.36.10" style="padding-left:2.5pt;padding-right:2.5pt;">16.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.36.36.11" style="padding-left:2.5pt;padding-right:2.5pt;">60.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.36.36.12" style="padding-left:2.5pt;padding-right:2.5pt;">58.7</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.37.37">
<td class="ltx_td ltx_align_left" id="A1.T4.3.37.37.1" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-instruct-beta-7b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.37.37.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.37.37.3" style="padding-left:2.5pt;padding-right:2.5pt;">81.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.37.37.4" style="padding-left:2.5pt;padding-right:2.5pt;">39.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.37.37.5" style="padding-left:2.5pt;padding-right:2.5pt;">88.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.37.37.6" style="padding-left:2.5pt;padding-right:2.5pt;">84.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.37.37.7" style="padding-left:2.5pt;padding-right:2.5pt;">78.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.37.37.8" style="padding-left:2.5pt;padding-right:2.5pt;">20.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.37.37.9" style="padding-left:2.5pt;padding-right:2.5pt;">75.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.37.37.10" style="padding-left:2.5pt;padding-right:2.5pt;">4.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.37.37.11" style="padding-left:2.5pt;padding-right:2.5pt;">51.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.37.37.12" style="padding-left:2.5pt;padding-right:2.5pt;">58.4</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.38.38">
<td class="ltx_td ltx_align_left" id="A1.T4.3.38.38.1" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-base-beta-7b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.38.38.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.38.38.3" style="padding-left:2.5pt;padding-right:2.5pt;">76.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.38.38.4" style="padding-left:2.5pt;padding-right:2.5pt;">38.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.38.38.5" style="padding-left:2.5pt;padding-right:2.5pt;">86.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.38.38.6" style="padding-left:2.5pt;padding-right:2.5pt;">87.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.38.38.7" style="padding-left:2.5pt;padding-right:2.5pt;">79.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.38.38.8" style="padding-left:2.5pt;padding-right:2.5pt;">21.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.38.38.9" style="padding-left:2.5pt;padding-right:2.5pt;">76.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.38.38.10" style="padding-left:2.5pt;padding-right:2.5pt;">7.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.38.38.11" style="padding-left:2.5pt;padding-right:2.5pt;">49.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.38.38.12" style="padding-left:2.5pt;padding-right:2.5pt;">58.1</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.39.39">
<td class="ltx_td ltx_align_left" id="A1.T4.3.39.39.1" style="padding-left:2.5pt;padding-right:2.5pt;">Qwen-7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.39.39.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.39.39.3" style="padding-left:2.5pt;padding-right:2.5pt;">76.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.39.39.4" style="padding-left:2.5pt;padding-right:2.5pt;">46.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.39.39.5" style="padding-left:2.5pt;padding-right:2.5pt;">83.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.39.39.6" style="padding-left:2.5pt;padding-right:2.5pt;">89.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.39.39.7" style="padding-left:2.5pt;padding-right:2.5pt;">69.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.39.39.8" style="padding-left:2.5pt;padding-right:2.5pt;">13.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.39.39.9" style="padding-left:2.5pt;padding-right:2.5pt;">60.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.39.39.10" style="padding-left:2.5pt;padding-right:2.5pt;">22.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.39.39.11" style="padding-left:2.5pt;padding-right:2.5pt;">57.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.39.39.12" style="padding-left:2.5pt;padding-right:2.5pt;">57.6</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.40.40">
<td class="ltx_td ltx_align_left" id="A1.T4.3.40.40.1" style="padding-left:2.5pt;padding-right:2.5pt;">youri-7b-gptq</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.40.40.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.40.40.3" style="padding-left:2.5pt;padding-right:2.5pt;">78.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.40.40.4" style="padding-left:2.5pt;padding-right:2.5pt;">40.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.40.40.5" style="padding-left:2.5pt;padding-right:2.5pt;">78.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.40.40.6" style="padding-left:2.5pt;padding-right:2.5pt;">85.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.40.40.7" style="padding-left:2.5pt;padding-right:2.5pt;">78.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.40.40.8" style="padding-left:2.5pt;padding-right:2.5pt;">16.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.40.40.9" style="padding-left:2.5pt;padding-right:2.5pt;">78.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.40.40.10" style="padding-left:2.5pt;padding-right:2.5pt;">4.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.40.40.11" style="padding-left:2.5pt;padding-right:2.5pt;">54.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.40.40.12" style="padding-left:2.5pt;padding-right:2.5pt;">57.2</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.41.41">
<td class="ltx_td ltx_align_left" id="A1.T4.3.41.41.1" style="padding-left:2.5pt;padding-right:2.5pt;">youri-7b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.41.41.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.41.41.3" style="padding-left:2.5pt;padding-right:2.5pt;">82.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.41.41.4" style="padding-left:2.5pt;padding-right:2.5pt;">35.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.41.41.5" style="padding-left:2.5pt;padding-right:2.5pt;">90.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.41.41.6" style="padding-left:2.5pt;padding-right:2.5pt;">57.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.41.41.7" style="padding-left:2.5pt;padding-right:2.5pt;">82.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.41.41.8" style="padding-left:2.5pt;padding-right:2.5pt;">20.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.41.41.9" style="padding-left:2.5pt;padding-right:2.5pt;">78.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.41.41.10" style="padding-left:2.5pt;padding-right:2.5pt;">6.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.41.41.11" style="padding-left:2.5pt;padding-right:2.5pt;">58.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.41.41.12" style="padding-left:2.5pt;padding-right:2.5pt;">56.9</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.42.42">
<td class="ltx_td ltx_align_left" id="A1.T4.3.42.42.1" style="padding-left:2.5pt;padding-right:2.5pt;">ELYZA-japanese-Llama-2-7b-instruct</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.42.42.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.42.42.3" style="padding-left:2.5pt;padding-right:2.5pt;">79.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.42.42.4" style="padding-left:2.5pt;padding-right:2.5pt;">38.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.42.42.5" style="padding-left:2.5pt;padding-right:2.5pt;">89.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.42.42.6" style="padding-left:2.5pt;padding-right:2.5pt;">83.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.42.42.7" style="padding-left:2.5pt;padding-right:2.5pt;">68.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.42.42.8" style="padding-left:2.5pt;padding-right:2.5pt;">16.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.42.42.9" style="padding-left:2.5pt;padding-right:2.5pt;">71.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.42.42.10" style="padding-left:2.5pt;padding-right:2.5pt;">11.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.42.42.11" style="padding-left:2.5pt;padding-right:2.5pt;">50.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.42.42.12" style="padding-left:2.5pt;padding-right:2.5pt;">56.6</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.43.43">
<td class="ltx_td ltx_align_left" id="A1.T4.3.43.43.1" style="padding-left:2.5pt;padding-right:2.5pt;">weblab-10b-instruction-sft</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.43.43.2" style="padding-left:2.5pt;padding-right:2.5pt;">10B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.43.43.3" style="padding-left:2.5pt;padding-right:2.5pt;">63.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.43.43.4" style="padding-left:2.5pt;padding-right:2.5pt;">42.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.43.43.5" style="padding-left:2.5pt;padding-right:2.5pt;">86.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.43.43.6" style="padding-left:2.5pt;padding-right:2.5pt;">87.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.43.43.7" style="padding-left:2.5pt;padding-right:2.5pt;">73.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.43.43.8" style="padding-left:2.5pt;padding-right:2.5pt;">23.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.43.43.9" style="padding-left:2.5pt;padding-right:2.5pt;">72.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.43.43.10" style="padding-left:2.5pt;padding-right:2.5pt;">2.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.43.43.11" style="padding-left:2.5pt;padding-right:2.5pt;">50.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.43.43.12" style="padding-left:2.5pt;padding-right:2.5pt;">55.9</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.44.44">
<td class="ltx_td ltx_align_left" id="A1.T4.3.44.44.1" style="padding-left:2.5pt;padding-right:2.5pt;">Mistral-7B-v0.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.44.44.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.44.44.3" style="padding-left:2.5pt;padding-right:2.5pt;">74.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.44.44.4" style="padding-left:2.5pt;padding-right:2.5pt;">44.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.44.44.5" style="padding-left:2.5pt;padding-right:2.5pt;">63.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.44.44.6" style="padding-left:2.5pt;padding-right:2.5pt;">85.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.44.44.7" style="padding-left:2.5pt;padding-right:2.5pt;">69.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.44.44.8" style="padding-left:2.5pt;padding-right:2.5pt;">22.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.44.44.9" style="padding-left:2.5pt;padding-right:2.5pt;">69.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.44.44.10" style="padding-left:2.5pt;padding-right:2.5pt;">20.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.44.44.11" style="padding-left:2.5pt;padding-right:2.5pt;">51.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.44.44.12" style="padding-left:2.5pt;padding-right:2.5pt;">55.7</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.45.45">
<td class="ltx_td ltx_align_left" id="A1.T4.3.45.45.1" style="padding-left:2.5pt;padding-right:2.5pt;">ELYZA-japanese-Llama-2-7b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.45.45.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.45.45.3" style="padding-left:2.5pt;padding-right:2.5pt;">75.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.45.45.4" style="padding-left:2.5pt;padding-right:2.5pt;">36.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.45.45.5" style="padding-left:2.5pt;padding-right:2.5pt;">87.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.45.45.6" style="padding-left:2.5pt;padding-right:2.5pt;">86.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.45.45.7" style="padding-left:2.5pt;padding-right:2.5pt;">68.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.45.45.8" style="padding-left:2.5pt;padding-right:2.5pt;">16.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.45.45.9" style="padding-left:2.5pt;padding-right:2.5pt;">72.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.45.45.10" style="padding-left:2.5pt;padding-right:2.5pt;">5.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.45.45.11" style="padding-left:2.5pt;padding-right:2.5pt;">53.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.45.45.12" style="padding-left:2.5pt;padding-right:2.5pt;">55.5</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.46.46">
<td class="ltx_td ltx_align_left" id="A1.T4.3.46.46.1" style="padding-left:2.5pt;padding-right:2.5pt;">nekomata-7b-gguf</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.46.46.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.46.46.3" style="padding-left:2.5pt;padding-right:2.5pt;">82.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.46.46.4" style="padding-left:2.5pt;padding-right:2.5pt;">33.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.46.46.5" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.46.46.6" style="padding-left:2.5pt;padding-right:2.5pt;">86.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.46.46.7" style="padding-left:2.5pt;padding-right:2.5pt;">74.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.46.46.8" style="padding-left:2.5pt;padding-right:2.5pt;">19.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.46.46.9" style="padding-left:2.5pt;padding-right:2.5pt;">78.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.46.46.10" style="padding-left:2.5pt;padding-right:2.5pt;">13.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.46.46.11" style="padding-left:2.5pt;padding-right:2.5pt;">55.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.46.46.12" style="padding-left:2.5pt;padding-right:2.5pt;">55.0</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.47.47">
<td class="ltx_td ltx_align_left" id="A1.T4.3.47.47.1" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-instruct-ja_vocab-beta-7b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.47.47.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.47.47.3" style="padding-left:2.5pt;padding-right:2.5pt;">79.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.47.47.4" style="padding-left:2.5pt;padding-right:2.5pt;">39.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.47.47.5" style="padding-left:2.5pt;padding-right:2.5pt;">79.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.47.47.6" style="padding-left:2.5pt;padding-right:2.5pt;">82.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.47.47.7" style="padding-left:2.5pt;padding-right:2.5pt;">78.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.47.47.8" style="padding-left:2.5pt;padding-right:2.5pt;">9.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.47.47.9" style="padding-left:2.5pt;padding-right:2.5pt;">68.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.47.47.10" style="padding-left:2.5pt;padding-right:2.5pt;">6.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.47.47.11" style="padding-left:2.5pt;padding-right:2.5pt;">49.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.47.47.12" style="padding-left:2.5pt;padding-right:2.5pt;">54.8</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.48.48">
<td class="ltx_td ltx_align_left" id="A1.T4.3.48.48.1" style="padding-left:2.5pt;padding-right:2.5pt;">japanese-stablelm-base-ja_vocab-beta-7b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.48.48.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.48.48.3" style="padding-left:2.5pt;padding-right:2.5pt;">69.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.48.48.4" style="padding-left:2.5pt;padding-right:2.5pt;">38.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.48.48.5" style="padding-left:2.5pt;padding-right:2.5pt;">80.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.48.48.6" style="padding-left:2.5pt;padding-right:2.5pt;">83.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.48.48.7" style="padding-left:2.5pt;padding-right:2.5pt;">80.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.48.48.8" style="padding-left:2.5pt;padding-right:2.5pt;">7.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.48.48.9" style="padding-left:2.5pt;padding-right:2.5pt;">72.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.48.48.10" style="padding-left:2.5pt;padding-right:2.5pt;">3.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.48.48.11" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.48.48.12" style="padding-left:2.5pt;padding-right:2.5pt;">54.0</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.49.49">
<td class="ltx_td ltx_align_left" id="A1.T4.3.49.49.1" style="padding-left:2.5pt;padding-right:2.5pt;">calm2-7b-chat</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.49.49.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.49.49.3" style="padding-left:2.5pt;padding-right:2.5pt;">70.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.49.49.4" style="padding-left:2.5pt;padding-right:2.5pt;">33.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.49.49.5" style="padding-left:2.5pt;padding-right:2.5pt;">87.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.49.49.6" style="padding-left:2.5pt;padding-right:2.5pt;">82.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.49.49.7" style="padding-left:2.5pt;padding-right:2.5pt;">77.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.49.49.8" style="padding-left:2.5pt;padding-right:2.5pt;">5.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.49.49.9" style="padding-left:2.5pt;padding-right:2.5pt;">70.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.49.49.10" style="padding-left:2.5pt;padding-right:2.5pt;">5.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.49.49.11" style="padding-left:2.5pt;padding-right:2.5pt;">51.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.49.49.12" style="padding-left:2.5pt;padding-right:2.5pt;">54.0</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.50.50">
<td class="ltx_td ltx_align_left" id="A1.T4.3.50.50.1" style="padding-left:2.5pt;padding-right:2.5pt;">stockmark-13b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.50.50.2" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.50.50.3" style="padding-left:2.5pt;padding-right:2.5pt;">70.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.50.50.4" style="padding-left:2.5pt;padding-right:2.5pt;">36.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.50.50.5" style="padding-left:2.5pt;padding-right:2.5pt;">56.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.50.50.6" style="padding-left:2.5pt;padding-right:2.5pt;">87.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.50.50.7" style="padding-left:2.5pt;padding-right:2.5pt;">87.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.50.50.8" style="padding-left:2.5pt;padding-right:2.5pt;">7.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.50.50.9" style="padding-left:2.5pt;padding-right:2.5pt;">73.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.50.50.10" style="padding-left:2.5pt;padding-right:2.5pt;">9.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.50.50.11" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.50.50.12" style="padding-left:2.5pt;padding-right:2.5pt;">53.2</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.51.51">
<td class="ltx_td ltx_align_left" id="A1.T4.3.51.51.1" style="padding-left:2.5pt;padding-right:2.5pt;">Llama-2-7b-hf</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.51.51.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.51.51.3" style="padding-left:2.5pt;padding-right:2.5pt;">65.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.51.51.4" style="padding-left:2.5pt;padding-right:2.5pt;">35.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.51.51.5" style="padding-left:2.5pt;padding-right:2.5pt;">83.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.51.51.6" style="padding-left:2.5pt;padding-right:2.5pt;">82.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.51.51.7" style="padding-left:2.5pt;padding-right:2.5pt;">70.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.51.51.8" style="padding-left:2.5pt;padding-right:2.5pt;">19.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.51.51.9" style="padding-left:2.5pt;padding-right:2.5pt;">65.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.51.51.10" style="padding-left:2.5pt;padding-right:2.5pt;">6.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.51.51.11" style="padding-left:2.5pt;padding-right:2.5pt;">47.1</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.51.51.12" style="padding-left:2.5pt;padding-right:2.5pt;">52.9</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.52.52">
<td class="ltx_td ltx_align_left" id="A1.T4.3.52.52.1" style="padding-left:2.5pt;padding-right:2.5pt;">calm2-7b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.52.52.2" style="padding-left:2.5pt;padding-right:2.5pt;">7B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.52.52.3" style="padding-left:2.5pt;padding-right:2.5pt;">58.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.52.52.4" style="padding-left:2.5pt;padding-right:2.5pt;">33.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.52.52.5" style="padding-left:2.5pt;padding-right:2.5pt;">81.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.52.52.6" style="padding-left:2.5pt;padding-right:2.5pt;">81.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.52.52.7" style="padding-left:2.5pt;padding-right:2.5pt;">81.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.52.52.8" style="padding-left:2.5pt;padding-right:2.5pt;">2.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.52.52.9" style="padding-left:2.5pt;padding-right:2.5pt;">73.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.52.52.10" style="padding-left:2.5pt;padding-right:2.5pt;">5.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.52.52.11" style="padding-left:2.5pt;padding-right:2.5pt;">53.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.52.52.12" style="padding-left:2.5pt;padding-right:2.5pt;">52.3</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.53.53">
<td class="ltx_td ltx_align_left" id="A1.T4.3.53.53.1" style="padding-left:2.5pt;padding-right:2.5pt;">plamo-13b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.53.53.2" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.53.53.3" style="padding-left:2.5pt;padding-right:2.5pt;">54.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.53.53.4" style="padding-left:2.5pt;padding-right:2.5pt;">33.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.53.53.5" style="padding-left:2.5pt;padding-right:2.5pt;">85.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.53.53.6" style="padding-left:2.5pt;padding-right:2.5pt;">78.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.53.53.7" style="padding-left:2.5pt;padding-right:2.5pt;">74.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.53.53.8" style="padding-left:2.5pt;padding-right:2.5pt;">12.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.53.53.9" style="padding-left:2.5pt;padding-right:2.5pt;">70.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.53.53.10" style="padding-left:2.5pt;padding-right:2.5pt;">2.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.53.53.11" style="padding-left:2.5pt;padding-right:2.5pt;">54.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.53.53.12" style="padding-left:2.5pt;padding-right:2.5pt;">51.9</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.54.54">
<td class="ltx_td ltx_align_left" id="A1.T4.3.54.54.1" style="padding-left:2.5pt;padding-right:2.5pt;">weblab-10b</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.54.54.2" style="padding-left:2.5pt;padding-right:2.5pt;">10B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.54.54.3" style="padding-left:2.5pt;padding-right:2.5pt;">44.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.54.54.4" style="padding-left:2.5pt;padding-right:2.5pt;">30.7</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.54.54.5" style="padding-left:2.5pt;padding-right:2.5pt;">64.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.54.54.6" style="padding-left:2.5pt;padding-right:2.5pt;">83.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.54.54.7" style="padding-left:2.5pt;padding-right:2.5pt;">74.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.54.54.8" style="padding-left:2.5pt;padding-right:2.5pt;">20.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.54.54.9" style="padding-left:2.5pt;padding-right:2.5pt;">71.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.54.54.10" style="padding-left:2.5pt;padding-right:2.5pt;">2.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.54.54.11" style="padding-left:2.5pt;padding-right:2.5pt;">50.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.54.54.12" style="padding-left:2.5pt;padding-right:2.5pt;">49.0</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.55.55">
<td class="ltx_td ltx_align_left" id="A1.T4.3.55.55.1" style="padding-left:2.5pt;padding-right:2.5pt;">llm-jp-13b-v1.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.55.55.2" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.55.55.3" style="padding-left:2.5pt;padding-right:2.5pt;">39.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.55.55.4" style="padding-left:2.5pt;padding-right:2.5pt;">35.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.55.55.5" style="padding-left:2.5pt;padding-right:2.5pt;">67.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.55.55.6" style="padding-left:2.5pt;padding-right:2.5pt;">79.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.55.55.7" style="padding-left:2.5pt;padding-right:2.5pt;">78.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.55.55.8" style="padding-left:2.5pt;padding-right:2.5pt;">10.9</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.55.55.9" style="padding-left:2.5pt;padding-right:2.5pt;">69.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.55.55.10" style="padding-left:2.5pt;padding-right:2.5pt;">2.0</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.55.55.11" style="padding-left:2.5pt;padding-right:2.5pt;">54.4</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.55.55.12" style="padding-left:2.5pt;padding-right:2.5pt;">48.5</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.56.56">
<td class="ltx_td ltx_align_left" id="A1.T4.3.56.56.1" style="padding-left:2.5pt;padding-right:2.5pt;">plamo-13b-instruct-nc</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.56.56.2" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.56.56.3" style="padding-left:2.5pt;padding-right:2.5pt;">45.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.56.56.4" style="padding-left:2.5pt;padding-right:2.5pt;">35.3</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.56.56.5" style="padding-left:2.5pt;padding-right:2.5pt;">91.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.56.56.6" style="padding-left:2.5pt;padding-right:2.5pt;">75.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.56.56.7" style="padding-left:2.5pt;padding-right:2.5pt;">63.5</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.56.56.8" style="padding-left:2.5pt;padding-right:2.5pt;">5.8</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.56.56.9" style="padding-left:2.5pt;padding-right:2.5pt;">65.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.56.56.10" style="padding-left:2.5pt;padding-right:2.5pt;">1.2</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.56.56.11" style="padding-left:2.5pt;padding-right:2.5pt;">50.6</td>
<td class="ltx_td ltx_align_right" id="A1.T4.3.56.56.12" style="padding-left:2.5pt;padding-right:2.5pt;">48.3</td>
</tr>
<tr class="ltx_tr" id="A1.T4.3.57.57">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T4.3.57.57.1" style="padding-left:2.5pt;padding-right:2.5pt;">plamo-13b-instruct</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.3.57.57.2" style="padding-left:2.5pt;padding-right:2.5pt;">13B</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.3.57.57.3" style="padding-left:2.5pt;padding-right:2.5pt;">42.5</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.3.57.57.4" style="padding-left:2.5pt;padding-right:2.5pt;">34.9</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.3.57.57.5" style="padding-left:2.5pt;padding-right:2.5pt;">90.0</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.3.57.57.6" style="padding-left:2.5pt;padding-right:2.5pt;">77.3</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.3.57.57.7" style="padding-left:2.5pt;padding-right:2.5pt;">67.0</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.3.57.57.8" style="padding-left:2.5pt;padding-right:2.5pt;">5.4</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.3.57.57.9" style="padding-left:2.5pt;padding-right:2.5pt;">62.9</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.3.57.57.10" style="padding-left:2.5pt;padding-right:2.5pt;">2.0</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.3.57.57.11" style="padding-left:2.5pt;padding-right:2.5pt;">50.0</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.3.57.57.12" style="padding-left:2.5pt;padding-right:2.5pt;">48.0</td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Evolving for License Specific Open-Source Models</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">In the main section, our <span class="ltx_text ltx_font_typewriter" id="A2.p1.1.1">EvoLLM-JP</span> results were evolved using models found on HuggingFace. However, some of the models uses, in particular, <span class="ltx_text ltx_font_typewriter" id="A2.p1.1.2">WizardMath-7B-V1.1</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#bib.bib34" title=""><span class="ltx_text" style="font-size:90%;">34</span></a>]</cite> has been released under a Non-Commercial, Research-only, Microsoft License, which is not <span class="ltx_text ltx_font_italic" id="A2.p1.1.3">truly</span> open-source. Therefore, our release of <span class="ltx_text ltx_font_typewriter" id="A2.p1.1.4">EvoLLM-JP</span> is also released under a Non-Commercial, Research-only License to be consistent with the <span class="ltx_text ltx_font_typewriter" id="A2.p1.1.5">WizardMath-7B-V1.1</span> model.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.p2">
<p class="ltx_p" id="A2.p2.1">As researchers who benefited from the open-source community, we would like for models that we release to also be under an open-source license. In the spirit of open-source, and to showcase the applicability of our method to tackle even challenging issues like model licenses. We have ran a similar experiment where we incorporated <span class="ltx_text ltx_font_italic" id="A2.p2.1.1">only</span> models that have been released under a true open-source license, such as MIT or Apache 2.0, and have produced a similar performing model called <span class="ltx_text ltx_font_typewriter" id="A2.p2.1.2">EvoLLM-JP-A</span>, which we will release under Apache 2.0.<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>This model will also be released on our GitHub: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/SakanaAI/" title="">https://github.com/SakanaAI/</a></span></span></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.p3">
<p class="ltx_p" id="A2.p3.1">Specifically, our <span class="ltx_text ltx_font_typewriter" id="A2.p3.1.1">EvoLLM-JP-A</span> is a merge of shisa-gamma-7b-v1, Arithmo2-Mistral-7B, and Abel-7B-002, all of which are under MIT or Apache 2.0 License.
The MGSM-JA score measured using the protocol described in Section&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.SS1" title="4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">4.1</span></a> is 52.4, and the Japanese Language Model Evaluation Harness score is 69.0.
We have included results of this Apache 2.0-licensed model for comparison in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#A1.T4" title="Table 4 ‣ Appendix A Evaluation Details ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">4</span></a>, which provides a more comprehensive comparison than Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#S4.T2" title="Table 2 ‣ 4.1.2 Results ‣ 4.1 Evolving Japanese Math LLM ‣ 4 Experiments ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">2</span></a> in the main text.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Case Study</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#A3.T5" title="Table 5 ‣ Appendix C Case Study ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">5</span></a> provides an example of responses to a mathematical question by existing models and our model. By merging a Japanese language model, we not only improve our capability to understand and use Japanese in reading and writing but also expand our knowledge about Japan. This example requires both mathematical reasoning and Japanese-specific knowledge, specifically that Setsubun is the day before the beginning of spring (Risshun). Notably, only our merged model provides the correct answer. Even when the question is translated into English, the English math model <span class="ltx_text ltx_font_typewriter" id="A3.p1.1.1">WizardMath-7B-V1.1</span> fails to answer correctly, demonstrating that our merged model is superior to a combination of machine translation and an English math model.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A3.p2">
<p class="ltx_p" id="A3.p2.1">It is worth noting that in Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#A3.T5" title="Table 5 ‣ Appendix C Case Study ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">5</span></a>, we also provide the answer from the general-purpose math model <span class="ltx_text ltx_font_typewriter" id="A3.p2.1.1">WizardMath-7B-V1.1</span> with the question translated into English. However, even with the translated question, <span class="ltx_text ltx_font_typewriter" id="A3.p2.1.2">WizardMath-7B-V1.1</span> fails to provide the correct answer. This highlights the fact that simply translating the question is not sufficient to solve the problem, as it also requires an understanding of the Japanese cultural context. Even if one were to consider a combination of machine translation and an English math model as an alternative approach, it would still fall short in capturing the nuances and context-specific knowledge required to answer the question correctly. This demonstrates the unique value of our merged model, which effectively combines mathematical reasoning capabilities with Japanese language understanding and cultural knowledge.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A3.T5">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 5: </span><span class="ltx_text ltx_font_bold" id="A3.T5.4.1">Case Study of EvoLLM-JP-v1-7B</span>. This study presents the responses of the LLMs to a problem that demands both Japanese-specific knowledge and mathematical reasoning.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T5.5">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T5.5.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T5.5.1.1.1">
<span class="ltx_text ltx_font_bold ltx_font_italic" id="A3.T5.5.1.1.1.1" style="font-size:70%;">Problem</span><span class="ltx_text" id="A3.T5.5.1.1.1.2" style="font-size:70%;"></span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.2.2">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T5.5.2.2.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.T5.5.2.2.1.1" style="font-size:70%;">JA Instruction</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T5.5.2.2.2" style="width:284.5pt;">
<p class="ltx_p ltx_align_top" id="A3.T5.5.2.2.2.1"><span class="ltx_text" id="A3.T5.5.2.2.2.1.1" style="font-size:70%;">去年の立春は2月3日でした。今年の立春は2月4日です。去年の節分の月、去年の節分の日、今年の節分の月、今年の節分の日を足し合わせると、いくつになりますか？</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.3.3">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T5.5.3.3.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.T5.5.3.3.1.1" style="font-size:70%;">EN Instruction</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T5.5.3.3.2" style="width:284.5pt;">
<p class="ltx_p ltx_align_top" id="A3.T5.5.3.3.2.1"><span class="ltx_text" id="A3.T5.5.3.3.2.1.1" style="font-size:70%;">Last year, Risshun was on February 3rd. This year, it is on February 4th. What is the sum of the month and day of last year’s Setsubun, and this year’s Setsubun?</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.4.4">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T5.5.4.4.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.T5.5.4.4.1.1" style="font-size:70%;">Ground Truth Answer</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T5.5.4.4.2" style="width:284.5pt;">
<p class="ltx_p ltx_align_top" id="A3.T5.5.4.4.2.1"><span class="ltx_text" id="A3.T5.5.4.4.2.1.1" style="font-size:70%;">9</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.5.5">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T5.5.5.5.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.T5.5.5.5.1.1" style="font-size:70%;">Note</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T5.5.5.5.2" style="width:284.5pt;">
<p class="ltx_p ltx_align_top" id="A3.T5.5.5.5.2.1"><span class="ltx_text" id="A3.T5.5.5.5.2.1.1" style="font-size:70%;">Setsubun, the eve of the first day of spring, always falls on the day before Risshun, which marks the start of spring according to the lunar calendar. The date of Risshun can vary annually.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.6.6">
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T5.5.6.6.1">
<span class="ltx_text ltx_font_bold ltx_font_italic" id="A3.T5.5.6.6.1.1" style="font-size:70%;">Answers</span><span class="ltx_text" id="A3.T5.5.6.6.1.2" style="font-size:70%;"></span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.7.7">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T5.5.7.7.1" style="width:85.4pt;">
<div class="ltx_block ltx_align_top" id="A3.T5.5.7.7.1.1">
<p class="ltx_p" id="A3.T5.5.7.7.1.1.1"><span class="ltx_text ltx_font_bold" id="A3.T5.5.7.7.1.1.1.1" style="font-size:70%;">EvoLLM-JP-v1-7B</span><span class="ltx_text" id="A3.T5.5.7.7.1.1.1.2" style="font-size:70%;"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.7.7.1.1.2"><span class="ltx_text" id="A3.T5.5.7.7.1.1.2.1" style="font-size:70%;">JA Instruction</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T5.5.7.7.2" style="width:284.5pt;">
<div class="ltx_block ltx_align_top" id="A3.T5.5.7.7.2.1">
<p class="ltx_p" id="A3.T5.5.7.7.2.1.1"><span class="ltx_text" id="A3.T5.5.7.7.2.1.1.1" style="font-size:70%;">去年の立春は2月3日で、今年の立春は2月4日です。
去年の節分は立春の前日、つまり2月2日でした。
今年の節分は立春の前日、つまり2月3日です。
去年の節分の月は2月、去年の節分の日は2日で、合計は2 + 2 = 4です。
今年の節分の月は2月、今年の節分の日は3日で、合計は2 + 3 = 5です。
足し合わせると、4 + 5 = 9になります。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.7.7.2.1.2"><span class="ltx_text" id="A3.T5.5.7.7.2.1.2.1" style="font-size:70%;">#### 9</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.7.7.2.1.3"><span class="ltx_text" id="A3.T5.5.7.7.2.1.3.1" style="font-size:70%;">The answer is: 9.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.8.8">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T5.5.8.8.1" style="width:85.4pt;">
<div class="ltx_block ltx_align_top" id="A3.T5.5.8.8.1.1">
<p class="ltx_p" id="A3.T5.5.8.8.1.1.1"><span class="ltx_text ltx_font_bold" id="A3.T5.5.8.8.1.1.1.1" style="font-size:70%;">shisa-gamma-7b</span><span class="ltx_text" id="A3.T5.5.8.8.1.1.1.2" style="font-size:70%;"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.8.8.1.1.2"><span class="ltx_text" id="A3.T5.5.8.8.1.1.2.1" style="font-size:70%;">JA Instruction</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T5.5.8.8.2" style="width:284.5pt;">
<div class="ltx_block ltx_align_top" id="A3.T5.5.8.8.2.1">
<p class="ltx_p" id="A3.T5.5.8.8.2.1.1"><span class="ltx_text" id="A3.T5.5.8.8.2.1.1.1" style="font-size:70%;">まず、去年の立春の日付を計算してみましょう。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.8.8.2.1.2"><span class="ltx_text" id="A3.T5.5.8.8.2.1.2.1" style="font-size:70%;">去年の立春の日付 = 2021年の2月3日</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.8.8.2.1.3"><span class="ltx_text" id="A3.T5.5.8.8.2.1.3.1" style="font-size:70%;">次に、去年の節分の日付を計算してみましょう。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.8.8.2.1.4"><span class="ltx_text" id="A3.T5.5.8.8.2.1.4.1" style="font-size:70%;">去年の節分の日付 = 2021年の2月2日</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.8.8.2.1.5"><span class="ltx_text" id="A3.T5.5.8.8.2.1.5.1" style="font-size:70%;">次に、今年の立春の日付を計算してみましょう。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.8.8.2.1.6"><span class="ltx_text" id="A3.T5.5.8.8.2.1.6.1" style="font-size:70%;">今年の立春の日付 = 2022年の2月4日</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.8.8.2.1.7"><span class="ltx_text" id="A3.T5.5.8.8.2.1.7.1" style="font-size:70%;">次に、今年の節分の日付を計算してみましょう。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.8.8.2.1.8"><span class="ltx_text" id="A3.T5.5.8.8.2.1.8.1" style="font-size:70%;">今年の節分の日付 = 2022年の2月1日</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.8.8.2.1.9"><span class="ltx_text" id="A3.T5.5.8.8.2.1.9.1" style="font-size:70%;">最後に、去年の節分の月と日、今年の節分の月と日を足し合わせてみましょう。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.8.8.2.1.10"><span class="ltx_text" id="A3.T5.5.8.8.2.1.10.1" style="font-size:70%;">去年の節分の月と日 = 2021年の2月2日
今年の節分の月と日 = 2022年の2月1日</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.8.8.2.1.11"><span class="ltx_text" id="A3.T5.5.8.8.2.1.11.1" style="font-size:70%;">これで、足し合わせることができます。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.8.8.2.1.12"><span class="ltx_text" id="A3.T5.5.8.8.2.1.12.1" style="font-size:70%;">足し合わせた月と日 = 2021年の2月2日 + 2022年の2月1日 = 2023年の2月3日</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.8.8.2.1.13"><span class="ltx_text" id="A3.T5.5.8.8.2.1.13.1" style="font-size:70%;">つまり、去年の節分の月と日、今年の節分の月と日を足し合わせると、2023年の2月3日になります。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.9.9">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T5.5.9.9.1" style="width:85.4pt;">
<div class="ltx_block ltx_align_top" id="A3.T5.5.9.9.1.1">
<p class="ltx_p" id="A3.T5.5.9.9.1.1.1"><span class="ltx_text ltx_font_bold" id="A3.T5.5.9.9.1.1.1.1" style="font-size:70%;">WizardMath-7B-V1.1</span><span class="ltx_text" id="A3.T5.5.9.9.1.1.1.2" style="font-size:70%;"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.1.1.2"><span class="ltx_text" id="A3.T5.5.9.9.1.1.2.1" style="font-size:70%;">JA Instruction</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T5.5.9.9.2" style="width:284.5pt;">
<div class="ltx_block ltx_align_top" id="A3.T5.5.9.9.2.1">
<p class="ltx_p" id="A3.T5.5.9.9.2.1.1"><span class="ltx_text" id="A3.T5.5.9.9.2.1.1.1" style="font-size:70%;">Step 1: Identify the dates for the given events.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.2"><span class="ltx_text" id="A3.T5.5.9.9.2.1.2.1" style="font-size:70%;">- Last year’s Setsubun (February 3)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.3"><span class="ltx_text" id="A3.T5.5.9.9.2.1.3.1" style="font-size:70%;">- This year’s Setsubun (February 4)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.4"><span class="ltx_text" id="A3.T5.5.9.9.2.1.4.1" style="font-size:70%;">Step 2: Determine the dates for the corresponding events in the previous and next years.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.5"><span class="ltx_text" id="A3.T5.5.9.9.2.1.5.1" style="font-size:70%;">- Last year’s Setsubun (February 3) falls on a Monday.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.6"><span class="ltx_text" id="A3.T5.5.9.9.2.1.6.1" style="font-size:70%;">- This year’s Setsubun (February 4) falls on a Tuesday.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.7"><span class="ltx_text" id="A3.T5.5.9.9.2.1.7.1" style="font-size:70%;">Step 3: Calculate the number of days between the corresponding events.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.8"><span class="ltx_text" id="A3.T5.5.9.9.2.1.8.1" style="font-size:70%;">- The number of days between last year’s and this year’s Setsubun is 1 day (Tuesday - Monday = 1 day).</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.9"><span class="ltx_text" id="A3.T5.5.9.9.2.1.9.1" style="font-size:70%;">Step 4: Determine the dates for the corresponding events in the lunar calendar.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.10"><span class="ltx_text" id="A3.T5.5.9.9.2.1.10.1" style="font-size:70%;">- Last year’s Setsubun was on the 1st day of the 2nd month.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.11"><span class="ltx_text" id="A3.T5.5.9.9.2.1.11.1" style="font-size:70%;">- This year’s Setsubun will be on the 2nd day of the 2nd month.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.12"><span class="ltx_text" id="A3.T5.5.9.9.2.1.12.1" style="font-size:70%;">Step 5: Calculate the number of days between the corresponding events in the lunar calendar.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.13"><span class="ltx_text" id="A3.T5.5.9.9.2.1.13.1" style="font-size:70%;">- The number of days between last year’s and this year’s Setsubun in the lunar calendar is 1 day (2nd day - 1st day = 1 day).</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.14"><span class="ltx_text" id="A3.T5.5.9.9.2.1.14.1" style="font-size:70%;">Step 6: Add the number of days between the corresponding events in both calendars.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.15"><span class="ltx_text" id="A3.T5.5.9.9.2.1.15.1" style="font-size:70%;">- The total number of days between last year’s and this year’s Setsubun is 1 (from the solar calendar) + 1 (from the lunar calendar) = 2 days.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.16"><span class="ltx_text" id="A3.T5.5.9.9.2.1.16.1" style="font-size:70%;">Step 7: Write the final answer.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.17"><span class="ltx_text" id="A3.T5.5.9.9.2.1.17.1" style="font-size:70%;">- The sum of the dates for the corresponding events is 2.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.9.9.2.1.18"><span class="ltx_text" id="A3.T5.5.9.9.2.1.18.1" style="font-size:70%;">The answer is: 2.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.T5.5.10.10">
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A3.T5.5.10.10.1" style="width:85.4pt;">
<div class="ltx_block ltx_align_top" id="A3.T5.5.10.10.1.1">
<p class="ltx_p" id="A3.T5.5.10.10.1.1.1"><span class="ltx_text ltx_font_bold" id="A3.T5.5.10.10.1.1.1.1" style="font-size:70%;">WizardMath-7B-V1.1</span><span class="ltx_text" id="A3.T5.5.10.10.1.1.1.2" style="font-size:70%;"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.10.10.1.1.2"><span class="ltx_text" id="A3.T5.5.10.10.1.1.2.1" style="font-size:70%;">EN Instruction</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A3.T5.5.10.10.2" style="width:284.5pt;">
<div class="ltx_block ltx_align_top" id="A3.T5.5.10.10.2.1">
<p class="ltx_p" id="A3.T5.5.10.10.2.1.1"><span class="ltx_text" id="A3.T5.5.10.10.2.1.1.1" style="font-size:70%;">We are given that last year, Risshun (the beginning of spring according to the lunisolar Japanese calendar) was on February 3rd, and this year it is on February 4th. We need to find the sum of the month and day of last year’s Setsubun, and this year’s Setsubun.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.10.10.2.1.2"><span class="ltx_text" id="A3.T5.5.10.10.2.1.2.1" style="font-size:70%;">Step 2: Identify the month and day of last year’s Setsubun.
Last year, Risshun was on February 3rd. So, the month is February (2) and the day is 3.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.10.10.2.1.3"><span class="ltx_text" id="A3.T5.5.10.10.2.1.3.1" style="font-size:70%;">Step 3: Identify the month and day of this year’s Setsubun.
This year, Risshun is on February 4th. So, the month is February (2) and the day is 4.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.10.10.2.1.4"><span class="ltx_text" id="A3.T5.5.10.10.2.1.4.1" style="font-size:70%;">Step 4: Calculate the sum of the month and day of last year’s and this year’s Setsubun.
The sum of the month and day of last year’s Setsubun is 2 + 3 = 5.
The sum of the month and day of this year’s Setsubun is 2 + 4 = 6.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.10.10.2.1.5"><span class="ltx_text" id="A3.T5.5.10.10.2.1.5.1" style="font-size:70%;">Step 5: Add the two sums together.
The total sum of the month and day of last year’s and this year’s Setsubun is 5 + 6 = 11.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.10.10.2.1.6"><span class="ltx_text" id="A3.T5.5.10.10.2.1.6.1" style="font-size:70%;">So, the sum of the month and day of last year’s Setsubun, and this year’s Setsubun is 11.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T5.5.10.10.2.1.7"><span class="ltx_text" id="A3.T5.5.10.10.2.1.7.1" style="font-size:70%;">The answer is: 11.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A3.p3">
<p class="ltx_p" id="A3.p3.1">Additionally, Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.13187v1#A3.T6" title="Table 6 ‣ Appendix C Case Study ‣ Evolutionary Optimization of Model Merging Recipes"><span class="ltx_text ltx_ref_tag">6</span></a> provides the case studies for our VLM. We observe that our VLM successfully obtained knowledge of the Japanese LLM. In the 1st example, our VLM generates the correct answer (Koi-nobori) while the original VLM (<span class="ltx_text ltx_font_typewriter" id="A3.p3.1.1">LLaVA-1.6-Mistral-7B</span>) answers incorrectly. Compared to the Japanese VLM (JSVLM), our VLM generally describes the photo more precisely as the 2nd example of a deer. Also, we found that the original VLM hallucinates a lot in Japanese such that it answers the color of traffic light is green while our VLM answers correctly.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A3.T6">
<figcaption class="ltx_caption ltx_centering" style="font-size:70%;"><span class="ltx_tag ltx_tag_table">Table 6: </span><span class="ltx_text ltx_font_bold" id="A3.T6.6.1">Case Study of EvoVLM-JP</span>. This study presents the responses of the VLMs to questions that demand both Japanese-specific knowledge and VQA abilities.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.T6.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T6.2.3.1">
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T6.2.3.1.1">
<span class="ltx_text ltx_font_bold ltx_font_italic" id="A3.T6.2.3.1.1.1" style="font-size:70%;">Example 1</span><span class="ltx_text" id="A3.T6.2.3.1.1.2" style="font-size:70%;"></span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.1.1">
<td class="ltx_td ltx_border_t" id="A3.T6.1.1.2" style="width:85.4pt;"></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.1.1.1" style="width:341.4pt;">
<p class="ltx_p ltx_align_top" id="A3.T6.1.1.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="89" id="A3.T6.1.1.1.1.1.g1" src="extracted/5480703/figures/vlm-koinobori.jpg" width="118"></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.2.4.2">
<td class="ltx_td ltx_align_justify" id="A3.T6.2.4.2.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.T6.2.4.2.1.1" style="font-size:70%;">User</span></td>
<td class="ltx_td ltx_align_justify" id="A3.T6.2.4.2.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.T6.2.4.2.2.1">
<p class="ltx_p" id="A3.T6.2.4.2.2.1.1"><span class="ltx_text" id="A3.T6.2.4.2.2.1.1.1" style="font-size:70%;">この画像に映っている魚の形をした飾りは、日本では何と呼ばれていますか？</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T6.2.4.2.2.1.2"><span class="ltx_text" id="A3.T6.2.4.2.2.1.2.1" style="font-size:70%;">(What is the fish-shaped decoration in this image called in Japan?)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.2.5.3">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.2.5.3.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.T6.2.5.3.1.1" style="font-size:70%;">LLaVA-1.6-Mistral-7B</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.2.5.3.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.T6.2.5.3.2.1">
<p class="ltx_p" id="A3.T6.2.5.3.2.1.1"><span class="ltx_text" id="A3.T6.2.5.3.2.1.1.1" style="font-size:70%;">この画像に映っている魚の形をした飾りは、日本では「花魚」と呼ばれています。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T6.2.5.3.2.1.2"><span class="ltx_text" id="A3.T6.2.5.3.2.1.2.1" style="font-size:70%;">(The fish-shaped decoration in this image is called "hana-gyo" in Japan.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.2.6.4">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.2.6.4.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.T6.2.6.4.1.1" style="font-size:70%;">Japanese Stable VLM</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.2.6.4.2" style="width:341.4pt;">
<p class="ltx_p ltx_align_top" id="A3.T6.2.6.4.2.1"><span class="ltx_text" id="A3.T6.2.6.4.2.1.1" style="font-size:70%;">こいのぼり (Koi-nobori)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.2.7.5">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.2.7.5.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.T6.2.7.5.1.1" style="font-size:70%;">EvoVLM-JP</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.2.7.5.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.T6.2.7.5.2.1">
<p class="ltx_p" id="A3.T6.2.7.5.2.1.1"><span class="ltx_text" id="A3.T6.2.7.5.2.1.1.1" style="font-size:70%;">この画像に映っている魚の形をした飾りは、日本では「鯉のぼり」と呼ばれています。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T6.2.7.5.2.1.2"><span class="ltx_text" id="A3.T6.2.7.5.2.1.2.1" style="font-size:70%;">(The fish-shaped decoration in this image is called "Koi-nobori" in Japan.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.2.8.6">
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.T6.2.8.6.1">
<span class="ltx_text ltx_font_bold ltx_font_italic" id="A3.T6.2.8.6.1.1" style="font-size:70%;">Example 2</span><span class="ltx_text" id="A3.T6.2.8.6.1.2" style="font-size:70%;"></span>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.2.2">
<td class="ltx_td ltx_border_t" id="A3.T6.2.2.2" style="width:85.4pt;"></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.2.2.1" style="width:341.4pt;">
<p class="ltx_p ltx_align_top" id="A3.T6.2.2.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_portrait" height="177" id="A3.T6.2.2.1.1.1.g1" src="extracted/5480703/figures/vlm-deer.jpg" width="118"></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.2.9.7">
<td class="ltx_td ltx_align_justify" id="A3.T6.2.9.7.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.T6.2.9.7.1.1" style="font-size:70%;">User</span></td>
<td class="ltx_td ltx_align_justify" id="A3.T6.2.9.7.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.T6.2.9.7.2.1">
<p class="ltx_p" id="A3.T6.2.9.7.2.1.1"><span class="ltx_text" id="A3.T6.2.9.7.2.1.1.1" style="font-size:70%;">写真を説明してください。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T6.2.9.7.2.1.2"><span class="ltx_text" id="A3.T6.2.9.7.2.1.2.1" style="font-size:70%;">(Please explain this photo.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.2.10.8">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.2.10.8.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.T6.2.10.8.1.1" style="font-size:70%;">LLaVA-1.6-Mistral-7B</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.2.10.8.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.T6.2.10.8.2.1">
<p class="ltx_p" id="A3.T6.2.10.8.2.1.1"><span class="ltx_text" id="A3.T6.2.10.8.2.1.1.1" style="font-size:70%;">この写真では、自然の中で小さな動物が歩いています。その動物は、犬のような外貌を持っていますが、実際には犬ではありません。この動物は、野生動物として知られていますが、具体的な種類はわかりません。 背景には、秋の季節になっていることがわかります。多くの樹木には、黄色い葉が落ちています。このような環境で、動物が歩いていることを見ることができます。 この写真では、動物が自然の中で活動していることを表現しています。同時に、秋の季節になっていることを伝えることもできます。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T6.2.10.8.2.1.2"><span class="ltx_text" id="A3.T6.2.10.8.2.1.2.1" style="font-size:70%;">(In this photo, a small animal is walking in nature. The animal has a canine-like appearance but is not actually a dog. This creature is known as a wild animal, but the specific species is unknown. In the background, it is evident that it is autumn. Many trees have yellow leaves falling. In such an environment, the animal can be seen walking. The photo depicts the animal being active in nature while also conveying that it is autumn.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.2.11.9">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.2.11.9.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.T6.2.11.9.1.1" style="font-size:70%;">Japanese Stable VLM</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.T6.2.11.9.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.T6.2.11.9.2.1">
<p class="ltx_p" id="A3.T6.2.11.9.2.1.1"><span class="ltx_text" id="A3.T6.2.11.9.2.1.1.1" style="font-size:70%;">紅葉と鹿の写真です。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T6.2.11.9.2.1.2"><span class="ltx_text" id="A3.T6.2.11.9.2.1.2.1" style="font-size:70%;">(It’s a photo of autumn leaves and deer.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.T6.2.12.10">
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A3.T6.2.12.10.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.T6.2.12.10.1.1" style="font-size:70%;">EvoVLM-JP</span></td>
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A3.T6.2.12.10.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.T6.2.12.10.2.1">
<p class="ltx_p" id="A3.T6.2.12.10.2.1.1"><span class="ltx_text" id="A3.T6.2.12.10.2.1.1.1" style="font-size:70%;">この写真は、一匹の小さな鹿が落ち葉の上に立っている様子を捉えています。鹿は警戒しているようで、周囲を注意深く見回しています。背景には紅葉した木々が見え、秋の雰囲気が感じられます。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.T6.2.12.10.2.1.2"><span class="ltx_text" id="A3.T6.2.12.10.2.1.2.1" style="font-size:70%;">(This photo captures a small deer standing on fallen leaves. The deer appears to be alert, carefully scanning its surroundings. In the background, you can see trees with autumn foliage, creating an atmosphere of autumn.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A3.2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A3.2.2">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.2.2.3.1">
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.2.2.3.1.1">
<span class="ltx_text ltx_font_bold ltx_font_italic" id="A3.2.2.3.1.1.1" style="font-size:70%;">Example 3</span><span class="ltx_text" id="A3.2.2.3.1.1.2" style="font-size:70%;"></span>
</td>
</tr>
<tr class="ltx_tr" id="A3.1.1.1">
<td class="ltx_td ltx_border_t" id="A3.1.1.1.2" style="width:85.4pt;"></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.1.1.1.1" style="width:341.4pt;">
<p class="ltx_p ltx_align_top" id="A3.1.1.1.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="167" id="A3.1.1.1.1.1.1.g1" src="extracted/5480703/figures/vlm-japan-traffic-lights.jpg" width="236"></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="A3.2.2.4.2">
<td class="ltx_td ltx_align_justify" id="A3.2.2.4.2.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.2.2.4.2.1.1" style="font-size:70%;">User</span></td>
<td class="ltx_td ltx_align_justify" id="A3.2.2.4.2.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.2.2.4.2.2.1">
<p class="ltx_p" id="A3.2.2.4.2.2.1.1"><span class="ltx_text" id="A3.2.2.4.2.2.1.1.1" style="font-size:70%;">この信号機の色は何色ですか?</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.2.2.4.2.2.1.2"><span class="ltx_text" id="A3.2.2.4.2.2.1.2.1" style="font-size:70%;">(What color is this traffic light?)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.2.2.5.3">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.2.2.5.3.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.2.2.5.3.1.1" style="font-size:70%;">LLaVA-1.6-Mistral-7B</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.2.2.5.3.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.2.2.5.3.2.1">
<p class="ltx_p" id="A3.2.2.5.3.2.1.1"><span class="ltx_text" id="A3.2.2.5.3.2.1.1.1" style="font-size:70%;">(A) この信号機の色は緑色です。
(The color of this traffic light is green.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.2.2.5.3.2.1.2"><span class="ltx_text" id="A3.2.2.5.3.2.1.2.1" style="font-size:70%;">(B) この信号機の色は緑色です。
(The color of this traffic light is green.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.2.2.5.3.2.1.3"><span class="ltx_text" id="A3.2.2.5.3.2.1.3.1" style="font-size:70%;">(C) この信号機の色は緑色です。
(The color of this traffic light is green.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.2.2.6.4">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.2.2.6.4.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.2.2.6.4.1.1" style="font-size:70%;">Japanese Stable VLM</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.2.2.6.4.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.2.2.6.4.2.1">
<p class="ltx_p" id="A3.2.2.6.4.2.1.1"><span class="ltx_text" id="A3.2.2.6.4.2.1.1.1" style="font-size:70%;">(A) 緑色です。
(It is green.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.2.2.6.4.2.1.2"><span class="ltx_text" id="A3.2.2.6.4.2.1.2.1" style="font-size:70%;">(B) 緑と白です。
(It is green and white.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.2.2.6.4.2.1.3"><span class="ltx_text" id="A3.2.2.6.4.2.1.3.1" style="font-size:70%;">(C) 白色
(White)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.2.2.7.5">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.2.2.7.5.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.2.2.7.5.1.1" style="font-size:70%;">EvoVLM-JP</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.2.2.7.5.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.2.2.7.5.2.1">
<p class="ltx_p" id="A3.2.2.7.5.2.1.1"><span class="ltx_text" id="A3.2.2.7.5.2.1.1.1" style="font-size:70%;">(A) この信号機の色は青です。
(The color of this traffic light is blue.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.2.2.7.5.2.1.2"><span class="ltx_text" id="A3.2.2.7.5.2.1.2.1" style="font-size:70%;">(B) この信号機の色は青です。
(The color of this traffic light is blue.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.2.2.7.5.2.1.3"><span class="ltx_text" id="A3.2.2.7.5.2.1.3.1" style="font-size:70%;">(C) この信号機の色は青です。
(The color of this traffic light is blue.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.2.2.8.6">
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A3.2.2.8.6.1">
<span class="ltx_text ltx_font_bold ltx_font_italic" id="A3.2.2.8.6.1.1" style="font-size:70%;">Example 4</span><span class="ltx_text" id="A3.2.2.8.6.1.2" style="font-size:70%;"></span>
</td>
</tr>
<tr class="ltx_tr" id="A3.2.2.2">
<td class="ltx_td ltx_border_t" id="A3.2.2.2.2" style="width:85.4pt;"></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.2.2.2.1" style="width:341.4pt;">
<p class="ltx_p ltx_align_top" id="A3.2.2.2.1.1.1"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="79" id="A3.2.2.2.1.1.1.g1" src="extracted/5480703/figures/vlm-genbaku.jpg" width="118"></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</td>
</tr>
<tr class="ltx_tr" id="A3.2.2.9.7">
<td class="ltx_td ltx_align_justify" id="A3.2.2.9.7.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.2.2.9.7.1.1" style="font-size:70%;">User</span></td>
<td class="ltx_td ltx_align_justify" id="A3.2.2.9.7.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.2.2.9.7.2.1">
<p class="ltx_p" id="A3.2.2.9.7.2.1.1"><span class="ltx_text" id="A3.2.2.9.7.2.1.1.1" style="font-size:70%;">この建物について教えてください。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.2.2.9.7.2.1.2"><span class="ltx_text" id="A3.2.2.9.7.2.1.2.1" style="font-size:70%;">(Please explain this building.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.2.2.10.8">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.2.2.10.8.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.2.2.10.8.1.1" style="font-size:70%;">LLaVA-1.6-Mistral-7B</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.2.2.10.8.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.2.2.10.8.2.1">
<p class="ltx_p" id="A3.2.2.10.8.2.1.1"><span class="ltx_text" id="A3.2.2.10.8.2.1.1.1" style="font-size:70%;">この建物は、日本で位置しています。具体的には、東京都渋谷区にあります。この建物は、1945年8月15日に、第二次世界大戦中に日本軍によって攻撃され、完全に破壊されました。その後、1964年に再構築されました。 この建物は、「平和の塔」（Peace Tower）と呼ばれています。その名前は、この建物が再構築される際に決められた名前です。この建物は、平和を祈るために作られたものであり、国内外から多くの人々が訪れる場所です。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.2.2.10.8.2.1.2"><span class="ltx_text" id="A3.2.2.10.8.2.1.2.1" style="font-size:70%;">(This building is located in Japan, specifically in Shibuya Ward, Tokyo. It was completely destroyed by the Japanese military during World War II on August 15, 1945. Subsequently, it was reconstructed in 1964. This building is called the "Peace Tower," a name decided upon during its reconstruction. It was created as a symbol of peace, and it is a place visited by many people from both within and outside the country to pray for peace.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.2.2.11.9">
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.2.2.11.9.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.2.2.11.9.1.1" style="font-size:70%;">Japanese Stable VLM</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" id="A3.2.2.11.9.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.2.2.11.9.2.1">
<p class="ltx_p" id="A3.2.2.11.9.2.1.1"><span class="ltx_text" id="A3.2.2.11.9.2.1.1.1" style="font-size:70%;">原爆ドーム</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.2.2.11.9.2.1.2"><span class="ltx_text" id="A3.2.2.11.9.2.1.2.1" style="font-size:70%;">(Atomic Bomb Dome)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="A3.2.2.12.10">
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A3.2.2.12.10.1" style="width:85.4pt;"><span class="ltx_text ltx_font_bold ltx_align_top" id="A3.2.2.12.10.1.1" style="font-size:70%;">EvoVLM-JP</span></td>
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="A3.2.2.12.10.2" style="width:341.4pt;">
<div class="ltx_block ltx_align_top" id="A3.2.2.12.10.2.1">
<p class="ltx_p" id="A3.2.2.12.10.2.1.1"><span class="ltx_text" id="A3.2.2.12.10.2.1.1.1" style="font-size:70%;">この建物は、日本の広島市にある「原爆ドーム」です。 1945年8月6日、広島市に原子爆弾が投下されました。 この原子爆弾は、広島市の中心部にある「広島県産業奨励館」に直撃しました。 この奨励館は、現在は「原爆ドーム」と呼ばれています。 この原爆ドームは、原子爆弾の被害を受けた建物の中で、唯一残っている建物です。 この原爆ドームは、1996年に世界遺産に登録されました。</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="A3.2.2.12.10.2.1.2"><span class="ltx_text" id="A3.2.2.12.10.2.1.2.1" style="font-size:70%;">(This building is the "Atomic Bomb Dome" located in Hiroshima City, Japan. On August 6, 1945, an atomic bomb was dropped on Hiroshima City. The bomb directly hit the "Hiroshima Prefectural Industrial Promotion Hall," located in the central part of Hiroshima City. This promotion hall is now known as the "Atomic Bomb Dome." It is the only building that remains standing among those damaged by the atomic bomb. The Atomic Bomb Dome was registered as a UNESCO World Heritage Site in 1996.)</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</article>
</div>

</div>


<div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated on Wed Dec 14 18:01:44 2022 by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button></body></html>