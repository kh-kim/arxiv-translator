# 언어 모델을 위한 합성 데이터에 대한 모범 사례 및 교훈

Ruibo Liu1

Jerry Wei1

Fangyu Liu1

Chenglei Si2

Yanzhe Zhang3

Jimmeng Rao1

Steven Zheng1

Daiyi Peng1

Diyi Yang2

데니 저우원 앤드류 M 다이원

1구글 딥마인드, 2스탠포드대학교, 3조지아공과대학

###### Abstract

AI 모델의 성공은 데이터 부족, 개인 정보 보호 문제 및 높은 비용으로 인해 얻기 어려울 수 있는 크고 다양하며 고품질 데이터 세트의 가용성에 달려 있다. 합성 데이터는 실제 패턴을 모방한 인공 데이터를 생성함으로써 유망한 솔루션으로 부상했다. 이 논문은 합성 데이터 연구의 개요와 응용, 과제 및 향후 방향에 대해 논의한다. 우리는 그 효과를 입증하기 위해 선행 기술의 경험적 증거를 제시하고 사실성, 충실성 및 편향성 보장의 중요성을 강조한다. 우리는 보다 강력하고 포괄적이며 신뢰할 수 있는 언어 모델을 구축하기 위해 합성 데이터를 책임감 있게 사용할 필요성을 강조한다.

## 1 Introduction

도 1: Imagen(Saharia et al., 2022a) v2.0에 의해 생성된 하나의 합성 이미지는 다음과 같은 설명을 포함하는 프롬프트와 함께: “_로봇 공장에서, 휴머노이드 로봇들은 조립 라인 상에서 협업하여 새로운 로봇들을 설계, 제작, 테스트 및 조립한다. 그들이 제조하고 있는 새로운 로봇들은 그들을 만들고 있는 로봇 작업자들과 유사하게 보인다. _ 미적 고려 사항에서 텍스트를 제어하는 몇 가지 스타일을 추가했습니다.

인공지능(AI) 기술의 급속한 발전은 보조 에이전트(예: ACT-1, Adept AI1) 및 소프트웨어 개발(예: 데빈, 인지 Lab2)에서 의료(Singhal 등, 2022) 및 금융(Zheng 등, 2022)에 이르기까지 수많은 도메인에 걸쳐 광범위한 채택으로 이어졌다. 그러나 AI 모델의 성공은 훈련 및 평가를 위한 크고 다양하며 고품질 데이터 세트의 가용성에 크게 의존한다. 이러한 데이터 세트를 획득하는 것은 데이터 희소성(Babbar and Scholkopf, 2019), 프라이버시 문제(Abay et al., 2019), 및 데이터 수집 및 주석의 순수한 비용(Gilardi et al., 2023)으로 인해 상당한 도전이 될 수 있다. 비관론자들은 2050년에 새로운 텍스트 데이터와 2060년에 이미지 데이터가 고갈될 것이라고 예측한다(Villalobos et al., 2022).

각주 1: ACT-1: [https://www.adept.ai/blog/act-1](https://www.adept.ai/blog/act-1)

각주 2: Devin: [https://www.cognition-labs.com/introducing-devin](https://www.cognition-labs.com/introducing-devin)

합성 데이터는 이러한 문제를 해결하기 위한 유망한 솔루션으로 등장했다(니콜렌코, 2021). 합성 데이터는 실세계 데이터의 특성과 패턴을 모방한 인공적으로 생성된 데이터를 의미하지만, 인간이 직접 생성하는 것이 아니라 알고리즘(Saxton et al., 2019), 생성 모델(Borisov et al., 2022; Meng et al., 2022), 또는 시뮬레이션(Liu et al., 2023; Vezhnevets et al., 2023)을 통해 생성된다. 합성 데이터를 활용함으로써 실세계 데이터의 한계를 극복할 수 있을 뿐만 아니라 보다 견고하고 신뢰할 수 있으며 공정한 AI 모델을 개발할 수 있는 가능성을 열어줄 수 있다(Lu et al., 2023; Lucini, 2021).

합성 데이터의 많은 이점 중 하나는 대규모로 생성될 수 있어 AI 모델에 대한 훈련 및 테스트 데이터를 풍부하게 제공할 수 있다는 것이다. 이는 실세계 데이터가 부족하거나 얻기 어려운 도메인에서 특히 유용하다(예를 들어, 모든 조건을 커버하는 기상 데이터(Lam 등, 2023; Li 등, 2023)). 둘째, 합성 데이터는 제어된 변형(예를 들어, 다국어 언어 학습(Przystupa and Abdul-Mageed, 2019))을 도입함으로써 상이한 클래스의 균형 잡힌 표현을 보장하는 것과 같은 특정 요건에 맞춰질 수 있다. 이러한 데이터 특성에 대한 통제 수준은 모델 성능 및 일반화를 향상시킬 수 있다. 셋째, 합성 데이터는 민감한 개인 정보를 포함하지 않는 익명화되거나 비식별화된 데이터 세트를 생성함으로써 프라이버시 우려를 완화하는데 도움을 줄 수 있다(El Emam et al., 2020; Howe et al., 2017). 이는 환자의 프라이버시가 가장 중요한 의료와 같은 영역에서 중요하다(Dahmen and Cook, 2019; Wei et al., 2019).

그 약속에도 불구하고 합성 데이터는 해결해야 할 과제도 제시한다. 그 중 하나는 합성 데이터의 사실성과 충실도를 보장하는 것이다(Heusel et al., 2017; Wood et al., 2021), 거짓, 환각 또는 편향된 합성 데이터에 대해 훈련된 모델이 실제 시나리오로 일반화하는 데 실패할 수 있기 때문이다(Guamera et al., 2020; Van Breugel et al., 2023). 연구자들은 실제 데이터에서 발견되는 복잡한 패턴과 관계를 정확하게 반영하는 합성 데이터를 만들기 위해 정교한 생성 모델과 평가 메트릭을 개발해야 한다. 또 다른 과제는 신중하게 설계되고 검증되지 않으면 합성 데이터가 편향을 증폭하거나 새로운 편향을 도입할 수 있는 가능성이다(Barbierato et al., 2022; Gupta et al., 2021). 우리는 이러한 위험을 완화하기 위해 엄격한 테스트와 공정성 평가가 필요하다고 믿는다.

본 논문에서는 합성 데이터 연구의 현재 상태를 추적하고 현재 모범 사례와 배운 교훈에 대해 논의한다. 나머지 논문은 다음과 같이 정리되어 있다. 섹션 2에서는 합성 데이터 생성 기술과 모델 훈련에서의 적용에 대한 개요를 제공하여 사례 연구와 경험적 증거를 제시한다. 3절에서는 평가에서 합성 데이터의 유용성에 대해 논의한다. 4절에서는 합성 데이터의 도전과 한계에 대해 논의하고 5절에서는 잠재적인 해결책과 향후 연구 방향에 대해 설명한다.

## 2 학습용 합성 데이터

실제 세계에서 수집된 실제 데이터를 모방하여 생성되는 합성 데이터는 실제 데이터의 효과적이고 비교적 저렴한 대안으로 입증되었다. 이 섹션에서는 합성 학습 데이터를 활용하는 몇 가지 주목할 만한 도메인을 탐색합니다.

### Reasoning

최근 언어 모델(LMs)에 대한 수학적 추론의 발전은 수학 관련 과제에 대한 성능을 향상시키기 위한 다양한 접근법의 개발로 이어졌다. 하나의 접근법은 미네르바(Lewkowycz et al., 2022), Llemina(Azerbayev et al., 2023), 및 DeepSeeKMath(Shao et al., 2024)와 같은 수학-타겟화된 사전-트레이닝 데이터에 대해 트레이닝하는 것이다. 또 다른 주류 방법은 목표 벤치마크의 훈련 또는 검증 세트를 모방하기 위해 합성 질문 및 답변을 생성하는 것이다. 예를 들어, WizardMath(Luo et al., 2023)는 일련의 연산을 활용하여 GPT-3.5를 사용하여 질문 및 답변의 복잡성을 증가시키는 반면, MetaMath(Yu et al., 2023)는 MATH 및 GSM8K에서 질문을 의미적 재표현, 자기 검증 및 역방향 추론과 같은 상이한 방식으로 재작성함으로써 부트스트랩한다. GAIR-Abel (Chern et al., 2023)은 질문의 패러프레이징으로 시작하는 답변과 바닐라 형식의 답변보다 더 나은 성능을 보여주는 단계적 솔루션으로 시작하는 답변과 함께 증강된 답변의 형식이 최종 성능에 중요하다는 것을 발견했다. Xwin-Math (Li et al., 2024)는 합성 SFT 데이터를 백만 개의 예들로 추가로 스케일링하고 LLaMA-2 7B 모델 (Touvron et al., 2023)이 여전히 데이터 스케일링으로부터 이익을 얻을 수 있다는 것을 발견하였다. MMIQC(Liu and Yao, 2024)는 OpenWebMath(Paster et al., 2023)와 같은 고품질 수학적 사전 훈련 데이터의 하위 집합과 함께 SFT 스타일 데이터를 주입(질답 재구성을 통해 또는 MetaMath에서 직접 가져온) 데이터 세트의 번들을 구성했다.

합성 수학 데이터의 생성을 확대하는 것은 간단한 과정이지만, 생성된 수학의 정확성을 보장하는 것은 실무자들에게 여전히 중요한 과제로 남아 있다. AlphaGeometry (Trinh et al., 2024)는 1억 개의 합성 데이터 포인트를 사용하여 신경망 모델을 트레이닝함으로써 이 문제를 해결하려는 최근의 시도이다. 이 모델은 복잡한 기하학 문제를 해결할 때 각 분기의 정확성을 검증하는 데 있어 솔루션을 제안하고 기호 추론 엔진을 안내한다. 알파기하학은 합성 데이터의 힘을 엄격한 검증 과정과 결합함으로써 인간 올림피아드 금메달리스트에 버금가는 문제 해결 능력을 달성하여 복잡한 수학적 추론 과제를 해결하는 데 있어 이 접근법의 잠재력을 보여준다.

코드.수학과는 달리 코드 추론을 위한 합성 데이터는 올바른 코드의 한 가지 요구 사항이 실행되고 있기 때문에 실행 결과를 구조화된 코드와 자연스럽게 결합할 수 있다. 코딩 강화 모델들에서, CodeRL(Le et al., 2022)은 합성 코드 샘플들 상의 피드백 신호들을 갖는 사전 트레이닝된 언어 모델들을 개선하기 위한 액터-크리틱 접근법을 제시한다. Haluptzok et al.(2022)은 모델들이 그들만의 합성 퍼즐-솔루션 쌍을 생성하는 자기계발 전략을 제안한다. 그런 다음 이러한 쌍은 언어 모델을 미세 조정하기 위해 사용되기 전에 실제 인터프리터에 의해 검증되고 필터링된다. Shypula et al.(2023)은 코드 최적화를 위한 자체 개선 합성 데이터 생성 및 CoT 프롬프트와 같은 시뮬레이션 환경 및 적응 전략을 활용하는 프레임워크를 추가로 제안한다. Yang et al.(2024)은 강화 학습 환경 내에서 상호 작용 코드 생성을 강화하도록 설계된 프레임워크인 InterCode를 개발하였는데, 여기서 코드는 행동 역할을 하고 실행 피드백은 관찰 역할을 한다. 반사(Shinn et al., 2024)는 언어 모델의 코드 추론 능력을 향상시키기 위해 외부 또는 내부 시뮬레이션된 언어 피드백 신호를 채용한다. 합성 SFT 데이터와 관련하여, 코드 알파카는 21개의 시드 작업에 걸쳐 SELF-INSTRUCT(Wang et al., 2022)를 ChatGPT에 적용함으로써 자동으로 생성된 20K 코드 명령들의 데이터세트를 포함한다. WizardCoder (Luo et al., 2023)는 합성 데이터의 복잡성과 다양성을 향상시키기 위해 휴리스틱 프롬프트를 갖는 ChatGPT를 가이드하기 위한 코드 Evol-Instruct를 도입한다. 한편, Magicoder (Wei et al., 2023c)는 오픈 소스 코드 조각으로부터 75K개의 다양한 합성 명령어 샘플을 생성하는 OSS-INSTRUCT를 개발했다.

다른 추론 작업.합성 데이터는 또한 다른 추론 작업에서 인상적인 성능으로 이어진다. 예를 들어, Wei et al.(2023a)은 자연어 레이블을 임의의 기호로 대체하여 500k 이상의 합성예제를 생성함으로써 기존의 자연어 데이터셋을 증강하였다. 이러한 합성 데이터를 지도 미세 조정에 사용하면 보이지 않는 상황 내 학습 및 알고리즘 추론 작업에서 모델 성능이 크게 향상되었다. STaR(Zelikman et al., 2022)은 합성 연쇄 사상 근거를 생성하고, 그들의 추론을 개선하기 위해 미세 조정 언어 모델에 대한 오답으로 이어지는 것들을 걸러낸다. 물리학 추론 영역에서 Mind's Eye (Liu et al., 2022)는 합성 "text-description \(\rightarrow\) 렌더링 코드" 데이터를 사용하여 텍스트-코드 모델을 훈련함으로써 새로운 접근법을 취한다. 이것은 모델이 텍스트 질문들을 렌더링 코드로 변환할 수 있게 하고, 그 다음 물리적 엔진(즉, DeepMind MuJoCo(Todorov et al., 2012))에서 실행된다. 렌더링 결과가 맥락에 주입돼 마인드스아이로 무장한 작은 언어 모델도 100배 큰 모델에 버금가는 성능을 낼 수 있다.

### 도구 사용 및 계획

합성 궤적을 통해 도구 사용을 학습한다. 합성 데이터는 또한 실제 인간 도구 사용 데이터를 수집하는 데 시간이 많이 걸릴 수 있고 도구 호출의 실제 분포가 왜곡될 수 있기 때문에 LMs가 시뮬레이션 궤적을 통해 도구 사용 능력을 학습할 수 있도록 하는 강력한 접근법이다. 예를 들어, LaMDA(Thoppilan et al., 2022)는 웹 문서뿐만 아니라 크라우드 워커와 모델 자체 간의 상호 작용 데이터에 대해 학습되었으며 합성 데이터는 적절한 도구에 대한 호출로 주석이 달렸다. 이 훈련 과정을 통해 LaMDA는 산술을 위한 계산기, 실시간 정보 탐색을 위한 검색 엔진, 번역을 위한 기계 번역기를 사용할 수 있는 능력을 개발할 수 있었다. 유사하게, 툴포머(Schick et al., 2024)는 템플릿 생성 데이터에 대한 트레이닝에 의해 호출할 API 및 어떤 인수를 전달할지를 결정하도록 학습하는 반면, Galactica(Taylor et al., 2022)는 API 호출 데이터를 사전 트레이닝 혼합물에 주입한다. ToolApaca (Tang et al., 2023)는 다중 에이전트 시뮬레이션 환경을 구축하고 에이전트가 도구를 반복적으로 선택하고 사용하도록 함으로써 다양한 도구 사용 코퍼스를 자동으로 생성하도록 설계된 새로운 프레임워크이다. 이러한 예는 LM이 도구 사용 능력을 획득하고 다양한 도메인에 걸쳐 추론 능력을 향상시킬 수 있도록 하는 합성 궤적의 잠재력을 보여준다.

합성 환경에서 계획하기 위한 학습. 자율 기계 지능(LeCun, 2022)에서 에이전트의 중요한 특징은 복잡한 작업을 하위 작업으로 분해하고 보상-최적 방식으로 하위 작업을 마무리하는 능력(Kambhampati 등, 2024)을 계획하는 것이다. 합성 데이터는 시뮬레이터로부터 수집된 피드백 신호의 역할을 할 수 있기 때문에 여기에서 귀중한 도구가 될 수 있으며(Park et al., 2023), 이에 대한 학습은 에이전트로 하여금 어포던스들을 인식하게 할 수 있다(Ahn et al., 2022; Liang et al., 2022). 예를 들어, Inner Monologue(Huang et al., 2022)는 시뮬레이션된 환경에 의해 생성된 자연어 형태 피드백을 활용하여 LLM 기반 로봇 계획을 가르친다. 그들은 그러한 피드백이 시뮬레이션된 영역과 실제 영역 모두에서 높은 수준의 명령 완성을 상당히 향상시킨다는 것을 발견했다. 많은 수의 사실적인 계획 태스크들(예를 들어, _"주어진 장면에 매칭하도록 테이블 상의 객체들을 재배열한다."_)을 구성하기 위해, VIMA(Jiang et al., 2022)는 객체들 및 텍스처들의 확장가능한 컬렉션들을 지원하는 VIMA-Bench라는 멀티모달리티 시뮬레이트된 환경을 생성한다. 마인크래프트 게임에서 보이저(Wang et al., 2023)는 합성 환경과 상호작용하기 위해 다수의 GPT-4 기반 에이전트들을 배치하고, 에이전트들이 합성 피드백의 도움으로 새로운 기술들을 더 빠르게 잠금 해제하고 더 효율적으로 계획을 완료할 수 있다는 것을 발견한다.

### Multimodality

시각에서 텍스트로 반전 렌더링.시각 언어 정렬 데이터는 시각 입력을 LLM(일반적으로 비전 인코더를 통해)에 정확하게 접지하는 데 중점을 둡니다. 웹 스크래핑 이미지-캡션 쌍은 CLIP(Radford et al., 2021) 및 ALIGN(Jia et al., 2021) 이후 지난 몇 년 동안 가장 인기 있는 MM 정렬 데이터였다. 그러나 웹 스크래핑된 이미지-텍스트 쌍은 일반적으로 잡음이 많고 거친 입도의 대응만을 가지고 있어 언어에서 이미지의 세부 사항을 접지하기에는 불충분하다. 문서, 화면, 도형 및 다이어그램과 같은 도메인에서 이러한 세밀한 정렬은 이미지 렌더링 엔진으로 구축된 데이터 합성 파이프라인에서 가장 편리하게 얻을 수 있다. Pix2Struct(Lee et al., 2023)는 웹 서버들을 사용하여 HTML 코드를 웹사이트 스크린샷들로 렌더링하고, 트레이닝 태스크는 마스킹된 스크린샷을 전체 HTML 코드로 디레더링하는 것이다. MatCha (Liu et al., 2023b)와 DePlot (Liu et al., 2023a)는 Python plotting library를 이용하여 표 형태의 데이터를 차트로 렌더링하고, 렌더링된 이미지를 주어 코드 및/또는 표 형태의 데이터를 생성함으로써 기초 모델을 사전 학습한다. Si 등(2024) 및 Laurencon 등(2024)은 웹페이지 스크린샷을 코드 구현으로 변환하는 작업을 위해 합성적으로 생성된 HTML 및 CSS 파일을 트레이닝한다. 합성 데이터에 대해 미세 조정된 모델은 인터넷에서 긁어낸 사실적인 데이터에 대해 합리적으로 잘 일반화할 수 있다. Borkman et al.(2021)은 컴퓨터 비전 연구를 돕기 위해 합성 데이터 생성기로 물리 엔진 또는 게임 엔진(예를 들어, Unity)을 사용할 것을 제안한다.

Multi-modality instruction following.Multi-modal LLMs의 다운스트림 애플리케이션은 추론 및 명령어 추종 기능을 필요로 한다. 이러한 데이터는 일반적으로 긴 형태의 질문 응답 쌍이며 인간이 생성하기에는 비용이 많이 든다. LLaVA(Liu et al., 2024b)는 다양하고 긴 형태의 프롬프트-응답 쌍을 기입하기 위해 기존의 이미지 캡션을 사용하여 GPT-4(텍스트 전용 모드에서)를 프롬프트한다. 멀티모달 LLM 트레이닝 동안, 캡션들 및 바운딩 박스 정보가 숨겨질 수 있는 동안 이미지들 및 프롬프트들이 입력으로서 사용된다. 이미지 캡션 외에도, 오브젝트 바운딩 박스(Zhao et al., 2023), OCR(Zhang et al., 2023d) 및 디레더링된 차트들(Carbune et al., 2024; Masry et al., 2023)과 같은 이미지 속성 정보의 다른 소스들은 모두 이미지 속성 + 텍스트 LLM 재작성 합성 데이터 파이프라인과 같은 것에 적합할 수 있다.

### Multilingual

역-번역 증강.많은 다국어 언어 모델들은 데이터 증강 방법으로서 역-번역을 사용하여, 단일 언어 데이터 소스들로부터 합성 병렬 트레이닝 데이터를 생성한다(Bi et al., 2021; Caswell et al., 2019; Liao et al., 2021; Marie et al., 2020; Pham et al., 2021; Sennrich et al., 2016; Xu et al., 2022; Zheng et al., 2020). 예를 들어, Sennrich 등(2016)은 단일 언어 타겟 데이터를 소스 언어 데이터로 역번역하여, 실질적인 번역 작업 개선을 위한 추가적인 병렬 트레이닝 샘플을 제공한다. 연구자들은 또한 역-번역(예를 들어, 빔 탐색, 제약된 샘플링, 제약되지 않은 샘플링)을 위한 상이한 샘플링 방법 및 이들의 비교 효과를 탐색하였다(Edunov et al., 2018; Graca et al., 2019; Sennrich et al., 2016). Xu et al.(2022)은 역변환을 이용한 최적의 NMT 성능을 위해 합성 데이터의 가중치와 품질의 중요성을 강조한다. 그들은 추정된 중요도 가중치와 품질의 균형을 맞추기 위해 검색 방법과 감마 점수 사이의 비율을 최적화하는 방법을 제안한다. 그러나 역번역 기반 합성 데이터 생성에는 몇 가지 제한 사항이 있다. 예를 들어, 합성 데이터의 품질과 다양성은 역번역 방법의 성능에 따라 달라진다. 합성 데이터가 너무 잡음이 많거나 다양하지 않다면, 성능 이득은 제한될 것이다(Chauhan et al., 2022; Epaliyana et al., 2021).

규모로 다국어 질문 및 답변을 생성하는 최근 연구는 다국어 및 교차 언어 질문 답변에서 언어 모델의 성능을 향상시키기 위해 합성 다국어 질문-응답(QA) 쌍의 생성 및 활용을 탐구한다(Abulkhanov et al., 2023; Asai et al., 2021; Chi et al., 2020; Kumar et al., 2019; Li and Callison-Burch, 2023; Riabi et al., 2021). 하나의 접근법은 기존의 단일 언어 질문들 및/또는 답변들을 다른 언어들로 번역하는 것이다(Asai et al., 2021). 다른 하나는 질문 생성(QG) 모델을 사용하여 답변 및/또는 소스 텍스트에 기초하여 교차 언어 방식으로 합성 질문을 생성하는 것을 포함한다(Chi et al., 2020; Kumar et al., 2019; Riabi et al., 2021). 최근의 노력은 또한 더 큰 유연성을 위해 다수의 언어로 질문 및 답변을 공동으로 생성하는 것에 초점을 맞추고 있다(Li and Callison-Burch, 2023; Shakeri et al., 2021). 예를 들어, Shakeri 등(2021)은 QA 생성 태스크와 다국어 마스킹 언어 모델링 태스크의 혼합에 대해 사전 훈련된 다국어 T5 모델(Xue 등, 2020)을 미세 조정하여 다국어로 합성 QA 쌍을 생성한다. 이러한 노력은 일반적으로 합성 QA 쌍에 대해 훈련된 언어 모델이 다국어 QA 및 정보 검색 벤치마크에서 향상된 성능을 입증한다는 것을 보여준다.

### Alignment

수업 팔로잉.합성 데이터는 특히 실제 데이터가 부족하거나 비용이 많이 들거나 얻기 어려운 시나리오에서 교육 수업 팔로잉 모델을 위한 유망한 접근법 역할을 할 수 있다. Self-instruct(Wang et al., 2022a) 및 Stanford Alpaca(Taori et al., 2023)는 둘 다 LLMs를 사용하여 광범위한 시나리오를 다루는 데이터에 후속하는 명령어를 생성한다. 그들은 먼저 "샘플에 따른 시드 지침"의 작은 세트를 선택한 다음 LLM에 더 많은 데모를 생성하기 위해 형식을 모방하도록 요청한다. 이러한 유형의 방법의 한 가지 관심사는 생성된 데이터를 고품질로 유지하는 방법이며, 이는 질의의 복잡성(Liu 등, 2023d), 시맨틱의 다양성(Ding 등, 2023), 및 합성 데이터세트의 스케일(Yuan 등, 2023)을 포함한다. 이를 위해 Xu et al. (2023)은 프롬프트를 통해 간단한 명령어에 복잡성을 추가하는 Evol-Instruct를 제안한다. Mukherjee et al. (2023)은 LLMs을 활용하여 FLAN 데이터셋(Wei et al., 2022)에 고품질 설명 트레이스를 포함하도록 명령 및 응답을 반복적으로 수정하고, 훈련된 모델이 많은 NLP 작업에서 성능이 향상되었음을 발견했다. UltraChat (Ding et al., 2023)은 두 개의 분리된 ChatGPT Turbo API 모델에 의해 생성되는 대규모 및 다중 라운드 합성 대화 데이터 세트이며, 하나는 사용자 역할을 하고 다른 하나는 어시스턴트 역할을 한다. 그들은 실제 인간 사용자 행동을 모방하도록 주의 깊게 설계된 프롬프트로 사용자 모델을 지시한다.

많은 언어 모델들은 명령들을 따르는 방법을 학습하도록 감독된 미세조정되지만, 이러한 행동을 학습함에 있어서, 부주의하게 또한 _sycophantic_(Perez et al., 2023)이 되도록 학습하고, 그 관점이 객관적으로 정확하지 않더라도, 사용자의 관점을 따르도록 그들의 응답들을 조정한다(Wei et al., 2023b). Sharma 등(2024)은 선호 모델들(즉, RLHF 트레이닝에 사용되는 보상 모델) 및 심지어 인간들이 때때로 아첨 반응을 선호한다는 증거를 찾는다. 이러한 측면에서 Wei et al.(2023b)은 합성 데이터를 생성하여 모델이 사용자 의견에 강인하도록 유도하고 이러한 데이터를 고정 프롬프트에 대한 아첨 행동을 줄이기 위해 미세 조정 단계에서 추가한다.

환각 완화.많은 널리 사용되는 언어 모델들은 사용자들과의 상호 작용을 정렬하는 것을 배우기 위해 감독된 미세조정(supervised finetuning; SFT)을 이용한다(Wang et al., 2022b; Zhang et al., 2023b). 특히, 추론 및 정렬과 같은 능력을 향상시킬 수 있는 합성 SFT 데이터를 생성하는 많은 방법들이 존재한다(Wei et al., 2023a,b). 그러나, 이러한 합성 데이터는 자명하지 않은 양의 환각 답변을 포함하거나 모델들이 그들이 답을 알지 못하는 질문에 답하는 것을 배우도록 강요함으로써 언어 모델들로 환각을 유도할 수 있다는 것이 밝혀졌다(Zhang et al., 2023c). 이러한 사례는 합성 데이터가 올바르게 적용되지 않더라도 실제로 언어 모델에서 환각을 증가시킬 수 있음을 보여준다.

한편, 최근의 연구는 합성 데이터를 사용하여 환각을 완화시키는 유망한 결과를 보여주기도 했다. 예를 들어, GPT-4(OpenAI, 2023)는 강화 학습을 수행하기 위해 합성 환각 데이터를 레버리지한 보상 모델을 이용하여 학습되었다(Zhang et al.,2023c). 이 방법은 TruthfulQA (Lin 등, 2022) 데이터 세트 (Zhang 등, 2023c)에서 상당한 성능 향상을 가져왔다. 마찬가지로 Jones et al. (2023)은 환각을 쉽게 평가할 수 있는 합성 작업을 설계했으며, 이 작업을 활용하여 접두사-동조를 통해 연속 후접점을 학습하여 LIM 출력을 최적화했다. Tian et al.(2023)은 자동화된 사실 확인 및 신뢰 점수를 사용하여 모델 응답 쌍의 사실성 점수를 순위화하고, 그 다음 DPO(Rafailov et al., 2023)로 언어 모델을 미세조정하여 사실성을 향상시킨다. 환각을 완화하기 위해 합성 데이터를 사용하는 지속적인 연구는 여전히 제한적이지만 환각을 확장적으로 평가할 수 있는 합성 작업의 부족으로 인해 제한적이다.

공유된 인간 선호도 및 값과 정렬.값 정렬 또는 인간 선호 데이터에 대한 직접 미세 조정은 언어 모델을 정렬하는 간단한 방법이지만 이 방법은 종종 상당한 인간 주석을 필요로 하며, 이는 대규모로 엄청나게 비쌀 수 있다. 추가적으로, 이러한 주석은 특히 품질 스펙트럼의 하단에서 주석이 제대로 달리지 않은 샘플의 경우에 다양한 스타일 및 일관되지 않은 품질을 자주 나타낸다(Gilardi et al., 2023b; Meta, 2023). 이러한 실제적인 과제를 해결하기 위해, "reinforcement learning from human feedback (RLHF)"로 알려진 진보된 기술이 제안되었다(Christiano et al., 2017; Leike et al., 2018; Ouyang et al., 2022). 이 접근법은 LM 생성 정책의 최적화를 안내하는 인간 판단의 대리인 역할을 하도록 인간 데이터로 보상 모델을 훈련시키는 것을 포함한다.

최근의 연구들은 보다 강건한 보상 모델들을 훈련시키기 위해 합성 데이터와 실제 인간 데이터의 혼합을 제안하였다(Gao et al., 2023). 헌법 AI(Bai et al., 2022)는 AI가 생성한 비판과 피드백을 조종하기 위해 작은 원칙 세트를 사용하고, 이러한 합성 데이터를 사용하여 일반적인 RLHF 파이프라인에서 실제 인간 데이터를 대체하는 것을 제안한다. 이 RLAIF(즉, AI 피드백으로부터의 강화 학습) 방법으로 훈련된 모델은 RLHF 기준선과 유사한 강한 성능을 보인다. 일반적으로 합성 데이터는 연구자가 저비용으로 대규모, 다양하고 통제된 훈련 데이터 세트를 생성할 수 있도록 함으로써 인간의 가치 및 선호도 정렬에 대한 강력한 솔루션을 제공한다(Cui et al., 2023; Ganguli et al., 2022). 윤리적 딜레마(Perez et al., 2022), 사회적 상호작용(Liu et al., 2023c), 문화적 규범(Ziems et al., 2023)을 포함하는 광범위한 시나리오를 시뮬레이션함으로써, 합성 데이터는 AI 모델의 인간 가치와의 정렬에 대한 포괄적이고 체계적인 테스트를 가능하게 한다(Askell et al., 2021). 이 접근법은 AI 시스템이 실제 환경에 배치되기 전에 편향(Liu et al., 2021; Ntoutsi et al., 2020), 공정성(Landers and Behrend, 2023; Zhao et al., 2018), 의도하지 않은 결과와 관련된 이슈를 식별하고 완화하는 것을 돕는다(Ye et al., 2024).

그러나, 저충실도의 합성 인간 선호 데이터는 미묘한 인간 판단을 정확하게 반영하는 데 한계가 있을 수 있다는 것을 인정하는 것이 중요하다(Argyle et al., 2023). 결과적으로, 결과 모델들은 "감옥 파괴 공격들" 하에서 덜 견고할 수 있고(Deshpande et al., 2023; Huang et al., 2023a), 안전 훈련을 통해서도 전략적으로 기만적인 행동을 드러낼 수 있다(Everitt et al., 2021; Pan et al., 2022; Steinhardt, 2022). 이러한 위험을 완화하기 위해 연구자들은 인간의 가치와 선호도의 복잡성을 더 잘 포착하는 보다 복잡하고 포괄적인 시나리오를 통합하여 합성 데이터의 품질과 다양성을 지속적으로 개선하고 개선해야 한다. 또한, 합성 데이터를 실제 데이터와 결합하고, 실제와 동기화할 수 있는 대화형 환경에서 합성 데이터를 생성하는 것은 유망한 해결책이다. 효과적인 AI 거버넌스 및 규제의 필요성이 증가함에 따라 합성 데이터는 신뢰, 책임 및 인간의 가치 및 사회적 기대와 일치하는 AI 기술의 개발을 촉진하는 확장 가능한 감독 메커니즘을 가능하게 하는 데 점점 더 중요한 역할을 할 것이다.

## 3 평가용 합성 데이터

합성 데이터는 다양한 관점의 평가에 널리 사용된다:

사실성.AI 시스템은 사실적 지식 또는 데이터에 근거하지 않은 정보 또는 응답을 생성하여 형식적으로 _환각_으로 알려진 오도 또는 허위 콘텐츠를 생성할 수 있다(Ji 등, 2023). 사실성 평가는 AI 시스템의 출력에 있는 지식과 그것의 훈련 데이터 및 지식 베이스가 제공하는 지식의 일관성을 보장하는 것을 목표로 한다(Ji et al., 2023; Zhang et al., 2023c). 초기 통계 기반 환각 평가 방법은 n-gram에 의존하여 입력과 출력 내용 사이의 어휘의 중첩을 직접 계산하였다(Dhingra et al., 2019; Wang et al., 2020). 그러나, 이러한 방법들은 어휘 중첩만을 고려하고 의미론이나 문장 의미를 고려하지 않아(Ji et al., 2023), 보다 복잡한 형태의 환각을 평가하기에 부적합하기 때문에 한계가 있다. 후속 보증 방법들은 통계적 접근법들에서 모델-기반 방법들로 이동하였는데, 이는 토큰-차이-기반 방법들에 비해 더 강건하다(Honovich et al., 2021). 이러한 모델 기반 평가 방법은 전작에 비해 진보된 것이지만 여전히 한계를 가지고 있다. 예를 들어, 모델들은 환각의 정도만을 출력할 수 있고 특정 오류를 정확히 지적하기 위해 고군분투할 수 있다(Falke et al., 2019). Feng et al.(2023a)은 LLMs 생성과 지식 그래프 상의 무작위 보행을 결합하여 그래프 상의 개체 및 관계를 알고 있는 사실성에 대한 합성 평가 데이터를 생성하는 것을 제안한다. Wei et al.(2024)은 LongFact(Long-form Factuality Evaluation)라는 합성 데이터세트를 생성하고 Google Search(Google Search)를 기반으로 자동화된 판단을 위한 LLM을 사용하여 인간 수준의 정확도를 달성했지만 비용이 현저히 낮았다(Min et al., 2023).

Safety.Red teaming은 AI 모델의 안전성 및 견고성을 평가하기 위한 강력한 기술이다(Casper et al., 2023b; Ganguli et al., 2022). 정렬되지 않거나 유해한 출력을 도출하도록 설계된 다양하고 현실적인 시나리오를 생성함으로써(Casper 등, 2023a), 레드 학습은 AI 시스템의 취약점 및 취약점을 노출시킬 수 있다(Perez 등, 2022). 예를 들어, Perez et al.(2023)은 LMs를 사용하여 다른 LMs의 거동을 평가하기 위한 데이터셋을 생성한다. 그들은 결국 154개의 고품질 데이터 세트를 생성하며, 크기가 커질수록 LMs가 악화되는 역 스케일링의 새로운 사례를 발견한다. 휴빙거 등(2024)은 합성 데이터를 활용하여 LMs에 대한 백도어 공격을 대규모로 트리거하며, LMs는 그러한 공격 하에서 기만적인 행동을 나타낼 수 있고 안전에 대한 잘못된 인상을 생성할 수 있으며, 표준 "안전 훈련"은 그러한 기만을 쉽게 제거할 수 없다. 이러한 방법들은 복잡한 문제들 및 보이지 않는 영역들에 대한 인간 감독(Bowman et al., 2022)을 확장하기 위해 AI 보조를 사용하는 것의 실현 가능성을 입증한다.

인간 평가를 보조하는 최근 연구에 따르면, 많은 경우에, 대규모 LMs(LLMs)로부터의 합성 판정은 실제 인간 평가에 대한 적격, 신속, 저비용 대안으로서 작용할 수 있다(Gilardi et al., 2023a). GPT-4를 심사위원으로 사용하여 Alpaca Eval(Li 등, 2023b)과 MT Bench(Zheng 등, 2023)는 LM 기반 ChatBot의 포괄적인 능력을 측정하는 두 가지 인기 있는 벤치마크이다. 코딩 작업에서 합성 환경은 인간이 실행 로그에 대한 실제 실행 및 분석을 통해 평가를 보다 효율적으로 수행할 수 있기 때문에 인간 평가를 돕기 위한 일반적인 선택이다. Gu 등(2024)은 CodeLAMA-34B에 의해 생성된 800개의 파이썬 함수들로 구성된 코드 실행 추론 벤치마크인 CRUXEval을 제안한다. 유사하게, Liu 등(2024a)은 IER(Independent Execution Reasoning),DER(Dependent Execution Reasoning), 및 SR(Specification Reasoning) 상의 LLMs들의 코드 추론 능력들을 측정하기 위한 프레임워크인 CodeMind를 소개한다. 합성 데이터를 기반으로 한 이러한 모든 평가는 실제 인간의 판단과 강한 상관 관계를 보여준다.

## 4 합성 데이터의 문제 및 한계

합성 데이터는 많은 혜택과 응용 프로그램을 제공하지만 사용과 관련된 잠재적인 도전과 한계를 인정하고 해결해야 한다. 이 섹션에서는 합성 데이터를 둘러싼 세 가지 주요 관심사를 조사한다.

합성 데이터의 오용은 잘못된 정보를 확산시킬 수 있다. 합성 데이터의 잠재적인 오용은 AI 시스템의 책임 있는 개발을 보장하기 위해 해결해야 하는 중요한 문제이다. 현재의 AI 모델들은 텍스트(Gemini-Team et al., 2023, 2024), 이미지들(Ramesh et al., 2022; Saharia et al., 2022), 노래들 3, 심지어 비디오들(예를 들어, OpenAI SORA 4)에 이르는 인간-유사 데이터를 생성하는 것이 점점 더 가능해지고 있다. 이는 합성 데이터가 실제 사람을 사칭하거나 여론을 조작하거나 정치적 과정에 영향을 미치는 데 사용될 때 특히 위험할 수 있다. 더욱이, 합성 데이터 기반 잘못된 정보의 보급은 합법적인 정보 소스에 대한 신뢰를 약화시켜, 사람들이 진실과 거짓을 구별하는 것을 점점 더 어렵게 할 수 있다(Byman et al., 2023; Rid, 2020). 이러한 위험을 완화하기 위해서는 연구자, 개발자 및 정책 입안자가 합성 잘못된 정보를 탐지하고 대응하기 위한 강력한 메커니즘을 포함하여 합성 데이터의 윤리적 생성 및 사용을 위한 명확한 지침 및 모범 사례를 수립하는 것이 중요하다(Groh et al., 2022). 이러한 문제를 사전에 해결함으로써 합성 데이터의 이점을 활용하면서 손상 가능성을 최소화할 수 있습니다.

각주 3: Suno AI로 노래 만들기: [https://app.suno.ai/](https://app.suno.ai/)

각주 4: OpenAI Sora: [https://openai.com/research/video-generation-models-as-world-simulators](https://openai.com/research/video-generation-models-as-world-simulators)

합성 데이터는 AI 정렬에 모호성을 유발할 수 있다. AI 모델을 정렬하는 데 합성 데이터의 사용 증가(예: Constitutional AI(Bai et al., 2022))는 상당한 모호성과 불확실성을 도입할 수 있다. AI 정렬의 목표는 AI 시스템이 인간의 가치와 의도와 일치하는 방식으로 행동하도록 하는 것이다. 그러나, 현실 세계 소스들로부터 수집되는 것이 아니라 인공적으로 생성되는 합성 데이터는 인간 가치들 및 선호도들의 뉘앙스들 및 복잡성들을 정확하게 나타내지 않을 수 있다(Zhou et al., 2024). 이러한 불일치는 편향된 데이터(Feng 등, 2023; Liu 등, 2021), 근거 없는 데이터(Liu 등, 2022; Patel and Pavlick, 2022), 또는 실제 시나리오의 잘못된 표현(Ji 등, 2023; Weidinger 등, 2021)으로부터 AI 모델 학습을 유도할 수 있다. 결과적으로, 합성 데이터에 대해 트레이닝된 AI 시스템은 인간의 기대와 잘못 정렬된 행동을 나타낼 수 있고, 잠재적으로 의도하지 않은 결과 또는 심지어 유해한 행동으로 이어질 수 있다(Anderljung et al., 2023; Zou et al., 2023). 더욱이, 합성 데이터에 의해 도입된 모호성은 AI 모델의 의사 결정 프로세스를 해석하고 이해하는 것을 어렵게 할 수 있으며(Lightman 등, 2023), 정렬을 보장하는 작업을 더욱 복잡하게 한다. 이러한 위험을 완화하기 위해 연구자들은 정렬 연구에서 합성 데이터를 사용하는 것의 한계와 잠재적인 단점을 주의 깊게 고려하고 그러한 데이터에 대해 훈련된 AI 모델의 검증 및 테스트를 위한 강력한 방법을 개발하는 것이 중요하다.

합성 데이터를 사용한 훈련은 평가 오염 제거를 더 어렵게 만든다. 모델 훈련에서 합성 데이터를 사용하는 것은 공정한 평가에 상당한 도전을 제기한다. 평가 벤치마크는 종종 코스워크 웹사이트나 포럼과 같은 공개 텍스트 소스를 참조하여 만들어진다. 결과적으로, 공개적으로 이용 가능한 모든 벤치마크 테스트 케이스가 LLMs의 사전 트레이닝 데이터에 때때로 포함될 수 있다는 것은 논쟁의 여지가 있다(Gao et al., 2021; Hoffmann et al., 2022). 합성 데이터의 사용은 이 문제를 완화하기보다는 악화시킨다. 커뮤니티에서는 \(k\) 롱테일 토큰의 확률을 확인하는 _min-k9 prob_(Shi et al., 2023)와 같은 평가 오염을 감지하기 위한 몇 가지 기술을 제안했지만 이러한 토큰 수준 오염 제거 방법은 모델이 합성 데이터로 훈련될 때 부적절한다. 합성 데이터는 벤치마크 데이터의 변경된 버전(Mattern 등, 2023; Oren 등, 2023)을 포함할 수 있으며, 토큰 수준의 오염을 비효율적으로 렌더링한다. 보다 발전된 평가 오염 감지 기술을 개발할 뿐만 아니라 모델 개발자가 자체 및 보호된 평가 벤치마크를 만들고 유지하는 데 투자할 것을 권장한다. 이러한 독점 벤치마크는 누출을 방지하고 평가 프로세스의 무결성을 보장하기 위해 신중하게 보호되어야 한다.

## 미래 작업 5 방향

합성 데이터 분야가 계속 발전함에 따라 향후 연구 개발을 위한 몇 가지 유망한 방향이 있다. 이 섹션에서는 추가 탐사가 필요한 세 가지 핵심 영역을 간략하게 설명한다.

합성 데이터 스케일링.과잉 트레이닝된 많은 작은 언어 모델들(예를 들어, 미스트랄 시리즈 모델들(Jiang et al., 2023), 및 Gemma 시리즈 모델들(Gemma-Team et al., 2024), _inter alia_)의 인상적인 성능은 많은 양의 토큰들(심지어 컴퓨팅-최적 친칠라 법칙을 통과함(Rae et al., 2021))을 갖는 트레이닝의 필요성을 입증한다. 그러나 합성 데이터의 품질이 실제 데이터만큼 일관되지 않을 수 있기 때문에 합성 데이터를 사용한 훈련에 대해 유사한 결론을 가지고 있는지 여부는 여전히 미해결 문제이다(Yu et al., 2024). 향후 연구에서는 합성 데이터에 대한 스케일링 법칙을 조사하고 합성 샘플의 양과 품질 사이의 최적 균형을 결정해야 한다. 이 탐색은 대규모 언어 모델을 훈련하는 데 합성 데이터를 활용하는 가장 효과적인 전략을 이해하는 데 도움이 될 수 있으며, 잠재적으로 더 효율적이고 비용 효율적인 접근법으로 이어질 수 있다(Muennighoff et al., 2024).

합성 데이터의 품질과 다양성을 더욱 향상시킨다. 합성 데이터를 생성하기 위한 기존의 방법이 가능성을 보여주었지만, 실제 데이터를 밀접하게 모방하는 고품질, 귀속된 합성 샘플을 생성하는 측면에서 여전히 개선의 여지가 있다. 향후 연구에서는 생성된 데이터의 특정 속성을 제어하고 조작할 수 있는 새로운 고급 기술(GAN(Generative Adversarial Networks)(Goodfellow et al., 2020) 또는 확산 모델(Ho et al., 2020), _inter alia_)을 기반으로 하여 다양하고 사용자 지정 가능한 합성 데이터 세트를 생성하는 데 중점을 두어야 한다. 또한, 연구자들은 생성된 데이터가 데이터 품질을 유지하면서(예를 들어, 검색 증강 생성(RAG; Retrieval Augmented Generation)을 통해)(Borgeaud 등, 2022; Lewis 등, 2020)) 타겟 도메인에 존재하는 기본 제약 및 패턴을 준수하도록 도메인-특정 지식을 통합할 수 있는 방법을 탐색해야 한다. 귀속 합성 데이터 생성에서 최첨단 기술을 발전시킴으로써, 우리는 의료(예를 들어, 합성 의료 이미지(Frid-Adar et al., 2018; Wei et al., 2019)) 및 금융(예를 들어, 시뮬레이션된 거래 궤적(Zheng et al., 2022))으로부터 사회 과학(Argyle et al., 2023; Park et al., 2023) 등에 이르기까지 다양한 분야에 걸친 프라이버시 보존 분석(Assefa et al., 2020) 및 모델 트레이닝을 위한 새로운 기회를 개방할 수 있다.

고충실도와 보다 효율적인 확장 가능한 감독을 향해.AI 모델이 점점 더 복잡하고 자율적이 됨에 따라, 인간의 감독 또는 실제 데이터(Amodei et al., 2016)에 의존하는 전통적인 감독 방법을 사용하여 그들의 행동을 모니터링하고 평가하는 것이 어려워진다. 향후 연구에서는 이러한 고급 시스템의 고충실도 확장 가능한 감독을 위해 합성 데이터의 사용을 탐구해야 한다. 기존의 방법들은 합성 데이터를 획득하기 위해 토론(Leike et al., 2018), 성찰(Zhang et al., 2023), 또는 수정들(Liu et al., 2023)과 같은 사회적 반복들에서 특정 시나리오를 전형적으로 시뮬레이션하는 반면, 새로운 접근법들은 더 포괄적인 시나리오들 및 더 많은 양식들(Sun et al., 2023)을 커버할 수 있는 반면, 최근의 연구들은 단지 좁혀진(Cheng et al., 2023) 장면들만을 커버하거나 지나치게 단순화된(Zhou et al., 2024) 장면들을 커버할 수 있는 시뮬레이션의 많은 이슈들을 발견했기 때문이다. 앞으로 또 다른 성장 방향은 확장 가능한 감독을 보다 효율적으로 달성하는 방법일 수 있습니다. 합성 데이터 생성을 완전히 제어할 수 있다는 점을 감안할 때 합성 데이터를 적게 사용하여 더 많은 목표 과시를 제공할 수 있습니다. 효과적인 AI 거버넌스 및 규제에 대한 필요성이 증가함에 따라 합성 데이터는 사회의 이익을 위해 AI 기술의 강력하고 책임 있으며 안전한 배치를 촉진하는 보다 신뢰할 수 있는 확장 가능한 감독 메커니즘을 가능하게 하는 데 점점 더 중요한 역할을 할 것이다(Askell 등, 2021; Bowman 등, 2022).

창발적인 자체 개선 능력.우리는 일반적으로 합성 데이터의 생성이 고품질이기 때문에 합성 데이터를 생성할 수 있는 가장 능력 있는 모델을 선택한다. 그러나 흥미로운 질문이 발생한다: 모델은 훈련된 데이터보다 더 나은 합성 데이터를 생성할 수 있으며, 따라서 스스로 개선할 수 있는가? 합성 데이터 생성을 통한 이러한 자기계발 개념은 향후 연구를 위한 흥미진진한 길이다. 모델이 원래의 트레이닝 세트보다 더 높은 품질의 데이터를 생성할 수 있다면, 향상된 합성 데이터로부터 반복적으로 학습함으로써 잠재적으로 자신의 성능을 부트스트랩할 수 있다(Chen 등, 2024). 이러한 자기계발 능력은 시간이 지남에 따라 자신의 기술과 지식을 자율적으로 정교화할 수 있는 보다 진보된 AI 시스템의 출현으로 이어질 수 있다(Burns et al., 2023; Huang et al., 2023). 최근 연구는 이러한 방향으로 고무적인 진전을 보여주고 있지만(Chen et al., 2024; Yuan et al., 2024), 자기 계발의 상한과 그 효과에 대한 근본적인 이유는 여전히 미해결 문제로 남아 있다. 향후 연구에서는 보다 다양한 시나리오에서 합성 데이터 생성을 통한 자기 계발의 이론적 토대와 실제 실현 가능성을 조사하고 필요 조건, 잠재적 한계 및 관련 위험을 조사해야 한다. 창발적인 자기계발 능력의 잠재력을 열어줌으로써, 우리는 보다 적응적이고 효율적이며 자율적인 학습 과정을 가능하게 할 수 있다(LeCun, 2022).

## 6 Conclusion

합성 데이터는 AI 개발에서 데이터 부족, 개인 정보 보호 문제 및 높은 비용의 문제를 해결하기 위한 유망한 솔루션으로 부상했다. 현실적이고 다양한 데이터 세트를 생성함으로써 합성 데이터는 다양한 도메인에 걸쳐 규모 있는 AI 모델의 훈련 및 평가를 가능하게 한다. 우리가 인간 수준 또는 심지어 초인간 수준의 지능에 접근할 때, 모델이 진보하기 위해 평균보다 나은 인간 품질 데이터가 필요하다는 점을 감안할 때 합성 데이터를 얻는 것은 훨씬 더 중요해진다. 그러나 합성 데이터의 사실성, 충실도 및 편향성 부족을 보장하는 것은 여전히 중요한 과제로 남아 있다.

합성 데이터에 대한 향후 연구 방향은 생성 모델의 충실도와 제어 가능성을 개선하고 표준화된 평가 및 오염 프로토콜 및 도구를 개발하는 데 중점을 둘 수 있다. 또한 합성 데이터와 다른 기술의 통합 및 다른 도메인에서의 적용을 탐구할 수 있다. 도전에도 불구하고 인공지능 연구를 발전시키는 데 있어 합성 데이터의 잠재적 이점은 중요하다. 합성 데이터를 책임감 있고 효과적으로 활용함으로써 사회 전반에 이익이 되는 보다 강력하고 포용적이며 신뢰할 수 있는 AI 시스템을 구축할 수 있습니다.

## References

*Abay et al.(2019) N. C. Abay, Y. 주만 Kantarcioglu, B. Thuraisingham, L. 스위니 딥러닝을 사용하여 합성 데이터 공개를 보호합니다. *Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2018, Dublin, Ireland, September 10-14, 2018, Proceedings, Part I 18_, pages 510-526. Springer, 2019.
* Abulkhanov et al. (2019) D. Abulkhanov, N. 소로킨 Nikolenko, V. 말리크 Lapca: 언어 불가지론 사전 훈련과 언어 교차 정렬. "Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval"에서 2098-2102, 2023 페이지.
* Ahn et al. [2022] M. Ahn, A. Brohan, N. Brown, Y. Chebotar, O. Cortes, B. David, C. Finn, K. Gopalakrishnan, K. Hausman, A. Herzog, et al. Do as i can, not as i say: Grounding language in robotic affordances. _ArXiv preprint_, abs/2204.01691, 2022. URL [https://arxiv.org/abs/2204.01691](https://arxiv.org/abs/2204.01691).
* Amodei et al. [2016] D. Amodei, C. Olah, J. Steinhardt, P. Christiano, J. Schulman, and D. Mane. Concrete problems in ai safety. _ArXiv preprint_, abs/1606.06565, 2016. URL [https://arxiv.org/abs/1606.06565](https://arxiv.org/abs/1606.06565).
* Anderljung et al. [2023] M. Anderljung, J. Barnhart, J. Leung, A. Korinek, C. O'Keefe, J. Whittlestone, S. Avin, M. Brundage, J. Bullock, D. Cass-Beggs, et al. Frontier ai regulation: Managing emerging risks to public safety. _ArXiv preprint_, abs/2307.03718, 2023. URL [https://arxiv.org/abs/2307.03718](https://arxiv.org/abs/2307.03718).
* Argyle et al. [2023] L. P. Argyle, E. C. Busby, N. Fulda, J. R. Gubler, C. Rytting, and D. Wingate. Out of one, many: Using language models to simulate human samples. _Political Analysis_, 31(3):337-351, 2023.
* Asai et al. [2021] A. Asai, X. Yu, J. Kasai, and H. Hajishirzi. One question answering model for many languages with cross-lingual dense passage retrieval. In M. Ranzato, A. Beygelzimer, Y. N. Dauphin, P. Liang, and J. W. Vaughan, editors, _Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual_, pages 7547-7560, 2021. URL [https://proceedings.neurips.cc/paper/2021/hash/3df07fdae1ab273a967aaa1d355b8bb6-Abstract.html](https://proceedings.neurips.cc/paper/2021/hash/3df07fdae1ab273a967aaa1d355b8bb6-Abstract.html).
* Askell et al. [2021] A. Askell, Y. Bai, A. Chen, D. Drain, D. Ganguli, T. Henighan, A. Jones, N. Joseph, B. Mann, N. DasSarma, et al. A general language assistant as a laboratory for alignment. _ArXiv preprint_, abs/2112.00861, 2021. URL [https://arxiv.org/abs/2112.00861](https://arxiv.org/abs/2112.00861).
* Assefa et al. [2020] S. A. Assefa, D. Devrovic, M. Mahfouz, R. E. Tillman, P. Reddy, and M. Veloso. Generating synthetic data in finance: opportunities, challenges and pitfalls. In _Proceedings of the First ACM International Conference on AI in Finance_, pages 1-8, 2020.
* Azerbayev et al. [2023] Z. Azerbayev, H. Schoelkopf, K. Paster, M. D. Santos, S. McAleer, A. Q. Jiang, J. Deng, S. Biderman, and S. Welleck. Lemma: An open language model for mathematics. _ArXiv preprint_, abs/2310.10631, 2023. URL [https://arxiv.org/abs/2310.10631](https://arxiv.org/abs/2310.10631).
* Babbar and Scholkopf [2019] R. Babbar와 B. Scholkopf. 데이터 부족, 견고성 및 극도의 다중 레이블 분류입니다. _ Machine Learning_, 108(8):1329-1351, 2019.
* Bai et al. [2022] Y. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, A. Jones, A. Chen, A. Goldie, A. Mirhoseini, C. McKinnon, et al. Constitutional ai: Harmlessness from ai feedback. _ArXiv preprint_, abs/2212.08073, 2022. URL [https://arxiv.org/abs/2212.08073](https://arxiv.org/abs/2212.08073).
* Barbierato et al. [2022] E. Barbierato, M. L. D. Vedova, D. Tessera, D. Toti, and N. Vanoli. A methodology for controlling bias and fairness in synthetic data generation. _Applied Sciences_, 12(9):4619, 2022.
* Bi et al. [2021] W. Bi, H. Li, and J. Huang. Data augmentation for text generation without any augmented data. In _Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)_, pages 2223-2237, Online, 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.acl-long.173. URL [https://aclanthology.org/2021.acl-long.173](https://aclanthology.org/2021.acl-long.173).
* Borgeaud et al. [2021] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. van den Driessche, J. Lespiau, B. Damoc, A. Clark, D. de Las Casas, A. Guy, J. Menick, R. Ring, T. Hennigan, S. Huang,L. Maggiore, C. Jones, A. Cassirer, A. Brock, M. Paganini, G. Irving, O. Vinyals, S. Osindero, K. Simonyan, J. W. Rae, E. Elsen, and L. Sifre. Improving language models by retrieving from trillions of tokens. In K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvari, G. Niu, and S. Sabato, editors, _International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA_, volume 162 of _Proceedings of Machine Learning Research_, pages 2206-2240. PMLR, 2022. URL [https://proceedings.mlr.press/v162/borgeaud22a.html](https://proceedings.mlr.press/v162/borgeaud22a.html).
* Borisov et al.(2022) V. 보리소프 세슬러 리만 Pawelczyk, G. Kasneci. 언어 모델은 현실적인 테이블 형식 데이터 생성자입니다. _ ArXiv preprint_, abs/2210.06280, 2022. URL [https://arxiv.org/abs/2210.06280](https://arxiv.org/abs/2210.06280).
* Borkman et al.(2021) S. Borkman A. Crespi, S. 다카드 강길리 J 호긴스 Y. C. 장민 카말자데, B.리, S. Leal, P. Parisi, C. Romero, W. 스미스 타만 Warren, N. 야다브 통합 인식: 컴퓨터 비전을 위한 합성 데이터를 생성합니다. _ ArXiv preprint_, abs/2107.04259, 2021. URL [https://arxiv.org/abs/2107.04259](https://arxiv.org/abs/2107.04259).
* Bowman et al. (2022) S. R. Bowman, J. Hyun, E. Perez, E. Chen, C. Pettit, S. 하이너 Lukosiute, A. Askell, A. Jones, A. Chen, et al. Measuring progress on scalable oversight for large language models. _ ArXiv preprint_, abs/2211.03540, 2022. URL [https://arxiv.org/abs/2211.03540](https://arxiv.org/abs/2211.03540).
* Burns et al. (2023) C. Burns, P. Izmailov, J. H. Kirchner, B. Baker, L. 가오락 아셴브레너 천아에코핏 Joglekar, J. Leike, et al. Weak-to-Strong Generalization: Eliciting strong capabilities with weak supervision. _ ArXiv preprint_, abs/2312.09390, 2023. URL [https://arxiv.org/abs/2312.09390](https://arxiv.org/abs/2312.09390).
* Byman et al.(2023) D. L. Byman, C. Gao, C. Meserole, and V. 수브라흐마니아인입니다 딥페이크와 국제 분쟁_. 브룩킹스 연구소, 2023년
* Carbune et al.(2024) V. 카부네, H. 만수르, F. 류, R. Aralikatte, G. Baechler, J. Chen, and A. Sharma. 차트 기반 추론: 기능을 lms에서 vlms로 전송합니다. _ ArXiv preprint_, abs/2403.12596, 2024. URL [https://arxiv.org/abs/2403.12596](https://arxiv.org/abs/2403.12596).
* Casper et al.(2023a) S. T. 캐스퍼 부영 이정리 장경 해리하란, D. 해드필드-메넬 특징 합성 도구를 사용한 레드 학습 심층 신경망. 《신경 정보 처리 시스템에 관한 제37차 회의》에서, 2023a.
* Casper et al.(2023b) S. Casper, J. Lin, J. Kwon, G. Culp, and D. Hadfield-Menell. 적색 학습 언어 모델을 처음부터 탐색, 설정, 활용합니다. _ ArXiv preprint_, abs/2306.09442, 2023b. URL [https://arxiv.org/abs/2306.09442](https://arxiv.org/abs/2306.09442).
* Caswell et al.(2019) I. Caswell, C. Chelba, and D. Grangier. 태그된 역 번역입니다. "Proceedings of the Fourth Conference on Machine Translation (제1권: Research Papers)"에서, 53-63 페이지, 피렌체, 이탈리아, 2019. Association for Computational Linguistics. doi: 10.18653/v1/W19-5206. URL [https://aclanthology.org/W19-5206](https://aclanthology.org/W19-5206).
* Chauhan et al.(2022) S. 차우한 삭세나, P. 대니얼 형태학적으로 풍부하고 자원이 적은 언어에 대해 의미적으로 가중된 역 번역을 사용하여 감독되지 않은 신경망 기계 번역을 개선했습니다. _ Neural Processing Letters_, 54(3):1707-1726, 2022.
* Chen et al.(2024) Z. 천영 등현원 지, 큐. 구 셀프 플레이 미세 조정은 약한 언어 모델을 강한 언어 모델로 전환합니다, 2024.
*Cheng et al.(2023) M. 정태 피카르디와 디양 CoMPosT: LLM 시뮬레이션에서 캐리커처를 특성화하고 평가합니다. In H. Bouamor, J. Pino, and K. 발리, 편집자, _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_, pages 10853-10875, Singapore, Dec. 2023년

계산 언어학 협회 doi: 10.18653/v1/2023.emnlp-main.669. URL [https://aclanthology.org/2023.emnlp-main.669](https://aclanthology.org/2023.emnlp-main.669)
* Chern et al.(2023) E. Chern, H. Zou, X. 이종호 Feng, J. Li, and P. Liu. Generative ai for math: Abel. [https://github.com/GAIR-NLP/abel] (https://github.com/GAIR-NLP/abel), 2023.
* Chi et al.(2020) Z. 지락 동필위 왕상욱 마오, 황 사전 교육을 통한 언어 간 자연어 생성 _The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020_, pages 7570-7577. AAAI Press, 2020. URL [https://aaai.org/ojs/index.php/AAAI/article/view/6256](https://aaai.org/ojs/index.php/AAAI/article/view/6256)
* Christiano et al. (2017) P. F. Christiano, J. Leike, T. B. Brown, M. 마틱 레그랑 D. 아모데이요 인간의 기호로부터 심층 강화 학습. 인규언 von Luxburg, S. 벤지오, H. M. 월락, R. Fergus, S. V. N. Vishwanathan, and R. Garnett, editors, _Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA_, pages 4299-4307, 2017. URL [https://proceedings.neurips.cc/paper/2017/hash/d5e2c0adad503c91f91df24d0d0cd4e49-Abstract.html](https://proceedings.neurips.cc/paper/2017/hash/d5e2c0adad503c91f91df24d0d0cd4e49-Abstract.html)
* Cui et al.(2023) G. Cui, L. 원남 딩규야오 주영 니규상 Lu, M. 선 울트라피드백: 고품질 피드백으로 언어 모델을 부스팅, 2023.
* Dahmen and Cook (2019) J. Dahmen and D. Cook. 싱크: 의료 응용 프로그램을 위한 합성 데이터 생성 시스템 _ Sensors_, 19(5):1181, 2019.
* Deshpande et al.(2023) A. Deshpande, V. 무라하리 Rajpurohit, A. Kalyan, K. 나라심한 chatgpt의 독성: 페르소나 할당 언어 모델을 분석 합니다. _ ArXiv preprint_, abs/2304.05335, 2023. URL [https://arxiv.org/abs/2304.05335](https://arxiv.org/abs/2304.05335).
* Dhingra et al.(2019) B. Dhingra, M. 파루키 아파리크 -W. 장다스, 우 코헨 테이블 대 텍스트 생성을 평가할 때 다양한 참조 텍스트를 처리합니다. "Proceedings of the 57th Annual Meeting of the Association of Computational Linguistics"에서, 페이지 4884-4895, Florence, Italy, 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1483. URL [https://aclanthology.org/P19-1483](https://aclanthology.org/P19-1483).
* Ding et al.(2023) N. 딩영 천병수 진진 정승 허진 유명 선, 주 고품질 교육 대화를 확장하여 채팅 언어 모델을 개선합니다. _ ArXiv preprint_, abs/2305.14233, 2023. URL [https://arxiv.org/abs/2305.14233](https://arxiv.org/abs/2305.14233).
* Edunov et al.(2018) S. 에두노프 오트 올리와 D. 그랑지에 역번역 규모의 이해 "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing"에서, 페이지 489-500, 벨기에, 브뤼셀, 2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1045. URL [https://aclanthology.org/D18-1045](https://aclanthology.org/D18-1045).
* El Emam et al.(2020) K. 엘이맘 Mosquera, R. 홉트로프. _ 실용적인 합성 데이터 생성: 프라이버시와 데이터의 광범위한 가용성의 균형을 맞추다_ 2020년 오라일리 미디어
* Epaliyama et al.(2021) K. 에팔리야마 Ranathunga, S. 야야세나 신할라-영어 nmt에 대한 반복 필터링 및 데이터 선택으로 역변환을 개선한다. MERCon (2021 Moratuwa Engineering Research Conference)_에서, 페이지 438-443. IEEE, 2021.
* Everitt et al.(2021) T. 에버릿 허터 Kumar, V. 크라코브나 강화 학습에서 보상 변조 문제 및 해결 방법: 인과 영향 다이어그램 관점. _ Synthese_, 198(Suppl 27):6435-6467, 2021.

* Falke et al. [2019] T. Falke, L. F. R. Ribeiro, P. A. Utama, I. Dagan, and I. Gurevych. Ranking generated summaries by correctness: An interesting but challenging application for natural language inference. In _Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics_, pages 2214-2220, Florence, Italy, 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1213. URL [https://aclanthology.org/P19-1213](https://aclanthology.org/P19-1213).
* Feng et al. [2023a] S. 펭 발라찬드란 배영 츠베트코프 팩트KB: 언어 모델을 사용한 일반화 가능한 사실성 평가는 사실적 지식으로 향상되었습니다. In H. Bouamor, J. Pino, and K. 발리, 편집자, _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_, pages 933-952, Singapore, Dec. 2023a. 계산 언어학 협회 doi: 10.18653/v1/2023.emnlp-main.59. URL [https://aclanthology.org/2023.emnlp-main.59](https://aclanthology.org/2023.emnlp-main.59).
* Feng et al. [2023b] S. 박윤봉 류영 츠베트코프 사전 훈련 데이터에서 언어 모델부터 다운스트림 작업까지: 불공정한 nlp 모델로 이어지는 정치적 편향의 흔적을 추적합니다. _ ArXiv preprint_, abs/2305.08283, 2023b. URL [https://arxiv.org/abs/2305.08283](https://arxiv.org/abs/2305.08283).
* Frid-Adar et al. [2018] M. Frid-Adar, E. Klang, M. Amitai, J. Goldberger, and H. Greenspan. Synthetic data augmentation using gan for improved liver lesion classification. In _2018 IEEE 15th international symposium on biomedical imaging (ISBI 2018)_, pages 289-293. IEEE, 2018.
* Ganguli et al. [2022] D. Ganguli, L. Lovitt, J. Kernion, A. Askell, Y. Bai, S. Kadavath, B. Mann, E. Perez, N. Schiefer, K. Ndousse, et al. Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned. _ArXiv preprint_, abs/2209.07858, 2022. URL [https://arxiv.org/abs/2209.07858](https://arxiv.org/abs/2209.07858).
* Gao et al. [2021] L. Gao, S. Biderman, S. Black, L. Golding, T. Hoppe, C. Foster, J. Phang, H. He, A. Thite, N. Nabeshima, et al. The pile: An 800gb dataset of diverse text for language modeling. _ArXiv preprint_, abs/2101.00027, 2021. URL [https://arxiv.org/abs/2101.00027](https://arxiv.org/abs/2101.00027).
* Gao et al. [2023] L. Gao, J. Schulman, and J. Hilton. Scaling laws for reward model overoptimization. In _International Conference on Machine Learning_, pages 10835-10866. PMLR, 2023.
* Gemini-Team et al. [2023] Gemini-Team, R. Anil, S. Borgeaud, Y. Wu, J.-B. Alayrac, J. Yu, R. Soricut, J. Schalkwyk, A. M. Dai, A. Hauth, et al. Gemini: a family of highly capable multimodal models. _ArXiv preprint_, abs/2312.11805, 2023. URL [https://arxiv.org/abs/2312.11805](https://arxiv.org/abs/2312.11805).
* Gemini-Team et al. [2024] Gemini-Team, M. Reid, N. Savinov, D. Teplyashin, D. Lepikhin, T. Lillicrap, J.-b. Alayrac, R. Soricut, A. Lazaridou, O. Firat, J. Schrittwieser, et al. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. _ArXiv preprint_, abs/2403.05530, 2024. URL [https://arxiv.org/abs/2403.05530](https://arxiv.org/abs/2403.05530).
* Gemma-Team et al. [2024] Gemma-Team, T. Mesnard, C. Hardin, R. Dadashi, S. Bhupatiraju, S. Pathak, L. Sifre, M. Riviere, M. S. Kale, J. Love, et al. Gemma: Open models based on gemini research and technology. _ArXiv preprint_, abs/2403.08295, 2024. URL [https://arxiv.org/abs/2403.08295](https://arxiv.org/abs/2403.08295).
* Gilardi et al. [2023a] F. Gilardi, M. Alizadeh, M. 쿠블리 채팅은 텍스트 주석 작업에서 크라우드 작업자를 능가합니다. _ Proceedings of the National Academy of Sciences_, 120(30):e2305016120, 2023a. doi: 10.1073/pnas.2305016120. URL [https://www.pnas.org/doi/abs/10.1073/pnas.2305016120](https://www.pnas.org/doi/abs/10.1073/pnas.2305016120).
* Gilardi et al. [2020] F. Gilardi, M. Alizadeh, and M. Kubli. Chatgpt outperforms crowd workers for text-annotation tasks. _Proceedings of the National Academy of Sciences_, 120(30):e2305016120, 2023b.
* Goodfellow et al. [2020] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial networks. _Communications of the ACM_, 63(11):139-144, 2020.

* Graca et al. [2019] M. Graca, Y. Kim, J. Schamper, S. Khadivi, and H. Ney. Generalizing back-translation in neural machine translation. In _Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers)_, pages 45-52, Florence, Italy, 2019. Association for Computational Linguistics. doi: 10.18653/v1/W19-5205. URL [https://aclanthology.org/W19-5205](https://aclanthology.org/W19-5205).
* Groh et al. [2022] M. Groh, Z. Epstein, C. Firestone, and R. Picard. Deepfake detection by human crowds, machines, and machine-informed crowds. _Proceedings of the National Academy of Sciences_, 119(1):e2110013119, 2022.
* Gu et al. [2024] A. Gu, B. Roziere, H. Leather, A. Solar-Lezama, G. Synnaeve, and S. I. Wang. Cruxeval: A benchmark for code reasoning, understanding and execution. _ArXiv preprint_, abs/2401.03065, 2024. URL [https://arxiv.org/abs/2401.03065](https://arxiv.org/abs/2401.03065).
* Guarnera et al. [2020] L. Guarnera, O. Giudice, and S. Battiato. Deepfake detection by analyzing convolutional traces. In _Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops_, pages 666-667, 2020.
* Gupta et al. [2021] A. Gupta, D. Bhatt, and A. Pandey. Transitioning from real to synthetic data: Quantifying the bias in model. _ArXiv preprint_, abs/2105.04144, 2021. URL [https://arxiv.org/abs/2105.04144](https://arxiv.org/abs/2105.04144).
* Haluptzok et al. [2022] P. Haluptzok, M. Bowers, and A. T. Kalai. Language models can teach themselves to program better. _ArXiv preprint_, abs/2207.14502, 2022. URL [https://arxiv.org/abs/2207.14502](https://arxiv.org/abs/2207.14502).
* Heusel et al. [2017] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. In I. Guyon, U. von Luxburg, S. Bengio, H. M. Wallach, R. Fergus, S. V. N. Vishwanathan, and R. Garnett, editors, _Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA_, pages 6626-6637, 2017. URL [https://proceedings.neurips.cc/paper/2017/hash/8aid694707eb0fefe65871369074926d-Abstract.html](https://proceedings.neurips.cc/paper/2017/hash/8aid694707eb0fefe65871369074926d-Abstract.html).
* Ho et al. [2020] J. Ho, A. Jain, and P. Abbeel. Denoising diffusion probabilistic models. In H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin, editors, _Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual_, 2020. URL [https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html](https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html).
* Hoffmann et al. [2022] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. de Las Casas, L. A. Hendricks, J. Welbl, A. Clark, et al. An empirical analysis of compute-optimal large language model training. _Advances in Neural Information Processing Systems_, 35:30016-30030, 2022.
* Honovich et al. [2021] O. Honovich, L. Choshen, R. Aharoni, E. Neeman, I. Szpektor, and O. Abend. \(q^{2}\): Evaluating factual consistency in knowledge-grounded dialogues via question generation and question answering. In _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing_, pages 7856-7870, Online and Punta Cana, Dominican Republic, 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.619. URL [https://aclanthology.org/2021.emnlp-main.619](https://aclanthology.org/2021.emnlp-main.619).
* Howe et al. [2017] B. Howe, J. Stoyanovich, H. Ping, B. Herman, and M. Gee. Synthetic data for social good. _ArXiv preprint_, abs/1710.08874, 2017. URL [https://arxiv.org/abs/1710.08874](https://arxiv.org/abs/1710.08874).
* Huang et al. [2023a] F. Huang, H. Kwak, and J. An. 채팅이 인간 주석자보다 나은가요? 암묵적인 혐오 발언을 설명하는 데 채팅의 잠재력과 한계. _ ArXiv preprint_, abs/2302.07736, 2023a. URL [https://arxiv.org/abs/2302.07736](https://arxiv.org/abs/2302.07736).

* Huang et al. (2023) J. Huang, S. 구락 허영 우상욱 왕현유, 한준 대형 언어 모델은 스스로 개선할 수 있습니다. In H. Bouamor, J. Pino, and K. 발리, 편집자, _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_, pages 1051-1068, Singapore, December. 2023b. 계산 언어학 협회 doi: 10.18653/v1/2023.emnlp-main.67. URL [https://aclanthology.org/2023.emnlp-main.67](https://aclanthology.org/2023.emnlp-main.67)
* Huang et al.(2022) W. 황환식 Xiao, H. Chan, J. Liang, P. Florence, A. Zeng, J. Tompson, I. Mordatch, Y. Chebotar, et al. Inner monologue: Embodied reasoning through planning with language models. _ ArXiv preprint_, abs/2207.05608, 2022. URL [https://arxiv.org/abs/2207.05608](https://arxiv.org/abs/2207.05608).
* Hubinger 등 (2024) E. Hubinger, C. Denison, J. Mu, M. 램버트 통민 맥디아미드 지글러 랜함 맥스웰 Cheng, et al. Sleepeper 에이전트: 안전 훈련을 통해 지속되는 기만적인 llms를 훈련합니다. _ ArXiv preprint_, abs/2401.05566, 2024. URL [https://arxiv.org/abs/2401.05566](https://arxiv.org/abs/2401.05566).
* Ji et al.(2023) Z. 지남 이락 프리스크 유동수 Xu, E. Ishii, Y. J. Bang, A. Madotto, and P. Fung. 자연어 생성의 환각에 대한 조사 _ ACM Computing Surveys (CSUR)_, 55(12):1-38, 2023.
* Jia et al.(2021) C. Jia, Y. 양영 샤영 천진 파레크, H.팜, Q.V.레, Y. 성종호 Li, T. 듀렉 시끄러운 텍스트 감독으로 시각 및 시각 언어 표현 학습을 확장합니다. In M. Meila and T. Zhang, editors, _Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event_, Volume 139 of _Proceedings of Machine Learning Research_, pages 4904-4916. PMLR, 2021. URL [http://proceedings.mlr.press/v139/jia21b.html](http://proceedings.mlr.press/v139/jia21b.html)
* Jiang 등(2023) A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. d. l. Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier, et al. Mistral 7b. _ ArXiv preprint_, abs/2310.06825, 2023. URL [https://arxiv.org/abs/2310.06825](https://arxiv.org/abs/2310.06825).
* Jiang et al.(2022) Y. 장갑타 장경왕 두영 천락 아난드쿠마르 페이페이 Zhu, L. 팬 Vima: 멀티모달 프롬프트를 사용한 일반적인 로봇 조작. "NeurIPS 2022 의사 결정 워크샵을 위한 기초 모델"에서, 2022.
* Jones et al. (2023) E. Jones, H. Palangi, C. Simoes, V. 찬드라세카란 무케르지, A. 미트라, A. 아와달라, E. 카마르 2023 합성 작업을 사용하여 언어 모델을 덜 환각적으로 가르칩니다. URL [https://arxiv.org/abs/2310.06827](https://arxiv.org/abs/2310.06827).
* Kambhampati et al.(2024) S. 감함파티 발미캄 관경 스테클리 버마 함비 살디트와 A 머시 Lms는 계획할 수 없지만 llvm-modulo 프레임워크에서 계획하는 데 도움이 될 수 있습니다. _ arXiv preprint arXiv:2402.01817_, 2024.
* Kumar et al.(2019) V. 구마르 Joshi, A. Mukherjee, G. Ramakrishnan, P. Jyothi. 자동 질문 생성을 위한 교차 언어 훈련. "Proceedings of the 57th Annual Meeting of the Association of Computational Linguistics"에서, 페이지 4863-4872, Florence, Italy, 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1481. URL [https://aclanthology.org/P19-1481](https://aclanthology.org/P19-1481).
* Lam et al.(2023) R. 람산체스 곤살레스 윌슨, P. 윈스버거, M. Fortunato, F. Alet, S. 라부리 Ewals, Z. 이튼로젠 Hu, et al. Learning skillful medium-range global weather prediction. _ Science_, 382(6677):1416-1421, 2023.
* Landers and Behrend (2023) R. N. Landers and T. S. Behrend. Ai 감사인을 감사하는 것: 높은 지분 ai 예측 모델에서 공정성과 편향을 평가하기 위한 프레임워크 _ American Psychologist_, 78(1):36, 2023.
* Laurencon 등(2024) H. Laurencon, L. Tronchon, V. 산 웹 사이트 데이터 세트 2024를 사용 하 여 웹 스크린샷을 html 코드로 변환 잠금 해제 합니다. URL [https://arxiv.org/abs/2403.09029](https://arxiv.org/abs/2403.09029).

* Le et al.(2022) H. Le, Y. 왕애드마레 Savarese, and S. C. H. Hoi. 코드: 사전 학습된 모델과 심층 강화 학습을 통해 코드 생성을 마스터합니다. _ Advances in Neural Information Processing Systems_, 35:21314-21328, 2022.
* LeCun(2022) Y. 르쿤 자율 머신 인텔리전스 버전 0.9. 2, 2022-06-27. _Open Review_, 62, 2022.
* Lee et al. (2023) K. 이명 Joshi, I. R. Turc, H. Hu, F. Liu, J. M. Eisenschlos, U. 칸델왈 P. 쇼 -W. 장경수 토타노바 Pix2struct: 시각적 언어 이해를 위한 사전 훈련으로서 스크린샷 파싱. [Machine Learning에 대한 국제 회의]에서 페이지 18893-18912. PMLR, 2023.
* Leike 등 (2018) J. Leike, D. Krueger, T. 에버릿 마틱, 브이 Maini, S. 레그 보상 모델링을 통한 확장 가능한 에이전트 정렬: 연구 방향 _ ArXiv preprint_, abs/1811.07871, 2018. URL [https://arxiv.org/abs/1811.07871](https://arxiv.org/abs/1811.07871).
* Lewis et al.(2020) P. S. H. Lewis, E. Perez, A. Piktus, F. Petroni, V. 카푸킨 고얄 H. 커틀러 루이스 이태 록타셸 리델, 디키엘라 지식 집약적인 NLP 작업을 위한 검색 강화 생성 인현라로셸 란자토 하델 Balcan 및 H. Lin, editors, _Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual_, 2020. URL [https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html](https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html)
* Lewkowycz et al. (2022) A. Lewkowycz, A. Andreassen, D. Dohan, E. Dyer, H. Michalewski, V. Ramasesh, A. Slone, C. Anil, I. Schlag, T. 굿만솔로 Wu, B. Neyshabur, G. Gur-Ari, V. 미즈라 언어 모델을 사용하여 정량적 추론 문제 해결, 2022. URL [https://arxiv.org/abs/2206.14858](https://arxiv.org/abs/2206.14858).
* Li and Callison-Burch (2023) B. Li and C. Callison-Burch. Paxqa: 교육 규모에서 언어 간 질문 응답 예제를 생성합니다. _ ArXiv preprint_, abs/2304.12206, 2023. URL [https://arxiv.org/abs/2304.12206](https://arxiv.org/abs/2304.12206).
*Li 등(2024) C. Li, W. 왕진후 위남 정현호 장현봉 일반적인 7b 언어 모델에는 이미 강력한 수학 기능이 있습니다. _ ArXiv preprint_, abs/2403.04706, 2024. URL [https://arxiv.org/abs/2403.04706](https://arxiv.org/abs/2403.04706).
*Li et al.(2023a) L. 이락 카버, I. 로페즈-고메즈, F. Sha, J. 앤더슨 종자: 일기 예보의 에뮬레이션은 확산 모델과 결합됩니다. _ ArXiv preprint_, abs/2306.14066, 2023a. URL [https://arxiv.org/abs/2306.14066](https://arxiv.org/abs/2306.14066).
*Li et al.(2023b) X. 이태환 장영 두부아 타오리, I. 굴라자니, C. 게스트린, P. 량 및 T. B. 하시모토. Alpaceval: 명령어 후속 모델의 자동 평가자 [https://github.com/tatsu-lab/alpaca_eval] (https://github.com/tatsu-lab/alpaca_eval), 2023b.
* Liang et al.(2022) J. Liang, W. 황환식 Hausman, B. Ichter, P. Florence, A. Zeng. 정책으로 코드: 체화된 제어를 위한 언어 모델 프로그램입니다. _ ArXiv preprint_, abs/2209.07753, 2022. URL [https://arxiv.org/abs/2209.07753](https://arxiv.org/abs/2209.07753).
* Liao et al.(2021) B. Liao, S. Kadivi, S. 휴비타라나 대규모 다국어 기계 번역을 위한 역번역 "Proceedings of the Sixth Conference on Machine Translation"에서, 페이지 418-424, Online, 2021. Association for Computational Linguistics. URL [https://aclanthology.org/2021.wmt-1.50](https://aclanthology.org/2021.wmt-1.50).
* Lightman 등(2023) H. Lightman, V. 고사라주 Burda, H. Edwards, B. Baker, T. Lee, J. Leike, J. Schulman, I. Sutskever 및 K. 코비 차근차근 확인해보겠습니다. _ ArXiv preprint_, abs/2305.20050, 2023. URL [https://arxiv.org/abs/2305.20050](https://arxiv.org/abs/2305.20050).

* Lin et al.(2022) S. Lin, J. Hilton, and O. 에반스 진실 QA: 모델들이 인간의 거짓을 어떻게 모방하는지 측정하는 것. 《제60회 컴퓨터 언어학 협회 연례 회의(제1권: 장문)》에서, 3214-3252쪽, 아일랜드 더블린, 2022. 컴퓨터 언어학 협회. doi: 10.18653/v1/2022.acl-long.229. URL [https://aclanthology.org/2022.acl-long.229](https://aclanthology.org/2022.acl-long.229).
* Liu et al.(2024a) C. Liu, S. D. Zhang, and R. 자바르반드 코드마인드: 코드 추론을 위해 대규모 언어 모델에 도전하는 프레임워크입니다. _ ArXiv preprint_, abs/2402.09664, 2024a. URL [https://arxiv.org/abs/2402.09664](https://arxiv.org/abs/2402.09664).
* Liu et al.(2023a) F. Liu, J. Eisenschlos, F. Piccinno, S. Krichene, C. Pang, K. 이명 조시우 천남 Collier, Y. 알툰 플롯: 플롯 투 테이블 번역에 의한 원샷 비주얼 언어 추론. 계산 언어학 협회의 발견: ACL 2023_, 페이지 10381-10399, 2023a에서.
* Liu et al.(2023b) F. Liu, F. Piccinno, S. Krichene, C. Pang, K. 이명 조시영 알툰 콜리어와 J. 아이젠슐로스 말차: 수학 추론과 차트 디렌더링으로 시각적 언어 사전 훈련을 강화합니다. <계산 언어학 협회 제61차 연례 회의(제1권: 장문)>, 제12756-12770, 2023b쪽.
* Liu and Yao(2024) H. Liu and A. C.-C. 야오 반복적인 질문 구성을 통해 수학 단어 문제를 확장합니다. _ ArXiv preprint_, abs/2401.09003, 2024. URL [https://arxiv.org/abs/2401.09003](https://arxiv.org/abs/2401.09003).
* Liu 등(2024b) H. Liu, C. Li, Q. 우영진 시각적 명령어 튜닝입니다. _ 신경 정보 처리 시스템_, 36, 2024b에서의 진보.
* Liu et al.(2021) R. 류철자, 제이웨이, 기수락 Wang, S. 보소이 강화된 보정을 통해 언어 모델의 정치적 편견을 완화합니다. _30-5차 AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021_, pages 14857-14866. AAAI Press, 2021. URL [https://ojs.aaai.org/index.php/AAAI/article/view/17744](https://ojs.aaai.org/index.php/AAAI/article/view/17744)
* Liu et al.(2022) R. 유재웨이 - Y. 우상욱 Vosoughi, C. Cui, D. Zhou, and A. M. Dai. 마음의 눈: 시뮬레이션을 통한 근거 언어 모델 추론. _ ArXiv preprint_, abs/2210.05359, 2022. URL [https://arxiv.org/abs/2210.05359](https://arxiv.org/abs/2210.05359).
* Liu et al.(2023c) R. 유락 양철자, 장기조, 주동조, A. M. Dai, D. Yang, S. 보소이 시뮬레이션된 인간 사회에서 사회적으로 정렬된 언어 모델을 훈련합니다. _ ArXiv preprint_, abs/2305.16960, 2023c. URL [https://arxiv.org/abs/2305.16960](https://arxiv.org/abs/2305.16960).
* Liu et al.(2023d) W. 류원 정경 허영 장준희 정렬에 좋은 데이터를 만드는 것은 무엇입니까? 명령어 튜닝에서 자동 데이터 선택에 대한 포괄적인 연구 _ ArXiv preprint_, abs/2312.15685, 2023d. URL [https://arxiv.org/abs/2312.15685](https://arxiv.org/abs/2312.15685).
* Lu et al.(2023) Y. 류민 신현왕 Wang, C. van Rechem, W. 웨이 합성 데이터 생성을 위한 기계 학습: 리뷰입니다. _ ArXiv preprint_, abs/2302.04062, 2023. URL [https://arxiv.org/abs/2302.04062](https://arxiv.org/abs/2302.04062).
* Lucini (2021) F. Lucini. 합성 데이터에 대한 실제 거래입니다. _ MIT Sloan Management Review_, 63(1):1-4, 2021.
* Luo et al.(2023) H. Luo, Q. Sun, C. Xu, P. Zhao, J. Lou, C. Tao, X. 겅규 임성호 천덕장 마법사: 강화된 evol-instruct를 통해 대규모 언어 모델에 대한 수학적 추론을 강화합니다. _ ArXiv preprint_, abs/2308.09583, 2023a. URL [https://arxiv.org/abs/2308.09583](https://arxiv.org/abs/2308.09583).

* Luo et al.(2023) Z. 뤄씨쉬피자오큐 선숙 겅우 허창타오 린, 디장 위저드코더: evol-instruct를 사용하여 코드 대용량 언어 모델에 권한을 부여합니다. _ ArXiv preprint_, abs/2306.08568, 2023b. URL [https://arxiv.org/abs/2306.08568](https://arxiv.org/abs/2306.08568).
* Marie et al.(2020) B. Marie, R. 루비노, A 후지타 태그된 역 번역이 다시 검토되었습니다: 왜 그것이 실제로 작동합니까? [컴퓨팅 언어학 협회 제58차 연차 회의]에서, 5990-5997 페이지, 온라인, 2020. 컴퓨팅 언어학 협회. doi: 10.18653/v1/2020.acl-main.532. URL [https://aclanthology.org/2020.acl-main.532](https://aclanthology.org/2020.acl-main.532)
* Masry et al. (2023) A. Masry, P. Kavehzadeh, X. L. Do, E. Hoque, and S. 조티 UniChart: 차트 이해와 추론을 위한 보편적인 비전 언어 사전 훈련 모델. In H. Bouamor, J. Pino, and K. Bali, editors, _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_, pages 14662-14684, Singapore, 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.906. URL [https://aclanthology.org/2023.emnlp-main.906](https://aclanthology.org/2023.emnlp-main.906)
* Mattern et al. (2023) J. Mattern, F. Mireshgallah, Z. 진병섭 Sachan, T. 버그 커크패트릭 이웃 비교를 통해 언어 모델에 대한 멤버십 추론 공격입니다. _ ArXiv preprint_, abs/2305.18462, 2023. URL [https://arxiv.org/abs/2305.18462](https://arxiv.org/abs/2305.18462).
*Meng et al.(2022) Y. 맹진황 장재한 언어 모델을 사용하여 훈련 데이터를 생성하는 것: 제로샷 언어 이해를 위해 _ Advances in Neural Information Processing Systems_, 35:462-477, 2022.
* Meta(2023) Meta. 메타와 마이크로소프트는 차세대 라마를 소개합니다. [https://ai.meta.com/blog/llama-2] (https://ai.meta.com/blog/llama-2), 2023.
* Min et al.(2023) S. 민규 크리슈나 류민 루이스 -t. 고필원 이이어 제틀모이어와 H. 하지시르지 팩트스코어: 긴 형식의 텍스트 생성에서 사실적 정밀도에 대한 세밀한 원자 평가 _ arXiv preprint arXiv:2305.14251_, 2023.
* Muennighoff 등(2024) N. Muennighoff, A. Rush, B. Barak, T. 르 스카오 타지, A. Piktus, S. 피살로 울프, C.A. 라펠 데이터 제한 언어 모델의 크기 조정 _ 신경 정보 처리 시스템_, 36, 2024에서의 진보.
* Mukherjee et al. (2023) S. 무케르지, A. 미트라, G. 자와하르, S. Agarwal, H. Palangi, A. Awadallah. Orca: gpt-4의 복잡한 설명 추적에서 점진적 학습 _ArXiv preprint_, abs/2306.02707, 2023. URL [https://arxiv.org/abs/2306.02707](https://arxiv.org/abs/2306.02707)입니다.
* Nikolenko (2021) S. I. Nikolenko. _ 딥러닝에 대한 합성 데이터_, 볼륨 174. 스프링어, 2021.
* Ntoutsi et al.(2020) E. Ntoutsi, P. Fafalios, U. 가디라주 Iosifidis, W. Nejdl, M. -E. Vidal, S. 루지에리 푸토리니 Papadopoulos, E. Krasanakis, et al. Bias in data-driven artificial intelligence systems -- a introductory survey _ Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery_, 10(3):e1356, 2020.
* OpenAI (2023) OpenAI. Gpt-4 기술 보고서, 2023년
* Oren et al.(2023) Y. 오렌 마이스터 채터지, F. 라드학, T. B. 하시모토 블랙박스 언어 모델에서 테스트 세트 오염을 입증합니다. _ ArXiv preprint_, abs/2310.17623, 2023. URL [https://arxiv.org/abs/2310.17623](https://arxiv.org/abs/2310.17623).
* Ouyang et al.(2022) L. 우양종우 장, 디 알메이다, C. L. 웨인라이트, P. 미쉬킨, C. 장, S. 아가르왈 Slama, A. Ray, J. Schulman, J. Hilton, F. Kelton, L. 밀러 Simens, A. Askell, P. Welinder, P. Christiano, J. Leike, and R. 로우 언어 모델을 훈련하여 인간의 피드백으로 지침을 따르도록 합니다. _ ArXiv preprint_, abs/2203.02155, 2022. URL [https://arxiv.org/abs/2203.02155](https://arxiv.org/abs/2203.02155).

* Pan et al.(2022) A. Pan, K. 바티아와 제이 스타인하르트 보상의 잘못 지정된 효과: 잘못된 정렬 모델을 매핑하고 완화합니다. <제10차 국제학술대회>의 ICLR 2022, Virtual Event, 4월 25일~29일, 2022. OpenReview.net, 2022. URL [https://openreview.net/forum?id=JYtwGwIL7ye](https://openreview.net/forum?id=JYtwGwIL7ye)
* Park 등(2023) J. S. Park, J. O'Brien, C. J. Cai, M. R. Morris, P. Liang, and M. S. Bernstein. 생성 에이전트: 인간 행동의 대화형 시뮬라크라. [사용자 인터페이스 소프트웨어 및 기술에 관한 제36회 ACM 심포지엄 회의록] 1-22, 2023쪽입니다.
*Paster et al.(2023) K. M. D. 산토스, Z. 아제르바예프, J. 바. Openwebmath: 고품질 수학 웹 텍스트의 열린 데이터 세트입니다. _ ArXiv preprint_, abs/2310.06786, 2023. URL [https://arxiv.org/abs/2310.06786](https://arxiv.org/abs/2310.06786).
* Patel and Pavlick (2022) R. Patel과 E. Pavlick 언어 모델을 근거 있는 개념 공간에 매핑합니다. <제10차 국제학술대회>의 ICLR 2022, Virtual Event, 4월 25일~29일, 2022. OpenReview.net, 2022. URL [https://openreview.net/forum?id=gJcEM8sxHK](https://openreview.net/forum?id=gJcEM8sxHK)
* Perez et al.(2022) E. Perez, S. 황환송 차래 Ring, J. Aslanides, A. Glaese, N. 매칼리스, G 어빙 언어 모델을 사용한 빨간색 학습 언어 모델 "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing"에서, 3419-3448 페이지, Abu Dhabi, United Arab Emirates, 2022. Association for Computational Linguistics. URL [https://aclanthology.org/2022.emnlp-main.225](https://aclanthology.org/2022.emnlp-main.225).
* Perez et al.(2023) E. Perez, S. 링거 루코시우트 천응우엔 Heiner, C. Pettit, C. Olsson, S. 건두성 Kadavath, et al. Discovering language model behavior with model-written evaluations. "Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023_, pages 13387-13434. Association for Computational Linguistics, 2023."
*Pham 등(2021) H. Pham, X. 왕영 양규백 메타 역번역 제9회 국제학술대회에서, ICLR 2021, 오스트리아 가상행사, 2021년 5월 3일부터 7일까지. OpenReview.net, 2021. URL [https://openreview.net/forum?id=3jjmdp7Hha](https://openreview.net/forum?id=3jjmdp7Hha)입니다.
* Przystupa and Abdul-Mageed (2019) M. Przystupa와 M. 압둘마지드 역번역과 함께 자원이 적고 유사한 언어의 신경 기계 번역입니다. "Proceedings of the Fourth Conference on Machine Translation (Volume 3: Shared Task Papers, Day 2)_", pages 224-235, Florence, Italy, 2019. Association for Computational Linguistics. doi: 10.18653/v1/W19-5431. URL [https://aclanthology.org/W19-5431](https://aclanthology.org/W19-5431).
*Radford et al.(2021) A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, G. Krueger, and I. Sutskever. 자연어 감독에서 전이 가능한 시각적 모델을 학습합니다. In M. Meila and T. Zhang, editors, _Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event_, volume 139 of _Proceedings of Machine Learning Research_, pages 8748-8763. PMLR, 2021. URL [http://proceedings.mlr.press/v139/radford21a.html](http://proceedings.mlr.press/v139/radford21a.html)
* Rae et al.(2021) J. W. Rae, S. 보르헤오 채광 Millican, J. Hoffmann, F. Song, J. Aslanides, S. 헨더슨 링성 영응러더포드 Hennigan, J. Menick, A. Cassirer, R. Powell, G. v. D. Driessche, L. A. Hendricks, M. 노필수 황, A. Glaese, J. Welbl, S. 다타트리 Huang, J. Uesato, J. Mellor, I. Higgins, A. Creswell, N. McAleese, A. Wu, E. Elsen, S. Jayakumar, E. Buchatskaya, D. Budden, E. Sutherland, K. 시모니안 파가니니 시프레 Martens, X. L. Li, A. Kuncoro, A. Nematzadeh, E. Gribovskaya, D. Donato, A. Lazaridou, A. Mensch, J.-B. 레스피아우 Tsimpoukelli 그리고레프 D.프리츠 소티옥 파자르스카스 폴렌 공도야마 이태환 터지브이 미쿨릭, I. Babuschkin, A. Clark, D. D. L. Casas, A. Guy, C. Jones, J. Bradbury, M. 존슨 B.헥트만 W. 가브리엘 와이딩거 이삭 록하트 오신데로 C. Dyer, Rimell. 비닐스, 케이 에이유브 제이스탠웨이 베넷 D. 하사비스 카부쿠오글루, G. 어빙 크기 조정 언어 모델: 교육 고퍼의 방법, 분석 및 통찰력, 2021. URL [https://arxiv.org/abs/2112.11446](https://arxiv.org/abs/2112.11446)입니다.
* Rafailov et al.(2023) R. 라파일로프, A. 샤르마, E. 미첼, S. 에르몬, C. D. 매닝, C. 핀 직접 선호도 최적화: 언어 모델은 비밀리에 보상 모델입니다. *NeurIPS_, 2023. URL [https://api.semanticscholar.org/CorpusID:258959321](https://api.semanticscholar.org/CorpusID:258959321).
* Ramesh et al.(2022) A. Ramesh, P. Dhariwal, A. Nichol, C. Chu, and M. 첸 클립 레이턴트를 사용한 계층적 텍스트 조건 이미지 생성 _ ArXiv preprint_, abs/2204.06125, 2022. URL [https://arxiv.org/abs/2204.06125](https://arxiv.org/abs/2204.06125).
* Riabi et al.(2021) A. Riabi, T. Scialom R. Keraron, B. Sagot, D. Seddah, J. Staiano. 0-shot 교차 언어 질문 응답을 위한 합성 데이터 증강. "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing"에서, 페이지 7016-7030, Online and Punta Cana, Dominican Republic, 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.emnlp-main.562. URL [https://aclanthology.org/2021.emnlp-main.562](https://aclanthology.org/2021.emnlp-main.562)
* Rid (2020) T. 리드 적극적인 조치: 허위 정보와 정치 전쟁의 비밀 역사_. 파라, 스트라우스, 지루 2020년
* Saharia et al.(2022a) C. Saharia, W. 찬성 삭세나 이종황 가세미푸르 곤티조 로페스, B. 카라골 아얀, T. Salimans, J. Ho, D. J. Fleet, and M. 노루지 진실론적 텍스트-이미지 확산 모델은 언어 이해력이 깊다. In S. 고예조 Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, _Advances in Neural Information Processing Systems_, volume 35, pages 36479-36494. Curran Associates, Inc., 2022a. URL [https://proceedings.neurips.cc/paper_files/paper/2022/file/ec795aeadae0b7d230fa35cbaf04c041-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2022/file/ec795aeadae0b7d230fa35cbaf04c041-Paper-Conference.pdf).
* Saharia et al.(2022b) C. Saharia, W. 찬성 삭세나 이종황 가세미푸르 곤티조 로페스, B. 카라골 아얀, T. Salimans, et al. Photorealistic text-to-image diffusion model with deep language understanding _ Advances in neural information processing systems_, 35:36479-36494, 2022b.
* Saxton et al.(2019) D. Saxton, E. Grefenstette, F. Hill, and P. Kohli. 신경 모델의 수학적 추론 능력을 분석하는 것. 제7회 International Conference on Learning Representations, ICLR 2019, New Orleans, LA, May 6-9, 2019_에서. OpenReview.net, 2019. URL [https://openreview.net/forum?id=H1gR5iR5FX](https://openreview.net/forum?id=H1gR5iR5FX)
* Schick et al.(2024) T. 신준덕 데시 라일레아누 로멜리 함브로 제틀모이어 Cancedda, T. 시알롬 도구 형성기: 언어 모델은 도구를 사용하는 방법을 스스로 가르칠 수 있습니다. _ 신경 정보 처리 시스템_, 36, 2024에서의 진보.
* Sennrich 등(2016) R. 센리히, B. 해도, A. 버치. 단일 언어 데이터로 신경망 기계 번역 모델을 개선합니다. “Proceedings of the 54th Annual Meeting of the Association of Computational Linguistics (제1권: Long Papers)_, pages 86-96, Berlin, Germany, 2016. The Association for Computational Linguistics. doi: 10.18653/v1/P16-1009. URL [https://aclanthology.org/P16-1009](https://aclanthology.org/P16-1009).
* Shakeri et al.(2021) S. 샤케리 Constant, M Kale, L. 쉐 교차언어 독해력을 위한 제로샷 다국어 합성 질의응답 생성 "Proceedings of the 14th International Conference on Natural Language Generation"에서, 35-45페이지, Aberdeen, Scotland, UK, 2021. Association for Computational Linguistics. URL [https://aclanthology.org/2021.inlg-1.4](https://aclanthology.org/2021.inlg-1.4).
* Shao et al.(2024) Z. 소필왕 주락 서정송 장영기 우, 디궈 심층수학: 개방형 언어 모델에서 수학적 추론의 한계를 밀어붙이는 것, 2024.

* Sharma et al.(2024) M. 샤르마 통태 Korbak, D. Duvenaud, A. Askell, S. R. Bowman, E. DURMUS, Z. Hatfield-Dodds, S. R. Johnston, S. M. Kravec, T. 맥스웰 맥캔들리쉬 Ndousse, O. 라우쉬 D. Yan, M. 장, E 페레즈 언어 모델의 아첨을 이해하기 위해서. <표상 학습에 관한 제12차 국제회의> 2024.
* Shi et al.(2023) W. 시아지스 샤영 황동유 Blevins, D. Chen, and L. 제틀모이어 대형 언어 모델로부터 프리트레이닝 데이터를 검출하는 단계, 2023.
* Shinn 등(2024) N. 신빈사 Narasimhan, S. 야오 반사: 언어 강화 학습을 하는 언어 에이전트입니다. _ 신경 정보 처리 시스템_, 36, 2024에서의 진보.
* Shypula 등(2023) A. Shypula, A. Madaan, Y. 정욱 알론 J. 가드너 Hashemi, G. Neubig, P. Ranganathan, O. Bastani, A. Yazdanbakhsh. 성능 향상 코드를 수정합니다. _ ArXiv preprint_, abs/2302.07867, 2023. URL [https://arxiv.org/abs/2302.07867](https://arxiv.org/abs/2302.07867).
*Si 등 (2024)C.Si, Y. 장중 양락 유덕양 Design2code: 프런트 엔드 엔지니어링을 자동화하는 데 얼마나 걸리나요?, 2024. URL [https://arxiv.org/abs/2403.03163](https://arxiv.org/abs/2403.03163).
* Singhal et al.(2022) K. 싱할 아지지 Tu, S. S. Mahdavi, J. Wei, H. W. Chung, N. Scales, A. Tanwani, H. Cole-Lewis, S. Pfohl, et al. Large language models encode clinical knowledge _ ArXiv preprint_, abs/2212.13138, 2022. URL [https://arxiv.org/abs/2212.13138](https://arxiv.org/abs/2212.13138).
* Steinhardt (2022) J. Steinhardt. MI 시스템에는 이상한 실패 모드가 있습니다. [https://bounded-regret.ghost.io/ml-systems-will-have-weird-failure-modes-2/] (https://bounded-regret.ghost.io/ml-systems-will-have-weird-failure-modes-2/), 2022.
* Sun et al.(2023) Z. 선성훈 신성훈 조현리 선창간 - Y. 귀영 -X. 왕영 Yang, et al. 대형 멀티모달 모델과 사실적으로 증강된 rlh를 정렬합니다. _ ArXiv preprint_, abs/2309.14525, 2023. URL [https://arxiv.org/abs/2309.14525](https://arxiv.org/abs/2309.14525).
* Tang et al.(2023) Q. 탕지 등현림 한규 Liang, L. 선 툴랄파카: 3000개의 시뮬레이션 사례가 있는 언어 모델에 대한 일반화된 도구 학습입니다. _ ArXiv preprint_, abs/2306.05301, 2023. URL [https://arxiv.org/abs/2306.05301](https://arxiv.org/abs/2306.05301)입니다.
* Taori et al.(2023) R. 타오리 일굴라자니 장영 두부아, 엑스 리철빈, 피량, 하시모토 Stanford alpaca: 명령어 후속 llama 모델. [https://github.com/tatsu-lab/stanford_alpaca] (https://github.com/tatsu-lab/stanford_alpaca), 2023.
* Taylor et al. (2022) R. 테일러 Kardas G. Cucurull, T. Scialom, A. Hartshorn, E. Saravia, A. Poulton, V. Kerkez, R. 스토닉 갤럭티카: 과학을 위한 대형 언어 모델입니다. _ ArXiv preprint_, abs/2211.09085, 2022. URL [https://arxiv.org/abs/2211.09085](https://arxiv.org/abs/2211.09085).
* Thoppilan et al.(2022) R. 토필란, D. 더 프라이타스, J. 홀, N. A. Kulshreshtha H.-T. Shazeer 정아진 보락 베이커 두영 이희정 메네갈리 황민 크리건, D. 레피킨, J. 진, D. 첸, Y. 서종호 천애로버츠 보즈마 자오영 주창철 장인규 루쉬 Pickett, P. Srinivasan, L. 야, K M. R. 모리스 마이어-헬스턴 도시산토스 Duke, J. Soraker, B. Zevenbergen, V. 프라바카란 디아즈, B. 허친슨 올슨, A. 몰리나, E. 호프만-존, J. Lee, L. 아로요 라자쿠마르 부트리나 램브이 쿠즈미나, J. 펜톤, A. 코헨, R. 번스타인 Kurzweil, B. Aguera-Arcas, C. Cui, M. Croak, E. Chi, Q. 레 람다: 대화 상자 응용 프로그램의 언어 모델입니다. _ ArXiv preprint_, abs/2201.08239, 2022. URL [https://arxiv.org/abs/2201.08239](https://arxiv.org/abs/2201.08239).
* Tian et al. (2023) K. Tian, E. Mitchell, H. Yao, C. D. Manning, and C. Finn. 사실성을 위한 미세 조정 언어 모델입니다. *ICLR_, 2023. URL [https://api.semanticscholar.org/CorpusID:265158181](https://api.semanticscholar.org/CorpusID:265158181).

* Todorov 등(2012) E. Todorov, T. Erez, Y. 타사 Mujoco: 모델 기반 제어를 위한 물리 엔진. *2012 IEEE/RSJ International Conference on Intelligent Robots and Systems_, pages 5026-5033. IEEE, 2012. doi: 10.1109/IROS.2012.6386109.
* Touvron et al. (2023) H. Touvron, L. 마틴 스톤, P. 알버트, A. 알마하이리, Y. 바배이 바슐리코프 P. Bhargava, S. Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. _ ArXiv preprint_, abs/2307.09288, 2023. URL [https://arxiv.org/abs/2307.09288](https://arxiv.org/abs/2307.09288).
* Trinh et al.(2024) T. H. Trinh, Y. Wu, Q. V. Le, H. He 및 T. 룽 인간 시범 없이 올림피아드 기하학을 푸는 것. _ Nature_, 625(7995):476-482, 2024.
* Van Breugel et al.(2023) B. Van Breugel, Z. Qian, M. 반 데 샤르 합성 데이터, 실제 오류: 합성 데이터를 게시하고 사용하는 방법. [Machine Learning에 대한 국제 회의]에서 페이지 34793-34808. PMLR, 2023.
* Vezhnevets 등(2023) A. S. Vezhnevets, J. P. Agapiou, A. Aharon, R. Ziv, J. Matyas, E. A. Duenez-Guzman, W. A. Cunningham, S. 오신데로, D. 카몬, J. Z. 레이보. 생성 에이전트 기반 모델링은 컨코디아를 사용하여 물리적, 사회적 또는 디지털 공간에 기반을 둔 작업입니다. _ ArXiv preprint_, abs/2312.03664, 2023. URL [https://arxiv.org/abs/2312.03664](https://arxiv.org/abs/2312.03664).
* Villalobos et al.(2022) P. Villalobos, J. Sevilla, L. 하태 Mesiroglu Hobbhahn, A. Ho. 데이터가 부족할까요? 기계 학습에서 데이터 세트의 크기 조정 한계에 대한 분석 _ ArXiv preprint_, abs/2211.04325, 2022. URL [https://arxiv.org/abs/2211.04325](https://arxiv.org/abs/2211.04325).
* Wang et al. (2023) G. Wang, Y. 시영 장만드레카르 주락 팬과 아난드쿠마르 보이저: 큰 언어 모델을 가진 개방형 체화된 에이전트입니다. _ ArXiv preprint_, abs/2305.16291, 2023. URL [https://arxiv.org/abs/2305.16291](https://arxiv.org/abs/2305.16291).
* Wang et al.(2022a) X. 왕제웨이, 도슈르만, 큐. 이은치 나랑, 아차우더리, 도주 자기일관성은 언어 모델에서 사고 추론의 사슬을 개선한다. 2022a. URL [https://arxiv.org/abs/2203.11171](https://arxiv.org/abs/2203.11171).
* Wang et al.(2022b) Y. 왕영 고디 Mishra, A. Liu, N. A. Smith, D. Khashabi, H. Hajishirzi. 자체 지침: 언어 모델을 자체 생성 지침과 정렬합니다. volume abs/2212.10560, 2022b. URL [https://arxiv.org/abs/2212.10560](https://arxiv.org/abs/2212.10560).
* Wang et al.(2020) Z. 왕상욱 왕병안, 대유, 천 콘텐츠 매칭 제약 조건을 가진 충실한 신경망 테이블-텍스트 생성을 위해 [컴퓨팅 언어학 협회 제58차 연차 회의]에서 1072-1086 페이지, Online, 2020. 컴퓨팅 언어학 협회. doi: 10.18653/v1/2020.acl-main.101. URL [https://aclanthology.org/2020.acl-main.101](https://aclanthology.org/2020.acl-main.101).
* Wei et al. (2019) J. Wei, A. Suriawinata, L. 베이커스, B 렌, X 유준웨이 하산푸어 대장 조직병리학 이미지에서 데이터 증강을 위한 생성 이미지 번역. 2019년, _신경 정보처리 시스템의 발전_ 에서.
* Wei et al.(2022) J. Wei, M. 보즈마 구아원유 두, A. M. 다이, Q. V. Le. 미세 조정된 언어 모델은 제로 샷 학습자입니다. _The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022._ OpenReview.net, 2022. URL [https://openreview.net/forum?id=gEZrGCozdqR](https://openreview.net/forum?id=gEZrGCozdqR)
* Wei et al. (2023) J. Wei, L. Hou, A. Lampinen, X. 천동황 타이, 엑스 천영 류동주 Ma, Q. V. Le. 기호 튜닝은 언어 모델에서 문맥 내 학습을 향상시킨다. volume abs/2305.08298, 2023a. URL [https://arxiv.org/abs/2305.08298](https://arxiv.org/abs/2305.08298).

* Wei et al. (2023) J. Wei, D. Huang, Y. 루동주, Q. V. Le. 간단한 합성 데이터는 대용량 언어 모델인 2023b에서 아첨을 감소시킨다. URL [https://arxiv.org/abs/2308.03958](https://arxiv.org/abs/2308.03958).
* Wei et al.(2024) J. Wei, C. Yang, X. 송영 류남 허덕천 유덕황, C.두, Q.V.레 대형 언어 모델의 긴 형식 사실성. 2024. URL [https://api.semanticscholar.org/CorpusID:268724304](https://api.semanticscholar.org/CorpusID:268724304).
* Wei et al.(2021) Y. 웨이지 왕재류 Ding, L. 장 매직코더: 소스 코드만 있으면 됩니다. _ ArXiv preprint_, abs/2312.02120, 2023c. URL [https://arxiv.org/abs/2312.02120](https://arxiv.org/abs/2312.02120).
* Weidinger et al.(2021) L. 웨이딩거 J. 멜러 Rauh, C. Griffin, J. Uesato, P.-S. 황민 정민 Glaese, B. Balle, A. Kasirzadeh, et al. Ethical and social risk of harm from language models. _ ArXiv preprint_, abs/2112.04359, 2021. URL [https://arxiv.org/abs/2112.04359](https://arxiv.org/abs/2112.04359).
* Wood et al.(2021) E. Wood, T. Baltrusaitis, C. Hewitt, S. Dziadzio, T. J. Cashman, J. Shotton. 성공할 때까지 가짜로 만들어 합성 데이터만으로 야생에서 얼굴 분석 _2021 IEEE/CVF International Conference on Computer Vision, ICCV 2021, Montreal, QC, Canada, October 10-17, 2021_에서 페이지 3661-3671. IEEE, 2021. doi: 10.1109/ICCV48922.2021.00366. URL [https://doi.org/10.1109/ICCV48922.2021.00366](https://doi.org/10.1109/ICCV48922.2021.00366).
* Xu et al.(2023) C. Xu, Q. 선광 정석 Geng, P. Zhao, J. Feng, C. Tao, D. Jiang. 마법사: 복잡한 지침을 따르도록 대규모 언어 모델에 권한을 부여합니다. _ ArXiv preprint_, abs/2304.12244, 2023. URL [https://arxiv.org/abs/2304.12244](https://arxiv.org/abs/2304.12244).
*Xu et al.(2022) J. Xu, Y. 루안우 비기황 시락 Chen, L. 류 역 번역을 위한 합성 데이터에 대한 것입니다. "Proceedings of the 2022 Conference of the North American Chapter of the Computational Linguistics: Human Language Technologies_", 419-430 페이지, Seattle, United States, 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.32. URL [https://aclanthology.org/2022.naacl-main.32](https://aclanthology.org/2022.naacl-main.32).
* Xue et al.(2020) L. 설남 Constant, A. Roberts, M. 케일 Al-Rfou, A. Siddhant, A. Barua, C. Raffel. mt5: 대규모 다국어 사전 훈련 텍스트 대 텍스트 변환기. _ arXiv preprint arXiv:2010.11934_, 2020.
* Yang et al. (2024) J. Yang, A. Prabhakar, K. Narasimhan, S. 야오 인터코드: 실행 피드백을 사용하여 대화형 코딩을 표준화 및 벤치마킹합니다. _ 신경 정보 처리 시스템_, 36, 2024에서의 진보.
* Ye et al.(2024) J. Ye, S. 이규리 가오영 우규 장태 Gui, X. 황 도구 도구: 도구 학습에서 대규모 언어 모델의 안전 문제를 세 단계에 걸쳐 공개합니다. _ ArXiv preprint_, abs/2402.10753, 2024. URL [https://arxiv.org/abs/2402.10753](https://arxiv.org/abs/2402.10753).
* Yu et al.(2023) L. 유원 장희석 류영 장종택 이아웰러 류 메타매스: 대용량 언어 모델에 대한 자신의 수학적 질문을 부트스트랩합니다. _ ArXiv preprint_, abs/2309.12284, 2023. URL [https://arxiv.org/abs/2309.12284](https://arxiv.org/abs/2309.12284).
* Yu et al.(2024) Y. 유영 장장영 맹애정래트너 Krishna, J. Shen, and C. Zhang. 대용량 언어 모델은 귀속 훈련 데이터 생성기입니다. 다양성과 편견에 대한 이야기입니다. _ 신경 정보 처리 시스템_, 36, 2024에서의 진보.
* Yuan et al.(2024) W. 원룡방 조성훈 수크바토르, J. 쉬, J. 웨스턴 자가 보상 언어 모델입니다. _ ArXiv preprint_, abs/2401.10020, 2024. URL [https://arxiv.org/abs/2401.10020](https://arxiv.org/abs/2401.10020).
* Yuan et al.(2023) Z. 원환위안, C.리, G.동, C.탄, C.주. 대규모 언어 모델을 사용하여 수학적 추론 학습에 대한 관계 확장 _ ArXiv preprint_, abs/2308.01825, 2023. URL [https://arxiv.org/abs/2308.01825](https://arxiv.org/abs/2308.01825).

* Zelikman et al.(2022) E. Zelikman, Y. 우, N. D. 굿맨 스타: 추론과 함께 부트스트래핑 추론. *NeurIPS_, 2022. URL [https://api.semanticscholar.org/CorpusID:247762790](https://api.semanticscholar.org/CorpusID:247762790).
* Zhang et al.(2023a) J. Zhang, X. Xu, S. 뎅 llm 에이전트를 위한 협업 메커니즘 탐색: 사회 심리학적 관점입니다. _ ArXiv preprint_, abs/2310.02124, 2023a. URL [https://arxiv.org/abs/2310.02124](https://arxiv.org/abs/2310.02124).
* Zhang et al.(2023b) S. 장락 동숙 이성훈 장상욱 선성훈 왕재리 허태 장현우 대형 언어 모델에 대한 명령어 튜닝: A survey, 2023b. URL [https://arxiv.org/abs/2308.10792](https://arxiv.org/abs/2308.10792).
* Zhang et al.(2023c) Y. 장영 이락 최동채 유태 푸엑스 황은자오 장영 Chen, et al. Siren's song in the ai ocean: A survey on 환각에 관한 대규모 언어 모델들. _ ArXiv preprint_, abs/2309.01219, 2023c. URL [https://arxiv.org/abs/2309.01219](https://arxiv.org/abs/2309.01219).
* Zhang et al.(2023d) Y. 장락 장재구 주남 립카, D. Yang, T. 선 Llavar: 텍스트가 풍부한 이미지 이해를 위한 향상된 시각적 명령어 튜닝입니다. _ ArXiv preprint_, abs/2306.17107, 2023d. URL [https://arxiv.org/abs/2306.17107](https://arxiv.org/abs/2306.17107).
* Zhao et al. (2023) B. Zhao, B. Wu, and T. 황 Svit: 시각적 명령 튜닝을 확장합니다. _ ArXiv preprint_, abs/2307.04087, 2023. URL [https://arxiv.org/abs/2307.04087](https://arxiv.org/abs/2307.04087).
* Zhao et al.(2018) J. Zhao, T. 왕민 야츠카르 Ordonez, K. -W. 챙 상호참조 해상도의 성별 편향: 평가 및 디바이싱 방법. <Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2(Short Papers)_), pages 15-20, New Orleans, Louisiana, 2018. Association for Computational Linguistics. doi: 10.18653/v1/N18-2003. URL [https://aclanthology.org/N18-2003](https://aclanthology.org/N18-2003).
* Zheng et al.(2023) L. 정우 -L. 장영 성성 장주 우영 장주 임종호 Li, D. Li, E. P. Xing, H. Zhang, J. E. Gonzalez 및 I. Stoica. 2023년, mt-bench와 챗봇의 무대로 판사를 판단합니다.
* Zheng et al.(2022) S. 정아트로트 Srinivasa, D. C. Parkes, and R. 소셔 경제학자: 2단계 심층 다중 에이전트 강화 학습을 통한 과세 정책 설계 _ Science advances_, 8(18):eabk2607, 2022.
* Zheng et al.(2020) Z. 정현주 황락 이희석 다이, 첸 거울-생성 신경 기계 번역. 제8회 국제학술대회에서, ICLR 2020, 에티오피아 아디스아바바, 2020년 4월 26일부터 30일까지. OpenReview.net, 2020. URL [https://openreview.net/forum?id=HkxQRTNYPH](https://openreview.net/forum?id=HkxQRTNYPH)
* Zhou et al.(2024) X. 주종 수태 Eisape, H. Kim, and M. 수액 이게 현실이야? 이거 그냥 판타지야? lms와의 사회적 상호 작용을 시뮬레이션하는 오판의 소지가 있는 성공 ArXiv preprint_, abs/2403.05020, 2024. URL [https://arxiv.org/abs/2403.05020](https://arxiv.org/abs/2403.05020).
* Ziems 등(2023) C. Ziems, J. Dwivedi-Yu, Y. -C. 왕, 에이 헤일레비, 디양 규범 은행: 상황적 사회 규범의 지식 은행입니다. _ ArXiv preprint_, abs/2305.17008, 2023. URL [https://arxiv.org/abs/2305.17008](https://arxiv.org/abs/2305.17008).
* Zou et al.(2023) A. Zou, Zou. Wang, J. Z. Kolter and M. 프레드릭슨 정렬된 언어 모델에 대한 범용 및 전송 가능한 적대적 공격 _ ArXiv preprint_, abs/2307.15043, 2023. URL [https://arxiv.org/abs/2307.15043](https://arxiv.org/abs/2307.15043).
