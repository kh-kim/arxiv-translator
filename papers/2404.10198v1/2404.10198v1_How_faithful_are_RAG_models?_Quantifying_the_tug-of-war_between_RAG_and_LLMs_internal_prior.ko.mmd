# RAG 모델은 얼마나 충실합니까? RAG와 LLMs 내부 사전의 줄다리기 정량화

Kevin Wu

Stanford University

kevinywu@stanford.edu

&Eric Wu

Stanford University

wue@stanford.edu

&James Zou

Stanford University

jamesz@stanford.edu

동일한 기여도를 나타냅니다.

Stanford University

jamesz@stanford.edu

###### Abstract

검색 증강 생성(rerieval augmented generation, RAG)은 종종 환각을 고정하고 대용량 언어 모델(LLM)에 대한 최신 지식을 제공하기 위해 사용된다. 그러나 LLM 단독으로 질문에 잘못 답한 경우 올바른 검색된 콘텐츠를 제공하는 것이 항상 오류를 해결합니까? 반대로, 검색된 콘텐츠가 잘못된 경우, LLM은 잘못된 정보를 무시하는 것을 알고 있는가, 아니면 오류를 요약하는가? 이러한 질문에 답하기 위해 LLM 내부 지식(즉, 이전)과 불일치할 때 설정에서 검색된 정보 간의 줄다리기를 체계적으로 분석한다. GPT-4 및 기타 LLMs는 참조 문서가 있거나 없는 데이터 세트 전체에서 질문 응답 능력에 대해 테스트한다. 예상대로, 정확한 검색된 정보를 제공하는 것은 대부분의 모델 실수를 수정한다(94% 정확도). 그러나 참조 문서가 잘못된 값의 수준이 증가함에 따라 교란될 때 LLM은 내부 사전이 약할 때 잘못된 수정된 정보를 암송할 가능성이 더 높지만 사전이 강할 때 내성이 더 높다. 유사하게, 우리는 또한 수정된 정보가 모델의 이전으로부터 더 많이 벗어날수록 모델이 그것을 선호할 가능성이 낮다는 것을 발견했다. 이러한 결과는 모델의 사전 지식과 참조 문서에 제시된 정보 사이의 근본적인 긴장을 강조한다.

## 1 Introduction

큰 언어 모델들(LLMs)은 강력하지만, 환각에 걸리기 쉽다(Pal et al., 2023; Sun et al., 2024; Ahmad et al., 2023). 또한 훈련 코퍼스에 포함된 지식으로 제한되므로 최근 이벤트 또는 공개적으로 제한된 정보에 대한 쿼리에 응답할 수 없습니다. 검색 증강 생성(RAG)은 LLM 프롬프트에서 관련 검색된 콘텐츠를 제공하는 일반적으로 사용되는 프레임워크이며 모델 정확도를 크게 향상시킬 수 있다(Mao et al., 2020; Chen et al., 2024; Lewis et al., 2020).

ChatGPT(OpenAI, 2023), Gemini(Gemini Team, 2023), Perplexity.ai와 같은 대부분의 상용 LLM은 이미 웹 인터페이스에 일부 버전의 RAG를 사용한다. 예를 들어 ChatGPT는 Bing 검색을 사용하는 반면 Gemini는 Google 검색 결과에 액세스합니다. RAG가 사용자-대면 LLM 시스템들의 디폴트 특징이 빠르게 되었지만, LLM 능력들의 대부분의 평가들은 여전히 비-RAG 대응물들에 대해 수행된다(Zheng et al., 2023). 이는 모델의 기본값 및 RAG 지원 응답이 검색된 콘텐츠의 품질과 정확도에 따라 크게 달라질 수 있기 때문에 문제가 된다. 이 문제는 웹 결과가 지속적으로 변화한다는 것을 고려할 때 더 복잡해지며, 구식, 부정확한 또는 유해한 정보를 포함할 수 있다(Dash et al., 2023; Daws, 2020; Nastasi et al., 2023). 따라서 RAG 지원 LLM 행동에 대한 객관적인 평가는 특히 RAG 시스템이 무수히 많은 도메인에서 사실 정보를 제공하는 데 점점 더 의존하기 때문에 비 RAG 대응물을 벤치마킹하는 것만큼 중요하다.

이 작업에서 우리는 LLM의 내부 지식과 RAG 설정에 제시된 검색된 정보 사이의 긴장을 정량화하는 것을 목표로 한다. 이 두 가지 경쟁력을 구별하기 위해 LLM에 쿼리하여 질문에 답하고 참조 문서에 다양한 섭동을 도입하면서 토큰 확률을 측정한다. 우리의 분석에서는 두 가지 주요 결과를 보여준다.

* LLM이 컨텍스트에서 제시된 검색된 정보를 준수할 가능성(RAG 선호도 비율)은 컨텍스트가 없는 응답에 대한 모델의 신뢰도와 역상관된다(사전 확률).
* 유사하게 LLM은 원래 컨텍스트가 비현실적인 값으로 점진적으로 수정될 때 이전으로 점점 되돌아갑니다.

우리는 이러한 관계가 1200개 이상의 질문에 걸쳐 6개의 다른 도메인 데이터 세트에 대한 분석에서 유지된다는 것을 발견했다. 또한 프롬프트 기술(예: 엄격하게 준수, 느슨하게 준수)의 선택이 이 관계의 기준선과 강도 모두에 영향을 미칠 수 있음을 발견했다. 이러한 결과는 모델의 사전 훈련된 지식과 컨텍스트에서 제공된 검색된 콘텐츠 사이의 LLM에 내재된 긴장을 강조한다.

LLM에서의 환각의 문제는 여러 컨텍스트 및 모델에서 탐구되었다(Ji et al., 2023; Kaddour et al., 2023). 응답으로서, RAG 시스템들은 환각을 감소시키는 것으로 나타났다(Shuster 외, 2021; Kang 외, 2023). 이전 작업들은 다양한 설정들에서 자동화된 RAG 평가 프레임워크들을 탐색하였다(Es et al., 2023; Hoshi et al., 2023; Saad-Falcon et al., 2023; Zhang et al., 2024). 예를 들어, 일부 연구들은 평가자로서 GPT-3.5를 사용함으로써 RAG 시스템들의 충실성, 답변 관련성, 및 컨텍스트 관련성을 평가하기 위해 LLMs들을 사용한다(Es et al., 2023; Saad-Falcon et al., 2023). 또 다른 연구에서, 저자들은 잡음 강건성, 부정적 거절, 정보 통합, 및 반사실적 강건성과 같은 메트릭들을 제안한다(Chen et al., 2024). 여러 연구에 따르면 RAG는 복잡하거나 오판의 소지가 있는 검색 결과가 있을 때 LLM을 오도할 수 있으며 이러한 모델은 올바른 응답이 주어졌을 때에도 여전히 실수를 할 수 있다(Foulds et al., 2024; Shuster et al., 2021). 모델 전적을 이해하는 것과 관련하여, 다른 작업들은 응답들에 대한 LLM의 신뢰도를 평가하기 위해 로그 확률들을 사용하였다(Mitchell et al., 2023; Zhao et al., 2024). 그러나, 지금까지 (로그프로브를 통한) 모델의 신뢰도와 RAG 제공 정보에 대한 모델의 선호도에 대한 체계적인 탐색은 없었다.

그림 1: 각 데이터 세트에 대해 수정된 문서를 생성하는 도식입니다. 질의와 관련된 정보를 포함하는 참조 문서가 있거나 없는 LLM에 질문이 제기된다. 그런 다음 이 문서는 수정된 정보를 포함하도록 교란되고 LLM에 대한 컨텍스트로 제공된다. 그런 다음 LLM이 수정된 정보를 선호하는지 아니면 자체 사전 답변을 선호하는지 관찰한다.

## 2 Methods

우리의 주요 분석은 RAG 문서에 다양한 수준의 섭동을 도입할 때 GPT-4의 RAG 질문 응답 능력을 평가하는 것으로 구성된다. 이 연구를 위해 데이터 세트는 6개의 다른 도메인에 걸쳐 총 1,294개의 질문으로 구성된다. 참조된 경우 사용된 GPT-4 모델은 2024년 3월에 액세스한 _gpt-4-turbo-preview_입니다. GPT3.5(_gpt-3.5-turbo-0125_) 및 Mistral-7B, _Mistral-7B-Instituct-v0.1_의 두 가지 다른 모델에 대해 데이터 세트를 추가로 평가합니다. 이 두 LLM은 (OpenAI 및 Huggingface API를 통해) 모델의 토큰 확률에 액세스할 수 있는 최고 성능의 모델이기 때문에 선택했다. 모든 주요 그림과 표는 GPT-4를 사용한 결과를 보고하며, GPT-3.5 및 미스트랄-7B를 사용한 분석에서는 부록에 보고된다.

그림 2: GPT-4를 사용하여 6개의 QA 데이터 세트에서 RAG 선호도 비율(y축)과 두 특성(x축) 사이의 역 관계를 일관되게 관찰한다. RAG 선호율은 프롬프트에 제시된 정보와 맥락으로 일치하는 응답의 비율로 정의된다. 모델의 사전 응답 확률은 RAG 없이 쿼리된 응답 토큰의 평균 로그 확률로부터 계산된다. 각 쌍의 왼쪽 그림은 RAG 선호율에 대한 사전 확률(10개의 빈으로 그룹화됨)을 가장 적합한 추세선 및 기울기와 함께 시각화합니다. 오른쪽 그림은 RAG 선호율에 대한 참조 정보(수치 데이터 세트(위)의 경우, 추세선과 함께 최대 2개의 로그-폴드 변경), 범주 데이터 세트(아래)의 경우, 총 4개의 수정 범주)로부터의 절대 편차를 시각화합니다. 또한, 상위 및 하위 절반 백분위수는 더 낮은 확률 사전 응답이 더 높은 확률 사전 응답보다 단조적으로 더 낮은 RAG 선호율을 갖는다는 것을 설명하기 위해 오른쪽 그림에 표시됩니다.

### Dataset

우리는 6개의 주제 영역에서 질문을 생성합니다. 많은 질의응답 쌍을 생성하기 위해 콘텐츠 웹페이지의 코퍼스를 추출한 후 GPT-4에 질의하여 텍스트를 기반으로 질문을 생성하고, 질문 생성에 사용된 진실 답변 및 발췌문을 생성한다. 아래 각 데이터 세트에 대해 부록에서 질문을 생성하는 데 사용되는 전체 프롬프트를 제공합니다.

#### 2.1.1 약물 투여량

우리는 처음에 임상의가 널리 사용하는 의료 참조 웹사이트인 UpToDate.com에서 500개의 약물 정보 페이지를 무작위로 샘플링했다. 질문의 범위를 제한하려면 프롬프트에서 답변이 숫자여야 하고 밀리그램으로 지정해야 한다. 지정된 기준(예: 모호한 질문, 잘못된 단위 등)을 충족하지 않는 생성된 질문을 필터링하기 위해 추가 품질 관리 단계를 수행하고 생성된 질문이 모든 기준을 충족하는지 GPT-4에 확인합니다. 이 단계 이후에는 266개의 질문-응답 쌍이 있습니다.

#### 2.1.2 스포츠 통계

우리는 위키피디아.org에서 육상, 역도, 수영, 양궁, 트랙 사이클, 조정, 사격, 쇼트트랙 스피드 스케이팅, 스피드 스케이팅 등 9개 종목에 걸쳐 올림픽 기록 페이지를 뽑았다. 레코드는 테이블 형식으로 추출되며, 이로부터 각 레코드 항목에 대한 질문이 생성된다. 전체적으로 필터링 후 192개의 고유한 질문과 답변을 추출했다.

#### 2.1.3 News

AP통신 RSS 피드에서 03/15/24에서 03/25/24까지의 날짜에 대한 상위 헤드라인을 추출한다. 1486개의 뉴스 기사의 초기 코퍼스로부터 GPT-4를 사용하여 기사당 하나의 질문을 생성하며, 이는 명확한 수치 해답이 있는 질문을 생성하도록 지시한다. 우리는 또 다른 GPT-4 품질 관리 단계를 수행하고 249개의 고유한 질문-응답 쌍을 생성한다.

#### 2.1.4 날짜, 이름 및 도시

우리는 Huggingface의 위키피디아 데이터 세트(20220301.en, (Foundation))에서 1000개의 기사의 무작위 샘플로 시작한다. 우리는 GPT-4를 사용하여 각 분야(날짜, 이름, 도시)와 관련된 질문을 생성하고 발췌문이 문맥에서 정확히 발견되지 않는 응답을 걸러낸다. 진실 답변을 일치시킬 때 모호성을 줄이기 위해 특정 형식에 맞게 답변을 제한한다. 날짜의 경우, 우리는 답변이 네 자릿수 연도(YYYY)를 준수할 것을 요구한다. 이름의 경우, 우리는 이름과 성을 필요로 한다(예를 들어, 조지 워싱턴). 도시들에 대해, 우리는 임의의 다른 신원들(예를 들어, 시애틀이 아닌 시애틀, WA)을 제거한다. 각 도메인에 대해 이러한 기준에 맞는 나머지 질문-응답 쌍 중 평가 세트에 대해 무작위로 200개를 샘플링한다.

### Concordance

우리는 기사 내용을 기반으로 생성된 참조 답변과 해당 생성된 질문에 대한 모델의 답변 간의 일치 또는 일치를 측정한다. 이것은 문맥이 있거나 없는 모델의 답변 모두에 대해 계산된다.

### 검색 문서 수정

우리는 각 질문/응답 쌍에 대해 체계적인 섭동을 수행한다(그림 1에서 시각화된 바와 같이). 수치적 답변을 가진 세 개의 데이터 세트(약물 용량, 스포츠 기록, 최신 뉴스)에서 원본 값에 승수 역할을 하는 10개의 수정을 생성한다: \(0.1,0.2,0.4,0.8,1.2,1.5,2.0,3.0,5.0,10.0\). 위키피디아 년도 데이터 세트에서 우리는 \([-100,100]\) 범위에 대해 20년 단위로 10개의 절대 수정을 수행한다. 위키피디아 이름 및 위치의 경우 개별 범주에는 더 많은 수공예 수준의 변형이 필요했다. 각각에 대해 약간의, 상당한, 코믹의 프롬프트를 통해 세 가지 범주적 섭동을 수행했다. 부록의 연구에 사용된 전체 프롬프트를 제공합니다. 예를 들어 _Bob Green_과 같은 이름의 경우 약간의 수정은 다른 실제 이름(_Rob Greene_)에 대한 작은 수정을 의미하는 반면, 상당한 수정은 유사하지만 가상의 이름(_Bilgorn Grevalle_)을 생성하고 코믹한 수정은 불합리한 변형(_Blob Lawnface_)이다. 마이애미_와 같은 도시 이름의 경우 약간의 수정이 가장 유사한 도시 이름을 변경하고(_Fort Lauderdale_), 상당한 수정이 가상의 도시 이름을 생성하고(_Marisole_), 코믹한 수정이 부조리한 변형(_Miameme_)을 생성합니다. 검색된 텍스트에 각 수정된 사실이 어떻게 나타날 수 있는지에 대한 차이 때문에 GPT-4를 사용하여 약물 투여량과 뉴스에 대한 교란된 발췌문을 생성한다. 수정된 각 팩트는 원래 검색된 텍스트에서 대체됩니다. 그런 다음 질문과 컨텍스트가 모두 GPT-4에 제기되며, 여기서 출력 토큰의 로그 확률과 함께 답변이 수집된다.

### RAG 대 모델 이전 분석

이 연구에서 수행한 주요 분석에서는 모델의 _RAG 선호도_를 내부 사전_과 비교하는 것이다. LLM은 먼저 문맥이 없는 질문으로 질의된다. 이 응답 및 토큰의 평균 확률(로그 프로브를 통해 액세스됨)은 각각 모델의 _사전 응답_ 및 _사전 확률_이라고 합니다. 그런 다음 LLM이 다시 쿼리되며, 이번에는 프롬프트에 검색된 콘텐츠가 표시됩니다. 그런 다음 결과 응답(RAG가 있는 응답)을 이전 응답과 비교합니다. 응답이 이전 응답과 여전히 동일한 경우 모델은 _이전_ 을 선호합니다. 반면에 모델 응답이 검색된 콘텐츠에 있는 정보와 일치하면 모델은 _RAG_를 선호합니다. 각 데이터 세트에 대해 _RAG 선호도 비율_ 은 모든 RAG 쿼리 전체에서 평균으로 계산됩니다.

RAG 선호율은 사전 확률과 사전 값으로부터의 편차의 두 측정치와 비교된다. 전자는 OpenAI API 호출에서 로그 확률에 액세스하여 계산됩니다. 이는 로그 척도로 제공되므로 결과를 제시할 때 선형 확률을 생성하기 위해 지수화한다. 후자는 여러 가지 방법으로 계산된다. 약물 투여량, 스포츠 통계 및 최신 뉴스 데이터 세트의 경우 이전 값과 수정된 값 사이의 절대 로그 배수 변화가 계산되고, 위키피디아 날짜 데이터 세트의 경우 단순 절대 연도 변화가 사용되며, 위키피디아 이름 및 위치 데이터 세트의 경우 각 범주 변화가 수정 정도 순서로 표시된다.

#### 2.4.1 서로 다른 촉진 전략의 효과 분석

프롬핑 기술 자체에 대한 추가 분석이 수행되며, 위의 예에서는 2024년 3월 현재 800k 이상의 다운로드가 있는 인기 있는 LLM 오픈 소스 라이브러리에서 사용되는 RAG 프롬프트를 기반으로 하는 표준 프롬프트 템플릿을 사용한다(LangChain 및 LlamalIndex). 이 템플릿(표준이라고 함) 외에도 검색된 컨텍스트에 대한 문자 그대로의 준수를 강력하게 강제하는 엄격함과 응답하기 전에 모델이 검색된 컨텍스트를 추론하도록 권장하는 느슨함이라는 두 가지 신속한 수정을 추가로 도입한다.

## 3 Results

### Concordance

표 1에서 우리는 모델의 사전 응답이 평균 34.7%의 참조 응답에만 동의한다는 것을 관찰한다. 그러나 RAG 답변은 일치도를 94%로 높였다. 이 결과는 이 작업에서 확립된 RAG 파이프라인이 모델이 검색된 콘텐츠를 준수하도록 장려하는 데 매우 효과적임을 보여준다. 그러나, 검색된 콘텐츠를 제공하는 것이 LLM을 수정하지 못하는 소수의 경우, 우리는 모델이 약 20%의 시간 동안 원래의 사전 답변으로 단순히 응답한다는 것을 발견한다.

### RAG 기본 설정 비율 대. 사전확률

그림 2(왼쪽 그림)에서 모델의 사전 답변의 토큰 확률과 6개의 모든 QA 데이터 세트에 대한 관련 RAG 선호도 비율 사이의 일관된 음의 관계를 관찰한다. 확률에 대한 균등 분포를 시각화하기 위해 \([0.0,1.0]\) 범위의 10개의 등거리 빈으로 확률을 비닝한다. 우리는 또한 표 1의 RAG 선호율에 대해 비닝된 확률 값에 대한 선형 회귀를 수행하여 기울기를 제시한다. 기울기는 검색된 컨텍스트에서 제시된 정보에 대한 모델의 선호도에 대한 더 강한 모델 신뢰도의 영향을 나타내며, 서로 다른 기울기(-0.1에서 -0.45 범위)를 관찰하며, 이는 서로 다른 QA 도메인에서 RAG의 효과가 모델의 내부 사전 지식 신뢰도에 상대적으로 민감하거나(예를 들어, 날짜 질문과 함께) 강건한 것으로 특징지어질 수 있음을 시사한다. 구체적으로 -0.45의 기울기는 예를 들어 모델의 사전 반응 확률이 10% 증가할 때마다 LLM이 상황 정보를 선호할 가능성이 4.5% 감소할 것으로 예상하는 것으로 해석할 수 있다.

#### 3.2.1 RAG Preference Rate vs Deviation from Prior

우리는 또한 모델의 이전 반응과 검색된 컨텍스트에 포함된 값 사이의 편차 정도를 고려한다(그림 2, 오른쪽 그림). 이 분석에서 유사한 패턴이 나타나는데, RAG 값이 모델의 이전과 다르기 때문에 모델은 자체 초기 응답보다 RAG 값을 채택할 가능성이 적다. 우리는 또한 상위 및 하위 절반 백분위수로 분할된 데이터를 플로팅하고 6개의 데이터 세트 모두에 걸쳐 낮은 확률 사전 응답이 높은 확률 응답 토큰보다 단조롭게 낮다는 것을 관찰한다. 따라서 편차와 RAG 응답 속도 사이의 상관 관계는 두 확률 밴드에 걸쳐 유지된다.

#### 3.2.2 프롬프팅 기법의 효과 RAG 준수

특정 프롬프트 기술이 RAG 준수에 미치는 영향 정도를 평가하기 위해 GPT-4에서 두 개의 추가 프롬프트("엄격한" 및 "느슨한")를 테스트한다. 엄격한 프롬프트는 모델의 자체 사전 응답을 무시하도록 강요하기 위한 것이며, 느슨한 프롬프트는

그림 3: 다양한 유형의 컨텍스트 수정에 걸쳐 차등 LLM 응답을 보여주는 세 개의 데이터 세트의 예. 빨간색 응답은 잘못된 응답(답변과 다름)을 나타내고 녹색 응답은 올바른 응답을 나타냅니다.

모델이 자체 사전 정보와 제공된 상황 정보 사이에서 중재하도록 의도되었다. 그림 4에서 엄격한 프롬프트는 표준 프롬프트보다 RAG 준수율이 균일하게 더 높다. 반면에 느슨한 프롬프트는 사전 확률이 증가함에 따라 훨씬 낮은 RAG 준수율을 초래한다. 흥미롭게도 기울기도 더 가파르며, 이는 사전 확률이 증가함에 따라 RAG 선호도가 단위당 더 크게 감소함을 나타낸다. 따라서 프롬프트의 선택은 LLM의 RAG 선호도에 영향을 미치는 중요한 메커니즘이다.

#### 3.2.3 GPT-4, GPT-3.5 및 Mistral-7B 간의 효과 차이

우리는 표 2와 그림 5에서 GPT-3.5와 미스트랄-7B를 사용할 때 동일한 분석을 보고한다. 이전과 RAG의 일치성에서 상당히 낮은 성능을 관찰한다. 그러나 그림 5에서 볼 수 있듯이 GPT-4를 사용한 결과에서 볼 수 있듯이 이 두 모델에서 동일한 역 추세를 관찰한다. 참고로, 일부 데이터 세트(최신 뉴스)는 RAG 없이 성능이 좋지 않다(모델은 대다수의 쿼리를 거부하거나 잘못된 응답을 제공했기 때문에 이전 토큰 확률을 분석할 수 없다). 미스트랄-7B 결과에서 우리는 또한 RAG를 사용한 응답 중 일부가 일관되게 유효한 응답을 제공할 수 없음을 관찰했다.

## 4 Discussion

RAG는 상업적으로 이용 가능한 LLM에서 표준 관행이 되고 있지만 이러한 시스템의 신뢰성은 아직 연구되지 않았다. 우리의 실험은 LLM이 RAG 시스템에 부착되는 정도를 조절하는 여러 메커니즘을 밝혀낸다. 구체적으로, 우리는 모델의 이전 강도와 모델 속도 사이의 줄다리기를 정량화한다.

그림 4: GPT-4를 사용한 다른 프롬프트가 RAG 선호율 대 사전 확률에 미치는 영향. "엄격한" 프롬프트는 검색된 컨텍스트에 대한 문자적 준수를 강력하게 강제하는 반면, "느슨한" 프롬프트는 모델이 제공된 컨텍스트에 비추어 합리적인 판단을 내리도록 권장한다. 느슨한 프롬프트와 엄격한 프롬프트로 RAG 준수의 더 낮고 가파른 감소를 관찰하며, 이는 신속한 표현이 RAG 준수를 제어하는 데 중요한 역할을 함을 시사한다. 전체 프롬프트는 부록에 제공됩니다.

RAG 문서의 사실에 근거한다. 이 효과는 RAG 자체가 환각을 단독으로 고칠 수 있다는 주장과 상충되며 모델이 RAG 문서를 엄격하게 준수하도록 촉구되는 경우에도 발생한다.

RAG 시스템은 사전 지식을 통합하여 빈틈을 메우고 검색된 정보를 추론할 수 있다는 점에서 전통적인 검색 엔진에 비해 독특한 매력을 가지고 있다. 우리는 이것이 절충점과 함께 제공된다는 것을 발견한다 - 즉, 그러한 전과가 문서에 제공된 정보를 무시할 수 있다는 것을. 광범위한 값의 간격에 걸쳐 RAG 문서를 교란할 때 모델이 이전 응답으로 되돌아가는 지점 또는 "팁핑 포인트"는 다른 모델과 도메인에 걸쳐 잠재되고 이질적이다. 강력한 전과가 본질적으로 문제가 되지 않지만(그리고 종종 모델을 보호하는 역할을 할 수 있지만), 모델이 참조 문서를 전과와 혼합하는 방법에 대한 명시적인 기대의 부족은 다운스트림 문제로 이어질 수 있다. 예를 들어, RAG 시스템이 알고리즘에 사용될 중첩된 재무 데이터를 추출하기 위해 사용된다면, 재무 문서에 오타가 있는 경우 어떤 일이 일어날 것인가? 모델이 오류를 알아차릴까요? 그렇다면 그 자리에 어떤 데이터를 제공할까요? LLM이 곧 의학 및 법을 포함한 많은 영역에 널리 배포될 것이라는 점을 감안할 때 사용자와 개발자 모두 의도하지 않은 영향을 인식해야 하며, 특히 사용자가 RAG 지원 시스템이 본질적으로 항상 진실하다는 선입견을 가지고 있는 경우 더욱 그렇다.

우리의 분석에는 몇 가지 주요 제한 사항이 있다. 첫째, RAG 시스템은 분석에서 다룰 수 있는 것보다 더 많은 도메인에 배포될 수 있다. 그러나 우리의 연구 ixix 도메인이 RAG 시스템의 특성에 대한 초기 그림을 그리기를 바란다. 둘째, 실험을 다루기 쉽게 만들기 위해 질문 생성 프로세스는 엄격하게 사실 기반이며 다단계 논리, 문서 합성 또는 기타 상위 수준 추론이 필요하지 않다. 셋째, 우리가 생성하는 섭동은 합리적이거나 불합리한 가치 범위를 구성하는 것에 대한 이전 기록을 기반으로 한다. 자연적인 설정에서, 우리는 더 이산적인 유형의 오류(예를 들어, 오타, 모호성, 누락된 정보 등)를 상상할 것이다. 시뮬레이션하기가 더 어렵습니다. 또한 OpenAI API가 응답과 함께 토큰별 로그 확률에 액세스할 수 있기 때문에 GPT-3.5 및 GPT-4에 대한 평가를 수행한다. 결과적으로 이러한 모델에 대한 API는 이러한 정보에 대한 액세스를 제공하지 않기 때문에 제미니 및 클로드와 같은 모델에 대해 보다 포괄적인 평가를 수행하는 데 한계가 있다.

LLM은 이제 일반적으로 더 크고 복잡한 시스템의 일부로 사용된다. 이러한 모델이 다양한 정도의 신뢰성, 정확성 및 균일성을 가진 정보와 상호 작용하는 방법을 이해하는 것이 중요하다. 우리의 분석에서는 LLM을 사용하여 상황 정보가 주어진 질문에 답하는 위험을 특성화하기 위해 추가 작업이 필요함을 보여준다. 특히, 우리는 모델 행동이 사전 신념의 한계에 존재하는 정보와 함께 제시될 때 불규칙하고 예측할 수 없다는 것을 발견한다.

\begin{table}
\begin{tabular}{l c c c} \hline \hline
**GPT-4** & **Concordance (Prior)** & **Concordance (w/ RAG)** & **Slope** \\ \hline Drug Dosage & 0.554 & 0.884 & -0.26 \\ Sports Stats & 0.240 & 0.943 & -0.18 \\ Latest News & 0.133 & 0.936 & -0.10 \\ Wikipedia Dates & 0.433 & 0.995 & -0.45 \\ Wikipedia Names & 0.350 & 0.965 & -0.13 \\ Wikipedia Locations & 0.375 & 0.920 & -0.28 \\ \hline _Average_ & _0.347_ & _0.940_ & _-0.23_ \\ \hline \hline \end{tabular}
\end{table}
표 1: GPT 응답과 각 데이터 세트에 대한 기준 값 간의 일치. Prior는 컨텍스트가 없는 GPT-4 응답을 지칭하고, "w/RAG"는 프롬프트에 포함된 관련 검색된 컨텍스트를 갖는 응답을 지칭한다. 또한 사전 확률과 RAG 선호도 사이의 관계의 기울기를 포함한다. 예를 들어, 평균 기울기는 -0.23이며, 이는 이전 토큰의 확률이 10% 증가할 때마다 RAG 선호 가능성이 2.3% 감소한다는 것을 의미한다.

## References

* A. Ahmad, I. Yaramis, and T. 로이(2023-06) 신뢰할 수 있는 LLM을 만드는 것: 의료 AI에서 환각을 다루는 것. 로 인용: SS1.
* J. Chen, H. Lin, X. 한명락 Sun (2024-04)Benchmarking large language models in retrieval-augmented generation. AAAI38(16), pp. 17754-17762. External Links: Link, Document Cited by: SS1.
* J. Chen, H. Lin, X. 한명락 Sun (2024)Benchmarking large language models in retrieval-augmented generation. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 38, pp. 17754-17762. External Links: Link, Document Cited by: SS1.
* D. Dash, R. 타파, J. M. 반다, A. 스와미나탄, M. 치탐 카샹 천정호 곰바르 다우닝 Pedreira, E. Goh, A. Armaout, G. K. Morris, H. Magon, M. P. Lungren, E. Horvitz, and N. H. Shah (2023-06)Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery. 외부 링크: 링크, SS1에 의해 인용된 문서.
* R. 오픈아이의 GPT-3를 활용한 도스(2020-10)메디컬 챗봇이 가짜 환자에게 스스로 목숨을 끊으라고 했다. 외부 링크: 링크, SS1에 의해 인용된 문서.
* S. E, J. James, L. Espinosa-Anke, S. Schockaert (2023-10)RAGAS: 자동 평가 검색 증강 생성. 외부 링크: 링크, SS1에 의해 인용된 문서.
* S. E, J. James, L. Espinosa-Anke, S. Schockaert (2023-10)RAGAS: 자동 평가 검색 증강 생성. 외부 링크: 링크, SS1에 의해 인용된 문서.
* P. F. Foulds, R. James, S. Pan (2024)Ragged edge: retrieval-augmented chatbot의 양날의 검. arXiv preprint arXiv:2403.01193. 인용: SS1.
* W. Foundation (2023)Wikimedia 다운로드. 외부 링크: 연결된 링크: SS1입니다.
* G. Team (2023)Gemini: 매우 유능한 멀티모달 모델 패밀리. 외부 링크: 연결된 링크: SS1입니다.
* Y. 미야시타 호시 응규 타츠노 모리오카 Torii, J. Deguchi (2023)RaLLe: Retrieval-Augmented large language models 개발 및 평가 프레임워크. 외부 링크: 링크, SS1에 의해 인용된 문서.
* Z. 지남 이락 프리스크 유동수 수이시이 Jin Bang, A. Madotto, and P. Fung (2023) Survey of 환각 in natural language generation. ACM Computing Surveys55(12), pp. 1-38. External Links: Link, Document Cited by: SS1.
* J. Kaddour, J. Harris, M. 모즈 H. 브래들리 Raileanu, R. McHardy (2023)의 도전과 대형 언어 모델의 적용. arXiv preprint arXiv:2307.10169. 인용: SS1.
* H. Kang, J. Ni, and H. Yao (2023)Ever: 실시간 검증 및 정정을 통해 대형 언어 모델에서 환각을 완화합니다. arXiv preprint arXiv:2311.09114. 인용: SS1.
* P. Lewis, E. Perez, A. Piktus, F. Petroni, V. 카푸킨 고얄 H. 커틀러 루이스 이태 Rocktaschel, O. (2020) 지식 집약적 nlp 작업에 대한 검색 강화 생성. Adv. 신경 감염입니다 공정. Syst.33, pp. 9459-9474. External Links: Link, Document Cited by: SS1.
* Y. 마오필하 류영 신재옥, 한재옥, 원재옥 Chen (2020)generation-augmented retrieval for open-domain question answering. 외부 링크: 링크, SS1에 의해 인용된 문서.
* E. Mitchell, Y. Lee, A. Khazatsky, C. D. Manning, and C. Finn (2023)DetectGPT: zero-shot machine-generated text detection using probability curvature. ICML29, pp. 24950-24962. External Links: Link, Document Cited by: SS1.

* Nastasi 등(2023) Anthony J Nastasi, Katherine R Courtright, Scott D Halpern, and Gary E Weissman. ChatGPT가 적절하고 공평한 의학적 조언을 제공합니까?: 진료 맥락 전반에 걸친 비녯 기반 임상 평가. 2023년 3월
* OpenAI (2023) OpenAI. GPT-4 기술 보고서 2023년 3월
* Pal et al. (2023) Ankit Pal, Logesh Kumar Umapathi, and Malaikannan Sankarasubbu. Med-HALT: 대형 언어 모델에 대한 의료 도메인 환각 테스트. 2023년 7월
* Saad-Falcon et al. (2023) Jon Saad-Falcon, Omar Khattab, Christopher Potts, and Matei Zaharia. ARES: 검색-증강 생성 시스템을 위한 자동화된 평가 프레임워크. 2023년 11월
* Saad-Falcon et al. (2023) Jon Saad-Falcon, Omar Khattab, Christopher Potts, and Matei Zaharia. Ares: 검색 강화 생성 시스템을 위한 자동화된 평가 프레임워크입니다. _ arXiv preprint arXiv:2311.09476_, 2023b.
* Shuster 등(2021) Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. 검색 확대는 대화에서 환각을 줄입니다. _ arXiv preprint arXiv:2104.07567_, 2021.
* 선 등(2021) 리차오 선, 위위 황, 하오란 왕, 시위안 우, 치후이 장, 추제 가오, 위신 황, 원한 류, 위선 장, 시닝 리, 진글량 류, 위신 류, 위신 류, 위위 왕, 위준 장, 바하야 카일쿠라, 카임잉 황, 하오 류, 훙이 왕, 훙이 왕, 훙이 왕, 훙이 장, 훙이 야오, 훙이 야오, 마놀리스 켈리스, 마린카 지트닉, 멍장, 모히트 반살, 제임스 조우, 지안 페이, 지안펑 가오, 지안훙 가오, 지앙 한, 지유 자오, 지량 탕, 진동 왕, 존 미첼, 카이 슈, 카이 쉬, 카이 위 창, 필립 S 유, 핀유 천, 취안 구, 란 쉬, 렉스 잉, 수만 야나, 톈룽 천, 톈밍 류, 티안 저우, 윌리안 왕, 상리, 상량 장, 샤오 왕, 싱 시 TrustLLM: 대형 언어 모델에서의 신뢰성. 2024년 1월
*Zhang et al.(2024) Zihan Zhang, Meng Fang, and Ling Chen. RetrievalQA: short-form Open-Domain 질의응답을 위한 적응적 검색-증강 생성 평가. 2024년 2월
* Zhao et al.(2024) Qinyu Zhao, Ming Xu, Kartik Gupta, Akshay Asthana, Liang Zheng, and Stephen Gould. 가장 먼저 알 수 있는 것은: 토큰 분포가 대형 Vision-Language 모델에서 숨겨진 지식을 어떻게 드러내는가? 2024년 3월
* Zheng et al. (2023) Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric P Xing, Hao Zhang, Joseph E Gonzalez, and Ion Stoica. LLM-as-a-Judge를 MT-Bench와 챗봇 아레나로 판단한다. 2023년 6월

## 부록 A Appendix

### Prompts

프롬프트의 길이로 인해 오픈 액세스 및 익명화된 리포지토리 내의 CSV에 저장했습니다. [https://anonymous.4open.science/r/rag-tug-of-war-1E48/prompts.csv](https://anonymous.4open.science/r/rag-tug-of-war-1E48/prompts.csv)

\begin{table}
\begin{tabular}{l c c c} \hline \hline
**GPT-3.5** & **Concordance (Prior)** & **Concordance (w/ RAG)** & **Slope** \\ \hline Drug Dosage & 0.052 & 0.509 & -0.20 \\ Sports Stats & 0.005 & 0.599 & -0.09 \\ Latest News & 0.008 & 0.839 & N/A \\ Wikipedia Dates & 0.275 & 0.985 & -0.71 \\ Wikipedia Names & 0.285 & 0.965 & -0.11 \\ Wikipedia Locations & 0.410 & 0.930 & -0.16 \\ \hline _Average_ & 0.173 & 0.805 & -0.25 \\ \hline \hline
**Mistral-7B** & **Concordance (Prior)** & **Concordance (w/ RAG)** & **Slope** \\ \hline Drug Dosage & 0.550 & 0.677 & -0.82 \\ Sports Stats & 0.240 & 0.057 & N/A \\ Latest News & N/A & N/A & N/A \\ Wikipedia Dates & 0.080 & 0.840 & -0.77 \\ Wikipedia Names & 0.065 & 0.760 & -0.14 \\ Wikipedia Locations & 0.490 & 0.690 & -0.030 \\ \hline _Average_ & _0.285_ & _0.605_ & _-0.44_ \\ \hline \hline \end{tabular}
\end{table}
표 2: GPT-3.5 및 미스트랄-7B와의 일치 및 경사. GPT-4를 사용하여 수행된 분석에 대한 전체 표 설명은 표 1을 참조하십시오.

그림 5: GPT-4(파란색), GPT-3.5(주황색) 및 미스트랄-7B(녹색)를 사용하여 사전 확률 및 편차에 대한 RAG 선호율에 대한 분석. 전체 그림 설명은 그림 2를 참조하십시오. 참고로 일부 모델은 특정 데이터 세트에 대해 의미 있는 사전 응답(거부, 부적절한 응답 등)을 생성하지 않았으므로 분석할 수 없었다.
