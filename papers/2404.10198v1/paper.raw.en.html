<html lang="en" data-theme="dark"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior</title>
<!--Generated on Tue Apr 16 00:57:08 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css">
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2404.10198v1/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
      <div class="html-header-logo">
        <a href="https://arxiv.org/">
          <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
          <span class="sr-only">Back to arXiv</span>
        </a>
      </div>
  
      <!--TOC, dark mode, links-->
      <div class="html-header-nav">
        <!--back to abstract-->
        
          <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2404.10198v1">
          <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
              <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
          </svg>
          </a>
        <!--dark mode-->
        <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode" aria-label="Dark mode">
          <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3" hidden="">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
          </label>
          <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
          </label>
          <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
          </label>
        </a>
        <!--nav-->
        <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
          <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
        </button>
      </div>
      </header><header class="desktop_header">
      <div class="html-header-logo">
        <a href="https://arxiv.org/">
            <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
            <span class="sr-only">Back to arXiv</span>
        </a>
      </div>
      <div class="html-header-message" role="banner">
          <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
          </p>
      </div>
      <nav class="html-header-nav">
        <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
        <a class="ar5iv-footer-button hover-effect" target="_blank" href="#myForm" onclick="event.preventDefault(); var modal = document.getElementById('myForm'); modal.style.display = 'block'; bugReportState.setInitiateWay('Header');">Report Issue</a>
        <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2404.10198v1">Back to Abstract</a>
        <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2404.10198v1" target="_blank">Download PDF</a>
        <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <label id="automatic-tog" class="toggle-icon" title="Switch to light mode" for="__palette_3" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9h-1.9M20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69m-9.15 3.96h2.3L12 9l-1.15 3.65Z"></path></svg>
        </label>
        <label id="light-tog" class="toggle-icon" title="Switch to dark mode" for="__palette_1" hidden="">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
        <label id="dark-tog" class="toggle-icon" title="Switch to system preference" for="__palette_2">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"></path></svg>
        </label>
      </a>
      </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

        <div id="listIcon" type="button" class="hide">
            <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
            <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
            </svg>
        </div>
        <div id="arrowIcon" type="button">
            <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
            <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
            </svg>
        </div><ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S1" title="1 Introduction ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S2" title="2 Methods ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S2.SS1" title="2.1 Dataset ‣ 2 Methods ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Dataset</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S2.SS1.SSS1" title="2.1.1 Drug Dosages ‣ 2.1 Dataset ‣ 2 Methods ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.1 </span>Drug Dosages</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S2.SS1.SSS2" title="2.1.2 Sports Statistics ‣ 2.1 Dataset ‣ 2 Methods ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.2 </span>Sports Statistics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S2.SS1.SSS3" title="2.1.3 News ‣ 2.1 Dataset ‣ 2 Methods ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.3 </span>News</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S2.SS1.SSS4" title="2.1.4 Dates, Names, and Cities ‣ 2.1 Dataset ‣ 2 Methods ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1.4 </span>Dates, Names, and Cities</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S2.SS2" title="2.2 Concordance ‣ 2 Methods ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Concordance</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S2.SS3" title="2.3 Modifying the Retrieved Documents ‣ 2 Methods ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Modifying the Retrieved Documents</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S2.SS4" title="2.4 RAG vs Model Prior Analyses ‣ 2 Methods ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>RAG vs Model Prior Analyses</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S2.SS4.SSS1" title="2.4.1 Analyzing the Effects of Different Prompting Strategies ‣ 2.4 RAG vs Model Prior Analyses ‣ 2 Methods ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4.1 </span>Analyzing the Effects of Different Prompting Strategies</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S3" title="3 Results ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S3.SS1" title="3.1 Concordance ‣ 3 Results ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Concordance</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S3.SS2" title="3.2 RAG Preference Rate vs. Prior Probability ‣ 3 Results ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>RAG Preference Rate vs. Prior Probability</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S3.SS2.SSS1" title="3.2.1 RAG Preference Rate vs Deviation from Prior ‣ 3.2 RAG Preference Rate vs. Prior Probability ‣ 3 Results ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>RAG Preference Rate vs Deviation from Prior</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S3.SS2.SSS2" title="3.2.2 Effect of prompting technique on RAG adherence ‣ 3.2 RAG Preference Rate vs. Prior Probability ‣ 3 Results ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Effect of prompting technique on RAG adherence</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S3.SS2.SSS3" title="3.2.3 Differences in effects between GPT-4, GPT-3.5, and Mistral-7B ‣ 3.2 RAG Preference Rate vs. Prior Probability ‣ 3 Results ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>Differences in effects between GPT-4, GPT-3.5, and Mistral-7B</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S4" title="4 Discussion ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#A1" title="Appendix A Appendix ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#A1.SS1" title="A.1 Prompts ‣ Appendix A Appendix ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Prompts</span></a></li>
</ol>
</li>
</ol></nav>

<div class="ltx_page_content"><div class="section" id="target-section"><div id="license-tr">License: CC BY 4.0</div><div id="watermark-tr">arXiv:2404.10198v1 [cs.CL] 16 Apr 2024</div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kevin Wu
<br class="ltx_break">Stanford University
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">kevinywu@stanford.edu</span>
<br class="ltx_break"><span class="ltx_ERROR undefined" id="id2.2.id2">\And</span>Eric Wu*
<br class="ltx_break">Stanford University
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id3.3.id3">wue@stanford.edu</span>
<br class="ltx_break"><span class="ltx_ERROR undefined" id="id4.4.id4">\And</span>James Zou 
<br class="ltx_break">Stanford University
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id5.5.id5">jamesz@stanford.edu</span>
<br class="ltx_break">
</span><span class="ltx_author_notes">Denotes equal contribution.</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id6.id1">Retrieval augmented generation (RAG) is often used to fix hallucinations and provide up-to-date knowledge for large language models (LLMs). However, in cases when the LLM alone incorrectly answers a question, does providing the correct retrieved content always fix the error? Conversely, in cases where the retrieved content is incorrect, does the LLM know to ignore the wrong information, or does it recapitulate the error? To answer these questions, we systematically analyze the tug-of-war between a LLM’s internal knowledge (i.e. its prior) and the retrieved information in settings when they disagree. We test GPT-4 and other LLMs on question-answering abilities across datasets with and without reference documents. As expected, providing the correct retrieved information fixes most model mistakes (94% accuracy). However, when the reference document is perturbed with increasing levels of wrong values, the LLM is more likely to recite the incorrect, modified information when its internal prior is weaker but is more resistant when its prior is stronger. Similarly, we also find that the more the modified information deviates from the model’s prior, the less likely the model is to prefer it. These results highlight an underlying tension between a model’s prior knowledge and the information presented in reference documents.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large language models (LLMs), though powerful, are prone to hallucination <cite class="ltx_cite ltx_citemacro_citep">(Pal et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib20" title="">2023</a>; Sun et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib24" title="">2024</a>; Ahmad et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib1" title="">2023</a>)</cite>. Additionally, they are restricted to knowledge contained in their training corpus, and so are unable to answer queries about recent events or publicly restricted information. Retrieval augmented generation (RAG) is a commonly used framework that provides relevant retrieved content in the LLM prompt and can significantly improve model accuracy <cite class="ltx_cite ltx_citemacro_citep">(Mao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib16" title="">2020</a>; Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib2" title="">2024a</a>; Lewis et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib15" title="">2020</a>)</cite>. 
<br class="ltx_break"></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Most commercial LLMs, like ChatGPT <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib19" title="">2023</a>)</cite>, Gemini <cite class="ltx_cite ltx_citemacro_citep">(Gemini Team, <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib10" title="">2023</a>)</cite>, and Perplexity.ai already employ some version of RAG in their Web interfaces. For example, ChatGPT employs a Bing search whereas Gemini accesses Google Search results. Though RAG has quickly become a default feature of user-facing LLM systems, most evaluations of LLM capabilities are still performed on the non-RAG counterparts <cite class="ltx_cite ltx_citemacro_citep">(Zheng et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib27" title="">2023</a>)</cite>. This is problematic, as a model’s default and RAG-enabled responses can drastically diverge depending on the quality and accuracy of the retrieved content. This problem is compounded when considering that web results constantly change, and can contain outdated, incorrect, or harmful information <cite class="ltx_cite ltx_citemacro_citep">(Dash et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib4" title="">2023</a>; Daws, <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib5" title="">2020</a>; Nastasi et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib18" title="">2023</a>)</cite>. Thus, objective evaluations of RAG-enabled LLM behavior are as important as benchmarking their non-RAG counterparts, especially as RAG systems are increasingly relied upon to provide factual information in a myriad of domains.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this work, we aim to quantify the tension between LLMs’ internal knowledge and the retrieved information presented in RAG settings. To tease apart these two competing forces, we query LLMs to answer questions and measure the token probabilities while introducing varying perturbations to reference documents. Our analyses reveal two key findings:
<br class="ltx_break"></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">The likelihood of the LLM to adhere to the retrieved information presented in context (RAG preference rate) is inversely correlated with the model’s confidence in its response without context (its prior probability).
<br class="ltx_break"></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Similarly, LLMs will increasingly revert to their priors when the original context is progressively modified with unrealistic values.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">We find that these relationships hold under analysis on six different domain datasets across over 1200 questions. We also find that the choice of prompting technique (e.g. strictly adhere, loosely adhere) can influence both the baseline and strength of this relationship. These results highlight the inherent tension in LLMs between the model’s pre-trained knowledge and the retrieved content provided in context.
<br class="ltx_break"></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">The issue of hallucination in LLMs has been explored in multiple contexts and models <cite class="ltx_cite ltx_citemacro_citep">(Ji et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib12" title="">2023</a>; Kaddour et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib13" title="">2023</a>)</cite>. As a response, RAG systems have been shown to reduce hallucination <cite class="ltx_cite ltx_citemacro_citep">(Shuster et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib23" title="">2021</a>; Kang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib14" title="">2023</a>)</cite>. Previous works have explored automated RAG evaluation frameworks in various settings <cite class="ltx_cite ltx_citemacro_citep">(Es et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib6" title="">2023a</a>; Hoshi et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib11" title="">2023</a>; Saad-Falcon et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib21" title="">2023a</a>; Zhang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib25" title="">2024</a>)</cite>. For example, some studies use LLMs to evaluate the faithfulness, answer relevance, and context relevance of RAG systems by using GPT-3.5 as an evaluator <cite class="ltx_cite ltx_citemacro_citep">(Es et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib7" title="">2023b</a>; Saad-Falcon et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib22" title="">2023b</a>)</cite>. In another study, the authors propose metrics such as noise robustness, negative rejection, information integration, and counterfactual robustness <cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib3" title="">2024b</a>)</cite>. Multiple studies have shown that RAG can mislead LLMs in the presence of complex or misleading search results and that such models can still make mistakes even when given the correct response <cite class="ltx_cite ltx_citemacro_citep">(Foulds et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib8" title="">2024</a>; Shuster et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib23" title="">2021</a>)</cite>. In relation to understanding model priors, other works have used log probabilities to assess the LLM’s confidence in responses <cite class="ltx_cite ltx_citemacro_citep">(Mitchell et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib17" title="">2023</a>; Zhao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib26" title="">2024</a>)</cite>. However, so far there has not been a systematic exploration of a model’s confidence (via logprobs) and the model’s preference for RAG-provided information.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="193" id="S1.F1.g1" src="extracted/5538499/schematic4.png" width="598">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>A schematic of generating modified documents for each dataset. A question is posed to the LLM with and without a reference document containing information relevant to the query. This document is then perturbed to contain modified information and given as context to the LLM. We then observe whether the LLM prefers the modified information or its own prior answer.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="454" id="S1.F2.g1" src="extracted/5538499/fig1-2.png" width="598">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Across six QA datasets using GPT-4, we consistently observe an inverse relationship between the RAG preference rate (y-axis) and two characteristics (x-axes): 1. the model’s prior response probability (lefthand plots), and 2. the amount of deviation from the prior (righthand plots). RAG preference rate is defined as the proportion of responses that align with the information presented in the prompt as context. The model’s prior response probability is computed from the average log probability of the response tokens queried without RAG.
The left plot in each pair visualizes the prior probability (grouped into 10 bins) against the RAG preference rate, along with the best-fit trend line and slope. The right plot visualizes absolute deviation from the reference information (for numerical datasets (top), up to two log-fold changes (along with the trendline); for categorical datasets (bottom), a total of four modification categories) against RAG preference rate. Additionally, the upper and lower half percentiles are shown in the right plots to illustrate that lower probability prior responses have monotonically lower RAG preference rates than higher probability prior responses.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Methods</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Our main analysis consists of evaluating the RAG question-answering capabilities of GPT-4 when introducing varying levels of perturbations on the RAG documents. For this study, our dataset consists of 1,294 total questions across 6 different domains. Wherever referenced, the GPT-4 model used is <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">gpt-4-turbo-preview</span>, accessed in March 2024. We additionally evaluate our dataset on two other models: GPT3.5 (<span class="ltx_text ltx_font_italic" id="S2.p1.1.2">gpt-3.5-turbo-0125</span>) and Mistral-7B, the <span class="ltx_text ltx_font_italic" id="S2.p1.1.3">Mistral-7B-Instruct-v0.1</span>. We chose these two LLMs as they are top-performing models that also allow access to the model’s token probabilities (via the OpenAI and Huggingface APIs). All main figures and tables report results using GPT-4; analyses using GPT-3.5 and Mistral-7B are reported in the Appendix.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Dataset</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">We generate questions from six subject domains. To generate a large set of question-and-answer pairs, we extract a corpus of content webpages and then query GPT-4 to generate a question based on the text, along with the ground truth answer and the excerpt used to generate the question. For each dataset below, we provide the full prompts used to generate questions in the Appendix.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S2.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>Drug Dosages</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSS1.p1">
<p class="ltx_p" id="S2.SS1.SSS1.p1.1">We initially randomly sampled 500 drug information pages from UpToDate.com, a medical reference website widely used by clinicians. To constrain the scope of questions, we specify in the prompt that the answer must be numerical and in milligrams. To filter out generated questions that did not meet the specified criteria (e.g. ambiguous question, incorrect units, etc.), we perform an additional quality control step, where we ask GPT-4 to verify that the generated question fulfills all criteria. After this step, we have 266 question-answer pairs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2 </span>Sports Statistics</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSS2.p1">
<p class="ltx_p" id="S2.SS1.SSS2.p1.1">We pulled Olympics records pages from Wikipedia.org across 9 sports: Athletics, weightlifting, swimming, archery, track cycling, rowing, shooting, short track speed skating, and speed skating. Records are extracted in a table format, from which questions are generated for each record entry. In total, after filtering, we extracted 192 unique questions and answers.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.3 </span>News</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSS3.p1">
<p class="ltx_p" id="S2.SS1.SSS3.p1.1">Top headlines are pulled from the Associated Press RSS feed for dates ranging from 03/15/24 to 03/25/24. From an initial corpus of 1486 news articles, we use GPT-4 to generate one question per article, instructing it to produce questions for which there is a clear numerical answer. We perform another GPT-4 quality control step and result in 249 unique question-answer pairs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S2.SS1.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.4 </span>Dates, Names, and Cities</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS1.SSS4.p1">
<p class="ltx_p" id="S2.SS1.SSS4.p1.1">We begin with a random sample of 1000 articles from Huggingface’s Wikipedia dataset (20220301.en, <cite class="ltx_cite ltx_citemacro_citep">(<a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#bib.bib9" title="">Foundation, </a>)</cite>). We use GPT-4 to generate questions related to each field (dates, names, and cities) and filter out responses where the excerpt is not exactly found in the context. To reduce ambiguity when matching groundtruth answers, we restrict the answers to fit certain formats. For dates, we require that the answer adheres to a four-digit year (YYYY). For names, we require a first and last name (eg. George Washington). For cities, we remove any other identities (eg. Seattle, not Seattle, WA). For each domain, among the remaining question-answer pairs that fit these criteria, we randomly sample 200 for our evaluation set.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Concordance</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">We measure concordance, or the agreement between the reference answer generated based on the article content, and the model’s answer to the corresponding generated question. This is computed for both the model’s answer with and without context.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Modifying the Retrieved Documents</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.2">We perform systematic perturbations on each question/answer pair (as visualized in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_tag">1</span></a>. In three datasets with numerical answers (Drug Dosages, Sports Records, Latest News), we produce ten modifications that act as multipliers on the original value: <math alttext="{0.1,0.2,0.4,0.8,1.2,1.5,2.0,3.0,5.0,10.0}" class="ltx_Math" display="inline" id="S2.SS3.p1.1.m1.10"><semantics id="S2.SS3.p1.1.m1.10a"><mrow id="S2.SS3.p1.1.m1.10.11.2" xref="S2.SS3.p1.1.m1.10.11.1.cmml"><mn id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml">0.1</mn><mo id="S2.SS3.p1.1.m1.10.11.2.1" xref="S2.SS3.p1.1.m1.10.11.1.cmml">,</mo><mn id="S2.SS3.p1.1.m1.2.2" xref="S2.SS3.p1.1.m1.2.2.cmml">0.2</mn><mo id="S2.SS3.p1.1.m1.10.11.2.2" xref="S2.SS3.p1.1.m1.10.11.1.cmml">,</mo><mn id="S2.SS3.p1.1.m1.3.3" xref="S2.SS3.p1.1.m1.3.3.cmml">0.4</mn><mo id="S2.SS3.p1.1.m1.10.11.2.3" xref="S2.SS3.p1.1.m1.10.11.1.cmml">,</mo><mn id="S2.SS3.p1.1.m1.4.4" xref="S2.SS3.p1.1.m1.4.4.cmml">0.8</mn><mo id="S2.SS3.p1.1.m1.10.11.2.4" xref="S2.SS3.p1.1.m1.10.11.1.cmml">,</mo><mn id="S2.SS3.p1.1.m1.5.5" xref="S2.SS3.p1.1.m1.5.5.cmml">1.2</mn><mo id="S2.SS3.p1.1.m1.10.11.2.5" xref="S2.SS3.p1.1.m1.10.11.1.cmml">,</mo><mn id="S2.SS3.p1.1.m1.6.6" xref="S2.SS3.p1.1.m1.6.6.cmml">1.5</mn><mo id="S2.SS3.p1.1.m1.10.11.2.6" xref="S2.SS3.p1.1.m1.10.11.1.cmml">,</mo><mn id="S2.SS3.p1.1.m1.7.7" xref="S2.SS3.p1.1.m1.7.7.cmml">2.0</mn><mo id="S2.SS3.p1.1.m1.10.11.2.7" xref="S2.SS3.p1.1.m1.10.11.1.cmml">,</mo><mn id="S2.SS3.p1.1.m1.8.8" xref="S2.SS3.p1.1.m1.8.8.cmml">3.0</mn><mo id="S2.SS3.p1.1.m1.10.11.2.8" xref="S2.SS3.p1.1.m1.10.11.1.cmml">,</mo><mn id="S2.SS3.p1.1.m1.9.9" xref="S2.SS3.p1.1.m1.9.9.cmml">5.0</mn><mo id="S2.SS3.p1.1.m1.10.11.2.9" xref="S2.SS3.p1.1.m1.10.11.1.cmml">,</mo><mn id="S2.SS3.p1.1.m1.10.10" xref="S2.SS3.p1.1.m1.10.10.cmml">10.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.10b"><list id="S2.SS3.p1.1.m1.10.11.1.cmml" xref="S2.SS3.p1.1.m1.10.11.2"><cn id="S2.SS3.p1.1.m1.1.1.cmml" type="float" xref="S2.SS3.p1.1.m1.1.1">0.1</cn><cn id="S2.SS3.p1.1.m1.2.2.cmml" type="float" xref="S2.SS3.p1.1.m1.2.2">0.2</cn><cn id="S2.SS3.p1.1.m1.3.3.cmml" type="float" xref="S2.SS3.p1.1.m1.3.3">0.4</cn><cn id="S2.SS3.p1.1.m1.4.4.cmml" type="float" xref="S2.SS3.p1.1.m1.4.4">0.8</cn><cn id="S2.SS3.p1.1.m1.5.5.cmml" type="float" xref="S2.SS3.p1.1.m1.5.5">1.2</cn><cn id="S2.SS3.p1.1.m1.6.6.cmml" type="float" xref="S2.SS3.p1.1.m1.6.6">1.5</cn><cn id="S2.SS3.p1.1.m1.7.7.cmml" type="float" xref="S2.SS3.p1.1.m1.7.7">2.0</cn><cn id="S2.SS3.p1.1.m1.8.8.cmml" type="float" xref="S2.SS3.p1.1.m1.8.8">3.0</cn><cn id="S2.SS3.p1.1.m1.9.9.cmml" type="float" xref="S2.SS3.p1.1.m1.9.9">5.0</cn><cn id="S2.SS3.p1.1.m1.10.10.cmml" type="float" xref="S2.SS3.p1.1.m1.10.10">10.0</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.10c">{0.1,0.2,0.4,0.8,1.2,1.5,2.0,3.0,5.0,10.0}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.1.m1.10d">0.1 , 0.2 , 0.4 , 0.8 , 1.2 , 1.5 , 2.0 , 3.0 , 5.0 , 10.0</annotation></semantics></math>. In the Wikipedia Years dataset, we perform ten absolute modifications in increments of 20 years for a range of <math alttext="[-100,100]" class="ltx_Math" display="inline" id="S2.SS3.p1.2.m2.2"><semantics id="S2.SS3.p1.2.m2.2a"><mrow id="S2.SS3.p1.2.m2.2.2.1" xref="S2.SS3.p1.2.m2.2.2.2.cmml"><mo id="S2.SS3.p1.2.m2.2.2.1.2" stretchy="false" xref="S2.SS3.p1.2.m2.2.2.2.cmml">[</mo><mrow id="S2.SS3.p1.2.m2.2.2.1.1" xref="S2.SS3.p1.2.m2.2.2.1.1.cmml"><mo id="S2.SS3.p1.2.m2.2.2.1.1a" xref="S2.SS3.p1.2.m2.2.2.1.1.cmml">−</mo><mn id="S2.SS3.p1.2.m2.2.2.1.1.2" xref="S2.SS3.p1.2.m2.2.2.1.1.2.cmml">100</mn></mrow><mo id="S2.SS3.p1.2.m2.2.2.1.3" xref="S2.SS3.p1.2.m2.2.2.2.cmml">,</mo><mn id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml">100</mn><mo id="S2.SS3.p1.2.m2.2.2.1.4" stretchy="false" xref="S2.SS3.p1.2.m2.2.2.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.2b"><interval closure="closed" id="S2.SS3.p1.2.m2.2.2.2.cmml" xref="S2.SS3.p1.2.m2.2.2.1"><apply id="S2.SS3.p1.2.m2.2.2.1.1.cmml" xref="S2.SS3.p1.2.m2.2.2.1.1"><minus id="S2.SS3.p1.2.m2.2.2.1.1.1.cmml" xref="S2.SS3.p1.2.m2.2.2.1.1"></minus><cn id="S2.SS3.p1.2.m2.2.2.1.1.2.cmml" type="integer" xref="S2.SS3.p1.2.m2.2.2.1.1.2">100</cn></apply><cn id="S2.SS3.p1.2.m2.1.1.cmml" type="integer" xref="S2.SS3.p1.2.m2.1.1">100</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.2c">[-100,100]</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.2.m2.2d">[ - 100 , 100 ]</annotation></semantics></math>. For the Wikipedia Names and Locations, the discrete categories required more hand-crafted levels of variation. For each, we performed three categorical perturbations via prompting: slight, significant, and comical. We provide the full prompts used in our study in the Appendix. For example, for a name like <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.2.1">Bob Green</span>, a slight modification implies a small tweak to another real name (<span class="ltx_text ltx_font_italic" id="S2.SS3.p1.2.2">Rob Greene</span>), whereas a significant modification produces a similar but fictitious name (<span class="ltx_text ltx_font_italic" id="S2.SS3.p1.2.3">Bilgorn Grevalle</span>), and a comical modification is an absurd variant (<span class="ltx_text ltx_font_italic" id="S2.SS3.p1.2.4">Blob Lawnface</span>). For a city name like <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.2.5">Miami</span>, a slight modification changes the name of the most similar city (<span class="ltx_text ltx_font_italic" id="S2.SS3.p1.2.6">Fort Lauderdale</span>), a significant modification produces a fictitious city name (<span class="ltx_text ltx_font_italic" id="S2.SS3.p1.2.7">Marisole</span>), and a comical modification produces an absurd variant (<span class="ltx_text ltx_font_italic" id="S2.SS3.p1.2.8">Miameme</span>). Because of differences in how each modified fact might appear in the retrieved text, we utilize GPT-4 to generate the perturbed excerpts for drug dosages and news. Each modified fact is replaced in the original retrieved text. Then, both the question and context are posed to GPT-4, from which the answers, along with the log probabilities of the output tokens, are collected.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>RAG vs Model Prior Analyses</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.1">The main analysis we perform in this study is comparing the <span class="ltx_text ltx_font_italic" id="S2.SS4.p1.1.1">RAG preference</span> of a model against its <span class="ltx_text ltx_font_italic" id="S2.SS4.p1.1.2">internal prior</span>. The LLM is first queried with a question without context. This response and the average probability of the tokens (accessed via the log probs) are referred to as the model’s <span class="ltx_text ltx_font_italic" id="S2.SS4.p1.1.3">prior response</span> and the <span class="ltx_text ltx_font_italic" id="S2.SS4.p1.1.4">prior probability</span>, respectively. The LLM is then queried again, this time with the retrieved content present in the prompt. The resulting response (the response with RAG) is then compared with the prior response: if the response is still the same as the prior response, then the model <span class="ltx_text ltx_font_italic" id="S2.SS4.p1.1.5">prefers its prior</span>. On the other hand, if the model response aligns with the information present in the retrieved content, then the model <span class="ltx_text ltx_font_italic" id="S2.SS4.p1.1.6">prefers RAG</span>. For each dataset, the <span class="ltx_text ltx_font_italic" id="S2.SS4.p1.1.7">RAG preference rate</span> is computed as the average across all RAG queries.
<br class="ltx_break"></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.1">The RAG preference rate is compared against two measurements: the prior probability and the deviation from the prior value. The former is computed by accessing the log probabilities from the OpenAI API call. As these are provided in log scale, we exponentiate them to produce linear probabilities when presenting the results. The latter is computed in several ways. For the Drug Dosages, Sports Statistics, and Latest News datasets, the absolute log fold change between the prior value and the modified value is computed; for the Wikipedia Dates dataset, the simple absolute year change is used; and for the Wikipedia Names and Locations datasets, each categorical change is presented in order of degree of modification.
<br class="ltx_break"></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S2.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.1 </span>Analyzing the Effects of Different Prompting Strategies</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS4.SSS1.p1">
<p class="ltx_p" id="S2.SS4.SSS1.p1.1">Additional analysis is performed on the prompting technique itself: for the examples above, we use a standard prompt template that is based on RAG prompts used on popular LLM open-source libraries, with over 800k downloads as of March 2024 (<a class="ltx_ref ltx_href" href="https://python.langchain.com/docs/expression_language/cookbook/retrieval" title="">LangChain</a> and <a class="ltx_ref ltx_href" href="https://docs.llamaindex.ai/en/stable/examples/prompts/prompts_rag/" title="">LlamaIndex</a>). In addition to this template (called Standard), we introduce two more prompt modifications: Strict, which strongly enforces literal adherence to the retrieved context, and Loose, which encourages the model to reason over the retrieved context before responding.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S2.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="352" id="S2.F3.g1" src="extracted/5538499/examples4.png" width="598">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Examples from three datasets demonstrating differential LLM responses across various types of context modifications. Responses in red indicate wrong responses (different than the answer); responses in green indicate correct responses.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S2.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="428" id="S2.F4.g1" src="extracted/5538499/adherence-prompts6.png" width="598">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Effect of different prompts using GPT-4 on RAG preference rate vs prior probability. The ”Strict” prompt strongly enforces literal adherence to the retrieved context, while the ”Loose” prompt encourages the model to make a reasonable judgment in light of the provided context. We observe lower and steeper drops in RAG adherence with the loose vs strict prompts, suggesting that prompt wording plays a significant factor in controlling RAG adherence. Full prompts are provided in the Appendix. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Concordance</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">In Table <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S3.T1" title="Table 1 ‣ 3.2.3 Differences in effects between GPT-4, GPT-3.5, and Mistral-7B ‣ 3.2 RAG Preference Rate vs. Prior Probability ‣ 3 Results ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_tag">1</span></a>, we observe that the model’s prior response only agreed with the reference answer 34.7% on average. However, the RAG answers elevated the concordance to 94%. This result demonstrates that the RAG pipeline established in this work is highly effective at encouraging the model to adhere to its retrieved content. However, in the minority of cases where providing the retrieved content fails to correct the LLM, we find that the model simply responds with its original prior answer about 20% of the time.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>RAG Preference Rate vs. Prior Probability</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_tag">2</span></a> (left side plots), we observe a consistent negative relationship between the token probability of the model’s prior answer and the associated RAG preference rate for all six QA datasets. To visualize an even distribution across probabilities, we bin the probabilities into ten equidistant bins in the range of <math alttext="[0.0,1.0]" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.2"><semantics id="S3.SS2.p1.1.m1.2a"><mrow id="S3.SS2.p1.1.m1.2.3.2" xref="S3.SS2.p1.1.m1.2.3.1.cmml"><mo id="S3.SS2.p1.1.m1.2.3.2.1" stretchy="false" xref="S3.SS2.p1.1.m1.2.3.1.cmml">[</mo><mn id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">0.0</mn><mo id="S3.SS2.p1.1.m1.2.3.2.2" xref="S3.SS2.p1.1.m1.2.3.1.cmml">,</mo><mn id="S3.SS2.p1.1.m1.2.2" xref="S3.SS2.p1.1.m1.2.2.cmml">1.0</mn><mo id="S3.SS2.p1.1.m1.2.3.2.3" stretchy="false" xref="S3.SS2.p1.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.2b"><interval closure="closed" id="S3.SS2.p1.1.m1.2.3.1.cmml" xref="S3.SS2.p1.1.m1.2.3.2"><cn id="S3.SS2.p1.1.m1.1.1.cmml" type="float" xref="S3.SS2.p1.1.m1.1.1">0.0</cn><cn id="S3.SS2.p1.1.m1.2.2.cmml" type="float" xref="S3.SS2.p1.1.m1.2.2">1.0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.2c">[0.0,1.0]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.2d">[ 0.0 , 1.0 ]</annotation></semantics></math>. We additionally present the slope from performing a linear regression on the binned probability values against the RAG preference rate in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S3.T1" title="Table 1 ‣ 3.2.3 Differences in effects between GPT-4, GPT-3.5, and Mistral-7B ‣ 3.2 RAG Preference Rate vs. Prior Probability ‣ 3 Results ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_tag">1</span></a>. The slope indicates the effect of stronger model confidence on the model’s preference for the information presented in the retrieved context; we observe different slopes (ranging from -0.1 to -0.45), suggesting that the effectiveness of RAG in different QA domains can be characterized as being relatively susceptible (e.g., with Dates questions) or robust (e.g., with News questions) to the model’s internal prior knowledge confidence. Specifically, a slope of -0.45, for instance, can be interpreted as expecting a 4.5% decrease in the likelihood of the LLM preferring the contextual information for every 10% increase in the probability of the model’s prior response.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>RAG Preference Rate vs Deviation from Prior</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">We also consider the degree of deviation between the model’s prior response and the value contained in the retrieved context (Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_tag">2</span></a>, right side plots). A similar pattern emerges in this analysis: as the RAG value diverges from the model’s prior, the model is less likely to adopt the RAG value over its own initial response. We additionally plot data split into the upper and lower half percentiles and observe that, across all six datasets, the lower probability prior responses are monotonically lower than the higher probability response tokens. Thus, the correlation between deviation and RAG response rate holds across both bands of probabilities.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Effect of prompting technique on RAG adherence</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">To assess the degree of influence that the specific prompting technique has on RAG adherence, we test two additional prompts (”strict” and ”loose”) on GPT-4. The strict prompt is intended to coerce the model to disregard its own prior response, while the loose prompt is intended for the model to arbitrate between its own prior and the contextual information provided. In Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S2.F4" title="Figure 4 ‣ 2.4.1 Analyzing the Effects of Different Prompting Strategies ‣ 2.4 RAG vs Model Prior Analyses ‣ 2 Methods ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_tag">4</span></a>, the strict prompt has uniformly higher RAG adherence than the standard prompt. The loose prompt, on the other hand, results in much lower RAG adherence rates as prior probability increases. Interestingly, the slope is also steeper, indicating a larger per-unit decrease in RAG preference as the prior probability increases. The choice of prompt is thus an important mechanism for influencing the LLM’s RAG preferences.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Differences in effects between GPT-4, GPT-3.5, and Mistral-7B</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS3.p1">
<p class="ltx_p" id="S3.SS2.SSS3.p1.1">We report the same analyses when using GPT-3.5 and Mistral-7B in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#A1.T2" title="Table 2 ‣ Appendix A Appendix ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_tag">2</span></a> and Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#A1.F5" title="Figure 5 ‣ Appendix A Appendix ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_tag">5</span></a>. We observe significantly lower performance both in concordance of the prior and with RAG. However, as seen in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#A1.F5" title="Figure 5 ‣ Appendix A Appendix ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_tag">5</span></a>, we nonetheless observe the same inverse trends in these two models as seen in the results with GPT-4. Of note, some datasets (like Latest News) perform poorly without RAG (the model refused the vast majority of queries or provided invalid responses), and thus the prior token probabilities could not be analyzed. In the Mistral-7B results, we also observe that some of the responses using RAG could not consistently provide valid responses.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1">GPT-4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.2.1">Concordance (Prior)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.3.1">Concordance (w/ RAG)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.4.1">Slope</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T1.1.2.1.1">Drug Dosage</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.2">0.554</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.3">0.884</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.2.1.4">-0.26</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.3.2.1">Sports Stats</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.2">0.240</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.3">0.943</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.3.2.4">-0.18</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.4.3.1">Latest News</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.3.2">0.133</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.3.3">0.936</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.4.3.4">-0.10</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.5.4.1">Wikipedia Dates</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.2">0.433</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.3">0.995</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.5.4.4">-0.45</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.6.5.1">Wikipedia Names</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.5.2">0.350</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.5.3">0.965</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.6.5.4">-0.13</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S3.T1.1.7.6.1">Wikipedia Locations</th>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.6.2">0.375</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.6.3">0.920</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.7.6.4">-0.28</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S3.T1.1.8.7.1"><span class="ltx_text ltx_font_italic" id="S3.T1.1.8.7.1.1">Average</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.8.7.2"><span class="ltx_text ltx_font_italic" id="S3.T1.1.8.7.2.1">0.347</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.8.7.3"><span class="ltx_text ltx_font_italic" id="S3.T1.1.8.7.3.1">0.940</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.8.7.4"><span class="ltx_text ltx_font_italic" id="S3.T1.1.8.7.4.1">-0.23</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Concordance between the GPT response and the reference values for each dataset. Prior refers to GPT-4 responses without context, and ”w/ RAG” refers to responses with the relevant retrieved context included in the prompt. Additionally, we include the slope of the relationship between prior probability and RAG preference rate. For instance, the average slope is -0.23, which means that for every 10% increase in the probability of the prior token, we observe a 2.3% decreased likelihood of RAG preference.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">While RAG is becoming standard practice in commercially available LLMs, the reliability of such systems is still understudied. Our experiments uncover several mechanisms that modulate the degree to which LLMs adhere to RAG systems. Specifically, we quantify a tug-of-war between the strength of the model’s prior and the rate at which the model adheres to the RAG document’s facts. This effect is at odds with claims that RAG itself can fix hallucinations alone, and occurs even when the model is prompted to adhere to RAG documents strictly.

<br class="ltx_break"></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">RAG systems have a unique appeal over traditional search engines in that they can incorporate prior knowledge to fill in the gaps and extrapolate the retrieved information. We find that this comes with trade-offs – namely, that such priors can override information provided in documents. When perturbing RAG documents over a wide interval of values, the point at which models revert to their prior responses, or ”tipping points”, are latent and heterogeneous across different models and domains. While strong priors are not inherently problematic (and can often serve to safeguard models), the lack of explicit expectations around how models will mix reference documents with their priors can lead to downstream issues. For example, if RAG systems are used to extract nested financial data to be used in an algorithm, what will happen if there is a typo in the financial documents? Will the model notice the error and if so, what data will it provide in its place?
Given that LLMs are soon to be widely deployed in many domains including medicine and law, users and developers alike should be cognizant of their unintended effects, especially if users have preconceptions that RAG-enabled systems are, by nature, always truthful.
<br class="ltx_break"></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">There are several key limitations in our analyses. First, RAG systems can be deployed to many more domains than can be covered by our analyses. However, we hope that our study ixix domains paints an initial picture of the nature of RAG systems. Second, to make our experiments tractable, our question-generation process is strictly fact-based and does not require multi-step logic, document synthesis, or other higher-level reasoning. Third, the perturbations we produce are based on our priors for what would constitute a reasonable or unreasonable range of values. In a natural setting, we would imagine more discrete types of errors (eg. typos, ambiguities, missing information, etc.) which are harder to simulate. We also perform evaluations on GPT-3.5 and GPT-4 because the OpenAI API allows for access to token-wise log probabilities along with the responses. As a consequence, we are limited against performing more comprehensive evaluations on models such as Gemini and Claude because the APIs for these models do not provide access to such information.
<br class="ltx_break"></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">LLMs are now commonly used as parts of larger, more complex systems. It is crucial to understand how these models interact with information with varying degrees of trustworthiness, accuracy, and uniformity. Our analysis shows that further work is required to characterize the risks of using LLMs to answer questions given contextual information. In particular, we find that model behavior can be erratic and unpredictable when presented with information that exists at the margin of its prior beliefs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ahmad et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Muhammad&nbsp;Aurangzeb Ahmad, Ilker Yaramis, and Taposh&nbsp;Dutta Roy.

</span>
<span class="ltx_bibblock">Creating trustworthy LLMs: Dealing with hallucinations in healthcare AI.

</span>
<span class="ltx_bibblock">September 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2024a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiawei Chen, Hongyu Lin, Xianpei Han, and Le&nbsp;Sun.

</span>
<span class="ltx_bibblock">Benchmarking large language models in Retrieval-Augmented generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">AAAI</em>, 38(16):17754–17762, March 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2024b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiawei Chen, Hongyu Lin, Xianpei Han, and Le&nbsp;Sun.

</span>
<span class="ltx_bibblock">Benchmarking large language models in retrieval-augmented generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume&nbsp;38, pp.&nbsp; 17754–17762, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dash et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Debadutta Dash, Rahul Thapa, Juan&nbsp;M Banda, Akshay Swaminathan, Morgan Cheatham, Mehr Kashyap, Nikesh Kotecha, Jonathan&nbsp;H Chen, Saurabh Gombar, Lance Downing, Rachel Pedreira, Ethan Goh, Angel Arnaout, Garret&nbsp;Kenn Morris, Honor Magon, Matthew&nbsp;P Lungren, Eric Horvitz, and Nigam&nbsp;H Shah.

</span>
<span class="ltx_bibblock">Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery.

</span>
<span class="ltx_bibblock">April 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Daws (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ryan Daws.

</span>
<span class="ltx_bibblock">Medical chatbot using OpenAI’s GPT-3 told a fake patient to kill themselves.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.artificialintelligence-news.com/2020/10/28/medical-chatbot-openai-gpt3-patient-kill-themselves/" title="">https://www.artificialintelligence-news.com/2020/10/28/medical-chatbot-openai-gpt3-patient-kill-themselves/</a>, October 2020.

</span>
<span class="ltx_bibblock">Accessed: 2024-1-19.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Es et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shahul Es, Jithin James, Luis Espinosa-Anke, and Steven Schockaert.

</span>
<span class="ltx_bibblock">RAGAS: Automated evaluation of retrieval augmented generation.

</span>
<span class="ltx_bibblock">September 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Es et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shahul Es, Jithin James, Luis Espinosa-Anke, and Steven Schockaert.

</span>
<span class="ltx_bibblock">Ragas: Automated evaluation of retrieval augmented generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2309.15217</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Foulds et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Philip&nbsp;Feldman Foulds, R&nbsp;James, and Shimei Pan.

</span>
<span class="ltx_bibblock">Ragged edges: The double-edged sword of retrieval-augmented chatbots.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2403.01193</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(9)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wikimedia Foundation.

</span>
<span class="ltx_bibblock">Wikimedia downloads.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://dumps.wikimedia.org" title="">https://dumps.wikimedia.org</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gemini Team (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Gemini Team.

</span>
<span class="ltx_bibblock">Gemini: A family of highly capable multimodal models.

</span>
<span class="ltx_bibblock">December 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoshi et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yasuto Hoshi, Daisuke Miyashita, Youyang Ng, Kento Tatsuno, Yasuhiro Morioka, Osamu Torii, and Jun Deguchi.

</span>
<span class="ltx_bibblock">RaLLe: A framework for developing and evaluating Retrieval-Augmented large language models.

</span>
<span class="ltx_bibblock">August 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye&nbsp;Jin Bang, Andrea Madotto, and Pascale Fung.

</span>
<span class="ltx_bibblock">Survey of hallucination in natural language generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">ACM Computing Surveys</em>, 55(12):1–38, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaddour et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jean Kaddour, Joshua Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, and Robert McHardy.

</span>
<span class="ltx_bibblock">Challenges and applications of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2307.10169</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Haoqiang Kang, Juntong Ni, and Huaxiu Yao.

</span>
<span class="ltx_bibblock">Ever: Mitigating hallucination in large language models through real-time verification and rectification.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2311.09114</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-Tau Yih, Tim Rocktäschel, and Others.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Adv. Neural Inf. Process. Syst.</em>, 33:9459–9474, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mao et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Shen, Jianfeng Gao, Jiawei Han, and Weizhu Chen.

</span>
<span class="ltx_bibblock">Generation-Augmented retrieval for open-domain question answering.

</span>
<span class="ltx_bibblock">September 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
E&nbsp;Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher&nbsp;D Manning, and Chelsea Finn.

</span>
<span class="ltx_bibblock">DetectGPT: Zero-shot machine-generated text detection using probability curvature.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">ICML</em>, pp.&nbsp; 24950–24962, January 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nastasi et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Anthony&nbsp;J Nastasi, Katherine&nbsp;R Courtright, Scott&nbsp;D Halpern, and Gary&nbsp;E Weissman.

</span>
<span class="ltx_bibblock">Does ChatGPT provide appropriate and equitable medical advice?: A vignette-based, clinical evaluation across care contexts.

</span>
<span class="ltx_bibblock">March 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">GPT-4 technical report.

</span>
<span class="ltx_bibblock">March 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pal et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ankit Pal, Logesh&nbsp;Kumar Umapathi, and Malaikannan Sankarasubbu.

</span>
<span class="ltx_bibblock">Med-HALT: Medical domain hallucination test for large language models.

</span>
<span class="ltx_bibblock">July 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saad-Falcon et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jon Saad-Falcon, Omar Khattab, Christopher Potts, and Matei Zaharia.

</span>
<span class="ltx_bibblock">ARES: An automated evaluation framework for Retrieval-Augmented generation systems.

</span>
<span class="ltx_bibblock">November 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saad-Falcon et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jon Saad-Falcon, Omar Khattab, Christopher Potts, and Matei Zaharia.

</span>
<span class="ltx_bibblock">Ares: An automated evaluation framework for retrieval-augmented generation systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2311.09476</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shuster et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston.

</span>
<span class="ltx_bibblock">Retrieval augmentation reduces hallucination in conversation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2104.07567</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lichao Sun, Yue Huang, Haoran Wang, Siyuan Wu, Qihui Zhang, Chujie Gao, Yixin Huang, Wenhan Lyu, Yixuan Zhang, Xiner Li, Zhengliang Liu, Yixin Liu, Yijue Wang, Zhikun Zhang, Bhavya Kailkhura, Caiming Xiong, Chaowei Xiao, Chunyuan Li, Eric Xing, Furong Huang, Hao Liu, Heng Ji, Hongyi Wang, Huan Zhang, Huaxiu Yao, Manolis Kellis, Marinka Zitnik, Meng Jiang, Mohit Bansal, James Zou, Jian Pei, Jian Liu, Jianfeng Gao, Jiawei Han, Jieyu Zhao, Jiliang Tang, Jindong Wang, John Mitchell, Kai Shu, Kaidi Xu, Kai-Wei Chang, Lifang He, Lifu Huang, Michael Backes, Neil&nbsp;Zhenqiang Gong, Philip&nbsp;S Yu, Pin-Yu Chen, Quanquan Gu, Ran Xu, Rex Ying, Shuiwang Ji, Suman Jana, Tianlong Chen, Tianming Liu, Tianyi Zhou, Willian Wang, Xiang Li, Xiangliang Zhang, Xiao Wang, Xing Xie, Xun Chen, Xuyu Wang, Yan Liu, Yanfang Ye, Yinzhi Cao, Yong Chen, and Yue Zhao.

</span>
<span class="ltx_bibblock">TrustLLM: Trustworthiness in large language models.

</span>
<span class="ltx_bibblock">January 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zihan Zhang, Meng Fang, and Ling Chen.

</span>
<span class="ltx_bibblock">RetrievalQA: Assessing adaptive Retrieval-Augmented generation for short-form Open-Domain question answering.

</span>
<span class="ltx_bibblock">February 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qinyu Zhao, Ming Xu, Kartik Gupta, Akshay Asthana, Liang Zheng, and Stephen Gould.

</span>
<span class="ltx_bibblock">The first to know: How token distributions reveal hidden knowledge in large Vision-Language models?

</span>
<span class="ltx_bibblock">March 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi&nbsp;Lin, Zhuohan Li, Dacheng Li, Eric&nbsp;P Xing, Hao Zhang, Joseph&nbsp;E Gonzalez, and Ion Stoica.

</span>
<span class="ltx_bibblock">Judging LLM-as-a-Judge with MT-Bench and chatbot arena.

</span>
<span class="ltx_bibblock">June 2023.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A1.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="415" id="A1.F5.g1" src="extracted/5538499/fig1combined2.png" width="548">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Analyses for RAG preference rate against prior probability and deviation, using GPT-4 (blue), GPT-3.5 (orange), and Mistral-7B (green). Please see Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_tag">2</span></a> for full figure descriptions. Of note, some models did not generate any meaningful prior responses (due to refusal, improper responses, etc.) for certain datasets and thus could not be analyzed.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A1.T2">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_flex_size_1 ltx_align_middle" id="A1.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A1.T2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.1.1.1">GPT-3.5</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T2.1.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.1.2.1">Concordance (Prior)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T2.1.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.1.3.1">Concordance (w/ RAG)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T2.1.1.1.4"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.1.4.1">Slope</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T2.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T2.1.2.1.1">Drug Dosage</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.1.2.1.2">0.052</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.1.2.1.3">0.509</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.1.2.1.4">-0.20</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T2.1.3.2.1">Sports Stats</th>
<td class="ltx_td ltx_align_center" id="A1.T2.1.3.2.2">0.005</td>
<td class="ltx_td ltx_align_center" id="A1.T2.1.3.2.3">0.599</td>
<td class="ltx_td ltx_align_center" id="A1.T2.1.3.2.4">-0.09</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T2.1.4.3.1">Latest News</th>
<td class="ltx_td ltx_align_center" id="A1.T2.1.4.3.2">0.008</td>
<td class="ltx_td ltx_align_center" id="A1.T2.1.4.3.3">0.839</td>
<td class="ltx_td ltx_align_center" id="A1.T2.1.4.3.4">N/A</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T2.1.5.4.1">Wikipedia Dates</th>
<td class="ltx_td ltx_align_center" id="A1.T2.1.5.4.2">0.275</td>
<td class="ltx_td ltx_align_center" id="A1.T2.1.5.4.3">0.985</td>
<td class="ltx_td ltx_align_center" id="A1.T2.1.5.4.4">-0.71</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T2.1.6.5.1">Wikipedia Names</th>
<td class="ltx_td ltx_align_center" id="A1.T2.1.6.5.2">0.285</td>
<td class="ltx_td ltx_align_center" id="A1.T2.1.6.5.3">0.965</td>
<td class="ltx_td ltx_align_center" id="A1.T2.1.6.5.4">-0.11</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T2.1.7.6.1">Wikipedia Locations</th>
<td class="ltx_td ltx_align_center" id="A1.T2.1.7.6.2">0.410</td>
<td class="ltx_td ltx_align_center" id="A1.T2.1.7.6.3">0.930</td>
<td class="ltx_td ltx_align_center" id="A1.T2.1.7.6.4">-0.16</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="A1.T2.1.8.7.1"><span class="ltx_text ltx_font_italic" id="A1.T2.1.8.7.1.1">Average</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T2.1.8.7.2">0.173</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T2.1.8.7.3">0.805</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T2.1.8.7.4">-0.25</td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_flex_size_1 ltx_align_middle" id="A1.T2.2">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T2.2.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A1.T2.2.1.1.1"><span class="ltx_text ltx_font_bold" id="A1.T2.2.1.1.1.1">Mistral-7B</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T2.2.1.1.2"><span class="ltx_text ltx_font_bold" id="A1.T2.2.1.1.2.1">Concordance (Prior)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T2.2.1.1.3"><span class="ltx_text ltx_font_bold" id="A1.T2.2.1.1.3.1">Concordance (w/ RAG)</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T2.2.1.1.4"><span class="ltx_text ltx_font_bold" id="A1.T2.2.1.1.4.1">Slope</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T2.2.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T2.2.2.1.1">Drug Dosage</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.2.2.1.2">0.550</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.2.2.1.3">0.677</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.2.2.1.4">-0.82</td>
</tr>
<tr class="ltx_tr" id="A1.T2.2.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T2.2.3.2.1">Sports Stats</th>
<td class="ltx_td ltx_align_center" id="A1.T2.2.3.2.2">0.240</td>
<td class="ltx_td ltx_align_center" id="A1.T2.2.3.2.3">0.057</td>
<td class="ltx_td ltx_align_center" id="A1.T2.2.3.2.4">N/A</td>
</tr>
<tr class="ltx_tr" id="A1.T2.2.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T2.2.4.3.1">Latest News</th>
<td class="ltx_td ltx_align_center" id="A1.T2.2.4.3.2">N/A</td>
<td class="ltx_td ltx_align_center" id="A1.T2.2.4.3.3">N/A</td>
<td class="ltx_td ltx_align_center" id="A1.T2.2.4.3.4">N/A</td>
</tr>
<tr class="ltx_tr" id="A1.T2.2.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T2.2.5.4.1">Wikipedia Dates</th>
<td class="ltx_td ltx_align_center" id="A1.T2.2.5.4.2">0.080</td>
<td class="ltx_td ltx_align_center" id="A1.T2.2.5.4.3">0.840</td>
<td class="ltx_td ltx_align_center" id="A1.T2.2.5.4.4">-0.77</td>
</tr>
<tr class="ltx_tr" id="A1.T2.2.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T2.2.6.5.1">Wikipedia Names</th>
<td class="ltx_td ltx_align_center" id="A1.T2.2.6.5.2">0.065</td>
<td class="ltx_td ltx_align_center" id="A1.T2.2.6.5.3">0.760</td>
<td class="ltx_td ltx_align_center" id="A1.T2.2.6.5.4">-0.14</td>
</tr>
<tr class="ltx_tr" id="A1.T2.2.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T2.2.7.6.1">Wikipedia Locations</th>
<td class="ltx_td ltx_align_center" id="A1.T2.2.7.6.2">0.490</td>
<td class="ltx_td ltx_align_center" id="A1.T2.2.7.6.3">0.690</td>
<td class="ltx_td ltx_align_center" id="A1.T2.2.7.6.4">-0.030</td>
</tr>
<tr class="ltx_tr" id="A1.T2.2.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="A1.T2.2.8.7.1"><span class="ltx_text ltx_font_italic" id="A1.T2.2.8.7.1.1">Average</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T2.2.8.7.2"><span class="ltx_text ltx_font_italic" id="A1.T2.2.8.7.2.1">0.285</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T2.2.8.7.3"><span class="ltx_text ltx_font_italic" id="A1.T2.2.8.7.3.1">0.605</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T2.2.8.7.4"><span class="ltx_text ltx_font_italic" id="A1.T2.2.8.7.4.1">-0.44</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Concordance and Slope with GPT-3.5 and Mistral-7B. Please see Table <a class="ltx_ref" href="https://arxiv.org/html/2404.10198v1#S3.T1" title="Table 1 ‣ 3.2.3 Differences in effects between GPT-4, GPT-3.5, and Mistral-7B ‣ 3.2 RAG Preference Rate vs. Prior Probability ‣ 3 Results ‣ How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs’ internal prior"><span class="ltx_text ltx_ref_tag">1</span></a> for a full table description of analyses performed using GPT-4.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Prompts</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">Due to the length of the prompts, we have stored them in a CSV within open-access and anonymized repository: https://anonymous.4open.science/r/rag-tug-of-war-1E48/prompts.csv</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
</article>
</div>

</div>


<div class="ltx_page_footer">
          <div class="ltx_page_logo">
              Generated by
              <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                  <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                      L
                      <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                      T
                      <span style="position: relative; bottom: -0.4ex;">E</span>
                  </span>
                  <span class="ltx_font_smallcaps">xml</span>
                  <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
              </a>
          </div></div><footer id="footer" class="ltx_document">
          <div class="keyboard-glossary">
              <h2>Instructions for reporting errors</h2>
              <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
              <ul>
                  <li>Click the "Report Issue" button.</li>
                  <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                  <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                  <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
              </ul>
              <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
              <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
          </div>
      </footer><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header" data-bs-theme="dark"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button></body></html>