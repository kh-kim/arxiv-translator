# 기초 모델을 사용한 추론 조사: 개념, 방법 및 전망

Jiankai Sun

홍콩의 중국 대학

 정주양

홍콩의 중국 대학

 엔제시

화웨이 노아의 방주연구소

 유정영

화웨이 노아의 방주연구소

 추리항

홍콩의 중국 대학

 지안기

홍콩의 중국 대학

 지아치쉬

중국 홍콩 대학교 홍콩 대학교

 민규딩

중국 홍콩 대학교 홍콩 대학교

 이홍양

중국 홍콩 대학교 홍콩 대학교

 칭구추

중국 홍콩 대학교 홍콩 대학교

 이케궈

홍콩과학기술대학교

 희웅

홍콩과학기술대학교

 권리우

홍콩과학기술대학교

 이진구

화웨이 노아의 방주연구소

###### Abstract

복잡한 문제 해결을 위한 중요한 능력인 추론은 협상, 의학적 진단, 범죄 수사 등 다양한 현실 환경에서 중추적인 역할을 한다. 인공지능(AGI) 분야의 근본적인 방법론으로 작용한다. 기초 모델의 지속적인 발전과 함께 추론 과제에 대한 그들의 능력을 탐구하는 것에 대한 관심이 증가하고 있다. 본 논문에서는 다양한 추론 작업, 방법 및 벤치마크에서 최신 발전을 강조하면서 제안되거나 적응 가능한 추론 기반 모델을 소개한다. 그런 다음 기초 모델 내에서 추론 능력의 출현 뒤에 숨겨진 잠재적인 미래 방향을 조사한다. 또한 추론 맥락에서 멀티모달 학습, 자율 에이전트 및 슈퍼 정렬의 관련성에 대해 논의한다. 이러한 미래 연구 방향을 논의함으로써 연구자들은 이 분야에 대한 탐구에 영감을 주고, LMM(Large Language Models)과 같은 기초 모델을 사용한 추론의 추가 발전을 자극하고 AGI의 발전에 기여하기를 바란다. *

각주 *: 관련 논문과 추론에 대한 인기 있는 벤치마크를 특징으로 하는 향후 연구에 도움이 되도록 지속적으로 업데이트된 읽기 목록을 유지한다. GitHub: [https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models](https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models)

각주 †: 예비 발매입니다. 우리는 이 작업의 품질과 최신성을 유지하기 위해 최선을 다하고 있습니다.

**키워드: 추론, 기본 모델, 멀티모달, AI 에이전트, 인공 일반 지능, 공식 방법**

###### Contents

* 1 소개
* 2 배경
	* 2.1 추론의 정의
		* 2.1.1 연역적 추론, 비연산적 추론 및 귀납적 추론
		* 2.1.2 수학적 표현
	* 2.2 기초 모델 및 최근 진행 상황
		* 2.2.1 언어 기초 모델 및 언어 프롬프트
		* 2.2.2 비전 기초 모델 및 시각적 프롬프트
		* 2.2.3 멀티모달 기초 모델
		* 2.2.4 Potential for Applications in reasoning
* 3 추론 작업
	* 3.1 상식 추론
		* 3.1.1 상식 질문 및 답변(QA)
		* 3.1.2 물리적 상식 추론
		* 3.1.3 공간 상식 추론
	* 3.2 수학적 추론
		* 3.2.1 산술 추론
		* 3.2.2 기하학적 추론
		* 3.2.3 자동화 정리 증명
		* 3.2.4 과학적 추론
	* 3.3 논리 추론
		* 3.3.1 명제 논리
		* 3.3.2 술어 논리
	* 3.4 인과 추론
		* 3.4.1 반사실적 추론
	* 3.5 시각적 추론
		* 3.5.1 3D 추론
	* 3.6 오디오 추론
		* 3.6.1 Speech
	* 3.7 멀티모달 추론
		* 3.7.1 정렬
		* 3.7.2 세대
		* 3.7.3 멀티모달 이해
	* 3.8 Agent Reasoning
		* 3.8.1 내성 추론
		* 3.8.2 외향적 추론
		* 3.8.3 Embodied Reasoning
		* 3.8.4 Multi-agent 추론
		* 3.8.5 자율 주행에서의 추론
	* 3.9 기타 작업 및 응용 프로그램
		* 3.9.1 마음 이론(ToM)
		* 3.9.2 기상예보

3.9.3 의학 추론 3.9.4 생물정보학 추론 3.9.5 코드 생성 3.9.6 롱체인 추론 3.9.7 추상 추론 3.9.8 추론 3.10 벤치마크, 데이터셋, 메트릭 3.10.1 코멘센스 추론 3.10.2 수학 추론 3.10.3 논리 추론 3.10.4 인과 추론 3.10.5 시각 추론 3.10.6 오디오 추론 3.10.7 멀티모달 추론 3.10.8 내재 추론 3.10.9 자율 주행 3.10.10 코드 생성
* 4 Foundation 모델 기법 4.1 Pre-Training 4.1.1 Data Source 4.1.2 Network Architecture 4.2 Fine-Tuning 4.2.1 Data Source 4.2.2 Parameter-Efficient Fine-Tuning 4.3 Alignment Training 4.3.1 Data Source 4.3.2 Training Pipeline 4.4 Mixture of Experts (MoE) 4.5 In-Context Learning 4.5.1 Demonation Example Selection 4.5.2 Chain-of-Thinking 4.5.3 Multi Round Prompting 4.6 Autonomous Agent
* 5 토론 : 도전, 한계 및 위험
* 6 미래 방향 6.1 안전성 및 프라이버시 6.2 해석성 및 투명성 6.3 자율 언어 에이전트 6.4 과학에 대한 추론 6.5 슈퍼 정렬
* 7 결론

## 1 Introduction

_"인간은 항상 단조롭지 않은 추론을 수행했지만 주어진 결론에 도달하는 데 있어 엄격한 단조로운 추론은 마땅히 더 존중되고 존경받아야 했다.

John McCarthy (2004)

추론은 인공지능의 필수적인 측면으로 문제 해결, 정리 증명, 의사 결정, 로봇 공학(매닝, 2022) 등 다양한 분야에 걸쳐 응용이 이루어지고 있다. Thinking, Fast and Slow_(Daniel, 2017)는 "System 1" 및 "System 2" 사고 모드로 구성된 인간 정신을 위한 이중 시스템 프레임워크를 설명한다. "시스템 1"은 본능, 감정, 직관, 무의식적 과정에 의존하며 빠르게 작동한다. 이에 비해 "시스템 2"는 알고리즘적 추론, 논리적 분석, 수학적 능력과 같은 의식적 숙고가 수반되어 더 느리게 작동한다. 추론은 "시스템 2"(Bengio, 2017; Weston and Sukhbaatar, 2023)의 핵심 기능 중 하나로 중요한 역할을 한다. 추론은 형식 언어 추론과 자연 언어 추론의 두 가지 광범위한 유형으로 분류될 수 있다(Reiter, 1975; Berzonsky, 1978; Teig and Scherer, 2016; Yu et al., 2023; Zhao et al., 2023; Li et al., 2023). 한편, 도 1에 도시된 바와 같이, 형식 언어 추론은 소프트웨어 및 하드웨어 시스템의 형식 검증, 정리 증명 및 자동화된 추론과 같은 영역에서 종종 사용된다(Reiter, 1975; Berzonsky, 1978). 한편, 자연어 추론은 보다 직관적인 인간-컴퓨터 상호작용을 가능하게 하며, 질의 응답(Shao et al., 2023; Jiang et al., 2021), 정보 검색(Zhu et al., 2023; Ai et al., 2023), 텍스트 요약(Liu et al., 2023), 감성 분석(Yu et al., 2023; Araci, 2019; Barbieri et al., 2021) 등의 작업을 지원한다.

그들의 개시 이후, 기초 모델들(Bommasani 등, 2021)은 자연어 처리(Qiao 등, 2022), 컴퓨터 비전(Wang 등, 2023), 및 멀티모달 태스크들(Li, 2023)을 포함하는 다양한 도메인들에 걸쳐 현저한 효능을 입증하였다. 그러나 범용 인공지능에 대한 급격한 관심은 기초 모델이 인간과 유사한 추론 능력을 발휘할 수 있는지에 대한 강력한 논쟁을 촉발했다. 이에 따라 기초 모델의 추론 능력에 대한 연구에 대한 관심이 급증하고 있다. 이전의 조사들이 상이한 관점들(Gu et al., 2023; Wang et al., 2023; Yin et al., 2023; Zong et al., 2023; Lou et al., 2023; Charalambous et al., 2023; Wang et al., 2023, 2023)으로부터 기초 모델들의 적용 가능성을 탐구했지만, 인간 추론 스타일들을 보다 밀접하게 에뮬레이트하는 멀티모달 및 상호작용 추론에서의 최근의 진보들에 구체적으로 초점을 맞추는 체계적이고 포괄적인 조사가 여전히 필요하다. 그림 2는 이 글에서 논의할 과제 및 기법과 관련된 추론의 개요를 제시한다.

파운데이션 모델들은 통상적으로 수십억 개의 파라미터들로 구성되며, 넓은 데이터세트(Bommasani et al., 2021) 상에서 자가-감독 학습을 사용하여 (사전-)트레이닝을 거친다(Jain et al., 2023). 일단 (사전-)훈련되면, 기초 모델들은 태스크-특정 미세 조정, 선형 프로빙, 또는 신속한 엔지니어링을 통해 수많은 다운스트림 태스크들을 해결하도록 적응될 수 있으며, 주목할만한 일반화 가능성 및 인상적인 정확도를 입증한다(Bommasani et al., 2021; Qiu et al., 2023). 기존의 변압기에서 사용되는 소프트 어텐션 메커니즘과 달리 시스템 2 어텐션(S2A)은 언어 추론을 용이하게 하기 위해 대용량 언어 모델(LLM)의 기능을 활용한다. 이 방법은 롱폼 콘텐츠 생성의 사실성과 객관성을 향상시킨다. 논리 규칙과 원리를 학습 과정에 통합함으로써(Mao et al., 2023), 이러한 모델들은 추론 및 추론과 같은 복잡한 작업을 수행할 수 있다. 이는 통계 패턴에만 의존하지 않고 명시적 지식(Mao et al., 2023) 및 논리적 추론에 기초하여 결정을 내릴 수 있게 한다(Yang et al., 2023). 인공지능 연구에서 빠르게 성장하는 분야로서, 기반 모델과의 추론은 복잡한 정보를 보다 인간다운 방식으로 이해하고 상호작용할 수 있는 모델을 개발하는 것을 목표로 한다. 이러한 모델은 논리적 추론과 지식 표현의 기초를 기반으로 하여 추상적 개념에 대한 추론과 논리적 규칙에 기반한 결정을 가능하게 한다.

첫째, 기초모형을 활용한 추론은 사전지식과 영역전문성의 적용을 가능하게 한다. 논리적 규칙은 전문가 지식으로부터 도출되거나 기존의 온톨로지 또는 지식 그래프로부터 형식화될 수 있다. 이 사전 지식을 활용함으로써 모델은 문제 영역에 대한 더 나은 이해로부터 이익을 얻을 수 있고 더 많은 정보에 입각한 결정을 내릴 수 있다. 둘째, 기초 모델을 사용한 추론은 견고성과 일반화 능력을 향상시킬 수 있다. 대규모 데이터에 포함된 정보를 통합하면 모델은 배포 중에 제한된 데이터에 직면하거나 보이지 않는 시나리오에 직면하는 상황을 더 잘 처리할 수 있습니다. 이를 통해 모델을 보다 신뢰할 수 있고 견고한 실제 사용을 연구할 수 있습니다.

기존의 설문조사와 달리, 프롬프트(Qiao et al., 2022), 환각(Rawte et al., 2023), 연역적 추론(Huang and Chang, 2022), 논리적 추론(Friedman, 2023; Yang et al., 2023), 인과적 추론(Kiciman et al., 2023; Stolfo et al., 2022), 건강 정보학(Qiu et al., 2023) 또는 AI 에이전트(Xi et al., 2023)와 같은 기초 모델의 특정 측면에 주로 초점을 맞춘 기존 설문조사와 달리, 본 논문은 이 분야의 다양한 연구 노력을 응집적이고 조직적으로 연결하는 것을 목표로 더 넓은 관점을 취한다. 그림 2에서 볼 수 있듯이 **상식 추론, 수학적 추론, 논리 추론, 인과 추론, 시각적 추론, 오디오** 를 포함한 다양한 추론 작업에 대한 간략한 개요를 제공합니다.

그림 1: 두 가지 광범위한 유형의 언어 추론과 지원되는 작업의 예.

추론, 멀티모달 추론, 내재된 추론, 실현 불가능한 추론, 그리고 그 이상. 이를 통해 현장의 다양한 측면 간의 상호 연결과 관계를 강조하는 포괄적인 개요를 제공하여 기초 모델을 사용하여 추론의 진보와 적극적으로 참여하려는 더 많은 연구 노력을 고무한다.

요약하면, 우리는 주로 지난 2년간의 연구에 초점을 맞춘 기초 모델에 대한 650개 이상의 논문을 대상으로 설문조사를 수행했다. 우리는 이러한 모델에서 사용되는 다양한 작업, 접근법, 기술 및 벤치마크에 대해 논의한다. 또한 질문-답변, 자동화된 추론 및 지식 표현과 같은 기초 모델을 사용하여 추론의 이점을 얻을 수 있는 다양한 응용 영역을 탐색한다. 또한 현재 추론의 도전과 한계에 대해 기초 모델과 향후 연구를 위한 잠재적 방향을 논의한다. 이 분야의 발전과 과제를 이해함으로써 연구자들은 더 인간과 유사하고 해석 가능한 방식으로 추론하고 결정을 내릴 수 있는 지능형 시스템을 개발하기 위한 새로운 길을 탐색할 수 있다. 전반적으로, 이 논문은 기초 모델, 그 현재 상태 및 미래의 가능성을 가진 추론에 대한 포괄적인 이해를 제공하는 것을 목표로 한다.

## 2 Background

이 절에서는 추론을 위한 기초 모델에 대한 배경 지식을 소개한다. 우리는 추론이 무엇인지, 최근 진행 상황과 같은 주요 측면을 조사할 것이다.

그림 2: 왼쪽: 3절에서 자세히 설명한 대로 이 조사에서 소개한 추론 과제의 개요. 오른쪽: 4절에서 자세히 설명한 대로 기초 모델에 대한 추론 기술의 개요.

일반적인 기초 모델, 기초 모델의 아키텍처 설계, 사용된 훈련 방법론, 추론 작업에 적용할 수 있는 전이 학습 패러다임이다. 이러한 근본적인 측면을 해명함으로써 독자들이 기초 모델로 추론을 주도하는 기본 원칙과 기술을 이해하여 이 분야의 최근 발전과 방법론에 대한 후속 탐구의 단계를 설정하기를 바란다.

### 추론 정의

추론이라는 용어가 제기될 때, 그 정확한 의미는 종종 사람들에게 불분명하다. 명확하게 하기 위해 먼저 추론의 명확한 정의를 정립해 보자. "추론"은 다양한 맥락에서 나타나는 광범위하고 다면적인 개념이다. 정보를 분석하고, 추론하고, 결론을 도출하고, 일관된 주장을 공식화하는 데 사용되는 인지 과정과 논리적 사고를 포함한다. 추론은 과학적 탐구, 문제 해결, 의사 결정, 일상 담론과 같은 다양한 영역에서 관찰될 수 있다. 그 근본적인 목적은 개인이 정보를 연결하고 관계를 평가하고 정보에 입각한 판단이나 해결책에 도달할 수 있도록 하는 것이다. 추론의 다양한 측면과 차원을 탐구함으로써 그 중요성에 대한 포괄적인 이해를 얻고 인간 인식의 이러한 근본적인 측면을 설명하고 향상시키는 데 사용되는 수학적 형식 및 기술을 탐구할 수 있다.

"추론"이라는 용어는 넓은 개념적 성격 외에도 다양한 분야 내에서 구체적인 정의를 담고 있다. 추론의 정의에 대해 간단히 살펴보자.

\begin{table}
\begin{tabular}{l|l} \hline \hline Context & Lee found the Northeast to be way too cold. Lee \\  & decided to move to Florida. \\ \hline Question & How would you describe Lee? \\ \hline \multirow{3}{*}{Answers} & a) happy \\  & b) likes cold weather \\  & **c) likes the heat** \\ \hline \hline \end{tabular}
\end{table}
표 1: Social IQA로부터의 상식 추론 문제의 예(Sap 등, 2019). 정답은 굵게 쓰여 있다.

\begin{table}
\begin{tabular}{l|l} \hline \hline Problem & A farmer has 3 types of fruits in his garden: apples, oranges, and pears. He has twice as many apples as oranges and three times as many pears as apples. If he has 24 oranges, how many pieces of fruit does he have in total? \\ \hline Expression & \(x=24\times 2+24\times 3\times 2+24\) \\ \hline Solution & 216 \\ \hline \hline \end{tabular}
\end{table}
표 2: 샘플 수학 단어 문제(MWP).

(Clark et al., 2020; Huang and Chang, 2022; Yang et al., 2022c; Young et al., 2022; Yu et al., 2023a).

철학 정의 1: (인지 추론). 인지 추론은 지식의 획득 및 업데이트로부터 결론의 도출까지의 모든 프로세스가 적절한 하드웨어 상에서 구현가능하고 실행가능해야 하는 지식의 표현을 수반하는 불완전하고 일관되지 않은 지식에도 불구하고 의미 있는 결론을 도출하는 인간의 능력을 모델링하는 것을 지칭한다(Furbach et al., 2019).

LogicDefinition 2: (논리 추론) 논리적 추론은 결론이 전제와 이러한 전제 사이의 관계를 기반으로 체계적으로 도출되는 사고 과정을 수반하여 결론이 논리적으로 암시되거나 필요한 것을 보장한다(Nunes, 2012).

NlpDefinition 3: (자연어 추론). 자연어 추론은 여러 지식(예를 들어, 백과사전적 지식과 상식적 지식)을 통합하여 (현실적 또는 가상적) 세계에 대한 몇 가지 새로운 결론을 도출하는 과정이다. 지식은 명시적이고 암시적인 출처에서 파생될 수 있다. 결론은 세계에서 참으로 가정된 주장 또는 사건, 또는 실질적인 행동이다(Yu et al., 2023a).

우리는 또한 다음 절에서 볼 수 있듯이 다른 관점에서 분류함으로써 추론이 무엇인지 더 잘 이해할 수 있다.

\begin{table}
\begin{tabular}{l l} \hline \hline \multicolumn{2}{c}{**Example**} \\ \hline Fact1 & This animal is a robin. \\ Rule & All robins are birds. \\ Fact2 & This animal is a bird. \\ \hline
**Reasoning Type** & **Representation** \\ \hline Deduction & (Fact1 + Rule \(\rightarrow\) Fact2) \\ Abduction & (Fact1 + Rule \(\leftarrow\) Fact2) \\ Induction & (Fact1 + Fact2 \(\rightarrow\) Rule) \\ \hline \hline \end{tabular}
\end{table}
표 3: 연역적 추론, 귀납적 추론, 귀납적 추론의 일러스트레이션. 이 예에서, 검은색 텍스트는 주어진 지식을 나타내는 반면, 빨간색 텍스트는 추론된 지식을 나타낸다. "팩트"라는 용어는 특정 정보를 나타내는 반면, "룰"은 일반적인 원칙 또는 지침을 나타낸다.

#### 2.1.1 Ductive, Abductive, Inductive Reasoning

최근의 발전을 탐구하기 전에 먼저 추론에 대한 전통적인 관점을 검토하고 귀납적 추론, 연역적 추론, 귀납적 추론의 세 가지 주요 유형으로 분류한다. 이러한 범주화는 오랫동안 인식되어 왔으며 다양한 추론 모드를 이해하기 위한 프레임워크를 제공한다. 각각의 유형을 조사함으로써, 우리는 그들의 독특한 특성과 응용을 더 잘 이해할 수 있다. 따라서 추론 과정에 대한 이해를 높이기 위해 이러한 전통적인 범주를 자세히 살펴보겠습니다.

표 3은 이 세 가지 추론 유형을 각각 설명하는 예를 제공한다. 연역적 추론은 일반적인 원칙이나 전제로부터 구체적인 결론을 도출하는 논리적 과정이다. 일반적인 원칙에서 시작하여 논리적 규칙을 적용하여 구체적인 결론에 도달하는 하향식 접근법을 따른다. 연역적 추론은 논리적으로 타당하고 결정적인 결과를 제공하는 것을 목표로 한다.

귀납적 추론은 특정한 관찰이나 증거에 기초하여 일반적인 결론이나 패턴을 그리는 것을 포함한다. 특정 사례에서 광범위한 일반화로 이동합니다. 귀납적 추론은 절대적인 확실성을 보장하는 것이 아니라 이용 가능한 증거에 기초하여 개연성 있는 결론을 제공한다(Wang et al., 2023).

귀납적 추론은 관찰된 사실이나 자료를 설명하기 위해 그럴듯한 설명이나 가설을 만드는 과정이다. 그것은 불완전하거나 제한된 정보로부터 가능한 최선의 설명을 추론하는 것을 포함한다. 귀납적 추론은 문제 해결과 가설 생성에 자주 사용된다.

일반적으로 사용되는 추론 용어에서, 비낙오적 논증(전제와 결론으로 구성된 논증)(Flach and Kakas, 2000)의 경우, 연역적 논증은 전제가 결론에 대한 결정적인 지지를 제공할 수 있을 때 그와 같이 분류된다. 즉, 논증의 전제가 모두 참이라면 결론이 거짓이 되는 것은 불가능할 것이다. 한편, 귀납적 논증은 결론에 대한 부분적인 지지만을 제공하는 전제가 특징이다(Salmon et al., 1989). 귀납적 논증의 경우, 결론은 구내에 포함된 정보를 확장하거나 능가한다(Salmon et al., 1989). 확정적 증명을 제공하는 연역적 주장이나 부분적 지지를 제공하는 귀납적 주장과 달리 귀납적 주장은 가능한 유일한 설명이 아닐지라도 주어진 상황에 대해 가장 합리적인 설명을 제공하는 것을 목표로 한다.

전형적으로, 추론 유형들의 트라이오(연역, 외전, 귀납)에서, 가장 광범위하게 연구 및 탐구된 것이 연역인 반면, 외전 및 귀납에 관한 연구는 상대적으로 제한적이고 덜 탐구된 채로 남아 있다(Flach and Kakas, 2000; Yang et al., 2023). 고무적으로 귀납적 추론 분야에서 최근 진전이 이루어지고 있다. Sinha 등(2019)은 자연어 이해(Natural Language Understanding, NLU)를 이용하여 단편 소설에서 친족 관계를 분류하기 위한 CLUTRR 데이터셋을 제안한다. 귀납적 관계 유도(Yang et al., 2022)는 보이지 않는 엔티티들을 포함하는 관계의 예측을 조사한다. Misra 등(2022)은 신경망을 이용하여 합성 언어 문장을 분류하는 것에 중점을 둔 반면 Yang and Deng(2021)은 준자연어(자연어보다는 기호어)를 이용한 규칙 귀납법을 연구하였다.

추론 과제의 다른 분류는 다음을 포함한다:

1. **형식 추론 vs. 비형식적 추론**(Evans and Thompson, 2004; Teig and Scherer, 2016): 이 분류법은 추론 과정의 성격이나 형식성에 기초한다. 형식적 추론은 결론을 도출하기 위해 엄격한 규칙, 논리적 틀 또는 형식적 체계를 따르는 것을 포함하며 종종 수학적 또는 연역적 추론에 의존한다. 반면 비형식적 추론은 개인적 경험, 상식, 휴리스틱에 의존하여 덜 구조화되고 직관적이다.
2. **신경 추론 vs. 상징적 추론 vs. Neural-Symbolic Reasoning**(Garcez et al., 2008, 2015, 2022): 이 분류법은 추론을 위해 사용되는 기본 계산 프레임워크를 기반으로 합니다. 신경추론은 추론 작업을 위해 신경망이나 딥러닝 모델을 활용하는 접근법을 의미한다. 기호적 추론은 기호 표현, 논리 기반 추론 규칙 또는 추론을 위한 기호 조작을 사용하는 것을 포함한다. 신경-상징적 추론은 신경망과 상징추론의 요소를 결합하여 각각의 장점을 통합하는 것을 목표로 한다.
3. **Backward Reasoning vs. Forward Reasoning**(Al-Ajlan, 2015): 이 분류법은 추론 프로세스의 방향을 기반으로 합니다. 후향 추론은 목표나 원하는 결과에서 출발하여 그 목표에 도달하기 위해 필요한 조건이나 단계를 결정하기 위해 규칙이나 증거를 적용하여 역으로 작동한다. 순방향 추론은 초기 전제나 증거로부터 시작하여 단계적으로 진행하여 새로운 결론을 도출하거나 최종 결과에 도달한다.
4. **단일 단계 추론 vs. 다단계 추론**(Song et al., 2018; Yu et al., 2023a): 이 분류법은 추론 프로세스와 관련된 단계의 복잡성 또는 수를 기반으로 한다. 다단계 추론은 해결책이나 결론에 도달하기 위해 다수의 순차적 또는 상호 연결된 단계를 필요로 하는 작업을 의미한다. 그것은 최종 결과에 도달하기 위해 중간 단계 또는 추론을 함께 연결하는 것을 포함한다.
5. **연역적 추론 vs. Defeasible Reasoning**(Yu et al., 2023a; Koons, 2005; Pollock, 1987, 1991): 이러한 유형의 추론에 대한 분류 기준은 추론 프로세스의 특성 및 예외 또는 충돌하는 정보의 처리에 기초한다. 실현 가능한 추론은 불확실성이 있거나 불완전한 정보를 가진 추론을 포함하며, 여기서 결론은 새로운 증거나 예외에 의해 무시되거나 패배될 수 있다. 추가적인 정보나 맥락을 바탕으로 결론을 수정하거나 재평가할 수 있도록 한다.
6. **Unimodal Reasoning vs. Multimodal Reasoning**(Sowa, 2003; Oberlander et al., 1996): 이 분류법은 추론 과정에서 사용되는 입력 양식에 기초한다. 유니모달 추론은 정보 또는 입력의 단일 모달리티를 수반하는 추론 태스크, 예를 들어 언어 정보만을 기반으로 하는 추론 태스크를 지칭한다. 반면에 멀티모달 추론은 정보의 여러 모달리티와 동시에 통합하고 추론하는 것을 포함한다. 이것은 추론 프로세스를 위한 시각적, 언어, 텍스트적, 청각적 또는 다른 유형의 입력을 결합하는 것을 포함할 수 있다.

위에서 언급한 범주화 외에도 정보 및 추론을 분류하거나 범주화하는 방법에는 사실 추론(Byrne and Tasso, 1999), 반사실 추론(Bottou et al., 2013), 그럴듯한(defeasible) 추론(Collins and Michalski, 1989), 디폴트 추론(Brewka, 2012), 추상 추론(Yu et al., 2021) 등이 있다.

#### 2.1.2 수학적 표현

이상과 같은 다양한 정의와 관점을 인정함으로써 철학적 탐구, 형식 논리, NLP와 같은 분야의 실제적 응용에 걸쳐 있는 다면적인 개념으로서 추론에 대한 보다 풍부한 이해를 얻게 된다. 이 섹션에서는 이러한 영역에 걸쳐 추론의 공통점과 고유한 특성을 탐색하고 추론 과정의 이해와 구현을 향상시키기 위해 사용되는 수학적 방법론을 조사할 것이다. 다음은 상이한 수학적 프레임워크에서 추론을 예시하는 예들이다:

_Propositional Logic_

논리적 명제: \(p\)와 \(q\)를 논리적 명제로 하자. 우리는 그들의 연결선(AND)을 \(p\wedge q\)으로 나타낼 수 있다. Modus Ponens: \(p\to q\) 및 \(p\)이 참이면 \(q\)을 결론을 내릴 수 있습니다. 이를 \((p\to q)\wedge p\to q\)로 나타낼 수 있다.

_Predicate Logic_

정량자와 술어: \(P(x)\)를 "\(x\)은 소수"를 나타내는 술어로 하자. 실존 양자화기 \((\exists)\)는 \(\exists xP(x)\)와 같이 소수의 존재를 표현하기 위해 사용될 수 있다. 범용 양자화기: \(Q(x)\)를 "\(x\)는 짝수"를 나타내는 술어로 하자. 범용 양자화기 \((\forall)\)는 \(\forall xQ(x)\)와 같이 모든 숫자가 짝수임을 표현하기 위해 사용될 수 있다.

_Set Theory_

교차로 설정: \(A\) 및 \(B\)를 집합으로 둡니다. \(A\)과 \(B\)의 교차는 \(A\cap B\)으로 표시된다. 보체 설정: \(A\)을 집합으로 설정합니다. \(A\)의 보체를 \(A^{\prime}\)이라고 한다.

_Graph Theory_

그래프 표현: \(G=(V,E)\)을 그래프로 하자, 여기서 \(V\)은 노드들의 집합을 나타내고 \(E\)은 에지들의 집합을 나타낸다. 가장 짧은 경로: \(d(u,v)\)는 그래프에서 노드 \(u\)와 \(v\) 사이의 가장 짧은 경로를 나타냅니다. 최단 경로 문제는 모든 노드 쌍에 대해 \(d(u,v)\)의 최소값을 찾는 것으로 공식화될 수 있다.

_Conditional Probability_

\(P(A)\)는 이벤트 확률을 나타냅니다 \(A\) 및 \(P(B)\)는 이벤트 확률을 나타냅니다 \(B\). 주어진 \(B\)의 조건부 확률은 \(P(A|B)\)로 표시되며 Bayes 정리를 사용하여 계산할 수 있다.

_Formal Systems_

공리적 체계: 공리 집합과 추론 규칙 집합을 가진 공리적 체계라고 하자. 시스템 내의 형식적 증명은 일련의 진술로 표현될 수 있는데, 여기서 각 진술은 공리이거나 추론 규칙을 사용하여 도출된다.

이러한 수학적 표현은 추론이 어떻게 다른 틀에서 수학적으로 표현될 수 있는지를 엿볼 수 있다. 그러나, 추론 문제의 복잡성은 종종 더 정교한 수학적 표현과 형식론을 필요로 하는 것이 중요하다.

이러한 전통적인 범주화와 엄격한 수학적 표현에도 불구하고 기초 모델의 등장으로 연구자들은 이러한 제한에 대한 엄격한 준수에서 점점 더 멀어지고 있다. 대신, 그들은 다양한 시나리오에서 다양한 형태와 응용 프로그램을 고려하여 추론에 대한 보다 유연한 접근법을 수용했다.

현대 연구에서 추론은 광범위한 과제와 맥락을 포괄하도록 발전했다. 예를 들어, 상식 추론은 AI 시스템에 일상적인 상황에 대한 이해와 추론 능력을 부여하여 공통 지식과 맥락적 이해를 통합하는 것을 목표로 연구의 중요한 영역으로 부상했다. 상식 추론을 설명하는 예는 표 1에 나와 있다. 마찬가지로 수학적 추론은 특히 기초 모델의 맥락에서 상당한 관심을 받았다. 연구자들은 수학 단어 문제를 해결하는 것을 포함하여 모델의 수학적 추론 능력을 향상시키는 방법을 탐색하고 있다. 수학 추론, 특히 수학 단어 문제를 보여주는 예는 표 2에 나와 있다.

이러한 예는 다양한 응용 영역에서 추론의 다양한 표현을 강조한다. 초점은 엄격한 분류에서 특정 추론 문제를 해결하고 효과적으로 다룰 수 있는 모델을 설계하는 것으로 전환되었다. 이 보다 유연하고 응용 중심의 관점을 수용함으로써 연구자들은 추론의 범위를 넓히고 다양한 작업 및 컨텍스트에 걸쳐 인간과 유사한 추론 능력을 나타낼 수 있는 AI 시스템의 개발을 발전시키는 것을 목표로 한다.

### Foundation Models and Recurrent Progress

최근 인공지능 분야는 기반 모델의 급속한 발전을 목격하고 있다. 기초 모델은 컴퓨터 비전, 자연 언어 처리 및 음성 인식을 포함하지만 이에 국한되지 않는 다양한 영역에 혁명을 일으켰다. 다음으로 <그림 3>에 정리된 바와 같이 기초모형의 세 가지 대분류와 그 대표작을 소개한다.

그림 3: 기초 모형은 주로 언어, 비전, 멀티모달 기초 모형으로 분류할 수 있으며, 각 모형은 활발히 연구되고 있는 분야이다.

#### 언어 기반 모델 및 언어 프롬프트

GPT-3(Brown et al., 2020)과 같은 기초 모델은 자연어 이해 및 생성 작업에서의 돌파구를 먼저 예고한다. 이러한 모델은 자연어로 일관되고 맥락적으로 적절한 응답을 이해하고 생성하는 능력을 보여주었으며 텍스트 완성, 번역, 대화, 요약, 질의 응답 및 그 이상을 포함한 다양한 언어 관련 작업에서 상당한 진전을 이루었다.

최근, 연구 및 정제된 트레이닝 방법론의 발전에 따라, 다양한 진보된 대규모 언어 모델(Zhao et al., 2023)SS가 출현하였다. 그 중 눈에 띄는 것은 Chat-GPT에 전력을 공급하는 GPT-4(OpenAI, 2023), Bard의 중요한 구성요소인 PaLM(Chowdhery 등, 2022)이다. 추가로, LLaMA(Touvron et al., 2023) 및 Llama 2(Touvron et al., 2023)는 7B에서 65B까지 파라미터가 변하는 오픈 소스 대형 언어 모델의 컬렉션으로서 인기를 얻었다. 다국어 지원에 대한 초점은 기초 모델링 연구의 핵심 관심 분야이기도 하다. 예를 들어, 중국어 데이터의 1.1 TB에 대해 사전 훈련되고 2,000억 개의 파라미터를 가진 PanGu-\(\alpha\)(Zeng et al., 2021)은 강력한 언어 모델링 기능을 보여준다. 또한 PanGu-\(\Sigma\)(Ren et al., 2023)은 RRE(Random Routed Experts)와 ECSS(Expert Computation and Storage Separation)와 같은 기법을 활용하여 조 단위의 언어 모델을 학습하는 시스템을 개발함으로써 이기종 컴퓨팅을 통한 학습 처리량이 6.3배 크게 증가하였다.

각주 §: [https://github.com/RUCAIBox/LLMSurvey](https://github.com/RUCAIBox/LLMSurvey)

#### Vision Foundation Models and Visual Prompt

언어 영역에서 기초 모델의 놀라운 성공에 이어, 그 의미는 비전 분야의 영역도 초월한다.

비전 트랜스포머(ViT)(Dosovitskiy et al., 2021)는 트랜스포머 프레임워크를 컴퓨터 비전 태스크에 적용하여, 셀프-어텐션 메커니즘을 활용하여 분류 및 검색 태스크에서 인상적인 성능을 달성한다. Swin Transformer(Liu et al., 2021)는 윈도우가 쉬프트된 계층적 구조를 도입하여 고해상도 영상을 처리하는 효율을 향상시켰다. 이미지 분류, 객체 탐지 및 시맨틱 세분화와 같은 다양한 컴퓨터 비전 작업에 걸쳐 강력한 성능을 입증했습니다. MAE(He et al., 2022), BEIT(Bao et al., 2021), CAE(Chen et al., 2023)와 같은 방법들은 범용의 시각적 표현을 학습하기 위한 효율적인 자기 지도 학습 전략으로서 마스킹된 모델링을 제안한다. VideoMAE V2(Wang et al., 2023)는 비디오 이해 작업을 위해 설계된 10억 개의 파라미터를 갖는 VideoMAE(Tong et al., 2022)의 향상된 버전이다. 자기 지도 학습을 활용하여 시간 및 공간적 종속성을 학습하여 동작 분류 및 동작 감지와 같은 작업에 탁월하다. 멀티태스크 비전 기초 모델로서, 플로렌스(Yuan et al., 2021) 및 플로렌스-2(Ding et al., 2022; Xiao et al., 2023)는 분류, 검색, 객체 검출, 시각 질의 응답(VQA), 이미지 캡셔닝, 비디오 검색 및 액션 인식 등과 같은 다양한 컴퓨터 비전 작업에 용이하게 적응될 수 있다. SAM(Segment Anything Model) (Kirillov et al., 2023)은 부분 마스크, 포인트 또는 박스와 같은 입력 프롬프트로부터 객체 마스크를 생산하는 데 탁월하다. 이미지의 모든 객체에 대한 마스크를 생성할 수 있습니다. SAM은 1100만 개의 이미지와 11억 개의 마스크를 포함하는 방대한 데이터 세트에 대해 훈련된다. 특히, SAM은 광범위한 분할 작업에 걸쳐 제로 샷 성능을 보여준다. Zero-shot anomaly segmentation으로 Segment Any Anomaly+ (SAA+) (Cao et al., 2023)는 기반 모델의 적응성을 향상시키기 위해 타겟 이미지로부터 도메인별 전문 지식 및 컨텍스트 정보를 활용하는 하이브리드 프롬프트 정규화(hybrid prompt regularization)를 도입한다. 이러한 요소를 정규화 프롬프트에 통합함으로써 SAA+는 프롬프트의 견고성을 강화하여 이상 지역을 보다 정확하게 식별할 수 있다. 나아가, Wang 등(2023)은 복잡한 장면에서 세그먼트화 과제를 해결하는 데 있어서 도메인 전문가 지식을 사전 지원으로서 통합하는 가능성을 또한 밝혔다.

_모델 융합: Combination__을 통한 Visual Task 개선

컴퓨터 비전 분야에서는 복잡한 시각적 작업을 보다 효과적으로 다루기 위해 각각 특정 작업을 전문으로 하는 서로 다른 사전 훈련된 비전 기초 모델을 결합하는 경향이 있다. 이러한 접근법은 이러한 기초 모델의 증가하는 힘과 다양성을 활용하여 도전적인 시각적 작업에서 우수한 성능을 달성하기 위해 개인의 장점을 활용한다.

인페인팅 Anything(Yu et al., 2023)은 이미지 인페인팅에서 세 가지 필수 기능, 즉 Remove Anything, Fill Anything, Replace Anything을 제시하는데, 이는 다양한 기초 모델의 상승적 결합을 통해 달성된다. 자동 분할을 위해 클릭 프롬프트를 활용하고, 마스킹된 영역을 채우기 위해 라마(Suvorov et al., 2021) 및 안정 확산(Rombach et al., 2022)과 같은 최첨단 인페인팅 모델을 활용하며, 텍스트 프롬프트와 함께 AI 모델을 채용하여 공극을 채우거나 대체하기 위한 특정 콘텐츠를 생성한다.

편집 Everything(Xie et al., 2023)은 SAM(Kirillov et al., 2023), CLIP(Radford et al., 2021) 및 Stable Diffusion(Rombach et al., 2022)을 결합하여 이미지 및 텍스트 입력 모두에 의해 안내되는 이미지 편집을 가능하게 하는 생성 시스템을 제시한다. 초기에, Edit Everything(Xie 등, 2023)은 SAM을 채용하여 원본 이미지를 여러 조각으로 분할한다. 이어서, 이미지 편집의 프로세스는 텍스트 프롬프트들에 의해 안내되어, 주어진 텍스트 프롬프트들에서 설명된 바와 같이 타겟 이미지와 대응되도록 소스 이미지를 조정하는 변환으로 이어진다.

SAM-Track(Cheng et al., 2023)은 여러 모달리티에 걸쳐 상호작용적이고 자동화된 객체 추적 및 세그먼트화를 용이하게 하기 위해 Grounding-DINO(Liu et al., 2023), DeAOT(Yang and Yang, 2022), SAM(Kirillov et al., 2023)을 통합하는 비디오 세그먼트화 프레임워크를 소개한다. 프레임워크는 SAM의 세그먼트화 프로세스를 안내하기 위해 비디오의 초기 프레임에서 클릭-프롬프트, 박스-프롬프트 및 텍스트-프롬프트를 포함하는 대화형 프롬프트를 허용한다. 설명 Any Concept(EAC)(Sun et al., 2023)은 개념 설명을 위한 접근법을 제시하며, 초기 세그먼테이션에 SAM을 활용하고 설명 프로세스의 효율성을 높이기 위해 대리 모델을 도입한다.

#### Multimodal Foundation Models

기초 모델이 언어 및 이미지와 같은 개별 모달리티에서 인상적인 성능을 계속 발휘함에 따라 자연스러운 확장이 발생한다. 이러한 모델은 멀티모달 데이터를 효과적으로 처리할 수 있는가? 이 질문은 실제 시나리오가 데이터에 대한 보다 포괄적이고 미묘한 이해를 집합적으로 제공하는 텍스트, 이미지 및 오디오와 같은 여러 모달리티를 포함하는 경우가 많다는 인식에서 발생한다.

Text2Seg(Zhang et al., 2023d)는 텍스트 프롬프트를 입력으로 활용하여 세그멘테이션 마스크를 생성하는 비전 언어 모델을 소개한다. 모델은 세그먼트화 마스크들을 생성하는데 SAM을 안내하는 Grounding DINO(Liu et al., 2023j)와 함께 바운딩 박스들을 생성하기 위해 텍스트 프롬프트를 사용함으로써 동작한다. CLIP(Radford et al., 2021)는 이미지와 텍스트의 공동 표현을 학습한다. 시각적 정보와 텍스트적 정보를 정렬하여 교차 모달적 이해를 가능하게 하고, 다양한 비전과 언어 과제에서 인상적인 역량을 발휘함으로써 이를 달성한다. 유사하게, 방법들(Chen et al., 2020; Li et al., 2020; Zhang et al., 2021; Zhai et al., 2022; Yao et al., 2021; Jia et al., 2021; Huo et al., 2021; Fei et al., 2022), ALIGN(Jia et al., 2021) 및 WenLan(Huo et al., 2021)과 같이, 공통 특징 공간을 학습함으로써 이미지 및 텍스트 표현들을 정렬한다. CoOp(Context Optimization)(Zhou et al., 2022b)은 다운스트림 작업에 대해 CLIP-유사 비전-언어 모델을 커스터마이징하기 위한 간단한 기술을 제시한다. CoOp은 미리 트레이닝된 파라미터들을 고정된 상태로 유지하면서 프롬프트에서 컨텍스트 워드들을 표현하기 위해 학습가능한 벡터들을 사용한다. GALIP(Generative Adversarial CLIPs)(Tao et al., 2023)는 텍스트 대 이미지 생성의 작업을 위해 특별히 개발된 또 다른 발전이다. CLIP Surgery(Li et al., 2023t)에서는 먼저 텍스트 프롬프트에 기초하여 히트맵이 생성된다. 그런 다음 이러한 히트맵으로부터 샘플링되는 포인트 프롬프트는 추가 처리를 위해 SAM(Kirillov 등, 2023)에 입력된다. 이어서, CLIP(Radford et al., 2021)를 활용한 유사도 알고리즘을 사용하여 최종 분할 맵을 생성한다. SAMText(He et al., 2023)는 장면 텍스트에 맞춘 세그먼트화 마스크들을 생성하기 위한 유연한 접근법을 제시한다. 이 방법은 기존의 장면 텍스트 검출 모델에 존재하는 주석들로부터 바운딩 박스 좌표들을 유도함으로써 시작된다. 그런 다음 이러한 좌표로 SAM에 마스크를 생성하라는 메시지가 표시됩니다. 캡션 Anything(Wang et al., 2023o)은 시각적 측면과 언어적 측면 모두에서 대화형 멀티모달 제어를 가능하게 하는 이미지 캡션을 위한 기초 모델-향상된 프레임워크를 제시한다. SAM(Kirillov et al., 2023)을 ChatGPT와 결합함으로써, 사용자는 상호작용 동안 포인트 프롬프트 또는 바운딩 박스 프롬프트를 포함하는 다양한 프롬프트를 사용하여 이미지를 조작하는 유연성을 얻는다. 또한, LMM(Large Language Models)을 활용하여 명령어를 세분화하여 사용자의 의도된 의미를 정확하게 반영하고 자신의 의도에 부합하는 상태를 유지하도록 한다. GPT-4V(비전)는 사용자에게 사용자가 제공하는 이미지 입력을 해석하고 분석할 수 있는 권한을 부여한다(OpenAI, 2023b).

기초 모델이 멀티모달 작업(텍스트 대 이미지, 텍스트 대 코드 및 음성 대 텍스트)에서 탁월할 수 있는 가능성은 다양한 영역에서 흥미로운 가능성을 열어줍니다. 이 모델은 다양한 모달리티의 정보를 원활하게 통합하고 처리함으로써 이미지 캡셔닝, 시각적 질문 응답 및 시청각 장면 이해와 같은 작업을 향상시킬 수 있다. 또한, 멀티모달 기반 모델은 여러 정보원에 기반한 추론 및 의사 결정이 필요한 응용 분야에서 가능성을 가지고 있다. 멀티모달 데이터의 힘을 활용함으로써, 이러한 모델들은 로봇 공학(Firoozi et al.,2023), 헬스케어(Qiu et al., 2023a), 자율 주행 차량(Zhou et al., 2023c) 및 멀티미디어 분석을 포함하는 광범위한 도메인에 걸쳐 새로운 수준의 이해, 상황 인식 및 성능을 해제할 가능성이 있다.

#### 추론 응용 프로그램에 대 한 잠재력입니다.

기초 모델과의 추론은 새로운 분야입니다. 최근 추론 과제에 기초 모델을 적용하려는 연구가 유입되고 유망한 결과가 달성되었다. 통계는 도 4에 제시된다. 라반 등(2023)은 LMM(Large Language Models)을 사용하여 복잡한 태스크를 평가하는 데 있어서의 과제를 식별하고 개선된 평가 벤치마크의 필요성을 강조한다. Shi 등(2023)은 다국어 언어 모델이 언어를 넘어 단어-인-컨텍스트 설정에서 상식 추론 및 의미 판단과 같은 작업을 수행할 수 있음을 보여준다. 언어 모델은 연쇄 사고 과정을 사용하는 다국어 추론기 역할을 한다. Self-Taught Reasoner (STaR) (Zelikman et al., 2022)는 정답을 기반으로 논리적 근거를 반복적으로 생성하고 미세 조정을 함으로써 모델의 추론 능력을 향상시킨다. MWP-BERT(Liang et al., 2022b)는 Math Word Problem(MWP) 해결을 해결하기 위해 BERT(Kenton and Toutanova, 2019)(110M) 및 RoBERTa(Liu et al., 2019)(123M) 사전 훈련을 모두 활용한다. 한편, PaLM(Chowdhery et al., 2022) 사전 훈련 언어 모델을 기반으로 하는 Minerva(Lewkowycz et al., 2022)는 최대 540B의 인상적인 파라미터 크기를 자랑한다. 미네르바는 화학, 생물학, 경제학, 물리학 및 양적 추론을 포함하는 기타 과학과 같은 다양한 분야의 200개 이상의 학부 수준의 문제의 거의 3분의 1에 정확하게 응답함으로써 강력한 성능을 보여준다. 제로-샷-CoT(Kojima et al., 2022)는 MultiArith(Patel et al., 2021), GSM8K(Cobbe et al., 2021)와 같은 산술 과제를 포함하는 다양한 추론 태스크에 걸쳐 인상적인 성능을 보여준다.

도. 4: 지난 2년간 "대형 언어 모델과의 추론"에 관한 arXiv 논문 수. 2023년 몇 달 동안 기사 수가 눈에 띄게 급증하는 등 연구 관심의 증가 추세를 묘사하고 있다.

2021), AQUA-RAT(Ling et al., 2017), SVAMP(Patel et al., 2021), 심볼릭 추론, 및 데이트 이해(Srivastava et al., 2023), 트래킹 셔플드 오브젝트(Srivastava et al., 2023)와 같은 다른 논리적 추론 태스크는 모두 수작업으로 조작된 소수의 샷 예에 대한 필요성이 없다. 단 하나의 신속한 템플릿을 사용하여 이 접근법은 LLM의 제로 샷 가능성과 고수준의 다중 작업 인지 능력을 나타내는 동시에 이 분야의 추가 연구에 대한 중요한 전망을 강조한다.

그러나, 단순한 패턴 인식을 넘어 보다 정교한 형태의 추론을 수행할 수 있는 지능형 시스템에 대한 요구가 여전히 존재한다.

## 3 추론 작업

이 절에서는 그림 2와 같이 다양한 추론 과제에 대한 간결한 개요를 제공한다. 여기서, 우리는 추론 접근법들 및 태스크들의 구별되는 카테고리들을 제시한다:

* 상식 추론(섹션 3.1): 일상적이고 직관적인 지식을 추론하고 적용할 수 있는 능력 탐색.
* 수학적 추론(3.2절): 수학적 문제를 해결하고 논리적 결론을 도출하는 능력을 중심으로
* 논리적 추론(섹션 3.3): 추론을 그리고 공식 논리에 기초하여 결정을 내리는 과정을 조사한다.
* 인과 추론(섹션 3.4): 원인과 결과 관계에 대한 이해와 그 의미를 조사한다.
* 멀티모달 추론(섹션 3.7): 텍스트, 이미지 및 감각 정보와 같은 여러 데이터 모달리티에 걸친 추론 관련.
* 시각적 추론(섹션 3.5): 시각적 데이터의 해석과 조작이 필요한 작업을 중심으로
* 구체화된 추론(섹션 3.8): 그들의 환경과 상호작용하는 구체화된 에이전트의 컨텍스트에서 추론을 탐구한다.
* 기타 추론 작업(섹션 3.9): 추론에 대한 논의는 추상적 추론 3.9.7, 패배 가능한 추론 3.9.8과 같은 개념적 프레임워크뿐만 아니라 의학적 추론 3.9.3, 생물정보학적 추론 3.9.4와 같은 응용 분야를 비롯하여 다양한 컨텍스트에 걸쳐 확장된다. 우리는 또한 연구자들이 3.9.6을 탐구할 수 있는 응용 프로그램에서 긴 사슬 추론의 엄청난 유용성을 강조한다.

이 포괄적인 개요는 추론 작업의 다양한 지형과 현장 내 접근 방식에 대한 통찰력을 제공한다. 각 추론 부문의 주요 작업 요약은 그림 5에서 확인할 수 있다.

### Commonsense Reasoning

상식 추론은 인간이 일상적으로 접하는 일상적인 상황의 성격과 특성에 대해 가정과 추론을 규칙적으로 할 수 있는 인간다운 능력을 말한다.

최근의 연구는 언어 모델이 상식 지식의 특정 측면을 획득할 수 있음을 나타낸다(Zhao et al., 2023; Ye et al., 2023). 구조화된 상식 추론의 영역에서, Madaan 등(2022)은 자연어 입력에 기초하여 그래프를 생성함으로써 과제를 해결한다. 그들은 그래프 표현을 구성하기 위해 코드로 프롬프트되는 큰 언어 모델을 활용하여 이 문제를 코드 생성 도전으로 공식화한다. Berglund 등(2023)은 또한 언어 모델들이 종종 논리적 연역에서의 근본적인 경과를 보여줌으로써, 그들의 트레이닝 세트에서의 공통 패턴을 일반화하는 데 실패하며, 구체적으로, "A가 B인 경우 "B가 A"가 발생할 가능성이 존재한다고 지적한다. Li et al. (2022)는 이에 대한 체계적인 접근법을 취한다.

그림 5: 기초모형을 이용한 추론과제 분류 각 작업 유형에 대한 대표적인 접근법만 나열됩니다.

다양한 상식 벤치마크에서 사전 훈련된 대규모 언어 모델의 성능을 평가합니다. 그들은 6개의 다른 모델 크기를 고려하여 4개의 다른 벤치마크에 걸쳐 0-샷 및 소수의 상식 평가를 수행한다. 특히, 그들의 평가에는 2,800억 개의 매개변수를 가진 현저하게 큰 언어 모델이 포함된다. 다양한 점수 함수 및 프롬프트 형식과 같은 여러 평가 설정을 탐색하여 상식 지식에 대한 모델의 포착 및 추론 능력을 종합적으로 평가한다.

상식 추론 분야의 또 다른 방향은 미리 훈련된 언어 모델과 상식별 미세 조정 기술을 결합하는 것이다. Chang 등(2021)은 몇 가지 아키텍처 변형을 제안하고, 외부 상식 말뭉치를 활용하고, 소셜 IQA 태스크를 위해 상식-특정 미세 조정 기술을 사용한다(Sap 등, 2019). 그들은 작업을 통해 이러한 최적화가 소셜 인텔리전스와 관련된 작업에서 모델의 성능을 향상시킬 수 있음을 보여준다. 또한, Yang et al.(2023)은 상식 생성의 과제에서 사전 훈련과 미세 조정을 연결하도록 설계된 2단계 프레임워크를 소개한다.

위에서 언급한 작품 외에도 탐구된 상식 추론의 다른 측면도 있다. 여기에는 그림 6과 같이 상식 질문 응답(QA), 물리적 추론, 공간 추론 및 해당 벤치마크가 포함된다. 이러한 연구 영역은 언어 모델이 다양한 맥락에서 상식 지식을 효과적으로 포착하고 추론할 수 있는 방법에 대한 더 깊은 이해에 기여한다.

#### 상식 질문 및 응답 (QA)

상식 추론의 하위 분야로서 상식 질문 응답(QA)은 일상적인 지식과 인간 같은 추론에 대한 깊은 이해가 필요한 질문에 답할 수 있는 시스템을 개발하는 데 중점을 둔다. 명시적 정보로부터 답을 도출할 수 있는 전통적인 사실 기반 QA와 달리 상식 QA는 그림 6(a)와 같이 암묵적 지식과 일상적인 인간 추론에 대한 이해와 추론을 포함한다.

<그림 6>은 상식 추론에서 기초 모형의 세 가지 연구 영역이다. (a) 일상적인 지식을 이해함으로써, 기초 모델은 질문으로부터 암시적 지식에 대해 추론하고 답변을 추론할 수 있다. (b) Foundation 모델은 일반적인 물리적 지식으로부터 광범위한 물리적 속성을 추론한다. (c) 기초 모델들은 객체들의 세트로부터 공간 속성들에 대해 추론한다.

상식 질문 응답(CQA) 데이터세트(Talmor et al., 2019)는 상식 질문 응답을 위해 특별히 설계된 도전형 객관식 데이터세트이다. ConceptNet(Speer et al., 2017)에서 도출된 것으로 약 12,000개의 문항으로 구성되어 있다. 모든 질문에는 1개의 정답과 4개의 추가 방해자 답이 함께 제공됩니다. 또한, CoS-E(Commonsense Explanations) 데이터셋(Rajani et al., 2019)에는 CQA 데이터셋에 대한 인간의 상식 설명이 포함되어 있다. CoS-E 데이터 세트는 답변 선택을 정당화하는 질문에 강조 표시된 텍스트 스팬인 선택 설명과 자유 형식 자연어 설명인 개방형 설명의 두 가지 유형의 설명으로 구성된다.

CAGE(Commonsense Auto-Generated Explanation) 모델(Rajani et al., 2019)은 문제 입력과 인간 생성 설명을 모두 사용하여 미세 조정하여 유용한 설명을 생성하기 위해 언어 모델을 훈련시키는 것을 포함하는 프레임워크이다.

효과적인 상식 QA 시스템의 개발은 활발한 연구 분야이며 언어 모델, 지식 표현 및 추론 기술의 지속적인 발전은 기계 지능에서 상식 이해의 경계를 계속 밀어내고 있다.

#### 3.1.2 Physical Commonsense Reasoning

상식적 물리적 추론(Ding et al., 2021)은 그림 6(b)와 같이 물리적 세계에 대한 일상적인 지식을 활용하여 사물의 행동과 그 속성을 추론하고 이해하는 것을 포함한다. 물체 추론의 속성(중력, 질량, 관성, 또는 마찰), 이들의 어포던스, 및 이들이 어떻게 조작될 수 있는지에 관한 물리적 개념에 관한 추론을 포함한다(Chu et al., 2023).

ESPRIT(Explaining Solutions to Physical ReasonIng Tasks) 프레임워크(Rajani et al., 2020)는 상식적인 물리적 추론과 자연어 설명을 통한 해석 가능성을 결합한다. 첫 번째, 작업에서 중요한 물리적 사건을 정확히 파악하는 단계, 두 번째, 초기 장면과 이러한 중요한 사건 모두에 대한 자연어 설명을 만드는 단계의 두 단계로 작동한다. 프레임워크는 중력, 마찰, 충돌과 같은 상식적 물리적 개념에 대한 추론에 통일된 접근법을 제공하는 동시에 자연 언어를 사용하여 질적인 설명을 제공하는 것을 목표로 한다. PACS(Physical Audiovisual CommonSense)(Yu et al., 2022)는 물리적 시청각 상식 추론을 위해 설계된 데이터세트이다. 1,377개의 별개의 질문과 1,526개의 물리적 상식을 위한 비디오를 포함하여 13,400개의 질문-답변 쌍으로 구성된다. PACS는 유니모달 및 멀티모달 추론 모델을 벤치마킹하여 현재 모델의 한계와 개선 영역을 식별함으로써 멀티모달 추론 접근법을 조사하여 물리적 추론 연구를 추진할 수 있는 귀중한 기회를 제공한다. PIQA(Physical Interaction: Question Answering)(Bisk et al., 2020)는 물리적 상호작용의 도메인에서 객관식 질문-응답에 초점을 맞춘 데이터세트이다. 작업은 주어진 질문에 기초하여 두 개의 주어진 옵션으로부터 가장 적절한 솔루션을 선택하는 것을 포함한다. PIQA 데이터 세트는 개발 및 테스트를 위해 예약된 추가 데이터와 함께 16,000개 이상의 훈련 QA 쌍으로 구성된다. PIQA의 문항은 평균 길이가 7.8단어인 반면 정답과 오답 모두 평균 길이가 21.3단어이다. NEWTON(Wang et al., 2023)은 LLM의 물리적 추론 능력을 평가하기 위해 구체적으로 생성된 저장소, 파이프라인 및 벤치마크 역할을 하는 포괄적인 플랫폼이다.

캐터(Girdhar and Ramanan, 2020)는 주로 물리학과 관련된 시각적 장면에 초점을 맞추고 있다. CLEVRER(Yi et al., 2019)는 강체-신체 충돌의 동적 비디오에 근거된 물리적 및 인과적 관계를 타겟으로 하는 비디오 질문-응답 벤치마크이다. CLEVRER-Humans(Mao et al., 2022)는 이를 인간 레이블을 갖는 물리적 사건의 인과적 판단까지 더 확장한다. Physion(Bear et al., 2021), Physion++(Tung et al., 2023), 및 ComPhy(Chen et al., 2022)는 물리 엔진들로부터 렌더링된 동적 비디오들로부터 상이한 잠재 물리적 속성들(예를 들어, 질량, 마찰, 탄성, 및 변형성)을 갖는 객체들을 평가한다.

상기 벤치마크들에 기초하여, 변압기 기반 기초 모델들(Ding et al., 2020; Wu et al., 2022) 및 미분가능한 물리학을 갖는 신경-상징 프레임워크들(Ding et al., 2021)이 개발된다. 알로에(Attention over Learned Object Embeddings)(Ding et al., 2020)는 비지도 객체 분할을 위한 MONet(Burgess et al., 2019)을 자기 주의 메커니즘과 통합하여 객체에 대한 시공간 물리적 추론을 용이하게 한다. Transformer 기반 객체 중심 동역학 모델인 SlotFormer(Wu et al., 2022)는 비디오로부터 복잡한 시스템 및 상호작용을 비감독적으로 해독하도록 설계된다. Spatial Transformer(Jaderberg et al., 2016), Generative Structured World Models(G-SWM)(Lin et al., 2020)에 의해 제공되는 컨텍스트 인코딩을 활용하는 것은 객체 중심 세계 모델링을 발전시킨다. 이들은 V-Prop(Versatile Propagation)로 알려진 코어 모듈을 통해 멀티모달 불확실성과 상황 인식을 통합한다. 이러한 프레임워크와 데이터 세트는 설명과 멀티모달 분석을 통해 모델 평가, 해석 가능성 및 물리적 개념 이해를 위한 자원을 제공함으로써 상식적 물리적 추론의 발전에 기여한다.

현재 기초 모델을 기반으로 한 물리적 상식 추론 영역은 상대적으로 탐구되지 않아 연구 개발을 위한 익은 길을 제공한다. 이것은 연구자와 실무자가 이러한 모델로 가능한 것의 경계를 조사하고 확장할 수 있는 독특한 기회를 제공하여 잠재적으로 획기적인 발전과 혁신으로 이어진다.

#### 3.1.3 Spatial Commonsense Reasoning

공간 상식 추론은 그림 6(c)와 같이 사물의 공간적 위치를 탐지하고 시각적 자극 간의 관계를 추론하여 주변 환경을 이해하는 것을 포함한다. 공간 상식 추론 영역 내에서 두 가지 중요한 관점은 객체 척도(Aroca-Ouellette et al., 2021)와 공간 관계(Hudson and Manning, 2019)이다. Liu 등(2022)은 공간 상식 벤치마크를 도입하며, 객체들의 상대적인 크기들 및 다양한 동작들에 걸쳐 개인들과 객체들 사이의 공간 상호 작용들을 뚜렷하게 강조한다. 그들은 미리 훈련된 비전 언어 모델과 이미지 합성 모델을 포함한 다양한 모델의 성능을 조사한다. 흥미롭게도, 그들은 이미지를 합성하기 위한 모델이 다른 모델에 비해 공간 관계에 대한 정확한 일관된 지식을 학습하는 데 더 나은 능력을 보여준다는 것을 발견했다. 또한 이러한 이미지 합성 모델을 통해 얻은 공간 통찰력은 공간 상식 추론을 필요로 하는 자연어 이해 과제를 향상시키는 데 유용함을 보여준다.

### 3.2 수학적 추론

수학은 상징적 형태와 의미의 정밀성에 의존하는 별개의 언어로 자신을 구별하고 자연어에 비해 차원이 낮다. 이러한 독특한 특성은 수학적 개념들의 상징적 표현들에 의해 예시된 바와 같이, 학습된 규칙 세트들의 세트로부터 의미가 도출될 수 있다는 것을 증명할 수 있게 한다(Floyd, 2004). 수학적 문제는 기호와 대응하는 표현을 사용하여 표현될 때 효과적으로 프로그래밍될 수 있다. 기계 코드로 번역될 수 있는 컴퓨터 언어로 이러한 문제를 공식화함으로써, 딥 러닝 기반 추론 시스템은 기본 규칙을 훈련하고 획득하는 능력을 갖는다(힌튼, 1990; 슈미트후버, 2015; 프리드먼, 2023b).

실험 결과, 대용량 언어 모델(LLM)의 성능은 질문 난이도와 약한 상관관계를 보였다. 링 등(2017)은 답을 생성할 뿐만 아니라 얻은 결과에 대한 설명이나 근거를 제공하는 방식으로 대수적 단어 문제를 해결하는 접근법을 제안한다. MT2Net(Zhao et al., 2022b)은 MultiHiertt 데이터셋(Zhao et al., 2022b)을 다루기 위해 설계된 특화된 모델이다. 재무 보고서에서 뒷받침하는 사실을 검색하고 질문에 답하기 위한 실행 가능한 추론 프로그램을 생성한다. 이 접근법은 주어진 질문에 대한 포괄적이고 정확한 해결책을 제공하는 것을 목표로 한다.

#### Arithmetic Reasoning

Math Word Problem (MWPs)은 언어 모델의 산술 추론 능력을 평가하기 위해 일반적으로 사용된다. 이러한 문제가 인간에게 복잡하지 않게 나타날 수 있지만, 언어 모델은 산술 추론과 관련된 태스크와 관련하여 종종 도전에 직면한다(Hendrycks et al., 2021b; Patel et al., 2021).

이전 연구에서는 이러한 문제를 해결하기 위한 다양한 접근법을 탐구했다. KAZB(Kushman et al., 2014), ZDC(Zhou et al., 2015), 유사도 기반 방법 SIM(Huang et al., 2016)과 같은 템플릿 기반 통계 학습 방법이 활용되고 있다. Wang 등(2017)은 수학 단어 문제를 방정식 템플릿으로 변환하기 위해 순환 신경망(Recurrent Neural Network, RNN)을 채용하여 복잡한 특징 공학의 필요성을 제거한다. 또한 RNN과 유사도 기반 검색 시스템을 통합한 하이브리드 모델을 개발하여 성능을 더욱 높였다. Xie and Sun(2019)은 수학 단어 문제 해결을 위한 목표 지향적 방식으로 표현 트리를 구성하는 혁신적인 신경 접근법을 소개한다. Shen 등(2021a)은 수학 단어 문제에 대한 새로운 랭킹 과제를 소개하고, 생성 사전 훈련된 언어 모델과 멀티-태스크 학습을 결합한 Generate & Rank 프레임워크를 제시한다. 이 접근법을 통해 모델은 오류로부터 학습하고 올바른 표현과 잘못된 표현을 효과적으로 구별할 수 있다. 주목할 만한 발견은 인상적인 5,400억 개의 파라미터를 포함하는 언어 모델과 함께 체인-오브-사상 프롬프팅(chain-of-thought prompting)을 사용하는 것이 다수의 태스크에 걸쳐 태스크-특정 미세-튜닝된 모델에 필적하는 성능을 산출한다는 것이다(Wei 등, 2022b). 프로그램 합성, 지식 그래프 추론과 같은 전통적인 기호 추론 과제와 달리 MWP를 풀기 위해서는 수치적 추론에 대한 추가적인 강조가 필요하다. PromptPG(Lu et al., 2022b)는 인-컨텍스트 예들의 선택을 학습하기 위해 정책 그래디언트 기법들을 활용함으로써 상이한 접근법을 취한다. 테스트 예마다 적절한 프롬프트를 동적으로 구성함으로써 프롬프트PG는 수학 단어 문제의 해결을 용이하게 한다. 이 적응적인 접근법은 수치 추론 작업을 효과적으로 처리할 수 있는 모델의 능력을 향상시킨다. (Wang et al., 2023)은 수학 문제에 대한 Large Language Models'(LLMs) 솔루션에서 각 단계에 보상 점수를 평가하고 할당하는 새로운 프로세스 중심의 수학 검증기인 MATH-SHEPHERD를 소개한다.

#### 3.2.2 Geometry reasoninging

GeoS(Seo et al., 2015)는 기하 단어 문제를 논리적 표현으로 매핑하기 위한 시스템을 제공하여, 문제 해결의 프로세스를 용이하게 한다. Chen 등(2021)은 GeoQA 벤치마크(Chen 등, 2021)에서 기하학적 문제들에 의해 제기된 도전들을 해결하기 위한 접근법으로서 NGS(Neural Geometric Solver)를 소개한다. NGS는 전체론적 접근법을 채택하여 멀티모달 정보를 능숙하게 구문 분석하고 해석 가능한 프로그램을 생성한다. Geoformer(Chen et al., 2022)는 시퀀스 생성을 통한 계산 및 증명 문제를 동시에 다룬다. 이 접근법은 통합된 공식을 사용함으로써 두 과제 모두에서 향상된 추론 능력을 보여준다. 추가적으로, 저자들은 문제 해결 내에서 수학적 표현을 예측하는 MEP(Mathematical Expression Pretraining) 방법을 제안한다(Chen et al., 2022). 이 기법은 수학적 표현을 효과적으로 다룰 수 있는 모델의 능력을 향상시킨다. Inter-GPS(Lu et al., 2021)는 기하학 해결 과제를 문제-목표-탐색 과정으로 공식화한다. 조건부 규칙으로 정리 지식을 통합함으로써 Inter-GPS는 단계별 기호 추론을 가능하게 하여 효과적인 기하 문제 해결을 가능하게 한다.

#### 3.2.3 자동 정리 증명

정리 증명은 하드웨어 및 소프트웨어 검증 모두에서 중추적이다(Khan 등, 2020; Li 등, 2005). 하드웨어 검증의 맥락에서, 그것은 집적 회로들의 설계에서 성공적인 적용을 발견했다(Khan 등, 2020; Li 등, 2005). 소프트웨어 검증의 영역에서 주목할 만한 성과는 검증된 C 컴파일러인 CertC의 개발이다(Berghofer and Strecker, 2004). 인텔과 같은 기업은 프로세서에 중요한 부동 소수점 버그가 없는지 확인하기 위해 공식 방법에 상당한 투자를 했다는 점을 언급할 가치가 있다. 이러한 버그의 결과에 대한 두드러진 예는 1994년 비용이 많이 드는 펜티엄 FDIV 버그로 인해 5억 달러의 손실이 발생했다(해리슨, 2010). 결과적으로, 정리 증명은 부동 소수점 펌웨어를 검증하는 데 중추적인 역할을 해왔다. 전통적으로 정리 증명은 특정 정리 증명 도구와 각각의 응용 영역에 능숙한 고도로 훈련된 인간 전문가에 의존해 왔다. 그러나 학습 가능한 자동화 정리 증명의 등장은 하드웨어와 소프트웨어 검증에 두 가지 중요한 방식으로 혁명을 일으킬 가능성을 가지고 있다. 첫째, 정리증명의 자동화 수준을 높여 인간의 전문성과 인력에 대한 의존도를 낮춘다. 둘째, 이러한 방법의 적응성을 높여 기계학습을 통해 활용성과 적용성을 넓힌다.

연구자들은 Isabelle(Paulson, 1994), Lean(de Moura et al., 2015), Coq(Barras et al., 1997), Metamath(Megill and Wheeler, 2019)를 포함하는 인터렉티브 정리 프로버(interactive theorem provers, ITP)에 기초하여 현대 수학적 검증 시스템을 생성한다. 최근 몇 년 동안, 다양한 접근법이 ITP와 기계 학습을 통합했다(Yang and Deng, 2019; Gauthier et al., 2021). 다양한 데이터세트들(PISA(Jiang et al., 2021), miniF2F(Zheng et al., 2021), LeanDojo(Yang et al., 2023), FIMO Liu et al.(2023) 및 TRIGO(Xiong et al., 2023) 상에서 검증됨), 이러한 접근법들은 언어 모델들(Polu and Sutskever, 2020; Han et al., 2021; Polu et al., 2023; jia, 2022; Lample et al., 2022; Mikula et al., 2023)에서의 진보를 레버리지하여, 언어 모델에 의해 제공된 액션들을 사용하여 올바른 단계들의 시퀀스를 식별하는 트리 탐색과 함께, 증명의 현재 상태에 기초하여 액션들을 추천한다. 이를 위해 MCTS(Monte Carlo Tree Search) (Silver et al., 2018; Wu et al., 2021; Laurent and Platzer, 2022) 또는 동적-트리 MCTS(Wang et al., 2023)와 같은 방법들이 채용된다. 이전 연구에서는 LMM(large language models)의 few-shot statement autoformalization 능력을 입증하였다(Wu et al., 2022). 이러한 발견들이 증명 자동 정형화에 대한 적용 가능성을 조사하기 위해, DSP는 Draft, Sketch, Proof(Jiang et al., 2022)를 사용하여 철저한 분석을 수행했다. 하위 목표 학습(Zhao et al., 2023)은 하위 목표 비공식 증명 및 시연 선택을 활용한다. LeanDojo(Yang et al., 2023)는 Lean(Moura and Ullrich, 2021)을 위한 오픈 소스 프로젝트로 툴킷, 데이터, 모델, 벤치마크가 포함되어 있다. Lyra(Zheng et al., 2023)는 LLM 환각을 완화하기 위한 Tool Correction 및 생성된 공식 증명 추측의 품질을 개선하기 위한 Conjecture Correction의 사용을 제안한다. Lyra의 지시에 따라, LEGO-Prover(Xin et al., 2023)는 정리 증명에 사용되는 LLM의 능력을 향상시키기 위한 스킬로서 검증된 lemmas를 포함하는 성장하는 스킬 라이브러리를 사용한다.

#### 3.2.4 Scientific Reasoning

과학적 추론은 가설이나 이론을 공식화, 평가, 정제하는 데 필요한 인지적 능력과 문제 해결 능력을 포괄한다. 고도로 발달된 숙련도의 경우 이러한 조사 활동을 통해 지식을 습득하고 진화하는 과정에 대한 비판적 성찰도 수반한다(Morris et al., 2012). 수학적 추론이 그 기초를 이루면서, 우리는 여기서 과학적 추론을 언급한다.

과학적 추론은 AI for Science(AI4Science)와 밀접한 관련이 있다(Zhang et al., 2023). 이 관련성은 물리학, 화학, 양자역학 등을 포함한 다양한 분야에 걸쳐 확장된다. 이러한 영역에 기반 모델을 통합하면 이해도가 향상될 뿐만 아니라 탐색과 혁신을 위한 새로운 길을 열 수 있다. 기초 모델이 전통적인 과학적 방법을 혁신하고 발견을 가속화하고 복잡한 문제를 해결할 수 있는 잠재력은 거대하여 현대 과학 풍경에서 필수 불가결한 도구가 된다. Subramanian et al.(2023)은 사전 훈련된 모델의 크기, 데이터 세트 규모, 모델의 혼합 및 훈련 분포 외부의 매개변수와 같은 다양한 요인이 기초 모델의 전이 학습 능력에 어떻게 영향을 미치는지 조사한다. 그들의 연구는 모델 파라미터의 수를 증가시키는 것이 성능을 향상시킬 수 있다는 것을 발견한다. 또한, "사전 훈련 및 미세 조정" 접근법은 특히 부분 미분 방정식(PDE)에 의해 지배되는 물리적 시스템에서 과학적 추론 작업에 매우 효과적이다. Horawalavithana 등(2022)은 OpenAI의 GPT-2 트랜스포머 디코더 아키텍처를 수정하여 화학을 위한 14억 7천만 파라미터 범용 모델을 구체적으로 개발한다. 이 대규모 모델은 도메인 내 과제뿐만 아니라 도메인 외 과제에서도 능숙함을 보여준다. 약 5,355만 개의 화학 중심의 과학 기사 및 초록을 포함하는 670GB의 텍스트 데이터의 상당한 코퍼스에 대해 훈련된다. IBM RXN for Chemistry(Team, 2022; Manica et al., 2023; Das et al., 2021)는 화학에서 화학 반응 및 절차 방법론을 예측하기 위한 기초 모델을 활용한다. 생물학과 관련된 기초 모델에 대한 보다 포괄적인 탐색은 섹션 3.9.3 및 섹션 3.9.4를 참조하십시오. 여기에서 생물학 기초 모델에 대해 더 자세히 설명하지 않는다. 현재 대부분의 과학적 추론 연구는 주로 수학, 물리학, 생물학, 의학 등의 분야에 집중되어 있다(Qiu et al., 2023). 대조적으로, 양자 영역에서의 기초 모델은 비교적 부족하다. 양자 시스템을 위한 확장 가능한 기반 모델 구축은 양자 역학의 본질적인 복잡성, 제한된 데이터 가용성, 표준화된 방법론의 부재, 양자 하드웨어 능력의 제약 등 몇 가지 문제에 직면해 있다. 이러한 장애물에도 불구하고 이 유망한 분야에 도전하는 것은 흥미롭고 잠재적으로 보람 있는 탐험 영역을 제시한다.

표준화는 과학적 추론 분야를 발전시키는 데 도움이 됩니다. 데이터셋이나 벤치마크를 제안하는 것은 표준화의 과정이다. 현재, 과학적 추론을 위한 데이터셋은 주로 수학, 물리학, 화학 등의 분야에 집중되어 있으며, 그 예로는 SciBench(Wang et al., 2023), ScienceWorld(Wang et al., 2022), ScienceQA(Lu et al., 2022) 등이 있다. SciBench(Wang et al., 2023)는 대학 수준의 과학 문제의 맥락에서 LLM의 과학적 추론 능력, 도메인 지식 및 고급 계산 능력을 평가하기 위해 설계된 전문 벤치마크이다. 이 포괄적인 벤치마크는 교육 교재에서 신중하게 조달된 695개 문제의 세심하게 선별된 모음을 포함한다. SciBench는 두 개의 데이터 세트로 구성된다. 첫 번째 데이터 세트는 수학, 화학 및 물리 교과서에서 제공되는 대학 수준의 과학적 문제의 광범위한 모음을 구성한다. 그것의 주요 목적은 다양한 과학적 주제 및 문제 범주를 다룰 수 있는 LLM의 능력을 평가하는 것이다. 반면에 SciBench의 두 번째 데이터 세트는 컴퓨터 과학과 수학 학부 시험에서 얻은 문제로 구성되어 닫힌 세트를 형성한다. 이 폐쇄 세트는 이러한 특정 분야 내에서 정밀한 문제 해결 과제를 해결하는 LLM의 숙련도를 측정하기 위해 의도적으로 제작된다. 사이언스월드(Wang et al., 2022)는 상호작용 텍스트 환경 내에서 에이전트의 과학적 추론 능력을 평가하기 위해 설계된다. 이 환경은 10개의 주제에 걸쳐 분포된 30개의 상위 과제 유형을 특징으로 하는 표준 초등학교 과학 교육과정을 시뮬레이션한다. 환경은 여러 상태를 지원하여 다양한 상호 작용 및 시나리오를 허용합니다. 세상을 추상화하고 광범위한 객체를 통합함으로써, 사이언스월드는 에이전트가 그 안에서 탐색하고 추론할 수 있도록 복잡한 상호 작용 텍스트 환경을 제공한다. 각각 최대 200가지 유형의 객체를 포함하는 10개의 상호 연결된 위치로 구성됩니다. 이 물건들은 다양한 범주와 가구, 책, 그림과 같은 일반적인 환경 항목에 걸쳐 있습니다. 환경은 에이전트가 상호 작용할 수 있는 풍부하고 다양한 환경을 제공합니다. 사이언스월드 내 설정된 행동은 과학의 영역과 관련된 행동과 공통된 행동을 포괄하는 25개의 상위 행동으로 구성된다. 사이언스월드의 각 단계는 약 200,000개의 가능한 액션-객체 쌍을 제시하지만 이러한 쌍의 일부만이 당면한 작업에 실제 영향을 미칠 것이다. ScienceQA(Lu et al., 2022a)는 초등 및 고등학교 과학 커리큘럼으로부터 소싱된 21,208개의 객관식 과학 질문들을 포함하는 멀티모달 데이터세트이다. 데이터 세트는 자연 과학, 언어 과학 및 사회 과학 주제를 포괄하여 더 풍부한 도메인 다양성을 제공한다.

이러한 자원은 복잡한 과학적 추론 영역에서 기초 모델의 능력을 테스트하기 위한 귀중한 플랫폼을 제공하여 추론 능력을 평가하는 보다 구조화된 접근 방식을 허용한다. 이러한 전통적인 과학에 대한 초점은 더 넓은 범위의 학문을 포함하도록 데이터 세트의 범위를 확장할 필요성을 강조하여 잠재적으로 과학적 추론에서 더 다양하고 포괄적인 발전으로 이어진다.

### Logical Reasoning

명제 논리와 서술어 논리를 포괄하는 논리적 추론(표 4)은 전제와 그 관계를 사용하여 전제에 내포된 결론을 도출하는 엄격한 사고 형태이다(누네스, 2012). 컴퓨터 과학과 수학에서 다양한 영역의 근본적 토대가 될 수 있다.

이전의 연구들은 신경-기호학적 방법들에서 신경망과 기호추론의 조합을 탐색하였다(Mao et al., 2019; Pryor et al., 2023; Tian et al., 2022; Cai et al., 2021; Sun et al., 2021; Manhaeve et al., 2021; Gupta et al., 2019). 그러나, 이러한 방법들은 종종 최적화 어려움으로 인해 일반화성 또는 취성이 결여된 특수화된 모듈 설계와 같은 한계에 직면한다. 대조적으로, LLM은 논리적 추론에 대해 더 강한 일반화 능력을 나타낸다. Logic-LM 프레임워크(Pan et al., 2023a)는 논리적 문제 해결을 강화하기 위해 LLMs 및 심볼릭 추론을 활용한다(Luo et al., 2023d). 그것은 자연어 문제를 기호 공식으로 변환하기 위해 LLM을 활용하는 것으로 시작하여 추론을 위해 결정론적 기호 해결기에 의해 처리된다. 또한, 자체 정제 단계를 도입하여 기호 해결자의 오류 메시지를 사용하여 기호 형식화를 수정한다. Bubeck 등(2023)은 GPT-4 모델이 수학적 및 일반적인 추론 문제를 다룰 때 논리적 추론 능력을 발현할 수 있음을 입증한다. 종종 창발적 속성들로서 지칭되는 이러한 고차 능력들은 큰 데이터세트들로 모델을 스케일링한 결과(Wei et al., 2022a). Zhao et al.(2023a)은 명시적 계획을 추론 절차에 통합하여 다단계 논리적 추론을 위한 언어 모델을 사용한다. 이러한 통합은 미래의 효과를 고려하여 각 단계에서 더 많은 정보에 입각한 추론 결정을 가능하게 한다. 또한 Creswell et al.(2023)은 사전 학습된 LLM들을 일반적인 처리 모듈로 사용하는 Selection-Inference (SI) 프레임워크를 제안한다. SI 프레임워크는 최종 답변으로 이어지는 해석 가능한 인과 추론 단계들의 시퀀스를 생성하기 위해 선택 단계들과 추론 단계들 사이를 번갈아 간다.

논리적 추론 작업을 위해 LLM을 활용하는 최근 작업은 그림 7과 같이 크게 두 가지 접근법으로 분류할 수 있다. 첫 번째 접근법은 맥락 내 학습으로, LLM에서 단계별 추론을 이끌어내기 위해 특정 프롬프트를 사용한다. 이 카테고리에서 주목할만한 방법들은 연쇄-생각 프롬프팅(Wei et al., 2022b; Wang et al., 2023) 및 최하위-대-최하위 프롬프팅 접근법(Zhou et al., 2022a)을 포함한다. 이러한 접근 방식은 자연어에 대한 직접적인 추론을 가능하게 하여 유연성을 제공한다. 그러나 자연어의 복잡성과 모호성은 불성실한 추론과 환각과 같은 도전을 초래할 수 있다. 두 번째 접근법은 미세 조정이며, 여기서 LLM의 추론 능력은 미세 조정 또는 훈련 특수 모듈을 통해 최적화된다(Clark et al., 2020; Tafjord et al., 2022; Yang et al., 2022b).

#### 3.3.1 제안 논리

명제 논리는 참이든 거짓이든 어떤 모호성 없이 진리값을 부여할 수 있는 선언적 문장을 다룬다. 명제 논리는 원자적 명제와 복합적 명제의 두 가지 유형이 있다. 원자 명제

\begin{table}
\begin{tabular}{p{113.8pt}|p{113.8pt}|p{113.8pt}} \hline \hline  & Propositional Logic & Predicate Logic \\ \hline Basic elements & Atomic propositions, Compound propositions & Atomic propositions, Compound propositions, Variables, Quantifiers, Predicates \\ \hline Complexity & Lower & Higher \\ \hline Expressive Power & Limited & More powerful \\ \hline Applications & Circuit design, Boolean algebra & Natural language processing, Knowledge representation, Database queries \\ \hline Examples & \(p\lor q\); \(p\wedge q\); \(\neg p\); \(p\to q\) & \(\forall x,P(x)\); \(\exists x,P(x)\) \\ \hline \hline \end{tabular}
\end{table}
표 4: 명제 논리와 서술어 논리의 기본 요소, 복잡성, 표현력, 응용에 대한 비교.

그림 7: 큰 언어 모델의 논리적 추론 능력을 향상시키기 위한 두 가지 주요 접근법. (a) 문맥 내 학습은 논리적 추론을 이끌어내기 위한 시연으로서 특정 프롬프트를 활용한다. (b) 미세 조정은 특수화된 모델 파라미터를 업데이트하기 위해 추가 트레이닝 샘플을 사용한다.

는 더 이상 분해할 수 없는 기본 진술인 반면, 복합 명제는 연결(AND), 분리(OR), 부정(NOT)과 같은 논리적 연결어를 사용하여 원자 명제를 결합하여 형성된다.

명제 논리 해결의 맥락에서 Tomasic et al.(2021)은 GPT-2 및 GPT-3 모델에 대해 미세 조정을 수행하여 명제 논리 해결의 시뮬레이션 목적으로 조정했다. 이 전문 교육은 연결, 분리 및 부정 커넥터를 포괄하는 비재귀적 규칙에 초점을 맞춘다. 이러한 언어 모델을 활용하여 명제 논리 문제에서 논리적 추론 능력을 향상시키는 것을 목표로 했다.

명제 논리 해결을 위한 언어 모델의 사용은 이 모델들이 자연어로 복잡한 패턴과 의미 관계를 포착하는 능력을 입증했기 때문에 흥미롭다. 명제 논리로 이해하고 추론하도록 훈련함으로써 연구자들은 논리적 추론 능력을 향상하고자 하였다.

#### 3.3.2 Predicate Logic

1차 논리라고도 하는 술어 논리는 명제 논리의 확장으로 볼 수 있어 보다 미묘한 표현을 가능하게 한다. 술어 논리에서는 술어를 사용하여 속성을 표현하고 문장의 주제에 대한 추가 정보를 제공한다. 지정된 도메인을 가진 변수를 포함하며 해당 객체 간의 객체, 관계 및 함수를 포함합니다.

유도 논리 프로그래밍(Inductive Logic Programming, ILP)은 기계 학습의 더 넓은 분야 내에서 특화된 도메인이다(Cropper et al., 2022). ILP는 가설과 데이터를 표현하기 위해 1차 논리를 활용하며, 논리적 언어를 지식 표현과 추론에서 중요한 구성 요소로 만든다(De Raedt and Kersting, 2010).

술어 논리적 표현 및 추론을 통합함으로써, LLM은 보다 해석가능하고 설명가능한 모델에 대한 가능성을 제공한다(Liu et al., 2022c). 데이터로부터 논리적 패턴과 규칙을 발견하여 인간이 이해할 수 있는 지식의 추출을 용이하게 한다.

### Causal Reasoning

인과 추론은 사건, 행동 또는 변수들 간의 인과 관계를 이해하고 설명하는 과정을 의미한다(Waldmann and Hagmayer, 2013; Liu et al., 2023l). 인과 추론 태스크는 인과 발견, 효과 추론, 귀속, 판단 및 기타 태스크로 분류될 수 있다(Kiciman et al., 2023). 인과적 발견은 변수들 간의 방향성 인과 관계를 밝히는 과정이다. 효과 추론은 공지된 또는 가정된 인과 관계의 크기 및 패턴의 특성화를 포함한다(LYU 등, 2022; Wang 등, 2021; Jin 등, 2023b). 반면 귀속은 특정 변화의 원인이나 원인을 규명하는 것을 수반한다. 판단 과업은 결과에 대한 보상 또는 비난의 배정을 포괄함으로써 귀속 과업을 확장한다. 또한 이러한 작업은 정책 최적화, 의사 결정, 설명, 과학적 발견 등과 같은 다양한 영역을 포함한다.

인과 네트워크 또는 인과 다이어그램으로도 알려진 인과 그래프는 변수 또는 이벤트 사이의 인과 관계를 그래픽으로 표현한 것이다(Balashankar and Subramanian, 2021; Scholkopf et al., 2021). 원인과 결과 관계를 묘사하고 시스템이나 현상의 인과 구조를 이해하는 데 사용되는 시각적 도구이다. 인과 그래프에서 변수나 사건은 노드로 표현되고, 그들 사이의 인과 관계는 방향 에지나 화살표로 묘사된다. 그림 8에서 우리는 위에서 언급한 여러 추론 과제를 설명하기 위해 인과 그래프를 사용한다.

#### Causal Discovery

인과 발견(Peters et al., 2017)은 관측된 데이터를 생성하는 것을 담당하는 기본 프로세스를 나타내는 인과 그래프(Long et al., 2022)를 식별하는 작업을 포함한다. LLM은 효과가 다를 수 있고 프롬프트의 신중한 크래프팅에 의해 영향을 받지만 쌍별 인과 관계를 식별하는 데 있어 경쟁 성능을 입증했다. Long et al.(2022)은 의학적 맥락에서 인과관계를 이해하는 데 있어 GPT-3의 한계를 조사한다. 신경병증성 통증 진단(Tu et al., 2019)의 틀 내에서, Tu et al.(2023)은 ChatGPT가 잘못된 부정적인 실수를 하는 경향이 있음을 발견한다. 인과적 발견에서 LLM의 성능은 아직 안정적이거나 일관적이지 않으며 잠재적으로 내부 모델 업데이트로 인해 동일한 질문에 대해 다른 답변을 제공할 수 있다. Long 등(2023)은 LLM의 지식을 포함한 전문적인 지식이 부정확할 수 있음을 제안한다. 그들은 인과적 발견 알고리즘의 출력의 불확실성을 줄이기 위해 LLM과 같은 불완전한 전문가를 활용하는 것을 제안한다. 객관적 데이터의 통계적 분석에 LLM의 전문성을 접목함으로써 인과 구조 학습의 정확성을 향상시키는 것을 목표로 한다. LLM 기반 인과적 발견에 대한 현재의 연구를 발전시켜, Ban et al.(2023)은 지식 기반 LLM 인과 분석을 데이터 기반 접근법과 학습 인과 구조에 통합한다. 그들은 기존의 인과 메커니즘에 관한 LLM의 전문성을 객관적인 데이터의 통계적 분석과 효과적으로 결합한다. 그들은 특정 변수에서 인과 그래프를 도출하는 것을 목표로 하는 특수화된 프롬프트 세트를 고안한다. 이러한 프롬프트를 사용하여 LLM 정보 인과 관계가 추론에 미치는 영향을 평가한다.

도 8: 서로 다른 캐주얼 추론 태스크를 반영하기 위한 인과 그래프의 예시. (a) 인과적 발견은 주어진 시스템에서 변수들 간의 근본적인 인과 관계를 식별한다. (b) 효과 추론은 알려진 인과 관계에 기초하여 시스템에 대한 특정 개입의 결과(예를 들어, 가중치)를 추정한다. (c) 귀인은 특정 원인이 주어진 효과에 대해 책임이 있는 정도를 결정한다. (d) 판단은 인과 관계의 인지된 결과 및 함축에 기초하여 결정을 한다.

자료로부터의 인과 구조. 텍스트 전용 LLM에 비해, 코드 프롬프트를 갖는 Code-LLM(Liu 등, 2023l)은 인과 추론에서 더 우수하다.

- 인과관계 및 실제 인과관계_

유형 인과성은 변수들 간의 인과 관계의 추론에 관한 것으로 인과 발견과 인과 효과 추정에서 분명하게 나타난다. 이와는 대조적으로, 실제 인과관계(Halpern, 2016)는 변수 및 그 상호관계에서 개별 사건으로 초점을 전환함으로써 인과적 발견에서 분기되며, 그 구체적인 원인을 밝혀내는 것을 목표로 한다.

CausLM(Feder et al., 2021)은 BERT(Kenton and Toutanova, 2019)와 같은 언어 모델이 보조적 적대적 사전 훈련 작업의 의도적인 선택을 통해 특정 관심 개념의 반사실적 표현을 얻을 수 있음을 입증했다. 이러한 반사실적 표현은 모델의 성과에 대한 개념의 실제 인과 효과의 예측을 가능하게 한다. 한편, Zhang 등(2023a)은 현재의 LLM들이 결합된 도메인 전문가들과 유사한, 기존의 인과적 지식을 레버리지함으로써 인과적 질문들을 해결할 수 있다고 믿는다. 그러나 이러한 모델은 여전히 새로운 지식을 발견하거나 높은 수준의 정밀도로 고위험 의사 결정 작업을 수행할 때 만족스러운 답변을 제공하기 위해 어려움을 겪고 있다. 현재의 LLM들은 그들의 이용가능한 텍스트 사실들에 대한 접지를 확립하기 위해 실제 물리적 데이터 측정들을 통합하는 능력이 부족하다(Zecevic et al., 2023; Willig et al., 2023). 그 결과 고전적(인과적) 구조 발견 방법과 유사하게 실제 귀납적 추론에 관여할 수 없게 된다. 이러한 한계는 사실로부터 배우는 과정에 대한 중요한 사회적 논의 지점을 제기한다. 후자는 일반화와 정당화가 모두 결여되어 있기 때문에 이상적인 목표는 단순한 '알기'가 아니라 '이해'여야 한다는 것은 논쟁의 여지가 있다.

요약하면, LLM은 인과적 발견에서 가능성을 보여주지만, 그들의 성능은 여전히 일관성이 없고 신속한 엔지니어링에 민감하다. 연구자들은 이러한 한계를 해결하기 위한 방안을 모색하고 있다.

#### Counterfactual Reasoning

반사실성은 현실 세계에서는 거짓이지만 가상의 시나리오에서는 참으로 가정되는 전제를 포함한다. 예를 들어, "고양이가 채식주의자라면", "고양이가 양배추를 좋아할 것이다"(Li et al., 2023g)와 같은 가상의 결과가 뒤따랐다. 반사실적 추론은 실제 사건 또는 상황 내의 요소 또는 조건을 변경함으로써 달성되는 가상 시나리오의 고려를 포함한다(Kahneman and Miller, 1986; Byrne, 2007). 그것은 인과 관계를 이해하는 데 근본적인 역할을 하여 다양한 상황에서 발생할 수 있는 잠재적 결과를 탐구할 수 있게 한다. 언어 모델을 반사실적 테스트에 적용함으로써 진술의 사실적 정확성과 가상적 특성을 조작하여 예측에서 이 정보를 분별하고 효과적으로 활용할 수 있는 모델의 능력을 평가할 수 있다. 이 테스트 접근법을 통해 실제 시나리오와 가상 시나리오를 구별하는 모델의 적성과 정확하고 맥락적으로 적절한 응답을 위해 이 이해도를 활용하는 능력에 대한 통찰력을 얻을 수 있다.

언어 모델의 컨텍스트에서 각 추론 작업은 매핑 함수 \(f_{w}:X\to Y\)로 나타낼 수 있으며, 이는 **세계 모델**\(w\in W\)을 사용하여 **입력**\(x\in X\)을 **출력**\(y\in Y\)으로 매핑합니다. 세계 모델은 함수 평가가 발생 하는 조건을 캡슐화 하 고 **기본 세계** 를 \(w^{\text{default}}\)로 표시 합니다. 가설 \(h\)은 \(f^{w}\)을 추정하는 반면, 반사실적 세계는 \(w^{\text{cf}\)으로 표현된다. 언어 모델의 주어진 인스턴스 \(x\)에 대한 \(f_{w}\)의 구현은 다음과 같이 표현될 수 있다:

\[h(f,w,x)=\operatorname*{argmax}_{y^{\prime}}P_{\text{LM}}(y^{\prime}|\text{ prompt}_{f}(f,x),\text{prompt}_{w}(w)), \tag{1}\]

여기서 반사실적 추론은 \(h(f,w^{\text{cf}},x)\), 사실적 추론은 \(h(f,w^{\text{default}},x)\)로 표시된다.

Li 등(2023)은 가상 시나리오와 실제 시나리오를 구별하는 데 있어 사전 훈련된 언어 모델(PLM)의 능력을 조사하기 위해 반사실적 조건식을 활용한다. 그들은 이 기능이 기존의 실제 지식 및 연관 단서의 모델 활용과 어떻게 인터페이스되는지 탐구한다. 그들의 연구 결과는 반사실적 상황에 직면했을 때 PLM은 확립된 세계 지식과 모순되는 완성물을 생성하는 경향이 있음을 보여준다. 예를 들어, GPT-3은 "If/had"와 "Because"을 구별하는 것과 같은 언어적 단서가 근처의 어휘 단서와 다음 단어 사이의 연결에 어떻게 영향을 미치는지에 대한 미묘한 이해를 발전시켰을 수 있다. 이는 PLM이 반사실적 프롬프트에 응답할 때 광범위한 사실 정보보다 즉각적인 맥락적 단서의 영향을 우선시할 수 있음을 시사한다. Wu 등(2023)은 "반사실적" 태스크 변동을 통합하는 평가 프레임워크를 소개한다. 그들은 11개의 반사실적 태스크들의 세트를 제시하고, 이러한 태스크들에 대한 GPT-4(OpenAI, 2023), Claude(Anthropic, 2023), PaLM-2(Anil et al., 2023)의 능력 및 성능을 평가하는데, 이는 디폴트 및 반사실적 조건 모두를 고려한다. 연구 결과는 현재 언어 모델이 어느 정도 추상적인 과제 해결 능력을 가지고 있지만, 그들의 수행은 종종 과제에 걸쳐 쉽게 전달되지 않는 좁은 맥락 특정 절차에 의존한다는 것을 나타낸다. 특히, 모델은 기본 설정에 비해 반사실적 작업 변형에 직면했을 때 성능이 지속적으로 크게 감소한다. 이러한 결과는 언어 모델 수행의 다양한 측면과 반사실적 추론이 제기하는 문제를 고려하여 언어 모델 수행에 대한 신중한 해석의 필요성을 강조한다.

### Visual Reasoning

시각적 추론은 시각적 정보로부터 이해, 분석, 결론을 도출하는 인지적 과정을 의미한다. 이미지, 장면 또는 다른 시각적 표현과 같은 시각적 자극에 대해 지각, 해석 및 추론하는 능력을 포함한다(Ding et al., 2023).

범용 시각 이해 평가(General-purpose Visual Understanding Evaluation, G-VUE)는 포괄적인 평가 프레임워크이다(Huang et al., 2023). 그것은 시각 인지 능력의 전체 범위를 평가하는 것을 목표로 한다. 프레임워크는 지각, 근거, 이성, 행위의 네 가지 기능적 영역으로 나뉜다. 그림 9와 같이 프레임워크는 이러한 영역을 나타내기 위해 3D 재구성, 시각적 추론, 조작 및 상호 작용을 포함하여 12개 작업의 신중하게 선택된 모음을 포함한다. G-VUE는 AI 시스템의 시각적 이해 능력을 평가하기 위한 표준화되고 포괄적인 플랫폼 역할을 한다. 다양한 기능 영역을 우선시하고 과제를 신중하게 선택함으로써 프레임워크는 광범위한 시각적 인지 능력의 포함을 보장한다. 이를 통해 AI 시스템의 장단점을 보다 정확하게 평가할 수 있다. VLGrammar(Hong et al., 2021)는 언어와 이미지 문법을 동시에 유도하기 위해 복합 확률적 문맥 자유 문법(PCFGs)을 채용한 모델이다. 이 두 모듈의 공동 학습을 용이하게 하는 새로운 대조적 학습 프레임워크도 제안된다. AeNER(Ding et al., 2021)은 동적 시각 시공간 추론 문제에 대한 일반적인 신경망 기반 접근법을 소개한다. 이 접근법은 모듈식 기호 컴포넌트, 독립 역학 모델 또는 의미 파서와 같은 맞춤형 방법과 다르다. AeNER은 동적 시각 시공간 추론 문제를 해결하기 위한 보다 다양하고 적응 가능한 솔루션을 제공한다. LISA(Lai et al., 2023)는 암시적 질의 텍스트로부터 대응하는 객체(들)의 마스크(들)를 획득하는 것을 목표로 하는 추론 분할이라는 새로운 비전 태스크를 제안한다. 관심 객체를 정확하게 찾기 위해서는 이미지 이해와 함께 LLM의 세계 지식이 필요하다.

#### 3.5.1 3D Reasoning

구체적으로, 3차원 추론은 3차원 객체 또는 공간 배치에 대한 이해, 분석 및 추론의 인지 과정을 의미한다.

3D-LLM(Hong et al., 2023)은 3D 포인트 클라우드들을 그들의 연관된 특징들과 함께 프로세싱하도록 설계된다. 조밀한 캡션, 3D 질문 응답, 3D 접지, 3D 보조 대화, 내비게이션, 작업 분해 및 그 너머를 포함하는 다양한 스펙트럼의 3D 관련 작업에 걸쳐 놀라운 숙련도를 보여준다. PointLLM(Xu et al., 2023)은 3D 데이터와 상호작용하고 해석하기 위해 기하학적, 시각적, 및 텍스트 정보를 결합하여 3D 포인트 클라우드를 이해하기 위해 LLM을 확장하는 접근법이다. 2D 베이스라인에 비해 객체 분류 및 자막 작업에서 우수한 성능을 보인다. 한편, 3D-VisTa(Ziyu et al., 2023)는 3D vision과 text를 정렬하기 위해 특별히 개발된 pre-trained Transformer 모델이다. 3D 시각 접지, 밀집 캡션, 상황 추론(Ma et al., 2023)과 같은 3D 비전 언어(3D-VL) 작업에 매우 가치가 있음을 증명한다.

도 9: 일반적인 비전 시스템 G-VUE(Huang et al., 2023)의 4개의 기능적 도메인 및 이들의 대응하는 시각적 태스크.

근거 모델을 사용한 3D 추론에 대한 연구는 매혹적인 시점에 있다. 3D-LLM, PointLLM, 3D-VisTa와 같은 모델은 이미 다양한 3D 작업, 기하학적, 시각적, 텍스트 데이터의 혼합에서 효과를 보여주었다. 이러한 발전에도 불구하고 이 분야는 여전히 급성장하고 있으며 탐사와 개선의 여지가 많다. 미래의 방향은 보다 복잡한 3D 장면 해석을 위한 모델 기능 정제, 시각 장애인 또는 시각 장애인을 위한 내비게이션 에이전트(Qiu 등, 2022)와 같은 실제 시나리오에서의 애플리케이션 확장, 및 현재 방법론의 격차를 해소하는 것을 포함할 수 있다.

### Audio Reasoning

음성 추론은 음성이 주요 출처인 청각 데이터를 이해, 조사 및 결론 도출의 인지 메커니즘과 관련이 있다. 자체 감독 방식으로 학습된 스피치 표현들은 이러한 방향으로 유망한 해결책을 제공하며, 여기서 단일 기초 모델이 훈련되고 광범위한 스펙트럼의 다운스트림 태스크들에 적용될 수 있다(Mohamed et al., 2022).

#### 3.6.1 Speech

음성 처리 분야는 크게 판별 과제와 생성 과제의 두 가지 별개의 범주로 분류할 수 있다. 차별적 과제는 연속적 발화를 기반으로 이산적인 결정을 내리는 과정을 수반하는 반면, 생성적 과제는 다양한 입력 소스로부터 연속적 발화의 생성을 수반한다. 음성 처리 범용 성능 벤치마크(SUPERB)(Yang et al., 2021)는 기초 모델의 판별 능력을 평가하기 위해 널리 채택된 프레임워크이다. 그림 10에서 보듯이, 그것은 내용, 화자, 의미론, 언어학의 네 가지 요소를 다루는 10개의 과제를 포괄한다.

향상된 음성 처리 범용 PERformance Benchmark(SUPERB-SG)(Tsai 등, 2022)는 생성성을 평가하기 위한 프레임워크를 추가로 도입한다.

<그림 10> SUPERB의 4개 평가 영역(Yang et al., 2021)은 기초 모형의 판별 능력과 해당 과제에 초점을 맞추고 있다. PR: 전화 인식, ASR: 자동 음성 인식, KS: 키워드 스포팅, QbE-STD: 예시 발화 용어 검출에 의한 쿼리, SID: 화자 식별, ASV: 자동 화자 검증, SD: 화자 이원화, IC: 의도 분류, SF: 슬롯 채움, ER: 감정 인식.

기초 모델의 성능은 음성 번역(ST), 도메인 외 자동 음성 인식(OOD-ASR), 음성 변환(VC), 음성 분리(SS), 음성 향상(SE)의 5가지 태스크로 구성된다.

자체 감독 음성 표현을 학습하기 위한 기초 모델은 크게 세 가지 유형으로 분류할 수 있습니다. 1) 제한되거나 손상된 뷰에서 입력 음성 시퀀스를 레버리징하는 **생성 모델** (예: VQ-VAE)(Van Den Oord et al., 2017), 자기 회귀 예측 코딩(APC)(Chung et al., 2019) 및 마스킹 음향 모델(MAM)(Liu et al., 2020); 2) 대상 양성 샘플과 산만한 음성 샘플을 구별하는 **대조 모델** (예: 대조 예측 코딩)(Oord et al., 2018), Wav2Vec 2.0 (Baevski et al., 2020) 및 Speech SIMCLR (Jiang et al., 2020); 및 3) 교사-학생 학습과 유사한 설정을 따르는 **예측 모델** (예: Hidden Unit BERT (HuBERT)(Hsu et al., 2021), WavLM (Chen et al., 2022) 및 Data2Vec (Baevski et al., 2022). Transformer-Encoder(Dong et al., 2018) 아키텍처와 Conformer-Encoder(Gulati et al., 2020) 아키텍처는 음성 기초 모델에서 널리 채택되고 있다.

### Multimodal Reasoning

멀티모달 추론은 이해를 높이고 복잡한 추론 작업을 수행하기 위해 텍스트, 이미지, 비디오 및 기타 감각 입력과 같은 정보의 여러 모달리티에 걸쳐 통합하고 추론하는 인지 프로세스를 의미한다(Yin et al., 2023; Zong et al., 2023)SS.

각주 §: [https://github.com/atfortes/Awesome-Multimodal-Reasoning](https://github.com/atfortes/Awesome-Multimodal-Reasoning)

인공지능(Artificial General Intelligence, AGI)을 개발하기 위해 멀티모달 추론은 여러 가지 이유로 유니모달 접근법보다 유망한 발전을 나타낸다. 첫째, 멀티모달 추론은 인간이 세상을 인식하는 방식과 더 밀접하게 일치한다. 인간은 여러 감각으로부터 자연스럽게 입력을 받아 서로 보완하고 협력하는 경우가 많다. 결과적으로 멀티모달 정보를 활용하면 멀티모달 기반 모델의 지능을 향상시킬 수 있을 것으로 기대된다. 둘째, 멀티모달 추론은 보다 사용자 친화적인 인터페이스를 제공한다. 멀티모달 입력에 대한 지원을 통합함으로써, 사용자는 보다 유연하고 다양하며 잠재적으로 보다 직관적인 방식으로 지능형 어시스턴트와 상호작용하고 통신할 수 있어, 전체 사용자 경험을 향상시킨다. 셋째, 멀티모달 추론은 보다 포괄적인 문제해결 능력을 촉진한다. 유니모달 언어 모델은 일반적으로 자연어 처리(NLP) 작업에서 탁월하지만 멀티모달 기반 모델은 광범위한 범위의 작업을 지원할 수 있는 잠재력을 가지고 있어 작업 해결자로서 더 다재다능하고 효과적이다. 멀티모달 기반 모델의 주요 기술 및 응용 분야는 멀티모달 명령어 기반 미세 조정 모델에 중점을 둔 멀티모달 명령어 튜닝(M-IT), 멀티모달 추론 기능을 강화하기 위해 상황 정보를 활용하는 멀티모달 상황 내 학습(M-ICL), 시각적 추론 기능을 강화하기 위해 LLM을 활용하는 LLM 지원 시각적 추론(LAVR) 등 다양하다. <그림 11>은 여러 개의 멀티모달 추론 과제와 이면의 핵심 기법을 보여주고 있는데, 이를 소개하면 다음과 같다.

#### 3.7.1 Alignment

_Image-Text Alignment_

CLIP(Radford et al., 2021)는 이미지와 텍스트 모두에 대한 응집적 표현의 생성을 가능하게 하는 학습 방법을 활용한다. CLIP는 시각 및 텍스트 정보를 정렬함으로써 교차 모달 이해를 촉진하고 광범위한 시각 및 언어 작업에 걸쳐 탁월한 숙련도를 보여준다. 유사한 맥락에서, BLIP-2(Li 등, 2023f)는 비전 인코더를 미세 조정하지 않고 효율적인 크로스-모달 정렬을 용이하게 하는 전략을 채택한다. 대신 고정된 이미지 인코더에서 시각적 특징을 추출하는 질의 변환기(Q-Former)를 소개한다. 이렇게 추출된 쿼리 임베딩은 정렬 프로세스에 대한 부드러운 시각적 프롬프트 역할을 합니다. 플라밍고(Alayrac et al., 2022)는 교차 주의와 토큰 융합에 의해 사전 훈련된 비전 및 언어 백본을 브리지한다.

그림 11: 멀티모달 추론 과제는 크게 이미지-텍스트 정렬, 텍스트-이미지 생성, 멀티모달-텍스트 생성, 멀티모달 이해로 분류할 수 있다. 현재 멀티모달 기반 모델은 주로 멀티모달 명령어 튜닝, 멀티모달 인 컨텍스트 학습 및 LLM 지원 시각적 추론을 포함하여 추론 작업에 접근하는 세 가지 핵심 기술을 포함한다. 튜토리얼(Li, 2023)의 피규어 스타일 크레딧입니다.

#### 3.7.2 Generation

_Text-to-image Generation_

안정 확산(Rombach et al., 2022)은 크로스-어텐션 계층들을 모델 아키텍처에 통합하고, 확산 모델들을 텍스트 및 바운딩 박스들과 같은 다양한 조건 입력들에 대한 강인하고 적응가능한 생성 모델들로 변환한다. 잠재 확산 모델(LDM)의 적용은 이미지 인페인팅에서 중요한 돌파구를 나타내는 동시에 무조건적인 콘텐츠 생성, 초해상도 이미지 생성 및 기타 작업에서 인상적인 결과를 제공한다. 특히, LDM은 높은 경쟁 성능을 유지하면서 픽셀 기반 확산 모델에 비해 계산 요구량을 크게 줄인다. DALL-E5는 자연어 기술을 기반으로 사실적인 이미지와 작품을 생성할 수 있는 능력을 갖춘 고급 AI 시스템입니다. 마찬가지로, Midjourney는 자연 언어 설명에 기초하여 이미지를 생성하는 것을 전문으로 하는 또 다른 AI 시스템이며, 이를 "prompts"라고 한다. AI의 힘을 활용하여 Midjourney6는 텍스트 프롬프트를 시각적 구성으로 번역하여 주어진 설명의 시각적 표현을 제공할 수 있다.

각주 5: [https://openai.com/dall-e-3](https://openai.com/dall-e-3)

각주 6: [https://www.midjourney.com](https://www.midjourney.com)

_Multimodal-to-text Generation_

플라밍고-80B(Alayrac et al., 2022)는 인-컨텍스트 소수의 샷 학습 능력을 갖춘 VLMs(Visual Language Models)의 패밀리를 포함한다. 이 모델은 시각적 질문 응답 및 캡션과 같은 개방형 태스크뿐만 아니라 객관식 시각적 질문 응답과 같은 폐쇄형 태스크를 포함하여 광범위한 태스크에 걸쳐 철저한 평가를 거친다. Frozen(Tsimpoukelli et al., 2021)은 시각적 정보를 접두사로 통합하면서 언어 모델(LM)의 언어 능력을 보존함으로써 멀티모달 컨텍스트 내에서 소수의 샷 학습 능력을 달성한다. 동결은 LM을 동결하고 이미지를 표현하기 위해 별도의 비전 인코더를 트레이닝함으로써 이를 달성한다. 겨울왕국 접근법에서 시각적 정보는 시각적 접두사 역할을 하는 임베딩의 시퀀스로 표현된다. MAGMA(Eichenberg et al., 2022)는 언어 모델을 동결 상태로 유지하면서 새로운 이미지 프리픽스 인코더를 통합함으로써 Frozen과 유사한 접근법을 따른다. 이것은 결합된 시각적 입력과 텍스트 입력으로부터 자동으로 텍스트를 생성할 수 있는 일련의 시각적 언어 모델을 훈련시킨다. Visual ChatGPT(Wu et al., 2023) 및 GPT-4(OpenAI, 2023)는 이미지 및 텍스트 프롬프트를 모두 지원하는 멀티모달 애플리케이션을 포괄하도록 챗봇 기능을 확장하는 발전을 나타낸다. Visual ChatGPT는 ChatGPT의 기초를 기반으로 하며 시각적 모델을 통합한다. 다양한 시각적 기초 모델의 이력을 관리하는 프롬프트 매니저가 통합되어 종합적인 멀티모달 대화 경험이 가능합니다. 반면 GPT-4는 이미지와 텍스트로 구성된 프롬프트를 수용하여 다른 접근 방식을 취하고 있다. 이러한 유연성은 사용자가 임의적으로 인터레이스된 텍스트 및 이미지 프롬프트에 응답하여 텍스트 출력을 생성함으로써 비전 및 언어 태스크를 특정할 수 있게 한다. 마이크로소프트는 또한 Kosmos-1(Huang et al., 2023) 및 Kosmos-2(Peng et al., 2023)를 포함하는 일련의 멀티모달 기초 모델을 제안했다. 이러한 모델은 멀티모달 기능의 개발에 추가로 기여하고 이미지와 텍스트 모두를 포함하는 풍부한 상호 작용을 촉진한다. 또한, 생체 의학 연구에 특히 초점을 맞춘 BiomedGPT(Zhang et al., 2023f)와 같은 특정 도메인에 GPT를 적응시키려는 노력이 계속되고 있다. 이러한 도메인별 적응은 전문 분야 내에서 언어 모델의 성능과 적용 가능성을 향상시키는 것을 목표로 한다.

#### Multimodal Understanding

Visual Instruction Tuning(Liu et al., 2023e)은 GPT-4를 활용하여 멀티모달 언어-이미지 명령어-추종 데이터를 생성하는 획기적인 접근법을 제시한다. 이 접근법은 대형 멀티모달 데이터 세트의 수동 주석에 대한 의존도를 줄일 수 있는 잠재력을 가지고 있다. 이 기초 위에서 확장하면, LLaVA(Large Language and Vision Assistant)(Liu 등, 2023e)는 광범위하게 훈련된, 대규모 멀티모달 모델을 나타낸다. 그것은 비전 인코더와 Vicuna(Chiang et al., 2023)를 매끄럽게 통합하여, 범용 애플리케이션에 대한 다용도 시각적 및 언어 이해를 용이하게 한다. LLaVA는 시각적 질문-답변, 이미지 캡션 및 지시-추종을 포괄하는 다중 모드 이해가 필요한 다양한 범위의 작업에 걸쳐 우수하다. 특히, 과학 도메인에서 멀티모달 추론 데이터 세트인 Science QA(Lu et al., 2022a)에서 인상적인 성능을 달성한다.

차트 상의 추론의 도메인에서, DePlot(Liu et al., 2023b)는 시각적 언어 추론을 위한 몇 샷 솔루션을 제시한다. 그것은 두 단계의 과정을 통해 도전을 다룬다: 첫째, 플롯을 텍스트로 번역한 다음 번역된 텍스트에 대한 추론을 수행한다. 저자는 또한 성능을 더욱 향상시키기 위해 DePlot과 LLM의 조합을 조사한다. MatCha(Math reasoning and Chart derendering pretraining)(Liu et al., 2023c)는 차트 도메인에서 시각적 언어 이해를 위한 포괄적인 프레임워크를 소개한다. 그것은 숫자 추출과 조직화를 포함한 레이아웃 이해, 수학적 추론의 두 가지 중요한 구성 요소의 중요성을 강조한다. 시각 언어 이해를 향상시키기 위해 저자는 주어진 플롯 또는 차트를 만드는 데 사용되는 기본 데이터 테이블 또는 코드를 생성하는 차트 디렌더링과 수학 추론의 두 가지 보완 사전 훈련 작업을 제안한다.

DetGPT(Pi et al., 2023)는 자신의 추론 기반 접근법을 통해 객체 검출에 혁명을 일으킨다. 객체가 명시적으로 언급되지 않은 경우에도 사용자 표현 욕구에 기초하여 관심 객체의 자동 로컬화를 가능하게 한다. 이 혁신적인 방법은 추론 기능을 통합하여 객체 탐지 프로세스를 향상시킵니다. Q-Bench(Wu et al., 2023c)는 멀티모달 기초 모델이 낮은 수준의 시각적 속성을 지각하고 이미지 품질 이해를 제공할 수 있음을 보여준다. LLaMA-VID(Li 등, 2023s)는 보다 효율적인 비디오 및 이미지 이해를 위해 LLM을 향상시킨다. 각 비디오 프레임을 두 개의 토큰으로 표현하여 필수 정보를 희생하지 않고 긴 비디오를 처리해야 하는 부담을 줄인다. 사용자가 멀티모달 이해의 포커스를 대화식으로 제어할 수 있도록 하기 위해, 프롬프트 하이라이터(Zhang et al., 2023l)는 특정 프롬프트 스팬을 강조하고 보다 타겟화된 출력을 생성하기 위해 자기회귀 생성을 효과적으로 안내한다.

텍스트, 이미지, 테이블 및 오디오와 같은 다양한 데이터 유형을 통합하는 것은 단일 모달 기반 모델과 비교하여 다중 모달 기반 모델에 대한 뚜렷한 과제를 제시한다. 주요 장애물은 이러한 다양한 데이터 형식을 효과적으로 병합하는 데 있으며, 이미지 콘텐츠와 해당 설명 간의 불일치 또는 누락된 데이터가 모델 성능에 부정적인 영향을 미칠 수 있는 데이터 세트의 불일치 및 불완전성과 같은 문제로 복잡한 작업이다. 또한, 멀티모달 기초 모델은 일반적으로 훈련을 위해 상당한 계산 자원을 요구한다. 따라서 이러한 모델에 대한 효율적인 훈련 방법을 탐색하는 것은 멀티모달 AI 시스템의 능력을 발전시키는 데 중요한 귀중한 연구 영역으로 부상한다. 이러한 멀티모달 기초 모델은 또한 재료 과학, 화학, 및 생물학과 같은 분야에 적용 가능한 보편적인 표현을 학습하는 데 중요한 역할을 한다(Team, 2022; Manica et al., 2023).

### Agent Reasoning

에이전트 추론은 자율 언어 에이전트가 추론 및 문제 해결을 지원하기 위해 물리적 환경 또는 시뮬레이션된 환경과 인식, 행동 및 상호 작용을 통합하는 인지 과정을 지칭하는 중요한 능력이다. 대규모 언어 모델의 맥락에서 자율 에이전트는 작업 분해, 코드 생성, 질문 응답, 대화 참여, 권장 사항 제공 등과 같은 광범위한 작업을 수행할 수 있는 능력을 가지고 있다. 종종 AI 에이전트로 알려진 자율 에이전트는 방대한 지식, 추론 기술 및 방대한 정보 자원을 활용하여 작업을 자율적으로 수행하기 위해 Large Language Models의 힘을 활용한다(Alibali et al., 2014).

여러 작품들이 계획 목적을 위한 언어의 사용을 조사하였다 (Jansen, 2020; Li et al., 2022; Sharma et al., 2021; Zeng et al., 2023; Huang et al., 2022; Ahn et al., 2022; Mu et al., 2023; Hu et al., 2023; Zhou et al., 2023a). 태스크 계획에서의 최근의 방법들은 사전-훈련된 자기회귀 기초 모델들을 활용하여 추상적이고 높은 레벨의 명령어들을 에이전트에 대한 실행가능하고 낮은 레벨의 스텝 시퀀스들로 분해하고, 제로-샷 접근법을 적용한다(Huang et al., 2022; Ahn et al., 2022). 구체적으로, Huang 등(2022)은 GPT-3(Brown 등, 2020) 및 Codex(Chen 등, 2021)에게 에이전트들에 대한 액션들을 생성하도록 프롬프트하고, 여기서 각 액션 단계들은 Sentence-RoBERTa(Liu 등, 2019; Reimers and Gurevych, 2019)를 통해 허용 액션으로 의미적으로 변환된다. 이에 반해 SayCan(Ahn et al., 2022)은 FLAN(Wei et al., 2021)에 의해 결정된 바와 같이 각 후보 액션의 확률을 액션의 가치 함수와 결합하여 액션과 언어를 근거한다. 후자는 어포던스를 측정하기 위한 대리자로서 작용한다(Shah et al., 2021). 그러나 두 접근 방법 모두 동적 환경에서 잠재적인 중간 실패를 고려하거나 하위 수준의 정책의 성능을 고려하지 않고 에이전트가 제안한 각 단계를 성공적으로 수행한다고 가정한다. SwiftSage(Lin 등, 2023)는 복잡한 상호 작용 추론 태스크 내에서 액션 플래닝에서 우수한 성능을 위해 맞춤화된, 인간 인지의 이중-프로세스 이론의 영향을 받는 프레임워크이다. 이 프레임워크는 SWIFT 모듈과 SAGE 모듈의 두 가지 주요 구성 요소를 중심으로 구성된다. SWIFT 모듈은 빠르고 직관적인 사고를 나타내며 오라클 에이전트의 행동 궤적을 기반으로 행동 계획을 담당한다. 이를 위해 특별히 미세 조정된 소형 인코더-디코더 언어 모델로 구현된다. 반면에 SAGE 모듈은 고의적인 사고 프로세스를 모방하고 GPT-4와 같은 LLM을 하위 목표 계획 및 접지에 활용한다. 이 모듈은 언어 모델의 힘을 활용하여 프레임워크 내에서 보다 정교한 추론 작업을 수행한다. 이와 관련하여 또 다른 주목할 만한 접근법은 Reasoning via Planning(RAP)(Hao et al., 2023a)이며, 이는 언어 모델의 이중 역할을 세계 모델 및 추론 에이전트로서 모두 활용한다. RAP는 추론의 확장적 영역 내에서 전략적 탐색을 용이하게 하기 위해 특히 몬테 카를로 트리 탐색에 기반한 잘 기반을 둔 계획 알고리즘을 통합한다. RAP의 유효성은 계획 생성, 수학적 추론(예를 들어, GSM8K(Cobbe et al., 2021)) 및 논리적 추론(예를 들어, PrOntoQA(Saparov and He, 2023))을 포함하는 다양한 태스크에 걸쳐 평가된다. 평가 결과는 RAP가 다양한 추론 과제를 해결하는 능력을 보여줌으로써 유능한 추론 에이전트로서의 다양성을 효과적으로 보여준다.

내향적 추론, 외향적 추론, 엠보디드 추론 및 멀티에이전트 추론은 상호 연결된 측면과 함께 에이전트 추론 시스템의 진보에서 중추적인 역할을 한다(Qin et al., 2023). 이러한 구성 요소는 자기 인식, 적응력, 효과적인 협업과 같은 상위 수준의 인지 능력 개발에 기여한다. 이러한 기능은 복잡하고 역동적인 환경에서 성공적으로 작동하고 인간과 원활하게 상호 작용하며 다른 에이전트와 협력 또는 경쟁 시나리오에 참여할 수 있는 지능형 시스템의 생성에 필수적이다. 우리는 기초 모델들을 로봇 공학에서 고전적 방법들과 결합하는 것이 인식(Chu et al., 2021), 매핑(Pan et al., 2020), 완성(Chu et al., 2023b), 파지(Li et al., 2021c), 계획(Mao et al., 2023b), 상호작용(Jiao et al., 2020) 및 제어와 같은 새로운 기회들을 생성할 수 있다고 믿는다. 안전은 구현된 지능형 시스템의 중요한 측면입니다. 이러한 맥락에서 PlanCP(Sun et al., 2023b)는 확산 동적 모델에 컨포멀 예측의 적용을 제안한다.

#### 3.8.1 Introspective Reasoning

그림 12(a)에 예시된 내성적 추론은 내부 지식과 추론에만 의존하여 도구 사용과 상호작용하지 않고 정적인 도구 사용 계획을 생성한다.

그림 12: 내현적 추론과 회고적 추론의 차이. 내성적 추론은 환경과의 상호 작용을 필요로 하지 않는 반면, 후향적 추론은 외부 환경의 관찰과 피드백을 활용하여 계획을 적응시킨다. 피규어 스타일은 일로부터의 크레딧이다(Qin 등, 2023).

environment (Leake, 2012). LLM을 이용한 내성 추론 분야의 여러 관련 작업에는 PAL(Program-Aided Language Models)(Gao et al., 2023b), ProgPrompt(Singh et al., 2023), 및 Code-as-Policies(Liang et al., 2022a)가 있다.

PAL(Gao et al., 2023b)은 자연어 문제의 이해 및 실행 가능한 프로그램 형태의 중간 추론 단계의 생성을 위해 LLM을 활용한다. 그럼에도 불구하고 솔루션 단계의 실제 실행은 Python 해석기와 같은 프로그래밍 런타임에 위임됩니다. 이 접근법은 PAL이 생성된 프로그램을 실행하기 위해 별개의 런타임 환경을 사용하면서 LLM의 언어 이해 능력을 활용할 수 있게 한다. ProgPrompt(Singh et al., 2023)는 프로그래밍과 유사한 구조화된 LLM 프롬프트를 제시하며, 다양한 로봇 기능 및 작업을 포괄하는 다양한 상황 설정에서 계획의 생성을 용이하게 하도록 제작된다. 이 구조는 실행을 위한 샘플 프로그램과 함께 주어진 환경에서 액세스 가능한 동작 및 개체에 대한 프로그램 스타일 설명으로 LLM을 프롬프트하는 것을 포함한다. Code-as-Policies(Liang et al., 2022a)는 언어 모델 생성 프로그램(LMP)을 위한 로봇 지향 프레임워크를 소개한다. 이러한 LMP는 임피던스 제어기와 같은 반응성 정책과 웨이포인트 지향 전략을 모두 묘사할 수 있다. Code-as-Policies의 다양성은 여러 실제 로봇 플랫폼에 걸쳐 입증되어 다양한 로봇 시나리오에서 적용 가능성을 보여준다.

내성적 추론은 효과적인 계획을 위해 외부 피드백과 환경과의 상호 작용이 중요한 동적 및 불확실한 환경에서 한계를 가질 수 있다. 변화하는 상황에 계획을 적응하거나 외부 정보 없이 예상치 못한 사건을 처리하는 데 어려움을 겪을 수 있다.

#### 3.8.2 외향적 추론

내성적 추론은 그 단순성에도 불구하고 중간 실행 결과를 바탕으로 계획을 조정하거나 수정할 수 있는 능력이 부족하다. 대조적으로, 소급 추론은 계획들을 점진적으로 생성함으로써 작동한다. 그림 12(b)와 같이 환경과 반복적으로 상호작용하고 이전 실행에서 얻은 피드백을 통합하여 이를 달성한다. 외향적 추론은 환경과의 상호 작용을 통해 수집된 외부 정보를 적극적으로 통합한다. 이는 소급 추론이 실시간 피드백 및 이전 액션의 관찰된 결과에 기초하여 자신의 계획을 적응시키고 정제할 수 있게 한다(Acay et al., 2007).

환경에 적극적으로 참여하고 피드백을 활용함으로써 후향적 추론은 계획을 생성하는 데 보다 유연하고 반응적인 접근법을 제공하며, 이는 경험에서 적응하고 학습할 수 있는 능력이 중요한 복잡하고 역동적인 상황에 특히 적합하다. LLM을 사용한 후향적 추론 분야의 여러 관련 작업에는 Self-Ask(Press et al., 2023), ReAct(Yao et al., 2023c), ToolFormer(Schick et al., 2023), LLM-Planner(Song et al., 2023a)가 있다. Self-Ask(Press et al., 2023)는 원래 질문을 다루기 전에 자신의 후속 쿼리를 사전에 생성하고 응답한다. 한편 ReAct(Yao et al., 2023c)는 대용량 언어 모델을 활용하여 추론 트레이스 및 태스크별 액션을 동시에 생성한다. 이 이중 접근법은 돌발 상황을 관리할 뿐만 아니라 실행 계획의 개발, 모니터링 및 수정을 돕는 추론 추적과 함께 이러한 요소 간의 상호 작용을 향상시킨다. 반대로, 액션은 지식 기반 또는 환경과 같은 외부 엔티티로부터 보충 데이터에 대한 모델의 참여 및 획득을 촉진한다. ToolFormer(Schick et al., 2023)는 활용할 적절한 API, 그들의 호출의 타이밍, 제공할 특정 인수, 및 획득된 결과를 후속 토큰 예측에 효과적으로 통합하는 방법을 지능적으로 결정하도록 설계된다. LLM-Planner(Song et al., 2023)는 구체화된 에이전트의 맥락에서 효율적인 소수의 샷 계획을 위해 대형 언어 모델의 능력을 활용한다.

전술한 연구 외에도, Statler(Yoneda 등, 2023)는 LLM에 세계 상태의 지속적이고 메모리와 유사한 표현을 구비하는 프레임워크를 제공한다. 그것은 세계 모델 독자와 세계 모델 작가의 두 가지 일반적인 LLM을 활용하며, 둘 다 세계 상태와 상호 작용하고 업데이트한다. 프레임워크에 메모리와 같은 요소를 추가하면 LLM의 추론 능력이 크게 향상되어 컨텍스트 길이 제한에 의해 일반적으로 부과되는 제약에서 벗어나 장기간에 걸쳐 정보를 처리할 수 있다. 세계 국가의 명시적 표현은 LLM이 관련 정보를 유지하고 액세스할 수 있도록 권한을 부여하여 보다 포괄적이고 맥락적으로 인식되는 추론 프로세스를 촉진한다. Dasgupta 등(2022)은 LLM의 상보적 추론 능력을 결합한 협업 시스템을 제안한다. 이 시스템에는 플래너, 액터 및 리포터의 세 가지 구성 요소가 있습니다. 플래너는 액터라고 하는 단순 구현된 에이전트의 동작을 안내하는 명령을 생성하는 사전 훈련된 언어 모델입니다. 리포터는 플래너와 행위자 간의 커뮤니케이션 브릿지 역할을 하며, 플래너에게 관련 정보를 전달하여 후속 명령 발행을 위한 의사결정 과정을 알려준다. 이 협력 시스템은 각 구성 요소의 장점을 활용하여 LLM의 전반적인 추론 및 의사 결정 기능을 향상시켜 언어 기반 명령어와 구현된 에이전트 간의 보다 효과적이고 상황 인식적인 상호 작용을 가능하게 하는 것을 목표로 한다. Inner Monologue(Huang et al., 2022)는 추가적인 훈련 없이 자연어 피드백을 활용하여 체화된 컨텍스트에서 LLM이 효과적으로 추론할 수 있는 능력을 조사한다. 저자들은 환경 피드백을 통합함으로써 LLM이 로봇 제어 시나리오 내에서 처리하고 계획하는 능력을 증가시키는 내부 독백을 개발할 수 있다고 제안한다. 이 개발을 통해 LLM은 환경에 대한 보다 포괄적인 이해도를 얻고 동적 환경에 대한 적응성을 향상시킬 수 있다.

후향적 추론의 반복적 특성은 환경의 진화하는 상태와 실행된 행동의 결과에 기초하여 계획을 동적으로 조정할 수 있게 한다. 이러한 적응 프로세스는 경험에서 얻은 지식을 활용하여 미래의 의사 결정을 지속적으로 개선하기 때문에 계획의 효율성과 효율성을 향상시킨다.

#### 3.8.3 Embodied Reasoning

최근 연구는 로보틱스 도메인에서 LLM의 성공적인 적용을 강조했다(Ahn et al., 2022; Zeng et al., 2023; Huang et al., 2022; Liang et al., 2022; Ding et al., 2023). 또한, 계획은 시간 추론의 한 형태로 간주될 수 있으며, LLM을 로봇 공학에 통합하는 것의 중요성을 더한다. 가토(Reed et al., 2022)는 멀티모달, 멀티태스크, 멀티체조 일반주의 정책으로서 기능한다. 12억의 인상적인 매개변수 수로 지도 학습을 활용합니다.

이 기술은 "범용" 인공 지능의 한 형태로 인정되어 인공 일반 지능의 실현에 대한 상당한 발전을 나타낸다. 로봇 트랜스포머 1(RT-1)(Brohan 등, 2022)은 700개 이상의 작업을 포괄하는 130,000개 이상의 에피소드로 구성된 포괄적인 실세계 로봇 데이터세트에 대해 훈련된다. 이 광범위한 데이터 세트는 매일 로봇의 13개 로봇을 사용하여 17개월 동안 수집되었다. RT-1은 확장 가능하고 사전 훈련된 모델로서 유망한 특성을 보여주며 데이터 크기, 모델 크기 및 데이터 다양성과 같은 요인을 기반으로 일반화하는 능력을 보여준다. RT-2는 실제 로봇에서 수집된 대규모 데이터를 활용함으로써 RT-1의 강건성과 실제 시나리오에서의 일반화 가능성에 기여한다. RT-1, Robotic Transformer 2 (RT-2) (Brohan et al., 2023)의 기능을 확장하면 모델의 세계 이해도를 더욱 향상시켜 로봇 작업을 보다 효율적이고 정확하게 수행할 수 있다. 사고 추론 체인을 통합함으로써 RT-2는 다단계 의미 추론 능력을 달성한다. 이러한 확장은 방대한 인터넷 규모의 데이터 세트에 대한 광범위한 훈련에서 파생된 일련의 새로운 능력으로 RT-2를 제공한다. 그 후, RT-X(Padalkar 등, 2023)는 RT-1 및 RT-2를 교차 실시예 설정으로 더 확장하고, 더 나은 전이성 및 제로-샷 능력을 나타낸다. RoboFlamingo(Li et al., 2023)는 미리 훈련된 Vision-Language Models(VLMs)를 활용하여 정교한 단일 단계 비전-언어 이해를 달성한다. 순차적인 이력 데이터를 효과적으로 포착하기 위해 명시적인 정책 헤드를 통합한다. 이 설계는 개방 루프 제어 전략을 구현하는 데 필요한 유연성을 부여하고 자원이 제한된 플랫폼에서 효율적인 배치를 위해 미세 조정된다.

구현된 추론은 지능형 로봇의 개발에 중요한 역할을 한다. 인간으로서 우리는 수치/물리적 법칙과 논리적 원리를 사용하여 세상을 이해하도록 교육받는다. 같은 능력을 가진 로봇에게 힘을 실어줄 수 있을까요? 수많은 일상적인 작업은 시각적 지각과 자연어 이해를 바탕으로 한 단순한 추론을 필요로 한다. 로봇 동반자가 우리와 협업할 수 있기를 원한다면, 그들은 시각 정보와 자연 언어 입력 모두에 대해 이해하고 추론하는 능력을 소유하는 것이 필수적이다. 스마트 로봇을 만드는 궁극적인 목적은 인간 능력에 필적하거나 심지어 능가하는 방식으로 행동할 수 있게 하는 것이다(Xu 등, 2021). 이는 인간과 기계의 간극을 메우는 것을 목표로 로봇에서 인간과 유사한 추론과 성능을 구현하는 것을 수반한다. 로봇이 시각적, 언어적 입력에 대해 이해하고 추론할 수 있도록 함으로써 인간과 효과적으로 상호작용하고 협업할 수 있는 로봇 개발의 목표를 달성하는 데 더 가까워진다.

#### Multi-agent Reasoning

다중 에이전트 추론은 다수의 자율 에이전트 또는 엔티티가 공유된 환경 또는 컨텍스트 내에서 추론, 의사 결정 및 커뮤니케이션에 참여하는 인지 프로세스를 의미한다. 단일 에이전트와의 추론과 비교할 때 개별 에이전트가 다른 에이전트의 행동, 목표, 신념 및 의도에 대해 인식하고 해석하고 추론하며 그에 따라 자신의 행동을 조정하는 능력을 포함한다. 그들의 차이점은 그림 13에 간략하게 요약되어 있다.

최근 연구는 다양한 시나리오에서 추론 능력을 높이고 사실적 정확성을 보장하기 위한 유망한 방법으로 다중 에이전트 토론의 개념을 도입했다. Zhang 등(2023c)의 작업에서, 그들은 체화된 환경 내의 다수의 에이전트들 간의 협력 상호작용을 육성하기 위해 LMM(Large Language Models)의 능력을 활용하는 프레임워크를 도입한다. 이 혁신적인 접근법은 구체화된 에이전트가 다른 에이전트 및 인간 모두와 효율적으로 전략화하고, 소통하고, 협력하도록 권한을 부여하여 복잡하고 장기적인 작업을 수행하는 능력을 향상시킨다. 유사한 맥락에서, Du 등(2023)은 토론에 참여하는 언어 모델의 여러 인스턴스를 포함하는 방법론을 제안한다. 추론 및 응답 생성의 반복적인 라운드를 통해 이러한 모델은 집합적으로 공통 최종 답변에 도달하는 방향으로 작동한다. 이 접근법은 다양한 작업에 걸쳐 수학적 및 전략적 추론에서 상당한 개선을 보여주었다.

앞서 언급한 연구들과 대조적으로, Nascimento 등(2023)은 GPT 기반 기술들과 같은 LLM들을 다중 에이전트 시스템들(MASs)에 통합하는 것을 제안한다. 그들은 자기 조정 에이전트를 만들기 위해 MAS에 LLM을 통합하는 개념을 도입한다. 이러한 통합은 LLM 기반 MAPE-K(Monitoring, Analyzing, Planning, Executing and Knowledge) 모델(do Nascimento and de Lucena, 2017; Redbooks, 2004)을 통해 달성되며, 이는 에이전트가 LLM에서 얻은 지식과 통찰력을 기반으로 행동을 적응하고 조정할 수 있도록 한다.

연방 학습(Federated Learning, FL)은 분산된 상태로 유지되는 데이터를 보호하면서 공동 모델의 공동 개발을 가능하게 하는 기술로 유명해졌다. Chen 등(2023a)은 연합 LLM의 사전 훈련, 이러한 모델의 미세 조정 및 연합 LLM에 특정한 프롬프트의 엔지니어링이라는 세 가지 중요한 요소를 포함하는 연합 LLM의 개념을 소개한다. 이 접근법은 LLM을 활용하여 다중 에이전트 추론을 향상시키기 위한 연합 학습의 잠재력을 활용한다.

이러한 연구 노력은 추론 능력과 사실적 정확성을 향상시키는 데 다중 에이전트 토론 접근법의 효과를 보여준다. 대형 언어 모델의 힘을 활용하고 에이전트 간의 협력적인 상호 작용을 가능하게 함으로써

도. 13: 단일 에이전트 추론과 다중 에이전트 추론의 차이점.

연구는 다양한 영역에서 복잡한 추론이 가능하고 성능이 향상될 수 있는 AI 시스템의 발전에 기여한다.

#### 자율 주행에서 추론

지각(Li et al., 2023, 2023, 2022, 2023), 안전성(Zhou et al., 2023), 설명가능성(Echterhoff et al., 2023; Sha et al., 2023; Sun et al., 2021; Huang et al., 2021) 및 시스템 레벨(Chen et al., 2023). Chen 등(2023)은 종단간 자율 주행을 위한 프론티어 및 과제를 제안하며, 여기서 LLM들을 사용한 논리적 추론은 상이한 운전 시나리오들에 실질적인 영향을 미칠 수 있다. Zhou et al.(2023)은 운전과 관련하여 LLM에 대한 최근 작업을 검토한다. 언어 데이터를 통합함으로써 운송 시스템뿐만 아니라 차량도 추론을 수행하고 더 높은 수준의 지능으로 실제 환경과 상호 작용할 수 있음을 시사한다.

우리는 기초 모델에서 물려받은 상식과 세계 지식이 코너 케이스를 처리하고 설명 가능성과 안전성을 향상시키기 위해 탑재된 알고리즘의 실질적인 효과를 발휘할 수 있다고 믿는다. 아래에서는 이 새로운 주제를 두 가지 관점에서 조사한다.

DriveGPT4(Xu 등, 2023)는 해석 가능한 엔드 투 엔드 자율 주행 시스템을 이해하기 위해 LLM을 활용하는 획기적인 시도를 나타낸다. 이러한 선구적인 노력은 도전적인 표준에 대해 벤치마킹했을 때 놀라운 질적 성과뿐만 아니라 양적 성과도 보여준다. GPT-Driver(Mao et al., 2023) 및 Agent Driver(Mao et al., 2023)는 툴 라이브러리를 동작시키기 위해 LLM을 인지 에이전트로 활용하여 접근 방법을 소개한다. 이 구현은 의사 결정 과정에 설명 가능성을 통합함으로써 운전 행동을 향상시킨다. MotionLM(Seff et al., 2023)은 언어 모델링 태스크로서 멀티 에이전트 모션 예측을 캐스팅하였다. 연속 궤적은 이산 모션 토큰의 시퀀스로 표현된다. 다른 많은 시도들 중에서, 한 가지 특별한 도전은 운전 행동을 합리화하고 설명하기 위해 논리적 추론(예를 들어, 사고 사슬)을 활용하는 방법이다. Echterhoff 등(2023)은 제어 명령 예측을 위한 개념 병목 현상을 이용한 새로운 뷰를 제안한다. Tan 등(2023)은 동적 트래픽 시나리오를 획득하기 위해 수퍼비전의 소스로서 언어에 의지하며, 현실성 및 충실성 측면에서 선행 작업을 능가한다. nuPrompt(Wu et al., 2023)는 3D, 멀티 뷰, 및 멀티 프레임 구동 장면을 위해 설정된 최초의 객체 중심 언어 프롬프트이다. 다양한 인스턴스 프롬프트 데이터를 탑재하고 객체 추적 작업에서 검증된다.

### 다른 작업 및 응용 프로그램

#### 마음 이론(ToM)

모델에서 마음 이론(ToM)과 같은 능력의 발달은 언어 기술의 진보의 결과로 자연스럽고 독립적으로 발생한 것으로 추측된다(코신스키, 2023). 또 다른 설명은 모델이 ToM을 명시적으로 사용하기보다는 발견되지 않은 언어 패턴을 발견하고 활용함으로써 ToM 작업을 해결할 수 있음을 시사한다. 이 대안적 설명은 평범해 보일 수 있지만 ToM의 직접적인 참여 없이 ToM 작업의 해결을 가능하게 하는 공개되지 않은 언어 규칙의 존재를 암시하기 때문에 실제로 주목할 만하다.

#### Weather Forecasting

날씨 예측은 과학적 연구와 사회적 응용 모두에서 중요한 역할을 한다. 과학적 추론의 응용으로서, 기상 예측은 데이터를 분석하고 패턴을 식별하며 미래의 기상 조건에 대한 예측을 하기 위해 추론 기술을 사용하는 것을 포함한다.

MetNet-2(Espeholt et al., 2022)는 최대 12시간 리드 타임을 갖는 고해상도 강수 예측을 위해 특별히 설계된 신경망이다. 이 모델은 원시 강수 목표를 정확하게 예측하는 데 탁월하며 현재 미국에서 사용되는 최첨단 물리 기반 모델보다 성능이 뛰어납니다. 또 다른 연구에서 Bi 등(2023)은 중간 범위의 정확한 글로벌 일기 예보를 달성하도록 설계된 AI 기반 접근법인 Pangu-Weather를 제시한다. 이 방법은 지구별 사전 정보를 통합하는 3D 심층 네트워크를 활용하여 복잡한 기상 데이터 패턴을 효과적으로 처리할 수 있습니다. 중거리 예측에서 발생하는 누적 오류를 완화하기 위해 계층적 시간 집계 전략을 사용한다. 39년간의 전 지구 기상 정보에 걸친 광범위한 데이터 세트에 대한 훈련을 통해 판구-날씨는 유럽 중거리 기상 예보 센터(ECMWF)의 운영 통합 예측 시스템과 비교할 때 평가된 모든 변수에 걸쳐 탁월한 결정론적 예측 성능을 보인다. 이는 정확한 글로벌 날씨 예보를 제공하는 판구-날씨의 놀라운 효과를 강조하여 날씨 관련 정보에 크게 의존하는 다양한 응용 프로그램에 귀중한 통찰력과 이점을 제공한다.

#### Medical Reasoning

추론은 의학에서도 흔하다. 예를 들어, 임상의는 환자의 증상의 잠재적 원인을 추론한 다음 진단을 받은 후 어떤 검사를 받고 어떤 치료가 가장 좋은지 조언한다(Qiu et al., 2023a).

광범위한 의학 지식 스펙트럼으로 기초 모델은 의학 맥락에서 전문가 수준의 추론을 수행할 수 있다. 예를 들어, 생물의학 대형 언어 모델(LLM)인 Med PaLM 2(Singhal et al., 2023)는 MedQA 벤치마크에서 의학 질문에 대한 답변에서 86.5%의 점수를 얻었으며, GPT-4는 86.7%의 점수로 USMLE(Medical Licensing Exam)을 통과하였다. LLM이 가져온 의학적 추론의 돌파구는 의료 영상과 같은 다른 의학적 양식에서 수행된 추론을 고무하기도 한다. 예를 들어, 안과 이미지 분석을 위한 기초 모델인 VisionFM(Qiu et al., 2023b)은 안저 사진으로부터 두개내 종양의 존재를 예측하는데 있어서 인상적인 추론 기술을 보여주며, 중급 및 상급 임상의 모두를 능가한다. RETFound(Zhou et al., 2023d)는 안구 이미지로부터 전신 질환을 추론하는 데 있어 괄목할 만한 성능을 보인다. LLaVA-Med(Li et al., 2023b)는 LLaVA(Liu et al., 2023e)를 응용하여 생물의학 어휘를 정렬하고 개방형 대화 시맨틱을 학습함으로써 생물의학 이미지의 해석을 가능하게 하고 생물의학 시각적 질문 답변에 유망한 성능을 달성한다. ELIXR(Xu 등, 2023d)은 흉부 X-선 이미지들에 대한 다양한 비전-언어 추론 태스크들을 수행하기 위해 언어-정렬 이미지 인코더를 통합한다. Tu 등(2023)은 임상 언어, 이미징 및 유전체학 데이터를 동시에 탐색할 뿐만 아니라 멀티모달 바이오메디컬 벤치마크인 MultiMedBench를 소개하기 위해 멀티모달 바이오메디컬 기초 모델인 Med-PaLM M을 개발한다. 의학의 멀티모달 특성을 고려할 때, 점점 더 지능화된 멀티모달 기초 모델(Yang et al., 2023)에 의해 의학적 추론이 더욱 증강될 것으로 예상된다.

그러나, 다른 영역에서와는 달리 의학에서의 추론은 더 주의를 기울여야 한다(Yan et al., 2023). 생물의학 추론 결과가 사실적으로 근거되도록 엄격한 검증과 검토가 이루어져야 하며, 생물의학 추론을 위한 기초 모델의 합법적이고 안전한 사용을 제공하기 위한 규정을 제정하고 시행해야 한다.

#### Bioinformatics Reasoning

생물정보학에서의 추론은 생물학의 복잡한 언어를 분석하고 해석하고 생명과 관련된 과정에 대한 통찰력을 얻는 것을 포함한다. 여기에는 대규모 데이터 세트의 분석을 통해 유전자 서열, 단백질 기능 및 세포 메커니즘을 이해하는 것이 포함된다. 파운데이션 모델은 단백질 구조를 예측하고 약물 발견에서 서열을 설계하는 등 생물학적 추론을 위한 다양한 관점을 재구성하고 있다(Savage, 2023).

생명공학 분야에서, 수많은 연구들은 DNA(Nguyen et al., 2023), RNA(Wang et al., 2023), 및 단백질(Jumper et al., 2021)을 추론하고 분석하는 데 있어서 기초 모델의 효능을 강조한다. 주목할 만한 예는 AlphaFold(Jumper et al., 2021)이며, 이는 단백질 구조를 정밀하게 예측하기 위해 트랜스포머 네트워크 아키텍처를 채용한다. 프로젠(Madani 등, 2023) 및 그의 후속 프로젠2(Nijkamp 등, 2022)는 단백질 서열을 생성하기 위한 자연 언어 모델과 유사한 대형 단백질 언어 모델의 제품군을 개발한다. RFdifusion(Watson et al., 2023)은 단백질 구조 설계에서 디노이징 확산 접근법을 채택하여, 다양한 단백질 설계 작업에 걸쳐 상당한 발전을 보여준다. 단백질-리간드 상호작용의 맥락에서, Li 등(2023)은 리간드 설계를 위한 언어 모델 능력을 활용하여 단백질-리간드 결합 데이터에 대한 GPT-2 모델을 훈련시킨다. Prot2Text(Abdine et al., 2023)는 자유 텍스트 형식의 단백질 기능을 예측하기 위해 그래프 신경망과 LLM을 결합한다. Chen 등(2023)은 약물 발견을 돕는 화학 합성에서의 상태 추천을 위해 LLM에 의해 구동되는 프레임워크를 소개한다. 이 프레임워크는 가장 최근의 화학 문헌을 검색하고, 맥락 내 학습 능력을 활용하고, 효율성을 높이기 위해 다중 LLM 토론 전략을 사용하도록 설계되었다. RNA 분석을 위해, Uni-RNA(Wang et al., 2023)는 광범위한 RNA 서열에 대한 대규모 사전 훈련을 레버리지함으로써, RNA 고차 구조 맵 예측을 포함한 구조적 및 기능적 예측에서 탁월한 성능을 나타낸다. 또한, HyenaDNA(Nguyen et al., 2023)는 LLM의 장거리 모델링 및 인-컨텍스트 학습 강점을 활용하고 인간 참조 게놈 데이터에 대해 사전 훈련되어 게놈 작업에서 상당한 성과를 산출한다. GeneGPT(Jin et al., 2023)는 유전체학과 관련된 질문에 대한 답변을 개선하는 NCBI(National Center for Biotechnology Information) API를 통합하여 LLM을 강화한다.

#### Code Generation

자연어 기술(NL2Code)(Zan 등, 2023)로부터 프로그램 합성 또는 코드를 생성하는 것으로도 지칭되는 코드 생성은 자연어로 된 입력을 컴퓨터 코드로 변환하는 프로세스 또는 기술이다. NL2Code는 자연어와 컴퓨터 코드 사이의 격차를 해소하기 위해 기초 모델을 활용하여 보다 직관적이고 접근 가능한 프로그래밍을 향한 중요한 단계를 나타낸다.

Clement 등(2020)의 작업에서 묘사된 PyMT5는 파이썬 기반 텍스트 대 텍스트 전송 변환기로서, 파이썬 방법 특징의 다양한 조합 사이에서 번역하는 데 능숙하다. 이 단수 모델은 자연어 문서 문자열에서 전체 메서드를 생성하고 코드를 다양한 공통 문서 문자열 스타일로 요약할 수 있습니다. 유사하게, IntelliCode Compose(Svyatkovskiy 등, 2020)는 다용도 다국어 코드 완성 툴로서, 코드 토큰 시퀀스들을 예측하고 구문적으로 정확한 코드 라인들을 생성하는데 능숙하다. GPT-Neo(Black et al., 2021)는 Mesh Tensorflow를 통한 분산 지원에 중점을 두고 GPT-2 및 GPT-3 유사 모델의 구현을 예시한다. 이 접근법은 Wang 및 Komatsuzaki(2021) 및 Black 등(2022)에 각각 상세히 기술된 바와 같이, GPT-J 및 GPT-NeoX-20B에서 더욱 확장된다. PLBART(Ahmad et al., 2021)는 디노이징 오토인코딩 접근법을 활용하여 자연어 텍스트와 결합된 자바 및 파이썬 함수의 광범위한 코퍼스에서 사전 훈련된 모델이다. CodeT5(Wang et al., 2021)는 자신을 통일된 사전 훈련된 인코더-디코더 Transformer로 구별하여 개발자 할당 식별자에 대한 의미론적 이해를 높이고 있다. LaMDA(Thoppilan et al., 2022)는 상당한 양의 대화 데이터 및 웹 텍스트에 대해 사전 훈련된, Transformer 기반 모델의 대화 전문 패밀리로 등장한다.

CodeParrot(Tunstall et al., 2022)는 Python 코드 생성을 위해 훈련된 GPT-2 기반 모델인 반면, Codex(Chen et al., 2021)는 GitHub로부터의 방대한 공개 코드 배열에 미세 조정된 GPT 언어 모델을 보여준다. Chandel 등(2022)은 공개 Jupyter Notebook 리포지토리에서 훈련된 트랜스포머 모델 JuPyT5에 의해 권한을 부여받은 데이터 사이언스 어시스턴트의 실용성을 조사하고, 새로운 평가 메트릭인 DSP를 소개한다. 폴리코드(Xu 등, 2022)는 대규모 코드 데이터세트에 대해 훈련된, 다수의 언어에 걸쳐 실질적인 코딩 숙련도를 갖는 GPT-2 기반 모델이다. 알파코드(Li et al., 2022)는 코드 생성 시스템으로 두각을 나타내고 있어 프로그래밍 대회에서 주목할 만한 성과를 보여주고 있다. CodeRL(Le et al., 2022)은 프로그램 합성을 위해 사전 훈련된 언어 모델을 강화 학습과 병합한다. ERNIE-Code(Chai et al., 2022)는 단일 언어 및 교차 언어 학습 모두에 초점을 맞춘 독특한 사전-훈련 방법을 채용한다. Pangu-Coder(Christopoulou et al., 2022)는 초기에 원시 프로그래밍 언어 데이터에 초점을 맞추고 후속적으로 텍스트-대-코드 생성에 초점을 맞추는, 2단계 트레이닝 전략을 채택한다. FIM(Bavarian et al., 2022)은 텍스트 채움에서 자기회귀 언어 모델의 효능을 입증한다. Zan 등(2022)은 라벨링되지 않은 데이터에 대해 훈련된, 상세한 코드 생성을 위한 스케처 및 생성기를 포함하는 모델인 CERT를 소개한다. InCoder(Fried et al., 2022)는 대규모의 허가된 코드 코퍼스로부터의 코드 파일 생성에 초점을 맞추어, 양방향 컨텍스트를 갖는 코드 채움을 가능하게 한다. Nijkamp 등(2022)은 JAXFORMER 트레이닝 라이브러리와 함께 자연어 및 프로그래밍 모두를 위한 대형 언어 모델들의 패밀리인 CodeGen을 제시한다.

CodeGeeX(Zheng et al., 2023c)는 프로그래밍 언어의 방대한 데이터세트에 대해 훈련된, 코드 생성을 위한 다국어 모델이다. SantaCoder(Allal et al., 2023)는 The Stack(Kocetkov et al., 2022)으로부터 Java, JavaScript, 및 Python 서브세트에 대해 훈련되고 MultiPL-E 텍스트-투-코드 벤치마크를 사용하여 평가된 11억 개의 파라미터를 갖는 모델이다. 본 연구를 통해 유사 중복 필터링을 강화하면 성능이 향상되고, 흥미롭게도 5개 이상의 GitHub 스타가 있는 리포지토리에서 파일을 선택하는 것이 성능을 크게 감소시키는 경향이 있음을 알 수 있었다. 대조적으로, StarCoder(Li et al., 2023k)는 155억 개의 파라미터 및 8K 컨텍스트 길이를 갖는 보다 강건한 모델이다. 멀티-쿼리 주의에 의해 인에이블되는 인필링 능력 및 신속한 대용량 추론을 자랑하며, The Stack(Kocetkov 등, 2022)으로부터 1조 토큰의 방대한 데이터세트에 대해 트레이닝된다. WizardCoder(Luo et al., 2023f)는 코드 도메인에 대한 Evol-Instruct 방법을 적용하여 복잡한 명령어 미세 조정을 통해 코드 LLM을 강화한다. AceCoder(Li et al., 2023h)는 코딩 문제를 해결하기 위해 두 가지 혁신적인 솔루션을 통합한다. 첫째, 가이드 코드 생성을 사용하여 LLM이 요구 사항을 초기에 분석하고 테스트 케이스와 같은 예비 출력을 생성하도록 유도하고, 둘째, 예제 검색을 특징으로 하며, 유사한 프로그램을 빠른 예제로 선택하여 알고리즘 및 API와 같은 관련 콘텐츠를 제공한다. CodeGen2(Nijkamp 등, 2023)는 모델 아키텍처, 학습 방법, 인필 샘플링 및 데이터 분포의 네 가지 필수 요소를 통합하여 프로그램 합성을 위한 LLM의 훈련을 보다 효율적으로 만드는 것을 목표로 한다. CodeT5+(Wang et al., 2023t)는 다운스트림 코드 태스크의 광범위한 스펙트럼을 다루기 위해 유연한 모듈 조합에 의해 특징지어지는 코드를 위한 인코더-디코더 LLM의 패밀리를 형성한다. CodeTF(Bui et al., 2023)는 최신 코드 LLM 및 코드 인텔리전스 애플리케이션을 전용으로 하는 오픈소스 Transformer 기반 라이브러리이다. 코드 Llama(Roziere et al., 2023)는 Llama 2에 기초하여, 코드에 대한 대규모 언어 모델들의 패밀리를 나타내며, 주입 능력들, 대규모 입력 컨텍스트들에 대한 지원 및 프로그래밍 태스크들에 대해 제로-샷 방식으로 명령어들을 따르는 능력과 함께 개방형 모델들 중 최상위 성능을 제공한다. CodeFuse(Di 등, 2023)는 코드 관련 작업을 위해 맞춤 제작되며, 40개 이상의 프로그래밍 언어를 수용하는 영어 및 중국어 프롬프트 모두에 대한 지원에서 유일하다.

#### Long-Chain Reasoning

긴 사슬 추론은 일련의 복잡하고 복잡한 정보 또는 사건에 대해 긴 순차적이고 확장된 방식으로 연결하고 추론하는 능력을 의미한다. 복잡한 시스템의 복잡한 문제 해결, 의사 결정 및 이해에서 긴 사슬 추론이 종종 필요하다.

Ho 등(2022)은 매우 큰 교사 모델을 활용하여 더 작은 모델을 미세 조정하기 위한 추론 샘플을 생성하는 방법인 Fine-tune-CoT를 소개한다. Fine-tune-CoT를 사용하여 더 작은 모델은 프롬프트 기반 기준선을 능가하고 수많은 작업에서 교사 모델을 능가하는 상당한 추론 능력을 획득한다.

기초 모델들의 출현 이전에, 이전 모델들의 추론 능력들은 현저하게 제한되었다(Sun et al., 2022a). 이러한 한계는 주로 학습 기반 모델이 이전 정보를 빠르게 잊는 경향에서 비롯되었다. 장사슬 추론은 AI 에이전트 추론 또는 구현 추론에 적용할 수 있는 큰 잠재력을 가지고 있어 보다 복잡하고 미묘한 작업을 처리할 수 있다.

GPT-4와 같은 기초 모델의 출현에도 불구하고 장사슬 추론을 마스터하는 것은 여전히 중요한 과제이다. 우리는 의사 결정, 계획 및 질문 응답과 같은 응용 프로그램에서 긴 사슬 추론의 엄청난 유용성을 강조한다. 이를 염두에 두고 이 분야에 주의를 기울이는 것을 목표로 하며, 기초 모델의 연구자들이 이 분야에서 더 조사하고 발전하도록 장려한다.

#### 3.9.7 추상 추론

추상추론은 특정한 맥락이나 구체적인 예시에 의존하지 않고 추상적인 개념이나 아이디어 또는 기호를 분석하고 조작하는 인지적 능력을 의미한다. 그것은 근본적인 패턴, 관계 및 기본 원칙을 식별하기 위해 즉각적인 감각 입력과 특정 사례를 초월하는 것을 포함한다. 추상적 추론은 제한된 데이터를 기반으로 일반적인 패턴을 식별하고 적용해야 한다.

Gendron 등(2023)은 추상적 추론 태스크들에서 최첨단의 LLM들을 광범위하게 평가한다. 그들의 연구에 따르면 이러한 모델은 다른 자연어 작업에 대한 성능에 비해 현저하게 제한된 성능을 보여준다. 연구 결과는 LLM이 추상적 추론을 효과적으로 다루는 데 있어 어려움에 직면해 있음을 시사하여 이 분야에서 추가 발전의 필요성을 강조한다.

#### 3.9.8 Defeasible Reasoning

실현 가능한 추론은 새로운 증거나 정보에 기초하여 결론이 뒤집히거나 수정될 수 있는 추론 방식을 의미한다(Madaan et al., 2021). CURIOUS(Madaan et al., 2021)는 추론 그래프(Pollock, 2009)를 활용하여 인간에 대한 패배 가능한 추론을 지원하는 프레임워크이다. Rudinger et al.(2020)은 배변추론의 맥락에서 \(\delta\)-ATOMIC, \(\delta\)-SNLI, \(\delta\)-SOCIAL의 세 가지 주목할 만한 데이터 세트를 제공했다. 이러한 데이터 세트는 여러 도메인을 포괄하여 다양성을 나타내며, 실패 가능한 추론을 연구하는 데 고유한 문제를 제공합니다. \ (\delta\)-ATOMIC는 상식 추론에 관한 것으로, 배경 지식과 일상적인 상황에 대한 이해를 바탕으로 패배할 수 있는 추론을 그려야 하는 시나리오를 제시한다. \ (\delta\)-SNLI는 자연어 추론에 초점을 두고 있으며, 전제와 가설 사이의 관계에 대한 추론이 필요하다. \ (\delta\)-SOCIAL은 사회적 규범과 관습에 대한 추론을 포함하며, 사회적 행동을 이해하고 해석하는 데 패배 가능한 추론의 적용을 조사하는 플랫폼을 제공한다. Zhou et al. (2020)은 지식 추상화, 구체화, 완성(KACC)과 같은 인간의 인지 과정을 시뮬레이션하는 모델의 능력을 평가하는 것을 목표로 하는 테스트 베드를 소개한다. 이 테스트 베드는 더 큰 개념 그래프, 충분한 크로스 뷰 링크, 밀집된 개체 그래프로 특징지어지는 새로운 데이터 세트를 포함하여 지식을 보다 포괄적으로 표현한다. 이 실험 프레임워크 내에서 저자는 혁신적인 도전, 특히 다중 홉 지식 추상화(MKA) 및 다중 홉 지식 구체화(MKC)를 소개한다. 이러한 과제는 여러 순차적 단계에 걸쳐 지식의 추상화 또는 구체화를 포함하는 모델로부터 복잡한 추론 능력을 필요로 한다. Kazemi et al. (2023)은 소스 선호도에 따라 안내되는 모순된 정보를 추론하는 문제를 _defeasible reasoning_의 고전적인 문제로 프레임화한다. 이 공식화는 상충되는 정보를 처리하고 추론 과정에서 다른 소스를 우선순위화하는 모델의 능력을 종합적으로 탐색할 수 있게 한다. BoardgameQA(Kazemi et al., 2023)는 모델의 패배 추론 능력을 평가하기 위해 설계된 데이터세트이다. 데이터 세트는 각 변형에 대해 1000개의 학습 예제, 500개의 유효성 검사 예제 및 1000개의 테스트 예제로 구성됩니다.

이러한 데이터 세트 각각은 다양한 도메인 내에서 패배 가능한 추론을 연구하고 발전시킬 수 있는 뚜렷한 도전과 기회를 제공한다. 연구자들은 이러한 데이터 세트를 활용하여 다양한 맥락에서 패배 가능한 추론 모델의 능력과 한계를 탐색할 수 있으며, 기초 모델 기술을 사용하여 강력하고 적응 가능한 추론 시스템의 개발에 기여할 수 있다.

### Benchmarks, Datasets 및 메트릭

벤치마크, 데이터셋 및 메트릭은 다양한 영역에서 추론 능력을 평가하고 발전시키고 혁신을 주도하며 보다 유능하고 신뢰할 수 있는 추론 시스템의 개발을 촉진하는 데 중요한 역할을 한다. 이러한 자원들은 연구자 및 개발자들이 추론 모델의 성능을 객관적으로 평가하고 상이한 접근법들을 비교할 수 있게 하는 표준화된 프레임워크들 및 태스크들을 제공한다. 대표적인 데이터 세트는 표 8과 9에 요약되어 있다.

#### 3.10.1 Commensense Reasoning

CQA(Talmor et al., 2019) 및 CoS-E(Rajani et al., 2019) 외에도, 상식 추론 평가에 이용 가능한 몇 가지 다른 벤치마크가 있다(표 5): PHYRE(PHYsical REasoning) 벤치마크(Bakhtin et al., 2019)는 물리적 추론에 초점을 맞춘 25개의 태스크 템플릿으로 구성된다. CConS(Counter-commonsense Contextual Size Comparison) 데이터 세트(Kondo et al., 2023)는 물리적 상식이 상황화된 크기 비교 작업에 미치는 영향을 조사한다. 물리적 상식과 일치하는 맥락과 그로부터 벗어나는 맥락을 모두 포함한다. 데이터세트는 139개의 템플릿을 포함하고 1,112개의 예를 자동으로 생성한다. SummEdits(Laban et al., 2023)는 10개의 도메인에 걸쳐 있는 벤치마크이다. 이전 벤치마크에 비해 샘플당 비용 효율적이도록 설계되어 20배 개선 효과를 제공합니다.

\begin{table}
\begin{tabular}{c|c|c|c} \hline \hline Dataset & Choices & Knowledge Types & Questions \\ \hline Swag Zellers et al. (2018) & 4 & Temporal, Physical & 113,000 \\ PHYRE Bakhtin et al. (2019) & / & Physical & 25 \\ HellaSwag Zellers et al. (2019) & 4 & Temporal, Physical & 70,000 \\ WinoGrande Sakaguchi et al. (2021) & 2 & Social, Physical & 44,000 \\ Social IQA Sap et al. (2019) & 3 & Social & 35,350 \\ PIQA Bisk et al. (2020) & 2 & Physical & 21,020 \\ SummEdits Laban et al. (2023) & 2 & Social & 6,348 \\ CConS Kondo et al. (2023) & / & Physical & 1,112 \\ \hline \hline \end{tabular}
\end{table}
표 5: 상식 추론 벤치마크 통계. 선택: 각 질문에 대한 선택 수; 질문: 질문 수입니다.

효율적으로. 이 벤치마크는 재현성이 높으며 복잡한 작업에 대한 언어 모델 기반 시스템(LLM)의 성능을 평가하는 것을 목표로 하며 기존 평가 벤치마크의 문제를 해결한다.

나아가 상식 지식은 물리적 상식, 사회적 상식, 시간적 상식 등 다양한 범주를 포괄한다. 이 영역의 벤치마크는 일반적으로 객관식 평가와 생성적 평가의 두 가지 과제에 속한다. SWAG(Zellers et al., 2018), HellaSWAG(Zellers et al., 2019), Social IQA(Sap et al., 2019), 및 PIQA(Bisk et al., 2020)와 같은 객관식 벤치마크는 모델들이 옵션들의 세트로부터 정답을 선택하도록 요구한다. 생성 평가(Lin 등, 2020)는 ProtoQA(Boratko 등, 2020) 및 CommonGen(Lin 등, 2020)과 같은 벤치마크에서 볼 수 있듯이 제공된 질문 및 컨텍스트에 기초하여 답변을 생성하는 것을 포함한다. 레인보우(Lourie et al., 2021)는 6개의 기존 태스크: 1) \(\alpha\)NLI(Bhagavatula et al., 2019); 2) 코스모스 QA(Huang et al., 2019); 3) HellaSWAG(Zellers et al., 2019); 4) PIQA(Bisk et al., 2020); 5) 소셜 IQA(Sap et al., 2019); 및 6) WinoGrande(Sakaguchi et al., 2021). 사회적 상식 추론과 물리적 상식 추론을 모두 포괄하고 종합적인 평가 플랫폼을 제공한다.

_Metrics_

선다형 벤치마크에서 정확도는 정답을 선택하는 모델의 능력을 평가하는 데 사용되는 주요 메트릭이다. 그러나, 언어 생성 평가에서, BLEU(Papineni 등, 2002)와 같은 자동화된 메트릭이 항상 인간의 판단과 완벽하게 일치하는 것은 아닐 수 있으므로, 주의해서 사용해야 한다.

PHYRE 벤치마크(Bakhtin 등, 2019)의 경우 AUCCESS라는 메트릭 측정 성능이 계산된다. AUCCESS는 가중 평균을 사용하여 다양한 시도 전반에 걸친 성공률을 집계한다. AUCCESS의 공식은 AUCCESS \(=\sum_{k}w_{k}\cdot s_{k}/\sum_{k}w_{k}\)이다. 여기서, \(w_{k}\)은 시도가 적은 작업에 더 중점을 두는 가중치를 나타내며, \(w_{k}=\log(k+1)-\log(k)\으로 계산된다. 변수 \(s_{k}\)은 \(k\) 번째 시도에서의 성공률을 나타낸다. AUCCESS는 여러 시도들에 걸친 성능을 고려하고, 더 적은 시도들로 태스크들을 해결하기 위한 모델들에 보상하는 더 포괄적인 평가를 제공한다.

#### Mathematical Reasoning

_MWPs(Math Word Problem)_

수학 단어 문제 해결을 위해 도입된 몇 가지 벤치마크 데이터 세트가 있다. 그러한 데이터세트 중 하나는 Alg514(Kushman et al., 2014)이며, 이는 또한 평가를 위해 (Zhou et al., 2015)에 의해 사용된다. Alg514는 온라인 플랫폼에서 제공되는 514개의 대수 단어 문제로 구성된다. 데이터 세트의 각 문제는 선형 방정식으로 주석이 달렸고, 각 문제의 템플릿은 전체 집합 내에서 최소 6번 나타나야 한다. 또 다른 데이터세트인 Verb395(Hosseini et al., 2014)는 덧셈 및 뺄셈 문제의 모음이다. DRAW 데이터 세트(Upadhyay and Chang, 2015)는 algebra.com에서 수집된 1,000개의 대수적 단어 문제를 대상으로 하였으며, SingleEQ(Koncel-Kedziorski 등, 2015)는 508개의 문제로 구성되어 있으며, 각 문제는 하나의 방정식에 해당한다. MaWPS(Koncel-Kedziorski et al., 2016) 저장소는 새로운 단어 문제를 추가하기 위한 인터페이스를 제공하며, 이는 데이터세트의 추가 확장을 허용한다. 이러한 벤치마크 데이터 세트는 다양한 난이도를 포괄하며 수학 단어 문제 해결 접근법을 평가하는 데 유용하다. Dolphin18K(Huang et al., 2016)는 초등수학 분야에서 주석이 달린 수학 단어 문제 18,000개 이상으로 구성되어 있다. 데이터세트에는 문제의 편집되지 않은 텍스트와 문제에 답한 개인이 제공한 단일 또는 다중 응답 텍스트가 모두 포함된다. MATH(Hendrycks 등, 2021)는 12,500개의 도전적인 경쟁 수학 문제를 포함한다. 이 데이터 세트의 각 문제에는 전체 단계별 솔루션이 함께 제공됩니다. 이 풍부한 주석이 달린 정보는 모델들이 상세한 답변 도출들 및 설명들을 생성하도록 훈련될 수 있게 한다. TabMWP(Lu et al., 2022)는 텍스트와 표 모두를 통한 수학적 추론이 필요한 38,431개의 등급 레벨의 오픈 도메인 문제들의 모음을 특징으로 한다. 이 데이터 세트는 6:2:2 분포에 따라 훈련, 개발 및 테스트 하위 집합으로 나뉜다. TabMWP에서 모든 쿼리는 이미지, 반구조 텍스트 및 구조화된 테이블로 표시되는 표 형식의 컨텍스트와 연결됩니다. 이 질문의 평균 길이는 22.1단어이며 솔루션은 평균 49.5단어입니다. TabMWP의 문제는 자유 텍스트 질문과 객관식 질문의 두 가지 유형이 될 수 있다. 모든 문제에는 다단계 추론을 설명하는 주석이 달린 황금 표준 솔루션이 함께 제공된다.

GSM8K(Cobbe et al., 2021)는 8.5K 초등학교 수학 단어 문제로 구성된 수학 단어 문제 데이터셋이다. 이러한 문제들은 다양한 수준의 언어적 복잡성과 어려움을 나타낸다. 문제 길이가 2단계부터 8단계까지 다양하기 때문에 효과적으로 해결하기 위해서는 다양한 수학적 기술과 전략이 필요하다. 다국어 초등학교 수학(MGSM) 벤치마크(Shi et al., 2023)는 GSM8K 데이터 세트(Cobbe et al., 2021)에서 다양한 언어 유형을 가진 10개 언어로 수동으로 번역된 250개의 초등학교 수학 문제로 구성된다. MGSM 벤치마크는 여러 언어에 걸쳐 언어 모델의 추론 능력을 평가하는 평가 도구 역할을 한다. 언어 간 교차 추론 및 언어 간 언어적 변이 처리와 같이 모델이 도전에 직면할 수 있는 영역을 식별하는 데 도움이 된다. 유형학적으로 다양한 언어를 통합함으로써 벤치마크는 실제 다국어 시나리오에 대한 적절성과 적용 가능성을 보장합니다.

초등학교 수준에서 수학 단어 문제를 위해 특별히 설계된 Math23K(Wang et al., 2017)와 HMWP(Qin et al., 2020)의 두 가지 중국 데이터 세트가 있다. 수학 23K(Wang et al., 2017)는 구조화된 방정식과 이에 대응하는 답으로 주석이 달린 23,161개의 문제로 구성되어 있다. HMWP(Hybrid Math Word Problem) 데이터셋(Qin et al., 2020)은 중국어 K12 수학 단어 문제은행에서 추출한 수학 단어 문제의 세 가지 유형을 포함한다. 데이터 세트는 5,491개의 수학 단어 문제로 구성되며, 다음과 같이 분류된다: 2,955개의 1-미지의 선형 MWP, 1,636개의 2-미지의 선형 MWP 및 900개의 1-미지의 비선형 MWP. 또한 1,000개의 일반 대수 단어 문제를 포함하는 DRAW1K 데이터 세트(Upadhyay and Chang, 2017)가 있다. 이 데이터 세트에는 문제 해결을 위한 정보 구조 역할을 하는 인간 주석 파생물이 포함된다. 저자는 또한 향후 평가를 용이하게 하기 위해 2,300개 이상의 대수적 단어 문제에 대한 파생 주석을 제공했다. 그들은 "도출 정확도"를 기반으로 해결사를 평가하는 것을 제안한다. Math23K-F 및 MAWPS-F(Liu et al., 2023)는 수학 단어 문제에 대한 각 추론 단계에서 수식 사용의 고품질, 정밀한 주석을 제공하는 데이터 세트이다. 이러한 데이터 세트는 문제 해결 과정 전반에 걸쳐 공식이 어떻게 활용되는지에 대한 이해도를 높이는 것을 목표로 한다. 이러한 데이터셋과 함께 저자는 이중 프로세스 이론의 통찰력을 통합하고 지식 시스템과 추론 시스템의 두 가지 구성 요소로 구성된 FOMAS 시스템(Liu et al., 2023)을 제안한다. 전자는 공식 지식을 학습하고 습득하는 역할을 하는 반면, 후자는 이 지식을 활용하여 수학 단어 문제를 해결한다. 이 이중 컴포넌트 아키텍처는 FOMAS가 추론 과정에서 공식 지식을 효과적으로 활용할 수 있도록 한다. The Academia Sinica Diverse MWP Dataset(ASDiv)(Miao et al., 2020)은 2,305개의 영어 수학 단어 문제(MWPs)로 구성된다. 이 데이터 세트의 수학 단어 문제(MWP)는 초등 교육에서 일반적으로 도입되는 대부분의 문제 유형을 포괄하는 다양한 텍스트 패턴을 보여준다. 또한, 컬렉션 내의 모든 문제는 유형과 교육 등급에 따라 세심하게 분류되어 난이도를 명확하게 나타낸다.

기존의 MWP 말뭉치는 크게 4개의 그룹으로 분류할 수 있는데, (1) 숫자와 관련된 문제를 배타적으로 포함하는 숫자 단어 말뭉치; (2) 4개의 기본 산술 연산을 포함하고 단일 단계 또는 다중 단계 문제가 될 수 있는 산술 단어 말뭉치; (3) 대수적 MWP에 초점을 맞춘 대수적 단어 말뭉치; (4) 일일 대수 또는 GRE/GMAT 시험에서 대규모 MWP 모음인 혼합형 MWP 말뭉치이다. SVAMP(Patel et al., 2021)는 ASDiv-A 데이터세트에서 초기 예제에 변형을 도입하여 만든 1,000개의 수학 단어 문제(MWPs)의 모음이다. 이 컴파일에는 26개의 고유한 방정식 모델이 있으며 각 문제는 평균 1.24개의 연산을 통합한다. SVAMP의 코퍼스 렉시콘 다양성(CLD)(Miao et al., 2020)이 ASDiv-A와 비교할 때 부족하지만 더 높은 수준의 난이도를 나타낸다. SVAMP의 제작자는 어휘 다양성이 MWP 데이터 세트에서 품질의 결정적인 척도라는 개념에 도전한다. SVAMP의 목표 관객은 초등학교 수준의 학생들이다.

#### 기하학적 문제 해결

GeoS(Seo et al., 2015)는 기하학에서 186개의 음영 영역 문제를 포함한다. 이 데이터 세트는 텍스트 이해와 다이어그램 해석을 결합합니다. 대조적으로, GeoShader(Alvin et al., 2017)는 102개의 음영 영역 문제를 포함하는 더 작은 데이터세트이다. 이러한 문제는 미국의 표준 수학 교과서에서 조달되고 인도 X급 시험에서 시험을 발표한다. 또 다른 벤치마크인 GEOS++(Sachan et al., 2017)는 SAT 시험의 스타일을 반영하는 1,406개의 질문을 포함하며, 6등급부터 10등급까지의 콘텐츠를 포함한다. 이 데이터 세트는 트레이닝(350개), 개발(150개), 및 테스트(906개) 서브세트로 세분화되어, 각 등급 레벨로부터의 질문의 균형 있는 표현을 보장한다. 저자는 훈련 및 개발 세트에서 주석이 달린 500개 질문에 대한 지상 진실 논리 양식을 제공한다. 마찬가지로 GEOS-OS (사찬과 싱, 2017)는 6-10학년 인도 고등학교 수학 교과서 집합에서 가져온 시연과 함께 2,235개의 기하 문제를 포함한다. 멀티 모달리티를 통합한 수치 추론 벤치마크로서 GeoQA(Chen et al., 2021)가 눈에 띈다. GeoQA에는 각각 주석이 달린 프로그램이 포함된 4,998개의 기하학적 문제가 포함된다. 특히 GeoQAsurpass는 GeoS(Seo et al., 2015) 및 GEOS++(Sachan et al., 2017)와 같은 기존 벤치마크를 크기 및 다양성 측면에서 평가한다.

UniGeo(Chen et al., 2022)는 기하학 문제에 대한 포괄적이고 대규모 벤치마크이다. 여기에는 GeoQA(Chen et al., 2021)에서 조달한 4,998개의 계산 문제와 9,543개의 추가 증명 문제가 포함된다. 증명 문제는 7.0:1.5:1.5의 비율로 열차, 검증, 테스트 세트로 나뉜다. 각 문제에는 다단계 증명을 구성하는 방식으로 이유와 수학적 표현이 표시된다. 모델 성능을 평가하기 위해 저자는 병렬, 삼각, 사각, 일치 및 유사성의 5가지 하위 작업을 정의하여 모델 기능에 대한 자세한 통찰력을 제공한다. 한편 Geometry3K(Lu et al., 2021)는 정형언어로 조밀한 주석이 있는 3,002개의 객관식 기하학 문제로 구성되어 있다. 이 데이터 세트는 두 개의 고등학교 교과서에서 제공되는 SAT와 같은 문제를 특징으로 하는 광범위한 기하학적 모양과 목표를 포함한다.

#### 4.2.2 _Math Question Answering Datasets_

AQuA 데이터세트(Ling et al., 2017)는 100,000개의 질문, 답변, 및 근거의 샘플로 구성되며, 근거 생성을 통한 프로그램 유도에 중점을 두고 있다. 데이터 세트의 각 질문은 문제 설명("질문"), 답변 "선택"( 객관식 형식), 정답에 도달하기 위해 사용된 "합리적인" 설명 및 "올바른 옵션"을 나타내는 라벨의 네 부분으로 나뉜다. AQuA 데이터세트(Ling et al., 2017)의 확장인 MathQA(Amini et al., 2019)는 완전히 특정된 운영 프로그램을 포함함으로써 이를 향상시킨다. MathQA에는 다양한 수학 영역에 걸쳐 있는 37,000개의 영어 객관식 수학 단어 문제가 포함되어 있다. 데이터 세트는 80/12/8% 분할 비율을 사용하여 훈련, 개발 및 테스트 세트로 무작위로 나뉜다. LLMs에 대해 구체적으로 맞춤화된, 어드밴스드 추론 벤치마크(Advanced Reasoning Benchmark; ARB)(Sawada et al., 2023)는 다수의 필드에 걸쳐 어드밴스드 추론에서 보다 도전적인 문제를 제공하도록 설계된다. ARB는 수학, 물리학, 생물학, 화학, 법과 같은 다양한 영역의 문제를 포함한다. 기존 벤치마크의 난이도를 뛰어넘는 벤치마크 역할을 하며 고급 추론 과제의 경계를 밀어내는 것이 목적이다.

IconQA(Lu et al., 2021)는 107,439개의 질문을 특징으로 하는 확장형 질문-응답 데이터세트이다. 여기에는 여러 이미지에서 선택하는 것, 다양한 텍스트 옵션에서 선택하는 것, 문장으로 빈칸을 완성하는 세 가지 별개의 하위 작업이 포함된다. 데이터세트는 6:2:2의 비율로 열차, 검증 및 테스트 세트로 분할된다. Icon645(Lu et al., 2021)는 377개의 클래스에 속하는 645,687개의 컬러 아이콘을 포함한다. 이러한 아이콘 기반 질문-답변 쌍은 시각적 추론과 상식적 추론을 포함한 다양한 추론 능력의 평가를 가능하게 한다. MultiHiertt(Zhao et al., 2022)는 Multi Hierarchical Tabular 및 Textual 데이터와 관련된 질문 및 답변을 중심으로 10,440개의 QA 쌍으로 전문적으로 주석이 달린 데이터세트이다. 이 데이터 세트는 다양한 재무 보고서에서 파생됩니다. 멀티히어트 내의 문서에는 상당한 비정형 텍스트와 함께 대부분 계층적인 여러 테이블이 포함되어 있다. 멀티히어트의 각 질문에 필요한 추론의 복잡성과 도전은 기존 벤치마크의 문제를 능가한다. 복잡한 수치적 추론을 강조하기 위해 추론 단계의 상세한 주석과 뒷받침하는 사실이 포함되어 있다.

Textual QA 데이터 세트의 영역에서, DROP(Discrete Reasoning Over the content of Paragraphs)(Dua et al., 2019)는 다양한 범위의 위키피디아 카테고리로부터 선별된 96,567개의 질문으로 구성되며, 특히 스포츠 게임 요약 및 역사적 서사에 중점을 둔다. 분산된 표현을 기호 및 이산 추론 기법과 결합하는 방법을 지원하는 것을 목표로 한다.

Tabular QA 데이터 세트로 넘어가면, WTQ(Wiki Table Questions) 또는 WikiTableQA(Pasupat and Liang, 2015)는 위키피디아에서 추출한 2,108개의 HTML 테이블에서 파생된 22,033개의 복잡한 질문-답변 쌍으로 구성된다. WTQ는 특히 반구조화된 테이블에 초점을 맞춘 질문-응답 태스크를 지원하도록 조정된다. 또한, WikiSQL(Zhong et al., 2018)은 단순 SQL 쿼리 및 단일 테이블에 집중한다. 이 데이터 세트에는 80,654개의 주의 깊게 주석이 달린 질문 및 해당 SQL 쿼리가 포함됩니다. 위키디아의 24,241개의 테이블에 걸쳐 있는 위키SQL은 크기가 비슷한 데이터 세트를 능가하는 상당한 규모를 자랑한다. 스파이더(Yu et al., 2018)는 복잡하고 교차 도메인 시맨틱 파싱 및 텍스트-대-SQL 챌린지에 맞게 조정된다. 이 데이터 세트는 200개 데이터베이스에 배포된 10,181개의 질문과 5,693개의 고유하고 복잡한 SQL 쿼리로 구성됩니다. 이 데이터베이스는 138개의 다른 도메인을 포함하는 여러 테이블로 구성되어 있습니다. 나아가, Yu 등(2018)은 스파이더 데이터셋을 이용하여 텍스트-투-SQL 문제를 위한 새로운 태스크를 제안한다. AIT-QA(항공사 산업 표 QA)(Katsis et al., 2022)는 항공 산업에 특정 초점을 두고 복잡하고 도메인별 표 QA 태스크에 맞게 조정된다. 결과 테스트 데이터세트는 116개의 테이블로부터 생성된 515개의 질문으로 구성된다. 이러한 표는 2017년에서 2019년 사이의 연도를 포괄하는 13개 항공사의 10-K 형태에서 선택된다. HiTab(Cheng et al., 2022)은 계층적 표에 특별히 맞춤화된 질문-답변(QA) 및 자연어 생성(NLG) 작업에 중점을 둔다. 이 교차 도메인 데이터 세트는 고유한 특성을 나타내는 풍부한 통계 보고서 및 위키피디아 페이지 모음으로 구성된다. 첫째, HiTab의 대부분의 테이블은 계층적이며 데이터 세트에 복잡성을 추가한다. 둘째, HiTab의 질문은 주석자에 의해 처음부터 생성되는 것이 아니라 분석자에 의해 작성되는 실제적이고 의미 있는 문장으로부터 수정된다. 마지막으로, 데이터 분석에서 복잡한 수치 추론을 밝히기 위해 수량 및 개체 정렬의 세밀한 주석이 제공된다. 데이터 세트는 3,597개의 테이블로 구성되며, 중복이 없는 트레인(70%), 디브(15%), 테스트(15%) 세트로 나뉜다.

Hybrid QA Dataset의 경우, HybridQA(Chen et al., 2020)는 이종 정보 소스에 대한 추론 능력에 도전하도록 설계된 포괄적이고 광범위한 질문-응답 데이터세트이다. 이 데이터 세트는 13,000개의 위키피디아 테이블과 정렬된 약 70,000개의 질문 응답 쌍을 포함한다. 다양하고 다양한 데이터 소스에서 정보를 추론하고 추출하는 능력을 평가하는 것을 목표로 한다. Free917(Cai and Yates, 2013)은 Freebase 데이터베이스 내의 81개 도메인으로부터 소싱된 917개의 질문으로 구성된다. 프리베이스는 광범위한 지식 도메인을 포괄하는 온라인, 사용자-기여, 관계형 데이터베이스이다. 데이터 세트에는 람다 미적분학 양식으로 주석이 달린 635개의 자유 염기 관계가 포함된다. 그러나 논리 양식에 대한 요구 사항으로 인해 Free917 데이터 세트는 논리 양식에 주석을 달 수 있는 전문 지식이 필요하기 때문에 확장하기가 어렵다. 대조적으로, WebQuestions(Berant et al., 2013)은 비전문가로부터 수집된 질문-답변 쌍을 포함한다. ATIS(Hemphill et al., 1990)와 같은 데이터 세트에 비해 더 많은 수의 단어 유형을 제시하여 어휘 매핑에 더 큰 어려움을 야기한다. 그럼에도 불구하고 웹 질문은 단항, 이진 및 엔터티로 구성된 많은 질문과 함께 보다 간단한 구조적 복잡성을 나타낸다. 이 데이터 세트는 5,810개의 질문-답변 쌍으로 구성된다. 질문은 Google Suggest API를 사용하여 수집되었으며 답변은 Amazon MTurk의 도움으로 Freebase에서 큐레이션되었다. WebQuestionsSP(WebQSP)(Yih et al., 2016)는 Freebase를 이용하여 답변 가능한 질문들에 대한 시맨틱 파싱들을 포함하는 WebQuestions(Berant et al., 2013)로부터 도출된다. 4,737개 질문에 대한 SPARQL 쿼리를 제공하여 프리베이스에서 직접 실행할 수 있습니다. WebQSP는 Free917(Cai and Yates, 2013)에 비해 크기가 더 크고 표준 Freebase entity 식별자를 갖는 SPARQL 형식의 시맨틱 파스를 제공한다. 읽기 이해(RC) 및 질문-답변(QA) 태스크를 평가하기 위해, 데이터세트 WebQ-Complex 또는 ComplexWebQuestions(Talmor and Berant, 2018)이 가치가 있음을 증명한다. 이는 광범위하고 복잡한 질문의 34,689개의 복잡한 예로 구성되며, 답변, 웹 스니펫 및 SPARQL 쿼리가 수반된다. 데이터 세트는 함수 구성, 연결, 최상급 및 비교와 관련된 더 복잡한 쿼리를 자동으로 생성합니다. MetaQA(MovicText Audio QA)(Zhang et al., 2017)는 단일 및 멀티-홉 추론 모두를 위해 설계된 400,000개 이상의 질문을 포함하는 포괄적인 데이터세트이다. 또한 텍스트 및 오디오 형식으로 보다 사실적인 버전을 제공합니다. MetaQA는 WikiMovies(Miller et al., 2016)에 확장되며 이에 대한 포괄적인 확장 역할을 한다. 이러한 데이터 세트, WebQuestionsSP(Yih et al., 2016), WebQComplex(Talmor and Berant, 2018), 및 MetaQA(Zhang et al., 2017)는 다양한 복잡성 및 도메인을 충족시키는 다양한 질의 응답 및 추론 작업에 귀중한 리소스를 제공한다.

단수 구절을 특징으로 하는 텍스트 중심 데이터 세트의 영역에서, 스탠포드 질문 응답 데이터 세트(SQuAD)(Rajpurkar et al., 2016)는 유의미한 독해 모음으로서 두드러진다. 여기에는 100,000개 이상의 질문이 포함되어 있으며, 모두 다양한 위키피디아 기사를 사용하여 크라우드 워커가 만들었습니다. SQuAD는 각 질문을 특정 읽기 단원과 고유하게 짝을 짓고, 각 질문에 대한 답은 해당 단원에서 직접 추출된 세그먼트이다. 데이터 세트는 536개의 논문에 걸쳐 총 107,785개의 질문-답변 쌍을 포함한다. SQuAD의 독특한 특징은 이 범주의 다른 데이터 세트와 달리 질문에 대한 미리 정의된 답변 선택이 없다는 것이다. 대신, 시스템은 구절 내의 가능한 모든 범위에서 답변을 선택해야 하며, 상대적으로 많은 수의 후보 답변을 처리해야 하는 과제를 제기한다.

오픈 도메인 텍스트 전용 데이터세트의 경우, TriviaQA(Joshi et al., 2017)는 65만 개 이상의 질문-답변-증거 트리플을 포함하는 또 다른 읽기 이해 데이터세트이다. 트리비아QA는 트리비아 애호가들이 기고한 95,000개의 질의응답 쌍으로 구성되어 있다. 또한 데이터 세트의 각 질문에 대해 평균 6개의 독립적인 증거 문서가 컴파일되어 질문 응답 지원의 품질을 향상시키는 강력한 원격 감독을 제공한다. 이것은 트리비아QA가 개방형 컨텍스트 내에서 질문을 이해하고 응답하는 시스템의 기능을 평가하는 데 귀중한 도구가 되도록 한다. HotpotQA(Yang et al., 2018)는 Wikipedia로부터 소싱된 113,000개의 질문-답변 쌍을 포함하는 데이터세트이다. 이를 위해 HotpotQA에 제시된 질문들은 다양한 증명문서를 기반으로 한 추론과 식별이 필요하다. 데이터 세트에는 확립된 지식 기반 또는 특정 지식 프레임워크에 국한되지 않는 광범위한 질문이 포함된다. HotpotQA는 추론 과정에 필요한 중요한 문장 수준의 뒷받침 사실을 제공한다. 이러한 수준의 세분성을 통해 QA 시스템은 강력한 감독으로 추론하고 예측에 대한 설명을 제공할 수 있다. 또한 HotpotQA는 새로운 유형의 팩토이드 비교 질문을 소개한다. 이러한 질문은 QA 시스템이 관련 사실을 추출하고 필요한 비교를 효과적으로 수행하는 능력을 평가한다. 이러한 네 가지 주요 기능을 통합하여 HotpotQA는 다중 문서 추론, 일반화, 설명 생성 및 팩토이드 비교에서 QA 시스템의 기능을 평가하기 위한 포괄적이고 도전적인 데이터 세트를 제공한다. Natural-QA(Kwiatkowski 등, 2019)는 구글 검색 엔진과의 상호작용으로부터 집계된 실제 익명화된 쿼리를 포함하는 질문-응답 데이터세트이다. Natural-QA에는 공개적으로 이용 가능한 총 307,373개의 훈련 사례가 포함되어 있다. 개발 데이터의 경우 5개의 가능한 답변으로 주석이 달린 7,830개의 예가 있다. 추가로, 테스트 데이터는 또한 5-방향 주석으로 주석된 또 다른 7,842개의 예들로 구성된다.

MultiModalQA(MMQA)(Talmor et al., 2021)는 텍스트, 테이블 및 이미지를 포함하는 여러 모달리티에 걸쳐 공동 추론에서 모델에 도전하도록 설계된 복잡한 질문-응답 데이터세트이다. 데이터 세트는 29,918개의 질문으로 구성되며 이러한 질문의 주목할만한 35.7%는 교차 모달리티 추론을 필요로 한다. GeoTSQA(Li et al., 2021)는 지리학의 도메인 내의 표형 시나리오 기반 질문 응답(TSQA) 태스크에 초점을 맞춘 데이터세트이다. 이 표 시나리오 내에서 맥락화된 1,012개의 실제 객관식 질문과 함께 556개의 시나리오로 구성된다.

정리QA(Chen et al., 2023)는 정리의 개념을 중심으로 하는 질문-답변 데이터세트이다. 수학, 물리, 전기 및 컴퓨터 과학(EE&CS), 금융 등 다양한 분야에 걸쳐 있는 350개의 정리를 포함하는 800개의 고품질 질문으로 구성된다. TAT-QA(Zhu et al., 2021)는 특히 금융의 영역에 초점을 맞춘 질문-답변 벤치마크 역할을 한다. 데이터 세트는 테이블과 텍스트 모두를 기반으로 질문에 답하는 모델의 능력을 평가한다. TAT-QA의 질문은 종종 산술 연산 수행, 계수, 값 비교 또는 정렬, 다중 추론 단계 결합과 같은 수치적 추론 기술을 필요로 한다. 벤치마크는 실제 재무 보고서에서 파생된 2,757개의 하이브리드 컨텍스트와 관련된 16,552개의 질문을 포함한다. 주가, 재무보고서, 은행거래, 환율 등 금융과 관련된 다양한 주제와 시나리오를 다루고 있다. FinQA(Chen et al., 2021)는 금융 데이터로 수치 추론 작업을 용이하게 하도록 특별히 설계된 데이터셋이다. 데이터 세트는 금융 계산을 중심으로 하는 8,281개의 질문-답변 쌍으로 구성된다. 중요한 것은 각 쌍에는 정답에 도달하는 과정에 대한 통찰력을 제공하는 자세한 추론 단계가 수반된다는 것이다.

#### Metrics

GeoS++(Sachan et al., 2017)는 공리 언급 클러스터링의 품질을 평가하기 위해 정규화된 상호 정보(NMI)(Strehl and Ghosh, 2002)를 사용한다. 주어진 MWP 코퍼스의 어휘 사용 다양성을 측정하기 위해, Miao 등(2020)은 BLEU의 사용을 소개하였다(Papineni 등, 2002). 그들은 또한 주어진 코퍼스의 어휘 다양성을 평가하기 위해 코퍼스 Lexicon Diversity(CLD) 메트릭을 제안했다(Miao et al., 2020). Chenget al.(2022)은 실행 정확도(EA)를 평가 메트릭으로 채택한다. 이 접근법은 정답이 있는 표본의 비율을 측정하는 Pasupat and Liang(2015)이 제안한 방법론을 따른다. GeoTSQA에 대한 TSQA 모델의 성능을 평가하기 위해 Li 등(2021)은 두 가지 표준 정보 검색 평가 메트릭인 평균 평균 정밀도(MAP)와 평균 상호 순위(MRR)를 사용한다. 이러한 메트릭은 표 시나리오를 기반으로 질문에 답할 때 모델의 검색 효과 및 순위 정확도에 대한 정량적 측정을 제공한다.

#### Logical Reasoning

4개의 주목할만한 논리적 추론 데이터 세트가 있다 : ProofWriter (Tafjord et al., 2021), PrOntoQA (Saparov and He, 2023), FOLIO (Han et al., 2022), 및 BIG-Bench (Srivastava et al., 2023).

ProofWriter (Tafjord et al., 2021)는 원래 RuleTaker D* 데이터 세트 (Clark et al., 2020)를 기반으로 하며 두 가지 추가 변형을 도입 합니다. 폐쇄 세계 가정(CWA) 변형은 부정과 관련된 사소한 불일치를 해결하는 반면, 개방 세계 가정(OWA) 변형은 추론 동안 개방 세계 가정을 통합한다. RuleTaker D* 데이터 세트(Clark et al., 2020)는 각각 100k 질문을 포함하는 5개의 하위 세트(D0, D1, D2, D3 및 D5)로 구성된다. PrOntoQA(Proof and Ontology-Generated Question-Answering)(Saparov and He, 2023)는 1차 논리로 표현된 합성 세계 모델에서 생성된 예를 포함한다. FOLIO(Han et al., 2022)는 광범위한 논리적 복잡성 및 다양성을 포괄하는 인간 주석이 달린 개방형 도메인 데이터세트이다. 1차 논리(FOL) 주석을 제공하며 1,435개의 예로 구성되어 있습니다. 또한 데이터 세트에는 결론의 유효성을 평가하기 위한 연역적 추론의 규칙 역할을 하는 487개의 전제 세트가 포함된다. BIG-Bench 내의 LogicalDuction 태스크(Srivastava et al., 2023)는 다단계 논리적 추론을 수행할 수 있는 능력을 평가하기 위한 평가 벤치마크 역할을 한다. 이 작업은 주어진 조건들의 최소 세트에 기초하여 객체들의 시퀀스의 순서를 추론하는 것을 포함한다. 각각의 인스턴스는 선반에 상이하게 색칠된 책들과 같은 3개 내지 7개의 유사한 객체들을 갖는 자연스럽게 정렬된 컨텍스트를 포함한다. 문맥과 함께, 일련의 간단한 단서들이 제공된다. 보다 관련 있는 데이터 세트와 해당 통계는 표 6에 나와 있다.

이러한 논리적 추론 데이터 세트는 논리적 추론 능력을 향상시키는 것을 목표로 하는 모델 및 시스템의 개발 및 평가에 기여한다. 그들은 합성 세계 모델에서 실제 상황에 이르기까지 다양한 시나리오와 과제를 제공하여 연구자들이 다양한 영역에서 논리적 추론을 탐색하고 발전시킬 수 있게 한다.

#### Causal Reasoning

Tubingen 원인-효과 쌍 데이터 세트(Mooij et al., 2016)는 기상학, 생물학, 의학, 공학, 경제학을 포함한 다양한 도메인에 걸쳐 있는 37개의 데이터 세트에서 얻은 108개의 원인-효과 쌍을 포함한다. 이 데이터 세트는 인과 추론 능력을 평가하기 위한 벤치마크 역할을 한다. 대조적으로, 신경병증성 통증 데이터세트(Neuropathatic Pain dataset, Tu et al., 2019)는 신경과 환자들에서 관찰되는 대응하는 증상들 사이의 관계에 초점을 맞춘다. 전문 의료 용어와 도메인별 지식으로 인해 이 데이터 세트 내의 변수 이름을 해석하려면 해당 분야의 전문 지식이 필요하다. 북극 해빙 데이터셋(Huang et al., 2021c)은 도메인 지식으로부터 도출된 그래프를 제시하며, 12개의 변수와 48개의 간선을 특징으로 한다. 북극 해빙의 역학에 대한 귀중한 통찰력을 제공합니다.

실제 인과 관계가 없는 경우에도 반사실적 추론은 언어 모델에 귀중한 능력이다. 원래 맥락에서 즉시 명백하지 않을 수 있는 숨겨진 통찰력을 의사 결정, 계획 및 밝히는 데 도움이 된다. CRASS(Counterfactual Reasoning Assessment)(Frohberg and Binder, 2021)는 반사실적 질의에 대한 언어 모델의 숙련도를 평가하기 위해 특별히 개발된 벤치마크이다. 이 벤치마크는 언어 모델이 반사실적 조건 질문과 함께 제시되는 275개의 인스턴스로 구성된다. 각각의 예에서, 모델은 제공된 객관식 옵션 세트로부터 가장 적합한 응답을 선택하는 임무를 부여받는다.

CRASS와 같은 인과 추론 벤치마크 및 데이터 세트에 대한 언어 모델의 성능을 평가할 때 일반적으로 사용되는 메트릭은 최고 정확도(k\)이다(Frohberg and Binder, 2021). 이 메트릭은 상위 \(k\) 순위 선택을 고려하여 올바른 예측을 할 수 있는 모델의 능력을 정량화한다. 모델의 인과 추론 과제에 대한 숙련도를 정량적으로 측정하는 역할을 한다. Percentage of Preference(Li 등, 2023g)는 반사실적 시나리오 및 사실적 시나리오 둘 다에서 논리적 완성들을 평가하기 위해 사용되는 메트릭이다. 이 메트릭은 언어 모델의 생성된 완성들이 논리적 일관성의 관점에서 인간의 선호 및 판단과 정렬되는 정도에 대한 정량적 측정을 제공한다.

#### Visual Reasoning

근거화된 문법 유도를 위한 벤치마크를 확립하기 위해, 연구자들은 PARTITT(Hong et al., 2021a)로 알려진 대규모 데이터세트를 큐레이션하였다. 이 데이터 세트는 3D 객체에 대한 파트 레벨 시맨틱스에 대한 상세한 설명을 제공하는 인간 작성 문장으로 구성된다. PTR(Hong et al., 2021b)은 시각적 추론 분석을 위해 맞춤화된 광범위하게 큐레이트된 데이터세트이다. 여기에는 약 70,000개의 합성 RGB-D 이미지가 포함되며, 각각 객체에 대한 상세한 지상 진실 데이터와 파트 레벨 주석이 수반된다. 이러한 주석은 공간 및 기하학과 같은 다양한 측면을 다룬다.

\begin{table}
\begin{tabular}{c|c|c|c|c|c|c} \hline \hline Dataset & Train Size & Dev size & Test size & Task Type & Synthetic & Type \\ \hline \(\alpha\)NLI & 169,654 & - & 1532 & NLI & ✗ & Abductive \\ Bhagavatula et al. (2019) & & & & & & \\ ProofWriter & 69,814 & 10,158 & 20,058 & FV & ✗ & Deductive \\ Tafjord et al. (2021) & & & & & & \\ FOLIO & & & & & & \\ Han et al. (2022) & & & & & & \\ LogicalDeduction & - & - & 1300 & FV & ✗ & Deductive \\ Srivastava et al. (2023) & & & & & & \\ PrOntoQA & - & - & 200 & MCQA & ✗ & Deductive \\ Saparov and He (2023) & & & & & & \\ \hline \hline \end{tabular}
\end{table}
표 6: 논리적 추론 Benchmarks Luo 등(2023d). 과제에는 객관식 질문 답변(MCQA), 자연어 추론(NLI), 사실 검증(FV)의 세 가지 유형이 있다.

관계, 의미 인스턴스 분할, 색상 속성 및 안정성과 같은 주요 물리적 속성입니다. PTR은 부분 기반 개념적, 관계적, 물리적 추론에 대한 연구를 용이하게 하도록 설계되었다. Compositional Language and Elementary Visual Reasoning (CLEVR)(Johnson et al., 2017)은 광범위한 시각적 추론 능력을 평가하는 널리 사용되는 진단 벤치마크이다. 렌더링된 이미지 10만 개와 자동으로 생성된 질문 약 100만 개로 구성되며, 고유 질문은 85만 3천 개입니다. CLEVR은 계수, 비교, 논리적 추론 및 기억 유지와 같은 작업을 포함하여 시각적 추론의 다양한 측면을 평가하기 위해 설계된 도전적인 이미지 및 질문 세트를 제공한다. 이 데이터 세트는 시각적 추론 알고리즘 및 모델을 테스트하고 발전시키기 위한 강력한 플랫폼을 제공하여 연구자들이 이 분야에서 그들의 능력을 탐색하고 향상시킬 수 있게 한다. Outside Knowledge Visual Question Answering(OK-VQA)(Marino et al., 2019)은 정확한 답변을 생성하기 위해 외부 지식의 활용을 필요로 하는 시각적 질문-답변 작업을 위해 특별히 설계된 데이터세트이다. 데이터 세트는 각각 5개의 지상 진실 답변과 관련된 14,055개의 개방형 질문으로 구성된다. 주석 처리 과정에서 질문은 위키피디아와 같은 출처의 정보와 같은 외부 지식이 모두 필요한지 확인하기 위해 신중하게 필터링되었다. 또한, 자주 발생하는 답변이 있는 질문을 줄임으로써 데이터 세트 편향을 완화하기 위한 노력을 기울였다. 이 데이터 세트는 시각적 질문-응답 작업에 외부 지식을 효과적으로 활용할 수 있는 방법을 개발하고 평가하는 데 귀중한 리소스 역할을 한다.

#### Audio Reasoning

오디오 추론의 다양한 측면에 대해 가장 널리 채택된 벤치마크 데이터세트, 즉 식별 태스크에 대한 음성 처리 범용 PERformance Benchmark(SUPERB)(Yang et al., 2021) 및 생성 태스크에 대한 향상된 음성 처리 범용 PERformance Benchmark(SUPERB-SG)(Tsai et al., 2022)가 섹션 3.6에 소개되었다. 이들 태스크에 대한 평가 메트릭은 표 7에 나열되어 있다.

\begin{table}
\begin{tabular}{c|c|c} \hline Tasks & Cat. & Evaluation Metric \\ \hline phone recognition & discr. & phone error rate (PER) \\ automatic speech recognition & discr. & word error rate (WER) \\ keyword spotting & discr. & accuracy (ACC) \\ query by example spoken term detection & discr. & maximum term weighted value (MTWV) \\ \hline speaker identification & discr. & accuracy (ACC) \\ automatic speaker verification & discr. & equal error rate (EER) \\ speaker diarization & discr. & diarization error rate (DER) \\ \hline intent classification & discr. & accuracy (ACC) \\ slot filling & discr. & F1-score and character error rate (CER) \\ \hline emotion recognition & discr. & accuracy (ACC) \\ \hline voice conversion & gen. & mel-cepstrum distortion (MCD) \\ speech separation & gen. & scale-invariant signal-to-distortion \\  & & ratio improvement (SI-SDRi) \\ speech enhancement & gen. & perceptual evaluation of speech quality (PESQ) \\  & & short time objective intelligibility (STOI) \\ \hline \end{tabular}
\end{table}
표 7: 오디오 추론 태스크의 메트릭. 여기서 "고양이"는 작업의 범주를 나타냅니다. “discr.”과 “gen.”은 차별적이고 생성적인 과제를 의미한다.

다양한 언어에서 데이터 세트의 가용성은 음성 표현의 자기 지도 학습(SSL)의 성공에 기여하며, 이는 오디오 추론의 중요한 기초를 제공한다. 기초 모델 사전 훈련을 위해 가장 크고 널리 활용되는 스피치 말뭉치 중 하나는 오디오북에서 유래한 영어로 약 60,000시간의 스피치를 포함하는 Libri-light(Kahn 등, 2020) 데이터세트이다. Didi Dictation 및 Didi Callcenter(Jiang et al., 2021)는 중국어로 이루어진 대규모 말뭉치로서, 각각 모바일 받아쓰기 애플리케이션 또는 전화 통화로부터 수집된 약 10,000시간의 데이터를 포함한다. 영어 및 중국어 외에도 VoxPopuli(Babu et al., 2022) (400,000시간, 23개 언어), 다국어 LibriSpeech(Pratap et al., 2020) (50,000시간, 8개 언어) 및 Common Voice(Ardila et al., 2020) (11,000시간, 76개 언어)를 포함하여 상당한 크기의 다국어 말뭉치도 사용할 수 있다. 일반적으로 사용할 수 있는 지상 진실 전사가 없기 때문에 이러한 데이터 세트를 사용하여 기존의 은닉 마르코프 모델(HMM) 및 감독 심층 신경망(DNN) 또는 종단 간(E2E) 모델을 훈련하는 것은 비현실적이다. SSL 기반 모델의 발전은 데이터의 힘을 활용하고 앞서 언급한 다운스트림 작업에 대해 라벨링된 데이터를 사용하여 추가 미세 조정을 위한 우수하고 보편적인 시작점을 제공한다.

#### Multimodal Reasoning

이들의 포괄적인 연구에서 Liu et al.(2023)은 다양한 텍스트 중심 과제에서 그들의 효능감에 초점을 맞추어 공개적으로 접근 가능한 멀티모달 모델에 대한 심층 평가를 수행했다. 이러한 작업에는 장면 텍스트, 예술 텍스트 및 필기 텍스트를 포함하는 텍스트 인식, 문서 텍스트, 장면 텍스트 및 이중 언어 텍스트를 포함하는 텍스트 기반 시각적 질문 응답, 영수증, 문서 및 영양 사실 라벨과 같은 다양한 출처에서 주요 정보 추출, 필기 수학적 표현의 인식이 포함된다. 이 연구는 이러한 모델에서 강점과 약점을 모두 확인했다. 의미적 이해를 통해 단어 인식에 뛰어나지만, 의미적 의미가 결여된 문자의 조합을 인지하는 데 어려움을 겪는다. 또한, 모델은 텍스트 길이에 관계없이 일관된 성능을 보이며 복잡한 이미지 세부 정보를 감지하는 데 제한된 기능을 가지고 있다. 전반적으로, 연구는 전통적인 텍스트 작업에서 가장 강력한 기존의 멀티모달 모델조차도 도메인 특정 방법에 비해 부족하다고 결론지었다. 이러한 결과는 복잡한 업무에서 제로샷 멀티모달 기법을 강화하고 모델 성능을 향상시키기 위한 혁신적인 전략의 필요성을 강조한다.

평가 벤치마크와 관련하여 Vedantam et al.(2015)은 PASCAL-50S와 ABSTRACT-50S의 두 데이터 세트를 도입하여 분야에 기여한다. 이러한 데이터 세트는 이미지 캡션 생성 방법을 평가하기 위해 설계되었다. 그들은 연구자들이 이미지 캡션 모델의 성능과 품질을 평가할 수 있는 귀중한 자원 역할을 한다. 이러한 데이터 세트를 활용하여 연구자들은 이미지 캡션 생성 기술을 발전시켜 이 연구 분야의 진보와 혁신을 촉진할 수 있다. LVLM-eHub(Xu 등, 2023)는 공개적으로 이용 가능한 대형 멀티모달 모델에 대한 포괄적이고 광범위한 평가 벤치마크 역할을 한다. 6가지 범주의 멀티모달 기능에 걸쳐 8개의 LVLM의 성능을 엄격하게 평가합니다. 평가 프로세스는 47개의 데이터 세트와 1개의 경기장 온라인 플랫폼의 활용을 포함하여 LVLM을 평가하기 위한 강력하고 표준화된 프레임워크를 제공한다. Odouard and Mitchell(2022)은 다양한 사례에 걸쳐 주어진 개념을 활용하는 AI 시스템의 숙련도를 평가하는 데 중점을 두고 체계적인 평가에 대한 개념 기반 접근법을 제시한다. 그들의 평가 접근법은 인용된 작업에 설명된 대로 RAVEN의 점진적 행렬(Raven and Court, 1938)과 추상화 및 추론 코퍼스(ARC)(Acquaviva 등, 2021)의 영향을 받는 두 가지 특정 도메인 내에서 사례 연구를 수행하는 것을 수반한다. 이는 AI 시스템에서 추상화 능력을 평가하고 발전시키는 데 자주 사용됩니다. 이 방법론은 AI 시스템의 추상적 추론 능력에 대한 이해와 적용에 대한 귀중한 정보를 제공하여 개념을 효과적으로 이해하고 활용하는 능력을 조명한다. 관련 연구에서 Yin et al.(2023)은 포인트 클라우드를 통합하여 MLLM(Multimodal Large Language Models)에 대한 연구를 확장하였다. 이들은 LAMM-Dataset과 LAMM-Benchmark를 도입하였으며, 특히 2D 이미지 및 3D 포인트 클라우드 이해 향상에 중점을 두었다.

환각은 잘 알려져 있는 문제이며 오랫동안 복합 기초 모델에도 존재했다. 최근 연구들(Dai et al., 2023; Li et al., 2023)은 객체 환각 측면에서 VLP(Visual Language Pretraining) 모델 및 VLMs(Vision and Language Models)의 성능을 조사하였다. Dai 등(2023)은 VLP 모델의 발전에도 불구하고 환각은 여전히 일반적인 문제로 남아 있음을 발견했다. 흥미롭게도 이 연구는 CIDEr(베단탐 등, 2015)과 같은 기존 메트릭에 대한 점수가 더 높은 모델이 더 불성실한 결과를 나타내는 경향이 있음을 보여주었다. 저자는 또한 패치 기반 기능이 더 작은 패치 해상도로 물체 환각을 줄이는 가장 좋은 결과를 산출한다는 것을 발견했다. 이 문제를 해결하기 위해 그들은 객체 마스크 언어 모델링(ObjMLM)(Dai 등, 2023)이라고 하는 간단하면서도 효과적인 VLP 손실을 제안했으며, 이는 객체 환각을 더욱 완화한다. 다양한 VLP 목표를 분리함으로써 저자는 환각을 줄이는 데 있어 토큰 수준의 이미지 텍스트 정렬 및 제어된 생성의 중요성을 입증했다. 유사하게, Li 등(2023)은 대표적인 VLMs에 대한 평가 실험을 수행하고 광범위한 대상 환각 문제를 발견하였다. 그들은 또한 시각적 명령어가 환각에 영향을 미칠 수 있다는 것을 발견했는데, 명령어에 자주 나타나거나 이미지 객체와 함께 발생하는 객체는 VLM에 의해 환각에 더 취약하다. 또한, 저자들은 기존의 평가 방법이 입력 지침과 VLM의 생성 스타일에 의해 영향을 받을 수 있음을 관찰했다. 이러한 문제를 해결하기 위해, 그들은 대상 환각을 보다 효과적으로 평가하기 위해 POPE(Polling-based Object Probing Evaluation)라는 개선된 평가 방법을 제안했다. Zhao et al.(2023)은 현실적인 시나리오와 고위험 시나리오에서 오픈 소스 대형 VLM의 견고성을 조사하기 위한 방법론을 제시했으며, 여기서 적대자는 제한된 블랙박스 시스템 액세스를 가지며 모델을 속여서 표적 응답을 생성하는 것을 목표로 한다. 저자는 CLIP(Radford et al., 2021) 및 BLIP(Li et al., 2022)와 같은 사전 훈련된 모델에 대해 표적화된 적대적 예제를 만드는 것으로 시작한다. 이들은 나중에 MiniGPT-4(Zhu 등, 2023), LLaVA(Liu 등, 2023), UniDiffuser(Bao 등, 2023), BLIP-2(Li 등, 2023), 및 Img2Prompt(Guo 등, 2023)를 포함하는 이러한 적대적 예들을 다른 VLM들에 전달한다. 저자는 대규모 VLM에서 표적 회피의 효과가 블랙박스 쿼리를 사용하여 크게 향상될 수 있음을 발견했다. 이 접근법은 표적 반응을 생성하는 데 놀라울 정도로 높은 성공률을 산출하여 적대적 공격에 대한 이러한 모델의 취약성을 강조한다. 또한, Huanget al.(2023c)은 합성 프롬프트를 처리하는 텍스트-이미지 생성 모델의 능력을 평가하기 위한 포괄적인 벤치마크인 T2I-CompBench를 소개한다. 이러한 T2I 모델이 속성 바인딩, 객체 관계, 복합 구도와 같은 구성 개념을 어떻게 해석하고 대표하는지 평가한다. T2I-CompBench는 또한 이러한 맥락에서 평가를 위해 멀티모달 LLM을 효과적으로 활용하는 것을 조사한다.

메트릭과 관련하여, DePlot(Liu et al., 2023b)는 테이블 유사도를 비교하기 위한 RNSS(Relative Number Set Similarity)라는 메트릭을 소개한다. RNSS는 열-n/행 순열의 영향을 받지 않고 남아 있는 동안 테이블의 구조와 숫자 값을 고려한다. Vedantam 등(2015)에 의해 소개된 바와 같이, CIDEr은 이미지 캡셔닝의 평가를 위한 자동화된 메트릭으로서 제시된다.

요약하면, 이러한 연구는 멀티모달 이해 분야에서 혁신적인 모델, 벤치마크 및 평가 메트릭의 개발에 기여한다. 그들은 시각적 명령어 추종, 차트 상의 추론, 객체 검출 및 이미지 관련 작업을 포함한 멀티모달 추론의 다양한 측면을 탐구한다. 제안된 접근법과 평가는 기존 모델의 장단점을 조명하고 멀티모달 기술에서 추가 발전의 필요성을 강조한다.

#### 3.10.8 Embodied Reasoning

RoboTHOR(Deitke et al., 2020)은 시뮬레이션 및 물리적 환경 모두에서 구현된 AI 에이전트를 개발하고 테스트하도록 설계된 플랫폼이다. VirtualHome(Puig et al., 2018)은 일반적인 가정 환경에서 발생하는 복잡한 활동을 모델링하는 데 초점을 맞춘 또 다른 플랫폼이다. 사람들의 집에서 볼 수 있는 다양한 활동을 다루는 프로그램 설명을 지원합니다. 깁슨(Xia et al., 2018)은 체화된 에이전트에 대한 실세계 인식을 강조한다. 시뮬레이션과 현실 사이의 갭을 메우기 위해, iGibson(Li et al., 2021a) 및 BEHAVIOR-1K(Li et al., 2022b)는 시뮬레이션 능력을 확장하여 보다 다양한 범위의 가정 과제를 포괄하고 높은 수준의 현실감을 달성한다. 이러한 플랫폼은 연구자에게 현실적인 시뮬레이션 환경에서 구현된 AI 접근법을 탐색하고 평가할 수 있는 도구를 제공한다. 해비타트(Manolis Savva* et al., 2019)는 싱글 스레드를 실행하더라도 초당 수천 프레임(fps)에 이를 정도로 높은 성능을 자랑한다. Habitat-Lab(Szot et al., 2021)은 체화된 AI의 영역에서 포괄적인 개발을 지원하는 고급 모듈형 라이브러리이다. 항법, 상호 작용, 지시 사항 따르기, 질문에 답하기 등 다양한 구현 AI 태스크의 사양을 가능하게 합니다. 이 플랫폼을 통해 연구자들은 특정 물리적 속성, 센서 및 기능을 가진 구현된 에이전트를 조정하고 확립된 메트릭을 사용하여 이러한 작업에 대한 성능을 평가할 수 있다.

이러한 시뮬레이션 플랫폼은 로봇 작업에 대한 LLM을 평가할 수 있는 큰 잠재력을 가지고 있다. 이러한 시뮬레이터를 활용함으로써 연구자들은 실제 시나리오의 맥락에서 LLM의 성능과 능력을 평가할 수 있어 구현된 AI 분야를 더욱 발전시킬 수 있다.

#### 3.10.9 자율 주행

DriveLM(DriveLM Contributors, 2023)은 다양한 측면에서 LLM의 역할을 조사하기 위한 포괄적인 운전 벤치마크이다. 이것은 설명 가능한 계획을 보장하고 안전한 결정을 내리기 위해 자율 주행에서 대형 언어 모델의 추론 능력을 도입한다. 인식, 예측, 계획 모듈에서 질문과 답변(QA)은 그래프 형식의 구조로 연결되며 QA 쌍은 노드로, 객체의 관계는 에지로 구성된다. DriveLM은 nuScenes QA(Qian et al., 2023) 및 HAD(Kim et al., 2019)와 같은 이전 연구와 비교하여 많은 장점을 도출하고 더 많은 작업과 다양한 시나리오에서 논리적 추론을 향상시킨다.

\begin{table}
\begin{tabular}{c|c|c} \hline \hline Dataset & Tasks & Size \\ \hline Swag Zellers et al. (2018) & Commonsense & 113,000 \\ PHYRE Bakhtin et al. (2019) & Commonsense & 25 \\ HellaSwag Zellers et al. (2019) & Commonsense & 70,000 \\ WinoGrande Sakaguchi et al. (2021) & Commonsense & 44,000 \\ Social IQA Sap et al. (2019) & Commonsense & 35,350 \\ PIQA Bisk et al. (2020) & Commonsense & 21,020 \\ SumEmdis Laban et al. (2023) & Commonsense & 6,348 \\ CConS Kondo et al. (2023) & Commonsense & 1,112 \\ \hline Alg514 Kushman et al. (2014) & Math & 514 \\ Verb395 Hosseini et al. (2014) & Math & 395 \\ Dolphin1878 Shi et al. (2015) & Math & 1878 \\ DRAW Upadhyay and Chang (2015) & Math & 1000 \\ SingleEQ Koncel-Kedziorski et al. (2015) & Math & 508 \\ Dolphin18K Huang et al. (2016) & Math & 18,000 \\ MATH Hendrycks et al. (2021) & Math & 12,500 \\ TabMWP Lu et al. (2022) & Math & 38,431 \\ GSM8K Cobbe et al. (2021) & Math & 8,500 \\ MGSM Shi et al. (2023) & Math & 250 \\ Math23K Wang et al. (2017) & Math & 23,161 \\ HMWP Qin et al. (2020) & Math & 5,491 \\ ASDiv Miao et al. (2020) & Math & 2,305 \\ VAMP Patel et al. (2021) & Math & 1,000 \\ GeoS Seo et al. (2015) & Math & 186 \\ GeoShader Alvin et al. (2017) & Math & 102 \\ GEO8+t Sachan et al. (2017) & Math & 1,406 \\ GEOS-OS Sachan and Xing (2017) & Math & 2,235 \\ GeoQA Chen et al. (2021) & Math & 4,998 \\ UniGeo Chen et al. (2022) & Math & 4,998 \\ Geometry3K Lu et al. (2021) & Math & 3,002 \\ AQuA dataset Ling et al. (2017) & Math & 100,000 \\ MathQA Amini et al. (2019) & Math & 37,000 \\ ARB Sawada et al. (2023) & Math (physics, biology, chemistry, law) & 1,207 \\ IconQA Lu et al. (2021) & Math & 107,439 \\ MultiHiertt Zhao et al. (2022) & Math & 10,440 \\ DROP Dua et al. (2019) & Textual QA & 96,567 \\ WTQ Pasupat and Liang (2015) & Textual QA & 22,033 \\ WikiSQL Zhong et al. (2018) & Textual QA & 80,654 \\ Spider Yu et al. (2018) & Textual QA & 10,181 \\ HybridQA Chen et al. (2020) & Hybrid QA & \(\sim\) 70,000 \\ MetaQA Zhang et al. (2017) & Hybrid QA & \(\sim\) 400,000 \\ SQuAD Rajpurkar et al. (2016) & Hybrid QA & \(\sim\) 100,000 \\ TriviQA Joshi et al. (2017) & Hybrid QA & 95,000 \\ HotpotQA Yang et al. (2018) & Hybrid QA & 113,000 \\ MMQA Talmor et al. (2021) & Hybrid QA & 29,918 \\ TheoremQA Chen et al. (2023) & Hybrid QA & 800 \\ TAT-QA Zhu et al. (2021) & Hybrid QA & 16,552 \\ FinQA Chen et al. (2021) & Hybrid QA & 8,281 \\ \hline \hline \end{tabular}
\end{table}
표 8: 일부 추론 데이터 세트 1의 요약

#### 3.10.10 Code Generation

코드 생성(Sun et al., 2021)은 코드 생성 및 평가의 고도화에 기여하는 여러 데이터 세트 및 벤치마크를 포괄한다. APPS 데이터세트(Hendrycks 등, 2021)는 코딩 경쟁으로부터 도출된 10,000개의 문제들로 구성된다. 자연어 서술에 의해 안내되는 코드 생성 업무를 평가하는 기준으로 기능한다. 이 데이터 세트는 연구자들이 자연어 프롬프트에 응답하여 코드를 생성하는 데 있어 모델의 효과를 측정하고 대조할 수 있는 플랫폼을 제공한다. 또한, 본 연구는 코드 생성을 위한 메트릭으로서 BLEU(Papineni et al., 2002)를 사용하는 것에 대한 우려를 강조하여, 그것이 가능할 수 있음을 시사한다

\begin{table}
\begin{tabular}{c|c|c} \hline \hline Dataset & Tasks & Size \\ \hline APPS Hendrycks et al. (2021) & Program Synthesis & 10,000 \\ HumanEval Chen et al. (2021) & Program Synthesis & 164 \\ MathQA-Python Austin et al. (2021) & Program Synthesis & 23,914 \\ MBPP Austin et al. (2021) & Program Synthesis & 974 \\ \hline \(\alpha\)NLI Bhagavatula et al. (2019) & Logical & 171,186 \\ ProofWriter Tafjord et al. (2021) & Logical & 100,030 \\ FOLIO Han et al. (2022) & Logical & 1,435 \\ PrOntoQA Saparov and He (2023) Srivastava et al. (2023) & Logical & 200 \\ LogicalDeduction Srivastava et al. (2023) & Logical & 1,300 \\ \hline Tübingen cause-effect pairs dataset Mooij et al. (2016) & Causal & 108 \\ Neuropathatic Pain dataset Tu et al. (2019) & Causal & N/A \\ Arctic sea ice dataset Huang et al. (2021) & Causal & N/A \\ CRASS Frohberg and Binder (2021) & Causal & 275 \\ \hline PARTIT Hong et al. (2021) & Visual & \(\sim\) 10,000 \\ PTR Hong et al. (2021) & Visual & 70,000 \\ CLEVR Johnson et al. (2017) & Visual & 100,000 \\ OK-VQA Marino et al. (2019) & Visual & 14,055 \\ \hline VoxPopuli Babu et al. (2022) & Audio & 400,000 hours \\ Libri-light Kahn et al. (2020) & Audio & 60,000 hours \\ Multilingual LibriSpeech Pratap et al. (2020) & Audio & 50,000 hours \\ Common Voice Ardila et al. (2020) & Audio & 11,000 hours \\ Didi Dictation Jiang et al. (2021) & Audio & 10,000 hours \\ Didi Callcenter Jiang et al. (2021) & Audio & 10,000 hours \\ \hline PASCAL-50S Vedantam et al. (2015) & Multimodal & 1,000 \\ ABSTRACT-50S Vedantam et al. (2015) & Multimodal & 500 \\ LVLM-eHub Xu et al. (2023) & Multimodal & 47 sub-dataset \\ LAMM-Dataset Yin et al. (2023) & Multimodal & 25 sub-datasets \\ \hline RoboTHOR Deitke et al. (2020) & Embodied & / \\ VirtualHome Puig et al. (2018) & Embodied & / \\ Gibson Xia et al. (2018) & Embodied & / \\ BEHAVIOR-1K Li et al. (2022) & Embodied & / \\ Habitat Manolis Savva* et al. (2019) & Embodied & / \\ \hline DriveLM DriveLM Contributors (2023) & Driving & 360,000 \\ nuScenes QA Qian et al. (2023) & Driving & 460,000 \\ HAD Kim et al. (2019) & Driving & 5,675 \\ \hline \hline \end{tabular}
\end{table}
표 9: 일부 추론 데이터 세트의 요약 2는 이러한 맥락에서 신뢰할 수 없다. 마찬가지로 HumanEval Chen 등(2021)은 164개의 필기 프로그래밍 문제로 구성되어 있으며, Codex Chen 등(2021)의 성능을 평가하기 위한 벤치마크 역할을 한다. HumanEval의 각 문제는 함수 서명, docstring, body, multiple unit test를 포함하며, 각 문제는 평균적으로 7.7개의 test를 가진다. MathQA-Python Austin 등(2021)은 MathQA Amini 등(2019) 벤치마크의 Python 버전이다. 복잡한 텍스트 설명으로부터 코드를 합성하는 모델의 능력을 평가하는 23,914개의 문제가 포함되어 있다. 특히, 이 연구는 인간의 자연 언어 피드백을 제공하는 것이 모델의 초기 예측에 비해 오류율이 크게 감소한다는 것을 발견했다. MBPP(Mostly Basic Programming Problems) 데이터세트 Austin 등(2021)은 엔트리-레벨 프로그래머들에 의해 해결 가능하도록 특별히 설계된 974개의 프로그래밍 작업들로 구성된다. MBPP에서는 루프 및 조건식과 같은 명령 제어 흐름 구조의 사용에 더 중점을 둔다. 한편, MathQA-Python Austin 등(2021)은 더 복잡한 자연어 기술들을 포함하고 있어, 문제 진술에서 더 높은 수준의 복잡성을 제공한다.

## 4 Foundation Model Techniques

이 섹션에서는 다양한 기초 모델 기술에 대한 간결한 개요를 제공한다. 여기서, 우리는 추론 기법들의 구별되는 카테고리들을 제시한다:

* 사전-훈련(섹션 4.1): 추론 기초 모델의 데이터 및 아키텍처 탐색.
* Fine-tuning (섹션 4.2): 추론 기초 모델의 Fine-tuning 데이터와 기법을 중심으로
* 정렬 트레이닝(섹션 4.3): 추론 기초 모델에 의해 사용되는 정렬 기술을 조사한다.
* 혼합물-전문가(섹션 4.4): 추론의 맥락에서 혼합물-전문가 기술을 도입한다.
* 문맥내 학습(섹션 4.5): 추론 기초 모델에서 문맥내 학습을 도입한다.
* 자율 에이전트(섹션 4.6): 여러 태스크에 대한 에이전트로서 추론 기반 모델을 중심으로

### Pre-Training

사전 훈련 부분에서 LLM은 필수적인 언어 이해와 생성 기술을 습득할 수 있다. 여기서 데이터 및 아키텍처는 기초 모델에 매우 중요합니다. 따라서, 우리는 다음 섹션에서 그것들을 논의할 것입니다.

#### 4.1.1 데이터 원본

기초 모델은 데이터 기반이며 데이터의 품질과 양은 기초 모델 개발의 핵심에 있습니다. 그림 14는 기초 모형 사전 훈련을 위한 세 가지 광범위한 유형의 데이터 소스를 제시한다.

#### Text Data

공개적으로 액세스할 수 있는 대규모 텍스트 데이터 세트의 영역은 상당한 확장을 보여 무수한 애플리케이션을 위한 풍부한 다양한 리소스를 제공했다. 대표적인 예로는 825GB의 인상적인 볼륨으로 주목할 만한 광범위한 영어 텍스트 코퍼스인 Pile(Gao et al., 2020)이 있으며, 특히 대규모 언어 모델의 훈련을 용이하게 하기 위해 선별되었다. 이 코퍼스는 다양성과 품질로 인정받는 22개의 다양한 하위 집합으로 구성되어 있으며 기존 콘텐츠와 새로 생성된 콘텐츠를 모두 통합하며 상당한 부분이 학술 및 전문 도메인에서 제공된다. 이 데이터의 상당 부분은 커먼 크롤 프로젝트와 유사한 웹 크롤링 이니셔티브를 통해 축적된다. 이러한 웹 크롤링은 위키피디아 항목과 같은 고구경 자료에서 스팸 이메일과 같은 하위 계층 콘텐츠에 이르기까지 다양한 콘텐츠를 생성하므로 데이터 품질을 높이기 위해 엄격한 필터링 및 처리가 필요하다는 것을 인정하는 것이 중요하다. 이 분야의 또 다른 주목할만한 데이터 세트는 다양한 부문에서 광범위하게 활용되는 커먼 크롤 웹 코퍼스의 확장적이고 정제된 버전을 나타내는 C4 데이터 세트(Raffel et al., 2019)이다. 대조적으로, ROOTS 데이터세트(로렌콘 등, 2022)는 3개의 매크로 지역 및 9개의 언어 패밀리로부터 유도된, 1.6TB를 포괄하고 46개의 자연 언어에 걸쳐 59개의 언어에 걸쳐 거대한 리소스로 등장한다. 또한 Java, PHP 및 C++가 대부분의 콘텐츠를 포함하는 13개의 프로그래밍 언어로 된 자료를 포함한다. 구텐베르크 프로젝트(라히리, 2014)는 142명의 저자가 3,036권의 영어책을 선정한다. 더 큰 프로젝트 Gutenberg 코퍼스의 하위 집합인 이 컬렉션은 메타데이터, 라이선스 세부 정보를 제거하기 위해 부지런히 정리되었습니다.

도 14: 주로 텍스트 데이터, 이미지 데이터 및 멀티모달리티 데이터를 포함하는 사전 트레이닝 기초 모델을 위한 다양한 데이터 소스 및 데이터 세트 세트.

그리고 필사자의 노트를 최대한으로 기록합니다. CLUECorpus Xu 등(2020)은 실질적인 100GB 자원으로서 중국 텍스트 도메인에서 두드러진다. 이 커뮤니티 주도 프로젝트는 단일 문장/문장 쌍 분류에서 기계 읽기 이해에 이르기까지 9가지 다양한 작업을 통합하며 모두 정통 중국 텍스트에 뿌리를 두고 있다. 추가적으로, 인상적인 80억 토큰들을 갖는 Proof-Pile 데이터세트 Azerbayev 등(2023)은 수학적 텍스트 영역에서 주목할 만하다. 일반 수학 분야에 특별히 조정된 소수의 오픈 소스 언어 모델 중 하나로 구별된다. 약 4천만 개의 오픈액세스 학술논문으로 구성된 peS2o 데이터셋 Soldaini and Lo(2023)는 매우 귀중한 자산이다. 철저한 청소, 필터링, 포맷을 거쳐 언어 모델을 사전 훈련하는 데 이상적입니다. 시맨틱 학술지 오픈 리서치 코퍼스(S2ORC)를 기반으로 학술 텍스트 자원의 가용성을 확장한다. 나아가, 연구자들은 Reddit corpus Roller 등(2020)과 같이 다양한 공개 대화 데이터셋에 접근할 수 있다. 온라인 소셜 미디어 플랫폼의 데이터는 또한 풍부한 대화 콘텐츠를 제공합니다. 과학 텍스트 컬렉션은 일반적으로 아르시브 논문, 과학 교과서, 수학적 웹사이트 및 관련 과학 자료와 같은 자료를 집계하는 데 중점을 둔다. 종종 수학적 기호와 단백질 서열이 포함된 과학적 데이터의 복잡한 특성은 언어 모델에 의한 표준화와 균일한 처리를 위해 전문화된 토큰화 및 전처리 방법을 필요로 한다. 최근 연구 Austin 등(2021)은 광범위한 코드 코퍼라에 대한 LMM(Large Language Models) 트레이닝의 이점을 강조하여, 생성된 프로그램 품질의 현저한 향상으로 이어진다. 이러한 말뭉치는 StackOverflow 및 GitHub와 같은 플랫폼에서 자주 공급됩니다. 마지막으로, 레드파자마 프로젝트 컴퓨터(2023)는 인상적인 1조 2천억 개의 토큰을 포함하는 LLaMA의 훈련 데이터 세트를 재현한 놀라운 업적에 대해 언급할 가치가 있다. 이 데이터 세트에는 CommonCrawl, C4, GitHub, Books, ArXiv, 위키피디아 및 StackExchange의 방대한 토큰 배열이 포함되어 있어 언어 모델의 개발 및 개선을 위한 포괄적이고 다양한 리소스를 제공한다.

#### Image Data

이미지넷 Deng et al. (2009) 및 ImageNet21K Ridnik et al. (2021)과 같은 광범위한 인간 큐레이트 데이터 세트를 사용하여 감독된 사전 훈련 방법론은 전달 가능한 시각적 표현을 개발하는 데 널리 퍼진 접근법이 되었다. 이 프로세스는 각각 특정 시각적 개념에 대응하는 입력 이미지와 별개의 라벨 사이의 연계를 생성하도록 구조화된다. 대규모 사전 훈련에 대한 필요성이 증가함에 따라 월드 와이드 웹에서 제공되는 이미지-텍스트 쌍으로부터 많은 양의 시끄러운 라벨의 생성이 점점 더 관련성이 높아졌다. 이러한 노이즈 레이블을 활용하여 수많은 선도적인 산업 연구소는 반자동 데이터 파이프라인을 사용하여 방대한 분류 데이터 세트를 능숙하게 조립했다. 그러한 노력들의 주목할만한 예들은 JFT Sun 등(2017) 및 I2E Wu 등(2023)을 포함한다. 또한 인스타그램 해시태그 싱 등(2022)과 같은 독점 데이터 소스를 활용하여 데이터 세트를 더욱 풍부하게 하고 사전 훈련된 모델의 정밀도를 높였다. 이 전략은 정교한 시각 인식 시스템의 발전에 크게 기여하여 광범위한 시각 개념과 대상을 효과적으로 식별하고 분류할 수 있는 능력을 갖추었다.

#### Multimodality Data

대규모 데이터 세트의 도메인에는 몇 가지 주목할 만한 예가 있다. SBU(Ordonez et al., 2011)는, 예를 들어, 광범위한 수의 플리커 질의를 실행한 다음, 결과를 엄격하게 필터링하여 시각적으로 적절한 캡션과 각각 쌍을 이루는 100만 개의 이미지를 생성한다. 반대로, RedCaps(Desai et al., 2021)는 Reddit로부터 소싱된, 1200만 이미지-텍스트 쌍을 포괄하는 실질적인 데이터세트이다. WIT 데이터세트(Srinivasan 등, 2021)는 3,760만 이미지-텍스트 인스턴스의 큐레이트된 컴파일, 엔티티 정보로 강화된, 108개의 위키피디아 언어를 커버하고, 1,150만 개의 고유한 이미지를 통합함으로써 구별된다. 이 분야의 다른 비교적 큰 데이터 세트는 Shutterstock(Nguyen et al., 2022), LAION-400M(Schuhmann et al., 2021), 및 COYO-700M(Byeon et al., 2022)을 포함한다. 오픈AI의 CLIP(래드포드 등, 2021)는 웹에서 꼼꼼하게 조달한 4억 개의 이미지-텍스트 쌍의 인상적인 컬렉션을 통해 정제됐다. 최근 10억 규모 수준의 데이터셋의 출현이 관측되고 있다. 예를 들어, LAION-5B 데이터세트(Schuhmann 등, 2022)는 58억 5,000만 개의 CLIP 필터링된 이미지-텍스트 쌍을 포함하며, 그 중 23억 2,000만 개는 영어이다. DataComp(Gadre et al., 2023)는 Common Crawl로부터 수집된 128억 이미지-텍스트 쌍의 새로운 풀에 초점을 맞추어 데이터셋 실험을 위한 플랫폼으로 기능한다. 플라밍고(Alayrac et al., 2022)는 MultiModal MassiveWeb(M3W) 데이터셋을 소개하고, 약 4300만 웹페이지의 텍스트와 이미지를 집계하고, DOM(Document Object Model)에 따라 이미지와 텍스트를 정렬한다. 이러한 맥락에서 주목할 만한 프로젝트는 ImageBind(Girdhar et al., 2023)이며, 이는 이미지, 텍스트, 오디오, 깊이, 열 및 IMU 데이터를 포함하는 6개의 별개의 모달리티를 커버하는 공동 임베딩을 개발하는 것을 목표로 하며, 포인트 클라우드와 같은 다른 모달리티로의 잠재적인 확장을 포함한다(Guo et al., 2023). 이 야심찬 노력은 다양한 데이터 유형에 걸쳐 의미 있는 연결을 설정함으로써 멀티모달 데이터에 대한 더 깊은 이해를 촉진하는 데 중요한 진전을 의미한다. 멀티모달 학습이 발전함에 따라 데이터셋 생성 및 응용 분야의 이러한 발전은 현장의 지속적인 혁신에 매우 중요하다.

#### 추론을 위한 데이터

기초 모델의 추론 능력을 향상시키는 데 있어 코드와 종이 데이터의 중요성이 무엇보다 중요하다. 코드 데이터를 먼저 논의한 CoCoGen(Madaan et al., 2022)의 연구는 구조화된 상식 추론 작업을 코드 생성 문제로 접근할 때, 코드에 대한 사전 학습된 언어 모델(LMs)이 자연어에 대해 학습된 언어에 비해 우수한 추론 능력을 보인다는 것을 나타낸다. 이것은 소스 코드가 포함되지 않은 작업에도 적용됩니다. 이러한 코드 데이터는 GitHub 및 일반 사용자가 사용할 수 있는 다양한 필터링된 데이터 세트를 통해 쉽게 액세스할 수 있습니다. 이를 강조하여, StarCoder(Li et al., 2023)는 코딩에서 LM의 숙련도를 더욱 정교화하기 위해 광범위한 사전 트레이닝 데이터세트(783GB)를 출시하였다. 논문 데이터의 측면에서, Galactica(Taylor et al., 2022)는 과학 논문, 참고 자료, 지식 베이스 및 기타 다양한 출처의 방대한 코퍼스에 대해 훈련된 것이 눈에 띈다. 이 모델은 기존 모델에 비해 과학 과제의 스펙트럼에 걸쳐 우수한 성능을 보여준다. 논문 데이터는 주로 Arxiv와 같은 학술 플랫폼에서 비롯되며 수학 논문에 주목할 만한 중점을 둔다. 또한, 시맨틱 학술지 오픈 리서치 코퍼스(S2ORC)의 4천만 개 이상의 오픈 액세스 학술 논문을 포함하는 peS2o(Soldaini and Lo, 2023) 데이터 세트는 모델의 사전 훈련을 위한 상당한 자원을 제공한다.

#### 4.1.2 네트워크 아키텍처

기초 모델 아키텍처는 필수적입니다. 우리는 다음에서 다양한 네트워크 아키텍처에 대해 논의하고 그림 15에 보여준다.

인코더-디코더 아키텍처 Vaswani 등(2017)에 의해 묘사된 바와 같이, 정액 트랜스포머 모델은 인코더-디코더 프레임워크에 기초한다. 이 패러다임은 트랜스포머 블록들의 이중 스택들을 채용하며, 여기서 하나는 인코더로서 기능하고 다른 하나는 디코더로서 기능한다. 인코더 페이즈는 입력 시퀀스 내의 고유 정보를 디코딩하기 위해 적층 배열로 멀티-헤드 셀프-어텐션 계층들을 활용하는 것을 포함하고, 이에 의해 잠재 표현들을 산출한다. 후속 단계에서, 디코더는 이러한 표현들에 교차-주의 메커니즘들을 적용하여, 타겟 시퀀스의 생성을 용이하게 한다. 이 혁신적인 아키텍처는 신경망 기계 번역과 같은 시퀀스 대 시퀀스 모델링 작업에 광범위하게 적용된다. 독특한 접근법에서, BERT(Kenton and Toutanova, 2019)는 라벨이 없는 텍스트로부터의 깊은 양방향 표현의 사전 훈련을 위해 엔지니어링된다. 모든 계층에 걸쳐 왼쪽 및 오른쪽 컨텍스트를 동시에 고유하게 처리하므로 과도한 NLP 작업에 대해 예외적으로 다재다능합니다. 반대로, BART(Lewis et al., 2020)는 신경망 기계 번역을 위한 종래의 Transformer-based 아키텍처를 통합한다. 그 구조가 간단해 보일 수 있지만, BART는 BERT의 양방향 인코더와 GPT의 단방향, 좌-우 디코더를 다른 고급 사전 훈련 방법론과 병합하는 BERT의 진화로 간주될 수 있다. 또한, T5(Raffel et al., 2019)에 의해 예시된 인코더-디코더 아키텍처 패러다임에 따른 사전 훈련 언어 모델(Pre-trained Language Models, PLM)은 광범위한 NLP 태스크에 걸쳐 지속적으로 놀라운 성능을 보여주었다.

도 15: Encoder-Decoder 프레임워크(왼쪽) 및 Decoder-Only 프레임워크(오른쪽)의 일러스트레이션. 상기 수치는 (Fu 등, 2023c)로부터 크레딧된다.

#### Decoder-only Architecture

디코더 전용 아키텍처는 각 입력 토큰이 자신을 포함하여 선행 토큰에 배타적으로 주의를 기울이도록 보장하는 중추 요소인 어텐션 마스크를 전략적으로 사용하는 것이 특징이다. 이러한 독특한 구성은 선행 토큰으로부터 디코더 내의 현재 토큰으로의 정보의 단방향 흐름을 용이하게 하여, 입력 및 출력 토큰의 처리를 효율화한다. 이 접근법은 학습 메커니즘을 단순화할 뿐만 아니라 모델의 일관성과 일관성을 강화한다. 언어 모델링의 도메인에서, GPT(Generative Pre-trained Transformer) 시리즈는 디코더 전용 아키텍처를 전형화한다. 이 시리즈는 GPT-1(래드포드 등, 2018), GPT-2(래드포드 등, 2019), 및 현저하게 진보된 GPT-3(브라운 등, 2020)을 포함한다. GPT-3은 특히 LMM(Large Language Models)의 구별되는 특징인 인-컨텍스트 학습에서 아키텍처 효과를 예시하는 이 패러다임 내에서 필수적인 모델 역할을 한다. 디코더 전용 아키텍처의 영향은 GPT 계통을 초월하여 LLM의 광범위한 분야에 상당한 영향을 미친다. 수많은 최첨단 언어 모델들이 이러한 아키텍처 프레임워크를 그들의 기반 구조로 채택했다. 예를 들어, OPT(Zhang 등, 2022)는 칭찬할 만한 자연어 이해 능력을 달성하기 위해 디코더 전용 아키텍처를 채용한다. 고퍼(Rae et al., 2021)는 또한 이러한 단방향 흐름을 활용하여 언어 모델링 작업의 복잡성과 규모를 높인다. 또한, 디코더 전용 아키텍처는 BLOOM(Scao et al., 2022)과 같은 모델의 진화에 중요한 역할을 했으며, 이는 컨텍스트 이해가 필요한 작업에 단방향 정보 흐름을 활용한다. LLaMA(Touvron et al., 2023) 및 그의 후속인 LLaMA-2(Touvron et al., 2023)는 언어 모델링의 발전을 추진하기 위해 이러한 아키텍처 스타일을 통합하여 다양한 NLP 벤치마크에 걸쳐 놀라운 성능을 달성했다. GLM(Zeng et al., 2022)은 언어 이해 태스크의 범위에서의 디코더 전용 아키텍처의 효능을 더욱 강조하여, 언어 모델링의 현대 풍경에서의 그의 중요한 역할을 강조한다.

#### CLIP Variants

CLIP(Radford et al., 2021)는 이미지 인코더와 텍스트 인코더를 동시에 트레이닝하여 \(<\)이미지, 텍스트\(>\) 쌍의 집합 중 올바른 쌍을 추론하는 혁신적인 접근법을 사용한다. 이 전략은 그것의 학습 과정의 기초를 형성한다 대조적으로, FILIP(Yao et al., 2021)는 교차-모달 후기 상호작용 메커니즘을 통합함으로써 더 미세한 입도에서 정렬을 향상시킨다. 이 메커니즘은 시각적 토큰과 텍스트 토큰 사이의 토큰별 최대 유사성 측정을 사용하여 대조적인 목표에 대한 지침을 제공하여 보다 정확한 정렬을 초래한다. FLIP(Li et al., 2023)는 이미지 패치의 상당 부분을 랜덤하게 마스킹하고 제거하는 것을 포함하는 획기적인 트레이닝 기법을 소개한다. 이 접근법은 동일한 벽-시계 시간 내에 학습될 수 있는 이미지-텍스트 쌍의 수를 증가시켜 메모리 사용량을 크게 증가시키지 않으면서 반복당 더 많은 샘플을 대조할 수 있게 한다. 언어 인코더 측에서, K-Lite(Shen et al., 2022)는 대조적 사전 훈련을 위해 원래 alt-text와 조합하여 엔티티에 대한 Wiki 정의의 형태로 외부 지식을 통합하는 것을 제안한다. 경험적 증거는 이러한 방식으로 텍스트 설명을 풍부하게 하면 CLIP 성능이 향상된다는 것을 나타낸다. LaCLIP(Fan et al., 2023)는 대형 언어 모델들의 인-컨텍스트 학습 능력을 활용하여 그들의 연관된 이미지들에 대한 텍스트 설명들을 재작성함으로써, 설명들을 시각적 콘텐츠와 더 효과적으로 정렬함으로써 모델의 성능을 더욱 향상시킨다. DetCLIP는 Yao 등(2022)에 소개된 바와 같이, 오픈 월드 검출을 위한 병렬 시각-개념 사전-훈련에서의 선구적인 접근법을 나타낸다. 세심하게 만들어진 개념 사전의 지식 강화를 활용합니다. 한편, 그의 후속인 DetCLIPv2(Yao et al., 2023)는 대조적인 목적을 지향하기 위해 지역 제안과 텍스트 단어 사이의 최대 단어-지역 유사성을 활용한다.

#### Other Architectures

전통적인 변압기 구조는 종종 2차 계산 복잡도에 의해 제한된다. 이를 해결하기 위해 최근 연구는 보다 효율적인 언어 모델링 아키텍처를 개발하는 데 초점을 맞추고 있다. S4 모델(Gu et al., 2021)은 상태 매트릭스를 조건화하기 위해 저순위 보정을 적용함으로써, 그것의 대각화를 안정화시키고 Cauchy 커널과 유사한 동작들에 대한 상태 공간 모델(SSM)의 복잡성을 감소시킴으로써 혁신적인 솔루션을 제공한다. 유사하게, GSS(Mehta et al., 2022)는 현저하게 더 빠른 트레이닝 시간의 이점을 갖는, S4 및 DSS(Gupta et al., 2022) 모델에 대한 설득력 있는 대안으로서 등장한다. 대조적으로, H3(Dao et al., 2022)는 시퀀스에서 이전 토큰을 리콜하고 시퀀스에 걸쳐 토큰을 비교하는 것과 같은 특정 기능에서 탁월하도록 설계되어 플래시코프의 통합을 통해 효율성을 더욱 향상시킨다. 주의 메커니즘에 대한 아차적 대안을 탐색하는 사람들에게, 하이엔라(Poli et al., 2023)는 주목할 만한 해결책을 제공한다. 이 모델은 암묵적으로 매개변수화된 긴 컨볼루션을 데이터 제어 게이팅과 결합하여 제작되어 계산 요구 사항을 크게 줄인다. RWKV(Peng et al., 2023)는 선형 주의 메커니즘을 활용하여 모델이 Transformer 또는 RNN 중 하나로서 기능할 수 있게 한다. 이 접근법은 훈련 동안 병렬화된 계산을 용이하게 할 뿐만 아니라 추론 동안 일정한 계산 및 메모리 복잡성을 보장하여 수백억 개의 매개변수로 확장 가능한 최초의 비변환기 아키텍처로 표시한다. RetNet(Sun et al., 2023)은 훈련 병렬성, 비용 효율적인 추론, 및 강건한 성능 사이에서 최적의 균형을 맞추는 또 다른 중요한 기여를 나타낸다. LongNet(Ding et al., 2023)은 토큰들 사이의 거리가 증가함에 따라 어텐션 필드를 상당히 넓히는 기법인 확장 어텐션을 도입하여 시퀀스 길이를 10억 개 이상의 토큰으로 효과적으로 스케일링할 수 있게 한다. 마지막으로, Streaming-LLM(Xiao et al., 2023)은 유한 길이의 주의 윈도우로 훈련된 언어 모델(LLM)이 추가적인 미세 조정 없이 무한한 시퀀스 길이에 적응할 수 있게 하는 효율적인 프레임워크를 제시한다. 이 돌파구는 이러한 모델의 시퀀스 길이 능력을 400만 토큰으로 확장했다.

### Fine-Tuning

대규모 언어 모델(LLM)이 사용하는 기본 전략은 광범위한 일반 도메인 데이터에 대한 사전 훈련 개념을 중심으로 한 다음 특정 작업 또는 도메인에 맞게 모델을 사용자 지정하는 것이다. 이 접근법은 LLM에 언어 패턴에 대한 포괄적인 이해를 부여하여 자연어 이해, 생성 및 번역을 포함한 광범위한 다운스트림 작업에 걸쳐 성능을 후속적으로 미세 조정할 수 있게 한다. 적응 과정은 LLM이 이전에 습득한 지식을 활용하여 새로운 사례에 적용할 수 있도록 권한을 부여하기 때문에 이러한 특정 작업에서 예외적인 결과를 달성하는 데 가장 중요한 의미를 갖는다. 적응 과정은 사전 훈련된 모델의 철저한 미세 조정부터 과제별 레이어 또는 모듈의 통합, 지식 증류와 같은 전이 학습 방법의 활용에 이르기까지 다양한 기술을 포함한다.

#### 4.2.1 데이터 원본

_Benchmark Data_

데이터 수집 과정의 자연스러운 단계는 기존 NLP 벤치마크의 적응을 수반한다. 이러한 벤치마크가 오픈 소스라는 점을 감안할 때 연구자들은 모델의 추론 능력을 강화하기 위해 추론 벤치마크를 활용하는 것이 더 편리하고 비용 효율적이라고 생각한다. 그러나 벤치마크의 양과 규모 측면에서 벤치마크의 가용성에 대한 문제가 발생하며, 새로운 벤치마크의 수동 생성은 자원 집약적인 작업임을 증명한다. 이 문제를 해결하기 위해 연구자들은 고급 언어 모델을 사용하여 추론 합성을 위한 미세 조정 데이터를 생성하는 전략을 고안하고 있다.

_Synthesis Data_

이 섹션에서는 고급 언어 모델(LLM)을 활용한 추론 데이터 합성을 조사하고 생성된 데이터를 미세 조정을 위해 활용한다. 본 연구의 핵심은 CoT 기법을 LLM에 적용하여 추론 경로를 생성하는 것이다. 이어서, 생성된 데이터는 모델 미세 조정을 위해 레버리지된다(Fu et al., 2023; Hsieh et al., 2023; Huang et al., 2022; Li et al., 2022; Magister et al., 2023). 또한 Ho 등(2022)에 의해 소개된 Finetune-CoT 방법은 LLM에서 여러 추론 경로를 샘플링하여 올바른 추론 경로를 가진 학생 모델을 미세 조정하는 데 사용된다. Hsieh 등(2023)에 의해 제안된 증류 단계 접근법은 (a) LLM을 능가하는 더 작은 모델을 훈련하는 것과 (b) 미세 조정 또는 증류를 위한 감소된 훈련 데이터 요구 사항으로 이러한 위업을 달성하는 두 가지 주요 목적을 가진 새로운 메커니즘을 소개한다. 또한, Huang 등(2022)에 자세히 설명된 자기 개선 접근법은 연쇄 사고 프롬프팅 및 자기 일관성을 사용하여 레이블이 지정되지 않은 질문에 대한 가장 높은 신뢰도를 가진 근거 강화 답변의 선택을 포함한다. 그 후, LLM은 질문 및 지상 진실 라벨을 LLM에 공급하여 추론 경로를 프롬프트하는 추가 단계와 함께 이러한 자체 생성 솔루션을 목표 출력으로 사용하여 미세 조정된다. 대안적인 접근법은 LLM의 시연으로서 인간-기록된 설명과 함께 여러 예를 활용하는 것을 포함하고, 이어서 트레이닝 세트에 대한 설명의 생성이 뒤따른다(Li 등, 2022). 특히, 본 연구는 더 큰 교사 모델에 의해 생성된 사고 출력의 사슬을 기반으로 학생 모델을 미세 조정하여 산술, 상식 및 상징 추론을 포함한 다양한 유형의 추론 데이터 세트에 걸쳐 과제 성능을 향상시키는 가능성을 뒷받침하는 증거를 제공한다(Magister et al., 2023). 수학 영역에서 WizardMath 프레임워크(Luo et al., 2023)는 RLEIF(Reforcement Learning from Evol-InstructFeedback)라는 새로운 방법을 소개한다. 이 접근법은 처음에 수학에 특화된 Evol-Instruct를 사용하여 다양한 수학 수업 데이터를 생성한다. 이어서, 명령어 보상 모델(IRM) 및 프로세스-감독 보상 모델(PRM)의 훈련을 수반한다(Yuan et al., 2023; Lightman et al., 2023). IRM은 진화된 명령어의 품질을 평가하는 반면 PRM은 솔루션의 각 단계에 대한 피드백을 받는다. 나아가, MetaMath(Yu et al., 2023)는 트레이닝 데이터세트를 증강하기 위해 혁신적인 질문 부트스트래핑 방법(예: forward-backward augmentation(Jiang et al., 2023))을 도입하여, MetaMathQ를 생성한다. 이 방법은 순방향 추론 경로와 역방향 추론 경로를 모두 사용하여 질문의 재작성을 수반하고 LLM을 사용하여 질문 텍스트를 재구문화한다. 마지막으로, Yue et al.(2023)이 소개한 MAmmoTH는 MathInstruct라는 새로운 수학 하이브리드 명령어 튜닝 데이터 세트를 제시한다. 이 데이터 세트는 다양한 수학 분야와 복잡성 수준의 광범위한 적용 범위와 하이브리드 CoT(체인 오브 사고) 및 PoT(프로세스 오브 사고) 근거의 통합이라는 두 가지 중요한 특성을 자랑한다. Mukherjee 등(2023)의 논문 "Orca"는 설명 튜닝이라는 방법을 소개하고 있다. 이 방법에는 쿼리 및 응답 쌍을 사용 하 여 모델을 미세 조정 하는 것이 포함 됩니다. 응답은 GPT-4의 자세한 설명과 함께 추가되어 각 응답을 생성함에 따라 교사 모델의 추론 과정을 명확히 한다. 후속 작업인 Mitra 등(2023)의 "Orca2"에서는 Prompt Erasing이라는 기술이 제안되어 있다. 이 방법은 과제를 실행하는 방법에 대한 특정 세부 사항을 생략하고 학생 시스템에 제공된 특정 명령을 일반 명령으로 대체하여 교육 프로세스를 수정하는 것을 포함한다.

#### Parameter-Efficient Fine-tuning

기반 모델 구축의 기본 패러다임 중 하나는 특정 작업 또는 도메인에 대한 맞춤화에 의해 성공한 일반 도메인 데이터에 대한 철저한 사전 교육을 수반한다. 모델 크기가 계속 증가함에 따라 모든 모델 매개변수를 변경하는 포괄적인 미세 조정을 수행하는 것은 점진적으로 불가능해진다. 따라서 기초 모델을 효율적으로 정제하는 데 있어 매개변수 효율적인 미세 조정의 중요성은 충분히 강조될 수 없다. 다양한 유형의 기술의 몇 가지 대표적인 접근법이 그림 16에 나와 있다.

#### Adapter Tuning

트랜스포머 모델 내에서 "adapters"라는 특수화된 신경망 모듈을 채용하는 기법인 어댑터 튜닝은 Houlsby 등(2019)에서 논의된다. 혁신적인 적응 방법, LLaMA-어댑터(Zhang et al., 2023)는 명령어-추종 태스크들에 대한 LLaMA 모델들을 효과적으로 미세 조정하기 위해 개발되었다. LLaMA-어댑터는 사전 훈련된 LLaMA 7B 모델에 120만 개의 학습 가능한 매개변수만 도입하고 52,000개의 자체 지시 데모를 활용하고 8개의 A100 GPU를 사용하여 1시간 이내에 미세 조정 프로세스를 완료함으로써 효율성을 보여준다. MAD-X(Pfeiffer et al., 2020)는 높은 이식성과 높은 파라미터 효율의 전달로 다양한 태스크 및 언어에 적응될 수 있는 모듈러 언어 및 태스크 표현을 학습하도록 설계된 어댑터 기반 프레임워크이다. 한편, AdaMix(Wang et al., 2022)는 대부분의 PLM 가중치를 동결 상태로 유지하면서 각 변압기 층에서 적응 모듈의 혼합물을 미세 조정한다. Compacter(Karimi Mahabadi et al., 2021)는 태스크-특정 가중치 매트릭스를 미리 훈련된 모델의 가중치에 통합하며, 이는 각 컴퓨터 계층에서 정의된 바와 같이 공유된 "느린" 가중치와 "빠른" 랭크-원 매트릭스 사이의 크로네커 곱의 합으로서 효율적으로 획득될 수 있다. 마지막으로, He 등(2021)은 이러한 접근법들 간의 연결을 확립하는 통일된 프레임워크를 소개한다.

도 16(a)에 도시된 LoRA(Low-Rank AdaptationLow-Rank Adaptation)(Hu 등, 2022)는 다운스트림 작업에 적용될 때 미리 훈련된 Transformer 모델에서 훈련 가능한 파라미터의 수를 감소시키는 것을 목표로 하는 독특한 접근법을 제공한다. 이 기술은

도 16: 상이한 파라미터-효율적인 트레이닝 접근법들의 예시. (a) Low-Rank Adaptation(LoRA)는 파라미터를 조정하기 위해 네트워크의 모든 계층에 랭크 분해에 기초한 트레이닝 가능한 매트릭스를 통합하면서, 사전 트레이닝된 모델의 원래 가중치를 변경하지 않고 유지한다. 도면 크레딧은 LoRA(Hu et al., 2022). (b) 프롬프트 튜닝은 입력 계층에서 트레이닝 가능한 프롬프트 벡터를 통합하고 프롬프트-증강 입력을 사용하여 특정 다운스트림 이슈를 다룬다. (c) SSF는 파라미터-효율적인 미세 조정을 위해 미리 트레이닝된 네트워크에 의해 추출된 딥 피처들을 스케일링하고 시프트하기만 하면 된다. 상기 수치는 SSF(Lian et al., 2022)로부터 크레딧된다. (d) MMA는 경량 어댑터를 훈련시켜 큰 언어 모델과 비전-언어 태스크 사이의 갭을 메워 비전과 언어 모델의 공동 최적화를 가능하게 한다. 도면은 MMA로부터 크레딧한다(Luo et al., 2023).

트랜스포머 아키텍처의 각 계층에 사전 훈련된 모델 가중치를 동결하고 훈련 가능한 순위 분해 행렬을 도입한다. 저순위 분해는 표현력 측면에서 한계가 있지만, KronA(Edalati et al., 2022)는 저순위 표현의 대안으로 크로네커 제품을 선택한다. AdaLoRA(Zhang et al., 2023)는 특이값 분해를 통해 증분 업데이트를 파라미터화하여 중요하지 않은 특이값의 효과적인 프루닝을 허용한다. DyLoRA(Valipour et al., 2022)는 단지 하나 대신에 랭크들의 스펙트럼에 걸쳐 LoRA 블록들을 트레이닝하는 것에 초점을 맞추어 대안적인 방법을 채택한다. 이는 어댑터 모듈에 의해 획득된 표현들을 트레이닝 프로세스 전반에 걸쳐 상이한 순위들로 조직함으로써 수행된다. 효율적인 미세 조정 솔루션을 찾는 사람들을 위해, "Efficient Fine-tuning of Quantized LLMs"(QLoRA)(Dettmers 등, 2023)는 매력적인 옵션을 제공한다. QLoRA는 단일 48GB GPU에서 최대 650억 개의 매개변수를 가진 모델의 미세 조정을 가능하게 하여 연구자와 실무자 모두에게 실용적이고 접근 가능한 선택이 가능하다. 보다 복잡한 추론 작업을 가능하게 하기 위해, LongLoRA(Chen et al., 2023)는 계산 효율 및 성능 무결성을 유지하면서 대형 언어 모델의 입력 컨텍스트 크기를 확장하는 새로운 방법을 제공한다.

Li 및 Liang(2021)에 처음 도입된 프롬프트 튜닝 프리픽스 튜닝은 각 계층에 "프리픽스"로 알려진 훈련 가능한 연속 벡터의 시퀀스를 추가함으로써 트랜스포머 기반 언어 모델을 확장한다. 그것은 "prefix tuning"(Lester et al., 2021)과 유사한 개념인 프롬프트 튜닝을 위한 기초를 마련하는데, 입력 계층에서 배타적으로 훈련가능한 프롬프트 벡터를 통합하는 것에 일차적으로 초점을 맞춘다. 프롬프트 튜닝은 미세 조정된 언어 모델이 특정 다운스트림 작업, 예를 들어 분류(Yang 등, 2022)에서 탁월하도록 권한을 부여하는 "소프트 프롬프트"를 획득하기 위한 간단하면서도 매우 효과적인 접근법을 나타내며, 이는 도 16(b)에 예시되어 있다. 유사한 맥락에서, OptiPrompt(Zhong 등, 2021)는 성능을 최적화하기 위해 연속 임베딩 공간 내에서 동작한다. 한편, P-튜닝(Liu 등, 2023)은 이산 프롬프트와 함께 트레이닝 가능한 연속 프롬프트 임베딩을 활용하며, 완전 감독 또는 소수의 샷 설정에서든 사전-훈련된 언어 모델 및 미세-튜닝된 언어 모델 모두에 걸쳐 유효성을 입증한다. 이 개념의 진화인 P-튜닝 V2(Liu et al., 2021)는 입력 계층에만 국한되지 않고 사전 훈련된 모델의 모든 계층에 연속 프롬프트의 통합을 제안한다. 이 확장은 모델의 아키텍처 전반에 걸쳐 연속 프롬프트를 활용하는 포괄적인 접근 방식을 제공합니다.

부분 파라미터 튜닝 매개변수 효율성을 강조하는 앞서 언급한 접근법과 달리 부분 파라미터 튜닝은 추가 구성요소를 도입하지 않고 원래 모델 내에서 특정 매개변수를 선택적으로 미세 조정함으로써 자신을 구별한다. 비트핏(Zaken et al., 2021)은 모델의 바이어스 항들을 조정하는 것에만 집중하면서, 희소 미세 조정을 위한 방법으로서 이 개념을 예시한다. ChildTuning(Xu et al., 2021)은 파라미터 적응에 대한 전략적 접근법을 채택한다. 그것은 백워드 패스 동안 비-차일드 네트워크로부터의 그라디언트들을 조심스럽게 마스킹하면서 큰 사전 트레이닝된 모델들 내의 "차일드 네트워크"로 알려진 파라미터들의 서브세트를 타겟팅한다. 도 16(c)에 대응하는 SSF(Lian et al., 2022)의 경우, 이 방법은 트레이닝에서 학습가능한 파라미터들을 도입한다. 이러한 여분의 파라미터는 추론 시 재-파라미터화를 통해 원래의 사전 훈련된 모델 가중치에 매끄럽게 통합될 수 있으며, 이러한 파라미터들의 완전한 세트 또는 서브세트에 수정들이 적용된다. 한편, DiffFit(Xie et al., 2023)은 대규모 사전 훈련된 확산 모델에 맞게 조정된 파라미터-효율적인 미세 조정 전략을 제시한다. 이 방법은 바이어스 항을 미세 조정하고 새로 도입된 스케일링 팩터를 모델의 특정 계층에 통합함으로써 새로운 도메인에 신속하게 적응할 수 있게 한다. Fu 등(2023)은 미세 조정 접근법에서 파라미터 희소성을 이론적으로 분석하고 적합한 파라미터의 선택을 최적화하기 위해 SAM을 설계한다.

#### Mixture-of-Modality Adaption

Luo 등(2023, 2023)은 MMA(Mixture-of-Modality Adaptation)라고 불리는 비전 언어 모델을 미세 조정하기 위한 선구적인 방법을 개발했다. 도 16(d)에 도시된 바와 같이, MMA는 효율적인 어댑터를 통해 LMM(Large Language Models)과 이미지 인코더를 통합하는 포괄적인 최적화 프레임워크의 역할을 한다. 또한 MMA에서 최첨단의 라우팅 알고리즘을 도입하여 단일 명령어와 멀티모달 명령어에 대한 추론 경로를 동적으로 수정할 수 있도록 하였다. MMA를 이용하여, 저자들은 다양한 명령어-추종 태스크에 걸쳐 향상된 트레이닝 효율 및 향상된 추론 능력을 나타내는 중요한 비전-언어 지시 모델인 LaVIN(Luo et al., 2023)을 생성하였다. LaVIN은 기존의 멀티모달 LLM에 비해 우수한 성능을 보인다. MMA 방법론과 LaVIN 모델은 특히 로봇 공학 및 자율 시스템과 같은 응용 분야에서 비전 언어 모델의 유용성을 높이는 데 상당한 잠재력을 가지고 있다. 유사한 맥락에서, LLaMA-Adapter V2(Gao et al., 2023)는 파라미터 효율 및 시각적 정보의 끊김 없는 통합에 초점을 맞춘 시각적 명령 모델을 나타낸다. 이 모델은 학습 가능한 매개변수 세트를 확장하고 시각적 토큰을 LLM의 초기 계층에 통합하기 위한 조기 융합 접근법을 채택하고 이미지-텍스트 페어링 및 명령어 추적 데이터 세트 모두에 대한 합동 훈련 접근법을 적용하는 등 성능을 향상시키기 위한 여러 전략을 통합한다. 대안적으로, LLaVA(Liu et al., 2023)는 자신을 엔드 투 엔드 트레이닝 프로세스를 겪는 통합된 멀티모달 모델로서 제시한다. LLaVA는 시각 인코더와 LLM을 연결하여 시각과 언어 이해 모두를 포함하는 광범위한 작업을 처리한다. LLaVA-1.5(Liu et al., 2023)는 CLIP-ViT-L-336px를 MLP 프로젝션과 활용하고 태스크-특정 VQA 데이터를 기본 응답 포맷팅 프롬프트와 통합하는 것과 같이 비교적 간단한 조정을 도입한다. 이러한 수정을 통해 LLaVA-1.5는 강력한 기본 성능을 설정 하 여 11 개의 벤치 마크 작업에 걸쳐 상위 계층 결과를 달성할 수 있습니다.

### Alignment Training

정렬 훈련의 방법론은 인간 피드백을 직접 사용하여 언어 모델을 최적화하기 위해 학습 기술을 사용하는 혁신적인 접근법을 소개한다. 이 개념은 언어 모델이 복잡한 인간의 가치와 더 밀접하게 대응하도록 미세 조정되는 새로운 패러다임을 시작했다. LMs(Large LanguageModels)가 주어진 예들에 기초하여 다양한 자연어 처리(NLP) 태스크들을 실행하도록 프롬프트될 수 있지만, 이들은 종종 의도하지 않은 동작들을 발현한다. 여기에는 가상 정보를 생성하거나 편향되거나 불쾌한 텍스트를 생성하거나 사용자 지침을 준수하지 않는 것이 포함됩니다. 이러한 불일치는 웹 기반 텍스트에서 다음 토큰을 예측하는 전통적인 언어 모델링 목표와 "도움이 되고 안전한 방식으로 사용자 지침을 따르기"라는 목표 사이의 차이에서 비롯되며, 이러한 불일치는 언어 모델링 목표에 잘못된 정렬을 시사한다. 이러한 의도하지 않은 행동을 수정하는 것은 특히 수많은 도메인에서 언어 모델의 광범위한 적용을 고려할 때 매우 중요하다.

#### 4.3.1 데이터 원본

우리는 데이터를 \(d_{k}=(i_{k},y_{k})\)으로 정의하며, 여기서 \(i_{k}\)은 명령어를 나타내고 \(y_{k}\)은 해당 응답을 나타낸다.

Human DataDatabricks는 총 15,000개의 명령어를 포함하는 "databricks-dolly-15k"(Conover et al., 2023)로 알려진 포괄적인 크라우드 소싱된 명령어 데이터세트를 큐레이션하였다. 이 외에도 OpenAssistant corpus(Kopf 등, 2023)는 13,000명 이상의 국제 주석자의 참여를 포함하는 10,000개 이상의 대화로 구성된다. UnifiedQA(Khashabi et al., 2020)는 다양한 언어 현상을 포괄하는 20개의 다양한 데이터 세트에 걸쳐 평가를 거쳤다. CrossFit(Ye 등, 2021)은 공개적으로 이용 가능한 NLP 데이터세트에서 통합된 텍스트 대 텍스트 형식으로 변환된 160개의 태스크를 포괄하는 NLP 벤치마크로 확립되었다. P3(Sanh et al., 2021)은 270개 이상의 데이터세트로부터 2,000개 이상의 영어 프롬프트를 수집하였고, MetaICL(Min et al., 2022)은 7개의 상이한 메타-트레이닝 및 타겟 분할을 갖는 142개의 NLP 데이터세트에 걸쳐 실험을 수행하였다. ExMix(Aribandi et al., 2022)는 107개의 감독된 NLP 태스크들의 다양한 세트를 제공한다. Natural Instructions 데이터세트(Mishra et al., 2022)는 61개의 태스크로 구성되며, Super-Natural Instructions(Wang et al., 2022)는 1.5k 이상의 태스크로 이를 확장한다. Flan 2022(Longpre et al., 2023)는 강력한 평가 성능을 달성하기 위해 템플릿을 적응시키는, 명령어 튜닝을 위한 다양한 소스를 결합한다. xP3(Crosslingual Public Pool of Prompts)(Muennighoff et al., 2022)는 46개 언어 및 16개의 NLP 태스크에 걸쳐 있는 프롬프트 및 데이터 세트의 모음으로서, 제로 샷 명령어-추종에서의 다국어 모델 BLOOMZ 및 mT0을 보조한다. LongForm(Koksal et al., 2023)은 C4 및 영어 위키피디아 코퍼스로부터 15,000개의 타겟 텍스트 예들을 선택한다. 또한, 웹사이트인 ShareGPT는 사용자가 매력적인 ChatGPT/GPT4 대화를 공유하도록 적극적으로 권장하여 고품질 ChatGPT/GPT4 응답을 이끌어낼 수 있는 다양하고 인간 저작 지침이 풍부하다. 비영어 데이터세트를 생성하기 위해, Open Instruction Generalist(COIG)(Zhang et al., 2023)는 영어 명령어를 중국어로 번역하고 주석기를 활용하여 명령어를 수정하고 재구성한다.

합성 인간 소스로부터 데이터를 수집하는 것은 자원 집약적이고 시간이 많이 소요되는 프로세스일 수 있다. GPT-4와 같은 대규모 언어 모델(LLM)의 놀라운 성공을 감안할 때, 인간 피드백(RLHF)으로부터 강화 학습에서 다른 LLM을 훈련하기 위한 지침을 공식화하기 위해 LLM 응답을 활용하는 것이 점점 더 실행가능해졌다.

Self-Instruct(Wang et al., 2022c)에 의해 입증된 바와 같이, 이 영역에서의 개척 작업은 상당한 양의 명령어들을 생성하기 위해 ChatGPT의 문맥 내 학습 능력을 활용한다. 이들 명령어들은 광범위한 토픽들 및 태스크 유형들에 걸쳐 미리 정의된 인간 주석된 예들의 세트로부터 도출된다. 이러한 접근법에 기초하여, Aplaca(Taori et al., 2023) 및 그의 다양한 반복들(Peng et al., 2023c; Chiang et al., 2023)은 LLM들을 채용하여 RLHF에 대한 수많은 트레이닝 쌍들을 생성한다. 명령어 역번역(Li et al., 2023o)은 Self-augmentation을 활용하여 명령어와 함께 응답을 생성하고 Self-curation을 활용하여 응답에 기초하여 명령어를 생성한다. 부자연적 명령어들(Honovich et al., 2022)은 시드 예들 및 리프레이징을 통해 LLM들에 의해 생성된 64,000개의 예들을 포함하는 혁신적인 명령들의 실질적인 데이터세트로서 두드러지며, 그 결과 대략 240,000개의 인스턴스들의 데이터세트가 생성된다. OPT-IML Bench(Iyer et al., 2022)는 Instruction Meta-Learning(IML)의 벤치마크 역할을 하며, 기존의 8개의 벤치마크에서 도출된 2,000개의 과제를 특징으로 한다. 바닐라 GPT-3의 자체 강사 접근법을 사용하여 모델 일반화를 평가하여 52,000개 이상의 지침과 82,000개 인스턴스를 산출한다. Koala(Geng et al., 2023)는 ChatGPT Distillation Data를 비롯한 다양한 소스로부터 큐레이션된 작지만 고품질의 데이터셋으로, 종합적이고 다양한 데이터셋을 생성한다. GPT4All(Anand et al., 2023)은 GPT-3.5-Turbo OpenAI API로부터 대략 백만 개의 프롬프트-응답 쌍들을 포함하고, 2023년 3월 20일부터 2023년 3월 26일까지의 기간에 걸쳐 있다. Alpaca-GPT4(Peng et al., 2023c)는 영어 및 중국어 모두에서 명령-추종의 52,000 개의 예들을 포함한다. GPT-4의 피드백 데이터를 통합하여 제로 샷 성능을 향상시킵니다. LaMini-LM(Wu et al., 2023d)은 GPT-3.5-Turbo 모델에 의해 생성된 2508만 개의 명령어-응답 쌍들의 방대한 데이터세트를 포함한다. 이러한 쌍은 다양성을 보장하기 위해 다양한 프롬프트 소스로부터 도출된다. CoEditT(Raheja et al., 2023)는 텍스트 편집 모델 훈련 및 평가를 위한 \(<\)instruction: source, target\(>\) pair의 82,000 데이터셋을 제공하는 시스템이다. UltraChat(Ding et al., 2023e)은 백만 스케일 멀티턴 지시 대화 데이터를 포함하는 멀티라운드 대화들의 오픈 소스 컬렉션이다. CoT 컬렉션(Kim et al., 2023)은 FLAN 컬렉션(Longpre et al., 2023)으로부터 188만 개의 인스턴스로 CoT(Chain-of-Thought) 근거를 증강한다. Dynosaur(Yin et al., 2023a)는 Huggingface Datasets Platform의 새로운 데이터셋을 통합함으로써, 명령어 튜닝에서 데이터 큐레이션을 위한 동적 패러다임이다.

#### Training Pipeline

대용량 언어 모델(LLM)이 구체적인 안내를 통해 인간의 의도를 보다 정확하게 해석하고 대응할 수 있도록 향상시키는 일반적인 방법은 감독 정밀 조정(supervised Fine-Tuning; SFT)이라고 알려져 있다. 이 기법은 \(x\)으로 표시된 지시 입력을 처리한 다음 \(y\)으로 표시된 실제 정답과 관련하여 교차 엔트로피 손실을 계산하는 것을 포함한다. SFT의 주요 역할은 LLM이 텍스트 프롬프트 내에서 더 깊은 의미를 이해하고 적절한 답변을 생성하는 데 도움이 되는 것이다. 그러나 SFT의 중요한 단점은 최상의 응답과 덜 이상적인 응답을 세부적으로 구별할 수 있는 능력이 부족하다는 것이다. 이 문제를 극복하려면 인간 선호도 훈련을 통합하는 것과 같은 추가 훈련 전략이 필요하다. 전체 훈련 파이프라인이 그림 17에 나와 있다.

#### 온라인 휴먼 선호도 트레이닝

Reinforcement Learning from Human Feedback (RLHF)(Ouyang et al., 2022)은 Proximal Policy Optimization (PPO)(Schulman et al., 2017)의 프레임워크 내에서 추가적인 보상 모델을 통합하여 인간의 선호도를 해석하기 위해 개발된 전략을 나타낸다. RLHF는 크게 세 단계로 나누어진다. 1) 초기 단계는 포괄적인 지침의 생성과 기존 LMM(Large Language Models)에 대한 감독 미세 조정(Supervised Fine-Tuning, SFT)의 적용을 포함한다. 2) 다음 단계는 응답 쌍을 수동으로 채점하는 인간 평가자를 포함하여 생성된 응답의 효과를 평가하는 보상 모델 개발을 돕는다. 3) 마지막으로 SFT 모델(정책)은 보상 모델에 의해 결정된 보상을 활용하여 PPO를 통해 개선된다.

PPO 프레임워크는 인간의 선호도를 학습하는 데 효과적인 것으로 알려져 있지만 도전 과제를 제시하고 훈련 중에 안정성을 덜 나타낼 수 있다. 대안적인 접근법인 RFT(Reward Ranked Fine-Tuning)(동 등, 2023)는 초기에 상당한 배치의 지시를 샘플링하는 것을 포함한다. 이어서, 현재 LLM들에 의해 응답들이 생성되고, 결과 데이터는 보상 모델을 사용하여 순위가 매겨진다. 그런 다음, 보상 모델에 의해 결정된 상위 인스턴스만 SFT에 사용됩니다. 추가적으로, 어드밴티지-유도된 정책 정렬(APA)(Zhu 등, 2023)은 추정된 이점들에 기초한 제곱 오차 손실 함수를 채용하여, RLHF 프레임워크 내에서 정책 정렬에 대한 대안적인 관점을 제공한다.

그림 17: 대형 언어 모델(LLM) 정렬 훈련을 위한 개발 프로세스입니다. 첫째, LLM은 고품질 명령 데이터를 사용하여 감독 미세 조정(supervised Fine-Tuning, SFT)을 통해 종래에 최적화되었다. 그리고, Human Preference Training을 통해 더 조정될 수 있다. 관련 기법으로는 강화 학습이 필요한 온라인 인간 선호 훈련(좌측)과 선호를 가장 잘 만족시키기 위해 정책을 직접 최적화하는 오프라인 선호 훈련(우측)이 있다.

#### 4.3.3 Offline Human Preference Training

이러한 온라인 알고리즘의 구현은 정책, 행동 정책, 보상 및 가치 모델 사이에 필요한 복잡한 상호 작용으로 인해 종종 어려울 수 있다. 이러한 복잡성은 성능을 강화하기 위해 수많은 하이퍼파라미터의 조정을 필요로 한다. 이러한 문제를 완화하기 위해 인간의 선호도에 대한 오프라인 학습이 연구되었다.

그러한 접근법 중 하나는 Direct Preference Optimization(DPO)(Rafailov et al., 2023)이며, 이는 기존의 Reinforcement Learning from Human Feedback(RLHF) 알고리즘과 동일한 목적을 암시적으로 최적화하는 것을 목표로 한다. PRO(Preference Ranking Optimization) (Song et al., 2023b)는 인간의 선호도에 더 잘 정렬하기 위해 LMM(Large Language Models)을 미세 조정함으로써 이를 더 취하고 정규화를 위한 SFT(Supervised Fine-Tuning) 트레이닝 목표를 소개한다. Sequence Likelihood Calibration(SLiC)(Zhao et al., 2022a)는 모델의 잠재 공간 내의 참조 시퀀스의 확률과 보다 밀접하게 일치하도록 모델에 의해 생성된 시퀀스의 확률을 조정하는 것에 초점을 맞춘다. 대조적으로, RRHF(Rank Responses to align Human Feedback) (Yuan et al., 2023b)는 순위 손실을 이용하여 다중 응답의 모델 확률을 인간 선호도와 정렬하여, PPO(Proximal Policy Optimization) 알고리즘의 성능을 유지하는 보다 간단하면서도 효과적인 대안을 제공한다. (Wang et al., 2023l)은 Alignment Fine-Tuning(AFT) 방법을 제시한다. Alignment Fine-Tuning(AFT) 방법은 체인 오브 사고 훈련 데이터로 LMM(Large Language Models)을 미세 조정하고, 생성된 응답을 정확성에 기초하여 긍정 또는 부정으로 분류하고, 새로운 제약 정렬 손실을 사용하여 응답 스코어를 조정하는 것을 포함한다.

### MoE(Mixture of Experts)

도 18에 묘사된 바와 같이, MoE(Mixture of Experts) 모델은 네트워크의 어레이로 구성된 정교한 지도 학습 프레임워크를 나타내며, 각각은 완전한 트레이닝 데이터세트의 특정 세그먼트를 처리하도록 미세 조정된다(Jacobs et al., 1991). 이 아키텍처에서, 개별 예들은 각자의 전문가 네트워크에 의해 처리된다. Sparsely-Gated Mixture-of-Experts 모델(Shazeer et al., 2017) 통합

도 18: 순환 언어 모델 내의 MoE(Mixture of Experts) 층. 이 시나리오에서는 필요한 계산을 수행하기 위해 한 쌍의 전문가를 선택하기 위해 희소 게이팅 함수를 사용한다. 도면은 (Shazeer et al., 2017)의 크레딧이다.

수천 개의 피드포워드 하위 네트워크를 사용하고 각 데이터 인스턴스에 대해 이러한 전문가의 희소 배열을 참여시키기 위해 선택적 메커니즘을 사용한다. 이 방법론은 놀라운 1,370억 매개변수가 있는 모델에서 최고조에 달하며 모든 예제에 단일 전문가를 할당한다. GShard(Lepikhin et al., 2020)는 각 피드포워드 계층을 Top-2 게이팅 네트워크가 장착된 pairwise MoE 계층으로 대체하여 변압기의 MoE 패러다임을 적응시킨다. 다른 접근법에서, 스위치 트랜스포머(Fedus et al., 2022)는 각각의 입력에 대해 최적의 전문가 또는 단일의 최상의 전문가(단, \(K\)는 1) 중 하나를 선택함으로써 MoE의 희소성을 정제한다. 추가로, GaLM(Du 등, 2022)은 밀도가 높은 모델에 비해 트레이닝 비용을 실질적으로 감소시키면서 모델 용량을 증폭시키기 위해 희소하게 활성화된 MoE 아키텍처를 활용한다. GaLM의 가장 큰 변형은 놀라운 1조 2천억 개의 매개변수를 자랑하며 규모 면에서 GPT-3를 크게 능가한다. MoE는 또한 비전 모델의 능력을 향상시키기 위해 효과적으로 구현되었다(Chen et al., 2023, 2022). 또한, MoE는 네트워크 압축 전략에서 응용 분야를 찾는다. WideNet(Xue et al., 2022)은 네트워크의 깊이를 따른 압축을 위해 파라미터 공유를 활용하는 파라미터 효율적인 방법을 나타낸다. 모델링 용량을 최적화하기 위해 WideNet은 표준 피드포워드 네트워크를 MoE 구조로 대체하고 다양한 의미 표현을 효과적으로 처리하기 위해 별개의 계층 규범을 통합하여 모델의 폭을 확장한다. MoEBERT(Zuo et al., 2022)는 유사한 전략을 채택하여, 사전 훈련된 모델의 피드-포워드 신경망을 다수의 전문가로 변환한다. 이 수정은 훈련 동안 층별 증류를 통합하면서 사전 훈련된 모델의 강력한 표현 능력을 유지한다. 추론에서는 단일 전문가가 활성화되어 성능을 최적화합니다.

### In-Context Learning

Brown 등(2020)에 설명된 바와 같이, In-Context Learning(ICL)은 데모를 제공하기 위해 태스크 설명 및 태스크 예들의 서브세트 모두를 포괄하는 꼼꼼하게 조작된 자연 언어 프롬프트를 활용하는 방법이다. 이 프로세스는 작업 설명과 함께 시작하고, 이어서 데모 역할을 하기 위해 작업 데이터세트에서 몇 가지 예를 신중하게 선택한다. 그런 다음 이러한 선택된 인스턴스는 신중하게 설계된 템플릿을 사용하여 자연 언어 프롬프트로 복잡하게 배열된다. 이어서, 테스트 인스턴스는 원하는 출력을 생성하기 위해 언어 모델들 또는 비전-언어 모델들(Chen 등, 2023)에 대한 입력으로서 이들 시연들과 결합된다. 제공된 태스크 데모를 활용하여 LLM은 명시적인 그래디언트 업데이트 없이도 새로운 태스크를 효과적으로 식별하고 실행할 수 있다. 두 방법 모두 작업 또는 인스턴스를 구조화하기 위해 자연 언어를 사용하기 때문에 ICL은 명령어 튜닝과 근본적인 연결을 공유한다는 점에 유의하는 것이 중요하다. 그럼에도 불구하고 명령어 튜닝은 모델을 적용하기 위해 LLM의 미세 조정을 필요로 하는 반면 ICL은 순전히 LLM의 적용을 촉구하는 데 의존한다. 더욱이, 특히 작업 설명만이 제공되는 제로 샷 상황에서, 명령어 튜닝이 특정 작업을 실행하기 위한 LLM의 ICL 능력을 향상시킬 수 있다는 점에 유의하는 것이 중요하다(Chung 등, 2022). 다양한 공통 기술 세트가 다음에 소개되고 그림 19에 나열된다.

#### 4.5.1 시연 예제 선택

ICL(In-Context Learning)의 효과는 종종 시연 예제의 선택에 기초하여 상당한 가변성을 나타낸다. 따라서 언어 모델(LLM)의 ICL 용량을 진정으로 활용할 수 있는 예제의 하위 집합을 신중하게 선택하는 것이 중요해진다. 실증 선택을 위한 두 가지 주요 방법은 Liu et al. (2022)와 Lee et al. (2022)의 연구에서 탐구한 바와 같이 휴리스틱 접근법과 LLM 기반 접근법이다.

**사전 지식 접근법** 비용 효율성과 단순성으로 인해 경험적 기술은 이전 연구에서 시연 선택을 위해 널리 채택되었습니다. 많은 연구들은 Liu 등(2022) 및 Lee 등(2022)에 의해 입증된 바와 같이, 특정 질의들에 대한 의미론적으로 관련된 예들을 식별하기 위해 k-NN 기반 검색기들을 통합하였다. 그러나, 이러한 접근법들은 전형적으로 전체 예시 세트에 대한 전체적 평가가 결여된, 예시별로 동작한다는 점에 유의하는 것이 중요하다. 이러한 한계를 극복하기 위해 레비 등(2022)과 홍진 등(2022)의 연구에서 탐구한 바와 같이 특정 과제의 스펙트럼을 집합적으로 나타내는 예제의 하위 집합을 선별하기 위해 다양성 중심 선택 전략이 도입되었다. 더욱이, Ye 등(2022)에 의해 수행된 연구는 실증 선택 프로세스에서의 관련성 및 다양성을 모두 고려한다. 흥미롭게도 Complex CoT (Fu et al., 2022)

도 19: In-Context Learning을 위한 공통 기법.

광범위한 추론 단계들을 포함하는 복잡한 예들의 포함을 옹호하는 한편, Auto-CoT(Zhang et al., 2022c)는 시연을 위한 보다 다양한 예들의 세트의 샘플링을 제안한다.

**검색 접근법** 또 다른 연구 영역은 LMM(언어 모델)의 기능을 사용하여 데모를 선택하는 데 전념합니다. 예를 들어, LLM은 Li 및 Qiu(2023a)에 의해 입증된 바와 같이 그 포함으로 인한 성능 개선을 정량화하여 각 예의 정보성을 직접 평가하는 데 사용될 수 있다. 관련된 맥락에서, Rubin 등(2022)은 2단계 검색 프로세스를 수반하는 EPR이라는 접근법을 도입한다. 처음에 EPR은 감독되지 않은 방법을 통해 유사한 예를 리콜한 다음 조밀한 검색기를 사용하여 순위를 매긴다. 이를 기반으로, Dr.ICL(Luo et al., 2023e)은 QA, NLI, MathR 및 BC를 포괄하는 광범위한 스펙트럼의 평가 과제에 EPR 접근법을 적용한다. 인-컨텍스트 학습의 컨텍스트 내에서, 인-컨텍스트 학습을 위한 구성 예시들(CEIL)(Ye 등, 2023a)은 입력과 인-컨텍스트 예들 사이의 상호 작용을 학습하기 위해 DPP(Determinantal Point Processes)를 이용한다. 이 모델은 잘 만들어진 대조적 학습 목표를 사용하여 최적화된다. 추가로, LLM-R(Wang et al., 2023k)은 지상-진실 출력들의 조건부 LLM 로그 확률들에 의존하여, 검색된 후보들에 대한 랭킹 방법을 채택한다. LLM으로부터 세밀한 순위 신호를 포착하기 위한 크로스 인코더 기반 보상 모델과 지식 증류를 통해 훈련된 바이 인코더 기반 조밀 검색기를 사용한다. UDR(Unified Demonstration Retriever)(Li et al., 2023n)은 서로 다른 태스크에 걸친 검색기들 간의 비전송성 문제를 극복하기 위해 공유된 데모 검색 모델을 활용한다. UDR은 LLM의 피드백에 기초하여 후보 예들의 순위를 매긴다. 훈련된 검색기와 함께, DQ-LoRe(Xiong et al., 2023a)는 Dual Queries 및 Low-rank approximation Re-ranking을 활용하여 문맥 내 학습을 위한 예시들을 자동으로 선택한다.

#### Chain-of-Thought

_Zero-Shot CoT_

제로 샷 CoT(Kojima et al., 2022)는 추가 문장을 통합하여 모델 추론 능력을 향상시키는 새로운 접근법을 소개한다. 예를 들어, "단계별로 생각하자"라는 문구를 포함하면 모델의 추론 능력이 크게 향상될 수 있다는 경험적 증거가 입증되었다. 유사한 맥락에서, Plan-and-Solve(PS) Prompting(Wang et al., 2023j)은 이중 전략을 제시한다. 첫째, 전체 작업을 더 작고 관리 가능한 하위 작업으로 분할하는 계획을 수립하는 것입니다. 이어서, 이들 서브 태스크는 고안된 계획에 따라 실행된다. 보다 정확하게는 PS 프롬프트가 제로샷 CoT에서 원작인 '차근차근 고민하자'를 '문제를 먼저 이해하고 해결할 방안을 구상해 보자'는 새로운 프롬프트로 대체한 뒤 계획을 실행해 단계적으로 해결하자'는 것이다.

_Few-Shot CoT_

CoT(Chain-of-Thought)(Wei et al., 2022b)는 상세한 추론 경로를 프롬프트로 사용하여 언어 모델(LLM)의 추론 능력을 향상시키기 위한 중요한 과정을 도표화했다. 이러한 지향성 추세는 다양한 CoT 변형, 예컨대 최소 대 최(Zhou et al., 2022a), 복합 CoT(Fu et al., 2022), 프로그램-of-thought(Chen et al., 2022d), 방정식-of-thought(Liu et al., 2023k), 프로그램-aid-language(Gao et al., 2023b), mathprompter(Imani et al., 2023), 및 코드 프롬프팅(Hu et al., 2023b)을 발생시켰다. 그러나 이러한 모든 방법에는 응용 프로그램에 실질적인 제한을 부과하는 주석이 필요하다는 점에 주목할 가치가 있다. 이러한 제약을 해결하기 위해, Auto-CoT(Zhang et al., 2022c)는 CoT 추론 경로들을 생성하기 위해 Zero-Shot-CoT(Kojima et al., 2022)를 활용하는 새로운 접근법을 제안한다. 또한 Auto-CoT는 이러한 추론 경로를 서로 다른 군집으로 나누고 각 군집의 중심과 가장 밀접하게 정렬된 질문을 선택한다. 사고 기억(Li and Qiu, 2023b)은 추론 과정에서 외부 기억에서 관련 있고 질 높은 생각을 선택한다. 한 걸음 더 나아가, Tree-of-Thought(Yao et al., 2023b)는 인간의 사고 과정을 사슬뿐만 아니라 트리로 모델링하는 반면, Graph-of-Thought(Yao et al., 2023d)는 이러한 개념을 확장하여 인간의 사고 과정을 사슬과 그래프 모두로 표현한다. 추가적으로, Skeleton-of-Thought(Ning et al., 2023)는 LLM들이 먼저 해답의 기본 구조를 생성한 다음, 일괄 디코딩을 사용하여 각각의 골격의 세부 사항을 동시에 채우도록 안내한다.

#### 다중 경로 집계

DIVERSE 접근법(Li et al., 2022h)은 다수의 추론 경로로부터 도출된 최종 답변을 통합하기 위해 투표 검증기를 채용한다. 유사한 맥락에서, Self-Consistency 방법(Wang et al., 2023s)은 다수의 추론 경로를 샘플링하고 최종 결과를 결정하기 위해 다수 투표를 하는 것을 제안한다. 이러한 방향을 바탕으로 다수결 투표를 위한 복잡도가 높은 추론 경로를 유지하는 복잡도 기반 투표의 개념이 도입되었다(Fu et al., 2022). 또한 모델 선택(Zhao et al., 2023d)은 CoT(Chain-of-Thought)와 PoT(Plan-of-Thought)를 통해 두 가지 답변을 샘플링한 다음 언어 모델(LLM)을 사용하여 올바른 답변을 선택하는 다른 접근법을 취한다. 완전한 추론 경로들을 생성하는 대신에, Self-Evaluation Guided Decoding(Xie et al., 2023c)은 단계 레벨에서 다양한 추론 단계들을 샘플링하고 빔 탐색을 활용하여 탐색 트리를 완성한다. 자기 일관성의 한 가지 주목할 만한 한계는 상대적으로 높은 비용이다. 이러한 단점을 완화하기 위해, Adaptive-Consistency(Aggarwal 등, 2023)는 미리 정의된 기준들이 충족될 때까지 추론 경로들을 점진적으로 샘플링한다. Tree-of-Thought와 관련된 두 가지 동시 접근법(Yao et al., 2023b; Long, 2023)은 완전한 추론 경로보다는 점진적으로 추론 단계를 샘플링한다. 추가적으로, RAP(Reasoning via Planning) (Hao et al., 2023a)는 LLM을 월드 모델 및 추론 에이전트 둘 다로서 용도화한다. 몬테카를로 트리 탐색을 기반으로 하는 원칙적인 계획 알고리즘을 통합하여 광범위한 추론 공간 내에서 전략적 탐색을 용이하게 한다. Exchange-of-Thought(Yin et al., 2023c) 및 X-of-Thoughts(Liu et al., 2023k)는 추론 성능을 향상시키기 위해 다양한 외부 추론 인사이트 및 추론 방법을 소개한다.

#### Multi-Round Prompting

다원적 프롬프트는 이러한 점진적 개선 과정을 사용하지 않는 사상 사슬이나 자기 일관성과 같은 단일원적 프롬프트 방법과 달리 반복적 개선을 통해 응답을 향상시킨다.

#### Learned Refiners

Learned Refiner는 트레이닝 프로세스를 필요로 하며, 감독된 정제화의 획득은 전형적으로 피드백 및 정제화의 쌍을 포함한다(Schick et al., 2022; Du et al., 2022; Yasunaga and Liang, 2020; Madaan et al., 2021). CURIOUS(Madaan et al., 2021)는 초기에 관련 영향을 나타내는 그래프를 구성한다. 이 그래프는 이어서 질문에 응답하기 위한 추가 입력으로서 통합된다. PEER(Schick et al., 2022)는 초안 작성, 수정 제안, 편집 제안 및 그 동작에 대한 설명을 포함하는 전체 작성 프로세스를 복제하는 고급 협력 언어 모델이다. 대조적으로, Read, Revise, Repeat(R3)(Du 등, 2022)는 최소한의 인간 개입으로 우수한 텍스트 수정을 달성하는 것을 목표로 한다. 모델 생성 수정 및 사용자 피드백을 분석하고, 문서 수정을 만들고, 인간-기계 상호작용을 반복함으로써 이를 달성한다. DrRepair(Yasunaga and Liang, 2020)는 소스 코드 수리와 관련된 심볼을 진단 피드백으로 연결하는 프로그램 피드백 그래프를 소개한다. 그런 다음 그래프 신경망을 사용하여 추론 프로세스를 모델링한다. Self-Correction(Welleck et al., 2022)은 표준 언어 모델 또는 감독된 시퀀스-투-시퀀스 모델과 같은 불완전한 베이스 생성기를 별도의 보정기로부터 디커플링함으로써 혁신적인 접근법을 취한다. 이 보정기는 출력을 점진적으로 정제하는 방법을 배웁니다. 또한, LLM-Augmenter(Peng et al., 2023)는 LLM 생성 응답의 사실성 점수와 같은 효용 함수에 의해 생성된 피드백을 통합함으로써 모델 응답을 개선하도록 LLM 프롬프트를 지속적으로 향상시킨다.

#### Prompted Refiners

REFINER 프레임워크(Paul et al., 2023)는 추론 과정에 대한 피드백을 자동화하는 비평가 모델을 사용하여 중간 추론 단계 생성을 목표로 언어 모델(LMs)을 미세 조정하도록 설계된 포괄적인 시스템이다. Self-Refine 프레임워크(Madaan et al., 2023)는 두 가지 중요한 구성 요소를 포함한다 : 먼저 LLM을 사용하여 출력을 생성한 다음 동일한 LLM을 사용하여 반복적인 자기 정제 프로세스를 통해 출력에 대한 피드백을 제공한다. Self-Debugging(Chen et al., 2023)은 성능을 향상시키기 위해 LLM과 툴 피드백을 모두 통합한다. 유사하게, PHP(Progressive-Hint Prompting)(Zheng et al., 2023)는 후속 응답을 생성하기 위한 참조로서 이전 답변을 활용한다. 또한, LLMs에 대해 별개의 프롬프트를 채용하는 것은 다양한 양태를 처리하는데 있어서 상이한 역할의 할당을 허용한다(Dong et al., 2023; Fu et al., 2023; Du et al., 2023). Du 등(2023)은 공유된 최종 답변에 도달하기 위해 다수의 라운드에 걸쳐 그들의 개별 응답 및 추론 프로세스에 관한 논의에 관여하는 언어 모델의 다수의 인스턴스를 포함하는, 언어 응답을 향상시키기 위한 상보적 접근법을 소개한다. 셀프-협업(Dong et al., 2023)은 다수의 LLM을 별개의 "전문가"로서 활용하고, 각각은 복잡한 할당 내에서 특정 서브 태스크를 담당하며, 협업 및 상호 작용을 위한 전략을 정의한다. Fu 등(2023)은 더 약한 모델이 게임 규칙을 이해하거나 추가 향상을 위해 AI 피드백을 통합하는 데 어려움을 겪을 수 있기 때문에, 고려된 언어 모델의 하위 집합만이 AI 피드백을 통해 자기 개선의 숙련도를 나타낸다는 것을 관찰한다. 결론적으로, 모델들은 그들의 역할들에 기초하여 피드백으로부터 학습하는 다양한 능력들을 나타내고, LMM들과 도구들 사이의 상호작용은 추론 성능을 더욱 향상시킬 수 있다(Chen et al., 2023; Gou et al., 2023; Zhang et al., 2023; Yang et al., 2023; Olaussson et al., 2023).

### Autonomous Agent

자율적으로 운영되는 에이전트는 종종 인공지능(AGI)을 달성하기 위한 핵심 경로로 여겨져 왔다. 이러한 에이전트는 계획을 독립적으로 공식화하고 지침에 따라 작업을 수행하는 데 능숙하다. 현재, 이러한 자율 엔티티들은 도 20에 도시된 바와 같이, 그들의 지정된 작업을 완료하기 위해 웹 브라우저들 및 코드 인터프리터들을 포함하는 다양한 툴들을 제어 및 오케스트레이션하기 위해 주로 LLM(Large Language Models)에 의존한다(Xi 등, 2023; Wang 등, 2023).

VISPROG(Gupta and Kembhavi, 2022)는 복잡한 시각 작업에 대한 신경 기호학적 접근법으로, 큰 언어 모델을 사용하여 작업별 훈련 없이 파이썬과 같은 모듈러 프로그램을 생성한다. 그것은 포괄적이고 해석 가능한 근거를 제공한다. ToolFormer(Schick et al., 2023)는 어떤 API를 호출할지, 언제, 어떤 인수로 결과를 데모를 기반으로 토큰 예측에 통합할지 결정하는 자체 감독 모델이다. ART(Paranjape et al., 2023)는 자동 추론 및 도구 사용을 위한 프레임워크를 도입하며, 동결된 LLM을 활용하여 중간 추론 단계를 생성하고 외부 도구를 원활하게 통합한다. CAMEL(Li 등, 2023)은 "역할-플레이잉"으로 알려진 선구적인 통신 에이전트 프레임워크를 제시하며, 이는 인간의 의도와의 정렬을 유지하면서 태스크를 달성하기 위해 채팅 에이전트들을 지시하도록 프롬프팅하는 것을 채용한다. GPT4Tools(Yang et al., 2023)는 다중 비전 태스크를 해결하기 위해 멀티모달 툴 능력을 가진 LLM에 권한을 부여한다. HuggingGPT(Shen et al., 2023)는 태스크를 해결하기 위한 AI 모델을 연결하고, 태스크 플래닝을 위해 ChatGPT를 사용하고, Hugging Face에서 함수 설명에 기반하여 모델을 선택한다.

도 20: 자율 에이전트를 갖는 LLM을 위한 일반적인 파이프라인. LLM 에이전트는 LLM을 디지털 뇌가 여러 능력을 마스터하고 높은 수준의 지능을 소유하는 것으로 활용한다. 에이전트는 다양한 인코딩된 데이터 세트를 입력으로서 수신할 수 있고, 이에 대응하여 구성하거나 지식 베이스 및 스킬 라이브러리에 액세스할 수 있다. 충분한 지식과 프롬프트로, 에이전트는 태스크의 스펙트럼을 동작시키기 위해 반자율적으로 작업할 수 있다.

카멜레온(Lu et al., 2023)은 복잡한 추론을 위해 LLM을 플러그 앤 플레이 모듈로 증강하고, 작업에 대한 다양한 도구를 구성하여 프로그램을 합성한다. Wang 등(2023)은 소프트 프롬프트인 "플래닝 토큰"을 학습할 것을 제안한다. TRICE(Qiao et al., 2023)는 툴 실행으로부터의 피드백을 통해 학습을 위한 2단계 프레임워크를 제안하면서, 툴을 언제 어떻게 사용하는지를 언어 모델을 가르치는 것의 과제를 다룬다. ChatCoT(Chen et al., 2023)는 생각 체인과 도구 사용을 자연스럽게 통합하기 위해 멀티-턴 대화를 사용하는, 채팅 기반 LLMs에 대한 도구-증강된 체인-오브-사상 추론 프레임워크를 제시한다. MultiTool-CoT(Inaba et al., 2023)는 추론 프로세스 동안 다수의 외부 도구를 통합하도록 프롬프팅하는 체인의 사고를 활용한다. AssistGPT(Gao et al., 2023)는 계획, 실행, 검사 및 자율 학습을 포함하는 인터리브된 코드 및 언어 추론 접근법을 갖는 멀티모달 AI 어시스턴트를 소개한다. OpenAGI(Ge et al., 2023)는 실세계 태스크를 위한 오픈 소스 AGI 연구 플랫폼으로, 자연어 질의를 사용하여 적절한 모델을 선택하고 실행하고 태스크 피드백 메커니즘으로부터 강화 학습을 제안한다. 툴켄GPT(Hao et al., 2023)는 유연한 툴 콜을 위한 토큰("toolkens")으로서 툴을 나타내는 툴 데모 데이터 및 인-컨텍스트 학습과 LLMs의 피니튜닝의 이점을 결합한다. AutoGPT(gravitas/auto gpt, 2023)는 문제를 하위 문제로 분해하고 이를 해결하기 위한 도구를 사용한다. ReAct(Yao et al., 2023)는 언어 태스크에서 향상된 시너지를 위해 추론 트레이스 및 태스크-특정 액션의 인터리브된 생성을 탐색하여, 해석 가능성 및 신뢰성을 향상시킨다. 반사(Shinn et al., 2023)는 언어적 피드백과 일화 기억을 통해 언어 에이전트를 강화하여 후속 시험에서 의사 결정을 개선한다. CREATOR(Qian et al., 2023)는 LLM이 문서화 및 코드 구현을 통해 자신만의 도구를 만들 수 있도록 허용하여 도구 사용 능력의 한계를 해결한다. 보이저(Wang et al., 2023)는 평생 학습을 위한 마인크래프트의 LLM-동력 에이전트로서, 자동 커리큘럼, 스킬 라이브러리, 및 반복적인 프롬프트 메커니즘을 통합한다. AutoAgents(Chen et al., 2023)는 태스크 정의에 기초하여 에이전트의 팀을 구축하기 위해 적응적으로 특화된 에이전트를 생성할 수 있다. SwiftSage(Lin et al., 2023)는 인간 인지의 이중 프로세스 이론에서 영감을 받은 에이전트 프레임워크로, 복잡한 추론 작업을 위한 행동 복제와 LLM을 통합하여 문제 해결 효율을 높인다. 이러한 참조는 다양한 도메인에 걸쳐 대규모 언어 모델의 기능을 향상시키기 위한 광범위한 접근법과 프레임워크를 다룬다.

## 5 논의: 도전, 제한 사항 및 위험

기반 모델은 추론 작업에서 유망한 능력을 보여 해당 분야에 대한 새로운 가능성을 열어주었다. 또한 사용과 관련된 도전, 한계 및 위험을 인정하는 것이 필수적이다.

_Hallucinations_

기초 모델에서 이루어진 유망한 진전에도 불구하고, 이러한 모델들이 특히 환각의 문제와 관련하여 여전히 도전에 직면해 있다는 것을 인정하는 것이 중요하다(Li et al., 2023; Mundler et al., 2023). 환각은 의도된 또는 예상되는 출력에서 벗어나 조작되거나 잘못된 정보를 포함하는 기초 모델에 의한 출력 생성을 의미한다. 이러한 환각은 모델의 생성된 콘텐츠의 신뢰성과 정확성을 저해하기 때문에 문제가 될 수 있다.

기초 모형에서의 환각 문제는 다양한 요인에 의해 발생한다. 한 가지 핵심 요소는 편향되거나 잘못된 정보를 포함할 수 있는 대규모 사전 훈련 데이터에 대한 의존도이다. 이는 모델 학습 및 잘못된 패턴을 전파하거나 비현실적인 출력을 생성할 수 있다. 기초 모형에서 환각 문제에 기여하는 또 다른 중요한 요인은 모형 자체의 지식 한계를 인정할 수 있는 능력의 부족이다. 그들의 이해를 넘어서는 질문들에 직면할 때, 이러한 모델들은 그들의 지식 부족을 인정하는 대신에 겉보기에 그럴듯한 답변을 조작하는 경향이 있다(Yin et al., 2023).

기초 모델에서 환각 문제를 해결하는 것은 현재 진행 중인 연구 분야이다. 과제별 데이터 미세 조정, 외부 지식 소스 통합, 고급 평가 메트릭 개발과 같은 기술은 환각을 완화하기 위해 탐색되었다. 연구자들은 또한 기초 모델에서 추론 능력을 향상시키는 방법을 탐색하여 보다 정보에 입각하고 정확한 예측을 할 수 있도록 하고 있다.

환각을 줄이는 데 진전이 있었지만 언어 이해와 세대의 고유한 복잡성으로 인해 환각을 완전히 제거하는 것은 여전히 과제로 남아 있다는 점에 주목할 필요가 있다.

컨텍스트 길이 또 다른 제한은 컨텍스트 길이 및 컨텍스트 구성을 최적화하는 것이다. 예를 들어, GPT 모델은 2K 윈도우 사이즈(GPT-3(Brown et al., 2020))로 시작하여 32K(GPT-4(OpenAI, 2023))까지 간다. 더 긴 컨텍스트 윈도우는 유전자 서열과 같은 긴 서열 데이터로 작업하는 데 유용하다. 더 큰 컨텍스트 윈도우를 가짐으로써, LLM은 전체 문서들과 같은 더 긴 입력들을 처리하거나 문서의 전체 범위를 이해할 수 있다. 이 능력은 LLM이 입력에 대한 보다 포괄적인 이해를 활용하여 보다 맥락적으로 관련된 응답을 생성할 수 있게 한다.

기초 모델에서 컨텍스트 윈도우 크기를 증가시키는 것은 더 긴 범위의 종속성을 포착하고 컨텍스트에 대한 모델의 이해도를 향상시키는 것과 같은 몇 가지 이점을 가져올 수 있다. 그러나 특정 도전과 비용도 함께 제공됩니다. 이전 연구에서, 더 큰 컨텍스트 윈도우 크기와 관련된 비용은 토큰의 수가 증가함에 따라 이차적인 증가를 나타내는 것으로 관찰되었다(Aryan et al., 2023). 이는 윈도우 크기가 커질수록 모델을 처리하고 훈련하는 데 필요한 계산 자원이 상당히 높아짐을 의미한다. LongNet(Ding et al., 2023)은 길이가 10억 토큰을 초과하는 시퀀스를 처리할 수 있는 트랜스포머 모델의 수정된 버전을 나타내지만, 더 짧은 시퀀스에 대해서는 여전히 그 효과를 유지한다. LongNet은 또한 선형 계산 복잡도를 갖는다. Position Interpolation(Chen et al., 2023)은 추론 동안 초기 컨텍스트 윈도우 크기와 정렬하기 위해 입력 위치 인덱스들의 선형 다운스케일링을 구현한다. 이 접근법은 그렇지 않으면 비정상적으로 높은 주의 점수를 초래하고 자기-주의 메커니즘을 방해할 수 있는 훈련된 컨텍스트 길이를 넘어 확장하는 것을 방지한다.

실제로, 언어 모델에서 컨텍스트 윈도우 크기를 증가시키는 것은 이점을 제공하지만 윈도우 크기와 일반화 능력 사이의 균형을 고려하는 것이 중요하다. 연구원들은 그들 사이에 트레이드오프가 있을 수 있다고 강조했다 (Liu et al., 2023). 탐색할 가치가 있는 한 가지 과제는 모델의 성능 및 일반화 능력을 희생시키지 않고 컨텍스트 윈도우 길이를 증가시키는 방법이다. 모델이 새로운 입력 또는 보이지 않는 입력에 잘 일반화하는 능력을 유지하면서 더 긴 범위의 종속성과 맥락을 포착할 수 있는 전략을 찾는 것이 중요하다.

멀티모달 학습 멀티모달 학습은 믿을 수 없을 정도로 강력하지만 종종 추론의 과소평가된 측면이다. 의료(CT, X선, MRI 스캔 및 유전자 서열), 로봇 공학, 전자 상거래, 소매, 게임 및 엔터테인먼트를 포함하여 멀티모달 데이터가 필수적인 수많은 분야에서 애플리케이션을 찾는다. 이러한 도메인에서 서로 다른 양식의 통합은 데이터에 대한 보다 포괄적인 이해를 가능하게 하고 보다 정교한 추론 프로세스를 용이하게 한다.

멀티모달 추론의 주요 장점 중 하나는 모델 성능을 크게 향상시킬 수 있다는 것이다. PaLM-E에 의해 제안된 체화된 추론을 위한 멀티모달 언어 모델(Driess et al., 2023) 및 플라밍고로 알려진 공포-샷 학습을 위한 시각적 언어 모델(Alayrac et al., 2022)과 같은 일부 선행 연구들이 멀티모달 추론을 파헤쳤지만, 추가적인 데이터 모달리티를 탐색할 여지는 여전히 충분하다. 비디오, 오디오, 3D 데이터 및 다중 이미지와 같은 모달리티를 통합하면 모델이 사용할 수 있는 정보가 풍부해질 뿐만 아니라 세계에 대한 보다 미묘하고 포괄적인 이해를 위한 흥미로운 가능성을 열어준다. 기초 모델 추론의 다른 잠재적인 응용은 프로그램 설계를 위한 전자 설계 자동화(EDA)의 도메인(Huang et al., 2021) 및 공식 방법(Woodcock et al., 2009)에 있다.

논리 추론과 본질적으로 연결된 형식적 방법은 소프트웨어와 하드웨어의 설계, 사양, 검증 및 분석을 위해 컴퓨터 과학의 영역에서 사용되는 수학적 전략이다. 이러한 기술은 구조화된 논리, 오토마타 이론 및 기타 포괄적인 수학적 프레임워크에 고정되어 있다. 시스템의 동작, 정확성 및 신뢰성을 꼼꼼하게 검사하는 데 사용됩니다. 공식적인 방법의 활용은 연구자와 전문가가 복잡한 시스템의 무결성과 정밀성을 보장할 수 있게 하여 소프트웨어 및 하드웨어의 생성 및 평가에 필수 불가결한 것으로 확립한다. 형식적 방법과 기초적 모델의 결합은 소프트웨어 및 하드웨어 시스템의 설계에서 추론 능력을 증가시키는 문을 연다. 형식적 방법은 시스템 특성을 정의하고 확인하기 위한 정확한 수학적 방법을 제공하는 반면, 기초 모델은 강력한 언어 이해 및 추론 기술을 제공한다. 이러한 방법론의 합성은 보다 신뢰할 수 있고 탄력적인 소프트웨어 및 하드웨어 시스템의 개발을 촉진할 수 있다.

다중 모드 추론을 활용하고 다양한 데이터 양식에 대한 탐구를 더욱 확장함으로써 추론 시스템에서 새로운 통찰력과 기능을 해제할 수 있다. 다양한 영역에서 추론의 잠재력을 충분히 활용하기 위해서는 멀티모달 추론의 힘을 인식하고 활용하는 것이 중요하다.

#### 효율성 및 비용

효율성과 비용은 추론을 위한 기초 모델의 중요한 과제이다. 기반 모델, 특히 대규모 아키텍처 및 광범위한 훈련 데이터를 갖는 모델은 훈련 및 배포에 계산적으로 비용이 많이 들 수 있다. 많은 수의 파라미터는 처리를 위해 더 많은 메모리 및 계산 자원을 필요로 한다. 이는 확장성, 접근성, 비용 효율성 측면에서 과제를 제기한다. 효율적인 추론 모델은 대화형 애플리케이션의 요구를 충족시키기 위해 빠르고 실시간 추론을 수행할 수 있어야 한다. 그러나 추론 작업에 수반되는 복잡한 계산은 추론 시간을 느리게 하여 실시간 성능과 사용자 경험을 방해할 수 있다. 따라서 기초 모델의 속도와 비용 효율성을 향상시켜 더 저렴하고 빠르게 만드는 것이 중요합니다.

기초 모델의 효율성을 향상시키기 위해 채용될 수 있는 몇 가지 기술이 있다:

* 모델 프루닝(Sun et al., 2023; Wang et al., 2020): 모델에서 불필요한 연결, 파라미터 또는 레이어를 제거한다. 따라서 더 컴팩트한 아키텍처가 되어 계산 요구 사항을 줄일 수 있습니다.
* 압축(Zhu 등, 2023) 및 양자화(Tao 등, 2022): 더 적은 비트를 사용하여, 모델의 크기를 감소시키거나 모델 파라미터의 정밀도를 감소시킨다. 이는 메모리 사용량과 계산 복잡도를 감소시킨다.
* Knowledge Distillation (Gu et al., 2023): 더 큰 모델 또는 모델(교사)의 앙상블의 거동 및 예측을 모방하기 위해 더 작은 모델(학생)을 트레이닝한다. 이러한 지식의 전달은 감소된 계산 리소스로 효율적인 추론을 가능하게 한다.
* Low-Rank Factorization (Ren and Zhu, 2023; Hsu et al., 2022): 고차원 텐서를 저차원 텐서로 대체한다. 파라미터들의 수를 감소시킴으로써, 이러한 방법들은 성능에서 큰 손실 없이 효율을 향상시킨다.

이러한 기법을 사용함으로써 기초 모델의 효율성을 높일 수 있어 다양한 추론 작업 및 응용에 대해 더 빠르고 비용 효율적이다.

#### Human Preference

편향, 불공정성, 조작 및 잘못된 정보와 같은 기반 모델과 관련된 위험과 잠재적 피해를 해결하려면 신중한 고려와 사전 조치가 필요하다. 한 가지 접근법은 보다 책임감 있고 정확한 모델 행동을 보장하기 위해 인간의 선호도와 피드백으로부터 학습을 개선하는 데 초점을 맞추는 것이다.

이러한 위험을 완화하기 위해 몇 가지 전략을 탐색할 수 있다. 첫째, 기초 모델의 훈련 및 미세 조정 단계에서 다양한 관점을 통합하고 편향을 완화하기 위한 메커니즘이 필요하다. 여기에는 다양한 데이터 수집, 대표적인 샘플링 및 광범위한 인간 관점에서 입력을 포함하는 신중한 주석 프로세스가 포함될 수 있다. 인간의 피드백에 의해 정보를 받은 지속적인 학습과 적응도 중요한 역할을 할 수 있다. 모델과 인간 주석자 또는 사용자 간의 지속적인 상호 작용을 가능하게 함으로써 피드백을 수집하고 모델의 동작을 반복적으로 정제할 수 있다. 이 반복적인 프로세스는 잠재적인 편향, 불공정 또는 잘못된 정보를 식별하고 수정하는 데 도움이 되어 시간이 지남에 따라 모델이 개선될 수 있다. 또한 기초 모델의 출력이 실제 증거, 실험 결과 및 명시적 지식과 일치하는지 확인하는 것이 필수적이다. 이를 위해서는 강력한 팩트 체킹 메커니즘과 검증 프로세스를 모델 학습 파이프라인에 통합해야 한다. 또한 신뢰할 수 있는 데이터베이스 또는 전문가 지식과 같은 외부 정보 소스를 활용하면 모델에 의해 생성된 출력을 확인하고 검증하는 데 도움이 될 수 있습니다.

Bai 등(2022)에 의해 제안된 바와 같이, 체질 AI는 "AI 피드백으로부터의 RLAIF"(RLAIF)와 같은 지도 학습 및 강화 학습 단계 모두를 포함하는 접근법을 제공한다. 유사하게, Bakker 등(2022)은 700억 개의 파라미터를 갖는 대형 언어 모델(LLM)을 미세 조정하여 다양하고 다양한 관점을 갖는 사람들에 대한 예상 승인을 최대화하는 진술을 생성하는 사용을 탐구한다. 이 접근법은 모델 훈련 과정에서 인간의 선호와 다양한 관점을 통합하는 것의 중요성을 강조한다.

이러한 기술과 접근 방식을 통합함으로써 기초 모델과 관련된 위험과 잠재적 피해를 완화하기 위해 노력할 수 있다. 인간의 선호도에서 학습을 개선하고 피드백에 의해 정보를 받은 지속적인 학습 및 실제 증거에 대한 충실도를 보장하는 것은 보다 책임 있고 신뢰할 수 있는 추론 시스템을 구축하는 데 어려운 단계이다.

#### Multilingual Support

추론 자체는 언어 불가지론적인 과정이지만 포괄적인 지식 소스의 가용성은 종종 주로 영어와 같은 몇 가지 언어로 제한된다. 역사적으로 언어 기반 모델은 중국어와 일본어와 같은 다른 언어에 대해 상대적으로 제한된 지원으로 주로 영어에서 예외적인 추론 성능을 보여주었다. 현재, 다양한 언어에 걸쳐 탁월한 강력한 다국어 추론 언어 기초 모델이 부족하다.

Fang 등(2022)은 영어를 그들의 상식 추론 프레임워크에서 피벗 언어로서 활용하는 것을 제안한다. 그들은 추론 능력을 향상시키기 위해 영어 지식 소스를 활용하는 번역-검색-번역(TRT) 전략을 사용합니다. 나아가, Huang 등(2023)은 언어 및 추론 모델(Language and Reasoning Models, LMM)의 다언어 능력을 향상시키기 위한 체계적인 접근법으로서 교차 언어 사고 프롬프트(XLT)를 도입한다.

이러한 발전을 감안할 때 다국어 추론에 전념하는 기초 모델 개발에 대한 관심이 증가하고 있다. 다국어 분야에서 뛰어난 강력한 모델을 구축하는 것은 향후 연구 및 개발을 위한 흥미로운 방법을 제시한다.

요약하면, 이러한 과제를 해결하기 위해서는 지속적인 연구 및 개발 노력이 필요하다. 여기에는 추론 모델의 배치를 개선하는 것이 포함됩니다.

## 6 Future Direction

이 분야의 추가 연구 개발은 기초 모델에서 훨씬 더 진보된 추론 능력을 해제할 수 있는 잠재력을 가지고 있다.

### 안전 및 프라이버시

기초 모델의 부상 및 추론 작업에 대한 이들의 적용은 그들의 안전성과 신뢰성을 보장하기 위한 중요한 필요성을 강조했다(Huang et al., 2023).

강건성 갭(Shreya and Khapra, 2022), 백도어 공격(Shen et al., 2021; Kurita et al., 2020), 피독(Carlini et al., 2023), 허위 정보(Nelson et al., 2008), 프라이버시 유출(Li et al., 2023), 정보의 무단 공개(Perez and Ribeiro, 2022) 등 다양한 의도된 공격이 확인되었다. 구체적으로, 백도어 공격은 훈련 데이터를 피독(Shen et al., 2021)하거나 모델 파라미터를 수정(Kurita et al., 2020)하는 등의 기법을 통해 기초 모델에 악성 지식을 주입하는 것을 포함한다.

프라이버시를 갖는 머신 러닝 모델들을 트레이닝하기 위한 가장 원칙적인 기법들 중 하나로서, 차등 프라이버시는 강화된 프라이버시 보호를 제공하는, 개별 트레이닝 예들의 세부사항들을 드러내지 않고 데이터세트들에 대한 트레이닝을 허용한다(Shi et al., 2022; Behnia et al., 2022). 적대적 공격을 방어하는 또 다른 효과적인 방법은 적대적 훈련에 의한 것으로, 이는 모델 입력에 추가된 악의적이면서도 인간의 보이지 않는 섭동에 직면할 때 또 다른 보안 계층을 제공할 수 있다(Li et al., 2023; Li and Spratling, 2023).

일부 저작권 우려에 응답하여, Kirchenbauer 등(2023)은 독점 언어 모델을 위해 특별히 설계된 워터마킹 프레임워크를 소개한다. 이 프레임워크는 텍스트 품질에 대한 영향을 최소화하면서 워터마크의 삽입을 가능하게 하고 효율적인 오픈 소스 알고리즘을 사용하여 워터마크의 검출을 용이하게 하여 언어 모델 API 또는 매개변수에 액세스할 필요가 없다.

### 해석 및 투명성

또한, 기초 모델(Liao and Vaughan, 2023)의 투명성 및 해석 가능성을 높일 필요가 있다. 이러한 모델이 복잡해지고 정교해짐에 따라 추론 과정과 결과에 영향을 미치는 요인을 이해하는 것이 점점 더 중요해지고 있다.

때때로, 파운데이션 모델들은 독성 콘텐츠를 생성하는데, 이는 폭력을 조장하고 인포데믹을 유발할 수 있다(Bender et al., 2021; Weidinger et al., 2021). 그들은 부주의하게 민감한 정보를 공개하여 사생활과 보안을 위태롭게 할 수 있다. 추가적으로, LLM은 의도적 및 비의도적으로 모두 잘못된 정보의 보급에 기여할 수 있다(Pan et al., 2023; Buchanan et al., 2021; Kreps et al., 2022; Zhou et al., 2023). 기초 모델의 복잡하고 불확실한 특성은 이러한 문제를 더욱 복잡하게 만든다. 이러한 모델들은 다양한 컨텍스트에 걸쳐 광범위한 태스크를 수행할 수 있는 현저한 능력을 나타낸다(Bommasani 등, 2021). 그러나 그들의 거대하고 불투명한 아키텍처는 능력과 행동에 대한 포괄적인 이해를 방해하여 의사 결정 과정과 잠재적인 편향을 확인하기 어렵다. 이러한 투명성의 결여는 모델 해석 가능성, 통제 및 책임성에 대한 우려를 불러일으킨다.

모델 해석 가능성을 위한 기술과 프레임워크를 개발하는 것은 투명성과 책임성에 관한 우려를 해결하는 데 도움이 될 수 있다.

### Autonomous Language Agent

논리 추론 능력은 체화된 환경에서 복잡한 작업을 달성하는 데 중요하며 체화된 지능에서 중요한 역할을 한다(Dasgupta et al., 2022). Foundation Models은 in-context learning의 과정을 통해 추론 및 유연성에 대한 강력한 능력을 발휘해 왔다(Yang et al., 2023). 보이저 및 DEPS와 같은 최근의 연구는 마인크래프트에서 계획을 위한 LLM의 사용을 탐구했다(Wang et al., 2023, 2023). DEPS는 LLMs에 기초한 대화형 계획 접근법을 구체적으로 제안한다(Wang et al., 2023). LLM은 또한 여분의 도메인 지식을 필요로 하지 않고 자연 언어 명령어에 기초하여 직접 액션 시퀀스를 생성하는 가능성을 보여주었다(Li 등, 2022). 상식적 지식을 갖는 구체화된 에이전트들을 장착하는 것은 다양한 환경들에서 복잡한 인간 명령들의 성공적인 완성을 위해 중요하다(Wu et al., 2023).

자율 에이전트들에 대한 추론의 맥락에서, 핵심 특성들이 있다:

* 무한 작업 능력: 기본 모델은 사전에 정의 되거나 예상 되지 않은 작업에서도 광범위한 작업을 처리할 수 있는 능력을 가진 에이전트에 권한을 부여 합니다. 이러한 유연성은 에이전트가 컨텍스트 및 사용자의 특정 요구에 대한 그들의 이해에 기초하여 태스크를 동적으로 생성할 수 있게 한다.
* 자율 작업 생성: 기본 모델 추론을 통해 에이전트는 주어진 컨텍스트 내에서 새로운 작업을 자율적으로 생성할 수 있습니다. 이 기능은 에이전트가 주도권을 갖고, 기회를 파악하고, 사용자에게 관련 작업을 제안할 수 있도록 지원합니다. 그들은 변화하는 상황에 적응하고 대응할 수 있어 사용자 요구 사항을 충족시키는 데 보다 다재다능하고 능동적이며 효율적이다.
* 가치 시스템: 자율 에이전트는 미리 훈련된 기반 모델에 의해 권한을 부여받은 가치 시스템에 의해 구동되며, 이는 작업 생성의 기반이 됩니다. 이 가치 체계는 우선 순위, 선호도, 윤리적 고려 사항 등의 요소를 고려하여 에이전트의 의사 결정 과정을 안내한다. 기초 모델의 기능을 활용함으로써 에이전트는 인간 가치와 일치하는 정보에 입각한 결정을 내릴 수 있어 책임감 있고 윤리적인 행동을 보장할 수 있다.
* 월드 모델: 기초 모델은 또한 현실 세계를 나타내고 에이전트의 상호 작용 및 추론의 기초가 되는 월드 모델로 활용될 수 있다. 이 포괄적인 모델을 통해 에이전트는 컨텍스트를 이해하고 자연 언어 입력을 해석하며 적절한 응답 또는 동작을 생성할 수 있다. 기초 모델을 그들의 세계 모델로 하여, 에이전트는 그들의 환경 내에서 효과적으로 탐색하고 동작할 수 있어, 지능적으로 상호작용하고 사용자 요구에 응답하는 능력을 향상시킨다.

기반 모델을 활용함으로써 자율 에이전트는 사용자와의 보다 의미 있고 효과적인 상호 작용을 촉진하고, 의도 및 요구를 더 잘 이해하고, 그에 따라 관련 작업을 생성할 수 있다. 이 접근법은 맥락 이해, 인간과 유사한 추론 및 개인화된 도움과 같은 분야에서 연구를 위한 유망한 길을 열어준다. 궁극적으로, 그것은 전반적인 사용자 경험을 향상시키고 더 정교하고 지능적인 AI 시스템의 개발을 가능하게 한다.

기초 모델은 추론 능력을 감안할 때 인간-컴퓨터 상호 작용 및 구체화된 지능에 적용할 수 있는 상당한 잠재력을 가지고 있다. 사용자 입력에 동적으로 응답하고 그에 따라 그들의 행동을 적응시킬 수 있는 상호작용 및 적응 시스템을 생성하기 위해 활용될 수 있다. 여기에는 사용자 상호 작용에서 학습하고 시간이 지남에 따라 지식과 행동을 업데이트할 수 있는 모델을 개발하는 것이 포함됩니다. 파운데이션 모델이 사용자와 적극적으로 참여하고 선호도와 요구에 적응할 수 있도록 함으로써 보다 개인화되고 사용자 중심의 인간-컴퓨터 상호 작용 경험을 만들 수 있다.

### Science 추론

향후 작업은 또한 오디오 질문 응답(AQA)(Fayek and Johnson, 2019)에 의해 입증된 바와 같이, 멀티모달 질문-응답 태스크 또는 사운드 추론(Brandt and McClure, 2011)에서의 시간적 추론에 대한 연구를 기반으로 할 수 있다. 연구자들은 청각 정보를 기반으로 추론하고 추론할 수 있는 기초 모델을 이해하고 개발하는 데 더 깊이 파고들 수 있다. 이는 오디오 기반 의사 결정 시스템, 환경 모니터링, 오디오 장면 이해 등의 영역에서 시사점을 줄 수 있다.

또한, 다중 모드 추론의 적용은 특히 유전자 서열 분석의 맥락에서 의학적 추론 및 진단과 같은 영역으로 확장될 수 있다. 이것은 유전적 장애의 식별, 개인화된 의학 및 잠재적인 치료법의 탐색에 도움이 될 수 있다.

전반적으로, 향후 연구는 기초 모델에서 멀티모달 추론 능력을 발전시키는 데 초점을 맞출 수 있다. 이러한 노력은 다양한 분야에서 보다 지능적이고 상황 인식 시스템의 개발에 기여할 수 있다.

### Super Alignment

OpenAI1에 따르면 초지능 정렬은 가장 중요한 다음 기계 학습 문제이다. 그러나 잠재적으로 초지능적인 AI 시스템의 제어 및 정렬을 보장하는 것은 중요한 문제를 제기합니다. 인간 피드백으로부터의 강화 학습(RLHF)과 같은 현재의 기술들은 인간의 감독 및 추론에 크게 의존한다. AI 시스템이 인간의 지능을 능가함에 따라 인간의 감독은 부적절하게 되어 정렬 연구의 새로운 과학적, 기술적 돌파구가 필요하다. 기존의 정렬 기법은 인간의 추론과 감독의 한계로 인해 초지능으로 확장되지 않을 것이다. 그들이 불량하게 되는 것을 막기 위해 고도로 지능화된 AI 시스템을 제어하고 조종할 것이라는 전망은 아직 해결되지 않은 과제로 남아 있다. 인간의 능력을 능가하는 이러한 추론 시스템을 감독하는 신뢰할 수 있는 수단이 없으면 인간의 의도와의 정렬을 보장하는 것이 점점 더 어려워진다.

각주 1: [https://openai.com/blog/introducing-superalignment](https://openai.com/blog/introducing-superalignment)

인간 지능을 능가하는 추론 시스템이 인간의 의도를 준수하도록 하는 과제를 해결하기 위한 한 가지 접근법은 대략적인 인간 수준의 자동화된 정렬 연구자를 개발하는 것이다. 이러한 시스템을 생성함으로써, 정렬 노력을 스케일링하고 초지능을 반복적으로 정렬하기 위해 광범위한 계산 자원을 활용하는 것이 가능해진다.

## 7 Conclusion

이 조사는 추론 분야에서 기초 모델의 진화 경로를 조명하여 초기 단계에서 현재 발전까지의 복잡성과 효능의 식별 가능한 진행을 보여준다. 우리는 데이터 중심 사고에서 만들어진 놀라운 진전을 인정하지만, 큰 모델의 강점과 한계를 객관적으로 인식하는 것이 중요하다. 이러한 맥락에서 해석 가능성과 보안성을 높이는 것의 중요성을 강조하는 것이 필수적이다. 우리는 또한 이 연구에서 조사된 모든 논문을 통해 기초 모델의 추론 능력을 일관성 있는 초인적 수준(예를 들어 IMO 메달을 따거나 열린 수학적 문제를 해결할 수 있음)으로 추진하는 방법에 대한 합의가 아직 이루어지지 않았다는 점에 주목한다.

결론적으로, 기초 모델은 추론 작업에서 흥미로운 가능성을 제공하지만, 그들의 개발과 적용에 비판적 시각으로 접근하는 것이 필수적이다. LLM 기반 추론과 관련된 도전, 한계 및 위험을 인정하는 것이 중요하다. 그렇게 함으로써 이 분야에서 책임감 있고 사려 깊은 발전을 도모하여 강력하고 신뢰할 수 있는 추론 시스템의 개발을 보장할 수 있습니다.

[MISSING_PAGE_EMPTY:98]

* Amini et al. (2019) Amini A, Gabriel S, Lin P, et al. (2019) Mathqa: Towards interpretedable math word problem solving with operation-based formalisms. arXiv preprint arXiv:190513319
* Anand et al. (2023) Anand Y, Nussbaum Z, Duderstadt B, et al. (2023) Gpt4all: Training a assistant-style chatbot with large scale data distillation from gpt-3.5-turbo. [https://github.com/nomic-ai/gpt4all] (https://github.com/nomic-ai/gpt4all)
* Anil 등(2023) Anil R, Dai AM, Firat O, 등(2023) Palm 2 기술 보고서. 2305.10403
*인류(2023)인류(2023)클로드 도입
* Araci(2019) Araci D(2019) Finbert: 사전 훈련된 언어 모델을 이용한 금융 감성 분석. arXiv preprint arXiv:190810063
* Arandjelovic and Zisserman (2017) Arandjelovic R, Zisserman A (2017) Look, listen and learn. In: Proceedings of the IEEE International conference on computer vision, pp 609-617
* Ardila 등(2020) Ardila R, Branson M, Davis K, 등(2020) Common Voice: A Massively-Multilingual Speech Corpus. In: Proceedings of the Twelfth Language Resources and Evaluation Conference, pp 4218-4222
* Aribandi et al. (2022) Aribandi V, Tay Y, Schuster T, et al. (2022) Ext5: Towards extreme multi-task scaling for transfer learning. In: International Conference on Learning Representations, URL [https://openreview.net/forum?id=Vzh1BFUCiIX](https://openreview.net/forum?id=Vzh1BFUCiIX)
* Aroca-Ouellette 등(2021) Aroca-Ouellette S, 백 C, 론콘 A, 등(2021) Prost: 공간과 시간을 통한 물체의 물리적 추론. 2106.03634
* Aryan 등(2023) Aryan A, Nain AK, McMahon A, 등(2023) The costly dilemma: Generalization, evaluation and cost-optimal deployment of large language models. 2308.08061
* Asai 등(2020) Asai A, Hashimoto K, Hajishirzi H, 등(2020) Learning to retrieve reasoning path over wikipedia graph for question answer. In: International Conference on Learning Representations, URL [https://openreview.net/forum?id=SJgVHkrYDH](https://openreview.net/forum?id=SJgVHkrYDH)
* Austin 등(2021) Austin J, Odena A, Nye M, 등(2021) 대형 언어 모델을 이용한 프로그램 합성. arXiv preprint arXiv:210807732
* Azerbayev 등(2023) Azerbayev Z, Schoelkopf H, Paster K, 등(2023) Llemma: An open language model for mathematics. 2310.10631
* Babu et al.(2022) Babu A, Wang C, Tjandra A, et al.(2022) XLS-R: Self-supervised cross-lingual speech representation learning at scale. In: INTERSPEECH, pp 2278-2282
* Bach 등(2022) Bach S, Sanh V, Yong ZX, 등(2022) PromptSource: An integrated development environment and repository for natural language prompts. In: Computational Linguistics Association의 60차 연차총회 진행: SystemDemonations. Association for Computational Linguistics, Dublin, Ireland, pp 93-104, [https://doi.org/10.18653/v1/2022.acl-demo.9](https://doi.org/10.18653/v1/2022.acl-demo.9), URL [https://aclanthology.org/2022.acl-demo.9](https://aclanthology.org/2022.acl-demo.9)
* Baevski 등(2020) Baevski A, Zhou Y, Mohamed A, 등(2020) wav2vec 2.0: A framework for self-supervised learning of speech representation. 신경 정보 처리 시스템들 33:12449-12460의 발전들
* Baevski 등(2022) Baevski A, Hsu WN, Xu Q, 등(2022) Data2vec: A general framework for self-supervised learning in speech, vision and language. In: International Conference on Machine Learning, PMLR, pp 1298-1312
* Bai 등(2022) Bai Y, Kadavath S, Kundu S, 등(2022) Constitutional ai: ai 피드백으로부터의 무해함. 2212.08073
* Bakhtin 등(2019) Bakhtin A, van der Maaten L, Johnson J, 등(2019) Phyre: A new benchmark for physical reasoning. 신경정보처리시스템 32의 발전
* Bakker et al.(2022) Bakker MA, Chadwick MJ, Sheahan HR, et al.(2022) Fine-tuning language models to find agreement between humans with various preference. 2211.15006
* Balashankar and Subramanian (2021) Balashankar A, Subramanian L (2021) Learning faithful representations of causal graph. In : 제59회 전산언어학회 연차총회 및 제11회 자연어처리 국제공동회의 회보(제1권: 장문) Association for Computational Linguistics, Online, pp 839-850, [https://doi.org/10.18653/v1/2021.acl-long.69](https://doi.org/10.18653/v1/2021.acl-long.69), URL [https://aclanthology.org/2021.acl-long.69](https://aclanthology.org/2021.acl-long.69)
* Ban et al. (2023) Ban T, Chen L, Wang X, et al. (2023) From query tools to causal architects: Harnessing large language models for advanced causal discovery from data. arXiv preprint arXiv:230616902
* Bansal et al. (2019) Bansal K, Loos S, Rabe M, et al. (2019) HOList: An environment for machine learning of higher order logic theorem prove. In: Chaudhuri K, Salakhutdinov R(eds) Proceedings of the 36th International Conference on Machine Learning, Proceedings of Machine Learning Research, vol 97. PMLR, pp 454-463, URL [https://proceedings.mlr.press/v97/bansal19a.html](https://proceedings.mlr.press/v97/bansal19a.html)
* Bao et al.(2023) Bao F, Nie S, Xue K, et al.(2023) One transformer fits all distribution in multi-modal diffusion at scale. 2303.06555
* Bao 등(2021) Bao H, Dong L, Piao S, 등(2021) Beit: Bert pre-training of image transformers. arXiv preprint arXiv:210608254
* Barbieri 등(2021) Barbieri F, Anke LE, Camacho-Collados J(2021) Xlm-t: 다국어 언어 모델 in twitter for sentiment analysis and beyond. arXiv preprint arXiv:210412250Barras B, Boutin S, Cornes C, et al. (1997) The coq proof assistant reference manual: Version 6.1. PhD thesis, Inria
* Bavarian et al.(2022) Bavarian M, Jun H, Tezak N, et al.(2022) Efficient training of language models to fill in the middle. arXiv preprint arXiv:220714255
* Bear 등(2021) Bear DM, Wang E, Mrowca D, 등(2021) Physion: 인간과 기계에서 시각으로부터 물리적 예측을 평가하는 것. arXiv preprint arXiv:210608261
* Behnia et al. (2022) Behnia R, Ebrahimi MR, Pacheco J, et al. (2022) Ew-tune: Differential privacy를 갖는 큰 언어 모델들을 개인적으로 미세 조정하기 위한 프레임워크. In: 2022 IEEE International Conference on Data Mining Workshops (ICDMW), IEEE, pp 560-566
* Bender et al. (2021) Bender EM, Gebru T, McMillan-Major A, et al. (2021) On the risk of stochastic parrots: Can language models are too big? In: Proceedings of 2021 ACM Conference on Fairness, Accountability and Transparency. Association for Computing Machinery, New York, NY, USA, FAccT '21, p 610-623, [https://doi.org/10.1145/3442188.3445922](https://doi.org/10.1145/3442188.3445922), URL [https://doi.org/10.1145/3442188.3445922](https://doi.org/10.1145/3442188.3445922)
* Bengio (2017) Bengio Y (2017) 의식 이전입니다. arXiv preprint arXiv:170908568
* Berant et al. (2013) Berant J, Chou A, Frostig R, et al. (2013) Semantic parsing on freebase from question-answer pairs. In: Proceedings of the 2013 conference on empirical methods in natural language processing, pp 1533-1544
* Berghofer and Strecker (2004) Berghofer S, Strecker M (2004) Extracting a formal verified, fully executable compiler from the proof assistant. 이론 컴퓨터 과학 82(2):377-394의 전자 노트
* Berglund 등(2023) Berglund L, Tong M, Kaufmann M, 등(2023) The reversal curse: Llms trained on" a is b" fail to learn" b is a. arXiv preprint arXiv:230912288
* Berka(2020) Berka P(2020) Rule-based and Case-based reasoning을 이용한 감성 분석. 지능 정보 시스템 55(1):51-66 저널
* Berzonsky(1978) Berzonsky MD(1978) 청소년기의 형식적 추론: 대안적 관점. 청소년기 13(50):279
* Bhagavatula et al. (2019) Bhagavatula C, Bras RL, Malaviya C, et al. (2019) Abductive 상식 추론. arXiv preprint arXiv:190805739
* Bi et al.(2023) Bi K, Xie L, Zhang H, et al.(2023) Accurate Medium-range global weather forecasting with 3d neural networks. Nature pp 1-6
* Bisk 등(2020) Bisk Y, Zellers R, Gao J, 등(2020) Piqa: Reasoning about physical commonsense in natural language. In: Proceedings of the AAAI conference on artificial intelligence, pp 7432-7439Black S, Gao L, Wang P, et al.(2021) GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow. [https://doi.org/10.5281/zenodo.5297715] (https://doi.org/10.5281/zenodo.5297715), URL [https://doi.org/10.5281/zenodo.5297715](https://doi.org/10.5281/zenodo.5297715) 이 소프트웨어를 사용하는 경우 이러한 메타데이터를 사용하여 인용하십시오.
* 대규모 언어 모델 만들기의 도전과 관점에 대한 워크샵입니다. Association for Computational Linguistics, virtual+Dublin, pp 95-136, [https://doi.org/10.18653/v1/2022.bigscience-1.9](https://doi.org/10.18653/v1/2022.bigscience-1.9), URL [https://aclanthology.org/2022.bigscience-1.9](https://aclanthology.org/2022.bigscience-1.9)
* Bommasani 등(2021) Bommasani R, Hudson DA, Adeli E, 등(2021) On the opportunities and risks of foundation models. 2108.07258
* Boratko 등(2020) Boratko M, Li XL, Das R, 등(2020) Protoqa: A question answer dataset for prototypical common-sense reasoning. arXiv preprint arXiv:200500771
* Bottou et al.(2013) Bottou L, Peters J, Quinonero-Candela J, et al.(2013) Counterfactual reasoning and learning systems: The example of computational advertising. 기계학습연구논문집 14(11)
* Bowman (2023) Bowman SR (2023) 대형 언어 모델에 대해 알아야 할 8 가지 사항입니다. arXiv preprint arXiv:230400612
* Brandt and McClure (2011) Brandt A, McClure R (2011) Sound reasoning
* Brewka (2012) Brewka G (2012) Default Reasoning, Springer US, Boston, MA, pp 915-917. [https://doi.org/10.1007/978-1-4419-1428-6_634](https://doi.org/10.1007/978-1-4419-1428-6_634), URL [https://doi.org/10.1007/978-1-4419-1428-6_634](https://doi.org/10.1007/978-1-4419-1428-6_634)
* Brohan 등(2022) Brohan A, Brown N, Carbajal J, 등(2022) Rt-1: Robotics transformer for real-world control at scale. arXiv preprint arXiv:221206817
* Brohan 등(2023) Brohan A, Brown N, Carbajal J, 등(2023) Rt-2: Vision-language-action models transfer web knowledge to robotic control. In: TODO
* Brown et al. (2020) Brown T, Mann B, Ryder N, et al. (2020) Language models are few-shot learners. 신경 정보 처리 시스템들에서의 발전들 33:1877-1901
* Bubeck 등(2023) Bubeck S, Chandrasekaran V, Eldan R, 등(2023) Sparks of artificial general intelligence: Early experiments with gpt-4. 2303.12712
* Buchanan et al. (2021) Buchanan B, Lohn A, Musser M, et al. (2021) Truth, lies, and automation: 언어 모델이 어떻게 허위 정보를 변경할 수 있는가. URL: https://cset georgetown edu/publication/truth-lies-and-automation/(visited on 10/13/2021)Buel GR, Walters KJ (2022) Can alphafold2 can missense mutations on structure? 자연구조 및 분자생물학 29(1):1-2
* Bui 등(2023) Bui ND, Le H, Wang Y, 등(2023) Codeff: One-stop transformer library for the state-of-the-art code llm. arXiv preprint arXiv:230600029
* Burgess 등(2019) Burgess CP, Matthey L, Watters N, 등(2019) Monet: Unsupervised scene decomposition and representation. arXiv preprint arXiv:190111390
* Byeon et al.(2022) Byeon M, Park B, Kim H, et al.(2022) Coyo-700m: Image-text pair dataset
* Byrne (2007) Byrne RM (2007) 합리적 상상력: 사람들이 현실에 대 한 대안을 만드는 방법입니다. MIT 프레스
* Byrne and Tasso(1999) Byrne RM, Tasso A(1999) Ductive reasoning with factual, possible and counterfactual conditionals. Memory & cognition 27:726-740
* Cai 등(2021) Cai LW, Dai WZ, Huang YX, 등(2021) Abductive learning with ground knowledge base. In: IJCAI, pp 1815-1821
* Cai and Yates (2013) Cai Q, Yates A (2013) Large-scale semantic parsing via schema matching and lexicon extension. In: 제51회 전산언어학회 연차총회 회보(제1권: 장문) Association for Computational Linguistics, Sofia, Bulgaria, pp 423-433, URL [https://aclanthology.org/P13-1042](https://aclanthology.org/P13-1042)
* Cao et al.(2023) Cao Y, Xu X, Sun C, et al.(2023) Segment any anomaly without training via hybrid prompt regularization. arXiv preprint arXiv:230510724
* Carlini 등(2023) Carlini N, Jagielski M, Choquette-Choo CA, 등(2023) Poisoning web-scale training datasets는 실용적이다. arXiv preprint arXiv:230210149
* Carpenter 등(1996) Carpenter TP, Fennema E, Franke ML(1996) Cognitively guided instruction: A knowledge base for reform in primary mathematics instruction. 초등학교 학술지 97(1):3-20
* Chai et al. (2022) Chai Y, Wang S, Pang C, et al. (2022) Ernie-code: Beyond English-centric cross-lingual pretraining for programming languages. arXiv preprint arXiv:221206742
* Chandel 등(2022) Chandel S, Clement CB, Serrato G, 등(2022) Training and Evaluation a jupyter notebook data science assistant. arXiv preprint arXiv:220112901
* Chang et al. (2021) Chang TY, Liu Y, Gopalakrishnan K, et al. (2021) Go beyond plain fine-tuning: Improving pretrained models for social commonsense. 2105.05913
* Changpinyo et al. (2021) Changpinyo S, Sharma P, Ding N, et al. (2021) Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 3558-3568Charalambous Y, Tihanyi N, Jain R, et al. (2023) A new era in software security: Towards self-healing software via large language models and formal verification. arXiv preprint arXiv:230514752
* Chen 등(2023a) Chen C, Feng X, Zhou J, 등(2023a) Federated large language model: A position paper. 2307.08925
* Chen 등(2023b) Chen G, Dong S, Shu Y, 등(2023b) Autoagents: A framework for automatic agent generation. arXiv preprint arXiv:230917288
* Chen 등(2019) Chen J, Lin St, Durrett G(2019) Multi-hop question answer via reasoning chains. arXiv preprint arXiv:191002610
* Chen 등(2021a) Chen J, Tang J, Qin J, 등(2021a) Geoqa: 멀티모달 수치 추론을 향한 기하학적 질의 응답 벤치마크. arXiv preprint arXiv:210514517
* Chen et al.(2022a) Chen J, Hu Z, Sun S, et al.(2022a) Interpretable rna foundation model from unannotated data for high accurate rna structure and function predictions. bioRxiv pp 2022-08
* Chen et al. (2022b) Chen J, Li T, Qin J, et al. (2022b) UniGeo: 수식 재구성을 통한 기하 논리적 추론 통합. In: 2022년 자연어처리 실증방법에 관한 회의의 진행. Association for Computational Linguistics, Abu Dhabi, United Arab Emirates, pp 3313-3323, URL [https://aclanthology.org/2022.emnlp-main.218](https://aclanthology.org/2022.emnlp-main.218)
* Chen 등(2023c) Chen K, Li J, Wang K, 등(2023c) 화학 합성에서 반응 조건 추천을 위한 자동 ai 제제를 향한다. arXiv preprint arXiv:231110776
* Chen 등(2023d) Chen K, Liu Z, Hong L, 등(2023d) Mixed autoencoder for self-supervised visual representation learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 22742-22751
* Chen 등(2023e) Chen L, Wu P, Chitta K, 등(2023e) End-to-end 자율 주행: Challengees and Frontiers. arXiv preprint arXiv:230616927
* Chen et al. (2021b) Chen M, Tworek J, Jun H, et al. (2021b) Evaluating large language models trained on code. arXiv preprint arXiv:210703374
* Chen et al.(2022c) Chen S, Wang C, Chen Z, et al.(2022c) WavLM: Large-scale self-supervised pre-training for full stack speech processing. IEEE Journal in Selected Topics in Signal Processing 16(6):1505-1518
* Chen et al.(2023f) Chen S, Wong S, Chen L, et al.(2023f) Extending context window of large language models via positional interpolation. 2306.15595Chen W, Zha H, Chen Z, et al.(2020a) HybridQA: A dataset of multi-hop question answering over tableular and textual data. In: Association of Association for Computational Linguistics: EMNLP 2020. Association for Computational Linguistics, Online, pp 1026-1036, [https://doi.org/10.18653/v1/2020.findings-emnlp.91](https://doi.org/10.18653/v1/2020.findings-emnlp.91), URL [https://aclanthology.org/2020.findings-emnlp.91](https://aclanthology.org/2020.findings-emnlp.91)
* Chen 등(2022d) Chen W, Ma X, Wang X, 등(2022d) Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:221112588
* Chen 등(2023g) Chen W, Yin M, Ku M, 등(2023g) Theoremqa: A theorem-driven question answering dataset. arXiv preprint arXiv:230512524
* Chen 등(2023h) Chen X, Ding M, Wang X, 등(2023h) Context autoencoder for self-supervised representation learning. International Journal of Computer Vision pp 1-16
* Chen et al.(2023i) Chen X, Lin M, Scharli N, et al.(2023i) Teaching large language models to self-debug. 2304.05128
* Chen et al.(2020b) Chen Y, Li L, Yu L, et al.(2020b) UNITER: universal image-text representation learning. In: ECCV, pp104-120
* Chen et al.(2023j) Chen Y, Qian S, Tang H, et al.(2023j) Longlora: Long-context large language model의 효율적인 fine-tuning. arXiv:230912307
* Chen et al.(2023k) Chen Y, Zhang S, Han B, et al.(2023k) Lightweight in-context tuning for multimodal unified models. 2310.05109
* Chen et al.(2021c) Chen Z, Chen W, Smiley C, et al.(2021c) Finqa: 재무 데이터에 대한 수치 추론의 데이터세트. EMNLP 2021의 진행사항
* Chen 등(2022e) Chen Z, Yi K, Li Y, 등(2022e) Compby: 비디오로부터의 객체 및 이벤트의 구성 물리적 추론. arXiv preprint arXiv:220501089
* Chen et al.(2023l) Chen Z, Ding M, Shen Y, et al.(2023l) Multi-task heterogeneous training을 통한 효율적인 범용 모듈러 비전 모델. arXiv preprint arXiv:230617165
* Chen et al.(2023m) Chen Z, Shen Y, Ding M, et al.(2023m) Mod-squad: 모듈형 멀티태스크 학습자로 전문가의 혼합물 설계. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 11828-11837
* Chen et al.(2023n) Chen Z, Zhou K, Zhang B, et al.(2023n) Chatcot: Tool-augmented chain-of-thought reasoning on chat-based large language models. 2305.14323
* Cheng et al. (2023) Cheng Y, Li L, Xu Y, et al. (2023) Segment and track anything. arXiv preprint arXiv:230506558Cheng Z, Dong H, Wang Z, et al. (2022) HiTab: A hierarchical table dataset for question answer and natural language generation. In: 제60회 전산언어학회 연차총회 회보(제1권: 장문) Association for Computational Linguistics, Dublin, Ireland, pp 1094-1110, [https://doi.org/10.18653/v1/2022.acl-long.78](https://doi.org/10.18653/v1/2022.acl-long.78), URL [https://aclanthology.org/2022.acl-long.78](https://aclanthology.org/2022.acl-long.78)
* Cherti et al.(2023) Cherti M, Beaumont R, Wightman R, et al.(2023) Reproducible scaling laws for contrastive language-image learning. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 2818-2829
* Chiang 등(2023) Chiang WL, Li Z, Lin Z, 등(2023) Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality. URL [https://lmsys.org/blog/2023-03-30-vicuna/](https://lmsys.org/blog/2023-03-30-vicuna/)
* Chowdhery 등(2022) Chowdhery A, Narang S, Devlin J, 등(2022) Palm: Scaling language modeling with pathways. 2204.02311
* Christopoulou 등(2022) Christopoulou F, Lampouras G, Gritta M, 등(2022) Pangu-coder: Program synthesis with function-level language modeling. arXiv preprint arXiv:220711280
* Chu et al.(2021) Chu R, Chen Y, Kong T, et al.(2021) Icm-3d: Instantiated category modeling for 3d instance segmentation. IEEE 로보틱스 및 자동화 문자
* Chu et al.(2023a) Chu R, Liu Z, Ye X, et al.(2023a) Command-driven articulated object understanding and manipulation. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp 8813-8823
* Chu et al.(2023b) Chu R, Xie E, Mo S, et al.(2023b) Diffcomplete: Diffusion-based generative 3d shape completion. arXiv preprint arXiv:230616329
* Chung 등(2022) Chung HW, Hou L, Longpre S, 등(2022) Scaling instruction-finetuned language models. arXiv preprint arXiv:221011416
* Chung et al. (2019) Chung YA, Hsu WN, Tang H, et al. (2019) An unsupervised autoregressive model for speech representation learning. In: INTERSPEECH, pp 146-150
* Clark 등(2020) Clark P, Tafjord O, Richardson K(2020) Transformers as soft reasoner over language. arXiv preprint arXiv:200205867
* Clement et al.(2020) Clement CB, Drain D, Timcheck J, et al.(2020) Pymt5: 트랜스포머를 사용한 자연어 및 파이썬 코드의 다중 모드 번역. arXiv preprint arXiv:201003150
* Cobbe et al. (2021) Cobbe K, Kosaraju V, Bavarian M, et al. (2021) Training verifiers to solve mathematics word problems. arXiv preprint arXiv:211014168
* Cohen (1997) Cohen GH (1997) 정렬: 삽입 및 삭제를 설명 하는 단백질 좌표를 중첩 하는 프로그램입니다. Journal of applied crystallography 30(6):1160-1161* Collins and Michalski(1989) Collins A, Michalski R(1989) The logic ofausible reasoning: A core theory. 인지과학 13(1):1-49
* 컴퓨터(2023) 컴퓨터 T(2023) Redpajama: llama 트레이닝 데이터세트를 재현하기 위한 오픈소스 레시피. URL [https://github.com/togethercomputer/RedPajama-Data](https://github.com/togethercomputer/RedPajama-Data)
* Conover et al.(2023) Conover M, Hayes M, Mathur A, et al.(2023) Free dolly: Introduction the world first truly open instruction-tuning llm
* Creswell 등(2023) Creswell A, Shanahan M, Higgins I(2023) Selection-inference: 해석 가능한 논리적 추론을 위해 대형 언어 모델을 이용한다. In: 학습 표현에 대 한 11 번째 국제 회의, URL [https://openreview.net/forum?id=3Pf3Wg6o-A4](https://openreview.net/forum?id=3Pf3Wg6o-A4)
* Cropper et al. (2022) Cropper A, Dumancic S, Evans R, et al. (2022) Inductive logic programming at 30. Machine Learning pp 1-26
* Dai et al. (2023) Dai W, Liu Z, Ji Z, et al. (2023) Plausible may not faithful: Probing object hallucination in vision-language pre-training. In: 계산 언어학 협회의 유럽 제17차 회의 회보입니다. Association for Computational Linguistics, Dubrovnik, Croatia, pp 2136-2148, URL [https://aclanthology.org/2023.eacl-main.156](https://aclanthology.org/2023.eacl-main.156)
* Daniel (2017) Daniel K (2017) Thinking, fast and slow
* Dao et al. (2022) Dao T, Fu DY, Saab KK, et al. (2022) Hungry hungry huppos: Towards language modeling with state space models. arXiv preprint arXiv:221214052
* Das et al.(2021) Das P, Sercu T, Wadhawan K, et al.(2021) Accelerated antimicrobial discovery via deep generative models and molecular dynamics simulation. 자연 의공학 5(6):613-623
* Dasgupta et al.(2022) Dasgupta I, Kaeser-Chen C, Marino K, et al.(2022) Collaborating with language models for embodied reasoning. In: 언어 및 강화 학습에 대한 두 번째 워크샵, URL [https://openreview.net/forum?id=YoS-abmWjJc](https://openreview.net/forum?id=YoS-abmWjJc)
* De Raedt and Kersting(2010) De Raedt L, Kersting K(2010) Statistical relational learning. 기계학습 백과사전
* Deitke 등(2020) Deitke M, Han W, Herrasti A, 등(2020) Robothor: An open simulation-to-real embodied ai platform. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp 3164-3174
* Deng et al. (2009) Deng J, Dong W, Socher R, et al. (2009) Imagenet: A large-scale hierarchical image database. In:2009 IEEE conference on computer vision and pattern recognition, Ieee, pp 248-255Desai K, Kaul G, Aysola Z, et al.(2021) Redcaps: Web-curated image-text data created by the people, for the people. arXiv preprint arXiv:211111431
* Dettmers 등(2023) Dettmers T, Pagnoni A, Holtzman A, 등(2023) Qlora: 효율적인 finetuning of quantized llms. arXiv preprint arXiv:230514314
* Devlin 등(2019) Devlin J, Chang MW, Lee K, 등(2019) BERT: 언어 이해를 위한 심층 양방향 변압기의 사전 훈련. In: Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1(Long and Short Papers). Association for Computational Linguistics, Minneapolis, Minnesota, pp 4171-4186, [https://doi.org/10.18653/v1/N19-1423](https://doi.org/10.18653/v1/N19-1423), URL [https://aclanthology.org/N19-1423](https://aclanthology.org/N19-1423)
* Di 등(2023) Di P, Li J, Yu H, 등(2023) Codefuse-13b: A pretrained multi-lingual code large language model. arXiv preprint arXiv:231006266
* Ding et al. (2020) Ding D, Hill F, Santoro A, et al. (2020) Object-based attention for spatio-temporal reasoning: Outperforming neuro-symbolic models with flexible distributed architecture. arXiv preprint arXiv:201208508
* Ding et al. (2021a) Ding D, Hill F, Santoro A, et al. (2021a) Attention over learned object embeddings enables complex visual reasoning. In: Beygelzimer A, Dauphin Y, Liang P, et al. (eds) Advances in Neural Information Processing Systems, URL [https://openreview.net/forum?id=lHmhW2zmVN](https://openreview.net/forum?id=lHmhW2zmVN)
* Ding et al. (2023a) Ding J, Ma S, Dong L, et al. (2023a) Longnet: Transformers to 1,000,000,000 tokens. 2307.02486
* Ding et al.(2021b) Ding M, Chen Z, Du T, et al.(2021b) Dynamic visual reasoning by learning differentiable physics models from video and language. 신경정보처리시스템 34:887-899의 발전
* Ding 등(2022) Ding M, Xiao B, Codella N, 등(2022) Davit: Dual attention vision transformers. In: European Conference on Computer Vision, Springer, pp 74-92
* Ding 등(2023b) Ding M, Shen Y, Fan L, 등(2023b) Visual dependency transformers: Dependency tree emerges from reversed attention. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 14528-14539
* Ding 등(2023c) Ding M, Xu Y, Chen Z, 등(2023c) Embodied Concept learner: Self-supervised learning of concepts and mapping through instruction following. In: Conference on Robot Learning, PMLR, pp 1743-1754
* Ding et al. (2023d) Ding N, Chen Y, Xu B, et al. (2023d) Ultrachat: A large-scale auto-generated multi-round dialogue data. [https://github.com/thunlp/ultrachat] (https://github.com/thunlp/ultrachat)Ding N, Chen Y, Xu B, et al. (2023e) Enhancing chat language models by scaling of high-quality instruction conversation. arXiv preprint arXiv:230514233
* Ding 등(2023f) Ding X, Han J, Xu H, 등(2023f) Hilm-d: 자율 주행을 위한 멀티모달 대형 언어 모델에서의 고해상도 이해를 향하여. arXiv preprint arXiv:230905186
* Nascimento 및 de Lucena 및 CJP (2017) do Nascimento NM, de Lucena CJP (2017) Fiot: 사물 인터넷을 기반으로 하는 자기 적응 및 자기 조직화 애플리케이션을 위한 에이전트 기반 프레임워크입니다. 정보 과학 378:161-176. [https://doi.org/https://doi.org/10.1016/j.ins.2016.10.031](https://doi.org/https://doi.org/10.1016/j.ins.2016.10.031), URL [https://www.sciencedirect.com/science/article/pii/S0020025516313664](https://www.sciencedirect.com/science/article/pii/S0020025516313664)
* Dong et al.(2023a) Dong H, Xiong W, Goyal D, et al.(2023a) Raft: Reward ranked finetuning for generative foundation model alignment. arXiv preprint arXiv:230406767
* Dong et al. (2018) Dong L, Xu S, Xu B (2018) Speech-transformer: a no-recurrence sequence-to-sequence model for speech recognition. In: ICASSP, pp 5884-5888
* Dong et al.(2023b) Dong Y, Jiang X, Jin Z, et al.(2023b) Self-collaboration code generation via chatgpt. 2304.07590
* Dosovitskiy 등(2021) Dosovitskiy A, Beyer L, Kolesnikov A, 등(2021) An image is worth 16x16 words: Transformers for image recognition at scale. In: 머신러닝 국제회의
* Driess 등(2023) Driess D, Xia F, Sajjadi MSM, 등(2023) Palm-e: An embodied multimodal language model. In: arXiv preprint arXiv:2303.03378
* Drive(2023) DriveLM Contributors(2023) Drive on Language. URL [https://github.com/OpenDriveLab/DriveLM/](https://github.com/OpenDriveLab/DriveLM/)
* Du et al. (2022a) Du N, Huang Y, Dai AM, et al. (2022a) Glam: Mixed-of-experts를 갖는 언어 모델의 효율적인 스케일링. In: International Conference on Machine Learning, PMLR, pp 5547-5569
* Du et al. (2022b) Du W, Kim ZM, Raheja V, et al. (2022b) Read, revise, repeat: A system demonstration for human-in-the-loop iterative text revision. arXiv preprint arXiv:220403685
* Du et al.(2023) Du Y, Li S, Torralba A, et al.(2023) Improving factuality and reasoning in language models through multiagent debate. 2305.14325
* Dua 등(2019) Dua D, Wang Y, Dasigi P, 등(2019) DROP: 문단에 대한 이산 추론을 요구하는 읽기 이해 벤치마크. In: Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1(Long and Short Papers). Association for Computational Linguistics, Minneapolis, Minnesota, pp 2368-2378, [https://doi.org/10.18653/v1/N19-1246](https://doi.org/10.18653/v1/N19-1246), URL [https://aclanthology.org/N19-1246](https://aclanthology.org/N19-1246)* Echterhoff et al. (2023) Echterhoff J, Yan A, Han K, et al. (2023) Driving through the concept gridlock: Unraveling explainability bottlenecks. arXiv preprint arXiv:231016639
* Edalati et al. (2022) Edalati A, Tahaei M, Kobyzev I, et al. (2022) Krona: Parameter efficient tuning with kronecker adapter. arXiv preprint arXiv:221210650
* 어댑터 기반 피니튜닝을 통한 생성 모델의 멀티모달 증강. In: Association for Computational Linguistics: EMNLP 2022. Association for Computational Linguistics, Abu Dhabi, United Arab Emirates, pp 2416-2428, URL [https://aclanthology.org/2022.findings-emnlp.179](https://aclanthology.org/2022.findings-emnlp.179)
* Espeholt et al. (2022) Espeholt L, Agrawal S, Sonderby C, et al. (2022) Deep learning for 12 hour precipitation forecast. 자연통신 13(1):1-10
* Evans and Thompson(2004) Evans JSB, Thompson VA(2004) Informal reasoning: Theory and method. Canadian Journal of Experimental Psychology/Revue canadienne de psychologie experimentale 58(2):69
* Fan 등(2021) Fan A, Bhosale S, Schwenk H, 등(2021) Beyond English-centric multilingual machine translation. J Mach Learn Res 22(1)
* Fan 등(2023) Fan L, Krishnan D, Isola P, 등(2023) Improving clip training with language rewrites. arXiv preprint arXiv:230520088
* Fang 등(2020) Fang Y, Sun S, Gan Z, 등(2020) Hierarchical graph network for multi-hop question answer. In: Proceedings of 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) Association for Computational Linguistics, Online, pp 8823-8838, [https://doi.org/10.18653/v1/2020.emnlp-main.710](https://doi.org/10.18653/v1/2020.emnlp-main.710), URL [https://aclanthology.org/2020.emnlp-main.710](https://aclanthology.org/2020.emnlp-main.710)
* Fang et al.(2022) Fang Y, Wang S, Xu Y, et al.(2022) Leveraging knowledge in multiilingual commonsense reasoning. In: Association for Computational Linguistics: ACL 2022. Association for Computational Linguistics, Dublin, Ireland, pp 3237-3246, [https://doi.org/10.18653/v1/2022.findings-acl.255](https://doi.org/10.18653/v1/2022.findings-acl.255), URL [https://aclanthology.org/2022.findings-acl.255](https://aclanthology.org/2022.findings-acl.255)
* Fayek and Johnson (2019) Fayek HM, Johnson J (2019) Temporal reasoning via audio question answer. 1911.09655
* Feder 등(2021) Feder A, Oved N, Shalit U, 등(2021) CausaLM: Causal Model Explanation Through Counterfactual Language Models. 계산 언어 47(2):333-386. [https://doi.org/10.1162/coli_a_00404](https://doi.org/10.1162/coli_a_00404), URL [https://doi.org/10.1162/coli_a_00404](https://doi.org/10.1162/coli_a_00404), [https://direct.mit.edu/coli/article-pdf/47/2/333/1938107/coli_a_00404.pdf](https://direct.mit.edu/coli/article-pdf/47/2/333/1938107/coli_a_00404.pdf)
* Fedus 등(2022) Fedus W, Zoph B, Shazeer N(2022) Switch Transformers: 단순하고 효율적인 희소성을 갖는 조 단위의 파라미터 모델로 스케일링. Machine Learning Research23(1):5232-5270의 저널
* Fei et al. (2022) Fei N, Lu Z, Gao Y, et al. (2022) Towards the artificial general intelligence via the multimodal foundation model. 자연통신 13(1):3094
* Fennema et al. (1996) Fennema E, Carpenter TP, Franke ML, et al. (1996) A longitudinal study of learning to use children's thinking in mathematics instruction. 수학교육을 위한 학술지 27(4):403-434
* Firoozi 등(2023) Firoozi R, Sun J, Tucker J, 등(2023) Foundation models in robotics: Applications, challenges, and the future. arXiv preprint
* Flach and Kakas (2000) Flach PA, Kakas AC (2000) Abductive and Inductive Reasoning: Background and Issues, Springer Netherlands, Dordrecht, pp 1-27. [https://doi.org/10.1007/978-94-017-0606-3_1](https://doi.org/10.1007/978-94-017-0606-3_1), URL [https://doi.org/10.1007/978-94-017-0606-3_1](https://doi.org/10.1007/978-94-017-0606-3_1)
* Floyd(2004) Floyd J(2004) Wittgenstein on philosophy of logic and mathematics. 대학원 교수 철학 저널 25(2):227-287
* Fried et al.(2022) Fried D, Aghajanyan A, Lin J, et al.(2022) Incoder: A Generative model for code filling and synthesis. arXiv preprint arXiv:220405999
* Friedman(2023a) Friedman R(2023a) Large language model and logical reasoning. 백과사전 3(2):687-697
* 지식 이론에서 프리드만(2023b) 프리드만 R(2023b) 토큰화. 백과사전 3(1):380-386
* Frohberg and Binder (2021) Frohberg J, Binder F (2021) Crass: A novel data set and benchmark to test counterfactual reasoning of large language models. arXiv preprint arXiv:211211941
* Fu et al. (2022) Fu Y, Peng H, Sabharwal A, et al. (2022) Complexity-based prompting for multi-step reasoning. arXiv preprint arXiv:221000720
* Fu et al. (2023a) Fu Y, Peng H, Khot T, et al. (2023a) Improving language model negotiation with self-play and in-context learning from ai feedback. 2305.10142
* Fu et al.(2023b) Fu Y, Peng H, Ou L, et al.(2023b) Specializing smaller language models toward multi-step reasoning. arXiv preprint arXiv:230112726
* Fu 등(2023c) Fu Z, Lam W, Yu Q, 등(2023c) Decoder-only or encoder-decoder? 언어 모델을 정규화된 인코더-디코더로 해석합니다. arXiv preprint arXiv:230404052
* Fu 등(2023d) Fu Z, Yang H, So AMC, 등(2023d) On the effectiveness of parameter-efficient fine-tuning. In: Proceedings of the AAAI Conference on Artificial Intelligence, pp 12799-12807Furbach U, Holldobler S, Ragni M, et al. (2019) Cognitive reasoning: A personal view. KI-Kunstliche Intelligenz 33:209-217
* Gadre 등(2023) Gadre SY, Ilharco G, Fang A, 등(2023) Datacomp: next generation of multimodal datasets. arXiv preprint arXiv:230414108
* Gao 등(2023a) Gao D, Ji L, Zhou L, 등(2023a) Assistgpt: 계획, 실행, 검사 및 학습이 가능한 일반적인 멀티모달 어시스턴트. 2306.08640
* Gao et al. (2020) Gao L, Biderman S, Black S, et al. (2020) The pile: An 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:210100027
* Gao 등(2023b) Gao L, Madaan A, Zhou S, 등(2023b) Pal: Program-aided language models. In: International Conference on Machine Learning, PMLR, pp 10764-10799
* Gao 등(2023c) Gao P, Han J, Zhang R, 등(2023c) Llama-adapter v2: Parameter-efficient visual instruction model. arXiv preprint arXiv:230415010
* Garcez et al. (2015) Garcez Ad, Besold TR, De Raedt L, et al. (2015) Neural-symbolic learning and reasoning: contributions and challenges. 2015 AAAI 봄 심포지엄 시리즈
* Garcez et al. (2022) Garcez Ad, Bader S, Bowman H, et al. (2022) Neural-symbolic learning and reasoning: survey and interpretation. 신경상징 인공지능: 최신기술 342(1):327
* Garcez 등(2008) Garcez AS, Lamb LC, Gabbay DM(2008) Neural-symbolic cognitive reasoning. 스프링어 사이언스 & 비즈니스 미디어
* Gauthier et al. (2021) Gauthier T, Kaliszyk C, Urban J, et al. (2021) Tactictoe: learning to prove with tactics. 자동추론기 65:257-286
* Ge 등(2023) Ge Y, Hua W, Mei K, 등(2023) Openagi: llm이 도메인 전문가를 만날 때. 2304. 04370
* Gemmeke 등(2017) Gemmeke JF, Ellis DP, Freedman D, 등(2017) Audio set: An ontology and human-labeled dataset for audio events. In: 2017 IEEE International conference on acoustics, speech and signal processing (ICASSP), IEEE, pp 776-780
* Gendron 등(2023) Gendron G, Bao Q, Witbrock M, 등(2023) Large language models are not abstract reasoner. 2305.19555
* Geng 등(2023) Geng X, Gudibande A, Liu H, 등(2023) Koala: A dialogue model for academic research. 블로그 게시물, URL [https://bair.berkeley.edu/blog/2023/04/03/koala/](https://bair.berkeley.edu/blog/2023/04/03/koala/)
* Geva 등(2021) Geva M, Khashabi D, Segal E, 등(2021) Did aristotle used a laptop? 암묵적 추론 전략을 가진 질의 응답 벤치마크 계산 언어 연합의 트랜잭션 9:346-361. [https://doi.org/10.1162/tacl_a_00370](https://doi.org/10.1162/tacl_a_00370), URL [https://aclanthology.org/2021.tacl-1.21](https://aclanthology.org/2021.tacl-1.21)Girdhar R, Ramanan D (2020) Cater: 구성 작업 및 시간 추론을 위한 진단 데이터 세트. In : ICLR
* Girdhar 등(2022) Girdhar R, Singh M, Ravi N, 등(2022) Omnivore: A single model for many visual modalities. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 16102-16112
* Girdhar 등(2023a) Girdhar R, El-Nouby A, Liu Z, 등(2023a) Imagebind: One embedding space to bind them all. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 15180-15190
* Girdhar 등(2023b) Girdhar R, El-Nouby A, Singh M, 등(2023b) Omnimae: Single model masked pretraining on images and videos. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 10406-10417
* Gou et al. (2023) Gou Z, Shao Z, Gong Y, et al. (2023) Critic: Large language models can self-correcting with tool-interactive critiquing. 2305.11738
* gravitas/auto gpt (2023) gravitas/auto gpt S (2023) gpt-4를 완전히 자율적으로 만들려는 실험적 오픈 소스 시도입니다. 2305.16291
* Gramopadhye 및 Szafir(2022) Gramopadhye M, Szafir D(2022) 환경 인식 언어 모델을 이용하여 실행 가능한 액션 플랜을 생성하는 단계. arXiv preprint arXiv:221004964
* Gu 등(2021) Gu A, Goel K, Re C(2021) 구조화된 상태 공간을 갖는 긴 시퀀스를 효율적으로 모델링. arXiv preprint arXiv:211100396
* Gu et al. (2023a) Gu J, Han Z, Chen S, et al. (2023a) A systematic survey of prompt engineering on vision-language foundation models. 2307.12980
* Gu et al. (2023b) Gu Y, Dong L, Wei F, et al. (2023b) Knowledge distillation of large language models. 2306.08543
* Gulati et al. (2020) Gulati A, Qin J, Chiu CC, et al. (2020) Conformer: Convolution-augmented transformer for speech recognition. In: INTERSPEECH, pp 5036-5040
* Guo 등(2023a) Guo J, Li J, Li D, 등(2023a) Image to textual prompts: Zero-shot vqa with frozen large language models. 2212.10846
* Guo et al.(2023b) Guo Z, Zhang R, Zhu X, et al.(2023b) Point-bind & point-llm: Aligning point cloud with multi-modality for 3d understanding, generation, and instruction following. arXiv preprint arXiv:230900615
* Gupta 등(2022) Gupta A, Gu A, Berant J(2022) Diagonal 상태 공간은 구조화된 상태 공간만큼 효과적이다. 신경정보처리시스템의 발전
* Gupta 등(2019) Gupta N, Lin K, Roth D, 등(2019) Neural module networks for reasoning over text. arXiv preprint arXiv:191204971Gupta T, Kembhavi A (2022) Visual Programming: Composition visual reasoning without training. 2211.11559
* Guzhov 등(2022) Guzhov A, Raue F, Hees J, 등(2022) Audioclip: clip to image, text and audio. In: ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE, pp 976-980
* Halpern (2016) Halpern JY (2016) 실제 인과 관계입니다. 미티 프레스
* Han et al.(2021) Han JM, Rute J, Wu Y, et al.(2021) Proof artifact co-training for theorem proving with language models. arXiv preprint arXiv:210206203
* Han et al.(2022) Han S, Schoelkopf H, Zhao Y, et al.(2022) Folio:Natural language reasoning with first-order logic. 2209.00840
* Hao et al. (2023a) Hao S, Gu Y, Ma H, et al. (2023a) Reasoning with language model is planning with world model. 2305.14992
* Hao 등(2023b) Hao S, Liu T, Wang Z, 등(2023b) Toolkengpt: Augmenting frozen language models with massive tools via tool embedding. 2305.11554
* Harrison (2010) Harrison J (2010) 정보 형식 메서드 - 개요. In: Second NASA Formal Methods Symposium, pp 179-195
* He 등(2023) He H, Zhang J, Xu M, 등(2023) Scalable mask annotation for video text spotting. arXiv preprint arXiv:230501443
*He 등(2021) He J, Zhou C, Ma X, 등(2021) Parameter-efficient transfer learning의 통일된 관점. In: 학습 표상에 관한 국제 회의
*He et al. (2022) He K, Chen X, Xie S, et al. (2022) Masked autoencoder들은 확장 가능한 비전 학습자들이다. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp 16000-16009
* Hemphill 등(1990) Hemphill CT, Godfrey JJ, Doddington GR(1990) The ATIS spoken language systems pilot corpus. In: Speech and Natural Language: Proceedings of Workshop Held at Hidden Valley, Pennsylvania, June 24-27, 1990, URL [https://aclanthology.org/H90-1021](https://aclanthology.org/H90-1021)
* Hendrycks 등(2021a) Hendrycks D, Basart S, Kadavath S, 등(2021a) App을 이용한 코딩 챌린지 능력 측정. 뉴어리스
* Hendrycks et al. (2021b) Hendrycks D, Burns C, Kadavath S, et al. (2021b) Measuring mathematical problem solving with the math dataset. 뉴어리스
* Hinton(1990) Hinton GE(1990) Connectionist 학습 절차. In: Machine Learning. Elsevier, p 555-610
* Hinton 등(2021)* Ho 등(2022) Ho N, Schmid L, Yun SY(2022) Large language models is reasoning teachers. arXiv preprint arXiv:221210071
* Hong et al.(2021a) Hong Y, Li Q, Zhu SC, et al.(2021a) Vlgrammar: Grounded grammar induction of vision and language
* Hong et al.(2021b) Hong Y, Yi L, Tenenbaum JB, et al.(2021b) Ptr: A benchmark for part-based conceptual, relational, and physical reasoning. 2112.05136
* Hong et al.(2023) Hong Y, Zhen H, Chen P, et al.(2023) 3d-llm: 3d World를 대형 언어 모델에 주입하는 것. arXiv
* Hongjin et al. (2022) Hongjin S, Kasai J, Wu CH, et al. (2022) Selective annotation makes language models better few-shot learners. In: 학습 표상에 관한 제11회 국제학술대회
* Honovich et al. (2022) Honovich O, Scialom T, Levy O, et al. (2022) Unnatural instructions: (거의) 인간 노동력이 없는 튜닝 언어 모델. URL [https://arxiv.org/abs/2212.09689](https://arxiv.org/abs/2212.09689)
* 대규모 언어 모델 만들기의 도전과 관점에 대한 워크샵입니다. Association for Computational Linguistics, virtual+Dublin, pp 160-172, [https://doi.org/10.18653/v1/2022.bigscience-1.12](https://doi.org/10.18653/v1/2022.bigscience-1.12), URL [https://aclanthology.org/2022.bigscience-1.12](https://aclanthology.org/2022.bigscience-1.12)
* Hosseini 등(2014) Hosseini MJ, Hajishirzi H, Etzioni O, 등(2014) Learning to solve arithmetic word problems with verb categorization. In: Proceedings of 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP) Association for Computational Linguistics, Doha, Qatar, pp 523-533, [https://doi.org/10.3115/v1/D14-1058](https://doi.org/10.3115/v1/D14-1058), URL [https://aclanthology.org/D14-1058](https://aclanthology.org/D14-1058)
* Houlsby 등(2019) Houlsby N, Giurgiu A, Jastrzebski S, 등(2019) Parameter-efficient transfer learning for nlp. In: International Conference on Machine Learning, PMLR, pp 2790-2799
* Hsieh et al.(2023) Hsieh CY, Li CL, Yeh CK, et al.(2023) 증류 단계! 학습 데이터가 적고 모델 크기가 작은 더 큰 언어 모델을 수행할 수 없습니다. In: Association for Computational Linguistics: ACL 2023. Association for Computational Linguistics, Toronto, Canada, pp 8003-8017, [https://doi.org/10.18653/v1/2023.findings-acl.507](https://doi.org/10.18653/v1/2023.findings-acl.507), URL [https://aclanthology.org/2023.findings-acl.507](https://aclanthology.org/2023.findings-acl.507)
* Hsu 등(2021) Hsu WN, Bolte B, Tsai YHH, 등(2021) HuBERT: hidden unit의 masked prediction에 의한 Self-supervised speech representation learning. IEEE/ACM Transactions on Audio, Speech and Language Processing 29:3451-3460
* Hsu et al. (2022) Hsu YC, Hua T, Chang S, et al. (2022) Language model compression with weighted low-rank factorization. 2207.00112
* Hsu 등(2021)Hu EJ, yelong shen, Wallis P, 등(2022) LoRA: Low-rank adaptation of large language models. In: International Conference on Learning Representations, URL [https://openreview.net/forum?id=nZeVKeeFYf9](https://openreview.net/forum?id=nZeVKeeFYf9)
* Hu 등(2023a) Hu M, Mu Y, Yu X, 등(2023a) Tree-planner: 큰 언어 모델을 갖는 효율적인 클로즈-루프 태스크 계획. arXiv preprint arXiv:231008582
* Hu et al. (2023b) Hu Y, Yang H, Lin Z, et al. (2023b) Code prompting: a neural symbolic method for complex reasoning in large language models. 2305.18507
* Huang et al. (2016) Huang D, Shi S, Lin CY, et al. (2016) 컴퓨터가 수학 단어 문제를 얼마나 잘 풀는가? 대규모 데이터 세트 구축 및 평가 In: Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics(Volume 1: Long Papers), pp 887-896
* Huang et al.(2021a) Huang G, Hu J, He Y, et al.(2021a) Machine Learning for electronic design automation: survey. 전자 시스템(TODAES)의 설계 자동화를 위한 ACM 트랜잭션 26(5):1-46
* Huang 등(2023a) Huang H, Tang T, Zhang D, 등(2023a) 모든 언어가 lms에서 동일하게 생성되는 것은 아니다: 교차 언어-생각 프롬프트에 의한 다국어 능력 향상. 2305.07004
* Huang and Chang (2022) Huang J, Chang KCC (2022) Towards reasoning in large language models: survey. arXiv preprint arXiv:221210403
* Huang 등(2021b) Huang J, Xie S, Sun J, 등(2021b) 운전자의 제어 행동을 모방하여 결정 모듈을 학습한다. In: Kober J, Ramos F, Tomlin C(eds) Proceedings of the 2020 Conference on Robot Learning, Proceedings of Machine Learning Research, vol 155. PMLR, pp 1-10, URL [https://proceedings.mlr.press/v155/huang21a.html](https://proceedings.mlr.press/v155/huang21a.html)
* Huang et al. (2022a) Huang J, Gu SS, Hou L, et al. (2022a) Large language models can self-improve. arXiv preprint arXiv:221011610
* Huang et al.(2023b) Huang J, Zhu WY, Jia B, et al.(2023b) Perceive, Ground, reason, and act: A benchmark for general-purpose visual representation. URL [https://openreview.net/forum?id=f6cywgfd11](https://openreview.net/forum?id=f6cywgfd11)
* Huang et al.(2023c) Huang K, Sun K, Xie E, et al.(2023c) T2i-compbench: A comprehensive benchmark for open-world compositional text-to-image generation. arXiv preprint arXiv:230706350
* Huang et al. (2019) Huang L, Bras RL, Bhagavatula C, et al. (2019) Cosmos qa: Machine reading comprehension with contextual commonsense reasoning. arXiv preprint arXiv:190900277
* Huang et al. (2023d) Huang S, Dong L, Wang W, et al. (2023d) Language is not all you need: Aligning perception with language models. arXiv preprint arXiv:230214045
* Huang et al.(2022b) Huang W, Abbeel P, Pathak D, et al.(2022b) Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. In: International Conferenceon Machine Learning, PMLR, pp 9118-9147
* Huang et al.(2022c) Huang W, Xia F, Xiao T, et al.(2022c) Inner monologue: 언어 모델과의 플래닝을 통한 Embodied reasoning. In: arXiv preprint arXiv:2207.05608
* Huang et al.(2023e) Huang X, Ruan W, Huang W, et al.(2023e) 검증 및 검증의 렌즈를 통한 대형 언어 모델의 안전성 및 신뢰성에 대한 조사. 2305.11391
* Huang et al.(2021c) Huang Y, Kleindessner M, Munishkin A, et al.(2021c) Benchmarking of data-driven causality discovery approaches in interactions of Arctic sea ice and atmosphere. 빅데이터 프론티어 4:642182
* Hudson and Manning(2019) Hudson DA, Manning CD(2019) Gqa: A new dataset for real-world visual reasoning and compositional question answer. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp 6700-6709
* Huo et al.(2021) Huo Y, Zhang M, Liu G, et al.(2021) Wenlan: Bridgeging vision and language by large-scale multi-modal pre-training. arXiv preprint arXiv:210306561
* Ilharco 등(2021) Ilharco G, Wortsman M, Wightman R, 등(2021) Openclip. 제노도 4:5
* Imani 등(2023) Imani S, Du L, Shrivastava H(2023) Mathprompter: Mathematical reasoning using large language models. 2303.05398
* Inaba 등(2023) Inaba T, Kiyomaru H, Cheng F, 등(2023) Multitool-cot: Gpt-3은 연쇄적 사고 프롬프팅과 함께 다수의 외부 도구를 사용할 수 있다. 2305.16896
* Iyer 등(2022) Iyer S, Lin XV, Pasunuru R, 등(2022) Opt-iml: Scaling language model instruction meta learning through the lens of generalization. arXiv preprint arXiv:221212017
* Jacobs 등(1991) Jacobs RA, Jordan MI, Nowlan SJ, 등(1991) Adaptive mixtures of local experts. 신경연산 3(1):79-87
* Jaderberg 등(2016) Jaderberg M, Simonyan K, Zisserman A, 등(2016) Spatial transformer networks. 1506.02025
* Jain 등(2023) Jain N, Saifullah K, Wen Y, 등(2023) Bring your own data! 대형 언어 모델에 대한 자체 감독 평가 arXiv preprint arXiv:230613651
* Jansen(2020) Jansen P(2020) Visually-grounded planning without vision: Language models infer detailed plan from high level instructions. In: Association of Association for Computational Linguistics: EMNLP 2020. Association for Computational Linguistics, Online, pp 4412-4417, [https://doi.org/10.18653/v1/2020.findings-emnlp.395](https://doi.org/10.18653/v1/2020.findings-emnlp.395), URL [https://aclanthology.org/2020.findings-emnlp.395](https://aclanthology.org/2020.findings-emnlp.395)
* Ji et al.(2023) Ji Z, Lee N, Frieske R, et al.(2023) Survey of hallucination in natural language generation. ACM 컴퓨팅 조사 55(12):1-38
* Ji et al. (2021)Jia C, Yang Y, Xia Y, et al. (2021) Scaling up visual and vision-language representation learning with noisy text supervision. In: International conference on machine learning, PMLR, pp 4904-4916
* Jiang et al. (2021a) Jiang AQ, Li W, Han JM, et al. (2021a) Lisa: isabelle proofs의 언어 모델. In: 6th Conference on Artificial Intelligence and Theorem Proving, pp 378-392
* Jiang et al. (2022) Jiang AQ, Welleck S, Zhou JP, et al. (2022) Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. arXiv preprint arXiv:221012283
* Jiang et al. (2020a) Jiang D, Li W, Cao M, et al. (2020a) Speech SIMCLR: Combining contrastive and reconstruction objective for self-supervised speech representation learning. In: INTERSPEECH, pp 1544-1548
* Jiang et al.(2021b) Jiang D, Li W, Zhang R, et al.(2021b) Transformer 기반 음성 인식을 위한 비지도 사전 훈련에 대한 추가 연구. In: ICASSP, pp 6538-6542
* Jiang et al.(2023a) Jiang W, Lin B, Shi H, et al.(2023a) Effective and parameter-efficient reusing fine-tuned models. arXiv preprint arXiv:231001886
* Jiang et al. (2023b) Jiang W, Shi H, Yu L, et al. (2023b) Backward reasoning in large language models for verification. arXiv preprint arXiv:230807758
* Jiang et al. (2023c) Jiang W, Zhang Y, Kwok J (2023c) Effective structured prompting by meta-learning and representative verbalizer. In: International Conference on Machine Learning, PMLR, pp 15186-15199
* Jiang et al. (2020b) Jiang Z, Xu FF, Araki J, et al. (2020b) What language models know를 어떻게 알 수 있는가? Computational Linguistics를 위한 Association의 트랜잭션 8:423-438
* Jiang 등(2021c) Jiang Z, Araki J, Ding H, 등(2021c) 언어모델이 언제 알 수 있는지 어떻게 알 수 있는가? 질문에 응답하기 위한 언어 모델의 보정에 사용됩니다. Computational Linguistics를 위한 Association의 트랜잭션 9:962-977
* Jiao et al. (2020) Jiao R, Wang Z, Chu R, et al. (2020) An intuitive end-to-end human-uav interaction system for field exploration. 신경로보틱스의 프론티어
* Jin et al.(2023a) Jin Q, Yang Y, Chen Q, et al.(2023a) Genegpt: Augmenting large language models with domain tools for improved access to biomical information. (주)아르크시브
* Jin et al. (2023b) Jin Z, Liu J, Lyu Z, et al. (2023b) Can large language models infer causation from correlation? arXiv preprint arXiv:230605836
* Johnson 등(2017) Johnson J, Hariharan B, Van Der Maaten L, 등(2017) Clevr: A diagnostic dataset for compositional language and elementary visual reasoning. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp 2901-2910Joshi M, Choi E, Weld D, et al. (2017) TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension. In: 제55회 전산언어학회 연차총회 회보(제1권: 장문) Association for Computational Linguistics, Vancouver, Canada, pp 1601-1611, [https://doi.org/10.18653/v1/P17-1147](https://doi.org/10.18653/v1/P17-1147), URL [https://aclanthology.org/P17-1147](https://aclanthology.org/P17-1147)
* Jumper 등(2021) Jumper J, Evans R, Pritzel A, 등(2021) alphafold를 이용한 높은 정확도의 단백질 구조 예측. Nature 596(7873):583-589
* Kahn et al. (2020) Kahn J, Riviere M, Zheng W, et al. (2020) Libri-light: A benchmark for asr with limited or no supervision. In: ICASSP, pp 7669-7673
* Kahneman and Miller (1986) Kahneman D, Miller DT (1986) Norm theory: reality to its alternatives. 심리적 검토 93(2):136
* Karimi Mahabadi 등(2021) Karimi Mahabadi R, Henderson J, Ruder S(2021) Compacter: Efficient low-rank hypercomplex adapter layers. 신경정보처리시스템의 발전
* Katsis et al. (2022) Katsis Y, Chemmengath S, Kumar V, et al. (2022) AIT-QA: 질문 응답 데이터셋 over complex table over airline industry. In: Proceedings of 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Track. Association for Computational Linguistics, Hybrid: Seattle, Washington + Online, pp 305-314, [https://doi.org/10.18653/v1/2022.naacl-industry.34](https://doi.org/10.18653/v1/2022.naacl-industry.34), URL [https://aclanthology.org/2022.naacl-industry.34](https://aclanthology.org/2022.naacl-industry.34)
* Kazemi 등(2023) Kazemi M, Yuan Q, Bhatia D, 등(2023) Boardgameqa: 모순된 정보를 가진 자연어 추론을 위한 데이터셋. arXiv preprint arXiv:230607934
* Kenton JDMWC(2019) Kenton JDMWC, Toutanova LK(2019) Bert: 언어 이해를 위한 심층 양방향 변압기 사전 훈련. In : naacL-HLT의 진행, p2
* Khan et al. (2020) Khan W, Kamran M, Naqvi SR, et al. (2020) Formal verification of hardware components in critical systems. 무선 통신 및 모바일 컴퓨팅 2020:1-15
* Khashabi et al. (2020) Khashabi D, Min S, Khot T, et al. (2020) Unifiedqa: Crossing format boundaries with a single qa system. arXiv preprint arXiv:200500700
* Kiciman et al. (2023) Kiciman E, Ness R, Sharma A, et al. (2023) Causal reasoning and large language models: Opening a new frontier for causality. arXiv preprint arXiv:230500050
* Kim 등(2019) Kim J, Misu T, Chen YT, 등(2019) Grounding human-to-vehicle advice for self-driving vehicles. In: IEEE/CVF Conference on Computer Vision and Pattern Recognition Kim S, Joo SJ, Kim D, et al. (2023) The cot collection: Improving zero-shot and few-shot learning of language models via chain-of-thought fine-tuning. arXiv preprint arXiv:230514045
* Kim et al.(2021) Kim W, Son B, Kim I (2021) Vilt: Vision-and-language transformer without convolution or region supervision. In: International Conference on Machine Learning, PMLR, pp 5583-5594
* Kirchenbauer et al. (2023) Kirchenbauer J, Geiping J, Wen Y, et al. (2023) A watermark for large language models. 2301.10226
* Kirillov 등(2023) Kirillov A, Mintun E, Ravi N, 등(2023) Segment anything. arXiv:230402643
* Koectkov 등(2022) Koectkov D, Li R, Allal LB, 등(2022) The stack: 3 tb of permissively licensed source code. arXiv preprint arXiv:221115533
* Kojima et al.(2022) Kojima T, Gu SS, Reid M, et al.(2022) Large language models are zero-shot reasoners. 신경 정보 처리 시스템들에서의 발전들 35:22199-22213
* Koncel-Kedziorski 등(2015) Koncel-Kedziorski R, Hajishirzi H, Sabharwal A, 등(2015) Parsing algebraic word problems into equations. 계산 언어 연합의 트랜잭션 3:585-597. [https://doi.org/10.1162/tacl_a_00160](https://doi.org/10.1162/tacl_a_00160), URL [https://aclanthology.org/Q15-1042](https://aclanthology.org/Q15-1042)
* Koncel-Kedziorski 등(2016) Koncel-Kedziorski R, Roy S, Amini A, 등(2016) Mawps: A math word problem repository. In: 북미 언어학 협회의 장
* Kondo 등(2023) Kondo K, Sugawara S, Aizawa A(2023) Probing physical reasoning with counter-commonsense context. In: 제61회 전산언어학회 연차총회 회보(제2권 : 짧은 논문). Association for Computational Linguistics, Toronto, Canada, pp 603-612, [https://doi.org/10.18653/v1/2023.acl-short.53](https://doi.org/10.18653/v1/2023.acl-short.53), URL [https://aclanthology.org/2023.acl-short.53](https://aclanthology.org/2023.acl-short.53)
* Koons(2005) Koons R(2005) Defeasible reasoning. arXiv
* Kosinski (2023) Kosinski M (2023) 마음 이론은 대규모 언어 모델에서 자발적으로 등장 했을 수 있습니다. 2302.02083
* Kreps 등(2022) Kreps S, McCain RM, Brundage M(2022) All the news that fit to fabricate: Aigenerated text as a tool of media misinformation. 실험정치학 9(1):104-117
* Kurita 등(2020) Kurita K, Michel P, Neubig G(2020) Weight poisoning attack on pre-trained models. arXiv preprint arXiv:200406660
* Kushman 등(2014) Kushman N, Artzi Y, Zettlemoyer L, 등(2014) Learning to automatically solve algebra word problems. In: 제52회 전산언어학회 연차총회 회보(제1권: 장문). Association for Computational Linguistics, Baltimore, Maryland, pp 271-281, [https://doi.org/10.3115/v1/P14-1026](https://doi.org/10.3115/v1/P14-1026), URL [https://aclanthology.org/P14-1026](https://aclanthology.org/P14-1026)
* Kwiatkowski et al. (2019) Kwiatkowski T, Palomaki J, Redfield O, et al. (2019) Natural questions: A benchmark for question answer research. 계산 언어 연합의 트랜잭션 7:452-466. [https://doi.org/10.1162/tacl_a_00276](https://doi.org/10.1162/tacl_a_00276), URL [https://aclanthology.org/Q19-1026](https://aclanthology.org/Q19-1026)
* Koksal 등(2023) Koksal A, Schick T, Korhonen A, 등(2023) Longform: 코퍼스 추출로 긴 텍스트 생성을 위한 명령어 튜닝 최적화. 2304.08460
* 대규모 언어 모델 정렬을 민주화합니다. 2304.07327
* Laban 등(2023) Laban P, Kryscinski W, Agarwal D, 등(2023) Llms as factual reasoners: Insights from existing benchmarks and beyond. 2305.14540
* Lahiri (2014) Lahiri S (2014) Complexity of Word Collocation Networks: A preliminary Structural Analysis. In: 계산 언어학 협회의 유럽 제14차 회의에서 학생 연구 워크숍의 진행. Association for Computational Linguistics, Gothenburg, Sweden, pp 96-105, URL [http://www.aclweb.org/anthology/E14-3011](http://www.aclweb.org/anthology/E14-3011)
* Lai 등(2023) Lai X, Tian Z, Chen Y, 등(2023) Lisa: Reasoning segmentation via large language model. arXiv preprint arXiv:230800692
* Lample et al.(2022) Lample G, Lacroix T, Lachaux MA, et al.(2022) Hypertree proof search for neural theorem prove. 신경정보처리시스템 35:26337-26349의 발전
* Laurencon 등(2022) Laurencon H, Saulnier L, Wang T, 등(2022) The bigscience root corpus: A 1.6 tb composite multilingual dataset. 신경정보처리시스템 35:31809-31826의 발전
* Laurent and Platzer(2022) Laurent J, Platzer A(2022) Learning to find proofs and theorem by learning to refine search strategies: The case of loop invariant synthesis. 신경정보처리시스템의 발전방향 35:4843-4856
* Le 등(2022) Le H, Wang Y, Gotmare AD, 등(2022) Coderl: 사전 훈련된 모델 및 심층 강화 학습을 통한 마스터링 코드 생성. 신경정보처리시스템 35:21314-21328의 발전
* Leake (2012) Leake DB (2012) Introspective Learning and Reasoning, Springer US, Boston, MA, pp 1638-1640. [https://doi.org/10.1007/978-1-4419-1428-6_1802](https://doi.org/10.1007/978-1-4419-1428-6_1802), URL [https://doi.org/10.1007/978-1-4419-1428-6_1802](https://doi.org/10.1007/978-1-4419-1428-6_1802)
* Leake et al. (2013) Lee YJ, Lim CG, Choi HJ (2022) Does gpt-3 generate empathetic dialogues? 공감 대화 생성을 위한 새로운 맥락 내 예제 선택 방법 및 자동 평가 메트릭. In: Proceedings of the 29th International Conference on Computational Linguistics, pp 669-683
* Lepikhin et al. (2020) Lepikhin D, Lee H, Xu Y, et al. (2020) Gshard: Scaling giant models with conditional computation and automatic sharding. arXiv preprint arXiv:200616668
* Lester 등(2021) Lester B, Al-Rfou R, Constant N(2021) The power of scale for parameter-efficient prompt tuning. In: 2021년 자연어 처리에 관한 실증적 방법에 관한 회의의 진행. Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, pp 3045-3059, [https://doi.org/10.18653/v1/2021.emnlp-main.243](https://doi.org/10.18653/v1/2021.emnlp-main.243), URL [https://aclanthology.org/2021.emnlp-main.243](https://aclanthology.org/2021.emnlp-main.243)
* Levy 등(2022) Levy I, Bogin B, Berant J(2022) Diverse demonstrations improve in-context compositional generalization. arXiv preprint arXiv:221206800
* Lewis 등(2020) Lewis M, Liu Y, Goyal N, 등(2020) BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In: 계산 언어학 협회의 제58차 연례 회의 진행. Association for Computational Linguistics, Online, pp 7871-7880, [https://doi.org/10.18653/v1/2020.acl-main.703](https://doi.org/10.18653/v1/2020.acl-main.703), URL [https://aclanthology.org/2020.acl-main.703](https://aclanthology.org/2020.acl-main.703)
* Lewkowycz et al.(2022) Lewkowycz A, Andreassen AJ, Dohan D, et al.(2022) Solving quantitative reasoning problems with language models. In: Oh AH, Agarwal A, Belgrave D, et al. (eds) Advances in Neural Information Processing Systems, URL [https://openreview.net/forum?id=IFXTZERXdM7](https://openreview.net/forum?id=IFXTZERXdM7)
* Li(2023) Li C(2023) Large multimodal models: Notes on cvpr 2023 tutorial. 2306.14895
* Li et al.(2021a) Li C, Xia F, Martin-Martin R, et al.(2021a) igibson 2.0: Object-centric simulation for robot learning of everyday household tasks. In: 5th Annual Conference on Robot Learning, URL [https://openreview.net/forum?id=2uGN5jNJROR](https://openreview.net/forum?id=2uGN5jNJROR)
* Li 등(2022a) Li C, Liu H, Li L, 등(2022a) Elevater: 언어 증강 시각 모델을 평가하기 위한 벤치마크 및 툴킷. 신경정보처리시스템 35:9287-9301의 발전
* Li et al. (2022b) Li C, Zhang R, Wong J, et al. (2022b) BEHAVIOR-1k: 1,000 일상 활동 및 현실적인 시뮬레이션을 갖는 구체화된 AI에 대한 벤치마크. In: 6th Annual Conference on Robot Learning, URL [https://openreview.net/forum?id=_8DoIe8G3t](https://openreview.net/forum?id=_8DoIe8G3t)
* Li 등(2023a) Li C, Gan Z, Yang Z, 등(2023a) 멀티모달 기초 모델: 전문가로부터 범용 보조자에 이르기까지. 2309.10020Li C, Wong C, Zhang S, et al.(2023b) Llava-med: Training a large language-and-vision assistant for biomedicine in one day. arXiv preprint arXiv:230600890
* Li 등(2023c) Li G, Hammoud HAAK, Itani H, 등(2023c) Camel: Communicative agents for "mind" exploration of large language model society. 신경정보처리시스템에 관한 제37회 회의
* Li 등(2023d) Li H, Guo D, Fan W, 등(2023d) Multi-step jailbreaking privacy attacks on chatgpt. arXiv preprint arXiv:230405197
* Li 등(2023e) Li H, Sima C, Dai J, 등(2023e) Delving in the Devils of bird's eye-view perception: A review, evaluation and recipe. 2209.05324
* Li 등(2017) Li J, Seltzer ML, Wang X, 등(2017) 교사-학생 학습을 통한 대규모 도메인 적응. In: INTERSPEECH, pp 2386-2390
* Li 등(2022c) Li J, Li D, Xiong C, 등(2022c) Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation. 2201.12086
* Li 등(2023f) Li J, Li D, Savarese S, 등(2023f) Blip-2: Bootstrapping language-image pre-training with frozen image encoder and large language models. 2301.12597
* Li 등(2023g) Li J, Yu L, Ettinger A(2023g) Counterfactual reasoning: 언어 모델의 가상 시나리오에 대한 이해를 테스트한다. arXiv preprint arXiv:230516572
* Li 등(2023h) Li J, Zhao Y, Li Y, 등(2023h) Accoder: 기존 코드 생성을 활용한다. 2303.17780
* Li 및 Spratling(2023) Li L, Spratling M(2023) 데이터 증강만으로도 적대적 훈련을 개선할 수 있다. arXiv preprint arXiv:230109879
* Li 등(2005) Li L, Szygenda SA, Thornton MA(2005) Combining simulation and formal verification for integrated circuit design validation. In: Proceedings of the 9th World Multi-Conference on Systemics, Cybernetics and Informatics (WMSCI), pp 92-97
* Li 등(2023i) Li L, Qiu J, Spratling M(2023i) Aroid: online instance-wise data augmentation을 통한 적대적 강건성 향상. arXiv preprint arXiv:230607197
* Li 등(2023j) Li P, Sun T, Tang Q, 등(2023j) Codeie: Large code generation models are better few-shot information extractor. In: Rogers A, Boyd-Graber JL, Okazaki N (eds) Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023. Association for Computational Linguistics, pp 15339-15353, [https://doi.org/10.18653/v1/2023.acl-long.855](https://doi.org/10.18653/v1/2023.acl-long.855), URL [https://doi.org/10.18653/v1/2023.acl-long.855](https://doi.org/10.18653/v1/2023.acl-long.855)
* Li 등(2023k) Li R, Allal LB, Zi Y, 등(2023k) Starcoder: may the source is with you! arXiv preprint arXiv:230506161Li S, Chen J, Shen Y, et al.(2022d) 대형 언어 모델로부터의 설명은 작은 추론기를 더 좋게 만든다. arXiv preprint arXiv:221006726
* Li 등(2022e) Li S, Puig X, Paxton C, 등(2022e) 대화형 의사 결정을 위한 사전 훈련된 언어 모델. 신경 정보 처리 시스템의 발전 35:31199-31212
* Li et al.(2023l) Li T, Chen L, Wang H, et al.(2023l) Graph-based topology reasoning for driving scenes. 2304.05277
* Li 및 Qiu(2023a) Li X, Qiu X(2023a) In-context 학습을 위한 지원 예들을 찾는 단계. arXiv preprint arXiv:230213539
* Li and Qiu(2023b) Li X, Qiu X(2023b) Mot: Memory-of-thought enables chatgpt to self-improve. 2305. 05181
* Li 등(2020) Li X, Yin X, Li C, 등(2020) Oscar: Object-semantics aligned pre-training for vision-language tasks. In: ECCV, pp 121-137
* Li 등(2021b) Li X, Sun Y, Cheng G(2021b) Tsqa: Tabular 시나리오 기반 질의 응답. ArXiv abs/2101.11429
* Li 등(2023m) Li X, Liu M, Zhang H, 등(2023m) Vision-language foundation models as effective robot imitators. arXiv preprint arXiv:231101378
* Li 등(2023n) Li X, Lv K, Yan H, 등(2023n) Unified demonstration retriver for in-context learning. In: Rogers A, Boyd-Graber J, Okazaki N(eds) Proceedings of the 61th Annual Meeting of the Association of Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Toronto, Canada, pp 4644-4668, [https://doi.org/10.18653/v1/2023.acl-long.256](https://doi.org/10.18653/v1/2023.acl-long.256), URL [https://aclanthology.org/2023.acl-long.256](https://aclanthology.org/2023.acl-long.256)
* Li 등(2023o) Li X, Yu P, Zhou C, 등(2023o) 명령어 역번역과의 자기 정렬. arXiv preprint arXiv:230806259
* Li 및 Liang(2021) Li XL, Liang P(2021) Prefix-tuning: 생성을 위한 연속 프롬프트 최적화. In : 제59회 전산언어학회 연차총회 및 제11회 자연어처리 국제공동회의 회보(제1권: 장문) Association for Computational Linguistics, Online, pp 4582-4597, [https://doi.org/10.18653/v1/2021.acl-long.353](https://doi.org/10.18653/v1/2021.acl-long.353), URL [https://aclanthology.org/2021.acl-long.353](https://aclanthology.org/2021.acl-long.353)
* Li 등(2022f) Li XL, Kuncoro A, Hoffmann J, 등(2022f) 대형 언어 모델에서의 상식 지식의 체계적인 조사. In: Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp 11838-11855Li Y, Kong T, Chu R, et al.(2021c) Simultaneous semantic and collision learning for 6-dof grasp pose estimation. 2021년에. In: RSJ International Conference on Intelligent Robot and Systems (IROS)
* Li 등(2022g) Li Y, Choi D, Chung J, 등(2022g) Competition-level code generation with alphacode. Science 378(6624):1092-1097
* Li et al. (2022h) Li Y, Lin Z, Zhang S, et al. (2022h) On the advance of making language models better reasoner. arXiv preprint arXiv:220602336
* Li 등(2023p) Li Y, Du Y, Zhou K, 등(2023p) arXiv preprint arXiv:230510355
* Li et al.(2023q) Li Y, Fan H, Hu R, et al.(2023q) Scaling language-image pre-training via masking. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 23390-23400
* Li et al.(2023r) Li Y, Gao C, Song X, et al.(2023r) Druggpt: A gpt-based strategy for designing potential ligands targeting specific proteins. bioRxiv pp 2023-06
* Li 등(2023s) Li Y, Wang C, Jia J(2023s) Llama-vid: An image is worth 2 tokens in large language models. arXiv preprint arXiv:231117043
* Li 등(2023t) Li Y, Wang H, Duan Y, 등(2023t) Clip surgery for better explainability with enhancement in open-vocabulary tasks. arXiv preprint arXiv:230405653
* Li et al. (2023u) Li Y, Zhou K, Zhao WX, et al. (2023u) Diffusion models for non-autoregressive text generation: survey. arXiv preprint arXiv:230306574
* Lian et al. (2022) Lian D, Zhou D, Feng J, et al. (2022) Scaling & shift your features: A new baseline for efficient model tuning. 신경 정보 처리 시스템의 발전 35:109-123
* Liang et al.(2022a) Liang J, Huang W, Xia F, et al.(2022a) Code as policies: Language model programs for embodied control. In: arXiv preprint arXiv:2209.07753
* Liang et al.(2022b) Liang Z, Zhang J, Wang L, et al.(2022b) Mwp-bert: Numeracy-augmented pre-training for math word problem solving. In: Findings of NAACL 2022, pp 997-1009
* Liao and Vaughan (2023) Liao QV, Vaughan JW (2023) Ai 투명도 in the age of llms: A human-centered research roadmap. arXiv preprint arXiv:230601941
* Lightman 등(2023) Lightman H, Kosaraju V, Burda Y, 등(2023) 단계별로 검증해 보자. 2305.20050
* Likhosherstov et al. (2021) Likhosherstov V, Arnab A, Choromanski K, et al. (2021) Polyvit: 이미지, 비디오 및 오디오 상의 비전 트랜스포머를 공동 트레이닝한다. arXiv preprint arXiv:211112993* Lin et al.(2023a) Lin B, Jiang W, Ye F, et al.(2023a) Dual-balancing for multi-task learning. Preprint arXiv:2308.12029
* Lin 등(2020a) Lin BY, Sun H, Dhingra B, 등(2020a) Differentiable open-ended 상식 추론. arXiv preprint arXiv:201014439
* Lin et al. (2020b) Lin BY, Zhou W, Shen M, et al. (2020b) CommonGen: A constrained text generation challenge for generative commonsense reasoning. In: Association of Association for Computational Linguistics: EMNLP 2020. Association for Computational Linguistics, Online, pp 1823-1840, [https://doi.org/10.18653/v1/2020.findings-emnlp.165](https://doi.org/10.18653/v1/2020.findings-emnlp.165), URL [https://aclanthology.org/2020.findings-emnlp.165](https://aclanthology.org/2020.findings-emnlp.165)
* Lin et al. (2023b) Lin BY, Fu Y, Yang K, et al. (2023b) Swiftsage: 복잡한 대화형 태스크에 대해 빠르고 느린 사고를 갖는 생성 에이전트. arXiv preprint arXiv:230517390
* Lin and Byrne(2022) Lin W, Byrne B(2022) Retrieval augmented visual question answer with external knowledge. In: 2022년 자연어처리 실증방법에 관한 회의의 진행. Association for Computational Linguistics, Abu Dhabi, United Arab Emirates, pp 11238-11254, [https://doi.org/10.18653/v1/2022.emnlp-main.772](https://doi.org/10.18653/v1/2022.emnlp-main.772), URL [https://aclanthology.org/2022.emnlp-main.772](https://aclanthology.org/2022.emnlp-main.772)
* Lin et al.(2020c) Lin Z, Wu YF, Peri S, et al.(2020c) Improving generative imagination in object-centric world models. 2010.02054
* Ling et al. (2017) Ling W, Yogatama D, Dyer C, et al. (2017) Program induction by rationale generation: Learning to solve and explain algebraic word problems. In: Barzilay R, Kan MY(eds) Proceedings of the 55th Annual Meeting of the Association of Computational Linguistics (Volume 1: Long Papers). Association for Computational Linguistics, Vancouver, Canada, pp 158-167, [https://doi.org/10.18653/v1/P17-1015](https://doi.org/10.18653/v1/P17-1015), URL [https://aclanthology.org/P17-1015](https://aclanthology.org/P17-1015)
* Liu et al. (2020) Liu AT, Yang Sw, Chi PH, et al. (2020) Mockingjay: Deep 양방향 트랜스포머 인코더를 사용한 비지도 음성 표현 학습. In: ICASSP, pp 6419-6423
* Liu 등(2023a) Liu C, Shen J, Xin H, 등(2023a) Fimo: A challenge formal dataset for automated theorem prove. arXiv preprint arXiv:230904295
* Liu 등(2023b) Liu F, Eisenschlos JM, Piccinno F, 등(2023b) Deplot: plot-to-table translation에 의한 One-shot visual language reasoning. In: Computational Linguistics Association의 61번째 연례 회의 결과 URL [https://arxiv.org/abs/2212.10505](https://arxiv.org/abs/2212.10505)
* Liu 등(2023c) Liu F, Piccinno F, Krichene S, 등(2023c) Matcha: Enhancing visual language pretraining with math reasoning and chart derendering. In: Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics, URL [https://arxiv.org/abs/2212.09662](https://arxiv.org/abs/2212.09662)* Liu et al.(2023) Liu H, Li C, Li Y, et al.(2023d) Improved Baseline with visual instruction tuning. arXiv preprint arXiv:231003744
* Liu 등(2023e) Liu H, Li C, Wu Q, 등(2023e) Visual instruction tuning. arXiv preprint arXiv:230408485
* Liu 등(2023f) Liu H, Sferrazza C, Abbeel P(2023f) Chain of hindsight는 언어 모델을 피드백과 정렬한다. arXiv preprint arXiv:230202676
* Liu et al. (2022a) Liu J, Liu A, Lu X, et al. (2022a) Generated knowledge prompting for commonsense reasoning. In: 제60회 전산언어학회 연차총회 회보(제1권: 장문) Association for Computational Linguistics, Dublin, Ireland, pp 3154-3169, [https://doi.org/10.18653/v1/2022.acl-long.225](https://doi.org/10.18653/v1/2022.acl-long.225), URL [https://aclanthology.org/2022.acl-long.225](https://aclanthology.org/2022.acl-long.225)
* Liu et al.(2022b) Liu J, Shen D, Zhang Y, et al.(2022b) What make good in-context examples for gpt-3? In: Proceedings of Deep Learning Inside Out(DeeLIO 2022): 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures, pp 100-114
* Liu 등(2023g) Liu J, Huang Z, Ma Z, 등(2023g) 상식 공식 지식의 숙달을 통한 수학적 추론을 안내함. In: 제29차 ACM SIGKDD 지식발견 및 데이터 마이닝 회의의 진행. Association for Computing Machinery, New York, NY, USA, KDD '23, p 1477-1488, [https://doi.org/10.1145/3580305.3599375](https://doi.org/10.1145/3580305.3599375), URL [https://doi.org/10.1145/3580305.3599375](https://doi.org/10.1145/3580305.3599375)
* Liu 등(2023h) Liu NF, Lin K, Hewitt J, 등(2023h) Lost in the middle: How language models used long context. 2307.03172
* Liu et al.(2023i) Liu Q, Zhou F, Jiang Z, et al.(2023i) From zero to hero: Examining the power of symbolic tasks in instruction tuning. arXiv preprint arXiv:230407995
* Liu 등(2023j) Liu S, Zeng Z, Ren T, 등(2023j) Grounding dino: Marrying dino with grounded pre-training for open-set object detection. arXiv preprint arXiv:230305499
* Liu et al.(2022c) Liu T, Guo Q, Hu X, et al.(2022c) RLET: A reinforcement learning based approach for explainable QA with entailment trees. In: Goldberg Y, Kozareva Z, Zhang Y (eds) Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Abu Dhabi, United Arab Emirates, pp 7177-7189, [https://doi.org/10.18653/v1/2022.emnlp-main.483](https://doi.org/10.18653/v1/2022.emnlp-main.483), URL [https://aclanthology.org/2022.emnlp-main.483](https://aclanthology.org/2022.emnlp-main.483)
* Liu et al.(2023k) Liu T, Guo Q, Yang Y, et al.(2023k) Plan, verify and switch: Integrated reasoning with various x-of-thoughts. 2310.14628
* Liu 등(2021a) Liu X, Ji K, Fu Y, 등(2021a) P-튜닝 v2: 프롬프트 튜닝은 스케일 및 태스크에 걸쳐 범용적으로 미세 튜닝에 필적할 수 있다. arXiv preprint arXiv:211007602
* Liu 등(2021b)Liu X, Yin D, Feng Y, 등(2022d) Things not written in text: Exploring spatial commonsense from visual signals. In: 제60회 전산언어학회 연차총회 회보(제1권: 장문) Association for Computational Linguistics, Dublin, Ireland, pp 2365-2376, [https://doi.org/10.18653/v1/2022.acl-long.168](https://doi.org/10.18653/v1/2022.acl-long.168), URL [https://aclanthology.org/2022.acl-long.168](https://aclanthology.org/2022.acl-long.168)
* Liu 등(2023l) Liu X, Yin D, Zhang C, 등(2023l) The magic of if: Investigating causal reasoning abilities in large language models of code. arXiv preprint arXiv:230519213
* Liu 등(2023m) Liu X, Zheng Y, Du Z, 등(2023m) Gpt도 이해한다. AI 오픈
* Liu et al. (2019) Liu Y, Ott M, Goyal N, et al. (2019) Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:190711692
* Liu 등(2023n) Liu Y, Fabbri AR, Liu P, 등(2023n) On learning to summarize with large language models as reference. arXiv preprint arXiv:230514239
* Liu 등(2023o) Liu Y, Li Z, Li H, 등(2023o) On the hidden mystery of ocr in large multimodal models. 2305.07895
* Liu 등(2021b) Liu Z, Lin Y, Cao Y, 등(2021b) Swin transformer: Shifted Window를 이용한 Hierarchical vision transformer. In: Proceedings of the IEEE/CVF International conference on computer vision, pp 10012-10022
* Liu et al.(2022e) Liu Z, Hu H, Lin Y, et al.(2022e) Swin transformer v2: Scaling up capacity and resolution. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp 12009-12019
* Lo 등(2020) Lo K, Wang LL, Neumann M, 등(2020) S2ORC: The semantic scholar open research corpus. In: 계산 언어학 협회의 제58차 연례 회의 진행. Association for Computational Linguistics, Online, pp 4969-4983, [https://doi.org/10.18653/v1/2020.acl-main.447](https://doi.org/10.18653/v1/2020.acl-main.447), URL [https://aclanthology.org/2020.acl-main.447](https://aclanthology.org/2020.acl-main.447)
* Long(2023) Long J(2023) Large language model guided tree-of-thought. 2305.08291
* Long 등(2022) Long S, Schuster T, Piche A(2022) Can large language models build causal graph? In: NeurIPS 2022 Workshop on Causality for Real-world Impact, URL [https://openreview.net/forum?id=LQQoJGw8JD1](https://openreview.net/forum?id=LQQoJGw8JD1)
* Long et al.(2023) Long S, Piche A, Zantedeschi V, et al.(2023) Causal discovery with language models as imperfect experts. arXiv preprint arXiv:230702390
* Longpre et al. (2023) Longpre S, Hou L, Vu T, et al. (2023) The flan collection: Designing data and methods for effective instruction tuning. arXiv preprint arXiv:230113688
* Lou 등(2023) Lou R, Zhang K, Yin W(2023) Is prompt all you need? 아니오. 교수 학습에 대한 포괄적이고 광범위한 관점. arXiv preprint arXiv:230310475
* Long et al. (2023)Lourie N, Le Bras R, Bhagavatula C, et al. (2021) Unicorn on rainbow: A universal commonsense reasoning model on a new multitask benchmark. In: Proceedings of the AAAI Conference on Artificial Intelligence, pp 13480-13488
* Lu et al. (2021a) Lu P, Gong R, Jiang S, et al. (2021a) Inter-gps: 해석 가능한 기하학 문제 풀이 with formal language and symbolic reasoning. arXiv preprint arXiv:210504165
* Lu 등(2021b) Lu P, Qiu L, Chen J, 등(2021b) Iconqa: 추상도 이해 및 시각적 언어 추론을 위한 새로운 벤치마크. In: 데이터셋과 벤치마크에 대한 신경정보처리시스템(NeurIPS) 트랙에 관한 제35차 회의
* Lu et al. (2022a) Lu P, Mishra S, Xia T, et al. (2022a) Learn to explain: Multimodal reasoning via thought chains for science question answer. In: 제36회 신경정보처리시스템학회
* Lu 등(2022b) Lu P, Qiu L, Chang KW, 등(2022b) 반구조화된 수학적 추론을 위한 정책 그래디언트를 통한 동적 프롬프트 학습. arXiv preprint arXiv:220914610
* Lu 등(2023) Lu P, Peng B, Cheng H, 등(2023) Chameleon: Plug-and-play compositional reasoning with large language models. 2304.09842
* Luo 등(2023a) Luo G, Huang M, Zhou Y, 등(2023a) 구조적 재-파라미터화를 통한 효율적인 시각적 적응을 지향한다. arXiv preprint arXiv:230208106
* Luo et al.(2023b) Luo G, Zhou Y, Ren T, et al.(2023b) Cheap and quick: Efficient vision-language instruction tuning for large language models. arXiv preprint arXiv:230515023
* Luo et al. (2023c) Luo H, Sun Q, Xu C, et al. (2023c) Wizardmath: 강화 진화-인스트럭션을 통한 대형 언어 모델에 대한 수학적인 추론력 부여. arXiv preprint arXiv:230809583
* Luo et al. (2023d) Luo M, Kumbhar S, shen M, et al. (2023d) Towards logiglue: 간단한 조사 및 언어 모델의 논리적 추론 능력 분석을 위한 벤치마크. 2310. 00836
* Luo 등(2023e) Luo M, Xu X, Dai Z, 등(2023e) Dr. icl: Demonstration-retrieved in-context learning. arXiv preprint arXiv:230514128
* Luo et al.(2023f) Luo Z, Xu C, Zhao P, et al.(2023f) Wizardcoder: Empowering code large language models with evolving-instruct. arXiv preprint arXiv:230608568
* LYU 등(2022) LYU Z, Jin Z, Mihalcea R, 등(2022) 큰 언어 모델들은 원인과 효과를 구별할 수 있는가? In: UAI 2022 Workshop on Causal Representation Learning, URL [https://openreview.net/forum?id=ucHh-ytUkOH](https://openreview.net/forum?id=ucHh-ytUkOH)
* Ma et al.(2023) Ma X, Yong S, Zheng Z, et al.(2023) Sqa3d: Situated question answer in 3d scenes. In: International Conference on Learning Representations, URL [https://openreview.net/forum?id=IDJx97BC38](https://openreview.net/forum?id=IDJx97BC38)Madaan A, Tandon N, Rajagopal D, et al. (2021) Think it! 먼저 질문 시나리오를 모델링하여 패배할 수 있는 추론을 개선합니다. arXiv preprint arXiv:211012349
* Madaan et al.(2022) Madaan A, Zhou S, Alon U, et al.(2022) Language models of code is few-shot commonsense learners. In: Goldberg Y, Kozareva Z, Zhang Y (eds) Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Abu Dhabi, United Arab Emirates, pp 1384-1403, [https://doi.org/10.18653/v1/2022.emnlp-main.90](https://doi.org/10.18653/v1/2022.emnlp-main.90), URL [https://aclanthology.org/2022.emnlp-main.90](https://aclanthology.org/2022.emnlp-main.90)
* Madaan 등(2023) Madaan A, Tandon N, Gupta P, 등(2023) Self-refine: Self-feedback을 이용한 반복적 정제. 2303.17651
* Madani 등(2023) Madani A, Krause B, Greene ER, 등(2023) Large language models generate functional protein sequences across diverse family. Nature Biotechnology pp 1-8
* Magister et al.(2023) Magister LC, Mallinson J, Adamek J, et al.(2023) Teaching small language models to reason. In: Rogers A, Boyd-Graber J, Okazaki N(eds) Proceedings of the 61th Annual Meeting of the Association of Computational Linguistics (Volume 2: Short Papers). Association for Computational Linguistics, Toronto, Canada, pp 1773-1781, [https://doi.org/10.18653/v1/2023.acl-short.151](https://doi.org/10.18653/v1/2023.acl-short.151), URL [https://aclanthology.org/2023.acl-short.151](https://aclanthology.org/2023.acl-short.151)
* Manhaeve et al. (2021) Manhaeve R, Dumancic S, Kimmig A, et al. (2021) Neural probabilistic logic programming in deepproblog. 인공지능 298:103504. [https://doi.org/https://doi.org/10.1016/j.artint.2021.103504](https://doi.org/https://doi.org/10.1016/j.artint.2021.103504), URL [https://www.sciencedirect.com/science/article/pii/S0004370221000552](https://www.sciencedirect.com/science/article/pii/S0004370221000552)
* Manica et al.(2023) Manica M, Born J, Cadow J, et al.(2023) Accelerating material design with the generative toolkit for scientific discovery. npj Computational Materials 9(1):69
* Manning(2022) Manning CD(2022) Human language understanding & reasoning. Daedalus 151(2):127-138
*Manolis Savva* 등(2019) Manolis Savva*, Abhishek Kadian*, Oleksandr Maksymets*, 등(2019) Habitat: A Platform for Embodied AI Research. In: ICCV(IEEE/CVF International Conference on Computer Vision)의 회보
* Mao et al. (2019) Mao J, Gan C, Kohli P, et al. (2019) The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words and Sentences From Natural Supervision. In: International Conference on Learning Representations, URL [https://openreview.net/forum?id=rJgMlhRctm](https://openreview.net/forum?id=rJgMlhRctm)
* Mao et al. (2022) Mao J, Yang X, Zhang X, et al. (2022) Clevrer-humans: 물리적 및 인과적 사건을 인간의 방식으로 기술한다. 신경 정보 처리 시스템의 발전 35:7755-7768
* Mao 등(2021)* Mao 등(2023) Mao J, Qian Y, Zhao H, 등(2023a) Gpt-driver: Learning to driving with gpt. 2310. 01415
* Mao et al.(2023b) Mao J, Ye J, Qian Y, et al.(2023b) A language agent for autonomous driving. arXiv
* Marino 등(2019) Marino K, Rastegari M, Farhadi A, 등(2019) Ok-vqa: 외부 지식을 필요로 하는 시각적 질의 응답 벤치마크. In: 컨퍼런스 on Computer Vision and Pattern Recognition (CVPR)
* Mavi 등(2022) Mavi V, Jangra A, Jatowt A(2022) A survey on multi-hop question answering and generation. 2204.09140
* Megill and Wheeler(2019) Megill N, Wheeler DA(2019) A computer language for mathematical proofs. arXiv
* Mehta 등(2022) Mehta H, Gupta A, Cutkosky A, 등(2022) 게이트 상태 공간을 통한 장거리 언어 모델링. arXiv preprint arXiv:220613947
* Miao 등(2020) Miao Sy, Liang CC, Su KY(2020) A various corpus for evaluating and develop English math word problem solvers. In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp 975-984
* Mikula 등(2023) Mikula M, Antoniak S, Tworkowski S, 등(2023) Magnushammer: A transformer-based approach to premise selection. arXiv preprint arXiv:230304488
* Miller et al. (2016) Miller A, Fisch A, Dodge J, et al. (2016) Key-value memory networks for directly reading documents. In: 2016년 자연어 처리에서의 경험적 방법에 관한 회의의 진행. Association for Computational Linguistics, Austin, Texas, pp 1400-1409, [https://doi.org/10.18653/v1/D16-1147](https://doi.org/10.18653/v1/D16-1147), URL [https://aclanthology.org/D16-1147](https://aclanthology.org/D16-1147)
* Min 등(2022) Min S, Lewis M, Zettlemoyer L, 등(2022) MetaICL: Learning to learn in context. In: NAACL-HLT
* Mishra 등(2022) Mishra S, Khashabi D, Baral C, 등(2022) Cross-task generalization via natural language crowdsourcing instructions. In: ACL
* Misra 등(2022) Misra K, Rayz JT, Ettinger A(2022) A property induction framework for neural language models. arXiv preprint arXiv:220506910
* Mitra et al.(2023) Mitra A, Del Corro L, Mahajan S, et al.(2023) Orca 2: Teaching small language models how to reason. arXiv preprint arXiv:231111045
* Moghaddam and Honey (2023) Moghaddam SR, Honey CJ (2023) Boosting theory-of-mind performance in large language models via prompting. 2304.11490
* Mohamed 등(2022) Mohamed A, Lee Hy, Borgholt L, 등(2022) Self-supervised speech representation learning: A review. IEEE Journal of Selected Topics in Signal ProcessingMooij JM, Peters J, Janzing D, et al. (2016) Distinguishing cause from effect using Observational data: methods and benchmarks. 기계학습학회지 17(1):1103-1204
* Morris et al. (2012) Morris BJ, Croker S, Masnick AM, et al. (2012) The emergence of scientific reasoning. In: Kloos H, Morris BJ, Amaral JL(eds) Current Topics in Children's Learning and Cognition. IntechOpen, Rijeka, chap 4, [https://doi.org/10.5772/53885](https://doi.org/10.5772/53885), URL [https://doi.org/10.5772/53885](https://doi.org/10.5772/53885)
* de Moura et al.(2015) de Moura L, Kong S, Avigad J, et al.(2015) The lean theorem prover(system description) In: Automated Deduction-CADE-25: 25th International Conference on Automated Deduction, Berlin, Germany, August 1-7, 2015, Proceedings 25, Springer, pp 378-388
* Moura and Ullrich (2021) Moura Ld, Ullrich S (2021) The lean 4 theorem prover and programming language. In: Automated Deduction-CADE 28: 28th International Conference on Automated Deduction, Virtual Event, July 12-15, 2021, Proceedings 28, Springer, pp 625-635
* Mu 등(2023) Mu Y, Zhang Q, Hu M, 등(2023) Embodiedgpt: embodied chain of thought를 통한 Vision-language pre-training. arXiv preprint arXiv:230515021
* Muennighoff 등(2022) Muennighoff N, Wang T, Sutawika L, 등(2022) Crosslingual generalization through multitask finetuning. arXiv preprint arXiv:221101786
* Mukherjee et al. (2023) Mukherjee S, Mitra A, Jawahar G, et al. (2023) Orca: Progressive learning from complex explanation traces of gpt-4. arXiv preprint arXiv:230602707
* Mundler et al. (2023) Mundler N, He J, Jenko S, et al. (2023) Self-contradictory hallinations of large language models: Evaluation, detection and mitigation. 2305.15852
* Nascimento 등(2023) Nascimento N, Alencar P, Cowan D(2023) Self-adaptive large language model(llm) 기반 멀티 에이전트 시스템. 2307.06187
* 넬슨 등(2008) 넬슨 B, Barreno M, Chi FJ, 등(2008) Exploiting machine learning to subvert your spam filter. LEET 8(1-9):16-17
* Nguyen et al. (2023) Nguyen E, Poli M, Faizi M, et al. (2023) Hyenadna: Long-range genomic sequence modeling at single nucleotide resolution. arXiv preprint arXiv:230615794
* Nguyen et al. (2022) Nguyen T, Ilharco G, Wortsman M, et al. (2022) Quality not quantity: 데이터 세트 설계와 클립의 견고성 간의 상호 작용입니다. 신경정보처리시스템 35:21455-21469의 발전
* Nijkamp et al. (2022a) Nijkamp E, Pang B, Hayashi H, et al. (2022a) Codegen: An open large language model for code with multi-turn program synthesis. arXiv preprint arXiv:220313474
* Nijkamp 등(2022b) Nijkamp E, Ruffolo JA, Weinstein EN, 등(2022b) Progen2: exploring the boundaries of protein language models. Cell SystemsNijkamp E, Hayashi H, Xiong C, et al.(2023) Codegen2: Lessons for training llms on programming and natural languages. arXiv preprint arXiv:230502309
* Ning 등(2023) Ning X, Lin Z, Zhou Z, 등(2023) Skeleton-of-thought: Large language models can do parallel decoding. 2307.15337
* Nunes (2012) Nunes T (2012) Logical Reasoning and Learning, Springer US, Boston, MA, pp 2066-2069. [https://doi.org/10.1007/978-1-4419-1428-6_790](https://doi.org/10.1007/978-1-4419-1428-6_790), URL [https://doi.org/10.1007/978-1-4419-1428-6_790](https://doi.org/10.1007/978-1-4419-1428-6_790)
* Oberlander 등(1996) Oberlander J, Cox R, Stenning K(1996) Proof style in multimodal reasoning. In: 논리, 언어 및 계산입니다. CSLI Publications, p 403-414
* Odouard and Mitchell(2022) Odouard VV, Mitchell M(2022) Evaluating understanding on conceptual abstraction benchmarks. arXiv preprint arXiv:220614187
* Olaussson 등(2023) Olaussson TX, Inala JP, Wang C, 등(2023) Demystifying gpt self-repair for code generation. 2306.09896
* Oord 등(2018) Oord Avd, Li Y, Vinyals O(2018) Representation learning with contrastive predictive coding. arXiv preprint arXiv:180703748
* OpenAI(2023a) OpenAI(2023a) Gpt-4 기술 보고서. 2303.08774
* OpenAI(2023b) OpenAI(2023b) Gpt-4v(ision) 시스템 카드. arXiv URL [https://cdn.openai.com/papers/GPTV_System_Card.pdf](https://cdn.openai.com/papers/GPTV_System_Card.pdf)
* Ordonez 등(2011) Ordonez V, Kulkarni G, Berg T(2011) Im2text: 100만 개의 캡션된 사진을 사용하여 이미지를 기술함. 신경 정보 처리 시스템들에서의 발전들 24
* Ouyang et al. (2022) Ouyang L, Wu J, Jiang X, et al. (2022) Training language models to follow instructions with human feedback. 신경정보처리시스템 35:27730-27744의 발전
* Padalkar 등(2023) Padalkar A, Pooley A, Jain A, 등(2023) Open x-embodiment: Robotic learning datasets and rt-x models. arXiv preprint arXiv:231008864
* Pan et al.(2020) Pan B, Sun J, Leung HYT, et al.(2020) Cross-view semantic segmentation for sensing surroundings. IEEE Robotics and Automation Letters 5(3):4867-4873. [https://doi.org/10.1109/LRA.2020.3004325](https://doi.org/10.1109/LRA.2020.3004325)
* Pan et al. (2023a) Pan L, Albalak A, Wang X, et al. (2023a) Logic-lm: 충실한 논리적 추론을 위해 상징적 솔버로 대형 언어 모델을 임파워링한다. arXiv preprint arXiv:230512295
* Pan et al.(2023b) Pan Y, Pan L, Chen W, et al.(2023b) On the risk of misinformation pollution with large language models. 2305.13661Papineni K, Roukos S, Ward T, et al. (2002) Bleu: a method for automatic evaluation of machine translation. In: Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pp 311-318
* Paranjape 등(2023) Paranjape B, Lundberg S, Singh S, 등(2023) Art: Automatic multi-step reasoning and tool-use for large language models. 2303.09014
* Paster et al.(2023) Paster K, Santos MD, Azerbayev Z, et al.(2023) Openwebmath: An open dataset of high-quality mathematical web text. 2310.06786
* Pasupat and Liang(2015) Pasupat P, Liang P(2015) Compositional semantic parsing on semi-structured table. In: 제53회 전산언어학회 연차총회 및 제7회 자연어처리 국제공동회의 회보(제1권: 장문) Association for Computational Linguistics, Beijing, China, pp 1470-1480, [https://doi.org/10.3115/v1/P15-1142](https://doi.org/10.3115/v1/P15-1142), URL [https://aclanthology.org/P15-1142](https://aclanthology.org/P15-1142)
* Patel et al. (2021) Patel A, Bhattacharya S, Goyal N (2021) NLP 모델이 정말 간단한 수학 단어 문제를 해결할 수 있나요? In: Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics, Online, pp 2080-2094, [https://doi.org/10.18653/v1/2021.naacl-main.168](https://doi.org/10.18653/v1/2021.naacl-main.168), URL [https://aclanthology.org/2021.naacl-main.168](https://aclanthology.org/2021.naacl-main.168)
* Paul 등(2023) Paul D, Ismayilzada M, Peyrard M, 등(2023) Refiner: Reasoning feedback on intermediate representation. 2304.01904
* Paulson(1994) Paulson LC(1994) Isabelle: A generic theorem prover. 스프링거
* Paulson (2010) Paulson LC (2010) 자동 및 대화형 정리 프로버 간의 실용적인 연결인 sledgehammer에 대 한 3 년의 경험입니다. In: Schmidt RA, Schulz S, Konev B(eds) Proceedings of the 2nd Workshop on Practical Aspects of Automated Reasoning, PAAR-2010, Edinburgh, Scotland, UK, July 14, 2010, July 14, EPiC Series in Computing, vol. EasyChair, pp 1-10, [https://doi.org/10.29007/tnfd](https://doi.org/10.29007/tnfd), URL [https://doi.org/10.29007/tnfd](https://doi.org/10.29007/tnfd)
* Peng 등(2023a) Peng B, Alcaide E, Anthony Q, 등(2023a) Rwkv: Reinventing rnns for the transformer era. arXiv preprint arXiv:230513048
* Peng et al. (2023b) Peng B, Galley M, He P, et al. (2023b) 팩트를 확인하고 다시 시도합니다. 외부 지식 및 자동화된 피드백을 사용하여 대형 언어 모델을 개선합니다. arXiv preprint arXiv:230212813
* Peng 등(2023c) Peng B, Li C, He P, 등(2023c) Instruction tuning with gpt-4. arXiv preprint arXiv:230403277Peng Z, Wang W, Dong L, 등(2023d) Kosmos-2: Grounding multimodal large language models to the world. 2306.14824
* Perez 및 Ribeiro (2022) Perez F, Ribeiro I (2022) 이전 프롬프트: 언어 모델에 대 한 공격 기술을 무시 합니다. arXiv preprint arXiv:221109527
* Peters 등(2017) Peters J, Janzing D, Scholkopf B(2017) Elements of causal inference: foundations and learning algorithms. 상기 MIT 프레스는
* Pfeiffer 등(2020) Pfeiffer J, Vulic I, Gurevych I, 등(2020) Mad-x: An adapter-based framework for multi-task cross-lingual transfer. arXiv preprint arXiv:200500052
* Pham 등(2023) Pham H, Dai Z, Ghiasi G, 등(2023) Combined scaling for zero-shot transfer learning. Neurocomputing 555:126658
* Pi 등(2023) Pi R, Gao J, Diao S, 등(2023) Detgpt: 추론을 통해 필요한 것을 검출한다. 2305.14167
* Pilault 등(2020) Pilault J, Li R, Subramanian S, 등(2020) On Extractive and abstractive neural document summarization with transformer language models. In: Webber B, Cohn T, He Y, et al. (eds) Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)). Association for Computational Linguistics, Online, pp 9308-9319, [https://doi.org/10.18653/v1/2020.emnlp-main.748](https://doi.org/10.18653/v1/2020.emnlp-main.748), URL [https://aclanthology.org/2020.emnlp-main.748](https://aclanthology.org/2020.emnlp-main.748)
* Leibniz-Zentrum fur Informatik, Dagstuhl, Germany, pp 1:1-1:18, [https://doi.org/10.4230/LIPIcs.ECRTS.2021.1](https://doi.org/10.4230/LIPIcs.ECRTS.2021.1), URL [https://drops.dagstuhl.de/opus/volltexte/2021/13932](https://drops.dagstuhl.de/opus/volltexte/2021/13932)
* Poli 등(2023) Poli M, Massaroli S, Nguyen E, 등(2023) Hyena hierarchy: Towards the larger convolutional language models. arXiv preprint arXiv:230210866
* Pollock(1987) Pollock JL(1987) Defeasible reasoning. 인지과학 11(4):481-518
* Pollock (1991) Pollock JL (1991) The theory of defeasible reasoning. International Journal of Intelligent Systems 6(1):33-54
* Pollock (2009) Pollock JL (2009) The recursive semantics for defeasible reasoning. 인공지능 pp 173-197의 논증
* Polu and Sutskever(2020) Polu S, Sutskever I(2020) Generative language modeling for automated theorem prove. arXiv preprint arXiv:200903393
* Polu 등(2023) Polu S, Han JM, Zheng K, 등(2023) 형식수학 진술 교육과정 학습. In: The 11번째 International Conference on Learning RepresentationsPratap V, Xu Q, Sriram A, et al. (2020) MLS: A large-scale multilingual dataset for speech research. In: INTERSPEECH, pp 2757-2761
* Press et al.(2023) Press O, Zhang M, Min S, et al.(2023) 언어 모델에서 구성성 갭을 측정하고 좁힌다. 2210.03350
* Pryor 등(2023) Pryor C, Dickens C, Augustine E, 등(2023) Neupsl: Neural probabilistic soft logic. 2205.14268
* Puig 등(2018) Puig X, Ra K, Boben M, 등(2018) Virtualhome: 프로그램을 통한 가정 활동 시뮬레이션. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp 8494-8502
* Qian et al. (2023a) Qian C, Han C, Fung YR, et al. (2023a) Creator: 도구 생성을 통한 대형 언어 모델의 추상적이고 구체적인 추론들을 Disentangling 한다. 2305.14318
* Qian 등(2023b) Qian T, Chen J, Zhuo L, 등(2023b) Nuscenes-qa: A multi-modal visual question answering benchmark for autonomous driving scenario. arXiv preprint arXiv:230514836
* Qiao et al.(2022) Qiao S, Ou Y, Zhang N, et al.(2022) Reasoning with language model prompting: survey. arXiv preprint arXiv:221209597
* Qiao et al. (2023) Qiao S, Gui H, Chen H, et al. (2023) Making language models made better tool learners with execution feedback. 2305.13068
* Qin et al. (2020) Qin J, Lin L, Liang X, et al. (2020) Semantically-aligned universal tree-structured solver for math word problems. ArXiv abs/2010.06823
* Qin 등(2023) Qin Y, Hu S, Lin Y, 등(2023) Tool learning with foundation models. 2304.08354
* Qiu et al. (2022) Qiu J, Chen L, Gu X, et al. (2022) Egocentric human trajectory forecasting with wearable camera and multi-modal fusion. IEEE Robotics and Automation Letters 7(4):8799-8806
* Qiu 등(2023a) Qiu J, Li L, Sun J, 등(2023a) Large ai model in health informationatics: Applications, challenges, and future. IEEE Journal of Biomedical and Health Informatics
* Qiu et al.(2023b) Qiu J, Wu J, Wei H, et al.(2023b) Visionfm: a multi-modal multi-task vision foundation model for generalist ophthalmic artificial intelligence. arXiv preprint arXiv:231004992
* Radford et al. (2018) Radford A, Narasimhan K, Salimans T, et al. (2018) Generative Pre-training에 의한 언어 이해력 향상. arXiv
* Radford 등(2019) Radford A, Wu J, Child R, 등(2019) Language models are nonsupervised multitask learners. OpenAI 블로그 1(8):9
*Radford et al. (2020)Radford A, Kim JW, Hallacy C, et al. (2021) Learning transferable visual models from natural language supervision. In: International conference on machine learning, PMLR, pp 8748-8763
* Rae et al. (2021) Rae JW, Borgeaud S, Cai T, et al. (2021) Scaling language models: Methods, analysis & insights from training gopher. arXiv preprint arXiv:211211446
* Rafailov et al. (2023) Rafailov R, Sharma A, Mitchell E, et al. (2023) Direct preference optimization: Your language model is secretly a reward model. arXiv preprint arXiv:230518290
* Raffel et al. (2019) Raffel C, Shazeer N, Roberts A, et al. (2019) Exploring the limit of transfer learning with a unified text-to-text transformer. arXiv e-prints arXiv:1910.10683
* Raheja 등(2023) Raheja V, Kumar D, Koo R, 등(2023) Coedit: task-specific instruction tuning에 의한 Text 편집. arXiv arXiv:2305.09857 [cs.CL]
* Rajani 등(2019) Rajani NF, McCann B, Xiong C, 등(2019) 설명하라! 상식 추론을 위한 언어 모델 활용 In: Proceedings of the 2019 Conference of the Association for Computational Linguistics (ACL2019), URL [https://arxiv.org/abs/1906.02361](https://arxiv.org/abs/1906.02361)
* Rajani 등(2020) Rajani NF, Zhang R, Tan YC, 등(2020) ESPRIT: Explaining solutions to physical reasoning tasks. In: 계산 언어학 협회의 제58차 연례 회의 진행. Association for Computational Linguistics, Online, pp 7906-7917, [https://doi.org/10.18653/v1/2020.acl-main.706](https://doi.org/10.18653/v1/2020.acl-main.706), URL [https://aclanthology.org/2020.acl-main.706](https://aclanthology.org/2020.acl-main.706)
* Rajpurkar 등(2016) Rajpurkar P, Zhang J, Lopyrev K, 등(2016) SQuAD: 100,000+ questions for machine comprehension of text. In: 2016년 자연어 처리에서의 경험적 방법에 관한 회의의 진행. Association for Computational Linguistics, Austin, Texas, pp 2383-2392, [https://doi.org/10.18653/v1/D16-1264](https://doi.org/10.18653/v1/D16-1264), URL [https://aclanthology.org/D16-1264](https://aclanthology.org/D16-1264)
* Raven and Court (1938) Raven JC, Court J (1938) Raven's progressive matrices. LA 서부 심리 서비스, 캘리포니아
* Rawte 등(2023) Rawte V, Sheth A, Das A(2023) A survey of hallucination in large foundation models. 2309.05922
* Redbooks(2004) Redbooks I(2004) Practical Guide to the IBM Autonomic Computing Toolkit. IBM
* Reed 등(2022) Reed S, Zolna K, Parisotto E, 등(2022) A generalist agent. arXiv preprint arXiv:220506175
* Reimers and Gurevych (2019) Reimers N, Gurevych I (2019) Sentence-bert: siamese bert-networks를 이용한 문장 임베딩. arXiv preprint arXiv:190810084Reiter R(1975) 형식 추론 및 언어 이해 시스템. In: 자연어 처리의 이론적 쟁점
* Ren and Zhu(2023) Ren S, Zhu KQ(2023) Low-rank prune-and-factorize for language model compression. 2306.14152
* Ren et al. (2023) Ren X, Zhou P, Meng X, et al. (2023) Pangu-\(\backslash{sigma}\): 희소 이종의 컴퓨팅을 사용하는 조 단위의 매개 변수 언어 모델입니다. arXiv preprint arXiv:230310845
* Ridnik et al. (2021) Ridnik T, Ben-Baruch E, Noy A, et al. (2021) Imagenet-21k preraining for the masses. In: 신경정보처리시스템 데이터셋과 벤치마크 트랙에 관한 제5차 회의(1라운드)
* Roller 등(2020) Roller S, Dinan E, Goyal N, 등(2020) Recipes for building a open-domain chatbot. arXiv preprint arXiv:200413637
* Rombach 등(2022) Rombach R, Blattmann A, Lorenz D, 등(2022) 잠재 확산 모델을 이용한 고해상도 영상 합성. In: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp 10684-10695
* Roziere 등(2023) Roziere B, Gehring J, Gloeckle F, 등(2023) Code llama: Open foundation models for code. arXiv preprint arXiv:230812950
* Rubin 등(2022) Rubin O, Herzig J, Berant J(2022) Learning to retrieve prompts for in-context learning. In: Proceedings of the 2022 Conference of the North American Chapter of Association for Computational Linguistics: Human Language Technologies, pp 2655-2671
* Rudinger 등(2020) Rudinger R, Shwartz V, Hwang JD, 등(2020) Thinking like a skeptic: Defeasible inference in natural language. In: Association of Association for Computational Linguistics: EMNLP 2020. Association for Computational Linguistics, Online, pp 4661-4675, [https://doi.org/10.18653/v1/2020.findings-emnlp.418](https://doi.org/10.18653/v1/2020.findings-emnlp.418), URL [https://aclanthology.org/2020.findings-emnlp.418](https://aclanthology.org/2020.findings-emnlp.418)
* 사찬과 싱(2017) 사찬 M, 싱 E(2017) 교과서의 자연어 시범에서 기하 문제를 푸는 학습. In: Proceedings of the 6th Joint Conference on Lexical and Computational Semantics(*SEM 2017). Association for Computational Linguistics, Vancouver, Canada, pp 251-261, [https://doi.org/10.18653/v1/S17-1029](https://doi.org/10.18653/v1/S17-1029), URL [https://aclanthology.org/S17-1029](https://aclanthology.org/S17-1029)
* Sachan and Dubey (2017) Sachan M, Dubey K, Xing E (2017) 교과서에서 지식까지: 기하 문제를 해결하기 위해 교과서에서 공리적 지식을 수확하는 사례 연구 In: Palmer M, Hwa R, Riedel S(eds) Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Copenhagen, Denmark, pp 773-784, [https://doi.org/10.18653/v1/D17-1081](https://doi.org/10.18653/v1/D17-1081), URL [https://aclanthology.org/D17-1081](https://aclanthology.org/D17-1081)Sakaguchi K, Bras RL, Bhagavatula C, et al. (2021) Winogrande: An adversarial winograd schema challenge at scale. ACM 64(9):99-106의 통신
* Salmon 등(1989) Salmon W, Salmon M, Kitcher P(1989) Scientific explanation. 미니애폴리스
* Sanh et al. (2021) Sanh V, Webson A, Raffel C, et al. (2021) Multitask prompted training enable zero-shot task generalization. 2110.08207
* Sap 등(2019) Sap M, Rashkin H, Chen D, 등(2019) Social IQa: 사회적 상호작용에 대한 상식 추론. In: Proceedings of 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) Association for Computational Linguistics, Hong Kong, China, pp 4463-4473, [https://doi.org/10.18653/v1/D19-1454](https://doi.org/10.18653/v1/D19-1454), URL [https://aclanthology.org/D19-1454](https://aclanthology.org/D19-1454)
* Saparov 및 He (2023) Saparov A, He H (2023) 언어 모델은 탐욕스러운 추론자: 연쇄 사상의 체계적인 형식 분석입니다. In: 학습 표현에 대 한 11 번째 국제 회의, URL [https://openreview.net/forum?id=qFVVBzXxR2V](https://openreview.net/forum?id=qFVVBzXxR2V)입니다.
* 새비지 (2023) 새비지 N (2023) 약물 검색 회사는 채팅을 사용자 지정 합니다. 다음은 방법입니다. 자연생명공학
* Sawada et al. (2023) Sawada T, Paleka D, Havrilla A, et al. (2023) Arb: Advanced reasoning benchmark for large language models. 2307.13692
* Scao 등(2022) Scao TL, Fan A, Akiki C, 등(2022) Bloom: A 176b-parameter open-access 다국어 언어 모델. arXiv preprint arXiv:221105100
* Schick 등(2022) Schick T, Dwivedi-Yu J, Jiang Z, 등(2022) Peer: A collaborative language model. arXiv preprint arXiv:220811663
* Schick et al. (2023) Schick T, Dwivedi-Yu J, Dessi R, et al. (2023) Toolformer: Language models can teach themselves to use tools. 2302.04761
* Schmidhuber (2015) Schmidhuber J (2015) Deep learning in neural networks: overview. 신경 회로망 61:85-117
* Schuhmann et al. (2021) Schuhmann C, Vencu R, Beaumont R, et al. (2021) Laion-400m: Open dataset of clip-filtered 4억 image-text pairs. arXiv preprint arXiv:211102114
* Schuhmann et al. (2022) Schuhmann C, Beaumont R, Vencu R, et al. (2022) Laion-5b: An open large-scale dataset for training next generation image-text models. 신경 정보 처리 시스템의 발전 35:25278-25294
* Schulman et al. (2017) Schulman J, Wolski F, Dhariwal P, et al. (2017) Proximal policy optimization algorithms. arXiv preprint arXiv:170706347
* Schulman et al.(2017)Scholkopf B, Locatello F, Bauer S, et al.(2021) Toward causal representation learning. Proceedings of IEEE 109(5):612-634. [https://doi.org/10.1109/JPROC.2021.3058954](https://doi.org/10.1109/JPROC.2021.3058954)
* Seff 등(2023) Seff A, Cera B, Chen D, 등(2023) MotionLM: Multi-Agent Motion Forecasting as Language Modeling. In: ICCV
* Seo et al. (2015) Seo M, Hajishirzi H, Farhadi A, et al. (2015) Solving geometry problems: Combining text and diagram interpretation. In: Marquez L, Callison-Burch C, Su J(eds) Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Lisbon, Portugal, pp 1466-1476, [https://doi.org/10.18653/v1/D15-1171](https://doi.org/10.18653/v1/D15-1171), URL [https://aclanthology.org/D15-1171](https://aclanthology.org/D15-1171)
* Sha 등(2023) Sha H, Mu Y, Jiang Y, 등(2023) Languagempc: Large language models as decision makers for autonomous driving. arXiv preprint arXiv:231003026
* Shah et al.(2021) Shah D, Xu P, Lu Y, et al.(2021) Value function spaces: Skill-centric state abstractions for long-horizon reasoning. arXiv preprint arXiv:211103189
* Shao et al.(2023) Shao Z, Yu Z, Wang M, et al.(2023) Prompting large language models with answer heuristics for knowledge-based visual question answer. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 14974-14983
* Sharma et al. (2018) Sharma P, Ding N, Goodman S, et al. (2018) Conceptual captions: A cleaned, hyper-nymed, image alt-text dataset for automatic image captioning. In: Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics(Volume 1: Long Papers), pp 2556-2565
* Sharma 등(2021) Sharma P, Torralba A, Andreas J(2021) Skill induction and planning with latent language. arXiv preprint arXiv:211001517
* Shazeer 등(2017) Shazeer N, Mirhoseini A, Maziarz K, 등(2017) Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. arXiv preprint arXiv:170106538
* Shen 등(2021a) Shen J, Yin Y, Li L, 등(2021a) Generate & rank: A multi-task framework for math word problems. In: Moens MF, Huang X, Specia L, et al. (eds) Findings of the Association for Computational Linguistics: EMNLP 2021. Association for Computational Linguistics, Punta Cana, Dominican Republic, pp 2269-2279, [https://doi.org/10.18653/v1/2021.findings-emnlp.195](https://doi.org/10.18653/v1/2021.findings-emnlp.195), URL [https://aclanthology.org/2021.findings-emnlp.195](https://aclanthology.org/2021.findings-emnlp.195)
* Shen 등(2021b) Shen L, Ji S, Zhang X, 등(2021b) Backdoor pre-trained models can transfer to all. arXiv preprint arXiv:211100197Shen S, Li C, Hu X, et al. (2022) K-lite: Learning transferable visual models with external knowledge. 신경정보처리시스템 35:15558-15573의 발전
* Shen et al. (2023) Shen Y, Song K, Tan X, et al. (2023) Hugginggpt: Chatgpt and its friends in hug face. 2303.17580
* Shi et al.(2023) Shi F, Suzgun M, Freitag M, et al.(2023) Language models are multilingual chain-of-thought reasoners. In: 학습 표현에 대 한 11 번째 국제 회의, URL [https://openreview.net/forum?id=fR3wGCk-IXp](https://openreview.net/forum?id=fR3wGCk-IXp)입니다.
* Shi et al. (2015) Shi S, Wang Y, Lin CY, et al. (2015) 의미 파싱 및 추론에 의해 숫자 단어 문제를 자동으로 해결함. 자연어처리(自然調處理)에 관한 실험적(實驗的) 연구(硏究)
* Shi et al.(2022) Shi W, Shea R, Chen S, et al.(2022) Just fine-tune twice: Selective differential privacy for large language models. arXiv preprint arXiv:220407667
* Shin et al. (2020) Shin T, Razeghi Y, Logan IV RL, et al. (2020) Autoprompt: 자동으로 생성된 프롬프트를 갖는 언어 모델로부터 지식을 유도하는 것. arXiv preprint arXiv:201015980
* Shinn et al. (2023) Shinn N, Cassano F, Labash B, et al. (2023) Reflexion: Language agent with verbal reinforcement learning. 2303.11366
* Shreya and Khapra (2022) Shreya G, Khapra MM (2022) A survey in adversarial defense and robustness in nlp. arXiv preprint arXiv:220306414
* Shridhar 등(2023) Shridhar K, Stolfo A, Sachan M(2023) Distilling reasoning capabilities into smaller language models. In: Association for Computational Linguistics: ACL 2023. Association for Computational Linguistics, Toronto, Canada, pp 7059-7073, [https://doi.org/10.18653/v1/2023.findings-acl.441](https://doi.org/10.18653/v1/2023.findings-acl.441), URL [https://aclanthology.org/2023.findings-acl.441](https://aclanthology.org/2023.findings-acl.441)
* Silver et al.(2016) Silver D, Huang A, Maddison CJ, et al.(2016) Mastering the game of go with deep neural networks and tree search. nature 529(7587):484-489
* Silver et al.(2018) Silver D, Hubert T, Schrittwieser J, et al.(2018) Chess, shogi, self-play를 마스터하고 거치는 일반적인 강화학습 알고리즘. Science 362(6419):1140-1144
* Singh 등(2023) Singh I, Blukis V, Mousavian A, 등(2023) Progprompt: 대형 언어 모델을 사용하여 상황 로봇 작업 계획을 생성하는 것. In: 2023 IEEE International Conference on Robotics and Automation (ICRA), IEEE, pp 11523-11530
* Singh et al.(2022) Singh M, Gustafson L, Adcock A, et al.(2022) Revisiting weakly supervised pre-training of visual perception models. In: Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition, pp 804-814
* Singhal et al. (2023) Singhal K, Tu T, Gottweis J, et al. (2023) Towards the expert-level medical question answer with large language models. arXiv preprint arXiv:230509617
* Sinha et al. (2019) Sinha K, Sodhani S, Dong J, et al. (2019) Clutrr: A diagnostic benchmark for induction reasoning from text. arXiv preprint arXiv:190806177
* Soldaini and Lo(2023) Soldaini L, Lo K(2023) peS2o(Pretraining Efficiently on S2ORC) Dataset. Tech. rep., Allen Institute for AI, oDC-By, [https://github.com/allenai/pes2o](https://github.com/allenai/pes2o)
* Song et al.(2023a) Song CH, Wu J, Washington C, et al.(2023a) Llm-planner: Few-shot grounded planning for embodied agent with large language models. 2212.04088
* Song et al.(2023b) Song F, Yu B, Li M, et al.(2023b) Preference ranking optimization for human alignment. arXiv preprint arXiv:230617492
* Song et al. (2018) Song X, Shi Y, Chen X, et al. (2018) Explore multi-step reasoning in video question answer. In: Proceedings of the 26th ACM international conference on Multimedia, pp 239-247
* Sowa (2003) Sowa JF (2003) 법칙, 사실 및 컨텍스트: 복합 추론을 위한 기초입니다. In: 지식 기여자. 스프링거, p 145-184
* Speer 등(2017) Speer R, Chin J, Havasi C(2017) Conceptnet 5.5: 개방형 다국어 일반지식 그래프. In: 인공지능에 관한 30번째 AAAI 회의의 진행. AAAI Press, AAAI'17, p 4444-4451
* Srinivasan 등(2021) Srinivasan K, Raman K, Chen J, 등(2021) Wit: Wikipedia 기반 이미지 텍스트 데이터셋 for multimodal multilingual machine learning. In: Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp 2443-2449
* Srivastava 등(2023) Srivastava A, Rastogi A, Rao A, 등(2023) Beyond the imitation game: Quantified and extrapolating of language models. Machine Learning 연구 URL의 트랜잭션 [https://openreview.net/forum?id=uyTL5Bvosj](https://openreview.net/forum?id=uyTL5Bvosj)
* Stolfo et al. (2022) Stolfo A, Jin Z, Shridhar K, et al. (2022) A causal framework to quantified of mathematical reasoning with language models. arXiv preprint arXiv:221012023
* Strehl 및 Ghosh (2002) Strehl A, Ghosh J (2002) 클러스터는 여러 파티션을 결합 하기 위한 지식 재사용 프레임워크입니다. Machine Learning Research 3(Dec):583-617 저널
* Subramanian et al.(2023) Subramanian S, Harrington P, Keutzer K, et al.(2023) Towards foundation models for scientific machine learning: Charactering scaling and transfer behavior. 2306.00258
* Sun et al. (2023a) Sun A, Ma P, Yuan Y, et al. (2023a) Explain any concept: Segment anything meets concept-based explanation. 2305.10289
* Sun et al. (2023b)Sun C, Shrivastava A, Singh S, et al. (2017) Revisiting unreasonable effectiveness of data in deep learning era. In: Proceedings of the IEEE International conference on computer vision, pp 843-852
* Sun et al.(2021) Sun J, Sun H, Han T, et al.(2021) Neuro-symbolic program search for autonomous driving decision module design. In: Kober J, Ramos F, Tomlin C(eds) Proceedings of the 2020 Conference on Robot Learning, Proceedings of Machine Learning Research, vol 155. PMLR, pp 21-30, URL [https://proceedings.mlr.press/v155/sun21a.html](https://proceedings.mlr.press/v155/sun21a.html)
* Sun et al.(2022a) Sun J, Huang DA, Lu B, et al.(2022a) Plate: Visually-grounded planning with transformers in procedural tasks. IEEE Robotics and Automation Letters 7(2):4924-4930
* Sun et al.(2022b) Sun J, Kousik S, Fridovich-Keil D, et al.(2022b) Self-supervised traffic advisor: Distributed, multi-view traffic prediction for smart cities. In: 2022 IEEE 25th International Conference on Intelligent Transportation Systems (ITSC), pp 917-922, [https://doi.org/10.1109/ITSC55140.2022.9922340](https://doi.org/10.1109/ITSC55140.2022.9922340)
* Sun et al. (2023b) Sun J, Jiang Y, Qiu J, et al. (2023b) Conformal prediction for uncertainty-aware planning with diffusion dynamics model. 신경정보처리시스템에 관한 제37회 회의
* Sun et al.(2023c) Sun J, Kousik S, Fridovich-Keil D, et al.(2023c) Connected autonomous vehicle motion planning with video predictions from smart, self-supervised infrastructure. arXiv preprint arXiv:230907504
* Sun et al.(2023d) Sun M, Liu Z, Bair A, et al.(2023d) A simple and effective pruning approach for large language models. 2306.11695
* Sun et al.(2023e) Sun Q, Yin Z, Li X, et al.(2023e) Corex: 다중 모델 협업을 통해 복잡한 추론의 경계를 밀어낸다. 2310.00280
* Sun et al.(2020) Sun T, Shao Y, Qiu X, et al.(2020) CoLAKE: Contextualized language and knowledge embedding. In: Scott D, Bel N, Zong C(eds) Proceedings of the 28th International Conference on Computational Linguistics. International Committee on Computational Linguistics, Barcelona, Spain (Online), pp 3660-3670, [https://doi.org/10.18653/v1/2020.coling-main.327](https://doi.org/10.18653/v1/2020.coling-main.327), URL [https://aclanthology.org/2020.coling-main.327](https://aclanthology.org/2020.coling-main.327)
* Sun et al.(2023f) Sun Y, Dong L, Huang S, et al.(2023f) Retentive network: A successor to transformer for large language models. arXiv preprint arXiv:230708621
* Suvorov 등(2021) Suvorov R, Logacheva E, Mashikhin A, 등(2021) Resolution-robust large mask inpainting with fourier convolutions. arXiv preprint arXiv:210907161
* Svyatkovskiy 등(2020) Svyatkovskiy A, Deng SK, Fu S, 등(2020) Intellicode compose: Transformer를 이용한 Code 생성. In: Proceedings of 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp 1433-1443
* Szot et al. (2021) Szot A, Clegg A, Undersander E, et al. (2021) Habitat 2.0: Training home assistants to rearrange their habitat. In: 신경 정보 처리 시스템(NeurIPS)의 발전
* Tafjord 등(2021) Tafjord O, Dalvi B, Clark P(2021) ProofWriter: 자연어를 통한 의미, 증명, 귀납적 진술 생성. In: Association of Association for Computational Linguistics: ACL-IJCNLP 2021. Association for Computational Linguistics, Online, pp 3621-3634, [https://doi.org/10.18653/v1/2021.findings-acl.317](https://doi.org/10.18653/v1/2021.findings-acl.317), URL [https://aclanthology.org/2021.findings-acl.317](https://aclanthology.org/2021.findings-acl.317)
* Tafjord 등(2022) Tafjord O, Dalvi Mishra B, Clark P(2022) Entailer: Answering questions with faithful and truthful chains of reasoning. In: 2022년 자연어처리 실증방법에 관한 회의의 진행. Association for Computational Linguistics, Abu Dhabi, United Arab Emirates, pp 2078-2093, [https://doi.org/10.18653/v1/2022.emnlp-main.134](https://doi.org/10.18653/v1/2022.emnlp-main.134), URL [https://aclanthology.org/2022.emnlp-main.134](https://aclanthology.org/2022.emnlp-main.134)
* Talmor 및 Berant (2018) Talmor A, Berant J (2018) 웹은 복잡한 질문에 응답하기 위한 지식 기반입니다. In: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1(Long Papers). Association for Computational Linguistics, New Orleans, Louisiana, pp 641-651, [https://doi.org/10.18653/v1/N18-1059](https://doi.org/10.18653/v1/N18-1059), URL [https://aclanthology.org/N18-1059](https://aclanthology.org/N18-1059)
* Talmor 등(2019) Talmor A, Herzig J, Lourie N, 등(2019) CommonsenseQA: 상식 지식을 대상으로 하는 질문 응답 도전. In: Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1(Long and Short Papers). Association for Computational Linguistics, Minneapolis, Minnesota, pp 4149-4158, [https://doi.org/10.18653/v1/N19-1421](https://doi.org/10.18653/v1/N19-1421), URL [https://aclanthology.org/N19-1421](https://aclanthology.org/N19-1421)
* Talmor 등 (2021) Talmor A, Yoran O, Catav A, 등 (2021) Multimodal{qa}: 텍스트, 테이블 및 이미지를 통한 복잡한 질문 응답입니다. In: International Conference on Learning Representations, URL [https://openreview.net/forum?id=ee6W5UgQLa](https://openreview.net/forum?id=ee6W5UgQLa)
* Tan 등(2023) Tan S, Ivanovic B, Weng X, 등(2023) Language conditioned traffic generation. (주)코알
* Tandon et al.(2021) Tandon N, Madaan A, Clark P, et al.(2021) Interscript: 오류 피드백을 통한 스크립트의 대화형 학습을 위한 데이터셋. arXiv preprint arXiv:211207867
* Tao et al.(2022) Tao C, Hou L, Zhang W, et al.(2022) Compression of generative pre-trained language models via quantization. 2203.10705
* Tandon 등(2021) Tao M, Bao BK, Tang H, 등(2023) Galip: Generative Adversarial Clips for text-to-image synthesis. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 14214-14223
* Taori 등(2023) Taori R, Gulrajani I, Zhang T, 등(2023) Alpaca: A strong, replicable instruction-following model. 기초 모델 연구를 위한 스탠포드 센터 https://crfm stanford edu/2023/03/13/alpaca html 3(6):7
* Taylor 등(2022) Taylor R, Kardas M, Cucurull G, 등(2022) Galactica: A large language model for science. arXiv preprint arXiv:221109085
* Team (2022) Team G (2022) GT4SD (Generative Toolkit for Scientific Discovery). URL [https://github.com/GT4SD/gt4sd-core](https://github.com/GT4SD/gt4sd-core)
* Teig and Scherer (2016) Teig N, Scherer R (2016) 공식 및 비공식 추론을 함께 가져오는 새로운 평가 시대입니다. 심리학계의 프론티어 7:1097
* Thomee et al. (2016) Thomee B, Shamma DA, Friedland G, et al. (2016) Yfcc100m: The new data in multimedia research. ACM 59(2):64-73의 통신
* Thoppilan 등(2022) Thoppilan R, De Freitas D, Hall J, 등(2022) Lamda: Language models for dialog applications. arXiv preprint arXiv:220108239
* Tian 등(2022) Tian J, Li Y, Chen W, 등(2022) Weakly supervised neural symbolic learning for cognitive tasks. In: Proceedings of the AAAI Conference on Artificial Intelligence, pp 5888-5896
* Tomasic 등(2021) Tomasic A, Romero OJ, Zimmerman J, 등(2021) Propositional reasoning via neural transformer language models. arXiv
* Tong et al. (2022) Tong Z, Song Y, Wang J, et al. (2022) Videomae: Masked autoencoder는 자체 감독 비디오 사전 훈련을 위한 데이터 효율적인 학습자이다. 2203.12602
* Touvron 등(2023) Touvron H, Lavril T, Izacard G, 등(2023a) Llama: Open and efficient foundation language models. 2302.13971
* Touvron 등(2023b) Touvron H, Martin L, Stone K, 등(2023b) Llama 2: Open Foundation and fine-tuned chat models. 2307.09288
* Tsai 등(2022) Tsai HS, Chang HJ, Huang WC, 등(2022) SUPERB-SG: Enhanced Speech processing Universal PERformance Benchmark for Semantic and Generative Capabilities. In: Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics, pp 8479-8492
* Tsimpoukelli et al. (2021) Tsimpoukelli M, Menick J, Cabi S, et al. (2021) Multimodal few-shot learning with frozen language models. In: Beygelzimer A, Dauphin Y, Liang P, et al. (eds) Advances in Neural Information Processing Systems, URL [https://openreview.net/forum?id=WtmMyno9Tq2](https://openreview.net/forum?id=WtmMyno9Tq2)* Tu et al. (2020) Tu M, Huang K, Wang G, et al. (2020) Select, answer and explain: Interpretable multi-hop reading comprehension over multiple documents. In: Proceedings of the AAAI conference on artificial intelligence, pp 9073-9080
* Tu 등(2019) Tu R, Zhang K, Bertilson B, 등(2019) 인과관계 발견 알고리즘 평가를 위한 신경병증성 통증 진단 시뮬레이터. 신경정보처리시스템 32의 발전
* Tu 등(2023a) Tu R, Ma C, Zhang C(2023a) Causal-discovery performance of chatgpt in the context of neuropathic pain diagnosis. 2301.13819
* Tu et al. (2023b) Tu T, Azizi S, Driess D, et al. (2023b) Towards generalist biomedical ai. arXiv preprint arXiv:230714334
* Tung 등(2023) Tung HY, Ding M, Chen Z, 등(2023) Physion++: 서로 다른 물리적 속성의 온라인 추론을 필요로 하는 물리적 장면 이해의 평가. arXiv preprint arXiv:230615668
* Tunstall 등(2022) Tunstall L, Von Werra L, Wolf T(2022) Transformer를 이용한 자연어 처리. (주)오라일리미디어
* Upadhyay and Chang(2015) Upadhyay S, Chang MW(2015) Draw: 도전적이고 다양한 대수 단어 문제 세트
* Upadhyay and Chang(2017) Upadhyay S, Chang MW(2017) Annotating derivations: A new evaluation strategy and dataset for algebra word problems. In: 계산 언어학 협회의 유럽 제15차 회의의 회보: 제1권, 긴 논문. Association for Computational Linguistics, Valencia, Spain, pp 494-504, URL [https://aclanthology.org/E17-1047](https://aclanthology.org/E17-1047)
* Valipour 등(2022) Valipour M, Rezagholizadeh M, Kobyzev I, 등(2022) Dylora: Parameter efficient tuning of pre-trained models using dynamic search-free low-rank adaptation. arXiv preprint arXiv:221007558
* Van Den Oord 등(2017) Van Den Oord A, Vinyals O, 등(2017) Neural Discrete Representation Learning. 신경 정보 처리 시스템(30)의 발전
* Vaswani 등(2017) Vaswani A, Shazeer N, Parmar N, 등(2017) Attention만 있으면 된다. 신경 정보 처리 시스템(30)의 발전
* Vedantam 등(2015) Vedantam R, Zitnick CL, Parikh D(2015) Cider: Consensus-based image description evaluation. 1411.5726
* Vilares 등(2018) Vilares D, Peng H, Satapathy R, 등(2018) Babelsenicnet: a commonense reasoning framework for multilingual sentiment analysis. In: 2018 IEEE symposium series on computational intelligence (SSCI), IEEE, pp 1292-1298
* Waldmann and Hagmayer (2013) Waldmann MR, Hagmayer Y (2013) 인과 추론. arXivWan Z, Cheng F, Mao Z, et al.(2023) Gpt-re: In-context learning for relation extraction using large language models. 2305.02105
* Wang (2021) Wang B (2021) Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer Language Model with JAX. [https://github.com/kingoflolz/mesh-transformer-jax] (https://github.com/kingoflolz/mesh-transformer-jax)
* Wang 등(2021) Wang B, Komatsuzaki A(2021) Gpt-j-6b: A 60 billion parameter autoregressive language model
* Wang 등(2022a) Wang B, Deng X, Sun H(2022a) Iteratively prompt pre-trained language models for chain of thought. arXiv preprint arXiv:220308383
* Wang 등(2023a) Wang C, Lu Y, Mu Y, 등(2023a) 지식 선택을 통해 사전 훈련된 언어 모델에 대한 개선된 지식 증류. 2302.00444
* Wang et al. (2023b) Wang D, Zhang J, Du B, et al. (2023b) Scaling-up remote sensing segmentation dataset with segment anything model. arXiv preprint arXiv:230502034
* Wang 등(2023c) Wang G, Xie Y, Jiang Y, 등(2023c) Voyager: 대형 언어 모델을 갖는 개방형 구체화된 에이전트. 2305.16291
* Wang 등(2023d) Wang H, Hu M, Deng Y, 등(2023d) Large language models as source planner for personalized knowledge-grounded dialogue. 2310.08840
* Wang et al. (2023e) Wang H, Wang R, Mi F, et al. (2023e) Chain-of-thought prompting for response in the depth dialogue questions with llm. arXiv preprint arXiv:230511792
* Wang et al. (2023f) Wang H, Yuan Y, Liu Z, et al. (2023f) Dt-solver: 증명-레벨 값 함수에 의해 안내된 동적-트리 샘플링으로 증명된 자동화 정리. In: Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics(Volume 1: Long Papers), pp 12632-12646
* Wang et al. (2023g) Wang J, Liu Z, Zhao L, et al. (2023g) Review of large vision models and visual prompt engineering. arXiv preprint arXiv:230700855
* Wang 등(2023h) Wang L, Huang B, Zhao Z, 등(2023h) Videomae v2: Scaling video masked autoencoder with dual masking. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 14549-14560
* Wang et al. (2023i) Wang L, Ma C, Feng X, et al. (2023i) A survey on large language model based autonomous agents. 2308.11432
* Wang et al. (2023j) Wang L, Xu W, Lan Y, et al. (2023j) Plan-and-solve prompting: Improved zero-shot chain-of-thought reasoning by large language models. arXiv preprint arXiv:230504091* Wang 등(2023) Wang L, Yang N, Wei F(2023k) Learning to retrieve in-context examples for large language models. arXiv preprint arXiv:230707164
* Wang 등(2023l) Wang P, Li L, Chen L, 등(2023l) 정렬을 갖는 더 나은 추론기들을 대형 언어 모델들로 만드는 것. arXiv preprint arXiv:230902144
* Wang 등(2023m) Wang P, Li L, Shao Z, 등(2023m) Math-shepherd: A label-free step-by-step verifier for llms in mathematical reasoning. arXiv preprint arXiv:231208935
* Wang et al. (2022b) Wang R, Jansen P, Cote MA, et al. (2022b) Scienceworld: Is your agent smarter than a 5 grader? arXiv preprint arXiv:220307540
* Wang 등(2023n) Wang R, Zelikman E, Poesia G, 등(2023n) 가설 탐색: 언어 모델을 이용한 귀납적 추론. 2309.05660
* Wang et al. (2023o) Wang T, Zhang J, Fei J, et al. (2023o) Caption anything: Interactive image description with various multimodal control. arXiv preprint arXiv:230502677
* Wang 등(2021a) Wang X, Xu X, Tong W, 등(2021a) Inferbert: a transformer-based causal inference framework for enhancing pharmacovigilance. 인공지능의 프론티어 4:659622
* Wang et al. (2023p) Wang X, Caccia L, Ostapenko O, et al. (2023p) Guiding language model reasoning with planning tokens. arXiv preprint arXiv:231005707
* Wang et al. (2023q) Wang X, Gu R, Chen Z, et al. (2023q) Uni-rna: universal pre-trained models is revolutionize rna research. bioRxiv pp 2023-07
* Wang et al. (2023r) Wang X, Hu Z, Lu P, et al. (2023r) Scibench: 대형 언어 모델의 대학 수준의 과학적 문제 해결 능력을 평가한다. arXiv preprint arXiv:230500970
* Wang 등(2023s) Wang X, Wei J, Schuurmans D, 등(2023s) Self-consistency는 언어 모델에서의 사고 추론의 연쇄를 향상시킨다. In: 학습 표현에 대 한 11 번째 국제 회의 URL [https://openreview.net/forum?id=1PL1NIMMrw](https://openreview.net/forum?id=1PL1NIMMrw)입니다.
* Wang et al. (2017) Wang Y, Liu X, Shi S (2017) Deep neural solver for math word problems. In: 2017년 자연어 처리에서의 경험적 방법에 관한 회의의 진행. Association for Computational Linguistics, Copenhagen, Denmark, pp 845-854, [https://doi.org/10.18653/v1/D17-1088](https://doi.org/10.18653/v1/D17-1088), URL [https://aclanthology.org/D17-1088](https://aclanthology.org/D17-1088)
* Wang et al.(2021b) Wang Y, Wang W, Joty S, et al.(2021b) Codet5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation. arXiv preprint arXiv:210900859
* Wang et al. (2022c) Wang Y, Kordi Y, Mishra S, et al. (2022c) Self-instruct: 자기 생성 명령어와 언어 모델을 정렬* Wang et al. (2022) Wang Y, Kordi Y, Mishra S, et al. (2022d) Self-instruct: 자기 생성 명령어와 언어 모델을 정렬. arXiv preprint arXiv:221210560
* Wang 등(2022e) Wang Y, Mishra S, Alipoormolabashi P, 등(2022e) Supernaturalinstructions: 1600+ 태스크에 대한 선언적 지시를 통한 일반화. In : EMNLP
* Wang 등(2022f) Wang Y, Mukherjee S, Liu X, 등(2022f) Adamix: Mixture-of-adapter for parameter-efficient tuning of large language models. arXiv preprint arXiv:220512410 1(2):4
* Wang et al. (2023t) Wang Y, Le H, Gotmare AD, et al. (2023t) Codel5+: Open code large language models for code understanding and generation. arXiv preprint arXiv:230507922
* Wang 등(2023u) Wang Y, Zhong W, Li L, 등(2023u) Aligning large language models with human: A survey. arXiv preprint arXiv:230712966
* Wang 등(2023v) Wang YR, Duan J, Fox D, 등(2023v) Newton: 대형 언어 모델이 물리적 추론이 가능한가? 2310.07018
* Wang 등(2020) Wang Z, Wohlwend J, Lei T(2020) Structured pruning of large language models. In: Proceedings of 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) 계산 언어 연결, [https://doi.org/10.18653/v1/2020.emnlp-main.496](https://doi.org/10.18653/v1/2020.emnlp-main.496), URL [https://doi.org/10.18653%2Fv1%2F2020.emnlp-main.496](https://doi.org/10.18653%2Fv1%2F2020.emnlp-main.496)
* Wang et al. (2023w) Wang Z, Cai S, Liu A, et al. (2023w) Describe, explain, plan and select: 대화형 계획 with large language models enables open-world multi-task agents. 2302. 01560
* Wang 등(2023x) Wang Z, Zhang G, Yang K, 등(2023x) Interactive 자연어 처리. arXiv preprint arXiv:230513246
* Watson et al.(2023) Watson JL, Juergens D, Bennett NR, et al.(2023) De novo design of protein structure and function with rfdiffusion. Nature 620(7976):1089-1100
* Wei 등(2021) Wei J, Bosma M, Zhao VY, 등(2021) Finetuned language models are zero-shot learners. arXiv preprint arXiv:210901652
* Wei et al.(2022a) Wei J, Tay Y, Bommasani R, et al.(2022a) Emergent abilities of large language models. 2206.07682
* Wei et al. (2022b) Wei J, Wang X, Schuurmans D, et al. (2022b) Chain-of-thought prompting promptedits reasoning in large language models. 신경정보처리시스템의 발전
* Weidinger 등(2021) Weidinger L, Mellor J, Rauh M, 등(2021) 언어 모델로부터의 위해의 윤리적 및 사회적 위험성. 2112.04359* Welleck et al. (2022) Welleck S, Lu X, West P, et al. (2022) self-correct를 학습하여 시퀀스들을 생성하는 단계를 포함한다. arXiv preprint arXiv:221100053
* Weston and Sukhbaatar (2023) Weston J, Sukhbaatar S (2023) System 2 attention (도 필요할 수 있음). 2311.11829
* Willig 등(2023) Willig M, Zecevic M, Dhami DS, 등(2023) Probing for correlations of causal facts: Large language models and causality. URL [https://openreview.net/forum?id=UPwzqPOs4-](https://openreview.net/forum?id=UPwzqPOs4-)
* Woodcock et al. (2009) Woodcock J, Larsen PG, Bicarregui J, et al. (2009) Formal methods: Practice and experience. ACM 컴퓨팅 조사(CSUR) 41(4):1-36
* Wu 등(2021a) Wu B, Zhang Z, Zhao H(2021a) Graph-free multi-hop reading comprehension: A select-to-guide strategy. ArXiv preprint abs/2107.11823. URL [https://arxiv.org/abs/2107.11823](https://arxiv.org/abs/2107.11823)
* Wu 등(2023a) Wu C, Yin S, Qi W, 등(2023a) Visual chatgpt: Talking, drawing and editing with visual foundation models. 2303.04671
* Wu 등(2023b) Wu D, Han W, Wang T, 등(2023b) Language prompt for autonomous driving. arXiv preprint arXiv:230904379
* Wu et al. (2023c) Wu H, Zhang Z, Zhang E, et al. (2023c) Q-bench: Low-level vision 상의 범용 기초 모델에 대한 벤치마크. arXiv preprint arXiv:230914181
* Wu 등(2021b) Wu M, Norrish M, Walder C, 등(2021b) Tacticzero: Learning to prove theorem from scratch with deep reinforcement learning. 신경정보처리시스템 34:9330-9342의 발전
* Wu 등(2023d) Wu M, Waheed A, Zhang C, 등(2023d) Lamini-lm: 대규모 지침으로부터의 다양한 증류 모델 무리. CoRR abs/2304.14402. URL [https://arxiv.org/abs/2304.14402](https://arxiv.org/abs/2304.14402), 2304.14402
* Wu 등(2023e) Wu W, Timofeev A, Chen C, 등(2023e) Mofi: 잡음 엔티티 주석된 이미지들로부터 이미지 표현들을 학습한다. arXiv preprint arXiv:230607952
* Wu 등(2022a) Wu Y, Jiang AQ, Li W, 등(2022a) Autoformalization with large language models. In: Oh AH, Agarwal A, Belgrave D, et al. (eds) Advances in Neural Information Processing Systems, URL [https://openreview.net/forum?id=IUIkebJ1Bf0](https://openreview.net/forum?id=IUIkebJ1Bf0)
* Wu et al. (2022b) Wu Z, Dvornik N, Greff K, et al. (2022b) Slotformer: Unsupervised visual dynamics simulation with object-centric models. arXiv preprint arXiv:221005861
* Wu 등(2023f) Wu Z, Qiu L, Ross A, 등(2023f) Reasoning or reciting? 반사실적 과제를 통해 언어 모델의 역량과 한계를 탐구한다. 2307.02477Wu Z, Wang Z, Xu X, et al.(2023g) Embodied task planning with large language models. arXiv preprint arXiv:230701848
* Xi 등(2023) Xi Z, Chen W, Guo X, 등(2023) The rise and potential of large language model based agents: survey. 2309.07864
* Xia 등(2018) Xia F, R. Zamir A, He ZY, et al. (2018) Gibson Env: real-world perception for embodied agents. In: Computer Vision and Pattern Recognition (CVPR), 2018 IEEE Conference on, IEEE
* Xiao et al.(2023a) Xiao B, Wu H, Xu W, et al.(2023a) Florence-2: Advancing a Unified representation for a various vision tasks. arXiv preprint arXiv:231106242
* Xiao 등(2023b) Xiao G, Tian Y, Chen B, 등(2023b) Attention 싱크를 갖는 효율적인 스트리밍 언어 모델. arXiv preprint arXiv:230917453
* Xie 등(2023a) Xie D, Wang R, Ma J, 등(2023a) Edit everything: A text-guided generation system for images editing. 2304.14006
* Xie et al.(2023b) Xie E, Yao L, Shi H, et al.(2023b) Difffit: Unlocking transferability of large diffusion models via simple parameter-efficient fine-tuning. arXiv preprint arXiv:230406648
* Xie et al. (2023c) Xie Y, Kawaguchi K, Zhao Y, et al. (2023c) Decomposition enhance reasoning via self-evaluation guided decoding. 2305.00633
* Xie and Sun (2019) Xie Z, Sun S (2019) A goal-driven tree-structured neural model for math word problems. In: IJcai, pp 5299-5305
* Xin 등(2023) Xin H, Wang H, Zheng C, 등(2023) Lego-prover: Neural theorem prove with growing libraries. arXiv preprint arXiv:231000656
* 15, 2022. ACM, pp 2166-2171, [https://doi.org/10.1145/3477495.3531824](https://doi.org/10.1145/3477495.3531824), URL [https://doi.org/10.1145/3477495.3531824](https://doi.org/10.1145/3477495.3531824)
* Xiong et al. (2023a) Xiong J, Li Z, Zheng C, et al. (2023a) Dq-lore: In-context 학습을 위해 낮은 랭크 근사치 재-랭킹을 갖는 이중 질의들. arXiv preprint arXiv:231002954 URL [https://api.semanticscholar.org/CorpusID:263620351](https://api.semanticscholar.org/CorpusID:263620351)
* Xiong 등(2023b) Xiong J, Shen J, Yuan Y, 등(2023b) Trigo: Benchmarking formal mathematical proof reduction for generative language models. arXiv preprint arXiv:231010180
* Xu et al. (2023a) Xu C, Sun Q, Zheng K, et al. (2023a) Wizardlm: Empowering large language models to follow complex instructions. 2304.12244Xu FF, Alon U, Neubig G, et al.(2022) A systematic evaluation of large language models of code. In: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, pp 1-10
* Xu 등(2020) Xu L, Hu H, Zhang X, 등(2020) CLUE: A Chinese language understanding evaluation benchmark. In: 제28회 전산언어학 국제회의 회보. International Committee on Computational Linguistics, Barcelona, Spain (Online), pp 4762-4772, [https://doi.org/10.18653/v1/2020](https://doi.org/10.18653/v1/2020). cooling-main.419, URL [https://aclanthology.org/2020.coling-main.419](https://aclanthology.org/2020.coling-main.419)
* Xu et al.(2023b) Xu P, Shao W, Zhang K, et al.(2023b) Lvlm-ehub: A comprehensive evaluation benchmark for large vision-language models. arXiv preprint arXiv:230609265
* Xu et al.(2021a) Xu R, Luo F, Zhang Z, et al.(2021a) Raise a child in large language model: Towards effective and generalizable fine-tuning. arXiv preprint arXiv:210905687
* Xu 등(2023c) Xu R, Wang X, Wang T, 등(2023c) Pointllm: 포인트 클라우드를 이해할 수 있도록 대용량 언어 모델에 힘을 실어준다. arXiv preprint arXiv:230816911
* Xu et al.(2023d) Xu S, Yang L, Kelly C, et al.(2023d) Elixr: 대형 언어 모델 및 방사선 비전 인코더의 정렬을 통한 범용 x-ray 인공지능 시스템을 향하여. arXiv preprint arXiv:230801317
* Xu 등(2021b) Xu Y, Liu X, Cao X, 등(2021b) 인공지능: 과학 연구를 위한 강력한 패러다임. 혁신 2(4):100179. [https://doi.org/https://doi.org/10.1016/j.xinn.2021.100179](https://doi.org/https://doi.org/10.1016/j.xinn.2021.100179), URL [https://www.sciencedirect.com/science/article/pii/S2666675821001041](https://www.sciencedirect.com/science/article/pii/S2666675821001041)
* Xu 등(2023e) Xu Z, Zhang Y, Xie E, 등(2023e) DriveGPT4: 해석 가능한 End-to-end Autonomous Driving via Large Language Model. arXiv preprint arXiv:231001412
* Xue et al.(2022) Xue F, Shi Z, Wei F, et al.(2022) 더 깊게 가는 대신 더 넓게 간다. In: Proceedings of the AAAI Conference on Artificial Intelligence, pp 8779-8787
* Yan et al. (2021) Yan H, Dai J, Ji T, et al. (2021) A unified generative framework for aspect-based sentiment analysis. In: Zong C, Xia F, Li W, et al. (eds) Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). Association for Computational Linguistics, Online, pp 2416-2429, [https://doi.org/10.18653/v1/2021.acl-long.188](https://doi.org/10.18653/v1/2021.acl-long.188), URL [https://aclanthology.org/2021.acl-long.188](https://aclanthology.org/2021.acl-long.188)
* Yan et al. (2023) Yan Z, Zhang K, Zhou R, et al. (2023) Multimodal chatgpt for medical applications: a experimental study of gpt-4v. arXiv preprint arXiv:231019061
* Yang et al. (2022a) Yang H, Li P, Lam W (2022a) Parameter-efficient tuning by manipulating hidden states of pretrained language models for classification tasks. arXiv preprint arXiv:220404596 Yang H, Wang Y, Li P, et al.(2023a) Bridging the gap between pre-training and fine-tuning for commonsense generation. In: Association for Computational Linguistics의 Findings: EACL 2023, pp 376-383
* Yang et al. (2023b) Yang J, Prabhakar A, Narasimhan K, et al. (2023b) Intercode: Standardizing and benchmarking interactive coding with execution feedback. 2306.14898
* Yang and Deng(2019) Yang K, Deng J(2019) Learning to prove theorems via interaction with proof assistants. In: International Conference on Machine Learning, PMLR, pp 6984-6994
* Yang and Deng(2021) Yang K, Deng J(2021) Learning symbol rules for reasoning in quasi-natural language. arXiv preprint arXiv:211112038
* Yang et al. (2022) Yang K, Deng J, Chen D (2022b) Generating natural language proofs with verifier-guided search. In: 2022년 자연어처리 실증방법에 관한 회의의 진행. Association for Computational Linguistics, Abu Dhabi, United Arab Emirates, pp 89-105, [https://doi.org/10.18653/v1/2022.emnlp-main.7](https://doi.org/10.18653/v1/2022.emnlp-main.7)
* Yang et al. (2022) Yang K, Swope AM, Gu A, et al. (2023c) Leandjo: Theorem prove with retrieval-augmented language models. arXiv preprint arXiv:230615626
* Yang et al. (2023d) Yang R, Song L, Li Y, et al. (2023d) Gpt4tools: teaching large language model to use tools via self-instruction. arXiv preprint arXiv:230518752
* Yang et al. (2023e) Yang S, Nachum O, Du Y, et al. (2023e) Foundation models for decisions making: Problems, methods, and opportunities. arXiv preprint arXiv:230304129
* Yang et al.(2021) Yang Sw, Chi PH, Chuang YS, et al.(2021) SUPERB: Speech Processing Universal PERformance Benchmark. In: INTERSPEECH, pp 1194-1198
* Yang and Yang (2022) Yang Z, Yang Y (2022) Decoupling features in hierarchical propagation for video object segmentation. 신경정보처리시스템 35:36324-36336 발전
* Yang et al. (2018) Yang Z, Qi P, Zhang S, et al. (2018) HotpotQA: A dataset for diverse, explainable multi-hop question answer. In: 2018 자연어처리 실증방법에 관한 회의의 진행. Association for Computational Linguistics, Brussels, Belgium, pp 2369-2380, [https://doi.org/10.18653/v1/D18-1259](https://doi.org/10.18653/v1/D18-1259), URL [https://aclanthology.org/D18-1259](https://aclanthology.org/D18-1259)
* Yang et al. (2022c) Yang Z, Dong L, Du X, et al. (2022c) Language models as inductive reasoners. arXiv preprint arXiv:221210923
* Yang et al. (2023f) Yang Z, Du X, Mao R, et al. (2023f) Logical reasoning over natural language as knowledge representation: survey. arXiv preprint arXiv:230312023
* Yang et al.(2023g) Yang Z, Li L, Lin K, et al.(2023g) The dawn of lmms: Preliminary Explorations with gpt-4v(ision). arXiv preprint arXiv:230917421Yao L, Huang R, Hou L, et al.(2021) Filip: Fine-grained interactive language-image pre-training. arXiv preprint arXiv:211107783
* Yao et al. (2022) Yao L, Han J, Wen Y, et al. (2022) Detclip: Dictionary-enriched visual-concept parallel pre-training for open-world detection. 신경정보처리시스템 35:9125-9138 발전
* Yao et al.(2023a) Yao L, Han J, Liang X, et al.(2023a) Detclipv2: Scalable open-vocabulary object detection pre-training via word-region alignment. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 23497-23506
* Yao 등(2023b) Yao S, Yu D, Zhao J, 등(2023b) Tree of thoughts: Deliberate problem solving with large language models. 2305.10601
* Yao 등(2023c) Yao S, Zhao J, Yu D, 등(2023c) ReAct: Synergizing reasoning and acting in language models. In: International Conference on Learning Representations (ICLR)
* Yao 등(2023d) Yao Y, Li Z, Zhao H(2023d) Beyond chain-of-thought, Effective graph-of-thought reasoning in large language models. 2305.16582
* Yasunaga and Liang (2020) Yasunaga M, Liang P (2020) Graph-based, self-supervised program repair from diagnostic feedback. In: International Conference on Machine Learning, PMLR, pp 10799-10808
* Ye 등(2023a) Ye J, Wu Z, Feng J, 등(2023a) Compositional exemplars for in-context learning. arXiv preprint arXiv:230205698
* Ye 등(2021) Ye Q, Lin BY, Ren X(2021) Crossfit: A few-shot learning challenge for cross-task generalization in nlp. arXiv preprint arXiv:210408835
* Ye et al.(2023b) Ye S, Xie Y, Chen D, et al.(2023b) Improving commonense in vision-language models via knowledge graph riddles. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 2634-2645
* Ye et al. (2022) Ye X, Iyer S, Celikyilmaz A, et al. (2022) Complementary explanation for effective in-context learning. arXiv preprint arXiv:221113892
* Yi 등(2019) Yi K, Gan C, Li Y, 등(2019) Clevrer: Collision events for video representation and reasoning. arXiv preprint arXiv:191001442
* Yih et al. (2016) Yih Wt, Richardson M, Meek C, et al. (2016) The value of semantic parse labeling for knowledge base question answer. In: 제54회 전산언어학회 연차총회 회보(제2권 : 짧은 논문). Association for Computational Linguistics, Berlin, Germany, pp 201-206, [https://doi.org/10.18653/v1/P16-2033](https://doi.org/10.18653/v1/P16-2033), URL [https://aclanthology.org/P16-2033](https://aclanthology.org/P16-2033)
* Yin 등(2023a) Yin D, Liu X, Yin F, 등(2023a) Dynosaur: A dynamic growth paradigm for instruction-tuning data curation. arXiv preprint arXiv:230514327
* Yin et al. (2023b) Yin, S., Fu, C., Zhao, S., et al. (2023b) A survey on multimodal large language models. 2306.13549
* Yin et al. (2023c) Yin Z, Sun Q, Chang C, et al. (2023c) Exchange-of-thought: Cross-model communication을 통한 대형 언어 모델 능력 향상. In: 2023 Conference on Empirical Methods in Natural Language Processing, URL [https://openreview.net/forum?id=30kbnyD9hF](https://openreview.net/forum?id=30kbnyD9hF)
* Yin et al.(2023d) Yin Z, Sun Q, Guo Q, et al.(2023d) Do large language models know what they know they don't know. In: Rogers A, Boyd-Graber J, Okazaki N(eds) Findings of the Association for Computational Linguistics: ACL 2023. Association for Computational Linguistics, Toronto, Canada, pp 8653-8665, [https://doi.org/10.18653/v1/2023.findings-acl.551](https://doi.org/10.18653/v1/2023.findings-acl.551), URL [https://aclanthology.org/2023.findings-acl.551](https://aclanthology.org/2023.findings-acl.551)
* Yin 등(2023e) Yin Z, Wang J, Cao J, 등(2023e) Lamm: Language-assisted multimodal instruction-tuning dataset, framework, and benchmark. arXiv preprint arXiv:230606687
* Yin et al.(2023f) Yin Z, Wang Y, Hu X, et al.(2023f) Rethinking label smoothing on multi-hop question answering. In: Sun M, Qin B, Qiu X, et al. (eds) Chinese Computational Linguistics. Springer Nature Singapore, Singapore, pp 72-87
* Yoneda et al. (2023) Yoneda T, Fang J, Li P, et al. (2023) Statler: State-maintaining language models for embodied reasoning. 2306.17840
* Young 등(2022) Young N, Bao Q, Bensemann J, 등(2022) AbductionRules: Training transformer to explain unexpected input. In: Association for Computational Linguistics: ACL 2022. Association for Computational Linguistics, Dublin, Ireland, pp 218-227, [https://doi.org/10.18653/v1/2022.findings-acl.19](https://doi.org/10.18653/v1/2022.findings-acl.19), URL [https://aclanthology.org/2022.findings-acl.19](https://aclanthology.org/2022.findings-acl.19)
* Yu et al. (2023a) Yu F, Zhang H, Tiwari P, et al. (2023a) Natural language reasoning, survey. arXiv preprint arXiv:230314725
* Yu 등(2023b) Yu L, Jiang W, Shi H, 등(2023b) Metamath: Bootstrap your own mathematical questions for large language models. arXiv preprint arXiv:230912284
* Yu 등(2021) Yu S, Mo S, Ahn S, 등(2021) 논리 유도 생성을 통한 추상 추론. 2107.10493
* Yu et al. (2022) Yu S, Wu P, Liang PP, et al. (2022) Pacs: A dataset for physical audiovisual commonsense reasoning. 2203.11130
* Yu et al. (2018) Yu T, Zhang R, Yang K, et al. (2018) Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-SQL task. In: 2018 자연어처리 실증방법에 관한 회의의 진행. Association for Computational Linguistics, Brussels, Belgium, pp 3911-3921, [https://doi.org/10.1007/s10052-004-001-0](https://doi.org/10.1007/s10052-004-001-0)
* Yu et al. (2020)//doi.org/10.18653/v1/D18-1425, URL [https://aclanthology.org/D18-1425](https://aclanthology.org/D18-1425)
* Yu 등(2023c) Yu T, Feng R, Feng R, 등(2023c) Inpaint anything: Segment anything meets image inpainting. arXiv preprint arXiv:230406790
* Yuan 등(2021) Yuan L, Chen D, Chen YL, 등(2021) Florence: A new foundation model for computer vision. arXiv preprint arXiv:211111432
* Yuan et al. (2023a) Yuan Z, Yuan H, Li C, et al. (2023a) Scaling relationship on learning mathematical reasoning with large language models. arXiv preprint arXiv:230801825
* Yuan et al.(2023b) Yuan Z, Yuan H, Tan C, et al.(2023b) Rrhf: Rank responses to align language models with human feedback without tears. arXiv preprint arXiv:230405302
* Yue et al.(2023) Yue X, Qu X, Zhang G, et al.(2023) Mammoth: Hybrid instruction tuning을 통한 수학 일반주의 모델 구축. arXiv preprint arXiv:230905653
* Zaken 등(2021) Zaken EB, Ravfogel S, Goldberg Y(2021) Bitfit: Simple parameter-efficient fine-tuning for transformer-based masked language-models. arXiv preprint arXiv:210610199
* Zan 등(2022) Zan D, Chen B, Yang D, 등(2022) Cert: 라이브러리 지향 코드 생성을 위한 스케치에 대한 연속 사전-훈련. arXiv preprint arXiv:220606888
* Zan 등(2023) Zan D, Chen B, Zhang F, 등(2023) Large language models meet nl2code:A survey. In: Proceedings of 61st Annual Meeting of the Association for Computational Linguistics(Volume 1: Long Papers), pp 7443-7464
* Zecevic et al.(2023) Zecevic M, Willig M, Dhami DS, et al.(2023) Causal parrots: Large language models may talk causality but not causal. arXiv preprint arXiv:230813067
* Zelikman 등(2022) Zelikman E, Wu Y, Mu J, 등(2022) STar: Bootstrapping reasoning with reasoning. In: Oh AH, Agarwal A, Belgrave D, et al. (eds) Advances in Neural Information Processing Systems, URL [https://openreview.net/forum?id=_3ELRdg2sgI](https://openreview.net/forum?id=_3ELRdg2sgI)
* Zellers et al. (2018) Zellers R, Bisk Y, Schwartz R, et al. (2018) Swag: 근거 있는 상식 추론을 위한 대규모 적대적 데이터세트. arXiv preprint arXiv:180805326
* Zellers 등(2019) Zellers R, Holtzman A, Bisk Y, 등(2019) Hellaswag: Can a machine really finish your sentence? arXiv preprint arXiv:190507830
* Zeng 등(2022) Zeng A, Liu X, Du Z, 등(2022) Glm-130b: 개방형 이중언어 사전 훈련 모델. arXiv preprint arXiv:221002414
* Zeng et al.(2023) Zeng A, Attarian M, Bryan ichter, et al.(2023) Socratic models: Composing zero-shot multimodal reasoning with language. In: The Eleventh International Conference on Learning Representations, URL [https://openreview.net/forum?id=G2Q2Mh3avow](https://openreview.net/forum?id=G2Q2Mh3avow)* Zeng et al. (2021) Zeng W, Ren X, Su T, et al. (2021) Pangu-\(\backslash alpha\): 자동 병렬 계산을 사용하여 대규모 자동 회귀 사전 훈련 중국어 모델. arXiv preprint arXiv:210412369
* Zhai 등(2022) Zhai X, Wang X, Mustafa B, 등(2022) Lit: Locked-image text tuning으로 Zero-shot transfer. In: CVPR, pp 18102-18112
* Zhang et al. (2023a) Zhang C, Bauer S, Bennett P, et al. (2023a) Understanding causality with large language models: Feasibility and opportunities. arXiv preprint arXiv:230405524
* Zhang et al.(2023b) Zhang G, Shi Y, Liu R, et al.(2023b) Chinese open instruction generalist: A preliminary release. arXiv preprint arXiv:230407987
* Zhang et al. (2023c) Zhang H, Du W, Shan J, et al. (2023c) 대형 언어 모델들과 모듈식으로 협동 체화된 에이전트들을 구축한다. 2307.02485
* Zhang et al.(2023d) Zhang J, Zhou Z, Mai G, et al.(2023d) Text2seg: Remote sensing image semantic segmentation via text-guided visual foundation models. arXiv preprint arXiv:230410597
* Zhang et al.(2023e) Zhang K, Li Z, Li J, et al.(2023e) Self-edit: 코드 생성을 위한 Fault-aware code editor. In: 제61회 전산언어학회 연차총회 회보(제1권: 장문의 논문). Association for Computational Linguistics, Toronto, Canada, pp 769-787, URL [https://aclanthology.org/2023.acl-long.45](https://aclanthology.org/2023.acl-long.45)
* Zhang et al.(2023f) Zhang K, Yu J, Yan Z, et al.(2023f) Biomedgpt: A Unified and generalist biomedical generative pre-trained transformer for vision, language, and multimodal tasks. 2305. 17100
* Zhang 등(2021) Zhang P, Li X, Hu X, 등(2021) Vinvl: 시각적 표현을 시각 언어 모델에서 중요하게 만든다. arXiv preprint arXiv:210100529
* Zhang 등(2023g) Zhang Q, Chen M, Bukharin A, 등(2023g) Adaptive budget allocation for parameter-efficient fine-tuning. arXiv preprint arXiv:230310512
* Zhang et al. (2023h) Zhang R, Han J, Zhou A, et al. (2023h) Llama-adapter: zero-init attention을 갖는 언어 모델의 효율적인 미세 조정. arXiv preprint arXiv:230316199
* Zhang et al.(2022a) Zhang S, Roller S, Goyal N, et al.(2022a) Opt: Open pre-trained transformer language models. arXiv preprint arXiv:220501068
* Zhang et al.(2023i) Zhang T, Ladhak F, Durmus E, et al.(2023i) Benchmarking large language models for news summarization. 2301.13848
* Zhang et al. (2023j) Zhang X, Wang L, Helwig J, et al. (2023j) Artificial intelligence for science in quantum, atomistic, and continuum systems. 2307.08423* Zhang et al.(2017) Zhang Y, Dai H, Kozareva Z, et al.(2017) Variational reasoning for question answer with knowledge graph. In: 인공지능에 대한 AAAI 회의
* Zhang 등(2022) Zhang Y, Feng S, Tan C(2022b) Active example selection for in-context learning. In: Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp 9134-9148
* Zhang et al.(2023) Zhang Y, Chen S, Jiang W, et al.(2023k) Domain-guided conditional diffusion model for unsupervised domain adaptation. arXiv preprint arXiv:230914360
* Zhang et al.(2023) Zhang Y, Qian S, Peng B, et al.(2023l) Prompt highlighter: Interactive control for multi-modal llms. arXiv 프리프린트 231204302
* Zhang et al.(2022c) Zhang Z, Zhang A, Li M, et al.(2022c) Automatic chain of thought prompting in large language models. arXiv preprint arXiv:221003493
* Zhao 등(2023a) Zhao H, Wang K, Yu M, 등(2023a) 명시적 계획은 논리적 추론에서 언어 모델을 돕는다. 2303.15714
* Zhao et al.(2023b) Zhao WX, Zhou K, Li J, et al.(2023b) A survey of large language models. arXiv preprint arXiv:230318223
* Zhao 등(2023c) Zhao X, Li W, Kong L(2023c) Decomposing the enigma: Subgoal-based demonstration learning for formal theorem 증명. arXiv preprint arXiv:230516366
* Zhao et al. (2023d) Zhao X, Xie Y, Kawaguchi K, et al. (2023d) 추론을 위한 큰 언어 모델을 갖는 자동 모델 선택. 2305.14333
* Zhao 등(2022a) Zhao Y, Khalman M, Joshi R, 등(2022a) Calibrating sequence likelihood improves conditional language generation. In: 학습 표상에 관한 제11회 국제학술대회
* Zhao et al.(2022b) Zhao Y, Li Y, Li C, et al.(2022b) MultiHiertt: Multi hierarchical tabular and textual data over Numerical reasoning. In: 제60회 전산언어학회 연차총회 회보(제1권: 장문) Association for Computational Linguistics, Dublin, Ireland, pp 6588-6600, [https://doi.org/10.18653/v1/2022.acl-long.454](https://doi.org/10.18653/v1/2022.acl-long.454), URL [https://aclanthology.org/2022.acl-long.454](https://aclanthology.org/2022.acl-long.454)
* Zhao et al.(2022) Zhao Y, Pang T, Du C, et al.(2022b) On evaluate adversarial robustness of large vision-language models. arXiv preprint arXiv:230516934
* Zhao et al.(2023f) Zhao Z, Lee WS, Hsu D(2023f) Large language models as common sense knowledge for large-scale task planning. arXiv preprint arXiv:230514078
* Zheng et al. (2023a) Zheng C, Liu Z, Xie E, et al. (2023a) Progressive-hint prompting improve reasoning in large language models. arXiv preprint arXiv:230409797* Zheng et al.(2023) Zheng C, Wang H, Xie E, et al.(2023b) Lyra: Orchestrating dual correction in automated theorem prove. arXiv preprint arXiv:230915806
* Zheng 등(2021) Zheng K, Han JM, Polu S(2021) Minif2f: a cross-system benchmark for formal olympiad-level mathematics. arXiv preprint arXiv:210900110
* Zheng et al. (2023c) Zheng Q, Xia X, Zou X, et al. (2023c) Codegeex: A pre-trained model for code generation with multilingual evaluations on humanval-x. arXiv preprint arXiv:230317568
* Zhong et al.(2020) Zhong M, Liu P, Chen Y, et al.(2020) Extractive summarization as text matching. In: Jurafsky D, Chai J, Schluter N, et al. (eds) Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, Online, pp 6197-6208, [https://doi.org/10.18653/v1/2020.acl-main.552](https://doi.org/10.18653/v1/2020.acl-main.552), URL [https://aclanthology.org/2020.acl-main.552](https://aclanthology.org/2020.acl-main.552)
* Zhong et al. (2023) Zhong T, Zhao W, Zhang Y, et al. (2023) Chatrario-valuer: Multi-institution and multi-system data에 기반한 일반화 가능한 영상의학 보고서 생성을 위한 채팅 대용량 언어 모델. arXiv preprint arXiv:231005242
* Zhong et al. (2018) Zhong V, Xiong C, Socher R (2018) Seq2SQL: 강화 학습을 이용하여 자연어로부터 구조화된 쿼리를 생성하는 단계. URL [https://openreview.net/forum?id=Syx6bz-Ab](https://openreview.net/forum?id=Syx6bz-Ab)
* Zhong et al.(2021) Zhong Z, Friedman D, Chen D(2021) Factual probing is [MASK]: Learning vs. 기억하는 법을 배우다. In: Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics, Online, pp 5017-5033, [https://doi.org/10.18653/v1/2021.naacl-main.398](https://doi.org/10.18653/v1/2021.naacl-main.398), URL [https://aclanthology.org/2021.naacl-main.398](https://aclanthology.org/2021.naacl-main.398)
* Zhou et al. (2022a) Zhou D, Scharli N, Hou L, et al. (2022a) Least-to-most prompting은 대형 언어 모델에서의 복잡한 추론을 가능하게 한다. arXiv preprint arXiv:220510625
* Zhou et al.(2023a) Zhou H, Ding M, Peng W, et al.(2023a) Generalizable long-horizon manipulations with large language models. arXiv preprint arXiv:231002264
* Zhou et al. (2020) Zhou J, Hu S, Lv X, et al. (2020) Kacc: A multi-task benchmark for knowledge abstraction, concretization and completion. arXiv preprint arXiv:200413631
* Zhou et al.(2023b) Zhou J, Zhang Y, Luo Q, et al.(2023b) Synthetic lies: ai-generated misinformation 이해 및 알고리즘 및 인간 솔루션 평가. In: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, pp 1-20
* Zhou et al.(2022b) Zhou K, Yang J, Loy CC, et al.(2022b) Learning to prompt for vision-language models. International Journal of Computer Vision 130(9):2337-2348Zhou L, Dai S, Chen L(2015) Learn to solve algebra word problems using quadratic programming. 자연어처리(自然調處理)에 관한 실험적(實驗的) 연구(硏究)
* Zhou 등(2023c) Zhou X, Liu M, Zagar BL, 등(2023c) Vision language models in autonomous driving and intelligent transportation systems. arXiv preprint arXiv:231014414
* Zhou et al.(2023d) Zhou Y, Chia MA, Wagner SK, et al.(2023d) An foundation model for generalizable disease detection from retinal images. Nature pp 1-8
* Zhu 등(2023a) Zhu B, Sharma H, Frujeri FV, 등(2023a) Fine-tuning language models with advantage-induced policy alignment. arXiv preprint arXiv:230602231
* Zhu 등(2023b) Zhu D, Chen J, Shen X, 등(2023b) Minigpt-4: Enhancing vision-language understanding with advanced large language models. 2304.10592
* Zhu 등(2021) Zhu F, Lei W, Huang Y, 등(2021) Tat-qa: 금융에서 표형 콘텐츠와 텍스트형 콘텐츠의 하이브리드 상의 질의 응답 벤치마크. arXiv preprint arXiv:210507624
* Zhu 등(2023c) Zhu X, Li J, Liu Y, 등(2023c) 대형 언어 모델에 대한 모델 압축에 관한 조사. 2308.07633
* Zhu 등(2023d) Zhu Y, Yuan H, Wang S, 등(2023d) Large language models for information retrieval: survey. 2308.07107
* Ziyu et al.(2023) Ziyu Z, Xiaojian M, Yixin C, et al.(2023) 3d-vista: Pre-trained transformer for 3d vision and text alignment. In: ICCV
* Zong et al.(2023) Zong Y, Aodha OM, Hospedales T(2023) Self-supervised multimodal learning: A survey. 2304.01008
* Zuo et al. (2022) Zuo S, Zhang Q, Liang C, et al. (2022) Moebert: bert에서 중요도-유도 적응을 통한 혼합물-of-experts로. arXiv preprint arXiv:220407675
