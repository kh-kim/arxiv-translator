<html lang="en" data-theme="light"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>Gemma: Open Models Based on Gemini Research and Technology</title>
<!--Generated on Wed Mar 13 06:59:14 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/addons.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="https://arxiv.org/html/2403.08295v1/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2403.08295v1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <span class="color-scheme-icon" aria-label="Light mode"></span>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="#myForm" onclick="event.preventDefault(); var modal = document.getElementById('myForm'); modal.style.display = 'block'; bugReportState.setInitiateWay('Header');">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2403.08295v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2403.08295v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
          <span class="color-scheme-icon"></span>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC mobile collapse" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S1" title="1 Introduction ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S2" title="2 Model Architecture ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Model Architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S3" title="3 Training Infrastructure ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Training Infrastructure</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S3.SS1" title="3.1 Carbon Footprint ‣ 3 Training Infrastructure ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Carbon Footprint</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S4" title="4 Pretraining ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Pretraining</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S4.SS1" title="4.1 Training Data ‣ 4 Pretraining ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Training Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S4.SS2" title="4.2 Filtering ‣ 4 Pretraining ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Filtering</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S5" title="5 Instruction Tuning ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Instruction Tuning</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S5.SS1" title="5.1 Supervised Fine-Tuning ‣ 5 Instruction Tuning ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Supervised Fine-Tuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S5.SS2" title="5.2 Filtering ‣ 5 Instruction Tuning ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Filtering</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S5.SS3" title="5.3 Formatting ‣ 5 Instruction Tuning ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Formatting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S5.SS4" title="5.4 Reinforcement Learning from Human Feedback ‣ 5 Instruction Tuning ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Reinforcement Learning from Human Feedback</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6" title="6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.SS1" title="6.1 Human Preference Evaluations ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Human Preference Evaluations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.SS2" title="6.2 Automated Benchmarks ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Automated Benchmarks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.SS3" title="6.3 Memorization Evaluations ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Memorization Evaluations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.SS3.SSS0.Px1" title="Verbatim Memorization ‣ 6.3 Memorization Evaluations ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title">Verbatim Memorization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.SS3.SSS0.Px2" title="Personal Data ‣ 6.3 Memorization Evaluations ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title">Personal Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.SS3.SSS0.Px3" title="Approximate Memorization ‣ 6.3 Memorization Evaluations ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title">Approximate Memorization</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S7" title="7 Responsible Deployment ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Responsible Deployment</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S7.SS1" title="7.1 Benefits ‣ 7 Responsible Deployment ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Benefits</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S7.SS2" title="7.2 Risks ‣ 7 Responsible Deployment ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Risks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S7.SS3" title="7.3 Mitigations ‣ 7 Responsible Deployment ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3 </span>Mitigations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S7.SS4" title="7.4 Assessment ‣ 7 Responsible Deployment ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.4 </span>Assessment</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S7.SS5" title="7.5 Going Forward ‣ 7 Responsible Deployment ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.5 </span>Going Forward</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S8" title="8 Discussion and Conclusion ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Discussion and Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S9" title="9 Contributions and Acknowledgments ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Contributions and Acknowledgments</span></a></li>
</ol></nav>

<div class="ltx_page_content"><div class="section" id="target-section"><div id="license-tr">License: CC BY 4.0</div><div id="watermark-tr">arXiv:2403.08295v1 [cs.CL] 13 Mar 2024</div></div>
<article class="ltx_document ltx_authors_1line"><span class="ltx_ERROR undefined" id="id1">\authfootnotetext</span>
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1">전체 작성자 목록은 기여 및 확인 섹션을 참조하십시오. <span class="ltx_text ltx_font_typewriter" id="p1.1.1">gemma-1-report@google.com</span>에 회신 부탁드립니다.</p>
</div>
<h1 class="ltx_title ltx_title_document">Gemma: Open Models Based on Gemini Research and Technology</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gemma Team
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Google DeepMind<span class="ltx_ERROR undefined" id="id1.1.id1">\authfootnotemark</span>1
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id2.id1">이 작품은 제미니 모델을 만드는 데 사용된 연구 및 기술로 구축된 경량, 최첨단 개방형 모델 가족인 젬마를 소개한다. 젬마 모델은 언어 이해, 추론 및 안전에 대한 학문적 벤치마크 전반에 걸쳐 강력한 성능을 보여준다. 우리는 두 가지 크기의 모델(20억 및 70억 매개변수)을 출시하고 사전 훈련 및 미세 조정된 체크포인트를 모두 제공한다. Gemma는 18개의 텍스트 기반 작업 중 11개에서 유사한 크기의 개방형 모델을 능가하며 모델 개발에 대한 자세한 설명과 함께 모델의 안전 및 책임 측면에 대한 포괄적인 평가를 제시한다. 우리는 LLM을 책임감 있게 출시하는 것이 프론티어 모델의 안전성을 향상시키고 LLM 혁신의 다음 물결을 가능하게 하는 데 중요하다고 믿습니다.</p>
</div>
<section class="ltx_section" id="S1" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">우리는 구글의 제미니 모델 <cite class="ltx_cite ltx_citemacro_citep">(Gemini Team, <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib18" title="">2023</a>)</cite>를 기반으로 한 개방형 모델 패밀리 Gemma를 제시한다.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">유사한 아키텍처, 데이터 및 훈련 레시피를 제미니 모델 패밀리로 사용하여 텍스트의 최대 6T 토큰에 대해 제마 모델을 훈련했다. 제미니와 마찬가지로 이러한 모델은 최첨단 이해 및 규모 추론 기술과 함께 텍스트 영역에서 강력한 일반주의적 능력을 달성한다. 이 작업을 통해 사전 훈련 및 미세 조정된 체크포인트와 추론 및 서비스를 위한 오픈 소스 코드베이스를 모두 공개합니다.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Gemma는 GPU 및 TPU에 효율적으로 배포 및 개발을 위한 70억 개의 매개 변수 모델과 CPU 및 온-디바이스 애플리케이션에 대한 20억 개의 매개 변수 모델의 두 가지 크기로 제공됩니다. 각 크기는 서로 다른 계산 제약, 애플리케이션 및 개발자 요구 사항을 해결하도록 설계되었습니다. 각 규모에서 원시, 사전 훈련된 검문소와 대화, 지시 따르기, 유용성 및 안전을 위해 미세 조정된 검문소를 공개합니다. 우리는 양적 및 질적 벤치마크 제품군에서 모델의 단점을 철저히 평가한다. 사전 훈련된 검문소와 미세 조정된 검문소의 공개는 현재 지시 조정 체제의 영향에 대한 철저한 연구와 조사와 점점 더 안전하고 책임 있는 모델 개발 방법론의 개발을 가능하게 할 것이라고 믿는다.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Gemma는 자동화된 벤치마크와 인간 평가를 모두 포함하는 광범위한 도메인에 걸쳐 비교 가능한 규모(및 일부 더 큰) 개방형 모델 <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib22" title="">2023</a>; Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib47" title="">2023b</a>, <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib46" title="">a</a>; Almazrouei et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib1" title="">2023</a>)</cite>에 비해 최첨단 성능을 향상시킨다. 예시적인 도메인들은 질문 응답 <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib13" title="">2019</a>; Kwiatkowski et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib27" title="">2019</a>)</cite>, 상식 추론 <cite class="ltx_cite ltx_citemacro_citep">(Sakaguchi et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib37" title="">2019</a>; Suzgun et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib44" title="">2022</a>)</cite>, 수학 및 과학 <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib15" title="">2021</a>; Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib19" title="">2020</a>)</cite>, 코딩 <cite class="ltx_cite ltx_citemacro_citep">(Austin et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib4" title="">2021</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib10" title="">2021</a>)</cite>를 포함한다. <a class="ltx_ref ltx_refmacro_nameref" href="https://arxiv.org/html/2403.08295v1#S6" title="6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title">Evaluation</span></a> 섹션의 전체 세부 정보를 참조하십시오.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="362" id="S1.F1.g1" src="https://arxiv.org/html/2403.08295v1/x1.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 1:</span>Gemma 7B에 걸친 언어 이해 및 생성 성능</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Language understanding and generation performance of Gemma 7B across
different capabilities compared to similarly sized open models. We group together standard academic benchmark evaluations by capability and average the respective scores; see Table&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.T6" title="Table 6 ‣ 6.2 Automated Benchmarks ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_tag">6</span></a> for a detailed breakdown of performance.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Gemma는 Gemini와 마찬가지로 시퀀스 모델 <cite class="ltx_cite ltx_citemacro_citep">(Sutskever et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib43" title="">2014</a>)</cite>와 트랜스포머 <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib48" title="">2017</a>)</cite>, 신경망 <cite class="ltx_cite ltx_citemacro_citep">(LeCun et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib28" title="">2015</a>)</cite>, 분산 시스템에서 대규모 학습을 위한 기법 <cite class="ltx_cite ltx_citemacro_citep">(Barham et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib6" title="">2022</a>; Roberts et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib36" title="">2023</a>; Dean et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib16" title="">2012</a>)</cite>에 대한 최근 연구를 기반으로 한다. Gemma는 또한 Word2Vec <cite class="ltx_cite ltx_citemacro_citep">(Mikolov et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib29" title="">2013</a>)</cite>, Transformer <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib48" title="">2017</a>)</cite>, BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib17" title="">2018</a>)</cite>, T5 <cite class="ltx_cite ltx_citemacro_citep">(Raffel et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib34" title="">2019</a>)</cite>와 T5X <cite class="ltx_cite ltx_citemacro_citep">(Roberts et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib35" title="">2022</a>)</cite> 등 구글의 오랜 오픈 모델 및 생태계 역사를 기반으로 한다.</p>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">LLM의 책임 있는 출시는 프론티어 모델의 안전성을 향상시키고, 이 획기적인 기술에 대한 공평한 접근을 보장하며, 현재 기술에 대한 엄격한 평가 및 분석을 가능하게 하고, 다음 혁신 물결의 개발을 가능하게 하는 데 중요하다고 믿는다. 모든 젬마 모델에 대한 철저한 테스트가 수행되었지만 테스트가 젬마를 사용할 수 있는 모든 애플리케이션 및 시나리오를 다룰 수는 없다. 이를 염두에 두고 모든 젬마 사용자는 배포 또는 사용 전에 사용 사례에 특정한 엄격한 안전 테스트를 수행해야 한다. 안전성에 대한 접근법에 대한 자세한 내용은 <a class="ltx_ref ltx_refmacro_nameref" href="https://arxiv.org/html/2403.08295v1#S7" title="7 Responsible Deployment ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_title">Responsible Deployment</span></a> 섹션에서 찾을 수 있다.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">이 기술 보고서에서 우리는 젬마에 대한 모델 아키텍처, 훈련 인프라, 사전 훈련 및 미세 조정 레시피에 대한 자세한 개요를 제공한 다음 다양한 양적 및 질적 벤치마크, 표준 학술 벤치마크 및 인간 선호도 평가 모두에 걸쳐 모든 체크포인트에 대한 철저한 평가를 제공한다. 그런 다음 안전하고 책임 있는 배치에 대한 접근 방식에 대해 자세히 논의합니다. 마지막으로 Gemma의 광범위한 함의와 그 한계와 장점, 결론에 대해 개괄한다.</p>
</div>
</section>
<section class="ltx_section" id="S2" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Model Architecture</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Gemma 모델 아키텍처는 트랜스포머 디코더 <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib48" title="">2017</a>)</cite>를 기반으로 한다. 아키텍처의 핵심 파라미터는 표 <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S2.T1" title="Table 1 ‣ 2 Model Architecture ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_tag">1</span></a>에 요약되어 있다. 모델들은 8192 토큰들의 컨텍스트 길이에 대해 트레이닝된다.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S2.T1.1">
<tbody><tr class="ltx_tr" id="S2.T1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.1.1.1">Parameters</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S2.T1.1.1.2"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.2.1">2B</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S2.T1.1.1.3"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.3.1">7B</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.1.2.1">
<span class="ltx_text ltx_font_italic" id="S2.T1.1.2.1.1">d</span>_model</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.T1.1.2.2">2048</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S2.T1.1.2.3">3072</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.3">
<td class="ltx_td ltx_align_left" id="S2.T1.1.3.1">Layers</td>
<td class="ltx_td ltx_align_right" id="S2.T1.1.3.2">18</td>
<td class="ltx_td ltx_align_right" id="S2.T1.1.3.3">28</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.4">
<td class="ltx_td ltx_align_left" id="S2.T1.1.4.1">Feedforward hidden dims</td>
<td class="ltx_td ltx_align_right" id="S2.T1.1.4.2">32768</td>
<td class="ltx_td ltx_align_right" id="S2.T1.1.4.3">49152</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.5">
<td class="ltx_td ltx_align_left" id="S2.T1.1.5.1">Num heads</td>
<td class="ltx_td ltx_align_right" id="S2.T1.1.5.2">8</td>
<td class="ltx_td ltx_align_right" id="S2.T1.1.5.3">16</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.6">
<td class="ltx_td ltx_align_left" id="S2.T1.1.6.1">Num KV heads</td>
<td class="ltx_td ltx_align_right" id="S2.T1.1.6.2">1</td>
<td class="ltx_td ltx_align_right" id="S2.T1.1.6.3">16</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.7">
<td class="ltx_td ltx_align_left" id="S2.T1.1.7.1">Head size</td>
<td class="ltx_td ltx_align_right" id="S2.T1.1.7.2">256</td>
<td class="ltx_td ltx_align_right" id="S2.T1.1.7.3">256</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.8">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S2.T1.1.8.1">Vocab size</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S2.T1.1.8.2">256128</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S2.T1.1.8.3">256128</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 1:</span>Key model parameters.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">또한 기존 변압기 용지 이후에 제안된 몇 가지 개선 사항을 활용한다. 아래에서는 포함된 개선 사항을 나열합니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p3">
<p class="ltx_p" id="S2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.p3.1.1">Multi-Query Attention</span> <cite class="ltx_cite ltx_citemacro_citep">(Shazeer, <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib39" title="">2019</a>)</cite>. 특히, 7B 모델은 멀티 헤드 어텐션을 사용하는 반면 2B 체크포인트는 멀티 쿼리 어텐션(<math alttext="num\_kv\_heads=1" class="ltx_Math" display="inline" id="S2.p3.1.m1.1"><semantics id="S2.p3.1.m1.1a"><mrow id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml"><mrow id="S2.p3.1.m1.1.1.2" xref="S2.p3.1.m1.1.1.2.cmml"><mi id="S2.p3.1.m1.1.1.2.2" xref="S2.p3.1.m1.1.1.2.2.cmml">n</mi><mo id="S2.p3.1.m1.1.1.2.1" xref="S2.p3.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S2.p3.1.m1.1.1.2.3" xref="S2.p3.1.m1.1.1.2.3.cmml">u</mi><mo id="S2.p3.1.m1.1.1.2.1a" xref="S2.p3.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S2.p3.1.m1.1.1.2.4" xref="S2.p3.1.m1.1.1.2.4.cmml">m</mi><mo id="S2.p3.1.m1.1.1.2.1b" xref="S2.p3.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S2.p3.1.m1.1.1.2.5" mathvariant="normal" xref="S2.p3.1.m1.1.1.2.5.cmml">_</mi><mo id="S2.p3.1.m1.1.1.2.1c" xref="S2.p3.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S2.p3.1.m1.1.1.2.6" xref="S2.p3.1.m1.1.1.2.6.cmml">k</mi><mo id="S2.p3.1.m1.1.1.2.1d" xref="S2.p3.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S2.p3.1.m1.1.1.2.7" xref="S2.p3.1.m1.1.1.2.7.cmml">v</mi><mo id="S2.p3.1.m1.1.1.2.1e" xref="S2.p3.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S2.p3.1.m1.1.1.2.8" mathvariant="normal" xref="S2.p3.1.m1.1.1.2.8.cmml">_</mi><mo id="S2.p3.1.m1.1.1.2.1f" xref="S2.p3.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S2.p3.1.m1.1.1.2.9" xref="S2.p3.1.m1.1.1.2.9.cmml">h</mi><mo id="S2.p3.1.m1.1.1.2.1g" xref="S2.p3.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S2.p3.1.m1.1.1.2.10" xref="S2.p3.1.m1.1.1.2.10.cmml">e</mi><mo id="S2.p3.1.m1.1.1.2.1h" xref="S2.p3.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S2.p3.1.m1.1.1.2.11" xref="S2.p3.1.m1.1.1.2.11.cmml">a</mi><mo id="S2.p3.1.m1.1.1.2.1i" xref="S2.p3.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S2.p3.1.m1.1.1.2.12" xref="S2.p3.1.m1.1.1.2.12.cmml">d</mi><mo id="S2.p3.1.m1.1.1.2.1j" xref="S2.p3.1.m1.1.1.2.1.cmml">⁢</mo><mi id="S2.p3.1.m1.1.1.2.13" xref="S2.p3.1.m1.1.1.2.13.cmml">s</mi></mrow><mo id="S2.p3.1.m1.1.1.1" xref="S2.p3.1.m1.1.1.1.cmml">=</mo><mn id="S2.p3.1.m1.1.1.3" xref="S2.p3.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><apply id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1"><eq id="S2.p3.1.m1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1"></eq><apply id="S2.p3.1.m1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.2"><times id="S2.p3.1.m1.1.1.2.1.cmml" xref="S2.p3.1.m1.1.1.2.1"></times><ci id="S2.p3.1.m1.1.1.2.2.cmml" xref="S2.p3.1.m1.1.1.2.2">𝑛</ci><ci id="S2.p3.1.m1.1.1.2.3.cmml" xref="S2.p3.1.m1.1.1.2.3">𝑢</ci><ci id="S2.p3.1.m1.1.1.2.4.cmml" xref="S2.p3.1.m1.1.1.2.4">𝑚</ci><ci id="S2.p3.1.m1.1.1.2.5.cmml" xref="S2.p3.1.m1.1.1.2.5">_</ci><ci id="S2.p3.1.m1.1.1.2.6.cmml" xref="S2.p3.1.m1.1.1.2.6">𝑘</ci><ci id="S2.p3.1.m1.1.1.2.7.cmml" xref="S2.p3.1.m1.1.1.2.7">𝑣</ci><ci id="S2.p3.1.m1.1.1.2.8.cmml" xref="S2.p3.1.m1.1.1.2.8">_</ci><ci id="S2.p3.1.m1.1.1.2.9.cmml" xref="S2.p3.1.m1.1.1.2.9">ℎ</ci><ci id="S2.p3.1.m1.1.1.2.10.cmml" xref="S2.p3.1.m1.1.1.2.10">𝑒</ci><ci id="S2.p3.1.m1.1.1.2.11.cmml" xref="S2.p3.1.m1.1.1.2.11">𝑎</ci><ci id="S2.p3.1.m1.1.1.2.12.cmml" xref="S2.p3.1.m1.1.1.2.12">𝑑</ci><ci id="S2.p3.1.m1.1.1.2.13.cmml" xref="S2.p3.1.m1.1.1.2.13">𝑠</ci></apply><cn id="S2.p3.1.m1.1.1.3.cmml" type="integer" xref="S2.p3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">num\_kv\_heads=1</annotation><annotation encoding="application/x-llamapun" id="S2.p3.1.m1.1d">italic_n italic_u italic_m _ italic_k italic_v _ italic_h italic_e italic_a italic_d italic_s = 1</annotation></semantics></math> 포함)을 사용하며, 각각의 어텐션 변형을 밝힌 절제 연구를 기반으로 각 스케일 <cite class="ltx_cite ltx_citemacro_citep">(Shazeer, <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib39" title="">2019</a>)</cite>에서 성능이 향상되었다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p4">
<p class="ltx_p" id="S2.p4.1"><span class="ltx_text ltx_font_bold" id="S2.p4.1.1">RoPE Embeddings</span> <cite class="ltx_cite ltx_citemacro_citep">(Su et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib42" title="">2021</a>)</cite>. 절대 위치 임베딩을 사용하는 대신 각 레이어에서 회전 위치 임베딩을 사용하며, 모델 크기를 줄이기 위해 입력과 출력에 걸쳐 임베딩을 공유한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p5">
<p class="ltx_p" id="S2.p5.1"><span class="ltx_text ltx_font_bold" id="S2.p5.1.1">GeGLU Activations</span> <cite class="ltx_cite ltx_citemacro_citep">(Shazeer, <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib40" title="">2020</a>)</cite>. 표준 ReLU 비선형성은 GeGLU 활성화 함수로 대체된다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.p6">
<p class="ltx_p" id="S2.p6.1"><span class="ltx_text ltx_font_bold" id="S2.p6.1.1">RMSNorm</span>. 각 변압기 하위 계층, 주의 계층 및 피드포워드 계층의 입력을 RMSNorm<cite class="ltx_cite ltx_citemacro_citep">(Zhang and Sennrich, <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib54" title="">2019</a>)</cite>로 정규화한다.</p>
</div>
</section>
<section class="ltx_section" id="S3" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Training Infrastructure</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">TPUv5e를 사용하여 젬마 모델을 훈련하며, TPUv5e는 16 x 16 칩의 2D 토러스로 구성된 256 칩의 포드에 배포된다. 7B 모델의 경우 총 4096 TPUv5e로 16개의 포드에 걸쳐 모델을 훈련한다. 2개의 포드에 걸쳐 2B 모델을 사전 훈련하여 총 512개의 TPUv5e를 수행했다. 포드 내에서 7B 모델에 대해 16-방향 모델 샤딩 및 16-방향 데이터 복제를 사용한다. 2B의 경우 256방향 데이터 복제를 사용합니다. 최적화기 상태는 ZeRO-3와 유사한 기술을 사용하여 추가로 샤딩된다. 우리는 포드를 넘어 <cite class="ltx_cite ltx_citemacro_citep">(Barham et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib6" title="">2022</a>)</cite>의 Pathways 접근법을 사용하여 데이터 센터 네트워크를 통해 데이터 복제 감소를 수행한다.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.1">
<tbody><tr class="ltx_tr" id="S3.T2.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T2.1.1.1">Model</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T2.1.1.2">
<span class="ltx_text" id="S3.T2.1.1.2.1"></span> <span class="ltx_text" id="S3.T2.1.1.2.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T2.1.1.2.2.1">
<span class="ltx_tr" id="S3.T2.1.1.2.2.1.1">
<span class="ltx_td ltx_align_center" id="S3.T2.1.1.2.2.1.1.1">Embedding</span></span>
<span class="ltx_tr" id="S3.T2.1.1.2.2.1.2">
<span class="ltx_td ltx_align_center" id="S3.T2.1.1.2.2.1.2.1">Parameters</span></span>
</span></span> <span class="ltx_text" id="S3.T2.1.1.2.3"></span>
</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S3.T2.1.1.3">
<span class="ltx_text" id="S3.T2.1.1.3.1"></span> <span class="ltx_text" id="S3.T2.1.1.3.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T2.1.1.3.2.1">
<span class="ltx_tr" id="S3.T2.1.1.3.2.1.1">
<span class="ltx_td ltx_align_center" id="S3.T2.1.1.3.2.1.1.1">Non-embedding</span></span>
<span class="ltx_tr" id="S3.T2.1.1.3.2.1.2">
<span class="ltx_td ltx_align_center" id="S3.T2.1.1.3.2.1.2.1">Parameters</span></span>
</span></span> <span class="ltx_text" id="S3.T2.1.1.3.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.1.2.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.2.1.1">2B</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.2.2">524,550,144</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S3.T2.1.2.3">1,981,884,416</td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.3">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.1.3.1"><span class="ltx_text ltx_font_bold" id="S3.T2.1.3.1.1">7B</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T2.1.3.2">786,825,216</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S3.T2.1.3.3">7,751,248,896</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 2:</span>Gemma 모델의 두 크기에 대한 파라미터 카운트.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">제미니에서와 같이 Jax <cite class="ltx_cite ltx_citemacro_citep">(Roberts et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib36" title="">2023</a>)</cite>와 Pathways <cite class="ltx_cite ltx_citemacro_citep">(Barham et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib6" title="">2022</a>)</cite>의 ’단일 컨트롤러’ 프로그래밍 패러다임을 활용하여 단일 Python 프로세스가 전체 훈련 실행을 오케스트레이션할 수 있도록 하여 개발 프로세스를 단순화하고, GSPMD 분할기 <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib53" title="">2021</a>)</cite>를 훈련 단계 계산에 활용하고 MegaScale XLA 컴파일러 <cite class="ltx_cite ltx_citemacro_citep">(XLA, <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib52" title="">2019</a>)</cite>를 활용한다.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Carbon Footprint</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.2">Gemma 모델을 사전 훈련하여 탄소 배출량을 <math alttext="\sim 131" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mrow id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml"></mi><mo id="S3.SS1.p1.1.m1.1.1.1" xref="S3.SS1.p1.1.m1.1.1.1.cmml">∼</mo><mn id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml">131</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="latexml" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">absent</csymbol><cn id="S3.SS1.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS1.p1.1.m1.1.1.3">131</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\sim 131</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">∼ 131</annotation></semantics></math> <math alttext="tCO_{2}eq" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mrow id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">t</mi><mo id="S3.SS1.p1.2.m2.1.1.1" xref="S3.SS1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml">C</mi><mo id="S3.SS1.p1.2.m2.1.1.1a" xref="S3.SS1.p1.2.m2.1.1.1.cmml">⁢</mo><msub id="S3.SS1.p1.2.m2.1.1.4" xref="S3.SS1.p1.2.m2.1.1.4.cmml"><mi id="S3.SS1.p1.2.m2.1.1.4.2" xref="S3.SS1.p1.2.m2.1.1.4.2.cmml">O</mi><mn id="S3.SS1.p1.2.m2.1.1.4.3" xref="S3.SS1.p1.2.m2.1.1.4.3.cmml">2</mn></msub><mo id="S3.SS1.p1.2.m2.1.1.1b" xref="S3.SS1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS1.p1.2.m2.1.1.5" xref="S3.SS1.p1.2.m2.1.1.5.cmml">e</mi><mo id="S3.SS1.p1.2.m2.1.1.1c" xref="S3.SS1.p1.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS1.p1.2.m2.1.1.6" xref="S3.SS1.p1.2.m2.1.1.6.cmml">q</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><times id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1.1"></times><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">𝑡</ci><ci id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3">𝐶</ci><apply id="S3.SS1.p1.2.m2.1.1.4.cmml" xref="S3.SS1.p1.2.m2.1.1.4"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.4.1.cmml" xref="S3.SS1.p1.2.m2.1.1.4">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.4.2.cmml" xref="S3.SS1.p1.2.m2.1.1.4.2">𝑂</ci><cn id="S3.SS1.p1.2.m2.1.1.4.3.cmml" type="integer" xref="S3.SS1.p1.2.m2.1.1.4.3">2</cn></apply><ci id="S3.SS1.p1.2.m2.1.1.5.cmml" xref="S3.SS1.p1.2.m2.1.1.5">𝑒</ci><ci id="S3.SS1.p1.2.m2.1.1.6.cmml" xref="S3.SS1.p1.2.m2.1.1.6">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">tCO_{2}eq</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_t italic_C italic_O start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT italic_e italic_q</annotation></semantics></math>로 추정한다. 이 값은 TPU 데이터 센터에서 직접 보고한 시간당 에너지 사용량을 기반으로 계산되며, 데이터 센터를 만들고 유지하는 데 사용되는 추가 에너지를 고려하여 이 값을 확장하여 훈련 실험을 위한 총 에너지 사용량을 제공합니다. 데이터 센터에서 보고한 시간당 탄소 배출 데이터와 시간당 에너지 사용량을 결합하여 총 에너지 사용량을 탄소 배출로 전환합니다.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">또한, 구글 데이터 센터는 에너지 효율, 재생 에너지 구매, 탄소 상쇄의 조합을 통해 달성되는 탄소 중립이다. 이 탄소 중성은 우리의 실험과 그것을 실행하는 데 사용되는 기계에도 적용됩니다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Pretraining</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Training Data</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Gemma 2B 및 7B는 웹 문서, 수학 및 코드로부터 주로 영어 데이터의 2T 및 6T 토큰에 대해 각각 트레이닝된다. 제미니(Gemini)와 달리 이 모델들은 멀티모달(multimodal)이 아니며, 다국어 작업에 대한 최신 성능을 위해 훈련된 것도 아니다.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1">호환성을 위해 Gemini의 SentencePiece tokenizer <cite class="ltx_cite ltx_citemacro_citep">(Kudo and Richardson, <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib25" title="">2018</a>)</cite>의 부분 집합을 사용한다. <cite class="ltx_cite ltx_citemacro_citep">(Chowdhery et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib11" title="">2022</a>)</cite> 및 <cite class="ltx_cite ltx_citemacro_citep">(Gemini Team, <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib18" title="">2023</a>)</cite> 모두에 사용되는 기술에 따라 숫자를 분할하고 추가 화이트 스페이스를 제거하지 않으며 알려지지 않은 토큰에 대한 바이트 수준 인코딩에 의존합니다. 어휘 크기는 256k 토큰입니다.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Filtering</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">원치 않거나 안전하지 않은 발화의 위험을 줄이기 위해 사전 훈련 데이터 세트를 필터링하고 특정 개인 정보 및 기타 민감한 데이터를 필터링합니다. 여기에는 유해하거나 품질이 낮은 콘텐츠를 제거하기 위해 휴리스틱 및 모델 기반 분류기를 모두 사용하는 것이 포함된다. 또한 사전 훈련 데이터 혼합물에서 모든 평가 세트를 필터링하고 표적 오염 분석을 실행하여 평가 세트 누출에 대해 확인하고 민감한 출력의 증식을 최소화하여 암송 위험을 줄인다.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">최종 데이터 혼합물은 2B 및 7B 모델 모두에 대한 일련의 삭제를 통해 결정되었다. <cite class="ltx_cite ltx_citemacro_citep">(Gemini Team, <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib18" title="">2023</a>)</cite>에서 주장한 접근법과 유사하게 훈련 종료 시 관련 고품질 데이터의 가중치를 높이기 위해 훈련 전반에 걸쳐 코퍼스 혼합물을 변경하는 훈련을 진행한다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Instruction Tuning</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">우리는 Gemma 2B와 7B를 텍스트 전용, 영어 전용 합성 및 인간 생성 프롬프트 응답 쌍과 인간 피드백으로부터의 강화 학습을 혼합한 지도 미세 조정(supervised fine-tuning, SFT)으로 미세 조정하고 레이블이 지정된 영어 전용 선호도 데이터와 고품질 프롬프트 세트를 기반으로 한 정책에 대해 훈련된 보상 모델을 인간 피드백(RLHF)으로부터 강화 학습한다. 두 단계 모두 다운스트림 자동 평가 및 모델 출력의 인간 선호도 평가에서 향상된 성능을 위해 중요하다는 것을 발견했다.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Supervised Fine-Tuning</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">LM 기반 측면 평가 <cite class="ltx_cite ltx_citemacro_citep">(Zheng et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib55" title="">2023</a>)</cite>를 기반으로 감독 미세 조정을 위해 데이터 혼합물을 선택했다. 유지된 프롬프트 세트가 주어지면 테스트 모델에서 응답을 생성하고 기준 모델에서 동일한 프롬프트에 대한 응답을 생성하고 이를 무작위로 섞고 더 크고 높은 능력 모델에 요청하여 두 응답 간의 선호도를 표현한다. 지시 준수, 사실성, 창의성 및 안전과 같은 특정 기능을 강조하기 위해 다양한 프롬프트 세트가 구성됩니다. 우리가 사용하는 서로 다른 자동 LM 기반 판정은 인간의 선호도와 정렬하기 위해 생각 연쇄 프롬프트 <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib49" title="">2022</a>)</cite> 및 루브릭 및 구성 <cite class="ltx_cite ltx_citemacro_citep">(Bai et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib5" title="">2022</a>)</cite>와 같은 여러 기술을 사용한다.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Filtering</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">합성 데이터를 사용할 때 특정 개인 정보, 안전하지 않거나 독성 모델 출력, 잘못된 자기 식별 데이터 또는 복제된 예를 보여주는 예제를 제거하거나 이를 필터링하는 여러 단계를 실행합니다. 제미니에 이어, 우리는 환각을 최소화하기 위해 더 나은 상황 내 귀인, 헤징 및 거부를 장려하는 데이터의 하위 집합을 포함하는 것이 다른 메트릭에 대한 모델 성능을 저하시키지 않으면서 여러 사실성 메트릭에 대한 성능을 향상시킬 수 있음을 발견했다.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">조정된 하이퍼파라미터를 포함하는 최종 데이터 혼합물과 감독된 미세 조정 레시피는 안전 및 환각과 관련된 모델 피해를 최소화하면서 유용성을 향상시키는 것을 기반으로 선택되었다.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Formatting</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">명령 튜닝된 모델들은 트레이닝 및 추론 시간 모두에서, 추가 정보를 갖는 모든 명령 튜닝 예들에 주석을 달아주는 특정 포맷터로 트레이닝된다. 그것은 1) 사용자 역할과 같은 대화에서 역할을 나타내는 것과 2) 특히 다중 회전 대화에서 회전을 묘사하는 두 가지 목적을 가지고 있다. 이를 위해 토큰화기에는 특수 제어 토큰이 예약되어 있습니다. 포맷터 없이 일관된 세대를 얻을 수 있지만 모델에 대한 분배가 불가능하고 더 나쁜 세대를 생성할 가능성이 매우 높다.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">관련 포맷팅 제어 토큰들은 표 <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S5.T3" title="Table 3 ‣ 5.3 Formatting ‣ 5 Instruction Tuning ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_tag">3</span></a>에 제시되며, 대화 예는 표 <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S5.T4" title="Table 4 ‣ 5.3 Formatting ‣ 5 Instruction Tuning ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_tag">4</span></a>에 제시된다.</p>
</div>
<figure class="ltx_table" id="S5.T3">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T3.1">
<tbody><tr class="ltx_tr" id="S5.T3.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T3.1.1.1"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.1.1" style="font-size:80%;">Context</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T3.1.1.2"><span class="ltx_text ltx_font_bold" id="S5.T3.1.1.2.1" style="font-size:80%;">Relevant Token</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.2.1"><span class="ltx_text" id="S5.T3.1.2.1.1" style="font-size:70%;">User turn</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.2.2"><span class="ltx_text ltx_font_typewriter" id="S5.T3.1.2.2.1" style="font-size:80%;color:#0F75FF;">user</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.3.1"><span class="ltx_text" id="S5.T3.1.3.1.1" style="font-size:70%;">Model turn</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.3.2"><span class="ltx_text ltx_font_typewriter" id="S5.T3.1.3.2.1" style="font-size:80%;color:#0F75FF;">model</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T3.1.4.1"><span class="ltx_text" id="S5.T3.1.4.1.1" style="font-size:70%;">Start of conversation turn</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T3.1.4.2"><span class="ltx_text ltx_font_typewriter" id="S5.T3.1.4.2.1" style="font-size:80%;color:#0F75FF;">&lt;start_of_turn&gt;</span></td>
</tr>
<tr class="ltx_tr" id="S5.T3.1.5">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S5.T3.1.5.1"><span class="ltx_text" id="S5.T3.1.5.1.1" style="font-size:70%;">End of conversation turn</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S5.T3.1.5.2"><span class="ltx_text ltx_font_typewriter" id="S5.T3.1.5.2.1" style="font-size:80%;color:#0F75FF;">&lt;end_of_turn&gt;</span></td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">표 3:</span>Gemma 모델의 SFT 및 RLHF 모두에 사용되는 관련 포맷팅 제어 토큰.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S5.T4">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T4.1">
<tbody><tr class="ltx_tr" id="S5.T4.1.1">
<td class="ltx_td ltx_align_right ltx_border_tt" id="S5.T4.1.1.1">
<span class="ltx_text" id="S5.T4.1.1.1.1" style="font-size:80%;">
</span><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.1.2" style="font-size:80%;">User:</span>
</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T4.1.1.2"><span class="ltx_text ltx_font_typewriter" id="S5.T4.1.1.2.1" style="font-size:80%;color:#0F75FF;">&lt;start_of_turn&gt;user</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.2">
<td class="ltx_td" id="S5.T4.1.2.1"></td>
<td class="ltx_td ltx_align_left" id="S5.T4.1.2.2"><span class="ltx_text ltx_font_typewriter" id="S5.T4.1.2.2.1" style="font-size:80%;">Knock knock.<span class="ltx_text" id="S5.T4.1.2.2.1.1" style="color:#0F75FF;">&lt;end_of_turn&gt;</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.3">
<td class="ltx_td" id="S5.T4.1.3.1"></td>
<td class="ltx_td ltx_align_left" id="S5.T4.1.3.2"><span class="ltx_text ltx_font_typewriter" id="S5.T4.1.3.2.1" style="font-size:80%;color:#0F75FF;">&lt;start_of_turn&gt;model</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.4">
<td class="ltx_td ltx_align_right" id="S5.T4.1.4.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.4.1.1" style="font-size:80%;">Model:</span></td>
<td class="ltx_td ltx_align_left" id="S5.T4.1.4.2"><span class="ltx_text ltx_font_typewriter" id="S5.T4.1.4.2.1" style="font-size:80%;">Who’s there?<span class="ltx_text" id="S5.T4.1.4.2.1.1" style="color:#0F75FF;">&lt;end_of_turn&gt;</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.5">
<td class="ltx_td ltx_align_right" id="S5.T4.1.5.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.5.1.1" style="font-size:80%;">User:</span></td>
<td class="ltx_td ltx_align_left" id="S5.T4.1.5.2"><span class="ltx_text ltx_font_typewriter" id="S5.T4.1.5.2.1" style="font-size:80%;color:#0F75FF;">&lt;start_of_turn&gt;user</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.6">
<td class="ltx_td" id="S5.T4.1.6.1"></td>
<td class="ltx_td ltx_align_left" id="S5.T4.1.6.2"><span class="ltx_text ltx_font_typewriter" id="S5.T4.1.6.2.1" style="font-size:80%;">Gemma.<span class="ltx_text" id="S5.T4.1.6.2.1.1" style="color:#0F75FF;">&lt;end_of_turn&gt;</span></span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.7">
<td class="ltx_td" id="S5.T4.1.7.1"></td>
<td class="ltx_td ltx_align_left" id="S5.T4.1.7.2"><span class="ltx_text ltx_font_typewriter" id="S5.T4.1.7.2.1" style="font-size:80%;color:#0F75FF;">&lt;start_of_turn&gt;model</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.8">
<td class="ltx_td ltx_align_right ltx_border_bb" id="S5.T4.1.8.1"><span class="ltx_text ltx_font_bold" id="S5.T4.1.8.1.1" style="font-size:80%;">Model:</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T4.1.8.2"><span class="ltx_text ltx_font_typewriter" id="S5.T4.1.8.2.1" style="font-size:80%;">Gemma who?<span class="ltx_text" id="S5.T4.1.8.2.1.1" style="color:#0F75FF;">&lt;end_of_turn&gt;</span></span></td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">표 4:</span>사용자 및 모델 제어 토큰과의 예제 대화.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Reinforcement Learning from Human Feedback</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">RLHF <cite class="ltx_cite ltx_citemacro_citep">(Christiano et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib12" title="">2017</a>; Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib31" title="">2022</a>)</cite>를 사용하여 감독 미세 조정 모델을 추가로 미세 조정했다. 우리는 인간 평가자로부터 선호도 쌍을 수집하고 제미니와 유사하게 브래들리-테리 모델 <cite class="ltx_cite ltx_citemacro_citep">(Bradley and Terry, <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib8" title="">1952</a>)</cite> 하에서 보상 함수를 훈련했다. 정책은 처음에 조정된 모델에 대한 쿨백-라이블러 정규화 항을 사용하여 REINFORCE <cite class="ltx_cite ltx_citemacro_citep">(Williams, <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib51" title="">1992</a>)</cite>의 변형을 사용하여 이 보상 함수를 최적화하도록 훈련되었다. SFT 단계와 유사하게 하이퍼파라미터를 조정하고 보상 해킹 <cite class="ltx_cite ltx_citemacro_citep">(Amodei et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib2" title="">2016</a>; Skalse et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib41" title="">2022</a>)</cite>를 추가로 완화하기 위해 자동 평가기로 고용량 모델에 의존했으며 기준 모델과 나란히 계산했다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Evaluation</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">자동 벤치마크와 인간 평가를 모두 사용하여 광범위한 도메인에 걸쳐 젬마를 평가한다.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Human Preference Evaluations</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">미세 조정 모델에 대한 표준 학술 벤치마크를 실행하는 것 외에도 최종 릴리스 후보를 인간 평가 연구에 보내 미스트랄 v0.2 7B 명령 모델 <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib22" title="">2023</a>)</cite>와 비교하도록 했다.</p>
</div>
<div class="ltx_para" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1">모델에게 창의적인 글쓰기 작업, 코딩 및 지침에 따라 지침을 따르도록 요청하는 방향으로 약 1000개의 프롬프트의 보류된 컬렉션에서 젬마 7B IT는 51.7%의 긍정적인 승률을 갖고 젬마 2B IT는 미스트랄 v0.2 7B 지침에 비해 41.6%의 승률을 갖는다. 기본 안전 프로토콜 테스트를 지향하는 약 400개의 프롬프트의 보류된 컬렉션에서 젬마 7B IT는 58%의 승률을 갖는 반면 젬마 2B IT는 56.5%의 승률을 갖는다. 우리는 표 <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.T5" title="Table 5 ‣ 6.1 Human Preference Evaluations ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_tag">5</span></a>에 해당하는 숫자를 보고한다.</p>
</div>
<figure class="ltx_table" id="S6.T5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T5.1">
<tbody><tr class="ltx_tr" id="S6.T5.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S6.T5.1.1.1"><span class="ltx_text" id="S6.T5.1.1.1.1" style="font-size:80%;">Model</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S6.T5.1.1.2"><span class="ltx_text" id="S6.T5.1.1.2.1" style="font-size:80%;">Safety</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="S6.T5.1.1.3"><span class="ltx_text" id="S6.T5.1.1.3.1" style="font-size:80%;">Instruction Following</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T5.1.2.1"><span class="ltx_text ltx_font_bold" id="S6.T5.1.2.1.1" style="font-size:80%;">Gemma 7B IT</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.2.2"><span class="ltx_text ltx_font_bold" id="S6.T5.1.2.2.1" style="font-size:80%;">58%</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S6.T5.1.2.3"><span class="ltx_text ltx_font_bold" id="S6.T5.1.2.3.1" style="font-size:80%;">51.7%</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.3">
<td class="ltx_td ltx_align_left" id="S6.T5.1.3.1"><span class="ltx_text ltx_font_italic" id="S6.T5.1.3.1.1" style="font-size:50%;">95% Conf. Interval</span></td>
<td class="ltx_td ltx_align_right" id="S6.T5.1.3.2"><span class="ltx_text" id="S6.T5.1.3.2.1" style="font-size:50%;">[55.9%, 60.1%]</span></td>
<td class="ltx_td ltx_align_right" id="S6.T5.1.3.3"><span class="ltx_text" id="S6.T5.1.3.3.1" style="font-size:50%;">[49.6%, 53.8%]</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.4">
<td class="ltx_td ltx_align_left" id="S6.T5.1.4.1"><span class="ltx_text ltx_font_italic" id="S6.T5.1.4.1.1" style="font-size:50%;">Win / Tie / Loss</span></td>
<td class="ltx_td ltx_align_right" id="S6.T5.1.4.2"><span class="ltx_text" id="S6.T5.1.4.2.1" style="font-size:50%;">42.9% / 30.2% / 26.9%</span></td>
<td class="ltx_td ltx_align_right" id="S6.T5.1.4.3"><span class="ltx_text" id="S6.T5.1.4.3.1" style="font-size:50%;">42.5% / 18.4% / 39.1%</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.5">
<td class="ltx_td ltx_align_left" id="S6.T5.1.5.1"><span class="ltx_text ltx_font_bold" id="S6.T5.1.5.1.1" style="font-size:80%;">Gemma 2B IT</span></td>
<td class="ltx_td ltx_align_right" id="S6.T5.1.5.2"><span class="ltx_text ltx_font_bold" id="S6.T5.1.5.2.1" style="font-size:80%;">56.5%</span></td>
<td class="ltx_td ltx_align_right" id="S6.T5.1.5.3"><span class="ltx_text" id="S6.T5.1.5.3.1" style="font-size:80%;">41.6%</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.6">
<td class="ltx_td ltx_align_left" id="S6.T5.1.6.1"><span class="ltx_text ltx_font_italic" id="S6.T5.1.6.1.1" style="font-size:50%;">95% Conf. Interval</span></td>
<td class="ltx_td ltx_align_right" id="S6.T5.1.6.2"><span class="ltx_text" id="S6.T5.1.6.2.1" style="font-size:50%;">[54.4%, 58.6%]</span></td>
<td class="ltx_td ltx_align_right" id="S6.T5.1.6.3"><span class="ltx_text" id="S6.T5.1.6.3.1" style="font-size:50%;">[39.5%, 43.7%]</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.1.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S6.T5.1.7.1"><span class="ltx_text ltx_font_italic" id="S6.T5.1.7.1.1" style="font-size:50%;">Win / Tie / Loss</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S6.T5.1.7.2"><span class="ltx_text" id="S6.T5.1.7.2.1" style="font-size:50%;">44.8% / 22.9% / 32.3%</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S6.T5.1.7.3"><span class="ltx_text" id="S6.T5.1.7.3.1" style="font-size:50%;">32.7% / 17.8% / 49.5%</span></td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering" style="font-size:80%;"><span class="ltx_tag ltx_tag_table">표 5: </span>Win rate of Gemma models versus Mistral 7B v0.2 Instruct with 95% confidence intervals. 승패의 결렬을 보고하고, 최종 승률을 보고할 때 균등하게 결렬을 한다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Automated Benchmarks</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S6.T6">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T6.15">
<tbody><tr class="ltx_tr" id="S6.T6.15.16">
<td class="ltx_td ltx_border_tt" id="S6.T6.15.16.1"></td>
<td class="ltx_td ltx_border_tt" id="S6.T6.15.16.2"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S6.T6.15.16.3">LLaMA-2</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T6.15.16.4">Mistral</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S6.T6.15.16.5">Gemma</td>
</tr>
<tr class="ltx_tr" id="S6.T6.15.17">
<td class="ltx_td ltx_align_left" id="S6.T6.15.17.1">Benchmark</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.17.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;metric</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.17.3">7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.17.4">13B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.17.5">7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.17.6">2B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.17.7">7B</td>
</tr>
<tr class="ltx_tr" id="S6.T6.15.18">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T6.15.18.1">MMLU</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.18.2">5-shot, top-1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.18.3">45.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.18.4">54.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.18.5">62.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.18.6">42.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.18.7"><span class="ltx_text ltx_font_bold" id="S6.T6.15.18.7.1">64.3</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.15.19">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T6.15.19.1">HellaSwag</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.19.2">0-shot</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.19.3">77.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.19.4">80.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.19.5">81.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.19.6">71.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.19.7"><span class="ltx_text ltx_font_bold" id="S6.T6.15.19.7.1">81.2</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.15.20">
<td class="ltx_td ltx_align_left" id="S6.T6.15.20.1">PIQA</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.20.2">0-shot</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.20.3">78.8</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.20.4">80.5</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.20.5"><span class="ltx_text ltx_font_bold" id="S6.T6.15.20.5.1">82.2</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.20.6">77.3</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.20.7">81.2</td>
</tr>
<tr class="ltx_tr" id="S6.T6.2.2">
<td class="ltx_td ltx_align_left" id="S6.T6.2.2.3">SIQA</td>
<td class="ltx_td ltx_align_center" id="S6.T6.2.2.4">0-shot</td>
<td class="ltx_td ltx_align_center" id="S6.T6.2.2.5">48.3</td>
<td class="ltx_td ltx_align_center" id="S6.T6.2.2.6">50.3</td>
<td class="ltx_td ltx_align_center" id="S6.T6.2.2.2">
<span class="ltx_text ltx_phantom" id="S6.T6.1.1.1.1"><span style="visibility:hidden"><math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.1.1.1.1.m1.1"><semantics id="S6.T6.1.1.1.1.m1.1a"><msup id="S6.T6.1.1.1.1.m1.1.1" xref="S6.T6.1.1.1.1.m1.1.1.cmml"><mi id="S6.T6.1.1.1.1.m1.1.1a" xref="S6.T6.1.1.1.1.m1.1.1.cmml"></mi><mo id="S6.T6.1.1.1.1.m1.1.1.1" xref="S6.T6.1.1.1.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.1.1.1.1.m1.1b"><apply id="S6.T6.1.1.1.1.m1.1.1.cmml" xref="S6.T6.1.1.1.1.m1.1.1"><times id="S6.T6.1.1.1.1.m1.1.1.1.cmml" xref="S6.T6.1.1.1.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.1.1.1.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.1.1.1.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span>47.0<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.2.2.2.m1.1"><semantics id="S6.T6.2.2.2.m1.1a"><msup id="S6.T6.2.2.2.m1.1.1" xref="S6.T6.2.2.2.m1.1.1.cmml"><mi id="S6.T6.2.2.2.m1.1.1a" xref="S6.T6.2.2.2.m1.1.1.cmml"></mi><mo id="S6.T6.2.2.2.m1.1.1.1" xref="S6.T6.2.2.2.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.2.2.2.m1.1b"><apply id="S6.T6.2.2.2.m1.1.1.cmml" xref="S6.T6.2.2.2.m1.1.1"><times id="S6.T6.2.2.2.m1.1.1.1.cmml" xref="S6.T6.2.2.2.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.2.2.2.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.2.2.2.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S6.T6.2.2.7">49.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.2.2.8"><span class="ltx_text ltx_font_bold" id="S6.T6.2.2.8.1">51.8</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.4.4">
<td class="ltx_td ltx_align_left" id="S6.T6.4.4.3">Boolq</td>
<td class="ltx_td ltx_align_center" id="S6.T6.4.4.4">0-shot</td>
<td class="ltx_td ltx_align_center" id="S6.T6.4.4.5">77.4</td>
<td class="ltx_td ltx_align_center" id="S6.T6.4.4.6">81.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.4.4.2">
<span class="ltx_text ltx_phantom" id="S6.T6.3.3.1.1"><span style="visibility:hidden"><math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.3.3.1.1.m1.1"><semantics id="S6.T6.3.3.1.1.m1.1a"><msup id="S6.T6.3.3.1.1.m1.1.1" xref="S6.T6.3.3.1.1.m1.1.1.cmml"><mi id="S6.T6.3.3.1.1.m1.1.1a" xref="S6.T6.3.3.1.1.m1.1.1.cmml"></mi><mo id="S6.T6.3.3.1.1.m1.1.1.1" xref="S6.T6.3.3.1.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.3.3.1.1.m1.1b"><apply id="S6.T6.3.3.1.1.m1.1.1.cmml" xref="S6.T6.3.3.1.1.m1.1.1"><times id="S6.T6.3.3.1.1.m1.1.1.1.cmml" xref="S6.T6.3.3.1.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.3.3.1.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.3.3.1.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span><span class="ltx_text ltx_font_bold" id="S6.T6.4.4.2.2">83.2<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.4.4.2.2.m1.1"><semantics id="S6.T6.4.4.2.2.m1.1a"><msup id="S6.T6.4.4.2.2.m1.1.1" xref="S6.T6.4.4.2.2.m1.1.1.cmml"><mi id="S6.T6.4.4.2.2.m1.1.1a" xref="S6.T6.4.4.2.2.m1.1.1.cmml"></mi><mo id="S6.T6.4.4.2.2.m1.1.1.1" mathvariant="normal" xref="S6.T6.4.4.2.2.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.4.4.2.2.m1.1b"><apply id="S6.T6.4.4.2.2.m1.1.1.cmml" xref="S6.T6.4.4.2.2.m1.1.1"><times id="S6.T6.4.4.2.2.m1.1.1.1.cmml" xref="S6.T6.4.4.2.2.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.4.4.2.2.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.4.4.2.2.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math></span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T6.4.4.7">69.4</td>
<td class="ltx_td ltx_align_center" id="S6.T6.4.4.8"><span class="ltx_text ltx_font_bold" id="S6.T6.4.4.8.1">83.2</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.15.21">
<td class="ltx_td ltx_align_left" id="S6.T6.15.21.1">Winogrande</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.21.2">partial scoring</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.21.3">69.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.21.4">72.8</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.21.5"><span class="ltx_text ltx_font_bold" id="S6.T6.15.21.5.1">74.2</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.21.6">65.4</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.21.7">72.3</td>
</tr>
<tr class="ltx_tr" id="S6.T6.6.6">
<td class="ltx_td ltx_align_left" id="S6.T6.6.6.3">CQA</td>
<td class="ltx_td ltx_align_center" id="S6.T6.6.6.4">7-shot</td>
<td class="ltx_td ltx_align_center" id="S6.T6.6.6.5">57.8</td>
<td class="ltx_td ltx_align_center" id="S6.T6.6.6.6">67.3</td>
<td class="ltx_td ltx_align_center" id="S6.T6.6.6.2">
<span class="ltx_text ltx_phantom" id="S6.T6.5.5.1.1"><span style="visibility:hidden"><math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.5.5.1.1.m1.1"><semantics id="S6.T6.5.5.1.1.m1.1a"><msup id="S6.T6.5.5.1.1.m1.1.1" xref="S6.T6.5.5.1.1.m1.1.1.cmml"><mi id="S6.T6.5.5.1.1.m1.1.1a" xref="S6.T6.5.5.1.1.m1.1.1.cmml"></mi><mo id="S6.T6.5.5.1.1.m1.1.1.1" xref="S6.T6.5.5.1.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.5.5.1.1.m1.1b"><apply id="S6.T6.5.5.1.1.m1.1.1.cmml" xref="S6.T6.5.5.1.1.m1.1.1"><times id="S6.T6.5.5.1.1.m1.1.1.1.cmml" xref="S6.T6.5.5.1.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.5.5.1.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.5.5.1.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span>66.3<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.6.6.2.m1.1"><semantics id="S6.T6.6.6.2.m1.1a"><msup id="S6.T6.6.6.2.m1.1.1" xref="S6.T6.6.6.2.m1.1.1.cmml"><mi id="S6.T6.6.6.2.m1.1.1a" xref="S6.T6.6.6.2.m1.1.1.cmml"></mi><mo id="S6.T6.6.6.2.m1.1.1.1" xref="S6.T6.6.6.2.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.6.6.2.m1.1b"><apply id="S6.T6.6.6.2.m1.1.1.cmml" xref="S6.T6.6.6.2.m1.1.1"><times id="S6.T6.6.6.2.m1.1.1.1.cmml" xref="S6.T6.6.6.2.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.6.6.2.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.6.6.2.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S6.T6.6.6.7">65.3</td>
<td class="ltx_td ltx_align_center" id="S6.T6.6.6.8"><span class="ltx_text ltx_font_bold" id="S6.T6.6.6.8.1">71.3</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.15.22">
<td class="ltx_td ltx_align_left" id="S6.T6.15.22.1">OBQA</td>
<td class="ltx_td" id="S6.T6.15.22.2"></td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.22.3"><span class="ltx_text ltx_font_bold" id="S6.T6.15.22.3.1">58.6</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.22.4">57.0</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.22.5">52.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.22.6">47.8</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.22.7">52.8</td>
</tr>
<tr class="ltx_tr" id="S6.T6.15.23">
<td class="ltx_td ltx_align_left" id="S6.T6.15.23.1">ARC-e</td>
<td class="ltx_td" id="S6.T6.15.23.2"></td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.23.3">75.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.23.4">77.3</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.23.5">80.5</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.23.6">73.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.23.7"><span class="ltx_text ltx_font_bold" id="S6.T6.15.23.7.1">81.5</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.15.24">
<td class="ltx_td ltx_align_left" id="S6.T6.15.24.1">ARC-c</td>
<td class="ltx_td" id="S6.T6.15.24.2"></td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.24.3">45.9</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.24.4">49.4</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.24.5"><span class="ltx_text ltx_font_bold" id="S6.T6.15.24.5.1">54.9</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.24.6">42.1</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.24.7">53.2</td>
</tr>
<tr class="ltx_tr" id="S6.T6.15.25">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T6.15.25.1">TriviaQA</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.25.2">5-shot</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.25.3">72.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.25.4"><span class="ltx_text ltx_font_bold" id="S6.T6.15.25.4.1">79.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.25.5">62.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.25.6">53.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.25.7">63.4</td>
</tr>
<tr class="ltx_tr" id="S6.T6.15.26">
<td class="ltx_td ltx_align_left" id="S6.T6.15.26.1">NQ</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.26.2">5-shot</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.26.3">25.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.26.4"><span class="ltx_text ltx_font_bold" id="S6.T6.15.26.4.1">31.2</span></td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.26.5">23.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.26.6">12.5</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.26.7">23.0</td>
</tr>
<tr class="ltx_tr" id="S6.T6.15.27">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T6.15.27.1">HumanEval</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.27.2">pass@1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.27.3">12.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.27.4">18.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.27.5">26.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.27.6">22.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.15.27.7"><span class="ltx_text ltx_font_bold" id="S6.T6.15.27.7.1">32.3</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.9.9">
<td class="ltx_td ltx_align_left" id="S6.T6.7.7.1">MBPP<math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="S6.T6.7.7.1.m1.1"><semantics id="S6.T6.7.7.1.m1.1a"><msup id="S6.T6.7.7.1.m1.1.1" xref="S6.T6.7.7.1.m1.1.1.cmml"><mi id="S6.T6.7.7.1.m1.1.1a" xref="S6.T6.7.7.1.m1.1.1.cmml"></mi><mo id="S6.T6.7.7.1.m1.1.1.1" xref="S6.T6.7.7.1.m1.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.7.7.1.m1.1b"><apply id="S6.T6.7.7.1.m1.1.1.cmml" xref="S6.T6.7.7.1.m1.1.1"><ci id="S6.T6.7.7.1.m1.1.1.1.cmml" xref="S6.T6.7.7.1.m1.1.1.1">†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.7.7.1.m1.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.7.7.1.m1.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S6.T6.9.9.4">3-shot</td>
<td class="ltx_td ltx_align_center" id="S6.T6.9.9.5">20.8</td>
<td class="ltx_td ltx_align_center" id="S6.T6.9.9.6">30.6</td>
<td class="ltx_td ltx_align_center" id="S6.T6.9.9.3">
<span class="ltx_text ltx_phantom" id="S6.T6.8.8.2.1"><span style="visibility:hidden"><math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.8.8.2.1.m1.1"><semantics id="S6.T6.8.8.2.1.m1.1a"><msup id="S6.T6.8.8.2.1.m1.1.1" xref="S6.T6.8.8.2.1.m1.1.1.cmml"><mi id="S6.T6.8.8.2.1.m1.1.1a" xref="S6.T6.8.8.2.1.m1.1.1.cmml"></mi><mo id="S6.T6.8.8.2.1.m1.1.1.1" xref="S6.T6.8.8.2.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.8.8.2.1.m1.1b"><apply id="S6.T6.8.8.2.1.m1.1.1.cmml" xref="S6.T6.8.8.2.1.m1.1.1"><times id="S6.T6.8.8.2.1.m1.1.1.1.cmml" xref="S6.T6.8.8.2.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.8.8.2.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.8.8.2.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span>40.2<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.9.9.3.m1.1"><semantics id="S6.T6.9.9.3.m1.1a"><msup id="S6.T6.9.9.3.m1.1.1" xref="S6.T6.9.9.3.m1.1.1.cmml"><mi id="S6.T6.9.9.3.m1.1.1a" xref="S6.T6.9.9.3.m1.1.1.cmml"></mi><mo id="S6.T6.9.9.3.m1.1.1.1" xref="S6.T6.9.9.3.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.9.9.3.m1.1b"><apply id="S6.T6.9.9.3.m1.1.1.cmml" xref="S6.T6.9.9.3.m1.1.1"><times id="S6.T6.9.9.3.m1.1.1.1.cmml" xref="S6.T6.9.9.3.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.9.9.3.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.9.9.3.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S6.T6.9.9.7">29.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.9.9.8"><span class="ltx_text ltx_font_bold" id="S6.T6.9.9.8.1">44.4</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.11.11">
<td class="ltx_td ltx_align_left" id="S6.T6.11.11.3">GSM8K</td>
<td class="ltx_td ltx_align_center" id="S6.T6.11.11.4">maj@1</td>
<td class="ltx_td ltx_align_center" id="S6.T6.11.11.5">14.6</td>
<td class="ltx_td ltx_align_center" id="S6.T6.11.11.6">28.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.11.11.2">
<span class="ltx_text ltx_phantom" id="S6.T6.10.10.1.1"><span style="visibility:hidden"><math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.10.10.1.1.m1.1"><semantics id="S6.T6.10.10.1.1.m1.1a"><msup id="S6.T6.10.10.1.1.m1.1.1" xref="S6.T6.10.10.1.1.m1.1.1.cmml"><mi id="S6.T6.10.10.1.1.m1.1.1a" xref="S6.T6.10.10.1.1.m1.1.1.cmml"></mi><mo id="S6.T6.10.10.1.1.m1.1.1.1" xref="S6.T6.10.10.1.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.10.10.1.1.m1.1b"><apply id="S6.T6.10.10.1.1.m1.1.1.cmml" xref="S6.T6.10.10.1.1.m1.1.1"><times id="S6.T6.10.10.1.1.m1.1.1.1.cmml" xref="S6.T6.10.10.1.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.10.10.1.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.10.10.1.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span>35.4<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.11.11.2.m1.1"><semantics id="S6.T6.11.11.2.m1.1a"><msup id="S6.T6.11.11.2.m1.1.1" xref="S6.T6.11.11.2.m1.1.1.cmml"><mi id="S6.T6.11.11.2.m1.1.1a" xref="S6.T6.11.11.2.m1.1.1.cmml"></mi><mo id="S6.T6.11.11.2.m1.1.1.1" xref="S6.T6.11.11.2.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.11.11.2.m1.1b"><apply id="S6.T6.11.11.2.m1.1.1.cmml" xref="S6.T6.11.11.2.m1.1.1"><times id="S6.T6.11.11.2.m1.1.1.1.cmml" xref="S6.T6.11.11.2.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.11.11.2.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.11.11.2.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center" id="S6.T6.11.11.7">17.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.11.11.8"><span class="ltx_text ltx_font_bold" id="S6.T6.11.11.8.1">46.4</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.15.28">
<td class="ltx_td ltx_align_left" id="S6.T6.15.28.1">MATH</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.28.2">4-shot</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.28.3">2.5</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.28.4">3.9</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.28.5">12.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.28.6">11.8</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.28.7"><span class="ltx_text ltx_font_bold" id="S6.T6.15.28.7.1">24.3</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.13.13">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T6.13.13.3">AGIEval</td>
<td class="ltx_td ltx_border_t" id="S6.T6.13.13.4"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.13.13.5">29.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.13.13.6">39.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.13.13.2">
<span class="ltx_text ltx_phantom" id="S6.T6.12.12.1.1"><span style="visibility:hidden"><math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.12.12.1.1.m1.1"><semantics id="S6.T6.12.12.1.1.m1.1a"><msup id="S6.T6.12.12.1.1.m1.1.1" xref="S6.T6.12.12.1.1.m1.1.1.cmml"><mi id="S6.T6.12.12.1.1.m1.1.1a" xref="S6.T6.12.12.1.1.m1.1.1.cmml"></mi><mo id="S6.T6.12.12.1.1.m1.1.1.1" xref="S6.T6.12.12.1.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.12.12.1.1.m1.1b"><apply id="S6.T6.12.12.1.1.m1.1.1.cmml" xref="S6.T6.12.12.1.1.m1.1.1"><times id="S6.T6.12.12.1.1.m1.1.1.1.cmml" xref="S6.T6.12.12.1.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.12.12.1.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.12.12.1.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span>41.2<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.13.13.2.m1.1"><semantics id="S6.T6.13.13.2.m1.1a"><msup id="S6.T6.13.13.2.m1.1.1" xref="S6.T6.13.13.2.m1.1.1.cmml"><mi id="S6.T6.13.13.2.m1.1.1a" xref="S6.T6.13.13.2.m1.1.1.cmml"></mi><mo id="S6.T6.13.13.2.m1.1.1.1" xref="S6.T6.13.13.2.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.13.13.2.m1.1b"><apply id="S6.T6.13.13.2.m1.1.1.cmml" xref="S6.T6.13.13.2.m1.1.1"><times id="S6.T6.13.13.2.m1.1.1.1.cmml" xref="S6.T6.13.13.2.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.13.13.2.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.13.13.2.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.13.13.7">24.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.13.13.8"><span class="ltx_text ltx_font_bold" id="S6.T6.13.13.8.1">41.7</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.15.15">
<td class="ltx_td ltx_align_left" id="S6.T6.15.15.3">BBH</td>
<td class="ltx_td" id="S6.T6.15.15.4"></td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.15.5">32.6</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.15.6">39.4</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.15.2">
<span class="ltx_text ltx_phantom" id="S6.T6.14.14.1.1"><span style="visibility:hidden"><math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.14.14.1.1.m1.1"><semantics id="S6.T6.14.14.1.1.m1.1a"><msup id="S6.T6.14.14.1.1.m1.1.1" xref="S6.T6.14.14.1.1.m1.1.1.cmml"><mi id="S6.T6.14.14.1.1.m1.1.1a" xref="S6.T6.14.14.1.1.m1.1.1.cmml"></mi><mo id="S6.T6.14.14.1.1.m1.1.1.1" xref="S6.T6.14.14.1.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.14.14.1.1.m1.1b"><apply id="S6.T6.14.14.1.1.m1.1.1.cmml" xref="S6.T6.14.14.1.1.m1.1.1"><times id="S6.T6.14.14.1.1.m1.1.1.1.cmml" xref="S6.T6.14.14.1.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.14.14.1.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.14.14.1.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math></span></span><span class="ltx_text ltx_font_bold" id="S6.T6.15.15.2.2">56.1<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.15.15.2.2.m1.1"><semantics id="S6.T6.15.15.2.2.m1.1a"><msup id="S6.T6.15.15.2.2.m1.1.1" xref="S6.T6.15.15.2.2.m1.1.1.cmml"><mi id="S6.T6.15.15.2.2.m1.1.1a" xref="S6.T6.15.15.2.2.m1.1.1.cmml"></mi><mo id="S6.T6.15.15.2.2.m1.1.1.1" mathvariant="normal" xref="S6.T6.15.15.2.2.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.15.15.2.2.m1.1b"><apply id="S6.T6.15.15.2.2.m1.1.1.cmml" xref="S6.T6.15.15.2.2.m1.1.1"><times id="S6.T6.15.15.2.2.m1.1.1.1.cmml" xref="S6.T6.15.15.2.2.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.15.15.2.2.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.15.15.2.2.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math></span>
</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.15.7">35.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.15.15.8">55.1</td>
</tr>
<tr class="ltx_tr" id="S6.T6.15.29">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S6.T6.15.29.1">Average</td>
<td class="ltx_td ltx_border_bb ltx_border_t" id="S6.T6.15.29.2"></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.15.29.3">47.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.15.29.4">52.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.15.29.5">54.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.15.29.6">44.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T6.15.29.7"><span class="ltx_text ltx_font_bold" id="S6.T6.15.29.7.1">56.4</span></td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 6:</span>Academic 벤치마크 결과, 일반 영어 텍스트 데이터에 대해 트레이닝된 유사한 크기의 오픈-가용 모델과 비교된다.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Academic benchmark results, compared to similarly sized, openly-available models trained on general English text data.
<math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="S6.T6.18.m1.1"><semantics id="S6.T6.18.m1.1b"><msup id="S6.T6.18.m1.1.1" xref="S6.T6.18.m1.1.1.cmml"><mi id="S6.T6.18.m1.1.1b" xref="S6.T6.18.m1.1.1.cmml"></mi><mo id="S6.T6.18.m1.1.1.1" xref="S6.T6.18.m1.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.18.m1.1c"><apply id="S6.T6.18.m1.1.1.cmml" xref="S6.T6.18.m1.1.1"><ci id="S6.T6.18.m1.1.1.1.cmml" xref="S6.T6.18.m1.1.1.1">†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.18.m1.1d">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.18.m1.1e">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math> Mistral reports 50.2 on a different split for MBPP and on their split our 7B model achieves 54.5.
<math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T6.19.m2.1"><semantics id="S6.T6.19.m2.1b"><msup id="S6.T6.19.m2.1.1" xref="S6.T6.19.m2.1.1.cmml"><mi id="S6.T6.19.m2.1.1b" xref="S6.T6.19.m2.1.1.cmml"></mi><mo id="S6.T6.19.m2.1.1.1" xref="S6.T6.19.m2.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T6.19.m2.1c"><apply id="S6.T6.19.m2.1.1.cmml" xref="S6.T6.19.m2.1.1"><times id="S6.T6.19.m2.1.1.1.cmml" xref="S6.T6.19.m2.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.19.m2.1d">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T6.19.m2.1e">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math> evaluations run by us. Note that due to restrictive licensing, we were unable to run evals on LLaMA-2; all values above were previously reported in <cite class="ltx_cite ltx_citemacro_cite">Touvron et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib47" title="">2023b</a>)</cite>.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">물리적 추론 <cite class="ltx_cite ltx_citemacro_citep">(Bisk et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib7" title="">2019</a>)</cite>, 사회적 추론 <cite class="ltx_cite ltx_citemacro_citep">(Sap et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib38" title="">2019</a>)</cite>, 질문 응답 <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib13" title="">2019</a>; Kwiatkowski et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib27" title="">2019</a>)</cite>, 코딩 <cite class="ltx_cite ltx_citemacro_citep">(Austin et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib4" title="">2021</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib10" title="">2021</a>)</cite>, 수학 <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib15" title="">2021</a>)</cite>, 상식 추론 <cite class="ltx_cite ltx_citemacro_citep">(Sakaguchi et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib37" title="">2019</a>)</cite>, 언어 모델링 <cite class="ltx_cite ltx_citemacro_citep">(Paperno et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib33" title="">2016</a>)</cite>, 독해 <cite class="ltx_cite ltx_citemacro_citep">(Joshi et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib23" title="">2017</a>)</cite> 등을 포함한 도메인에서 Gemma 모델의 성능을 측정한다.</p>
</div>
<figure class="ltx_table" id="S6.T7">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T7.1">
<tbody><tr class="ltx_tr" id="S6.T7.1.1">
<td class="ltx_td ltx_border_tt" id="S6.T7.1.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T7.1.1.2">Mistral</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T7.1.1.3">Gemma</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.2">
<td class="ltx_td ltx_align_left" id="S6.T7.1.2.1">Benchmark</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.2.2">7B</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.2.3">7B</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T7.1.3.1">ARC-c</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.3.2">60.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T7.1.3.3"><span class="ltx_text ltx_font_bold" id="S6.T7.1.3.3.1">61.9</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.4">
<td class="ltx_td ltx_align_left" id="S6.T7.1.4.1">HellaSwag</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.4.2"><span class="ltx_text ltx_font_bold" id="S6.T7.1.4.2.1">83.3</span></td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.4.3">82.2</td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.5">
<td class="ltx_td ltx_align_left" id="S6.T7.1.5.1">MMLU</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.5.2">64.2</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.5.3"><span class="ltx_text ltx_font_bold" id="S6.T7.1.5.3.1">64.6</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.6">
<td class="ltx_td ltx_align_left" id="S6.T7.1.6.1">TruthfulQA</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.6.2">42.2</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.6.3"><span class="ltx_text ltx_font_bold" id="S6.T7.1.6.3.1">44.8</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.7">
<td class="ltx_td ltx_align_left" id="S6.T7.1.7.1">Winogrande</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.7.2">78.4</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.7.3"><span class="ltx_text ltx_font_bold" id="S6.T7.1.7.3.1">79.0</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.8">
<td class="ltx_td ltx_align_left" id="S6.T7.1.8.1">GSM8K</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.8.2">37.8</td>
<td class="ltx_td ltx_align_center" id="S6.T7.1.8.3"><span class="ltx_text ltx_font_bold" id="S6.T7.1.8.3.1">50.9</span></td>
</tr>
<tr class="ltx_tr" id="S6.T7.1.9">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S6.T7.1.9.1">Average</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T7.1.9.2">61.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S6.T7.1.9.3"><span class="ltx_text ltx_font_bold" id="S6.T7.1.9.3.1">63.8</span></td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 7:</span>HuggingFace H6 벤치마크.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>HuggingFace H6 benchmark.
The performance of small models are sensitive to small modifications in prompts and we further validate the quality of our models on an independent implementation of multiple known benchmarks. All evaluations were run by HuggingFace.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.1">대부분의 자동화된 벤치마크의 경우 쌍둥이와 동일한 평가 방법론을 사용한다. 특히 미스트랄과 비교하여 성과를 보고하는 사람들의 경우 가능한 한 밀접하게 미스트랄 기술 보고서에서 방법론을 복제했다. 이러한 특정 벤치마크는 ARC <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib14" title="">2018</a>)</cite>, CommonsenseQA <cite class="ltx_cite ltx_citemacro_citep">(Talmor et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib45" title="">2019</a>)</cite>, Big Bench Hard <cite class="ltx_cite ltx_citemacro_citep">(Suzgun et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib44" title="">2022</a>)</cite>, AGI Eval(English-only) <cite class="ltx_cite ltx_citemacro_citep">(Zhong et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib56" title="">2023</a>)</cite>이다. 제한적인 라이선스로 인해 LLaMA-2에 대한 평가를 실행할 수 없었고 이전에 보고된 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib47" title="">2023b</a>)</cite> 메트릭만 인용했다.</p>
</div>
<div class="ltx_para" id="S6.SS2.p3">
<p class="ltx_p" id="S6.SS2.p3.1">표 <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.T6" title="Table 6 ‣ 6.2 Automated Benchmarks ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_tag">6</span></a> 및 표 <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.T7" title="Table 7 ‣ 6.2 Automated Benchmarks ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_tag">7</span></a>에 보고된 일련의 학술 벤치마크에 걸쳐 Gemma 2B 및 7B 모델을 여러 외부 오픈 소스(OSS) LLM과 비교한다.</p>
</div>
<div class="ltx_para" id="S6.SS2.p4">
<p class="ltx_p" id="S6.SS2.p4.1">MLU <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib19" title="">2020</a>)</cite>에서 Gemma 7B는 동일한 규모 또는 작은 규모에서 모든 OSS 대안을 능가하며 LLaMA2 13B를 포함한 여러 대형 모델도 능가한다. 그러나 인간 전문가 성능은 벤치마크 저자에 의해 89.8%로 측정되며, 제미니 울트라가 이 임계값을 초과하는 첫 번째 모델이기 때문에 제미니 및 인간 수준의 성능을 달성하기 위해 지속적으로 개선할 여지가 있다.</p>
</div>
<div class="ltx_para" id="S6.SS2.p5">
<p class="ltx_p" id="S6.SS2.p5.1">Gemma 모델은 수학 및 코딩 벤치마크에서 특히 강력한 성능을 보여준다. 모델의 일반적인 분석 능력을 벤치마킹하는 데 자주 사용되는 수학 과제에서 Gemma 모델은 GSM8K <cite class="ltx_cite ltx_citemacro_citep">(Cobbe et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib15" title="">2021</a>)</cite> 및 MATH <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib20" title="">2021</a>)</cite> 벤치마크에서 최소 10점 이상 다른 모델을 능가한다. 마찬가지로 휴먼Eval <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib10" title="">2021</a>)</cite>에서 최소 6점만큼 대체 개방형 모델을 능가합니다. 그들은 심지어 MBPP에서 코드 미세 조정된 CodeLLaMA-7B 모델의 성능을 능가한다(CodeLLaMA는 41.4%의 점수를 달성하며 Gemma 7B는 44.4%를 달성한다).</p>
</div>
<figure class="ltx_table" id="S6.T8">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S6.T8.3">
<tbody><tr class="ltx_tr" id="S6.T8.3.1">
<td class="ltx_td ltx_border_tt" id="S6.T8.3.1.1"></td>
<td class="ltx_td ltx_border_tt" id="S6.T8.3.1.2"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S6.T8.3.1.3">Mistral</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S6.T8.3.1.4">Gemma</td>
</tr>
<tr class="ltx_tr" id="S6.T8.3.2">
<td class="ltx_td ltx_align_left" id="S6.T8.3.2.1">Benchmark</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.2.2">metric</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.3.2.3">7B*</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.3.2.4">2B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.3.2.5">7B</td>
</tr>
<tr class="ltx_tr" id="S6.T8.3.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S6.T8.3.3.1">RealToxicity</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.3.3.2">avg</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.3.3.3">8.44</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.3.3.4"><span class="ltx_text ltx_font_bold" id="S6.T8.3.3.4.1">6.86</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T8.3.3.5">7.90</td>
</tr>
<tr class="ltx_tr" id="S6.T8.3.4">
<td class="ltx_td ltx_align_left" id="S6.T8.3.4.1">BOLD</td>
<td class="ltx_td" id="S6.T8.3.4.2"></td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.4.3">38.21</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.4.4">45.57</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.4.5"><span class="ltx_text ltx_font_bold" id="S6.T8.3.4.5.1">49.08</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.3.5">
<td class="ltx_td ltx_align_left" id="S6.T8.3.5.1">CrowS-Pairs</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.5.2">top-1</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.5.3">32.76</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.5.4">45.82</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.5.5"><span class="ltx_text ltx_font_bold" id="S6.T8.3.5.5.1">51.33</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.3.6">
<td class="ltx_td ltx_align_left" id="S6.T8.3.6.1">BBQ Ambig</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.6.2">1-shot, top-1</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.6.3"><span class="ltx_text ltx_font_bold" id="S6.T8.3.6.3.1">97.53</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.6.4">62.58</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.6.5">92.54</td>
</tr>
<tr class="ltx_tr" id="S6.T8.3.7">
<td class="ltx_td ltx_align_left" id="S6.T8.3.7.1">BBQ Disambig</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.7.2">top-1</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.7.3"><span class="ltx_text ltx_font_bold" id="S6.T8.3.7.3.1">84.45</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.7.4">54.62</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.7.5">71.99</td>
</tr>
<tr class="ltx_tr" id="S6.T8.3.8">
<td class="ltx_td ltx_align_left" id="S6.T8.3.8.1">Winogender</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.8.2">top-1</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.8.3"><span class="ltx_text ltx_font_bold" id="S6.T8.3.8.3.1">64.3</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.8.4">51.25</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.8.5">54.17</td>
</tr>
<tr class="ltx_tr" id="S6.T8.3.9">
<td class="ltx_td ltx_align_left" id="S6.T8.3.9.1">TruthfulQA</td>
<td class="ltx_td" id="S6.T8.3.9.2"></td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.9.3">44.2</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.9.4"><span class="ltx_text ltx_font_bold" id="S6.T8.3.9.4.1">44.84</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.9.5">31.81</td>
</tr>
<tr class="ltx_tr" id="S6.T8.3.10">
<td class="ltx_td ltx_align_left" id="S6.T8.3.10.1">Winobias 1_2</td>
<td class="ltx_td" id="S6.T8.3.10.2"></td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.10.3"><span class="ltx_text ltx_font_bold" id="S6.T8.3.10.3.1">65.72</span></td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.10.4">56.12</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.10.5">59.09</td>
</tr>
<tr class="ltx_tr" id="S6.T8.3.11">
<td class="ltx_td ltx_align_left" id="S6.T8.3.11.1">Winobias 2_2</td>
<td class="ltx_td" id="S6.T8.3.11.2"></td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.11.3">84.53</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.11.4">91.1</td>
<td class="ltx_td ltx_align_center" id="S6.T8.3.11.5"><span class="ltx_text ltx_font_bold" id="S6.T8.3.11.5.1">92.23</span></td>
</tr>
<tr class="ltx_tr" id="S6.T8.3.12">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S6.T8.3.12.1">Toxigen</td>
<td class="ltx_td ltx_border_bb" id="S6.T8.3.12.2"></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T8.3.12.3">60.26</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T8.3.12.4"><span class="ltx_text ltx_font_bold" id="S6.T8.3.12.4.1">29.77</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T8.3.12.5">39.59</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 8:</span>Safety academic benchmark results, compared to similar size, openly-available models.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Safety academic benchmark results, compared to similarly sized, openly-available models.
<br class="ltx_break"><math alttext="{}^{*}" class="ltx_Math" display="inline" id="S6.T8.2.m1.1"><semantics id="S6.T8.2.m1.1b"><msup id="S6.T8.2.m1.1.1" xref="S6.T8.2.m1.1.1.cmml"><mi id="S6.T8.2.m1.1.1b" xref="S6.T8.2.m1.1.1.cmml"></mi><mo id="S6.T8.2.m1.1.1.1" xref="S6.T8.2.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S6.T8.2.m1.1c"><apply id="S6.T8.2.m1.1.1.cmml" xref="S6.T8.2.m1.1.1"><times id="S6.T8.2.m1.1.1.1.cmml" xref="S6.T8.2.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T8.2.m1.1d">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="S6.T8.2.m1.1e">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math> evaluations run by us. Note that due to restrictive licensing, we were unable to run evals on LLaMA-2; we do not report previously-published LLaMA-2 numbers for TruthfulQA, as we use different, non-comparable evaluation set-ups (we use MC2, where LLaMA-2 uses GPT-Judge).
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Memorization Evaluations</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">최근 연구에 따르면 정렬된 모델은 정렬 <cite class="ltx_cite ltx_citemacro_citep">(Nasr et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib30" title="">2023</a>)</cite>를 우회할 수 있는 새로운 적대적 공격에 취약할 수 있다. 이러한 공격들은 모델들이 발산하게 할 수 있고, 때때로 그 과정에서 암기된 훈련 데이터를 역류시킬 수 있다. 우리는 모델<cite class="ltx_cite ltx_citemacro_citep">(Nasr et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib30" title="">2023</a>)</cite>의 암기에 대한 합리적인 상한선 역할을 하는 발견 가능한 암기에 초점을 맞추고 있으며, 여러 연구에서 사용된 공통 정의인 <cite class="ltx_cite ltx_citemacro_citep">(Carlini et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib9" title="">2022</a>; Anil et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib3" title="">2023</a>; Kudugunta et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib26" title="">2023</a>)</cite>이다.</p>
</div>
<figure class="ltx_figure" id="S6.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="480" id="S6.F2.g1" src="https://arxiv.org/html/2403.08295v1/x2.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 2:</span>모델 패밀리에 걸친 평균 암기율을 비교하는 중입니다. 우리는 Gemma 사전 훈련 모델을 비슷한 크기의 PaLM 및 PaLM 2 모델과 비교하고 유사하게 낮은 암기율을 찾는다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS3.p2">
<p class="ltx_p" id="S6.SS3.p2.1"><cite class="ltx_cite ltx_citemacro_citet">Anil et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib3" title="">2023</a>)</cite>에서 수행된 것과 동일한 방법론으로 Gemma 사전 훈련 모델의 암기 <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Our use of “memorization” relies on the definition of that term found at www.genlaw.org/glossary.html.</span></span></span>에 대해 테스트한다. 각 말뭉치에서 10,000개의 문서를 샘플링하고 처음 50개의 토큰을 모델에 대한 프롬프트로 사용한다. 우리는 주로 정확한 암기에 초점을 맞추며, 여기서 모델에 의해 생성된 후속 50개의 토큰이 텍스트에서 그라운드 트루스 연속과 정확히 일치하면 텍스트를 암기된 것으로 분류한다. 그러나 잠재적인 암기를 더 잘 포착하기 위해 10% 편집 거리 임계값을 사용하여 대략적인 암기 <cite class="ltx_cite ltx_citemacro_citep">(Ippolito et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib21" title="">2022</a>)</cite>를 포함한다. <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.F2" title="Figure 2 ‣ 6.3 Memorization Evaluations ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_tag">2</span></a>에서는 가장 가까운 크기의 PaLM<cite class="ltx_cite ltx_citemacro_citep">(Chowdhery et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib11" title="">2022</a>)</cite> 및 PaLM2 모델<cite class="ltx_cite ltx_citemacro_citep">(Anil et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib3" title="">2023</a>)</cite>와 평가 결과를 비교한다.</p>
</div>
<section class="ltx_paragraph" id="S6.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Verbatim Memorization</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS3.SSS0.Px1.p1.1">PaLM 2는 훈련 말뭉치의 공유 하위 집합에 대해 평가하여 PaLM과 비교했다. 그러나 PaLM 모델과 Gemma 사전 훈련 데이터 간에 겹치는 부분이 훨씬 적기 때문에 이 동일한 방법론을 사용하여 훨씬 더 낮은 암기율을 관찰한다(그림 <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.F2" title="Figure 2 ‣ 6.3 Memorization Evaluations ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_tag">2</span></a> left). 대신, 우리는 전체 사전 훈련 데이터 세트에 걸쳐 "전체 암기"를 추정하는 것이 더 신뢰할 수 있는 추정치를 제공한다는 것을 발견한다(그림<a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.F2" title="Figure 2 ‣ 6.3 Memorization Evaluations ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_tag">2</span></a> right). 여기서 이제 Gemma가 PaLM과 비슷한 속도로 훈련 데이터를 암기한다는 것을 발견한다.</p>
</div>
<figure class="ltx_figure" id="S6.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="477" id="S6.F3.g1" src="https://arxiv.org/html/2403.08295v1/x3.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 3:</span>개인 및 민감한 데이터 암기율을 측정합니다. <span class="ltx_text ltx_font_bold" id="S6.F3.2.1">중요한 데이터가 암기되지 않았으므로 그림</span>에서 생략됩니다.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S6.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Personal Data</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS3.SSS0.Px2.p1.1">아마도 더 중요한 것은 개인 데이터가 암기될 수 있다는 가능성일 것이다. Gemma 사전 훈련 모델을 안전하고 신뢰할 수 있도록 만들기 위해 자동화된 기술을 사용하여 훈련 세트에서 특정 개인 정보 및 기타 민감한 데이터를 필터링했습니다.</p>
</div>
<div class="ltx_para" id="S6.SS3.SSS0.Px2.p2">
<p class="ltx_p" id="S6.SS3.SSS0.Px2.p2.1">개인 데이터의 발생 가능성을 식별하기 위해 Google Cloud Sensitive Data Protection<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Available at: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cloud.google.com/sensitive-data-protection" title="">https://cloud.google.com/sensitive-data-protection</a></span></span></span>을 사용합니다. 이 도구는 개인 데이터의 많은 범주(예: 이름, 이메일 등)를 기반으로 세 가지 심각도 수준을 출력한다. 우리는 가장 높은 심각도를 "민감"으로 분류하고 나머지 두 가지를 단순히 "개인"으로 분류한다. 그런 다음, 얼마나 많은 암기된 출력들이 민감한 데이터 또는 개인 데이터를 포함하는지를 측정한다. <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.F3" title="Figure 3 ‣ Verbatim Memorization ‣ 6.3 Memorization Evaluations ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_tag">3</span></a> <em class="ltx_emph ltx_font_italic" id="S6.SS3.SSS0.Px2.p2.1.1">우리는 암기된 민감한 데이터의 경우를 관찰하지 않는다. <em> 우리는 모델이 위에서 언급한 대로 잠재적으로 "개인"으로 분류된 일부 데이터를 암기하지만 종종 훨씬 낮은 비율로 기억한다는 것을 발견했다. 또한, 이러한 도구는 (패턴만 일치하고 컨텍스트를 고려하지 않기 때문에) 많은 거짓 긍정이 있는 것으로 알려져 있다는 점에 유의하는 것이 중요하며, 이는 우리의 결과가 식별된 개인 데이터의 양을 과대평가할 가능성이 있음을 의미한다.</p>
</div>
<figure class="ltx_figure" id="S6.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="485" id="S6.F4.g1" src="https://arxiv.org/html/2403.08295v1/x4.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4:</span>Comparison exact and approximate memorization.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_paragraph" id="S6.SS3.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Approximate Memorization</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS3.SSS0.Px3.p1">
<p class="ltx_p" id="S6.SS3.SSS0.Px3.p1.1">그림 <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.F4" title="Figure 4 ‣ Personal Data ‣ 6.3 Memorization Evaluations ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_tag">4</span></a>에서 약 50% 더 많은 데이터가 대략적으로 기억되고(로그 척도에 유의) 이것이 데이터 세트에 걸쳐 서로 다른 하위 범주 각각에 걸쳐 거의 일관된다는 것을 관찰한다.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S7" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Responsible Deployment</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">구글의 AI 기술 <cite class="ltx_cite ltx_citemacro_citep">(Gemini Team, <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib18" title="">2023</a>; Kavukcuoglu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib24" title="">2022</a>)</cite>의 이전 출시에 따라 예상 가능한 다운스트림 사회적 영향을 식별, 측정 및 관리하기 위해 모델의 책임 있는 개발 및 배포에 대한 구조화된 접근법을 따른다. 최근 제미니 릴리스와 마찬가지로 언어 모델 위험 <cite class="ltx_cite ltx_citemacro_citep">(Weidinger et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib50" title="">2021</a>)</cite>, 업계 전반에 걸쳐 수행된 유사한 사전 연습의 결과 <cite class="ltx_cite ltx_citemacro_citep">(Anil et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib3" title="">2023</a>)</cite>, 내부 및 외부 전문가와의 지속적인 참여, 새로운 모델 취약성을 발견하기 위한 구조화되지 않은 시도에 대한 이전 학술 문헌에 의해 알려진다.</p>
</div>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Benefits</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.SS1.p1">
<p class="ltx_p" id="S7.SS1.p1.1">우리는 AI 과학 기술의 개방성이 상당한 이점을 가져올 수 있다고 믿습니다. 오픈 소싱은 과학과 혁신의 중요한 동인이자 대부분의 상황에서 책임 있는 관행이다. 그러나 이것은 행위자에게 현재 또는 미래에 피해를 줄 수 있는 도구를 제공할 위험과 균형을 이루어야 한다.</p>
</div>
<div class="ltx_para" id="S7.SS1.p2">
<p class="ltx_p" id="S7.SS1.p2.1">구글은 오랫동안 성공적인 연구 혁신(GraphCast, Transformer, BERT, T5, Word2Vec)에 대한 광범위한 액세스를 제공하는 데 전념해 왔으며, 우리는 젬마를 AI 개발 생태계에 출시하면 다운스트림 개발자가 과학, 교육 및 예술과 같은 분야에서 유익한 응용 프로그램을 많이 만들 수 있을 것이라고 믿습니다. 명령 조정 오퍼링은 다양한 개발자가 Gemma의 채팅 및 코드 기능을 활용하여 자신의 유익한 애플리케이션을 지원하는 동시에 특정 사용 사례에 대한 모델의 기능을 전문화할 수 있도록 사용자 정의 미세 조정을 허용해야 합니다. Gemma가 광범위한 개발자 요구를 지원하도록 하기 위해 서로 다른 환경을 최적으로 지원하기 위해 두 가지 모델 크기도 출시하고 있으며, 이러한 모델을 여러 플랫폼에서 사용할 수 있도록 만들었습니다(자세한 내용은 <a class="ltx_ref ltx_href" href="https://www.kaggle.com/models/google/gemma/frameworks/flax/variations/7b-it" title="">Kaggle</a> 참조). 이러한 방식으로 젬마에 광범위한 액세스를 제공하는 것은 이러한 기술을 워크스트림에 통합할 때 새로운 벤처 또는 독립 개발자가 직면하는 경제적 및 기술적 장벽을 줄여야 한다.</p>
</div>
<div class="ltx_para" id="S7.SS1.p3">
<p class="ltx_p" id="S7.SS1.p3.1">개발자에게 명령 조정 모델을 제공할 뿐만 아니라 해당 기본 사전 훈련 모델에 대한 액세스도 제공했다. 이를 통해 AI 안전 연구와 커뮤니티 혁신을 더욱 장려하여 개발자가 사용할 수 있는 다양한 모델 풀을 제공하여 커뮤니티가 이미 <cite class="ltx_cite ltx_citemacro_citep">(Pacchiardi et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib32" title="">2023</a>; Zou et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib57" title="">2023</a>)</cite>로부터 혜택을 받은 다양한 투명성 및 해석 가능성 연구를 구축할 수 있도록 하려는 의도입니다.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Risks</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.SS2.p1">
<p class="ltx_p" id="S7.SS2.p1.1">AI 개발 생태계에 이점을 가져올 뿐만 아니라 딥페이크 이미지 생성, AI 생성 허위 정보, 불법 및 교란 물질과 같은 LLM의 악의적인 사용은 개인 및 기관 수준 <cite class="ltx_cite ltx_citemacro_citep">(Weidinger et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#bib.bib50" title="">2021</a>)</cite> 모두에 피해를 줄 수 있음을 알고 있다. 또한 API 뒤에 있는 모델을 릴리스 하는 것이 아니라 모델 가중치에 대 한 액세스를 제공 하면 책임 있는 배포에 대 한 새로운 문제가 발생 합니다.</p>
</div>
<div class="ltx_para" id="S7.SS2.p2">
<p class="ltx_p" id="S7.SS2.p2.1">첫째, 나쁜 행위자가 우리의 젬마 금지 사용 정책을 위반하는 방식으로 젬마 모델의 사용을 금지하는 사용 약관의 적용을 받음에도 불구하고 악의적인 의도를 위해 젬마를 미세 조정하는 것을 방지할 수 없다. 그러나 구글 딥마인드가 내부적으로 더 광범위한 AI 커뮤니티와 협력하여 지속적으로 탐구할 개방형 시스템의 의도적인 오용에 대한 보다 강력한 완화 전략을 구축하기 위해서는 추가 작업이 필요하다는 것을 인식하고 있다.</p>
</div>
<div class="ltx_para" id="S7.SS2.p3">
<p class="ltx_p" id="S7.SS2.p3.1">우리가 직면한 두 번째 과제는 독성 언어의 생성 또는 차별적인 사회적 피해의 영구화, 모델 환각 및 개인 식별 정보의 유출을 포함하여 열린 모델의 의도하지 않은 행동으로부터 개발자와 다운스트림 사용자를 보호하는 것이다. API 뒤에 모델을 배포할 때 이러한 위험을 다양한 필터링 방법을 통해 줄일 수 있습니다.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.3 </span>Mitigations</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.SS3.p1">
<p class="ltx_p" id="S7.SS3.p1.1">Gemma 계열 모델에 대한 이러한 방어 계층 없이 Gemini 접근법에 따라 사전 훈련 데이터의 편향을 필터링하고 측정하고 표준화된 AI 안전 벤치마크를 통해 안전성을 평가하고 Gemma의 외부 사용과 관련된 위험을 더 잘 이해하기 위한 내부 레드 학습 및 모델을 엄격한 윤리 및 안전 평가에 적용함으로써 이러한 위험으로부터 보호하려고 노력했으며 그 결과는 <a class="ltx_ref" href="https://arxiv.org/html/2403.08295v1#S6.T8" title="Table 8 ‣ 6.2 Automated Benchmarks ‣ 6 Evaluation ‣ Gemma: Open Models Based on Gemini Research and Technology"><span class="ltx_text ltx_ref_tag">8</span></a>에서 볼 수 있다.</p>
</div>
<div class="ltx_para" id="S7.SS3.p2">
<p class="ltx_p" id="S7.SS3.p2.1">우리는 모델을 개선하는 데 상당한 투자를 했지만, 그 한계를 인식하고 있습니다. 다운스트림 사용자의 투명성을 보장하기 위해 연구자에게 젬마에 대한 보다 포괄적인 이해를 제공하기 위해 자세한 <a class="ltx_ref ltx_href" href="https://ai.google.dev/gemma/docs/model_card" title="">model card</a>를 출판했다.</p>
</div>
<div class="ltx_para" id="S7.SS3.p3">
<p class="ltx_p" id="S7.SS3.p3.1">개발자가 책임감 있게 AI를 구축할 수 있도록 지원하는 '생성적 AI 책임 툴킷'도 출시했다. 여기에는 개발자가 책임 있는 AI 모범 사례를 설계하고 구현하고 자체 사용자를 안전하게 유지하는 데 도움이 되는 일련의 자산이 포함됩니다.</p>
</div>
<div class="ltx_para" id="S7.SS3.p4">
<p class="ltx_p" id="S7.SS3.p4.1">개방형 가중치 모델을 출시하는 상대적 신규성은 이러한 모델의 새로운 용도와 오용이 여전히 발견되고 있음을 의미하며, 이것이 구글 딥마인드가 미래 모델 개발과 함께 강력한 완화 전략의 지속적인 연구 개발에 전념하는 이유이다.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.4 </span>Assessment</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.SS4.p1">
<p class="ltx_p" id="S7.SS4.p1.1">궁극적으로 기존 생태계 내에서 접근 가능한 더 큰 시스템의 능력을 감안할 때 젬마 출시가 AI 리스크 포트폴리오 전반에 미치는 영향은 미미할 것으로 판단된다. 이에 비추어 볼 때, 연구, 감사 및 다운스트림 제품 개발을 위한 이러한 모델의 유용성을 감안할 때 AI 커뮤니티에 대한 젬마의 이점이 설명된 위험을 능가한다고 확신한다.</p>
</div>
</section>
<section class="ltx_subsection" id="S7.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.5 </span>Going Forward</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.SS5.p1">
<p class="ltx_p" id="S7.SS5.p1.1">가이드 원칙으로 구글 딥마인드는 우리 모델의 잠재적 위험에 비례하는 평가와 안전 완화를 채택하기 위해 노력한다. 이 경우 젬마 모델이 커뮤니티에 순 이익을 제공할 것이라고 확신하지만 안전에 대한 강조는 이 릴리즈의 되돌릴 수 없는 특성에서 비롯된다. 개방형 모델로 인한 폐해가 아직 잘 정의되지 않았고 그러한 모델에 대한 확립된 평가 프레임워크도 존재하지 않기 때문에 우리는 이 선례를 계속 따르고 개방형 모델 개발에 대해 측정적이고 신중한 접근법을 취할 것이다. 기능이 발전함에 따라 책임 있는 AI 개발을 보장하기 위해 확장 테스트, 시차 릴리스 또는 대체 액세스 메커니즘을 탐색해야 할 수 있습니다.</p>
</div>
<div class="ltx_para" id="S7.SS5.p2">
<p class="ltx_p" id="S7.SS5.p2.1">생태계가 진화함에 따라, 우리는 더 넓은 AI 커뮤니티가 단순한 개방 대 개방을 넘어 이동할 것을 촉구한다. 우리는 위험과 이익에 대한 미묘한 협력적 접근이 필수적이라고 믿기 때문에, 토론을 종결하고 잠재적인 피해를 과장하거나 최소화하는 것을 피한다. 구글 딥마인드에서 우리는 고품질 평가를 개발하고 AI 시스템에 대한 더 깊은 이해를 위해 커뮤니티가 우리와 함께 할 것을 약속합니다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S8" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Discussion and Conclusion</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">텍스트와 코드에 대해 공개적으로 사용할 수 있는 생성 언어 모델 제품군인 젬마를 소개합니다. 젬마는 공개적으로 사용 가능한 언어 모델 성능, 안전성 및 책임 있는 개발의 최첨단 기술을 발전시킵니다.</p>
</div>
<div class="ltx_para" id="S8.p2">
<p class="ltx_p" id="S8.p2.1">특히, 우리는 Gemma 모델이 광범위한 안전 평가 및 완화를 감안할 때 커뮤니티에 순 이익을 제공할 것이라고 확신하지만, 이 방출이 되돌릴 수 없고 열린 모델로 인한 피해가 아직 잘 정의되지 않았음을 인정하므로 이러한 모델의 잠재적 위험에 비례하는 평가 및 안전 완화를 계속 채택한다. 또한, 당사의 모델은 6개의 표준 안전 벤치마크와 인간 측면 평가에서 경쟁사보다 우수합니다.</p>
</div>
<div class="ltx_para" id="S8.p3">
<p class="ltx_p" id="S8.p3.1">젬마 모델은 대화, 추론, 수학 및 코드 생성을 포함한 광범위한 영역에서 성능을 향상시킨다. MLU(64.3%) 및 MBPP(44.4%)에 대한 결과는 젬마의 높은 성능과 공개적으로 사용 가능한 LLM 성능의 지속적인 헤드룸을 모두 보여준다.</p>
</div>
<div class="ltx_para" id="S8.p4">
<p class="ltx_p" id="S8.p4.1">벤치마크 과제에 대한 최첨단 성과 척도를 넘어 지역사회에서 어떤 새로운 유스케이스가 발생하고, 함께 분야를 발전시켜 나가면서 어떤 새로운 역량이 생겨나는지 기대된다. 연구자들이 Gemma를 사용하여 광범위한 연구를 가속화하고 개발자가 유익한 새로운 애플리케이션, 사용자 경험 및 기타 기능을 만들기를 바랍니다.</p>
</div>
<div class="ltx_para" id="S8.p5">
<p class="ltx_p" id="S8.p5.1">Gemma는 코드, 데이터, 아키텍처, 명령어 튜닝, 인간 피드백으로부터의 강화 학습 및 평가를 포함하는 Gemini 모델 프로그램의 많은 학습으로부터 이점을 얻는다. 제미니 기술 보고서에서 논의한 바와 같이 LLM 사용에 대한 완전하지 않은 제한 세트를 반복한다. 벤치마크 작업에 대한 뛰어난 성능에도 불구하고 의도한 대로 안정적으로 수행하는 강력하고 안전한 모델을 만들기 위해서는 추가 연구가 필요하다. 추가 연구 영역의 예는 사실성, 정렬, 복잡한 추론 및 적대적 입력에 대한 견고성을 포함한다. 제미니에서 논의한 바와 같이, 우리는 더 도전적이고 강력한 벤치마크의 필요성에 주목한다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_section" id="S9" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Contributions and Acknowledgments</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S9.p1">
<p class="ltx_p" id="S9.p1.1"><span class="ltx_text ltx_font_bold" id="S9.p1.1.1">Core Contributors</span> <br class="ltx_break"/>Thomas Mesnard  <br class="ltx_break"/>Cassidy Hardin  <br class="ltx_break"/>Robert Dadashi  <br class="ltx_break"/>Surya Bhupatiraju  <br class="ltx_break"/>Shreya Pathak  <br class="ltx_break"/>Laurea Pathak  <br class="ltx_break"/>Laurea Sifre  <br class="ltx_break"/>Morgane Rivière  <br class="ltx_break"/>Mihir Sanjay Kale  <br class="ltx_break"/>Juliette Love  <br class="ltx_break"/>Pouya Tafti  <br class="ltx_break"/>Léonard H</p>
</div>
<div class="ltx_para ltx_noindent" id="S9.p2">
<p class="ltx_p" id="S9.p2.1"><span class="ltx_text ltx_font_bold" id="S9.p2.1">Contributors</span> <br class="ltx_break"/>Aakanksha Chowdhery  <br class="ltx_break"/>Adam Roberts  <br class="ltx_break"/>Aditya Barua  <br class="ltx_break"/>Alex Castro-Ros  <br class="ltx_break"/>Ambrose Slone  <br class="ltx_break"/>Anna Bulanova  <br class="ltx_break"/>Anna Tacchetti  <br class="ltx_break"/>Anna Tacchetti  <br class="ltx_break"/>Anna Tsai  <br class="ltx_break"/>Anna Tacchetti  <br class="ltx_break"/>Anna Tacchetti  <br class="ltx_break"/>Anna Tacchetti  <br class="ltx_</p>
</div>
<div class="ltx_para ltx_noindent" id="S9.p3">
<p class="ltx_p" id="S9.p3.1"><span class="ltx_text ltx_font_bold" id="S9.p3.1.1">Product Management</span> <br class="ltx_break"/>Tris Warkentin  <br class="ltx_break"/>Ludovic Peran</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para ltx_noindent" id="S9.p4">
<p class="ltx_p" id="S9.p4.1"><span class="ltx_text ltx_font_bold" id="S9.p4.1.1">Program Management</span> <br class="ltx_break"/>Minh Giang</p>
</div>
<div class="ltx_para ltx_noindent" id="S9.p5">
<p class="ltx_p" id="S9.p5.1"><span class="ltx_text ltx_font_bold" id="S9.p5.1.1">Executive Sponsors</span> <br class="ltx_break"/>Clément Farabet  <br class="ltx_break"/>Oriol Vinyals  <br class="ltx_break"/>Jeff Dean  <br class="ltx_break"/>Koray Kavukcuoglu  <br class="ltx_break"/>Demis Hassabis  <br class="ltx_break"/>Zoubin Ghahramani  <br class="ltx_break"/>Douglas Eck  <br class="ltx_break"/>Joelle Barral  <br class="ltx_break"/>Fernando Pereira  <br class="ltx_break"/>Eli Collins</p>
</div>
<div class="ltx_para ltx_noindent" id="S9.p6">
<p class="ltx_p" id="S9.p6.1"><span class="ltx_text ltx_font_bold" id="S9.p6.1.1">Leads</span> <br class="ltx_break"/>Armand Joulin  <br class="ltx_break"/>Noah Fiedel  <br class="ltx_break"/>Evan Senter</p>
</div>
<div class="ltx_para ltx_noindent" id="S9.p7">
<p class="ltx_p" id="S9.p7.2"><span class="ltx_text ltx_font_bold" id="S9.p7.2.1">Tech Leads</span> <br class="ltx_break">Alek Andreev<math alttext="\dagger{}" class="ltx_Math" display="inline" id="S9.p7.1.m1.1"><semantics id="S9.p7.1.m1.1a"><mo id="S9.p7.1.m1.1.1" xref="S9.p7.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.p7.1.m1.1b"><ci id="S9.p7.1.m1.1.1.cmml" xref="S9.p7.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.p7.1.m1.1c">\dagger{}</annotation><annotation encoding="application/x-llamapun" id="S9.p7.1.m1.1d">†</annotation></semantics></math> <br class="ltx_break">Kathleen Kenealy<math alttext="\dagger{}" class="ltx_Math" display="inline" id="S9.p7.2.m2.1"><semantics id="S9.p7.2.m2.1a"><mo id="S9.p7.2.m2.1.1" xref="S9.p7.2.m2.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S9.p7.2.m2.1b"><ci id="S9.p7.2.m2.1.1.cmml" xref="S9.p7.2.m2.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S9.p7.2.m2.1c">\dagger{}</annotation><annotation encoding="application/x-llamapun" id="S9.p7.2.m2.1d">†</annotation></semantics></math> <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><math alttext="\dagger{}" class="ltx_Math" display="inline" id="footnote3.m1.1"><semantics id="footnote3.m1.1b"><mo id="footnote3.m1.1.1" xref="footnote3.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="footnote3.m1.1c"><ci id="footnote3.m1.1.1.cmml" xref="footnote3.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote3.m1.1d">\dagger{}</annotation><annotation encoding="application/x-llamapun" id="footnote3.m1.1e">†</annotation></semantics></math> equal contribution.</span></span></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S9.p8">
<p class="ltx_p" id="S9.p8.1"><span class="ltx_text ltx_font_bold" id="S9.p8.1.1">Acknowledgements</span> <br class="ltx_break"/>우리의 작업은 Google에서 수많은 팀의 헌신과 노력에 의해 가능해집니다. 제미니, 제미니 안전, 제미니 인프라, 제미니 평가, 구글 클라우드, 구글 리서치 책임 AI, 캐글, 케라스 등 팀의 지원을 인정하고자 합니다.</p>
</div>
<div class="ltx_para" id="S9.p9">
<p class="ltx_p" id="S9.p9.1">아드리안 허터, 안드레아스 테르지스, 안드레이 쿨릭, 안젤로스 필로스, 아누산 페르난도, 아우렐리엔 보피, 다닐라 시노팔니코프, 에두아르 레우랑, 가브리엘라 수리타, 제프리 시데론, 지린 첸, 카르티카 루랑, 케빈 로빈슨, 크리티카 무랄리다란, 르후, 레너드 베라다, 레프 프롤레예프, 루청 허, 마리 펠라트, 마크 셔우드, 맷 호프만, 마티아스 그룬드만, 니콜라 데 카오, 니콜라 모체프, 니노 비에야르, 노아 콘스탄트, 피터 류, 피오트르 스탠치크, 차오 장, 루바 하룬, 셀리엠 엘세드, 싯타르타 브라흐마, 톈허(케빈) 유, 톰 르 파인, 잉지에 마오, 원중 쉬, 유팅 선에게 특별한 감사와 인정을 보낸다.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib" lang="en">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Almazrouei et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
E.&nbsp;Almazrouei, H.&nbsp;Alobeidli, A.&nbsp;Alshamsi, A.&nbsp;Cappelli, R.&nbsp;Cojocaru, M.&nbsp;Debbah,
Étienne Goffinet, D.&nbsp;Hesslow, J.&nbsp;Launay, Q.&nbsp;Malartic, D.&nbsp;Mazzotta, B.&nbsp;Noune,
B.&nbsp;Pannier, and G.&nbsp;Penedo.

</span>
<span class="ltx_bibblock">The falcon series of open language models, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amodei et&nbsp;al. (2016)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
D.&nbsp;Amodei, C.&nbsp;Olah, J.&nbsp;Steinhardt, P.&nbsp;Christiano, J.&nbsp;Schulman, and D.&nbsp;Mané.

</span>
<span class="ltx_bibblock">Concrete problems in AI safety.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint</em>, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
R.&nbsp;Anil, A.&nbsp;M. Dai, O.&nbsp;Firat, M.&nbsp;Johnson, D.&nbsp;Lepikhin, A.&nbsp;Passos, S.&nbsp;Shakeri,
E.&nbsp;Taropa, P.&nbsp;Bailey, Z.&nbsp;Chen, et&nbsp;al.

</span>
<span class="ltx_bibblock">Palm 2 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2305.10403</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Austin et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;Austin, A.&nbsp;Odena, M.&nbsp;I. Nye, M.&nbsp;Bosma, H.&nbsp;Michalewski, D.&nbsp;Dohan, E.&nbsp;Jiang,
C.&nbsp;J. Cai, M.&nbsp;Terry, Q.&nbsp;V. Le, and C.&nbsp;Sutton.

</span>
<span class="ltx_bibblock">Program synthesis with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">CoRR</em>, abs/2108.07732, 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2108.07732" title="">https://arxiv.org/abs/2108.07732</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Y.&nbsp;Bai, S.&nbsp;Kadavath, S.&nbsp;Kundu, A.&nbsp;Askell, J.&nbsp;Kernion, A.&nbsp;Jones, A.&nbsp;Chen,
A.&nbsp;Goldie, A.&nbsp;Mirhoseini, C.&nbsp;McKinnon, C.&nbsp;Chen, C.&nbsp;Olsson, C.&nbsp;Olah,
D.&nbsp;Hernandez, D.&nbsp;Drain, D.&nbsp;Ganguli, D.&nbsp;Li, E.&nbsp;Tran-Johnson, E.&nbsp;Perez,
J.&nbsp;Kerr, J.&nbsp;Mueller, J.&nbsp;Ladish, J.&nbsp;Landau, K.&nbsp;Ndousse, K.&nbsp;Lukosuite,
L.&nbsp;Lovitt, M.&nbsp;Sellitto, N.&nbsp;Elhage, N.&nbsp;Schiefer, N.&nbsp;Mercado, N.&nbsp;DasSarma,
R.&nbsp;Lasenby, R.&nbsp;Larson, S.&nbsp;Ringer, S.&nbsp;Johnston, S.&nbsp;Kravec, S.&nbsp;E. Showk,
S.&nbsp;Fort, T.&nbsp;Lanham, T.&nbsp;Telleen-Lawton, T.&nbsp;Conerly, T.&nbsp;Henighan, T.&nbsp;Hume,
S.&nbsp;R. Bowman, Z.&nbsp;Hatfield-Dodds, B.&nbsp;Mann, D.&nbsp;Amodei, N.&nbsp;Joseph,
S.&nbsp;McCandlish, T.&nbsp;Brown, and J.&nbsp;Kaplan.

</span>
<span class="ltx_bibblock">Constitutional ai: Harmlessness from ai feedback, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barham et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
P.&nbsp;Barham, A.&nbsp;Chowdhery, J.&nbsp;Dean, S.&nbsp;Ghemawat, S.&nbsp;Hand, D.&nbsp;Hurt, M.&nbsp;Isard,
H.&nbsp;Lim, R.&nbsp;Pang, S.&nbsp;Roy, B.&nbsp;Saeta, P.&nbsp;Schuh, R.&nbsp;Sepassi, L.&nbsp;E. Shafey, C.&nbsp;A.
Thekkath, and Y.&nbsp;Wu.

</span>
<span class="ltx_bibblock">Pathways: Asynchronous distributed dataflow for ml, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bisk et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Y.&nbsp;Bisk, R.&nbsp;Zellers, R.&nbsp;L. Bras, J.&nbsp;Gao, and Y.&nbsp;Choi.

</span>
<span class="ltx_bibblock">PIQA: reasoning about physical commonsense in natural language.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">CoRR</em>, abs/1911.11641, 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1911.11641" title="">http://arxiv.org/abs/1911.11641</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bradley and Terry (1952)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
R.&nbsp;A. Bradley and M.&nbsp;E. Terry.

</span>
<span class="ltx_bibblock">Rank analysis of incomplete block designs: I. the method of paired
comparisons.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Biometrika</em>, 39, 1952.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
N.&nbsp;Carlini, D.&nbsp;Ippolito, M.&nbsp;Jagielski, K.&nbsp;Lee, F.&nbsp;Tramer, and C.&nbsp;Zhang.

</span>
<span class="ltx_bibblock">Quantifying memorization across neural language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2202.07646</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
M.&nbsp;Chen, J.&nbsp;Tworek, H.&nbsp;Jun, Q.&nbsp;Yuan, H.&nbsp;P. de&nbsp;Oliveira&nbsp;Pinto, J.&nbsp;Kaplan,
H.&nbsp;Edwards, Y.&nbsp;Burda, N.&nbsp;Joseph, G.&nbsp;Brockman, A.&nbsp;Ray, R.&nbsp;Puri, G.&nbsp;Krueger,
M.&nbsp;Petrov, H.&nbsp;Khlaaf, G.&nbsp;Sastry, P.&nbsp;Mishkin, B.&nbsp;Chan, S.&nbsp;Gray, N.&nbsp;Ryder,
M.&nbsp;Pavlov, A.&nbsp;Power, L.&nbsp;Kaiser, M.&nbsp;Bavarian, C.&nbsp;Winter, P.&nbsp;Tillet, F.&nbsp;P.
Such, D.&nbsp;Cummings, M.&nbsp;Plappert, F.&nbsp;Chantzis, E.&nbsp;Barnes, A.&nbsp;Herbert-Voss,
W.&nbsp;H. Guss, A.&nbsp;Nichol, A.&nbsp;Paino, N.&nbsp;Tezak, J.&nbsp;Tang, I.&nbsp;Babuschkin, S.&nbsp;Balaji,
S.&nbsp;Jain, W.&nbsp;Saunders, C.&nbsp;Hesse, A.&nbsp;N. Carr, J.&nbsp;Leike, J.&nbsp;Achiam, V.&nbsp;Misra,
E.&nbsp;Morikawa, A.&nbsp;Radford, M.&nbsp;Knight, M.&nbsp;Brundage, M.&nbsp;Murati, K.&nbsp;Mayer,
P.&nbsp;Welinder, B.&nbsp;McGrew, D.&nbsp;Amodei, S.&nbsp;McCandlish, I.&nbsp;Sutskever, and
W.&nbsp;Zaremba.

</span>
<span class="ltx_bibblock">Evaluating large language models trained on code.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">CoRR</em>, abs/2107.03374, 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2107.03374" title="">https://arxiv.org/abs/2107.03374</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Chowdhery, S.&nbsp;Narang, J.&nbsp;Devlin, M.&nbsp;Bosma, G.&nbsp;Mishra, A.&nbsp;Roberts, P.&nbsp;Barham,
H.&nbsp;W. Chung, C.&nbsp;Sutton, S.&nbsp;Gehrmann, P.&nbsp;Schuh, K.&nbsp;Shi, S.&nbsp;Tsvyashchenko,
J.&nbsp;Maynez, A.&nbsp;Rao, P.&nbsp;Barnes, Y.&nbsp;Tay, N.&nbsp;Shazeer, V.&nbsp;Prabhakaran, E.&nbsp;Reif,
N.&nbsp;Du, B.&nbsp;Hutchinson, R.&nbsp;Pope, J.&nbsp;Bradbury, J.&nbsp;Austin, M.&nbsp;Isard, G.&nbsp;Gur-Ari,
P.&nbsp;Yin, T.&nbsp;Duke, A.&nbsp;Levskaya, S.&nbsp;Ghemawat, S.&nbsp;Dev, H.&nbsp;Michalewski, X.&nbsp;Garcia,
V.&nbsp;Misra, K.&nbsp;Robinson, L.&nbsp;Fedus, D.&nbsp;Zhou, D.&nbsp;Ippolito, D.&nbsp;Luan, H.&nbsp;Lim,
B.&nbsp;Zoph, A.&nbsp;Spiridonov, R.&nbsp;Sepassi, D.&nbsp;Dohan, S.&nbsp;Agrawal, M.&nbsp;Omernick, A.&nbsp;M.
Dai, T.&nbsp;S. Pillai, M.&nbsp;Pellat, A.&nbsp;Lewkowycz, E.&nbsp;Moreira, R.&nbsp;Child, O.&nbsp;Polozov,
K.&nbsp;Lee, Z.&nbsp;Zhou, X.&nbsp;Wang, B.&nbsp;Saeta, M.&nbsp;Diaz, O.&nbsp;Firat, M.&nbsp;Catasta, J.&nbsp;Wei,
K.&nbsp;Meier-Hellstern, D.&nbsp;Eck, J.&nbsp;Dean, S.&nbsp;Petrov, and N.&nbsp;Fiedel.

</span>
<span class="ltx_bibblock">Palm: Scaling language modeling with pathways, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Christiano et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
P.&nbsp;F. Christiano, J.&nbsp;Leike, T.&nbsp;Brown, M.&nbsp;Martic, S.&nbsp;Legg, and D.&nbsp;Amodei.

</span>
<span class="ltx_bibblock">Deep reinforcement learning from human preferences.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Advances in Neural Information Processing Systems</em>, 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
C.&nbsp;Clark, K.&nbsp;Lee, M.&nbsp;Chang, T.&nbsp;Kwiatkowski, M.&nbsp;Collins, and K.&nbsp;Toutanova.

</span>
<span class="ltx_bibblock">Boolq: Exploring the surprising difficulty of natural yes/no
questions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">CoRR</em>, abs/1905.10044, 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1905.10044" title="">http://arxiv.org/abs/1905.10044</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
P.&nbsp;Clark, I.&nbsp;Cowhey, O.&nbsp;Etzioni, T.&nbsp;Khot, A.&nbsp;Sabharwal, C.&nbsp;Schoenick, and
O.&nbsp;Tafjord.

</span>
<span class="ltx_bibblock">Think you have solved question answering? try arc, the ai2 reasoning
challenge, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
K.&nbsp;Cobbe, V.&nbsp;Kosaraju, M.&nbsp;Bavarian, M.&nbsp;Chen, H.&nbsp;Jun, L.&nbsp;Kaiser, M.&nbsp;Plappert,
J.&nbsp;Tworek, J.&nbsp;Hilton, R.&nbsp;Nakano, C.&nbsp;Hesse, and J.&nbsp;Schulman.

</span>
<span class="ltx_bibblock">Training verifiers to solve math word problems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">CoRR</em>, abs/2110.14168, 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2110.14168" title="">https://arxiv.org/abs/2110.14168</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dean et&nbsp;al. (2012)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;Dean, G.&nbsp;Corrado, R.&nbsp;Monga, K.&nbsp;Chen, M.&nbsp;Devin, M.&nbsp;Mao, M.&nbsp;a. Ranzato,
A.&nbsp;Senior, P.&nbsp;Tucker, K.&nbsp;Yang, Q.&nbsp;Le, and A.&nbsp;Ng.

</span>
<span class="ltx_bibblock">Large scale distributed deep networks.

</span>
<span class="ltx_bibblock">In F.&nbsp;Pereira, C.&nbsp;Burges, L.&nbsp;Bottou, and K.&nbsp;Weinberger, editors,
<em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Advances in Neural Information Processing Systems</em>, volume&nbsp;25. Curran
Associates, Inc., 2012.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2012/file/6aca97005c68f1206823815f66102863-Paper.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2012/file/6aca97005c68f1206823815f66102863-Paper.pdf</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;Devlin, M.&nbsp;Chang, K.&nbsp;Lee, and K.&nbsp;Toutanova.

</span>
<span class="ltx_bibblock">BERT: pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">CoRR</em>, abs/1810.04805, 2018.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1810.04805" title="">http://arxiv.org/abs/1810.04805</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gemini Team (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Gemini Team.

</span>
<span class="ltx_bibblock">Gemini: A family of highly capable multimodal models, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
D.&nbsp;Hendrycks, C.&nbsp;Burns, S.&nbsp;Basart, A.&nbsp;Zou, M.&nbsp;Mazeika, D.&nbsp;Song, and
J.&nbsp;Steinhardt.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">CoRR</em>, abs/2009.03300, 2020.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2009.03300" title="">https://arxiv.org/abs/2009.03300</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
D.&nbsp;Hendrycks, C.&nbsp;Burns, S.&nbsp;Kadavath, A.&nbsp;Arora, S.&nbsp;Basart, E.&nbsp;Tang, D.&nbsp;Song, and
J.&nbsp;Steinhardt.

</span>
<span class="ltx_bibblock">Measuring mathematical problem solving with the math dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">NeurIPS</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ippolito et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
D.&nbsp;Ippolito, F.&nbsp;Tramèr, M.&nbsp;Nasr, C.&nbsp;Zhang, M.&nbsp;Jagielski, K.&nbsp;Lee, C.&nbsp;A.
Choquette-Choo, and N.&nbsp;Carlini.

</span>
<span class="ltx_bibblock">Preventing verbatim memorization in language models gives a false
sense of privacy.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2210.17546</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Q. Jiang, A.&nbsp;Sablayrolles, A.&nbsp;Mensch, C.&nbsp;Bamford, D.&nbsp;S. Chaplot, D.&nbsp;de&nbsp;las
Casas, F.&nbsp;Bressand, G.&nbsp;Lengyel, G.&nbsp;Lample, L.&nbsp;Saulnier, L.&nbsp;R. Lavaud, M.-A.
Lachaux, P.&nbsp;Stock, T.&nbsp;L. Scao, T.&nbsp;Lavril, T.&nbsp;Wang, T.&nbsp;Lacroix, and W.&nbsp;E.
Sayed.

</span>
<span class="ltx_bibblock">Mistral 7b, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
M.&nbsp;Joshi, E.&nbsp;Choi, D.&nbsp;S. Weld, and L.&nbsp;Zettlemoyer.

</span>
<span class="ltx_bibblock">Triviaqa: A large scale distantly supervised challenge dataset for
reading comprehension.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">CoRR</em>, abs/1705.03551, 2017.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1705.03551" title="">http://arxiv.org/abs/1705.03551</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kavukcuoglu et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
K.&nbsp;Kavukcuoglu, P.&nbsp;Kohli, L.&nbsp;Ibrahim, D.&nbsp;Bloxwich, and S.&nbsp;Brown.

</span>
<span class="ltx_bibblock">How our principles helped define alphafold’s release, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kudo and Richardson (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
T.&nbsp;Kudo and J.&nbsp;Richardson.

</span>
<span class="ltx_bibblock">SentencePiece: A simple and language independent subword
tokenizer and detokenizer for neural text processing.

</span>
<span class="ltx_bibblock">In E.&nbsp;Blanco and W.&nbsp;Lu, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 2018
Conference on Empirical Methods in Natural Language Processing: System
Demonstrations</em>, pages 66–71, Brussels, Belgium, Nov. 2018. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock"><a class="ltx_ref" href="https:/doi.org/10.18653/v1/D18-2012" title="">10.18653/v1/D18-2012</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/D18-2012" title="">https://aclanthology.org/D18-2012</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kudugunta et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
S.&nbsp;Kudugunta, I.&nbsp;Caswell, B.&nbsp;Zhang, X.&nbsp;Garcia, C.&nbsp;A. Choquette-Choo, K.&nbsp;Lee,
D.&nbsp;Xin, A.&nbsp;Kusupati, R.&nbsp;Stella, A.&nbsp;Bapna, et&nbsp;al.

</span>
<span class="ltx_bibblock">Madlad-400: A multilingual and document-level large audited dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2309.04662</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
T.&nbsp;Kwiatkowski, J.&nbsp;Palomaki, O.&nbsp;Redfield, M.&nbsp;Collins, A.&nbsp;Parikh, C.&nbsp;Alberti,
D.&nbsp;Epstein, I.&nbsp;Polosukhin, J.&nbsp;Devlin, K.&nbsp;Lee, K.&nbsp;Toutanova, L.&nbsp;Jones,
M.&nbsp;Kelcey, M.-W. Chang, A.&nbsp;M. Dai, J.&nbsp;Uszkoreit, Q.&nbsp;Le, and S.&nbsp;Petrov.

</span>
<span class="ltx_bibblock">Natural questions: A benchmark for question answering research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Transactions of the Association for Computational Linguistics</em>,
7:452–466, 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref" href="https:/doi.org/10.1162/tacl_a_00276" title="">10.1162/tacl_a_00276</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/Q19-1026" title="">https://aclanthology.org/Q19-1026</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun et&nbsp;al. (2015)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Y.&nbsp;LeCun, Y.&nbsp;Bengio, and G.&nbsp;Hinton.

</span>
<span class="ltx_bibblock">Deep learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">nature</em>, 521(7553):436–444, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mikolov et&nbsp;al. (2013)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
T.&nbsp;Mikolov, K.&nbsp;Chen, G.&nbsp;Corrado, and J.&nbsp;Dean.

</span>
<span class="ltx_bibblock">Efficient estimation of word representations in vector space.

</span>
<span class="ltx_bibblock">In Y.&nbsp;Bengio and Y.&nbsp;LeCun, editors, <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">1st International
Conference on Learning Representations, ICLR 2013, Scottsdale, Arizona,
USA, May 2-4, 2013, Workshop Track Proceedings</em>, 2013.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1301.3781" title="">http://arxiv.org/abs/1301.3781</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nasr et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
M.&nbsp;Nasr, N.&nbsp;Carlini, J.&nbsp;Hayase, M.&nbsp;Jagielski, A.&nbsp;F. Cooper, D.&nbsp;Ippolito, C.&nbsp;A.
Choquette-Choo, E.&nbsp;Wallace, F.&nbsp;Tramèr, and K.&nbsp;Lee.

</span>
<span class="ltx_bibblock">Scalable extraction of training data from (production) language
models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2311.17035</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
L.&nbsp;Ouyang, J.&nbsp;Wu, X.&nbsp;Jiang, D.&nbsp;Almeida, C.&nbsp;Wainwright, P.&nbsp;Mishkin, C.&nbsp;Zhang,
S.&nbsp;Agarwal, K.&nbsp;Slama, A.&nbsp;Ray, et&nbsp;al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Advances in Neural Information Processing Systems</em>, 35, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pacchiardi et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
L.&nbsp;Pacchiardi, A.&nbsp;J. Chan, S.&nbsp;Mindermann, I.&nbsp;Moscovitz, A.&nbsp;Y. Pan, Y.&nbsp;Gal,
O.&nbsp;Evans, and J.&nbsp;Brauner.

</span>
<span class="ltx_bibblock">How to catch an ai liar: Lie detection in black-box llms by asking
unrelated questions, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paperno et&nbsp;al. (2016)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
D.&nbsp;Paperno, G.&nbsp;Kruszewski, A.&nbsp;Lazaridou, Q.&nbsp;N. Pham, R.&nbsp;Bernardi, S.&nbsp;Pezzelle,
M.&nbsp;Baroni, G.&nbsp;Boleda, and R.&nbsp;Fernández.

</span>
<span class="ltx_bibblock">The LAMBADA dataset: Word prediction requiring a broad discourse
context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">CoRR</em>, abs/1606.06031, 2016.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1606.06031" title="">http://arxiv.org/abs/1606.06031</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
C.&nbsp;Raffel, N.&nbsp;Shazeer, A.&nbsp;Roberts, K.&nbsp;Lee, S.&nbsp;Narang, M.&nbsp;Matena, Y.&nbsp;Zhou,
W.&nbsp;Li, and P.&nbsp;J. Liu.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text
transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">CoRR</em>, abs/1910.10683, 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1910.10683" title="">http://arxiv.org/abs/1910.10683</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roberts et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Roberts, H.&nbsp;W. Chung, A.&nbsp;Levskaya, G.&nbsp;Mishra, J.&nbsp;Bradbury, D.&nbsp;Andor,
S.&nbsp;Narang, B.&nbsp;Lester, C.&nbsp;Gaffney, A.&nbsp;Mohiuddin, C.&nbsp;Hawthorne, A.&nbsp;Lewkowycz,
A.&nbsp;Salcianu, M.&nbsp;van Zee, J.&nbsp;Austin, S.&nbsp;Goodman, L.&nbsp;B. Soares, H.&nbsp;Hu,
S.&nbsp;Tsvyashchenko, A.&nbsp;Chowdhery, J.&nbsp;Bastings, J.&nbsp;Bulian, X.&nbsp;Garcia, J.&nbsp;Ni,
A.&nbsp;Chen, K.&nbsp;Kenealy, J.&nbsp;H. Clark, S.&nbsp;Lee, D.&nbsp;Garrette, J.&nbsp;Lee-Thorp,
C.&nbsp;Raffel, N.&nbsp;Shazeer, M.&nbsp;Ritter, M.&nbsp;Bosma, A.&nbsp;Passos, J.&nbsp;Maitin-Shepard,
N.&nbsp;Fiedel, M.&nbsp;Omernick, B.&nbsp;Saeta, R.&nbsp;Sepassi, A.&nbsp;Spiridonov, J.&nbsp;Newlan, and
A.&nbsp;Gesmundo.

</span>
<span class="ltx_bibblock">Scaling up models and data with <span class="ltx_text ltx_markedasmath ltx_font_typewriter" id="bib.bib35.3.1">t5x</span> and <span class="ltx_text ltx_markedasmath ltx_font_typewriter" id="bib.bib35.4.2">seqio</span>,
2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roberts et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Roberts, H.&nbsp;W. Chung, G.&nbsp;Mishra, A.&nbsp;Levskaya, J.&nbsp;Bradbury, D.&nbsp;Andor,
S.&nbsp;Narang, B.&nbsp;Lester, C.&nbsp;Gaffney, A.&nbsp;Mohiuddin, et&nbsp;al.

</span>
<span class="ltx_bibblock">Scaling up models and data with t5x and seqio.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Journal of Machine Learning Research</em>, 24(377):1–8, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sakaguchi et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
K.&nbsp;Sakaguchi, R.&nbsp;L. Bras, C.&nbsp;Bhagavatula, and Y.&nbsp;Choi.

</span>
<span class="ltx_bibblock">WINOGRANDE: an adversarial winograd schema challenge at scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">CoRR</em>, abs/1907.10641, 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1907.10641" title="">http://arxiv.org/abs/1907.10641</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sap et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
M.&nbsp;Sap, H.&nbsp;Rashkin, D.&nbsp;Chen, R.&nbsp;L. Bras, and Y.&nbsp;Choi.

</span>
<span class="ltx_bibblock">Socialiqa: Commonsense reasoning about social interactions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">CoRR</em>, abs/1904.09728, 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1904.09728" title="">http://arxiv.org/abs/1904.09728</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
N.&nbsp;Shazeer.

</span>
<span class="ltx_bibblock">Fast transformer decoding: One write-head is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">CoRR</em>, abs/1911.02150, 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1911.02150" title="">http://arxiv.org/abs/1911.02150</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
N.&nbsp;Shazeer.

</span>
<span class="ltx_bibblock">GLU variants improve transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">CoRR</em>, abs/2002.05202, 2020.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2002.05202" title="">https://arxiv.org/abs/2002.05202</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Skalse et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;M.&nbsp;V. Skalse, N.&nbsp;H.&nbsp;R. Howe, D.&nbsp;Krasheninnikov, and D.&nbsp;Krueger.

</span>
<span class="ltx_bibblock">Defining and characterizing reward gaming.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">NeurIPS</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;Su, Y.&nbsp;Lu, S.&nbsp;Pan, B.&nbsp;Wen, and Y.&nbsp;Liu.

</span>
<span class="ltx_bibblock">Roformer: Enhanced transformer with rotary position embedding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">CoRR</em>, abs/2104.09864, 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2104.09864" title="">https://arxiv.org/abs/2104.09864</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sutskever et&nbsp;al. (2014)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
I.&nbsp;Sutskever, O.&nbsp;Vinyals, and Q.&nbsp;V. Le.

</span>
<span class="ltx_bibblock">Sequence to sequence learning with neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">CoRR</em>, abs/1409.3215, 2014.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1409.3215" title="">http://arxiv.org/abs/1409.3215</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suzgun et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
M.&nbsp;Suzgun, N.&nbsp;Scales, N.&nbsp;Schärli, S.&nbsp;Gehrmann, Y.&nbsp;Tay, H.&nbsp;W. Chung,
A.&nbsp;Chowdhery, Q.&nbsp;V. Le, E.&nbsp;H. Chi, D.&nbsp;Zhou, and J.&nbsp;Wei.

</span>
<span class="ltx_bibblock">Challenging big-bench tasks and whether chain-of-thought can solve
them, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Talmor et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Talmor, J.&nbsp;Herzig, N.&nbsp;Lourie, and J.&nbsp;Berant.

</span>
<span class="ltx_bibblock">Commonsenseqa: A question answering challenge targeting commonsense
knowledge, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
H.&nbsp;Touvron, T.&nbsp;Lavril, G.&nbsp;Izacard, X.&nbsp;Martinet, M.-A. Lachaux, T.&nbsp;Lacroix,
B.&nbsp;Rozière, N.&nbsp;Goyal, E.&nbsp;Hambro, F.&nbsp;Azhar, A.&nbsp;Rodriguez, A.&nbsp;Joulin,
E.&nbsp;Grave, and G.&nbsp;Lample.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models,
2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
H.&nbsp;Touvron, L.&nbsp;Martin, K.&nbsp;Stone, P.&nbsp;Albert, A.&nbsp;Almahairi, Y.&nbsp;Babaei,
N.&nbsp;Bashlykov, S.&nbsp;Batra, P.&nbsp;Bhargava, S.&nbsp;Bhosale, D.&nbsp;Bikel, L.&nbsp;Blecher, C.&nbsp;C.
Ferrer, M.&nbsp;Chen, G.&nbsp;Cucurull, D.&nbsp;Esiobu, J.&nbsp;Fernandes, J.&nbsp;Fu, W.&nbsp;Fu,
B.&nbsp;Fuller, C.&nbsp;Gao, V.&nbsp;Goswami, N.&nbsp;Goyal, A.&nbsp;Hartshorn, S.&nbsp;Hosseini, R.&nbsp;Hou,
H.&nbsp;Inan, M.&nbsp;Kardas, V.&nbsp;Kerkez, M.&nbsp;Khabsa, I.&nbsp;Kloumann, A.&nbsp;Korenev, P.&nbsp;S.
Koura, M.-A. Lachaux, T.&nbsp;Lavril, J.&nbsp;Lee, D.&nbsp;Liskovich, Y.&nbsp;Lu, Y.&nbsp;Mao,
X.&nbsp;Martinet, T.&nbsp;Mihaylov, P.&nbsp;Mishra, I.&nbsp;Molybog, Y.&nbsp;Nie, A.&nbsp;Poulton,
J.&nbsp;Reizenstein, R.&nbsp;Rungta, K.&nbsp;Saladi, A.&nbsp;Schelten, R.&nbsp;Silva, E.&nbsp;M. Smith,
R.&nbsp;Subramanian, X.&nbsp;E. Tan, B.&nbsp;Tang, R.&nbsp;Taylor, A.&nbsp;Williams, J.&nbsp;X. Kuan,
P.&nbsp;Xu, Z.&nbsp;Yan, I.&nbsp;Zarov, Y.&nbsp;Zhang, A.&nbsp;Fan, M.&nbsp;Kambadur, S.&nbsp;Narang,
A.&nbsp;Rodriguez, R.&nbsp;Stojnic, S.&nbsp;Edunov, and T.&nbsp;Scialom.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models,
2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Vaswani, N.&nbsp;Shazeer, N.&nbsp;Parmar, J.&nbsp;Uszkoreit, L.&nbsp;Jones, A.&nbsp;N. Gomez,
L.&nbsp;Kaiser, and I.&nbsp;Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">CoRR</em>, abs/1706.03762, 2017.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1706.03762" title="">http://arxiv.org/abs/1706.03762</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
J.&nbsp;Wei, X.&nbsp;Wang, D.&nbsp;Schuurmans, M.&nbsp;Bosma, E.&nbsp;H. Chi, Q.&nbsp;Le, and D.&nbsp;Zhou.

</span>
<span class="ltx_bibblock">Chain of thought prompting elicits reasoning in large language
models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">CoRR</em>, abs/2201.11903, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2201.11903" title="">https://arxiv.org/abs/2201.11903</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weidinger et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
L.&nbsp;Weidinger, J.&nbsp;Mellor, M.&nbsp;Rauh, C.&nbsp;Griffin, J.&nbsp;Uesato, P.&nbsp;Huang, M.&nbsp;Cheng,
M.&nbsp;Glaese, B.&nbsp;Balle, A.&nbsp;Kasirzadeh, Z.&nbsp;Kenton, S.&nbsp;Brown, W.&nbsp;Hawkins,
T.&nbsp;Stepleton, C.&nbsp;Biles, A.&nbsp;Birhane, J.&nbsp;Haas, L.&nbsp;Rimell, L.&nbsp;A. Hendricks,
W.&nbsp;Isaac, S.&nbsp;Legassick, G.&nbsp;Irving, and I.&nbsp;Gabriel.

</span>
<span class="ltx_bibblock">Ethical and social risks of harm from language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">CoRR</em>, abs/2112.04359, 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2112.04359" title="">https://arxiv.org/abs/2112.04359</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Williams (1992)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
R.&nbsp;J. Williams.

</span>
<span class="ltx_bibblock">Simple statistical gradient-following algorithms for connectionist
reinforcement learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Machine learning</em>, 8, 1992.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">XLA (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
XLA.

</span>
<span class="ltx_bibblock">Xla: Optimizing compiler for tensorflow, 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.tensorflow.org/xla" title="">https://www.tensorflow.org/xla</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Y.&nbsp;Xu, H.&nbsp;Lee, D.&nbsp;Chen, B.&nbsp;A. Hechtman, Y.&nbsp;Huang, R.&nbsp;Joshi, M.&nbsp;Krikun,
D.&nbsp;Lepikhin, A.&nbsp;Ly, M.&nbsp;Maggioni, R.&nbsp;Pang, N.&nbsp;Shazeer, S.&nbsp;Wang, T.&nbsp;Wang,
Y.&nbsp;Wu, and Z.&nbsp;Chen.

</span>
<span class="ltx_bibblock">GSPMD: general and scalable parallelization for ML computation
graphs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">CoRR</em>, abs/2105.04663, 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2105.04663" title="">https://arxiv.org/abs/2105.04663</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Sennrich (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
B.&nbsp;Zhang and R.&nbsp;Sennrich.

</span>
<span class="ltx_bibblock">Root mean square layer normalization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">CoRR</em>, abs/1910.07467, 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1910.07467" title="">http://arxiv.org/abs/1910.07467</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
L.&nbsp;Zheng, W.-L. Chiang, Y.&nbsp;Sheng, S.&nbsp;Zhuang, Z.&nbsp;Wu, Y.&nbsp;Zhuang, Z.&nbsp;Lin, Z.&nbsp;Li,
D.&nbsp;Li, E.&nbsp;P. Xing, H.&nbsp;Zhang, J.&nbsp;E. Gonzalez, and I.&nbsp;Stoica.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
W.&nbsp;Zhong, R.&nbsp;Cui, Y.&nbsp;Guo, Y.&nbsp;Liang, S.&nbsp;Lu, Y.&nbsp;Wang, A.&nbsp;Saied, W.&nbsp;Chen, and
N.&nbsp;Duan.

</span>
<span class="ltx_bibblock">Agieval: A human-centric benchmark for evaluating foundation models,
2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
A.&nbsp;Zou, L.&nbsp;Phan, S.&nbsp;Chen, J.&nbsp;Campbell, P.&nbsp;Guo, R.&nbsp;Ren, A.&nbsp;Pan, X.&nbsp;Yin,
M.&nbsp;Mazeika, A.-K. Dombrowski, S.&nbsp;Goel, N.&nbsp;Li, M.&nbsp;J. Byun, Z.&nbsp;Wang, A.&nbsp;Mallen,
S.&nbsp;Basart, S.&nbsp;Koyejo, D.&nbsp;Song, M.&nbsp;Fredrikson, J.&nbsp;Z. Kolter, and D.&nbsp;Hendrycks.

</span>
<span class="ltx_bibblock">Representation engineering: A top-down approach to ai transparency,
2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>

</div>


<div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated on Wed Dec 14 18:01:44 2022 by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button></body></html>