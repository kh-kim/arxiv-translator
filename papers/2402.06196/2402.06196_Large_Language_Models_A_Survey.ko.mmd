# Large Language Models: Survey

셔빈 미나에, 토마스 미콜로프, 나르제스 니자드, 마이삼 체나글루

리차드 소셰, 자비에 아마트리아인 지안펑 가오

###### Abstract

대용량 언어 모델은 2022년 11월 ChatGPT를 발표한 이후 광범위한 자연어 태스크에서 강력한 성능을 보여 많은 주목을 받고 있다. LLM의 범용 언어 이해 및 생성 능력은 법칙을 확장하여 예측한 바와 같이 방대한 양의 텍스트 데이터에 대해 수십억 개의 모델의 매개변수를 훈련함으로써 획득된다[1, 2]. LLM의 연구 영역은 매우 최근이지만 다양한 방식으로 빠르게 발전하고 있다. 본 논문에서는 3개의 인기 있는 LLM 패밀리(GPT, LLaMA, PaLM)를 포함하여 가장 두드러진 LLM 중 일부를 검토하고 특성, 기여 및 한계에 대해 논의한다. 또한 LLM을 구축하고 확장하기 위해 개발된 기술에 대한 개요를 제공합니다. 그런 다음 LLM 훈련, 미세 조정 및 평가를 위해 준비된 인기 데이터 세트를 조사하고 널리 사용되는 LLM 평가 메트릭을 검토하고 대표적인 벤치마크 세트에 대한 여러 인기 LLM의 성능을 비교한다. 마지막으로, 열린 도전과제와 향후 연구 방향에 대해 논의함으로써 논문을 마무리한다.

## I Introduction

언어 모델링은 1950년대 섀넌이 정보 이론을 인간 언어에 적용한 것으로 거슬러 올라가는 오랜 연구 주제이며, 여기서 그는 간단한 n-그램 언어 모델이 자연 언어 텍스트를 얼마나 잘 예측하거나 압축하는지 측정했다[3]. 이후 통계적 언어 모델링은 음성 인식, 기계 번역에서 정보 검색에 이르기까지 많은 자연 언어 이해와 생성 작업에 기본이 되었다[4, 5, 6].

최근 웹 스케일의 텍스트 코퍼라에서 사전 학습된 트랜스포머 기반 대용량 언어 모델(LLM)의 발전은 언어 모델(LLM)의 기능을 크게 확장시켰다. 예를 들어 OpenAI의 ChatGPT 및 GPT-4는 자연어 처리뿐만 아니라 Microsoft의 Co-Pilot 시스템에 전원을 공급하기 위한 일반적인 작업 해결기로 사용될 수 있으며, 예를 들어 필요한 경우 다단계 추론을 수행하는 복잡한 새로운 작업의 인간 명령을 따를 수 있다. 따라서 LLM은 범용 AI 에이전트 또는 인공지능(AGI) 개발을 위한 기본 구성 요소가 되고 있다.

LLM 분야가 빠르게 발전하고 있으며 새로운 발견, 모델 및 기술이 몇 달 또는 몇 주 안에 발표되고 있다[7, 8, 9, 10, 11]. AI 연구자와 실무자는 종종 작업에 대한 LLM 기반 AI 시스템을 구축하기 위한 최상의 레시피를 파악하는 데 어려움을 겪는다. 이 논문은 LLMs에 대한 최근의 진보에 대한 시기적절한 조사를 제공한다. 이 조사가 학생, 연구원 및 개발자에게 가치 있고 접근 가능한 자원이 될 수 있기를 바랍니다.

LLM은 신경망을 기반으로 하는 대규모의 사전 훈련된 통계적 언어 모델이다. 최근 LLM의 성공은 수십 년의 언어 모델 연구 및 개발의 누적이며, 이는 통계 언어 모델, 신경 언어 모델, 사전 훈련 언어 모델 및 LLM의 시작점과 속도가 다른 4가지 파동으로 분류할 수 있다.

통계 언어 모델(SLM)은 텍스트를 단어의 시퀀스로 보고, 텍스트의 확률을 단어 확률의 곱으로 추정한다. SLM의 지배적인 형태는 n-gram 모델로 알려진 마르코프 연쇄 모델이며, 이는 단어의 즉시 진행 \(n-1\) 단어에 대한 조건화된 단어의 확률을 계산한다. 단어 확률은 텍스트 말뭉치로부터 수집된 단어 및 n-그램 카운트를 사용하여 추정되기 때문에, 모델은 _평활화_ 를 사용하여 데이터 희소성(즉, 보이지 않는 단어 또는 n-그램에 0 확률을 할당함)을 처리할 필요가 있으며, 여기서 모델의 일부 확률 질량은 보이지 않는 n-그램에 대해 예약된다[12]. N-gram 모델은 많은 NLP 시스템에서 널리 사용된다. 그러나 이러한 모델은 데이터 희소성으로 인해 자연어의 다양성과 가변성을 완전히 포착할 수 없다는 점에서 불완전하다.

초기 신경망 모델(NLMs)[13, 14, 15, 16]은 저차원 연속 벡터(임베딩 벡터)에 단어를 매핑하여 데이터 희소성을 다루고 신경망을 사용하여 진행 단어의 임베딩 벡터의 집계에 기초하여 다음 단어를 예측한다. NLM에 의해 학습된 임베딩 벡터는 벡터들 사이의 의미적 유사성이 그들의 거리로 쉽게 계산될 수 있는 숨겨진 공간을 정의한다. 이것은 그들의 형태들(예를 들어, 쿼리들 대 쿼리들)에 관계없이 임의의 두 입력들의 시맨틱 유사성 컴퓨팅의 문을 연다. 웹 검색에서의 문서들[17, 18], 기계 번역에서의 상이한 언어들의 문장들[19, 20]) 또는 모달리티들(예를 들어, 이미지 캡션에서의 이미지 및 텍스트[21, 22])이다. 초기 NLM은 태스크별 데이터로 학습되고 학습된 숨겨진 공간이 태스크별이라는 점에서 태스크별 모델이다.

사전 훈련된 언어 모델(PLM)은 초기 NLM과 달리 작업 불가지론적이다. 이러한 일반성은 학습된 은닉 임베딩 공간으로도 확장된다. PLM의 훈련 및 추론은 _사전 훈련 및 미세 조정_ 패러다임을 따르며, 여기서 순환 신경망[23] 또는 변압기[24, 25, 26]가 있는 언어 모델은 단어 예측과 같은 일반적인 작업에 대해 웹 규모 라벨이 없는 텍스트 코퍼스에서 사전 훈련된 다음 소량의 (라벨이 붙은) 작업 특정 데이터를 사용하여 특정 작업에 미세 조정된다. PLM에 대한 최근의 조사는 [8, 27, 28]을 포함한다.

대형 언어 모델(LLM)은 주로 표 III에 요약된 바와 같이 PaLM[31], LLaMA[32], GPT-4[33]과 같은 방대한 텍스트 데이터에 대해 사전 훈련된 수백억 내지 수천억 개의 파라미터를 포함하는 변압기 기반 신경망 언어 모델 1을 지칭한다. PLM에 비해 LLM은 모델 크기가 훨씬 클 뿐만 아니라 더 강력한 언어 이해 및 생성 능력, 더 중요한 것은 소규모 언어 모델에는 없는 창발 능력을 나타낸다. 도면에 도시된 바와 같이, 1, 이러한 창발 능력은 (1) 상황 내 학습, 여기서 LLMs는 추론 시간에 프롬프트에 제시된 작은 예제 세트로부터 새로운 과제를 학습하고, (2) 명령 후속, 여기서 LLMs는 명령 튜닝 후에 명시적인 예를 사용하지 않고 새로운 유형의 작업에 대한 명령을 따를 수 있고, (3) 다단계 추론은 LLMs가 생각 연쇄 프롬프트에서 입증된 바와 같이 그 과제를 중간 추론 단계로 분해함으로써 복잡한 과제를 해결할 수 있다[34]. LLM은 또한 외부 지식 및 도구[35, 36]를 사용하여 증강될 수 있어 사용자 및 환경[37]과 효과적으로 상호 작용할 수 있고, 상호 작용을 통해 수집된 피드백 데이터를 사용하여(예를 들어, 인간 피드백(RLHF)과의 강화 학습을 통해) 지속적으로 자신을 개선할 수 있다.

고급 사용 및 증강 기술을 통해 LLM은 환경을 감지하고 결정을 내리고 조치를 취하는 인공 개체라는 소위 AI 에이전트로 배포될 수 있다. 이전 연구에서는 특정 작업 및 도메인에 대한 에이전트 개발에 중점을 두었다. LLM에 의해 입증된 새로운 능력은 LLM을 기반으로 하는 범용 AI 에이전트를 구축할 수 있게 한다. LLM은 정적 설정에서 응답을 생성하도록 훈련되지만 AI 에이전트는 동적 환경과 상호 작용하기 위한 조치를 취해야 한다. 따라서, LLM 기반 에이전트는 외부 지식 베이스로부터 업데이트된 정보를 얻고, 시스템 액션이 예상된 결과를 생성하는지 검증하고, 상황이 예상대로 진행되지 않을 때 대처하는 등 LLM을 보강해야 하는 경우가 많다. 섹션 IV에서 LLM 기반 에이전트에 대해 자세히 논의할 것이다.

이 논문의 나머지 부분에서 섹션 II는 3개의 LLM 패밀리(GPT, LLaMA 및 PaLM) 및 기타 대표적인 모델을 중심으로 LLM 기술의 개요를 제시한다. 섹션 III에서는 LLM이 어떻게 구축되는지 논의한다. 섹션 IV에서는 LLM이 사용되는 방법에 대해 논의하고 실제 응용 프로그램에 대해 확장 섹션 V 및 VI에서는 LLM을 평가하기 위한 인기 있는 데이터 세트 및 벤치마크를 검토하고 보고된 LLM 평가 결과를 요약한다. 마지막으로 제7절은 과제 및 향후 연구 방향을 요약하여 논문을 마무리한다.

## II 대용량 언어 모델

이 섹션에서는 초기 사전 훈련된 신경망 모델이 LLM의 기반이기 때문에 검토부터 시작한 다음 GPT, LlaMA 및 PaLM의 세 가지 LLM 계열에 대한 논의를 집중한다. 표 I은 이러한 모델 중 일부와 그 특성에 대한 개요를 제공한다.

### _조기 사전 훈련된 신경망 모델_

신경망을 이용한 언어 모델링은 [38, 39, 40]에 의해 개척되었다. Bengio et al. [13]은 n-gram 모델에 필적하는 최초의 신경망 모델들(NLMs) 중 하나를 개발했다. 그런 다음 [14]는 NLM을 기계 번역에 성공적으로 적용했다. 미콜로프[41, 42]에 의한 RNNLM(오픈 소스 NLM 툴킷)의 출시는 NLM을 상당히 대중화하는 데 도움이 되었다. 그 후, 순환 신경망(RNN)에 기초한 NLM들 및 그 변형들, 예를 들어, LSTM(Long Short-term Memory) [19] 및 GRU(Gated Recurrent Unit) [20]은 기계 번역, 텍스트 생성 및 텍스트 분류[43]를 포함하는 많은 자연 언어 애플리케이션에 널리 사용되었다.

그런 다음, 트랜스포머 아키텍처의 발명[44]은 NLM 개발의 또 다른 이정표를 표시한다. 문장이나 문서의 모든 단어에 대해 자기 주의를 병렬적으로 계산하기 위해 "주의 점수"를 적용하여 각 단어가 다른 단어에 미치는 영향을 모델링함으로써, 트랜스포머는 RNN보다 훨씬 더 많은 병렬화를 허용하며, 이는 GPU의 대용량 데이터에 대해 매우 큰 언어 모델을 효율적으로 사전 훈련시키는 것을 가능하게 한다. 이러한 사전 훈련된 언어 모델(PLM)은 많은 다운스트림 작업에 대해 미세 조정될 수 있다.

도. 1: LLM Capabilities.

초기 인기 있는 트랜스포머 기반 PLM을 신경망 구조를 기반으로 인코더 전용, 디코더 전용 및 인코더-디코더 모델의 세 가지 주요 범주로 그룹화한다. 초기 PLM에 대한 포괄적인 조사는 [43, 28]에서 제공된다.

#### Iii-A1 Encoder-only PLMs

이름에서 알 수 있듯이 인코더 전용 모델은 인코더 네트워크로만 구성됩니다. 이러한 모델은 원래 텍스트 분류와 같은 언어 이해 작업을 위해 개발되었으며, 여기서 모델은 입력 텍스트에 대한 클래스 레이블을 예측해야 한다. 대표적인 인코더 전용 모델은 아래에서 설명하는 바와 같이 BERT 및 그 변형, 예를 들어 RoBERTa, ALBERT, DeBERTa, XLM, XLNet, UNILM을 포함한다.

BERT(Birectional Encoder Representations from Transformers) [24]는 가장 널리 사용되는 인코더 전용 언어 모델 중 하나이다. BERT는 (1) 입력 텍스트를 임베딩 벡터의 시퀀스로 변환하는 임베딩 모듈, (2) 임베딩 벡터를 문맥적 표현 벡터로 변환하는 트랜스포머 인코더 스택, (3) 표현 벡터를 (최종 계층에서) 원-핫 벡터로 변환하는 완전 연결 계층으로 구성된다. BERT는 마스킹 언어 모델링(Masked Language Modeling, MMLM)과 다음 문장 예측의 두 가지 목적을 사용하여 사전 훈련된다. 사전 학습된 BERT 모델은 텍스트부터 시작해서 많은 언어 이해 작업을 위한 분류기 계층을 추가함으로써 미세 조정될 수 있다.

도. 2: 종이 구조물.

분류, 언어 추론에 대한 질의 응답. BERT 프레임워크의 높은 수준의 개요는 그림 3에 나와 있다. BERT가 출판되었을 때 광범위한 언어 이해 작업에 대한 최신 기술을 크게 향상시켰기 때문에 AI 커뮤니티는 BERT를 기반으로 하는 많은 유사한 인코더 전용 언어 모델을 개발하도록 영감을 받았다.

RoBERTa[25]는 몇 개의 주요 하이퍼파라미터를 수정하고, 다음 문장 사전 훈련 목적을 제거하고 훨씬 더 큰 미니 배치 및 학습률을 갖는 훈련과 같은 일련의 모델 설계 선택 및 훈련 전략을 사용하여 BERT의 견고성을 상당히 개선한다. ALBERT [45]는 메모리 소비를 낮추고 BERT의 트레이닝 속도를 높이기 위해 두 가지 파라미터 감소 기법을 사용한다: (1) 임베딩 행렬을 두 개의 더 작은 행렬로 분할하고, (2) 그룹들 사이에서 분할된 반복 계층을 사용한다. DeBERTa (Decoding-enhanced BERT with disentangled attention) [26]은 두 가지 새로운 기법을 사용하여 BERT 및 RoBERTa 모델을 개선한다. 첫 번째는 분리 어텐션 메커니즘으로, 각 단어는 각각 내용과 위치를 인코딩하는 두 개의 벡터를 사용하여 표현되며 단어 간의 어텐션 가중치이다.

\begin{table}
\begin{tabular}{p{56.9pt} p{56.9pt} p{56.9pt} p{56.9pt} p{56.9pt} p{56.9pt} p{56.9pt} p{56.9pt}} \hline \hline
**Type** & **Model Name** & **\#Parameters** & **Relase** & **Base Models** & **Open Source** & **\#Tokens** & **Training dataset** \\ \hline \multirow{6}{*}{**Encoder-Only**} & BERT & 110M, 340M & 2018 & - & ✓ & 137B & BooksCorpus, English Wikipedia \\  & RoBERTa & 355M & 2019 & - & ✓ & 2.2T & BooksCorpus, English Wikipedia, CC-NEWS, STORIES (a subset of Common Crawl), Reddit BooksCorpus, English Wikipedia \\  & ALBERT & 12M, 18M, 235M & 60M, 2019 & - & ✓ & 137B & BooksCorpus, English Wikipedia \\  & DeBERTa & - & 2020 & - & ✓ & - & BooksCorpus, English Wikipedia, STORIES, Reddit content \\  & XLNet & 110M, 340M & 2019 & - & ✓ & 32.89B & BooksCorpus, English Wikipedia, Gig5, Common Crawl, Chewe 2012-B \\ \hline \multirow{2}{*}{**Decoder-only**} & GPT-1 & 120M & 2018 & - & ✓ & 1.3B & BooksCorpus \\  & GPT-2 & 1.5B & 2019 & - & ✓ & 10B & Reddit outbound \\ \cline{2-7}  & T5 (Base) & 223M & 2019 & - & ✓ & 156B & Common Crawl \\  & MTS (Base) & 300M & 2020 & - & ✓ & - & New Common Crawl-based dataset in 101 languages (m Common Crawl) & \\  & BART (Base) & 139M & 2019 & - & ✓ & - & Computing text \\ \hline \multirow{6}{*}{**GPT Family**} & GPT-3 & 125M, 350M, 760M, 1, 13B, 2.7B, 6.7B, 6.7B, 13B, 175B & & & & & \\  & CODEX & 12B & 2021 & GPT & ✓ & - & Public GitHub software repositories \\  & WebGPT & 760M, 13B, 175B & 2021 & GPT-3 & \(\times\) & - & ELI5 \\  & GPT-4 & 1.767 & 2023 & - & \(\times\) & 13T & - \\ \hline \multirow{6}{*}{**LLAMA Family**} & LLMA1 & 78, 13B, 33B, 65B & 2023 & - & ✓ & 1T, 1.4T & Online sources \\  & LLMA2 & 78, 13B, 34B, 70B & 2023 & - & ✓ & 2T & Online sources \\  & Alpaca & 7B & 2023 & LLMA1 & ✓ & - & GPT-3 \\  & Vienna-13B & 13B & 2023 & LLMA1 & ✓ & - & GPT-3 \\  & Koula & 13B & 2023 & LLMA & ✓ & - & Dialogue data \\  & Mixtal-7B & 7.3B & 2023 & & ✓ & - & - \\  & Code Lima & 34 & 2023 & LLMA2 & ✓ & 500B & Publicly available code \\  & LongLLAMA & 3B, 7B & 2023 & OpenLLAMA & ✓ & 1T & - \\  & LLMA-Pro-8B & 8.3B & 2024 & LLMA-7B & ✓ & 80B & Code and math corpora \\  & TinyLlama-1.1B & 1.1B & 2024 & LLMA1.1B & ✓ & 3T & Simnjajtana, Staverderdata \\ \hline \multirow{6}{*}{**PaLM Family**} & PatLM & 8B, 62B, 540B & 2022 & - & \(\times\) & 780B & Web documents, books, Wikipedia, conversations, GitHub code \\  & U-PalM & 8B, 62B, 540B & 2022 & - & \(\times\) & 1.3B & Web documents, books, Wikipedia, conversations, GitHub code \\  & PuLM-2 & 340B & 2023 & - & ✓ & 3.6T & Web documents, books, code, mathematics, conversational data \\  & Med-PulM & 540B & 2022 & PuLM & \(\times\) & 780B & HealthSearchQA, MedicationQA, LiveQA \\  & Med-PulM 2 & - & 2023 & PuLM 2 & \(\times\) & - & ModQA, MedMCQA, HealthSearchQA, LiveQA \\  & MedicationQA & & & & & MedicationQA \\ \hline \multirow{6}{*}{**Other Popular LLA**} & PLAN & 137B & 2021 & LaMDA-PT & ✓ & - & Web documents, code, dialog data, Wikipedia \\  & Gober & 280B & 2021 & - & \(\times\) & 300B & MassiveText \\  & ERNE 4.0 & 10B & 2023 & - & \(\times\) & 4TB & Chinese text \\  & Retro & 7.5B & 2021 & - & \(\times\) & 600B & MassiveText \\  & LMDA & 137B & 2022 & - & \(\times\) & 168B & public dialog data and web documents \\  & ChinChilla & 70B & 2022 & - & \(\times\) & 1.4T & MassiveText \\  & Glacitci-120B & 120B & 2022 & - & \(\times\) & 450B & \\  & CodGen & 16.1B & 2022 & - & ✓ & - & THE PLE, BIGQUERY, BIGPYTHON \\  & BLOOM & 176B & 2022 & - & ✓ & 366B & ROOTS \\  & Zaghyr & 7.2Bk & 2023 & Mistral-7B & ✓ & 800B & Synthetic data \\  & Grok-0 & 33B & 2023 & - & \(\times\) & - & Online source \\  & ORCA-2 & 13B & 2023 & LLMA2 & - & 200B & - \\  & StartColor & 15.5B & 2023 & - & ✓ & 35B & GitHub \\  & MPT & 7B & 2023 & - & ✓ & 1T & RedPajama, m Common Crawl, S2ORC, Common Crawl \\  & Mixxtal-8x7B & 46.7B & 2023 & - & ✓ & - & Instruction dataset \\  & Falcon 180B & 180B & 2023 & - & ✓ & 3.5T & RefinedWeb \\  & Gemini & 1.8B, 3.25B & 2023 & - & ✓ & - & Web documents, books, and code, image data, audio data, video data \\  & DeepSee-Coder & 1.3B, 6.7B, 33B & 2024 & - & ✓ & 2T & GitHub’s Markdown and StackExchange \\  & DocLLM & 1B,7B & 2024 & - & \(\times\) & 2T & IIT-CDIP Test Collection 1.0, DocBank \\ \hline \hline \end{tabular}
\end{table} TABLE I: High-level Overview of Popular Language Modelsare computed using disentangled matrices on their contents and relative positions, respectively. Second, an enhanced mask decoder is used to incorporate absolute positions in the decoding layer to predict the masked tokens in model pre-training. In addition, a novel virtual adversarial training method is used for fine-tuning to improve models' generalization. ELECTRA [46] uses a new pre-training task, known as replaced token detection (RTD), which is empirically proven to be more sample-efficient than MLM. Instead of masking the input, RTD corrupts it by replacing some tokens with plausible alternatives sampled from a small generator network. Then, instead of training a model that predicts the original identities of the corrupted tokens, a discriminative model is trained to predict whether a token in the corrupted input was replaced by a generated sample or not. RTD is more sample-efficient than MLM because the former is defined over all input tokens rather than just the small subset being masked out, as illustrated in Fig 4.

XLM[47]은 두 가지 방법을 사용하여 BERT를 교차 언어 모델로 확장했다: (1) 단일 언어 데이터에만 의존하는 비감독 방법과 (2) 그림 5에 도시된 바와 같이 새로운 교차 언어 모델 목표로 병렬 데이터를 활용하는 감독 방법. XLM은 제안 당시 교차 언어 분류, 비감독 및 감독 기계 번역에 대한 최신 결과를 얻었다.

모델 학습 및 추론을 위해 자동 회귀(디코더) 모델의 장점을 활용하는 인코더 전용 언어 모델도 있다. 두 가지 예는 XLNet과 UNILM이다. XLNet[48]은 트랜스포머-XL을 기반으로 하며, 인수분해 차수의 모든 순열들에 걸쳐 예상 우도를 최대화함으로써 양방향 컨텍스트들을 학습할 수 있게 하는 일반화된 자기회귀 방법을 사용하여 사전 트레이닝된다. UNILM(UNIfied pre-trained Language Model) [49]는 단방향, 양방향 및 시퀀스 간 예측의 세 가지 유형의 언어 모델링 작업을 사용하여 사전 훈련된다. 이것은 그림 6에 예시된 바와 같이, 공유 트랜스포머 네트워크를 채용하고 예측이 어떤 컨텍스트에서 컨디셔닝되는지를 제어하기 위해 특정 셀프-어텐션 마스크들을 활용함으로써 달성된다. 사전-트레이닝된 모델은 자연 언어 이해 및 생성 태스크들 모두에 대해 미세-튜닝될 수 있다.

#### Iii-C2 디코더 전용 PLM

가장 널리 사용되는 디코더 전용 PLM 중 두 개는 OpenAI에서 개발한 GPT-1과 GPT-2이다. 이러한 모델은 이후에 GPT-3 및 GPT-4와 같은 보다 강력한 LLM에 기반을 마련한다.

GPT-1 [50]은 자율 지도 학습 방식(즉, 다음 단어/토큰 조건)에서 레이블이 지정되지 않은 텍스트의 다양한 코퍼스 상의 디코더 전용 트랜스포머 모델의 GPT(Generative Pre-Training)에 의해 광범위한 자연 언어 작업에 대한 우수한 성능을 얻을 수 있다는 것을 처음으로 입증한다.

도. 4: 교체된 토큰 검출과 마스킹된 언어 모델링 간의 비교. [46]의 예절.

도. 5: 언어 간 언어 모델 사전 훈련. MLM 목표는 BERT와 유사하지만 문장 쌍과 대조적으로 텍스트의 연속 스트림이 있다. TLM 목표는 MLM을 병렬 문장 쌍으로 확장한다. 마스크된 영어 단어를 예측하기 위해, 모델은 영어 문장과 그것의 프랑스어 번역 모두에 참석할 수 있고, 영어와 프랑스어 표현을 정렬하도록 권장된다. [47]의 예절.

도. 3: BERT에 대한 전체 사전 훈련 및 미세 조정 절차. [24]의 예절.

도. 6: 통합 LM 사전 훈련 개요. 모델 매개변수는 LM 목표(즉, 양방향 LM, 단방향 LM 및 시퀀스 대 시퀀스 LM)에 걸쳐 공유된다. [49]의 예절.

도 7에 예시된 바와 같이, 각 특정 다운스트림 태스크(훨씬 적은 샘플로)에 대한 차별적인 미세 조정이 뒤따르며, GPT-1은 후속 GPT 모델에 대한 길을 열어주며, 각 버전은 아키텍처를 개선하고 다양한 언어 태스크에서 더 나은 성능을 달성한다.

GPT-2 [51]은 언어 모델들이 수백만 개의 웹페이지들로 구성된 대규모 웹텍스트 데이터세트 상에서 트레이닝될 때 명시적인 감독 없이 특정 자연 언어 태스크들을 수행하는 것을 학습할 수 있다는 것을 보여준다. GPT-2 모델은 몇 가지 수정으로 GPT-1의 모델 설계를 따른다: 계층 정규화는 각 서브-블록의 입력으로 이동되고, 추가 계층 정규화는 최종 셀프-어텐션 블록 이후에 추가되며, 초기화는 잔여 경로 상의 축적을 고려하도록 수정되고 잔여 계층들의 가중치들을 스케일링하고, 어휘 크기는 50,25로 확장되며, 컨텍스트 크기는 512에서 1024 토큰으로 증가된다.

#### Iv-A3 Encoder-Decoder PLMs

[52]에서, Raffle 등은 거의 모든 NLP 태스크들이 시퀀스-투-시퀀스 생성 태스크로서 캐스팅될 수 있음을 보여준다. 따라서, 인코더-디코더 언어 모델은, 설계에 의해, 모든 자연 언어 이해 및 생성 태스크들을 수행할 수 있다는 점에서 통일된 모델이다. 아래에서 검토할 대표적인 인코더-디코더 PLM은 T5, mT5, MASS 및 BART이다.

T5[52]는 T5(Text-to-Text Transfer Transformer) 모델로서, 모든 NLP 태스크들이 텍스트-to-텍스트 생성 태스크로서 캐스팅되는 통일된 프레임워크의 도입을 통해 전이 학습이 NLP에 대해 효과적으로 활용된다. mT5[53]는 101개 언어의 텍스트로 구성된 새로운 Common Crawl 기반 데이터 세트에서 사전 훈련된 T5의 다국어 변형이다.

MASS(MASked Sequence to Sequence pre-training) [54]는 인코더-디코더 프레임워크를 채택하여 문장의 나머지 부분이 주어지면 문장 조각을 재구성한다. 인코더는 랜덤하게 마스킹된 단편(몇 개의 연속적인 토큰들)을 입력으로 하는 문장을 취하고, 디코더는 마스킹된 단편을 예측한다. 이러한 방식으로, MASS는 언어 임베딩 및 생성을 위해 인코더 및 디코더를 각각 공동으로 트레이닝한다.

BART[55]는 표준 시퀀스 대 시퀀스 변환 모델 아키텍처를 사용한다. 임의의 노이즈링 기능으로 텍스트를 손상시킨 후 원문을 재구성하는 학습을 하여 사전 학습한다.

### _Large Language Model Families_

대형 언어 모델(LLM)은 주로 수백억에서 수천억 개의 파라미터를 포함하는 변압기 기반 PLM을 말한다. 위에서 검토한 PLM에 비해 LLM은 모델 크기가 훨씬 클 뿐만 아니라 소규모 모델에는 없는 더 강력한 언어 이해 및 생성 및 창발 능력을 나타낸다. 다음에서 그림 8과 같이 GPT, LLaMA 및 PaLM의 세 가지 LLM 계열을 검토한다.

#### Iv-B1 **The GPT Family**

GPT(Generative Pre-trained Transformers)는 OpenAI에서 개발한 디코더 전용 트랜스포머 기반 언어 모델 계열이다. 이 패밀리는 GPT-1, GPT-2, GPT-3, InstrucGPT, ChatGPT, GPT-4, CODEX 및 WebGPT로 구성된다. GPT-1 및 GPT-2와 같은 초기 GPT 모델은 오픈 소스이지만 GPT-3 및 GPT-4와 같은 최근 모델은 근접 소스이며 API를 통해만 액세스할 수 있다. GPT-1 및 GPT-2 모델은 초기 PLM 하위 섹션에서 논의되었다. 아래 GPT-3부터 시작합니다.

GPT-3 [56]은 1,750억 개의 파라미터를 갖는 사전 훈련된 자기 회귀 언어 모델이다. GPT-3는 이전 PLM보다 훨씬 클 뿐만 아니라 이전에 더 작은 PLM에서 관찰되지 않은 새로운 능력을 처음으로 보여준다는 점에서 첫 번째 LLM으로 널리 간주된다. GPT-3은 컨텍스트 내 학습의 창발 능력을 보여주며, 이는 GPT-3이 그래프 업데이트 또는 미세 조정 없이 모든 다운스트림 태스크에 적용될 수 있음을 의미하며, 태스크 및 소수의 샷 데모는 순전히 모델과의 텍스트 상호 작용을 통해 지정된다. GPT-3는 번역, 질의 응답 및 클로즈 작업을 포함한 많은 NLP 작업과 문장의 새로운 단어인 3자리 산술을 사용하여 스크램블링 해제와 같이 즉석 추론 또는 도메인 적응이 필요한 여러 작업에서 강력한 성능을 달성했다. 그림 9는 문맥 내 프롬프트에서 예제 수의 함수로 GPT-3의 성능을 보여준다.

오픈AI가 2023년 3월 출시한 코덱스[57]는 자연어를 파싱하고 이에 대응하여 코드를 생성할 수 있는 범용 프로그래밍 모델이다. CODEX는 GitHub에서 수집된 코드 코퍼스의 프로그래밍 애플리케이션을 위해 미세 조정된 GPT-3의 후손이다. CODEX는 Microsoft의 GitHub Copilot에 권한을 부여합니다.

WebGPT[58]는 GPT-3의 또 다른 후손으로서, 텍스트 기반 웹 브라우저를 사용하여 개방형 질문에 답하도록 미세 조정되어, 사용자가 웹을 검색하고 탐색하는 것을 용이하게 한다. 구체적으로, WebGPT는 세 단계로 훈련된다. 첫 번째는 WebGPT가 인간의 시연 데이터를 사용하여 인간의 브라우징 행동을 모방하는 방법을 배우는 것이다. 그런 다음 보상 함수를 학습하여 인간의 선호도를 예측합니다. 마지막으로, 강화 학습과 거부 샘플링을 통해 보상 함수를 최적화하기 위해 WebGPT를 정제한다.

LLM들이 예상된 인간 명령들을 따를 수 있게 하기 위해, InstructGPT [59]는 인간 피드백과의 미세 조정에 의해 광범위한 태스크들에 대한 사용자 의도와 언어 모델들을 정렬하기 위해 제안된다. OpenAI API를 통해 제출된 라벨러 작성 프롬프트 및 프롬프트 집합으로 시작하여 원하는 모델 동작의 라벨러 시연 데이터 세트가 수집된다. 그런 다음 GPT-3는 이 데이터 세트에서 미세 조정됩니다. 그런 다음, 강화 학습을 사용하여 모델을 추가로 미세 조정하기 위해 인간 순위 모델 출력의 데이터 세트를 수집한다. 이 방법은 인간 피드백으로부터 강화 학습으로 알려져 있다.

도. 7: GPT 사전 훈련 및 미세 조정 단계의 상위 레벨 개요. 오픈AI의 공손함

10에 나타난 바와 같이, InstructGPT 모델은 공개 NLP 데이터 세트에서 최소한의 성능 회귀를 가지면서도 진실성 및 독성 출력 생성의 감소를 보여주었다.

LLM 개발의 가장 중요한 이정표는 2022년 11월 30일 ChatGPT(Chat Generative Pre-trained Transformer)[60]의 출시이다. ChatGPT는 사용자가 대화를 조종하여 질의 응답, 정보 탐색, 텍스트 요약 등과 같은 광범위한 작업을 완료할 수 있도록 하는 챗봇이다. ChatGPT는 InstructGPT에 대한 형제 모델인 GPT-3.5(그리고 나중에 GPT-4에 의해 구동되며, 이는 프롬프트에서 명령을 따르고 상세한 응답을 제공하도록 훈련된다.

GPT-4 [33]은 GPT 계열에서 가장 최신적이고 강력한 LLM이다. 2023년 3월에 출범한 GPT-4는 이미지와 텍스트를 입력으로 하고 텍스트 출력을 낼 수 있다는 점에서 멀티모달 LLM이다. GPT-4는 여전히 가장 어려운 실제 시나리오에서 인간보다 능력이 낮지만, 그림 11과 같이 시험 응시자의 상위 10% 정도의 점수로 모의 변호사 시험에 합격하는 등 다양한 전문 및 학술 벤치마크에서 인간 수준의 성능을 보인다. 초기 GPT 모델과 마찬가지로 GPT-4는 먼저 대규모 텍스트 말뭉치에서 다음 토큰을 예측하도록 사전 훈련된 다음 RLHF로 미세 조정되어 모델 행동을 인간이 원하는 것과 정렬했다.

#### V-A2 **The LLaMA Family**

LLaMA는 메타에서 출시한 기초 언어 모델 모음이다. GPT 모델과 달리 LLaMA 모델은 오픈 소스이며, 즉 모델 가중치는 비상업 라이선스에 따라 연구 커뮤니티에 공개된다. 따라서 LLaMA 계열은 많은 연구 그룹에서 폐쇄 소스 LLM과 경쟁하거나 임무 중요 응용을 위한 작업 특정 LLM을 개발하기 위해 더 나은 오픈 소스 LLM을 개발하기 위해 널리 사용됨에 따라 빠르게 성장한다.

첫 번째 LLaMA 모델 세트 [32]는 7B에서 65B 매개변수에 이르기까지 2023년 2월에 출시되었다. 이러한 모델은 공개적으로 사용 가능한 데이터 세트에서 수집된 수조 개의 토큰에 대해 사전 훈련됩니다. LLaMA는 GPT-3의 트랜스포머 구조를 사용하며, (1) ReLU 대신 SwiGLU 활성화 함수를 사용하고, (2) 절대 위치 임베딩 대신 회전 위치 임베딩을 사용하고, (3) 표준 계층 정규화 대신 평균 제곱근 계층 정규화를 사용하는 등 몇 가지 사소한 아키텍처 수정을 포함한다. 오픈 소스 LLaMA-13B 모델은 대부분의 벤치마크에서 독점 GPT-3(175B) 모델을 능가하여 LLM 연구에 좋은 기준선이 된다.

도. 10: RLHF의 상위 레벨 개요. [59]의 예절.

도. 도 9: GPT-3은 더 큰 모델들이 상황 내 정보의 점점 더 효율적인 사용을 만든다는 것을 보여준다. 자연어 과제 설명이 있는 경우와 없는 경우 모두 모델에서 단어에서 무작위 기호를 제거해야 하는 간단한 과제에 대한 맥락 내 학습 성능을 보여준다. [56]의 예절.

도. 8 : 인기 LLM 가족.

2023년 7월, 메타는 마이크로소프트와 제휴하여 LLaMA-2 컬렉션[61]을 출시했는데, 이 컬렉션은 LLaMA-2 Chat으로 알려진 다이얼로그를 위해 미세 조정된 기본 언어 모델과 Chat 모델을 모두 포함한다. LLaMA-2 채팅 모델은 많은 공개 벤치마크에서 다른 오픈 소스 모델을 능가하는 것으로 보고되었다. 그림 12는 LLaMA-2 Chat의 훈련 과정을 보여준다. 이 프로세스는 공개적으로 사용 가능한 온라인 데이터를 사용하여 LLaMA-2를 사전 훈련하는 것으로 시작한다. 그런 다음 감독 미세 조정을 통해 LLaMA-2 채팅의 초기 버전을 구축한다. 그 후, 모델은 RLHF, 거부 샘플링 및 근위 정책 최적화를 사용하여 반복적으로 정제된다. RLHF 단계에서 보상 모델을 수정하기 위한 인간 피드백의 축적은 보상 모델이 너무 많이 변경되지 않도록 하는 데 중요하며, 이는 LLaMA 모델 훈련의 안정성을 해칠 수 있다.

알파카[62]는 GPT-3.5(text-davinci-003)를 사용하여 자체 명령 방식으로 생성된 52K 명령 후속 데모를 사용하여 LLaMA-7B 모델에서 미세 조정된다. 알파카는 훈련, 특히 학술 연구에 매우 비용 효율적입니다. 자가 지시 평가 세트에서 알파카는 알파카가 훨씬 작음에도 불구하고 GPT-3.5와 유사하게 수행한다.

비쿠나 팀은 쉐어GPT에서 수집한 사용자 공유 대화에서 LLaMA를 미세 조정해 13B 채팅 모델인 비쿠나-13B를 개발했다. GPT-4를 평가자로 사용한 예비평가 결과, Vicuna-13B는 OpenAI의 ChatGPT와 구글의 Bard의 품질이 90% 이상을 달성하면서 LLaMA, Stanford Alpaca와 같은 다른 모델보다 90% 이상 우수한 것으로 나타났다. 도 13은 GPT-4에 의한 Vicuna 및 몇몇 다른 잘 알려진 모델들의 상대적인 응답 품질을 도시한다. Vicuna-13B의 또 다른 이점은 모델 트레이닝에 대한 상대적인 제한된 계산 수요이다. 비쿠나-13B의 훈련 비용은 단지 300달러이다.

알파카 및 비쿠나와 마찬가지로 구아나코 모델[63]도 명령어 후속 데이터를 사용하여 미세 조정된 LLaMA 모델이다. 그러나 단일 48GB GPU에서 65B 파라미터 모델을 미세 조정할 수 있도록 QLoRA를 사용하여 미세 조정을 매우 효율적으로 수행한다. QLoRA는 동결된 4비트 양자화된 사전 훈련 언어 모델을 통해 기울기를 LoRA(Low Rank Adapters)로 역전파한다. 최상의 Guanaco 모델은 Vicuna 벤치마크에서 이전에 출시된 모든 모델을 능가하여 ChatGPT의 성능 수준의 99.3%에 도달했으며 단일 GPU에서 24시간의 미세 조정만 요구합니다.

코알라[64]는 LLaMA에 구축된 또 다른 명령어 후속 언어 모델이지만, ChatGPT와 같은 고도로 유능한 폐쇄 소스 채팅 모델에 의해 생성된 응답 및 사용자 입력을 포함하는 상호작용 데이터에 특정 초점을 맞춘다. 코알라-13B 모델은 실제 사용자 프롬프트에 기초한 인간 평가에 따라 최첨단 채팅 모델과 경쟁적으로 수행한다.

Mistral-7B[65]는 우수한 성능과 효율성을 위해 설계된 7B-파라미터 언어 모델이다. Mistral-7B는 평가된 모든 벤치마크에서 최고의 오픈 소스 13B 모델(LLaMA-2-13B)과 추론, 수학 및 코드 생성에서 최고의 오픈 소스 34B 모델(LLaMA-34B)을 능가한다. 이 모델은 더 빠른 추론을 위해 그룹화된 쿼리 어텐션을 활용하고, 슬라이딩 윈도우 어텐션과 결합하여 추론 비용이 감소된 임의의 길이의 시퀀스를 효과적으로 처리한다.

LLaMA 계열은 코드 LLaMA[66], 고릴라[67], 기린[68], 비고뉴[69], 툴루 65B[70], 롱 LLaMA[71], 안정 벨루가2[72]를 포함하여 LLaMA 또는 LLaMA-2에 더 많은 명령어 후속 모델이 구축됨에 따라 빠르게 성장하고 있다.

#### V-B3 **The PaLM Family**

PaLM(Pathways Language Model) 패밀리는 구글에서 개발한다. 첫 번째 PaLM 모델[31]은 2022년 4월에 발표되었고 2023년 3월까지 비공개로 유지되었다. 540B 파라미터 변압기 기반 LLM이다. 이 모델은 광범위한 자연어 작업과 사용 사례로 구성된 7,800억 개의 토큰으로 구성된 고품질 텍스트 코퍼스에 대해 사전 훈련된다. PaLM은 사전 훈련된

도. 11: GPT 3.5와 비교하여, 학업 및 전문 시험에 대한 GPT-4 성능. [33]의 예의.

도. 12: LLaMA-2 채팅의 트레이닝. [61]의 예절.

도. 13: Vicuna의 상대 반응 품질 및 GPT-4에 의해 몇몇 다른 잘 알려진 모델들. Vicuna 팀의 예의.

6144개의 TPU v4 칩에서 패스웨이 시스템을 사용하여 여러 TPU 포드에 걸쳐 매우 효율적인 훈련을 수행할 수 있습니다. PaLM은 수백 개의 언어 이해 및 생성 벤치마크에 대한 최첨단 소샷 학습 결과를 달성함으로써 스케일링의 지속적인 이점을 보여준다. PaLM-540B는 여러 단계의 추론 작업 세트에서 최첨단 미세 조정 모델뿐만 아니라 최근에 출시된 BIG 벤치마크에서 인간과 동등하다.

8B, 62B 및 540B 스케일의 U-PaLM 모델은 UL2R을 사용하여 PaLM에서 지속적으로 훈련되며, UL2의 데노아저 혼합 목표[73]를 사용하여 몇 단계로 LLM을 계속 훈련하는 방법이다. 약 2배 계산 절감율이 보고된다.

U-PaLM은 나중에 Flan-PaLM[74]으로 지시-미세조정된다. 위에서 언급한 다른 명령어 미세 조정 작업에 비해 Flan-PaLM의 미세 조정은 훨씬 더 많은 수의 작업, 더 큰 모델 크기 및 연쇄 사상 데이터를 사용하여 수행된다. 그 결과, Flan-PaLM은 기존의 명령어 추종 모델보다 훨씬 우수한 성능을 보였다. 예를 들어, 1.8K 태스크에서 명령어-파인튜닝된 Flan-PaLM-540B는 PaLM-540B를 큰 마진(평균 +9.4%)만큼 능가한다. 미세 조정 데이터는 그림 14와 같이 473개의 데이터 세트, 146개의 작업 범주 및 1,836개의 총 작업으로 구성된다.

PaLM-2 [75]는 이전의 PaLM에 비해 더 나은 다국어 및 추론 기능을 가진 더 계산 효율적인 LLM이다. PaLM-2는 목표의 혼합을 사용하여 훈련된다. PaLM-2는 영어, 다국어 및 추론 작업에 대한 광범위한 평가를 통해 다양한 모델 크기에 걸쳐 다운스트림 작업에 대한 모델 성능을 크게 향상시키는 동시에 PaLM보다 빠르고 효율적인 추론을 나타낸다.

Med-PaLM[76]은 도메인별 PaLM이며 의료 질문에 대한 고품질 답변을 제공하도록 설계되었다. Med-PaLM은 몇 가지 예를 사용하여 LLM을 새로운 도메인에 정렬하기 위한 매개변수 효율적인 방법인 명령 프롬프트 튜닝을 사용하여 PaLM에서 미세 조정된다. Med-PaLM은 많은 의료 업무에 대해 매우 고무적인 결과를 얻지만 여전히 인간 임상의에 비해 열등하다. Med-PaLM 2는 Med 도메인 미세 조정 및 앙상블 프롬프트를 통해 Med-PaLM을 개선한다[77]. Med-PaLM 2는 MedQA 데이터 세트(즉, 전문 의료 시험, 연구 및 소비자 질의에 걸쳐 있는 6개의 기존 개방형 질문 응답 데이터 세트를 결합한 벤치마크)에서 최대 86.5%의 점수를 얻었고 Med-PaLM을 19% 이상 개선하고 새로운 최첨단 설정을 했다.

### _Other Representative LLMs_

이전 하위 섹션에서 논의된 모델 외에도 세 모델 패밀리에 속하지 않는 인기 있는 LLM이 있지만 큰 성과를 거두었고 LLM 필드를 앞으로 밀어붙였다. 우리는 이 하위 섹션에서 이러한 LLM을 간략하게 설명한다.

**FLAN:** [78]에서 Wei 등은 언어 모델의 제로샷 학습 능력을 향상시키기 위한 간단한 방법을 탐구했습니다. 그들은 명령어들을 통해 기술된 데이터 세트들의 컬렉션 상의 명령어 튜닝 언어 모델들이 보이지 않는 태스크들에 대한 제로 샷 성능을 실질적으로 향상시킨다는 것을 보여주었다. 그들은 137B 매개변수 사전 훈련된 언어 모델을 취하고 자연어 명령어 템플릿을 통해 구두화된 60개 이상의 NLP 데이터 세트에서 이를 조정한다. 그들은 이것을 명령어 조정 모델 FLAN이라고 부른다. 그림 15는 사전 훈련-미세 조정 및 프롬프트와 명령어 튜닝을 비교한 것이다.

**고퍼:** [79]에서 Rae 등은 수천만 개의 매개 변수를 가진 모델부터 고퍼라는 2,800억 개의 매개 변수 모델까지 광범위한 모델 규모에 걸쳐 트랜스포머 기반 언어 모델 성능의 분석을 제시했다. 이 모델은 152개의 다양한 작업에 대해 평가되어 대다수에 걸쳐 최첨단 성능을 달성했다. 레이어의 수, 키/값 크기 및 다른 모델 크기의 기타 하이퍼 매개 변수는 그림 16에 나와 있다.

**T0:** [80]에서 Sanh 등은 자연어 작업을 사람이 읽을 수 있는 프롬프트 형태로 쉽게 매핑할 수 있는 시스템인 T0을 개발했다. 그들은 다양한 문구를 가진 여러 프롬프트가 있는 감독된 데이터 세트의 큰 세트를 변환했다.

도. 14: Flan-PaLM 미세 조정은 위의 작업 범주에서 473개의 데이터 세트로 구성된다. [74]의 예절.

도. 15: 사전 훈련-미세 조정 및 프롬프트와의 명령어 튜닝 비교. [78]의 예절.

이러한 프롬프트된 데이터 세트를 사용하면 모델이 완전히 보류된 작업을 수행하는 능력을 벤치마킹할 수 있습니다. 그런 다음 텍스트 입력을 소비하고 목표 응답을 생성하기 위해 T0 인코더-디코더 모델이 개발된다. 모델은 서로 다른 태스크로 분할된 NLP 데이터 세트의 멀티태스크 혼합물에 대해 트레이닝된다.

**ERNIE 3.0:** [81]에서 Sun 등은 대규모 지식 향상 모델을 사전 훈련하기 위해 ERNIE 3.0이라는 통일된 프레임워크를 제안했다. 자동 회귀 네트워크와 자동 인코딩 네트워크를 융합하여 학습된 모델이 제로 샷 학습, 적은 샷 학습 또는 미세 조정을 사용하여 자연어 이해 및 생성 작업 모두에 쉽게 맞춤화될 수 있도록 한다. 그들은 일반 텍스트와 대규모 지식 그래프로 구성된 4TB 코퍼스에서 100억 개의 매개변수로 ERNIE 3.0을 훈련했다. 그림 17은 어니 3.0의 모델 아키텍처를 보여준다.

**RETRO:** [82]에서 Borgeaud 등은 이전 토큰과의 로컬 유사성을 기반으로 대규모 말뭉치에서 검색된 문서 청크를 컨디셔닝하여 자동 회귀 언어 모델을 향상시켰습니다. 2조 개의 토큰 데이터베이스를 사용하여 검색 강화 트랜스포머(Retro)는 25% 적은 매개변수를 사용함에도 불구하고 파일에서 GPT-3 및 쥬라기-1 [83]과 유사한 성능을 얻는다. 도 18에 도시된 바와 같이, Retro는 동결된 Bert 리트리버, 미분가능한 인코더 및 청크화된 교차-어텐션 메커니즘을 결합하여 트레이닝 동안 통상적으로 소비되는 것보다 더 많은 데이터 크기에 기초하여 토큰들을 예측한다.

**GLaM:** [84]에서 Du 등은 GLaM(일반 언어 모델)이라는 LLM의 패밀리를 제안했는데, GLaM(일반 언어 모델)은 모델 용량을 확장하기 위해 희박하게 활성화된 전문가 혼합 아키텍처를 사용하면서 조밀한 변형에 비해 실질적으로 적은 훈련 비용을 발생시킨다. 가장 큰 GLaM은 1.2조 개의 매개변수를 가지며, 이는 GPT-3보다 약 7배 크다. GPT-3을 훈련하는 데 사용되는 에너지의 1/3만 소비하고 추론을 위해 계산 플롭의 절반을 요구하지만 29개의 NLP 작업에서 여전히 더 나은 전체 제로, 1 및 소수의 샷 성능을 달성한다. 그림 19는 GLAM의 고급 아키텍처를 보여준다.

**LaMDA:** [85]에서 Thoppilan 등은 최대 137B 매개 변수를 가지고 공용 대화 데이터 및 웹 텍스트의 1.56T 단어에 대해 사전 훈련된 대화 상자에 특화된 트랜스포머 기반 신경망 언어 모델 계열인 LaMDA를 제시했다. 그들은 주석이 달린 데이터로 미세 조정하고 모델이 외부 지식 소스와 상담할 수 있도록 하는 것이 안전과 사실적 근거의 두 가지 주요 문제를 크게 개선할 수 있음을 보여주었다.

**OPT:** [86]에서 Zhang 등은 연구자와 공유하는 125M에서 175B 매개 변수 범위의 디코더 전용 사전 훈련 변압기 제품군인 OPT(Open Pre-trained Transformers)를 제시했다. OPT 모델의 매개변수는 20에 표시된다.

도. 19: GLaM 모델 아키텍처. 각각의 MoE 층(하부 블록)은 트랜스포머 층(상부 블록)과 인터리빙된다. [84]의 예절.

도. 20: 상이한 OPT 모델들의 아키텍처 세부사항. [86]의 예절.

도. 17: ERNIE 3.0의 하이레벨 모델 아키텍처. [81]의 예의.

**친칠라:** [2]에서 Hoffmann 등은 주어진 컴퓨팅 예산 하에서 변압기 언어 모델을 훈련하기 위한 최적의 모델 크기 및 토큰 수를 조사했다. 5,000억에서 5,000억 토큰에 대해 7,000만에서 160억 이상의 매개변수에 이르는 400개 이상의 언어 모델을 훈련함으로써, 그들은 컴퓨팅-최적 훈련을 위해 모델 크기와 훈련 토큰의 수가 동등하게 스케일링되어야 한다는 것을 발견했다: 모델 크기의 두 배가 될 때마다 훈련 토큰의 수 또한 두 배가 되어야 한다. 그들은 고퍼와 동일한 컴퓨팅 예산을 사용하지만 70B 매개변수와 4% 더 많은 데이터를 사용하는 예측된 컴퓨팅 최적 모델인 친칠라를 훈련하여 이 가설을 테스트했다.

**Galactica:** [87]에서 Taylor 등은 과학적 지식을 저장하고 결합하고 추론할 수 있는 대규모 언어 모델인 Galactica를 소개했습니다. 그들은 논문, 참고 자료, 지식 기반 및 기타 많은 출처의 대규모 과학 코퍼스에 대해 훈련했다. 갈락티카는 추론에서 잘 수행되어 수학적 MMLU에서 친칠라를 41.3%에서 35.7%, MATH에서 PaLM 540B를 20.4% 대 8.8%로 능가했다.

**CodeGen:** [88]에서 Nijkamp 등은 자연어 및 프로그래밍 언어 데이터에 CODEGEN이라고 하는 최대 16.1B 매개 변수 패밀리를 학습하고 릴리스했으며 교육 라이브러리 JAXFORMER를 오픈 소싱했습니다. 그들은 휴먼에벌의 제로샷 파이썬 코드 생성에서 이전의 최첨단 기술과 경쟁력이 있음을 입증함으로써 훈련된 모델의 유용성을 보여주었다. 그들은 또한 단일 프로그램이 하위 문제를 지정하는 여러 프롬프트로 인수분해되는 프로그램 합성을 위한 다단계 패러다임을 조사했다. 또한 115개의 다양한 문제 집합으로 구성된 개방형 벤치마크인 멀티턴 프로그래밍 벤치마크(Multi-Turn Programming Benchmark, MTPB)를 구성하여 멀티턴 프롬프트로 인수분해하였다.

**AlexaTM:** [89]에서 Soltan 등은 디노이징과 인과 언어 모델링(CLM) 작업의 혼합물에서 사전 훈련된 다국어 대규모 시퀀스 투 시퀀스(seq2seq) 모델이 다양한 작업에서 디코더 전용 모델보다 더 효율적인 소수의 샷 학습자임을 입증했다. 그들은 Alexa Teacher 모델(AlexaTM 20B)이라고 불리는 200억 개의 파라미터 다국어 seq2seq 모델을 훈련시켰고, 1-샷 요약 태스크에서 SOTA(최첨단) 성능을 달성하여 훨씬 더 큰 540B PaLM 디코더 모델을 능가함을 보여주었다. AlexaTM은 인코더 층 46개, 디코더 층 32개, 어텐션 헤드 32개, \(d_{model}=4096\)로 구성된다.

**참새:** [90]에서 Glaese 등은 프롬프트 언어 모델 기준선에 비해 더 유용하고 정확하며 무해하도록 훈련된 정보 추구 대화 에이전트인 Sparrow를 제시했습니다. 그들은 인간 피드백으로부터 강화 학습을 사용하여 인간 평가자가 에이전트 행동을 판단하는 데 도움이 되는 두 가지 새로운 추가와 함께 모델을 훈련시켰다. 스패로우 모델의 상위 파이프라인은 그림 21에 나와 있다.

**Minerva:** [91]에서 Lewkowycz 등은 일반적인 자연어 데이터에 대해 사전 훈련되고 기술 내용에 대해 추가로 훈련된 대규모 언어 모델인 Minerva를 도입하여 이전의 LLM 문제를 정량적 추론(예: 수학, 과학 및 공학 문제 해결)으로 해결했습니다.

**MoD:** [92]에서 Tay 등은 NLP에서 자기 감독에 대한 일반화되고 통일된 관점을 제시하고 서로 다른 사전 훈련 목표가 서로 캐스팅될 수 있는 방법과 서로 다른 목표 간의 보간이 어떻게 효과적일 수 있는지 보여준다. 그들은 다양한 사전 훈련 패러다임을 함께 결합하는 사전 훈련 목표인 데노이저 혼합(Mixture-of-Denoisers, MoD)을 제안했다. 이 프레임워크는 언어 학습 통합(UL2)으로 알려져 있다. UL2 사전 훈련 패러다임의 개요는 그림 21에 나와 있다.

**BLOOM:** [93]에서 Scao 등은 수백 명의 연구자의 협업 덕분에 설계 및 구축된 176B 매개 변수 개방형 액세스 언어 모델인 BLOOM을 제시했다. BLOOM은 ROOTS 코퍼스에서 훈련된 디코더 전용 트랜스포머 언어 모델로서, 46개의 자연 언어 및 13개의 프로그래밍 언어(총 59개)로 수백 개의 소스를 포함하는 데이터세트이다. BLOOM 아키텍처의 개요는 그림 23에 나와 있다.

**GLM:** [94]에서 Zeng 등은 GLM-130B, a

도. 21: 참새 파이프라인은 훈련 세트를 지속적으로 확장하기 위해 인간의 참여에 의존한다. [90]의 예절.

도. 22: UL2 프리트레이닝 패러다임의 개요. [92]의 예절.

도. 23: BLOOM 아키텍처의 개요. [93]의 예절.

1,300억 개의 매개 변수를 가진 이중 언어(영어와 중국어) 사전 훈련된 언어 모델. 적어도 GPT-3(다빈치)만큼 좋은 100B 규모의 모델을 오픈 소스화하고 그러한 규모의 모델이 성공적으로 사전 훈련될 수 있는 방법을 공개하려는 시도였다.

**피티아:** [95]에서 Biderman 등은 Pythia를 소개했습니다. Pythia는 16개의 LLM 집합으로, 모두 동일한 순서로 보여지고 크기가 70M에서 12B 매개 변수 범위입니다. 추가 연구를 위해 정확한 훈련 데이터 로더를 다운로드하고 재구성하는 도구와 함께 16개 모델 각각에 대해 154개의 체크포인트에 대한 공개 액세스를 제공한다.

**Orca:** [96]에서 Mukherjee 등은 대규모 기초 모델의 추론 프로세스를 모방하도록 학습하는 130억 개의 매개 변수 모델인 Orca를 개발합니다. 오르카는 설명 트레이스를 포함한 GPT-4의 풍부한 신호, 단계별 사고 과정, ChatGPT의 교사 지원에 의해 안내되는 기타 복잡한 명령으로부터 학습한다.

**StarCoder:** [97]에서 Li 등은 StarCoder 및 StarCoderBase를 도입했습니다. 8K 컨텍스트 길이, 채우기 기능 및 다중 쿼리 주의에 의해 활성화된 빠른 대규모 배치 추론을 가진 15.5B 매개변수 모델이다. 스타코더베이스는 검사 도구와 옵트아웃 프로세스를 갖춘 허가된 GitHub 리포지토리의 대규모 컬렉션인 더 스택에서 조달한 1조 개의 토큰에 대해 교육됩니다. 그들은 35B Python 토큰에서 StarCoderBase를 미세 조정하여 StarCoder를 만들었습니다. 그들은 현재까지 코드 LLM에 대한 가장 포괄적인 평가를 수행했으며 StarCoderBase가 여러 프로그래밍 언어를 지원하는 모든 오픈 코드 LLM을 능가하고 OpenAI 코드-cushman-001 모델과 일치하거나 능가함을 보여주었다.

**Kosmos:** [98]에서 Huang 등은 일반적인 모달리티를 인식하고 컨텍스트에서 학습하고 지침(즉, 적은 샷)을 따를 수 있는 MLLM(Multimodal Large Language Model)인 KOSMOS-1을 도입했습니다. 구체적으로, 그들은 임의로 인터리빙된 텍스트와 이미지, 이미지-캡션 쌍 및 텍스트 데이터를 포함한 웹 규모의 멀티모달 코퍼라에서 처음부터 KOSMOS-1을 훈련시켰다. 실험 결과, KOSMOS-1은 (i) 언어 이해, 생성, 심지어 OCR이 없는 NLP(문서 이미지가 직접 공급됨), (ii) 멀티모달 대화, 이미지 캡션, 시각적 질문 응답을 포함한 지각 언어 작업, (iii) 설명을 사용한 이미지 인식(텍스트 명령을 통한 분류 지정)과 같은 비전 작업에 대해 인상적인 성능을 달성했다.

**제미니:** [99]에서 제미니 팀은 이미지, 오디오, 비디오 및 텍스트 이해에 걸쳐 유망한 기능을 나타내는 새로운 멀티모달 모델 패밀리를 도입했습니다. 제미니 패밀리에는 고도로 복잡한 작업을 위한 울트라, 대규모의 향상된 성능과 배포성을 위한 프로, 온-디바이스 애플리케이션을 위한 나노의 세 가지 버전이 포함됩니다. 제미니 아키텍처는 트랜스포머 디코더 위에 구축되며, (효율적인 주의 메커니즘을 사용하여) 32k 컨텍스트 길이를 지원하도록 훈련된다.

다른 인기 있는 LLM 프레임워크(또는 LLM의 효율적인 개발을 위해 사용되는 기술) 중 일부는 Inner-Monologue[100], Megatron-Turing NLG[101], LongFormer[102], OPT-IML[103], MeTaLM[104], Dromedary[105], Palmyra[106], Camel[107], Yalm[108], MPT[109], ORCA-2[110], Gorilla[67], PAL[111], Claude[112], CodeGen 2[113], Zephyr[114], Groke[115], Qwen[116], Mamba[30], Mistral-8x7B[117], DocLLM[118], DeepSeek-Coder[119], FuseLLM-7B[120], TinyLlama-1.1B[121], LLaMA-Pro-8B[122].

그림 24는 가장 대표적인 LLM 프레임워크 중 일부와 LLM 성공에 기여하고 LLM 한계를 밀어내는 데 도움이 된 관련 작업에 대한 개요를 제공한다.

## III LLMs 구축 방법

이 섹션에서는 먼저 LLM에 사용되는 인기 있는 아키텍처를 검토한 다음 데이터 준비, 토큰화, 사전 훈련, 명령어 튜닝 및 정렬에 이르는 데이터 및 모델링 기술에 대해 논의한다.

모델 아키텍처가 선택되면, LLM 트레이닝에 관련된 주요 단계는 데이터 준비(수집, 청소, 디듀핑 등), 토큰화, 모델 사전 트레이닝(자기 지도 학습 방식으로), 명령어 튜닝 및 정렬을 포함한다. 우리는 그것들을 각각 아래에 별도의 하위 섹션으로 설명할 것이다. 이러한 단계들은 또한 도 25에 예시되어 있다.

### _Dominant LLM 아키텍처_

가장 널리 사용되는 LLM 아키텍처는 인코더 전용, 디코더 전용 및 인코더-디코더이다. 대부분은 트랜스포머(빌딩 블록)를 기반으로 합니다. 따라서 본 논문에서는 트랜스포머 아키텍처를 검토한다.

#### Iii-A1 **Transformer**

Vaswani 등은 획기적인 작업[44]에서 원래 GPU를 사용하여 효과적인 병렬 컴퓨팅을 위해 설계된 트랜스포머 프레임워크를 제안했다. 트랜스포머의 핵심은 반복 및 컨볼루션 메커니즘보다 GPU를 사용하여 훨씬 더 효과적으로 장기 컨텍스트 정보를 캡처할 수 있는 (자기-주의 메커니즘)이다. 그림 26은 변압기 작업의 고급 개요를 제공한다. 이 섹션에서는 주요 요소 및 변형에 대한 개요를 제공하며 자세한 내용은 [44, 123]을 참조하십시오.

원래 기계 번역을 위해 제안된 트랜스포머 언어 모델 아키텍처는 인코더와 디코더로 구성된다. 인코더는 N=6개의 동일한 트랜스포머 계층들의 스택으로 구성된다. 각 층은 두 개의 하위 층을 갖는다. 첫 번째는 다중 헤드 자기 주의 계층이고, 다른 하나는 간단한 위치-와이즈 완전 연결 피드-포워드 네트워크이다. 디코더는 6개의 동일한 층들의 스택으로 구성된다. 각각의 인코더 계층 내의 2개의 서브-레이어에 더하여, 디코더는 제3 서브-레이어를 가지며, 이는 인코더 스택의 출력에 걸쳐 멀티-헤드 어텐션을 수행한다. 어텐션 함수는 쿼리 및 키-값 쌍의 세트를 출력에 매핑하는 것으로 설명될 수 있으며, 여기서 쿼리, 키, 값 및 출력은 모두 벡터이다. 출력은 값들의 가중 합으로서 계산되며, 여기서 각각의 값에 할당된 가중치는 대응하는 키와의 질의의 호환성 함수에 의해 계산된다. 이 방법은 \(d_{model}\) 차원 키, 값 및 질의로 단일 어텐션 함수를 수행하는 대신, 각각 \(d_{k}\), \(d_{k}\) 및 \(d_{v}\) 차원에 서로 다른 학습된 선형 투영을 갖는 질의, 키 및 값 \(h\)을 선형 투영하는 것이 유리하다. 위치 인코딩은 시퀀스 내의 토큰들의 상대적 또는 절대적 위치에 관한 정보를 융합하기 위해 통합된다.

#### Vi-A2 **Encoder-Only**

이 패밀리의 경우 각 단계에서 어텐션 레이어는 초기 문장의 모든 단어에 액세스할 수 있다. 이러한 모델의 사전 훈련은 일반적으로 주어진 문장을 어떻게든 손상시키는 것(예를 들어, 그 안에 무작위 단어를 마스킹함으로써)과 초기 문장을 찾거나 재구성하는 것으로 모델을 작업시키는 것으로 구성된다. 인코더 모델은 문장 분류, 개체명 인식 및 추출 질의 응답과 같이 전체 시퀀스에 대한 이해가 필요한 작업에 적합하다. 하나의 두드러진 인코더 전용 모델은 [24]에서 제안된 BERT(Bidirectional Encoder Representations from Transformers)이다.

#### Vi-A3 **Decoder-Only**

이러한 모델의 경우 각 단계에서 모든 단어에 대해 어텐션 레이어는 문장에서 그 앞에 위치한 단어에만 액세스할 수 있다. 이러한 모델은 때때로 자동 회귀 모델이라고도 합니다. 이러한 모델의 사전 훈련은 일반적으로 시퀀스에서 다음 단어(또는 토큰)를 예측하는 것으로 공식화된다. 디코더 전용 모델은 텍스트 생성과 관련된 작업에 가장 적합하다. GPT 모델은 이 모델 범주의 두드러진 예이다.

#### Vi-A4 **Encoder-Decoder**

이러한 모델들은 인코더와 디코더를 모두 사용하며, 때때로 시퀀스-투-시퀀스 모델이라고 불린다. 각 단계에서, 인코더의 어텐션 계층들은 초기 문장 내의 모든 단어들에 액세스할 수 있는 반면, 디코더의 어텐션 계층들은 입력 내의 주어진 단어 이전에 위치된 단어들에만 액세스한다. 이러한 모델들은 보통 인코더 또는 디코더 모델들의 목적들을 사용하여 사전 트레이닝되지만, 보통은 약간 더 복잡한 것을 수반한다. 예를 들어, 일부 모델은 (여러 단어를 포함할 수 있는) 텍스트의 랜덤 스팬을 단일 마스크 특수 단어로 대체함으로써 사전 트레이닝되고, 그 다음 목적은 이 마스크 단어가 대체하는 텍스트를 예측하는 것이다. 인코더-디코더 모델들은 요약, 번역 또는 생성 질의 응답과 같은 주어진 입력에 조건화된 새로운 문장들을 생성하는 것에 관한 태스크들에 가장 적합하다.

### _Data Cleaning_

데이터 품질은 언어 모델에 대해 훈련된 언어 모델의 성능에 매우 중요합니다. 필터링, 중복제거와 같은 데이터 클리닝 기법은 모델 성능에 큰 영향을 미치는 것으로 나타났다.

예를 들어 **Falcon40B**[124]에서 Penedo 등은 적절하게 필터링되고 중복 제거된 웹 데이터만으로도 강력한 모델로 이어질 수 있음을 보여주었습니다. 광범위한 필터링에도 불구하고, 그들은 커먼크롤로부터 5조 개의 토큰을 얻을 수 있었다. 그들은 또한 REFINEDWEB 데이터 세트에서 6,000억 토큰의 추출물과 이에 대해 훈련된 1.3/7.5B 매개변수 언어 모델을 출시했습니다. 도 27은 본 작업에 의한 CommonCrawl 데이터의 정제 과정을 나타낸다.

#### Vi-B1 데이터 필터링

데이터 필터링은 훈련 데이터의 품질과 훈련된 LLM의 효과를 향상시키는 것을 목표로 한다. 공통 데이터 필터링 기술들은 다음을 포함한다:

**잡음 제거:** 는 모델의 일반화 능력에 영향을 미칠 수 있는 관련 없거나 잡음이 많은 데이터를 제거하는 것을 나타냅니다. 예를 들어, 학습 데이터에서 잘못된 정보를 제거하여 모델이 잘못된 응답을 생성할 가능성을 낮추는 것을 생각할 수 있다. 품질 필터링을 위한 두 가지 주류 접근법은 분류기 기반 및 휴리스틱 기반 프레임워크를 포함한다.

도. 24: 가장 대표적인 LLM 프레임워크의 일부(지금까지)의 타임라인. 본 논문에서 제안한 #파라미터 임계치를 갖는 대규모 언어 모델뿐만 아니라, 언어 모델의 한계를 밀어붙인 몇 가지 대표적인 작업들을 포함시켰고, 그 성공의 길을 열어준 바닐라 트랜스포머, BERT, GPT-1과 같은 몇몇 소규모 언어 모델들도 포함시켰다. \ (\clubsuit\)는 모델뿐만 아니라 접근 방식으로도 사용되는 엔터티를 보여줍니다. \ (\clubsuit\)는 접근법만 보여줍니다.

[MISSING_PAGE_POST]

garwal

**이상치 처리:** 데이터에서 이상치 또는 이상이 모델에 불균형적으로 영향을 미치지 않도록 식별 및 처리합니다.

**불균형 해결:** 편향을 방지하고 공정한 표현을 보장하기 위해 데이터 세트에서 클래스 또는 범주의 분산을 조정합니다. 책임 있는 모델 훈련 및 평가에 특히 유용합니다.

**텍스트 전처리:** 모델의 학습에 크게 기여하지 않을 수 있는 불용어, 구두점 또는 기타 요소를 제거하여 텍스트 데이터를 정리하고 표준화합니다.

**모호성 처리:** 훈련 중에 모델을 혼동할 수 있는 모호하거나 모순된 데이터를 해결하거나 제외합니다. 이는 모델이 보다 확실하고 신뢰할 수 있는 답변을 제공하는 데 도움이 될 수 있다.

#### V-B2 Deduplication

중복은 데이터셋에서 동일한 데이터의 중복 인스턴스 또는 반복된 발생을 제거하는 과정을 의미한다. 중복된 데이터 포인트는 모델이 동일한 예로부터 여러 번 학습하여 잠재적으로 그러한 특정 인스턴스에 과적합으로 이어질 수 있기 때문에 모델 트레이닝 프로세스에 편향을 도입하고 다양성을 감소시킬 수 있다. 일부 작업[125]은 중복 제거가 모델의 새로운 보이지 않는 데이터로 일반화하는 능력을 향상시킨다는 것을 보여주었다.

중복은 의도하지 않게 특정 패턴이나 특성의 중요성을 부풀릴 수 있기 때문에 대규모 데이터 세트를 다룰 때 중복 제거 프로세스가 특히 중요하다. 이것은 특히 다양하고 대표적인 훈련 데이터가 강력한 언어 모델을 구축하는 데 중요한 NLP 작업과 관련이 있다.

특정 중복 제거 방법은 데이터의 특성 및 훈련되는 특정 언어 모델의 요구 사항에 따라 달라질 수 있다. 이는 중복을 식별하고 제거하기 위해 전체 데이터 포인트 또는 특정 특징을 비교하는 것을 수반할 수 있다. 문서 수준에서 기존 작업은 주로 문서 간의 높은 수준의 특징(예: n-gram 중첩)의 중첩 비율에 의존하여 중복 샘플을 탐지한다.

### _Tokenizations_

토큰화는 텍스트 시퀀스를 토큰으로 알려진 더 작은 부분으로 변환하는 프로세스를 의미한다. 가장 간단한 토큰화 도구는 텍스트를 화이트 스페이스에 기초하여 토큰으로 간단히 잘라내는 반면, 대부분의 토큰화 도구는 단어 사전(word dictionary)에 의존한다. 그러나 이 경우 토큰화기는 사전에 단어만 알고 있기 때문에 어휘 외(OOV)가 문제가 된다. 사전의 커버리지를 증가시키기 위해, LLMs에 사용되는 인기 있는 토큰라이저는 서브-워드들에 기초하며, 서브-워드들은 트레이닝 데이터에서 보이지 않는 워드들 또는 상이한 언어들의 워드들을 포함하여 많은 수의 워드들을 형성하도록 결합될 수 있다. 다음은 세 가지 인기 있는 토크나이저에 대해 설명합니다.

#### V-C1 **BytePairEncoding**

_BytePairEncoding_은 원래 바이트 수준의 빈발 패턴을 사용하여 데이터를 압축하는 데이터 압축 알고리즘의 한 종류이다. 정의에 따르면, 이 알고리즘은 주로 빈발 단어를 원래 형태로 유지하고 일반적이지 않은 단어를 분해하려고 한다. 이 단순한 패러다임은 어휘의 크기를 그다지 크게 유지하지 않을 뿐만 아니라 공통 단어를 동시에 나타낼 수 있을 만큼 충분히 좋다. 또한 알고리즘의 학습 데이터에 접미사 또는 접두사가 공통적으로 제시되면 빈발 단어의 형태적 형태가 매우 잘 표현될 수 있다.

#### V-C2 **WordPieceEncoding**

이 알고리즘은 주로 BERT 및 Electra와 같은 매우 잘 알려진 모델에 사용된다. 훈련 시작 시 알고리즘은 훈련 데이터에서 모든 알파벳을 가져와서 훈련 데이터 세트에서 UNK 또는 _알 수 없는_ 로 남는 것이 없는지 확인합니다. 이 경우 모델에 토큰화기에서 토큰화할 수 없는 입력이 주어질 때 발생합니다. 대부분의 경우 일부 문자가 토큰화할 수 없는 경우에 발생합니다. BytePairEncoding과 유사하게 빈도에 따라 모든 토큰을 어휘에 넣을 가능성을 최대화하려고 한다.

#### V-C3 **SentencePieceEncoding**

앞서 설명한 두 토큰라이저는 모두 화이트 스페이스 토큰화에 비해 강력하고 많은 이점이 있지만 여전히 단어가 항상 화이트 스페이스로 분리된다는 가정을 당연한 것으로 받아들인다. 이러한 가정이 항상 사실인 것은 아니며, 실제로 일부 언어에서 단어는 원치 않는 공간과 같은 많은 잡음 요소에 의해 손상되거나 심지어 발명된 단어에 의해 손상될 수 있다. SentencePieceEncoding은 이 문제를 해결하려고 합니다.

도. 27: Macrodata Refinement의 후속 단계는 원래 CommonCrawl에 있는 문서의 거의 90%를 제거합니다. [124]의 예절.

도. 26: 변압기 작업의 상위 레벨 개요. [44]의 예절.

### **Positional Encoding**

#### Iii-D1 **절대 위치 임베딩**

(APE) [44]는 시퀀스 순서의 정보를 보존하기 위해 원래 트랜스포머 모델에서 사용되었다. 따라서, 인코더 및 디코더 스택 모두의 하단의 입력 임베딩에 단어의 위치 정보가 추가된다. 위치 인코딩에는 학습되거나 고정된 다양한 옵션이 있다. 바닐라 트랜스포머에서는 사인 함수와 코사인 함수가 이 목적을 위해 사용된다. 트랜스포머에서 APE를 사용하는 것의 주요 단점은 특정 수의 토큰에 대한 제한이다. 또한 APE는 토큰 간의 상대적 거리를 설명하지 못합니다.

#### Iii-D2 **상대적 위치 임베딩**

(RPE) [126]은 입력 엘리먼트들 사이의 쌍별 링크들을 고려하기 위해 자기 주의를 확장하는 것을 포함한다. RPE는 두 가지 수준에서 모델에 추가되며, 첫째는 키에 대한 추가 구성 요소이고, 이후는 값 행렬의 하위 구성 요소로 추가된다. 이 접근법은 입력을 레이블 및 지향된 간선이 있는 완전히 연결된 그래프로 본다. 선형 시퀀스의 경우, 에지는 입력 요소 간의 상대적인 위치 차이에 대한 정보를 캡처할 수 있다. k \(2\leq k\leq n-4\)로 표시되는 클리핑 거리는 상대 위치의 최대 제한을 지정합니다. 이는 모델이 트레이닝 데이터의 일부가 아닌 시퀀스 길이에 대해 합리적인 예측을 할 수 있게 한다.

#### Iii-D3 **회전 위치 임베딩**

Rotary Positional Embedding (RoPE) [127]은 기존의 접근법들과 문제점을 해결한다. 학습된 절대적 위치 인코딩은 특히 문장이 짧을 때 일반화 가능성과 의미가 부족할 수 있다. 더욱이, T5의 위치 임베딩과 같은 현재의 방법들은 위치들 사이의 완전한 주의 행렬을 구성하는 데 어려움을 겪는다. RoPE는 단어의 절대 위치를 인코딩하기 위해 회전 매트릭스를 사용하고 동시에 자기 주의에 명시적인 상대 위치 세부사항을 포함한다. RoPE는 문장 길이에 대한 유연성, 상대 거리가 증가함에 따른 단어 의존성의 감소, 상대 위치 인코딩을 통한 선형 자기 주의력 향상 기능과 같은 유용한 기능을 제공한다. GPT-NeoX-20B, PaLM, CODEGEN 및 LLaMA는 아키텍처에서 RoPE를 활용하는 모델 중 하나이다.

#### Iii-D4 **상대적 위치 편향**

이러한 유형의 위치 임베딩 뒤에 있는 개념은 훈련에서 마주치는 것보다 긴 시퀀스에 대한 추론 동안 외삽을 용이하게 하는 것이다. [128] Press et al. proposed Attention with Linear Biases (ALiBi). 그들은 단순히 단어 임베딩에 위치 임베딩을 추가하는 대신 쿼리-키 쌍의 주의 점수에 편향을 도입하여 거리에 비례하는 페널티를 부과했다. BLOOM 모델에서는 ALiBi가 레버리지된다.

### _Model Pre-training_

사전 훈련은 대규모 언어 모델 훈련 파이프라인에서 첫 번째 단계로 LLM이 기본 언어 이해 능력을 습득할 수 있도록 도와주며, 이는 광범위한 언어 관련 작업에서 유용할 수 있다. 사전 훈련 동안, LLM은 대량의 (일반적으로) 라벨이 지정되지 않은 텍스트, 일반적으로 자기-감독 방식으로 훈련된다. 다음 문장 예측[24]과 같이 사전 훈련에 사용되는 다른 접근법이 있으며, 가장 일반적인 두 가지 접근법에는 다음 토큰 예측(자동 회귀 언어 모델링) 및 마스킹 언어 모델링이 포함된다.

**자동 회귀 언어 모델링** 프레임워크에서 \(n\) 토큰 \(x_{1}\),..., \(x_{n}\)의 시퀀스가 지정되면 모델은 다음 토큰 \(x_{n+1}\)(및 때때로 다음 토큰 시퀀스)를 자동 회귀 방식으로 예측하려고 합니다. 이 경우 인기 있는 손실 함수 중 하나는 Eq2와 같이 예측된 토큰의 로그 우도입니다.

\[\mathscr{L}_{ALM}(x)=\sum_{i=1}^{N}p(x_{i+n}|x_{i},...,x_{i+n-1}) \tag{1}\]

이 프레임워크의 자동 회귀 특성을 감안할 때 디코더 전용 모델은 자연스럽게 이러한 작업을 수행하는 방법을 배우는 데 더 적합하다.

**마스크 언어 모델링** 에서 일부 단어는 시퀀스로 마스킹되고 모델은 주변 컨텍스트를 기반으로 마스킹된 단어를 예측하도록 훈련됩니다. 때때로 사람들은 이 접근 방식을 자동 인코딩을 제거하는 것으로도 언급한다. 우리가 시퀀스 \(x\), \(\tilde{x}\)에서 마스킹된/손상된 샘플들을 나타내면, 이 접근법의 트레이닝 목적은 다음과 같이 기입될 수 있다:

\[\mathscr{L}_{MLM}(x)=\sum_{i=1}^{N}p(\tilde{x}|x\backslash\tilde{x}) \tag{2}\]

그리고 최근에는 LLM 공간에서도 **Mixture of Experts (MoE)**[130, 131]이 매우 인기를 얻고 있습니다. MoE는 모델이 훨씬 적은 계산으로 미리 훈련될 수 있도록 하며, 이는 밀도가 높은 모델과 동일한 계산 예산으로 모델 또는 데이터 세트 크기를 극적으로 확장할 수 있음을 의미한다. MoE는 두 가지 주요 요소(FFN( dense feed-forward network) 계층 대신 사용되는 **희소 MoE 계층**)으로 구성되며, 각 전문가가 신경망인 특정 수의 "전문가"(예: 8)를 갖는다. 실제로 전문가들은 FFN이지만 더 복잡한 네트워크일 수도 있다. **게이트 네트워크 또는 라우터** 는 어떤 토큰이 어떤 전문가에게 전송되는지 결정합니다. 하나 이상의 전문가에게 토큰을 보낼 수 있다는 점에 주목할 필요가 있습니다. 토큰을 전문가에게 라우팅하는 방법은 MoE와 함께 작업할 때 중요한 결정 중 하나입니다. 라우터는 학습된 매개변수로 구성되며 네트워크의 나머지 부분과 동시에 사전 훈련됩니다. 도 29는 MoE에서 사용되는 스위치 트랜스포머 인코더 블록의 예시를 제공한다.

### _Fine-tuning and Instruction Tuning_

섹션 III-E에서 설명한 대로 자체 감독을 사용하여 훈련된 BERT와 같은 초기 언어 모델은 특정 작업을 수행할 수 없었다. 기초 모델이 유용하기 위해서는 라벨링된 데이터(소위 감독 미세 조정 또는 줄여서 SFT)를 사용하여 특정 작업에 미세 조정해야 한다. 예를 들어, 원래의 BERT 논문[24]에서, 모델은 11개의 상이한 태스크들로 미세 조정되었다. 최근 LLM은 더 이상 미세 조정을 사용할 필요가 없지만 작업 또는 데이터별 미세 조정에서 이점을 얻을 수 있습니다. 예를 들어, OpenAI는 훨씬 더 작은 GPT-3.5 터보 모델이 태스크 특정 데이터 2로 미세 조정될 때 GPT-4를 능가할 수 있다고 보고한다.

각주 2: [https://platform.openai.com/docs/guides/fine-tuning](https://platform.openai.com/docs/guides/fine-tuning)

파인-튜닝은 단일 태스크에 대해 수행될 필요는 없고, 멀티-태스크 파인-튜닝에 대한 상이한 접근법들이 존재한다(예를 들어, Mahabi 등 [132] 참조). 하나 이상의 작업에 대한 미세 조정은 결과를 개선하고 신속한 엔지니어링의 복잡성을 줄이는 것으로 알려져 있으며 검색 증강 생성의 대안 역할을 할 수 있다. 또한, 미세 조정이 권장되는 다른 이유가 있습니다. 예를 들어 모델을 사전 훈련 중에 노출되지 않은 새 데이터 또는 독점 데이터에 노출하도록 미세 조정하려고 할 수 있습니다.

LLM을 미세 조정하는 중요한 이유는 프롬프트를 통해 지침을 제공할 때 인간이 가질 기대에 대한 응답을 정렬하기 위한 것이다. 이것은 소위 **명령 튜닝**[133]이다. 섹션 IV-B에서 프롬프트를 설계하고 엔지니어링하는 방법에 대한 세부 사항을 살펴보지만, 명령어 튜닝의 맥락에서, 명령어는 LLM이 수행해야 하는 작업을 지정하는 프롬프트임을 이해하는 것이 중요하다. 자연 명령어[134]와 같은 명령어 튜닝 데이터 세트는 태스크 정의뿐만 아니라 포지티브/네거티브 예 또는 회피할 사물들과 같은 다른 컴포넌트들을 포함한다.

LLM을 명령 조정하기 위해 사용되는 특정 접근법 및 명령 데이터 세트는 다양하지만 일반적으로 명령 조정 모델은 기본 기반 모델을 능가한다. 예를 들어, InstructGPT[59]는 대부분의 벤치마크에서 GPT-3보다 우수하다. LLMA와 비교할 때 Alpaca[62]에 대해서도 마찬가지이다.

왕 등이 제안한 **Self-Instruct**[135]도 이 라인을 따라 인기 있는 접근법으로, 자체 세대를 부트스트랩하여 사전 훈련된 언어 모델의 명령어 후속 기능을 개선하기 위한 프레임워크를 도입했다. 파이프라인은 언어 모델에서 명령, 입력 및 출력 샘플을 생성한 다음 잘못된 샘플 또는 유사한 샘플을 필터링한 후 원래 모델을 미세 조정하기 위해 사용합니다.

### _Alignment_

AI 정렬은 AI 시스템을 인간의 목표, 선호도 및 원칙으로 조종하는 프로세스입니다. 단어 예측을 위해 미리 훈련된 LLM은 종종 의도하지 않은 행동을 나타낸다. 예를 들어, 독성, 유해성, 오판의 소지가 있고 편향된 콘텐츠를 생성할 수 있다.

위에서 논의한 명령어 튜닝은 LLMs가 정렬에 한 걸음 더 가까워지게 한다. 그러나 많은 경우 모델의 정렬을 개선하고 의도하지 않은 행동을 피하기 위한 추가 단계를 포함하는 것이 중요하다.

도. 28: 다양한 위치 인코딩이 LLM에 채용된다.

도. 29 : 스위치 트랜스포머 인코더 블록의 일러스트레이션. 그들은 트랜스포머에 존재하는 조밀한 피드 포워드 네트워크(FFN) 층을 희소 스위치 FFN 층(연청색)으로 대체했다. [131]의 예절.

이 하위 섹션에서 선형에 접근합니다.

**RLHF**(인간 피드백의 강화 학습) 및 **RLAIF**(AI 피드백의 강화 학습)는 두 가지 인기 있는 접근법이다. RLHF는 보상 모델을 사용하여 인간의 피드백으로부터 정렬을 학습한다. 이 보상 모델은 튜닝된 후 다양한 출력을 평가하고 인간이 제공하는 정렬 선호도에 따라 점수를 매길 수 있다. 보상 모델은 원래 LLM에 피드백을 제공하고 이 피드백은 LLM을 더 조정하기 위해 사용된다[137]. 반면에 AI 피드백으로부터의 강화 학습은 사전 훈련되고 잘 정렬된 모델을 LLM에 직접 연결하고 더 크고 더 정렬된 모델로부터 학습하도록 돕는다[138].

또 다른 최근 작업(**DPO**로 알려져 있음) [139]에서 Rafailov 등은 RLHF가 복잡하고 종종 불안정한 절차임을 논의했으며 새로운 접근법으로 이를 해결하려고 했다. 그들은 보상 함수와 최적 정책 간의 매핑을 활용하여 이러한 제한된 보상 최대화 문제가 단일 단계의 정책 훈련으로 정확하게 최적화될 수 있음을 보여주며 본질적으로 인간 선호 데이터에 대한 분류 문제를 해결한다. 직접 선호 최적화(DPO)라고 하는 결과 알고리즘은 안정적이고 성능이 뛰어나며 계산적으로 가벼워 보상 모델을 피팅하거나 미세 조정 중에 LM에서 샘플링하거나 상당한 하이퍼파라미터 튜닝을 수행할 필요가 없다. 그들은 DPO와의 미세 조정이 세대의 감성을 제어하고 요약에서 응답 품질을 향상시키는 RLHF의 능력을 초과한다는 것을 관찰했다. 그림 30은 DPO 대 RLHF 간의 고수준 비교를 보여준다.

더욱 최근에 Ethayarajh 등은 Kahneman-Tversky Optimization(KTO)[136]이라는 새로운 정렬 접근법을 제안하였다. 기존의 최신 접근법과 달리 KTO는 짝을 이루는 선호도 데이터(\(x\), \(y_{w}\), \(y_{l}\))를 필요로 하지 않으며, \(y\)가 바람직한지 바람직하지 않은지에 대한 (x,y)와 지식만 필요로 한다. KTO 정렬 모델은 쌍을 이루는 선호도를 사용하지 않았음에도 불구하고 1B에서 30B까지의 척도에서 DPO 정렬 모델보다 좋거나 더 나은 것으로 나타났다. KTO는 또한 필요한 데이터의 종류가 훨씬 풍부하기 때문에 선호 최적화 방법보다 실제 세계에서 사용하기 훨씬 쉽다. 예로서, 모든 소매 회사에는 많은 고객 상호 작용 데이터가 있고, 그 상호 작용이 성공적이었는지(예를 들어, 구매가 이루어졌는가) 또는 성공적이지 않았는지(예를 들어, 구매가 이루어지지 않았는가)가 있다. 그러나 고객상호작용에 실패한 고객상호작용 \(y_{l}\)을 성공적인 고객상호작용 \(y_{w}\)으로 만든 데이터는 거의 또는 전혀 없다. 그림 31은 위에서 논의한 KTO와 다른 정렬 접근법 간의 고수준의 비교를 보여준다.

### _Decoding Strategies_

디코딩은 미리 학습된 LLM을 이용하여 텍스트를 생성하는 과정을 의미한다. 입력 프롬프트가 주어지면, 토큰화기는 입력 텍스트의 각각의 토큰을 대응하는 토큰 ID로 변환한다. 그런 다음 언어 모델은 이러한 토큰 ID를 입력으로 사용하고 다음으로 가능성이 높은 토큰(또는 토큰의 시퀀스)을 예측합니다. 마지막으로, 소프트맥스 함수를 이용하여 확률로 변환한 로짓(logits)을 생성한다. 상이한 디코딩 전략들이 제안되었다. 가장 인기 있는 것 중 일부는 탐욕 탐색, 빔 탐색뿐만 아니라 top-K, top-P(핵 샘플링)와 같은 다양한 샘플 기술이다.

#### V-H1 **Greedy Search**

탐욕 검색은 각 단계에서 가장 가능성이 높은 토큰을 시퀀스의 다음 토큰으로 사용하여 다른 모든 잠재적 옵션을 폐기한다. 상상할 수 있듯이, 이것은 간단한 접근 방식이며 많은 시간적 일관성과 일관성을 잃을 수 있습니다. 순서에 대한 전반적인 영향을 고려하지 않고 각 단계에서 가장 가능성 있는 토큰만 고려한다. 이 속성은 속도를 빠르게 만들지만 다음 토큰의 가능성이 약간 낮은 상태에서 나타났을 수 있는 더 나은 시퀀스를 놓칠 수 있음을 의미하기도 합니다.

#### V-H2 **빔 검색**

다음 가장 가능성 있는 토큰만 고려하는 탐욕스러운 검색과 달리 빔 검색은 **N** 가장 가능성 있는 토큰을 고려하며, 여기서 **N** 은 빔의 수를 나타냅니다. 이 절차는 미리 정의된 최대 시퀀스 길이에 도달하거나 시퀀스 종료 토큰이 나타날 때까지 반복된다. 이 시점에서, 가장 높은 전체 스코어를 갖는 토큰들의 시퀀스(AKA "빔")가 출력으로서 선택된다. 예를 들어, 빔 크기가 2이고 최대 길이가 5인 경우, 빔 탐색은 \(2^{5}=32\)개의 가능한 시퀀스를 추적해야 한다. 따라서 탐욕스러운 검색보다 계산 집약적이다.

#### V-H3 **Top-k 샘플링**

Top-k 샘플링은 언어 모델에 의해 생성된 확률 분포를 이용하여 k개의 가장 가능성 있는 옵션 중에서 랜덤하게 토큰을 선택하는 기법이다.

6개의 토큰(A, B, C, D, E, F)과 k=2, P(A)=30%, P(B)=20%, P(C)=P(D)=P(D)=P(E)=P(F)=P(F)=

도. 31: LLM 정렬은 감독된 미세조정에 이어 인간 중심 손실(HALO)을 최적화하는 것을 수반한다. 그러나 기존 접근법이 필요로 하는 페어링된 선호도는 얻기 어렵다. 대조적으로, KTO는 훨씬 더 풍부한 종류의 데이터를 사용하여 실제 세계에서 훨씬 더 쉽게 사용할 수 있다. [136]의 예절.

도. 30: DPO는 강화 학습을 피하면서 인간의 선호도에 최적화한다. 인간 피드백으로 언어 모델을 미세 조정하는 기존의 방법은 먼저 응답 쌍에 대한 프롬프트 및 인간 선호의 데이터 세트에 보상 모델을 피팅한 다음 RL을 사용하여 학습된 보상을 최대화하는 정책을 찾는다. 대조적으로, DPO는 명시적 보상 함수 또는 RL 없이 간단한 분류 목적으로 선호도를 가장 잘 충족하는 정책에 직접 최적화한다. [139]의 예절.

12.5%였다. Top-k 샘플링에서 토큰 C, D, E, F는 무시되고 모델은 시간의 60%인 A와 시간의 40%인 B를 출력한다. 이 접근법은 선택 프로세스에서 무작위성의 요소를 도입하면서 가장 가능성 있는 토큰의 우선 순위를 보장한다.

무작위성은 보통 온도의 개념을 통해 도입된다. 온도 T는 0에서 1까지의 범위인 파라미터로 소프트맥스 함수에 의해 생성된 확률에 영향을 주어 가장 가능성이 높은 토큰이 더 영향력이 있다. 실제로, 그것은 단순히 입력 로짓들을 온도 값으로 나누는 것으로 구성된다:

\[softmax(x_{i})=\frac{e^{x_{i}/T}}{\sum_{j}e^{x_{j}/T}} \tag{3}\]

낮은 온도 설정은 확률 분포를 크게 변경하며(그리고 생성된 출력에서 "창의성" 수준을 제어하기 위해 텍스트 생성에서 일반적으로 사용되는 반면, 큰 온도는 더 높은 확률을 갖는 토큰을 우선시한다). Top-k는 창의적인 샘플링 방법으로 빔 탐색과 함께 사용할 수 있다. Top-k 샘플링에 의해 선택된 시퀀스는 빔 탐색에서 가장 높은 확률을 갖는 시퀀스가 아닐 수 있다. 그러나 가장 높은 점수가 항상 더 사실적이거나 의미 있는 시퀀스로 이어지는 것은 아니라는 것을 기억하는 것이 중요합니다.

#### V-B4 **Top-p 샘플링**

핵 샘플링이라고도 하는 Top-p 샘플링은 Top-k 샘플링과 약간 다른 접근법을 취한다. 핵 샘플링은 상위 k개의 가장 가능성 있는 토큰을 선택하는 대신 선택된 토큰의 확률의 합이 p를 초과하도록 컷오프 값 p를 선택한다. 이는 다음 토큰을 무작위로 선택할 토큰의 "핵"을 형성한다. 즉, top-p 샘플링에서 언어 모델은 확률의 합이 임계값 p를 초과할 때까지 내림차순으로 가장 가능성이 높은 토큰을 검사하고 목록에 계속 추가한다. 상상할 수 있듯이, 이는 top-k 토큰이 큰 확률 질량을 갖지 않는 시나리오에 더 적합할 수 있다. Top-k 샘플링과 달리 핵 샘플링에 포함된 토큰의 수는 고정되어 있지 않다. 이러한 가변성은 종종 더 다양하고 창의적인 출력을 초래하여 텍스트 생성 관련 작업에 핵 샘플링을 인기 있게 만든다.

### _Cost-Effective Training/Inference/Adaptation/Compression_

이 부분에서는 LLM의 보다 비용 친화적인 (및 계산 친화적인) 훈련 및 사용에 사용되는 인기 있는 접근법 중 일부를 검토한다.

#### V-I1 **최적화된 교육**

LLM의 최적화된 훈련을 위해 개발된 많은 프레임워크가 있으며, 여기에서는 몇 가지 두드러진 프레임워크를 소개한다.

**ZeRO:** [140]에서 Rajbhandari 등은 메모리를 최적화하기 위해 새로운 솔루션 ZeRO(Zero Redundancy Optimizer)를 개발했으며, LLM의 훈련 속도를 크게 향상시키면서 효율적으로 훈련할 수 있는 모델 크기를 늘렸습니다. ZeRO는 낮은 통신 볼륨과 높은 계산 입도를 유지하면서 데이터 및 모델 병렬 훈련에서 메모리 중복성을 제거하여 지속적인 높은 효율로 장치 수에 비례하는 모델 크기를 확장할 수 있다.

**RWKV:** [141]에서 Peng 등은 트랜스포머의 효율적인 병렬화 훈련과 RNN의 효율적인 추론을 결합하는 새로운 모델 아키텍처인 Recceptance Weighted Key Value(RWKV)를 제안했다. 그들의 접근법은 선형 주의 메커니즘을 활용하고 모델을 트랜스포머 또는 RNN으로 공식화할 수 있으며, 이는 훈련 동안 계산을 병렬화하고 추론 동안 일정한 계산 및 메모리 복잡성을 유지하여 최초의 비 트랜스포머 아키텍처가 수백억 개의 매개변수로 스케일링되도록 한다. RWKV 아키텍처는 그림 32에 나와 있다.

다른 변압기를 사용한 RWKV의 시간 복잡성 비교는 그림 33에 나와 있다.

#### V-I2 **Low-Rank Adaption(LoRA)**

Low-Rank Adaptation은 훈련 가능한 파라미터들의 수를 상당히 감소시키는 대중적이고 경량화된 훈련 기법이며, 전문화된 작업에 대한 미세 조정된 가중치들과 초기 사전 트레이닝된 가중치들 사이의 차이가 종종 "낮은 고유 순위"를 나타낸다는 중요한 통찰력에 기초한다 - 그것은 낮은 순위 매트릭스에 의해 잘 근사화될 수 있다는 것을 의미한다[142].

도. 33: 서로 다른 트랜스포머를 갖는 RWKV의 시간 복잡도 비교. 여기서 T는 시퀀스 길이, d는 특징 차원, c는 MEGA의 2차 주의 청크 크기이다. [141]의 예절.

도. 32: RWKV 아키텍처. [141]의 예절.

LoRA를 사용한 훈련은 훨씬 빠르고 메모리 효율적이며 저장 및 공유가 쉬운 더 작은 모델 가중치(수백MB)를 생성한다. 저순위 행렬의 한 가지 특성은 두 개의 더 작은 행렬의 곱으로 나타낼 수 있다는 것이다. 이 실현은 미세 조정된 가중치와 초기 사전 훈련된 가중치 사이의 이러한 델타가 훨씬 더 작은 두 행렬의 행렬 곱으로 표현될 수 있다는 가설로 이어진다. 전체 원래의 가중치 행렬이 아닌 이들 두 개의 더 작은 행렬들을 업데이트하는 것에 집중함으로써, 계산 효율이 실질적으로 개선될 수 있다.

구체적으로, 미리 훈련된 가중치 행렬 \(W_{0}\in R^{d\times k}\)에 대해 LoRA는 낮은 순위 분해 \(W_{0}+\Delta W=\hat{W}_{0}+BA\)로 후자를 표현하여 갱신을 제한하며, 여기서 \(B\in R^{d\times r}\,,\,A\in R^{r\times k}\) 및 순위 \(r\ll min(d,k)\). 훈련 중에는 \(W_{0}\)가 동결되어 기울기 업데이트를 받지 않는 반면, \(A\) 및 \(B\)에는 훈련 가능한 매개 변수가 포함되어 있습니다. \(W_{0}\)와 \(\Delta W=BA\)는 모두 동일한 입력으로 곱해지고 각각의 출력 벡터는 좌표 단위로 합산된다는 점을 언급할 가치가 있다. \(h=W_{0}x\)의 경우 수정된 순방향 통과 수율은 \(h=W_{0}x+\Delta Wx=W_{0}x+BAx\)이다. 일반적으로 \(A\)에는 랜덤 가우시안 초기화가 사용되고 \(B\)에는 제로 초기화가 사용되므로 \(\Delta W=BA\)는 훈련 초기에 제로이다. 그런 다음 \(\Delta Wx\)를 \(\alpha r\)로 확장합니다. 여기서 \(\alpha\)는 r에서 상수입니다. 이 재파라미트리제이션은 그림 34에 나와 있다.

LoRA는 훈련 가능한 파라미터의 수를 감소시키기 위해 신경망의 가중치 행렬의 임의의 서브세트에 적용될 수 있다는 것을 언급할 가치가 있다. 트랜스포머 구조에서는 자체 주의 모듈(\(W_{q}\), \(W_{k}\), \(W_{w}\), \(W_{o}\))에 4개의 가중치 행렬이 있고, MLP 모듈에는 2개의 가중치 행렬이 있다. LoRA는 대부분 다운스트림 태스크에 대해서만 어텐션 가중치를 적용하는 데 중점을 두고 있으며, MLP 모듈을 동결하기 때문에 단순성과 매개변수 효율성을 위해 다운스트림 태스크에서 훈련되지 않는다.

#### Iii-B3 **Knowledge Distillation**

지식증류는 더 큰 모형으로부터 학습하는 과정이다[143]. 초기의 최고 성능의 모델 릴리즈는 이 접근법이 API 증류 접근법에 사용되더라도 매우 유용하다는 것을 입증했다. 단일 모델이 아니라 실제로 여러 모델의 지식을 더 작은 모델로 증류하는 접근법이라고도 한다. 이 접근법으로 더 작은 모델을 만들면 에지 장치에서도 사용할 수 있는 더 작은 모델 크기가 생성된다. 그림 35와 같은 지식 증류는 이 훈련 계획의 일반적인 설정을 보여준다.

지식은 반응 증류, 기능 증류 및 API 증류와 같은 다양한 형태의 학습에 의해 전달될 수 있다. 반응 증류는 교사 모델의 출력에만 관심을 가지며 학생 모델이 교사로서 (예측의 의미에서) 정확히 또는 적어도 유사하게 수행하는 방법을 가르치려고 한다. 특징 증류는 마지막 층뿐만 아니라 중간 층도 사용하여 학생 모델에 대한 더 나은 내부 표현을 생성한다. 이는 더 작은 모형이 교사 모형과 유사한 표상을 갖도록 돕는다.

API 증류는 더 작은 모델을 훈련하기 위해 API(일반적으로 OpenAI와 같은 LLM 제공자의 API)를 사용하는 프로세스이다. LLM의 경우 반응 증류와 매우 유사한 더 큰 모델의 직접 출력에서 모델을 훈련하는 데 사용된다. 모델 자체를 공개적으로 사용할 수 없는 경우 최종 사용자에 대해 (일반적으로) 유료 API가 노출되기 때문에 이러한 유형의 증류에 의해 많은 우려가 제기됩니다. 반면에 사용자가 각 통화에 대해 비용을 지불하는 동안 예측을 사용하는 방법은 제한적입니다. 예를 들어 OpenAI는 나중에 경쟁하는 데 사용될 LLM을 생성하기 위해 API 사용을 금지합니다. 그러한 경우의 주요값은 훈련 데이터이다.

#### Iii-B4 **Quantization**

심층 학습은 행렬에 적용되는 수학적 함수의 집합으로 모델 가중치에 대한 특정 정밀도를 갖는다. 가중치의 정밀도를 감소시키는 것은 모델의 크기를 감소시키고 또한 더 빠르게 하는 데 사용될 수 있다. 예로서, Int-8 동작들에 비해 Float-32 동작들은 더 느리다. 양자화라고 불리는 이 과정은 서로 다른 위상으로 적용될 수 있다. 모델 양자화를 위한 주요 접근법은 훈련 후 양자화 및 양자화 인식 훈련으로 분류될 수 있다. 훈련 후 양자화는 동적인 방법과 정적인 두 가지 잘 알려진 방법으로 양자화된 훈련된 모델에 관한 것이다. 동적 훈련 후 양자화는 런타임에서 양자화의 범위를 계산하며 정적 양자화에 비해 느리다. 양자화 인식 훈련은 훈련에 양자화 기준을 추가하고, 훈련 과정에서 양자화된 모델이 훈련되고 최적화된다. 이 접근법은 최종 모델이 좋은 성능을 가질 것이고 또한 트레이닝 후에 양자화될 필요가 없다는 것을 보장한다.

## IV LLMs 사용 및 확장 방법

LLM이 학습되면 다양한 작업에 원하는 출력을 생성하는 데 사용할 수 있습니다. LLM은 기본 프롬프트를 통해 직접 사용할 수 있습니다. 그러나 그들의 잠재력을 최대한 활용하거나 일부 단점을 해결하기 위해

도. 34: LoRA reparametrizan의 예시. 이 과정에서 \(A\) 및 \(B\)만 훈련되었습니다. [142]의 예절.

도. 35: 학생 및 교사와의 일반적인 지식 증류 프레임워크(Courtesy of [144]).

우리는 몇 가지 외부 수단을 통해 모델을 확장해야 합니다. 이 섹션에서는 먼저 환각 문제에 대해 더 자세히 살펴보고 LLM의 주요 결점에 대한 간략한 개요를 제공한다. 그런 다음 프롬프트 및 일부 증강 접근법이 이러한 한계를 해결할 뿐만 아니라 LLM을 외부 세계와 인터페이스할 수 있는 능력을 가진 완전한 AI 에이전트로 전환하는 LLM 기능을 증강하는 데 어떻게 사용될 수 있는지 설명한다.

### _LLM limitations_

LLM은 토큰을 예측하도록 훈련된다는 것을 기억하는 것이 중요하다. 미세 조정 및 정렬은 성능을 향상시키고 능력에 다른 차원을 추가하지만, 특히 순진하게 사용되는 경우 나타나는 몇 가지 중요한 한계가 있다. 그 중 일부는 다음을 포함한다:

* 상태/메모리가 없습니다. LLM은 이전 프롬프트에서 보낸 내용조차 스스로 기억할 수 없습니다. 그것은 어떤 형태의 상태를 필요로 하는 많은 사용 사례에 대한 중요한 제한이다.
* 확률적/확률적입니다. LLM에 동일한 프롬프트를 여러 번 보내면 다른 응답을 받을 수 있습니다. 매개 변수, 특히 온도의 경우 반응의 변동성을 제한하지만 이는 문제를 생성할 수 있는 훈련의 고유한 특성입니다.
* 오래된 정보가 있으며 자체적으로 외부 데이터에 액세스할 수 없습니다. LLM은 자체적으로 현재 시간이나 요일에 대해서도 알지 못하며 훈련 세트에 없는 정보에 접근할 수 없다.
* 이들은 일반적으로 매우 크다. 이것은 많은 비용이 많이 드는 GPU 기계가 훈련과 서비스를 위해 필요하다는 것을 의미합니다. 일부 경우에, 가장 큰 모델은 특히 대기 시간 측면에서 열악한 SLA를 갖는다.
* 환각을 봅니다. LLM은 "진실"이라는 개념이 없으며 일반적으로 좋은 내용과 나쁜 내용의 혼합에 대해 교육을 받았다. 그들은 매우 그럴듯하지만 진실되지 않은 답을 내놓을 수 있다.

이전 제한이 일부 응용 프로그램에서는 모두 중요해질 수 있지만 지난 몇 달 동안 많은 관심을 모았고 나중에 설명하는 많은 신속한 접근법과 LLM 확장 방법을 촉발시켰기 때문에 마지막 한계인 환각에 대해 조금 더 살펴볼 가치가 있다.

**환각:** 큰 언어 모델(LLM) 영역에서 "환각" 현상이 크게 주목을 받았습니다. 문헌, 특히 "자연어 생성에서의 환각에 대한 조사" 논문 [145]에서 LLM에서의 환각은 "제공된 소스에 대해 무의미하거나 불성실한 내용의 생성"으로 특징지어진다. 이 용어는 심리적 통용에 뿌리를 두고 있지만 인공 지능 분야에서 전유되어 왔다.

LLM의 환각은 크게 두 가지 유형으로 분류될 수 있다.

1. **내재 환각**: 이러한 것은 원본 자료와 직접 충돌하여 사실적 부정확성 또는 논리적 불일치를 도입합니다.
2. **외인성 환각**: 모순되지는 않지만 추측적이거나 확인할 수 없는 요소를 포함하여 원본에 대해 검증할 수 없습니다.

LLM 컨텍스트에서 '소스'의 정의는 태스크에 따라 달라지며, 대화 기반 태스크에서는 '세계 지식'을 지칭하는 반면 텍스트 요약에서는 입력 텍스트 자체에 관한 것이다. 이러한 구분은 환각을 평가하고 해석하는 데 중요한 역할을 한다. 환각의 영향 또한 문맥 의존적이다. 예를 들어, 시 쓰기와 같은 창의적인 노력에서 환각은 허용되거나 심지어 유익한 것으로 간주될 수 있다.

인터넷, 책, 위키피디아를 포함한 다양한 데이터 세트에서 훈련된 LLM은 진리나 거짓에 대한 본질적인 이해 없이 확률 모델을 기반으로 텍스트를 생성한다. 인간 피드백으로부터의 지시 튜닝 및 강화 학습(RLHF)과 같은 최근의 발전은 LLM을 보다 사실적인 출력으로 조종하려고 시도했지만 근본적인 확률적 특성과 그 고유한 한계는 남아 있다. 최근 연구 "추론 작업에 대한 대규모 언어 모델에 의한 환각의 출처" [146]은 LLM 훈련 및 출력 생성에 내재된 복잡성을 강조하면서 LLM에서 환각에 기여하는 두 가지 핵심 측면을 강조한다.

LLM에서 환각을 효과적으로 자동 측정하려면 통계 및 모델 기반 메트릭의 조합이 필요하다.

_Statistical Metrics_:

* ROUGE [147] 및 BLEU [148]과 같은 메트릭은 고유한 환각에 초점을 맞추어 텍스트 유사성을 평가하는 데 일반적입니다.
* PARENT [149], PARENT-T [150] 및 Knowledge F1 [151]과 같은 고급 메트릭은 구조화된 지식 원본을 사용할 수 있는 경우 활용 됩니다. 이러한 메트릭은 효과적이지만 구문 및 의미 뉘앙스를 포착하는 데 한계가 있다.

_Model-Based Metrics_:

* **IE 기반 메트릭**: 정보 추출 모델을 사용하여 지식을 관계형 튜플로 단순화한 다음 원본과 비교합니다.
* **QA 기반 메트릭**: 질문 답변 프레임워크를 통해 생성된 콘텐츠와 원본 간의 중첩을 평가합니다([152] 참조).
* **NLI 기반 메트릭**: 자연어 추론 데이터 세트를 사용하여 주어진 전제를 기반으로 생성된 가설의 진실성을 평가합니다([153] 참조).
* **충성 분류 메트릭**: 미묘한 평가를 위해 작업별 데이터 세트를 만들어 정제된 평가를 제공합니다([154] 참조).

자동화된 메트릭의 발전에도 불구하고 인간의 판단은 여전히 중요한 부분이다. 일반적으로 두 가지 방법론이 포함 됩니다. 1. **점수 매기기**: 인간 평가자는 미리 정의된 척도 내에서 환각 수준을 평가 합니다.
2. **비교 분석**: 평가자는 생성된 콘텐츠를 기준 또는 지상 진실 참조와 비교하여 주관적인 평가의 필수 계층을 추가합니다.

FactScore[155]는 인간 및 모델 기반 평가 모두에 사용될 수 있는 메트릭의 최근 예이다. 메트릭은 LLM 생성을 "원자적 사실"로 나눈다. 최종 점수는 각 원자 사실에 대한 정확도의 합으로 계산되어 각각에 동일한 가중치를 부여한다. 정확도는 원자적 사실이 원천에 의해 뒷받침되는지 여부를 단순히 나타내는 이진수이다. 저자들은 LLM을 사용하여 이 메트릭을 추정하는 다양한 자동화 전략을 구현한다.

마지막으로 LLM에서 환각을 완화하는 것은 다양한 응용 프로그램에 맞는 맞춤형 전략이 필요한 다면적인 도전이다. 그것들은 다음을 포함한다:

* 사용 사례 설계, 입력/출력 구조화 또는 사용자 피드백을 위한 메커니즘 제공과 같은 제품 설계 및 사용자 상호 작용 전략.
* 데이터 관리 및 지속적인 개선. 추적 환각 세트를 유지하고 분석하는 것은 지속적인 모델 개선을 위해 필수적이다.
* Prompt Engineering 및 Metaprompt Design. 검색 증강 생성과 같은 IV-B에 설명된 많은 고급 프롬프트 기술은 환각 위험을 직접 해결한다.
* 환각 완화를 위한 모델 선택 및 구성. 엑셈플의 경우 온도 설정이 낮은 더 큰 모델이 일반적으로 더 나은 성능을 발휘합니다. 또한 RLHF 또는 도메인별 미세 조정과 같은 기술은 환각 위험을 완화할 수 있다.

### _LLMs 사용: **프롬프트 설계 및 엔지니어링**_

생성 AI 모델의 프롬프트는 모델의 출력을 안내하기 위해 사용자가 제공하는 텍스트 입력이다. 이는 간단한 질문에서부터 상세한 설명 또는 특정 작업에 이르기까지 다양할 수 있다. 프롬프트는 일반적으로 명령어, 질문, 입력 데이터 및 예제로 구성된다. 실제로 AI 모델에서 원하는 응답을 이끌어내기 위해 프롬프트에는 지시사항이나 질문이 포함되어야 하며 다른 요소는 선택 사항이다. 고급 프롬프트에는 다음과 같은 더 복잡한 구조가 포함됩니다.

도. 36: LLM이 사용 및 증강되는 방법.

"사고 사슬" 프롬프트는 모델이 해답에 도달하기 위해 논리적 추론 프로세스를 따르도록 안내된다.

신속한 공학은 LLM 및 기타 생성 AI 모델의 상호 작용 및 출력을 형성하는 빠르게 진화하는 학문이다. 신속한 공학의 본질은 생성적 모델로 특정 목표를 달성하기 위한 최적의 프롬프트를 만드는 데 있다. 이 과정은 모델을 지시하는 것뿐만 아니라 모델의 능력과 한계, 그리고 그것이 작동하는 맥락에 대한 일부 이해도 포함한다.

프롬프트 엔지니어링은 프롬프트의 단순한 구성을 초월하며, 도메인 지식, AI 모델에 대한 이해 및 다양한 컨텍스트에 대한 프롬프트를 맞춤화하는 방법적 접근 방식의 혼합이 필요하다. 여기에는 지정된 데이터 세트 또는 컨텍스트를 기반으로 프로그래밍 방식으로 수정할 수 있는 템플릿 만들기가 포함될 수 있습니다. 예를 들어, 사용자 데이터에 기초하여 개인화된 응답을 생성하는 것은 관련 사용자 정보로 동적으로 채워지는 템플릿을 사용할 수 있다.

또한, 신속한 엔지니어링은 모델 평가 또는 하이퍼파라미터 튜닝과 같은 전통적인 기계 학습 관행과 유사한 반복적이고 탐색적인 프로세스이다. 이 분야의 급속한 성장은 피처 또는 아키텍처 엔지니어링과 같은 전통적인 방법을 넘어 머신 러닝의 특정 측면에 혁명을 일으킬 가능성을 시사한다. 반면에 버전 제어 및 회귀 테스트와 같은 전통적인 엔지니어링 관행은 다른 기계 학습 접근법에 적응된 것처럼 이 새로운 패러다임에 적응될 필요가 있다[156].

다음 단락에서 우리는 가장 흥미롭고 인기 있는 신속한 엔지니어링 접근법 중 일부를 자세히 설명한다.

#### Iii-B1 Chain of Thought (CoT)

구글 연구자들에 의해 "대규모 언어 모델에서 추론하는 연쇄 사상(Chain-of-Thinking Prompting Elicits Reasoning in Large Language Models)"[34]에 처음 기술된 CoT(Chain of Thought) 기법은 대규모 언어 모델(Large Language Models)을 위한 신속한 엔지니어링의 중추적인 발전을 나타낸다. 이 접근법은 LLM이 토큰 예측에 능숙하지만 명시적 추론을 위해 본질적으로 설계되지 않는다는 이해에 달려 있다. CoT는 필수 추론 단계를 통해 모델을 안내함으로써 이를 해결한다.

CoT는 LLM의 암시적 추론 과정을 명시적으로 만드는 것을 기반으로 한다. 추론에 필요한 단계를 설명함으로써, 모델은 특히 단순한 정보 검색 또는 패턴 인식 이상의 것을 요구하는 시나리오에서 논리적이고 추론된 출력에 더 가깝게 지향된다.

CoT 프롬프트 매니페스트는 두 가지 기본 형태로 나타난다:

1. **Zero-Shot CoT:** 이 형식에는 LLM에 "단계별 생각"을 지시하여 문제를 해체하고 추론의 각 단계를 명확히 하도록 프롬프트하는 것이 포함됩니다.
2. **수동 CoT:** 보다 복잡한 변형으로 모델에 대한 템플릿으로 단계별 추론 예제를 제공해야 합니다. 보다 효과적인 결과를 얻을 수 있지만 확장성과 유지 관리에 문제가 있습니다.

수동형 CoT가 제로샷보다 더 효과적이다. 그러나 이 예제 기반 CoT의 효과는 다양한 예제의 선택에 달려 있으며, 손으로 단계적 추론의 그러한 예제로 프롬프트를 구성하는 것은 어렵고 오류가 발생하기 쉽다. 그곳이 바로 자동 CoT[157]가 작동되는 곳이다.

#### Iii-B2 Thought Tree (ToT)

사상의 나무(ToT)[158] 프롬프트 기법은 가장 그럴듯한 방법으로 수렴하기 전에 다양한 대안적 해결책이나 사고 과정을 고려하는 개념에서 영감을 얻었다. ToT는 각 가지가 다른 추론 라인을 나타내는 여러 "사상 트리"로 분기하는 개념을 기반으로 한다. 이 방법을 사용하면 LLM이 가장 가능성이 높은 시나리오를 결정하기 전에 여러 시나리오를 고려하는 인간의 인지 과정과 마찬가지로 다양한 가능성과 가설을 탐색할 수 있다.

ToT의 중요한 측면은 이러한 추론 경로에 대한 평가이다. LLM은 다양한 사고의 분기를 생성하므로 각각은 질의에 대한 유효성 및 관련성에 대해 평가된다. 이 프로세스에는 분기의 실시간 분석 및 비교가 포함되어 가장 일관되고 논리적인 결과를 선택할 수 있다.

ToT는 한 가지 추론으로 충분하지 않을 수 있는 복잡한 문제 해결 시나리오에서 특히 유용하다. 그것은 LLM이 결론에 도달하기 전에 다양한 가능성을 고려하여 보다 인간다운 문제 해결 접근법을 모방할 수 있게 한다. 이 기술은 모호성, 복잡성 및 미묘한 작업을 처리하는 모델의 능력을 향상시켜 고급 AI 응용 프로그램에서 유용한 도구가 된다.

#### Iii-B3 Self-Consistency

Self-Consistency[159]는 앙상블 기반 방법을 활용하는데, 여기서 LLM은 동일한 쿼리에 대한 다수의 응답들을 생성하도록 프롬프트된다. 이러한 응답 간의 일관성은 정확성과 신뢰성을 나타내는 지표 역할을 한다.

자기 일관성 접근법은 LLM이 동일한 프롬프트에 대해 유사한 여러 응답을 생성하면 응답이 정확할 가능성이 더 높다는 원칙에 근거한다. 이 방법은 일관성을 위해 응답을 분석할 때마다 LLM에 여러 번 쿼리를 처리하도록 요청하는 것을 포함한다. 이 기술은 사실적 정확도와 정밀도가 가장 중요한 시나리오에서 특히 유용하다.

반응의 일관성은 다양한 방법을 사용하여 측정할 수 있다. 한 가지 일반적인 접근법은 응답 내용의 중복을 분석하는 것이다. 다른 방법들은 응답들의 의미론적 유사성을 비교하는 것 또는 BERT-점수들 또는 n-그램 중첩들과 같은 보다 정교한 기법들을 채용하는 것을 포함할 수 있다. 이러한 측정은 LLM에 의해 생성된 응답 간의 일치 수준을 정량화하는 데 도움이 된다.

자기일관성은 정보의 진실성이 중요한 분야에서 중요한 응용을 가지고 있다. 특히 AI 모델에서 제공하는 정보의 정확성을 보장하는 것이 필수적인 팩트 체킹과 같은 시나리오와 관련이 있다. 이 기술을 사용하면 신속한 엔지니어가 LLM의 신뢰성을 향상시켜 높은 수준의 사실적 정확성을 요구하는 작업에 더 신뢰할 수 있다.

#### Iii-B4 Reflection

반성[160]은 LLM들이 그들의 응답들의 정확성 및 일관성에 관한 추론에 기초하여 그들 자신의 출력들을 평가하고 잠재적으로 수정하도록 촉구하는 것을 포함한다. 리플렉션의 개념은 LLM이 자기 평가의 한 형태에 참여할 수 있는 능력에 중점을 둔다. 초기 반응을 생성한 후, 모델은 사실적 정확성, 논리적 일관성 및 관련성과 같은 요소를 고려하여 자체 출력을 반영하도록 프롬프트된다. 이러한 내성적인 과정은 수정되거나 개선된 반응의 생성으로 이어질 수 있다.

반성의 핵심 측면은 LLM이 자체 편집을 할 수 있는 능력이다. 초기 반응을 평가함으로써 모델은 잠재적인 오류 또는 개선 영역을 식별할 수 있다. 이러한 생성, 반영 및 수정 반복 과정을 통해 LLM은 출력을 정제하여 응답의 전반적인 품질과 신뢰성을 향상시킬 수 있다.

#### Iii-B5 Expert Prompting

전문가 프롬프밍[161]은 다양한 분야의 전문가들의 응답을 시뮬레이션함으로써 LLM(Large Language Models)의 능력을 향상시킨다. 이 방법은 LLM이 전문가의 역할을 맡고 그에 따라 응답하도록 촉구하여 고품질의 정보에 입각한 답변을 제공하는 것을 포함한다. 전문가 프롬프밍 내의 핵심 전략은 다중 전문가 접근법이다. LLM은 여러 전문가 관점에서 응답을 고려하도록 촉구되며, 이를 종합하여 포괄적이고 균형 잡힌 답변을 형성한다. 이 기법은 반응의 깊이를 높일 뿐만 아니라 다양한 관점을 통합하여 주제에 대한 보다 총체적인 이해를 반영한다.

#### Iii-B6 Chains

체인은 LLM(Large Language Models)으로 복잡한 작업을 처리하기 위해 여러 컴포넌트를 시퀀스로 연결하는 방법을 의미한다. 이 접근법은 각각 최종 결과에 기여하는 일련의 상호 연결된 단계 또는 프로세스를 생성하는 것을 포함한다. 체인(Chains)의 개념은 서로 다른 스테이지 또는 컴포넌트가 순차적으로 배치되는 워크플로우(Workflow)를 구성하는 아이디어에 기초한다. 체인 내의 각 구성 요소는 특정 기능을 수행하며, 하나의 출력은 다음 입력을 위한 입력 역할을 한다. 이 종단간 배열은 각 단계가 작업의 특정 측면을 처리하도록 조정될 수 있기 때문에 보다 복잡하고 미묘한 처리를 허용한다. 체인은 요구 사항에 따라 복잡성과 구조가 달라질 수 있습니다. "PromptChainer: Chaining Large Language Model Prompts through Visual Programming" [162]에서 저자는 체인 설계의 주요 과제를 설명할 뿐만 아니라 이러한 작업을 지원하는 시각적 도구를 설명합니다.

#### Iii-B7 Rails

고급 프롬프트 엔지니어링의 레일은 미리 정의된 규칙 또는 템플릿을 통해 LLM(Large Language Models)의 출력을 안내하고 제어하는 방법을 의미한다. 이 접근법은 모델의 반응이 특정 표준 또는 기준을 준수하도록 설계되어 출력의 관련성, 안전성 및 정확도를 향상시킨다. 레일의 개념은 LLM이 응답을 생성하는 동안 따라야 하는 프레임워크 또는 일련의 지침을 설정하는 것을 포함한다. 이러한 지침은 일반적으로 자연 언어 문장이 구조화되고 전달되는 방식을 표준화하는 캐노니컬 폼으로 알려진 모델링 언어 또는 템플릿을 사용하여 정의된다.

레일은 애플리케이션의 특정 요구에 따라, 다양한 목적을 위해 설계될 수 있다:

* **국소 레일:** LLM이 특정 주제 또는 도메인에 붙어 있는지 확인합니다.
* **Fact-Checking Rails:** 잘못된 정보 또는 오판의 소지가 있는 정보의 생성을 최소화하는 데 중점을 둡니다.
* **철창 깨기 레일:** LLM이 자체 운영 제약 조건 또는 지침을 우회하려는 응답을 생성하지 않도록 합니다.

#### Iii-B8 자동 프롬프트 엔지니어링(APE)

APE(Automatic Prompt Engineering) [163]은 LLM(Large Language Models)에 대한 프롬프트 생성 프로세스를 자동화하는 데 중점을 둔다. APE는 프롬프트를 생성하고 평가하기 위해 LLM 자체의 기능을 활용하여 프롬프트 설계 프로세스를 간소화하고 최적화하고자 한다. APE는 모델이 프롬프트를 생성, 점수화 및 정제하기 위해 사용되는 자체 참조 방식으로 LLM을 사용하는 것을 포함한다. LLM의 이러한 재귀적 사용은 원하는 응답 또는 결과를 이끌어낼 가능성이 더 높은 고품질 프롬프트를 생성할 수 있다.

APE의 방법론은 몇 가지 주요 단계로 분해될 수 있다:

* **프롬프트 생성:** LLM은 지정된 작업 또는 목적에 따라 다양한 잠재적 프롬프트를 생성합니다.
* **프롬프트 점수:** 생성된 각 프롬프트는 종종 명확성, 특이성 및 원하는 응답을 이끌어낼 가능성과 같은 기준을 사용하여 그 효과에 대해 평가됩니다.
* **정제 및 반복:** 이러한 평가를 기반으로 프롬프트를 정제하고 반복할 수 있으므로 품질과 효율성이 더욱 향상됩니다.

### _외부 지식을 통해 LLMs 강화 - RAG_

사전 훈련된 LLM의 주요 한계 중 하나는 최신 지식이나 개인 또는 사용 사례별 정보에 대한 액세스가 부족하다는 것이다. 여기서 검색 증강 생성(RAG)이 그림[164]에 들어온다. 도 37에 예시된 RAG는 입력 프롬프트로부터 쿼리를 추출하고 그 쿼리를 사용하여 외부 지식 소스(예를 들어, 검색 엔진 또는 지식 그래프, 도면 38 참조)로부터 관련 정보를 검색하는 것을 포함한다. 그런 다음 관련 정보가 원래 프롬프트에 추가되고 모델이 최종 응답을 생성하기 위해 LLM에 공급된다. RAG 시스템은 검색, 생성, 증강의 세 가지 중요한 구성요소를 포함한다[165].

RAG-인지 프롬프트 기법은 고급 LLM 시스템을 구축하기 위한 RAG의 중요성 때문에 최근 몇 가지 RAG-인지 프롬프트 기법이 개발되었다. 이러한 기술 중 하나는 FLARE(Forward-looking Active Retrieval Augmented Generation)이다.

FLARE(Forward-looking Active Retrieval Augmented Generation) [168]은 예측과 정보 검색을 반복적으로 결합하여 LLM(Large Language Models)의 성능을 향상시킨다. FLARE는 LLM 응답의 정확성과 관련성을 개선하기 위한 검색 증강 생성 사용의 진화를 나타낸다.

FLARE는 LLM이 다가오는 콘텐츠를 능동적으로 예측하고 이러한 예측을 관련 정보를 검색하기 위한 쿼리로 사용하는 반복 프로세스를 포함한다. 이 방법은 일반적으로 정보를 한 번 검색한 다음 생성을 진행하는 전통적인 검색 증강 모델과 대조된다. FLARE에서 이 프로세스는 동적이며 생성 단계 전반에 걸쳐 진행 중이다. FLARE에서는 LLM에 의해 생성된 각각의 문장 또는 세그먼트가 신뢰도에 대해 평가된다. 신뢰 수준이 특정 임계값 미만인 경우, 모델은 관련 정보를 검색하기 위한 쿼리로서 생성된 콘텐츠를 사용하고, 이는 이어서 문장을 재생성하거나 정제하는 데 사용된다. 이러한 반복 프로세스는 응답의 각 부분이 이용 가능한 가장 관련되고 현재 정보에 의해 통지되는 것을 보장한다.

RAG 프레임워크 및 관련 작업에 대한 자세한 내용은 독자들에게 검색 증강 세대에 대한 조사를 참조한다[165].

### **외부 도구 사용**

전술한 바와 같이 외부 지식 소스로부터 정보를 검색하는 것은 LLM을 증강시키는 잠재적인 방법 중 하나일 뿐이다. 보다 일반적으로 LLM은 기능을 보강하기 위해 다양한 외부 도구(예: 서비스에 대한 API)에 액세스할 수 있습니다. 이와 관련하여 RAG는 소위 "도구"의 광범위한 범주의 특정 사례로 볼 수 있다.

이러한 맥락에서 도구는 LLM이 활용할 수 있는 외부 기능 또는 서비스이다. 이러한 도구는 기본 정보 검색에서 외부 데이터베이스 또는 API와의 복잡한 상호 작용까지 LLM이 수행할 수 있는 작업의 범위를 확장한다.

"Toolformer: Language Models Can Teach Themuls to Use Tools" [169]에서 저자는 LLM을 교육하여 언제 어떤 도구를 사용할지, API에 어떤 매개 변수가 필요한지 결정함으로써 단순한 도구 사용을 넘어섰다. 도구에는 두 개의 서로 다른 검색 엔진 또는 계산기가 포함됩니다. 다음 예제에서 LLM은 외부 Q&A 도구, 계산기 및 위키피디아 검색 엔진을 호출하기로 결정합니다. 최근 버클리의 연구자들은 구체적이지만 상당히 일반적인 도구인 API를 사용할 때 GPT-4를 능가하는 고릴라[67]라는 새로운 LLM을 훈련했습니다.

RAG로 설명한 것과 유사한 도구 인식 프롬프트 기술은 도구의 사용을 보다 확장 가능하게 하기 위해 여러 도구 인식 프롬프트 접근법이 개발되었다. 대표적인 기술로는 자동 다단계 추론 및 도구 사용(Automatic Multi-Step Reasoning and Tool-use, ART)이 있다.

자동 다단계 추론 및 도구 사용(ART) [170]은 자동화된 사고 프롬프트 체인과 외부 도구 사용을 결합하는 프롬프트 엔지니어링 기술이다. ART는 여러 신속한 엔지니어링 전략의 융합을 나타내며, 외부 데이터 소스 또는 도구와의 추론 및 상호 작용을 모두 필요로 하는 복잡한 작업을 처리하는 LLM(Large Language Models)의 능력을 향상시킨다.

ART는 태스크와 입력이 주어지면, 시스템이 먼저 태스크 라이브러리로부터 유사한 태스크들을 식별하는 체계적인 접근법을 포함한다. 그런 다음 이러한 작업을 프롬프트에서 예로 사용하여 현재 작업에 접근하고 실행하는 방법에 대해 LLM을 안내합니다. 이 방법은 작업이 내부 추론과 외부 데이터 처리 또는 검색의 조합을 필요로 할 때 특히 효과적이다.

### **LLM Agents**

AI 에이전트의 아이디어는 AI의 역사에서 잘 탐구되었습니다. 에이전트는 전형적으로 자신의 센서를 사용하여 환경을 지각하고, 현재 상태에 기초하여 판단을 내리고, 그에 따라 자신에게 이용 가능한 행동들에 기초하여 행동할 수 있는 자율 엔티티이다.

LLM의 맥락에서 에이전트는 특정 작업을 자율적으로 수행할 수 있는 (증강된) LL의 특수 인스턴스화에 기반한 시스템을 의미한다. 이들 에이전트는 입력 및 상호작용의 의도된 목표에 기초하여 결정을 내리기 위해 사용자 및 환경과 상호작용하도록 설계된다. 에이전트는 탑재된 LLM을 기반으로 합니다.

도. 37: 질의 응답 애플리케이션용 LLMs에 RAG를 합성하는 예[166].

도. 38: 리트리버로서 KG를 LLMs와 합성하는 하나의 예이다[167].

도구에 액세스하고 사용하고 주어진 입력에 따라 결정을 내릴 수 있습니다. 그들은 일반적으로 단순한 응답 생성을 넘어 어느 정도의 자율성과 의사 결정이 필요한 작업을 처리하도록 설계되었다.

일반 LLM-기반 에이전트의 기능들은 다음을 포함한다:

* 도구 액세스 및 활용: 에이전트는 외부 도구 및 서비스에 액세스하고 이러한 리소스를 효과적으로 활용하여 작업을 수행할 수 있는 기능을 가지고 있습니다.
* 의사 결정: 입력, 컨텍스트 및 사용자가 사용할 수 있는 도구를 기반으로 의사 결정을 내릴 수 있으며 종종 복잡한 추론 프로세스를 사용합니다.

일 예로, 날씨 API와 같은 함수(또는 API)에 접근할 수 있는 LLM은 특정 장소의 날씨와 관련된 어떠한 질문에도 답할 수 있다. 즉, 문제를 해결하기 위해 API를 사용할 수 있다. 더욱이, LLM이 구매를 가능하게 하는 API에 대한 액세스를 갖는다면, 구매 에이전트는 외부 세계로부터 정보를 판독할 수 있는 능력을 가질 뿐만 아니라 그것에 대해 행동할 수 있도록 구축될 수 있다[171].

도. 도 40은 대화 정보를 찾기 위한 LLM 기반 에이전트들의 또 다른 예를 도시한 도면[36]으로서, 여기서 LLM은 대화 상태를 추적하는 _워킹 메모리_, 작업에 대한 실행 계획을 세우고 다음 시스템 액션을 선택하는 _정책_, 정책에 의해 선택된 액션을 수행하는 _액션 실행기_(외부 지식으로부터 증거를 통합하거나 LLM을 프롬프트하여 응답을 생성함), 및 사용자 기대 또는 특정 비즈니스 요구 사항과 LLM 응답의 정렬에 액세스하고 피드백을 생성하여 에이전트 성능을 향상시키는 피드백을 생성한다.

LLM 기반 AI 에이전트에 대한 자세한 내용은 최근 조사[172, 173, 174]를 참조하십시오.

RAG 및 도구와 같은 에이전트에 대한 신속한 엔지니어링 기술, LLM 기반 에이전트의 요구를 구체적으로 해결하는 신속한 엔지니어링 기술이 개발되었다. 이러한 세 가지 예는 관찰 없는 추론(ReWOO), 이유 및 행위(ReAct), 대화 가능 해결 에이전트(DERA)이다.

관찰 없는 추론(ReWOO) [175]는 직접적인 관찰로부터 추론을 분리하는 것을 목표로 한다. ReWOO는 LLM이 외부 데이터나 도구에 즉시 의존하지 않고 포괄적인 추론 계획이나 메타 계획을 수립할 수 있도록 함으로써 작동한다. 이 접근법은 에이전트가 필요한 데이터 또는 관찰이 이용가능하면 실행될 수 있는 추론을 위한 구조화된 프레임워크를 생성할 수 있게 한다. ReWOO에서 LLM은 처음에 주어진 문제에 접근하고 해결하는 방법을 설명하는 계획(일련의 단계)을 개발한다. 이 메타 계획 단계는 에이전트가 정보를 사용할 수 있게 되면 정보를 처리할 수 있는 단계를 설정하기 때문에 중요합니다. 그 다음 실행 단계는 실제 데이터 또는 관찰을 미리 지정된 계획에 통합하여 일관되고 맥락적으로 관련된 응답으로 이어지는 것을 포함한다. ReWOO는 토큰 효율성과 도구 실패에 대한 견고성 측면에서 상당한 이점을 제공한다. 이를 통해 LLM은 외부 데이터에 대한 즉각적인 액세스를 사용할 수 없는 작업을 처리할 수 있으며, 대신 잘 구조화된 추론 프레임워크에 의존할 수 있습니다. 이 방법은 데이터 검색이 비용이 많이 들거나 느리거나 불확실한 시나리오에서 특히 유리하여 LLM 기반 에이전트가 높은 수준의 성능 및 신뢰성을 유지할 수 있게 한다.

이성과 행동(ReAct)[176]은 LLMs에게 언어적 추론뿐만 아니라 행동 가능한 단계를 생성하도록 촉구하여 모델의 동적 문제 해결 능력을 향상시킨다. ReAct는 추론과 행동을 통합하는 원리에 근거한다. 이 접근법에서, LLM은 인터리브 방식으로 추론 트레이스들(설명들)을 생성하는 것과 액션들(단계들 또는 명령들)을 취하는 것 사이에서 대체하도록 프롬프트된다. 이 접근법은 모델이 문제에 대해 동적으로 추론할 수 있게 하고, 동시에 구체적인 행동을 제안하고 취할 수 있게 한다.

대화 가능 해결 에이전트(Dialog-Enabled Resolving Agent,DERA) [177]은 대화형 교환을 기반으로 대화, 쿼리 해결 및 의사 결정을 수행할 수 있는 전문 AI 에이전트입니다. DERA는 각각 특정 역할과 기능을 가진 대화 컨텍스트 내에서 여러 에이전트를 활용하는 아이디어를 기반으로 개발된다. 이러한 에이전트에는 정보를 수집하고 분석하는 연구자와 제공된 정보를 기반으로 최종 판단을 내리는 결정자가 포함될 수 있다. 이러한 역할 분담은 문제 해결과 의사 결정에 대한 체계적이고 효율적인 접근을 가능하게 한다. DERA는 의료 진단 또는 고객 서비스와 같이 복잡한 의사 결정 및 문제 해결을 필요로 하는 시나리오에서 특히 유리하다. DERA 에이전트의 협력적이고 상호 작용하는 특성으로 인해 단일 에이전트 시스템이 어려움을 겪을 수 있는 깊이 및 뉘앙스 수준의 복잡한 쿼리를 처리할 수 있다. 또한, 이 접근법은 인간의 의사 결정 프로세스와 잘 일치하여 AI 추론을 더 공감하고 신뢰할 수 있게 만든다.

## V Popular Datasets for LLMs

대형 언어 모델은 유망한 성과를 보여주지만, 발생하는 주요 질문은 그들이 얼마나 효과적으로 기능하고 특정 작업이나 애플리케이션에서 성능을 평가할 수 있는지이다.

LLM의 평가는 애플리케이션의 진화하는 풍경으로 인해 특정 문제를 제기한다. LLM 개발의 원래 목적은 번역, 요약, 질의 응답 등과 같은 NLP 작업의 성능을 향상시키는 것이었다[178]. 그러나 오늘날 이러한 모델이 코드 생성 및 금융을 포함한 다양한 도메인에서 유용성을 찾고 있음이 분명하다. 더욱이 LLM의 평가는 공정성과 편견, 사실 확인, 추론과 같은 몇 가지 중요한 고려 사항을 포함한다. 이 섹션에서는 LLM을 평가하기 위해 일반적으로 사용되는 벤치마크를 설명한다. 이러한 벤치마크는 교육 또는 LLM 능력 평가에 따라 분류됩니다.

### _기본 작업에 대 한 데이터 세트: 언어 모델링/이해/generation_

이 섹션에서는 LLM의 기본 능력을 평가하는 데 적합한 벤치마크 및 데이터 세트에 대한 개요를 제공합니다.

* **내추럴 쿼리**[179]는 질문으로 Google 검색 엔진에 제출 된 실제 익명화 된 집계 된 쿼리로 구성 된 QA 데이터 세트입니다. 주석자는 상위 \(5\) 검색 결과에서 위키피디아 페이지와 함께 질문을 제시하며, 페이지에 존재하는 경우 긴 답변(일반적으로 문단)과 짧은 답변(하나 이상의 엔티티)에 주석을 달거나, 긴/짧은 답변이 없는 경우 null로 표시한다.
* **MMLU**[180]은 zero-shot 및 few-shot 시나리오에서 얻은 지식을 평가 하기 위한 것입니다. 이는 MMLU가 모델의 일반적인 지식과 문제 해결 능력을 모두 평가한다는 것을 의미한다. STEM, 인문, 사회과학 및 기타 분야의 57개 과목을 다루고 있습니다. 벤치마크는 초등에서 고급 전문가에 이르기까지 복잡성이 다양하다. 이 데이터 세트의 주요 기여는 다중 작업 언어 이해, 질문 응답 및 산술 추론에 있다는 점을 언급할 가치가 있다.
* **MBPP**[181]은 "대부분 기본 Python 문제"의 약자이며 코드 생성을 위해 설계된 모델의 성능을 평가하기 위한 벤치마크를 제공합니다. 벤치마크는 기본 프로그래밍 개념 및 표준 라이브러리 사용 등 광범위한 주제를 포함하는 \(974\) 짧은 파이썬 프로그램을 포함한다. 각 챌린지는 작업 설명, 코드 솔루션 및 3개의 자동화된 테스트 케이스로 구성됩니다.
* **HumanEval**[182]는 코드 생성 작업에 대 한 데이터 집합입니다. 이 데이터 세트는 \(164\) 손으로 만든 프로그래밍 문제로 구성됩니다. 각 챌린지에는 함수 서명, docstring, 코드 본문 및 여러 단위 테스트가 동반됩니다. 이 데이터 세트를 개발하는 주요 직관은 코드 생성 모델을 위한 훈련 데이터 세트에서 해당 콘텐츠의 배제를 보장하는 것이다.
* **APPS**[183]은 Python 프로그래밍 언어에 초점을 맞춘 코드 생성 작업을 위해 설계되었습니다. APPS 데이터 세트에는 \(232,444\) Python 프로그램 컬렉션이 포함되어 있습니다. 데이터 세트의 각 프로그램에는 평균 \(18\) 줄의 Python 코드가 있습니다. 또한, APPS는 각각 텍스트 기반 문제 설명이 포함된 \(10,000\) 고유 프로그래밍 연습의 리포지토리에 대한 액세스를 제공합니다. 마지막으로 강조할 점은 테스트 케이스를 포함한다는 것입니다.
* **WikiSQL**[184]는 코드 생성 작업을 위해 만들어졌으며 위키피디아 테이블에서 87,726개의 신중하게 레이블이 지정된 SQL 쿼리 쌍 및 해당 자연어 질문이 있습니다. SQL 쿼리는 테스트 세트(\(17,284\) 예), 개발(\(9,145\) 예) 및 훈련(\(61,297\) 예)의 세 가지 하위 집합으로 구성된다.
* **TriviaQA**[185]는 QA 작업을 위해 설계되었습니다. 이 데이터 세트는 \(650,000\) 이상의 질문-응답-증거 트리플을 포함한다. 이 데이터 세트에는 \(95,000\)개의 질문-응답 쌍이 있으며, 각각은 퀴즈 애호가들에 의해 작성되고 평균 6개의 독립적으로 출처된 증거 문서에 의해 지원된다. 이러한 문서는 위키피디아 또는 광범위한 웹 검색 결과에서 자동으로 획득됩니다. 데이터세트는 위키피디아와 웹 도메인의 정답을 포함하는 두 개의 세그먼트로 분류되며, 검증된 세트는 위키피디아와 온라인의 관련 문서와 함께 정확하게 답한 질문을 구현한다.

도. 40: 대화 정보 탐색을 위한 LLM 기반 에이전트. [36]의 예절.

도. 39: HuggingGPT: 도구를 사용하고 읽기 이해 작업을 위한 [이미지 예절 [171]]* **RACE**[186] 슈트를 계획하는 에이전트 기반 접근법입니다. 이 데이터 세트는 중학교와 고등학교의 중국 학생들이 작성한 영어 테스트를 기반으로 하며, 주로 영어 강사인 인간 전문가에 의해 엄격하게 준비된 대략적인 \(28,000\) 텍스트와 \(100,000\) 질문을 포함한다. 이 데이터 세트에는 학생들의 이해력과 추론 능력을 평가하기 위해 의도적으로 선택된 광범위한 과목이 포함되어 있다. 이 데이터 세트는 RACE-M, RACE-H 및 RACE의 세 하위 그룹에서 사용할 수 있습니다. RACE-M은 중학교 시험을 의미하는 반면, RACE-H는 고등학교 시험을 의미한다. 마지막으로, RACE는 RACE-M과 RACE-H의 합성이다.
* **SQuAD**[187]은 "Stanford Question Answering Dataset"의 약자이며 위키피디아 기사를 기반으로 하는 크라우드소싱 읽기 이해 데이터 세트입니다. 이는 약 \(100,000\)의 질의응답 쌍이 \(500\) 이상의 논문에 연결되어 있다. 이러한 질문들에 대한 답변들은 전형적으로 대응하는 판독 패시지들로부터 취해진 텍스트 단편들 또는 스팬들이다. 그 질문들은 어떤 경우에는 대답할 수 없을 수도 있다. 데이터 세트는 \(80\%\) 훈련 세트, \(10\%\) 개발 세트 및 \(10\%\) 숨겨진 테스트 세트의 세 세 세 세트로 나뉜다.

도. 41: 데이터셋 어플리케이션.

* **BoolQ**[188]은 목표가 읽기 이해 작업인 예/아니오 질문 응답 데이터 세트입니다. BoolQ는 \(15,942\)의 예를 포함한다. 각 예는 질문, 관련 단락 및 솔루션을 포함하는 트리플렛이다. 이 데이터 세트의 이면에 있는 주요 직관은 독해이지만 추론, 자연어 추론 및 질의 응답 작업에 사용할 수 있다.
* **MultiRC**[189]는 읽기 이해 작업에 맞는 또 다른 데이터 세트입니다. 멀티RC는 단락의 정보를 이용하여 답할 수 있는 다문장 질문뿐만 아니라 간략한 단락이 포함되어 있다. 이 데이터 세트의 단락은 뉴스, 소설, 역사 텍스트, 위키피디아 기사, 사회와 법에 대한 토론, 초등학교 과학 교과서 및 9/11 보고서를 포함한 다양한 출처에서 비롯된다. 각 질문에는 하나 이상의 정답이 있는 많은 응답 선택이 있습니다. 질문에 답하려면 여러 문장에 걸쳐 추론이 필요합니다. 다중RC 데이터 세트는 800개 이상의 단락에서 수집된 약 6,000\의 다중 문장 질문을 포함한다. 평균적으로, 각 질문은 총 5개 중 2개의 유효한 답변 대안을 제공한다.

### _Datasets for Emergent: ICL, reasoning (CoT), instruction following_

이 섹션에서는 LLM의 새로운 능력을 평가하는 데 사용된 벤치마크 및 데이터 세트에 중점을 둔다.

* **GSM8K**[190]은 다단계 수학적 추론을 위한 모델의 능력을 평가하도록 설계되었습니다. GSM8K는 언어적으로 인간이 쓴 8.5K의 다양한 초등학교 수학 단어 문제를 포함한다. 데이터 세트는 \(7.5K\) 문제가 있는 훈련 세트와 \(1\)K 문제가 있는 테스트 세트로 나뉜다. 이러한 문제를 해결하기 위해서는 \(2\) ~ \(8\) 단계가 필요하다. 솔루션은 주로 기본 사칙연산을 이용한 일련의 기본 연산이다.
* **MATH**[191]을 사용하면 모델이 수학 문제를 얼마나 잘 해결할 수 있는지 평가할 수 있습니다. MATH 데이터 세트는 고등학교 수학 경시대회에서 나온 마지막 \(12\), \(500\) 문제이다. 데이터 세트의 각 문제에는 단계별 솔루션과 최종 답변이 상자에 동봉되어 있습니다. 그 문제들은 광범위한 주제를 다루며 복잡성의 수준이 다르다. 총 7개의 과목이 있습니다. 또한, 각 문제의 난이도는 AoPS 표준에 따라 \({}^{\prime}1^{\prime}\)에서 \({}^{\prime}5^{\prime}\)까지의 척도로 평가된다. ({}^{\prime}1^{\prime}\)가 가장 쉬운 문제이고, ({}^{\prime}5^{\prime}\)가 가장 어려운 문제이다. 포맷팅 측면에서는 LATEX와 Asymptote 벡터 그래픽 언어를 사용하여 모든 문제와 해결책을 제시한다.
* **HellaSwag**[192]는 LLM에서 상식 추론을 평가하도록 설계되었습니다. 이 벤치마크에는 \(70,000\) 객관식 질문이 포함됩니다. 각 질문은 ActivityNet 또는 WikiHow의 두 도메인 중 하나에서 파생되며 다음 상황에서 발생할 수 있는 문제에 대한 네 가지 답변 선택을 제시한다. 상기 정답은,

도. 42: 서로 다른 라이선스에서 라이선스된 데이터 세트.

다음 사건이지만, 세 가지 오답은 기계를 혼란스럽게 만들기 위해 만들어집니다.
* **AI2 추론 챌린지(ARC)**[193]는 상식 추론에 사용됩니다. 이 벤치마크는 \(7,787\) 과학 시험 문제를 포함한다. 이러한 문항은 영어로 되어 있으며, 대부분 객관식 형식으로 설정되어 있다. 그 결과, '어려운 문제'와 '쉬운 문제'가 각각 5,197문항으로 분류되었다. 각 컬렉션은 열차, 개발 및 테스트 하위 집합으로 사전 분할되었습니다.
* **PIQA**[194]는 물리적 상식에 대한 지식에 대한 언어 표현을 평가하기 위한 것입니다. 이 데이터 세트에서는 흔하지 않은 솔루션을 선호하는 일상적인 상황에 초점을 맞춥니다. 중심 과제는 객관식 질문 응답이며, 여기서 질문 \((q)\)은 두 개의 잠재적인 해결책 \((s1,s2)\와 함께 제공된다. 그런 다음 모델인지 인간인지에 따라 최상의 솔루션을 선택합니다. 각 질문에 대한 정답은 오직 하나의 해답일 뿐이다.
* **SIQA**[195]는 사회적 상황에 대한 상식 추론에 대한 모델의 능력을 평가하기 위한 프레임워크를 제공합니다. SIQA 데이터 세트에는 일상적인 환경에서 감정 및 사회적 지능을 평가하기 위해 고안된 3만 8천 개의 객관식 질문이 있다. 이 데이터 세트는 다양한 소셜 시나리오를 다룹니다. SIQA에서 잠재적인 답변은 적대적 과정을 통해 필터링된 인간이 선택한 응답과 기계가 생성한 응답의 혼합이다.
* **OpenBookQA(OBQA)**[196]은 질문에 답하려면 책에 포함되지 않은 추가 공통 및 상식 지식과 풍부한 텍스트 이해가 필요한 새로운 유형의 질문 답변 데이터 세트입니다. 이 데이터 세트에는 약 6,000개의 객관식 질문이 포함되어 있습니다. 각 질문은 하나의 핵심 사실과 \(6000\) 이상의 사실의 추가 수집과 연결된다. 다단계 크라우드소싱과 전문가 필터링 절차를 사용하여 질문을 개발했다. OpenBookQA 문항은 배경이 제한된 멀티홉 추론이 필요하기 때문에 난이도가 높다.
* **TruthfulQA**[197]은 질문에 대한 답변을 생성할 때 언어 모델의 진실성을 평가하기 위해 특별히 설계되었습니다. 이 데이터 세트에는 건강, 법률, 재정 및 정치를 포함한 다양한 범주에서 \(38\)의 저자가 작성한 817개의 질문이 포함된다. 이러한 질문은 오답으로 이어지는 일반적인 오해를 포함할 수 있기 때문에 의도적으로 인간 응답자에게 도전하기 위해 고안되었다.
* **OPT-IML 벤치**[103]은 Instruction Meta-Learning에 대한 포괄적인 벤치마크입니다. 기존 8개의 벤치마크에서 2000개의 NLP 작업을 포함합니다. OPT-IML Bench는 17.9 M의 예제들을 가진 훈련 세트, 145K 샘플들을 가진 dev 세트, 321K 샘플들을 가진 테스트 세트로 구성된다.

### _증강용 데이터 세트: 외부 지식/tools_ 사용

이 섹션에서는 LLM의 향상된 기능을 위해 설계된 데이터 세트에 중점을 둡니다.

* **HotpotQA**[198]은 다중 홉 추론이 필요한 다양하고 설명 가능한 질문 응답 데이터 세트를 포함하도록 설계되었습니다. 이 데이터 세트는 영어 위키피디아에서 파생됩니다. 그것은 대략 \(113,000\)의 질문들로 구성되어 있다. 데이터 세트의 각 질문은 두 개의 위키피디아 기사에서 골드 단락이라고 하는 두 개의 단락과 함께 제공된다. 또한, 크라우드 워커가 질문에 답하는 데 중요한 것으로 선택한 문단에는 문장 목록이 있습니다.
* **ToolQA**[199]는 질문에 답하기 위해 외부 도구를 사용하는 LLMs의 기능을 평가하기 위한 질문 답변 벤치마크입니다.
* **GPT4Tools** 는 고급 교사 (예: Chat-GPT)에게 지시 하 여 생성 된 교육 데이터 세트 역할을 하며 지침은 시각적 콘텐츠 및 도구 설명에 제한 됩니다. 이러한 과정은 도구 사용과 관련된 명령어 생성으로 귀결된다. 이 데이터 세트에는 세 가지 버전이 있습니다. 첫 번째 버전은 GPT4Tools 모델을 미세 조정하는 데 사용되는 71,000개의 명령어 후속 데이터 포인트로 구성된다. 다음 버전은 검증에 사용되는 수동으로 세척된 명령 데이터로 구성되며, 첫 번째 버전의 도구와 관련된 명령을 포함합니다. 마지막 버전은 테스트에 사용되는 정리된 명령어 데이터이며 첫 번째 버전에는 없는 일부 도구와 관련된 명령어를 포함한다.

## VI Prominent LLMs의 벤치마크 성능

이 섹션에서는 먼저 다양한 시나리오에서 LLM의 성능을 평가하는 데 사용되는 몇 가지 인기 있는 메트릭에 대한 개요를 제공한다. 그런 다음 인기 있는 데이터 세트와 벤치마크 중 일부에서 두드러진 대형 언어 모델의 성능을 살펴본다.

### _Popular Metrics for Evaluation LLMs_

생성 언어 모델의 성능을 평가하는 것은 그들이 사용할 기본 작업에 달려 있다. 주로 주어진 것 중 선택을 선택하는 것(감정 분석 등)에 관한 작업은 분류처럼 단순하다고 볼 수 있으며 분류 메트릭을 사용하여 성능을 평가할 수 있다. 이 경우 정확도, 정밀도, 재현율, F1 등의 메트릭이 적용 가능하다. 또한 객관식 질문 답변과 같은 특정 작업에 대해 모델에 의해 생성된 답변은 항상 참 또는 거짓 중 하나라는 점에 유의하는 것이 중요하다. 답이 선택지 집합에 없다면 거짓으로도 볼 수 있다.

그러나 순수하게 개방형 텍스트 생성인 일부 작업은 범주화와 같은 방식으로 평가할 수 없다. 평가의 특정 목적을 위해 다양한 측정 기준이 필요합니다. 코드 생성은 개방형 생성 평가에서 매우 다른 경우이다. 생성된 코드는 테스트 제품군을 통과해야 하지만 모델이 코드로서 서로 다른 솔루션을 생성할 수 있는지, 그 중 올바른 솔루션을 선택할 확률은 얼마인지 이해하는 것도 중요하다. Pass@k는 이 경우에 매우 좋은 메트릭이다. 문제가 주어지면 코드와 같은 다양한 솔루션이 생성되는 방식으로 작동합니다. 다양한 기능 테스트를 사용하여 정확성을 테스트합니다. 그 후, 솔루션에서 생성되고 그 각각의 c 번호가 올바른 방정식 4가 최종 값을 제공한다.

\[\text{pass@}k:=\underset{\text{Problems}}{\mathbb{E}}\left[1-\frac{\binom{n-c}{k}}{\binom{n}{k}}\right] \tag{4}\

정확한 일치(EM)는 대부분 (미리 정의된) 답변의 정확한 일치와 관련된 또 다른 메트릭이다. 토큰별로 둘 이상의 원하는 참조 텍스트 토큰 중 하나와 정확히 일치하는 경우 예측이 올바른 것으로 계산됩니다. 경우에 따라 정확도와 동일할 수 있으며 식 5는 수학적 정의를 보여준다. 여기서 M은 총 정답 수이고 N은 총 질문 수이다[202].

\[EM=\frac{M}{N} \tag{5}\]

한편, 인간 동등성 점수(HEQ)는 F1 점수에 대한 대안이다[203]. HEQ-Q는 개별 질문의 정밀도를 나타내며, 모델의 F1 점수가 평균 인간 F1 점수를 초과하는 경우 정답이 올바른 것으로 간주된다. 마찬가지로, HEQ-D는 각 대화의 정밀도를 나타내며, 대화 내의 모든 질문이 HEQ[182]의 기준을 충족할 때 정확하다고 간주된다.

기계 번역과 같은 다른 생성 작업의 평가는 Rouge 및 BLEU와 같은 메트릭을 기반으로 한다. 이 점수는 사실(번역 등)과 생성 모델에 의해 생성되는 가설인 참조 텍스트가 있는 경우 LLM에서 잘 작동한다. 이러한 스코어들은 대부분 계산 방식으로 답변과 그라운드 트루스의 유사성을 검출하는 것이 목표인 경우에 사용된다. 계산 방식으로, 그것은 N-Grams만이 사용될 것이라는 것을 의미했다. 그러나 BERT-Score와 같은 메트릭도 이러한 경우에 좋지만 또한 무겁다.

\begin{table}
\begin{tabular}{|l|l|l|l|l|} \hline
**Benchmark Name** & **Evaluation Metric** & **Leaderboard** & **Source** & **paperswithcode** \\ \hline HumanEval & Pass@k & Link & Link & Link \\ \hline MBPP & Pass@k, Accuracy & - & Link & Link \\ \hline APPS & Pass@k, Accuracy & - & Link & Link \\ \hline WikiSQL & Accuracy & - & Link & Link \\ \hline CoNLA & BLEU & Link & Link \\ \hline CodeParrot & Pass@k & - & Link & - \\ \hline HellaSWang & Accuracy & Link & Link & Link \\ \hline AI2 & Reasoning & Accuracy & Link & Link \\ Challenge (ARC) & Accuracy & Link & Link & Link \\ \hline BoolQ & Accuracy & - & Link & Link \\ \hline MultiRC & F1-score, Accuracy & - & Link & Link \\ \hline CNN/Daily Mail [200] & Accuracy & - & Link & - \\ \hline SQuAD & F1-score, EM & Link & Link & Link \\ \hline RAC & Accuracy & - & Link & Link \\ \hline CNN/Daily Mail [201] & ROUGE & - & Link & Link \\ \hline Drop & F1-score, EM & Link & Link & Link \\ \hline QuAC: & F1-score, HEQ-Q, HEQ-D & Link & Link & Link \\ \hline TriviaQA & EM, F1-score, Accuracy & Link & Link & Link \\ \hline Natural Questions & EM, F1-score, Accuracy & Link & Link & Link \\ \hline StrategyQA & Accuracy, Recall@10, SARI & Link & Link & Link \\ \hline CoQA & F1-score & Link & Link & Link \\ \hline XSum & ROUGE & - & Link & Link \\ \hline SAMSun & ROUGE & - & Link & Link \\ \hline WikiSum & ROUGE & - & Link & - \\ \hline DialogSum & ROUGE & - & Link & Link \\ \hline TruthIUQA & MCI, MC2, \% true, \% info, BLEU/RT & Link & Link & Link \\ \hline MMLU & Accuracy & Link & Link & Link \\ \hline GSM8K & Accuracy & Link & Link & Link \\ \hline PIQA & Accuracy & Link & Link & Link \\ \hline SIQA & Accuracy & Link & Link & Link \\ \hline OpenBookQA (OBQA) & Accuracy & Link & Link & Link \\ \hline HotopQA & EM, F1-score, Joint EM, Joint F1-score, & Link & Link & Link \\ \hline MATH & Accuracy & - & Link & Link \\ \hline CommonseQA & Accuracy & Link & Link & Link \\ \hline Natural Instructions & ROUGE-L, Human & Link & Link & Link \\ \hline BIG-bench & Accuracy, Average & - & Link & Link \\ \hline ToolTalk & Success rate, Precision, Recall, Incorrect & - & Link & Link \\ \hline MetaTool & Accuracy, Precision, Recall, F1-score & - & Link & Link \\ \hline GPT4Tools & Successful Rate of Thought, Successful Rate of Action, Successful Rate of Arguments, Success Rate & - & Link & Link \\ \hline API-Bank & Correctness, ROUGE, Error(API Hallution, Has Exception, Invalid Input Parameters, False API Call Format, API Call, Miss Input Parameters) & - & Link & Link \\ \hline Alpaca-CoT & - & - & Link & Link \\ \hline \end{tabular}
\end{table} TABLE II: LLM Datasets Overview.

다른 모델이 판단하는데 사용되기 때문에 비도덕적이다. 여전히, 오늘날에도, 순수하게 생성된 콘텐츠를 평가하는 것은 매우 어렵고 완전히 피팅되는 메트릭이 발견되지 않고, 메트릭들은 N-Gram, SkipGram 등과 같은 단순한 특징들을 찾고 있거나, 또는 알려지지 않은 정확성 및 정밀성을 갖는 모델들이다[204].

생성 평가 메트릭은 또한 답변을 평가하기 위해 또 다른 LLM을 사용하는 LLM에 대한 또 다른 유형의 평가 메트릭이다. 다만, 과제 자체에 따라 이와 같이 평가가 가능할 수도 있고 그렇지 않을 수도 있다. 생성 평가 오류를 쉽게 만드는 또 다른 종속성은 프롬프트 자체에 의존하는 것이다. RAGAS는 생성 평가의 사용을 통합하는 좋은 예 중 하나이다.

대형 언어 모델의 세계에서 가장 어려운 문제를 해결하기 위해 다양한 벤치마크와 리더보드가 제안되었습니다: 어떤 것이 더 나은가요? 그러나 간단한 대답은 이 문제를 해결할 수 없다. 대답은 대형 언어 모델의 다양한 측면에 달려 있습니다. 섹션 V는 서로 다른 작업의 범주적 표현과 각 범주에서 가장 중요한 데이터 세트를 보여준다. 우리는 동일한 분류를 따르고 각 범주에 따른 비교를 제공할 것이다. 각 범주에 대한 비교를 제공한 후 서로 다른 작업에 대해 보고된 성능 메트릭을 평균화하여 집계된 성능에 대한 광범위한 개요를 제공합니다.

다른 LLM을 평가하는 것은 다른 관점에서도 볼 수 있다. 예를 들어, 매개변수 수가 급격히 적은 LLM은 매개변수 수가 더 많은 LLM과 완전히 비교할 수 없다. 이러한 관점에서 LLM은 **작은**(10억 매개 변수 이하), **중간**(10억에서 100억 사이), **큰**(10억에서 1000억 사이) 및 **매우 큰**(1000억 이상)의 네 가지 범주로 분류할 것입니다. 우리가 사용하는 LLMs에 대한 또 다른 분류는 그들의 주요 사용 사례이다. 각 LLM은 **Foundation** 모델(명령 미세 조정 및 채팅 미세 조정이 없는 사전 학습된 언어 모델), **명령** 모델(명령 미세 조정만 있는 사전 학습된 언어 모델) 및 **채팅** 모델(명령 및 채팅 미세 조정이 있는 사전 학습된 언어 모델) 중 하나로 간주됩니다. 설명된 모든 범주화 외에도 원래 모델과 조정된 모델을 구별하기 위해 다른 범주가 필요하다. **원본** 모델은 기초 모델 또는 미세 조정 모델로 출시된 모델입니다. **튜닝** 모델은 원래 모델을 파악하고 다른 데이터 세트 또는 심지어 다른 훈련 접근 방식으로 튜닝한 모델입니다. 원본 모델은 일반적으로 특정 데이터 세트 또는 심지어 다른 접근법에 대해 미세 조정된 기초 모델이라는 점에 주목하는 것도 좋다. 라이선스에 관계없이 모델 가중치의 가용성은 분류의 또 다른 범주이다. 중량이 공개적으로 사용 가능한 모델(요청을 통해서도)은 **공용** 모델로 표시되고 다른 모델은 **개인**으로 표시됩니다. 표 III은 나머지 기사에서 사용된 이러한 정의 및 약어를 모두 보여준다. 도 43은 이들을 시각적으로 도시한 것이다.

제공된 분류에 따라 표 IV와 같이 각 주목할만한 LLM을 분류하고 레이블을 지정할 수 있다. 이 표에서 볼 수 있듯이 매우 큰 것으로 분류된 모델도 사용할 수 없다.

### _LLMs' Performance on Different Tasks_

상식 추론은 각 모델이 얻을 수 있는 중요한 능력 중 하나이다. 이 능력은 추론 능력과 결합하여 사전 지식을 사용할 수 있는 모델의 능력을 나타낸다. 예를 들어, HellaSwag의 경우, 텍스트의 연속을 찾는 것은 어려운데, 왜냐하면 주어진 텍스트는 스토리의 일부를 포함하는 반면 연속으로서 주어진 선택들은 선택하기 까다롭고, 사전이 없기 때문이다.

\begin{table}
\begin{tabular}{|l|l|l|l|l|l|} \hline Model & Size & \#Params (B) & Type & Availability & Origin \\ \hline Davinci-002 & Very Large & 175 & Instruction & Unavailable & Tuned \\ \hline Davinci-003 & Very Large & 175 & Instruction & Unavailable & Tuned \\ \hline GPT 3.5-turbo & Large & 20 & Chat & Unavailable & Tuned \\ \hline Falcon 7B & Medium & 7 & Foundation & Public & Original \\ \hline Alpaca & Large & 13 & Chat & Public & Tuned \\ \hline Pythia 7B & Medium & 7 & Foundation & Public & Original \\ \hline Pythia 12B & Large & 12 & Foundation & Public & Original \\ \hline LLAMA 7B & Medium & 7 & Chat & Public & Original \\ \hline LLAMA 2 7B & Medium & 7 & Chat & Public & Tuned \\ \hline LLAMA 2 7B & Medium & 7 & Foundation & Public & Original \\ \hline Vicuna 13B & Large & 13 & Foundation & Public & Tuned \\ \hline Vicuna 7B & Medium & 7 & Foundation & Public & Tuned \\ \hline Claude & Large & 93 & Chat & Unavailable & Original \\ \hline Claude 2 & Very Large & 137 & Chat & Unavailable & Original \\ \hline \end{tabular}
\end{table} TABLE IV: Different LLM categorization.

\begin{table}
\begin{tabular}{|l|l|l|} \hline Classification & Category & Description \\ \hline \multirow{3}{*}{Size} & Small & Number of parameters \(\leq\) 1B \\ \cline{2-3}  & Medium & 1B \(<\) Number of parameters \(\leq\) 10B \\ \cline{2-3}  & Large & 100B \(<\) Number of parameters \(\leq\) 100B \\ \cline{2-3}  & Very Large & 100B \(<\) Number of parameters \\ \hline \multirow{3}{*}{Type} & Foundation model & Pretrained language model \\ \cline{2-3}  & Instruction model & Pretrained and instruction fine-tuned language model \\ \cline{2-3}  & Chat model & Pretrained, instruction fine-tuned, and chat fine-tuned language model \\ \hline \multirow{2}{*}{Origin} & Original model & An original model released with either Foundation, Instruction, or Chat model \\ \cline{2-3}  & Tuned model & Fine-tuned version of an original model \\ \hline \multirow{2}{*}{Availability} & Publicly available & Model and weights are available due to request to without request \\ \cline{2-3}  & Publicly unavailable & Model and weights are not publicly available \\ \hline \end{tabular}
\end{table} TABLE III: LLM categories and respective definitions.

세상에 대한 지식은 가능하지 않다. 이러한 특정 유형의 추론은 공개된 텍스트 서술 장면이나 사실로 이전의 지식을 활용하는 것과 관련이 있기 때문에 높은 관심을 받을 만하다. 표 V에서 볼 수 있듯이 Unavailable 모델뿐만 아니라 Public 모델도 다양한 테스트에서 좋은 결과를 얻을 수 있다.

표 V에 제시된 결과에서 GPT-4가 헬라스웨그에 대해 최상의 결과를 달성하는 반면 다빈치-003은 OBQA에 대해 최상의 모델임이 분명하다. OBQA에 대한 결과가 모든 모델에 대해 보고되지 않으며 다빈치-003이 OBQA에서 가장 높은 결과를 달성하는 최상의 모델이 아니라는 점에 주목하는 것도 좋다.

모든 모델이 모든 데이터 세트에 대한 성능을 보고하는 것은 아니며, 그 때문에 성능이 다른 테이블에서 보고되는 모델의 수가 다르다.

세계 지식은 대부분 일반적인 지식 질문에 관한 것으로, 예를 들어 위키팩트 데이터 세트에서 "특정 잘 알려진 책의 저자는 누구인가"와 같은 질문을 찾을 수 있고 참고 문헌도 제공된다. 결과를 표 VII에 나타낸다.

\begin{table}
\begin{tabular}{|l|l|l|} \hline Model & OBQA & HellaSwag \\ \hline Davinci-003 & **51** & 83.4 \\ \hline Falcon 7B & 44.4 & 76.3 \\ \hline Alpaca & 43.4 & 73.9 \\ \hline Pythia 7B & 37.2 & 64 \\ \hline Pythia 12B & 43.2 & 68.1 \\ \hline LLAMA 7B & 42.4 & 73 \\ \hline Dolly 6B & 41.2 & 67.6 \\ \hline Dolly 12B & 40.4 & 71 \\ \hline Alpaca 7B & 43.4 & 73.9 \\ \hline Alpaca Lora 7B & 42.6 & 74 \\ \hline GPT-6 7B & 38.2 & 66.2 \\ \hline LLAMA 7B & 42.4 & 73 \\ \hline LLAMA 13B & 42.2 & 76.2 \\ \hline Pythia 7B & 37.2 & 64 \\ \hline Pythia 12B & 38 & 67.3 \\ \hline StableLM Tuned & 33.4 & 53.6 \\ \hline Koula 13B & 42.8 & 72.6 \\ \hline Moisea pipel-7B & 42.6 & 76.3 \\ \hline \hline LLAMA 20B & - & 87.33 \\ \hline LLAMA 65B & - & 86.09 \\ \hline Falcon 40B & - & 85.3 \\ \hline Falcon 180B & - & 88.36 \\ \hline MPT Insitract 30B & - & 84.31 \\ \hline MPT Insitract 7B & - & 77.91 \\ \hline Yi 6B & - & 76.42 \\ \hline Yi 34B & - & 85.69 \\ \hline GPT-4 & - & **95.3** \\ \hline Gemini Ultra & - & 87.8 \\ \hline \end{tabular}
\end{table} TABLE V: Commonsense reasoning comparison.

\begin{table}
\begin{tabular}{|l|l|l|} \hline Model & Objects & Penguins \\ \hline GPT-NeoX & 26 & 33.56 \\ \hline OPT 66B8 & 31.2 & 28.08 \\ \hline Bloomberg GPT & 34.8 & 37.67 \\ \hline BLOOM 176B & 36.8 & 40.41 \\ \hline PJM 540B & 38 & 44.5 \\ \hline Gopher-280B & 49.2 & 40.6 \\ \hline Chinchilla-70B & 59.7 & 48.7 \\ \hline PuLM 2 & 61.2 & 65.8 \\ \hline \end{tabular}
\end{table} TABLE VI: Symbolic reasoning comparison.

도. 43: LLM 분류.

특정 유스케이스 모델의 경우, 코딩 및 코드 생성 기능을 갖는 것이 매우 요구된다. 표 VIII는 코딩 능력에 대한 다양한 모델의 결과를 보여준다.

산술 추론은 달성해야 할 또 다른 도전적인 추론 능력이다. 예를 들어 GSM8K는 답과 관련하여 초등학교 수학 문제를 포함한다. 표 IX는 다양한 모델 비교에 대한 통찰력을 제공한다.

대형 언어 모델은 단순히 다음 토큰 예측 기계이기 때문에 환각적인 답변을 하는 경우도 있다. 환각은 큰 언어 모델이 얼마나 신뢰할 수 있고 신뢰할 수 있는지를 측정하는 중요한 요소 중 하나이다. 다른 한편으로 환각을 측정하는 것은 각각의 사실이 다른 스타일로 쓰여질 수 있고 심지어 글의 작은 변화조차도 감지하기 어렵게 만들기 때문에 보기 때문에 쉽지 않다. 특정 LLM이 텍스트에서 잘못된 정보의 환각을 감지할 수 있는 능력이 더 있다면 더 신뢰할 수 있다고 가정하는 것이 옳다. HaluEval은 이 분야의 환각을 측정하는 것을 목표로 하는 데이터 세트 중 하나이다[205]. 평가는 또한 실제 답변과 관련하여 응답을 판단하는 다른 모델에 의해 수행될 수 있다[206]. 표 X는 이러한 데이터 세트를 기반으로 한 다양한 모델의 평가를 보여준다.

## VII 문제 및 미래 방향

이전 섹션에서 보았듯이 대형 언어 모델은 지난 1-2년 동안 인상적인 결과를 달성했다.

\begin{table}
\begin{tabular}{|l|l|l|} \hline Model & GSM8k & MATH \\ \hline Gemini Ultra & 94.4 & 53.2 \\ \hline GPT-4 & 87.1 & 42.5 \\ \hline Gemini Pro & 86.5 & 32.6 \\ \hline ToRA 70B & 84.3 & 49.7 \\ \hline MatchCoder-L-70B & 83.9 & - \\ \hline MetaMM 70B & 82.3 & 26 \\ \hline MuggelMATH 70B & 82.3 & - \\ \hline MatchCoder-L-34B & 81.7 & 45.2 \\ \hline ToRA-Code 34B & 80.7 & 50.8 \\ \hline MetaMath-Mistral-7B & 77.7 & - \\ \hline Arithm2-Mistral-7B & 76.4 & - \\ \hline ToRA-Code 13B & 75.8 & 48.1 \\ \hline Arithmo-Mistral-7B & 74.7 & - \\ \hline MatchCoder-L-13B & 74.1 & 35.9 \\ \hline MuggelMATH 13B & 74. & - \\ \hline CodeT5+ & 73.8 & - \\ \hline Kavai YuMish 13B & 73.3 & - \\ \hline ToRA-Code 7B & 72.6 & 44.6 \\ \hline MathlCoder-L-13B & 72.6 & 29.9 \\ \hline Metahali 13B & 71 & 22.5 \\ \hline LMAM 65B & 69.7 & 10.6 \\ \hline MuggelMATH 7B & 68.4 & - \\ \hline MatchCoder-CL-7B & 67.8 & 23.3 \\ \hline MetaMM 7B & 66.4 & 19.4 \\ \hline RFT 70B & 64.8 & - \\ \hline MatchCoder-T-7B & 64.2 & - \\ \hline Orca -21B & 59.14 & - \\ \hline U-PalM & 58.5 & - \\ \hline PalM-540B & 58.1 & 8.8 \\ \hline LLAMA 2 70B & 56.8 & - \\ \hline RFT 13B & 53.3 & - \\ \hline LiLMA 33B & 53.1 & 7.1 \\ \hline Mistral 7B & 52.2 & 13.1 \\ \hline RFT 7B & 51.2 & - \\ \hline LLAMA 65B & 50.9 & 20.5 \\ \hline Orac 2-7B & 47.23 & - \\ \hline Text-davni-002 & 40.7 & 19.1 \\ \hline LAMA 3B & 33.6 & 3.9 \\ \hline GPT-27B & 19.5 & - \\ \hline GLPM 7B & 18.1 & 2.9 \\ \hline PalM 540B & 17.9 & 8.8 \\ \hline LLAMA 13B & 17.8 & 3.9 \\ \hline LLAMA 7B & 11.2 & 2.9 \\ \hline GLPM-Neo-125M & 7.5 & - \\ \hline Pahl 8B & 4.1 & 1.5 \\ \hline GPT-2 & - & 5.4 \\ \hline GPT-3 175Bb & - & 5.2 \\ \hline PALM 62B & - & 4.4 \\ \hline GPT-3-13B & - & 3.3 \\ \hline LLAMA 7B & 11 & 2.9 \\ \hline LLAMA 7B & 11 & 2.9 \\ \hline PLM 8B & - & 1.5 \\ \hline \end{tabular}
\end{table} TABLE IX: Arithmetic reasoning comparison.

\begin{table}
\begin{tabular}{|l|l|l|l|l|} \hline Model & TriviaQA & NaturalQ & WebQ & ARC \\ \hline BLOMOM & - & - & - & 32.9 \\ \hline BLOMOM 176B & - & - & - & 50.85 \\ \hline Bloomberg GPT & - & - & - & 48.63 \\ \hline Chinchilla & - & 35.5 & - & - \\ \hline Code + REPLUG & 76.8 & 44.7 & - & - \\ \hline GAL 120B & - & - & - & 67.9 \\ \hline GLAM 62R64E & 75.8 & 32.5 & 15.5 & 50.3 \\ \hline Gopher & - & 28.2 & - & - \\ \hline GPT-3 175B & 71.2 & 29.9 & 41.5 & 85.2 \\ \hline GPT-4 & - & - & - & 96.4 \\ \hline GPT-NoK & - & - & - & 45.9 \\ \hline LLAMA 13B & - & - & - & 52.7 \\ \hline LLAMA 2 70B & 85 & 33 & - & - \\ \hline LLAMA 33B & - & 24.9 & - & 57.8 \\ \hline LMAM 65B & 72.6 & 39.9 & - & - \\ \hline LLAMA 7B & - & - & 47.6 \\ \hline Mistral 7B & 69.9 & 28.8 & - & 55.5 \\ \hline ToR-Code 7B & - & 13.7 & - & - \\ \hline OptF & - & - & - & 31.1 \\ \hline OFI 66B & - & - & - & 44.54 \\ \hline OPT-175B & - & - & - & 43.94 \\ \hline OPT-175B & - & - & - & 25.6 \\ \hline PalM 2-1 & 86.1 & 37.5 & 28.2 & 95.1 \\ \hline PALM 2-M & 81.7 & 32 & 26.9 & 64.9 \\ \hline PalM 2-5B & 75.2 & 25.3 & 21.8 & 59.6 \\ \hline PalM 34-540B & 81.4 & 39.6 & 43.5 & 87.1 \\ \hline PriL-5web 1.3B & - & - & - & 44.9 \\ \hline SparseGPT & - & - & - & 38.99 \\ \hline SparseGPT & - & - & - & 39.85 \\ \hline SparseGPT & - & - & - & 41.3 \\ \hline \end{tabular}
\end{table} TABLE VIII: Coding capability comparison.

\begin{table}
\begin{tabular}{|l|l|l|} \hline Model & HumanEval \\ \hline Gemini Ultra & 74.4 \\ \hline Gemini Pro & 67.7 \\ \hline GPT-4 & 67 \\ \hline Wizard-Coder 15B & 57.3 \\ \hline phi-1 1.3B & 50.6 \\ \hline Code Llama & 48.8 \\ \hline OPT-3.5 & 48.1 \\ \hline OtotCoder & 46.2 \\ \hline phi-1-small & 45 \\ \hline PALM 2-5 & 37.6 \\ \hline InstructCodeT5+ 16B & 35 \\ \hline Mistral 7B & 30.5 \\ \hline LLAMA 2 & 29.9 \\ \hline phi-1-base & 29 \\ \hline Code-12B & 28.81 \\ \hline PALM 540B & 26.2 \\ \hline LLCAMA 7B & 24.2 \\ \hline L-LAMA 65B & 23.7 \\ \hline LLAMA 33B & 21.7 \\ \hline PALM 62B & 15.9 \\ \hline LLAMA 13B & 15.8 \\ \hline LMMA 137B & 14 \\ \hline MIM-350M & 13.7 \\ \hline LLAMA 7B & 10.5 \\ \hline PALM 8B & 3.6 \\ \hline \end{tabular}
\end{table} TABLE VII: World knowledge comparison.

동시에 이것은 여전히 둔화되기보다는 혁신의 속도가 증가하고 있는 새롭고 매우 활발한 연구 분야이다. 그러나 다른 진화하는 영역과 마찬가지로 아직 많은 도전이 남아 있다. 여기에서 우리는 지금까지 알려진 몇 가지 도전과 주요 활동 영역을 간략하게 언급한다. LLM 도전이 Kaddour et al. [207]의 작업에서 세부적으로 논의된다는 점에 주목할 필요가 있다.

### _작고 효율적인 언어 모델_

이것은 _대규모_ 언어 모델에 대한 조사이며, GPT-4와 같은 훨씬 더 큰 모델이 벤치마크에서 더 나은 정확도와 성능을 얻는 데 분명히 보상을 받는 "더 큰 것이 더 좋다"에 대한 초기 추진이 있었다. 그러나 이러한 대규모 모델은 여러 차원(예: 높은 대기 시간)에서 비용이 많이 들고 비효율적이다. 이 모든 것에 대응하여, 특히 더 큰 모델의 전체 일반성을 필요로 하지 않을 수 있는 특정 작업에 사용될 때 LLMs에 대한 비용 효율적인 대안으로 작은 언어 모델(SLMs)을 고안하려는 현재 연구 경향이 있다. 이러한 방향에서 두드러진 작품으로는 Microsoft사의 Phi-1[208], Phi-1.5[209], Phi-2 등이 있다.

더 일반적으로, 우리는 더 작고 효율적인 모델을 훈련하는 방법에 대한 이 분야에서 많은 연구 노력을 기대해야 한다. 매개변수 효율적인 미세 조정(PEFT), 교사/학생 및 기타 형태의 증류(섹션 III-I 참조)와 같은 기술은 더 큰 모델 중에서 더 작은 모델을 구축하는 데 계속 사용될 것이다.

### _New Post-attention Architectural Paradigms_

트랜스포머 블록은 현재 대부분의 LLM 프레임워크의 중요하고 지속적인 부분이며, 이 아키텍처가 얼마나 오랫동안 유행할 것인지, 그리고 딥 러닝(및 NLP) 분야에서 다음 큰 아키텍처 돌파구는 무엇인지에 대한 큰 물음표입니다. 2012년 AlexNet 이후, 우리는 LSTM, GRU, seq2seq 등 많은 아키텍처가 유행과 퇴출하는 것을 보았지만, 트랜스포머는 그 시작부터 지배적인 접근법이었다. 앞서 설명한 바와 같이 변압기를 구동하는 주요 메커니즘에는 관심이 있다. 보다 최근에는 주의 후라고 명명되는 대안적 접근법에 대한 유망한 연구가 있었다.

이러한 주의 후 모델의 중요한 클래스는 소위 State Space Models(SSMs)이다. 상태 공간 모델들의 개념은 기계 학습에서 오랜 역사를 가지고 있지만, 언어 모델들의 맥락에서, SSM은 일반적으로 새로운 구조 상태 공간 모델 아키텍처 또는 줄여서 S4를 참조하여 사용된다는 것에 유의해야 한다(Gu et al. [29] 참조). 이 범주의 일부 최근 모델은 맘바[30], 하이에나[210] 및 줄무늬 하이에나[211]이다.

이러한 모든 모델은 리더보드의 성능 및 효율성 측면에서 매우 경쟁력이 있지만 보다 전통적인 주의 집중 기반 아키텍처에서 중요한 과제인 _더 큰 컨텍스트 창에 대한 지원 부족_도 해결합니다.

많은 프롬프트에 대한 좋은 답변을 얻으려면 컨텍스트가 필요합니다. 예를 들어, "나에게 좋은 영화를 추천해줘"에 대한 응답은 "나"에 대한 많은 컨텍스트뿐만 아니라 어떤 영화가 이용 가능하고 어떤 영화 1이 시청하지 않았는지에 대한 많은 컨텍스트를 필요로 한다. 텍스트 길이는 RAG에 특히 중요하며, 여기서 텍스트의 많은 부분이 검색되고 생성을 위해 프롬프트에 주입될 수 있다(섹션 IV-C 참조).

컨텍스트 길이가 길수록, 우리는 컨텍스트에 더 많은 토큰을 압착할 수 있다. 모델이 더 많은 정보에 접근할수록 모델의 응답은 더 좋아집니다. 그러나 다른 한편으로는, 매우 긴 문맥을 가지고 있어서, 모델이 모든 것을 기억하고 모든 정보를 효율적으로 처리하는 것은 어려울 것이다. 주목 기반 모델은 더 긴 컨텍스트에 대해 매우 비효율적이며, 따라서 우리는 더 긴 컨텍스트를 처리할 수 있고 일반적으로 더 효율적인 아키텍처를 제공하는 다양한 메커니즘에서 더 많은 연구를 기대해야 한다.

즉, 새로운 아키텍처가 제안할 수 있을 뿐만 아니라

\begin{table}
\begin{tabular}{|l|l|l|l|l|l|} \hline Model & HREM & HaluEval QA & HaluEval Dialogue & HaluEval Sum. & HaluEval General \\ \hline GPT 4 & 97 & - & - & - & - \\ \hline GPT 4 Turbo & 97 & - & - & - & - \\ \hline GPT 3.5 Turbo & 96.5 & 62.59 & 72.4 & 58.53 & 79.44 \\ \hline Davinci002 & - & 60.05 & 60.81 & 47.77 & 80.42 \\ \hline Davinci003 & - & 49.65 & 68.37 & 48.07 & 80.4 \\ \hline GPT-3 & - & 49.21 & 50.02 & 51.23 & 72.72 \\ \hline Google Gemini Pro & 95.2 & - & - & - & - \\ \hline Lima 2.70B & 94.9 & - & - & - & - \\ \hline Lima 2.7B & 94.4 & 49.6 & 43.99 & 49.55 & 20.46 \\ \hline Lima 2 13B & 94.1 & - & - & - & - \\ \hline Cohere-Chat & 92.5 & - & - & - & - \\ \hline Cohere & 91.5 & - & - & - & - \\ \hline Claude 2 & 91.5 & 69.78 & 64.73 & 57.75 & 75 \\ \hline Claude 1 & & 67.6 & 64.83 & 53.76 & 73.88 \\ \hline Microsoft Phi 2 & 91.5 & - & - & - & - \\ \hline Google Palm 2 (beta) & 91.4 & - & - & - & - \\ \hline Mixtral S8/7B & 90.7 & - & - & - & - \\ \hline Amazon Tran Express & 90.6 & - & - & - & - \\ \hline Mistral 7B & 90.6 & - & - & - & - \\ \hline Google Palm 2 Chat (beta) & 90 & - & - & - & - \\ \hline Google Palm 2 & 87.9 & - & - & - & - \\ \hline Google Palm 2 Chat & 72.8 & - & - & - & - \\ \hline ChatGLM & - & 47.93 & 44.41 & 48.57 & 30.92 \\ \hline Falcon & - & 39.66 & 29.08 & 42.71 & 18.98 \\ \hline Vicuna & - & 60.34 & 46.35 & 45.62 & 19.48 \\ \hline Alpaca & - & 6.68 & 17.55 & 20.63 & 9.54 \\ \hline \end{tabular}
\end{table} TABLE X: Hallucination evaluation alternatives for the attention mechanism but rather rethink the whole Transformer architecture. As an early example of this, Monarch Mixer [212] proposes a new architecture that uses the same sub-quadratic primitive that achieves high hardware efficiency on GPUs - Monarch matrices - along both sequence length and model dimension.

스펙트럼의 다른 쪽 끝에는 최근에 증기를 얻고 더 좋고 더 강력한 LLM을 만드는 데 가치를 입증하는 몇 가지 주의 호환 아키텍처 메커니즘이 있다는 점을 언급할 가치가 있다. 아마도 그러한 메커니즘의 가장 좋은 예는 전문가 혼합(MoE)일 것이다. MoE는 딥 러닝 시대[213] 이전에도 수년 동안 머신 러닝에 존재했지만 그 이후로, 특히 트랜스포머 모델과 LLM의 맥락에서 인기를 얻고 있다.

LLM에서 MoE는 게이팅/가중치 기능이 할당된 가중치가 낮은 곳이면 전문가 중 일부가 꺼질 때 추론 중에 부분적으로만 인스턴스화되는 것보다 매우 큰 모델을 훈련할 수 있다. 예를 들어, GLaM 모델은 1.2조 개의 파라미터를 갖지만, 추론 동안 64명의 전문가 중 2명만이 사용된다[84].

MoEs는 오늘날 소위 프런티어 LLM(즉, 가장 진보되고 유능한 모델)의 중요한 구성요소이다. GPT-4 자체는 MoE 아키텍처를 기반으로 한다는 소문이 있고, Mixtral[117]과 같은 가장 성능이 좋은 LLM들 중 일부는 기본적으로 기존 LLM들의 MoE 버전이다.

마지막으로, MoEs가 주목 여부에 관계없이 임의의 아키텍처의 컴포넌트로서 사용될 수 있다는 점에 유의하는 것이 중요하다. 사실, MoE는 Mamba citepioro2024moemamba와 같은 SSM 기반 LLM에도 적용되었다. 우리는 기본 아키텍처에 관계없이 향후 MoE 기반 개선을 계속 보아야 한다.

### _Multi-modal Models_

향후 LLM은 멀티모달이 될 것으로 예상되며 텍스트, 이미지, 비디오, 오디오 등 다양한 데이터 유형을 통일적으로 처리할 수 있다. 이는 질의 응답, 콘텐츠 생성, 창작 예술, 의료, 로봇 공학 및 그 이상과 같은 분야에서 보다 다양한 응용을 위한 가능성을 열어준다. LLAVA[214], LLAVA-Plus[215], GPT-4[33], Qwen-vl[116], Next-GPT[216] 등 이미 몇 가지 두드러진 멀티모달 LLM이 있지만 추세는 계속될 것으로 예상된다. 이러한 모델의 평가 또한 새로운 연구 주제이며, 특히 대화 생성 비전 모델이다[217]. 멀티모달 LLM은 다양한 작업에서 거대한 잠재력을 발휘할 수 있으며, 모든 세부 사항을 논의하기 위한 전용 논문이 필요한 이 방향으로 이미 하강 진전이 있었다.

### _개선된 LLM 사용량 및 증강 기술_

sectionIV에서 설명한 대로 _환각_과 같은 LLM의 많은 단점과 한계는 고급 신속한 엔지니어링, 도구 사용 또는 기타 증강 기술을 통해 해결할 수 있다. 우리는 이 분야에서 지속적인 연구뿐만 아니라 가속화된 연구를 기대해야 한다. 소프트웨어 엔지니어링의 특정 사례에서 일부 작업([218])은 전체 소프트웨어 엔지니어링 워크플로우에서 이 문제를 자동으로 제거하려고 시도했다는 점을 언급할 가치가 있다.

LLM 기반 시스템은 이미 최근까지 다른 접근법을 사용하던 기계 학습 시스템을 대체하기 시작했다. 이것의 명확한 예로서, LLMs는 이제 사람들의 선호도와 관심사를 더 잘 이해하고, 고객 서비스, 콘텐츠 추천, 또는 다른 애플리케이션에서든지, 보다 개인화된 상호 작용을 제공하기 위해 전개되고 있다. 이것은 사용자 선호도에 대한 더 나은 이해와 그들의 과거 상호 작용을 분석하고 컨텍스트로 사용하는 것을 포함한다. 우리는 _개인화 및 권장 사항_ 뿐만 아니라 다른 기계 학습 기술을 사용하는 많은 다른 응용 분야에 대한 LLM의 응용 및 사용에 대한 연구를 계속 볼 것이다.

마지막으로, 우리가 더 많은 관심을 모을 것으로 예상되는 또 다른 중요한 연구 영역은 _LLM 기반 에이전트 및 다중 에이전트 시스템_[172, 173, 174]의 것이다. 외부 도구에 대한 접근과 의사 결정 능력을 갖춘 LLM 시스템의 개발은 흥미롭고 도전적이다. 우리는 일각에서 인공지능(AGI)으로 이어질 수 있다고 주장하는 이 중요한 분야에서 지속적인 연구와 진전을 보게 될 것이다.

### _Security and Ethical/Responsible AI_

적대적 공격 및 기타 취약성에 대한 LLM의 견고성 및 보안을 보장하는 것은 연구의 중요한 영역이다[219]. LLM이 실제 응용 프로그램에 점점 더 많이 배포됨에 따라 잠재적인 위협으로부터 보호되어야 하며, 사람을 조작하거나 잘못된 정보를 퍼뜨리는 데 사용되는 것을 방지해야 한다.

LLM의 윤리적 우려와 편견을 해결하는 것은 또 다른 활발한 연구 분야이다. LLM이 공정하고, 편파적이지 않으며, 민감한 정보를 책임감 있게 처리할 수 있도록 하기 위한 노력이 이루어지고 있다. LLM이 매일 많은 사람들에 의해 점점 더 많이 사용되고 있기 때문에, 그들이 편파적이지 않고 책임감 있게 행동하는지 확인하는 것이 중요하다.

## VIII Conclusion

본 논문은 최근 몇 년 동안 개발된 LLMs에 대한 설문 조사를 제시한다. 먼저 초기 사전 훈련 언어 모델(예: BERT)에 대한 개요를 제공한 다음 세 가지 인기 있는 LLM 패밀리(GPT, LLaMA, PaLM) 및 기타 대표적인 LLM을 검토한다. 그런 다음 LLM을 구축하고, 증강하고, 사용하는 방법과 기술을 조사한다. 우리는 인기 있는 LLM 데이터 세트와 벤치마크를 검토하고 공개 벤치마크에서 두드러진 모델 세트의 성능을 비교한다. 마지막으로, 우리는 열린 도전과제와 향후 연구 방향을 제시한다.

## References

* [1] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Radford, J. Wu, and D. Amodei, "Scaling laws for neural language models," _arXiv preprint arXiv:2001.08361_, 2020.
* [2] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. d. L. Casas, L. A. Hendricks, J. Welbl, A. Clark _et al._, "Training compute-optimal large language models," _arXiv preprint arXiv:2203.15556_, 2022.
* [3] C. E. Shannon, "Prediction and entropy of printed english," _Bell system technical journal_, vol. 30, no. 1, pp. 50-64, 1951.
* [4] F. Jelinek, _Statistical methods for speech recognition_. MIT press, 1998.
* [5] C. Manning and H. Schutze, _Foundations of statistical natural language processing_. MIT press, 1999.

* [6] C. D. Manning, _An introduction to information retrieval_. Cambridge university press, 2009.
* [7] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang, J. Zhang, Z. Dong _et al._, "A survey of large language models," _arXiv preprint arXiv:2303.18223_, 2023.
* [8] C. Zhou, Q. Li, C. Li, J. Yu, Y. Liu, G. Wang, K. Zhang, C. Ji, Q. Yan, L. He _et al._, "A comprehensive survey on pretrained foundation models: A history from bert to chatpst," _arXiv preprint arXiv:2302.09419_, 2023.
* [9] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, and G. Neubig, "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing," _ACM Computing Surveys_, vol. 55, no. 9, pp. 1-35, 2023.
* [10] Q. Dong, L. Li, D. Dai, C. Zheng, Z. Wu, B. Chang, X. Sun, J. Xu, and Z. Sui, "A survey for in-context learning," _arXiv preprint arXiv:2301.00234_, 2022.
* [11] J. Huang and K. C.-C. Chang, "Towards reasoning in large language models: A survey," _arXiv preprint arXiv:2212.10403_, 2022.
* [12] S. F. Chen and J. Goodman, "An empirical study of smoothing techniques for language modeling," _Computer Speech & Language_, vol. 13, no. 4, pp. 359-394, 1999.
* [13] Y. Bengio, R. Ducharme, and P. Vincent, "A neural probabilistic language model," _Advances in neural information processing systems_, vol. 13, 2000.
* [14] H. Schwenk, D. Dechelotte, and J.-L. Gauvain, "Continuous space language models for statistical machine translation," in _Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions_, 2006, pp. 723-730.
* [15] T. Mikolov, M. Karafiat, L. Burget, J. Cernocky, and S. Khudanpur, "Recurrent neural network based language model." in _Interspeech_, vol. 2, no. 3. Makhunai, 2010, pp. 1045-1048.
* [16] A. Graves, "Generating sequences with recurrent neural networks," _arXiv preprint arXiv:1308.0850_, 2013.
* [17] P.-S. Huang, X. He, J. Gao, L. Deng, A. Acero, and L. Heck, "Learning deep structured semantic models for web search using clickthrough data," in _Proceedings of the 22nd ACM international conference on Information & Knowledge Management_, 2013, pp. 2333-2338.
* [18] J. Gao, C. Xiong, P. Bennett, and N. Craswell, _Neural Approaches to Conversational Information Retrieval_. Springer Nature, 2023, vol. 44.
* [19] I. Sutskever, O. Vinyals, and Q. V. Le, "Sequence to sequence learning with neural networks," _Advances in neural information processing systems_, vol. 27, 2014.
* [20] K. Cho, B. Van Merrienboer, D. Bahdanau, and Y. Bengio, "On the properties of neural machine translation: Encoder-decoder approaches," _arXiv preprint arXiv:1409.1259_, 2014.
* [21] H. Fang, S. Gupta, F. Iandola, R. K. Srivastava, L. Deng, P. Dollar, J. Gao, X. He, M. Mitchell, J. C. Plat _et al._, "From captions to visual concepts and back," in _Proceedings of the IEEE conference on computer vision and pattern recognition_, 2015, pp. 1473-1482.
* [22] O. Vinyals, A. Toshev, S. Bengio, and D. Erhan, "Show and tell: A neural image caption generator," in _Proceedings of the IEEE conference on computer vision and pattern recognition_, 2015, pp. 3156-3164.
* [23] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and L. Zettlemoyer, "Deep contextualized word representations. corr abs/1802.05365 (2018)," _arXiv preprint arXiv:1802.05365_, 2018.
* [24] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, "Bert: Pre-training of deep bidirectional transformers for language understanding," _arXiv preprint arXiv:1810.04805_, 2018.
* [25] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov, "Roberta: A robustly optimized bert pretraining approach," _arXiv preprint arXiv:1907.11692_, 2019.
* [26] P. He, X. Liu, J. Gao, and W. Chen, "Deberta: Decoding-enhanced bert with disentangled attention," _arXiv preprint arXiv:2006.03654_, 2020.
* [27] X. Han, Z. Zhang, N. Ding, Y. Gu, X. Liu, Y. Huo, J. Qiu, Y. Yao, A. Zhang, L. Zhang _et al._, "Pre-trained models: Past, present and future," _AI Open_, vol. 2, pp. 225-250, 2021.
* [28] X. Qiu, T. Sun, Y. Xu, Y. Shao, N. Dai, and X. Huang, "Pre-trained models for natural language processing: A survey," _Science China Technological Sciences_, vol. 63, no. 10, pp. 1872-1897, 2020.
* [29] A. Gu, K. Goel, and C. Re, "Efficiently modeling long sequences with structured state spaces," 2022.
* [30] A. Gu and T. Dao, "Mambu: Linear-time sequence modeling with selective state spaces," _arXiv preprint arXiv:2312.00752_, 2023.
* [31] A. Chowdhory, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P. Barham, H. W. Chung, C. Sutton, S. Gehrmann _et al._, "Palm: Scaling language modeling with pathways," _arXiv preprint arXiv:2204.02311_, 2022.
* [32] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux, T. Lacorix, B. Roziere, N. Goyal, E. Hambro, F. Azhar _et al._, "Llama: Open and efficient foundation language models," _arXiv preprint arXiv:2302.13971_, 2023.
* [33] OpenAI, "GPT-4 Technical Report," [https://arxiv.org/pdf/2303.08774v3.pdf](https://arxiv.org/pdf/2303.08774v3.pdf), 2023.
* [34] J. Wei, X. Wang, D. Schuurmans, M. Bosma, b. ichter, F. Xia, E. Chi, Q. V. Le, and D. Zhou, "Chain-of-thought prompting elicits reasoning in large language models," in _Advances in Neural Information Processing Systems_, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, Eds., vol. 35. Curran Associates, Inc., 2022, pp. 24 824-24 837. [Online]. Available: [https://proceedings.neurips.cc/paper_files/paper/2022/file/945069613524ec4f15af0f7b7b3lac84e4-Paper-Conference.pdf](https://proceedings.neurips.cc/paper_files/paper/2022/file/945069613524ec4f15af0f7b7b3lac84e4-Paper-Conference.pdf)
* [35] G. Mialon, R. Dessl, M. Lomeli, C. Naimipnis, R. Pasunuru, R. Raileanu, B. Roziere, T. Schick, J. Dwivedi-Yu, A. Celikyilmaz _et al._, "Augmented language models: a survey," _arXiv preprint arXiv:2302.07842_, 2023.
* [36] B. Peng, M. Galley, P. He, H. Cheng, Y. Xie, Y. Hu, Q. Huang, L. Lidem, Z. Yu, W. Chen, and J. Gao, "Check your facts and try again: Improving large language models with external knowledge and automated feedback," _arXiv preprint arXiv:2302.12813_, 2023.
* [37] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y. Cao, "React: Synergistic reasoning and acting in language models," _arXiv preprint arXiv:2120.03629_, 2022.
* [38] D. E. Rumelhart, G. E. Hinton, R. J. Williams _et al._, "Learning internal representations by error propagation," 1985.
* [39] J. L. Elman, "Finding structure in time," _Cognitive science_, vol. 14, no. 2, pp. 179-211, 1990.
* [40] M. V. Mahoney, "Fast text compression with neural networks." in _FLAIRS conference_, 2000, pp. 230-234.
* [41] T. Mikolov, A. Deoras, D. Povey, L. Burget, and J. Cernocky, "Strategies for training large scale neural network language models," in _2011 IEEE Workshop on Automatic Speech Recognition & Understanding_. IEEE, 2011, pp. 196-201.
* [42] tmiikolov, "mlm. [Online]. Available: [https://www.fit.vutbr.cz/~imikolov/mml/](https://www.fit.vutbr.cz/~imikolov/mml/)
* [43] S. Minaee, N. Kalchbrenner, E. Cambria, N. Nikzad, M. Chenaghlu, and J. Gao, "Deep learning-based text classification: a comprehensive review," _ACM computing surveys (CSUR)_, vol. 54, no. 3, pp. 1-40, 2021.
* [44] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin, "Attention is all you need," _Advances in neural information processing systems_, vol. 30, 2017.
* [45] Z. Lan, M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut, "Albert: A lite for self-supervised learning of language representations," _arXiv preprint arXiv:1909.11942_, 2019.
* [46] K. Clark, M.-T. Luong, Q. V. Le, and C. D. Manning, "Electra: Pre-training text encoders as discriminators rather than generators," _arXiv preprint arXiv:2003.10555_, 2020.
* [47] G. Lample and A. Conneau, "Cross-lingual language model pretraining," _arXiv preprint arXiv:1901.07291_, 2019.
* [48] Z. Yang, Z. Dai, Y. Yang, J. Carbonell, R. R. Salakhutdinov, and Q. V. Le, "Xlnet: Generalized autoregressive pretraining for language understanding," _Advances in neural information processing systems_, vol. 32, 2019.
* [49] L. Dong, N. Yang, W. Wang, F. Wei, X. Liu, Y. Wang, J. Gao, M. Zhou, and H.-W. Hon, "Unified language model pre-training for natural language understanding and generation," _Advances in neural information processing systems_, vol. 32, 2019.
* [50] A. Radford, K. Narasimhan, T. Salimans, I. Sutskever _et al._, "Improving language understanding by generative pre-training," 2018.
* [51] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever _et al._, "Language models are unsupervised multitask learners," _OpenAI blog_, vol. 1, no. 8, p. 9, 2019.
* [52] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu, "Exploring the limits of transfer learning with a unified text-to-text transformer," _The Journal of Machine Learning Research_, vol. 21, no. 1, pp. 5485-5551, 2020.
* [53] L. Xue, N. Constant, A. Roberts, M. Kale, R. Al-Rfou, A. Siddhant, A. Barua, and C. Raffel, "mt5: A massively multilingual pre-trained text-to-text transformer," _arXiv preprint arXiv:2010.11934_, 2020.
* [54] K. Song, X. Tan, T. Qin, J. Lu, and T.-Y. Liu, "Mass: Masked sequence to sequence pre-training for language generation," _arXiv preprint arXiv:1905.02450_, 2019.
* [55] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V. Stoyanov, and L. Zettlemoyer, "Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension," _arXiv preprint arXiv:1910.13461_, 2019.
* [56] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell _et al._, "Language models are few-shot learners," _Advances in neural information processing systems_, vol. 33, pp. 1877-1901, 2020.
* [57] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. d. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman _et al._, "Evaluating large language models trained on code," _arXiv preprint arXiv:2107.03374_, 2021.
* [58] R. Nakano, J. Hilton, S. Balaji, J. Wu, L. Ouyang, C. Kim, C. Hesse, S. Jain, V. Kosaraju, W. Saunders _et al._, "Webgpt: Browser-assisted question-answering with human feedback," _arXiv preprint arXiv:2112.09332_, 2021.
* [59] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright, P. Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray _et al._, "Training language models to follow instructions with human feedback," _Advances in Neural Information Processing Systems_, vol. 35, pp. 27 730-27 744, 2022.
* [60] OpenAI. (2022) Introducing chatqpt. [Online]. Available: [https://openai.com/blog/chatqpt](https://openai.com/blog/chatqpt)
* [61] H. Touvron, L. Martin, K. Stone, P. Albert, A. Almahairi, Y. Babaei, N. Bashlykov, S. Batra, P. Bhargava, S. Bhosale _et al._, "Llama 2: Open foundation and fine-tuned chat models," _arXiv preprint arXiv:2307.09288_, 2023.
* [62] R. Taori, I. Gulrajani, T. Zhang, Y. Dubois, X. Li, C. Guestrin, P. Liang, and T. B. Hashimoto, "Alpaca: A strong, replicable instruction-following model," _Stanford Center for Research on Foundation Models. https://crfcn. stanford. edu/2023/03/13/alpaca. html_, vol. 3, no. 6, p. 7, 2023.
* [63] T. Dettmers, A. Pagnoni, A. Holtzman, and L. Zettlemoyer, "Qlora: Efficient finetuning of quantized llms," _arXiv preprint arXiv:2305.14314_, 2023.
* [64] X. Geng, A. Gudibande, H. Liu, E. Wallace, P. Abbeel, S. Levine, and D. Song, "Koala: A dialogue model for academic research," _Blog post, April_, vol. 1, 2023.
* [65] A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. d. I. Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier _et al._, "Mistral 7b," _arXiv preprint arXiv:2310.06825_, 2023.
* [66] B. Roziere, J. Gehring, F. Gloeckle, S. Sootla, I. Gat, X. E. Tan, Y. Adi, J. Liu, T. Remez, J. Rapin _et al._, "Code llama: Open foundation models for code," _arXiv preprint arXiv:2308.12950_, 2023.
* [67] S. G. Patil, T. Zhang, X. Wang, and J. E. Gonzalez, "Gorilla: Large language model connected with massive apis," 2023.
* [68] A. Pal, D. Karkhanis, M. Roberts, S. Dooley, A. Sundararajan, and S. Naidu, "Giraffe: Adventures in expanding context lengths in lms," _arXiv preprint arXiv:2308.10882_, 2023.
* [69] B. Huang, "Vigogne: French instruction-following and chat models," [https://github.com/bofenghuang/vigogne](https://github.com/bofenghuang/vigogne), 2023.
* [70] Y. Wang, H. Ivison, P. Dasigi, J. Hessel, T. Khot, K. R. Chandu, D. Wadden, K. MacMillan, N. A. Smith, I. Beltagy _et al._, "How far can camels go? exploring the state of instruction tuning on open resources," _arXiv preprint arXiv:2306.04751_, 2023.
* [71] S. Tworkowski, K. Staniszewski, M. Paacek, Y. Wu, H. Michalewski, and P. Milos, "Focused transformer: Contrastive training for context scaling," _arXiv preprint arXiv:2307.03170_, 2023.
* [72] D. Mahan, R. Carlow, L. Castricato, N. Cooper, and C. Lafotte, "Stable bequa models." [Online]. Available: [[https://huggingface.c/ots/blibii/ai/StableBeluga2](https://huggingface.c/ots/blibii/ai/StableBeluga2)][https://huggingface.co/stabilityai/StableBeluga2](https://huggingface.co/stabilityai/StableBeluga2)][https://huggingface.co/stabilityai/StableBeluga2](https://huggingface.co/stabilityai/StableBeluga2))
* [73] Y. Tay, J. Wei, H. W. Chung, V. Q. Tran, D. R. So, S. Shakeri, X. Garcia, H. S. Zheng, J. Rao, A. Chowdhery _et al._, "Transcending scaling laws with 0.1% extra compute," _arXiv preprint arXiv:2210.11399_, 2022.
* [74] H. W. Chung, L. Hou, S. Longpre, B. Zoph, Y. Tay, W. Fedus, Y. Li, X. Wang, M. Dehghani, S. Brahma _et al._, "Scaling instruction-finetuned language models," _arXiv preprint arXiv:2210.11416_, 2022.
* [75] R. Anil, A. M. Dai, O. Firat, M. Johnson, D. Lepikhin, A. Passos, S. Shakeri, E. Taropa, P. Bailey, Z. Chen _et al._, "Palm 2 technical report," _arXiv preprint arXiv:2305.10403_, 2023.
* [76] K. Singhal, S. Azizi, T. Tu, S. S. Mahdavi, J. Wei, H. W. Chung, N. Scales, A. Tanwani, H. Cole-Lewis, S. Pfohl _et al._, "Large language models encode clinical knowledge," _arXiv preprint arXiv:2212.13138_, 2022.
* [77] K. Singhal, T. Tu, J. Gottweis, R. Sayres, E. Wulczyn, L. Hou, K. Clark, S. Pfohl, H. Cole-Lewis, D. Neal _et al._, "Towards expert-level medical question answering with large language models," _arXiv preprint arXiv:2305.09617_, 2023.
* [78] J. Wei, M. Bosma, V. Y. Zhao, K. Guu, A. W. Yu, B. Lester, N. Du, A. M. Dai, and Q. V. Le, "Finetuned language models are zero-shot learners," _arXiv preprint arXiv:2109.01652_, 2021.
* [79] J. W. Rae, S. Borgeaud, T. Cai, K. Millican, J. Hoffmann, F. Song, J. Aslanides, S. Henderson, R. Ring, S. Young _et al._, "Scaling language models: Methods, analysis & insights from training gopher," _arXiv preprint arXiv:2112.11446_, 2021.
* [80] V. Sanh, A. Webson, C. Raffel, S. H. Bach, L. Sutawika, Z. Alyafeai, A. Chaffin, A. Stiegler, T. L. Scao, A. Raja _et al._, "Multi-task prompted training enables zero-shot task generalization," _arXiv preprint arXiv:2110.08207_, 2021.
* [81] Y. Sun, S. Wang, S. Feng, S. Ding, C. Pang, J. Shang, J. Liu, X. Chen, Y. Zhao, Y. Lu _et al._, "Emie 3:0: Large-scale knowledge enhanced pre-training for language understanding and generation," _arXiv preprint arXiv:2107.02137_, 2021.
* [82] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. B. Van Den Driessche, J.-B. Lespiau, B. Damoc, A. Clark _et al._, "Improving language models by retrieving from trillions of tokens," in _International conference on machine learning_. PMLR, 2022, pp. 2206-2240.
* [83] O. Lieber, O. Sharir, B. Lenz, and Y. Shoham, "Jurassic-1: Technical details and evaluation," _White Paper. AI21 Labs_, vol. 1, p. 9, 2021.
* [84] N. Du, Y. Huang, A. M. Dai, S. Tong, D. Lepikhin, Y. Xu, M. Krikun, Y. Zhou, A. W. Yu, O. Firat _et al._, "Glam: Efficient scaling of language models with mixture-of-experts," in _International Conference on Machine Learning_. PMLR, 2022, pp. 5547-5569.
* [85] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, A. Kulshreshtha, H.-T. Cheng, A. Jin, T. Bos, L. Baker, Y. Du _et al._, "Lambda: Language models for dialog applications," _arXiv preprint arXiv:2201.08239_, 2022.
* [86] S. Zhang, S. Roller, N. Goyal, M. Artetxe, M. Chen, S. Chen, C. Dewan, M. Diab, X. Li, X. V. Lin _et al._, "Opt: Open pre-trained transformer language models," _arXiv preprint arXiv:2205.01068_, 2022.
* [87] R. Taylor, M. Kardas, G. Cucurull,* [89] S. Soltan, S. Ananthakrishnan, J. FitzGerald, R. Gupta, W. Hamza, H. Khan, C. Peris, S. Rawls, A. Rosenbaum, A. Rumshisky _et al._, "Alexatm 20b: Few-shot learning using a large-scale multilingual seq2seq model," _arXiv preprint arXiv:2208.01448_, 2022.
* [90] A. Glaese, N. McAleese, M. Trebacz, J. Aslanides, V. Firoiu, T. Ewalds, M. Rauh, L. Weidinger, M. Chadwick, P. Thacker _et al._, "Improving alignment of dialogue agents via targeted human judgements," _arXiv preprint arXiv:2209.14375_, 2022.
* [91] A. Lewkowycz, A. Andreassen, D. Dohan, E. Dyer, H. Michalewski, V. Ramasesh, A. Slone, C. Anil, I. Schlag, T. Gutman-Solo _et al._, "Solving quantitative reasoning problems with language models," _Advances in Neural Information Processing Systems_, vol. 35, pp. 3843-3857, 2022.
* [92] Y. Tay, M. Dehghani, V. Q. Tran, X. Garcia, D. Bahri, T. Schuster, H. S. Zheng, N. Houlsby, and D. Metzler, "Unifying language learning paradigms," _arXiv preprint arXiv:2205.05131_, 2022.
* [93] T. L. Scao, A. Fan, C. Akiki, E. Pavlick, S. Ilic, D. Hesslow, R. Castagne, A. S. Luccioni, F. Yvon, M. Galle _et al._, "Bloom: A 176b-parameter open-access multilingual language model," _arXiv preprint arXiv:2211.05100_, 2022.
* [94] A. Zeng, X. Liu, Z. Du, Z. Wang, H. Lai, M. Ding, Z. Yang, Y. Xu, W. Zheng, X. Xia _et al._, "Glim-130b: An open bilingual pre-trained model," _arXiv preprint arXiv:2210.02414_, 2022.
* [95] S. Biderman, H. Schoelkopf, Q. G. Anthony, H. Bradley, K. O'Brien, E. Hallahan, M. A. Khan, S. Purohit, U. S. Prashanth, E. Raff _et al._, "Pythia: A suite for analyzing large language models across training and scaling," in _International Conference on Machine Learning_. PMLR, 2023, pp. 2397-2430.
* [96] S. Mukherjee, A. Mitra, G. Jawahar, S. Agarwal, H. Palangi, and A. Awadallah, "Orca: Progressive learning from complex explanation traces of gpt-4," _arXiv preprint arXiv:2306.02707_, 2023.
* [97] R. Li, L. B. Allal, Y. Zi, N. Muenthigth, D. Kocektov, C. Mou, M. Marone, C. Akiki, J. Li, J. Chim _et al._, "Stracorder: may the source be with you!" _arXiv preprint arXiv:2305.06161_, 2023.
* [98] S. Huang, L. Dong, W. Wang, Y. Hao, S. Singhal, S. Ma, T. Lv, L. Cui, O. K. Mohammed, Q. Liu _et al._, "Language is not all you need: Aligning perception with language models," _arXiv preprint arXiv:2302.14045_, 2023.
* [99] G. Team, R. Anil, S. Borgeaud, Y. Wu, J.-B. Alayrac, J. Yu, R. Soricut, J. Schalkwyk, A. M. Dai, A. Hauth _et al._, "Gemini: a family of highly capable multimodal models," _arXiv preprint arXiv:2312.11805_, 2023.
* [100] W. Huang, F. Xia, T. Xiao, H. Chan, J. Liang, P. Florence, A. Zeng, J. Tompson, I. Mordatch, Y. Chebotar _et al._, "Inner monologue: Embodied reasoning through planning with language models," _arXiv preprint arXiv:2207.05608_, 2022.
* [101] S. Smith, M. Patwary, B. Norick, P. LeGresley, S. Rajbhandari, J. Casper, Z. Liu, S. Prabhumoye, G. Zerveas, V. Korthikanti _et al._, "Using deepspeed and megatron to train megatron-turing meg 530b, a large-scale generative language model," _arXiv preprint arXiv:2201.11990_, 2022.
* [102] I. Beltagy, M. E. Peters, and A. Cohan, "Longformer: The long-document transformer," _arXiv preprint arXiv:2004.05150_, 2020.
* [103] S. Iyer, X. V. Lin, R. Pasunuru, T. Mihaylov, D. Simig, P. Yu, K. Shuster, T. Wang, Q. Liu, P. S. Koura _et al._, "Opt-iml: Scaling language model instruction meta learning through the lens of generalization," _arXiv preprint arXiv:2212.12017_, 2022.
* [104] Y. Hao, H. Song, L. Dong, S. Huang, Z. Chi, W. Wang, S. Ma, and F. Wei, "Language models are general-purpose interfaces," _arXiv preprint arXiv:2206.06366_, 2022.
* [105] Z. Sun, Y. Shen, Q. Zhou, H. Zhang, Z. Chen, D. Cox, Y. Yang, and C. Gan, "Principle-driven self-alignment of language models from scratch with minimal human supervision," _arXiv preprint arXiv:2305.03047_, 2023.
* [106] W. E. team, "Palmyra-base Parameter Autoregressive Language Model," [https://dev.writer.com](https://dev.writer.com), 2023.
* [107] ----, "Camel-5b instructept," [https://dev.writer.com](https://dev.writer.com), 2023.
* [108] Yandex. Yalm. [Online]. Available: [https://github.com/yandex/Yal.M-100B](https://github.com/yandex/Yal.M-100B)
* [109] M. Team _et al._, "Introducing mpt-7b: a new standard for open-source, commercially usable llms," 2023.
* [110] A. Mitra, L. D. Corto, S. Mahajan, A. Codas, C. Simoes, S. Agarwal, X. Chen, A. Razdiabiedina, E. Jones, K. Aggarwal, H. Palangi, G. Zheng, C. Rosset, H. Khanpour, and A. Awadallah, "Orca 2: Teaching small language models how to reason," 2023.
* [111] L. Gao, A. Madan, S. Zhou, U. Alon, P. Liu, Y. Yang, J. Callan, and G. Neubig, "Pal: Program-aided language models," in _International Conference on Machine Learning_. PMLR, 2023, pp. 10 764-10 799.
* [112] Anthropic. calude. [Online]. Available: [https://www.anthropic.com/news/introducing-claude](https://www.anthropic.com/news/introducing-claude)
* [113] E. Nijkamp, H. Hayashi, C. Xiong, S. Savarese, and Y. Zhou, "Codegen22: Lessons for training llms on programming and natural languages," _arXiv preprint arXiv:2305.02309_, 2023.
* [114] L. Tunstall, E. Beeching, N. Lambert, N. Rajani, K. Rasul, Y. Belkada, S. Huang, L. von Werra, C. Fourrier, N. Habib _et al._, "Zephyr: Direct distillation of lm alignment," _arXiv preprint arXiv:2310.16944_, 2023.
* [115] X. team. Grok. [Online]. Available: [https://grok.xai/](https://grok.xai/)
* [116] J. Bai, S. Bai, S. Yang, S. Wang, S. Tan, P. Wang, I. Lin, C. Zhou, and J. Zhou, "Qwen-vl: A frontier large vision-language model with versatile abilities," _arXiv preprint arXiv:2308.12966_, 2023.
* [117] mixtral. mixtral. [Online]. Available: [https://mistral.ai/news/](https://mistral.ai/news/) mixtral-of-experts/
* [118] D. Wang, N. Raman, M. Sibue, Z. Ma, P. Babkin, S. Kaur, Y. Pei, A. Nourbakhsh, and X. Liu, "Docllm: A layout-aware generative language model for multimodal document understanding," 2023.
* 코드 인텔리전스의 증가," 2024.
* [120] F. Wan, X. Huang, D. Cai, X. Quan, W. Bi, and S. Shi, "Knowledge fusion of large language models," 2024.
* [121] P. Zhang, G. Zeng, T. Wang, and W. Lu, "Tinyllama: An open-source small language model," 2024.
* [122] C. Wu, Y. Gan, Y. Ge, Z. Lu, J. Wang, Y. Feng, P. Luo, and Y. Shan, "Llama pro: Progressive llama with block expansion," 2024.
* [123] X. Amatraina, A. Sankar, J. Bing, P. K. Bodiguta, T. J. Hazen, and M. Kazzi, "Transformer models: an introduction and catalog," 2023.
* [124] G. Penedo, Q. Malartic, D. Hesslow, R. Cojocaru, A. Cappelli, H. Alobeidli, B. Pannier, E. Almazrouei, and J. Launay, "The refined-web dataset for falcon llm: outperforming curated corpora with web data, and web data only," _arXiv preprint arXiv:2306.01116_, 2016.
* [125] D. Hernandez, T. Brown, T. Conerly, N. DasSarma, D. Drain, S. El-Showk, N. Elhage, Z. Hatfield-Dodds, T. Henighan, T. Hume _et al._, "Scaling laws and interpretability of learning from repeated data," _arXiv preprint arXiv:2205.10487_, 2022.
* [126] P. Shaw, J. Uszkoreit, and A. Vaswani, "Self-attention with relative position representations," _arXiv preprint arXiv:1803.02155_, 2018.
* [127] J. Su, Y. Lu, S. Pan, B. Wen, and Y. Liu, "Roformer: Enhanced transformer with rotary position embedding," _arXiv preprint arXiv:2104.09864_, 2021.
* [128] O. Press, N. A. Smith, and M. Lewis, "Train short, test long: Attention with linear biases enables input length extrapolation," _arXiv preprint arXiv:2108.12409_, 2021.
* [129] G. Ke, D. He, and T.-Y. Liu, "Rethinking positional encoding in language pre-training," _arXiv preprint arXiv:2006.15595_, 2020.
* [130] N. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton, and J. Dean, "Outrageously large neural networks: The sparsely-gated mixture-of-experts layer," _arXiv preprint arXiv:1701.06538_, 2017.
* [131] W. Fedus, B. Zoph, and N. Shazeer, "Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity," _The Journal of Machine Learning Research_, vol. 23, no. 1, pp. 5232-5270, 2022.
* [132] R. K. Mahabadi, S. Ruder, M. Dehghani, and J * [134] S. Mishra, D. Khashabi, C. Baral, and H. Hajishirzi, "Cross-task generalization via natural language crowdsourcing instructions," _arXiv preprint arXiv:2104.08773_, 2021.
* [135] Y. Wang, Y. Kordi, S. Mishra, A. Liu, N. A. Smith, D. Khashabi, and H. Hajishirzi, "Self-instruct: Aligning language model with self generated instructions," _arXiv preprint arXiv:2212.10560_, 2022.
* [136] K. Ethayarajh, W. Xu, D. Jurafsky, and D. Kiela. Kto. [Online]. Available: [https://github.com/ContextualAI/HALOs/blob/main/assets/report.pdf](https://github.com/ContextualAI/HALOs/blob/main/assets/report.pdf)
* [137] P. F. Christiano, J. Leike, T. Brown, M. Martic, S. Legg, and D. Amodei, "Deep reinforcement learning from human preferences," _Advances in neural information processing systems_, vol. 30, 2017.
* [138] H. Lee, S. Phatale, H. Mansoor, K. Lu, T. Mesnard, C. Bishop, V. Carbone, and A. Rastogi, "Rlafi: Scaling reinforcement learning from human feedback with ai feedback," _arXiv preprint arXiv:2309.00267_, 2023.
* [139] R. Rafailov, A. Sharma, E. Mitchell, S. Ermon, C. D. Manning, and C. Finn, "Direct preference optimization: Your language model is secretly a reward model," _arXiv preprint arXiv:2305.18290_, 2023.
* [140] S. Rajbhandari, J. Rasley, O. Ruwase, and Y. He, "Zero: Memory optimizations toward training trillion parameter models," in _SC20: International Conference for High Performance Computing, Networking, Storage and Analysis_. IEEE, 2020, pp. 1-16.
* [141] B. Peng, E. Alcalide, Q. Anthony, A. Albalak, S. Arcadinho, H. Cao, X. Cheng, M. Chung, M. Grella, K. K. GV _et al._, "Rwkv: Reinventing rnns for the transformer era," _arXiv preprint arXiv:2305.13048_, 2023.
* [142] E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, "Lora: Low-rank adaptation of large language models," _arXiv preprint arXiv:2106.09685_, 2021.
* [143] G. Hinton, O. Vinyals, and J. Dean, "Distilling the knowledge in a neural network," _arXiv preprint arXiv:1503.02531_, 2015.
* [144] J. Gou, B. Yu, S. J. Maybank, and D. Tao, "Knowledge distillation: A survey," _International Journal of Computer Vision_, vol. 129, pp. 1789-1819, 2021.
* [145] Z. Ji, N. Lee, R. Frieske, T. Yu, D. Su, Y. Xu, E. Ishii, Y. J. Bang, A. Madotto, and P. Fung, "Survey of hallucination in natural language generation," _ACM Comput. Surv._, vol. 55, no. 12, mar 2023. [Online]. Available: [https://doi.org/10.1145/3571730](https://doi.org/10.1145/3571730)
* [146] N. McKenna, T. Li, L. Cheng, M. J. Hosseini, M. Johnson, and M. Steedman, "Sources of hallucination by large language models on inference tasks," 2023.
* [147] C.-Y. Lin, "ROUGE: A package for automatic evaluation of summaries," in _Text Summarization Branches Out_. Barcelona, Spain: Association for Computational Linguistics, Jul. 2004, pp. 74-81. [Online]. Available: [https://aclanthology.org/W04-1013](https://aclanthology.org/W04-1013)
* [148] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, "Bleu: a method for automatic evaluation of machine translation," in _Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics_, P. Isabelle, E. Charniak, and D. Lin, Eds. Philadelphia, Pennsylvania, USA: Association for Computational Linguistics, Jul. 2002, pp. 311-318. [Online]. Available: [https://aclanthology.org/P02-1040](https://aclanthology.org/P02-1040)
* [149] B. Dhingra, M. Faruqui, A. Parikh, M.-W. Chang, D. Das, and W. Cohen, "Handling divergent reference texts when evaluating table-to-text generation," in _Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics_, A. Korhonen, D. Traum, and L. Matrieuz, Eds. Florence, Italy: Association for Computational Linguistics, Jul. 2019, pp. 4884-4895. [Online]. Available: [https://aclanthology.org/P19-1483](https://aclanthology.org/P19-1483)
* [150] Z. Wang, X. Wang, B. An, D. Yu, and C. Chen, "Towards faithful neural table-to-text generation with content-matching constraints," in _Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics_, D. Jurafsky, J. Chai, N. Schluter, and J. Tetreault, Eds. Online: Association for Computational Linguistics, Jul. 2020, pp. 1072-1086. [Online]. Available: [https://aclanthology.org/2020.acl-main.101](https://aclanthology.org/2020.acl-main.101)
* [151] H. Song, W.-N. Zhang, J. Hu, and T. Liu, "Generating person consistent dialogues by exploiting natural language inference," _Proceedings of the AAAI Conference on Artificial Intelligence_, vol. 34, no. 05, pp. 8878-8885, Apr. 2020.
* [152] O. Honovich, L. Choshen, R. Aharoni, E. Neeman, I. Szpektor, and O. Abend, "\(q^{2}\): Evaluating factual consistency in knowledge-grounded dialogues via question generation and question answering," in _Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing_, M.-F. Moons, X. Huang, L. Specia, and S. W.-t. Yih, Eds. Online and Punta Cana, Dominican Republic: Association for Computational Linguistics, Nov. 2021, pp. 7856-7870. [Online]. Available: [https://aclanthology.org/2021.emnlp-main.619](https://aclanthology.org/2021.emnlp-main.619)
* [153] N. Dziri, H. Rashkin, T. Linzen, and D. Reitter, "Evaluating attribution in dialogue systems: The BEGIN benchmark," _Transactions of the Association for Computational Linguistics_, vol. 10, pp. 1066-1068, 2022. [Online]. Available: [https://aclanthology.org/2022.tacl-1.62](https://aclanthology.org/2022.tacl-1.62)
* [154] S. Santhanam, B. Hedayatnia, S. Gella, A. Padmakumar, S. Kim, Y. Liu, and D. Z. Hakkani-Tur, "Rome was built in 1776: A case study on factual correctness in knowledge-grounded response generation," _ArXiv_, vol. abs/2110.05456, 2021.
* [155] S. Min, K. Krishna, X. Lyu, M. Lewis, W. tau Yih, P. W. Koh, M. Iyyer, L. Zettlemoyer, and H. Hajishirzi, "Factscore: Fine-grained atomic evaluation of factual precision in long form text generation," 2023.
* [156] D. Sculley, G. Holt, D. Golovin, E. Davydov, T. Phillips, D. Ebner, V. Chaudhary, and M. Young, "Machine learning: The high interest credit card of technical debt," in _SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop)_, 2014.
* [157] Z. Zhang, A. Zhang, M. Li, and A. Smola, "Automatic chain of thought prompting in large language models," 2022.
* [158] S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths, Y. Cao, and K. Narasimhan, "Tree of thoughts: Deliberate problem solving with large language models," 2023.
* [159] P. Manakul, A. Liuise, and M. J. F. Gales, "Selfcheckkgtr: Zero-resource black-box hallucination detection for generative large language models," 2023.
* [160] N. Shinn, F. Cassano, E. Berman, A. Gopinath, K. Narasimhan, and S. Yao, "Reflexion: Language agents with verbal reinforcement learning," 2023.
* [161] S. J. Zhang, S. Florin, A. N. Lee, E. Niknafs, A. Marginean, A. Wang, K. Tyser, Z. Chin, Y. Hicke, N. Singh, M. Udell, Y. Kim, T. Buonassisi, A. Solar-Lezama, and I. Drori, "Exploring the mit mathematics and ecces curriculum using large language models," 2023.
* [162] T. Wu, E. Jiang, A. Donsbach, J. Gray, A. Molina, M. Terry, and C. J. Cai, "Prompt chainer: Chaining large language model prompts through visual programming," 2022.
* [163] Y. Zhou, A. I. Muresanu, Z. Han, K. Paster, S. Pitis, H. Chan, and J. Ba, "Large language models are human-level prompt engineers," 2023.
* [164] P. S. H. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Kuttler, M. Lewis, W. Yih, T. Rocktaschel, S. Riedel, and D. Kiela, "Retrieval-augmented generation for knowledge-intensive NLP tasks," _CoRR_, vol. abs/2005.11401, 2020. [Online]. Available: [https://arxiv.org/abs/2005.11401](https://arxiv.org/abs/2005.11401)
* [165] Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, and H. Wang, "Retrieval-augmented generation for large language models: A survey," _arXiv preprint arXiv:2312.10997_, 2023.
* [166] A. W. Services. (Year of publication, e.g., 2023) Question answering using retrieval augmented generation with foundation models in amazon asgemaker jumpstart. Accessed: Date of access, e.g., December 5, 2023. [Online]. Available: [https://shorturl.at/d/5v47](https://shorturl.at/d/5v47)
* [167] S. Pan, L. Luo, Y. Wang, C. Chen, J. Wang, and X. Wu, "Unifying large language models and knowledge graphs: A roadmap," _arXiv preprint arXiv:2306.08302_, 2023.
* [168] Z. Jiang, F. F. Xu, L. Gao, Z. Sun, Q. Liu, J. Dwivedi-Yu, Y. Yang, J. Callan, and G. Neubig, "Active retrieval augmented generation," 2023.
* [169] T. Schick, J. Dwivedi-Yu, R. Dessi, R. Raileanu, M. Lomeli, L. Zettlemoyer, N. Cancedda, and T. Scialom, "Toolformer: Language models can teach themselves to use tools," 2023.
* [170] B. Paranjape, S. Lundberg, S. Singh, H. Hajishirzi, L. Zettlemoyer, and M. T. Ribeiro, "Art: Automatic multi-step reasoning and tool-use for large language models," 2023.
* [171] Y. Shen, K. Song, X. Tan, D. Li, W. Lu, and Y. Zhuang, "Huggingnet: Solving ai tasks with chatgpt and its friends in huggingface," _arXiv preprint arXiv:2303.17580_, 2023.

* [172] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang, S. Jin, E. Zhou _et al._, "The rise and potential of large language model based agents: A survey," _arXiv preprint arXiv:2309.07864_, 2023.
* [173] L. Wang, C. Ma, X. Feng, Z. Zhang, H. Yang, J. Zhang, Z. Chen, J. Tang, X. Chen, Y. Lin _et al._, "A survey on large language model based autonomous agents," _arXiv preprint arXiv:2308.11432_, 2023.
* [174] Z. Durante, Q. Huang, N. Wake, R. Gong, J. S. Park, B. Sarkar, R. Taori, Y. Noda, D. Terzopoulos, Y. Choi, K. Ikeuchi, H. Vo, L. Fei-Fei, and J. Gao, "Agent ai: Surveying the horizons of multimodal interaction," _arXiv preprint arXiv:2401.03568_, 2024.
* [175] B. Xu, Z. Peng, B. Lei, S. Mukherjee, Y. Liu, and D. Xu, "Rewoo: Decoupling reasoning from observations for efficient augmented language models," 2023.
* [176] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y. Cao, "React: Synergizing reasoning and acting in language models," 2023.
* [177] V. Nair, E. Schumacher, G. Tso, and A. Kannan, "Dera: Enhancing large language model completions with dialog-enabled resolving agents," 2023.
* [178] Y. Chang, X. Wang, J. Wang, Y. Wu, L. Yang, K. Zhu, H. Chen, X. Yi, C. Wang, Y. Wang, W. Ye, Y. Zhang, Y. Chang, P. S. Yu, Q. Yang, and X. Xie, "A survey on evaluation of large language models," 2023.
* [179] T. Kwiatkowski, J. Palomaki, O. Redfield, M. Collins, A. Parikh, C. Alberti, D. Epstein, I. Polosukhin, J. Devlin, K. Lee, K. Toutanova, L. Jones, M. Kelcey, M.-W. Chang, A. M. Dai, J. Uszkoreit, Q. Le, and S. Petrov, "Natural questions: A benchmark for question answering research," _Transactions of the Association for Computational Linguistics_, vol. 7, pp. 452-466, 2019. [Online]. Available: [https://aclanthology.org/Q19-1026](https://aclanthology.org/Q19-1026)
* [180] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt, "Measuring massive multitask language understanding," 2021.
* [181] J. Austin, A. Odena, M. Nye, M. Bosma, H. Michalewski, D. Dohan, E. Jiang, C. Cai, M. Terry, Q. Le _et al._, "Program synthesis with large language models," _arXiv preprint arXiv:2108.07732_, 2021.
* [182] E. Choi, H. He, M. Iyyer, M. Yatskar, W.-t. Yih, Y. Choi, P. Liang, and L. Zettlemoyer, "QuAC: Question answering in context," in _Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing_, E. Riloff, D. Chiang, J. Hockenmaier, and J. Tsuji, Eds. Brussels, Belgium: Association for Computational Linguistics, Oct.-Nov. 2018, pp. 2174-2184. [Online]. Available: [https://aclanthology.org/D18-1241](https://aclanthology.org/D18-1241)
* [183] D. Hendrycks, S. Basart, S. Kadavath, M. Mazeika, A. Arora, E. Guo, C. Burns, S. Paranik, H. He, D. Song, and J. Steinhardt, "Measuring coding challenge competence with apps," _NeurIPS_, 2021.
* [184] V. Zhong, C. Xiong, and R. Socher, "Seq2sql: Generating structured queries from natural language using reinforcement learning," _arXiv preprint arXiv:1709.00103_, 2017.
* [185] M. Joshi, E. Choi, D. Weld, and L. Zettlemoyer, "TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension," in _Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, R. Barzilay and M.-Y. Kan, Eds. Vancouver, Canada: Association for Computational Linguistics, Jul. 2017, pp. 1601-1611. [Online]. Available: [https://aclanthology.org/P17-1147](https://aclanthology.org/P17-1147)
* [186] G. Lai, Q. Xie, H. Liu, Y. Yang, and E. Hovy, "RACE: Large-scale ReAding comprehension dataset from examinations," in _Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing_, M. Palmer, R. Hwa, and S. Riedel, Eds. Copenhagen, Denmark: Association for Computational Linguistics, Sep. 2017, pp. 785-794. [Online]. Available: [https://aclanthology.org/D17-1082](https://aclanthology.org/D17-1082)
* [187] P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang, "SQuAD: 100.000+ questions for machine comprehension of text," in _Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing_, J. Su, K. Duh, and X. Carreras, Eds. Austin, Texas: Association for Computational Linguistics, Nov. 2016, pp. 2383-2392. [Online]. Available: [https://aclanthology.org/D16-1264](https://aclanthology.org/D16-1264)
* [188] C. Clark, K. Lee, M. Chang, T. Kwiatkowski, M. Collins, and K. Toutanova, "Bool: Exploring the surprising difficulty of natural yes/no questions," _CoRR_, vol. abs/1905.10044, 2019. [Online]. Available: [http://arxiv.org/abs/1905.10044](http://arxiv.org/abs/1905.10044)
* [189] D. Khashabi, S. Chaturvedi, M. Roth, S. Upadhyay, and D. Roth, "Looking beyond the surface:a challenge set for reading comprehension over multiple sentences," in _Proceedings of North American American Conference of the Association for Computational Linguistics (NAACL)_, 2018.
* [190] K. Cobbe, V. Kosaraju, M. Bavarian, M. Chen, H. Jun, L. Kaiser, M. Plappert, J. Tworek, J. Hilton, R. Nakano, C. Hesse, and J. Schulman, "Training verifiers to solve math word problems," _CoRR_, vol. abs/2110.14168, 2021. [Online]. Available: [https://arxiv.org/abs/2110.14168](https://arxiv.org/abs/2110.14168)
* [191] D. Hendrycks, C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song, and J. Steinhardt, "Measuring mathematical problem solving with the MATH dataset," _CoRR_, vol. abs/2103.03874, 2021. [Online]. Available: [https://arxiv.org/abs/2103.03874](https://arxiv.org/abs/2103.03874)
* [192] R. Zellers, A. Holtzman, Y. Bisk, A. Farhadi, and Y. Choi, "Hellaswag: Can a machine really finish your sentence?" 2019.
* [193] P. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick, and O. Tafjord, "Think you have solved question answering? try arc, the AI2 reasoning challenge," _CoRR_, vol. abs/1803.05457, 2018. [Online]. Available: [http://arxiv.org/abs/1803.05457](http://arxiv.org/abs/1803.05457)
* [194] Y. Bisk, R. Zellers, R. L. Bras, J. Gao, and Y. Choi, "PIQA: reasoning about physical commonsense in natural language," _CoRR_, vol. abs/1911.11641, 2019. [Online]. Available: [http://arxiv.org/abs/1911.11641](http://arxiv.org/abs/1911.11641)
* [195] M. Sap, H. Rashkin, D. Chen, R. L. Bras, and Y. Choi, "Socialiqa: Commonsense reasoning about social interactions," _CoRR_, vol. abs/1904.09728, 2019. [Online]. Available: [http://arxiv.org/abs/1904.09728](http://arxiv.org/abs/1904.09728)
* [196] T. Mihaylov, P. Clark, T. Khot, and A. Sabharwal, "Can a suit of armor conduct electricity? A new dataset for open book question answering," _CoRR_, vol. abs/1809.02789, 2018. [Online]. Available: [http://arxiv.org/abs/1809.02789](http://arxiv.org/abs/1809.02789)
* [197] S. Lin, J. Hilton, and O. Evans, "Truthfulqa: Measuring how models mimic human falsehoods," _arXiv preprint arXiv:2109.07958_, 2021.
* [198] Z. Yang, P. Qi, S. Zhang, Y. Bengio, W. W. Cohen, R. Salakhutdinov, and C. D. Manning, "Hotpotqa: A dataset for diverse, explainable multi-hop question answering," _CoRR_, vol. abs/1809.09600, 2018. [Online]. Available: [http://arxiv.org/abs/1809.09600](http://arxiv.org/abs/1809.09600)
* [199] Y. Zhuang, Y. Yu, K. Wang, H. Sun, and C. Zhang, "Toolqa: A dataset for llm question answering with external tools," _arXiv preprint arXiv:2306.13304_, 2023.
* [200] D. Chen, J. Bolton, and C. D. Manning, "A thorough examination of the cnn/daily mail reading comprehension task," in _Association for Computational Linguistics (ACL)_, 2016.
* [201] R. Nallapati, B. Zhou, C. Gulcehre, B. Xiang _et al._, "Abstractive text summarization using sequence-to-sequence rnns and beyond," _arXiv preprint arXiv:1602.06023_, 2016.
* [202] Y. Bai and D. Z. Wang, "More than reading comprehension: A survey on datasets and metrics of textual question answering," _arXiv preprint arXiv:2109.12264_, 2021.
* [203] H.-Y. Huang, E. Choi, and W.-t. Yih, "Flowqa: Grasping flow in history for conversational machine comprehension," _arXiv preprint arXiv:1810.06683_, 2018.
* [204] S. Lee, J. Lee, H. Moon, C. Park, J. Seo, S. Eo, S. Koo, and H. Lim, "A survey on evaluation metrics for machine translation," _Mathematics_, vol. 11, no. 4, p. 1006, 2023.
* [205] J. Li, X. Cheng, W. X. Zhao, J.-Y. Nie, and J.-R. Wen, "Halueval: A large-scale hallucination evaluation benchmark for large language models," in _Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing_, 2023, pp. 6449-6464.
* [206] Simon Mark Hughes, "Hughes hallucination evaluation model (hlem) leaderboard," 2024, [https://huggingface.co/spaces/vectar/Hallucination-evaluation-leaderboard](https://huggingface.co/spaces/vectar/Hallucination-evaluation-leaderboard), Last accessed on 2024-01-21.
* [207] J. Kadodur, J. Harris, M. Mozes, H. Bradley, R. Railleau, and R. McHardy, "Challenges and applications of large language models," _arXiv preprint arXiv:2307.10169_, 2023.
* [208] S. Gunasekar, Y. Zhang, J. Aneja, C. C. T. Mendes, A. Del Giorno, S. Gopi, M. Javaherpi, P. Kauffmann, G. de Rosa, O. Saarikivi* [209] Y. Li, S. Bubeck, R. Eldan, A. Del Giorno, S. Gunasekar, and Y. T. Lee, "Textbooks are all you need ii: phi-1.5 technical report," _arXiv preprint arXiv:2309.05463_, 2023.
* [210] M. Poli, S. Massaroli, E. Nguyen, D. Y. Fu, T. Dao, S. Baccus, Y. Bengio, S. Ermon, and C. Re, "Hyena hierarchy: Towards larger convolutional language models," 2023.
* [211] M. Poli, J. Wang, S. Massaroli, J. Quesnelle, E. Nguyen, and A. Thomas, "StripedHyeena: Moving Beyond Transformers with Hybrid Signal Processing Models," 12 2023. [Online]. Available: [https://github.com/togethercomputer/stripedhgena](https://github.com/togethercomputer/stripedhgena)
* [212] D. Y. Fu, S. Arora, J. Grogan, I. Johnson, S. Fayboglu, A. W. Thomas, B. Spector, M. Poli, A. Rudra, and C. Re, "Monarch mixer: A simple sub-quadratic gemm-based architecture," 2023.
* [213] G. J. McLachlan, S. X. Lee, and S. I. Rathnayake, "Finite mixture models," _Annual review of statistics and its application_, vol. 6, pp. 355-378, 2019.
* [214] H. Liu, C. Li, Q. Wu, and Y. J. Lee, "Visual instruction tuning," _arXiv preprint arXiv:2304.08485_, 2023.
* [215] S. Liu, H. Cheng, H. Liu, H. Zhang, F. Li, T. Ren, X. Zou, J. Yang, H. Su, J. Zhu, L. Zhang, J. Gao, and C. Li, "Llava-plus: Learning to use tools for creating multimodal agents," _arXiv preprint arXiv:2311.05437_, 2023.
* [216] S. Wu, H. Fei, L. Qu, W. Ji, and T.-S. Chua, "Next-gpt: Any-to-any multimodal llm," _arXiv preprint arXiv:2309.05519_, 2023.
* [217] N. N. Khasmaki, M. Asgari-Chenaghlu, N. Asghar, P. Schaer, and D. Zihike, "Convexing: Evaluation of conversational generative vision models," 2023.
* [218] N. Alshahwan, J. Chheda, A. Finegenova, B. Gokkaya, M. Harman, I. Harper, A. Marginean, S. Sengupta, and E. Wang, "Automated unit test improvement using large language models at meta," _arXiv preprint arXiv:2402.09171_, 2024.
* [219] L. Sun, Y. Huang, H. Wang, S. Wu, Q. Zhang, C. Gao, Y. Huang, W. Lyu, Y. Zhang, X. Li _et al._, "Trustllm: Trustworthiness in large language models," _arXiv preprint arXiv:2401.05561_, 2024.
* [220] Microsoft. Deepspeed. [Online]. Available: [https://github.com/microsoft/DeepSpeed](https://github.com/microsoft/DeepSpeed)
* [221] HuggingFace. Transformers. [Online]. Available: [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)
* [222] Nvidia. Megatron. [Online]. Available: [https://github.com/NVIDIA/Megatron-LM](https://github.com/NVIDIA/Megatron-LM)
* [223] BMTrain. Bmtrain. [Online]. Available: [https://github.com/OpenBMB/BMTrain](https://github.com/OpenBMB/BMTrain)
* [224] EleutherAI. gpt-neox. [Online]. Available: [https://github.com/EleutherAI/gpt-neox](https://github.com/EleutherAI/gpt-neox)
* [225] microsoft. Lora. [Online]. Available: [https://github.com/microsoft/LoRA](https://github.com/microsoft/LoRA)
* [226] ColossalAI. Colossalai. [Online]. Available: [https://github.com/bioaiteatch/ColossalAI](https://github.com/bioaiteatch/ColossalAI)
* [227] FastChat. FastChat. [Online]. Available: [https://github.com/lm-sys/FastChat](https://github.com/lm-sys/FastChat)
* [228] skypilot. skypilot. [Online]. Available: [https://github.com/skypilot-org/skypilot](https://github.com/skypilot-org/skypilot)
* [229] vllm. vllm. [Online]. Available: [https://github.com/vllm-project/vllm](https://github.com/vllm-project/vllm)
* [230] huggingface. text-generation-inference. [Online]. Available: [https://github.com/huggingface/text-generation-inference](https://github.com/huggingface/text-generation-inference)
* [231] langchain. langchain. [Online]. Available: [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)
* [232] bentoml. Openllm. [Online]. Available: [https://github.com/bentoml/OpenLLM](https://github.com/bentoml/OpenLLM)
* [233] embedchain. embbedchain. [Online]. Available: [https://github.com/embedchain](https://github.com/embedchain)
* [234] microsoft. autogen. [Online]. Available: [https://github.com/microsoft/autogen](https://github.com/microsoft/autogen)
* [235] babyagi. babyagi. [Online]. Available: [https://github.com/yoheinakajima/babyagi](https://github.com/yoheinakajima/babyagi)
* [236] guidance. guidance. [Online]. Available: [https://github.com/guidance-ai/guidance](https://github.com/guidance-ai/guidance)
* [237] promptiools. prompttools. [Online]. Available: [https://github.com/hegelai/promptools](https://github.com/hegelai/promptools)
* [238] promptfoo. promptfoo. [Online]. Available: [https://github.com/promptfoo/promptfoo](https://github.com/promptfoo/promptfoo)
* [239] facebook. faiss. [Online]. Available: [https://github.com/facebookresearch/faiss](https://github.com/facebookresearch/faiss)
* [240] mixus. mixus. [Online]. Available: [https://github.com/milvus-io/mixus](https://github.com/milvus-io/mixus)
* [241] qdrant. qdrant. [Online]. Available: [https://github.com/qdrant/qdrant](https://github.com/qdrant/qdrant)
* [242] weaviate. weaviate. [Online]. Available: [https://github.com/weaviate/weaviate](https://github.com/weaviate/weaviate)
* [243] Ilama index. Ilama-index. [Online]. Available: [https://github.com/run-lama/Ilama_index](https://github.com/run-lama/Ilama_index)

## 부록 LLM 개발 및 배포를 위한 오픈 소스 도구 키트

LLM 교육, 평가 및 배치를 위해 개발된 다양한 프레임워크와 라이브러리가 있으며 모든 프레임워크를 다루는 것은 본 논문의 범위를 벗어난다. 그러나 우리는 다른 범주로 그룹화된 가장 인기 있는 몇 가지에 대한 간략한 소개를 제공하고자 합니다.

### _LLM Training/Inference Frameworks_

LLM 트레이닝에 유용한 인기 있는 프레임워크들 중 일부는 (그들 중 일부는 LLM 트레이닝을 넘어서도 사용될 수 있다는 점에 주목한다):

**DeepSpeed**[220]은 분산 학습 및 추론을 쉽고 효율적이며 효과적으로 만드는 딥 러닝 최적화 라이브러리입니다. 딥스피드는 MT-530B 및 BLOOM과 같은 세계에서 가장 강력한 언어 모델을 가능하게 한다. 훈련과 추론 모두에 전례 없는 규모와 속도를 제공하는 사용하기 쉬운 딥러닝 최적화 소프트웨어 제품군입니다. 딥스피드를 사용하면...

**트랜스포머**[221]은 텍스트, 비전 및 오디오와 같은 다양한 양식에서 작업을 수행하기 위해 수천 개의 사전 훈련된 모델을 제공하는 HuggingFace의 라이브러리입니다. 사전 훈련된 모델을 사용하면 컴퓨팅 비용, 탄소 발자국을 줄이고 모델을 처음부터 훈련하는 데 필요한 시간과 리소스를 절약할 수 있습니다.

**메가트론-LM**[222]는 NVIDIA의 응용 딥러닝 연구 팀이 개발한 크고 강력한 변압기입니다. 효율적인 모델 병렬(텐서, 시퀀스, 파이프라인)과 혼합 정밀도를 이용한 GPT, BERT, T5와 같은 변압기 기반 모델의 다중 노드 사전 훈련을 포함한다.

**BMTrain**[223]은 수백억 개의 매개 변수를 사용하여 대규모 모델을 훈련하는 데 사용할 수 있는 효율적인 대규모 모델 훈련 도구 키트입니다. 독립형 훈련처럼 코드를 단순하게 유지하면서 분산 방식으로 모델을 훈련할 수 있습니다.

**GPT-NeoX**[224]는 인기 있는 메가트론-딥스피드 라이브러리와 동일한 기능 및 기술을 많이 활용하지만 사용성과 새로운 최적화가 상당히 향상되었습니다.

**LoRA**[225] 라이브러리는 대용량 언어 모델의 하위 순위 적응을 지원합니다. 원래 가중치를 동결시키면서 순위 분해 행렬 쌍을 학습하여 훈련 가능한 매개변수의 수를 줄인다. 이는 특정 태스크에 적응된 대규모 언어 모델에 대한 스토리지 요구 사항을 크게 감소시키고, 추론 대기 시간을 도입하지 않고도 배치 동안 효율적인 태스크 전환을 가능하게 한다. LoRA는 또한 어댑터, 접두사 튜닝 및 미세 조정을 포함한 여러 다른 적응 방법을 능가한다.

**ColossalAI** 라이브러리 [226]은 병렬 구성 요소의 컬렉션을 제공합니다. 개발자가 노트북에 모델을 쓰는 것처럼 분산 딥러닝 모델을 쓸 수 있도록 지원하는 것을 목표로 한다. 그들은 몇 줄로 분산된 훈련과 추론을 시작할 수 있는 사용자 친화적인 도구를 제공한다. 병렬성 전략 측면에서 데이터 병렬성, 파이프라인 병렬성, 시퀀스 병렬성, ZeRO(Zero Redundancy Optimizer) [140] 및 자동 병렬성을 지원합니다.

### _Deployment Tools_

여기에서 가장 인기 있는 LLM 배포 도구 중 일부에 대한 개요를 제공합니다.

**FastChat**[227]은 대규모 언어 모델 기반 챗봇을 교육, 서비스 및 평가하기 위한 개방형 플랫폼입니다. FastChat의 핵심 기능은 다음과 같습니다. 최신 모델(예: Vicuna, MT-Bench)에 대한 훈련 및 평가 코드, 웹 UI 및 OpenAI 호환 RESTful API가 있는 분산 다중 모델 서빙 시스템.

**Skypilot**[228]은 모든 클라우드에서 LLM, AI 및 배치 작업을 실행 하 여 최대 비용 절감, GPU 가용성 및 관리 되는 실행을 제공 하는 프레임워크입니다.

**vLLM**[229]는 LLM 추론 및 서비스를 위한 빠르고 사용하기 쉬운 라이브러리입니다. vLLM은 Aquila, Baichuan, BLOOM, ChatGLM, DeciLM, Falcon, GPT BigCode, LLaMA, LLaMA 2, Mistral, Mistral, MPT, OPT, Qwen, Yi 등의 아키텍처를 포함하여 많은 Hugging Face 모델을 원활하게 지원합니다.

**text-generation-inference**[230]은 LLM(대규모 언어 모델)을 배포하고 서비스하기 위한 도구 키트입니다. TGI는 라마, 팔콘, 스타코더, BLOOM, GPT-NeoX 등을 포함한 가장 인기 있는 오픈 소스 LLM에 대한 고성능 텍스트 생성을 가능하게 한다.

**LangChain**[231]은 언어 모델로 구동되는 애플리케이션을 개발하기 위한 프레임워크입니다. 응용 프로그램을 사용 하도록 설정 하면 다음과 같습니다.

* 상황 인식: 언어 모델을 컨텍스트 원본에 연결 합니다 (빠른 명령, 몇 개의 샷 예, 응답을 접지할 콘텐츠 등).
* 추론: 언어 모델에 의존하여 추론(제공된 컨텍스트를 기반으로 답변하는 방법, 취해야 할 조치 등에 대해)

**OpenLLM**[232]는 실제 애플리케이션에서 대규모 언어 모델(LLM)의 배포 및 작업을 용이하게 하도록 설계된 오픈 소스 플랫폼입니다. OpenLLM을 사용하면 모든 오픈 소스 LLM에서 추론을 실행하고 클라우드 또는 온-프레미스에 배포하고 강력한 AI 애플리케이션을 빌드할 수 있습니다.

**Embedchain**[233]은 AI 앱을 쉽게 만들고 배포할 수 있는 오픈 소스 RAG 프레임워크입니다. 임베드 체인은 RAG 애플리케이션 생성을 간소화하여 다양한 유형의 비정형 데이터를 관리하기 위한 원활한 프로세스를 제공합니다. 데이터를 관리 가능한 청크로 효율적으로 분할하고 관련 임베딩을 생성하여 벡터 데이터베이스에 저장하여 최적화된 검색을 수행한다.

**Autogen**[234]는 작업을 해결하기 위해 서로 대화할 수 있는 여러 에이전트를 사용하여 LLM 애플리케이션을 개발할 수 있도록 하는 프레임워크입니다. 오토젠 에이전트는 사용자 정의 가능하고 볼록하며 원활하게 사람이 참여할 수 있습니다. 그들은 LLM, 인간 입력 및 도구의 조합을 사용하는 다양한 모드에서 작동할 수 있다.

**BabyAGI**[235]는 지정된 목표를 기반으로 작업을 생성하고 실행하도록 설계된 자율 인공지능 에이전트입니다. 오픈AI, 핀콘, 랭체인, 크로마 등 첨단 기술을 활용해 업무를 자동화하고 구체적인 목표를 달성한다. 이 블로그 게시물에서는 BabyAGI의 고유한 기능에 대해 살펴보고 작업 자동화를 간소화할 수 있는 방법을 탐색할 것입니다.

### _Prompting Libraries_

**가이드**[236]은 기존 프롬프트 및 체인화에 비해 우수한 제어 및 효율성을 제공하는 프로그래밍 패러다임입니다. 이를 통해 사용자는 생성(예: regex 및 CFG 포함)을 제한하고 제어(조건부, 루프) 및 생성을 원활하게 인터리브할 수 있습니다.

**PromptTools**[237]은 LLM, 벡터 데이터베이스 및 프롬프트를 실험, 테스트 및 평가하기 위한 오픈 소스 자체 호스팅 가능한 도구 집합을 제공합니다. 핵심 아이디어는 개발자가 코드, 노트북, 지역 놀이터와 같은 친숙한 인터페이스를 사용하여 평가할 수 있도록 하는 것입니다.

**PromptBench**[29]는 LLM(대용량 언어 모델 평가)을 위한 Pytorch 기반 Python 패키지입니다. 연구자가 LLMs에 대한 평가를 수행할 수 있는 사용자 친화적인 API를 제공합니다.

**Promptfoo**[238]은 LLM 출력 품질을 테스트하고 평가하기 위한 도구입니다. 미리 정의된 테스트 케이스를 사용하여 프롬프트, 모델 및 RAG를 체계적으로 테스트합니다.

### _VectorDB_

**Faiss**[239]는 고밀도 벡터의 효율적인 유사성 검색 및 클러스터링을 제공하는 Facebook AI Research에서 개발한 라이브러리입니다. 대규모 고차원 데이터와 함께 사용할 수 있도록 설계되었으며 다양한 사용 사례에 대한 여러 인덱스 유형과 알고리즘을 지원합니다.

**Milvus**[240]은 유사성 검색 및 AI 애플리케이션에 전력을 공급하기 위해 구축된 오픈 소스 벡터 데이터베이스입니다. 밀버스는 비정형 데이터 검색에 더 쉽게 접근할 수 있도록 하며, 배포 환경에 관계없이 일관된 사용자 경험을 제공한다.

**Qdrant**[241]은 벡터 유사성 검색 엔진 및 벡터 데이터베이스입니다. 포인트를 저장, 검색 및 관리할 수 있는 편리한 API를 사용하여 프로덕션 준비 서비스를 제공합니다. 추가 페이로드가 있는 벡터는 확장 필터링 지원에 맞게 조정됩니다. 환경.

**Weaviate**[242]는 고차원 데이터에서 유사성 검색을 가능하게 하는 오픈 소스 GraphQL 기반 벡터 검색 엔진입니다. 오픈 소스이지만 상용 버전은 추가 기능, 지원 및 관리 서비스를 제공합니다.

다른 인기 있는 옵션에는 **LlamaIndex**[243] 및 **파인콘** 이 있습니다.
