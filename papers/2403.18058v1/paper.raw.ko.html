<html lang="en" data-theme="light"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning</title>
<!--Generated on Tue Mar 26 19:13:16 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/addons.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="https://arxiv.org/html/2403.18058v1/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2403.18058v1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <span class="color-scheme-icon" aria-label="Light mode"></span>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="#myForm" onclick="event.preventDefault(); var modal = document.getElementById('myForm'); modal.style.display = 'block'; bugReportState.setInitiateWay('Header');">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2403.18058v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2403.18058v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
          <span class="color-scheme-icon"></span>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC mobile collapse" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S1" title="1 Introduction ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S2" title="2 Related Work ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S2.SS1" title="2.1 Instruction Tuning Dataset ‣ 2 Related Work ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Instruction Tuning Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S2.SS2" title="2.2 Data Mixture of SFT ‣ 2 Related Work ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Data Mixture of SFT</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3" title="3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>CQIA CURATION</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS1" title="3.1 Social Media &amp; Forums ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Social Media &amp; Forums</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS1.SSS0.Px1" title="Zhihu ‣ 3.1 Social Media &amp; Forums ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">Zhihu</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS1.SSS0.Px2" title="SegmentFault ‣ 3.1 Social Media &amp; Forums ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">SegmentFault</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS1.SSS0.Px3" title="Douban ‣ 3.1 Social Media &amp; Forums ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">Douban</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS1.SSS0.Px4" title="Xiaohongshu ‣ 3.1 Social Media &amp; Forums ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">Xiaohongshu</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS1.SSS0.Px5" title="Ruozhiba ‣ 3.1 Social Media &amp; Forums ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">Ruozhiba</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS2" title="3.2 World Knowledge ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>World Knowledge</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS2.SSS1" title="3.2.1 General Encyclopedia ‣ 3.2 World Knowledge ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>General Encyclopedia</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS2.SSS2" title="3.2.2 Domain Specific Knowledge ‣ 3.2 World Knowledge ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Domain Specific Knowledge</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS3" title="3.3 Examinations ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Examinations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS3.SSS0.Px1" title="The Middle School and College Entrance Examinations ‣ 3.3 Examinations ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">The Middle School and College Entrance Examinations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS3.SSS0.Px2" title="Graduate Entrance Examination ‣ 3.3 Examinations ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">Graduate Entrance Examination</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS3.SSS0.Px3" title="Logical Reasoning Test ‣ 3.3 Examinations ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">Logical Reasoning Test</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS3.SSS0.Px4" title="Chinese Culture Test ‣ 3.3 Examinations ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">Chinese Culture Test</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS4" title="3.4 NLP Datasets ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>NLP Datasets</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS4.SSS0.Px1" title="COIG-PC ‣ 3.4 NLP Datasets ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">COIG-PC</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS4.SSS0.Px2" title="COIG Human Value ‣ 3.4 NLP Datasets ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">COIG Human Value</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS4.SSS0.Px3" title="Firefly Chinese Traditional ‣ 3.4 NLP Datasets ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">Firefly Chinese Traditional</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.SS4.SSS0.Px4" title="100PoisonMpts ‣ 3.4 NLP Datasets ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">100PoisonMpts</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S4" title="4 Data Analysis ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Data Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S4.SS1" title="4.1 Statistics ‣ 4 Data Analysis ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Statistics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S4.SS2" title="4.2 Diversity ‣ 4 Data Analysis ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Diversity</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S5" title="5 EXPERIMENTAL SETUP ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>EXPERIMENTAL SETUP</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S5.SS1" title="5.1 Evaluation ‣ 5 EXPERIMENTAL SETUP ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S5.SS1.SSS0.Px1" title="C-Eval ‣ 5.1 Evaluation ‣ 5 EXPERIMENTAL SETUP ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">C-Eval</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S5.SS1.SSS0.Px2" title="CMMLU ‣ 5.1 Evaluation ‣ 5 EXPERIMENTAL SETUP ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">CMMLU</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S5.SS1.SSS0.Px3" title="BELLE-EVAL ‣ 5.1 Evaluation ‣ 5 EXPERIMENTAL SETUP ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">BELLE-EVAL</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S5.SS1.SSS0.Px4" title="SafetyBench ‣ 5.1 Evaluation ‣ 5 EXPERIMENTAL SETUP ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title">SafetyBench</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S5.SS2" title="5.2 Implementation Details ‣ 5 EXPERIMENTAL SETUP ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Implementation Details</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S6" title="6 EXPERIMENT RESULTS ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>EXPERIMENT RESULTS</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S6.SS1" title="6.1 Ablating Instruction Data Sources ‣ 6 EXPERIMENT RESULTS ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Ablating Instruction Data Sources</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S6.SS2" title="6.2 Human Evaluation ‣ 6 EXPERIMENT RESULTS ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Human Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S6.SS3" title="6.3 Scaling Model Size ‣ 6 EXPERIMENT RESULTS ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Scaling Model Size</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S6.SS4" title="6.4 Safety ‣ 6 EXPERIMENT RESULTS ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4 </span>Safety</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S7" title="7 Conclusion ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
</ol></nav>

<div class="ltx_page_content">
<div aria-label="Conversion errors have been found" class="package-alerts ltx_document" role="status">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewBox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: inconsolata</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><div class="section" id="target-section"><div id="license-tr">License: CC BY 4.0</div><div id="watermark-tr">arXiv:2403.18058v1 [cs.CL] 26 Mar 2024</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span class="ltx_text ltx_font_bold" id="id1.1.id1">Yuelin Bai<sup class="ltx_sup" id="id1.1.id1.1"><span class="ltx_text ltx_font_medium" id="id1.1.id1.1.1">1</span></sup></span> <span class="ltx_text ltx_font_bold" id="id2.2.id2">Xinrun Du<sup class="ltx_sup" id="id2.2.id2.1"><span class="ltx_text ltx_font_medium" id="id2.2.id2.1.1">2</span></sup><span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnotex1.1.1.1">1</span></span></span></span></span></span> <span class="ltx_text ltx_font_bold" id="id3.3.id3">Yiming Liang<sup class="ltx_sup" id="id3.3.id3.1"><span class="ltx_text ltx_font_medium" id="id3.3.id3.1.1">3</span></sup><span class="ltx_note ltx_role_footnotemark" id="footnotex2"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnotex2.1.1.1">1</span></span></span></span></span></span> <span class="ltx_text ltx_font_bold" id="id4.4.id4">Yonggang Jin<sup class="ltx_sup" id="id4.4.id4.1"><span class="ltx_text ltx_font_medium" id="id4.4.id4.1.1">2</span></sup><span class="ltx_note ltx_role_footnotemark" id="footnotex3"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnotex3.1.1.1">1</span></span></span></span></span>
<br class="ltx_break">Ziqiang Liu<sup class="ltx_sup" id="id4.4.id4.2"><span class="ltx_text ltx_font_medium" id="id4.4.id4.2.1">1</span></sup></span> <span class="ltx_text ltx_font_bold" id="id5.5.id5">Junting Zhou<sup class="ltx_sup" id="id5.5.id5.1"><span class="ltx_text ltx_font_medium" id="id5.5.id5.1.1">4,2</span></sup></span> <span class="ltx_text ltx_font_bold" id="id6.6.id6">Tianyu Zheng<sup class="ltx_sup" id="id6.6.id6.1"><span class="ltx_text ltx_font_medium" id="id6.6.id6.1.1">2</span></sup></span> <span class="ltx_text ltx_font_bold" id="id7.7.id7">Xincheng Zhang<sup class="ltx_sup" id="id7.7.id7.1"><span class="ltx_text ltx_font_medium" id="id7.7.id7.1.1">5</span></sup></span> <span class="ltx_text ltx_font_bold" id="id8.8.id8">Nuo Ma<sup class="ltx_sup" id="id8.8.id8.1"><span class="ltx_text ltx_font_medium" id="id8.8.id8.1.1">6</span></sup>
<br class="ltx_break">Zekun Wang<sup class="ltx_sup" id="id8.8.id8.2"><span class="ltx_text ltx_font_medium" id="id8.8.id8.2.1">2</span></sup></span> <span class="ltx_text ltx_font_bold" id="id9.9.id9">Ruibin Yuan<sup class="ltx_sup" id="id9.9.id9.1"><span class="ltx_text ltx_font_medium" id="id9.9.id9.1.1">7,2</span></sup></span> <span class="ltx_text ltx_font_bold" id="id10.10.id10">Haihong Wu<sup class="ltx_sup" id="id10.10.id10.1"><span class="ltx_text ltx_font_medium" id="id10.10.id10.1.1">5</span></sup></span> <span class="ltx_text ltx_font_bold" id="id11.11.id11">Hongquan Lin<sup class="ltx_sup" id="id11.11.id11.1"><span class="ltx_text ltx_font_medium" id="id11.11.id11.1.1">5</span></sup></span> <span class="ltx_text ltx_font_bold" id="id12.12.id12">Wenhao Huang<sup class="ltx_sup" id="id12.12.id12.1"><span class="ltx_text ltx_font_medium" id="id12.12.id12.1.1">6</span></sup>
<br class="ltx_break">Jiajun Zhang<sup class="ltx_sup" id="id12.12.id12.2"><span class="ltx_text ltx_font_medium" id="id12.12.id12.2.1">3</span></sup></span> <span class="ltx_text ltx_font_bold" id="id13.13.id13">Wenhu Chen<sup class="ltx_sup" id="id13.13.id13.1"><span class="ltx_text ltx_font_medium" id="id13.13.id13.1.1">8,9,2</span></sup></span> <span class="ltx_text ltx_font_bold" id="id14.14.id14">Chenghua Lin<sup class="ltx_sup" id="id14.14.id14.1"><span class="ltx_text ltx_font_medium" id="id14.14.id14.1.1">10,2</span></sup></span> <span class="ltx_text ltx_font_bold" id="id15.15.id15">Jie Fu<sup class="ltx_sup" id="id15.15.id15.1"><span class="ltx_text ltx_font_medium" id="id15.15.id15.1.1">7,2</span></sup></span> <span class="ltx_text ltx_font_bold" id="id16.16.id16">Min Yang<sup class="ltx_sup" id="id16.16.id16.1"><span class="ltx_text ltx_font_medium" id="id16.16.id16.1.1">1</span></sup>
<br class="ltx_break">Shiwen Ni<sup class="ltx_sup" id="id16.16.id16.2"><span class="ltx_text ltx_font_medium" id="id16.16.id16.2.1">1</span></sup></span> <span class="ltx_text ltx_font_bold" id="id17.17.id17">Ge Zhang<sup class="ltx_sup" id="id17.17.id17.1"><span class="ltx_text ltx_font_medium" id="id17.17.id17.1.1">8,9</span></sup><span class="ltx_note ltx_role_footnotemark" id="footnotex4"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_medium" id="footnotex4.1.1.1">2</span></span></span></span></span>
<br class="ltx_break"><sup class="ltx_sup" id="id17.17.id17.2"><span class="ltx_text ltx_font_medium" id="id17.17.id17.2.1">1</span></sup></span>Shenzhen Institute of Advanced Technology, CAS <sup class="ltx_sup" id="id18.18.id18">2</sup>M-A-P  <sup class="ltx_sup" id="id19.19.id19">3</sup>Institute of Automation, CAS
<br class="ltx_break"><sup class="ltx_sup" id="id20.20.id20">4</sup>Peking University <sup class="ltx_sup" id="id21.21.id21">5</sup>University of Science and Technology of China <sup class="ltx_sup" id="id22.22.id22">6</sup>01.ai <sup class="ltx_sup" id="id23.23.id23">7</sup>HKUST
<br class="ltx_break"><sup class="ltx_sup" id="id24.24.id24">8</sup>University of Waterloo <sup class="ltx_sup" id="id25.25.id25">9</sup>Vector Institute <sup class="ltx_sup" id="id26.26.id26">10</sup>University of Manchester 

<br class="ltx_break">
</span><span class="ltx_author_notes">Equal contributionCorresponding author</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id27.id1">Recently, there have been significant advancements in large language models (LLMs), particularly focused on the English language. These advancements have enabled these LLMs to understand and execute complex instructions with unprecedented accuracy and fluency. However, despite these advancements, there remains a noticeable gap in the development of Chinese instruction tuning. The unique linguistic features and cultural depth of the Chinese language pose challenges for instruction tuning tasks. Existing datasets are either derived from English-centric LLMs or are ill-suited for aligning with the interaction patterns of real-world Chinese users. To bridge this gap, we introduce COIG-CQIA, a high-quality Chinese instruction tuning dataset. Our aim is to build a diverse, wide-ranging instruction-tuning dataset to better align model behavior with human interactions. To this end, we collect a high-quality human-written corpus from various sources on the Chinese Internet, including Q&amp;A communities, Wikis, examinations, and existing NLP datasets. This corpus was rigorously filtered and carefully processed to form the COIG-CQIA dataset. Furthermore, we train models of various scales on different subsets of CQIA, following in-depth evaluation and analyses. The findings from our experiments offer valuable insights for selecting and developing Chinese instruction-tuning datasets. We also find that models trained on CQIA-Subset achieve competitive results in human assessment as well as knowledge and security benchmarks. Data are available at <a class="ltx_ref ltx_href" href="https://huggingface.co/datasets/m-a-p/COIG-CQIA" title="">https://huggingface.co/datasets/m-a-p/COIG-CQIA</a></p>최근, 특히 영어에 초점을 맞춘 대규모 언어 모델(LLM)의 상당한 발전이 있었다. 이러한 발전은 이러한 LLM이 전례 없는 정확성과 유창성으로 복잡한 명령을 이해하고 실행할 수 있도록 했다. 그러나 이러한 발전에도 불구하고 중국어 명령어 튜닝의 발전에는 눈에 띄는 격차가 남아 있다. 중국어의 독특한 언어적 특징과 문화적 깊이는 수업 조율 작업에 어려움을 준다. 기존 데이터 세트는 영어 중심 LLM에서 파생되거나 실제 중국 사용자의 상호 작용 패턴과 일치하기에 적합하지 않다. 이러한 격차를 해소하기 위해 고품질 중국어 명령어 튜닝 데이터 세트인 COIG-CQIA를 소개한다. 우리의 목표는 모델 행동을 인간의 상호 작용과 더 잘 정렬하기 위해 다양하고 광범위한 명령 조정 데이터 세트를 구축하는 것이다. 이를 위해 질의응답 커뮤니티, 위키스, 시험, 기존 NLP 데이터셋 등 중국 인터넷 상의 다양한 소스로부터 고품질의 인간이 작성한 코퍼스를 수집한다. 이 말뭉치는 엄격하게 필터링되고 신중하게 처리되어 COIG-CQIA 데이터 세트를 형성했다. 또한 심층 평가 및 분석에 따라 CQIA의 다양한 하위 집합에 대한 다양한 척도 모델을 훈련한다. 본 연구의 결과는 중국어 학습 데이터 세트를 선택하고 개발하는 데 유용한 통찰력을 제공한다. 또한 CQIA-Subset에서 훈련된 모델이 지식 및 보안 벤치마크뿐만 아니라 인간 평가에서 경쟁력 있는 결과를 달성한다는 것을 발견했다. 데이터는 <a class="ltx_ref ltx_href" href="https://huggingface.co/datasets/m-a-p/COIG-CQIA" title="">https://huggingface.co/datasets/m-a-p/COIG-CQIA</a>에서 이용 가능하다.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">GPT-3<cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib2" title="">2020</a>)</cite>, LLaMA<cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib22" title="">2023</a>)</cite>, PaLM<cite class="ltx_cite ltx_citemacro_citep">(Chowdhery et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib4" title="">2023</a>)</cite>와 같은 LLM(Large Language Models)은 범용 보조자로서 주목할 만한 능력을 보여주었다. 이 성취의 초석은 명령어 튜닝으로 명령어-출력 쌍 <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib29" title="">2023b</a>)</cite>로 구성된 데이터셋에 대한 학습을 통해 LLM의 능력과 제어 능력을 크게 향상시킨다. 이 기술은 모델의 훈련 목표를 인간의 의도와 효과적으로 정렬하여 모델이 인간의 명령을 효과적이고 안전하게 해석하고 실행할 수 있도록 한다. 따라서 LLM이 효율적이고 신뢰할 수 있는 보조자로 작동하려면 고품질 명령어 튜닝 데이터 세트의 가용성이 중요하다.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">많은 영어 명령어 튜닝 데이터 세트가 존재한다. 그러나 중국어 명령어 튜닝을 위한 사용 가능한 데이터 세트는 일반적으로 크기가 제한적이거나 품질이 부족하다. 중국어 명령어 튜닝 데이터셋은 (1) 영어 명령어 데이터셋에서 파생된 데이터셋들 <cite class="ltx_cite ltx_citemacro_citep">(Peng et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib17" title="">2023</a>)</cite> 또는 NLP 데이터셋들 <cite class="ltx_cite ltx_citemacro_citep">(CLUEbenchmark, <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib6" title="">2022</a>; Yang, <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib26" title="">2023</a>)</cite>, (2) LLMs <cite class="ltx_cite ltx_citemacro_citep">(Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib8" title="">2023</a>)</cite>, (3) 자체 생성한 명령어 튜닝 데이터셋들 <cite class="ltx_cite ltx_citemacro_citep">(Ji et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib12" title="">2023</a>; Sun et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib20" title="">2023</a>)</cite>의 세 가지 유형으로 분류된다. COIG <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib28" title="">2023a</a>)</cite>는 인간이 검증한 보편적인 고품질 중국어 명령어 코퍼스를 구성하기 위해 다중 접근법을 통합한다. 그러나, 앞서 언급한 중국어 명령어 튜닝 데이터셋은 자연적인 중국어 통신 패턴과 일치하지 않거나, 진정한 중국어 언어 데이터가 부족하고, 수많은 문제가 있는 데이터 포인트가 포함되어 있고, 작은 규모의 데이터를 가지고 있는 등의 본질적인 문제를 가지고 있다. 본 논문은 중국어 학습에서 LLM의 숙련도를 높이기 위해 다양한 도메인에 걸쳐 진실한 중국어 언어 데이터에서 출처하고 세심한 수동 세척 절차를 거친 중국어 학습 동조 데이터 세트를 구성하는 데 중점을 둔다.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">본 논문에서는 COIG-<span class="ltx_text ltx_font_bold" id="S1.p3.1.1">CQIA</span> (<span class="ltx_text ltx_font_bold" id="S1.p3.1.2">Chinese</span> Open Instruction Generalist - <span class="ltx_text ltx_font_bold" id="S1.p3.1.3">Q</span>uality <span class="ltx_text ltx_font_bold" id="S1.p3.1.4">I</span>s <span class="ltx_text ltx_font_bold" id="S1.p3.1.5">A</span>ll You Need)는 중국 NLP 커뮤니티에 고품질 및 인간 상호 작용 정렬 명령 미세 조정 데이터를 제공하도록 설계된 고품질 중국 명령 조정 데이터 세트입니다. LIMA <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib30" title="">2023</a>)</cite>의 작업에 영감을 받은 COIG-CQIA는 Q&A 세션과 기사를 포함하여 중국 인터넷 소스의 데이터 세트를 선별하는 데 중점을 둔다. 이러한 출처는 고품질, 다양성 및 관련성을 보장하기 위해 철저한 세척, 구조 조정 및 수동 검토를 거칩니다. 또한, 데이터 품질, 출처 및 혼합 비율의 영향을 평가하기 위한 분석 실험을 수행한다.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">요약하면, 기여도는 다음과 같다:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">우리는 엄격한 필터링 절차를 통해 달성된 인간 상호 작용과 일치하도록 특별히 설계된 고품질 중국 명령어 미세 조정 데이터 세트를 제안한다.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">우리는 소셜 미디어, 백과사전 및 전통적인 NLP 작업을 포함한 다양한 데이터 소스가 모델 성능에 미치는 영향을 탐구한다. 우리의 분석은 중국 인터넷에서 훈련 데이터를 선택하는 데 필수적인 통찰력을 제공한다.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">다양한 벤치마크 테스트 및 인간 평가는 CQIA 데이터 세트에서 미세 조정된 모델이 우수한 성능을 나타냄을 확인하여 CQIA를 중국 NLP 커뮤니티의 귀중한 자원으로 확립한다.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Instruction Tuning Dataset</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">명령어 튜닝은 입력 명령어와 정렬되는 응답을 생성하기 위해 큰 언어 모델을 트레이닝하는 것을 목표로 하며, 이에 의해 대화 및 태스크 실행 능력을 갖는 LLM을 가능하게 한다. 표준 LLM과 비교하여, SFT는 모델의 행동이 더 제어가능하고 예측가능하도록 하여, 인간의 의지를 정렬하는 목적을 달성한다. 명령어 튜닝 데이터세트를 구축하는 방법은 다음과 같다. (1) 순수 수동 주석 <cite class="ltx_cite ltx_citemacro_citep">(Conover et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib7" title="">2023</a>)</cite>. 이 방법은 명령어 및 답변을 수동으로 완전히 구성하는데, 이는 매우 시간이 많이 걸리고 힘든 작업이다; (2) 기존 데이터 세트로부터 변환된 <cite class="ltx_cite ltx_citemacro_citep">(Mishra et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib16" title="">2022</a>; Sanh et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib18" title="">2022</a>; Chung et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib5" title="">2022</a>)</cite>. 일부 연구에서는 NLP 태스크에서 감독된 데이터 세트를 사용하여 명령어 튜닝 데이터를 구성합니다. (3) LLM<cite class="ltx_cite ltx_citemacro_citep">(Honovich et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib10" title="">2022</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib23" title="">2023</a>; Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib24" title="">2023a</a>; Ji et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib12" title="">2023</a>; Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib25" title="">2023b</a>)</cite>를 사용하여 자동으로 생성됩니다. 다른 사람들은 명령어 튜닝 데이터를 생성하기 위해 기존의 LLM을 사용한다. 일반적인 관행은 먼저 고품질 시드 데이터 세트에 수동으로 주석을 달았다가 LLM을 사용하여 시드 명령 및 해당 출력을 확장하여 인간 주석이 거의 없는 대규모 명령 튜닝 데이터를 생성할 수 있다. 그러나 품질을 보장할 수 없고 일정량의 잡음이 있는 데이터가 있어 환각을 유발할 수 있다.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">많은 영어 명령어 튜닝 데이터 세트가 존재한다. 이에 비해 기존의 중국어 명령어 튜닝 데이터셋은 규모가 작거나 품질 문제가 있다. 일부 연구에서는 영어 명령어 튜닝 데이터 세트를 중국어 <cite class="ltx_cite ltx_citemacro_citep">(Peng et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib17" title="">2023</a>)</cite>로 번역했지만, 이는 번역 오류가 누적될 수 있다. pCLUE <cite class="ltx_cite ltx_citemacro_citep">(CLUEbenchmark, <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib6" title="">2022</a>)</cite> and Firefly <cite class="ltx_cite ltx_citemacro_citep">(Yang, <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib26" title="">2023</a>)</cite> original NLP task dataset을 instruction tuning datasets로 변환한다. HC3<cite class="ltx_cite ltx_citemacro_citep">(Guo et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib8" title="">2023</a>)</cite>는 인간 전문가와 ChatGPT 둘 다로부터 수만 개의 비교 응답을 수집한다. COIG <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib28" title="">2023a</a>)</cite>는 인간이 검증한 범용 고품질 중국어 명령어 코퍼스를 구축한다. BELLE <cite class="ltx_cite ltx_citemacro_citep">(Ji et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib12" title="">2023</a>)</cite>와 MOSS <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib20" title="">2023</a>)</cite>는 중국어 명령어 튜닝 데이터셋을 자동으로 생성하기 위해 self-instruct <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib23" title="">2023</a>)</cite>와 유사한 방법을 사용한다.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Data Mixture of SFT</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">현재, 점점 더 많은 연구들이 수업 튜닝의 데이터 품질의 중요성에 주목하기 시작했다. LIMA<cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib30" title="">2023</a>)</cite>는 SFT에 대해 1,000개의 고품질 명령어와 출력만을 사용하며, 매우 강력한 성능을 얻기 위해 RLHF 훈련을 수행할 필요도 없다. AlpaGasus <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib3" title="">2023</a>)</cite>는 강력한 LLM을 사용하여 저품질 데이터를 자동으로 식별하고 필터링하여 고성능 명령어 튜닝 데이터를 생성하여 성능과 훈련 속도를 향상시킨다. Humpback <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib14" title="">2023</a>)</cite>는 고품질 샘플을 필터링하여 보다 강력한 LLM을 미세 조정합니다.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Others<cite class="ltx_cite ltx_citemacro_citep">(Song et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib19" title="">2023</a>)</cite>는 서로 다른 명령어 튜닝 데이터 세트의 혼합 전략의 영향을 탐구한다. Tulu 시리즈 <cite class="ltx_cite ltx_citemacro_citep">(Konchakov et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib13" title="">2023</a>; Ivison et al., <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib11" title="">2023</a>)</cite>는 명령어 다양성이 증가하면 성능이 효과적으로 향상될 수 있으며 서로 다른 명령어 튜닝 데이터세트는 특정 기술을 발견하거나 향상시킬 수 있는 반면, 어떤 데이터세트(또는 조합)도 모든 평가에서 최상의 성능을 제공하지 않는다는 것을 보여준다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>CQIA CURATION</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S3.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.1" style="width:433.6pt;height:284.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(38.6pt,-25.3pt) scale(1.21637025000768,1.21637025000768) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.T1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.1.1">Source</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.2.1">Quantity</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.3.1">Source</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T1.1.1.1.1.4.1">Quantity</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.1.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.1.1">Zhihu</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.1.2">8837</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.1.3">Douban</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.1.1.2.1.4">3132</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.3.2">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.2.1">Xiaohongshu</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.2.2">1508</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.2.3">Segment Fault</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.3.2.4">458</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.4.3">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.3.1">Encyclopedia Article</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.3.2">980</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.3.3">Encyclopedia of China</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.4.3.4">1706</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.5.4">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.4.1">WikiHow</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.4.2">1876</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.4.3">COIG PC</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.5.4.4">3000</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.6.5">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.5.1">Middle school Exam</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.5.2">2000</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.5.3">Graduate Entrance Examination</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.6.5.4">475</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.7.6">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.7.6.1">Logi QA</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.7.6.2">422</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.7.6.3">CValue</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.7.6.4">906</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.8.7">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.7.1">COIG-Human-Value</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.7.2">101</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.7.3">Chinese Traditional</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.8.7.4">232</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.9.8">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.9.8.1">Idiom Explanation</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.9.8.2">112</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.9.8.3">Poem Writing</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.9.8.4">47</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.10.9">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.10.9.1">Classical Chinese Translation</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.10.9.2">112</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.10.9.3">MBA Encyclopedia</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.10.9.4">10689</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.11.10">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.11.10.1">Finance NLP Task</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.11.10.2">600</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.11.10.3">Medical Encyclopedia</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.11.10.4">8351</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.12.11">
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.12.11.1">Medical Article</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.12.11.2">186</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.12.11.3">Law</td>
<td class="ltx_td ltx_align_center" id="S3.T1.1.1.12.11.4">2645</td>
</tr>
<tr class="ltx_tr" id="S3.T1.1.1.13.12">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.1.13.12.1">Total</td>
<td class="ltx_td ltx_border_bb ltx_border_t" id="S3.T1.1.1.13.12.2"></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.1.1.13.12.3">48375</td>
<td class="ltx_td ltx_border_bb ltx_border_t" id="S3.T1.1.1.13.12.4"></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 1:</span></figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>
The amount of data from different sources of the dataset mixture
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">To ensure the quality and diversity of our data, we manually selected 13 data sources from high-quality websites and data resources within the Chinese Internet. These sources include community Q&amp;A forums, encyclopedic sites, content creation platforms, examinations, etc. We also incorporated high-quality Chinese NLP datasets to enrich the diversity of tasks. Specifically, we categorized all data sources into four types: Social Media &amp; forums, World Knowledge, NLP tasks, and Examinations. The data sources and their descriptions are as follows.</p>데이터의 품질과 다양성을 보장하기 위해 고품질 웹사이트와 중국 인터넷 내 데이터 리소스에서 13개의 데이터 소스를 수동으로 선택했다. 이러한 출처에는 커뮤니티 Q&A 포럼, 백과사전 사이트, 콘텐츠 생성 플랫폼, 테스트 등이 포함된다. 또한 작업의 다양성을 풍부하게 하기 위해 고품질 중국 NLP 데이터 세트를 통합했습니다. 구체적으로, 우리는 모든 데이터 소스를 소셜 미디어 및 포럼, 세계 지식, NLP 과제 및 시험의 네 가지 유형으로 분류했다. 데이터 소스 및 그 설명은 다음과 같다.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Social Media &amp; Forums</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Zhihu</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.1">사용자가 광범위한 주제에 대해 질문하고 답할 수 있는 생생한 질의응답 플랫폼으로 지식과 통찰력의 포괄적인 저장소입니다. Zhihu는 사용자들이 전문적인 지식이나 개인적인 경험을 반영하며 유익하고 잘 숙고된 답변을 제공하도록 권장한다. 그러나 Zhihu에 대한 답변에 대한 검토 메커니즘의 부재는 우리의 품질 표준에 미치지 못하는 많은 양의 콘텐츠로 이어진다. 저품질 답변을 필터링하기 위해 50개 이상의 업보트가 포함된 답변을 선택한 후 규칙 기반 방법을 사용하여 민감하거나 유해한 키워드가 포함된 콘텐츠를 필터링했다. 그 후 GPT-4를 사용하여 1-10의 척도로 응답을 채점하고 점수가 8 이상인 응답을 유지했다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">SegmentFault</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.1">IT 기술에 초점을 맞춘 질의응답 커뮤니티로 중국 개발자에게 스택 오버플로우와 유사한 고품질 교환 플랫폼을 제공한다. 이 커뮤니티에서 사용자는 IT 기술과 관련된 질문을 묻고 답하는 데 참여하며, 여기서 질문자는 가장 유용한 답변을 수용할 수 있다. 또한 커뮤니티 구성원은 답변에 대해 투표하거나 의견을 제시할 수도 있습니다. 우리의 데이터는 프로그래밍 언어 또는 소프트웨어 버전의 변경으로 인해 이전 콘텐츠가 구식이 될 수 있기 때문에 2018년 이전에 게시된 콘텐츠에서 수집된다. 그런 다음 최소 5개의 투표로 "승인된" 답변을 선택합니다. 또한, 저품질 콘텐츠를 제거하거나 수정하기 위해 모든 (질문, 답변) 쌍을 수동으로 검토합니다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Douban</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px3.p1.1">이는 사용자가 영화, 책, TV 시리즈, 음악 등과 같은 문학 및 예술 작품과 관련된 콘텐츠를 만들 수 있도록 하는 소셜 네트워크 및 데이터베이스이다. 우리는 책, 영화, TV 시리즈에서 데이터를 샘플링하고 평점, 배우/승무원에 대한 자세한 정보, 긴 리뷰를 포함하는 메타데이터를 추출합니다. 그리고 시놉시스 생성, 리뷰 생성, 추천의 세 가지 작업을 설계한다. 각 작업에 대해 다양한 프롬프트 템플릿을 수동으로 설계하고 이러한 템플릿을 메타데이터와 결합하여 명령어를 구성했다. 시놉시스 생성 및 리뷰 생성을 위해 영화 또는 TV 시리즈 이름과 결합된 프롬프트 템플릿과 더반 사용자가 생성한 응답을 사용하여 지침을 구성합니다. 그런 다음 임계값보다 짧은 길이의 응답을 제거하고 개인 정보 및 관련 없는 내용(예: "공식 계정 구독")을 삭제합니다. 또한 응답의 세부 정보와 더 잘 일치하도록 복잡한 암시적 의도를 추가하기 위해 일부 지침을 수동으로 조정했습니다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Xiaohongshu</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS0.Px4.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px4.p1.1">사용자가 자신의 삶, 여행, 음식, 상품 추천 등을 공유할 수 있는 공간을 제공한다. 이 플랫폼의 콘텐츠는 독특하고 표현적인 스타일로 중국 인터넷에서 유명합니다. 다른 사용자들과의 상호 작용을 수반하는 것("@User_Name") 및 이미지 또는 비디오를 참조하는 것("그림/비디오에 도시된 바와 같이")을 제외하고, 500 내지 2000 범위의 길이를 갖는 게시물을 샘플링한다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px5">
<h5 class="ltx_title ltx_title_paragraph">Ruozhiba</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.SSS0.Px5.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px5.p1.1">은 이익에 기반을 둔 커뮤니티 포럼인 바이두 티에바의 하위 포럼이다. 그 게시물에는 종종 말장난, 다의어 용어, 인과적 역전 및 동음이가 포함되어 있으며, 그 중 다수는 논리적 함정으로 설계되어 인간에게도 도전을 제기한다. 우리는 가장 많은 지지를 받은 500개의 실을 모았다. 제목을 지침으로 사용하여 지시적이지 않은(즉, 선언적 진술 또는 답변할 수 없는) 또는 독성이 있는 제목을 제거한다. 응답은 인간 또는 GPT-4에 의해 생성되었다. 우리는 정확성을 보장하기 위해 GPT4의 응답에 대한 수동 검토를 수행하여 궁극적으로 240개의 (명령, 응답) 쌍을 얻었다.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>World Knowledge</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>General Encyclopedia</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">일반 백과사전은 다양한 분야에 걸쳐 광범위한 주제에 대한 포괄적인 취재를 제공한다. 중국 백과사전 웹사이트(One Hundred Thousand Whys<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://10why.net/</span></span></span>, wikiHow-zh<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://zh.wikihow.com</span></span></span> and Encyclopedia of China<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://www.zgbk.com/</span></span></span>)에서 데이터를 수집한다. <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p1.1.1">One Hundred Thousand Whys</span>은 인기 있는 과학을 목표로 하는 백과사전 웹사이트로, 자연 과학에서 인문학에 이르기까지 주제에 걸쳐 "왜"를 묻는 수천 개의 고품질 기사를 특징으로 합니다. 우리는 모든 15개 범주에서 데이터를 수집하고 각 범주에 걸쳐 균일한 분포를 보장한다. 기사 제목은 교육(예: "비행할 때 고산병에 걸리지 않을까?")으로 사용되며 내용은 응답으로 사용되며 300자 미만의 응답은 걸러진다. <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p1.1.2">wikiHow-zh</span>, wikiHow의 중국어 버전은 광범위한 주제를 다루는 백과사전 스타일의 웹사이트로, 여러 개정이 있는 수만 개의 "how-to" 기사를 특징으로 합니다. 사이트에서 xxx 기사를 수집하고 샘플링 온도가 3인 19개 카테고리 모두에서 1500개의 항목을 샘플링했다. 원본 데이터는 HTML에 있으므로 HTML을 파싱하고 마크다운을 사용하여 기사 콘텐츠를 연결한다. 그 후, 우리는 저품질 데이터(예: 잘못된 수식 변환)와 3000 단어 길이를 초과하는 기사를 필터링했다. 제목을 지침으로 사용하고 기사 내용을 응답으로 사용합니다. <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p1.1.3">Encyclopedia of China</span>은 도메인 전문가에 의해 작성되고 수정된 대략 500,000개의 엔트리를 포함하는 포괄적인 백과사전이다. 개념 설명 작업을 위한 다양한 프롬프트 템플릿을 설계합니다. 우리는 각각의 내용과 함께 엔트리 이름과 여러 자막으로 구성된 구조로 모든 74개 범주의 엔트리를 샘플링한다. 명령어를 구성하기 위해 입력 이름 또는 자막을 프롬프트 템플릿과 무작위로 결합했다. 예를 들어, 자막 "<span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS1.p1.1.4">Biography</span>", "<span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS1.p1.1.5">Academic Theories</span>", 및 "<span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS1.p1.1.6">Impacts</span>"을 포함하는 "Confucius" 항목에 대해 "<span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS1.p1.1.7">Academic Theories</span>"를 선택하여 "<span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS1.p1.1.8">Academic Theories</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Domain Specific Knowledge</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">우리는 의학, 경제 관리, 전자 및 농업의 4가지 특정 영역에서 데이터를 수집했다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p2">
<p class="ltx_p" id="S3.SS2.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p2.1.1">Medical Domain</span> sources from three websites: Baobaozhidao, Qianwen Health, and Baikemingyi. <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p2.1.2">Baobaozhidao</span> 및 <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p2.1.3">Qianwen Health</span> 기능 질문 및 답변 스타일 기사는 의료 전문가가 작성했으며 전자는 주로 광범위한 의료 분야에 초점을 맞춘 반면 후자는 모체 및 유아 건강에 중점을 둔다. 제목이 문제되지 않는 사이트를 제외하고 이 두 사이트에서 기사를 수집했다. 그 후, 제목을 지침으로, 기사 내용을 응답으로 사용했다. <span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p2.1.4">Baikemingyi</span> contains Wikipedia-style structured data, featuring introduced to the 수만 개의 질병 및 약물. 다양한 프롬프트 템플릿과 이러한 템플릿과 결합된 엔트리 이름을 설계하여 명령을 구성했습니다 (예: "<span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS2.p2.1.5">관절 통증에 대한 전문 소개를 작성</span>).</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p3">
<p class="ltx_p" id="S3.SS2.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p3.1.1">Economic Management Domain</span> 데이터는 Wikipedia-style structured knowledge, authored and revised by numerous contributors. "<span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS2.p3.1.2">Remittance Agent</span>과 같이 명령어를 구성하기 위해 엔트리 이름과 랜덤 템플릿을 결합하여 다양한 프롬프트 템플릿을 설계하였다. 궁극적으로, 엔트리의 내용은 연결되고 마크다운 형식의 응답으로 구성된다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p4">
<p class="ltx_p" id="S3.SS2.SSS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p4.1.1">Electronics Domain</span> data is sourced from the EETrees electronic encyclopedia, also structured in form. 다양한 프롬프트 템플릿을 설계하고 이를 엔트리 이름과 결합하여 해당 콘텐츠를 응답으로 사용하여 지침을 구성합니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p5">
<p class="ltx_p" id="S3.SS2.SSS2.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p5.1.1">농업 도메인</span> 농업 백과사전 웹사이트의 소스, 식물 재배에서 동물 육종에 이르기까지 다양한 주제를 포함한다. 비질문 제목, 이미지가 포함되거나 길이가 300개 미만인 항목을 제외한 10개 주제에 대한 기사를 모두 수집했다. 그 후, 논문의 제목과 내용으로부터 (지시, 응답) 쌍을 구성한다.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Examinations</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">The Middle School and College Entrance Examinations</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS3.SSS0.Px1.p1.1">COIG 데이터 세트 <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib28" title="">2023a</a>)</cite>, 무해하고 유용하며 다양한 중국 명령어 데이터 세트에서 주로 파생된다. 중국의 시험은 그 일부이며, 중학교와 대학 입학시험은 중국의 주요 일반 능력 시험이다. 이들 자료에는 인문 교과(중국어, 영어, 정치, 생물, 역사, 지리)를 주로 다루는 다양한 질문 유형과 상세한 답변 설명이 포함되어 있다. 우리는 이 주제에 걸친 데이터에 대한 온도 샘플링을 사용한 다음 형식 오류가 있는 질문과 답변을 걸러낸다. 질문은 지침으로 사용되었으며 "답변"과 "분석" 필드가 연결되어 확장된 응답을 형성하여 1964(지침, 응답) 쌍이 생성되었다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Graduate Entrance Examination</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS3.SSS0.Px2.p1.1">중국에서 가장 어려운 시험 중 하나로 대학 입시를 능가하고 고도의 지식 적용과 깊이가 필요하다. 우리는 최근 몇 년 동안 수학, 컴퓨터 과학, 화학, 법, 심리학, 의학 등을 포함한 학문에 걸쳐 다양한 시험지를 수집했습니다. 이미지-텍스트 변환을 위해 Mathpix<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://mathpix.com/</span></span></span>을 사용하여 질문과 답변을 추출하여 LaTeX 형식으로 변환하였다. 분석 없이 데이터를 제거하고 질문과 답변의 정확성을 수동으로 검증합니다. 분석 없이 데이터를 제거하고 질문과 답변의 정확성을 수동으로 검증합니다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Logical Reasoning Test</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS3.SSS0.Px3.p1.1">논리적, 분석적 추론을 적용하여 문제를 해결하는 능력을 평가하는 것을 목표로 한다. 이러한 유형의 검사는 비판적 사고력과 문제 해결력을 평가하기 위한 다양한 경쟁 시험에서 널리 사용되고 있다. 우리는 인터넷에서 논리 추론 질문을 수집하고 상세한 답변 분석이 포함된 질문을 유지한 다음 (명령, 응답) 쌍으로 구성한다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Chinese Culture Test</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.SSS0.Px4.p1">
<p class="ltx_p" id="S3.SS3.SSS0.Px4.p1.1">중국 전통문화와 역사에 대한 숙달을 조사하다. 이를 위해 중국 전통문화에 대한 객관식 문항을 인터넷상에서 수집하였고, 이에 대한 답안 분석을 실시하여 (지도, 응답) 쌍으로 구성하였다.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>NLP Datasets</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">COIG-PC</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px1.p1.1">COIG-PC 데이터 세트는 중국 NLP 연구의 발전을 목표로 하는 중국 NLP 작업의 포괄적인 모음이다. 이 데이터 세트의 목표는 연구자와 개발자에게 풍부한 리소스 세트를 제공하는 것이며, 이는 중국 텍스트를 다루는 언어 모델의 능력을 향상시키는 데 사용할 수 있다. 연구자와 개발자를 위한 포괄적인 리소스 세트를 제공하여 텍스트 생성, 정보 추출, 감정 분석 및 기계 번역 등을 포함한 다양한 도메인에 걸쳐 언어 모델 기능의 발전을 촉진한다. 처음에는 COIG-PC에서 중국어와 영어를 모두 포함하는 1,413개의 과제를 선택했다. 그런 다음, 주로 전통적인 NLP 데이터 세트에서 출처된 정보 추출, 분류, 요약 및 기타를 포함하여 품질 기준을 충족하는 250개의 작업을 수동으로 선택한다. 온도 샘플링을 통해 최종적으로 3,000개(명령, 응답) 쌍을 샘플링하며, 이는 품질을 보장하기 위해 인간에 의해 추가로 검증된다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">COIG Human Value</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px2.p1.1">는 인간 값에 정렬된 명령 미세 조정 데이터를 제공하도록 설계된 COIG 데이터세트<cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib28" title="">2023a</a>)</cite>의 서브세트이다. 자체-인스트럭션(Self-Instruct<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib23" title="">2023</a>)</cite>) 방법을 사용하여 구축한 중국 문화 가치를 반영하는 부분을 수동으로 선택한 시드 명령어에서 선택했다. 우리는 형식 오류와 오답이 있는 데이터를 수동으로 필터링하여 (지시, 응답) 쌍을 형성하기 위한 답변에 대한 설명을 포함하는 데이터를 유지했다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Firefly Chinese Traditional</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS4.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px3.p1.1">이 작업은 중국 전통 문화와 관련된 반딧불이 데이터 세트 <cite class="ltx_cite ltx_citemacro_cite">Yang (<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib26" title="">2023</a>)</cite>의 하위 집합인 고전 중국 번역, 고대 시 쓰기 및 Idiom 해석의 세 가지 작업을 포함한다. 300자보다 짧은 응답을 필터링하고 각 작업에서 300개의 인스턴스를 샘플링합니다. 그런 다음 명령어-응답 불일치, 응답 오류 및 응답할 수 없는 명령어와 같은 저품질 데이터를 수동으로 필터링했다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">100PoisonMpts</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS4.SSS0.Px4.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px4.p1.1">차별과 공감에 대한 문제를 다루는 것은 법학, 심리학, 아동 교육, 모호한 사실, 친밀한 관계 등을 포함한 다양한 차원에 걸쳐 있다. 그것은 편견과 차별을 불러일으키는 인간 생성 프롬프트와 인간 가치와 일치하는 전문가 조작 응답을 포함한다. CQIA의 무해성을 향상시키기 위해 100PoisonMpts의 모든 데이터를 샘플링한다.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="567" id="S3.F1.g1" src="https://arxiv.org/html/2403.18058v1/extracted/5497703/fig/self-instruct-final.png" width="598">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1:</span>Most common root verbs (inner circle) and top direct noun objects (outer circle) in the CQIA dataset. 우리는 특정 동사-명사 쌍이 30개 이상의 인스턴스를 가질 때만 시각화하며 많은 명령에는 동사-명사 구조가 포함되어 있지 않다.</figcaption><figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Most common root verbs (inner circle) and top direct noun objects (outer circle) in the CQIA dataset. Note that we only visualize when a certain verb-noun pair has more than 30 instances, and many instructions do not contain a verb-noun structure.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="370" id="S3.F2.g1" src="https://arxiv.org/html/2403.18058v1/extracted/5497703/fig/overview_cqia.png" width="598">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2:</span>Overview of CQIA Task Types.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="396" id="S3.F3.g1" src="https://arxiv.org/html/2403.18058v1/extracted/5497703/fig/dis-1.png" width="598">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3:</span>Length distribution of instruction and responses. 명령어는 데이터 세트에서 원래 명령어와 입력의 연결입니다.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Length distribution of instruction and responses. Note that the instruction is the concatenation of original instructions and inputs in our dataset.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Data Analysis</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Statistics</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">표 <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.T1" title="Table 1 ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_tag">1</span></a>는 모든 소스에 대한 데이터 통계를 설명한다. 우리는 중국 인터넷과 커뮤니티의 22개 출처에서 총 48,375건의 사례를 수집하여 일반 지식과 STEM에서 인문학에 이르는 영역을 다루었다. <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.F2" title="Figure 2 ‣ 100PoisonMpts ‣ 3.4 NLP Datasets ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_tag">2</span></a>는 정보 추출, 질의 응답, 코드 생성 등을 포괄하는 다양한 작업 유형을 예시하고 있다. 우리는 그림<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.F3" title="Figure 3 ‣ 100PoisonMpts ‣ 3.4 NLP Datasets ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_tag">3</span></a>에서 명령어와 응답의 길이 분포를 시연했다.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Diversity</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">COIG-CQIA 데이터셋의 다양성을 분석하기 위해 Hanlp tool<cite class="ltx_cite ltx_citemacro_cite">He and Choi (<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib9" title="">2021</a>)</cite>를 사용하여 선행 작업<cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib23" title="">2023</a>); Lou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib15" title="">2023</a>)</cite>를 따라 명령어를 파싱한 후 상위 직접 명사 객체와 함께 근에 가장 가까운 동사를 추출한다. 그런 다음 그림<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S3.F1" title="Figure 1 ‣ 100PoisonMpts ‣ 3.4 NLP Datasets ‣ 3 CQIA CURATION ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_tag">1</span></a>에서 상위 20개의 가장 일반적인 루트 동사와 해당 직접 명사 객체를 표시한다. 이 그림에서 우리는 CQIA가 다양한 범위의 지시와 의도를 가지고 있음을 관찰할 수 있다.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.1" style="width:433.6pt;height:188.5pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-53.5pt,23.2pt) scale(0.802028748010008,0.802028748010008) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T2.1.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.2.1">Source</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.3.1">Open QA</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.4.1">Brainstorming</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.5.1">Classification</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.6.1">Generation</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.7.1">Summarization</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.8.1">Rewrite</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.9"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.9.1">Closed QA</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.10"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.10.1">Extract</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.11"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.11.1">Math</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T2.1.1.1.1.12"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.12.1">Code</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.1.1.1.1.13"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.1.1.13.1">Average</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T2.1.1.2.1.1" rowspan="13"><span class="ltx_text" id="S4.T2.1.1.2.1.1.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T2.1.1.2.1.1.1.1" style="width:6.8pt;height:25.7pt;vertical-align:-9.4pt;"><span class="ltx_transformed_inner" style="width:25.7pt;transform:translate(-9.43pt,0pt) rotate(-90deg) ;">
<span class="ltx_p" id="S4.T2.1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.2.1.1.1.1.1.1">Yi-6B</span></span>
</span></span></span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.2">SegmentFault</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.3">26.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.4">33.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.5">8.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.6">23.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.7">29.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.8">20.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.9">25.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.10">22.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.11">14.5</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T2.1.1.2.1.12">32.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.13">23.7</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.3.2">
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.1">COIG PC</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.2">31.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.3">47.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.4">28.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.5">44.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.6">43.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.7">53.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.8">45.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.9">28.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.10">35.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.1.1.3.2.11">23.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.12">38.2</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.4.3">
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.3.1">Douban</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.3.2">45.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.3.3">64.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.3.4">23.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.3.5">64.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.3.6">38.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.3.7">37.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.3.8">34.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.3.9">25.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.3.10">32.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.1.1.4.3.11">42.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.4.3.12">40.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.5.4">
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.4.1">Zhihu</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.4.2">48.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.4.3">72.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.4.4">19.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.4.5">66.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.4.6">24.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.4.7">29.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.4.8">28.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.4.9">12.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.4.10">8.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.1.1.5.4.11">40.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.5.4.12">35.0</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.6.5">
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.5.1">Logi QA</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.5.2">45.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.5.3">65.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.5.4">32.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.5.5">55.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.5.6">37.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.5.7">49.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.5.8">47.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.5.9">38.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.5.10">17.9</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.1.1.6.5.11">40.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.6.5.12">42.9</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.7.6">
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.6.1">Ruozhiba</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.6.2"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.6.2.1">64.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.6.3"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.1.7.6.3.1">84.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.6.4"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.6.4.1">50.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.6.5"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.1.7.6.5.1">73.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.6.6">45.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.6.7">39.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.6.8"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.6.8.1">57.0</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.6.9">30.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.6.10">27.3</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.1.1.7.6.11"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.7.6.11.1">63.6</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.7.6.12">53.6</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.8.7">
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.8.7.1">Wiki</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.8.7.2">51.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.8.7.3">67.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.8.7.4">21.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.8.7.5">60.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.8.7.6">30.8</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.8.7.7">31.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.8.7.8">30.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.8.7.9">21.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.8.7.10">22.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.1.1.8.7.11">34.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.8.7.12">37.2</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.9.8">
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.8.1">Finance</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.8.2">43.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.8.3">65.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.8.4">30.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.8.5">57.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.8.6">36.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.8.7">30.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.8.8">34.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.8.9">31.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.8.10">15.7</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.1.1.9.8.11">27.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.9.8.12">37.2</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.10.9">
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.9.1">Exam</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.9.2">51.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.9.3">74.3</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.9.4">42.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.9.5">70.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.9.6"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.1.10.9.6.1">54.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.9.7"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.1.10.9.7.1">60.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.9.8"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.1.10.9.8.1">56.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.9.9"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.10.9.9.1">47.7</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.9.10"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.10.9.10.1">41.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.1.1.10.9.11">49.9</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.10.9.12"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.1.10.9.12.1">54.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.11.10">
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.10.1">Xhs</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.10.2">25.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.10.3">47.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.10.4">8.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.10.5">45.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.10.6">8.6</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.10.7">21.4</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.10.8">22.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.10.9">7.0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.10.10">28.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.1.1.11.10.11">27.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.11.10.12">24.1</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.12.11">
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.11.1">WikiHow</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.11.2">0.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.11.3">1.2</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.11.4">1.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.11.5">7.7</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.11.6">18.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.11.7">3.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.11.8">23.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.11.9">0.5</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.11.10">0.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T2.1.1.12.11.11">2.1</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.12.11.12">5.8</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.13.12">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.1.13.12.1">CQIA-Subset</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.1.13.12.2"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.1.13.12.2.1">59.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.1.13.12.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.13.12.3.1">86.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.1.13.12.4"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.1.13.12.4.1">48.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.1.13.12.5"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.13.12.5.1">79.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.1.13.12.6"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.13.12.6.1">60.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.1.13.12.7"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.13.12.7.1">69.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.1.13.12.8">50.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.1.13.12.9"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.1.13.12.9.1">42.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.1.13.12.10"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.1.13.12.10.1">37.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T2.1.1.13.12.11"><span class="ltx_text ltx_framed_underline" id="S4.T2.1.1.13.12.11.1">55.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.1.1.13.12.12"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.13.12.12.1">64.2</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 2:</span>GPT4를 사용하여 BELLE-EVAL에서 평가된 다양한 데이터셋에 대해 학습된 Yi-6B의 성능.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S4.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.1" style="width:433.6pt;height:188.5pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-53.5pt,23.2pt) scale(0.802028748010008,0.802028748010008) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.1.1.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T3.1.1.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.2.1">Source</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.3.1">Open QA</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.4.1">Brainstorming</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.5.1">Classification</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.6.1">Generation</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.7.1">Summarization</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.8"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.8.1">Rewrite</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.9"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.9.1">Closed QA</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.10"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.10.1">Extract</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.11"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.11.1">Math</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T3.1.1.1.1.12"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.12.1">Code</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.1.1.1.1.13"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1.13.1">Average</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T3.1.1.2.1.1" rowspan="13"><span class="ltx_text" id="S4.T3.1.1.2.1.1.1">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T3.1.1.2.1.1.1.1" style="width:6.8pt;height:25.7pt;vertical-align:-9.4pt;"><span class="ltx_transformed_inner" style="width:25.7pt;transform:translate(-9.43pt,0pt) rotate(-90deg) ;">
<span class="ltx_p" id="S4.T3.1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.2.1.1.1.1.1.1">Yi-6B</span></span>
</span></span></span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.2.1.2">SegmentFault</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.2.1.3">51.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.2.1.4">70.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.2.1.5">43.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.2.1.6">66.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.2.1.7">57.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.2.1.8">75.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.2.1.9">41.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.2.1.10">47.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.2.1.11">75.5</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T3.1.1.2.1.12">65.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.1.2.1.13">60.7</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.3.2">
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.3.2.1">COIG PC</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.3.2.2">19.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.3.2.3">38.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.3.2.4">27.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.3.2.5">43.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.3.2.6">37.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.3.2.7">63.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.3.2.8">40.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.3.2.9">25.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.3.2.10">43.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.3.2.11">19.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.3.2.12">37.2</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.4.3">
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.3.1">Douban</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.3.2">57.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.3.3">81.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.3.4">63.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.3.5">76.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.3.6">54.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.3.7">60.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.3.8">47.5</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.3.9">50.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.3.10">73.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.4.3.11">50.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.4.3.12">63.2</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.5.4">
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.4.1">Zhihu</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.4.2">66.5</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.4.3">90.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.4.4">52.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.4.5">82.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.4.6">71.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.4.7">78.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.4.8">46.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.4.9">39.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.4.10"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.5.4.10.1">76.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.5.4.11">62.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.5.4.12">69.1</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.6.5">
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.5.1">Logi QA</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.5.2">51.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.5.3">76.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.5.4">64.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.5.5">75.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.5.6">60.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.5.7">71.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.5.8">61.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.5.9">52.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.5.10">47.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.6.5.11">45.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.6.5.12">62.0</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.7.6">
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.7.6.1">Ruozhiba</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.7.6.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.6.2.1">75.9</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.7.6.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.6.3.1">92.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.7.6.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.6.4.1">76.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.7.6.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.6.5.1">92.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.7.6.6"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.6.6.1">77.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.7.6.7">70.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.7.6.8"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.6.8.1">67.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.7.6.9"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.6.9.1">68.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.7.6.10">72.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.7.6.11"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.6.11.1">65.2</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.7.6.12"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.6.12.1">76.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.8.7">
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.7.1">Wiki</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.7.2">63.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.7.3">75.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.7.4">44.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.7.5">80.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.7.6">47.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.7.7">66.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.7.8">47.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.7.9">50.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.7.10">56.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.8.7.11">55.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.8.7.12">60.5</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.9.8">
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.8.1">Finance</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.8.2">46.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.8.3">71.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.8.4">17.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.8.5">60.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.8.6">27.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.8.7">23.6</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.8.8">17.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.8.9">29.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.8.10">28.5</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.9.8.11">24.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.9.8.12">36.7</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.10.9">
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.9.1">Exam</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.9.2">49.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.9.3">79.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.9.4">64.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.9.5">79.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.9.6">61.5</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.9.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.1.10.9.7.1">79.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.9.8">66.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.9.9">61.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.9.10">52.8</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.10.9.11">56.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.10.9.12">66.2</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.11.10">
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.11.10.1">Xhs</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.11.10.2">51.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.11.10.3">76.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.11.10.4">38.5</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.11.10.5">68.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.11.10.6">25.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.11.10.7">46.0</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.11.10.8">28.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.11.10.9">32.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.11.10.10">74.6</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.11.10.11">36.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.11.10.12">50.3</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.12.11">
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.12.11.1">Wikihow</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.12.11.2">54.7</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.12.11.3">75.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.12.11.4">32.1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.12.11.5">68.2</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.12.11.6">45.3</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.12.11.7">55.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.12.11.8">40.9</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.12.11.9">55.8</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.12.11.10">41.0</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T3.1.1.12.11.11">44.4</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.1.12.11.12">52.7</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.13.12">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.1.13.12.1">CQIA-Subset</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.1.13.12.2">56.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.1.13.12.3">84.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.1.13.12.4">48.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.1.13.12.5">72.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.1.13.12.6">60.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.1.13.12.7">70.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.1.13.12.8">54.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.1.13.12.9">50.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.1.13.12.10">52.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T3.1.1.13.12.11">49.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T3.1.1.13.12.12">61.9</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 3:</span>GPT4를 사용하여 BELLE-EVAL에서 평가된 다양한 데이터셋에 대해 학습된 Yi-34B의 성능.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>EXPERIMENTAL SETUP</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">이 섹션에서는 COIG-CQIA를 사용하여 모델을 미세 조정하고 평가 방법을 자세히 설명한다.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Evaluation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">C-Eval</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.1">은 기초 모델에 대한 포괄적인 중국 평가 제품군이다. 52개의 다양한 학문과 4개의 난이도에 걸쳐 13948개의 객관식 문항으로 구성되어 있다. 모형의 최종 예측으로 로그 우도가 가장 높은 답안 옵션을 선택한다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">CMMLU</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px2.p1.1">그것은 중국어와 문화의 맥락에서 LLM의 지식과 추론 능력을 평가하기 위해 특별히 고안된 포괄적인 평가 벤치마크이다. CMMLU는 초등에서 고급 전문가 수준에 이르는 67개의 주제로 구성된 광범위한 주제를 다룬다. 물리학, 수학 등 계산적 전문지식이 필요한 과목과 인문사회과학 분야의 학문을 포함한다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">BELLE-EVAL</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px3.p1.1">는 개방형 질문 응답, 브레인스토밍, 수학, 코딩 등을 포함하는 다양한 도메인에 걸쳐 12개의 상이한 명령 유형을 포함하는 개방형 테스트 세트이다. 다양한 유형에 걸쳐 지침을 따르는 모델의 능력을 평가하는 데 사용할 수 있습니다. 명령어에 대한 응답을 생성하기 위해 샘플링 생성을 사용하고 모델 기반 평가 방법을 사용한다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">SafetyBench</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS1.SSS0.Px4.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px4.p1.1">7개의 개별 안전 문제 범주에 걸쳐 11,435개의 다양한 객관식 질문을 포함합니다. 우리는 소수의 샷 설정에서 모델을 평가한다.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Implementation Details</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">중국어 모델의 선두를 나타내는 Yi<cite class="ltx_cite ltx_citemacro_cite">Young et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib27" title="">2024</a>)</cite>, Qwen<cite class="ltx_cite ltx_citemacro_cite">Bai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib1" title="">2023</a>)</cite>, InternLM<cite class="ltx_cite ltx_citemacro_cite">Team (<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib21" title="">2023</a>)</cite>를 포함하여 COIG-CQIA 상에서 이중언어 LLMs(Chinese and English)를 미세 조정하였다. 우리는 다음 개정에서 구현 세부 사항을 제공할 것입니다.</p>
</div>
<figure class="ltx_table" id="S5.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T4.1" style="width:346.9pt;height:701.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(97.8pt,-197.7pt) scale(2.29226864828893,2.29226864828893) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T4.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T4.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T4.1.1.1.1.1">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T4.1.1.1.1.2">SafetyBench</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T4.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T4.1.1.2.1.1">COIG PC</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.2.1.2">81.2</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.3.2.1">Chinese Tradiational</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.3.2.2">76.6</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.4.3.1">Douban</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.4.3.2">76.2</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.5.4.1">Exam</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.5.4.2">77.6</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.6.5.1">Finance</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.6.5.2">75.1</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.7.6.1">Logi QA</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.7.6.2">79.1</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.8.7.1">Ruozhiba</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.8.7.2">81.3</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.9.8.1">Segmentfault</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.9.8.2">78.0</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.10.9.1">Wiki</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.10.9.2">75.8</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.11.10.1">Wikihow</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.11.10.2">76.4</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.12.11.1">Xhs</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.12.11.2">76.0</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.13.12.1">Zhihu</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.13.12.2">75.8</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T4.1.1.14.13.1">Human Value</th>
<td class="ltx_td ltx_align_center" id="S5.T4.1.1.14.13.2">79.1</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T4.1.1.15.14.1">CQIA-Sub-6B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.15.14.2"><span class="ltx_text ltx_font_bold" id="S5.T4.1.1.15.14.2.1">81.7</span></td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.16.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T4.1.1.16.15.1">GPT-4-0613</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T4.1.1.16.15.2">89.2</td>
</tr>
<tr class="ltx_tr" id="S5.T4.1.1.17.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T4.1.1.17.16.1">GPT-3.5-turbo-0613</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T4.1.1.17.16.2">80.4</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 4:</span>SafetyBench scores of Yi-6B trained on various data sources.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S5.T5">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T5.1" style="width:442.3pt;height:225.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(97.6pt,-49.7pt) scale(1.78965518838146,1.78965518838146) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T5.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S5.T5.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S5.T5.1.1.1.1.1">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.1.2">Ceval (val 5-shot)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S5.T5.1.1.1.1.3">CMMLU (test 5-shot)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T5.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T5.1.1.2.1.1">Qwen-1.8b</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.2.1.2">51.34</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T5.1.1.2.1.3">47.26</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.1.3.2.1">Yi-6B</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.3.2.2">73.40</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.3.2.3">74.85</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.1.4.3.1">Qwen-14b</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.4.3.2">68.20</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.4.3.3">67.96</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.1.5.4.1">InternLM2-20b</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.5.4.2">71.25</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.5.4.3">67.48</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T5.1.1.6.5.1">Yi-34b</th>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.6.5.2">77.04</td>
<td class="ltx_td ltx_align_center" id="S5.T5.1.1.6.5.3">78.18</td>
</tr>
<tr class="ltx_tr" id="S5.T5.1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T5.1.1.7.6.1">Qwen-72b</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.7.6.2">78.68</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T5.1.1.7.6.3">76.79</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 5:</span>COIG Subset 데이터에 대한 학습 후 서로 다른 기본 모델의 성능.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S5.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="197" id="S5.F4.g1" src="https://arxiv.org/html/2403.18058v1/x1.png" width="307">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 4:</span>유사한 파라미터 스케일에서 CQIA-Subset과 5개의 강한 베이스라인 사이의 쌍별 비교의 인간 평가.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>EXPERIMENT RESULTS</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Ablating Instruction Data Sources</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">데이터 세트의 서로 다른 데이터 소스에서 Yi 시리즈 모델<cite class="ltx_cite ltx_citemacro_cite">Young et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib27" title="">2024</a>)</cite> 및 Qwen-72B<cite class="ltx_cite ltx_citemacro_cite">Bai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#bib.bib1" title="">2023</a>)</cite> 모델을 미세 조정한다. 다양한 도메인 지식에서 데이터 소스가 모델 기능에 미치는 영향을 분석합니다. 그런 다음, 모델 기반(GPT-4) 자동 평가를 Belle-Eval에 적용하여 다양한 유형의 어시스턴트 스타일 태스크에 대한 각 모델 성능을 평가한다.</p>
</div>
<div class="ltx_para" id="S6.SS1.p2">
<p class="ltx_p" id="S6.SS1.p2.1">훈련 데이터 소스와 다른 태스크의 다운스트림 성능 사이의 상관 관계를 이해하기 위해 BELLE-Eval에서 10개의 태스크에 대한 모델을 평가한다. 우리는 0에서 1 범위의 점수로 모델 반응을 채점하기 위해 GPT-4를 평가자로 사용한다.</p>
</div>
<div class="ltx_para" id="S6.SS1.p3">
<p class="ltx_p" id="S6.SS1.p3.1">Tabel <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S4.T2" title="Table 2 ‣ 4.2 Diversity ‣ 4 Data Analysis ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_tag">2</span></a>는 서로 다른 하위 집합에서 미세 조정된 서로 다른 Yi-6B 기반 모델의 결과를 보여준다. 표에서 우리는 데이터에 대해 훈련된 모델이 브레인스토밍, 생성 및 요약과 같은 생성 작업에서는 뛰어나지만 수학과 코딩에서는 제대로 작동하지 않음을 알 수 있다. <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p3.1.1">Exam</span> 하위 집합은 평균 점수 54.9로 모든 하위 집합에서 최상의 성능을 달성하며 특히 Extract 및 Math 작업에서 탁월합니다. 이는 <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p3.1.2">Exam</span>이 더 많은 수학 퀴즈와 시험 유형(예: 읽기 이해)을 포함하므로 대부분의 태스크에서 모델의 성능을 잠재적으로 높일 수 있습니다. 흥미롭게도 <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p3.1.3">Ruozhiba</span>은 모든 하위 집합에서 평균 2위를 차지합니다. 우리는 이것이 모델의 논리적 추론 능력을 향상시켜 대부분의 지시 후속 작업에 도움이 될 수 있기 때문이라고 추측한다. <span class="ltx_text ltx_font_typewriter" id="S6.SS1.p3.1.4">COIG-PC</span>은 Belle-Eval에서 C-Eval, yet underperforms와 같은 지식 차원의 평가에 대한 숙련도를 보여줍니다. 이러한 불일치는 전통적인 NLP 데이터 세트의 출처와 짧은 응답 길이로 인해 추론 작업을 손상시킬 수 있고 모델 기반 평가자가 덜 선호하기 때문이다. C-Eval과 Belle-Eval 사이의 상당한 격차는 중국 LLM을 포괄적이고 정확하게 평가할 수 있는 평가 개발의 중요성을 강조한다. 더욱이 위키하우의 점수는 5.8에 불과하며, 이는 "방법" 지침의 다양성이 부족하기 때문이라고 생각한다.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Human Evaluation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">자동 평가 외에도 CQIA 하위 집합에서 Yi-6B 미세 조정을 유사한 매개변수 규모의 최신 중국 오픈 소스 채팅 모델과 비교하여 평가한다. 우리는 실제 중국어를 사용하는 사용자들이 제기하는 질문들에 초점을 맞추고 있다. 우리는 인간 평가를 위한 훈련 세트에 존재하지 않는 OL-CC<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>https://data.baai.ac.cn/details/OL-CC</span></span></span> 및 Zhihu로부터 200개의 질문을 샘플링한다. 우리는 우리의 모델이 실제 인간 프롬프트에 직면할 때 다른 모델들과 비교하여 어떻게 수행되는지를 입증하기 위해 쌍별 비교를 수행한다.</p>
</div>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.1">각 프롬프트에 대해 각각 <span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content">6</sup><span class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><span class="ltmath idx=0></math>=0.85, <math alttext="k" class="ltx_Math" display="inline" id="footnote6.m2.1"><semantics id="footnote6.m2.1b"><mi id="footnote6.m2.1.1" xref="footnote6.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="footnote6.m2.1c"><ci id="footnote6.m2.1.1.cmml" xref="footnote6.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote6.m2.1d">k</annotation><annotation encoding="application/x-llamapun" id="footnote6.m2.1e">italic_k</annotation></semantics></math>=50 및 온도=0.9.</span></span></span>를 사용하여 핵 샘플링을 사용하여 응답을 생성합니다. 그런 다음 주석에는 프롬프트와 두 개의 응답이 제공됩니다. 하나는 <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p2.1.1">CQIA</span> 모델에 의해 생성되고 하나는 다른 기준 모델에 의해 생성됩니다. 그 후, 주석자가 어떤 응답을 선호하는지 질문하여 더 나은 응답이 판단하기 어려울 때 "넥타이" 선택을 허용한다.</p>
</div>
<div class="ltx_para" id="S6.SS2.p3">
<p class="ltx_p" id="S6.SS2.p3.1">그림 <a class="ltx_ref" href="https://arxiv.org/html/2403.18058v1#S5.F4" title="Figure 4 ‣ 5.2 Implementation Details ‣ 5 EXPERIMENTAL SETUP ‣ COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning"><span class="ltx_text ltx_ref_tag">4</span></a>는 <span class="ltx_text ltx_font_typewriter" id="S6.SS2.p3.1.1">CQIA</span> 및 기타 5개 베이스라인, 즉 Yi-6B-Chat, Baichuan2-7B-Chat, ChatGLM2-6B, Qwen-7B-Chat 및 InternLM-7B-Chat을 사용한 인간 평가 결과를 보여준다. 결과는 강한 기준선과 비교하여 CQIA-하위 집합이 더 높은 인간 선호도를 달성했으며 응답의 최소 60% 이상이 기준선 모델보다 우수하거나 동등하다는 것을 보여준다. 이는 CQIA가 인간 질문이나 지침에 대한 고품질 응답을 생성하는 것뿐만 아니라 응답이 실제 인간 커뮤니케이션 패턴과 더 정렬되어 인간 선호도가 높기 때문일 수 있다.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Scaling Model Size</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">우리는 CQIA-Subset에서 미세 조정 후 다양한 파라미터 크기를 갖는 다른 기본 모델의 성능을 조사한다. 특히 Yi-6B는 매개변수 크기가 최소 두 배인 Qwen-14B와 InternLM-20B를 능가한다. 또한 Yi-34B는 C-Eval 및 CMMLU 벤치마크 모두에서 Qwen-72B와 유사한 결과를 달성했다. 이 관측기는 모델 크기, 아키텍처 최적화 및 훈련 방법론 간의 균형을 강조합니다. 스케일링 법칙은 더 큰 모델이 언어 이해 능력 증가로 인해 본질적으로 더 나은 성능을 발휘한다는 것을 시사할 수 있지만, 우리의 결과는 이것이 항상 그렇지 않다는 것을 나타낸다. 특히, 훨씬 더 많은 매개변수를 가진 모델에 대한 Yi-6B 모델의 우수한 성능은 매개변수 수만으로도 모델 효능의 충분한 예측 변수라는 개념에 도전한다.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Safety</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.SS4.p1">
<p class="ltx_p" id="S6.SS4.p1.1">We explore the impact of data sources on model safety by evaluating our models on SafetyBench. Models trained on CQIA-Subset scores the highest within CQIA series, surpassing GPT-3.5-turbo-0613. Model trained on Social Media&amp; Forums such as Douban, Zhihu, and Xhs perform moderate safety scores, we conjecture this is due to the diversity and openness of social media content, which also highlights the risks of harmful information. Additionally, models trained on Wiki-style data tend to perform lower safety scores, potentially reflecting the limited diversity within professional data sources, leading to poor performance on safety issues outside specialty domains. </p>안전 벤치에서 모델을 평가하여 데이터 소스가 모델 안전에 미치는 영향을 조사합니다. CQIA-Subset에서 훈련된 모델은 GPT-3.5-turbo-0613을 능가하여 CQIA 시리즈 내에서 가장 높은 점수를 받았다. Douban, Zhihu, Xhs와 같은 소셜 미디어&포럼에서 훈련된 모델은 중간 정도의 안전 점수를 수행하는데, 이는 소셜 미디어 콘텐츠의 다양성과 개방성 때문이며, 이는 또한 유해한 정보의 위험을 강조한다. 또한 위키 스타일 데이터에 대해 훈련된 모델은 더 낮은 안전 점수를 수행하는 경향이 있으며, 이는 잠재적으로 전문 데이터 소스 내의 제한된 다양성을 반영하여 특수 영역 외부의 안전 문제에 대한 성능 저하로 이어진다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">In this paper, we introduce a a high-quality Chinese instruction fine-tuning dataset. COIG-CQIA focuses on creating a dataset from Chinese internet sources including Q&amp;A and articles. These are deeply cleansed, restructured, and manually reviewed to ensure quality, diversity, and relevance. This dataset is designed to provide the Chinese NLP community with high-quality and human interaction-aligned instruction fine-tuning data. </p>본 논문에서는 고품질의 중국어 명령어 미세조정 데이터셋을 소개한다. COIG-CQIA는 Q&A 및 기사를 포함한 중국 인터넷 소스에서 데이터 세트를 만드는 데 중점을 둔다. 품질, 다양성 및 관련성을 보장하기 위해 심층 세척, 재구성 및 수동으로 검토합니다. 이 데이터 세트는 중국 NLP 커뮤니티에 고품질 및 인간 상호 작용 정렬 명령 미세 조정 데이터를 제공하도록 설계되었다.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu&nbsp;Han, Fei Huang, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Qwen technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2309.16609</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared&nbsp;D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et&nbsp;al. 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Advances in neural information processing systems</em>, 33:1877–1901.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav, Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, and Hongxia Jin. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2307.08701" title="">Alpagasus: Training a better alpaca with fewer data</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung&nbsp;Won Chung, Charles Sutton, Sebastian Gehrmann, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Palm: Scaling language modeling with pathways.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Journal of Machine Learning Research</em>, 24(240):1–113.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hyung&nbsp;Won Chung, Le&nbsp;Hou, Shayne Longpre, Barret Zoph, Yi&nbsp;Tay, William Fedus, Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang&nbsp;Shane Gu, Zhuyun Dai, Mirac Suzgun, Xinyun Chen, Aakanksha Chowdhery, Alex Castro-Ros, Marie Pellat, Kevin Robinson, Dasha Valter, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed&nbsp;H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc&nbsp;V. Le, and Jason Wei. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2210.11416" title="">Scaling instruction-finetuned language models</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">CLUEbenchmark (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
CLUEbenchmark. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://github.com/CLUEbenchmark/pCLUE" title="">pclue: Large-scale prompt-based dataset for multi-task and zero-shot learning in chinese</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conover et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm" title="">Free dolly: Introducing the world’s first truly open instruction-tuned llm</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie, Yuxuan Ding, Jianwei Yue, and Yupeng Wu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2301.07597" title="">How close is chatgpt to human experts? comparison corpus, evaluation, and detection</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He and Choi (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Han He and Jinho&nbsp;D Choi. 2021.

</span>
<span class="ltx_bibblock">The stem cell hypothesis: Dilemma behind multi-task learning with transformer encoders.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2109.06939</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Or&nbsp;Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2212.09689" title="">Unnatural instructions: Tuning language models with (almost) no human labor</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ivison et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hamish Ivison, Yizhong Wang, Valentina Pyatkin, Nathan Lambert, Matthew Peters, Pradeep Dasigi, Joel Jang, David Wadden, Noah&nbsp;A. Smith, Iz&nbsp;Beltagy, and Hannaneh Hajishirzi. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2311.10702" title="">Camels in a changing climate: Enhancing lm adaptation with tulu 2</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yunjie Ji, Yong Deng, Yan Gong, Yiping Peng, Qiang Niu, Lei Zhang, Baochang Ma, and Xiangang Li. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2303.14742" title="">Exploring the impact of instruction data scaling on large language models: An empirical study on real-world use cases</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konchakov et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
R.&nbsp;A. Konchakov, A.&nbsp;S. Makarov, G.&nbsp;V. Afonin, J.&nbsp;C. Qiao, M.&nbsp;G. Vasin, N.&nbsp;P. Kobelev, and V.&nbsp;A. Khonik. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2306.00475" title="">Critical behavior of the fluctuation heat capacity near the glass transition of metallic glasses</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke Zettlemoyer, Omer Levy, Jason Weston, and Mike Lewis. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2308.06259" title="">Self-alignment with instruction backtranslation</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Renze Lou, Kai Zhang, Jian Xie, Yuxuan Sun, Janice Ahn, Hanzi Xu, Yu&nbsp;Su, and Wenpeng Yin. 2023.

</span>
<span class="ltx_bibblock">Muffin: Curating multi-faceted instructions for improving instruction following.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2104.08773" title="">Cross-task generalization via natural language crowdsourcing instructions</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023.

</span>
<span class="ltx_bibblock">Instruction tuning with gpt-4.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2304.03277</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanh et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Victor Sanh, Albert Webson, Colin Raffel, Stephen&nbsp;H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven&nbsp;Le Scao, Arun Raja, Manan Dey, M&nbsp;Saiful Bari, Canwen Xu, Urmish Thakker, Shanya&nbsp;Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng&nbsp;Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason&nbsp;Alan Fries, Ryan Teehan, Tali Bers, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander&nbsp;M. Rush. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2110.08207" title="">Multitask prompted training enables zero-shot task generalization</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chiyu Song, Zhanchao Zhou, Jianhao Yan, Yuejiao Fei, Zhenzhong Lan, and Yue Zhang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2310.19651" title="">Dynamics of instruction tuning: Each ability of large language models has its own growth pace</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tianxiang Sun, Xiaotian Zhang, Zhengfu He, Peng Li, Qinyuan Cheng, Hang Yan, Xiangyang Liu, Yunfan Shao, Qiong Tang, Xingjian Zhao, Ke&nbsp;Chen, Yining Zheng, Zhejian Zhou, Ruixiao Li, Jun Zhan, Yunhua Zhou, Linyang Li, Xiaogui Yang, Lingling Wu, Zhangyue Yin, Xuanjing Huang, and Xipeng Qiu. 2023.

</span>
<span class="ltx_bibblock">Moss: Training conversational language models from synthetic data.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
InternLM Team. 2023.

</span>
<span class="ltx_bibblock">Internlm: A multilingual language model with progressively enhanced capabilities.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/InternLM/InternLM" title="">https://github.com/InternLM/InternLM</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">arXiv preprint arXiv:2302.13971</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah&nbsp;A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2212.10560" title="">Self-instruct: Aligning language models with self-generated instructions</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu&nbsp;Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2304.12244" title="">Wizardlm: Empowering large language models to follow complex instructions</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2304.01196" title="">Baize: An open-source chat model with parameter-efficient tuning on self-chat data</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jianxin Yang. 2023.

</span>
<span class="ltx_bibblock">Firefly(流萤): 中文对话式大语言模型.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/yangjianxin1/Firefly" title="">https://github.com/yangjianxin1/Firefly</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Young et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alex Young, Bei Chen, Chao Li, Chengen Huang, Ge&nbsp;Zhang, Guanwei Zhang, Heng Li, Jiangcheng Zhu, Jianqun Chen, Jing Chang, et&nbsp;al. 2024.

</span>
<span class="ltx_bibblock">Yi: Open foundation models by 01. ai.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2403.04652</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ge&nbsp;Zhang, Yemin Shi, Ruibo Liu, Ruibin Yuan, Yizhi Li, Siwei Dong, Yu&nbsp;Shu, Zhaoqun Li, Zekun Wang, Chenghua Lin, Wenhao Huang, and Jie Fu. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2304.07987" title="">Chinese open instruction generalist: A preliminary release</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, et&nbsp;al. 2023b.

</span>
<span class="ltx_bibblock">Instruction tuning for large language models: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2308.10792</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, Susan Zhang, Gargi Ghosh, Mike Lewis, Luke Zettlemoyer, and Omer Levy. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="http://arxiv.org/abs/2305.11206" title="">Lima: Less is more for alignment</a>.

</span>
</li>
</ul>
</section>
</article>
</div>

</div>


<div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated on Wed Dec 14 18:01:44 2022 by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button></body></html>