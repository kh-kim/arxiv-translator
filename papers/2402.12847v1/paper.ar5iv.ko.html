<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2402.12847] Instruction-tuned Language Models are Better Knowledge Learners</title><meta property="og:description" content="In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it must be possible to update their factual knowledge through continued training on new data.
The standard re…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Instruction-tuned Language Models are Better Knowledge Learners">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Instruction-tuned Language Models are Better Knowledge Learners">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2402.12847">

<!--Generated on Tue Mar  5 14:57:27 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.7.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.1.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Instruction-tuned Language Models are Better Knowledge Learners</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhengbao Jiang<sup id="id13.13.id1" class="ltx_sup"><span id="id13.13.id1.1" class="ltx_text ltx_font_italic">2</span></sup>  Zhiqing Sun<sup id="id14.14.id2" class="ltx_sup">2</sup>  Weijia Shi<sup id="id15.15.id3" class="ltx_sup"><span id="id15.15.id3.1" class="ltx_text ltx_font_italic">1,3</span></sup>  Pedro Rodriguez<sup id="id16.16.id4" class="ltx_sup">1</sup>  Chunting Zhou<sup id="id17.17.id5" class="ltx_sup">1</sup> 
<br class="ltx_break"> <span id="id9.9.4" class="ltx_text ltx_font_bold">Graham Neubig<sup id="id9.9.4.1" class="ltx_sup"><span id="id9.9.4.1.1" class="ltx_text ltx_font_medium">2</span></sup>  Xi Victoria Lin<sup id="id9.9.4.2" class="ltx_sup"><span id="id9.9.4.2.1" class="ltx_text ltx_font_medium">1</span></sup>  Wen-tau Yih<sup id="id9.9.4.3" class="ltx_sup"><span id="id9.9.4.3.1" class="ltx_text ltx_font_medium">1</span></sup>  Srinivasan Iyer<sup id="id9.9.4.4" class="ltx_sup"><span id="id9.9.4.4.1" class="ltx_text ltx_font_medium">1</span></sup></span> 
<br class="ltx_break"><sup id="id18.18.id6" class="ltx_sup">1</sup>FAIR at Meta  <sup id="id19.19.id7" class="ltx_sup">2</sup>Carnegie Mellon University  <sup id="id20.20.id8" class="ltx_sup">3</sup>University of Washington 
<br class="ltx_break"><span id="id21.21.id9" class="ltx_text ltx_font_typewriter">{zhengbaj,gneubig}@cs.cmu.edu</span>  <span id="id22.22.id10" class="ltx_text ltx_font_typewriter">{victorialin,scottyih,sviyer}@meta.com</span>
</span><span class="ltx_author_notes">Majority of the work done during an internship at Meta.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id23.id1">대형 언어 모델(LLM) 기반 어시스턴트가 진화하는 정보 요구에 효과적으로 적응하기 위해서는 새로운 데이터에 대한 지속적인 훈련을 통해 사실적 지식을 업데이트할 수 있어야 한다. 이를 위한 표준 레시피는 새로운 문서에 대한 사전 교육을 계속한 후 질의응답(QA) 쌍에 대한 지시 조정을 포함한다. 그러나 이 레시피로 훈련된 LLM은 문서의 복잡성을 최소화하더라도 질문에 답하는 데 어려움을 겪고 있음을 알 수 있다. 우리는 QA 쌍이 일반적으로 간단하지만 문서가 더 복잡하여 복잡한 방식으로 많은 사실 진술을 함께 엮는다는 것을 발견했다. 따라서 우리는 LLMs을 QA 쌍 <em class="ltx_emph ltx_font_italic" id="id23.id1.1">before</em> 계속된 사전 훈련에 노출시켜 복잡한 문서로부터 지식을 인코딩하는 프로세스가 질문을 통해 이 지식에 접근하는 방식을 고려하도록 하는 것이 유익하다고 가정한다. 이를 기반으로 문서에 대한 학습 전에 질문에 대해 명령어를 조정하는 방법인 <span class="ltx_text ltx_font_bold" id="id23.id1.2">pre-instruction-tuning (PIT)</span>을 제안한다. 이는 문서에 대한 학습 후 지식을 추출하는 방법을 학습하는 표준 명령어 조정과 대비된다. 광범위한 실험과 절제 연구는 PIT가 새로운 문서의 지식을 흡수하는 LLM의 능력을 크게 향상시켜 표준 명령어 조정을 17.8% 능가한다는 것을 보여준다.</p>
</div>
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\addauthor</span>
<p class="ltx_p" id="p1.2">gnmagenta</p>
</div>
<div id="p2" class="ltx_para ltx_noindent">
<div id="p2.12" class="ltx_block ltx_align_bottom">
<p class="ltx_p" id="p2.12.13"><span class="ltx_text ltx_font_bold" id="p2.12.13.1">Instruction-tuned Language Models is Better Knowledge Learners</span></p>
<br class="ltx_break ltx_centering">
<p id="p2.12.12" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p2.12.12.12" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p2.12.12.12.12" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p2.5.5.5.5.5" class="ltx_tr">
<span id="p2.5.5.5.5.5.5" class="ltx_td ltx_align_center"><span id="p2.5.5.5.5.5.5.5" class="ltx_text ltx_font_bold">Zhengbao Jiang<sup id="p2.5.5.5.5.5.5.5.1" class="ltx_sup"><span id="p2.5.5.5.5.5.5.5.1.1" class="ltx_text ltx_font_medium ltx_font_italic">2</span></sup><span id="p2.5.5.5.5.5.5.5.2" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span>Majority of the work done during an internship at Meta.</span></span></span>  Zhiqing Sun<sup id="p2.5.5.5.5.5.5.5.3" class="ltx_sup"><span id="p2.5.5.5.5.5.5.5.3.1" class="ltx_text ltx_font_medium">2</span></sup>  Weijia Shi<sup id="p2.5.5.5.5.5.5.5.4" class="ltx_sup"><span id="p2.5.5.5.5.5.5.5.4.1" class="ltx_text ltx_font_medium ltx_font_italic">1,3</span></sup>  Pedro Rodriguez<sup id="p2.5.5.5.5.5.5.5.5" class="ltx_sup"><span id="p2.5.5.5.5.5.5.5.5.1" class="ltx_text ltx_font_medium">1</span></sup>  Chunting Zhou<sup id="p2.5.5.5.5.5.5.5.6" class="ltx_sup"><span id="p2.5.5.5.5.5.5.5.6.1" class="ltx_text ltx_font_medium">1</span></sup></span></span></span>
<span id="p2.9.9.9.9.9" class="ltx_tr">
<span id="p2.9.9.9.9.9.4" class="ltx_td ltx_align_center"><span id="p2.9.9.9.9.9.4.4" class="ltx_text ltx_font_bold">Graham Neubig<sup id="p2.9.9.9.9.9.4.4.1" class="ltx_sup"><span id="p2.9.9.9.9.9.4.4.1.1" class="ltx_text ltx_font_medium">2</span></sup>  Xi Victoria Lin<sup id="p2.9.9.9.9.9.4.4.2" class="ltx_sup"><span id="p2.9.9.9.9.9.4.4.2.1" class="ltx_text ltx_font_medium">1</span></sup>  Wen-tau Yih<sup id="p2.9.9.9.9.9.4.4.3" class="ltx_sup"><span id="p2.9.9.9.9.9.4.4.3.1" class="ltx_text ltx_font_medium">1</span></sup>  Srinivasan Iyer<sup id="p2.9.9.9.9.9.4.4.4" class="ltx_sup"><span id="p2.9.9.9.9.9.4.4.4.1" class="ltx_text ltx_font_medium">1</span></sup></span></span></span>
<span id="p2.12.12.12.12.12" class="ltx_tr">
<span id="p2.12.12.12.12.12.3" class="ltx_td ltx_align_center"><sup id="p2.12.12.12.12.12.3.1" class="ltx_sup">1</sup>FAIR at Meta  <sup id="p2.12.12.12.12.12.3.2" class="ltx_sup">2</sup>Carnegie Mellon University  <sup id="p2.12.12.12.12.12.3.3" class="ltx_sup">3</sup>University of Washington</span></span>
<span id="p2.12.12.12.12.13.1" class="ltx_tr">
<span id="p2.12.12.12.12.13.1.1" class="ltx_td ltx_align_center"><span id="p2.12.12.12.12.13.1.1.1" class="ltx_text ltx_font_typewriter">{zhengbaj,gneubig}@cs.cmu.edu</span>  <span id="p2.12.12.12.12.13.1.1.2" class="ltx_text ltx_font_typewriter">{victorialin,scottyih,sviyer}@meta.com</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<figure id="S0.F1" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.12847/assets/x1.png" id="S0.F1.g1" class="ltx_graphics ltx_img_landscape" width="369" height="129" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 1:</span>Illustration of continue pre-training (첫 번째 행), continue pre-training 후 instruction-tuning (두 번째 행), pre-instruction-tuning before continue pre-training (마지막 행)과 함께 평가 질문에 대한 정확도와 함께. 각각의 오른쪽 포인팅 광-청색 삼각형은 트레이닝 단계를 나타낸다.</figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p" id="S1.p1.1">대규모 언어 모델(LLM)은 대규모 사전 훈련을 통해 방대한 양의 사실적 지식을 매개 변수에 저장하며, 이 지식은 “세계에서 가장 큰 빙상이 어디에 위치해 있는가” <cite class="ltx_cite ltx_citemacro_cite">Brown et al. (<a class="ltx_ref" href="#bib.bib5" title="">2020</a>); OpenAI (<a class="ltx_ref" href="#bib.bib34" title="">2023</a>); Chowdhery et al. (<a class="ltx_ref" href="#bib.bib10" title="">2022</a>); Zhang et al. (<a class="ltx_ref" href="#bib.bib60" title="">2022</a>); Touvron et al. (<a class="ltx_ref" href="#bib.bib51" title="">2023a</a>, <a class="ltx_ref" href="#bib.bib52" title="">b</a>); Gemini Team (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite>와 같은 다양한 질문에 답하는 데 사용될 수 있다. 그러나 이러한 사실적 지식은 정적이며, 이는 세계가 진화함에 따라 구식이 되거나 LLM이 전문적이거나 사적인 영역에서 사용될 때 불충분하다는 것을 증명할 수 있음을 의미한다.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p" id="S1.p2.1">LLM들을 최신의 상태로 유지하기 위해, 파라미터들에 지식을 저장하기 위해 새로운 문서들에 대한 사전 트레이닝을 계속하는 것이 일반적이며, 이는 LLM들이 최신의 정보 <cite class="ltx_cite ltx_citemacro_cite">Jang et al. (<a class="ltx_ref" href="#bib.bib20" title="">2022</a>)</cite>를 필요로 하는 질의들에 효과적으로 응답할 수 있게 한다. 널리 유지되는 견해는 파라미터에 저장된 사실적 지식이 프롬프트 <cite class="ltx_cite ltx_citemacro_cite">Brown et al. (<a class="ltx_ref" href="#bib.bib5" title="">2020</a>); Petroni et al. (<a class="ltx_ref" href="#bib.bib37" title="">2019</a>); Roberts et al. (<a class="ltx_ref" href="#bib.bib42" title="">2020</a>)</cite>를 통해 도출될 수 있고, 지시-튜닝(지도된 미세-튜닝 또는 정렬이라고도 함)이 이러한 도출을 더 효과적으로 <cite class="ltx_cite ltx_citemacro_cite">Sanh et al. (<a class="ltx_ref" href="#bib.bib44" title="">2022</a>); Wei et al. (<a class="ltx_ref" href="#bib.bib56" title="">2022</a>); Ouyang et al. (<a class="ltx_ref" href="#bib.bib35" title="">2022</a>)</cite>로 만든다는 것이다. 본 논문의 첫 부분(<a class="ltx_ref ltx_refmacro_autoref" href="#S4" title="4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">§ 4</span></a>)에서는 다음 질문에 답하기 위해 Llama-2 <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="#bib.bib52" title="">2023b</a>)</cite>를 사용하여 광범위한 실험을 수행했다. <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">to what extent we augment the knowledge in modern LLMs by continue pre-training on new documents, with or without subsequent instruction-tuning</em>? 우리는 복잡도가 1로 최소화되는 범위에서 문서에 대해 LLM을 반복적으로 훈련함에 따라 LLM이 올바르게 대답하는 문서에 대한 질문의 비율이 27.6%로 일관되게 증가한다는 것을 발견했다. 후속 명령어 조정은 이를 30.3%로 더욱 향상시키며, 이러한 널리 사용되는 연습이 LLMs로부터 더 많은 지식을 이끌어내는 데 유용함을 확인한다. <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>This capacity might be underestimated by previous works due to using relatively small LMs or randomly initialized transformers, or lack of exhaustive training or instruction-tuning <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="#bib.bib54" title="">2021</a>); Hu et al. (<a class="ltx_ref" href="#bib.bib16" title="">2023</a>); Zhu and Li (<a class="ltx_ref" href="#bib.bib63" title="">2023a</a>)</cite>.</span></span></span> 그러나, 도출된 지식의 양은 여전히 제한적이며, 문서의 복잡성을 최소화하더라도, 우리가 "복잡성의 저주"라고 부르는 현상이다. <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Inspired by the “reversal curse” of <cite class="ltx_cite ltx_citemacro_citet">Berglund et al. (<a class="ltx_ref" href="#bib.bib3" title="">2023</a>)</cite>.</span></span></span></p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p" id="S1.p3.2">두 번째 부분(<a class="ltx_ref ltx_refmacro_autoref" href="#S5" title="5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">§ 5</span></a>)에서는 LLMs을 문서로부터 지식을 흡수하는 데 더 능숙하게 만들어 복잡성 저주를 완화시키는 방법을 연구한다. <cite class="ltx_cite ltx_citemacro_citet">Zhu and Li (<a class="ltx_ref" href="#bib.bib63" title="">2023a</a>)</cite>는 전기와 관련 질문의 혼합에서 무작위로 초기화된 변압기를 처음부터 훈련시키는 것이 새로운 질문에 대한 강력한 일반화를 초래한다는 흥미로운 결과를 제시했다. 그러나 이러한 발견의 이유를 이해하고 새로운 문서로부터 지식을 흡수하기 위해 실제로 적용할 수 있는 방법을 탐구하는 것은 추가 조사가 필요하다. 우리는 질의응답(QA) 쌍이 일반적으로 간단하고 쉽게 소화되는 반면 문서는 더 복잡하고 어수선하며 종종 더 복잡한 방식으로 많은 사실 진술을 함께 엮는 경향이 있음을 발견했다. 따라서 <em class="ltx_emph ltx_font_italic" id="S1.p3.2.1">문서에 대한 사전 학습을 계속하기 전에 의도적으로 LLMs를 QA 데이터에 노출시켜 복잡한 문서로부터 지식을 인코딩하는 프로세스가 질문을 통해 이 지식이 액세스되는 방식을 고려하는 것이 유익하다고 가정한다</em>. 이를 <span class="ltx_text ltx_font_bold" id="S1.p3.2.2">pre-instruction-tuning (PIT)</span>이라고 하고 이 방법의 다양한 변형을 벤치마킹하기 위한 포괄적인 실험을 수행한다. <a class="ltx_ref ltx_refmacro_autoref" href="#S0.F1" title="Figure 1 ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 1</span></a>에 도시된 바와 같이, 우리의 가장 우수한 변형은 지식이 어떻게 액세스되는지를 파악하기 위해 QA 쌍(예를 들어, "오펜하이머의 편집을 처리한 사람")에 대한 독점적인 훈련으로 시작한다. 이어서, 이들 QA 쌍들 및 연관된 문서들(예를 들어, "누가 오펜하이머의 편집을 처리했는가" 및 "오펜하이머"에 관한 문서를 처리했는가)의 조합에 대한 트레이닝이 뒤따른다. 이 단계에서 LLM은 정보 밀도가 높은 문서에서 지식을 흡수하는 능력을 향상시켜 이미 숙달한 QA 쌍을 기반으로 한다. 지속적인 지식 획득을 연구하기 위해, 우리는 2023년과 관련된 Wikipedia의 문서 모음을 포함하는 <span class="ltx_text ltx_font_typewriter" id="S1.p3.2.3">Wiki2023</span>이라는 데이터 세트를 구축한다. <span class="ltx_text ltx_font_typewriter" id="S1.p3.2.4">Wiki2023</span>에 대한 포괄적인 실험은 PIT 이후에 LLMs가 새로운 문서(예를 들어, "Barbie"에 관한 문서)로부터 지식을 흡수하는 향상된 능력을 나타낸다는 것을 입증한다. 자세한 절제 연구는 이 능력이 주로 문서로부터 지식을 인코딩하기 위한 학습보다 지식에 접근하는 방법을 우선시하는 학습에서 비롯된다는 것을 보여준다. 전반적으로, PIT는 표준 명령어 조정 방식(<a class="ltx_ref ltx_refmacro_autoref" href="#S5.SS1" title="5.1 Variants of Pre-instruction-tuning ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">§ 5.1</span></a> 및 <a class="ltx_ref ltx_refmacro_autoref" href="#S5.SS2" title="5.2 Pre-instruction-tuning++ ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">§ 5.2</span></a>)을 크게 능가하여 Llama-2 7B에서 17.8%의 QA 정확도를 향상시켰고(30.3% <math alttext="\shortrightarrow" class="ltx_Math" display="inline" id="S1.p3.1.m1.1"><semantics id="S1.p3.1.m1.1a"><mo id="S1.p3.1.m1.1.1" stretchy="false" xref="S1.p3.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">\shortrightarrow</annotation></semantics></math> 48.1%), Llama-2 70B에서 16.3%의 QA 정확도를 향상시켰다(46.4% <math alttext="\shortrightarrow" class="ltx_Math" display="inline" id="S1.p3.2.m2.1"><semantics id="S1.p3.2.m2.1a"><mo id="S1.p3.2.m2.1.1" stretchy="false" xref="S1.p3.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S1.p3.2.m2.1b"><ci id="S1.p3.2.m2.1.1.cmml" xref="S1.p3.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.2.m2.1c">\shortrightarrow</annotation></semantics></math> 62.7%). 더욱이, PIT는 또한 <em class="ltx_emph ltx_font_italic" id="S1.p3.2.5">different</em> 도메인의 문서로부터 지식을 흡수하는 능력을 향상시키며, 이 방법을 보다 강력한 일반화를 위한 보다 다양한 문서 및 명령어까지 확장할 수 있는 가능성을 밝혀준다(<a class="ltx_ref ltx_refmacro_autoref" href="#S5.SS4" title="5.4 Cross-domain Generalization ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">§ 5.4</span></a>).</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Building a Dataset to Study Continual Knowledge Acquisition</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p" id="S2.p1.1">LLM이 새로운 문서로부터 지식을 학습하는 능력을 평가하기 위해서는 원래의 사전 훈련 말뭉치와 최소한의 중복을 갖는 문서 말뭉치를 사용하는 것이 필수적이다. 이는 LLM이 질문에 올바르게 답할 때 이 기능을 원래 사전 훈련 말뭉치에서 유사한 질문을 접하는 것이 아니라 새로운 문서로부터의 학습에 자신 있게 귀속시킬 수 있음을 보장한다. 이 절에서는 위키피디아에서 이러한 말뭉치를 구축하기 위한 방법론을 설명한다.</p>
</div>
<figure id="S2.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S2.F2.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2402.12847/assets/x2.png" id="S2.F2.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="217" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S2.F2.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2402.12847/assets/x3.png" id="S2.F2.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="230" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 2:</span>The <span class="ltx_text ltx_font_typewriter" id="S2.F2.7.1">Wiki2023</span> dataset. <span class="ltx_text ltx_font_bold" id="S2.F2.8.2">Top-right</span>: 문서 및 QA 쌍의 수; <span class="ltx_text ltx_font_bold" id="S2.F2.9.3">Top-left</span>: 질문에서 빈번한 키워드; <span class="ltx_text ltx_font_bold" id="S2.F2.10.4">Bottom</span>: 문서, 질문 및 답변에서 토큰 카운트의 분포입니다.</figcaption>
</figure>
<figure id="S2.F3" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.12847/assets/x4.png" id="S2.F3.g1" class="ltx_graphics ltx_img_square" width="461" height="446" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 3:</span> <span class="ltx_text ltx_font_typewriter" id="S2.F3.2.1">Wiki2023</span>에서 "Oppenheimer" 및 해당 QA 쌍에 대한 예제 문서입니다. 손실 계산에 사용되는 토큰은 녹색으로 강조 표시됩니다.</figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Wiki2023 Document Corpus</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p1.1">다음의 실험(<a class="ltx_ref ltx_refmacro_autoref" href="#S4" title="4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">§ 4</span></a> 및 <a class="ltx_ref ltx_refmacro_autoref" href="#S5" title="5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">§ 5</span></a>)에서 Llama-2(7B 및 70B) <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="#bib.bib52" title="">2023b</a>)</cite>는 가장 성능이 좋은 LLMs 중 하나이기 때문에 사용한다. 우리는 영화, 예술, 경제, 정치, 사건 등과 같은 다양한 영역의 주제를 포함하여 "2023" 범주에 따라 분류된 위키피디아 기사를 사용한다. <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://en.wikipedia.org/wiki/Category:2023" target="_blank" title="">https://en.wikipedia.org/wiki/Category:2023</a></span></span></span> 이 사실 정보가 원본 학습 말뭉치에 포함되지 않을 가능성은 <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T1" title="Table 1 ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 1</span></a> (7B/70B의 경우 9.5%/17.2%)에서 낮은 QA 성능에 의해 지원된다. <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>It is important to note the difficulty in completely avoiding factual overlap between <span class="ltx_text ltx_font_typewriter" id="footnote4.1">Wiki2023</span> and the pre-training corpus of Llama-2. For example, a film released in 2023 might have had information available before 2023. Data duplication detection is an active research direction, which falls beyond the focus of this study.</span></span></span> 훈련 프로세스를 가속화하기 위해 철저한 요약을 제공하고 많은 사실적 진술을 포함하는 각 기사의 첫 번째 섹션만 사용합니다. “Oppenheimer”에 대한 수집 문서 수와 예시 문서는 <a class="ltx_ref ltx_refmacro_autoref" href="#S2.F2" title="Figure 2 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 2</span></a>와 <a class="ltx_ref ltx_refmacro_autoref" href="#S2.F3" title="Figure 3 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 3</span></a>에서 찾을 수 있다. 이를 <span class="ltx_text ltx_font_typewriter" id="S2.SS1.p1.1.1">Wiki2023</span> dataset이라고 한다.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Wiki2023 Question-answer Pairs</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p1.1">명령어 조정 또는 성능 평가를 위해 QA 쌍을 수집하기 위해 공개적으로 사용 가능한 LLM을 사용하여 프롬프트<a class="ltx_ref ltx_refmacro_autoref" href="#S2.SS2" title="2.2 Wiki2023 Question-answer Pairs ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">§ 2.2</span></a>에 이어 문맥으로 기사가 주어진 다양한 질문과 해당 답변을 생성한다. 글마다 평균 4.93개의 문항이 생성된다. <a class="ltx_ref ltx_refmacro_autoref" href="#S2.F2" title="Figure 2 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 2</span></a> 및 <a class="ltx_ref ltx_refmacro_autoref" href="#S2.F3" title="Figure 3 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 3</span></a>는 각각 “Oppenheimer”에 대한 상세한 통계 및 예제 QA 쌍을 보여준다.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<svg id="S2.SS2.p2.pic1" class="ltx_picture" height="223.85" overflow="visible" version="1.1" width="600"><g transform="translate(0,223.85) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.32 L 0 218.53 C 0 221.47 2.38 223.85 5.32 223.85 L 594.68 223.85 C 597.62 223.85 600 221.47 600 218.53 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.38 5.32 L 1.38 195.1 L 598.62 195.1 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.0"><path d="M 1.38 196.49 L 1.38 218.53 C 1.38 220.71 3.15 222.47 5.32 222.47 L 594.68 222.47 C 596.85 222.47 598.62 220.71 598.62 218.53 L 598.62 196.49 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 203.4)"><foreignObject width="583.4" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S2.SS2.p2.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:421.6pt;">
<span id="S2.SS2.p2.pic1.1.1.1.1.1.1" class="ltx_p">Prompt 1: question-answer generation prompt</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignObject width="583.4" height="179.88" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S2.SS2.p2.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:421.6pt;">
<span id="S2.SS2.p2.pic1.2.2.2.1.1.1" class="ltx_p">Given the following summary about the subject {topic}, generate a comprehensive list of questions and corresponding answers that cover all aspects. To make the question clear, always include {topic} in the question. Answers should be concise, consisting of a few short phrases separated by commas.</span>
<span id="S2.SS2.p2.pic1.2.2.2.1.1.2" class="ltx_p">Output in the following format:</span>
<span id="S2.SS2.p2.pic1.2.2.2.1.1.3" class="ltx_p">Q: an open-domain question about the subject {topic} (the subject {topic} should always be included)</span>
<span id="S2.SS2.p2.pic1.2.2.2.1.1.4" class="ltx_p">A: phrase1, phrase2, …</span>
<span id="S2.SS2.p2.pic1.2.2.2.1.1.5" class="ltx_p">Summary:</span>
<span id="S2.SS2.p2.pic1.2.2.2.1.1.6" class="ltx_p">{summary}</span>
</span></foreignObject></g></g></svg>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Splits</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p1.1">모든 도메인 중 평가를 위해 필름 도메인을 선택하고 테스트 분할로 256개의 기사를 무작위로 선택한다(<span class="ltx_text ltx_font_typewriter" id="S2.SS3.p1.1.1">Wiki2023-film-test</span>). 테스트 분할(<span class="ltx_text ltx_font_typewriter" id="S2.SS3.p1.1.2">Wiki2023-film-test-doc</span>)에서 문서에 LLMs을 지속적으로 훈련하고 해당 질문의 정확도에 따라 성능을 평가한다(<span class="ltx_text ltx_font_typewriter" id="S2.SS3.p1.1.3">Wiki2023-film-test-QA</span>). 나머지 1720개의 기사 및 해당 QA 쌍(<span class="ltx_text ltx_font_typewriter" id="S2.SS3.p1.1.4">Wiki2023-film-train</span>)은 <a class="ltx_ref ltx_refmacro_autoref" href="#S2.F2" title="Figure 2 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 2</span></a>의 도메인 내 설정에 해당하는 다양한 훈련 전략을 연구하는 데 사용될 것이다. 또한 <a class="ltx_ref ltx_refmacro_autoref" href="#S2.F2" title="Figure 2 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 2</span></a>의 교차 도메인 설정에 해당하는 도메인 전반에 걸쳐 다양한 방법의 효과를 연구하기 위해 필름 도메인에 대한 평가 전에 다른 도메인에 대해 훈련한다.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Settings</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Objectives</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.2" class="ltx_p">When training on documents, we prepend a &lt;bos&gt; token and compute the standard next-token prediction loss by averaging over all tokens in the document: <math id="S3.SS1.p1.1.m1.2" class="ltx_Math" alttext="L_{\bm{d}}=-\sum_{t}{\log P(\bm{d}_{t}|\bm{d}_{<t})}/|\bm{d}|" display="inline"><semantics id="S3.SS1.p1.1.m1.2a"><mrow id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml"><msub id="S3.SS1.p1.1.m1.2.2.3" xref="S3.SS1.p1.1.m1.2.2.3.cmml"><mi id="S3.SS1.p1.1.m1.2.2.3.2" xref="S3.SS1.p1.1.m1.2.2.3.2.cmml">L</mi><mi id="S3.SS1.p1.1.m1.2.2.3.3" xref="S3.SS1.p1.1.m1.2.2.3.3.cmml">𝒅</mi></msub><mo id="S3.SS1.p1.1.m1.2.2.2" xref="S3.SS1.p1.1.m1.2.2.2.cmml">=</mo><mrow id="S3.SS1.p1.1.m1.2.2.1" xref="S3.SS1.p1.1.m1.2.2.1.cmml"><mo id="S3.SS1.p1.1.m1.2.2.1a" xref="S3.SS1.p1.1.m1.2.2.1.cmml">−</mo><mrow id="S3.SS1.p1.1.m1.2.2.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.cmml"><msub id="S3.SS1.p1.1.m1.2.2.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.2.cmml"><mo id="S3.SS1.p1.1.m1.2.2.1.1.2.2" xref="S3.SS1.p1.1.m1.2.2.1.1.2.2.cmml">∑</mo><mi id="S3.SS1.p1.1.m1.2.2.1.1.2.3" xref="S3.SS1.p1.1.m1.2.2.1.1.2.3.cmml">t</mi></msub><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.cmml"><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.cmml"><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3a" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.cmml">⁡</mo><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml"><msub id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.2.cmml">𝒅</mi><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.2.cmml">𝒅</mi><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.2.cmml"></mi><mo id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.1.cmml">&lt;</mo><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></msub></mrow><mo stretchy="false" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS1.p1.1.m1.2.2.1.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.2.cmml">/</mo><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.3.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3.1.cmml"><mo stretchy="false" id="S3.SS1.p1.1.m1.2.2.1.1.1.3.2.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3.1.1.cmml">|</mo><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">𝒅</mi><mo stretchy="false" id="S3.SS1.p1.1.m1.2.2.1.1.1.3.2.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3.1.1.cmml">|</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.2b"><apply id="S3.SS1.p1.1.m1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2"><eq id="S3.SS1.p1.1.m1.2.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.2"></eq><apply id="S3.SS1.p1.1.m1.2.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.3.2">𝐿</ci><ci id="S3.SS1.p1.1.m1.2.2.3.3.cmml" xref="S3.SS1.p1.1.m1.2.2.3.3">𝒅</ci></apply><apply id="S3.SS1.p1.1.m1.2.2.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1"><minus id="S3.SS1.p1.1.m1.2.2.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1"></minus><apply id="S3.SS1.p1.1.m1.2.2.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1"><apply id="S3.SS1.p1.1.m1.2.2.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.2.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.2">subscript</csymbol><sum id="S3.SS1.p1.1.m1.2.2.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.2.2"></sum><ci id="S3.SS1.p1.1.m1.2.2.1.1.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.2.3">𝑡</ci></apply><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1"><divide id="S3.SS1.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.2"></divide><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1"><times id="S3.SS1.p1.1.m1.2.2.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.2"></times><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3"><log id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.1"></log><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.2">𝑃</ci></apply><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.2">𝒅</ci><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.2">𝒅</ci><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3"><lt id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.1"></lt><csymbol cd="latexml" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.2">absent</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.3">𝑡</ci></apply></apply></apply></apply><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3.2"><abs id="S3.SS1.p1.1.m1.2.2.1.1.1.3.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3.2.1"></abs><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝒅</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.2c">L_{\bm{d}}=-\sum_{t}{\log P(\bm{d}_{t}|\bm{d}_{&lt;t})}/|\bm{d}|</annotation></semantics></math>.<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>We do not append a ¡eos¿ token at the end of documents because we only use the first section, which does not signify the conclusion of the entire article.</span></span></span> When training on QA pairs, we compute the average negative log-likelihood loss only on tokens in the answer given the question as the prefix: <math id="S3.SS1.p1.2.m2.3" class="ltx_Math" alttext="L_{\bm{a}}=-\sum_{t}{\log P(\bm{a}_{t}|\bm{q},\bm{a}_{<t})}/|\bm{a}|" display="inline"><semantics id="S3.SS1.p1.2.m2.3a"><mrow id="S3.SS1.p1.2.m2.3.3" xref="S3.SS1.p1.2.m2.3.3.cmml"><msub id="S3.SS1.p1.2.m2.3.3.3" xref="S3.SS1.p1.2.m2.3.3.3.cmml"><mi id="S3.SS1.p1.2.m2.3.3.3.2" xref="S3.SS1.p1.2.m2.3.3.3.2.cmml">L</mi><mi id="S3.SS1.p1.2.m2.3.3.3.3" xref="S3.SS1.p1.2.m2.3.3.3.3.cmml">𝒂</mi></msub><mo id="S3.SS1.p1.2.m2.3.3.2" xref="S3.SS1.p1.2.m2.3.3.2.cmml">=</mo><mrow id="S3.SS1.p1.2.m2.3.3.1" xref="S3.SS1.p1.2.m2.3.3.1.cmml"><mo id="S3.SS1.p1.2.m2.3.3.1a" xref="S3.SS1.p1.2.m2.3.3.1.cmml">−</mo><mrow id="S3.SS1.p1.2.m2.3.3.1.1" xref="S3.SS1.p1.2.m2.3.3.1.1.cmml"><msub id="S3.SS1.p1.2.m2.3.3.1.1.2" xref="S3.SS1.p1.2.m2.3.3.1.1.2.cmml"><mo id="S3.SS1.p1.2.m2.3.3.1.1.2.2" xref="S3.SS1.p1.2.m2.3.3.1.1.2.2.cmml">∑</mo><mi id="S3.SS1.p1.2.m2.3.3.1.1.2.3" xref="S3.SS1.p1.2.m2.3.3.1.1.2.3.cmml">t</mi></msub><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.cmml"><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.cmml"><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1.1.3" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.3a" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.cmml">⁡</mo><mi id="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.cmml"><msub id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.2.cmml">𝒂</mi><mi id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.3" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo fence="false" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.2.cmml">|</mo><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">𝒒</mi><mo id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.2.cmml">,</mo><msub id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">𝒂</mi><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.2.cmml"></mi><mo id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.1.cmml">&lt;</mo><mi id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.3.cmml">t</mi></mrow></msub></mrow></mrow><mo stretchy="false" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.3" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS1.p1.2.m2.3.3.1.1.1.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.2.cmml">/</mo><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1.3.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.3.1.cmml"><mo stretchy="false" id="S3.SS1.p1.2.m2.3.3.1.1.1.3.2.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.3.1.1.cmml">|</mo><mi id="S3.SS1.p1.2.m2.2.2" xref="S3.SS1.p1.2.m2.2.2.cmml">𝒂</mi><mo stretchy="false" id="S3.SS1.p1.2.m2.3.3.1.1.1.3.2.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.3.1.1.cmml">|</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.3b"><apply id="S3.SS1.p1.2.m2.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3"><eq id="S3.SS1.p1.2.m2.3.3.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2"></eq><apply id="S3.SS1.p1.2.m2.3.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.3.1.cmml" xref="S3.SS1.p1.2.m2.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.2.m2.3.3.3.2.cmml" xref="S3.SS1.p1.2.m2.3.3.3.2">𝐿</ci><ci id="S3.SS1.p1.2.m2.3.3.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3.3.3">𝒂</ci></apply><apply id="S3.SS1.p1.2.m2.3.3.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1"><minus id="S3.SS1.p1.2.m2.3.3.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1"></minus><apply id="S3.SS1.p1.2.m2.3.3.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1"><apply id="S3.SS1.p1.2.m2.3.3.1.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.1.1.2.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.2">subscript</csymbol><sum id="S3.SS1.p1.2.m2.3.3.1.1.2.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.2.2"></sum><ci id="S3.SS1.p1.2.m2.3.3.1.1.2.3.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.2.3">𝑡</ci></apply><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1"><divide id="S3.SS1.p1.2.m2.3.3.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.2"></divide><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1"><times id="S3.SS1.p1.2.m2.3.3.1.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.2"></times><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.3"><log id="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.1"></log><ci id="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.2">𝑃</ci></apply><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.2">conditional</csymbol><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.2">𝒂</ci><ci id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.3">𝑡</ci></apply><list id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝒒</ci><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.2">𝒂</ci><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3"><lt id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.1"></lt><csymbol cd="latexml" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.2">absent</csymbol><ci id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.3">𝑡</ci></apply></apply></list></apply></apply><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.3.2"><abs id="S3.SS1.p1.2.m2.3.3.1.1.1.3.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.3.2.1"></abs><ci id="S3.SS1.p1.2.m2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2">𝒂</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.3c">L_{\bm{a}}=-\sum_{t}{\log P(\bm{a}_{t}|\bm{q},\bm{a}_{&lt;t})}/|\bm{a}|</annotation></semantics></math>. <a href="#S2.F3" title="Figure 3 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;3</span></a> presents an example document alongside QA pairs, where tokens used for computing losses are highlighted.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Hyperparameters</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p1.2">AdamW <cite class="ltx_cite ltx_citemacro_cite">Loshchilov and Hutter (<a class="ltx_ref" href="#bib.bib30" title="">2019</a>)</cite>와 <math alttext="\beta_{1}=0.9" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><msub id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2.2" xref="S3.SS2.p1.1.m1.1.1.2.2.cmml">β</mi><mn id="S3.SS2.p1.1.m1.1.1.2.3" xref="S3.SS2.p1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><eq id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></eq><apply id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.2.1.cmml" xref="S3.SS2.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2.2">𝛽</ci><cn id="S3.SS2.p1.1.m1.1.1.2.3.cmml" type="integer" xref="S3.SS2.p1.1.m1.1.1.2.3">1</cn></apply><cn id="S3.SS2.p1.1.m1.1.1.3.cmml" type="float" xref="S3.SS2.p1.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\beta_{1}=0.9</annotation></semantics></math>, <math alttext="\beta_{2}=0.95" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><mrow id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><msub id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2.2" xref="S3.SS2.p1.2.m2.1.1.2.2.cmml">β</mi><mn id="S3.SS2.p1.2.m2.1.1.2.3" xref="S3.SS2.p1.2.m2.1.1.2.3.cmml">2</mn></msub><mo id="S3.SS2.p1.2.m2.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">0.95</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><eq id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1"></eq><apply id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2.2">𝛽</ci><cn id="S3.SS2.p1.2.m2.1.1.2.3.cmml" type="integer" xref="S3.SS2.p1.2.m2.1.1.2.3">2</cn></apply><cn id="S3.SS2.p1.2.m2.1.1.3.cmml" type="float" xref="S3.SS2.p1.2.m2.1.1.3">0.95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\beta_{2}=0.95</annotation></semantics></math>, 무게감쇠는 0.1이다. 웜업 없이 코사인 스케줄러를 사용하여 학습률을 초기값의 10%로 감쇠시킨다. 문서에 대한 사전 학습 시 256개의 문서 배치 크기와 3e-5의 초기 학습률을 사용한다. QA 쌍에 대한 명령어 조정 시 256개의 QA 쌍과 동일한 배치 크기를 사용하지만 계산 손실을 계산하는 데 사용되는 단일 배치의 토큰 수가 더 적기 때문에 5e-6의 감소된 초기 학습률을 선택한다. 에포크 수는 설정에 따라 달라지며 해당 섹션에 자세히 설명되어 있다.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Evaluation Metrics</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.p1.1">추론 시간에는 <a class="ltx_ref ltx_refmacro_autoref" href="#S2.F3" title="Figure 3 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 3</span></a>의 형식에 따라 질문이 주어진 답변을 컨텍스트로 생성하기 위해 탐욕적 디코딩을 사용한다. 원래 Llama-2를 평가하기 위해 5개의 QA 쌍을 컨텍스트 예제로 추가하여 QA 형식을 따르는지 확인한다. 대부분의 질문은 단순한 팩토이드 질문이고 대부분의 답변은 상대적으로 짧기 때문에 모델의 출력이 정규화 후 정확하게 골드 답변과 일치하는지 여부를 측정하는 기본 메트릭 <cite class="ltx_cite ltx_citemacro_cite">Kwiatkowski et al. (<a class="ltx_ref" href="#bib.bib25" title="">2019</a>)</cite>로 정확 일치(EM)를 사용한다(예: 기사 및 구두점 제거). 더 긴 응답을 평가하고 사소한 어휘 차이를 수용하기 위해 금 답이 모델의 출력에 나타나는지 평가하는 답변 회상과 모델의 출력과 금 답 사이의 가장 긴 공통 서브시퀀스를 측정하는 ROUGE-L도 보고한다.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.12847/assets/x5.png" id="S3.F4.g1" class="ltx_graphics ltx_img_landscape" width="461" height="145" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 4:</span>이 논문에서 조사한 서로 다른 실험 설정. 각 행은 고유한 이름과 숫자를 가진 서로 다른 실험 설정을 나타내며, 오른쪽을 가리키는 밝은 파란색 삼각형으로 강조 표시된 각 수직 섹션은 훈련 단계를 나타낸다. 모델은 모든 설정에서 테스트 QA에 대해 평가됩니다. 여러 데이터 세트가 점선 사각형 내에 동봉될 때마다, 이들은 훈련 프로세스 동안 함께 혼합된다.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning?</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p" id="S4.p1.1">LLM의 파라미터에 저장된 사실적 지식은 추가적인 훈련 <cite class="ltx_cite ltx_citemacro_cite">Brown et al. (<a class="ltx_ref" href="#bib.bib5" title="">2020</a>); Petroni et al. (<a class="ltx_ref" href="#bib.bib37" title="">2019</a>); Jiang et al. (<a class="ltx_ref" href="#bib.bib22" title="">2020</a>); Roberts et al. (<a class="ltx_ref" href="#bib.bib42" title="">2020</a>)</cite> 없이 프롬프트를 통해 질문에 대한 답변에 접근하여 적용할 수 있다. 고품질 데이터 <cite class="ltx_cite ltx_citemacro_cite">Sanh et al. (<a class="ltx_ref" href="#bib.bib44" title="">2022</a>); Wei et al. (<a class="ltx_ref" href="#bib.bib56" title="">2022</a>)</cite>에 대한 추가 명령 조정(지도 미세 조정이라고도 함)을 사용하면 LLMs에서 지식을 보다 효과적으로 이끌어낼 수 있는 것 같다. 그러나 LLM이 질문에 올바르게 답할 때 사전 훈련 데이터의 다양성으로 인해 지식의 출처가 불분명하다. 예를 들어, “세계에서 가장 큰 빙상이 어디에 있는가”라는 질문에 답할 때, LLM은 남극 빙상에 대해 본 문서에서 정보를 회상하고 일반화하여 그들의 응답을 도출하거나, 훈련 데이터에서 마주치는 유사한 질문에서 답을 반복하는 것일까? 전자의 시나리오는 나중에 도출될 수 있는 방식으로 문서를 이해하고 매개 변수 내에 지식을 효과적으로 저장할 수 있는 능력을 의미하는 반면, 후자의 경우는 단순한 암기이기 때문에 이러한 차이는 매우 중요하다.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p" id="S4.p2.1">여러 연구에서 이 문제를 연구했으며 주요 발견은 LMs가 <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="#bib.bib54" title="">2021</a>); Zhu and Li (<a class="ltx_ref" href="#bib.bib63" title="">2023a</a>)</cite>에서 훈련된 문서에 대한 질문에 답하기 어렵다는 것이다. 그러나 이러한 실험은 주로 BART, T5 또는 GPT-2 <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="#bib.bib54" title="">2021</a>); Jang et al. (<a class="ltx_ref" href="#bib.bib20" title="">2022</a>); Hu et al. (<a class="ltx_ref" href="#bib.bib16" title="">2023</a>)</cite>와 같이 상대적으로 작은 LMs를 사용하여, 무작위로 초기화된 트랜스포머 <cite class="ltx_cite ltx_citemacro_cite">Zhu and Li (<a class="ltx_ref" href="#bib.bib63" title="">2023a</a>)</cite>를 사용하거나 명령어 조정 없이 <cite class="ltx_cite ltx_citemacro_cite">Ovadia et al. (<a class="ltx_ref" href="#bib.bib36" title="">2023</a>)</cite>를 사용하여 수행되었다는 점에 유의하는 것이 중요하다. 이를 통해 <em class="ltx_emph ltx_font_italic" id="S4.p2.1.1">새로운 문서로부터 지식을 흡수하고 이에 대한 질문에 표준 연속 사전 훈련 후 명령어 조정 레시피를 사용하여 대답하는 현대 LLM의 실제 한계가 무엇인지 궁금하다</em> 이 섹션에서는 한계를 테스트하기 위해 <span class="ltx_text ltx_font_typewriter" id="S4.p2.1.2">Wiki2023-film</span>에서 Llama-2 7B 및 70B를 사용하여 광범위한 실험을 실행합니다.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Vanilla Continued Pre-training and Instruction-tuning</h3>

<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Experimental settings</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">두 가지 표준 설정을 실험하고 관련 질문에 답하여 성능을 평가합니다.</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i1.p1.1">계속된 사전 훈련: 명령어-튜닝 없이 테스트 문서 상에서 훈련(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➀). <span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>We found that LLMs struggle to adhere to the QA format after training on raw documents for multiple epochs. Therefore, we include a small set of QA pairs (64) during continued pre-training to prevent LLMs from forgetting the QA format.</span></span></span></p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i2.p1.1">표준 명령 조정: 열차 QA 쌍에 대한 명령 조정 전 열차 및 테스트 문서 모두에 대한 열차(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➁)</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.2">우리는 단일 에폭에 대해 명령어 튜닝을 수행하는데, 이는 더 많은 에폭들이 일반적으로 감소된 성능을 초래하기 때문이다. 문서 교육을 위해 효과적인 지식 습득이 가능하고 적당한 크기의 코퍼라에 대해 저렴한 비용으로 사용할 수 있는 여러 시기(7B/70B 모델의 경우 10/5)를 선택합니다.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Experimental results</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1"><a class="ltx_ref ltx_refmacro_autoref" href="#S4.T1" title="Table 1 ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 1</span></a>에 나타난 바와 같이, 원본 Llama-2 모델(7B/70B의 경우 9.5%/17.2%)의 상대적으로 낮은 성능은 테스트 문서 내의 대부분의 지식이 원본 사전 훈련 코퍼스에 포함되지 않음을 나타낸다. 문서에 대한 사전 교육을 계속한 후, 성능은 27.2%/41.7%로 증가하여 LLM이 어느 정도의 지식을 흡수할 수 있음을 나타낸다. 지침 조정은 성능을 30.3%/46.4%로 더욱 증가시켜 이 표준 레시피의 효과를 확인시켜준다. 이 관찰은 사전 훈련 후 명령어 조정이 무작위로 초기화된 GPT-2 유사 변압기에서 효과가 없음을 보여주는 <cite class="ltx_cite ltx_citemacro_citet">Zhu and Li (<a class="ltx_ref" href="#bib.bib63" title="">2023a</a>)</cite>와 다르다. 그 차이는 아마도 Llama-2가 원시 문서와 QA 데이터로 구성된 다양한 말뭉치에 대한 사전 교육을 통해 질문을 통해 매개 변수에서 지식을 추출하는 데 어느 정도 숙련도를 발전시켰기 때문에 발생할 것이다. 또한 해당 문서가 문맥(<a class="ltx_ref ltx_refmacro_autoref" href="#S4.T1" title="Table 1 ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 1</span></a>의 "open-book w/ doc")으로 Llama-2에 직접 제공되는 성능을 보고한다. 닫힌 책과 열린 책 설정 사이의 상당한 차이는 LLM의 매개변수에서 지식을 검색하는 것이 여전히 어렵다는 것을 시사한다.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2402.12847/assets/x6.png" id="S4.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="312" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a)</span>Training dynamics w/(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➁) and w/o instruction-tuning(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➀) 당혹도의 감소는 일관되게 QA 정확도의 개선으로 이어지며, 이는 사실적 지식 획득이 철저한 손실 최소화를 필요로 함을 나타낸다.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2402.12847/assets/x7.png" id="S4.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="285" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b)</span>Training dynamics with different learning rate (<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➀) 당혹감을 최소화한 후, 더 큰 학습률은 일반적으로 문서의 기만적인 패턴에 덜 과적합하고 질문에 응답할 때 더 나은 일반화로 이어진다.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 5:</span>Llama-2 7B의 트레이닝 다이내믹스를 연구하기 위해 계속되는 사전 트레이닝 동안 epoch의 수(<a class="ltx_ref ltx_refmacro_autoref" href="#S4.F5.sf1" title="Figure 5(a) ‣ Figure 5 ‣ Experimental results ‣ 4.1 Vanilla Continued Pre-training and Instruction-tuning ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">5(a)</span></a>) 및 학습률(<a class="ltx_ref ltx_refmacro_autoref" href="#S4.F5.sf2" title="Figure 5(b) ‣ Figure 5 ‣ Experimental results ‣ 4.1 Vanilla Continued Pre-training and Instruction-tuning ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">5(b)</span></a>)을 변화시킨다. 왼쪽 축은 <span class="ltx_text" id="S4.F5.5.1" style="color:#228B22;">QA accuracyacies</span> for test questions, measured by exact match. 오른쪽 축에는 문서에 있는 모든 토큰의 <span class="ltx_text" id="S4.F5.6.2" 스타일="color:#0000CD;">perplexity</span> 및 [span class="ltx_text" id="S4.F5.7.3" 스타일="color:#B22222;">knowledge retention accuracy</span>, Natural Questions 데이터 세트에서 QA 정확도로 측정한 두 가지 메트릭이 표시 됩니다. <span class="ltx_text" id="S4.F5.8.4" style="color:#00008B;background-color:#F2F2FF;">perplexity of all document tokens is minimized to 1</span>.</figcaption>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Analyzing the Training Dynamics: Perplexity and Generalization</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p1.1">문서의 복잡성을 낮추면 관련 질문에 대한 답으로 일반화될 수 있는 방법은 무엇인가? 문서에 대한 지속적인 사전 학습을 위해 에포크 수(<a class="ltx_ref ltx_refmacro_autoref" href="#S4.F5.sf1" title="Figure 5(a) ‣ Figure 5 ‣ Experimental results ‣ 4.1 Vanilla Continued Pre-training and Instruction-tuning ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">5(a)</span></a>)와 학습률(<a class="ltx_ref ltx_refmacro_autoref" href="#S4.F5.sf2" title="Figure 5(b) ‣ Figure 5 ‣ Experimental results ‣ 4.1 Vanilla Continued Pre-training and Instruction-tuning ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">5(b)</span></a>)을 변화시키고, 학습 동학을 연구하기 위해 세 가지 메트릭을 모니터링한다. <span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>Since we always decay the learning rate to 10% of its initial value, training for more epochs is not the same as continuing training from a checkpoint obtained after fewer epochs.</span></span></span></p>
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">Knowledge acquisition</span>QA accuracyacies on test questions measured by exact match.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">Perplexity of documents</span> We compute perplexity (PPL) on all tokens within the documents.</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p class="ltx_p" id="S4.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.1">Knowledge retention</span> 우리는 NQ(Natural Questions) 데이터 세트에 대한 QA 정확도를 평가하여 사전 훈련 동안 축적된 지식의 유지를 근사화한다. NQ는 2019년에 발표되었으며 주로 당시 위키피디아 기사를 기반으로 한 질문을 포함한다.</p>
</div>
</li>
</ul>
</div>
<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.1.2.1" class="ltx_tr">
<th id="S4.T1.1.2.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<td id="S4.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3"><span id="S4.T1.1.2.1.2.1" class="ltx_text ltx_font_bold">Llama-2 7B</span></td>
<td id="S4.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S4.T1.1.2.1.3.1" class="ltx_text ltx_font_bold">Llama-2 70B</span></td>
</tr>
<tr id="S4.T1.1.3.2" class="ltx_tr">
<th id="S4.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.1.3.2.1.1" class="ltx_text ltx_font_bold">Settings</span></th>
<td id="S4.T1.1.3.2.2" class="ltx_td ltx_nopad_l ltx_align_right"><span id="S4.T1.1.3.2.2.1" class="ltx_text ltx_font_bold">EM</span></td>
<td id="S4.T1.1.3.2.3" class="ltx_td ltx_nopad_l ltx_align_right"><span id="S4.T1.1.3.2.3.1" class="ltx_text ltx_font_bold">Rec.</span></td>
<td id="S4.T1.1.3.2.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r"><span id="S4.T1.1.3.2.4.1" class="ltx_text ltx_font_bold">R-L</span></td>
<td id="S4.T1.1.3.2.5" class="ltx_td ltx_align_right"><span id="S4.T1.1.3.2.5.1" class="ltx_text ltx_font_bold">EM</span></td>
<td id="S4.T1.1.3.2.6" class="ltx_td ltx_nopad_l ltx_align_right"><span id="S4.T1.1.3.2.6.1" class="ltx_text ltx_font_bold">Rec.</span></td>
<td id="S4.T1.1.3.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right"><span id="S4.T1.1.3.2.7.1" class="ltx_text ltx_font_bold">R-L</span></td>
</tr>
<tr id="S4.T1.1.4.3" class="ltx_tr">
<th id="S4.T1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="7"><em id="S4.T1.1.4.3.1.1" class="ltx_emph ltx_font_italic">closed- and open-book performance before training</em></th>
</tr>
<tr id="S4.T1.1.5.4" class="ltx_tr">
<th id="S4.T1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">closed-book</th>
<td id="S4.T1.1.5.4.2" class="ltx_td ltx_nopad_l ltx_align_right">9.5</td>
<td id="S4.T1.1.5.4.3" class="ltx_td ltx_nopad_l ltx_align_right">10.0</td>
<td id="S4.T1.1.5.4.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">21.2</td>
<td id="S4.T1.1.5.4.5" class="ltx_td ltx_align_right">17.2</td>
<td id="S4.T1.1.5.4.6" class="ltx_td ltx_nopad_l ltx_align_right">18.1</td>
<td id="S4.T1.1.5.4.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">31.4</td>
</tr>
<tr id="S4.T1.1.6.5" class="ltx_tr">
<th id="S4.T1.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">open-book w/ doc</th>
<td id="S4.T1.1.6.5.2" class="ltx_td ltx_nopad_l ltx_align_right">72.2</td>
<td id="S4.T1.1.6.5.3" class="ltx_td ltx_nopad_l ltx_align_right">75.4</td>
<td id="S4.T1.1.6.5.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">91.5</td>
<td id="S4.T1.1.6.5.5" class="ltx_td ltx_align_right">78.2</td>
<td id="S4.T1.1.6.5.6" class="ltx_td ltx_nopad_l ltx_align_right">80.6</td>
<td id="S4.T1.1.6.5.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">94.9</td>
</tr>
<tr id="S4.T1.1.7.6" class="ltx_tr">
<th id="S4.T1.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="7"><em id="S4.T1.1.7.6.1.1" class="ltx_emph ltx_font_italic">closed-book performance w/ standard methods</em></th>
</tr>
<tr id="S4.T1.1.8.7" class="ltx_tr">
<th id="S4.T1.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">cont. pre-training  ➀</th>
<td id="S4.T1.1.8.7.2" class="ltx_td ltx_nopad_l ltx_align_right">27.6</td>
<td id="S4.T1.1.8.7.3" class="ltx_td ltx_nopad_l ltx_align_right">31.6</td>
<td id="S4.T1.1.8.7.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">43.8</td>
<td id="S4.T1.1.8.7.5" class="ltx_td ltx_align_right">41.7</td>
<td id="S4.T1.1.8.7.6" class="ltx_td ltx_nopad_l ltx_align_right">45.8</td>
<td id="S4.T1.1.8.7.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">60.2</td>
</tr>
<tr id="S4.T1.1.9.8" class="ltx_tr">
<th id="S4.T1.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">&nbsp;&nbsp; +instruction-tuning  ➁</th>
<td id="S4.T1.1.9.8.2" class="ltx_td ltx_nopad_l ltx_align_right">30.3</td>
<td id="S4.T1.1.9.8.3" class="ltx_td ltx_nopad_l ltx_align_right">34.7</td>
<td id="S4.T1.1.9.8.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">47.4</td>
<td id="S4.T1.1.9.8.5" class="ltx_td ltx_align_right">46.4</td>
<td id="S4.T1.1.9.8.6" class="ltx_td ltx_nopad_l ltx_align_right">50.9</td>
<td id="S4.T1.1.9.8.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">64.1</td>
</tr>
<tr id="S4.T1.1.10.9" class="ltx_tr">
<th id="S4.T1.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">mix all data  ➃</th>
<td id="S4.T1.1.10.9.2" class="ltx_td ltx_nopad_l ltx_align_right">39.4</td>
<td id="S4.T1.1.10.9.3" class="ltx_td ltx_nopad_l ltx_align_right">44.6</td>
<td id="S4.T1.1.10.9.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">56.7</td>
<td id="S4.T1.1.10.9.5" class="ltx_td ltx_align_right">57.1</td>
<td id="S4.T1.1.10.9.6" class="ltx_td ltx_nopad_l ltx_align_right">63.4</td>
<td id="S4.T1.1.10.9.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">72.4</td>
</tr>
<tr id="S4.T1.1.11.10" class="ltx_tr">
<th id="S4.T1.1.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="7"><em id="S4.T1.1.11.10.1.1" class="ltx_emph ltx_font_italic">closed-book performance w/ pre-instruction-tuning (PIT)</em></th>
</tr>
<tr id="S4.T1.1.12.11" class="ltx_tr">
<th id="S4.T1.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PIT (QA only)  ➄</th>
<td id="S4.T1.1.12.11.2" class="ltx_td ltx_nopad_l ltx_align_right">28.6</td>
<td id="S4.T1.1.12.11.3" class="ltx_td ltx_nopad_l ltx_align_right">32.7</td>
<td id="S4.T1.1.12.11.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">45.2</td>
<td id="S4.T1.1.12.11.5" class="ltx_td ltx_align_right">49.7</td>
<td id="S4.T1.1.12.11.6" class="ltx_td ltx_nopad_l ltx_align_right">53.7</td>
<td id="S4.T1.1.12.11.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">67.9</td>
</tr>
<tr id="S4.T1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PIT (QA <math id="S4.T1.1.1.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S4.T1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">\shortrightarrow</annotation></semantics></math> docs)  ➅</th>
<td id="S4.T1.1.1.2" class="ltx_td ltx_nopad_l ltx_align_right">32.5</td>
<td id="S4.T1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_right">37.2</td>
<td id="S4.T1.1.1.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">49.0</td>
<td id="S4.T1.1.1.5" class="ltx_td ltx_align_right">54.6</td>
<td id="S4.T1.1.1.6" class="ltx_td ltx_nopad_l ltx_align_right">60.0</td>
<td id="S4.T1.1.1.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">73.8</td>
</tr>
<tr id="S4.T1.1.13.12" class="ltx_tr">
<th id="S4.T1.1.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">PIT  ➆</th>
<td id="S4.T1.1.13.12.2" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb"><span id="S4.T1.1.13.12.2.1" class="ltx_text ltx_font_bold">45.4</span></td>
<td id="S4.T1.1.13.12.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb"><span id="S4.T1.1.13.12.3.1" class="ltx_text ltx_font_bold">51.2</span></td>
<td id="S4.T1.1.13.12.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb ltx_border_r"><span id="S4.T1.1.13.12.4.1" class="ltx_text ltx_font_bold">63.2</span></td>
<td id="S4.T1.1.13.12.5" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T1.1.13.12.5.1" class="ltx_text ltx_font_bold">62.7</span></td>
<td id="S4.T1.1.13.12.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb"><span id="S4.T1.1.13.12.6.1" class="ltx_text ltx_font_bold">68.6</span></td>
<td id="S4.T1.1.13.12.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_bb"><span id="S4.T1.1.13.12.7.1" class="ltx_text ltx_font_bold">78.8</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 1:</span>Standard instruction-tuning과 pre-instruction-tuning 간의 QA 성능(%) 비교. 가장 좋은 결과는 굵은 글씨입니다. 레크 R-L은 ROUGE-L을 의미한다.</figcaption>
</figure>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Experiment results</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<ul id="S4.I3" class="ltx_itemize">
<li id="S4.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I3.i1.p1.1"><a class="ltx_ref ltx_refmacro_autoref" href="#S4.F5.sf1" title="Figure 5(a) ‣ Figure 5 ‣ Experimental results ‣ 4.1 Vanilla Continued Pre-training and Instruction-tuning ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">5(a)</span></a>에 도시된 바와 같이, QA 정확도는 퍼플렉시티가 1에 접근함에 따라 일관되게 개선되며, 이는 <em class="ltx_emph ltx_font_italic" id="S4.I3.i1.p1.1.1">사실적 지식 학습은 모든 토큰</em>에 걸쳐 완전한 손실 최소화를 필요로 함을 나타낸다. 이것은 지나치게 최적화하면 과적합으로 이어지는 일반적인 기술을 배우는 것과 대조된다.</p>
</div>
</li>
<li id="S4.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I3.i2.p1.1"><a class="ltx_ref ltx_refmacro_autoref" href="#S4.F5.sf1" title="Figure 5(a) ‣ Figure 5 ‣ Experimental results ‣ 4.1 Vanilla Continued Pre-training and Instruction-tuning ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">5(a)</span></a> 및 <a class="ltx_ref ltx_refmacro_autoref" href="#S4.F5.sf2" title="Figure 5(b) ‣ Figure 5 ‣ Experimental results ‣ 4.1 Vanilla Continued Pre-training and Instruction-tuning ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">5(b)</span></a>에 도시된 바와 같이, LLM이 문서에 대한 복잡도를 최소화한 모든 경우들 중에서, 더 많은 에폭 또는 더 큰 학습률로 트레이닝된 경우들은 전형적으로 우수한 QA 성능을 나타낸다. <em class="ltx_emph ltx_font_italic" id="S4.I3.i2.p1.1.1">보다 공격적인 훈련은 문서의 기만적인 패턴에 덜 과적합하고 질문에 응답할 때 더 나은 일반화로 이어진다</em></p>
</div>
</li>
</ul>
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.1">요약하면, 더 낮은 당혹도는 질문에 응답할 때 더 강한 일반화로 이어지지만 이전에 습득한 지식을 잊어버리는 희생을 치르게 된다.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.9.10.1" class="ltx_tr">
<th id="S4.T2.9.10.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt"><span id="S4.T2.9.10.1.1.1" class="ltx_text ltx_font_bold">Setting names</span></th>
<th id="S4.T2.9.10.1.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_tt"><span id="S4.T2.9.10.1.2.1" class="ltx_text ltx_font_bold">Setting configurations</span></th>
<td id="S4.T2.9.10.1.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_tt"><span id="S4.T2.9.10.1.3.1" class="ltx_text ltx_font_bold">EM</span></td>
<td id="S4.T2.9.10.1.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_tt"><span id="S4.T2.9.10.1.4.1" class="ltx_text ltx_font_bold">Rec.</span></td>
<td id="S4.T2.9.10.1.5" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_tt"><span id="S4.T2.9.10.1.5.1" class="ltx_text ltx_font_bold">R-L</span></td>
</tr>
<tr id="S4.T2.9.11.2" class="ltx_tr">
<th id="S4.T2.9.11.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5"><em id="S4.T2.9.11.2.1.1" class="ltx_emph ltx_font_italic">baselines</em></th>
</tr>
<tr id="S4.T2.9.12.3" class="ltx_tr">
<th id="S4.T2.9.12.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">continued pre-training  ➀</th>
<th id="S4.T2.9.12.3.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">test doc</th>
<td id="S4.T2.9.12.3.3" class="ltx_td ltx_nopad_l ltx_align_right">27.6</td>
<td id="S4.T2.9.12.3.4" class="ltx_td ltx_nopad_l ltx_align_right">31.6</td>
<td id="S4.T2.9.12.3.5" class="ltx_td ltx_nopad_l ltx_align_right">43.8</td>
</tr>
<tr id="S4.T2.1.1" class="ltx_tr">
<th id="S4.T2.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">&nbsp;&nbsp; +instruction-tuning  ➁</th>
<th id="S4.T2.1.1.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">train doc + test doc <math id="S4.T2.1.1.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.1.1.1.m1.1a"><mo stretchy="false" id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">\shortrightarrow</annotation></semantics></math> train QA</th>
<td id="S4.T2.1.1.3" class="ltx_td ltx_nopad_l ltx_align_right">30.3</td>
<td id="S4.T2.1.1.4" class="ltx_td ltx_nopad_l ltx_align_right">34.7</td>
<td id="S4.T2.1.1.5" class="ltx_td ltx_nopad_l ltx_align_right">47.4</td>
</tr>
<tr id="S4.T2.2.2" class="ltx_tr">
<th id="S4.T2.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">&nbsp;&nbsp; +instruction-tuning (w/o forget)  ➂</th>
<th id="S4.T2.2.2.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">train doc + test doc <math id="S4.T2.2.2.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T2.2.2.1.m1.1.1" xref="S4.T2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.1.m1.1b"><ci id="S4.T2.2.2.1.m1.1.1.cmml" xref="S4.T2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.1.m1.1c">\shortrightarrow</annotation></semantics></math> train QA + test doc</th>
<td id="S4.T2.2.2.3" class="ltx_td ltx_nopad_l ltx_align_right">30.2</td>
<td id="S4.T2.2.2.4" class="ltx_td ltx_nopad_l ltx_align_right">34.1</td>
<td id="S4.T2.2.2.5" class="ltx_td ltx_nopad_l ltx_align_right">46.4</td>
</tr>
<tr id="S4.T2.3.3" class="ltx_tr">
<th id="S4.T2.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">&nbsp;&nbsp; +instruction-tuning (w/o train doc)</th>
<th id="S4.T2.3.3.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">test doc <math id="S4.T2.3.3.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.3.3.1.m1.1a"><mo stretchy="false" id="S4.T2.3.3.1.m1.1.1" xref="S4.T2.3.3.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.1.m1.1b"><ci id="S4.T2.3.3.1.m1.1.1.cmml" xref="S4.T2.3.3.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.1.m1.1c">\shortrightarrow</annotation></semantics></math> train QA</th>
<td id="S4.T2.3.3.3" class="ltx_td ltx_nopad_l ltx_align_right">27.1</td>
<td id="S4.T2.3.3.4" class="ltx_td ltx_nopad_l ltx_align_right">30.7</td>
<td id="S4.T2.3.3.5" class="ltx_td ltx_nopad_l ltx_align_right">42.3</td>
</tr>
<tr id="S4.T2.9.13.4" class="ltx_tr">
<th id="S4.T2.9.13.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">weighted continued pre-training</th>
<th id="S4.T2.9.13.4.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">test doc (weighted)</th>
<td id="S4.T2.9.13.4.3" class="ltx_td ltx_nopad_l ltx_align_right">27.7</td>
<td id="S4.T2.9.13.4.4" class="ltx_td ltx_nopad_l ltx_align_right">32.7</td>
<td id="S4.T2.9.13.4.5" class="ltx_td ltx_nopad_l ltx_align_right">43.3</td>
</tr>
<tr id="S4.T2.4.4" class="ltx_tr">
<th id="S4.T2.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">adapted continued pre-training</th>
<th id="S4.T2.4.4.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">train doc <math id="S4.T2.4.4.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.4.4.1.m1.1a"><mo stretchy="false" id="S4.T2.4.4.1.m1.1.1" xref="S4.T2.4.4.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.1.m1.1b"><ci id="S4.T2.4.4.1.m1.1.1.cmml" xref="S4.T2.4.4.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.1.m1.1c">\shortrightarrow</annotation></semantics></math> test doc</th>
<td id="S4.T2.4.4.3" class="ltx_td ltx_nopad_l ltx_align_right">26.9</td>
<td id="S4.T2.4.4.4" class="ltx_td ltx_nopad_l ltx_align_right">32.7</td>
<td id="S4.T2.4.4.5" class="ltx_td ltx_nopad_l ltx_align_right">44.2</td>
</tr>
<tr id="S4.T2.9.14.5" class="ltx_tr">
<th id="S4.T2.9.14.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">mix all data  ➃</th>
<th id="S4.T2.9.14.5.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">train QA + train doc + test doc</th>
<td id="S4.T2.9.14.5.3" class="ltx_td ltx_nopad_l ltx_align_right">39.4</td>
<td id="S4.T2.9.14.5.4" class="ltx_td ltx_nopad_l ltx_align_right">44.6</td>
<td id="S4.T2.9.14.5.5" class="ltx_td ltx_nopad_l ltx_align_right">56.7</td>
</tr>
<tr id="S4.T2.9.15.6" class="ltx_tr">
<th id="S4.T2.9.15.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5"><em id="S4.T2.9.15.6.1.1" class="ltx_emph ltx_font_italic">various pre-instruction-tuning (PIT) methods and ablation studies</em></th>
</tr>
<tr id="S4.T2.5.5" class="ltx_tr">
<th id="S4.T2.5.5.2" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T2.5.5.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.5.5.1.1" class="ltx_text" style="background-color:#F7FBFF;">train QA + train doc (3 epochs) <math id="S4.T2.5.5.1.1.m1.1" class="ltx_Math" style="background-color:#F7FBFF;" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.5.5.1.1.m1.1a"><mo mathbackground="#F7FBFF" stretchy="false" id="S4.T2.5.5.1.1.m1.1.1" xref="S4.T2.5.5.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.1.1.m1.1b"><ci id="S4.T2.5.5.1.1.m1.1.1.cmml" xref="S4.T2.5.5.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.1.1.m1.1c">\shortrightarrow</annotation></semantics></math> test doc</span></th>
<td id="S4.T2.5.5.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.5.5.3.1" class="ltx_text" style="background-color:#F7FBFF;">45.4</span></td>
<td id="S4.T2.5.5.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.5.5.4.1" class="ltx_text" style="background-color:#F7FBFF;">51.2</span></td>
<td id="S4.T2.5.5.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.5.5.5.1" class="ltx_text" style="background-color:#F7FBFF;">63.2</span></td>
</tr>
<tr id="S4.T2.9.16.7" class="ltx_tr">
<th id="S4.T2.9.16.7.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S4.T2.9.16.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="background-color:#F7FBFF;" colspan="4"><em id="S4.T2.9.16.7.2.1" class="ltx_emph ltx_font_italic" style="background-color:#F7FBFF;">ablation studies of the number of epochs</em></th>
</tr>
<tr id="S4.T2.9.17.8" class="ltx_tr">
<th id="S4.T2.9.17.8.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T2.9.17.8.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.17.8.2.1" class="ltx_text" style="background-color:#F7FBFF;"> 1 epoch</span></th>
<td id="S4.T2.9.17.8.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.17.8.3.1" class="ltx_text" style="background-color:#F7FBFF;">33.3</span></td>
<td id="S4.T2.9.17.8.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.17.8.4.1" class="ltx_text" style="background-color:#F7FBFF;">39.1</span></td>
<td id="S4.T2.9.17.8.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.17.8.5.1" class="ltx_text" style="background-color:#F7FBFF;">50.3</span></td>
</tr>
<tr id="S4.T2.9.18.9" class="ltx_tr">
<th id="S4.T2.9.18.9.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T2.9.18.9.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.18.9.2.1" class="ltx_text" style="background-color:#F7FBFF;"> 5 epochs</span></th>
<td id="S4.T2.9.18.9.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.18.9.3.1" class="ltx_text" style="background-color:#F7FBFF;">45.8</span></td>
<td id="S4.T2.9.18.9.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.18.9.4.1" class="ltx_text" style="background-color:#F7FBFF;">52.1</span></td>
<td id="S4.T2.9.18.9.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.18.9.5.1" class="ltx_text" style="background-color:#F7FBFF;">63.6</span></td>
</tr>
<tr id="S4.T2.9.19.10" class="ltx_tr">
<th id="S4.T2.9.19.10.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T2.9.19.10.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.19.10.2.1" class="ltx_text" style="background-color:#F7FBFF;"> 10 pochs</span></th>
<td id="S4.T2.9.19.10.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.19.10.3.1" class="ltx_text" style="background-color:#F7FBFF;">46.5</span></td>
<td id="S4.T2.9.19.10.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.19.10.4.1" class="ltx_text" style="background-color:#F7FBFF;">52.3</span></td>
<td id="S4.T2.9.19.10.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.19.10.5.1" class="ltx_text" style="background-color:#F7FBFF;">61.9</span></td>
</tr>
<tr id="S4.T2.9.20.11" class="ltx_tr">
<th id="S4.T2.9.20.11.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S4.T2.9.20.11.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="background-color:#F7FBFF;" colspan="4"><em id="S4.T2.9.20.11.2.1" class="ltx_emph ltx_font_italic" style="background-color:#F7FBFF;">ablation studies of different learning mechanisms</em></th>
</tr>
<tr id="S4.T2.9.21.12" class="ltx_tr">
<th id="S4.T2.9.21.12.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T2.9.21.12.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.21.12.2.1" class="ltx_text" style="background-color:#F7FBFF;"> QA before doc (grouped)</span></th>
<td id="S4.T2.9.21.12.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.21.12.3.1" class="ltx_text" style="background-color:#F7FBFF;">38.2</span></td>
<td id="S4.T2.9.21.12.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.21.12.4.1" class="ltx_text" style="background-color:#F7FBFF;">43.2</span></td>
<td id="S4.T2.9.21.12.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.21.12.5.1" class="ltx_text" style="background-color:#F7FBFF;">56.3</span></td>
</tr>
<tr id="S4.T2.9.22.13" class="ltx_tr">
<th id="S4.T2.9.22.13.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T2.9.22.13.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.22.13.2.1" class="ltx_text" style="background-color:#F7FBFF;"> QA after doc (grouped)</span></th>
<td id="S4.T2.9.22.13.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.22.13.3.1" class="ltx_text" style="background-color:#F7FBFF;">27.2</span></td>
<td id="S4.T2.9.22.13.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.22.13.4.1" class="ltx_text" style="background-color:#F7FBFF;">31.1</span></td>
<td id="S4.T2.9.22.13.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.22.13.5.1" class="ltx_text" style="background-color:#F7FBFF;">42.1</span></td>
</tr>
<tr id="S4.T2.9.23.14" class="ltx_tr">
<th id="S4.T2.9.23.14.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T2.9.23.14.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.23.14.2.1" class="ltx_text" style="background-color:#F7FBFF;"> QA before doc (interleaved)</span></th>
<td id="S4.T2.9.23.14.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.23.14.3.1" class="ltx_text" style="background-color:#F7FBFF;">45.9</span></td>
<td id="S4.T2.9.23.14.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.23.14.4.1" class="ltx_text" style="background-color:#F7FBFF;">51.3</span></td>
<td id="S4.T2.9.23.14.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.23.14.5.1" class="ltx_text" style="background-color:#F7FBFF;">64.5</span></td>
</tr>
<tr id="S4.T2.9.24.15" class="ltx_tr">
<th id="S4.T2.9.24.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.24.15.1.1" class="ltx_text" style="background-color:#F7FBFF;">PIT  ➆</span></th>
<th id="S4.T2.9.24.15.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.24.15.2.1" class="ltx_text" style="background-color:#F7FBFF;"> QA after doc (interleaved)</span></th>
<td id="S4.T2.9.24.15.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.24.15.3.1" class="ltx_text" style="background-color:#F7FBFF;">43.2</span></td>
<td id="S4.T2.9.24.15.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.24.15.4.1" class="ltx_text" style="background-color:#F7FBFF;">49.1</span></td>
<td id="S4.T2.9.24.15.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.24.15.5.1" class="ltx_text" style="background-color:#F7FBFF;">61.6</span></td>
</tr>
<tr id="S4.T2.7.7" class="ltx_tr">
<th id="S4.T2.7.7.3" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="background-color:#FFF7FA;"><span id="S4.T2.7.7.3.1" class="ltx_text" style="background-color:#FFF7FA;">PIT–</span></th>
<th id="S4.T2.7.7.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#FFF7FA;"><span id="S4.T2.7.7.2.2" class="ltx_text" style="background-color:#FFF7FA;">train QA + train doc <math id="S4.T2.6.6.1.1.m1.1" class="ltx_Math" style="background-color:#FFF7FA;" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.6.6.1.1.m1.1a"><mo mathbackground="#FFF7FA" stretchy="false" id="S4.T2.6.6.1.1.m1.1.1" xref="S4.T2.6.6.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.1.1.m1.1b"><ci id="S4.T2.6.6.1.1.m1.1.1.cmml" xref="S4.T2.6.6.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.1.1.m1.1c">\shortrightarrow</annotation></semantics></math> train QA <math id="S4.T2.7.7.2.2.m2.1" class="ltx_Math" style="background-color:#FFF7FA;" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.7.7.2.2.m2.1a"><mo mathbackground="#FFF7FA" stretchy="false" id="S4.T2.7.7.2.2.m2.1.1" xref="S4.T2.7.7.2.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.2.2.m2.1b"><ci id="S4.T2.7.7.2.2.m2.1.1.cmml" xref="S4.T2.7.7.2.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.2.2.m2.1c">\shortrightarrow</annotation></semantics></math> test doc</span></th>
<td id="S4.T2.7.7.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#FFF7FA;"><span id="S4.T2.7.7.4.1" class="ltx_text" style="background-color:#FFF7FA;">44.4</span></td>
<td id="S4.T2.7.7.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#FFF7FA;"><span id="S4.T2.7.7.5.1" class="ltx_text" style="background-color:#FFF7FA;">51.3</span></td>
<td id="S4.T2.7.7.6" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#FFF7FA;"><span id="S4.T2.7.7.6.1" class="ltx_text" style="background-color:#FFF7FA;">63.4</span></td>
</tr>
<tr id="S4.T2.9.9" class="ltx_tr">
<th id="S4.T2.9.9.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="background-color:#E9FCE9;"><span id="S4.T2.9.9.3.1" class="ltx_text" style="background-color:#E9FCE9;">PIT++  ➇</span></th>
<th id="S4.T2.9.9.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="background-color:#E9FCE9;"><span id="S4.T2.9.9.2.2" class="ltx_text" style="background-color:#E9FCE9;">train QA <math id="S4.T2.8.8.1.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.8.8.1.1.m1.1a"><mo mathbackground="#E9FCE9" stretchy="false" id="S4.T2.8.8.1.1.m1.1.1" xref="S4.T2.8.8.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.1.1.m1.1b"><ci id="S4.T2.8.8.1.1.m1.1.1.cmml" xref="S4.T2.8.8.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.1.1.m1.1c">\shortrightarrow</annotation></semantics></math> train QA + train doc <math id="S4.T2.9.9.2.2.m2.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.9.9.2.2.m2.1a"><mo mathbackground="#E9FCE9" stretchy="false" id="S4.T2.9.9.2.2.m2.1.1" xref="S4.T2.9.9.2.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.9.9.2.2.m2.1b"><ci id="S4.T2.9.9.2.2.m2.1.1.cmml" xref="S4.T2.9.9.2.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.9.2.2.m2.1c">\shortrightarrow</annotation></semantics></math> test doc</span></th>
<td id="S4.T2.9.9.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" style="background-color:#E9FCE9;"><span id="S4.T2.9.9.4.1" class="ltx_text ltx_font_bold" style="background-color:#E9FCE9;">48.1</span></td>
<td id="S4.T2.9.9.5" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" style="background-color:#E9FCE9;"><span id="S4.T2.9.9.5.1" class="ltx_text ltx_font_bold" style="background-color:#E9FCE9;">54.4</span></td>
<td id="S4.T2.9.9.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" style="background-color:#E9FCE9;"><span id="S4.T2.9.9.6.1" class="ltx_text ltx_font_bold" style="background-color:#E9FCE9;">66.4</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 2:</span>Llama-2 7B를 사용하여 향상된 성능에 대한 주요 기여자를 식별하기 위한 다양한 사전 명령 조정 방법 및 절제 연구의 비교(%)입니다. 상이한 배경 컬러들은 상이한 사전 명령-튜닝 방법들을 나타낸다. 가장 좋은 결과는 굵은 글씨입니다.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Improving LLMs in Absorbing Knowledge from Documents</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p" id="S5.p1.1">표준적인 지시-조정을 통해 도출되는 지식의 양은 여전히 제한적이며, 문서의 당혹성을 최소화하더라도 우리가 "당혹성의 저주"라고 부르는 현상이다. 우리의 다음 질문은 어떻게 LLM이 문서로부터 지식을 흡수하여 복잡성 저주를 완화할 수 있는 능력을 향상시킬 수 있는가이다. 주요 과제는 지식이 원시문서에서 제시되는 방식과 질의응답을 통해 접근하는 방식의 괴리이다. 우리는 QA 쌍이 일반적으로 간단하지만 문서가 더 복잡하고 어수선하여 더 복잡한 방식으로 많은 사실 진술을 함께 엮는 경향이 있음을 발견했다. <a class="ltx_ref ltx_refmacro_autoref" href="#S2.F3" title="Figure 3 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 3</span></a>를 예로 들면, “오펜하이머의 편집을 누가 처리했는가”라는 질문에 대한 답은 “오펜하이머”를 명시적으로 언급하지 않은 “편집은 제니퍼 라임에 의해 처리되었다.”라는 글의 중간에 있는 문장에 포함되어 있다. 훈련 동안 LLM은 문맥을 이해하고 "편집"이 매개변수에서 이 지식을 효과적으로 인코딩하기 위해 "오펜하이머의 편집"을 지칭한다는 것을 추론해야 한다.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p class="ltx_p" id="S5.p2.1"><cite class="ltx_cite ltx_citemacro_citet">Zhu and Li (<a class="ltx_ref" href="#bib.bib63" title="">2023a</a>)</cite>는 합성 전기에서 무작위로 초기화된 GPT-2 유사 변압기를 처음부터 훈련하여 이 문제를 연구하고 개인에 대한 질문에 답하는 능력을 평가했다. 그들은 <a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>의 ➃ 설정과 유사한 나머지 전기 절반에 대한 질문에 답할 때 전기와 전기 절반과 관련된 질문을 혼합하여 교육하는 것이 강력한 일반화로 이어진다는 것을 발견했다. 대조적으로, 전기 및 QA 쌍에 대한 교육은 순차적으로 실패했다. 그러나 데이터가 함께 혼합되었기 때문에 성공의 핵심 기여자는 여전히 불확실하며 새로운 문서의 지식을 흡수하기 위해 실제로 이를 적용하는 방법이 불분명하다. QA 쌍과 문서 사이의 서로 다른 난이도 수준과 <cite class="ltx_cite ltx_citemacro_citet">Zhu and Li (<a class="ltx_ref" href="#bib.bib63" title="">2023a</a>)</cite>의 발견에 영감을 받아 <em class="ltx_emph ltx_font_italic" id="S5.p2.1.1">을 계속 사전 훈련 전에 지시 조정 데이터에 의도적으로 LLMs를 노출시켜 복잡한 문서로부터 지식을 인코딩하는 프로세스가 이 지식에 액세스하는 방법을 고려하는 것이 유익하다고 가정한다. </em> 우리는 이것을 <span class="ltx_text ltx_font_bold" id="S5.p2.1.2">pre-instruction-tuning (PIT)</span>이라고 부르고 계속된 학습에 앞서 PIT의 다양한 구현을 연구한다(<a class="ltx_ref ltx_refmacro_autoref" href="#S5.SS1" title="5.1 Variants of Pre-instruction-tuning ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">§ 5.1</span></a>), 이어서 성능에 기여하는 키들을 식별하는 상세한 제거들(<a class="ltx_ref ltx_refmacro_autoref" href="#S5.SS2" title="5.2 Pre-instruction-tuning++ ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">§ 5.2</span></a> 및 <a class="ltx_ref ltx_refmacro_autoref" href="#S5.SS3" title="5.3 Ablation Studies ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">§ 5.3</span></a>), 그리고 마지막으로 PIT가 도메인에 걸쳐 얼마나 잘 수행하는지를 평가한다(<a class="ltx_ref ltx_refmacro_autoref" href="#S5.SS4" title="5.4 Cross-domain Generalization ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">§ 5.4</span></a>). <a class="ltx_ref ltx_refmacro_autoref" href="#S3.SS2" title="3.2 Hyperparameters ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">§ 3.2</span></a>에 요약된 하이퍼파라미터를 준수하고 달리 명시되지 않는 한 3개의 에폭에 대해 PIT를 수행한다.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Variants of Pre-instruction-tuning</h3>

<section id="S5.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Pre-instruction-tuning w/ QA only</h4>

<div id="S5.SS1.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.1">우리는 문서에 대한 사전 교육을 계속하기 전에 명령어 조정 데이터를 노출하는 것으로 시작한다. 테스트 문서에 대한 교육을 하기 전에 국소적으로 관련된 QA 쌍에 대한 교육을 한다(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➄). 이는 계속되는 사전 훈련 설정(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➀)과 직접적으로 비교될 수 있다. 직관은 질문이 LLMs가 주요 유형의 정보를 인식하는 데 도움이 되어 질문이 문서와 직접 연결되지 않더라도 후속 문서에 대한 사전 훈련 중에 LLMs가 중요한 정보에 집중할 수 있도록 한다는 것이다. 예를 들어, “누가 오펜하이머의 편집을 처리했는가”와 같은 질문에 대한 교육은 “바비”와 같은 새로운 문서에 대한 교육을 할 때 LLM이 시나리오 작성자에게 주의를 기울이는 데 도움이 될 수 있다. <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T1" title="Table 1 ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 1</span></a>에 나타낸 바와 같이, 이 방법은 특히 더 큰 LLMs(7B/70B의 경우 27.6%/41.7% <math alttext="\shortrightarrow" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="S5.SS1.SSS0.Px1.p1.1.m1.1a"><mo id="S5.SS1.SSS0.Px1.p1.1.m1.1.1" stretchy="false" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="S5.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.1.m1.1c">\shortrightarrow</annotation></semantics></math> 28.6%/49.7%)에서 계속되는 사전 훈련보다 우수하다. 문서들에 대한 트레이닝 후에 QA 데이터에 대해 트레이닝하는 절제(<a class="ltx_ref ltx_refmacro_autoref" href="#S4.T2" title="Table 2 ‣ Experiment results ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 2</span></a>의 “명령-튜닝 w/o train doc”)는 비효율적이며, 문서들을 인코딩하기 전의 워밍업으로서 질문들에 대한 트레이닝의 중요성을 확인시켜준다.</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Pre-instruction-tuning on QA and documents sequentially</h4>

<div id="S5.SS1.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS0.Px2.p1.1">두 번째 구현은 단순화된 QA 쌍을 파악한 후 복잡한 문서에 LLM을 학습하면 문서로부터 지식을 흡수할 수 있는 능력이 강화될 수 있다는 직감으로 QA와 관련 문서를 순차적으로 학습한다(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➅). 예를 들어, LLM이 이미 “제니퍼 레임”이 “누가 오펜하이머의 편집을 처리했는가”에 대한 답이라는 것을 배웠다면, “편집은 제니퍼 레임에 의해 처리되었다”라는 문서에 대한 훈련은 매개 변수에 있는 지식의 저장을 더 효율적으로 정제할 수 있다. <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T1" title="Table 1 ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 1</span></a>와 같이 QA 쌍과 문서에 대한 PIT는 QA 전용 변형(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➄)과 표준 명령 조정(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➁)을 순차적으로 능가한다(7B/70B의 경우 30.3%/46.4% <math alttext="\shortrightarrow" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px2.p1.1.m1.1"><semantics id="S5.SS1.SSS0.Px2.p1.1.m1.1a"><mo id="S5.SS1.SSS0.Px2.p1.1.m1.1.1" stretchy="false" xref="S5.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p1.1.m1.1b"><ci id="S5.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p1.1.m1.1c">\shortrightarrow</annotation></semantics></math> 32.5%/54.6%).</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Pre-instruction-tuning </h4>

<div id="S5.SS1.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS0.Px3.p1.1">PIT의 효과는 관련된 QA 쌍이 각각의 문서를 인코딩하기 전에 이미 학습되었는지 확인하는 것에 달려 있다. 그러나 문서(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➅의 훈련 doc)에 대한 훈련 후 해당 문항에 대한 정확도(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➅의 훈련 QA)가 거의 완벽에서 30%로 떨어져 심각한 망각임을 알 수 있었다. 이를 해결하기 위해 관련 QA 쌍과 문서를 함께 학습한다(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➆). <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T1" title="Table 1 ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 1</span></a>에 도시된 바와 같이, 이는 모든 데이터를 함께 혼합하는 것(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➃)을 포함한 다른 모든 접근법보다 큰 마진(7B/70B의 경우 39.4%/57.1% <math alttext="\shortrightarrow" class="ltx_Math" display="inline" id="S5.SS1.SSS0.Px3.p1.1.m1.1"><semantics id="S5.SS1.SSS0.Px3.p1.1.m1.1a"><mo id="S5.SS1.SSS0.Px3.p1.1.m1.1.1" stretchy="false" xref="S5.SS1.SSS0.Px3.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px3.p1.1.m1.1b"><ci id="S5.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px3.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px3.p1.1.m1.1c">\shortrightarrow</annotation></semantics></math> 45.5%/62.7%)만큼 성능을 크게 향상시킨다. QA 쌍과 문서 모두에 대한 훈련은 망각을 방지하지만 학습 프로세스가 작동하는 방식도 모호합니다. LLM이 문서로부터 지식을 인코딩하기 전에 QA 쌍을 파악하는지, 아니면 반대로 작동하는지는 불분명하다. 다음 섹션에서는 이를 조사하기 위해 훈련 중 QA 쌍과 문서의 순서를 의도적으로 배열하여 PIT의 개선된 버전을 제안한다.</p>
</div>
<figure id="S5.F6" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.12847/assets/x8.png" id="S5.F6.g1" class="ltx_graphics ltx_img_landscape" width="461" height="247" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 6:</span>QA 쌍과 해당 문서 간의 서로 다른 배열. 타원은 다른 예를 나타낸다.</figcaption>
</figure>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Pre-instruction-tuning++</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS2.p1.1">우리는 먼저 에폭의 수에 따라 성능이 어떻게 달라지는지 연구한다. <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T2" title="Table 2 ‣ Experiment results ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 2</span></a>와 같이 1 epoch에 대한 훈련이 부족하고 3, 5, 10 epoch의 성능도 유사하다. 에포크 수를 3으로 고정하고 QA 쌍과 해당 문서의 순서를 <a class="ltx_ref ltx_refmacro_autoref" href="#S5.F6" title="Figure 6 ‣ Pre-instruction-tuning ‣ 5.1 Variants of Pre-instruction-tuning ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 6</span></a>와 같이 배열한다. 인터리브된 배열은 모든 데이터를 3번 반복하여 각 에포크에서 질문이 관련 문서에 선행하거나 후속하도록 한다. 반면에, 그룹화된 배열은 각각의 예의 3가지 모습을 함께 클러스터링하여, 반복되는 질문이 각각의 반복되는 문서 앞 또는 뒤에 위치한다는 것을 보장한다. <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T2" title="Table 2 ‣ Experiment results ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 2</span></a>에 나타낸 바와 같이, 해당 문서 이전에 QA 쌍을 위치시키는 것은 그룹화된 배열과 인터리빙된 배열 모두에서 더 나은 성능을 달성하며, 이는 PIT 동안 학습 메커니즘이 더 복잡하고 정보 밀도가 높은 문서로부터 정보를 흡수하기 위해 학습 전에 지식에 액세스하는 방법을 이해하는 것을 우선시한다는 것을 나타낸다.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S5.SS2.p2.1">이를 기반으로 지식 접근의 패턴을 이해하기 위해 QA 쌍만을 학습하고, 문서로부터 질문과 지식 인코딩을 통해 지식 접근을 정렬하기 위해 QA와 문서 데이터의 조합에 대한 학습으로 진행하는 pre-instruction-tuning++라는 개선된 변형을 제안한다(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➇). <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T2" title="Table 2 ‣ Experiment results ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 2</span></a>에서 볼 수 있듯이 PIT++는 PIT(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➆)를 45.4%에서 48.1%로 크게 능가하는 반면, 믹스 후 QA 데이터에 대한 훈련(PIT- in <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T2" title="Table 2 ‣ Experiment results ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 2</span></a>)은 추가 이점을 제공하지 않는다. 이것은 지식이 접근하는 방법을 이해하는 것이 문서로부터 지식을 흡수하는 데 도움이 되므로 우선시되어야 한다는 우리의 가설을 강화한다.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Ablation Studies</h3>

<section id="S5.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Standard instruction-tuning is inferior not due to forgetting</h4>

<div id="S5.SS3.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS3.SSS0.Px1.p1.1">표준 명령어 튜닝의 단점은 QA 쌍에 대한 트레이닝 후에 테스트 문서의 지식이 잊혀질 수 있다는 것이다("정렬 세금" <cite class="ltx_cite ltx_citemacro_cite">Ouyang et al. (<a class="ltx_ref" href="#bib.bib35" title="">2022</a>)</cite>로도 알려진 현상). 표준 명령어 튜닝의 성능이 망각으로 인한 것이 아님을 보이기 위해 명령어 튜닝 시 테스트 문서와 훈련 QA를 혼합하여 망각을 방지하는 설정을 추가한다(<a class="ltx_ref ltx_refmacro_autoref" href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Fig. 4</span></a>  ➂). <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T2" title="Table 2 ‣ Experiment results ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 2</span></a>와 같이 이는 도움이 되지 않아 우리의 가설을 확인시켜준다.</p>
</div>
</section>
<section id="S5.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Pre-instruction-tuning is not simply upweighting salient tokens from documents</h4>

<div id="S5.SS3.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS3.SSS0.Px2.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Hu et al. (<a class="ltx_ref" href="#bib.bib16" title="">2023</a>)</cite>에서 영감을 받은 삭제는 눈에 띄는 정보에 초점을 맞추기 위해 문서를 사전 훈련할 때 토큰을 가중화하는 것이다. 답변에 포함된 문서의 토큰에 1.0의 가중치를 부여하고(예: "편집은 제니퍼 라임에 의해 처리되었다" 문장에서 "제니퍼 라임"과 같이), 다른 토큰에 0.5의 낮은 가중치를 부여한다. <a class="ltx_ref ltx_refmacro_autoref" href="#S4.T2" title="Table 2 ‣ Experiment results ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 2</span></a>와 같이 이 가중 지속 사전 훈련은 효과가 없어 우리의 가설을 확인시켜준다.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<table id="S5.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.1.1.1" class="ltx_tr">
<th id="S5.T3.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<td id="S5.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3"><span id="S5.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Llama-2 7B</span></td>
<td id="S5.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S5.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">Llama-2 70B</span></td>
</tr>
<tr id="S5.T3.1.2.2" class="ltx_tr">
<th id="S5.T3.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T3.1.2.2.1.1" class="ltx_text ltx_font_bold">Settings</span></th>
<td id="S5.T3.1.2.2.2" class="ltx_td ltx_align_right"><span id="S5.T3.1.2.2.2.1" class="ltx_text ltx_font_bold">EM</span></td>
<td id="S5.T3.1.2.2.3" class="ltx_td ltx_nopad_l ltx_align_right"><span id="S5.T3.1.2.2.3.1" class="ltx_text ltx_font_bold">Rec.</span></td>
<td id="S5.T3.1.2.2.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r"><span id="S5.T3.1.2.2.4.1" class="ltx_text ltx_font_bold">R-L</span></td>
<td id="S5.T3.1.2.2.5" class="ltx_td ltx_align_right"><span id="S5.T3.1.2.2.5.1" class="ltx_text ltx_font_bold">EM</span></td>
<td id="S5.T3.1.2.2.6" class="ltx_td ltx_nopad_l ltx_align_right"><span id="S5.T3.1.2.2.6.1" class="ltx_text ltx_font_bold">Rec.</span></td>
<td id="S5.T3.1.2.2.7" class="ltx_td ltx_nopad_l ltx_align_right"><span id="S5.T3.1.2.2.7.1" class="ltx_text ltx_font_bold">R-L</span></td>
</tr>
<tr id="S5.T3.1.3.3" class="ltx_tr">
<th id="S5.T3.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="7">
<em id="S5.T3.1.3.3.1.1" class="ltx_emph ltx_font_italic">standard instruction-tuning</em>  ➁</th>
</tr>
<tr id="S5.T3.1.4.4" class="ltx_tr">
<th id="S5.T3.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">in-domain</th>
<td id="S5.T3.1.4.4.2" class="ltx_td ltx_align_right">30.3</td>
<td id="S5.T3.1.4.4.3" class="ltx_td ltx_nopad_l ltx_align_right">34.7</td>
<td id="S5.T3.1.4.4.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">47.4</td>
<td id="S5.T3.1.4.4.5" class="ltx_td ltx_align_right">46.4</td>
<td id="S5.T3.1.4.4.6" class="ltx_td ltx_nopad_l ltx_align_right">50.9</td>
<td id="S5.T3.1.4.4.7" class="ltx_td ltx_nopad_l ltx_align_right">64.1</td>
</tr>
<tr id="S5.T3.1.5.5" class="ltx_tr">
<th id="S5.T3.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">cross-domain</th>
<td id="S5.T3.1.5.5.2" class="ltx_td ltx_align_right">23.6</td>
<td id="S5.T3.1.5.5.3" class="ltx_td ltx_nopad_l ltx_align_right">28.2</td>
<td id="S5.T3.1.5.5.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">38.4</td>
<td id="S5.T3.1.5.5.5" class="ltx_td ltx_align_right">42.8</td>
<td id="S5.T3.1.5.5.6" class="ltx_td ltx_nopad_l ltx_align_right">49.7</td>
<td id="S5.T3.1.5.5.7" class="ltx_td ltx_nopad_l ltx_align_right">58.5</td>
</tr>
<tr id="S5.T3.1.6.6" class="ltx_tr">
<th id="S5.T3.1.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="7">
<em id="S5.T3.1.6.6.1.1" class="ltx_emph ltx_font_italic">pre-instruction-tuning</em>  ➆</th>
</tr>
<tr id="S5.T3.1.7.7" class="ltx_tr">
<th id="S5.T3.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">in-domain</th>
<td id="S5.T3.1.7.7.2" class="ltx_td ltx_align_right">45.4</td>
<td id="S5.T3.1.7.7.3" class="ltx_td ltx_nopad_l ltx_align_right">51.2</td>
<td id="S5.T3.1.7.7.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">63.2</td>
<td id="S5.T3.1.7.7.5" class="ltx_td ltx_align_right">62.7</td>
<td id="S5.T3.1.7.7.6" class="ltx_td ltx_nopad_l ltx_align_right">68.6</td>
<td id="S5.T3.1.7.7.7" class="ltx_td ltx_nopad_l ltx_align_right">78.8</td>
</tr>
<tr id="S5.T3.1.8.8" class="ltx_tr">
<th id="S5.T3.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">cross-domain</th>
<td id="S5.T3.1.8.8.2" class="ltx_td ltx_align_right ltx_border_bb">36.9</td>
<td id="S5.T3.1.8.8.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb">43.2</td>
<td id="S5.T3.1.8.8.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb ltx_border_r">54.9</td>
<td id="S5.T3.1.8.8.5" class="ltx_td ltx_align_right ltx_border_bb">55.2</td>
<td id="S5.T3.1.8.8.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb">66.7</td>
<td id="S5.T3.1.8.8.7" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb">74.0</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 3:</span>In-domain and cross-domain PIT.</figcaption>
</figure>
<figure id="S5.T4" class="ltx_table">
<table id="S5.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T4.1.1.1" class="ltx_tr">
<th id="S5.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt"><span id="S5.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">Settings</span></th>
<td id="S5.T4.1.1.1.2" class="ltx_td ltx_align_right ltx_border_tt"><span id="S5.T4.1.1.1.2.1" class="ltx_text ltx_font_bold">EM</span></td>
<td id="S5.T4.1.1.1.3" class="ltx_td ltx_align_right ltx_border_tt"><span id="S5.T4.1.1.1.3.1" class="ltx_text ltx_font_bold">Rec.</span></td>
<td id="S5.T4.1.1.1.4" class="ltx_td ltx_align_right ltx_border_tt"><span id="S5.T4.1.1.1.4.1" class="ltx_text ltx_font_bold">R-L</span></td>
</tr>
<tr id="S5.T4.1.2.2" class="ltx_tr">
<th id="S5.T4.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4"><em id="S5.T4.1.2.2.1.1" class="ltx_emph ltx_font_italic">generalization to the biography dataset <span id="S5.T4.1.2.2.1.1.1" class="ltx_text ltx_font_typewriter">bioS</span></em></th>
</tr>
<tr id="S5.T4.1.3.3" class="ltx_tr">
<th id="S5.T4.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">closed-book</th>
<td id="S5.T4.1.3.3.2" class="ltx_td ltx_align_right">2.9</td>
<td id="S5.T4.1.3.3.3" class="ltx_td ltx_align_right">2.9</td>
<td id="S5.T4.1.3.3.4" class="ltx_td ltx_align_right">11.0</td>
</tr>
<tr id="S5.T4.1.4.4" class="ltx_tr">
<th id="S5.T4.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">open-book w/ doc</th>
<td id="S5.T4.1.4.4.2" class="ltx_td ltx_align_right">95.2</td>
<td id="S5.T4.1.4.4.3" class="ltx_td ltx_align_right">95.4</td>
<td id="S5.T4.1.4.4.4" class="ltx_td ltx_align_right">95.6</td>
</tr>
<tr id="S5.T4.1.5.5" class="ltx_tr">
<th id="S5.T4.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">continued pre-training  ➀</th>
<td id="S5.T4.1.5.5.2" class="ltx_td ltx_align_right">29.6</td>
<td id="S5.T4.1.5.5.3" class="ltx_td ltx_align_right">29.8</td>
<td id="S5.T4.1.5.5.4" class="ltx_td ltx_align_right">38.7</td>
</tr>
<tr id="S5.T4.1.6.6" class="ltx_tr">
<th id="S5.T4.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">pre-instruction-tuning  ➆</th>
<td id="S5.T4.1.6.6.2" class="ltx_td ltx_align_right"><span id="S5.T4.1.6.6.2.1" class="ltx_text ltx_font_bold">58.1</span></td>
<td id="S5.T4.1.6.6.3" class="ltx_td ltx_align_right"><span id="S5.T4.1.6.6.3.1" class="ltx_text ltx_font_bold">58.4</span></td>
<td id="S5.T4.1.6.6.4" class="ltx_td ltx_align_right"><span id="S5.T4.1.6.6.4.1" class="ltx_text ltx_font_bold">61.9</span></td>
</tr>
<tr id="S5.T4.1.7.7" class="ltx_tr">
<th id="S5.T4.1.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4"><em id="S5.T4.1.7.7.1.1" class="ltx_emph ltx_font_italic">generalization to questions by real users from Google</em></th>
</tr>
<tr id="S5.T4.1.8.8" class="ltx_tr">
<th id="S5.T4.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">standard instruction-tuning  ➁</th>
<td id="S5.T4.1.8.8.2" class="ltx_td ltx_align_right">21.5</td>
<td id="S5.T4.1.8.8.3" class="ltx_td ltx_align_right">30.1</td>
<td id="S5.T4.1.8.8.4" class="ltx_td ltx_align_right">36.8</td>
</tr>
<tr id="S5.T4.1.9.9" class="ltx_tr">
<th id="S5.T4.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">pre-instruction-tuning  ➆</th>
<td id="S5.T4.1.9.9.2" class="ltx_td ltx_align_right ltx_border_bb"><span id="S5.T4.1.9.9.2.1" class="ltx_text ltx_font_bold">29.0</span></td>
<td id="S5.T4.1.9.9.3" class="ltx_td ltx_align_right ltx_border_bb"><span id="S5.T4.1.9.9.3.1" class="ltx_text ltx_font_bold">35.5</span></td>
<td id="S5.T4.1.9.9.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S5.T4.1.9.9.4.1" class="ltx_text ltx_font_bold">48.2</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 4:</span>pre-instruction-tuning으로 학습된 Llama-2 7B 모델의 일반화.</figcaption>
</figure>
</section>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Cross-domain Generalization</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS4.p1.1">우리는 동일한 도메인(<span class="ltx_text ltx_font_typewriter" id="S5.SS4.p1.1.1">Wiki2023-film</span>)의 데이터에 대한 훈련 및 평가를 통해 PIT의 유효성을 검증했다. <em class="ltx_emph ltx_font_italic" id="S5.SS4.p1.1.2">Can PIT makes LLMs made the better at absorbing knowledge from the documents of a different domain? 이를 위해 다른 도메인에 대한 학습(<span class="ltx_text ltx_font_typewriter" id="S5.SS4.p1.1.3">Wiki2023-other-train</span>) 및 필름 도메인에 대한 테스트(<span class="ltx_text ltx_font_typewriter" id="S5.SS4.p1.1.4">Wiki2023-film-test</span>)에 설명된 교차 도메인 설정을 따릅니다. 표준 명령어 조정 및 PIT의 결과는 도메인 내 및 교차 도메인 설정 모두에서 <a class="ltx_ref ltx_refmacro_autoref" href="#S5.T3" title="Table 3 ‣ Pre-instruction-tuning is not simply upweighting salient tokens from documents ‣ 5.3 Ablation Studies ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 3</span></a>에 자세히 설명되어 있다. 비록 그것이 도메인 내 대응물만큼 효과적이지는 않지만, 교차 도메인 PIT는 여전히 명령어-튜닝을 상당히 능가하여, 그것이 상이한 도메인들에 걸쳐 일반화될 수 있음을 입증한다. 이 발견은 이 방법을 보다 강력한 일반화를 위한 광범위한 범위의 문서 및 지침으로 확장할 가능성을 조명한다.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p class="ltx_p" id="S5.SS4.p2.1">또한 두 가지 다른 시나리오에서 PIT의 효과를 평가한다: (1) 비위키피디아 문서에 적용될 때, (2) 실제 사용자가 질문한 질문에 답할 때. 첫 번째 시나리오는 <span class="ltx_text ltx_font_typewriter" id="S5.SS4.p2.1.1">2023Wiki-other</span>에서 PIT로 훈련된 Llama-2 7B 모델을 취하여 <cite class="ltx_cite ltx_citemacro_citet">Zhu and Li (<a class="ltx_ref" href="#bib.bib63" title="">2023a</a>)</cite>에서 합성된 전기(<span class="ltx_text ltx_font_typewriter" id="S5.SS4.p2.1.2">bioS</span>)에서 추가로 훈련한다. 그런 다음 개인에 대한 질문을 기반으로 평가합니다. 두 번째 시나리오는 <span class="ltx_text ltx_font_typewriter" id="S5.SS4.p2.1.3">Wiki2023-film-test</span>에서 LLMs에 의해 생성된 질문을 사용하여 구글을 수동으로 검색하고, 구글의 "People Also Ask" 기능을 활용하여 실제 사용자로부터 총 93개의 유사한 질문을 수집한 다음, 이러한 질문에 대해 Llama-2 7B를 평가한다. <a class="ltx_ref ltx_refmacro_autoref" href="#S5.T4" title="Table 4 ‣ Pre-instruction-tuning is not simply upweighting salient tokens from documents ‣ 5.3 Ablation Studies ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners"><span class="ltx_text ltx_ref_tag">Tab. 4</span></a>와 같이 PIT는 두 시나리오 모두에서 기준선을 능가하여 일반화 능력을 보여준다.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Related Work</h2>

<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Continual Knowledge Acquisition</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS1.p1.1">여러 연구에서 LMs가 학습한 문서의 정보에 대한 질문에 답할 수 있는지 여부를 연구했다. <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="#bib.bib54" title="">2021</a>); Jang et al. (<a class="ltx_ref" href="#bib.bib20" title="">2022</a>); Hu et al. (<a class="ltx_ref" href="#bib.bib16" title="">2023</a>)</cite>는 BART <cite class="ltx_cite ltx_citemacro_cite">Lewis et al. (<a class="ltx_ref" href="#bib.bib27" title="">2020a</a>)</cite>, T5 <cite class="ltx_cite ltx_citemacro_cite">Raffel et al. (<a class="ltx_ref" href="#bib.bib41" title="">2020</a>)</cite>, 또는 GPT-2 <cite class="ltx_cite ltx_citemacro_cite">Radford et al. (<a class="ltx_ref" href="#bib.bib39" title="">2019</a>)</cite>와 같이 비교적 작은 LMs를 사용한다. <cite class="ltx_cite ltx_citemacro_citet">Ovadia et al. (<a class="ltx_ref" href="#bib.bib36" title="">2023</a>)</cite>는 명령어-튜닝을 사용하지 않고 RAG와 계속된 사전-훈련 접근법 간의 비교에 초점을 맞춘다. <cite class="ltx_cite ltx_citemacro_citet">Zhu and Li (<a class="ltx_ref" href="#bib.bib63" title="">2023a</a>, <a class="ltx_ref" href="#bib.bib64" title="">b</a>)</cite>는 합성 전기에서 처음부터 훈련되고 개인과 관련된 QA 쌍에서 미세 조정된 GPT-2 유사 변압기를 사용하여 우리와 유사한 각도에서 이 문제를 조사한다. 그들은 전기와 QA 쌍 모두에 대한 혼합 훈련 환경을 조사했으며, 이는 지속적인 사전 훈련 전에 QA 데이터를 통합하기 위한 다양한 전략을 연구하려는 주요 동기이다. 다른 연구에서는 다양한 전략을 통해 LLM을 새로운 도메인에 적응시키는 <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="#bib.bib59" title="">2023</a>); Cheng et al. (<a class="ltx_ref" href="#bib.bib8" title="">2023</a>); Han et al. (<a class="ltx_ref" href="#bib.bib14" title="">2023</a>); Wu et al. (<a class="ltx_ref" href="#bib.bib57" title="">2023</a>); Nguyen et al. (<a class="ltx_ref" href="#bib.bib33" title="">2023</a>); Zhao et al. (<a class="ltx_ref" href="#bib.bib61" title="">2023</a>)</cite>를 연구한다.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Instruction-tuning or Alignment</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS2.p1.1">고품질 주석이 달린 데이터 <cite class="ltx_cite ltx_citemacro_cite">Sanh et al. (<a class="ltx_ref" href="#bib.bib44" title="">2022</a>); Wei et al. (<a class="ltx_ref" href="#bib.bib56" title="">2022</a>); Mishra et al. (<a class="ltx_ref" href="#bib.bib31" title="">2022</a>); Iyer et al. (<a class="ltx_ref" href="#bib.bib18" title="">2022</a>); Kopf et al. (<a class="ltx_ref" href="#bib.bib24" title="">2023</a>); Zhou et al. (<a class="ltx_ref" href="#bib.bib62" title="">2023</a>); Sun et al. (<a class="ltx_ref" href="#bib.bib47" title="">2023b</a>, <a class="ltx_ref" href="#bib.bib46" title="">a</a>)</cite> 및/또는 독점 모델에 의해 생성된 데이터 <cite class="ltx_cite ltx_citemacro_cite">Taori et al. (<a class="ltx_ref" href="#bib.bib48" title="">2023</a>); Chiang et al. (<a class="ltx_ref" href="#bib.bib9" title="">2023</a>); Wang et al. (<a class="ltx_ref" href="#bib.bib55" title="">2023b</a>); Ivison et al. (<a class="ltx_ref" href="#bib.bib17" title="">2023</a>)</cite> 또는 인간 피드백으로부터의 강화 학습과의 정렬(RLHF) 또는 직접 선호도 최적화(DPO) <cite class="ltx_cite ltx_citemacro_cite">Ouyang et al. (<a class="ltx_ref" href="#bib.bib35" title="">2022</a>); Touvron et al. (<a class="ltx_ref" href="#bib.bib52" title="">2023b</a>); Rafailov et al. (<a class="ltx_ref" href="#bib.bib40" title="">2023</a>); Tian et al. (<a class="ltx_ref" href="#bib.bib49" title="">2023</a>)</cite>에 대한 명령 조정(지도 미세 조정이라고도 함)은 LLM으로부터 지식을 유도하고 사용자의 질문을 처리하는 다양한 능력을 향상시키기 때문에 최근 중심 주제이다. 우리는 사실성에 초점을 맞추고 LLM에서 사실적 지식을 이끌어내기 위해 수업 조정을 수행하는 가장 좋은 방법을 연구한다.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Analyzing the Training Dynamics of LMs</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS3.p1.1">많은 연구에서 LM의 훈련 역학을 다양한 관점에서 연구한다. <cite class="ltx_cite ltx_citemacro_citet">Carlini et al. (<a class="ltx_ref" href="#bib.bib6" title="">2022</a>)</cite>는 모델 크기와 데이터 복제 빈도에 따른 암기를 정량화한다. <cite class="ltx_cite ltx_citemacro_citet">Tirumala et al. (<a class="ltx_ref" href="#bib.bib50" title="">2022</a>)</cite>는 더 큰 LMs가 더 적은 오버피팅으로 트레이닝 데이터를 더 빨리 암기한다는 것을 발견한다. <cite class="ltx_cite ltx_citemacro_citet">Xia et al. (<a class="ltx_ref" href="#bib.bib58" title="">2023</a>)</cite>는 perplexity가 다른 요인들보다 모델 행동을 더 잘 예측한다는 것을 보여준다. <cite class="ltx_cite ltx_citemacro_citet">Dery et al. (<a class="ltx_ref" href="#bib.bib11" title="">2022</a>)</cite> studies end-task aware pre-training using classification tasks and RoBERTa models. 우리의 작업은 질문에 답하기 위해 본 문서에서 정보를 리콜하고 일반화하는 능력에 특별히 초점을 맞춘다는 점에서 다르다.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Retrieval-augmented Generation</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS4.p1.1">RAG(Retrieval-augmented Generation)는 외부 소스 <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="#bib.bib7" title="">2017</a>); Guu et al. (<a class="ltx_ref" href="#bib.bib13" title="">2020</a>); Lewis et al. (<a class="ltx_ref" href="#bib.bib28" title="">2020b</a>); Borgeaud et al. (<a class="ltx_ref" href="#bib.bib4" title="">2022</a>); Wang et al. (<a class="ltx_ref" href="#bib.bib53" title="">2023a</a>); Alon et al. (<a class="ltx_ref" href="#bib.bib1" title="">2022</a>); He et al. (<a class="ltx_ref" href="#bib.bib15" title="">2021</a>); Sachan et al. (<a class="ltx_ref" href="#bib.bib43" title="">2021</a>); Izacard et al. (<a class="ltx_ref" href="#bib.bib19" title="">2023</a>); Lee et al. (<a class="ltx_ref" href="#bib.bib26" title="">2022</a>); Jiang et al. (<a class="ltx_ref" href="#bib.bib21" title="">2022</a>); Shi et al. (<a class="ltx_ref" href="#bib.bib45" title="">2023</a>); Jiang et al. (<a class="ltx_ref" href="#bib.bib23" title="">2023</a>); Asai et al. (<a class="ltx_ref" href="#bib.bib2" title="">2023</a>); Nakano et al. (<a class="ltx_ref" href="#bib.bib32" title="">2021</a>); Qin et al. (<a class="ltx_ref" href="#bib.bib38" title="">2023</a>); Lin et al. (<a class="ltx_ref" href="#bib.bib29" title="">2023</a>)</cite>에서 검색된 정보를 고정 LLMs에 증강하여 새로운 지식을 LLMs에 통합하기 위해 널리 사용되는 접근법이다. RAG는 매개변수에 저장된 지식에만 의존할 때 일반적으로 경험하는 환각을 줄이는 데 효과적이지만 검색 및 생성 프로세스는 추가 지연과 복잡성을 추가한다. 대조적으로, 매개 변수에 지식을 저장하는 지속적인 사전 훈련과 닫힌 책 방식으로 질문에 답하기 위해 저장된 지식을 활용하는 것은 추론 시간에 더 간단하고 빠르다. 이 능력을 향상시키는 것은 또한 LLM을 정보에 액세스하기 위한 신뢰할 수 있는 보조자로 사용하는 기본 단계를 나타내기 때문에 과학적으로 중요하다. 따라서 본 논문에서는 파라메트릭 접근 방법을 탐색하는 데 중점을 둔다.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p class="ltx_p" id="S7.p1.1">우리는 나중에 사실적 지식을 이끌어내는 것을 목표로 새로운 문서에 대한 지속적인 훈련의 가장 좋은 방법을 연구한다. 우리는 문서로부터 지식을 인코딩하기 전에 QA 쌍을 통해 지식이 액세스되는 방법을 학습하는 사전 명령 튜닝을 제안한다. 광범위한 실험은 사전 명령-튜닝 대 표준 명령-튜닝의 우수성을 입증한다. 향후 방향에는 이 방법을 보다 강력한 일반화를 위한 광범위한 범위의 문서 및 지침으로 확장하는 것이 포함된다.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.p1.1"><span class="ltx_text ltx_font_typewriter" id="Sx1.p1.1.1">Wiki2023</span> 데이터 세트는 지속적인 지식 획득을 연구하기 위한 비교적 깨끗한 테스트베드를 제공합니다. 그러나 그 범위는 커먼 크롤의 웹 페이지나 arXiv의 과학 문서와 같은 다른 소스에 대한 학습된 모델의 적응성을 제한하는 위키피디아로 제한된다. 본 논문에서는 QA 데이터에 대한 교수-조정을 통해 사실적 지식을 도출하는 데 중점을 둔다. 추론이나 이해력과 같은 다른 기술을 향상시키기 위한 다양한 유형의 데이터로 사전 수업 조정의 효과는 향후 연구에서 탐구될 필요가 있다.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx2.p1" class="ltx_para">
<p class="ltx_p" id="Sx2.p1.1">우리는 실험과 건설적인 피드백에 도움을 준 제위안 알렌주, 제우안 중, 슈얀 저우, 프랭크 F. 쉬, 첸 류, 루오홍 장에게 감사드린다.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alon et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Uri Alon, Frank&nbsp;F. Xu, Junxian He, Sudipta Sengupta, Dan Roth, and Graham Neubig. 2022.

</span>
<span class="ltx_bibblock">Neuro-symbolic language modeling with automaton-augmented retrieval.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2310.11511" title="" class="ltx_ref ltx_href">Self-rag: Learning to retrieve, generate, and critique through self-reflection</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.11511.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berglund et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa&nbsp;Cooper Stickland, Tomasz Korbak, and Owain Evans. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2309.12288" title="" class="ltx_ref ltx_href">The reversal curse: Llms trained on "a is b" fail to learn "b is a"</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.12288.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Borgeaud et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van&nbsp;den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de&nbsp;Las&nbsp;Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Simonyan, Jack&nbsp;W. Rae, Erich Elsen, and Laurent Sifre. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.mlr.press/v162/borgeaud22a.html" title="" class="ltx_ref ltx_href">Improving language models by retrieving from trillions of tokens</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA</em>, volume 162 of <em id="bib.bib4.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages 2206–2240. PMLR.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Tom&nbsp;B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel&nbsp;M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html" title="" class="ltx_ref ltx_href">Language models are few-shot learners</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramèr, and Chiyuan Zhang. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2202.07646" title="" class="ltx_ref ltx_href">Quantifying memorization across neural language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2202.07646.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P17-1171" title="" class="ltx_ref ltx_href">Reading wikipedia to answer open-domain questions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers</em>, pages 1870–1879. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Daixuan Cheng, Shaohan Huang, and Furu Wei. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2309.09530" title="" class="ltx_ref ltx_href">Adapting large language models via reading comprehension</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.09530.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Wei-Lin Chiang, Zhuohan Li, Zi&nbsp;Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph&nbsp;E. Gonzalez, Ion Stoica, and Eric&nbsp;P. Xing. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://lmsys.org/blog/2023-03-30-vicuna/" title="" class="ltx_ref ltx_href">Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality</a>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung&nbsp;Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi&nbsp;Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew&nbsp;M. Dai, Thanumalayan&nbsp;Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel.
2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2204.02311" title="" class="ltx_ref ltx_href">Palm: Scaling language modeling with pathways</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2204.02311.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dery et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Lucio&nbsp;M. Dery, Paul Michel, Ameet Talwalkar, and Graham Neubig. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=2bO2x8NAIMB" title="" class="ltx_ref ltx_href">Should we be pre-training? an argument for end-task aware training as an alternative</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gemini Team (2023)</span>
<span class="ltx_bibblock">
Gemini Team. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2312.11805" title="" class="ltx_ref ltx_href">Gemini: A family of highly capable multimodal models</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guu et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2002.08909" title="" class="ltx_ref ltx_href">REALM: retrieval-augmented language model pre-training</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2002.08909.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tianyu Han, Lisa&nbsp;C. Adams, Jens-Michalis Papaioannou, Paul Grundmann, Tom Oberhauser, Alexander Löser, Daniel Truhn, and Keno&nbsp;K. Bressem. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2304.08247" title="" class="ltx_ref ltx_href">Medalpaca - an open-source collection of medical conversational AI models and training data</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2304.08247.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Junxian He, Graham Neubig, and Taylor Berg-Kirkpatrick. 2021.

</span>
<span class="ltx_bibblock">Efficient nearest neighbor language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language Processing</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Nathan Hu, Eric Mitchell, Christopher&nbsp;D. Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2023.emnlp-main.268" title="" class="ltx_ref ltx_href">Meta-learning online adaptation of language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023</em>, pages 4418–4432. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ivison et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Hamish Ivison, Yizhong Wang, Valentina Pyatkin, Nathan Lambert, Matthew Peters, Pradeep Dasigi, Joel Jang, David Wadden, Noah&nbsp;A. Smith, Iz&nbsp;Beltagy, and Hannaneh Hajishirzi. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2311.10702" title="" class="ltx_ref ltx_href">Camels in a changing climate: Enhancing LM adaptation with tulu 2</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.10702.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iyer et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Srinivasan Iyer, Xi&nbsp;Victoria Lin, Ramakanth Pasunuru, Todor Mihaylov, Daniel Simig, Ping Yu, Kurt Shuster, Tianlu Wang, Qing Liu, Punit&nbsp;Singh Koura, Xian Li, Brian O’Horo, Gabriel Pereyra, Jeff Wang, Christopher Dewan, Asli Celikyilmaz, Luke Zettlemoyer, and Ves Stoyanov. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2212.12017" title="" class="ltx_ref ltx_href">OPT-IML: scaling language model instruction meta learning through the lens of generalization</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2212.12017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Gautier Izacard, Patrick S.&nbsp;H. Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://jmlr.org/papers/v24/23-0037.html" title="" class="ltx_ref ltx_href">Atlas: Few-shot learning with retrieval augmented language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">J. Mach. Learn. Res.</em>, 24:251:1–251:43.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Joel Jang, Seonghyeon Ye, Sohee Yang, Joongbo Shin, Janghoon Han, Gyeonghun Kim, Stanley&nbsp;Jungkyu Choi, and Minjoon Seo. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=vfsRB5MImo9" title="" class="ltx_ref ltx_href">Towards continual knowledge learning of language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Zhengbao Jiang, Luyu Gao, Zhiruo Wang, Jun Araki, Haibo Ding, Jamie Callan, and Graham Neubig. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2022.EMNLP-MAIN.149" title="" class="ltx_ref ltx_href">Retrieval as attention: End-to-end learning of retrieval and reading within a single transformer</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, pages 2336–2349. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Zhengbao Jiang, Frank&nbsp;F. Xu, Jun Araki, and Graham Neubig. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00324" title="" class="ltx_ref ltx_href">How can we know what language models know</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Trans. Assoc. Comput. Linguistics</em>, 8:423–438.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhengbao Jiang, Frank&nbsp;F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2023.emnlp-main.495" title="" class="ltx_ref ltx_href">Active retrieval augmented generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023</em>, pages 7969–7992. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kopf et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Andreas Kopf, Yannic Kilcher, Dimitri von Rutte, Sotiris Anagnostidis, Zhi&nbsp;Rui Tam, Keith Stevens, Abdullah Barhoum, Nguyen&nbsp;Minh Duc, Oliver Stanley, Rich’ard Nagyfi, ES&nbsp;Shahul, Sameer Suri, David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, and Alexander Mattick. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258179434" title="" class="ltx_ref ltx_href">Openassistant conversations - democratizing large language model alignment</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2304.07327.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur&nbsp;P. Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew&nbsp;M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00276" title="" class="ltx_ref ltx_href">Natural questions: a benchmark for question answering research</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Trans. Assoc. Comput. Linguistics</em>, 7:452–466.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Haejun Lee, Akhil Kedia, Jongwon Lee, Ashwin Paranjape, Christopher&nbsp;D. Manning, and Kyoung-Gu Woo. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2022.EMNLP-MAIN.198" title="" class="ltx_ref ltx_href">You only need one model for open-domain question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, pages 3047–3060. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2020a)</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.703" title="" class="ltx_ref ltx_href">BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020</em>, pages 7871–7880. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2020b)</span>
<span class="ltx_bibblock">
Patrick S.&nbsp;H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2020b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html" title="" class="ltx_ref ltx_href">Retrieval-augmented generation for knowledge-intensive NLP tasks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Xi&nbsp;Victoria Lin, Xilun Chen, Mingda Chen, Weijia Shi, Maria Lomeli, Rich James, Pedro Rodriguez, Jacob Kahn, Gergely Szilvasy, Mike Lewis, Luke Zettlemoyer, and Scott Yih. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2310.01352" title="" class="ltx_ref ltx_href">RA-DIT: retrieval-augmented dual instruction tuning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.01352.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2019)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=Bkg6RiCqY7" title="" class="ltx_ref ltx_href">Decoupled weight decay regularization</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2022.ACL-LONG.244" title="" class="ltx_ref ltx_href">Cross-task generalization via natural language crowdsourcing instructions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022</em>, pages 3470–3487. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nakano et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu&nbsp;Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2112.09332" title="" class="ltx_ref ltx_href">Webgpt: Browser-assisted question-answering with human feedback</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2112.09332.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tuan&nbsp;Dung Nguyen, Yuan-Sen Ting, Ioana Ciuca, Charlie O’Neill, Ze-Chang Sun, Maja Jablonska, Sandor Kruk, Ernest Perkowski, Jack&nbsp;W. Miller, Jason Li, Josh Peek, Kartheik Iyer, Tomasz Rózanski, Pranav Khetarpal, Sharaf Zaman, David Brodrick, Sergio J.&nbsp;Rodríguez Méndez, Thang Bui, Alyssa Goodman, Alberto Accomazzi, Jill&nbsp;P. Naiman, Jesse Cranney, Kevin Schawinski, and UniverseTBD. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2309.06126" title="" class="ltx_ref ltx_href">Astrollama: Towards specialized foundation models in astronomy</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.06126.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2303.08774" title="" class="ltx_ref ltx_href">GPT-4 technical report</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.08774.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeff Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll&nbsp;L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul&nbsp;F. Christiano, Jan Leike, and Ryan Lowe. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2203.02155" title="" class="ltx_ref ltx_href">Training language models to follow instructions with human feedback</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2203.02155.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ovadia et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Oded Ovadia, Menachem Brief, Moshik Mishaeli, and Oren Elisha. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2312.05934" title="" class="ltx_ref ltx_href">Fine-tuning or retrieval? comparing knowledge injection in llms</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2312.05934.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick S.&nbsp;H. Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander&nbsp;H. Miller. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D19-1250" title="" class="ltx_ref ltx_href">Language models as knowledge bases?</a>

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019</em>, pages 2463–2473. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yujia Qin, Zihan Cai, Dian Jin, Lan Yan, Shihao Liang, Kunlun Zhu, Yankai Lin, Xu&nbsp;Han, Ning Ding, Huadong Wang, Ruobing Xie, Fanchao Qi, Zhiyuan Liu, Maosong Sun, and Jie Zhou. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.06849" title="" class="ltx_ref ltx_href">Webcpm: Interactive web search for chinese long-form question answering</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.06849.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf" title="" class="ltx_ref ltx_href">Language models are unsupervised multitask learners</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">OpenAI Blog</em>, 1(8).

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher&nbsp;D. Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2305.18290" title="" class="ltx_ref ltx_href">Direct preference optimization: Your language model is secretly a reward model</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.18290.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J. Liu. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://jmlr.org/papers/v21/20-074.html" title="" class="ltx_ref ltx_href">Exploring the limits of transfer learning with a unified text-to-text transformer</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">J. Mach. Learn. Res.</em>, 21:140:1–140:67.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roberts et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Adam Roberts, Colin Raffel, and Noam Shazeer. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.emnlp-main.437" title="" class="ltx_ref ltx_href">How much knowledge can you pack into the parameters of a language model?</a>

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020</em>, pages 5418–5426. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sachan et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Devendra&nbsp;Singh Sachan, Siva Reddy, William&nbsp;L. Hamilton, Chris Dyer, and Dani Yogatama. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper/2021/hash/da3fde159d754a2555eaa198d2d105b2-Abstract.html" title="" class="ltx_ref ltx_href">End-to-end training of multi-document reader and retriever for open-domain question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual</em>, pages 25968–25981.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanh et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Victor Sanh, Albert Webson, Colin Raffel, Stephen&nbsp;H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M&nbsp;Saiful Bari, Canwen Xu, Urmish Thakker, Shanya&nbsp;Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal&nbsp;V. Nayak, Debajyoti Datta, Jonathan Chang, Mike&nbsp;Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng&nbsp;Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Févry, Jason&nbsp;Alan Fries, Ryan Teehan, Teven&nbsp;Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander&nbsp;M. Rush. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=9Vrb9D0WI4" title="" class="ltx_ref ltx_href">Multitask prompted training enables zero-shot task generalization</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2301.12652" title="" class="ltx_ref ltx_href">REPLUG: retrieval-augmented black-box language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2301.12652.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Zhiqing Sun, Yikang Shen, Hongxin Zhang, Qinhong Zhou, Zhenfang Chen, David&nbsp;D. Cox, Yiming Yang, and Chuang Gan. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2310.05910" title="" class="ltx_ref ltx_href">SALMON: self-alignment with principle-following reward models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.05910.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David&nbsp;D. Cox, Yiming Yang, and Chuang Gan. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2305.03047" title="" class="ltx_ref ltx_href">Principle-driven self-alignment of language models from scratch with minimal human supervision</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.03047.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori&nbsp;B. Hashimoto. 2023.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tatsu-lab/stanford_alpaca</a>.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Katherine Tian, Eric Mitchell, Huaxiu Yao, Christopher&nbsp;D. Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2311.08401" title="" class="ltx_ref ltx_href">Fine-tuning language models for factuality</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.08401.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tirumala et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Kushal Tirumala, Aram&nbsp;H. Markosyan, Luke Zettlemoyer, and Armen Aghajanyan. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://papers.nips.cc/paper_files/paper/2022/hash/fa0509f4dab6807e2cb465715bf2d249-Abstract-Conference.html" title="" class="ltx_ref ltx_href">Memorization without overfitting: Analyzing the training dynamics of large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022</em>.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurélien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2302.13971" title="" class="ltx_ref ltx_href">Llama: Open and efficient foundation language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2302.13971.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit&nbsp;Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric&nbsp;Michael Smith, Ranjan Subramanian, Xiaoqing&nbsp;Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian&nbsp;Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurélien Rodriguez, Robert Stojnic, Sergey Edunov,
and Thomas Scialom. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2307.09288" title="" class="ltx_ref ltx_href">Llama 2: Open foundation and fine-tuned chat models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.09288.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Boxin Wang, Wei Ping, Peng Xu, Lawrence McAfee, Zihan Liu, Mohammad Shoeybi, Yi&nbsp;Dong, Oleksii Kuchaiev, Bo&nbsp;Li, Chaowei Xiao, Anima Anandkumar, and Bryan Catanzaro. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2023.emnlp-main.482" title="" class="ltx_ref ltx_href">Shall we pretrain autoregressive language models with retrieval? A comprehensive study</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023</em>, pages 7763–7786. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Cunxiang Wang, Pai Liu, and Yue Zhang. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2021.ACL-LONG.251" title="" class="ltx_ref ltx_href">Can generative pre-trained language models serve as knowledge bases for closed-book qa?</a>

</span>
<span class="ltx_bibblock">In <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021</em>, pages 3241–3251. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi&nbsp;Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah&nbsp;A. Smith, Iz&nbsp;Beltagy, and Hannaneh Hajishirzi. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2306.04751" title="" class="ltx_ref ltx_href">How far can camels go? exploring the state of instruction tuning on open resources</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2306.04751.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent&nbsp;Y. Zhao, Kelvin Guu, Adams&nbsp;Wei Yu, Brian Lester, Nan Du, Andrew&nbsp;M. Dai, and Quoc&nbsp;V. Le. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=gEZrGCozdqR" title="" class="ltx_ref ltx_href">Finetuned language models are zero-shot learners</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chaoyi Wu, Weixiong Lin, Xiaoman Zhang, Ya&nbsp;Zhang, Yanfeng Wang, and Weidi Xie. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2304.14454" title="" class="ltx_ref ltx_href">Pmc-llama: Towards building open-source language models for medicine</a>.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Mengzhou Xia, Mikel Artetxe, Chunting Zhou, Xi&nbsp;Victoria Lin, Ramakanth Pasunuru, Danqi Chen, Luke Zettlemoyer, and Veselin Stoyanov. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2023.ACL-LONG.767" title="" class="ltx_ref ltx_href">Training trajectories of language models across scales</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 13711–13738. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Ruohong Zhang, Luyu Gao, Chen Zheng, Zhen Fan, Guokun Lai, Zheng Zhang, Fangzhou Ai, Yiming Yang, and Hongxia Yang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2311.10614" title="" class="ltx_ref ltx_href">A self-enhancement approach for domain-specific chatbot training via knowledge mining and digest</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.10614.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi&nbsp;Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit&nbsp;Singh Koura, Anjali Sridhar, Tianlu Wang, and Luke Zettlemoyer. 2022.

</span>
<span class="ltx_bibblock">Opt: Open pre-trained transformer language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2205.01068.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Wayne&nbsp;Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2303.18223" title="" class="ltx_ref ltx_href">A survey of large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.18223.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, Susan Zhang, Gargi Ghosh, Mike Lewis, Luke Zettlemoyer, and Omer Levy. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2305.11206" title="" class="ltx_ref ltx_href">LIMA: less is more for alignment</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.11206.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu and Li (2023a)</span>
<span class="ltx_bibblock">
Zeyuan&nbsp;Allen Zhu and Yuanzhi Li. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2309.14316" title="" class="ltx_ref ltx_href">Physics of language models: Part 3.1, knowledge storage and extraction</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.14316.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu and Li (2023b)</span>
<span class="ltx_bibblock">
Zeyuan&nbsp;Allen Zhu and Yuanzhi Li. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2309.14402" title="" class="ltx_ref ltx_href">Physics of language models: Part 3.2, knowledge manipulation</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.14402.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2402.12846" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2402.12847" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2402.12847">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2402.12847" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2402.12848" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar  5 14:57:27 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>