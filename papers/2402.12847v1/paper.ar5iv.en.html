<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2402.12847] Instruction-tuned Language Models are Better Knowledge Learners</title><meta property="og:description" content="In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it must be possible to update their factual knowledge through continued training on new data.
The standard re…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Instruction-tuned Language Models are Better Knowledge Learners">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Instruction-tuned Language Models are Better Knowledge Learners">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2402.12847">

<!--Generated on Tue Mar  5 14:57:27 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Instruction-tuned Language Models are Better Knowledge Learners</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhengbao Jiang<sup id="id13.13.id1" class="ltx_sup"><span id="id13.13.id1.1" class="ltx_text ltx_font_italic">2</span></sup>  Zhiqing Sun<sup id="id14.14.id2" class="ltx_sup">2</sup>  Weijia Shi<sup id="id15.15.id3" class="ltx_sup"><span id="id15.15.id3.1" class="ltx_text ltx_font_italic">1,3</span></sup>  Pedro Rodriguez<sup id="id16.16.id4" class="ltx_sup">1</sup>  Chunting Zhou<sup id="id17.17.id5" class="ltx_sup">1</sup> 
<br class="ltx_break"> <span id="id9.9.4" class="ltx_text ltx_font_bold">Graham Neubig<sup id="id9.9.4.1" class="ltx_sup"><span id="id9.9.4.1.1" class="ltx_text ltx_font_medium">2</span></sup>  Xi Victoria Lin<sup id="id9.9.4.2" class="ltx_sup"><span id="id9.9.4.2.1" class="ltx_text ltx_font_medium">1</span></sup>  Wen-tau Yih<sup id="id9.9.4.3" class="ltx_sup"><span id="id9.9.4.3.1" class="ltx_text ltx_font_medium">1</span></sup>  Srinivasan Iyer<sup id="id9.9.4.4" class="ltx_sup"><span id="id9.9.4.4.1" class="ltx_text ltx_font_medium">1</span></sup></span> 
<br class="ltx_break"><sup id="id18.18.id6" class="ltx_sup">1</sup>FAIR at Meta  <sup id="id19.19.id7" class="ltx_sup">2</sup>Carnegie Mellon University  <sup id="id20.20.id8" class="ltx_sup">3</sup>University of Washington 
<br class="ltx_break"><span id="id21.21.id9" class="ltx_text ltx_font_typewriter">{zhengbaj,gneubig}@cs.cmu.edu</span>  <span id="id22.22.id10" class="ltx_text ltx_font_typewriter">{victorialin,scottyih,sviyer}@meta.com</span>
</span><span class="ltx_author_notes">Majority of the work done during an internship at Meta.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id23.id1" class="ltx_p">In order for large language model (LLM)-based assistants to effectively adapt to evolving information needs, it must be possible to update their factual knowledge through continued training on new data.
The standard recipe for doing so involves continued pre-training on new documents followed by instruction-tuning on question-answer (QA) pairs.
However, we find that LLMs trained with this recipe struggle to answer questions, even though the perplexity of documents is minimized.
We found that QA pairs are generally straightforward, while documents are more complex, weaving many factual statements together in an intricate manner.
Therefore, we hypothesize that it is beneficial to expose LLMs to QA pairs <em id="id23.id1.1" class="ltx_emph ltx_font_italic">before</em> continued pre-training on documents so that the process of encoding knowledge from complex documents takes into account how this knowledge is accessed through questions.
Based on this, we propose <span id="id23.id1.2" class="ltx_text ltx_font_bold">pre-instruction-tuning (PIT)</span>, a method that instruction-tunes on questions prior to training on documents.
This contrasts with standard instruction-tuning, which learns how to extract knowledge after training on documents.
Extensive experiments and ablation studies demonstrate that PIT significantly enhances the ability of LLMs to absorb knowledge from new documents, outperforming standard instruction-tuning by 17.8%.</p>
</div>
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\addauthor</span>
<p id="p1.2" class="ltx_p">gnmagenta</p>
</div>
<div id="p2" class="ltx_para ltx_noindent">
<div id="p2.12" class="ltx_block ltx_align_bottom">
<p id="p2.12.13" class="ltx_p"><span id="p2.12.13.1" class="ltx_text ltx_font_bold">Instruction-tuned Language Models are Better Knowledge Learners</span></p>
<br class="ltx_break ltx_centering">
<p id="p2.12.12" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p2.12.12.12" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p2.12.12.12.12" class="ltx_tabular ltx_align_top">
<span class="ltx_tbody">
<span id="p2.5.5.5.5.5" class="ltx_tr">
<span id="p2.5.5.5.5.5.5" class="ltx_td ltx_align_center"><span id="p2.5.5.5.5.5.5.5" class="ltx_text ltx_font_bold">Zhengbao Jiang<sup id="p2.5.5.5.5.5.5.5.1" class="ltx_sup"><span id="p2.5.5.5.5.5.5.5.1.1" class="ltx_text ltx_font_medium ltx_font_italic">2</span></sup><span id="p2.5.5.5.5.5.5.5.2" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span>Majority of the work done during an internship at Meta.</span></span></span>  Zhiqing Sun<sup id="p2.5.5.5.5.5.5.5.3" class="ltx_sup"><span id="p2.5.5.5.5.5.5.5.3.1" class="ltx_text ltx_font_medium">2</span></sup>  Weijia Shi<sup id="p2.5.5.5.5.5.5.5.4" class="ltx_sup"><span id="p2.5.5.5.5.5.5.5.4.1" class="ltx_text ltx_font_medium ltx_font_italic">1,3</span></sup>  Pedro Rodriguez<sup id="p2.5.5.5.5.5.5.5.5" class="ltx_sup"><span id="p2.5.5.5.5.5.5.5.5.1" class="ltx_text ltx_font_medium">1</span></sup>  Chunting Zhou<sup id="p2.5.5.5.5.5.5.5.6" class="ltx_sup"><span id="p2.5.5.5.5.5.5.5.6.1" class="ltx_text ltx_font_medium">1</span></sup></span></span></span>
<span id="p2.9.9.9.9.9" class="ltx_tr">
<span id="p2.9.9.9.9.9.4" class="ltx_td ltx_align_center"><span id="p2.9.9.9.9.9.4.4" class="ltx_text ltx_font_bold">Graham Neubig<sup id="p2.9.9.9.9.9.4.4.1" class="ltx_sup"><span id="p2.9.9.9.9.9.4.4.1.1" class="ltx_text ltx_font_medium">2</span></sup>  Xi Victoria Lin<sup id="p2.9.9.9.9.9.4.4.2" class="ltx_sup"><span id="p2.9.9.9.9.9.4.4.2.1" class="ltx_text ltx_font_medium">1</span></sup>  Wen-tau Yih<sup id="p2.9.9.9.9.9.4.4.3" class="ltx_sup"><span id="p2.9.9.9.9.9.4.4.3.1" class="ltx_text ltx_font_medium">1</span></sup>  Srinivasan Iyer<sup id="p2.9.9.9.9.9.4.4.4" class="ltx_sup"><span id="p2.9.9.9.9.9.4.4.4.1" class="ltx_text ltx_font_medium">1</span></sup></span></span></span>
<span id="p2.12.12.12.12.12" class="ltx_tr">
<span id="p2.12.12.12.12.12.3" class="ltx_td ltx_align_center"><sup id="p2.12.12.12.12.12.3.1" class="ltx_sup">1</sup>FAIR at Meta  <sup id="p2.12.12.12.12.12.3.2" class="ltx_sup">2</sup>Carnegie Mellon University  <sup id="p2.12.12.12.12.12.3.3" class="ltx_sup">3</sup>University of Washington</span></span>
<span id="p2.12.12.12.12.13.1" class="ltx_tr">
<span id="p2.12.12.12.12.13.1.1" class="ltx_td ltx_align_center"><span id="p2.12.12.12.12.13.1.1.1" class="ltx_text ltx_font_typewriter">{zhengbaj,gneubig}@cs.cmu.edu</span>  <span id="p2.12.12.12.12.13.1.1.2" class="ltx_text ltx_font_typewriter">{victorialin,scottyih,sviyer}@meta.com</span></span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<figure id="S0.F1" class="ltx_figure"><img src="/html/2402.12847/assets/x1.png" id="S0.F1.g1" class="ltx_graphics ltx_img_landscape" width="369" height="129" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Illustration of continued pre-training (first row), continued pre-training followed by instruction-tuning (second row), and pre-instruction-tuning before continued pre-training (last row), along with their accuracies on evaluation questions. Each right-pointing light-blue triangle indicates a training phase.</figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Large language models (LLMs) store vast amounts of factual knowledge in their parameters through large-scale pre-training, and this knowledge can be used to answer various questions such as “where is the world’s largest ice sheet located” <cite class="ltx_cite ltx_citemacro_cite">Brown et&nbsp;al. (<a href="#bib.bib5" title="" class="ltx_ref">2020</a>); OpenAI (<a href="#bib.bib34" title="" class="ltx_ref">2023</a>); Chowdhery et&nbsp;al. (<a href="#bib.bib10" title="" class="ltx_ref">2022</a>); Zhang et&nbsp;al. (<a href="#bib.bib60" title="" class="ltx_ref">2022</a>); Touvron et&nbsp;al. (<a href="#bib.bib51" title="" class="ltx_ref">2023a</a>, <a href="#bib.bib52" title="" class="ltx_ref">b</a>); Gemini Team (<a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite>.
However, this factual knowledge is static, meaning that it can become outdated as the world evolves, or prove insufficient when LLMs are used in specialized or private domains.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To keep LLMs up-to-date, it is common to continue pre-training on new documents to store knowledge in parameters, which allows LLMs to effectively answer queries that require up-to-date information <cite class="ltx_cite ltx_citemacro_cite">Jang et&nbsp;al. (<a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite>.
A widely held view is that the factual knowledge stored in parameters can be elicited through prompting <cite class="ltx_cite ltx_citemacro_cite">Brown et&nbsp;al. (<a href="#bib.bib5" title="" class="ltx_ref">2020</a>); Petroni et&nbsp;al. (<a href="#bib.bib37" title="" class="ltx_ref">2019</a>); Roberts et&nbsp;al. (<a href="#bib.bib42" title="" class="ltx_ref">2020</a>)</cite>, and that instruction-tuning (also known as supervised fine-tuning or alignment) makes this elicitation more effective <cite class="ltx_cite ltx_citemacro_cite">Sanh et&nbsp;al. (<a href="#bib.bib44" title="" class="ltx_ref">2022</a>); Wei et&nbsp;al. (<a href="#bib.bib56" title="" class="ltx_ref">2022</a>); Ouyang et&nbsp;al. (<a href="#bib.bib35" title="" class="ltx_ref">2022</a>)</cite>.
In the first part of this paper (<a href="#S4" title="4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">§&nbsp;4</span></a>), we conduct extensive experiments using Llama-2 <cite class="ltx_cite ltx_citemacro_cite">Touvron et&nbsp;al. (<a href="#bib.bib52" title="" class="ltx_ref">2023b</a>)</cite> to answer the following question: <em id="S1.p2.1.1" class="ltx_emph ltx_font_italic">to what extent can we augment the knowledge stored in modern LLMs by continued pre-training on new documents, either with or without subsequent instruction-tuning</em>?
We find that, as we train LLMs repeatedly over documents to the extent that perplexity is minimized to one, the percentage of questions regarding those documents that LLMs answer correctly increases consistently to 27.6%.
Subsequent instruction-tuning further improves it to 30.3%, confirming that this widely used practice is useful to elicit more knowledge from LLMs.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>This capacity might be underestimated by previous works due to using relatively small LMs or randomly initialized transformers, or lack of exhaustive training or instruction-tuning <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib54" title="" class="ltx_ref">2021</a>); Hu et&nbsp;al. (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>); Zhu and Li (<a href="#bib.bib63" title="" class="ltx_ref">2023a</a>)</cite>.</span></span></span>
However, the amount of elicited knowledge is still limited, even though the perplexity of documents is minimized, a phenomenon we refer to as the “perplexity curse”.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Inspired by the “reversal curse” of <cite class="ltx_cite ltx_citemacro_citet">Berglund et&nbsp;al. (<a href="#bib.bib3" title="" class="ltx_ref">2023</a>)</cite>.</span></span></span></p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.2" class="ltx_p">In the second part of the paper (<a href="#S5" title="5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">§&nbsp;5</span></a>), we study methods to mitigate the perplexity curse by making LLMs more adept at absorbing knowledge from documents.
<cite class="ltx_cite ltx_citemacro_citet">Zhu and Li (<a href="#bib.bib63" title="" class="ltx_ref">2023a</a>)</cite> presented an intriguing finding that training a randomly initialized transformer from scratch on a mix of biographies and related questions resulted in strong generalization to new questions.
However, understanding the reasons behind this finding and exploring ways to practically apply it for absorbing knowledge from new documents requires further investigation.
We found that question-answer (QA) pairs are generally straightforward and easily digestible, while documents tend to be more complex and cluttered, often weaving many factual statements together in a more intricate manner.
Therefore, we hypothesize that <em id="S1.p3.2.1" class="ltx_emph ltx_font_italic">it is beneficial to deliberately expose LLMs to QA data before continued pre-training on documents so that the process of encoding knowledge from complex documents takes into account how this knowledge is accessed through questions</em>.
We refer to this as <span id="S1.p3.2.2" class="ltx_text ltx_font_bold">pre-instruction-tuning (PIT)</span> and conduct comprehensive experiments to benchmark different variations of this method.
As shown in <a href="#S0.F1" title="Figure 1 ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;1</span></a>, our best-performing variation starts with training exclusively on QA pairs (e.g., “who handled the editing of Oppenheimer”) to grasp how knowledge is accessed.
This is followed by training on a combination of these QA pairs and associated documents (e.g., “who handled the editing of Oppenheimer” and a document about “Oppenheimer”).
In this phase, LLMs enhance their ability to absorb knowledge from information-dense documents, building upon the QA pairs that they have already mastered.
To study continual knowledge acquisition, we build a dataset named <span id="S1.p3.2.3" class="ltx_text ltx_font_typewriter">Wiki2023</span>, which includes a collection of documents from Wikipedia that are relevant to the year 2023.
Comprehensive experiments on <span id="S1.p3.2.4" class="ltx_text ltx_font_typewriter">Wiki2023</span> demonstrate that after PIT, LLMs exhibit an enhanced ability to absorb knowledge from new documents (e.g., a document about “Barbie”).
Detailed ablation studies reveal that this ability primarily stems from prioritizing learning how to access knowledge over learning to encode knowledge from documents.
Overall, PIT significantly outperforms the standard instruction-tuning approach (<a href="#S5.SS1" title="5.1 Variants of Pre-instruction-tuning ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">§&nbsp;5.1</span></a> and <a href="#S5.SS2" title="5.2 Pre-instruction-tuning++ ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">§&nbsp;5.2</span></a>), improving QA accuracies by 17.8% on Llama-2 7B (30.3% <math id="S1.p3.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S1.p3.1.m1.1a"><mo stretchy="false" id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">\shortrightarrow</annotation></semantics></math> 48.1%) and 16.3% on Llama-2 70B (46.4% <math id="S1.p3.2.m2.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S1.p3.2.m2.1a"><mo stretchy="false" id="S1.p3.2.m2.1.1" xref="S1.p3.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S1.p3.2.m2.1b"><ci id="S1.p3.2.m2.1.1.cmml" xref="S1.p3.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.2.m2.1c">\shortrightarrow</annotation></semantics></math> 62.7%).
Moreover, PIT also enhances the ability to absorb knowledge from documents of a <em id="S1.p3.2.5" class="ltx_emph ltx_font_italic">different</em> domain, shedding light on the potential to scale this method up to a wider variety of documents and instructions for more robust generalization (<a href="#S5.SS4" title="5.4 Cross-domain Generalization ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">§&nbsp;5.4</span></a>).</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Building a Dataset to Study Continual Knowledge Acquisition</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">To assess the ability of LLMs to learn knowledge from new documents, it is essential to use a document corpus with minimal overlap with the original pre-training corpus.
This ensures that when an LLM correctly answers questions, we can confidently attribute this capability to its learning from the new documents, rather than encountering similar questions in its original pre-training corpus.
In this section, we describe a methodology for building such a corpus from Wikipedia.</p>
</div>
<figure id="S2.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S2.F2.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.12847/assets/x2.png" id="S2.F2.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="217" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S2.F2.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.12847/assets/x3.png" id="S2.F2.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="230" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>The <span id="S2.F2.7.1" class="ltx_text ltx_font_typewriter">Wiki2023</span> dataset. <span id="S2.F2.8.2" class="ltx_text ltx_font_bold">Top-right</span>: the number of documents and QA pairs; <span id="S2.F2.9.3" class="ltx_text ltx_font_bold">Top-left</span>: frequent keywords in questions; <span id="S2.F2.10.4" class="ltx_text ltx_font_bold">Bottom</span>: the distribution of token counts in documents, questions, and answers.</figcaption>
</figure>
<figure id="S2.F3" class="ltx_figure"><img src="/html/2402.12847/assets/x4.png" id="S2.F3.g1" class="ltx_graphics ltx_img_square" width="461" height="446" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>An example document about “Oppenheimer” and corresponding QA pairs from <span id="S2.F3.2.1" class="ltx_text ltx_font_typewriter">Wiki2023</span>. Tokens used for computing losses are highlighted in green.</figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Wiki2023 Document Corpus</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">In the following experiments (<a href="#S4" title="4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">§&nbsp;4</span></a> and <a href="#S5" title="5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">§&nbsp;5</span></a>), we use Llama-2 (7B and 70B) <cite class="ltx_cite ltx_citemacro_cite">Touvron et&nbsp;al. (<a href="#bib.bib52" title="" class="ltx_ref">2023b</a>)</cite> since it is one of the best-performing LLMs.
We use Wikipedia articles classified under the “2023” Category including topics from diverse domains such as films, arts, economics, politics, events, etc.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://en.wikipedia.org/wiki/Category:2023" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://en.wikipedia.org/wiki/Category:2023</a></span></span></span>
The likelihood that this factual information is not included in the original training corpus is supported by the low QA performance in <a href="#S4.T1" title="Table 1 ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;1</span></a> (9.5%/17.2% for 7B/70B).<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>It is important to note the difficulty in completely avoiding factual overlap between <span id="footnote4.1" class="ltx_text ltx_font_typewriter">Wiki2023</span> and the pre-training corpus of Llama-2.
For example, a film released in 2023 might have had information available before 2023.
Data duplication detection is an active research direction, which falls beyond the focus of this study.</span></span></span>
To accelerate the training process, we only use the first section of each article, which offers a thorough summary and contains many factual statements.
The number of collected documents and an example document about “Oppenheimer” can be found in <a href="#S2.F2" title="Figure 2 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;2</span></a> and <a href="#S2.F3" title="Figure 3 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;3</span></a>.
We refer to this as the <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_typewriter">Wiki2023</span> dataset.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Wiki2023 Question-answer Pairs</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">To collect QA pairs for either instruction-tuning or performance evaluation, we employ publicly available LLMs to generate diverse questions and their respective answers given the article as context, following the Prompt&nbsp;<a href="#S2.SS2" title="2.2 Wiki2023 Question-answer Pairs ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">§&nbsp;2.2</span></a>.
On average, 4.93 questions are generated for each article. <a href="#S2.F2" title="Figure 2 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;2</span></a> and <a href="#S2.F3" title="Figure 3 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;3</span></a> show the detailed statistics and example QA pairs about “Oppenheimer”, respectively.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<svg id="S2.SS2.p2.pic1" class="ltx_picture" height="223.85" overflow="visible" version="1.1" width="600"><g transform="translate(0,223.85) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.32 L 0 218.53 C 0 221.47 2.38 223.85 5.32 223.85 L 594.68 223.85 C 597.62 223.85 600 221.47 600 218.53 L 600 5.32 C 600 2.38 597.62 0 594.68 0 L 5.32 0 C 2.38 0 0 2.38 0 5.32 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.38 5.32 L 1.38 195.1 L 598.62 195.1 L 598.62 5.32 C 598.62 3.15 596.85 1.38 594.68 1.38 L 5.32 1.38 C 3.15 1.38 1.38 3.15 1.38 5.32 Z" style="stroke:none"></path></g><g fill="#666666" fill-opacity="1.0"><path d="M 1.38 196.49 L 1.38 218.53 C 1.38 220.71 3.15 222.47 5.32 222.47 L 594.68 222.47 C 596.85 222.47 598.62 220.71 598.62 218.53 L 598.62 196.49 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 203.4)"><foreignObject width="583.4" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FFFFFF">
<span id="S2.SS2.p2.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:421.6pt;">
<span id="S2.SS2.p2.pic1.1.1.1.1.1.1" class="ltx_p">Prompt 1: question-answer generation prompt</span>
</span></foreignObject></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 8.3 8.3)"><foreignObject width="583.4" height="179.88" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S2.SS2.p2.pic1.2.2.2.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:421.6pt;">
<span id="S2.SS2.p2.pic1.2.2.2.1.1.1" class="ltx_p">Given the following summary about the subject {topic}, generate a comprehensive list of questions and corresponding answers that cover all aspects. To make the question clear, always include {topic} in the question. Answers should be concise, consisting of a few short phrases separated by commas.</span>
<span id="S2.SS2.p2.pic1.2.2.2.1.1.2" class="ltx_p">Output in the following format:</span>
<span id="S2.SS2.p2.pic1.2.2.2.1.1.3" class="ltx_p">Q: an open-domain question about the subject {topic} (the subject {topic} should always be included)</span>
<span id="S2.SS2.p2.pic1.2.2.2.1.1.4" class="ltx_p">A: phrase1, phrase2, …</span>
<span id="S2.SS2.p2.pic1.2.2.2.1.1.5" class="ltx_p">Summary:</span>
<span id="S2.SS2.p2.pic1.2.2.2.1.1.6" class="ltx_p">{summary}</span>
</span></foreignObject></g></g></svg>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Splits</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Among all domains, we select the film domain for evaluation and randomly select 256 articles as the test split (<span id="S2.SS3.p1.1.1" class="ltx_text ltx_font_typewriter">Wiki2023-film-test</span>).
We continually train LLMs on documents from the test split (<span id="S2.SS3.p1.1.2" class="ltx_text ltx_font_typewriter">Wiki2023-film-test-doc</span>), and assess their performance based on the accuracy of corresponding questions (<span id="S2.SS3.p1.1.3" class="ltx_text ltx_font_typewriter">Wiki2023-film-test-QA</span>).
The remaining 1720 articles and corresponding QA pairs (<span id="S2.SS3.p1.1.4" class="ltx_text ltx_font_typewriter">Wiki2023-film-train</span>) will be used to study different training strategies, which corresponds to the in-domain setting in <a href="#S2.F2" title="Figure 2 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;2</span></a>.
We also train on other domains before evaluation on the film domain to study the effectiveness of different methods across domains, which corresponds to the cross-domain setting in <a href="#S2.F2" title="Figure 2 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;2</span></a>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Settings</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Objectives</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.2" class="ltx_p">When training on documents, we prepend a &lt;bos&gt; token and compute the standard next-token prediction loss by averaging over all tokens in the document: <math id="S3.SS1.p1.1.m1.2" class="ltx_Math" alttext="L_{\bm{d}}=-\sum_{t}{\log P(\bm{d}_{t}|\bm{d}_{<t})}/|\bm{d}|" display="inline"><semantics id="S3.SS1.p1.1.m1.2a"><mrow id="S3.SS1.p1.1.m1.2.2" xref="S3.SS1.p1.1.m1.2.2.cmml"><msub id="S3.SS1.p1.1.m1.2.2.3" xref="S3.SS1.p1.1.m1.2.2.3.cmml"><mi id="S3.SS1.p1.1.m1.2.2.3.2" xref="S3.SS1.p1.1.m1.2.2.3.2.cmml">L</mi><mi id="S3.SS1.p1.1.m1.2.2.3.3" xref="S3.SS1.p1.1.m1.2.2.3.3.cmml">𝒅</mi></msub><mo id="S3.SS1.p1.1.m1.2.2.2" xref="S3.SS1.p1.1.m1.2.2.2.cmml">=</mo><mrow id="S3.SS1.p1.1.m1.2.2.1" xref="S3.SS1.p1.1.m1.2.2.1.cmml"><mo id="S3.SS1.p1.1.m1.2.2.1a" xref="S3.SS1.p1.1.m1.2.2.1.cmml">−</mo><mrow id="S3.SS1.p1.1.m1.2.2.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.cmml"><msub id="S3.SS1.p1.1.m1.2.2.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.2.cmml"><mo id="S3.SS1.p1.1.m1.2.2.1.1.2.2" xref="S3.SS1.p1.1.m1.2.2.1.1.2.2.cmml">∑</mo><mi id="S3.SS1.p1.1.m1.2.2.1.1.2.3" xref="S3.SS1.p1.1.m1.2.2.1.1.2.3.cmml">t</mi></msub><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.cmml"><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.cmml"><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3a" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.cmml">⁡</mo><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml"><msub id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.2.cmml">𝒅</mi><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.2.cmml">𝒅</mi><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.2.cmml"></mi><mo id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.1.cmml">&lt;</mo><mi id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.3.cmml">t</mi></mrow></msub></mrow><mo stretchy="false" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.3" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS1.p1.1.m1.2.2.1.1.1.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.2.cmml">/</mo><mrow id="S3.SS1.p1.1.m1.2.2.1.1.1.3.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3.1.cmml"><mo stretchy="false" id="S3.SS1.p1.1.m1.2.2.1.1.1.3.2.1" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3.1.1.cmml">|</mo><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">𝒅</mi><mo stretchy="false" id="S3.SS1.p1.1.m1.2.2.1.1.1.3.2.2" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3.1.1.cmml">|</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.2b"><apply id="S3.SS1.p1.1.m1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2"><eq id="S3.SS1.p1.1.m1.2.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.2"></eq><apply id="S3.SS1.p1.1.m1.2.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.3.2">𝐿</ci><ci id="S3.SS1.p1.1.m1.2.2.3.3.cmml" xref="S3.SS1.p1.1.m1.2.2.3.3">𝒅</ci></apply><apply id="S3.SS1.p1.1.m1.2.2.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1"><minus id="S3.SS1.p1.1.m1.2.2.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1"></minus><apply id="S3.SS1.p1.1.m1.2.2.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1"><apply id="S3.SS1.p1.1.m1.2.2.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.2.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.2">subscript</csymbol><sum id="S3.SS1.p1.1.m1.2.2.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.2.2"></sum><ci id="S3.SS1.p1.1.m1.2.2.1.1.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.2.3">𝑡</ci></apply><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1"><divide id="S3.SS1.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.2"></divide><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1"><times id="S3.SS1.p1.1.m1.2.2.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.2"></times><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3"><log id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.1"></log><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.3.2">𝑃</ci></apply><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.2">𝒅</ci><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.2">𝒅</ci><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3"><lt id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.1"></lt><csymbol cd="latexml" id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.2">absent</csymbol><ci id="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.1.1.1.1.3.3.3">𝑡</ci></apply></apply></apply></apply><apply id="S3.SS1.p1.1.m1.2.2.1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3.2"><abs id="S3.SS1.p1.1.m1.2.2.1.1.1.3.1.1.cmml" xref="S3.SS1.p1.1.m1.2.2.1.1.1.3.2.1"></abs><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">𝒅</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.2c">L_{\bm{d}}=-\sum_{t}{\log P(\bm{d}_{t}|\bm{d}_{&lt;t})}/|\bm{d}|</annotation></semantics></math>.<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>We do not append a ¡eos¿ token at the end of documents because we only use the first section, which does not signify the conclusion of the entire article.</span></span></span>
When training on QA pairs, we compute the average negative log-likelihood loss only on tokens in the answer given the question as the prefix: <math id="S3.SS1.p1.2.m2.3" class="ltx_Math" alttext="L_{\bm{a}}=-\sum_{t}{\log P(\bm{a}_{t}|\bm{q},\bm{a}_{<t})}/|\bm{a}|" display="inline"><semantics id="S3.SS1.p1.2.m2.3a"><mrow id="S3.SS1.p1.2.m2.3.3" xref="S3.SS1.p1.2.m2.3.3.cmml"><msub id="S3.SS1.p1.2.m2.3.3.3" xref="S3.SS1.p1.2.m2.3.3.3.cmml"><mi id="S3.SS1.p1.2.m2.3.3.3.2" xref="S3.SS1.p1.2.m2.3.3.3.2.cmml">L</mi><mi id="S3.SS1.p1.2.m2.3.3.3.3" xref="S3.SS1.p1.2.m2.3.3.3.3.cmml">𝒂</mi></msub><mo id="S3.SS1.p1.2.m2.3.3.2" xref="S3.SS1.p1.2.m2.3.3.2.cmml">=</mo><mrow id="S3.SS1.p1.2.m2.3.3.1" xref="S3.SS1.p1.2.m2.3.3.1.cmml"><mo id="S3.SS1.p1.2.m2.3.3.1a" xref="S3.SS1.p1.2.m2.3.3.1.cmml">−</mo><mrow id="S3.SS1.p1.2.m2.3.3.1.1" xref="S3.SS1.p1.2.m2.3.3.1.1.cmml"><msub id="S3.SS1.p1.2.m2.3.3.1.1.2" xref="S3.SS1.p1.2.m2.3.3.1.1.2.cmml"><mo id="S3.SS1.p1.2.m2.3.3.1.1.2.2" xref="S3.SS1.p1.2.m2.3.3.1.1.2.2.cmml">∑</mo><mi id="S3.SS1.p1.2.m2.3.3.1.1.2.3" xref="S3.SS1.p1.2.m2.3.3.1.1.2.3.cmml">t</mi></msub><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.cmml"><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.cmml"><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1.1.3" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.3a" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.cmml">⁡</mo><mi id="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.2.cmml">P</mi></mrow><mo lspace="0em" rspace="0em" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.2.cmml">​</mo><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.cmml"><msub id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.2.cmml">𝒂</mi><mi id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.3" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo fence="false" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.2.cmml">|</mo><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">𝒒</mi><mo id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.2.cmml">,</mo><msub id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml">𝒂</mi><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.2.cmml"></mi><mo id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.1.cmml">&lt;</mo><mi id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.3.cmml">t</mi></mrow></msub></mrow></mrow><mo stretchy="false" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.3" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.SS1.p1.2.m2.3.3.1.1.1.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.2.cmml">/</mo><mrow id="S3.SS1.p1.2.m2.3.3.1.1.1.3.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.3.1.cmml"><mo stretchy="false" id="S3.SS1.p1.2.m2.3.3.1.1.1.3.2.1" xref="S3.SS1.p1.2.m2.3.3.1.1.1.3.1.1.cmml">|</mo><mi id="S3.SS1.p1.2.m2.2.2" xref="S3.SS1.p1.2.m2.2.2.cmml">𝒂</mi><mo stretchy="false" id="S3.SS1.p1.2.m2.3.3.1.1.1.3.2.2" xref="S3.SS1.p1.2.m2.3.3.1.1.1.3.1.1.cmml">|</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.3b"><apply id="S3.SS1.p1.2.m2.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3"><eq id="S3.SS1.p1.2.m2.3.3.2.cmml" xref="S3.SS1.p1.2.m2.3.3.2"></eq><apply id="S3.SS1.p1.2.m2.3.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.3.1.cmml" xref="S3.SS1.p1.2.m2.3.3.3">subscript</csymbol><ci id="S3.SS1.p1.2.m2.3.3.3.2.cmml" xref="S3.SS1.p1.2.m2.3.3.3.2">𝐿</ci><ci id="S3.SS1.p1.2.m2.3.3.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3.3.3">𝒂</ci></apply><apply id="S3.SS1.p1.2.m2.3.3.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1"><minus id="S3.SS1.p1.2.m2.3.3.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1"></minus><apply id="S3.SS1.p1.2.m2.3.3.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1"><apply id="S3.SS1.p1.2.m2.3.3.1.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.1.1.2.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.2">subscript</csymbol><sum id="S3.SS1.p1.2.m2.3.3.1.1.2.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.2.2"></sum><ci id="S3.SS1.p1.2.m2.3.3.1.1.2.3.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.2.3">𝑡</ci></apply><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1"><divide id="S3.SS1.p1.2.m2.3.3.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.2"></divide><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1"><times id="S3.SS1.p1.2.m2.3.3.1.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.2"></times><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.3"><log id="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.1"></log><ci id="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.3.2">𝑃</ci></apply><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.2">conditional</csymbol><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.2">𝒂</ci><ci id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.3.3">𝑡</ci></apply><list id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">𝒒</ci><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.2">𝒂</ci><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3"><lt id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.1"></lt><csymbol cd="latexml" id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.2">absent</csymbol><ci id="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.1.1.1.1.1.1.1.3.3">𝑡</ci></apply></apply></list></apply></apply><apply id="S3.SS1.p1.2.m2.3.3.1.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.3.2"><abs id="S3.SS1.p1.2.m2.3.3.1.1.1.3.1.1.cmml" xref="S3.SS1.p1.2.m2.3.3.1.1.1.3.2.1"></abs><ci id="S3.SS1.p1.2.m2.2.2.cmml" xref="S3.SS1.p1.2.m2.2.2">𝒂</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.3c">L_{\bm{a}}=-\sum_{t}{\log P(\bm{a}_{t}|\bm{q},\bm{a}_{&lt;t})}/|\bm{a}|</annotation></semantics></math>.
<a href="#S2.F3" title="Figure 3 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;3</span></a> presents an example document alongside QA pairs, where tokens used for computing losses are highlighted.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Hyperparameters</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.2" class="ltx_p">We use AdamW <cite class="ltx_cite ltx_citemacro_cite">Loshchilov and Hutter (<a href="#bib.bib30" title="" class="ltx_ref">2019</a>)</cite> with <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\beta_{1}=0.9" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mrow id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><msub id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2.2" xref="S3.SS2.p1.1.m1.1.1.2.2.cmml">β</mi><mn id="S3.SS2.p1.1.m1.1.1.2.3" xref="S3.SS2.p1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S3.SS2.p1.1.m1.1.1.1" xref="S3.SS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><eq id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1.1"></eq><apply id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.2.1.cmml" xref="S3.SS2.p1.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2.2">𝛽</ci><cn type="integer" id="S3.SS2.p1.1.m1.1.1.2.3.cmml" xref="S3.SS2.p1.1.m1.1.1.2.3">1</cn></apply><cn type="float" id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\beta_{1}=0.9</annotation></semantics></math>, <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="\beta_{2}=0.95" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mrow id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><msub id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2.2" xref="S3.SS2.p1.2.m2.1.1.2.2.cmml">β</mi><mn id="S3.SS2.p1.2.m2.1.1.2.3" xref="S3.SS2.p1.2.m2.1.1.2.3.cmml">2</mn></msub><mo id="S3.SS2.p1.2.m2.1.1.1" xref="S3.SS2.p1.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">0.95</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><eq id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1.1"></eq><apply id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2.2">𝛽</ci><cn type="integer" id="S3.SS2.p1.2.m2.1.1.2.3.cmml" xref="S3.SS2.p1.2.m2.1.1.2.3">2</cn></apply><cn type="float" id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3">0.95</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\beta_{2}=0.95</annotation></semantics></math>, and a weight decay of 0.1.
We decay the learning rate to 10% of its initial value using a cosine scheduler without warm-up.
When pre-training on documents, we use a batch size of 256 documents and an initial learning rate of 3e-5.
During instruction-tuning on QA pairs, we use the same batch size of 256 QA pairs, but opt for a reduced initial learning rate of 5e-6 because the number of tokens in a single batch used for computing losses is lower.
The number of epochs varies depending on the setting and is detailed in the corresponding sections.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Evaluation Metrics</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">At inference time, we use greedy decoding to generate answers given questions as context, following the format in <a href="#S2.F3" title="Figure 3 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;3</span></a>.
To evaluate the original Llama-2, we add 5 QA pairs as in-context exemplars to make sure it follows the QA format.
Since most questions are simple factoid questions and most answers are relatively short, we use exact match (EM) as our primary metric <cite class="ltx_cite ltx_citemacro_cite">Kwiatkowski et&nbsp;al. (<a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite>, which measures whether the model’s output matches the gold answer exactly after normalization (e.g., remove articles and punctuations).
To assess longer responses and accommodate minor lexical differences, we also report answer recall, which assesses if the gold answer appears in the model’s output, and ROUGE-L, which measures the longest common subsequence between the model’s output and the gold answer.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2402.12847/assets/x5.png" id="S3.F4.g1" class="ltx_graphics ltx_img_landscape" width="461" height="145" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Different experimental settings examined in this paper. Each row represents a different experimental setting with a unique name and number, and each vertical section highlighted by a right-pointing light-blue triangle indicates a training phase. Models are assessed on test QA across all settings. Whenever multiple datasets are enclosed within a dashed square, they are mixed together during the training process.</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning?</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Factual knowledge stored in the parameters of LLMs can be accessed and applied to answering questions through prompting without additional training <cite class="ltx_cite ltx_citemacro_cite">Brown et&nbsp;al. (<a href="#bib.bib5" title="" class="ltx_ref">2020</a>); Petroni et&nbsp;al. (<a href="#bib.bib37" title="" class="ltx_ref">2019</a>); Jiang et&nbsp;al. (<a href="#bib.bib22" title="" class="ltx_ref">2020</a>); Roberts et&nbsp;al. (<a href="#bib.bib42" title="" class="ltx_ref">2020</a>)</cite>.
With additional instruction-tuning (also known as supervised fine-tuning) on high-quality data <cite class="ltx_cite ltx_citemacro_cite">Sanh et&nbsp;al. (<a href="#bib.bib44" title="" class="ltx_ref">2022</a>); Wei et&nbsp;al. (<a href="#bib.bib56" title="" class="ltx_ref">2022</a>)</cite>, knowledge seems to be more effectively elicited from LLMs.
However, when LLMs correctly answer a question, the source of the knowledge is unclear due to the diversity of the pre-training data.
For instance, when answering the question “where is the world’s largest ice sheet located”, do LLMs derive their response by recalling and generalizing information from a seen document about the Antarctic ice sheet, or do they merely repeat answers from similar questions encountered in the training data?
This distinction is crucial, as the former scenario implies an ability to comprehend documents and effectively store knowledge within parameters in a way that can be elicited later, whereas the latter is mere rote memorization.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Several works have studied this problem and the predominant finding is that LMs struggle to answer questions about documents they have been trained on <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib54" title="" class="ltx_ref">2021</a>); Zhu and Li (<a href="#bib.bib63" title="" class="ltx_ref">2023a</a>)</cite>.
It is important to note, however, that these experiments were mainly conducted using relatively small LMs such as BART, T5, or GPT-2 <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib54" title="" class="ltx_ref">2021</a>); Jang et&nbsp;al. (<a href="#bib.bib20" title="" class="ltx_ref">2022</a>); Hu et&nbsp;al. (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>)</cite>, using randomly initialized transformers <cite class="ltx_cite ltx_citemacro_cite">Zhu and Li (<a href="#bib.bib63" title="" class="ltx_ref">2023a</a>)</cite>, or without instruction-tuning <cite class="ltx_cite ltx_citemacro_cite">Ovadia et&nbsp;al. (<a href="#bib.bib36" title="" class="ltx_ref">2023</a>)</cite>.
This makes us wonder <em id="S4.p2.1.1" class="ltx_emph ltx_font_italic">what are the actual limits of modern LLMs to absorb knowledge from new documents and answer questions about them using the standard continued pre-training followed by instruction-tuning recipe</em>.
In this section, we run extensive experiments using Llama-2 7B and 70B on <span id="S4.p2.1.2" class="ltx_text ltx_font_typewriter">Wiki2023-film</span> to test their limits.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Vanilla Continued Pre-training and Instruction-tuning</h3>

<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Experimental settings</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">We experiment with two standard settings and assess their performance by answering associated questions.</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">Continued pre-training: train on test documents without instruction-tuning (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➀).<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>We found that LLMs struggle to adhere to the QA format after training on raw documents for multiple epochs. Therefore, we include a small set of QA pairs (64) during continued pre-training to prevent LLMs from forgetting the QA format.</span></span></span></p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">Standard instruction-tuning: train on both train and test documents before instruction-tuning on train QA pairs (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➁).</p>
</div>
</li>
</ul>
<p id="S4.SS1.SSS0.Px1.p1.2" class="ltx_p">We perform instruction-tuning for a single epoch since more epochs usually result in diminished performance.
For training on documents, we opt for multiple epochs (10/5 for a 7B/70B model), which allows for effective knowledge acquisition and remains affordable for corpora of moderate sizes.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Experimental results</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">As shown in <a href="#S4.T1" title="Table 1 ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;1</span></a>, the relatively low performance of the original Llama-2 model (9.5%/17.2% for 7B/70B) indicates that most knowledge in the test documents is not included in the original pre-training corpus.
After continued pre-training on documents, performances increase to 27.2%/41.7%, indicating that LLMs can absorb some amount of knowledge.
Instruction-tuning further increases the performance to 30.3%/46.4%, confirming the effectiveness of this standard recipe.
This observation is different from <cite class="ltx_cite ltx_citemacro_citet">Zhu and Li (<a href="#bib.bib63" title="" class="ltx_ref">2023a</a>)</cite>, which demonstrates that instruction-tuning after pre-training is ineffective on a randomly initialized GPT-2-like transformer.
The difference probably arises because Llama-2, through its pre-training on diverse corpora comprising raw documents and QA data, has developed a certain degree of proficiency in extracting knowledge from its parameters via questions.
We also report the performance where the corresponding document is directly provided to Llama-2 as context (“open-book w/ doc” in <a href="#S4.T1" title="Table 1 ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;1</span></a>).
The significant gap between closed-book and open-book settings suggests that retrieving knowledge from the parameters of LLMs is still challenging.</p>
</div>
<figure id="S4.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.12847/assets/x6.png" id="S4.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="312" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Training dynamics w/ (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➁) and w/o instruction-tuning (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➀). Reduction in perplexity consistently leads to improvement in QA accuracy, indicating that factual knowledge acquisition necessitates exhaustive loss minimization.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2402.12847/assets/x7.png" id="S4.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="285" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span>Training dynamics with different learning rates (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➀). After perplexity is minimized, larger learning rates usually lead to less overfitting to deceptive patterns in documents and better generalization when responding to questions.</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>We vary the number of epochs (<a href="#S4.F5.sf1" title="Figure 5(a) ‣ Figure 5 ‣ Experimental results ‣ 4.1 Vanilla Continued Pre-training and Instruction-tuning ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">5(a)</span></a>) and learning rate (<a href="#S4.F5.sf2" title="Figure 5(b) ‣ Figure 5 ‣ Experimental results ‣ 4.1 Vanilla Continued Pre-training and Instruction-tuning ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">5(b)</span></a>) during continued pre-training to study the training dynamics of Llama-2 7B. The left axis is <span id="S4.F5.5.1" class="ltx_text" style="color:#228B22;">QA accuracies</span> for test questions, measured by exact match. On the right axis, we display 2 metrics indicated by distinct colors: the <span id="S4.F5.6.2" class="ltx_text" style="color:#0000CD;">perplexity</span> of all tokens in the documents, and the <span id="S4.F5.7.3" class="ltx_text" style="color:#B22222;">knowledge retention accuracy</span>, measured by QA accuracy on the Natural Questions dataset. We highlight situations where <span id="S4.F5.8.4" class="ltx_text" style="color:#00008B;background-color:#F2F2FF;">perplexity of all document tokens is minimized to 1</span>.</figcaption>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Analyzing the Training Dynamics: Perplexity and Generalization</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">How does lower perplexity of documents lead to generalization to answering related questions?
We vary the number of epochs (<a href="#S4.F5.sf1" title="Figure 5(a) ‣ Figure 5 ‣ Experimental results ‣ 4.1 Vanilla Continued Pre-training and Instruction-tuning ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">5(a)</span></a>) and learning rate (<a href="#S4.F5.sf2" title="Figure 5(b) ‣ Figure 5 ‣ Experimental results ‣ 4.1 Vanilla Continued Pre-training and Instruction-tuning ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">5(b)</span></a>) for continued pre-training on documents and monitor three metrics to study the training dynamics.<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>Since we always decay the learning rate to 10% of its initial value, training for more epochs is not the same as continuing training from a checkpoint obtained after fewer epochs.</span></span></span></p>
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p id="S4.I2.i1.p1.1" class="ltx_p"><span id="S4.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Knowledge acquisition</span> QA accuracies on test questions measured by exact match.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p id="S4.I2.i2.p1.1" class="ltx_p"><span id="S4.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Perplexity of documents</span> We compute perplexity (PPL) on all tokens within the documents.</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p id="S4.I2.i3.p1.1" class="ltx_p"><span id="S4.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Knowledge retention</span> We approximate the retention of accumulated knowledge during pre-training by assessing the QA accuracy on the Natural Questions (NQ) dataset. NQ was released in 2019, and primarily includes questions based on Wikipedia articles from that time.</p>
</div>
</li>
</ul>
</div>
<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.1.2.1" class="ltx_tr">
<th id="S4.T1.1.2.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<td id="S4.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3"><span id="S4.T1.1.2.1.2.1" class="ltx_text ltx_font_bold">Llama-2 7B</span></td>
<td id="S4.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S4.T1.1.2.1.3.1" class="ltx_text ltx_font_bold">Llama-2 70B</span></td>
</tr>
<tr id="S4.T1.1.3.2" class="ltx_tr">
<th id="S4.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.1.3.2.1.1" class="ltx_text ltx_font_bold">Settings</span></th>
<td id="S4.T1.1.3.2.2" class="ltx_td ltx_nopad_l ltx_align_right"><span id="S4.T1.1.3.2.2.1" class="ltx_text ltx_font_bold">EM</span></td>
<td id="S4.T1.1.3.2.3" class="ltx_td ltx_nopad_l ltx_align_right"><span id="S4.T1.1.3.2.3.1" class="ltx_text ltx_font_bold">Rec.</span></td>
<td id="S4.T1.1.3.2.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r"><span id="S4.T1.1.3.2.4.1" class="ltx_text ltx_font_bold">R-L</span></td>
<td id="S4.T1.1.3.2.5" class="ltx_td ltx_align_right"><span id="S4.T1.1.3.2.5.1" class="ltx_text ltx_font_bold">EM</span></td>
<td id="S4.T1.1.3.2.6" class="ltx_td ltx_nopad_l ltx_align_right"><span id="S4.T1.1.3.2.6.1" class="ltx_text ltx_font_bold">Rec.</span></td>
<td id="S4.T1.1.3.2.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right"><span id="S4.T1.1.3.2.7.1" class="ltx_text ltx_font_bold">R-L</span></td>
</tr>
<tr id="S4.T1.1.4.3" class="ltx_tr">
<th id="S4.T1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="7"><em id="S4.T1.1.4.3.1.1" class="ltx_emph ltx_font_italic">closed- and open-book performance before training</em></th>
</tr>
<tr id="S4.T1.1.5.4" class="ltx_tr">
<th id="S4.T1.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">closed-book</th>
<td id="S4.T1.1.5.4.2" class="ltx_td ltx_nopad_l ltx_align_right">9.5</td>
<td id="S4.T1.1.5.4.3" class="ltx_td ltx_nopad_l ltx_align_right">10.0</td>
<td id="S4.T1.1.5.4.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">21.2</td>
<td id="S4.T1.1.5.4.5" class="ltx_td ltx_align_right">17.2</td>
<td id="S4.T1.1.5.4.6" class="ltx_td ltx_nopad_l ltx_align_right">18.1</td>
<td id="S4.T1.1.5.4.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">31.4</td>
</tr>
<tr id="S4.T1.1.6.5" class="ltx_tr">
<th id="S4.T1.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">open-book w/ doc</th>
<td id="S4.T1.1.6.5.2" class="ltx_td ltx_nopad_l ltx_align_right">72.2</td>
<td id="S4.T1.1.6.5.3" class="ltx_td ltx_nopad_l ltx_align_right">75.4</td>
<td id="S4.T1.1.6.5.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">91.5</td>
<td id="S4.T1.1.6.5.5" class="ltx_td ltx_align_right">78.2</td>
<td id="S4.T1.1.6.5.6" class="ltx_td ltx_nopad_l ltx_align_right">80.6</td>
<td id="S4.T1.1.6.5.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">94.9</td>
</tr>
<tr id="S4.T1.1.7.6" class="ltx_tr">
<th id="S4.T1.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="7"><em id="S4.T1.1.7.6.1.1" class="ltx_emph ltx_font_italic">closed-book performance w/ standard methods</em></th>
</tr>
<tr id="S4.T1.1.8.7" class="ltx_tr">
<th id="S4.T1.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">cont. pre-training  ➀</th>
<td id="S4.T1.1.8.7.2" class="ltx_td ltx_nopad_l ltx_align_right">27.6</td>
<td id="S4.T1.1.8.7.3" class="ltx_td ltx_nopad_l ltx_align_right">31.6</td>
<td id="S4.T1.1.8.7.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">43.8</td>
<td id="S4.T1.1.8.7.5" class="ltx_td ltx_align_right">41.7</td>
<td id="S4.T1.1.8.7.6" class="ltx_td ltx_nopad_l ltx_align_right">45.8</td>
<td id="S4.T1.1.8.7.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">60.2</td>
</tr>
<tr id="S4.T1.1.9.8" class="ltx_tr">
<th id="S4.T1.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">&nbsp;&nbsp; +instruction-tuning  ➁</th>
<td id="S4.T1.1.9.8.2" class="ltx_td ltx_nopad_l ltx_align_right">30.3</td>
<td id="S4.T1.1.9.8.3" class="ltx_td ltx_nopad_l ltx_align_right">34.7</td>
<td id="S4.T1.1.9.8.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">47.4</td>
<td id="S4.T1.1.9.8.5" class="ltx_td ltx_align_right">46.4</td>
<td id="S4.T1.1.9.8.6" class="ltx_td ltx_nopad_l ltx_align_right">50.9</td>
<td id="S4.T1.1.9.8.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">64.1</td>
</tr>
<tr id="S4.T1.1.10.9" class="ltx_tr">
<th id="S4.T1.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">mix all data  ➃</th>
<td id="S4.T1.1.10.9.2" class="ltx_td ltx_nopad_l ltx_align_right">39.4</td>
<td id="S4.T1.1.10.9.3" class="ltx_td ltx_nopad_l ltx_align_right">44.6</td>
<td id="S4.T1.1.10.9.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">56.7</td>
<td id="S4.T1.1.10.9.5" class="ltx_td ltx_align_right">57.1</td>
<td id="S4.T1.1.10.9.6" class="ltx_td ltx_nopad_l ltx_align_right">63.4</td>
<td id="S4.T1.1.10.9.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">72.4</td>
</tr>
<tr id="S4.T1.1.11.10" class="ltx_tr">
<th id="S4.T1.1.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="7"><em id="S4.T1.1.11.10.1.1" class="ltx_emph ltx_font_italic">closed-book performance w/ pre-instruction-tuning (PIT)</em></th>
</tr>
<tr id="S4.T1.1.12.11" class="ltx_tr">
<th id="S4.T1.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PIT (QA only)  ➄</th>
<td id="S4.T1.1.12.11.2" class="ltx_td ltx_nopad_l ltx_align_right">28.6</td>
<td id="S4.T1.1.12.11.3" class="ltx_td ltx_nopad_l ltx_align_right">32.7</td>
<td id="S4.T1.1.12.11.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">45.2</td>
<td id="S4.T1.1.12.11.5" class="ltx_td ltx_align_right">49.7</td>
<td id="S4.T1.1.12.11.6" class="ltx_td ltx_nopad_l ltx_align_right">53.7</td>
<td id="S4.T1.1.12.11.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">67.9</td>
</tr>
<tr id="S4.T1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">PIT (QA <math id="S4.T1.1.1.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S4.T1.1.1.1.m1.1a"><mo stretchy="false" id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">\shortrightarrow</annotation></semantics></math> docs)  ➅</th>
<td id="S4.T1.1.1.2" class="ltx_td ltx_nopad_l ltx_align_right">32.5</td>
<td id="S4.T1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_right">37.2</td>
<td id="S4.T1.1.1.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">49.0</td>
<td id="S4.T1.1.1.5" class="ltx_td ltx_align_right">54.6</td>
<td id="S4.T1.1.1.6" class="ltx_td ltx_nopad_l ltx_align_right">60.0</td>
<td id="S4.T1.1.1.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right">73.8</td>
</tr>
<tr id="S4.T1.1.13.12" class="ltx_tr">
<th id="S4.T1.1.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">PIT  ➆</th>
<td id="S4.T1.1.13.12.2" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb"><span id="S4.T1.1.13.12.2.1" class="ltx_text ltx_font_bold">45.4</span></td>
<td id="S4.T1.1.13.12.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb"><span id="S4.T1.1.13.12.3.1" class="ltx_text ltx_font_bold">51.2</span></td>
<td id="S4.T1.1.13.12.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb ltx_border_r"><span id="S4.T1.1.13.12.4.1" class="ltx_text ltx_font_bold">63.2</span></td>
<td id="S4.T1.1.13.12.5" class="ltx_td ltx_align_right ltx_border_bb"><span id="S4.T1.1.13.12.5.1" class="ltx_text ltx_font_bold">62.7</span></td>
<td id="S4.T1.1.13.12.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb"><span id="S4.T1.1.13.12.6.1" class="ltx_text ltx_font_bold">68.6</span></td>
<td id="S4.T1.1.13.12.7" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_right ltx_border_bb"><span id="S4.T1.1.13.12.7.1" class="ltx_text ltx_font_bold">78.8</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison of QA performance (%) between standard instruction-tuning and pre-instruction-tuning. The best results are in bold. Rec. is short for answer recall, and R-L refers to ROUGE-L.</figcaption>
</figure>
<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Experiment results</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<ul id="S4.I3" class="ltx_itemize">
<li id="S4.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i1.p1" class="ltx_para">
<p id="S4.I3.i1.p1.1" class="ltx_p">As shown in <a href="#S4.F5.sf1" title="Figure 5(a) ‣ Figure 5 ‣ Experimental results ‣ 4.1 Vanilla Continued Pre-training and Instruction-tuning ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">5(a)</span></a>, QA accuracy consistently improves as perplexity approaches one, indicating that <em id="S4.I3.i1.p1.1.1" class="ltx_emph ltx_font_italic">factual knowledge learning necessitates exhaustive loss minimization over all tokens</em>.
This contrasts with learning general skills, where overly optimizing leads to overfitting.</p>
</div>
</li>
<li id="S4.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i2.p1" class="ltx_para">
<p id="S4.I3.i2.p1.1" class="ltx_p">As shown in <a href="#S4.F5.sf1" title="Figure 5(a) ‣ Figure 5 ‣ Experimental results ‣ 4.1 Vanilla Continued Pre-training and Instruction-tuning ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">5(a)</span></a> and <a href="#S4.F5.sf2" title="Figure 5(b) ‣ Figure 5 ‣ Experimental results ‣ 4.1 Vanilla Continued Pre-training and Instruction-tuning ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">5(b)</span></a>, among all cases where LLMs have minimized perplexity on documents, cases trained with more epochs or larger learning rates typically exhibit superior QA performance. We hypothesize that <em id="S4.I3.i2.p1.1.1" class="ltx_emph ltx_font_italic">more aggressive training leads to less overfitting to deceptive patterns in documents and better generalization when responding to questions</em>.</p>
</div>
</li>
</ul>
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">In summary, lower perplexity does lead to stronger generalization when responding to questions, but it comes at the expense of forgetting previously acquired knowledge.
</p>
</div>
<figure id="S4.T2" class="ltx_table">
<table id="S4.T2.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.9.10.1" class="ltx_tr">
<th id="S4.T2.9.10.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt"><span id="S4.T2.9.10.1.1.1" class="ltx_text ltx_font_bold">Setting names</span></th>
<th id="S4.T2.9.10.1.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_tt"><span id="S4.T2.9.10.1.2.1" class="ltx_text ltx_font_bold">Setting configurations</span></th>
<td id="S4.T2.9.10.1.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_tt"><span id="S4.T2.9.10.1.3.1" class="ltx_text ltx_font_bold">EM</span></td>
<td id="S4.T2.9.10.1.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_tt"><span id="S4.T2.9.10.1.4.1" class="ltx_text ltx_font_bold">Rec.</span></td>
<td id="S4.T2.9.10.1.5" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_tt"><span id="S4.T2.9.10.1.5.1" class="ltx_text ltx_font_bold">R-L</span></td>
</tr>
<tr id="S4.T2.9.11.2" class="ltx_tr">
<th id="S4.T2.9.11.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5"><em id="S4.T2.9.11.2.1.1" class="ltx_emph ltx_font_italic">baselines</em></th>
</tr>
<tr id="S4.T2.9.12.3" class="ltx_tr">
<th id="S4.T2.9.12.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">continued pre-training  ➀</th>
<th id="S4.T2.9.12.3.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">test doc</th>
<td id="S4.T2.9.12.3.3" class="ltx_td ltx_nopad_l ltx_align_right">27.6</td>
<td id="S4.T2.9.12.3.4" class="ltx_td ltx_nopad_l ltx_align_right">31.6</td>
<td id="S4.T2.9.12.3.5" class="ltx_td ltx_nopad_l ltx_align_right">43.8</td>
</tr>
<tr id="S4.T2.1.1" class="ltx_tr">
<th id="S4.T2.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">&nbsp;&nbsp; +instruction-tuning  ➁</th>
<th id="S4.T2.1.1.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">train doc + test doc <math id="S4.T2.1.1.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.1.1.1.m1.1a"><mo stretchy="false" id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.m1.1c">\shortrightarrow</annotation></semantics></math> train QA</th>
<td id="S4.T2.1.1.3" class="ltx_td ltx_nopad_l ltx_align_right">30.3</td>
<td id="S4.T2.1.1.4" class="ltx_td ltx_nopad_l ltx_align_right">34.7</td>
<td id="S4.T2.1.1.5" class="ltx_td ltx_nopad_l ltx_align_right">47.4</td>
</tr>
<tr id="S4.T2.2.2" class="ltx_tr">
<th id="S4.T2.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">&nbsp;&nbsp; +instruction-tuning (w/o forget)  ➂</th>
<th id="S4.T2.2.2.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">train doc + test doc <math id="S4.T2.2.2.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.2.2.1.m1.1a"><mo stretchy="false" id="S4.T2.2.2.1.m1.1.1" xref="S4.T2.2.2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.1.m1.1b"><ci id="S4.T2.2.2.1.m1.1.1.cmml" xref="S4.T2.2.2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.1.m1.1c">\shortrightarrow</annotation></semantics></math> train QA + test doc</th>
<td id="S4.T2.2.2.3" class="ltx_td ltx_nopad_l ltx_align_right">30.2</td>
<td id="S4.T2.2.2.4" class="ltx_td ltx_nopad_l ltx_align_right">34.1</td>
<td id="S4.T2.2.2.5" class="ltx_td ltx_nopad_l ltx_align_right">46.4</td>
</tr>
<tr id="S4.T2.3.3" class="ltx_tr">
<th id="S4.T2.3.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">&nbsp;&nbsp; +instruction-tuning (w/o train doc)</th>
<th id="S4.T2.3.3.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">test doc <math id="S4.T2.3.3.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.3.3.1.m1.1a"><mo stretchy="false" id="S4.T2.3.3.1.m1.1.1" xref="S4.T2.3.3.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.1.m1.1b"><ci id="S4.T2.3.3.1.m1.1.1.cmml" xref="S4.T2.3.3.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.1.m1.1c">\shortrightarrow</annotation></semantics></math> train QA</th>
<td id="S4.T2.3.3.3" class="ltx_td ltx_nopad_l ltx_align_right">27.1</td>
<td id="S4.T2.3.3.4" class="ltx_td ltx_nopad_l ltx_align_right">30.7</td>
<td id="S4.T2.3.3.5" class="ltx_td ltx_nopad_l ltx_align_right">42.3</td>
</tr>
<tr id="S4.T2.9.13.4" class="ltx_tr">
<th id="S4.T2.9.13.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">weighted continued pre-training</th>
<th id="S4.T2.9.13.4.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">test doc (weighted)</th>
<td id="S4.T2.9.13.4.3" class="ltx_td ltx_nopad_l ltx_align_right">27.7</td>
<td id="S4.T2.9.13.4.4" class="ltx_td ltx_nopad_l ltx_align_right">32.7</td>
<td id="S4.T2.9.13.4.5" class="ltx_td ltx_nopad_l ltx_align_right">43.3</td>
</tr>
<tr id="S4.T2.4.4" class="ltx_tr">
<th id="S4.T2.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">adapted continued pre-training</th>
<th id="S4.T2.4.4.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">train doc <math id="S4.T2.4.4.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.4.4.1.m1.1a"><mo stretchy="false" id="S4.T2.4.4.1.m1.1.1" xref="S4.T2.4.4.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.1.m1.1b"><ci id="S4.T2.4.4.1.m1.1.1.cmml" xref="S4.T2.4.4.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.1.m1.1c">\shortrightarrow</annotation></semantics></math> test doc</th>
<td id="S4.T2.4.4.3" class="ltx_td ltx_nopad_l ltx_align_right">26.9</td>
<td id="S4.T2.4.4.4" class="ltx_td ltx_nopad_l ltx_align_right">32.7</td>
<td id="S4.T2.4.4.5" class="ltx_td ltx_nopad_l ltx_align_right">44.2</td>
</tr>
<tr id="S4.T2.9.14.5" class="ltx_tr">
<th id="S4.T2.9.14.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">mix all data  ➃</th>
<th id="S4.T2.9.14.5.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row">train QA + train doc + test doc</th>
<td id="S4.T2.9.14.5.3" class="ltx_td ltx_nopad_l ltx_align_right">39.4</td>
<td id="S4.T2.9.14.5.4" class="ltx_td ltx_nopad_l ltx_align_right">44.6</td>
<td id="S4.T2.9.14.5.5" class="ltx_td ltx_nopad_l ltx_align_right">56.7</td>
</tr>
<tr id="S4.T2.9.15.6" class="ltx_tr">
<th id="S4.T2.9.15.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="5"><em id="S4.T2.9.15.6.1.1" class="ltx_emph ltx_font_italic">various pre-instruction-tuning (PIT) methods and ablation studies</em></th>
</tr>
<tr id="S4.T2.5.5" class="ltx_tr">
<th id="S4.T2.5.5.2" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T2.5.5.1" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.5.5.1.1" class="ltx_text" style="background-color:#F7FBFF;">train QA + train doc (3 epochs) <math id="S4.T2.5.5.1.1.m1.1" class="ltx_Math" style="background-color:#F7FBFF;" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.5.5.1.1.m1.1a"><mo mathbackground="#F7FBFF" stretchy="false" id="S4.T2.5.5.1.1.m1.1.1" xref="S4.T2.5.5.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.1.1.m1.1b"><ci id="S4.T2.5.5.1.1.m1.1.1.cmml" xref="S4.T2.5.5.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.1.1.m1.1c">\shortrightarrow</annotation></semantics></math> test doc</span></th>
<td id="S4.T2.5.5.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.5.5.3.1" class="ltx_text" style="background-color:#F7FBFF;">45.4</span></td>
<td id="S4.T2.5.5.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.5.5.4.1" class="ltx_text" style="background-color:#F7FBFF;">51.2</span></td>
<td id="S4.T2.5.5.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.5.5.5.1" class="ltx_text" style="background-color:#F7FBFF;">63.2</span></td>
</tr>
<tr id="S4.T2.9.16.7" class="ltx_tr">
<th id="S4.T2.9.16.7.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S4.T2.9.16.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="background-color:#F7FBFF;" colspan="4"><em id="S4.T2.9.16.7.2.1" class="ltx_emph ltx_font_italic" style="background-color:#F7FBFF;">ablation studies of the number of epochs</em></th>
</tr>
<tr id="S4.T2.9.17.8" class="ltx_tr">
<th id="S4.T2.9.17.8.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T2.9.17.8.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.17.8.2.1" class="ltx_text" style="background-color:#F7FBFF;"> 1 epoch</span></th>
<td id="S4.T2.9.17.8.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.17.8.3.1" class="ltx_text" style="background-color:#F7FBFF;">33.3</span></td>
<td id="S4.T2.9.17.8.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.17.8.4.1" class="ltx_text" style="background-color:#F7FBFF;">39.1</span></td>
<td id="S4.T2.9.17.8.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.17.8.5.1" class="ltx_text" style="background-color:#F7FBFF;">50.3</span></td>
</tr>
<tr id="S4.T2.9.18.9" class="ltx_tr">
<th id="S4.T2.9.18.9.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T2.9.18.9.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.18.9.2.1" class="ltx_text" style="background-color:#F7FBFF;"> 5 epochs</span></th>
<td id="S4.T2.9.18.9.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.18.9.3.1" class="ltx_text" style="background-color:#F7FBFF;">45.8</span></td>
<td id="S4.T2.9.18.9.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.18.9.4.1" class="ltx_text" style="background-color:#F7FBFF;">52.1</span></td>
<td id="S4.T2.9.18.9.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.18.9.5.1" class="ltx_text" style="background-color:#F7FBFF;">63.6</span></td>
</tr>
<tr id="S4.T2.9.19.10" class="ltx_tr">
<th id="S4.T2.9.19.10.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T2.9.19.10.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.19.10.2.1" class="ltx_text" style="background-color:#F7FBFF;"> 10 pochs</span></th>
<td id="S4.T2.9.19.10.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.19.10.3.1" class="ltx_text" style="background-color:#F7FBFF;">46.5</span></td>
<td id="S4.T2.9.19.10.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.19.10.4.1" class="ltx_text" style="background-color:#F7FBFF;">52.3</span></td>
<td id="S4.T2.9.19.10.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.19.10.5.1" class="ltx_text" style="background-color:#F7FBFF;">61.9</span></td>
</tr>
<tr id="S4.T2.9.20.11" class="ltx_tr">
<th id="S4.T2.9.20.11.1" class="ltx_td ltx_th ltx_th_row ltx_border_t"></th>
<th id="S4.T2.9.20.11.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" style="background-color:#F7FBFF;" colspan="4"><em id="S4.T2.9.20.11.2.1" class="ltx_emph ltx_font_italic" style="background-color:#F7FBFF;">ablation studies of different learning mechanisms</em></th>
</tr>
<tr id="S4.T2.9.21.12" class="ltx_tr">
<th id="S4.T2.9.21.12.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T2.9.21.12.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.21.12.2.1" class="ltx_text" style="background-color:#F7FBFF;"> QA before doc (grouped)</span></th>
<td id="S4.T2.9.21.12.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.21.12.3.1" class="ltx_text" style="background-color:#F7FBFF;">38.2</span></td>
<td id="S4.T2.9.21.12.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.21.12.4.1" class="ltx_text" style="background-color:#F7FBFF;">43.2</span></td>
<td id="S4.T2.9.21.12.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.21.12.5.1" class="ltx_text" style="background-color:#F7FBFF;">56.3</span></td>
</tr>
<tr id="S4.T2.9.22.13" class="ltx_tr">
<th id="S4.T2.9.22.13.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T2.9.22.13.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.22.13.2.1" class="ltx_text" style="background-color:#F7FBFF;"> QA after doc (grouped)</span></th>
<td id="S4.T2.9.22.13.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.22.13.3.1" class="ltx_text" style="background-color:#F7FBFF;">27.2</span></td>
<td id="S4.T2.9.22.13.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.22.13.4.1" class="ltx_text" style="background-color:#F7FBFF;">31.1</span></td>
<td id="S4.T2.9.22.13.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.22.13.5.1" class="ltx_text" style="background-color:#F7FBFF;">42.1</span></td>
</tr>
<tr id="S4.T2.9.23.14" class="ltx_tr">
<th id="S4.T2.9.23.14.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="S4.T2.9.23.14.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.23.14.2.1" class="ltx_text" style="background-color:#F7FBFF;"> QA before doc (interleaved)</span></th>
<td id="S4.T2.9.23.14.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.23.14.3.1" class="ltx_text" style="background-color:#F7FBFF;">45.9</span></td>
<td id="S4.T2.9.23.14.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.23.14.4.1" class="ltx_text" style="background-color:#F7FBFF;">51.3</span></td>
<td id="S4.T2.9.23.14.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.23.14.5.1" class="ltx_text" style="background-color:#F7FBFF;">64.5</span></td>
</tr>
<tr id="S4.T2.9.24.15" class="ltx_tr">
<th id="S4.T2.9.24.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.24.15.1.1" class="ltx_text" style="background-color:#F7FBFF;">PIT  ➆</span></th>
<th id="S4.T2.9.24.15.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#F7FBFF;"><span id="S4.T2.9.24.15.2.1" class="ltx_text" style="background-color:#F7FBFF;"> QA after doc (interleaved)</span></th>
<td id="S4.T2.9.24.15.3" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.24.15.3.1" class="ltx_text" style="background-color:#F7FBFF;">43.2</span></td>
<td id="S4.T2.9.24.15.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.24.15.4.1" class="ltx_text" style="background-color:#F7FBFF;">49.1</span></td>
<td id="S4.T2.9.24.15.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#F7FBFF;"><span id="S4.T2.9.24.15.5.1" class="ltx_text" style="background-color:#F7FBFF;">61.6</span></td>
</tr>
<tr id="S4.T2.7.7" class="ltx_tr">
<th id="S4.T2.7.7.3" class="ltx_td ltx_align_left ltx_th ltx_th_row" style="background-color:#FFF7FA;"><span id="S4.T2.7.7.3.1" class="ltx_text" style="background-color:#FFF7FA;">PIT–</span></th>
<th id="S4.T2.7.7.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row" style="background-color:#FFF7FA;"><span id="S4.T2.7.7.2.2" class="ltx_text" style="background-color:#FFF7FA;">train QA + train doc <math id="S4.T2.6.6.1.1.m1.1" class="ltx_Math" style="background-color:#FFF7FA;" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.6.6.1.1.m1.1a"><mo mathbackground="#FFF7FA" stretchy="false" id="S4.T2.6.6.1.1.m1.1.1" xref="S4.T2.6.6.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.1.1.m1.1b"><ci id="S4.T2.6.6.1.1.m1.1.1.cmml" xref="S4.T2.6.6.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.1.1.m1.1c">\shortrightarrow</annotation></semantics></math> train QA <math id="S4.T2.7.7.2.2.m2.1" class="ltx_Math" style="background-color:#FFF7FA;" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.7.7.2.2.m2.1a"><mo mathbackground="#FFF7FA" stretchy="false" id="S4.T2.7.7.2.2.m2.1.1" xref="S4.T2.7.7.2.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.2.2.m2.1b"><ci id="S4.T2.7.7.2.2.m2.1.1.cmml" xref="S4.T2.7.7.2.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.2.2.m2.1c">\shortrightarrow</annotation></semantics></math> test doc</span></th>
<td id="S4.T2.7.7.4" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#FFF7FA;"><span id="S4.T2.7.7.4.1" class="ltx_text" style="background-color:#FFF7FA;">44.4</span></td>
<td id="S4.T2.7.7.5" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#FFF7FA;"><span id="S4.T2.7.7.5.1" class="ltx_text" style="background-color:#FFF7FA;">51.3</span></td>
<td id="S4.T2.7.7.6" class="ltx_td ltx_nopad_l ltx_align_right" style="background-color:#FFF7FA;"><span id="S4.T2.7.7.6.1" class="ltx_text" style="background-color:#FFF7FA;">63.4</span></td>
</tr>
<tr id="S4.T2.9.9" class="ltx_tr">
<th id="S4.T2.9.9.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="background-color:#E9FCE9;"><span id="S4.T2.9.9.3.1" class="ltx_text" style="background-color:#E9FCE9;">PIT++  ➇</span></th>
<th id="S4.T2.9.9.2" class="ltx_td ltx_nopad_l ltx_align_left ltx_th ltx_th_row ltx_border_bb" style="background-color:#E9FCE9;"><span id="S4.T2.9.9.2.2" class="ltx_text" style="background-color:#E9FCE9;">train QA <math id="S4.T2.8.8.1.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.8.8.1.1.m1.1a"><mo mathbackground="#E9FCE9" stretchy="false" id="S4.T2.8.8.1.1.m1.1.1" xref="S4.T2.8.8.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.1.1.m1.1b"><ci id="S4.T2.8.8.1.1.m1.1.1.cmml" xref="S4.T2.8.8.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.1.1.m1.1c">\shortrightarrow</annotation></semantics></math> train QA + train doc <math id="S4.T2.9.9.2.2.m2.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S4.T2.9.9.2.2.m2.1a"><mo mathbackground="#E9FCE9" stretchy="false" id="S4.T2.9.9.2.2.m2.1.1" xref="S4.T2.9.9.2.2.m2.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T2.9.9.2.2.m2.1b"><ci id="S4.T2.9.9.2.2.m2.1.1.cmml" xref="S4.T2.9.9.2.2.m2.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.9.2.2.m2.1c">\shortrightarrow</annotation></semantics></math> test doc</span></th>
<td id="S4.T2.9.9.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" style="background-color:#E9FCE9;"><span id="S4.T2.9.9.4.1" class="ltx_text ltx_font_bold" style="background-color:#E9FCE9;">48.1</span></td>
<td id="S4.T2.9.9.5" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" style="background-color:#E9FCE9;"><span id="S4.T2.9.9.5.1" class="ltx_text ltx_font_bold" style="background-color:#E9FCE9;">54.4</span></td>
<td id="S4.T2.9.9.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" style="background-color:#E9FCE9;"><span id="S4.T2.9.9.6.1" class="ltx_text ltx_font_bold" style="background-color:#E9FCE9;">66.4</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison (%) of various pre-instruction-tuning methods and ablation studies to identify the key contributors to improved performance using Llama-2 7B. Different background colors indicate different pre-instruction-tuning methods. The best results are in bold.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Improving LLMs in Absorbing Knowledge from Documents</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The amount of knowledge elicited through the standard instruction-tuning is still limited, even though the perplexity of documents is minimized, a phenomenon we refer to as the “perplexity curse”.
Our next question is how can we improve the ability of LLMs to absorb knowledge from documents to mitigate the perplexity curse.
The main challenge is the gap between the way knowledge is presented in raw documents and how it is accessed through question-answering.
We found that QA pairs are generally straightforward, while documents tend to be more complex and cluttered, weaving many factual statements together in a more intricate manner.
Using <a href="#S2.F3" title="Figure 3 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;3</span></a> as an example, the answer to the question “who handled the editing of Oppenheimer” is included in a sentence in the middle of the article “Editing was handled by Jennifer Lame …”, which does not explicitly mention “Oppenheimer”.
During training, LLMs must understand the context and deduce that “editing” refers to “the editing of Oppenheimer” to effectively encode this knowledge in the parameters.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Zhu and Li (<a href="#bib.bib63" title="" class="ltx_ref">2023a</a>)</cite> studied this problem by training a randomly initialized GPT-2-like transformer from scratch on synthetic biographies and evaluated its ability to answer questions about the individuals.
They found that training on a mix of biographies and questions related to half of those biographies led to strong generalization when answering questions about the remaining half of biographies, which resembles setting  ➃ in <a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>.
In contrast, training on biographies and QA pairs sequentially failed.
However, the key contributor to the success remains uncertain because the data were blended together, and it is unclear how to apply this practically to absorb knowledge from new documents.
Inspired by our observation of the different difficulty levels between QA pairs and documents, and the finding from <cite class="ltx_cite ltx_citemacro_citet">Zhu and Li (<a href="#bib.bib63" title="" class="ltx_ref">2023a</a>)</cite>, we hypothesize that <em id="S5.p2.1.1" class="ltx_emph ltx_font_italic">it is beneficial to deliberately expose LLMs to instruction-tuning data before continued pre-training so that the process of encoding knowledge from complex documents takes into account how this knowledge is accessed.</em>
We refer to this as <span id="S5.p2.1.2" class="ltx_text ltx_font_bold">pre-instruction-tuning (PIT)</span> and study various implementations of PIT prior to continued learning (<a href="#S5.SS1" title="5.1 Variants of Pre-instruction-tuning ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">§&nbsp;5.1</span></a>), followed by detailed ablations identifying the keys contributor to performance (<a href="#S5.SS2" title="5.2 Pre-instruction-tuning++ ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">§&nbsp;5.2</span></a> and <a href="#S5.SS3" title="5.3 Ablation Studies ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">§&nbsp;5.3</span></a>), and finally assess how well PIT performs across domains (<a href="#S5.SS4" title="5.4 Cross-domain Generalization ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">§&nbsp;5.4</span></a>).
We adhere to the hyperparameters outlined in <a href="#S3.SS2" title="3.2 Hyperparameters ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">§&nbsp;3.2</span></a> and perform PIT for 3 epochs unless specified otherwise.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Variants of Pre-instruction-tuning</h3>

<section id="S5.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Pre-instruction-tuning w/ QA only</h4>

<div id="S5.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px1.p1.1" class="ltx_p">We start with exposing instruction-tuning data before continued pre-training on documents—training on topically related QA pairs before training on test documents (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➄).
This can be directly compared with the continued pre-training setting (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➀).
The intuition is that questions help LLMs recognize key types of information, enabling LLMs to focus on important information during pre-training on subsequent documents, even though the questions are not directly tied to the documents.
For example, training on a question like “who handled the editing of Oppenheimer” could help LLMs pay attention to screenwriters when training on new documents like “Barbie”.
As shown in <a href="#S4.T1" title="Table 1 ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;1</span></a>, this method outperforms continued pre-training, especially on larger LLMs (27.6%/41.7% <math id="S5.SS1.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S5.SS1.SSS0.Px1.p1.1.m1.1a"><mo stretchy="false" id="S5.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px1.p1.1.m1.1b"><ci id="S5.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px1.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px1.p1.1.m1.1c">\shortrightarrow</annotation></semantics></math> 28.6%/49.7% for 7B/70B).
The ablation that trains on QA data after training on documents (“instruction-tuning w/o train doc” in <a href="#S4.T2" title="Table 2 ‣ Experiment results ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;2</span></a>) is ineffective, confirming the importance of training on questions as a warm-up before encoding documents.</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Pre-instruction-tuning on QA and documents sequentially</h4>

<div id="S5.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p1.1" class="ltx_p">Our second implementation trains on QA and associated documents sequentially (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➅), with the intuition that the ability to absorb knowledge from documents can be strengthened if an LLM is trained on the complex documents after it has grasped the associated simpler QA pairs.
For instance, if an LLM has already learned that “Jennifer Lame” is the answer to “who handled the editing of Oppenheimer”, training on the document “Editing was handled by Jennifer Lame” can more efficiently refine its storage of knowledge in its parameters.
As shown in <a href="#S4.T1" title="Table 1 ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;1</span></a>, PIT on QA pairs and documents sequentially surpasses the QA-only variant (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➄) and standard instruction-tuning (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➁) (30.3%/46.4% <math id="S5.SS1.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S5.SS1.SSS0.Px2.p1.1.m1.1a"><mo stretchy="false" id="S5.SS1.SSS0.Px2.p1.1.m1.1.1" xref="S5.SS1.SSS0.Px2.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px2.p1.1.m1.1b"><ci id="S5.SS1.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px2.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px2.p1.1.m1.1c">\shortrightarrow</annotation></semantics></math> 32.5%/54.6% for 7B/70B), demonstrating its effectiveness.</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Pre-instruction-tuning </h4>

<div id="S5.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px3.p1.1" class="ltx_p">The effectiveness of PIT depends on ensuring that the associated QA pairs are already learned before encoding the respective documents.
However, we observed that after training on documents (train doc in <a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➅), the accuracy for corresponding questions (train QA in <a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➅) dropped from almost perfect to 30%, indicating severe forgetting.
To fix this, we train on the associated QA pairs and documents together (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➆).
As shown in <a href="#S4.T1" title="Table 1 ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;1</span></a>, this significantly improves the performance, outperforming all other approaches, including mixing all data together (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➃), by a large margin (39.4%/57.1% <math id="S5.SS1.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\shortrightarrow" display="inline"><semantics id="S5.SS1.SSS0.Px3.p1.1.m1.1a"><mo stretchy="false" id="S5.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S5.SS1.SSS0.Px3.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS0.Px3.p1.1.m1.1b"><ci id="S5.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS0.Px3.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS0.Px3.p1.1.m1.1c">\shortrightarrow</annotation></semantics></math> 45.5%/62.7% for 7B/70B).
Training on both QA pairs and documents prevents forgetting, but it also obscures how the learning process works.
It is unclear whether LLMs grasp QA pairs before encoding knowledge from documents, or if it works the other way around.
In the following section, we deliberately arrange the order of QA pairs and documents during training to examine this, which leads us to propose an improved version of PIT.</p>
</div>
<figure id="S5.F6" class="ltx_figure"><img src="/html/2402.12847/assets/x8.png" id="S5.F6.g1" class="ltx_graphics ltx_img_landscape" width="461" height="247" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Different arrangements between QA pairs and corresponding documents. The ellipses represent other examples.</figcaption>
</figure>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Pre-instruction-tuning++</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">We first study how the performance varies with different numbers of epochs.
As shown in <a href="#S4.T2" title="Table 2 ‣ Experiment results ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;2</span></a>, training for 1 epoch is insufficient, and the performance of 3, 5, or 10 epochs is similar.
We fix the number of epochs to 3 and arrange the order of QA pairs and corresponding documents as shown in <a href="#S5.F6" title="Figure 6 ‣ Pre-instruction-tuning ‣ 5.1 Variants of Pre-instruction-tuning ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;6</span></a>.
The interleaved arrangement cycles through all the data 3 times, ensuring that in each epoch, questions either precede or follow their associated documents.
On the other hand, the grouped arrangement clusters each example’s 3 appearances together, guaranteeing that the repeated questions are positioned either before or after their respective repeated documents.
As shown in <a href="#S4.T2" title="Table 2 ‣ Experiment results ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;2</span></a>, positioning QA pairs before corresponding documents achieves better performance in both grouped and interleaved arrangements, indicating that during PIT, the learning mechanism prioritizes understanding how to access knowledge before learning to absorb information from the more complex and information-dense documents.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">Based on this, we propose an improved variant called pre-instruction-tuning++, which trains exclusively on QA pairs to understand patterns of knowledge access, then progresses to training on a combination of QA and document data to align knowledge access through questions and knowledge encoding from documents (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➇).
As shown in <a href="#S4.T2" title="Table 2 ‣ Experiment results ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;2</span></a>, PIT++ significantly outperforms PIT (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➆) from 45.4% to 48.1%, while training on QA data after on the mix (PIT– in <a href="#S4.T2" title="Table 2 ‣ Experiment results ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;2</span></a>) does not yield additional benefits.
This reinforces our hypothesis that understanding how knowledge is accessed aids in absorbing knowledge from documents, and therefore, should be prioritized.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Ablation Studies</h3>

<section id="S5.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Standard instruction-tuning is inferior not due to forgetting</h4>

<div id="S5.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px1.p1.1" class="ltx_p">A drawback of standard instruction-tuning is that knowledge in test documents might be forgotten after training on QA pairs (a phenomenon also known as the “alignment tax” <cite class="ltx_cite ltx_citemacro_cite">Ouyang et&nbsp;al. (<a href="#bib.bib35" title="" class="ltx_ref">2022</a>)</cite>).
To show that the lower performance of standard instruction-tuning is not due to forgetting, we add a setting where we mix train QA with test documents during instruction-tuning to prevent forgetting (<a href="#S3.F4" title="Figure 4 ‣ 3.3 Evaluation Metrics ‣ 3 Experimental Settings ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;4</span></a>  ➂).
As shown in <a href="#S4.T2" title="Table 2 ‣ Experiment results ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;2</span></a>, this does not help, confirming our hypothesis.</p>
</div>
</section>
<section id="S5.SS3.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Pre-instruction-tuning is not simply upweighting salient tokens from documents</h4>

<div id="S5.SS3.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS3.SSS0.Px2.p1.1" class="ltx_p">We include an ablation inspired by <cite class="ltx_cite ltx_citemacro_citet">Hu et&nbsp;al. (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>)</cite> which upweights tokens when pre-training on documents to focus on salient information.
We assign a weight of 1.0 to tokens in documents that are included in the answers (e.g., “Jennifer Lame” in the sentence “Editing was handled by Jennifer Lame”), and assign a lower weight of 0.5 to other tokens.
As shown in <a href="#S4.T2" title="Table 2 ‣ Experiment results ‣ 4.2 Analyzing the Training Dynamics: Perplexity and Generalization ‣ 4 How Much Knowledge Can LLMs Absorb via Continued Pre-training Followed by Instruction-tuning? ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;2</span></a>, this weighted continued pre-training is ineffective, confirming our hypothesis.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<table id="S5.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.1.1.1" class="ltx_tr">
<th id="S5.T3.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<td id="S5.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3"><span id="S5.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Llama-2 7B</span></td>
<td id="S5.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S5.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">Llama-2 70B</span></td>
</tr>
<tr id="S5.T3.1.2.2" class="ltx_tr">
<th id="S5.T3.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S5.T3.1.2.2.1.1" class="ltx_text ltx_font_bold">Settings</span></th>
<td id="S5.T3.1.2.2.2" class="ltx_td ltx_align_right"><span id="S5.T3.1.2.2.2.1" class="ltx_text ltx_font_bold">EM</span></td>
<td id="S5.T3.1.2.2.3" class="ltx_td ltx_nopad_l ltx_align_right"><span id="S5.T3.1.2.2.3.1" class="ltx_text ltx_font_bold">Rec.</span></td>
<td id="S5.T3.1.2.2.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r"><span id="S5.T3.1.2.2.4.1" class="ltx_text ltx_font_bold">R-L</span></td>
<td id="S5.T3.1.2.2.5" class="ltx_td ltx_align_right"><span id="S5.T3.1.2.2.5.1" class="ltx_text ltx_font_bold">EM</span></td>
<td id="S5.T3.1.2.2.6" class="ltx_td ltx_nopad_l ltx_align_right"><span id="S5.T3.1.2.2.6.1" class="ltx_text ltx_font_bold">Rec.</span></td>
<td id="S5.T3.1.2.2.7" class="ltx_td ltx_nopad_l ltx_align_right"><span id="S5.T3.1.2.2.7.1" class="ltx_text ltx_font_bold">R-L</span></td>
</tr>
<tr id="S5.T3.1.3.3" class="ltx_tr">
<th id="S5.T3.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="7">
<em id="S5.T3.1.3.3.1.1" class="ltx_emph ltx_font_italic">standard instruction-tuning</em>  ➁</th>
</tr>
<tr id="S5.T3.1.4.4" class="ltx_tr">
<th id="S5.T3.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">in-domain</th>
<td id="S5.T3.1.4.4.2" class="ltx_td ltx_align_right">30.3</td>
<td id="S5.T3.1.4.4.3" class="ltx_td ltx_nopad_l ltx_align_right">34.7</td>
<td id="S5.T3.1.4.4.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">47.4</td>
<td id="S5.T3.1.4.4.5" class="ltx_td ltx_align_right">46.4</td>
<td id="S5.T3.1.4.4.6" class="ltx_td ltx_nopad_l ltx_align_right">50.9</td>
<td id="S5.T3.1.4.4.7" class="ltx_td ltx_nopad_l ltx_align_right">64.1</td>
</tr>
<tr id="S5.T3.1.5.5" class="ltx_tr">
<th id="S5.T3.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">cross-domain</th>
<td id="S5.T3.1.5.5.2" class="ltx_td ltx_align_right">23.6</td>
<td id="S5.T3.1.5.5.3" class="ltx_td ltx_nopad_l ltx_align_right">28.2</td>
<td id="S5.T3.1.5.5.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">38.4</td>
<td id="S5.T3.1.5.5.5" class="ltx_td ltx_align_right">42.8</td>
<td id="S5.T3.1.5.5.6" class="ltx_td ltx_nopad_l ltx_align_right">49.7</td>
<td id="S5.T3.1.5.5.7" class="ltx_td ltx_nopad_l ltx_align_right">58.5</td>
</tr>
<tr id="S5.T3.1.6.6" class="ltx_tr">
<th id="S5.T3.1.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="7">
<em id="S5.T3.1.6.6.1.1" class="ltx_emph ltx_font_italic">pre-instruction-tuning</em>  ➆</th>
</tr>
<tr id="S5.T3.1.7.7" class="ltx_tr">
<th id="S5.T3.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">in-domain</th>
<td id="S5.T3.1.7.7.2" class="ltx_td ltx_align_right">45.4</td>
<td id="S5.T3.1.7.7.3" class="ltx_td ltx_nopad_l ltx_align_right">51.2</td>
<td id="S5.T3.1.7.7.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r">63.2</td>
<td id="S5.T3.1.7.7.5" class="ltx_td ltx_align_right">62.7</td>
<td id="S5.T3.1.7.7.6" class="ltx_td ltx_nopad_l ltx_align_right">68.6</td>
<td id="S5.T3.1.7.7.7" class="ltx_td ltx_nopad_l ltx_align_right">78.8</td>
</tr>
<tr id="S5.T3.1.8.8" class="ltx_tr">
<th id="S5.T3.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">cross-domain</th>
<td id="S5.T3.1.8.8.2" class="ltx_td ltx_align_right ltx_border_bb">36.9</td>
<td id="S5.T3.1.8.8.3" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb">43.2</td>
<td id="S5.T3.1.8.8.4" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb ltx_border_r">54.9</td>
<td id="S5.T3.1.8.8.5" class="ltx_td ltx_align_right ltx_border_bb">55.2</td>
<td id="S5.T3.1.8.8.6" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb">66.7</td>
<td id="S5.T3.1.8.8.7" class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb">74.0</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>In-domain and cross-domain PIT.</figcaption>
</figure>
<figure id="S5.T4" class="ltx_table">
<table id="S5.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T4.1.1.1" class="ltx_tr">
<th id="S5.T4.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt"><span id="S5.T4.1.1.1.1.1" class="ltx_text ltx_font_bold">Settings</span></th>
<td id="S5.T4.1.1.1.2" class="ltx_td ltx_align_right ltx_border_tt"><span id="S5.T4.1.1.1.2.1" class="ltx_text ltx_font_bold">EM</span></td>
<td id="S5.T4.1.1.1.3" class="ltx_td ltx_align_right ltx_border_tt"><span id="S5.T4.1.1.1.3.1" class="ltx_text ltx_font_bold">Rec.</span></td>
<td id="S5.T4.1.1.1.4" class="ltx_td ltx_align_right ltx_border_tt"><span id="S5.T4.1.1.1.4.1" class="ltx_text ltx_font_bold">R-L</span></td>
</tr>
<tr id="S5.T4.1.2.2" class="ltx_tr">
<th id="S5.T4.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4"><em id="S5.T4.1.2.2.1.1" class="ltx_emph ltx_font_italic">generalization to the biography dataset <span id="S5.T4.1.2.2.1.1.1" class="ltx_text ltx_font_typewriter">bioS</span></em></th>
</tr>
<tr id="S5.T4.1.3.3" class="ltx_tr">
<th id="S5.T4.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">closed-book</th>
<td id="S5.T4.1.3.3.2" class="ltx_td ltx_align_right">2.9</td>
<td id="S5.T4.1.3.3.3" class="ltx_td ltx_align_right">2.9</td>
<td id="S5.T4.1.3.3.4" class="ltx_td ltx_align_right">11.0</td>
</tr>
<tr id="S5.T4.1.4.4" class="ltx_tr">
<th id="S5.T4.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">open-book w/ doc</th>
<td id="S5.T4.1.4.4.2" class="ltx_td ltx_align_right">95.2</td>
<td id="S5.T4.1.4.4.3" class="ltx_td ltx_align_right">95.4</td>
<td id="S5.T4.1.4.4.4" class="ltx_td ltx_align_right">95.6</td>
</tr>
<tr id="S5.T4.1.5.5" class="ltx_tr">
<th id="S5.T4.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">continued pre-training  ➀</th>
<td id="S5.T4.1.5.5.2" class="ltx_td ltx_align_right">29.6</td>
<td id="S5.T4.1.5.5.3" class="ltx_td ltx_align_right">29.8</td>
<td id="S5.T4.1.5.5.4" class="ltx_td ltx_align_right">38.7</td>
</tr>
<tr id="S5.T4.1.6.6" class="ltx_tr">
<th id="S5.T4.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">pre-instruction-tuning  ➆</th>
<td id="S5.T4.1.6.6.2" class="ltx_td ltx_align_right"><span id="S5.T4.1.6.6.2.1" class="ltx_text ltx_font_bold">58.1</span></td>
<td id="S5.T4.1.6.6.3" class="ltx_td ltx_align_right"><span id="S5.T4.1.6.6.3.1" class="ltx_text ltx_font_bold">58.4</span></td>
<td id="S5.T4.1.6.6.4" class="ltx_td ltx_align_right"><span id="S5.T4.1.6.6.4.1" class="ltx_text ltx_font_bold">61.9</span></td>
</tr>
<tr id="S5.T4.1.7.7" class="ltx_tr">
<th id="S5.T4.1.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" colspan="4"><em id="S5.T4.1.7.7.1.1" class="ltx_emph ltx_font_italic">generalization to questions by real users from Google</em></th>
</tr>
<tr id="S5.T4.1.8.8" class="ltx_tr">
<th id="S5.T4.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">standard instruction-tuning  ➁</th>
<td id="S5.T4.1.8.8.2" class="ltx_td ltx_align_right">21.5</td>
<td id="S5.T4.1.8.8.3" class="ltx_td ltx_align_right">30.1</td>
<td id="S5.T4.1.8.8.4" class="ltx_td ltx_align_right">36.8</td>
</tr>
<tr id="S5.T4.1.9.9" class="ltx_tr">
<th id="S5.T4.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">pre-instruction-tuning  ➆</th>
<td id="S5.T4.1.9.9.2" class="ltx_td ltx_align_right ltx_border_bb"><span id="S5.T4.1.9.9.2.1" class="ltx_text ltx_font_bold">29.0</span></td>
<td id="S5.T4.1.9.9.3" class="ltx_td ltx_align_right ltx_border_bb"><span id="S5.T4.1.9.9.3.1" class="ltx_text ltx_font_bold">35.5</span></td>
<td id="S5.T4.1.9.9.4" class="ltx_td ltx_align_right ltx_border_bb"><span id="S5.T4.1.9.9.4.1" class="ltx_text ltx_font_bold">48.2</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Generalization of the Llama-2 7B model trained with pre-instruction-tuning.</figcaption>
</figure>
</section>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Cross-domain Generalization</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">We validated the effectiveness of PIT by training and evaluation on data from the same domain (<span id="S5.SS4.p1.1.1" class="ltx_text ltx_font_typewriter">Wiki2023-film</span>).
<em id="S5.SS4.p1.1.2" class="ltx_emph ltx_font_italic">Can PIT make LLMs better at absorbing knowledge from documents of a different domain?</em>
To this end, we follow the cross-domain setting outlined in <a href="#S2.F2" title="Figure 2 ‣ 2 Building a Dataset to Study Continual Knowledge Acquisition ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Fig.&nbsp;2</span></a>—training on other domains (<span id="S5.SS4.p1.1.3" class="ltx_text ltx_font_typewriter">Wiki2023-other-train</span>) and testing on the film domain (<span id="S5.SS4.p1.1.4" class="ltx_text ltx_font_typewriter">Wiki2023-film-test</span>).
The results of standard instruction-tuning and PIT, in both in-domain and cross-domain settings, are detailed in <a href="#S5.T3" title="Table 3 ‣ Pre-instruction-tuning is not simply upweighting salient tokens from documents ‣ 5.3 Ablation Studies ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;3</span></a>.
Even though it is not as effective as the in-domain counterparts, cross-domain PIT still significantly outperforms instruction-tuning, demonstrating that it can generalize across different domains.
This finding sheds light on the potential to scale this method up to a broader range of documents and instructions for more robust generalization.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.1" class="ltx_p">We also evaluate the effectiveness of PIT in two other scenarios: (1) when applied to non-Wikipedia documents, and (2) when addressing questions asked by real users.
For the first scenario, we take the Llama-2 7B model trained with PIT on <span id="S5.SS4.p2.1.1" class="ltx_text ltx_font_typewriter">2023Wiki-other</span> and further train it on biographies synthesized in <cite class="ltx_cite ltx_citemacro_citet">Zhu and Li (<a href="#bib.bib63" title="" class="ltx_ref">2023a</a>)</cite> (<span id="S5.SS4.p2.1.2" class="ltx_text ltx_font_typewriter">bioS</span>).
Then, we evaluate based on questions about the individuals.
For the second scenario, we manually search Google using questions generated by LLMs from <span id="S5.SS4.p2.1.3" class="ltx_text ltx_font_typewriter">Wiki2023-film-test</span>, collect a total of 93 similar questions from real users by leveraging Google’s “People Also Ask” feature, and then evaluate Llama-2 7B on these questions.
As shown in <a href="#S5.T4" title="Table 4 ‣ Pre-instruction-tuning is not simply upweighting salient tokens from documents ‣ 5.3 Ablation Studies ‣ 5 Improving LLMs in Absorbing Knowledge from Documents ‣ Instruction-tuned Language Models are Better Knowledge Learners" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Tab.&nbsp;4</span></a>, PIT outperforms baselines in both scenarios, demonstrating its generalization ability.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Related Work</h2>

<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Continual Knowledge Acquisition</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">Several works have studied whether LMs can answer questions about information in documents they have been trained on.
<cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib54" title="" class="ltx_ref">2021</a>); Jang et&nbsp;al. (<a href="#bib.bib20" title="" class="ltx_ref">2022</a>); Hu et&nbsp;al. (<a href="#bib.bib16" title="" class="ltx_ref">2023</a>)</cite> use relatively small LMs such as BART <cite class="ltx_cite ltx_citemacro_cite">Lewis et&nbsp;al. (<a href="#bib.bib27" title="" class="ltx_ref">2020a</a>)</cite>, T5 <cite class="ltx_cite ltx_citemacro_cite">Raffel et&nbsp;al. (<a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite>, or GPT-2 <cite class="ltx_cite ltx_citemacro_cite">Radford et&nbsp;al. (<a href="#bib.bib39" title="" class="ltx_ref">2019</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Ovadia et&nbsp;al. (<a href="#bib.bib36" title="" class="ltx_ref">2023</a>)</cite> focus on the comparison between RAG and continued pre-training approaches without using instruction-tuning.
<cite class="ltx_cite ltx_citemacro_citet">Zhu and Li (<a href="#bib.bib63" title="" class="ltx_ref">2023a</a>, <a href="#bib.bib64" title="" class="ltx_ref">b</a>)</cite> examine this problem from a similar angle as ours using a GPT-2-like transformer trained from scratch on synthetic biographies and fine-tuned on QA pairs related to the individuals.
They examined a mixed training setting on both biographies and QA pairs, which is our major motivation to study different strategies to incorporate QA data before continued pre-training.
Other works study adapting LLMs to new domains via various strategies <cite class="ltx_cite ltx_citemacro_cite">Zhang et&nbsp;al. (<a href="#bib.bib59" title="" class="ltx_ref">2023</a>); Cheng et&nbsp;al. (<a href="#bib.bib8" title="" class="ltx_ref">2023</a>); Han et&nbsp;al. (<a href="#bib.bib14" title="" class="ltx_ref">2023</a>); Wu et&nbsp;al. (<a href="#bib.bib57" title="" class="ltx_ref">2023</a>); Nguyen et&nbsp;al. (<a href="#bib.bib33" title="" class="ltx_ref">2023</a>); Zhao et&nbsp;al. (<a href="#bib.bib61" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Instruction-tuning or Alignment</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">Instruction-tuning (also known as supervised fine-tuning) on high-quality annotated data <cite class="ltx_cite ltx_citemacro_cite">Sanh et&nbsp;al. (<a href="#bib.bib44" title="" class="ltx_ref">2022</a>); Wei et&nbsp;al. (<a href="#bib.bib56" title="" class="ltx_ref">2022</a>); Mishra et&nbsp;al. (<a href="#bib.bib31" title="" class="ltx_ref">2022</a>); Iyer et&nbsp;al. (<a href="#bib.bib18" title="" class="ltx_ref">2022</a>); Kopf et&nbsp;al. (<a href="#bib.bib24" title="" class="ltx_ref">2023</a>); Zhou et&nbsp;al. (<a href="#bib.bib62" title="" class="ltx_ref">2023</a>); Sun et&nbsp;al. (<a href="#bib.bib47" title="" class="ltx_ref">2023b</a>, <a href="#bib.bib46" title="" class="ltx_ref">a</a>)</cite> and/or data generated by proprietary models <cite class="ltx_cite ltx_citemacro_cite">Taori et&nbsp;al. (<a href="#bib.bib48" title="" class="ltx_ref">2023</a>); Chiang et&nbsp;al. (<a href="#bib.bib9" title="" class="ltx_ref">2023</a>); Wang et&nbsp;al. (<a href="#bib.bib55" title="" class="ltx_ref">2023b</a>); Ivison et&nbsp;al. (<a href="#bib.bib17" title="" class="ltx_ref">2023</a>)</cite>, or alignment with reinforcement learning from human feedback (RLHF) or direct preference optimization (DPO) <cite class="ltx_cite ltx_citemacro_cite">Ouyang et&nbsp;al. (<a href="#bib.bib35" title="" class="ltx_ref">2022</a>); Touvron et&nbsp;al. (<a href="#bib.bib52" title="" class="ltx_ref">2023b</a>); Rafailov et&nbsp;al. (<a href="#bib.bib40" title="" class="ltx_ref">2023</a>); Tian et&nbsp;al. (<a href="#bib.bib49" title="" class="ltx_ref">2023</a>)</cite> has been a central topic recently because it elicits knowledge from LLMs and enhances various abilities to handle questions from users.
We focus on factuality and study the best way to perform instruction-tuning to elicit factual knowledge from LLMs.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Analyzing the Training Dynamics of LMs</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">Many works study the training dynamics of LMs from different perspectives.
<cite class="ltx_cite ltx_citemacro_citet">Carlini et&nbsp;al. (<a href="#bib.bib6" title="" class="ltx_ref">2022</a>)</cite> quantifies memorization across model sizes and the frequency of data duplication.
<cite class="ltx_cite ltx_citemacro_citet">Tirumala et&nbsp;al. (<a href="#bib.bib50" title="" class="ltx_ref">2022</a>)</cite> finds that larger LMs memorize training data faster with less overfitting.
<cite class="ltx_cite ltx_citemacro_citet">Xia et&nbsp;al. (<a href="#bib.bib58" title="" class="ltx_ref">2023</a>)</cite> show that perplexity is more predictive of model behaviors than other factors.
<cite class="ltx_cite ltx_citemacro_citet">Dery et&nbsp;al. (<a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite> studies end-task aware pre-training using classification tasks and RoBERTa models.
Our work differs in that we specifically focus on the capacity of recalling and generalizing information from a seen document to answer questions.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Retrieval-augmented Generation</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.1" class="ltx_p">Retrieval-augmented generation (RAG) is a widely used approach to incorporate new knowledge into LLMs by augmenting fixed LLMs with retrieved information from external sources <cite class="ltx_cite ltx_citemacro_cite">Chen et&nbsp;al. (<a href="#bib.bib7" title="" class="ltx_ref">2017</a>); Guu et&nbsp;al. (<a href="#bib.bib13" title="" class="ltx_ref">2020</a>); Lewis et&nbsp;al. (<a href="#bib.bib28" title="" class="ltx_ref">2020b</a>); Borgeaud et&nbsp;al. (<a href="#bib.bib4" title="" class="ltx_ref">2022</a>); Wang et&nbsp;al. (<a href="#bib.bib53" title="" class="ltx_ref">2023a</a>); Alon et&nbsp;al. (<a href="#bib.bib1" title="" class="ltx_ref">2022</a>); He et&nbsp;al. (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>); Sachan et&nbsp;al. (<a href="#bib.bib43" title="" class="ltx_ref">2021</a>); Izacard et&nbsp;al. (<a href="#bib.bib19" title="" class="ltx_ref">2023</a>); Lee et&nbsp;al. (<a href="#bib.bib26" title="" class="ltx_ref">2022</a>); Jiang et&nbsp;al. (<a href="#bib.bib21" title="" class="ltx_ref">2022</a>); Shi et&nbsp;al. (<a href="#bib.bib45" title="" class="ltx_ref">2023</a>); Jiang et&nbsp;al. (<a href="#bib.bib23" title="" class="ltx_ref">2023</a>); Asai et&nbsp;al. (<a href="#bib.bib2" title="" class="ltx_ref">2023</a>); Nakano et&nbsp;al. (<a href="#bib.bib32" title="" class="ltx_ref">2021</a>); Qin et&nbsp;al. (<a href="#bib.bib38" title="" class="ltx_ref">2023</a>); Lin et&nbsp;al. (<a href="#bib.bib29" title="" class="ltx_ref">2023</a>)</cite>.
While RAG is effective in reducing hallucinations commonly experienced when relying solely on knowledge stored in parameters, its retrieval and generation process adds extra latency and complexity.
In contrast, continued pre-training to store knowledge in parameters and utilizing the stored knowledge to answer questions in a closed-book manner are simpler and faster at inference time.
Enhancing this capability is also scientifically significant, as it represents a fundamental step in employing LLMs as dependable assistants for accessing information.
Therefore, this paper focuses on exploring parametric approaches.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">We study the best way of continued training on new documents with the goal of later eliciting factual knowledge.
We propose pre-instruction-tuning that learns how knowledge is accessed via QA pairs prior to encoding knowledge from documents.
Extensive experiments demonstrate the superiority of pre-instruction-tuning versus standard instruction-tuning.
Future directions include scaling this method up to a broader range of documents and instructions for more robust generalization.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The <span id="Sx1.p1.1.1" class="ltx_text ltx_font_typewriter">Wiki2023</span> dataset provides a relatively clean testbed for studying continual knowledge acquisition.
However, its scope is limited to Wikipedia, which restricts the trained models’ adaptability to other sources like web pages from Common Crawl or scientific documents from arXiv.
We focus on eliciting factual knowledge with instruction-tuning on QA data in this paper.
The effectiveness of pre-instruction-tuning with different types of data for enhancing other skills like reasoning or comprehension is something that needs to be explored in future studies.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">We would like to thank Zeyuan Allen-Zhu, Zexuan Zhong, Shuyan Zhou, Frank F. Xu, Qian Liu, and Ruohong Zhang for their help with the experiments and constructive feedback.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alon et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Uri Alon, Frank&nbsp;F. Xu, Junxian He, Sudipta Sengupta, Dan Roth, and Graham Neubig. 2022.

</span>
<span class="ltx_bibblock">Neuro-symbolic language modeling with automaton-augmented retrieval.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2310.11511" title="" class="ltx_ref ltx_href">Self-rag: Learning to retrieve, generate, and critique through self-reflection</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.11511.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berglund et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa&nbsp;Cooper Stickland, Tomasz Korbak, and Owain Evans. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2309.12288" title="" class="ltx_ref ltx_href">The reversal curse: Llms trained on "a is b" fail to learn "b is a"</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.12288.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Borgeaud et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican, George van&nbsp;den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, Diego de&nbsp;Las&nbsp;Casas, Aurelia Guy, Jacob Menick, Roman Ring, Tom Hennigan, Saffron Huang, Loren Maggiore, Chris Jones, Albin Cassirer, Andy Brock, Michela Paganini, Geoffrey Irving, Oriol Vinyals, Simon Osindero, Karen Simonyan, Jack&nbsp;W. Rae, Erich Elsen, and Laurent Sifre. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.mlr.press/v162/borgeaud22a.html" title="" class="ltx_ref ltx_href">Improving language models by retrieving from trillions of tokens</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA</em>, volume 162 of <em id="bib.bib4.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages 2206–2240. PMLR.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Tom&nbsp;B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel&nbsp;M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html" title="" class="ltx_ref ltx_href">Language models are few-shot learners</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian Tramèr, and Chiyuan Zhang. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2202.07646" title="" class="ltx_ref ltx_href">Quantifying memorization across neural language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2202.07646.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P17-1171" title="" class="ltx_ref ltx_href">Reading wikipedia to answer open-domain questions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long Papers</em>, pages 1870–1879. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Daixuan Cheng, Shaohan Huang, and Furu Wei. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2309.09530" title="" class="ltx_ref ltx_href">Adapting large language models via reading comprehension</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.09530.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Wei-Lin Chiang, Zhuohan Li, Zi&nbsp;Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph&nbsp;E. Gonzalez, Ion Stoica, and Eric&nbsp;P. Xing. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://lmsys.org/blog/2023-03-30-vicuna/" title="" class="ltx_ref ltx_href">Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality</a>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung&nbsp;Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi&nbsp;Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew&nbsp;M. Dai, Thanumalayan&nbsp;Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel.
2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2204.02311" title="" class="ltx_ref ltx_href">Palm: Scaling language modeling with pathways</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2204.02311.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dery et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Lucio&nbsp;M. Dery, Paul Michel, Ameet Talwalkar, and Graham Neubig. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=2bO2x8NAIMB" title="" class="ltx_ref ltx_href">Should we be pre-training? an argument for end-task aware training as an alternative</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gemini Team (2023)</span>
<span class="ltx_bibblock">
Gemini Team. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2312.11805" title="" class="ltx_ref ltx_href">Gemini: A family of highly capable multimodal models</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guu et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2002.08909" title="" class="ltx_ref ltx_href">REALM: retrieval-augmented language model pre-training</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2002.08909.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tianyu Han, Lisa&nbsp;C. Adams, Jens-Michalis Papaioannou, Paul Grundmann, Tom Oberhauser, Alexander Löser, Daniel Truhn, and Keno&nbsp;K. Bressem. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2304.08247" title="" class="ltx_ref ltx_href">Medalpaca - an open-source collection of medical conversational AI models and training data</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2304.08247.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Junxian He, Graham Neubig, and Taylor Berg-Kirkpatrick. 2021.

</span>
<span class="ltx_bibblock">Efficient nearest neighbor language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language Processing</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Nathan Hu, Eric Mitchell, Christopher&nbsp;D. Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2023.emnlp-main.268" title="" class="ltx_ref ltx_href">Meta-learning online adaptation of language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023</em>, pages 4418–4432. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ivison et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Hamish Ivison, Yizhong Wang, Valentina Pyatkin, Nathan Lambert, Matthew Peters, Pradeep Dasigi, Joel Jang, David Wadden, Noah&nbsp;A. Smith, Iz&nbsp;Beltagy, and Hannaneh Hajishirzi. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2311.10702" title="" class="ltx_ref ltx_href">Camels in a changing climate: Enhancing LM adaptation with tulu 2</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.10702.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iyer et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Srinivasan Iyer, Xi&nbsp;Victoria Lin, Ramakanth Pasunuru, Todor Mihaylov, Daniel Simig, Ping Yu, Kurt Shuster, Tianlu Wang, Qing Liu, Punit&nbsp;Singh Koura, Xian Li, Brian O’Horo, Gabriel Pereyra, Jeff Wang, Christopher Dewan, Asli Celikyilmaz, Luke Zettlemoyer, and Ves Stoyanov. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2212.12017" title="" class="ltx_ref ltx_href">OPT-IML: scaling language model instruction meta learning through the lens of generalization</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2212.12017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Gautier Izacard, Patrick S.&nbsp;H. Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://jmlr.org/papers/v24/23-0037.html" title="" class="ltx_ref ltx_href">Atlas: Few-shot learning with retrieval augmented language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">J. Mach. Learn. Res.</em>, 24:251:1–251:43.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Joel Jang, Seonghyeon Ye, Sohee Yang, Joongbo Shin, Janghoon Han, Gyeonghun Kim, Stanley&nbsp;Jungkyu Choi, and Minjoon Seo. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=vfsRB5MImo9" title="" class="ltx_ref ltx_href">Towards continual knowledge learning of language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Zhengbao Jiang, Luyu Gao, Zhiruo Wang, Jun Araki, Haibo Ding, Jamie Callan, and Graham Neubig. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2022.EMNLP-MAIN.149" title="" class="ltx_ref ltx_href">Retrieval as attention: End-to-end learning of retrieval and reading within a single transformer</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, pages 2336–2349. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Zhengbao Jiang, Frank&nbsp;F. Xu, Jun Araki, and Graham Neubig. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00324" title="" class="ltx_ref ltx_href">How can we know what language models know</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Trans. Assoc. Comput. Linguistics</em>, 8:423–438.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhengbao Jiang, Frank&nbsp;F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, and Graham Neubig. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2023.emnlp-main.495" title="" class="ltx_ref ltx_href">Active retrieval augmented generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023</em>, pages 7969–7992. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kopf et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Andreas Kopf, Yannic Kilcher, Dimitri von Rutte, Sotiris Anagnostidis, Zhi&nbsp;Rui Tam, Keith Stevens, Abdullah Barhoum, Nguyen&nbsp;Minh Duc, Oliver Stanley, Rich’ard Nagyfi, ES&nbsp;Shahul, Sameer Suri, David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, and Alexander Mattick. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258179434" title="" class="ltx_ref ltx_href">Openassistant conversations - democratizing large language model alignment</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2304.07327.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur&nbsp;P. Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew&nbsp;M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00276" title="" class="ltx_ref ltx_href">Natural questions: a benchmark for question answering research</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Trans. Assoc. Comput. Linguistics</em>, 7:452–466.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Haejun Lee, Akhil Kedia, Jongwon Lee, Ashwin Paranjape, Christopher&nbsp;D. Manning, and Kyoung-Gu Woo. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2022.EMNLP-MAIN.198" title="" class="ltx_ref ltx_href">You only need one model for open-domain question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022</em>, pages 3047–3060. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2020a)</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.703" title="" class="ltx_ref ltx_href">BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020</em>, pages 7871–7880. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2020b)</span>
<span class="ltx_bibblock">
Patrick S.&nbsp;H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2020b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper/2020/hash/6b493230205f780e1bc26945df7481e5-Abstract.html" title="" class="ltx_ref ltx_href">Retrieval-augmented generation for knowledge-intensive NLP tasks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Xi&nbsp;Victoria Lin, Xilun Chen, Mingda Chen, Weijia Shi, Maria Lomeli, Rich James, Pedro Rodriguez, Jacob Kahn, Gergely Szilvasy, Mike Lewis, Luke Zettlemoyer, and Scott Yih. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2310.01352" title="" class="ltx_ref ltx_href">RA-DIT: retrieval-augmented dual instruction tuning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.01352.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2019)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=Bkg6RiCqY7" title="" class="ltx_ref ltx_href">Decoupled weight decay regularization</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2022.ACL-LONG.244" title="" class="ltx_ref ltx_href">Cross-task generalization via natural language crowdsourcing instructions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022</em>, pages 3470–3487. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nakano et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu&nbsp;Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2112.09332" title="" class="ltx_ref ltx_href">Webgpt: Browser-assisted question-answering with human feedback</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2112.09332.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tuan&nbsp;Dung Nguyen, Yuan-Sen Ting, Ioana Ciuca, Charlie O’Neill, Ze-Chang Sun, Maja Jablonska, Sandor Kruk, Ernest Perkowski, Jack&nbsp;W. Miller, Jason Li, Josh Peek, Kartheik Iyer, Tomasz Rózanski, Pranav Khetarpal, Sharaf Zaman, David Brodrick, Sergio J.&nbsp;Rodríguez Méndez, Thang Bui, Alyssa Goodman, Alberto Accomazzi, Jill&nbsp;P. Naiman, Jesse Cranney, Kevin Schawinski, and UniverseTBD. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2309.06126" title="" class="ltx_ref ltx_href">Astrollama: Towards specialized foundation models in astronomy</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.06126.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2303.08774" title="" class="ltx_ref ltx_href">GPT-4 technical report</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.08774.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeff Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll&nbsp;L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul&nbsp;F. Christiano, Jan Leike, and Ryan Lowe. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2203.02155" title="" class="ltx_ref ltx_href">Training language models to follow instructions with human feedback</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2203.02155.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ovadia et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Oded Ovadia, Menachem Brief, Moshik Mishaeli, and Oren Elisha. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2312.05934" title="" class="ltx_ref ltx_href">Fine-tuning or retrieval? comparing knowledge injection in llms</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2312.05934.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Fabio Petroni, Tim Rocktäschel, Sebastian Riedel, Patrick S.&nbsp;H. Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander&nbsp;H. Miller. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/D19-1250" title="" class="ltx_ref ltx_href">Language models as knowledge bases?</a>

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019</em>, pages 2463–2473. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yujia Qin, Zihan Cai, Dian Jin, Lan Yan, Shihao Liang, Kunlun Zhu, Yankai Lin, Xu&nbsp;Han, Ning Ding, Huadong Wang, Ruobing Xie, Fanchao Qi, Zhiyuan Liu, Maosong Sun, and Jie Zhou. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2305.06849" title="" class="ltx_ref ltx_href">Webcpm: Interactive web search for chinese long-form question answering</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.06849.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf" title="" class="ltx_ref ltx_href">Language models are unsupervised multitask learners</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">OpenAI Blog</em>, 1(8).

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher&nbsp;D. Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2305.18290" title="" class="ltx_ref ltx_href">Direct preference optimization: Your language model is secretly a reward model</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.18290.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J. Liu. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://jmlr.org/papers/v21/20-074.html" title="" class="ltx_ref ltx_href">Exploring the limits of transfer learning with a unified text-to-text transformer</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">J. Mach. Learn. Res.</em>, 21:140:1–140:67.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roberts et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Adam Roberts, Colin Raffel, and Noam Shazeer. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.emnlp-main.437" title="" class="ltx_ref ltx_href">How much knowledge can you pack into the parameters of a language model?</a>

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020</em>, pages 5418–5426. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sachan et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Devendra&nbsp;Singh Sachan, Siva Reddy, William&nbsp;L. Hamilton, Chris Dyer, and Dani Yogatama. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://proceedings.neurips.cc/paper/2021/hash/da3fde159d754a2555eaa198d2d105b2-Abstract.html" title="" class="ltx_ref ltx_href">End-to-end training of multi-document reader and retriever for open-domain question answering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual</em>, pages 25968–25981.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanh et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Victor Sanh, Albert Webson, Colin Raffel, Stephen&nbsp;H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M&nbsp;Saiful Bari, Canwen Xu, Urmish Thakker, Shanya&nbsp;Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal&nbsp;V. Nayak, Debajyoti Datta, Jonathan Chang, Mike&nbsp;Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng&nbsp;Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Févry, Jason&nbsp;Alan Fries, Ryan Teehan, Teven&nbsp;Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander&nbsp;M. Rush. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=9Vrb9D0WI4" title="" class="ltx_ref ltx_href">Multitask prompted training enables zero-shot task generalization</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau Yih. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2301.12652" title="" class="ltx_ref ltx_href">REPLUG: retrieval-augmented black-box language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2301.12652.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Zhiqing Sun, Yikang Shen, Hongxin Zhang, Qinhong Zhou, Zhenfang Chen, David&nbsp;D. Cox, Yiming Yang, and Chuang Gan. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2310.05910" title="" class="ltx_ref ltx_href">SALMON: self-alignment with principle-following reward models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.05910.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David&nbsp;D. Cox, Yiming Yang, and Chuang Gan. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2305.03047" title="" class="ltx_ref ltx_href">Principle-driven self-alignment of language models from scratch with minimal human supervision</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.03047.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori&nbsp;B. Hashimoto. 2023.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tatsu-lab/stanford_alpaca</a>.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tian et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Katherine Tian, Eric Mitchell, Huaxiu Yao, Christopher&nbsp;D. Manning, and Chelsea Finn. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2311.08401" title="" class="ltx_ref ltx_href">Fine-tuning language models for factuality</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.08401.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tirumala et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Kushal Tirumala, Aram&nbsp;H. Markosyan, Luke Zettlemoyer, and Armen Aghajanyan. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://papers.nips.cc/paper_files/paper/2022/hash/fa0509f4dab6807e2cb465715bf2d249-Abstract-Conference.html" title="" class="ltx_ref ltx_href">Memorization without overfitting: Analyzing the training dynamics of large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022</em>.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurélien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2302.13971" title="" class="ltx_ref ltx_href">Llama: Open and efficient foundation language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2302.13971.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit&nbsp;Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric&nbsp;Michael Smith, Ranjan Subramanian, Xiaoqing&nbsp;Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian&nbsp;Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurélien Rodriguez, Robert Stojnic, Sergey Edunov,
and Thomas Scialom. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2307.09288" title="" class="ltx_ref ltx_href">Llama 2: Open foundation and fine-tuned chat models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.09288.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Boxin Wang, Wei Ping, Peng Xu, Lawrence McAfee, Zihan Liu, Mohammad Shoeybi, Yi&nbsp;Dong, Oleksii Kuchaiev, Bo&nbsp;Li, Chaowei Xiao, Anima Anandkumar, and Bryan Catanzaro. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2023.emnlp-main.482" title="" class="ltx_ref ltx_href">Shall we pretrain autoregressive language models with retrieval? A comprehensive study</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023</em>, pages 7763–7786. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Cunxiang Wang, Pai Liu, and Yue Zhang. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2021.ACL-LONG.251" title="" class="ltx_ref ltx_href">Can generative pre-trained language models serve as knowledge bases for closed-book qa?</a>

</span>
<span class="ltx_bibblock">In <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021</em>, pages 3241–3251. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi&nbsp;Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah&nbsp;A. Smith, Iz&nbsp;Beltagy, and Hannaneh Hajishirzi. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2306.04751" title="" class="ltx_ref ltx_href">How far can camels go? exploring the state of instruction tuning on open resources</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2306.04751.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent&nbsp;Y. Zhao, Kelvin Guu, Adams&nbsp;Wei Yu, Brian Lester, Nan Du, Andrew&nbsp;M. Dai, and Quoc&nbsp;V. Le. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=gEZrGCozdqR" title="" class="ltx_ref ltx_href">Finetuned language models are zero-shot learners</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>. OpenReview.net.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chaoyi Wu, Weixiong Lin, Xiaoman Zhang, Ya&nbsp;Zhang, Yanfeng Wang, and Weidi Xie. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2304.14454" title="" class="ltx_ref ltx_href">Pmc-llama: Towards building open-source language models for medicine</a>.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Mengzhou Xia, Mikel Artetxe, Chunting Zhou, Xi&nbsp;Victoria Lin, Ramakanth Pasunuru, Danqi Chen, Luke Zettlemoyer, and Veselin Stoyanov. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2023.ACL-LONG.767" title="" class="ltx_ref ltx_href">Training trajectories of language models across scales</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, pages 13711–13738. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Ruohong Zhang, Luyu Gao, Chen Zheng, Zhen Fan, Guokun Lai, Zheng Zhang, Fangzhou Ai, Yiming Yang, and Hongxia Yang. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2311.10614" title="" class="ltx_ref ltx_href">A self-enhancement approach for domain-specific chatbot training via knowledge mining and digest</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.10614.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi&nbsp;Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit&nbsp;Singh Koura, Anjali Sridhar, Tianlu Wang, and Luke Zettlemoyer. 2022.

</span>
<span class="ltx_bibblock">Opt: Open pre-trained transformer language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2205.01068.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Wayne&nbsp;Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2303.18223" title="" class="ltx_ref ltx_href">A survey of large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.18223.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, Susan Zhang, Gargi Ghosh, Mike Lewis, Luke Zettlemoyer, and Omer Levy. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2305.11206" title="" class="ltx_ref ltx_href">LIMA: less is more for alignment</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2305.11206.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu and Li (2023a)</span>
<span class="ltx_bibblock">
Zeyuan&nbsp;Allen Zhu and Yuanzhi Li. 2023a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2309.14316" title="" class="ltx_ref ltx_href">Physics of language models: Part 3.1, knowledge storage and extraction</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.14316.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu and Li (2023b)</span>
<span class="ltx_bibblock">
Zeyuan&nbsp;Allen Zhu and Yuanzhi Li. 2023b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2309.14402" title="" class="ltx_ref ltx_href">Physics of language models: Part 3.2, knowledge manipulation</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2309.14402.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2402.12846" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2402.12847" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2402.12847">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2402.12847" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2402.12848" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar  5 14:57:27 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>