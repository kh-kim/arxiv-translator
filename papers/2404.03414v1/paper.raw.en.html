<html lang="en" data-theme="light"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought</title>
<!--Generated on Thu Apr  4 12:45:04 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css">
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2404.03414v1/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2404.03414v1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <span class="color-scheme-icon" aria-label="Light mode"></span>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="#myForm" onclick="event.preventDefault(); var modal = document.getElementById('myForm'); modal.style.display = 'block'; bugReportState.setInitiateWay('Header');">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2404.03414v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2404.03414v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
          <span class="color-scheme-icon"></span>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S1" title="1. Introduction ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S2" title="2. Related Work ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S3" title="3. LM-guided Chain-of-Thought ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>LM-guided Chain-of-Thought</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S3.SS1" title="3.1. Rationale Distillation ‚Ä£ 3. LM-guided Chain-of-Thought ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Rationale Distillation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S3.SS2" title="3.2. Rationale Refinement ‚Ä£ 3. LM-guided Chain-of-Thought ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Rationale Refinement</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S4" title="4. Experiments and Results ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments and Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S4.SS1" title="4.1. Experimental Setup ‚Ä£ 4. Experiments and Results ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Experimental Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S4.SS2" title="4.2. Results ‚Ä£ 4. Experiments and Results ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Results</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S5" title="5. Conclusion ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S6" title="6. Limitations ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S7" title="7. Ethical Considerations ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Ethical Considerations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S8" title="8. Acknowledgments ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Acknowledgments</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S9" title="9. Bibliographical References ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Bibliographical References</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S10" title="10. Language Resource References ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">10 </span>Language Resource References</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S11" title="11. Appendices ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11 </span>Appendices</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S11.SS1" title="11.1. Human Annotation for Rationale Quality Measurement ‚Ä£ 11. Appendices ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11.1 </span>Human Annotation for Rationale Quality Measurement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S11.SS2" title="11.2. Automatic Measurement for Rationale Quality ‚Ä£ 11. Appendices ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11.2 </span>Automatic Measurement for Rationale Quality</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S11.SS3" title="11.3. Training Configuration ‚Ä£ 11. Appendices ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">11.3 </span>Training Configuration</span></a></li>
</ol>
</li>
</ol></nav>

<div class="ltx_page_content">
<div aria-label="Conversion errors have been found" class="package-alerts ltx_document" role="status">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewBox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: dingbat</li>
<li>failed: bigfoot</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><div class="section" id="target-section"><div id="license-tr">License: CC BY 4.0</div><div id="watermark-tr">arXiv:2404.03414v1 [cs.CL] 04 Apr 2024</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Can Small Language Models Help Large Language Models Reason Better?: <span class="ltx_text ltx_font_italic" id="id1.id1">LM-Guided Chain-of-Thought</span>
</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id2.id1">We introduce a novel framework, <span class="ltx_text ltx_font_bold" id="id2.id1.1">LM-Guided CoT</span>, that leverages a lightweight (<span class="ltx_text ltx_font_italic" id="id2.id1.2">i.e.</span>, &lt;1B) language model (LM) for guiding a black-box large (<span class="ltx_text ltx_font_italic" id="id2.id1.3">i.e.</span>, &gt;10B) LM in reasoning tasks. Specifically, the lightweight LM first generates a rationale for each input instance. The Frozen large LM is then prompted to predict a task output based on the rationale generated by the lightweight LM. Our approach is resource-efficient in the sense that it only requires training the lightweight LM. We optimize the model through 1) knowledge distillation and 2) reinforcement learning from rationale-oriented and task-oriented reward signals. We assess our method with multi-hop extractive question answering (QA) benchmarks, HotpotQA, and 2WikiMultiHopQA. Experimental results show that our approach outperforms all baselines regarding answer prediction accuracy. We also find that reinforcement learning helps the model to produce higher-quality rationales with improved QA performance. 
<br class="ltx_break">
<br class="ltx_break">
<span class="ltx_text ltx_font_bold" id="id2.id1.4">Keywords:‚Äâ</span>Chain-of-Thought Prompting, Large Language Model, Reinforcement Learning, Knowledge Distillation</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<span class="ltx_ERROR undefined" id="id1">\useunder</span>
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1"><span class="ltx_text ltx_ulem_uline" id="p1.1.1"></span><span class="ltx_text ltx_framed_underline" id="p1.1.2"></span>
<span class="ltx_ERROR undefined" id="p1.1.3">\NAT@set@cites</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para" id="p2">
<p class="ltx_p" id="p2.1"><span class="ltx_text" id="p2.1.1"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_align_center" id="p3">
<p class="ltx_p" id="p3.1"><span class="ltx_text ltx_font_bold" id="p3.1.1" style="font-size:144%;">Can Small Language Models Help Large Language Models Reason Better?: <span class="ltx_text ltx_font_medium ltx_font_italic" id="p3.1.1.1">LM-Guided Chain-of-Thought</span></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_align_center" id="p4">
<table class="ltx_tabular ltx_align_top" id="p4.10">
<tbody><tr class="ltx_tr" id="p4.8.8">
<td class="ltx_td ltx_align_center" id="p4.8.8.8">
<div class="ltx_block ltx_parbox ltx_align_middle" id="p4.8.8.8.8" style="width:433.6pt;">
<p class="ltx_p ltx_align_center" id="p4.5.5.5.5.5"><span class="ltx_text ltx_font_bold" id="p4.5.5.5.5.5.2" style="font-size:120%;">Jooyoung Lee</span><math alttext="{}^{1{\dagger}}" class="ltx_Math" display="inline" id="p4.1.1.1.1.1.m1.2"><semantics id="p4.1.1.1.1.1.m1.2a"><msup id="p4.1.1.1.1.1.m1.2.2" xref="p4.1.1.1.1.1.m1.2.2.cmml"><mi id="p4.1.1.1.1.1.m1.2.2a" xref="p4.1.1.1.1.1.m1.2.2.cmml"></mi><mrow id="p4.1.1.1.1.1.m1.2.2.2.4" xref="p4.1.1.1.1.1.m1.2.2.2.3.cmml"><mn id="p4.1.1.1.1.1.m1.1.1.1.1" mathsize="120%" xref="p4.1.1.1.1.1.m1.1.1.1.1.cmml">1</mn><mo id="p4.1.1.1.1.1.m1.2.2.2.4.1" lspace="0.222em" xref="p4.1.1.1.1.1.m1.2.2.2.3.cmml">‚Å£</mo><mo id="p4.1.1.1.1.1.m1.2.2.2.2" mathsize="120%" xref="p4.1.1.1.1.1.m1.2.2.2.2.cmml">‚Ä†</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p4.1.1.1.1.1.m1.2b"><apply id="p4.1.1.1.1.1.m1.2.2.cmml" xref="p4.1.1.1.1.1.m1.2.2"><list id="p4.1.1.1.1.1.m1.2.2.2.3.cmml" xref="p4.1.1.1.1.1.m1.2.2.2.4"><cn id="p4.1.1.1.1.1.m1.1.1.1.1.cmml" type="integer" xref="p4.1.1.1.1.1.m1.1.1.1.1">1</cn><ci id="p4.1.1.1.1.1.m1.2.2.2.2.cmml" xref="p4.1.1.1.1.1.m1.2.2.2.2">‚Ä†</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="p4.1.1.1.1.1.m1.2c">{}^{1{\dagger}}</annotation><annotation encoding="application/x-llamapun" id="p4.1.1.1.1.1.m1.2d">start_FLOATSUPERSCRIPT 1 ‚Ä† end_FLOATSUPERSCRIPT</annotation></semantics></math><span class="ltx_note ltx_role_thanks" id="p4.2.2.2.2.2.1"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">thanks: </span><math alttext="{}^{\dagger}" class="ltx_Math" display="inline" id="p4.2.2.2.2.2.1.m1.1"><semantics id="p4.2.2.2.2.2.1.m1.1b"><msup id="p4.2.2.2.2.2.1.m1.1.1" xref="p4.2.2.2.2.2.1.m1.1.1.cmml"><mi id="p4.2.2.2.2.2.1.m1.1.1b" xref="p4.2.2.2.2.2.1.m1.1.1.cmml"></mi><mo id="p4.2.2.2.2.2.1.m1.1.1.1" mathsize="120%" xref="p4.2.2.2.2.2.1.m1.1.1.1.cmml">‚Ä†</mo></msup><annotation-xml encoding="MathML-Content" id="p4.2.2.2.2.2.1.m1.1c"><apply id="p4.2.2.2.2.2.1.m1.1.1.cmml" xref="p4.2.2.2.2.2.1.m1.1.1"><ci id="p4.2.2.2.2.2.1.m1.1.1.1.cmml" xref="p4.2.2.2.2.2.1.m1.1.1.1">‚Ä†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p4.2.2.2.2.2.1.m1.1d">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="p4.2.2.2.2.2.1.m1.1e">start_FLOATSUPERSCRIPT ‚Ä† end_FLOATSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="p4.2.2.2.2.2.1.1" style="font-size:120%;">This work was done during the internship at Amazon.</span></span></span></span><span class="ltx_text ltx_font_bold" id="p4.5.5.5.5.5.3" style="font-size:120%;">, Fan Yang</span><math alttext="{}^{2}" class="ltx_Math" display="inline" id="p4.3.3.3.3.3.m2.1"><semantics id="p4.3.3.3.3.3.m2.1a"><msup id="p4.3.3.3.3.3.m2.1.1" xref="p4.3.3.3.3.3.m2.1.1.cmml"><mi id="p4.3.3.3.3.3.m2.1.1a" xref="p4.3.3.3.3.3.m2.1.1.cmml"></mi><mn id="p4.3.3.3.3.3.m2.1.1.1" mathsize="120%" xref="p4.3.3.3.3.3.m2.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p4.3.3.3.3.3.m2.1b"><apply id="p4.3.3.3.3.3.m2.1.1.cmml" xref="p4.3.3.3.3.3.m2.1.1"><cn id="p4.3.3.3.3.3.m2.1.1.1.cmml" type="integer" xref="p4.3.3.3.3.3.m2.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p4.3.3.3.3.3.m2.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p4.3.3.3.3.3.m2.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="p4.5.5.5.5.5.4" style="font-size:120%;">, Thanh Tran</span><math alttext="{}^{2}" class="ltx_Math" display="inline" id="p4.4.4.4.4.4.m3.1"><semantics id="p4.4.4.4.4.4.m3.1a"><msup id="p4.4.4.4.4.4.m3.1.1" xref="p4.4.4.4.4.4.m3.1.1.cmml"><mi id="p4.4.4.4.4.4.m3.1.1a" xref="p4.4.4.4.4.4.m3.1.1.cmml"></mi><mn id="p4.4.4.4.4.4.m3.1.1.1" mathsize="120%" xref="p4.4.4.4.4.4.m3.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p4.4.4.4.4.4.m3.1b"><apply id="p4.4.4.4.4.4.m3.1.1.cmml" xref="p4.4.4.4.4.4.m3.1.1"><cn id="p4.4.4.4.4.4.m3.1.1.1.cmml" type="integer" xref="p4.4.4.4.4.4.m3.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p4.4.4.4.4.4.m3.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p4.4.4.4.4.4.m3.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="p4.5.5.5.5.5.5" style="font-size:120%;">, Qian Hu</span><math alttext="{}^{2}" class="ltx_Math" display="inline" id="p4.5.5.5.5.5.m4.1"><semantics id="p4.5.5.5.5.5.m4.1a"><msup id="p4.5.5.5.5.5.m4.1.1" xref="p4.5.5.5.5.5.m4.1.1.cmml"><mi id="p4.5.5.5.5.5.m4.1.1a" xref="p4.5.5.5.5.5.m4.1.1.cmml"></mi><mn id="p4.5.5.5.5.5.m4.1.1.1" mathsize="120%" xref="p4.5.5.5.5.5.m4.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p4.5.5.5.5.5.m4.1b"><apply id="p4.5.5.5.5.5.m4.1.1.cmml" xref="p4.5.5.5.5.5.m4.1.1"><cn id="p4.5.5.5.5.5.m4.1.1.1.cmml" type="integer" xref="p4.5.5.5.5.5.m4.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p4.5.5.5.5.5.m4.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p4.5.5.5.5.5.m4.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="p4.5.5.5.5.5.6" style="font-size:120%;"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p ltx_align_center" id="p4.8.8.8.8.8"><span class="ltx_text ltx_font_bold" id="p4.8.8.8.8.8.1" style="font-size:120%;">Emre Barut</span><math alttext="{}^{2}" class="ltx_Math" display="inline" id="p4.6.6.6.6.6.m1.1"><semantics id="p4.6.6.6.6.6.m1.1a"><msup id="p4.6.6.6.6.6.m1.1.1" xref="p4.6.6.6.6.6.m1.1.1.cmml"><mi id="p4.6.6.6.6.6.m1.1.1a" xref="p4.6.6.6.6.6.m1.1.1.cmml"></mi><mn id="p4.6.6.6.6.6.m1.1.1.1" mathsize="120%" xref="p4.6.6.6.6.6.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p4.6.6.6.6.6.m1.1b"><apply id="p4.6.6.6.6.6.m1.1.1.cmml" xref="p4.6.6.6.6.6.m1.1.1"><cn id="p4.6.6.6.6.6.m1.1.1.1.cmml" type="integer" xref="p4.6.6.6.6.6.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p4.6.6.6.6.6.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p4.6.6.6.6.6.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="p4.8.8.8.8.8.2" style="font-size:120%;">, Kai-Wei Chang</span><math alttext="{}^{2}" class="ltx_Math" display="inline" id="p4.7.7.7.7.7.m2.1"><semantics id="p4.7.7.7.7.7.m2.1a"><msup id="p4.7.7.7.7.7.m2.1.1" xref="p4.7.7.7.7.7.m2.1.1.cmml"><mi id="p4.7.7.7.7.7.m2.1.1a" xref="p4.7.7.7.7.7.m2.1.1.cmml"></mi><mn id="p4.7.7.7.7.7.m2.1.1.1" mathsize="120%" xref="p4.7.7.7.7.7.m2.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p4.7.7.7.7.7.m2.1b"><apply id="p4.7.7.7.7.7.m2.1.1.cmml" xref="p4.7.7.7.7.7.m2.1.1"><cn id="p4.7.7.7.7.7.m2.1.1.1.cmml" type="integer" xref="p4.7.7.7.7.7.m2.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p4.7.7.7.7.7.m2.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p4.7.7.7.7.7.m2.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="p4.8.8.8.8.8.3" style="font-size:120%;">, Chengwei Su</span><math alttext="{}^{2}" class="ltx_Math" display="inline" id="p4.8.8.8.8.8.m3.1"><semantics id="p4.8.8.8.8.8.m3.1a"><msup id="p4.8.8.8.8.8.m3.1.1" xref="p4.8.8.8.8.8.m3.1.1.cmml"><mi id="p4.8.8.8.8.8.m3.1.1a" xref="p4.8.8.8.8.8.m3.1.1.cmml"></mi><mn id="p4.8.8.8.8.8.m3.1.1.1" mathsize="120%" xref="p4.8.8.8.8.8.m3.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p4.8.8.8.8.8.m3.1b"><apply id="p4.8.8.8.8.8.m3.1.1.cmml" xref="p4.8.8.8.8.8.m3.1.1"><cn id="p4.8.8.8.8.8.m3.1.1.1.cmml" type="integer" xref="p4.8.8.8.8.8.m3.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p4.8.8.8.8.8.m3.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p4.8.8.8.8.8.m3.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="p4.8.8.8.8.8.4" style="font-size:120%;"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</td>
</tr>
<tr class="ltx_tr" id="p4.9.9">
<td class="ltx_td ltx_align_center" id="p4.9.9.1">Penn State University, PA, USA<math alttext="{}^{1}" class="ltx_Math" display="inline" id="p4.9.9.1.m1.1"><semantics id="p4.9.9.1.m1.1a"><msup id="p4.9.9.1.m1.1.1" xref="p4.9.9.1.m1.1.1.cmml"><mi id="p4.9.9.1.m1.1.1a" xref="p4.9.9.1.m1.1.1.cmml"></mi><mn id="p4.9.9.1.m1.1.1.1" xref="p4.9.9.1.m1.1.1.1.cmml">1</mn></msup><annotation-xml encoding="MathML-Content" id="p4.9.9.1.m1.1b"><apply id="p4.9.9.1.m1.1.1.cmml" xref="p4.9.9.1.m1.1.1"><cn id="p4.9.9.1.m1.1.1.1.cmml" type="integer" xref="p4.9.9.1.m1.1.1.1">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p4.9.9.1.m1.1c">{}^{1}</annotation><annotation encoding="application/x-llamapun" id="p4.9.9.1.m1.1d">start_FLOATSUPERSCRIPT 1 end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="p4.10.10">
<td class="ltx_td ltx_align_center" id="p4.10.10.1">Amazon AGI, MA, USA<math alttext="{}^{2}" class="ltx_Math" display="inline" id="p4.10.10.1.m1.1"><semantics id="p4.10.10.1.m1.1a"><msup id="p4.10.10.1.m1.1.1" xref="p4.10.10.1.m1.1.1.cmml"><mi id="p4.10.10.1.m1.1.1a" xref="p4.10.10.1.m1.1.1.cmml"></mi><mn id="p4.10.10.1.m1.1.1.1" xref="p4.10.10.1.m1.1.1.1.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="p4.10.10.1.m1.1b"><apply id="p4.10.10.1.m1.1.1.cmml" xref="p4.10.10.1.m1.1.1"><cn id="p4.10.10.1.m1.1.1.1.cmml" type="integer" xref="p4.10.10.1.m1.1.1.1">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="p4.10.10.1.m1.1c">{}^{2}</annotation><annotation encoding="application/x-llamapun" id="p4.10.10.1.m1.1d">start_FLOATSUPERSCRIPT 2 end_FLOATSUPERSCRIPT</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="p4.10.11">
<td class="ltx_td ltx_align_center" id="p4.10.11.1">jfl5838@psu.edu,
{fyaamz, tdt, huqia, ebarut, kaiwec, chengwes}@amazon.com</td>
</tr>
</tbody></table>
<br class="ltx_break">
<p class="ltx_p" id="p4.11"><span class="ltx_text ltx_font_italic" id="p4.11.1">Abstract content</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">1.&nbsp;&nbsp;&nbsp;Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Chain-of-Thought (CoT) prompting <cite class="ltx_cite ltx_citemacro_cite">Wei et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib22" title="">2022b</a>)</cite> has gained attention as a means to elicit the inherent reasoning abilities of a language model (LM). By prompting the models with <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">‚ÄúLet‚Äôs think step by step‚Äù</span> following the actual task description, the model first produces intermediate reasoning steps and then predicts a task output. It has been shown to enhance the downstream task performance in complex reasoning domains such as arithmetic <cite class="ltx_cite ltx_citemacro_cite">Lewkowycz et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib8" title="">2022</a>)</cite>, commonsense <cite class="ltx_cite ltx_citemacro_cite">Jung et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib5" title="">2022</a>)</cite>, and symbolic <cite class="ltx_cite ltx_citemacro_cite">Khot et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib6" title="">2022</a>)</cite> reasoning. However, there are several limitations to conventional CoT prompting. Firstly, the performance gains when compared to standard prompting (<span class="ltx_text ltx_font_italic" id="S1.p1.1.2">i.e.</span>, without <span class="ltx_text ltx_font_italic" id="S1.p1.1.3">‚ÄúLet‚Äôs think step by step‚Äù</span>) are only likely to emerge in very large LMs, preferably 100+ billion parameters <cite class="ltx_cite ltx_citemacro_cite">Wei et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib21" title="">2022a</a>)</cite>. Moreover, the models may still generate low-quality rationales that are repetitive and vacuous <cite class="ltx_cite ltx_citemacro_cite">Ye and Durrett (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib23" title="">2022</a>)</cite>. This can be attributed to their tendencies to lack faithfulness to an input instance <cite class="ltx_cite ltx_citemacro_cite">Lanham et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib7" title="">2023</a>)</cite> and to produce unaligned rationales and answers <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib20" title="">2022b</a>); Turpin et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib17" title="">2023</a>)</cite>. </p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Given that CoT prompting is primarily effective with large LMs, rectifying these undesirable behaviors through direct model modifications is non-trivial, particularly with constrained computational resources. Hence, we propose <span class="ltx_text ltx_font_bold" id="S1.p2.1.1">LM-guided CoT</span>, a novel framework that leverages two independent LMs (<span class="ltx_text ltx_font_italic" id="S1.p2.1.2">i.e.</span>, a small LM for rationale generation and a large LM for answer prediction) for CoT reasoning. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S1.F1" title="Figure 1 ‚Ä£ 1. Introduction ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">1</span></a>, we first employ a vanilla knowledge distillation (KD) technique to the small LM with rationales generated by the large LM (¬ß<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S3.SS1" title="3.1. Rationale Distillation ‚Ä£ 3. LM-guided Chain-of-Thought ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">3.1</span></a>).
This initial step helps narrow the gap in reasoning capabilities between the smaller and larger LMs to a certain extent. To further improve the quality of rationales generated by the knowledge-distilled LM, we establish fine-grained measurements concerning 8 rationale-specific aspects (relevance, actuality, logicality, consistency, coherence, fluency, naturalness, and readability) and use them to optimize the knowledge-distilled LM with reinforcement learning (RL) (¬ß<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S3.SS2" title="3.2. Rationale Refinement ‚Ä£ 3. LM-guided Chain-of-Thought ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">3.2</span></a>).</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="467" id="S1.F1.g1" src="x1.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Illustration of our proposed method.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">We conduct experiments on an extractive multi-hop question answering (QA) task using two popular benchmarks, HotpotQA <cite class="ltx_cite ltx_citemacro_cite">Yang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#biba.bib2" title="">2018</a>)</cite> and 2WikiMultiHopQA <cite class="ltx_cite ltx_citemacro_cite">Ho et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#biba.bib1" title="">2020</a>)</cite>. Although our framework can be flexibly applied to a wide range of LMs, we use FLAN-T5 <cite class="ltx_cite ltx_citemacro_cite">Longpre et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib11" title="">2023</a>)</cite> models in this work because they are open-source and instruction-tuned on both QA and CoT data, enabling us to use it off-the-shelf without additional training or prompt engineering.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We also ran a small experiment with the <a class="ltx_ref ltx_href" href="https://huggingface.co/VMware/open-llama-7b-open-instruct" title="">instruction-tuned Open LLaMa (7B) model</a> and confirmed that its performance is significantly worse than FLAN-T5 in a zero-shot setting.</span></span></span> Our experiment results show that <span class="ltx_text ltx_ulem_uline" id="S1.p3.1.1">LM-guided CoT prompting outperforms both the standard prompting and the original CoT prompting.</span> More precisely, we find that (1) LM-guided CoT with KD and self-consistency (SC) decoding strategy <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib20" title="">2022b</a>)</cite> maximizes the performance gain; (2) RL contributes to a slight increase in overall rationale quality and task performance; (3) choosing the highest-quality rationales for the large LM does not always guarantee improved task performance. This work presents a unique alternative to the direct optimization of the large LM through fine-tuning the comparatively smaller LM. Moreover, the clear separation of two fundamental sub-tasks within CoT reasoning grants practitioners greater control over each task. </p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">2.&nbsp;&nbsp;&nbsp;Related Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.p1.1.1">Rationale Distillation.</span> For computation efficiency or task performance, recent literature has explored methods to improve small LMs‚Äô reasoning abilities. <cite class="ltx_cite ltx_citemacro_citet">Li et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib9" title="">2023</a>); Shridhar et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib15" title="">2023</a>); Ma et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib12" title="">2023</a>)</cite> have experimented with rationale distillation, where a small student LM learns from a large teacher LM to generate CoT rationales. While these studies have mainly concentrated on comparing its performance in downstream tasks against that of large LMs, there has been limited investigation into addressing errors in the generated rationales that might have been inherited from the teacher model.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Rationale Evaluation and Refinement.</span> In contexts beyond rationale distillation, there have been growing efforts to unravel which aspects of the generated reasoning steps contribute to the downstream task performance. <cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib18" title="">2022a</a>)</cite> report that rationales‚Äô logicality and relevance to the query are key factors in successful CoT reasoning. Few studies have measured the validity of reasoning steps from the lens of more diverse aspects like informativeness, coherence, and repetition, etc <cite class="ltx_cite ltx_citemacro_cite">Golovneva et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib3" title="">2022</a>); Prasad et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib13" title="">2023</a>)</cite>.
While RL has gained popularity as an approach for addressing misaligned behaviors in LMs, the field of rationale correction has seen limited research.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">3.&nbsp;&nbsp;&nbsp;LM-guided Chain-of-Thought</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.3">The proposed framework consists of two LMs: a lightweight model <math alttext="M^{S}" class="ltx_Math" display="inline" id="S3.p1.1.m1.1"><semantics id="S3.p1.1.m1.1a"><msup id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mi id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">M</mi><mi id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1">superscript</csymbol><ci id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">ùëÄ</ci><ci id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3">ùëÜ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">M^{S}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.1.m1.1d">italic_M start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT</annotation></semantics></math> that focuses on generating the optimal rationale given an input instance, and a black-box large model <math alttext="M^{L}" class="ltx_Math" display="inline" id="S3.p1.2.m2.1"><semantics id="S3.p1.2.m2.1a"><msup id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">M</mi><mi id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1">superscript</csymbol><ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">ùëÄ</ci><ci id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3">ùêø</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">M^{L}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.2.m2.1d">italic_M start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math> that predicts an output based on the rationale generated by <math alttext="M^{S}" class="ltx_Math" display="inline" id="S3.p1.3.m3.1"><semantics id="S3.p1.3.m3.1a"><msup id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><mi id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml">M</mi><mi id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1">superscript</csymbol><ci id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2">ùëÄ</ci><ci id="S3.p1.3.m3.1.1.3.cmml" xref="S3.p1.3.m3.1.1.3">ùëÜ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">M^{S}</annotation><annotation encoding="application/x-llamapun" id="S3.p1.3.m3.1d">italic_M start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT</annotation></semantics></math>. </p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T1.11">
<tbody><tr class="ltx_tr" id="S3.T1.11.12">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.11.12.1"><span class="ltx_text ltx_font_bold" id="S3.T1.11.12.1.1" style="font-size:90%;">Aspects</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.11.12.2"><span class="ltx_text ltx_font_bold" id="S3.T1.11.12.2.1" style="font-size:90%;">Descriptions</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.2.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.2.2.3"><span class="ltx_text" id="S3.T1.2.2.3.1" style="font-size:90%;">Factuality</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.2.2.2">
<span class="ltx_text" id="S3.T1.2.2.2.3" style="font-size:90%;">Percentage (0.0-1.0) measuring if the reasoning is grounded based on the context </span><span class="ltx_text ltx_font_italic" id="S3.T1.2.2.2.2" style="font-size:90%;color:#0000FF;">(Input: <math alttext="c" class="ltx_Math" display="inline" id="S3.T1.1.1.1.1.m1.1"><semantics id="S3.T1.1.1.1.1.m1.1a"><mi id="S3.T1.1.1.1.1.m1.1.1" mathcolor="#0000FF" xref="S3.T1.1.1.1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><ci id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1">ùëê</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.T1.1.1.1.1.m1.1d">italic_c</annotation></semantics></math> &amp; <math alttext="r^{\prime}" class="ltx_Math" display="inline" id="S3.T1.2.2.2.2.m2.1"><semantics id="S3.T1.2.2.2.2.m2.1a"><msup id="S3.T1.2.2.2.2.m2.1.1" xref="S3.T1.2.2.2.2.m2.1.1.cmml"><mi id="S3.T1.2.2.2.2.m2.1.1.2" mathcolor="#0000FF" xref="S3.T1.2.2.2.2.m2.1.1.2.cmml">r</mi><mo id="S3.T1.2.2.2.2.m2.1.1.3" mathcolor="#0000FF" mathvariant="normal" xref="S3.T1.2.2.2.2.m2.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.2.m2.1b"><apply id="S3.T1.2.2.2.2.m2.1.1.cmml" xref="S3.T1.2.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.T1.2.2.2.2.m2.1.1.1.cmml" xref="S3.T1.2.2.2.2.m2.1.1">superscript</csymbol><ci id="S3.T1.2.2.2.2.m2.1.1.2.cmml" xref="S3.T1.2.2.2.2.m2.1.1.2">ùëü</ci><ci id="S3.T1.2.2.2.2.m2.1.1.3.cmml" xref="S3.T1.2.2.2.2.m2.1.1.3">normal-‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.2.m2.1c">r^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.2.2.2.m2.1d">italic_r start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>)</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.4">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.4.4.3"><span class="ltx_text" id="S3.T1.4.4.3.1" style="font-size:90%;">Relevance</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.4.4.2">
<span class="ltx_text" id="S3.T1.4.4.2.3" style="font-size:90%;">Percentage (0.0-1.0) measuring if the reasoning is relevant to the question </span><span class="ltx_text ltx_font_italic" id="S3.T1.4.4.2.2" style="font-size:90%;color:#0000FF;">(Input: <math alttext="q" class="ltx_Math" display="inline" id="S3.T1.3.3.1.1.m1.1"><semantics id="S3.T1.3.3.1.1.m1.1a"><mi id="S3.T1.3.3.1.1.m1.1.1" mathcolor="#0000FF" xref="S3.T1.3.3.1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.1.1.m1.1b"><ci id="S3.T1.3.3.1.1.m1.1.1.cmml" xref="S3.T1.3.3.1.1.m1.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.T1.3.3.1.1.m1.1d">italic_q</annotation></semantics></math> &amp; <math alttext="r^{\prime}" class="ltx_Math" display="inline" id="S3.T1.4.4.2.2.m2.1"><semantics id="S3.T1.4.4.2.2.m2.1a"><msup id="S3.T1.4.4.2.2.m2.1.1" xref="S3.T1.4.4.2.2.m2.1.1.cmml"><mi id="S3.T1.4.4.2.2.m2.1.1.2" mathcolor="#0000FF" xref="S3.T1.4.4.2.2.m2.1.1.2.cmml">r</mi><mo id="S3.T1.4.4.2.2.m2.1.1.3" mathcolor="#0000FF" mathvariant="normal" xref="S3.T1.4.4.2.2.m2.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.2.2.m2.1b"><apply id="S3.T1.4.4.2.2.m2.1.1.cmml" xref="S3.T1.4.4.2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.T1.4.4.2.2.m2.1.1.1.cmml" xref="S3.T1.4.4.2.2.m2.1.1">superscript</csymbol><ci id="S3.T1.4.4.2.2.m2.1.1.2.cmml" xref="S3.T1.4.4.2.2.m2.1.1.2">ùëü</ci><ci id="S3.T1.4.4.2.2.m2.1.1.3.cmml" xref="S3.T1.4.4.2.2.m2.1.1.3">normal-‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.2.2.m2.1c">r^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.4.4.2.2.m2.1d">italic_r start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>)</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.11.13">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.11.13.1"><span class="ltx_text" id="S3.T1.11.13.1.1" style="font-size:90%;">Logicality</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.11.13.2"><span class="ltx_text" id="S3.T1.11.13.2.1" style="font-size:90%;">Binary (0 or 1) measuring if the reasoning is logical and can reach a final answer</span></td>
</tr>
<tr class="ltx_tr" id="S3.T1.6.6">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.6.6.3"><span class="ltx_text" id="S3.T1.6.6.3.1" style="font-size:90%;">Consistency</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.6.6.2">
<span class="ltx_text" id="S3.T1.6.6.2.3" style="font-size:90%;">Binary (0 or 1) measuring if the reasoning remains consistent and coherent </span><span class="ltx_text ltx_font_italic" id="S3.T1.6.6.2.2" style="font-size:90%;color:#0000FF;">(Input: <math alttext="q" class="ltx_Math" display="inline" id="S3.T1.5.5.1.1.m1.1"><semantics id="S3.T1.5.5.1.1.m1.1a"><mi id="S3.T1.5.5.1.1.m1.1.1" mathcolor="#0000FF" xref="S3.T1.5.5.1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.1.1.m1.1b"><ci id="S3.T1.5.5.1.1.m1.1.1.cmml" xref="S3.T1.5.5.1.1.m1.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.T1.5.5.1.1.m1.1d">italic_q</annotation></semantics></math> &amp; <math alttext="r^{\prime}" class="ltx_Math" display="inline" id="S3.T1.6.6.2.2.m2.1"><semantics id="S3.T1.6.6.2.2.m2.1a"><msup id="S3.T1.6.6.2.2.m2.1.1" xref="S3.T1.6.6.2.2.m2.1.1.cmml"><mi id="S3.T1.6.6.2.2.m2.1.1.2" mathcolor="#0000FF" xref="S3.T1.6.6.2.2.m2.1.1.2.cmml">r</mi><mo id="S3.T1.6.6.2.2.m2.1.1.3" mathcolor="#0000FF" mathvariant="normal" xref="S3.T1.6.6.2.2.m2.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.2.2.m2.1b"><apply id="S3.T1.6.6.2.2.m2.1.1.cmml" xref="S3.T1.6.6.2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.T1.6.6.2.2.m2.1.1.1.cmml" xref="S3.T1.6.6.2.2.m2.1.1">superscript</csymbol><ci id="S3.T1.6.6.2.2.m2.1.1.2.cmml" xref="S3.T1.6.6.2.2.m2.1.1.2">ùëü</ci><ci id="S3.T1.6.6.2.2.m2.1.1.3.cmml" xref="S3.T1.6.6.2.2.m2.1.1.3">normal-‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.2.2.m2.1c">r^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.6.6.2.2.m2.1d">italic_r start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>)</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.8.8">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.8.8.3"><span class="ltx_text" id="S3.T1.8.8.3.1" style="font-size:90%;">Coherence</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.8.8.2">
<span class="ltx_text" id="S3.T1.8.8.2.3" style="font-size:90%;">Binary (0 or 1) measuring if the reasoning is without redundant information </span><span class="ltx_text ltx_font_italic" id="S3.T1.8.8.2.2" style="font-size:90%;color:#0000FF;">(Input: <math alttext="q" class="ltx_Math" display="inline" id="S3.T1.7.7.1.1.m1.1"><semantics id="S3.T1.7.7.1.1.m1.1a"><mi id="S3.T1.7.7.1.1.m1.1.1" mathcolor="#0000FF" xref="S3.T1.7.7.1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.1.1.m1.1b"><ci id="S3.T1.7.7.1.1.m1.1.1.cmml" xref="S3.T1.7.7.1.1.m1.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.T1.7.7.1.1.m1.1d">italic_q</annotation></semantics></math> &amp; <math alttext="r^{\prime}" class="ltx_Math" display="inline" id="S3.T1.8.8.2.2.m2.1"><semantics id="S3.T1.8.8.2.2.m2.1a"><msup id="S3.T1.8.8.2.2.m2.1.1" xref="S3.T1.8.8.2.2.m2.1.1.cmml"><mi id="S3.T1.8.8.2.2.m2.1.1.2" mathcolor="#0000FF" xref="S3.T1.8.8.2.2.m2.1.1.2.cmml">r</mi><mo id="S3.T1.8.8.2.2.m2.1.1.3" mathcolor="#0000FF" mathvariant="normal" xref="S3.T1.8.8.2.2.m2.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.2.2.m2.1b"><apply id="S3.T1.8.8.2.2.m2.1.1.cmml" xref="S3.T1.8.8.2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.T1.8.8.2.2.m2.1.1.1.cmml" xref="S3.T1.8.8.2.2.m2.1.1">superscript</csymbol><ci id="S3.T1.8.8.2.2.m2.1.1.2.cmml" xref="S3.T1.8.8.2.2.m2.1.1.2">ùëü</ci><ci id="S3.T1.8.8.2.2.m2.1.1.3.cmml" xref="S3.T1.8.8.2.2.m2.1.1.3">normal-‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.2.2.m2.1c">r^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.8.8.2.2.m2.1d">italic_r start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>)</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.9.9">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.9.9.2"><span class="ltx_text" id="S3.T1.9.9.2.1" style="font-size:90%;">Fluency</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.9.9.1">
<span class="ltx_text" id="S3.T1.9.9.1.2" style="font-size:90%;">Binary (0 or 1) measuring if the reasoning is well-written and grammatically correct </span><span class="ltx_text ltx_font_italic" id="S3.T1.9.9.1.1" style="font-size:90%;color:#0000FF;">(Input: <math alttext="r^{\prime}" class="ltx_Math" display="inline" id="S3.T1.9.9.1.1.m1.1"><semantics id="S3.T1.9.9.1.1.m1.1a"><msup id="S3.T1.9.9.1.1.m1.1.1" xref="S3.T1.9.9.1.1.m1.1.1.cmml"><mi id="S3.T1.9.9.1.1.m1.1.1.2" mathcolor="#0000FF" xref="S3.T1.9.9.1.1.m1.1.1.2.cmml">r</mi><mo id="S3.T1.9.9.1.1.m1.1.1.3" mathcolor="#0000FF" mathvariant="normal" xref="S3.T1.9.9.1.1.m1.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.1.1.m1.1b"><apply id="S3.T1.9.9.1.1.m1.1.1.cmml" xref="S3.T1.9.9.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.9.9.1.1.m1.1.1.1.cmml" xref="S3.T1.9.9.1.1.m1.1.1">superscript</csymbol><ci id="S3.T1.9.9.1.1.m1.1.1.2.cmml" xref="S3.T1.9.9.1.1.m1.1.1.2">ùëü</ci><ci id="S3.T1.9.9.1.1.m1.1.1.3.cmml" xref="S3.T1.9.9.1.1.m1.1.1.3">normal-‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.1.1.m1.1c">r^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.9.9.1.1.m1.1d">italic_r start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>)</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.10.10">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.10.10.2"><span class="ltx_text" id="S3.T1.10.10.2.1" style="font-size:90%;">Naturalness</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.10.10.1">
<span class="ltx_text" id="S3.T1.10.10.1.2" style="font-size:90%;">Binary (0 or 1) measuring if the reasoning is natural and human-like </span><span class="ltx_text ltx_font_italic" id="S3.T1.10.10.1.1" style="font-size:90%;color:#0000FF;">(Input: <math alttext="r^{\prime}" class="ltx_Math" display="inline" id="S3.T1.10.10.1.1.m1.1"><semantics id="S3.T1.10.10.1.1.m1.1a"><msup id="S3.T1.10.10.1.1.m1.1.1" xref="S3.T1.10.10.1.1.m1.1.1.cmml"><mi id="S3.T1.10.10.1.1.m1.1.1.2" mathcolor="#0000FF" xref="S3.T1.10.10.1.1.m1.1.1.2.cmml">r</mi><mo id="S3.T1.10.10.1.1.m1.1.1.3" mathcolor="#0000FF" mathvariant="normal" xref="S3.T1.10.10.1.1.m1.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.1.1.m1.1b"><apply id="S3.T1.10.10.1.1.m1.1.1.cmml" xref="S3.T1.10.10.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.10.10.1.1.m1.1.1.1.cmml" xref="S3.T1.10.10.1.1.m1.1.1">superscript</csymbol><ci id="S3.T1.10.10.1.1.m1.1.1.2.cmml" xref="S3.T1.10.10.1.1.m1.1.1.2">ùëü</ci><ci id="S3.T1.10.10.1.1.m1.1.1.3.cmml" xref="S3.T1.10.10.1.1.m1.1.1.3">normal-‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.1.1.m1.1c">r^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.10.10.1.1.m1.1d">italic_r start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>)</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T1.11.11">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T1.11.11.2"><span class="ltx_text" id="S3.T1.11.11.2.1" style="font-size:90%;">Readability</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T1.11.11.1">
<span class="ltx_text" id="S3.T1.11.11.1.2" style="font-size:90%;">Binary (0 or 1) measuring if the reasoning is easy to follow and understandable </span><span class="ltx_text ltx_font_italic" id="S3.T1.11.11.1.1" style="font-size:90%;color:#0000FF;">(Input: <math alttext="r^{\prime}" class="ltx_Math" display="inline" id="S3.T1.11.11.1.1.m1.1"><semantics id="S3.T1.11.11.1.1.m1.1a"><msup id="S3.T1.11.11.1.1.m1.1.1" xref="S3.T1.11.11.1.1.m1.1.1.cmml"><mi id="S3.T1.11.11.1.1.m1.1.1.2" mathcolor="#0000FF" xref="S3.T1.11.11.1.1.m1.1.1.2.cmml">r</mi><mo id="S3.T1.11.11.1.1.m1.1.1.3" mathcolor="#0000FF" mathvariant="normal" xref="S3.T1.11.11.1.1.m1.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.1.1.m1.1b"><apply id="S3.T1.11.11.1.1.m1.1.1.cmml" xref="S3.T1.11.11.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.11.11.1.1.m1.1.1.1.cmml" xref="S3.T1.11.11.1.1.m1.1.1">superscript</csymbol><ci id="S3.T1.11.11.1.1.m1.1.1.2.cmml" xref="S3.T1.11.11.1.1.m1.1.1.2">ùëü</ci><ci id="S3.T1.11.11.1.1.m1.1.1.3.cmml" xref="S3.T1.11.11.1.1.m1.1.1.3">normal-‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.1.1.m1.1c">r^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.11.11.1.1.m1.1d">italic_r start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>)</span>
</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Descriptions of 8 rationale aspects used for evaluation. <math alttext="q" class="ltx_Math" display="inline" id="S3.T1.15.m1.1"><semantics id="S3.T1.15.m1.1b"><mi id="S3.T1.15.m1.1.1" xref="S3.T1.15.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.T1.15.m1.1c"><ci id="S3.T1.15.m1.1.1.cmml" xref="S3.T1.15.m1.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.m1.1d">q</annotation><annotation encoding="application/x-llamapun" id="S3.T1.15.m1.1e">italic_q</annotation></semantics></math>, <math alttext="c" class="ltx_Math" display="inline" id="S3.T1.16.m2.1"><semantics id="S3.T1.16.m2.1b"><mi id="S3.T1.16.m2.1.1" xref="S3.T1.16.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.T1.16.m2.1c"><ci id="S3.T1.16.m2.1.1.cmml" xref="S3.T1.16.m2.1.1">ùëê</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.16.m2.1d">c</annotation><annotation encoding="application/x-llamapun" id="S3.T1.16.m2.1e">italic_c</annotation></semantics></math>, and <math alttext="r^{\prime}" class="ltx_Math" display="inline" id="S3.T1.17.m3.1"><semantics id="S3.T1.17.m3.1b"><msup id="S3.T1.17.m3.1.1" xref="S3.T1.17.m3.1.1.cmml"><mi id="S3.T1.17.m3.1.1.2" xref="S3.T1.17.m3.1.1.2.cmml">r</mi><mo id="S3.T1.17.m3.1.1.3" xref="S3.T1.17.m3.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.17.m3.1c"><apply id="S3.T1.17.m3.1.1.cmml" xref="S3.T1.17.m3.1.1"><csymbol cd="ambiguous" id="S3.T1.17.m3.1.1.1.cmml" xref="S3.T1.17.m3.1.1">superscript</csymbol><ci id="S3.T1.17.m3.1.1.2.cmml" xref="S3.T1.17.m3.1.1.2">ùëü</ci><ci id="S3.T1.17.m3.1.1.3.cmml" xref="S3.T1.17.m3.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.17.m3.1d">r^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.T1.17.m3.1e">italic_r start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> denote a question, context, and a corresponding rationale generated by the small LM, respectively.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">3.1.&nbsp;&nbsp;&nbsp;Rationale Distillation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.10"><span class="ltx_text ltx_font_bold" id="S3.SS1.p1.10.1">Rationale Generation.</span> In general, multi-hop extractive QA datasets contain a list of questions <math alttext="Q" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ùëÑ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">Q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">italic_Q</annotation></semantics></math>, contexts <math alttext="C" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ùê∂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">C</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">italic_C</annotation></semantics></math>, and corresponding ground truth answers <math alttext="A" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ùê¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">A</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">italic_A</annotation></semantics></math>. For each input (<math alttext="q" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">italic_q</annotation></semantics></math>, <math alttext="c" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">ùëê</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">italic_c</annotation></semantics></math>)-output (<math alttext="a" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">ùëé</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">a</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">italic_a</annotation></semantics></math>) pair, we need a corresponding ground truth rationale <math alttext="r" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1"><semantics id="S3.SS1.p1.7.m7.1a"><mi id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">ùëü</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">r</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m7.1d">italic_r</annotation></semantics></math> to train <math alttext="M^{S}" class="ltx_Math" display="inline" id="S3.SS1.p1.8.m8.1"><semantics id="S3.SS1.p1.8.m8.1a"><msup id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml"><mi id="S3.SS1.p1.8.m8.1.1.2" xref="S3.SS1.p1.8.m8.1.1.2.cmml">M</mi><mi id="S3.SS1.p1.8.m8.1.1.3" xref="S3.SS1.p1.8.m8.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><apply id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">superscript</csymbol><ci id="S3.SS1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1.2">ùëÄ</ci><ci id="S3.SS1.p1.8.m8.1.1.3.cmml" xref="S3.SS1.p1.8.m8.1.1.3">ùëÜ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">M^{S}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.8.m8.1d">italic_M start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT</annotation></semantics></math> for rationale generation in a supervised manner. However, most QA benchmarks do not provide <math alttext="r" class="ltx_Math" display="inline" id="S3.SS1.p1.9.m9.1"><semantics id="S3.SS1.p1.9.m9.1a"><mi id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><ci id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">ùëü</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">r</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.9.m9.1d">italic_r</annotation></semantics></math>. Given that manual annotation for <math alttext="r" class="ltx_Math" display="inline" id="S3.SS1.p1.10.m10.1"><semantics id="S3.SS1.p1.10.m10.1a"><mi id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><ci id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">ùëü</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">r</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.10.m10.1d">italic_r</annotation></semantics></math> is labor-intensive and time-consuming, we </p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<svg class="ltx_picture" height="90.12" id="S3.SS1.p2.pic1" overflow="visible" version="1.1" width="605.83"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,90.12) matrix(1 0 0 -1 0 0) translate(0,-5.83) translate(0,5.83)"><g fill="#808080" stroke="#808080"><g fill-opacity="0.010000" stroke-opacity="0.010000"><path d="M 2.05 3.94 L 2.05 72.48 C 2.05 77.87 6.42 82.24 11.81 82.24 L 596.06 82.24 C 601.46 82.24 605.83 77.87 605.83 72.48 L 605.83 3.94 C 605.83 -1.46 601.46 -5.83 596.06 -5.83 L 11.81 -5.83 C 6.42 -5.83 2.05 -1.46 2.05 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.020000" stroke-opacity="0.020000"><path d="M 2.52 3.94 L 2.52 72.48 C 2.52 77.61 6.68 81.77 11.81 81.77 L 596.06 81.77 C 601.19 81.77 605.35 77.61 605.35 72.48 L 605.35 3.94 C 605.35 -1.19 601.19 -5.35 596.06 -5.35 L 11.81 -5.35 C 6.68 -5.35 2.52 -1.19 2.52 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.040000" stroke-opacity="0.040000"><path d="M 2.99 3.94 L 2.99 72.48 C 2.99 77.35 6.94 81.3 11.81 81.3 L 596.06 81.3 C 600.93 81.3 604.88 77.35 604.88 72.48 L 604.88 3.94 C 604.88 -0.93 600.93 -4.88 596.06 -4.88 L 11.81 -4.88 C 6.94 -4.88 2.99 -0.93 2.99 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.070000" stroke-opacity="0.070000"><path d="M 3.46 3.94 L 3.46 72.48 C 3.46 77.09 7.2 80.83 11.81 80.83 L 596.06 80.83 C 600.67 80.83 604.41 77.09 604.41 72.48 L 604.41 3.94 C 604.41 -0.67 600.67 -4.41 596.06 -4.41 L 11.81 -4.41 C 7.2 -4.41 3.46 -0.67 3.46 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.110000" stroke-opacity="0.110000"><path d="M 3.94 3.94 L 3.94 72.48 C 3.94 76.83 7.46 80.35 11.81 80.35 L 596.06 80.35 C 600.41 80.35 603.94 76.83 603.94 72.48 L 603.94 3.94 C 603.94 -0.41 600.41 -3.94 596.06 -3.94 L 11.81 -3.94 C 7.46 -3.94 3.94 -0.41 3.94 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.110000" stroke-opacity="0.110000"><path d="M 4.41 3.94 L 4.41 72.48 C 4.41 76.57 7.72 79.88 11.81 79.88 L 596.06 79.88 C 600.15 79.88 603.46 76.57 603.46 72.48 L 603.46 3.94 C 603.46 -0.15 600.15 -3.46 596.06 -3.46 L 11.81 -3.46 C 7.72 -3.46 4.41 -0.15 4.41 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.070000" stroke-opacity="0.070000"><path d="M 4.88 3.94 L 4.88 72.48 C 4.88 76.31 7.98 79.41 11.81 79.41 L 596.06 79.41 C 599.89 79.41 602.99 76.31 602.99 72.48 L 602.99 3.94 C 602.99 0.11 599.89 -2.99 596.06 -2.99 L 11.81 -2.99 C 7.98 -2.99 4.88 0.11 4.88 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.040000" stroke-opacity="0.040000"><path d="M 5.35 3.94 L 5.35 72.48 C 5.35 76.05 8.25 78.94 11.81 78.94 L 596.06 78.94 C 599.63 78.94 602.52 76.05 602.52 72.48 L 602.52 3.94 C 602.52 0.37 599.63 -2.52 596.06 -2.52 L 11.81 -2.52 C 8.25 -2.52 5.35 0.37 5.35 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.020000" stroke-opacity="0.020000"><path d="M 5.83 3.94 L 5.83 72.48 C 5.83 75.78 8.51 78.46 11.81 78.46 L 596.06 78.46 C 599.37 78.46 602.05 75.78 602.05 72.48 L 602.05 3.94 C 602.05 0.63 599.37 -2.05 596.06 -2.05 L 11.81 -2.05 C 8.51 -2.05 5.83 0.63 5.83 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.010000" stroke-opacity="0.010000"><path d="M 6.3 3.94 L 6.3 72.48 C 6.3 75.52 8.77 77.99 11.81 77.99 L 596.06 77.99 C 599.11 77.99 601.57 75.52 601.57 72.48 L 601.57 3.94 C 601.57 0.89 599.11 -1.57 596.06 -1.57 L 11.81 -1.57 C 8.77 -1.57 6.3 0.89 6.3 3.94 Z" style="stroke:none"></path></g></g><g fill="#F5F5F5" fill-opacity="1.000000"><path d="M 0 5.91 L 0 78.39 C 0 81.65 2.64 84.29 5.91 84.29 L 594.09 84.29 C 597.36 84.29 600 81.65 600 78.39 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F5F5F5" fill-opacity="1.000000"><path d="M 1.97 5.91 L 1.97 78.39 C 1.97 80.56 3.73 82.32 5.91 82.32 L 594.09 82.32 C 596.27 82.32 598.03 80.56 598.03 78.39 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject height="56.73" overflow="visible" transform="matrix(1 0 0 -1 0 15.22)" width="556.69">
<p class="ltx_p ltx_minipage ltx_align_bottom" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2" style="width:402.3pt;"><span class="ltx_text" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2" style="font-size:90%;">Based on the provided context, answer the following question (Q) by reasoning step-by-step.

<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.1">Context</span>: <math alttext="c" class="ltx_Math" display="inline" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1"><semantics id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1a"><mi id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1.1" xref="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1b"><ci id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1.1.cmml" xref="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1.1">ùëê</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1d">italic_c</annotation></semantics></math>
<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.2">Q</span>: <math alttext="q" class="ltx_Math" display="inline" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1"><semantics id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1a"><mi id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1.1" xref="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1b"><ci id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1.1.cmml" xref="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1d">italic_q</annotation></semantics></math>
<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.3">A</span> : Let‚Äôs think step by step.</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">For generation, we use greedy decoding; <span class="ltx_text ltx_font_italic" id="S3.SS1.p3.1.1">i.e.</span>, choosing the most plausible token at each generation step.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">Rationale Filtering and Training.</span> When it comes to knowledge distillation, data cleaning processes play a crucial role in preventing errors or noises included in the generation from the teacher LM being inherited to the student LM. Thus, we filter samples associated with unfaithful responses to the prompt (<span class="ltx_text ltx_font_italic" id="S3.SS1.p4.1.2">i.e.</span>, not providing rationales prior to providing a final answer) and inaccurate answer prediction. Finally, we instruction-tune <math alttext="M^{S}" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><msup id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml">M</mi><mi id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2">ùëÄ</ci><ci id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3">ùëÜ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">M^{S}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">italic_M start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT</annotation></semantics></math> using the following prompt:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<svg class="ltx_picture" height="105.2" id="S3.SS1.p5.pic1" overflow="visible" version="1.1" width="605.83"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,105.2) matrix(1 0 0 -1 0 0) translate(0,-5.83) translate(0,5.83)"><g fill="#808080" stroke="#808080"><g fill-opacity="0.010000" stroke-opacity="0.010000"><path d="M 2.05 3.94 L 2.05 87.56 C 2.05 92.95 6.42 97.33 11.81 97.33 L 596.06 97.33 C 601.46 97.33 605.83 92.95 605.83 87.56 L 605.83 3.94 C 605.83 -1.46 601.46 -5.83 596.06 -5.83 L 11.81 -5.83 C 6.42 -5.83 2.05 -1.46 2.05 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.020000" stroke-opacity="0.020000"><path d="M 2.52 3.94 L 2.52 87.56 C 2.52 92.69 6.68 96.85 11.81 96.85 L 596.06 96.85 C 601.19 96.85 605.35 92.69 605.35 87.56 L 605.35 3.94 C 605.35 -1.19 601.19 -5.35 596.06 -5.35 L 11.81 -5.35 C 6.68 -5.35 2.52 -1.19 2.52 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.040000" stroke-opacity="0.040000"><path d="M 2.99 3.94 L 2.99 87.56 C 2.99 92.43 6.94 96.38 11.81 96.38 L 596.06 96.38 C 600.93 96.38 604.88 92.43 604.88 87.56 L 604.88 3.94 C 604.88 -0.93 600.93 -4.88 596.06 -4.88 L 11.81 -4.88 C 6.94 -4.88 2.99 -0.93 2.99 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.070000" stroke-opacity="0.070000"><path d="M 3.46 3.94 L 3.46 87.56 C 3.46 92.17 7.2 95.91 11.81 95.91 L 596.06 95.91 C 600.67 95.91 604.41 92.17 604.41 87.56 L 604.41 3.94 C 604.41 -0.67 600.67 -4.41 596.06 -4.41 L 11.81 -4.41 C 7.2 -4.41 3.46 -0.67 3.46 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.110000" stroke-opacity="0.110000"><path d="M 3.94 3.94 L 3.94 87.56 C 3.94 91.91 7.46 95.44 11.81 95.44 L 596.06 95.44 C 600.41 95.44 603.94 91.91 603.94 87.56 L 603.94 3.94 C 603.94 -0.41 600.41 -3.94 596.06 -3.94 L 11.81 -3.94 C 7.46 -3.94 3.94 -0.41 3.94 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.110000" stroke-opacity="0.110000"><path d="M 4.41 3.94 L 4.41 87.56 C 4.41 91.65 7.72 94.96 11.81 94.96 L 596.06 94.96 C 600.15 94.96 603.46 91.65 603.46 87.56 L 603.46 3.94 C 603.46 -0.15 600.15 -3.46 596.06 -3.46 L 11.81 -3.46 C 7.72 -3.46 4.41 -0.15 4.41 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.070000" stroke-opacity="0.070000"><path d="M 4.88 3.94 L 4.88 87.56 C 4.88 91.39 7.98 94.49 11.81 94.49 L 596.06 94.49 C 599.89 94.49 602.99 91.39 602.99 87.56 L 602.99 3.94 C 602.99 0.11 599.89 -2.99 596.06 -2.99 L 11.81 -2.99 C 7.98 -2.99 4.88 0.11 4.88 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.040000" stroke-opacity="0.040000"><path d="M 5.35 3.94 L 5.35 87.56 C 5.35 91.13 8.25 94.02 11.81 94.02 L 596.06 94.02 C 599.63 94.02 602.52 91.13 602.52 87.56 L 602.52 3.94 C 602.52 0.37 599.63 -2.52 596.06 -2.52 L 11.81 -2.52 C 8.25 -2.52 5.35 0.37 5.35 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.020000" stroke-opacity="0.020000"><path d="M 5.83 3.94 L 5.83 87.56 C 5.83 90.87 8.51 93.55 11.81 93.55 L 596.06 93.55 C 599.37 93.55 602.05 90.87 602.05 87.56 L 602.05 3.94 C 602.05 0.63 599.37 -2.05 596.06 -2.05 L 11.81 -2.05 C 8.51 -2.05 5.83 0.63 5.83 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.010000" stroke-opacity="0.010000"><path d="M 6.3 3.94 L 6.3 87.56 C 6.3 90.61 8.77 93.07 11.81 93.07 L 596.06 93.07 C 599.11 93.07 601.57 90.61 601.57 87.56 L 601.57 3.94 C 601.57 0.89 599.11 -1.57 596.06 -1.57 L 11.81 -1.57 C 8.77 -1.57 6.3 0.89 6.3 3.94 Z" style="stroke:none"></path></g></g><g fill="#F5F5F5" fill-opacity="1.000000"><path d="M 0 5.91 L 0 93.47 C 0 96.73 2.64 99.37 5.91 99.37 L 594.09 99.37 C 597.36 99.37 600 96.73 600 93.47 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F5F5F5" fill-opacity="1.000000"><path d="M 1.97 5.91 L 1.97 93.47 C 1.97 95.64 3.73 97.4 5.91 97.4 L 594.09 97.4 C 596.27 97.4 598.03 95.64 598.03 93.47 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject height="71.81" overflow="visible" transform="matrix(1 0 0 -1 0 15.22)" width="556.69">
<p class="ltx_p ltx_minipage ltx_align_bottom" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3" style="width:402.3pt;"><span class="ltx_text" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3" style="font-size:90%;">Given a question (Q) and a context, generate a chain of reasoning step by step to answer the question.

<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.1">Context</span>: <math alttext="c" class="ltx_Math" display="inline" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1"><semantics id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1a"><mi id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1.1" xref="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1b"><ci id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1.1.cmml" xref="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1.1">ùëê</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1d">italic_c</annotation></semantics></math>
<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.2">Q</span>: <math alttext="q" class="ltx_Math" display="inline" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1"><semantics id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1a"><mi id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1.1" xref="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1b"><ci id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1.1.cmml" xref="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1d">italic_q</annotation></semantics></math>
<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.3">Reasoning</span>: <math alttext="r^{\prime}" class="ltx_Math" display="inline" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1"><semantics id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1a"><msup id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1" xref="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.cmml"><mi id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.2" xref="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.2.cmml">r</mi><mo id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.3" xref="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1b"><apply id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.cmml" xref="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.1.cmml" xref="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1">superscript</csymbol><ci id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.2.cmml" xref="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.2">ùëü</ci><ci id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.3.cmml" xref="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1c">r^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1d">italic_r start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.1">For the rest of the paper, we denote the rationale-distilled model as <math alttext="M^{*}" class="ltx_Math" display="inline" id="S3.SS1.p6.1.m1.1"><semantics id="S3.SS1.p6.1.m1.1a"><msup id="S3.SS1.p6.1.m1.1.1" xref="S3.SS1.p6.1.m1.1.1.cmml"><mi id="S3.SS1.p6.1.m1.1.1.2" xref="S3.SS1.p6.1.m1.1.1.2.cmml">M</mi><mo id="S3.SS1.p6.1.m1.1.1.3" xref="S3.SS1.p6.1.m1.1.1.3.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.1b"><apply id="S3.SS1.p6.1.m1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.1.m1.1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.p6.1.m1.1.1.2.cmml" xref="S3.SS1.p6.1.m1.1.1.2">ùëÄ</ci><times id="S3.SS1.p6.1.m1.1.1.3.cmml" xref="S3.SS1.p6.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.1c">M^{*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.1.m1.1d">italic_M start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">3.2.&nbsp;&nbsp;&nbsp;Rationale Refinement</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.7"><span class="ltx_text ltx_font_bold" id="S3.SS2.p1.7.1">Annotation for Rationale Quality Measurement.</span>
Inspired by previous text and rationale generation evaluation metrics <cite class="ltx_cite ltx_citemacro_cite">Golovneva et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib3" title="">2022</a>); Fu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib2" title="">2023</a>)</cite>, we attempt to quantify 8 linguistic aspects (factuality, relevance, logicality, consistency, coherence, fluency, naturalness, readability) of rationales generated by <math alttext="M^{*}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><msup id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">M</mi><mo id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ùëÄ</ci><times id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">M^{*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_M start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT</annotation></semantics></math> in ¬ß<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S3.SS1" title="3.1. Rationale Distillation ‚Ä£ 3. LM-guided Chain-of-Thought ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">3.1</span></a>. Let us denote <math alttext="r^{*}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><msup id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">r</mi><mo id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">ùëü</ci><times id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">r^{*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_r start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT</annotation></semantics></math> as <math alttext="M^{*}" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><msup id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">M</mi><mo id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">ùëÄ</ci><times id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">M^{*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_M start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT</annotation></semantics></math>-generated reasoning. Since there is no ground truth rationale <math alttext="r" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">ùëü</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">r</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_r</annotation></semantics></math> available for comparison, our metrics are reference-free, utilizing a pair of <math alttext="r^{*}" class="ltx_Math" display="inline" id="S3.SS2.p1.5.m5.1"><semantics id="S3.SS2.p1.5.m5.1a"><msup id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><mi id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml">r</mi><mo id="S3.SS2.p1.5.m5.1.1.3" xref="S3.SS2.p1.5.m5.1.1.3.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">superscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2">ùëü</ci><times id="S3.SS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">r^{*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.5.m5.1d">italic_r start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT</annotation></semantics></math> and one of existing inputs (<math alttext="q" class="ltx_Math" display="inline" id="S3.SS2.p1.6.m6.1"><semantics id="S3.SS2.p1.6.m6.1a"><mi id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><ci id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.6.m6.1d">italic_q</annotation></semantics></math> or <math alttext="c" class="ltx_Math" display="inline" id="S3.SS2.p1.7.m7.1"><semantics id="S3.SS2.p1.7.m7.1a"><mi id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><ci id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">ùëê</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.7.m7.1d">italic_c</annotation></semantics></math>). Table <a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S3.T1" title="Table 1 ‚Ä£ 3. LM-guided Chain-of-Thought ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">1</span></a> describes each aspect type and input combinations. As we intend to use these metrics for reward scoring in RL, it is critical to have an accurate metric. Hence, we obtain a small set (n=100) of gold labels for all aspect types through human annotation. A detailed description of the annotation process and results is reported in ¬ß<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S11.SS1" title="11.1. Human Annotation for Rationale Quality Measurement ‚Ä£ 11. Appendices ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">11.1</span></a>.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Automatic Measurement for Rationale Quality.</span>
Manual annotation offers substantial value, but within the context of RL, it becomes notably challenging due to frequent reward scoring. Therefore, we probe several ways to automate this process. <cite class="ltx_cite ltx_citemacro_citet">Ye and Durrett (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib23" title="">2022</a>)</cite> introduced the simple yet effective approach for assessing factuality and relevance through token-level lexical overlap. We follow their method for factuality and relevance measurement. For the remaining 6 categories, two methods are considered. The first approach is to harness a large LM to function as reference-free NLG evaluators, inspired by recent works (<span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.2">e.g.</span>, <cite class="ltx_cite ltx_citemacro_citet">Liu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib10" title="">2023</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib19" title="">2023</a>)</cite>). The second approach, in contrast, involves training a simple machine learning classifier using human-annotated data. Both approaches are comprehensively described in ¬ß<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S11.SS2" title="11.2. Automatic Measurement for Rationale Quality ‚Ä£ 11. Appendices ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">11.2</span></a>. Due to inference time efficiency and higher alignment scores to human annotators (see Table <a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S11.T5" title="Table 5 ‚Ä£ 11.2. Automatic Measurement for Rationale Quality ‚Ä£ 11. Appendices ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">5</span></a>), we resort to the second method for all our experiments.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.11"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.11.1">RL for Rationale Refinement.</span>
We next detail how to utilize established evaluation metrics as reward signals to update the knowledge-distilled <math alttext="M^{*}" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><msup id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">M</mi><mo id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">ùëÄ</ci><times id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">M^{*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">italic_M start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT</annotation></semantics></math> with Proximal Policy Optimization (PPO) <cite class="ltx_cite ltx_citemacro_cite">Schulman et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib14" title="">2017</a>)</cite>. Given each input (<math alttext="q" class="ltx_Math" display="inline" id="S3.SS2.p3.2.m2.1"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.2.m2.1d">italic_q</annotation></semantics></math>, <math alttext="c" class="ltx_Math" display="inline" id="S3.SS2.p3.3.m3.1"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">ùëê</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.3.m3.1d">italic_c</annotation></semantics></math>)-output (<math alttext="a" class="ltx_Math" display="inline" id="S3.SS2.p3.4.m4.1"><semantics id="S3.SS2.p3.4.m4.1a"><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">ùëé</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">a</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.4.m4.1d">italic_a</annotation></semantics></math>) pair from training data, we first prompt <math alttext="M^{*}" class="ltx_Math" display="inline" id="S3.SS2.p3.5.m5.1"><semantics id="S3.SS2.p3.5.m5.1a"><msup id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml"><mi id="S3.SS2.p3.5.m5.1.1.2" xref="S3.SS2.p3.5.m5.1.1.2.cmml">M</mi><mo id="S3.SS2.p3.5.m5.1.1.3" xref="S3.SS2.p3.5.m5.1.1.3.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">superscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2">ùëÄ</ci><times id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">M^{*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.5.m5.1d">italic_M start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT</annotation></semantics></math> to generate a corresponding rationale <math alttext="r^{*}" class="ltx_Math" display="inline" id="S3.SS2.p3.6.m6.1"><semantics id="S3.SS2.p3.6.m6.1a"><msup id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2.cmml">r</mi><mo id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">superscript</csymbol><ci id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">ùëü</ci><times id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">r^{*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.6.m6.1d">italic_r start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT</annotation></semantics></math>. During the generation process, an aspect-specific reward (denoted as <math alttext="R_{aspect}" class="ltx_Math" display="inline" id="S3.SS2.p3.7.m7.1"><semantics id="S3.SS2.p3.7.m7.1a"><msub id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml"><mi id="S3.SS2.p3.7.m7.1.1.2" xref="S3.SS2.p3.7.m7.1.1.2.cmml">R</mi><mrow id="S3.SS2.p3.7.m7.1.1.3" xref="S3.SS2.p3.7.m7.1.1.3.cmml"><mi id="S3.SS2.p3.7.m7.1.1.3.2" xref="S3.SS2.p3.7.m7.1.1.3.2.cmml">a</mi><mo id="S3.SS2.p3.7.m7.1.1.3.1" xref="S3.SS2.p3.7.m7.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.7.m7.1.1.3.3" xref="S3.SS2.p3.7.m7.1.1.3.3.cmml">s</mi><mo id="S3.SS2.p3.7.m7.1.1.3.1a" xref="S3.SS2.p3.7.m7.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.7.m7.1.1.3.4" xref="S3.SS2.p3.7.m7.1.1.3.4.cmml">p</mi><mo id="S3.SS2.p3.7.m7.1.1.3.1b" xref="S3.SS2.p3.7.m7.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.7.m7.1.1.3.5" xref="S3.SS2.p3.7.m7.1.1.3.5.cmml">e</mi><mo id="S3.SS2.p3.7.m7.1.1.3.1c" xref="S3.SS2.p3.7.m7.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.7.m7.1.1.3.6" xref="S3.SS2.p3.7.m7.1.1.3.6.cmml">c</mi><mo id="S3.SS2.p3.7.m7.1.1.3.1d" xref="S3.SS2.p3.7.m7.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.7.m7.1.1.3.7" xref="S3.SS2.p3.7.m7.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><apply id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m7.1.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p3.7.m7.1.1.2.cmml" xref="S3.SS2.p3.7.m7.1.1.2">ùëÖ</ci><apply id="S3.SS2.p3.7.m7.1.1.3.cmml" xref="S3.SS2.p3.7.m7.1.1.3"><times id="S3.SS2.p3.7.m7.1.1.3.1.cmml" xref="S3.SS2.p3.7.m7.1.1.3.1"></times><ci id="S3.SS2.p3.7.m7.1.1.3.2.cmml" xref="S3.SS2.p3.7.m7.1.1.3.2">ùëé</ci><ci id="S3.SS2.p3.7.m7.1.1.3.3.cmml" xref="S3.SS2.p3.7.m7.1.1.3.3">ùë†</ci><ci id="S3.SS2.p3.7.m7.1.1.3.4.cmml" xref="S3.SS2.p3.7.m7.1.1.3.4">ùëù</ci><ci id="S3.SS2.p3.7.m7.1.1.3.5.cmml" xref="S3.SS2.p3.7.m7.1.1.3.5">ùëí</ci><ci id="S3.SS2.p3.7.m7.1.1.3.6.cmml" xref="S3.SS2.p3.7.m7.1.1.3.6">ùëê</ci><ci id="S3.SS2.p3.7.m7.1.1.3.7.cmml" xref="S3.SS2.p3.7.m7.1.1.3.7">ùë°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">R_{aspect}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.7.m7.1d">italic_R start_POSTSUBSCRIPT italic_a italic_s italic_p italic_e italic_c italic_t end_POSTSUBSCRIPT</annotation></semantics></math>) is measured by aggregating all values returned from automatic evaluation metrics.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>We also test with normalization or weighted summation for the scores, but they did not affect the performance. </span></span></span>
We then pass <math alttext="r^{*}" class="ltx_Math" display="inline" id="S3.SS2.p3.8.m8.1"><semantics id="S3.SS2.p3.8.m8.1a"><msup id="S3.SS2.p3.8.m8.1.1" xref="S3.SS2.p3.8.m8.1.1.cmml"><mi id="S3.SS2.p3.8.m8.1.1.2" xref="S3.SS2.p3.8.m8.1.1.2.cmml">r</mi><mo id="S3.SS2.p3.8.m8.1.1.3" xref="S3.SS2.p3.8.m8.1.1.3.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m8.1b"><apply id="S3.SS2.p3.8.m8.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m8.1.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1">superscript</csymbol><ci id="S3.SS2.p3.8.m8.1.1.2.cmml" xref="S3.SS2.p3.8.m8.1.1.2">ùëü</ci><times id="S3.SS2.p3.8.m8.1.1.3.cmml" xref="S3.SS2.p3.8.m8.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m8.1c">r^{*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.8.m8.1d">italic_r start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT</annotation></semantics></math> to <math alttext="M^{L}" class="ltx_Math" display="inline" id="S3.SS2.p3.9.m9.1"><semantics id="S3.SS2.p3.9.m9.1a"><msup id="S3.SS2.p3.9.m9.1.1" xref="S3.SS2.p3.9.m9.1.1.cmml"><mi id="S3.SS2.p3.9.m9.1.1.2" xref="S3.SS2.p3.9.m9.1.1.2.cmml">M</mi><mi id="S3.SS2.p3.9.m9.1.1.3" xref="S3.SS2.p3.9.m9.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m9.1b"><apply id="S3.SS2.p3.9.m9.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.9.m9.1.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1">superscript</csymbol><ci id="S3.SS2.p3.9.m9.1.1.2.cmml" xref="S3.SS2.p3.9.m9.1.1.2">ùëÄ</ci><ci id="S3.SS2.p3.9.m9.1.1.3.cmml" xref="S3.SS2.p3.9.m9.1.1.3">ùêø</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m9.1c">M^{L}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.9.m9.1d">italic_M start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math> to retrieve the answer prediction <math alttext="a^{*}" class="ltx_Math" display="inline" id="S3.SS2.p3.10.m10.1"><semantics id="S3.SS2.p3.10.m10.1a"><msup id="S3.SS2.p3.10.m10.1.1" xref="S3.SS2.p3.10.m10.1.1.cmml"><mi id="S3.SS2.p3.10.m10.1.1.2" xref="S3.SS2.p3.10.m10.1.1.2.cmml">a</mi><mo id="S3.SS2.p3.10.m10.1.1.3" xref="S3.SS2.p3.10.m10.1.1.3.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.10.m10.1b"><apply id="S3.SS2.p3.10.m10.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.10.m10.1.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1">superscript</csymbol><ci id="S3.SS2.p3.10.m10.1.1.2.cmml" xref="S3.SS2.p3.10.m10.1.1.2">ùëé</ci><times id="S3.SS2.p3.10.m10.1.1.3.cmml" xref="S3.SS2.p3.10.m10.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.10.m10.1c">a^{*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.10.m10.1d">italic_a start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT</annotation></semantics></math> and compute a task-specific reward (denoted as <math alttext="R_{taskAcc}" class="ltx_Math" display="inline" id="S3.SS2.p3.11.m11.1"><semantics id="S3.SS2.p3.11.m11.1a"><msub id="S3.SS2.p3.11.m11.1.1" xref="S3.SS2.p3.11.m11.1.1.cmml"><mi id="S3.SS2.p3.11.m11.1.1.2" xref="S3.SS2.p3.11.m11.1.1.2.cmml">R</mi><mrow id="S3.SS2.p3.11.m11.1.1.3" xref="S3.SS2.p3.11.m11.1.1.3.cmml"><mi id="S3.SS2.p3.11.m11.1.1.3.2" xref="S3.SS2.p3.11.m11.1.1.3.2.cmml">t</mi><mo id="S3.SS2.p3.11.m11.1.1.3.1" xref="S3.SS2.p3.11.m11.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.11.m11.1.1.3.3" xref="S3.SS2.p3.11.m11.1.1.3.3.cmml">a</mi><mo id="S3.SS2.p3.11.m11.1.1.3.1a" xref="S3.SS2.p3.11.m11.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.11.m11.1.1.3.4" xref="S3.SS2.p3.11.m11.1.1.3.4.cmml">s</mi><mo id="S3.SS2.p3.11.m11.1.1.3.1b" xref="S3.SS2.p3.11.m11.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.11.m11.1.1.3.5" xref="S3.SS2.p3.11.m11.1.1.3.5.cmml">k</mi><mo id="S3.SS2.p3.11.m11.1.1.3.1c" xref="S3.SS2.p3.11.m11.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.11.m11.1.1.3.6" xref="S3.SS2.p3.11.m11.1.1.3.6.cmml">A</mi><mo id="S3.SS2.p3.11.m11.1.1.3.1d" xref="S3.SS2.p3.11.m11.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.11.m11.1.1.3.7" xref="S3.SS2.p3.11.m11.1.1.3.7.cmml">c</mi><mo id="S3.SS2.p3.11.m11.1.1.3.1e" xref="S3.SS2.p3.11.m11.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.11.m11.1.1.3.8" xref="S3.SS2.p3.11.m11.1.1.3.8.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.11.m11.1b"><apply id="S3.SS2.p3.11.m11.1.1.cmml" xref="S3.SS2.p3.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.11.m11.1.1.1.cmml" xref="S3.SS2.p3.11.m11.1.1">subscript</csymbol><ci id="S3.SS2.p3.11.m11.1.1.2.cmml" xref="S3.SS2.p3.11.m11.1.1.2">ùëÖ</ci><apply id="S3.SS2.p3.11.m11.1.1.3.cmml" xref="S3.SS2.p3.11.m11.1.1.3"><times id="S3.SS2.p3.11.m11.1.1.3.1.cmml" xref="S3.SS2.p3.11.m11.1.1.3.1"></times><ci id="S3.SS2.p3.11.m11.1.1.3.2.cmml" xref="S3.SS2.p3.11.m11.1.1.3.2">ùë°</ci><ci id="S3.SS2.p3.11.m11.1.1.3.3.cmml" xref="S3.SS2.p3.11.m11.1.1.3.3">ùëé</ci><ci id="S3.SS2.p3.11.m11.1.1.3.4.cmml" xref="S3.SS2.p3.11.m11.1.1.3.4">ùë†</ci><ci id="S3.SS2.p3.11.m11.1.1.3.5.cmml" xref="S3.SS2.p3.11.m11.1.1.3.5">ùëò</ci><ci id="S3.SS2.p3.11.m11.1.1.3.6.cmml" xref="S3.SS2.p3.11.m11.1.1.3.6">ùê¥</ci><ci id="S3.SS2.p3.11.m11.1.1.3.7.cmml" xref="S3.SS2.p3.11.m11.1.1.3.7">ùëê</ci><ci id="S3.SS2.p3.11.m11.1.1.3.8.cmml" xref="S3.SS2.p3.11.m11.1.1.3.8">ùëê</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.11.m11.1c">R_{taskAcc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.11.m11.1d">italic_R start_POSTSUBSCRIPT italic_t italic_a italic_s italic_k italic_A italic_c italic_c end_POSTSUBSCRIPT</annotation></semantics></math>). Specifically, we leverage the F1 score between the predicted answer and the ground truth answer:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S11.EGx1">
<tbody id="S3.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle R_{\text{taskAcc}}=\begin{cases}1&amp;\text{if }F1(a,a^{*})>0.5,\\
0&amp;\text{else}.\end{cases}" class="ltx_Math" display="inline" id="S3.Ex1.m1.4"><semantics id="S3.Ex1.m1.4a"><mrow id="S3.Ex1.m1.4.5" xref="S3.Ex1.m1.4.5.cmml"><msub id="S3.Ex1.m1.4.5.2" xref="S3.Ex1.m1.4.5.2.cmml"><mi id="S3.Ex1.m1.4.5.2.2" xref="S3.Ex1.m1.4.5.2.2.cmml">R</mi><mtext id="S3.Ex1.m1.4.5.2.3" xref="S3.Ex1.m1.4.5.2.3a.cmml">taskAcc</mtext></msub><mo id="S3.Ex1.m1.4.5.1" xref="S3.Ex1.m1.4.5.1.cmml">=</mo><mrow id="S3.Ex1.m1.4.4a" xref="S3.Ex1.m1.4.5.3.1.cmml"><mo id="S3.Ex1.m1.4.4a.5" xref="S3.Ex1.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" id="S3.Ex1.m1.4.4.4a" rowspacing="0pt" xref="S3.Ex1.m1.4.5.3.1.cmml"><mtr id="S3.Ex1.m1.4.4.4aa" xref="S3.Ex1.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.4.4.4ab" xref="S3.Ex1.m1.4.5.3.1.cmml"><mn id="S3.Ex1.m1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.cmml">1</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.4.4.4ac" xref="S3.Ex1.m1.4.5.3.1.cmml"><mrow id="S3.Ex1.m1.2.2.2.2.2.1.2" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.cmml"><mrow id="S3.Ex1.m1.2.2.2.2.2.1.2.1" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.cmml"><mrow id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.cmml"><mtext id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.3" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.3a.cmml">if&nbsp;</mtext><mo id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2.cmml">‚Å¢</mo><mi id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.4" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.4.cmml">F</mi><mo id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2a" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2.cmml">‚Å¢</mo><mn id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.5" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.5.cmml">1</mn><mo id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2b" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2.cmml">‚Å¢</mo><mrow id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.2.cmml"><mo id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.2" stretchy="false" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.2.cmml">(</mo><mi id="S3.Ex1.m1.2.2.2.2.2.1.1" xref="S3.Ex1.m1.2.2.2.2.2.1.1.cmml">a</mi><mo id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.3" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.2.cmml">,</mo><msup id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.2.cmml">a</mi><mo id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.3.cmml">*</mo></msup><mo id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.4" stretchy="false" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.2.2.2.2.2.1.2.1.2" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.2.cmml">&gt;</mo><mn id="S3.Ex1.m1.2.2.2.2.2.1.2.1.3" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.3.cmml">0.5</mn></mrow><mo id="S3.Ex1.m1.2.2.2.2.2.1.2.2" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.cmml">,</mo></mrow></mtd></mtr><mtr id="S3.Ex1.m1.4.4.4ad" xref="S3.Ex1.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.4.4.4ae" xref="S3.Ex1.m1.4.5.3.1.cmml"><mn id="S3.Ex1.m1.3.3.3.3.1.1" xref="S3.Ex1.m1.3.3.3.3.1.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.4.4.4af" xref="S3.Ex1.m1.4.5.3.1.cmml"><mrow id="S3.Ex1.m1.4.4.4.4.2.1.3" xref="S3.Ex1.m1.4.4.4.4.2.1.1a.cmml"><mtext id="S3.Ex1.m1.4.4.4.4.2.1.1" xref="S3.Ex1.m1.4.4.4.4.2.1.1.cmml">else</mtext><mo id="S3.Ex1.m1.4.4.4.4.2.1.3.1" lspace="0em" xref="S3.Ex1.m1.4.4.4.4.2.1.1a.cmml">.</mo></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.4b"><apply id="S3.Ex1.m1.4.5.cmml" xref="S3.Ex1.m1.4.5"><eq id="S3.Ex1.m1.4.5.1.cmml" xref="S3.Ex1.m1.4.5.1"></eq><apply id="S3.Ex1.m1.4.5.2.cmml" xref="S3.Ex1.m1.4.5.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.4.5.2.1.cmml" xref="S3.Ex1.m1.4.5.2">subscript</csymbol><ci id="S3.Ex1.m1.4.5.2.2.cmml" xref="S3.Ex1.m1.4.5.2.2">ùëÖ</ci><ci id="S3.Ex1.m1.4.5.2.3a.cmml" xref="S3.Ex1.m1.4.5.2.3"><mtext id="S3.Ex1.m1.4.5.2.3.cmml" mathsize="70%" xref="S3.Ex1.m1.4.5.2.3">taskAcc</mtext></ci></apply><apply id="S3.Ex1.m1.4.5.3.1.cmml" xref="S3.Ex1.m1.4.4a"><csymbol cd="latexml" id="S3.Ex1.m1.4.5.3.1.1.cmml" xref="S3.Ex1.m1.4.4a.5">cases</csymbol><cn id="S3.Ex1.m1.1.1.1.1.1.1.cmml" type="integer" xref="S3.Ex1.m1.1.1.1.1.1.1">1</cn><apply id="S3.Ex1.m1.2.2.2.2.2.1.2.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2"><gt id="S3.Ex1.m1.2.2.2.2.2.1.2.1.2.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.2"></gt><apply id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1"><times id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2"></times><ci id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.3a.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.3"><mtext id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.3.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.3">if&nbsp;</mtext></ci><ci id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.4.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.4">ùêπ</ci><cn id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.5.cmml" type="integer" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.5">1</cn><interval closure="open" id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1"><ci id="S3.Ex1.m1.2.2.2.2.2.1.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.1">ùëé</ci><apply id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1">superscript</csymbol><ci id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.2">ùëé</ci><times id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.3"></times></apply></interval></apply><cn id="S3.Ex1.m1.2.2.2.2.2.1.2.1.3.cmml" type="float" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.3">0.5</cn></apply><cn id="S3.Ex1.m1.3.3.3.3.1.1.cmml" type="integer" xref="S3.Ex1.m1.3.3.3.3.1.1">0</cn><ci id="S3.Ex1.m1.4.4.4.4.2.1.1a.cmml" xref="S3.Ex1.m1.4.4.4.4.2.1.3"><mtext id="S3.Ex1.m1.4.4.4.4.2.1.1.cmml" xref="S3.Ex1.m1.4.4.4.4.2.1.1">else</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.4c">\displaystyle R_{\text{taskAcc}}=\begin{cases}1&amp;\text{if }F1(a,a^{*})&gt;0.5,\\
0&amp;\text{else}.\end{cases}</annotation><annotation encoding="application/x-llamapun" id="S3.Ex1.m1.4d">italic_R start_POSTSUBSCRIPT taskAcc end_POSTSUBSCRIPT = { start_ROW start_CELL 1 end_CELL start_CELL if italic_F 1 ( italic_a , italic_a start_POSTSUPERSCRIPT * end_POSTSUPERSCRIPT ) &gt; 0.5 , end_CELL end_ROW start_ROW start_CELL 0 end_CELL start_CELL else . end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p3.14">A final reward score for model training is the summation of <math alttext="R_{aspect}" class="ltx_Math" display="inline" id="S3.SS2.p3.12.m1.1"><semantics id="S3.SS2.p3.12.m1.1a"><msub id="S3.SS2.p3.12.m1.1.1" xref="S3.SS2.p3.12.m1.1.1.cmml"><mi id="S3.SS2.p3.12.m1.1.1.2" xref="S3.SS2.p3.12.m1.1.1.2.cmml">R</mi><mrow id="S3.SS2.p3.12.m1.1.1.3" xref="S3.SS2.p3.12.m1.1.1.3.cmml"><mi id="S3.SS2.p3.12.m1.1.1.3.2" xref="S3.SS2.p3.12.m1.1.1.3.2.cmml">a</mi><mo id="S3.SS2.p3.12.m1.1.1.3.1" xref="S3.SS2.p3.12.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.12.m1.1.1.3.3" xref="S3.SS2.p3.12.m1.1.1.3.3.cmml">s</mi><mo id="S3.SS2.p3.12.m1.1.1.3.1a" xref="S3.SS2.p3.12.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.12.m1.1.1.3.4" xref="S3.SS2.p3.12.m1.1.1.3.4.cmml">p</mi><mo id="S3.SS2.p3.12.m1.1.1.3.1b" xref="S3.SS2.p3.12.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.12.m1.1.1.3.5" xref="S3.SS2.p3.12.m1.1.1.3.5.cmml">e</mi><mo id="S3.SS2.p3.12.m1.1.1.3.1c" xref="S3.SS2.p3.12.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.12.m1.1.1.3.6" xref="S3.SS2.p3.12.m1.1.1.3.6.cmml">c</mi><mo id="S3.SS2.p3.12.m1.1.1.3.1d" xref="S3.SS2.p3.12.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.12.m1.1.1.3.7" xref="S3.SS2.p3.12.m1.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.12.m1.1b"><apply id="S3.SS2.p3.12.m1.1.1.cmml" xref="S3.SS2.p3.12.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.12.m1.1.1.1.cmml" xref="S3.SS2.p3.12.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.12.m1.1.1.2.cmml" xref="S3.SS2.p3.12.m1.1.1.2">ùëÖ</ci><apply id="S3.SS2.p3.12.m1.1.1.3.cmml" xref="S3.SS2.p3.12.m1.1.1.3"><times id="S3.SS2.p3.12.m1.1.1.3.1.cmml" xref="S3.SS2.p3.12.m1.1.1.3.1"></times><ci id="S3.SS2.p3.12.m1.1.1.3.2.cmml" xref="S3.SS2.p3.12.m1.1.1.3.2">ùëé</ci><ci id="S3.SS2.p3.12.m1.1.1.3.3.cmml" xref="S3.SS2.p3.12.m1.1.1.3.3">ùë†</ci><ci id="S3.SS2.p3.12.m1.1.1.3.4.cmml" xref="S3.SS2.p3.12.m1.1.1.3.4">ùëù</ci><ci id="S3.SS2.p3.12.m1.1.1.3.5.cmml" xref="S3.SS2.p3.12.m1.1.1.3.5">ùëí</ci><ci id="S3.SS2.p3.12.m1.1.1.3.6.cmml" xref="S3.SS2.p3.12.m1.1.1.3.6">ùëê</ci><ci id="S3.SS2.p3.12.m1.1.1.3.7.cmml" xref="S3.SS2.p3.12.m1.1.1.3.7">ùë°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.12.m1.1c">R_{aspect}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.12.m1.1d">italic_R start_POSTSUBSCRIPT italic_a italic_s italic_p italic_e italic_c italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="R_{taskAcc}" class="ltx_Math" display="inline" id="S3.SS2.p3.13.m2.1"><semantics id="S3.SS2.p3.13.m2.1a"><msub id="S3.SS2.p3.13.m2.1.1" xref="S3.SS2.p3.13.m2.1.1.cmml"><mi id="S3.SS2.p3.13.m2.1.1.2" xref="S3.SS2.p3.13.m2.1.1.2.cmml">R</mi><mrow id="S3.SS2.p3.13.m2.1.1.3" xref="S3.SS2.p3.13.m2.1.1.3.cmml"><mi id="S3.SS2.p3.13.m2.1.1.3.2" xref="S3.SS2.p3.13.m2.1.1.3.2.cmml">t</mi><mo id="S3.SS2.p3.13.m2.1.1.3.1" xref="S3.SS2.p3.13.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.13.m2.1.1.3.3" xref="S3.SS2.p3.13.m2.1.1.3.3.cmml">a</mi><mo id="S3.SS2.p3.13.m2.1.1.3.1a" xref="S3.SS2.p3.13.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.13.m2.1.1.3.4" xref="S3.SS2.p3.13.m2.1.1.3.4.cmml">s</mi><mo id="S3.SS2.p3.13.m2.1.1.3.1b" xref="S3.SS2.p3.13.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.13.m2.1.1.3.5" xref="S3.SS2.p3.13.m2.1.1.3.5.cmml">k</mi><mo id="S3.SS2.p3.13.m2.1.1.3.1c" xref="S3.SS2.p3.13.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.13.m2.1.1.3.6" xref="S3.SS2.p3.13.m2.1.1.3.6.cmml">A</mi><mo id="S3.SS2.p3.13.m2.1.1.3.1d" xref="S3.SS2.p3.13.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.13.m2.1.1.3.7" xref="S3.SS2.p3.13.m2.1.1.3.7.cmml">c</mi><mo id="S3.SS2.p3.13.m2.1.1.3.1e" xref="S3.SS2.p3.13.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.SS2.p3.13.m2.1.1.3.8" xref="S3.SS2.p3.13.m2.1.1.3.8.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.13.m2.1b"><apply id="S3.SS2.p3.13.m2.1.1.cmml" xref="S3.SS2.p3.13.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.13.m2.1.1.1.cmml" xref="S3.SS2.p3.13.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.13.m2.1.1.2.cmml" xref="S3.SS2.p3.13.m2.1.1.2">ùëÖ</ci><apply id="S3.SS2.p3.13.m2.1.1.3.cmml" xref="S3.SS2.p3.13.m2.1.1.3"><times id="S3.SS2.p3.13.m2.1.1.3.1.cmml" xref="S3.SS2.p3.13.m2.1.1.3.1"></times><ci id="S3.SS2.p3.13.m2.1.1.3.2.cmml" xref="S3.SS2.p3.13.m2.1.1.3.2">ùë°</ci><ci id="S3.SS2.p3.13.m2.1.1.3.3.cmml" xref="S3.SS2.p3.13.m2.1.1.3.3">ùëé</ci><ci id="S3.SS2.p3.13.m2.1.1.3.4.cmml" xref="S3.SS2.p3.13.m2.1.1.3.4">ùë†</ci><ci id="S3.SS2.p3.13.m2.1.1.3.5.cmml" xref="S3.SS2.p3.13.m2.1.1.3.5">ùëò</ci><ci id="S3.SS2.p3.13.m2.1.1.3.6.cmml" xref="S3.SS2.p3.13.m2.1.1.3.6">ùê¥</ci><ci id="S3.SS2.p3.13.m2.1.1.3.7.cmml" xref="S3.SS2.p3.13.m2.1.1.3.7">ùëê</ci><ci id="S3.SS2.p3.13.m2.1.1.3.8.cmml" xref="S3.SS2.p3.13.m2.1.1.3.8">ùëê</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.13.m2.1c">R_{taskAcc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.13.m2.1d">italic_R start_POSTSUBSCRIPT italic_t italic_a italic_s italic_k italic_A italic_c italic_c end_POSTSUBSCRIPT</annotation></semantics></math>. Following <cite class="ltx_cite ltx_citemacro_citet">Stiennon et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib16" title="">2020</a>)</cite>, we also incorporate penalties based on the Kullback Leibler (KL) divergence between the learned policy LM and <math alttext="M^{S}" class="ltx_Math" display="inline" id="S3.SS2.p3.14.m3.1"><semantics id="S3.SS2.p3.14.m3.1a"><msup id="S3.SS2.p3.14.m3.1.1" xref="S3.SS2.p3.14.m3.1.1.cmml"><mi id="S3.SS2.p3.14.m3.1.1.2" xref="S3.SS2.p3.14.m3.1.1.2.cmml">M</mi><mi id="S3.SS2.p3.14.m3.1.1.3" xref="S3.SS2.p3.14.m3.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.14.m3.1b"><apply id="S3.SS2.p3.14.m3.1.1.cmml" xref="S3.SS2.p3.14.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.14.m3.1.1.1.cmml" xref="S3.SS2.p3.14.m3.1.1">superscript</csymbol><ci id="S3.SS2.p3.14.m3.1.1.2.cmml" xref="S3.SS2.p3.14.m3.1.1.2">ùëÄ</ci><ci id="S3.SS2.p3.14.m3.1.1.3.cmml" xref="S3.SS2.p3.14.m3.1.1.3">ùëÜ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.14.m3.1c">M^{S}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.14.m3.1d">italic_M start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S3.T2">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.4">
<tbody><tr class="ltx_tr" id="S3.T2.4.5">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.4.5.1" rowspan="2"><span class="ltx_text" id="S3.T2.4.5.1.1" style="font-size:90%;">Prompt</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.4.5.2" rowspan="2"><span class="ltx_text" id="S3.T2.4.5.2.1" style="font-size:90%;"><span class="ltx_text" id="S3.T2.4.5.2.1.1"></span> <span class="ltx_text" id="S3.T2.4.5.2.1.2">
<span class="ltx_tabular ltx_align_middle" id="S3.T2.4.5.2.1.2.1">
<span class="ltx_tr" id="S3.T2.4.5.2.1.2.1.1">
<span class="ltx_td ltx_align_center" id="S3.T2.4.5.2.1.2.1.1.1">Rationale</span></span>
<span class="ltx_tr" id="S3.T2.4.5.2.1.2.1.2">
<span class="ltx_td ltx_align_center" id="S3.T2.4.5.2.1.2.1.2.1">Provision?</span></span>
</span></span> <span class="ltx_text" id="S3.T2.4.5.2.1.3"></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S3.T2.4.5.3"><span class="ltx_text" id="S3.T2.4.5.3.1" style="font-size:90%;">HotpotQA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="3" id="S3.T2.4.5.4"><span class="ltx_text" id="S3.T2.4.5.4.1" style="font-size:90%;">2WikiMultiHopQA</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.6">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.6.1"><span class="ltx_text" id="S3.T2.4.6.1.1" style="font-size:90%;">EM</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.6.2"><span class="ltx_text" id="S3.T2.4.6.2.1" style="font-size:90%;">F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.6.3">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.4.6.3.1">
<tbody><tr class="ltx_tr" id="S3.T2.4.6.3.1.1">
<td class="ltx_td ltx_align_center" id="S3.T2.4.6.3.1.1.1"><span class="ltx_text" id="S3.T2.4.6.3.1.1.1.1" style="font-size:90%;">Answer</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.6.3.1.2">
<td class="ltx_td ltx_align_center" id="S3.T2.4.6.3.1.2.1"><span class="ltx_text" id="S3.T2.4.6.3.1.2.1.1" style="font-size:90%;">Inclusion</span></td>
</tr>
</tbody></table>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.6.4"><span class="ltx_text" id="S3.T2.4.6.4.1" style="font-size:90%;">EM</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.6.5"><span class="ltx_text" id="S3.T2.4.6.5.1" style="font-size:90%;">F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.6.6">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.4.6.6.1">
<tbody><tr class="ltx_tr" id="S3.T2.4.6.6.1.1">
<td class="ltx_td ltx_align_center" id="S3.T2.4.6.6.1.1.1"><span class="ltx_text" id="S3.T2.4.6.6.1.1.1.1" style="font-size:90%;">Answer</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.6.6.1.2">
<td class="ltx_td ltx_align_center" id="S3.T2.4.6.6.1.2.1"><span class="ltx_text" id="S3.T2.4.6.6.1.2.1.1" style="font-size:90%;">Inclusion</span></td>
</tr>
</tbody></table>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.7">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.7.1"><span class="ltx_text" id="S3.T2.4.7.1.1" style="font-size:90%;">standard prompting</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.7.2"><span class="ltx_text" id="S3.T2.4.7.2.1" style="font-size:90%;color:#FF0000;">‚úó</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.7.3"><span class="ltx_text" id="S3.T2.4.7.3.1" style="font-size:90%;">0.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.7.4"><span class="ltx_text ltx_font_bold" id="S3.T2.4.7.4.1" style="font-size:90%;">0.714</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.7.5"><span class="ltx_text" id="S3.T2.4.7.5.1" style="font-size:90%;">0.583</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.7.6"><span class="ltx_text" id="S3.T2.4.7.6.1" style="font-size:90%;">0.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.7.7"><span class="ltx_text" id="S3.T2.4.7.7.1" style="font-size:90%;">0.625</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.7.8"><span class="ltx_text" id="S3.T2.4.7.8.1" style="font-size:90%;">0.647</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.8">
<td class="ltx_td ltx_align_center" id="S3.T2.4.8.1"><span class="ltx_text" id="S3.T2.4.8.1.1" style="font-size:90%;">CoT prompting</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.8.2"><span class="ltx_text" id="S3.T2.4.8.2.1" style="font-size:90%;color:#008000;">‚úì</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.8.3"><span class="ltx_text" id="S3.T2.4.8.3.1" style="font-size:90%;">0.483</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.8.4"><span class="ltx_text" id="S3.T2.4.8.4.1" style="font-size:90%;">0.686</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.8.5"><span class="ltx_text" id="S3.T2.4.8.5.1" style="font-size:90%;">0.611</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.8.6"><span class="ltx_text" id="S3.T2.4.8.6.1" style="font-size:90%;">0.4</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.8.7"><span class="ltx_text" id="S3.T2.4.8.7.1" style="font-size:90%;">0.532</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.8.8"><span class="ltx_text" id="S3.T2.4.8.8.1" style="font-size:90%;">0.561</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.9">
<td class="ltx_td ltx_align_center" id="S3.T2.4.9.1"><span class="ltx_text" id="S3.T2.4.9.1.1" style="font-size:90%;">CoT prompting + SC</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.9.2"><span class="ltx_text" id="S3.T2.4.9.2.1" style="font-size:90%;color:#FF0000;">‚úó</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.9.3"><span class="ltx_text" id="S3.T2.4.9.3.1" style="font-size:90%;">0.503</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.9.4"><span class="ltx_text" id="S3.T2.4.9.4.1" style="font-size:90%;">0.70</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.9.5"><span class="ltx_text" id="S3.T2.4.9.5.1" style="font-size:90%;">0.624</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.9.6"><span class="ltx_text" id="S3.T2.4.9.6.1" style="font-size:90%;">0.471</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.9.7"><span class="ltx_text" id="S3.T2.4.9.7.1" style="font-size:90%;">0.603</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.9.8"><span class="ltx_text" id="S3.T2.4.9.8.1" style="font-size:90%;">0.625</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.10">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.10.1"><span class="ltx_text" id="S3.T2.4.10.1.1" style="font-size:90%;">LM-guided CoT prompting (KD)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.10.2"><span class="ltx_text" id="S3.T2.4.10.2.1" style="font-size:90%;color:#008000;">‚úì</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.10.3"><span class="ltx_text" id="S3.T2.4.10.3.1" style="font-size:90%;">0.507</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.10.4"><span class="ltx_text" id="S3.T2.4.10.4.1" style="font-size:90%;">0.702</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.10.5"><span class="ltx_text" id="S3.T2.4.10.5.1" style="font-size:90%;">0.625</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.10.6"><span class="ltx_text" id="S3.T2.4.10.6.1" style="font-size:90%;">0.506</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.10.7"><span class="ltx_text" id="S3.T2.4.10.7.1" style="font-size:90%;">0.626</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.4.10.8"><span class="ltx_text" id="S3.T2.4.10.8.1" style="font-size:90%;">0.661</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.11">
<td class="ltx_td ltx_align_center" id="S3.T2.4.11.1"><span class="ltx_text" id="S3.T2.4.11.1.1" style="font-size:90%;">LM-guided CoT prompting (KD + SC)</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.11.2"><span class="ltx_text" id="S3.T2.4.11.2.1" style="font-size:90%;color:#FF0000;">‚úó</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.11.3"><span class="ltx_text ltx_font_bold" id="S3.T2.4.11.3.1" style="font-size:90%;">0.513</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.11.4"><span class="ltx_text ltx_font_bold" id="S3.T2.4.11.4.1" style="font-size:90%;">0.714</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.11.5"><span class="ltx_text ltx_font_bold" id="S3.T2.4.11.5.1" style="font-size:90%;">0.635</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.11.6"><span class="ltx_text ltx_font_bold" id="S3.T2.4.11.6.1" style="font-size:90%;">0.524</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.11.7"><span class="ltx_text ltx_font_bold" id="S3.T2.4.11.7.1" style="font-size:90%;">0.644</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.4.11.8"><span class="ltx_text ltx_font_bold" id="S3.T2.4.11.8.1" style="font-size:90%;">0.679</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1">
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.1">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.1.1.1.1">
<tbody><tr class="ltx_tr" id="S3.T2.1.1.1.1.2">
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.1.1.2.1"><span class="ltx_text" id="S3.T2.1.1.1.1.2.1.1" style="font-size:90%;">LM-guided CoT prompting</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.1.1.1.1.1">
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.1.1.1.1">
<span class="ltx_text" id="S3.T2.1.1.1.1.1.1.1" style="font-size:90%;">(KD + </span><math alttext="R_{aspect}" class="ltx_Math" display="inline" id="S3.T2.1.1.1.1.1.1.m1.1"><semantics id="S3.T2.1.1.1.1.1.1.m1.1a"><msub id="S3.T2.1.1.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S3.T2.1.1.1.1.1.1.m1.1.1.2" mathsize="90%" xref="S3.T2.1.1.1.1.1.1.m1.1.1.2.cmml">R</mi><mrow id="S3.T2.1.1.1.1.1.1.m1.1.1.3" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.cmml"><mi id="S3.T2.1.1.1.1.1.1.m1.1.1.3.2" mathsize="90%" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.cmml">a</mi><mo id="S3.T2.1.1.1.1.1.1.m1.1.1.3.1" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.1.1.1.1.1.1.m1.1.1.3.3" mathsize="90%" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.3.cmml">s</mi><mo id="S3.T2.1.1.1.1.1.1.m1.1.1.3.1a" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.1.1.1.1.1.1.m1.1.1.3.4" mathsize="90%" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.4.cmml">p</mi><mo id="S3.T2.1.1.1.1.1.1.m1.1.1.3.1b" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.1.1.1.1.1.1.m1.1.1.3.5" mathsize="90%" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.5.cmml">e</mi><mo id="S3.T2.1.1.1.1.1.1.m1.1.1.3.1c" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.1.1.1.1.1.1.m1.1.1.3.6" mathsize="90%" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.6.cmml">c</mi><mo id="S3.T2.1.1.1.1.1.1.m1.1.1.3.1d" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.1.1.1.1.1.1.m1.1.1.3.7" mathsize="90%" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.1.1.m1.1b"><apply id="S3.T2.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.2">ùëÖ</ci><apply id="S3.T2.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3"><times id="S3.T2.1.1.1.1.1.1.m1.1.1.3.1.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.1"></times><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.2">ùëé</ci><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.3.3.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.3">ùë†</ci><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.3.4.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.4">ùëù</ci><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.3.5.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.5">ùëí</ci><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.3.6.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.6">ùëê</ci><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.3.7.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.7">ùë°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.1.1.m1.1c">R_{aspect}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.1.1.1.1.1.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_a italic_s italic_p italic_e italic_c italic_t end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.T2.1.1.1.1.1.1.2" style="font-size:90%;">)</span>
</td>
</tr>
</tbody></table>
</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.2"><span class="ltx_text" id="S3.T2.1.1.2.1" style="font-size:90%;color:#008000;">‚úì</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.3"><span class="ltx_text" id="S3.T2.1.1.3.1" style="font-size:90%;">0.503</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.4"><span class="ltx_text" id="S3.T2.1.1.4.1" style="font-size:90%;">0.698</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.5"><span class="ltx_text" id="S3.T2.1.1.5.1" style="font-size:90%;">0.625</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.6">
<span class="ltx_text ltx_framed_underline" id="S3.T2.1.1.6.1" style="font-size:90%;">0</span><span class="ltx_text" id="S3.T2.1.1.6.2" style="font-size:90%;">.507</span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.7">
<span class="ltx_text ltx_framed_underline" id="S3.T2.1.1.7.1" style="font-size:90%;">0</span><span class="ltx_text" id="S3.T2.1.1.7.2" style="font-size:90%;">.631</span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T2.1.1.8">
<span class="ltx_text ltx_framed_underline" id="S3.T2.1.1.8.1" style="font-size:90%;">0</span><span class="ltx_text" id="S3.T2.1.1.8.2" style="font-size:90%;">.665</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3">
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.2">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.3.3.2.2">
<tbody><tr class="ltx_tr" id="S3.T2.3.3.2.2.3">
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.2.2.3.1"><span class="ltx_text" id="S3.T2.3.3.2.2.3.1.1" style="font-size:90%;">LM-guided CoT prompting</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3.2.2.2">
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.2.2.2.2">
<span class="ltx_text" id="S3.T2.3.3.2.2.2.2.1" style="font-size:90%;">(KD + </span><math alttext="R_{aspect}" class="ltx_Math" display="inline" id="S3.T2.2.2.1.1.1.1.m1.1"><semantics id="S3.T2.2.2.1.1.1.1.m1.1a"><msub id="S3.T2.2.2.1.1.1.1.m1.1.1" xref="S3.T2.2.2.1.1.1.1.m1.1.1.cmml"><mi id="S3.T2.2.2.1.1.1.1.m1.1.1.2" mathsize="90%" xref="S3.T2.2.2.1.1.1.1.m1.1.1.2.cmml">R</mi><mrow id="S3.T2.2.2.1.1.1.1.m1.1.1.3" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.cmml"><mi id="S3.T2.2.2.1.1.1.1.m1.1.1.3.2" mathsize="90%" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.2.cmml">a</mi><mo id="S3.T2.2.2.1.1.1.1.m1.1.1.3.1" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.2.2.1.1.1.1.m1.1.1.3.3" mathsize="90%" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.3.cmml">s</mi><mo id="S3.T2.2.2.1.1.1.1.m1.1.1.3.1a" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.2.2.1.1.1.1.m1.1.1.3.4" mathsize="90%" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.4.cmml">p</mi><mo id="S3.T2.2.2.1.1.1.1.m1.1.1.3.1b" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.2.2.1.1.1.1.m1.1.1.3.5" mathsize="90%" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.5.cmml">e</mi><mo id="S3.T2.2.2.1.1.1.1.m1.1.1.3.1c" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.2.2.1.1.1.1.m1.1.1.3.6" mathsize="90%" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.6.cmml">c</mi><mo id="S3.T2.2.2.1.1.1.1.m1.1.1.3.1d" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.2.2.1.1.1.1.m1.1.1.3.7" mathsize="90%" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.1.1.1.1.m1.1b"><apply id="S3.T2.2.2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.2.2.1.1.1.1.m1.1.1.1.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T2.2.2.1.1.1.1.m1.1.1.2.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.2">ùëÖ</ci><apply id="S3.T2.2.2.1.1.1.1.m1.1.1.3.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3"><times id="S3.T2.2.2.1.1.1.1.m1.1.1.3.1.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.1"></times><ci id="S3.T2.2.2.1.1.1.1.m1.1.1.3.2.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.2">ùëé</ci><ci id="S3.T2.2.2.1.1.1.1.m1.1.1.3.3.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.3">ùë†</ci><ci id="S3.T2.2.2.1.1.1.1.m1.1.1.3.4.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.4">ùëù</ci><ci id="S3.T2.2.2.1.1.1.1.m1.1.1.3.5.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.5">ùëí</ci><ci id="S3.T2.2.2.1.1.1.1.m1.1.1.3.6.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.6">ùëê</ci><ci id="S3.T2.2.2.1.1.1.1.m1.1.1.3.7.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.7">ùë°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.1.1.1.1.m1.1c">R_{aspect}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.2.2.1.1.1.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_a italic_s italic_p italic_e italic_c italic_t end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.T2.3.3.2.2.2.2.2" style="font-size:90%;"> + </span><math alttext="R_{taskAcc}" class="ltx_Math" display="inline" id="S3.T2.3.3.2.2.2.2.m2.1"><semantics id="S3.T2.3.3.2.2.2.2.m2.1a"><msub id="S3.T2.3.3.2.2.2.2.m2.1.1" xref="S3.T2.3.3.2.2.2.2.m2.1.1.cmml"><mi id="S3.T2.3.3.2.2.2.2.m2.1.1.2" mathsize="90%" xref="S3.T2.3.3.2.2.2.2.m2.1.1.2.cmml">R</mi><mrow id="S3.T2.3.3.2.2.2.2.m2.1.1.3" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.cmml"><mi id="S3.T2.3.3.2.2.2.2.m2.1.1.3.2" mathsize="90%" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.2.cmml">t</mi><mo id="S3.T2.3.3.2.2.2.2.m2.1.1.3.1" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.3.3.2.2.2.2.m2.1.1.3.3" mathsize="90%" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.3.cmml">a</mi><mo id="S3.T2.3.3.2.2.2.2.m2.1.1.3.1a" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.3.3.2.2.2.2.m2.1.1.3.4" mathsize="90%" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.4.cmml">s</mi><mo id="S3.T2.3.3.2.2.2.2.m2.1.1.3.1b" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.3.3.2.2.2.2.m2.1.1.3.5" mathsize="90%" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.5.cmml">k</mi><mo id="S3.T2.3.3.2.2.2.2.m2.1.1.3.1c" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.3.3.2.2.2.2.m2.1.1.3.6" mathsize="90%" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.6.cmml">A</mi><mo id="S3.T2.3.3.2.2.2.2.m2.1.1.3.1d" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.3.3.2.2.2.2.m2.1.1.3.7" mathsize="90%" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.7.cmml">c</mi><mo id="S3.T2.3.3.2.2.2.2.m2.1.1.3.1e" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.3.3.2.2.2.2.m2.1.1.3.8" mathsize="90%" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.8.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.2.2.2.2.m2.1b"><apply id="S3.T2.3.3.2.2.2.2.m2.1.1.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.T2.3.3.2.2.2.2.m2.1.1.1.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1">subscript</csymbol><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.2.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.2">ùëÖ</ci><apply id="S3.T2.3.3.2.2.2.2.m2.1.1.3.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3"><times id="S3.T2.3.3.2.2.2.2.m2.1.1.3.1.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.1"></times><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.3.2.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.2">ùë°</ci><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.3.3.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.3">ùëé</ci><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.3.4.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.4">ùë†</ci><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.3.5.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.5">ùëò</ci><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.3.6.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.6">ùê¥</ci><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.3.7.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.7">ùëê</ci><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.3.8.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.8">ùëê</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.2.2.2.2.m2.1c">R_{taskAcc}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.3.3.2.2.2.2.m2.1d">italic_R start_POSTSUBSCRIPT italic_t italic_a italic_s italic_k italic_A italic_c italic_c end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.T2.3.3.2.2.2.2.3" style="font-size:90%;">)</span>
</td>
</tr>
</tbody></table>
</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.3"><span class="ltx_text" id="S3.T2.3.3.3.1" style="font-size:90%;color:#008000;">‚úì</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.4">
<span class="ltx_text ltx_framed_underline" id="S3.T2.3.3.4.1" style="font-size:90%;">0</span><span class="ltx_text" id="S3.T2.3.3.4.2" style="font-size:90%;">.508</span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.5">
<span class="ltx_text ltx_framed_underline" id="S3.T2.3.3.5.1" style="font-size:90%;">0</span><span class="ltx_text" id="S3.T2.3.3.5.2" style="font-size:90%;">.704</span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.6">
<span class="ltx_text ltx_framed_underline" id="S3.T2.3.3.6.1" style="font-size:90%;">0</span><span class="ltx_text" id="S3.T2.3.3.6.2" style="font-size:90%;">.627</span>
</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.7"><span class="ltx_text" id="S3.T2.3.3.7.1" style="font-size:90%;">0.503</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.8"><span class="ltx_text" id="S3.T2.3.3.8.1" style="font-size:90%;">0.622</span></td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.9"><span class="ltx_text" id="S3.T2.3.3.9.1" style="font-size:90%;">0.657</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.4">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.1">
<table class="ltx_tabular ltx_align_middle" id="S3.T2.4.4.1.1">
<tbody><tr class="ltx_tr" id="S3.T2.4.4.1.1.2">
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.1.1.2.1"><span class="ltx_text" id="S3.T2.4.4.1.1.2.1.1" style="font-size:90%;">LM-guided CoT prompting</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.4.1.1.1">
<td class="ltx_td ltx_align_center" id="S3.T2.4.4.1.1.1.1">
<span class="ltx_text" id="S3.T2.4.4.1.1.1.1.1" style="font-size:90%;">(KD +</span><math alttext="R_{aspect}" class="ltx_Math" display="inline" id="S3.T2.4.4.1.1.1.1.m1.1"><semantics id="S3.T2.4.4.1.1.1.1.m1.1a"><msub id="S3.T2.4.4.1.1.1.1.m1.1.1" xref="S3.T2.4.4.1.1.1.1.m1.1.1.cmml"><mi id="S3.T2.4.4.1.1.1.1.m1.1.1.2" mathsize="90%" xref="S3.T2.4.4.1.1.1.1.m1.1.1.2.cmml">R</mi><mrow id="S3.T2.4.4.1.1.1.1.m1.1.1.3" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.cmml"><mi id="S3.T2.4.4.1.1.1.1.m1.1.1.3.2" mathsize="90%" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.2.cmml">a</mi><mo id="S3.T2.4.4.1.1.1.1.m1.1.1.3.1" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.4.4.1.1.1.1.m1.1.1.3.3" mathsize="90%" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.3.cmml">s</mi><mo id="S3.T2.4.4.1.1.1.1.m1.1.1.3.1a" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.4.4.1.1.1.1.m1.1.1.3.4" mathsize="90%" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.4.cmml">p</mi><mo id="S3.T2.4.4.1.1.1.1.m1.1.1.3.1b" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.4.4.1.1.1.1.m1.1.1.3.5" mathsize="90%" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.5.cmml">e</mi><mo id="S3.T2.4.4.1.1.1.1.m1.1.1.3.1c" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.4.4.1.1.1.1.m1.1.1.3.6" mathsize="90%" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.6.cmml">c</mi><mo id="S3.T2.4.4.1.1.1.1.m1.1.1.3.1d" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S3.T2.4.4.1.1.1.1.m1.1.1.3.7" mathsize="90%" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.1.1.1.1.m1.1b"><apply id="S3.T2.4.4.1.1.1.1.m1.1.1.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.4.4.1.1.1.1.m1.1.1.1.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T2.4.4.1.1.1.1.m1.1.1.2.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.2">ùëÖ</ci><apply id="S3.T2.4.4.1.1.1.1.m1.1.1.3.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3"><times id="S3.T2.4.4.1.1.1.1.m1.1.1.3.1.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.1"></times><ci id="S3.T2.4.4.1.1.1.1.m1.1.1.3.2.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.2">ùëé</ci><ci id="S3.T2.4.4.1.1.1.1.m1.1.1.3.3.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.3">ùë†</ci><ci id="S3.T2.4.4.1.1.1.1.m1.1.1.3.4.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.4">ùëù</ci><ci id="S3.T2.4.4.1.1.1.1.m1.1.1.3.5.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.5">ùëí</ci><ci id="S3.T2.4.4.1.1.1.1.m1.1.1.3.6.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.6">ùëê</ci><ci id="S3.T2.4.4.1.1.1.1.m1.1.1.3.7.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.7">ùë°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.1.1.1.1.m1.1c">R_{aspect}</annotation><annotation encoding="application/x-llamapun" id="S3.T2.4.4.1.1.1.1.m1.1d">italic_R start_POSTSUBSCRIPT italic_a italic_s italic_p italic_e italic_c italic_t end_POSTSUBSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.T2.4.4.1.1.1.1.2" style="font-size:90%;"> + ranking)</span>
</td>
</tr>
</tbody></table>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.2"><span class="ltx_text" id="S3.T2.4.4.2.1" style="font-size:90%;color:#008000;">‚úì</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.3"><span class="ltx_text" id="S3.T2.4.4.3.1" style="font-size:90%;">0.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.4"><span class="ltx_text" id="S3.T2.4.4.4.1" style="font-size:90%;">0.698</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.5"><span class="ltx_text" id="S3.T2.4.4.5.1" style="font-size:90%;">0.623</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.6"><span class="ltx_text" id="S3.T2.4.4.6.1" style="font-size:90%;">0.501</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.7"><span class="ltx_text" id="S3.T2.4.4.7.1" style="font-size:90%;">0.619</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.4.4.8"><span class="ltx_text" id="S3.T2.4.4.8.1" style="font-size:90%;">0.653</span></td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Answer prediction performance results of baselines and our approach. We regard SC decoding as a non-rationale provision because this method can result in multiple variations of rationales, rather than a single one. Values in bold represent the highest scores and underlined values are the second highest scores.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S3.T3">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.7">
<tbody><tr class="ltx_tr" id="S3.T3.7.8">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.7.8.1"><span class="ltx_text ltx_font_bold" id="S3.T3.7.8.1.1" style="font-size:90%;">Type</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.7.8.2"><span class="ltx_text ltx_font_bold" id="S3.T3.7.8.2.1" style="font-size:90%;">Description</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.7.8.3">
<span class="ltx_text ltx_font_bold" id="S3.T3.7.8.3.1" style="font-size:90%;">Template</span><span class="ltx_text" id="S3.T3.7.8.3.2" style="font-size:90%;"></span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.2.2">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.2.2.3">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.2.2.3.1">
<tbody><tr class="ltx_tr" id="S3.T3.2.2.3.1.1">
<td class="ltx_td ltx_align_center" id="S3.T3.2.2.3.1.1.1"><span class="ltx_text" id="S3.T3.2.2.3.1.1.1.1" style="font-size:90%;">Standard</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.2.2.3.1.2">
<td class="ltx_td ltx_align_center" id="S3.T3.2.2.3.1.2.1"><span class="ltx_text" id="S3.T3.2.2.3.1.2.1.1" style="font-size:90%;">prompting</span></td>
</tr>
</tbody></table>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.2.2.4">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.2.2.4.1">
<tbody><tr class="ltx_tr" id="S3.T3.2.2.4.1.1">
<td class="ltx_td ltx_align_center" id="S3.T3.2.2.4.1.1.1"><span class="ltx_text" id="S3.T3.2.2.4.1.1.1.1" style="font-size:90%;">Directly predicting the answer</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.2.2.4.1.2">
<td class="ltx_td ltx_align_center" id="S3.T3.2.2.4.1.2.1"><span class="ltx_text" id="S3.T3.2.2.4.1.2.1.1" style="font-size:90%;">based on input</span></td>
</tr>
</tbody></table>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.2.2.2">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.2.2.2.2">
<tbody><tr class="ltx_tr" id="S3.T3.2.2.2.2.3">
<td class="ltx_td ltx_align_left" id="S3.T3.2.2.2.2.3.1"><span class="ltx_text" id="S3.T3.2.2.2.2.3.1.1" style="font-size:90%;">Based on the provided context, answer the following question (Q).</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.1.1.1.1">
<td class="ltx_td ltx_align_left" id="S3.T3.1.1.1.1.1.1">
<span class="ltx_text" id="S3.T3.1.1.1.1.1.1.1" style="font-size:90%;">Context: </span><math alttext="c" class="ltx_Math" display="inline" id="S3.T3.1.1.1.1.1.1.m1.1"><semantics id="S3.T3.1.1.1.1.1.1.m1.1a"><mi id="S3.T3.1.1.1.1.1.1.m1.1.1" mathcolor="#008000" mathsize="90%" xref="S3.T3.1.1.1.1.1.1.m1.1.1.cmml">ùíÑ</mi><annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.1.1.1.m1.1b"><ci id="S3.T3.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.T3.1.1.1.1.1.1.m1.1.1">ùíÑ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.1.1.1.1.1.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.T3.1.1.1.1.1.1.m1.1d">bold_italic_c</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.2.2.2.2.2">
<td class="ltx_td ltx_align_left" id="S3.T3.2.2.2.2.2.1">
<span class="ltx_text" id="S3.T3.2.2.2.2.2.1.1" style="font-size:90%;">Q: </span><math alttext="q" class="ltx_Math" display="inline" id="S3.T3.2.2.2.2.2.1.m1.1"><semantics id="S3.T3.2.2.2.2.2.1.m1.1a"><mi id="S3.T3.2.2.2.2.2.1.m1.1.1" mathcolor="#FF00FF" mathsize="90%" xref="S3.T3.2.2.2.2.2.1.m1.1.1.cmml">ùíí</mi><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.2.2.1.m1.1b"><ci id="S3.T3.2.2.2.2.2.1.m1.1.1.cmml" xref="S3.T3.2.2.2.2.2.1.m1.1.1">ùíí</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.2.2.2.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.T3.2.2.2.2.2.1.m1.1d">bold_italic_q</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.2.2.2.2.4">
<td class="ltx_td ltx_align_left" id="S3.T3.2.2.2.2.4.1"><span class="ltx_text" id="S3.T3.2.2.2.2.4.1.1" style="font-size:90%;">A:</span></td>
</tr>
</tbody></table>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.4">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.4.4.3">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.4.4.3.1">
<tbody><tr class="ltx_tr" id="S3.T3.4.4.3.1.1">
<td class="ltx_td ltx_align_center" id="S3.T3.4.4.3.1.1.1"><span class="ltx_text" id="S3.T3.4.4.3.1.1.1.1" style="font-size:90%;">CoT</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.4.3.1.2">
<td class="ltx_td ltx_align_center" id="S3.T3.4.4.3.1.2.1"><span class="ltx_text" id="S3.T3.4.4.3.1.2.1.1" style="font-size:90%;">prompting</span></td>
</tr>
</tbody></table>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S3.T3.4.4.4">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.4.4.4.1">
<tbody><tr class="ltx_tr" id="S3.T3.4.4.4.1.1">
<td class="ltx_td ltx_align_center" id="S3.T3.4.4.4.1.1.1"><span class="ltx_text" id="S3.T3.4.4.4.1.1.1.1" style="font-size:90%;">Predicting the answer after</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.4.4.1.2">
<td class="ltx_td ltx_align_center" id="S3.T3.4.4.4.1.2.1"><span class="ltx_text" id="S3.T3.4.4.4.1.2.1.1" style="font-size:90%;">generating the reasoning</span></td>
</tr>
</tbody></table>
</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T3.4.4.2">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.4.4.2.2">
<tbody><tr class="ltx_tr" id="S3.T3.4.4.2.2.3">
<td class="ltx_td ltx_align_left" id="S3.T3.4.4.2.2.3.1"><span class="ltx_text" id="S3.T3.4.4.2.2.3.1.1" style="font-size:90%;">Based on the provided context, answer the following question (Q)</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.4.2.2.4">
<td class="ltx_td ltx_align_left" id="S3.T3.4.4.2.2.4.1"><span class="ltx_text" id="S3.T3.4.4.2.2.4.1.1" style="font-size:90%;">by reasoning step-by-step.</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.3.3.1.1.1">
<td class="ltx_td ltx_align_left" id="S3.T3.3.3.1.1.1.1">
<span class="ltx_text" id="S3.T3.3.3.1.1.1.1.1" style="font-size:90%;">Context: </span><math alttext="c" class="ltx_Math" display="inline" id="S3.T3.3.3.1.1.1.1.m1.1"><semantics id="S3.T3.3.3.1.1.1.1.m1.1a"><mi id="S3.T3.3.3.1.1.1.1.m1.1.1" mathcolor="#008000" mathsize="90%" xref="S3.T3.3.3.1.1.1.1.m1.1.1.cmml">ùíÑ</mi><annotation-xml encoding="MathML-Content" id="S3.T3.3.3.1.1.1.1.m1.1b"><ci id="S3.T3.3.3.1.1.1.1.m1.1.1.cmml" xref="S3.T3.3.3.1.1.1.1.m1.1.1">ùíÑ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.3.1.1.1.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.T3.3.3.1.1.1.1.m1.1d">bold_italic_c</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.4.2.2.2">
<td class="ltx_td ltx_align_left" id="S3.T3.4.4.2.2.2.1">
<span class="ltx_text" id="S3.T3.4.4.2.2.2.1.1" style="font-size:90%;">Q: </span><math alttext="q" class="ltx_Math" display="inline" id="S3.T3.4.4.2.2.2.1.m1.1"><semantics id="S3.T3.4.4.2.2.2.1.m1.1a"><mi id="S3.T3.4.4.2.2.2.1.m1.1.1" mathcolor="#FF00FF" mathsize="90%" xref="S3.T3.4.4.2.2.2.1.m1.1.1.cmml">ùíí</mi><annotation-xml encoding="MathML-Content" id="S3.T3.4.4.2.2.2.1.m1.1b"><ci id="S3.T3.4.4.2.2.2.1.m1.1.1.cmml" xref="S3.T3.4.4.2.2.2.1.m1.1.1">ùíí</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.4.2.2.2.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.T3.4.4.2.2.2.1.m1.1d">bold_italic_q</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.4.4.2.2.5">
<td class="ltx_td ltx_align_left" id="S3.T3.4.4.2.2.5.1"><span class="ltx_text" id="S3.T3.4.4.2.2.5.1.1" style="font-size:90%;">A : Let‚Äôs think step by step.</span></td>
</tr>
</tbody></table>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.7.7">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t" id="S3.T3.7.7.4">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.7.7.4.1">
<tbody><tr class="ltx_tr" id="S3.T3.7.7.4.1.1">
<td class="ltx_td ltx_align_center" id="S3.T3.7.7.4.1.1.1"><span class="ltx_text" id="S3.T3.7.7.4.1.1.1.1" style="font-size:90%;">LM-guided</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.7.7.4.1.2">
<td class="ltx_td ltx_align_center" id="S3.T3.7.7.4.1.2.1"><span class="ltx_text" id="S3.T3.7.7.4.1.2.1.1" style="font-size:90%;">CoT prompting</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.7.7.4.1.3">
<td class="ltx_td ltx_align_center" id="S3.T3.7.7.4.1.3.1"><span class="ltx_text ltx_font_bold ltx_font_italic" id="S3.T3.7.7.4.1.3.1.1" style="font-size:90%;color:#BE2D2D;">(our method)</span></td>
</tr>
</tbody></table>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" id="S3.T3.7.7.5">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.7.7.5.1">
<tbody><tr class="ltx_tr" id="S3.T3.7.7.5.1.1">
<td class="ltx_td ltx_align_center" id="S3.T3.7.7.5.1.1.1"><span class="ltx_text" id="S3.T3.7.7.5.1.1.1.1" style="font-size:90%;">Predicting the answer with</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.7.7.5.1.2">
<td class="ltx_td ltx_align_center" id="S3.T3.7.7.5.1.2.1"><span class="ltx_text" id="S3.T3.7.7.5.1.2.1.1" style="font-size:90%;">conditional generation upon</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.7.7.5.1.3">
<td class="ltx_td ltx_align_center" id="S3.T3.7.7.5.1.3.1"><span class="ltx_text" id="S3.T3.7.7.5.1.3.1.1" style="font-size:90%;">the LM-generated reasoning</span></td>
</tr>
</tbody></table>
</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" id="S3.T3.7.7.3">
<table class="ltx_tabular ltx_align_middle" id="S3.T3.7.7.3.3">
<tbody><tr class="ltx_tr" id="S3.T3.7.7.3.3.4">
<td class="ltx_td ltx_align_left" id="S3.T3.7.7.3.3.4.1"><span class="ltx_text" id="S3.T3.7.7.3.3.4.1.1" style="font-size:90%;">Based on the provided context, answer the following question (Q)</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.7.7.3.3.5">
<td class="ltx_td ltx_align_left" id="S3.T3.7.7.3.3.5.1"><span class="ltx_text" id="S3.T3.7.7.3.3.5.1.1" style="font-size:90%;">by reasoning step-by-step.</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.5.5.1.1.1">
<td class="ltx_td ltx_align_left" id="S3.T3.5.5.1.1.1.1">
<span class="ltx_text" id="S3.T3.5.5.1.1.1.1.1" style="font-size:90%;">Context: </span><math alttext="c" class="ltx_Math" display="inline" id="S3.T3.5.5.1.1.1.1.m1.1"><semantics id="S3.T3.5.5.1.1.1.1.m1.1a"><mi id="S3.T3.5.5.1.1.1.1.m1.1.1" mathcolor="#008000" mathsize="90%" xref="S3.T3.5.5.1.1.1.1.m1.1.1.cmml">ùíÑ</mi><annotation-xml encoding="MathML-Content" id="S3.T3.5.5.1.1.1.1.m1.1b"><ci id="S3.T3.5.5.1.1.1.1.m1.1.1.cmml" xref="S3.T3.5.5.1.1.1.1.m1.1.1">ùíÑ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.5.5.1.1.1.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.T3.5.5.1.1.1.1.m1.1d">bold_italic_c</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.6.6.2.2.2">
<td class="ltx_td ltx_align_left" id="S3.T3.6.6.2.2.2.1">
<span class="ltx_text" id="S3.T3.6.6.2.2.2.1.1" style="font-size:90%;">Q: </span><math alttext="q" class="ltx_Math" display="inline" id="S3.T3.6.6.2.2.2.1.m1.1"><semantics id="S3.T3.6.6.2.2.2.1.m1.1a"><mi id="S3.T3.6.6.2.2.2.1.m1.1.1" mathcolor="#FF00FF" mathsize="90%" xref="S3.T3.6.6.2.2.2.1.m1.1.1.cmml">ùíí</mi><annotation-xml encoding="MathML-Content" id="S3.T3.6.6.2.2.2.1.m1.1b"><ci id="S3.T3.6.6.2.2.2.1.m1.1.1.cmml" xref="S3.T3.6.6.2.2.2.1.m1.1.1">ùíí</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.6.6.2.2.2.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.T3.6.6.2.2.2.1.m1.1d">bold_italic_q</annotation></semantics></math>
</td>
</tr>
<tr class="ltx_tr" id="S3.T3.7.7.3.3.3">
<td class="ltx_td ltx_align_left" id="S3.T3.7.7.3.3.3.1">
<span class="ltx_text" id="S3.T3.7.7.3.3.3.1.1" style="font-size:90%;">A : Let‚Äôs think step by step. </span><math alttext="r^{\prime}" class="ltx_Math" display="inline" id="S3.T3.7.7.3.3.3.1.m1.1"><semantics id="S3.T3.7.7.3.3.3.1.m1.1a"><msup id="S3.T3.7.7.3.3.3.1.m1.1.1" xref="S3.T3.7.7.3.3.3.1.m1.1.1.cmml"><mi id="S3.T3.7.7.3.3.3.1.m1.1.1.2" mathcolor="#FF8000" mathsize="90%" xref="S3.T3.7.7.3.3.3.1.m1.1.1.2.cmml">ùíì</mi><mo id="S3.T3.7.7.3.3.3.1.m1.1.1.3" mathcolor="#FF8000" mathsize="90%" mathvariant="bold" xref="S3.T3.7.7.3.3.3.1.m1.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T3.7.7.3.3.3.1.m1.1b"><apply id="S3.T3.7.7.3.3.3.1.m1.1.1.cmml" xref="S3.T3.7.7.3.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T3.7.7.3.3.3.1.m1.1.1.1.cmml" xref="S3.T3.7.7.3.3.3.1.m1.1.1">superscript</csymbol><ci id="S3.T3.7.7.3.3.3.1.m1.1.1.2.cmml" xref="S3.T3.7.7.3.3.3.1.m1.1.1.2">ùíì</ci><ci id="S3.T3.7.7.3.3.3.1.m1.1.1.3.cmml" xref="S3.T3.7.7.3.3.3.1.m1.1.1.3">bold-‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.7.7.3.3.3.1.m1.1c">r^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.7.7.3.3.3.1.m1.1d">bold_italic_r start_POSTSUPERSCRIPT bold_‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.T3.7.7.3.3.3.1.2" style="font-size:90%;color:#FF8000;"> <span class="ltx_text" id="S3.T3.7.7.3.3.3.1.2.1" style="color:#000000;">. Hence, the answer is</span></span>
</td>
</tr>
</tbody></table>
</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Descriptions and templates of each prompt used for the answer prediction task. <math alttext="q" class="ltx_Math" display="inline" id="S3.T3.11.m1.1"><semantics id="S3.T3.11.m1.1b"><mi id="S3.T3.11.m1.1.1" mathcolor="#FF00FF" xref="S3.T3.11.m1.1.1.cmml">ùíí</mi><annotation-xml encoding="MathML-Content" id="S3.T3.11.m1.1c"><ci id="S3.T3.11.m1.1.1.cmml" xref="S3.T3.11.m1.1.1">ùíí</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.11.m1.1d">q</annotation><annotation encoding="application/x-llamapun" id="S3.T3.11.m1.1e">bold_italic_q</annotation></semantics></math><span class="ltx_text" id="S3.T3.13.2" style="color:#000000;">, <math alttext="c" class="ltx_Math" display="inline" id="S3.T3.12.1.m1.1"><semantics id="S3.T3.12.1.m1.1b"><mi id="S3.T3.12.1.m1.1.1" mathcolor="#008000" xref="S3.T3.12.1.m1.1.1.cmml">ùíÑ</mi><annotation-xml encoding="MathML-Content" id="S3.T3.12.1.m1.1c"><ci id="S3.T3.12.1.m1.1.1.cmml" xref="S3.T3.12.1.m1.1.1">ùíÑ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.12.1.m1.1d">c</annotation><annotation encoding="application/x-llamapun" id="S3.T3.12.1.m1.1e">bold_italic_c</annotation></semantics></math>, and <math alttext="r^{\prime}" class="ltx_Math" display="inline" id="S3.T3.13.2.m2.1"><semantics id="S3.T3.13.2.m2.1b"><msup id="S3.T3.13.2.m2.1.1" xref="S3.T3.13.2.m2.1.1.cmml"><mi id="S3.T3.13.2.m2.1.1.2" mathcolor="#FF8000" xref="S3.T3.13.2.m2.1.1.2.cmml">ùíì</mi><mo id="S3.T3.13.2.m2.1.1.3" mathcolor="#FF8000" mathvariant="bold" xref="S3.T3.13.2.m2.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T3.13.2.m2.1c"><apply id="S3.T3.13.2.m2.1.1.cmml" xref="S3.T3.13.2.m2.1.1"><csymbol cd="ambiguous" id="S3.T3.13.2.m2.1.1.1.cmml" xref="S3.T3.13.2.m2.1.1">superscript</csymbol><ci id="S3.T3.13.2.m2.1.1.2.cmml" xref="S3.T3.13.2.m2.1.1.2">ùíì</ci><ci id="S3.T3.13.2.m2.1.1.3.cmml" xref="S3.T3.13.2.m2.1.1.3">bold-‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.13.2.m2.1d">r^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.T3.13.2.m2.1e">bold_italic_r start_POSTSUPERSCRIPT bold_‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math><span class="ltx_text" id="S3.T3.13.2.1" style="color:#FF8000;"> </span>denote a question, context, and a corresponding rationale generated by the small LM, respectively.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">4.&nbsp;&nbsp;&nbsp;Experiments and Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">4.1.&nbsp;&nbsp;&nbsp;Experimental Setup</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.2"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.2.1">Model and Dataset.</span> we utilize FLAN-T5 small (80M) for <math alttext="M^{S}" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><msup id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">M</mi><mi id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">ùëÄ</ci><ci id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">ùëÜ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">M^{S}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_M start_POSTSUPERSCRIPT italic_S end_POSTSUPERSCRIPT</annotation></semantics></math> and FLAN-T5 XXL (11B) for <math alttext="M^{L}" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><msup id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">M</mi><mi id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">ùëÄ</ci><ci id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3">ùêø</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">M^{L}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">italic_M start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math>.
Both HotpotQA <cite class="ltx_cite ltx_citemacro_cite">Yang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#biba.bib2" title="">2018</a>)</cite> and 2WikiMultiHopQA <cite class="ltx_cite ltx_citemacro_cite">Ho et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#biba.bib1" title="">2020</a>)</cite> consist of an input question, and an answer, along with 9-10 context paragraphs with supportiveness labels indicating whether the paragraph contains supporting facts. Due to the input token size limitation of FLAN-T5, we only use supporting paragraphs as context. </p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Training &amp; Evaluation Setup.</span> We use a randomly sampled subset of training data from two datasets (15K samples per data) for model training. After filtering unqualified reasoning, it results in 23K samples. All training-related hyperparameters can be found in ¬ß<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S11.SS3" title="11.3. Training Configuration ‚Ä£ 11. Appendices ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">11.3</span></a>. According to our preliminary experiments, the impact of CoT prompting appeared to be diminished due to two potential factors: (1) questions being overly simplistic, obscuring the significance of intermediate reasoning processes; (2) LMs already possessing pertinent background information (<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.2">e.g.</span>, Flan-T5 is fine-tuned on various question-answering datasets). To prevent models from answering based on parametric memory, we attempt to make the existing evaluation data more challenging, similar to the approaches taken by <cite class="ltx_cite ltx_citemacro_citet">Ye and Durrett (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib23" title="">2022</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Zhao et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib24" title="">2023</a>)</cite>. For each dataset, we leverage the prediction outcomes of standard prompting and select 1000 input instances that <math alttext="M^{L}" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><msup id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">M</mi><mi id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">ùëÄ</ci><ci id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3">ùêø</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">M^{L}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">italic_M start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math> answered correctly and an additional 1000 from questions where the model provided incorrect responses. This results in a total of 2000 samples for evaluation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.1.1">Baselines and Evaluation Metrics.</span> We use standard prompting and CoT prompting as our baselines (see Table <a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S3.T3" title="Table 3 ‚Ä£ 3.2. Rationale Refinement ‚Ä£ 3. LM-guided Chain-of-Thought ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">3</span></a>). We also experiment with the SC decoding strategy <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib20" title="">2022b</a>)</cite>, which samples multiple reasoning paths (n=10) and selects the most consistent answer. For evaluation, we report three metrics for the answer prediction task: (1) exact match (EM), computing whether the prediction exactly matches the ground truth answer, (2) F1, computing the average word overlap between the prediction and ground truth answer, and (3) answer inclusion<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>We included this measurement because models often provide more extensive responses (<span class="ltx_text ltx_font_italic" id="footnote3.1">e.g.</span>, ground truth: World‚Äôs Best Goalkeeper <math alttext="\rightarrow" class="ltx_Math" display="inline" id="footnote3.m1.1"><semantics id="footnote3.m1.1b"><mo id="footnote3.m1.1.1" stretchy="false" xref="footnote3.m1.1.1.cmml">‚Üí</mo><annotation-xml encoding="MathML-Content" id="footnote3.m1.1c"><ci id="footnote3.m1.1.1.cmml" xref="footnote3.m1.1.1">‚Üí</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote3.m1.1d">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="footnote3.m1.1e">‚Üí</annotation></semantics></math> generation: IFFHS World‚Äôs Best Goalkeeper). This may be explained by our usage of contextual paragraphs as input.</span></span></span>, computing whether the ground truth answer is mentioned in the prediction.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">4.2.&nbsp;&nbsp;&nbsp;Results</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.2"><span class="ltx_text ltx_font_bold" id="S4.SS2.p1.2.1">Baseline Performance.</span>
As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S3.T2" title="Table 2 ‚Ä£ 3.2. Rationale Refinement ‚Ä£ 3. LM-guided Chain-of-Thought ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">2</span></a>, we find that <math alttext="M^{L}" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><msup id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">M</mi><mi id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">ùëÄ</ci><ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">ùêø</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">M^{L}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">italic_M start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math> (equivalent to FLAN-T5 XXL) does not benefit from the original CoT prompting, as its EM and F1 scores dropped in both datasets (except for answer inclusion score for HotpotQA) when compared to standard prompting. This is consistent with previous research findings that models with less than 50B parameters exhibit limited reasoning capabilities. We also observe that the performance drop is more significant with 2WikiMultihopQA (nearly 10% for EM and F1) than HotpotQA. Based on our manual inspection of incorrect predictions, <math alttext="M^{L}" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><msup id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">M</mi><mi id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">ùëÄ</ci><ci id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">ùêø</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">M^{L}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">italic_M start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT</annotation></semantics></math> was prone to repeat sentences in the context and fail to provide a final answer to the questions. This hints that, when context gets too long, models face difficulties in digesting the content and establishing valid reasoning steps. Overall, SC CoT prompting enables the model to noticeably recover from answer prediction errors, especially for 2WikiMultihopQA.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">LM-guided CoT Performance.</span>
Table <a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S3.T2" title="Table 2 ‚Ä£ 3.2. Rationale Refinement ‚Ä£ 3. LM-guided Chain-of-Thought ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">2</span></a> shows a comprehensive breakdown of our method‚Äôs performance. Additionally, we explore an extension of our approach, which involves sampling multiple reasoning paths and subsequently ranking the most optimal rationales. Our method with only KD outperforms the original CoT prompting with 2% gain for HotpotQA and 10% for 2WikiMultiHopQA, respectively. Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S4.F2" title="Figure 2 ‚Ä£ 4.2. Results ‚Ä£ 4. Experiments and Results ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the respective rationale qualities of all prompting techniques, reinforcing the effectiveness of our method in enhancing both answer prediction and rationale qualities. When employing the original CoT prompting for questions with lengthy contexts, models frequently recycle sentences from the provided context and struggle to deliver a conclusive answer to the question. This trend is mitigated by our approach, resulting in a significant decrease in error rates. It also surpasses the performance of CoT prompting + SC and is on par with standard prompting in terms of EM and F1. For the answer inclusion score, LM-guided CoT prompting is slightly higher (1-2%) than standard prompting. Furthermore, LM-guided CoT prompting + SC achieves the highest performance across all settings.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="337" id="S4.F2.g1" src="extracted/5516451/reward_new2.png" width="598">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Average answer prediction performance (across three evaluation metrics) and average rationale quality scores (<span class="ltx_text ltx_font_italic" id="S4.F2.4.1">i.e.</span>, <math alttext="R_{aspect}" class="ltx_Math" display="inline" id="S4.F2.2.m1.1"><semantics id="S4.F2.2.m1.1b"><msub id="S4.F2.2.m1.1.1" xref="S4.F2.2.m1.1.1.cmml"><mi id="S4.F2.2.m1.1.1.2" xref="S4.F2.2.m1.1.1.2.cmml">R</mi><mrow id="S4.F2.2.m1.1.1.3" xref="S4.F2.2.m1.1.1.3.cmml"><mi id="S4.F2.2.m1.1.1.3.2" xref="S4.F2.2.m1.1.1.3.2.cmml">a</mi><mo id="S4.F2.2.m1.1.1.3.1" xref="S4.F2.2.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S4.F2.2.m1.1.1.3.3" xref="S4.F2.2.m1.1.1.3.3.cmml">s</mi><mo id="S4.F2.2.m1.1.1.3.1b" xref="S4.F2.2.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S4.F2.2.m1.1.1.3.4" xref="S4.F2.2.m1.1.1.3.4.cmml">p</mi><mo id="S4.F2.2.m1.1.1.3.1c" xref="S4.F2.2.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S4.F2.2.m1.1.1.3.5" xref="S4.F2.2.m1.1.1.3.5.cmml">e</mi><mo id="S4.F2.2.m1.1.1.3.1d" xref="S4.F2.2.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S4.F2.2.m1.1.1.3.6" xref="S4.F2.2.m1.1.1.3.6.cmml">c</mi><mo id="S4.F2.2.m1.1.1.3.1e" xref="S4.F2.2.m1.1.1.3.1.cmml">‚Å¢</mo><mi id="S4.F2.2.m1.1.1.3.7" xref="S4.F2.2.m1.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.F2.2.m1.1c"><apply id="S4.F2.2.m1.1.1.cmml" xref="S4.F2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.F2.2.m1.1.1.1.cmml" xref="S4.F2.2.m1.1.1">subscript</csymbol><ci id="S4.F2.2.m1.1.1.2.cmml" xref="S4.F2.2.m1.1.1.2">ùëÖ</ci><apply id="S4.F2.2.m1.1.1.3.cmml" xref="S4.F2.2.m1.1.1.3"><times id="S4.F2.2.m1.1.1.3.1.cmml" xref="S4.F2.2.m1.1.1.3.1"></times><ci id="S4.F2.2.m1.1.1.3.2.cmml" xref="S4.F2.2.m1.1.1.3.2">ùëé</ci><ci id="S4.F2.2.m1.1.1.3.3.cmml" xref="S4.F2.2.m1.1.1.3.3">ùë†</ci><ci id="S4.F2.2.m1.1.1.3.4.cmml" xref="S4.F2.2.m1.1.1.3.4">ùëù</ci><ci id="S4.F2.2.m1.1.1.3.5.cmml" xref="S4.F2.2.m1.1.1.3.5">ùëí</ci><ci id="S4.F2.2.m1.1.1.3.6.cmml" xref="S4.F2.2.m1.1.1.3.6">ùëê</ci><ci id="S4.F2.2.m1.1.1.3.7.cmml" xref="S4.F2.2.m1.1.1.3.7">ùë°</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.2.m1.1d">R_{aspect}</annotation><annotation encoding="application/x-llamapun" id="S4.F2.2.m1.1e">italic_R start_POSTSUBSCRIPT italic_a italic_s italic_p italic_e italic_c italic_t end_POSTSUBSCRIPT</annotation></semantics></math>) for HotpotQA (left) and 2WikiMultiHopQA (right). The right y-axis represents the mean answer prediction scores, and the left y-axis represents the mean rationale quality scores.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S4.F2" title="Figure 2 ‚Ä£ 4.2. Results ‚Ä£ 4. Experiments and Results ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">2</span></a>, the implementation of RL enables the model to achieve additional improvements in both rationale qualities and task performance. However, in line with <cite class="ltx_cite ltx_citemacro_citet">Joshi et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib4" title="">2023</a>)</cite>‚Äôs findings, a slight decrease in task performance is observed at the cost of maximized rationale qualities when selecting top-quality rationales. There may be several underlying factors involved (<span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.1">e.g.</span>, models‚Äô unfaithfulness), but this is not the scope of this work.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">5.&nbsp;&nbsp;&nbsp;Conclusion</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1"><span class="ltx_text ltx_font_bold" id="S5.p1.1.1">LM-Guided CoT</span> is a novel framework that decomposes a conventional CoT prompting into two steps using two models: (1) rationale generation and (2) answer prediction. This includes distilling the reasoning ability from a large LM to a small LM and further optimizing it with RL. The results reveal that our method outperforms all baselines, highlighting its potential to serve as an effective and resource-efficient approach to tackle challenges within the CoT prompting paradigm. Meanwhile, we also find that selecting top-quality rationales for answer prediction may not consistently boost task performance. This prompts the need to explore a more harmonious balance between LM-generated rationale utilities and overall task performance.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">6.&nbsp;&nbsp;&nbsp;Limitations</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Although our framework can seamlessly accommodate various model combinations in a plug-and-play manner, we have restricted our experimental reporting to FLAN-T5. In a similar vein, this work only explores the task of multi-hop QA, leaving an open question about generalizability to other reasoning tasks. We anticipate future research endeavors to extend the application of our approach across diverse domains requiring sophisticated reasoning. Lastly, due to resource constraints, we were unable to collect extensive human annotations for established aspect evaluation metrics.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">7.&nbsp;&nbsp;&nbsp;Ethical Considerations</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">All the datasets that we use in our work are publicly available, and we have given appropriate credit to the original authors throughout the paper. We acknowledge that occasionally, the generated rationales may include non-factual and offensive statements. As we do not plan on distributing these artifacts, it effectively reduces the potential for harm.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">8.&nbsp;&nbsp;&nbsp;Acknowledgments</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">We thank all the reviewers for providing valuable feedback.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S9">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">9.&nbsp;&nbsp;&nbsp;Bibliographical References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<span class="ltx_ERROR undefined" id="S9.1">\c@NAT@ctr</span>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography"></h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fleiss (1971)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Joseph&nbsp;L Fleiss. 1971.

</span>
<span class="ltx_bibblock">Measuring nominal scale agreement among many raters.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Psychological bulletin</em>, 76(5):378.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu. 2023.

</span>
<span class="ltx_bibblock">Gptscore: Evaluate as you desire.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2302.04166</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Golovneva et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Olga Golovneva, Moya Chen, Spencer Poff, Martin Corredor, Luke Zettlemoyer, Maryam Fazel-Zarandi, and Asli Celikyilmaz. 2022.

</span>
<span class="ltx_bibblock">Roscoe: A suite of metrics for scoring step-by-step reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">In The Eleventh International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Brihi Joshi, Ziyi Liu, Sahana Ramnath, Aaron Chan, Zhewei Tong, Shaoliang Nie, Qifan Wang, Yejin Choi, and Xiang Ren. 2023.

</span>
<span class="ltx_bibblock">Are machine rationales (not) useful to humans? measuring and improving human utility of free-text rationales.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2305.07095</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jung et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Jaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brahman, Chandra Bhagavatula, Ronan&nbsp;Le Bras, and Yejin Choi. 2022.

</span>
<span class="ltx_bibblock">Maieutic prompting: Logically consistent reasoning with recursive explanations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2205.11822</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khot et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. 2022.

</span>
<span class="ltx_bibblock">Decomposed prompting: A modular approach for solving complex tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2210.02406</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lanham et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Tamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner, Carson Denison, Danny Hernandez, Dustin Li, Esin Durmus, Evan Hubinger, Jackson Kernion, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Measuring faithfulness in chain-of-thought reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2307.13702</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewkowycz et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Solving quantitative reasoning problems with language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Advances in Neural Information Processing Systems</em>, 35:3843‚Äì3857.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Liunian&nbsp;Harold Li, Jack Hessel, Youngjae Yu, Xiang Ren, Kai-Wei Chang, and Yejin Choi. 2023.

</span>
<span class="ltx_bibblock">Symbolic chain-of-thought distillation: Small models can also" think" step-by-step.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2306.14050</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. 2023.

</span>
<span class="ltx_bibblock">Gpteval: Nlg evaluation using gpt-4 with better human alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2303.16634</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longpre et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Shayne Longpre, Le&nbsp;Hou, Tu&nbsp;Vu, Albert Webson, Hyung&nbsp;Won Chung, Yi&nbsp;Tay, Denny Zhou, Quoc&nbsp;V Le, Barret Zoph, Jason Wei, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">The flan collection: Designing data and methods for effective instruction tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2301.13688</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Yuhan Ma, Haiqi Jiang, and Chenyou Fan. 2023.

</span>
<span class="ltx_bibblock">Sci-cot: Leveraging large language models for enhanced knowledge distillation in small models for scientific qa.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2308.04679</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prasad et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Archiki Prasad, Swarnadeep Saha, Xiang Zhou, and Mohit Bansal. 2023.

</span>
<span class="ltx_bibblock">Receval: Evaluating reasoning chains via correctness and informativeness.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2304.10703</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schulman et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. 2017.

</span>
<span class="ltx_bibblock">Proximal policy optimization algorithms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:1707.06347</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shridhar et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Kumar Shridhar, Alessandro Stolfo, and Mrinmaya Sachan. 2023.

</span>
<span class="ltx_bibblock">Distilling reasoning capabilities into smaller language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 7059‚Äì7073.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stiennon et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul&nbsp;F Christiano. 2020.

</span>
<span class="ltx_bibblock">Learning to summarize with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Advances in Neural Information Processing Systems</em>, 33:3008‚Äì3021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Turpin et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Miles Turpin, Julian Michael, Ethan Perez, and Samuel&nbsp;R Bowman. 2023.

</span>
<span class="ltx_bibblock">Language models don‚Äôt always say what they think: Unfaithful explanations in chain-of-thought prompting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2305.04388</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022a)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Boshi Wang, Sewon Min, Xiang Deng, Jiaming Shen, You Wu, Luke Zettlemoyer, and Huan Sun. 2022a.

</span>
<span class="ltx_bibblock">Towards understanding chain-of-thought prompting: An empirical study of what matters.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2212.10001</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Jiaan Wang, Yunlong Liang, Fandong Meng, Haoxiang Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, and Jie Zhou. 2023.

</span>
<span class="ltx_bibblock">Is chatgpt a good nlg evaluator? a preliminary study.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2303.04048</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022b)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed&nbsp;Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022b.

</span>
<span class="ltx_bibblock">Self-consistency improves chain of thought reasoning in language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2203.11171</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022a)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Jason Wei, Yi&nbsp;Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et&nbsp;al. 2022a.

</span>
<span class="ltx_bibblock">Emergent abilities of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2206.07682</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022b)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed&nbsp;Chi, Quoc&nbsp;V Le, Denny Zhou, et&nbsp;al. 2022b.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Advances in Neural Information Processing Systems</em>, 35:24824‚Äì24837.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye and Durrett (2022)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Xi&nbsp;Ye and Greg Durrett. 2022.

</span>
<span class="ltx_bibblock">The unreliability of explanations in few-shot prompting for textual reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Advances in neural information processing systems</em>, 35:30378‚Äì30392.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Ruochen Zhao, Xingxuan Li, Shafiq Joty, Chengwei Qin, and Lidong Bing. 2023.

</span>
<span class="ltx_bibblock">Verify-and-edit: A knowledge-enhanced chain-of-thought framework.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:2305.03268</em>.

</span>
</li>
</ul>
</section>
<section class="ltx_section" id="S10">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">10.&nbsp;&nbsp;&nbsp;Language Resource References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<span class="ltx_ERROR undefined" id="S10.1">\c@NAT@ctr</span>
</section>
<section class="ltx_bibliography" id="biba">
<h2 class="ltx_title ltx_title_bibliography">&nbsp;</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="biba.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Ho, Xanh and Nguyen, Anh-Khoa Duong and Sugawara, Saku and Aizawa, Akiko. 2020.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="biba.bib1.1.1">Constructing a multi-hop QA dataset for comprehensive evaluation of reasoning steps</em>.

</span>
</li>
<li class="ltx_bibitem" id="biba.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">‚Üë</button></span>
<span class="ltx_bibblock">
Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W and Salakhutdinov, Ruslan and Manning, Christopher D. 2018.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="biba.bib2.1.1">HotpotQA: A dataset for diverse, explainable multi-hop question answering</em>.

</span>
</li>
</ul>
</section>
<section class="ltx_section" id="S11">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">11.&nbsp;&nbsp;&nbsp;Appendices</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S11.SS1">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">11.1.&nbsp;&nbsp;&nbsp;Human Annotation for Rationale Quality Measurement</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S11.F3">
<p class="ltx_p ltx_align_center" id="S11.F3.1"><span class="ltx_text" id="S11.F3.1.1"><svg height="328" overflow="visible" version="1.1" width="471"><g transform="translate(0,328) scale(1,-1)"><rect fill="none" height="237.0pt" stroke="black" stroke-width="0.4" width="340.4pt" x="0" y="0"></rect><g class="makebox" transform="translate(0,0)"><g transform="translate(0,328) scale(1, -1)"><foreignObject height="328" overflow="visible" width="471"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="328" id="S11.F3.1.1.pic1.1.g1" src="extracted/5516451/annotation_example.png" width="471"></foreignObject></g></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Demonstration example for "logicality" annotation.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S11.SS1.p1">
<p class="ltx_p" id="S11.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S11.SS1.p1.1.1">Annotation Details.</span> Three researchers manually inspected 100 instances randomly sampled from training data. To ensure the quality and consistency of the annotation process, one researcher designed the annotation instruction describing the definition of each aspect (see Table <a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S3.T1" title="Table 1 ‚Ä£ 3. LM-guided Chain-of-Thought ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">1</span></a>) as well as 4 demonstration examples for each aspect category. Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S11.F3" title="Figure 3 ‚Ä£ 11.1. Human Annotation for Rationale Quality Measurement ‚Ä£ 11. Appendices ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">3</span></a> displays demonstration examples for logicality. These examples are chosen randomly from the remaining training set, which was not included in the initial set of 100 annotation samples, and are manually annotated based on aspect descriptions. Upon the completion of annotation, we gauged the inter-rater agreement rates to validate the reliability of submitted annotation results by computing the average Fleiss‚Äô Kappa coefficient <cite class="ltx_cite ltx_citemacro_cite">Fleiss (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib1" title="">1971</a>)</cite>. The mean Kappa score among the three annotators across all aspect categories was 0.56, indicating a moderate agreement rate. Ultimately, we take the mode of annotated labels submitted by three annotators and consider it as a ground truth.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S11.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="316" id="S11.F4.g1" src="extracted/5516451/barplot_annotation.png" width="510">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Mean scores of human annotation results by answer prediction correctness.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S11.SS1.p2">
<p class="ltx_p" id="S11.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S11.SS1.p2.1.1">Analysis of Relationships between Aspect Types and Task Performance.</span>
Based on 100 labeled instances, we perform a post-hoc analysis to understand how the proposed aspects are related to answer prediction performance. The label distributions are as follows: correct (n=78) vs. incorrect (n=22). We compare the mean difference of evaluation scores based on correct &amp; incorrect responses. As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S11.F4" title="Figure 4 ‚Ä£ 11.1. Human Annotation for Rationale Quality Measurement ‚Ä£ 11. Appendices ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">4</span></a>, rationales associated with correct answer prediction are prone to have higher scores than those with incorrect prediction. In particular, coherence has the largest mean difference, followed by readability and logicality. For fluency and naturalness, the gap seems minimal. We further conduct statistical testing to validate their statistical significance. T-test results confirm that the mean difference observed in coherence (<span class="ltx_text ltx_font_italic" id="S11.SS1.p2.1.2">p</span> = 0.003), readability (<span class="ltx_text ltx_font_italic" id="S11.SS1.p2.1.3">p</span> = 0.0002), and logicality (<span class="ltx_text ltx_font_italic" id="S11.SS1.p2.1.4">p</span> = 0.05) are statistically significant with <span class="ltx_text ltx_font_italic" id="S11.SS1.p2.1.5">p</span> &lt; 0.05.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S11.SS2">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">11.2.&nbsp;&nbsp;&nbsp;Automatic Measurement for Rationale Quality</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<a class="ltx_anchor" id="method1" name="method1"></a>
<figure class="ltx_table" id="S11.T4">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S11.T4.1">
<tbody><tr class="ltx_tr" id="S11.T4.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2" id="S11.T4.1.1.1"><span class="ltx_text" id="S11.T4.1.1.1.1" style="font-size:90%;">Prompting</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S11.T4.1.1.2"><span class="ltx_text" id="S11.T4.1.1.2.1" style="font-size:90%;">Coherence</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S11.T4.1.1.3"><span class="ltx_text" id="S11.T4.1.1.3.1" style="font-size:90%;">Consistency</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S11.T4.1.1.4"><span class="ltx_text" id="S11.T4.1.1.4.1" style="font-size:90%;">Logicality</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S11.T4.1.1.5"><span class="ltx_text" id="S11.T4.1.1.5.1" style="font-size:90%;">Fluency</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S11.T4.1.1.6"><span class="ltx_text" id="S11.T4.1.1.6.1" style="font-size:90%;">Naturalness</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S11.T4.1.1.7"><span class="ltx_text" id="S11.T4.1.1.7.1" style="font-size:90%;">Readability</span></td>
</tr>
<tr class="ltx_tr" id="S11.T4.1.2">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S11.T4.1.2.1" rowspan="2">
<span class="ltx_text" id="S11.T4.1.2.1.1" style="font-size:90%;">IST</span><span class="ltx_text" id="S11.T4.1.2.1.2" style="font-size:90%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S11.T4.1.2.2"><span class="ltx_text" id="S11.T4.1.2.2.1" style="font-size:90%;">IST</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T4.1.2.3"><span class="ltx_text" id="S11.T4.1.2.3.1" style="font-size:90%;">0.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T4.1.2.4"><span class="ltx_text ltx_font_bold" id="S11.T4.1.2.4.1" style="font-size:90%;">0.70</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T4.1.2.5"><span class="ltx_text" id="S11.T4.1.2.5.1" style="font-size:90%;">0.73</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T4.1.2.6"><span class="ltx_text" id="S11.T4.1.2.6.1" style="font-size:90%;">0.91</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T4.1.2.7"><span class="ltx_text ltx_font_bold" id="S11.T4.1.2.7.1" style="font-size:90%;">0.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T4.1.2.8"><span class="ltx_text ltx_font_bold" id="S11.T4.1.2.8.1" style="font-size:90%;">0.86</span></td>
</tr>
<tr class="ltx_tr" id="S11.T4.1.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S11.T4.1.3.1"><span class="ltx_text" id="S11.T4.1.3.1.1" style="font-size:90%;">IST + self-consistency</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.3.2"><span class="ltx_text ltx_font_bold" id="S11.T4.1.3.2.1" style="font-size:90%;">0.53</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.3.3"><span class="ltx_text" id="S11.T4.1.3.3.1" style="font-size:90%;">0.67</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.3.4"><span class="ltx_text ltx_font_bold" id="S11.T4.1.3.4.1" style="font-size:90%;">0.74</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.3.5"><span class="ltx_text" id="S11.T4.1.3.5.1" style="font-size:90%;">0.90</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.3.6"><span class="ltx_text" id="S11.T4.1.3.6.1" style="font-size:90%;">0.50</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.3.7"><span class="ltx_text" id="S11.T4.1.3.7.1" style="font-size:90%;">0.85</span></td>
</tr>
<tr class="ltx_tr" id="S11.T4.1.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S11.T4.1.4.1" rowspan="4">
<span class="ltx_text" id="S11.T4.1.4.1.1" style="font-size:90%;">IDM</span><span class="ltx_text" id="S11.T4.1.4.1.2" style="font-size:90%;"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S11.T4.1.4.2"><span class="ltx_text" id="S11.T4.1.4.2.1" style="font-size:90%;">IDM (1 shot)</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T4.1.4.3"><span class="ltx_text ltx_font_bold" id="S11.T4.1.4.3.1" style="font-size:90%;">0.53</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T4.1.4.4"><span class="ltx_text" id="S11.T4.1.4.4.1" style="font-size:90%;">0.64</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T4.1.4.5"><span class="ltx_text" id="S11.T4.1.4.5.1" style="font-size:90%;">0.70</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T4.1.4.6"><span class="ltx_text ltx_font_bold" id="S11.T4.1.4.6.1" style="font-size:90%;">0.92</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T4.1.4.7"><span class="ltx_text" id="S11.T4.1.4.7.1" style="font-size:90%;">0.29</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T4.1.4.8"><span class="ltx_text" id="S11.T4.1.4.8.1" style="font-size:90%;">0.70</span></td>
</tr>
<tr class="ltx_tr" id="S11.T4.1.5">
<td class="ltx_td ltx_align_center ltx_border_r" id="S11.T4.1.5.1"><span class="ltx_text" id="S11.T4.1.5.1.1" style="font-size:90%;">IDM (2 shot)</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.5.2"><span class="ltx_text ltx_font_bold" id="S11.T4.1.5.2.1" style="font-size:90%;">0.53</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.5.3"><span class="ltx_text" id="S11.T4.1.5.3.1" style="font-size:90%;">0.62</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.5.4"><span class="ltx_text" id="S11.T4.1.5.4.1" style="font-size:90%;">0.73</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.5.5"><span class="ltx_text" id="S11.T4.1.5.5.1" style="font-size:90%;">0.91</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.5.6"><span class="ltx_text" id="S11.T4.1.5.6.1" style="font-size:90%;">0.24</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.5.7"><span class="ltx_text" id="S11.T4.1.5.7.1" style="font-size:90%;">0.69</span></td>
</tr>
<tr class="ltx_tr" id="S11.T4.1.6">
<td class="ltx_td ltx_align_center ltx_border_r" id="S11.T4.1.6.1"><span class="ltx_text" id="S11.T4.1.6.1.1" style="font-size:90%;">IDM (3 shot)</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.6.2"><span class="ltx_text" id="S11.T4.1.6.2.1" style="font-size:90%;">0.51</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.6.3"><span class="ltx_text" id="S11.T4.1.6.3.1" style="font-size:90%;">0.62</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.6.4"><span class="ltx_text" id="S11.T4.1.6.4.1" style="font-size:90%;">0.73</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.6.5"><span class="ltx_text" id="S11.T4.1.6.5.1" style="font-size:90%;">0.88</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.6.6"><span class="ltx_text" id="S11.T4.1.6.6.1" style="font-size:90%;">0.28</span></td>
<td class="ltx_td ltx_align_center" id="S11.T4.1.6.7"><span class="ltx_text" id="S11.T4.1.6.7.1" style="font-size:90%;">0.67</span></td>
</tr>
<tr class="ltx_tr" id="S11.T4.1.7">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S11.T4.1.7.1"><span class="ltx_text" id="S11.T4.1.7.1.1" style="font-size:90%;">IDM (4 shot)</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S11.T4.1.7.2"><span class="ltx_text" id="S11.T4.1.7.2.1" style="font-size:90%;">0.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S11.T4.1.7.3"><span class="ltx_text" id="S11.T4.1.7.3.1" style="font-size:90%;">0.62</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S11.T4.1.7.4"><span class="ltx_text" id="S11.T4.1.7.4.1" style="font-size:90%;">0.70</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S11.T4.1.7.5"><span class="ltx_text" id="S11.T4.1.7.5.1" style="font-size:90%;">0.89</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S11.T4.1.7.6"><span class="ltx_text" id="S11.T4.1.7.6.1" style="font-size:90%;">0.36</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S11.T4.1.7.7"><span class="ltx_text" id="S11.T4.1.7.7.1" style="font-size:90%;">0.50</span></td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>The macro F1 scores for 5 prompt-based experiments from Method 1, based on 100 human-labeled examples. Values in bold represent the best performance in each aspect.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S11.T5">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S11.T5.1">
<tbody><tr class="ltx_tr" id="S11.T5.1.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="S11.T5.1.1.1" rowspan="2"><span class="ltx_text" id="S11.T5.1.1.1.1" style="font-size:90%;">Methods</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S11.T5.1.1.2"><span class="ltx_text" id="S11.T5.1.1.2.1" style="font-size:90%;">Coherence &amp; Consistency &amp; Logicality</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="4" id="S11.T5.1.1.3"><span class="ltx_text" id="S11.T5.1.1.3.1" style="font-size:90%;">Fluency &amp; Naturalness &amp; Readability</span></td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.2.1"><span class="ltx_text" id="S11.T5.1.2.1.1" style="font-size:90%;">Acc</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.2.2"><span class="ltx_text" id="S11.T5.1.2.2.1" style="font-size:90%;">Precision</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.2.3"><span class="ltx_text" id="S11.T5.1.2.3.1" style="font-size:90%;">Recall</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.2.4"><span class="ltx_text" id="S11.T5.1.2.4.1" style="font-size:90%;">F1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.2.5"><span class="ltx_text" id="S11.T5.1.2.5.1" style="font-size:90%;">Acc</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.2.6"><span class="ltx_text" id="S11.T5.1.2.6.1" style="font-size:90%;">Precision</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.2.7"><span class="ltx_text" id="S11.T5.1.2.7.1" style="font-size:90%;">Recall</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.2.8"><span class="ltx_text" id="S11.T5.1.2.8.1" style="font-size:90%;">F1</span></td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.3">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S11.T5.1.3.1"><span class="ltx_text" id="S11.T5.1.3.1.1" style="font-size:90%;">Method 1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.3.2"><span class="ltx_text" id="S11.T5.1.3.2.1" style="font-size:90%;">0.62</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.3.3"><span class="ltx_text" id="S11.T5.1.3.3.1" style="font-size:90%;">0.62</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.3.4"><span class="ltx_text" id="S11.T5.1.3.4.1" style="font-size:90%;">0.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.3.5"><span class="ltx_text" id="S11.T5.1.3.5.1" style="font-size:90%;">0.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.3.6"><span class="ltx_text" id="S11.T5.1.3.6.1" style="font-size:90%;">0.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.3.7"><span class="ltx_text" id="S11.T5.1.3.7.1" style="font-size:90%;">0.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.3.8"><span class="ltx_text ltx_font_bold" id="S11.T5.1.3.8.1" style="font-size:90%;">0.81</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S11.T5.1.3.9"><span class="ltx_text" id="S11.T5.1.3.9.1" style="font-size:90%;">0.67</span></td>
</tr>
<tr class="ltx_tr" id="S11.T5.1.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S11.T5.1.4.1"><span class="ltx_text" id="S11.T5.1.4.1.1" style="font-size:90%;">Method 2</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S11.T5.1.4.2"><span class="ltx_text ltx_font_bold" id="S11.T5.1.4.2.1" style="font-size:90%;">0.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S11.T5.1.4.3"><span class="ltx_text ltx_font_bold" id="S11.T5.1.4.3.1" style="font-size:90%;">0.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S11.T5.1.4.4"><span class="ltx_text ltx_font_bold" id="S11.T5.1.4.4.1" style="font-size:90%;">0.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S11.T5.1.4.5"><span class="ltx_text ltx_font_bold" id="S11.T5.1.4.5.1" style="font-size:90%;">0.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S11.T5.1.4.6"><span class="ltx_text ltx_font_bold" id="S11.T5.1.4.6.1" style="font-size:90%;">0.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S11.T5.1.4.7"><span class="ltx_text ltx_font_bold" id="S11.T5.1.4.7.1" style="font-size:90%;">0.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S11.T5.1.4.8"><span class="ltx_text" id="S11.T5.1.4.8.1" style="font-size:90%;">0.75</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S11.T5.1.4.9"><span class="ltx_text ltx_font_bold" id="S11.T5.1.4.9.1" style="font-size:90%;">0.9</span></td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5: </span>Evaluation results (Method 1 vs. Method 2). Values in bold represent the best performance in each aspect.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S11.SS2.p1">
<p class="ltx_p" id="S11.SS2.p1.3"><span class="ltx_text ltx_font_bold" id="S11.SS2.p1.3.1">Method 1: Self-Evaluation from Large LMs.</span> <cite class="ltx_cite ltx_citemacro_citet">Fu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib2" title="">2023</a>)</cite> have demonstrated the emergent capabilities of large LMs in neural text evaluation, achieved through zero-shot instruction and in-context learning. The key idea is that, given the natural language description of desired task and evaluation aspects, large LMs can assess multi-dimensional text quality without any learning process. Motivated by this, we instruct FLAN-T5 XXL to evaluate 6 aspects of the machine-generated rationales. Similar to <cite class="ltx_cite ltx_citemacro_citet">Fu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#bib.bib2" title="">2023</a>)</cite>‚Äôs experiments, we investigate the performance of instruction-only (IST) prompting and instruction+demonstration (IDM) prompting.
Let‚Äôs say <math alttext="q" class="ltx_Math" display="inline" id="S11.SS2.p1.1.m1.1"><semantics id="S11.SS2.p1.1.m1.1a"><mi id="S11.SS2.p1.1.m1.1.1" xref="S11.SS2.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S11.SS2.p1.1.m1.1b"><ci id="S11.SS2.p1.1.m1.1.1.cmml" xref="S11.SS2.p1.1.m1.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S11.SS2.p1.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S11.SS2.p1.1.m1.1d">italic_q</annotation></semantics></math> and <math alttext="r^{\prime}" class="ltx_Math" display="inline" id="S11.SS2.p1.2.m2.1"><semantics id="S11.SS2.p1.2.m2.1a"><msup id="S11.SS2.p1.2.m2.1.1" xref="S11.SS2.p1.2.m2.1.1.cmml"><mi id="S11.SS2.p1.2.m2.1.1.2" xref="S11.SS2.p1.2.m2.1.1.2.cmml">r</mi><mo id="S11.SS2.p1.2.m2.1.1.3" xref="S11.SS2.p1.2.m2.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S11.SS2.p1.2.m2.1b"><apply id="S11.SS2.p1.2.m2.1.1.cmml" xref="S11.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S11.SS2.p1.2.m2.1.1.1.cmml" xref="S11.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S11.SS2.p1.2.m2.1.1.2.cmml" xref="S11.SS2.p1.2.m2.1.1.2">ùëü</ci><ci id="S11.SS2.p1.2.m2.1.1.3.cmml" xref="S11.SS2.p1.2.m2.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S11.SS2.p1.2.m2.1c">r^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S11.SS2.p1.2.m2.1d">italic_r start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math> denote a question and a machine-generated rationale that is yet to be evaluated. <math alttext="d" class="ltx_Math" display="inline" id="S11.SS2.p1.3.m3.1"><semantics id="S11.SS2.p1.3.m3.1a"><mi id="S11.SS2.p1.3.m3.1.1" xref="S11.SS2.p1.3.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S11.SS2.p1.3.m3.1b"><ci id="S11.SS2.p1.3.m3.1.1.cmml" xref="S11.SS2.p1.3.m3.1.1">ùëë</ci></annotation-xml><annotation encoding="application/x-tex" id="S11.SS2.p1.3.m3.1c">d</annotation><annotation encoding="application/x-llamapun" id="S11.SS2.p1.3.m3.1d">italic_d</annotation></semantics></math> represents the aspect definition of our interest from Table <a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S3.T1" title="Table 1 ‚Ä£ 3. LM-guided Chain-of-Thought ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">1</span></a>. A prompt template used for IST is:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S11.SS2.p2">
<svg class="ltx_picture" height="133.22" id="S11.SS2.p2.pic1" overflow="visible" version="1.1" width="605.83"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,133.22) matrix(1 0 0 -1 0 0) translate(0,-5.83) translate(0,5.83)"><g fill="#808080" stroke="#808080"><g fill-opacity="0.010000" stroke-opacity="0.010000"><path d="M 2.05 3.94 L 2.05 115.58 C 2.05 120.97 6.42 125.35 11.81 125.35 L 596.06 125.35 C 601.46 125.35 605.83 120.97 605.83 115.58 L 605.83 3.94 C 605.83 -1.46 601.46 -5.83 596.06 -5.83 L 11.81 -5.83 C 6.42 -5.83 2.05 -1.46 2.05 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.020000" stroke-opacity="0.020000"><path d="M 2.52 3.94 L 2.52 115.58 C 2.52 120.71 6.68 124.87 11.81 124.87 L 596.06 124.87 C 601.19 124.87 605.35 120.71 605.35 115.58 L 605.35 3.94 C 605.35 -1.19 601.19 -5.35 596.06 -5.35 L 11.81 -5.35 C 6.68 -5.35 2.52 -1.19 2.52 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.040000" stroke-opacity="0.040000"><path d="M 2.99 3.94 L 2.99 115.58 C 2.99 120.45 6.94 124.4 11.81 124.4 L 596.06 124.4 C 600.93 124.4 604.88 120.45 604.88 115.58 L 604.88 3.94 C 604.88 -0.93 600.93 -4.88 596.06 -4.88 L 11.81 -4.88 C 6.94 -4.88 2.99 -0.93 2.99 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.070000" stroke-opacity="0.070000"><path d="M 3.46 3.94 L 3.46 115.58 C 3.46 120.19 7.2 123.93 11.81 123.93 L 596.06 123.93 C 600.67 123.93 604.41 120.19 604.41 115.58 L 604.41 3.94 C 604.41 -0.67 600.67 -4.41 596.06 -4.41 L 11.81 -4.41 C 7.2 -4.41 3.46 -0.67 3.46 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.110000" stroke-opacity="0.110000"><path d="M 3.94 3.94 L 3.94 115.58 C 3.94 119.93 7.46 123.46 11.81 123.46 L 596.06 123.46 C 600.41 123.46 603.94 119.93 603.94 115.58 L 603.94 3.94 C 603.94 -0.41 600.41 -3.94 596.06 -3.94 L 11.81 -3.94 C 7.46 -3.94 3.94 -0.41 3.94 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.110000" stroke-opacity="0.110000"><path d="M 4.41 3.94 L 4.41 115.58 C 4.41 119.67 7.72 122.98 11.81 122.98 L 596.06 122.98 C 600.15 122.98 603.46 119.67 603.46 115.58 L 603.46 3.94 C 603.46 -0.15 600.15 -3.46 596.06 -3.46 L 11.81 -3.46 C 7.72 -3.46 4.41 -0.15 4.41 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.070000" stroke-opacity="0.070000"><path d="M 4.88 3.94 L 4.88 115.58 C 4.88 119.41 7.98 122.51 11.81 122.51 L 596.06 122.51 C 599.89 122.51 602.99 119.41 602.99 115.58 L 602.99 3.94 C 602.99 0.11 599.89 -2.99 596.06 -2.99 L 11.81 -2.99 C 7.98 -2.99 4.88 0.11 4.88 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.040000" stroke-opacity="0.040000"><path d="M 5.35 3.94 L 5.35 115.58 C 5.35 119.15 8.25 122.04 11.81 122.04 L 596.06 122.04 C 599.63 122.04 602.52 119.15 602.52 115.58 L 602.52 3.94 C 602.52 0.37 599.63 -2.52 596.06 -2.52 L 11.81 -2.52 C 8.25 -2.52 5.35 0.37 5.35 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.020000" stroke-opacity="0.020000"><path d="M 5.83 3.94 L 5.83 115.58 C 5.83 118.89 8.51 121.57 11.81 121.57 L 596.06 121.57 C 599.37 121.57 602.05 118.89 602.05 115.58 L 602.05 3.94 C 602.05 0.63 599.37 -2.05 596.06 -2.05 L 11.81 -2.05 C 8.51 -2.05 5.83 0.63 5.83 3.94 Z" style="stroke:none"></path></g><g fill-opacity="0.010000" stroke-opacity="0.010000"><path d="M 6.3 3.94 L 6.3 115.58 C 6.3 118.63 8.77 121.09 11.81 121.09 L 596.06 121.09 C 599.11 121.09 601.57 118.63 601.57 115.58 L 601.57 3.94 C 601.57 0.89 599.11 -1.57 596.06 -1.57 L 11.81 -1.57 C 8.77 -1.57 6.3 0.89 6.3 3.94 Z" style="stroke:none"></path></g></g><g fill="#F5F5F5" fill-opacity="1.000000"><path d="M 0 5.91 L 0 121.49 C 0 124.75 2.64 127.39 5.91 127.39 L 594.09 127.39 C 597.36 127.39 600 124.75 600 121.49 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F5F5F5" fill-opacity="1.000000"><path d="M 1.97 5.91 L 1.97 121.49 C 1.97 123.66 3.73 125.42 5.91 125.42 L 594.09 125.42 C 596.27 125.42 598.03 123.66 598.03 121.49 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject height="99.83" overflow="visible" transform="matrix(1 0 0 -1 0 15.22)" width="556.69">
<p class="ltx_p ltx_minipage ltx_align_bottom" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3" style="width:402.3pt;"><span class="ltx_text" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3" style="font-size:90%;">Answer the question based on the provided information.

<br class="ltx_break">Question: Can the given reasoning <math alttext="d" class="ltx_Math" display="inline" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1"><semantics id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1a"><mi id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1.1" xref="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1b"><ci id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1.1.cmml" xref="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1.1">ùëë</ci></annotation-xml><annotation encoding="application/x-tex" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1c">d</annotation><annotation encoding="application/x-llamapun" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1.m1.1d">italic_d</annotation></semantics></math> ? (a) Yes. (b) No.

<br class="ltx_break">
<br class="ltx_break"><span class="ltx_text ltx_font_bold" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.1">Information</span>:

<br class="ltx_break">Question: <math alttext="q" class="ltx_Math" display="inline" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1"><semantics id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1a"><mi id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1.1" xref="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1b"><ci id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1.1.cmml" xref="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1.1">ùëû</ci></annotation-xml><annotation encoding="application/x-tex" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.2.m2.1d">italic_q</annotation></semantics></math>
<br class="ltx_break">Reasoning: <math alttext="r^{\prime}" class="ltx_Math" display="inline" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1"><semantics id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1a"><msup id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1" xref="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.cmml"><mi id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.2" xref="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.2.cmml">r</mi><mo id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.3" xref="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.3.cmml">‚Ä≤</mo></msup><annotation-xml encoding="MathML-Content" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1b"><apply id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.cmml" xref="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1"><csymbol cd="ambiguous" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.1.cmml" xref="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1">superscript</csymbol><ci id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.2.cmml" xref="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.2">ùëü</ci><ci id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.3.cmml" xref="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1.1.3">‚Ä≤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1c">r^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.3.m3.1d">italic_r start_POSTSUPERSCRIPT ‚Ä≤ end_POSTSUPERSCRIPT</annotation></semantics></math>
<br class="ltx_break">Answer :</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S11.SS2.p3">
<p class="ltx_p" id="S11.SS2.p3.1">A prompt template for IDM is equivalent to IST but with the inclusion of a few task demonstrations. The number of demonstrations ranges from 1 to 4. We use the same demonstrations included in the human annotation instruction (¬ß<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S11.SS1" title="11.1. Human Annotation for Rationale Quality Measurement ‚Ä£ 11. Appendices ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">11.1</span></a>). Lastly, we evaluate IST in combination with SC decoding, which involves sampling the prediction multiple times (n = 10) and taking the mode as a final prediction. To ensure that the rationale evaluation of FLAN-T5 XXL aligns closely with human annotation, we compute the macro F1 scores for 5 prompt-based experiments using 100 human-labeled examples (Table <a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S11.T4" title="Table 4 ‚Ä£ 11.2. Automatic Measurement for Rationale Quality ‚Ä£ 11. Appendices ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">4</span></a>). In most cases except for fluency, IST prompting demonstrates the highest performance.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S11.SS2.p4">
<p class="ltx_p" id="S11.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S11.SS2.p4.1.1">Method 2: Supervised Training with Human-Annotated Data.</span>
Here we train a logistic regression classifier using 100 ground truth data from ¬ß<a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S11.SS1" title="11.1. Human Annotation for Rationale Quality Measurement ‚Ä£ 11. Appendices ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">11.1</span></a>. This can be done by converting input data into TF-IDF vectors. Due to a small training data size, we resort to training two independent binary classifiers instead of having 6 models for each aspect type. While the first model is to predict if a given reasoning is logical, coherent, and consistent, the second model focuses on predicting whether the reasoning is fluent, natural, and readable. If at least one of the components is not satisfied, we consider it a negative label. The final label distribution is as follows: logicality &amp; consistency &amp; coherence (0: 60 vs. 1: 40), and fluency &amp; naturalness &amp; readability (0: 20 vs. 1: 80). We use 90% of the dataset (n=90) for training and the remaining 10% (n=10) for evaluation.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S11.SS2.p5">
<p class="ltx_p" id="S11.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S11.SS2.p5.1.1">Method 1 vs. Method 2.</span> We attempt to assess which one is more suitable for providing rewards for RL. For a fair comparison, we use the same evaluation data that was used in Method 2. Since Method 1 has 6 aspect categories, we obtain individual results using the best-performing approach and group them into two as we did for Method 2. Table <a class="ltx_ref" href="https://arxiv.org/html/2404.03414v1#S11.T5" title="Table 5 ‚Ä£ 11.2. Automatic Measurement for Rationale Quality ‚Ä£ 11. Appendices ‚Ä£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought"><span class="ltx_text ltx_ref_tag">5</span></a> reports the accuracy, macro precision, macro recall, and macro F1 for Method 1 and Method 2. The results indicate that, although models from Method 2 are trained on a relatively small dataset, Method 2 is more aligned with human judgments compared to Method 1. Additionally, inference time using Method 2 is significantly faster than Method 1, making it easier to retrieve rewards in the RL setting. As a result, we use Method 2 for all our experiments.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S11.SS3">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">11.3.&nbsp;&nbsp;&nbsp;Training Configuration</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S11.SS3.p1">
<p class="ltx_p" id="S11.SS3.p1.1">We provide a comprehensive description of the hyperparameters utilized in the model training process.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S11.SS3.p2">
<p class="ltx_p" id="S11.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S11.SS3.p2.1.1">Rationale Distillation.</span>
For rationale generation from the teacher model, we randomly sampled 15K examples from each of the two datasets, resulting in a total of 30K examples. After filtering invalid rationales, the dataset was reduced to a total of 23K examples. 90% of data was used for training, and the remaining 10% was used for validation. For training, we used 8 NVIDIA Tesla V100 GPUs with 16GB configurations. Hyperparameters for training are as follows: 3e-3 for learning rates, 5 epochs, 64 batch size.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S11.SS3.p3">
<p class="ltx_p" id="S11.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S11.SS3.p3.1.1">RL for Rationale Refinement.</span> For RL, we utilized the Huggingface‚Äôs TRL<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://huggingface.co/docs/trl/index</span></span></span> library that provides a set of tools to train transformer LMs with RL. Instead of using the same examples used for the rationale distillation, we selectively chose 5000 examples that FLAN-T5 XXL failed to answer the question correctly. The reason behind this choice was to increase the model‚Äôs exposure to challenging questions, thus increasing the likelihood of receiving more learning signals. We used 90% of data for training and the remaining 10% for validation. Training hyperparameters are as follows: 1.4e-5 for learning rates, 1 epoch, 16 batch size. For generation configurations, we set top_k as 0.0, top_p as 1.0, and enabled sampling.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>

</div>


<div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated on Wed Dec 14 18:01:44 2022 by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button></body></html>