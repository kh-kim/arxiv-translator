<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2404.03414] Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought</title><meta property="og:description" content="We introduce a novel framework, LM-Guided CoT, that leverages a lightweight (i.e., <1B) language model (LM) for guiding a black-box large (i.e., >10B) LM in reasoning tasks. Specifically, the lightweight LM firstâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2404.03414">

<!--Generated on Sun May  5 17:59:36 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Can Small Language Models Help Large Language Models Reason Better?: <span id="id12.id1" class="ltx_text ltx_font_italic">LM-Guided Chain-of-Thought</span>
</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id13.id1" class="ltx_p">We introduce a novel framework, <span id="id13.id1.1" class="ltx_text ltx_font_bold">LM-Guided CoT</span>, that leverages a lightweight (<span id="id13.id1.2" class="ltx_text ltx_font_italic">i.e.</span>, &lt;1B) language model (LM) for guiding a black-box large (<span id="id13.id1.3" class="ltx_text ltx_font_italic">i.e.</span>, &gt;10B) LM in reasoning tasks. Specifically, the lightweight LM first generates a rationale for each input instance. The Frozen large LM is then prompted to predict a task output based on the rationale generated by the lightweight LM. Our approach is resource-efficient in the sense that it only requires training the lightweight LM. We optimize the model through 1) knowledge distillation and 2) reinforcement learning from rationale-oriented and task-oriented reward signals. We assess our method with multi-hop extractive question answering (QA) benchmarks, HotpotQA, and 2WikiMultiHopQA. Experimental results show that our approach outperforms all baselines regarding answer prediction accuracy. We also find that reinforcement learning helps the model to produce higher-quality rationales with improved QA performance. 
<br class="ltx_break">
<br class="ltx_break">
<span id="id13.id1.4" class="ltx_text ltx_font_bold">Keywords:â€‰</span>Chain-of-Thought Prompting, Large Language Model, Reinforcement Learning, Knowledge Distillation</p>
</div>
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\useunder</span>
<p id="p1.2" class="ltx_p"><span id="p1.2.1" class="ltx_text ltx_ulem_uline"></span><span id="p1.2.2" class="ltx_text ltx_framed ltx_framed_underline"></span>










<span id="p1.2.3" class="ltx_ERROR undefined">\NAT@set@cites</span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p2" class="ltx_para">
<p id="p2.1" class="ltx_p"><span id="p2.1.1" class="ltx_text"></span></p>
</div>
<div id="id11" class="ltx_logical-block">
<div id="id11.p1" class="ltx_para">
<p id="id11.p1.1" class="ltx_p ltx_align_center"><span id="id11.p1.1.1" class="ltx_text ltx_font_bold" style="font-size:144%;">Can Small Language Models Help Large Language Models Reason Better?: <span id="id11.p1.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">LM-Guided Chain-of-Thought</span></span></p>
<br class="ltx_break ltx_centering">
<table id="id10.10" class="ltx_tabular ltx_centering ltx_align_top">
<tbody><tr id="id8.8.8" class="ltx_tr">
<td id="id8.8.8.8" class="ltx_td ltx_align_center">
<span id="id8.8.8.8.8" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:433.6pt;">
<span id="id5.5.5.5.5.5" class="ltx_p"><span id="id5.5.5.5.5.5.2" class="ltx_text ltx_font_bold" style="font-size:120%;">Jooyoung Lee</span><sup id="id5.5.5.5.5.5.3" class="ltx_sup"><span id="id5.5.5.5.5.5.3.1" class="ltx_text ltx_font_italic" style="font-size:120%;">1â€ </span></sup><span id="id2.2.2.2.2.2.1" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">thanks: </span><sup id="id2.2.2.2.2.2.1.1" class="ltx_sup"><span id="id2.2.2.2.2.2.1.1.1" class="ltx_text" style="font-size:120%;">â€ </span></sup><span id="id2.2.2.2.2.2.1.2" class="ltx_text ltx_font_bold" style="font-size:120%;">This work was done during the internship at Amazon.</span></span></span></span><span id="id5.5.5.5.5.5.4" class="ltx_text ltx_font_bold" style="font-size:120%;">, Fan Yang</span><sup id="id5.5.5.5.5.5.5" class="ltx_sup"><span id="id5.5.5.5.5.5.5.1" class="ltx_text" style="font-size:120%;">2</span></sup><span id="id5.5.5.5.5.5.6" class="ltx_text ltx_font_bold" style="font-size:120%;">, Thanh Tran</span><sup id="id5.5.5.5.5.5.7" class="ltx_sup"><span id="id5.5.5.5.5.5.7.1" class="ltx_text" style="font-size:120%;">2</span></sup><span id="id5.5.5.5.5.5.8" class="ltx_text ltx_font_bold" style="font-size:120%;">, Qian Hu</span><sup id="id5.5.5.5.5.5.9" class="ltx_sup"><span id="id5.5.5.5.5.5.9.1" class="ltx_text" style="font-size:120%;">2</span></sup><span id="id5.5.5.5.5.5.10" class="ltx_text ltx_font_bold" style="font-size:120%;"></span></span>
<span id="id8.8.8.8.8.8" class="ltx_p ltx_align_center"><span id="id8.8.8.8.8.8.1" class="ltx_text ltx_font_bold" style="font-size:120%;">Emre Barut</span><sup id="id8.8.8.8.8.8.2" class="ltx_sup"><span id="id8.8.8.8.8.8.2.1" class="ltx_text" style="font-size:120%;">2</span></sup><span id="id8.8.8.8.8.8.3" class="ltx_text ltx_font_bold" style="font-size:120%;">, Kai-Wei Chang</span><sup id="id8.8.8.8.8.8.4" class="ltx_sup"><span id="id8.8.8.8.8.8.4.1" class="ltx_text" style="font-size:120%;">2</span></sup><span id="id8.8.8.8.8.8.5" class="ltx_text ltx_font_bold" style="font-size:120%;">, Chengwei Su</span><sup id="id8.8.8.8.8.8.6" class="ltx_sup"><span id="id8.8.8.8.8.8.6.1" class="ltx_text" style="font-size:120%;">2</span></sup><span id="id8.8.8.8.8.8.7" class="ltx_text ltx_font_bold" style="font-size:120%;"></span></span>
</span>
</td>
</tr>
<tr id="id9.9.9" class="ltx_tr">
<td id="id9.9.9.1" class="ltx_td ltx_align_center">Penn State University, PA, USA<sup id="id9.9.9.1.1" class="ltx_sup">1</sup>
</td>
</tr>
<tr id="id10.10.10" class="ltx_tr">
<td id="id10.10.10.1" class="ltx_td ltx_align_center">Amazon AGI, MA, USA<sup id="id10.10.10.1.1" class="ltx_sup">2</sup>
</td>
</tr>
<tr id="id10.10.11" class="ltx_tr">
<td id="id10.10.11.1" class="ltx_td ltx_align_center">jfl5838@psu.edu,
{fyaamz, tdt, huqia, ebarut, kaiwec, chengwes}@amazon.com</td>
</tr>
</tbody></table>
<p id="id11.p1.2" class="ltx_p ltx_align_center"><span id="id11.p1.2.1" class="ltx_text ltx_font_italic">Abstract content</span></p>
</div>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">1.&nbsp;&nbsp;&nbsp;Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Chain-of-Thought (CoT) prompting <cite class="ltx_cite ltx_citemacro_cite">Wei et&nbsp;al. (<a href="#bib.bib22" title="" class="ltx_ref">2022b</a>)</cite> has gained attention as a means to elicit the inherent reasoning abilities of a language model (LM). By prompting the models with <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">â€œLetâ€™s think step by stepâ€</span> following the actual task description, the model first produces intermediate reasoning steps and then predicts a task output. It has been shown to enhance the downstream task performance in complex reasoning domains such as arithmetic <cite class="ltx_cite ltx_citemacro_cite">Lewkowycz et&nbsp;al. (<a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite>, commonsense <cite class="ltx_cite ltx_citemacro_cite">Jung et&nbsp;al. (<a href="#bib.bib5" title="" class="ltx_ref">2022</a>)</cite>, and symbolic <cite class="ltx_cite ltx_citemacro_cite">Khot et&nbsp;al. (<a href="#bib.bib6" title="" class="ltx_ref">2022</a>)</cite> reasoning. However, there are several limitations to conventional CoT prompting. Firstly, the performance gains when compared to standard prompting (<span id="S1.p1.1.2" class="ltx_text ltx_font_italic">i.e.</span>, without <span id="S1.p1.1.3" class="ltx_text ltx_font_italic">â€œLetâ€™s think step by stepâ€</span>) are only likely to emerge in very large LMs, preferably 100+ billion parameters <cite class="ltx_cite ltx_citemacro_cite">Wei et&nbsp;al. (<a href="#bib.bib21" title="" class="ltx_ref">2022a</a>)</cite>. Moreover, the models may still generate low-quality rationales that are repetitive and vacuous <cite class="ltx_cite ltx_citemacro_cite">Ye and Durrett (<a href="#bib.bib23" title="" class="ltx_ref">2022</a>)</cite>. This can be attributed to their tendencies to lack faithfulness to an input instance <cite class="ltx_cite ltx_citemacro_cite">Lanham et&nbsp;al. (<a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite> and to produce unaligned rationales and answers <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib20" title="" class="ltx_ref">2022b</a>); Turpin et&nbsp;al. (<a href="#bib.bib17" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Given that CoT prompting is primarily effective with large LMs, rectifying these undesirable behaviors through direct model modifications is non-trivial, particularly with constrained computational resources. Hence, we propose <span id="S1.p2.1.1" class="ltx_text ltx_font_bold">LM-guided CoT</span>, a novel framework that leverages two independent LMs (<span id="S1.p2.1.2" class="ltx_text ltx_font_italic">i.e.</span>, a small LM for rationale generation and a large LM for answer prediction) for CoT reasoning. As shown in Figure <a href="#S1.F1" title="Figure 1 â€£ 1. Introduction â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, we first employ a vanilla knowledge distillation (KD) technique to the small LM with rationales generated by the large LM (Â§<a href="#S3.SS1" title="3.1. Rationale Distillation â€£ 3. LM-guided Chain-of-Thought â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>).
This initial step helps narrow the gap in reasoning capabilities between the smaller and larger LMs to a certain extent. To further improve the quality of rationales generated by the knowledge-distilled LM, we establish fine-grained measurements concerning 8 rationale-specific aspects (relevance, actuality, logicality, consistency, coherence, fluency, naturalness, and readability) and use them to optimize the knowledge-distilled LM with reinforcement learning (RL) (Â§<a href="#S3.SS2" title="3.2. Rationale Refinement â€£ 3. LM-guided Chain-of-Thought â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>).</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2404.03414/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Illustration of our proposed method.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">We conduct experiments on an extractive multi-hop question answering (QA) task using two popular benchmarks, HotpotQA <cite class="ltx_cite ltx_citemacro_cite">Yang et&nbsp;al. (<a href="#biba.bib2" title="" class="ltx_ref">2018</a>)</cite> and 2WikiMultiHopQA <cite class="ltx_cite ltx_citemacro_cite">Ho et&nbsp;al. (<a href="#biba.bib1" title="" class="ltx_ref">2020</a>)</cite>. Although our framework can be flexibly applied to a wide range of LMs, we use FLAN-T5 <cite class="ltx_cite ltx_citemacro_cite">Longpre et&nbsp;al. (<a href="#bib.bib11" title="" class="ltx_ref">2023</a>)</cite> models in this work because they are open-source and instruction-tuned on both QA and CoT data, enabling us to use it off-the-shelf without additional training or prompt engineering.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We also ran a small experiment with the <a target="_blank" href="https://huggingface.co/VMware/open-llama-7b-open-instruct" title="" class="ltx_ref ltx_href">instruction-tuned Open LLaMa (7B) model</a> and confirmed that its performance is significantly worse than FLAN-T5 in a zero-shot setting.</span></span></span> Our experiment results show that <span id="S1.p3.1.1" class="ltx_text ltx_ulem_uline">LM-guided CoT prompting outperforms both the standard prompting and the original CoT prompting.</span> More precisely, we find that (1) LM-guided CoT with KD and self-consistency (SC) decoding strategy <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib20" title="" class="ltx_ref">2022b</a>)</cite> maximizes the performance gain; (2) RL contributes to a slight increase in overall rationale quality and task performance; (3) choosing the highest-quality rationales for the large LM does not always guarantee improved task performance. This work presents a unique alternative to the direct optimization of the large LM through fine-tuning the comparatively smaller LM. Moreover, the clear separation of two fundamental sub-tasks within CoT reasoning grants practitioners greater control over each task.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">2.&nbsp;&nbsp;&nbsp;Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p"><span id="S2.p1.1.1" class="ltx_text ltx_font_bold">Rationale Distillation.</span> For computation efficiency or task performance, recent literature has explored methods to improve small LMsâ€™ reasoning abilities. <cite class="ltx_cite ltx_citemacro_citet">Li et&nbsp;al. (<a href="#bib.bib9" title="" class="ltx_ref">2023</a>); Shridhar et&nbsp;al. (<a href="#bib.bib15" title="" class="ltx_ref">2023</a>); Ma et&nbsp;al. (<a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite> have experimented with rationale distillation, where a small student LM learns from a large teacher LM to generate CoT rationales. While these studies have mainly concentrated on comparing its performance in downstream tasks against that of large LMs, there has been limited investigation into addressing errors in the generated rationales that might have been inherited from the teacher model.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Rationale Evaluation and Refinement.</span> In contexts beyond rationale distillation, there have been growing efforts to unravel which aspects of the generated reasoning steps contribute to the downstream task performance. <cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib18" title="" class="ltx_ref">2022a</a>)</cite> report that rationalesâ€™ logicality and relevance to the query are key factors in successful CoT reasoning. Few studies have measured the validity of reasoning steps from the lens of more diverse aspects like informativeness, coherence, and repetition, etc <cite class="ltx_cite ltx_citemacro_cite">Golovneva et&nbsp;al. (<a href="#bib.bib3" title="" class="ltx_ref">2022</a>); Prasad et&nbsp;al. (<a href="#bib.bib13" title="" class="ltx_ref">2023</a>)</cite>.
While RL has gained popularity as an approach for addressing misaligned behaviors in LMs, the field of rationale correction has seen limited research.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">3.&nbsp;&nbsp;&nbsp;LM-guided Chain-of-Thought</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.3" class="ltx_p">The proposed framework consists of two LMs: a lightweight model <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="M^{S}" display="inline"><semantics id="S3.p1.1.m1.1a"><msup id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml"><mi id="S3.p1.1.m1.1.1.2" xref="S3.p1.1.m1.1.1.2.cmml">M</mi><mi id="S3.p1.1.m1.1.1.3" xref="S3.p1.1.m1.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><apply id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p1.1.m1.1.1.1.cmml" xref="S3.p1.1.m1.1.1">superscript</csymbol><ci id="S3.p1.1.m1.1.1.2.cmml" xref="S3.p1.1.m1.1.1.2">ğ‘€</ci><ci id="S3.p1.1.m1.1.1.3.cmml" xref="S3.p1.1.m1.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">M^{S}</annotation></semantics></math> that focuses on generating the optimal rationale given an input instance, and a black-box large model <math id="S3.p1.2.m2.1" class="ltx_Math" alttext="M^{L}" display="inline"><semantics id="S3.p1.2.m2.1a"><msup id="S3.p1.2.m2.1.1" xref="S3.p1.2.m2.1.1.cmml"><mi id="S3.p1.2.m2.1.1.2" xref="S3.p1.2.m2.1.1.2.cmml">M</mi><mi id="S3.p1.2.m2.1.1.3" xref="S3.p1.2.m2.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p1.2.m2.1b"><apply id="S3.p1.2.m2.1.1.cmml" xref="S3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.p1.2.m2.1.1.1.cmml" xref="S3.p1.2.m2.1.1">superscript</csymbol><ci id="S3.p1.2.m2.1.1.2.cmml" xref="S3.p1.2.m2.1.1.2">ğ‘€</ci><ci id="S3.p1.2.m2.1.1.3.cmml" xref="S3.p1.2.m2.1.1.3">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.2.m2.1c">M^{L}</annotation></semantics></math> that predicts an output based on the rationale generated by <math id="S3.p1.3.m3.1" class="ltx_Math" alttext="M^{S}" display="inline"><semantics id="S3.p1.3.m3.1a"><msup id="S3.p1.3.m3.1.1" xref="S3.p1.3.m3.1.1.cmml"><mi id="S3.p1.3.m3.1.1.2" xref="S3.p1.3.m3.1.1.2.cmml">M</mi><mi id="S3.p1.3.m3.1.1.3" xref="S3.p1.3.m3.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S3.p1.3.m3.1b"><apply id="S3.p1.3.m3.1.1.cmml" xref="S3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.p1.3.m3.1.1.1.cmml" xref="S3.p1.3.m3.1.1">superscript</csymbol><ci id="S3.p1.3.m3.1.1.2.cmml" xref="S3.p1.3.m3.1.1.2">ğ‘€</ci><ci id="S3.p1.3.m3.1.1.3.cmml" xref="S3.p1.3.m3.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.3.m3.1c">M^{S}</annotation></semantics></math>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.11" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T1.11.12" class="ltx_tr">
<td id="S3.T1.11.12.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.11.12.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Aspects</span></td>
<td id="S3.T1.11.12.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.11.12.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Descriptions</span></td>
</tr>
<tr id="S3.T1.2.2" class="ltx_tr">
<td id="S3.T1.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.2.2.3.1" class="ltx_text" style="font-size:90%;">Factuality</span></td>
<td id="S3.T1.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S3.T1.2.2.2.3" class="ltx_text" style="font-size:90%;">Percentage (0.0-1.0) measuring if the reasoning is grounded based on the context </span><span id="S3.T1.2.2.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;color:#0000FF;">(Input: <math id="S3.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.T1.1.1.1.1.m1.1a"><mi mathcolor="#0000FF" id="S3.T1.1.1.1.1.m1.1.1" xref="S3.T1.1.1.1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.T1.1.1.1.1.m1.1b"><ci id="S3.T1.1.1.1.1.m1.1.1.cmml" xref="S3.T1.1.1.1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.1.1.1.1.m1.1c">c</annotation></semantics></math> &amp; <math id="S3.T1.2.2.2.2.m2.1" class="ltx_Math" alttext="r^{\prime}" display="inline"><semantics id="S3.T1.2.2.2.2.m2.1a"><msup id="S3.T1.2.2.2.2.m2.1.1" xref="S3.T1.2.2.2.2.m2.1.1.cmml"><mi mathcolor="#0000FF" id="S3.T1.2.2.2.2.m2.1.1.2" xref="S3.T1.2.2.2.2.m2.1.1.2.cmml">r</mi><mo mathcolor="#0000FF" id="S3.T1.2.2.2.2.m2.1.1.3" xref="S3.T1.2.2.2.2.m2.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.2.2.2.2.m2.1b"><apply id="S3.T1.2.2.2.2.m2.1.1.cmml" xref="S3.T1.2.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.T1.2.2.2.2.m2.1.1.1.cmml" xref="S3.T1.2.2.2.2.m2.1.1">superscript</csymbol><ci id="S3.T1.2.2.2.2.m2.1.1.2.cmml" xref="S3.T1.2.2.2.2.m2.1.1.2">ğ‘Ÿ</ci><ci id="S3.T1.2.2.2.2.m2.1.1.3.cmml" xref="S3.T1.2.2.2.2.m2.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.2.2.2.m2.1c">r^{\prime}</annotation></semantics></math>)</span>
</td>
</tr>
<tr id="S3.T1.4.4" class="ltx_tr">
<td id="S3.T1.4.4.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.4.4.3.1" class="ltx_text" style="font-size:90%;">Relevance</span></td>
<td id="S3.T1.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S3.T1.4.4.2.3" class="ltx_text" style="font-size:90%;">Percentage (0.0-1.0) measuring if the reasoning is relevant to the question </span><span id="S3.T1.4.4.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;color:#0000FF;">(Input: <math id="S3.T1.3.3.1.1.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.T1.3.3.1.1.m1.1a"><mi mathcolor="#0000FF" id="S3.T1.3.3.1.1.m1.1.1" xref="S3.T1.3.3.1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.T1.3.3.1.1.m1.1b"><ci id="S3.T1.3.3.1.1.m1.1.1.cmml" xref="S3.T1.3.3.1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.3.3.1.1.m1.1c">q</annotation></semantics></math> &amp; <math id="S3.T1.4.4.2.2.m2.1" class="ltx_Math" alttext="r^{\prime}" display="inline"><semantics id="S3.T1.4.4.2.2.m2.1a"><msup id="S3.T1.4.4.2.2.m2.1.1" xref="S3.T1.4.4.2.2.m2.1.1.cmml"><mi mathcolor="#0000FF" id="S3.T1.4.4.2.2.m2.1.1.2" xref="S3.T1.4.4.2.2.m2.1.1.2.cmml">r</mi><mo mathcolor="#0000FF" id="S3.T1.4.4.2.2.m2.1.1.3" xref="S3.T1.4.4.2.2.m2.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.2.2.m2.1b"><apply id="S3.T1.4.4.2.2.m2.1.1.cmml" xref="S3.T1.4.4.2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.T1.4.4.2.2.m2.1.1.1.cmml" xref="S3.T1.4.4.2.2.m2.1.1">superscript</csymbol><ci id="S3.T1.4.4.2.2.m2.1.1.2.cmml" xref="S3.T1.4.4.2.2.m2.1.1.2">ğ‘Ÿ</ci><ci id="S3.T1.4.4.2.2.m2.1.1.3.cmml" xref="S3.T1.4.4.2.2.m2.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.2.2.m2.1c">r^{\prime}</annotation></semantics></math>)</span>
</td>
</tr>
<tr id="S3.T1.11.13" class="ltx_tr">
<td id="S3.T1.11.13.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.11.13.1.1" class="ltx_text" style="font-size:90%;">Logicality</span></td>
<td id="S3.T1.11.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S3.T1.11.13.2.1" class="ltx_text" style="font-size:90%;">Binary (0 or 1) measuring if the reasoning is logical and can reach a final answer</span></td>
</tr>
<tr id="S3.T1.6.6" class="ltx_tr">
<td id="S3.T1.6.6.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.6.6.3.1" class="ltx_text" style="font-size:90%;">Consistency</span></td>
<td id="S3.T1.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S3.T1.6.6.2.3" class="ltx_text" style="font-size:90%;">Binary (0 or 1) measuring if the reasoning remains consistent and coherent </span><span id="S3.T1.6.6.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;color:#0000FF;">(Input: <math id="S3.T1.5.5.1.1.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.T1.5.5.1.1.m1.1a"><mi mathcolor="#0000FF" id="S3.T1.5.5.1.1.m1.1.1" xref="S3.T1.5.5.1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.1.1.m1.1b"><ci id="S3.T1.5.5.1.1.m1.1.1.cmml" xref="S3.T1.5.5.1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.1.1.m1.1c">q</annotation></semantics></math> &amp; <math id="S3.T1.6.6.2.2.m2.1" class="ltx_Math" alttext="r^{\prime}" display="inline"><semantics id="S3.T1.6.6.2.2.m2.1a"><msup id="S3.T1.6.6.2.2.m2.1.1" xref="S3.T1.6.6.2.2.m2.1.1.cmml"><mi mathcolor="#0000FF" id="S3.T1.6.6.2.2.m2.1.1.2" xref="S3.T1.6.6.2.2.m2.1.1.2.cmml">r</mi><mo mathcolor="#0000FF" id="S3.T1.6.6.2.2.m2.1.1.3" xref="S3.T1.6.6.2.2.m2.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.2.2.m2.1b"><apply id="S3.T1.6.6.2.2.m2.1.1.cmml" xref="S3.T1.6.6.2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.T1.6.6.2.2.m2.1.1.1.cmml" xref="S3.T1.6.6.2.2.m2.1.1">superscript</csymbol><ci id="S3.T1.6.6.2.2.m2.1.1.2.cmml" xref="S3.T1.6.6.2.2.m2.1.1.2">ğ‘Ÿ</ci><ci id="S3.T1.6.6.2.2.m2.1.1.3.cmml" xref="S3.T1.6.6.2.2.m2.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.2.2.m2.1c">r^{\prime}</annotation></semantics></math>)</span>
</td>
</tr>
<tr id="S3.T1.8.8" class="ltx_tr">
<td id="S3.T1.8.8.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.8.8.3.1" class="ltx_text" style="font-size:90%;">Coherence</span></td>
<td id="S3.T1.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S3.T1.8.8.2.3" class="ltx_text" style="font-size:90%;">Binary (0 or 1) measuring if the reasoning is without redundant information </span><span id="S3.T1.8.8.2.2" class="ltx_text ltx_font_italic" style="font-size:90%;color:#0000FF;">(Input: <math id="S3.T1.7.7.1.1.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.T1.7.7.1.1.m1.1a"><mi mathcolor="#0000FF" id="S3.T1.7.7.1.1.m1.1.1" xref="S3.T1.7.7.1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.1.1.m1.1b"><ci id="S3.T1.7.7.1.1.m1.1.1.cmml" xref="S3.T1.7.7.1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.1.1.m1.1c">q</annotation></semantics></math> &amp; <math id="S3.T1.8.8.2.2.m2.1" class="ltx_Math" alttext="r^{\prime}" display="inline"><semantics id="S3.T1.8.8.2.2.m2.1a"><msup id="S3.T1.8.8.2.2.m2.1.1" xref="S3.T1.8.8.2.2.m2.1.1.cmml"><mi mathcolor="#0000FF" id="S3.T1.8.8.2.2.m2.1.1.2" xref="S3.T1.8.8.2.2.m2.1.1.2.cmml">r</mi><mo mathcolor="#0000FF" id="S3.T1.8.8.2.2.m2.1.1.3" xref="S3.T1.8.8.2.2.m2.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.2.2.m2.1b"><apply id="S3.T1.8.8.2.2.m2.1.1.cmml" xref="S3.T1.8.8.2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.T1.8.8.2.2.m2.1.1.1.cmml" xref="S3.T1.8.8.2.2.m2.1.1">superscript</csymbol><ci id="S3.T1.8.8.2.2.m2.1.1.2.cmml" xref="S3.T1.8.8.2.2.m2.1.1.2">ğ‘Ÿ</ci><ci id="S3.T1.8.8.2.2.m2.1.1.3.cmml" xref="S3.T1.8.8.2.2.m2.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.2.2.m2.1c">r^{\prime}</annotation></semantics></math>)</span>
</td>
</tr>
<tr id="S3.T1.9.9" class="ltx_tr">
<td id="S3.T1.9.9.2" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.9.9.2.1" class="ltx_text" style="font-size:90%;">Fluency</span></td>
<td id="S3.T1.9.9.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S3.T1.9.9.1.2" class="ltx_text" style="font-size:90%;">Binary (0 or 1) measuring if the reasoning is well-written and grammatically correct </span><span id="S3.T1.9.9.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;color:#0000FF;">(Input: <math id="S3.T1.9.9.1.1.m1.1" class="ltx_Math" alttext="r^{\prime}" display="inline"><semantics id="S3.T1.9.9.1.1.m1.1a"><msup id="S3.T1.9.9.1.1.m1.1.1" xref="S3.T1.9.9.1.1.m1.1.1.cmml"><mi mathcolor="#0000FF" id="S3.T1.9.9.1.1.m1.1.1.2" xref="S3.T1.9.9.1.1.m1.1.1.2.cmml">r</mi><mo mathcolor="#0000FF" id="S3.T1.9.9.1.1.m1.1.1.3" xref="S3.T1.9.9.1.1.m1.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.1.1.m1.1b"><apply id="S3.T1.9.9.1.1.m1.1.1.cmml" xref="S3.T1.9.9.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.9.9.1.1.m1.1.1.1.cmml" xref="S3.T1.9.9.1.1.m1.1.1">superscript</csymbol><ci id="S3.T1.9.9.1.1.m1.1.1.2.cmml" xref="S3.T1.9.9.1.1.m1.1.1.2">ğ‘Ÿ</ci><ci id="S3.T1.9.9.1.1.m1.1.1.3.cmml" xref="S3.T1.9.9.1.1.m1.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.1.1.m1.1c">r^{\prime}</annotation></semantics></math>)</span>
</td>
</tr>
<tr id="S3.T1.10.10" class="ltx_tr">
<td id="S3.T1.10.10.2" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.10.10.2.1" class="ltx_text" style="font-size:90%;">Naturalness</span></td>
<td id="S3.T1.10.10.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span id="S3.T1.10.10.1.2" class="ltx_text" style="font-size:90%;">Binary (0 or 1) measuring if the reasoning is natural and human-like </span><span id="S3.T1.10.10.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;color:#0000FF;">(Input: <math id="S3.T1.10.10.1.1.m1.1" class="ltx_Math" alttext="r^{\prime}" display="inline"><semantics id="S3.T1.10.10.1.1.m1.1a"><msup id="S3.T1.10.10.1.1.m1.1.1" xref="S3.T1.10.10.1.1.m1.1.1.cmml"><mi mathcolor="#0000FF" id="S3.T1.10.10.1.1.m1.1.1.2" xref="S3.T1.10.10.1.1.m1.1.1.2.cmml">r</mi><mo mathcolor="#0000FF" id="S3.T1.10.10.1.1.m1.1.1.3" xref="S3.T1.10.10.1.1.m1.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.10.10.1.1.m1.1b"><apply id="S3.T1.10.10.1.1.m1.1.1.cmml" xref="S3.T1.10.10.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.10.10.1.1.m1.1.1.1.cmml" xref="S3.T1.10.10.1.1.m1.1.1">superscript</csymbol><ci id="S3.T1.10.10.1.1.m1.1.1.2.cmml" xref="S3.T1.10.10.1.1.m1.1.1.2">ğ‘Ÿ</ci><ci id="S3.T1.10.10.1.1.m1.1.1.3.cmml" xref="S3.T1.10.10.1.1.m1.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.10.10.1.1.m1.1c">r^{\prime}</annotation></semantics></math>)</span>
</td>
</tr>
<tr id="S3.T1.11.11" class="ltx_tr">
<td id="S3.T1.11.11.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.11.11.2.1" class="ltx_text" style="font-size:90%;">Readability</span></td>
<td id="S3.T1.11.11.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T1.11.11.1.2" class="ltx_text" style="font-size:90%;">Binary (0 or 1) measuring if the reasoning is easy to follow and understandable </span><span id="S3.T1.11.11.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;color:#0000FF;">(Input: <math id="S3.T1.11.11.1.1.m1.1" class="ltx_Math" alttext="r^{\prime}" display="inline"><semantics id="S3.T1.11.11.1.1.m1.1a"><msup id="S3.T1.11.11.1.1.m1.1.1" xref="S3.T1.11.11.1.1.m1.1.1.cmml"><mi mathcolor="#0000FF" id="S3.T1.11.11.1.1.m1.1.1.2" xref="S3.T1.11.11.1.1.m1.1.1.2.cmml">r</mi><mo mathcolor="#0000FF" id="S3.T1.11.11.1.1.m1.1.1.3" xref="S3.T1.11.11.1.1.m1.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.11.11.1.1.m1.1b"><apply id="S3.T1.11.11.1.1.m1.1.1.cmml" xref="S3.T1.11.11.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.11.11.1.1.m1.1.1.1.cmml" xref="S3.T1.11.11.1.1.m1.1.1">superscript</csymbol><ci id="S3.T1.11.11.1.1.m1.1.1.2.cmml" xref="S3.T1.11.11.1.1.m1.1.1.2">ğ‘Ÿ</ci><ci id="S3.T1.11.11.1.1.m1.1.1.3.cmml" xref="S3.T1.11.11.1.1.m1.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.11.11.1.1.m1.1c">r^{\prime}</annotation></semantics></math>)</span>
</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Descriptions of 8 rationale aspects used for evaluation. <math id="S3.T1.15.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.T1.15.m1.1b"><mi id="S3.T1.15.m1.1.1" xref="S3.T1.15.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.T1.15.m1.1c"><ci id="S3.T1.15.m1.1.1.cmml" xref="S3.T1.15.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.15.m1.1d">q</annotation></semantics></math>, <math id="S3.T1.16.m2.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.T1.16.m2.1b"><mi id="S3.T1.16.m2.1.1" xref="S3.T1.16.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.T1.16.m2.1c"><ci id="S3.T1.16.m2.1.1.cmml" xref="S3.T1.16.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.16.m2.1d">c</annotation></semantics></math>, and <math id="S3.T1.17.m3.1" class="ltx_Math" alttext="r^{\prime}" display="inline"><semantics id="S3.T1.17.m3.1b"><msup id="S3.T1.17.m3.1.1" xref="S3.T1.17.m3.1.1.cmml"><mi id="S3.T1.17.m3.1.1.2" xref="S3.T1.17.m3.1.1.2.cmml">r</mi><mo id="S3.T1.17.m3.1.1.3" xref="S3.T1.17.m3.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T1.17.m3.1c"><apply id="S3.T1.17.m3.1.1.cmml" xref="S3.T1.17.m3.1.1"><csymbol cd="ambiguous" id="S3.T1.17.m3.1.1.1.cmml" xref="S3.T1.17.m3.1.1">superscript</csymbol><ci id="S3.T1.17.m3.1.1.2.cmml" xref="S3.T1.17.m3.1.1.2">ğ‘Ÿ</ci><ci id="S3.T1.17.m3.1.1.3.cmml" xref="S3.T1.17.m3.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.17.m3.1d">r^{\prime}</annotation></semantics></math> denote a question, context, and a corresponding rationale generated by the small LM, respectively.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">3.1.&nbsp;&nbsp;&nbsp;Rationale Distillation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.10" class="ltx_p"><span id="S3.SS1.p1.10.1" class="ltx_text ltx_font_bold">Rationale Generation.</span> In general, multi-hop extractive QA datasets contain a list of questions <math id="S3.SS1.p1.1.m1.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="S3.SS1.p1.1.m1.1a"><mi id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><ci id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">ğ‘„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">Q</annotation></semantics></math>, contexts <math id="S3.SS1.p1.2.m2.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.SS1.p1.2.m2.1a"><mi id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><ci id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">C</annotation></semantics></math>, and corresponding ground truth answers <math id="S3.SS1.p1.3.m3.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS1.p1.3.m3.1a"><mi id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><ci id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">A</annotation></semantics></math>. For each input (<math id="S3.SS1.p1.4.m4.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS1.p1.4.m4.1a"><mi id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><ci id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">q</annotation></semantics></math>, <math id="S3.SS1.p1.5.m5.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS1.p1.5.m5.1a"><mi id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><ci id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">c</annotation></semantics></math>)-output (<math id="S3.SS1.p1.6.m6.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S3.SS1.p1.6.m6.1a"><mi id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><ci id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">a</annotation></semantics></math>) pair, we need a corresponding ground truth rationale <math id="S3.SS1.p1.7.m7.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS1.p1.7.m7.1a"><mi id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><ci id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">r</annotation></semantics></math> to train <math id="S3.SS1.p1.8.m8.1" class="ltx_Math" alttext="M^{S}" display="inline"><semantics id="S3.SS1.p1.8.m8.1a"><msup id="S3.SS1.p1.8.m8.1.1" xref="S3.SS1.p1.8.m8.1.1.cmml"><mi id="S3.SS1.p1.8.m8.1.1.2" xref="S3.SS1.p1.8.m8.1.1.2.cmml">M</mi><mi id="S3.SS1.p1.8.m8.1.1.3" xref="S3.SS1.p1.8.m8.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.8.m8.1b"><apply id="S3.SS1.p1.8.m8.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.8.m8.1.1.1.cmml" xref="S3.SS1.p1.8.m8.1.1">superscript</csymbol><ci id="S3.SS1.p1.8.m8.1.1.2.cmml" xref="S3.SS1.p1.8.m8.1.1.2">ğ‘€</ci><ci id="S3.SS1.p1.8.m8.1.1.3.cmml" xref="S3.SS1.p1.8.m8.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.8.m8.1c">M^{S}</annotation></semantics></math> for rationale generation in a supervised manner. However, most QA benchmarks do not provide <math id="S3.SS1.p1.9.m9.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS1.p1.9.m9.1a"><mi id="S3.SS1.p1.9.m9.1.1" xref="S3.SS1.p1.9.m9.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.9.m9.1b"><ci id="S3.SS1.p1.9.m9.1.1.cmml" xref="S3.SS1.p1.9.m9.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.9.m9.1c">r</annotation></semantics></math>. Given that manual annotation for <math id="S3.SS1.p1.10.m10.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS1.p1.10.m10.1a"><mi id="S3.SS1.p1.10.m10.1.1" xref="S3.SS1.p1.10.m10.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.10.m10.1b"><ci id="S3.SS1.p1.10.m10.1.1.cmml" xref="S3.SS1.p1.10.m10.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.10.m10.1c">r</annotation></semantics></math> is labor-intensive and time-consuming, we </p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<svg id="S3.SS1.p2.pic1" class="ltx_picture" height="90.12" overflow="visible" version="1.1" width="605.83"><g transform="translate(0,90.12) matrix(1 0 0 -1 0 0) translate(0,5.83)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#808080" fill="#808080" color="#808080"><g stroke-opacity="0.01" fill-opacity="0.01"><path d="M 2.05 3.94 L 2.05 72.48 C 2.05 77.87 6.42 82.24 11.81 82.24 L 596.06 82.24 C 601.46 82.24 605.83 77.87 605.83 72.48 L 605.83 3.94 C 605.83 -1.46 601.46 -5.83 596.06 -5.83 L 11.81 -5.83 C 6.42 -5.83 2.05 -1.46 2.05 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.02" fill-opacity="0.02"><path d="M 2.52 3.94 L 2.52 72.48 C 2.52 77.61 6.68 81.77 11.81 81.77 L 596.06 81.77 C 601.19 81.77 605.35 77.61 605.35 72.48 L 605.35 3.94 C 605.35 -1.19 601.19 -5.35 596.06 -5.35 L 11.81 -5.35 C 6.68 -5.35 2.52 -1.19 2.52 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.04" fill-opacity="0.04"><path d="M 2.99 3.94 L 2.99 72.48 C 2.99 77.35 6.94 81.3 11.81 81.3 L 596.06 81.3 C 600.93 81.3 604.88 77.35 604.88 72.48 L 604.88 3.94 C 604.88 -0.93 600.93 -4.88 596.06 -4.88 L 11.81 -4.88 C 6.94 -4.88 2.99 -0.93 2.99 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.07" fill-opacity="0.07"><path d="M 3.46 3.94 L 3.46 72.48 C 3.46 77.09 7.2 80.83 11.81 80.83 L 596.06 80.83 C 600.67 80.83 604.41 77.09 604.41 72.48 L 604.41 3.94 C 604.41 -0.67 600.67 -4.41 596.06 -4.41 L 11.81 -4.41 C 7.2 -4.41 3.46 -0.67 3.46 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.11" fill-opacity="0.11"><path d="M 3.94 3.94 L 3.94 72.48 C 3.94 76.83 7.46 80.35 11.81 80.35 L 596.06 80.35 C 600.41 80.35 603.94 76.83 603.94 72.48 L 603.94 3.94 C 603.94 -0.41 600.41 -3.94 596.06 -3.94 L 11.81 -3.94 C 7.46 -3.94 3.94 -0.41 3.94 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.11" fill-opacity="0.11"><path d="M 4.41 3.94 L 4.41 72.48 C 4.41 76.57 7.72 79.88 11.81 79.88 L 596.06 79.88 C 600.15 79.88 603.46 76.57 603.46 72.48 L 603.46 3.94 C 603.46 -0.15 600.15 -3.46 596.06 -3.46 L 11.81 -3.46 C 7.72 -3.46 4.41 -0.15 4.41 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.07" fill-opacity="0.07"><path d="M 4.88 3.94 L 4.88 72.48 C 4.88 76.31 7.98 79.41 11.81 79.41 L 596.06 79.41 C 599.89 79.41 602.99 76.31 602.99 72.48 L 602.99 3.94 C 602.99 0.11 599.89 -2.99 596.06 -2.99 L 11.81 -2.99 C 7.98 -2.99 4.88 0.11 4.88 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.04" fill-opacity="0.04"><path d="M 5.35 3.94 L 5.35 72.48 C 5.35 76.05 8.25 78.94 11.81 78.94 L 596.06 78.94 C 599.63 78.94 602.52 76.05 602.52 72.48 L 602.52 3.94 C 602.52 0.37 599.63 -2.52 596.06 -2.52 L 11.81 -2.52 C 8.25 -2.52 5.35 0.37 5.35 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.02" fill-opacity="0.02"><path d="M 5.83 3.94 L 5.83 72.48 C 5.83 75.78 8.51 78.46 11.81 78.46 L 596.06 78.46 C 599.37 78.46 602.05 75.78 602.05 72.48 L 602.05 3.94 C 602.05 0.63 599.37 -2.05 596.06 -2.05 L 11.81 -2.05 C 8.51 -2.05 5.83 0.63 5.83 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.01" fill-opacity="0.01"><path d="M 6.3 3.94 L 6.3 72.48 C 6.3 75.52 8.77 77.99 11.81 77.99 L 596.06 77.99 C 599.11 77.99 601.57 75.52 601.57 72.48 L 601.57 3.94 C 601.57 0.89 599.11 -1.57 596.06 -1.57 L 11.81 -1.57 C 8.77 -1.57 6.3 0.89 6.3 3.94 Z" style="stroke:none"></path></g></g><g fill="#F5F5F5" fill-opacity="1.0"><path d="M 0 5.91 L 0 78.39 C 0 81.65 2.64 84.29 5.91 84.29 L 594.09 84.29 C 597.36 84.29 600 81.65 600 78.39 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F5F5F5" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 78.39 C 1.97 80.56 3.73 82.32 5.91 82.32 L 594.09 82.32 C 596.27 82.32 598.03 80.56 598.03 78.39 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="556.69" height="56.73" transform="matrix(1 0 0 -1 0 15.22)" overflow="visible" color="#000000">
<span id="S3.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="S3.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" class="ltx_p"><span id="S3.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" class="ltx_text" style="font-size:90%;">Based on the provided context, answer the following question (Q) by reasoning step-by-step.

<br class="ltx_break"><span id="S3.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.1" class="ltx_text ltx_font_bold">Context</span>: <math id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mi id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">c</annotation></semantics></math>

<br class="ltx_break"><span id="S3.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2" class="ltx_text ltx_font_bold">Q</span>: <math id="S3.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a"><mi id="S3.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="S3.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b"><ci id="S3.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S3.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">q</annotation></semantics></math>

<br class="ltx_break"><span id="S3.SS1.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.3" class="ltx_text ltx_font_bold">A</span> : Letâ€™s think step by step.</span></span>
</span></foreignObject></g></g></svg>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p id="S3.SS1.p3.1" class="ltx_p">For generation, we use greedy decoding; <span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_italic">i.e.</span>, choosing the most plausible token at each generation step.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Rationale Filtering and Training.</span> When it comes to knowledge distillation, data cleaning processes play a crucial role in preventing errors or noises included in the generation from the teacher LM being inherited to the student LM. Thus, we filter samples associated with unfaithful responses to the prompt (<span id="S3.SS1.p4.1.2" class="ltx_text ltx_font_italic">i.e.</span>, not providing rationales prior to providing a final answer) and inaccurate answer prediction. Finally, we instruction-tune <math id="S3.SS1.p4.1.m1.1" class="ltx_Math" alttext="M^{S}" display="inline"><semantics id="S3.SS1.p4.1.m1.1a"><msup id="S3.SS1.p4.1.m1.1.1" xref="S3.SS1.p4.1.m1.1.1.cmml"><mi id="S3.SS1.p4.1.m1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.2.cmml">M</mi><mi id="S3.SS1.p4.1.m1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.2">ğ‘€</ci><ci id="S3.SS1.p4.1.m1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">M^{S}</annotation></semantics></math> using the following prompt:</p>
</div>
<div id="S3.SS1.p5" class="ltx_para ltx_noindent">
<svg id="S3.SS1.p5.pic1" class="ltx_picture" height="105.2" overflow="visible" version="1.1" width="605.83"><g transform="translate(0,105.2) matrix(1 0 0 -1 0 0) translate(0,5.83)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#808080" fill="#808080" color="#808080"><g stroke-opacity="0.01" fill-opacity="0.01"><path d="M 2.05 3.94 L 2.05 87.56 C 2.05 92.95 6.42 97.33 11.81 97.33 L 596.06 97.33 C 601.46 97.33 605.83 92.95 605.83 87.56 L 605.83 3.94 C 605.83 -1.46 601.46 -5.83 596.06 -5.83 L 11.81 -5.83 C 6.42 -5.83 2.05 -1.46 2.05 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.02" fill-opacity="0.02"><path d="M 2.52 3.94 L 2.52 87.56 C 2.52 92.69 6.68 96.85 11.81 96.85 L 596.06 96.85 C 601.19 96.85 605.35 92.69 605.35 87.56 L 605.35 3.94 C 605.35 -1.19 601.19 -5.35 596.06 -5.35 L 11.81 -5.35 C 6.68 -5.35 2.52 -1.19 2.52 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.04" fill-opacity="0.04"><path d="M 2.99 3.94 L 2.99 87.56 C 2.99 92.43 6.94 96.38 11.81 96.38 L 596.06 96.38 C 600.93 96.38 604.88 92.43 604.88 87.56 L 604.88 3.94 C 604.88 -0.93 600.93 -4.88 596.06 -4.88 L 11.81 -4.88 C 6.94 -4.88 2.99 -0.93 2.99 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.07" fill-opacity="0.07"><path d="M 3.46 3.94 L 3.46 87.56 C 3.46 92.17 7.2 95.91 11.81 95.91 L 596.06 95.91 C 600.67 95.91 604.41 92.17 604.41 87.56 L 604.41 3.94 C 604.41 -0.67 600.67 -4.41 596.06 -4.41 L 11.81 -4.41 C 7.2 -4.41 3.46 -0.67 3.46 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.11" fill-opacity="0.11"><path d="M 3.94 3.94 L 3.94 87.56 C 3.94 91.91 7.46 95.44 11.81 95.44 L 596.06 95.44 C 600.41 95.44 603.94 91.91 603.94 87.56 L 603.94 3.94 C 603.94 -0.41 600.41 -3.94 596.06 -3.94 L 11.81 -3.94 C 7.46 -3.94 3.94 -0.41 3.94 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.11" fill-opacity="0.11"><path d="M 4.41 3.94 L 4.41 87.56 C 4.41 91.65 7.72 94.96 11.81 94.96 L 596.06 94.96 C 600.15 94.96 603.46 91.65 603.46 87.56 L 603.46 3.94 C 603.46 -0.15 600.15 -3.46 596.06 -3.46 L 11.81 -3.46 C 7.72 -3.46 4.41 -0.15 4.41 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.07" fill-opacity="0.07"><path d="M 4.88 3.94 L 4.88 87.56 C 4.88 91.39 7.98 94.49 11.81 94.49 L 596.06 94.49 C 599.89 94.49 602.99 91.39 602.99 87.56 L 602.99 3.94 C 602.99 0.11 599.89 -2.99 596.06 -2.99 L 11.81 -2.99 C 7.98 -2.99 4.88 0.11 4.88 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.04" fill-opacity="0.04"><path d="M 5.35 3.94 L 5.35 87.56 C 5.35 91.13 8.25 94.02 11.81 94.02 L 596.06 94.02 C 599.63 94.02 602.52 91.13 602.52 87.56 L 602.52 3.94 C 602.52 0.37 599.63 -2.52 596.06 -2.52 L 11.81 -2.52 C 8.25 -2.52 5.35 0.37 5.35 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.02" fill-opacity="0.02"><path d="M 5.83 3.94 L 5.83 87.56 C 5.83 90.87 8.51 93.55 11.81 93.55 L 596.06 93.55 C 599.37 93.55 602.05 90.87 602.05 87.56 L 602.05 3.94 C 602.05 0.63 599.37 -2.05 596.06 -2.05 L 11.81 -2.05 C 8.51 -2.05 5.83 0.63 5.83 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.01" fill-opacity="0.01"><path d="M 6.3 3.94 L 6.3 87.56 C 6.3 90.61 8.77 93.07 11.81 93.07 L 596.06 93.07 C 599.11 93.07 601.57 90.61 601.57 87.56 L 601.57 3.94 C 601.57 0.89 599.11 -1.57 596.06 -1.57 L 11.81 -1.57 C 8.77 -1.57 6.3 0.89 6.3 3.94 Z" style="stroke:none"></path></g></g><g fill="#F5F5F5" fill-opacity="1.0"><path d="M 0 5.91 L 0 93.47 C 0 96.73 2.64 99.37 5.91 99.37 L 594.09 99.37 C 597.36 99.37 600 96.73 600 93.47 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F5F5F5" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 93.47 C 1.97 95.64 3.73 97.4 5.91 97.4 L 594.09 97.4 C 596.27 97.4 598.03 95.64 598.03 93.47 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="556.69" height="71.81" transform="matrix(1 0 0 -1 0 15.22)" overflow="visible" color="#000000">
<span id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3" class="ltx_p"><span id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3" class="ltx_text" style="font-size:90%;">Given a question (Q) and a context, generate a chain of reasoning step by step to answer the question.

<br class="ltx_break"><span id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1" class="ltx_text ltx_font_bold">Context</span>: <math id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1a"><mi id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c">c</annotation></semantics></math>

<br class="ltx_break"><span id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.2" class="ltx_text ltx_font_bold">Q</span>: <math id="S3.SS1.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS1.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a"><mi id="S3.SS1.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="S3.SS1.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b"><ci id="S3.SS1.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S3.SS1.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">q</annotation></semantics></math>

<br class="ltx_break"><span id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3" class="ltx_text ltx_font_bold">Reasoning</span>: <math id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1" class="ltx_Math" alttext="r^{\prime}" display="inline"><semantics id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1a"><msup id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1" xref="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml"><mi id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2" xref="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.cmml">r</mi><mo id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3" xref="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1b"><apply id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml" xref="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.1.cmml" xref="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1">superscript</csymbol><ci id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.cmml" xref="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2">ğ‘Ÿ</ci><ci id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3.cmml" xref="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1c">r^{\prime}</annotation></semantics></math></span></span>
</span></foreignObject></g></g></svg>
</div>
<div id="S3.SS1.p6" class="ltx_para ltx_noindent">
<p id="S3.SS1.p6.1" class="ltx_p">For the rest of the paper, we denote the rationale-distilled model as <math id="S3.SS1.p6.1.m1.1" class="ltx_Math" alttext="M^{*}" display="inline"><semantics id="S3.SS1.p6.1.m1.1a"><msup id="S3.SS1.p6.1.m1.1.1" xref="S3.SS1.p6.1.m1.1.1.cmml"><mi id="S3.SS1.p6.1.m1.1.1.2" xref="S3.SS1.p6.1.m1.1.1.2.cmml">M</mi><mo id="S3.SS1.p6.1.m1.1.1.3" xref="S3.SS1.p6.1.m1.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.1b"><apply id="S3.SS1.p6.1.m1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.1.m1.1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1">superscript</csymbol><ci id="S3.SS1.p6.1.m1.1.1.2.cmml" xref="S3.SS1.p6.1.m1.1.1.2">ğ‘€</ci><times id="S3.SS1.p6.1.m1.1.1.3.cmml" xref="S3.SS1.p6.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.1c">M^{*}</annotation></semantics></math>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">3.2.&nbsp;&nbsp;&nbsp;Rationale Refinement</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.7" class="ltx_p"><span id="S3.SS2.p1.7.1" class="ltx_text ltx_font_bold">Annotation for Rationale Quality Measurement.</span>
Inspired by previous text and rationale generation evaluation metrics <cite class="ltx_cite ltx_citemacro_cite">Golovneva et&nbsp;al. (<a href="#bib.bib3" title="" class="ltx_ref">2022</a>); Fu et&nbsp;al. (<a href="#bib.bib2" title="" class="ltx_ref">2023</a>)</cite>, we attempt to quantify 8 linguistic aspects (factuality, relevance, logicality, consistency, coherence, fluency, naturalness, readability) of rationales generated by <math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="M^{*}" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><msup id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">M</mi><mo id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">ğ‘€</ci><times id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">M^{*}</annotation></semantics></math> in Â§<a href="#S3.SS1" title="3.1. Rationale Distillation â€£ 3. LM-guided Chain-of-Thought â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>. Let us denote <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="r^{*}" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><msup id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">r</mi><mo id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">ğ‘Ÿ</ci><times id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">r^{*}</annotation></semantics></math> as <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="M^{*}" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><msup id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml">M</mi><mo id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2">ğ‘€</ci><times id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">M^{*}</annotation></semantics></math>-generated reasoning. Since there is no ground truth rationale <math id="S3.SS2.p1.4.m4.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S3.SS2.p1.4.m4.1a"><mi id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><ci id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">ğ‘Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">r</annotation></semantics></math> available for comparison, our metrics are reference-free, utilizing a pair of <math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="r^{*}" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><msup id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><mi id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml">r</mi><mo id="S3.SS2.p1.5.m5.1.1.3" xref="S3.SS2.p1.5.m5.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1">superscript</csymbol><ci id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2">ğ‘Ÿ</ci><times id="S3.SS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">r^{*}</annotation></semantics></math> and one of existing inputs (<math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><mi id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><ci id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">q</annotation></semantics></math> or <math id="S3.SS2.p1.7.m7.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS2.p1.7.m7.1a"><mi id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.1b"><ci id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.1c">c</annotation></semantics></math>). Table <a href="#S3.T1" title="Table 1 â€£ 3. LM-guided Chain-of-Thought â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> describes each aspect type and input combinations. As we intend to use these metrics for reward scoring in RL, it is critical to have an accurate metric. Hence, we obtain a small set (n=100) of gold labels for all aspect types through human annotation. A detailed description of the annotation process and results is reported in Â§<a href="#S11.SS1" title="11.1. Human Annotation for Rationale Quality Measurement â€£ 11. Appendices â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11.1</span></a>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Automatic Measurement for Rationale Quality.</span>
Manual annotation offers substantial value, but within the context of RL, it becomes notably challenging due to frequent reward scoring. Therefore, we probe several ways to automate this process. <cite class="ltx_cite ltx_citemacro_citet">Ye and Durrett (<a href="#bib.bib23" title="" class="ltx_ref">2022</a>)</cite> introduced the simple yet effective approach for assessing factuality and relevance through token-level lexical overlap. We follow their method for factuality and relevance measurement. For the remaining 6 categories, two methods are considered. The first approach is to harness a large LM to function as reference-free NLG evaluators, inspired by recent works (<span id="S3.SS2.p2.1.2" class="ltx_text ltx_font_italic">e.g.</span>, <cite class="ltx_cite ltx_citemacro_citet">Liu et&nbsp;al. (<a href="#bib.bib10" title="" class="ltx_ref">2023</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib19" title="" class="ltx_ref">2023</a>)</cite>). The second approach, in contrast, involves training a simple machine learning classifier using human-annotated data. Both approaches are comprehensively described in Â§<a href="#S11.SS2" title="11.2. Automatic Measurement for Rationale Quality â€£ 11. Appendices â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11.2</span></a>. Due to inference time efficiency and higher alignment scores to human annotators (see Table <a href="#S11.T5" title="Table 5 â€£ 11.2. Automatic Measurement for Rationale Quality â€£ 11. Appendices â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>), we resort to the second method for all our experiments.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p id="S3.SS2.p3.11" class="ltx_p"><span id="S3.SS2.p3.11.1" class="ltx_text ltx_font_bold">RL for Rationale Refinement.</span>
We next detail how to utilize established evaluation metrics as reward signals to update the knowledge-distilled <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="M^{*}" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><msup id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">M</mi><mo id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">ğ‘€</ci><times id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">M^{*}</annotation></semantics></math> with Proximal Policy Optimization (PPO) <cite class="ltx_cite ltx_citemacro_cite">Schulman et&nbsp;al. (<a href="#bib.bib14" title="" class="ltx_ref">2017</a>)</cite>. Given each input (<math id="S3.SS2.p3.2.m2.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS2.p3.2.m2.1a"><mi id="S3.SS2.p3.2.m2.1.1" xref="S3.SS2.p3.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.2.m2.1b"><ci id="S3.SS2.p3.2.m2.1.1.cmml" xref="S3.SS2.p3.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.2.m2.1c">q</annotation></semantics></math>, <math id="S3.SS2.p3.3.m3.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.SS2.p3.3.m3.1a"><mi id="S3.SS2.p3.3.m3.1.1" xref="S3.SS2.p3.3.m3.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.3.m3.1b"><ci id="S3.SS2.p3.3.m3.1.1.cmml" xref="S3.SS2.p3.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.3.m3.1c">c</annotation></semantics></math>)-output (<math id="S3.SS2.p3.4.m4.1" class="ltx_Math" alttext="a" display="inline"><semantics id="S3.SS2.p3.4.m4.1a"><mi id="S3.SS2.p3.4.m4.1.1" xref="S3.SS2.p3.4.m4.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.4.m4.1b"><ci id="S3.SS2.p3.4.m4.1.1.cmml" xref="S3.SS2.p3.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.4.m4.1c">a</annotation></semantics></math>) pair from training data, we first prompt <math id="S3.SS2.p3.5.m5.1" class="ltx_Math" alttext="M^{*}" display="inline"><semantics id="S3.SS2.p3.5.m5.1a"><msup id="S3.SS2.p3.5.m5.1.1" xref="S3.SS2.p3.5.m5.1.1.cmml"><mi id="S3.SS2.p3.5.m5.1.1.2" xref="S3.SS2.p3.5.m5.1.1.2.cmml">M</mi><mo id="S3.SS2.p3.5.m5.1.1.3" xref="S3.SS2.p3.5.m5.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.5.m5.1b"><apply id="S3.SS2.p3.5.m5.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.5.m5.1.1.1.cmml" xref="S3.SS2.p3.5.m5.1.1">superscript</csymbol><ci id="S3.SS2.p3.5.m5.1.1.2.cmml" xref="S3.SS2.p3.5.m5.1.1.2">ğ‘€</ci><times id="S3.SS2.p3.5.m5.1.1.3.cmml" xref="S3.SS2.p3.5.m5.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.5.m5.1c">M^{*}</annotation></semantics></math> to generate a corresponding rationale <math id="S3.SS2.p3.6.m6.1" class="ltx_Math" alttext="r^{*}" display="inline"><semantics id="S3.SS2.p3.6.m6.1a"><msup id="S3.SS2.p3.6.m6.1.1" xref="S3.SS2.p3.6.m6.1.1.cmml"><mi id="S3.SS2.p3.6.m6.1.1.2" xref="S3.SS2.p3.6.m6.1.1.2.cmml">r</mi><mo id="S3.SS2.p3.6.m6.1.1.3" xref="S3.SS2.p3.6.m6.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.6.m6.1b"><apply id="S3.SS2.p3.6.m6.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.6.m6.1.1.1.cmml" xref="S3.SS2.p3.6.m6.1.1">superscript</csymbol><ci id="S3.SS2.p3.6.m6.1.1.2.cmml" xref="S3.SS2.p3.6.m6.1.1.2">ğ‘Ÿ</ci><times id="S3.SS2.p3.6.m6.1.1.3.cmml" xref="S3.SS2.p3.6.m6.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.6.m6.1c">r^{*}</annotation></semantics></math>. During the generation process, an aspect-specific reward (denoted as <math id="S3.SS2.p3.7.m7.1" class="ltx_Math" alttext="R_{aspect}" display="inline"><semantics id="S3.SS2.p3.7.m7.1a"><msub id="S3.SS2.p3.7.m7.1.1" xref="S3.SS2.p3.7.m7.1.1.cmml"><mi id="S3.SS2.p3.7.m7.1.1.2" xref="S3.SS2.p3.7.m7.1.1.2.cmml">R</mi><mrow id="S3.SS2.p3.7.m7.1.1.3" xref="S3.SS2.p3.7.m7.1.1.3.cmml"><mi id="S3.SS2.p3.7.m7.1.1.3.2" xref="S3.SS2.p3.7.m7.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m7.1.1.3.1" xref="S3.SS2.p3.7.m7.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.7.m7.1.1.3.3" xref="S3.SS2.p3.7.m7.1.1.3.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m7.1.1.3.1a" xref="S3.SS2.p3.7.m7.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.7.m7.1.1.3.4" xref="S3.SS2.p3.7.m7.1.1.3.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m7.1.1.3.1b" xref="S3.SS2.p3.7.m7.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.7.m7.1.1.3.5" xref="S3.SS2.p3.7.m7.1.1.3.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m7.1.1.3.1c" xref="S3.SS2.p3.7.m7.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.7.m7.1.1.3.6" xref="S3.SS2.p3.7.m7.1.1.3.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.7.m7.1.1.3.1d" xref="S3.SS2.p3.7.m7.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.7.m7.1.1.3.7" xref="S3.SS2.p3.7.m7.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.7.m7.1b"><apply id="S3.SS2.p3.7.m7.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.7.m7.1.1.1.cmml" xref="S3.SS2.p3.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.p3.7.m7.1.1.2.cmml" xref="S3.SS2.p3.7.m7.1.1.2">ğ‘…</ci><apply id="S3.SS2.p3.7.m7.1.1.3.cmml" xref="S3.SS2.p3.7.m7.1.1.3"><times id="S3.SS2.p3.7.m7.1.1.3.1.cmml" xref="S3.SS2.p3.7.m7.1.1.3.1"></times><ci id="S3.SS2.p3.7.m7.1.1.3.2.cmml" xref="S3.SS2.p3.7.m7.1.1.3.2">ğ‘</ci><ci id="S3.SS2.p3.7.m7.1.1.3.3.cmml" xref="S3.SS2.p3.7.m7.1.1.3.3">ğ‘ </ci><ci id="S3.SS2.p3.7.m7.1.1.3.4.cmml" xref="S3.SS2.p3.7.m7.1.1.3.4">ğ‘</ci><ci id="S3.SS2.p3.7.m7.1.1.3.5.cmml" xref="S3.SS2.p3.7.m7.1.1.3.5">ğ‘’</ci><ci id="S3.SS2.p3.7.m7.1.1.3.6.cmml" xref="S3.SS2.p3.7.m7.1.1.3.6">ğ‘</ci><ci id="S3.SS2.p3.7.m7.1.1.3.7.cmml" xref="S3.SS2.p3.7.m7.1.1.3.7">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.7.m7.1c">R_{aspect}</annotation></semantics></math>) is measured by aggregating all values returned from automatic evaluation metrics.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>We also test with normalization or weighted summation for the scores, but they did not affect the performance. </span></span></span>
We then pass <math id="S3.SS2.p3.8.m8.1" class="ltx_Math" alttext="r^{*}" display="inline"><semantics id="S3.SS2.p3.8.m8.1a"><msup id="S3.SS2.p3.8.m8.1.1" xref="S3.SS2.p3.8.m8.1.1.cmml"><mi id="S3.SS2.p3.8.m8.1.1.2" xref="S3.SS2.p3.8.m8.1.1.2.cmml">r</mi><mo id="S3.SS2.p3.8.m8.1.1.3" xref="S3.SS2.p3.8.m8.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.8.m8.1b"><apply id="S3.SS2.p3.8.m8.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.8.m8.1.1.1.cmml" xref="S3.SS2.p3.8.m8.1.1">superscript</csymbol><ci id="S3.SS2.p3.8.m8.1.1.2.cmml" xref="S3.SS2.p3.8.m8.1.1.2">ğ‘Ÿ</ci><times id="S3.SS2.p3.8.m8.1.1.3.cmml" xref="S3.SS2.p3.8.m8.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.8.m8.1c">r^{*}</annotation></semantics></math> to <math id="S3.SS2.p3.9.m9.1" class="ltx_Math" alttext="M^{L}" display="inline"><semantics id="S3.SS2.p3.9.m9.1a"><msup id="S3.SS2.p3.9.m9.1.1" xref="S3.SS2.p3.9.m9.1.1.cmml"><mi id="S3.SS2.p3.9.m9.1.1.2" xref="S3.SS2.p3.9.m9.1.1.2.cmml">M</mi><mi id="S3.SS2.p3.9.m9.1.1.3" xref="S3.SS2.p3.9.m9.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.9.m9.1b"><apply id="S3.SS2.p3.9.m9.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.9.m9.1.1.1.cmml" xref="S3.SS2.p3.9.m9.1.1">superscript</csymbol><ci id="S3.SS2.p3.9.m9.1.1.2.cmml" xref="S3.SS2.p3.9.m9.1.1.2">ğ‘€</ci><ci id="S3.SS2.p3.9.m9.1.1.3.cmml" xref="S3.SS2.p3.9.m9.1.1.3">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.9.m9.1c">M^{L}</annotation></semantics></math> to retrieve the answer prediction <math id="S3.SS2.p3.10.m10.1" class="ltx_Math" alttext="a^{*}" display="inline"><semantics id="S3.SS2.p3.10.m10.1a"><msup id="S3.SS2.p3.10.m10.1.1" xref="S3.SS2.p3.10.m10.1.1.cmml"><mi id="S3.SS2.p3.10.m10.1.1.2" xref="S3.SS2.p3.10.m10.1.1.2.cmml">a</mi><mo id="S3.SS2.p3.10.m10.1.1.3" xref="S3.SS2.p3.10.m10.1.1.3.cmml">âˆ—</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.10.m10.1b"><apply id="S3.SS2.p3.10.m10.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.10.m10.1.1.1.cmml" xref="S3.SS2.p3.10.m10.1.1">superscript</csymbol><ci id="S3.SS2.p3.10.m10.1.1.2.cmml" xref="S3.SS2.p3.10.m10.1.1.2">ğ‘</ci><times id="S3.SS2.p3.10.m10.1.1.3.cmml" xref="S3.SS2.p3.10.m10.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.10.m10.1c">a^{*}</annotation></semantics></math> and compute a task-specific reward (denoted as <math id="S3.SS2.p3.11.m11.1" class="ltx_Math" alttext="R_{taskAcc}" display="inline"><semantics id="S3.SS2.p3.11.m11.1a"><msub id="S3.SS2.p3.11.m11.1.1" xref="S3.SS2.p3.11.m11.1.1.cmml"><mi id="S3.SS2.p3.11.m11.1.1.2" xref="S3.SS2.p3.11.m11.1.1.2.cmml">R</mi><mrow id="S3.SS2.p3.11.m11.1.1.3" xref="S3.SS2.p3.11.m11.1.1.3.cmml"><mi id="S3.SS2.p3.11.m11.1.1.3.2" xref="S3.SS2.p3.11.m11.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.11.m11.1.1.3.1" xref="S3.SS2.p3.11.m11.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.11.m11.1.1.3.3" xref="S3.SS2.p3.11.m11.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.11.m11.1.1.3.1a" xref="S3.SS2.p3.11.m11.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.11.m11.1.1.3.4" xref="S3.SS2.p3.11.m11.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.11.m11.1.1.3.1b" xref="S3.SS2.p3.11.m11.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.11.m11.1.1.3.5" xref="S3.SS2.p3.11.m11.1.1.3.5.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.11.m11.1.1.3.1c" xref="S3.SS2.p3.11.m11.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.11.m11.1.1.3.6" xref="S3.SS2.p3.11.m11.1.1.3.6.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.11.m11.1.1.3.1d" xref="S3.SS2.p3.11.m11.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.11.m11.1.1.3.7" xref="S3.SS2.p3.11.m11.1.1.3.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.11.m11.1.1.3.1e" xref="S3.SS2.p3.11.m11.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.11.m11.1.1.3.8" xref="S3.SS2.p3.11.m11.1.1.3.8.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.11.m11.1b"><apply id="S3.SS2.p3.11.m11.1.1.cmml" xref="S3.SS2.p3.11.m11.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.11.m11.1.1.1.cmml" xref="S3.SS2.p3.11.m11.1.1">subscript</csymbol><ci id="S3.SS2.p3.11.m11.1.1.2.cmml" xref="S3.SS2.p3.11.m11.1.1.2">ğ‘…</ci><apply id="S3.SS2.p3.11.m11.1.1.3.cmml" xref="S3.SS2.p3.11.m11.1.1.3"><times id="S3.SS2.p3.11.m11.1.1.3.1.cmml" xref="S3.SS2.p3.11.m11.1.1.3.1"></times><ci id="S3.SS2.p3.11.m11.1.1.3.2.cmml" xref="S3.SS2.p3.11.m11.1.1.3.2">ğ‘¡</ci><ci id="S3.SS2.p3.11.m11.1.1.3.3.cmml" xref="S3.SS2.p3.11.m11.1.1.3.3">ğ‘</ci><ci id="S3.SS2.p3.11.m11.1.1.3.4.cmml" xref="S3.SS2.p3.11.m11.1.1.3.4">ğ‘ </ci><ci id="S3.SS2.p3.11.m11.1.1.3.5.cmml" xref="S3.SS2.p3.11.m11.1.1.3.5">ğ‘˜</ci><ci id="S3.SS2.p3.11.m11.1.1.3.6.cmml" xref="S3.SS2.p3.11.m11.1.1.3.6">ğ´</ci><ci id="S3.SS2.p3.11.m11.1.1.3.7.cmml" xref="S3.SS2.p3.11.m11.1.1.3.7">ğ‘</ci><ci id="S3.SS2.p3.11.m11.1.1.3.8.cmml" xref="S3.SS2.p3.11.m11.1.1.3.8">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.11.m11.1c">R_{taskAcc}</annotation></semantics></math>). Specifically, we leverage the F1 score between the predicted answer and the ground truth answer:</p>
<table id="S11.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S3.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.Ex1.m1.4" class="ltx_Math" alttext="\displaystyle R_{\text{taskAcc}}=\begin{cases}1&amp;\text{if }F1(a,a^{*})>0.5,\\
0&amp;\text{else}.\end{cases}" display="inline"><semantics id="S3.Ex1.m1.4a"><mrow id="S3.Ex1.m1.4.5" xref="S3.Ex1.m1.4.5.cmml"><msub id="S3.Ex1.m1.4.5.2" xref="S3.Ex1.m1.4.5.2.cmml"><mi id="S3.Ex1.m1.4.5.2.2" xref="S3.Ex1.m1.4.5.2.2.cmml">R</mi><mtext id="S3.Ex1.m1.4.5.2.3" xref="S3.Ex1.m1.4.5.2.3a.cmml">taskAcc</mtext></msub><mo id="S3.Ex1.m1.4.5.1" xref="S3.Ex1.m1.4.5.1.cmml">=</mo><mrow id="S3.Ex1.m1.4.4a" xref="S3.Ex1.m1.4.5.3.1.cmml"><mo id="S3.Ex1.m1.4.4a.5" xref="S3.Ex1.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" rowspacing="0pt" id="S3.Ex1.m1.4.4.4a" xref="S3.Ex1.m1.4.5.3.1.cmml"><mtr id="S3.Ex1.m1.4.4.4aa" xref="S3.Ex1.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.4.4.4ab" xref="S3.Ex1.m1.4.5.3.1.cmml"><mn id="S3.Ex1.m1.1.1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.1.1.cmml">1</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.4.4.4ac" xref="S3.Ex1.m1.4.5.3.1.cmml"><mrow id="S3.Ex1.m1.2.2.2.2.2.1.2" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.cmml"><mrow id="S3.Ex1.m1.2.2.2.2.2.1.2.1" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.cmml"><mrow id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.cmml"><mtext id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.3" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.3a.cmml">if&nbsp;</mtext><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2.cmml">â€‹</mo><mi id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.4" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2a" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2.cmml">â€‹</mo><mn id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.5" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.5.cmml">1</mn><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2b" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2.cmml">â€‹</mo><mrow id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.2.cmml"><mo stretchy="false" id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.2" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.2.cmml">(</mo><mi id="S3.Ex1.m1.2.2.2.2.2.1.1" xref="S3.Ex1.m1.2.2.2.2.2.1.1.cmml">a</mi><mo id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.3" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.2.cmml">,</mo><msup id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.cmml"><mi id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.2" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.2.cmml">a</mi><mo id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.3" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.3.cmml">âˆ—</mo></msup><mo stretchy="false" id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.4" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.2.2.2.2.2.1.2.1.2" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.2.cmml">&gt;</mo><mn id="S3.Ex1.m1.2.2.2.2.2.1.2.1.3" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.3.cmml">0.5</mn></mrow><mo id="S3.Ex1.m1.2.2.2.2.2.1.2.2" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.cmml">,</mo></mrow></mtd></mtr><mtr id="S3.Ex1.m1.4.4.4ad" xref="S3.Ex1.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.4.4.4ae" xref="S3.Ex1.m1.4.5.3.1.cmml"><mn id="S3.Ex1.m1.3.3.3.3.1.1" xref="S3.Ex1.m1.3.3.3.3.1.1.cmml">0</mn></mtd><mtd class="ltx_align_left" columnalign="left" id="S3.Ex1.m1.4.4.4af" xref="S3.Ex1.m1.4.5.3.1.cmml"><mrow id="S3.Ex1.m1.4.4.4.4.2.1.3" xref="S3.Ex1.m1.4.4.4.4.2.1.1a.cmml"><mtext id="S3.Ex1.m1.4.4.4.4.2.1.1" xref="S3.Ex1.m1.4.4.4.4.2.1.1.cmml">else</mtext><mo lspace="0em" id="S3.Ex1.m1.4.4.4.4.2.1.3.1" xref="S3.Ex1.m1.4.4.4.4.2.1.1a.cmml">.</mo></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.4b"><apply id="S3.Ex1.m1.4.5.cmml" xref="S3.Ex1.m1.4.5"><eq id="S3.Ex1.m1.4.5.1.cmml" xref="S3.Ex1.m1.4.5.1"></eq><apply id="S3.Ex1.m1.4.5.2.cmml" xref="S3.Ex1.m1.4.5.2"><csymbol cd="ambiguous" id="S3.Ex1.m1.4.5.2.1.cmml" xref="S3.Ex1.m1.4.5.2">subscript</csymbol><ci id="S3.Ex1.m1.4.5.2.2.cmml" xref="S3.Ex1.m1.4.5.2.2">ğ‘…</ci><ci id="S3.Ex1.m1.4.5.2.3a.cmml" xref="S3.Ex1.m1.4.5.2.3"><mtext mathsize="70%" id="S3.Ex1.m1.4.5.2.3.cmml" xref="S3.Ex1.m1.4.5.2.3">taskAcc</mtext></ci></apply><apply id="S3.Ex1.m1.4.5.3.1.cmml" xref="S3.Ex1.m1.4.4a"><csymbol cd="latexml" id="S3.Ex1.m1.4.5.3.1.1.cmml" xref="S3.Ex1.m1.4.4a.5">cases</csymbol><cn type="integer" id="S3.Ex1.m1.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1.1.1">1</cn><apply id="S3.Ex1.m1.2.2.2.2.2.1.2.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2"><gt id="S3.Ex1.m1.2.2.2.2.2.1.2.1.2.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.2"></gt><apply id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1"><times id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.2"></times><ci id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.3a.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.3"><mtext id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.3.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.3">if&nbsp;</mtext></ci><ci id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.4.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.4">ğ¹</ci><cn type="integer" id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.5.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.5">1</cn><interval closure="open" id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1"><ci id="S3.Ex1.m1.2.2.2.2.2.1.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.1">ğ‘</ci><apply id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.1.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1">superscript</csymbol><ci id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.2.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.2">ğ‘</ci><times id="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.3.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.1.1.1.1.3"></times></apply></interval></apply><cn type="float" id="S3.Ex1.m1.2.2.2.2.2.1.2.1.3.cmml" xref="S3.Ex1.m1.2.2.2.2.2.1.2.1.3">0.5</cn></apply><cn type="integer" id="S3.Ex1.m1.3.3.3.3.1.1.cmml" xref="S3.Ex1.m1.3.3.3.3.1.1">0</cn><ci id="S3.Ex1.m1.4.4.4.4.2.1.1a.cmml" xref="S3.Ex1.m1.4.4.4.4.2.1.3"><mtext id="S3.Ex1.m1.4.4.4.4.2.1.1.cmml" xref="S3.Ex1.m1.4.4.4.4.2.1.1">else</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.4c">\displaystyle R_{\text{taskAcc}}=\begin{cases}1&amp;\text{if }F1(a,a^{*})&gt;0.5,\\
0&amp;\text{else}.\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S3.SS2.p3.14" class="ltx_p">A final reward score for model training is the summation of <math id="S3.SS2.p3.12.m1.1" class="ltx_Math" alttext="R_{aspect}" display="inline"><semantics id="S3.SS2.p3.12.m1.1a"><msub id="S3.SS2.p3.12.m1.1.1" xref="S3.SS2.p3.12.m1.1.1.cmml"><mi id="S3.SS2.p3.12.m1.1.1.2" xref="S3.SS2.p3.12.m1.1.1.2.cmml">R</mi><mrow id="S3.SS2.p3.12.m1.1.1.3" xref="S3.SS2.p3.12.m1.1.1.3.cmml"><mi id="S3.SS2.p3.12.m1.1.1.3.2" xref="S3.SS2.p3.12.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.12.m1.1.1.3.1" xref="S3.SS2.p3.12.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.12.m1.1.1.3.3" xref="S3.SS2.p3.12.m1.1.1.3.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.12.m1.1.1.3.1a" xref="S3.SS2.p3.12.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.12.m1.1.1.3.4" xref="S3.SS2.p3.12.m1.1.1.3.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.12.m1.1.1.3.1b" xref="S3.SS2.p3.12.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.12.m1.1.1.3.5" xref="S3.SS2.p3.12.m1.1.1.3.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.12.m1.1.1.3.1c" xref="S3.SS2.p3.12.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.12.m1.1.1.3.6" xref="S3.SS2.p3.12.m1.1.1.3.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.12.m1.1.1.3.1d" xref="S3.SS2.p3.12.m1.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.12.m1.1.1.3.7" xref="S3.SS2.p3.12.m1.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.12.m1.1b"><apply id="S3.SS2.p3.12.m1.1.1.cmml" xref="S3.SS2.p3.12.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.12.m1.1.1.1.cmml" xref="S3.SS2.p3.12.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.12.m1.1.1.2.cmml" xref="S3.SS2.p3.12.m1.1.1.2">ğ‘…</ci><apply id="S3.SS2.p3.12.m1.1.1.3.cmml" xref="S3.SS2.p3.12.m1.1.1.3"><times id="S3.SS2.p3.12.m1.1.1.3.1.cmml" xref="S3.SS2.p3.12.m1.1.1.3.1"></times><ci id="S3.SS2.p3.12.m1.1.1.3.2.cmml" xref="S3.SS2.p3.12.m1.1.1.3.2">ğ‘</ci><ci id="S3.SS2.p3.12.m1.1.1.3.3.cmml" xref="S3.SS2.p3.12.m1.1.1.3.3">ğ‘ </ci><ci id="S3.SS2.p3.12.m1.1.1.3.4.cmml" xref="S3.SS2.p3.12.m1.1.1.3.4">ğ‘</ci><ci id="S3.SS2.p3.12.m1.1.1.3.5.cmml" xref="S3.SS2.p3.12.m1.1.1.3.5">ğ‘’</ci><ci id="S3.SS2.p3.12.m1.1.1.3.6.cmml" xref="S3.SS2.p3.12.m1.1.1.3.6">ğ‘</ci><ci id="S3.SS2.p3.12.m1.1.1.3.7.cmml" xref="S3.SS2.p3.12.m1.1.1.3.7">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.12.m1.1c">R_{aspect}</annotation></semantics></math> and <math id="S3.SS2.p3.13.m2.1" class="ltx_Math" alttext="R_{taskAcc}" display="inline"><semantics id="S3.SS2.p3.13.m2.1a"><msub id="S3.SS2.p3.13.m2.1.1" xref="S3.SS2.p3.13.m2.1.1.cmml"><mi id="S3.SS2.p3.13.m2.1.1.2" xref="S3.SS2.p3.13.m2.1.1.2.cmml">R</mi><mrow id="S3.SS2.p3.13.m2.1.1.3" xref="S3.SS2.p3.13.m2.1.1.3.cmml"><mi id="S3.SS2.p3.13.m2.1.1.3.2" xref="S3.SS2.p3.13.m2.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.13.m2.1.1.3.1" xref="S3.SS2.p3.13.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.13.m2.1.1.3.3" xref="S3.SS2.p3.13.m2.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.13.m2.1.1.3.1a" xref="S3.SS2.p3.13.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.13.m2.1.1.3.4" xref="S3.SS2.p3.13.m2.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.13.m2.1.1.3.1b" xref="S3.SS2.p3.13.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.13.m2.1.1.3.5" xref="S3.SS2.p3.13.m2.1.1.3.5.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.13.m2.1.1.3.1c" xref="S3.SS2.p3.13.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.13.m2.1.1.3.6" xref="S3.SS2.p3.13.m2.1.1.3.6.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.13.m2.1.1.3.1d" xref="S3.SS2.p3.13.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.13.m2.1.1.3.7" xref="S3.SS2.p3.13.m2.1.1.3.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS2.p3.13.m2.1.1.3.1e" xref="S3.SS2.p3.13.m2.1.1.3.1.cmml">â€‹</mo><mi id="S3.SS2.p3.13.m2.1.1.3.8" xref="S3.SS2.p3.13.m2.1.1.3.8.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.13.m2.1b"><apply id="S3.SS2.p3.13.m2.1.1.cmml" xref="S3.SS2.p3.13.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.13.m2.1.1.1.cmml" xref="S3.SS2.p3.13.m2.1.1">subscript</csymbol><ci id="S3.SS2.p3.13.m2.1.1.2.cmml" xref="S3.SS2.p3.13.m2.1.1.2">ğ‘…</ci><apply id="S3.SS2.p3.13.m2.1.1.3.cmml" xref="S3.SS2.p3.13.m2.1.1.3"><times id="S3.SS2.p3.13.m2.1.1.3.1.cmml" xref="S3.SS2.p3.13.m2.1.1.3.1"></times><ci id="S3.SS2.p3.13.m2.1.1.3.2.cmml" xref="S3.SS2.p3.13.m2.1.1.3.2">ğ‘¡</ci><ci id="S3.SS2.p3.13.m2.1.1.3.3.cmml" xref="S3.SS2.p3.13.m2.1.1.3.3">ğ‘</ci><ci id="S3.SS2.p3.13.m2.1.1.3.4.cmml" xref="S3.SS2.p3.13.m2.1.1.3.4">ğ‘ </ci><ci id="S3.SS2.p3.13.m2.1.1.3.5.cmml" xref="S3.SS2.p3.13.m2.1.1.3.5">ğ‘˜</ci><ci id="S3.SS2.p3.13.m2.1.1.3.6.cmml" xref="S3.SS2.p3.13.m2.1.1.3.6">ğ´</ci><ci id="S3.SS2.p3.13.m2.1.1.3.7.cmml" xref="S3.SS2.p3.13.m2.1.1.3.7">ğ‘</ci><ci id="S3.SS2.p3.13.m2.1.1.3.8.cmml" xref="S3.SS2.p3.13.m2.1.1.3.8">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.13.m2.1c">R_{taskAcc}</annotation></semantics></math>. Following <cite class="ltx_cite ltx_citemacro_citet">Stiennon et&nbsp;al. (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>, we also incorporate penalties based on the Kullback Leibler (KL) divergence between the learned policy LM and <math id="S3.SS2.p3.14.m3.1" class="ltx_Math" alttext="M^{S}" display="inline"><semantics id="S3.SS2.p3.14.m3.1a"><msup id="S3.SS2.p3.14.m3.1.1" xref="S3.SS2.p3.14.m3.1.1.cmml"><mi id="S3.SS2.p3.14.m3.1.1.2" xref="S3.SS2.p3.14.m3.1.1.2.cmml">M</mi><mi id="S3.SS2.p3.14.m3.1.1.3" xref="S3.SS2.p3.14.m3.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.14.m3.1b"><apply id="S3.SS2.p3.14.m3.1.1.cmml" xref="S3.SS2.p3.14.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.14.m3.1.1.1.cmml" xref="S3.SS2.p3.14.m3.1.1">superscript</csymbol><ci id="S3.SS2.p3.14.m3.1.1.2.cmml" xref="S3.SS2.p3.14.m3.1.1.2">ğ‘€</ci><ci id="S3.SS2.p3.14.m3.1.1.3.cmml" xref="S3.SS2.p3.14.m3.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.14.m3.1c">M^{S}</annotation></semantics></math>.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T2.4.5" class="ltx_tr">
<td id="S3.T2.4.5.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S3.T2.4.5.1.1" class="ltx_text" style="font-size:90%;">Prompt</span></td>
<td id="S3.T2.4.5.2" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S3.T2.4.5.2.1" class="ltx_text" style="font-size:90%;"><span id="S3.T2.4.5.2.1.1" class="ltx_text"></span> <span id="S3.T2.4.5.2.1.2" class="ltx_text">
<span id="S3.T2.4.5.2.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.4.5.2.1.2.1.1" class="ltx_tr">
<span id="S3.T2.4.5.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Rationale</span></span>
<span id="S3.T2.4.5.2.1.2.1.2" class="ltx_tr">
<span id="S3.T2.4.5.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Provision?</span></span>
</span></span> <span id="S3.T2.4.5.2.1.3" class="ltx_text"></span></span></td>
<td id="S3.T2.4.5.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S3.T2.4.5.3.1" class="ltx_text" style="font-size:90%;">HotpotQA</span></td>
<td id="S3.T2.4.5.4" class="ltx_td ltx_border_tt"></td>
<td id="S3.T2.4.5.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="3"><span id="S3.T2.4.5.5.1" class="ltx_text" style="font-size:90%;">2WikiMultiHopQA</span></td>
</tr>
<tr id="S3.T2.4.6" class="ltx_tr">
<td id="S3.T2.4.6.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.6.1.1" class="ltx_text" style="font-size:90%;">EM</span></td>
<td id="S3.T2.4.6.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.6.2.1" class="ltx_text" style="font-size:90%;">F1</span></td>
<td id="S3.T2.4.6.3" class="ltx_td ltx_align_center ltx_border_t">
<table id="S3.T2.4.6.3.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T2.4.6.3.1.1" class="ltx_tr">
<td id="S3.T2.4.6.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.4.6.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Answer</span></td>
</tr>
<tr id="S3.T2.4.6.3.1.2" class="ltx_tr">
<td id="S3.T2.4.6.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.4.6.3.1.2.1.1" class="ltx_text" style="font-size:90%;">Inclusion</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T2.4.6.4" class="ltx_td"></td>
<td id="S3.T2.4.6.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.6.5.1" class="ltx_text" style="font-size:90%;">EM</span></td>
<td id="S3.T2.4.6.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.6.6.1" class="ltx_text" style="font-size:90%;">F1</span></td>
<td id="S3.T2.4.6.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">
<table id="S3.T2.4.6.7.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T2.4.6.7.1.1" class="ltx_tr">
<td id="S3.T2.4.6.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.4.6.7.1.1.1.1" class="ltx_text" style="font-size:90%;">Answer</span></td>
</tr>
<tr id="S3.T2.4.6.7.1.2" class="ltx_tr">
<td id="S3.T2.4.6.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.4.6.7.1.2.1.1" class="ltx_text" style="font-size:90%;">Inclusion</span></td>
</tr>
</tbody></table>
</td>
</tr>
<tr id="S3.T2.4.7" class="ltx_tr">
<td id="S3.T2.4.7.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.7.1.1" class="ltx_text" style="font-size:90%;">standard prompting</span></td>
<td id="S3.T2.4.7.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.7.2.1" class="ltx_text" style="font-size:90%;color:#FF0000;">âœ—</span></td>
<td id="S3.T2.4.7.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.7.3.1" class="ltx_text" style="font-size:90%;">0.5</span></td>
<td id="S3.T2.4.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.7.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.714</span></td>
<td id="S3.T2.4.7.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.7.5.1" class="ltx_text" style="font-size:90%;">0.583</span></td>
<td id="S3.T2.4.7.6" class="ltx_td ltx_border_t"></td>
<td id="S3.T2.4.7.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.7.7.1" class="ltx_text" style="font-size:90%;">0.5</span></td>
<td id="S3.T2.4.7.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.7.8.1" class="ltx_text" style="font-size:90%;">0.625</span></td>
<td id="S3.T2.4.7.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S3.T2.4.7.9.1" class="ltx_text" style="font-size:90%;">0.647</span></td>
</tr>
<tr id="S3.T2.4.8" class="ltx_tr">
<td id="S3.T2.4.8.1" class="ltx_td ltx_align_center"><span id="S3.T2.4.8.1.1" class="ltx_text" style="font-size:90%;">CoT prompting</span></td>
<td id="S3.T2.4.8.2" class="ltx_td ltx_align_center"><span id="S3.T2.4.8.2.1" class="ltx_text" style="font-size:90%;color:#008000;">âœ“</span></td>
<td id="S3.T2.4.8.3" class="ltx_td ltx_align_center"><span id="S3.T2.4.8.3.1" class="ltx_text" style="font-size:90%;">0.483</span></td>
<td id="S3.T2.4.8.4" class="ltx_td ltx_align_center"><span id="S3.T2.4.8.4.1" class="ltx_text" style="font-size:90%;">0.686</span></td>
<td id="S3.T2.4.8.5" class="ltx_td ltx_align_center"><span id="S3.T2.4.8.5.1" class="ltx_text" style="font-size:90%;">0.611</span></td>
<td id="S3.T2.4.8.6" class="ltx_td"></td>
<td id="S3.T2.4.8.7" class="ltx_td ltx_align_center"><span id="S3.T2.4.8.7.1" class="ltx_text" style="font-size:90%;">0.4</span></td>
<td id="S3.T2.4.8.8" class="ltx_td ltx_align_center"><span id="S3.T2.4.8.8.1" class="ltx_text" style="font-size:90%;">0.532</span></td>
<td id="S3.T2.4.8.9" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.4.8.9.1" class="ltx_text" style="font-size:90%;">0.561</span></td>
</tr>
<tr id="S3.T2.4.9" class="ltx_tr">
<td id="S3.T2.4.9.1" class="ltx_td ltx_align_center"><span id="S3.T2.4.9.1.1" class="ltx_text" style="font-size:90%;">CoT prompting + SC</span></td>
<td id="S3.T2.4.9.2" class="ltx_td ltx_align_center"><span id="S3.T2.4.9.2.1" class="ltx_text" style="font-size:90%;color:#FF0000;">âœ—</span></td>
<td id="S3.T2.4.9.3" class="ltx_td ltx_align_center"><span id="S3.T2.4.9.3.1" class="ltx_text" style="font-size:90%;">0.503</span></td>
<td id="S3.T2.4.9.4" class="ltx_td ltx_align_center"><span id="S3.T2.4.9.4.1" class="ltx_text" style="font-size:90%;">0.70</span></td>
<td id="S3.T2.4.9.5" class="ltx_td ltx_align_center"><span id="S3.T2.4.9.5.1" class="ltx_text" style="font-size:90%;">0.624</span></td>
<td id="S3.T2.4.9.6" class="ltx_td"></td>
<td id="S3.T2.4.9.7" class="ltx_td ltx_align_center"><span id="S3.T2.4.9.7.1" class="ltx_text" style="font-size:90%;">0.471</span></td>
<td id="S3.T2.4.9.8" class="ltx_td ltx_align_center"><span id="S3.T2.4.9.8.1" class="ltx_text" style="font-size:90%;">0.603</span></td>
<td id="S3.T2.4.9.9" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.4.9.9.1" class="ltx_text" style="font-size:90%;">0.625</span></td>
</tr>
<tr id="S3.T2.4.10" class="ltx_tr">
<td id="S3.T2.4.10.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.10.1.1" class="ltx_text" style="font-size:90%;">LM-guided CoT prompting (KD)</span></td>
<td id="S3.T2.4.10.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.10.2.1" class="ltx_text" style="font-size:90%;color:#008000;">âœ“</span></td>
<td id="S3.T2.4.10.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.10.3.1" class="ltx_text" style="font-size:90%;">0.507</span></td>
<td id="S3.T2.4.10.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.10.4.1" class="ltx_text" style="font-size:90%;">0.702</span></td>
<td id="S3.T2.4.10.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.10.5.1" class="ltx_text" style="font-size:90%;">0.625</span></td>
<td id="S3.T2.4.10.6" class="ltx_td ltx_border_t"></td>
<td id="S3.T2.4.10.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.10.7.1" class="ltx_text" style="font-size:90%;">0.506</span></td>
<td id="S3.T2.4.10.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T2.4.10.8.1" class="ltx_text" style="font-size:90%;">0.626</span></td>
<td id="S3.T2.4.10.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S3.T2.4.10.9.1" class="ltx_text" style="font-size:90%;">0.661</span></td>
</tr>
<tr id="S3.T2.4.11" class="ltx_tr">
<td id="S3.T2.4.11.1" class="ltx_td ltx_align_center"><span id="S3.T2.4.11.1.1" class="ltx_text" style="font-size:90%;">LM-guided CoT prompting (KD + SC)</span></td>
<td id="S3.T2.4.11.2" class="ltx_td ltx_align_center"><span id="S3.T2.4.11.2.1" class="ltx_text" style="font-size:90%;color:#FF0000;">âœ—</span></td>
<td id="S3.T2.4.11.3" class="ltx_td ltx_align_center"><span id="S3.T2.4.11.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.513</span></td>
<td id="S3.T2.4.11.4" class="ltx_td ltx_align_center"><span id="S3.T2.4.11.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.714</span></td>
<td id="S3.T2.4.11.5" class="ltx_td ltx_align_center"><span id="S3.T2.4.11.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.635</span></td>
<td id="S3.T2.4.11.6" class="ltx_td"></td>
<td id="S3.T2.4.11.7" class="ltx_td ltx_align_center"><span id="S3.T2.4.11.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.524</span></td>
<td id="S3.T2.4.11.8" class="ltx_td ltx_align_center"><span id="S3.T2.4.11.8.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.644</span></td>
<td id="S3.T2.4.11.9" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.4.11.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.679</span></td>
</tr>
<tr id="S3.T2.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1" class="ltx_td ltx_align_center">
<table id="S3.T2.1.1.1.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T2.1.1.1.1.2" class="ltx_tr">
<td id="S3.T2.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.1.1.1.1.2.1.1" class="ltx_text" style="font-size:90%;">LM-guided CoT prompting</span></td>
</tr>
<tr id="S3.T2.1.1.1.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">
<span id="S3.T2.1.1.1.1.1.1.1" class="ltx_text" style="font-size:90%;">(KD + </span><math id="S3.T2.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="R_{aspect}" display="inline"><semantics id="S3.T2.1.1.1.1.1.1.m1.1a"><msub id="S3.T2.1.1.1.1.1.1.m1.1.1" xref="S3.T2.1.1.1.1.1.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.T2.1.1.1.1.1.1.m1.1.1.2" xref="S3.T2.1.1.1.1.1.1.m1.1.1.2.cmml">R</mi><mrow id="S3.T2.1.1.1.1.1.1.m1.1.1.3" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.cmml"><mi mathsize="90%" id="S3.T2.1.1.1.1.1.1.m1.1.1.3.2" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.T2.1.1.1.1.1.1.m1.1.1.3.1" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.1.1.1.1.1.1.m1.1.1.3.3" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.T2.1.1.1.1.1.1.m1.1.1.3.1a" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.1.1.1.1.1.1.m1.1.1.3.4" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.T2.1.1.1.1.1.1.m1.1.1.3.1b" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.1.1.1.1.1.1.m1.1.1.3.5" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.T2.1.1.1.1.1.1.m1.1.1.3.1c" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.1.1.1.1.1.1.m1.1.1.3.6" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.T2.1.1.1.1.1.1.m1.1.1.3.1d" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.1.1.1.1.1.1.m1.1.1.3.7" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T2.1.1.1.1.1.1.m1.1b"><apply id="S3.T2.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.2">ğ‘…</ci><apply id="S3.T2.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3"><times id="S3.T2.1.1.1.1.1.1.m1.1.1.3.1.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.1"></times><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.3.2.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.2">ğ‘</ci><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.3.3.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.3">ğ‘ </ci><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.3.4.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.4">ğ‘</ci><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.3.5.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.5">ğ‘’</ci><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.3.6.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.6">ğ‘</ci><ci id="S3.T2.1.1.1.1.1.1.m1.1.1.3.7.cmml" xref="S3.T2.1.1.1.1.1.1.m1.1.1.3.7">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.1.1.1.1.1.1.m1.1c">R_{aspect}</annotation></semantics></math><span id="S3.T2.1.1.1.1.1.1.2" class="ltx_text" style="font-size:90%;">)</span>
</td>
</tr>
</tbody></table>
</td>
<td id="S3.T2.1.1.2" class="ltx_td ltx_align_center"><span id="S3.T2.1.1.2.1" class="ltx_text" style="font-size:90%;color:#008000;">âœ“</span></td>
<td id="S3.T2.1.1.3" class="ltx_td ltx_align_center"><span id="S3.T2.1.1.3.1" class="ltx_text" style="font-size:90%;">0.503</span></td>
<td id="S3.T2.1.1.4" class="ltx_td ltx_align_center"><span id="S3.T2.1.1.4.1" class="ltx_text" style="font-size:90%;">0.698</span></td>
<td id="S3.T2.1.1.5" class="ltx_td ltx_align_center"><span id="S3.T2.1.1.5.1" class="ltx_text" style="font-size:90%;">0.625</span></td>
<td id="S3.T2.1.1.6" class="ltx_td"></td>
<td id="S3.T2.1.1.7" class="ltx_td ltx_align_center">
<span id="S3.T2.1.1.7.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">0</span><span id="S3.T2.1.1.7.2" class="ltx_text" style="font-size:90%;">.507</span>
</td>
<td id="S3.T2.1.1.8" class="ltx_td ltx_align_center">
<span id="S3.T2.1.1.8.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">0</span><span id="S3.T2.1.1.8.2" class="ltx_text" style="font-size:90%;">.631</span>
</td>
<td id="S3.T2.1.1.9" class="ltx_td ltx_nopad_r ltx_align_center">
<span id="S3.T2.1.1.9.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">0</span><span id="S3.T2.1.1.9.2" class="ltx_text" style="font-size:90%;">.665</span>
</td>
</tr>
<tr id="S3.T2.3.3" class="ltx_tr">
<td id="S3.T2.3.3.2" class="ltx_td ltx_align_center">
<table id="S3.T2.3.3.2.2" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T2.3.3.2.2.3" class="ltx_tr">
<td id="S3.T2.3.3.2.2.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.3.3.2.2.3.1.1" class="ltx_text" style="font-size:90%;">LM-guided CoT prompting</span></td>
</tr>
<tr id="S3.T2.3.3.2.2.2" class="ltx_tr">
<td id="S3.T2.3.3.2.2.2.2" class="ltx_td ltx_nopad_r ltx_align_center">
<span id="S3.T2.3.3.2.2.2.2.1" class="ltx_text" style="font-size:90%;">(KD + </span><math id="S3.T2.2.2.1.1.1.1.m1.1" class="ltx_Math" alttext="R_{aspect}" display="inline"><semantics id="S3.T2.2.2.1.1.1.1.m1.1a"><msub id="S3.T2.2.2.1.1.1.1.m1.1.1" xref="S3.T2.2.2.1.1.1.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.T2.2.2.1.1.1.1.m1.1.1.2" xref="S3.T2.2.2.1.1.1.1.m1.1.1.2.cmml">R</mi><mrow id="S3.T2.2.2.1.1.1.1.m1.1.1.3" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.cmml"><mi mathsize="90%" id="S3.T2.2.2.1.1.1.1.m1.1.1.3.2" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.T2.2.2.1.1.1.1.m1.1.1.3.1" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.2.2.1.1.1.1.m1.1.1.3.3" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.T2.2.2.1.1.1.1.m1.1.1.3.1a" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.2.2.1.1.1.1.m1.1.1.3.4" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.T2.2.2.1.1.1.1.m1.1.1.3.1b" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.2.2.1.1.1.1.m1.1.1.3.5" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.T2.2.2.1.1.1.1.m1.1.1.3.1c" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.2.2.1.1.1.1.m1.1.1.3.6" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.T2.2.2.1.1.1.1.m1.1.1.3.1d" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.2.2.1.1.1.1.m1.1.1.3.7" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T2.2.2.1.1.1.1.m1.1b"><apply id="S3.T2.2.2.1.1.1.1.m1.1.1.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.2.2.1.1.1.1.m1.1.1.1.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T2.2.2.1.1.1.1.m1.1.1.2.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.2">ğ‘…</ci><apply id="S3.T2.2.2.1.1.1.1.m1.1.1.3.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3"><times id="S3.T2.2.2.1.1.1.1.m1.1.1.3.1.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.1"></times><ci id="S3.T2.2.2.1.1.1.1.m1.1.1.3.2.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.2">ğ‘</ci><ci id="S3.T2.2.2.1.1.1.1.m1.1.1.3.3.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.3">ğ‘ </ci><ci id="S3.T2.2.2.1.1.1.1.m1.1.1.3.4.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.4">ğ‘</ci><ci id="S3.T2.2.2.1.1.1.1.m1.1.1.3.5.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.5">ğ‘’</ci><ci id="S3.T2.2.2.1.1.1.1.m1.1.1.3.6.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.6">ğ‘</ci><ci id="S3.T2.2.2.1.1.1.1.m1.1.1.3.7.cmml" xref="S3.T2.2.2.1.1.1.1.m1.1.1.3.7">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.2.2.1.1.1.1.m1.1c">R_{aspect}</annotation></semantics></math><span id="S3.T2.3.3.2.2.2.2.2" class="ltx_text" style="font-size:90%;"> + </span><math id="S3.T2.3.3.2.2.2.2.m2.1" class="ltx_Math" alttext="R_{taskAcc}" display="inline"><semantics id="S3.T2.3.3.2.2.2.2.m2.1a"><msub id="S3.T2.3.3.2.2.2.2.m2.1.1" xref="S3.T2.3.3.2.2.2.2.m2.1.1.cmml"><mi mathsize="90%" id="S3.T2.3.3.2.2.2.2.m2.1.1.2" xref="S3.T2.3.3.2.2.2.2.m2.1.1.2.cmml">R</mi><mrow id="S3.T2.3.3.2.2.2.2.m2.1.1.3" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.cmml"><mi mathsize="90%" id="S3.T2.3.3.2.2.2.2.m2.1.1.3.2" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.T2.3.3.2.2.2.2.m2.1.1.3.1" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.3.3.2.2.2.2.m2.1.1.3.3" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.T2.3.3.2.2.2.2.m2.1.1.3.1a" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.3.3.2.2.2.2.m2.1.1.3.4" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.T2.3.3.2.2.2.2.m2.1.1.3.1b" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.3.3.2.2.2.2.m2.1.1.3.5" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.5.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.T2.3.3.2.2.2.2.m2.1.1.3.1c" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.3.3.2.2.2.2.m2.1.1.3.6" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.6.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.T2.3.3.2.2.2.2.m2.1.1.3.1d" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.3.3.2.2.2.2.m2.1.1.3.7" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.7.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.T2.3.3.2.2.2.2.m2.1.1.3.1e" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.3.3.2.2.2.2.m2.1.1.3.8" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.8.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T2.3.3.2.2.2.2.m2.1b"><apply id="S3.T2.3.3.2.2.2.2.m2.1.1.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.T2.3.3.2.2.2.2.m2.1.1.1.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1">subscript</csymbol><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.2.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.2">ğ‘…</ci><apply id="S3.T2.3.3.2.2.2.2.m2.1.1.3.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3"><times id="S3.T2.3.3.2.2.2.2.m2.1.1.3.1.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.1"></times><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.3.2.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.2">ğ‘¡</ci><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.3.3.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.3">ğ‘</ci><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.3.4.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.4">ğ‘ </ci><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.3.5.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.5">ğ‘˜</ci><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.3.6.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.6">ğ´</ci><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.3.7.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.7">ğ‘</ci><ci id="S3.T2.3.3.2.2.2.2.m2.1.1.3.8.cmml" xref="S3.T2.3.3.2.2.2.2.m2.1.1.3.8">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.3.3.2.2.2.2.m2.1c">R_{taskAcc}</annotation></semantics></math><span id="S3.T2.3.3.2.2.2.2.3" class="ltx_text" style="font-size:90%;">)</span>
</td>
</tr>
</tbody></table>
</td>
<td id="S3.T2.3.3.3" class="ltx_td ltx_align_center"><span id="S3.T2.3.3.3.1" class="ltx_text" style="font-size:90%;color:#008000;">âœ“</span></td>
<td id="S3.T2.3.3.4" class="ltx_td ltx_align_center">
<span id="S3.T2.3.3.4.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">0</span><span id="S3.T2.3.3.4.2" class="ltx_text" style="font-size:90%;">.508</span>
</td>
<td id="S3.T2.3.3.5" class="ltx_td ltx_align_center">
<span id="S3.T2.3.3.5.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">0</span><span id="S3.T2.3.3.5.2" class="ltx_text" style="font-size:90%;">.704</span>
</td>
<td id="S3.T2.3.3.6" class="ltx_td ltx_align_center">
<span id="S3.T2.3.3.6.1" class="ltx_text ltx_framed ltx_framed_underline" style="font-size:90%;">0</span><span id="S3.T2.3.3.6.2" class="ltx_text" style="font-size:90%;">.627</span>
</td>
<td id="S3.T2.3.3.7" class="ltx_td"></td>
<td id="S3.T2.3.3.8" class="ltx_td ltx_align_center"><span id="S3.T2.3.3.8.1" class="ltx_text" style="font-size:90%;">0.503</span></td>
<td id="S3.T2.3.3.9" class="ltx_td ltx_align_center"><span id="S3.T2.3.3.9.1" class="ltx_text" style="font-size:90%;">0.622</span></td>
<td id="S3.T2.3.3.10" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.3.3.10.1" class="ltx_text" style="font-size:90%;">0.657</span></td>
</tr>
<tr id="S3.T2.4.4" class="ltx_tr">
<td id="S3.T2.4.4.1" class="ltx_td ltx_align_center ltx_border_bb">
<table id="S3.T2.4.4.1.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T2.4.4.1.1.2" class="ltx_tr">
<td id="S3.T2.4.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T2.4.4.1.1.2.1.1" class="ltx_text" style="font-size:90%;">LM-guided CoT prompting</span></td>
</tr>
<tr id="S3.T2.4.4.1.1.1" class="ltx_tr">
<td id="S3.T2.4.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">
<span id="S3.T2.4.4.1.1.1.1.1" class="ltx_text" style="font-size:90%;">(KD +</span><math id="S3.T2.4.4.1.1.1.1.m1.1" class="ltx_Math" alttext="R_{aspect}" display="inline"><semantics id="S3.T2.4.4.1.1.1.1.m1.1a"><msub id="S3.T2.4.4.1.1.1.1.m1.1.1" xref="S3.T2.4.4.1.1.1.1.m1.1.1.cmml"><mi mathsize="90%" id="S3.T2.4.4.1.1.1.1.m1.1.1.2" xref="S3.T2.4.4.1.1.1.1.m1.1.1.2.cmml">R</mi><mrow id="S3.T2.4.4.1.1.1.1.m1.1.1.3" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.cmml"><mi mathsize="90%" id="S3.T2.4.4.1.1.1.1.m1.1.1.3.2" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.T2.4.4.1.1.1.1.m1.1.1.3.1" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.4.4.1.1.1.1.m1.1.1.3.3" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.T2.4.4.1.1.1.1.m1.1.1.3.1a" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.4.4.1.1.1.1.m1.1.1.3.4" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.T2.4.4.1.1.1.1.m1.1.1.3.1b" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.4.4.1.1.1.1.m1.1.1.3.5" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.T2.4.4.1.1.1.1.m1.1.1.3.1c" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.4.4.1.1.1.1.m1.1.1.3.6" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.T2.4.4.1.1.1.1.m1.1.1.3.1d" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.1.cmml">â€‹</mo><mi mathsize="90%" id="S3.T2.4.4.1.1.1.1.m1.1.1.3.7" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.T2.4.4.1.1.1.1.m1.1b"><apply id="S3.T2.4.4.1.1.1.1.m1.1.1.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T2.4.4.1.1.1.1.m1.1.1.1.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T2.4.4.1.1.1.1.m1.1.1.2.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.2">ğ‘…</ci><apply id="S3.T2.4.4.1.1.1.1.m1.1.1.3.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3"><times id="S3.T2.4.4.1.1.1.1.m1.1.1.3.1.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.1"></times><ci id="S3.T2.4.4.1.1.1.1.m1.1.1.3.2.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.2">ğ‘</ci><ci id="S3.T2.4.4.1.1.1.1.m1.1.1.3.3.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.3">ğ‘ </ci><ci id="S3.T2.4.4.1.1.1.1.m1.1.1.3.4.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.4">ğ‘</ci><ci id="S3.T2.4.4.1.1.1.1.m1.1.1.3.5.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.5">ğ‘’</ci><ci id="S3.T2.4.4.1.1.1.1.m1.1.1.3.6.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.6">ğ‘</ci><ci id="S3.T2.4.4.1.1.1.1.m1.1.1.3.7.cmml" xref="S3.T2.4.4.1.1.1.1.m1.1.1.3.7">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T2.4.4.1.1.1.1.m1.1c">R_{aspect}</annotation></semantics></math><span id="S3.T2.4.4.1.1.1.1.2" class="ltx_text" style="font-size:90%;"> + ranking)</span>
</td>
</tr>
</tbody></table>
</td>
<td id="S3.T2.4.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.4.4.2.1" class="ltx_text" style="font-size:90%;color:#008000;">âœ“</span></td>
<td id="S3.T2.4.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.4.4.3.1" class="ltx_text" style="font-size:90%;">0.5</span></td>
<td id="S3.T2.4.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.4.4.4.1" class="ltx_text" style="font-size:90%;">0.698</span></td>
<td id="S3.T2.4.4.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.4.4.5.1" class="ltx_text" style="font-size:90%;">0.623</span></td>
<td id="S3.T2.4.4.6" class="ltx_td ltx_border_bb"></td>
<td id="S3.T2.4.4.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.4.4.7.1" class="ltx_text" style="font-size:90%;">0.501</span></td>
<td id="S3.T2.4.4.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T2.4.4.8.1" class="ltx_text" style="font-size:90%;">0.619</span></td>
<td id="S3.T2.4.4.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S3.T2.4.4.9.1" class="ltx_text" style="font-size:90%;">0.653</span></td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Answer prediction performance results of baselines and our approach. We regard SC decoding as a non-rationale provision because this method can result in multiple variations of rationales, rather than a single one. Values in bold represent the highest scores and underlined values are the second highest scores.</figcaption>
</figure>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.7" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.7.8" class="ltx_tr">
<td id="S3.T3.7.8.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T3.7.8.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Type</span></td>
<td id="S3.T3.7.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T3.7.8.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Description</span></td>
<td id="S3.T3.7.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T3.7.8.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Template</span></td>
</tr>
<tr id="S3.T3.2.2" class="ltx_tr">
<td id="S3.T3.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<table id="S3.T3.2.2.3.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.2.2.3.1.1" class="ltx_tr">
<td id="S3.T3.2.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T3.2.2.3.1.1.1.1" class="ltx_text" style="font-size:90%;">Standard</span></td>
</tr>
<tr id="S3.T3.2.2.3.1.2" class="ltx_tr">
<td id="S3.T3.2.2.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T3.2.2.3.1.2.1.1" class="ltx_text" style="font-size:90%;">prompting</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S3.T3.2.2.4.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.2.2.4.1.1" class="ltx_tr">
<td id="S3.T3.2.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T3.2.2.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Directly predicting the answer</span></td>
</tr>
<tr id="S3.T3.2.2.4.1.2" class="ltx_tr">
<td id="S3.T3.2.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T3.2.2.4.1.2.1.1" class="ltx_text" style="font-size:90%;">based on input</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S3.T3.2.2.2.2" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.2.2.2.2.3" class="ltx_tr">
<td id="S3.T3.2.2.2.2.3.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.2.2.2.2.3.1.1" class="ltx_text" style="font-size:90%;">Based on the provided context, answer the following question (Q).</span></td>
</tr>
<tr id="S3.T3.1.1.1.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T3.1.1.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Context: </span><math id="S3.T3.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.T3.1.1.1.1.1.1.m1.1a"><mi mathcolor="#008000" mathsize="90%" id="S3.T3.1.1.1.1.1.1.m1.1.1" xref="S3.T3.1.1.1.1.1.1.m1.1.1.cmml">ğ’„</mi><annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.1.1.1.m1.1b"><ci id="S3.T3.1.1.1.1.1.1.m1.1.1.cmml" xref="S3.T3.1.1.1.1.1.1.m1.1.1">ğ’„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.1.1.1.1.1.1.m1.1c">c</annotation></semantics></math>
</td>
</tr>
<tr id="S3.T3.2.2.2.2.2" class="ltx_tr">
<td id="S3.T3.2.2.2.2.2.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T3.2.2.2.2.2.1.1" class="ltx_text" style="font-size:90%;">Q: </span><math id="S3.T3.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.T3.2.2.2.2.2.1.m1.1a"><mi mathcolor="#FF00FF" mathsize="90%" id="S3.T3.2.2.2.2.2.1.m1.1.1" xref="S3.T3.2.2.2.2.2.1.m1.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.2.2.1.m1.1b"><ci id="S3.T3.2.2.2.2.2.1.m1.1.1.cmml" xref="S3.T3.2.2.2.2.2.1.m1.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.2.2.2.1.m1.1c">q</annotation></semantics></math>
</td>
</tr>
<tr id="S3.T3.2.2.2.2.4" class="ltx_tr">
<td id="S3.T3.2.2.2.2.4.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.2.2.2.2.4.1.1" class="ltx_text" style="font-size:90%;">A:</span></td>
</tr>
</tbody></table>
</td>
</tr>
<tr id="S3.T3.4.4" class="ltx_tr">
<td id="S3.T3.4.4.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<table id="S3.T3.4.4.3.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.4.4.3.1.1" class="ltx_tr">
<td id="S3.T3.4.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T3.4.4.3.1.1.1.1" class="ltx_text" style="font-size:90%;">CoT</span></td>
</tr>
<tr id="S3.T3.4.4.3.1.2" class="ltx_tr">
<td id="S3.T3.4.4.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T3.4.4.3.1.2.1.1" class="ltx_text" style="font-size:90%;">prompting</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<table id="S3.T3.4.4.4.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.4.4.4.1.1" class="ltx_tr">
<td id="S3.T3.4.4.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T3.4.4.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Predicting the answer after</span></td>
</tr>
<tr id="S3.T3.4.4.4.1.2" class="ltx_tr">
<td id="S3.T3.4.4.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T3.4.4.4.1.2.1.1" class="ltx_text" style="font-size:90%;">generating the reasoning</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S3.T3.4.4.2.2" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.4.4.2.2.3" class="ltx_tr">
<td id="S3.T3.4.4.2.2.3.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.4.4.2.2.3.1.1" class="ltx_text" style="font-size:90%;">Based on the provided context, answer the following question (Q)</span></td>
</tr>
<tr id="S3.T3.4.4.2.2.4" class="ltx_tr">
<td id="S3.T3.4.4.2.2.4.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.4.4.2.2.4.1.1" class="ltx_text" style="font-size:90%;">by reasoning step-by-step.</span></td>
</tr>
<tr id="S3.T3.3.3.1.1.1" class="ltx_tr">
<td id="S3.T3.3.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T3.3.3.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Context: </span><math id="S3.T3.3.3.1.1.1.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.T3.3.3.1.1.1.1.m1.1a"><mi mathcolor="#008000" mathsize="90%" id="S3.T3.3.3.1.1.1.1.m1.1.1" xref="S3.T3.3.3.1.1.1.1.m1.1.1.cmml">ğ’„</mi><annotation-xml encoding="MathML-Content" id="S3.T3.3.3.1.1.1.1.m1.1b"><ci id="S3.T3.3.3.1.1.1.1.m1.1.1.cmml" xref="S3.T3.3.3.1.1.1.1.m1.1.1">ğ’„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.3.1.1.1.1.m1.1c">c</annotation></semantics></math>
</td>
</tr>
<tr id="S3.T3.4.4.2.2.2" class="ltx_tr">
<td id="S3.T3.4.4.2.2.2.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T3.4.4.2.2.2.1.1" class="ltx_text" style="font-size:90%;">Q: </span><math id="S3.T3.4.4.2.2.2.1.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.T3.4.4.2.2.2.1.m1.1a"><mi mathcolor="#FF00FF" mathsize="90%" id="S3.T3.4.4.2.2.2.1.m1.1.1" xref="S3.T3.4.4.2.2.2.1.m1.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.T3.4.4.2.2.2.1.m1.1b"><ci id="S3.T3.4.4.2.2.2.1.m1.1.1.cmml" xref="S3.T3.4.4.2.2.2.1.m1.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.4.2.2.2.1.m1.1c">q</annotation></semantics></math>
</td>
</tr>
<tr id="S3.T3.4.4.2.2.5" class="ltx_tr">
<td id="S3.T3.4.4.2.2.5.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.4.4.2.2.5.1.1" class="ltx_text" style="font-size:90%;">A : Letâ€™s think step by step.</span></td>
</tr>
</tbody></table>
</td>
</tr>
<tr id="S3.T3.7.7" class="ltx_tr">
<td id="S3.T3.7.7.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<table id="S3.T3.7.7.4.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.7.7.4.1.1" class="ltx_tr">
<td id="S3.T3.7.7.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T3.7.7.4.1.1.1.1" class="ltx_text" style="font-size:90%;">LM-guided</span></td>
</tr>
<tr id="S3.T3.7.7.4.1.2" class="ltx_tr">
<td id="S3.T3.7.7.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T3.7.7.4.1.2.1.1" class="ltx_text" style="font-size:90%;">CoT prompting</span></td>
</tr>
<tr id="S3.T3.7.7.4.1.3" class="ltx_tr">
<td id="S3.T3.7.7.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T3.7.7.4.1.3.1.1" class="ltx_text ltx_font_bold ltx_font_italic" style="font-size:90%;color:#BE2D2D;">(our method)</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.7.7.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">
<table id="S3.T3.7.7.5.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.7.7.5.1.1" class="ltx_tr">
<td id="S3.T3.7.7.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T3.7.7.5.1.1.1.1" class="ltx_text" style="font-size:90%;">Predicting the answer with</span></td>
</tr>
<tr id="S3.T3.7.7.5.1.2" class="ltx_tr">
<td id="S3.T3.7.7.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T3.7.7.5.1.2.1.1" class="ltx_text" style="font-size:90%;">conditional generation upon</span></td>
</tr>
<tr id="S3.T3.7.7.5.1.3" class="ltx_tr">
<td id="S3.T3.7.7.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T3.7.7.5.1.3.1.1" class="ltx_text" style="font-size:90%;">the LM-generated reasoning</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.7.7.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">
<table id="S3.T3.7.7.3.3" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.7.7.3.3.4" class="ltx_tr">
<td id="S3.T3.7.7.3.3.4.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.7.7.3.3.4.1.1" class="ltx_text" style="font-size:90%;">Based on the provided context, answer the following question (Q)</span></td>
</tr>
<tr id="S3.T3.7.7.3.3.5" class="ltx_tr">
<td id="S3.T3.7.7.3.3.5.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.7.7.3.3.5.1.1" class="ltx_text" style="font-size:90%;">by reasoning step-by-step.</span></td>
</tr>
<tr id="S3.T3.5.5.1.1.1" class="ltx_tr">
<td id="S3.T3.5.5.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T3.5.5.1.1.1.1.1" class="ltx_text" style="font-size:90%;">Context: </span><math id="S3.T3.5.5.1.1.1.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.T3.5.5.1.1.1.1.m1.1a"><mi mathcolor="#008000" mathsize="90%" id="S3.T3.5.5.1.1.1.1.m1.1.1" xref="S3.T3.5.5.1.1.1.1.m1.1.1.cmml">ğ’„</mi><annotation-xml encoding="MathML-Content" id="S3.T3.5.5.1.1.1.1.m1.1b"><ci id="S3.T3.5.5.1.1.1.1.m1.1.1.cmml" xref="S3.T3.5.5.1.1.1.1.m1.1.1">ğ’„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.5.5.1.1.1.1.m1.1c">c</annotation></semantics></math>
</td>
</tr>
<tr id="S3.T3.6.6.2.2.2" class="ltx_tr">
<td id="S3.T3.6.6.2.2.2.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T3.6.6.2.2.2.1.1" class="ltx_text" style="font-size:90%;">Q: </span><math id="S3.T3.6.6.2.2.2.1.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.T3.6.6.2.2.2.1.m1.1a"><mi mathcolor="#FF00FF" mathsize="90%" id="S3.T3.6.6.2.2.2.1.m1.1.1" xref="S3.T3.6.6.2.2.2.1.m1.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.T3.6.6.2.2.2.1.m1.1b"><ci id="S3.T3.6.6.2.2.2.1.m1.1.1.cmml" xref="S3.T3.6.6.2.2.2.1.m1.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.6.6.2.2.2.1.m1.1c">q</annotation></semantics></math>
</td>
</tr>
<tr id="S3.T3.7.7.3.3.3" class="ltx_tr">
<td id="S3.T3.7.7.3.3.3.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T3.7.7.3.3.3.1.1" class="ltx_text" style="font-size:90%;">A : Letâ€™s think step by step. </span><math id="S3.T3.7.7.3.3.3.1.m1.1" class="ltx_Math" alttext="r^{\prime}" display="inline"><semantics id="S3.T3.7.7.3.3.3.1.m1.1a"><msup id="S3.T3.7.7.3.3.3.1.m1.1.1" xref="S3.T3.7.7.3.3.3.1.m1.1.1.cmml"><mi mathcolor="#FF8000" mathsize="90%" id="S3.T3.7.7.3.3.3.1.m1.1.1.2" xref="S3.T3.7.7.3.3.3.1.m1.1.1.2.cmml">ğ’“</mi><mo class="ltx_mathvariant_bold" mathcolor="#FF8000" mathsize="90%" mathvariant="bold" id="S3.T3.7.7.3.3.3.1.m1.1.1.3" xref="S3.T3.7.7.3.3.3.1.m1.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T3.7.7.3.3.3.1.m1.1b"><apply id="S3.T3.7.7.3.3.3.1.m1.1.1.cmml" xref="S3.T3.7.7.3.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T3.7.7.3.3.3.1.m1.1.1.1.cmml" xref="S3.T3.7.7.3.3.3.1.m1.1.1">superscript</csymbol><ci id="S3.T3.7.7.3.3.3.1.m1.1.1.2.cmml" xref="S3.T3.7.7.3.3.3.1.m1.1.1.2">ğ’“</ci><ci id="S3.T3.7.7.3.3.3.1.m1.1.1.3.cmml" xref="S3.T3.7.7.3.3.3.1.m1.1.1.3">bold-â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.7.7.3.3.3.1.m1.1c">r^{\prime}</annotation></semantics></math><span id="S3.T3.7.7.3.3.3.1.2" class="ltx_text" style="font-size:90%;color:#FF8000;"> <span id="S3.T3.7.7.3.3.3.1.2.1" class="ltx_text" style="color:#000000;">. Hence, the answer is</span></span>
</td>
</tr>
</tbody></table>
</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Descriptions and templates of each prompt used for the answer prediction task. <math id="S3.T3.11.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.T3.11.m1.1b"><mi mathcolor="#FF00FF" id="S3.T3.11.m1.1.1" xref="S3.T3.11.m1.1.1.cmml">ğ’’</mi><annotation-xml encoding="MathML-Content" id="S3.T3.11.m1.1c"><ci id="S3.T3.11.m1.1.1.cmml" xref="S3.T3.11.m1.1.1">ğ’’</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.11.m1.1d">q</annotation></semantics></math><span id="S3.T3.13.2" class="ltx_text" style="color:#000000;">, <math id="S3.T3.12.1.m1.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S3.T3.12.1.m1.1b"><mi mathcolor="#008000" id="S3.T3.12.1.m1.1.1" xref="S3.T3.12.1.m1.1.1.cmml">ğ’„</mi><annotation-xml encoding="MathML-Content" id="S3.T3.12.1.m1.1c"><ci id="S3.T3.12.1.m1.1.1.cmml" xref="S3.T3.12.1.m1.1.1">ğ’„</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.12.1.m1.1d">c</annotation></semantics></math>, and <math id="S3.T3.13.2.m2.1" class="ltx_Math" alttext="r^{\prime}" display="inline"><semantics id="S3.T3.13.2.m2.1b"><msup id="S3.T3.13.2.m2.1.1" xref="S3.T3.13.2.m2.1.1.cmml"><mi mathcolor="#FF8000" id="S3.T3.13.2.m2.1.1.2" xref="S3.T3.13.2.m2.1.1.2.cmml">ğ’“</mi><mo class="ltx_mathvariant_bold" mathcolor="#FF8000" mathvariant="bold" id="S3.T3.13.2.m2.1.1.3" xref="S3.T3.13.2.m2.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S3.T3.13.2.m2.1c"><apply id="S3.T3.13.2.m2.1.1.cmml" xref="S3.T3.13.2.m2.1.1"><csymbol cd="ambiguous" id="S3.T3.13.2.m2.1.1.1.cmml" xref="S3.T3.13.2.m2.1.1">superscript</csymbol><ci id="S3.T3.13.2.m2.1.1.2.cmml" xref="S3.T3.13.2.m2.1.1.2">ğ’“</ci><ci id="S3.T3.13.2.m2.1.1.3.cmml" xref="S3.T3.13.2.m2.1.1.3">bold-â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.13.2.m2.1d">r^{\prime}</annotation></semantics></math><span id="S3.T3.13.2.1" class="ltx_text" style="color:#FF8000;"> </span>denote a question, context, and a corresponding rationale generated by the small LM, respectively.</span></figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">4.&nbsp;&nbsp;&nbsp;Experiments and Results</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">4.1.&nbsp;&nbsp;&nbsp;Experimental Setup</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.2" class="ltx_p"><span id="S4.SS1.p1.2.1" class="ltx_text ltx_font_bold">Model and Dataset.</span> we utilize FLAN-T5 small (80M) for <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="M^{S}" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><msup id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">M</mi><mi id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">ğ‘€</ci><ci id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">M^{S}</annotation></semantics></math> and FLAN-T5 XXL (11B) for <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="M^{L}" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><msup id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">M</mi><mi id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">ğ‘€</ci><ci id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">M^{L}</annotation></semantics></math>.
Both HotpotQA <cite class="ltx_cite ltx_citemacro_cite">Yang et&nbsp;al. (<a href="#biba.bib2" title="" class="ltx_ref">2018</a>)</cite> and 2WikiMultiHopQA <cite class="ltx_cite ltx_citemacro_cite">Ho et&nbsp;al. (<a href="#biba.bib1" title="" class="ltx_ref">2020</a>)</cite> consist of an input question, and an answer, along with 9-10 context paragraphs with supportiveness labels indicating whether the paragraph contains supporting facts. Due to the input token size limitation of FLAN-T5, we only use supporting paragraphs as context.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Training &amp; Evaluation Setup.</span> We use a randomly sampled subset of training data from two datasets (15K samples per data) for model training. After filtering unqualified reasoning, it results in 23K samples. All training-related hyperparameters can be found in Â§<a href="#S11.SS3" title="11.3. Training Configuration â€£ 11. Appendices â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11.3</span></a>. According to our preliminary experiments, the impact of CoT prompting appeared to be diminished due to two potential factors: (1) questions being overly simplistic, obscuring the significance of intermediate reasoning processes; (2) LMs already possessing pertinent background information (<span id="S4.SS1.p2.1.2" class="ltx_text ltx_font_italic">e.g.</span>, Flan-T5 is fine-tuned on various question-answering datasets). To prevent models from answering based on parametric memory, we attempt to make the existing evaluation data more challenging, similar to the approaches taken by <cite class="ltx_cite ltx_citemacro_citet">Ye and Durrett (<a href="#bib.bib23" title="" class="ltx_ref">2022</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Zhao et&nbsp;al. (<a href="#bib.bib24" title="" class="ltx_ref">2023</a>)</cite>. For each dataset, we leverage the prediction outcomes of standard prompting and select 1000 input instances that <math id="S4.SS1.p2.1.m1.1" class="ltx_Math" alttext="M^{L}" display="inline"><semantics id="S4.SS1.p2.1.m1.1a"><msup id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml"><mi id="S4.SS1.p2.1.m1.1.1.2" xref="S4.SS1.p2.1.m1.1.1.2.cmml">M</mi><mi id="S4.SS1.p2.1.m1.1.1.3" xref="S4.SS1.p2.1.m1.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><apply id="S4.SS1.p2.1.m1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p2.1.m1.1.1.1.cmml" xref="S4.SS1.p2.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.p2.1.m1.1.1.2.cmml" xref="S4.SS1.p2.1.m1.1.1.2">ğ‘€</ci><ci id="S4.SS1.p2.1.m1.1.1.3.cmml" xref="S4.SS1.p2.1.m1.1.1.3">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">M^{L}</annotation></semantics></math> answered correctly and an additional 1000 from questions where the model provided incorrect responses. This results in a total of 2000 samples for evaluation.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Baselines and Evaluation Metrics.</span> We use standard prompting and CoT prompting as our baselines (see Table <a href="#S3.T3" title="Table 3 â€£ 3.2. Rationale Refinement â€£ 3. LM-guided Chain-of-Thought â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). We also experiment with the SC decoding strategy <cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib20" title="" class="ltx_ref">2022b</a>)</cite>, which samples multiple reasoning paths (n=10) and selects the most consistent answer. For evaluation, we report three metrics for the answer prediction task: (1) exact match (EM), computing whether the prediction exactly matches the ground truth answer, (2) F1, computing the average word overlap between the prediction and ground truth answer, and (3) answer inclusion<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>We included this measurement because models often provide more extensive responses (<span id="footnote3.1" class="ltx_text ltx_font_italic">e.g.</span>, ground truth: Worldâ€™s Best Goalkeeper <math id="footnote3.m1.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="footnote3.m1.1b"><mo stretchy="false" id="footnote3.m1.1.1" xref="footnote3.m1.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="footnote3.m1.1c"><ci id="footnote3.m1.1.1.cmml" xref="footnote3.m1.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote3.m1.1d">\rightarrow</annotation></semantics></math> generation: IFFHS Worldâ€™s Best Goalkeeper). This may be explained by our usage of contextual paragraphs as input.</span></span></span>, computing whether the ground truth answer is mentioned in the prediction.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">4.2.&nbsp;&nbsp;&nbsp;Results</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.2" class="ltx_p"><span id="S4.SS2.p1.2.1" class="ltx_text ltx_font_bold">Baseline Performance.</span>
As shown in Table <a href="#S3.T2" title="Table 2 â€£ 3.2. Rationale Refinement â€£ 3. LM-guided Chain-of-Thought â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we find that <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="M^{L}" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><msup id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">M</mi><mi id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">ğ‘€</ci><ci id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">M^{L}</annotation></semantics></math> (equivalent to FLAN-T5 XXL) does not benefit from the original CoT prompting, as its EM and F1 scores dropped in both datasets (except for answer inclusion score for HotpotQA) when compared to standard prompting. This is consistent with previous research findings that models with less than 50B parameters exhibit limited reasoning capabilities. We also observe that the performance drop is more significant with 2WikiMultihopQA (nearly 10% for EM and F1) than HotpotQA. Based on our manual inspection of incorrect predictions, <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="M^{L}" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><msup id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml"><mi id="S4.SS2.p1.2.m2.1.1.2" xref="S4.SS2.p1.2.m2.1.1.2.cmml">M</mi><mi id="S4.SS2.p1.2.m2.1.1.3" xref="S4.SS2.p1.2.m2.1.1.3.cmml">L</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><apply id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p1.2.m2.1.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS2.p1.2.m2.1.1.2.cmml" xref="S4.SS2.p1.2.m2.1.1.2">ğ‘€</ci><ci id="S4.SS2.p1.2.m2.1.1.3.cmml" xref="S4.SS2.p1.2.m2.1.1.3">ğ¿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">M^{L}</annotation></semantics></math> was prone to repeat sentences in the context and fail to provide a final answer to the questions. This hints that, when context gets too long, models face difficulties in digesting the content and establishing valid reasoning steps. Overall, SC CoT prompting enables the model to noticeably recover from answer prediction errors, especially for 2WikiMultihopQA.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">LM-guided CoT Performance.</span>
Table <a href="#S3.T2" title="Table 2 â€£ 3.2. Rationale Refinement â€£ 3. LM-guided Chain-of-Thought â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows a comprehensive breakdown of our methodâ€™s performance. Additionally, we explore an extension of our approach, which involves sampling multiple reasoning paths and subsequently ranking the most optimal rationales. Our method with only KD outperforms the original CoT prompting with 2% gain for HotpotQA and 10% for 2WikiMultiHopQA, respectively. Figure <a href="#S4.F2" title="Figure 2 â€£ 4.2. Results â€£ 4. Experiments and Results â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the respective rationale qualities of all prompting techniques, reinforcing the effectiveness of our method in enhancing both answer prediction and rationale qualities. When employing the original CoT prompting for questions with lengthy contexts, models frequently recycle sentences from the provided context and struggle to deliver a conclusive answer to the question. This trend is mitigated by our approach, resulting in a significant decrease in error rates. It also surpasses the performance of CoT prompting + SC and is on par with standard prompting in terms of EM and F1. For the answer inclusion score, LM-guided CoT prompting is slightly higher (1-2%) than standard prompting. Furthermore, LM-guided CoT prompting + SC achieves the highest performance across all settings.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2404.03414/assets/reward_new2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="337" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Average answer prediction performance (across three evaluation metrics) and average rationale quality scores (<span id="S4.F2.4.1" class="ltx_text ltx_font_italic">i.e.</span>, <math id="S4.F2.2.m1.1" class="ltx_Math" alttext="R_{aspect}" display="inline"><semantics id="S4.F2.2.m1.1b"><msub id="S4.F2.2.m1.1.1" xref="S4.F2.2.m1.1.1.cmml"><mi id="S4.F2.2.m1.1.1.2" xref="S4.F2.2.m1.1.1.2.cmml">R</mi><mrow id="S4.F2.2.m1.1.1.3" xref="S4.F2.2.m1.1.1.3.cmml"><mi id="S4.F2.2.m1.1.1.3.2" xref="S4.F2.2.m1.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S4.F2.2.m1.1.1.3.1" xref="S4.F2.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.F2.2.m1.1.1.3.3" xref="S4.F2.2.m1.1.1.3.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S4.F2.2.m1.1.1.3.1b" xref="S4.F2.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.F2.2.m1.1.1.3.4" xref="S4.F2.2.m1.1.1.3.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S4.F2.2.m1.1.1.3.1c" xref="S4.F2.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.F2.2.m1.1.1.3.5" xref="S4.F2.2.m1.1.1.3.5.cmml">e</mi><mo lspace="0em" rspace="0em" id="S4.F2.2.m1.1.1.3.1d" xref="S4.F2.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.F2.2.m1.1.1.3.6" xref="S4.F2.2.m1.1.1.3.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="S4.F2.2.m1.1.1.3.1e" xref="S4.F2.2.m1.1.1.3.1.cmml">â€‹</mo><mi id="S4.F2.2.m1.1.1.3.7" xref="S4.F2.2.m1.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.F2.2.m1.1c"><apply id="S4.F2.2.m1.1.1.cmml" xref="S4.F2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.F2.2.m1.1.1.1.cmml" xref="S4.F2.2.m1.1.1">subscript</csymbol><ci id="S4.F2.2.m1.1.1.2.cmml" xref="S4.F2.2.m1.1.1.2">ğ‘…</ci><apply id="S4.F2.2.m1.1.1.3.cmml" xref="S4.F2.2.m1.1.1.3"><times id="S4.F2.2.m1.1.1.3.1.cmml" xref="S4.F2.2.m1.1.1.3.1"></times><ci id="S4.F2.2.m1.1.1.3.2.cmml" xref="S4.F2.2.m1.1.1.3.2">ğ‘</ci><ci id="S4.F2.2.m1.1.1.3.3.cmml" xref="S4.F2.2.m1.1.1.3.3">ğ‘ </ci><ci id="S4.F2.2.m1.1.1.3.4.cmml" xref="S4.F2.2.m1.1.1.3.4">ğ‘</ci><ci id="S4.F2.2.m1.1.1.3.5.cmml" xref="S4.F2.2.m1.1.1.3.5">ğ‘’</ci><ci id="S4.F2.2.m1.1.1.3.6.cmml" xref="S4.F2.2.m1.1.1.3.6">ğ‘</ci><ci id="S4.F2.2.m1.1.1.3.7.cmml" xref="S4.F2.2.m1.1.1.3.7">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.2.m1.1d">R_{aspect}</annotation></semantics></math>) for HotpotQA (left) and 2WikiMultiHopQA (right). The right y-axis represents the mean answer prediction scores, and the left y-axis represents the mean rationale quality scores.</figcaption>
</figure>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p id="S4.SS2.p3.1" class="ltx_p">As shown in Figure <a href="#S4.F2" title="Figure 2 â€£ 4.2. Results â€£ 4. Experiments and Results â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the implementation of RL enables the model to achieve additional improvements in both rationale qualities and task performance. However, in line with <cite class="ltx_cite ltx_citemacro_citet">Joshi et&nbsp;al. (<a href="#bib.bib4" title="" class="ltx_ref">2023</a>)</cite>â€™s findings, a slight decrease in task performance is observed at the cost of maximized rationale qualities when selecting top-quality rationales. There may be several underlying factors involved (<span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_italic">e.g.</span>, modelsâ€™ unfaithfulness), but this is not the scope of this work.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">5.&nbsp;&nbsp;&nbsp;Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p"><span id="S5.p1.1.1" class="ltx_text ltx_font_bold">LM-Guided CoT</span> is a novel framework that decomposes a conventional CoT prompting into two steps using two models: (1) rationale generation and (2) answer prediction. This includes distilling the reasoning ability from a large LM to a small LM and further optimizing it with RL. The results reveal that our method outperforms all baselines, highlighting its potential to serve as an effective and resource-efficient approach to tackle challenges within the CoT prompting paradigm. Meanwhile, we also find that selecting top-quality rationales for answer prediction may not consistently boost task performance. This prompts the need to explore a more harmonious balance between LM-generated rationale utilities and overall task performance.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">6.&nbsp;&nbsp;&nbsp;Limitations</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Although our framework can seamlessly accommodate various model combinations in a plug-and-play manner, we have restricted our experimental reporting to FLAN-T5. In a similar vein, this work only explores the task of multi-hop QA, leaving an open question about generalizability to other reasoning tasks. We anticipate future research endeavors to extend the application of our approach across diverse domains requiring sophisticated reasoning. Lastly, due to resource constraints, we were unable to collect extensive human annotations for established aspect evaluation metrics.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">7.&nbsp;&nbsp;&nbsp;Ethical Considerations</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">All the datasets that we use in our work are publicly available, and we have given appropriate credit to the original authors throughout the paper. We acknowledge that occasionally, the generated rationales may include non-factual and offensive statements. As we do not plan on distributing these artifacts, it effectively reduces the potential for harm.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">8.&nbsp;&nbsp;&nbsp;Acknowledgments</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">We thank all the reviewers for providing valuable feedback.</p>
</div>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">9.&nbsp;&nbsp;&nbsp;Bibliographical References</h2>

<div id="S9.p1" class="ltx_para">
<span id="S9.p1.1" class="ltx_ERROR undefined">\c@NAT@ctr</span>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography"></h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fleiss (1971)</span>
<span class="ltx_bibblock">
Joseph&nbsp;L Fleiss. 1971.

</span>
<span class="ltx_bibblock">Measuring nominal scale agreement among many raters.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Psychological bulletin</em>, 76(5):378.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu. 2023.

</span>
<span class="ltx_bibblock">Gptscore: Evaluate as you desire.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.04166</em>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Golovneva et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Olga Golovneva, Moya Chen, Spencer Poff, Martin Corredor, Luke Zettlemoyer, Maryam Fazel-Zarandi, and Asli Celikyilmaz. 2022.

</span>
<span class="ltx_bibblock">Roscoe: A suite of metrics for scoring step-by-step reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">In The Eleventh International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Brihi Joshi, Ziyi Liu, Sahana Ramnath, Aaron Chan, Zhewei Tong, Shaoliang Nie, Qifan Wang, Yejin Choi, and Xiang Ren. 2023.

</span>
<span class="ltx_bibblock">Are machine rationales (not) useful to humans? measuring and improving human utility of free-text rationales.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.07095</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jung et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Jaehun Jung, Lianhui Qin, Sean Welleck, Faeze Brahman, Chandra Bhagavatula, Ronan&nbsp;Le Bras, and Yejin Choi. 2022.

</span>
<span class="ltx_bibblock">Maieutic prompting: Logically consistent reasoning with recursive explanations.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.11822</em>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khot et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. 2022.

</span>
<span class="ltx_bibblock">Decomposed prompting: A modular approach for solving complex tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.02406</em>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lanham et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner, Carson Denison, Danny Hernandez, Dustin Li, Esin Durmus, Evan Hubinger, Jackson Kernion, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">Measuring faithfulness in chain-of-thought reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.13702</em>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewkowycz et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock">Solving quantitative reasoning problems with language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 35:3843â€“3857.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Liunian&nbsp;Harold Li, Jack Hessel, Youngjae Yu, Xiang Ren, Kai-Wei Chang, and Yejin Choi. 2023.

</span>
<span class="ltx_bibblock">Symbolic chain-of-thought distillation: Small models can also" think" step-by-step.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.14050</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. 2023.

</span>
<span class="ltx_bibblock">Gpteval: Nlg evaluation using gpt-4 with better human alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.16634</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Longpre et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Shayne Longpre, Le&nbsp;Hou, Tu&nbsp;Vu, Albert Webson, Hyung&nbsp;Won Chung, Yi&nbsp;Tay, Denny Zhou, Quoc&nbsp;V Le, Barret Zoph, Jason Wei, et&nbsp;al. 2023.

</span>
<span class="ltx_bibblock">The flan collection: Designing data and methods for effective instruction tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.13688</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yuhan Ma, Haiqi Jiang, and Chenyou Fan. 2023.

</span>
<span class="ltx_bibblock">Sci-cot: Leveraging large language models for enhanced knowledge distillation in small models for scientific qa.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.04679</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Prasad et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Archiki Prasad, Swarnadeep Saha, Xiang Zhou, and Mohit Bansal. 2023.

</span>
<span class="ltx_bibblock">Receval: Evaluating reasoning chains via correctness and informativeness.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.10703</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schulman et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. 2017.

</span>
<span class="ltx_bibblock">Proximal policy optimization algorithms.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1707.06347</em>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shridhar et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Kumar Shridhar, Alessandro Stolfo, and Mrinmaya Sachan. 2023.

</span>
<span class="ltx_bibblock">Distilling reasoning capabilities into smaller language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023</em>, pages 7059â€“7073.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stiennon et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul&nbsp;F Christiano. 2020.

</span>
<span class="ltx_bibblock">Learning to summarize with human feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 33:3008â€“3021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Turpin et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Miles Turpin, Julian Michael, Ethan Perez, and Samuel&nbsp;R Bowman. 2023.

</span>
<span class="ltx_bibblock">Language models donâ€™t always say what they think: Unfaithful explanations in chain-of-thought prompting.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.04388</em>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022a)</span>
<span class="ltx_bibblock">
Boshi Wang, Sewon Min, Xiang Deng, Jiaming Shen, You Wu, Luke Zettlemoyer, and Huan Sun. 2022a.

</span>
<span class="ltx_bibblock">Towards understanding chain-of-thought prompting: An empirical study of what matters.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.10001</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Jiaan Wang, Yunlong Liang, Fandong Meng, Haoxiang Shi, Zhixu Li, Jinan Xu, Jianfeng Qu, and Jie Zhou. 2023.

</span>
<span class="ltx_bibblock">Is chatgpt a good nlg evaluator? a preliminary study.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.04048</em>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022b)</span>
<span class="ltx_bibblock">
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed&nbsp;Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. 2022b.

</span>
<span class="ltx_bibblock">Self-consistency improves chain of thought reasoning in language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.11171</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022a)</span>
<span class="ltx_bibblock">
Jason Wei, Yi&nbsp;Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et&nbsp;al. 2022a.

</span>
<span class="ltx_bibblock">Emergent abilities of large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.07682</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022b)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed&nbsp;Chi, Quoc&nbsp;V Le, Denny Zhou, et&nbsp;al. 2022b.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 35:24824â€“24837.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye and Durrett (2022)</span>
<span class="ltx_bibblock">
Xi&nbsp;Ye and Greg Durrett. 2022.

</span>
<span class="ltx_bibblock">The unreliability of explanations in few-shot prompting for textual reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, 35:30378â€“30392.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Ruochen Zhao, Xingxuan Li, Shafiq Joty, Chengwei Qin, and Lidong Bing. 2023.

</span>
<span class="ltx_bibblock">Verify-and-edit: A knowledge-enhanced chain-of-thought framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.03268</em>.

</span>
</li>
</ul>
</section>
<section id="S10" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">10.&nbsp;&nbsp;&nbsp;Language Resource References</h2>

<div id="S10.p1" class="ltx_para">
<span id="S10.p1.1" class="ltx_ERROR undefined">\c@NAT@ctr</span>
</div>
</section>
<section id="biba" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">&nbsp;</h2>

<ul class="ltx_biblist">
<li id="biba.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Ho, Xanh and Nguyen, Anh-Khoa Duong and Sugawara, Saku and Aizawa, Akiko. 2020.

</span>
<span class="ltx_bibblock"><em id="biba.bib1.1.1" class="ltx_emph ltx_font_italic">Constructing a multi-hop QA dataset for comprehensive evaluation of reasoning steps</em>.

</span>
</li>
<li id="biba.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2018)</span>
<span class="ltx_bibblock">
Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W and Salakhutdinov, Ruslan and Manning, Christopher D. 2018.

</span>
<span class="ltx_bibblock"><em id="biba.bib2.1.1" class="ltx_emph ltx_font_italic">HotpotQA: A dataset for diverse, explainable multi-hop question answering</em>.

</span>
</li>
</ul>
</section>
<section id="S11" class="ltx_section">
<h2 class="ltx_title ltx_font_bold ltx_title_section" style="font-size:120%;">11.&nbsp;&nbsp;&nbsp;Appendices</h2>

<section id="S11.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">11.1.&nbsp;&nbsp;&nbsp;Human Annotation for Rationale Quality Measurement</h3>

<figure id="S11.F3" class="ltx_figure">
<p id="S11.F3.1" class="ltx_p ltx_align_center"><span id="S11.F3.1.1" class="ltx_text"><svg version="1.1" width="471" height="328" overflow="visible"><g transform="translate(0,328) scale(1,-1)"><rect fill="none" height="237.0pt" stroke="#000000" stroke-width="0.4" width="340.4pt" x="0" y="0"></rect><g class="makebox" transform="translate(0,0)"><g transform="translate(0,328) scale(1, -1)"><foreignObject width="471" height="328" overflow="visible"><img src="/html/2404.03414/assets/annotation_example.png" id="S11.F3.1.1.pic1.1.g1" class="ltx_graphics ltx_img_landscape" width="471" height="328" alt="Refer to caption"></foreignObject></g></g></g></svg></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Demonstration example for "logicality" annotation.</figcaption>
</figure>
<div id="S11.SS1.p1" class="ltx_para">
<p id="S11.SS1.p1.1" class="ltx_p"><span id="S11.SS1.p1.1.1" class="ltx_text ltx_font_bold">Annotation Details.</span> Three researchers manually inspected 100 instances randomly sampled from training data. To ensure the quality and consistency of the annotation process, one researcher designed the annotation instruction describing the definition of each aspect (see Table <a href="#S3.T1" title="Table 1 â€£ 3. LM-guided Chain-of-Thought â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>) as well as 4 demonstration examples for each aspect category. Figure <a href="#S11.F3" title="Figure 3 â€£ 11.1. Human Annotation for Rationale Quality Measurement â€£ 11. Appendices â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> displays demonstration examples for logicality. These examples are chosen randomly from the remaining training set, which was not included in the initial set of 100 annotation samples, and are manually annotated based on aspect descriptions. Upon the completion of annotation, we gauged the inter-rater agreement rates to validate the reliability of submitted annotation results by computing the average Fleissâ€™ Kappa coefficient <cite class="ltx_cite ltx_citemacro_cite">Fleiss (<a href="#bib.bib1" title="" class="ltx_ref">1971</a>)</cite>. The mean Kappa score among the three annotators across all aspect categories was 0.56, indicating a moderate agreement rate. Ultimately, we take the mode of annotated labels submitted by three annotators and consider it as a ground truth.</p>
</div>
<figure id="S11.F4" class="ltx_figure"><img src="/html/2404.03414/assets/barplot_annotation.png" id="S11.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="510" height="316" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Mean scores of human annotation results by answer prediction correctness.</figcaption>
</figure>
<div id="S11.SS1.p2" class="ltx_para ltx_noindent">
<p id="S11.SS1.p2.1" class="ltx_p"><span id="S11.SS1.p2.1.1" class="ltx_text ltx_font_bold">Analysis of Relationships between Aspect Types and Task Performance.</span>
Based on 100 labeled instances, we perform a post-hoc analysis to understand how the proposed aspects are related to answer prediction performance. The label distributions are as follows: correct (n=78) vs. incorrect (n=22). We compare the mean difference of evaluation scores based on correct &amp; incorrect responses. As shown in Figure <a href="#S11.F4" title="Figure 4 â€£ 11.1. Human Annotation for Rationale Quality Measurement â€£ 11. Appendices â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, rationales associated with correct answer prediction are prone to have higher scores than those with incorrect prediction. In particular, coherence has the largest mean difference, followed by readability and logicality. For fluency and naturalness, the gap seems minimal. We further conduct statistical testing to validate their statistical significance. T-test results confirm that the mean difference observed in coherence (<span id="S11.SS1.p2.1.2" class="ltx_text ltx_font_italic">p</span> = 0.003), readability (<span id="S11.SS1.p2.1.3" class="ltx_text ltx_font_italic">p</span> = 0.0002), and logicality (<span id="S11.SS1.p2.1.4" class="ltx_text ltx_font_italic">p</span> = 0.05) are statistically significant with <span id="S11.SS1.p2.1.5" class="ltx_text ltx_font_italic">p</span> &lt; 0.05.</p>
</div>
</section>
<section id="S11.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">11.2.&nbsp;&nbsp;&nbsp;Automatic Measurement for Rationale Quality</h3>

<figure id="S11.T4" class="ltx_table">
<table id="S11.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S11.T4.1.1" class="ltx_tr">
<td id="S11.T4.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="2"><span id="S11.T4.1.1.1.1" class="ltx_text" style="font-size:90%;">Prompting</span></td>
<td id="S11.T4.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S11.T4.1.1.2.1" class="ltx_text" style="font-size:90%;">Coherence</span></td>
<td id="S11.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S11.T4.1.1.3.1" class="ltx_text" style="font-size:90%;">Consistency</span></td>
<td id="S11.T4.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S11.T4.1.1.4.1" class="ltx_text" style="font-size:90%;">Logicality</span></td>
<td id="S11.T4.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S11.T4.1.1.5.1" class="ltx_text" style="font-size:90%;">Fluency</span></td>
<td id="S11.T4.1.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S11.T4.1.1.6.1" class="ltx_text" style="font-size:90%;">Naturalness</span></td>
<td id="S11.T4.1.1.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S11.T4.1.1.7.1" class="ltx_text" style="font-size:90%;">Readability</span></td>
</tr>
<tr id="S11.T4.1.2" class="ltx_tr">
<td id="S11.T4.1.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S11.T4.1.2.1.1" class="ltx_text" style="font-size:90%;">IST</span></td>
<td id="S11.T4.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S11.T4.1.2.2.1" class="ltx_text" style="font-size:90%;">IST</span></td>
<td id="S11.T4.1.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T4.1.2.3.1" class="ltx_text" style="font-size:90%;">0.52</span></td>
<td id="S11.T4.1.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T4.1.2.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.70</span></td>
<td id="S11.T4.1.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T4.1.2.5.1" class="ltx_text" style="font-size:90%;">0.73</span></td>
<td id="S11.T4.1.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T4.1.2.6.1" class="ltx_text" style="font-size:90%;">0.91</span></td>
<td id="S11.T4.1.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T4.1.2.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.52</span></td>
<td id="S11.T4.1.2.8" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S11.T4.1.2.8.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.86</span></td>
</tr>
<tr id="S11.T4.1.3" class="ltx_tr">
<td id="S11.T4.1.3.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S11.T4.1.3.1.1" class="ltx_text" style="font-size:90%;">IST + self-consistency</span></td>
<td id="S11.T4.1.3.2" class="ltx_td ltx_align_center"><span id="S11.T4.1.3.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.53</span></td>
<td id="S11.T4.1.3.3" class="ltx_td ltx_align_center"><span id="S11.T4.1.3.3.1" class="ltx_text" style="font-size:90%;">0.67</span></td>
<td id="S11.T4.1.3.4" class="ltx_td ltx_align_center"><span id="S11.T4.1.3.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.74</span></td>
<td id="S11.T4.1.3.5" class="ltx_td ltx_align_center"><span id="S11.T4.1.3.5.1" class="ltx_text" style="font-size:90%;">0.90</span></td>
<td id="S11.T4.1.3.6" class="ltx_td ltx_align_center"><span id="S11.T4.1.3.6.1" class="ltx_text" style="font-size:90%;">0.50</span></td>
<td id="S11.T4.1.3.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S11.T4.1.3.7.1" class="ltx_text" style="font-size:90%;">0.85</span></td>
</tr>
<tr id="S11.T4.1.4" class="ltx_tr">
<td id="S11.T4.1.4.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="4"><span id="S11.T4.1.4.1.1" class="ltx_text" style="font-size:90%;">IDM</span></td>
<td id="S11.T4.1.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S11.T4.1.4.2.1" class="ltx_text" style="font-size:90%;">IDM (1 shot)</span></td>
<td id="S11.T4.1.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T4.1.4.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.53</span></td>
<td id="S11.T4.1.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T4.1.4.4.1" class="ltx_text" style="font-size:90%;">0.64</span></td>
<td id="S11.T4.1.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T4.1.4.5.1" class="ltx_text" style="font-size:90%;">0.70</span></td>
<td id="S11.T4.1.4.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T4.1.4.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.92</span></td>
<td id="S11.T4.1.4.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T4.1.4.7.1" class="ltx_text" style="font-size:90%;">0.29</span></td>
<td id="S11.T4.1.4.8" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S11.T4.1.4.8.1" class="ltx_text" style="font-size:90%;">0.70</span></td>
</tr>
<tr id="S11.T4.1.5" class="ltx_tr">
<td id="S11.T4.1.5.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S11.T4.1.5.1.1" class="ltx_text" style="font-size:90%;">IDM (2 shot)</span></td>
<td id="S11.T4.1.5.2" class="ltx_td ltx_align_center"><span id="S11.T4.1.5.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.53</span></td>
<td id="S11.T4.1.5.3" class="ltx_td ltx_align_center"><span id="S11.T4.1.5.3.1" class="ltx_text" style="font-size:90%;">0.62</span></td>
<td id="S11.T4.1.5.4" class="ltx_td ltx_align_center"><span id="S11.T4.1.5.4.1" class="ltx_text" style="font-size:90%;">0.73</span></td>
<td id="S11.T4.1.5.5" class="ltx_td ltx_align_center"><span id="S11.T4.1.5.5.1" class="ltx_text" style="font-size:90%;">0.91</span></td>
<td id="S11.T4.1.5.6" class="ltx_td ltx_align_center"><span id="S11.T4.1.5.6.1" class="ltx_text" style="font-size:90%;">0.24</span></td>
<td id="S11.T4.1.5.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S11.T4.1.5.7.1" class="ltx_text" style="font-size:90%;">0.69</span></td>
</tr>
<tr id="S11.T4.1.6" class="ltx_tr">
<td id="S11.T4.1.6.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S11.T4.1.6.1.1" class="ltx_text" style="font-size:90%;">IDM (3 shot)</span></td>
<td id="S11.T4.1.6.2" class="ltx_td ltx_align_center"><span id="S11.T4.1.6.2.1" class="ltx_text" style="font-size:90%;">0.51</span></td>
<td id="S11.T4.1.6.3" class="ltx_td ltx_align_center"><span id="S11.T4.1.6.3.1" class="ltx_text" style="font-size:90%;">0.62</span></td>
<td id="S11.T4.1.6.4" class="ltx_td ltx_align_center"><span id="S11.T4.1.6.4.1" class="ltx_text" style="font-size:90%;">0.73</span></td>
<td id="S11.T4.1.6.5" class="ltx_td ltx_align_center"><span id="S11.T4.1.6.5.1" class="ltx_text" style="font-size:90%;">0.88</span></td>
<td id="S11.T4.1.6.6" class="ltx_td ltx_align_center"><span id="S11.T4.1.6.6.1" class="ltx_text" style="font-size:90%;">0.28</span></td>
<td id="S11.T4.1.6.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S11.T4.1.6.7.1" class="ltx_text" style="font-size:90%;">0.67</span></td>
</tr>
<tr id="S11.T4.1.7" class="ltx_tr">
<td id="S11.T4.1.7.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S11.T4.1.7.1.1" class="ltx_text" style="font-size:90%;">IDM (4 shot)</span></td>
<td id="S11.T4.1.7.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S11.T4.1.7.2.1" class="ltx_text" style="font-size:90%;">0.52</span></td>
<td id="S11.T4.1.7.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S11.T4.1.7.3.1" class="ltx_text" style="font-size:90%;">0.62</span></td>
<td id="S11.T4.1.7.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S11.T4.1.7.4.1" class="ltx_text" style="font-size:90%;">0.70</span></td>
<td id="S11.T4.1.7.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S11.T4.1.7.5.1" class="ltx_text" style="font-size:90%;">0.89</span></td>
<td id="S11.T4.1.7.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S11.T4.1.7.6.1" class="ltx_text" style="font-size:90%;">0.36</span></td>
<td id="S11.T4.1.7.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S11.T4.1.7.7.1" class="ltx_text" style="font-size:90%;">0.50</span></td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>The macro F1 scores for 5 prompt-based experiments from Method 1, based on 100 human-labeled examples. Values in bold represent the best performance in each aspect.</figcaption>
</figure>
<figure id="S11.T5" class="ltx_table">
<table id="S11.T5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S11.T5.1.1" class="ltx_tr">
<td id="S11.T5.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S11.T5.1.1.1.1" class="ltx_text" style="font-size:90%;">Methods</span></td>
<td id="S11.T5.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="S11.T5.1.1.2.1" class="ltx_text" style="font-size:90%;">Coherence &amp; Consistency &amp; Logicality</span></td>
<td id="S11.T5.1.1.3" class="ltx_td ltx_border_tt"></td>
<td id="S11.T5.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="S11.T5.1.1.4.1" class="ltx_text" style="font-size:90%;">Fluency &amp; Naturalness &amp; Readability</span></td>
</tr>
<tr id="S11.T5.1.2" class="ltx_tr">
<td id="S11.T5.1.2.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T5.1.2.1.1" class="ltx_text" style="font-size:90%;">Acc</span></td>
<td id="S11.T5.1.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T5.1.2.2.1" class="ltx_text" style="font-size:90%;">Precision</span></td>
<td id="S11.T5.1.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T5.1.2.3.1" class="ltx_text" style="font-size:90%;">Recall</span></td>
<td id="S11.T5.1.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T5.1.2.4.1" class="ltx_text" style="font-size:90%;">F1</span></td>
<td id="S11.T5.1.2.5" class="ltx_td ltx_border_t"></td>
<td id="S11.T5.1.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T5.1.2.6.1" class="ltx_text" style="font-size:90%;">Acc</span></td>
<td id="S11.T5.1.2.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T5.1.2.7.1" class="ltx_text" style="font-size:90%;">Precision</span></td>
<td id="S11.T5.1.2.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T5.1.2.8.1" class="ltx_text" style="font-size:90%;">Recall</span></td>
<td id="S11.T5.1.2.9" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S11.T5.1.2.9.1" class="ltx_text" style="font-size:90%;">F1</span></td>
</tr>
<tr id="S11.T5.1.3" class="ltx_tr">
<td id="S11.T5.1.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S11.T5.1.3.1.1" class="ltx_text" style="font-size:90%;">Method 1</span></td>
<td id="S11.T5.1.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T5.1.3.2.1" class="ltx_text" style="font-size:90%;">0.62</span></td>
<td id="S11.T5.1.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T5.1.3.3.1" class="ltx_text" style="font-size:90%;">0.62</span></td>
<td id="S11.T5.1.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T5.1.3.4.1" class="ltx_text" style="font-size:90%;">0.6</span></td>
<td id="S11.T5.1.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T5.1.3.5.1" class="ltx_text" style="font-size:90%;">0.6</span></td>
<td id="S11.T5.1.3.6" class="ltx_td"></td>
<td id="S11.T5.1.3.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T5.1.3.7.1" class="ltx_text" style="font-size:90%;">0.7</span></td>
<td id="S11.T5.1.3.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T5.1.3.8.1" class="ltx_text" style="font-size:90%;">0.7</span></td>
<td id="S11.T5.1.3.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S11.T5.1.3.9.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.81</span></td>
<td id="S11.T5.1.3.10" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S11.T5.1.3.10.1" class="ltx_text" style="font-size:90%;">0.67</span></td>
</tr>
<tr id="S11.T5.1.4" class="ltx_tr">
<td id="S11.T5.1.4.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r"><span id="S11.T5.1.4.1.1" class="ltx_text" style="font-size:90%;">Method 2</span></td>
<td id="S11.T5.1.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S11.T5.1.4.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.8</span></td>
<td id="S11.T5.1.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S11.T5.1.4.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.79</span></td>
<td id="S11.T5.1.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S11.T5.1.4.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.79</span></td>
<td id="S11.T5.1.4.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S11.T5.1.4.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.79</span></td>
<td id="S11.T5.1.4.6" class="ltx_td ltx_border_bb"></td>
<td id="S11.T5.1.4.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S11.T5.1.4.7.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.9</span></td>
<td id="S11.T5.1.4.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S11.T5.1.4.8.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.94</span></td>
<td id="S11.T5.1.4.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S11.T5.1.4.9.1" class="ltx_text" style="font-size:90%;">0.75</span></td>
<td id="S11.T5.1.4.10" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S11.T5.1.4.10.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.9</span></td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5: </span>Evaluation results (Method 1 vs. Method 2). Values in bold represent the best performance in each aspect.</figcaption>
</figure>
<div id="S11.SS2.p1" class="ltx_para">
<p id="S11.SS2.p1.3" class="ltx_p"><span id="S11.SS2.p1.3.1" class="ltx_text ltx_font_bold">Method 1: Self-Evaluation from Large LMs.</span> <cite class="ltx_cite ltx_citemacro_citet">Fu et&nbsp;al. (<a href="#bib.bib2" title="" class="ltx_ref">2023</a>)</cite> have demonstrated the emergent capabilities of large LMs in neural text evaluation, achieved through zero-shot instruction and in-context learning. The key idea is that, given the natural language description of desired task and evaluation aspects, large LMs can assess multi-dimensional text quality without any learning process. Motivated by this, we instruct FLAN-T5 XXL to evaluate 6 aspects of the machine-generated rationales. Similar to <cite class="ltx_cite ltx_citemacro_citet">Fu et&nbsp;al. (<a href="#bib.bib2" title="" class="ltx_ref">2023</a>)</cite>â€™s experiments, we investigate the performance of instruction-only (IST) prompting and instruction+demonstration (IDM) prompting.
Letâ€™s say <math id="S11.SS2.p1.1.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S11.SS2.p1.1.m1.1a"><mi id="S11.SS2.p1.1.m1.1.1" xref="S11.SS2.p1.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S11.SS2.p1.1.m1.1b"><ci id="S11.SS2.p1.1.m1.1.1.cmml" xref="S11.SS2.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S11.SS2.p1.1.m1.1c">q</annotation></semantics></math> and <math id="S11.SS2.p1.2.m2.1" class="ltx_Math" alttext="r^{\prime}" display="inline"><semantics id="S11.SS2.p1.2.m2.1a"><msup id="S11.SS2.p1.2.m2.1.1" xref="S11.SS2.p1.2.m2.1.1.cmml"><mi id="S11.SS2.p1.2.m2.1.1.2" xref="S11.SS2.p1.2.m2.1.1.2.cmml">r</mi><mo id="S11.SS2.p1.2.m2.1.1.3" xref="S11.SS2.p1.2.m2.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S11.SS2.p1.2.m2.1b"><apply id="S11.SS2.p1.2.m2.1.1.cmml" xref="S11.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S11.SS2.p1.2.m2.1.1.1.cmml" xref="S11.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S11.SS2.p1.2.m2.1.1.2.cmml" xref="S11.SS2.p1.2.m2.1.1.2">ğ‘Ÿ</ci><ci id="S11.SS2.p1.2.m2.1.1.3.cmml" xref="S11.SS2.p1.2.m2.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S11.SS2.p1.2.m2.1c">r^{\prime}</annotation></semantics></math> denote a question and a machine-generated rationale that is yet to be evaluated. <math id="S11.SS2.p1.3.m3.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S11.SS2.p1.3.m3.1a"><mi id="S11.SS2.p1.3.m3.1.1" xref="S11.SS2.p1.3.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S11.SS2.p1.3.m3.1b"><ci id="S11.SS2.p1.3.m3.1.1.cmml" xref="S11.SS2.p1.3.m3.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S11.SS2.p1.3.m3.1c">d</annotation></semantics></math> represents the aspect definition of our interest from Table <a href="#S3.T1" title="Table 1 â€£ 3. LM-guided Chain-of-Thought â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. A prompt template used for IST is:
</p>
</div>
<div id="S11.SS2.p2" class="ltx_para ltx_noindent">
<a name="method1" id="method1" class="ltx_anchor"><svg id="S11.SS2.p2.pic1" class="ltx_picture" height="133.22" overflow="visible" version="1.1" width="605.83"><g transform="translate(0,133.22) matrix(1 0 0 -1 0 0) translate(0,5.83)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g stroke="#808080" fill="#808080" color="#808080"><g stroke-opacity="0.01" fill-opacity="0.01"><path d="M 2.05 3.94 L 2.05 115.58 C 2.05 120.97 6.42 125.35 11.81 125.35 L 596.06 125.35 C 601.46 125.35 605.83 120.97 605.83 115.58 L 605.83 3.94 C 605.83 -1.46 601.46 -5.83 596.06 -5.83 L 11.81 -5.83 C 6.42 -5.83 2.05 -1.46 2.05 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.02" fill-opacity="0.02"><path d="M 2.52 3.94 L 2.52 115.58 C 2.52 120.71 6.68 124.87 11.81 124.87 L 596.06 124.87 C 601.19 124.87 605.35 120.71 605.35 115.58 L 605.35 3.94 C 605.35 -1.19 601.19 -5.35 596.06 -5.35 L 11.81 -5.35 C 6.68 -5.35 2.52 -1.19 2.52 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.04" fill-opacity="0.04"><path d="M 2.99 3.94 L 2.99 115.58 C 2.99 120.45 6.94 124.4 11.81 124.4 L 596.06 124.4 C 600.93 124.4 604.88 120.45 604.88 115.58 L 604.88 3.94 C 604.88 -0.93 600.93 -4.88 596.06 -4.88 L 11.81 -4.88 C 6.94 -4.88 2.99 -0.93 2.99 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.07" fill-opacity="0.07"><path d="M 3.46 3.94 L 3.46 115.58 C 3.46 120.19 7.2 123.93 11.81 123.93 L 596.06 123.93 C 600.67 123.93 604.41 120.19 604.41 115.58 L 604.41 3.94 C 604.41 -0.67 600.67 -4.41 596.06 -4.41 L 11.81 -4.41 C 7.2 -4.41 3.46 -0.67 3.46 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.11" fill-opacity="0.11"><path d="M 3.94 3.94 L 3.94 115.58 C 3.94 119.93 7.46 123.46 11.81 123.46 L 596.06 123.46 C 600.41 123.46 603.94 119.93 603.94 115.58 L 603.94 3.94 C 603.94 -0.41 600.41 -3.94 596.06 -3.94 L 11.81 -3.94 C 7.46 -3.94 3.94 -0.41 3.94 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.11" fill-opacity="0.11"><path d="M 4.41 3.94 L 4.41 115.58 C 4.41 119.67 7.72 122.98 11.81 122.98 L 596.06 122.98 C 600.15 122.98 603.46 119.67 603.46 115.58 L 603.46 3.94 C 603.46 -0.15 600.15 -3.46 596.06 -3.46 L 11.81 -3.46 C 7.72 -3.46 4.41 -0.15 4.41 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.07" fill-opacity="0.07"><path d="M 4.88 3.94 L 4.88 115.58 C 4.88 119.41 7.98 122.51 11.81 122.51 L 596.06 122.51 C 599.89 122.51 602.99 119.41 602.99 115.58 L 602.99 3.94 C 602.99 0.11 599.89 -2.99 596.06 -2.99 L 11.81 -2.99 C 7.98 -2.99 4.88 0.11 4.88 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.04" fill-opacity="0.04"><path d="M 5.35 3.94 L 5.35 115.58 C 5.35 119.15 8.25 122.04 11.81 122.04 L 596.06 122.04 C 599.63 122.04 602.52 119.15 602.52 115.58 L 602.52 3.94 C 602.52 0.37 599.63 -2.52 596.06 -2.52 L 11.81 -2.52 C 8.25 -2.52 5.35 0.37 5.35 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.02" fill-opacity="0.02"><path d="M 5.83 3.94 L 5.83 115.58 C 5.83 118.89 8.51 121.57 11.81 121.57 L 596.06 121.57 C 599.37 121.57 602.05 118.89 602.05 115.58 L 602.05 3.94 C 602.05 0.63 599.37 -2.05 596.06 -2.05 L 11.81 -2.05 C 8.51 -2.05 5.83 0.63 5.83 3.94 Z" style="stroke:none"></path></g><g stroke-opacity="0.01" fill-opacity="0.01"><path d="M 6.3 3.94 L 6.3 115.58 C 6.3 118.63 8.77 121.09 11.81 121.09 L 596.06 121.09 C 599.11 121.09 601.57 118.63 601.57 115.58 L 601.57 3.94 C 601.57 0.89 599.11 -1.57 596.06 -1.57 L 11.81 -1.57 C 8.77 -1.57 6.3 0.89 6.3 3.94 Z" style="stroke:none"></path></g></g><g fill="#F5F5F5" fill-opacity="1.0"><path d="M 0 5.91 L 0 121.49 C 0 124.75 2.64 127.39 5.91 127.39 L 594.09 127.39 C 597.36 127.39 600 124.75 600 121.49 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F5F5F5" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 121.49 C 1.97 123.66 3.73 125.42 5.91 125.42 L 594.09 125.42 C 596.27 125.42 598.03 123.66 598.03 121.49 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="556.69" height="99.83" transform="matrix(1 0 0 -1 0 15.22)" overflow="visible" color="#000000">
<span id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3" class="ltx_p"><span id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3" class="ltx_text" style="font-size:90%;">Answer the question based on the provided information.

<br class="ltx_break">Question: Can the given reasoning <math id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1b"><mi id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1c"><ci id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S11.SS2.p2.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1d">d</annotation></semantics></math> ? (a) Yes. (b) No.

<br class="ltx_break">
<br class="ltx_break"><span id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.1" class="ltx_text ltx_font_bold">Information</span>:

<br class="ltx_break">Question: <math id="S11.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S11.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b"><mi id="S11.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="S11.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S11.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c"><ci id="S11.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S11.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S11.SS2.p2.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1d">q</annotation></semantics></math>

<br class="ltx_break">Reasoning: <math id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1" class="ltx_Math" alttext="r^{\prime}" display="inline"><semantics id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1b"><msup id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1" xref="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml"><mi id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2" xref="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.cmml">r</mi><mo id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3" xref="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1c"><apply id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml" xref="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1"><csymbol cd="ambiguous" id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.1.cmml" xref="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1">superscript</csymbol><ci id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2.cmml" xref="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.2">ğ‘Ÿ</ci><ci id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3.cmml" xref="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S11.SS2.p2.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1d">r^{\prime}</annotation></semantics></math>

<br class="ltx_break">Answer :</span></span>
</span></foreignObject></g></g></svg></a>
</div>
<div id="S11.SS2.p3" class="ltx_para ltx_noindent">
<p id="S11.SS2.p3.1" class="ltx_p">A prompt template for IDM is equivalent to IST but with the inclusion of a few task demonstrations. The number of demonstrations ranges from 1 to 4. We use the same demonstrations included in the human annotation instruction (Â§<a href="#S11.SS1" title="11.1. Human Annotation for Rationale Quality Measurement â€£ 11. Appendices â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11.1</span></a>). Lastly, we evaluate IST in combination with SC decoding, which involves sampling the prediction multiple times (n = 10) and taking the mode as a final prediction. To ensure that the rationale evaluation of FLAN-T5 XXL aligns closely with human annotation, we compute the macro F1 scores for 5 prompt-based experiments using 100 human-labeled examples (Table <a href="#S11.T4" title="Table 4 â€£ 11.2. Automatic Measurement for Rationale Quality â€£ 11. Appendices â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). In most cases except for fluency, IST prompting demonstrates the highest performance.</p>
</div>
<div id="S11.SS2.p4" class="ltx_para ltx_noindent">
<p id="S11.SS2.p4.1" class="ltx_p"><span id="S11.SS2.p4.1.1" class="ltx_text ltx_font_bold">Method 2: Supervised Training with Human-Annotated Data.</span>
Here we train a logistic regression classifier using 100 ground truth data from Â§<a href="#S11.SS1" title="11.1. Human Annotation for Rationale Quality Measurement â€£ 11. Appendices â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11.1</span></a>. This can be done by converting input data into TF-IDF vectors. Due to a small training data size, we resort to training two independent binary classifiers instead of having 6 models for each aspect type. While the first model is to predict if a given reasoning is logical, coherent, and consistent, the second model focuses on predicting whether the reasoning is fluent, natural, and readable. If at least one of the components is not satisfied, we consider it a negative label. The final label distribution is as follows: logicality &amp; consistency &amp; coherence (0: 60 vs. 1: 40), and fluency &amp; naturalness &amp; readability (0: 20 vs. 1: 80). We use 90% of the dataset (n=90) for training and the remaining 10% (n=10) for evaluation.</p>
</div>
<div id="S11.SS2.p5" class="ltx_para ltx_noindent">
<p id="S11.SS2.p5.1" class="ltx_p"><span id="S11.SS2.p5.1.1" class="ltx_text ltx_font_bold">Method 1 vs. Method 2.</span> We attempt to assess which one is more suitable for providing rewards for RL. For a fair comparison, we use the same evaluation data that was used in Method 2. Since Method 1 has 6 aspect categories, we obtain individual results using the best-performing approach and group them into two as we did for Method 2. Table <a href="#S11.T5" title="Table 5 â€£ 11.2. Automatic Measurement for Rationale Quality â€£ 11. Appendices â€£ Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> reports the accuracy, macro precision, macro recall, and macro F1 for Method 1 and Method 2. The results indicate that, although models from Method 2 are trained on a relatively small dataset, Method 2 is more aligned with human judgments compared to Method 1. Additionally, inference time using Method 2 is significantly faster than Method 1, making it easier to retrieve rewards in the RL setting. As a result, we use Method 2 for all our experiments.</p>
</div>
</section>
<section id="S11.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_font_bold ltx_title_subsection" style="font-size:110%;">11.3.&nbsp;&nbsp;&nbsp;Training Configuration</h3>

<div id="S11.SS3.p1" class="ltx_para">
<p id="S11.SS3.p1.1" class="ltx_p">We provide a comprehensive description of the hyperparameters utilized in the model training process.</p>
</div>
<div id="S11.SS3.p2" class="ltx_para ltx_noindent">
<p id="S11.SS3.p2.1" class="ltx_p"><span id="S11.SS3.p2.1.1" class="ltx_text ltx_font_bold">Rationale Distillation.</span>
For rationale generation from the teacher model, we randomly sampled 15K examples from each of the two datasets, resulting in a total of 30K examples. After filtering invalid rationales, the dataset was reduced to a total of 23K examples. 90% of data was used for training, and the remaining 10% was used for validation. For training, we used 8 NVIDIA Tesla V100 GPUs with 16GB configurations. Hyperparameters for training are as follows: 3e-3 for learning rates, 5 epochs, 64 batch size.</p>
</div>
<div id="S11.SS3.p3" class="ltx_para ltx_noindent">
<p id="S11.SS3.p3.1" class="ltx_p"><span id="S11.SS3.p3.1.1" class="ltx_text ltx_font_bold">RL for Rationale Refinement.</span> For RL, we utilized the Huggingfaceâ€™s TRL<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://huggingface.co/docs/trl/index</span></span></span> library that provides a set of tools to train transformer LMs with RL. Instead of using the same examples used for the rationale distillation, we selectively chose 5000 examples that FLAN-T5 XXL failed to answer the question correctly. The reason behind this choice was to increase the modelâ€™s exposure to challenging questions, thus increasing the likelihood of receiving more learning signals. We used 90% of data for training and the remaining 10% for validation. Training hyperparameters are as follows: 1.4e-5 for learning rates, 1 epoch, 16 batch size. For generation configurations, we set top_k as 0.0, top_p as 1.0, and enabled sampling.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2404.03413" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2404.03414" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2404.03414">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2404.03414" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2404.03415" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun May  5 17:59:36 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>