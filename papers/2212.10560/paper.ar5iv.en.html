<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2212.10560] ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions</title><meta property="og:description" content="Large “instruction-tuned” language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks.
Nevertheless, they depend heavily on human-written ins…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2212.10560">

<!--Generated on Fri Mar  1 10:10:10 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">

 ACL 2023
<br class="ltx_break">
<span id="id17.id1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span>: Aligning Language Models 
<br class="ltx_break">with Self-Generated Instructions</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yizhong Wang<sup id="id1.1.1" class="ltx_sup"><math id="id1.1.1.m1.1" class="ltx_Math" alttext="\clubsuit" display="inline"><semantics id="id1.1.1.m1.1a"><mi mathvariant="normal" id="id1.1.1.m1.1.1" xref="id1.1.1.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="id1.1.1.m1.1b"><ci id="id1.1.1.m1.1.1.cmml" xref="id1.1.1.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="id1.1.1.m1.1c">\clubsuit</annotation></semantics></math></sup>    
Yeganeh Kordi<sup id="id2.2.2" class="ltx_sup"><math id="id2.2.2.m1.1" class="ltx_Math" alttext="\diamondsuit" display="inline"><semantics id="id2.2.2.m1.1a"><mi mathvariant="normal" id="id2.2.2.m1.1.1" xref="id2.2.2.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="id2.2.2.m1.1b"><ci id="id2.2.2.m1.1.1.cmml" xref="id2.2.2.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="id2.2.2.m1.1c">\diamondsuit</annotation></semantics></math></sup>    
Swaroop Mishra<sup id="id3.3.3" class="ltx_sup"><math id="id3.3.3.m1.1" class="ltx_Math" alttext="\heartsuit" display="inline"><semantics id="id3.3.3.m1.1a"><mi mathvariant="normal" id="id3.3.3.m1.1.1" xref="id3.3.3.m1.1.1.cmml">♡</mi><annotation-xml encoding="MathML-Content" id="id3.3.3.m1.1b"><ci id="id3.3.3.m1.1.1.cmml" xref="id3.3.3.m1.1.1">♡</ci></annotation-xml><annotation encoding="application/x-tex" id="id3.3.3.m1.1c">\heartsuit</annotation></semantics></math></sup>    
<span id="id6.6.6" class="ltx_text ltx_font_bold">Alisa Liu<sup id="id4.4.4.1" class="ltx_sup"><math id="id4.4.4.1.m1.1" class="ltx_Math" alttext="\clubsuit" display="inline"><semantics id="id4.4.4.1.m1.1a"><mi mathvariant="normal" id="id4.4.4.1.m1.1.1" xref="id4.4.4.1.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="id4.4.4.1.m1.1b"><ci id="id4.4.4.1.m1.1.1.cmml" xref="id4.4.4.1.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="id4.4.4.1.m1.1c">\clubsuit</annotation></semantics></math></sup>
<br class="ltx_break">Noah A. Smith<sup id="id5.5.5.2" class="ltx_sup"><math id="id5.5.5.2.m1.1" class="ltx_Math" alttext="\clubsuit" display="inline"><semantics id="id5.5.5.2.m1.1a"><mi mathvariant="normal" id="id5.5.5.2.m1.1.1" xref="id5.5.5.2.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="id5.5.5.2.m1.1b"><ci id="id5.5.5.2.m1.1.1.cmml" xref="id5.5.5.2.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="id5.5.5.2.m1.1c">\clubsuit</annotation></semantics></math></sup><sup id="id6.6.6.3" class="ltx_sup"><math id="id6.6.6.3.m1.1" class="ltx_Math" alttext="+" display="inline"><semantics id="id6.6.6.3.m1.1a"><mo id="id6.6.6.3.m1.1.1" xref="id6.6.6.3.m1.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="id6.6.6.3.m1.1b"><plus id="id6.6.6.3.m1.1.1.cmml" xref="id6.6.6.3.m1.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="id6.6.6.3.m1.1c">+</annotation></semantics></math></sup></span>    
<span id="id7.7.7" class="ltx_text ltx_font_bold">Daniel Khashabi<sup id="id7.7.7.1" class="ltx_sup"><math id="id7.7.7.1.m1.1" class="ltx_Math" alttext="\spadesuit" display="inline"><semantics id="id7.7.7.1.m1.1a"><mi mathvariant="normal" id="id7.7.7.1.m1.1.1" xref="id7.7.7.1.m1.1.1.cmml">♠</mi><annotation-xml encoding="MathML-Content" id="id7.7.7.1.m1.1b"><ci id="id7.7.7.1.m1.1.1.cmml" xref="id7.7.7.1.m1.1.1">♠</ci></annotation-xml><annotation encoding="application/x-tex" id="id7.7.7.1.m1.1c">\spadesuit</annotation></semantics></math></sup></span>     
<span id="id10.10.10" class="ltx_text ltx_font_bold">Hannaneh Hajishirzi<sup id="id8.8.8.1" class="ltx_sup"><math id="id8.8.8.1.m1.1" class="ltx_Math" alttext="\clubsuit" display="inline"><semantics id="id8.8.8.1.m1.1a"><mi mathvariant="normal" id="id8.8.8.1.m1.1.1" xref="id8.8.8.1.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="id8.8.8.1.m1.1b"><ci id="id8.8.8.1.m1.1.1.cmml" xref="id8.8.8.1.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="id8.8.8.1.m1.1c">\clubsuit</annotation></semantics></math></sup><sup id="id9.9.9.2" class="ltx_sup"><math id="id9.9.9.2.m1.1" class="ltx_Math" alttext="+" display="inline"><semantics id="id9.9.9.2.m1.1a"><mo id="id9.9.9.2.m1.1.1" xref="id9.9.9.2.m1.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="id9.9.9.2.m1.1b"><plus id="id9.9.9.2.m1.1.1.cmml" xref="id9.9.9.2.m1.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="id9.9.9.2.m1.1c">+</annotation></semantics></math></sup>
<br class="ltx_break"><sup id="id10.10.10.3" class="ltx_sup"><math id="id10.10.10.3.m1.1" class="ltx_Math" alttext="\clubsuit" display="inline"><semantics id="id10.10.10.3.m1.1a"><mi mathvariant="normal" id="id10.10.10.3.m1.1.1" xref="id10.10.10.3.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="id10.10.10.3.m1.1b"><ci id="id10.10.10.3.m1.1.1.cmml" xref="id10.10.10.3.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="id10.10.10.3.m1.1c">\clubsuit</annotation></semantics></math></sup></span>University of Washington  
<sup id="id11.11.11" class="ltx_sup"><math id="id11.11.11.m1.1" class="ltx_Math" alttext="\diamondsuit" display="inline"><semantics id="id11.11.11.m1.1a"><mi mathvariant="normal" id="id11.11.11.m1.1.1" xref="id11.11.11.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="id11.11.11.m1.1b"><ci id="id11.11.11.m1.1.1.cmml" xref="id11.11.11.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="id11.11.11.m1.1c">\diamondsuit</annotation></semantics></math></sup>Tehran Polytechnic  
<sup id="id12.12.12" class="ltx_sup"><math id="id12.12.12.m1.1" class="ltx_Math" alttext="\heartsuit" display="inline"><semantics id="id12.12.12.m1.1a"><mi mathvariant="normal" id="id12.12.12.m1.1.1" xref="id12.12.12.m1.1.1.cmml">♡</mi><annotation-xml encoding="MathML-Content" id="id12.12.12.m1.1b"><ci id="id12.12.12.m1.1.1.cmml" xref="id12.12.12.m1.1.1">♡</ci></annotation-xml><annotation encoding="application/x-tex" id="id12.12.12.m1.1c">\heartsuit</annotation></semantics></math></sup>Arizona State University 
<br class="ltx_break"><sup id="id13.13.13" class="ltx_sup"><math id="id13.13.13.m1.1" class="ltx_Math" alttext="\spadesuit" display="inline"><semantics id="id13.13.13.m1.1a"><mi mathvariant="normal" id="id13.13.13.m1.1.1" xref="id13.13.13.m1.1.1.cmml">♠</mi><annotation-xml encoding="MathML-Content" id="id13.13.13.m1.1b"><ci id="id13.13.13.m1.1.1.cmml" xref="id13.13.13.m1.1.1">♠</ci></annotation-xml><annotation encoding="application/x-tex" id="id13.13.13.m1.1c">\spadesuit</annotation></semantics></math></sup>Johns Hopkins University  <sup id="id14.14.14" class="ltx_sup"><math id="id14.14.14.m1.1" class="ltx_Math" alttext="+" display="inline"><semantics id="id14.14.14.m1.1a"><mo id="id14.14.14.m1.1.1" xref="id14.14.14.m1.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="id14.14.14.m1.1b"><plus id="id14.14.14.m1.1.1.cmml" xref="id14.14.14.m1.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="id14.14.14.m1.1c">+</annotation></semantics></math></sup>Allen Institute for AI 
<br class="ltx_break"> <span id="id18.15.id1" class="ltx_text ltx_font_typewriter">yizhongw@cs.washington.edu</span>  
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id16.2" class="ltx_p">Large “instruction-tuned” language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks.
Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model.
We introduce <span id="id16.2.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span>, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations.
Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model.
Applying our method to the vanilla <span id="id16.2.2" class="ltx_text ltx_font_smallcaps">GPT3</span>, we demonstrate a 33% absolute improvement over the original model on <span id="id16.2.3" class="ltx_text ltx_font_smallcaps">Super-NaturalInstructions</span>, on par with the performance of <math id="id15.1.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{001}}" display="inline"><semantics id="id15.1.m1.1a"><msub id="id15.1.m1.1.1" xref="id15.1.m1.1.1.cmml"><mtext id="id15.1.m1.1.1.2" xref="id15.1.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="id15.1.m1.1.1.3" xref="id15.1.m1.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="id15.1.m1.1b"><apply id="id15.1.m1.1.1.cmml" xref="id15.1.m1.1.1"><csymbol cd="ambiguous" id="id15.1.m1.1.1.1.cmml" xref="id15.1.m1.1.1">subscript</csymbol><ci id="id15.1.m1.1.1.2a.cmml" xref="id15.1.m1.1.1.2"><mtext id="id15.1.m1.1.1.2.cmml" xref="id15.1.m1.1.1.2">InstructGPT</mtext></ci><ci id="id15.1.m1.1.1.3a.cmml" xref="id15.1.m1.1.1.3"><mtext mathsize="70%" id="id15.1.m1.1.1.3.cmml" xref="id15.1.m1.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id15.1.m1.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>,<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Unless otherwise specified, our comparisons are with the <span id="footnote1.1" class="ltx_text ltx_font_typewriter">text-davinci-001</span> engine.
We focus on this engine since it is the closest to our experimental setup: supervised finetuning with human demonstrations. The newer engines are more powerful, though they use more data (e.g., code completion or latest user queries) or algorithms (e.g., PPO) that are difficult to compare with.</span></span></span> which was trained with private user data and human annotations.
For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with <span id="id16.2.4" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> outperforms using existing public instruction datasets by a large margin, leaving only a 5% absolute gap behind <math id="id16.2.m2.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{001}}" display="inline"><semantics id="id16.2.m2.1a"><msub id="id16.2.m2.1.1" xref="id16.2.m2.1.1.cmml"><mtext id="id16.2.m2.1.1.2" xref="id16.2.m2.1.1.2a.cmml">InstructGPT</mtext><mtext id="id16.2.m2.1.1.3" xref="id16.2.m2.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="id16.2.m2.1b"><apply id="id16.2.m2.1.1.cmml" xref="id16.2.m2.1.1"><csymbol cd="ambiguous" id="id16.2.m2.1.1.1.cmml" xref="id16.2.m2.1.1">subscript</csymbol><ci id="id16.2.m2.1.1.2a.cmml" xref="id16.2.m2.1.1.2"><mtext id="id16.2.m2.1.1.2.cmml" xref="id16.2.m2.1.1.2">InstructGPT</mtext></ci><ci id="id16.2.m2.1.1.3a.cmml" xref="id16.2.m2.1.1.3"><mtext mathsize="70%" id="id16.2.m2.1.1.3.cmml" xref="id16.2.m2.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id16.2.m2.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>.
<span id="id16.2.5" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> provides an almost annotation-free method for aligning pretrained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Code and data are available at <a target="_blank" href="https://github.com/yizhongw/self-instruct" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/yizhongw/self-instruct</a>
</span></span></span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure"><img src="/html/2212.10560/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="452" height="695" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
Selected tasks from the generated instruction data using vanilla <span id="S1.F1.2.1" class="ltx_text ltx_font_smallcaps">GPT3</span>. Some texts are reformatted for presentation. See <a href="#A3.T10" title="Table 10 ‣ Appendix C Task and Instance Examples from the Generated Instruction Data ‣ B.3 Example Predictions from GPT3_&quot;Self-Inst&quot; ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;10</span></a> for more examples.
</figcaption>
</figure>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2212.10560/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="315" height="138" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>
A high-level overview of <span id="S1.F2.3.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span>.
The process starts with a small seed set of tasks as the task pool.
Random tasks are sampled from the task pool, and used to prompt an off-the-shelf LM to generate both new instructions and corresponding instances,
followed by filtering low-quality or similar generations, and then added back to the initial repository of tasks. The resulting data can be used for the instruction tuning of the language model itself later to follow instructions better. Tasks shown in the figure are generated by <span id="S1.F2.4.2" class="ltx_text ltx_font_smallcaps">GPT3</span>.
</figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The recent NLP literature has witnessed a tremendous amount of activity in building models that can follow natural language instructions&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Mishra et&nbsp;al., <a href="#bib.bib22" title="" class="ltx_ref">2022</a>; Wei et&nbsp;al., <a href="#bib.bib35" title="" class="ltx_ref">2022</a>; Sanh et&nbsp;al., <a href="#bib.bib27" title="" class="ltx_ref">2022</a>; Wang et&nbsp;al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>; Ouyang et&nbsp;al., <a href="#bib.bib23" title="" class="ltx_ref">2022</a>; Chung et&nbsp;al., <a href="#bib.bib4" title="" class="ltx_ref">2022</a>, i.a.)</cite>.
These developments are powered by two key components: large pretrained language models (LM) and human-written instruction data (e.g.,
<span id="S1.p1.1.1" class="ltx_text ltx_font_smallcaps">PromptSource</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Bach et&nbsp;al., <a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite> and <span id="S1.p1.1.2" class="ltx_text ltx_font_smallcaps">Super-NaturalInstructions</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>, <span id="S1.p1.1.3.1" class="ltx_text ltx_font_smallcaps">SuperNI</span> for short)</cite>).
However, collecting such instruction data is costly and often suffers limited diversity given that most human generations tend to be popular NLP tasks, falling short of covering a true variety of tasks and different ways to describe them.
Continuing to improve the quality and coverage of instruction-tuned models
necessitates the development of alternative approaches for supervising the instruction tuning process.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this work, we introduce <span id="S1.p2.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span>, a semi-automated process for instruction-tuning a pretrained LM using instructional signals from the model itself.
The overall process is an iterative bootstrapping algorithm (see <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure&nbsp;2</span></a>), which starts off with a limited (e.g., 175 in our study) seed set of manually-written tasks that are used to guide the overall generation.
In the first phase, the model is prompted to generate instructions for new tasks.
This step leverages the existing collection of instructions to create
more broad-coverage instructions that define (often new) tasks.
Given the newly-generated set of instructions, the framework also creates input-output instances for them, which can be later used for supervising the instruction tuning.
Finally, various heuristics are used to automatically filter low-quality or repeated instructions, before adding the remaining valid tasks to the task pool.
This process can be repeated for many iterations until reaching a large number of tasks.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.6" class="ltx_p">To evaluate <span id="S1.p3.6.5" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> empirically, we run this framework on <span id="S1.p3.6.6" class="ltx_text ltx_font_smallcaps">GPT3</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Brown et&nbsp;al. (<a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite>, which is a vanilla LM (§<a href="#S3" title="3 Self-Instruct Data from GPT3 ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).
The iterative <span id="S1.p3.6.7" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> process on this model leads to about 52k instructions, paired with about 82K instance inputs and target outputs.
We observe that the resulting data provides a diverse range of creative tasks, as is demonstrated by examples in <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure&nbsp;1</span></a>. These generated tasks deviate from the distribution of typical NLP tasks, and also have fairly small overlap with the seed tasks (§<a href="#S3.SS2" title="3.2 Diversity ‣ 3 Self-Instruct Data from GPT3 ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>).
On this resulting data, we build <span id="S1.p3.1.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S1.p3.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S1.p3.1.1.m1.1a"><msub id="S1.p3.1.1.m1.1.1" xref="S1.p3.1.1.m1.1.1.cmml"><mi id="S1.p3.1.1.m1.1.1a" xref="S1.p3.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S1.p3.1.1.m1.1.1.1" xref="S1.p3.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p3.1.1.m1.1b"><apply id="S1.p3.1.1.m1.1.1.cmml" xref="S1.p3.1.1.m1.1.1"><ci id="S1.p3.1.1.m1.1.1.1a.cmml" xref="S1.p3.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S1.p3.1.1.m1.1.1.1.cmml" xref="S1.p3.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> by finetuning <span id="S1.p3.6.8" class="ltx_text ltx_font_smallcaps">GPT3</span> (i.e., the same model used for generating the instruction data).
We evaluate <span id="S1.p3.2.2" class="ltx_text ltx_font_smallcaps">GPT3<math id="S1.p3.2.2.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S1.p3.2.2.m1.1a"><msub id="S1.p3.2.2.m1.1.1" xref="S1.p3.2.2.m1.1.1.cmml"><mi id="S1.p3.2.2.m1.1.1a" xref="S1.p3.2.2.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S1.p3.2.2.m1.1.1.1" xref="S1.p3.2.2.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p3.2.2.m1.1b"><apply id="S1.p3.2.2.m1.1.1.cmml" xref="S1.p3.2.2.m1.1.1"><ci id="S1.p3.2.2.m1.1.1.1a.cmml" xref="S1.p3.2.2.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S1.p3.2.2.m1.1.1.1.cmml" xref="S1.p3.2.2.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.2.2.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> in comparison to various other models on both typical NLP tasks included in <span id="S1.p3.6.9" class="ltx_text ltx_font_smallcaps">SuperNI</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>, and a set of new instructions that are created for novel usage of instruction-following models (§<a href="#S4" title="4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>).
The results indicate that
<span id="S1.p3.3.3" class="ltx_text ltx_font_smallcaps">GPT3<math id="S1.p3.3.3.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S1.p3.3.3.m1.1a"><msub id="S1.p3.3.3.m1.1.1" xref="S1.p3.3.3.m1.1.1.cmml"><mi id="S1.p3.3.3.m1.1.1a" xref="S1.p3.3.3.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S1.p3.3.3.m1.1.1.1" xref="S1.p3.3.3.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p3.3.3.m1.1b"><apply id="S1.p3.3.3.m1.1.1.cmml" xref="S1.p3.3.3.m1.1.1"><ci id="S1.p3.3.3.m1.1.1.1a.cmml" xref="S1.p3.3.3.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S1.p3.3.3.m1.1.1.1.cmml" xref="S1.p3.3.3.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.3.3.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> outperforms <span id="S1.p3.6.10" class="ltx_text ltx_font_smallcaps">GPT3</span> (the original model) by a large margin (+33.1%) and nearly matches the performance of <math id="S1.p3.4.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{001}}" display="inline"><semantics id="S1.p3.4.m1.1a"><msub id="S1.p3.4.m1.1.1" xref="S1.p3.4.m1.1.1.cmml"><mtext id="S1.p3.4.m1.1.1.2" xref="S1.p3.4.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="S1.p3.4.m1.1.1.3" xref="S1.p3.4.m1.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p3.4.m1.1b"><apply id="S1.p3.4.m1.1.1.cmml" xref="S1.p3.4.m1.1.1"><csymbol cd="ambiguous" id="S1.p3.4.m1.1.1.1.cmml" xref="S1.p3.4.m1.1.1">subscript</csymbol><ci id="S1.p3.4.m1.1.1.2a.cmml" xref="S1.p3.4.m1.1.1.2"><mtext id="S1.p3.4.m1.1.1.2.cmml" xref="S1.p3.4.m1.1.1.2">InstructGPT</mtext></ci><ci id="S1.p3.4.m1.1.1.3a.cmml" xref="S1.p3.4.m1.1.1.3"><mtext mathsize="70%" id="S1.p3.4.m1.1.1.3.cmml" xref="S1.p3.4.m1.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.4.m1.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>. Moreover, our human evaluation on the newly-created instruction set shows that <span id="S1.p3.5.4" class="ltx_text ltx_font_smallcaps">GPT3<math id="S1.p3.5.4.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S1.p3.5.4.m1.1a"><msub id="S1.p3.5.4.m1.1.1" xref="S1.p3.5.4.m1.1.1.cmml"><mi id="S1.p3.5.4.m1.1.1a" xref="S1.p3.5.4.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S1.p3.5.4.m1.1.1.1" xref="S1.p3.5.4.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p3.5.4.m1.1b"><apply id="S1.p3.5.4.m1.1.1.cmml" xref="S1.p3.5.4.m1.1.1"><ci id="S1.p3.5.4.m1.1.1.1a.cmml" xref="S1.p3.5.4.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S1.p3.5.4.m1.1.1.1.cmml" xref="S1.p3.5.4.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.5.4.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> demonstrates a broad range of instruction following ability, outperforming models trained on other publicly available instruction datasets and leaving only a 5% gap behind <math id="S1.p3.6.m2.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{001}}" display="inline"><semantics id="S1.p3.6.m2.1a"><msub id="S1.p3.6.m2.1.1" xref="S1.p3.6.m2.1.1.cmml"><mtext id="S1.p3.6.m2.1.1.2" xref="S1.p3.6.m2.1.1.2a.cmml">InstructGPT</mtext><mtext id="S1.p3.6.m2.1.1.3" xref="S1.p3.6.m2.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p3.6.m2.1b"><apply id="S1.p3.6.m2.1.1.cmml" xref="S1.p3.6.m2.1.1"><csymbol cd="ambiguous" id="S1.p3.6.m2.1.1.1.cmml" xref="S1.p3.6.m2.1.1">subscript</csymbol><ci id="S1.p3.6.m2.1.1.2a.cmml" xref="S1.p3.6.m2.1.1.2"><mtext id="S1.p3.6.m2.1.1.2.cmml" xref="S1.p3.6.m2.1.1.2">InstructGPT</mtext></ci><ci id="S1.p3.6.m2.1.1.3a.cmml" xref="S1.p3.6.m2.1.1.3"><mtext mathsize="70%" id="S1.p3.6.m2.1.1.3.cmml" xref="S1.p3.6.m2.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.6.m2.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In summary, our contributions are: (1) we introduce <span id="S1.p4.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span>, a method for inducing instruction following capabilities with minimal human-labeled data; (2) we demonstrate its effectiveness via extensive instruction-tuning experiments; and (3) we release a large synthetic dataset of 52K instructions and a set of manually-written novel tasks for building and evaluating future instruction-following models.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Method</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Annotating large-scale instruction data can be challenging for humans because it requires 1) creativity to come up with novel tasks and 2)
expertise for writing the solutions to each task.
Here, we detail our process for <span id="S2.p1.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span>, which refers to the pipeline of generating tasks with a <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">vanilla pretrained language model</span> itself, filtering the generated data, and then
conducting
instruction tuning with this generated data in order to align the LM to follow instructions better. This pipeline is depicted in <a href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure&nbsp;2</span></a>.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Defining Instruction Data</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.9" class="ltx_p">The instruction data we want to generate contains a set of instructions <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="\{I_{t}\}" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mrow id="S2.SS1.p1.1.m1.1.1.1" xref="S2.SS1.p1.1.m1.1.1.2.cmml"><mo stretchy="false" id="S2.SS1.p1.1.m1.1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.2.cmml">{</mo><msub id="S2.SS1.p1.1.m1.1.1.1.1" xref="S2.SS1.p1.1.m1.1.1.1.1.cmml"><mi id="S2.SS1.p1.1.m1.1.1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.1.1.2.cmml">I</mi><mi id="S2.SS1.p1.1.m1.1.1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.SS1.p1.1.m1.1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><set id="S2.SS1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.1"><apply id="S2.SS1.p1.1.m1.1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.1.m1.1.1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1.2">𝐼</ci><ci id="S2.SS1.p1.1.m1.1.1.1.1.3.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1.3">𝑡</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">\{I_{t}\}</annotation></semantics></math>, each of which defines a task <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">t</annotation></semantics></math> in natural language. Task <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">t</annotation></semantics></math> has <math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="n_{t}\geq 1" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><mrow id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml"><msub id="S2.SS1.p1.4.m4.1.1.2" xref="S2.SS1.p1.4.m4.1.1.2.cmml"><mi id="S2.SS1.p1.4.m4.1.1.2.2" xref="S2.SS1.p1.4.m4.1.1.2.2.cmml">n</mi><mi id="S2.SS1.p1.4.m4.1.1.2.3" xref="S2.SS1.p1.4.m4.1.1.2.3.cmml">t</mi></msub><mo id="S2.SS1.p1.4.m4.1.1.1" xref="S2.SS1.p1.4.m4.1.1.1.cmml">≥</mo><mn id="S2.SS1.p1.4.m4.1.1.3" xref="S2.SS1.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><apply id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1"><geq id="S2.SS1.p1.4.m4.1.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1.1"></geq><apply id="S2.SS1.p1.4.m4.1.1.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p1.4.m4.1.1.2.1.cmml" xref="S2.SS1.p1.4.m4.1.1.2">subscript</csymbol><ci id="S2.SS1.p1.4.m4.1.1.2.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2.2">𝑛</ci><ci id="S2.SS1.p1.4.m4.1.1.2.3.cmml" xref="S2.SS1.p1.4.m4.1.1.2.3">𝑡</ci></apply><cn type="integer" id="S2.SS1.p1.4.m4.1.1.3.cmml" xref="S2.SS1.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">n_{t}\geq 1</annotation></semantics></math> input-output instances <math id="S2.SS1.p1.5.m5.5" class="ltx_Math" alttext="\{(X_{t,i},Y_{t,i})\}_{i=1}^{n_{t}}" display="inline"><semantics id="S2.SS1.p1.5.m5.5a"><msubsup id="S2.SS1.p1.5.m5.5.5" xref="S2.SS1.p1.5.m5.5.5.cmml"><mrow id="S2.SS1.p1.5.m5.5.5.1.1.1" xref="S2.SS1.p1.5.m5.5.5.1.1.2.cmml"><mo stretchy="false" id="S2.SS1.p1.5.m5.5.5.1.1.1.2" xref="S2.SS1.p1.5.m5.5.5.1.1.2.cmml">{</mo><mrow id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.3" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.3.cmml">(</mo><msub id="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1.2" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1.2.cmml">X</mi><mrow id="S2.SS1.p1.5.m5.2.2.2.4" xref="S2.SS1.p1.5.m5.2.2.2.3.cmml"><mi id="S2.SS1.p1.5.m5.1.1.1.1" xref="S2.SS1.p1.5.m5.1.1.1.1.cmml">t</mi><mo id="S2.SS1.p1.5.m5.2.2.2.4.1" xref="S2.SS1.p1.5.m5.2.2.2.3.cmml">,</mo><mi id="S2.SS1.p1.5.m5.2.2.2.2" xref="S2.SS1.p1.5.m5.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.4" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.3.cmml">,</mo><msub id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2.cmml"><mi id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2.2" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2.2.cmml">Y</mi><mrow id="S2.SS1.p1.5.m5.4.4.2.4" xref="S2.SS1.p1.5.m5.4.4.2.3.cmml"><mi id="S2.SS1.p1.5.m5.3.3.1.1" xref="S2.SS1.p1.5.m5.3.3.1.1.cmml">t</mi><mo id="S2.SS1.p1.5.m5.4.4.2.4.1" xref="S2.SS1.p1.5.m5.4.4.2.3.cmml">,</mo><mi id="S2.SS1.p1.5.m5.4.4.2.2" xref="S2.SS1.p1.5.m5.4.4.2.2.cmml">i</mi></mrow></msub><mo stretchy="false" id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.5" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S2.SS1.p1.5.m5.5.5.1.1.1.3" xref="S2.SS1.p1.5.m5.5.5.1.1.2.cmml">}</mo></mrow><mrow id="S2.SS1.p1.5.m5.5.5.1.3" xref="S2.SS1.p1.5.m5.5.5.1.3.cmml"><mi id="S2.SS1.p1.5.m5.5.5.1.3.2" xref="S2.SS1.p1.5.m5.5.5.1.3.2.cmml">i</mi><mo id="S2.SS1.p1.5.m5.5.5.1.3.1" xref="S2.SS1.p1.5.m5.5.5.1.3.1.cmml">=</mo><mn id="S2.SS1.p1.5.m5.5.5.1.3.3" xref="S2.SS1.p1.5.m5.5.5.1.3.3.cmml">1</mn></mrow><msub id="S2.SS1.p1.5.m5.5.5.3" xref="S2.SS1.p1.5.m5.5.5.3.cmml"><mi id="S2.SS1.p1.5.m5.5.5.3.2" xref="S2.SS1.p1.5.m5.5.5.3.2.cmml">n</mi><mi id="S2.SS1.p1.5.m5.5.5.3.3" xref="S2.SS1.p1.5.m5.5.5.3.3.cmml">t</mi></msub></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.5b"><apply id="S2.SS1.p1.5.m5.5.5.cmml" xref="S2.SS1.p1.5.m5.5.5"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.5.5.2.cmml" xref="S2.SS1.p1.5.m5.5.5">superscript</csymbol><apply id="S2.SS1.p1.5.m5.5.5.1.cmml" xref="S2.SS1.p1.5.m5.5.5"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.5.5.1.2.cmml" xref="S2.SS1.p1.5.m5.5.5">subscript</csymbol><set id="S2.SS1.p1.5.m5.5.5.1.1.2.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1"><interval closure="open" id="S2.SS1.p1.5.m5.5.5.1.1.1.1.3.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.2"><apply id="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1.2">𝑋</ci><list id="S2.SS1.p1.5.m5.2.2.2.3.cmml" xref="S2.SS1.p1.5.m5.2.2.2.4"><ci id="S2.SS1.p1.5.m5.1.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1">𝑡</ci><ci id="S2.SS1.p1.5.m5.2.2.2.2.cmml" xref="S2.SS1.p1.5.m5.2.2.2.2">𝑖</ci></list></apply><apply id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2.1.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2">subscript</csymbol><ci id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2.2.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2.2">𝑌</ci><list id="S2.SS1.p1.5.m5.4.4.2.3.cmml" xref="S2.SS1.p1.5.m5.4.4.2.4"><ci id="S2.SS1.p1.5.m5.3.3.1.1.cmml" xref="S2.SS1.p1.5.m5.3.3.1.1">𝑡</ci><ci id="S2.SS1.p1.5.m5.4.4.2.2.cmml" xref="S2.SS1.p1.5.m5.4.4.2.2">𝑖</ci></list></apply></interval></set><apply id="S2.SS1.p1.5.m5.5.5.1.3.cmml" xref="S2.SS1.p1.5.m5.5.5.1.3"><eq id="S2.SS1.p1.5.m5.5.5.1.3.1.cmml" xref="S2.SS1.p1.5.m5.5.5.1.3.1"></eq><ci id="S2.SS1.p1.5.m5.5.5.1.3.2.cmml" xref="S2.SS1.p1.5.m5.5.5.1.3.2">𝑖</ci><cn type="integer" id="S2.SS1.p1.5.m5.5.5.1.3.3.cmml" xref="S2.SS1.p1.5.m5.5.5.1.3.3">1</cn></apply></apply><apply id="S2.SS1.p1.5.m5.5.5.3.cmml" xref="S2.SS1.p1.5.m5.5.5.3"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.5.5.3.1.cmml" xref="S2.SS1.p1.5.m5.5.5.3">subscript</csymbol><ci id="S2.SS1.p1.5.m5.5.5.3.2.cmml" xref="S2.SS1.p1.5.m5.5.5.3.2">𝑛</ci><ci id="S2.SS1.p1.5.m5.5.5.3.3.cmml" xref="S2.SS1.p1.5.m5.5.5.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.5c">\{(X_{t,i},Y_{t,i})\}_{i=1}^{n_{t}}</annotation></semantics></math>.
A model <math id="S2.SS1.p1.6.m6.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.SS1.p1.6.m6.1a"><mi id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><ci id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">M</annotation></semantics></math> is expected to produce the output, given the task instruction and the corresponding input: <math id="S2.SS1.p1.7.m7.6" class="ltx_Math" alttext="M(I_{t},X_{t,i})=Y_{t,i}" display="inline"><semantics id="S2.SS1.p1.7.m7.6a"><mrow id="S2.SS1.p1.7.m7.6.6" xref="S2.SS1.p1.7.m7.6.6.cmml"><mrow id="S2.SS1.p1.7.m7.6.6.2" xref="S2.SS1.p1.7.m7.6.6.2.cmml"><mi id="S2.SS1.p1.7.m7.6.6.2.4" xref="S2.SS1.p1.7.m7.6.6.2.4.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p1.7.m7.6.6.2.3" xref="S2.SS1.p1.7.m7.6.6.2.3.cmml">​</mo><mrow id="S2.SS1.p1.7.m7.6.6.2.2.2" xref="S2.SS1.p1.7.m7.6.6.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p1.7.m7.6.6.2.2.2.3" xref="S2.SS1.p1.7.m7.6.6.2.2.3.cmml">(</mo><msub id="S2.SS1.p1.7.m7.5.5.1.1.1.1" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.cmml"><mi id="S2.SS1.p1.7.m7.5.5.1.1.1.1.2" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.2.cmml">I</mi><mi id="S2.SS1.p1.7.m7.5.5.1.1.1.1.3" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.SS1.p1.7.m7.6.6.2.2.2.4" xref="S2.SS1.p1.7.m7.6.6.2.2.3.cmml">,</mo><msub id="S2.SS1.p1.7.m7.6.6.2.2.2.2" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2.cmml"><mi id="S2.SS1.p1.7.m7.6.6.2.2.2.2.2" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2.2.cmml">X</mi><mrow id="S2.SS1.p1.7.m7.2.2.2.4" xref="S2.SS1.p1.7.m7.2.2.2.3.cmml"><mi id="S2.SS1.p1.7.m7.1.1.1.1" xref="S2.SS1.p1.7.m7.1.1.1.1.cmml">t</mi><mo id="S2.SS1.p1.7.m7.2.2.2.4.1" xref="S2.SS1.p1.7.m7.2.2.2.3.cmml">,</mo><mi id="S2.SS1.p1.7.m7.2.2.2.2" xref="S2.SS1.p1.7.m7.2.2.2.2.cmml">i</mi></mrow></msub><mo stretchy="false" id="S2.SS1.p1.7.m7.6.6.2.2.2.5" xref="S2.SS1.p1.7.m7.6.6.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p1.7.m7.6.6.3" xref="S2.SS1.p1.7.m7.6.6.3.cmml">=</mo><msub id="S2.SS1.p1.7.m7.6.6.4" xref="S2.SS1.p1.7.m7.6.6.4.cmml"><mi id="S2.SS1.p1.7.m7.6.6.4.2" xref="S2.SS1.p1.7.m7.6.6.4.2.cmml">Y</mi><mrow id="S2.SS1.p1.7.m7.4.4.2.4" xref="S2.SS1.p1.7.m7.4.4.2.3.cmml"><mi id="S2.SS1.p1.7.m7.3.3.1.1" xref="S2.SS1.p1.7.m7.3.3.1.1.cmml">t</mi><mo id="S2.SS1.p1.7.m7.4.4.2.4.1" xref="S2.SS1.p1.7.m7.4.4.2.3.cmml">,</mo><mi id="S2.SS1.p1.7.m7.4.4.2.2" xref="S2.SS1.p1.7.m7.4.4.2.2.cmml">i</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m7.6b"><apply id="S2.SS1.p1.7.m7.6.6.cmml" xref="S2.SS1.p1.7.m7.6.6"><eq id="S2.SS1.p1.7.m7.6.6.3.cmml" xref="S2.SS1.p1.7.m7.6.6.3"></eq><apply id="S2.SS1.p1.7.m7.6.6.2.cmml" xref="S2.SS1.p1.7.m7.6.6.2"><times id="S2.SS1.p1.7.m7.6.6.2.3.cmml" xref="S2.SS1.p1.7.m7.6.6.2.3"></times><ci id="S2.SS1.p1.7.m7.6.6.2.4.cmml" xref="S2.SS1.p1.7.m7.6.6.2.4">𝑀</ci><interval closure="open" id="S2.SS1.p1.7.m7.6.6.2.2.3.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.2"><apply id="S2.SS1.p1.7.m7.5.5.1.1.1.1.cmml" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.5.5.1.1.1.1.1.cmml" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.7.m7.5.5.1.1.1.1.2.cmml" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.2">𝐼</ci><ci id="S2.SS1.p1.7.m7.5.5.1.1.1.1.3.cmml" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.3">𝑡</ci></apply><apply id="S2.SS1.p1.7.m7.6.6.2.2.2.2.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.6.6.2.2.2.2.1.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p1.7.m7.6.6.2.2.2.2.2.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2.2">𝑋</ci><list id="S2.SS1.p1.7.m7.2.2.2.3.cmml" xref="S2.SS1.p1.7.m7.2.2.2.4"><ci id="S2.SS1.p1.7.m7.1.1.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1.1.1">𝑡</ci><ci id="S2.SS1.p1.7.m7.2.2.2.2.cmml" xref="S2.SS1.p1.7.m7.2.2.2.2">𝑖</ci></list></apply></interval></apply><apply id="S2.SS1.p1.7.m7.6.6.4.cmml" xref="S2.SS1.p1.7.m7.6.6.4"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.6.6.4.1.cmml" xref="S2.SS1.p1.7.m7.6.6.4">subscript</csymbol><ci id="S2.SS1.p1.7.m7.6.6.4.2.cmml" xref="S2.SS1.p1.7.m7.6.6.4.2">𝑌</ci><list id="S2.SS1.p1.7.m7.4.4.2.3.cmml" xref="S2.SS1.p1.7.m7.4.4.2.4"><ci id="S2.SS1.p1.7.m7.3.3.1.1.cmml" xref="S2.SS1.p1.7.m7.3.3.1.1">𝑡</ci><ci id="S2.SS1.p1.7.m7.4.4.2.2.cmml" xref="S2.SS1.p1.7.m7.4.4.2.2">𝑖</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m7.6c">M(I_{t},X_{t,i})=Y_{t,i}</annotation></semantics></math>, for <math id="S2.SS1.p1.8.m8.3" class="ltx_Math" alttext="i\in\{1,\ldots,n_{t}\}" display="inline"><semantics id="S2.SS1.p1.8.m8.3a"><mrow id="S2.SS1.p1.8.m8.3.3" xref="S2.SS1.p1.8.m8.3.3.cmml"><mi id="S2.SS1.p1.8.m8.3.3.3" xref="S2.SS1.p1.8.m8.3.3.3.cmml">i</mi><mo id="S2.SS1.p1.8.m8.3.3.2" xref="S2.SS1.p1.8.m8.3.3.2.cmml">∈</mo><mrow id="S2.SS1.p1.8.m8.3.3.1.1" xref="S2.SS1.p1.8.m8.3.3.1.2.cmml"><mo stretchy="false" id="S2.SS1.p1.8.m8.3.3.1.1.2" xref="S2.SS1.p1.8.m8.3.3.1.2.cmml">{</mo><mn id="S2.SS1.p1.8.m8.1.1" xref="S2.SS1.p1.8.m8.1.1.cmml">1</mn><mo id="S2.SS1.p1.8.m8.3.3.1.1.3" xref="S2.SS1.p1.8.m8.3.3.1.2.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p1.8.m8.2.2" xref="S2.SS1.p1.8.m8.2.2.cmml">…</mi><mo id="S2.SS1.p1.8.m8.3.3.1.1.4" xref="S2.SS1.p1.8.m8.3.3.1.2.cmml">,</mo><msub id="S2.SS1.p1.8.m8.3.3.1.1.1" xref="S2.SS1.p1.8.m8.3.3.1.1.1.cmml"><mi id="S2.SS1.p1.8.m8.3.3.1.1.1.2" xref="S2.SS1.p1.8.m8.3.3.1.1.1.2.cmml">n</mi><mi id="S2.SS1.p1.8.m8.3.3.1.1.1.3" xref="S2.SS1.p1.8.m8.3.3.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.SS1.p1.8.m8.3.3.1.1.5" xref="S2.SS1.p1.8.m8.3.3.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m8.3b"><apply id="S2.SS1.p1.8.m8.3.3.cmml" xref="S2.SS1.p1.8.m8.3.3"><in id="S2.SS1.p1.8.m8.3.3.2.cmml" xref="S2.SS1.p1.8.m8.3.3.2"></in><ci id="S2.SS1.p1.8.m8.3.3.3.cmml" xref="S2.SS1.p1.8.m8.3.3.3">𝑖</ci><set id="S2.SS1.p1.8.m8.3.3.1.2.cmml" xref="S2.SS1.p1.8.m8.3.3.1.1"><cn type="integer" id="S2.SS1.p1.8.m8.1.1.cmml" xref="S2.SS1.p1.8.m8.1.1">1</cn><ci id="S2.SS1.p1.8.m8.2.2.cmml" xref="S2.SS1.p1.8.m8.2.2">…</ci><apply id="S2.SS1.p1.8.m8.3.3.1.1.1.cmml" xref="S2.SS1.p1.8.m8.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.8.m8.3.3.1.1.1.1.cmml" xref="S2.SS1.p1.8.m8.3.3.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.8.m8.3.3.1.1.1.2.cmml" xref="S2.SS1.p1.8.m8.3.3.1.1.1.2">𝑛</ci><ci id="S2.SS1.p1.8.m8.3.3.1.1.1.3.cmml" xref="S2.SS1.p1.8.m8.3.3.1.1.1.3">𝑡</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m8.3c">i\in\{1,\ldots,n_{t}\}</annotation></semantics></math>.
Note that the instruction and instance input does not have a strict boundary in many cases. For example, “write an essay about school safety” can be a valid instruction that we expect models to respond to directly, while it can also be formulated as “write an essay about the following topic” as the instruction, and “school safety” as an instance input. To encourage the diversity of the data format, we allow such instructions that do not require additional input (i.e., <math id="S2.SS1.p1.9.m9.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S2.SS1.p1.9.m9.1a"><mi id="S2.SS1.p1.9.m9.1.1" xref="S2.SS1.p1.9.m9.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.9.m9.1b"><ci id="S2.SS1.p1.9.m9.1.1.cmml" xref="S2.SS1.p1.9.m9.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.9.m9.1c">X</annotation></semantics></math> is empty).</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Automatic Instruction Data Generation</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Our pipeline for data generation consists of
four steps: 1) generating task instructions, 2)
determining if the instruction represents a classification task,
3) instance generation with either an input-first or output-first approach, and 4) filtering low-quality data.</p>
</div>
<section id="S2.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Instruction Generation.</h4>

<div id="S2.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px1.p1.1" class="ltx_p">At the first step, <span id="S2.SS2.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> generates new instructions from a small set of seed human-written instructions in a bootstrapping fashion. We initiate the task pool with 175 tasks (1 instruction and 1 instance for each task).<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>These tasks were newly written by the authors and their labmates at UW, without reference to existing datasets or the test set used in this work. We provide more details about these tasks and analyze their similarity to the test tasks in Appendix §<a href="#A1.SS1" title="A.1 Writing the Seed Tasks ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</span></span></span> For every step, we sample 8 task instructions from this pool as in-context examples.
Of the 8 instructions, 6 are from the human-written tasks,
and 2 are from the model-generated tasks in previous steps to promote diversity.
The prompting template is shown in <a href="#A1.T5" title="Table 5 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;5</span></a>.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Classification Task Identification.</h4>

<div id="S2.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px2.p1.1" class="ltx_p">Because we need two different approaches for classification and non-classification tasks, we next identify whether the generated instruction represents a classification task or not.<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>More concretely, we regard tasks that have a small limited output label space as classification tasks.</span></span></span>
We prompt the LM in a few-shot way to determine this, using 12 classification instructions and 19 non-classification instructions from the seed tasks. The prompting template is shown in <a href="#A1.T6" title="Table 6 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;6</span></a>.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Instance Generation.</h4>

<div id="S2.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px3.p1.1" class="ltx_p">Given the instructions and their task type, we generate instances for each instruction independently. This is challenging because it requires the model to understand what the target task is, based on the instruction, figure out what additional input fields are needed and generate them, and finally complete the task by producing the output. We found that pretrained LMs can achieve this to a large extent when prompted with instruction-input-output in-context examples from other tasks.
A natural way to do this is the <span id="S2.SS2.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_bold">Input-first Approach</span>, where we can ask an LM to come up with the input fields first based on the instruction, and then produce the corresponding output. This generation order is similar to how models are used to respond to instruction and input, but here with in-context examples from other tasks. The prompting template is shown in <a href="#A1.T7" title="Table 7 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;7</span></a>.</p>
</div>
<div id="S2.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S2.SS2.SSS0.Px3.p2.1" class="ltx_p">However, we found that this approach can generate inputs biased toward one label, especially for classification tasks (e.g., for grammar error detection, it usually generates grammatical input). Therefore, we additionally propose an
<span id="S2.SS2.SSS0.Px3.p2.1.1" class="ltx_text ltx_font_bold">Output-first Approach</span> for classification tasks, where we first generate the possible class labels, and then condition the input generation on each class label. The prompting template is shown in <a href="#A1.T8" title="Table 8 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;8</span></a>.<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>In this work, we use a fixed set of seed tasks for prompting the instance generation, and thus only generate a small number of instances per task in one round. Future work can use randomly sampled tasks to prompt the model to generate a larger number of instances in multiple rounds.</span></span></span> We apply the output-first approach to the classification tasks identified in the former step, and the input-first approach to the remaining non-classification tasks.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Filtering and Postprocessing.</h4>

<div id="S2.SS2.SSS0.Px4.p1" class="ltx_para">
<p id="S2.SS2.SSS0.Px4.p1.1" class="ltx_p">To encourage diversity, a new instruction is added to the task pool only when its ROUGE-L similarity with any existing instruction is less than 0.7.
We also exclude instructions that contain some specific keywords (e.g., image, picture, graph) that usually can not be processed by LMs. When generating new instances for each instruction, we filter out instances that are exactly the same or those with the same input but different outputs. Invalid generations are identified and filtered out based on heuristics (e.g., instruction is too long or too short, instance output is a repetition of the input).</p>
</div>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Finetuning the LM to Follow Instructions</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">After creating large-scale instruction data, we use it to finetune the original LM (i.e., <span id="S2.SS3.p1.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span>). To do this, we concatenate the instruction and instance input as a prompt and train the model to generate the instance output in a standard supervised way. To make the model robust to different formats, we use multiple templates to encode the instruction and instance input together. For example, the instruction can be prefixed with “Task:” or not, the input can be prefixed with “Input:” or not, “Output:” can be appended at the end of the prompt or not, and different numbers of break lines can be put in the middle, etc.</p>
</div>
<figure id="S2.F5" class="ltx_figure">
<p id="S2.F5.5" class="ltx_p"><span id="S2.F5.1.1" class="ltx_text" style="position:relative; bottom:-210.3pt;">
<span id="S2.F5.1.1.1.1.1" class="ltx_inline-block ltx_transformed_outer" style="width:245.2pt;height:413.6pt;vertical-align:-203.3pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S2.F5.1.1.1.1.1.1" class="ltx_p"><span id="S2.F5.1.1.1.1.1.1.1" class="ltx_text">

<span id="S2.F5.1.1.1.1.1.1.1.1" class="ltx_block ltx_minipage ltx_align_middle" style="width:238.5pt;"><img src="/html/2212.10560/assets/x3.png" id="S2.F5.1.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="298" height="311" alt="[Uncaptioned image]">
<span class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_block">Figure 3: </span>The top 20 most common root verbs (inner circle) and their top 4 direct noun objects (outer circle) in the generated instructions. Despite their diversity, the instructions shown here only account for 14% of all the generated instructions because many instructions (e.g., “Classify whether the user is satisfied with the service.”) do not contain such a verb-noun structure. </span>
</span></span></span>
</span></span></span>
 <span id="S2.F5.5.5" class="ltx_text" style="position:relative; bottom:-294.6pt;">
<span id="S2.F5.5.5.4.4.4" class="ltx_inline-block ltx_transformed_outer" style="width:180.1pt;height:582.2pt;vertical-align:-287.6pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span id="S2.F5.5.5.4.4.4.4" class="ltx_p"><span id="S2.F5.5.5.4.4.4.4.4" class="ltx_text">

<span id="S2.F5.5.5.4.4.4.4.4.4" class="ltx_block ltx_minipage ltx_align_middle" style="width:173.4pt;">
<span id="S2.F5.2.2.1.1.1.1.1.1.1" class="ltx_figure"><img src="/html/2212.10560/assets/x4.png" id="S2.F5.2.2.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="332" height="80" alt="[Uncaptioned image]">
</span>
<span class="ltx_caption"><span class="ltx_tag ltx_tag_block">Figure 4: </span>Distribution of the ROUGE-L scores between generated instructions and their most similar seed instructions. </span>
<br class="ltx_break">
<span id="S2.F5.3.3.2.2.2.2.2.2.2" class="ltx_figure"><img src="/html/2212.10560/assets/x5.png" id="S2.F5.3.3.2.2.2.2.2.2.2.g1" class="ltx_graphics ltx_img_landscape" width="332" height="101" alt="[Uncaptioned image]">
</span>
<span id="S2.F5.4.4.3.3.3.3.3.3.3" class="ltx_figure"><img src="/html/2212.10560/assets/x6.png" id="S2.F5.4.4.3.3.3.3.3.3.3.g1" class="ltx_graphics ltx_img_landscape" width="461" height="148" alt="[Uncaptioned image]">
</span>
<span id="S2.F5.5.5.4.4.4.4.4.4.4" class="ltx_figure"><img src="/html/2212.10560/assets/x7.png" id="S2.F5.5.5.4.4.4.4.4.4.4.g1" class="ltx_graphics ltx_img_landscape" width="332" height="101" alt="[Uncaptioned image]">
</span>
<span class="ltx_caption"><span class="ltx_tag ltx_tag_block">Figure 5: </span>Length distribution of the generated instructions, non-empty inputs, and outputs. 
</span>
</span></span></span>
</span></span></span></p>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> Data from <span id="S3.2.2" class="ltx_text ltx_font_smallcaps">GPT3</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we apply our method for inducing instruction data to <span id="S3.p1.1.1" class="ltx_text ltx_font_smallcaps">GPT3</span> as a case study. We use the largest GPT3 LM (“davinci” engine) accessed through the OpenAI API.<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a target="_blank" href="https://openai.com/api/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openai.com/api/</a></span></span></span> The parameters for making queries are described in Appendix <a href="#A1.SS2" title="A.2 Querying the GPT3 API ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.2</span></a>. Here we present an overview of the generated data.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Statistics</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p"><a href="#S3.T1" title="Table 1 ‣ 3.1 Statistics ‣ 3 Self-Instruct Data from GPT3 ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;1</span></a> describes the basic statistics of the generated data. We generate a total of over 52K instructions and more than 82K instances corresponding to these instructions after filtering.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt ltx_border_t">statistic</td>
<td id="S3.T1.1.1.2" class="ltx_td ltx_border_tt ltx_border_t"></td>
</tr>
<tr id="S3.T1.1.2" class="ltx_tr">
<td id="S3.T1.1.2.1" class="ltx_td ltx_align_left ltx_border_t"># of instructions</td>
<td id="S3.T1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">52,445</td>
</tr>
<tr id="S3.T1.1.3" class="ltx_tr">
<td id="S3.T1.1.3.1" class="ltx_td ltx_align_left">- # of classification instructions</td>
<td id="S3.T1.1.3.2" class="ltx_td ltx_align_center">11,584</td>
</tr>
<tr id="S3.T1.1.4" class="ltx_tr">
<td id="S3.T1.1.4.1" class="ltx_td ltx_align_left">- # of non-classification instructions</td>
<td id="S3.T1.1.4.2" class="ltx_td ltx_align_center">40,861</td>
</tr>
<tr id="S3.T1.1.5" class="ltx_tr">
<td id="S3.T1.1.5.1" class="ltx_td ltx_align_left"># of instances</td>
<td id="S3.T1.1.5.2" class="ltx_td ltx_align_center">82,439</td>
</tr>
<tr id="S3.T1.1.6" class="ltx_tr">
<td id="S3.T1.1.6.1" class="ltx_td ltx_align_left">- # of instances with empty input</td>
<td id="S3.T1.1.6.2" class="ltx_td ltx_align_center">35,878</td>
</tr>
<tr id="S3.T1.1.7" class="ltx_tr">
<td id="S3.T1.1.7.1" class="ltx_td ltx_align_left">ave.&nbsp;instruction length (in words)</td>
<td id="S3.T1.1.7.2" class="ltx_td ltx_align_center">15.9</td>
</tr>
<tr id="S3.T1.1.8" class="ltx_tr">
<td id="S3.T1.1.8.1" class="ltx_td ltx_align_left">ave.&nbsp;non-empty input length (in words)</td>
<td id="S3.T1.1.8.2" class="ltx_td ltx_align_center">12.7</td>
</tr>
<tr id="S3.T1.1.9" class="ltx_tr">
<td id="S3.T1.1.9.1" class="ltx_td ltx_align_left ltx_border_bb">ave.&nbsp;output length (in words)</td>
<td id="S3.T1.1.9.2" class="ltx_td ltx_align_center ltx_border_bb">18.9</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>
Statistics of the generated data by applying <span id="S3.T1.3.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> to GPT3.
</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Diversity</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">To study what types of instructions are generated and how diverse they are, we identify the verb-noun structure in the generated instructions. We use the Berkeley Neural Parser<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a target="_blank" href="https://parser.kitaev.io/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://parser.kitaev.io/</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Kitaev and Klein, <a href="#bib.bib15" title="" class="ltx_ref">2018</a>; Kitaev et&nbsp;al., <a href="#bib.bib14" title="" class="ltx_ref">2019</a>)</cite> to parse the instructions and then extract the verb that is closest to the root
as well as its first direct noun object. 26,559 out of the 52,445 instructions contain such structure; other instructions usually contain more complex clauses (e.g., “Classify whether this tweet contains political content or not.”) or are framed as questions (e.g., “Which of these statements are true?”).
We plot the top 20 most common root verbs and their top 4
direct noun objects in <a href="#S2.F5" title="Figure 5 ‣ 2.3 Finetuning the LM to Follow Instructions ‣ 2 Method ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure&nbsp;5</span></a>, which account for 14% of the entire set. Overall, we see quite diverse intents and textual formats in these instructions.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">We further study how the generated instructions differ from the seed instructions used to prompt the generation. For each generated instruction, we compute its highest ROUGE-L overlap with the 175 seed instructions. We plot the distribution of these ROUGE-L scores in <a href="#S2.F5" title="Figure 5 ‣ 2.3 Finetuning the LM to Follow Instructions ‣ 2 Method ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure&nbsp;5</span></a>. The results indicate a decent number of new instructions were generated, which do not have much overlap with the seeds.
We also demonstrate diversity in the length of the instructions, instance inputs, and instance outputs in <a href="#S2.F5" title="Figure 5 ‣ 2.3 Finetuning the LM to Follow Instructions ‣ 2 Method ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure&nbsp;5</span></a>.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Quality</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">So far, we have shown the quantity and diversity of the generated data, but its quality remains uncertain. To investigate this, we randomly sample 200 instructions and randomly select 1 instance per instruction. We asked an expert annotator (author of this work) to label whether each instance is correct or not, in terms of the instruction, the instance input, and the instance output.
Evaluation results in <a href="#S3.T2" title="Table 2 ‣ 3.3 Quality ‣ 3 Self-Instruct Data from GPT3 ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;2</span></a> show that most of the generated instructions are meaningful, while the generated instances may contain more noise (to a reasonable extent). However, we found that even though the generations may contain errors, most of them are still in the correct format or partially correct, which can provide useful guidance for training models to follow instructions. We listed a number of good examples and bad examples in <a href="#A3.T10" title="Table 10 ‣ Appendix C Task and Instance Examples from the Generated Instruction Data ‣ B.3 Example Predictions from GPT3_&quot;Self-Inst&quot; ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;10</span></a> and <a href="#A3.T11" title="Table 11 ‣ Appendix C Task and Instance Examples from the Generated Instruction Data ‣ B.3 Example Predictions from GPT3_&quot;Self-Inst&quot; ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, respectively.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T2.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt">Quality Review Question</td>
<td id="S3.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Yes %</td>
</tr>
<tr id="S3.T2.1.2" class="ltx_tr">
<td id="S3.T2.1.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt">
<span id="S3.T2.1.2.1.1" class="ltx_text"></span> <span id="S3.T2.1.2.1.2" class="ltx_text">
<span id="S3.T2.1.2.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.1.2.1.2.1.1" class="ltx_tr">
<span id="S3.T2.1.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-2.5pt;padding-bottom:-2.5pt;">Does the instruction</span></span>
<span id="S3.T2.1.2.1.2.1.2" class="ltx_tr">
<span id="S3.T2.1.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-2.5pt;padding-bottom:-2.5pt;">describe a valid task?</span></span>
</span></span><span id="S3.T2.1.2.1.3" class="ltx_text"></span></td>
<td id="S3.T2.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">92%</td>
</tr>
<tr id="S3.T2.1.3" class="ltx_tr">
<td id="S3.T2.1.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.1.3.1.1" class="ltx_text"></span> <span id="S3.T2.1.3.1.2" class="ltx_text">
<span id="S3.T2.1.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.1.3.1.2.1.1" class="ltx_tr">
<span id="S3.T2.1.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-2.5pt;padding-bottom:-2.5pt;">Is the input appropriate</span></span>
<span id="S3.T2.1.3.1.2.1.2" class="ltx_tr">
<span id="S3.T2.1.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-2.5pt;padding-bottom:-2.5pt;">for the instruction?</span></span>
</span></span><span id="S3.T2.1.3.1.3" class="ltx_text"></span></td>
<td id="S3.T2.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">79%</td>
</tr>
<tr id="S3.T2.1.4" class="ltx_tr">
<td id="S3.T2.1.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.1.4.1.1" class="ltx_text"></span> <span id="S3.T2.1.4.1.2" class="ltx_text">
<span id="S3.T2.1.4.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.1.4.1.2.1.1" class="ltx_tr">
<span id="S3.T2.1.4.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-2.5pt;padding-bottom:-2.5pt;">Is the output a correct and acceptable</span></span>
<span id="S3.T2.1.4.1.2.1.2" class="ltx_tr">
<span id="S3.T2.1.4.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-2.5pt;padding-bottom:-2.5pt;">response to the instruction and input?</span></span>
</span></span><span id="S3.T2.1.4.1.3" class="ltx_text"></span></td>
<td id="S3.T2.1.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">58%</td>
</tr>
<tr id="S3.T2.1.5" class="ltx_tr">
<td id="S3.T2.1.5.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_l ltx_border_r ltx_border_tt">All fields are valid</td>
<td id="S3.T2.1.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt">54%</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Data quality review for the instruction, input, and output of the generated data. See <a href="#A3.T10" title="Table 10 ‣ Appendix C Task and Instance Examples from the Generated Instruction Data ‣ B.3 Example Predictions from GPT3_&quot;Self-Inst&quot; ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;10</span></a> and <a href="#A3.T11" title="Table 11 ‣ Appendix C Task and Instance Examples from the Generated Instruction Data ‣ B.3 Example Predictions from GPT3_&quot;Self-Inst&quot; ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;11</span></a> for representative valid and invalid examples.
</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Results</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We conduct experiments to measure and compare the performance of models under various instruction tuning setups.
We first describe our models and other baselines, followed by our experiments.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span><span id="S4.SS1.1.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.SS1.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.SS1.1.1.m1.1b"><msub id="S4.SS1.1.1.m1.1.1" xref="S4.SS1.1.1.m1.1.1.cmml"><mi id="S4.SS1.1.1.m1.1.1b" xref="S4.SS1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS1.1.1.m1.1.1.1" xref="S4.SS1.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.1.1.m1.1c"><apply id="S4.SS1.1.1.m1.1.1.cmml" xref="S4.SS1.1.1.m1.1.1"><ci id="S4.SS1.1.1.m1.1.1.1a.cmml" xref="S4.SS1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.SS1.1.1.m1.1.1.1.cmml" xref="S4.SS1.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.1.1.m1.1d">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>: finetuning <span id="S4.SS1.2.2" class="ltx_text ltx_font_smallcaps">GPT3</span> on its own instruction data</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Given the instruction-generated instruction data, we conduct instruction tuning with the <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_smallcaps">GPT3</span> model itself (“davinci” engine). As described in §<a href="#S2.SS3" title="2.3 Finetuning the LM to Follow Instructions ‣ 2 Method ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>, we use various templates to concatenate the instruction and input, and train the model to generate the output. This finetuning is done through the OpenAI finetuning API.<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>See <a target="_blank" href="https://beta.openai.com/docs/guides/fine-tuning" title="" class="ltx_ref ltx_href">OpenAI’s documentation on finetuning</a>.
</span></span></span> We use the default hyper-parameters, except that we set the prompt loss weight to 0, and we train the model for 2 epochs. We refer the reader to Appendix&nbsp;<a href="#A1.SS3" title="A.3 Finetuning GPT3 ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a> for additional finetuning details. The resulting model is denoted by <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.SS1.p1.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.SS1.p1.1.1.m1.1a"><msub id="S4.SS1.p1.1.1.m1.1.1" xref="S4.SS1.p1.1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.1.m1.1.1a" xref="S4.SS1.p1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS1.p1.1.1.m1.1.1.1" xref="S4.SS1.p1.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.1.m1.1b"><apply id="S4.SS1.p1.1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.1.m1.1.1"><ci id="S4.SS1.p1.1.1.m1.1.1.1a.cmml" xref="S4.SS1.p1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.SS1.p1.1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Baselines</h3>

<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Off-the-shelf LMs.</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px1.p1.1" class="ltx_p">We evaluate T5-LM <cite class="ltx_cite ltx_citemacro_cite">Lester et&nbsp;al. (<a href="#bib.bib16" title="" class="ltx_ref">2021</a>); Raffel et&nbsp;al. (<a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite> and <span id="S4.SS2.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_smallcaps">GPT3</span>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Brown et&nbsp;al. (<a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite> as the vanilla LM baselines (only pretraining, no additional finetuning).
These baselines will indicate the extent to which off-the-shelf LMs are capable of following instructions naturally immediately after pretraining.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Publicly available instruction-tuned models.</h4>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px2.p1.2" class="ltx_p"><span id="S4.SS2.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_smallcaps">T<math id="S4.SS2.SSS0.Px2.p1.1.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.1.1.m1.1a"><mn id="S4.SS2.SSS0.Px2.p1.1.1.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.1.1.m1.1b"><cn type="integer" id="S4.SS2.SSS0.Px2.p1.1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.1.1.m1.1.1">0</cn></annotation-xml></semantics></math></span> and <span id="S4.SS2.SSS0.Px2.p1.2.2" class="ltx_text ltx_font_smallcaps">T<math id="S4.SS2.SSS0.Px2.p1.2.2.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS2.SSS0.Px2.p1.2.2.m1.1a"><mi id="S4.SS2.SSS0.Px2.p1.2.2.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.2.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.2.2.m1.1b"><ci id="S4.SS2.SSS0.Px2.p1.2.2.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.2.2.m1.1c">k</annotation></semantics></math>-Instruct</span> are two instruction-tuned models proposed in <cite class="ltx_cite ltx_citemacro_citet">Sanh et&nbsp;al. (<a href="#bib.bib27" title="" class="ltx_ref">2022</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>, respectively, and are demonstrated to be able to follow instructions for many NLP tasks.
Both of these models are finetuned from the T5&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Raffel et&nbsp;al. (<a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite> checkpoints and are publicly available.<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>
<span id="footnote9.1" class="ltx_text ltx_font_smallcaps">T<math id="footnote9.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="footnote9.1.m1.1b"><mn id="footnote9.1.m1.1.1" xref="footnote9.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="footnote9.1.m1.1c"><cn type="integer" id="footnote9.1.m1.1.1.cmml" xref="footnote9.1.m1.1.1">0</cn></annotation-xml></semantics></math></span> is available at <a target="_blank" href="https://huggingface.co/bigscience/T0" title="" class="ltx_ref ltx_href">here</a> and <span id="footnote9.2" class="ltx_text ltx_font_smallcaps">T<math id="footnote9.2.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="footnote9.2.m1.1b"><mi id="footnote9.2.m1.1.1" xref="footnote9.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="footnote9.2.m1.1c"><ci id="footnote9.2.m1.1.1.cmml" xref="footnote9.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote9.2.m1.1d">k</annotation></semantics></math>-Instruct</span> is <a target="_blank" href="https://huggingface.co/allenai/tk-instruct-11b-def" title="" class="ltx_ref ltx_href">here</a>.
</span></span></span> For both of these models, we use their largest version with 11B parameters.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Instruction-tuned GPT3 models.</h4>

<div id="S4.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS2.SSS0.Px3.p1.1" class="ltx_p">We evaluate <math id="S4.SS2.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{}}" display="inline"><semantics id="S4.SS2.SSS0.Px3.p1.1.m1.1a"><msub id="S4.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.cmml"><mtext id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2a.cmml">InstructGPT</mtext><mrow id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3a.cmml"></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p1.1.m1.1b"><apply id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2a.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2"><mtext id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3a.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3"><mrow id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3"></mrow></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px3.p1.1.m1.1c">\text{InstructGPT}_{\text{}}</annotation></semantics></math>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Ouyang et&nbsp;al. (<a href="#bib.bib23" title="" class="ltx_ref">2022</a>)</cite>,
which is developed by OpenAI based on GPT3 to follow human instructions better and has been found by the community to have impressive zero-shot abilities.
There are various generations of these models,
where newer ones use more expansive data or algorithmic novelties.<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>
See <a target="_blank" href="https://beta.openai.com/docs/model-index-for-researchers" title="" class="ltx_ref ltx_href">OpenAI’s documentation on their models.</a>
</span></span></span>
For our <span id="S4.SS2.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_smallcaps">SuperNI</span> experiments in §<a href="#S4.SS3" title="4.3 Experiment 1: Zero-Shot Generalization on SuperNI benchmark ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>, we only compare with their <span id="S4.SS2.SSS0.Px3.p1.1.2" class="ltx_text ltx_font_typewriter">text-davinci-001</span> engine, because their newer engines are trained with the latest user data and are likely to have already seen the <span id="S4.SS2.SSS0.Px3.p1.1.3" class="ltx_text ltx_font_smallcaps">SuperNI</span> test set. For our human evaluation on newly written instructions, we include their 001, 002 and 003 engines for completeness.</p>
</div>
<div id="S4.SS2.SSS0.Px3.p2" class="ltx_para">
<p id="S4.SS2.SSS0.Px3.p2.3" class="ltx_p">Additionally, to compare <span id="S4.SS2.SSS0.Px3.p2.3.4" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> training with other publicly available instruction tuning data, we further finetune GPT3 model with data from <span id="S4.SS2.SSS0.Px3.p2.3.5" class="ltx_text ltx_font_smallcaps">PromptSource</span> and <span id="S4.SS2.SSS0.Px3.p2.3.6" class="ltx_text ltx_font_smallcaps">SuperNI</span>, which are used to train the <span id="S4.SS2.SSS0.Px3.p2.1.1" class="ltx_text ltx_font_smallcaps">T<math id="S4.SS2.SSS0.Px3.p2.1.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS2.SSS0.Px3.p2.1.1.m1.1a"><mn id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p2.1.1.m1.1b"><cn type="integer" id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1">0</cn></annotation-xml></semantics></math></span> and <span id="S4.SS2.SSS0.Px3.p2.2.2" class="ltx_text ltx_font_smallcaps">T<math id="S4.SS2.SSS0.Px3.p2.2.2.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS2.SSS0.Px3.p2.2.2.m1.1a"><mi id="S4.SS2.SSS0.Px3.p2.2.2.m1.1.1" xref="S4.SS2.SSS0.Px3.p2.2.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p2.2.2.m1.1b"><ci id="S4.SS2.SSS0.Px3.p2.2.2.m1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p2.2.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px3.p2.2.2.m1.1c">k</annotation></semantics></math>-Instruct</span> models. We call them <span id="S4.SS2.SSS0.Px3.p2.3.3" class="ltx_text ltx_font_smallcaps">T<math id="S4.SS2.SSS0.Px3.p2.3.3.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS2.SSS0.Px3.p2.3.3.m1.1a"><mn id="S4.SS2.SSS0.Px3.p2.3.3.m1.1.1" xref="S4.SS2.SSS0.Px3.p2.3.3.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p2.3.3.m1.1b"><cn type="integer" id="S4.SS2.SSS0.Px3.p2.3.3.m1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p2.3.3.m1.1.1">0</cn></annotation-xml></semantics></math></span> training and <span id="S4.SS2.SSS0.Px3.p2.3.7" class="ltx_text ltx_font_smallcaps">SuperNI</span> training for short, respectively.
To save the training budget, we sampled 50K instances (but covering all their instructions) for each dataset, which has a comparable size to the instruction data we generated. Based on the findings from <cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite> and our early experiments, reducing the number of instances per training task does not degrade the model’s generalization performance to unseen tasks.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Experiment 1: Zero-Shot Generalization on <span id="S4.SS3.1.1" class="ltx_text ltx_font_smallcaps">SuperNI</span> benchmark</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We first evaluate the models’ ability to follow instructions on typical NLP tasks in a zero-shot fashion.
We use the evaluation set of <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_smallcaps">SuperNI</span> &nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wang et&nbsp;al. (<a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>, which consists of 119 tasks with 100 instances in each task.
In this work, we mainly focus on the zero-shot setup, i.e., the model is prompted with the definition of the tasks only, without in-context demonstration examples.
For all our requests to the <span id="S4.SS3.p1.1.2" class="ltx_text ltx_font_smallcaps">GPT3</span> variants, we use the deterministic generation mode (temperature as 0 and no nucleus sampling) without specific stop sequences.</p>
</div>
<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.5" class="ltx_p">We make the following observations from the results in <a href="#S4.T3" title="Table 3 ‣ Results. ‣ 4.3 Experiment 1: Zero-Shot Generalization on SuperNI benchmark ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;3</span></a>.
<span id="S4.SS3.SSS0.Px1.p1.5.5" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> boosts the instruction-following ability of <span id="S4.SS3.SSS0.Px1.p1.5.6" class="ltx_text ltx_font_smallcaps">GPT3</span> by a large margin. The vanilla <span id="S4.SS3.SSS0.Px1.p1.5.7" class="ltx_text ltx_font_smallcaps">GPT3</span> model basically cannot follow human instructions at all. Upon manual analysis, we find that it usually generates irrelevant and repetitive text, and does not know when to stop generation.
Compared with other models that are not specifically trained for <span id="S4.SS3.SSS0.Px1.p1.5.8" class="ltx_text ltx_font_smallcaps">SuperNI</span>, <span id="S4.SS3.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.SS3.SSS0.Px1.p1.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.1.1.m1.1a"><msub id="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1a" xref="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.1.1.m1.1b"><apply id="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1"><ci id="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.1a.cmml" xref="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> achieves better performance than <span id="S4.SS3.SSS0.Px1.p1.2.2" class="ltx_text ltx_font_smallcaps">T<math id="S4.SS3.SSS0.Px1.p1.2.2.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.2.2.m1.1a"><mn id="S4.SS3.SSS0.Px1.p1.2.2.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.2.2.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.2.2.m1.1b"><cn type="integer" id="S4.SS3.SSS0.Px1.p1.2.2.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.2.2.m1.1.1">0</cn></annotation-xml></semantics></math></span> or the <span id="S4.SS3.SSS0.Px1.p1.5.9" class="ltx_text ltx_font_smallcaps">GPT3</span> finetuned on the <span id="S4.SS3.SSS0.Px1.p1.3.3" class="ltx_text ltx_font_smallcaps">T<math id="S4.SS3.SSS0.Px1.p1.3.3.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.3.3.m1.1a"><mn id="S4.SS3.SSS0.Px1.p1.3.3.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.3.3.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.3.3.m1.1b"><cn type="integer" id="S4.SS3.SSS0.Px1.p1.3.3.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.3.3.m1.1.1">0</cn></annotation-xml></semantics></math></span> training set, which takes tremendous human labeling efforts. Notably, <span id="S4.SS3.SSS0.Px1.p1.4.4" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.SS3.SSS0.Px1.p1.4.4.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.4.4.m1.1a"><msub id="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1a" xref="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.1" xref="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.4.4.m1.1b"><apply id="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1"><ci id="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.1a.cmml" xref="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.4.4.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> also nearly matches the performance of <math id="S4.SS3.SSS0.Px1.p1.5.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{001}}" display="inline"><semantics id="S4.SS3.SSS0.Px1.p1.5.m1.1a"><msub id="S4.SS3.SSS0.Px1.p1.5.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1.cmml"><mtext id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.2" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.3" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.5.m1.1b"><apply id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1">subscript</csymbol><ci id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.2a.cmml" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1.2"><mtext id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.3a.cmml" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1.3"><mtext mathsize="70%" id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.3.cmml" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.5.m1.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>, which is trained with private user data and human-annotated labels.</p>
</div>
<div id="S4.SS3.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p2.1" class="ltx_p">Models trained on the <span id="S4.SS3.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_smallcaps">SuperNI</span> training set still achieve better performance on its evaluation set, which we attribute to the similar instruction style and formatting. However,
we show that
<span id="S4.SS3.SSS0.Px1.p2.1.2" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> still brings in additional gains when combined with the <span id="S4.SS3.SSS0.Px1.p2.1.3" class="ltx_text ltx_font_smallcaps">SuperNI</span> training set, proving its value as complementary data.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2212.10560/assets/x8.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="315" height="136" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>
Performance of GPT3 model and its instruction-tuned variants, evaluated by human experts on our 252 user-oriented instructions (§<a href="#S4.SS4" title="4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>). Human evaluators are instructed to rate the models’ responses into four levels.
The results indicate that <span id="S4.F6.4.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.F6.4.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.F6.4.1.m1.1b"><msub id="S4.F6.4.1.m1.1.1" xref="S4.F6.4.1.m1.1.1.cmml"><mi id="S4.F6.4.1.m1.1.1b" xref="S4.F6.4.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.F6.4.1.m1.1.1.1" xref="S4.F6.4.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F6.4.1.m1.1c"><apply id="S4.F6.4.1.m1.1.1.cmml" xref="S4.F6.4.1.m1.1.1"><ci id="S4.F6.4.1.m1.1.1.1a.cmml" xref="S4.F6.4.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.F6.4.1.m1.1.1.1.cmml" xref="S4.F6.4.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.4.1.m1.1d">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> outperforms
all the other <span id="S4.F6.8.3" class="ltx_text ltx_font_smallcaps">GPT3</span> variants trained on publicly available instruction datasets.
Additionally, <span id="S4.F6.5.2" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.F6.5.2.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.F6.5.2.m1.1b"><msub id="S4.F6.5.2.m1.1.1" xref="S4.F6.5.2.m1.1.1.cmml"><mi id="S4.F6.5.2.m1.1.1b" xref="S4.F6.5.2.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.F6.5.2.m1.1.1.1" xref="S4.F6.5.2.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F6.5.2.m1.1c"><apply id="S4.F6.5.2.m1.1.1.cmml" xref="S4.F6.5.2.m1.1.1"><ci id="S4.F6.5.2.m1.1.1.1a.cmml" xref="S4.F6.5.2.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.F6.5.2.m1.1.1.1.cmml" xref="S4.F6.5.2.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.5.2.m1.1d">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> scores nearly as good as <math id="S4.F6.6.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{001}}" display="inline"><semantics id="S4.F6.6.m1.1b"><msub id="S4.F6.6.m1.1.1" xref="S4.F6.6.m1.1.1.cmml"><mtext id="S4.F6.6.m1.1.1.2" xref="S4.F6.6.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.F6.6.m1.1.1.3" xref="S4.F6.6.m1.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F6.6.m1.1c"><apply id="S4.F6.6.m1.1.1.cmml" xref="S4.F6.6.m1.1.1"><csymbol cd="ambiguous" id="S4.F6.6.m1.1.1.1.cmml" xref="S4.F6.6.m1.1.1">subscript</csymbol><ci id="S4.F6.6.m1.1.1.2a.cmml" xref="S4.F6.6.m1.1.1.2"><mtext id="S4.F6.6.m1.1.1.2.cmml" xref="S4.F6.6.m1.1.1.2">InstructGPT</mtext></ci><ci id="S4.F6.6.m1.1.1.3a.cmml" xref="S4.F6.6.m1.1.1.3"><mtext mathsize="70%" id="S4.F6.6.m1.1.1.3.cmml" xref="S4.F6.6.m1.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.6.m1.1d">\text{InstructGPT}_{\text{001}}</annotation></semantics></math> (cf.&nbsp;<a href="#footnote1" title="footnote 1 ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">footnote&nbsp;1</span></a>).
</figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.T3.12" class="ltx_inline-block ltx_figure_panel ltx_transformed_outer" style="width:411.9pt;height:339.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(64.0pt,-52.8pt) scale(1.45089119638244,1.45089119638244) ;">
<table id="S4.T3.12.12" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S4.T3.12.12.13" class="ltx_tr">
<td id="S4.T3.12.12.13.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" style="padding:0.5pt 1.5pt;"><span id="S4.T3.12.12.13.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S4.T3.12.12.13.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding:0.5pt 1.5pt;"><span id="S4.T3.12.12.13.2.1" class="ltx_text ltx_font_bold"># Params</span></td>
<td id="S4.T3.12.12.13.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding:0.5pt 1.5pt;"><span id="S4.T3.12.12.13.3.1" class="ltx_text ltx_font_bold">ROUGE-L</span></td>
</tr>
<tr id="S4.T3.12.12.14" class="ltx_tr">
<td id="S4.T3.12.12.14.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding:0.5pt 1.5pt;"><span id="S4.T3.12.12.14.1.1" class="ltx_text ltx_font_bold">Vanilla LMs</span></td>
<td id="S4.T3.12.12.14.2" class="ltx_td ltx_border_t" style="padding:0.5pt 1.5pt;"></td>
<td id="S4.T3.12.12.14.3" class="ltx_td ltx_border_t" style="padding:0.5pt 1.5pt;"></td>
</tr>
<tr id="S4.T3.12.12.15" class="ltx_tr">
<td id="S4.T3.12.12.15.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;">T5-LM</td>
<td id="S4.T3.12.12.15.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">11B</td>
<td id="S4.T3.12.12.15.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">25.7</td>
</tr>
<tr id="S4.T3.1.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;">
<svg id="S4.T3.1.1.1.1.pic1" class="ltx_picture" height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)"></g></svg> <span id="S4.T3.1.1.1.1.1" class="ltx_text" style="color:#000000;"> <span id="S4.T3.1.1.1.1.1.1" class="ltx_text ltx_font_smallcaps">GPT3</span></span>
</td>
<td id="S4.T3.1.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">175B</td>
<td id="S4.T3.1.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">6.8</td>
</tr>
<tr id="S4.T3.12.12.16" class="ltx_tr">
<td id="S4.T3.12.12.16.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding:0.5pt 1.5pt;"><span id="S4.T3.12.12.16.1.1" class="ltx_text ltx_font_bold">Instruction-tuned w/o <span id="S4.T3.12.12.16.1.1.1" class="ltx_text ltx_font_smallcaps" style="color:#000000;">SuperNI</span></span></td>
<td id="S4.T3.12.12.16.2" class="ltx_td ltx_border_t" style="padding:0.5pt 1.5pt;"></td>
<td id="S4.T3.12.12.16.3" class="ltx_td ltx_border_t" style="padding:0.5pt 1.5pt;"></td>
</tr>
<tr id="S4.T3.2.2.2" class="ltx_tr">
<td id="S4.T3.2.2.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;"><span id="S4.T3.2.2.2.1.1" class="ltx_text ltx_font_smallcaps">T<math id="S4.T3.2.2.2.1.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.T3.2.2.2.1.1.m1.1a"><mn id="S4.T3.2.2.2.1.1.m1.1.1" xref="S4.T3.2.2.2.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.1.1.m1.1b"><cn type="integer" id="S4.T3.2.2.2.1.1.m1.1.1.cmml" xref="S4.T3.2.2.2.1.1.m1.1.1">0</cn></annotation-xml></semantics></math></span></td>
<td id="S4.T3.2.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">11B</td>
<td id="S4.T3.2.2.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">33.1</td>
</tr>
<tr id="S4.T3.3.3.3" class="ltx_tr">
<td id="S4.T3.3.3.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;">
<span id="S4.T3.3.3.3.1.2" class="ltx_text" style="color:#000000;"><span id="S4.T3.3.3.3.1.2.1" class="ltx_text ltx_font_smallcaps">GPT3</span></span> + <span id="S4.T3.3.3.3.1.1" class="ltx_text ltx_font_smallcaps">T<math id="S4.T3.3.3.3.1.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.T3.3.3.3.1.1.m1.1a"><mn id="S4.T3.3.3.3.1.1.m1.1.1" xref="S4.T3.3.3.3.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.1.1.m1.1b"><cn type="integer" id="S4.T3.3.3.3.1.1.m1.1.1.cmml" xref="S4.T3.3.3.3.1.1.m1.1.1">0</cn></annotation-xml></semantics></math></span> Training</td>
<td id="S4.T3.3.3.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">175B</td>
<td id="S4.T3.3.3.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">37.9</td>
</tr>
<tr id="S4.T3.6.6.6" class="ltx_tr">
<td id="S4.T3.6.6.6.3" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;">
<svg id="S4.T3.4.4.4.1.pic1" class="ltx_picture" height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)"></g></svg> <svg id="S4.T3.5.5.5.2.pic2" class="ltx_picture" height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)"></g></svg><span id="S4.T3.6.6.6.3.1" class="ltx_text" style="color:#000000;"> <span id="S4.T3.6.6.6.3.1.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.T3.6.6.6.3.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.T3.6.6.6.3.1.1.m1.1a"><msub id="S4.T3.6.6.6.3.1.1.m1.1.1" xref="S4.T3.6.6.6.3.1.1.m1.1.1.cmml"><mi id="S4.T3.6.6.6.3.1.1.m1.1.1a" xref="S4.T3.6.6.6.3.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" mathcolor="#000000" id="S4.T3.6.6.6.3.1.1.m1.1.1.1" xref="S4.T3.6.6.6.3.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.3.1.1.m1.1b"><apply id="S4.T3.6.6.6.3.1.1.m1.1.1.cmml" xref="S4.T3.6.6.6.3.1.1.m1.1.1"><ci id="S4.T3.6.6.6.3.1.1.m1.1.1.1a.cmml" xref="S4.T3.6.6.6.3.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathcolor="#000000" mathsize="70%" id="S4.T3.6.6.6.3.1.1.m1.1.1.1.cmml" xref="S4.T3.6.6.6.3.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.3.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> </span>
(Ours)</td>
<td id="S4.T3.6.6.6.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">175B</td>
<td id="S4.T3.6.6.6.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">39.9</td>
</tr>
<tr id="S4.T3.8.8.8" class="ltx_tr">
<td id="S4.T3.8.8.8.2" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;">
<svg id="S4.T3.7.7.7.1.pic1" class="ltx_picture" height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)"></g></svg><math id="S4.T3.8.8.8.2.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{001}}" display="inline"><semantics id="S4.T3.8.8.8.2.m1.1a"><msub id="S4.T3.8.8.8.2.m1.1.1" xref="S4.T3.8.8.8.2.m1.1.1.cmml"><mtext mathcolor="#000000" id="S4.T3.8.8.8.2.m1.1.1.2" xref="S4.T3.8.8.8.2.m1.1.1.2a.cmml">InstructGPT</mtext><mtext mathcolor="#000000" id="S4.T3.8.8.8.2.m1.1.1.3" xref="S4.T3.8.8.8.2.m1.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.8.2.m1.1b"><apply id="S4.T3.8.8.8.2.m1.1.1.cmml" xref="S4.T3.8.8.8.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.8.8.8.2.m1.1.1.1.cmml" xref="S4.T3.8.8.8.2.m1.1.1">subscript</csymbol><ci id="S4.T3.8.8.8.2.m1.1.1.2a.cmml" xref="S4.T3.8.8.8.2.m1.1.1.2"><mtext id="S4.T3.8.8.8.2.m1.1.1.2.cmml" xref="S4.T3.8.8.8.2.m1.1.1.2">InstructGPT</mtext></ci><ci id="S4.T3.8.8.8.2.m1.1.1.3a.cmml" xref="S4.T3.8.8.8.2.m1.1.1.3"><mtext mathsize="70%" id="S4.T3.8.8.8.2.m1.1.1.3.cmml" xref="S4.T3.8.8.8.2.m1.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.8.2.m1.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>
</td>
<td id="S4.T3.8.8.8.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">175B</td>
<td id="S4.T3.8.8.8.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;"><span id="S4.T3.8.8.8.4.1" class="ltx_text ltx_font_bold">40.8</span></td>
</tr>
<tr id="S4.T3.12.12.17" class="ltx_tr">
<td id="S4.T3.12.12.17.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding:0.5pt 1.5pt;"><span id="S4.T3.12.12.17.1.1" class="ltx_text ltx_font_bold">Instruction-tuned w/ <span id="S4.T3.12.12.17.1.1.1" class="ltx_text ltx_font_smallcaps" style="color:#000000;">SuperNI</span></span></td>
<td id="S4.T3.12.12.17.2" class="ltx_td ltx_border_t" style="padding:0.5pt 1.5pt;"></td>
<td id="S4.T3.12.12.17.3" class="ltx_td ltx_border_t" style="padding:0.5pt 1.5pt;"></td>
</tr>
<tr id="S4.T3.9.9.9" class="ltx_tr">
<td id="S4.T3.9.9.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;"><span id="S4.T3.9.9.9.1.1" class="ltx_text ltx_font_smallcaps">T<math id="S4.T3.9.9.9.1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.T3.9.9.9.1.1.m1.1a"><mi id="S4.T3.9.9.9.1.1.m1.1.1" xref="S4.T3.9.9.9.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.T3.9.9.9.1.1.m1.1b"><ci id="S4.T3.9.9.9.1.1.m1.1.1.cmml" xref="S4.T3.9.9.9.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.9.9.1.1.m1.1c">k</annotation></semantics></math>-Instruct</span></td>
<td id="S4.T3.9.9.9.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">11B</td>
<td id="S4.T3.9.9.9.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">46.0</td>
</tr>
<tr id="S4.T3.10.10.10" class="ltx_tr">
<td id="S4.T3.10.10.10.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;">
<svg id="S4.T3.10.10.10.1.pic1" class="ltx_picture" height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)"></g></svg><span id="S4.T3.10.10.10.1.1" class="ltx_text" style="color:#000000;"> <span id="S4.T3.10.10.10.1.1.1" class="ltx_text ltx_font_smallcaps">GPT3</span></span> + <span id="S4.T3.10.10.10.1.2" class="ltx_text ltx_font_smallcaps" style="color:#000000;">SuperNI</span> Training</td>
<td id="S4.T3.10.10.10.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">175B</td>
<td id="S4.T3.10.10.10.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">49.5</td>
</tr>
<tr id="S4.T3.12.12.12" class="ltx_tr">
<td id="S4.T3.12.12.12.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" style="padding:0.5pt 1.5pt;">
<svg id="S4.T3.11.11.11.1.pic1" class="ltx_picture" height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)"></g></svg><span id="S4.T3.12.12.12.2.1" class="ltx_text" style="color:#000000;"> <span id="S4.T3.12.12.12.2.1.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.T3.12.12.12.2.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.T3.12.12.12.2.1.1.m1.1a"><msub id="S4.T3.12.12.12.2.1.1.m1.1.1" xref="S4.T3.12.12.12.2.1.1.m1.1.1.cmml"><mi id="S4.T3.12.12.12.2.1.1.m1.1.1a" xref="S4.T3.12.12.12.2.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" mathcolor="#000000" id="S4.T3.12.12.12.2.1.1.m1.1.1.1" xref="S4.T3.12.12.12.2.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T3.12.12.12.2.1.1.m1.1b"><apply id="S4.T3.12.12.12.2.1.1.m1.1.1.cmml" xref="S4.T3.12.12.12.2.1.1.m1.1.1"><ci id="S4.T3.12.12.12.2.1.1.m1.1.1.1a.cmml" xref="S4.T3.12.12.12.2.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathcolor="#000000" mathsize="70%" id="S4.T3.12.12.12.2.1.1.m1.1.1.1.cmml" xref="S4.T3.12.12.12.2.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.12.12.2.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span></span>
+ <span id="S4.T3.12.12.12.2.2" class="ltx_text ltx_font_smallcaps" style="color:#000000;">SuperNI</span> Training (Ours)</td>
<td id="S4.T3.12.12.12.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:0.5pt 1.5pt;">175B</td>
<td id="S4.T3.12.12.12.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:0.5pt 1.5pt;"><span id="S4.T3.12.12.12.4.1" class="ltx_text ltx_font_bold">51.6</span></td>
</tr>
</tbody></table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><svg id="S4.T3.pic1" class="ltx_picture ltx_figure_panel" height="123.15" overflow="visible" version="1.1" width="353.74"><g transform="translate(0,123.15) matrix(1 0 0 -1 0 0) translate(353.32,0) translate(0,94.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M -2.66 6.6 C -0.89 3.53 -0.89 0.05 -2.66 -3.02" style="fill:none"></path><g transform="matrix(-0.5 0.86603 -0.86603 -0.5 -2.66 6.6)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><g transform="matrix(-0.5 -0.86603 0.86603 -0.5 -2.66 -3.02)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -348.71 13.22)" fill="#000000" stroke="#000000"><foreignObject width="48.05" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T3.pic1.1.1.1.1.1" class="ltx_text">\tiny1⃝</span></foreignObject></g><path d="M -2.34 5.66 C -2.34 5.66 -2.98 5.66 -2.34 5.66" style="fill:none"></path><g transform="matrix(-1.0 0.0 0.0 -1.0 -2.34 5.66)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.62 5.66)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -348.71 -26.69)" fill="#000000" stroke="#000000"><foreignObject width="48.05" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T3.pic1.2.2.2.1.1" class="ltx_text">\tiny2⃝</span></foreignObject></g><path d="M -3.62 17.87 C -3.44 17.87 -3.44 19.06 -3.62 19.06" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.62 17.87)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.62 19.06)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -348.71 -86.87)" fill="#000000" stroke="#000000"><foreignObject width="48.05" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T3.pic1.3.3.3.1.1" class="ltx_text">\tiny3⃝</span></foreignObject></g></g></svg></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Evaluation results on <em id="S4.T3.19.1" class="ltx_emph ltx_font_italic">unseen</em> tasks from <span id="S4.T3.20.2" class="ltx_text ltx_font_smallcaps" style="color:#000000;">SuperNI</span> (§<a href="#S4.SS3" title="4.3 Experiment 1: Zero-Shot Generalization on SuperNI benchmark ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>).
From the results, we see that \tiny1⃝ <span id="S4.T3.21.3" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> can boost <span id="S4.T3.22.4" class="ltx_text ltx_font_smallcaps">GPT3</span> performance by a large margin (+33.1%) and \tiny2⃝ nearly matches the performance of <math id="S4.T3.14.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{001}}" display="inline"><semantics id="S4.T3.14.m1.1b"><msub id="S4.T3.14.m1.1.1" xref="S4.T3.14.m1.1.1.cmml"><mtext id="S4.T3.14.m1.1.1.2" xref="S4.T3.14.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.T3.14.m1.1.1.3" xref="S4.T3.14.m1.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T3.14.m1.1c"><apply id="S4.T3.14.m1.1.1.cmml" xref="S4.T3.14.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.14.m1.1.1.1.cmml" xref="S4.T3.14.m1.1.1">subscript</csymbol><ci id="S4.T3.14.m1.1.1.2a.cmml" xref="S4.T3.14.m1.1.1.2"><mtext id="S4.T3.14.m1.1.1.2.cmml" xref="S4.T3.14.m1.1.1.2">InstructGPT</mtext></ci><ci id="S4.T3.14.m1.1.1.3a.cmml" xref="S4.T3.14.m1.1.1.3"><mtext mathsize="70%" id="S4.T3.14.m1.1.1.3.cmml" xref="S4.T3.14.m1.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.14.m1.1d">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>.
Additionally, \tiny3⃝ it can further improve the performance even when a large amount of labeled instruction data is present.
</figcaption>
</figure>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Experiment 2: Generalization to User-oriented Instructions on Novel Tasks</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Despite the comprehensiveness of <span id="S4.SS4.p1.1.1" class="ltx_text ltx_font_smallcaps">SuperNI</span> in collecting existing NLP tasks, most of these NLP tasks were proposed for research purposes and skewed toward classification. To better access the practical value of instruction-following models, a subset of the authors curate a new set of instructions motivated by user-oriented applications.
We first brainstorm various domains where large LMs may be useful (e.g., email writing, social media, productivity tools, entertainment, programming), then craft instructions related to each domain along with an input-output instance (again, input is optional). We aim to diversify the styles and formats of these tasks (e.g., instructions may be long or short; input/output may take the form of bullet points, tables, codes, equations, etc.). In total, we create 252 instructions with 1 instance per instruction. We believe it can serve as a testbed for evaluating how instruction-based models handle diverse and unfamiliar instructions. <a href="#A2.SS3" title="B.3 Example Predictions from GPT3_&quot;Self-Inst&quot; ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">subsection&nbsp;B.3</span></a> presents a small portion of them. The entire set is available in our GitHub repository. We analyze the overlap between this set set and the seed instructions in §<a href="#A1.SS1" title="A.1 Writing the Seed Tasks ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</p>
</div>
<section id="S4.SS4.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Human evaluation setup.</h4>

<div id="S4.SS4.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px1.p1.1" class="ltx_p">Evaluating models’ performance on this evaluation set of diverse tasks is extremely challenging because different tasks require different expertise. Indeed, many of these tasks cannot be measured by automatic metrics or even be judged by normal crowdworkers (e.g., writing a program, or converting first-order logic into natural language). To get a more faithful evaluation, we asked the authors of the instructions to judge model predictions. Details on how we set up this human evaluation are described in Appendix <a href="#A2" title="Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>. The evaluators were asked to rate the output based on whether it accurately and effectively completes the task. We implemented a four-level rating system for categorizing the quality of the models’ outputs:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_smallcaps">Rating-A:</span> The response is valid and satisfying.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_smallcaps">Rating-B:</span> The response is acceptable but has minor errors or imperfections.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_smallcaps">Rating-C:</span> The response is relevant and responds to the instruction, but it has significant errors in the content. For example, GPT3 might generate a valid output first, but continue to generate other irrelevant things.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p"><span id="S4.I1.i4.p1.1.1" class="ltx_text ltx_font_smallcaps">Rating-D:</span> The response is irrelevant or completely invalid.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS4.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>

<div id="S4.SS4.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS4.SSS0.Px2.p1.9" class="ltx_p"><a href="#S4.F6" title="Figure 6 ‣ Results. ‣ 4.3 Experiment 1: Zero-Shot Generalization on SuperNI benchmark ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure&nbsp;6</span></a> shows the performance of <span id="S4.SS4.SSS0.Px2.p1.9.5" class="ltx_text ltx_font_smallcaps">GPT3</span> model and its instruction-tuned counterparts on this newly written instruction set (w. inter-rater agreement <math id="S4.SS4.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\kappa=0.57" display="inline"><semantics id="S4.SS4.SSS0.Px2.p1.1.m1.1a"><mrow id="S4.SS4.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.2.cmml">κ</mi><mo id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.1" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.cmml">0.57</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1"><eq id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.1"></eq><ci id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.2">𝜅</ci><cn type="float" id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3">0.57</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.1.m1.1c">\kappa=0.57</annotation></semantics></math> on the 4-class categorical scale, see Appendix <a href="#A2" title="Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a> for details). As anticipated, the vanilla <span id="S4.SS4.SSS0.Px2.p1.9.6" class="ltx_text ltx_font_smallcaps">GPT3</span> LM is largely unable to respond to instructions, and all instruction-tuned models demonstrate comparatively higher performance.
Nonetheless, <span id="S4.SS4.SSS0.Px2.p1.2.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.SS4.SSS0.Px2.p1.2.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.SS4.SSS0.Px2.p1.2.1.m1.1a"><msub id="S4.SS4.SSS0.Px2.p1.2.1.m1.1.1" xref="S4.SS4.SSS0.Px2.p1.2.1.m1.1.1.cmml"><mi id="S4.SS4.SSS0.Px2.p1.2.1.m1.1.1a" xref="S4.SS4.SSS0.Px2.p1.2.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.2.1.m1.1.1.1" xref="S4.SS4.SSS0.Px2.p1.2.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.2.1.m1.1b"><apply id="S4.SS4.SSS0.Px2.p1.2.1.m1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.2.1.m1.1.1"><ci id="S4.SS4.SSS0.Px2.p1.2.1.m1.1.1.1a.cmml" xref="S4.SS4.SSS0.Px2.p1.2.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.SS4.SSS0.Px2.p1.2.1.m1.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.2.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.2.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> (i.e., <span id="S4.SS4.SSS0.Px2.p1.9.7" class="ltx_text ltx_font_smallcaps">GPT3</span> model finetuned with <span id="S4.SS4.SSS0.Px2.p1.9.8" class="ltx_text ltx_font_smallcaps">Self-Instruct</span>) outperforms those counterparts trained on <span id="S4.SS4.SSS0.Px2.p1.3.2" class="ltx_text ltx_font_smallcaps">T<math id="S4.SS4.SSS0.Px2.p1.3.2.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS4.SSS0.Px2.p1.3.2.m1.1a"><mn id="S4.SS4.SSS0.Px2.p1.3.2.m1.1.1" xref="S4.SS4.SSS0.Px2.p1.3.2.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.3.2.m1.1b"><cn type="integer" id="S4.SS4.SSS0.Px2.p1.3.2.m1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.3.2.m1.1.1">0</cn></annotation-xml></semantics></math></span> or <span id="S4.SS4.SSS0.Px2.p1.9.9" class="ltx_text ltx_font_smallcaps">SuperNI</span> data by a large margin, demonstrating the value of the generated data despite the noise.
Compared with <math id="S4.SS4.SSS0.Px2.p1.4.m2.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{001}}" display="inline"><semantics id="S4.SS4.SSS0.Px2.p1.4.m2.1a"><msub id="S4.SS4.SSS0.Px2.p1.4.m2.1.1" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1.cmml"><mtext id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.2" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.3" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.4.m2.1b"><apply id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1">subscript</csymbol><ci id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.2a.cmml" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1.2"><mtext id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.2.cmml" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.3a.cmml" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1.3"><mtext mathsize="70%" id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.3.cmml" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.4.m2.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>, <span id="S4.SS4.SSS0.Px2.p1.5.3" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.SS4.SSS0.Px2.p1.5.3.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.SS4.SSS0.Px2.p1.5.3.m1.1a"><msub id="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1" xref="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.cmml"><mi id="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1a" xref="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.1" xref="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.5.3.m1.1b"><apply id="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1"><ci id="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.1a.cmml" xref="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.5.3.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> is quite close in performance—if we count acceptable response with minor imperfections (<span id="S4.SS4.SSS0.Px2.p1.9.10" class="ltx_text ltx_font_smallcaps">Rating-B</span>) as valid, <span id="S4.SS4.SSS0.Px2.p1.6.4" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.SS4.SSS0.Px2.p1.6.4.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.SS4.SSS0.Px2.p1.6.4.m1.1a"><msub id="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1" xref="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.cmml"><mi id="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1a" xref="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.1" xref="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.6.4.m1.1b"><apply id="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1"><ci id="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.1a.cmml" xref="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.6.4.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> is only 5% behind <math id="S4.SS4.SSS0.Px2.p1.7.m3.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{001}}" display="inline"><semantics id="S4.SS4.SSS0.Px2.p1.7.m3.1a"><msub id="S4.SS4.SSS0.Px2.p1.7.m3.1.1" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1.cmml"><mtext id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.2" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.3" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.7.m3.1b"><apply id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1">subscript</csymbol><ci id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.2a.cmml" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1.2"><mtext id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.2.cmml" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.3a.cmml" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1.3"><mtext mathsize="70%" id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.3.cmml" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.7.m3.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>. Lastly, our evaluation confirms the impressive instruction-following ability of <math id="S4.SS4.SSS0.Px2.p1.8.m4.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{002}}" display="inline"><semantics id="S4.SS4.SSS0.Px2.p1.8.m4.1a"><msub id="S4.SS4.SSS0.Px2.p1.8.m4.1.1" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1.cmml"><mtext id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.2" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.3" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1.3a.cmml">002</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.8.m4.1b"><apply id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1">subscript</csymbol><ci id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.2a.cmml" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1.2"><mtext id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.2.cmml" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.3a.cmml" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1.3"><mtext mathsize="70%" id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.3.cmml" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1.3">002</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.8.m4.1c">\text{InstructGPT}_{\text{002}}</annotation></semantics></math> and <math id="S4.SS4.SSS0.Px2.p1.9.m5.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{003}}" display="inline"><semantics id="S4.SS4.SSS0.Px2.p1.9.m5.1a"><msub id="S4.SS4.SSS0.Px2.p1.9.m5.1.1" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1.cmml"><mtext id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.2" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.3" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1.3a.cmml">003</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.9.m5.1b"><apply id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1">subscript</csymbol><ci id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.2a.cmml" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1.2"><mtext id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.2.cmml" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.3a.cmml" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1.3"><mtext mathsize="70%" id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.3.cmml" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1.3">003</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.9.m5.1c">\text{InstructGPT}_{\text{003}}</annotation></semantics></math>. Although there are many factors behind this success, we conjecture that future work can largely benefit from improving the quality of our generated data by using human annotators or training a reward model to select better generations, similar to the algorithm used by <cite class="ltx_cite ltx_citemacro_citet">Ouyang et&nbsp;al. (<a href="#bib.bib23" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Effect of Data Size and Quality</h3>

<section id="S4.SS5.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data size.</h4>

<div id="S4.SS5.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS5.SSS0.Px1.p1.1" class="ltx_p"><span id="S4.SS5.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> provides a way to grow instruction data at a low cost with almost no human labeling; could more of this generated data lead to better instruction-following ability? We conduct an analysis of the size of generated data by subsampling different numbers of instructions from the generated dataset, finetuning <span id="S4.SS5.SSS0.Px1.p1.1.3" class="ltx_text ltx_font_smallcaps">GPT3</span> on the sampled subsets, and evaluating how the resulting models perform on the 252 user-oriented instruction set. We conduct the same human evaluation as in §<a href="#S4.SS4" title="4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>.
<a href="#S4.F7" title="Figure 7 ‣ Data quality. ‣ 4.5 Effect of Data Size and Quality ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure&nbsp;7</span></a> presents the performance of <span id="S4.SS5.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.SS5.SSS0.Px1.p1.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.SS5.SSS0.Px1.p1.1.1.m1.1a"><msub id="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1" xref="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.cmml"><mi id="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1a" xref="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.1" xref="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.SSS0.Px1.p1.1.1.m1.1b"><apply id="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.cmml" xref="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1"><ci id="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.1a.cmml" xref="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.1.cmml" xref="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.SSS0.Px1.p1.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> models finetuned with different sizes of generated data. Overall, we see consistent improvement as we grow the data size. However, this improvement almost plateaus after 16K.
This is in-line with the data scaling experiments in <cite class="ltx_cite ltx_citemacro_citet">Wang et&nbsp;al. (<a href="#bib.bib33" title="" class="ltx_ref">2022</a>, Fig.&nbsp;5)</cite>.
Interestingly, when evaluating on <span id="S4.SS5.SSS0.Px1.p1.1.4" class="ltx_text ltx_font_smallcaps">SuperNI</span> we found the model’s performance gain plateaus earlier at around hundreds of instructions.
This may be due to the fact that the new generated data is distinct from typical NLP tasks in <span id="S4.SS5.SSS0.Px1.p1.1.5" class="ltx_text ltx_font_smallcaps">SuperNI</span>, indicating that future research may benefit from using a combination of different instruction data for better performance on various types of tasks.</p>
</div>
</section>
<section id="S4.SS5.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data quality.</h4>

<div id="S4.SS5.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS5.SSS0.Px2.p1.2" class="ltx_p">Another direction to improve the model’s performance is to take our generated data and get better supervision (with less noise). We explore this idea by using <math id="S4.SS5.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{003}}" display="inline"><semantics id="S4.SS5.SSS0.Px2.p1.1.m1.1a"><msub id="S4.SS5.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.cmml"><mtext id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3a.cmml">003</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2a.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2"><mtext id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3a.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3">003</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.SSS0.Px2.p1.1.m1.1c">\text{InstructGPT}_{\text{003}}</annotation></semantics></math> (the best available general-purpose model) to regenerate the output field of all our instances given the instruction and input. We then use this improved version of our data to finetune <span id="S4.SS5.SSS0.Px2.p1.2.1" class="ltx_text ltx_font_smallcaps">GPT3</span>. This can be regarded as a distillation of <math id="S4.SS5.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{003}}" display="inline"><semantics id="S4.SS5.SSS0.Px2.p1.2.m2.1a"><msub id="S4.SS5.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.cmml"><mtext id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3a.cmml">003</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.SSS0.Px2.p1.2.m2.1b"><apply id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2a.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2"><mtext id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3a.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3"><mtext mathsize="70%" id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3">003</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.SSS0.Px2.p1.2.m2.1c">\text{InstructGPT}_{\text{003}}</annotation></semantics></math> with our data. As is shown in <a href="#S4.F7" title="Figure 7 ‣ Data quality. ‣ 4.5 Effect of Data Size and Quality ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure&nbsp;7</span></a>, the resulting model outperforms the counterpart trained with the original data by 10%, which suggests big room for future work on using our generation pipeline to get initial data and then improving the data quality with human experts or distillation from better models.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2212.10560/assets/x9.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_square" width="332" height="271" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Human evaluation performance of <span id="S4.F7.4.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.F7.4.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.F7.4.1.m1.1b"><msub id="S4.F7.4.1.m1.1.1" xref="S4.F7.4.1.m1.1.1.cmml"><mi id="S4.F7.4.1.m1.1.1b" xref="S4.F7.4.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.F7.4.1.m1.1.1.1" xref="S4.F7.4.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F7.4.1.m1.1c"><apply id="S4.F7.4.1.m1.1.1.cmml" xref="S4.F7.4.1.m1.1.1"><ci id="S4.F7.4.1.m1.1.1.1a.cmml" xref="S4.F7.4.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.F7.4.1.m1.1.1.1.cmml" xref="S4.F7.4.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.4.1.m1.1d">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> models tuned with different sizes of instructions. <math id="S4.F7.5.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.F7.5.m1.1b"><mi id="S4.F7.5.m1.1.1" xref="S4.F7.5.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.F7.5.m1.1c"><ci id="S4.F7.5.m1.1.1.cmml" xref="S4.F7.5.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.5.m1.1d">x</annotation></semantics></math>-axis is in log scale. The smallest size is 175, where only the seed tasks are used for instruction tuning.
We also evaluate whether improving the data quality will further improve the performance by distilling the outputs from <math id="S4.F7.6.m2.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{003}}" display="inline"><semantics id="S4.F7.6.m2.1b"><msub id="S4.F7.6.m2.1.1" xref="S4.F7.6.m2.1.1.cmml"><mtext id="S4.F7.6.m2.1.1.2" xref="S4.F7.6.m2.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.F7.6.m2.1.1.3" xref="S4.F7.6.m2.1.1.3a.cmml">003</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F7.6.m2.1c"><apply id="S4.F7.6.m2.1.1.cmml" xref="S4.F7.6.m2.1.1"><csymbol cd="ambiguous" id="S4.F7.6.m2.1.1.1.cmml" xref="S4.F7.6.m2.1.1">subscript</csymbol><ci id="S4.F7.6.m2.1.1.2a.cmml" xref="S4.F7.6.m2.1.1.2"><mtext id="S4.F7.6.m2.1.1.2.cmml" xref="S4.F7.6.m2.1.1.2">InstructGPT</mtext></ci><ci id="S4.F7.6.m2.1.1.3a.cmml" xref="S4.F7.6.m2.1.1.3"><mtext mathsize="70%" id="S4.F7.6.m2.1.1.3.cmml" xref="S4.F7.6.m2.1.1.3">003</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.6.m2.1d">\text{InstructGPT}_{\text{003}}</annotation></semantics></math>. We see consistent improvement from using larger data with better quality.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2>

<section id="S5.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Instruction-following LMs.</h4>

<div id="S5.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p1.1" class="ltx_p">A series of works have found evidence that vanilla LMs can be effective at following general language instructions if tuned with annotated “instructional” data—datasets containing language instructional commands and their desired outcomes based on human annotation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">(Weller et&nbsp;al., <a href="#bib.bib38" title="" class="ltx_ref">2020</a>; Mishra et&nbsp;al., <a href="#bib.bib22" title="" class="ltx_ref">2022</a>; Wei et&nbsp;al., <a href="#bib.bib35" title="" class="ltx_ref">2022</a>; Sanh et&nbsp;al., <a href="#bib.bib27" title="" class="ltx_ref">2022</a>, i.a.)</cite>.
Additionally, they show a direct correlation between the size and diversity of the “instructional” data and the generalizability of resulting models to unseen tasks <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>; Chung et&nbsp;al., <a href="#bib.bib4" title="" class="ltx_ref">2022</a>)</cite>.
However, since these developments largely focus on existing NLP tasks and depend on human-annotated instructions, this poses a bottleneck for progress toward more generalizable models
<cite class="ltx_cite ltx_citemacro_cite">(e.g., see Fig.&nbsp;5a in Wang et&nbsp;al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite>.
Our work aims to move beyond classical NLP tasks and tackle the challenges of creating diverse instruction data by employing pretrained LMs.
<math id="S5.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{}}" display="inline"><semantics id="S5.SS0.SSS0.Px1.p1.1.m1.1a"><msub id="S5.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.cmml"><mtext id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2a.cmml">InstructGPT</mtext><mrow id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3a.cmml"></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p1.1.m1.1b"><apply id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2a.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2"><mtext id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2">InstructGPT</mtext></ci><ci id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3a.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3"><mrow id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3"></mrow></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.1.m1.1c">\text{InstructGPT}_{\text{}}</annotation></semantics></math>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Ouyang et&nbsp;al. (<a href="#bib.bib23" title="" class="ltx_ref">2022</a>)</cite> shares a similar goal as ours in building more general-purpose LMs, and has demonstrated remarkable performance in following diverse user instructions. However, as a commercial system, their construction process still remains quite opaque. In particular, the role of <em id="S5.SS0.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">data</em> has remained understudied due to limited transparency and the private user data they used in their study.
Addressing such challenges necessitates the creation of a large-scale, public dataset covering a broad range of tasks.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Language models for data generation and augmentation.</h4>

<div id="S5.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px2.p1.1" class="ltx_p">A variety of works have proposed using LMs for data generation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Schick and Schütze (<a href="#bib.bib28" title="" class="ltx_ref">2021</a>); Wang et&nbsp;al. (<a href="#bib.bib34" title="" class="ltx_ref">2021</a>); Liu et&nbsp;al. (<a href="#bib.bib17" title="" class="ltx_ref">2022</a>); Meng et&nbsp;al. (<a href="#bib.bib20" title="" class="ltx_ref">2023</a>)</cite> or augmentation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Feng et&nbsp;al. (<a href="#bib.bib6" title="" class="ltx_ref">2021</a>); Yang et&nbsp;al. (<a href="#bib.bib42" title="" class="ltx_ref">2020</a>); Mekala et&nbsp;al. (<a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite>.
Our work differs from this line in that it is <em id="S5.SS0.SSS0.Px2.p1.1.1" class="ltx_emph ltx_font_italic">not</em> specific to a particular task (say, QA or NLI). In contrast, a distinct motivation for <span id="S5.SS0.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> is to bootstrap new task definitions that may not have been defined before by NLP practitioners (though potentially still important for real users). In parallel with our work, <cite class="ltx_cite ltx_citemacro_citet">Honovich et&nbsp;al. (<a href="#bib.bib10" title="" class="ltx_ref">2022a</a>)</cite> also propose to generate large-scale instruction data (so-called Unnatural Instructions) with GPT3 models. The major differences are that 1) they use tasks in <span id="S5.SS0.SSS0.Px2.p1.1.3" class="ltx_text ltx_font_smallcaps">SuperNI</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite> as their seed tasks, resulting in a different distribution of generated tasks; 2) they employ <math id="S5.SS0.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{002}}" display="inline"><semantics id="S5.SS0.SSS0.Px2.p1.1.m1.1a"><msub id="S5.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S5.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mtext id="S5.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="S5.SS0.SSS0.Px2.p1.1.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="S5.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="S5.SS0.SSS0.Px2.p1.1.m1.1.1.3a.cmml">002</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="S5.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S5.SS0.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS0.SSS0.Px2.p1.1.m1.1.1.2a.cmml" xref="S5.SS0.SSS0.Px2.p1.1.m1.1.1.2"><mtext id="S5.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S5.SS0.SSS0.Px2.p1.1.m1.1.1.2">InstructGPT</mtext></ci><ci id="S5.SS0.SSS0.Px2.p1.1.m1.1.1.3a.cmml" xref="S5.SS0.SSS0.Px2.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S5.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S5.SS0.SSS0.Px2.p1.1.m1.1.1.3">002</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px2.p1.1.m1.1c">\text{InstructGPT}_{\text{002}}</annotation></semantics></math> for generating the data, in which sense they are distilling knowledge from an already instruction-tuned model, while we solely rely on the vanilla LM; 3) the detailed generation pipeline and templates are different. Nevertheless, we believe that both efforts in expanding instruction data are complementary, and the community will benefit from these diverse datasets.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Instruction generation.</h4>

<div id="S5.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px3.p1.1" class="ltx_p">A series of recent works&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhou et&nbsp;al. (<a href="#bib.bib47" title="" class="ltx_ref">2022b</a>); Ye et&nbsp;al. (<a href="#bib.bib43" title="" class="ltx_ref">2022</a>); Singh et&nbsp;al. (<a href="#bib.bib30" title="" class="ltx_ref">2022</a>); Honovich et&nbsp;al. (<a href="#bib.bib11" title="" class="ltx_ref">2022b</a>)</cite> generate instructions of a task given a few examples. While <span id="S5.SS0.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> also involves instruction generation, a major difference in our case is it is task-agnostic; we generate new tasks (instructions along with instances) from scratch.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Model self-training.</h4>

<div id="S5.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px4.p1.1" class="ltx_p">A typical self-training framework &nbsp;<cite class="ltx_cite ltx_citemacro_cite">He et&nbsp;al. (<a href="#bib.bib8" title="" class="ltx_ref">2019</a>); Xie et&nbsp;al. (<a href="#bib.bib40" title="" class="ltx_ref">2020</a>); Du et&nbsp;al. (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>); Amini et&nbsp;al. (<a href="#bib.bib1" title="" class="ltx_ref">2022</a>); Huang et&nbsp;al. (<a href="#bib.bib12" title="" class="ltx_ref">2022</a>)</cite> uses trained models to assign labels to unlabeled data and then leverages the newly labeled data to improve the model. In a similar line, <cite class="ltx_cite ltx_citemacro_citet">Zhou et&nbsp;al. (<a href="#bib.bib46" title="" class="ltx_ref">2022a</a>)</cite> use multiple prompts to specify a single task and propose
to regularize via prompt consistency, encouraging
consistent predictions over the
prompts. This allows either
finetuning the model with extra unlabeled
training data, or direct application at inference time.
While <span id="S5.SS0.SSS0.Px4.p1.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> has similarities with the self-training literature, most self-training methods assume a specific <span id="S5.SS0.SSS0.Px4.p1.1.2" class="ltx_text ltx_font_italic">target task</span> as well as <span id="S5.SS0.SSS0.Px4.p1.1.3" class="ltx_text ltx_font_italic">unlabeled examples</span> under it; in contrast, <span id="S5.SS0.SSS0.Px4.p1.1.4" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> produces a variety of tasks from scratch.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Knowledge distillation.</h4>

<div id="S5.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px5.p1.1" class="ltx_p">Knowledge distillation&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Hinton et&nbsp;al. (<a href="#bib.bib9" title="" class="ltx_ref">2015</a>); Sanh et&nbsp;al. (<a href="#bib.bib26" title="" class="ltx_ref">2019</a>); West et&nbsp;al. (<a href="#bib.bib39" title="" class="ltx_ref">2021</a>); Magister et&nbsp;al. (<a href="#bib.bib18" title="" class="ltx_ref">2022</a>)</cite> often involves the transfer of knowledge from larger models to smaller ones. <span id="S5.SS0.SSS0.Px5.p1.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> can also be viewed as a form of “knowledge distillation", however, it differs from this line in the following ways: (1) the source and target of distillation are the same, i.e., a model’s knowledge is distilled to itself; (2) the content of distillation is in the form of an instruction task (i.e., instructions that define a task, and a set of examples that instantiate it).</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px6" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Bootstrapping with limited resources.</h4>

<div id="S5.SS0.SSS0.Px6.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px6.p1.1" class="ltx_p">A series of recent works use language models to bootstrap some inferences using specialized methods.
NPPrompt&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zhao et&nbsp;al. (<a href="#bib.bib45" title="" class="ltx_ref">2022</a>)</cite> provides a method to generate predictions for semantic labels without any finetuning. It uses a model’s own embeddings to automatically find words relevant to the label of the data sample and hence reduces the dependency on manual mapping from model prediction to label (verbalizers).
STAR&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Zelikman et&nbsp;al. (<a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite> iteratively leverages a small number of rationale examples and a large dataset without rationales, to bootstrap a model’s ability to perform reasoning. Self-Correction&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Welleck et&nbsp;al. (<a href="#bib.bib37" title="" class="ltx_ref">2023</a>)</cite> decouples an imperfect base generator (model) from a separate corrector that learns to iteratively correct imperfect generations and demonstrates improvement over the base generator. Our work instead focuses on bootstrapping new tasks in the instruction paradigm.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px7" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Multi-modal instruction-following.</h4>

<div id="S5.SS0.SSS0.Px7.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px7.p1.1" class="ltx_p">Instruction-following models have also been of interest in the multi-modal learning literature <cite class="ltx_cite ltx_citemacro_cite">Fried et&nbsp;al. (<a href="#bib.bib7" title="" class="ltx_ref">2018</a>); Shridhar et&nbsp;al. (<a href="#bib.bib29" title="" class="ltx_ref">2020</a>); Min et&nbsp;al. (<a href="#bib.bib21" title="" class="ltx_ref">2022</a>); Weir et&nbsp;al. (<a href="#bib.bib36" title="" class="ltx_ref">2022</a>)</cite>.
<span id="S5.SS0.SSS0.Px7.p1.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span>, as a general approach to expanding data, can potentially also be helpful in those settings, which we leave to future work.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We introduce <span id="S6.p1.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span>, a method to improve the instruction-following ability of LMs via their own generation of instruction data. On experimenting with vanilla <span id="S6.p1.1.2" class="ltx_text ltx_font_smallcaps">GPT3</span>, we automatically construct a large-scale dataset of 52K instructions for diverse tasks, and finetuning GPT3 on this data leads to a 33% absolute improvement on <span id="S6.p1.1.3" class="ltx_text ltx_font_smallcaps">SuperNI</span> over the original <span id="S6.p1.1.4" class="ltx_text ltx_font_smallcaps">GPT3</span>. Furthermore, we curate a set of expert-written instructions for novel tasks. Human evaluation on this set shows that tuning GPT3 with <span id="S6.p1.1.5" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> outperforms using existing public instruction datasets by a large margin and performs closely to <math id="S6.p1.1.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{001}}" display="inline"><semantics id="S6.p1.1.m1.1a"><msub id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml"><mtext id="S6.p1.1.m1.1.1.2" xref="S6.p1.1.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="S6.p1.1.m1.1.1.3" xref="S6.p1.1.m1.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><apply id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S6.p1.1.m1.1.1.1.cmml" xref="S6.p1.1.m1.1.1">subscript</csymbol><ci id="S6.p1.1.m1.1.1.2a.cmml" xref="S6.p1.1.m1.1.1.2"><mtext id="S6.p1.1.m1.1.1.2.cmml" xref="S6.p1.1.m1.1.1.2">InstructGPT</mtext></ci><ci id="S6.p1.1.m1.1.1.3a.cmml" xref="S6.p1.1.m1.1.1.3"><mtext mathsize="70%" id="S6.p1.1.m1.1.1.3.cmml" xref="S6.p1.1.m1.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>.
We hope <span id="S6.p1.1.6" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> can serve as the first step to align pretrained LMs to follow human instructions, and future work can build on top of this data to improve instruction-following models.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Broader Impact</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Beyond the immediate focus of this paper, we believe that <span id="S7.p1.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> may help bring more transparency to what happens “behind the scenes” of widely-used instruction-tuned models like <math id="S7.p1.1.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{}}" display="inline"><semantics id="S7.p1.1.m1.1a"><msub id="S7.p1.1.m1.1.1" xref="S7.p1.1.m1.1.1.cmml"><mtext id="S7.p1.1.m1.1.1.2" xref="S7.p1.1.m1.1.1.2a.cmml">InstructGPT</mtext><mrow id="S7.p1.1.m1.1.1.3" xref="S7.p1.1.m1.1.1.3a.cmml"></mrow></msub><annotation-xml encoding="MathML-Content" id="S7.p1.1.m1.1b"><apply id="S7.p1.1.m1.1.1.cmml" xref="S7.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S7.p1.1.m1.1.1.1.cmml" xref="S7.p1.1.m1.1.1">subscript</csymbol><ci id="S7.p1.1.m1.1.1.2a.cmml" xref="S7.p1.1.m1.1.1.2"><mtext id="S7.p1.1.m1.1.1.2.cmml" xref="S7.p1.1.m1.1.1.2">InstructGPT</mtext></ci><ci id="S7.p1.1.m1.1.1.3a.cmml" xref="S7.p1.1.m1.1.1.3"><mrow id="S7.p1.1.m1.1.1.3.cmml" xref="S7.p1.1.m1.1.1.3"></mrow></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.1.m1.1c">\text{InstructGPT}_{\text{}}</annotation></semantics></math> or ChatGPT.
Unfortunately, such industrial models remain behind API walls as their datasets are not released, and hence there is little understanding of their construction and why they demonstrate impressive capabilities.
The burden now falls on academia to better understand the source of success in these models and strive for better—and more open—models. We believe our findings in this paper demonstrate the importance of diverse instruction data, and our large synthetic dataset can be the first step toward higher-quality data for building better instruction-following models.
At this writing, the central idea of this paper has been adopted in several follow-up works for such endeavors <cite class="ltx_cite ltx_citemacro_citep">(Taori et&nbsp;al., <a href="#bib.bib32" title="" class="ltx_ref">2023</a>; Xu et&nbsp;al., <a href="#bib.bib41" title="" class="ltx_ref">2023</a>; Sun et&nbsp;al., <a href="#bib.bib31" title="" class="ltx_ref">2023</a>, i.a.)</cite>.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Limitations</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">Here, we discuss some limitations of this work to inspire future research in this direction.</p>
</div>
<section id="S8.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Tail phenomena.</h4>

<div id="S8.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S8.SS0.SSS0.Px1.p1.1" class="ltx_p"><span id="S8.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> depends on LMs, and it will inherit all the limitations that carry over with LMs.
As recent studies have shown&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Razeghi et&nbsp;al. (<a href="#bib.bib25" title="" class="ltx_ref">2022</a>); Kandpal et&nbsp;al. (<a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite>, <em id="S8.SS0.SSS0.Px1.p1.1.2" class="ltx_emph ltx_font_italic">tail phenomena</em> pose a serious challenge to the success of LMs. In other words, LMs’ largest gains correspond to the frequent uses of languages (head of the language use distribution), and there might be minimal gains in the low-frequency contexts.
Similarly, in the context of this work, it would not be surprising if the majority of the gains by <span id="S8.SS0.SSS0.Px1.p1.1.3" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> are skewed toward
tasks or instructions that present more frequently in the pretraining corpus.
As a consequence, the approach might show brittleness with respect to uncommon and creative instructions.</p>
</div>
</section>
<section id="S8.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Dependence on large models.</h4>

<div id="S8.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S8.SS0.SSS0.Px2.p1.1" class="ltx_p">Because of <span id="S8.SS0.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span>’s dependence on the inductive biases extracted from LMs, it might work best for larger models.
If true, this may create barriers to access for those who may not have large computing resources.
We hope future studies will carefully study the gains as a function of model size or various other parameters.
It is worthwhile to note that instruction-tuning with human annotation also suffers from a similar limitation: gains of instruction-tuning are higher for larger models&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Wei et&nbsp;al. (<a href="#bib.bib35" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
</section>
<section id="S8.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Reinforcing LM biases.</h4>

<div id="S8.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S8.SS0.SSS0.Px3.p1.1" class="ltx_p">A point of concern for the authors is the unintended consequences of this iterative algorithm, such as the amplification of problematic social biases (stereotypes or slurs about gender, race, etc.).
Relatedly, one observed challenge in this process is the algorithm’s difficulty in producing balanced labels, which reflected models’ prior biases.
We hope future work will lead to better understanding of the pros and cons of the approach.</p>
</div>
</section>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The authors would like to thank the anonymous reviewers for their constructive feedback. We especially thank Sewon Min, Eric Wallace, Ofir Press, and other members of UWNLP and AllenNLP for their encouraging feedback and intellectual support.
This work was supported in part by
DARPA MCS program through NIWC Pacific (N66001-19-2-4031),
ONR N00014-18-1-2826, ONR MURI N00014-18-1-2670,
and gifts from AI2 and an Allen Investigator award.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amini et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Massih-Reza Amini, Vasilii Feofanov, Loic Pauletto, Emilie Devijver, and Yury
Maximov. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2202.12040" title="" class="ltx_ref ltx_href">Self-training: A survey</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2202.12040</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bach et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Stephen&nbsp;H Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson, Colin Raffel,
Nihal&nbsp;V Nayak, Abheesht Sharma, Taewoon Kim, M&nbsp;Saiful Bari, Thibault Fevry,
et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2202.01279" title="" class="ltx_ref ltx_href">PromptSource: An
Integrated Development Environment and Repository for Natural Language
Prompts</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational
Linguistics (ACL) - System Demonstrations</em>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Tom&nbsp;B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, and et&nbsp;al. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html" title="" class="ltx_ref ltx_href">Language models are few-shot learners</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
(NeurIPS)</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Hyung&nbsp;Won Chung, Le&nbsp;Hou, Shayne Longpre, Barret Zoph, Yi&nbsp;Tay, William Fedus,
Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2210.11416" title="" class="ltx_ref ltx_href">Scaling
instruction-finetuned language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.11416</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Jingfei Du, Édouard Grave, Beliz Gunel, Vishrav Chaudhary, Onur Celebi,
Michael Auli, Veselin Stoyanov, and Alexis Conneau. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2021.naacl-main.426" title="" class="ltx_ref ltx_href">Self-training
improves pre-training for natural language understanding</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Conference of the North American Chapter of the Association
for Computational Linguistics (NAACL): Human Language Technologies</em>,
pages 5408–5418.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Steven&nbsp;Y Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi,
Teruko Mitamura, and Eduard Hovy. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2021.findings-acl.84/" title="" class="ltx_ref ltx_href">A survey of
data augmentation approaches for nlp</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational
Linguistics (ACL)&nbsp;ACL-IJCNLP - Findings</em>, pages 968–988.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fried et&nbsp;al. (2018)</span>
<span class="ltx_bibblock">
Daniel Fried, Ronghang Hu, Volkan Cirik, Anna Rohrbach, Jacob Andreas,
Louis-Philippe Morency, Taylor Berg-Kirkpatrick, Kate Saenko, Dan Klein, and
Trevor Darrell. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1806.02724" title="" class="ltx_ref ltx_href">Speaker-follower models for
vision-and-language navigation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
(NeurIPS)</em>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Junxian He, Jiatao Gu, Jiajun Shen, and Marc’Aurelio Ranzato. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1909.13788" title="" class="ltx_ref ltx_href">Revisiting self-training
for neural sequence generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations
(ICLR)</em>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton et&nbsp;al. (2015)</span>
<span class="ltx_bibblock">
Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et&nbsp;al. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1503.02531" title="" class="ltx_ref ltx_href">Distilling the knowledge in
a neural network</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
(NeurIPS)&nbsp;Workshop on Deep Learning</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich et&nbsp;al. (2022a)</span>
<span class="ltx_bibblock">
Or&nbsp;Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 2022a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2212.09689" title="" class="ltx_ref ltx_href">Unnatural instructions:
Tuning language models with (almost) no human labor</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.09689</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich et&nbsp;al. (2022b)</span>
<span class="ltx_bibblock">
Or&nbsp;Honovich, Uri Shaham, Samuel&nbsp;R Bowman, and Omer Levy. 2022b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2205.10782" title="" class="ltx_ref ltx_href">Instruction induction: From
few examples to natural language task descriptions</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.10782</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Jiaxin Huang, Shixiang&nbsp;Shane Gu, Le&nbsp;Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu,
and Jiawei Han. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2205.10782" title="" class="ltx_ref ltx_href">Large language models can
self-improve</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.11610</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kandpal et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel.
2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2211.08411" title="" class="ltx_ref ltx_href">Large language models
struggle to learn long-tail knowledge</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.08411</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kitaev et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Nikita Kitaev, Steven Cao, and Dan Klein. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P19-1340" title="" class="ltx_ref ltx_href">Multilingual
constituency parsing with self-attention and pre-training</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational
Linguistics (ACL)</em>, pages 3499–3505.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kitaev and Klein (2018)</span>
<span class="ltx_bibblock">
Nikita Kitaev and Dan Klein. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P18-1249" title="" class="ltx_ref ltx_href">Constituency parsing
with a self-attentive encoder</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational
Linguistics (ACL)</em>, pages 2676–2686.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lester et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2104.08691" title="" class="ltx_ref ltx_href">The power of scale for
parameter-efficient prompt tuning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP)</em>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Alisa Liu, Swabha Swayamdipta, Noah&nbsp;A. Smith, and Yejin Choi. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://preview.aclanthology.org/emnlp-22-ingestion/2022.findings-emnlp.508/" title="" class="ltx_ref ltx_href">WANLI: Worker and ai collaboration for natural language inference dataset
creation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP) - Findings</em>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Magister et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Lucie&nbsp;Charlotte Magister, Jonathan Mallinson, Jakub Adamek, Eric Malmi, and
Aliaksei Severyn. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2212.08410" title="" class="ltx_ref ltx_href">Teaching small language
models to reason</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.08410</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mekala et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Dheeraj Mekala, Tu&nbsp;Vu, Timo Schick, and Jingbo Shang. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2205.12604" title="" class="ltx_ref ltx_href">Leveraging qa datasets to
improve generative data augmentation</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.12604</em>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yu&nbsp;Meng, Martin Michalski, Jiaxin Huang, Yu&nbsp;Zhang, Tarek Abdelzaher, and Jiawei
Han. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2211.03044" title="" class="ltx_ref ltx_href">Tuning language models as
training data generators for augmentation-enhanced few-shot learning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning (ICML)</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
So&nbsp;Yeon Min, Devendra&nbsp;Singh Chaplot, Pradeep Ravikumar, Yonatan Bisk, and
Ruslan Salakhutdinov. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2110.07342" title="" class="ltx_ref ltx_href">FILM: Following
Instructions in Language with Modular Methods</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations
(ICLR)</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2104.08773" title="" class="ltx_ref ltx_href">Cross-Task Generalization
via Natural Language Crowdsourcing Instructions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational
Linguistics (ACL)</em>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeff Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll&nbsp;L Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et&nbsp;al.
2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2203.02155" title="" class="ltx_ref ltx_href">Training Language Models
to Follow Instructions with Human Feedback</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
(NeurIPS)</em>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J Liu. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1910.10683" title="" class="ltx_ref ltx_href">Exploring the limits of
transfer learning with a unified text-to-text transformer</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research (JMLR)</em>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Razeghi et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yasaman Razeghi, Robert&nbsp;L Logan&nbsp;IV, Matt Gardner, and Sameer Singh. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2202.07206" title="" class="ltx_ref ltx_href">Impact of pretraining term
frequencies on few-shot reasoning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2202.07206</em>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanh et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1910.01108" title="" class="ltx_ref ltx_href">Distilbert, a distilled
version of bert: smaller, faster, cheaper and lighter</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
(NeurIPS) Workshop on Energy Efficient Machine Learning and Cognitive
Computing</em>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanh et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid
Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M&nbsp;Saiful
Bari, Canwen Xu, Urmish Thakker, Shanya&nbsp;Sharma Sharma, Eliza Szczechla,
Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang,
Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng&nbsp;Xin Yong,
Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen,
Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason&nbsp;Alan Fries, Ryan
Teehan, Teven&nbsp;Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander&nbsp;M
Rush. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2110.08207" title="" class="ltx_ref ltx_href">Multitask Prompted
Training Enables Zero-Shot Task Generalization</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations
(ICLR)</em>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schick and Schütze (2021)</span>
<span class="ltx_bibblock">
Timo Schick and Hinrich Schütze. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2021.emnlp-main.555/" title="" class="ltx_ref ltx_href">Generating
datasets with pretrained language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP)</em>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shridhar et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han,
Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1912.01734" title="" class="ltx_ref ltx_href">ALFRED: A Benchmark for
Interpreting Grounded Instructions for Everyday Tasks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</em>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Chandan Singh, John&nbsp;X Morris, Jyoti Aneja, Alexander&nbsp;M Rush, and Jianfeng Gao.
2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2210.01848" title="" class="ltx_ref ltx_href">Explaining patterns in data
with language models via interpretable autoprompting</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.01848</em>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David
Cox, Yiming Yang, and Chuang Gan. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2305.03047" title="" class="ltx_ref ltx_href">Principle-driven
self-alignment of language models from scratch with minimal human
supervision</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.03047</em>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
Guestrin, Percy Liang, and Tatsunori&nbsp;B. Hashimoto. 2023.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tatsu-lab/stanford_alpaca</a>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza
Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut&nbsp;Selvan Dhanasekaran, Atharva
Naik, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi&nbsp;Gary Lai,
Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi,
Maitreya Patel, Kuntal&nbsp;Kumar Pal, Mehrad Moradshahi, Mihir Parmar, Mirali
Purohit, Neeraj Varshney, Phani&nbsp;Rohitha Kaza, Pulkit Verma, Ravsehaj&nbsp;Singh
Puri, Rushang Karia, Shailaja&nbsp;Keyur Sampat, Savan Doshi, Siddhartha Mishra,
Sujan Reddy, Sumanta Patro, Tanay Dixit, Xudong Shen, Chitta Baral, Yejin
Choi, Noah&nbsp;A. Smith, Hannaneh Hajishirzi, and Daniel Khashabi. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2204.07705" title="" class="ltx_ref ltx_href">Super-naturalinstructions:
Generalization via declarative instructions on 1600+ tasks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP)</em>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Zirui Wang, Adams&nbsp;Wei Yu, Orhan Firat, and Yuan Cao. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2109.09193" title="" class="ltx_ref ltx_href">Towards zero-label language
learning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.09193</em>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams&nbsp;Wei Yu, Brian Lester,
Nan Du, Andrew&nbsp;M. Dai, and Quoc&nbsp;V Le. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2109.01652" title="" class="ltx_ref ltx_href">Finetuned Language Models
are Zero-Shot Learners</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations
(ICLR)</em>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weir et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Nathaniel Weir, Xingdi Yuan, Marc-Alexandre Côté, Matthew Hausknecht,
Romain Laroche, Ida Momennejad, Harm Van&nbsp;Seijen, and Benjamin Van&nbsp;Durme.
2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2203.04806" title="" class="ltx_ref ltx_href">One-Shot Learning from a
Demonstration with Hierarchical Latent Language</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.04806</em>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Welleck et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Sean Welleck, Ximing Lu, Peter West, Faeze Brahman, Tianxiao Shen, Daniel
Khashabi, and Yejin Choi. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2211.00053" title="" class="ltx_ref ltx_href">Generating sequences by
learning to self-correct</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations
(ICLR)</em>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weller et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Orion Weller, Nicholas Lourie, Matt Gardner, and Matthew Peters. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2020.emnlp-main.105/" title="" class="ltx_ref ltx_href">Learning from
Task Descriptions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP)</em>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">West et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Peter West, Chandra Bhagavatula, Jack Hessel, Jena&nbsp;D Hwang, Liwei Jiang,
Ronan&nbsp;Le Bras, Ximing Lu, Sean Welleck, and Yejin Choi. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2022.naacl-main.341/" title="" class="ltx_ref ltx_href">Symbolic
knowledge distillation: from general language models to commonsense models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Conference of the North American Chapter of the Association
for Computational Linguistics (NAACL)</em>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc&nbsp;V Le. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1911.04252" title="" class="ltx_ref ltx_href">Self-training with noisy
student improves imagenet classification</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</em>, pages 10687–10698.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2304.01196" title="" class="ltx_ref ltx_href">Baize: An open-source chat
model with parameter-efficient tuning on self-chat data</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.01196</em>.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Yiben Yang, Chaitanya Malaviya, Jared Fernandez, Swabha Swayamdipta, Ronan&nbsp;Le
Bras, Ji-Ping Wang, Chandra Bhagavatula, Yejin Choi, and Doug Downey. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2020.findings-emnlp.90" title="" class="ltx_ref ltx_href">Generative
data augmentation for commonsense reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP) - Findings</em>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Seonghyeon Ye, Doyoung Kim, Joel Jang, Joongbo Shin, and Minjoon Seo. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2210.02969" title="" class="ltx_ref ltx_href">Guess the instruction!
making language models stronger zero-shot learners</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.02969</em>.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zelikman et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Eric Zelikman, Jesse Mu, Noah&nbsp;D Goodman, and Yuhuai&nbsp;Tony Wu. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2203.14465" title="" class="ltx_ref ltx_href">STar: Self-taught
reasoner bootstrapping reasoning with reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
(NeurIPS)</em>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Xuandong Zhao, Siqi Ouyang, Zhiguo Yu, Ming Wu, and Lei Li. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2212.06950" title="" class="ltx_ref ltx_href">Pre-trained language models
can be fully zero-shot learners</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.06950</em>.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2022a)</span>
<span class="ltx_bibblock">
Chunting Zhou, Junxian He, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham
Neubig. 2022a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2205.00049" title="" class="ltx_ref ltx_href">Prompt Consistency for
Zero-Shot Task Generalization</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP) - Findings</em>.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2022b)</span>
<span class="ltx_bibblock">
Yongchao Zhou, Andrei&nbsp;Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis,
Harris Chan, and Jimmy Ba. 2022b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2211.01910" title="" class="ltx_ref ltx_href">Large language models are
human-level prompt engineers</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.01910</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p ltx_align_center"><span id="p1.1.1" class="ltx_text ltx_font_bold">Supplemental Material</span></p>
</div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Implementation Details</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Writing the Seed Tasks</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p id="A1.SS1.p1.1" class="ltx_p">Our method relies on a set of seed tasks to bootstrap the generation. The seed tasks are important for both encouraging the task diversity and demonstrating correct ways for solving the diverse tasks. For example, with coding tasks to prompt the model, it has a larger chance to generate coding-related tasks; it’s also better to have coding output to guide the model in writing code for new tasks. So, the more diverse the seed tasks are, the more diverse and better quality the generated tasks will be.</p>
</div>
<div id="A1.SS1.p2" class="ltx_para">
<p id="A1.SS1.p2.1" class="ltx_p">Our seed tasks were written when we initiated this project, and targeted for the diverse and interesting usages of LLMs. The tasks were written by the authors and our labmates at UWNLP, without explicit reference to existing datasets or specific testing tasks. We further categorized the tasks into classification and non-classification tasks, based on whether the task has a limited output label space. In total, there are 25 classification tasks and 150 non-classification tasks. We release this data in our GitHub repository.<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a target="_blank" href="https://github.com/yizhongw/self-instruct/blob/main/human_eval/user_oriented_instructions.jsonl" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/yizhongw/self-instruct/blob/main/human_eval/user_oriented_instructions.jsonl</a></span></span></span></p>
</div>
<div id="A1.SS1.p3" class="ltx_para">
<p id="A1.SS1.p3.1" class="ltx_p">To provide a sense of how much the model is generalizing beyond these seed tasks, we further quantify the overlap between the instructions of these seed tasks and the instructions of our test sets, including both <span id="A1.SS1.p3.1.1" class="ltx_text ltx_font_smallcaps">SuperNI</span> task instructions (§<a href="#S4.SS3" title="4.3 Experiment 1: Zero-Shot Generalization on SuperNI benchmark ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>) and the user-oriented instructions in our human evaluation(§<a href="#S4.SS4" title="4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>). We compute ROUGE-L similarities between each seed instruction and its most similar instruction in the test set. The distribution of the ROUGE-L scores are plotted in <a href="#A1.F8" title="Figure 8 ‣ A.1 Writing the Seed Tasks ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure&nbsp;8</span></a>, with the average ROUGE-L similarity between the seed instructions and <span id="A1.SS1.p3.1.2" class="ltx_text ltx_font_smallcaps">SuperNI</span> as 0.21, and the average ROUGE-L similarity between the seed instructions and user-oriented instructions as 0.34. We see a decent difference between the seed tasks and both test sets. There is exactly one identical seed instruction occurring in the user-oriented instruction test set, which is “answer the following question” and the following questions are actually very different.</p>
</div>
<figure id="A1.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A1.F8.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.10560/assets/x10.png" id="A1.F8.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="311" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A1.F8.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2212.10560/assets/x11.png" id="A1.F8.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="310" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Distribution of the ROUGE-L scores between seed instructions and their most similar instructions in <span id="A1.F8.4.1" class="ltx_text ltx_font_smallcaps">SuperNI</span> (left) and the 252 user-oriented instructions (right).</figcaption>
</figure>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Querying the GPT3 API</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p id="A1.SS2.p1.1" class="ltx_p">We use different sets of hyperparameters when querying GPT3 API for different purposes. These hyperparameters are found to work well with the GPT3 model (“davinci” engine) and the other instruction-tuned <span id="A1.SS2.p1.1.1" class="ltx_text ltx_font_smallcaps">GPT3</span> variants. We listed them in <a href="#A1.T4" title="Table 4 ‣ A.2 Querying the GPT3 API ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;4</span></a>. OpenAI charges $0.02 per 1000 tokens for making completion request to the “davinci” engine as of December, 2022. The generation of our entire dataset cost around $600.</p>
</div>
<figure id="A1.T4" class="ltx_table">
<table id="A1.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A1.T4.1.1" class="ltx_tr">
<td id="A1.T4.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Experiments <math id="A1.T4.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A1.T4.1.1.1.m1.1a"><mo stretchy="false" id="A1.T4.1.1.1.m1.1.1" xref="A1.T4.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A1.T4.1.1.1.m1.1b"><ci id="A1.T4.1.1.1.m1.1.1.cmml" xref="A1.T4.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="A1.T4.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Temp.</td>
<td id="A1.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Top_P</td>
<td id="A1.T4.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Freq. Penalty</td>
<td id="A1.T4.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Presence Penalty</td>
<td id="A1.T4.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Beam Size</td>
<td id="A1.T4.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Max Length</td>
<td id="A1.T4.1.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Stop Sequences</td>
</tr>
<tr id="A1.T4.1.2" class="ltx_tr">
<td id="A1.T4.1.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Generating instructions</td>
<td id="A1.T4.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0.7</td>
<td id="A1.T4.1.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0.5</td>
<td id="A1.T4.1.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">2</td>
<td id="A1.T4.1.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td id="A1.T4.1.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">1024</td>
<td id="A1.T4.1.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">"\n\n", "\n16", "16.", "16 ."</td>
</tr>
<tr id="A1.T4.1.3" class="ltx_tr">
<td id="A1.T4.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">Identifying clf. tasks</td>
<td id="A1.T4.1.3.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.3.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.3.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.3.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td id="A1.T4.1.3.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">3</td>
<td id="A1.T4.1.3.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">"\n", "Task:"</td>
</tr>
<tr id="A1.T4.1.4" class="ltx_tr">
<td id="A1.T4.1.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">Generating instances</td>
<td id="A1.T4.1.4.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.4.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.4.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.4.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1.5</td>
<td id="A1.T4.1.4.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td id="A1.T4.1.4.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">300</td>
<td id="A1.T4.1.4.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">"Task:"</td>
</tr>
<tr id="A1.T4.1.5" class="ltx_tr">
<td id="A1.T4.1.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">Evaluating models</td>
<td id="A1.T4.1.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.5.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.5.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1024</td>
<td id="A1.T4.1.5.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">None (default)</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Hyper-parameters for querying OpenAI API in different experiments.</figcaption>
</figure>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Finetuning GPT3</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p id="A1.SS3.p1.2" class="ltx_p"><span id="A1.SS3.p1.1.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="A1.SS3.p1.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="A1.SS3.p1.1.1.m1.1a"><msub id="A1.SS3.p1.1.1.m1.1.1" xref="A1.SS3.p1.1.1.m1.1.1.cmml"><mi id="A1.SS3.p1.1.1.m1.1.1a" xref="A1.SS3.p1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="A1.SS3.p1.1.1.m1.1.1.1" xref="A1.SS3.p1.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.1.1.m1.1b"><apply id="A1.SS3.p1.1.1.m1.1.1.cmml" xref="A1.SS3.p1.1.1.m1.1.1"><ci id="A1.SS3.p1.1.1.m1.1.1.1a.cmml" xref="A1.SS3.p1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="A1.SS3.p1.1.1.m1.1.1.1.cmml" xref="A1.SS3.p1.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> and some of our baselines are finetuned from <span id="A1.SS3.p1.2.3" class="ltx_text ltx_font_smallcaps">GPT3</span> model (“davinci” engine with 175B parameters). We conduct this finetuning via OpenAI’s finetuning API.<span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>
<a target="_blank" href="https://beta.openai.com/docs/guides/fine-tuning" title="" class="ltx_ref ltx_href">See the the details on OpenAI’s API.</a>
</span></span></span> While the details of how the model is finetuned with this API are not currently available (e.g., which parameters are updated, or what the optimizer is), we tune all our models with the default hyperparameters of this API so that the results are comparable. We only set the “prompt_loss_weight” to 0 since we find this works better in our case, and every finetuning experiment is trained for two epochs to avoid overfitting the training tasks. Finetuning is charged based on the number of tokens in the training file. In our case, finetuning <span id="A1.SS3.p1.2.2" class="ltx_text ltx_font_smallcaps">GPT3<math id="A1.SS3.p1.2.2.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="A1.SS3.p1.2.2.m1.1a"><msub id="A1.SS3.p1.2.2.m1.1.1" xref="A1.SS3.p1.2.2.m1.1.1.cmml"><mi id="A1.SS3.p1.2.2.m1.1.1a" xref="A1.SS3.p1.2.2.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="A1.SS3.p1.2.2.m1.1.1.1" xref="A1.SS3.p1.2.2.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.2.2.m1.1b"><apply id="A1.SS3.p1.2.2.m1.1.1.cmml" xref="A1.SS3.p1.2.2.m1.1.1"><ci id="A1.SS3.p1.2.2.m1.1.1.1a.cmml" xref="A1.SS3.p1.2.2.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="A1.SS3.p1.2.2.m1.1.1.1.cmml" xref="A1.SS3.p1.2.2.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.2.2.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> from the <span id="A1.SS3.p1.2.4" class="ltx_text ltx_font_smallcaps">GPT3</span> model on the entire generated data cost $338.</p>
</div>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Prompting Templates for Data Generation</h3>

<div id="A1.SS4.p1" class="ltx_para">
<p id="A1.SS4.p1.1" class="ltx_p"><span id="A1.SS4.p1.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> relies on a number of prompting templates in order to elicit the generation from language models. Here we provide our four templates for generating the instruction (<a href="#A1.T5" title="Table 5 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;5</span></a>), classifying whether an instruction represents a classification task or not (<a href="#A1.T6" title="Table 6 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;6</span></a>), generating non-classification instances with the input-first approach (<a href="#A1.T7" title="Table 7 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;7</span></a>), and generating classification instances with the output-first approach (<a href="#A1.T8" title="Table 8 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;8</span></a>).</p>
</div>
<figure id="A1.T5" class="ltx_table">
<p id="A1.T5.1" class="ltx_p ltx_align_center">
<span id="A1.T5.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle ltx_framed ltx_framed_rectangle" style="width:232.8pt;">
<span id="A1.T5.1.1.1" class="ltx_p"><span id="A1.T5.1.1.1.1" class="ltx_text ltx_font_typewriter">Come up with a series of tasks:
<br class="ltx_break">
<br class="ltx_break">Task 1: {instruction for existing task 1} 
<br class="ltx_break">Task 2: {instruction for existing task 2} 
<br class="ltx_break">Task 3: {instruction for existing task 3} 
<br class="ltx_break">Task 4: {instruction for existing task 4} 
<br class="ltx_break">Task 5: {instruction for existing task 5} 
<br class="ltx_break">Task 6: {instruction for existing task 6} 
<br class="ltx_break">Task 7: {instruction for existing task 7} 
<br class="ltx_break">Task 8: {instruction for existing task 8} 
<br class="ltx_break">Task 9:</span></span>
</span>
</p>
<br class="ltx_break ltx_break">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Prompt used for generating new instructions. 8 existing instructions are randomly sampled from the task pool for in-context demonstration. The model is allowed to generate instructions for new tasks, until it stops its generation, reaches its length limit or generates “Task 16” tokens.</figcaption>
</figure>
<figure id="A1.T6" class="ltx_table">
<p id="A1.T6.1" class="ltx_p ltx_align_center">
<span id="A1.T6.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle ltx_framed ltx_framed_rectangle" style="width:430.8pt;">
<span id="A1.T6.1.1.1.1" class="ltx_p"><span id="A1.T6.1.1.1.1.1" class="ltx_text ltx_font_typewriter">Can the following task be regarded as a classification task with finite output labels?
<br class="ltx_break">
<br class="ltx_break">Task: Given my personality and the job, tell me if I would be suitable.
<br class="ltx_break">Is it classification? Yes
<br class="ltx_break">
<br class="ltx_break">Task: Give me an example of a time when you had to use your sense of humor.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Replace the placeholders in the given text with appropriate named entities.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Fact checking - tell me if the statement is true, false, or unknown, based on your knowledge and common sense.
<br class="ltx_break">Is it classification? Yes
<br class="ltx_break">
<br class="ltx_break">Task: Return the SSN number for the person.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Detect if the Reddit thread contains hate speech.
<br class="ltx_break">Is it classification? Yes
<br class="ltx_break">
<br class="ltx_break">Task: Analyze the sentences below to identify biases.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Select the longest sentence in terms of the number of words in the paragraph, output the sentence index.
<br class="ltx_break">Is it classification? Yes
<br class="ltx_break">
<br class="ltx_break">Task: Find out the toxic word or phrase in the sentence.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Rank these countries by their population.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: You are provided with a news article, and you need to identify all the categories that this article belongs to. Possible categories include: Music, Sports, Politics, Tech, Finance, Basketball, Soccer, Tennis, Entertainment, Digital Game, World News. Output its categories one by one, seperated by comma.
<br class="ltx_break">Is it classification? Yes
<br class="ltx_break">
<br class="ltx_break">Task: Given the name of an exercise, explain how to do it.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Select the oldest person from the list.
<br class="ltx_break">Is it classification? Yes
<br class="ltx_break">
<br class="ltx_break">Task: Find the four smallest perfect numbers.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Does the information in the document supports the claim? You can answer "Support" or "Unsupport".
<br class="ltx_break">Is it classification? Yes
<br class="ltx_break">
<br class="ltx_break">Task: Create a detailed budget for the given hypothetical trip.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Given a sentence, detect if there is any potential stereotype in it. If so, you should explain the stereotype. Else, output no.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break"><math id="A1.T6.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\cdots" display="inline"><semantics id="A1.T6.1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="A1.T6.1.1.1.1.1.m1.1.1" xref="A1.T6.1.1.1.1.1.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A1.T6.1.1.1.1.1.m1.1b"><ci id="A1.T6.1.1.1.1.1.m1.1.1.cmml" xref="A1.T6.1.1.1.1.1.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.1.1.1.1.1.m1.1c">\cdots</annotation></semantics></math> 
<br class="ltx_break">
<br class="ltx_break">Task: To make the pairs have the same analogy, write the fourth word.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Given a set of numbers, find all possible subsets that sum to a given number.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: {instruction for the target task}</span></span>
</span>
</p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Prompt used for classifying whether a task instruction is a classification task or not.</figcaption>
</figure>
<figure id="A1.T7" class="ltx_table">
<p id="A1.T7.1" class="ltx_p ltx_align_center">
<span id="A1.T7.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle ltx_framed ltx_framed_rectangle" style="width:430.8pt;">
<span id="A1.T7.1.1.1.1" class="ltx_p"><span id="A1.T7.1.1.1.1.1" class="ltx_text ltx_font_typewriter">Come up with examples for the following tasks. Try to generate multiple examples when possible. If the task doesn’t require additional input, you can generate the output directly.
<br class="ltx_break">
<br class="ltx_break">Task: Which exercises are best for reducing belly fat at home?
<br class="ltx_break">Output:
<br class="ltx_break">- Lying Leg Raises
<br class="ltx_break">- Leg In And Out
<br class="ltx_break">- Plank
<br class="ltx_break">- Side Plank
<br class="ltx_break">- Sit-ups
<br class="ltx_break">
<br class="ltx_break">Task: Extract all the country names in the paragraph, list them separated by commas.
<br class="ltx_break">Example 1
<br class="ltx_break">Paragraph: Dr. No is the sixth novel by the English author Ian Fleming to feature his British Secret Service agent James Bond. Written at Fleming’s Goldeneye estate in Jamaica, it was first published in the United Kingdom by Jonathan Cape in 1958. In the novel Bond looks into the disappearance in Jamaica of two fellow MI6 operatives who had been investigating Doctor No. Bond travels to No’s Caribbean island and meets Honeychile Rider, who is there to collect shells. They are captured and taken to a luxurious facility carved into a mountain. The character of Doctor No, the son of a German missionary and a Chinese woman, was influenced by Sax Rohmer’s Fu Manchu stories. Dr. No was the first of Fleming’s novels to face widespread negative reviews in Britain, but it was received more favourably in the United States.
<br class="ltx_break">Output: English, British, Jamaica, the United Kingdom, German, Chinese, Britain, the United States.
<br class="ltx_break">
<br class="ltx_break">Task: Converting 85 F to Celsius.
<br class="ltx_break">Output: 85°F = 29.44°C
<br class="ltx_break">
<br class="ltx_break">Task: Sort the given list ascendingly. 
<br class="ltx_break">Example 1
<br class="ltx_break">List: [10, 92, 2, 5, -4, 92, 5, 101]
<br class="ltx_break">Output: [-4, 2, 5, 5, 10, 92, 92, 101]
<br class="ltx_break">Example 2
<br class="ltx_break">Input 2 - List: [9.99, 10, -5, -1000, 5e6, 999]
<br class="ltx_break">Output: [-1000, -5, 9.99, 10, 999, 5e6]
<br class="ltx_break">
<br class="ltx_break">Task: Suggest a better and more professional rephrasing of the following sentence.
<br class="ltx_break">Example 1
<br class="ltx_break">Sentence: This house is surprisingly not constructed very well, and you probably need more money to fix it after you buy it. If you ask me, I would suggest you to consider other candidates.
<br class="ltx_break">Output: This house does not seem to be constructed well, so you may need to spend more money to fix it after you purchase it. I would suggest that you look at other properties.
<br class="ltx_break">Example 2
<br class="ltx_break">Sentence: Just so you know, we did an experiment last week and found really surprising results - language model can improve itself!
<br class="ltx_break">Output: Our experiments last week demonstrated surprising results, proving that the language model can improve itself.
<br class="ltx_break">
<br class="ltx_break"><math id="A1.T7.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\cdots" display="inline"><semantics id="A1.T7.1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="A1.T7.1.1.1.1.1.m1.1.1" xref="A1.T7.1.1.1.1.1.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A1.T7.1.1.1.1.1.m1.1b"><ci id="A1.T7.1.1.1.1.1.m1.1.1.cmml" xref="A1.T7.1.1.1.1.1.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.1.1.1.1.1.m1.1c">\cdots</annotation></semantics></math> 
<br class="ltx_break">
<br class="ltx_break">Task: Turn down a job offer by sending an email to a recruiter explaining the reason.
<br class="ltx_break">Output: Hi [Recruiter],
<br class="ltx_break">Thank you so much for the generous offer to join your team. As we discussed, I’ve admired the company for a number of years, and am a proud endorser of its products. However, after further consideration of where I currently am in my career, I’ve decided to accept an offer at another company.
<br class="ltx_break">I would love to stay in touch with you and have already started following you on [Social Media Platform]. Again, thank you so much for your time and consideration.
<br class="ltx_break">Thanks again,
<br class="ltx_break">[Your Name]
<br class="ltx_break">&nbsp;
<br class="ltx_break">Task: {Instruction for the target task}</span></span>
</span>
</p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Prompt used for the input-first approach of instance generation. The model is prompted to generate the instance first, and then generate the corresponding output. For instructions that don’t require additional input, the output is allowed to be generated directly.</figcaption>
</figure>
<figure id="A1.T8" class="ltx_table">
<p id="A1.T8.1" class="ltx_p ltx_align_center">
<span id="A1.T8.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle ltx_framed ltx_framed_rectangle" style="width:430.8pt;">
<span id="A1.T8.1.1.1.1" class="ltx_p"><span id="A1.T8.1.1.1.1.1" class="ltx_text ltx_font_typewriter">Given the classification task definition and the class labels, generate an input that corresponds to each of the class labels. If the task doesn’t require input, just generate the correct class label.
<br class="ltx_break">
<br class="ltx_break">Task: Classify the sentiment of the sentence into positive, negative, or mixed.
<br class="ltx_break">Class label: mixed
<br class="ltx_break">Sentence: I enjoy the flavor of the restaurant but their service is too slow.
<br class="ltx_break">Class label: Positive
<br class="ltx_break">Sentence: I had a great day today. The weather was beautiful and I spent time with friends.
<br class="ltx_break">Class label: Negative
<br class="ltx_break">Sentence: I was really disappointed by the latest superhero movie. I would not recommend it.
<br class="ltx_break">
<br class="ltx_break">Task: Given a dialogue, classify whether the user is satisfied with the service. You should respond with "Satisfied" or "Unsatisfied".
<br class="ltx_break">Class label: Satisfied
<br class="ltx_break">Dialogue:
<br class="ltx_break">- Agent: Thank you for your feedback. We will work to improve our service in the future.
<br class="ltx_break">- Customer: I am happy with the service you provided. Thank you for your help.
<br class="ltx_break">Class label: Unsatisfied
<br class="ltx_break">Dialogue:
<br class="ltx_break">- Agent: Sorry that we will cancel your order. You will get a refund within 7 business days.
<br class="ltx_break">- Customer: oh that takes too long. I want you to take quicker action on this.
<br class="ltx_break">
<br class="ltx_break">Task: Given a political opinion, classify whether the speaker is a Democrat or Republican.
<br class="ltx_break">Class label: Democrats
<br class="ltx_break">Opinion: I believe, all should have access to quality healthcare regardless of their income.
<br class="ltx_break">Class label: Republicans
<br class="ltx_break">Opinion: I believe that people should be able to keep more of their hard-earned money and should not be taxed at high rates.
<br class="ltx_break">
<br class="ltx_break">Task: Tell me if the following email is a promotion email or not.
<br class="ltx_break">Class label: Promotion
<br class="ltx_break">Email: Check out our amazing new sale! We’ve got discounts on all of your favorite products.
<br class="ltx_break">Class label: Not Promotion
<br class="ltx_break">Email: We hope you are doing well. Let us know if you need any help.
<br class="ltx_break">
<br class="ltx_break">Task: Detect if the Reddit thread contains hate speech.
<br class="ltx_break">Class label: Hate Speech
<br class="ltx_break">Thread: All people of color are stupid and should not be allowed to vote.
<br class="ltx_break">Class label: Not Hate Speech
<br class="ltx_break">Thread: The best way to cook a steak on the grill.
<br class="ltx_break">
<br class="ltx_break">Task: Does the document supports the claim? Answer with "Support" or "Unsupport".
<br class="ltx_break">Class label: Unsupport
<br class="ltx_break">Document: After a record-breaking run that saw mortgage rates plunge to all-time lows and home prices soar to new highs, the U.S. housing market finally is slowing. While demand and price gains are cooling, any correction is likely to be a modest one, housing economists and analysts say. No one expects price drops on the scale of the declines experienced during the Great Recession.
<br class="ltx_break">Claim: The US housing market is going to crash soon.
<br class="ltx_break">Class label: Support
<br class="ltx_break">Document: The U.S. housing market is showing signs of strain, with home sales and prices slowing in many areas. Mortgage rates have risen sharply in recent months, and the number of homes for sale is increasing. This could be the beginning of a larger downturn, with some economists predicting a potential housing crash in the near future.
<br class="ltx_break">Claim: The US housing market is going to crash soon.
<br class="ltx_break">
<br class="ltx_break"><math id="A1.T8.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\cdots" display="inline"><semantics id="A1.T8.1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="A1.T8.1.1.1.1.1.m1.1.1" xref="A1.T8.1.1.1.1.1.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A1.T8.1.1.1.1.1.m1.1b"><ci id="A1.T8.1.1.1.1.1.m1.1.1.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.1.1.1.1.1.m1.1c">\cdots</annotation></semantics></math> 
<br class="ltx_break">
<br class="ltx_break">Task: Which of the following is not an input type? (a) number (b) date (c) phone number (d) email address (e) all of these are valid inputs.
<br class="ltx_break">Class label: (e)
<br class="ltx_break">
<br class="ltx_break">Task: {instruction for the target task}</span></span>
</span>
</p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Prompt used for the output-first approach of instance generation. The model is prompted to generate the class label first, and then generate the corresponding input. This prompt is used for generating the instances for classification tasks.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Human Evaluation Details for Following the User-oriented Instructions</h2>

<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Human Evaluation Setup</h3>

<div id="A2.SS1.p1" class="ltx_para">
<p id="A2.SS1.p1.1" class="ltx_p">Here we provide more details for the human evaluation described in §<a href="#S4.SS4" title="4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a> for rating the models’ responses to the 252 user-oriented instructions. To ensure faithful and reliable evaluation, we asked two authors of these instructions (and of this paper) to judge model predictions. These two evaluators coordinated the standards for the 4-level rating system before starting annotation and then each of them rated all the instances independently. They were presented with the instruction, instance input, target output (as a reference), and model responses. Model responses are listed in random order, with all the model information anonymized.
<a href="#A2.F9" title="Figure 9 ‣ B.1 Human Evaluation Setup ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure&nbsp;9</span></a> provides a screenshot of the annotation interface. The reported performance in this paper is based on the results from one of the evaluators, and the trends from the other evaluator’s results are the same.</p>
</div>
<figure id="A2.F9" class="ltx_figure"><img src="/html/2212.10560/assets/figures/human_eval_screenshot.png" id="A2.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="410" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Human evaluation in done using a Google sheet, with predictions from different models present in random order and the model information being anonymized. Our expert evaluators are required to read the instruction and input, refer to the target, and then select the rating for the model’s response from A/B/C/D, corresponding to the 4 levels described in §<a href="#S4.SS4" title="4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>.</figcaption>
</figure>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Human Evaluation Agreement</h3>

<div id="A2.SS2.p1" class="ltx_para">
<p id="A2.SS2.p1.1" class="ltx_p">To measure how reliable our human evaluation is, we calculate the inner-rater agreement between our two evaluators.</p>
</div>
<div id="A2.SS2.p2" class="ltx_para">
<p id="A2.SS2.p2.3" class="ltx_p">We first report Cohen’s <math id="A2.SS2.p2.1.m1.1" class="ltx_Math" alttext="\kappa" display="inline"><semantics id="A2.SS2.p2.1.m1.1a"><mi id="A2.SS2.p2.1.m1.1.1" xref="A2.SS2.p2.1.m1.1.1.cmml">κ</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p2.1.m1.1b"><ci id="A2.SS2.p2.1.m1.1.1.cmml" xref="A2.SS2.p2.1.m1.1.1">𝜅</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p2.1.m1.1c">\kappa</annotation></semantics></math>, which is commonly used to measure inter-rater agreement for <span id="A2.SS2.p2.3.1" class="ltx_text ltx_font_italic">categorical</span> items. When calculating this, we treat the 4-level rating (A-D) as a categorical variable, leading to a <math id="A2.SS2.p2.2.m2.1" class="ltx_Math" alttext="\kappa" display="inline"><semantics id="A2.SS2.p2.2.m2.1a"><mi id="A2.SS2.p2.2.m2.1.1" xref="A2.SS2.p2.2.m2.1.1.cmml">κ</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p2.2.m2.1b"><ci id="A2.SS2.p2.2.m2.1.1.cmml" xref="A2.SS2.p2.2.m2.1.1">𝜅</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p2.2.m2.1c">\kappa</annotation></semantics></math> of 0.58, which is a moderate agreement according to common practice.<span id="footnote13" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a target="_blank" href="https://en.wikipedia.org/wiki/Cohen%27s_kappa" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://en.wikipedia.org/wiki/Cohen%27s_kappa</a></span></span></span> Furthermore, we also calculate the agreement of our evaluators on classifying acceptable responses ((A or B) vs. (C or D)), with a final <math id="A2.SS2.p2.3.m3.1" class="ltx_Math" alttext="\kappa" display="inline"><semantics id="A2.SS2.p2.3.m3.1a"><mi id="A2.SS2.p2.3.m3.1.1" xref="A2.SS2.p2.3.m3.1.1.cmml">κ</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p2.3.m3.1b"><ci id="A2.SS2.p2.3.m3.1.1.cmml" xref="A2.SS2.p2.3.m3.1.1">𝜅</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p2.3.m3.1c">\kappa</annotation></semantics></math> of 0.75, indicating substantial agreement.</p>
</div>
<div id="A2.SS2.p3" class="ltx_para">
<p id="A2.SS2.p3.2" class="ltx_p">We also compute the Spearman correlation coefficient <math id="A2.SS2.p3.1.m1.1" class="ltx_Math" alttext="\rho" display="inline"><semantics id="A2.SS2.p3.1.m1.1a"><mi id="A2.SS2.p3.1.m1.1.1" xref="A2.SS2.p3.1.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p3.1.m1.1b"><ci id="A2.SS2.p3.1.m1.1.1.cmml" xref="A2.SS2.p3.1.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p3.1.m1.1c">\rho</annotation></semantics></math> between the ratings of our two evaluators by treating the rating as an ordinal variable (A&gt;B&gt;C&gt;D). The final coefficient is <math id="A2.SS2.p3.2.m2.1" class="ltx_Math" alttext="\rho=0.81" display="inline"><semantics id="A2.SS2.p3.2.m2.1a"><mrow id="A2.SS2.p3.2.m2.1.1" xref="A2.SS2.p3.2.m2.1.1.cmml"><mi id="A2.SS2.p3.2.m2.1.1.2" xref="A2.SS2.p3.2.m2.1.1.2.cmml">ρ</mi><mo id="A2.SS2.p3.2.m2.1.1.1" xref="A2.SS2.p3.2.m2.1.1.1.cmml">=</mo><mn id="A2.SS2.p3.2.m2.1.1.3" xref="A2.SS2.p3.2.m2.1.1.3.cmml">0.81</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS2.p3.2.m2.1b"><apply id="A2.SS2.p3.2.m2.1.1.cmml" xref="A2.SS2.p3.2.m2.1.1"><eq id="A2.SS2.p3.2.m2.1.1.1.cmml" xref="A2.SS2.p3.2.m2.1.1.1"></eq><ci id="A2.SS2.p3.2.m2.1.1.2.cmml" xref="A2.SS2.p3.2.m2.1.1.2">𝜌</ci><cn type="float" id="A2.SS2.p3.2.m2.1.1.3.cmml" xref="A2.SS2.p3.2.m2.1.1.3">0.81</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p3.2.m2.1c">\rho=0.81</annotation></semantics></math>, indicating a high correlation between the two evaluators.</p>
</div>
</section>
<section id="A2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Example Predictions from <span id="A2.SS3.1.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="A2.SS3.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="A2.SS3.1.1.m1.1b"><msub id="A2.SS3.1.1.m1.1.1" xref="A2.SS3.1.1.m1.1.1.cmml"><mi id="A2.SS3.1.1.m1.1.1b" xref="A2.SS3.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="A2.SS3.1.1.m1.1.1.1" xref="A2.SS3.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.SS3.1.1.m1.1c"><apply id="A2.SS3.1.1.m1.1.1.cmml" xref="A2.SS3.1.1.m1.1.1"><ci id="A2.SS3.1.1.m1.1.1.1a.cmml" xref="A2.SS3.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="A2.SS3.1.1.m1.1.1.1.cmml" xref="A2.SS3.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.1.1.m1.1d">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>
</h3>

<div id="A2.SS3.p1" class="ltx_para">
<p id="A2.SS3.p1.1" class="ltx_p">We present a selection of user-oriented tasks, the corresponding <span id="A2.SS3.p1.1.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="A2.SS3.p1.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="A2.SS3.p1.1.1.m1.1a"><msub id="A2.SS3.p1.1.1.m1.1.1" xref="A2.SS3.p1.1.1.m1.1.1.cmml"><mi id="A2.SS3.p1.1.1.m1.1.1a" xref="A2.SS3.p1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="A2.SS3.p1.1.1.m1.1.1.1" xref="A2.SS3.p1.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.1.1.m1.1b"><apply id="A2.SS3.p1.1.1.m1.1.1.cmml" xref="A2.SS3.p1.1.1.m1.1.1"><ci id="A2.SS3.p1.1.1.m1.1.1.1a.cmml" xref="A2.SS3.p1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="A2.SS3.p1.1.1.m1.1.1.1.cmml" xref="A2.SS3.p1.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>-produced responses and annotator ratings in <a href="#A2.SS3" title="B.3 Example Predictions from GPT3_&quot;Self-Inst&quot; ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">subsection&nbsp;B.3</span></a>.
We see that even for responses rated as level C, the model demonstrates extensive steps in solving the task, even though its final output is incorrect.</p>
</div>
<figure id="A2.SS3.8" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="A2.SS3.6.5" class="ltx_inline-block ltx_figure_panel ltx_transformed_outer" style="width:429.3pt;height:820.9pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-34.1pt,65.2pt) scale(0.862809144010476,0.862809144010476) ;">
<table id="A2.SS3.6.5.5" class="ltx_tabular ltx_align_middle">
<tbody><tr id="A2.SS3.2.1.1.1" class="ltx_tr">
<td id="A2.SS3.2.1.1.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_align_top ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.2.1.1.1.2.1" class="ltx_text ltx_font_bold">Instruction + Instance Input</span></td>
<td id="A2.SS3.2.1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_align_top ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.2.1.1.1.3.1" class="ltx_text ltx_font_bold">Target Response</span></td>
<td id="A2.SS3.2.1.1.1.1" class="ltx_td ltx_nopad_l ltx_align_center ltx_align_top ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.2.1.1.1.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">GPT3<math id="A2.SS3.2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="A2.SS3.2.1.1.1.1.1.m1.1a"><msub id="A2.SS3.2.1.1.1.1.1.m1.1.1" xref="A2.SS3.2.1.1.1.1.1.m1.1.1.cmml"><mi id="A2.SS3.2.1.1.1.1.1.m1.1.1a" xref="A2.SS3.2.1.1.1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="A2.SS3.2.1.1.1.1.1.m1.1.1.1" xref="A2.SS3.2.1.1.1.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.SS3.2.1.1.1.1.1.m1.1b"><apply id="A2.SS3.2.1.1.1.1.1.m1.1.1.cmml" xref="A2.SS3.2.1.1.1.1.1.m1.1.1"><ci id="A2.SS3.2.1.1.1.1.1.m1.1.1.1a.cmml" xref="A2.SS3.2.1.1.1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="A2.SS3.2.1.1.1.1.1.m1.1.1.1.cmml" xref="A2.SS3.2.1.1.1.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.2.1.1.1.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math><span id="A2.SS3.2.1.1.1.1.1.1" class="ltx_text ltx_font_upright"> Response</span></span></td>
<td id="A2.SS3.2.1.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.2.1.1.1.4.1" class="ltx_text ltx_font_bold">Rating</span></td>
</tr>
<tr id="A2.SS3.6.5.5.6" class="ltx_tr">
<td id="A2.SS3.6.5.5.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.6.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.6.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.6.1.1.1.2" class="ltx_text ltx_font_typewriter"> Give students tips on how to keep their nerves under control during class presentations.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.6.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.6.2.1.1.1" class="ltx_text ltx_font_typewriter">Everyone gets a little nervous when speaking in front of a group. That’s normal. But the more preparation you’ve done—meaning plenty of researching, organizing, and rehearsing—the more confident you’ll be. Preparation is the key. And if you make a mistake or stumble over your words, just regroup and keep going. Nobody’s perfect, and nobody expects you to be.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.6.3.1.1" class="ltx_p" style="width:138.8pt;">

<span id="A2.I1" class="ltx_itemize">
<span id="A2.I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I1.i1.p1" class="ltx_para">
<span id="A2.I1.i1.p1.1" class="ltx_p"><span id="A2.I1.i1.p1.1.1" class="ltx_text ltx_font_typewriter">Practice your presentation in front of friends and family.</span></span>
</span></span>
<span id="A2.I1.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I1.i2.p1" class="ltx_para">
<span id="A2.I1.i2.p1.1" class="ltx_p"><span id="A2.I1.i2.p1.1.1" class="ltx_text ltx_font_typewriter">Don’t drink too much caffeine before the presentation.</span></span>
</span></span>
<span id="A2.I1.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I1.i3.p1" class="ltx_para">
<span id="A2.I1.i3.p1.1" class="ltx_p"><span id="A2.I1.i3.p1.1.1" class="ltx_text ltx_font_typewriter">Take deep breaths before you start speaking.</span></span>
</span></span>
<span id="A2.I1.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I1.i4.p1" class="ltx_para">
<span id="A2.I1.i4.p1.1" class="ltx_p"><span id="A2.I1.i4.p1.1.1" class="ltx_text ltx_font_typewriter">If you feel nervous, smile.</span></span>
</span></span>
<span id="A2.I1.i5" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I1.i5.p1" class="ltx_para">
<span id="A2.I1.i5.p1.1" class="ltx_p"><span id="A2.I1.i5.p1.1.1" class="ltx_text ltx_font_typewriter">Remember that everyone in the audience is rooting for you.</span></span>
</span></span>
</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.6.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.6.4.1" class="ltx_text ltx_font_typewriter">A</span></td>
</tr>
<tr id="A2.SS3.6.5.5.7" class="ltx_tr">
<td id="A2.SS3.6.5.5.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.7.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.7.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.7.1.1.1.2" class="ltx_text ltx_font_typewriter"> Make a list of the pros and cons of the given decision.

<br class="ltx_break"><span id="A2.SS3.6.5.5.7.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span> Implementing a Remote Working Policy</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.7.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.7.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.7.2.1.1.1" class="ltx_text ltx_font_typewriter">Pros: 
<span id="A2.I2" class="ltx_itemize">
<span id="A2.I2.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I2.i1.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I2.i1.p1" class="ltx_para">
<span id="A2.I2.i1.p1.1" class="ltx_p">Allowing employees to work from home can reduce their stressful commutes and increase their productivity.</span>
</span></span>
<span id="A2.I2.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I2.i2.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I2.i2.p1" class="ltx_para">
<span id="A2.I2.i2.p1.1" class="ltx_p">Remote working provides greater flexibility, particularly for working parents and caregivers who have other responsibilities.
</span>
</span></span>
<span id="A2.I2.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I2.i3.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I2.i3.p1" class="ltx_para">
<span id="A2.I2.i3.p1.1" class="ltx_p">…(more points)</span>
</span></span>
</span></span></span>
<span id="A2.SS3.6.5.5.7.2.1.2" class="ltx_p"><span id="A2.SS3.6.5.5.7.2.1.2.1" class="ltx_text ltx_font_typewriter">Cons:</span></span>
<span id="A2.I3" class="ltx_itemize">
<span id="A2.I3.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I3.i1.p1" class="ltx_para">
<span id="A2.I3.i1.p1.1" class="ltx_p"><span id="A2.I3.i1.p1.1.1" class="ltx_text ltx_font_typewriter">It may be more difficult for team members to build meaningful, productive, creative relationships with one another.</span></span>
</span></span>
<span id="A2.I3.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I3.i2.p1" class="ltx_para">
<span id="A2.I3.i2.p1.1" class="ltx_p"><span id="A2.I3.i2.p1.1.1" class="ltx_text ltx_font_typewriter">…(more points)</span></span>
</span></span>
</span>
</span>
</td>
<td id="A2.SS3.6.5.5.7.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.7.3.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.7.3.1.1.1" class="ltx_text ltx_font_typewriter">Pros:

<span id="A2.I4" class="ltx_itemize">
<span id="A2.I4.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I4.i1.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I4.i1.p1" class="ltx_para">
<span id="A2.I4.i1.p1.1" class="ltx_p">Employees can work from home and save on commuting costs.</span>
</span></span>
<span id="A2.I4.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I4.i2.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I4.i2.p1" class="ltx_para">
<span id="A2.I4.i2.p1.1" class="ltx_p">Employees can spend more time with their families.</span>
</span></span>
</span>
Cons:

<span id="A2.I5" class="ltx_itemize">
<span id="A2.I5.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I5.i1.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I5.i1.p1" class="ltx_para">
<span id="A2.I5.i1.p1.1" class="ltx_p">Employees may not be as productive as they would be in the office.</span>
</span></span>
<span id="A2.I5.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I5.i2.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I5.i2.p1" class="ltx_para">
<span id="A2.I5.i2.p1.1" class="ltx_p">Employees may not be as motivated to work.</span>
</span></span>
</span></span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.7.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.7.4.1" class="ltx_text ltx_font_typewriter">A</span></td>
</tr>
<tr id="A2.SS3.6.5.5.8" class="ltx_tr">
<td id="A2.SS3.6.5.5.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.8.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.8.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.8.1.1.1.2" class="ltx_text ltx_font_typewriter"> A user story is an informal, general explanation of a software feature written from the perspective of the end-user or customer. Write a user story for a given software. 
<br class="ltx_break"><span id="A2.SS3.6.5.5.8.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span> Gmail</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.8.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.8.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.8.2.1.1.1" class="ltx_text ltx_font_typewriter">As a user, I want to be able to recover the password to my account, so that I will be able to access my account in case I forgot the password.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.8.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.8.3.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.8.3.1.1.1" class="ltx_text ltx_font_typewriter">As a user, I want to be able to send emails to my friends and family. I want to be able to attach files to my emails. I want to be able to search for emails in my inbox.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.8.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.8.4.1" class="ltx_text ltx_font_typewriter">A</span></td>
</tr>
<tr id="A2.SS3.4.3.3.3" class="ltx_tr">
<td id="A2.SS3.4.3.3.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.4.3.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.4.3.3.3.3.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.4.3.3.3.3.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.4.3.3.3.3.1.1.2" class="ltx_text ltx_font_typewriter"> A color description has been provided. Find the CSS code associated with that color.

<br class="ltx_break"><span id="A2.SS3.4.3.3.3.3.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span> A light red color with a medium light shade of pink</span></span>
</span>
</td>
<td id="A2.SS3.3.2.2.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.3.2.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.3.2.2.2.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.3.2.2.2.1.1.1.1" class="ltx_text ltx_font_typewriter">#DB7093 (<math id="A2.SS3.3.2.2.2.1.1.1.1.m1.1" class="ltx_Math" alttext="{\color[rgb]{0.859375,0.4375,0.578125}\definecolor[named]{pgfstrokecolor}{rgb}{0.859375,0.4375,0.578125}\lgblksquare}" display="inline"><semantics id="A2.SS3.3.2.2.2.1.1.1.1.m1.1a"><merror class="ltx_ERROR undefined undefined" id="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1" xref="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1b.cmml"><mtext id="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1a" xref="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1b.cmml">\lgblksquare</mtext></merror><annotation-xml encoding="MathML-Content" id="A2.SS3.3.2.2.2.1.1.1.1.m1.1b"><ci id="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1b.cmml" xref="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1"><merror class="ltx_ERROR undefined undefined" id="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1.cmml" xref="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1"><mtext id="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1a.cmml" xref="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1">\lgblksquare</mtext></merror></ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.3.2.2.2.1.1.1.1.m1.1c">{\color[rgb]{0.859375,0.4375,0.578125}\definecolor[named]{pgfstrokecolor}{rgb}{0.859375,0.4375,0.578125}\lgblksquare}</annotation></semantics></math>)</span></span>
</span>
</td>
<td id="A2.SS3.4.3.3.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.4.3.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.4.3.3.3.2.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.4.3.3.3.2.1.1.1" class="ltx_text ltx_font_typewriter">&nbsp;#ff66cc (<math id="A2.SS3.4.3.3.3.2.1.1.1.m1.1" class="ltx_Math" alttext="{\color[rgb]{1,0.3984375,0.80078125}\definecolor[named]{pgfstrokecolor}{rgb}{1,0.3984375,0.80078125}\lgblksquare}" display="inline"><semantics id="A2.SS3.4.3.3.3.2.1.1.1.m1.1a"><merror class="ltx_ERROR undefined undefined" id="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1" xref="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1b.cmml"><mtext id="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1a" xref="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1b.cmml">\lgblksquare</mtext></merror><annotation-xml encoding="MathML-Content" id="A2.SS3.4.3.3.3.2.1.1.1.m1.1b"><ci id="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1b.cmml" xref="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1"><merror class="ltx_ERROR undefined undefined" id="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1.cmml" xref="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1"><mtext id="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1a.cmml" xref="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1">\lgblksquare</mtext></merror></ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.4.3.3.3.2.1.1.1.m1.1c">{\color[rgb]{1,0.3984375,0.80078125}\definecolor[named]{pgfstrokecolor}{rgb}{1,0.3984375,0.80078125}\lgblksquare}</annotation></semantics></math>)</span></span>
</span>
</td>
<td id="A2.SS3.4.3.3.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.4.3.3.3.4.1" class="ltx_text ltx_font_typewriter">B</span></td>
</tr>
<tr id="A2.SS3.6.5.5.9" class="ltx_tr">
<td id="A2.SS3.6.5.5.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.9.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.9.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.9.1.1.1.2" class="ltx_text ltx_font_typewriter"> Someone gives you some information about where they want to go and what they enjoy seeing and doing. Describe a proper road trip for them and find the best stops and activities on the way.

<br class="ltx_break"><span id="A2.SS3.6.5.5.9.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span> I’m looking for a west coast road trip. My goal is to start near San Diego and travel to Los Angeles.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.9.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.9.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.9.2.1.1.1" class="ltx_text ltx_font_typewriter">Begin near the city of San Diego and make the first stop in coastal La Jolla. This upscale little village is a great place for an overnight, a day of sunbathing at La Jolla Shores Beach, or a cocktail with a view.
Just 20 minutes north, stop into beachy Encinitas to window shop the boutiques or sample fish tacos. Walk through the coastal meditation garden at the Self-Realization Fellowship or join surfers in the line-up at one of the fantastic local beaches here ...(more ideas)</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.9.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.9.3.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.9.3.1.1.1" class="ltx_text ltx_font_typewriter">You should start your trip in San Diego, California. You can visit the San Diego Zoo, which is one of the best zoos in the world. Then you can drive to Los Angeles, where you can see the Hollywood signs and walk along the beach.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.9.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.9.4.1" class="ltx_text ltx_font_typewriter">B</span></td>
</tr>
<tr id="A2.SS3.6.5.5.10" class="ltx_tr">
<td id="A2.SS3.6.5.5.10.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.10.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.10.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.10.1.1.1.2" class="ltx_text ltx_font_typewriter"> Give some examples of what people usually say in the given social situation.

<br class="ltx_break"><span id="A2.SS3.6.5.5.10.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span> when someone arrives safely</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.10.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.10.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.10.2.1.1.1" class="ltx_text ltx_font_typewriter">

<span id="A2.I6" class="ltx_itemize">
<span id="A2.I6.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I6.i1.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I6.i1.p1" class="ltx_para">
<span id="A2.I6.i1.p1.1" class="ltx_p">‘‘Glad you made it safe and sound.’’</span>
</span></span>
<span id="A2.I6.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I6.i2.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I6.i2.p1" class="ltx_para">
<span id="A2.I6.i2.p1.1" class="ltx_p">‘‘Good to see you got here unscathed.’’</span>
</span></span>
<span id="A2.I6.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I6.i3.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I6.i3.p1" class="ltx_para">
<span id="A2.I6.i3.p1.1" class="ltx_p">‘‘So, bulletproof vests actually work!’’</span>
</span></span>
</span></span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.10.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.10.3.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.10.3.1.1.1" class="ltx_text ltx_font_typewriter">Thank God, I made it.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.10.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.10.4.1" class="ltx_text ltx_font_typewriter">B</span></td>
</tr>
<tr id="A2.SS3.6.5.5.5" class="ltx_tr">
<td id="A2.SS3.6.5.5.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.5.2.2" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.5.2.2.2" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.5.2.2.2.3" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.5.2.2.2.2" class="ltx_text ltx_font_typewriter"> You are given a sentence in first-order logic. Translate it into natural language.

<br class="ltx_break"><span id="A2.SS3.6.5.5.5.2.2.2.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
<math id="A2.SS3.5.4.4.4.1.1.1.1.m1.1" class="ltx_math_unparsed" alttext="\exists x\forall y(soldier(x)" display="inline"><semantics id="A2.SS3.5.4.4.4.1.1.1.1.m1.1a"><mrow id="A2.SS3.5.4.4.4.1.1.1.1.m1.1b"><mo rspace="0.167em" id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.2">∃</mo><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.3">x</mi><mo lspace="0.167em" rspace="0.167em" id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.4">∀</mo><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.5">y</mi><mrow id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6"><mo stretchy="false" id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.1">(</mo><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.2">s</mi><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.3">o</mi><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.4">l</mi><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.5">d</mi><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.6">i</mi><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.7">e</mi><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.8">r</mi><mrow id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.9"><mo stretchy="false" id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.9.1">(</mo><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.1">x</mi><mo stretchy="false" id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.9.2">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex" id="A2.SS3.5.4.4.4.1.1.1.1.m1.1c">\exists x\forall y(soldier(x)</annotation></semantics></math>
<math id="A2.SS3.6.5.5.5.2.2.2.2.m2.2" class="ltx_math_unparsed" alttext="\to general(x,y))" display="inline"><semantics id="A2.SS3.6.5.5.5.2.2.2.2.m2.2a"><mrow id="A2.SS3.6.5.5.5.2.2.2.2.m2.2b"><mo stretchy="false" id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.3">→</mo><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.4">g</mi><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.5">e</mi><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.6">n</mi><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.7">e</mi><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.8">r</mi><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.9">a</mi><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.10">l</mi><mrow id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.11"><mo stretchy="false" id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.11.1">(</mo><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.1.1">x</mi><mo id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.11.2">,</mo><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.2">y</mi><mo stretchy="false" id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.11.3">)</mo></mrow><mo stretchy="false" id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.12">)</mo></mrow><annotation encoding="application/x-tex" id="A2.SS3.6.5.5.5.2.2.2.2.m2.2c">\to general(x,y))</annotation></semantics></math></span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.5.3.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.5.3.1.1.1" class="ltx_text ltx_font_typewriter">There is someone (x) such that if he is a soldier, then he is general of everyone.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.5.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.5.4.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.5.4.1.1.1" class="ltx_text ltx_font_typewriter">There exists a soldier such that for every general, he is a general.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.5.5.1" class="ltx_text ltx_font_typewriter">C</span></td>
</tr>
<tr id="A2.SS3.6.5.5.11" class="ltx_tr">
<td id="A2.SS3.6.5.5.11.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.11.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.11.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.11.1.1.1.2" class="ltx_text ltx_font_typewriter"> Make a questionnaire to help hotel guests write hotel reviews.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.11.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.11.2.1.1" class="ltx_p" style="width:173.4pt;">
<span id="A2.I7" class="ltx_itemize">
<span id="A2.I7.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I7.i1.p1" class="ltx_para">
<span id="A2.I7.i1.p1.1" class="ltx_p"><span id="A2.I7.i1.p1.1.1" class="ltx_text ltx_font_typewriter">Your overall rating of this hotel:</span></span>
</span></span>
<span id="A2.I7.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I7.i2.p1" class="ltx_para">
<span id="A2.I7.i2.p1.1" class="ltx_p"><span id="A2.I7.i2.p1.1.1" class="ltx_text ltx_font_typewriter">Summarize your visit or highlight an interesting detail:</span></span>
</span></span>
<span id="A2.I7.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I7.i3.p1" class="ltx_para">
<span id="A2.I7.i3.p1.1" class="ltx_p"><span id="A2.I7.i3.p1.1.1" class="ltx_text ltx_font_typewriter">...(more questions)</span></span>
</span></span>
</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.11.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.11.3.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.11.3.1.1.1" class="ltx_text ltx_font_typewriter">Question: How would you rate the service at the front desk? 
<br class="ltx_break">Answer: Excellent, Good, Average, Poor</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.11.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.11.4.1" class="ltx_text ltx_font_typewriter">C</span></td>
</tr>
<tr id="A2.SS3.6.5.5.12" class="ltx_tr">
<td id="A2.SS3.6.5.5.12.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.12.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.12.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.12.1.1.1.2" class="ltx_text ltx_font_typewriter">
Design an outline for a blog post based on the given information and list the sections accordingly.

<br class="ltx_break"><span id="A2.SS3.6.5.5.12.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
This blog post is going to about making a list of last-minute gift ideas. Also, the tone of the post is going to be relaxed and casual.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.12.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.12.2.1.1" class="ltx_p" style="width:173.4pt;">
<span id="A2.I8" class="ltx_itemize">
<span id="A2.I8.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I8.i1.p1" class="ltx_para">
<span id="A2.I8.i1.p1.1" class="ltx_p"><span id="A2.I8.i1.p1.1.1" class="ltx_text ltx_font_typewriter">Section: Movie tickets</span></span>
</span></span>
<span id="A2.I8.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I8.i2.p1" class="ltx_para">
<span id="A2.I8.i2.p1.1" class="ltx_p"><span id="A2.I8.i2.p1.1.1" class="ltx_text ltx_font_typewriter">Section: A fun game console
</span></span>
</span></span>
<span id="A2.I8.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I8.i3.p1" class="ltx_para">
<span id="A2.I8.i3.p1.1" class="ltx_p"><span id="A2.I8.i3.p1.1.1" class="ltx_text ltx_font_typewriter">Section: Personalized items with photos/artwork</span></span>
</span></span>
<span id="A2.I8.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I8.i4.p1" class="ltx_para">
<span id="A2.I8.i4.p1.1" class="ltx_p"><span id="A2.I8.i4.p1.1.1" class="ltx_text ltx_font_typewriter">...(more sections)</span></span>
</span></span>
<span id="A2.I8.i5" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I8.i5.p1" class="ltx_para">
<span id="A2.I8.i5.p1.1" class="ltx_p"><span id="A2.I8.i5.p1.1.1" class="ltx_text ltx_font_typewriter">Takeaway: Don’t stress about out running out of time to buy, make a gift.</span></span>
</span></span>
</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.12.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.12.3.1.1" class="ltx_p" style="width:138.8pt;">
<span id="A2.I9" class="ltx_itemize">
<span id="A2.I9.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I9.i1.p1" class="ltx_para">
<span id="A2.I9.i1.p1.1" class="ltx_p"><span id="A2.I9.i1.p1.1.1" class="ltx_text ltx_font_typewriter">Introduction</span></span>
</span></span>
<span id="A2.I9.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I9.i2.p1" class="ltx_para">
<span id="A2.I9.i2.p1.1" class="ltx_p"><span id="A2.I9.i2.p1.1.1" class="ltx_text ltx_font_typewriter">List of Gift Ideas</span></span>
</span></span>
<span id="A2.I9.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I9.i3.p1" class="ltx_para">
<span id="A2.I9.i3.p1.1" class="ltx_p"><span id="A2.I9.i3.p1.1.1" class="ltx_text ltx_font_typewriter">Conclusion</span></span>
</span></span>
</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.12.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.12.4.1" class="ltx_text ltx_font_typewriter">C</span></td>
</tr>
<tr id="A2.SS3.6.5.5.13" class="ltx_tr">
<td id="A2.SS3.6.5.5.13.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.13.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.13.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.13.1.1.1.2" class="ltx_text ltx_font_typewriter">
Write a Jira ticket for the given task.

<br class="ltx_break"><span id="A2.SS3.6.5.5.13.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
New Employee onboarding</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.13.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.13.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.13.2.1.1.1" class="ltx_text ltx_font_typewriter">Title: Please help our new employee get settled.
Prepare a desk, chair, and computer for them to use.
Create their company account, email, and temporary password.
Grant access to company documents.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.13.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.13.3.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.13.3.1.1.1" class="ltx_text ltx_font_typewriter">Hi [Manager],
I’m writing to you because I have a question about the new employee onboarding process. I’ve been working here for a few months now, and I’m still not sure how it works. Could you please explain it to me?</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.13.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.13.4.1" class="ltx_text ltx_font_typewriter">D</span></td>
</tr>
<tr id="A2.SS3.6.5.5.14" class="ltx_tr">
<td id="A2.SS3.6.5.5.14.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.14.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.14.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.14.1.1.1.2" class="ltx_text ltx_font_typewriter">
Create alliterations by finding synonyms for words in the given sentence.

<br class="ltx_break"><span id="A2.SS3.6.5.5.14.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
David wears a hat everyday.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.14.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.14.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.14.2.1.1.1" class="ltx_text ltx_font_typewriter">David dons a derby daily.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.14.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.14.3.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.14.3.1.1.1" class="ltx_text ltx_font_typewriter">David wears a hat every day.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.14.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.14.4.1" class="ltx_text ltx_font_typewriter">D</span></td>
</tr>
</tbody></table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9: </span>Examples in the user-oriented instructions dataset (§<a href="#S4.SS4" title="4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>) and predictions from <span id="A2.SS3.8.7.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="A2.SS3.8.7.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="A2.SS3.8.7.1.m1.1b"><msub id="A2.SS3.8.7.1.m1.1.1" xref="A2.SS3.8.7.1.m1.1.1.cmml"><mi id="A2.SS3.8.7.1.m1.1.1b" xref="A2.SS3.8.7.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="A2.SS3.8.7.1.m1.1.1.1" xref="A2.SS3.8.7.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.SS3.8.7.1.m1.1c"><apply id="A2.SS3.8.7.1.m1.1.1.cmml" xref="A2.SS3.8.7.1.m1.1.1"><ci id="A2.SS3.8.7.1.m1.1.1.1a.cmml" xref="A2.SS3.8.7.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="A2.SS3.8.7.1.m1.1.1.1.cmml" xref="A2.SS3.8.7.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.8.7.1.m1.1d">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>. The right column indicates one of the four quality ratings assigned to the model’s response, with “A” indicating “valid and satisfying” responses (highest)
and “D” indicating “irrelevant or invalid response” (lowest).
</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_pagination ltx_figure_panel ltx_role_newpage"></div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<section id="A3" class="ltx_appendix ltx_figure_panel">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Task and Instance Examples from the Generated Instruction Data</h2>

<figure id="A3.T10" class="ltx_table">
<div id="A3.T10.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:842.6pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-17.0pt,33.0pt) scale(0.927291480460659,0.927291480460659) ;">
<table id="A3.T10.2.2" class="ltx_tabular ltx_align_middle">
<tbody><tr id="A3.T10.2.2.3" class="ltx_tr">
<td id="A3.T10.2.2.3.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="A3.T10.2.2.3.1.1" class="ltx_text ltx_font_bold">Instruction + Instance Input</span></td>
<td id="A3.T10.2.2.3.2" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="A3.T10.2.2.3.2.1" class="ltx_text ltx_font_bold">Target Output</span></td>
<td id="A3.T10.2.2.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.3.3.1.1" class="ltx_p" style="width:39.0pt;"><span id="A3.T10.2.2.3.3.1.1.1" class="ltx_text ltx_font_bold">Validity</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.4" class="ltx_tr">
<td id="A3.T10.2.2.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.4.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.4.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.4.1.1.1.2" class="ltx_text ltx_font_typewriter">
Generate a random password with at least 6 characters.</span></span>
</span>
</td>
<td id="A3.T10.2.2.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.4.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.4.2.1.1.1" class="ltx_text ltx_font_typewriter">def generateRandomPassword():

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;password = ""

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while len(password) &lt; 6:

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;password += chr(random.randint(65, 90))

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return password</span></span>
</span>
</td>
<td id="A3.T10.2.2.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.4.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.4.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.4.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.4.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.5" class="ltx_tr">
<td id="A3.T10.2.2.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.5.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.5.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.5.1.1.1.2" class="ltx_text ltx_font_typewriter"> Write a paragraph describing how to tie shoelaces for people who have never tied their shoes before. explain each step briefly.</span></span>
</span>
</td>
<td id="A3.T10.2.2.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.5.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.5.2.1.1.1" class="ltx_text ltx_font_typewriter">Paragraph: To tie shoelaces, first you need to make a loop with one end of the lace. Then pass the other end through the loop and pull it tight. Next, you need to wrap the lace around the shoe several times. Finally, tuck in the loose end into the wrapped part of the lace.</span></span>
</span>
</td>
<td id="A3.T10.2.2.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.5.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.5.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.5.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.5.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.6" class="ltx_tr">
<td id="A3.T10.2.2.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.6.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.6.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.6.1.1.1.2" class="ltx_text ltx_font_typewriter">
Given a word, find out its length and its number of vowels.

<br class="ltx_break"><span id="A3.T10.2.2.6.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
Word = "hello"</span></span>
</span>
</td>
<td id="A3.T10.2.2.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.6.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.6.2.1.1.1" class="ltx_text ltx_font_typewriter">Length = 5, Number of vowels = 2</span></span>
</span>
</td>
<td id="A3.T10.2.2.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.6.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.6.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.6.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.6.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.7" class="ltx_tr">
<td id="A3.T10.2.2.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.7.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.7.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.7.1.1.1.2" class="ltx_text ltx_font_typewriter">
Write a story with three characters: a person, an animal and an object.

<br class="ltx_break"><span id="A3.T10.2.2.7.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
Person: John, a programmer. 
<br class="ltx_break">Animal: A dog. 
<br class="ltx_break">Object: A laptop. 
<br class="ltx_break"></span></span>
</span>
</td>
<td id="A3.T10.2.2.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.7.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.7.2.1.1.1" class="ltx_text ltx_font_typewriter">John was sitting on the floor in front of his laptop when he heard a knock at the door. He opened it to find a dog standing there. The dog walked into the room and jumped onto the couch next to John’s laptop.</span></span>
</span>
</td>
<td id="A3.T10.2.2.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.7.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.7.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.7.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.7.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.8" class="ltx_tr">
<td id="A3.T10.2.2.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.8.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.8.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.8.1.1.1.2" class="ltx_text ltx_font_typewriter">
Compose an email and send it to your friend, asking for advice on what to do in this situation.

<br class="ltx_break"><span id="A3.T10.2.2.8.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
Situation: You are a programmer and you have been working on a project for the past few months. The deadline is approaching, but you haven’t finished yet. Your manager has asked you to stay late every day this week to finish it.</span></span>
</span>
</td>
<td id="A3.T10.2.2.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.8.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.8.2.1.1.1" class="ltx_text ltx_font_typewriter">Hi [Friend], 
<br class="ltx_break">I’m having a bit of trouble with my current job. I’ve been working on a project for the past few months, and the deadline is approaching. My manager has asked me to stay late every day this week to finish it. I don’t think I can do that because I have other commitments. What should I do?</span></span>
</span>
</td>
<td id="A3.T10.2.2.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.8.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.8.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.8.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.8.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.9" class="ltx_tr">
<td id="A3.T10.2.2.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.9.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.9.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.9.1.1.1.2" class="ltx_text ltx_font_typewriter">
What are some ways we can make our school more eco-friendly?</span></span>
</span>
</td>
<td id="A3.T10.2.2.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.9.2.1.1" class="ltx_p" style="width:242.8pt;">
<span id="A3.I1" class="ltx_itemize">
<span id="A3.I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I1.i1.p1" class="ltx_para">
<span id="A3.I1.i1.p1.1" class="ltx_p"><span id="A3.I1.i1.p1.1.1" class="ltx_text ltx_font_typewriter">Use reusable water bottles instead of disposable plastic ones.</span></span>
</span></span>
<span id="A3.I1.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I1.i2.p1" class="ltx_para">
<span id="A3.I1.i2.p1.1" class="ltx_p"><span id="A3.I1.i2.p1.1.1" class="ltx_text ltx_font_typewriter">Turn off lights when you leave a room.</span></span>
</span></span>
<span id="A3.I1.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I1.i3.p1" class="ltx_para">
<span id="A3.I1.i3.p1.1" class="ltx_p"><span id="A3.I1.i3.p1.1.1" class="ltx_text ltx_font_typewriter">Recycle paper, cans and bottles.</span></span>
</span></span>
<span id="A3.I1.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I1.i4.p1" class="ltx_para">
<span id="A3.I1.i4.p1.1" class="ltx_p"><span id="A3.I1.i4.p1.1.1" class="ltx_text ltx_font_typewriter">Plant trees to absorb carbon dioxide.</span></span>
</span></span>
</span></span>
</span>
</td>
<td id="A3.T10.2.2.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.9.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.9.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.9.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.9.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.10" class="ltx_tr">
<td id="A3.T10.2.2.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.10.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.10.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.10.1.1.1.2" class="ltx_text ltx_font_typewriter"> I am looking for a new apartment. there are many options available but they are all quite expensive. i want to move as soon as possible. give me advice on what to do.</span></span>
</span>
</td>
<td id="A3.T10.2.2.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.10.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.10.2.1.1.1" class="ltx_text ltx_font_typewriter">You should look for a cheaper apartment. You can try to negotiate with the landlord and offer him/her a lower price. If you are lucky, they will accept your offer. Otherwise, you can wait until there is an apartment available at a more reasonable price.</span></span>
</span>
</td>
<td id="A3.T10.2.2.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.10.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.10.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.10.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.10.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.11" class="ltx_tr">
<td id="A3.T10.2.2.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.11.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.11.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.11.1.1.1.2" class="ltx_text ltx_font_typewriter">
Write a dialogue between two people who have been friends for a long time, and one of them is trying to convince the other to do something that he or she doesn’t want to do.</span></span>
</span>
</td>
<td id="A3.T10.2.2.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.11.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.11.2.1.1.1" class="ltx_text ltx_font_typewriter">A: Hey, I have a great idea! Let’s go to the beach today.
<br class="ltx_break">B: No thanks, I’m not really in the mood for that.
<br class="ltx_break">A: Come on, it’ll be fun! We haven’t been there together in ages.
B: I know, but I just don’t feel like going.
<br class="ltx_break">A: But you love the beach! You always say how much you enjoy swimming and lying in the sun.
<br class="ltx_break">B: Yeah, I do. It’s just that I’ve been feeling kind of tired lately.
<br class="ltx_break">A: Oh, come on. You’re never tired. You’re always so energetic.
<br class="ltx_break">B: Well, I am now. I think I need some rest.
<br class="ltx_break">A: Okay, fine. If you change your mind, let me know.</span></span>
</span>
</td>
<td id="A3.T10.2.2.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.11.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.11.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.11.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.11.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.12" class="ltx_tr">
<td id="A3.T10.2.2.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.12.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.12.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.12.1.1.1.2" class="ltx_text ltx_font_typewriter"> How can i create an app that will be able to identify different kinds of plants by taking photos of them?</span></span>
</span>
</td>
<td id="A3.T10.2.2.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.12.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.12.2.1.1.1" class="ltx_text ltx_font_typewriter">You can use the following steps to create an app that will be able to identify different kinds of plants by taking photos of them. 
<br class="ltx_break">Step 1: Create a database with all the information about the plants you want to identify. 
<br class="ltx_break">Step 2: Create a user interface for your application. 
<br class="ltx_break">Step 3: Use image recognition techniques to identify the plant in the photo. 
<br class="ltx_break">Step 4: Display the name of the plant on the screen.</span></span>
</span>
</td>
<td id="A3.T10.2.2.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.12.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.12.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.12.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.12.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.2" class="ltx_tr">
<td id="A3.T10.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.1.1.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.1.1.1.1.1.1.2" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.1.1.1.1.1.1.1" class="ltx_text ltx_font_typewriter"> Find the closest matching emoji to a given one. 
<br class="ltx_break"><span id="A3.T10.1.1.1.1.1.1.1.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span> Emoji: <img src="/html/2212.10560/assets/figures/woman-surfing.png" id="A3.T10.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="9" height="8" alt="[Uncaptioned image]"></span></span>
</span>
</td>
<td id="A3.T10.2.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.2.2.1.1" class="ltx_p" style="width:242.8pt;"><img src="/html/2212.10560/assets/figures/water-wave.png" id="A3.T10.2.2.2.2.1.1.g1" class="ltx_graphics ltx_img_square" width="9" height="8" alt="[Uncaptioned image]"></span>
</span>
</td>
<td id="A3.T10.2.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.2.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.2.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.2.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.2.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.13" class="ltx_tr">
<td id="A3.T10.2.2.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.13.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.13.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.13.1.1.1.2" class="ltx_text ltx_font_typewriter"> Describe your favorite video game using only verbs. 
<br class="ltx_break"><span id="A3.T10.2.2.13.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span> Game: The Legend of Zelda</span></span>
</span>
</td>
<td id="A3.T10.2.2.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.13.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.13.2.1.1.1" class="ltx_text ltx_font_typewriter">Explore, fight, solve, upgrade, repeat</span></span>
</span>
</td>
<td id="A3.T10.2.2.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.13.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.13.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.13.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.13.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Representative <span id="A3.T10.4.1" class="ltx_text ltx_font_bold">valid</span> tasks generated by GPT3. As is discussed in §<a href="#S3" title="3 Self-Instruct Data from GPT3 ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, these generated tasks cover a broad range of formats, text types, and underlying expertise, while being correct on more than half of all the generated tasks. </figcaption>
</figure>
<figure id="A3.T11" class="ltx_table">
<div id="A3.T11.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:979.6pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.0pt,31.6pt) scale(0.939344141726076,0.939344141726076) ;">
<table id="A3.T11.7.7" class="ltx_tabular ltx_align_middle">
<tbody><tr id="A3.T11.7.7.8" class="ltx_tr">
<td id="A3.T11.7.7.8.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A3.T11.7.7.8.1.1" class="ltx_text ltx_font_bold">Instruction + Instance Input</span></td>
<td id="A3.T11.7.7.8.2" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A3.T11.7.7.8.2.1" class="ltx_text ltx_font_bold">Target Output</span></td>
<td id="A3.T11.7.7.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.8.3.1.1" class="ltx_p" style="width:39.0pt;"><span id="A3.T11.7.7.8.3.1.1.1" class="ltx_text ltx_font_bold">Validity</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.7" class="ltx_tr">
<td id="A3.T11.7.7.7.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.7.7.7" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.7.7.7.7" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.7.7.7.7.8" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.7.7.7.7.7" class="ltx_text ltx_font_typewriter">
Given a set of words <math id="A3.T11.1.1.1.1.1.1.1.m1.4" class="ltx_Math" alttext="w=\{w_{1},w_{2},...,w_{n}\}" display="inline"><semantics id="A3.T11.1.1.1.1.1.1.1.m1.4a"><mrow id="A3.T11.1.1.1.1.1.1.1.m1.4.4" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.cmml"><mi id="A3.T11.1.1.1.1.1.1.1.m1.4.4.5" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.5.cmml">w</mi><mo id="A3.T11.1.1.1.1.1.1.1.m1.4.4.4" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.4.cmml">=</mo><mrow id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.4.cmml"><mo stretchy="false" id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.4" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.4.cmml">{</mo><msub id="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1" xref="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.cmml"><mi id="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.2" xref="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.2.cmml">w</mi><mn id="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.3" xref="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.5" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.4.cmml">,</mo><msub id="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2" xref="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.cmml"><mi id="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.2" xref="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.2.cmml">w</mi><mn id="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.3" xref="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.6" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="A3.T11.1.1.1.1.1.1.1.m1.1.1" xref="A3.T11.1.1.1.1.1.1.1.m1.1.1.cmml">…</mi><mo id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.7" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.4.cmml">,</mo><msub id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.cmml"><mi id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.2" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.2.cmml">w</mi><mi id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.3" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.3.cmml">n</mi></msub><mo stretchy="false" id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.8" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.T11.1.1.1.1.1.1.1.m1.4b"><apply id="A3.T11.1.1.1.1.1.1.1.m1.4.4.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4"><eq id="A3.T11.1.1.1.1.1.1.1.m1.4.4.4.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.4"></eq><ci id="A3.T11.1.1.1.1.1.1.1.m1.4.4.5.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.5">𝑤</ci><set id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.4.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3"><apply id="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.1.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.2.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.2">𝑤</ci><cn type="integer" id="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.3.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.1.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.2.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.2">𝑤</ci><cn type="integer" id="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.3.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="A3.T11.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.1.1">…</ci><apply id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.1.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3">subscript</csymbol><ci id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.2.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.2">𝑤</ci><ci id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.3.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.1.1.1.1.1.1.1.m1.4c">w=\{w_{1},w_{2},...,w_{n}\}</annotation></semantics></math> where each word <math id="A3.T11.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="w_{i}" display="inline"><semantics id="A3.T11.2.2.2.2.2.2.2.m2.1a"><msub id="A3.T11.2.2.2.2.2.2.2.m2.1.1" xref="A3.T11.2.2.2.2.2.2.2.m2.1.1.cmml"><mi id="A3.T11.2.2.2.2.2.2.2.m2.1.1.2" xref="A3.T11.2.2.2.2.2.2.2.m2.1.1.2.cmml">w</mi><mi id="A3.T11.2.2.2.2.2.2.2.m2.1.1.3" xref="A3.T11.2.2.2.2.2.2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A3.T11.2.2.2.2.2.2.2.m2.1b"><apply id="A3.T11.2.2.2.2.2.2.2.m2.1.1.cmml" xref="A3.T11.2.2.2.2.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="A3.T11.2.2.2.2.2.2.2.m2.1.1.1.cmml" xref="A3.T11.2.2.2.2.2.2.2.m2.1.1">subscript</csymbol><ci id="A3.T11.2.2.2.2.2.2.2.m2.1.1.2.cmml" xref="A3.T11.2.2.2.2.2.2.2.m2.1.1.2">𝑤</ci><ci id="A3.T11.2.2.2.2.2.2.2.m2.1.1.3.cmml" xref="A3.T11.2.2.2.2.2.2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.2.2.2.2.2.2.2.m2.1c">w_{i}</annotation></semantics></math> has <math id="A3.T11.3.3.3.3.3.3.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="A3.T11.3.3.3.3.3.3.3.m3.1a"><mi id="A3.T11.3.3.3.3.3.3.3.m3.1.1" xref="A3.T11.3.3.3.3.3.3.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="A3.T11.3.3.3.3.3.3.3.m3.1b"><ci id="A3.T11.3.3.3.3.3.3.3.m3.1.1.cmml" xref="A3.T11.3.3.3.3.3.3.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.3.3.3.3.3.3.3.m3.1c">n</annotation></semantics></math> letters, write a function that takes a target length <math id="A3.T11.4.4.4.4.4.4.4.m4.1" class="ltx_Math" alttext="l" display="inline"><semantics id="A3.T11.4.4.4.4.4.4.4.m4.1a"><mi id="A3.T11.4.4.4.4.4.4.4.m4.1.1" xref="A3.T11.4.4.4.4.4.4.4.m4.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="A3.T11.4.4.4.4.4.4.4.m4.1b"><ci id="A3.T11.4.4.4.4.4.4.4.m4.1.1.cmml" xref="A3.T11.4.4.4.4.4.4.4.m4.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.4.4.4.4.4.4.4.m4.1c">l</annotation></semantics></math> and returns a new set of words <math id="A3.T11.5.5.5.5.5.5.5.m5.1" class="ltx_Math" alttext="s" display="inline"><semantics id="A3.T11.5.5.5.5.5.5.5.m5.1a"><mi id="A3.T11.5.5.5.5.5.5.5.m5.1.1" xref="A3.T11.5.5.5.5.5.5.5.m5.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="A3.T11.5.5.5.5.5.5.5.m5.1b"><ci id="A3.T11.5.5.5.5.5.5.5.m5.1.1.cmml" xref="A3.T11.5.5.5.5.5.5.5.m5.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.5.5.5.5.5.5.5.m5.1c">s</annotation></semantics></math> such that <math id="A3.T11.6.6.6.6.6.6.6.m6.1" class="ltx_Math" alttext="|s|=l" display="inline"><semantics id="A3.T11.6.6.6.6.6.6.6.m6.1a"><mrow id="A3.T11.6.6.6.6.6.6.6.m6.1.2" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.cmml"><mrow id="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.2" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.1.cmml"><mo stretchy="false" id="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.2.1" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.1.1.cmml">|</mo><mi id="A3.T11.6.6.6.6.6.6.6.m6.1.1" xref="A3.T11.6.6.6.6.6.6.6.m6.1.1.cmml">s</mi><mo stretchy="false" id="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.2.2" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.1.1.cmml">|</mo></mrow><mo id="A3.T11.6.6.6.6.6.6.6.m6.1.2.1" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.1.cmml">=</mo><mi id="A3.T11.6.6.6.6.6.6.6.m6.1.2.3" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.3.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T11.6.6.6.6.6.6.6.m6.1b"><apply id="A3.T11.6.6.6.6.6.6.6.m6.1.2.cmml" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2"><eq id="A3.T11.6.6.6.6.6.6.6.m6.1.2.1.cmml" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.1"></eq><apply id="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.1.cmml" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.2"><abs id="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.1.1.cmml" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.2.1"></abs><ci id="A3.T11.6.6.6.6.6.6.6.m6.1.1.cmml" xref="A3.T11.6.6.6.6.6.6.6.m6.1.1">𝑠</ci></apply><ci id="A3.T11.6.6.6.6.6.6.6.m6.1.2.3.cmml" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.6.6.6.6.6.6.6.m6.1c">|s|=l</annotation></semantics></math> and <math id="A3.T11.7.7.7.7.7.7.7.m7.3" class="ltx_Math" alttext="|\{i:w_{i}\in s\}|\leq l/|w|" display="inline"><semantics id="A3.T11.7.7.7.7.7.7.7.m7.3a"><mrow id="A3.T11.7.7.7.7.7.7.7.m7.3.3" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.cmml"><mrow id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.2.cmml"><mo stretchy="false" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.2.1.cmml">|</mo><mrow id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.2.cmml"><mo stretchy="false" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.2.1.cmml">{</mo><mi id="A3.T11.7.7.7.7.7.7.7.m7.1.1" xref="A3.T11.7.7.7.7.7.7.7.m7.1.1.cmml">i</mi><mo lspace="0.278em" rspace="0.278em" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.3" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.2.1.cmml">:</mo><mrow id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.cmml"><msub id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.cmml"><mi id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.2.cmml">w</mi><mi id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.3" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.1" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.1.cmml">∈</mo><mi id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.3" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.3.cmml">s</mi></mrow><mo stretchy="false" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.4" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.2.1.cmml">}</mo></mrow><mo stretchy="false" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.3" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.2.1.cmml">|</mo></mrow><mo id="A3.T11.7.7.7.7.7.7.7.m7.3.3.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.2.cmml">≤</mo><mrow id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.cmml"><mi id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.2.cmml">l</mi><mo id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.1" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.1.cmml">/</mo><mrow id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.1.cmml"><mo stretchy="false" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.2.1" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.1.1.cmml">|</mo><mi id="A3.T11.7.7.7.7.7.7.7.m7.2.2" xref="A3.T11.7.7.7.7.7.7.7.m7.2.2.cmml">w</mi><mo stretchy="false" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.2.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.1.1.cmml">|</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.T11.7.7.7.7.7.7.7.m7.3b"><apply id="A3.T11.7.7.7.7.7.7.7.m7.3.3.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3"><leq id="A3.T11.7.7.7.7.7.7.7.m7.3.3.2.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.2"></leq><apply id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.2.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1"><abs id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.2.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.2"></abs><apply id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.2.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1"><csymbol cd="latexml" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.2.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.2">conditional-set</csymbol><ci id="A3.T11.7.7.7.7.7.7.7.m7.1.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.1.1">𝑖</ci><apply id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1"><in id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.1"></in><apply id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2">subscript</csymbol><ci id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.2.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.2">𝑤</ci><ci id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.3.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.3.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.3">𝑠</ci></apply></apply></apply><apply id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3"><divide id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.1"></divide><ci id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.2.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.2">𝑙</ci><apply id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.2"><abs id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.1.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.2.1"></abs><ci id="A3.T11.7.7.7.7.7.7.7.m7.2.2.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.2.2">𝑤</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.7.7.7.7.7.7.7.m7.3c">|\{i:w_{i}\in s\}|\leq l/|w|</annotation></semantics></math>.</span></span>
</span>
</td>
<td id="A3.T11.7.7.7.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.7.8.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.7.8.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.7.8.1.1.1" class="ltx_text ltx_font_typewriter">def wordSubsetSum(w, l):

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s = []

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for i in range(len(w)):

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if len(s) + 1 &lt; l:

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s.append(w[i])

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return s</span></span>
</span>
</td>
<td id="A3.T11.7.7.7.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.7.9.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.7.9.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.7.9.1.1.1" class="ltx_text" style="color:#FF0000;">✗
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.7.9.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.7.9.1.1.3" class="ltx_text" style="color:#FF0000;">✗</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.9" class="ltx_tr">
<td id="A3.T11.7.7.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.9.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.9.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.9.1.1.1.2" class="ltx_text ltx_font_typewriter">
The house on fire! go!</span></span>
</span>
</td>
<td id="A3.T11.7.7.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.9.2.1.1" class="ltx_p" style="width:242.8pt;">
<span id="A3.I2" class="ltx_itemize">
<span id="A3.I2.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I2.i1.p1" class="ltx_para">
<span id="A3.I2.i1.p1.1" class="ltx_p"><span id="A3.I2.i1.p1.1.1" class="ltx_text ltx_font_typewriter">Go to the kitchen and take a pan.</span></span>
</span></span>
<span id="A3.I2.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I2.i2.p1" class="ltx_para">
<span id="A3.I2.i2.p1.1" class="ltx_p"><span id="A3.I2.i2.p1.1.1" class="ltx_text ltx_font_typewriter">Take water from the tap.</span></span>
</span></span>
<span id="A3.I2.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I2.i3.p1" class="ltx_para">
<span id="A3.I2.i3.p1.1" class="ltx_p"><span id="A3.I2.i3.p1.1.1" class="ltx_text ltx_font_typewriter">Pour water into the pan.</span></span>
</span></span>
<span id="A3.I2.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I2.i4.p1" class="ltx_para">
<span id="A3.I2.i4.p1.1" class="ltx_p"><span id="A3.I2.i4.p1.1.1" class="ltx_text ltx_font_typewriter">Put out the fire with the pan.</span></span>
</span></span>
</span></span>
</span>
</td>
<td id="A3.T11.7.7.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.9.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.9.3.1.1.1" class="ltx_text" style="color:#FF0000;">✗
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.9.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.9.3.1.1.3" class="ltx_text" style="color:#FF0000;">✗</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.10" class="ltx_tr">
<td id="A3.T11.7.7.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.10.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.10.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.10.1.1.1.2" class="ltx_text ltx_font_typewriter"> Find out if you have any friends who like to play football or chess.</span></span>
</span>
</td>
<td id="A3.T11.7.7.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.10.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.10.2.1.1.1" class="ltx_text ltx_font_typewriter">def hasFriendsWhoLikeToPlayFootballOrChess(self):

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;friends = []

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for friend in self.friends:

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if friend.likes == ’football’ or friend.likes == ’chess’:

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;friends.append(friend)

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return len(friends) &gt; 0</span></span>
</span>
</td>
<td id="A3.T11.7.7.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.10.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.10.3.1.1.1" class="ltx_text" style="color:#FF0000;">✗
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.10.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.10.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.11" class="ltx_tr">
<td id="A3.T11.7.7.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.11.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.11.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.11.1.1.1.2" class="ltx_text ltx_font_typewriter">
A number of people are lined up for an interview. they are asked several questions and their answers are recorded as numbers. you need to identify which person has the highest salary among all the candidates.

<br class="ltx_break"><span id="A3.T11.7.7.11.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
Person 1: 2, 3, 4, 5, 6 
<br class="ltx_break">Person 2: 7, 8, 9, 10, 11 
<br class="ltx_break">Person 3: 12, 13, 14, 15, 16 
<br class="ltx_break">Person 4: 17, 18, 19, 20, 21 
<br class="ltx_break">Person 5: 22, 23, 24, 25, 26 
<br class="ltx_break">Person 6: 27, 28, 29, 30, 31</span></span>
</span>
</td>
<td id="A3.T11.7.7.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.11.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.11.2.1.1.1" class="ltx_text ltx_font_typewriter">Highest salary</span></span>
</span>
</td>
<td id="A3.T11.7.7.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.11.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.11.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.11.3.1.1.2" class="ltx_text" style="color:#FF0000;">✗
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.11.3.1.1.3" class="ltx_text" style="color:#FF0000;">✗</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.12" class="ltx_tr">
<td id="A3.T11.7.7.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.12.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.12.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.12.1.1.1.2" class="ltx_text ltx_font_typewriter">
Given a list of words, generate a story about a group of people who live on a planet. the story should contain at least 10 sentences. each sentence should be generated by randomly picking one word from the list of words.</span></span>
</span>
</td>
<td id="A3.T11.7.7.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.12.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.12.2.1.1.1" class="ltx_text ltx_font_typewriter">The story starts with a group of people who live on a planet. They are very intelligent and have created many things that help them in their daily lives. One day, they decided to create a machine that can make food for them. The machine was able to produce food but it also produced something else. It produced a liquid that could be used as fuel for the machines. The people were happy because they didn’t need to go out and look for food or fuel anymore. They had everything they needed right there in their homes. However, one day, the machine stopped working. The people tried to fix it but couldn’t figure out what went wrong. They tried to find someone who could help them but no one knew how to fix the machine. After a few days, the people realized that they would die if they didn’t do anything about it. So, they decided to send some of their best scientists to space to find a new planet where they could live. The scientists traveled for a long time before they found a planet that looked like a good place to live. They sent a message back to the people telling them about the planet. The people were excited and started preparing for the journey. They built spaceships and flew to the new planet. When they arrived, they saw that the planet was beautiful. There were trees and rivers and mountains. The people were so happy that they finally found a new home. They started building houses and planting crops. They lived happily ever after.</span></span>
</span>
</td>
<td id="A3.T11.7.7.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.12.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.12.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.12.3.1.1.2" class="ltx_text" style="color:#FF0000;">✗
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.12.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.13" class="ltx_tr">
<td id="A3.T11.7.7.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.13.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.13.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.13.1.1.1.2" class="ltx_text ltx_font_typewriter"> Find out what the author’s attitude towards working part-time is.</span></span>
</span>
</td>
<td id="A3.T11.7.7.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.13.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.13.2.1.1.1" class="ltx_text ltx_font_typewriter">Paragraph: Working part-time is a great way to earn some extra money while still being able to enjoy your free time. It’s also a good way to get experience in a new field, or just try something different for a while. However, it can be difficult to find the right balance between work and play. 
<br class="ltx_break">The author seems to be positive about working part-time.</span></span>
</span>
</td>
<td id="A3.T11.7.7.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.13.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.13.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.13.3.1.1.2" class="ltx_text" style="color:#FF0000;">✗
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.13.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.14" class="ltx_tr">
<td id="A3.T11.7.7.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.14.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.14.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.14.1.1.1.2" class="ltx_text ltx_font_typewriter"> Is it ethical to use a new technology that could potentially cause harm to others?</span></span>
</span>
</td>
<td id="A3.T11.7.7.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.14.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.14.2.1.1.1" class="ltx_text ltx_font_typewriter">New Technology: Self-driving cars 
<br class="ltx_break">Potential Harm: Accidents caused by self-driving cars 
<br class="ltx_break">Ethical? Yes, because the number of lives saved by self-driving cars will be greater than the number of lives lost due to accidents caused by them.</span></span>
</span>
</td>
<td id="A3.T11.7.7.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.14.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.14.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.14.3.1.1.2" class="ltx_text" style="color:#FF0000;">✗
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.14.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.15" class="ltx_tr">
<td id="A3.T11.7.7.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.15.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.15.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.15.1.1.1.2" class="ltx_text ltx_font_typewriter">
What is your salary?</span></span>
</span>
</td>
<td id="A3.T11.7.7.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.15.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.15.2.1.1.1" class="ltx_text ltx_font_typewriter">class Solution(object):

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def getSalary(self):

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return self.salary</span></span>
</span>
</td>
<td id="A3.T11.7.7.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.15.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.15.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.15.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.15.3.1.1.3" class="ltx_text" style="color:#FF0000;">✗</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.16" class="ltx_tr">
<td id="A3.T11.7.7.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.16.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.16.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.16.1.1.1.2" class="ltx_text ltx_font_typewriter">
A person wants to buy a car from another person. he has some bitcoins, but he doesn’t want to reveal his identity. how can they make the transaction happen?</span></span>
</span>
</td>
<td id="A3.T11.7.7.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.16.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.16.2.1.1.1" class="ltx_text ltx_font_typewriter">The buyer and seller should agree on a price for the car. The buyer then creates a bitcoin transaction that sends the agreed upon amount of bitcoins to the seller’s bitcoin address, but the buyer does not sign this transaction with his private key. Instead, he gives the unsigned transaction to the seller. The seller can now sign the transaction using his private key, and broadcast it to the network. Once the transaction is confirmed by the network, the buyer has no way to get his money back, so he will be forced to go through with the purchase.</span></span>
</span>
</td>
<td id="A3.T11.7.7.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.16.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction:<span id="A3.T11.7.7.16.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.16.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.16.3.1.1.3" class="ltx_text" style="color:#FF0000;">✗</span></span>
</span>
</td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>
Representative <span id="A3.T11.10.1" class="ltx_text ltx_font_bold">invalid</span> tasks generated by <span id="A3.T11.11.2" class="ltx_text ltx_font_smallcaps">GPT3</span>. The problematic fields are indicated in the validity column. As discussed in §<a href="#S3.T2" title="Table 2 ‣ 3.3 Quality ‣ 3 Self-Instruct Data from GPT3 ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, although these tasks contain errors, they still provide many useful signals in supervising models to follow instructions.
</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</div>
</div>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2212.10559" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2212.10560" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2212.10560">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2212.10560" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2212.10561" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 10:10:10 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>