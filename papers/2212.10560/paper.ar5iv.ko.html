<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2212.10560] ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions</title><meta property="og:description" content="Large “instruction-tuned” language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks.
Nevertheless, they depend heavily on human-written ins…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2212.10560">

<!--Generated on Fri Mar  1 10:10:10 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">

 ACL 2023
<br class="ltx_break">
<span id="id17.id1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span>: Aligning Language Models 
<br class="ltx_break">with Self-Generated Instructions</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Yizhong Wang<sup id="id1.1.1" class="ltx_sup"><math id="id1.1.1.m1.1" class="ltx_Math" alttext="\clubsuit" display="inline"><semantics id="id1.1.1.m1.1a"><mi mathvariant="normal" id="id1.1.1.m1.1.1" xref="id1.1.1.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="id1.1.1.m1.1b"><ci id="id1.1.1.m1.1.1.cmml" xref="id1.1.1.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="id1.1.1.m1.1c">\clubsuit</annotation></semantics></math></sup>    
Yeganeh Kordi<sup id="id2.2.2" class="ltx_sup"><math id="id2.2.2.m1.1" class="ltx_Math" alttext="\diamondsuit" display="inline"><semantics id="id2.2.2.m1.1a"><mi mathvariant="normal" id="id2.2.2.m1.1.1" xref="id2.2.2.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="id2.2.2.m1.1b"><ci id="id2.2.2.m1.1.1.cmml" xref="id2.2.2.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="id2.2.2.m1.1c">\diamondsuit</annotation></semantics></math></sup>    
Swaroop Mishra<sup id="id3.3.3" class="ltx_sup"><math id="id3.3.3.m1.1" class="ltx_Math" alttext="\heartsuit" display="inline"><semantics id="id3.3.3.m1.1a"><mi mathvariant="normal" id="id3.3.3.m1.1.1" xref="id3.3.3.m1.1.1.cmml">♡</mi><annotation-xml encoding="MathML-Content" id="id3.3.3.m1.1b"><ci id="id3.3.3.m1.1.1.cmml" xref="id3.3.3.m1.1.1">♡</ci></annotation-xml><annotation encoding="application/x-tex" id="id3.3.3.m1.1c">\heartsuit</annotation></semantics></math></sup>    
<span id="id6.6.6" class="ltx_text ltx_font_bold">Alisa Liu<sup id="id4.4.4.1" class="ltx_sup"><math id="id4.4.4.1.m1.1" class="ltx_Math" alttext="\clubsuit" display="inline"><semantics id="id4.4.4.1.m1.1a"><mi mathvariant="normal" id="id4.4.4.1.m1.1.1" xref="id4.4.4.1.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="id4.4.4.1.m1.1b"><ci id="id4.4.4.1.m1.1.1.cmml" xref="id4.4.4.1.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="id4.4.4.1.m1.1c">\clubsuit</annotation></semantics></math></sup>
<br class="ltx_break">Noah A. Smith<sup id="id5.5.5.2" class="ltx_sup"><math id="id5.5.5.2.m1.1" class="ltx_Math" alttext="\clubsuit" display="inline"><semantics id="id5.5.5.2.m1.1a"><mi mathvariant="normal" id="id5.5.5.2.m1.1.1" xref="id5.5.5.2.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="id5.5.5.2.m1.1b"><ci id="id5.5.5.2.m1.1.1.cmml" xref="id5.5.5.2.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="id5.5.5.2.m1.1c">\clubsuit</annotation></semantics></math></sup><sup id="id6.6.6.3" class="ltx_sup"><math id="id6.6.6.3.m1.1" class="ltx_Math" alttext="+" display="inline"><semantics id="id6.6.6.3.m1.1a"><mo id="id6.6.6.3.m1.1.1" xref="id6.6.6.3.m1.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="id6.6.6.3.m1.1b"><plus id="id6.6.6.3.m1.1.1.cmml" xref="id6.6.6.3.m1.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="id6.6.6.3.m1.1c">+</annotation></semantics></math></sup></span>    
<span id="id7.7.7" class="ltx_text ltx_font_bold">Daniel Khashabi<sup id="id7.7.7.1" class="ltx_sup"><math id="id7.7.7.1.m1.1" class="ltx_Math" alttext="\spadesuit" display="inline"><semantics id="id7.7.7.1.m1.1a"><mi mathvariant="normal" id="id7.7.7.1.m1.1.1" xref="id7.7.7.1.m1.1.1.cmml">♠</mi><annotation-xml encoding="MathML-Content" id="id7.7.7.1.m1.1b"><ci id="id7.7.7.1.m1.1.1.cmml" xref="id7.7.7.1.m1.1.1">♠</ci></annotation-xml><annotation encoding="application/x-tex" id="id7.7.7.1.m1.1c">\spadesuit</annotation></semantics></math></sup></span>     
<span id="id10.10.10" class="ltx_text ltx_font_bold">Hannaneh Hajishirzi<sup id="id8.8.8.1" class="ltx_sup"><math id="id8.8.8.1.m1.1" class="ltx_Math" alttext="\clubsuit" display="inline"><semantics id="id8.8.8.1.m1.1a"><mi mathvariant="normal" id="id8.8.8.1.m1.1.1" xref="id8.8.8.1.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="id8.8.8.1.m1.1b"><ci id="id8.8.8.1.m1.1.1.cmml" xref="id8.8.8.1.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="id8.8.8.1.m1.1c">\clubsuit</annotation></semantics></math></sup><sup id="id9.9.9.2" class="ltx_sup"><math id="id9.9.9.2.m1.1" class="ltx_Math" alttext="+" display="inline"><semantics id="id9.9.9.2.m1.1a"><mo id="id9.9.9.2.m1.1.1" xref="id9.9.9.2.m1.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="id9.9.9.2.m1.1b"><plus id="id9.9.9.2.m1.1.1.cmml" xref="id9.9.9.2.m1.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="id9.9.9.2.m1.1c">+</annotation></semantics></math></sup>
<br class="ltx_break"><sup id="id10.10.10.3" class="ltx_sup"><math id="id10.10.10.3.m1.1" class="ltx_Math" alttext="\clubsuit" display="inline"><semantics id="id10.10.10.3.m1.1a"><mi mathvariant="normal" id="id10.10.10.3.m1.1.1" xref="id10.10.10.3.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="id10.10.10.3.m1.1b"><ci id="id10.10.10.3.m1.1.1.cmml" xref="id10.10.10.3.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="id10.10.10.3.m1.1c">\clubsuit</annotation></semantics></math></sup></span>University of Washington  
<sup id="id11.11.11" class="ltx_sup"><math id="id11.11.11.m1.1" class="ltx_Math" alttext="\diamondsuit" display="inline"><semantics id="id11.11.11.m1.1a"><mi mathvariant="normal" id="id11.11.11.m1.1.1" xref="id11.11.11.m1.1.1.cmml">♢</mi><annotation-xml encoding="MathML-Content" id="id11.11.11.m1.1b"><ci id="id11.11.11.m1.1.1.cmml" xref="id11.11.11.m1.1.1">♢</ci></annotation-xml><annotation encoding="application/x-tex" id="id11.11.11.m1.1c">\diamondsuit</annotation></semantics></math></sup>Tehran Polytechnic  
<sup id="id12.12.12" class="ltx_sup"><math id="id12.12.12.m1.1" class="ltx_Math" alttext="\heartsuit" display="inline"><semantics id="id12.12.12.m1.1a"><mi mathvariant="normal" id="id12.12.12.m1.1.1" xref="id12.12.12.m1.1.1.cmml">♡</mi><annotation-xml encoding="MathML-Content" id="id12.12.12.m1.1b"><ci id="id12.12.12.m1.1.1.cmml" xref="id12.12.12.m1.1.1">♡</ci></annotation-xml><annotation encoding="application/x-tex" id="id12.12.12.m1.1c">\heartsuit</annotation></semantics></math></sup>Arizona State University 
<br class="ltx_break"><sup id="id13.13.13" class="ltx_sup"><math id="id13.13.13.m1.1" class="ltx_Math" alttext="\spadesuit" display="inline"><semantics id="id13.13.13.m1.1a"><mi mathvariant="normal" id="id13.13.13.m1.1.1" xref="id13.13.13.m1.1.1.cmml">♠</mi><annotation-xml encoding="MathML-Content" id="id13.13.13.m1.1b"><ci id="id13.13.13.m1.1.1.cmml" xref="id13.13.13.m1.1.1">♠</ci></annotation-xml><annotation encoding="application/x-tex" id="id13.13.13.m1.1c">\spadesuit</annotation></semantics></math></sup>Johns Hopkins University  <sup id="id14.14.14" class="ltx_sup"><math id="id14.14.14.m1.1" class="ltx_Math" alttext="+" display="inline"><semantics id="id14.14.14.m1.1a"><mo id="id14.14.14.m1.1.1" xref="id14.14.14.m1.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="id14.14.14.m1.1b"><plus id="id14.14.14.m1.1.1.cmml" xref="id14.14.14.m1.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="id14.14.14.m1.1c">+</annotation></semantics></math></sup>Allen Institute for AI 
<br class="ltx_break"> <span id="id18.15.id1" class="ltx_text ltx_font_typewriter">yizhongw@cs.washington.edu</span>  
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id16.2">큰 "명령 조정" 언어 모델(즉, 명령에 응답하도록 미세 조정됨)은 제로 샷을 새로운 작업에 일반화하는 놀라운 능력을 입증했다. 그럼에도 불구하고, 이는 종종 양, 다양성 및 창의성이 제한되는 인간이 작성한 명령 데이터에 크게 의존하여 조정된 모델의 일반성을 방해한다. <span class="ltx_text ltx_font_smallcaps" id="id16.2.1">Self-Instruct</span>은 자신의 세대를 부트스트랩하여 사전 훈련된 언어 모델의 명령어 추종 능력을 향상시키기 위한 프레임워크이다. 당사의 파이프라인은 언어 모델에서 명령, 입력 및 출력 샘플을 생성한 다음 잘못된 샘플 또는 유사한 샘플을 필터링한 후 원래 모델을 미세 조정하기 위해 사용합니다. 본 논문에서 제안한 방법을 바닐라 <span class="ltx_text ltx_font_smallcaps" id="id16.2.2">GPT3</span>에 적용하여, 개인 사용자 데이터 및 인간 주석으로 학습한 <math alttext="\text{InstructGPT}_{\text{001}}" class="ltx_Math" display="inline" id="id15.1.m1.1"><semantics id="id15.1.m1.1a"><msub id="id15.1.m1.1.1" xref="id15.1.m1.1.1.cmml"><mtext id="id15.1.m1.1.1.2" xref="id15.1.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="id15.1.m1.1.1.3" xref="id15.1.m1.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="id15.1.m1.1b"><apply id="id15.1.m1.1.1.cmml" xref="id15.1.m1.1.1"><csymbol cd="ambiguous" id="id15.1.m1.1.1.1.cmml" xref="id15.1.m1.1.1">subscript</csymbol><ci id="id15.1.m1.1.1.2a.cmml" xref="id15.1.m1.1.1.2"><mtext id="id15.1.m1.1.1.2.cmml" xref="id15.1.m1.1.1.2">InstructGPT</mtext></ci><ci id="id15.1.m1.1.1.3a.cmml" xref="id15.1.m1.1.1.3"><mtext id="id15.1.m1.1.1.3.cmml" mathsize="70%" xref="id15.1.m1.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id15.1.m1.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>, <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Unless otherwise specified, our comparisons are with the <span class="ltx_text ltx_font_typewriter" id="footnote1.1">text-davinci-001</span> engine. We focus on this engine since it is the closest to our experimental setup: supervised finetuning with human demonstrations. The newer engines are more powerful, though they use more data (e.g., code completion or latest user queries) or algorithms (e.g., PPO) that are difficult to compare with.</span></span></span>의 성능과 동등하게 <span class="ltx_text ltx_font_smallcaps" id="id16.2.3">Super-NaturalInstructions</span>에서 기존 모델에 비해 33%의 절대적 향상을 보였다. 추가 평가를 위해 전문가에 의해 작성된 새로운 작업에 대한 명령어 세트를 큐레이트하고 인간 평가를 통해 GPT3을 <span class="ltx_text ltx_font_smallcaps" id="id16.2.4">Self-Instruct</span>이 기존 공개 명령어 데이터 세트를 사용하여 큰 마진만큼 성능이 향상되어 <math alttext="\text{InstructGPT}_{\text{001}}" class="ltx_Math" display="inline" id="id16.2.m2.1"><semantics id="id16.2.m2.1a"><msub id="id16.2.m2.1.1" xref="id16.2.m2.1.1.cmml"><mtext id="id16.2.m2.1.1.2" xref="id16.2.m2.1.1.2a.cmml">InstructGPT</mtext><mtext id="id16.2.m2.1.1.3" xref="id16.2.m2.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="id16.2.m2.1b"><apply id="id16.2.m2.1.1.cmml" xref="id16.2.m2.1.1"><csymbol cd="ambiguous" id="id16.2.m2.1.1.1.cmml" xref="id16.2.m2.1.1">subscript</csymbol><ci id="id16.2.m2.1.1.2a.cmml" xref="id16.2.m2.1.1.2"><mtext id="id16.2.m2.1.1.2.cmml" xref="id16.2.m2.1.1.2">InstructGPT</mtext></ci><ci id="id16.2.m2.1.1.3a.cmml" xref="id16.2.m2.1.1.3"><mtext id="id16.2.m2.1.1.3.cmml" mathsize="70%" xref="id16.2.m2.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id16.2.m2.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math> 뒤에 5% 절대 차이만 남김을 보여준다. <span class="ltx_text ltx_font_smallcaps" id="id16.2.5">Self-Instruct</span>은 사전 훈련된 언어 모델을 명령어와 정렬하기 위한 거의 주석 없는 방법을 제공하며, 명령어 튜닝에 대한 향후 연구를 용이하게 하기 위해 대규모 합성 데이터 세트를 출시한다. <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Code and data are available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/yizhongw/self-instruct" target="_blank" title="">https://github.com/yizhongw/self-instruct</a> </span></span></span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<figure id="S1.F1" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2212.10560/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="452" height="695" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 1:</span></figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
Selected tasks from the generated instruction data using vanilla <span id="S1.F1.2.1" class="ltx_text ltx_font_smallcaps">GPT3</span>. Some texts are reformatted for presentation. See <a href="#A3.T10" title="Table 10 ‣ Appendix C Task and Instance Examples from the Generated Instruction Data ‣ B.3 Example Predictions from GPT3_&quot;Self-Inst&quot; ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;10</span></a> for more examples.
</figcaption>
</figure>
<figure id="S1.F2" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2212.10560/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="315" height="138" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 2:</span></figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>
A high-level overview of <span id="S1.F2.3.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span>.
The process starts with a small seed set of tasks as the task pool.
Random tasks are sampled from the task pool, and used to prompt an off-the-shelf LM to generate both new instructions and corresponding instances,
followed by filtering low-quality or similar generations, and then added back to the initial repository of tasks. The resulting data can be used for the instruction tuning of the language model itself later to follow instructions better. Tasks shown in the figure are generated by <span id="S1.F2.4.2" class="ltx_text ltx_font_smallcaps">GPT3</span>.
</figcaption>
</figure>
<div id="S1.p1" class="ltx_para">
<p class="ltx_p" id="S1.p1.1">최근 NLP 문헌은 자연어 명령어 <cite class="ltx_cite ltx_citemacro_citep">(Mishra et al., <a class="ltx_ref" href="#bib.bib22" title="">2022</a>; Wei et al., <a class="ltx_ref" href="#bib.bib35" title="">2022</a>; Sanh et al., <a class="ltx_ref" href="#bib.bib27" title="">2022</a>; Wang et al., <a class="ltx_ref" href="#bib.bib33" title="">2022</a>; Ouyang et al., <a class="ltx_ref" href="#bib.bib23" title="">2022</a>; Chung et al., <a class="ltx_ref" href="#bib.bib4" title="">2022</a>, i.a.)</cite>를 따를 수 있는 모델 구축에서 엄청난 양의 활동을 목격했다. 이러한 개발은 큰 사전 훈련 언어 모델(LM)과 인간이 작성한 명령 데이터(예: <span class="ltx_text ltx_font_smallcaps" id="S1.p1.1.1">PromptSource</span> <cite class="ltx_cite ltx_citemacro_citep">(Bach et al., <a class="ltx_ref" href="#bib.bib2" title="">2022</a>)</cite> 및 <span class="ltx_text ltx_font_smallcaps" id="S1.p1.1.2">Super-NaturalInstructions</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib33" title="">2022</a>, <span class="ltx_text ltx_font_smallcaps" id="S1.p1.1.3.1">SuperNI</span> for short)</cite>)의 두 가지 주요 구성 요소에 의해 구동됩니다. 그러나 대부분의 인간 세대가 인기 있는 NLP 작업인 경향이 있어 진정한 다양한 작업과 이를 설명하는 다양한 방법에 미치지 못한다는 점을 감안할 때 이러한 명령 데이터를 수집하는 것은 비용이 많이 들고 종종 제한된 다양성을 겪는다. 명령어 조정 모델의 품질과 적용 범위를 계속 개선하려면 명령어 조정 프로세스를 감독하기 위한 대안적 접근법의 개발이 필요하다.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p" id="S1.p2.1">본 연구에서는 모델 자체의 지시 신호를 사용하여 사전 훈련된 LM을 지시 조정하기 위한 반자동 프로세스인 <span class="ltx_text ltx_font_smallcaps" id="S1.p2.1.1">Self-Instruct</span>을 소개한다. 전체 프로세스는 반복 부트스트래핑 알고리즘(<a class="ltx_ref ltx_refmacro_autoref" href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Figure 2</span></a> 참조)이며, 이는 전체 생성을 안내하는 데 사용되는 수동 작성 작업의 제한된 시드 세트(예: 우리 연구에서 175개)로 시작한다. 첫 번째 단계에서, 모델은 새로운 태스크들에 대한 명령어들을 생성하도록 프롬프트된다. 이 단계는 명령어들의 기존 컬렉션을 활용하여 (종종 새로운) 태스크들을 정의하는 보다 광범위한 커버리지 명령어들을 생성한다. 새로 생성된 명령어 세트가 주어지면, 프레임워크는 또한 이들에 대한 입력-출력 인스턴스를 생성하며, 이는 나중에 명령어 튜닝을 감독하는 데 사용될 수 있다. 마지막으로, 나머지 유효한 태스크들을 태스크 풀에 추가하기 전에, 저품질 또는 반복된 명령어들을 자동으로 필터링하기 위해 다양한 휴리스틱들이 사용된다. 이러한 프로세스는 많은 수의 태스크들에 도달할 때까지 많은 반복들에 대해 반복될 수 있다.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p" id="S1.p3.6"><span class="ltx_text ltx_font_smallcaps" id="S1.p3.6.5">Self-Instruct</span> 경험적으로 평가하기 위해 바닐라 LM(§<a class="ltx_ref" href="#S3" title="3 Self-Instruct Data from GPT3 ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">3</span></a>)인 <span class="ltx_text ltx_font_smallcaps" id="S1.p3.6.6">GPT3</span> <cite class="ltx_cite ltx_citemacro_cite">Brown et al. (<a class="ltx_ref" href="#bib.bib3" title="">2020</a>)</cite>에서 이 프레임워크를 실행합니다. 이 모델의 반복 <span class="ltx_text ltx_font_smallcaps" id="S1.p3.6.7">Self-Instruct</span> 프로세스는 약 82K 인스턴스 입력 및 대상 출력과 쌍을 이루는 약 52k 명령어로 이어집니다. 우리는 결과 데이터가 <a class="ltx_ref ltx_refmacro_autoref" href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>의 예제에 의해 입증된 바와 같이 다양한 범위의 창의적인 작업을 제공한다는 것을 관찰한다. 이들 생성된 태스크들은 전형적인 NLP 태스크들의 분포로부터 벗어나며, 또한 시드 태스크들(§<a class="ltx_ref" href="#S3.SS2" title="3.2 Diversity ‣ 3 Self-Instruct Data from GPT3 ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">3.2</span></a>)과 상당히 작은 중첩을 갖는다. 이 결과 데이터에 대해 Finetuning에 의해 <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.1">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="S1.p3.1.1.m1.1"><semantics id="S1.p3.1.1.m1.1a"><msub id="S1.p3.1.1.m1.1.1" xref="S1.p3.1.1.m1.1.1.cmml"><mi id="S1.p3.1.1.m1.1.1a" xref="S1.p3.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S1.p3.1.1.m1.1.1.1" xref="S1.p3.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p3.1.1.m1.1b"><apply id="S1.p3.1.1.m1.1.1.cmml" xref="S1.p3.1.1.m1.1.1"><ci id="S1.p3.1.1.m1.1.1.1a.cmml" xref="S1.p3.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S1.p3.1.1.m1.1.1.1.cmml" mathsize="70%" xref="S1.p3.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> <span class="ltx_text ltx_font_smallcaps" id="S1.p3.6.8">GPT3</span> (즉, 명령 데이터 생성에 사용된 동일한 모델)을 빌드합니다. <span class="ltx_text ltx_font_smallcaps" id="S1.p3.2.2">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="S1.p3.2.2.m1.1"><semantics id="S1.p3.2.2.m1.1a"><msub id="S1.p3.2.2.m1.1.1" xref="S1.p3.2.2.m1.1.1.cmml"><mi id="S1.p3.2.2.m1.1.1a" xref="S1.p3.2.2.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S1.p3.2.2.m1.1.1.1" xref="S1.p3.2.2.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p3.2.2.m1.1b"><apply id="S1.p3.2.2.m1.1.1.cmml" xref="S1.p3.2.2.m1.1.1"><ci id="S1.p3.2.2.m1.1.1.1a.cmml" xref="S1.p3.2.2.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S1.p3.2.2.m1.1.1.1.cmml" mathsize="70%" xref="S1.p3.2.2.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.2.2.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>은 <span class="ltx_text ltx_font_smallcaps" id="S1.p3.6.9">SuperNI</span><cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="#bib.bib33" title="">2022</a>)</cite> 및 명령어 후속 모델의 새로운 사용을 위해 생성된 새로운 명령어 세트를 다른 다양한 모델과 비교하여 평가한다(§<a class="ltx_ref" href="#S4" title="4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">4</span></a>). 그 결과 <span class="ltx_text ltx_font_smallcaps" id="S1.p3.3.3">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="S1.p3.3.3.m1.1"><semantics id="S1.p3.3.3.m1.1a"><msub id="S1.p3.3.3.m1.1.1" xref="S1.p3.3.3.m1.1.1.cmml"><mi id="S1.p3.3.3.m1.1.1a" xref="S1.p3.3.3.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S1.p3.3.3.m1.1.1.1" xref="S1.p3.3.3.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p3.3.3.m1.1b"><apply id="S1.p3.3.3.m1.1.1.cmml" xref="S1.p3.3.3.m1.1.1"><ci id="S1.p3.3.3.m1.1.1.1a.cmml" xref="S1.p3.3.3.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S1.p3.3.3.m1.1.1.1.cmml" mathsize="70%" xref="S1.p3.3.3.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.3.3.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>이 <span class="ltx_text ltx_font_smallcaps" id="S1.p3.6.10">GPT3</span> (the original model)의 성능을 큰 마진(+33.1%)만큼 상회하며 <math alttext="\text{InstructGPT}_{\text{001}}" class="ltx_Math" display="inline" id="S1.p3.4.m1.1"><semantics id="S1.p3.4.m1.1a"><msub id="S1.p3.4.m1.1.1" xref="S1.p3.4.m1.1.1.cmml"><mtext id="S1.p3.4.m1.1.1.2" xref="S1.p3.4.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="S1.p3.4.m1.1.1.3" xref="S1.p3.4.m1.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p3.4.m1.1b"><apply id="S1.p3.4.m1.1.1.cmml" xref="S1.p3.4.m1.1.1"><csymbol cd="ambiguous" id="S1.p3.4.m1.1.1.1.cmml" xref="S1.p3.4.m1.1.1">subscript</csymbol><ci id="S1.p3.4.m1.1.1.2a.cmml" xref="S1.p3.4.m1.1.1.2"><mtext id="S1.p3.4.m1.1.1.2.cmml" xref="S1.p3.4.m1.1.1.2">InstructGPT</mtext></ci><ci id="S1.p3.4.m1.1.1.3a.cmml" xref="S1.p3.4.m1.1.1.3"><mtext id="S1.p3.4.m1.1.1.3.cmml" mathsize="70%" xref="S1.p3.4.m1.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.4.m1.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>의 성능과 거의 일치함을 알 수 있었다. 또한, 새로 생성된 명령어 집합에 대한 인간 평가는 <span class="ltx_text ltx_font_smallcaps" id="S1.p3.5.4">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="S1.p3.5.4.m1.1"><semantics id="S1.p3.5.4.m1.1a"><msub id="S1.p3.5.4.m1.1.1" xref="S1.p3.5.4.m1.1.1.cmml"><mi id="S1.p3.5.4.m1.1.1a" xref="S1.p3.5.4.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S1.p3.5.4.m1.1.1.1" xref="S1.p3.5.4.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p3.5.4.m1.1b"><apply id="S1.p3.5.4.m1.1.1.cmml" xref="S1.p3.5.4.m1.1.1"><ci id="S1.p3.5.4.m1.1.1.1a.cmml" xref="S1.p3.5.4.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S1.p3.5.4.m1.1.1.1.cmml" mathsize="70%" xref="S1.p3.5.4.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.5.4.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>은 다른 공개적으로 사용 가능한 명령어 데이터셋에 대해 훈련된 모델을 능가하고 <math alttext="\text{InstructGPT}_{\text{001}}" class="ltx_Math" display="inline" id="S1.p3.6.m2.1"><semantics id="S1.p3.6.m2.1a"><msub id="S1.p3.6.m2.1.1" xref="S1.p3.6.m2.1.1.cmml"><mtext id="S1.p3.6.m2.1.1.2" xref="S1.p3.6.m2.1.1.2a.cmml">InstructGPT</mtext><mtext id="S1.p3.6.m2.1.1.3" xref="S1.p3.6.m2.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.p3.6.m2.1b"><apply id="S1.p3.6.m2.1.1.cmml" xref="S1.p3.6.m2.1.1"><csymbol cd="ambiguous" id="S1.p3.6.m2.1.1.1.cmml" xref="S1.p3.6.m2.1.1">subscript</csymbol><ci id="S1.p3.6.m2.1.1.2a.cmml" xref="S1.p3.6.m2.1.1.2"><mtext id="S1.p3.6.m2.1.1.2.cmml" xref="S1.p3.6.m2.1.1.2">InstructGPT</mtext></ci><ci id="S1.p3.6.m2.1.1.3a.cmml" xref="S1.p3.6.m2.1.1.3"><mtext id="S1.p3.6.m2.1.1.3.cmml" mathsize="70%" xref="S1.p3.6.m2.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.6.m2.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>에 5% 차이만 남기는 광범위한 명령어 추종 능력을 보여준다.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p" id="S1.p4.1">요약하면, 우리의 기여는 (1) <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.1">Self-Instruct</span>을 소개하고, (2) 광범위한 명령어 조정 실험을 통해 그 효과를 입증하고, (3) 향후 명령어 후속 모델을 구축하고 평가하기 위해 52K 명령어의 대규모 합성 데이터세트와 수동으로 작성된 새로운 태스크 세트를 출시한다.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Method</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p" id="S2.p1.1">대규모 수업 데이터를 주석하는 것은 1) 새로운 과제를 도출하기 위한 창의성과 2) 각 과제에 대한 해결책을 작성하기 위한 전문성이 필요하기 때문에 인간에게 어려울 수 있다. 여기서는 <span class="ltx_text ltx_font_smallcaps" id="S2.p1.1.1">Self-Instruct</span>에 대한 프로세스를 자세히 설명하며, 이는 <span class="ltx_text ltx_font_italic" id="S2.p1.1.2">vanilla 사전 훈련 언어 모델</span> 자체로 작업을 생성하고, 생성된 데이터를 필터링한 다음, LM이 명령을 더 잘 따르도록 정렬하기 위해 이 생성된 데이터로 명령 튜닝을 수행하는 파이프라인을 나타낸다. 이 파이프라인은 <a class="ltx_ref ltx_refmacro_autoref" href="#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>에 묘사되어 있다.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Defining Instruction Data</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.9" class="ltx_p">The instruction data we want to generate contains a set of instructions <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="\{I_{t}\}" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mrow id="S2.SS1.p1.1.m1.1.1.1" xref="S2.SS1.p1.1.m1.1.1.2.cmml"><mo stretchy="false" id="S2.SS1.p1.1.m1.1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.2.cmml">{</mo><msub id="S2.SS1.p1.1.m1.1.1.1.1" xref="S2.SS1.p1.1.m1.1.1.1.1.cmml"><mi id="S2.SS1.p1.1.m1.1.1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.1.1.2.cmml">I</mi><mi id="S2.SS1.p1.1.m1.1.1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.SS1.p1.1.m1.1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.2.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><set id="S2.SS1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.1"><apply id="S2.SS1.p1.1.m1.1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.1.m1.1.1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1.2">𝐼</ci><ci id="S2.SS1.p1.1.m1.1.1.1.1.3.cmml" xref="S2.SS1.p1.1.m1.1.1.1.1.3">𝑡</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">\{I_{t}\}</annotation></semantics></math>, each of which defines a task <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">t</annotation></semantics></math> in natural language. Task <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">t</annotation></semantics></math> has <math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="n_{t}\geq 1" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><mrow id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml"><msub id="S2.SS1.p1.4.m4.1.1.2" xref="S2.SS1.p1.4.m4.1.1.2.cmml"><mi id="S2.SS1.p1.4.m4.1.1.2.2" xref="S2.SS1.p1.4.m4.1.1.2.2.cmml">n</mi><mi id="S2.SS1.p1.4.m4.1.1.2.3" xref="S2.SS1.p1.4.m4.1.1.2.3.cmml">t</mi></msub><mo id="S2.SS1.p1.4.m4.1.1.1" xref="S2.SS1.p1.4.m4.1.1.1.cmml">≥</mo><mn id="S2.SS1.p1.4.m4.1.1.3" xref="S2.SS1.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><apply id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1"><geq id="S2.SS1.p1.4.m4.1.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1.1"></geq><apply id="S2.SS1.p1.4.m4.1.1.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p1.4.m4.1.1.2.1.cmml" xref="S2.SS1.p1.4.m4.1.1.2">subscript</csymbol><ci id="S2.SS1.p1.4.m4.1.1.2.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2.2">𝑛</ci><ci id="S2.SS1.p1.4.m4.1.1.2.3.cmml" xref="S2.SS1.p1.4.m4.1.1.2.3">𝑡</ci></apply><cn type="integer" id="S2.SS1.p1.4.m4.1.1.3.cmml" xref="S2.SS1.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">n_{t}\geq 1</annotation></semantics></math> input-output instances <math id="S2.SS1.p1.5.m5.5" class="ltx_Math" alttext="\{(X_{t,i},Y_{t,i})\}_{i=1}^{n_{t}}" display="inline"><semantics id="S2.SS1.p1.5.m5.5a"><msubsup id="S2.SS1.p1.5.m5.5.5" xref="S2.SS1.p1.5.m5.5.5.cmml"><mrow id="S2.SS1.p1.5.m5.5.5.1.1.1" xref="S2.SS1.p1.5.m5.5.5.1.1.2.cmml"><mo stretchy="false" id="S2.SS1.p1.5.m5.5.5.1.1.1.2" xref="S2.SS1.p1.5.m5.5.5.1.1.2.cmml">{</mo><mrow id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.3" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.3.cmml">(</mo><msub id="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1.2" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1.2.cmml">X</mi><mrow id="S2.SS1.p1.5.m5.2.2.2.4" xref="S2.SS1.p1.5.m5.2.2.2.3.cmml"><mi id="S2.SS1.p1.5.m5.1.1.1.1" xref="S2.SS1.p1.5.m5.1.1.1.1.cmml">t</mi><mo id="S2.SS1.p1.5.m5.2.2.2.4.1" xref="S2.SS1.p1.5.m5.2.2.2.3.cmml">,</mo><mi id="S2.SS1.p1.5.m5.2.2.2.2" xref="S2.SS1.p1.5.m5.2.2.2.2.cmml">i</mi></mrow></msub><mo id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.4" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.3.cmml">,</mo><msub id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2.cmml"><mi id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2.2" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2.2.cmml">Y</mi><mrow id="S2.SS1.p1.5.m5.4.4.2.4" xref="S2.SS1.p1.5.m5.4.4.2.3.cmml"><mi id="S2.SS1.p1.5.m5.3.3.1.1" xref="S2.SS1.p1.5.m5.3.3.1.1.cmml">t</mi><mo id="S2.SS1.p1.5.m5.4.4.2.4.1" xref="S2.SS1.p1.5.m5.4.4.2.3.cmml">,</mo><mi id="S2.SS1.p1.5.m5.4.4.2.2" xref="S2.SS1.p1.5.m5.4.4.2.2.cmml">i</mi></mrow></msub><mo stretchy="false" id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.5" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S2.SS1.p1.5.m5.5.5.1.1.1.3" xref="S2.SS1.p1.5.m5.5.5.1.1.2.cmml">}</mo></mrow><mrow id="S2.SS1.p1.5.m5.5.5.1.3" xref="S2.SS1.p1.5.m5.5.5.1.3.cmml"><mi id="S2.SS1.p1.5.m5.5.5.1.3.2" xref="S2.SS1.p1.5.m5.5.5.1.3.2.cmml">i</mi><mo id="S2.SS1.p1.5.m5.5.5.1.3.1" xref="S2.SS1.p1.5.m5.5.5.1.3.1.cmml">=</mo><mn id="S2.SS1.p1.5.m5.5.5.1.3.3" xref="S2.SS1.p1.5.m5.5.5.1.3.3.cmml">1</mn></mrow><msub id="S2.SS1.p1.5.m5.5.5.3" xref="S2.SS1.p1.5.m5.5.5.3.cmml"><mi id="S2.SS1.p1.5.m5.5.5.3.2" xref="S2.SS1.p1.5.m5.5.5.3.2.cmml">n</mi><mi id="S2.SS1.p1.5.m5.5.5.3.3" xref="S2.SS1.p1.5.m5.5.5.3.3.cmml">t</mi></msub></msubsup><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.5b"><apply id="S2.SS1.p1.5.m5.5.5.cmml" xref="S2.SS1.p1.5.m5.5.5"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.5.5.2.cmml" xref="S2.SS1.p1.5.m5.5.5">superscript</csymbol><apply id="S2.SS1.p1.5.m5.5.5.1.cmml" xref="S2.SS1.p1.5.m5.5.5"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.5.5.1.2.cmml" xref="S2.SS1.p1.5.m5.5.5">subscript</csymbol><set id="S2.SS1.p1.5.m5.5.5.1.1.2.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1"><interval closure="open" id="S2.SS1.p1.5.m5.5.5.1.1.1.1.3.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.2"><apply id="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.1.1.2">𝑋</ci><list id="S2.SS1.p1.5.m5.2.2.2.3.cmml" xref="S2.SS1.p1.5.m5.2.2.2.4"><ci id="S2.SS1.p1.5.m5.1.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1">𝑡</ci><ci id="S2.SS1.p1.5.m5.2.2.2.2.cmml" xref="S2.SS1.p1.5.m5.2.2.2.2">𝑖</ci></list></apply><apply id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2.1.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2">subscript</csymbol><ci id="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2.2.cmml" xref="S2.SS1.p1.5.m5.5.5.1.1.1.1.2.2.2">𝑌</ci><list id="S2.SS1.p1.5.m5.4.4.2.3.cmml" xref="S2.SS1.p1.5.m5.4.4.2.4"><ci id="S2.SS1.p1.5.m5.3.3.1.1.cmml" xref="S2.SS1.p1.5.m5.3.3.1.1">𝑡</ci><ci id="S2.SS1.p1.5.m5.4.4.2.2.cmml" xref="S2.SS1.p1.5.m5.4.4.2.2">𝑖</ci></list></apply></interval></set><apply id="S2.SS1.p1.5.m5.5.5.1.3.cmml" xref="S2.SS1.p1.5.m5.5.5.1.3"><eq id="S2.SS1.p1.5.m5.5.5.1.3.1.cmml" xref="S2.SS1.p1.5.m5.5.5.1.3.1"></eq><ci id="S2.SS1.p1.5.m5.5.5.1.3.2.cmml" xref="S2.SS1.p1.5.m5.5.5.1.3.2">𝑖</ci><cn type="integer" id="S2.SS1.p1.5.m5.5.5.1.3.3.cmml" xref="S2.SS1.p1.5.m5.5.5.1.3.3">1</cn></apply></apply><apply id="S2.SS1.p1.5.m5.5.5.3.cmml" xref="S2.SS1.p1.5.m5.5.5.3"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.5.5.3.1.cmml" xref="S2.SS1.p1.5.m5.5.5.3">subscript</csymbol><ci id="S2.SS1.p1.5.m5.5.5.3.2.cmml" xref="S2.SS1.p1.5.m5.5.5.3.2">𝑛</ci><ci id="S2.SS1.p1.5.m5.5.5.3.3.cmml" xref="S2.SS1.p1.5.m5.5.5.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.5c">\{(X_{t,i},Y_{t,i})\}_{i=1}^{n_{t}}</annotation></semantics></math>. A model <math id="S2.SS1.p1.6.m6.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.SS1.p1.6.m6.1a"><mi id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><ci id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">M</annotation></semantics></math> is expected to produce the output, given the task instruction and the corresponding input: <math id="S2.SS1.p1.7.m7.6" class="ltx_Math" alttext="M(I_{t},X_{t,i})=Y_{t,i}" display="inline"><semantics id="S2.SS1.p1.7.m7.6a"><mrow id="S2.SS1.p1.7.m7.6.6" xref="S2.SS1.p1.7.m7.6.6.cmml"><mrow id="S2.SS1.p1.7.m7.6.6.2" xref="S2.SS1.p1.7.m7.6.6.2.cmml"><mi id="S2.SS1.p1.7.m7.6.6.2.4" xref="S2.SS1.p1.7.m7.6.6.2.4.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.SS1.p1.7.m7.6.6.2.3" xref="S2.SS1.p1.7.m7.6.6.2.3.cmml">​</mo><mrow id="S2.SS1.p1.7.m7.6.6.2.2.2" xref="S2.SS1.p1.7.m7.6.6.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p1.7.m7.6.6.2.2.2.3" xref="S2.SS1.p1.7.m7.6.6.2.2.3.cmml">(</mo><msub id="S2.SS1.p1.7.m7.5.5.1.1.1.1" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.cmml"><mi id="S2.SS1.p1.7.m7.5.5.1.1.1.1.2" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.2.cmml">I</mi><mi id="S2.SS1.p1.7.m7.5.5.1.1.1.1.3" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.SS1.p1.7.m7.6.6.2.2.2.4" xref="S2.SS1.p1.7.m7.6.6.2.2.3.cmml">,</mo><msub id="S2.SS1.p1.7.m7.6.6.2.2.2.2" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2.cmml"><mi id="S2.SS1.p1.7.m7.6.6.2.2.2.2.2" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2.2.cmml">X</mi><mrow id="S2.SS1.p1.7.m7.2.2.2.4" xref="S2.SS1.p1.7.m7.2.2.2.3.cmml"><mi id="S2.SS1.p1.7.m7.1.1.1.1" xref="S2.SS1.p1.7.m7.1.1.1.1.cmml">t</mi><mo id="S2.SS1.p1.7.m7.2.2.2.4.1" xref="S2.SS1.p1.7.m7.2.2.2.3.cmml">,</mo><mi id="S2.SS1.p1.7.m7.2.2.2.2" xref="S2.SS1.p1.7.m7.2.2.2.2.cmml">i</mi></mrow></msub><mo stretchy="false" id="S2.SS1.p1.7.m7.6.6.2.2.2.5" xref="S2.SS1.p1.7.m7.6.6.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p1.7.m7.6.6.3" xref="S2.SS1.p1.7.m7.6.6.3.cmml">=</mo><msub id="S2.SS1.p1.7.m7.6.6.4" xref="S2.SS1.p1.7.m7.6.6.4.cmml"><mi id="S2.SS1.p1.7.m7.6.6.4.2" xref="S2.SS1.p1.7.m7.6.6.4.2.cmml">Y</mi><mrow id="S2.SS1.p1.7.m7.4.4.2.4" xref="S2.SS1.p1.7.m7.4.4.2.3.cmml"><mi id="S2.SS1.p1.7.m7.3.3.1.1" xref="S2.SS1.p1.7.m7.3.3.1.1.cmml">t</mi><mo id="S2.SS1.p1.7.m7.4.4.2.4.1" xref="S2.SS1.p1.7.m7.4.4.2.3.cmml">,</mo><mi id="S2.SS1.p1.7.m7.4.4.2.2" xref="S2.SS1.p1.7.m7.4.4.2.2.cmml">i</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m7.6b"><apply id="S2.SS1.p1.7.m7.6.6.cmml" xref="S2.SS1.p1.7.m7.6.6"><eq id="S2.SS1.p1.7.m7.6.6.3.cmml" xref="S2.SS1.p1.7.m7.6.6.3"></eq><apply id="S2.SS1.p1.7.m7.6.6.2.cmml" xref="S2.SS1.p1.7.m7.6.6.2"><times id="S2.SS1.p1.7.m7.6.6.2.3.cmml" xref="S2.SS1.p1.7.m7.6.6.2.3"></times><ci id="S2.SS1.p1.7.m7.6.6.2.4.cmml" xref="S2.SS1.p1.7.m7.6.6.2.4">𝑀</ci><interval closure="open" id="S2.SS1.p1.7.m7.6.6.2.2.3.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.2"><apply id="S2.SS1.p1.7.m7.5.5.1.1.1.1.cmml" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.5.5.1.1.1.1.1.cmml" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.7.m7.5.5.1.1.1.1.2.cmml" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.2">𝐼</ci><ci id="S2.SS1.p1.7.m7.5.5.1.1.1.1.3.cmml" xref="S2.SS1.p1.7.m7.5.5.1.1.1.1.3">𝑡</ci></apply><apply id="S2.SS1.p1.7.m7.6.6.2.2.2.2.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.6.6.2.2.2.2.1.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p1.7.m7.6.6.2.2.2.2.2.cmml" xref="S2.SS1.p1.7.m7.6.6.2.2.2.2.2">𝑋</ci><list id="S2.SS1.p1.7.m7.2.2.2.3.cmml" xref="S2.SS1.p1.7.m7.2.2.2.4"><ci id="S2.SS1.p1.7.m7.1.1.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1.1.1">𝑡</ci><ci id="S2.SS1.p1.7.m7.2.2.2.2.cmml" xref="S2.SS1.p1.7.m7.2.2.2.2">𝑖</ci></list></apply></interval></apply><apply id="S2.SS1.p1.7.m7.6.6.4.cmml" xref="S2.SS1.p1.7.m7.6.6.4"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.6.6.4.1.cmml" xref="S2.SS1.p1.7.m7.6.6.4">subscript</csymbol><ci id="S2.SS1.p1.7.m7.6.6.4.2.cmml" xref="S2.SS1.p1.7.m7.6.6.4.2">𝑌</ci><list id="S2.SS1.p1.7.m7.4.4.2.3.cmml" xref="S2.SS1.p1.7.m7.4.4.2.4"><ci id="S2.SS1.p1.7.m7.3.3.1.1.cmml" xref="S2.SS1.p1.7.m7.3.3.1.1">𝑡</ci><ci id="S2.SS1.p1.7.m7.4.4.2.2.cmml" xref="S2.SS1.p1.7.m7.4.4.2.2">𝑖</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m7.6c">M(I_{t},X_{t,i})=Y_{t,i}</annotation></semantics></math>, for <math id="S2.SS1.p1.8.m8.3" class="ltx_Math" alttext="i\in\{1,\ldots,n_{t}\}" display="inline"><semantics id="S2.SS1.p1.8.m8.3a"><mrow id="S2.SS1.p1.8.m8.3.3" xref="S2.SS1.p1.8.m8.3.3.cmml"><mi id="S2.SS1.p1.8.m8.3.3.3" xref="S2.SS1.p1.8.m8.3.3.3.cmml">i</mi><mo id="S2.SS1.p1.8.m8.3.3.2" xref="S2.SS1.p1.8.m8.3.3.2.cmml">∈</mo><mrow id="S2.SS1.p1.8.m8.3.3.1.1" xref="S2.SS1.p1.8.m8.3.3.1.2.cmml"><mo stretchy="false" id="S2.SS1.p1.8.m8.3.3.1.1.2" xref="S2.SS1.p1.8.m8.3.3.1.2.cmml">{</mo><mn id="S2.SS1.p1.8.m8.1.1" xref="S2.SS1.p1.8.m8.1.1.cmml">1</mn><mo id="S2.SS1.p1.8.m8.3.3.1.1.3" xref="S2.SS1.p1.8.m8.3.3.1.2.cmml">,</mo><mi mathvariant="normal" id="S2.SS1.p1.8.m8.2.2" xref="S2.SS1.p1.8.m8.2.2.cmml">…</mi><mo id="S2.SS1.p1.8.m8.3.3.1.1.4" xref="S2.SS1.p1.8.m8.3.3.1.2.cmml">,</mo><msub id="S2.SS1.p1.8.m8.3.3.1.1.1" xref="S2.SS1.p1.8.m8.3.3.1.1.1.cmml"><mi id="S2.SS1.p1.8.m8.3.3.1.1.1.2" xref="S2.SS1.p1.8.m8.3.3.1.1.1.2.cmml">n</mi><mi id="S2.SS1.p1.8.m8.3.3.1.1.1.3" xref="S2.SS1.p1.8.m8.3.3.1.1.1.3.cmml">t</mi></msub><mo stretchy="false" id="S2.SS1.p1.8.m8.3.3.1.1.5" xref="S2.SS1.p1.8.m8.3.3.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m8.3b"><apply id="S2.SS1.p1.8.m8.3.3.cmml" xref="S2.SS1.p1.8.m8.3.3"><in id="S2.SS1.p1.8.m8.3.3.2.cmml" xref="S2.SS1.p1.8.m8.3.3.2"></in><ci id="S2.SS1.p1.8.m8.3.3.3.cmml" xref="S2.SS1.p1.8.m8.3.3.3">𝑖</ci><set id="S2.SS1.p1.8.m8.3.3.1.2.cmml" xref="S2.SS1.p1.8.m8.3.3.1.1"><cn type="integer" id="S2.SS1.p1.8.m8.1.1.cmml" xref="S2.SS1.p1.8.m8.1.1">1</cn><ci id="S2.SS1.p1.8.m8.2.2.cmml" xref="S2.SS1.p1.8.m8.2.2">…</ci><apply id="S2.SS1.p1.8.m8.3.3.1.1.1.cmml" xref="S2.SS1.p1.8.m8.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.8.m8.3.3.1.1.1.1.cmml" xref="S2.SS1.p1.8.m8.3.3.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.8.m8.3.3.1.1.1.2.cmml" xref="S2.SS1.p1.8.m8.3.3.1.1.1.2">𝑛</ci><ci id="S2.SS1.p1.8.m8.3.3.1.1.1.3.cmml" xref="S2.SS1.p1.8.m8.3.3.1.1.1.3">𝑡</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m8.3c">i\in\{1,\ldots,n_{t}\}</annotation></semantics></math>. Note that the instruction and instance input does not have a strict boundary in many cases. For example, “write an essay about school safety” can be a valid instruction that we expect models to respond to directly, while it can also be formulated as “write an essay about the following topic” as the instruction, and “school safety” as an instance input. To encourage the diversity of the data format, we allow such instructions that do not require additional input (i.e., <math id="S2.SS1.p1.9.m9.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S2.SS1.p1.9.m9.1a"><mi id="S2.SS1.p1.9.m9.1.1" xref="S2.SS1.p1.9.m9.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.9.m9.1b"><ci id="S2.SS1.p1.9.m9.1.1.cmml" xref="S2.SS1.p1.9.m9.1.1">𝑋</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.9.m9.1c">X</annotation></semantics></math> is empty).</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Automatic Instruction Data Generation</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p1.1">데이터 생성을 위한 파이프라인은 1) 작업 명령어 생성, 2) 명령어가 분류 작업을 나타내는지 판단하는 단계, 3) 입력-우선 또는 출력-우선 접근 방식을 사용하는 인스턴스 생성, 4) 저품질 데이터를 필터링하는 단계로 구성된다.</p>
</div>
<section id="S2.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Instruction Generation.</h4>

<div id="S2.SS2.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.1">첫 번째 단계에서 <span class="ltx_text ltx_font_smallcaps" id="S2.SS2.SSS0.Px1.p1.1.1">Self-Instruct</span>은 부트스트래핑 방식으로 작은 세트의 시드 인간 작성 명령으로부터 새로운 명령을 생성한다. 우리는 175개의 태스크(각 태스크에 대한 1개의 명령 및 1개의 인스턴스)로 태스크 풀을 시작한다. <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>These tasks were newly written by the authors and their labmates at UW, without reference to existing datasets or the test set used in this work. We provide more details about these tasks and analyze their similarity to the test tasks in Appendix §<a class="ltx_ref" href="#A1.SS1" title="A.1 Writing the Seed Tasks ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</span></span></span> 모든 단계에 대해 컨텍스트 내 예제로 이 풀에서 8개의 작업 지침을 샘플링합니다. 8개의 명령 중 6개는 인간이 작성한 작업에서, 2개는 다양성을 촉진하기 위해 이전 단계에서 모델이 생성한 작업에서 가져온 것이다. 프롬핑 템플릿은 <a class="ltx_ref ltx_refmacro_autoref" href="#A1.T5" title="Table 5 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Table 5</span></a>에 나와 있다.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Classification Task Identification.</h4>

<div id="S2.SS2.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px2.p1.1">우리는 분류 태스크와 비분류 태스크에 대해 두 가지 다른 접근법이 필요하기 때문에, 다음으로 생성된 명령어가 분류 태스크를 나타내는지 여부를 식별한다. <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>More concretely, we regard tasks that have a small limited output label space as classification tasks.</span></span></span> 시드 작업에서 12개의 분류 명령과 19개의 비분류 명령을 사용하여 몇 번의 샷 방식으로 LM을 프롬프트하여 이를 결정합니다. 프롬핑 템플릿은 <a class="ltx_ref ltx_refmacro_autoref" href="#A1.T6" title="Table 6 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Table 6</span></a>에 나와 있다.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Instance Generation.</h4>

<div id="S2.SS2.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px3.p1.1">명령어와 태스크 유형이 주어지면, 우리는 각 명령어에 대한 인스턴스를 독립적으로 생성한다. 이는 모델이 목표 태스크가 무엇인지 이해하고, 명령어를 기반으로 추가 입력 필드가 필요한 것을 파악하여 생성한 후, 최종적으로 출력을 산출함으로써 태스크를 완성해야 하기 때문에 어렵다. 우리는 사전 훈련된 LMs가 다른 태스크의 명령-입력-출력 컨텍스트 예제로 프롬프트될 때 이를 크게 달성할 수 있음을 발견했다. 이를 수행하는 자연스러운 방법은 <span class="ltx_text ltx_font_bold" id="S2.SS2.SSS0.Px3.p1.1.1">Input-first Approach</span>이며, 여기서 LM에게 명령을 기반으로 먼저 입력 필드를 작성한 다음 해당 출력을 생성하도록 요청할 수 있습니다. 이러한 생성 순서는 명령 및 입력에 응답하기 위해 모델들이 사용되는 방식과 유사하지만, 여기서는 다른 태스크들의 문맥 내 예시들을 갖는다. 프롬핑 템플릿은 <a class="ltx_ref ltx_refmacro_autoref" href="#A1.T7" title="Table 7 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Table 7</span></a>에 나와 있다.</p>
</div>
<div id="S2.SS2.SSS0.Px3.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px3.p2.1">그러나, 우리는 이 접근법이 특히 분류 태스크(예를 들어, 문법 오류 검출의 경우, 일반적으로 문법 입력을 생성함)에 대해 하나의 라벨에 편향된 입력을 생성할 수 있다는 것을 발견했다. 따라서 우리는 분류 작업에 대해 <span class="ltx_text ltx_font_bold" id="S2.SS2.SSS0.Px3.p2.1.1">Output-first Approach</span>을 추가로 제안하며, 여기서 먼저 가능한 클래스 레이블을 생성한 다음 각 클래스 레이블에 대한 입력 생성을 조건화한다. 프롬핑 템플릿은 <a class="ltx_ref ltx_refmacro_autoref" href="#A1.T8" title="Table 8 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Table 8</span></a>에 나와 있다. <span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>In this work, we use a fixed set of seed tasks for prompting the instance generation, and thus only generate a small number of instances per task in one round. Future work can use randomly sampled tasks to prompt the model to generate a larger number of instances in multiple rounds.</span></span></span> 전자 단계에서 식별된 분류 작업에 출력 우선 접근법을 적용하고 나머지 비분류 작업에 입력 우선 접근법을 적용한다.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Filtering and Postprocessing.</h4>

<div id="S2.SS2.SSS0.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px4.p1.1">다양성을 장려하기 위해 기존 명령어와의 ROUGE-L 유사도가 0.7 미만인 경우에만 새로운 명령어를 태스크 풀에 추가한다. 또한 일반적으로 LMs에 의해 처리될 수 없는 일부 특정 키워드(예: 이미지, 그림, 그래프)를 포함하는 명령어도 제외한다. 각 명령어에 대해 새로운 인스턴스를 생성할 때, 우리는 정확히 동일한 또는 동일한 입력이지만 상이한 출력을 갖는 인스턴스를 필터링한다. 잘못된 세대가 식별되고 휴리스틱에 기초하여 필터링된다(예를 들어, 명령은 너무 길거나 너무 짧다, 인스턴스 출력은 입력의 반복이다).</p>
</div>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Finetuning the LM to Follow Instructions</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p1.1">대규모 명령어 데이터를 생성한 후 이를 사용하여 원래 LM(즉, <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.p1.1.1">Self-Instruct</span>)을 미세 조정합니다. 이를 위해 명령어와 인스턴스 입력을 프롬프트로 연결하고 모델을 훈련하여 표준 감독 방식으로 인스턴스 출력을 생성한다. 모델을 다른 포맷에 강건하게 만들기 위해, 우리는 명령어와 인스턴스 입력을 함께 인코딩하기 위해 여러 템플릿을 사용한다. 예를 들어, 명령어는 "Task:" 또는 "Not"로 접두사가 붙을 수 있고, 입력은 "Input:" 또는 "Not"로 접두사가 붙을 수 있으며, 프롬프트의 끝에 "Output:"이 붙을 수 있고, 중간에 다른 수의 브레이크 라인이 들어갈 수 있다.</p>
</div>
<figure id="S2.F5" class="ltx_figure">
<p class="ltx_p" id="S2.F5.5"><span class="ltx_text" id="S2.F5.1.1.1" style="position:relative; bottom:-210.3pt;"><span class="ltx_inline-block ltx_transformed_outer" style="width:245.2pt;height:413.6pt;vertical-align:-203.3pt;"><span class="ltx_p" id="S2.F5.1.1.1.1.1.1.1.1.1.1.1.1" style="width:238.5pt;"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="311" id="S2.F5.1.1.1.1.1.1.g1" src="https://ar5iv.labs.arxiv.org/html/2212.10560/assets/x3.png" width="298"/> <span class="ltx_caption lt 이들의 다양성에도 불구하고, 여기에 도시된 명령어들은 많은 명령어들(예를 들어, “사용자가 서비스에 만족하는지 여부를 분류한다.”)이 그러한 동사-명사 구조를 포함하지 않기 때문에 생성된 명령어들의 전체 14%만을 차지한다. (0.0pt,0.0pt) scale(1,1) ;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;"><span class="ltx_p" style="S2.F5.5.5.4.4.4" style="width:180.1pt;height:582.2pt;vertical-align:-287.6pt;"><span class="ltx_text" id="S2.F5.5.5.4.4.4.4.4.4.4"><span class="ltx_graphics ltx_minipage ltx_align_middle" id="S2.F5.5.5.4.4.4.4.4.4.4" style="width:173.4pt;"><span class="ltx_graphics ltx_img_landscape" height="80" id="S2.F5.2.2.1. [Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="101" id="S2.F5.3.3.2.2.2.2.2.2"><img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="148" id="S2.F5.4.4.3.3.3.g1" src="https://ar5iv.labs.arxiv.org/html/2212.10560/assets/x5.png" width="332"/> </span> <span class="ltx_figure" id="S2.F5.4.4.4.4.4.4.4.4.g1" src="https://ar5iv.labs.arxiv.org/html/2212.10560/assets/x5.png" width="332"/> </span> <span class="ltx_figure" id="S2. </span><//span></span></span></span></p>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> Data from <span id="S3.2.2" class="ltx_text ltx_font_smallcaps">GPT3</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p" id="S3.p1.1">본 절에서는 사례 연구로 <span class="ltx_text ltx_font_smallcaps" id="S3.p1.1.1">GPT3</span>에 명령어 데이터를 유도하는 방법을 적용한다. 우리는 OpenAI API를 통해 접근한 가장 큰 GPT3 LM(“다빈치” 엔진)을 사용한다. <span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/api/" target="_blank" title="">https://openai.com/api/</a></span></span></span> 쿼리를 만들기 위한 매개 변수는 부록 <a class="ltx_ref" href="#A1.SS2" title="A.2 Querying the GPT3 API ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">A.2</span></a>에 설명되어 있습니다. 여기서는 생성된 데이터에 대한 개요를 제시한다.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Statistics</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.p1.1"><a class="ltx_ref ltx_refmacro_autoref" href="#S3.T1" title="Table 1 ‣ 3.1 Statistics ‣ 3 Self-Instruct Data from GPT3 ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Table 1</span></a>는 생성된 데이터의 기초 통계량을 설명한다. 우리는 필터링 후 총 52K개 이상의 명령어와 이 명령어에 해당하는 82K개 이상의 인스턴스를 생성한다.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt ltx_border_t">statistic</td>
<td id="S3.T1.1.1.2" class="ltx_td ltx_border_tt ltx_border_t"></td>
</tr>
<tr id="S3.T1.1.2" class="ltx_tr">
<td id="S3.T1.1.2.1" class="ltx_td ltx_align_left ltx_border_t"># of instructions</td>
<td id="S3.T1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">52,445</td>
</tr>
<tr id="S3.T1.1.3" class="ltx_tr">
<td id="S3.T1.1.3.1" class="ltx_td ltx_align_left">- # of classification instructions</td>
<td id="S3.T1.1.3.2" class="ltx_td ltx_align_center">11,584</td>
</tr>
<tr id="S3.T1.1.4" class="ltx_tr">
<td id="S3.T1.1.4.1" class="ltx_td ltx_align_left">- # of non-classification instructions</td>
<td id="S3.T1.1.4.2" class="ltx_td ltx_align_center">40,861</td>
</tr>
<tr id="S3.T1.1.5" class="ltx_tr">
<td id="S3.T1.1.5.1" class="ltx_td ltx_align_left"># of instances</td>
<td id="S3.T1.1.5.2" class="ltx_td ltx_align_center">82,439</td>
</tr>
<tr id="S3.T1.1.6" class="ltx_tr">
<td id="S3.T1.1.6.1" class="ltx_td ltx_align_left">- # of instances with empty input</td>
<td id="S3.T1.1.6.2" class="ltx_td ltx_align_center">35,878</td>
</tr>
<tr id="S3.T1.1.7" class="ltx_tr">
<td id="S3.T1.1.7.1" class="ltx_td ltx_align_left">ave.&nbsp;instruction length (in words)</td>
<td id="S3.T1.1.7.2" class="ltx_td ltx_align_center">15.9</td>
</tr>
<tr id="S3.T1.1.8" class="ltx_tr">
<td id="S3.T1.1.8.1" class="ltx_td ltx_align_left">ave.&nbsp;non-empty input length (in words)</td>
<td id="S3.T1.1.8.2" class="ltx_td ltx_align_center">12.7</td>
</tr>
<tr id="S3.T1.1.9" class="ltx_tr">
<td id="S3.T1.1.9.1" class="ltx_td ltx_align_left ltx_border_bb">ave.&nbsp;output length (in words)</td>
<td id="S3.T1.1.9.2" class="ltx_td ltx_align_center ltx_border_bb">18.9</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 1:</span></figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>
Statistics of the generated data by applying <span id="S3.T1.3.1" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> to GPT3.
</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Diversity</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p1.1">어떤 유형의 명령어가 생성되고 얼마나 다양한지 연구하기 위해 생성된 명령어의 동사-명사 구조를 식별한다. 버클리 신경망 파서 <span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://parser.kitaev.io/" target="_blank" title="">https://parser.kitaev.io/</a></span></span></span> <cite class="ltx_cite ltx_citemacro_citep">(Kitaev and Klein, <a class="ltx_ref" href="#bib.bib15" title="">2018</a>; Kitaev et al., <a class="ltx_ref" href="#bib.bib14" title="">2019</a>)</cite>를 사용하여 명령어를 파싱한 후, 첫 번째 직접 명사 객체뿐만 아니라 근에 가장 가까운 동사를 추출한다. 52,445개의 명령어들 중 26,559개는 그러한 구조를 포함하고; 다른 명령들은 일반적으로 더 복잡한 조항들(예를 들어, “이 트윗이 정치적 내용을 포함하는지 아닌지 분류하세요.”)을 포함하거나 질문들(예를 들어, “이러한 진술들 중 어느 것이 참인가?”)로 프레임화된다. 전체 집합의 14%를 차지하는 <a class="ltx_ref ltx_refmacro_autoref" href="#S2.F5" title="Figure 5 ‣ 2.3 Finetuning the LM to Follow Instructions ‣ 2 Method ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>에서 상위 20개의 가장 일반적인 루트 동사와 상위 4개의 직접 명사 객체를 플로팅한다. 전반적으로 이 지침에서 상당히 다양한 의도와 텍스트 형식을 볼 수 있습니다.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p2.1">생성된 지침이 생성을 촉구하는 데 사용되는 시드 지침과 어떻게 다른지 추가로 연구한다. 생성된 각 명령어에 대해 175개의 시드 명령어와 가장 높은 ROUGE-L 중첩을 계산한다. 이러한 ROUGE-L 점수의 분포를 <a class="ltx_ref ltx_refmacro_autoref" href="#S2.F5" title="Figure 5 ‣ 2.3 Finetuning the LM to Follow Instructions ‣ 2 Method ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>로 표시한다. 결과는 종자와 많이 겹치지 않는 적절한 수의 새로운 지침이 생성되었음을 나타낸다. 또한 <a class="ltx_ref ltx_refmacro_autoref" href="#S2.F5" title="Figure 5 ‣ 2.3 Finetuning the LM to Follow Instructions ‣ 2 Method ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Figure 5</span></a>에서 명령어, 인스턴스 입력 및 인스턴스 출력 길이의 다양성을 보여준다.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Quality</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.p1.1">지금까지 생성된 데이터의 양과 다양성을 보여주었지만 품질은 여전히 불확실하다. 이를 조사하기 위해 200개의 명령어를 무작위로 샘플링하고 명령어당 1개의 인스턴스를 무작위로 선택한다. 우리는 전문가 주석자(이 작업의 저자)에게 명령, 인스턴스 입력 및 인스턴스 출력 측면에서 각 인스턴스가 올바른지 여부를 레이블링하도록 요청했다. <a class="ltx_ref ltx_refmacro_autoref" href="#S3.T2" title="Table 2 ‣ 3.3 Quality ‣ 3 Self-Instruct Data from GPT3 ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Table 2</span></a>의 평가 결과는 생성된 명령어들의 대부분이 의미 있는 반면, 생성된 인스턴스들은 (합리적인 정도로) 더 많은 노이즈를 포함할 수 있음을 보여준다. 그러나 우리는 세대가 오류를 포함할 수 있지만 대부분은 여전히 올바른 형식 또는 부분적으로 올바르며 이는 훈련 모델이 지침을 따르는 데 유용한 지침을 제공할 수 있음을 발견했다. 우리는 각각 <a class="ltx_ref ltx_refmacro_autoref" href="#A3.T10" title='Table 10 ‣ Appendix C Task and Instance Examples from the Generated Instruction Data ‣ B.3 Example Predictions from GPT3_"Self-Inst" ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions'><span class="ltx_text ltx_ref_tag">Table 10</span></a>와 <a class="ltx_ref" href="#A3.T11" title='Table 11 ‣ Appendix C Task and Instance Examples from the Generated Instruction Data ‣ B.3 Example Predictions from GPT3_"Self-Inst" ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions'><span class="ltx_text ltx_ref_tag">11</span></a>에 다수의 좋은 예와 나쁜 예를 나열했다.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T2.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt">Quality Review Question</td>
<td id="S3.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Yes %</td>
</tr>
<tr id="S3.T2.1.2" class="ltx_tr">
<td id="S3.T2.1.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt">
<span id="S3.T2.1.2.1.1" class="ltx_text"></span> <span id="S3.T2.1.2.1.2" class="ltx_text">
<span id="S3.T2.1.2.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.1.2.1.2.1.1" class="ltx_tr">
<span id="S3.T2.1.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-2.5pt;padding-bottom:-2.5pt;">Does the instruction</span></span>
<span id="S3.T2.1.2.1.2.1.2" class="ltx_tr">
<span id="S3.T2.1.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-2.5pt;padding-bottom:-2.5pt;">describe a valid task?</span></span>
</span></span><span id="S3.T2.1.2.1.3" class="ltx_text"></span></td>
<td id="S3.T2.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">92%</td>
</tr>
<tr id="S3.T2.1.3" class="ltx_tr">
<td id="S3.T2.1.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.1.3.1.1" class="ltx_text"></span> <span id="S3.T2.1.3.1.2" class="ltx_text">
<span id="S3.T2.1.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.1.3.1.2.1.1" class="ltx_tr">
<span id="S3.T2.1.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-2.5pt;padding-bottom:-2.5pt;">Is the input appropriate</span></span>
<span id="S3.T2.1.3.1.2.1.2" class="ltx_tr">
<span id="S3.T2.1.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-2.5pt;padding-bottom:-2.5pt;">for the instruction?</span></span>
</span></span><span id="S3.T2.1.3.1.3" class="ltx_text"></span></td>
<td id="S3.T2.1.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">79%</td>
</tr>
<tr id="S3.T2.1.4" class="ltx_tr">
<td id="S3.T2.1.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<span id="S3.T2.1.4.1.1" class="ltx_text"></span> <span id="S3.T2.1.4.1.2" class="ltx_text">
<span id="S3.T2.1.4.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.1.4.1.2.1.1" class="ltx_tr">
<span id="S3.T2.1.4.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-2.5pt;padding-bottom:-2.5pt;">Is the output a correct and acceptable</span></span>
<span id="S3.T2.1.4.1.2.1.2" class="ltx_tr">
<span id="S3.T2.1.4.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center" style="padding-top:-2.5pt;padding-bottom:-2.5pt;">response to the instruction and input?</span></span>
</span></span><span id="S3.T2.1.4.1.3" class="ltx_text"></span></td>
<td id="S3.T2.1.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">58%</td>
</tr>
<tr id="S3.T2.1.5" class="ltx_tr">
<td id="S3.T2.1.5.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_l ltx_border_r ltx_border_tt">All fields are valid</td>
<td id="S3.T2.1.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_tt">54%</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 2:</span>생성된 데이터의 명령어, 입력 및 출력에 대한 데이터 품질 검토. 대표적인 유효 및 무효 예는 <a class="ltx_ref ltx_refmacro_autoref" href="#A3.T10" title='Table 10 ‣ Appendix C Task and Instance Examples from the Generated Instruction Data ‣ B.3 Example Predictions from GPT3_"Self-Inst" ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions'><span class="ltx_text ltx_ref_tag">Table 10</span></a> 및 <a class="ltx_ref ltx_refmacro_autoref" href="#A3.T11" title='Table 11 ‣ Appendix C Task and Instance Examples from the Generated Instruction Data ‣ B.3 Example Predictions from GPT3_"Self-Inst" ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions'><span class="ltx_text ltx_ref_tag">Table 11</span></a>를 참조한다.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Data quality review for the instruction, input, and output of the generated data. See <a href="#A3.T10" title="Table 10 ‣ Appendix C Task and Instance Examples from the Generated Instruction Data ‣ B.3 Example Predictions from GPT3_&quot;Self-Inst&quot; ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;10</span></a> and <a href="#A3.T11" title="Table 11 ‣ Appendix C Task and Instance Examples from the Generated Instruction Data ‣ B.3 Example Predictions from GPT3_&quot;Self-Inst&quot; ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table&nbsp;11</span></a> for representative valid and invalid examples.
</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental Results</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p" id="S4.p1.1">다양한 명령어 튜닝 설정 하에서 모델의 성능을 측정하고 비교하는 실험을 수행한다. 먼저 모델 및 기타 기준선에 대해 설명한 다음 실험을 수행합니다.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span><span id="S4.SS1.1.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.SS1.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.SS1.1.1.m1.1b"><msub id="S4.SS1.1.1.m1.1.1" xref="S4.SS1.1.1.m1.1.1.cmml"><mi id="S4.SS1.1.1.m1.1.1b" xref="S4.SS1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS1.1.1.m1.1.1.1" xref="S4.SS1.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.1.1.m1.1c"><apply id="S4.SS1.1.1.m1.1.1.cmml" xref="S4.SS1.1.1.m1.1.1"><ci id="S4.SS1.1.1.m1.1.1.1a.cmml" xref="S4.SS1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.SS1.1.1.m1.1.1.1.cmml" xref="S4.SS1.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.1.1.m1.1d">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>: finetuning <span id="S4.SS1.2.2" class="ltx_text ltx_font_smallcaps">GPT3</span> on its own instruction data</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p1.1">명령 생성 명령 데이터가 주어지면 <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p1.1.2">GPT3</span> 모델 자체("davinci" 엔진)를 사용하여 명령 튜닝을 수행합니다. §<a class="ltx_ref" href="#S2.SS3" title="2.3 Finetuning the LM to Follow Instructions ‣ 2 Method ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">2.3</span></a>에서 설명한 바와 같이 다양한 템플릿을 사용하여 명령어와 입력을 연결하고 모델을 훈련하여 출력을 생성한다. 이 미세 조정은 OpenAI 미세 조정 API를 통해 수행됩니다. <span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>See <a class="ltx_ref ltx_href" href="https://beta.openai.com/docs/guides/fine-tuning" target="_blank" title="">OpenAI’s documentation on finetuning</a>. </span></span></span> 프롬프트 손실 가중치를 0으로 설정하고 2개의 epoch에 대해 모델을 훈련하는 것을 제외하고는 기본 하이퍼 매개 변수를 사용합니다. 추가적인 미세 조정 세부 사항은 판독기를 부록 <a class="ltx_ref" href="#A1.SS3" title="A.3 Finetuning GPT3 ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">A.3</span></a>에 참조한다. 결과 모델은 <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p1.1.1">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="S4.SS1.p1.1.1.m1.1"><semantics id="S4.SS1.p1.1.1.m1.1a"><msub id="S4.SS1.p1.1.1.m1.1.1" xref="S4.SS1.p1.1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.1.m1.1.1a" xref="S4.SS1.p1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS1.p1.1.1.m1.1.1.1" xref="S4.SS1.p1.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.1.m1.1b"><apply id="S4.SS1.p1.1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.1.m1.1.1"><ci id="S4.SS1.p1.1.1.m1.1.1.1a.cmml" xref="S4.SS1.p1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S4.SS1.p1.1.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.SS1.p1.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>로 표시된다.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Baselines</h3>

<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Off-the-shelf LMs.</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.1">T5-LM <cite class="ltx_cite ltx_citemacro_cite">Lester et al. (<a class="ltx_ref" href="#bib.bib16" title="">2021</a>); Raffel et al. (<a class="ltx_ref" href="#bib.bib24" title="">2020</a>)</cite>와 <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px1.p1.1.1">GPT3</span> <cite class="ltx_cite ltx_citemacro_cite">Brown et al. (<a class="ltx_ref" href="#bib.bib3" title="">2020</a>)</cite>를 바닐라 LM 베이스라인으로 평가한다(사전 훈련만, 추가 핀튜닝 없음). 이러한 기준선은 사전 훈련 직후 기성 LM이 자연스럽게 지침을 따를 수 있는 정도를 나타낸다.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Publicly available instruction-tuned models.</h4>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS0.Px2.p1.2"><span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px2.p1.1.1">T<math alttext="0" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px2.p1.1.1.m1.1"><semantics id="S4.SS2.SSS0.Px2.p1.1.1.m1.1a"><mn id="S4.SS2.SSS0.Px2.p1.1.1.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.1.1.m1.1b"><cn id="S4.SS2.SSS0.Px2.p1.1.1.m1.1.1.cmml" type="integer" xref="S4.SS2.SSS0.Px2.p1.1.1.m1.1.1">0</cn></annotation-xml></semantics></math></span> 및 <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px2.p1.2.2">T<math alttext="k" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px2.p1.2.2.m1.1"><semantics id="S4.SS2.SSS0.Px2.p1.2.2.m1.1a"><mi id="S4.SS2.SSS0.Px2.p1.2.2.m1.1.1" xref="S4.SS2.SSS0.Px2.p1.2.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px2.p1.2.2.m1.1b"><ci id="S4.SS2.SSS0.Px2.p1.2.2.m1.1.1.cmml" xref="S4.SS2.SSS0.Px2.p1.2.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px2.p1.2.2.m1.1c">k</annotation></semantics></math>-Instruct</span>은 각각 <cite class="ltx_cite ltx_citemacro_citet">Sanh et al. (<a class="ltx_ref" href="#bib.bib27" title="">2022</a>)</cite> 및 <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="#bib.bib33" title="">2022</a>)</cite>에서 제안된 두 가지 명령 조정 모델이며, 많은 NLP 작업에 대한 명령을 따를 수 있음을 입증한다. 이 두 모델은 모두 T5<cite class="ltx_cite ltx_citemacro_cite">Raffel et al. (<a class="ltx_ref" href="#bib.bib24" title="">2020</a>)</cite> 체크포인트에서 미세 조정되며 공개적으로 사용할 수 있다. <span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content">9</sup><span class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><span class="ltx_text ltx_font_smallcaps" id="footnote9.1">T<math alttext="0" class="ltx_Math" display="inline" id="footnote9.1.m1.1"><semantics id="footnote9.1.m1.1b"><mn id="footnote9.1.m1.1.1" xref="footnote9.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="footnote9.1.m1.1c"><cn id="footnote9.1.m1.1.1.cmml" type="integer" xref="footnote9.1.m1.1.1">0</cn></annotation-xml></semantics></math></span>은 <a class="ltx_ref ltx_href" href="https://huggingface.co/bigscience/T0" target="_blank" title="">here</a>에서 사용 가능하며 <span class="ltx_text ltx_font_smallcaps" id="footnote9.2">T<math alttext="k" class="ltx_Math" display="inline" id="footnote9.2.m1.1"><semantics id="footnote9.2.m1.1b"><mi id="footnote9.2.m1.1.1" xref="footnote9.2.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="footnote9.2.m1.1c"><ci id="footnote9.2.m1.1.1.cmml" xref="footnote9.2.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote9.2.m1.1d">k</annotation></semantics></math>-Instruct</span>은 <a class="ltx_ref ltx_href" href="https://huggingface.co/allenai/tk-instruct-11b-def" target="_blank" title="">here</a>에서 사용 가능하다. </span></span></span> 이 두 모델 모두에 대해 11B 매개 변수가 있는 가장 큰 버전을 사용합니다.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Instruction-tuned GPT3 models.</h4>

<div id="S4.SS2.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS0.Px3.p1.1">우리는 GPT3를 기반으로 OpenAI가 개발한 <math alttext="\text{InstructGPT}_{\text{}}" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px3.p1.1.m1.1"><semantics id="S4.SS2.SSS0.Px3.p1.1.m1.1a"><msub id="S4.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.cmml"><mtext id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2a.cmml">InstructGPT</mtext><mrow id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3a.cmml"></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p1.1.m1.1b"><apply id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2a.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2"><mtext id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3a.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3"><mrow id="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S4.SS2.SSS0.Px3.p1.1.m1.1.1.3"></mrow></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px3.p1.1.m1.1c">\text{InstructGPT}_{\text{}}</annotation></semantics></math><cite class="ltx_cite ltx_citemacro_cite">Ouyang et al. (<a class="ltx_ref" href="#bib.bib23" title="">2022</a>)</cite>를 평가하며, 커뮤니티에서 인상적인 제로샷 능력을 가진 것으로 나타났다. 이러한 모델에는 다양한 세대가 있으며, 더 새로운 모델은 더 광범위한 데이터 또는 알고리즘적인 신규성을 사용한다. <span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span> See <a class="ltx_ref ltx_href" href="https://beta.openai.com/docs/model-index-for-researchers" target="_blank" title="">OpenAI’s documentation on their models.</a> </span></span></span> 우리의 <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p1.1.1">SuperNI</span> 실험 in §<a class="ltx_ref" href="#S4.SS3" title="4.3 Experiment 1: Zero-Shot Generalization on SuperNI benchmark ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">4.3</span></a>는 그들의 <span class="ltx_text ltx_font_typewriter" id="S4.SS2.SSS0.Px3.p1.1.2">text-davinci-001</span> 엔진과 비교할 뿐이다. 왜냐하면 그들의 새로운 엔진은 최신 사용자 데이터로 훈련되고 이미 <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p1.1.3">SuperNI</span> 테스트 세트를 보았을 가능성이 높기 때문이다. 새로 작성된 지침에 대한 인간 평가를 위해 우리는 완전성을 위해 001, 002 및 003 엔진을 포함한다.</p>
</div>
<div id="S4.SS2.SSS0.Px3.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS0.Px3.p2.3">또한, <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p2.3.4">Self-Instruct</span> training with other publicly available instruction tuning data, we further finetune GPT3 model with data from <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p2.3.5">PromptSource</span> and <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p2.3.6">SuperNI</span> and <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p2.1.1">T<math alttext="0" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px3.p2.1.1.m1.1"><semantics id="S4.SS2.SSS0.Px3.p2.1.1.m1.1a"><mn id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p2.1.1.m1.1b"><cn id="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1.cmml" type="integer" xref="S4.SS2.SSS0.Px3.p2.1.1.m1.1.1">0</cn></annotation-xml></semantics></math></span> and <span class="ltx_text ltx_font_smallcaps" id=" 이를 <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p2.3.3">T<math alttext="0" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px3.p2.3.3.m1.1"><semantics id="S4.SS2.SSS0.Px3.p2.3.3.m1.1a"><mn id="S4.SS2.SSS0.Px3.p2.3.3.m1.1.1" xref="S4.SS2.SSS0.Px3.p2.3.3.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px3.p2.3.3.m1.1b"><cn id="S4.SS2.SSS0.Px3.p2.3.3.m1.1.1.cmml" type="integer" xref="S4.SS2.SSS0.Px3.p2.3.3.m1.1.1">0</cn></annotation-xml></semantics></math></span> training 및 <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px3.p2.3.7">SuperNI</span> training for short라고 한다. 훈련 예산을 절약하기 위해 각 데이터 세트에 대해 50K 인스턴스(그러나 모든 명령을 포함함)를 샘플링했으며, 이는 우리가 생성한 명령 데이터와 유사한 크기를 갖는다. <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="#bib.bib33" title="">2022</a>)</cite>의 결과와 초기 실험에 따르면 훈련 작업당 인스턴스 수를 줄이는 것이 모델의 일반화 성능을 보이지 않는 작업으로 저하시키지 않는다.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Experiment 1: Zero-Shot Generalization on <span id="S4.SS3.1.1" class="ltx_text ltx_font_smallcaps">SuperNI</span> benchmark</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS3.p1.1">우리는 먼저 제로샷 방식으로 일반적인 NLP 작업에 대한 지침을 따르는 모델의 능력을 평가한다. 각 태스크에 100개의 인스턴스가 있는 119개의 태스크로 구성된 <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.p1.1.1">SuperNI</span>  <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="#bib.bib33" title="">2022</a>)</cite>의 평가 집합을 사용한다. 이 작업에서는 주로 제로 샷 설정에 중점을 둡니다. 즉, 모델은 컨텍스트 데모 예 없이 태스크의 정의만으로 프롬프트됩니다. <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.p1.1.2">GPT3</span> 변이체에 대한 모든 요청에 대해 특정 중지 시퀀스 없이 결정론적 생성 모드(온도가 0이고 핵 샘플링 없음)를 사용한다.</p>
</div>
<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.5"><a class="ltx_ref ltx_refmacro_autoref" href="#S4.T3" title="Table 3 ‣ Results. ‣ 4.3 Experiment 1: Zero-Shot Generalization on SuperNI benchmark ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Table 3</span></a>의 결과로부터 다음과 같은 관찰을 한다. <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.5.5">Self-Instruct</span> boosts the instruction-following ability of <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.5.6">GPT3</span> by large margin. 바닐라 <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.5.7">GPT3</span> 모델은 기본적으로 인간의 지시를 전혀 따를 수 없다. 수동 분석 결과, 일반적으로 관련 없는 반복적인 텍스트를 생성하며 언제 생성을 중단해야 하는지 알 수 없다. <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.5.8">SuperNI</span>, <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.1.1">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p1.1.1.m1.1"><semantics id="S4.SS3.SSS0.Px1.p1.1.1.m1.1a"><msub id="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1a" xref="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.1.1.m1.1b"><apply id="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1"><ci id="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.1a.cmml" xref="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.SS3.SSS0.Px1.p1.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>은 <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.2.2">T<math alttext="0" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p1.2.2.m1.1"><semantics id="S4.SS3.SSS0.Px1.p1.2.2.m1.1a"><mn id="S4.SS3.SSS0.Px1.p1.2.2.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.2.2.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.2.2.m1.1b"><cn id="S4.SS3.SSS0.Px1.p1.2.2.m1.1.1.cmml" type="integer" xref="S4.SS3.SSS0.Px1.p1.2.2.m1.1.1">0</cn></annotation-xml></semantics></math></span>보다 더 나은 성능을 달성합니다. 특히, <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.4.4">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p1.4.4.m1.1"><semantics id="S4.SS3.SSS0.Px1.p1.4.4.m1.1a"><msub id="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.cmml"><mi id="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1a" xref="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.1" xref="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.4.4.m1.1b"><apply id="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1"><ci id="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.1a.cmml" xref="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.1.cmml" mathsize="70%" xref="S4.SS3.SSS0.Px1.p1.4.4.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.4.4.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> 또한 사설 사용자 데이터 및 인간 주석 라벨로 훈련된 <math alttext="\text{InstructGPT}_{\text{001}}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p1.5.m1.1"><semantics id="S4.SS3.SSS0.Px1.p1.5.m1.1a"><msub id="S4.SS3.SSS0.Px1.p1.5.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1.cmml"><mtext id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.2" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.3" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.5.m1.1b"><apply id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1">subscript</csymbol><ci id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.2a.cmml" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1.2"><mtext id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.2.cmml" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.3a.cmml" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1.3"><mtext id="S4.SS3.SSS0.Px1.p1.5.m1.1.1.3.cmml" mathsize="70%" xref="S4.SS3.SSS0.Px1.p1.5.m1.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.5.m1.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>의 성능과 거의 일치한다.</p>
</div>
<div id="S4.SS3.SSS0.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p2.1"><span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p2.1.1">SuperNI</span> 훈련 세트는 여전히 평가 세트에서 더 나은 성능을 달성하며, 이는 유사한 명령 스타일 및 포맷팅에 기인한다. 그러나 <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p2.1.2">Self-Instruct</span>은 <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p2.1.3">SuperNI</span> 트레이닝 세트와 결합하여 보완 데이터로서의 가치를 입증할 때 여전히 추가 이득을 가져옵니다.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2212.10560/assets/x8.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="315" height="136" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 6:</span></figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>
Performance of GPT3 model and its instruction-tuned variants, evaluated by human experts on our 252 user-oriented instructions (§<a href="#S4.SS4" title="4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>). Human evaluators are instructed to rate the models’ responses into four levels.
The results indicate that <span id="S4.F6.4.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.F6.4.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.F6.4.1.m1.1b"><msub id="S4.F6.4.1.m1.1.1" xref="S4.F6.4.1.m1.1.1.cmml"><mi id="S4.F6.4.1.m1.1.1b" xref="S4.F6.4.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.F6.4.1.m1.1.1.1" xref="S4.F6.4.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F6.4.1.m1.1c"><apply id="S4.F6.4.1.m1.1.1.cmml" xref="S4.F6.4.1.m1.1.1"><ci id="S4.F6.4.1.m1.1.1.1a.cmml" xref="S4.F6.4.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.F6.4.1.m1.1.1.1.cmml" xref="S4.F6.4.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.4.1.m1.1d">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> outperforms
all the other <span id="S4.F6.8.3" class="ltx_text ltx_font_smallcaps">GPT3</span> variants trained on publicly available instruction datasets.
Additionally, <span id="S4.F6.5.2" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.F6.5.2.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.F6.5.2.m1.1b"><msub id="S4.F6.5.2.m1.1.1" xref="S4.F6.5.2.m1.1.1.cmml"><mi id="S4.F6.5.2.m1.1.1b" xref="S4.F6.5.2.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.F6.5.2.m1.1.1.1" xref="S4.F6.5.2.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F6.5.2.m1.1c"><apply id="S4.F6.5.2.m1.1.1.cmml" xref="S4.F6.5.2.m1.1.1"><ci id="S4.F6.5.2.m1.1.1.1a.cmml" xref="S4.F6.5.2.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.F6.5.2.m1.1.1.1.cmml" xref="S4.F6.5.2.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.5.2.m1.1d">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> scores nearly as good as <math id="S4.F6.6.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{001}}" display="inline"><semantics id="S4.F6.6.m1.1b"><msub id="S4.F6.6.m1.1.1" xref="S4.F6.6.m1.1.1.cmml"><mtext id="S4.F6.6.m1.1.1.2" xref="S4.F6.6.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.F6.6.m1.1.1.3" xref="S4.F6.6.m1.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F6.6.m1.1c"><apply id="S4.F6.6.m1.1.1.cmml" xref="S4.F6.6.m1.1.1"><csymbol cd="ambiguous" id="S4.F6.6.m1.1.1.1.cmml" xref="S4.F6.6.m1.1.1">subscript</csymbol><ci id="S4.F6.6.m1.1.1.2a.cmml" xref="S4.F6.6.m1.1.1.2"><mtext id="S4.F6.6.m1.1.1.2.cmml" xref="S4.F6.6.m1.1.1.2">InstructGPT</mtext></ci><ci id="S4.F6.6.m1.1.1.3a.cmml" xref="S4.F6.6.m1.1.1.3"><mtext mathsize="70%" id="S4.F6.6.m1.1.1.3.cmml" xref="S4.F6.6.m1.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F6.6.m1.1d">\text{InstructGPT}_{\text{001}}</annotation></semantics></math> (cf.&nbsp;<a href="#footnote1" title="footnote 1 ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">footnote&nbsp;1</span></a>).
</figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.T3.12" class="ltx_inline-block ltx_figure_panel ltx_transformed_outer" style="width:411.9pt;height:339.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(64.0pt,-52.8pt) scale(1.45089119638244,1.45089119638244) ;">
<table id="S4.T3.12.12" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S4.T3.12.12.13" class="ltx_tr">
<td id="S4.T3.12.12.13.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_tt" style="padding:0.5pt 1.5pt;"><span id="S4.T3.12.12.13.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S4.T3.12.12.13.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding:0.5pt 1.5pt;"><span id="S4.T3.12.12.13.2.1" class="ltx_text ltx_font_bold"># Params</span></td>
<td id="S4.T3.12.12.13.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding:0.5pt 1.5pt;"><span id="S4.T3.12.12.13.3.1" class="ltx_text ltx_font_bold">ROUGE-L</span></td>
</tr>
<tr id="S4.T3.12.12.14" class="ltx_tr">
<td id="S4.T3.12.12.14.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding:0.5pt 1.5pt;"><span id="S4.T3.12.12.14.1.1" class="ltx_text ltx_font_bold">Vanilla LMs</span></td>
<td id="S4.T3.12.12.14.2" class="ltx_td ltx_border_t" style="padding:0.5pt 1.5pt;"></td>
<td id="S4.T3.12.12.14.3" class="ltx_td ltx_border_t" style="padding:0.5pt 1.5pt;"></td>
</tr>
<tr id="S4.T3.12.12.15" class="ltx_tr">
<td id="S4.T3.12.12.15.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;">T5-LM</td>
<td id="S4.T3.12.12.15.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">11B</td>
<td id="S4.T3.12.12.15.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">25.7</td>
</tr>
<tr id="S4.T3.1.1.1" class="ltx_tr">
<td id="S4.T3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;">
<svg id="S4.T3.1.1.1.1.pic1" class="ltx_picture" height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)"></g></svg> <span id="S4.T3.1.1.1.1.1" class="ltx_text" style="color:#000000;"> <span id="S4.T3.1.1.1.1.1.1" class="ltx_text ltx_font_smallcaps">GPT3</span></span>
</td>
<td id="S4.T3.1.1.1.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">175B</td>
<td id="S4.T3.1.1.1.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">6.8</td>
</tr>
<tr id="S4.T3.12.12.16" class="ltx_tr">
<td id="S4.T3.12.12.16.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding:0.5pt 1.5pt;"><span id="S4.T3.12.12.16.1.1" class="ltx_text ltx_font_bold">Instruction-tuned w/o <span id="S4.T3.12.12.16.1.1.1" class="ltx_text ltx_font_smallcaps" style="color:#000000;">SuperNI</span></span></td>
<td id="S4.T3.12.12.16.2" class="ltx_td ltx_border_t" style="padding:0.5pt 1.5pt;"></td>
<td id="S4.T3.12.12.16.3" class="ltx_td ltx_border_t" style="padding:0.5pt 1.5pt;"></td>
</tr>
<tr id="S4.T3.2.2.2" class="ltx_tr">
<td id="S4.T3.2.2.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;"><span id="S4.T3.2.2.2.1.1" class="ltx_text ltx_font_smallcaps">T<math id="S4.T3.2.2.2.1.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.T3.2.2.2.1.1.m1.1a"><mn id="S4.T3.2.2.2.1.1.m1.1.1" xref="S4.T3.2.2.2.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.1.1.m1.1b"><cn type="integer" id="S4.T3.2.2.2.1.1.m1.1.1.cmml" xref="S4.T3.2.2.2.1.1.m1.1.1">0</cn></annotation-xml></semantics></math></span></td>
<td id="S4.T3.2.2.2.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">11B</td>
<td id="S4.T3.2.2.2.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">33.1</td>
</tr>
<tr id="S4.T3.3.3.3" class="ltx_tr">
<td id="S4.T3.3.3.3.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;">
<span id="S4.T3.3.3.3.1.2" class="ltx_text" style="color:#000000;"><span id="S4.T3.3.3.3.1.2.1" class="ltx_text ltx_font_smallcaps">GPT3</span></span> + <span id="S4.T3.3.3.3.1.1" class="ltx_text ltx_font_smallcaps">T<math id="S4.T3.3.3.3.1.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.T3.3.3.3.1.1.m1.1a"><mn id="S4.T3.3.3.3.1.1.m1.1.1" xref="S4.T3.3.3.3.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.1.1.m1.1b"><cn type="integer" id="S4.T3.3.3.3.1.1.m1.1.1.cmml" xref="S4.T3.3.3.3.1.1.m1.1.1">0</cn></annotation-xml></semantics></math></span> Training</td>
<td id="S4.T3.3.3.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">175B</td>
<td id="S4.T3.3.3.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">37.9</td>
</tr>
<tr id="S4.T3.6.6.6" class="ltx_tr">
<td id="S4.T3.6.6.6.3" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;">
<svg id="S4.T3.4.4.4.1.pic1" class="ltx_picture" height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)"></g></svg> <svg id="S4.T3.5.5.5.2.pic2" class="ltx_picture" height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)"></g></svg><span id="S4.T3.6.6.6.3.1" class="ltx_text" style="color:#000000;"> <span id="S4.T3.6.6.6.3.1.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.T3.6.6.6.3.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.T3.6.6.6.3.1.1.m1.1a"><msub id="S4.T3.6.6.6.3.1.1.m1.1.1" xref="S4.T3.6.6.6.3.1.1.m1.1.1.cmml"><mi id="S4.T3.6.6.6.3.1.1.m1.1.1a" xref="S4.T3.6.6.6.3.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" mathcolor="#000000" id="S4.T3.6.6.6.3.1.1.m1.1.1.1" xref="S4.T3.6.6.6.3.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.3.1.1.m1.1b"><apply id="S4.T3.6.6.6.3.1.1.m1.1.1.cmml" xref="S4.T3.6.6.6.3.1.1.m1.1.1"><ci id="S4.T3.6.6.6.3.1.1.m1.1.1.1a.cmml" xref="S4.T3.6.6.6.3.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathcolor="#000000" mathsize="70%" id="S4.T3.6.6.6.3.1.1.m1.1.1.1.cmml" xref="S4.T3.6.6.6.3.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.3.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> </span>
(Ours)</td>
<td id="S4.T3.6.6.6.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">175B</td>
<td id="S4.T3.6.6.6.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">39.9</td>
</tr>
<tr id="S4.T3.8.8.8" class="ltx_tr">
<td id="S4.T3.8.8.8.2" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;">
<svg id="S4.T3.7.7.7.1.pic1" class="ltx_picture" height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)"></g></svg><math id="S4.T3.8.8.8.2.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{001}}" display="inline"><semantics id="S4.T3.8.8.8.2.m1.1a"><msub id="S4.T3.8.8.8.2.m1.1.1" xref="S4.T3.8.8.8.2.m1.1.1.cmml"><mtext mathcolor="#000000" id="S4.T3.8.8.8.2.m1.1.1.2" xref="S4.T3.8.8.8.2.m1.1.1.2a.cmml">InstructGPT</mtext><mtext mathcolor="#000000" id="S4.T3.8.8.8.2.m1.1.1.3" xref="S4.T3.8.8.8.2.m1.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T3.8.8.8.2.m1.1b"><apply id="S4.T3.8.8.8.2.m1.1.1.cmml" xref="S4.T3.8.8.8.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.8.8.8.2.m1.1.1.1.cmml" xref="S4.T3.8.8.8.2.m1.1.1">subscript</csymbol><ci id="S4.T3.8.8.8.2.m1.1.1.2a.cmml" xref="S4.T3.8.8.8.2.m1.1.1.2"><mtext id="S4.T3.8.8.8.2.m1.1.1.2.cmml" xref="S4.T3.8.8.8.2.m1.1.1.2">InstructGPT</mtext></ci><ci id="S4.T3.8.8.8.2.m1.1.1.3a.cmml" xref="S4.T3.8.8.8.2.m1.1.1.3"><mtext mathsize="70%" id="S4.T3.8.8.8.2.m1.1.1.3.cmml" xref="S4.T3.8.8.8.2.m1.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.8.8.2.m1.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>
</td>
<td id="S4.T3.8.8.8.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">175B</td>
<td id="S4.T3.8.8.8.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;"><span id="S4.T3.8.8.8.4.1" class="ltx_text ltx_font_bold">40.8</span></td>
</tr>
<tr id="S4.T3.12.12.17" class="ltx_tr">
<td id="S4.T3.12.12.17.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_border_t" style="padding:0.5pt 1.5pt;"><span id="S4.T3.12.12.17.1.1" class="ltx_text ltx_font_bold">Instruction-tuned w/ <span id="S4.T3.12.12.17.1.1.1" class="ltx_text ltx_font_smallcaps" style="color:#000000;">SuperNI</span></span></td>
<td id="S4.T3.12.12.17.2" class="ltx_td ltx_border_t" style="padding:0.5pt 1.5pt;"></td>
<td id="S4.T3.12.12.17.3" class="ltx_td ltx_border_t" style="padding:0.5pt 1.5pt;"></td>
</tr>
<tr id="S4.T3.9.9.9" class="ltx_tr">
<td id="S4.T3.9.9.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;"><span id="S4.T3.9.9.9.1.1" class="ltx_text ltx_font_smallcaps">T<math id="S4.T3.9.9.9.1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.T3.9.9.9.1.1.m1.1a"><mi id="S4.T3.9.9.9.1.1.m1.1.1" xref="S4.T3.9.9.9.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.T3.9.9.9.1.1.m1.1b"><ci id="S4.T3.9.9.9.1.1.m1.1.1.cmml" xref="S4.T3.9.9.9.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.9.9.1.1.m1.1c">k</annotation></semantics></math>-Instruct</span></td>
<td id="S4.T3.9.9.9.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">11B</td>
<td id="S4.T3.9.9.9.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">46.0</td>
</tr>
<tr id="S4.T3.10.10.10" class="ltx_tr">
<td id="S4.T3.10.10.10.1" class="ltx_td ltx_nopad_r ltx_align_left" style="padding:0.5pt 1.5pt;">
<svg id="S4.T3.10.10.10.1.pic1" class="ltx_picture" height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)"></g></svg><span id="S4.T3.10.10.10.1.1" class="ltx_text" style="color:#000000;"> <span id="S4.T3.10.10.10.1.1.1" class="ltx_text ltx_font_smallcaps">GPT3</span></span> + <span id="S4.T3.10.10.10.1.2" class="ltx_text ltx_font_smallcaps" style="color:#000000;">SuperNI</span> Training</td>
<td id="S4.T3.10.10.10.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">175B</td>
<td id="S4.T3.10.10.10.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" style="padding:0.5pt 1.5pt;">49.5</td>
</tr>
<tr id="S4.T3.12.12.12" class="ltx_tr">
<td id="S4.T3.12.12.12.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" style="padding:0.5pt 1.5pt;">
<svg id="S4.T3.11.11.11.1.pic1" class="ltx_picture" height="1" overflow="visible" version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)"></g></svg><span id="S4.T3.12.12.12.2.1" class="ltx_text" style="color:#000000;"> <span id="S4.T3.12.12.12.2.1.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.T3.12.12.12.2.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.T3.12.12.12.2.1.1.m1.1a"><msub id="S4.T3.12.12.12.2.1.1.m1.1.1" xref="S4.T3.12.12.12.2.1.1.m1.1.1.cmml"><mi id="S4.T3.12.12.12.2.1.1.m1.1.1a" xref="S4.T3.12.12.12.2.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" mathcolor="#000000" id="S4.T3.12.12.12.2.1.1.m1.1.1.1" xref="S4.T3.12.12.12.2.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T3.12.12.12.2.1.1.m1.1b"><apply id="S4.T3.12.12.12.2.1.1.m1.1.1.cmml" xref="S4.T3.12.12.12.2.1.1.m1.1.1"><ci id="S4.T3.12.12.12.2.1.1.m1.1.1.1a.cmml" xref="S4.T3.12.12.12.2.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathcolor="#000000" mathsize="70%" id="S4.T3.12.12.12.2.1.1.m1.1.1.1.cmml" xref="S4.T3.12.12.12.2.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.12.12.2.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span></span>
+ <span id="S4.T3.12.12.12.2.2" class="ltx_text ltx_font_smallcaps" style="color:#000000;">SuperNI</span> Training (Ours)</td>
<td id="S4.T3.12.12.12.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:0.5pt 1.5pt;">175B</td>
<td id="S4.T3.12.12.12.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" style="padding:0.5pt 1.5pt;"><span id="S4.T3.12.12.12.4.1" class="ltx_text ltx_font_bold">51.6</span></td>
</tr>
</tbody></table>
</span></div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><svg id="S4.T3.pic1" class="ltx_picture ltx_figure_panel" height="123.15" overflow="visible" version="1.1" width="353.74"><g transform="translate(0,123.15) matrix(1 0 0 -1 0 0) translate(353.32,0) translate(0,94.94)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><path d="M -2.66 6.6 C -0.89 3.53 -0.89 0.05 -2.66 -3.02" style="fill:none"></path><g transform="matrix(-0.5 0.86603 -0.86603 -0.5 -2.66 6.6)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><g transform="matrix(-0.5 -0.86603 0.86603 -0.5 -2.66 -3.02)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -348.71 13.22)" fill="#000000" stroke="#000000"><foreignObject width="48.05" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T3.pic1.1.1.1.1.1" class="ltx_text">\tiny1⃝</span></foreignObject></g><path d="M -2.34 5.66 C -2.34 5.66 -2.98 5.66 -2.34 5.66" style="fill:none"></path><g transform="matrix(-1.0 0.0 0.0 -1.0 -2.34 5.66)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.62 5.66)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -348.71 -26.69)" fill="#000000" stroke="#000000"><foreignObject width="48.05" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T3.pic1.2.2.2.1.1" class="ltx_text">\tiny2⃝</span></foreignObject></g><path d="M -3.62 17.87 C -3.44 17.87 -3.44 19.06 -3.62 19.06" style="fill:none"></path><g transform="matrix(1.0 0.0 0.0 1.0 -3.62 17.87)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -3.62 19.06)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linecap="round" stroke-linejoin="round" stroke-width="0.32pt"><path d="M -1.66 2.21 C -1.52 1.38 0 0.14 0.42 0 C 0 -0.14 -1.52 -1.38 -1.66 -2.21" style="fill:none"></path></g><g transform="matrix(1.0 0.0 0.0 1.0 -348.71 -86.87)" fill="#000000" stroke="#000000"><foreignObject width="48.05" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><span id="S4.T3.pic1.3.3.3.1.1" class="ltx_text">\tiny3⃝</span></foreignObject></g></g></svg></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 3:</span> <em class="ltx_emph ltx_font_italic" id="S4.T3.19.1">unseen</em> tasks from <span class="ltx_text ltx_font_smallcaps" id="S4.T3.20.2" style="color:#000000;">SuperNI</span> (§<a class="ltx_ref" href="#S4.SS3" title="4.3 Experiment 1: Zero-Shot Generalization on SuperNI benchmark ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">4.3</span></a>).</figcaption><figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Evaluation results on <em id="S4.T3.19.1" class="ltx_emph ltx_font_italic">unseen</em> tasks from <span id="S4.T3.20.2" class="ltx_text ltx_font_smallcaps" style="color:#000000;">SuperNI</span> (§<a href="#S4.SS3" title="4.3 Experiment 1: Zero-Shot Generalization on SuperNI benchmark ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>).
From the results, we see that \tiny1⃝ <span id="S4.T3.21.3" class="ltx_text ltx_font_smallcaps">Self-Instruct</span> can boost <span id="S4.T3.22.4" class="ltx_text ltx_font_smallcaps">GPT3</span> performance by a large margin (+33.1%) and \tiny2⃝ nearly matches the performance of <math id="S4.T3.14.m1.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{001}}" display="inline"><semantics id="S4.T3.14.m1.1b"><msub id="S4.T3.14.m1.1.1" xref="S4.T3.14.m1.1.1.cmml"><mtext id="S4.T3.14.m1.1.1.2" xref="S4.T3.14.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.T3.14.m1.1.1.3" xref="S4.T3.14.m1.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T3.14.m1.1c"><apply id="S4.T3.14.m1.1.1.cmml" xref="S4.T3.14.m1.1.1"><csymbol cd="ambiguous" id="S4.T3.14.m1.1.1.1.cmml" xref="S4.T3.14.m1.1.1">subscript</csymbol><ci id="S4.T3.14.m1.1.1.2a.cmml" xref="S4.T3.14.m1.1.1.2"><mtext id="S4.T3.14.m1.1.1.2.cmml" xref="S4.T3.14.m1.1.1.2">InstructGPT</mtext></ci><ci id="S4.T3.14.m1.1.1.3a.cmml" xref="S4.T3.14.m1.1.1.3"><mtext mathsize="70%" id="S4.T3.14.m1.1.1.3.cmml" xref="S4.T3.14.m1.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.14.m1.1d">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>.
Additionally, \tiny3⃝ it can further improve the performance even when a large amount of labeled instruction data is present.
</figcaption>
</figure>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Experiment 2: Generalization to User-oriented Instructions on Novel Tasks</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS4.p1.1">기존 NLP 작업 수집에서 <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.p1.1.1">SuperNI</span>의 포괄성에도 불구하고, 이러한 NLP 작업의 대부분은 연구 목적으로 제안되었으며 분류에 편향되었다. 명령어 후속 모델의 실용적인 가치에 더 잘 접근하기 위해 저자의 하위 집합은 사용자 지향 애플리케이션에 의해 동기화된 새로운 명령어 세트를 선별한다. 먼저 대규모 LMs가 유용할 수 있는 다양한 도메인(예: 이메일 작성, 소셜 미디어, 생산성 도구, 엔터테인먼트, 프로그래밍)을 브레인스토밍한 다음 입력 출력 인스턴스(다시, 입력은 선택 사항)와 함께 각 도메인과 관련된 지침을 작성한다. 우리는 이러한 태스크의 스타일과 형식을 다양화하는 것을 목표로 한다(예를 들어, 명령어는 길거나 짧을 수 있고, 입력/출력은 글머리점, 표, 코드, 방정식 등의 형태를 취할 수 있다). 총 252개의 명령어를 생성하고, 명령어당 1개의 인스턴스를 생성한다. 우리는 이것이 명령 기반 모델이 다양하고 익숙하지 않은 명령을 처리하는 방법을 평가하는 테스트 베드 역할을 할 수 있다고 믿는다. <a class="ltx_ref ltx_refmacro_autoref" href="#A2.SS3" title='B.3 Example Predictions from GPT3_"Self-Inst" ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions'><span class="ltx_text ltx_ref_tag">subsection B.3</span></a>는 그들 중 작은 부분을 제시한다. 전체 세트는 GitHub 리포지토리에서 사용할 수 있습니다. 우리는 §<a class="ltx_ref" href="#A1.SS1" title="A.1 Writing the Seed Tasks ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">A.1</span></a>에서 이 집합 집합과 시드 명령어 간의 중첩을 분석한다.</p>
</div>
<section id="S4.SS4.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Human evaluation setup.</h4>

<div id="S4.SS4.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS4.SSS0.Px1.p1.1">다양한 작업들의 이러한 평가 세트에 대한 모델들의 성능을 평가하는 것은 상이한 작업들이 상이한 전문 지식을 요구하기 때문에 매우 어렵다. 실제로, 이러한 태스크들 중 다수는 자동 메트릭에 의해 측정되거나 심지어 정상적인 크라우드 워커들에 의해 판단될 수 없다(예를 들어, 프로그램을 작성하거나, 1차 로직을 자연 언어로 변환하는 것). 보다 충실한 평가를 받기 위해 지침의 저자에게 모델 예측을 판단하도록 요청했다. 이 인간 평가를 설정하는 방법에 대한 자세한 내용은 부록 <a class="ltx_ref" href="#A2" title="Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">B</span></a>에 설명되어 있다. 평가자들은 과제를 정확하고 효과적으로 완성하는지 여부에 따라 산출물을 평가하도록 하였다. 모델 출력의 품질을 분류하기 위해 4단계 등급 시스템을 구현했다.</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_smallcaps" id="S4.I1.i1.p1.1.1">Rating-A:</span> The response is valid and satisfying.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_smallcaps" id="S4.I1.i2.p1.1.1">Rating-B:</span> 응답은 허용 가능하지만 사소한 오류 또는 불완전성을 가지고 있습니다.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_smallcaps" id="S4.I1.i3.p1.1.1">Rating-C:</span> The response is relevant and responds to the instruction, but it has significant errors in the content. 예를 들어 GPT3는 먼저 유효한 출력을 생성하지만 관련 없는 다른 항목을 계속 생성할 수 있습니다.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i4.p1.1"><span class="ltx_text ltx_font_smallcaps" id="S4.I1.i4.p1.1.1">Rating-D:</span> The response is irrelevant or completely invalid.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS4.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>

<div id="S4.SS4.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS4.SSS0.Px2.p1.9"><a class="ltx_ref ltx_refmacro_autoref" href="#S4.F6" title="Figure 6 ‣ Results. ‣ 4.3 Experiment 1: Zero-Shot Generalization on SuperNI benchmark ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Figure 6</span></a>는 <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.9.5">GPT3</span> 모델 및 이 새로 작성된 명령 세트에 대한 명령 조정 대응물의 성능을 보여준다(w. inter-rater agreement <math alttext="\kappa=0.57" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS4.SSS0.Px2.p1.1.m1.1a"><mrow id="S4.SS4.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.2.cmml">κ</mi><mo id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.1" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.cmml">0.57</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1"><eq id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.1"></eq><ci id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.2">𝜅</ci><cn id="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3.cmml" type="float" xref="S4.SS4.SSS0.Px2.p1.1.m1.1.1.3">0.57</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.1.m1.1c">\kappa=0.57</annotation></semantics></math> on the 4-class categorical scale, see Appendix <a class="ltx_ref" href="#A2" title="Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">B</span></a> for details). 예상대로 바닐라 <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.9.6">GPT3</span> LM은 대부분 명령에 응답할 수 없으며 모든 명령 조정 모델은 비교적 더 높은 성능을 보여줍니다. 그럼에도 불구하고, <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.2.1">GPT3<math></span> (i.e., <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.9.7">GPT3</span> model finetuned with <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.9.8">T<math alttext="0" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px2.p1.3.2.m1.1"><semantics id="S4.SS4.SSS0.Px2.p1.3.2.m1.1a"><mn id="S4.SS4.SSS0.Px2.p1.3.2.m1.1.1" xref="S4.SS4.SSS0.Px2.p1.3.2.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.3.2.m1.1b"><cn id="S4.SS4.SSS0.Px2.p1.3.2.m1.1.1.cmml" type="integer" xref="S4.SS4.SSS0.Px2.p1.3.2.m1.1.1">0</cn></annotation-xml></semantics></math></span> 또는 <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.9.9">SuperNI</span> data는 노이즈에도 불구하고 생성된 데이터의 값을 큰 마진으로 보여준다. <math alttext="\text{InstructGPT}_{\text{001}}" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px2.p1.4.m2.1"><semantics id="S4.SS4.SSS0.Px2.p1.4.m2.1a"><msub id="S4.SS4.SSS0.Px2.p1.4.m2.1.1" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1.cmml"><mtext id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.2" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.3" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.4.m2.1b"><apply id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1">subscript</csymbol><ci id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.2a.cmml" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1.2"><mtext id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.2.cmml" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.3a.cmml" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1.3"><mtext id="S4.SS4.SSS0.Px2.p1.4.m2.1.1.3.cmml" mathsize="70%" xref="S4.SS4.SSS0.Px2.p1.4.m2.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.4.m2.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>와 비교하면, <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.5.3">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px2.p1.5.3.m1.1"><semantics id="S4.SS4.SSS0.Px2.p1.5.3.m1.1a"><msub id="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1" xref="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.cmml"><mi id="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1a" xref="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.1" xref="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.5.3.m1.1b"><apply id="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1"><ci id="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.1a.cmml" xref="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.1.cmml" mathsize="70%" xref="S4.SS4.SSS0.Px2.p1.5.3.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.5.3.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>은 성능이 상당히 비슷합니다. 사소한 불완전성으로 허용 가능한 응답을 카운트하면(<span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.9.10">Rating-B</span>) 유효한 것으로 <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.6.4">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px2.p1.6.4.m1.1"><semantics id="S4.SS4.SSS0.Px2.p1.6.4.m1.1a"><msub id="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1" xref="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.cmml"><mi id="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1a" xref="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.1" xref="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.6.4.m1.1b"><apply id="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1"><ci id="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.1a.cmml" xref="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.1.cmml" mathsize="70%" xref="S4.SS4.SSS0.Px2.p1.6.4.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.6.4.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>은 <math alttext="\text{InstructGPT}_{\text{001}}" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px2.p1.7.m3.1"><semantics id="S4.SS4.SSS0.Px2.p1.7.m3.1a"><msub id="S4.SS4.SSS0.Px2.p1.7.m3.1.1" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1.cmml"><mtext id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.2" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.3" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.7.m3.1b"><apply id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1">subscript</csymbol><ci id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.2a.cmml" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1.2"><mtext id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.2.cmml" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.3a.cmml" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1.3"><mtext id="S4.SS4.SSS0.Px2.p1.7.m3.1.1.3.cmml" mathsize="70%" xref="S4.SS4.SSS0.Px2.p1.7.m3.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.7.m3.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>에 비해 5%밖에 뒤지지 않습니다. 마지막으로, <math alttext="\text{InstructGPT}_{\text{002}}" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px2.p1.8.m4.1"><semantics id="S4.SS4.SSS0.Px2.p1.8.m4.1a"><msub id="S4.SS4.SSS0.Px2.p1.8.m4.1.1" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1.cmml"><mtext id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.2" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.3" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1.3a.cmml">002</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.8.m4.1b"><apply id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1">subscript</csymbol><ci id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.2a.cmml" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1.2"><mtext id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.2.cmml" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.3a.cmml" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1.3"><mtext id="S4.SS4.SSS0.Px2.p1.8.m4.1.1.3.cmml" mathsize="70%" xref="S4.SS4.SSS0.Px2.p1.8.m4.1.1.3">002</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.8.m4.1c">\text{InstructGPT}_{\text{002}}</annotation></semantics></math>와 <math alttext="\text{InstructGPT}_{\text{003}}" class="ltx_Math" display="inline" id="S4.SS4.SSS0.Px2.p1.9.m5.1"><semantics id="S4.SS4.SSS0.Px2.p1.9.m5.1a"><msub id="S4.SS4.SSS0.Px2.p1.9.m5.1.1" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1.cmml"><mtext id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.2" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.3" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1.3a.cmml">003</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS4.SSS0.Px2.p1.9.m5.1b"><apply id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1"><csymbol cd="ambiguous" id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.1.cmml" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1">subscript</csymbol><ci id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.2a.cmml" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1.2"><mtext id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.2.cmml" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.3a.cmml" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1.3"><mtext id="S4.SS4.SSS0.Px2.p1.9.m5.1.1.3.cmml" mathsize="70%" xref="S4.SS4.SSS0.Px2.p1.9.m5.1.1.3">003</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.SSS0.Px2.p1.9.m5.1c">\text{InstructGPT}_{\text{003}}</annotation></semantics></math>의 인상적인 명령어 수행 능력을 확인하였다. 이러한 성공의 배경에는 많은 요인이 있지만, 향후 작업은 <cite class="ltx_cite ltx_citemacro_citet">Ouyang et al. (<a class="ltx_ref" href="#bib.bib23" title="">2022</a>)</cite>에서 사용하는 알고리즘과 유사하게 인간 주석기를 사용하거나 보상 모델을 훈련하여 더 나은 세대를 선택하여 생성된 데이터의 품질을 개선하는 데 크게 도움이 될 수 있다고 추측한다.</p>
</div>
</section>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Effect of Data Size and Quality</h3>

<section id="S4.SS5.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data size.</h4>

<div id="S4.SS5.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS5.SSS0.Px1.p1.1"><span class="ltx_text ltx_font_smallcaps" id="S4.SS5.SSS0.Px1.p1.1.2">Self-Instruct</span>은 인간 라벨링이 거의 없는 낮은 비용으로 명령어 데이터를 성장시키는 방법을 제공한다; 이러한 생성된 데이터가 더 나은 명령어 추종 능력으로 이어질 수 있다? 생성된 데이터셋에서 서로 다른 수의 명령어를 서브샘플링하고, 샘플링된 하위 집합에 대해 <span class="ltx_text ltx_font_smallcaps" id="S4.SS5.SSS0.Px1.p1.1.3">GPT3</span>을 핀튜닝하고, 252개의 사용자 지향 명령어 집합에 대해 결과 모델이 어떻게 수행되는지 평가하여 생성된 데이터의 크기를 분석한다. 우리는 §<a class="ltx_ref" href="#S4.SS4" title="4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">4.4</span></a>에서와 동일한 인간 평가를 수행한다. <a class="ltx_ref ltx_refmacro_autoref" href="#S4.F7" title="Figure 7 ‣ Data quality. ‣ 4.5 Effect of Data Size and Quality ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Figure 7</span></a>는 생성된 데이터의 서로 다른 크기로 파인튜닝된 <span class="ltx_text ltx_font_smallcaps" id="S4.SS5.SSS0.Px1.p1.1.1">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="S4.SS5.SSS0.Px1.p1.1.1.m1.1"><semantics id="S4.SS5.SSS0.Px1.p1.1.1.m1.1a"><msub id="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1" xref="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.cmml"><mi id="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1a" xref="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.1" xref="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.SSS0.Px1.p1.1.1.m1.1b"><apply id="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.cmml" xref="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1"><ci id="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.1a.cmml" xref="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.SS5.SSS0.Px1.p1.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.SSS0.Px1.p1.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> 모델의 성능을 제시한다. 전반적으로 데이터 크기를 늘리면 일관된 개선을 볼 수 있습니다. 그러나, 이러한 개선은 16K 이후 거의 안정적이다 이는 <cite class="ltx_cite ltx_citemacro_citet">Wang et al. (<a class="ltx_ref" href="#bib.bib33" title="">2022</a>, Fig. 5)</cite>의 데이터 스케일링 실험과 일맥상통한다. 흥미롭게도 <span class="ltx_text ltx_font_smallcaps" id="S4.SS5.SSS0.Px1.p1.1.4">SuperNI</span>에서 모델의 성능 향상 플래토스를 약 수백 개의 지침에서 더 일찍 발견했습니다. 이는 새로운 생성 데이터가 <span class="ltx_text ltx_font_smallcaps" id="S4.SS5.SSS0.Px1.p1.1.5">SuperNI</span>에서 일반적인 NLP 작업과 구별된다는 사실 때문일 수 있으며, 이는 향후 연구가 다양한 유형의 작업에 대한 더 나은 성능을 위해 서로 다른 명령 데이터의 조합을 사용하는 것으로부터 이익을 얻을 수 있음을 나타낸다.</p>
</div>
</section>
<section id="S4.SS5.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Data quality.</h4>

<div id="S4.SS5.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS5.SSS0.Px2.p1.2">모델의 성능을 개선하기 위한 또 다른 방향은 생성된 데이터를 가져가서 (소음이 적은) 더 나은 감독을 받는 것이다. 우리는 명령어와 입력이 주어진 모든 인스턴스의 출력 필드를 재생성하기 위해 <math alttext="\text{InstructGPT}_{\text{003}}" class="ltx_Math" display="inline" id="S4.SS5.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS5.SSS0.Px2.p1.1.m1.1a"><msub id="S4.SS5.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.cmml"><mtext id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3a.cmml">003</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2a.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2"><mtext id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3a.cmml" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3"><mtext id="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S4.SS5.SSS0.Px2.p1.1.m1.1.1.3">003</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.SSS0.Px2.p1.1.m1.1c">\text{InstructGPT}_{\text{003}}</annotation></semantics></math>(가장 좋은 범용 모델)를 사용하여 이 아이디어를 탐구한다. 그런 다음 이 개선된 버전의 데이터를 사용하여 <span class="ltx_text ltx_font_smallcaps" id="S4.SS5.SSS0.Px2.p1.2.1">GPT3</span>을 핀튠합니다. 이는 우리의 데이터와 함께 <math alttext="\text{InstructGPT}_{\text{003}}" class="ltx_Math" display="inline" id="S4.SS5.SSS0.Px2.p1.2.m2.1"><semantics id="S4.SS5.SSS0.Px2.p1.2.m2.1a"><msub id="S4.SS5.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.cmml"><mtext id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3a.cmml">003</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS5.SSS0.Px2.p1.2.m2.1b"><apply id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2a.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2"><mtext id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.2">InstructGPT</mtext></ci><ci id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3a.cmml" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3"><mtext id="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S4.SS5.SSS0.Px2.p1.2.m2.1.1.3">003</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.SSS0.Px2.p1.2.m2.1c">\text{InstructGPT}_{\text{003}}</annotation></semantics></math>의 증류로 간주할 수 있다. <a class="ltx_ref ltx_refmacro_autoref" href="#S4.F7" title="Figure 7 ‣ Data quality. ‣ 4.5 Effect of Data Size and Quality ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Figure 7</span></a>에 나타난 바와 같이, 결과 모델은 원본 데이터로 훈련된 상대 모델보다 10% 이상 성능이 향상되었으며, 이는 초기 데이터를 얻은 다음 인간 전문가 또는 더 나은 모델의 증류로 데이터 품질을 개선하기 위해 생성 파이프라인을 사용하는 향후 작업에 큰 여지를 제공한다.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2212.10560/assets/x9.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_square" width="332" height="271" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 7:</span>Human evaluation performance of <span class="ltx_text ltx_font_smallcaps" id="S4.F7.4.1">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="S4.F7.4.1.m1.1"><semantics id="S4.F7.4.1.m1.1b"><msub id="S4.F7.4.1.m1.1.1" xref="S4.F7.4.1.m1.1.1.cmml"><mi id="S4.F7.4.1.m1.1.1b" xref="S4.F7.4.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.F7.4.1.m1.1.1.1" xref="S4.F7.4.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F7.4.1.m1.1c"><apply id="S4.F7.4.1.m1.1.1.cmml" xref="S4.F7.4.1.m1.1.1"><ci id="S4.F7.4.1.m1.1.1.1a.cmml" xref="S4.F7.4.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="S4.F7.4.1.m1.1.1.1.cmml" mathsize="70%" xref="S4.F7.4.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.4.1.m1.1d">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> models tuned with different size of instructions. <math alttext="x" class="ltx_Math" display="inline" id="S4.F7.5.m1.1"><semantics id="S4.F7.5.m1.1b"><mi id="S4.F7.5.m1.1.1" xref="S4.F7.5.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.F7.5.m1.1c"><ci id="S4.F7.5.m1.1.1.cmml" xref="S4.F7.5.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.5.m1.1d">x</annotation></semantics></math>-axis is in log scale. 가장 작은 크기는 175이며, 여기서 시드 작업만이 명령어 튜닝을 위해 사용된다.</figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Human evaluation performance of <span id="S4.F7.4.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="S4.F7.4.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="S4.F7.4.1.m1.1b"><msub id="S4.F7.4.1.m1.1.1" xref="S4.F7.4.1.m1.1.1.cmml"><mi id="S4.F7.4.1.m1.1.1b" xref="S4.F7.4.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="S4.F7.4.1.m1.1.1.1" xref="S4.F7.4.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F7.4.1.m1.1c"><apply id="S4.F7.4.1.m1.1.1.cmml" xref="S4.F7.4.1.m1.1.1"><ci id="S4.F7.4.1.m1.1.1.1a.cmml" xref="S4.F7.4.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="S4.F7.4.1.m1.1.1.1.cmml" xref="S4.F7.4.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.4.1.m1.1d">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> models tuned with different sizes of instructions. <math id="S4.F7.5.m1.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S4.F7.5.m1.1b"><mi id="S4.F7.5.m1.1.1" xref="S4.F7.5.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S4.F7.5.m1.1c"><ci id="S4.F7.5.m1.1.1.cmml" xref="S4.F7.5.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.5.m1.1d">x</annotation></semantics></math>-axis is in log scale. The smallest size is 175, where only the seed tasks are used for instruction tuning.
We also evaluate whether improving the data quality will further improve the performance by distilling the outputs from <math id="S4.F7.6.m2.1" class="ltx_Math" alttext="\text{InstructGPT}_{\text{003}}" display="inline"><semantics id="S4.F7.6.m2.1b"><msub id="S4.F7.6.m2.1.1" xref="S4.F7.6.m2.1.1.cmml"><mtext id="S4.F7.6.m2.1.1.2" xref="S4.F7.6.m2.1.1.2a.cmml">InstructGPT</mtext><mtext id="S4.F7.6.m2.1.1.3" xref="S4.F7.6.m2.1.1.3a.cmml">003</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.F7.6.m2.1c"><apply id="S4.F7.6.m2.1.1.cmml" xref="S4.F7.6.m2.1.1"><csymbol cd="ambiguous" id="S4.F7.6.m2.1.1.1.cmml" xref="S4.F7.6.m2.1.1">subscript</csymbol><ci id="S4.F7.6.m2.1.1.2a.cmml" xref="S4.F7.6.m2.1.1.2"><mtext id="S4.F7.6.m2.1.1.2.cmml" xref="S4.F7.6.m2.1.1.2">InstructGPT</mtext></ci><ci id="S4.F7.6.m2.1.1.3a.cmml" xref="S4.F7.6.m2.1.1.3"><mtext mathsize="70%" id="S4.F7.6.m2.1.1.3.cmml" xref="S4.F7.6.m2.1.1.3">003</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F7.6.m2.1d">\text{InstructGPT}_{\text{003}}</annotation></semantics></math>. We see consistent improvement from using larger data with better quality.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2>

<section id="S5.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Instruction-following LMs.</h4>

<div id="S5.SS0.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1">일련의 연구는 바닐라 LM이 주석이 달린 "지시" 데이터-언어 지시 명령을 포함하는 데이터 세트 및 인간 주석 <cite class="ltx_cite ltx_citemacro_cite">(Weller et al., <a class="ltx_ref" href="#bib.bib38" title="">2020</a>; Mishra et al., <a class="ltx_ref" href="#bib.bib22" title="">2022</a>; Wei et al., <a class="ltx_ref" href="#bib.bib35" title="">2022</a>; Sanh et al., <a class="ltx_ref" href="#bib.bib27" title="">2022</a>, i.a.)</cite>에 기반한 원하는 결과를 조정하면 일반적인 언어 지침을 따르는 데 효과적일 수 있다는 증거를 발견했다. 또한, "지시" 데이터의 크기와 다양성과 보이지 않는 태스크 <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib33" title="">2022</a>; Chung et al., <a class="ltx_ref" href="#bib.bib4" title="">2022</a>)</cite>에 대한 결과 모델의 일반화 가능성 사이에 직접적인 상관 관계를 보여준다. 그러나 이러한 개발은 주로 기존의 NLP 작업에 초점을 맞추고 사람이 주석을 달 수 있는 지침에 의존하기 때문에 더 일반화할 수 있는 모델 <cite class="ltx_cite ltx_citemacro_cite">(e.g., see Fig. 5a in Wang et al., <a class="ltx_ref" href="#bib.bib33" title="">2022</a>)</cite>로의 진전에 병목 현상을 제기한다. 우리의 작업은 고전적인 NLP 작업을 넘어 사전 훈련된 LMs를 사용하여 다양한 수업 데이터를 만드는 문제를 해결하는 것을 목표로 한다. <math alttext="\text{InstructGPT}_{\text{}}" class="ltx_Math" display="inline" id="S5.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="S5.SS0.SSS0.Px1.p1.1.m1.1a"><msub id="S5.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.cmml"><mtext id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2a.cmml">InstructGPT</mtext><mrow id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3a.cmml"></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p1.1.m1.1b"><apply id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2a.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2"><mtext id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2">InstructGPT</mtext></ci><ci id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3a.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3"><mrow id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3"></mrow></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.1.m1.1c">\text{InstructGPT}_{\text{}}</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">Ouyang et al. (<a class="ltx_ref" href="#bib.bib23" title="">2022</a>)</cite>는 보다 범용적인 LMs를 구축하는 데 있어 우리와 유사한 목표를 공유하며, 다양한 사용자 지시를 따르는 데 있어서 괄목할 만한 성능을 보여주었다. 그러나 상업 시스템으로서 그들의 건설 과정은 여전히 상당히 불투명하다. 특히 <em class="ltx_emph ltx_font_italic" id="S5.SS0.SSS0.Px1.p1.1.1">data</em>은 제한된 투명성과 연구에 사용된 개인 사용자 데이터로 인해 아직 연구되지 않은 상태로 남아 있다. 이러한 문제를 해결하려면 광범위한 작업을 포함하는 대규모 공개 데이터 세트를 만들어야 합니다.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Language models for data generation and augmentation.</h4>

<div id="S5.SS0.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS0.SSS0.Px2.p1.1">데이터 생성용 LMs(<cite class="ltx_cite ltx_citemacro_cite">Schick and Schütze (<a class="ltx_ref" href="#bib.bib28" title="">2021</a>); Wang et al. (<a class="ltx_ref" href="#bib.bib34" title="">2021</a>); Liu et al. (<a class="ltx_ref" href="#bib.bib17" title="">2022</a>); Meng et al. (<a class="ltx_ref" href="#bib.bib20" title="">2023</a>)</cite>) 또는 증강용 LMs(<cite class="ltx_cite ltx_citemacro_cite">Feng et al. (<a class="ltx_ref" href="#bib.bib6" title="">2021</a>); Yang et al. (<a class="ltx_ref" href="#bib.bib42" title="">2020</a>); Mekala et al. (<a class="ltx_ref" href="#bib.bib19" title="">2022</a>)</cite>)을 이용한 다양한 연구들이 제안되었다. 우리의 작업은 특정 작업(say, QA 또는 NLI)에 특정한 <em class="ltx_emph ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.1.1">not</em>이라는 점에서 이 라인과 다르다. 이와는 대조적으로, <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px2.p1.1.2">Self-Instruct</span>은 NLP 실무자들에 의해 이전에 정의되지 않았을 수도 있는 새로운 작업 정의를 부트스트랩하는 것이다. 그럼에도 불구하고, 우리는 수업 데이터를 확장하는 두 가지 노력이 상호 보완적이며 커뮤니티가 이러한 다양한 데이터 세트로부터 이익을 얻을 것이라고 믿는다.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Instruction generation.</h4>

<div id="S5.SS0.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS0.SSS0.Px3.p1.1">일련의 최근 작업 <cite class="ltx_cite ltx_citemacro_cite">Zhou et al. (<a class="ltx_ref" href="#bib.bib47" title="">2022b</a>); Ye et al. (<a class="ltx_ref" href="#bib.bib43" title="">2022</a>); Singh et al. (<a class="ltx_ref" href="#bib.bib30" title="">2022</a>); Honovich et al. (<a class="ltx_ref" href="#bib.bib11" title="">2022b</a>)</cite>는 몇 가지 예가 주어진 작업의 명령을 생성한다. <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px3.p1.1.1">Self-Instruct</span>도 명령어 생성을 포함하지만, 이 경우의 주요 차이점은 태스크 불가지론이며, 처음부터 새로운 태스크(인스트럭션과 함께 명령어)를 생성합니다.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Model self-training.</h4>

<div id="S5.SS0.SSS0.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS0.SSS0.Px4.p1.1">전형적인 셀프-트레이닝 프레임워크 <cite class="ltx_cite ltx_citemacro_cite">He et al. (<a class="ltx_ref" href="#bib.bib8" title="">2019</a>); Xie et al. (<a class="ltx_ref" href="#bib.bib40" title="">2020</a>); Du et al. (<a class="ltx_ref" href="#bib.bib5" title="">2021</a>); Amini et al. (<a class="ltx_ref" href="#bib.bib1" title="">2022</a>); Huang et al. (<a class="ltx_ref" href="#bib.bib12" title="">2022</a>)</cite>는 트레이닝된 모델들을 사용하여 라벨이 지정되지 않은 데이터에 라벨을 할당한 다음, 새로 라벨링된 데이터를 활용하여 모델을 개선한다. 유사한 라인에서, <cite class="ltx_cite ltx_citemacro_citet">Zhou et al. (<a class="ltx_ref" href="#bib.bib46" title="">2022a</a>)</cite>는 단일 태스크를 특정하기 위해 다수의 프롬프트를 사용하고 프롬프트 일관성을 통해 정규화할 것을 제안하여 프롬프트에 대한 일관된 예측을 장려한다. 이를 통해 추가 레이블이 지정되지 않은 훈련 데이터로 모델을 미세 조정하거나 추론 시간에 직접 적용할 수 있다. <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px4.p1.1.1">Self-Instruct</span>은 자체 학습 문헌과 유사하지만 대부분의 자체 학습 방법은 특정 <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.2">target task</span>뿐만 아니라 <span class="ltx_text ltx_font_italic" id="S5.SS0.SSS0.Px4.p1.1.3">unlabeled examples</span> under it; 대조적으로 <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px4.p1.1.4">Self-Instruct</span>은 처음부터 다양한 작업을 생성한다고 가정합니다.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Knowledge distillation.</h4>

<div id="S5.SS0.SSS0.Px5.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS0.SSS0.Px5.p1.1">지식증류<cite class="ltx_cite ltx_citemacro_cite">Hinton et al. (<a class="ltx_ref" href="#bib.bib9" title="">2015</a>); Sanh et al. (<a class="ltx_ref" href="#bib.bib26" title="">2019</a>); West et al. (<a class="ltx_ref" href="#bib.bib39" title="">2021</a>); Magister et al. (<a class="ltx_ref" href="#bib.bib18" title="">2022</a>)</cite>는 종종 더 큰 모델에서 더 작은 모델로 지식을 전달하는 것을 포함한다. <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px5.p1.1.1">Self-Instruct</span>도 "knowledge distillation"의 형태로 볼 수 있지만, 이는 다음과 같은 방식으로 이 라인과 다르다: (1) 증류의 소스와 타겟은 동일하며, 즉 모델의 지식은 스스로 증류된다; (2) 증류의 내용은 명령 태스크의 형태(즉, 태스크를 정의하는 명령어, 및 그것을 인스턴스화하는 예시들의 세트)이다.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px6" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Bootstrapping with limited resources.</h4>

<div id="S5.SS0.SSS0.Px6.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS0.SSS0.Px6.p1.1">일련의 최근 연구는 언어 모델을 사용하여 특수화된 방법을 사용하여 일부 추론을 부트스트랩한다. NPPrompt <cite class="ltx_cite ltx_citemacro_cite">Zhao et al. (<a class="ltx_ref" href="#bib.bib45" title="">2022</a>)</cite>는 어떠한 미세 조정도 없이 의미 레이블에 대한 예측을 생성하는 방법을 제공한다. 모델 자체 임베딩을 사용하여 데이터 샘플의 레이블과 관련된 단어를 자동으로 찾으므로 모델 예측에서 레이블(버벌라이저)로의 수동 매핑에 대한 의존성을 줄입니다. STAR<cite class="ltx_cite ltx_citemacro_cite">Zelikman et al. (<a class="ltx_ref" href="#bib.bib44" title="">2022</a>)</cite>는 소수의 근거 예제와 근거 없는 대규모 데이터 세트를 반복적으로 활용하여 모델의 추론 능력을 부트스트랩한다. Self-Correction <cite class="ltx_cite ltx_citemacro_cite">Welleck et al. (<a class="ltx_ref" href="#bib.bib37" title="">2023</a>)</cite>는 불완전한 베이스 생성기(모델)를 불완전한 세대를 반복적으로 교정하도록 학습하고 베이스 생성기에 대한 개선을 입증하는 별도의 교정기로부터 분리한다. 우리의 작업은 대신 명령 패러다임에서 새로운 작업을 부트스트랩하는 데 중점을 둔다.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px7" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Multi-modal instruction-following.</h4>

<div id="S5.SS0.SSS0.Px7.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS0.SSS0.Px7.p1.1">명령어 추종 모델은 또한 멀티모달 학습 문헌 <cite class="ltx_cite ltx_citemacro_cite">Fried et al. (<a class="ltx_ref" href="#bib.bib7" title="">2018</a>); Shridhar et al. (<a class="ltx_ref" href="#bib.bib29" title="">2020</a>); Min et al. (<a class="ltx_ref" href="#bib.bib21" title="">2022</a>); Weir et al. (<a class="ltx_ref" href="#bib.bib36" title="">2022</a>)</cite>에서 관심을 가져왔다. <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px7.p1.1.1">Self-Instruct</span> 데이터 확장에 대한 일반적인 접근 방식으로서 잠재적으로 이러한 설정에도 도움이 될 수 있으며, 이는 향후 작업으로 남겨둔다.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p" id="S6.p1.1">본 논문에서는 자체적인 명령어 데이터 생성을 통해 LMs의 명령어 추종 능력을 향상시키는 방법인 <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.1">Self-Instruct</span>을 소개한다. 바닐라 <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.2">GPT3</span>을 사용하여 다양한 작업에 대한 52K 지침의 대규모 데이터 세트를 자동으로 구성하고 이 데이터에 GPT3를 핀튜닝하면 원래 <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.3">SuperNI</span>에서 33% 절대 개선이 됩니다. 또한, 우리는 새로운 작업에 대해 전문가가 작성한 일련의 지침을 선별합니다. 이 세트에 대한 인간 평가는 GPT3을 <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.5">Self-Instruct</span>이 기존 공개 명령 데이터 세트를 사용하는 것보다 큰 마진만큼 성능이 뛰어나며 <math alttext="\text{InstructGPT}_{\text{001}}" class="ltx_Math" display="inline" id="S6.p1.1.m1.1"><semantics id="S6.p1.1.m1.1a"><msub id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml"><mtext id="S6.p1.1.m1.1.1.2" xref="S6.p1.1.m1.1.1.2a.cmml">InstructGPT</mtext><mtext id="S6.p1.1.m1.1.1.3" xref="S6.p1.1.m1.1.1.3a.cmml">001</mtext></msub><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><apply id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S6.p1.1.m1.1.1.1.cmml" xref="S6.p1.1.m1.1.1">subscript</csymbol><ci id="S6.p1.1.m1.1.1.2a.cmml" xref="S6.p1.1.m1.1.1.2"><mtext id="S6.p1.1.m1.1.1.2.cmml" xref="S6.p1.1.m1.1.1.2">InstructGPT</mtext></ci><ci id="S6.p1.1.m1.1.1.3a.cmml" xref="S6.p1.1.m1.1.1.3"><mtext id="S6.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S6.p1.1.m1.1.1.3">001</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">\text{InstructGPT}_{\text{001}}</annotation></semantics></math>와 밀접하게 수행됨을 보여준다. <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.6">Self-Instruct</span>은 사전 훈련된 LMs를 정렬하여 인간 명령을 따르도록 하는 첫 번째 단계 역할을 할 수 있으며 향후 작업은 이 데이터 위에 빌드하여 명령 수행 모델을 개선할 수 있다.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Broader Impact</h2>

<div id="S7.p1" class="ltx_para">
<p class="ltx_p" id="S7.p1.1">본 논문의 즉각적인 초점을 넘어 <span class="ltx_text ltx_font_smallcaps" id="S7.p1.1.1">Self-Instruct</span>은 <math alttext="\text{InstructGPT}_{\text{}}" class="ltx_Math" display="inline" id="S7.p1.1.m1.1"><semantics id="S7.p1.1.m1.1a"><msub id="S7.p1.1.m1.1.1" xref="S7.p1.1.m1.1.1.cmml"><mtext id="S7.p1.1.m1.1.1.2" xref="S7.p1.1.m1.1.1.2a.cmml">InstructGPT</mtext><mrow id="S7.p1.1.m1.1.1.3" xref="S7.p1.1.m1.1.1.3a.cmml"></mrow></msub><annotation-xml encoding="MathML-Content" id="S7.p1.1.m1.1b"><apply id="S7.p1.1.m1.1.1.cmml" xref="S7.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S7.p1.1.m1.1.1.1.cmml" xref="S7.p1.1.m1.1.1">subscript</csymbol><ci id="S7.p1.1.m1.1.1.2a.cmml" xref="S7.p1.1.m1.1.1.2"><mtext id="S7.p1.1.m1.1.1.2.cmml" xref="S7.p1.1.m1.1.1.2">InstructGPT</mtext></ci><ci id="S7.p1.1.m1.1.1.3a.cmml" xref="S7.p1.1.m1.1.1.3"><mrow id="S7.p1.1.m1.1.1.3.cmml" xref="S7.p1.1.m1.1.1.3"></mrow></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.1.m1.1c">\text{InstructGPT}_{\text{}}</annotation></semantics></math> 또는 ChatGPT와 같이 널리 사용되는 명령 조정 모델의 "behind the scenes"에서 발생하는 일에 더 많은 투명성을 가져오는 데 도움이 될 수 있다고 믿는다. 불행히도 이러한 산업 모델은 데이터 세트가 공개되지 않아 API 벽 뒤에 남아 있으며, 따라서 구성 및 인상적인 기능을 보여주는 이유에 대한 이해가 거의 없다. 이제 학계는 이러한 모델의 성공 원인을 더 잘 이해하고 더 나은 모델 및 더 열린 모델을 위해 노력해야 한다. 본 논문의 연구 결과는 다양한 명령어 데이터의 중요성을 보여주며, 대규모 합성 데이터 세트는 더 나은 명령어 후속 모델을 구축하기 위한 고품질 데이터를 향한 첫 번째 단계가 될 수 있다고 믿는다. 이 글에서 이 논문의 중심 아이디어는 <cite class="ltx_cite ltx_citemacro_citep">(Taori et al., <a class="ltx_ref" href="#bib.bib32" title="">2023</a>; Xu et al., <a class="ltx_ref" href="#bib.bib41" title="">2023</a>; Sun et al., <a class="ltx_ref" href="#bib.bib31" title="">2023</a>, i.a.)</cite>와 같은 노력을 위한 몇 가지 후속 작업에서 채택되었다.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Limitations</h2>

<div id="S8.p1" class="ltx_para">
<p class="ltx_p" id="S8.p1.1">여기서는 이러한 방향으로 향후 연구에 영감을 주기 위해 이 작업의 몇 가지 제한 사항에 대해 논의한다.</p>
</div>
<section id="S8.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Tail phenomena.</h4>

<div id="S8.SS0.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS0.SSS0.Px1.p1.1"><span class="ltx_text ltx_font_smallcaps" id="S8.SS0.SSS0.Px1.p1.1.1">Self-Instruct</span> depends on LMs, and it will inherit all the limitations of carry over with LMs. 최근 연구에서 <cite class="ltx_cite ltx_citemacro_cite">Razeghi et al. (<a class="ltx_ref" href="#bib.bib25" title="">2022</a>); Kandpal et al. (<a class="ltx_ref" href="#bib.bib13" title="">2022</a>)</cite>, <em class="ltx_emph ltx_font_italic" id="S8.SS0.SSS0.Px1.p1.1.2">tail phenomena</em>은 LMs의 성공에 심각한 도전을 제기한다. 즉, LMs의 최대 이득은 언어의 빈번한 사용(언어 사용 분포의 선두)에 해당하며, 저빈도 컨텍스트에서는 최소 이득이 있을 수 있다. 유사하게, 이 작업의 맥락에서 <span class="ltx_text ltx_font_smallcaps" id="S8.SS0.SSS0.Px1.p1.1.3">Self-Instruct</span>이 사전 훈련 코퍼스에서 더 자주 나타나는 작업 또는 명령으로 치우쳐 있으면 놀라운 일이 아니다. 결과적으로 접근 방식은 흔하지 않고 창의적인 지침에 대해 취성을 보일 수 있다.</p>
</div>
</section>
<section id="S8.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Dependence on large models.</h4>

<div id="S8.SS0.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS0.SSS0.Px2.p1.1"><span class="ltx_text ltx_font_smallcaps" id="S8.SS0.SSS0.Px2.p1.1.1">Self-Instruct</span>의 LMs에서 추출한 유도 편향에 대한 의존성으로 인해 더 큰 모델에 가장 적합할 수 있습니다. 만약 사실이라면, 이것은 큰 컴퓨팅 자원을 가지고 있지 않을 수 있는 사람들에게 접근의 장벽을 만들 수 있다. 향후 연구에서는 모델 크기 또는 다양한 다른 매개변수의 함수로 이득을 신중하게 연구할 수 있기를 바란다. 인간 주석을 사용한 명령 조정도 유사한 한계를 겪는다는 점은 주목할 가치가 있다. 명령 조정의 이득은 더 큰 모델 <cite class="ltx_cite ltx_citemacro_cite">Wei et al. (<a class="ltx_ref" href="#bib.bib35" title="">2022</a>)</cite>에서 더 높다.</p>
</div>
</section>
<section id="S8.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Reinforcing LM biases.</h4>

<div id="S8.SS0.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS0.SSS0.Px3.p1.1">저자들이 우려하는 점은 문제가 되는 사회적 편향(성별, 인종 등에 대한 고정관념이나 비방)의 증폭과 같은 이 반복 알고리즘의 의도하지 않은 결과이다. 이와 관련하여 이 과정에서 관찰된 한 가지 과제는 모델의 이전 편향을 반영한 균형 잡힌 레이블을 생성하는 알고리즘의 어려움이다. 향후 작업이 접근법의 장단점에 대한 더 나은 이해로 이어지기를 바랍니다.</p>
</div>
</section>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.p1.1">저자들은 건설적인 피드백에 대해 익명의 리뷰어들에게 감사를 표하고 싶습니다. 우리는 특히 세원민, 에릭 월리스, 오피어 프레스, 그리고 UWNLP와 AllenNLP의 다른 멤버들이 격려하는 피드백과 지적 지원에 감사한다. 이 작업은 NIWC 퍼시픽(N66001-19-2-4031), ONR N00014-18-1-2826, ONR MURI N00014-18-1-2670을 통한 DARPA MCS 프로그램과 AI2 및 알렌 조사관 상의 선물로 부분적으로 지원되었다.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amini et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Massih-Reza Amini, Vasilii Feofanov, Loic Pauletto, Emilie Devijver, and Yury
Maximov. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2202.12040" title="" class="ltx_ref ltx_href">Self-training: A survey</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2202.12040</em>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bach et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Stephen&nbsp;H Bach, Victor Sanh, Zheng-Xin Yong, Albert Webson, Colin Raffel,
Nihal&nbsp;V Nayak, Abheesht Sharma, Taewoon Kim, M&nbsp;Saiful Bari, Thibault Fevry,
et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2202.01279" title="" class="ltx_ref ltx_href">PromptSource: An
Integrated Development Environment and Repository for Natural Language
Prompts</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational
Linguistics (ACL) - System Demonstrations</em>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Tom&nbsp;B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, and et&nbsp;al. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html" title="" class="ltx_ref ltx_href">Language models are few-shot learners</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
(NeurIPS)</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Hyung&nbsp;Won Chung, Le&nbsp;Hou, Shayne Longpre, Barret Zoph, Yi&nbsp;Tay, William Fedus,
Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et&nbsp;al. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2210.11416" title="" class="ltx_ref ltx_href">Scaling
instruction-finetuned language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.11416</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Jingfei Du, Édouard Grave, Beliz Gunel, Vishrav Chaudhary, Onur Celebi,
Michael Auli, Veselin Stoyanov, and Alexis Conneau. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2021.naacl-main.426" title="" class="ltx_ref ltx_href">Self-training
improves pre-training for natural language understanding</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Conference of the North American Chapter of the Association
for Computational Linguistics (NAACL): Human Language Technologies</em>,
pages 5408–5418.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Steven&nbsp;Y Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi,
Teruko Mitamura, and Eduard Hovy. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2021.findings-acl.84/" title="" class="ltx_ref ltx_href">A survey of
data augmentation approaches for nlp</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational
Linguistics (ACL)&nbsp;ACL-IJCNLP - Findings</em>, pages 968–988.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fried et&nbsp;al. (2018)</span>
<span class="ltx_bibblock">
Daniel Fried, Ronghang Hu, Volkan Cirik, Anna Rohrbach, Jacob Andreas,
Louis-Philippe Morency, Taylor Berg-Kirkpatrick, Kate Saenko, Dan Klein, and
Trevor Darrell. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1806.02724" title="" class="ltx_ref ltx_href">Speaker-follower models for
vision-and-language navigation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
(NeurIPS)</em>.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Junxian He, Jiatao Gu, Jiajun Shen, and Marc’Aurelio Ranzato. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1909.13788" title="" class="ltx_ref ltx_href">Revisiting self-training
for neural sequence generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations
(ICLR)</em>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton et&nbsp;al. (2015)</span>
<span class="ltx_bibblock">
Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et&nbsp;al. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1503.02531" title="" class="ltx_ref ltx_href">Distilling the knowledge in
a neural network</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
(NeurIPS)&nbsp;Workshop on Deep Learning</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich et&nbsp;al. (2022a)</span>
<span class="ltx_bibblock">
Or&nbsp;Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 2022a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2212.09689" title="" class="ltx_ref ltx_href">Unnatural instructions:
Tuning language models with (almost) no human labor</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.09689</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honovich et&nbsp;al. (2022b)</span>
<span class="ltx_bibblock">
Or&nbsp;Honovich, Uri Shaham, Samuel&nbsp;R Bowman, and Omer Levy. 2022b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2205.10782" title="" class="ltx_ref ltx_href">Instruction induction: From
few examples to natural language task descriptions</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.10782</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Jiaxin Huang, Shixiang&nbsp;Shane Gu, Le&nbsp;Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu,
and Jiawei Han. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2205.10782" title="" class="ltx_ref ltx_href">Large language models can
self-improve</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.11610</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kandpal et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel.
2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2211.08411" title="" class="ltx_ref ltx_href">Large language models
struggle to learn long-tail knowledge</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.08411</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kitaev et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Nikita Kitaev, Steven Cao, and Dan Klein. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P19-1340" title="" class="ltx_ref ltx_href">Multilingual
constituency parsing with self-attention and pre-training</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational
Linguistics (ACL)</em>, pages 3499–3505.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kitaev and Klein (2018)</span>
<span class="ltx_bibblock">
Nikita Kitaev and Dan Klein. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/P18-1249" title="" class="ltx_ref ltx_href">Constituency parsing
with a self-attentive encoder</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational
Linguistics (ACL)</em>, pages 2676–2686.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lester et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2104.08691" title="" class="ltx_ref ltx_href">The power of scale for
parameter-efficient prompt tuning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP)</em>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Alisa Liu, Swabha Swayamdipta, Noah&nbsp;A. Smith, and Yejin Choi. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://preview.aclanthology.org/emnlp-22-ingestion/2022.findings-emnlp.508/" title="" class="ltx_ref ltx_href">WANLI: Worker and ai collaboration for natural language inference dataset
creation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP) - Findings</em>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Magister et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Lucie&nbsp;Charlotte Magister, Jonathan Mallinson, Jakub Adamek, Eric Malmi, and
Aliaksei Severyn. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2212.08410" title="" class="ltx_ref ltx_href">Teaching small language
models to reason</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.08410</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mekala et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Dheeraj Mekala, Tu&nbsp;Vu, Timo Schick, and Jingbo Shang. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2205.12604" title="" class="ltx_ref ltx_href">Leveraging qa datasets to
improve generative data augmentation</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.12604</em>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yu&nbsp;Meng, Martin Michalski, Jiaxin Huang, Yu&nbsp;Zhang, Tarek Abdelzaher, and Jiawei
Han. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2211.03044" title="" class="ltx_ref ltx_href">Tuning language models as
training data generators for augmentation-enhanced few-shot learning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning (ICML)</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
So&nbsp;Yeon Min, Devendra&nbsp;Singh Chaplot, Pradeep Ravikumar, Yonatan Bisk, and
Ruslan Salakhutdinov. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2110.07342" title="" class="ltx_ref ltx_href">FILM: Following
Instructions in Language with Modular Methods</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations
(ICLR)</em>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Swaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2104.08773" title="" class="ltx_ref ltx_href">Cross-Task Generalization
via Natural Language Crowdsourcing Instructions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational
Linguistics (ACL)</em>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeff Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll&nbsp;L Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et&nbsp;al.
2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2203.02155" title="" class="ltx_ref ltx_href">Training Language Models
to Follow Instructions with Human Feedback</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
(NeurIPS)</em>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J Liu. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1910.10683" title="" class="ltx_ref ltx_href">Exploring the limits of
transfer learning with a unified text-to-text transformer</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research (JMLR)</em>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Razeghi et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yasaman Razeghi, Robert&nbsp;L Logan&nbsp;IV, Matt Gardner, and Sameer Singh. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2202.07206" title="" class="ltx_ref ltx_href">Impact of pretraining term
frequencies on few-shot reasoning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2202.07206</em>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanh et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1910.01108" title="" class="ltx_ref ltx_href">Distilbert, a distilled
version of bert: smaller, faster, cheaper and lighter</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
(NeurIPS) Workshop on Energy Efficient Machine Learning and Cognitive
Computing</em>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanh et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid
Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M&nbsp;Saiful
Bari, Canwen Xu, Urmish Thakker, Shanya&nbsp;Sharma Sharma, Eliza Szczechla,
Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang,
Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng&nbsp;Xin Yong,
Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen,
Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason&nbsp;Alan Fries, Ryan
Teehan, Teven&nbsp;Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander&nbsp;M
Rush. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2110.08207" title="" class="ltx_ref ltx_href">Multitask Prompted
Training Enables Zero-Shot Task Generalization</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations
(ICLR)</em>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schick and Schütze (2021)</span>
<span class="ltx_bibblock">
Timo Schick and Hinrich Schütze. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2021.emnlp-main.555/" title="" class="ltx_ref ltx_href">Generating
datasets with pretrained language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP)</em>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shridhar et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han,
Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1912.01734" title="" class="ltx_ref ltx_href">ALFRED: A Benchmark for
Interpreting Grounded Instructions for Everyday Tasks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</em>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singh et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Chandan Singh, John&nbsp;X Morris, Jyoti Aneja, Alexander&nbsp;M Rush, and Jianfeng Gao.
2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2210.01848" title="" class="ltx_ref ltx_href">Explaining patterns in data
with language models via interpretable autoprompting</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.01848</em>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David
Cox, Yiming Yang, and Chuang Gan. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2305.03047" title="" class="ltx_ref ltx_href">Principle-driven
self-alignment of language models from scratch with minimal human
supervision</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.03047</em>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
Guestrin, Percy Liang, and Tatsunori&nbsp;B. Hashimoto. 2023.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tatsu-lab/stanford_alpaca</a>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza
Mirzaei, Anjana Arunkumar, Arjun Ashok, Arut&nbsp;Selvan Dhanasekaran, Atharva
Naik, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi&nbsp;Gary Lai,
Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi,
Maitreya Patel, Kuntal&nbsp;Kumar Pal, Mehrad Moradshahi, Mihir Parmar, Mirali
Purohit, Neeraj Varshney, Phani&nbsp;Rohitha Kaza, Pulkit Verma, Ravsehaj&nbsp;Singh
Puri, Rushang Karia, Shailaja&nbsp;Keyur Sampat, Savan Doshi, Siddhartha Mishra,
Sujan Reddy, Sumanta Patro, Tanay Dixit, Xudong Shen, Chitta Baral, Yejin
Choi, Noah&nbsp;A. Smith, Hannaneh Hajishirzi, and Daniel Khashabi. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2204.07705" title="" class="ltx_ref ltx_href">Super-naturalinstructions:
Generalization via declarative instructions on 1600+ tasks</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP)</em>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Zirui Wang, Adams&nbsp;Wei Yu, Orhan Firat, and Yuan Cao. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2109.09193" title="" class="ltx_ref ltx_href">Towards zero-label language
learning</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.09193</em>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams&nbsp;Wei Yu, Brian Lester,
Nan Du, Andrew&nbsp;M. Dai, and Quoc&nbsp;V Le. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2109.01652" title="" class="ltx_ref ltx_href">Finetuned Language Models
are Zero-Shot Learners</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations
(ICLR)</em>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weir et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Nathaniel Weir, Xingdi Yuan, Marc-Alexandre Côté, Matthew Hausknecht,
Romain Laroche, Ida Momennejad, Harm Van&nbsp;Seijen, and Benjamin Van&nbsp;Durme.
2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2203.04806" title="" class="ltx_ref ltx_href">One-Shot Learning from a
Demonstration with Hierarchical Latent Language</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.04806</em>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Welleck et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Sean Welleck, Ximing Lu, Peter West, Faeze Brahman, Tianxiao Shen, Daniel
Khashabi, and Yejin Choi. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2211.00053" title="" class="ltx_ref ltx_href">Generating sequences by
learning to self-correct</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations
(ICLR)</em>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weller et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Orion Weller, Nicholas Lourie, Matt Gardner, and Matthew Peters. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2020.emnlp-main.105/" title="" class="ltx_ref ltx_href">Learning from
Task Descriptions</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP)</em>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">West et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Peter West, Chandra Bhagavatula, Jack Hessel, Jena&nbsp;D Hwang, Liwei Jiang,
Ronan&nbsp;Le Bras, Ximing Lu, Sean Welleck, and Yejin Choi. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2022.naacl-main.341/" title="" class="ltx_ref ltx_href">Symbolic
knowledge distillation: from general language models to commonsense models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Conference of the North American Chapter of the Association
for Computational Linguistics (NAACL)</em>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc&nbsp;V Le. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/1911.04252" title="" class="ltx_ref ltx_href">Self-training with noisy
student improves imagenet classification</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</em>, pages 10687–10698.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2304.01196" title="" class="ltx_ref ltx_href">Baize: An open-source chat
model with parameter-efficient tuning on self-chat data</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.01196</em>.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Yiben Yang, Chaitanya Malaviya, Jared Fernandez, Swabha Swayamdipta, Ronan&nbsp;Le
Bras, Ji-Ping Wang, Chandra Bhagavatula, Yejin Choi, and Doug Downey. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2020.findings-emnlp.90" title="" class="ltx_ref ltx_href">Generative
data augmentation for commonsense reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP) - Findings</em>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Seonghyeon Ye, Doyoung Kim, Joel Jang, Joongbo Shin, and Minjoon Seo. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2210.02969" title="" class="ltx_ref ltx_href">Guess the instruction!
making language models stronger zero-shot learners</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.02969</em>.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zelikman et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Eric Zelikman, Jesse Mu, Noah&nbsp;D Goodman, and Yuhuai&nbsp;Tony Wu. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2203.14465" title="" class="ltx_ref ltx_href">STar: Self-taught
reasoner bootstrapping reasoning with reasoning</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems
(NeurIPS)</em>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Xuandong Zhao, Siqi Ouyang, Zhiguo Yu, Ming Wu, and Lei Li. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2212.06950" title="" class="ltx_ref ltx_href">Pre-trained language models
can be fully zero-shot learners</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.06950</em>.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2022a)</span>
<span class="ltx_bibblock">
Chunting Zhou, Junxian He, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham
Neubig. 2022a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2205.00049" title="" class="ltx_ref ltx_href">Prompt Consistency for
Zero-Shot Task Generalization</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language
Processing (EMNLP) - Findings</em>.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2022b)</span>
<span class="ltx_bibblock">
Yongchao Zhou, Andrei&nbsp;Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis,
Harris Chan, and Jimmy Ba. 2022b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://arxiv.org/abs/2211.01910" title="" class="ltx_ref ltx_href">Large language models are
human-level prompt engineers</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.01910</em>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p ltx_align_center"><span id="p1.1.1" class="ltx_text ltx_font_bold">Supplemental Material</span></p>
</div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Implementation Details</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Writing the Seed Tasks</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS1.p1.1">우리의 방법은 세대를 부트스트랩하기 위해 일련의 시드 작업에 의존한다. 시드 과제는 과제 다양성을 장려하고 다양한 과제를 해결하기 위한 올바른 방법을 입증하는 데 중요하다. 예를 들어, 모델을 프롬프트하기 위한 코딩 태스크들의 경우, 코딩 관련 태스크들을 생성할 가능성이 더 크며, 또한 새로운 태스크들에 대한 코드를 작성함에 있어서 모델을 안내하기 위한 코딩 출력을 갖는 것이 더 좋다. 따라서, 시드 태스크가 다양할수록 생성된 태스크는 더 다양하고 더 나은 품질을 가질 것이다.</p>
</div>
<div id="A1.SS1.p2" class="ltx_para">
<p class="ltx_p" id="A1.SS1.p2.1">우리의 종자 작업은 이 프로젝트를 시작할 때 작성되었으며 LLM의 다양하고 흥미로운 사용을 목표로 했다. 작업은 기존 데이터 세트 또는 특정 테스트 작업에 대한 명시적 참조 없이 UWNLP의 저자와 연구원이 작성했다. 우리는 또한 태스크가 제한된 출력 레이블 공간을 갖는지 여부에 따라 태스크를 분류 태스크와 비분류 태스크로 분류했다. 총 25개의 분류 작업과 150개의 비분류 작업이 있습니다. 이 데이터는 GitHub 리포지토리에서 릴리스됩니다. <span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/yizhongw/self-instruct/blob/main/human_eval/user_oriented_instructions.jsonl" target="_blank" title="">https://github.com/yizhongw/self-instruct/blob/main/human_eval/user_oriented_instructions.jsonl</a></span></span></span></p>
</div>
<div id="A1.SS1.p3" class="ltx_para">
<p class="ltx_p" id="A1.SS1.p3.1">모델이 이러한 시드 작업을 넘어 얼마나 일반화되고 있는지에 대한 감각을 제공하기 위해, 우리는 <span class="ltx_text ltx_font_smallcaps" id="A1.SS1.p3.1.1">SuperNI</span> 태스크 명령(§<a class="ltx_ref" href="#S4.SS3" title="4.3 Experiment 1: Zero-Shot Generalization on SuperNI benchmark ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">4.3</span></a>)과 인간 평가(§<a class="ltx_ref" href="#S4.SS4" title="4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">4.4</span></a>)에서 사용자 지향 명령(§<a class="ltx_ref" href="#S4.SS4" title="4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">4.4</span></a>)을 포함하여 이러한 시드 작업의 명령과 테스트 세트의 명령 간의 중첩을 추가로 정량화한다. 우리는 테스트 세트에서 각 시드 명령어와 가장 유사한 명령어들 사이의 ROUGE-L 유사성을 계산한다. ROUGE-L 점수의 분포는 시드 명령어와 <span class="ltx_text ltx_font_smallcaps" id="A1.SS1.p3.1.2">SuperNI</span> 사이의 평균 ROUGE-L 유사도가 0.21이고 시드 명령어와 사용자 지향 명령어의 평균 ROUGE-L 유사도가 0.34인 <a class="ltx_ref ltx_refmacro_autoref" href="#A1.F8" title="Figure 8 ‣ A.1 Writing the Seed Tasks ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Figure 8</span></a>로 표시된다. 시드 태스크와 두 테스트 세트 사이에는 상당한 차이가 있다. 사용자 중심 수업 테스트 세트에서 정확히 하나의 동일한 시드 수업이 발생하는데, 이는 "다음 질문에 답하기"이고 다음 질문은 실제로 매우 다르다.</p>
</div>
<figure id="A1.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A1.F8.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2212.10560/assets/x10.png" id="A1.F8.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="311" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A1.F8.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2212.10560/assets/x11.png" id="A1.F8.2.g1" class="ltx_graphics ltx_img_landscape" width="461" height="310" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 8:</span>Distribution of the ROUGE-L scores between seed instructions and their most similar instructions in <span class="ltx_text ltx_font_smallcaps" id="A1.F8.4.1">SuperNI</span> (left) and the 252 user-oriented instructions (right).</figcaption>
</figure>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Querying the GPT3 API</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS2.p1.1">우리는 다른 목적으로 GPT3 API를 쿼리할 때 다른 하이퍼파라미터 세트를 사용한다. 이러한 하이퍼 매개 변수는 GPT3 모델("davinci" 엔진) 및 기타 명령 조정 <span class="ltx_text ltx_font_smallcaps" id="A1.SS2.p1.1.1">GPT3</span> 변형과 잘 작동 하는 것으로 확인 됩니다. 우리는 그것들을 <a class="ltx_ref ltx_refmacro_autoref" href="#A1.T4" title="Table 4 ‣ A.2 Querying the GPT3 API ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Table 4</span></a>에 나열했다. OpenAI는 2022년 12월 현재 "다빈치" 엔진에 완료 요청을 하는 경우 토큰 1000개당 0.02달러를 청구합니다. 전체 데이터 세트의 생성 비용은 약 600달러입니다.</p>
</div>
<figure id="A1.T4" class="ltx_table">
<table id="A1.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="A1.T4.1.1" class="ltx_tr">
<td id="A1.T4.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Experiments <math id="A1.T4.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="A1.T4.1.1.1.m1.1a"><mo stretchy="false" id="A1.T4.1.1.1.m1.1.1" xref="A1.T4.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="A1.T4.1.1.1.m1.1b"><ci id="A1.T4.1.1.1.m1.1.1.cmml" xref="A1.T4.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T4.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
<td id="A1.T4.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Temp.</td>
<td id="A1.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Top_P</td>
<td id="A1.T4.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Freq. Penalty</td>
<td id="A1.T4.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Presence Penalty</td>
<td id="A1.T4.1.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Beam Size</td>
<td id="A1.T4.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Max Length</td>
<td id="A1.T4.1.1.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" style="padding-left:2.0pt;padding-right:2.0pt;">Stop Sequences</td>
</tr>
<tr id="A1.T4.1.2" class="ltx_tr">
<td id="A1.T4.1.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">Generating instructions</td>
<td id="A1.T4.1.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0.7</td>
<td id="A1.T4.1.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0.5</td>
<td id="A1.T4.1.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">2</td>
<td id="A1.T4.1.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td id="A1.T4.1.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">1024</td>
<td id="A1.T4.1.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="padding-left:2.0pt;padding-right:2.0pt;">"\n\n", "\n16", "16.", "16 ."</td>
</tr>
<tr id="A1.T4.1.3" class="ltx_tr">
<td id="A1.T4.1.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">Identifying clf. tasks</td>
<td id="A1.T4.1.3.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.3.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.3.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.3.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.3.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td id="A1.T4.1.3.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">3</td>
<td id="A1.T4.1.3.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">"\n", "Task:"</td>
</tr>
<tr id="A1.T4.1.4" class="ltx_tr">
<td id="A1.T4.1.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">Generating instances</td>
<td id="A1.T4.1.4.2" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.4.3" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.4.4" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.4.5" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1.5</td>
<td id="A1.T4.1.4.6" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1</td>
<td id="A1.T4.1.4.7" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">300</td>
<td id="A1.T4.1.4.8" class="ltx_td ltx_align_center ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">"Task:"</td>
</tr>
<tr id="A1.T4.1.5" class="ltx_tr">
<td id="A1.T4.1.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_l ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">Evaluating models</td>
<td id="A1.T4.1.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.5.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.5.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">0</td>
<td id="A1.T4.1.5.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">1024</td>
<td id="A1.T4.1.5.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="padding-left:2.0pt;padding-right:2.0pt;">None (default)</td>
</tr>
</tbody></table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 4:</span> 서로 다른 실험에서 OpenAI API를 쿼리하기 위한 Hyper-parameters.</figcaption>
</figure>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Finetuning GPT3</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS3.p1.2"><span class="ltx_text ltx_font_smallcaps" id="A1.SS3.p1.1.1">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="A1.SS3.p1.1.1.m1.1"><semantics id="A1.SS3.p1.1.1.m1.1a"><msub id="A1.SS3.p1.1.1.m1.1.1" xref="A1.SS3.p1.1.1.m1.1.1.cmml"><mi id="A1.SS3.p1.1.1.m1.1.1a" xref="A1.SS3.p1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="A1.SS3.p1.1.1.m1.1.1.1" xref="A1.SS3.p1.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.1.1.m1.1b"><apply id="A1.SS3.p1.1.1.m1.1.1.cmml" xref="A1.SS3.p1.1.1.m1.1.1"><ci id="A1.SS3.p1.1.1.m1.1.1.1a.cmml" xref="A1.SS3.p1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="A1.SS3.p1.1.1.m1.1.1.1.cmml" mathsize="70%" xref="A1.SS3.p1.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> 및 일부 베이스라인은 <span class="ltx_text ltx_font_smallcaps" id="A1.SS3.p1.2.3">GPT3</span> 모델("davinci" engine with 175B parameters). OpenAI의 미세 조정 API를 통해 이 미세 조정을 수행합니다. <span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span> <a class="ltx_ref ltx_href" href="https://beta.openai.com/docs/guides/fine-tuning" target="_blank" title="">See the the details on OpenAI’s API.</a> </span></span></span> 모델이 이 API로 미세 조정되는 방법에 대한 세부 정보는 현재 사용할 수 없지만(예: 어떤 파라미터가 업데이트되는지, 또는 최적기가 무엇인지), 결과가 비슷하도록 이 API의 기본 하이퍼파라미터로 모든 모델을 조정합니다. 우리는 이것이 우리의 경우에 더 잘 작동한다는 것을 발견하기 때문에 "prompt_loss_weight"만을 0으로 설정하고, 모든 미세 조정 실험은 훈련 태스크가 과적합되는 것을 피하기 위해 두 에포크에 대해 훈련된다. 파인튜닝은 학습 파일의 토큰 수에 따라 요금이 부과됩니다. 이 경우 전체 생성 데이터에 대해 <span class="ltx_text ltx_font_smallcaps" id="A1.SS3.p1.2.2">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="A1.SS3.p1.2.2.m1.1"><semantics id="A1.SS3.p1.2.2.m1.1a"><msub id="A1.SS3.p1.2.2.m1.1.1" xref="A1.SS3.p1.2.2.m1.1.1.cmml"><mi id="A1.SS3.p1.2.2.m1.1.1a" xref="A1.SS3.p1.2.2.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="A1.SS3.p1.2.2.m1.1.1.1" xref="A1.SS3.p1.2.2.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.2.2.m1.1b"><apply id="A1.SS3.p1.2.2.m1.1.1.cmml" xref="A1.SS3.p1.2.2.m1.1.1"><ci id="A1.SS3.p1.2.2.m1.1.1.1a.cmml" xref="A1.SS3.p1.2.2.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="A1.SS3.p1.2.2.m1.1.1.1.cmml" mathsize="70%" xref="A1.SS3.p1.2.2.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.2.2.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span> <span class="ltx_text ltx_font_smallcaps" id="A1.SS3.p1.2.4">GPT3</span> 모델에서 $338입니다.</p>
</div>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Prompting Templates for Data Generation</h3>

<div id="A1.SS4.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS4.p1.1"><span class="ltx_text ltx_font_smallcaps" id="A1.SS4.p1.1.1">Self-Instruct</span>은 언어 모델로부터 생성을 이끌어내기 위해 다수의 프롬프트 템플릿에 의존한다. 여기서는 명령어 생성(<a class="ltx_ref ltx_refmacro_autoref" href="#A1.T5" title="Table 5 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Table 5</span></a>), 명령어가 분류 태스크를 나타내는지 여부를 분류하는(<a class="ltx_ref ltx_refmacro_autoref" href="#A1.T6" title="Table 6 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Table 6</span></a>), 입력 우선 접근법으로 비분류 인스턴스를 생성하는(<a class="ltx_ref ltx_refmacro_autoref" href="#A1.T7" title="Table 7 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Table 7</span></a>), 출력 우선 접근법으로 분류 인스턴스를 생성하는(<a class="ltx_ref ltx_refmacro_autoref" href="#A1.T8" title="Table 8 ‣ A.4 Prompting Templates for Data Generation ‣ Appendix A Implementation Details ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Table 8</span></a>) 네 가지 템플릿을 제공한다.</p>
</div>
<figure id="A1.T5" class="ltx_table">
<p id="A1.T5.1" class="ltx_p ltx_align_center">
<span id="A1.T5.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle ltx_framed ltx_framed_rectangle" style="width:232.8pt;">
<span id="A1.T5.1.1.1" class="ltx_p"><span id="A1.T5.1.1.1.1" class="ltx_text ltx_font_typewriter">Come up with a series of tasks:
<br class="ltx_break">
<br class="ltx_break">Task 1: {instruction for existing task 1} 
<br class="ltx_break">Task 2: {instruction for existing task 2} 
<br class="ltx_break">Task 3: {instruction for existing task 3} 
<br class="ltx_break">Task 4: {instruction for existing task 4} 
<br class="ltx_break">Task 5: {instruction for existing task 5} 
<br class="ltx_break">Task 6: {instruction for existing task 6} 
<br class="ltx_break">Task 7: {instruction for existing task 7} 
<br class="ltx_break">Task 8: {instruction for existing task 8} 
<br class="ltx_break">Task 9:</span></span>
</span>
</p>
<br class="ltx_break ltx_break">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 5:</span>새로운 명령어 생성에 사용되는 Prompt. 8개의 기존 명령어는 상황 내 데모를 위해 태스크 풀에서 무작위로 샘플링된다. 모델은 생성을 중지하고 길이 한계에 도달하거나 "작업 16" 토큰을 생성할 때까지 새로운 작업에 대한 명령을 생성할 수 있다.</figcaption>
</figure>
<figure id="A1.T6" class="ltx_table">
<p id="A1.T6.1" class="ltx_p ltx_align_center">
<span id="A1.T6.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle ltx_framed ltx_framed_rectangle" style="width:430.8pt;">
<span id="A1.T6.1.1.1.1" class="ltx_p"><span id="A1.T6.1.1.1.1.1" class="ltx_text ltx_font_typewriter">Can the following task be regarded as a classification task with finite output labels?
<br class="ltx_break">
<br class="ltx_break">Task: Given my personality and the job, tell me if I would be suitable.
<br class="ltx_break">Is it classification? Yes
<br class="ltx_break">
<br class="ltx_break">Task: Give me an example of a time when you had to use your sense of humor.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Replace the placeholders in the given text with appropriate named entities.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Fact checking - tell me if the statement is true, false, or unknown, based on your knowledge and common sense.
<br class="ltx_break">Is it classification? Yes
<br class="ltx_break">
<br class="ltx_break">Task: Return the SSN number for the person.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Detect if the Reddit thread contains hate speech.
<br class="ltx_break">Is it classification? Yes
<br class="ltx_break">
<br class="ltx_break">Task: Analyze the sentences below to identify biases.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Select the longest sentence in terms of the number of words in the paragraph, output the sentence index.
<br class="ltx_break">Is it classification? Yes
<br class="ltx_break">
<br class="ltx_break">Task: Find out the toxic word or phrase in the sentence.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Rank these countries by their population.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: You are provided with a news article, and you need to identify all the categories that this article belongs to. Possible categories include: Music, Sports, Politics, Tech, Finance, Basketball, Soccer, Tennis, Entertainment, Digital Game, World News. Output its categories one by one, seperated by comma.
<br class="ltx_break">Is it classification? Yes
<br class="ltx_break">
<br class="ltx_break">Task: Given the name of an exercise, explain how to do it.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Select the oldest person from the list.
<br class="ltx_break">Is it classification? Yes
<br class="ltx_break">
<br class="ltx_break">Task: Find the four smallest perfect numbers.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Does the information in the document supports the claim? You can answer "Support" or "Unsupport".
<br class="ltx_break">Is it classification? Yes
<br class="ltx_break">
<br class="ltx_break">Task: Create a detailed budget for the given hypothetical trip.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Given a sentence, detect if there is any potential stereotype in it. If so, you should explain the stereotype. Else, output no.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break"><math id="A1.T6.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\cdots" display="inline"><semantics id="A1.T6.1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="A1.T6.1.1.1.1.1.m1.1.1" xref="A1.T6.1.1.1.1.1.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A1.T6.1.1.1.1.1.m1.1b"><ci id="A1.T6.1.1.1.1.1.m1.1.1.cmml" xref="A1.T6.1.1.1.1.1.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.1.1.1.1.1.m1.1c">\cdots</annotation></semantics></math> 
<br class="ltx_break">
<br class="ltx_break">Task: To make the pairs have the same analogy, write the fourth word.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: Given a set of numbers, find all possible subsets that sum to a given number.
<br class="ltx_break">Is it classification? No
<br class="ltx_break">
<br class="ltx_break">Task: {instruction for the target task}</span></span>
</span>
</p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 6:</span>작업 명령어가 분류 작업인지 아닌지를 분류하는 데 사용되는Prompt.</figcaption>
</figure>
<figure id="A1.T7" class="ltx_table">
<p id="A1.T7.1" class="ltx_p ltx_align_center">
<span id="A1.T7.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle ltx_framed ltx_framed_rectangle" style="width:430.8pt;">
<span id="A1.T7.1.1.1.1" class="ltx_p"><span id="A1.T7.1.1.1.1.1" class="ltx_text ltx_font_typewriter">Come up with examples for the following tasks. Try to generate multiple examples when possible. If the task doesn’t require additional input, you can generate the output directly.
<br class="ltx_break">
<br class="ltx_break">Task: Which exercises are best for reducing belly fat at home?
<br class="ltx_break">Output:
<br class="ltx_break">- Lying Leg Raises
<br class="ltx_break">- Leg In And Out
<br class="ltx_break">- Plank
<br class="ltx_break">- Side Plank
<br class="ltx_break">- Sit-ups
<br class="ltx_break">
<br class="ltx_break">Task: Extract all the country names in the paragraph, list them separated by commas.
<br class="ltx_break">Example 1
<br class="ltx_break">Paragraph: Dr. No is the sixth novel by the English author Ian Fleming to feature his British Secret Service agent James Bond. Written at Fleming’s Goldeneye estate in Jamaica, it was first published in the United Kingdom by Jonathan Cape in 1958. In the novel Bond looks into the disappearance in Jamaica of two fellow MI6 operatives who had been investigating Doctor No. Bond travels to No’s Caribbean island and meets Honeychile Rider, who is there to collect shells. They are captured and taken to a luxurious facility carved into a mountain. The character of Doctor No, the son of a German missionary and a Chinese woman, was influenced by Sax Rohmer’s Fu Manchu stories. Dr. No was the first of Fleming’s novels to face widespread negative reviews in Britain, but it was received more favourably in the United States.
<br class="ltx_break">Output: English, British, Jamaica, the United Kingdom, German, Chinese, Britain, the United States.
<br class="ltx_break">
<br class="ltx_break">Task: Converting 85 F to Celsius.
<br class="ltx_break">Output: 85°F = 29.44°C
<br class="ltx_break">
<br class="ltx_break">Task: Sort the given list ascendingly. 
<br class="ltx_break">Example 1
<br class="ltx_break">List: [10, 92, 2, 5, -4, 92, 5, 101]
<br class="ltx_break">Output: [-4, 2, 5, 5, 10, 92, 92, 101]
<br class="ltx_break">Example 2
<br class="ltx_break">Input 2 - List: [9.99, 10, -5, -1000, 5e6, 999]
<br class="ltx_break">Output: [-1000, -5, 9.99, 10, 999, 5e6]
<br class="ltx_break">
<br class="ltx_break">Task: Suggest a better and more professional rephrasing of the following sentence.
<br class="ltx_break">Example 1
<br class="ltx_break">Sentence: This house is surprisingly not constructed very well, and you probably need more money to fix it after you buy it. If you ask me, I would suggest you to consider other candidates.
<br class="ltx_break">Output: This house does not seem to be constructed well, so you may need to spend more money to fix it after you purchase it. I would suggest that you look at other properties.
<br class="ltx_break">Example 2
<br class="ltx_break">Sentence: Just so you know, we did an experiment last week and found really surprising results - language model can improve itself!
<br class="ltx_break">Output: Our experiments last week demonstrated surprising results, proving that the language model can improve itself.
<br class="ltx_break">
<br class="ltx_break"><math id="A1.T7.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\cdots" display="inline"><semantics id="A1.T7.1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="A1.T7.1.1.1.1.1.m1.1.1" xref="A1.T7.1.1.1.1.1.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A1.T7.1.1.1.1.1.m1.1b"><ci id="A1.T7.1.1.1.1.1.m1.1.1.cmml" xref="A1.T7.1.1.1.1.1.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T7.1.1.1.1.1.m1.1c">\cdots</annotation></semantics></math> 
<br class="ltx_break">
<br class="ltx_break">Task: Turn down a job offer by sending an email to a recruiter explaining the reason.
<br class="ltx_break">Output: Hi [Recruiter],
<br class="ltx_break">Thank you so much for the generous offer to join your team. As we discussed, I’ve admired the company for a number of years, and am a proud endorser of its products. However, after further consideration of where I currently am in my career, I’ve decided to accept an offer at another company.
<br class="ltx_break">I would love to stay in touch with you and have already started following you on [Social Media Platform]. Again, thank you so much for your time and consideration.
<br class="ltx_break">Thanks again,
<br class="ltx_break">[Your Name]
<br class="ltx_break">&nbsp;
<br class="ltx_break">Task: {Instruction for the target task}</span></span>
</span>
</p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 7:</span>Prompt used for the input-first approach of instance generation. 모델은 인스턴스를 먼저 생성한 다음 해당 출력을 생성하도록 프롬프트됩니다. 추가 입력이 필요하지 않은 명령의 경우 출력을 직접 생성할 수 있습니다.</figcaption>
</figure>
<figure id="A1.T8" class="ltx_table">
<p id="A1.T8.1" class="ltx_p ltx_align_center">
<span id="A1.T8.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_middle ltx_framed ltx_framed_rectangle" style="width:430.8pt;">
<span id="A1.T8.1.1.1.1" class="ltx_p"><span id="A1.T8.1.1.1.1.1" class="ltx_text ltx_font_typewriter">Given the classification task definition and the class labels, generate an input that corresponds to each of the class labels. If the task doesn’t require input, just generate the correct class label.
<br class="ltx_break">
<br class="ltx_break">Task: Classify the sentiment of the sentence into positive, negative, or mixed.
<br class="ltx_break">Class label: mixed
<br class="ltx_break">Sentence: I enjoy the flavor of the restaurant but their service is too slow.
<br class="ltx_break">Class label: Positive
<br class="ltx_break">Sentence: I had a great day today. The weather was beautiful and I spent time with friends.
<br class="ltx_break">Class label: Negative
<br class="ltx_break">Sentence: I was really disappointed by the latest superhero movie. I would not recommend it.
<br class="ltx_break">
<br class="ltx_break">Task: Given a dialogue, classify whether the user is satisfied with the service. You should respond with "Satisfied" or "Unsatisfied".
<br class="ltx_break">Class label: Satisfied
<br class="ltx_break">Dialogue:
<br class="ltx_break">- Agent: Thank you for your feedback. We will work to improve our service in the future.
<br class="ltx_break">- Customer: I am happy with the service you provided. Thank you for your help.
<br class="ltx_break">Class label: Unsatisfied
<br class="ltx_break">Dialogue:
<br class="ltx_break">- Agent: Sorry that we will cancel your order. You will get a refund within 7 business days.
<br class="ltx_break">- Customer: oh that takes too long. I want you to take quicker action on this.
<br class="ltx_break">
<br class="ltx_break">Task: Given a political opinion, classify whether the speaker is a Democrat or Republican.
<br class="ltx_break">Class label: Democrats
<br class="ltx_break">Opinion: I believe, all should have access to quality healthcare regardless of their income.
<br class="ltx_break">Class label: Republicans
<br class="ltx_break">Opinion: I believe that people should be able to keep more of their hard-earned money and should not be taxed at high rates.
<br class="ltx_break">
<br class="ltx_break">Task: Tell me if the following email is a promotion email or not.
<br class="ltx_break">Class label: Promotion
<br class="ltx_break">Email: Check out our amazing new sale! We’ve got discounts on all of your favorite products.
<br class="ltx_break">Class label: Not Promotion
<br class="ltx_break">Email: We hope you are doing well. Let us know if you need any help.
<br class="ltx_break">
<br class="ltx_break">Task: Detect if the Reddit thread contains hate speech.
<br class="ltx_break">Class label: Hate Speech
<br class="ltx_break">Thread: All people of color are stupid and should not be allowed to vote.
<br class="ltx_break">Class label: Not Hate Speech
<br class="ltx_break">Thread: The best way to cook a steak on the grill.
<br class="ltx_break">
<br class="ltx_break">Task: Does the document supports the claim? Answer with "Support" or "Unsupport".
<br class="ltx_break">Class label: Unsupport
<br class="ltx_break">Document: After a record-breaking run that saw mortgage rates plunge to all-time lows and home prices soar to new highs, the U.S. housing market finally is slowing. While demand and price gains are cooling, any correction is likely to be a modest one, housing economists and analysts say. No one expects price drops on the scale of the declines experienced during the Great Recession.
<br class="ltx_break">Claim: The US housing market is going to crash soon.
<br class="ltx_break">Class label: Support
<br class="ltx_break">Document: The U.S. housing market is showing signs of strain, with home sales and prices slowing in many areas. Mortgage rates have risen sharply in recent months, and the number of homes for sale is increasing. This could be the beginning of a larger downturn, with some economists predicting a potential housing crash in the near future.
<br class="ltx_break">Claim: The US housing market is going to crash soon.
<br class="ltx_break">
<br class="ltx_break"><math id="A1.T8.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\cdots" display="inline"><semantics id="A1.T8.1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="A1.T8.1.1.1.1.1.m1.1.1" xref="A1.T8.1.1.1.1.1.m1.1.1.cmml">⋯</mi><annotation-xml encoding="MathML-Content" id="A1.T8.1.1.1.1.1.m1.1b"><ci id="A1.T8.1.1.1.1.1.m1.1.1.cmml" xref="A1.T8.1.1.1.1.1.m1.1.1">⋯</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T8.1.1.1.1.1.m1.1c">\cdots</annotation></semantics></math> 
<br class="ltx_break">
<br class="ltx_break">Task: Which of the following is not an input type? (a) number (b) date (c) phone number (d) email address (e) all of these are valid inputs.
<br class="ltx_break">Class label: (e)
<br class="ltx_break">
<br class="ltx_break">Task: {instruction for the target task}</span></span>
</span>
</p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8:</span>Prompt used for the output-first approach of instance generation. 클래스 레이블을 먼저 생성한 다음 해당 입력을 생성하도록 모델이 프롬프트됩니다. 이 프롬프트는 분류 작업에 대한 인스턴스를 생성하는 데 사용됩니다.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Human Evaluation Details for Following the User-oriented Instructions</h2>

<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Human Evaluation Setup</h3>

<div id="A2.SS1.p1" class="ltx_para">
<p class="ltx_p" id="A2.SS1.p1.1">여기서는 252개의 사용자 지향 지침에 대한 모델의 응답을 평가하기 위해 §<a class="ltx_ref" href="#S4.SS4" title="4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">4.4</span></a>에 설명된 인간 평가에 대한 자세한 내용을 제공한다. 충실하고 신뢰할 수 있는 평가를 보장하기 위해 이러한 지침(및 본 문서의)의 두 명의 저자에게 모델 예측을 판단하도록 요청했다. 이 두 평가자는 주석을 시작하기 전에 4단계 평가 시스템에 대한 표준을 조정한 다음 각각 모든 인스턴스를 독립적으로 평가했다. 명령어, 인스턴스 입력, 대상 출력(참조) 및 모델 응답이 제시되었다. 모델 응답은 모든 모델 정보가 익명화되어 랜덤 순서로 나열됩니다. <a class="ltx_ref ltx_refmacro_autoref" href="#A2.F9" title="Figure 9 ‣ B.1 Human Evaluation Setup ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">Figure 9</span></a>는 주석 인터페이스의 스크린샷을 제공한다. 본 논문에서 보고된 성과는 평가자 중 한 명의 결과를 기반으로 하며, 다른 평가자의 결과로부터의 경향은 동일하다.</p>
</div>
<figure id="A2.F9" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2212.10560/assets/figures/human_eval_screenshot.png" id="A2.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="410" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9:</span>Human evaluation in done using a Google sheet, the predictions from different models exists and the model information is anonymized. 전문가 평가자는 명령 및 입력을 읽고 대상을 참조한 다음 §<a class="ltx_ref" href="#S4.SS4" title="4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">4.4</span></a>에 설명된 4개 수준에 해당하는 A/B/C/D에서 모델의 응답에 대한 등급을 선택해야 한다.</figcaption>
</figure>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Human Evaluation Agreement</h3>

<div id="A2.SS2.p1" class="ltx_para">
<p class="ltx_p" id="A2.SS2.p1.1">우리의 인간 평가가 얼마나 신뢰할 수 있는지 측정하기 위해 우리는 두 평가자 간의 내부 평가자 일치를 계산한다.</p>
</div>
<div id="A2.SS2.p2" class="ltx_para">
<p class="ltx_p" id="A2.SS2.p2.3">먼저 <span class="ltx_text ltx_font_italic" id="A2.SS2.p2.3.1">categorical</span> 항목에 대한 평가자 간 일치도를 측정하는 데 일반적으로 사용되는 Cohen의 <math alttext="\kappa" class="ltx_Math" display="inline" id="A2.SS2.p2.1.m1.1"><semantics id="A2.SS2.p2.1.m1.1a"><mi id="A2.SS2.p2.1.m1.1.1" xref="A2.SS2.p2.1.m1.1.1.cmml">κ</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p2.1.m1.1b"><ci id="A2.SS2.p2.1.m1.1.1.cmml" xref="A2.SS2.p2.1.m1.1.1">𝜅</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p2.1.m1.1c">\kappa</annotation></semantics></math>를 보고한다. 이를 계산할 때 4수준 평점(A-D)을 범주형 변수로 취급하여 <math alttext="\kappa" class="ltx_Math" display="inline" id="A2.SS2.p2.2.m2.1"><semantics id="A2.SS2.p2.2.m2.1a"><mi id="A2.SS2.p2.2.m2.1.1" xref="A2.SS2.p2.2.m2.1.1.cmml">κ</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p2.2.m2.1b"><ci id="A2.SS2.p2.2.m2.1.1.cmml" xref="A2.SS2.p2.2.m2.1.1">𝜅</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p2.2.m2.1c">\kappa</annotation></semantics></math>가 0.58로 나타나 일반적인 관행에 따라 중간 정도의 일치도를 보인다. <span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://en.wikipedia.org/wiki/Cohen%27s_kappa" target="_blank" title="">https://en.wikipedia.org/wiki/Cohen%27s_kappa</a></span></span></span> 또한, 수용 가능한 응답((A 또는 B) vs. (C 또는 D)), 최종 <math alttext="\kappa" class="ltx_Math" display="inline" id="A2.SS2.p2.3.m3.1"><semantics id="A2.SS2.p2.3.m3.1a"><mi id="A2.SS2.p2.3.m3.1.1" xref="A2.SS2.p2.3.m3.1.1.cmml">κ</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p2.3.m3.1b"><ci id="A2.SS2.p2.3.m3.1.1.cmml" xref="A2.SS2.p2.3.m3.1.1">𝜅</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p2.3.m3.1c">\kappa</annotation></semantics></math>가 0.75로, 실질적인 일치를 나타낸다.</p>
</div>
<div id="A2.SS2.p3" class="ltx_para">
<p class="ltx_p" id="A2.SS2.p3.2">또한 평점을 순서형 변수(A>B>C>D)로 처리하여 두 평가자의 평점 간의 Spearman 상관계수 <math alttext="\rho" class="ltx_Math" display="inline" id="A2.SS2.p3.1.m1.1"><semantics id="A2.SS2.p3.1.m1.1a"><mi id="A2.SS2.p3.1.m1.1.1" xref="A2.SS2.p3.1.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="A2.SS2.p3.1.m1.1b"><ci id="A2.SS2.p3.1.m1.1.1.cmml" xref="A2.SS2.p3.1.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p3.1.m1.1c">\rho</annotation></semantics></math>를 계산한다. 최종 계수는 <math alttext="\rho=0.81" class="ltx_Math" display="inline" id="A2.SS2.p3.2.m2.1"><semantics id="A2.SS2.p3.2.m2.1a"><mrow id="A2.SS2.p3.2.m2.1.1" xref="A2.SS2.p3.2.m2.1.1.cmml"><mi id="A2.SS2.p3.2.m2.1.1.2" xref="A2.SS2.p3.2.m2.1.1.2.cmml">ρ</mi><mo id="A2.SS2.p3.2.m2.1.1.1" xref="A2.SS2.p3.2.m2.1.1.1.cmml">=</mo><mn id="A2.SS2.p3.2.m2.1.1.3" xref="A2.SS2.p3.2.m2.1.1.3.cmml">0.81</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS2.p3.2.m2.1b"><apply id="A2.SS2.p3.2.m2.1.1.cmml" xref="A2.SS2.p3.2.m2.1.1"><eq id="A2.SS2.p3.2.m2.1.1.1.cmml" xref="A2.SS2.p3.2.m2.1.1.1"></eq><ci id="A2.SS2.p3.2.m2.1.1.2.cmml" xref="A2.SS2.p3.2.m2.1.1.2">𝜌</ci><cn id="A2.SS2.p3.2.m2.1.1.3.cmml" type="float" xref="A2.SS2.p3.2.m2.1.1.3">0.81</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p3.2.m2.1c">\rho=0.81</annotation></semantics></math>로 두 평가자 간의 높은 상관 관계를 나타낸다.</p>
</div>
</section>
<section id="A2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.3 </span>Example Predictions from <span id="A2.SS3.1.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="A2.SS3.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="A2.SS3.1.1.m1.1b"><msub id="A2.SS3.1.1.m1.1.1" xref="A2.SS3.1.1.m1.1.1.cmml"><mi id="A2.SS3.1.1.m1.1.1b" xref="A2.SS3.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="A2.SS3.1.1.m1.1.1.1" xref="A2.SS3.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.SS3.1.1.m1.1c"><apply id="A2.SS3.1.1.m1.1.1.cmml" xref="A2.SS3.1.1.m1.1.1"><ci id="A2.SS3.1.1.m1.1.1.1a.cmml" xref="A2.SS3.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="A2.SS3.1.1.m1.1.1.1.cmml" xref="A2.SS3.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.1.1.m1.1d">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>
</h3>

<div id="A2.SS3.p1" class="ltx_para">
<p class="ltx_p" id="A2.SS3.p1.1">사용자 지향 작업, 해당 <span class="ltx_text ltx_font_smallcaps" id="A2.SS3.p1.1.1">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="A2.SS3.p1.1.1.m1.1"><semantics id="A2.SS3.p1.1.1.m1.1a"><msub id="A2.SS3.p1.1.1.m1.1.1" xref="A2.SS3.p1.1.1.m1.1.1.cmml"><mi id="A2.SS3.p1.1.1.m1.1.1a" xref="A2.SS3.p1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="A2.SS3.p1.1.1.m1.1.1.1" xref="A2.SS3.p1.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.SS3.p1.1.1.m1.1b"><apply id="A2.SS3.p1.1.1.m1.1.1.cmml" xref="A2.SS3.p1.1.1.m1.1.1"><ci id="A2.SS3.p1.1.1.m1.1.1.1a.cmml" xref="A2.SS3.p1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="A2.SS3.p1.1.1.m1.1.1.1.cmml" mathsize="70%" xref="A2.SS3.p1.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.p1.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>-produced responses and annotator rating in <a class="ltx_ref ltx_refmacro_autoref" href="#A2.SS3" title='B.3 Example Predictions from GPT3_"Self-Inst" ‣ Appendix B Human Evaluation Details for Following the User-oriented Instructions ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions'><span class="ltx_text ltx_ref_tag">subsection B.3</span></a>. 우리는 레벨 C로 평가된 응답의 경우에도 모델이 최종 출력이 잘못되었음에도 불구하고 과제 해결의 광범위한 단계를 보여준다.</p>
</div>
<figure id="A2.SS3.8" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="A2.SS3.6.5" class="ltx_inline-block ltx_figure_panel ltx_transformed_outer" style="width:429.3pt;height:820.9pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-34.1pt,65.2pt) scale(0.862809144010476,0.862809144010476) ;">
<table id="A2.SS3.6.5.5" class="ltx_tabular ltx_align_middle">
<tbody><tr id="A2.SS3.2.1.1.1" class="ltx_tr">
<td id="A2.SS3.2.1.1.1.2" class="ltx_td ltx_nopad_l ltx_align_center ltx_align_top ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.2.1.1.1.2.1" class="ltx_text ltx_font_bold">Instruction + Instance Input</span></td>
<td id="A2.SS3.2.1.1.1.3" class="ltx_td ltx_nopad_l ltx_align_center ltx_align_top ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.2.1.1.1.3.1" class="ltx_text ltx_font_bold">Target Response</span></td>
<td id="A2.SS3.2.1.1.1.1" class="ltx_td ltx_nopad_l ltx_align_center ltx_align_top ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.2.1.1.1.1.1" class="ltx_text ltx_font_bold ltx_font_smallcaps">GPT3<math id="A2.SS3.2.1.1.1.1.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="A2.SS3.2.1.1.1.1.1.m1.1a"><msub id="A2.SS3.2.1.1.1.1.1.m1.1.1" xref="A2.SS3.2.1.1.1.1.1.m1.1.1.cmml"><mi id="A2.SS3.2.1.1.1.1.1.m1.1.1a" xref="A2.SS3.2.1.1.1.1.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="A2.SS3.2.1.1.1.1.1.m1.1.1.1" xref="A2.SS3.2.1.1.1.1.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.SS3.2.1.1.1.1.1.m1.1b"><apply id="A2.SS3.2.1.1.1.1.1.m1.1.1.cmml" xref="A2.SS3.2.1.1.1.1.1.m1.1.1"><ci id="A2.SS3.2.1.1.1.1.1.m1.1.1.1a.cmml" xref="A2.SS3.2.1.1.1.1.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="A2.SS3.2.1.1.1.1.1.m1.1.1.1.cmml" xref="A2.SS3.2.1.1.1.1.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.2.1.1.1.1.1.m1.1c">{}_{\textsc{Self-Inst}}</annotation></semantics></math><span id="A2.SS3.2.1.1.1.1.1.1" class="ltx_text ltx_font_upright"> Response</span></span></td>
<td id="A2.SS3.2.1.1.1.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_tt" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.2.1.1.1.4.1" class="ltx_text ltx_font_bold">Rating</span></td>
</tr>
<tr id="A2.SS3.6.5.5.6" class="ltx_tr">
<td id="A2.SS3.6.5.5.6.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.6.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.6.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.6.1.1.1.2" class="ltx_text ltx_font_typewriter"> Give students tips on how to keep their nerves under control during class presentations.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.6.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.6.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.6.2.1.1.1" class="ltx_text ltx_font_typewriter">Everyone gets a little nervous when speaking in front of a group. That’s normal. But the more preparation you’ve done—meaning plenty of researching, organizing, and rehearsing—the more confident you’ll be. Preparation is the key. And if you make a mistake or stumble over your words, just regroup and keep going. Nobody’s perfect, and nobody expects you to be.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.6.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.6.3.1.1" class="ltx_p" style="width:138.8pt;">

<span id="A2.I1" class="ltx_itemize">
<span id="A2.I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I1.i1.p1" class="ltx_para">
<span id="A2.I1.i1.p1.1" class="ltx_p"><span id="A2.I1.i1.p1.1.1" class="ltx_text ltx_font_typewriter">Practice your presentation in front of friends and family.</span></span>
</span></span>
<span id="A2.I1.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I1.i2.p1" class="ltx_para">
<span id="A2.I1.i2.p1.1" class="ltx_p"><span id="A2.I1.i2.p1.1.1" class="ltx_text ltx_font_typewriter">Don’t drink too much caffeine before the presentation.</span></span>
</span></span>
<span id="A2.I1.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I1.i3.p1" class="ltx_para">
<span id="A2.I1.i3.p1.1" class="ltx_p"><span id="A2.I1.i3.p1.1.1" class="ltx_text ltx_font_typewriter">Take deep breaths before you start speaking.</span></span>
</span></span>
<span id="A2.I1.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I1.i4.p1" class="ltx_para">
<span id="A2.I1.i4.p1.1" class="ltx_p"><span id="A2.I1.i4.p1.1.1" class="ltx_text ltx_font_typewriter">If you feel nervous, smile.</span></span>
</span></span>
<span id="A2.I1.i5" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I1.i5.p1" class="ltx_para">
<span id="A2.I1.i5.p1.1" class="ltx_p"><span id="A2.I1.i5.p1.1.1" class="ltx_text ltx_font_typewriter">Remember that everyone in the audience is rooting for you.</span></span>
</span></span>
</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.6.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.6.4.1" class="ltx_text ltx_font_typewriter">A</span></td>
</tr>
<tr id="A2.SS3.6.5.5.7" class="ltx_tr">
<td id="A2.SS3.6.5.5.7.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.7.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.7.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.7.1.1.1.2" class="ltx_text ltx_font_typewriter"> Make a list of the pros and cons of the given decision.

<br class="ltx_break"><span id="A2.SS3.6.5.5.7.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span> Implementing a Remote Working Policy</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.7.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.7.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.7.2.1.1.1" class="ltx_text ltx_font_typewriter">Pros: 
<span id="A2.I2" class="ltx_itemize">
<span id="A2.I2.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I2.i1.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I2.i1.p1" class="ltx_para">
<span id="A2.I2.i1.p1.1" class="ltx_p">Allowing employees to work from home can reduce their stressful commutes and increase their productivity.</span>
</span></span>
<span id="A2.I2.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I2.i2.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I2.i2.p1" class="ltx_para">
<span id="A2.I2.i2.p1.1" class="ltx_p">Remote working provides greater flexibility, particularly for working parents and caregivers who have other responsibilities.
</span>
</span></span>
<span id="A2.I2.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I2.i3.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I2.i3.p1" class="ltx_para">
<span id="A2.I2.i3.p1.1" class="ltx_p">…(more points)</span>
</span></span>
</span></span></span>
<span id="A2.SS3.6.5.5.7.2.1.2" class="ltx_p"><span id="A2.SS3.6.5.5.7.2.1.2.1" class="ltx_text ltx_font_typewriter">Cons:</span></span>
<span id="A2.I3" class="ltx_itemize">
<span id="A2.I3.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I3.i1.p1" class="ltx_para">
<span id="A2.I3.i1.p1.1" class="ltx_p"><span id="A2.I3.i1.p1.1.1" class="ltx_text ltx_font_typewriter">It may be more difficult for team members to build meaningful, productive, creative relationships with one another.</span></span>
</span></span>
<span id="A2.I3.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I3.i2.p1" class="ltx_para">
<span id="A2.I3.i2.p1.1" class="ltx_p"><span id="A2.I3.i2.p1.1.1" class="ltx_text ltx_font_typewriter">…(more points)</span></span>
</span></span>
</span>
</span>
</td>
<td id="A2.SS3.6.5.5.7.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.7.3.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.7.3.1.1.1" class="ltx_text ltx_font_typewriter">Pros:

<span id="A2.I4" class="ltx_itemize">
<span id="A2.I4.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I4.i1.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I4.i1.p1" class="ltx_para">
<span id="A2.I4.i1.p1.1" class="ltx_p">Employees can work from home and save on commuting costs.</span>
</span></span>
<span id="A2.I4.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I4.i2.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I4.i2.p1" class="ltx_para">
<span id="A2.I4.i2.p1.1" class="ltx_p">Employees can spend more time with their families.</span>
</span></span>
</span>
Cons:

<span id="A2.I5" class="ltx_itemize">
<span id="A2.I5.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I5.i1.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I5.i1.p1" class="ltx_para">
<span id="A2.I5.i1.p1.1" class="ltx_p">Employees may not be as productive as they would be in the office.</span>
</span></span>
<span id="A2.I5.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I5.i2.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I5.i2.p1" class="ltx_para">
<span id="A2.I5.i2.p1.1" class="ltx_p">Employees may not be as motivated to work.</span>
</span></span>
</span></span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.7.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.7.4.1" class="ltx_text ltx_font_typewriter">A</span></td>
</tr>
<tr id="A2.SS3.6.5.5.8" class="ltx_tr">
<td id="A2.SS3.6.5.5.8.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.8.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.8.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.8.1.1.1.2" class="ltx_text ltx_font_typewriter"> A user story is an informal, general explanation of a software feature written from the perspective of the end-user or customer. Write a user story for a given software. 
<br class="ltx_break"><span id="A2.SS3.6.5.5.8.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span> Gmail</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.8.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.8.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.8.2.1.1.1" class="ltx_text ltx_font_typewriter">As a user, I want to be able to recover the password to my account, so that I will be able to access my account in case I forgot the password.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.8.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.8.3.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.8.3.1.1.1" class="ltx_text ltx_font_typewriter">As a user, I want to be able to send emails to my friends and family. I want to be able to attach files to my emails. I want to be able to search for emails in my inbox.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.8.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.8.4.1" class="ltx_text ltx_font_typewriter">A</span></td>
</tr>
<tr id="A2.SS3.4.3.3.3" class="ltx_tr">
<td id="A2.SS3.4.3.3.3.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.4.3.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.4.3.3.3.3.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.4.3.3.3.3.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.4.3.3.3.3.1.1.2" class="ltx_text ltx_font_typewriter"> A color description has been provided. Find the CSS code associated with that color.

<br class="ltx_break"><span id="A2.SS3.4.3.3.3.3.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span> A light red color with a medium light shade of pink</span></span>
</span>
</td>
<td id="A2.SS3.3.2.2.2.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.3.2.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.3.2.2.2.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.3.2.2.2.1.1.1.1" class="ltx_text ltx_font_typewriter">#DB7093 (<math id="A2.SS3.3.2.2.2.1.1.1.1.m1.1" class="ltx_Math" alttext="{\color[rgb]{0.859375,0.4375,0.578125}\definecolor[named]{pgfstrokecolor}{rgb}{0.859375,0.4375,0.578125}\lgblksquare}" display="inline"><semantics id="A2.SS3.3.2.2.2.1.1.1.1.m1.1a"><merror class="ltx_ERROR undefined undefined" id="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1" xref="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1b.cmml"><mtext id="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1a" xref="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1b.cmml">\lgblksquare</mtext></merror><annotation-xml encoding="MathML-Content" id="A2.SS3.3.2.2.2.1.1.1.1.m1.1b"><ci id="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1b.cmml" xref="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1"><merror class="ltx_ERROR undefined undefined" id="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1.cmml" xref="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1"><mtext id="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1a.cmml" xref="A2.SS3.3.2.2.2.1.1.1.1.m1.1.1">\lgblksquare</mtext></merror></ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.3.2.2.2.1.1.1.1.m1.1c">{\color[rgb]{0.859375,0.4375,0.578125}\definecolor[named]{pgfstrokecolor}{rgb}{0.859375,0.4375,0.578125}\lgblksquare}</annotation></semantics></math>)</span></span>
</span>
</td>
<td id="A2.SS3.4.3.3.3.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.4.3.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.4.3.3.3.2.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.4.3.3.3.2.1.1.1" class="ltx_text ltx_font_typewriter">&nbsp;#ff66cc (<math id="A2.SS3.4.3.3.3.2.1.1.1.m1.1" class="ltx_Math" alttext="{\color[rgb]{1,0.3984375,0.80078125}\definecolor[named]{pgfstrokecolor}{rgb}{1,0.3984375,0.80078125}\lgblksquare}" display="inline"><semantics id="A2.SS3.4.3.3.3.2.1.1.1.m1.1a"><merror class="ltx_ERROR undefined undefined" id="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1" xref="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1b.cmml"><mtext id="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1a" xref="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1b.cmml">\lgblksquare</mtext></merror><annotation-xml encoding="MathML-Content" id="A2.SS3.4.3.3.3.2.1.1.1.m1.1b"><ci id="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1b.cmml" xref="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1"><merror class="ltx_ERROR undefined undefined" id="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1.cmml" xref="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1"><mtext id="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1a.cmml" xref="A2.SS3.4.3.3.3.2.1.1.1.m1.1.1">\lgblksquare</mtext></merror></ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.4.3.3.3.2.1.1.1.m1.1c">{\color[rgb]{1,0.3984375,0.80078125}\definecolor[named]{pgfstrokecolor}{rgb}{1,0.3984375,0.80078125}\lgblksquare}</annotation></semantics></math>)</span></span>
</span>
</td>
<td id="A2.SS3.4.3.3.3.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.4.3.3.3.4.1" class="ltx_text ltx_font_typewriter">B</span></td>
</tr>
<tr id="A2.SS3.6.5.5.9" class="ltx_tr">
<td id="A2.SS3.6.5.5.9.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.9.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.9.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.9.1.1.1.2" class="ltx_text ltx_font_typewriter"> Someone gives you some information about where they want to go and what they enjoy seeing and doing. Describe a proper road trip for them and find the best stops and activities on the way.

<br class="ltx_break"><span id="A2.SS3.6.5.5.9.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span> I’m looking for a west coast road trip. My goal is to start near San Diego and travel to Los Angeles.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.9.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.9.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.9.2.1.1.1" class="ltx_text ltx_font_typewriter">Begin near the city of San Diego and make the first stop in coastal La Jolla. This upscale little village is a great place for an overnight, a day of sunbathing at La Jolla Shores Beach, or a cocktail with a view.
Just 20 minutes north, stop into beachy Encinitas to window shop the boutiques or sample fish tacos. Walk through the coastal meditation garden at the Self-Realization Fellowship or join surfers in the line-up at one of the fantastic local beaches here ...(more ideas)</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.9.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.9.3.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.9.3.1.1.1" class="ltx_text ltx_font_typewriter">You should start your trip in San Diego, California. You can visit the San Diego Zoo, which is one of the best zoos in the world. Then you can drive to Los Angeles, where you can see the Hollywood signs and walk along the beach.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.9.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.9.4.1" class="ltx_text ltx_font_typewriter">B</span></td>
</tr>
<tr id="A2.SS3.6.5.5.10" class="ltx_tr">
<td id="A2.SS3.6.5.5.10.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.10.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.10.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.10.1.1.1.2" class="ltx_text ltx_font_typewriter"> Give some examples of what people usually say in the given social situation.

<br class="ltx_break"><span id="A2.SS3.6.5.5.10.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span> when someone arrives safely</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.10.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.10.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.10.2.1.1.1" class="ltx_text ltx_font_typewriter">

<span id="A2.I6" class="ltx_itemize">
<span id="A2.I6.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I6.i1.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I6.i1.p1" class="ltx_para">
<span id="A2.I6.i1.p1.1" class="ltx_p">‘‘Glad you made it safe and sound.’’</span>
</span></span>
<span id="A2.I6.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I6.i2.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I6.i2.p1" class="ltx_para">
<span id="A2.I6.i2.p1.1" class="ltx_p">‘‘Good to see you got here unscathed.’’</span>
</span></span>
<span id="A2.I6.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item"><span id="A2.I6.i3.1.1.1" class="ltx_text ltx_font_serif">–</span></span> 
<span id="A2.I6.i3.p1" class="ltx_para">
<span id="A2.I6.i3.p1.1" class="ltx_p">‘‘So, bulletproof vests actually work!’’</span>
</span></span>
</span></span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.10.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.10.3.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.10.3.1.1.1" class="ltx_text ltx_font_typewriter">Thank God, I made it.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.10.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.10.4.1" class="ltx_text ltx_font_typewriter">B</span></td>
</tr>
<tr id="A2.SS3.6.5.5.5" class="ltx_tr">
<td id="A2.SS3.6.5.5.5.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.5.2.2" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.5.2.2.2" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.5.2.2.2.3" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.5.2.2.2.2" class="ltx_text ltx_font_typewriter"> You are given a sentence in first-order logic. Translate it into natural language.

<br class="ltx_break"><span id="A2.SS3.6.5.5.5.2.2.2.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
<math id="A2.SS3.5.4.4.4.1.1.1.1.m1.1" class="ltx_math_unparsed" alttext="\exists x\forall y(soldier(x)" display="inline"><semantics id="A2.SS3.5.4.4.4.1.1.1.1.m1.1a"><mrow id="A2.SS3.5.4.4.4.1.1.1.1.m1.1b"><mo rspace="0.167em" id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.2">∃</mo><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.3">x</mi><mo lspace="0.167em" rspace="0.167em" id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.4">∀</mo><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.5">y</mi><mrow id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6"><mo stretchy="false" id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.1">(</mo><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.2">s</mi><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.3">o</mi><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.4">l</mi><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.5">d</mi><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.6">i</mi><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.7">e</mi><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.8">r</mi><mrow id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.9"><mo stretchy="false" id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.9.1">(</mo><mi id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.1">x</mi><mo stretchy="false" id="A2.SS3.5.4.4.4.1.1.1.1.m1.1.6.9.2">)</mo></mrow></mrow></mrow><annotation encoding="application/x-tex" id="A2.SS3.5.4.4.4.1.1.1.1.m1.1c">\exists x\forall y(soldier(x)</annotation></semantics></math>
<math id="A2.SS3.6.5.5.5.2.2.2.2.m2.2" class="ltx_math_unparsed" alttext="\to general(x,y))" display="inline"><semantics id="A2.SS3.6.5.5.5.2.2.2.2.m2.2a"><mrow id="A2.SS3.6.5.5.5.2.2.2.2.m2.2b"><mo stretchy="false" id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.3">→</mo><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.4">g</mi><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.5">e</mi><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.6">n</mi><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.7">e</mi><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.8">r</mi><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.9">a</mi><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.10">l</mi><mrow id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.11"><mo stretchy="false" id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.11.1">(</mo><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.1.1">x</mi><mo id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.11.2">,</mo><mi id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.2">y</mi><mo stretchy="false" id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.11.3">)</mo></mrow><mo stretchy="false" id="A2.SS3.6.5.5.5.2.2.2.2.m2.2.12">)</mo></mrow><annotation encoding="application/x-tex" id="A2.SS3.6.5.5.5.2.2.2.2.m2.2c">\to general(x,y))</annotation></semantics></math></span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.5.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.5.3.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.5.3.1.1.1" class="ltx_text ltx_font_typewriter">There is someone (x) such that if he is a soldier, then he is general of everyone.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.5.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.5.4.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.5.4.1.1.1" class="ltx_text ltx_font_typewriter">There exists a soldier such that for every general, he is a general.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.5.5" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.5.5.1" class="ltx_text ltx_font_typewriter">C</span></td>
</tr>
<tr id="A2.SS3.6.5.5.11" class="ltx_tr">
<td id="A2.SS3.6.5.5.11.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.11.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.11.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.11.1.1.1.2" class="ltx_text ltx_font_typewriter"> Make a questionnaire to help hotel guests write hotel reviews.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.11.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.11.2.1.1" class="ltx_p" style="width:173.4pt;">
<span id="A2.I7" class="ltx_itemize">
<span id="A2.I7.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I7.i1.p1" class="ltx_para">
<span id="A2.I7.i1.p1.1" class="ltx_p"><span id="A2.I7.i1.p1.1.1" class="ltx_text ltx_font_typewriter">Your overall rating of this hotel:</span></span>
</span></span>
<span id="A2.I7.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I7.i2.p1" class="ltx_para">
<span id="A2.I7.i2.p1.1" class="ltx_p"><span id="A2.I7.i2.p1.1.1" class="ltx_text ltx_font_typewriter">Summarize your visit or highlight an interesting detail:</span></span>
</span></span>
<span id="A2.I7.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I7.i3.p1" class="ltx_para">
<span id="A2.I7.i3.p1.1" class="ltx_p"><span id="A2.I7.i3.p1.1.1" class="ltx_text ltx_font_typewriter">...(more questions)</span></span>
</span></span>
</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.11.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.11.3.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.11.3.1.1.1" class="ltx_text ltx_font_typewriter">Question: How would you rate the service at the front desk? 
<br class="ltx_break">Answer: Excellent, Good, Average, Poor</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.11.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.11.4.1" class="ltx_text ltx_font_typewriter">C</span></td>
</tr>
<tr id="A2.SS3.6.5.5.12" class="ltx_tr">
<td id="A2.SS3.6.5.5.12.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.12.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.12.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.12.1.1.1.2" class="ltx_text ltx_font_typewriter">
Design an outline for a blog post based on the given information and list the sections accordingly.

<br class="ltx_break"><span id="A2.SS3.6.5.5.12.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
This blog post is going to about making a list of last-minute gift ideas. Also, the tone of the post is going to be relaxed and casual.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.12.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.12.2.1.1" class="ltx_p" style="width:173.4pt;">
<span id="A2.I8" class="ltx_itemize">
<span id="A2.I8.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I8.i1.p1" class="ltx_para">
<span id="A2.I8.i1.p1.1" class="ltx_p"><span id="A2.I8.i1.p1.1.1" class="ltx_text ltx_font_typewriter">Section: Movie tickets</span></span>
</span></span>
<span id="A2.I8.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I8.i2.p1" class="ltx_para">
<span id="A2.I8.i2.p1.1" class="ltx_p"><span id="A2.I8.i2.p1.1.1" class="ltx_text ltx_font_typewriter">Section: A fun game console
</span></span>
</span></span>
<span id="A2.I8.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I8.i3.p1" class="ltx_para">
<span id="A2.I8.i3.p1.1" class="ltx_p"><span id="A2.I8.i3.p1.1.1" class="ltx_text ltx_font_typewriter">Section: Personalized items with photos/artwork</span></span>
</span></span>
<span id="A2.I8.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I8.i4.p1" class="ltx_para">
<span id="A2.I8.i4.p1.1" class="ltx_p"><span id="A2.I8.i4.p1.1.1" class="ltx_text ltx_font_typewriter">...(more sections)</span></span>
</span></span>
<span id="A2.I8.i5" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I8.i5.p1" class="ltx_para">
<span id="A2.I8.i5.p1.1" class="ltx_p"><span id="A2.I8.i5.p1.1.1" class="ltx_text ltx_font_typewriter">Takeaway: Don’t stress about out running out of time to buy, make a gift.</span></span>
</span></span>
</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.12.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.12.3.1.1" class="ltx_p" style="width:138.8pt;">
<span id="A2.I9" class="ltx_itemize">
<span id="A2.I9.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I9.i1.p1" class="ltx_para">
<span id="A2.I9.i1.p1.1" class="ltx_p"><span id="A2.I9.i1.p1.1.1" class="ltx_text ltx_font_typewriter">Introduction</span></span>
</span></span>
<span id="A2.I9.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I9.i2.p1" class="ltx_para">
<span id="A2.I9.i2.p1.1" class="ltx_p"><span id="A2.I9.i2.p1.1.1" class="ltx_text ltx_font_typewriter">List of Gift Ideas</span></span>
</span></span>
<span id="A2.I9.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A2.I9.i3.p1" class="ltx_para">
<span id="A2.I9.i3.p1.1" class="ltx_p"><span id="A2.I9.i3.p1.1.1" class="ltx_text ltx_font_typewriter">Conclusion</span></span>
</span></span>
</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.12.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.12.4.1" class="ltx_text ltx_font_typewriter">C</span></td>
</tr>
<tr id="A2.SS3.6.5.5.13" class="ltx_tr">
<td id="A2.SS3.6.5.5.13.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.13.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.13.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.13.1.1.1.2" class="ltx_text ltx_font_typewriter">
Write a Jira ticket for the given task.

<br class="ltx_break"><span id="A2.SS3.6.5.5.13.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
New Employee onboarding</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.13.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.13.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.13.2.1.1.1" class="ltx_text ltx_font_typewriter">Title: Please help our new employee get settled.
Prepare a desk, chair, and computer for them to use.
Create their company account, email, and temporary password.
Grant access to company documents.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.13.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.13.3.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.13.3.1.1.1" class="ltx_text ltx_font_typewriter">Hi [Manager],
I’m writing to you because I have a question about the new employee onboarding process. I’ve been working here for a few months now, and I’m still not sure how it works. Could you please explain it to me?</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.13.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.13.4.1" class="ltx_text ltx_font_typewriter">D</span></td>
</tr>
<tr id="A2.SS3.6.5.5.14" class="ltx_tr">
<td id="A2.SS3.6.5.5.14.1" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.14.1.1.1" class="ltx_p" style="width:134.4pt;"><span id="A2.SS3.6.5.5.14.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A2.SS3.6.5.5.14.1.1.1.2" class="ltx_text ltx_font_typewriter">
Create alliterations by finding synonyms for words in the given sentence.

<br class="ltx_break"><span id="A2.SS3.6.5.5.14.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
David wears a hat everyday.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.14.2" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.14.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="A2.SS3.6.5.5.14.2.1.1.1" class="ltx_text ltx_font_typewriter">David dons a derby daily.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.14.3" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;">
<span id="A2.SS3.6.5.5.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="A2.SS3.6.5.5.14.3.1.1" class="ltx_p" style="width:138.8pt;"><span id="A2.SS3.6.5.5.14.3.1.1.1" class="ltx_text ltx_font_typewriter">David wears a hat every day.</span></span>
</span>
</td>
<td id="A2.SS3.6.5.5.14.4" class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" style="padding-left:1.0pt;padding-right:1.0pt;"><span id="A2.SS3.6.5.5.14.4.1" class="ltx_text ltx_font_typewriter">D</span></td>
</tr>
</tbody></table>
</span></div>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 9:</span>Example in the user-oriented instructions dataset (§<a class="ltx_ref" href="#S4.SS4" title="4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">4.4</span></a>) and predictions from <span class="ltx_text ltx_font_smallcaps" id="A2.SS3.8.7.1">GPT3<math alttext="{}_{\textsc{Self-Inst}}" class="ltx_Math" display="inline" id="A2.SS3.8.7.1.m1.1"><semantics id="A2.SS3.8.7.1.m1.1b"><msub id="A2.SS3.8.7.1.m1.1.1" xref="A2.SS3.8.7.1.m1.1.1.cmml"><mi id="A2.SS3.8.7.1.m1.1.1b" xref="A2.SS3.8.7.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="A2.SS3.8.7.1.m1.1.1.1" xref="A2.SS3.8.7.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.SS3.8.7.1.m1.1c"><apply id="A2.SS3.8.7.1.m1.1.1.cmml" xref="A2.SS3.8.7.1.m1.1.1"><ci id="A2.SS3.8.7.1.m1.1.1.1a.cmml" xref="A2.SS3.8.7.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" id="A2.SS3.8.7.1.m1.1.1.1.cmml" mathsize="70%" xref="A2.SS3.8.7.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.8.7.1.m1.1d">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>. 오른쪽 열은 모델의 반응에 할당된 네 가지 품질 등급 중 하나를 나타내며, "A"는 "유효하고 만족스러운" 반응(가장 높은)을 나타낸다.</figcaption><figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9: </span>Examples in the user-oriented instructions dataset (§<a href="#S4.SS4" title="4.4 Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ‣ 4 Experimental Results ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>) and predictions from <span id="A2.SS3.8.7.1" class="ltx_text ltx_font_smallcaps">GPT3<math id="A2.SS3.8.7.1.m1.1" class="ltx_Math" alttext="{}_{\textsc{Self-Inst}}" display="inline"><semantics id="A2.SS3.8.7.1.m1.1b"><msub id="A2.SS3.8.7.1.m1.1.1" xref="A2.SS3.8.7.1.m1.1.1.cmml"><mi id="A2.SS3.8.7.1.m1.1.1b" xref="A2.SS3.8.7.1.m1.1.1.cmml"></mi><mtext class="ltx_font_smallcaps" id="A2.SS3.8.7.1.m1.1.1.1" xref="A2.SS3.8.7.1.m1.1.1.1a.cmml">Self-Inst</mtext></msub><annotation-xml encoding="MathML-Content" id="A2.SS3.8.7.1.m1.1c"><apply id="A2.SS3.8.7.1.m1.1.1.cmml" xref="A2.SS3.8.7.1.m1.1.1"><ci id="A2.SS3.8.7.1.m1.1.1.1a.cmml" xref="A2.SS3.8.7.1.m1.1.1.1"><mtext class="ltx_font_smallcaps" mathsize="70%" id="A2.SS3.8.7.1.m1.1.1.1.cmml" xref="A2.SS3.8.7.1.m1.1.1.1">Self-Inst</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS3.8.7.1.m1.1d">{}_{\textsc{Self-Inst}}</annotation></semantics></math></span>. The right column indicates one of the four quality ratings assigned to the model’s response, with “A” indicating “valid and satisfying” responses (highest)
and “D” indicating “irrelevant or invalid response” (lowest).
</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_pagination ltx_figure_panel ltx_role_newpage"></div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<section id="A3" class="ltx_appendix ltx_figure_panel">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Task and Instance Examples from the Generated Instruction Data</h2>

<figure id="A3.T10" class="ltx_table">
<div id="A3.T10.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:842.6pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-17.0pt,33.0pt) scale(0.927291480460659,0.927291480460659) ;">
<table id="A3.T10.2.2" class="ltx_tabular ltx_align_middle">
<tbody><tr id="A3.T10.2.2.3" class="ltx_tr">
<td id="A3.T10.2.2.3.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="A3.T10.2.2.3.1.1" class="ltx_text ltx_font_bold">Instruction + Instance Input</span></td>
<td id="A3.T10.2.2.3.2" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;"><span id="A3.T10.2.2.3.2.1" class="ltx_text ltx_font_bold">Target Output</span></td>
<td id="A3.T10.2.2.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.3.3.1.1" class="ltx_p" style="width:39.0pt;"><span id="A3.T10.2.2.3.3.1.1.1" class="ltx_text ltx_font_bold">Validity</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.4" class="ltx_tr">
<td id="A3.T10.2.2.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.4.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.4.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.4.1.1.1.2" class="ltx_text ltx_font_typewriter">
Generate a random password with at least 6 characters.</span></span>
</span>
</td>
<td id="A3.T10.2.2.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.4.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.4.2.1.1.1" class="ltx_text ltx_font_typewriter">def generateRandomPassword():

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;password = ""

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while len(password) &lt; 6:

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;password += chr(random.randint(65, 90))

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return password</span></span>
</span>
</td>
<td id="A3.T10.2.2.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.4.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.4.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.4.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.4.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.5" class="ltx_tr">
<td id="A3.T10.2.2.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.5.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.5.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.5.1.1.1.2" class="ltx_text ltx_font_typewriter"> Write a paragraph describing how to tie shoelaces for people who have never tied their shoes before. explain each step briefly.</span></span>
</span>
</td>
<td id="A3.T10.2.2.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.5.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.5.2.1.1.1" class="ltx_text ltx_font_typewriter">Paragraph: To tie shoelaces, first you need to make a loop with one end of the lace. Then pass the other end through the loop and pull it tight. Next, you need to wrap the lace around the shoe several times. Finally, tuck in the loose end into the wrapped part of the lace.</span></span>
</span>
</td>
<td id="A3.T10.2.2.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.5.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.5.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.5.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.5.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.6" class="ltx_tr">
<td id="A3.T10.2.2.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.6.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.6.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.6.1.1.1.2" class="ltx_text ltx_font_typewriter">
Given a word, find out its length and its number of vowels.

<br class="ltx_break"><span id="A3.T10.2.2.6.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
Word = "hello"</span></span>
</span>
</td>
<td id="A3.T10.2.2.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.6.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.6.2.1.1.1" class="ltx_text ltx_font_typewriter">Length = 5, Number of vowels = 2</span></span>
</span>
</td>
<td id="A3.T10.2.2.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.6.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.6.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.6.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.6.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.7" class="ltx_tr">
<td id="A3.T10.2.2.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.7.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.7.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.7.1.1.1.2" class="ltx_text ltx_font_typewriter">
Write a story with three characters: a person, an animal and an object.

<br class="ltx_break"><span id="A3.T10.2.2.7.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
Person: John, a programmer. 
<br class="ltx_break">Animal: A dog. 
<br class="ltx_break">Object: A laptop. 
<br class="ltx_break"></span></span>
</span>
</td>
<td id="A3.T10.2.2.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.7.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.7.2.1.1.1" class="ltx_text ltx_font_typewriter">John was sitting on the floor in front of his laptop when he heard a knock at the door. He opened it to find a dog standing there. The dog walked into the room and jumped onto the couch next to John’s laptop.</span></span>
</span>
</td>
<td id="A3.T10.2.2.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.7.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.7.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.7.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.7.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.8" class="ltx_tr">
<td id="A3.T10.2.2.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.8.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.8.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.8.1.1.1.2" class="ltx_text ltx_font_typewriter">
Compose an email and send it to your friend, asking for advice on what to do in this situation.

<br class="ltx_break"><span id="A3.T10.2.2.8.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
Situation: You are a programmer and you have been working on a project for the past few months. The deadline is approaching, but you haven’t finished yet. Your manager has asked you to stay late every day this week to finish it.</span></span>
</span>
</td>
<td id="A3.T10.2.2.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.8.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.8.2.1.1.1" class="ltx_text ltx_font_typewriter">Hi [Friend], 
<br class="ltx_break">I’m having a bit of trouble with my current job. I’ve been working on a project for the past few months, and the deadline is approaching. My manager has asked me to stay late every day this week to finish it. I don’t think I can do that because I have other commitments. What should I do?</span></span>
</span>
</td>
<td id="A3.T10.2.2.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.8.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.8.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.8.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.8.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.9" class="ltx_tr">
<td id="A3.T10.2.2.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.9.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.9.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.9.1.1.1.2" class="ltx_text ltx_font_typewriter">
What are some ways we can make our school more eco-friendly?</span></span>
</span>
</td>
<td id="A3.T10.2.2.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.9.2.1.1" class="ltx_p" style="width:242.8pt;">
<span id="A3.I1" class="ltx_itemize">
<span id="A3.I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I1.i1.p1" class="ltx_para">
<span id="A3.I1.i1.p1.1" class="ltx_p"><span id="A3.I1.i1.p1.1.1" class="ltx_text ltx_font_typewriter">Use reusable water bottles instead of disposable plastic ones.</span></span>
</span></span>
<span id="A3.I1.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I1.i2.p1" class="ltx_para">
<span id="A3.I1.i2.p1.1" class="ltx_p"><span id="A3.I1.i2.p1.1.1" class="ltx_text ltx_font_typewriter">Turn off lights when you leave a room.</span></span>
</span></span>
<span id="A3.I1.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I1.i3.p1" class="ltx_para">
<span id="A3.I1.i3.p1.1" class="ltx_p"><span id="A3.I1.i3.p1.1.1" class="ltx_text ltx_font_typewriter">Recycle paper, cans and bottles.</span></span>
</span></span>
<span id="A3.I1.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I1.i4.p1" class="ltx_para">
<span id="A3.I1.i4.p1.1" class="ltx_p"><span id="A3.I1.i4.p1.1.1" class="ltx_text ltx_font_typewriter">Plant trees to absorb carbon dioxide.</span></span>
</span></span>
</span></span>
</span>
</td>
<td id="A3.T10.2.2.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.9.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.9.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.9.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.9.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.10" class="ltx_tr">
<td id="A3.T10.2.2.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.10.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.10.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.10.1.1.1.2" class="ltx_text ltx_font_typewriter"> I am looking for a new apartment. there are many options available but they are all quite expensive. i want to move as soon as possible. give me advice on what to do.</span></span>
</span>
</td>
<td id="A3.T10.2.2.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.10.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.10.2.1.1.1" class="ltx_text ltx_font_typewriter">You should look for a cheaper apartment. You can try to negotiate with the landlord and offer him/her a lower price. If you are lucky, they will accept your offer. Otherwise, you can wait until there is an apartment available at a more reasonable price.</span></span>
</span>
</td>
<td id="A3.T10.2.2.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.10.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.10.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.10.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.10.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.11" class="ltx_tr">
<td id="A3.T10.2.2.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.11.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.11.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.11.1.1.1.2" class="ltx_text ltx_font_typewriter">
Write a dialogue between two people who have been friends for a long time, and one of them is trying to convince the other to do something that he or she doesn’t want to do.</span></span>
</span>
</td>
<td id="A3.T10.2.2.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.11.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.11.2.1.1.1" class="ltx_text ltx_font_typewriter">A: Hey, I have a great idea! Let’s go to the beach today.
<br class="ltx_break">B: No thanks, I’m not really in the mood for that.
<br class="ltx_break">A: Come on, it’ll be fun! We haven’t been there together in ages.
B: I know, but I just don’t feel like going.
<br class="ltx_break">A: But you love the beach! You always say how much you enjoy swimming and lying in the sun.
<br class="ltx_break">B: Yeah, I do. It’s just that I’ve been feeling kind of tired lately.
<br class="ltx_break">A: Oh, come on. You’re never tired. You’re always so energetic.
<br class="ltx_break">B: Well, I am now. I think I need some rest.
<br class="ltx_break">A: Okay, fine. If you change your mind, let me know.</span></span>
</span>
</td>
<td id="A3.T10.2.2.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.11.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.11.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.11.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.11.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.12" class="ltx_tr">
<td id="A3.T10.2.2.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.12.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.12.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.12.1.1.1.2" class="ltx_text ltx_font_typewriter"> How can i create an app that will be able to identify different kinds of plants by taking photos of them?</span></span>
</span>
</td>
<td id="A3.T10.2.2.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.12.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.12.2.1.1.1" class="ltx_text ltx_font_typewriter">You can use the following steps to create an app that will be able to identify different kinds of plants by taking photos of them. 
<br class="ltx_break">Step 1: Create a database with all the information about the plants you want to identify. 
<br class="ltx_break">Step 2: Create a user interface for your application. 
<br class="ltx_break">Step 3: Use image recognition techniques to identify the plant in the photo. 
<br class="ltx_break">Step 4: Display the name of the plant on the screen.</span></span>
</span>
</td>
<td id="A3.T10.2.2.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.12.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.12.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.12.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.12.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.2" class="ltx_tr">
<td id="A3.T10.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.1.1.1.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.1.1.1.1.1.1.2" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.1.1.1.1.1.1.1" class="ltx_text ltx_font_typewriter"> Find the closest matching emoji to a given one. 
<br class="ltx_break"><span id="A3.T10.1.1.1.1.1.1.1.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span> Emoji: <img src="https://ar5iv.labs.arxiv.org/html/2212.10560/assets/figures/woman-surfing.png" id="A3.T10.1.1.1.1.1.1.1.g1" class="ltx_graphics ltx_img_square" width="9" height="8" alt="[Uncaptioned image]"></span></span>
</span>
</td>
<td id="A3.T10.2.2.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.2.2.1.1" class="ltx_p" style="width:242.8pt;"><img src="https://ar5iv.labs.arxiv.org/html/2212.10560/assets/figures/water-wave.png" id="A3.T10.2.2.2.2.1.1.g1" class="ltx_graphics ltx_img_square" width="9" height="8" alt="[Uncaptioned image]"></span>
</span>
</td>
<td id="A3.T10.2.2.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.2.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.2.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.2.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.2.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T10.2.2.13" class="ltx_tr">
<td id="A3.T10.2.2.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.13.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T10.2.2.13.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T10.2.2.13.1.1.1.2" class="ltx_text ltx_font_typewriter"> Describe your favorite video game using only verbs. 
<br class="ltx_break"><span id="A3.T10.2.2.13.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span> Game: The Legend of Zelda</span></span>
</span>
</td>
<td id="A3.T10.2.2.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.13.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T10.2.2.13.2.1.1.1" class="ltx_text ltx_font_typewriter">Explore, fight, solve, upgrade, repeat</span></span>
</span>
</td>
<td id="A3.T10.2.2.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="padding-left:4.0pt;padding-right:4.0pt;">
<span id="A3.T10.2.2.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T10.2.2.13.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T10.2.2.13.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T10.2.2.13.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T10.2.2.13.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 10: </span>Representative <span class="ltx_text ltx_font_bold" id="A3.T10.4.1">valid</span> GPT3에 의해 생성된 태스크들. §<a class="ltx_ref" href="#S3" title="3 Self-Instruct Data from GPT3 ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions"><span class="ltx_text ltx_ref_tag">3</span></a>에서 논의되는 바와 같이, 이들 생성된 태스크들은 광범위한 포맷들, 텍스트 타입들 및 기초 전문 지식을 커버하면서, 생성된 태스크들 중 절반 이상에서는 정확하다.</figcaption>
</figure>
<figure id="A3.T11" class="ltx_table">
<div id="A3.T11.7" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:979.6pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-14.0pt,31.6pt) scale(0.939344141726076,0.939344141726076) ;">
<table id="A3.T11.7.7" class="ltx_tabular ltx_align_middle">
<tbody><tr id="A3.T11.7.7.8" class="ltx_tr">
<td id="A3.T11.7.7.8.1" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A3.T11.7.7.8.1.1" class="ltx_text ltx_font_bold">Instruction + Instance Input</span></td>
<td id="A3.T11.7.7.8.2" class="ltx_td ltx_align_center ltx_align_top ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;"><span id="A3.T11.7.7.8.2.1" class="ltx_text ltx_font_bold">Target Output</span></td>
<td id="A3.T11.7.7.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.8.3.1.1" class="ltx_p" style="width:39.0pt;"><span id="A3.T11.7.7.8.3.1.1.1" class="ltx_text ltx_font_bold">Validity</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.7" class="ltx_tr">
<td id="A3.T11.7.7.7.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.7.7.7" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.7.7.7.7" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.7.7.7.7.8" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.7.7.7.7.7" class="ltx_text ltx_font_typewriter">
Given a set of words <math id="A3.T11.1.1.1.1.1.1.1.m1.4" class="ltx_Math" alttext="w=\{w_{1},w_{2},...,w_{n}\}" display="inline"><semantics id="A3.T11.1.1.1.1.1.1.1.m1.4a"><mrow id="A3.T11.1.1.1.1.1.1.1.m1.4.4" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.cmml"><mi id="A3.T11.1.1.1.1.1.1.1.m1.4.4.5" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.5.cmml">w</mi><mo id="A3.T11.1.1.1.1.1.1.1.m1.4.4.4" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.4.cmml">=</mo><mrow id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.4.cmml"><mo stretchy="false" id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.4" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.4.cmml">{</mo><msub id="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1" xref="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.cmml"><mi id="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.2" xref="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.2.cmml">w</mi><mn id="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.3" xref="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.5" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.4.cmml">,</mo><msub id="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2" xref="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.cmml"><mi id="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.2" xref="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.2.cmml">w</mi><mn id="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.3" xref="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.6" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="A3.T11.1.1.1.1.1.1.1.m1.1.1" xref="A3.T11.1.1.1.1.1.1.1.m1.1.1.cmml">…</mi><mo id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.7" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.4.cmml">,</mo><msub id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.cmml"><mi id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.2" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.2.cmml">w</mi><mi id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.3" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.3.cmml">n</mi></msub><mo stretchy="false" id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.8" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.T11.1.1.1.1.1.1.1.m1.4b"><apply id="A3.T11.1.1.1.1.1.1.1.m1.4.4.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4"><eq id="A3.T11.1.1.1.1.1.1.1.m1.4.4.4.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.4"></eq><ci id="A3.T11.1.1.1.1.1.1.1.m1.4.4.5.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.5">𝑤</ci><set id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.4.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3"><apply id="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.1.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.2.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.2">𝑤</ci><cn type="integer" id="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.3.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.1.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.2.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.2">𝑤</ci><cn type="integer" id="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.3.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="A3.T11.1.1.1.1.1.1.1.m1.1.1.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.1.1">…</ci><apply id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.1.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3">subscript</csymbol><ci id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.2.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.2">𝑤</ci><ci id="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.3.cmml" xref="A3.T11.1.1.1.1.1.1.1.m1.4.4.3.3.3.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.1.1.1.1.1.1.1.m1.4c">w=\{w_{1},w_{2},...,w_{n}\}</annotation></semantics></math> where each word <math id="A3.T11.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="w_{i}" display="inline"><semantics id="A3.T11.2.2.2.2.2.2.2.m2.1a"><msub id="A3.T11.2.2.2.2.2.2.2.m2.1.1" xref="A3.T11.2.2.2.2.2.2.2.m2.1.1.cmml"><mi id="A3.T11.2.2.2.2.2.2.2.m2.1.1.2" xref="A3.T11.2.2.2.2.2.2.2.m2.1.1.2.cmml">w</mi><mi id="A3.T11.2.2.2.2.2.2.2.m2.1.1.3" xref="A3.T11.2.2.2.2.2.2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A3.T11.2.2.2.2.2.2.2.m2.1b"><apply id="A3.T11.2.2.2.2.2.2.2.m2.1.1.cmml" xref="A3.T11.2.2.2.2.2.2.2.m2.1.1"><csymbol cd="ambiguous" id="A3.T11.2.2.2.2.2.2.2.m2.1.1.1.cmml" xref="A3.T11.2.2.2.2.2.2.2.m2.1.1">subscript</csymbol><ci id="A3.T11.2.2.2.2.2.2.2.m2.1.1.2.cmml" xref="A3.T11.2.2.2.2.2.2.2.m2.1.1.2">𝑤</ci><ci id="A3.T11.2.2.2.2.2.2.2.m2.1.1.3.cmml" xref="A3.T11.2.2.2.2.2.2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.2.2.2.2.2.2.2.m2.1c">w_{i}</annotation></semantics></math> has <math id="A3.T11.3.3.3.3.3.3.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="A3.T11.3.3.3.3.3.3.3.m3.1a"><mi id="A3.T11.3.3.3.3.3.3.3.m3.1.1" xref="A3.T11.3.3.3.3.3.3.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="A3.T11.3.3.3.3.3.3.3.m3.1b"><ci id="A3.T11.3.3.3.3.3.3.3.m3.1.1.cmml" xref="A3.T11.3.3.3.3.3.3.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.3.3.3.3.3.3.3.m3.1c">n</annotation></semantics></math> letters, write a function that takes a target length <math id="A3.T11.4.4.4.4.4.4.4.m4.1" class="ltx_Math" alttext="l" display="inline"><semantics id="A3.T11.4.4.4.4.4.4.4.m4.1a"><mi id="A3.T11.4.4.4.4.4.4.4.m4.1.1" xref="A3.T11.4.4.4.4.4.4.4.m4.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="A3.T11.4.4.4.4.4.4.4.m4.1b"><ci id="A3.T11.4.4.4.4.4.4.4.m4.1.1.cmml" xref="A3.T11.4.4.4.4.4.4.4.m4.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.4.4.4.4.4.4.4.m4.1c">l</annotation></semantics></math> and returns a new set of words <math id="A3.T11.5.5.5.5.5.5.5.m5.1" class="ltx_Math" alttext="s" display="inline"><semantics id="A3.T11.5.5.5.5.5.5.5.m5.1a"><mi id="A3.T11.5.5.5.5.5.5.5.m5.1.1" xref="A3.T11.5.5.5.5.5.5.5.m5.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="A3.T11.5.5.5.5.5.5.5.m5.1b"><ci id="A3.T11.5.5.5.5.5.5.5.m5.1.1.cmml" xref="A3.T11.5.5.5.5.5.5.5.m5.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.5.5.5.5.5.5.5.m5.1c">s</annotation></semantics></math> such that <math id="A3.T11.6.6.6.6.6.6.6.m6.1" class="ltx_Math" alttext="|s|=l" display="inline"><semantics id="A3.T11.6.6.6.6.6.6.6.m6.1a"><mrow id="A3.T11.6.6.6.6.6.6.6.m6.1.2" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.cmml"><mrow id="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.2" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.1.cmml"><mo stretchy="false" id="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.2.1" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.1.1.cmml">|</mo><mi id="A3.T11.6.6.6.6.6.6.6.m6.1.1" xref="A3.T11.6.6.6.6.6.6.6.m6.1.1.cmml">s</mi><mo stretchy="false" id="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.2.2" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.1.1.cmml">|</mo></mrow><mo id="A3.T11.6.6.6.6.6.6.6.m6.1.2.1" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.1.cmml">=</mo><mi id="A3.T11.6.6.6.6.6.6.6.m6.1.2.3" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.3.cmml">l</mi></mrow><annotation-xml encoding="MathML-Content" id="A3.T11.6.6.6.6.6.6.6.m6.1b"><apply id="A3.T11.6.6.6.6.6.6.6.m6.1.2.cmml" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2"><eq id="A3.T11.6.6.6.6.6.6.6.m6.1.2.1.cmml" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.1"></eq><apply id="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.1.cmml" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.2"><abs id="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.1.1.cmml" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.2.2.1"></abs><ci id="A3.T11.6.6.6.6.6.6.6.m6.1.1.cmml" xref="A3.T11.6.6.6.6.6.6.6.m6.1.1">𝑠</ci></apply><ci id="A3.T11.6.6.6.6.6.6.6.m6.1.2.3.cmml" xref="A3.T11.6.6.6.6.6.6.6.m6.1.2.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.6.6.6.6.6.6.6.m6.1c">|s|=l</annotation></semantics></math> and <math id="A3.T11.7.7.7.7.7.7.7.m7.3" class="ltx_Math" alttext="|\{i:w_{i}\in s\}|\leq l/|w|" display="inline"><semantics id="A3.T11.7.7.7.7.7.7.7.m7.3a"><mrow id="A3.T11.7.7.7.7.7.7.7.m7.3.3" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.cmml"><mrow id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.2.cmml"><mo stretchy="false" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.2.1.cmml">|</mo><mrow id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.2.cmml"><mo stretchy="false" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.2.1.cmml">{</mo><mi id="A3.T11.7.7.7.7.7.7.7.m7.1.1" xref="A3.T11.7.7.7.7.7.7.7.m7.1.1.cmml">i</mi><mo lspace="0.278em" rspace="0.278em" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.3" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.2.1.cmml">:</mo><mrow id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.cmml"><msub id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.cmml"><mi id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.2.cmml">w</mi><mi id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.3" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.1" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.1.cmml">∈</mo><mi id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.3" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.3.cmml">s</mi></mrow><mo stretchy="false" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.4" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.2.1.cmml">}</mo></mrow><mo stretchy="false" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.3" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.2.1.cmml">|</mo></mrow><mo id="A3.T11.7.7.7.7.7.7.7.m7.3.3.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.2.cmml">≤</mo><mrow id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.cmml"><mi id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.2.cmml">l</mi><mo id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.1" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.1.cmml">/</mo><mrow id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.1.cmml"><mo stretchy="false" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.2.1" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.1.1.cmml">|</mo><mi id="A3.T11.7.7.7.7.7.7.7.m7.2.2" xref="A3.T11.7.7.7.7.7.7.7.m7.2.2.cmml">w</mi><mo stretchy="false" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.2.2" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.1.1.cmml">|</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.T11.7.7.7.7.7.7.7.m7.3b"><apply id="A3.T11.7.7.7.7.7.7.7.m7.3.3.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3"><leq id="A3.T11.7.7.7.7.7.7.7.m7.3.3.2.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.2"></leq><apply id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.2.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1"><abs id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.2.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.2"></abs><apply id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.2.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1"><csymbol cd="latexml" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.2.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.2">conditional-set</csymbol><ci id="A3.T11.7.7.7.7.7.7.7.m7.1.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.1.1">𝑖</ci><apply id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1"><in id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.1"></in><apply id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2"><csymbol cd="ambiguous" id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2">subscript</csymbol><ci id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.2.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.2">𝑤</ci><ci id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.3.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.3.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.1.1.1.1.1.3">𝑠</ci></apply></apply></apply><apply id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3"><divide id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.1"></divide><ci id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.2.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.2">𝑙</ci><apply id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.2"><abs id="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.1.1.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.3.3.3.3.2.1"></abs><ci id="A3.T11.7.7.7.7.7.7.7.m7.2.2.cmml" xref="A3.T11.7.7.7.7.7.7.7.m7.2.2">𝑤</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.T11.7.7.7.7.7.7.7.m7.3c">|\{i:w_{i}\in s\}|\leq l/|w|</annotation></semantics></math>.</span></span>
</span>
</td>
<td id="A3.T11.7.7.7.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.7.8.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.7.8.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.7.8.1.1.1" class="ltx_text ltx_font_typewriter">def wordSubsetSum(w, l):

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s = []

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for i in range(len(w)):

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if len(s) + 1 &lt; l:

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s.append(w[i])

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return s</span></span>
</span>
</td>
<td id="A3.T11.7.7.7.9" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.7.9.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.7.9.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.7.9.1.1.1" class="ltx_text" style="color:#FF0000;">✗
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.7.9.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.7.9.1.1.3" class="ltx_text" style="color:#FF0000;">✗</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.9" class="ltx_tr">
<td id="A3.T11.7.7.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.9.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.9.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.9.1.1.1.2" class="ltx_text ltx_font_typewriter">
The house on fire! go!</span></span>
</span>
</td>
<td id="A3.T11.7.7.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.9.2.1.1" class="ltx_p" style="width:242.8pt;">
<span id="A3.I2" class="ltx_itemize">
<span id="A3.I2.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I2.i1.p1" class="ltx_para">
<span id="A3.I2.i1.p1.1" class="ltx_p"><span id="A3.I2.i1.p1.1.1" class="ltx_text ltx_font_typewriter">Go to the kitchen and take a pan.</span></span>
</span></span>
<span id="A3.I2.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I2.i2.p1" class="ltx_para">
<span id="A3.I2.i2.p1.1" class="ltx_p"><span id="A3.I2.i2.p1.1.1" class="ltx_text ltx_font_typewriter">Take water from the tap.</span></span>
</span></span>
<span id="A3.I2.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I2.i3.p1" class="ltx_para">
<span id="A3.I2.i3.p1.1" class="ltx_p"><span id="A3.I2.i3.p1.1.1" class="ltx_text ltx_font_typewriter">Pour water into the pan.</span></span>
</span></span>
<span id="A3.I2.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_item">–</span> 
<span id="A3.I2.i4.p1" class="ltx_para">
<span id="A3.I2.i4.p1.1" class="ltx_p"><span id="A3.I2.i4.p1.1.1" class="ltx_text ltx_font_typewriter">Put out the fire with the pan.</span></span>
</span></span>
</span></span>
</span>
</td>
<td id="A3.T11.7.7.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.9.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.9.3.1.1.1" class="ltx_text" style="color:#FF0000;">✗
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.9.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.9.3.1.1.3" class="ltx_text" style="color:#FF0000;">✗</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.10" class="ltx_tr">
<td id="A3.T11.7.7.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.10.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.10.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.10.1.1.1.2" class="ltx_text ltx_font_typewriter"> Find out if you have any friends who like to play football or chess.</span></span>
</span>
</td>
<td id="A3.T11.7.7.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.10.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.10.2.1.1.1" class="ltx_text ltx_font_typewriter">def hasFriendsWhoLikeToPlayFootballOrChess(self):

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;friends = []

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for friend in self.friends:

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if friend.likes == ’football’ or friend.likes == ’chess’:

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;friends.append(friend)

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return len(friends) &gt; 0</span></span>
</span>
</td>
<td id="A3.T11.7.7.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.10.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.10.3.1.1.1" class="ltx_text" style="color:#FF0000;">✗
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.10.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.10.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.11" class="ltx_tr">
<td id="A3.T11.7.7.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.11.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.11.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.11.1.1.1.2" class="ltx_text ltx_font_typewriter">
A number of people are lined up for an interview. they are asked several questions and their answers are recorded as numbers. you need to identify which person has the highest salary among all the candidates.

<br class="ltx_break"><span id="A3.T11.7.7.11.1.1.1.2.1" class="ltx_text" style="background-color:#E7FFDB;">Input:</span>
Person 1: 2, 3, 4, 5, 6 
<br class="ltx_break">Person 2: 7, 8, 9, 10, 11 
<br class="ltx_break">Person 3: 12, 13, 14, 15, 16 
<br class="ltx_break">Person 4: 17, 18, 19, 20, 21 
<br class="ltx_break">Person 5: 22, 23, 24, 25, 26 
<br class="ltx_break">Person 6: 27, 28, 29, 30, 31</span></span>
</span>
</td>
<td id="A3.T11.7.7.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.11.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.11.2.1.1.1" class="ltx_text ltx_font_typewriter">Highest salary</span></span>
</span>
</td>
<td id="A3.T11.7.7.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.11.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.11.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.11.3.1.1.2" class="ltx_text" style="color:#FF0000;">✗
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.11.3.1.1.3" class="ltx_text" style="color:#FF0000;">✗</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.12" class="ltx_tr">
<td id="A3.T11.7.7.12.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.12.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.12.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.12.1.1.1.2" class="ltx_text ltx_font_typewriter">
Given a list of words, generate a story about a group of people who live on a planet. the story should contain at least 10 sentences. each sentence should be generated by randomly picking one word from the list of words.</span></span>
</span>
</td>
<td id="A3.T11.7.7.12.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.12.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.12.2.1.1.1" class="ltx_text ltx_font_typewriter">The story starts with a group of people who live on a planet. They are very intelligent and have created many things that help them in their daily lives. One day, they decided to create a machine that can make food for them. The machine was able to produce food but it also produced something else. It produced a liquid that could be used as fuel for the machines. The people were happy because they didn’t need to go out and look for food or fuel anymore. They had everything they needed right there in their homes. However, one day, the machine stopped working. The people tried to fix it but couldn’t figure out what went wrong. They tried to find someone who could help them but no one knew how to fix the machine. After a few days, the people realized that they would die if they didn’t do anything about it. So, they decided to send some of their best scientists to space to find a new planet where they could live. The scientists traveled for a long time before they found a planet that looked like a good place to live. They sent a message back to the people telling them about the planet. The people were excited and started preparing for the journey. They built spaceships and flew to the new planet. When they arrived, they saw that the planet was beautiful. There were trees and rivers and mountains. The people were so happy that they finally found a new home. They started building houses and planting crops. They lived happily ever after.</span></span>
</span>
</td>
<td id="A3.T11.7.7.12.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.12.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.12.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.12.3.1.1.2" class="ltx_text" style="color:#FF0000;">✗
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.12.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.13" class="ltx_tr">
<td id="A3.T11.7.7.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.13.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.13.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.13.1.1.1.2" class="ltx_text ltx_font_typewriter"> Find out what the author’s attitude towards working part-time is.</span></span>
</span>
</td>
<td id="A3.T11.7.7.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.13.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.13.2.1.1.1" class="ltx_text ltx_font_typewriter">Paragraph: Working part-time is a great way to earn some extra money while still being able to enjoy your free time. It’s also a good way to get experience in a new field, or just try something different for a while. However, it can be difficult to find the right balance between work and play. 
<br class="ltx_break">The author seems to be positive about working part-time.</span></span>
</span>
</td>
<td id="A3.T11.7.7.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.13.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.13.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.13.3.1.1.2" class="ltx_text" style="color:#FF0000;">✗
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.13.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.14" class="ltx_tr">
<td id="A3.T11.7.7.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.14.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.14.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.14.1.1.1.2" class="ltx_text ltx_font_typewriter"> Is it ethical to use a new technology that could potentially cause harm to others?</span></span>
</span>
</td>
<td id="A3.T11.7.7.14.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.14.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.14.2.1.1.1" class="ltx_text ltx_font_typewriter">New Technology: Self-driving cars 
<br class="ltx_break">Potential Harm: Accidents caused by self-driving cars 
<br class="ltx_break">Ethical? Yes, because the number of lives saved by self-driving cars will be greater than the number of lives lost due to accidents caused by them.</span></span>
</span>
</td>
<td id="A3.T11.7.7.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.14.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.14.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.14.3.1.1.2" class="ltx_text" style="color:#FF0000;">✗
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.14.3.1.1.3" class="ltx_text" style="color:#1E821E;">✓</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.15" class="ltx_tr">
<td id="A3.T11.7.7.15.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.15.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.15.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.15.1.1.1.2" class="ltx_text ltx_font_typewriter">
What is your salary?</span></span>
</span>
</td>
<td id="A3.T11.7.7.15.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.15.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.15.2.1.1.1" class="ltx_text ltx_font_typewriter">class Solution(object):

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;def getSalary(self):

<br class="ltx_break">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return self.salary</span></span>
</span>
</td>
<td id="A3.T11.7.7.15.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.15.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction: <span id="A3.T11.7.7.15.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.15.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.15.3.1.1.3" class="ltx_text" style="color:#FF0000;">✗</span></span>
</span>
</td>
</tr>
<tr id="A3.T11.7.7.16" class="ltx_tr">
<td id="A3.T11.7.7.16.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.16.1.1.1" class="ltx_p" style="width:151.8pt;"><span id="A3.T11.7.7.16.1.1.1.1" class="ltx_text ltx_font_typewriter" style="background-color:#E7FFDB;">Instruction:</span><span id="A3.T11.7.7.16.1.1.1.2" class="ltx_text ltx_font_typewriter">
A person wants to buy a car from another person. he has some bitcoins, but he doesn’t want to reveal his identity. how can they make the transaction happen?</span></span>
</span>
</td>
<td id="A3.T11.7.7.16.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.16.2.1.1" class="ltx_p" style="width:242.8pt;"><span id="A3.T11.7.7.16.2.1.1.1" class="ltx_text ltx_font_typewriter">The buyer and seller should agree on a price for the car. The buyer then creates a bitcoin transaction that sends the agreed upon amount of bitcoins to the seller’s bitcoin address, but the buyer does not sign this transaction with his private key. Instead, he gives the unsigned transaction to the seller. The seller can now sign the transaction using his private key, and broadcast it to the network. Once the transaction is confirmed by the network, the buyer has no way to get his money back, so he will be forced to go through with the purchase.</span></span>
</span>
</td>
<td id="A3.T11.7.7.16.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="padding-left:3.0pt;padding-right:3.0pt;">
<span id="A3.T11.7.7.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="A3.T11.7.7.16.3.1.1" class="ltx_p" style="width:39.0pt;">Instruction:<span id="A3.T11.7.7.16.3.1.1.1" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Input: <span id="A3.T11.7.7.16.3.1.1.2" class="ltx_text" style="color:#1E821E;">✓
<br class="ltx_break"></span>Output: <span id="A3.T11.7.7.16.3.1.1.3" class="ltx_text" style="color:#FF0000;">✗</span></span>
</span>
</td>
</tr>
</tbody></table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11:</span></figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>
Representative <span id="A3.T11.10.1" class="ltx_text ltx_font_bold">invalid</span> tasks generated by <span id="A3.T11.11.2" class="ltx_text ltx_font_smallcaps">GPT3</span>. The problematic fields are indicated in the validity column. As discussed in §<a href="#S3.T2" title="Table 2 ‣ 3.3 Quality ‣ 3 Self-Instruct Data from GPT3 ‣ ACL 2023 Self-Instruct: Aligning Language Models with Self-Generated Instructions" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, although these tasks contain errors, they still provide many useful signals in supervising models to follow instructions.
</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</div>
</div>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2212.10559" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2212.10560" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2212.10560">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2212.10560" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2212.10561" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 10:10:10 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>