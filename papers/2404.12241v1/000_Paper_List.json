{
    "2404.12241v1": {
        "paper_id": "2404.12241v1",
        "abs_url": "https://arxiv.org/abs/2404.12241v1",
        "pdf_url": "https://arxiv.org/pdf/2404.12241v1.pdf",
        "supp_url": null,
        "src_website": "ArXiv",
        "download_name": "2404.12241v1_Introducing_v05_of_the_AI_Safety_Benchmark_from_MLCommons.pdf",
        "title": "Introducing v0.5 of the AI Safety Benchmark from MLCommons",
        "year": null,
        "paper_venue": null,
        "authors": [
            "Bertie Vidgen",
            "Adarsh Agrawal",
            "Ahmed M. Ahmed",
            "Victor Akinwande",
            "Namir Al-Nuaimi",
            "Najla Alfaraj",
            "Elie Alhajjar",
            "Lora Aroyo",
            "Trupti Bavalatti",
            "Borhane Blili-Hamelin",
            "Kurt Bollacker",
            "Rishi Bomassani",
            "Marisa Ferrara Boston",
            "Sim\u00e9on Campos",
            "Kal Chakra",
            "Canyu Chen",
            "Cody Coleman",
            "Zacharie Delpierre Coudert",
            "Leon Derczynski",
            "Debojyoti Dutta",
            "Ian Eisenberg",
            "James Ezick",
            "Heather Frase",
            "Brian Fuller",
            "Ram Gandikota",
            "Agasthya Gangavarapu",
            "Ananya Gangavarapu",
            "James Gealy",
            "Rajat Ghosh",
            "James Goel",
            "Usman Gohar",
            "Sujata Goswami",
            "Scott A. Hale",
            "Wiebke Hutiri",
            "Joseph Marvin Imperial",
            "Surgan Jandial",
            "Nick Judd",
            "Felix Juefei-Xu",
            "Foutse Khomh",
            "Bhavya Kailkhura",
            "Hannah Rose Kirk",
            "Kevin Klyman",
            "Chris Knotz",
            "Michael Kuchnik",
            "Shachi H. Kumar",
            "Chris Lengerich",
            "Bo Li",
            "Zeyi Liao",
            "Eileen Peters Long",
            "Victor Lu",
            "Yifan Mai",
            "Priyanka Mary Mammen",
            "Kelvin Manyeki",
            "Sean McGregor",
            "Virendra Mehta",
            "Shafee Mohammed",
            "Emanuel Moss",
            "Lama Nachman",
            "Dinesh Jinenhally Naganna",
            "Amin Nikanjam",
            "Besmira Nushi",
            "Luis Oala",
            "Iftach Orr",
            "Alicia Parrish",
            "Cigdem Patlak",
            "William Pietri",
            "Forough Poursabzi-Sangdeh",
            "Eleonora Presani",
            "Fabrizio Puletti",
            "Paul R\u00f6ttger",
            "Saurav Sahay",
            "Tim Santos",
            "Nino Scherrer",
            "Alice Schoenauer Sebag",
            "Patrick Schramowski",
            "Abolfazl Shahbazi",
            "Vin Sharma",
            "Xudong Shen",
            "Vamsi Sistla",
            "Leonard Tang",
            "Davide Testuggine",
            "Vithursan Thangarasa",
            "Elizabeth Anne Watkins",
            "Rebecca Weiss",
            "Chris Welty",
            "Tyler Wilbers",
            "Adina Williams",
            "Carole-Jean Wu",
            "Poonam Yadav",
            "Xianjun Yang",
            "Yi Zeng",
            "Wenhui Zhang",
            "Fedor Zhdanov",
            "Jiacheng Zhu",
            "Percy Liang",
            "Peter Mattson",
            "Joaquin Vanschoren"
        ],
        "abstract": "This paper introduces v0.5 of the AI Safety Benchmark, which has been created by the MLCommons AI Safety Working Group. The AI Safety Benchmark has been designed to assess the safety risks of AI systems that use chat-tuned language models. We introduce a principled approach to specifying and constructing the benchmark, which for v0.5 covers only a single use case (an adult chatting to a general-purpose assistant in English), and a limited set of personas (i.e., typical users, malicious users, and vulnerable users). We created a new taxonomy of 13 hazard categories, of which 7 have tests in the v0.5 benchmark. We plan to release version 1.0 of the AI Safety Benchmark by the end of 2024. The v1.0 benchmark will provide meaningful insights into the safety of AI systems. However, the v0.5 benchmark should not be used to assess the safety of AI systems. We have sought to fully document the limitations, flaws, and challenges of v0.5. This release of v0.5 of the AI Safety Benchmark includes (1) a principled approach to specifying and constructing the benchmark, which comprises use cases, types of systems under test (SUTs), language and context, personas, tests, and test items; (2) a taxonomy of 13 hazard categories with definitions and subcategories; (3) tests for seven of the hazard categories, each comprising a unique set of test items, i.e., prompts. There are 43,090 test items in total, which we created with templates; (4) a grading system for AI systems against the benchmark; (5) an openly available platform, and downloadable tool, called ModelBench that can be used to evaluate the safety of AI systems on the benchmark; (6) an example evaluation report which benchmarks the performance of over a dozen openly available chat-tuned language models; (7) a test specification for the benchmark.",
        "comments": "",
        "official_code_urls": [
            "https://github.com/mlcommons/modelbench"
        ],
        "pwc_page_url": "https://paperswithcode.com/paper/introducing-v0-5-of-the-ai-safety-benchmark",
        "bibtex": "@misc{vidgen2024introducing,\n      title={Introducing v0.5 of the AI Safety Benchmark from MLCommons}, \n      author={Bertie Vidgen and Adarsh Agrawal and Ahmed M. Ahmed and Victor Akinwande and Namir Al-Nuaimi and Najla Alfaraj and Elie Alhajjar and Lora Aroyo and Trupti Bavalatti and Borhane Blili-Hamelin and Kurt Bollacker and Rishi Bomassani and Marisa Ferrara Boston and Sim\u00e9on Campos and Kal Chakra and Canyu Chen and Cody Coleman and Zacharie Delpierre Coudert and Leon Derczynski and Debojyoti Dutta and Ian Eisenberg and James Ezick and Heather Frase and Brian Fuller and Ram Gandikota and Agasthya Gangavarapu and Ananya Gangavarapu and James Gealy and Rajat Ghosh and James Goel and Usman Gohar and Sujata Goswami and Scott A. Hale and Wiebke Hutiri and Joseph Marvin Imperial and Surgan Jandial and Nick Judd and Felix Juefei-Xu and Foutse Khomh and Bhavya Kailkhura and Hannah Rose Kirk and Kevin Klyman and Chris Knotz and Michael Kuchnik and Shachi H. Kumar and Chris Lengerich and Bo Li and Zeyi Liao and Eileen Peters Long and Victor Lu and Yifan Mai and Priyanka Mary Mammen and Kelvin Manyeki and Sean McGregor and Virendra Mehta and Shafee Mohammed and Emanuel Moss and Lama Nachman and Dinesh Jinenhally Naganna and Amin Nikanjam and Besmira Nushi and Luis Oala and Iftach Orr and Alicia Parrish and Cigdem Patlak and William Pietri and Forough Poursabzi-Sangdeh and Eleonora Presani and Fabrizio Puletti and Paul R\u00f6ttger and Saurav Sahay and Tim Santos and Nino Scherrer and Alice Schoenauer Sebag and Patrick Schramowski and Abolfazl Shahbazi and Vin Sharma and Xudong Shen and Vamsi Sistla and Leonard Tang and Davide Testuggine and Vithursan Thangarasa and Elizabeth Anne Watkins and Rebecca Weiss and Chris Welty and Tyler Wilbers and Adina Williams and Carole-Jean Wu and Poonam Yadav and Xianjun Yang and Yi Zeng and Wenhui Zhang and Fedor Zhdanov and Jiacheng Zhu and Percy Liang and Peter Mattson and Joaquin Vanschoren},\n      year={2024},\n      eprint={2404.12241},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}"
    }
}