<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2402.06196] Large Language Models: A Survey</title><meta property="og:description" content="Large Language Models (LLMs) have drawn a lot of attention due to their strong performance on a wide range of natural language tasks, since the release of ChatGPT in November 2022.
LLMs’ ability of general-purpose lang…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Large Language Models: A Survey">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Large Language Models: A Survey">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2402.06196">

<!--Generated on Tue Mar  5 17:44:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Large Language Models: A Survey</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu 
<br class="ltx_break">Richard Socher, Xavier Amatriain, Jianfeng Gao 
<br class="ltx_break">
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Large Language Models (LLM)은 2022년 11월에 ChatGPT가 출시된 이후 광범위한 자연어 태스크에 대한 강력한 성능으로 인해 많은 주목을 받았다. LLM의 범용 언어 이해 및 생성 능력은 법칙 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>, <a class="ltx_ref" href="#bib.bib2" title="">2</a>]</cite>를 스케일링하여 예측한 바와 같이 방대한 양의 텍스트 데이터에 대해 수십억 개의 모델의 매개변수를 훈련함으로써 획득된다. LLM의 연구 영역은 매우 최근이지만 다양한 방식으로 빠르게 발전하고 있다. 본 논문에서는 3개의 인기 있는 LLM 패밀리(GPT, LLaMA, PaLM)를 포함하여 가장 두드러진 LLM 중 일부를 검토하고 특성, 기여 및 한계에 대해 논의한다. 또한 LLM을 구축하고 확장하기 위해 개발된 기술에 대한 개요를 제공합니다. 그런 다음 LLM 훈련, 미세 조정 및 평가를 위해 준비된 인기 데이터 세트를 조사하고 널리 사용되는 LLM 평가 메트릭을 검토하고 대표적인 벤치마크 세트에 대한 여러 인기 LLM의 성능을 비교한다. 마지막으로, 열린 도전과제와 향후 연구 방향에 대해 논의함으로써 논문을 마무리한다.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p" id="S1.p1.1">언어 모델링은 1950년대 섀넌이 정보 이론을 인간 언어에 적용한 것으로 거슬러 올라가는 오랜 연구 주제이며, 여기서 그는 간단한 n-그램 언어 모델이 자연 언어 텍스트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib3" title="">3</a>]</cite>를 얼마나 잘 예측하거나 압축하는지 측정했다. 그 이후로 통계적 언어 모델링은 음성 인식, 기계 번역에서 정보 검색 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib4" title="">4</a>, <a class="ltx_ref" href="#bib.bib5" title="">5</a>, <a class="ltx_ref" href="#bib.bib6" title="">6</a>]</cite>에 이르기까지 많은 자연 언어 이해와 생성 작업에 기본이 되었다.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p" id="S1.p2.1">최근 웹 스케일의 텍스트 코퍼라에서 사전 학습된 트랜스포머 기반 대용량 언어 모델(LLM)의 발전은 언어 모델(LLM)의 기능을 크게 확장시켰다. 예를 들어 OpenAI의 ChatGPT 및 GPT-4는 자연어 처리뿐만 아니라 Microsoft의 Co-Pilot 시스템에 전원을 공급하기 위한 일반적인 작업 해결 수단으로 사용될 수 있으며, 예를 들어 필요한 경우 다단계 추론을 수행하는 복잡한 새로운 작업의 인간 명령을 따를 수 있다. 따라서 LLM은 범용 AI 에이전트 또는 인공지능(AGI) 개발을 위한 기본 구성 요소가 되고 있다.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p" id="S1.p3.1">LLM 분야가 빠르게 움직이고 있으며 새로운 발견과 함께 모델 및 기술이 몇 달 또는 몇 주 사이에 출판되는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib7" title="">7</a>, <a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib9" title="">9</a>, <a class="ltx_ref" href="#bib.bib10" title="">10</a>, <a class="ltx_ref" href="#bib.bib11" title="">11</a>]</cite>와 같이 AI 연구자와 실무자는 종종 작업에 대한 LLM 기반 AI 시스템을 구축하기 위한 최상의 레시피를 파악하는 것이 어렵다는 것을 알게 된다. 이 논문은 LLMs에 대한 최근의 진보에 대한 시기적절한 조사를 제공한다. 이 조사가 학생, 연구원 및 개발자에게 가치 있고 접근 가능한 자원이 될 수 있기를 바랍니다.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p" id="S1.p4.1">LLM은 신경망을 기반으로 하는 대규모의 사전 훈련된 통계적 언어 모델이다. 최근 LLM의 성공은 수십 년의 언어 모델 연구 및 개발의 누적이며, 이는 통계 언어 모델, 신경 언어 모델, 사전 훈련 언어 모델 및 LLM의 시작점과 속도가 다른 4가지 파동으로 분류할 수 있다.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p" id="S1.p5.1">통계 언어 모델(SLM)은 텍스트를 단어의 시퀀스로 보고, 텍스트의 확률을 단어 확률의 곱으로 추정한다. SLM의 지배적인 형태는 n-gram 모델로 알려진 마르코프 체인 모델이며, 이는 단어의 즉시 진행 <math alttext="n-1" class="ltx_Math" display="inline" id="S1.p5.1.m1.1"><semantics id="S1.p5.1.m1.1a"><mrow id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml"><mi id="S1.p5.1.m1.1.1.2" xref="S1.p5.1.m1.1.1.2.cmml">n</mi><mo id="S1.p5.1.m1.1.1.1" xref="S1.p5.1.m1.1.1.1.cmml">−</mo><mn id="S1.p5.1.m1.1.1.3" xref="S1.p5.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><apply id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1"><minus id="S1.p5.1.m1.1.1.1.cmml" xref="S1.p5.1.m1.1.1.1"></minus><ci id="S1.p5.1.m1.1.1.2.cmml" xref="S1.p5.1.m1.1.1.2">𝑛</ci><cn id="S1.p5.1.m1.1.1.3.cmml" type="integer" xref="S1.p5.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">n-1</annotation></semantics></math> 단어에 조건화된 단어의 확률을 계산한다. 단어 확률은 텍스트 말뭉치로부터 수집된 단어 및 n-gram 카운트를 사용하여 추정되기 때문에, 모델은 <em class="ltx_emph ltx_font_italic" id="S1.p5.1.1">smoothing</em>, 여기서 모델의 일부 확률 질량은 보이지 않는 n-grams <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib12" title="">12</a>]</cite>에 대해 예약된다. N-gram 모델은 많은 NLP 시스템에서 널리 사용된다. 그러나 이러한 모델은 데이터 희소성으로 인해 자연어의 다양성과 가변성을 완전히 포착할 수 없다는 점에서 불완전하다.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p class="ltx_p" id="S1.p6.1">초기 신경망 모델(NLMs) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>, <a class="ltx_ref" href="#bib.bib14" title="">14</a>, <a class="ltx_ref" href="#bib.bib15" title="">15</a>, <a class="ltx_ref" href="#bib.bib16" title="">16</a>]</cite>는 저차원 연속 벡터(embedding vector)에 단어를 매핑하여 데이터 희소성을 처리하고 신경망을 이용하여 진행 단어의 임베딩 벡터의 집계를 기반으로 다음 단어를 예측한다. NLM에 의해 학습된 임베딩 벡터는 벡터들 사이의 의미적 유사성이 그들의 거리로 쉽게 계산될 수 있는 숨겨진 공간을 정의한다. 이것은 그들의 형태들(예를 들어, 쿼리들 대 쿼리들)에 관계없이 임의의 두 입력들의 시맨틱 유사성 컴퓨팅의 문을 연다. 웹 검색의 문서 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib17" title="">17</a>, <a class="ltx_ref" href="#bib.bib18" title="">18</a>]</cite>, 기계 번역의 서로 다른 언어의 문장 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib19" title="">19</a>, <a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite>) 또는 모달리티(예: 이미지 캡션의 이미지와 텍스트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib21" title="">21</a>, <a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>) 초기 NLM은 태스크별 데이터로 학습되고 학습된 숨겨진 공간이 태스크별이라는 점에서 태스크별 모델이다.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p class="ltx_p" id="S1.p7.1">사전 훈련된 언어 모델(PLM)은 초기 NLM과 달리 작업 불가지론적이다. 이러한 일반성은 학습된 은닉 임베딩 공간으로도 확장된다. PLM의 학습과 추론은 <em class="ltx_emph ltx_font_italic" id="S1.p7.1.1">pre-training 및 fine-tuning</em> 패러다임을 따르며, 여기서 순환 신경망 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite> 또는 트랜스포머 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>, <a class="ltx_ref" href="#bib.bib25" title="">25</a>, <a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>를 가진 언어 모델은 단어 예측과 같은 일반적인 작업을 위해 웹 스케일의 레이블이 없는 텍스트 코퍼라에서 사전 훈련된 다음 소량의 (레이블된) 작업 특정 데이터를 사용하여 특정 작업으로 미세 조정된다. PLM에 대한 최근 조사에는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib27" title="">27</a>, <a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite>가 있다.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/x1.png" id="S1.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="170" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.3.1.1" style="font-size:90%;">Figure 1</span>:</span><span class="ltx_text" id="S1.F1.4.2" style="font-size:90%;">LLM Capabilities. </span></figcaption>
</figure>
<div id="S1.p8" class="ltx_para">
<p class="ltx_p" id="S1.p8.1">대형 언어 모델(LLM)은 주로 표 III에 요약된 바와 같이 PaLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>, LLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib32" title="">32</a>]</cite>, GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>와 같이 방대한 텍스트 데이터에 대해 사전 훈련된 수백억에서 수천억 개의 파라미터를 포함하는 트랜스포머 기반 신경망 언어 모델 <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Recently, several very promising non-transformer LLMs have been proposed, such as the LLMs based on structured state space models <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib29" title="">29</a>, <a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>. See Section <a class="ltx_ref" href="#S7" title="VII Challenges and Future Directions ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">VII</span></a> for more details.</span></span></span>을 말한다. PLM에 비해 LLM은 모델 크기가 훨씬 클 뿐만 아니라 더 강력한 언어 이해 및 생성 능력, 더 중요한 것은 소규모 언어 모델에는 없는 창발 능력을 나타낸다. 도면에 도시된 바와 같이. <a class="ltx_ref" href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">1</span></a>, 이러한 창발 능력은 (1) 상황 내 학습, 여기서 LLMs는 추론 시간에 프롬프트에 제시된 작은 예제 세트로부터 새로운 작업을 학습하고, (2) 명령 후속, 여기서 LLMs는 명령 튜닝 후에 명시적인 예를 사용하지 않고 새로운 유형의 작업에 대한 명령을 따를 수 있고, (3) 다단계 추론은 LLMs가 연쇄 사상 프롬프트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib34" title="">34</a>]</cite>에서 입증된 바와 같이 그 작업을 중간 추론 단계로 분해함으로써 복잡한 작업을 해결할 수 있다. LLM은 또한 외부 지식 및 도구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib35" title="">35</a>, <a class="ltx_ref" href="#bib.bib36" title="">36</a>]</cite>를 사용하여 사용자 및 환경 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib37" title="">37</a>]</cite>와 효과적으로 상호 작용할 수 있도록 증강될 수 있고, 상호 작용을 통해 수집된 피드백 데이터를 사용하여 지속적으로 자신을 개선할 수 있다(예를 들어, 인간 피드백으로 강화 학습(RLHF)을 통해).</p>
</div>
<div id="S1.p9" class="ltx_para">
<p class="ltx_p" id="S1.p9.1">고급 사용 및 증강 기술을 통해 LLM은 환경을 감지하고 결정을 내리고 조치를 취하는 인공 개체라는 소위 AI 에이전트로 배포될 수 있다. 이전 연구에서는 특정 작업 및 도메인에 대한 에이전트 개발에 중점을 두었다. LLM에 의해 입증된 새로운 능력은 LLM을 기반으로 하는 범용 AI 에이전트를 구축할 수 있게 한다. LLM은 정적 설정에서 응답을 생성하도록 훈련되지만 AI 에이전트는 동적 환경과 상호 작용하기 위한 조치를 취해야 한다. 따라서, LLM 기반 에이전트는 외부 지식 베이스로부터 업데이트된 정보를 얻고, 시스템 액션이 예상된 결과를 생성하는지 검증하고, 상황이 예상대로 진행되지 않을 때 대처하는 등 LLM을 보강해야 하는 경우가 많다. 우리는 섹션 <a class="ltx_ref" href="#S4" title="IV How LLMs Are Used and Augmented ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">IV</span></a>에서 LLM 기반 에이전트에 대해 자세히 논의할 것이다.</p>
</div>
<div id="S1.p10" class="ltx_para">
<p class="ltx_p" id="S1.p10.1">이 논문의 나머지 부분에서 섹션 <a class="ltx_ref" href="#S2" title="II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">II</span></a>는 3개의 LLM 패밀리(GPT, LLaMA 및 PaLM) 및 기타 대표적인 모델을 중심으로 LLM 기술의 개요를 제시한다. 섹션 <a class="ltx_ref" href="#S3" title="III How LLMs Are Built ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">III</span></a>에서는 LLM이 빌드되는 방법에 대해 설명합니다. 섹션 <a class="ltx_ref" href="#S4" title="IV How LLMs Are Used and Augmented ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">IV</span></a>에서는 LLM이 사용되는 방법에 대해 논의하고 실제 응용 프로그램에 대해 확장 섹션 <a class="ltx_ref" href="#S5" title="V Popular Datasets for LLMs ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">V</span></a> 및 <a class="ltx_ref" href="#S6" title="VI Prominent LLMs’ Performance on Benchmarks ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">VI</span></a>에서는 LLM을 평가하기 위한 인기 있는 데이터 세트 및 벤치마크를 검토하고 보고된 LLM 평가 결과를 요약합니다. 마지막으로 <a class="ltx_ref" href="#S7" title="VII Challenges and Future Directions ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">VII</span></a> 절에서는 과제 및 향후 연구 방향을 요약하여 논문을 마무리한다.</p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/x2.png" id="S1.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="271" height="376" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.3.1.1" style="font-size:90%;">Figure 2</span>:</span><span class="ltx_text" id="S1.F2.4.2" style="font-size:90%;">The paper structure. </span></figcaption>
</figure>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Large Language Models</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p" id="S2.p1.1">이 섹션에서는 초기 사전 훈련된 신경망 모델이 LLM의 기반이기 때문에 검토부터 시작한 다음 GPT, LlaMA 및 PaLM의 세 가지 LLM 계열에 대한 논의를 집중한다. 표 <a class="ltx_ref" href="#S2.T1" title="TABLE I ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">I</span></a>는 이들 모델 중 일부 모델과 그 특성에 대한 개요를 제공한다.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S2.T1.16.1.1" style="font-size:90%;">TABLE I</span>:</span><span class="ltx_text" id="S2.T1.17.2" style="font-size:90%;">High-level Overview of Popular Language Models</span></figcaption>
<table id="S2.T1.14" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.14.15.1" class="ltx_tr">
<td id="S2.T1.14.15.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T1.14.15.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.15.1.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S2.T1.14.15.1.1.1.1.1" class="ltx_text ltx_font_bold">Type</span></span>
</span>
</td>
<td id="S2.T1.14.15.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T1.14.15.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.15.1.2.1.1" class="ltx_p" style="width:48.4pt;"><span id="S2.T1.14.15.1.2.1.1.1" class="ltx_text ltx_font_bold">Model Name</span></span>
</span>
</td>
<td id="S2.T1.14.15.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T1.14.15.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.15.1.3.1.1" class="ltx_p" style="width:56.9pt;"><span id="S2.T1.14.15.1.3.1.1.1" class="ltx_text ltx_font_bold">#Parameters</span></span>
</span>
</td>
<td id="S2.T1.14.15.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T1.14.15.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.15.1.4.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.14.15.1.4.1.1.1" class="ltx_text ltx_font_bold">Release</span></span>
</span>
</td>
<td id="S2.T1.14.15.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T1.14.15.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.15.1.5.1.1" class="ltx_p" style="width:42.7pt;"><span id="S2.T1.14.15.1.5.1.1.1" class="ltx_text ltx_font_bold">Base Models</span></span>
</span>
</td>
<td id="S2.T1.14.15.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T1.14.15.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.15.1.6.1.1" class="ltx_p" style="width:22.8pt;"><span id="S2.T1.14.15.1.6.1.1.1" class="ltx_text ltx_font_bold">Open Source</span></span>
</span>
</td>
<td id="S2.T1.14.15.1.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T1.14.15.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.15.1.7.1.1" class="ltx_p" style="width:28.5pt;"><span id="S2.T1.14.15.1.7.1.1.1" class="ltx_text ltx_font_bold">#Tokens</span></span>
</span>
</td>
<td id="S2.T1.14.15.1.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S2.T1.14.15.1.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.15.1.8.1.1" class="ltx_p" style="width:142.3pt;"><span id="S2.T1.14.15.1.8.1.1.1" class="ltx_text ltx_font_bold">Training dataset</span></span>
</span>
</td>
</tr>
<tr id="S2.T1.14.16.2" class="ltx_tr">
<td id="S2.T1.14.16.2.1" class="ltx_td ltx_align_top ltx_border_t"></td>
<td id="S2.T1.14.16.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.16.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.16.2.2.1.1" class="ltx_p" style="width:48.4pt;">BERT</span>
</span>
</td>
<td id="S2.T1.14.16.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.16.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.16.2.3.1.1" class="ltx_p" style="width:56.9pt;">110M, 340M</span>
</span>
</td>
<td id="S2.T1.14.16.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.16.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.16.2.4.1.1" class="ltx_p" style="width:28.5pt;">2018</span>
</span>
</td>
<td id="S2.T1.14.16.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.16.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.16.2.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.16.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.16.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.16.2.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.16.2.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.16.2.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.16.2.7.1.1" class="ltx_p" style="width:28.5pt;">137B</span>
</span>
</td>
<td id="S2.T1.14.16.2.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.16.2.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.16.2.8.1.1" class="ltx_p" style="width:142.3pt;">BooksCorpus, English Wikipedia</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.17.3" class="ltx_tr">
<td id="S2.T1.14.17.3.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.17.3.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.17.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.17.3.2.1.1" class="ltx_p" style="width:48.4pt;">RoBERTa</span>
</span>
</td>
<td id="S2.T1.14.17.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.17.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.17.3.3.1.1" class="ltx_p" style="width:56.9pt;">355M</span>
</span>
</td>
<td id="S2.T1.14.17.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.17.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.17.3.4.1.1" class="ltx_p" style="width:28.5pt;">2019</span>
</span>
</td>
<td id="S2.T1.14.17.3.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.17.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.17.3.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.17.3.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.17.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.17.3.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.17.3.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.17.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.17.3.7.1.1" class="ltx_p" style="width:28.5pt;">2.2T</span>
</span>
</td>
<td id="S2.T1.14.17.3.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.17.3.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.17.3.8.1.1" class="ltx_p" style="width:142.3pt;">BooksCorpus, English Wikipedia, CC-NEWS, STORIES (a subset of Common Crawl), Reddit</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.18.4" class="ltx_tr">
<td id="S2.T1.14.18.4.1" class="ltx_td ltx_align_justify ltx_align_top" rowspan="2">
<span id="S2.T1.14.18.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.18.4.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S2.T1.14.18.4.1.1.1.1" class="ltx_text ltx_font_bold">Encoder-Only</span></span>
</span>
</td>
<td id="S2.T1.14.18.4.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.18.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.18.4.2.1.1" class="ltx_p" style="width:48.4pt;">ALBERT</span>
</span>
</td>
<td id="S2.T1.14.18.4.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.18.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.18.4.3.1.1" class="ltx_p" style="width:56.9pt;">12M, 18M, 60M, 235M</span>
</span>
</td>
<td id="S2.T1.14.18.4.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.18.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.18.4.4.1.1" class="ltx_p" style="width:28.5pt;">2019</span>
</span>
</td>
<td id="S2.T1.14.18.4.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.18.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.18.4.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.18.4.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.18.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.18.4.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.18.4.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.18.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.18.4.7.1.1" class="ltx_p" style="width:28.5pt;">137B</span>
</span>
</td>
<td id="S2.T1.14.18.4.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.18.4.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.18.4.8.1.1" class="ltx_p" style="width:142.3pt;">BooksCorpus, English Wikipedia</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.19.5" class="ltx_tr">
<td id="S2.T1.14.19.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.19.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.19.5.1.1.1" class="ltx_p" style="width:48.4pt;">DeBERTa</span>
</span>
</td>
<td id="S2.T1.14.19.5.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.19.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.19.5.2.1.1" class="ltx_p" style="width:56.9pt;">-</span>
</span>
</td>
<td id="S2.T1.14.19.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.19.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.19.5.3.1.1" class="ltx_p" style="width:28.5pt;">2020</span>
</span>
</td>
<td id="S2.T1.14.19.5.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.19.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.19.5.4.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.19.5.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.19.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.19.5.5.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.19.5.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.19.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.19.5.6.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.14.19.5.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.19.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.19.5.7.1.1" class="ltx_p" style="width:142.3pt;">BooksCorpus, English Wikipedia, STORIES, Reddit content</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.20.6" class="ltx_tr">
<td id="S2.T1.14.20.6.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.20.6.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.20.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.20.6.2.1.1" class="ltx_p" style="width:48.4pt;">XLNet</span>
</span>
</td>
<td id="S2.T1.14.20.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.20.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.20.6.3.1.1" class="ltx_p" style="width:56.9pt;">110M, 340M</span>
</span>
</td>
<td id="S2.T1.14.20.6.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.20.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.20.6.4.1.1" class="ltx_p" style="width:28.5pt;">2019</span>
</span>
</td>
<td id="S2.T1.14.20.6.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.20.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.20.6.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.20.6.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.20.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.20.6.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.20.6.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.20.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.20.6.7.1.1" class="ltx_p" style="width:28.5pt;">32.89B</span>
</span>
</td>
<td id="S2.T1.14.20.6.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.20.6.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.20.6.8.1.1" class="ltx_p" style="width:142.3pt;">BooksCorpus, English Wikipedia, Giga5, Common Crawl, ClueWeb 2012-B</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.21.7" class="ltx_tr">
<td id="S2.T1.14.21.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" rowspan="2">
<span id="S2.T1.14.21.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.21.7.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S2.T1.14.21.7.1.1.1.1" class="ltx_text ltx_font_bold">Decoder-only</span></span>
</span>
</td>
<td id="S2.T1.14.21.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.21.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.21.7.2.1.1" class="ltx_p" style="width:48.4pt;">GPT-1</span>
</span>
</td>
<td id="S2.T1.14.21.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.21.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.21.7.3.1.1" class="ltx_p" style="width:56.9pt;">120M</span>
</span>
</td>
<td id="S2.T1.14.21.7.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.21.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.21.7.4.1.1" class="ltx_p" style="width:28.5pt;">2018</span>
</span>
</td>
<td id="S2.T1.14.21.7.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.21.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.21.7.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.21.7.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.21.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.21.7.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.21.7.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.21.7.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.21.7.7.1.1" class="ltx_p" style="width:28.5pt;">1.3B</span>
</span>
</td>
<td id="S2.T1.14.21.7.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.21.7.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.21.7.8.1.1" class="ltx_p" style="width:142.3pt;">BooksCorpus</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.22.8" class="ltx_tr">
<td id="S2.T1.14.22.8.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.22.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.22.8.1.1.1" class="ltx_p" style="width:48.4pt;">GPT-2</span>
</span>
</td>
<td id="S2.T1.14.22.8.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.22.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.22.8.2.1.1" class="ltx_p" style="width:56.9pt;">1.5B</span>
</span>
</td>
<td id="S2.T1.14.22.8.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.22.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.22.8.3.1.1" class="ltx_p" style="width:28.5pt;">2019</span>
</span>
</td>
<td id="S2.T1.14.22.8.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.22.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.22.8.4.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.22.8.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.22.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.22.8.5.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.22.8.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.22.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.22.8.6.1.1" class="ltx_p" style="width:28.5pt;">10B</span>
</span>
</td>
<td id="S2.T1.14.22.8.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.22.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.22.8.7.1.1" class="ltx_p" style="width:142.3pt;">Reddit outbound</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.23.9" class="ltx_tr">
<td id="S2.T1.14.23.9.1" class="ltx_td ltx_align_top ltx_border_t"></td>
<td id="S2.T1.14.23.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.23.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.23.9.2.1.1" class="ltx_p" style="width:48.4pt;">T5 (Base)</span>
</span>
</td>
<td id="S2.T1.14.23.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.23.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.23.9.3.1.1" class="ltx_p" style="width:56.9pt;">223M</span>
</span>
</td>
<td id="S2.T1.14.23.9.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.23.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.23.9.4.1.1" class="ltx_p" style="width:28.5pt;">2019</span>
</span>
</td>
<td id="S2.T1.14.23.9.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.23.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.23.9.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.23.9.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.23.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.23.9.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.23.9.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.23.9.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.23.9.7.1.1" class="ltx_p" style="width:28.5pt;">156B</span>
</span>
</td>
<td id="S2.T1.14.23.9.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.23.9.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.23.9.8.1.1" class="ltx_p" style="width:142.3pt;">Common Crawl</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.24.10" class="ltx_tr">
<td id="S2.T1.14.24.10.1" class="ltx_td ltx_align_justify ltx_align_top" rowspan="2">
<span id="S2.T1.14.24.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.24.10.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S2.T1.14.24.10.1.1.1.1" class="ltx_text ltx_font_bold">Encoder-Decoder</span></span>
</span>
</td>
<td id="S2.T1.14.24.10.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.24.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.24.10.2.1.1" class="ltx_p" style="width:48.4pt;">MT5 (Base)</span>
</span>
</td>
<td id="S2.T1.14.24.10.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.24.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.24.10.3.1.1" class="ltx_p" style="width:56.9pt;">300M</span>
</span>
</td>
<td id="S2.T1.14.24.10.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.24.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.24.10.4.1.1" class="ltx_p" style="width:28.5pt;">2020</span>
</span>
</td>
<td id="S2.T1.14.24.10.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.24.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.24.10.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.24.10.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.24.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.24.10.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.24.10.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.24.10.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.24.10.7.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.14.24.10.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.24.10.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.24.10.8.1.1" class="ltx_p" style="width:142.3pt;">New Common Crawl-based dataset in 101 languages (m Common Crawl)</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.25.11" class="ltx_tr">
<td id="S2.T1.14.25.11.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.25.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.25.11.1.1.1" class="ltx_p" style="width:48.4pt;">BART (Base)</span>
</span>
</td>
<td id="S2.T1.14.25.11.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.25.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.25.11.2.1.1" class="ltx_p" style="width:56.9pt;">139M</span>
</span>
</td>
<td id="S2.T1.14.25.11.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.25.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.25.11.3.1.1" class="ltx_p" style="width:28.5pt;">2019</span>
</span>
</td>
<td id="S2.T1.14.25.11.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.25.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.25.11.4.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.25.11.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.25.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.25.11.5.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.25.11.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.25.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.25.11.6.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.14.25.11.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.25.11.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.25.11.7.1.1" class="ltx_p" style="width:142.3pt;">Corrupting text</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.2" class="ltx_td ltx_align_top ltx_border_t"></td>
<td id="S2.T1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.3.1.1" class="ltx_p" style="width:48.4pt;">GPT-3</span>
</span>
</td>
<td id="S2.T1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.4.1.1" class="ltx_p" style="width:56.9pt;">125M, 350M, 760M, 1.3B, 2.7B, 6.7B, 13B, 175B</span>
</span>
</td>
<td id="S2.T1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.5.1.1" class="ltx_p" style="width:28.5pt;">2020</span>
</span>
</td>
<td id="S2.T1.1.1.6" class="ltx_td ltx_align_top ltx_border_t"></td>
<td id="S2.T1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.1.1" class="ltx_p" style="width:22.8pt;"><math id="S2.T1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.1.1.1.1.1.m1.1a"><mo id="S2.T1.1.1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.1.1.m1.1b"><times id="S2.T1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T1.1.1.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.7.1.1" class="ltx_p" style="width:28.5pt;">300B</span>
</span>
</td>
<td id="S2.T1.1.1.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.1.1.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.8.1.1" class="ltx_p" style="width:142.3pt;">Common Crawl (filtered), WebText2, Books1, Books2, Wikipedia</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.26.12" class="ltx_tr">
<td id="S2.T1.14.26.12.1" class="ltx_td ltx_align_justify ltx_align_top" rowspan="2">
<span id="S2.T1.14.26.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.26.12.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S2.T1.14.26.12.1.1.1.1" class="ltx_text ltx_font_bold">GPT Family</span></span>
</span>
</td>
<td id="S2.T1.14.26.12.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.26.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.26.12.2.1.1" class="ltx_p" style="width:48.4pt;">CODEX</span>
</span>
</td>
<td id="S2.T1.14.26.12.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.26.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.26.12.3.1.1" class="ltx_p" style="width:56.9pt;">12B</span>
</span>
</td>
<td id="S2.T1.14.26.12.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.26.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.26.12.4.1.1" class="ltx_p" style="width:28.5pt;">2021</span>
</span>
</td>
<td id="S2.T1.14.26.12.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.26.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.26.12.5.1.1" class="ltx_p" style="width:42.7pt;">GPT</span>
</span>
</td>
<td id="S2.T1.14.26.12.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.26.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.26.12.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.26.12.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.26.12.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.26.12.7.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.14.26.12.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.26.12.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.26.12.8.1.1" class="ltx_p" style="width:142.3pt;">Public GitHub software repositories</span>
</span>
</td>
</tr>
<tr id="S2.T1.2.2" class="ltx_tr">
<td id="S2.T1.2.2.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.2.2.2.1.1" class="ltx_p" style="width:48.4pt;">WebGPT</span>
</span>
</td>
<td id="S2.T1.2.2.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.2.2.3.1.1" class="ltx_p" style="width:56.9pt;">760M, 13B, 175B</span>
</span>
</td>
<td id="S2.T1.2.2.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.2.2.4.1.1" class="ltx_p" style="width:28.5pt;">2021</span>
</span>
</td>
<td id="S2.T1.2.2.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.2.2.5.1.1" class="ltx_p" style="width:42.7pt;">GPT-3</span>
</span>
</td>
<td id="S2.T1.2.2.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.2.2.1.1.1" class="ltx_p" style="width:22.8pt;"><math id="S2.T1.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.2.2.1.1.1.m1.1a"><mo id="S2.T1.2.2.1.1.1.m1.1.1" xref="S2.T1.2.2.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.1.1.1.m1.1b"><times id="S2.T1.2.2.1.1.1.m1.1.1.cmml" xref="S2.T1.2.2.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T1.2.2.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.2.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.2.2.6.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.2.2.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.2.2.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.2.2.7.1.1" class="ltx_p" style="width:142.3pt;">ELI5</span>
</span>
</td>
</tr>
<tr id="S2.T1.3.3" class="ltx_tr">
<td id="S2.T1.3.3.2" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.3.3.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.3.3.3.1.1" class="ltx_p" style="width:48.4pt;">GPT-4</span>
</span>
</td>
<td id="S2.T1.3.3.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.3.3.4.1.1" class="ltx_p" style="width:56.9pt;">1.76T</span>
</span>
</td>
<td id="S2.T1.3.3.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.3.3.5.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.3.3.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.3.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.3.3.6.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.3.3.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.3.3.1.1.1" class="ltx_p" style="width:22.8pt;"><math id="S2.T1.3.3.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.3.3.1.1.1.m1.1a"><mo id="S2.T1.3.3.1.1.1.m1.1.1" xref="S2.T1.3.3.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.1.1.1.m1.1b"><times id="S2.T1.3.3.1.1.1.m1.1.1.cmml" xref="S2.T1.3.3.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T1.3.3.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.3.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.3.3.7.1.1" class="ltx_p" style="width:28.5pt;">13T</span>
</span>
</td>
<td id="S2.T1.3.3.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.3.3.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.3.3.8.1.1" class="ltx_p" style="width:142.3pt;">-</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.27.13" class="ltx_tr">
<td id="S2.T1.14.27.13.1" class="ltx_td ltx_align_top ltx_border_t"></td>
<td id="S2.T1.14.27.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.27.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.27.13.2.1.1" class="ltx_p" style="width:48.4pt;">LLaMA1</span>
</span>
</td>
<td id="S2.T1.14.27.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.27.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.27.13.3.1.1" class="ltx_p" style="width:56.9pt;">7B, 13B, 33B, 65B</span>
</span>
</td>
<td id="S2.T1.14.27.13.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.27.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.27.13.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.27.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.27.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.27.13.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.27.13.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.27.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.27.13.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.27.13.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.27.13.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.27.13.7.1.1" class="ltx_p" style="width:28.5pt;">1T, 1.4T</span>
</span>
</td>
<td id="S2.T1.14.27.13.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.27.13.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.27.13.8.1.1" class="ltx_p" style="width:142.3pt;">Online sources</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.28.14" class="ltx_tr">
<td id="S2.T1.14.28.14.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.28.14.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.28.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.28.14.2.1.1" class="ltx_p" style="width:48.4pt;">LLaMA2</span>
</span>
</td>
<td id="S2.T1.14.28.14.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.28.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.28.14.3.1.1" class="ltx_p" style="width:56.9pt;">7B, 13B, 34B, 70B</span>
</span>
</td>
<td id="S2.T1.14.28.14.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.28.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.28.14.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.28.14.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.28.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.28.14.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.28.14.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.28.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.28.14.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.28.14.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.28.14.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.28.14.7.1.1" class="ltx_p" style="width:28.5pt;">2T</span>
</span>
</td>
<td id="S2.T1.14.28.14.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.28.14.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.28.14.8.1.1" class="ltx_p" style="width:142.3pt;">Online sources</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.29.15" class="ltx_tr">
<td id="S2.T1.14.29.15.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.29.15.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.29.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.29.15.2.1.1" class="ltx_p" style="width:48.4pt;">Alpaca</span>
</span>
</td>
<td id="S2.T1.14.29.15.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.29.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.29.15.3.1.1" class="ltx_p" style="width:56.9pt;">7B</span>
</span>
</td>
<td id="S2.T1.14.29.15.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.29.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.29.15.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.29.15.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.29.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.29.15.5.1.1" class="ltx_p" style="width:42.7pt;">LLaMA1</span>
</span>
</td>
<td id="S2.T1.14.29.15.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.29.15.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.29.15.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.29.15.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.29.15.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.29.15.7.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.14.29.15.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.29.15.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.29.15.8.1.1" class="ltx_p" style="width:142.3pt;">GPT-3.5</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.30.16" class="ltx_tr">
<td id="S2.T1.14.30.16.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.30.16.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.30.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.30.16.2.1.1" class="ltx_p" style="width:48.4pt;">Vicuna-13B</span>
</span>
</td>
<td id="S2.T1.14.30.16.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.30.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.30.16.3.1.1" class="ltx_p" style="width:56.9pt;">13B</span>
</span>
</td>
<td id="S2.T1.14.30.16.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.30.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.30.16.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.30.16.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.30.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.30.16.5.1.1" class="ltx_p" style="width:42.7pt;">LLaMA1</span>
</span>
</td>
<td id="S2.T1.14.30.16.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.30.16.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.30.16.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.30.16.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.30.16.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.30.16.7.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.14.30.16.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.30.16.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.30.16.8.1.1" class="ltx_p" style="width:142.3pt;">GPT-3.5</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.31.17" class="ltx_tr">
<td id="S2.T1.14.31.17.1" class="ltx_td ltx_align_justify ltx_align_top" rowspan="2">
<span id="S2.T1.14.31.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.31.17.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S2.T1.14.31.17.1.1.1.1" class="ltx_text ltx_font_bold">LLaMA Family</span></span>
</span>
</td>
<td id="S2.T1.14.31.17.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.31.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.31.17.2.1.1" class="ltx_p" style="width:48.4pt;">Koala</span>
</span>
</td>
<td id="S2.T1.14.31.17.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.31.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.31.17.3.1.1" class="ltx_p" style="width:56.9pt;">13B</span>
</span>
</td>
<td id="S2.T1.14.31.17.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.31.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.31.17.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.31.17.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.31.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.31.17.5.1.1" class="ltx_p" style="width:42.7pt;">LLaMA</span>
</span>
</td>
<td id="S2.T1.14.31.17.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.31.17.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.31.17.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.31.17.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.31.17.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.31.17.7.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.14.31.17.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.31.17.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.31.17.8.1.1" class="ltx_p" style="width:142.3pt;">Dialogue data</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.32.18" class="ltx_tr">
<td id="S2.T1.14.32.18.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.32.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.32.18.1.1.1" class="ltx_p" style="width:48.4pt;">Mistral-7B</span>
</span>
</td>
<td id="S2.T1.14.32.18.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.32.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.32.18.2.1.1" class="ltx_p" style="width:56.9pt;">7.3B</span>
</span>
</td>
<td id="S2.T1.14.32.18.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.32.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.32.18.3.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.32.18.4" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.32.18.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.32.18.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.32.18.5.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.32.18.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.32.18.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.32.18.6.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.14.32.18.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.32.18.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.32.18.7.1.1" class="ltx_p" style="width:142.3pt;">-</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.33.19" class="ltx_tr">
<td id="S2.T1.14.33.19.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.33.19.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.33.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.33.19.2.1.1" class="ltx_p" style="width:48.4pt;">Code Llama</span>
</span>
</td>
<td id="S2.T1.14.33.19.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.33.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.33.19.3.1.1" class="ltx_p" style="width:56.9pt;">34</span>
</span>
</td>
<td id="S2.T1.14.33.19.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.33.19.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.33.19.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.33.19.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.33.19.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.33.19.5.1.1" class="ltx_p" style="width:42.7pt;">LLaMA2</span>
</span>
</td>
<td id="S2.T1.14.33.19.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.33.19.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.33.19.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.33.19.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.33.19.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.33.19.7.1.1" class="ltx_p" style="width:28.5pt;">500B</span>
</span>
</td>
<td id="S2.T1.14.33.19.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.33.19.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.33.19.8.1.1" class="ltx_p" style="width:142.3pt;">Publicly available code</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.34.20" class="ltx_tr">
<td id="S2.T1.14.34.20.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.34.20.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.34.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.34.20.2.1.1" class="ltx_p" style="width:48.4pt;">LongLLaMA</span>
</span>
</td>
<td id="S2.T1.14.34.20.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.34.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.34.20.3.1.1" class="ltx_p" style="width:56.9pt;">3B, 7B</span>
</span>
</td>
<td id="S2.T1.14.34.20.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.34.20.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.34.20.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.34.20.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.34.20.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.34.20.5.1.1" class="ltx_p" style="width:42.7pt;">OpenLLaMA</span>
</span>
</td>
<td id="S2.T1.14.34.20.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.34.20.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.34.20.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.34.20.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.34.20.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.34.20.7.1.1" class="ltx_p" style="width:28.5pt;">1T</span>
</span>
</td>
<td id="S2.T1.14.34.20.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.34.20.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.34.20.8.1.1" class="ltx_p" style="width:142.3pt;">-</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.35.21" class="ltx_tr">
<td id="S2.T1.14.35.21.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.35.21.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.35.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.35.21.2.1.1" class="ltx_p" style="width:48.4pt;">LLaMA-Pro-8B</span>
</span>
</td>
<td id="S2.T1.14.35.21.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.35.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.35.21.3.1.1" class="ltx_p" style="width:56.9pt;">8.3B</span>
</span>
</td>
<td id="S2.T1.14.35.21.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.35.21.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.35.21.4.1.1" class="ltx_p" style="width:28.5pt;">2024</span>
</span>
</td>
<td id="S2.T1.14.35.21.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.35.21.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.35.21.5.1.1" class="ltx_p" style="width:42.7pt;">LLaMA2-7B</span>
</span>
</td>
<td id="S2.T1.14.35.21.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.35.21.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.35.21.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.35.21.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.35.21.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.35.21.7.1.1" class="ltx_p" style="width:28.5pt;">80B</span>
</span>
</td>
<td id="S2.T1.14.35.21.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.35.21.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.35.21.8.1.1" class="ltx_p" style="width:142.3pt;">Code and math corpora</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.36.22" class="ltx_tr">
<td id="S2.T1.14.36.22.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.36.22.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.36.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.36.22.2.1.1" class="ltx_p" style="width:48.4pt;">TinyLlama-1.1B</span>
</span>
</td>
<td id="S2.T1.14.36.22.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.36.22.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.36.22.3.1.1" class="ltx_p" style="width:56.9pt;">1.1B</span>
</span>
</td>
<td id="S2.T1.14.36.22.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.36.22.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.36.22.4.1.1" class="ltx_p" style="width:28.5pt;">2024</span>
</span>
</td>
<td id="S2.T1.14.36.22.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.36.22.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.36.22.5.1.1" class="ltx_p" style="width:42.7pt;">LLaMA1.1B</span>
</span>
</td>
<td id="S2.T1.14.36.22.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.36.22.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.36.22.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.36.22.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.36.22.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.36.22.7.1.1" class="ltx_p" style="width:28.5pt;">3T</span>
</span>
</td>
<td id="S2.T1.14.36.22.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.36.22.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.36.22.8.1.1" class="ltx_p" style="width:142.3pt;">SlimPajama, Starcoderdata</span>
</span>
</td>
</tr>
<tr id="S2.T1.4.4" class="ltx_tr">
<td id="S2.T1.4.4.2" class="ltx_td ltx_align_top ltx_border_t"></td>
<td id="S2.T1.4.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.4.3.1.1" class="ltx_p" style="width:48.4pt;">PaLM</span>
</span>
</td>
<td id="S2.T1.4.4.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.4.4.1.1" class="ltx_p" style="width:56.9pt;">8B, 62B, 540B</span>
</span>
</td>
<td id="S2.T1.4.4.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.4.5.1.1" class="ltx_p" style="width:28.5pt;">2022</span>
</span>
</td>
<td id="S2.T1.4.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.4.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.4.6.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.4.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.4.1.1.1" class="ltx_p" style="width:22.8pt;"><math id="S2.T1.4.4.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.4.4.1.1.1.m1.1a"><mo id="S2.T1.4.4.1.1.1.m1.1.1" xref="S2.T1.4.4.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.1.1.1.m1.1b"><times id="S2.T1.4.4.1.1.1.m1.1.1.cmml" xref="S2.T1.4.4.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T1.4.4.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.4.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.4.7.1.1" class="ltx_p" style="width:28.5pt;">780B</span>
</span>
</td>
<td id="S2.T1.4.4.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.4.4.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.4.4.8.1.1" class="ltx_p" style="width:142.3pt;">Web documents, books, Wikipedia, conversations, GitHub code</span>
</span>
</td>
</tr>
<tr id="S2.T1.5.5" class="ltx_tr">
<td id="S2.T1.5.5.2" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.5.5.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.5.5.3.1.1" class="ltx_p" style="width:48.4pt;">U-PaLM</span>
</span>
</td>
<td id="S2.T1.5.5.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.5.5.4.1.1" class="ltx_p" style="width:56.9pt;">8B, 62B, 540B</span>
</span>
</td>
<td id="S2.T1.5.5.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.5.5.5.1.1" class="ltx_p" style="width:28.5pt;">2022</span>
</span>
</td>
<td id="S2.T1.5.5.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.5.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.5.5.6.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.5.5.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.5.5.1.1.1" class="ltx_p" style="width:22.8pt;"><math id="S2.T1.5.5.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.5.5.1.1.1.m1.1a"><mo id="S2.T1.5.5.1.1.1.m1.1.1" xref="S2.T1.5.5.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.5.5.1.1.1.m1.1b"><times id="S2.T1.5.5.1.1.1.m1.1.1.cmml" xref="S2.T1.5.5.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.5.5.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T1.5.5.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.5.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.5.5.7.1.1" class="ltx_p" style="width:28.5pt;">1.3B</span>
</span>
</td>
<td id="S2.T1.5.5.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.5.5.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.5.5.8.1.1" class="ltx_p" style="width:142.3pt;">Web documents, books, Wikipedia, conversations, GitHub code</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.37.23" class="ltx_tr">
<td id="S2.T1.14.37.23.1" class="ltx_td ltx_align_justify ltx_align_top" rowspan="2">
<span id="S2.T1.14.37.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.37.23.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S2.T1.14.37.23.1.1.1.1" class="ltx_text ltx_font_bold">PaLM Family</span></span>
</span>
</td>
<td id="S2.T1.14.37.23.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.37.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.37.23.2.1.1" class="ltx_p" style="width:48.4pt;">PaLM-2</span>
</span>
</td>
<td id="S2.T1.14.37.23.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.37.23.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.37.23.3.1.1" class="ltx_p" style="width:56.9pt;">340B</span>
</span>
</td>
<td id="S2.T1.14.37.23.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.37.23.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.37.23.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.37.23.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.37.23.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.37.23.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.37.23.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.37.23.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.37.23.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.37.23.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.37.23.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.37.23.7.1.1" class="ltx_p" style="width:28.5pt;">3.6T</span>
</span>
</td>
<td id="S2.T1.14.37.23.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.37.23.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.37.23.8.1.1" class="ltx_p" style="width:142.3pt;">Web documents, books, code, mathematics, conversational data</span>
</span>
</td>
</tr>
<tr id="S2.T1.6.6" class="ltx_tr">
<td id="S2.T1.6.6.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.6.6.2.1.1" class="ltx_p" style="width:48.4pt;">Med-PaLM</span>
</span>
</td>
<td id="S2.T1.6.6.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.6.6.3.1.1" class="ltx_p" style="width:56.9pt;">540B</span>
</span>
</td>
<td id="S2.T1.6.6.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.6.6.4.1.1" class="ltx_p" style="width:28.5pt;">2022</span>
</span>
</td>
<td id="S2.T1.6.6.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.6.6.5.1.1" class="ltx_p" style="width:42.7pt;">PaLM</span>
</span>
</td>
<td id="S2.T1.6.6.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.6.6.1.1.1" class="ltx_p" style="width:22.8pt;"><math id="S2.T1.6.6.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.6.6.1.1.1.m1.1a"><mo id="S2.T1.6.6.1.1.1.m1.1.1" xref="S2.T1.6.6.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.6.6.1.1.1.m1.1b"><times id="S2.T1.6.6.1.1.1.m1.1.1.cmml" xref="S2.T1.6.6.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.6.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T1.6.6.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.6.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.6.6.6.1.1" class="ltx_p" style="width:28.5pt;">780B</span>
</span>
</td>
<td id="S2.T1.6.6.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.6.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.6.6.7.1.1" class="ltx_p" style="width:142.3pt;">HealthSearchQA, MedicationQA, LiveQA</span>
</span>
</td>
</tr>
<tr id="S2.T1.7.7" class="ltx_tr">
<td id="S2.T1.7.7.2" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.7.7.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.7.7.3.1.1" class="ltx_p" style="width:48.4pt;">Med-PaLM 2</span>
</span>
</td>
<td id="S2.T1.7.7.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.7.7.4.1.1" class="ltx_p" style="width:56.9pt;">-</span>
</span>
</td>
<td id="S2.T1.7.7.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.7.7.5.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.7.7.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.7.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.7.7.6.1.1" class="ltx_p" style="width:42.7pt;">PaLM 2</span>
</span>
</td>
<td id="S2.T1.7.7.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.7.7.1.1.1" class="ltx_p" style="width:22.8pt;"><math id="S2.T1.7.7.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.7.7.1.1.1.m1.1a"><mo id="S2.T1.7.7.1.1.1.m1.1.1" xref="S2.T1.7.7.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.7.7.1.1.1.m1.1b"><times id="S2.T1.7.7.1.1.1.m1.1.1.cmml" xref="S2.T1.7.7.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.7.7.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T1.7.7.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.7.7.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.7.7.7.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.7.7.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.7.7.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.7.7.8.1.1" class="ltx_p" style="width:142.3pt;">MedQA, MedMCQA, HealthSearchQA, LiveQA, MedicationQA</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.38.24" class="ltx_tr">
<td id="S2.T1.14.38.24.1" class="ltx_td ltx_align_top ltx_border_t"></td>
<td id="S2.T1.14.38.24.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.38.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.38.24.2.1.1" class="ltx_p" style="width:48.4pt;">FLAN</span>
</span>
</td>
<td id="S2.T1.14.38.24.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.38.24.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.38.24.3.1.1" class="ltx_p" style="width:56.9pt;">137B</span>
</span>
</td>
<td id="S2.T1.14.38.24.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.38.24.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.38.24.4.1.1" class="ltx_p" style="width:28.5pt;">2021</span>
</span>
</td>
<td id="S2.T1.14.38.24.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.38.24.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.38.24.5.1.1" class="ltx_p" style="width:42.7pt;">LaMDA-PT</span>
</span>
</td>
<td id="S2.T1.14.38.24.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.38.24.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.38.24.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.38.24.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.38.24.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.38.24.7.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.14.38.24.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S2.T1.14.38.24.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.38.24.8.1.1" class="ltx_p" style="width:142.3pt;">Web documents, code, dialog data, Wikipedia</span>
</span>
</td>
</tr>
<tr id="S2.T1.8.8" class="ltx_tr">
<td id="S2.T1.8.8.2" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.8.8.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.8.8.3.1.1" class="ltx_p" style="width:48.4pt;">Gopher</span>
</span>
</td>
<td id="S2.T1.8.8.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.8.8.4.1.1" class="ltx_p" style="width:56.9pt;">280B</span>
</span>
</td>
<td id="S2.T1.8.8.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.8.8.5.1.1" class="ltx_p" style="width:28.5pt;">2021</span>
</span>
</td>
<td id="S2.T1.8.8.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.8.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.8.8.6.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.8.8.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.8.8.1.1.1" class="ltx_p" style="width:22.8pt;"><math id="S2.T1.8.8.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.8.8.1.1.1.m1.1a"><mo id="S2.T1.8.8.1.1.1.m1.1.1" xref="S2.T1.8.8.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.8.8.1.1.1.m1.1b"><times id="S2.T1.8.8.1.1.1.m1.1.1.cmml" xref="S2.T1.8.8.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.8.8.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T1.8.8.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.8.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.8.8.7.1.1" class="ltx_p" style="width:28.5pt;">300B</span>
</span>
</td>
<td id="S2.T1.8.8.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.8.8.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.8.8.8.1.1" class="ltx_p" style="width:142.3pt;">MassiveText</span>
</span>
</td>
</tr>
<tr id="S2.T1.9.9" class="ltx_tr">
<td id="S2.T1.9.9.2" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.9.9.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.9.9.3.1.1" class="ltx_p" style="width:48.4pt;">ERNIE 4.0</span>
</span>
</td>
<td id="S2.T1.9.9.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.9.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.9.9.4.1.1" class="ltx_p" style="width:56.9pt;">10B</span>
</span>
</td>
<td id="S2.T1.9.9.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.9.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.9.9.5.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.9.9.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.9.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.9.9.6.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.9.9.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.9.9.1.1.1" class="ltx_p" style="width:22.8pt;"><math id="S2.T1.9.9.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.9.9.1.1.1.m1.1a"><mo id="S2.T1.9.9.1.1.1.m1.1.1" xref="S2.T1.9.9.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.9.9.1.1.1.m1.1b"><times id="S2.T1.9.9.1.1.1.m1.1.1.cmml" xref="S2.T1.9.9.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.9.9.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T1.9.9.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.9.9.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.9.9.7.1.1" class="ltx_p" style="width:28.5pt;">4TB</span>
</span>
</td>
<td id="S2.T1.9.9.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.9.9.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.9.9.8.1.1" class="ltx_p" style="width:142.3pt;">Chinese text</span>
</span>
</td>
</tr>
<tr id="S2.T1.10.10" class="ltx_tr">
<td id="S2.T1.10.10.2" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.10.10.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.10.10.3.1.1" class="ltx_p" style="width:48.4pt;">Retro</span>
</span>
</td>
<td id="S2.T1.10.10.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.10.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.10.10.4.1.1" class="ltx_p" style="width:56.9pt;">7.5B</span>
</span>
</td>
<td id="S2.T1.10.10.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.10.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.10.10.5.1.1" class="ltx_p" style="width:28.5pt;">2021</span>
</span>
</td>
<td id="S2.T1.10.10.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.10.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.10.10.6.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.10.10.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.10.10.1.1.1" class="ltx_p" style="width:22.8pt;"><math id="S2.T1.10.10.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.10.10.1.1.1.m1.1a"><mo id="S2.T1.10.10.1.1.1.m1.1.1" xref="S2.T1.10.10.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.10.10.1.1.1.m1.1b"><times id="S2.T1.10.10.1.1.1.m1.1.1.cmml" xref="S2.T1.10.10.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.10.10.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T1.10.10.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.10.10.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.10.10.7.1.1" class="ltx_p" style="width:28.5pt;">600B</span>
</span>
</td>
<td id="S2.T1.10.10.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.10.10.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.10.10.8.1.1" class="ltx_p" style="width:142.3pt;">MassiveText</span>
</span>
</td>
</tr>
<tr id="S2.T1.11.11" class="ltx_tr">
<td id="S2.T1.11.11.2" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.11.11.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.11.11.3.1.1" class="ltx_p" style="width:48.4pt;">LaMDA</span>
</span>
</td>
<td id="S2.T1.11.11.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.11.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.11.11.4.1.1" class="ltx_p" style="width:56.9pt;">137B</span>
</span>
</td>
<td id="S2.T1.11.11.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.11.11.5.1.1" class="ltx_p" style="width:28.5pt;">2022</span>
</span>
</td>
<td id="S2.T1.11.11.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.11.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.11.11.6.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.11.11.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.11.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.11.11.1.1.1" class="ltx_p" style="width:22.8pt;"><math id="S2.T1.11.11.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.11.11.1.1.1.m1.1a"><mo id="S2.T1.11.11.1.1.1.m1.1.1" xref="S2.T1.11.11.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.11.11.1.1.1.m1.1b"><times id="S2.T1.11.11.1.1.1.m1.1.1.cmml" xref="S2.T1.11.11.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.11.11.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T1.11.11.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.11.11.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.11.11.7.1.1" class="ltx_p" style="width:28.5pt;">168B</span>
</span>
</td>
<td id="S2.T1.11.11.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.11.11.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.11.11.8.1.1" class="ltx_p" style="width:142.3pt;">public dialog data and web documents</span>
</span>
</td>
</tr>
<tr id="S2.T1.12.12" class="ltx_tr">
<td id="S2.T1.12.12.2" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.12.12.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.12.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.12.12.3.1.1" class="ltx_p" style="width:48.4pt;">ChinChilla</span>
</span>
</td>
<td id="S2.T1.12.12.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.12.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.12.12.4.1.1" class="ltx_p" style="width:56.9pt;">70B</span>
</span>
</td>
<td id="S2.T1.12.12.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.12.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.12.12.5.1.1" class="ltx_p" style="width:28.5pt;">2022</span>
</span>
</td>
<td id="S2.T1.12.12.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.12.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.12.12.6.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.12.12.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.12.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.12.12.1.1.1" class="ltx_p" style="width:22.8pt;"><math id="S2.T1.12.12.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.12.12.1.1.1.m1.1a"><mo id="S2.T1.12.12.1.1.1.m1.1.1" xref="S2.T1.12.12.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.12.12.1.1.1.m1.1b"><times id="S2.T1.12.12.1.1.1.m1.1.1.cmml" xref="S2.T1.12.12.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.12.12.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T1.12.12.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.12.12.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.12.12.7.1.1" class="ltx_p" style="width:28.5pt;">1.4T</span>
</span>
</td>
<td id="S2.T1.12.12.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.12.12.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.12.12.8.1.1" class="ltx_p" style="width:142.3pt;">MassiveText</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.39.25" class="ltx_tr">
<td id="S2.T1.14.39.25.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.39.25.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.39.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.39.25.2.1.1" class="ltx_p" style="width:48.4pt;">Galactia-120B</span>
</span>
</td>
<td id="S2.T1.14.39.25.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.39.25.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.39.25.3.1.1" class="ltx_p" style="width:56.9pt;">120B</span>
</span>
</td>
<td id="S2.T1.14.39.25.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.39.25.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.39.25.4.1.1" class="ltx_p" style="width:28.5pt;">2022</span>
</span>
</td>
<td id="S2.T1.14.39.25.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.39.25.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.39.25.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.39.25.6" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.39.25.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.39.25.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.39.25.7.1.1" class="ltx_p" style="width:28.5pt;">450B</span>
</span>
</td>
<td id="S2.T1.14.39.25.8" class="ltx_td ltx_align_top"></td>
</tr>
<tr id="S2.T1.14.40.26" class="ltx_tr">
<td id="S2.T1.14.40.26.1" class="ltx_td ltx_align_justify ltx_align_top" rowspan="2">
<span id="S2.T1.14.40.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.40.26.1.1.1" class="ltx_p" style="width:68.3pt;"><span id="S2.T1.14.40.26.1.1.1.1" class="ltx_text ltx_font_bold">Other Popular LLMs</span></span>
</span>
</td>
<td id="S2.T1.14.40.26.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.40.26.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.40.26.2.1.1" class="ltx_p" style="width:48.4pt;">CodeGen</span>
</span>
</td>
<td id="S2.T1.14.40.26.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.40.26.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.40.26.3.1.1" class="ltx_p" style="width:56.9pt;">16.1B</span>
</span>
</td>
<td id="S2.T1.14.40.26.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.40.26.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.40.26.4.1.1" class="ltx_p" style="width:28.5pt;">2022</span>
</span>
</td>
<td id="S2.T1.14.40.26.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.40.26.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.40.26.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.40.26.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.40.26.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.40.26.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.40.26.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.40.26.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.40.26.7.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.14.40.26.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.40.26.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.40.26.8.1.1" class="ltx_p" style="width:142.3pt;">THE PILE, BIGQUERY, BIGPYTHON</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.41.27" class="ltx_tr">
<td id="S2.T1.14.41.27.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.41.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.41.27.1.1.1" class="ltx_p" style="width:48.4pt;">BLOOM</span>
</span>
</td>
<td id="S2.T1.14.41.27.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.41.27.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.41.27.2.1.1" class="ltx_p" style="width:56.9pt;">176B</span>
</span>
</td>
<td id="S2.T1.14.41.27.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.41.27.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.41.27.3.1.1" class="ltx_p" style="width:28.5pt;">2022</span>
</span>
</td>
<td id="S2.T1.14.41.27.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.41.27.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.41.27.4.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.41.27.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.41.27.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.41.27.5.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.41.27.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.41.27.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.41.27.6.1.1" class="ltx_p" style="width:28.5pt;">366B</span>
</span>
</td>
<td id="S2.T1.14.41.27.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.41.27.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.41.27.7.1.1" class="ltx_p" style="width:142.3pt;">ROOTS</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.42.28" class="ltx_tr">
<td id="S2.T1.14.42.28.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.42.28.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.42.28.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.42.28.2.1.1" class="ltx_p" style="width:48.4pt;">Zephyr</span>
</span>
</td>
<td id="S2.T1.14.42.28.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.42.28.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.42.28.3.1.1" class="ltx_p" style="width:56.9pt;">7.24B</span>
</span>
</td>
<td id="S2.T1.14.42.28.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.42.28.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.42.28.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.42.28.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.42.28.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.42.28.5.1.1" class="ltx_p" style="width:42.7pt;">Mistral-7B</span>
</span>
</td>
<td id="S2.T1.14.42.28.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.42.28.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.42.28.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.42.28.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.42.28.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.42.28.7.1.1" class="ltx_p" style="width:28.5pt;">800B</span>
</span>
</td>
<td id="S2.T1.14.42.28.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.42.28.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.42.28.8.1.1" class="ltx_p" style="width:142.3pt;">Synthetic data</span>
</span>
</td>
</tr>
<tr id="S2.T1.13.13" class="ltx_tr">
<td id="S2.T1.13.13.2" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.13.13.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.13.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.13.13.3.1.1" class="ltx_p" style="width:48.4pt;">Grok-0</span>
</span>
</td>
<td id="S2.T1.13.13.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.13.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.13.13.4.1.1" class="ltx_p" style="width:56.9pt;">33B</span>
</span>
</td>
<td id="S2.T1.13.13.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.13.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.13.13.5.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.13.13.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.13.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.13.13.6.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.13.13.1" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.13.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.13.13.1.1.1" class="ltx_p" style="width:22.8pt;"><math id="S2.T1.13.13.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.13.13.1.1.1.m1.1a"><mo id="S2.T1.13.13.1.1.1.m1.1.1" xref="S2.T1.13.13.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.13.13.1.1.1.m1.1b"><times id="S2.T1.13.13.1.1.1.m1.1.1.cmml" xref="S2.T1.13.13.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.13.13.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T1.13.13.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.13.13.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.13.13.7.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.13.13.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.13.13.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.13.13.8.1.1" class="ltx_p" style="width:142.3pt;">Online source</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.43.29" class="ltx_tr">
<td id="S2.T1.14.43.29.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.43.29.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.43.29.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.43.29.2.1.1" class="ltx_p" style="width:48.4pt;">ORCA-2</span>
</span>
</td>
<td id="S2.T1.14.43.29.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.43.29.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.43.29.3.1.1" class="ltx_p" style="width:56.9pt;">13B</span>
</span>
</td>
<td id="S2.T1.14.43.29.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.43.29.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.43.29.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.43.29.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.43.29.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.43.29.5.1.1" class="ltx_p" style="width:42.7pt;">LLaMA2</span>
</span>
</td>
<td id="S2.T1.14.43.29.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.43.29.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.43.29.6.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.14.43.29.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.43.29.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.43.29.7.1.1" class="ltx_p" style="width:28.5pt;">2001B</span>
</span>
</td>
<td id="S2.T1.14.43.29.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.43.29.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.43.29.8.1.1" class="ltx_p" style="width:142.3pt;">-</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.44.30" class="ltx_tr">
<td id="S2.T1.14.44.30.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.44.30.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.44.30.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.44.30.2.1.1" class="ltx_p" style="width:48.4pt;">StartCoder</span>
</span>
</td>
<td id="S2.T1.14.44.30.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.44.30.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.44.30.3.1.1" class="ltx_p" style="width:56.9pt;">15.5B</span>
</span>
</td>
<td id="S2.T1.14.44.30.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.44.30.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.44.30.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.44.30.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.44.30.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.44.30.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.44.30.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.44.30.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.44.30.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.44.30.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.44.30.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.44.30.7.1.1" class="ltx_p" style="width:28.5pt;">35B</span>
</span>
</td>
<td id="S2.T1.14.44.30.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.44.30.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.44.30.8.1.1" class="ltx_p" style="width:142.3pt;">GitHub</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.45.31" class="ltx_tr">
<td id="S2.T1.14.45.31.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.45.31.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.45.31.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.45.31.2.1.1" class="ltx_p" style="width:48.4pt;">MPT</span>
</span>
</td>
<td id="S2.T1.14.45.31.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.45.31.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.45.31.3.1.1" class="ltx_p" style="width:56.9pt;">7B</span>
</span>
</td>
<td id="S2.T1.14.45.31.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.45.31.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.45.31.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.45.31.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.45.31.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.45.31.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.45.31.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.45.31.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.45.31.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.45.31.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.45.31.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.45.31.7.1.1" class="ltx_p" style="width:28.5pt;">1T</span>
</span>
</td>
<td id="S2.T1.14.45.31.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.45.31.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.45.31.8.1.1" class="ltx_p" style="width:142.3pt;">RedPajama, m Common Crawl, S2ORC, Common Crawl</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.46.32" class="ltx_tr">
<td id="S2.T1.14.46.32.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.46.32.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.46.32.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.46.32.2.1.1" class="ltx_p" style="width:48.4pt;">Mixtral-8x7B</span>
</span>
</td>
<td id="S2.T1.14.46.32.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.46.32.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.46.32.3.1.1" class="ltx_p" style="width:56.9pt;">46.7B</span>
</span>
</td>
<td id="S2.T1.14.46.32.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.46.32.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.46.32.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.46.32.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.46.32.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.46.32.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.46.32.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.46.32.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.46.32.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.46.32.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.46.32.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.46.32.7.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.14.46.32.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.46.32.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.46.32.8.1.1" class="ltx_p" style="width:142.3pt;">Instruction dataset</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.47.33" class="ltx_tr">
<td id="S2.T1.14.47.33.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.47.33.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.47.33.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.47.33.2.1.1" class="ltx_p" style="width:48.4pt;">Falcon 180B</span>
</span>
</td>
<td id="S2.T1.14.47.33.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.47.33.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.47.33.3.1.1" class="ltx_p" style="width:56.9pt;">180B</span>
</span>
</td>
<td id="S2.T1.14.47.33.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.47.33.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.47.33.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.47.33.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.47.33.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.47.33.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.47.33.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.47.33.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.47.33.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.47.33.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.47.33.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.47.33.7.1.1" class="ltx_p" style="width:28.5pt;">3.5T</span>
</span>
</td>
<td id="S2.T1.14.47.33.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.47.33.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.47.33.8.1.1" class="ltx_p" style="width:142.3pt;">RefinedWeb</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.48.34" class="ltx_tr">
<td id="S2.T1.14.48.34.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.48.34.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.48.34.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.48.34.2.1.1" class="ltx_p" style="width:48.4pt;">Gemini</span>
</span>
</td>
<td id="S2.T1.14.48.34.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.48.34.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.48.34.3.1.1" class="ltx_p" style="width:56.9pt;">1.8B, 3.25B</span>
</span>
</td>
<td id="S2.T1.14.48.34.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.48.34.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.48.34.4.1.1" class="ltx_p" style="width:28.5pt;">2023</span>
</span>
</td>
<td id="S2.T1.14.48.34.5" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.48.34.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.48.34.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.48.34.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.48.34.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.48.34.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.48.34.7.1.1" class="ltx_p" style="width:28.5pt;">-</span>
</span>
</td>
<td id="S2.T1.14.48.34.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.48.34.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.48.34.8.1.1" class="ltx_p" style="width:142.3pt;">Web documents, books, and code, image data, audio data, video data</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.49.35" class="ltx_tr">
<td id="S2.T1.14.49.35.1" class="ltx_td ltx_align_top"></td>
<td id="S2.T1.14.49.35.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.49.35.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.49.35.2.1.1" class="ltx_p" style="width:48.4pt;">DeepSeek-Coder</span>
</span>
</td>
<td id="S2.T1.14.49.35.3" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.49.35.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.49.35.3.1.1" class="ltx_p" style="width:56.9pt;">1.3B, 6.7B, 33B</span>
</span>
</td>
<td id="S2.T1.14.49.35.4" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.49.35.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.49.35.4.1.1" class="ltx_p" style="width:28.5pt;">2024</span>
</span>
</td>
<td id="S2.T1.14.49.35.5" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.49.35.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.49.35.5.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.49.35.6" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.49.35.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.49.35.6.1.1" class="ltx_p" style="width:22.8pt;">✓</span>
</span>
</td>
<td id="S2.T1.14.49.35.7" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.49.35.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.49.35.7.1.1" class="ltx_p" style="width:28.5pt;">2T</span>
</span>
</td>
<td id="S2.T1.14.49.35.8" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S2.T1.14.49.35.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.49.35.8.1.1" class="ltx_p" style="width:142.3pt;">GitHub’s Markdown and StackExchange</span>
</span>
</td>
</tr>
<tr id="S2.T1.14.14" class="ltx_tr">
<td id="S2.T1.14.14.2" class="ltx_td ltx_align_top ltx_border_bb"></td>
<td id="S2.T1.14.14.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S2.T1.14.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.14.3.1.1" class="ltx_p" style="width:48.4pt;">DocLLM</span>
</span>
</td>
<td id="S2.T1.14.14.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S2.T1.14.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.14.4.1.1" class="ltx_p" style="width:56.9pt;">1B,7B</span>
</span>
</td>
<td id="S2.T1.14.14.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S2.T1.14.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.14.5.1.1" class="ltx_p" style="width:28.5pt;">2024</span>
</span>
</td>
<td id="S2.T1.14.14.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S2.T1.14.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.14.6.1.1" class="ltx_p" style="width:42.7pt;">-</span>
</span>
</td>
<td id="S2.T1.14.14.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S2.T1.14.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.14.1.1.1" class="ltx_p" style="width:22.8pt;"><math id="S2.T1.14.14.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.14.14.1.1.1.m1.1a"><mo id="S2.T1.14.14.1.1.1.m1.1.1" xref="S2.T1.14.14.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.14.14.1.1.1.m1.1b"><times id="S2.T1.14.14.1.1.1.m1.1.1.cmml" xref="S2.T1.14.14.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.14.14.1.1.1.m1.1c">\times</annotation></semantics></math></span>
</span>
</td>
<td id="S2.T1.14.14.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S2.T1.14.14.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.14.7.1.1" class="ltx_p" style="width:28.5pt;">2T</span>
</span>
</td>
<td id="S2.T1.14.14.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S2.T1.14.14.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.14.14.8.1.1" class="ltx_p" style="width:142.3pt;">IIT-CDIP Test Collection 1.0, DocBank</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Early Pre-trained Neural Language Models</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p1.1">신경망을 이용한 언어 모델링은 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib38" title="">38</a>, <a class="ltx_ref" href="#bib.bib39" title="">39</a>, <a class="ltx_ref" href="#bib.bib40" title="">40</a>]</cite>에 의해 개척되었다. Bengio et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite>는 n-gram 모델에 버금가는 최초의 신경망 모델(NLMs) 중 하나를 개발했다. 그런 다음 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib14" title="">14</a>]</cite>는 NLM을 기계 번역에 성공적으로 적용했다. Mikolov <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib41" title="">41</a>, <a class="ltx_ref" href="#bib.bib42" title="">42</a>]</cite>에 의한 RNNLM(open source NLM toolkit)의 출시는 NLM의 대중화에 크게 도움이 되었다. 그 후, RNN(Recurrent Neural Network)을 기반으로 하는 NLM과 그 변형인 LSTM(Long Short-term Memory) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib19" title="">19</a>]</cite> 및 GRU(Gated Recurrent Unit) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite>는 기계 번역, 텍스트 생성 및 텍스트 분류 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib43" title="">43</a>]</cite>를 포함한 많은 자연어 응용 분야에 널리 사용되었다.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p2.1">그런 다음, 트랜스포머 아키텍처 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib44" title="">44</a>]</cite>의 발명은 NLMs 개발에 있어서 또 다른 이정표를 표시한다. 문장 또는 문서의 모든 단어에 대해 병렬적으로 계산하기 위해 자기 주의를 적용하여 "주의 점수"를 사용하여 각 단어가 다른 단어에 미치는 영향을 모델링함으로써, 트랜스포머는 RNN보다 훨씬 더 많은 병렬화를 허용하며, 이는 GPU의 대용량 데이터에 대해 매우 큰 언어 모델을 효율적으로 사전 훈련시키는 것을 가능하게 한다. 이러한 사전 훈련된 언어 모델(PLM)은 많은 다운스트림 작업에 대해 미세 조정될 수 있다.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p3.1">초기 인기 있는 트랜스포머 기반 PLM을 신경망 구조를 기반으로 인코더 전용, 디코더 전용 및 인코더-디코더 모델의 세 가지 주요 범주로 그룹화한다. 초기 PLM에 대한 포괄적인 조사는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib43" title="">43</a>, <a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite>에서 제공된다.</p>
</div>
<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS1.5.1.1" class="ltx_text">II-A</span>1 </span>Encoder-only PLMs</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p1.1">이름에서 알 수 있듯이 인코더 전용 모델은 인코더 네트워크로만 구성됩니다. 이러한 모델은 원래 텍스트 분류와 같은 언어 이해 작업을 위해 개발되었으며, 여기서 모델은 입력 텍스트에 대한 클래스 레이블을 예측해야 한다. 대표적인 인코더 전용 모델은 아래에서 설명하는 바와 같이 BERT 및 그 변형, 예를 들어 RoBERTa, ALBERT, DeBERTa, XLM, XLNet, UNILM을 포함한다.</p>
</div>
<div id="S2.SS1.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p2.1">BERT(Birectional Encoder Representations from Transformers) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>]</cite>는 가장 널리 사용되는 인코더 전용 언어 모델 중 하나이다. BERT는 (1) 입력 텍스트를 임베딩 벡터의 시퀀스로 변환하는 임베딩 모듈, (2) 임베딩 벡터를 문맥적 표현 벡터로 변환하는 트랜스포머 인코더 스택, (3) 표현 벡터를 (최종 계층에서) 원-핫 벡터로 변환하는 완전 연결 계층으로 구성된다. BERT는 마스킹 언어 모델링(Masked Language Modeling, MMLM)과 다음 문장 예측의 두 가지 목적을 사용하여 사전 훈련된다. 사전 학습된 BERT 모델은 텍스트 분류, 질의 응답, 언어 추론에 이르기까지 많은 언어 이해 작업을 위한 분류기 계층을 추가함으로써 미세 조정될 수 있다. BERT 프레임워크의 상위 레벨 개요는 그림 <a class="ltx_ref" href="#S2.F3" title="Figure 3 ‣ II-A1 Encoder-only PLMs ‣ II-A Early Pre-trained Neural Language Models ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">3</span></a>에 나와 있다. BERT가 출판되었을 때 광범위한 언어 이해 작업에 대한 최신 기술이 크게 향상됨에 따라 AI 커뮤니티는 BERT를 기반으로 하는 유사한 인코더 전용 언어 모델을 많이 개발하도록 영감을 받았다.</p>
</div>
<figure id="S2.F3" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/bert_arch.png" id="S2.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="375" height="154" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F3.3.1.1" style="font-size:90%;">Figure 3</span>:</span><span class="ltx_text" id="S2.F3.4.2" style="font-size:90%;">Overall pre-training and fine-tuning procedures for BERT. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>]</cite></span></figcaption>
</figure>
<div id="S2.SS1.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p3.1">RoBERTa <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>]</cite>는 몇 가지 주요 하이퍼파라미터 수정, 다음 문장 사전 훈련 목적 제거 및 훨씬 더 큰 미니 배치 및 학습 속도로 훈련과 같은 모델 설계 선택 및 훈련 전략 세트를 사용하여 BERT의 견고성을 크게 향상시킨다. ALBERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib45" title="">45</a>]</cite>는 메모리 소모를 줄이고 BERT의 학습 속도를 높이기 위해 두 가지 파라미터 감소 기법을 사용한다: (1) 임베딩 행렬을 두 개의 작은 행렬로 분할하고, (2) 그룹 간 반복 레이어를 분할한다. DeBERTa (Decoding-enhanced BERT with disentangled attention) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>는 두 가지 새로운 기법을 사용하여 BERT 및 RoBERTa 모델을 개선한다. 첫 번째는 각 단어의 내용과 위치를 각각 부호화하는 두 개의 벡터를 이용하여 각 단어를 표현하고, 각 단어의 내용과 상대적인 위치에 대한 서로 다른 행렬들을 이용하여 단어간의 주의 가중치를 계산하는 분리 어텐션 메커니즘이다. 둘째, 개선된 마스크 디코더는 모델 사전 트레이닝에서 마스킹된 토큰들을 예측하기 위해 디코딩 계층 내의 절대 위치들을 통합하는데 사용된다. 또한, 모델의 일반화를 개선하기 위해 미세 조정을 위해 새로운 가상 적대적 훈련 방법을 사용한다. ELECTRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>는 교체된 토큰 검출(RTD)로 알려진 새로운 사전 훈련 작업을 사용하며, 이는 경험적으로 MLM보다 샘플 효율이 더 높은 것으로 입증된다. 입력을 마스킹하는 대신, RTD는 일부 토큰을 작은 생성기 네트워크에서 샘플링된 그럴듯한 대안으로 교체함으로써 입력을 손상시킨다. 그런 다음 손상된 토큰의 원래 ID를 예측하는 모델을 훈련하는 대신 손상된 입력의 토큰이 생성된 샘플로 대체되었는지 여부를 예측하기 위해 판별 모델을 훈련한다. RTD는 그림 <a class="ltx_ref" href="#S2.F4" title="Figure 4 ‣ II-A1 Encoder-only PLMs ‣ II-A Early Pre-trained Neural Language Models ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">4</span></a>에 도시된 바와 같이 전자는 마스킹되는 작은 서브세트보다 모든 입력 토큰에 걸쳐 정의되기 때문에 MLM보다 샘플 효율적이다.</p>
</div>
<figure id="S2.F4" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/electra.png" id="S2.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="436" height="198" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F4.3.1.1" style="font-size:90%;">Figure 4</span>:</span><span class="ltx_text" id="S2.F4.4.2" style="font-size:90%;">A comparison between replaced token detection and masked language modeling. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S2.SS1.SSS1.p4" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p4.1">XLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib47" title="">47</a>]</cite>는 두 가지 방법을 사용하여 교차 언어 모델로 BERT를 확장했다: (1) 단일 언어 데이터에만 의존하는 비감독 방법과 (2) 그림 <a class="ltx_ref" href="#S2.F5" title="Figure 5 ‣ II-A1 Encoder-only PLMs ‣ II-A Early Pre-trained Neural Language Models ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">5</span></a>에 예시된 바와 같이 새로운 교차 언어 모델 목적으로 병렬 데이터를 활용하는 감독 방법. XLM은 제안 당시 언어 간 분류, 비감독 및 감독 기계 번역에 대한 최신 결과를 얻었다.</p>
</div>
<figure id="S2.F5" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/xlm.png" id="S2.F5.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="386" height="214" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F5.3.1.1" style="font-size:90%;">Figure 5</span>:</span><span class="ltx_text" id="S2.F5.4.2" style="font-size:90%;">Cross-lingual language model pretraining. MLM 목표는 BERT와 유사하지만 문장 쌍과 대조적으로 텍스트의 연속 스트림이 있다. TLM 목표는 MLM을 병렬 문장 쌍으로 확장한다. To</span></figcaption><figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S2.F5.4.2" class="ltx_text" style="font-size:90%;"> Cross-lingual language model pretraining. The MLM objective is similar to BERT, but with continuous streams of text as opposed to sentence pairs. The TLM objective extends MLM to pairs of parallel sentences. To
predict a masked English word, the model can attend to both the English sentence and its French translation, and is encouraged to align English and French representations. Courtesy of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite>.</span></figcaption>
</figure>
<div id="S2.SS1.SSS1.p5" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p5.1">모델 학습 및 추론을 위해 자동 회귀(디코더) 모델의 장점을 활용하는 인코더 전용 언어 모델도 있다. 두 가지 예는 XLNet과 UNILM이다. XLNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib48" title="">48</a>]</cite>는 Transformer-XL을 기반으로 하며, 인수분해 순서의 모든 순열에 대해 예상 우도를 최대화하여 양방향 컨텍스트 학습을 가능하게 하는 일반화된 자기회귀 방법을 사용하여 사전 훈련된다. UNILM(UNIfied pre-trained Language Model) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib49" title="">49</a>]</cite>는 단방향, 양방향, 시퀀스 대 시퀀스 예측의 세 가지 유형의 언어 모델링 작업을 사용하여 사전 훈련된다. 이는 공유 트랜스포머 네트워크를 사용하고 그림 <a class="ltx_ref" href="#S2.F6" title="Figure 6 ‣ II-A1 Encoder-only PLMs ‣ II-A Early Pre-trained Neural Language Models ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">6</span></a>에 예시된 바와 같이 예측이 어떤 컨텍스트에서 조건화되는지를 제어하기 위해 특정 자기 주의 마스크를 활용함으로써 달성된다. 사전 학습된 모델은 자연어 이해 및 생성 작업 모두에 대해 미세 조정될 수 있다.</p>
</div>
<figure id="S2.F6" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/UNILM.png" id="S2.F6.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="330" height="244" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F6.3.1.1" style="font-size:90%;">Figure 6</span>:</span><span class="ltx_text" id="S2.F6.4.2" style="font-size:90%;">Overview of unified LM pre-training. 모델 매개변수는 LM</span>에 걸쳐 공유됩니다.</figcaption><figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F6.3.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S2.F6.4.2" class="ltx_text" style="font-size:90%;">Overview of unified LM pre-training. The model parameters are shared across the LM
objectives (i.e., bidirectional LM, unidirectional LM, and sequence-to-sequence LM). Courtesy of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>.</span></figcaption>
</figure>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS2.5.1.1" class="ltx_text">II-A</span>2 </span>Decoder-only PLMs</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS2.p1.1">가장 널리 사용되는 디코더 전용 PLM 중 두 개는 OpenAI에서 개발한 GPT-1과 GPT-2이다. 이러한 모델은 이후에 GPT-3 및 GPT-4와 같은 보다 강력한 LLM에 기반을 마련한다.</p>
</div>
<div id="S2.SS1.SSS2.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS2.p2.1">GPT-1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib50" title="">50</a>]</cite>는 도 <a class="ltx_ref" href="#S2.F7" title="Figure 7 ‣ II-A2 Decoder-only PLMs ‣ II-A Early Pre-trained Neural Language Models ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">7</span></a>에 예시된 바와 같이, 자기 지도 학습 방식(즉, 다음 단어/토큰 예측)으로 라벨이 지정되지 않은 텍스트의 다양한 코퍼스에 대한 디코더 전용 트랜스포머 모델의 GPT(Generative Pre-Training)에 의해 광범위한 자연 언어 작업에 대한 우수한 성능을 얻을 수 있음을 처음으로 보여준다. GPT-1은 후속 GPT 모델의 길을 열어주며, 각 버전은 아키텍처를 개선하고 다양한 언어 작업에서 더 나은 성능을 달성한다.</p>
</div>
<figure id="S2.F7" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/GPT.png" id="S2.F7.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="391" height="168" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F7.3.1.1" style="font-size:90%;">Figure 7</span>:</span><span class="ltx_text" id="S2.F7.4.2" style="font-size:90%;">High-level overview of GPT pretraining, and fine-tuning steps. 오픈AI의 공손함 </span></figcaption>
</figure>
<div id="S2.SS1.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS2.p3.1">GPT-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib51" title="">51</a>]</cite>는 언어 모델이 수백만 개의 웹 페이지로 구성된 대규모 웹 텍스트 데이터 세트에서 훈련될 때 명시적인 감독 없이 특정 자연어 작업을 수행하는 것을 학습할 수 있음을 보여준다. GPT-2 모델은 몇 가지 수정으로 GPT-1의 모델 설계를 따른다: 계층 정규화는 각 서브-블록의 입력으로 이동되고, 추가 계층 정규화는 최종 셀프-어텐션 블록 이후에 추가되며, 초기화는 잔여 경로 상의 축적을 고려하도록 수정되고 잔여 계층들의 가중치들을 스케일링하고, 어휘 크기는 50,25로 확장되며, 컨텍스트 크기는 512에서 1024 토큰으로 증가된다.</p>
</div>
</section>
<section id="S2.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS3.5.1.1" class="ltx_text">II-A</span>3 </span>Encoder-Decoder PLMs</h4>

<div id="S2.SS1.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS3.p1.1"><cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib52" title="">52</a>]</cite>에서 Raffle 등은 거의 모든 NLP 태스크들이 시퀀스-투-시퀀스 생성 태스크로서 캐스팅될 수 있음을 보여준다. 따라서, 인코더-디코더 언어 모델은, 설계에 의해, 모든 자연 언어 이해 및 생성 태스크들을 수행할 수 있다는 점에서 통일된 모델이다. 아래에서 검토할 대표적인 인코더-디코더 PLM은 T5, mT5, MASS 및 BART이다.</p>
</div>
<div id="S2.SS1.SSS3.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS3.p2.1">T5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib52" title="">52</a>]</cite>는 T5(Text-to-Text Transfer Transformer) 모델로, 모든 NLP 태스크가 텍스트 대 텍스트 생성 태스크로 캐스팅되는 통합 프레임워크의 도입을 통해 전이 학습이 NLP에 효과적으로 활용된다. mT5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib53" title="">53</a>]</cite>는 101개 언어의 텍스트로 구성된 새로운 Common Crawl 기반 데이터 세트에서 사전 훈련된 T5의 다국어 변형이다.</p>
</div>
<div id="S2.SS1.SSS3.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS3.p3.1">MASS(MAsked Sequence to Sequence pre-training) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib54" title="">54</a>]</cite>는 인코더-디코더 프레임워크를 채택하여 문장의 나머지 부분이 주어진 문장 조각을 재구성한다. 인코더는 랜덤하게 마스킹된 단편(몇 개의 연속적인 토큰들)을 입력으로 하는 문장을 취하고, 디코더는 마스킹된 단편을 예측한다. 이러한 방식으로, MASS는 언어 임베딩 및 생성을 위해 인코더 및 디코더를 각각 공동으로 트레이닝한다.</p>
</div>
<div id="S2.SS1.SSS3.p4" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS3.p4.1">BART <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>는 표준 시퀀스 대 시퀀스 변환 모델 아키텍처를 사용한다. 임의의 노이즈링 기능으로 텍스트를 손상시킨 후 원문을 재구성하는 학습을 하여 사전 학습한다.</p>
</div>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Large Language Model Families</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p1.1">대형 언어 모델(LLM)은 주로 수백억에서 수천억 개의 파라미터를 포함하는 변압기 기반 PLM을 말한다. 위에서 검토한 PLM에 비해 LLM은 모델 크기가 훨씬 클 뿐만 아니라 소규모 모델에는 없는 더 강력한 언어 이해 및 생성 및 창발 능력을 나타낸다. 다음에서 그림 <a class="ltx_ref" href="#S2.F8" title="Figure 8 ‣ II-B Large Language Model Families ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">8</span></a>에 설명된 대로 GPT, LLaMA 및 PaLM의 세 가지 LLM 계열을 검토한다.</p>
</div>
<figure id="S2.F8" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/x3.png" id="S2.F8.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="393" height="134" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F8.3.1.1" style="font-size:90%;">Figure 8</span>:</span><span class="ltx_text" id="S2.F8.4.2" style="font-size:90%;">Popular LLM Families. </span></figcaption>
</figure>
<section id="S2.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS2.SSS1.5.1.1" class="ltx_text">II-B</span>1 </span><span id="S2.SS2.SSS1.6.2" class="ltx_text ltx_font_bold">The GPT Family</span>
</h4>

<div id="S2.SS2.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS1.p1.1">GPT(Generative Pre-trained Transformers)는 OpenAI에서 개발한 디코더 전용 트랜스포머 기반 언어 모델 계열이다. 이 패밀리는 GPT-1, GPT-2, GPT-3, InstrucGPT, ChatGPT, GPT-4, CODEX 및 WebGPT로 구성된다. GPT-1 및 GPT-2와 같은 초기 GPT 모델은 오픈 소스이지만 GPT-3 및 GPT-4와 같은 최근 모델은 근접 소스이며 API를 통해만 액세스할 수 있다. GPT-1 및 GPT-2 모델은 초기 PLM 하위 섹션에서 논의되었다. 아래 GPT-3부터 시작합니다.</p>
</div>
<div id="S2.SS2.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS1.p2.1">GPT-3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>는 1,750억 개의 파라미터를 가진 사전 훈련된 자기 회귀 언어 모델이다. GPT-3는 이전 PLM보다 훨씬 클 뿐만 아니라 이전에 더 작은 PLM에서 관찰되지 않은 새로운 능력을 처음으로 보여준다는 점에서 첫 번째 LLM으로 널리 간주된다. GPT-3은 컨텍스트 내 학습의 창발 능력을 보여주며, 이는 GPT-3이 그래프 업데이트 또는 미세 조정 없이 모든 다운스트림 태스크에 적용될 수 있음을 의미하며, 태스크 및 소수의 샷 데모는 순전히 모델과의 텍스트 상호 작용을 통해 지정된다. GPT-3는 번역, 질의 응답 및 클로즈 작업을 포함한 많은 NLP 작업과 문장의 새로운 단어인 3자리 산술을 사용하여 스크램블링 해제와 같이 즉석 추론 또는 도메인 적응이 필요한 여러 작업에서 강력한 성능을 달성했다. 그림 <a class="ltx_ref" href="#S2.F9" title="Figure 9 ‣ II-B1 The GPT Family ‣ II-B Large Language Model Families ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">9</span></a>는 컨텍스트 내 프롬프트에서 예제 수의 함수로 GPT-3의 성능을 표시합니다.</p>
</div>
<figure id="S2.F9" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/gpt3_size.png" id="S2.F9.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="361" height="203" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F9.3.1.1" style="font-size:90%;">Figure 9</span>:</span><span class="ltx_text" id="S2.F9.4.2" style="font-size:90%;">GPT-3는 더 큰 모델이 컨텍스트 내 정보의 점점 더 효율적인 사용을 만든다는 것을 보여준다. 그것은 모델이 a</span>이 있거나 없는 단어에서 무작위 기호를 제거하도록 요구하는 간단한 작업에 대한 문맥 내 학습 성능을 보여준다.</figcaption><figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F9.3.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S2.F9.4.2" class="ltx_text" style="font-size:90%;">GPT-3 shows that larger models make increasingly efficient use of in-context information. It shows in-context learning performance on a simple task requiring the model to remove random symbols from a word, both with and without a
natural language task description. Courtesy of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>.</span></figcaption>
</figure>
<div id="S2.SS2.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS1.p3.1">OpenAI가 2023년 3월 출시한 CODEX <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>는 자연어를 파싱하고 이에 대응하여 코드를 생성할 수 있는 범용 프로그래밍 모델이다. CODEX는 GitHub에서 수집된 코드 코퍼스의 프로그래밍 애플리케이션을 위해 미세 조정된 GPT-3의 후손이다. CODEX는 Microsoft의 GitHub Copilot에 권한을 부여합니다.</p>
</div>
<div id="S2.SS2.SSS1.p4" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS1.p4.1">WebGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib58" title="">58</a>]</cite>는 GPT-3의 또 다른 후손이며, 텍스트 기반 웹 브라우저를 사용하여 개방형 질문에 답하도록 미세 조정되어 사용자가 웹을 검색하고 탐색할 수 있도록 돕는다. 구체적으로, WebGPT는 세 단계로 훈련된다. 첫 번째는 WebGPT가 인간의 시연 데이터를 사용하여 인간의 브라우징 행동을 모방하는 방법을 배우는 것이다. 그런 다음 보상 함수를 학습하여 인간의 선호도를 예측합니다. 마지막으로, 강화 학습과 거부 샘플링을 통해 보상 함수를 최적화하기 위해 WebGPT를 정제한다.</p>
</div>
<div id="S2.SS2.SSS1.p5" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS1.p5.1">LLM이 예상되는 인간 명령을 따를 수 있도록 하기 위해, InstructGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib59" title="">59</a>]</cite>는 인간 피드백으로 미세 조정함으로써 광범위한 작업에 대한 사용자 의도와 언어 모델을 정렬하기 위해 제안된다. OpenAI API를 통해 제출된 라벨러 작성 프롬프트 및 프롬프트 집합으로 시작하여 원하는 모델 동작의 라벨러 시연 데이터 세트가 수집된다. 그런 다음 GPT-3는 이 데이터 세트에서 미세 조정됩니다. 그런 다음, 강화 학습을 사용하여 모델을 추가로 미세 조정하기 위해 인간 순위 모델 출력의 데이터 세트를 수집한다. 방법은 <a class="ltx_ref" href="#S2.F10" title="Figure 10 ‣ II-B1 The GPT Family ‣ II-B Large Language Model Families ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">10</span></a>에 나타낸 바와 같이, 인간 피드백으로부터의 강화 학습(RLHF)이 알려져 있다. 결과 InstructGPT 모델은 공개 NLP 데이터 세트에 대한 성능 회귀를 최소화하면서 진실성 개선과 독성 출력 생성 감소를 보여주었다.</p>
</div>
<figure id="S2.F10" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/SFT.png" id="S2.F10.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="366" height="217" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F10.3.1.1" style="font-size:90%;">Figure 10</span>:</span><span class="ltx_text" id="S2.F10.4.2" style="font-size:90%;">The high-level overview of RLHF. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib59" title="">59</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S2.SS2.SSS1.p6" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS1.p6.1">LLM 개발의 가장 중요한 이정표는 2022년 11월 30일 ChatGPT(Chat Generative Pre-trained Transformer) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib60" title="">60</a>]</cite>의 출시이다. ChatGPT는 사용자가 대화를 조종하여 질의 응답, 정보 탐색, 텍스트 요약 등과 같은 광범위한 작업을 완료할 수 있도록 하는 챗봇이다. ChatGPT는 InstructGPT에 대한 형제 모델인 GPT-3.5(그리고 나중에 GPT-4에 의해 구동되며, 이는 프롬프트에서 명령을 따르고 상세한 응답을 제공하도록 훈련된다.</p>
</div>
<div id="S2.SS2.SSS1.p7" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS1.p7.1">GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>는 GPT 계열에서 가장 최신이고 강력한 LLM이다. 2023년 3월에 출시된 GPT-4는 이미지와 텍스트를 입력으로 하고 텍스트 출력을 생성할 수 있다는 점에서 멀티모달 LLM이다. GPT-4는 그림 <a class="ltx_ref" href="#S2.F11" title="Figure 11 ‣ II-B1 The GPT Family ‣ II-B Large Language Model Families ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">11</span></a>와 같이 가장 어려운 실제 시나리오 중 일부에서 인간보다 능력이 낮지만 수험생의 상위 10% 정도의 점수로 모의 변호사 시험에 합격하는 등 다양한 전문 및 학술 벤치마크에서 인간 수준의 성능을 나타낸다. 초기 GPT 모델과 마찬가지로 GPT-4는 먼저 큰 텍스트 말뭉치에서 다음 토큰을 예측하도록 사전 훈련된 다음 모델 행동을 인간이 원하는 것과 정렬하기 위해 RLHF로 미세 조정되었다.</p>
</div>
<figure id="S2.F11" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/gpt4.png" id="S2.F11.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="352" height="315" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F11.3.1.1" style="font-size:90%;">Figure 11</span>:</span><span class="ltx_text" id="S2.F11.4.2" style="font-size:90%;">GPT-4 performance on academic and professional exams, compared with GPT 3.5. Courtesy of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>. </span></figcaption>
</figure>
</section>
<section id="S2.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS2.SSS2.5.1.1" class="ltx_text">II-B</span>2 </span><span id="S2.SS2.SSS2.6.2" class="ltx_text ltx_font_bold">The LLaMA Family</span>
</h4>

<div id="S2.SS2.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS2.p1.1">LLaMA는 메타에서 출시한 기초 언어 모델 모음이다. GPT 모델과 달리 LLaMA 모델은 오픈 소스이며, 즉 모델 가중치는 비상업 라이선스에 따라 연구 커뮤니티에 공개된다. 따라서 LLaMA 계열은 많은 연구 그룹에서 폐쇄 소스 LLM과 경쟁하거나 임무 중요 응용을 위한 작업 특정 LLM을 개발하기 위해 더 나은 오픈 소스 LLM을 개발하기 위해 널리 사용됨에 따라 빠르게 성장한다.</p>
</div>
<div id="S2.SS2.SSS2.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS2.p2.1">LLaMA 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib32" title="">32</a>]</cite>의 첫 번째 세트는 2023년 2월에 7B에서 65B 매개 변수에 이르기까지 출시되었다. 이러한 모델은 공개적으로 사용 가능한 데이터 세트에서 수집된 수조 개의 토큰에 대해 사전 훈련됩니다. LLaMA는 GPT-3의 트랜스포머 구조를 사용하며, (1) ReLU 대신 SwiGLU 활성화 함수를 사용하고, (2) 절대 위치 임베딩 대신 회전 위치 임베딩을 사용하고, (3) 표준 계층 정규화 대신 평균 제곱근 계층 정규화를 사용하는 등 몇 가지 사소한 아키텍처 수정을 포함한다. 오픈 소스 LLaMA-13B 모델은 대부분의 벤치마크에서 독점 GPT-3(175B) 모델을 능가하여 LLM 연구에 좋은 기준선이 된다.</p>
</div>
<div id="S2.SS2.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS2.p3.1">2023년 7월, 메타는 마이크로소프트와 제휴하여 LLaMA-2 Chat으로 알려진 대화용으로 미세 조정된 기본 언어 모델과 Chat 모델을 모두 포함하는 LLaMA-2 모음 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib61" title="">61</a>]</cite>를 출시했다. LLaMA-2 채팅 모델은 많은 공개 벤치마크에서 다른 오픈 소스 모델을 능가하는 것으로 보고되었다. <a class="ltx_ref" href="#S2.F12" title="Figure 12 ‣ II-B2 The LLaMA Family ‣ II-B Large Language Model Families ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">12</span></a>는 LLaMA-2 Chat의 트레이닝 과정을 나타낸다. 이 프로세스는 공개적으로 사용 가능한 온라인 데이터를 사용하여 LLaMA-2를 사전 훈련하는 것으로 시작한다. 그런 다음 감독 미세 조정을 통해 LLaMA-2 채팅의 초기 버전을 구축한다. 그 후, 모델은 RLHF, 거부 샘플링 및 근위 정책 최적화를 사용하여 반복적으로 정제된다. RLHF 단계에서 보상 모델을 수정하기 위한 인간 피드백의 축적은 보상 모델이 너무 많이 변경되지 않도록 하는 데 중요하며, 이는 LLaMA 모델 훈련의 안정성을 해칠 수 있다.</p>
</div>
<figure id="S2.F12" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/llama2.png" id="S2.F12.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="428" height="199" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F12.3.1.1" style="font-size:90%;">Figure 12</span>:</span><span class="ltx_text" id="S2.F12.4.2" style="font-size:90%;">Training of LLaMA-2 Chat. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib61" title="">61</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S2.SS2.SSS2.p4" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS2.p4.1">Alpaca <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib62" title="">62</a>]</cite>는 GPT-3.5(text-davinci-003)를 사용하여 자체 명령 형식으로 생성된 52K 명령 후속 데모를 사용하여 LLaMA-7B 모델에서 미세 조정된다. 알파카는 훈련, 특히 학술 연구에 매우 비용 효율적입니다. 자가 지시 평가 세트에서 알파카는 알파카가 훨씬 작음에도 불구하고 GPT-3.5와 유사하게 수행한다.</p>
</div>
<div id="S2.SS2.SSS2.p5" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS2.p5.1">비쿠나 팀은 쉐어GPT에서 수집한 사용자 공유 대화에서 LLaMA를 미세 조정해 13B 채팅 모델인 비쿠나-13B를 개발했다. GPT-4를 평가자로 사용한 예비 평가 결과, 비쿠나-13B는 오픈AI의 ChatGPT와 구글의 Bard의 품질을 90% 이상 달성하면서 LLaMA나 Stanford Alpaca와 같은 다른 모델을 90% 이상 능가하는 것으로 나타났다. <a class="ltx_ref" href="#S2.F13" title="Figure 13 ‣ II-B2 The LLaMA Family ‣ II-B Large Language Model Families ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">13</span></a>는 GPT-4에 의한 Vicuna와 몇몇 다른 잘 알려진 모델들의 상대적인 응답 품질을 보여준다. Vicuna-13B의 또 다른 이점은 모델 트레이닝에 대한 상대적인 제한된 계산 요구이다. 비쿠나-13B의 훈련 비용은 단지 300달러이다.</p>
</div>
<figure id="S2.F13" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/vicuna.png" id="S2.F13.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="284" height="124" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F13.3.1.1" style="font-size:90%;">Figure 13</span>:</span><span class="ltx_text" id="S2.F13.4.2" style="font-size:90%;">Relative Response Quality of Vicuna and a few other well-known models by GPT-4. Courtesy of Vicuna Team. </span></figcaption>
</figure>
<div id="S2.SS2.SSS2.p6" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS2.p6.1">Alpaca 및 Vicuna와 마찬가지로 Guanaco 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib63" title="">63</a>]</cite>도 명령 후속 데이터를 사용하여 미세 조정된 LLaMA 모델이다. 그러나 단일 48GB GPU에서 65B 파라미터 모델을 미세 조정할 수 있도록 QLoRA를 사용하여 미세 조정을 매우 효율적으로 수행한다. QLoRA는 동결된 4비트 양자화된 사전 훈련 언어 모델을 통해 기울기를 LoRA(Low Rank Adapters)로 역전파한다. 최상의 Guanaco 모델은 Vicuna 벤치마크에서 이전에 출시된 모든 모델을 능가하여 ChatGPT의 성능 수준의 99.3%에 도달했으며 단일 GPU에서 24시간의 미세 조정만 요구합니다.</p>
</div>
<div id="S2.SS2.SSS2.p7" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS2.p7.1">Koala <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>는 LLaMA에 구축된 또 다른 명령어 후속 언어 모델이지만, ChatGPT와 같은 매우 유능한 폐쇄 소스 채팅 모델에 의해 생성된 사용자 입력 및 응답을 포함하는 상호작용 데이터에 특정 초점을 맞춘다. 코알라-13B 모델은 실제 사용자 프롬프트에 기초한 인간 평가에 따라 최첨단 채팅 모델과 경쟁적으로 수행한다.</p>
</div>
<div id="S2.SS2.SSS2.p8" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS2.p8.1">Mistral-7B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib65" title="">65</a>]</cite>는 우수한 성능과 효율성을 위해 설계된 7B 파라미터 언어 모델이다. Mistral-7B는 평가된 모든 벤치마크에서 최고의 오픈 소스 13B 모델(LLaMA-2-13B)과 추론, 수학 및 코드 생성에서 최고의 오픈 소스 34B 모델(LLaMA-34B)을 능가한다. 이 모델은 더 빠른 추론을 위해 그룹화된 쿼리 어텐션을 활용하고, 슬라이딩 윈도우 어텐션과 결합하여 추론 비용이 감소된 임의의 길이의 시퀀스를 효과적으로 처리한다.</p>
</div>
<div id="S2.SS2.SSS2.p9" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS2.p9.1">LLaMA 계열은 Code LLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>, Gorilla <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>, Giraffe <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib68" title="">68</a>]</cite>, Vigogne <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>, Tulu 65B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib70" title="">70</a>]</cite>, Long LLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib71" title="">71</a>]</cite>, Stable Beluga2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib72" title="">72</a>]</cite>를 포함하여 더 많은 명령어 후속 모델이 LLaMA 또는 LLaMA-2에 구축됨에 따라 빠르게 성장하고 있다.</p>
</div>
</section>
<section id="S2.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS2.SSS3.5.1.1" class="ltx_text">II-B</span>3 </span><span id="S2.SS2.SSS3.6.2" class="ltx_text ltx_font_bold">The PaLM Family</span>
</h4>

<div id="S2.SS2.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS3.p1.1">PaLM(Pathways Language Model) 패밀리는 구글에서 개발한다. 첫 번째 PaLM 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>는 2022년 4월에 발표되었으며 2023년 3월까지 비공개로 유지되었다. 540B 파라미터 변압기 기반 LLM이다. 이 모델은 광범위한 자연어 작업과 사용 사례로 구성된 7,800억 개의 토큰으로 구성된 고품질 텍스트 코퍼스에 대해 사전 훈련된다. PaLM은 패스웨이 시스템을 사용하여 6144개의 TPU v4 칩에서 사전 훈련되어 여러 TPU 포드에 걸쳐 매우 효율적인 훈련이 가능하다. PaLM은 수백 개의 언어 이해 및 생성 벤치마크에 대한 최첨단 소샷 학습 결과를 달성함으로써 스케일링의 지속적인 이점을 보여준다. PaLM-540B는 여러 단계의 추론 작업 세트에서 최첨단 미세 조정 모델뿐만 아니라 최근에 출시된 BIG 벤치마크에서 인간과 동등하다.</p>
</div>
<div id="S2.SS2.SSS3.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS3.p2.1">8B, 62B 및 540B 스케일의 U-PaLM 모델은 UL2R을 사용하여 PaLM에서 지속적으로 훈련되며, UL2의 데노아저 혼합 목표 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib73" title="">73</a>]</cite>로 몇 단계에서 LLM을 계속 훈련하는 방법이다. 약 2배 계산 절감율이 보고된다.</p>
</div>
<div id="S2.SS2.SSS3.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS3.p3.1">U-PaLM은 나중에 Flan-PaLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib74" title="">74</a>]</cite>로 instruction-finetuned된다. 위에서 언급한 다른 명령어 미세 조정 작업에 비해 플란-PaLM의 미세 조정은 훨씬 더 많은 수의 작업, 더 큰 모델 크기 및 연쇄 사상 데이터를 사용하여 수행된다. 그 결과, Flan-PaLM은 기존의 명령어 추종 모델보다 훨씬 우수한 성능을 보였다. 예를 들어, 1.8K 태스크에서 명령어-파인튜닝된 Flan-PaLM-540B는 PaLM-540B를 큰 마진(평균 +9.4%)만큼 능가한다. 파인튜닝 데이터는 그림 <a class="ltx_ref" href="#S2.F14" title="Figure 14 ‣ II-B3 The PaLM Family ‣ II-B Large Language Model Families ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">14</span></a>에 도시된 바와 같이 473개의 데이터 세트, 146개의 작업 범주 및 1,836개의 총 작업으로 구성된다.</p>
</div>
<figure id="S2.F14" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/FlanPaLM.png" id="S2.F14.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="396" height="284" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F14.3.1.1" style="font-size:90%;">Figure 14</span>:</span><span class="ltx_text" id="S2.F14.4.2" style="font-size:90%;">Flan-PaLM finetuning consist of 473 datasets in the above task categories. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib74" title="">74</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S2.SS2.SSS3.p4" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS3.p4.1">PaLM-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib75" title="">75</a>]</cite>는 이전의 PaLM에 비해 더 나은 다국어 및 추론 능력을 가진 더 계산 효율적인 LLM이다. PaLM-2는 목표의 혼합을 사용하여 훈련된다. PaLM-2는 영어, 다국어 및 추론 작업에 대한 광범위한 평가를 통해 다양한 모델 크기에 걸쳐 다운스트림 작업에 대한 모델 성능을 크게 향상시키는 동시에 PaLM보다 빠르고 효율적인 추론을 나타낸다.</p>
</div>
<div id="S2.SS2.SSS3.p5" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS3.p5.1">Med-PaLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib76" title="">76</a>]</cite>는 도메인별 PaLM이며 의료 질문에 대한 고품질 답변을 제공하도록 설계되었다. Med-PaLM은 몇 가지 예를 사용하여 LLM을 새로운 도메인에 정렬하기 위한 매개변수 효율적인 방법인 명령 프롬프트 튜닝을 사용하여 PaLM에서 미세 조정된다. Med-PaLM은 많은 의료 업무에 대해 매우 고무적인 결과를 얻지만 여전히 인간 임상의에 비해 열등하다. Med-PaLM 2는 Med-domain finetuning과 ensemble prompting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib77" title="">77</a>]</cite>를 통해 Med-PaLM을 개선한다. Med-PaLM 2는 MedQA 데이터 세트(즉, 전문 의료 시험, 연구 및 소비자 질의에 걸쳐 있는 6개의 기존 개방형 질문 응답 데이터 세트를 결합한 벤치마크)에서 최대 86.5%의 점수를 얻었고 Med-PaLM을 19% 이상 개선하고 새로운 최첨단 설정을 했다.</p>
</div>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">Other Representative LLMs</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p1.1">이전 하위 섹션에서 논의된 모델 외에도 세 모델 패밀리에 속하지 않는 인기 있는 LLM이 있지만 큰 성과를 거두었고 LLM 필드를 앞으로 밀어붙였다. 우리는 이 하위 섹션에서 이러한 LLM을 간략하게 설명한다.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p2.1.1">FLAN:</span> In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>, Wei 등은 언어 모델의 제로샷 학습 능력을 향상시키기 위한 간단한 방법을 탐색하였다. 그들은 명령어들을 통해 기술된 데이터 세트들의 컬렉션 상의 명령어 튜닝 언어 모델들이 보이지 않는 태스크들에 대한 제로 샷 성능을 실질적으로 향상시킨다는 것을 보여주었다. 그들은 137B 매개변수 사전 훈련된 언어 모델을 취하고 자연어 명령어 템플릿을 통해 구두화된 60개 이상의 NLP 데이터 세트에서 이를 조정한다. 그들은 이것을 명령어 조정 모델 FLAN이라고 부른다. 그림 <a class="ltx_ref" href="#S2.F15" title="Figure 15 ‣ II-C Other Representative LLMs ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">15</span></a>는 사전 훈련-미세 조정 및 프롬프트와 명령어 조정의 비교를 제공한다.</p>
</div>
<figure id="S2.F15" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/FLAN.png" id="S2.F15.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="399" height="134" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F15.3.1.1" style="font-size:90%;">Figure 15</span>:</span><span class="ltx_text" id="S2.F15.4.2" style="font-size:90%;">comparison of instruction tuning with pretrain-finetune and prompting. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S2.SS3.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p3.1.1">Gopher:</span> In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib79" title="">79</a>]</cite> Rae 등은 광범위한 모델 스케일에 걸친 Transformer 기반 언어 모델 성능의 분석을 제시하였는데, 이는 수천만 개의 파라미터를 가진 모델부터 최대 2,800억 개의 파라미터 모델까지 Gopher라고 한다. 이 모델은 152개의 다양한 작업에 대해 평가되어 대다수에 걸쳐 최첨단 성능을 달성했다. 레이어 수, 키/값 크기 및 다른 모델 크기의 기타 하이퍼 매개 변수는 그림 <a class="ltx_ref" href="#S2.F16" title="Figure 16 ‣ II-C Other Representative LLMs ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">16</span></a>에 나와 있다.</p>
</div>
<figure id="S2.F16" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/gopher.png" id="S2.F16.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="404" height="111" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F16.3.1.1" style="font-size:90%;">Figure 16</span>:</span><span class="ltx_text" id="S2.F16.4.2" style="font-size:90%;">Model architecture details of Gopher with different number of parameters. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S2.SS3.p4" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p4.1.1">T0:</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib80" title="">80</a>]</cite>, Sanh 등은 임의의 자연어 태스크를 사람이 읽을 수 있는 프롬프트 형태로 쉽게 매핑하기 위한 시스템인 T0을 개발했다. 그들은 다양한 문구를 가진 여러 프롬프트가 있는 감독된 데이터 세트의 큰 세트를 변환했다. 이러한 프롬프트된 데이터 세트를 사용하면 모델이 완전히 보류된 작업을 수행하는 능력을 벤치마킹할 수 있습니다. 그런 다음 텍스트 입력을 소비하고 목표 응답을 생성하기 위해 T0 인코더-디코더 모델이 개발된다. 모델은 서로 다른 태스크로 분할된 NLP 데이터 세트의 멀티태스크 혼합물에 대해 트레이닝된다.</p>
</div>
<div id="S2.SS3.p5" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p5.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p5.1.1">ERNIE 3.0:</span> In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib81" title="">81</a>]</cite>, Sun 등은 Pre-training large-scale knowledge enhanced models을 위해 ERNIE 3.0이라는 통일된 프레임워크를 제안하였다. 자동 회귀 네트워크와 자동 인코딩 네트워크를 융합하여 학습된 모델이 제로 샷 학습, 적은 샷 학습 또는 미세 조정을 사용하여 자연어 이해 및 생성 작업 모두에 쉽게 맞춤화될 수 있도록 한다. 그들은 일반 텍스트와 대규모 지식 그래프로 구성된 4TB 코퍼스에서 100억 개의 매개변수로 ERNIE 3.0을 훈련했다. <a class="ltx_ref" href="#S2.F17" title="Figure 17 ‣ II-C Other Representative LLMs ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">17</span></a>는 어니 3.0의 모델 아키텍처를 예시한다.</p>
</div>
<figure id="S2.F17" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/ernie3.png" id="S2.F17.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="387" height="210" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F17.3.1.1" style="font-size:90%;">Figure 17</span>:</span><span class="ltx_text" id="S2.F17.4.2" style="font-size:90%;">High-level model architecture of ERNIE 3.0. Courtesy of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib81" title="">81</a>]</cite>. </span></figcaption>
</figure>
<div id="S2.SS3.p6" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p6.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p6.1.1">RETRO:</span> In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>, Borgeaud et al. enhanced auto-regressive language models by conditioning on the document chunk retrieved from a large corpus, based on local similarity with preceding tokens. 2조 개의 토큰 데이터베이스를 사용하여 Retrieval-Enhanced Transformer(Retro)는 25% 적은 매개 변수를 사용함에도 불구하고 파일에서 GPT-3 및 Jurassic-1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib83" title="">83</a>]</cite>와 유사한 성능을 얻는다. 도 <a class="ltx_ref" href="#S2.F18" title="Figure 18 ‣ II-C Other Representative LLMs ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">18</span></a>에 도시된 바와 같이, Retro는 동결된 Bert 리트리버, 미분가능한 인코더 및 청크화된 교차-어텐션 메커니즘을 결합하여 트레이닝 동안 통상적으로 소비되는 것보다 더 많은 데이터 크기에 기초하여 토큰들을 예측한다.</p>
</div>
<figure id="S2.F18" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/retro.png" id="S2.F18.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="421" height="166" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F18.3.1.1" style="font-size:90%;">Figure 18</span>:</span><span class="ltx_text" id="S2.F18.4.2" style="font-size:90%;">Retro architecture. 왼쪽: 길이 n = 12의 시퀀스가 크기 m = 4의 l = 3 청크로 분할되는 단순화된 버전. 각 청크에 대해, 우리는 각각 r = 5 토큰의 k = 2 이웃을 검색한다. 검색 경로가 맨 위에 표시됩니다. 오른쪽: CCA 연산자의 상호 작용에 대한 세부 정보입니다. 인과성은 제1 청크의 이웃들이 제1 청크의 마지막 토큰 및 제2 청크로부터의 토큰들에만 영향을 미치기 때문에 유지된다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S2.SS3.p7" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p7.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p7.1.1">GLaM:</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib84" title="">84</a>]</cite>에서 Du 등은 GLaM(Generalist Language Model)이라고 명명된 LLMs 패밀리를 제안했는데, 이 패밀리는 희소하게 활성화된 혼합물-전문가 아키텍처를 사용하여 모델 용량을 스케일링하는 동시에 조밀한 변이체에 비해 실질적으로 적은 트레이닝 비용을 발생시킨다. 가장 큰 GLaM은 1.2조 개의 매개변수를 가지며, 이는 GPT-3보다 약 7배 크다. GPT-3을 훈련하는 데 사용되는 에너지의 1/3만 소비하고 추론을 위해 계산 플롭의 절반을 요구하지만 29개의 NLP 작업에서 여전히 더 나은 전체 제로, 1 및 소수의 샷 성능을 달성한다. 그림 <a class="ltx_ref" href="#S2.F19" title="Figure 19 ‣ II-C Other Representative LLMs ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">19</span></a>는 GLAM의 상위 레벨 아키텍처를 보여준다.</p>
</div>
<figure id="S2.F19" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/GLAM.png" id="S2.F19.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="203" height="249" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F19.3.1.1" style="font-size:90%;">Figure 19</span>:</span><span class="ltx_text" id="S2.F19.4.2" style="font-size:90%;">GLaM 모델 아키텍처. 각각의 MoE 층(the bottom</span></figcaption><figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F19.3.1.1" class="ltx_text" style="font-size:90%;">Figure 19</span>: </span><span id="S2.F19.4.2" class="ltx_text" style="font-size:90%;">GLaM model architecture. Each MoE layer (the bottom
block) is interleaved with a Transformer layer (the upper block). Courtesy of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite>.</span></figcaption>
</figure>
<div id="S2.SS3.p8" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p8.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p8.1.1">LaMDA:</span> In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib85" title="">85</a>]</cite>, Thoppilan et al. presented LaMDA, a family of Transformer-based neural language models specialized for dialog, which has up to 137B parameters and pre-trained on 1.56T words of public dialog data and web text. 그들은 주석이 달린 데이터로 미세 조정하고 모델이 외부 지식 소스와 상담할 수 있도록 하는 것이 안전과 사실적 근거의 두 가지 주요 문제를 크게 개선할 수 있음을 보여주었다.</p>
</div>
<div id="S2.SS3.p9" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p9.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p9.1.1">OPT:</span> In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib86" title="">86</a>]</cite>, Zhang 등은 Open Pre-trained Transformers (OPT), a suite of decoder-only pre-trained Transformers ranging from 125M to 175B parameters, they share with researchers. OPT 모델의 매개 변수는 <a class="ltx_ref" href="#S2.F20" title="Figure 20 ‣ II-C Other Representative LLMs ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">20</span></a>에 나와 있습니다.</p>
</div>
<figure id="S2.F20" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/opt.png" id="S2.F20.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="192" height="134" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F20.3.1.1" style="font-size:90%;">Figure 20</span>:</span><span class="ltx_text" id="S2.F20.4.2" style="font-size:90%;">Different OPT Models' architecture details. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib86" title="">86</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S2.SS3.p10" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p10.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p10.1.1">Chinchilla:</span> In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib2" title="">2</a>]</cite> Hoffmann et al. investigated the optimal model size and number of tokens for training a transformer language model under the given compute budget. 5,000억에서 5,000억 토큰에 대해 7,000만에서 160억 이상의 매개변수에 이르는 400개 이상의 언어 모델을 훈련함으로써, 그들은 컴퓨팅-최적 훈련을 위해 모델 크기와 훈련 토큰의 수가 동등하게 스케일링되어야 한다는 것을 발견했다: 모델 크기의 두 배가 될 때마다 훈련 토큰의 수 또한 두 배가 되어야 한다. 그들은 고퍼와 동일한 컴퓨팅 예산을 사용하지만 70B 매개변수와 4% 더 많은 데이터를 사용하는 예측된 컴퓨팅 최적 모델인 친칠라를 훈련하여 이 가설을 테스트했다.</p>
</div>
<div id="S2.SS3.p11" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p11.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p11.1.1">Galactica:</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib87" title="">87</a>]</cite>에서 Taylor 등은 과학적 지식에 대해 저장, 결합 및 추론할 수 있는 대형 언어 모델인 Galactica를 소개하였다. 그들은 논문, 참고 자료, 지식 기반 및 기타 많은 출처의 대규모 과학 코퍼스에 대해 훈련했다. 갈락티카는 추론에서 잘 수행되어 수학적 MMLU에서 친칠라를 41.3%에서 35.7%, MATH에서 PaLM 540B를 20.4% 대 8.8%로 능가했다.</p>
</div>
<div id="S2.SS3.p12" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p12.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p12.1.1">CodeGen:</span> In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib88" title="">88</a>]</cite>, Nijkamp 등은 자연어 및 프로그래밍 언어 데이터 상에서 CODEGEN이라고 불리는 최대 16.1B 파라미터들의 큰 언어 모델들의 패밀리를 트레이닝하고 릴리즈하였으며, 오픈 소싱된 트레이닝 라이브러리 JAXFORMER를 사용하였다. 그들은 휴먼에벌의 제로샷 파이썬 코드 생성에서 이전의 최첨단 기술과 경쟁력이 있음을 입증함으로써 훈련된 모델의 유용성을 보여주었다. 그들은 또한 단일 프로그램이 하위 문제를 지정하는 여러 프롬프트로 인수분해되는 프로그램 합성을 위한 다단계 패러다임을 조사했다. 또한 115개의 다양한 문제 집합으로 구성된 개방형 벤치마크인 멀티턴 프로그래밍 벤치마크(Multi-Turn Programming Benchmark, MTPB)를 구성하여 멀티턴 프롬프트로 인수분해하였다.</p>
</div>
<div id="S2.SS3.p13" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p13.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p13.1.1">AlexaTM:</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib89" title="">89</a>]</cite>에서 Soltan 등은 디노이징과 인과 언어 모델링(CLM) 작업의 혼합물에서 사전 훈련된 다중 언어 대규모 시퀀스-투-시퀀스(seq2seq) 모델이 다양한 작업에서 디코더 전용 모델보다 더 효율적인 소수의 샷 학습자임을 입증했다. 그들은 Alexa Teacher 모델(AlexaTM 20B)이라고 불리는 200억 개의 파라미터 다국어 seq2seq 모델을 훈련시켰고, 1-샷 요약 태스크에서 SOTA(최첨단) 성능을 달성하여 훨씬 더 큰 540B PaLM 디코더 모델을 능가함을 보여주었다. AlexaTM은 46개의 인코더 계층, 32개의 디코더 계층, 32개의 어텐션 헤드, 및 <math alttext="d_{model}=4096" class="ltx_Math" display="inline" id="S2.SS3.p13.1.m1.1"><semantics id="S2.SS3.p13.1.m1.1a"><mrow id="S2.SS3.p13.1.m1.1.1" xref="S2.SS3.p13.1.m1.1.1.cmml"><msub id="S2.SS3.p13.1.m1.1.1.2" xref="S2.SS3.p13.1.m1.1.1.2.cmml"><mi id="S2.SS3.p13.1.m1.1.1.2.2" xref="S2.SS3.p13.1.m1.1.1.2.2.cmml">d</mi><mrow id="S2.SS3.p13.1.m1.1.1.2.3" xref="S2.SS3.p13.1.m1.1.1.2.3.cmml"><mi id="S2.SS3.p13.1.m1.1.1.2.3.2" xref="S2.SS3.p13.1.m1.1.1.2.3.2.cmml">m</mi><mo id="S2.SS3.p13.1.m1.1.1.2.3.1" lspace="0em" rspace="0em" xref="S2.SS3.p13.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S2.SS3.p13.1.m1.1.1.2.3.3" xref="S2.SS3.p13.1.m1.1.1.2.3.3.cmml">o</mi><mo id="S2.SS3.p13.1.m1.1.1.2.3.1a" lspace="0em" rspace="0em" xref="S2.SS3.p13.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S2.SS3.p13.1.m1.1.1.2.3.4" xref="S2.SS3.p13.1.m1.1.1.2.3.4.cmml">d</mi><mo id="S2.SS3.p13.1.m1.1.1.2.3.1b" lspace="0em" rspace="0em" xref="S2.SS3.p13.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S2.SS3.p13.1.m1.1.1.2.3.5" xref="S2.SS3.p13.1.m1.1.1.2.3.5.cmml">e</mi><mo id="S2.SS3.p13.1.m1.1.1.2.3.1c" lspace="0em" rspace="0em" xref="S2.SS3.p13.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S2.SS3.p13.1.m1.1.1.2.3.6" xref="S2.SS3.p13.1.m1.1.1.2.3.6.cmml">l</mi></mrow></msub><mo id="S2.SS3.p13.1.m1.1.1.1" xref="S2.SS3.p13.1.m1.1.1.1.cmml">=</mo><mn id="S2.SS3.p13.1.m1.1.1.3" xref="S2.SS3.p13.1.m1.1.1.3.cmml">4096</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p13.1.m1.1b"><apply id="S2.SS3.p13.1.m1.1.1.cmml" xref="S2.SS3.p13.1.m1.1.1"><eq id="S2.SS3.p13.1.m1.1.1.1.cmml" xref="S2.SS3.p13.1.m1.1.1.1"></eq><apply id="S2.SS3.p13.1.m1.1.1.2.cmml" xref="S2.SS3.p13.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p13.1.m1.1.1.2.1.cmml" xref="S2.SS3.p13.1.m1.1.1.2">subscript</csymbol><ci id="S2.SS3.p13.1.m1.1.1.2.2.cmml" xref="S2.SS3.p13.1.m1.1.1.2.2">𝑑</ci><apply id="S2.SS3.p13.1.m1.1.1.2.3.cmml" xref="S2.SS3.p13.1.m1.1.1.2.3"><times id="S2.SS3.p13.1.m1.1.1.2.3.1.cmml" xref="S2.SS3.p13.1.m1.1.1.2.3.1"></times><ci id="S2.SS3.p13.1.m1.1.1.2.3.2.cmml" xref="S2.SS3.p13.1.m1.1.1.2.3.2">𝑚</ci><ci id="S2.SS3.p13.1.m1.1.1.2.3.3.cmml" xref="S2.SS3.p13.1.m1.1.1.2.3.3">𝑜</ci><ci id="S2.SS3.p13.1.m1.1.1.2.3.4.cmml" xref="S2.SS3.p13.1.m1.1.1.2.3.4">𝑑</ci><ci id="S2.SS3.p13.1.m1.1.1.2.3.5.cmml" xref="S2.SS3.p13.1.m1.1.1.2.3.5">𝑒</ci><ci id="S2.SS3.p13.1.m1.1.1.2.3.6.cmml" xref="S2.SS3.p13.1.m1.1.1.2.3.6">𝑙</ci></apply></apply><cn id="S2.SS3.p13.1.m1.1.1.3.cmml" type="integer" xref="S2.SS3.p13.1.m1.1.1.3">4096</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p13.1.m1.1c">d_{model}=4096</annotation></semantics></math>로 구성된다.</p>
</div>
<div id="S2.SS3.p14" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p14.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p14.1.1">Sparrow:</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib90" title="">90</a>]</cite>에서 Glaese 등은 프롬프트 언어 모델 기준선에 비해 더 도움이 되고 정확하며 무해하도록 훈련된 정보 탐색 대화 에이전트인 Sparrow를 제시하였다. 그들은 인간 피드백으로부터 강화 학습을 사용하여 인간 평가자가 에이전트 행동을 판단하는 데 도움이 되는 두 가지 새로운 추가와 함께 모델을 훈련시켰다. 스패로우 모델의 상위 파이프라인은 그림 <a class="ltx_ref" href="#S2.F21" title="Figure 21 ‣ II-C Other Representative LLMs ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">21</span></a>에 나와 있다.</p>
</div>
<figure id="S2.F21" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/sparrow.png" id="S2.F21.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="329" height="172" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F21.3.1.1" style="font-size:90%;">Figure 21</span>:</span><span class="ltx_text" id="S2.F21.4.2" style="font-size:90%;">Sparrow pipeline relies on human participation to continually expand a training set. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib90" title="">90</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S2.SS3.p15" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p15.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p15.1.1">Minerva:</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib91" title="">91</a>]</cite>에서 Lewkowycz 등은 일반적인 자연어 데이터에 대해 사전 훈련되고 기술 내용에 대해 추가로 훈련된 대규모 언어 모델 Minerva를 도입하여 이전의 LLM 투쟁을 정량적 추론(수학, 과학 및 공학 문제 해결 등)으로 해결했다.</p>
</div>
<div id="S2.SS3.p16" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p16.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p16.1.1">MoD:</span> In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib92" title="">92</a>]</cite> Tay 등은 NLP에서 self-supervision을 위한 일반화되고 통일된 관점을 제시하였으며, 서로 다른 사전 훈련 목적들이 어떻게 서로 캐스팅될 수 있는지, 그리고 서로 다른 목적들 간의 보간이 어떻게 효과적일 수 있는지를 보여준다. 그들은 다양한 사전 훈련 패러다임을 함께 결합하는 사전 훈련 목표인 데노이저 혼합(Mixture-of-Denoisers, MoD)을 제안했다. 이 프레임워크는 언어 학습 통합(UL2)으로 알려져 있다. UL2 사전 훈련 패러다임의 개요는 그림 <a class="ltx_ref" href="#S2.F21" title="Figure 21 ‣ II-C Other Representative LLMs ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">21</span></a>에 나와 있다.</p>
</div>
<figure id="S2.F22" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/ul2.png" id="S2.F22.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="328" height="208" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F22.3.1.1" style="font-size:90%;">Figure 22</span>:</span><span class="ltx_text" id="S2.F22.4.2" style="font-size:90%;">An overview of UL2 pretraining paradigm. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib92" title="">92</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S2.SS3.p17" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p17.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p17.1.1">BLOOM:</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>에서 Scao 등은 수백 명의 연구자들의 협업 덕분에 설계되고 구축된 176B 파라미터 오픈액세스 언어 모델인 BLOOM을 제시하였다. BLOOM은 ROOTS 코퍼스에서 훈련된 디코더 전용 트랜스포머 언어 모델로서, 46개의 자연 언어 및 13개의 프로그래밍 언어(총 59개)로 수백 개의 소스를 포함하는 데이터세트이다. BLOOM 아키텍처의 개요는 그림 <a class="ltx_ref" href="#S2.F23" title="Figure 23 ‣ II-C Other Representative LLMs ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">23</span></a>에 나와 있다.</p>
</div>
<figure id="S2.F23" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/bloom.png" id="S2.F23.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="379" height="184" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F23.3.1.1" style="font-size:90%;">Figure 23</span>:</span><span class="ltx_text" id="S2.F23.4.2" style="font-size:90%;">An overview of BLOOM architecture. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S2.SS3.p18" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p18.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p18.1.1">GLM:</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib94" title="">94</a>]</cite>에서 Zeng 등은 130억 개의 파라미터를 갖는 이중 언어(영어 및 중국어) 사전 학습된 언어 모델인 GLM-130B를 소개하였다. 적어도 GPT-3(다빈치)만큼 좋은 100B 규모의 모델을 오픈 소스화하고 그러한 규모의 모델이 성공적으로 사전 훈련될 수 있는 방법을 공개하려는 시도였다.</p>
</div>
<div id="S2.SS3.p19" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p19.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p19.1.1">Pythia:</span> In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib95" title="">95</a>]</cite>, Biderman 등은 Pythia, a suite of 16 LLMs all trained on public data seen in exactly same order and ranging in size from 70M to 12B parameters. 추가 연구를 위해 정확한 훈련 데이터 로더를 다운로드하고 재구성하는 도구와 함께 16개 모델 각각에 대해 154개의 체크포인트에 대한 공개 액세스를 제공한다.</p>
</div>
<div id="S2.SS3.p20" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p20.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p20.1.1">Orca:</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib96" title="">96</a>]</cite>에서 Mukherjee 등은 큰 기초 모델의 추론 과정을 모방하도록 학습하는 130억 개의 파라미터 모델인 Orca를 개발한다. 오르카는 설명 트레이스를 포함한 GPT-4의 풍부한 신호, 단계별 사고 과정, ChatGPT의 교사 지원에 의해 안내되는 기타 복잡한 명령으로부터 학습한다.</p>
</div>
<div id="S2.SS3.p21" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p21.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p21.1.1">StarCoder:</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib97" title="">97</a>]</cite>, Li 등은 StarCoder와 StarCoderBase를 소개하였다. 8K 컨텍스트 길이, 채우기 기능 및 다중 쿼리 주의에 의해 활성화된 빠른 대규모 배치 추론을 가진 15.5B 매개변수 모델이다. 스타코더베이스는 검사 도구와 옵트아웃 프로세스를 갖춘 허가된 GitHub 리포지토리의 대규모 컬렉션인 더 스택에서 조달한 1조 개의 토큰에 대해 교육됩니다. 그들은 35B Python 토큰에서 StarCoderBase를 미세 조정하여 StarCoder를 만들었습니다. 그들은 현재까지 코드 LLM에 대한 가장 포괄적인 평가를 수행했으며 StarCoderBase가 여러 프로그래밍 언어를 지원하는 모든 오픈 코드 LLM을 능가하고 OpenAI 코드-cushman-001 모델과 일치하거나 능가함을 보여주었다.</p>
</div>
<div id="S2.SS3.p22" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p22.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p22.1.1">KOSMOS:</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib98" title="">98</a>]</cite>에서 Huang 등은 KOSMOS-1, a Multimodal Large Language Model (MLLM)을 도입하여 일반적인 모달리티를 인지하고, 문맥에서 학습(즉, few-shot), 명령어(즉, zero-shot)를 따를 수 있다. 구체적으로, 그들은 임의로 인터리빙된 텍스트와 이미지, 이미지-캡션 쌍 및 텍스트 데이터를 포함한 웹 규모의 멀티모달 코퍼라에서 처음부터 KOSMOS-1을 훈련시켰다. 실험 결과, KOSMOS-1은 (i) 언어 이해, 생성, 심지어 OCR이 없는 NLP(문서 이미지가 직접 공급됨), (ii) 멀티모달 대화, 이미지 캡션, 시각적 질문 응답을 포함한 지각 언어 작업, (iii) 설명을 사용한 이미지 인식(텍스트 명령을 통한 분류 지정)과 같은 비전 작업에 대해 인상적인 성능을 달성했다.</p>
</div>
<div id="S2.SS3.p23" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p23.1"><span class="ltx_text ltx_font_bold" id="S2.SS3.p23.1.1">Gemini:</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>에서 Gemini 팀은 이미지, 오디오, 비디오 및 텍스트 이해에 걸쳐 유망한 기능을 나타내는 새로운 멀티모달 모델 패밀리를 도입했습니다. 제미니 패밀리에는 고도로 복잡한 작업을 위한 울트라, 대규모의 향상된 성능과 배포성을 위한 프로, 온-디바이스 애플리케이션을 위한 나노의 세 가지 버전이 포함됩니다. 제미니 아키텍처는 트랜스포머 디코더 위에 구축되며, (효율적인 주의 메커니즘을 사용하여) 32k 컨텍스트 길이를 지원하도록 훈련된다.</p>
</div>
<figure id="S2.F24" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/timeline.png" id="S2.F24.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="1062" height="505" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F24.7.3.1" style="font-size:90%;">그림 24</span>:</span><span class="ltx_text" id="S2.F24.5.2" style="font-size:90%;">가장 대표적인 LLM 프레임워크(지금까지)의 일부 타임라인. 본 논문에서 제안한 #파라미터 임계치를 갖는 대규모 언어 모델 외에도, 언어 모델의 한계를 밀어붙인 몇 가지 대표적인 작업들을 포함시켰고, 그 성공의 길을 열어준 바닐라 트랜스포머, BERT, GPT-1과 같은 몇몇 소규모 언어 모델들을 포함시켰다. </span></figcaption><figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F24.7.3.1" class="ltx_text" style="font-size:90%;">Figure 24</span>: </span><span id="S2.F24.5.2" class="ltx_text" style="font-size:90%;">Timeline of some of the most representative LLM frameworks (so far). In addition to large language models with our #parameters threshold, we included a few representative works, which pushed the limits of language models, and paved the way for their success (e.g. vanilla Transformer, BERT, GPT-1), as well as some small language models.
<math id="S2.F24.4.1.m1.1" class="ltx_Math" alttext="\clubsuit" display="inline"><semantics id="S2.F24.4.1.m1.1b"><mi mathvariant="normal" id="S2.F24.4.1.m1.1.1" xref="S2.F24.4.1.m1.1.1.cmml">♣</mi><annotation-xml encoding="MathML-Content" id="S2.F24.4.1.m1.1c"><ci id="S2.F24.4.1.m1.1.1.cmml" xref="S2.F24.4.1.m1.1.1">♣</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F24.4.1.m1.1d">\clubsuit</annotation></semantics></math> shows entities that serve not only as models but also as approaches. <math id="S2.F24.5.2.m2.1" class="ltx_Math" alttext="\blacklozenge" display="inline"><semantics id="S2.F24.5.2.m2.1b"><mi mathvariant="normal" id="S2.F24.5.2.m2.1.1" xref="S2.F24.5.2.m2.1.1.cmml">◆</mi><annotation-xml encoding="MathML-Content" id="S2.F24.5.2.m2.1c"><ci id="S2.F24.5.2.m2.1.1.cmml" xref="S2.F24.5.2.m2.1.1">◆</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.F24.5.2.m2.1d">\blacklozenge</annotation></semantics></math> shows only approaches.</span></figcaption>
</figure>
<div id="S2.SS3.p24" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p24.1">다른 인기 있는 LLM 프레임워크들(또는 LLM의 효율적인 개발을 위해 사용되는 기술들) 중 일부는 Inner-Monologue <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib100" title="">100</a>]</cite>, Megatron-Turing NLG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib101" title="">101</a>]</cite>, LongFormer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib102" title="">102</a>]</cite>, OPT-IML <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib103" title="">103</a>]</cite>, MeTaLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib104" title="">104</a>]</cite>, Dromedary <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib105" title="">105</a>]</cite>, Palmyra <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib106" title="">106</a>]</cite>, Camel <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib107" title="">107</a>]</cite>, Mephyr <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>, ORCA-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>, Mamba <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>, Mixtral-8x7B <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib117" title="">117</a>]</cite>, DocLLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib118" title="">118</a>]</cite>, DeepSeek-Coder <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib119" title="">119</a>]</cite>, FuseLL</p>
</div>
<div id="S2.SS3.p25" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p25.1">그림 <a class="ltx_ref" href="#S2.F24" title="Figure 24 ‣ II-C Other Representative LLMs ‣ II Large Language Models ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">24</span></a>는 가장 대표적인 LLM 프레임워크 중 일부와 LLM 성공에 기여하고 LLM 한계를 밀어내는 데 도움이 된 관련 작업에 대한 개요를 제공한다.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">How LLMs Are Built</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p" id="S3.p1.1">이 섹션에서는 먼저 LLM에 사용되는 인기 있는 아키텍처를 검토한 다음 데이터 준비, 토큰화, 사전 훈련, 명령어 튜닝 및 정렬에 이르는 데이터 및 모델링 기술에 대해 논의한다.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p class="ltx_p" id="S3.p2.1">모델 아키텍처가 선택되면, LLM 트레이닝에 관련된 주요 단계는 데이터 준비(수집, 청소, 디듀핑 등), 토큰화, 모델 사전 트레이닝(자기 지도 학습 방식으로), 명령어 튜닝 및 정렬을 포함한다. 우리는 그것들을 각각 아래에 별도의 하위 섹션으로 설명할 것이다. 이들 단계는 또한 도 <a class="ltx_ref" href="#S3.F25" title="Figure 25 ‣ III How LLMs Are Built ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">25</span></a>에 예시되어 있다.</p>
</div>
<figure id="S3.F25" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/x4.png" id="S3.F25.g1" class="ltx_graphics ltx_centering ltx_img_square" width="405" height="458" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F25.2.1.1" style="font-size:90%;">그림 25</span>:</span><span class="ltx_text" id="S3.F25.3.2" style="font-size:90%;">이 그림은 LLM의 다른 구성 요소를 보여줍니다. </span></figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Dominant LLM Architectures</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.p1.1">가장 널리 사용되는 LLM 아키텍처는 인코더 전용, 디코더 전용 및 인코더-디코더이다. 대부분은 트랜스포머(빌딩 블록)를 기반으로 합니다. 따라서 본 논문에서는 트랜스포머 아키텍처를 검토한다.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS1.5.1.1" class="ltx_text">III-A</span>1 </span><span id="S3.SS1.SSS1.6.2" class="ltx_text ltx_font_bold">Transformer</span>
</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">Vaswani 등은 GPU를 이용한 효과적인 병렬 컴퓨팅을 위해 고안된 Transformer 프레임워크를 획기적인 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib44" title="">44</a>]</cite>에서 제안하였다. 트랜스포머의 핵심은 반복 및 컨볼루션 메커니즘보다 GPU를 사용하여 훨씬 더 효과적으로 장기 컨텍스트 정보를 캡처할 수 있는 (자기-주의 메커니즘)이다. <a class="ltx_ref" href="#S3.F26" title="Figure 26 ‣ III-A1 Transformer ‣ III-A Dominant LLM Architectures ‣ III How LLMs Are Built ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">26</span></a>는 변압기 작업에 대한 높은 수준의 개요를 제공한다. 이 섹션에서는 주요 요소 및 변형에 대한 개요를 제공하며 자세한 내용은 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib44" title="">44</a>, <a class="ltx_ref" href="#bib.bib123" title="">123</a>]</cite>를 참조하세요.</p>
</div>
<div id="S3.SS1.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.p2.5">원래 기계 번역을 위해 제안된 트랜스포머 언어 모델 아키텍처는 인코더와 디코더로 구성된다. 인코더는 N=6개의 동일한 트랜스포머 계층들의 스택으로 구성된다. 각 층은 두 개의 하위 층을 갖는다. 첫 번째는 다중 헤드 자기 주의 계층이고, 다른 하나는 간단한 위치-와이즈 완전 연결 피드-포워드 네트워크이다. 디코더는 6개의 동일한 층들의 스택으로 구성된다. 각각의 인코더 계층 내의 2개의 서브-레이어에 더하여, 디코더는 제3 서브-레이어를 가지며, 이는 인코더 스택의 출력에 걸쳐 멀티-헤드 어텐션을 수행한다. 어텐션 함수는 쿼리 및 키-값 쌍의 세트를 출력에 매핑하는 것으로 설명될 수 있으며, 여기서 쿼리, 키, 값 및 출력은 모두 벡터이다. 출력은 값들의 가중 합으로서 계산되며, 여기서 각각의 값에 할당된 가중치는 대응하는 키와의 질의의 호환성 함수에 의해 계산된다. <math alttext="d_{model}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p2.1.m1.1"><semantics id="S3.SS1.SSS1.p2.1.m1.1a"><msub id="S3.SS1.SSS1.p2.1.m1.1.1" xref="S3.SS1.SSS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.p2.1.m1.1.1.2" xref="S3.SS1.SSS1.p2.1.m1.1.1.2.cmml">d</mi><mrow id="S3.SS1.SSS1.p2.1.m1.1.1.3" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.cmml"><mi id="S3.SS1.SSS1.p2.1.m1.1.1.3.2" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.2.cmml">m</mi><mo id="S3.SS1.SSS1.p2.1.m1.1.1.3.1" lspace="0em" rspace="0em" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS1.p2.1.m1.1.1.3.3" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.3.cmml">o</mi><mo id="S3.SS1.SSS1.p2.1.m1.1.1.3.1a" lspace="0em" rspace="0em" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS1.p2.1.m1.1.1.3.4" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.4.cmml">d</mi><mo id="S3.SS1.SSS1.p2.1.m1.1.1.3.1b" lspace="0em" rspace="0em" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS1.p2.1.m1.1.1.3.5" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.5.cmml">e</mi><mo id="S3.SS1.SSS1.p2.1.m1.1.1.3.1c" lspace="0em" rspace="0em" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS1.p2.1.m1.1.1.3.6" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.6.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.1.m1.1b"><apply id="S3.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.2">𝑑</ci><apply id="S3.SS1.SSS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.3"><times id="S3.SS1.SSS1.p2.1.m1.1.1.3.1.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.1"></times><ci id="S3.SS1.SSS1.p2.1.m1.1.1.3.2.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.2">𝑚</ci><ci id="S3.SS1.SSS1.p2.1.m1.1.1.3.3.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.3">𝑜</ci><ci id="S3.SS1.SSS1.p2.1.m1.1.1.3.4.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.4">𝑑</ci><ci id="S3.SS1.SSS1.p2.1.m1.1.1.3.5.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.5">𝑒</ci><ci id="S3.SS1.SSS1.p2.1.m1.1.1.3.6.cmml" xref="S3.SS1.SSS1.p2.1.m1.1.1.3.6">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.1.m1.1c">d_{model}</annotation></semantics></math> 차원 키, 값 및 쿼리로 단일 주의 함수를 수행하는 대신, 쿼리, 키 및 값 <math alttext="h" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p2.2.m2.1"><semantics id="S3.SS1.SSS1.p2.2.m2.1a"><mi id="S3.SS1.SSS1.p2.2.m2.1.1" xref="S3.SS1.SSS1.p2.2.m2.1.1.cmml">h</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.2.m2.1b"><ci id="S3.SS1.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p2.2.m2.1.1">ℎ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.2.m2.1c">h</annotation></semantics></math>를 각각 다르게 선형 투영하고, 학습된 선형 투영을 <math alttext="d_{k}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p2.3.m3.1"><semantics id="S3.SS1.SSS1.p2.3.m3.1a"><msub id="S3.SS1.SSS1.p2.3.m3.1.1" xref="S3.SS1.SSS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.SSS1.p2.3.m3.1.1.2" xref="S3.SS1.SSS1.p2.3.m3.1.1.2.cmml">d</mi><mi id="S3.SS1.SSS1.p2.3.m3.1.1.3" xref="S3.SS1.SSS1.p2.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.3.m3.1b"><apply id="S3.SS1.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1.2">𝑑</ci><ci id="S3.SS1.SSS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.SSS1.p2.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.3.m3.1c">d_{k}</annotation></semantics></math>, <math alttext="d_{k}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p2.4.m4.1"><semantics id="S3.SS1.SSS1.p2.4.m4.1a"><msub id="S3.SS1.SSS1.p2.4.m4.1.1" xref="S3.SS1.SSS1.p2.4.m4.1.1.cmml"><mi id="S3.SS1.SSS1.p2.4.m4.1.1.2" xref="S3.SS1.SSS1.p2.4.m4.1.1.2.cmml">d</mi><mi id="S3.SS1.SSS1.p2.4.m4.1.1.3" xref="S3.SS1.SSS1.p2.4.m4.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.4.m4.1b"><apply id="S3.SS1.SSS1.p2.4.m4.1.1.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.4.m4.1.1.1.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.4.m4.1.1.2.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1.2">𝑑</ci><ci id="S3.SS1.SSS1.p2.4.m4.1.1.3.cmml" xref="S3.SS1.SSS1.p2.4.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.4.m4.1c">d_{k}</annotation></semantics></math> 및 <math alttext="d_{v}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p2.5.m5.1"><semantics id="S3.SS1.SSS1.p2.5.m5.1a"><msub id="S3.SS1.SSS1.p2.5.m5.1.1" xref="S3.SS1.SSS1.p2.5.m5.1.1.cmml"><mi id="S3.SS1.SSS1.p2.5.m5.1.1.2" xref="S3.SS1.SSS1.p2.5.m5.1.1.2.cmml">d</mi><mi id="S3.SS1.SSS1.p2.5.m5.1.1.3" xref="S3.SS1.SSS1.p2.5.m5.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p2.5.m5.1b"><apply id="S3.SS1.SSS1.p2.5.m5.1.1.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p2.5.m5.1.1.1.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p2.5.m5.1.1.2.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1.2">𝑑</ci><ci id="S3.SS1.SSS1.p2.5.m5.1.1.3.cmml" xref="S3.SS1.SSS1.p2.5.m5.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p2.5.m5.1c">d_{v}</annotation></semantics></math> 차원으로 선형 투영하는 것이 유익한 것으로 나타났다. 위치 인코딩은 시퀀스 내의 토큰들의 상대적 또는 절대적 위치에 관한 정보를 융합하기 위해 통합된다.</p>
</div>
<figure id="S3.F26" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/transformer.png" id="S3.F26.1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="282" height="378" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F26.3.1.1" style="font-size:90%;">Figure 26</span>:</span><span class="ltx_text" id="S3.F26.4.2" style="font-size:90%;">High-level overview of transformer work. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib44" title="">44</a>]</cite>의 예절. </span></figcaption>
</figure>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS2.5.1.1" class="ltx_text">III-A</span>2 </span><span id="S3.SS1.SSS2.6.2" class="ltx_text ltx_font_bold">Encoder-Only</span>
</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">이 패밀리의 경우 각 단계에서 어텐션 레이어는 초기 문장의 모든 단어에 액세스할 수 있다. 이러한 모델의 사전 훈련은 일반적으로 주어진 문장을 어떻게든 손상시키는 것(예를 들어, 그 안에 무작위 단어를 마스킹함으로써)과 초기 문장을 찾거나 재구성하는 것으로 모델을 작업시키는 것으로 구성된다. 인코더 모델은 문장 분류, 개체명 인식 및 추출 질의 응답과 같이 전체 시퀀스에 대한 이해가 필요한 작업에 적합하다. 하나의 두드러진 인코더 전용 모델은 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>]</cite>에서 제안된 BERT(Bidirectional Encoder Representations from Transformers)이다.</p>
</div>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS3.5.1.1" class="ltx_text">III-A</span>3 </span><span id="S3.SS1.SSS3.6.2" class="ltx_text ltx_font_bold">Decoder-Only</span>
</h4>

<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS3.p1.1">이러한 모델의 경우 각 단계에서 모든 단어에 대해 어텐션 레이어는 문장에서 그 앞에 위치한 단어에만 액세스할 수 있다. 이러한 모델은 때때로 자동 회귀 모델이라고도 합니다. 이러한 모델의 사전 훈련은 일반적으로 시퀀스에서 다음 단어(또는 토큰)를 예측하는 것으로 공식화된다. 디코더 전용 모델은 텍스트 생성과 관련된 작업에 가장 적합하다. GPT 모델은 이 모델 범주의 두드러진 예이다.</p>
</div>
</section>
<section id="S3.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS4.5.1.1" class="ltx_text">III-A</span>4 </span><span id="S3.SS1.SSS4.6.2" class="ltx_text ltx_font_bold">Encoder-Decoder</span>
</h4>

<div id="S3.SS1.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS4.p1.1">이러한 모델들은 인코더와 디코더를 모두 사용하며, 때때로 시퀀스-투-시퀀스 모델이라고 불린다. 각 단계에서, 인코더의 어텐션 계층들은 초기 문장 내의 모든 단어들에 액세스할 수 있는 반면, 디코더의 어텐션 계층들은 입력 내의 주어진 단어 이전에 위치된 단어들에만 액세스한다. 이러한 모델들은 보통 인코더 또는 디코더 모델들의 목적들을 사용하여 사전 트레이닝되지만, 보통은 약간 더 복잡한 것을 수반한다. 예를 들어, 일부 모델은 (여러 단어를 포함할 수 있는) 텍스트의 랜덤 스팬을 단일 마스크 특수 단어로 대체함으로써 사전 트레이닝되고, 그 다음 목적은 이 마스크 단어가 대체하는 텍스트를 예측하는 것이다. 인코더-디코더 모델들은 요약, 번역 또는 생성 질의 응답과 같은 주어진 입력에 조건화된 새로운 문장들을 생성하는 것에 관한 태스크들에 가장 적합하다.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Data Cleaning</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p1.1">데이터 품질은 언어 모델에 대해 훈련된 언어 모델의 성능에 매우 중요합니다. 필터링, 중복제거와 같은 데이터 클리닝 기법은 모델 성능에 큰 영향을 미치는 것으로 나타났다.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p2.1">예를 들어, <span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Falcon40B</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib124" title="">124</a>]</cite>에서 Penedo 등은 적절하게 필터링되고 중복 제거된 웹 데이터만으로도 강력한 모델로 이어질 수 있음을 보여주었으며, 심지어 The Pile에서 훈련된 최첨단 모델의 모델도 상당히 능가했다. 광범위한 필터링에도 불구하고, 그들은 커먼크롤로부터 5조 개의 토큰을 얻을 수 있었다. 그들은 또한 REFINEDWEB 데이터 세트에서 6,000억 토큰의 추출물과 이에 대해 훈련된 1.3/7.5B 매개변수 언어 모델을 출시했습니다. <a class="ltx_ref" href="#S3.F27" title="Figure 27 ‣ III-B Data Cleaning ‣ III How LLMs Are Built ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">27</span></a>는 본 작업에 의한 CommonCrawl 데이터의 정제 과정을 보여준다.</p>
</div>
<figure id="S3.F27" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/Falcon40B_filtering.png" id="S3.F27.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="360" height="199" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F27.3.1.1" style="font-size:90%;">그림 27</span>:</span><span class="ltx_text" id="S3.F27.4.2" style="font-size:90%;">Macrodata Refinement의 후속 단계들은 원래 CommonCrawl에 있는 문서들의 거의 90%를 제거한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib124" title="">124</a>]</cite>의 예절. </span></figcaption>
</figure>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS1.5.1.1" class="ltx_text">III-B</span>1 </span>Data Filtering</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">데이터 필터링은 훈련 데이터의 품질과 훈련된 LLM의 효과를 향상시키는 것을 목표로 한다. 공통 데이터 필터링 기술들은 다음을 포함한다:</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p2.1.1">Removing Noise:</span>은 모델의 일반화 능력에 영향을 미칠 수 있는 관련 없거나 노이즈 데이터를 제거하는 것을 말합니다. 예를 들어, 학습 데이터에서 잘못된 정보를 제거하여 모델이 잘못된 응답을 생성할 가능성을 낮추는 것을 생각할 수 있다. 품질 필터링을 위한 두 가지 주류 접근법은 분류기 기반 및 휴리스틱 기반 프레임워크를 포함한다.</p>
</div>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p3.1.1">Handling Outliers:</span> 데이터에서 Outliers 또는 anomalies를 식별하고 처리하여 모델에 불균형적으로 영향을 미치는 것을 방지합니다.</p>
</div>
<div id="S3.SS2.SSS1.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p4.1.1">Addressing Imbalances:</span> Balancing the distribution of classes or categories in the dataset to avoid bias and ensure fair representation. 책임 있는 모델 훈련 및 평가에 특히 유용합니다.</p>
</div>
<div id="S3.SS2.SSS1.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p5.1.1">Text Preprocessing:</span> 모델의 학습에 크게 기여하지 않을 수 있는 중지 단어, 구두점 또는 기타 요소를 제거하여 텍스트 데이터를 정리하고 표준화합니다.</p>
</div>
<div id="S3.SS2.SSS1.p6" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS1.p6.1.1">Dealing with Ambiguities:</span> Resolving or excluding ambiguous or contradictory data that might confuse the model during training. 이는 모델이 보다 확실하고 신뢰할 수 있는 답변을 제공하는 데 도움이 될 수 있다.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS2.SSS2.5.1.1" class="ltx_text">III-B</span>2 </span>Deduplication</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">중복은 데이터셋에서 동일한 데이터의 중복 인스턴스 또는 반복된 발생을 제거하는 과정을 의미한다. 중복된 데이터 포인트는 모델이 동일한 예로부터 여러 번 학습하여 잠재적으로 그러한 특정 인스턴스에 과적합으로 이어질 수 있기 때문에 모델 트레이닝 프로세스에 편향을 도입하고 다양성을 감소시킬 수 있다. 일부 작품 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib125" title="">125</a>]</cite>는 중복 제거가 모델의 새로운 보이지 않는 데이터로 일반화하는 능력을 향상시킨다는 것을 보여주었다.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS2.p2.1">중복은 의도하지 않게 특정 패턴이나 특성의 중요성을 부풀릴 수 있기 때문에 대규모 데이터 세트를 다룰 때 중복 제거 프로세스가 특히 중요하다. 이것은 특히 다양하고 대표적인 훈련 데이터가 강력한 언어 모델을 구축하는 데 중요한 NLP 작업과 관련이 있다.</p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS2.p3.1">특정 중복 제거 방법은 데이터의 특성 및 훈련되는 특정 언어 모델의 요구 사항에 따라 달라질 수 있다. 이는 중복을 식별하고 제거하기 위해 전체 데이터 포인트 또는 특정 특징을 비교하는 것을 수반할 수 있다. 문서 수준에서 기존 작업은 주로 문서 간의 높은 수준의 특징(예: n-gram 중첩)의 중첩 비율에 의존하여 중복 샘플을 탐지한다.</p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Tokenizations</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.p1.1">토큰화는 텍스트 시퀀스를 토큰으로 알려진 더 작은 부분으로 변환하는 프로세스를 의미한다. 가장 간단한 토큰화 도구는 텍스트를 화이트 스페이스에 기초하여 토큰으로 간단히 잘라내는 반면, 대부분의 토큰화 도구는 단어 사전(word dictionary)에 의존한다. 그러나 이 경우 토큰화기는 사전에 단어만 알고 있기 때문에 어휘 외(OOV)가 문제가 된다. 사전의 커버리지를 증가시키기 위해, LLMs에 사용되는 인기 있는 토큰라이저는 서브-워드들에 기초하며, 서브-워드들은 트레이닝 데이터에서 보이지 않는 워드들 또는 상이한 언어들의 워드들을 포함하여 많은 수의 워드들을 형성하도록 결합될 수 있다. 다음은 세 가지 인기 있는 토크나이저에 대해 설명합니다.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS1.5.1.1" class="ltx_text">III-C</span>1 </span><span id="S3.SS3.SSS1.6.2" class="ltx_text ltx_font_bold">BytePairEncoding</span>
</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.p1.1"><span class="ltx_text ltx_font_italic" id="S3.SS3.SSS1.p1.1.1">BytePairEncoding</span>은 원래 바이트 수준에서 빈발 패턴을 사용하여 데이터를 압축하는 데이터 압축 알고리즘의 한 종류이다. 정의에 따르면, 이 알고리즘은 주로 빈발 단어를 원래 형태로 유지하고 일반적이지 않은 단어를 분해하려고 한다. 이 단순한 패러다임은 어휘의 크기를 그다지 크게 유지하지 않을 뿐만 아니라 공통 단어를 동시에 나타낼 수 있을 만큼 충분히 좋다. 또한 알고리즘의 학습 데이터에 접미사 또는 접두사가 공통적으로 제시되면 빈발 단어의 형태적 형태가 매우 잘 표현될 수 있다.</p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS2.5.1.1" class="ltx_text">III-C</span>2 </span><span id="S3.SS3.SSS2.6.2" class="ltx_text ltx_font_bold">WordPieceEncoding</span>
</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS2.p1.1">이 알고리즘은 주로 BERT 및 Electra와 같은 매우 잘 알려진 모델에 사용된다. 훈련 시작 시 알고리즘은 훈련 데이터에서 모든 알파벳을 가져와서 아무것도 UNK 또는 훈련 데이터 세트에서 <span class="ltx_text ltx_font_italic" id="S3.SS3.SSS2.p1.1.1">unknown</span>으로 남지 않도록 합니다. 이 경우 모델에 토큰화기에서 토큰화할 수 없는 입력이 주어질 때 발생합니다. 대부분의 경우 일부 문자가 토큰화할 수 없는 경우에 발생합니다. BytePairEncoding과 유사하게 빈도에 따라 모든 토큰을 어휘에 넣을 가능성을 최대화하려고 한다.</p>
</div>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS3.SSS3.5.1.1" class="ltx_text">III-C</span>3 </span><span id="S3.SS3.SSS3.6.2" class="ltx_text ltx_font_bold">SentencePieceEncoding</span>
</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS3.p1.1">앞서 설명한 두 토큰라이저는 모두 화이트 스페이스 토큰화에 비해 강력하고 많은 이점이 있지만 여전히 단어가 항상 화이트 스페이스로 분리된다는 가정을 당연한 것으로 받아들인다. 이러한 가정이 항상 사실인 것은 아니며, 실제로 일부 언어에서 단어는 원치 않는 공간과 같은 많은 잡음 요소에 의해 손상되거나 심지어 발명된 단어에 의해 손상될 수 있다. SentencePieceEncoding은 이 문제를 해결하려고 합니다.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.5.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.6.2" class="ltx_text ltx_font_bold">Positional Encoding</span>
</h3>

<section id="S3.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS4.SSS1.5.1.1" class="ltx_text">III-D</span>1 </span><span id="S3.SS4.SSS1.6.2" class="ltx_text ltx_font_bold">Absolute Positional Embeddings</span>
</h4>

<div id="S3.SS4.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS1.p1.1">(APE) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib44" title="">44</a>]</cite>는 시퀀스 순서의 정보를 보존하기 위해 원래 Transformer 모델에서 사용되었다. 따라서, 인코더 및 디코더 스택 모두의 하단의 입력 임베딩에 단어의 위치 정보가 추가된다. 위치 인코딩에는 학습되거나 고정된 다양한 옵션이 있다. 바닐라 트랜스포머에서는 사인 함수와 코사인 함수가 이 목적을 위해 사용된다. 트랜스포머에서 APE를 사용하는 것의 주요 단점은 특정 수의 토큰에 대한 제한이다. 또한 APE는 토큰 간의 상대적 거리를 설명하지 못합니다.</p>
</div>
</section>
<section id="S3.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS4.SSS2.5.1.1" class="ltx_text">III-D</span>2 </span><span id="S3.SS4.SSS2.6.2" class="ltx_text ltx_font_bold">Relative Positional Embeddings</span>
</h4>

<div id="S3.SS4.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS2.p1.1">(RPE) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib126" title="">126</a>]</cite>는 입력 요소 간의 쌍별 링크를 고려하기 위해 자기 주의를 확장하는 것을 포함한다. RPE는 두 가지 수준에서 모델에 추가되며, 첫째는 키에 대한 추가 구성 요소이고, 이후는 값 행렬의 하위 구성 요소로 추가된다. 이 접근법은 입력을 레이블 및 지향된 간선이 있는 완전히 연결된 그래프로 본다. 선형 시퀀스의 경우, 에지는 입력 요소 간의 상대적인 위치 차이에 대한 정보를 캡처할 수 있다. k <math alttext="2\leq k\leq n-4" class="ltx_Math" display="inline" id="S3.SS4.SSS2.p1.1.m1.1"><semantics id="S3.SS4.SSS2.p1.1.m1.1a"><mrow id="S3.SS4.SSS2.p1.1.m1.1.1" xref="S3.SS4.SSS2.p1.1.m1.1.1.cmml"><mn id="S3.SS4.SSS2.p1.1.m1.1.1.2" xref="S3.SS4.SSS2.p1.1.m1.1.1.2.cmml">2</mn><mo id="S3.SS4.SSS2.p1.1.m1.1.1.3" xref="S3.SS4.SSS2.p1.1.m1.1.1.3.cmml">≤</mo><mi id="S3.SS4.SSS2.p1.1.m1.1.1.4" xref="S3.SS4.SSS2.p1.1.m1.1.1.4.cmml">k</mi><mo id="S3.SS4.SSS2.p1.1.m1.1.1.5" xref="S3.SS4.SSS2.p1.1.m1.1.1.5.cmml">≤</mo><mrow id="S3.SS4.SSS2.p1.1.m1.1.1.6" xref="S3.SS4.SSS2.p1.1.m1.1.1.6.cmml"><mi id="S3.SS4.SSS2.p1.1.m1.1.1.6.2" xref="S3.SS4.SSS2.p1.1.m1.1.1.6.2.cmml">n</mi><mo id="S3.SS4.SSS2.p1.1.m1.1.1.6.1" xref="S3.SS4.SSS2.p1.1.m1.1.1.6.1.cmml">−</mo><mn id="S3.SS4.SSS2.p1.1.m1.1.1.6.3" xref="S3.SS4.SSS2.p1.1.m1.1.1.6.3.cmml">4</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS2.p1.1.m1.1b"><apply id="S3.SS4.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS4.SSS2.p1.1.m1.1.1"><and id="S3.SS4.SSS2.p1.1.m1.1.1a.cmml" xref="S3.SS4.SSS2.p1.1.m1.1.1"></and><apply id="S3.SS4.SSS2.p1.1.m1.1.1b.cmml" xref="S3.SS4.SSS2.p1.1.m1.1.1"><leq id="S3.SS4.SSS2.p1.1.m1.1.1.3.cmml" xref="S3.SS4.SSS2.p1.1.m1.1.1.3"></leq><cn id="S3.SS4.SSS2.p1.1.m1.1.1.2.cmml" type="integer" xref="S3.SS4.SSS2.p1.1.m1.1.1.2">2</cn><ci id="S3.SS4.SSS2.p1.1.m1.1.1.4.cmml" xref="S3.SS4.SSS2.p1.1.m1.1.1.4">𝑘</ci></apply><apply id="S3.SS4.SSS2.p1.1.m1.1.1c.cmml" xref="S3.SS4.SSS2.p1.1.m1.1.1"><leq id="S3.SS4.SSS2.p1.1.m1.1.1.5.cmml" xref="S3.SS4.SSS2.p1.1.m1.1.1.5"></leq><share href="#S3.SS4.SSS2.p1.1.m1.1.1.4.cmml" id="S3.SS4.SSS2.p1.1.m1.1.1d.cmml" xref="S3.SS4.SSS2.p1.1.m1.1.1"></share><apply id="S3.SS4.SSS2.p1.1.m1.1.1.6.cmml" xref="S3.SS4.SSS2.p1.1.m1.1.1.6"><minus id="S3.SS4.SSS2.p1.1.m1.1.1.6.1.cmml" xref="S3.SS4.SSS2.p1.1.m1.1.1.6.1"></minus><ci id="S3.SS4.SSS2.p1.1.m1.1.1.6.2.cmml" xref="S3.SS4.SSS2.p1.1.m1.1.1.6.2">𝑛</ci><cn id="S3.SS4.SSS2.p1.1.m1.1.1.6.3.cmml" type="integer" xref="S3.SS4.SSS2.p1.1.m1.1.1.6.3">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS2.p1.1.m1.1c">2\leq k\leq n-4</annotation></semantics></math>로 표시되는 클리핑 거리는 상대 위치에 대한 최대 제한을 지정합니다. 이는 모델이 트레이닝 데이터의 일부가 아닌 시퀀스 길이에 대해 합리적인 예측을 할 수 있게 한다.</p>
</div>
</section>
<section id="S3.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS4.SSS3.5.1.1" class="ltx_text">III-D</span>3 </span><span id="S3.SS4.SSS3.6.2" class="ltx_text ltx_font_bold">Rotary Position Embeddings</span>
</h4>

<div id="S3.SS4.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS3.p1.1">Rotary Positional Embedding (RoPE) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib127" title="">127</a>]</cite>는 기존의 접근법들과 문제점을 해결한다. 학습된 절대적 위치 인코딩은 특히 문장이 짧을 때 일반화 가능성과 의미가 부족할 수 있다. 더욱이, T5의 위치 임베딩과 같은 현재의 방법들은 위치들 사이의 완전한 주의 행렬을 구성하는 데 어려움을 겪는다. RoPE는 단어의 절대 위치를 인코딩하기 위해 회전 매트릭스를 사용하고 동시에 자기 주의에 명시적인 상대 위치 세부사항을 포함한다. RoPE는 문장 길이에 대한 유연성, 상대 거리가 증가함에 따른 단어 의존성의 감소, 상대 위치 인코딩을 통한 선형 자기 주의력 향상 기능과 같은 유용한 기능을 제공한다. GPT-NeoX-20B, PaLM, CODEGEN 및 LLaMA는 아키텍처에서 RoPE를 활용하는 모델 중 하나이다.</p>
</div>
</section>
<section id="S3.SS4.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS4.SSS4.5.1.1" class="ltx_text">III-D</span>4 </span><span id="S3.SS4.SSS4.6.2" class="ltx_text ltx_font_bold">Relative Positional Bias</span>
</h4>

<div id="S3.SS4.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS4.p1.1">이러한 유형의 위치 임베딩 뒤에 있는 개념은 훈련에서 마주치는 것보다 긴 시퀀스에 대한 추론 동안 외삽을 용이하게 하는 것이다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib128" title="">128</a>]</cite> Press et al. proposed Attention with Linear Biases (ALiBi). 그들은 단순히 단어 임베딩에 위치 임베딩을 추가하는 대신 쿼리-키 쌍의 주의 점수에 편향을 도입하여 거리에 비례하는 페널티를 부과했다. BLOOM 모델에서는 ALiBi가 레버리지된다.</p>
</div>
<figure id="S3.F28" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F28.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/APE.png" id="S3.F28.sf1.g1" class="ltx_graphics ltx_img_portrait" width="299" height="436" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F28.sf1.2.1.1" style="font-size:90%;">(a)</span></span><span class="ltx_text" id="S3.F28.sf1.3.2" style="font-size:90%;">Absolute Positional Embeddings <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib129" title="">129</a>]</cite></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F28.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/RPE.png" id="S3.F28.sf2.g1" class="ltx_graphics ltx_img_landscape" width="538" height="382" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F28.sf2.2.1.1" style="font-size:90%;">(b)</span></span><span class="ltx_text" id="S3.F28.sf2.3.2" style="font-size:90%;">Relative Positional Embeddings</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F28.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/RoPE.png" id="S3.F28.sf3.g1" class="ltx_graphics ltx_img_landscape" width="538" height="311" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F28.sf3.2.1.1" style="font-size:90%;">(c)</span></span><span class="ltx_text" id="S3.F28.sf3.3.2" style="font-size:90%;">Rotary Positional Embedding <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib127" title="">127</a>]</cite></span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F28.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/alibi.png" id="S3.F28.sf4.g1" class="ltx_graphics ltx_img_landscape" width="419" height="184" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F28.sf4.2.1.1" style="font-size:90%;">(d)</span></span><span class="ltx_text" id="S3.F28.sf4.3.2" style="font-size:90%;">Relative Positional Bias <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib128" title="">128</a>]</cite></span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F28.2.1.1" style="font-size:90%;">Figure 28</span>:</span><span class="ltx_text" id="S3.F28.3.2" style="font-size:90%;">LLMs에는 다양한 위치 인코딩이 사용됩니다. </span></figcaption>
</figure>
</section>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS5.5.1.1" class="ltx_text">III-E</span> </span><span id="S3.SS5.6.2" class="ltx_text ltx_font_italic">Model Pre-training</span>
</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS5.p1.1">사전 훈련은 대규모 언어 모델 훈련 파이프라인에서 첫 번째 단계로 LLM이 기본 언어 이해 능력을 습득할 수 있도록 도와주며, 이는 광범위한 언어 관련 작업에서 유용할 수 있다. 사전 훈련 동안, LLM은 대량의 (일반적으로) 라벨이 지정되지 않은 텍스트, 일반적으로 자기-감독 방식으로 훈련된다. 다음 문장 예측 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>]</cite>와 같이 사전 훈련에 사용되는 다양한 접근법이 있으며, 가장 일반적인 두 가지 방법은 다음 토큰 예측(자동 회귀 언어 모델링) 및 마스킹 언어 모델링이다.</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS5.p2.4"><span class="ltx_text ltx_font_bold" id="S3.SS5.p2.4.1">Autoregressive Language Modeling</span> framework, given a sequence of <math alttext="n" class="ltx_Math" display="inline" id="S3.SS5.p2.1.m1.1"><semantics id="S3.SS5.p2.1.m1.1a"><mi id="S3.SS5.p2.1.m1.1.1" xref="S3.SS5.p2.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.1.m1.1b"><ci id="S3.SS5.p2.1.m1.1.1.cmml" xref="S3.SS5.p2.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.1.m1.1c">n</annotation></semantics></math> tokens <math alttext="x_{1}" class="ltx_Math" display="inline" id="S3.SS5.p2.2.m2.1"><semantics id="S3.SS5.p2.2.m2.1a"><msub id="S3.SS5.p2.2.m2.1.1" xref="S3.SS5.p2.2.m2.1.1.cmml"><mi id="S3.SS5.p2.2.m2.1.1.2" xref="S3.SS5.p2.2.m2.1.1.2.cmml">x</mi><mn id="S3.SS5.p2.2.m2.1.1.3" xref="S3.SS5.p2.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.2.m2.1b"><apply id="S3.SS5.p2.2.m2.1.1.cmml" xref="S3.SS5.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.2.m2.1.1.1.cmml" xref="S3.SS5.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS5.p2.2.m2.1.1.2.cmml" xref="S3.SS5.p2.2.m2.1.1.2">𝑥</ci><cn id="S3.SS5.p2.2.m2.1.1.3.cmml" type="integer" xref="S3.SS5.p2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.2.m2.1c">x_{1}</annotation></semantics></math>, …, <math alttext="x_{n}" class="ltx_Math" display="inline" id="S3.SS5.p2.3.m3.1"><semantics id="S3.SS5.p2.3.m3.1a"><msub id="S3.SS5.p2.3.m3.1.1" xref="S3.SS5.p2.3.m3.1.1.cmml"><mi id="S3.SS5.p2.3.m3.1.1.2" xref="S3.SS5.p2.3.m3.1.1.2.cmml">x</mi><mi id="S3.SS5.p2.3.m3.1.1.3" xref="S3.SS5.p2.3.m3.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.3.m3.1b"><apply id="S3.SS5.p2.3.m3.1.1.cmml" xref="S3.SS5.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.3.m3.1.1.1.cmml" xref="S3.SS5.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS5.p2.3.m3.1.1.2.cmml" xref="S3.SS5.p2.3.m3.1.1.2">𝑥</ci><ci id="S3.SS5.p2.3.m3.1.1.3.cmml" xref="S3.SS5.p2.3.m3.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.3.m3.1c">x_{n}</annotation></semantics></math>, model tries to predict next token <math alttext="x_{n+1}" class="ltx_Math" display="inline" id="S3.SS5.p2.4.m4.1"><semantics id="S3.SS5.p2.4.m4.1a"><msub id="S3.SS5.p2.4.m4.1.1" xref="S3.SS5.p2.4.m4.1.1.cmml"><mi id="S3.SS5.p2.4.m4.1.1.2" xref="S3.SS5.p2.4.m4.1.1.2.cmml">x</mi><mrow id="S3.SS5.p2.4.m4.1.1.3" xref="S3.SS5.p2.4.m4.1.1.3.cmml"><mi id="S3.SS5.p2.4.m4.1.1.3.2" xref="S3.SS5.p2.4.m4.1.1.3.2.cmml">n</mi><mo id="S3.SS5.p2.4.m4.1.1.3.1" xref="S3.SS5.p2.4.m4.1.1.3.1.cmml">+</mo><mn id="S3.SS5.p2.4.m4.1.1.3.3" xref="S3.SS5.p2.4.m4.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p2.4.m4.1b"><apply id="S3.SS5.p2.4.m4.1.1.cmml" xref="S3.SS5.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS5.p2.4.m4.1.1.1.cmml" xref="S3.SS5.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS5.p2.4.m4.1.1.2.cmml" xref="S3.SS5.p2.4.m4.1.1.2">𝑥</ci><apply id="S3.SS5.p2.4.m4.1.1.3.cmml" xref="S3.SS5.p2.4.m4.1.1.3"><plus id="S3.SS5.p2.4.m4.1.1.3.1.cmml" xref="S3.SS5.p2.4.m4.1.1.3.1"></plus><ci id="S3.SS5.p2.4.m4.1.1.3.2.cmml" xref="S3.SS5.p2.4.m4.1.1.3.2">𝑛</ci><cn id="S3.SS5.p2.4.m4.1.1.3.3.cmml" type="integer" xref="S3.SS5.p2.4.m4.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p2.4.m4.1c">x_{n+1}</annotation></semantics></math> (and sometimes next sequence of tokens) in auto-regressive fashion. 이 경우 인기 있는 손실 함수 중 하나는 Eq <a class="ltx_ref" href="#S3.E2" title="In III-E Model Pre-training ‣ III How LLMs Are Built ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">2</span></a>와 같이 예측된 토큰의 로그 우도이다.</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.3" class="ltx_Math" alttext="\mathscr{L}_{ALM}(x)=\sum_{i=1}^{N}p(x_{i+n}|x_{i},...,x_{i+n-1})" display="block"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml"><mrow id="S3.E1.m1.3.3.3" xref="S3.E1.m1.3.3.3.cmml"><msub id="S3.E1.m1.3.3.3.2" xref="S3.E1.m1.3.3.3.2.cmml"><mi class="ltx_font_mathscript" id="S3.E1.m1.3.3.3.2.2" xref="S3.E1.m1.3.3.3.2.2.cmml">ℒ</mi><mrow id="S3.E1.m1.3.3.3.2.3" xref="S3.E1.m1.3.3.3.2.3.cmml"><mi id="S3.E1.m1.3.3.3.2.3.2" xref="S3.E1.m1.3.3.3.2.3.2.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.3.2.3.1" xref="S3.E1.m1.3.3.3.2.3.1.cmml">​</mo><mi id="S3.E1.m1.3.3.3.2.3.3" xref="S3.E1.m1.3.3.3.2.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.3.2.3.1a" xref="S3.E1.m1.3.3.3.2.3.1.cmml">​</mo><mi id="S3.E1.m1.3.3.3.2.3.4" xref="S3.E1.m1.3.3.3.2.3.4.cmml">M</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.3.1" xref="S3.E1.m1.3.3.3.1.cmml">​</mo><mrow id="S3.E1.m1.3.3.3.3.2" xref="S3.E1.m1.3.3.3.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.3.3.2.1" xref="S3.E1.m1.3.3.3.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S3.E1.m1.3.3.3.3.2.2" xref="S3.E1.m1.3.3.3.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S3.E1.m1.3.3.2" xref="S3.E1.m1.3.3.2.cmml">=</mo><mrow id="S3.E1.m1.3.3.1" xref="S3.E1.m1.3.3.1.cmml"><munderover id="S3.E1.m1.3.3.1.2" xref="S3.E1.m1.3.3.1.2.cmml"><mo movablelimits="false" id="S3.E1.m1.3.3.1.2.2.2" xref="S3.E1.m1.3.3.1.2.2.2.cmml">∑</mo><mrow id="S3.E1.m1.3.3.1.2.2.3" xref="S3.E1.m1.3.3.1.2.2.3.cmml"><mi id="S3.E1.m1.3.3.1.2.2.3.2" xref="S3.E1.m1.3.3.1.2.2.3.2.cmml">i</mi><mo id="S3.E1.m1.3.3.1.2.2.3.1" xref="S3.E1.m1.3.3.1.2.2.3.1.cmml">=</mo><mn id="S3.E1.m1.3.3.1.2.2.3.3" xref="S3.E1.m1.3.3.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.3.3.1.2.3" xref="S3.E1.m1.3.3.1.2.3.cmml">N</mi></munderover><mrow id="S3.E1.m1.3.3.1.1" xref="S3.E1.m1.3.3.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.3" xref="S3.E1.m1.3.3.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.3.1.1.2" xref="S3.E1.m1.3.3.1.1.2.cmml">​</mo><mrow id="S3.E1.m1.3.3.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.cmml"><msub id="S3.E1.m1.3.3.1.1.1.1.1.4" xref="S3.E1.m1.3.3.1.1.1.1.1.4.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.4.2" xref="S3.E1.m1.3.3.1.1.1.1.1.4.2.cmml">x</mi><mrow id="S3.E1.m1.3.3.1.1.1.1.1.4.3" xref="S3.E1.m1.3.3.1.1.1.1.1.4.3.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.4.3.2" xref="S3.E1.m1.3.3.1.1.1.1.1.4.3.2.cmml">i</mi><mo id="S3.E1.m1.3.3.1.1.1.1.1.4.3.1" xref="S3.E1.m1.3.3.1.1.1.1.1.4.3.1.cmml">+</mo><mi id="S3.E1.m1.3.3.1.1.1.1.1.4.3.3" xref="S3.E1.m1.3.3.1.1.1.1.1.4.3.3.cmml">n</mi></mrow></msub><mo fence="false" id="S3.E1.m1.3.3.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.3.cmml">|</mo><mrow id="S3.E1.m1.3.3.1.1.1.1.1.2.2" xref="S3.E1.m1.3.3.1.1.1.1.1.2.3.cmml"><msub id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.E1.m1.3.3.1.1.1.1.1.2.2.3" xref="S3.E1.m1.3.3.1.1.1.1.1.2.3.cmml">,</mo><mi mathvariant="normal" id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">…</mi><mo id="S3.E1.m1.3.3.1.1.1.1.1.2.2.4" xref="S3.E1.m1.3.3.1.1.1.1.1.2.3.cmml">,</mo><msub id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.2" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.2.cmml">x</mi><mrow id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.cmml"><mrow id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2.cmml"><mi id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2.2" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2.2.cmml">i</mi><mo id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2.1" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2.1.cmml">+</mo><mi id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2.3" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2.3.cmml">n</mi></mrow><mo id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.1" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.1.cmml">−</mo><mn id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.3" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.3.cmml">1</mn></mrow></msub></mrow></mrow><mo stretchy="false" id="S3.E1.m1.3.3.1.1.1.1.3" xref="S3.E1.m1.3.3.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3"><eq id="S3.E1.m1.3.3.2.cmml" xref="S3.E1.m1.3.3.2"></eq><apply id="S3.E1.m1.3.3.3.cmml" xref="S3.E1.m1.3.3.3"><times id="S3.E1.m1.3.3.3.1.cmml" xref="S3.E1.m1.3.3.3.1"></times><apply id="S3.E1.m1.3.3.3.2.cmml" xref="S3.E1.m1.3.3.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.3.2.1.cmml" xref="S3.E1.m1.3.3.3.2">subscript</csymbol><ci id="S3.E1.m1.3.3.3.2.2.cmml" xref="S3.E1.m1.3.3.3.2.2">ℒ</ci><apply id="S3.E1.m1.3.3.3.2.3.cmml" xref="S3.E1.m1.3.3.3.2.3"><times id="S3.E1.m1.3.3.3.2.3.1.cmml" xref="S3.E1.m1.3.3.3.2.3.1"></times><ci id="S3.E1.m1.3.3.3.2.3.2.cmml" xref="S3.E1.m1.3.3.3.2.3.2">𝐴</ci><ci id="S3.E1.m1.3.3.3.2.3.3.cmml" xref="S3.E1.m1.3.3.3.2.3.3">𝐿</ci><ci id="S3.E1.m1.3.3.3.2.3.4.cmml" xref="S3.E1.m1.3.3.3.2.3.4">𝑀</ci></apply></apply><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">𝑥</ci></apply><apply id="S3.E1.m1.3.3.1.cmml" xref="S3.E1.m1.3.3.1"><apply id="S3.E1.m1.3.3.1.2.cmml" xref="S3.E1.m1.3.3.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.2.1.cmml" xref="S3.E1.m1.3.3.1.2">superscript</csymbol><apply id="S3.E1.m1.3.3.1.2.2.cmml" xref="S3.E1.m1.3.3.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.2.2.1.cmml" xref="S3.E1.m1.3.3.1.2">subscript</csymbol><sum id="S3.E1.m1.3.3.1.2.2.2.cmml" xref="S3.E1.m1.3.3.1.2.2.2"></sum><apply id="S3.E1.m1.3.3.1.2.2.3.cmml" xref="S3.E1.m1.3.3.1.2.2.3"><eq id="S3.E1.m1.3.3.1.2.2.3.1.cmml" xref="S3.E1.m1.3.3.1.2.2.3.1"></eq><ci id="S3.E1.m1.3.3.1.2.2.3.2.cmml" xref="S3.E1.m1.3.3.1.2.2.3.2">𝑖</ci><cn type="integer" id="S3.E1.m1.3.3.1.2.2.3.3.cmml" xref="S3.E1.m1.3.3.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.3.3.1.2.3.cmml" xref="S3.E1.m1.3.3.1.2.3">𝑁</ci></apply><apply id="S3.E1.m1.3.3.1.1.cmml" xref="S3.E1.m1.3.3.1.1"><times id="S3.E1.m1.3.3.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.2"></times><ci id="S3.E1.m1.3.3.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.3">𝑝</ci><apply id="S3.E1.m1.3.3.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.3.3.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.3">conditional</csymbol><apply id="S3.E1.m1.3.3.1.1.1.1.1.4.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.1.4.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.1.4.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.4.2">𝑥</ci><apply id="S3.E1.m1.3.3.1.1.1.1.1.4.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.4.3"><plus id="S3.E1.m1.3.3.1.1.1.1.1.4.3.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.4.3.1"></plus><ci id="S3.E1.m1.3.3.1.1.1.1.1.4.3.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.4.3.2">𝑖</ci><ci id="S3.E1.m1.3.3.1.1.1.1.1.4.3.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.4.3.3">𝑛</ci></apply></apply><list id="S3.E1.m1.3.3.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2"><apply id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.1.1.1.3">𝑖</ci></apply><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">…</ci><apply id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.2">𝑥</ci><apply id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3"><minus id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.1"></minus><apply id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2"><plus id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2.1.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2.1"></plus><ci id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2.2.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2.2">𝑖</ci><ci id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.2.3">𝑛</ci></apply><cn type="integer" id="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.3.cmml" xref="S3.E1.m1.3.3.1.1.1.1.1.2.2.2.3.3">1</cn></apply></apply></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">\mathscr{L}_{ALM}(x)=\sum_{i=1}^{N}p(x_{i+n}|x_{i},...,x_{i+n-1})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS5.p2.5">이 프레임워크의 자동 회귀 특성을 감안할 때 디코더 전용 모델은 자연스럽게 이러한 작업을 수행하는 방법을 배우는 데 더 적합하다.</p>
</div>
<div id="S3.SS5.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS5.p3.2"><span class="ltx_text ltx_font_bold" id="S3.SS5.p3.2.1">Masked Language Modeling</span>에서 일부 단어는 시퀀스로 마스킹되고 모델은 주변 컨텍스트를 기반으로 마스킹된 단어를 예측하도록 훈련된다. 때때로 사람들은 이 접근 방식을 자동 인코딩을 제거하는 것으로도 언급한다. 우리가 시퀀스 <math alttext="x" class="ltx_Math" display="inline" id="S3.SS5.p3.1.m1.1"><semantics id="S3.SS5.p3.1.m1.1a"><mi id="S3.SS5.p3.1.m1.1.1" xref="S3.SS5.p3.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.1.m1.1b"><ci id="S3.SS5.p3.1.m1.1.1.cmml" xref="S3.SS5.p3.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.1.m1.1c">x</annotation></semantics></math>, <math alttext="\tilde{x}" class="ltx_Math" display="inline" id="S3.SS5.p3.2.m2.1"><semantics id="S3.SS5.p3.2.m2.1a"><mover accent="true" id="S3.SS5.p3.2.m2.1.1" xref="S3.SS5.p3.2.m2.1.1.cmml"><mi id="S3.SS5.p3.2.m2.1.1.2" xref="S3.SS5.p3.2.m2.1.1.2.cmml">x</mi><mo id="S3.SS5.p3.2.m2.1.1.1" xref="S3.SS5.p3.2.m2.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.2.m2.1b"><apply id="S3.SS5.p3.2.m2.1.1.cmml" xref="S3.SS5.p3.2.m2.1.1"><ci id="S3.SS5.p3.2.m2.1.1.1.cmml" xref="S3.SS5.p3.2.m2.1.1.1">~</ci><ci id="S3.SS5.p3.2.m2.1.1.2.cmml" xref="S3.SS5.p3.2.m2.1.1.2">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.2.m2.1c">\tilde{x}</annotation></semantics></math>로 마스킹/파손된 샘플들을 표시하면, 이 접근법의 트레이닝 목적은 다음과 같이 기입될 수 있다:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.2" class="ltx_Math" alttext="\mathscr{L}_{MLM}(x)=\sum_{i=1}^{N}p(\tilde{x}|x\backslash\tilde{x})" display="block"><semantics id="S3.E2.m1.2a"><mrow id="S3.E2.m1.2.2" xref="S3.E2.m1.2.2.cmml"><mrow id="S3.E2.m1.2.2.3" xref="S3.E2.m1.2.2.3.cmml"><msub id="S3.E2.m1.2.2.3.2" xref="S3.E2.m1.2.2.3.2.cmml"><mi class="ltx_font_mathscript" id="S3.E2.m1.2.2.3.2.2" xref="S3.E2.m1.2.2.3.2.2.cmml">ℒ</mi><mrow id="S3.E2.m1.2.2.3.2.3" xref="S3.E2.m1.2.2.3.2.3.cmml"><mi id="S3.E2.m1.2.2.3.2.3.2" xref="S3.E2.m1.2.2.3.2.3.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.3.2.3.1" xref="S3.E2.m1.2.2.3.2.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.3.2.3.3" xref="S3.E2.m1.2.2.3.2.3.3.cmml">L</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.3.2.3.1a" xref="S3.E2.m1.2.2.3.2.3.1.cmml">​</mo><mi id="S3.E2.m1.2.2.3.2.3.4" xref="S3.E2.m1.2.2.3.2.3.4.cmml">M</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.3.1" xref="S3.E2.m1.2.2.3.1.cmml">​</mo><mrow id="S3.E2.m1.2.2.3.3.2" xref="S3.E2.m1.2.2.3.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.3.3.2.1" xref="S3.E2.m1.2.2.3.cmml">(</mo><mi id="S3.E2.m1.1.1" xref="S3.E2.m1.1.1.cmml">x</mi><mo stretchy="false" id="S3.E2.m1.2.2.3.3.2.2" xref="S3.E2.m1.2.2.3.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S3.E2.m1.2.2.2" xref="S3.E2.m1.2.2.2.cmml">=</mo><mrow id="S3.E2.m1.2.2.1" xref="S3.E2.m1.2.2.1.cmml"><munderover id="S3.E2.m1.2.2.1.2" xref="S3.E2.m1.2.2.1.2.cmml"><mo movablelimits="false" id="S3.E2.m1.2.2.1.2.2.2" xref="S3.E2.m1.2.2.1.2.2.2.cmml">∑</mo><mrow id="S3.E2.m1.2.2.1.2.2.3" xref="S3.E2.m1.2.2.1.2.2.3.cmml"><mi id="S3.E2.m1.2.2.1.2.2.3.2" xref="S3.E2.m1.2.2.1.2.2.3.2.cmml">i</mi><mo id="S3.E2.m1.2.2.1.2.2.3.1" xref="S3.E2.m1.2.2.1.2.2.3.1.cmml">=</mo><mn id="S3.E2.m1.2.2.1.2.2.3.3" xref="S3.E2.m1.2.2.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E2.m1.2.2.1.2.3" xref="S3.E2.m1.2.2.1.2.3.cmml">N</mi></munderover><mrow id="S3.E2.m1.2.2.1.1" xref="S3.E2.m1.2.2.1.1.cmml"><mi id="S3.E2.m1.2.2.1.1.3" xref="S3.E2.m1.2.2.1.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.1.1.2" xref="S3.E2.m1.2.2.1.1.2.cmml">​</mo><mrow id="S3.E2.m1.2.2.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.cmml"><mover accent="true" id="S3.E2.m1.2.2.1.1.1.1.1.2" xref="S3.E2.m1.2.2.1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.2.2" xref="S3.E2.m1.2.2.1.1.1.1.1.2.2.cmml">x</mi><mo id="S3.E2.m1.2.2.1.1.1.1.1.2.1" xref="S3.E2.m1.2.2.1.1.1.1.1.2.1.cmml">~</mo></mover><mo fence="false" id="S3.E2.m1.2.2.1.1.1.1.1.1" xref="S3.E2.m1.2.2.1.1.1.1.1.1.cmml">|</mo><mrow id="S3.E2.m1.2.2.1.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.3.2" xref="S3.E2.m1.2.2.1.1.1.1.1.3.2.cmml">x</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.2.2.1.1.1.1.1.3.1" xref="S3.E2.m1.2.2.1.1.1.1.1.3.1.cmml">\</mo><mover accent="true" id="S3.E2.m1.2.2.1.1.1.1.1.3.3" xref="S3.E2.m1.2.2.1.1.1.1.1.3.3.cmml"><mi id="S3.E2.m1.2.2.1.1.1.1.1.3.3.2" xref="S3.E2.m1.2.2.1.1.1.1.1.3.3.2.cmml">x</mi><mo id="S3.E2.m1.2.2.1.1.1.1.1.3.3.1" xref="S3.E2.m1.2.2.1.1.1.1.1.3.3.1.cmml">~</mo></mover></mrow></mrow><mo stretchy="false" id="S3.E2.m1.2.2.1.1.1.1.3" xref="S3.E2.m1.2.2.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.2b"><apply id="S3.E2.m1.2.2.cmml" xref="S3.E2.m1.2.2"><eq id="S3.E2.m1.2.2.2.cmml" xref="S3.E2.m1.2.2.2"></eq><apply id="S3.E2.m1.2.2.3.cmml" xref="S3.E2.m1.2.2.3"><times id="S3.E2.m1.2.2.3.1.cmml" xref="S3.E2.m1.2.2.3.1"></times><apply id="S3.E2.m1.2.2.3.2.cmml" xref="S3.E2.m1.2.2.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.3.2.1.cmml" xref="S3.E2.m1.2.2.3.2">subscript</csymbol><ci id="S3.E2.m1.2.2.3.2.2.cmml" xref="S3.E2.m1.2.2.3.2.2">ℒ</ci><apply id="S3.E2.m1.2.2.3.2.3.cmml" xref="S3.E2.m1.2.2.3.2.3"><times id="S3.E2.m1.2.2.3.2.3.1.cmml" xref="S3.E2.m1.2.2.3.2.3.1"></times><ci id="S3.E2.m1.2.2.3.2.3.2.cmml" xref="S3.E2.m1.2.2.3.2.3.2">𝑀</ci><ci id="S3.E2.m1.2.2.3.2.3.3.cmml" xref="S3.E2.m1.2.2.3.2.3.3">𝐿</ci><ci id="S3.E2.m1.2.2.3.2.3.4.cmml" xref="S3.E2.m1.2.2.3.2.3.4">𝑀</ci></apply></apply><ci id="S3.E2.m1.1.1.cmml" xref="S3.E2.m1.1.1">𝑥</ci></apply><apply id="S3.E2.m1.2.2.1.cmml" xref="S3.E2.m1.2.2.1"><apply id="S3.E2.m1.2.2.1.2.cmml" xref="S3.E2.m1.2.2.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.2.1.cmml" xref="S3.E2.m1.2.2.1.2">superscript</csymbol><apply id="S3.E2.m1.2.2.1.2.2.cmml" xref="S3.E2.m1.2.2.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.2.2.1.2.2.1.cmml" xref="S3.E2.m1.2.2.1.2">subscript</csymbol><sum id="S3.E2.m1.2.2.1.2.2.2.cmml" xref="S3.E2.m1.2.2.1.2.2.2"></sum><apply id="S3.E2.m1.2.2.1.2.2.3.cmml" xref="S3.E2.m1.2.2.1.2.2.3"><eq id="S3.E2.m1.2.2.1.2.2.3.1.cmml" xref="S3.E2.m1.2.2.1.2.2.3.1"></eq><ci id="S3.E2.m1.2.2.1.2.2.3.2.cmml" xref="S3.E2.m1.2.2.1.2.2.3.2">𝑖</ci><cn type="integer" id="S3.E2.m1.2.2.1.2.2.3.3.cmml" xref="S3.E2.m1.2.2.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E2.m1.2.2.1.2.3.cmml" xref="S3.E2.m1.2.2.1.2.3">𝑁</ci></apply><apply id="S3.E2.m1.2.2.1.1.cmml" xref="S3.E2.m1.2.2.1.1"><times id="S3.E2.m1.2.2.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.2"></times><ci id="S3.E2.m1.2.2.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.3">𝑝</ci><apply id="S3.E2.m1.2.2.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1"><csymbol cd="latexml" id="S3.E2.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.1">conditional</csymbol><apply id="S3.E2.m1.2.2.1.1.1.1.1.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2"><ci id="S3.E2.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.1">~</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.2.2">𝑥</ci></apply><apply id="S3.E2.m1.2.2.1.1.1.1.1.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.3"><ci id="S3.E2.m1.2.2.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.3.1">\</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.3.2">𝑥</ci><apply id="S3.E2.m1.2.2.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.3.3"><ci id="S3.E2.m1.2.2.1.1.1.1.1.3.3.1.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.3.3.1">~</ci><ci id="S3.E2.m1.2.2.1.1.1.1.1.3.3.2.cmml" xref="S3.E2.m1.2.2.1.1.1.1.1.3.3.2">𝑥</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.2c">\mathscr{L}_{MLM}(x)=\sum_{i=1}^{N}p(\tilde{x}|x\backslash\tilde{x})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS5.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS5.p4.1">그리고 최근에는 <span class="ltx_text ltx_font_bold" id="S3.SS5.p4.1.1">Mixture of Experts (MoE)</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib130" title="">130</a>, <a class="ltx_ref" href="#bib.bib131" title="">131</a>]</cite>도 LLM 공간에서 매우 인기를 얻고 있다. MoE는 모델이 훨씬 적은 계산으로 미리 훈련될 수 있도록 하며, 이는 밀도가 높은 모델과 동일한 계산 예산으로 모델 또는 데이터 세트 크기를 극적으로 확장할 수 있음을 의미한다. MoE는 두 가지 주요 요소, 즉 <span class="ltx_text ltx_font_bold" id="S3.SS5.p4.1.2">Sparse MoE layers</span>로 구성되며, FFN( dense feed-forward network) 계층 대신 사용되며, 각 전문가가 신경망인 특정 수의 "전문가"(예: 8)를 갖는다. 실제로 전문가들은 FFN이지만 더 복잡한 네트워크일 수도 있다. <span class="ltx_text ltx_font_bold" id="S3.SS5.p4.1.3">A gate network or router</span>은 어떤 토큰이 어떤 전문가에게 전송되는지를 결정한다. 하나 이상의 전문가에게 토큰을 보낼 수 있다는 점에 주목할 필요가 있습니다. 토큰을 전문가에게 라우팅하는 방법은 MoE와 함께 작업할 때 중요한 결정 중 하나입니다. 라우터는 학습된 매개변수로 구성되며 네트워크의 나머지 부분과 동시에 사전 훈련됩니다. <a class="ltx_ref" href="#S3.F29" title="Figure 29 ‣ III-E Model Pre-training ‣ III How LLMs Are Built ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">29</span></a>는 MoE에서 사용되는 스위치 트랜스포머 인코더 블록의 예시를 제공한다.</p>
</div>
<figure id="S3.F29" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/moe.png" id="S3.F29.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="212" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F29.3.1.1" style="font-size:90%;">Figure 29</span>:</span><span class="ltx_text" id="S3.F29.4.2" style="font-size:90%;">: Illustration of a Switch Transformer encoder block. 그들은 트랜스포머에 존재하는 조밀한 피드 포워드 네트워크(FFN) 층을 희소 스위치 FFN 층(옅은 청색)으로 교체하였다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib131" title="">131</a>]</cite>의 예절. </span></figcaption>
</figure>
</section>
<section id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS6.5.1.1" class="ltx_text">III-F</span> </span><span id="S3.SS6.6.2" class="ltx_text ltx_font_italic">Fine-tuning and Instruction Tuning</span>
</h3>

<div id="S3.SS6.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS6.p1.1"><a class="ltx_ref" href="#S3.SS5" title="III-E Model Pre-training ‣ III How LLMs Are Built ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-E</span></span></a> 섹션에서 설명한 대로 자체 감독을 사용하여 훈련된 BERT와 같은 초기 언어 모델은 특정 작업을 수행할 수 없었다. 기초 모델이 유용하기 위해서는 라벨링된 데이터(소위 감독 미세 조정 또는 줄여서 SFT)를 사용하여 특정 작업에 미세 조정해야 한다. 예를 들어, 원래의 BERT 논문 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>]</cite>에서 모델은 11개의 다른 태스크로 미세 조정되었다. 최근 LLM은 더 이상 미세 조정을 사용할 필요가 없지만 작업 또는 데이터별 미세 조정에서 이점을 얻을 수 있습니다. 예를 들어 OpenAI는 훨씬 작은 GPT-3.5 터보 모델이 태스크 특정 데이터 <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://platform.openai.com/docs/guides/fine-tuning</span></span></span>으로 미세 조정될 때 GPT-4를 능가할 수 있다고 보고합니다.</p>
</div>
<div id="S3.SS6.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS6.p2.1">파인-튜닝은 단일 태스크에 대해 수행될 필요는 없고, 멀티-태스크 파인-튜닝에 대한 상이한 접근법들이 존재한다(예를 들어, Mahabi 등 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib132" title="">132</a>]</cite> 참조). 하나 이상의 태스크에 대한 미세 조정은 결과를 개선하고 신속한 엔지니어링의 복잡성을 감소시키는 것으로 알려져 있으며, 검색 증강 생성의 대안으로 작용할 수 있다. 또한, 미세 조정이 권장되는 다른 이유가 있습니다. 예를 들어 모델을 사전 훈련 중에 노출되지 않은 새 데이터 또는 독점 데이터에 노출하도록 미세 조정하려고 할 수 있습니다.</p>
</div>
<div id="S3.SS6.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS6.p3.1">LLM을 미세 조정하는 중요한 이유는 프롬프트를 통해 지침을 제공할 때 인간이 가질 기대에 대한 응답을 정렬하기 위한 것이다. 이것은 소위 <span class="ltx_text ltx_font_bold" id="S3.SS6.p3.1.1">instruction tuning</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>]</cite>이다. 섹션 <a class="ltx_ref" href="#S4.SS2" title="IV-B Using LLMs: Prompt Design and Engineering ‣ IV How LLMs Are Used and Augmented ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-B</span></span></a>에서 프롬프트를 설계하고 엔지니어링하는 방법에 대한 세부 사항을 살펴보지만, 명령어 튜닝의 맥락에서 명령어는 LLM이 수행해야 하는 작업을 지정하는 프롬프트임을 이해하는 것이 중요하다. 자연 명령어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib134" title="">134</a>]</cite>와 같은 명령어 튜닝 데이터 세트는 태스크 정의뿐만 아니라 포지티브/네거티브 예 또는 회피할 사물들과 같은 다른 컴포넌트들을 포함한다.</p>
</div>
<div id="S3.SS6.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS6.p4.1">LLM을 명령 조정하기 위해 사용되는 특정 접근법 및 명령 데이터 세트는 다양하지만 일반적으로 명령 조정 모델은 기본 기반 모델을 능가한다. 예를 들어, InstructGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib59" title="">59</a>]</cite>는 대부분의 벤치마크에서 GPT-3보다 성능이 우수하다. 이는 LLaMA와 비교할 때 Alpaca<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib62" title="">62</a>]</cite>에 대해서도 마찬가지이다.</p>
</div>
<div id="S3.SS6.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS6.p5.1">Wang 등이 제안한 <span class="ltx_text ltx_font_bold" id="S3.SS6.p5.1.1">Self-Instruct</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib135" title="">135</a>]</cite>도 이 라인을 따라 인기 있는 접근법으로, 이들은 자신의 세대를 부트스트래핑함으로써 사전 훈련된 언어 모델의 명령어 추종 능력을 향상시키기 위한 프레임워크를 도입하였다. 파이프라인은 언어 모델에서 명령, 입력 및 출력 샘플을 생성한 다음 잘못된 샘플 또는 유사한 샘플을 필터링한 후 원래 모델을 미세 조정하기 위해 사용합니다.</p>
</div>
</section>
<section id="S3.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS7.5.1.1" class="ltx_text">III-G</span> </span><span id="S3.SS7.6.2" class="ltx_text ltx_font_italic">Alignment</span>
</h3>

<div id="S3.SS7.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.p1.1">AI 정렬은 AI 시스템을 인간의 목표, 선호도 및 원칙으로 조종하는 프로세스입니다. 단어 예측을 위해 미리 훈련된 LLM은 종종 의도하지 않은 행동을 나타낸다. 예를 들어, 독성, 유해성, 오판의 소지가 있고 편향된 콘텐츠를 생성할 수 있다.</p>
</div>
<div id="S3.SS7.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS7.p2.1">위에서 논의한 명령어 튜닝은 LLMs가 정렬에 한 걸음 더 가까워지게 한다. 그러나 많은 경우 모델의 정렬을 개선하고 의도하지 않은 동작 <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>According to very recent research by Ethayarajh et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib136" title="">136</a>]</cite>, further alignment besides SFT mainly improves models of at least 7B parameters. For smaller models, SFT is sufficient.</span></span></span>을 피하기 위한 추가 단계를 포함하는 것이 중요하다. 우리는 이 하위 섹션에서 정렬에 대한 가장 인기 있는 접근법을 검토한다.</p>
</div>
<div id="S3.SS7.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS7.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS7.p3.1.1">RLHF</span> (인간 피드백으로부터의 강화 학습) 및 <span class="ltx_text ltx_font_bold" id="S3.SS7.p3.1.2">RLAIF</span> (AI 피드백으로부터의 강화 학습)은 두 가지 인기 있는 접근법이다. RLHF는 보상 모델을 사용하여 인간의 피드백으로부터 정렬을 학습한다. 이 보상 모델은 튜닝된 후 다양한 출력을 평가하고 인간이 제공하는 정렬 선호도에 따라 점수를 매길 수 있다. 보상 모델은 원래 LLM에 피드백을 제공하고 이 피드백은 LLM을 추가로 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib137" title="">137</a>]</cite>로 조정하는 데 사용된다. 반면에 AI 피드백으로부터의 강화 학습은 사전 훈련되고 잘 정렬된 모델을 LLM에 직접 연결하고 더 크고 더 정렬된 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite>로부터 학습하도록 돕는다.</p>
</div>
<div id="S3.SS7.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS7.p4.1">또 다른 최근 작업(<span class="ltx_text ltx_font_bold" id="S3.SS7.p4.1.1">DPO</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib139" title="">139</a>]</cite>, Rafailov 등은 RLHF가 복잡하고 종종 불안정한 절차임을 논의하고 새로운 접근법으로 이를 해결하려고 시도했다. 그들은 보상 함수와 최적 정책 간의 매핑을 활용하여 이러한 제한된 보상 최대화 문제가 단일 단계의 정책 훈련으로 정확하게 최적화될 수 있음을 보여주며 본질적으로 인간 선호 데이터에 대한 분류 문제를 해결한다. 직접 선호 최적화(DPO)라고 하는 결과 알고리즘은 안정적이고 성능이 뛰어나며 계산적으로 가벼워 보상 모델을 피팅하거나 미세 조정 중에 LM에서 샘플링하거나 상당한 하이퍼파라미터 튜닝을 수행할 필요가 없다. 그들은 DPO와의 미세 조정이 세대의 감성을 제어하고 요약에서 응답 품질을 향상시키는 RLHF의 능력을 초과한다는 것을 관찰했다. 그림 <a class="ltx_ref" href="#S3.F30" title="Figure 30 ‣ III-G Alignment ‣ III How LLMs Are Built ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">30</span></a>는 DPO 대 RLHF 간의 상위 수준 비교를 보여준다.</p>
</div>
<figure id="S3.F30" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/DPO.png" id="S3.F30.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="408" height="86" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F30.3.1.1" style="font-size:90%;">Figure 30</span>:</span><span class="ltx_text" id="S3.F30.4.2" style="font-size:90%;">DPO optimizes for human preferences while avoiding reinforcement learning. 인간 피드백으로 언어 모델을 미세 조정하는 기존의 방법은 먼저 응답 쌍에 대한 프롬프트 및 인간 선호의 데이터 세트에 보상 모델을 피팅한 다음 RL을 사용하여 학습된 보상을 최대화하는 정책을 찾는다. 대조적으로, DPO는 명시적 보상 함수 또는 RL 없이 간단한 분류 목적으로 선호도를 가장 잘 충족하는 정책에 직접 최적화한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib139" title="">139</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S3.SS7.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS7.p5.6">더욱 최근에 Ethayarajh 등은 Kahneman-Tversky Optimization (KTO) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib136" title="">136</a>]</cite>라는 새로운 정렬 접근법을 제안하였다. 기존의 최첨단 접근법들과 달리, KTO는 페어링된 선호도 데이터(<math alttext="x" class="ltx_Math" display="inline" id="S3.SS7.p5.1.m1.1"><semantics id="S3.SS7.p5.1.m1.1a"><mi id="S3.SS7.p5.1.m1.1.1" xref="S3.SS7.p5.1.m1.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S3.SS7.p5.1.m1.1b"><ci id="S3.SS7.p5.1.m1.1.1.cmml" xref="S3.SS7.p5.1.m1.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS7.p5.1.m1.1c">x</annotation></semantics></math>, <math alttext="y_{w}" class="ltx_Math" display="inline" id="S3.SS7.p5.2.m2.1"><semantics id="S3.SS7.p5.2.m2.1a"><msub id="S3.SS7.p5.2.m2.1.1" xref="S3.SS7.p5.2.m2.1.1.cmml"><mi id="S3.SS7.p5.2.m2.1.1.2" xref="S3.SS7.p5.2.m2.1.1.2.cmml">y</mi><mi id="S3.SS7.p5.2.m2.1.1.3" xref="S3.SS7.p5.2.m2.1.1.3.cmml">w</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS7.p5.2.m2.1b"><apply id="S3.SS7.p5.2.m2.1.1.cmml" xref="S3.SS7.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS7.p5.2.m2.1.1.1.cmml" xref="S3.SS7.p5.2.m2.1.1">subscript</csymbol><ci id="S3.SS7.p5.2.m2.1.1.2.cmml" xref="S3.SS7.p5.2.m2.1.1.2">𝑦</ci><ci id="S3.SS7.p5.2.m2.1.1.3.cmml" xref="S3.SS7.p5.2.m2.1.1.3">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS7.p5.2.m2.1c">y_{w}</annotation></semantics></math>, <math alttext="y_{l}" class="ltx_Math" display="inline" id="S3.SS7.p5.3.m3.1"><semantics id="S3.SS7.p5.3.m3.1a"><msub id="S3.SS7.p5.3.m3.1.1" xref="S3.SS7.p5.3.m3.1.1.cmml"><mi id="S3.SS7.p5.3.m3.1.1.2" xref="S3.SS7.p5.3.m3.1.1.2.cmml">y</mi><mi id="S3.SS7.p5.3.m3.1.1.3" xref="S3.SS7.p5.3.m3.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS7.p5.3.m3.1b"><apply id="S3.SS7.p5.3.m3.1.1.cmml" xref="S3.SS7.p5.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS7.p5.3.m3.1.1.1.cmml" xref="S3.SS7.p5.3.m3.1.1">subscript</csymbol><ci id="S3.SS7.p5.3.m3.1.1.2.cmml" xref="S3.SS7.p5.3.m3.1.1.2">𝑦</ci><ci id="S3.SS7.p5.3.m3.1.1.3.cmml" xref="S3.SS7.p5.3.m3.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS7.p5.3.m3.1c">y_{l}</annotation></semantics></math>)를 필요로 하지 않으며, 단지 <math alttext="y" class="ltx_Math" display="inline" id="S3.SS7.p5.4.m4.1"><semantics id="S3.SS7.p5.4.m4.1a"><mi id="S3.SS7.p5.4.m4.1.1" xref="S3.SS7.p5.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S3.SS7.p5.4.m4.1b"><ci id="S3.SS7.p5.4.m4.1.1.cmml" xref="S3.SS7.p5.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS7.p5.4.m4.1c">y</annotation></semantics></math>가 바람직한지 또는 바람직하지 않은지에 대한 (x,y) 및 지식만을 필요로 한다. KTO 정렬 모델은 쌍을 이루는 선호도를 사용하지 않았음에도 불구하고 1B에서 30B까지의 척도에서 DPO 정렬 모델보다 좋거나 더 나은 것으로 나타났다. KTO는 또한 필요한 데이터의 종류가 훨씬 풍부하기 때문에 선호 최적화 방법보다 실제 세계에서 사용하기 훨씬 쉽다. 예로서, 모든 소매 회사에는 많은 고객 상호 작용 데이터가 있고, 그 상호 작용이 성공적이었는지(예를 들어, 구매가 이루어졌는가) 또는 성공적이지 않았는지(예를 들어, 구매가 이루어지지 않았는가)가 있다. 그러나, 그들은 반사실적인 데이터가 거의 또는 전혀 없다(즉, 실패한 고객 상호 작용 <math alttext="y_{l}" class="ltx_Math" display="inline" id="S3.SS7.p5.5.m5.1"><semantics id="S3.SS7.p5.5.m5.1a"><msub id="S3.SS7.p5.5.m5.1.1" xref="S3.SS7.p5.5.m5.1.1.cmml"><mi id="S3.SS7.p5.5.m5.1.1.2" xref="S3.SS7.p5.5.m5.1.1.2.cmml">y</mi><mi id="S3.SS7.p5.5.m5.1.1.3" xref="S3.SS7.p5.5.m5.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS7.p5.5.m5.1b"><apply id="S3.SS7.p5.5.m5.1.1.cmml" xref="S3.SS7.p5.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS7.p5.5.m5.1.1.1.cmml" xref="S3.SS7.p5.5.m5.1.1">subscript</csymbol><ci id="S3.SS7.p5.5.m5.1.1.2.cmml" xref="S3.SS7.p5.5.m5.1.1.2">𝑦</ci><ci id="S3.SS7.p5.5.m5.1.1.3.cmml" xref="S3.SS7.p5.5.m5.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS7.p5.5.m5.1c">y_{l}</annotation></semantics></math>를 성공적인 것 <math alttext="y_{w}" class="ltx_Math" display="inline" id="S3.SS7.p5.6.m6.1"><semantics id="S3.SS7.p5.6.m6.1a"><msub id="S3.SS7.p5.6.m6.1.1" xref="S3.SS7.p5.6.m6.1.1.cmml"><mi id="S3.SS7.p5.6.m6.1.1.2" xref="S3.SS7.p5.6.m6.1.1.2.cmml">y</mi><mi id="S3.SS7.p5.6.m6.1.1.3" xref="S3.SS7.p5.6.m6.1.1.3.cmml">w</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS7.p5.6.m6.1b"><apply id="S3.SS7.p5.6.m6.1.1.cmml" xref="S3.SS7.p5.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS7.p5.6.m6.1.1.1.cmml" xref="S3.SS7.p5.6.m6.1.1">subscript</csymbol><ci id="S3.SS7.p5.6.m6.1.1.2.cmml" xref="S3.SS7.p5.6.m6.1.1.2">𝑦</ci><ci id="S3.SS7.p5.6.m6.1.1.3.cmml" xref="S3.SS7.p5.6.m6.1.1.3">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS7.p5.6.m6.1c">y_{w}</annotation></semantics></math>로 만들었을 것). 그림 <a class="ltx_ref" href="#S3.F31" title="Figure 31 ‣ III-G Alignment ‣ III How LLMs Are Built ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">31</span></a>는 위에서 논의한 KTO와 다른 정렬 접근법 간의 높은 수준의 비교를 보여준다.</p>
</div>
<figure id="S3.F31" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/KTO.png" id="S3.F31.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="406" height="165" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F31.3.1.1" style="font-size:90%;">그림 31</span>:</span><span class="ltx_text" id="S3.F31.4.2" style="font-size:90%;">LLM alignment involves supervised finetuning followed a human-centered loss (HALO) 최적화. 그러나 기존 접근법이 필요로 하는 페어링된 선호도는 얻기 어렵다. 대조적으로, KTO는 훨씬 더 풍부한 종류의 데이터를 사용하여 실제 세계에서 훨씬 더 쉽게 사용할 수 있다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib136" title="">136</a>]</cite>의 예절. </span></figcaption>
</figure>
</section>
<section id="S3.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS8.5.1.1" class="ltx_text">III-H</span> </span><span id="S3.SS8.6.2" class="ltx_text ltx_font_italic">Decoding Strategies</span>
</h3>

<div id="S3.SS8.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.p1.1">디코딩은 미리 훈련된 LLM을 이용하여 텍스트를 생성하는 과정을 의미한다. 입력 프롬프트가 주어지면, 토큰화기는 입력 텍스트의 각각의 토큰을 대응하는 토큰 ID로 변환한다. 그런 다음 언어 모델은 이러한 토큰 ID를 입력으로 사용하고 다음으로 가능성이 높은 토큰(또는 토큰의 시퀀스)을 예측합니다. 마지막으로, 소프트맥스 함수를 이용하여 확률로 변환한 로짓(logits)을 생성한다. 상이한 디코딩 전략들이 제안되었다. 가장 인기 있는 것 중 일부는 탐욕 탐색, 빔 탐색뿐만 아니라 top-K, top-P(핵 샘플링)와 같은 다양한 샘플 기술이다.</p>
</div>
<section id="S3.SS8.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS8.SSS1.5.1.1" class="ltx_text">III-H</span>1 </span><span id="S3.SS8.SSS1.6.2" class="ltx_text ltx_font_bold">Greedy Search</span>
</h4>

<div id="S3.SS8.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.p1.1">탐욕 검색은 각 단계에서 가장 가능성이 높은 토큰을 시퀀스의 다음 토큰으로 사용하여 다른 모든 잠재적 옵션을 폐기한다. 상상할 수 있듯이, 이것은 간단한 접근 방식이며 많은 시간적 일관성과 일관성을 잃을 수 있습니다. 순서에 대한 전반적인 영향을 고려하지 않고 각 단계에서 가장 가능성 있는 토큰만 고려한다. 이 속성은 속도를 빠르게 만들지만 다음 토큰의 가능성이 약간 낮은 상태에서 나타났을 수 있는 더 나은 시퀀스를 놓칠 수 있음을 의미하기도 합니다.</p>
</div>
</section>
<section id="S3.SS8.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS8.SSS2.5.1.1" class="ltx_text">III-H</span>2 </span><span id="S3.SS8.SSS2.6.2" class="ltx_text ltx_font_bold">Beam Search</span>
</h4>

<div id="S3.SS8.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS2.p1.1">다음 가장 가능성 있는 토큰만 고려하는 그리디 검색과 달리 빔 검색은 <span class="ltx_text ltx_font_bold" id="S3.SS8.SSS2.p1.1.1">N</span> 가장 가능성 있는 토큰을 고려하며, 여기서 <span class="ltx_text ltx_font_bold" id="S3.SS8.SSS2.p1.1.2">N</span>은 빔의 수를 나타냅니다. 이 절차는 미리 정의된 최대 시퀀스 길이에 도달하거나 시퀀스 종료 토큰이 나타날 때까지 반복된다. 이 시점에서, 가장 높은 전체 스코어를 갖는 토큰들의 시퀀스(AKA "빔")가 출력으로서 선택된다. 예를 들어, 2의 빔 크기 및 5의 최대 길이에 대해, 빔 탐색은 <math alttext="2^{5}=32" class="ltx_Math" display="inline" id="S3.SS8.SSS2.p1.1.m1.1"><semantics id="S3.SS8.SSS2.p1.1.m1.1a"><mrow id="S3.SS8.SSS2.p1.1.m1.1.1" xref="S3.SS8.SSS2.p1.1.m1.1.1.cmml"><msup id="S3.SS8.SSS2.p1.1.m1.1.1.2" xref="S3.SS8.SSS2.p1.1.m1.1.1.2.cmml"><mn id="S3.SS8.SSS2.p1.1.m1.1.1.2.2" xref="S3.SS8.SSS2.p1.1.m1.1.1.2.2.cmml">2</mn><mn id="S3.SS8.SSS2.p1.1.m1.1.1.2.3" xref="S3.SS8.SSS2.p1.1.m1.1.1.2.3.cmml">5</mn></msup><mo id="S3.SS8.SSS2.p1.1.m1.1.1.1" xref="S3.SS8.SSS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS8.SSS2.p1.1.m1.1.1.3" xref="S3.SS8.SSS2.p1.1.m1.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS8.SSS2.p1.1.m1.1b"><apply id="S3.SS8.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS8.SSS2.p1.1.m1.1.1"><eq id="S3.SS8.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS8.SSS2.p1.1.m1.1.1.1"></eq><apply id="S3.SS8.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS8.SSS2.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS8.SSS2.p1.1.m1.1.1.2.1.cmml" xref="S3.SS8.SSS2.p1.1.m1.1.1.2">superscript</csymbol><cn id="S3.SS8.SSS2.p1.1.m1.1.1.2.2.cmml" type="integer" xref="S3.SS8.SSS2.p1.1.m1.1.1.2.2">2</cn><cn id="S3.SS8.SSS2.p1.1.m1.1.1.2.3.cmml" type="integer" xref="S3.SS8.SSS2.p1.1.m1.1.1.2.3">5</cn></apply><cn id="S3.SS8.SSS2.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS8.SSS2.p1.1.m1.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS8.SSS2.p1.1.m1.1c">2^{5}=32</annotation></semantics></math> 가능한 시퀀스들의 트랙을 유지할 필요가 있다. 따라서 탐욕스러운 검색보다 계산 집약적이다.</p>
</div>
</section>
<section id="S3.SS8.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS8.SSS3.5.1.1" class="ltx_text">III-H</span>3 </span><span id="S3.SS8.SSS3.6.2" class="ltx_text ltx_font_bold">Top-k Sampling</span>
</h4>

<div id="S3.SS8.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS3.p1.1">Top-k 샘플링은 언어 모델에 의해 생성된 확률 분포를 이용하여 k개의 가장 가능성 있는 옵션 중에서 랜덤하게 토큰을 선택하는 기법이다.</p>
</div>
<div id="S3.SS8.SSS3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS3.p2.1">우리는 6개의 토큰(A, B, C, D, E, F)과 k=2, P(A)=30%, P(B)=20%, P(C)=P(D)=P(E)=P(F)=12.5%)을 가지고 있다고 가정하자. Top-k 샘플링에서 토큰 C, D, E, F는 무시되고 모델은 시간의 60%인 A와 시간의 40%인 B를 출력한다. 이 접근법은 선택 프로세스에서 무작위성의 요소를 도입하면서 가장 가능성 있는 토큰의 우선 순위를 보장한다.</p>
</div>
<div id="S3.SS8.SSS3.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS3.p3.1">무작위성은 보통 온도의 개념을 통해 도입된다. 온도 T는 0에서 1까지의 범위인 파라미터로 소프트맥스 함수에 의해 생성된 확률에 영향을 주어 가장 가능성이 높은 토큰이 더 영향력이 있다. 실제로, 그것은 단순히 입력 로짓들을 온도 값으로 나누는 것으로 구성된다:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.1" class="ltx_Math" alttext="softmax(x_{i})=\frac{e^{x_{i}/T}}{\sum_{j}e^{x_{j}/T}}" display="block"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.3" xref="S3.E3.m1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.2.cmml">​</mo><mi id="S3.E3.m1.1.1.1.4" xref="S3.E3.m1.1.1.1.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.2a" xref="S3.E3.m1.1.1.1.2.cmml">​</mo><mi id="S3.E3.m1.1.1.1.5" xref="S3.E3.m1.1.1.1.5.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.2b" xref="S3.E3.m1.1.1.1.2.cmml">​</mo><mi id="S3.E3.m1.1.1.1.6" xref="S3.E3.m1.1.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.2c" xref="S3.E3.m1.1.1.1.2.cmml">​</mo><mi id="S3.E3.m1.1.1.1.7" xref="S3.E3.m1.1.1.1.7.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.2d" xref="S3.E3.m1.1.1.1.2.cmml">​</mo><mi id="S3.E3.m1.1.1.1.8" xref="S3.E3.m1.1.1.1.8.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.2e" xref="S3.E3.m1.1.1.1.2.cmml">​</mo><mi id="S3.E3.m1.1.1.1.9" xref="S3.E3.m1.1.1.1.9.cmml">x</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.1.1.1.2f" xref="S3.E3.m1.1.1.1.2.cmml">​</mo><mrow id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.1.1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S3.E3.m1.1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S3.E3.m1.1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.1.1.2" xref="S3.E3.m1.1.1.2.cmml">=</mo><mfrac id="S3.E3.m1.1.1.3" xref="S3.E3.m1.1.1.3.cmml"><msup id="S3.E3.m1.1.1.3.2" xref="S3.E3.m1.1.1.3.2.cmml"><mi id="S3.E3.m1.1.1.3.2.2" xref="S3.E3.m1.1.1.3.2.2.cmml">e</mi><mrow id="S3.E3.m1.1.1.3.2.3" xref="S3.E3.m1.1.1.3.2.3.cmml"><msub id="S3.E3.m1.1.1.3.2.3.2" xref="S3.E3.m1.1.1.3.2.3.2.cmml"><mi id="S3.E3.m1.1.1.3.2.3.2.2" xref="S3.E3.m1.1.1.3.2.3.2.2.cmml">x</mi><mi id="S3.E3.m1.1.1.3.2.3.2.3" xref="S3.E3.m1.1.1.3.2.3.2.3.cmml">i</mi></msub><mo id="S3.E3.m1.1.1.3.2.3.1" xref="S3.E3.m1.1.1.3.2.3.1.cmml">/</mo><mi id="S3.E3.m1.1.1.3.2.3.3" xref="S3.E3.m1.1.1.3.2.3.3.cmml">T</mi></mrow></msup><mrow id="S3.E3.m1.1.1.3.3" xref="S3.E3.m1.1.1.3.3.cmml"><msub id="S3.E3.m1.1.1.3.3.1" xref="S3.E3.m1.1.1.3.3.1.cmml"><mo id="S3.E3.m1.1.1.3.3.1.2" xref="S3.E3.m1.1.1.3.3.1.2.cmml">∑</mo><mi id="S3.E3.m1.1.1.3.3.1.3" xref="S3.E3.m1.1.1.3.3.1.3.cmml">j</mi></msub><msup id="S3.E3.m1.1.1.3.3.2" xref="S3.E3.m1.1.1.3.3.2.cmml"><mi id="S3.E3.m1.1.1.3.3.2.2" xref="S3.E3.m1.1.1.3.3.2.2.cmml">e</mi><mrow id="S3.E3.m1.1.1.3.3.2.3" xref="S3.E3.m1.1.1.3.3.2.3.cmml"><msub id="S3.E3.m1.1.1.3.3.2.3.2" xref="S3.E3.m1.1.1.3.3.2.3.2.cmml"><mi id="S3.E3.m1.1.1.3.3.2.3.2.2" xref="S3.E3.m1.1.1.3.3.2.3.2.2.cmml">x</mi><mi id="S3.E3.m1.1.1.3.3.2.3.2.3" xref="S3.E3.m1.1.1.3.3.2.3.2.3.cmml">j</mi></msub><mo id="S3.E3.m1.1.1.3.3.2.3.1" xref="S3.E3.m1.1.1.3.3.2.3.1.cmml">/</mo><mi id="S3.E3.m1.1.1.3.3.2.3.3" xref="S3.E3.m1.1.1.3.3.2.3.3.cmml">T</mi></mrow></msup></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1"><eq id="S3.E3.m1.1.1.2.cmml" xref="S3.E3.m1.1.1.2"></eq><apply id="S3.E3.m1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><times id="S3.E3.m1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.2"></times><ci id="S3.E3.m1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.3">𝑠</ci><ci id="S3.E3.m1.1.1.1.4.cmml" xref="S3.E3.m1.1.1.1.4">𝑜</ci><ci id="S3.E3.m1.1.1.1.5.cmml" xref="S3.E3.m1.1.1.1.5">𝑓</ci><ci id="S3.E3.m1.1.1.1.6.cmml" xref="S3.E3.m1.1.1.1.6">𝑡</ci><ci id="S3.E3.m1.1.1.1.7.cmml" xref="S3.E3.m1.1.1.1.7">𝑚</ci><ci id="S3.E3.m1.1.1.1.8.cmml" xref="S3.E3.m1.1.1.1.8">𝑎</ci><ci id="S3.E3.m1.1.1.1.9.cmml" xref="S3.E3.m1.1.1.1.9">𝑥</ci><apply id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.1.1.2">𝑥</ci><ci id="S3.E3.m1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S3.E3.m1.1.1.3.cmml" xref="S3.E3.m1.1.1.3"><divide id="S3.E3.m1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.3"></divide><apply id="S3.E3.m1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.2.1.cmml" xref="S3.E3.m1.1.1.3.2">superscript</csymbol><ci id="S3.E3.m1.1.1.3.2.2.cmml" xref="S3.E3.m1.1.1.3.2.2">𝑒</ci><apply id="S3.E3.m1.1.1.3.2.3.cmml" xref="S3.E3.m1.1.1.3.2.3"><divide id="S3.E3.m1.1.1.3.2.3.1.cmml" xref="S3.E3.m1.1.1.3.2.3.1"></divide><apply id="S3.E3.m1.1.1.3.2.3.2.cmml" xref="S3.E3.m1.1.1.3.2.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.2.3.2.1.cmml" xref="S3.E3.m1.1.1.3.2.3.2">subscript</csymbol><ci id="S3.E3.m1.1.1.3.2.3.2.2.cmml" xref="S3.E3.m1.1.1.3.2.3.2.2">𝑥</ci><ci id="S3.E3.m1.1.1.3.2.3.2.3.cmml" xref="S3.E3.m1.1.1.3.2.3.2.3">𝑖</ci></apply><ci id="S3.E3.m1.1.1.3.2.3.3.cmml" xref="S3.E3.m1.1.1.3.2.3.3">𝑇</ci></apply></apply><apply id="S3.E3.m1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.3.3"><apply id="S3.E3.m1.1.1.3.3.1.cmml" xref="S3.E3.m1.1.1.3.3.1"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.3.1.1.cmml" xref="S3.E3.m1.1.1.3.3.1">subscript</csymbol><sum id="S3.E3.m1.1.1.3.3.1.2.cmml" xref="S3.E3.m1.1.1.3.3.1.2"></sum><ci id="S3.E3.m1.1.1.3.3.1.3.cmml" xref="S3.E3.m1.1.1.3.3.1.3">𝑗</ci></apply><apply id="S3.E3.m1.1.1.3.3.2.cmml" xref="S3.E3.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.3.2.1.cmml" xref="S3.E3.m1.1.1.3.3.2">superscript</csymbol><ci id="S3.E3.m1.1.1.3.3.2.2.cmml" xref="S3.E3.m1.1.1.3.3.2.2">𝑒</ci><apply id="S3.E3.m1.1.1.3.3.2.3.cmml" xref="S3.E3.m1.1.1.3.3.2.3"><divide id="S3.E3.m1.1.1.3.3.2.3.1.cmml" xref="S3.E3.m1.1.1.3.3.2.3.1"></divide><apply id="S3.E3.m1.1.1.3.3.2.3.2.cmml" xref="S3.E3.m1.1.1.3.3.2.3.2"><csymbol cd="ambiguous" id="S3.E3.m1.1.1.3.3.2.3.2.1.cmml" xref="S3.E3.m1.1.1.3.3.2.3.2">subscript</csymbol><ci id="S3.E3.m1.1.1.3.3.2.3.2.2.cmml" xref="S3.E3.m1.1.1.3.3.2.3.2.2">𝑥</ci><ci id="S3.E3.m1.1.1.3.3.2.3.2.3.cmml" xref="S3.E3.m1.1.1.3.3.2.3.2.3">𝑗</ci></apply><ci id="S3.E3.m1.1.1.3.3.2.3.3.cmml" xref="S3.E3.m1.1.1.3.3.2.3.3">𝑇</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">softmax(x_{i})=\frac{e^{x_{i}/T}}{\sum_{j}e^{x_{j}/T}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS8.SSS3.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS3.p4.1">낮은 온도 설정은 확률 분포를 크게 변경(그리고 생성된 출력에서 "창의성" 수준을 제어하기 위해 텍스트 생성에서 일반적으로 사용됨)하는 반면, 큰 온도는 더 높은 확률을 갖는 토큰을 우선시한다. Top-k는 창의적인 샘플링 방법으로 빔 탐색과 함께 사용할 수 있다. Top-k 샘플링에 의해 선택된 시퀀스는 빔 탐색에서 가장 높은 확률을 갖는 시퀀스가 아닐 수 있다. 그러나 가장 높은 점수가 항상 더 사실적이거나 의미 있는 시퀀스로 이어지는 것은 아니라는 것을 기억하는 것이 중요합니다.</p>
</div>
</section>
<section id="S3.SS8.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS8.SSS4.5.1.1" class="ltx_text">III-H</span>4 </span><span id="S3.SS8.SSS4.6.2" class="ltx_text ltx_font_bold">Top-p Sampling</span>
</h4>

<div id="S3.SS8.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS4.p1.1">핵 샘플링이라고도 하는 Top-p 샘플링은 Top-k 샘플링과 약간 다른 접근법을 취한다. 핵 샘플링은 상위 k개의 가장 가능성 있는 토큰을 선택하는 대신 선택된 토큰의 확률의 합이 p를 초과하도록 컷오프 값 p를 선택한다. 이는 다음 토큰을 무작위로 선택할 토큰의 "핵"을 형성한다. 즉, top-p 샘플링에서 언어 모델은 확률의 합이 임계값 p를 초과할 때까지 내림차순으로 가장 가능성이 높은 토큰을 검사하고 목록에 계속 추가한다. 상상할 수 있듯이, 이는 top-k 토큰이 큰 확률 질량을 갖지 않는 시나리오에 더 적합할 수 있다. Top-k 샘플링과 달리 핵 샘플링에 포함된 토큰의 수는 고정되어 있지 않다. 이러한 가변성은 종종 더 다양하고 창의적인 출력을 초래하여 텍스트 생성 관련 작업에 핵 샘플링을 인기 있게 만든다.</p>
</div>
</section>
</section>
<section id="S3.SS9" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS9.5.1.1" class="ltx_text">III-I</span> </span><span id="S3.SS9.6.2" class="ltx_text ltx_font_italic">Cost-Effective Training/Inference/Adaptation/Compression</span>
</h3>

<div id="S3.SS9.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS9.p1.1">이 부분에서는 LLM의 보다 비용 친화적인 (및 계산 친화적인) 훈련 및 사용에 사용되는 인기 있는 접근법 중 일부를 검토한다.</p>
</div>
<section id="S3.SS9.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS9.SSS1.5.1.1" class="ltx_text">III-I</span>1 </span><span id="S3.SS9.SSS1.6.2" class="ltx_text ltx_font_bold">Optimized Training</span>
</h4>

<div id="S3.SS9.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS9.SSS1.p1.1">LLM의 최적화된 훈련을 위해 개발된 많은 프레임워크가 있으며, 여기에서는 몇 가지 두드러진 프레임워크를 소개한다.</p>
</div>
<div id="S3.SS9.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS9.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS9.SSS1.p2.1.1">ZeRO:</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib140" title="">140</a>]</cite>에서 Rajbhandari 등은 메모리를 최적화하기 위해 새로운 솔루션인 ZeRO(Zero Redundancy Optimizer)를 개발하여 LLM의 훈련 속도를 크게 향상시키면서 효율적으로 훈련할 수 있는 모델 크기를 증가시켰다. ZeRO는 낮은 통신 볼륨과 높은 계산 입도를 유지하면서 데이터 및 모델 병렬 훈련에서 메모리 중복성을 제거하여 지속적인 높은 효율로 장치 수에 비례하는 모델 크기를 확장할 수 있다.</p>
</div>
<div id="S3.SS9.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS9.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS9.SSS1.p3.1.1">RWKV:</span> In <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib141" title="">141</a>]</cite>, Peng 등은 Transformers의 효율적인 병렬화 훈련과 RNNs의 효율적인 추론을 결합한 새로운 모델 아키텍처인 Receptance Weighted Key Value(RWKV)를 제안했다. 그들의 접근법은 선형 주의 메커니즘을 활용하고 모델을 트랜스포머 또는 RNN으로 공식화할 수 있으며, 이는 훈련 동안 계산을 병렬화하고 추론 동안 일정한 계산 및 메모리 복잡성을 유지하여 최초의 비 트랜스포머 아키텍처가 수백억 개의 매개변수로 스케일링되도록 한다. RWKV 아키텍처는 그림 <a class="ltx_ref" href="#S3.F32" title="Figure 32 ‣ III-I1 Optimized Training ‣ III-I Cost-Effective Training/Inference/Adaptation/Compression ‣ III How LLMs Are Built ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">32</span></a>에 나와 있다.</p>
</div>
<figure id="S3.F32" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/rwkv.png" id="S3.F32.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="387" height="381" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F32.3.1.1" style="font-size:90%;">Figure 32</span>:</span><span class="ltx_text" id="S3.F32.4.2" style="font-size:90%;">RWKV architecture. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib141" title="">141</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S3.SS9.SSS1.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS9.SSS1.p4.1">서로 다른 트랜스포머를 사용한 RWKV의 시간 복잡도 비교는 그림 <a class="ltx_ref" href="#S3.F33" title="Figure 33 ‣ III-I1 Optimized Training ‣ III-I Cost-Effective Training/Inference/Adaptation/Compression ‣ III How LLMs Are Built ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">33</span></a>에 나와 있다.</p>
</div>
<figure id="S3.F33" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/rwkv_time.png" id="S3.F33.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="327" height="156" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F33.3.1.1" style="font-size:90%;">Figure 33</span>:</span><span class="ltx_text" id="S3.F33.4.2" style="font-size:90%;">Time Complexity comparison of RWKV with different Transformers. 여기서 T는 시퀀스 길이, d는 특징 차원, c는 MEGA의 2차 주의 청크 크기이다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib141" title="">141</a>]</cite>의 예절. </span></figcaption>
</figure>
</section>
<section id="S3.SS9.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS9.SSS2.5.1.1" class="ltx_text">III-I</span>2 </span><span id="S3.SS9.SSS2.6.2" class="ltx_text ltx_font_bold">Low-Rank Adaption (LoRA)</span>
</h4>

<div id="S3.SS9.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS9.SSS2.p1.1">Low-Rank Adaptation은 훈련 가능한 파라미터의 수를 상당히 감소시키는 대중적이고 가벼운 훈련 기법이며, 전문화된 작업에 대한 미세 조정된 가중치와 초기 사전 훈련된 가중치 사이의 차이가 종종 "낮은 고유 순위"를 나타낸다는 중요한 통찰력에 기초한다 - 이는 낮은 순위 행렬 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite>에 의해 잘 근사화될 수 있음을 의미한다. LoRA를 사용한 훈련은 훨씬 빠르고 메모리 효율적이며 저장 및 공유가 쉬운 더 작은 모델 가중치(수백MB)를 생성한다. 저순위 행렬의 한 가지 특성은 두 개의 더 작은 행렬의 곱으로 나타낼 수 있다는 것이다. 이 실현은 미세 조정된 가중치와 초기 사전 훈련된 가중치 사이의 이러한 델타가 훨씬 더 작은 두 행렬의 행렬 곱으로 표현될 수 있다는 가설로 이어진다. 전체 원래의 가중치 행렬이 아닌 이들 두 개의 더 작은 행렬들을 업데이트하는 것에 집중함으로써, 계산 효율이 실질적으로 개선될 수 있다.</p>
</div>
<div id="S3.SS9.SSS2.p2" class="ltx_para">
<p id="S3.SS9.SSS2.p2.18" class="ltx_p">Specifically, for a pre-trained weight matrix <math id="S3.SS9.SSS2.p2.1.m1.1" class="ltx_Math" alttext="W_{0}\in R^{d\times k}" display="inline"><semantics id="S3.SS9.SSS2.p2.1.m1.1a"><mrow id="S3.SS9.SSS2.p2.1.m1.1.1" xref="S3.SS9.SSS2.p2.1.m1.1.1.cmml"><msub id="S3.SS9.SSS2.p2.1.m1.1.1.2" xref="S3.SS9.SSS2.p2.1.m1.1.1.2.cmml"><mi id="S3.SS9.SSS2.p2.1.m1.1.1.2.2" xref="S3.SS9.SSS2.p2.1.m1.1.1.2.2.cmml">W</mi><mn id="S3.SS9.SSS2.p2.1.m1.1.1.2.3" xref="S3.SS9.SSS2.p2.1.m1.1.1.2.3.cmml">0</mn></msub><mo id="S3.SS9.SSS2.p2.1.m1.1.1.1" xref="S3.SS9.SSS2.p2.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS9.SSS2.p2.1.m1.1.1.3" xref="S3.SS9.SSS2.p2.1.m1.1.1.3.cmml"><mi id="S3.SS9.SSS2.p2.1.m1.1.1.3.2" xref="S3.SS9.SSS2.p2.1.m1.1.1.3.2.cmml">R</mi><mrow id="S3.SS9.SSS2.p2.1.m1.1.1.3.3" xref="S3.SS9.SSS2.p2.1.m1.1.1.3.3.cmml"><mi id="S3.SS9.SSS2.p2.1.m1.1.1.3.3.2" xref="S3.SS9.SSS2.p2.1.m1.1.1.3.3.2.cmml">d</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS9.SSS2.p2.1.m1.1.1.3.3.1" xref="S3.SS9.SSS2.p2.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S3.SS9.SSS2.p2.1.m1.1.1.3.3.3" xref="S3.SS9.SSS2.p2.1.m1.1.1.3.3.3.cmml">k</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.1.m1.1b"><apply id="S3.SS9.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS9.SSS2.p2.1.m1.1.1"><in id="S3.SS9.SSS2.p2.1.m1.1.1.1.cmml" xref="S3.SS9.SSS2.p2.1.m1.1.1.1"></in><apply id="S3.SS9.SSS2.p2.1.m1.1.1.2.cmml" xref="S3.SS9.SSS2.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p2.1.m1.1.1.2.1.cmml" xref="S3.SS9.SSS2.p2.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS9.SSS2.p2.1.m1.1.1.2.2.cmml" xref="S3.SS9.SSS2.p2.1.m1.1.1.2.2">𝑊</ci><cn type="integer" id="S3.SS9.SSS2.p2.1.m1.1.1.2.3.cmml" xref="S3.SS9.SSS2.p2.1.m1.1.1.2.3">0</cn></apply><apply id="S3.SS9.SSS2.p2.1.m1.1.1.3.cmml" xref="S3.SS9.SSS2.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p2.1.m1.1.1.3.1.cmml" xref="S3.SS9.SSS2.p2.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS9.SSS2.p2.1.m1.1.1.3.2.cmml" xref="S3.SS9.SSS2.p2.1.m1.1.1.3.2">𝑅</ci><apply id="S3.SS9.SSS2.p2.1.m1.1.1.3.3.cmml" xref="S3.SS9.SSS2.p2.1.m1.1.1.3.3"><times id="S3.SS9.SSS2.p2.1.m1.1.1.3.3.1.cmml" xref="S3.SS9.SSS2.p2.1.m1.1.1.3.3.1"></times><ci id="S3.SS9.SSS2.p2.1.m1.1.1.3.3.2.cmml" xref="S3.SS9.SSS2.p2.1.m1.1.1.3.3.2">𝑑</ci><ci id="S3.SS9.SSS2.p2.1.m1.1.1.3.3.3.cmml" xref="S3.SS9.SSS2.p2.1.m1.1.1.3.3.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.1.m1.1c">W_{0}\in R^{d\times k}</annotation></semantics></math>, LoRA constrains its update by representing the latter with a low-rank decomposition <math id="S3.SS9.SSS2.p2.2.m2.1" class="ltx_Math" alttext="W_{0}+\Delta W=W_{0}+BA" display="inline"><semantics id="S3.SS9.SSS2.p2.2.m2.1a"><mrow id="S3.SS9.SSS2.p2.2.m2.1.1" xref="S3.SS9.SSS2.p2.2.m2.1.1.cmml"><mrow id="S3.SS9.SSS2.p2.2.m2.1.1.2" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.cmml"><msub id="S3.SS9.SSS2.p2.2.m2.1.1.2.2" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.2.cmml"><mi id="S3.SS9.SSS2.p2.2.m2.1.1.2.2.2" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.2.2.cmml">W</mi><mn id="S3.SS9.SSS2.p2.2.m2.1.1.2.2.3" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.2.3.cmml">0</mn></msub><mo id="S3.SS9.SSS2.p2.2.m2.1.1.2.1" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.1.cmml">+</mo><mrow id="S3.SS9.SSS2.p2.2.m2.1.1.2.3" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.3.cmml"><mi mathvariant="normal" id="S3.SS9.SSS2.p2.2.m2.1.1.2.3.2" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.2.m2.1.1.2.3.1" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.3.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.2.m2.1.1.2.3.3" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.3.3.cmml">W</mi></mrow></mrow><mo id="S3.SS9.SSS2.p2.2.m2.1.1.1" xref="S3.SS9.SSS2.p2.2.m2.1.1.1.cmml">=</mo><mrow id="S3.SS9.SSS2.p2.2.m2.1.1.3" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.cmml"><msub id="S3.SS9.SSS2.p2.2.m2.1.1.3.2" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.2.cmml"><mi id="S3.SS9.SSS2.p2.2.m2.1.1.3.2.2" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.2.2.cmml">W</mi><mn id="S3.SS9.SSS2.p2.2.m2.1.1.3.2.3" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.2.3.cmml">0</mn></msub><mo id="S3.SS9.SSS2.p2.2.m2.1.1.3.1" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.1.cmml">+</mo><mrow id="S3.SS9.SSS2.p2.2.m2.1.1.3.3" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.3.cmml"><mi id="S3.SS9.SSS2.p2.2.m2.1.1.3.3.2" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.2.m2.1.1.3.3.1" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.3.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.2.m2.1.1.3.3.3" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.3.3.cmml">A</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.2.m2.1b"><apply id="S3.SS9.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1"><eq id="S3.SS9.SSS2.p2.2.m2.1.1.1.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.1"></eq><apply id="S3.SS9.SSS2.p2.2.m2.1.1.2.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.2"><plus id="S3.SS9.SSS2.p2.2.m2.1.1.2.1.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.1"></plus><apply id="S3.SS9.SSS2.p2.2.m2.1.1.2.2.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.2"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p2.2.m2.1.1.2.2.1.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.2">subscript</csymbol><ci id="S3.SS9.SSS2.p2.2.m2.1.1.2.2.2.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.2.2">𝑊</ci><cn type="integer" id="S3.SS9.SSS2.p2.2.m2.1.1.2.2.3.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.2.3">0</cn></apply><apply id="S3.SS9.SSS2.p2.2.m2.1.1.2.3.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.3"><times id="S3.SS9.SSS2.p2.2.m2.1.1.2.3.1.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.3.1"></times><ci id="S3.SS9.SSS2.p2.2.m2.1.1.2.3.2.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.3.2">Δ</ci><ci id="S3.SS9.SSS2.p2.2.m2.1.1.2.3.3.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.2.3.3">𝑊</ci></apply></apply><apply id="S3.SS9.SSS2.p2.2.m2.1.1.3.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.3"><plus id="S3.SS9.SSS2.p2.2.m2.1.1.3.1.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.1"></plus><apply id="S3.SS9.SSS2.p2.2.m2.1.1.3.2.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p2.2.m2.1.1.3.2.1.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.2">subscript</csymbol><ci id="S3.SS9.SSS2.p2.2.m2.1.1.3.2.2.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.2.2">𝑊</ci><cn type="integer" id="S3.SS9.SSS2.p2.2.m2.1.1.3.2.3.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.2.3">0</cn></apply><apply id="S3.SS9.SSS2.p2.2.m2.1.1.3.3.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.3"><times id="S3.SS9.SSS2.p2.2.m2.1.1.3.3.1.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.3.1"></times><ci id="S3.SS9.SSS2.p2.2.m2.1.1.3.3.2.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.3.2">𝐵</ci><ci id="S3.SS9.SSS2.p2.2.m2.1.1.3.3.3.cmml" xref="S3.SS9.SSS2.p2.2.m2.1.1.3.3.3">𝐴</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.2.m2.1c">W_{0}+\Delta W=W_{0}+BA</annotation></semantics></math>, where <math id="S3.SS9.SSS2.p2.3.m3.1" class="ltx_Math" alttext="B\in R^{d\times r}" display="inline"><semantics id="S3.SS9.SSS2.p2.3.m3.1a"><mrow id="S3.SS9.SSS2.p2.3.m3.1.1" xref="S3.SS9.SSS2.p2.3.m3.1.1.cmml"><mi id="S3.SS9.SSS2.p2.3.m3.1.1.2" xref="S3.SS9.SSS2.p2.3.m3.1.1.2.cmml">B</mi><mo id="S3.SS9.SSS2.p2.3.m3.1.1.1" xref="S3.SS9.SSS2.p2.3.m3.1.1.1.cmml">∈</mo><msup id="S3.SS9.SSS2.p2.3.m3.1.1.3" xref="S3.SS9.SSS2.p2.3.m3.1.1.3.cmml"><mi id="S3.SS9.SSS2.p2.3.m3.1.1.3.2" xref="S3.SS9.SSS2.p2.3.m3.1.1.3.2.cmml">R</mi><mrow id="S3.SS9.SSS2.p2.3.m3.1.1.3.3" xref="S3.SS9.SSS2.p2.3.m3.1.1.3.3.cmml"><mi id="S3.SS9.SSS2.p2.3.m3.1.1.3.3.2" xref="S3.SS9.SSS2.p2.3.m3.1.1.3.3.2.cmml">d</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS9.SSS2.p2.3.m3.1.1.3.3.1" xref="S3.SS9.SSS2.p2.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S3.SS9.SSS2.p2.3.m3.1.1.3.3.3" xref="S3.SS9.SSS2.p2.3.m3.1.1.3.3.3.cmml">r</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.3.m3.1b"><apply id="S3.SS9.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS9.SSS2.p2.3.m3.1.1"><in id="S3.SS9.SSS2.p2.3.m3.1.1.1.cmml" xref="S3.SS9.SSS2.p2.3.m3.1.1.1"></in><ci id="S3.SS9.SSS2.p2.3.m3.1.1.2.cmml" xref="S3.SS9.SSS2.p2.3.m3.1.1.2">𝐵</ci><apply id="S3.SS9.SSS2.p2.3.m3.1.1.3.cmml" xref="S3.SS9.SSS2.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p2.3.m3.1.1.3.1.cmml" xref="S3.SS9.SSS2.p2.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS9.SSS2.p2.3.m3.1.1.3.2.cmml" xref="S3.SS9.SSS2.p2.3.m3.1.1.3.2">𝑅</ci><apply id="S3.SS9.SSS2.p2.3.m3.1.1.3.3.cmml" xref="S3.SS9.SSS2.p2.3.m3.1.1.3.3"><times id="S3.SS9.SSS2.p2.3.m3.1.1.3.3.1.cmml" xref="S3.SS9.SSS2.p2.3.m3.1.1.3.3.1"></times><ci id="S3.SS9.SSS2.p2.3.m3.1.1.3.3.2.cmml" xref="S3.SS9.SSS2.p2.3.m3.1.1.3.3.2">𝑑</ci><ci id="S3.SS9.SSS2.p2.3.m3.1.1.3.3.3.cmml" xref="S3.SS9.SSS2.p2.3.m3.1.1.3.3.3">𝑟</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.3.m3.1c">B\in R^{d\times r}</annotation></semantics></math> , <math id="S3.SS9.SSS2.p2.4.m4.1" class="ltx_Math" alttext="A\in R^{r\times k}" display="inline"><semantics id="S3.SS9.SSS2.p2.4.m4.1a"><mrow id="S3.SS9.SSS2.p2.4.m4.1.1" xref="S3.SS9.SSS2.p2.4.m4.1.1.cmml"><mi id="S3.SS9.SSS2.p2.4.m4.1.1.2" xref="S3.SS9.SSS2.p2.4.m4.1.1.2.cmml">A</mi><mo id="S3.SS9.SSS2.p2.4.m4.1.1.1" xref="S3.SS9.SSS2.p2.4.m4.1.1.1.cmml">∈</mo><msup id="S3.SS9.SSS2.p2.4.m4.1.1.3" xref="S3.SS9.SSS2.p2.4.m4.1.1.3.cmml"><mi id="S3.SS9.SSS2.p2.4.m4.1.1.3.2" xref="S3.SS9.SSS2.p2.4.m4.1.1.3.2.cmml">R</mi><mrow id="S3.SS9.SSS2.p2.4.m4.1.1.3.3" xref="S3.SS9.SSS2.p2.4.m4.1.1.3.3.cmml"><mi id="S3.SS9.SSS2.p2.4.m4.1.1.3.3.2" xref="S3.SS9.SSS2.p2.4.m4.1.1.3.3.2.cmml">r</mi><mo lspace="0.222em" rspace="0.222em" id="S3.SS9.SSS2.p2.4.m4.1.1.3.3.1" xref="S3.SS9.SSS2.p2.4.m4.1.1.3.3.1.cmml">×</mo><mi id="S3.SS9.SSS2.p2.4.m4.1.1.3.3.3" xref="S3.SS9.SSS2.p2.4.m4.1.1.3.3.3.cmml">k</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.4.m4.1b"><apply id="S3.SS9.SSS2.p2.4.m4.1.1.cmml" xref="S3.SS9.SSS2.p2.4.m4.1.1"><in id="S3.SS9.SSS2.p2.4.m4.1.1.1.cmml" xref="S3.SS9.SSS2.p2.4.m4.1.1.1"></in><ci id="S3.SS9.SSS2.p2.4.m4.1.1.2.cmml" xref="S3.SS9.SSS2.p2.4.m4.1.1.2">𝐴</ci><apply id="S3.SS9.SSS2.p2.4.m4.1.1.3.cmml" xref="S3.SS9.SSS2.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p2.4.m4.1.1.3.1.cmml" xref="S3.SS9.SSS2.p2.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS9.SSS2.p2.4.m4.1.1.3.2.cmml" xref="S3.SS9.SSS2.p2.4.m4.1.1.3.2">𝑅</ci><apply id="S3.SS9.SSS2.p2.4.m4.1.1.3.3.cmml" xref="S3.SS9.SSS2.p2.4.m4.1.1.3.3"><times id="S3.SS9.SSS2.p2.4.m4.1.1.3.3.1.cmml" xref="S3.SS9.SSS2.p2.4.m4.1.1.3.3.1"></times><ci id="S3.SS9.SSS2.p2.4.m4.1.1.3.3.2.cmml" xref="S3.SS9.SSS2.p2.4.m4.1.1.3.3.2">𝑟</ci><ci id="S3.SS9.SSS2.p2.4.m4.1.1.3.3.3.cmml" xref="S3.SS9.SSS2.p2.4.m4.1.1.3.3.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.4.m4.1c">A\in R^{r\times k}</annotation></semantics></math>, and the rank <math id="S3.SS9.SSS2.p2.5.m5.2" class="ltx_Math" alttext="r\ll min(d,k)" display="inline"><semantics id="S3.SS9.SSS2.p2.5.m5.2a"><mrow id="S3.SS9.SSS2.p2.5.m5.2.3" xref="S3.SS9.SSS2.p2.5.m5.2.3.cmml"><mi id="S3.SS9.SSS2.p2.5.m5.2.3.2" xref="S3.SS9.SSS2.p2.5.m5.2.3.2.cmml">r</mi><mo id="S3.SS9.SSS2.p2.5.m5.2.3.1" xref="S3.SS9.SSS2.p2.5.m5.2.3.1.cmml">≪</mo><mrow id="S3.SS9.SSS2.p2.5.m5.2.3.3" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.cmml"><mi id="S3.SS9.SSS2.p2.5.m5.2.3.3.2" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.5.m5.2.3.3.1" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.5.m5.2.3.3.3" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.3.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.5.m5.2.3.3.1a" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.5.m5.2.3.3.4" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.5.m5.2.3.3.1b" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.1.cmml">​</mo><mrow id="S3.SS9.SSS2.p2.5.m5.2.3.3.5.2" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.5.1.cmml"><mo stretchy="false" id="S3.SS9.SSS2.p2.5.m5.2.3.3.5.2.1" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.5.1.cmml">(</mo><mi id="S3.SS9.SSS2.p2.5.m5.1.1" xref="S3.SS9.SSS2.p2.5.m5.1.1.cmml">d</mi><mo id="S3.SS9.SSS2.p2.5.m5.2.3.3.5.2.2" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.5.1.cmml">,</mo><mi id="S3.SS9.SSS2.p2.5.m5.2.2" xref="S3.SS9.SSS2.p2.5.m5.2.2.cmml">k</mi><mo stretchy="false" id="S3.SS9.SSS2.p2.5.m5.2.3.3.5.2.3" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.5.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.5.m5.2b"><apply id="S3.SS9.SSS2.p2.5.m5.2.3.cmml" xref="S3.SS9.SSS2.p2.5.m5.2.3"><csymbol cd="latexml" id="S3.SS9.SSS2.p2.5.m5.2.3.1.cmml" xref="S3.SS9.SSS2.p2.5.m5.2.3.1">much-less-than</csymbol><ci id="S3.SS9.SSS2.p2.5.m5.2.3.2.cmml" xref="S3.SS9.SSS2.p2.5.m5.2.3.2">𝑟</ci><apply id="S3.SS9.SSS2.p2.5.m5.2.3.3.cmml" xref="S3.SS9.SSS2.p2.5.m5.2.3.3"><times id="S3.SS9.SSS2.p2.5.m5.2.3.3.1.cmml" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.1"></times><ci id="S3.SS9.SSS2.p2.5.m5.2.3.3.2.cmml" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.2">𝑚</ci><ci id="S3.SS9.SSS2.p2.5.m5.2.3.3.3.cmml" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.3">𝑖</ci><ci id="S3.SS9.SSS2.p2.5.m5.2.3.3.4.cmml" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.4">𝑛</ci><interval closure="open" id="S3.SS9.SSS2.p2.5.m5.2.3.3.5.1.cmml" xref="S3.SS9.SSS2.p2.5.m5.2.3.3.5.2"><ci id="S3.SS9.SSS2.p2.5.m5.1.1.cmml" xref="S3.SS9.SSS2.p2.5.m5.1.1">𝑑</ci><ci id="S3.SS9.SSS2.p2.5.m5.2.2.cmml" xref="S3.SS9.SSS2.p2.5.m5.2.2">𝑘</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.5.m5.2c">r\ll min(d,k)</annotation></semantics></math>. During training, <math id="S3.SS9.SSS2.p2.6.m6.1" class="ltx_Math" alttext="W_{0}" display="inline"><semantics id="S3.SS9.SSS2.p2.6.m6.1a"><msub id="S3.SS9.SSS2.p2.6.m6.1.1" xref="S3.SS9.SSS2.p2.6.m6.1.1.cmml"><mi id="S3.SS9.SSS2.p2.6.m6.1.1.2" xref="S3.SS9.SSS2.p2.6.m6.1.1.2.cmml">W</mi><mn id="S3.SS9.SSS2.p2.6.m6.1.1.3" xref="S3.SS9.SSS2.p2.6.m6.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.6.m6.1b"><apply id="S3.SS9.SSS2.p2.6.m6.1.1.cmml" xref="S3.SS9.SSS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p2.6.m6.1.1.1.cmml" xref="S3.SS9.SSS2.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS9.SSS2.p2.6.m6.1.1.2.cmml" xref="S3.SS9.SSS2.p2.6.m6.1.1.2">𝑊</ci><cn type="integer" id="S3.SS9.SSS2.p2.6.m6.1.1.3.cmml" xref="S3.SS9.SSS2.p2.6.m6.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.6.m6.1c">W_{0}</annotation></semantics></math> is frozen and does not receive gradient updates, while <math id="S3.SS9.SSS2.p2.7.m7.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS9.SSS2.p2.7.m7.1a"><mi id="S3.SS9.SSS2.p2.7.m7.1.1" xref="S3.SS9.SSS2.p2.7.m7.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.7.m7.1b"><ci id="S3.SS9.SSS2.p2.7.m7.1.1.cmml" xref="S3.SS9.SSS2.p2.7.m7.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.7.m7.1c">A</annotation></semantics></math> and <math id="S3.SS9.SSS2.p2.8.m8.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.SS9.SSS2.p2.8.m8.1a"><mi id="S3.SS9.SSS2.p2.8.m8.1.1" xref="S3.SS9.SSS2.p2.8.m8.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.8.m8.1b"><ci id="S3.SS9.SSS2.p2.8.m8.1.1.cmml" xref="S3.SS9.SSS2.p2.8.m8.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.8.m8.1c">B</annotation></semantics></math> contain trainable parameters. It is worth mentioning that both <math id="S3.SS9.SSS2.p2.9.m9.1" class="ltx_Math" alttext="W_{0}" display="inline"><semantics id="S3.SS9.SSS2.p2.9.m9.1a"><msub id="S3.SS9.SSS2.p2.9.m9.1.1" xref="S3.SS9.SSS2.p2.9.m9.1.1.cmml"><mi id="S3.SS9.SSS2.p2.9.m9.1.1.2" xref="S3.SS9.SSS2.p2.9.m9.1.1.2.cmml">W</mi><mn id="S3.SS9.SSS2.p2.9.m9.1.1.3" xref="S3.SS9.SSS2.p2.9.m9.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.9.m9.1b"><apply id="S3.SS9.SSS2.p2.9.m9.1.1.cmml" xref="S3.SS9.SSS2.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p2.9.m9.1.1.1.cmml" xref="S3.SS9.SSS2.p2.9.m9.1.1">subscript</csymbol><ci id="S3.SS9.SSS2.p2.9.m9.1.1.2.cmml" xref="S3.SS9.SSS2.p2.9.m9.1.1.2">𝑊</ci><cn type="integer" id="S3.SS9.SSS2.p2.9.m9.1.1.3.cmml" xref="S3.SS9.SSS2.p2.9.m9.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.9.m9.1c">W_{0}</annotation></semantics></math> and <math id="S3.SS9.SSS2.p2.10.m10.1" class="ltx_Math" alttext="\Delta W=BA" display="inline"><semantics id="S3.SS9.SSS2.p2.10.m10.1a"><mrow id="S3.SS9.SSS2.p2.10.m10.1.1" xref="S3.SS9.SSS2.p2.10.m10.1.1.cmml"><mrow id="S3.SS9.SSS2.p2.10.m10.1.1.2" xref="S3.SS9.SSS2.p2.10.m10.1.1.2.cmml"><mi mathvariant="normal" id="S3.SS9.SSS2.p2.10.m10.1.1.2.2" xref="S3.SS9.SSS2.p2.10.m10.1.1.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.10.m10.1.1.2.1" xref="S3.SS9.SSS2.p2.10.m10.1.1.2.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.10.m10.1.1.2.3" xref="S3.SS9.SSS2.p2.10.m10.1.1.2.3.cmml">W</mi></mrow><mo id="S3.SS9.SSS2.p2.10.m10.1.1.1" xref="S3.SS9.SSS2.p2.10.m10.1.1.1.cmml">=</mo><mrow id="S3.SS9.SSS2.p2.10.m10.1.1.3" xref="S3.SS9.SSS2.p2.10.m10.1.1.3.cmml"><mi id="S3.SS9.SSS2.p2.10.m10.1.1.3.2" xref="S3.SS9.SSS2.p2.10.m10.1.1.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.10.m10.1.1.3.1" xref="S3.SS9.SSS2.p2.10.m10.1.1.3.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.10.m10.1.1.3.3" xref="S3.SS9.SSS2.p2.10.m10.1.1.3.3.cmml">A</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.10.m10.1b"><apply id="S3.SS9.SSS2.p2.10.m10.1.1.cmml" xref="S3.SS9.SSS2.p2.10.m10.1.1"><eq id="S3.SS9.SSS2.p2.10.m10.1.1.1.cmml" xref="S3.SS9.SSS2.p2.10.m10.1.1.1"></eq><apply id="S3.SS9.SSS2.p2.10.m10.1.1.2.cmml" xref="S3.SS9.SSS2.p2.10.m10.1.1.2"><times id="S3.SS9.SSS2.p2.10.m10.1.1.2.1.cmml" xref="S3.SS9.SSS2.p2.10.m10.1.1.2.1"></times><ci id="S3.SS9.SSS2.p2.10.m10.1.1.2.2.cmml" xref="S3.SS9.SSS2.p2.10.m10.1.1.2.2">Δ</ci><ci id="S3.SS9.SSS2.p2.10.m10.1.1.2.3.cmml" xref="S3.SS9.SSS2.p2.10.m10.1.1.2.3">𝑊</ci></apply><apply id="S3.SS9.SSS2.p2.10.m10.1.1.3.cmml" xref="S3.SS9.SSS2.p2.10.m10.1.1.3"><times id="S3.SS9.SSS2.p2.10.m10.1.1.3.1.cmml" xref="S3.SS9.SSS2.p2.10.m10.1.1.3.1"></times><ci id="S3.SS9.SSS2.p2.10.m10.1.1.3.2.cmml" xref="S3.SS9.SSS2.p2.10.m10.1.1.3.2">𝐵</ci><ci id="S3.SS9.SSS2.p2.10.m10.1.1.3.3.cmml" xref="S3.SS9.SSS2.p2.10.m10.1.1.3.3">𝐴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.10.m10.1c">\Delta W=BA</annotation></semantics></math> are multiplied with the same input, and their respective output vectors are summed coordinate-wise. For <math id="S3.SS9.SSS2.p2.11.m11.1" class="ltx_Math" alttext="h=W_{0}x" display="inline"><semantics id="S3.SS9.SSS2.p2.11.m11.1a"><mrow id="S3.SS9.SSS2.p2.11.m11.1.1" xref="S3.SS9.SSS2.p2.11.m11.1.1.cmml"><mi id="S3.SS9.SSS2.p2.11.m11.1.1.2" xref="S3.SS9.SSS2.p2.11.m11.1.1.2.cmml">h</mi><mo id="S3.SS9.SSS2.p2.11.m11.1.1.1" xref="S3.SS9.SSS2.p2.11.m11.1.1.1.cmml">=</mo><mrow id="S3.SS9.SSS2.p2.11.m11.1.1.3" xref="S3.SS9.SSS2.p2.11.m11.1.1.3.cmml"><msub id="S3.SS9.SSS2.p2.11.m11.1.1.3.2" xref="S3.SS9.SSS2.p2.11.m11.1.1.3.2.cmml"><mi id="S3.SS9.SSS2.p2.11.m11.1.1.3.2.2" xref="S3.SS9.SSS2.p2.11.m11.1.1.3.2.2.cmml">W</mi><mn id="S3.SS9.SSS2.p2.11.m11.1.1.3.2.3" xref="S3.SS9.SSS2.p2.11.m11.1.1.3.2.3.cmml">0</mn></msub><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.11.m11.1.1.3.1" xref="S3.SS9.SSS2.p2.11.m11.1.1.3.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.11.m11.1.1.3.3" xref="S3.SS9.SSS2.p2.11.m11.1.1.3.3.cmml">x</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.11.m11.1b"><apply id="S3.SS9.SSS2.p2.11.m11.1.1.cmml" xref="S3.SS9.SSS2.p2.11.m11.1.1"><eq id="S3.SS9.SSS2.p2.11.m11.1.1.1.cmml" xref="S3.SS9.SSS2.p2.11.m11.1.1.1"></eq><ci id="S3.SS9.SSS2.p2.11.m11.1.1.2.cmml" xref="S3.SS9.SSS2.p2.11.m11.1.1.2">ℎ</ci><apply id="S3.SS9.SSS2.p2.11.m11.1.1.3.cmml" xref="S3.SS9.SSS2.p2.11.m11.1.1.3"><times id="S3.SS9.SSS2.p2.11.m11.1.1.3.1.cmml" xref="S3.SS9.SSS2.p2.11.m11.1.1.3.1"></times><apply id="S3.SS9.SSS2.p2.11.m11.1.1.3.2.cmml" xref="S3.SS9.SSS2.p2.11.m11.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p2.11.m11.1.1.3.2.1.cmml" xref="S3.SS9.SSS2.p2.11.m11.1.1.3.2">subscript</csymbol><ci id="S3.SS9.SSS2.p2.11.m11.1.1.3.2.2.cmml" xref="S3.SS9.SSS2.p2.11.m11.1.1.3.2.2">𝑊</ci><cn type="integer" id="S3.SS9.SSS2.p2.11.m11.1.1.3.2.3.cmml" xref="S3.SS9.SSS2.p2.11.m11.1.1.3.2.3">0</cn></apply><ci id="S3.SS9.SSS2.p2.11.m11.1.1.3.3.cmml" xref="S3.SS9.SSS2.p2.11.m11.1.1.3.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.11.m11.1c">h=W_{0}x</annotation></semantics></math>, their modified forward pass yields: <math id="S3.SS9.SSS2.p2.12.m12.1" class="ltx_Math" alttext="h=W_{0}x+\Delta Wx=W_{0}x+BAx" display="inline"><semantics id="S3.SS9.SSS2.p2.12.m12.1a"><mrow id="S3.SS9.SSS2.p2.12.m12.1.1" xref="S3.SS9.SSS2.p2.12.m12.1.1.cmml"><mi id="S3.SS9.SSS2.p2.12.m12.1.1.2" xref="S3.SS9.SSS2.p2.12.m12.1.1.2.cmml">h</mi><mo id="S3.SS9.SSS2.p2.12.m12.1.1.3" xref="S3.SS9.SSS2.p2.12.m12.1.1.3.cmml">=</mo><mrow id="S3.SS9.SSS2.p2.12.m12.1.1.4" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.cmml"><mrow id="S3.SS9.SSS2.p2.12.m12.1.1.4.2" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.2.cmml"><msub id="S3.SS9.SSS2.p2.12.m12.1.1.4.2.2" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.2.2.cmml"><mi id="S3.SS9.SSS2.p2.12.m12.1.1.4.2.2.2" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.2.2.2.cmml">W</mi><mn id="S3.SS9.SSS2.p2.12.m12.1.1.4.2.2.3" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.2.2.3.cmml">0</mn></msub><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.12.m12.1.1.4.2.1" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.2.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.12.m12.1.1.4.2.3" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.2.3.cmml">x</mi></mrow><mo id="S3.SS9.SSS2.p2.12.m12.1.1.4.1" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.1.cmml">+</mo><mrow id="S3.SS9.SSS2.p2.12.m12.1.1.4.3" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.3.cmml"><mi mathvariant="normal" id="S3.SS9.SSS2.p2.12.m12.1.1.4.3.2" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.12.m12.1.1.4.3.1" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.3.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.12.m12.1.1.4.3.3" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.3.3.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.12.m12.1.1.4.3.1a" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.3.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.12.m12.1.1.4.3.4" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.3.4.cmml">x</mi></mrow></mrow><mo id="S3.SS9.SSS2.p2.12.m12.1.1.5" xref="S3.SS9.SSS2.p2.12.m12.1.1.5.cmml">=</mo><mrow id="S3.SS9.SSS2.p2.12.m12.1.1.6" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.cmml"><mrow id="S3.SS9.SSS2.p2.12.m12.1.1.6.2" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.2.cmml"><msub id="S3.SS9.SSS2.p2.12.m12.1.1.6.2.2" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.2.2.cmml"><mi id="S3.SS9.SSS2.p2.12.m12.1.1.6.2.2.2" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.2.2.2.cmml">W</mi><mn id="S3.SS9.SSS2.p2.12.m12.1.1.6.2.2.3" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.2.2.3.cmml">0</mn></msub><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.12.m12.1.1.6.2.1" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.2.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.12.m12.1.1.6.2.3" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.2.3.cmml">x</mi></mrow><mo id="S3.SS9.SSS2.p2.12.m12.1.1.6.1" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.1.cmml">+</mo><mrow id="S3.SS9.SSS2.p2.12.m12.1.1.6.3" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.3.cmml"><mi id="S3.SS9.SSS2.p2.12.m12.1.1.6.3.2" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.12.m12.1.1.6.3.1" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.3.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.12.m12.1.1.6.3.3" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.3.3.cmml">A</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.12.m12.1.1.6.3.1a" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.3.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.12.m12.1.1.6.3.4" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.3.4.cmml">x</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.12.m12.1b"><apply id="S3.SS9.SSS2.p2.12.m12.1.1.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1"><and id="S3.SS9.SSS2.p2.12.m12.1.1a.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1"></and><apply id="S3.SS9.SSS2.p2.12.m12.1.1b.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1"><eq id="S3.SS9.SSS2.p2.12.m12.1.1.3.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.3"></eq><ci id="S3.SS9.SSS2.p2.12.m12.1.1.2.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.2">ℎ</ci><apply id="S3.SS9.SSS2.p2.12.m12.1.1.4.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.4"><plus id="S3.SS9.SSS2.p2.12.m12.1.1.4.1.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.1"></plus><apply id="S3.SS9.SSS2.p2.12.m12.1.1.4.2.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.2"><times id="S3.SS9.SSS2.p2.12.m12.1.1.4.2.1.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.2.1"></times><apply id="S3.SS9.SSS2.p2.12.m12.1.1.4.2.2.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.2.2"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p2.12.m12.1.1.4.2.2.1.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.2.2">subscript</csymbol><ci id="S3.SS9.SSS2.p2.12.m12.1.1.4.2.2.2.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.2.2.2">𝑊</ci><cn type="integer" id="S3.SS9.SSS2.p2.12.m12.1.1.4.2.2.3.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.2.2.3">0</cn></apply><ci id="S3.SS9.SSS2.p2.12.m12.1.1.4.2.3.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.2.3">𝑥</ci></apply><apply id="S3.SS9.SSS2.p2.12.m12.1.1.4.3.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.3"><times id="S3.SS9.SSS2.p2.12.m12.1.1.4.3.1.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.3.1"></times><ci id="S3.SS9.SSS2.p2.12.m12.1.1.4.3.2.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.3.2">Δ</ci><ci id="S3.SS9.SSS2.p2.12.m12.1.1.4.3.3.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.3.3">𝑊</ci><ci id="S3.SS9.SSS2.p2.12.m12.1.1.4.3.4.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.4.3.4">𝑥</ci></apply></apply></apply><apply id="S3.SS9.SSS2.p2.12.m12.1.1c.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1"><eq id="S3.SS9.SSS2.p2.12.m12.1.1.5.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.5"></eq><share href="#S3.SS9.SSS2.p2.12.m12.1.1.4.cmml" id="S3.SS9.SSS2.p2.12.m12.1.1d.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1"></share><apply id="S3.SS9.SSS2.p2.12.m12.1.1.6.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.6"><plus id="S3.SS9.SSS2.p2.12.m12.1.1.6.1.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.1"></plus><apply id="S3.SS9.SSS2.p2.12.m12.1.1.6.2.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.2"><times id="S3.SS9.SSS2.p2.12.m12.1.1.6.2.1.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.2.1"></times><apply id="S3.SS9.SSS2.p2.12.m12.1.1.6.2.2.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.2.2"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p2.12.m12.1.1.6.2.2.1.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.2.2">subscript</csymbol><ci id="S3.SS9.SSS2.p2.12.m12.1.1.6.2.2.2.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.2.2.2">𝑊</ci><cn type="integer" id="S3.SS9.SSS2.p2.12.m12.1.1.6.2.2.3.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.2.2.3">0</cn></apply><ci id="S3.SS9.SSS2.p2.12.m12.1.1.6.2.3.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.2.3">𝑥</ci></apply><apply id="S3.SS9.SSS2.p2.12.m12.1.1.6.3.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.3"><times id="S3.SS9.SSS2.p2.12.m12.1.1.6.3.1.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.3.1"></times><ci id="S3.SS9.SSS2.p2.12.m12.1.1.6.3.2.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.3.2">𝐵</ci><ci id="S3.SS9.SSS2.p2.12.m12.1.1.6.3.3.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.3.3">𝐴</ci><ci id="S3.SS9.SSS2.p2.12.m12.1.1.6.3.4.cmml" xref="S3.SS9.SSS2.p2.12.m12.1.1.6.3.4">𝑥</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.12.m12.1c">h=W_{0}x+\Delta Wx=W_{0}x+BAx</annotation></semantics></math>. Usually a random Gaussian initialization is used for <math id="S3.SS9.SSS2.p2.13.m13.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S3.SS9.SSS2.p2.13.m13.1a"><mi id="S3.SS9.SSS2.p2.13.m13.1.1" xref="S3.SS9.SSS2.p2.13.m13.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.13.m13.1b"><ci id="S3.SS9.SSS2.p2.13.m13.1.1.cmml" xref="S3.SS9.SSS2.p2.13.m13.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.13.m13.1c">A</annotation></semantics></math>, and zero initialization for <math id="S3.SS9.SSS2.p2.14.m14.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S3.SS9.SSS2.p2.14.m14.1a"><mi id="S3.SS9.SSS2.p2.14.m14.1.1" xref="S3.SS9.SSS2.p2.14.m14.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.14.m14.1b"><ci id="S3.SS9.SSS2.p2.14.m14.1.1.cmml" xref="S3.SS9.SSS2.p2.14.m14.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.14.m14.1c">B</annotation></semantics></math>, so <math id="S3.SS9.SSS2.p2.15.m15.1" class="ltx_Math" alttext="\Delta W=BA" display="inline"><semantics id="S3.SS9.SSS2.p2.15.m15.1a"><mrow id="S3.SS9.SSS2.p2.15.m15.1.1" xref="S3.SS9.SSS2.p2.15.m15.1.1.cmml"><mrow id="S3.SS9.SSS2.p2.15.m15.1.1.2" xref="S3.SS9.SSS2.p2.15.m15.1.1.2.cmml"><mi mathvariant="normal" id="S3.SS9.SSS2.p2.15.m15.1.1.2.2" xref="S3.SS9.SSS2.p2.15.m15.1.1.2.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.15.m15.1.1.2.1" xref="S3.SS9.SSS2.p2.15.m15.1.1.2.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.15.m15.1.1.2.3" xref="S3.SS9.SSS2.p2.15.m15.1.1.2.3.cmml">W</mi></mrow><mo id="S3.SS9.SSS2.p2.15.m15.1.1.1" xref="S3.SS9.SSS2.p2.15.m15.1.1.1.cmml">=</mo><mrow id="S3.SS9.SSS2.p2.15.m15.1.1.3" xref="S3.SS9.SSS2.p2.15.m15.1.1.3.cmml"><mi id="S3.SS9.SSS2.p2.15.m15.1.1.3.2" xref="S3.SS9.SSS2.p2.15.m15.1.1.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.15.m15.1.1.3.1" xref="S3.SS9.SSS2.p2.15.m15.1.1.3.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.15.m15.1.1.3.3" xref="S3.SS9.SSS2.p2.15.m15.1.1.3.3.cmml">A</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.15.m15.1b"><apply id="S3.SS9.SSS2.p2.15.m15.1.1.cmml" xref="S3.SS9.SSS2.p2.15.m15.1.1"><eq id="S3.SS9.SSS2.p2.15.m15.1.1.1.cmml" xref="S3.SS9.SSS2.p2.15.m15.1.1.1"></eq><apply id="S3.SS9.SSS2.p2.15.m15.1.1.2.cmml" xref="S3.SS9.SSS2.p2.15.m15.1.1.2"><times id="S3.SS9.SSS2.p2.15.m15.1.1.2.1.cmml" xref="S3.SS9.SSS2.p2.15.m15.1.1.2.1"></times><ci id="S3.SS9.SSS2.p2.15.m15.1.1.2.2.cmml" xref="S3.SS9.SSS2.p2.15.m15.1.1.2.2">Δ</ci><ci id="S3.SS9.SSS2.p2.15.m15.1.1.2.3.cmml" xref="S3.SS9.SSS2.p2.15.m15.1.1.2.3">𝑊</ci></apply><apply id="S3.SS9.SSS2.p2.15.m15.1.1.3.cmml" xref="S3.SS9.SSS2.p2.15.m15.1.1.3"><times id="S3.SS9.SSS2.p2.15.m15.1.1.3.1.cmml" xref="S3.SS9.SSS2.p2.15.m15.1.1.3.1"></times><ci id="S3.SS9.SSS2.p2.15.m15.1.1.3.2.cmml" xref="S3.SS9.SSS2.p2.15.m15.1.1.3.2">𝐵</ci><ci id="S3.SS9.SSS2.p2.15.m15.1.1.3.3.cmml" xref="S3.SS9.SSS2.p2.15.m15.1.1.3.3">𝐴</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.15.m15.1c">\Delta W=BA</annotation></semantics></math> is zero at the beginning of training. They then scale <math id="S3.SS9.SSS2.p2.16.m16.1" class="ltx_Math" alttext="\Delta Wx" display="inline"><semantics id="S3.SS9.SSS2.p2.16.m16.1a"><mrow id="S3.SS9.SSS2.p2.16.m16.1.1" xref="S3.SS9.SSS2.p2.16.m16.1.1.cmml"><mi mathvariant="normal" id="S3.SS9.SSS2.p2.16.m16.1.1.2" xref="S3.SS9.SSS2.p2.16.m16.1.1.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.16.m16.1.1.1" xref="S3.SS9.SSS2.p2.16.m16.1.1.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.16.m16.1.1.3" xref="S3.SS9.SSS2.p2.16.m16.1.1.3.cmml">W</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.16.m16.1.1.1a" xref="S3.SS9.SSS2.p2.16.m16.1.1.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.16.m16.1.1.4" xref="S3.SS9.SSS2.p2.16.m16.1.1.4.cmml">x</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.16.m16.1b"><apply id="S3.SS9.SSS2.p2.16.m16.1.1.cmml" xref="S3.SS9.SSS2.p2.16.m16.1.1"><times id="S3.SS9.SSS2.p2.16.m16.1.1.1.cmml" xref="S3.SS9.SSS2.p2.16.m16.1.1.1"></times><ci id="S3.SS9.SSS2.p2.16.m16.1.1.2.cmml" xref="S3.SS9.SSS2.p2.16.m16.1.1.2">Δ</ci><ci id="S3.SS9.SSS2.p2.16.m16.1.1.3.cmml" xref="S3.SS9.SSS2.p2.16.m16.1.1.3">𝑊</ci><ci id="S3.SS9.SSS2.p2.16.m16.1.1.4.cmml" xref="S3.SS9.SSS2.p2.16.m16.1.1.4">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.16.m16.1c">\Delta Wx</annotation></semantics></math> by <math id="S3.SS9.SSS2.p2.17.m17.1" class="ltx_Math" alttext="\alpha r" display="inline"><semantics id="S3.SS9.SSS2.p2.17.m17.1a"><mrow id="S3.SS9.SSS2.p2.17.m17.1.1" xref="S3.SS9.SSS2.p2.17.m17.1.1.cmml"><mi id="S3.SS9.SSS2.p2.17.m17.1.1.2" xref="S3.SS9.SSS2.p2.17.m17.1.1.2.cmml">α</mi><mo lspace="0em" rspace="0em" id="S3.SS9.SSS2.p2.17.m17.1.1.1" xref="S3.SS9.SSS2.p2.17.m17.1.1.1.cmml">​</mo><mi id="S3.SS9.SSS2.p2.17.m17.1.1.3" xref="S3.SS9.SSS2.p2.17.m17.1.1.3.cmml">r</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.17.m17.1b"><apply id="S3.SS9.SSS2.p2.17.m17.1.1.cmml" xref="S3.SS9.SSS2.p2.17.m17.1.1"><times id="S3.SS9.SSS2.p2.17.m17.1.1.1.cmml" xref="S3.SS9.SSS2.p2.17.m17.1.1.1"></times><ci id="S3.SS9.SSS2.p2.17.m17.1.1.2.cmml" xref="S3.SS9.SSS2.p2.17.m17.1.1.2">𝛼</ci><ci id="S3.SS9.SSS2.p2.17.m17.1.1.3.cmml" xref="S3.SS9.SSS2.p2.17.m17.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.17.m17.1c">\alpha r</annotation></semantics></math>, where <math id="S3.SS9.SSS2.p2.18.m18.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS9.SSS2.p2.18.m18.1a"><mi id="S3.SS9.SSS2.p2.18.m18.1.1" xref="S3.SS9.SSS2.p2.18.m18.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p2.18.m18.1b"><ci id="S3.SS9.SSS2.p2.18.m18.1.1.cmml" xref="S3.SS9.SSS2.p2.18.m18.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p2.18.m18.1c">\alpha</annotation></semantics></math> is a constant in r. This reparametrization is illustrated in Figure <a href="#S3.F34" title="Figure 34 ‣ III-I2 Low-Rank Adaption (LoRA) ‣ III-I Cost-Effective Training/Inference/Adaptation/Compression ‣ III How LLMs Are Built ‣ Large Language Models: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">34</span></a></p>
</div>
<figure id="S3.F34" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/lora.png" id="S3.F34.g1" class="ltx_graphics ltx_centering ltx_img_square" width="218" height="209" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F34.6.3.1" style="font-size:90%;">Figure 34</span>:</span><span class="ltx_text" id="S3.F34.4.2" style="font-size:90%;">An illustration of LoRA reparametrizan. 이 과정에서 훈련된 <math alttext="A" class="ltx_Math" display="inline" id="S3.F34.3.1.m1.1"><semantics id="S3.F34.3.1.m1.1b"><mi id="S3.F34.3.1.m1.1.1" xref="S3.F34.3.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S3.F34.3.1.m1.1c"><ci id="S3.F34.3.1.m1.1.1.cmml" xref="S3.F34.3.1.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F34.3.1.m1.1d">A</annotation></semantics></math>와 <math alttext="B" class="ltx_Math" display="inline" id="S3.F34.4.2.m2.1"><semantics id="S3.F34.4.2.m2.1b"><mi id="S3.F34.4.2.m2.1.1" xref="S3.F34.4.2.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S3.F34.4.2.m2.1c"><ci id="S3.F34.4.2.m2.1.1.cmml" xref="S3.F34.4.2.m2.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F34.4.2.m2.1d">B</annotation></semantics></math>뿐이다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S3.SS9.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS9.SSS2.p3.4">LoRA는 훈련 가능한 파라미터의 수를 감소시키기 위해 신경망의 가중치 행렬의 임의의 서브세트에 적용될 수 있다는 것을 언급할 가치가 있다. 트랜스포머 아키텍처에서, 셀프-어텐션 모듈(<math alttext="W_{q}" class="ltx_Math" display="inline" id="S3.SS9.SSS2.p3.1.m1.1"><semantics id="S3.SS9.SSS2.p3.1.m1.1a"><msub id="S3.SS9.SSS2.p3.1.m1.1.1" xref="S3.SS9.SSS2.p3.1.m1.1.1.cmml"><mi id="S3.SS9.SSS2.p3.1.m1.1.1.2" xref="S3.SS9.SSS2.p3.1.m1.1.1.2.cmml">W</mi><mi id="S3.SS9.SSS2.p3.1.m1.1.1.3" xref="S3.SS9.SSS2.p3.1.m1.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p3.1.m1.1b"><apply id="S3.SS9.SSS2.p3.1.m1.1.1.cmml" xref="S3.SS9.SSS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p3.1.m1.1.1.1.cmml" xref="S3.SS9.SSS2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS9.SSS2.p3.1.m1.1.1.2.cmml" xref="S3.SS9.SSS2.p3.1.m1.1.1.2">𝑊</ci><ci id="S3.SS9.SSS2.p3.1.m1.1.1.3.cmml" xref="S3.SS9.SSS2.p3.1.m1.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p3.1.m1.1c">W_{q}</annotation></semantics></math>, <math alttext="W_{k}" class="ltx_Math" display="inline" id="S3.SS9.SSS2.p3.2.m2.1"><semantics id="S3.SS9.SSS2.p3.2.m2.1a"><msub id="S3.SS9.SSS2.p3.2.m2.1.1" xref="S3.SS9.SSS2.p3.2.m2.1.1.cmml"><mi id="S3.SS9.SSS2.p3.2.m2.1.1.2" xref="S3.SS9.SSS2.p3.2.m2.1.1.2.cmml">W</mi><mi id="S3.SS9.SSS2.p3.2.m2.1.1.3" xref="S3.SS9.SSS2.p3.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p3.2.m2.1b"><apply id="S3.SS9.SSS2.p3.2.m2.1.1.cmml" xref="S3.SS9.SSS2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p3.2.m2.1.1.1.cmml" xref="S3.SS9.SSS2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS9.SSS2.p3.2.m2.1.1.2.cmml" xref="S3.SS9.SSS2.p3.2.m2.1.1.2">𝑊</ci><ci id="S3.SS9.SSS2.p3.2.m2.1.1.3.cmml" xref="S3.SS9.SSS2.p3.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p3.2.m2.1c">W_{k}</annotation></semantics></math>, <math alttext="W_{v}" class="ltx_Math" display="inline" id="S3.SS9.SSS2.p3.3.m3.1"><semantics id="S3.SS9.SSS2.p3.3.m3.1a"><msub id="S3.SS9.SSS2.p3.3.m3.1.1" xref="S3.SS9.SSS2.p3.3.m3.1.1.cmml"><mi id="S3.SS9.SSS2.p3.3.m3.1.1.2" xref="S3.SS9.SSS2.p3.3.m3.1.1.2.cmml">W</mi><mi id="S3.SS9.SSS2.p3.3.m3.1.1.3" xref="S3.SS9.SSS2.p3.3.m3.1.1.3.cmml">v</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p3.3.m3.1b"><apply id="S3.SS9.SSS2.p3.3.m3.1.1.cmml" xref="S3.SS9.SSS2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p3.3.m3.1.1.1.cmml" xref="S3.SS9.SSS2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS9.SSS2.p3.3.m3.1.1.2.cmml" xref="S3.SS9.SSS2.p3.3.m3.1.1.2">𝑊</ci><ci id="S3.SS9.SSS2.p3.3.m3.1.1.3.cmml" xref="S3.SS9.SSS2.p3.3.m3.1.1.3">𝑣</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p3.3.m3.1c">W_{v}</annotation></semantics></math>, <math alttext="W_{o}" class="ltx_Math" display="inline" id="S3.SS9.SSS2.p3.4.m4.1"><semantics id="S3.SS9.SSS2.p3.4.m4.1a"><msub id="S3.SS9.SSS2.p3.4.m4.1.1" xref="S3.SS9.SSS2.p3.4.m4.1.1.cmml"><mi id="S3.SS9.SSS2.p3.4.m4.1.1.2" xref="S3.SS9.SSS2.p3.4.m4.1.1.2.cmml">W</mi><mi id="S3.SS9.SSS2.p3.4.m4.1.1.3" xref="S3.SS9.SSS2.p3.4.m4.1.1.3.cmml">o</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS9.SSS2.p3.4.m4.1b"><apply id="S3.SS9.SSS2.p3.4.m4.1.1.cmml" xref="S3.SS9.SSS2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS9.SSS2.p3.4.m4.1.1.1.cmml" xref="S3.SS9.SSS2.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS9.SSS2.p3.4.m4.1.1.2.cmml" xref="S3.SS9.SSS2.p3.4.m4.1.1.2">𝑊</ci><ci id="S3.SS9.SSS2.p3.4.m4.1.1.3.cmml" xref="S3.SS9.SSS2.p3.4.m4.1.1.3">𝑜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS9.SSS2.p3.4.m4.1c">W_{o}</annotation></semantics></math>)에는 네 개의 가중치 매트릭스가 있고, MLP 모듈에는 두 개의 가중치 매트릭스가 있다. LoRA는 대부분 다운스트림 태스크에 대해서만 어텐션 가중치를 적용하는 데 중점을 두고 있으며, MLP 모듈을 동결하기 때문에 단순성과 매개변수 효율성을 위해 다운스트림 태스크에서 훈련되지 않는다.</p>
</div>
</section>
<section id="S3.SS9.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS9.SSS3.5.1.1" class="ltx_text">III-I</span>3 </span><span id="S3.SS9.SSS3.6.2" class="ltx_text ltx_font_bold">Knowledge Distillation</span>
</h4>

<div id="S3.SS9.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS9.SSS3.p1.1">지식증류는 더 큰 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib143" title="">143</a>]</cite>로부터 학습하는 과정이다. 초기의 최고 성능의 모델 릴리즈는 이 접근법이 API 증류 접근법에 사용되더라도 매우 유용하다는 것을 입증했다. 단일 모델이 아니라 실제로 여러 모델의 지식을 더 작은 모델로 증류하는 접근법이라고도 한다. 이 접근법으로 더 작은 모델을 만들면 에지 장치에서도 사용할 수 있는 더 작은 모델 크기가 생성된다. 그림 <a class="ltx_ref" href="#S3.F35" title="Figure 35 ‣ III-I3 Knowledge Distillation ‣ III-I Cost-Effective Training/Inference/Adaptation/Compression ‣ III How LLMs Are Built ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">35</span></a>와 같은 지식 증류는 이 훈련 스킴의 일반적인 설정을 보여준다.</p>
</div>
<figure id="S3.F35" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/x5.jpg" id="S3.F35.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="230" height="102" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F35.2.1.1" style="font-size:90%;">Figure 35</span>:</span><span class="ltx_text" id="S3.F35.3.2" style="font-size:90%;">A generic knowledge distillation framework with student and teacher (Courtesy of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib144" title="">144</a>]</cite>). </span></figcaption>
</figure>
<div id="S3.SS9.SSS3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS9.SSS3.p2.1">지식은 반응 증류, 기능 증류 및 API 증류와 같은 다양한 형태의 학습에 의해 전달될 수 있다. 반응 증류는 교사 모델의 출력에만 관심을 가지며 학생 모델이 교사로서 (예측의 의미에서) 정확히 또는 적어도 유사하게 수행하는 방법을 가르치려고 한다. 특징 증류는 마지막 층뿐만 아니라 중간 층도 사용하여 학생 모델에 대한 더 나은 내부 표현을 생성한다. 이는 더 작은 모형이 교사 모형과 유사한 표상을 갖도록 돕는다.</p>
</div>
<div id="S3.SS9.SSS3.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS9.SSS3.p3.1">API 증류는 더 작은 모델을 훈련하기 위해 API(일반적으로 OpenAI와 같은 LLM 제공자의 API)를 사용하는 프로세스이다. LLM의 경우 반응 증류와 매우 유사한 더 큰 모델의 직접 출력에서 모델을 훈련하는 데 사용된다. 모델 자체를 공개적으로 사용할 수 없는 경우 최종 사용자에 대해 (일반적으로) 유료 API가 노출되기 때문에 이러한 유형의 증류에 의해 많은 우려가 제기됩니다. 반면에 사용자가 각 통화에 대해 비용을 지불하는 동안 예측을 사용하는 방법은 제한적입니다. 예를 들어 OpenAI는 나중에 경쟁하는 데 사용될 LLM을 생성하기 위해 API 사용을 금지합니다. 그러한 경우의 주요값은 훈련 데이터이다.</p>
</div>
</section>
<section id="S3.SS9.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS9.SSS4.5.1.1" class="ltx_text">III-I</span>4 </span><span id="S3.SS9.SSS4.6.2" class="ltx_text ltx_font_bold">Quantization</span>
</h4>

<div id="S3.SS9.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS9.SSS4.p1.1">심층 학습은 행렬에 적용되는 수학적 함수의 집합으로 모델 가중치에 대한 특정 정밀도를 갖는다. 가중치의 정밀도를 감소시키는 것은 모델의 크기를 감소시키고 또한 더 빠르게 하는 데 사용될 수 있다. 예로서, Int-8 동작들에 비해 Float-32 동작들은 더 느리다. 양자화라고 불리는 이 과정은 서로 다른 위상으로 적용될 수 있다. 모델 양자화를 위한 주요 접근법은 훈련 후 양자화 및 양자화 인식 훈련으로 분류될 수 있다. 훈련 후 양자화는 동적인 방법과 정적인 두 가지 잘 알려진 방법으로 양자화된 훈련된 모델에 관한 것이다. 동적 훈련 후 양자화는 런타임에서 양자화의 범위를 계산하며 정적 양자화에 비해 느리다. 양자화 인식 훈련은 훈련에 양자화 기준을 추가하고, 훈련 과정에서 양자화된 모델이 훈련되고 최적화된다. 이 접근법은 최종 모델이 좋은 성능을 가질 것이고 또한 트레이닝 후에 양자화될 필요가 없다는 것을 보장한다.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">How LLMs Are Used and Augmented</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p" id="S4.p1.1">LLM이 학습되면 다양한 작업에 원하는 출력을 생성하는 데 사용할 수 있습니다. LLM은 기본 프롬프트를 통해 직접 사용할 수 있습니다. 그러나 그들의 잠재력을 최대한 활용하거나 일부 단점을 해결하기 위해 우리는 몇 가지 외부 수단을 통해 모델을 보강해야 한다. 이 섹션에서는 먼저 환각 문제에 대해 더 자세히 살펴보고 LLM의 주요 결점에 대한 간략한 개요를 제공한다. 그런 다음 프롬프트 및 일부 증강 접근법이 이러한 한계를 해결할 뿐만 아니라 LLM을 외부 세계와 인터페이스할 수 있는 능력을 가진 완전한 AI 에이전트로 전환하는 LLM 기능을 증강하는 데 어떻게 사용될 수 있는지 설명한다.</p>
</div>
<figure id="S4.F36" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/x6.png" id="S4.F36.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="389" height="289" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F36.2.1.1" style="font-size:90%;">Figure 36</span>:</span><span class="ltx_text" id="S4.F36.3.2" style="font-size:90%;">How LLMs Are Used and Augmented. </span></figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">LLM limitations</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p1.1">LLM은 토큰을 예측하도록 훈련된다는 것을 기억하는 것이 중요하다. 미세 조정 및 정렬은 성능을 향상시키고 능력에 다른 차원을 추가하지만, 특히 순진하게 사용되는 경우 나타나는 몇 가지 중요한 한계가 있다. 그 중 일부는 다음을 포함한다:</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i1.p1.1">그들은 주/기억이 없다. LLM은 이전 프롬프트에서 보낸 내용조차 스스로 기억할 수 없습니다. 그것은 어떤 형태의 상태를 필요로 하는 많은 사용 사례에 대한 중요한 제한이다.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i2.p1.1">그것들은 확률적/확률적이다. LLM에 동일한 프롬프트를 여러 번 보내면 다른 응답을 받을 수 있습니다. 매개 변수, 특히 온도의 경우 반응의 변동성을 제한하지만 이는 문제를 생성할 수 있는 훈련의 고유한 특성입니다.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i3.p1.1">그들은 진부한 정보를 가지고 있고, 그들 스스로 외부 데이터에 접근할 수 없다. LLM은 자체적으로 현재 시간이나 요일에 대해서도 알지 못하며 훈련 세트에 없는 정보에 접근할 수 없다.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i4.p1.1">그것들은 일반적으로 매우 크다. 이것은 많은 비용이 많이 드는 GPU 기계가 훈련과 서비스를 위해 필요하다는 것을 의미합니다. 일부 경우에, 가장 큰 모델은 특히 대기 시간 측면에서 열악한 SLA를 갖는다.</p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i5.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i5.p1.1">환각이에요 LLM은 “진실”에 대한 개념이 없으며 일반적으로 좋은 내용과 나쁜 내용이 혼합된 교육을 받았다. 그들은 매우 그럴듯하지만 진실되지 않은 답을 내놓을 수 있다.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p3.1">이전 제한이 일부 응용 프로그램에서는 모두 중요해질 수 있지만 지난 몇 달 동안 많은 관심을 모았고 나중에 설명하는 많은 신속한 접근법과 LLM 확장 방법을 촉발시켰기 때문에 마지막 한계인 환각에 대해 조금 더 살펴볼 가치가 있다.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p4.1.1">Hallucination:</span> In the realm of Large Language Models (LLMs), the phenomenon of ”hallucinations” is got significant attention. 문헌에서 정의된 "자연어 생성의 환각 조사" 논문 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib145" title="">145</a>]</cite>에서 LLM에서의 환각은 "제공된 소스에 대해 무의미하거나 불성실한 콘텐츠 생성"으로 특징지어진다. 이 용어는 심리학적 통념에 뿌리를 두고 있지만 인공지능 분야에서 전유되어 왔다.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p5.1">LLM의 환각은 크게 두 가지 유형으로 분류될 수 있다.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<ol id="S4.I2" class="ltx_enumerate">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">Intrinsic Hallucinations</span>: These directly conflict with the source material, introducing factual inaccuracies or logical inconsistencies.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">Extrinsic Hallucinations</span>: 이러한 것들은 모순되지 않지만, 추론적이거나 확인 불가능한 요소를 포괄하여 소스에 대해 검증할 수 없다.</p>
</div>
</li>
</ol>
</div>
<div id="S4.SS1.p7" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p7.1">LLM 맥락에서 '소스'의 정의는 작업에 따라 다르다. 대화 기반 과제에서는 '세계 지식'을 지칭하는 반면, 텍스트 요약에서는 입력 텍스트 자체에 관한 것이다. 이러한 구분은 환각을 평가하고 해석하는 데 중요한 역할을 한다. 환각의 영향 또한 문맥 의존적이다. 예를 들어, 시 쓰기와 같은 창의적인 노력에서 환각은 허용되거나 심지어 유익한 것으로 간주될 수 있다.</p>
</div>
<div id="S4.SS1.p8" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p8.1">인터넷, 책, 위키피디아를 포함한 다양한 데이터 세트에서 훈련된 LLM은 진리나 거짓에 대한 본질적인 이해 없이 확률 모델을 기반으로 텍스트를 생성한다. 인간 피드백으로부터의 지시 튜닝 및 강화 학습(RLHF)과 같은 최근의 발전은 LLM을 보다 사실적인 출력으로 조종하려고 시도했지만 근본적인 확률적 특성과 그 고유한 한계는 남아 있다. 최근 연구 "추론 작업에 대한 대규모 언어 모델에 의한 환각의 출처" <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib146" title="">146</a>]</cite>는 LLM에서 환각에 기여하는 두 가지 핵심 측면을 강조하며, LLM 훈련 및 출력 생성에 내재된 복잡성을 강조한다.</p>
</div>
<div id="S4.SS1.p9" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p9.1">LLM에서 환각을 효과적으로 자동 측정하려면 통계 및 모델 기반 메트릭의 조합이 필요하다.</p>
</div>
<div id="S4.SS1.p10" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p10.1"><em class="ltx_emph ltx_font_italic" id="S4.SS1.p10.1.1">Statistical Metrics</em></p>
<ul id="S4.I3" class="ltx_itemize">
<li id="S4.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I3.i1.p1.1">ROUGE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib147" title="">147</a>]</cite> 및 BLEU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>와 같은 메트릭은 고유한 환각에 초점을 맞추어 텍스트 유사성을 평가하는 데 일반적이다.</p>
</div>
</li>
<li id="S4.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I3.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I3.i2.p1.1">구조화된 지식 소스가 사용 가능한 경우 PARENT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib149" title="">149</a>]</cite>, PARENT-T <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib150" title="">150</a>]</cite>, Knowledge F1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib151" title="">151</a>]</cite>와 같은 고급 메트릭이 활용된다. 이러한 메트릭은 효과적이지만 구문 및 의미 뉘앙스를 포착하는 데 한계가 있다.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS1.p11" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p11.1"><em class="ltx_emph ltx_font_italic" id="S4.SS1.p11.1.1">Model-Based Metrics</em></p>
<ul id="S4.I4" class="ltx_itemize">
<li id="S4.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I4.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I4.i1.p1.1.1">IE-Based Metrics</span>: Utilize Information Extraction models to simplify knowledge into relational tuples, then comparison these with the source.</p>
</div>
</li>
<li id="S4.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I4.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I4.i2.p1.1.1">QA-Based Metrics</span>: 질문-답변 프레임워크를 통해 생성된 콘텐츠와 소스 간의 중첩을 평가한다(<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib152" title="">152</a>]</cite> 참조).</p>
</div>
</li>
<li id="S4.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i3.p1" class="ltx_para">
<p class="ltx_p" id="S4.I4.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I4.i3.p1.1.1">NLI-Based Metrics</span>: Use Natural Language Inference datasets to evaluate the truthfulness of a generated hypothesis based on the given premise (see <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib153" title="">153</a>]</cite>).</p>
</div>
</li>
<li id="S4.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I4.i4.p1" class="ltx_para">
<p class="ltx_p" id="S4.I4.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I4.i4.p1.1.1">Faithfulness Classification Metrics</span>: Offer a refined assessment by creating task-specific datasets for a nuanced evaluation (see <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib154" title="">154</a>]</cite>).</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS1.p12" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p12.1">자동화된 메트릭의 발전에도 불구하고 인간의 판단은 여전히 중요한 부분이다. 일반적으로 두 가지 방법론이 포함됩니다.</p>
</div>
<div id="S4.SS1.p13" class="ltx_para">
<ol id="S4.I5" class="ltx_enumerate">
<li id="S4.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I5.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I5.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I5.i1.p1.1.1">Scoring</span>: Human evaluators rate the level of hallucination within a predefined scale.</p>
</div>
</li>
<li id="S4.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I5.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I5.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I5.i2.p1.1.1">Comparative Analysis</span>: Evaluators compared generated content against baseline or ground-truth references, adding essential layer of subjective assessment.</p>
</div>
</li>
</ol>
</div>
<div id="S4.SS1.p14" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p14.1">FactScore <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib155" title="">155</a>]</cite>는 인간 및 모델 기반 평가에 모두 사용할 수 있는 메트릭의 최근 예이다. 메트릭은 LLM 생성을 "원자적 사실"로 나눈다. 최종 점수는 각 원자 사실에 대한 정확도의 합으로 계산되어 각각에 동일한 가중치를 부여한다. 정확도는 원자적 사실이 원천에 의해 뒷받침되는지 여부를 단순히 나타내는 이진수이다. 저자들은 LLM을 사용하여 이 메트릭을 추정하는 다양한 자동화 전략을 구현한다.</p>
</div>
<div id="S4.SS1.p15" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p15.1">마지막으로 LLM에서 환각을 완화하는 것은 다양한 응용 프로그램에 맞는 맞춤형 전략이 필요한 다면적인 도전이다. 그것들은 다음을 포함한다:</p>
<ul id="S4.I6" class="ltx_itemize">
<li id="S4.I6.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I6.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I6.i1.p1.1">유스케이스 디자인, 입출력 구조화 또는 사용자 피드백을 위한 메커니즘 제공과 같은 제품 디자인 및 사용자 상호작용 전략.</p>
</div>
</li>
<li id="S4.I6.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I6.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I6.i2.p1.1">데이터 관리 및 지속적인 개선 추적 환각 세트를 유지하고 분석하는 것은 지속적인 모델 개선을 위해 필수적이다.</p>
</div>
</li>
<li id="S4.I6.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I6.i3.p1" class="ltx_para">
<p class="ltx_p" id="S4.I6.i3.p1.1">신속한 엔지니어링 및 메타프롬프트 디자인 검색 증강 생성과 같은 <a class="ltx_ref" href="#S4.SS2" title="IV-B Using LLMs: Prompt Design and Engineering ‣ IV How LLMs Are Used and Augmented ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-B</span></span></a>에 설명된 많은 고급 프롬프트 기술은 환각 위험을 직접 다룬다.</p>
</div>
</li>
<li id="S4.I6.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I6.i4.p1" class="ltx_para">
<p class="ltx_p" id="S4.I6.i4.p1.1">환각 완화를 위한 모델 선택 및 구성 엑셈플의 경우 온도 설정이 낮은 더 큰 모델이 일반적으로 더 나은 성능을 발휘합니다. 또한 RLHF 또는 도메인 중심 미세 조정과 같은 기술은 환각 위험을 완화할 수 있다.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Using LLMs: </span><span id="S4.SS2.7.3" class="ltx_text ltx_font_bold">Prompt Design and Engineering</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p1.1">생성 AI 모델의 프롬프트는 모델의 출력을 안내하기 위해 사용자가 제공하는 텍스트 입력이다. 이는 간단한 질문에서부터 상세한 설명 또는 특정 작업에 이르기까지 다양할 수 있다. 프롬프트는 일반적으로 명령어, 질문, 입력 데이터 및 예제로 구성된다. 실제로 AI 모델에서 원하는 응답을 이끌어내기 위해 프롬프트에는 지시사항이나 질문이 포함되어야 하며 다른 요소는 선택 사항이다. 고급 프롬프트는 모델이 해답에 도달하기 위해 논리적 추론 과정을 따르도록 안내되는 “사고 사슬” 프롬프트와 같은 더 복잡한 구조를 포함한다.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p2.1">신속한 공학은 LLM 및 기타 생성 AI 모델의 상호 작용 및 출력을 형성하는 빠르게 진화하는 학문이다. 신속한 공학의 본질은 생성적 모델로 특정 목표를 달성하기 위한 최적의 프롬프트를 만드는 데 있다. 이 과정은 모델을 지시하는 것뿐만 아니라 모델의 역량과 한계, 그리고 모델이 작동하는 맥락에 대한 일부 이해도 포함한다.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p3.1">프롬프트 엔지니어링은 프롬프트의 단순한 구성을 초월하며, 도메인 지식, AI 모델에 대한 이해 및 다양한 컨텍스트에 대한 프롬프트를 맞춤화하는 방법적 접근 방식의 혼합이 필요하다. 여기에는 지정된 데이터 세트 또는 컨텍스트를 기반으로 프로그래밍 방식으로 수정할 수 있는 템플릿 만들기가 포함될 수 있습니다. 예를 들어, 사용자 데이터에 기초하여 개인화된 응답을 생성하는 것은 관련 사용자 정보로 동적으로 채워지는 템플릿을 사용할 수 있다.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p4.1">또한, 신속한 엔지니어링은 모델 평가 또는 하이퍼파라미터 튜닝과 같은 전통적인 기계 학습 관행과 유사한 반복적이고 탐색적인 프로세스이다. 이 분야의 급속한 성장은 피처 또는 아키텍처 엔지니어링과 같은 전통적인 방법을 넘어 머신 러닝의 특정 측면에 혁명을 일으킬 가능성을 시사한다. 반면에 버전 제어 및 회귀 테스트와 같은 전통적인 엔지니어링 관행은 다른 기계 학습 접근법 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib156" title="">156</a>]</cite>에 적응한 것처럼 이 새로운 패러다임에 적응해야 한다.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p5.1">다음 단락에서 우리는 가장 흥미롭고 인기 있는 신속한 엔지니어링 접근법 중 일부를 자세히 설명한다.</p>
</div>
<section id="S4.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS1.5.1.1" class="ltx_text">IV-B</span>1 </span>Chain of Thought (CoT)</h4>

<div id="S4.SS2.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">구글 연구진의 "대형 언어 모델에서 추론하는 연쇄 사상(Chain-of-Thought Prompting Elicits Reasoning in Large Language Models)" <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib34" title="">34</a>]</cite>에 처음 기술된 CoT(Chain of Thought) 기법은 대형 언어 모델(LLM)을 위한 신속한 엔지니어링의 중추적인 발전을 나타낸다. 이 접근법은 LLM이 토큰 예측에 능숙하지만 명시적 추론을 위해 본질적으로 설계되지 않는다는 이해에 달려 있다. CoT는 필수 추론 단계를 통해 모델을 안내함으로써 이를 해결한다.</p>
</div>
<div id="S4.SS2.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS1.p2.1">CoT는 LLM의 암시적 추론 과정을 명시적으로 만드는 것을 기반으로 한다. 추론에 필요한 단계를 설명함으로써, 모델은 특히 단순한 정보 검색 또는 패턴 인식 이상의 것을 요구하는 시나리오에서 논리적이고 추론된 출력에 더 가깝게 지향된다.</p>
</div>
<div id="S4.SS2.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS1.p3.1">CoT 프롬프트 매니페스트는 두 가지 기본 형태로 나타난다:</p>
<ol id="S4.I7" class="ltx_enumerate">
<li id="S4.I7.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I7.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I7.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I7.i1.p1.1.1">Zero-Shot CoT:</span> 이 형태는 LLM에 “think step by step”을 지시할 것을 수반하고, 문제를 해체하고 추론의 각 단계를 분명하게 지시한다.</p>
</div>
</li>
<li id="S4.I7.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I7.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I7.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I7.i2.p1.1.1">Manual CoT:</span> 보다 복잡한 변형으로 모델에 대한 템플릿으로 단계별 추론 예제를 제공해야 합니다. 보다 효과적인 결과를 얻을 수 있지만 확장성과 유지 관리에 문제가 있습니다.</p>
</div>
</li>
</ol>
</div>
<div id="S4.SS2.SSS1.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS1.p4.1">수동형 CoT가 제로샷보다 더 효과적이다. 그러나 이 예제 기반 CoT의 효과는 다양한 예제의 선택에 달려 있으며, 손으로 단계적 추론의 그러한 예제로 프롬프트를 구성하는 것은 어렵고 오류가 발생하기 쉽다. 그곳에서 자동 CoT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib157" title="">157</a>]</cite>가 작동한다.</p>
</div>
</section>
<section id="S4.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS2.5.1.1" class="ltx_text">IV-B</span>2 </span>Tree of Thought (ToT)</h4>

<div id="S4.SS2.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p1.1">Tree of Thought (ToT) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib158" title="">158</a>]</cite> 프롬프트 기법은 가장 그럴듯한 방법으로 수렴하기 전에 다양한 대안적 해결책이나 사고 과정을 고려하는 개념에서 영감을 얻었다. ToT는 각 가지가 다른 추론 라인을 나타내는 여러 개의 “사상 트리”로 분기하는 아이디어를 기반으로 한다. 이 방법을 사용하면 LLM이 가장 가능성이 높은 시나리오를 결정하기 전에 여러 시나리오를 고려하는 인간의 인지 과정과 마찬가지로 다양한 가능성과 가설을 탐색할 수 있다.</p>
</div>
<div id="S4.SS2.SSS2.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p2.1">ToT의 중요한 측면은 이러한 추론 경로에 대한 평가이다. LLM은 다양한 사고의 분기를 생성하므로 각각은 질의에 대한 유효성 및 관련성에 대해 평가된다. 이 프로세스에는 분기의 실시간 분석 및 비교가 포함되어 가장 일관되고 논리적인 결과를 선택할 수 있다.</p>
</div>
<div id="S4.SS2.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS2.p3.1">ToT는 한 가지 추론으로 충분하지 않을 수 있는 복잡한 문제 해결 시나리오에서 특히 유용하다. 그것은 LLM이 결론에 도달하기 전에 다양한 가능성을 고려하여 보다 인간다운 문제 해결 접근법을 모방할 수 있게 한다. 이 기술은 모호성, 복잡성 및 미묘한 작업을 처리하는 모델의 능력을 향상시켜 고급 AI 응용 프로그램에서 유용한 도구가 된다.</p>
</div>
</section>
<section id="S4.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS3.5.1.1" class="ltx_text">IV-B</span>3 </span>Self-Consistency</h4>

<div id="S4.SS2.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS3.p1.1">Self-Consistency <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib159" title="">159</a>]</cite>는 앙상블 기반 방법을 활용하는데, 여기서 LLM은 동일한 쿼리에 대한 다수의 응답을 생성하도록 프롬프트된다. 이러한 응답 간의 일관성은 정확성과 신뢰성을 나타내는 지표 역할을 한다.</p>
</div>
<div id="S4.SS2.SSS3.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS3.p2.1">자기 일관성 접근법은 LLM이 동일한 프롬프트에 대해 유사한 여러 응답을 생성하면 응답이 정확할 가능성이 더 높다는 원칙에 근거한다. 이 방법은 일관성을 위해 응답을 분석할 때마다 LLM에 여러 번 쿼리를 처리하도록 요청하는 것을 포함한다. 이 기술은 사실적 정확도와 정밀도가 가장 중요한 시나리오에서 특히 유용하다.</p>
</div>
<div id="S4.SS2.SSS3.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS3.p3.1">반응의 일관성은 다양한 방법을 사용하여 측정할 수 있다. 한 가지 일반적인 접근법은 응답 내용의 중복을 분석하는 것이다. 다른 방법들은 응답들의 의미론적 유사성을 비교하는 것 또는 BERT-점수들 또는 n-그램 중첩들과 같은 보다 정교한 기법들을 채용하는 것을 포함할 수 있다. 이러한 측정은 LLM에 의해 생성된 응답 간의 일치 수준을 정량화하는 데 도움이 된다.</p>
</div>
<div id="S4.SS2.SSS3.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS3.p4.1">자기일관성은 정보의 진실성이 중요한 분야에서 중요한 응용을 가지고 있다. 특히 AI 모델에서 제공하는 정보의 정확성을 보장하는 것이 필수적인 팩트 체킹과 같은 시나리오와 관련이 있다. 이 기술을 사용하면 신속한 엔지니어가 LLM의 신뢰성을 향상시켜 높은 수준의 사실적 정확성을 요구하는 작업에 더 신뢰할 수 있다.</p>
</div>
</section>
<section id="S4.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS4.5.1.1" class="ltx_text">IV-B</span>4 </span>Reflection</h4>

<div id="S4.SS2.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS4.p1.1">반영 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib160" title="">160</a>]</cite>는 LLM이 응답의 정확성과 일관성에 대한 추론을 기반으로 자신의 출력을 평가하고 잠재적으로 수정하도록 촉구하는 것을 포함한다. 리플렉션의 개념은 LLM이 자기 평가의 한 형태에 참여할 수 있는 능력에 중점을 둔다. 초기 반응을 생성한 후, 모델은 사실적 정확성, 논리적 일관성 및 관련성과 같은 요소를 고려하여 자체 출력을 반영하도록 프롬프트된다. 이러한 내성적인 과정은 수정되거나 개선된 반응의 생성으로 이어질 수 있다.</p>
</div>
<div id="S4.SS2.SSS4.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS4.p2.1">반성의 핵심 측면은 LLM이 자체 편집을 할 수 있는 능력이다. 초기 반응을 평가함으로써 모델은 잠재적인 오류 또는 개선 영역을 식별할 수 있다. 이러한 생성, 반영 및 수정 반복 과정을 통해 LLM은 출력을 정제하여 응답의 전반적인 품질과 신뢰성을 향상시킬 수 있다.</p>
</div>
</section>
<section id="S4.SS2.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS5.5.1.1" class="ltx_text">IV-B</span>5 </span>Expert Prompting</h4>

<div id="S4.SS2.SSS5.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS5.p1.1">Expert Prompting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib161" title="">161</a>]</cite>는 다양한 분야의 전문가들의 응답을 시뮬레이션하여 LLM(Large Language Models)의 능력을 향상시킨다. 이 방법은 LLM이 전문가의 역할을 맡고 그에 따라 응답하도록 촉구하여 고품질의 정보에 입각한 답변을 제공하는 것을 포함한다. 전문가 프롬프밍 내의 핵심 전략은 다중 전문가 접근법이다. LLM은 여러 전문가 관점에서 응답을 고려하도록 촉구되며, 이를 종합하여 포괄적이고 균형 잡힌 답변을 형성한다. 이 기법은 반응의 깊이를 높일 뿐만 아니라 다양한 관점을 통합하여 주제에 대한 보다 총체적인 이해를 반영한다.</p>
</div>
</section>
<section id="S4.SS2.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS6.5.1.1" class="ltx_text">IV-B</span>6 </span>Chains</h4>

<div id="S4.SS2.SSS6.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS6.p1.1">체인은 LLM(Large Language Models)으로 복잡한 작업을 처리하기 위해 여러 컴포넌트를 시퀀스로 연결하는 방법을 의미한다. 이 접근법은 각각 최종 결과에 기여하는 일련의 상호 연결된 단계 또는 프로세스를 생성하는 것을 포함한다. 체인(Chains)의 개념은 서로 다른 스테이지 또는 컴포넌트가 순차적으로 배치되는 워크플로우(Workflow)를 구성하는 아이디어에 기초한다. 체인 내의 각 구성 요소는 특정 기능을 수행하며, 하나의 출력은 다음 입력을 위한 입력 역할을 한다. 이 종단간 배열은 각 단계가 작업의 특정 측면을 처리하도록 조정될 수 있기 때문에 보다 복잡하고 미묘한 처리를 허용한다. 체인은 요구 사항에 따라 복잡성과 구조가 달라질 수 있습니다. "PromptChainer: Chaining Large Language Model Prompts through Visual Programming" <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib162" title="">162</a>]</cite>에서 저자는 체인 디자인의 주요 과제를 설명할 뿐만 아니라 이러한 작업을 지원하는 시각적 도구를 설명한다.</p>
</div>
</section>
<section id="S4.SS2.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS7.5.1.1" class="ltx_text">IV-B</span>7 </span>Rails</h4>

<div id="S4.SS2.SSS7.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS7.p1.1">고급 프롬프트 엔지니어링의 레일은 미리 정의된 규칙 또는 템플릿을 통해 LLM(Large Language Models)의 출력을 안내하고 제어하는 방법을 의미한다. 이 접근법은 모델의 반응이 특정 표준 또는 기준을 준수하도록 설계되어 출력의 관련성, 안전성 및 정확도를 향상시킨다. 레일의 개념은 LLM이 응답을 생성하는 동안 따라야 하는 프레임워크 또는 일련의 지침을 설정하는 것을 포함한다. 이러한 지침은 일반적으로 자연 언어 문장이 구조화되고 전달되는 방식을 표준화하는 캐노니컬 폼으로 알려진 모델링 언어 또는 템플릿을 사용하여 정의된다.</p>
</div>
<div id="S4.SS2.SSS7.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS7.p2.1">레일은 애플리케이션의 특정 요구에 따라, 다양한 목적을 위해 설계될 수 있다:</p>
<ul id="S4.I8" class="ltx_itemize">
<li id="S4.I8.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I8.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I8.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I8.i1.p1.1.1">Topical Rails:</span> LLM이 특정 토픽 또는 도메인에 붙는지 확인합니다.</p>
</div>
</li>
<li id="S4.I8.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I8.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I8.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I8.i2.p1.1.1">Fact-Checking Rails:</span> Aimed at minimizing the generation of false or misleading information.</p>
</div>
</li>
<li id="S4.I8.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I8.i3.p1" class="ltx_para">
<p class="ltx_p" id="S4.I8.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I8.i3.p1.1.1">Jailbreaking Rails:</span> LLM이 자체 운영 제약 조건 또는 지침을 우회하려고 시도하는 응답을 생성하지 못하도록 방지합니다.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS2.SSS8" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS2.SSS8.5.1.1" class="ltx_text">IV-B</span>8 </span>Automatic Prompt Engineering (APE)</h4>

<div id="S4.SS2.SSS8.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS8.p1.1">APE(Automatic Prompt Engineering) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib163" title="">163</a>]</cite>는 LLM(Large Language Models)에 대한 프롬프트 생성 과정을 자동화하는 데 중점을 둔다. APE는 프롬프트를 생성하고 평가하기 위해 LLM 자체의 기능을 활용하여 프롬프트 설계 프로세스를 간소화하고 최적화하고자 한다. APE는 모델이 프롬프트를 생성, 점수화 및 정제하기 위해 사용되는 자체 참조 방식으로 LLM을 사용하는 것을 포함한다. LLM의 이러한 재귀적 사용은 원하는 응답 또는 결과를 이끌어낼 가능성이 더 높은 고품질 프롬프트를 생성할 수 있다.</p>
</div>
<div id="S4.SS2.SSS8.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS2.SSS8.p2.1">APE의 방법론은 몇 가지 주요 단계로 분해될 수 있다:</p>
<ul id="S4.I9" class="ltx_itemize">
<li id="S4.I9.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I9.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I9.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I9.i1.p1.1.1">Prompt Generation:</span> LLM은 주어진 작업 또는 목적에 기초하여 잠재적인 프롬프트의 범위를 생성한다.</p>
</div>
</li>
<li id="S4.I9.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I9.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I9.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I9.i2.p1.1.1">Prompt Scoring:</span> 생성된 각 프롬프트는 종종 원하는 응답을 이끌어내는 명확성, 특이성 및 가능성과 같은 기준을 사용하여 그 효과에 대해 평가됩니다.</p>
</div>
</li>
<li id="S4.I9.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I9.i3.p1" class="ltx_para">
<p class="ltx_p" id="S4.I9.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I9.i3.p1.1.1">Refinement and Iteration:</span> 이러한 평가에 기초하여 프롬프트는 정제되고 반복될 수 있으며, 이는 그들의 품질 및 유효성을 더욱 향상시킨다.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_bold">Augmenting LLMs through external knowledge - RAG</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS3.p1.1">사전 훈련된 LLM의 주요 한계 중 하나는 최신 지식이나 개인 또는 사용 사례별 정보에 대한 액세스가 부족하다는 것이다. 여기에서 검색 증강 생성(RAG)이 그림 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib164" title="">164</a>]</cite>로 들어옵니다. 그림 <a class="ltx_ref" href="#S4.F37" title="Figure 37 ‣ IV-C Augmenting LLMs through external knowledge - RAG ‣ IV How LLMs Are Used and Augmented ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">37</span></a>에 예시된 RAG는 입력 프롬프트로부터 쿼리를 추출하고 그 쿼리를 사용하여 외부 지식 소스로부터 관련 정보를 검색하는 것을 포함한다(예를 들어, 검색 엔진 또는 지식 그래프, 그림 <a class="ltx_ref" href="#S4.F38" title="Figure 38 ‣ IV-C Augmenting LLMs through external knowledge - RAG ‣ IV How LLMs Are Used and Augmented ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">38</span></a> 참조). 그런 다음 관련 정보가 원래 프롬프트에 추가되고 모델이 최종 응답을 생성하기 위해 LLM에 공급된다. RAG 시스템은 Retrieval, Generation, Augmentation <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib165" title="">165</a>]</cite>의 세 가지 중요한 구성요소를 포함한다.</p>
</div>
<figure id="S4.F37" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/rag.png" id="S4.F37.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="449" height="266" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F37.2.1.1" style="font-size:90%;">Figure 37</span>:</span><span class="ltx_text" id="S4.F37.3.2" style="font-size:90%;">An example of synthesizing RAG with LLMs for question answering application <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib166" title="">166</a>]</cite>. </span></figcaption>
</figure>
<figure id="S4.F38" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/rag_kg.png" id="S4.F38.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="500" height="230" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F38.2.1.1" style="font-size:90%;">Figure 38</span>:</span><span class="ltx_text" id="S4.F38.3.2" style="font-size:90%;">This is one example of synthesizing the KG as a retriever with LLMs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib167" title="">167</a>]</cite>. </span></figcaption>
</figure>
<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">RAG-aware prompting techniques</h5>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.1">고급 LLM 시스템을 구축하기 위한 RAG의 중요성 때문에 최근 몇 가지 RAG 인식 프롬프트 기술이 개발되었다. 이러한 기술 중 하나는 FLARE(Forward-looking Active Retrieval Augmented Generation)이다.</p>
</div>
<div id="S4.SS3.SSS0.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p2.1">FLARE(Forward-looking Active Retrieval Augmented Generation) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib168" title="">168</a>]</cite>는 예측과 정보 검색을 반복적으로 결합하여 LLM(Large Language Models)의 성능을 향상시킨다. FLARE는 LLM 응답의 정확성과 관련성을 개선하기 위한 검색 증강 생성 사용의 진화를 나타낸다.</p>
</div>
<div id="S4.SS3.SSS0.Px1.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p3.1">FLARE는 LLM이 다가오는 콘텐츠를 능동적으로 예측하고 이러한 예측을 관련 정보를 검색하기 위한 쿼리로 사용하는 반복 프로세스를 포함한다. 이 방법은 일반적으로 정보를 한 번 검색한 다음 생성을 진행하는 전통적인 검색 증강 모델과 대조된다. FLARE에서 이 프로세스는 동적이며 생성 단계 전반에 걸쳐 진행 중이다. FLARE에서는 LLM에 의해 생성된 각각의 문장 또는 세그먼트가 신뢰도에 대해 평가된다. 신뢰 수준이 특정 임계값 미만인 경우, 모델은 관련 정보를 검색하기 위한 쿼리로서 생성된 콘텐츠를 사용하고, 이는 이어서 문장을 재생성하거나 정제하는 데 사용된다. 이러한 반복 프로세스는 응답의 각 부분이 이용 가능한 가장 관련되고 현재 정보에 의해 통지되는 것을 보장한다.</p>
</div>
<div id="S4.SS3.SSS0.Px1.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p4.1">RAG 프레임워크 및 관련 작업에 대한 자세한 내용은 독자들에게 검색 증강 세대 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib165" title="">165</a>]</cite>에 대한 조사를 참조한다.</p>
</div>
</section>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS4.5.1.1" class="ltx_text">IV-D</span> </span><span id="S4.SS4.6.2" class="ltx_text ltx_font_bold">Using External Tools</span>
</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS4.p1.1">전술한 바와 같이 외부 지식 소스로부터 정보를 검색하는 것은 LLM을 증강시키는 잠재적인 방법 중 하나일 뿐이다. 보다 일반적으로 LLM은 기능을 보강하기 위해 다양한 외부 도구(예: 서비스에 대한 API)에 액세스할 수 있습니다. 그런 점에서 RAG는 소위 "도구"의 광범위한 범주의 특정 사례로 볼 수 있다.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS4.p2.1">이러한 맥락에서 도구는 LLM이 활용할 수 있는 외부 기능 또는 서비스이다. 이러한 도구는 기본 정보 검색에서 외부 데이터베이스 또는 API와의 복잡한 상호 작용까지 LLM이 수행할 수 있는 작업의 범위를 확장한다.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS4.p3.1">논문 “Toolformer: Language Models Can Teach Themuls to Use Tools” <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib169" title="">169</a>]</cite>에서 저자들은 LLM을 교육하여 언제 어떤 도구를 사용할지, API에 어떤 매개 변수가 필요한지 결정함으로써 단순한 도구 사용을 넘어섰다. 도구에는 두 개의 서로 다른 검색 엔진 또는 계산기가 포함됩니다. 다음 예제에서 LLM은 외부 Q&A 도구, 계산기 및 위키피디아 검색 엔진을 호출하기로 결정합니다. 최근 버클리의 연구자들은 구체적이지만 상당히 일반적인 도구인 API를 사용할 때 GPT-4를 능가하는 고릴라 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>라는 새로운 LLM을 훈련했습니다.</p>
</div>
<section id="S4.SS4.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Tool-aware prompting techniques</h5>

<div id="S4.SS4.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS4.SSS0.Px1.p1.1">RAG에서 설명한 것과 유사하게 도구 사용을 보다 확장 가능하게 하기 위해 여러 도구 인식 프롬프트 접근법이 개발되었다. 대표적인 기술로는 자동 다단계 추론 및 도구 사용(Automatic Multi-Step Reasoning and Tool-use, ART)이 있다.</p>
</div>
<div id="S4.SS4.SSS0.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS4.SSS0.Px1.p2.1">자동 다단계 추론 및 도구 사용(ART) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib170" title="">170</a>]</cite>는 자동화된 사고 프롬프트 체인과 외부 도구 사용을 결합한 프롬프트 엔지니어링 기술이다. ART는 여러 신속한 엔지니어링 전략의 융합을 나타내며, 외부 데이터 소스 또는 도구와의 추론 및 상호 작용을 모두 필요로 하는 복잡한 작업을 처리하는 LLM(Large Language Models)의 능력을 향상시킨다.</p>
</div>
<div id="S4.SS4.SSS0.Px1.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS4.SSS0.Px1.p3.1">ART는 태스크와 입력이 주어지면, 시스템이 먼저 태스크 라이브러리로부터 유사한 태스크들을 식별하는 체계적인 접근법을 포함한다. 그런 다음 이러한 작업을 프롬프트에서 예로 사용하여 현재 작업에 접근하고 실행하는 방법에 대해 LLM을 안내합니다. 이 방법은 작업이 내부 추론과 외부 데이터 처리 또는 검색의 조합을 필요로 할 때 특히 효과적이다.</p>
</div>
</section>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS5.5.1.1" class="ltx_text">IV-E</span> </span><span id="S4.SS5.6.2" class="ltx_text ltx_font_bold">LLM Agents</span>
</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS5.p1.1">AI 에이전트의 아이디어는 AI의 역사에서 잘 탐구되었습니다. 에이전트는 전형적으로 자신의 센서를 사용하여 환경을 지각하고, 현재 상태에 기초하여 판단을 내리고, 그에 따라 자신에게 이용 가능한 행동들에 기초하여 행동할 수 있는 자율 엔티티이다.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS5.p2.1">LLM의 맥락에서 에이전트는 특정 작업을 자율적으로 수행할 수 있는 (증강된) LL의 특수 인스턴스화에 기반한 시스템을 의미한다. 이들 에이전트는 입력 및 상호작용의 의도된 목표에 기초하여 결정을 내리기 위해 사용자 및 환경과 상호작용하도록 설계된다. 에이전트는 도구에 액세스하고 사용하고 주어진 입력에 따라 결정을 내릴 수 있는 기능을 갖춘 LLM을 기반으로 한다. 그들은 일반적으로 단순한 응답 생성을 넘어 어느 정도의 자율성과 의사 결정이 필요한 작업을 처리하도록 설계되었다.</p>
</div>
<div id="S4.SS5.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS5.p3.1">일반 LLM-기반 에이전트의 기능들은 다음을 포함한다:</p>
<ul id="S4.I10" class="ltx_itemize">
<li id="S4.I10.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I10.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I10.i1.p1.1">도구 액세스 및 활용: 에이전트는 외부 도구 및 서비스에 액세스하고 이러한 리소스를 효과적으로 활용하여 작업을 수행할 수 있습니다.</p>
</div>
</li>
<li id="S4.I10.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I10.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I10.i2.p1.1">의사 결정: 그들은 종종 복잡한 추론 프로세스를 사용하여 입력, 컨텍스트 및 그들이 사용할 수 있는 도구에 기초하여 의사 결정을 내릴 수 있다.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS5.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS5.p4.1">일 예로, 날씨 API와 같은 함수(또는 API)에 접근할 수 있는 LLM은 특정 장소의 날씨와 관련된 어떠한 질문에도 답할 수 있다. 즉, 문제를 해결하기 위해 API를 사용할 수 있다. 또한 LLM이 구매를 허용하는 API에 액세스할 수 있는 경우 구매 에이전트가 구축되어 외부 세계에서 정보를 읽을 수 있는 기능을 가질 뿐만 아니라 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib171" title="">171</a>]</cite>에 작용할 수 있습니다.</p>
</div>
<figure id="S4.F39" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/jarvis.png" id="S4.F39.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="445" height="197" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F39.2.1.1" style="font-size:90%;">Figure 39</span>:</span><span class="ltx_text" id="S4.F39.3.2" style="font-size:90%;">HuggingGPT: An agent-based approach to use tools and planning [image courtesy of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib171" title="">171</a>]</cite>]</span></figcaption>
</figure>
<div id="S4.SS5.p5" class="ltx_para">
<p class="ltx_p" id="S4.SS5.p5.1">도. <a class="ltx_ref" href="#S4.F40" title="Figure 40 ‣ IV-E LLM Agents ‣ IV How LLMs Are Used and Augmented ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">40</span></a>는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib36" title="">36</a>]</cite>를 찾는 대화 정보를 위한 LLM 기반 에이전트의 또 다른 예를 보여주며, 여기서 LLM은 대화 상태를 추적하는 <em class="ltx_emph ltx_font_italic" id="S4.SS5.p5.1.1">working memory</em>, 작업에 대한 실행 계획을 만들고 다음 시스템 액션을 선택하는 <em class="ltx_emph ltx_font_italic" id="S4.SS5.p5.1.2">policy</em>, 정책에 의해 선택된 액션을 수행하는 <em class="ltx_emph ltx_font_italic" id="S4.SS5.p5.1.3">action executor</em>(외부 지식으로부터 증거를 통합하거나 LLM을 프롬프트하여 응답을 생성함), 및 사용자 기대 또는 특정 비즈니스 요구 사항을 갖는 LLM 응답의 정렬에 액세스하고, 에이전트 성능을 향상시키기 위한 피드백을 생성하는 <em class="ltx_emph ltx_font_italic" id="S4.SS5.p5.1.4">utility</p>
</div>
<figure id="S4.F40" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/llm-augmenter.png" id="S4.F40.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="565" height="401" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F40.3.1.1" style="font-size:90%;">Figure 40</span>:</span><span class="ltx_text" id="S4.F40.4.2" style="font-size:90%;">A LLM-based agent for conversational information seeking. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib36" title="">36</a>]</cite>의 예절. </span></figcaption>
</figure>
<div id="S4.SS5.p6" class="ltx_para">
<p class="ltx_p" id="S4.SS5.p6.1">LLM 기반 AI 에이전트에 대한 자세한 내용은 최근 조사 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib172" title="">172</a>, <a class="ltx_ref" href="#bib.bib173" title="">173</a>, <a class="ltx_ref" href="#bib.bib174" title="">174</a>]</cite>를 참조하세요.</p>
</div>
<section id="S4.SS5.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Prompt engineering techniques for agents</h5>

<div id="S4.SS5.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS5.SSS0.Px1.p1.1">RAG 및 도구와 마찬가지로 LLM 기반 에이전트의 요구를 구체적으로 해결하는 신속한 엔지니어링 기술이 개발되었다. 이러한 세 가지 예는 관찰 없는 추론(ReWOO), 이유 및 행위(ReAct), 대화 가능 해결 에이전트(DERA)이다.</p>
</div>
<div id="S4.SS5.SSS0.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS5.SSS0.Px1.p2.1">관찰 없는 추론(ReWOO) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib175" title="">175</a>]</cite>는 직접적인 관찰로부터 추론을 분리하는 것을 목표로 한다. ReWOO는 LLM이 외부 데이터나 도구에 즉시 의존하지 않고 포괄적인 추론 계획이나 메타 계획을 수립할 수 있도록 함으로써 작동한다. 이 접근법은 에이전트가 필요한 데이터 또는 관찰이 이용가능하면 실행될 수 있는 추론을 위한 구조화된 프레임워크를 생성할 수 있게 한다. ReWOO에서 LLM은 처음에 주어진 문제에 접근하고 해결하는 방법을 설명하는 계획(일련의 단계)을 개발한다. 이 메타 계획 단계는 에이전트가 정보를 사용할 수 있게 되면 정보를 처리할 수 있는 단계를 설정하기 때문에 중요합니다. 그 다음 실행 단계는 실제 데이터 또는 관찰을 미리 지정된 계획에 통합하여 일관되고 맥락적으로 관련된 응답으로 이어지는 것을 포함한다. ReWOO는 토큰 효율성과 도구 실패에 대한 견고성 측면에서 상당한 이점을 제공한다. 이를 통해 LLM은 외부 데이터에 대한 즉각적인 액세스를 사용할 수 없는 작업을 처리할 수 있으며, 대신 잘 구조화된 추론 프레임워크에 의존할 수 있습니다. 이 방법은 데이터 검색이 비용이 많이 들거나 느리거나 불확실한 시나리오에서 특히 유리하여 LLM 기반 에이전트가 높은 수준의 성능 및 신뢰성을 유지할 수 있게 한다.</p>
</div>
<div id="S4.SS5.SSS0.Px1.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS5.SSS0.Px1.p3.1">이성과 행동(ReAct)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib176" title="">176</a>]</cite>는 LLM을 프롬프트하여 언어적 추론뿐만 아니라 행동 가능한 단계를 생성하여 모델의 동적 문제 해결 능력을 향상시킨다. ReAct는 추론과 행동을 통합하는 원리에 근거한다. 이 접근법에서, LLM은 인터리브 방식으로 추론 트레이스들(설명들)을 생성하는 것과 액션들(단계들 또는 명령들)을 취하는 것 사이에서 대체하도록 프롬프트된다. 이 접근법은 모델이 문제에 대해 동적으로 추론할 수 있게 하고, 동시에 구체적인 행동을 제안하고 취할 수 있게 한다.</p>
</div>
<div id="S4.SS5.SSS0.Px1.p4" class="ltx_para">
<p class="ltx_p" id="S4.SS5.SSS0.Px1.p4.1">Dialog-Enabled Resolving Agent (DERA) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib177" title="">177</a>]</cite>는 대화형 교환을 기반으로 대화, 쿼리 해결 및 의사 결정을 할 수 있는 전문 AI 에이전트입니다. DERA는 각각 특정 역할과 기능을 가진 대화 컨텍스트 내에서 여러 에이전트를 활용하는 아이디어를 기반으로 개발된다. 이러한 에이전트에는 정보를 수집하고 분석하는 연구자와 제공된 정보를 기반으로 최종 판단을 내리는 결정자가 포함될 수 있다. 이러한 역할 분담은 문제 해결과 의사 결정에 대한 체계적이고 효율적인 접근을 가능하게 한다. DERA는 의료 진단 또는 고객 서비스와 같이 복잡한 의사 결정 및 문제 해결을 필요로 하는 시나리오에서 특히 유리하다. DERA 에이전트의 협력적이고 상호 작용하는 특성으로 인해 단일 에이전트 시스템이 어려움을 겪을 수 있는 깊이 및 뉘앙스 수준의 복잡한 쿼리를 처리할 수 있다. 또한, 이 접근법은 인간의 의사 결정 프로세스와 잘 일치하여 AI 추론을 더 공감하고 신뢰할 수 있게 만든다.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Popular Datasets for LLMs</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p" id="S5.p1.1">대형 언어 모델은 유망한 성과를 보여주지만, 발생하는 주요 질문은 그들이 얼마나 효과적으로 기능하고 특정 작업이나 애플리케이션에서 성능을 평가할 수 있는지이다.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p class="ltx_p" id="S5.p2.1">LLM의 평가는 애플리케이션의 진화하는 풍경으로 인해 특정 문제를 제기한다. LLM 개발의 원래 목적은 번역, 요약, 질문 응답 등과 같은 NLP 작업의 성능을 향상시키는 것이었다. 그러나 오늘날 이러한 모델이 코드 생성 및 금융을 포함한 다양한 도메인에서 유용성을 찾고 있음이 분명하다. 더욱이 LLM의 평가는 공정성과 편견, 사실 확인, 추론과 같은 몇 가지 중요한 고려 사항을 포함한다. 이 섹션에서는 LLM을 평가하기 위해 일반적으로 사용되는 벤치마크를 설명한다. 이러한 벤치마크는 교육 또는 LLM 능력 평가에 따라 분류됩니다.</p>
</div>
<figure id="S5.F41" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/db_visu.png" id="S5.F41.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="492" height="492" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F41.3.1.1" style="font-size:90%;">Figure 41</span>:</span><span class="ltx_text" id="S5.F41.4.2" style="font-size:90%;">Dataset application. </span></figcaption>
</figure>
<figure id="S5.F42" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/img/dataset_hist_ver.png" id="S5.F42.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="450" height="409" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F42.3.1.1" style="font-size:90%;">Figure 42</span>:</span><span class="ltx_text" id="S5.F42.4.2" style="font-size:90%;">Datasets licensed under different licenses. </span></figcaption>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.5.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.6.2" class="ltx_text ltx_font_italic">Datasets for Basic Tasks: language modeling/understanding/generation</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.p1.1">이 섹션에서는 LLM의 기본 능력을 평가하는 데 적합한 벤치마크 및 데이터 세트에 대한 개요를 제공합니다.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S5.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i1.p1.1.1">Natural Questions</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib179" title="">179</a>]</cite>는 Google 검색 엔진에 질문으로 제출된 실제 익명화된 집계 쿼리로 구성된 QA 데이터 세트입니다. 주석자는 상위 <math alttext="5" class="ltx_Math" display="inline" id="S5.I1.i1.p1.1.m1.1"><semantics id="S5.I1.i1.p1.1.m1.1a"><mn id="S5.I1.i1.p1.1.m1.1.1" xref="S5.I1.i1.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.I1.i1.p1.1.m1.1b"><cn id="S5.I1.i1.p1.1.m1.1.1.cmml" type="integer" xref="S5.I1.i1.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i1.p1.1.m1.1c">5</annotation></semantics></math> 검색 결과에서 Wikipedia 페이지와 함께 질문을 제시하며, 페이지에 존재하는 경우 긴 답변(전형적으로 단락)과 짧은 답변(하나 이상의 엔티티)에 주석을 달거나, 긴/짧은 답변이 존재하지 않는 경우 null로 표시한다.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S5.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i2.p1.1.1">MMLU</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib180" title="">180</a>]</cite>는 zero-shot 시나리오와 few-shot 시나리오에서 얻은 지식을 평가하기 위한 것이다. 이는 MMLU가 모델의 일반적인 지식과 문제 해결 능력을 모두 평가한다는 것을 의미한다. STEM, 인문, 사회과학 및 기타 분야의 57개 과목을 다루고 있습니다. 벤치마크는 초등에서 고급 전문가에 이르기까지 복잡성이 다양하다. 이 데이터 세트의 주요 기여는 다중 작업 언어 이해, 질문 응답 및 산술 추론에 있다는 점을 언급할 가치가 있다.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S5.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i3.p1.1.1">MBPP</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib181" title="">181</a>]</cite>는 "Mostly Basic Python Problems"의 약자로 코드 생성을 위해 설계된 모델의 성능을 평가하기 위한 벤치마크를 제공한다. 벤치마크는 기본 프로그래밍 개념 및 표준 라이브러리 사용 등을 포함하여 광범위한 주제를 포함하는 <math alttext="974" class="ltx_Math" display="inline" id="S5.I1.i3.p1.1.m1.1"><semantics id="S5.I1.i3.p1.1.m1.1a"><mn id="S5.I1.i3.p1.1.m1.1.1" xref="S5.I1.i3.p1.1.m1.1.1.cmml">974</mn><annotation-xml encoding="MathML-Content" id="S5.I1.i3.p1.1.m1.1b"><cn id="S5.I1.i3.p1.1.m1.1.1.cmml" type="integer" xref="S5.I1.i3.p1.1.m1.1.1">974</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i3.p1.1.m1.1c">974</annotation></semantics></math> 짧은 Python 프로그램을 포함한다. 각 챌린지는 작업 설명, 코드 솔루션 및 3개의 자동화된 테스트 케이스로 구성됩니다.</p>
</div>
</li>
<li id="S5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="S5.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i4.p1.1.1">HumanEval</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib182" title="">182</a>]</cite>는 코드 생성 작업을 위한 데이터셋이다. 이 데이터 세트는 <math alttext="164" class="ltx_Math" display="inline" id="S5.I1.i4.p1.1.m1.1"><semantics id="S5.I1.i4.p1.1.m1.1a"><mn id="S5.I1.i4.p1.1.m1.1.1" xref="S5.I1.i4.p1.1.m1.1.1.cmml">164</mn><annotation-xml encoding="MathML-Content" id="S5.I1.i4.p1.1.m1.1b"><cn id="S5.I1.i4.p1.1.m1.1.1.cmml" type="integer" xref="S5.I1.i4.p1.1.m1.1.1">164</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i4.p1.1.m1.1c">164</annotation></semantics></math> 손으로 만든 프로그래밍 도전으로 구성된다. 각 챌린지에는 함수 서명, docstring, 코드 본문 및 여러 단위 테스트가 동반됩니다. 이 데이터 세트를 개발하는 주요 직관은 코드 생성 모델을 위한 훈련 데이터 세트에서 해당 콘텐츠의 배제를 보장하는 것이다.</p>
</div>
</li>
<li id="S5.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i5.p1" class="ltx_para">
<p class="ltx_p" id="S5.I1.i5.p1.3"><span class="ltx_text ltx_font_bold" id="S5.I1.i5.p1.3.1">APPS</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib183" title="">183</a>]</cite>는 Python 프로그래밍 언어에 초점을 맞춘 코드 생성 작업을 위해 설계되었습니다. APPS 데이터 세트는 <math alttext="232,444" class="ltx_Math" display="inline" id="S5.I1.i5.p1.1.m1.2"><semantics id="S5.I1.i5.p1.1.m1.2a"><mrow id="S5.I1.i5.p1.1.m1.2.3.2" xref="S5.I1.i5.p1.1.m1.2.3.1.cmml"><mn id="S5.I1.i5.p1.1.m1.1.1" xref="S5.I1.i5.p1.1.m1.1.1.cmml">232</mn><mo id="S5.I1.i5.p1.1.m1.2.3.2.1" xref="S5.I1.i5.p1.1.m1.2.3.1.cmml">,</mo><mn id="S5.I1.i5.p1.1.m1.2.2" xref="S5.I1.i5.p1.1.m1.2.2.cmml">444</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i5.p1.1.m1.2b"><list id="S5.I1.i5.p1.1.m1.2.3.1.cmml" xref="S5.I1.i5.p1.1.m1.2.3.2"><cn id="S5.I1.i5.p1.1.m1.1.1.cmml" type="integer" xref="S5.I1.i5.p1.1.m1.1.1">232</cn><cn id="S5.I1.i5.p1.1.m1.2.2.cmml" type="integer" xref="S5.I1.i5.p1.1.m1.2.2">444</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i5.p1.1.m1.2c">232,444</annotation></semantics></math> Python 프로그램의 컬렉션을 포함한다. 데이터 세트의 각 프로그램은 Python 코드의 평균 <math alttext="18" class="ltx_Math" display="inline" id="S5.I1.i5.p1.2.m2.1"><semantics id="S5.I1.i5.p1.2.m2.1a"><mn id="S5.I1.i5.p1.2.m2.1.1" xref="S5.I1.i5.p1.2.m2.1.1.cmml">18</mn><annotation-xml encoding="MathML-Content" id="S5.I1.i5.p1.2.m2.1b"><cn id="S5.I1.i5.p1.2.m2.1.1.cmml" type="integer" xref="S5.I1.i5.p1.2.m2.1.1">18</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i5.p1.2.m2.1c">18</annotation></semantics></math> 라인을 갖는다. 또한 APPS는 각각 텍스트 기반 문제 설명이 포함된 <math alttext="10,000" class="ltx_Math" display="inline" id="S5.I1.i5.p1.3.m3.2"><semantics id="S5.I1.i5.p1.3.m3.2a"><mrow id="S5.I1.i5.p1.3.m3.2.3.2" xref="S5.I1.i5.p1.3.m3.2.3.1.cmml"><mn id="S5.I1.i5.p1.3.m3.1.1" xref="S5.I1.i5.p1.3.m3.1.1.cmml">10</mn><mo id="S5.I1.i5.p1.3.m3.2.3.2.1" xref="S5.I1.i5.p1.3.m3.2.3.1.cmml">,</mo><mn id="S5.I1.i5.p1.3.m3.2.2" xref="S5.I1.i5.p1.3.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i5.p1.3.m3.2b"><list id="S5.I1.i5.p1.3.m3.2.3.1.cmml" xref="S5.I1.i5.p1.3.m3.2.3.2"><cn id="S5.I1.i5.p1.3.m3.1.1.cmml" type="integer" xref="S5.I1.i5.p1.3.m3.1.1">10</cn><cn id="S5.I1.i5.p1.3.m3.2.2.cmml" type="integer" xref="S5.I1.i5.p1.3.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i5.p1.3.m3.2c">10,000</annotation></semantics></math> 고유 프로그래밍 연습의 리포지토리에 대한 액세스를 제공합니다. 마지막으로 강조할 점은 테스트 케이스를 포함한다는 것입니다.</p>
</div>
</li>
<li id="S5.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i6.p1" class="ltx_para">
<p class="ltx_p" id="S5.I1.i6.p1.3"><span class="ltx_text ltx_font_bold" id="S5.I1.i6.p1.3.1">WikiSQL</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite> is crafted for code generation task and it has 87,726 carefully labeled pairs of SQL query and corresponding natural language questions from Wikipedia tables. SQL 쿼리는 테스트 세트(<math alttext="17,284" class="ltx_Math" display="inline" id="S5.I1.i6.p1.1.m1.2"><semantics id="S5.I1.i6.p1.1.m1.2a"><mrow id="S5.I1.i6.p1.1.m1.2.3.2" xref="S5.I1.i6.p1.1.m1.2.3.1.cmml"><mn id="S5.I1.i6.p1.1.m1.1.1" xref="S5.I1.i6.p1.1.m1.1.1.cmml">17</mn><mo id="S5.I1.i6.p1.1.m1.2.3.2.1" xref="S5.I1.i6.p1.1.m1.2.3.1.cmml">,</mo><mn id="S5.I1.i6.p1.1.m1.2.2" xref="S5.I1.i6.p1.1.m1.2.2.cmml">284</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i6.p1.1.m1.2b"><list id="S5.I1.i6.p1.1.m1.2.3.1.cmml" xref="S5.I1.i6.p1.1.m1.2.3.2"><cn id="S5.I1.i6.p1.1.m1.1.1.cmml" type="integer" xref="S5.I1.i6.p1.1.m1.1.1">17</cn><cn id="S5.I1.i6.p1.1.m1.2.2.cmml" type="integer" xref="S5.I1.i6.p1.1.m1.2.2">284</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i6.p1.1.m1.2c">17,284</annotation></semantics></math> examples), 개발(<math alttext="9,145" class="ltx_Math" display="inline" id="S5.I1.i6.p1.2.m2.2"><semantics id="S5.I1.i6.p1.2.m2.2a"><mrow id="S5.I1.i6.p1.2.m2.2.3.2" xref="S5.I1.i6.p1.2.m2.2.3.1.cmml"><mn id="S5.I1.i6.p1.2.m2.1.1" xref="S5.I1.i6.p1.2.m2.1.1.cmml">9</mn><mo id="S5.I1.i6.p1.2.m2.2.3.2.1" xref="S5.I1.i6.p1.2.m2.2.3.1.cmml">,</mo><mn id="S5.I1.i6.p1.2.m2.2.2" xref="S5.I1.i6.p1.2.m2.2.2.cmml">145</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i6.p1.2.m2.2b"><list id="S5.I1.i6.p1.2.m2.2.3.1.cmml" xref="S5.I1.i6.p1.2.m2.2.3.2"><cn id="S5.I1.i6.p1.2.m2.1.1.cmml" type="integer" xref="S5.I1.i6.p1.2.m2.1.1">9</cn><cn id="S5.I1.i6.p1.2.m2.2.2.cmml" type="integer" xref="S5.I1.i6.p1.2.m2.2.2">145</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i6.p1.2.m2.2c">9,145</annotation></semantics></math> examples) 및 훈련(<math alttext="61,297" class="ltx_Math" display="inline" id="S5.I1.i6.p1.3.m3.2"><semantics id="S5.I1.i6.p1.3.m3.2a"><mrow id="S5.I1.i6.p1.3.m3.2.3.2" xref="S5.I1.i6.p1.3.m3.2.3.1.cmml"><mn id="S5.I1.i6.p1.3.m3.1.1" xref="S5.I1.i6.p1.3.m3.1.1.cmml">61</mn><mo id="S5.I1.i6.p1.3.m3.2.3.2.1" xref="S5.I1.i6.p1.3.m3.2.3.1.cmml">,</mo><mn id="S5.I1.i6.p1.3.m3.2.2" xref="S5.I1.i6.p1.3.m3.2.2.cmml">297</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i6.p1.3.m3.2b"><list id="S5.I1.i6.p1.3.m3.2.3.1.cmml" xref="S5.I1.i6.p1.3.m3.2.3.2"><cn id="S5.I1.i6.p1.3.m3.1.1.cmml" type="integer" xref="S5.I1.i6.p1.3.m3.1.1">61</cn><cn id="S5.I1.i6.p1.3.m3.2.2.cmml" type="integer" xref="S5.I1.i6.p1.3.m3.2.2">297</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i6.p1.3.m3.2c">61,297</annotation></semantics></math> examples)의 세 가지 하위 집합으로 구성된다.</p>
</div>
</li>
<li id="S5.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i7.p1" class="ltx_para">
<p class="ltx_p" id="S5.I1.i7.p1.2"><span class="ltx_text ltx_font_bold" id="S5.I1.i7.p1.2.1">TriviaQA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib185" title="">185</a>]</cite>는 QA 작업을 위해 설계되었습니다. 이 데이터 세트는 <math alttext="650,000" class="ltx_Math" display="inline" id="S5.I1.i7.p1.1.m1.2"><semantics id="S5.I1.i7.p1.1.m1.2a"><mrow id="S5.I1.i7.p1.1.m1.2.3.2" xref="S5.I1.i7.p1.1.m1.2.3.1.cmml"><mn id="S5.I1.i7.p1.1.m1.1.1" xref="S5.I1.i7.p1.1.m1.1.1.cmml">650</mn><mo id="S5.I1.i7.p1.1.m1.2.3.2.1" xref="S5.I1.i7.p1.1.m1.2.3.1.cmml">,</mo><mn id="S5.I1.i7.p1.1.m1.2.2" xref="S5.I1.i7.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i7.p1.1.m1.2b"><list id="S5.I1.i7.p1.1.m1.2.3.1.cmml" xref="S5.I1.i7.p1.1.m1.2.3.2"><cn id="S5.I1.i7.p1.1.m1.1.1.cmml" type="integer" xref="S5.I1.i7.p1.1.m1.1.1">650</cn><cn id="S5.I1.i7.p1.1.m1.2.2.cmml" type="integer" xref="S5.I1.i7.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i7.p1.1.m1.2c">650,000</annotation></semantics></math> question-answer-evidence triples 이상을 포함한다. 이 데이터 세트에는 <math alttext="95,000" class="ltx_Math" display="inline" id="S5.I1.i7.p1.2.m2.2"><semantics id="S5.I1.i7.p1.2.m2.2a"><mrow id="S5.I1.i7.p1.2.m2.2.3.2" xref="S5.I1.i7.p1.2.m2.2.3.1.cmml"><mn id="S5.I1.i7.p1.2.m2.1.1" xref="S5.I1.i7.p1.2.m2.1.1.cmml">95</mn><mo id="S5.I1.i7.p1.2.m2.2.3.2.1" xref="S5.I1.i7.p1.2.m2.2.3.1.cmml">,</mo><mn id="S5.I1.i7.p1.2.m2.2.2" xref="S5.I1.i7.p1.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i7.p1.2.m2.2b"><list id="S5.I1.i7.p1.2.m2.2.3.1.cmml" xref="S5.I1.i7.p1.2.m2.2.3.2"><cn id="S5.I1.i7.p1.2.m2.1.1.cmml" type="integer" xref="S5.I1.i7.p1.2.m2.1.1">95</cn><cn id="S5.I1.i7.p1.2.m2.2.2.cmml" type="integer" xref="S5.I1.i7.p1.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i7.p1.2.m2.2c">95,000</annotation></semantics></math> 질문-응답 쌍이 있으며, 각각은 퀴즈 애호가들에 의해 작성되고 평균 6개의 독립적으로 출처된 증거 문서에 의해 지원된다. 이러한 문서는 위키피디아 또는 광범위한 웹 검색 결과에서 자동으로 획득됩니다. 데이터세트는 위키피디아와 웹 도메인의 정답을 포함하는 두 개의 세그먼트로 분류되며, 검증된 세트는 위키피디아와 온라인의 관련 문서와 함께 정확하게 답한 질문을 구현한다.</p>
</div>
</li>
<li id="S5.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i8.p1" class="ltx_para">
<p class="ltx_p" id="S5.I1.i8.p1.4"><span class="ltx_text ltx_font_bold" id="S5.I1.i8.p1.4.1">RACE</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib186" title="">186</a>]</cite> suits for reading comprehension task. 이 데이터 세트는 중학교와 고등학교의 중국 학생들이 완성한 영어 테스트, 나이 <math alttext="12" class="ltx_Math" display="inline" id="S5.I1.i8.p1.1.m1.1"><semantics id="S5.I1.i8.p1.1.m1.1a"><mn id="S5.I1.i8.p1.1.m1.1.1" xref="S5.I1.i8.p1.1.m1.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="S5.I1.i8.p1.1.m1.1b"><cn id="S5.I1.i8.p1.1.m1.1.1.cmml" type="integer" xref="S5.I1.i8.p1.1.m1.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i8.p1.1.m1.1c">12</annotation></semantics></math> ~ <math alttext="18" class="ltx_Math" display="inline" id="S5.I1.i8.p1.2.m2.1"><semantics id="S5.I1.i8.p1.2.m2.1a"><mn id="S5.I1.i8.p1.2.m2.1.1" xref="S5.I1.i8.p1.2.m2.1.1.cmml">18</mn><annotation-xml encoding="MathML-Content" id="S5.I1.i8.p1.2.m2.1b"><cn id="S5.I1.i8.p1.2.m2.1.1.cmml" type="integer" xref="S5.I1.i8.p1.2.m2.1.1">18</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i8.p1.2.m2.1c">18</annotation></semantics></math>를 기반으로 하며, 주로 영어 강사인 인간 전문가에 의해 엄격하게 준비된 대략 <math alttext="28,000" class="ltx_Math" display="inline" id="S5.I1.i8.p1.3.m3.2"><semantics id="S5.I1.i8.p1.3.m3.2a"><mrow id="S5.I1.i8.p1.3.m3.2.3.2" xref="S5.I1.i8.p1.3.m3.2.3.1.cmml"><mn id="S5.I1.i8.p1.3.m3.1.1" xref="S5.I1.i8.p1.3.m3.1.1.cmml">28</mn><mo id="S5.I1.i8.p1.3.m3.2.3.2.1" xref="S5.I1.i8.p1.3.m3.2.3.1.cmml">,</mo><mn id="S5.I1.i8.p1.3.m3.2.2" xref="S5.I1.i8.p1.3.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i8.p1.3.m3.2b"><list id="S5.I1.i8.p1.3.m3.2.3.1.cmml" xref="S5.I1.i8.p1.3.m3.2.3.2"><cn id="S5.I1.i8.p1.3.m3.1.1.cmml" type="integer" xref="S5.I1.i8.p1.3.m3.1.1">28</cn><cn id="S5.I1.i8.p1.3.m3.2.2.cmml" type="integer" xref="S5.I1.i8.p1.3.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i8.p1.3.m3.2c">28,000</annotation></semantics></math> 텍스트와 <math alttext="100,000" class="ltx_Math" display="inline" id="S5.I1.i8.p1.4.m4.2"><semantics id="S5.I1.i8.p1.4.m4.2a"><mrow id="S5.I1.i8.p1.4.m4.2.3.2" xref="S5.I1.i8.p1.4.m4.2.3.1.cmml"><mn id="S5.I1.i8.p1.4.m4.1.1" xref="S5.I1.i8.p1.4.m4.1.1.cmml">100</mn><mo id="S5.I1.i8.p1.4.m4.2.3.2.1" xref="S5.I1.i8.p1.4.m4.2.3.1.cmml">,</mo><mn id="S5.I1.i8.p1.4.m4.2.2" xref="S5.I1.i8.p1.4.m4.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i8.p1.4.m4.2b"><list id="S5.I1.i8.p1.4.m4.2.3.1.cmml" xref="S5.I1.i8.p1.4.m4.2.3.2"><cn id="S5.I1.i8.p1.4.m4.1.1.cmml" type="integer" xref="S5.I1.i8.p1.4.m4.1.1">100</cn><cn id="S5.I1.i8.p1.4.m4.2.2.cmml" type="integer" xref="S5.I1.i8.p1.4.m4.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i8.p1.4.m4.2c">100,000</annotation></semantics></math> 질문을 포함한다. 이 데이터 세트에는 학생들의 이해력과 추론 능력을 평가하기 위해 의도적으로 선택된 광범위한 과목이 포함되어 있다. 이 데이터 세트는 RACE-M, RACE-H 및 RACE의 세 하위 그룹에서 사용할 수 있습니다. RACE-M은 중학교 시험을 의미하는 반면, RACE-H는 고등학교 시험을 의미한다. 마지막으로, RACE는 RACE-M과 RACE-H의 합성이다.</p>
</div>
</li>
<li id="S5.I1.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i9.p1" class="ltx_para">
<p class="ltx_p" id="S5.I1.i9.p1.5"><span class="ltx_text ltx_font_bold" id="S5.I1.i9.p1.5.1">SQuAD</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib187" title="">187</a>]</cite>는 "Stanford Question Answering Dataset"의 약자로 Wikipedia articles 기반의 크라우드소싱 읽기 이해 데이터셋이다. 이는 대략 <math alttext="100,000" class="ltx_Math" display="inline" id="S5.I1.i9.p1.1.m1.2"><semantics id="S5.I1.i9.p1.1.m1.2a"><mrow id="S5.I1.i9.p1.1.m1.2.3.2" xref="S5.I1.i9.p1.1.m1.2.3.1.cmml"><mn id="S5.I1.i9.p1.1.m1.1.1" xref="S5.I1.i9.p1.1.m1.1.1.cmml">100</mn><mo id="S5.I1.i9.p1.1.m1.2.3.2.1" xref="S5.I1.i9.p1.1.m1.2.3.1.cmml">,</mo><mn id="S5.I1.i9.p1.1.m1.2.2" xref="S5.I1.i9.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i9.p1.1.m1.2b"><list id="S5.I1.i9.p1.1.m1.2.3.1.cmml" xref="S5.I1.i9.p1.1.m1.2.3.2"><cn id="S5.I1.i9.p1.1.m1.1.1.cmml" type="integer" xref="S5.I1.i9.p1.1.m1.1.1">100</cn><cn id="S5.I1.i9.p1.1.m1.2.2.cmml" type="integer" xref="S5.I1.i9.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i9.p1.1.m1.2c">100,000</annotation></semantics></math> question-answer pairs가 <math alttext="500" class="ltx_Math" display="inline" id="S5.I1.i9.p1.2.m2.1"><semantics id="S5.I1.i9.p1.2.m2.1a"><mn id="S5.I1.i9.p1.2.m2.1.1" xref="S5.I1.i9.p1.2.m2.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S5.I1.i9.p1.2.m2.1b"><cn id="S5.I1.i9.p1.2.m2.1.1.cmml" type="integer" xref="S5.I1.i9.p1.2.m2.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i9.p1.2.m2.1c">500</annotation></semantics></math> articles보다 더 많이 연결되어 있다. 이러한 질문들에 대한 답변들은 전형적으로 대응하는 판독 패시지들로부터 취해진 텍스트 단편들 또는 스팬들이다. 그 질문들은 어떤 경우에는 대답할 수 없을 수도 있다. 데이터세트는 <math alttext="80\%" class="ltx_Math" display="inline" id="S5.I1.i9.p1.3.m3.1"><semantics id="S5.I1.i9.p1.3.m3.1a"><mrow id="S5.I1.i9.p1.3.m3.1.1" xref="S5.I1.i9.p1.3.m3.1.1.cmml"><mn id="S5.I1.i9.p1.3.m3.1.1.2" xref="S5.I1.i9.p1.3.m3.1.1.2.cmml">80</mn><mo id="S5.I1.i9.p1.3.m3.1.1.1" xref="S5.I1.i9.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i9.p1.3.m3.1b"><apply id="S5.I1.i9.p1.3.m3.1.1.cmml" xref="S5.I1.i9.p1.3.m3.1.1"><csymbol cd="latexml" id="S5.I1.i9.p1.3.m3.1.1.1.cmml" xref="S5.I1.i9.p1.3.m3.1.1.1">percent</csymbol><cn id="S5.I1.i9.p1.3.m3.1.1.2.cmml" type="integer" xref="S5.I1.i9.p1.3.m3.1.1.2">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i9.p1.3.m3.1c">80\%</annotation></semantics></math> training set, <math alttext="10\%" class="ltx_Math" display="inline" id="S5.I1.i9.p1.4.m4.1"><semantics id="S5.I1.i9.p1.4.m4.1a"><mrow id="S5.I1.i9.p1.4.m4.1.1" xref="S5.I1.i9.p1.4.m4.1.1.cmml"><mn id="S5.I1.i9.p1.4.m4.1.1.2" xref="S5.I1.i9.p1.4.m4.1.1.2.cmml">10</mn><mo id="S5.I1.i9.p1.4.m4.1.1.1" xref="S5.I1.i9.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i9.p1.4.m4.1b"><apply id="S5.I1.i9.p1.4.m4.1.1.cmml" xref="S5.I1.i9.p1.4.m4.1.1"><csymbol cd="latexml" id="S5.I1.i9.p1.4.m4.1.1.1.cmml" xref="S5.I1.i9.p1.4.m4.1.1.1">percent</csymbol><cn id="S5.I1.i9.p1.4.m4.1.1.2.cmml" type="integer" xref="S5.I1.i9.p1.4.m4.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i9.p1.4.m4.1c">10\%</annotation></semantics></math> development set, <math alttext="10\%" class="ltx_Math" display="inline" id="S5.I1.i9.p1.5.m5.1"><semantics id="S5.I1.i9.p1.5.m5.1a"><mrow id="S5.I1.i9.p1.5.m5.1.1" xref="S5.I1.i9.p1.5.m5.1.1.cmml"><mn id="S5.I1.i9.p1.5.m5.1.1.2" xref="S5.I1.i9.p1.5.m5.1.1.2.cmml">10</mn><mo id="S5.I1.i9.p1.5.m5.1.1.1" xref="S5.I1.i9.p1.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i9.p1.5.m5.1b"><apply id="S5.I1.i9.p1.5.m5.1.1.cmml" xref="S5.I1.i9.p1.5.m5.1.1"><csymbol cd="latexml" id="S5.I1.i9.p1.5.m5.1.1.1.cmml" xref="S5.I1.i9.p1.5.m5.1.1.1">percent</csymbol><cn id="S5.I1.i9.p1.5.m5.1.1.2.cmml" type="integer" xref="S5.I1.i9.p1.5.m5.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i9.p1.5.m5.1c">10\%</annotation></semantics></math> hidden test set의 세 세 세트로 구분된다.</p>
</div>
</li>
<li id="S5.I1.i10" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i10.p1" class="ltx_para">
<p class="ltx_p" id="S5.I1.i10.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i10.p1.1.1">BoolQ</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib188" title="">188</a>]</cite>는 예/아니오 질문 응답 데이터 세트이며, 여기서 목표는 읽기 이해 작업입니다. BoolQ는 <math alttext="15,942" class="ltx_Math" display="inline" id="S5.I1.i10.p1.1.m1.2"><semantics id="S5.I1.i10.p1.1.m1.2a"><mrow id="S5.I1.i10.p1.1.m1.2.3.2" xref="S5.I1.i10.p1.1.m1.2.3.1.cmml"><mn id="S5.I1.i10.p1.1.m1.1.1" xref="S5.I1.i10.p1.1.m1.1.1.cmml">15</mn><mo id="S5.I1.i10.p1.1.m1.2.3.2.1" xref="S5.I1.i10.p1.1.m1.2.3.1.cmml">,</mo><mn id="S5.I1.i10.p1.1.m1.2.2" xref="S5.I1.i10.p1.1.m1.2.2.cmml">942</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i10.p1.1.m1.2b"><list id="S5.I1.i10.p1.1.m1.2.3.1.cmml" xref="S5.I1.i10.p1.1.m1.2.3.2"><cn id="S5.I1.i10.p1.1.m1.1.1.cmml" type="integer" xref="S5.I1.i10.p1.1.m1.1.1">15</cn><cn id="S5.I1.i10.p1.1.m1.2.2.cmml" type="integer" xref="S5.I1.i10.p1.1.m1.2.2">942</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i10.p1.1.m1.2c">15,942</annotation></semantics></math> 예시들을 포함한다. 각 예는 질문, 관련 단락 및 솔루션을 포함하는 트리플렛이다. 이 데이터 세트의 이면에 있는 주요 직관은 독해이지만 추론, 자연어 추론 및 질의 응답 작업에 사용할 수 있다.</p>
</div>
</li>
<li id="S5.I1.i11" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i11.p1" class="ltx_para">
<p class="ltx_p" id="S5.I1.i11.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I1.i11.p1.1.1">MultiRC</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib189" title="">189</a>]</cite>는 읽기 이해 작업에 맞는 또 다른 데이터 세트입니다. 멀티RC는 단락의 정보를 이용하여 답할 수 있는 다문장 질문뿐만 아니라 간략한 단락이 포함되어 있다. 이 데이터 세트의 단락은 뉴스, 소설, 역사 텍스트, 위키피디아 기사, 사회와 법에 대한 토론, 초등학교 과학 교과서 및 9/11 보고서를 포함한 다양한 출처에서 비롯된다. 각 질문에는 하나 이상의 정답이 있는 많은 응답 선택이 있습니다. 질문에 답하려면 여러 문장에 걸쳐 추론이 필요합니다. 다중RC 데이터 세트는 800개 이상의 단락에서 수집된 <math alttext="6,000" class="ltx_Math" display="inline" id="S5.I1.i11.p1.1.m1.2"><semantics id="S5.I1.i11.p1.1.m1.2a"><mrow id="S5.I1.i11.p1.1.m1.2.3.2" xref="S5.I1.i11.p1.1.m1.2.3.1.cmml"><mn id="S5.I1.i11.p1.1.m1.1.1" xref="S5.I1.i11.p1.1.m1.1.1.cmml">6</mn><mo id="S5.I1.i11.p1.1.m1.2.3.2.1" xref="S5.I1.i11.p1.1.m1.2.3.1.cmml">,</mo><mn id="S5.I1.i11.p1.1.m1.2.2" xref="S5.I1.i11.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I1.i11.p1.1.m1.2b"><list id="S5.I1.i11.p1.1.m1.2.3.1.cmml" xref="S5.I1.i11.p1.1.m1.2.3.2"><cn id="S5.I1.i11.p1.1.m1.1.1.cmml" type="integer" xref="S5.I1.i11.p1.1.m1.1.1">6</cn><cn id="S5.I1.i11.p1.1.m1.2.2.cmml" type="integer" xref="S5.I1.i11.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I1.i11.p1.1.m1.2c">6,000</annotation></semantics></math> 다중 문장 질문을 포함한다. 평균적으로, 각 질문은 총 5개 중 2개의 유효한 답변 대안을 제공한다.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.5.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.6.2" class="ltx_text ltx_font_italic">Datasets for Emergent: ICL, reasoning (CoT), instruction following</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS2.p1.1">이 섹션에서는 LLM의 새로운 능력을 평가하는 데 사용된 벤치마크 및 데이터 세트에 중점을 둔다.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<ul id="S5.I2" class="ltx_itemize">
<li id="S5.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i1.p1" class="ltx_para">
<p class="ltx_p" id="S5.I2.i1.p1.4"><span class="ltx_text ltx_font_bold" id="S5.I2.i1.p1.4.1">GSM8K</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib190" title="">190</a>]</cite>는 모델의 다단계 수학적 추론 능력을 평가하도록 설계되었다. GSM8K는 언어적으로 인간이 쓴 8.5K의 다양한 초등학교 수학 단어 문제를 포함한다. 데이터 세트는 <math alttext="7.5K" class="ltx_Math" display="inline" id="S5.I2.i1.p1.1.m1.1"><semantics id="S5.I2.i1.p1.1.m1.1a"><mrow id="S5.I2.i1.p1.1.m1.1.1" xref="S5.I2.i1.p1.1.m1.1.1.cmml"><mn id="S5.I2.i1.p1.1.m1.1.1.2" xref="S5.I2.i1.p1.1.m1.1.1.2.cmml">7.5</mn><mo id="S5.I2.i1.p1.1.m1.1.1.1" lspace="0em" rspace="0em" xref="S5.I2.i1.p1.1.m1.1.1.1.cmml">​</mo><mi id="S5.I2.i1.p1.1.m1.1.1.3" xref="S5.I2.i1.p1.1.m1.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.I2.i1.p1.1.m1.1b"><apply id="S5.I2.i1.p1.1.m1.1.1.cmml" xref="S5.I2.i1.p1.1.m1.1.1"><times id="S5.I2.i1.p1.1.m1.1.1.1.cmml" xref="S5.I2.i1.p1.1.m1.1.1.1"></times><cn id="S5.I2.i1.p1.1.m1.1.1.2.cmml" type="float" xref="S5.I2.i1.p1.1.m1.1.1.2">7.5</cn><ci id="S5.I2.i1.p1.1.m1.1.1.3.cmml" xref="S5.I2.i1.p1.1.m1.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.I2.i1.p1.1.m1.1c">7.5K</annotation></semantics></math> 문제가 있는 훈련 세트와 <math alttext="1" class="ltx_Math" display="inline" id="S5.I2.i1.p1.2.m2.1"><semantics id="S5.I2.i1.p1.2.m2.1a"><mn id="S5.I2.i1.p1.2.m2.1.1" xref="S5.I2.i1.p1.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.I2.i1.p1.2.m2.1b"><cn id="S5.I2.i1.p1.2.m2.1.1.cmml" type="integer" xref="S5.I2.i1.p1.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I2.i1.p1.2.m2.1c">1</annotation></semantics></math>K 문제가 있는 테스트 세트로 나뉜다. 이러한 문제들은 풀어야 할 <math alttext="2" class="ltx_Math" display="inline" id="S5.I2.i1.p1.3.m3.1"><semantics id="S5.I2.i1.p1.3.m3.1a"><mn id="S5.I2.i1.p1.3.m3.1.1" xref="S5.I2.i1.p1.3.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S5.I2.i1.p1.3.m3.1b"><cn id="S5.I2.i1.p1.3.m3.1.1.cmml" type="integer" xref="S5.I2.i1.p1.3.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I2.i1.p1.3.m3.1c">2</annotation></semantics></math> 내지 <math alttext="8" class="ltx_Math" display="inline" id="S5.I2.i1.p1.4.m4.1"><semantics id="S5.I2.i1.p1.4.m4.1a"><mn id="S5.I2.i1.p1.4.m4.1.1" xref="S5.I2.i1.p1.4.m4.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S5.I2.i1.p1.4.m4.1b"><cn id="S5.I2.i1.p1.4.m4.1.1.cmml" type="integer" xref="S5.I2.i1.p1.4.m4.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I2.i1.p1.4.m4.1c">8</annotation></semantics></math> 단계가 필요하다. 솔루션은 주로 기본 사칙연산을 이용한 일련의 기본 연산이다.</p>
</div>
</li>
<li id="S5.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i2.p1" class="ltx_para">
<p class="ltx_p" id="S5.I2.i2.p1.6"><span class="ltx_text ltx_font_bold" id="S5.I2.i2.p1.6.1">MATH</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib191" title="">191</a>]</cite> enables to assess how well models can solve math problems. MATH 데이터 세트는 고등학교 수학 경쟁에서 나온 <math alttext="12" class="ltx_Math" display="inline" id="S5.I2.i2.p1.1.m1.1"><semantics id="S5.I2.i2.p1.1.m1.1a"><mn id="S5.I2.i2.p1.1.m1.1.1" xref="S5.I2.i2.p1.1.m1.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="S5.I2.i2.p1.1.m1.1b"><cn id="S5.I2.i2.p1.1.m1.1.1.cmml" type="integer" xref="S5.I2.i2.p1.1.m1.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I2.i2.p1.1.m1.1c">12</annotation></semantics></math>, <math alttext="500" class="ltx_Math" display="inline" id="S5.I2.i2.p1.2.m2.1"><semantics id="S5.I2.i2.p1.2.m2.1a"><mn id="S5.I2.i2.p1.2.m2.1.1" xref="S5.I2.i2.p1.2.m2.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S5.I2.i2.p1.2.m2.1b"><cn id="S5.I2.i2.p1.2.m2.1.1.cmml" type="integer" xref="S5.I2.i2.p1.2.m2.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I2.i2.p1.2.m2.1c">500</annotation></semantics></math> 문제를 해결한다. 데이터 세트의 각 문제에는 단계별 솔루션과 최종 답변이 상자에 동봉되어 있습니다. 그 문제들은 광범위한 주제를 다루며 복잡성의 수준이 다르다. 총 7개의 과목이 있습니다. 또한, 각 문제의 난이도는 <math alttext="{}^{\prime}1^{\prime}" class="ltx_math_unparsed" display="inline" id="S5.I2.i2.p1.3.m3.1"><semantics id="S5.I2.i2.p1.3.m3.1a"><mmultiscripts id="S5.I2.i2.p1.3.m3.1.1"><mn id="S5.I2.i2.p1.3.m3.1.1.2.2">1</mn><mrow id="S5.I2.i2.p1.3.m3.1.1a"></mrow><mo id="S5.I2.i2.p1.3.m3.1.1.2.3">′</mo><mprescripts id="S5.I2.i2.p1.3.m3.1.1b"></mprescripts><mrow id="S5.I2.i2.p1.3.m3.1.1c"></mrow><mo id="S5.I2.i2.p1.3.m3.1.1.3">′</mo></mmultiscripts><annotation encoding="application/x-tex" id="S5.I2.i2.p1.3.m3.1b">{}^{\prime}1^{\prime}</annotation></semantics></math>부터 <math alttext="{}^{\prime}5^{\prime}" class="ltx_math_unparsed" display="inline" id="S5.I2.i2.p1.4.m4.1"><semantics id="S5.I2.i2.p1.4.m4.1a"><mmultiscripts id="S5.I2.i2.p1.4.m4.1.1"><mn id="S5.I2.i2.p1.4.m4.1.1.2.2">5</mn><mrow id="S5.I2.i2.p1.4.m4.1.1a"></mrow><mo id="S5.I2.i2.p1.4.m4.1.1.2.3">′</mo><mprescripts id="S5.I2.i2.p1.4.m4.1.1b"></mprescripts><mrow id="S5.I2.i2.p1.4.m4.1.1c"></mrow><mo id="S5.I2.i2.p1.4.m4.1.1.3">′</mo></mmultiscripts><annotation encoding="application/x-tex" id="S5.I2.i2.p1.4.m4.1b">{}^{\prime}5^{\prime}</annotation></semantics></math>까지의 척도로 AoPS 표준을 기준으로 등급을 매긴다. <math alttext="{}^{\prime}1^{\prime}" class="ltx_math_unparsed" display="inline" id="S5.I2.i2.p1.5.m5.1"><semantics id="S5.I2.i2.p1.5.m5.1a"><mmultiscripts id="S5.I2.i2.p1.5.m5.1.1"><mn id="S5.I2.i2.p1.5.m5.1.1.2.2">1</mn><mrow id="S5.I2.i2.p1.5.m5.1.1a"></mrow><mo id="S5.I2.i2.p1.5.m5.1.1.2.3">′</mo><mprescripts id="S5.I2.i2.p1.5.m5.1.1b"></mprescripts><mrow id="S5.I2.i2.p1.5.m5.1.1c"></mrow><mo id="S5.I2.i2.p1.5.m5.1.1.3">′</mo></mmultiscripts><annotation encoding="application/x-tex" id="S5.I2.i2.p1.5.m5.1b">{}^{\prime}1^{\prime}</annotation></semantics></math>는 과목에서 가장 쉬운 문제를 나타내고, <math alttext="{}^{\prime}5^{\prime}" class="ltx_math_unparsed" display="inline" id="S5.I2.i2.p1.6.m6.1"><semantics id="S5.I2.i2.p1.6.m6.1a"><mmultiscripts id="S5.I2.i2.p1.6.m6.1.1"><mn id="S5.I2.i2.p1.6.m6.1.1.2.2">5</mn><mrow id="S5.I2.i2.p1.6.m6.1.1a"></mrow><mo id="S5.I2.i2.p1.6.m6.1.1.2.3">′</mo><mprescripts id="S5.I2.i2.p1.6.m6.1.1b"></mprescripts><mrow id="S5.I2.i2.p1.6.m6.1.1c"></mrow><mo id="S5.I2.i2.p1.6.m6.1.1.3">′</mo></mmultiscripts><annotation encoding="application/x-tex" id="S5.I2.i2.p1.6.m6.1b">{}^{\prime}5^{\prime}</annotation></semantics></math>는 가장 어려운 문제를 나타낸다. 포맷팅 측면에서는 LATEX와 Asymptote 벡터 그래픽 언어를 사용하여 모든 문제와 해결책을 제시한다.</p>
</div>
</li>
<li id="S5.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i3.p1" class="ltx_para">
<p class="ltx_p" id="S5.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I2.i3.p1.1.1">HellaSwag</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib192" title="">192</a>]</cite> is designed to assess commonsense reasoning in LLMs. 이 벤치마크에는 <math alttext="70,000" class="ltx_Math" display="inline" id="S5.I2.i3.p1.1.m1.2"><semantics id="S5.I2.i3.p1.1.m1.2a"><mrow id="S5.I2.i3.p1.1.m1.2.3.2" xref="S5.I2.i3.p1.1.m1.2.3.1.cmml"><mn id="S5.I2.i3.p1.1.m1.1.1" xref="S5.I2.i3.p1.1.m1.1.1.cmml">70</mn><mo id="S5.I2.i3.p1.1.m1.2.3.2.1" xref="S5.I2.i3.p1.1.m1.2.3.1.cmml">,</mo><mn id="S5.I2.i3.p1.1.m1.2.2" xref="S5.I2.i3.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I2.i3.p1.1.m1.2b"><list id="S5.I2.i3.p1.1.m1.2.3.1.cmml" xref="S5.I2.i3.p1.1.m1.2.3.2"><cn id="S5.I2.i3.p1.1.m1.1.1.cmml" type="integer" xref="S5.I2.i3.p1.1.m1.1.1">70</cn><cn id="S5.I2.i3.p1.1.m1.2.2.cmml" type="integer" xref="S5.I2.i3.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I2.i3.p1.1.m1.2c">70,000</annotation></semantics></math> 객관식 문항이 포함된다. 각 질문은 ActivityNet 또는 WikiHow의 두 도메인 중 하나에서 파생되며 다음 상황에서 발생할 수 있는 문제에 대한 네 가지 답변 선택을 제시한다. 정답은 다가오는 사건을 설명하는 실제 진술을 제공하지만, 3개의 오답은 기계를 혼란스럽게 만들기 위해 만들어진다.</p>
</div>
</li>
<li id="S5.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i4.p1" class="ltx_para">
<p class="ltx_p" id="S5.I2.i4.p1.2"><span class="ltx_text ltx_font_bold" id="S5.I2.i4.p1.2.1">AI2 Reasoning Challenge (ARC)</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib193" title="">193</a>]</cite> is used for commonsense reasoning. 이 벤치마크는 <math alttext="7,787" class="ltx_Math" display="inline" id="S5.I2.i4.p1.1.m1.2"><semantics id="S5.I2.i4.p1.1.m1.2a"><mrow id="S5.I2.i4.p1.1.m1.2.3.2" xref="S5.I2.i4.p1.1.m1.2.3.1.cmml"><mn id="S5.I2.i4.p1.1.m1.1.1" xref="S5.I2.i4.p1.1.m1.1.1.cmml">7</mn><mo id="S5.I2.i4.p1.1.m1.2.3.2.1" xref="S5.I2.i4.p1.1.m1.2.3.1.cmml">,</mo><mn id="S5.I2.i4.p1.1.m1.2.2" xref="S5.I2.i4.p1.1.m1.2.2.cmml">787</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I2.i4.p1.1.m1.2b"><list id="S5.I2.i4.p1.1.m1.2.3.1.cmml" xref="S5.I2.i4.p1.1.m1.2.3.2"><cn id="S5.I2.i4.p1.1.m1.1.1.cmml" type="integer" xref="S5.I2.i4.p1.1.m1.1.1">7</cn><cn id="S5.I2.i4.p1.1.m1.2.2.cmml" type="integer" xref="S5.I2.i4.p1.1.m1.2.2">787</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I2.i4.p1.1.m1.2c">7,787</annotation></semantics></math> 과학 시험 문제를 포괄한다. 이러한 문항은 영어로 되어 있으며, 대부분 객관식 형식으로 설정되어 있다. 질문은 <math alttext="2,590" class="ltx_Math" display="inline" id="S5.I2.i4.p1.2.m2.2"><semantics id="S5.I2.i4.p1.2.m2.2a"><mrow id="S5.I2.i4.p1.2.m2.2.3.2" xref="S5.I2.i4.p1.2.m2.2.3.1.cmml"><mn id="S5.I2.i4.p1.2.m2.1.1" xref="S5.I2.i4.p1.2.m2.1.1.cmml">2</mn><mo id="S5.I2.i4.p1.2.m2.2.3.2.1" xref="S5.I2.i4.p1.2.m2.2.3.1.cmml">,</mo><mn id="S5.I2.i4.p1.2.m2.2.2" xref="S5.I2.i4.p1.2.m2.2.2.cmml">590</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I2.i4.p1.2.m2.2b"><list id="S5.I2.i4.p1.2.m2.2.3.1.cmml" xref="S5.I2.i4.p1.2.m2.2.3.2"><cn id="S5.I2.i4.p1.2.m2.1.1.cmml" type="integer" xref="S5.I2.i4.p1.2.m2.1.1">2</cn><cn id="S5.I2.i4.p1.2.m2.2.2.cmml" type="integer" xref="S5.I2.i4.p1.2.m2.2.2">590</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I2.i4.p1.2.m2.2c">2,590</annotation></semantics></math> 난이도 질문이 있는 챌린지 세트와 5,197개의 질문이 있는 이지 세트로 나누어졌다. 각 컬렉션은 열차, 개발 및 테스트 하위 집합으로 사전 분할되었습니다.</p>
</div>
</li>
<li id="S5.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i5.p1" class="ltx_para">
<p class="ltx_p" id="S5.I2.i5.p1.2"><span class="ltx_text ltx_font_bold" id="S5.I2.i5.p1.2.1">PIQA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib194" title="">194</a>]</cite> is intended to evaluate the language representations on their knowledge of physical commonsense. 이 데이터 세트에서는 흔하지 않은 솔루션을 선호하는 일상적인 상황에 초점을 맞춥니다. 중심 과제는 객관식 질문 응답이고, 여기서 질문 <math alttext="(q)" class="ltx_Math" display="inline" id="S5.I2.i5.p1.1.m1.1"><semantics id="S5.I2.i5.p1.1.m1.1a"><mrow id="S5.I2.i5.p1.1.m1.1.2.2"><mo id="S5.I2.i5.p1.1.m1.1.2.2.1" stretchy="false">(</mo><mi id="S5.I2.i5.p1.1.m1.1.1" xref="S5.I2.i5.p1.1.m1.1.1.cmml">q</mi><mo id="S5.I2.i5.p1.1.m1.1.2.2.2" stretchy="false">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.I2.i5.p1.1.m1.1b"><ci id="S5.I2.i5.p1.1.m1.1.1.cmml" xref="S5.I2.i5.p1.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.I2.i5.p1.1.m1.1c">(q)</annotation></semantics></math>는 두 개의 잠재적인 솔루션 <math alttext="(s1,s2)" class="ltx_Math" display="inline" id="S5.I2.i5.p1.2.m2.2"><semantics id="S5.I2.i5.p1.2.m2.2a"><mrow id="S5.I2.i5.p1.2.m2.2.2.2" xref="S5.I2.i5.p1.2.m2.2.2.3.cmml"><mo id="S5.I2.i5.p1.2.m2.2.2.2.3" stretchy="false" xref="S5.I2.i5.p1.2.m2.2.2.3.cmml">(</mo><mrow id="S5.I2.i5.p1.2.m2.1.1.1.1" xref="S5.I2.i5.p1.2.m2.1.1.1.1.cmml"><mi id="S5.I2.i5.p1.2.m2.1.1.1.1.2" xref="S5.I2.i5.p1.2.m2.1.1.1.1.2.cmml">s</mi><mo id="S5.I2.i5.p1.2.m2.1.1.1.1.1" lspace="0em" rspace="0em" xref="S5.I2.i5.p1.2.m2.1.1.1.1.1.cmml">​</mo><mn id="S5.I2.i5.p1.2.m2.1.1.1.1.3" xref="S5.I2.i5.p1.2.m2.1.1.1.1.3.cmml">1</mn></mrow><mo id="S5.I2.i5.p1.2.m2.2.2.2.4" xref="S5.I2.i5.p1.2.m2.2.2.3.cmml">,</mo><mrow id="S5.I2.i5.p1.2.m2.2.2.2.2" xref="S5.I2.i5.p1.2.m2.2.2.2.2.cmml"><mi id="S5.I2.i5.p1.2.m2.2.2.2.2.2" xref="S5.I2.i5.p1.2.m2.2.2.2.2.2.cmml">s</mi><mo id="S5.I2.i5.p1.2.m2.2.2.2.2.1" lspace="0em" rspace="0em" xref="S5.I2.i5.p1.2.m2.2.2.2.2.1.cmml">​</mo><mn id="S5.I2.i5.p1.2.m2.2.2.2.2.3" xref="S5.I2.i5.p1.2.m2.2.2.2.2.3.cmml">2</mn></mrow><mo id="S5.I2.i5.p1.2.m2.2.2.2.5" stretchy="false" xref="S5.I2.i5.p1.2.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.I2.i5.p1.2.m2.2b"><interval closure="open" id="S5.I2.i5.p1.2.m2.2.2.3.cmml" xref="S5.I2.i5.p1.2.m2.2.2.2"><apply id="S5.I2.i5.p1.2.m2.1.1.1.1.cmml" xref="S5.I2.i5.p1.2.m2.1.1.1.1"><times id="S5.I2.i5.p1.2.m2.1.1.1.1.1.cmml" xref="S5.I2.i5.p1.2.m2.1.1.1.1.1"></times><ci id="S5.I2.i5.p1.2.m2.1.1.1.1.2.cmml" xref="S5.I2.i5.p1.2.m2.1.1.1.1.2">𝑠</ci><cn id="S5.I2.i5.p1.2.m2.1.1.1.1.3.cmml" type="integer" xref="S5.I2.i5.p1.2.m2.1.1.1.1.3">1</cn></apply><apply id="S5.I2.i5.p1.2.m2.2.2.2.2.cmml" xref="S5.I2.i5.p1.2.m2.2.2.2.2"><times id="S5.I2.i5.p1.2.m2.2.2.2.2.1.cmml" xref="S5.I2.i5.p1.2.m2.2.2.2.2.1"></times><ci id="S5.I2.i5.p1.2.m2.2.2.2.2.2.cmml" xref="S5.I2.i5.p1.2.m2.2.2.2.2.2">𝑠</ci><cn id="S5.I2.i5.p1.2.m2.2.2.2.2.3.cmml" type="integer" xref="S5.I2.i5.p1.2.m2.2.2.2.2.3">2</cn></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.I2.i5.p1.2.m2.2c">(s1,s2)</annotation></semantics></math>와 함께 제공된다. 그런 다음 모델인지 인간인지에 따라 최상의 솔루션을 선택합니다. 각 질문에 대한 정답은 오직 하나의 해답일 뿐이다.</p>
</div>
</li>
<li id="S5.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i6.p1" class="ltx_para">
<p class="ltx_p" id="S5.I2.i6.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I2.i6.p1.1.1">SIQA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib195" title="">195</a>]</cite>는 소셜 상황에 대한 커먼센스 추론에 대한 모델의 능력을 평가하기 위한 프레임워크를 제공한다. SIQA 데이터 세트에는 일상적인 환경에서 감정 및 사회적 지능을 평가하기 위해 설계된 <math alttext="38,000" class="ltx_Math" display="inline" id="S5.I2.i6.p1.1.m1.2"><semantics id="S5.I2.i6.p1.1.m1.2a"><mrow id="S5.I2.i6.p1.1.m1.2.3.2" xref="S5.I2.i6.p1.1.m1.2.3.1.cmml"><mn id="S5.I2.i6.p1.1.m1.1.1" xref="S5.I2.i6.p1.1.m1.1.1.cmml">38</mn><mo id="S5.I2.i6.p1.1.m1.2.3.2.1" xref="S5.I2.i6.p1.1.m1.2.3.1.cmml">,</mo><mn id="S5.I2.i6.p1.1.m1.2.2" xref="S5.I2.i6.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I2.i6.p1.1.m1.2b"><list id="S5.I2.i6.p1.1.m1.2.3.1.cmml" xref="S5.I2.i6.p1.1.m1.2.3.2"><cn id="S5.I2.i6.p1.1.m1.1.1.cmml" type="integer" xref="S5.I2.i6.p1.1.m1.1.1">38</cn><cn id="S5.I2.i6.p1.1.m1.2.2.cmml" type="integer" xref="S5.I2.i6.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I2.i6.p1.1.m1.2c">38,000</annotation></semantics></math> 객관식 질문이 있다. 이 데이터 세트는 다양한 소셜 시나리오를 다룹니다. SIQA에서 잠재적인 답변은 적대적 과정을 통해 필터링된 인간이 선택한 응답과 기계가 생성한 응답의 혼합이다.</p>
</div>
</li>
<li id="S5.I2.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i7.p1" class="ltx_para">
<p class="ltx_p" id="S5.I2.i7.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I2.i7.p1.1.1">OpenBookQA(OBQA)</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib196" title="">196</a>]</cite>는 새로운 종류의 질문-답변 데이터세트로, 질문에 답하려면 책에 포함되어 있지 않은 추가적인 공통 및 상식 지식과 풍부한 텍스트 이해가 필요하다. 이 데이터 세트에는 약 6,000개의 객관식 질문이 포함되어 있습니다. 각 질문은 하나의 핵심 사실과 함께 <math alttext="6000" class="ltx_Math" display="inline" id="S5.I2.i7.p1.1.m1.1"><semantics id="S5.I2.i7.p1.1.m1.1a"><mn id="S5.I2.i7.p1.1.m1.1.1" xref="S5.I2.i7.p1.1.m1.1.1.cmml">6000</mn><annotation-xml encoding="MathML-Content" id="S5.I2.i7.p1.1.m1.1b"><cn id="S5.I2.i7.p1.1.m1.1.1.cmml" type="integer" xref="S5.I2.i7.p1.1.m1.1.1">6000</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I2.i7.p1.1.m1.1c">6000</annotation></semantics></math> 사실에 대한 추가 모음과 연결된다. 다단계 크라우드소싱과 전문가 필터링 절차를 사용하여 질문을 개발했다. OpenBookQA 문항은 배경이 제한된 멀티홉 추론이 필요하기 때문에 난이도가 높다.</p>
</div>
</li>
<li id="S5.I2.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i8.p1" class="ltx_para">
<p class="ltx_p" id="S5.I2.i8.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I2.i8.p1.1.1">TruthfulQA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib197" title="">197</a>]</cite>는 질문에 대한 답변을 생성함에 있어 언어 모델의 진실성을 평가하기 위해 특별히 설계되었다. 이 데이터 세트에는 건강, 법률, 금융 및 정치를 포함한 다양한 범주 <math alttext="38" class="ltx_Math" display="inline" id="S5.I2.i8.p1.1.m1.1"><semantics id="S5.I2.i8.p1.1.m1.1a"><mn id="S5.I2.i8.p1.1.m1.1.1" xref="S5.I2.i8.p1.1.m1.1.1.cmml">38</mn><annotation-xml encoding="MathML-Content" id="S5.I2.i8.p1.1.m1.1b"><cn id="S5.I2.i8.p1.1.m1.1.1.cmml" type="integer" xref="S5.I2.i8.p1.1.m1.1.1">38</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.I2.i8.p1.1.m1.1c">38</annotation></semantics></math>의 저자가 작성한 817개의 질문이 포함된다. 이러한 질문은 오답으로 이어지는 일반적인 오해를 포함할 수 있기 때문에 의도적으로 인간 응답자에게 도전하기 위해 고안되었다.</p>
</div>
</li>
<li id="S5.I2.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I2.i9.p1" class="ltx_para">
<p class="ltx_p" id="S5.I2.i9.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I2.i9.p1.1.1">OPT-IML Bench</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib103" title="">103</a>]</cite>는 Instruction Meta-Learning에 대한 포괄적인 벤치마크이다. 기존 8개의 벤치마크에서 2000개의 NLP 작업을 포함합니다. OPT-IML Bench는 17.9 M의 예제들을 가진 훈련 세트, 145K 샘플들을 가진 dev 세트, 321K 샘플들을 가진 테스트 세트로 구성된다.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS3.5.1.1" class="ltx_text">V-C</span> </span><span id="S5.SS3.6.2" class="ltx_text ltx_font_italic">Datasets for Augmented: using external knowledge/tools</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS3.p1.1">이 섹션에서는 LLM의 향상된 기능을 위해 설계된 데이터 세트에 중점을 둡니다.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<ul id="S5.I3" class="ltx_itemize">
<li id="S5.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I3.i1.p1" class="ltx_para">
<p class="ltx_p" id="S5.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i1.p1.1.1">HotpotQA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib198" title="">198</a>]</cite>는 멀티 홉 추론을 필요로 하는 다양하고 설명 가능한 질문 응답 데이터 세트를 커버하도록 설계되었다. 이 데이터 세트는 영어 위키피디아에서 파생됩니다. 대략 <math alttext="113,000" class="ltx_Math" display="inline" id="S5.I3.i1.p1.1.m1.2"><semantics id="S5.I3.i1.p1.1.m1.2a"><mrow id="S5.I3.i1.p1.1.m1.2.3.2" xref="S5.I3.i1.p1.1.m1.2.3.1.cmml"><mn id="S5.I3.i1.p1.1.m1.1.1" xref="S5.I3.i1.p1.1.m1.1.1.cmml">113</mn><mo id="S5.I3.i1.p1.1.m1.2.3.2.1" xref="S5.I3.i1.p1.1.m1.2.3.1.cmml">,</mo><mn id="S5.I3.i1.p1.1.m1.2.2" xref="S5.I3.i1.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.I3.i1.p1.1.m1.2b"><list id="S5.I3.i1.p1.1.m1.2.3.1.cmml" xref="S5.I3.i1.p1.1.m1.2.3.2"><cn id="S5.I3.i1.p1.1.m1.1.1.cmml" type="integer" xref="S5.I3.i1.p1.1.m1.1.1">113</cn><cn id="S5.I3.i1.p1.1.m1.2.2.cmml" type="integer" xref="S5.I3.i1.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S5.I3.i1.p1.1.m1.2c">113,000</annotation></semantics></math> 문항으로 구성되어 있다. 데이터 세트의 각 질문은 두 개의 위키피디아 기사에서 골드 단락이라고 하는 두 개의 단락과 함께 제공된다. 또한, 크라우드 워커가 질문에 답하는 데 중요한 것으로 선택한 문단에는 문장 목록이 있습니다.</p>
</div>
</li>
<li id="S5.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I3.i2.p1" class="ltx_para">
<p class="ltx_p" id="S5.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i2.p1.1.1">ToolQA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib199" title="">199</a>]</cite>는 질문 답변에 외부 도구를 사용하는 LLMs의 능력을 평가하기 위한 질문 답변 벤치마크이다.</p>
</div>
</li>
<li id="S5.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I3.i3.p1" class="ltx_para">
<p class="ltx_p" id="S5.I3.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.I3.i3.p1.1.1">GPT4Tools</span>은 시각적 콘텐츠 및 도구 설명에 조건화된 명령어와 함께 고급 교사(예: ChatGPT)에게 명령하여 생성된 교육 데이터 세트 역할을 합니다. 이러한 과정은 도구 사용과 관련된 명령어 생성으로 귀결된다. 이 데이터 세트에는 세 가지 버전이 있습니다. 첫 번째 버전은 GPT4Tools 모델을 미세 조정하는 데 사용되는 71,000개의 명령어 후속 데이터 포인트로 구성된다. 다음 버전은 검증에 사용되는 수동으로 세척된 명령 데이터로 구성되며, 첫 번째 버전의 도구와 관련된 명령을 포함합니다. 마지막 버전은 테스트에 사용되는 정리된 명령어 데이터이며 첫 번째 버전에는 없는 일부 도구와 관련된 명령어를 포함한다.</p>
</div>
</li>
</ul>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S5.T2.2.1.1" style="font-size:90%;">TABLE II</span>:</span><span class="ltx_text" id="S5.T2.3.2" style="font-size:90%;">LLM Datasets Overview. </span></figcaption>
<table id="S5.T2.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T2.4.1.1" class="ltx_tr">
<td id="S5.T2.4.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.1.1.1.1.1" class="ltx_p"><span id="S5.T2.4.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Benchmark Name</span></span>
</span>
</td>
<td id="S5.T2.4.1.1.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.1.1.2.1.1" class="ltx_p"><span id="S5.T2.4.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Evaluation Metric</span></span>
</span>
</td>
<td id="S5.T2.4.1.1.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.1.1.3.1.1" class="ltx_p"><span id="S5.T2.4.1.1.3.1.1.1" class="ltx_text ltx_font_bold">Leaderboard</span></span>
</span>
</td>
<td id="S5.T2.4.1.1.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.1.1.4.1.1" class="ltx_p"><span id="S5.T2.4.1.1.4.1.1.1" class="ltx_text ltx_font_bold">Source</span></span>
</span>
</td>
<td id="S5.T2.4.1.1.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.1.1.5.1.1" class="ltx_p"><span id="S5.T2.4.1.1.5.1.1.1" class="ltx_text ltx_font_bold">paperswithcode</span></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.2.2" class="ltx_tr">
<td id="S5.T2.4.2.2.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.2.2.1.1.1" class="ltx_p">HumanEval</span>
</span>
</td>
<td id="S5.T2.4.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.2.2.2.1.1" class="ltx_p">PASS@k</span>
</span>
</td>
<td id="S5.T2.4.2.2.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.2.2.3.1.1" class="ltx_p"><a target="_blank" href="https://llm-leaderboard.streamlit.app" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.2.2.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.2.2.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/openai/human-eval" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.2.2.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.2.2.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/code-generation-on-humaneval" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.3.3" class="ltx_tr">
<td id="S5.T2.4.3.3.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.3.3.1.1.1" class="ltx_p">MBPP</span>
</span>
</td>
<td id="S5.T2.4.3.3.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.3.3.2.1.1" class="ltx_p">PASS@k, Accuracy</span>
</span>
</td>
<td id="S5.T2.4.3.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.3.3.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.3.3.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.3.3.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/google-research/google-research/tree/master/mbpp" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.3.3.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.3.3.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/code-generation-on-mbpp" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.4.4" class="ltx_tr">
<td id="S5.T2.4.4.4.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.4.4.1.1.1" class="ltx_p">APPS</span>
</span>
</td>
<td id="S5.T2.4.4.4.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.4.4.2.1.1" class="ltx_p">PASS@k, Accuracy</span>
</span>
</td>
<td id="S5.T2.4.4.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.4.4.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.4.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.4.4.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/hendrycks/apps" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.4.4.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.4.4.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/code-generation-on-apps" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.5.5" class="ltx_tr">
<td id="S5.T2.4.5.5.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.5.5.1.1.1" class="ltx_p">WikiSQL</span>
</span>
</td>
<td id="S5.T2.4.5.5.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.5.5.2.1.1" class="ltx_p">Accuracy</span>
</span>
</td>
<td id="S5.T2.4.5.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.5.5.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.5.5.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.5.5.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/IBM/SQL-to-Text" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.5.5.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.5.5.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/code-generation-on-wikisql" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.6.6" class="ltx_tr">
<td id="S5.T2.4.6.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.6.6.1.1.1" class="ltx_p">CoNaLa</span>
</span>
</td>
<td id="S5.T2.4.6.6.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.6.6.2.1.1" class="ltx_p">BLEU</span>
</span>
</td>
<td id="S5.T2.4.6.6.3" class="ltx_td ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;"></td>
<td id="S5.T2.4.6.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.6.6.4.1.1" class="ltx_p"><a target="_blank" href="https://conala-corpus.github.io/" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.6.6.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.6.6.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/code-generation-on-conala" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.7.7" class="ltx_tr">
<td id="S5.T2.4.7.7.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.7.7.1.1.1" class="ltx_p">CodeParrot</span>
</span>
</td>
<td id="S5.T2.4.7.7.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.7.7.2.1.1" class="ltx_p">PASS@k</span>
</span>
</td>
<td id="S5.T2.4.7.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.7.7.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.7.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.7.7.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/huggingface/blog/blob/main/codeparrot.md" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.7.7.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.7.7.5.1.1" class="ltx_p">-</span>
</span>
</td>
</tr>
<tr id="S5.T2.4.8.8" class="ltx_tr">
<td id="S5.T2.4.8.8.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.8.8.1.1.1" class="ltx_p">HellaSwag</span>
</span>
</td>
<td id="S5.T2.4.8.8.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.8.8.2.1.1" class="ltx_p">Accuracy</span>
</span>
</td>
<td id="S5.T2.4.8.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.8.8.3.1.1" class="ltx_p"><a target="_blank" href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.8.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.8.8.4.1.1" class="ltx_p"><a target="_blank" href="https://rowanzellers.com/hellaswag" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.8.8.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.8.8.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/sentence-completion-on-hellaswag" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.9.9" class="ltx_tr">
<td id="S5.T2.4.9.9.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.9.9.1.1.1" class="ltx_p">AI2 Reasoning Challenge (ARC)</span>
</span>
</td>
<td id="S5.T2.4.9.9.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.9.9.2.1.1" class="ltx_p">Accuracy</span>
</span>
</td>
<td id="S5.T2.4.9.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.9.9.3.1.1" class="ltx_p"><a target="_blank" href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.9.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.9.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.9.9.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/fchollet/ARC/" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.9.9.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.9.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.9.9.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/common-sense-reasoning-on-arc-challenge" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.10.10" class="ltx_tr">
<td id="S5.T2.4.10.10.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.10.10.1.1.1" class="ltx_p">BoolQ</span>
</span>
</td>
<td id="S5.T2.4.10.10.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.10.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.10.10.2.1.1" class="ltx_p">Accuracy</span>
</span>
</td>
<td id="S5.T2.4.10.10.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.10.10.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.10.10.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.10.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.10.10.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/google-research-datasets/boolean-questions" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.10.10.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.10.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.10.10.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/question-answering-on-boolq" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.11.11" class="ltx_tr">
<td id="S5.T2.4.11.11.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.11.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.11.11.1.1.1" class="ltx_p">MultiRC</span>
</span>
</td>
<td id="S5.T2.4.11.11.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.11.11.2.1.1" class="ltx_p">F1-score, Accuracy</span>
</span>
</td>
<td id="S5.T2.4.11.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.11.11.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.11.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.11.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.11.11.4.1.1" class="ltx_p"><a target="_blank" href="https://cogcomp.seas.upenn.edu/multirc/" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.11.11.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.11.11.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/question-answering-on-multirc" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.12.12" class="ltx_tr">
<td id="S5.T2.4.12.12.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.12.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.12.12.1.1.1" class="ltx_p">CNN/Daily Mail <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib200" title="" class="ltx_ref">200</a>]</cite></span>
</span>
</td>
<td id="S5.T2.4.12.12.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.12.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.12.12.2.1.1" class="ltx_p">Accuracy</span>
</span>
</td>
<td id="S5.T2.4.12.12.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.12.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.12.12.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.12.12.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.12.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.12.12.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/danqi/rc-cnn-dailymail" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.12.12.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.12.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.12.12.5.1.1" class="ltx_p">-</span>
</span>
</td>
</tr>
<tr id="S5.T2.4.13.13" class="ltx_tr">
<td id="S5.T2.4.13.13.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.13.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.13.13.1.1.1" class="ltx_p">SQuAD</span>
</span>
</td>
<td id="S5.T2.4.13.13.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.13.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.13.13.2.1.1" class="ltx_p">F1-score, EM</span>
</span>
</td>
<td id="S5.T2.4.13.13.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.13.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.13.13.3.1.1" class="ltx_p"><a target="_blank" href="https://rajpurkar.github.io/SQuAD-explorer/" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.13.13.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.13.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.13.13.4.1.1" class="ltx_p"><a target="_blank" href="https://rajpurkar.github.io/SQuAD-explorer/" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.13.13.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.13.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.13.13.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/dataset/squad" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.14.14" class="ltx_tr">
<td id="S5.T2.4.14.14.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.14.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.14.14.1.1.1" class="ltx_p">RACE</span>
</span>
</td>
<td id="S5.T2.4.14.14.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.14.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.14.14.2.1.1" class="ltx_p">Accuracy</span>
</span>
</td>
<td id="S5.T2.4.14.14.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.14.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.14.14.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.14.14.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.14.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.14.14.4.1.1" class="ltx_p"><a target="_blank" href="https://www.cs.cmu.edu/~glai1/data/race/" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.14.14.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.14.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.14.14.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/reading-comprehension-on-race" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.15.15" class="ltx_tr">
<td id="S5.T2.4.15.15.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.15.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.15.15.1.1.1" class="ltx_p">CNN/Daily Mail <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib201" title="" class="ltx_ref">201</a>]</cite></span>
</span>
</td>
<td id="S5.T2.4.15.15.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.15.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.15.15.2.1.1" class="ltx_p">ROUGE</span>
</span>
</td>
<td id="S5.T2.4.15.15.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.15.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.15.15.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.15.15.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.15.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.15.15.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/abisee/cnn-dailymail" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.15.15.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.15.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.15.15.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/abstractive-text-summarization-on-cnn-daily" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.16.16" class="ltx_tr">
<td id="S5.T2.4.16.16.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.16.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.16.16.1.1.1" class="ltx_p">Drop</span>
</span>
</td>
<td id="S5.T2.4.16.16.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.16.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.16.16.2.1.1" class="ltx_p">F1-score, EM</span>
</span>
</td>
<td id="S5.T2.4.16.16.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.16.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.16.16.3.1.1" class="ltx_p"><a target="_blank" href="https://leaderboard.allenai.org/drop/submissions/public" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.16.16.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.16.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.16.16.4.1.1" class="ltx_p"><a target="_blank" href="https://allenai.org/data/drop" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.16.16.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.16.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.16.16.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/question-answering-on-drop-test" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.17.17" class="ltx_tr">
<td id="S5.T2.4.17.17.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.17.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.17.17.1.1.1" class="ltx_p">QuAC</span>
</span>
</td>
<td id="S5.T2.4.17.17.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.17.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.17.17.2.1.1" class="ltx_p">F1-score, HEQ-Q, HEQ-D</span>
</span>
</td>
<td id="S5.T2.4.17.17.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.17.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.17.17.3.1.1" class="ltx_p"><a target="_blank" href="https://quac.ai/" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.17.17.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.17.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.17.17.4.1.1" class="ltx_p"><a target="_blank" href="https://quac.ai/" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.17.17.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.17.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.17.17.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/question-answering-on-quac" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.18.18" class="ltx_tr">
<td id="S5.T2.4.18.18.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.18.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.18.18.1.1.1" class="ltx_p">TriviaQA</span>
</span>
</td>
<td id="S5.T2.4.18.18.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.18.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.18.18.2.1.1" class="ltx_p">EM, F1-score, Accuracy</span>
</span>
</td>
<td id="S5.T2.4.18.18.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.18.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.18.18.3.1.1" class="ltx_p"><a target="_blank" href="https://competitions.codalab.org/competitions/17208#results" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.18.18.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.18.18.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.18.18.4.1.1" class="ltx_p"><a target="_blank" href="https://nlp.cs.washington.edu/triviaqa/" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.18.18.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.18.18.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.18.18.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/question-answering-on-triviaqa" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.19.19" class="ltx_tr">
<td id="S5.T2.4.19.19.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.19.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.19.19.1.1.1" class="ltx_p">Natural Questions</span>
</span>
</td>
<td id="S5.T2.4.19.19.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.19.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.19.19.2.1.1" class="ltx_p">EM, F1-score, Accuracy</span>
</span>
</td>
<td id="S5.T2.4.19.19.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.19.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.19.19.3.1.1" class="ltx_p"><a target="_blank" href="https://ai.google.com/research/NaturalQuestions" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.19.19.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.19.19.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.19.19.4.1.1" class="ltx_p"><a target="_blank" href="https://ai.google.com/research/NaturalQuestions" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.19.19.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.19.19.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.19.19.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/question-answering-on-natural-questions" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.20.20" class="ltx_tr">
<td id="S5.T2.4.20.20.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.20.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.20.20.1.1.1" class="ltx_p">StrategyQA</span>
</span>
</td>
<td id="S5.T2.4.20.20.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.20.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.20.20.2.1.1" class="ltx_p">Accuracy, Recall@10, SARI</span>
</span>
</td>
<td id="S5.T2.4.20.20.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.20.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.20.20.3.1.1" class="ltx_p"><a target="_blank" href="https://leaderboard.allenai.org/strategyqa/submissions/public" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.20.20.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.20.20.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.20.20.4.1.1" class="ltx_p"><a target="_blank" href="https://allenai.org/data/strategyqa" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.20.20.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.20.20.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.20.20.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/question-answering-on-strategyqa" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.21.21" class="ltx_tr">
<td id="S5.T2.4.21.21.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.21.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.21.21.1.1.1" class="ltx_p">CoQA</span>
</span>
</td>
<td id="S5.T2.4.21.21.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.21.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.21.21.2.1.1" class="ltx_p">F1-score</span>
</span>
</td>
<td id="S5.T2.4.21.21.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.21.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.21.21.3.1.1" class="ltx_p"><a target="_blank" href="https://stanfordnlp.github.io/coqa/" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.21.21.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.21.21.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.21.21.4.1.1" class="ltx_p"><a target="_blank" href="https://stanfordnlp.github.io/coqa/" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.21.21.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.21.21.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.21.21.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/dataset/coqa" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.22.22" class="ltx_tr">
<td id="S5.T2.4.22.22.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.22.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.22.22.1.1.1" class="ltx_p">XSum</span>
</span>
</td>
<td id="S5.T2.4.22.22.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.22.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.22.22.2.1.1" class="ltx_p">ROUGE</span>
</span>
</td>
<td id="S5.T2.4.22.22.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.22.22.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.22.22.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.22.22.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.22.22.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.22.22.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/EdinburghNLP/XSum" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.22.22.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.22.22.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.22.22.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/text-summarization-on-x-sum" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.23.23" class="ltx_tr">
<td id="S5.T2.4.23.23.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.23.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.23.23.1.1.1" class="ltx_p">SAMSum</span>
</span>
</td>
<td id="S5.T2.4.23.23.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.23.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.23.23.2.1.1" class="ltx_p">ROUGE</span>
</span>
</td>
<td id="S5.T2.4.23.23.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.23.23.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.23.23.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.23.23.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.23.23.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.23.23.4.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.23.23.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.23.23.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.23.23.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/dataset/samsum-corpus" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.24.24" class="ltx_tr">
<td id="S5.T2.4.24.24.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.24.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.24.24.1.1.1" class="ltx_p">WikiSum</span>
</span>
</td>
<td id="S5.T2.4.24.24.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.24.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.24.24.2.1.1" class="ltx_p">ROUGE</span>
</span>
</td>
<td id="S5.T2.4.24.24.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.24.24.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.24.24.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.24.24.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.24.24.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.24.24.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/tensorflow/tensor2tensor/tree/master/tensor2tensor/data_generators/wikisum" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.24.24.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.24.24.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.24.24.5.1.1" class="ltx_p">-</span>
</span>
</td>
</tr>
<tr id="S5.T2.4.25.25" class="ltx_tr">
<td id="S5.T2.4.25.25.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.25.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.25.25.1.1.1" class="ltx_p">DialogSum</span>
</span>
</td>
<td id="S5.T2.4.25.25.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.25.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.25.25.2.1.1" class="ltx_p">ROUGE</span>
</span>
</td>
<td id="S5.T2.4.25.25.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.25.25.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.25.25.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.25.25.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.25.25.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.25.25.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/cylnlp/dialogsum" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.25.25.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.25.25.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.25.25.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/dataset/dialogsum" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.26.26" class="ltx_tr">
<td id="S5.T2.4.26.26.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.26.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.26.26.1.1.1" class="ltx_p">TruthfulQA</span>
</span>
</td>
<td id="S5.T2.4.26.26.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.26.26.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.26.26.2.1.1" class="ltx_p">MC1 , MC2, % true, % info, BLEURT</span>
</span>
</td>
<td id="S5.T2.4.26.26.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.26.26.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.26.26.3.1.1" class="ltx_p"><a target="_blank" href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.26.26.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.26.26.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.26.26.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/sylinrl/TruthfulQA" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.26.26.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.26.26.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.26.26.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/question-answering-on-truthfulqa" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.27.27" class="ltx_tr">
<td id="S5.T2.4.27.27.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.27.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.27.27.1.1.1" class="ltx_p">MMLU</span>
</span>
</td>
<td id="S5.T2.4.27.27.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.27.27.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.27.27.2.1.1" class="ltx_p">Accuracy</span>
</span>
</td>
<td id="S5.T2.4.27.27.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.27.27.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.27.27.3.1.1" class="ltx_p"><a target="_blank" href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.27.27.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.27.27.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.27.27.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/hendrycks/test" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.27.27.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.27.27.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.27.27.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/dataset/mmlu" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.28.28" class="ltx_tr">
<td id="S5.T2.4.28.28.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.28.28.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.28.28.1.1.1" class="ltx_p">GSM8K</span>
</span>
</td>
<td id="S5.T2.4.28.28.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.28.28.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.28.28.2.1.1" class="ltx_p">Accuracy</span>
</span>
</td>
<td id="S5.T2.4.28.28.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.28.28.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.28.28.3.1.1" class="ltx_p"><a target="_blank" href="https://opencompass.org.cn/dataset-detail/GSM8K" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.28.28.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.28.28.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.28.28.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/openai/grade-school-math" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.28.28.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.28.28.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.28.28.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/arithmetic-reasoning-on-gsm8k" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.29.29" class="ltx_tr">
<td id="S5.T2.4.29.29.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.29.29.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.29.29.1.1.1" class="ltx_p">PIQA</span>
</span>
</td>
<td id="S5.T2.4.29.29.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.29.29.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.29.29.2.1.1" class="ltx_p">Accuracy</span>
</span>
</td>
<td id="S5.T2.4.29.29.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.29.29.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.29.29.3.1.1" class="ltx_p"><a target="_blank" href="https://leaderboard.allenai.org/physicaliqa/submissions/public" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.29.29.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.29.29.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.29.29.4.1.1" class="ltx_p"><a target="_blank" href="https://leaderboard.allenai.org/physicaliqa/submissions/about" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.29.29.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.29.29.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.29.29.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/question-answering-on-piqa" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.30.30" class="ltx_tr">
<td id="S5.T2.4.30.30.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.30.30.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.30.30.1.1.1" class="ltx_p">SIQA</span>
</span>
</td>
<td id="S5.T2.4.30.30.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.30.30.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.30.30.2.1.1" class="ltx_p">Accuracy</span>
</span>
</td>
<td id="S5.T2.4.30.30.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.30.30.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.30.30.3.1.1" class="ltx_p"><a target="_blank" href="https://leaderboard.allenai.org/socialiqa/submissions/public" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.30.30.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.30.30.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.30.30.4.1.1" class="ltx_p"><a target="_blank" href="https://leaderboard.allenai.org/socialiqa/submissions/about" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.30.30.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.30.30.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.30.30.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/question-answering-on-social-iqa" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.31.31" class="ltx_tr">
<td id="S5.T2.4.31.31.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.31.31.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.31.31.1.1.1" class="ltx_p">OpenBookQA (OBQA)</span>
</span>
</td>
<td id="S5.T2.4.31.31.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.31.31.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.31.31.2.1.1" class="ltx_p">Accuracy</span>
</span>
</td>
<td id="S5.T2.4.31.31.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.31.31.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.31.31.3.1.1" class="ltx_p"><a target="_blank" href="https://leaderboard.allenai.org/open_book_qa/submissions/public" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.31.31.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.31.31.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.31.31.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/allenai/OpenBookQA" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.31.31.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.31.31.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.31.31.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/question-answering-on-openbookqa" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.32.32" class="ltx_tr">
<td id="S5.T2.4.32.32.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.32.32.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.32.32.1.1.1" class="ltx_p">HotpotQA</span>
</span>
</td>
<td id="S5.T2.4.32.32.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.32.32.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.32.32.2.1.1" class="ltx_p">EM, F1-score, Joint EM, Joint F1-score,</span>
</span>
</td>
<td id="S5.T2.4.32.32.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.32.32.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.32.32.3.1.1" class="ltx_p"><a target="_blank" href="https://hotpotqa.github.io/" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.32.32.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.32.32.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.32.32.4.1.1" class="ltx_p"><a target="_blank" href="https://hotpotqa.github.io/" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.32.32.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.32.32.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.32.32.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/question-answering-on-hotpotqa" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.33.33" class="ltx_tr">
<td id="S5.T2.4.33.33.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.33.33.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.33.33.1.1.1" class="ltx_p">MATH</span>
</span>
</td>
<td id="S5.T2.4.33.33.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.33.33.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.33.33.2.1.1" class="ltx_p">Accuracy</span>
</span>
</td>
<td id="S5.T2.4.33.33.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.33.33.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.33.33.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.33.33.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.33.33.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.33.33.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/hendrycks/math" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.33.33.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.33.33.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.33.33.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/math-word-problem-solving-on-math" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.34.34" class="ltx_tr">
<td id="S5.T2.4.34.34.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.34.34.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.34.34.1.1.1" class="ltx_p">CommonsenseQA</span>
</span>
</td>
<td id="S5.T2.4.34.34.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.34.34.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.34.34.2.1.1" class="ltx_p">Accuracy</span>
</span>
</td>
<td id="S5.T2.4.34.34.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.34.34.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.34.34.3.1.1" class="ltx_p"><a target="_blank" href="https://www.tau-nlp.sites.tau.ac.il/csqa-leaderboard2" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.34.34.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.34.34.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.34.34.4.1.1" class="ltx_p"><a target="_blank" href="https://www.tau-nlp.sites.tau.ac.il/commonsenseqa" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.34.34.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.34.34.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.34.34.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/sota/common-sense-reasoning-on-commonsenseqa" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.35.35" class="ltx_tr">
<td id="S5.T2.4.35.35.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.35.35.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.35.35.1.1.1" class="ltx_p">Natural Instructions</span>
</span>
</td>
<td id="S5.T2.4.35.35.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.35.35.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.35.35.2.1.1" class="ltx_p">ROUGE-L, Human</span>
</span>
</td>
<td id="S5.T2.4.35.35.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.35.35.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.35.35.3.1.1" class="ltx_p"><a target="_blank" href="https://leaderboard.allenai.org/natural-instructions/submissions/public" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.35.35.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.35.35.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.35.35.4.1.1" class="ltx_p"><a target="_blank" href="https://instructions.apps.allenai.org/" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.35.35.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.35.35.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.35.35.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/dataset/natural-instructions" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.36.36" class="ltx_tr">
<td id="S5.T2.4.36.36.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.36.36.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.36.36.1.1.1" class="ltx_p">BIG-bench</span>
</span>
</td>
<td id="S5.T2.4.36.36.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.36.36.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.36.36.2.1.1" class="ltx_p">Accuracy, Average</span>
</span>
</td>
<td id="S5.T2.4.36.36.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.36.36.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.36.36.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.36.36.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.36.36.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.36.36.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/google/BIG-bench" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.36.36.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.36.36.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.36.36.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/dataset/big-bench" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.37.37" class="ltx_tr">
<td id="S5.T2.4.37.37.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.37.37.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.37.37.1.1.1" class="ltx_p">ToolTalk</span>
</span>
</td>
<td id="S5.T2.4.37.37.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.37.37.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.37.37.2.1.1" class="ltx_p">Success rate, Precision, Recall, Incorrect action rate, Percent of failing error types</span>
</span>
</td>
<td id="S5.T2.4.37.37.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.37.37.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.37.37.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.37.37.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.37.37.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.37.37.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/microsoft/ToolTalk" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.37.37.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.37.37.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.37.37.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/paper/tooltlk-evaluating-tool-usage-in-a" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.38.38" class="ltx_tr">
<td id="S5.T2.4.38.38.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.38.38.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.38.38.1.1.1" class="ltx_p">MetaTool</span>
</span>
</td>
<td id="S5.T2.4.38.38.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.38.38.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.38.38.2.1.1" class="ltx_p">Accuracy, Precision, Recall, F1-score</span>
</span>
</td>
<td id="S5.T2.4.38.38.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.38.38.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.38.38.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.38.38.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.38.38.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.38.38.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/HowieHwong/MetaTool?tab=readme-ov-file" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.38.38.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.38.38.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.38.38.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/paper/metatool-benchmark-deciding-whether-to-use" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.39.39" class="ltx_tr">
<td id="S5.T2.4.39.39.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.39.39.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.39.39.1.1.1" class="ltx_p">GPT4Tools</span>
</span>
</td>
<td id="S5.T2.4.39.39.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.39.39.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.39.39.2.1.1" class="ltx_p">Successful Rate of Thought, Successful Rate of Action, Successful Rate of Arguments, Success Rate</span>
</span>
</td>
<td id="S5.T2.4.39.39.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.39.39.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.39.39.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.39.39.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.39.39.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.39.39.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/AILab-CVC/GPT4Tools" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.39.39.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.39.39.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.39.39.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/paper/gpt4tools-teaching-large-language-model-to" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.40.40" class="ltx_tr">
<td id="S5.T2.4.40.40.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.40.40.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.40.40.1.1.1" class="ltx_p">API-Bank</span>
</span>
</td>
<td id="S5.T2.4.40.40.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.40.40.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.40.40.2.1.1" class="ltx_p">Correctness, ROUGE, Error(API Hallucination, Has Exception, Invalid Input Parameters, False API Call Format, API Call, Miss Input Parameters)</span>
</span>
</td>
<td id="S5.T2.4.40.40.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.40.40.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.40.40.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.40.40.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.40.40.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.40.40.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/api-bank" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.40.40.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.40.40.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.40.40.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/paper/api-bank-a-benchmark-for-tool-augmented-llms" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
<tr id="S5.T2.4.41.41" class="ltx_tr">
<td id="S5.T2.4.41.41.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="width:71.1pt;">
<span id="S5.T2.4.41.41.1.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.41.41.1.1.1" class="ltx_p">Alpaca-CoT</span>
</span>
</td>
<td id="S5.T2.4.41.41.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S5.T2.4.41.41.2.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.41.41.2.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.41.41.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.41.41.3.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.41.41.3.1.1" class="ltx_p">-</span>
</span>
</td>
<td id="S5.T2.4.41.41.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.41.41.4.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.41.41.4.1.1" class="ltx_p"><a target="_blank" href="https://github.com/PhoebusSi/alpaca-CoT" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
<td id="S5.T2.4.41.41.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:56.9pt;">
<span id="S5.T2.4.41.41.5.1" class="ltx_inline-block ltx_align_top">
<span id="S5.T2.4.41.41.5.1.1" class="ltx_p"><a target="_blank" href="https://paperswithcode.com/paper/an-empirical-study-of-instruction-tuning" title="" class="ltx_ref ltx_href">Link</a></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Prominent LLMs’ Performance on Benchmarks</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p" id="S6.p1.1">이 섹션에서는 먼저 다양한 시나리오에서 LLM의 성능을 평가하는 데 사용되는 몇 가지 인기 있는 메트릭에 대한 개요를 제공한다. 그런 다음 인기 있는 데이터 세트와 벤치마크 중 일부에서 두드러진 대형 언어 모델의 성능을 살펴본다.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS1.5.1.1" class="ltx_text">VI-A</span> </span><span id="S6.SS1.6.2" class="ltx_text ltx_font_italic">Popular Metrics for Evaluating LLMs</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS1.p1.1">생성 언어 모델의 성능을 평가하는 것은 그들이 사용할 기본 작업에 달려 있다. 주로 주어진 것 중 선택을 선택하는 것(감정 분석 등)에 관한 작업은 분류처럼 단순하다고 볼 수 있으며 분류 메트릭을 사용하여 성능을 평가할 수 있다. 이 경우 정확도, 정밀도, 재현율, F1 등의 메트릭이 적용 가능하다. 또한 객관식 질문 답변과 같은 특정 작업에 대해 모델에 의해 생성된 답변은 항상 참 또는 거짓 중 하나라는 점에 유의하는 것이 중요하다. 답이 선택지 집합에 없다면 거짓으로도 볼 수 있다.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p class="ltx_p" id="S6.SS1.p2.1">그러나 순수하게 개방형 텍스트 생성인 일부 작업은 범주화와 같은 방식으로 평가할 수 없다. 평가의 특정 목적을 위해 다양한 측정 기준이 필요합니다. 코드 생성은 개방형 생성 평가에서 매우 다른 경우이다. 생성된 코드는 테스트 제품군을 통과해야 하지만 모델이 코드로서 서로 다른 솔루션을 생성할 수 있는지, 그 중 올바른 솔루션을 선택할 확률은 얼마인지 이해하는 것도 중요하다. Pass@k는 이 경우에 매우 좋은 메트릭이다. 문제가 주어지면 코드와 같은 다양한 솔루션이 생성되는 방식으로 작동합니다. 다양한 기능 테스트를 사용하여 정확성을 테스트합니다. 이후 생성된 n개의 솔루션에서 각 c개의 솔루션이 올바른 방정식 <a class="ltx_ref" href="#S6.E4" title="In VI-A Popular Metrics for Evaluating LLMs ‣ VI Prominent LLMs’ Performance on Benchmarks ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">4</span></a>가 최종 값을 제공한다.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<table id="S6.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.E4.m1.6" class="ltx_Math" alttext="\text{pass@$k$}:=\mathop{\mathbb{E}}_{\text{Problems}}\left[1-\frac{{\binom{n-c}{k}}}{\binom{n}{k}}\right]" display="block"><semantics id="S6.E4.m1.6a"><mrow id="S6.E4.m1.6.6" xref="S6.E4.m1.6.6.cmml"><mrow id="S6.E4.m1.1.1.1" xref="S6.E4.m1.1.1.1b.cmml"><mtext id="S6.E4.m1.1.1.1a" xref="S6.E4.m1.1.1.1b.cmml">pass@</mtext><mi id="S6.E4.m1.1.1.1.m1.1.1" xref="S6.E4.m1.1.1.1.m1.1.1.cmml">k</mi></mrow><mo lspace="0.278em" id="S6.E4.m1.6.6.2" xref="S6.E4.m1.6.6.2.cmml">:=</mo><mrow id="S6.E4.m1.6.6.1" xref="S6.E4.m1.6.6.1.cmml"><munder id="S6.E4.m1.6.6.1.2" xref="S6.E4.m1.6.6.1.2.cmml"><mo lspace="0.111em" movablelimits="false" rspace="0em" id="S6.E4.m1.6.6.1.2.2" xref="S6.E4.m1.6.6.1.2.2.cmml">𝔼</mo><mtext id="S6.E4.m1.6.6.1.2.3" xref="S6.E4.m1.6.6.1.2.3a.cmml">Problems</mtext></munder><mrow id="S6.E4.m1.6.6.1.1.1" xref="S6.E4.m1.6.6.1.1.2.cmml"><mo id="S6.E4.m1.6.6.1.1.1.2" xref="S6.E4.m1.6.6.1.1.2.1.cmml">[</mo><mrow id="S6.E4.m1.6.6.1.1.1.1" xref="S6.E4.m1.6.6.1.1.1.1.cmml"><mn id="S6.E4.m1.6.6.1.1.1.1.2" xref="S6.E4.m1.6.6.1.1.1.1.2.cmml">1</mn><mo id="S6.E4.m1.6.6.1.1.1.1.1" xref="S6.E4.m1.6.6.1.1.1.1.1.cmml">−</mo><mfrac id="S6.E4.m1.5.5" xref="S6.E4.m1.5.5.cmml"><mrow id="S6.E4.m1.3.3.2.4" xref="S6.E4.m1.3.3.2.3.cmml"><mo id="S6.E4.m1.3.3.2.4.1" xref="S6.E4.m1.3.3.2.3.1.cmml">(</mo><mfrac linethickness="0pt" id="S6.E4.m1.3.3.2.2.2.2" xref="S6.E4.m1.3.3.2.3.cmml"><mrow id="S6.E4.m1.2.2.1.1.1.1.1.1" xref="S6.E4.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S6.E4.m1.2.2.1.1.1.1.1.1.3" xref="S6.E4.m1.2.2.1.1.1.1.1.1.3.cmml">n</mi><mo id="S6.E4.m1.2.2.1.1.1.1.1.1.2" xref="S6.E4.m1.2.2.1.1.1.1.1.1.2.cmml">−</mo><mi id="S6.E4.m1.2.2.1.1.1.1.1.1.4" xref="S6.E4.m1.2.2.1.1.1.1.1.1.4.cmml">c</mi></mrow><mi id="S6.E4.m1.3.3.2.2.2.2.2.1" xref="S6.E4.m1.3.3.2.2.2.2.2.1.cmml">k</mi></mfrac><mo id="S6.E4.m1.3.3.2.4.2" xref="S6.E4.m1.3.3.2.3.1.cmml">)</mo></mrow><mrow id="S6.E4.m1.5.5.4.4" xref="S6.E4.m1.5.5.4.3.cmml"><mo id="S6.E4.m1.5.5.4.4.1" xref="S6.E4.m1.5.5.4.3.1.cmml">(</mo><mfrac linethickness="0pt" id="S6.E4.m1.5.5.4.2.2.2" xref="S6.E4.m1.5.5.4.3.cmml"><mi id="S6.E4.m1.4.4.3.1.1.1.1.1" xref="S6.E4.m1.4.4.3.1.1.1.1.1.cmml">n</mi><mi id="S6.E4.m1.5.5.4.2.2.2.2.1" xref="S6.E4.m1.5.5.4.2.2.2.2.1.cmml">k</mi></mfrac><mo id="S6.E4.m1.5.5.4.4.2" xref="S6.E4.m1.5.5.4.3.1.cmml">)</mo></mrow></mfrac></mrow><mo id="S6.E4.m1.6.6.1.1.1.3" xref="S6.E4.m1.6.6.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.E4.m1.6b"><apply id="S6.E4.m1.6.6.cmml" xref="S6.E4.m1.6.6"><csymbol cd="latexml" id="S6.E4.m1.6.6.2.cmml" xref="S6.E4.m1.6.6.2">assign</csymbol><ci id="S6.E4.m1.1.1.1b.cmml" xref="S6.E4.m1.1.1.1"><mrow id="S6.E4.m1.1.1.1.cmml" xref="S6.E4.m1.1.1.1"><mtext id="S6.E4.m1.1.1.1a.cmml" xref="S6.E4.m1.1.1.1">pass@</mtext><mi id="S6.E4.m1.1.1.1.m1.1.1.cmml" xref="S6.E4.m1.1.1.1.m1.1.1">k</mi></mrow></ci><apply id="S6.E4.m1.6.6.1.cmml" xref="S6.E4.m1.6.6.1"><apply id="S6.E4.m1.6.6.1.2.cmml" xref="S6.E4.m1.6.6.1.2"><csymbol cd="ambiguous" id="S6.E4.m1.6.6.1.2.1.cmml" xref="S6.E4.m1.6.6.1.2">subscript</csymbol><ci id="S6.E4.m1.6.6.1.2.2.cmml" xref="S6.E4.m1.6.6.1.2.2">𝔼</ci><ci id="S6.E4.m1.6.6.1.2.3a.cmml" xref="S6.E4.m1.6.6.1.2.3"><mtext mathsize="70%" id="S6.E4.m1.6.6.1.2.3.cmml" xref="S6.E4.m1.6.6.1.2.3">Problems</mtext></ci></apply><apply id="S6.E4.m1.6.6.1.1.2.cmml" xref="S6.E4.m1.6.6.1.1.1"><csymbol cd="latexml" id="S6.E4.m1.6.6.1.1.2.1.cmml" xref="S6.E4.m1.6.6.1.1.1.2">delimited-[]</csymbol><apply id="S6.E4.m1.6.6.1.1.1.1.cmml" xref="S6.E4.m1.6.6.1.1.1.1"><minus id="S6.E4.m1.6.6.1.1.1.1.1.cmml" xref="S6.E4.m1.6.6.1.1.1.1.1"></minus><cn type="integer" id="S6.E4.m1.6.6.1.1.1.1.2.cmml" xref="S6.E4.m1.6.6.1.1.1.1.2">1</cn><apply id="S6.E4.m1.5.5.cmml" xref="S6.E4.m1.5.5"><divide id="S6.E4.m1.5.5.5.cmml" xref="S6.E4.m1.5.5"></divide><apply id="S6.E4.m1.3.3.2.3.cmml" xref="S6.E4.m1.3.3.2.4"><csymbol cd="latexml" id="S6.E4.m1.3.3.2.3.1.cmml" xref="S6.E4.m1.3.3.2.4.1">binomial</csymbol><apply id="S6.E4.m1.2.2.1.1.1.1.1.1.cmml" xref="S6.E4.m1.2.2.1.1.1.1.1.1"><minus id="S6.E4.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S6.E4.m1.2.2.1.1.1.1.1.1.2"></minus><ci id="S6.E4.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S6.E4.m1.2.2.1.1.1.1.1.1.3">𝑛</ci><ci id="S6.E4.m1.2.2.1.1.1.1.1.1.4.cmml" xref="S6.E4.m1.2.2.1.1.1.1.1.1.4">𝑐</ci></apply><ci id="S6.E4.m1.3.3.2.2.2.2.2.1.cmml" xref="S6.E4.m1.3.3.2.2.2.2.2.1">𝑘</ci></apply><apply id="S6.E4.m1.5.5.4.3.cmml" xref="S6.E4.m1.5.5.4.4"><csymbol cd="latexml" id="S6.E4.m1.5.5.4.3.1.cmml" xref="S6.E4.m1.5.5.4.4.1">binomial</csymbol><ci id="S6.E4.m1.4.4.3.1.1.1.1.1.cmml" xref="S6.E4.m1.4.4.3.1.1.1.1.1">𝑛</ci><ci id="S6.E4.m1.5.5.4.2.2.2.2.1.cmml" xref="S6.E4.m1.5.5.4.2.2.2.2.1">𝑘</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E4.m1.6c">\text{pass@$k$}:=\mathop{\mathbb{E}}_{\text{Problems}}\left[1-\frac{{\binom{n-c}{k}}}{\binom{n}{k}}\right]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div id="S6.SS1.p4" class="ltx_para">
<p class="ltx_p" id="S6.SS1.p4.1">정확한 일치(EM)는 대부분 (미리 정의된) 답변의 정확한 일치와 관련된 또 다른 메트릭이다. 토큰별로 둘 이상의 원하는 참조 텍스트 토큰 중 하나와 정확히 일치하는 경우 예측이 올바른 것으로 계산됩니다. 경우에 따라 정확도와 동일할 수 있으며 수식 <a class="ltx_ref" href="#S6.E5" title="In VI-A Popular Metrics for Evaluating LLMs ‣ VI Prominent LLMs’ Performance on Benchmarks ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">5</span></a>는 수학적 정의를 나타낸다. 여기서, M은 총 정답 수이고, N은 총 질문 수 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib202" title="">202</a>]</cite>이다.</p>
</div>
<div id="S6.SS1.p5" class="ltx_para">
<table id="S6.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S6.E5.m1.1" class="ltx_Math" alttext="EM=\frac{M}{N}" display="block"><semantics id="S6.E5.m1.1a"><mrow id="S6.E5.m1.1.1" xref="S6.E5.m1.1.1.cmml"><mrow id="S6.E5.m1.1.1.2" xref="S6.E5.m1.1.1.2.cmml"><mi id="S6.E5.m1.1.1.2.2" xref="S6.E5.m1.1.1.2.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S6.E5.m1.1.1.2.1" xref="S6.E5.m1.1.1.2.1.cmml">​</mo><mi id="S6.E5.m1.1.1.2.3" xref="S6.E5.m1.1.1.2.3.cmml">M</mi></mrow><mo id="S6.E5.m1.1.1.1" xref="S6.E5.m1.1.1.1.cmml">=</mo><mfrac id="S6.E5.m1.1.1.3" xref="S6.E5.m1.1.1.3.cmml"><mi id="S6.E5.m1.1.1.3.2" xref="S6.E5.m1.1.1.3.2.cmml">M</mi><mi id="S6.E5.m1.1.1.3.3" xref="S6.E5.m1.1.1.3.3.cmml">N</mi></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S6.E5.m1.1b"><apply id="S6.E5.m1.1.1.cmml" xref="S6.E5.m1.1.1"><eq id="S6.E5.m1.1.1.1.cmml" xref="S6.E5.m1.1.1.1"></eq><apply id="S6.E5.m1.1.1.2.cmml" xref="S6.E5.m1.1.1.2"><times id="S6.E5.m1.1.1.2.1.cmml" xref="S6.E5.m1.1.1.2.1"></times><ci id="S6.E5.m1.1.1.2.2.cmml" xref="S6.E5.m1.1.1.2.2">𝐸</ci><ci id="S6.E5.m1.1.1.2.3.cmml" xref="S6.E5.m1.1.1.2.3">𝑀</ci></apply><apply id="S6.E5.m1.1.1.3.cmml" xref="S6.E5.m1.1.1.3"><divide id="S6.E5.m1.1.1.3.1.cmml" xref="S6.E5.m1.1.1.3"></divide><ci id="S6.E5.m1.1.1.3.2.cmml" xref="S6.E5.m1.1.1.3.2">𝑀</ci><ci id="S6.E5.m1.1.1.3.3.cmml" xref="S6.E5.m1.1.1.3.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.E5.m1.1c">EM=\frac{M}{N}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
</div>
<div id="S6.SS1.p6" class="ltx_para">
<p class="ltx_p" id="S6.SS1.p6.1">반면에 인간 동등성 점수(HEQ)는 F1 점수 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib203" title="">203</a>]</cite>에 대한 대안이다. HEQ-Q는 개별 질문의 정밀도를 나타내며, 모델의 F1 점수가 평균 인간 F1 점수를 초과하는 경우 정답이 올바른 것으로 간주된다. 마찬가지로 HEQ-D는 각 대화의 정밀도를 나타내며, 대화 내의 모든 질문이 HEQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib182" title="">182</a>]</cite>의 기준을 충족할 때 정확하다고 간주된다.</p>
</div>
<figure id="S6.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S6.T3.8.1.1" style="font-size:90%;">TABLE III</span>:</span><span class="ltx_text" id="S6.T3.9.2" style="font-size:90%;">LLM categories and respective definitions. </span></figcaption>
<table id="S6.T3.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T3.6.7.1" class="ltx_tr">
<th id="S6.T3.6.7.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Classification</th>
<th id="S6.T3.6.7.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Category</th>
<th id="S6.T3.6.7.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Description</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T3.1.1" class="ltx_tr">
<td id="S6.T3.1.1.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="4"><span id="S6.T3.1.1.2.1" class="ltx_text">Size</span></td>
<td id="S6.T3.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Small</td>
<td id="S6.T3.1.1.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Number of parameters <math id="S6.T3.1.1.1.m1.1" class="ltx_Math" alttext="\leq" display="inline"><semantics id="S6.T3.1.1.1.m1.1a"><mo id="S6.T3.1.1.1.m1.1.1" xref="S6.T3.1.1.1.m1.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="S6.T3.1.1.1.m1.1b"><leq id="S6.T3.1.1.1.m1.1.1.cmml" xref="S6.T3.1.1.1.m1.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.1.1.1.m1.1c">\leq</annotation></semantics></math> 1B</td>
</tr>
<tr id="S6.T3.3.3" class="ltx_tr">
<td id="S6.T3.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Medium</td>
<td id="S6.T3.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1B <math id="S6.T3.2.2.1.m1.1" class="ltx_Math" alttext="<" display="inline"><semantics id="S6.T3.2.2.1.m1.1a"><mo id="S6.T3.2.2.1.m1.1.1" xref="S6.T3.2.2.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S6.T3.2.2.1.m1.1b"><lt id="S6.T3.2.2.1.m1.1.1.cmml" xref="S6.T3.2.2.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.2.2.1.m1.1c">&lt;</annotation></semantics></math> Number of parameters <math id="S6.T3.3.3.2.m2.1" class="ltx_Math" alttext="\leq" display="inline"><semantics id="S6.T3.3.3.2.m2.1a"><mo id="S6.T3.3.3.2.m2.1.1" xref="S6.T3.3.3.2.m2.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="S6.T3.3.3.2.m2.1b"><leq id="S6.T3.3.3.2.m2.1.1.cmml" xref="S6.T3.3.3.2.m2.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.3.3.2.m2.1c">\leq</annotation></semantics></math> 10B</td>
</tr>
<tr id="S6.T3.5.5" class="ltx_tr">
<td id="S6.T3.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Large</td>
<td id="S6.T3.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">10B <math id="S6.T3.4.4.1.m1.1" class="ltx_Math" alttext="<" display="inline"><semantics id="S6.T3.4.4.1.m1.1a"><mo id="S6.T3.4.4.1.m1.1.1" xref="S6.T3.4.4.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S6.T3.4.4.1.m1.1b"><lt id="S6.T3.4.4.1.m1.1.1.cmml" xref="S6.T3.4.4.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.4.4.1.m1.1c">&lt;</annotation></semantics></math> Number of parameters <math id="S6.T3.5.5.2.m2.1" class="ltx_Math" alttext="\leq" display="inline"><semantics id="S6.T3.5.5.2.m2.1a"><mo id="S6.T3.5.5.2.m2.1.1" xref="S6.T3.5.5.2.m2.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="S6.T3.5.5.2.m2.1b"><leq id="S6.T3.5.5.2.m2.1.1.cmml" xref="S6.T3.5.5.2.m2.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.5.5.2.m2.1c">\leq</annotation></semantics></math> 100B</td>
</tr>
<tr id="S6.T3.6.6" class="ltx_tr">
<td id="S6.T3.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Very Large</td>
<td id="S6.T3.6.6.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">100B <math id="S6.T3.6.6.1.m1.1" class="ltx_Math" alttext="<" display="inline"><semantics id="S6.T3.6.6.1.m1.1a"><mo id="S6.T3.6.6.1.m1.1.1" xref="S6.T3.6.6.1.m1.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S6.T3.6.6.1.m1.1b"><lt id="S6.T3.6.6.1.m1.1.1.cmml" xref="S6.T3.6.6.1.m1.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.6.6.1.m1.1c">&lt;</annotation></semantics></math> Number of parameters</td>
</tr>
<tr id="S6.T3.6.8.1" class="ltx_tr">
<td id="S6.T3.6.8.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S6.T3.6.8.1.1.1" class="ltx_text">Type</span></td>
<td id="S6.T3.6.8.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Foundation model</td>
<td id="S6.T3.6.8.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Pretrained language model</td>
</tr>
<tr id="S6.T3.6.9.2" class="ltx_tr">
<td id="S6.T3.6.9.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Instruction model</td>
<td id="S6.T3.6.9.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Pretrained and instruction fine-tuned language model</td>
</tr>
<tr id="S6.T3.6.10.3" class="ltx_tr">
<td id="S6.T3.6.10.3.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Chat model</td>
<td id="S6.T3.6.10.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Pretrained, instruction fine-tuned, and chat fine-tuned language model</td>
</tr>
<tr id="S6.T3.6.11.4" class="ltx_tr">
<td id="S6.T3.6.11.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S6.T3.6.11.4.1.1" class="ltx_text">Origin</span></td>
<td id="S6.T3.6.11.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Original model</td>
<td id="S6.T3.6.11.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">An original model released with either Foundation, Instruction, or Chat model</td>
</tr>
<tr id="S6.T3.6.12.5" class="ltx_tr">
<td id="S6.T3.6.12.5.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Tuned model</td>
<td id="S6.T3.6.12.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Fine-tuned version of an original model</td>
</tr>
<tr id="S6.T3.6.13.6" class="ltx_tr">
<td id="S6.T3.6.13.6.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S6.T3.6.13.6.1.1" class="ltx_text">Availability</span></td>
<td id="S6.T3.6.13.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Publicly available</td>
<td id="S6.T3.6.13.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Model and weights are available due to request to without request</td>
</tr>
<tr id="S6.T3.6.14.7" class="ltx_tr">
<td id="S6.T3.6.14.7.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">Publicly unavailable</td>
<td id="S6.T3.6.14.7.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">Model and weights are not publicly available</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S6.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S6.T4.2.1.1" style="font-size:90%;">TABLE IV</span>:</span><span class="ltx_text" id="S6.T4.3.2" style="font-size:90%;">Different LLM categorization. </span></figcaption>
<table id="S6.T4.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T4.4.1.1" class="ltx_tr">
<td id="S6.T4.4.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Model</td>
<td id="S6.T4.4.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Size</td>
<td id="S6.T4.4.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">#Params (B)</td>
<td id="S6.T4.4.1.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Type</td>
<td id="S6.T4.4.1.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Availability</td>
<td id="S6.T4.4.1.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Origin</td>
</tr>
<tr id="S6.T4.4.2.2" class="ltx_tr">
<td id="S6.T4.4.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Davinci-002</td>
<td id="S6.T4.4.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFBFBF;"><span id="S6.T4.4.2.2.2.1" class="ltx_text" style="background-color:#FFBFBF;">Very Large</span></td>
<td id="S6.T4.4.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">175</td>
<td id="S6.T4.4.2.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFBFFF;"><span id="S6.T4.4.2.2.4.1" class="ltx_text" style="background-color:#BFBFFF;">Instruction</span></td>
<td id="S6.T4.4.2.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFFFBF;"><span id="S6.T4.4.2.2.5.1" class="ltx_text" style="background-color:#FFFFBF;">Unavailable</span></td>
<td id="S6.T4.4.2.2.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFEFEF;"><span id="S6.T4.4.2.2.6.1" class="ltx_text" style="background-color:#FFEFEF;">Tuned</span></td>
</tr>
<tr id="S6.T4.4.3.3" class="ltx_tr">
<td id="S6.T4.4.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Davinci-003</td>
<td id="S6.T4.4.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFBFBF;"><span id="S6.T4.4.3.3.2.1" class="ltx_text" style="background-color:#FFBFBF;">Very Large</span></td>
<td id="S6.T4.4.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">175</td>
<td id="S6.T4.4.3.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFBFFF;"><span id="S6.T4.4.3.3.4.1" class="ltx_text" style="background-color:#BFBFFF;">Instruction</span></td>
<td id="S6.T4.4.3.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFFFBF;"><span id="S6.T4.4.3.3.5.1" class="ltx_text" style="background-color:#FFFFBF;">Unavailable</span></td>
<td id="S6.T4.4.3.3.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFEFEF;"><span id="S6.T4.4.3.3.6.1" class="ltx_text" style="background-color:#FFEFEF;">Tuned</span></td>
</tr>
<tr id="S6.T4.4.4.4" class="ltx_tr">
<td id="S6.T4.4.4.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT 3.5-turbo</td>
<td id="S6.T4.4.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFFFBF;"><span id="S6.T4.4.4.4.2.1" class="ltx_text" style="background-color:#FFFFBF;">Large</span></td>
<td id="S6.T4.4.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">20</td>
<td id="S6.T4.4.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#EFBFCF;"><span id="S6.T4.4.4.4.4.1" class="ltx_text" style="background-color:#EFBFCF;">Chat</span></td>
<td id="S6.T4.4.4.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFFFBF;"><span id="S6.T4.4.4.4.5.1" class="ltx_text" style="background-color:#FFFFBF;">Unavailable</span></td>
<td id="S6.T4.4.4.4.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFEFEF;"><span id="S6.T4.4.4.4.6.1" class="ltx_text" style="background-color:#FFEFEF;">Tuned</span></td>
</tr>
<tr id="S6.T4.4.5.5" class="ltx_tr">
<td id="S6.T4.4.5.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Falcon 7B</td>
<td id="S6.T4.4.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.5.5.2.1" class="ltx_text" style="background-color:#BFFFBF;">Medium</span></td>
<td id="S6.T4.4.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">7</td>
<td id="S6.T4.4.5.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#DFDFDF;"><span id="S6.T4.4.5.5.4.1" class="ltx_text" style="background-color:#DFDFDF;">Foundation</span></td>
<td id="S6.T4.4.5.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.5.5.5.1" class="ltx_text" style="background-color:#BFFFBF;">Public</span></td>
<td id="S6.T4.4.5.5.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFDFDF;"><span id="S6.T4.4.5.5.6.1" class="ltx_text" style="background-color:#BFDFDF;">Original</span></td>
</tr>
<tr id="S6.T4.4.6.6" class="ltx_tr">
<td id="S6.T4.4.6.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Alpaca</td>
<td id="S6.T4.4.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFFFBF;"><span id="S6.T4.4.6.6.2.1" class="ltx_text" style="background-color:#FFFFBF;">Large</span></td>
<td id="S6.T4.4.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">13</td>
<td id="S6.T4.4.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#EFBFCF;"><span id="S6.T4.4.6.6.4.1" class="ltx_text" style="background-color:#EFBFCF;">Chat</span></td>
<td id="S6.T4.4.6.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.6.6.5.1" class="ltx_text" style="background-color:#BFFFBF;">Public</span></td>
<td id="S6.T4.4.6.6.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFEFEF;"><span id="S6.T4.4.6.6.6.1" class="ltx_text" style="background-color:#FFEFEF;">Tuned</span></td>
</tr>
<tr id="S6.T4.4.7.7" class="ltx_tr">
<td id="S6.T4.4.7.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Pythia 7B</td>
<td id="S6.T4.4.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.7.7.2.1" class="ltx_text" style="background-color:#BFFFBF;">Medium</span></td>
<td id="S6.T4.4.7.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">7</td>
<td id="S6.T4.4.7.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#DFDFDF;"><span id="S6.T4.4.7.7.4.1" class="ltx_text" style="background-color:#DFDFDF;">Foundation</span></td>
<td id="S6.T4.4.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.7.7.5.1" class="ltx_text" style="background-color:#BFFFBF;">Public</span></td>
<td id="S6.T4.4.7.7.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFDFDF;"><span id="S6.T4.4.7.7.6.1" class="ltx_text" style="background-color:#BFDFDF;">Original</span></td>
</tr>
<tr id="S6.T4.4.8.8" class="ltx_tr">
<td id="S6.T4.4.8.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Pythia 12B</td>
<td id="S6.T4.4.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFFFBF;"><span id="S6.T4.4.8.8.2.1" class="ltx_text" style="background-color:#FFFFBF;">Large</span></td>
<td id="S6.T4.4.8.8.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">12</td>
<td id="S6.T4.4.8.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#DFDFDF;"><span id="S6.T4.4.8.8.4.1" class="ltx_text" style="background-color:#DFDFDF;">Foundation</span></td>
<td id="S6.T4.4.8.8.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.8.8.5.1" class="ltx_text" style="background-color:#BFFFBF;">Public</span></td>
<td id="S6.T4.4.8.8.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFDFDF;"><span id="S6.T4.4.8.8.6.1" class="ltx_text" style="background-color:#BFDFDF;">Original</span></td>
</tr>
<tr id="S6.T4.4.9.9" class="ltx_tr">
<td id="S6.T4.4.9.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLAMA 7B</td>
<td id="S6.T4.4.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.9.9.2.1" class="ltx_text" style="background-color:#BFFFBF;">Medium</span></td>
<td id="S6.T4.4.9.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">7</td>
<td id="S6.T4.4.9.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#EFBFCF;"><span id="S6.T4.4.9.9.4.1" class="ltx_text" style="background-color:#EFBFCF;">Chat</span></td>
<td id="S6.T4.4.9.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.9.9.5.1" class="ltx_text" style="background-color:#BFFFBF;">Public</span></td>
<td id="S6.T4.4.9.9.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFDFDF;"><span id="S6.T4.4.9.9.6.1" class="ltx_text" style="background-color:#BFDFDF;">Original</span></td>
</tr>
<tr id="S6.T4.4.10.10" class="ltx_tr">
<td id="S6.T4.4.10.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLAMA 2 7B</td>
<td id="S6.T4.4.10.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.10.10.2.1" class="ltx_text" style="background-color:#BFFFBF;">Medium</span></td>
<td id="S6.T4.4.10.10.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">7</td>
<td id="S6.T4.4.10.10.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#EFBFCF;"><span id="S6.T4.4.10.10.4.1" class="ltx_text" style="background-color:#EFBFCF;">Chat</span></td>
<td id="S6.T4.4.10.10.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.10.10.5.1" class="ltx_text" style="background-color:#BFFFBF;">Public</span></td>
<td id="S6.T4.4.10.10.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFEFEF;"><span id="S6.T4.4.10.10.6.1" class="ltx_text" style="background-color:#FFEFEF;">Tuned</span></td>
</tr>
<tr id="S6.T4.4.11.11" class="ltx_tr">
<td id="S6.T4.4.11.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLAMA 2 7B</td>
<td id="S6.T4.4.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.11.11.2.1" class="ltx_text" style="background-color:#BFFFBF;">Medium</span></td>
<td id="S6.T4.4.11.11.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">7</td>
<td id="S6.T4.4.11.11.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#DFDFDF;"><span id="S6.T4.4.11.11.4.1" class="ltx_text" style="background-color:#DFDFDF;">Foundation</span></td>
<td id="S6.T4.4.11.11.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.11.11.5.1" class="ltx_text" style="background-color:#BFFFBF;">Public</span></td>
<td id="S6.T4.4.11.11.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFDFDF;"><span id="S6.T4.4.11.11.6.1" class="ltx_text" style="background-color:#BFDFDF;">Original</span></td>
</tr>
<tr id="S6.T4.4.12.12" class="ltx_tr">
<td id="S6.T4.4.12.12.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Vicuna 13B</td>
<td id="S6.T4.4.12.12.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFFFBF;"><span id="S6.T4.4.12.12.2.1" class="ltx_text" style="background-color:#FFFFBF;">Large</span></td>
<td id="S6.T4.4.12.12.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">13</td>
<td id="S6.T4.4.12.12.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#DFDFDF;"><span id="S6.T4.4.12.12.4.1" class="ltx_text" style="background-color:#DFDFDF;">Foundation</span></td>
<td id="S6.T4.4.12.12.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.12.12.5.1" class="ltx_text" style="background-color:#BFFFBF;">Public</span></td>
<td id="S6.T4.4.12.12.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFEFEF;"><span id="S6.T4.4.12.12.6.1" class="ltx_text" style="background-color:#FFEFEF;">Tuned</span></td>
</tr>
<tr id="S6.T4.4.13.13" class="ltx_tr">
<td id="S6.T4.4.13.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Vicuna 7B</td>
<td id="S6.T4.4.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.13.13.2.1" class="ltx_text" style="background-color:#BFFFBF;">Medium</span></td>
<td id="S6.T4.4.13.13.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">7</td>
<td id="S6.T4.4.13.13.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#DFDFDF;"><span id="S6.T4.4.13.13.4.1" class="ltx_text" style="background-color:#DFDFDF;">Foundation</span></td>
<td id="S6.T4.4.13.13.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T4.4.13.13.5.1" class="ltx_text" style="background-color:#BFFFBF;">Public</span></td>
<td id="S6.T4.4.13.13.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFEFEF;"><span id="S6.T4.4.13.13.6.1" class="ltx_text" style="background-color:#FFEFEF;">Tuned</span></td>
</tr>
<tr id="S6.T4.4.14.14" class="ltx_tr">
<td id="S6.T4.4.14.14.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Claude</td>
<td id="S6.T4.4.14.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFFFBF;"><span id="S6.T4.4.14.14.2.1" class="ltx_text" style="background-color:#FFFFBF;">Large</span></td>
<td id="S6.T4.4.14.14.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">93</td>
<td id="S6.T4.4.14.14.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#EFBFCF;"><span id="S6.T4.4.14.14.4.1" class="ltx_text" style="background-color:#EFBFCF;">Chat</span></td>
<td id="S6.T4.4.14.14.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#FFFFBF;"><span id="S6.T4.4.14.14.5.1" class="ltx_text" style="background-color:#FFFFBF;">Unavailable</span></td>
<td id="S6.T4.4.14.14.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t" style="background-color:#BFDFDF;"><span id="S6.T4.4.14.14.6.1" class="ltx_text" style="background-color:#BFDFDF;">Original</span></td>
</tr>
<tr id="S6.T4.4.15.15" class="ltx_tr">
<td id="S6.T4.4.15.15.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Claude 2</td>
<td id="S6.T4.4.15.15.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" style="background-color:#FFBFBF;"><span id="S6.T4.4.15.15.2.1" class="ltx_text" style="background-color:#FFBFBF;">Very Large</span></td>
<td id="S6.T4.4.15.15.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">137</td>
<td id="S6.T4.4.15.15.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" style="background-color:#EFBFCF;"><span id="S6.T4.4.15.15.4.1" class="ltx_text" style="background-color:#EFBFCF;">Chat</span></td>
<td id="S6.T4.4.15.15.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" style="background-color:#FFFFBF;"><span id="S6.T4.4.15.15.5.1" class="ltx_text" style="background-color:#FFFFBF;">Unavailable</span></td>
<td id="S6.T4.4.15.15.6" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t" style="background-color:#BFDFDF;"><span id="S6.T4.4.15.15.6.1" class="ltx_text" style="background-color:#BFDFDF;">Original</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S6.SS1.p7" class="ltx_para">
<p class="ltx_p" id="S6.SS1.p7.1">기계 번역과 같은 다른 생성 작업의 평가는 Rouge 및 BLEU와 같은 메트릭을 기반으로 한다. 이 점수는 사실(번역 등)과 생성 모델에 의해 생성되는 가설인 참조 텍스트가 있는 경우 LLM에서 잘 작동한다. 이러한 스코어들은 대부분 계산 방식으로 답변과 그라운드 트루스의 유사성을 검출하는 것이 목표인 경우에 사용된다. 계산 방식으로, 그것은 N-Grams만이 사용될 것이라는 것을 의미했다. 그러나 BERT-Score와 같은 메트릭은 이러한 경우에도 좋지만 다른 모델을 사용하여 판단하기 때문에 큰 오류가 있다. 여전히, 오늘날에도, 순수하게 생성된 콘텐츠를 평가하는 것은 매우 어렵고 완전히 피팅되는 메트릭이 발견되지 않고, 메트릭은 N-Gram, SkipGram 등과 같은 단순한 특징을 찾고 있거나, 또는 알려지지 않은 정확성 및 정밀성 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib204" title="">204</a>]</cite>를 갖는 모델이다.</p>
</div>
<div id="S6.SS1.p8" class="ltx_para">
<p class="ltx_p" id="S6.SS1.p8.1">생성 평가 메트릭은 또한 답변을 평가하기 위해 또 다른 LLM을 사용하는 LLM에 대한 또 다른 유형의 평가 메트릭이다. 다만, 과제 자체에 따라 이와 같이 평가가 가능할 수도 있고 그렇지 않을 수도 있다. 생성 평가 오류를 쉽게 만드는 또 다른 종속성은 프롬프트 자체에 의존하는 것이다. <span class="ltx_ref ltx_ref_self">RAGAS</span>은 생성 평가의 사용을 통합한 좋은 예 중 하나이다.</p>
</div>
<div id="S6.SS1.p9" class="ltx_para">
<p class="ltx_p" id="S6.SS1.p9.1">대형 언어 모델의 세계에서 가장 어려운 문제를 해결하기 위해 다양한 벤치마크와 리더보드가 제안되었습니다: 어떤 것이 더 나은가요? 그러나 간단한 대답은 이 문제를 해결할 수 없다. 대답은 대형 언어 모델의 다양한 측면에 달려 있습니다. 섹션 <a class="ltx_ref" href="#S5" title="V Popular Datasets for LLMs ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">V</span></a>는 서로 다른 작업의 범주형 프레젠테이션과 각 범주에서 가장 중요한 데이터 세트를 보여준다. 우리는 동일한 분류를 따르고 각 범주에 따른 비교를 제공할 것이다. 각 범주에 대한 비교를 제공한 후 서로 다른 작업에 대해 보고된 성능 메트릭을 평균화하여 집계된 성능에 대한 광범위한 개요를 제공합니다.</p>
</div>
<div id="S6.SS1.p10" class="ltx_para">
<p class="ltx_p" id="S6.SS1.p10.1">다른 LLM을 평가하는 것은 다른 관점에서도 볼 수 있다. 예를 들어, 매개변수 수가 급격히 적은 LLM은 매개변수 수가 더 많은 LLM과 완전히 비교할 수 없다. 이러한 관점에서 우리는 LLMs를 <span class="ltx_text ltx_font_bold" id="S6.SS1.p10.1.1">small</span> (10억 매개 변수 이하), <span class="ltx_text ltx_font_bold" id="S6.SS1.p10.1.2">medium</span> (1억에서 100억 사이), <span class="ltx_text ltx_font_bold" id="S6.SS1.p10.1.3">large</span> (10억에서 1000억 사이), <span class="ltx_text ltx_font_bold" id="S6.SS1.p10.1.4">very large</span> (1000억 이상)의 네 가지 범주로 분류할 것이다. 우리가 사용하는 LLMs에 대한 또 다른 분류는 그들의 주요 사용 사례이다. 우리는 각 LLM을 다음과 같이 간주합니다. <span class="ltx_text ltx_font_bold" id="S6.SS1.p10.1.5">Foundation</span> 모델(명령 미세 조정 및 채팅 미세 조정이 없는pretrained 언어 모델), <span class="ltx_text ltx_font_bold" id="S6.SS1.p10.1.6">Instruction</span> 모델(명령 미세 조정만 있는pretrained 언어 모델) 및 <span class="ltx_text ltx_font_bold" id="S6.SS1.p10.1.7">Chat</span> 모델(명령 및 채팅 미세 조정이 있는pretrained 언어 모델)입니다. 설명된 모든 범주화 외에도 원래 모델과 조정된 모델을 구별하기 위해 다른 범주가 필요하다. <span class="ltx_text ltx_font_bold" id="S6.SS1.p10.1.8">Original</span> 모델은 기초 모델 또는 미세 조정 모델로 릴리스된 모델입니다. <span class="ltx_text ltx_font_bold" id="S6.SS1.p10.1.9">Tuned</span> 모델은 원본 모델을 파악하고 다른 데이터 세트 또는 심지어 다른 훈련 접근 방식으로 튜닝한 모델입니다. 원본 모델은 일반적으로 특정 데이터 세트 또는 심지어 다른 접근법에 대해 미세 조정된 기초 모델이라는 점에 주목하는 것도 좋다. 라이선스에 관계없이 모델 가중치의 가용성은 분류의 또 다른 범주이다. 그들의 가중치를 공개적으로 사용할 수 있는(요청을 통해) 모델들은 <span class="ltx_text ltx_font_bold" id="S6.SS1.p10.1.10">Public</span> 모델들로서 주목되는 반면, 다른 모델들은 <span class="ltx_text ltx_font_bold" id="S6.SS1.p10.1.11">Private</span>으로 주목된다. 표 <a class="ltx_ref" href="#S6.T3" title="TABLE III ‣ VI-A Popular Metrics for Evaluating LLMs ‣ VI Prominent LLMs’ Performance on Benchmarks ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">III</span></a>는 나머지 문서에서 사용된 이러한 정의 및 약어를 모두 보여준다. 도<a class="ltx_ref" href="#S6.F43" title="Figure 43 ‣ VI-A Popular Metrics for Evaluating LLMs ‣ VI Prominent LLMs’ Performance on Benchmarks ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">43</span></a>는 이들을 시각적으로 도시한 것이다.</p>
</div>
<figure id="S6.F43" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2402.06196/assets/x7.png" id="S6.F43.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="340" height="222" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F43.2.1.1" style="font-size:90%;">Figure 43</span>:</span><span class="ltx_text" id="S6.F43.3.2" style="font-size:90%;">LLM categorizations. </span></figcaption>
</figure>
<div id="S6.SS1.p11" class="ltx_para">
<p class="ltx_p" id="S6.SS1.p11.1">제공된 범주화에 따라 표 <a class="ltx_ref" href="#S6.T4" title="TABLE IV ‣ VI-A Popular Metrics for Evaluating LLMs ‣ VI Prominent LLMs’ Performance on Benchmarks ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">IV</span></a>와 같이 각 주목할만한 LLM을 범주화하고 레이블을 지정할 수 있다. 이 표에서 볼 수 있듯이 매우 큰 것으로 분류된 모델도 사용할 수 없다.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS2.5.1.1" class="ltx_text">VI-B</span> </span><span id="S6.SS2.6.2" class="ltx_text ltx_font_italic">LLMs’ Performance on Different Tasks</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS2.p1.1">상식 추론은 각 모델이 얻을 수 있는 중요한 능력 중 하나이다. 이 능력은 추론 능력과 결합하여 사전 지식을 사용할 수 있는 모델의 능력을 나타낸다. 예를 들어, HellaSwag의 경우, 주어진 텍스트가 이야기의 일부를 포함하고 있는 반면 연속으로서 주어진 선택은 선택하기 까다롭고 세계에 대한 사전 지식을 가지고 있지 않기 때문에 텍스트의 연속을 찾는 것은 어렵다. 이러한 특정 유형의 추론은 공개된 텍스트 서술 장면이나 사실로 이전의 지식을 활용하는 것과 관련이 있기 때문에 높은 관심을 받을 만하다. 표 <a class="ltx_ref" href="#S6.T5" title="TABLE V ‣ VI-B LLMs’ Performance on Different Tasks ‣ VI Prominent LLMs’ Performance on Benchmarks ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">V</span></a>에서 알 수 있듯이 Unavailable 모델뿐만 아니라 Public 모델도 다양한 테스트에서 좋은 결과를 얻을 수 있다.</p>
</div>
<figure id="S6.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S6.T5.2.1.1" style="font-size:90%;">TABLE V</span>:</span><span class="ltx_text" id="S6.T5.3.2" style="font-size:90%;">Commonsense reasoning comparison. </span></figcaption>
<table id="S6.T5.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T5.4.1.1" class="ltx_tr">
<td id="S6.T5.4.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Model</td>
<td id="S6.T5.4.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">OBQA</td>
<td id="S6.T5.4.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">HellaSwag</td>
</tr>
<tr id="S6.T5.4.2.2" class="ltx_tr">
<td id="S6.T5.4.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Davinci-003</td>
<td id="S6.T5.4.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S6.T5.4.2.2.2.1" class="ltx_text ltx_font_bold">51</span></td>
<td id="S6.T5.4.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">83.4</td>
</tr>
<tr id="S6.T5.4.3.3" class="ltx_tr">
<td id="S6.T5.4.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Falcon 7B</td>
<td id="S6.T5.4.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">44.4</td>
<td id="S6.T5.4.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">76.3</td>
</tr>
<tr id="S6.T5.4.4.4" class="ltx_tr">
<td id="S6.T5.4.4.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Alpaca</td>
<td id="S6.T5.4.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">43.4</td>
<td id="S6.T5.4.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">73.9</td>
</tr>
<tr id="S6.T5.4.5.5" class="ltx_tr">
<td id="S6.T5.4.5.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Pythia 7B</td>
<td id="S6.T5.4.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">37.2</td>
<td id="S6.T5.4.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">64</td>
</tr>
<tr id="S6.T5.4.6.6" class="ltx_tr">
<td id="S6.T5.4.6.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Pythia 12B</td>
<td id="S6.T5.4.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">43.2</td>
<td id="S6.T5.4.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">68.1</td>
</tr>
<tr id="S6.T5.4.7.7" class="ltx_tr">
<td id="S6.T5.4.7.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLAMA 7B</td>
<td id="S6.T5.4.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">42.4</td>
<td id="S6.T5.4.7.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">73</td>
</tr>
<tr id="S6.T5.4.8.8" class="ltx_tr">
<td id="S6.T5.4.8.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Dolly 6B</td>
<td id="S6.T5.4.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">41.2</td>
<td id="S6.T5.4.8.8.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">67.6</td>
</tr>
<tr id="S6.T5.4.9.9" class="ltx_tr">
<td id="S6.T5.4.9.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Dolly 12B</td>
<td id="S6.T5.4.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">40.4</td>
<td id="S6.T5.4.9.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">71</td>
</tr>
<tr id="S6.T5.4.10.10" class="ltx_tr">
<td id="S6.T5.4.10.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Alpaca 7B</td>
<td id="S6.T5.4.10.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">43.4</td>
<td id="S6.T5.4.10.10.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">73.9</td>
</tr>
<tr id="S6.T5.4.11.11" class="ltx_tr">
<td id="S6.T5.4.11.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Alpaca Lora 7B</td>
<td id="S6.T5.4.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">42.6</td>
<td id="S6.T5.4.11.11.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">74</td>
</tr>
<tr id="S6.T5.4.12.12" class="ltx_tr">
<td id="S6.T5.4.12.12.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT-J 6.7B</td>
<td id="S6.T5.4.12.12.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">38.2</td>
<td id="S6.T5.4.12.12.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">66.2</td>
</tr>
<tr id="S6.T5.4.13.13" class="ltx_tr">
<td id="S6.T5.4.13.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLama 7B</td>
<td id="S6.T5.4.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">42.4</td>
<td id="S6.T5.4.13.13.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">73</td>
</tr>
<tr id="S6.T5.4.14.14" class="ltx_tr">
<td id="S6.T5.4.14.14.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLama 13B</td>
<td id="S6.T5.4.14.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">42.2</td>
<td id="S6.T5.4.14.14.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">76.2</td>
</tr>
<tr id="S6.T5.4.15.15" class="ltx_tr">
<td id="S6.T5.4.15.15.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Pythia 6.7B</td>
<td id="S6.T5.4.15.15.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">37.2</td>
<td id="S6.T5.4.15.15.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">64</td>
</tr>
<tr id="S6.T5.4.16.16" class="ltx_tr">
<td id="S6.T5.4.16.16.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Pythia 12B</td>
<td id="S6.T5.4.16.16.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">38</td>
<td id="S6.T5.4.16.16.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">67.3</td>
</tr>
<tr id="S6.T5.4.17.17" class="ltx_tr">
<td id="S6.T5.4.17.17.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">StableLM Tuned</td>
<td id="S6.T5.4.17.17.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">33.4</td>
<td id="S6.T5.4.17.17.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">53.6</td>
</tr>
<tr id="S6.T5.4.18.18" class="ltx_tr">
<td id="S6.T5.4.18.18.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Koala 13B</td>
<td id="S6.T5.4.18.18.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">42.8</td>
<td id="S6.T5.4.18.18.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">72.6</td>
</tr>
<tr id="S6.T5.4.19.19" class="ltx_tr">
<td id="S6.T5.4.19.19.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Mosaic mpt-7B</td>
<td id="S6.T5.4.19.19.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">42.6</td>
<td id="S6.T5.4.19.19.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">76.3</td>
</tr>
<tr id="S6.T5.4.20.20" class="ltx_tr">
<td id="S6.T5.4.20.20.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_tt">LLAMA 2 70B</td>
<td id="S6.T5.4.20.20.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">-</td>
<td id="S6.T5.4.20.20.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">87.33</td>
</tr>
<tr id="S6.T5.4.21.21" class="ltx_tr">
<td id="S6.T5.4.21.21.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLAMA 65B</td>
<td id="S6.T5.4.21.21.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T5.4.21.21.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">86.09</td>
</tr>
<tr id="S6.T5.4.22.22" class="ltx_tr">
<td id="S6.T5.4.22.22.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Falcon 40B</td>
<td id="S6.T5.4.22.22.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T5.4.22.22.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">85.3</td>
</tr>
<tr id="S6.T5.4.23.23" class="ltx_tr">
<td id="S6.T5.4.23.23.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Falcon 180B</td>
<td id="S6.T5.4.23.23.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T5.4.23.23.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">88.86</td>
</tr>
<tr id="S6.T5.4.24.24" class="ltx_tr">
<td id="S6.T5.4.24.24.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MPT Instruct 30B</td>
<td id="S6.T5.4.24.24.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T5.4.24.24.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">84.31</td>
</tr>
<tr id="S6.T5.4.25.25" class="ltx_tr">
<td id="S6.T5.4.25.25.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MPT Instruct 7B</td>
<td id="S6.T5.4.25.25.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T5.4.25.25.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">77.91</td>
</tr>
<tr id="S6.T5.4.26.26" class="ltx_tr">
<td id="S6.T5.4.26.26.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Yi 6B</td>
<td id="S6.T5.4.26.26.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T5.4.26.26.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">76.42</td>
</tr>
<tr id="S6.T5.4.27.27" class="ltx_tr">
<td id="S6.T5.4.27.27.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Yi 34B</td>
<td id="S6.T5.4.27.27.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T5.4.27.27.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">85.69</td>
</tr>
<tr id="S6.T5.4.28.28" class="ltx_tr">
<td id="S6.T5.4.28.28.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT-4</td>
<td id="S6.T5.4.28.28.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T5.4.28.28.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S6.T5.4.28.28.3.1" class="ltx_text ltx_font_bold">95.3</span></td>
</tr>
<tr id="S6.T5.4.29.29" class="ltx_tr">
<td id="S6.T5.4.29.29.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Gemini Ultra</td>
<td id="S6.T5.4.29.29.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">-</td>
<td id="S6.T5.4.29.29.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">87.8</td>
</tr>
</tbody>
</table>
</figure>
<div id="S6.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S6.SS2.p2.1">표 <a class="ltx_ref" href="#S6.T5" title="TABLE V ‣ VI-B LLMs’ Performance on Different Tasks ‣ VI Prominent LLMs’ Performance on Benchmarks ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">V</span></a>에 제시된 결과로부터 GPT-4가 HellaSwag에 대해 최상의 결과를 달성하는 반면 Davinci-003은 OBQA에 대해 최상의 모델을 달성한다는 것이 분명하다. OBQA에 대한 결과가 모든 모델에 대해 보고되지 않으며 다빈치-003이 OBQA에서 가장 높은 결과를 달성하는 최상의 모델이 아니라는 점에 주목하는 것도 좋다.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para">
<p class="ltx_p" id="S6.SS2.p3.1">모든 모델이 모든 데이터 세트에 대한 성능을 보고하는 것은 아니며, 그 때문에 성능이 다른 테이블에서 보고되는 모델의 수가 다르다.</p>
</div>
<figure id="S6.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S6.T6.2.1.1" style="font-size:90%;">TABLE VI</span>:</span><span class="ltx_text" id="S6.T6.3.2" style="font-size:90%;">Symbolic reasoning comparison. </span></figcaption>
<table id="S6.T6.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T6.4.1.1" class="ltx_tr">
<th id="S6.T6.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">Model</th>
<th id="S6.T6.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Cobjects</th>
<th id="S6.T6.4.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">Penguins</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T6.4.2.1" class="ltx_tr">
<td id="S6.T6.4.2.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT-NeoX</td>
<td id="S6.T6.4.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">26</td>
<td id="S6.T6.4.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">33.56</td>
</tr>
<tr id="S6.T6.4.3.2" class="ltx_tr">
<td id="S6.T6.4.3.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">OPT 66B</td>
<td id="S6.T6.4.3.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">31.2</td>
<td id="S6.T6.4.3.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">28.08</td>
</tr>
<tr id="S6.T6.4.4.3" class="ltx_tr">
<td id="S6.T6.4.4.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Bloomberg GPT</td>
<td id="S6.T6.4.4.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">34.8</td>
<td id="S6.T6.4.4.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">37.67</td>
</tr>
<tr id="S6.T6.4.5.4" class="ltx_tr">
<td id="S6.T6.4.5.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">BLOOM 176B</td>
<td id="S6.T6.4.5.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">36.8</td>
<td id="S6.T6.4.5.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">40.41</td>
</tr>
<tr id="S6.T6.4.6.5" class="ltx_tr">
<td id="S6.T6.4.6.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">PaLM 540B</td>
<td id="S6.T6.4.6.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">38</td>
<td id="S6.T6.4.6.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">44.5</td>
</tr>
<tr id="S6.T6.4.7.6" class="ltx_tr">
<td id="S6.T6.4.7.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Gopher-280B</td>
<td id="S6.T6.4.7.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">49.2</td>
<td id="S6.T6.4.7.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">40.6</td>
</tr>
<tr id="S6.T6.4.8.7" class="ltx_tr">
<td id="S6.T6.4.8.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Chinchilla-70B</td>
<td id="S6.T6.4.8.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">59.7</td>
<td id="S6.T6.4.8.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">48.7</td>
</tr>
<tr id="S6.T6.4.9.8" class="ltx_tr">
<td id="S6.T6.4.9.8.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">PaLM 2</td>
<td id="S6.T6.4.9.8.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">61.2</td>
<td id="S6.T6.4.9.8.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">65.8</td>
</tr>
</tbody>
</table>
</figure>
<div id="S6.SS2.p4" class="ltx_para">
<p class="ltx_p" id="S6.SS2.p4.1">세계 지식은 대부분 일반적인 지식 질문에 관한 것으로, 예를 들어 위키팩트 데이터 세트에서 “특정 잘 알려진 책의 저자는 누구인가”와 같은 질문을 찾을 수 있고 참고 자료도 제공된다. 표 <a class="ltx_ref" href="#S6.T7" title="TABLE VII ‣ VI-B LLMs’ Performance on Different Tasks ‣ VI Prominent LLMs’ Performance on Benchmarks ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">VII</span></a>에 그 결과를 나타낸다.</p>
</div>
<figure id="S6.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S6.T7.2.1.1" style="font-size:90%;">TABLE VII</span>:</span><span class="ltx_text" id="S6.T7.3.2" style="font-size:90%;">World knowledge comparison. </span></figcaption>
<table id="S6.T7.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T7.4.1.1" class="ltx_tr">
<td id="S6.T7.4.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Model</td>
<td id="S6.T7.4.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">TriviaQA</td>
<td id="S6.T7.4.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">NaturalQ</td>
<td id="S6.T7.4.1.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">WebQ</td>
<td id="S6.T7.4.1.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">ARC</td>
</tr>
<tr id="S6.T7.4.2.2" class="ltx_tr">
<td id="S6.T7.4.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">BLOOM</td>
<td id="S6.T7.4.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.2.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.2.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">32.9</td>
</tr>
<tr id="S6.T7.4.3.3" class="ltx_tr">
<td id="S6.T7.4.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">BLOOM 176B</td>
<td id="S6.T7.4.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.3.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.3.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">50.85</td>
</tr>
<tr id="S6.T7.4.4.4" class="ltx_tr">
<td id="S6.T7.4.4.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Bloomberg GPT</td>
<td id="S6.T7.4.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.4.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">48.63</td>
</tr>
<tr id="S6.T7.4.5.5" class="ltx_tr">
<td id="S6.T7.4.5.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Chinchilla</td>
<td id="S6.T7.4.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">35.5</td>
<td id="S6.T7.4.5.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.5.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T7.4.6.6" class="ltx_tr">
<td id="S6.T7.4.6.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Codex + REPLUG</td>
<td id="S6.T7.4.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">76.8</td>
<td id="S6.T7.4.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">44.7</td>
<td id="S6.T7.4.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.6.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T7.4.7.7" class="ltx_tr">
<td id="S6.T7.4.7.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GAL 120B</td>
<td id="S6.T7.4.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.7.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.7.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">67.9</td>
</tr>
<tr id="S6.T7.4.8.8" class="ltx_tr">
<td id="S6.T7.4.8.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GLaM 62B/64E</td>
<td id="S6.T7.4.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">75.8</td>
<td id="S6.T7.4.8.8.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">32.5</td>
<td id="S6.T7.4.8.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">15.5</td>
<td id="S6.T7.4.8.8.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">50.3</td>
</tr>
<tr id="S6.T7.4.9.9" class="ltx_tr">
<td id="S6.T7.4.9.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Gopher</td>
<td id="S6.T7.4.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.9.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">28.2</td>
<td id="S6.T7.4.9.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.9.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T7.4.10.10" class="ltx_tr">
<td id="S6.T7.4.10.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT-3 175B</td>
<td id="S6.T7.4.10.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">71.2</td>
<td id="S6.T7.4.10.10.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">29.9</td>
<td id="S6.T7.4.10.10.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">41.5</td>
<td id="S6.T7.4.10.10.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">85.2</td>
</tr>
<tr id="S6.T7.4.11.11" class="ltx_tr">
<td id="S6.T7.4.11.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT-4</td>
<td id="S6.T7.4.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.11.11.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.11.11.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.11.11.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">96.4</td>
</tr>
<tr id="S6.T7.4.12.12" class="ltx_tr">
<td id="S6.T7.4.12.12.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT-NeoX</td>
<td id="S6.T7.4.12.12.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.12.12.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.12.12.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.12.12.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">45.39</td>
</tr>
<tr id="S6.T7.4.13.13" class="ltx_tr">
<td id="S6.T7.4.13.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLaMA 13B</td>
<td id="S6.T7.4.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.13.13.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.13.13.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.13.13.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">52.7</td>
</tr>
<tr id="S6.T7.4.14.14" class="ltx_tr">
<td id="S6.T7.4.14.14.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLaMA 2 70B</td>
<td id="S6.T7.4.14.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">85</td>
<td id="S6.T7.4.14.14.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">33</td>
<td id="S6.T7.4.14.14.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.14.14.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T7.4.15.15" class="ltx_tr">
<td id="S6.T7.4.15.15.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLaMA 33B</td>
<td id="S6.T7.4.15.15.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.15.15.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">24.9</td>
<td id="S6.T7.4.15.15.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.15.15.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">57.8</td>
</tr>
<tr id="S6.T7.4.16.16" class="ltx_tr">
<td id="S6.T7.4.16.16.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLaMA 65B</td>
<td id="S6.T7.4.16.16.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">72.6</td>
<td id="S6.T7.4.16.16.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">39.9</td>
<td id="S6.T7.4.16.16.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.16.16.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T7.4.17.17" class="ltx_tr">
<td id="S6.T7.4.17.17.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLaMA 7B</td>
<td id="S6.T7.4.17.17.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.17.17.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.17.17.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.17.17.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">47.6</td>
</tr>
<tr id="S6.T7.4.18.18" class="ltx_tr">
<td id="S6.T7.4.18.18.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Mistral 7B</td>
<td id="S6.T7.4.18.18.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">69.9</td>
<td id="S6.T7.4.18.18.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">28.8</td>
<td id="S6.T7.4.18.18.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.18.18.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">55.5</td>
</tr>
<tr id="S6.T7.4.19.19" class="ltx_tr">
<td id="S6.T7.4.19.19.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Neo-6B</td>
<td id="S6.T7.4.19.19.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.19.19.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">13.7</td>
<td id="S6.T7.4.19.19.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.19.19.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T7.4.20.20" class="ltx_tr">
<td id="S6.T7.4.20.20.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">OPT</td>
<td id="S6.T7.4.20.20.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.20.20.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.20.20.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.20.20.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">31.1</td>
</tr>
<tr id="S6.T7.4.21.21" class="ltx_tr">
<td id="S6.T7.4.21.21.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">OPT 66B</td>
<td id="S6.T7.4.21.21.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.21.21.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.21.21.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.21.21.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">44.54</td>
</tr>
<tr id="S6.T7.4.22.22" class="ltx_tr">
<td id="S6.T7.4.22.22.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">OPT-175B</td>
<td id="S6.T7.4.22.22.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.22.22.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.22.22.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.22.22.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">43.94</td>
</tr>
<tr id="S6.T7.4.23.23" class="ltx_tr">
<td id="S6.T7.4.23.23.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">OPT-175B</td>
<td id="S6.T7.4.23.23.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.23.23.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.23.23.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.23.23.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25.6</td>
</tr>
<tr id="S6.T7.4.24.24" class="ltx_tr">
<td id="S6.T7.4.24.24.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">PaLM 2-L</td>
<td id="S6.T7.4.24.24.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">86.1</td>
<td id="S6.T7.4.24.24.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">37.5</td>
<td id="S6.T7.4.24.24.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">28.2</td>
<td id="S6.T7.4.24.24.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.1</td>
</tr>
<tr id="S6.T7.4.25.25" class="ltx_tr">
<td id="S6.T7.4.25.25.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">PaLM 2-M</td>
<td id="S6.T7.4.25.25.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">81.7</td>
<td id="S6.T7.4.25.25.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">32</td>
<td id="S6.T7.4.25.25.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">26.9</td>
<td id="S6.T7.4.25.25.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">64.9</td>
</tr>
<tr id="S6.T7.4.26.26" class="ltx_tr">
<td id="S6.T7.4.26.26.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">PaLM 2-S</td>
<td id="S6.T7.4.26.26.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">75.2</td>
<td id="S6.T7.4.26.26.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">25.3</td>
<td id="S6.T7.4.26.26.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.8</td>
<td id="S6.T7.4.26.26.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">59.6</td>
</tr>
<tr id="S6.T7.4.27.27" class="ltx_tr">
<td id="S6.T7.4.27.27.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">PaLM-540B</td>
<td id="S6.T7.4.27.27.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">81.4</td>
<td id="S6.T7.4.27.27.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">39.6</td>
<td id="S6.T7.4.27.27.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">43.5</td>
<td id="S6.T7.4.27.27.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">87.1</td>
</tr>
<tr id="S6.T7.4.28.28" class="ltx_tr">
<td id="S6.T7.4.28.28.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">phi-1.5-web 1.3B</td>
<td id="S6.T7.4.28.28.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.28.28.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.28.28.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.28.28.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">44.9</td>
</tr>
<tr id="S6.T7.4.29.29" class="ltx_tr">
<td id="S6.T7.4.29.29.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">SparseGPT</td>
<td id="S6.T7.4.29.29.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.29.29.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.29.29.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.29.29.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">38.99</td>
</tr>
<tr id="S6.T7.4.30.30" class="ltx_tr">
<td id="S6.T7.4.30.30.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">SparseGPT</td>
<td id="S6.T7.4.30.30.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.30.30.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.30.30.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.30.30.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">39.85</td>
</tr>
<tr id="S6.T7.4.31.31" class="ltx_tr">
<td id="S6.T7.4.31.31.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">SparseGPT</td>
<td id="S6.T7.4.31.31.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.31.31.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.31.31.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">-</td>
<td id="S6.T7.4.31.31.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">41.3</td>
</tr>
</tbody>
</table>
</figure>
<div id="S6.SS2.p5" class="ltx_para">
<p class="ltx_p" id="S6.SS2.p5.1">특정 유스케이스 모델의 경우, 코딩 및 코드 생성 기능을 갖는 것이 매우 요구된다. 표 <a class="ltx_ref" href="#S6.T8" title="TABLE VIII ‣ VI-B LLMs’ Performance on Different Tasks ‣ VI Prominent LLMs’ Performance on Benchmarks ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">VIII</span></a>는 코딩 능력에 대한 서로 다른 모델의 결과를 보여준다.</p>
</div>
<figure id="S6.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S6.T8.2.1.1" style="font-size:90%;">TABLE VIII</span>:</span><span class="ltx_text" id="S6.T8.3.2" style="font-size:90%;">Coding capability comparison. </span></figcaption>
<table id="S6.T8.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T8.4.1.1" class="ltx_tr">
<th id="S6.T8.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Model</th>
<td id="S6.T8.4.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">HumanEval</td>
</tr>
<tr id="S6.T8.4.2.2" class="ltx_tr">
<th id="S6.T8.4.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Gemini Ultra</th>
<td id="S6.T8.4.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">74.4</td>
</tr>
<tr id="S6.T8.4.3.3" class="ltx_tr">
<th id="S6.T8.4.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Gemini Pro</th>
<td id="S6.T8.4.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">67.7</td>
</tr>
<tr id="S6.T8.4.4.4" class="ltx_tr">
<th id="S6.T8.4.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">GPT-4</th>
<td id="S6.T8.4.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">67</td>
</tr>
<tr id="S6.T8.4.5.5" class="ltx_tr">
<th id="S6.T8.4.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">WizardCoder 15B</th>
<td id="S6.T8.4.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">57.3</td>
</tr>
<tr id="S6.T8.4.6.6" class="ltx_tr">
<th id="S6.T8.4.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">phi-1 1.3B</th>
<td id="S6.T8.4.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">50.6</td>
</tr>
<tr id="S6.T8.4.7.7" class="ltx_tr">
<th id="S6.T8.4.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Code Llama</th>
<td id="S6.T8.4.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">48.8</td>
</tr>
<tr id="S6.T8.4.8.8" class="ltx_tr">
<th id="S6.T8.4.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">GPT-3.5</th>
<td id="S6.T8.4.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">48.1</td>
</tr>
<tr id="S6.T8.4.9.9" class="ltx_tr">
<th id="S6.T8.4.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">OctoCoder</th>
<td id="S6.T8.4.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">46.2</td>
</tr>
<tr id="S6.T8.4.10.10" class="ltx_tr">
<th id="S6.T8.4.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">phi-1-small</th>
<td id="S6.T8.4.10.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">45</td>
</tr>
<tr id="S6.T8.4.11.11" class="ltx_tr">
<th id="S6.T8.4.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">PaLM 2-S</th>
<td id="S6.T8.4.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">37.6</td>
</tr>
<tr id="S6.T8.4.12.12" class="ltx_tr">
<th id="S6.T8.4.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">InstructCodeT5+ 16B</th>
<td id="S6.T8.4.12.12.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">35</td>
</tr>
<tr id="S6.T8.4.13.13" class="ltx_tr">
<th id="S6.T8.4.13.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Mistral 7B</th>
<td id="S6.T8.4.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">30.5</td>
</tr>
<tr id="S6.T8.4.14.14" class="ltx_tr">
<th id="S6.T8.4.14.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">LLaMA 2</th>
<td id="S6.T8.4.14.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">29.9</td>
</tr>
<tr id="S6.T8.4.15.15" class="ltx_tr">
<th id="S6.T8.4.15.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">phi-1-base</th>
<td id="S6.T8.4.15.15.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">29</td>
</tr>
<tr id="S6.T8.4.16.16" class="ltx_tr">
<th id="S6.T8.4.16.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Codex-12B</th>
<td id="S6.T8.4.16.16.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">28.81</td>
</tr>
<tr id="S6.T8.4.17.17" class="ltx_tr">
<th id="S6.T8.4.17.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">PaLM 540B</th>
<td id="S6.T8.4.17.17.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">26.2</td>
</tr>
<tr id="S6.T8.4.18.18" class="ltx_tr">
<th id="S6.T8.4.18.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">CodeT5+ 2B</th>
<td id="S6.T8.4.18.18.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">24.2</td>
</tr>
<tr id="S6.T8.4.19.19" class="ltx_tr">
<th id="S6.T8.4.19.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">LLaMA 65B</th>
<td id="S6.T8.4.19.19.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">23.7</td>
</tr>
<tr id="S6.T8.4.20.20" class="ltx_tr">
<th id="S6.T8.4.20.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">LLaMA 33B</th>
<td id="S6.T8.4.20.20.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">21.7</td>
</tr>
<tr id="S6.T8.4.21.21" class="ltx_tr">
<th id="S6.T8.4.21.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">PaLM 62B</th>
<td id="S6.T8.4.21.21.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">15.9</td>
</tr>
<tr id="S6.T8.4.22.22" class="ltx_tr">
<th id="S6.T8.4.22.22.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">LLaMA 13B</th>
<td id="S6.T8.4.22.22.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">15.8</td>
</tr>
<tr id="S6.T8.4.23.23" class="ltx_tr">
<th id="S6.T8.4.23.23.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">LaMDA 137B</th>
<td id="S6.T8.4.23.23.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">14</td>
</tr>
<tr id="S6.T8.4.24.24" class="ltx_tr">
<th id="S6.T8.4.24.24.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">MIM-350M</th>
<td id="S6.T8.4.24.24.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">13.7</td>
</tr>
<tr id="S6.T8.4.25.25" class="ltx_tr">
<th id="S6.T8.4.25.25.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">LLaMA 7B</th>
<td id="S6.T8.4.25.25.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">10.5</td>
</tr>
<tr id="S6.T8.4.26.26" class="ltx_tr">
<th id="S6.T8.4.26.26.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">PaLM 8B</th>
<td id="S6.T8.4.26.26.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">3.6</td>
</tr>
</tbody>
</table>
</figure>
<div id="S6.SS2.p6" class="ltx_para">
<p class="ltx_p" id="S6.SS2.p6.1">산술 추론은 달성해야 할 또 다른 도전적인 추론 능력이다. 예를 들어 GSM8K는 답과 관련하여 초등학교 수학 문제를 포함한다. 표 <a class="ltx_ref" href="#S6.T9" title="TABLE IX ‣ VI-B LLMs’ Performance on Different Tasks ‣ VI Prominent LLMs’ Performance on Benchmarks ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">IX</span></a>는 서로 다른 모델 비교에 대한 통찰력을 제공한다.</p>
</div>
<figure id="S6.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S6.T9.2.1.1" style="font-size:90%;">TABLE IX</span>:</span><span class="ltx_text" id="S6.T9.3.2" style="font-size:90%;">Arithmetic reasoning comparison. </span></figcaption>
<table id="S6.T9.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T9.4.1.1" class="ltx_tr">
<td id="S6.T9.4.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Model</td>
<td id="S6.T9.4.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">GSM8k</td>
<td id="S6.T9.4.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">MATH</td>
</tr>
<tr id="S6.T9.4.2.2" class="ltx_tr">
<td id="S6.T9.4.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Gemini Ultra</td>
<td id="S6.T9.4.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">94.4</td>
<td id="S6.T9.4.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">53.2</td>
</tr>
<tr id="S6.T9.4.3.3" class="ltx_tr">
<td id="S6.T9.4.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT-4</td>
<td id="S6.T9.4.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">87.1</td>
<td id="S6.T9.4.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">42.5</td>
</tr>
<tr id="S6.T9.4.4.4" class="ltx_tr">
<td id="S6.T9.4.4.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Gemini Pro</td>
<td id="S6.T9.4.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">86.5</td>
<td id="S6.T9.4.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">32.6</td>
</tr>
<tr id="S6.T9.4.5.5" class="ltx_tr">
<td id="S6.T9.4.5.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">ToRA 70B</td>
<td id="S6.T9.4.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">84.3</td>
<td id="S6.T9.4.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">49.7</td>
</tr>
<tr id="S6.T9.4.6.6" class="ltx_tr">
<td id="S6.T9.4.6.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MathCoder-L-70B</td>
<td id="S6.T9.4.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">83.9</td>
<td id="S6.T9.4.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.7.7" class="ltx_tr">
<td id="S6.T9.4.7.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MetaMath 70B</td>
<td id="S6.T9.4.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">82.3</td>
<td id="S6.T9.4.7.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">26</td>
</tr>
<tr id="S6.T9.4.8.8" class="ltx_tr">
<td id="S6.T9.4.8.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MuggleMATH 70B</td>
<td id="S6.T9.4.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">82.3</td>
<td id="S6.T9.4.8.8.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.9.9" class="ltx_tr">
<td id="S6.T9.4.9.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MathCoder-CL-34B</td>
<td id="S6.T9.4.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">81.7</td>
<td id="S6.T9.4.9.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">45.2</td>
</tr>
<tr id="S6.T9.4.10.10" class="ltx_tr">
<td id="S6.T9.4.10.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">ToRA-Code 34B</td>
<td id="S6.T9.4.10.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">80.7</td>
<td id="S6.T9.4.10.10.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">50.8</td>
</tr>
<tr id="S6.T9.4.11.11" class="ltx_tr">
<td id="S6.T9.4.11.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MetaMath-Mistral-7B</td>
<td id="S6.T9.4.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">77.7</td>
<td id="S6.T9.4.11.11.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.12.12" class="ltx_tr">
<td id="S6.T9.4.12.12.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Arithmo2-Mistral-7B</td>
<td id="S6.T9.4.12.12.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">76.4</td>
<td id="S6.T9.4.12.12.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.13.13" class="ltx_tr">
<td id="S6.T9.4.13.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">ToRA-Code 13B</td>
<td id="S6.T9.4.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">75.8</td>
<td id="S6.T9.4.13.13.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">48.1</td>
</tr>
<tr id="S6.T9.4.14.14" class="ltx_tr">
<td id="S6.T9.4.14.14.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Arithmo-Mistral-7B</td>
<td id="S6.T9.4.14.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">74.7</td>
<td id="S6.T9.4.14.14.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.15.15" class="ltx_tr">
<td id="S6.T9.4.15.15.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MathCoder-CL-13B</td>
<td id="S6.T9.4.15.15.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">74.1</td>
<td id="S6.T9.4.15.15.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">35.9</td>
</tr>
<tr id="S6.T9.4.16.16" class="ltx_tr">
<td id="S6.T9.4.16.16.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MuggleMATH 13B</td>
<td id="S6.T9.4.16.16.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">74</td>
<td id="S6.T9.4.16.16.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.17.17" class="ltx_tr">
<td id="S6.T9.4.17.17.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">CodeT5+</td>
<td id="S6.T9.4.17.17.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">73.8</td>
<td id="S6.T9.4.17.17.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.18.18" class="ltx_tr">
<td id="S6.T9.4.18.18.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">KwaiYiiMath 13B</td>
<td id="S6.T9.4.18.18.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">73.3</td>
<td id="S6.T9.4.18.18.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.19.19" class="ltx_tr">
<td id="S6.T9.4.19.19.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">ToRA-Code 7B</td>
<td id="S6.T9.4.19.19.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">72.6</td>
<td id="S6.T9.4.19.19.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">44.6</td>
</tr>
<tr id="S6.T9.4.20.20" class="ltx_tr">
<td id="S6.T9.4.20.20.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MathCoder-L-13B</td>
<td id="S6.T9.4.20.20.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">72.6</td>
<td id="S6.T9.4.20.20.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">29.9</td>
</tr>
<tr id="S6.T9.4.21.21" class="ltx_tr">
<td id="S6.T9.4.21.21.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MetaMath 13B</td>
<td id="S6.T9.4.21.21.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">71</td>
<td id="S6.T9.4.21.21.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">22.5</td>
</tr>
<tr id="S6.T9.4.22.22" class="ltx_tr">
<td id="S6.T9.4.22.22.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLaMA 65B</td>
<td id="S6.T9.4.22.22.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">69.7</td>
<td id="S6.T9.4.22.22.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">10.6</td>
</tr>
<tr id="S6.T9.4.23.23" class="ltx_tr">
<td id="S6.T9.4.23.23.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MuggleMATH 7B</td>
<td id="S6.T9.4.23.23.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">68.4</td>
<td id="S6.T9.4.23.23.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.24.24" class="ltx_tr">
<td id="S6.T9.4.24.24.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MathCoder-CL-7B</td>
<td id="S6.T9.4.24.24.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">67.8</td>
<td id="S6.T9.4.24.24.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">23.3</td>
</tr>
<tr id="S6.T9.4.25.25" class="ltx_tr">
<td id="S6.T9.4.25.25.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MetaMath 7B</td>
<td id="S6.T9.4.25.25.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">66.4</td>
<td id="S6.T9.4.25.25.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">19.4</td>
</tr>
<tr id="S6.T9.4.26.26" class="ltx_tr">
<td id="S6.T9.4.26.26.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">RFT 70B</td>
<td id="S6.T9.4.26.26.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">64.8</td>
<td id="S6.T9.4.26.26.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.27.27" class="ltx_tr">
<td id="S6.T9.4.27.27.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">MathCoder-L-7B</td>
<td id="S6.T9.4.27.27.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">64.2</td>
<td id="S6.T9.4.27.27.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.28.28" class="ltx_tr">
<td id="S6.T9.4.28.28.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Orca 2-13B</td>
<td id="S6.T9.4.28.28.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">59.14</td>
<td id="S6.T9.4.28.28.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.29.29" class="ltx_tr">
<td id="S6.T9.4.29.29.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">U-PaLM</td>
<td id="S6.T9.4.29.29.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">58.5</td>
<td id="S6.T9.4.29.29.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.30.30" class="ltx_tr">
<td id="S6.T9.4.30.30.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">PaLM-540B</td>
<td id="S6.T9.4.30.30.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">58.1</td>
<td id="S6.T9.4.30.30.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">8.8</td>
</tr>
<tr id="S6.T9.4.31.31" class="ltx_tr">
<td id="S6.T9.4.31.31.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLaMA 2 70B</td>
<td id="S6.T9.4.31.31.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">56.8</td>
<td id="S6.T9.4.31.31.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.32.32" class="ltx_tr">
<td id="S6.T9.4.32.32.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">RFT 13B</td>
<td id="S6.T9.4.32.32.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">55.3</td>
<td id="S6.T9.4.32.32.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.33.33" class="ltx_tr">
<td id="S6.T9.4.33.33.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLaMA 33B</td>
<td id="S6.T9.4.33.33.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">53.1</td>
<td id="S6.T9.4.33.33.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">7.1</td>
</tr>
<tr id="S6.T9.4.34.34" class="ltx_tr">
<td id="S6.T9.4.34.34.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Mistral 7B</td>
<td id="S6.T9.4.34.34.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">52.2</td>
<td id="S6.T9.4.34.34.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">13.1</td>
</tr>
<tr id="S6.T9.4.35.35" class="ltx_tr">
<td id="S6.T9.4.35.35.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">RFT 7B</td>
<td id="S6.T9.4.35.35.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">51.2</td>
<td id="S6.T9.4.35.35.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.36.36" class="ltx_tr">
<td id="S6.T9.4.36.36.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLaMA 65B</td>
<td id="S6.T9.4.36.36.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">50.9</td>
<td id="S6.T9.4.36.36.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">20.5</td>
</tr>
<tr id="S6.T9.4.37.37" class="ltx_tr">
<td id="S6.T9.4.37.37.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Orca 2-7B</td>
<td id="S6.T9.4.37.37.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">47.23</td>
<td id="S6.T9.4.37.37.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.38.38" class="ltx_tr">
<td id="S6.T9.4.38.38.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Text-davinci-002</td>
<td id="S6.T9.4.38.38.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">40.7</td>
<td id="S6.T9.4.38.38.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">19.1</td>
</tr>
<tr id="S6.T9.4.39.39" class="ltx_tr">
<td id="S6.T9.4.39.39.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLaMA 33B</td>
<td id="S6.T9.4.39.39.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">35.6</td>
<td id="S6.T9.4.39.39.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3.9</td>
</tr>
<tr id="S6.T9.4.40.40" class="ltx_tr">
<td id="S6.T9.4.40.40.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT-Neo-2.7B</td>
<td id="S6.T9.4.40.40.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">19.5</td>
<td id="S6.T9.4.40.40.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.41.41" class="ltx_tr">
<td id="S6.T9.4.41.41.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLaMA 7B</td>
<td id="S6.T9.4.41.41.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">18.1</td>
<td id="S6.T9.4.41.41.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2.9</td>
</tr>
<tr id="S6.T9.4.42.42" class="ltx_tr">
<td id="S6.T9.4.42.42.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">PaLM 540B</td>
<td id="S6.T9.4.42.42.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">17.9</td>
<td id="S6.T9.4.42.42.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">8.8</td>
</tr>
<tr id="S6.T9.4.43.43" class="ltx_tr">
<td id="S6.T9.4.43.43.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLaMA 13B</td>
<td id="S6.T9.4.43.43.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">17.8</td>
<td id="S6.T9.4.43.43.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3.9</td>
</tr>
<tr id="S6.T9.4.44.44" class="ltx_tr">
<td id="S6.T9.4.44.44.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLaMA 7B</td>
<td id="S6.T9.4.44.44.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">11</td>
<td id="S6.T9.4.44.44.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2.9</td>
</tr>
<tr id="S6.T9.4.45.45" class="ltx_tr">
<td id="S6.T9.4.45.45.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT-Neo-125M</td>
<td id="S6.T9.4.45.45.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">7.5</td>
<td id="S6.T9.4.45.45.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T9.4.46.46" class="ltx_tr">
<td id="S6.T9.4.46.46.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">PaLM 8B</td>
<td id="S6.T9.4.46.46.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4.1</td>
<td id="S6.T9.4.46.46.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1.5</td>
</tr>
<tr id="S6.T9.4.47.47" class="ltx_tr">
<td id="S6.T9.4.47.47.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT-2</td>
<td id="S6.T9.4.47.47.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T9.4.47.47.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">5.4</td>
</tr>
<tr id="S6.T9.4.48.48" class="ltx_tr">
<td id="S6.T9.4.48.48.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT-3 175B</td>
<td id="S6.T9.4.48.48.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T9.4.48.48.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">5.2</td>
</tr>
<tr id="S6.T9.4.49.49" class="ltx_tr">
<td id="S6.T9.4.49.49.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">PaLM 62B</td>
<td id="S6.T9.4.49.49.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T9.4.49.49.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4.4</td>
</tr>
<tr id="S6.T9.4.50.50" class="ltx_tr">
<td id="S6.T9.4.50.50.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT-3-13B</td>
<td id="S6.T9.4.50.50.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T9.4.50.50.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3</td>
</tr>
<tr id="S6.T9.4.51.51" class="ltx_tr">
<td id="S6.T9.4.51.51.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">LLaMA 7B</td>
<td id="S6.T9.4.51.51.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">11</td>
<td id="S6.T9.4.51.51.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2.9</td>
</tr>
<tr id="S6.T9.4.52.52" class="ltx_tr">
<td id="S6.T9.4.52.52.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">PaLM 8B</td>
<td id="S6.T9.4.52.52.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">-</td>
<td id="S6.T9.4.52.52.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">1.5</td>
</tr>
</tbody>
</table>
</figure>
<div id="S6.SS2.p7" class="ltx_para">
<p class="ltx_p" id="S6.SS2.p7.1">대형 언어 모델은 단순히 다음 토큰 예측 기계이기 때문에 환각적인 답변을 하는 경우도 있다. 환각은 큰 언어 모델이 얼마나 신뢰할 수 있고 신뢰할 수 있는지를 측정하는 중요한 요소 중 하나이다. 다른 한편으로 환각을 측정하는 것은 각각의 사실이 다른 스타일로 쓰여질 수 있고 심지어 글의 작은 변화조차도 감지하기 어렵게 만들기 때문에 보기 때문에 쉽지 않다. 특정 LLM이 텍스트에서 잘못된 정보의 환각을 감지할 수 있는 능력이 더 있다면 더 신뢰할 수 있다고 가정하는 것이 옳다. HaluEval은 이 필드 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib205" title="">205</a>]</cite>에서 환각을 측정하는 것을 목표로 하는 데이터 세트 중 하나이다. 실제 답변 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib206" title="">206</a>]</cite>와 관련하여 응답을 판단하는 다른 모델에 의해서도 평가를 수행할 수 있다. 표 <a class="ltx_ref" href="#S6.T10" title="TABLE X ‣ VI-B LLMs’ Performance on Different Tasks ‣ VI Prominent LLMs’ Performance on Benchmarks ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">X</span></a>는 이러한 데이터 세트를 기반으로 한 서로 다른 모델의 평가를 보여준다.</p>
</div>
<figure id="S6.T10" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S6.T10.2.1.1" style="font-size:90%;">TABLE X</span>:</span><span class="ltx_text" id="S6.T10.3.2" style="font-size:90%;">Hallucination evaluation</span></figcaption>
<table id="S6.T10.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T10.4.1.1" class="ltx_tr">
<td id="S6.T10.4.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Model</td>
<td id="S6.T10.4.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">HHEM</td>
<td id="S6.T10.4.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">HaluEval QA</td>
<td id="S6.T10.4.1.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">HaluEval Dialogue</td>
<td id="S6.T10.4.1.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">HaluEval Sum.</td>
<td id="S6.T10.4.1.1.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">HaluEval General</td>
</tr>
<tr id="S6.T10.4.2.2" class="ltx_tr">
<td id="S6.T10.4.2.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT 4</td>
<td id="S6.T10.4.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">97</td>
<td id="S6.T10.4.2.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.2.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.2.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.2.2.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.3.3" class="ltx_tr">
<td id="S6.T10.4.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT 4 Turbo</td>
<td id="S6.T10.4.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">97</td>
<td id="S6.T10.4.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.3.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.3.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.3.3.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.4.4" class="ltx_tr">
<td id="S6.T10.4.4.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT 3.5 Turbo</td>
<td id="S6.T10.4.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">96.5</td>
<td id="S6.T10.4.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">62.59</td>
<td id="S6.T10.4.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">72.4</td>
<td id="S6.T10.4.4.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">58.53</td>
<td id="S6.T10.4.4.4.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">79.44</td>
</tr>
<tr id="S6.T10.4.5.5" class="ltx_tr">
<td id="S6.T10.4.5.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Davinci002</td>
<td id="S6.T10.4.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">60.05</td>
<td id="S6.T10.4.5.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">60.81</td>
<td id="S6.T10.4.5.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">47.77</td>
<td id="S6.T10.4.5.5.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">80.42</td>
</tr>
<tr id="S6.T10.4.6.6" class="ltx_tr">
<td id="S6.T10.4.6.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Davinci003</td>
<td id="S6.T10.4.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">49.65</td>
<td id="S6.T10.4.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">68.37</td>
<td id="S6.T10.4.6.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">48.07</td>
<td id="S6.T10.4.6.6.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">80.4</td>
</tr>
<tr id="S6.T10.4.7.7" class="ltx_tr">
<td id="S6.T10.4.7.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">GPT-3</td>
<td id="S6.T10.4.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.7.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">49.21</td>
<td id="S6.T10.4.7.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">50.02</td>
<td id="S6.T10.4.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">51.23</td>
<td id="S6.T10.4.7.7.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">72.72</td>
</tr>
<tr id="S6.T10.4.8.8" class="ltx_tr">
<td id="S6.T10.4.8.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Google Gemini Pro</td>
<td id="S6.T10.4.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">95.2</td>
<td id="S6.T10.4.8.8.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.8.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.8.8.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.8.8.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.9.9" class="ltx_tr">
<td id="S6.T10.4.9.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Llama 2 70B</td>
<td id="S6.T10.4.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">94.9</td>
<td id="S6.T10.4.9.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.9.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.9.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.9.9.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.10.10" class="ltx_tr">
<td id="S6.T10.4.10.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Llama 2 7B</td>
<td id="S6.T10.4.10.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">94.4</td>
<td id="S6.T10.4.10.10.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">49.6</td>
<td id="S6.T10.4.10.10.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">43.99</td>
<td id="S6.T10.4.10.10.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">49.55</td>
<td id="S6.T10.4.10.10.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">20.46</td>
</tr>
<tr id="S6.T10.4.11.11" class="ltx_tr">
<td id="S6.T10.4.11.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Llama 2 13B</td>
<td id="S6.T10.4.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">94.1</td>
<td id="S6.T10.4.11.11.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.11.11.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.11.11.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.11.11.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.12.12" class="ltx_tr">
<td id="S6.T10.4.12.12.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Cohere-Chat</td>
<td id="S6.T10.4.12.12.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">92.5</td>
<td id="S6.T10.4.12.12.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.12.12.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.12.12.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.12.12.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.13.13" class="ltx_tr">
<td id="S6.T10.4.13.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Cohere</td>
<td id="S6.T10.4.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">91.5</td>
<td id="S6.T10.4.13.13.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.13.13.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.13.13.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.13.13.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.14.14" class="ltx_tr">
<td id="S6.T10.4.14.14.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Claude 2</td>
<td id="S6.T10.4.14.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">91.5</td>
<td id="S6.T10.4.14.14.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">69.78</td>
<td id="S6.T10.4.14.14.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">64.73</td>
<td id="S6.T10.4.14.14.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">57.75</td>
<td id="S6.T10.4.14.14.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">75</td>
</tr>
<tr id="S6.T10.4.15.15" class="ltx_tr">
<td id="S6.T10.4.15.15.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Claude 1</td>
<td id="S6.T10.4.15.15.2" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S6.T10.4.15.15.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">67.6</td>
<td id="S6.T10.4.15.15.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">64.83</td>
<td id="S6.T10.4.15.15.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">53.76</td>
<td id="S6.T10.4.15.15.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">73.88</td>
</tr>
<tr id="S6.T10.4.16.16" class="ltx_tr">
<td id="S6.T10.4.16.16.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Microsoft Phi 2</td>
<td id="S6.T10.4.16.16.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">91.5</td>
<td id="S6.T10.4.16.16.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.16.16.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.16.16.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.16.16.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.17.17" class="ltx_tr">
<td id="S6.T10.4.17.17.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Google Palm 2 (beta)</td>
<td id="S6.T10.4.17.17.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">91.4</td>
<td id="S6.T10.4.17.17.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.17.17.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.17.17.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.17.17.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.18.18" class="ltx_tr">
<td id="S6.T10.4.18.18.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Mixtral 8x7B</td>
<td id="S6.T10.4.18.18.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">90.7</td>
<td id="S6.T10.4.18.18.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.18.18.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.18.18.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.18.18.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.19.19" class="ltx_tr">
<td id="S6.T10.4.19.19.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Amazon Titan Express</td>
<td id="S6.T10.4.19.19.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">90.6</td>
<td id="S6.T10.4.19.19.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.19.19.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.19.19.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.19.19.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.20.20" class="ltx_tr">
<td id="S6.T10.4.20.20.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Mistral 7B</td>
<td id="S6.T10.4.20.20.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">90.6</td>
<td id="S6.T10.4.20.20.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.20.20.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.20.20.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.20.20.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.21.21" class="ltx_tr">
<td id="S6.T10.4.21.21.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Google Palm 2 Chat (beta)</td>
<td id="S6.T10.4.21.21.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">90</td>
<td id="S6.T10.4.21.21.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.21.21.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.21.21.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.21.21.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.22.22" class="ltx_tr">
<td id="S6.T10.4.22.22.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Google Palm 2</td>
<td id="S6.T10.4.22.22.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">87.9</td>
<td id="S6.T10.4.22.22.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.22.22.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.22.22.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.22.22.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.23.23" class="ltx_tr">
<td id="S6.T10.4.23.23.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Google Palm 2 Chat</td>
<td id="S6.T10.4.23.23.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">72.8</td>
<td id="S6.T10.4.23.23.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.23.23.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.23.23.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.23.23.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="S6.T10.4.24.24" class="ltx_tr">
<td id="S6.T10.4.24.24.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">ChatGLM</td>
<td id="S6.T10.4.24.24.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.24.24.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">47.93</td>
<td id="S6.T10.4.24.24.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">44.41</td>
<td id="S6.T10.4.24.24.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">48.57</td>
<td id="S6.T10.4.24.24.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">30.92</td>
</tr>
<tr id="S6.T10.4.25.25" class="ltx_tr">
<td id="S6.T10.4.25.25.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Falcon</td>
<td id="S6.T10.4.25.25.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.25.25.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">39.66</td>
<td id="S6.T10.4.25.25.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">29.08</td>
<td id="S6.T10.4.25.25.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">42.71</td>
<td id="S6.T10.4.25.25.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">18.98</td>
</tr>
<tr id="S6.T10.4.26.26" class="ltx_tr">
<td id="S6.T10.4.26.26.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">Vicuna</td>
<td id="S6.T10.4.26.26.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.26.26.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">60.34</td>
<td id="S6.T10.4.26.26.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">46.35</td>
<td id="S6.T10.4.26.26.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">45.62</td>
<td id="S6.T10.4.26.26.6" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">19.48</td>
</tr>
<tr id="S6.T10.4.27.27" class="ltx_tr">
<td id="S6.T10.4.27.27.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Alpaca</td>
<td id="S6.T10.4.27.27.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">-</td>
<td id="S6.T10.4.27.27.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">6.68</td>
<td id="S6.T10.4.27.27.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">17.55</td>
<td id="S6.T10.4.27.27.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">20.63</td>
<td id="S6.T10.4.27.27.6" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">9.54</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">Challenges and Future Directions</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p class="ltx_p" id="S7.p1.1">이전 섹션에서 보았듯이 대형 언어 모델은 지난 1-2년 동안 인상적인 결과를 달성했다. 동시에 이것은 여전히 둔화되기보다는 혁신의 속도가 증가하고 있는 새롭고 매우 활발한 연구 분야이다. 그러나 다른 진화하는 영역과 마찬가지로 아직 많은 도전이 남아 있다. 여기에서 우리는 지금까지 알려진 몇 가지 도전과 주요 활동 영역을 간략하게 언급한다. LLM 과제가 Kaddour et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib207" title="">207</a>]</cite>의 작업에서 자세히 논의된다는 점은 주목할 가치가 있다.</p>
</div>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS1.5.1.1" class="ltx_text">VII-A</span> </span><span id="S7.SS1.6.2" class="ltx_text ltx_font_italic">Smaller and more efficient Language Models</span>
</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS1.p1.1">이것은 <em class="ltx_emph ltx_font_italic" id="S7.SS1.p1.1.1">large</em> 언어 모델에 대한 조사이며, GPT-4와 같은 훨씬 더 큰 모델이 벤치마크에서 더 나은 정확도와 성능을 얻는 데 분명히 보상을 받는 "larger is better"를 향한 초기 추진이 있었다. 그러나 이러한 대규모 모델은 여러 차원(예: 높은 대기 시간)에서 비용이 많이 들고 비효율적이다. 이 모든 것에 대응하여, 특히 더 큰 모델의 전체 일반성을 필요로 하지 않을 수 있는 특정 작업에 사용될 때 LLMs에 대한 비용 효율적인 대안으로 작은 언어 모델(SLMs)을 고안하려는 현재 연구 경향이 있다. 이러한 방향으로 두드러진 작품으로는 Microsoft사의 Phi-1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib208" title="">208</a>]</cite>, Phi-1.5 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib209" title="">209</a>]</cite>, Phi-2 등이 있다.</p>
</div>
<div id="S7.SS1.p2" class="ltx_para">
<p class="ltx_p" id="S7.SS1.p2.1">더 일반적으로, 우리는 더 작고 효율적인 모델을 훈련하는 방법에 대한 이 분야에서 많은 연구 노력을 기대해야 한다. 매개 변수 효율적인 미세 조정(PEFT), 교사/학생 및 기타 형태의 증류(섹션 <a class="ltx_ref" href="#S3.SS9" title="III-I Cost-Effective Training/Inference/Adaptation/Compression ‣ III How LLMs Are Built ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-I</span></span></a> 참조)와 같은 기술은 더 큰 모델 중에서 더 작은 모델을 구축하는 데 계속 사용됩니다.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS2.5.1.1" class="ltx_text">VII-B</span> </span><span id="S7.SS2.6.2" class="ltx_text ltx_font_italic">New Post-attention Architectural Paradigms</span>
</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS2.p1.1">트랜스포머 블록은 현재 대부분의 LLM 프레임워크의 중요하고 지속적인 부분이며, 이 아키텍처가 얼마나 오랫동안 유행할 것인지, 그리고 딥 러닝(및 NLP) 분야에서 다음 큰 아키텍처 돌파구는 무엇인지에 대한 큰 물음표이다. 2012년 AlexNet 이후, 우리는 LSTM, GRU, seq2seq 등 많은 아키텍처가 유행과 퇴출하는 것을 보았지만, 트랜스포머는 그 시작부터 지배적인 접근법이었다. 앞서 설명한 바와 같이 변압기를 구동하는 주요 메커니즘에는 관심이 있다. 보다 최근에는 주의 후라고 명명되는 대안적 접근법에 대한 유망한 연구가 있었다.</p>
</div>
<div id="S7.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S7.SS2.p2.1">이러한 주의 후 모델의 중요한 클래스는 소위 State Space Models(SSMs)이다. 상태 공간 모델들의 개념은 기계 학습에서 오랜 역사를 가지고 있지만, 언어 모델들의 맥락에서, SSM은 일반적으로 새로운 구조 상태 공간 모델 아키텍처 또는 줄여서 S4를 참조하여 사용된다(Gu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib29" title="">29</a>]</cite> 참조). 이 범주의 일부 최신 모델은 Mamba <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>, Hyena <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib210" title="">210</a>]</cite>, Striped Hyena <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib211" title="">211</a>]</cite>이다.</p>
</div>
<div id="S7.SS2.p3" class="ltx_para">
<p class="ltx_p" id="S7.SS2.p3.1">이러한 모든 모델은 리더보드 성능 및 효율성 측면에서 매우 경쟁적이지만 보다 전통적인 주의 기반 아키텍처에서 중요한 문제를 해결합니다. <em class="ltx_emph ltx_font_italic" id="S7.SS2.p3.1.1">더 큰 컨텍스트 창에 대한 지원 부족</em>.</p>
</div>
<div id="S7.SS2.p4" class="ltx_para">
<p class="ltx_p" id="S7.SS2.p4.1">많은 프롬프트에 대한 좋은 답변을 얻으려면 컨텍스트가 필요합니다. 예를 들어 ‘나에게 좋은 영화를 추천해줘’에 대한 반응은 ‘나’에 대한 맥락은 물론 어떤 영화가 있고 어떤 영화를 보지 않았는지 등에 대한 맥락이 많이 필요하다. 컨텍스트 길이는 RAG에 특히 중요하며, 여기서 텍스트의 많은 부분이 검색되고 생성을 위해 프롬프트에 주입될 수 있다(섹션 <a class="ltx_ref" href="#S4.SS3" title="IV-C Augmenting LLMs through external knowledge - RAG ‣ IV How LLMs Are Used and Augmented ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-C</span></span></a> 참조).</p>
</div>
<div id="S7.SS2.p5" class="ltx_para">
<p class="ltx_p" id="S7.SS2.p5.1">컨텍스트 길이가 길수록, 우리는 컨텍스트에 더 많은 토큰을 압착할 수 있다. 모델이 더 많은 정보에 접근할수록 모델의 응답은 더 좋아집니다. 그러나 다른 한편으로는, 매우 긴 문맥을 가지고 있어서, 모델이 모든 것을 기억하고 모든 정보를 효율적으로 처리하는 것은 어려울 것이다. 주목 기반 모델은 더 긴 컨텍스트에 대해 매우 비효율적이며, 따라서 우리는 더 긴 컨텍스트를 처리할 수 있고 일반적으로 더 효율적인 아키텍처를 제공하는 다양한 메커니즘에서 더 많은 연구를 기대해야 한다.</p>
</div>
<div id="S7.SS2.p6" class="ltx_para">
<p class="ltx_p" id="S7.SS2.p6.1">즉, 새로운 아키텍처는 주의 메커니즘을 위한 대안을 제안할 뿐만 아니라 전체 트랜스포머 아키텍처를 다시 생각할 수 있다. 이에 대한 초기 예로서, Monarch Mixer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib212" title="">212</a>]</cite>는 시퀀스 길이와 모델 차원을 따라 GPU – Monarch 행렬 – 에서 높은 하드웨어 효율성을 달성하는 동일한 하위 2차 프리미티브를 사용하는 새로운 아키텍처를 제안한다.</p>
</div>
<div id="S7.SS2.p7" class="ltx_para">
<p class="ltx_p" id="S7.SS2.p7.1">스펙트럼의 다른 쪽 끝에는 최근에 증기를 얻고 더 좋고 더 강력한 LLM을 만드는 데 가치를 입증하는 몇 가지 주의 호환 아키텍처 메커니즘이 있다는 점을 언급할 가치가 있다. 아마도 그러한 메커니즘의 가장 좋은 예는 전문가 혼합(MoE)일 것이다. MoE는 딥 러닝 시대 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib213" title="">213</a>]</cite> 이전에도 수년 동안 머신 러닝에 존재했지만 이후, 특히 트랜스포머 모델과 LLM의 맥락에서 인기를 얻고 있다.</p>
</div>
<div id="S7.SS2.p8" class="ltx_para">
<p class="ltx_p" id="S7.SS2.p8.1">LLM에서 MoE는 게이팅/가중치 기능이 할당된 가중치가 낮은 곳이면 전문가 중 일부가 꺼질 때 추론 중에 부분적으로만 인스턴스화되는 것보다 매우 큰 모델을 훈련할 수 있다. 예를 들어, GLaM 모델은 1.2조 개의 파라미터를 갖지만, 추론 동안 64명의 전문가 중 2명만이 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib84" title="">84</a>]</cite>를 사용한다.</p>
</div>
<div id="S7.SS2.p9" class="ltx_para">
<p class="ltx_p" id="S7.SS2.p9.1">MoEs는 오늘날 소위 프런티어 LLM(즉, 가장 진보되고 유능한 모델)의 중요한 구성요소이다. GPT-4 자체는 MoE 아키텍처를 기반으로 한다고 알려져 있으며, Mixtral <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib117" title="">117</a>]</cite>와 같은 가장 성능이 좋은 LLM 중 일부는 기본적으로 기존 LLM의 MoE 버전이다.</p>
</div>
<div id="S7.SS2.p10" class="ltx_para">
<p class="ltx_p" id="S7.SS2.p10.1">마지막으로, MoEs가 주목 여부에 관계없이 임의의 아키텍처의 컴포넌트로서 사용될 수 있다는 점에 유의하는 것이 중요하다. 사실, MoE는 Mamba Citepioro2024moemamba와 같은 SSM 기반 LLM에도 적용되었다. 우리는 기본 아키텍처에 관계없이 향후 MoE 기반 개선을 계속 보아야 한다.</p>
</div>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS3.5.1.1" class="ltx_text">VII-C</span> </span><span id="S7.SS3.6.2" class="ltx_text ltx_font_italic">Multi-modal Models</span>
</h3>

<div id="S7.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS3.p1.1">향후 LLM은 멀티모달이 될 것으로 예상되며 텍스트, 이미지, 비디오, 오디오 등 다양한 데이터 유형을 통일적으로 처리할 수 있다. 이는 질의 응답, 콘텐츠 생성, 창작 예술, 의료, 로봇 공학 및 그 이상과 같은 분야에서 보다 다양한 응용을 위한 가능성을 열어준다. LLAVA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib214" title="">214</a>]</cite>, LLAVA-Plus <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib215" title="">215</a>]</cite>, GPT-4 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>, Qwen-vl <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib116" title="">116</a>]</cite>, Next-GPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib216" title="">216</a>]</cite> 등 이미 몇 개의 두드러진 멀티모달 LLMs가 존재하지만 그 추세는 계속될 것으로 예상된다. 이러한 모델에 대한 평가 또한 새로운 연구 주제이며, 특히 대화 생성 비전 모델 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib217" title="">217</a>]</cite>이다. 멀티모달 LLM은 다양한 작업에서 거대한 잠재력을 발휘할 수 있으며, 모든 세부 사항을 논의하기 위한 전용 논문이 필요한 이 방향으로 이미 하강 진전이 있었다.</p>
</div>
</section>
<section id="S7.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS4.5.1.1" class="ltx_text">VII-D</span> </span><span id="S7.SS4.6.2" class="ltx_text ltx_font_italic">Improved LLM Usage and Augmentation techniques</span>
</h3>

<div id="S7.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS4.p1.1"><a class="ltx_ref" href="#S4" title="IV How LLMs Are Used and Augmented ‣ Large Language Models: A Survey"><span class="ltx_text ltx_ref_tag">IV</span></a> 섹션에서 설명한 바와 같이 <em class="ltx_emph ltx_font_italic" id="S7.SS4.p1.1.1">hallucination</em>과 같은 LLM의 많은 단점과 한계는 고급 프롬프트 엔지니어링, 도구 사용 또는 기타 증강 기술을 통해 해결할 수 있다. 우리는 이 분야에서 지속적인 연구뿐만 아니라 가속화된 연구를 기대해야 한다. 소프트웨어 엔지니어링의 특정 사례에서 일부 작업(<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib218" title="">218</a>]</cite>)이 전체 소프트웨어 엔지니어링 워크플로에서 이 문제를 자동으로 제거하려고 시도했다는 점을 언급할 가치가 있습니다.</p>
</div>
<div id="S7.SS4.p2" class="ltx_para">
<p class="ltx_p" id="S7.SS4.p2.1">LLM 기반 시스템은 이미 최근까지 다른 접근법을 사용하던 기계 학습 시스템을 대체하기 시작했다. 이것의 명확한 예로서, LLMs는 이제 사람들의 선호도와 관심사를 더 잘 이해하고, 고객 서비스, 콘텐츠 추천, 또는 다른 애플리케이션에서든지, 보다 개인화된 상호 작용을 제공하기 위해 전개되고 있다. 이것은 사용자 선호도에 대한 더 나은 이해와 그들의 과거 상호 작용을 분석하고 컨텍스트로 사용하는 것을 포함한다. 우리는 <em class="ltx_emph ltx_font_italic" id="S7.SS4.p2.1.1">personalization and recommendations</em> 뿐만 아니라 다른 기계 학습 기술을 사용하는 많은 다른 응용 분야에 대한 LLM의 응용 및 사용에 대한 연구를 계속 볼 것이다.</p>
</div>
<div id="S7.SS4.p3" class="ltx_para">
<p class="ltx_p" id="S7.SS4.p3.1">마지막으로, 우리가 관심을 끌 것으로 예상되는 또 다른 중요한 연구 분야는 <em class="ltx_emph ltx_font_italic" id="S7.SS4.p3.1.1">LLM 기반 에이전트 및 다중 에이전트 시스템</em> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib172" title="">172</a>, <a class="ltx_ref" href="#bib.bib173" title="">173</a>, <a class="ltx_ref" href="#bib.bib174" title="">174</a>]</cite>이다. 외부 도구에 대한 접근과 의사 결정 능력을 갖춘 LLM 시스템의 개발은 흥미롭고 도전적이다. 우리는 일각에서 인공지능(AGI)으로 이어질 수 있다고 주장하는 이 중요한 분야에서 지속적인 연구와 진전을 보게 될 것이다.</p>
</div>
</section>
<section id="S7.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS5.5.1.1" class="ltx_text">VII-E</span> </span><span id="S7.SS5.6.2" class="ltx_text ltx_font_italic">Security and Ethical/Responsible AI</span>
</h3>

<div id="S7.SS5.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS5.p1.1">적대적 공격 및 기타 취약성에 대한 LLM의 견고성과 보안을 보장하는 것은 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib219" title="">219</a>]</cite>의 중요한 영역이다. LLM이 실제 응용 프로그램에 점점 더 많이 배포됨에 따라 잠재적인 위협으로부터 보호되어야 하며, 사람을 조작하거나 잘못된 정보를 퍼뜨리는 데 사용되는 것을 방지해야 한다.</p>
</div>
<div id="S7.SS5.p2" class="ltx_para">
<p class="ltx_p" id="S7.SS5.p2.1">LLM의 윤리적 우려와 편견을 해결하는 것은 또 다른 활발한 연구 분야이다. LLM이 공정하고, 편파적이지 않으며, 민감한 정보를 책임감 있게 처리할 수 있도록 하기 위한 노력이 이루어지고 있다. LLM이 매일 많은 사람들에 의해 점점 더 많이 사용되고 있기 때문에, 그들이 편파적이지 않고 책임감 있게 행동하는지 확인하는 것이 중요하다.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VIII </span><span id="S8.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S8.p1" class="ltx_para">
<p class="ltx_p" id="S8.p1.1">본 논문은 최근 몇 년 동안 개발된 LLMs에 대한 설문 조사를 제시한다. 먼저 초기 사전 훈련 언어 모델(예: BERT)에 대한 개요를 제공한 다음 세 가지 인기 있는 LLM 패밀리(GPT, LLaMA, PaLM) 및 기타 대표적인 LLM을 검토한다. 그런 다음 LLM을 구축하고, 증강하고, 사용하는 방법과 기술을 조사한다. 우리는 인기 있는 LLM 데이터 세트와 벤치마크를 검토하고 공개 벤치마크에서 두드러진 모델 세트의 성능을 비교한다. 마지막으로, 우리는 열린 도전과제와 향후 연구 방향을 제시한다.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
J.&nbsp;Kaplan, S.&nbsp;McCandlish, T.&nbsp;Henighan, T.&nbsp;B. Brown, B.&nbsp;Chess, R.&nbsp;Child, S.&nbsp;Gray, A.&nbsp;Radford, J.&nbsp;Wu, and D.&nbsp;Amodei, “Scaling laws for neural language models,” <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.08361</em>, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
J.&nbsp;Hoffmann, S.&nbsp;Borgeaud, A.&nbsp;Mensch, E.&nbsp;Buchatskaya, T.&nbsp;Cai, E.&nbsp;Rutherford, D.&nbsp;d.&nbsp;L. Casas, L.&nbsp;A. Hendricks, J.&nbsp;Welbl, A.&nbsp;Clark <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Training compute-optimal large language models,” <em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.15556</em>, 2022.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
C.&nbsp;E. Shannon, “Prediction and entropy of printed english,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Bell system technical journal</em>, vol.&nbsp;30, no.&nbsp;1, pp. 50–64, 1951.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
F.&nbsp;Jelinek, <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Statistical methods for speech recognition</em>.&nbsp;&nbsp;&nbsp;MIT press, 1998.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
C.&nbsp;Manning and H.&nbsp;Schutze, <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Foundations of statistical natural language processing</em>.&nbsp;&nbsp;&nbsp;MIT press, 1999.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
C.&nbsp;D. Manning, <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">An introduction to information retrieval</em>.&nbsp;&nbsp;&nbsp;Cambridge university press, 2009.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
W.&nbsp;X. Zhao, K.&nbsp;Zhou, J.&nbsp;Li, T.&nbsp;Tang, X.&nbsp;Wang, Y.&nbsp;Hou, Y.&nbsp;Min, B.&nbsp;Zhang, J.&nbsp;Zhang, Z.&nbsp;Dong <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “A survey of large language models,” <em id="bib.bib7.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.18223</em>, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
C.&nbsp;Zhou, Q.&nbsp;Li, C.&nbsp;Li, J.&nbsp;Yu, Y.&nbsp;Liu, G.&nbsp;Wang, K.&nbsp;Zhang, C.&nbsp;Ji, Q.&nbsp;Yan, L.&nbsp;He <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “A comprehensive survey on pretrained foundation models: A history from bert to chatgpt,” <em id="bib.bib8.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.09419</em>, 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
P.&nbsp;Liu, W.&nbsp;Yuan, J.&nbsp;Fu, Z.&nbsp;Jiang, H.&nbsp;Hayashi, and G.&nbsp;Neubig, “Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys</em>, vol.&nbsp;55, no.&nbsp;9, pp. 1–35, 2023.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Q.&nbsp;Dong, L.&nbsp;Li, D.&nbsp;Dai, C.&nbsp;Zheng, Z.&nbsp;Wu, B.&nbsp;Chang, X.&nbsp;Sun, J.&nbsp;Xu, and Z.&nbsp;Sui, “A survey for in-context learning,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.00234</em>, 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
J.&nbsp;Huang and K.&nbsp;C.-C. Chang, “Towards reasoning in large language models: A survey,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.10403</em>, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
S.&nbsp;F. Chen and J.&nbsp;Goodman, “An empirical study of smoothing techniques for language modeling,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Computer Speech &amp; Language</em>, vol.&nbsp;13, no.&nbsp;4, pp. 359–394, 1999.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Y.&nbsp;Bengio, R.&nbsp;Ducharme, and P.&nbsp;Vincent, “A neural probabilistic language model,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol.&nbsp;13, 2000.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
H.&nbsp;Schwenk, D.&nbsp;Déchelotte, and J.-L. Gauvain, “Continuous space language models for statistical machine translation,” in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions</em>, 2006, pp. 723–730.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
T.&nbsp;Mikolov, M.&nbsp;Karafiát, L.&nbsp;Burget, J.&nbsp;Cernockỳ, and S.&nbsp;Khudanpur, “Recurrent neural network based language model.” in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, vol.&nbsp;2, no.&nbsp;3.&nbsp;&nbsp;&nbsp;Makuhari, 2010, pp. 1045–1048.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
A.&nbsp;Graves, “Generating sequences with recurrent neural networks,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1308.0850</em>, 2013.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
P.-S. Huang, X.&nbsp;He, J.&nbsp;Gao, L.&nbsp;Deng, A.&nbsp;Acero, and L.&nbsp;Heck, “Learning deep structured semantic models for web search using clickthrough data,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 22nd ACM international conference on Information &amp; Knowledge Management</em>, 2013, pp. 2333–2338.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
J.&nbsp;Gao, C.&nbsp;Xiong, P.&nbsp;Bennett, and N.&nbsp;Craswell, <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Neural Approaches to Conversational Information Retrieval</em>.&nbsp;&nbsp;&nbsp;Springer Nature, 2023, vol.&nbsp;44.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
I.&nbsp;Sutskever, O.&nbsp;Vinyals, and Q.&nbsp;V. Le, “Sequence to sequence learning with neural networks,” <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol.&nbsp;27, 2014.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
K.&nbsp;Cho, B.&nbsp;Van&nbsp;Merriënboer, D.&nbsp;Bahdanau, and Y.&nbsp;Bengio, “On the properties of neural machine translation: Encoder-decoder approaches,” <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1409.1259</em>, 2014.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
H.&nbsp;Fang, S.&nbsp;Gupta, F.&nbsp;Iandola, R.&nbsp;K. Srivastava, L.&nbsp;Deng, P.&nbsp;Dollár, J.&nbsp;Gao, X.&nbsp;He, M.&nbsp;Mitchell, J.&nbsp;C. Platt <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “From captions to visual concepts and back,” in <em id="bib.bib21.2.2" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, 2015, pp. 1473–1482.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
O.&nbsp;Vinyals, A.&nbsp;Toshev, S.&nbsp;Bengio, and D.&nbsp;Erhan, “Show and tell: A neural image caption generator,” in <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, 2015, pp. 3156–3164.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
M.&nbsp;E. Peters, M.&nbsp;Neumann, M.&nbsp;Iyyer, M.&nbsp;Gardner, C.&nbsp;Clark, K.&nbsp;Lee, and L.&nbsp;Zettlemoyer, “Deep contextualized word representations. corr abs/1802.05365 (2018),” <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1802.05365</em>, 2018.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
J.&nbsp;Devlin, M.-W. Chang, K.&nbsp;Lee, and K.&nbsp;Toutanova, “Bert: Pre-training of deep bidirectional transformers for language understanding,” <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1810.04805</em>, 2018.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Y.&nbsp;Liu, M.&nbsp;Ott, N.&nbsp;Goyal, J.&nbsp;Du, M.&nbsp;Joshi, D.&nbsp;Chen, O.&nbsp;Levy, M.&nbsp;Lewis, L.&nbsp;Zettlemoyer, and V.&nbsp;Stoyanov, “Roberta: A robustly optimized bert pretraining approach,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1907.11692</em>, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
P.&nbsp;He, X.&nbsp;Liu, J.&nbsp;Gao, and W.&nbsp;Chen, “Deberta: Decoding-enhanced bert with disentangled attention,” <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.03654</em>, 2020.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
X.&nbsp;Han, Z.&nbsp;Zhang, N.&nbsp;Ding, Y.&nbsp;Gu, X.&nbsp;Liu, Y.&nbsp;Huo, J.&nbsp;Qiu, Y.&nbsp;Yao, A.&nbsp;Zhang, L.&nbsp;Zhang <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Pre-trained models: Past, present and future,” <em id="bib.bib27.2.2" class="ltx_emph ltx_font_italic">AI Open</em>, vol.&nbsp;2, pp. 225–250, 2021.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
X.&nbsp;Qiu, T.&nbsp;Sun, Y.&nbsp;Xu, Y.&nbsp;Shao, N.&nbsp;Dai, and X.&nbsp;Huang, “Pre-trained models for natural language processing: A survey,” <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Science China Technological Sciences</em>, vol.&nbsp;63, no.&nbsp;10, pp. 1872–1897, 2020.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
A.&nbsp;Gu, K.&nbsp;Goel, and C.&nbsp;Ré, “Efficiently modeling long sequences with structured state spaces,” 2022.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
A.&nbsp;Gu and T.&nbsp;Dao, “Mamba: Linear-time sequence modeling with selective state spaces,” <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.00752</em>, 2023.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
A.&nbsp;Chowdhery, S.&nbsp;Narang, J.&nbsp;Devlin, M.&nbsp;Bosma, G.&nbsp;Mishra, A.&nbsp;Roberts, P.&nbsp;Barham, H.&nbsp;W. Chung, C.&nbsp;Sutton, S.&nbsp;Gehrmann <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Palm: Scaling language modeling with pathways,” <em id="bib.bib31.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.02311</em>, 2022.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
H.&nbsp;Touvron, T.&nbsp;Lavril, G.&nbsp;Izacard, X.&nbsp;Martinet, M.-A. Lachaux, T.&nbsp;Lacroix, B.&nbsp;Rozière, N.&nbsp;Goyal, E.&nbsp;Hambro, F.&nbsp;Azhar <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Llama: Open and efficient foundation language models,” <em id="bib.bib32.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.13971</em>, 2023.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
OpenAI, “GPT-4 Technical Report,” <a target="_blank" href="https://arxiv.org/pdf/2303.08774v3.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/pdf/2303.08774v3.pdf</a>, 2023.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
J.&nbsp;Wei, X.&nbsp;Wang, D.&nbsp;Schuurmans, M.&nbsp;Bosma, b.&nbsp;ichter, F.&nbsp;Xia, E.&nbsp;Chi, Q.&nbsp;V. Le, and D.&nbsp;Zhou, “Chain-of-thought prompting elicits reasoning in large language models,” in <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, S.&nbsp;Koyejo, S.&nbsp;Mohamed, A.&nbsp;Agarwal, D.&nbsp;Belgrave, K.&nbsp;Cho, and A.&nbsp;Oh, Eds., vol.&nbsp;35.&nbsp;&nbsp;&nbsp;Curran Associates, Inc., 2022, pp. 24 824–24 837. [Online]. Available: <a target="_blank" href="https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf</a>

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
G.&nbsp;Mialon, R.&nbsp;Dessì, M.&nbsp;Lomeli, C.&nbsp;Nalmpantis, R.&nbsp;Pasunuru, R.&nbsp;Raileanu, B.&nbsp;Rozière, T.&nbsp;Schick, J.&nbsp;Dwivedi-Yu, A.&nbsp;Celikyilmaz <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Augmented language models: a survey,” <em id="bib.bib35.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.07842</em>, 2023.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
B.&nbsp;Peng, M.&nbsp;Galley, P.&nbsp;He, H.&nbsp;Cheng, Y.&nbsp;Xie, Y.&nbsp;Hu, Q.&nbsp;Huang, L.&nbsp;Liden, Z.&nbsp;Yu, W.&nbsp;Chen, and J.&nbsp;Gao, “Check your facts and try again: Improving large language models with external knowledge and automated feedback,” <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.12813</em>, 2023.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
S.&nbsp;Yao, J.&nbsp;Zhao, D.&nbsp;Yu, N.&nbsp;Du, I.&nbsp;Shafran, K.&nbsp;Narasimhan, and Y.&nbsp;Cao, “React: Synergizing reasoning and acting in language models,” <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.03629</em>, 2022.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
D.&nbsp;E. Rumelhart, G.&nbsp;E. Hinton, R.&nbsp;J. Williams <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Learning internal representations by error propagation,” 1985.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
J.&nbsp;L. Elman, “Finding structure in time,” <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Cognitive science</em>, vol.&nbsp;14, no.&nbsp;2, pp. 179–211, 1990.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
M.&nbsp;V. Mahoney, “Fast text compression with neural networks.” in <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">FLAIRS conference</em>, 2000, pp. 230–234.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
T.&nbsp;Mikolov, A.&nbsp;Deoras, D.&nbsp;Povey, L.&nbsp;Burget, and J.&nbsp;Černockỳ, “Strategies for training large scale neural network language models,” in <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">2011 IEEE Workshop on Automatic Speech Recognition &amp; Understanding</em>.&nbsp;&nbsp;&nbsp;IEEE, 2011, pp. 196–201.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
tmikolov. rnnlm. [Online]. Available: <a target="_blank" href="https://www.fit.vutbr.cz/~imikolov/rnnlm/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.fit.vutbr.cz/~imikolov/rnnlm/</a>

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
S.&nbsp;Minaee, N.&nbsp;Kalchbrenner, E.&nbsp;Cambria, N.&nbsp;Nikzad, M.&nbsp;Chenaghlu, and J.&nbsp;Gao, “Deep learning–based text classification: a comprehensive review,” <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">ACM computing surveys (CSUR)</em>, vol.&nbsp;54, no.&nbsp;3, pp. 1–40, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
A.&nbsp;Vaswani, N.&nbsp;Shazeer, N.&nbsp;Parmar, J.&nbsp;Uszkoreit, L.&nbsp;Jones, A.&nbsp;N. Gomez, <span id="bib.bib44.1.1" class="ltx_text ltx_font_caligraphic">L</span>.&nbsp;Kaiser, and I.&nbsp;Polosukhin, “Attention is all you need,” <em id="bib.bib44.2.2" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol.&nbsp;30, 2017.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Z.&nbsp;Lan, M.&nbsp;Chen, S.&nbsp;Goodman, K.&nbsp;Gimpel, P.&nbsp;Sharma, and R.&nbsp;Soricut, “Albert: A lite bert for self-supervised learning of language representations,” <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.11942</em>, 2019.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
K.&nbsp;Clark, M.-T. Luong, Q.&nbsp;V. Le, and C.&nbsp;D. Manning, “Electra: Pre-training text encoders as discriminators rather than generators,” <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.10555</em>, 2020.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
G.&nbsp;Lample and A.&nbsp;Conneau, “Cross-lingual language model pretraining,” <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1901.07291</em>, 2019.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Z.&nbsp;Yang, Z.&nbsp;Dai, Y.&nbsp;Yang, J.&nbsp;Carbonell, R.&nbsp;R. Salakhutdinov, and Q.&nbsp;V. Le, “Xlnet: Generalized autoregressive pretraining for language understanding,” <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol.&nbsp;32, 2019.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
L.&nbsp;Dong, N.&nbsp;Yang, W.&nbsp;Wang, F.&nbsp;Wei, X.&nbsp;Liu, Y.&nbsp;Wang, J.&nbsp;Gao, M.&nbsp;Zhou, and H.-W. Hon, “Unified language model pre-training for natural language understanding and generation,” <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol.&nbsp;32, 2019.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
A.&nbsp;Radford, K.&nbsp;Narasimhan, T.&nbsp;Salimans, I.&nbsp;Sutskever <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Improving language understanding by generative pre-training,” 2018.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
A.&nbsp;Radford, J.&nbsp;Wu, R.&nbsp;Child, D.&nbsp;Luan, D.&nbsp;Amodei, I.&nbsp;Sutskever <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Language models are unsupervised multitask learners,” <em id="bib.bib51.2.2" class="ltx_emph ltx_font_italic">OpenAI blog</em>, vol.&nbsp;1, no.&nbsp;8, p.&nbsp;9, 2019.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
C.&nbsp;Raffel, N.&nbsp;Shazeer, A.&nbsp;Roberts, K.&nbsp;Lee, S.&nbsp;Narang, M.&nbsp;Matena, Y.&nbsp;Zhou, W.&nbsp;Li, and P.&nbsp;J. Liu, “Exploring the limits of transfer learning with a unified text-to-text transformer,” <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">The Journal of Machine Learning Research</em>, vol.&nbsp;21, no.&nbsp;1, pp. 5485–5551, 2020.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
L.&nbsp;Xue, N.&nbsp;Constant, A.&nbsp;Roberts, M.&nbsp;Kale, R.&nbsp;Al-Rfou, A.&nbsp;Siddhant, A.&nbsp;Barua, and C.&nbsp;Raffel, “mt5: A massively multilingual pre-trained text-to-text transformer,” <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.11934</em>, 2020.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
K.&nbsp;Song, X.&nbsp;Tan, T.&nbsp;Qin, J.&nbsp;Lu, and T.-Y. Liu, “Mass: Masked sequence to sequence pre-training for language generation,” <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.02450</em>, 2019.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
M.&nbsp;Lewis, Y.&nbsp;Liu, N.&nbsp;Goyal, M.&nbsp;Ghazvininejad, A.&nbsp;Mohamed, O.&nbsp;Levy, V.&nbsp;Stoyanov, and L.&nbsp;Zettlemoyer, “Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension,” <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.13461</em>, 2019.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
T.&nbsp;Brown, B.&nbsp;Mann, N.&nbsp;Ryder, M.&nbsp;Subbiah, J.&nbsp;D. Kaplan, P.&nbsp;Dhariwal, A.&nbsp;Neelakantan, P.&nbsp;Shyam, G.&nbsp;Sastry, A.&nbsp;Askell <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Language models are few-shot learners,” <em id="bib.bib56.2.2" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol.&nbsp;33, pp. 1877–1901, 2020.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
M.&nbsp;Chen, J.&nbsp;Tworek, H.&nbsp;Jun, Q.&nbsp;Yuan, H.&nbsp;P. d.&nbsp;O. Pinto, J.&nbsp;Kaplan, H.&nbsp;Edwards, Y.&nbsp;Burda, N.&nbsp;Joseph, G.&nbsp;Brockman <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Evaluating large language models trained on code,” <em id="bib.bib57.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.03374</em>, 2021.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
R.&nbsp;Nakano, J.&nbsp;Hilton, S.&nbsp;Balaji, J.&nbsp;Wu, L.&nbsp;Ouyang, C.&nbsp;Kim, C.&nbsp;Hesse, S.&nbsp;Jain, V.&nbsp;Kosaraju, W.&nbsp;Saunders <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Webgpt: Browser-assisted question-answering with human feedback,” <em id="bib.bib58.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2112.09332</em>, 2021.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
L.&nbsp;Ouyang, J.&nbsp;Wu, X.&nbsp;Jiang, D.&nbsp;Almeida, C.&nbsp;Wainwright, P.&nbsp;Mishkin, C.&nbsp;Zhang, S.&nbsp;Agarwal, K.&nbsp;Slama, A.&nbsp;Ray <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Training language models to follow instructions with human feedback,” <em id="bib.bib59.2.2" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol.&nbsp;35, pp. 27 730–27 744, 2022.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
OpenAI. (2022) Introducing chatgpt. [Online]. Available: <a target="_blank" href="https://openai.com/blog/chatgpt" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openai.com/blog/chatgpt</a>

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
H.&nbsp;Touvron, L.&nbsp;Martin, K.&nbsp;Stone, P.&nbsp;Albert, A.&nbsp;Almahairi, Y.&nbsp;Babaei, N.&nbsp;Bashlykov, S.&nbsp;Batra, P.&nbsp;Bhargava, S.&nbsp;Bhosale <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Llama 2: Open foundation and fine-tuned chat models,” <em id="bib.bib61.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.09288</em>, 2023.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
R.&nbsp;Taori, I.&nbsp;Gulrajani, T.&nbsp;Zhang, Y.&nbsp;Dubois, X.&nbsp;Li, C.&nbsp;Guestrin, P.&nbsp;Liang, and T.&nbsp;B. Hashimoto, “Alpaca: A strong, replicable instruction-following model,” <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">Stanford Center for Research on Foundation Models. https://crfm. stanford. edu/2023/03/13/alpaca. html</em>, vol.&nbsp;3, no.&nbsp;6, p.&nbsp;7, 2023.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
T.&nbsp;Dettmers, A.&nbsp;Pagnoni, A.&nbsp;Holtzman, and L.&nbsp;Zettlemoyer, “Qlora: Efficient finetuning of quantized llms,” <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.14314</em>, 2023.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
X.&nbsp;Geng, A.&nbsp;Gudibande, H.&nbsp;Liu, E.&nbsp;Wallace, P.&nbsp;Abbeel, S.&nbsp;Levine, and D.&nbsp;Song, “Koala: A dialogue model for academic research,” <em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">Blog post, April</em>, vol.&nbsp;1, 2023.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
A.&nbsp;Q. Jiang, A.&nbsp;Sablayrolles, A.&nbsp;Mensch, C.&nbsp;Bamford, D.&nbsp;S. Chaplot, D.&nbsp;d.&nbsp;l. Casas, F.&nbsp;Bressand, G.&nbsp;Lengyel, G.&nbsp;Lample, L.&nbsp;Saulnier <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Mistral 7b,” <em id="bib.bib65.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.06825</em>, 2023.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
B.&nbsp;Roziere, J.&nbsp;Gehring, F.&nbsp;Gloeckle, S.&nbsp;Sootla, I.&nbsp;Gat, X.&nbsp;E. Tan, Y.&nbsp;Adi, J.&nbsp;Liu, T.&nbsp;Remez, J.&nbsp;Rapin <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Code llama: Open foundation models for code,” <em id="bib.bib66.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.12950</em>, 2023.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
S.&nbsp;G. Patil, T.&nbsp;Zhang, X.&nbsp;Wang, and J.&nbsp;E. Gonzalez, “Gorilla: Large language model connected with massive apis,” 2023.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
A.&nbsp;Pal, D.&nbsp;Karkhanis, M.&nbsp;Roberts, S.&nbsp;Dooley, A.&nbsp;Sundararajan, and S.&nbsp;Naidu, “Giraffe: Adventures in expanding context lengths in llms,” <em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.10882</em>, 2023.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
B.&nbsp;Huang, “Vigogne: French instruction-following and chat models,” <a target="_blank" href="https://github.com/bofenghuang/vigogne" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/bofenghuang/vigogne</a>, 2023.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Y.&nbsp;Wang, H.&nbsp;Ivison, P.&nbsp;Dasigi, J.&nbsp;Hessel, T.&nbsp;Khot, K.&nbsp;R. Chandu, D.&nbsp;Wadden, K.&nbsp;MacMillan, N.&nbsp;A. Smith, I.&nbsp;Beltagy <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “How far can camels go? exploring the state of instruction tuning on open resources,” <em id="bib.bib70.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.04751</em>, 2023.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
S.&nbsp;Tworkowski, K.&nbsp;Staniszewski, M.&nbsp;Pacek, Y.&nbsp;Wu, H.&nbsp;Michalewski, and P.&nbsp;Miłoś, “Focused transformer: Contrastive training for context scaling,” <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.03170</em>, 2023.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
D.&nbsp;Mahan, R.&nbsp;Carlow, L.&nbsp;Castricato, N.&nbsp;Cooper, and C.&nbsp;Laforte, “Stable beluga models.” [Online]. Available: <a href="%5Bhttps://huggingface.co/stabilityai/StableBeluga2%5D(https://huggingface.co/stabilityai/StableBeluga2)" title="" class="ltx_ref ltx_url ltx_font_typewriter">[https://huggingface.co/stabilityai/StableBeluga2](https://huggingface.co/stabilityai/StableBeluga2)</a>

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Y.&nbsp;Tay, J.&nbsp;Wei, H.&nbsp;W. Chung, V.&nbsp;Q. Tran, D.&nbsp;R. So, S.&nbsp;Shakeri, X.&nbsp;Garcia, H.&nbsp;S. Zheng, J.&nbsp;Rao, A.&nbsp;Chowdhery <em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Transcending scaling laws with 0.1% extra compute,” <em id="bib.bib73.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.11399</em>, 2022.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
H.&nbsp;W. Chung, L.&nbsp;Hou, S.&nbsp;Longpre, B.&nbsp;Zoph, Y.&nbsp;Tay, W.&nbsp;Fedus, Y.&nbsp;Li, X.&nbsp;Wang, M.&nbsp;Dehghani, S.&nbsp;Brahma <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Scaling instruction-finetuned language models,” <em id="bib.bib74.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.11416</em>, 2022.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
R.&nbsp;Anil, A.&nbsp;M. Dai, O.&nbsp;Firat, M.&nbsp;Johnson, D.&nbsp;Lepikhin, A.&nbsp;Passos, S.&nbsp;Shakeri, E.&nbsp;Taropa, P.&nbsp;Bailey, Z.&nbsp;Chen <em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Palm 2 technical report,” <em id="bib.bib75.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.10403</em>, 2023.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
K.&nbsp;Singhal, S.&nbsp;Azizi, T.&nbsp;Tu, S.&nbsp;S. Mahdavi, J.&nbsp;Wei, H.&nbsp;W. Chung, N.&nbsp;Scales, A.&nbsp;Tanwani, H.&nbsp;Cole-Lewis, S.&nbsp;Pfohl <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Large language models encode clinical knowledge,” <em id="bib.bib76.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.13138</em>, 2022.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
K.&nbsp;Singhal, T.&nbsp;Tu, J.&nbsp;Gottweis, R.&nbsp;Sayres, E.&nbsp;Wulczyn, L.&nbsp;Hou, K.&nbsp;Clark, S.&nbsp;Pfohl, H.&nbsp;Cole-Lewis, D.&nbsp;Neal <em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Towards expert-level medical question answering with large language models,” <em id="bib.bib77.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.09617</em>, 2023.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
J.&nbsp;Wei, M.&nbsp;Bosma, V.&nbsp;Y. Zhao, K.&nbsp;Guu, A.&nbsp;W. Yu, B.&nbsp;Lester, N.&nbsp;Du, A.&nbsp;M. Dai, and Q.&nbsp;V. Le, “Finetuned language models are zero-shot learners,” <em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.01652</em>, 2021.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
J.&nbsp;W. Rae, S.&nbsp;Borgeaud, T.&nbsp;Cai, K.&nbsp;Millican, J.&nbsp;Hoffmann, F.&nbsp;Song, J.&nbsp;Aslanides, S.&nbsp;Henderson, R.&nbsp;Ring, S.&nbsp;Young <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Scaling language models: Methods, analysis &amp; insights from training gopher,” <em id="bib.bib79.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2112.11446</em>, 2021.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
V.&nbsp;Sanh, A.&nbsp;Webson, C.&nbsp;Raffel, S.&nbsp;H. Bach, L.&nbsp;Sutawika, Z.&nbsp;Alyafeai, A.&nbsp;Chaffin, A.&nbsp;Stiegler, T.&nbsp;L. Scao, A.&nbsp;Raja <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Multitask prompted training enables zero-shot task generalization,” <em id="bib.bib80.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.08207</em>, 2021.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
Y.&nbsp;Sun, S.&nbsp;Wang, S.&nbsp;Feng, S.&nbsp;Ding, C.&nbsp;Pang, J.&nbsp;Shang, J.&nbsp;Liu, X.&nbsp;Chen, Y.&nbsp;Zhao, Y.&nbsp;Lu <em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Ernie 3.0: Large-scale knowledge enhanced pre-training for language understanding and generation,” <em id="bib.bib81.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.02137</em>, 2021.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
S.&nbsp;Borgeaud, A.&nbsp;Mensch, J.&nbsp;Hoffmann, T.&nbsp;Cai, E.&nbsp;Rutherford, K.&nbsp;Millican, G.&nbsp;B. Van Den&nbsp;Driessche, J.-B. Lespiau, B.&nbsp;Damoc, A.&nbsp;Clark <em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Improving language models by retrieving from trillions of tokens,” in <em id="bib.bib82.2.2" class="ltx_emph ltx_font_italic">International conference on machine learning</em>.&nbsp;&nbsp;&nbsp;PMLR, 2022, pp. 2206–2240.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
O.&nbsp;Lieber, O.&nbsp;Sharir, B.&nbsp;Lenz, and Y.&nbsp;Shoham, “Jurassic-1: Technical details and evaluation,” <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">White Paper. AI21 Labs</em>, vol.&nbsp;1, p.&nbsp;9, 2021.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
N.&nbsp;Du, Y.&nbsp;Huang, A.&nbsp;M. Dai, S.&nbsp;Tong, D.&nbsp;Lepikhin, Y.&nbsp;Xu, M.&nbsp;Krikun, Y.&nbsp;Zhou, A.&nbsp;W. Yu, O.&nbsp;Firat <em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Glam: Efficient scaling of language models with mixture-of-experts,” in <em id="bib.bib84.2.2" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.&nbsp;&nbsp;&nbsp;PMLR, 2022, pp. 5547–5569.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
R.&nbsp;Thoppilan, D.&nbsp;De&nbsp;Freitas, J.&nbsp;Hall, N.&nbsp;Shazeer, A.&nbsp;Kulshreshtha, H.-T. Cheng, A.&nbsp;Jin, T.&nbsp;Bos, L.&nbsp;Baker, Y.&nbsp;Du <em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Lamda: Language models for dialog applications,” <em id="bib.bib85.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.08239</em>, 2022.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
S.&nbsp;Zhang, S.&nbsp;Roller, N.&nbsp;Goyal, M.&nbsp;Artetxe, M.&nbsp;Chen, S.&nbsp;Chen, C.&nbsp;Dewan, M.&nbsp;Diab, X.&nbsp;Li, X.&nbsp;V. Lin <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Opt: Open pre-trained transformer language models,” <em id="bib.bib86.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.01068</em>, 2022.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
R.&nbsp;Taylor, M.&nbsp;Kardas, G.&nbsp;Cucurull, T.&nbsp;Scialom, A.&nbsp;Hartshorn, E.&nbsp;Saravia, A.&nbsp;Poulton, V.&nbsp;Kerkez, and R.&nbsp;Stojnic, “Galactica: A large language model for science,” <em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.09085</em>, 2022.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
E.&nbsp;Nijkamp, B.&nbsp;Pang, H.&nbsp;Hayashi, L.&nbsp;Tu, H.&nbsp;Wang, Y.&nbsp;Zhou, S.&nbsp;Savarese, and C.&nbsp;Xiong, “Codegen: An open large language model for code with multi-turn program synthesis,” <em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2203.13474</em>, 2022.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
S.&nbsp;Soltan, S.&nbsp;Ananthakrishnan, J.&nbsp;FitzGerald, R.&nbsp;Gupta, W.&nbsp;Hamza, H.&nbsp;Khan, C.&nbsp;Peris, S.&nbsp;Rawls, A.&nbsp;Rosenbaum, A.&nbsp;Rumshisky <em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Alexatm 20b: Few-shot learning using a large-scale multilingual seq2seq model,” <em id="bib.bib89.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2208.01448</em>, 2022.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
A.&nbsp;Glaese, N.&nbsp;McAleese, M.&nbsp;Trebacz, J.&nbsp;Aslanides, V.&nbsp;Firoiu, T.&nbsp;Ewalds, M.&nbsp;Rauh, L.&nbsp;Weidinger, M.&nbsp;Chadwick, P.&nbsp;Thacker <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Improving alignment of dialogue agents via targeted human judgements,” <em id="bib.bib90.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2209.14375</em>, 2022.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
A.&nbsp;Lewkowycz, A.&nbsp;Andreassen, D.&nbsp;Dohan, E.&nbsp;Dyer, H.&nbsp;Michalewski, V.&nbsp;Ramasesh, A.&nbsp;Slone, C.&nbsp;Anil, I.&nbsp;Schlag, T.&nbsp;Gutman-Solo <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Solving quantitative reasoning problems with language models,” <em id="bib.bib91.2.2" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, vol.&nbsp;35, pp. 3843–3857, 2022.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
Y.&nbsp;Tay, M.&nbsp;Dehghani, V.&nbsp;Q. Tran, X.&nbsp;Garcia, D.&nbsp;Bahri, T.&nbsp;Schuster, H.&nbsp;S. Zheng, N.&nbsp;Houlsby, and D.&nbsp;Metzler, “Unifying language learning paradigms,” <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.05131</em>, 2022.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
T.&nbsp;L. Scao, A.&nbsp;Fan, C.&nbsp;Akiki, E.&nbsp;Pavlick, S.&nbsp;Ilić, D.&nbsp;Hesslow, R.&nbsp;Castagné, A.&nbsp;S. Luccioni, F.&nbsp;Yvon, M.&nbsp;Gallé <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Bloom: A 176b-parameter open-access multilingual language model,” <em id="bib.bib93.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.05100</em>, 2022.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
A.&nbsp;Zeng, X.&nbsp;Liu, Z.&nbsp;Du, Z.&nbsp;Wang, H.&nbsp;Lai, M.&nbsp;Ding, Z.&nbsp;Yang, Y.&nbsp;Xu, W.&nbsp;Zheng, X.&nbsp;Xia <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Glm-130b: An open bilingual pre-trained model,” <em id="bib.bib94.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.02414</em>, 2022.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
S.&nbsp;Biderman, H.&nbsp;Schoelkopf, Q.&nbsp;G. Anthony, H.&nbsp;Bradley, K.&nbsp;O’Brien, E.&nbsp;Hallahan, M.&nbsp;A. Khan, S.&nbsp;Purohit, U.&nbsp;S. Prashanth, E.&nbsp;Raff <em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Pythia: A suite for analyzing large language models across training and scaling,” in <em id="bib.bib95.2.2" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.&nbsp;&nbsp;&nbsp;PMLR, 2023, pp. 2397–2430.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
S.&nbsp;Mukherjee, A.&nbsp;Mitra, G.&nbsp;Jawahar, S.&nbsp;Agarwal, H.&nbsp;Palangi, and A.&nbsp;Awadallah, “Orca: Progressive learning from complex explanation traces of gpt-4,” <em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.02707</em>, 2023.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
R.&nbsp;Li, L.&nbsp;B. Allal, Y.&nbsp;Zi, N.&nbsp;Muennighoff, D.&nbsp;Kocetkov, C.&nbsp;Mou, M.&nbsp;Marone, C.&nbsp;Akiki, J.&nbsp;Li, J.&nbsp;Chim <em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Starcoder: may the source be with you!” <em id="bib.bib97.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.06161</em>, 2023.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
S.&nbsp;Huang, L.&nbsp;Dong, W.&nbsp;Wang, Y.&nbsp;Hao, S.&nbsp;Singhal, S.&nbsp;Ma, T.&nbsp;Lv, L.&nbsp;Cui, O.&nbsp;K. Mohammed, Q.&nbsp;Liu <em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Language is not all you need: Aligning perception with language models,” <em id="bib.bib98.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.14045</em>, 2023.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
G.&nbsp;Team, R.&nbsp;Anil, S.&nbsp;Borgeaud, Y.&nbsp;Wu, J.-B. Alayrac, J.&nbsp;Yu, R.&nbsp;Soricut, J.&nbsp;Schalkwyk, A.&nbsp;M. Dai, A.&nbsp;Hauth <em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Gemini: a family of highly capable multimodal models,” <em id="bib.bib99.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.11805</em>, 2023.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
W.&nbsp;Huang, F.&nbsp;Xia, T.&nbsp;Xiao, H.&nbsp;Chan, J.&nbsp;Liang, P.&nbsp;Florence, A.&nbsp;Zeng, J.&nbsp;Tompson, I.&nbsp;Mordatch, Y.&nbsp;Chebotar <em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Inner monologue: Embodied reasoning through planning with language models,” <em id="bib.bib100.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2207.05608</em>, 2022.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
S.&nbsp;Smith, M.&nbsp;Patwary, B.&nbsp;Norick, P.&nbsp;LeGresley, S.&nbsp;Rajbhandari, J.&nbsp;Casper, Z.&nbsp;Liu, S.&nbsp;Prabhumoye, G.&nbsp;Zerveas, V.&nbsp;Korthikanti <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Using deepspeed and megatron to train megatron-turing nlg 530b, a large-scale generative language model,” <em id="bib.bib101.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2201.11990</em>, 2022.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
I.&nbsp;Beltagy, M.&nbsp;E. Peters, and A.&nbsp;Cohan, “Longformer: The long-document transformer,” <em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.05150</em>, 2020.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
S.&nbsp;Iyer, X.&nbsp;V. Lin, R.&nbsp;Pasunuru, T.&nbsp;Mihaylov, D.&nbsp;Simig, P.&nbsp;Yu, K.&nbsp;Shuster, T.&nbsp;Wang, Q.&nbsp;Liu, P.&nbsp;S. Koura <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Opt-iml: Scaling language model instruction meta learning through the lens of generalization,” <em id="bib.bib103.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.12017</em>, 2022.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
Y.&nbsp;Hao, H.&nbsp;Song, L.&nbsp;Dong, S.&nbsp;Huang, Z.&nbsp;Chi, W.&nbsp;Wang, S.&nbsp;Ma, and F.&nbsp;Wei, “Language models are general-purpose interfaces,” <em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.06336</em>, 2022.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
Z.&nbsp;Sun, Y.&nbsp;Shen, Q.&nbsp;Zhou, H.&nbsp;Zhang, Z.&nbsp;Chen, D.&nbsp;Cox, Y.&nbsp;Yang, and C.&nbsp;Gan, “Principle-driven self-alignment of language models from scratch with minimal human supervision,” <em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.03047</em>, 2023.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
W.&nbsp;E. team, “Palmyra-base Parameter Autoregressive Language Model,” <a target="_blank" href="https://dev.writer.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://dev.writer.com</a>, 2023.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
——, “Camel-5b instructgpt,” <a target="_blank" href="https://dev.writer.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://dev.writer.com</a>, 2023.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
Yandex. Yalm. [Online]. Available: <a target="_blank" href="https://github.com/yandex/YaLM-100B" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/yandex/YaLM-100B</a>

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
M.&nbsp;Team <em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Introducing mpt-7b: a new standard for open-source, commercially usable llms,” 2023.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
A.&nbsp;Mitra, L.&nbsp;D. Corro, S.&nbsp;Mahajan, A.&nbsp;Codas, C.&nbsp;Simoes, S.&nbsp;Agarwal, X.&nbsp;Chen, A.&nbsp;Razdaibiedina, E.&nbsp;Jones, K.&nbsp;Aggarwal, H.&nbsp;Palangi, G.&nbsp;Zheng, C.&nbsp;Rosset, H.&nbsp;Khanpour, and A.&nbsp;Awadallah, “Orca 2: Teaching small language models how to reason,” 2023.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
L.&nbsp;Gao, A.&nbsp;Madaan, S.&nbsp;Zhou, U.&nbsp;Alon, P.&nbsp;Liu, Y.&nbsp;Yang, J.&nbsp;Callan, and G.&nbsp;Neubig, “Pal: Program-aided language models,” in <em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>.&nbsp;&nbsp;&nbsp;PMLR, 2023, pp. 10 764–10 799.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
Anthropic. claude. [Online]. Available: <a target="_blank" href="https://www.anthropic.com/news/introducing-claude" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.anthropic.com/news/introducing-claude</a>

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
E.&nbsp;Nijkamp, H.&nbsp;Hayashi, C.&nbsp;Xiong, S.&nbsp;Savarese, and Y.&nbsp;Zhou, “Codegen2: Lessons for training llms on programming and natural languages,” <em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.02309</em>, 2023.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
L.&nbsp;Tunstall, E.&nbsp;Beeching, N.&nbsp;Lambert, N.&nbsp;Rajani, K.&nbsp;Rasul, Y.&nbsp;Belkada, S.&nbsp;Huang, L.&nbsp;von Werra, C.&nbsp;Fourrier, N.&nbsp;Habib <em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Zephyr: Direct distillation of lm alignment,” <em id="bib.bib114.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.16944</em>, 2023.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
X.&nbsp;team. Grok. [Online]. Available: <a target="_blank" href="https://grok.x.ai/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://grok.x.ai/</a>

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
J.&nbsp;Bai, S.&nbsp;Bai, S.&nbsp;Yang, S.&nbsp;Wang, S.&nbsp;Tan, P.&nbsp;Wang, J.&nbsp;Lin, C.&nbsp;Zhou, and J.&nbsp;Zhou, “Qwen-vl: A frontier large vision-language model with versatile abilities,” <em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.12966</em>, 2023.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
mixtral. mixtral. [Online]. Available: <a target="_blank" href="https://mistral.ai/news/mixtral-of-experts/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://mistral.ai/news/mixtral-of-experts/</a>

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
D.&nbsp;Wang, N.&nbsp;Raman, M.&nbsp;Sibue, Z.&nbsp;Ma, P.&nbsp;Babkin, S.&nbsp;Kaur, Y.&nbsp;Pei, A.&nbsp;Nourbakhsh, and X.&nbsp;Liu, “Docllm: A layout-aware generative language model for multimodal document understanding,” 2023.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
D.&nbsp;Guo, Q.&nbsp;Zhu, D.&nbsp;Yang, Z.&nbsp;Xie, K.&nbsp;Dong, W.&nbsp;Zhang, G.&nbsp;Chen, X.&nbsp;Bi, Y.&nbsp;Wu, Y.&nbsp;K. Li, F.&nbsp;Luo, Y.&nbsp;Xiong, and W.&nbsp;Liang, “Deepseek-coder: When the large language model meets programming – the rise of code intelligence,” 2024.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
F.&nbsp;Wan, X.&nbsp;Huang, D.&nbsp;Cai, X.&nbsp;Quan, W.&nbsp;Bi, and S.&nbsp;Shi, “Knowledge fusion of large language models,” 2024.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
P.&nbsp;Zhang, G.&nbsp;Zeng, T.&nbsp;Wang, and W.&nbsp;Lu, “Tinyllama: An open-source small language model,” 2024.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
C.&nbsp;Wu, Y.&nbsp;Gan, Y.&nbsp;Ge, Z.&nbsp;Lu, J.&nbsp;Wang, Y.&nbsp;Feng, P.&nbsp;Luo, and Y.&nbsp;Shan, “Llama pro: Progressive llama with block expansion,” 2024.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
X.&nbsp;Amatriain, A.&nbsp;Sankar, J.&nbsp;Bing, P.&nbsp;K. Bodigutla, T.&nbsp;J. Hazen, and M.&nbsp;Kazi, “Transformer models: an introduction and catalog,” 2023.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
G.&nbsp;Penedo, Q.&nbsp;Malartic, D.&nbsp;Hesslow, R.&nbsp;Cojocaru, A.&nbsp;Cappelli, H.&nbsp;Alobeidli, B.&nbsp;Pannier, E.&nbsp;Almazrouei, and J.&nbsp;Launay, “The refinedweb dataset for falcon llm: outperforming curated corpora with web data, and web data only,” <em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.01116</em>, 2023.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
D.&nbsp;Hernandez, T.&nbsp;Brown, T.&nbsp;Conerly, N.&nbsp;DasSarma, D.&nbsp;Drain, S.&nbsp;El-Showk, N.&nbsp;Elhage, Z.&nbsp;Hatfield-Dodds, T.&nbsp;Henighan, T.&nbsp;Hume <em id="bib.bib125.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Scaling laws and interpretability of learning from repeated data,” <em id="bib.bib125.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2205.10487</em>, 2022.

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock">
P.&nbsp;Shaw, J.&nbsp;Uszkoreit, and A.&nbsp;Vaswani, “Self-attention with relative position representations,” <em id="bib.bib126.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1803.02155</em>, 2018.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock">
J.&nbsp;Su, Y.&nbsp;Lu, S.&nbsp;Pan, B.&nbsp;Wen, and Y.&nbsp;Liu, “Roformer: Enhanced transformer with rotary position embedding,” <em id="bib.bib127.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.09864</em>, 2021.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock">
O.&nbsp;Press, N.&nbsp;A. Smith, and M.&nbsp;Lewis, “Train short, test long: Attention with linear biases enables input length extrapolation,” <em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2108.12409</em>, 2021.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock">
G.&nbsp;Ke, D.&nbsp;He, and T.-Y. Liu, “Rethinking positional encoding in language pre-training,” <em id="bib.bib129.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.15595</em>, 2020.

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock">
N.&nbsp;Shazeer, A.&nbsp;Mirhoseini, K.&nbsp;Maziarz, A.&nbsp;Davis, Q.&nbsp;Le, G.&nbsp;Hinton, and J.&nbsp;Dean, “Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,” <em id="bib.bib130.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1701.06538</em>, 2017.

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock">
W.&nbsp;Fedus, B.&nbsp;Zoph, and N.&nbsp;Shazeer, “Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity,” <em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">The Journal of Machine Learning Research</em>, vol.&nbsp;23, no.&nbsp;1, pp. 5232–5270, 2022.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock">
R.&nbsp;K. Mahabadi, S.&nbsp;Ruder, M.&nbsp;Dehghani, and J.&nbsp;Henderson, “Parameter-efficient multi-task fine-tuning for transformers via shared hypernetworks,” 2021.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock">
S.&nbsp;Zhang, L.&nbsp;Dong, X.&nbsp;Li, S.&nbsp;Zhang, X.&nbsp;Sun, S.&nbsp;Wang, J.&nbsp;Li, R.&nbsp;Hu, T.&nbsp;Zhang, F.&nbsp;Wu, and G.&nbsp;Wang, “Instruction tuning for large language models: A survey,” 2023.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock">
S.&nbsp;Mishra, D.&nbsp;Khashabi, C.&nbsp;Baral, and H.&nbsp;Hajishirzi, “Cross-task generalization via natural language crowdsourcing instructions,” <em id="bib.bib134.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.08773</em>, 2021.

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock">
Y.&nbsp;Wang, Y.&nbsp;Kordi, S.&nbsp;Mishra, A.&nbsp;Liu, N.&nbsp;A. Smith, D.&nbsp;Khashabi, and H.&nbsp;Hajishirzi, “Self-instruct: Aligning language model with self generated instructions,” <em id="bib.bib135.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.10560</em>, 2022.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock">
K.&nbsp;Ethayarajh, W.&nbsp;Xu, D.&nbsp;Jurafsky, and D.&nbsp;Kiela. Kto. [Online]. Available: <a target="_blank" href="https://github.com/ContextualAI/HALOs/blob/main/assets/report.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/ContextualAI/HALOs/blob/main/assets/report.pdf</a>

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[137]</span>
<span class="ltx_bibblock">
P.&nbsp;F. Christiano, J.&nbsp;Leike, T.&nbsp;Brown, M.&nbsp;Martic, S.&nbsp;Legg, and D.&nbsp;Amodei, “Deep reinforcement learning from human preferences,” <em id="bib.bib137.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, vol.&nbsp;30, 2017.

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[138]</span>
<span class="ltx_bibblock">
H.&nbsp;Lee, S.&nbsp;Phatale, H.&nbsp;Mansoor, K.&nbsp;Lu, T.&nbsp;Mesnard, C.&nbsp;Bishop, V.&nbsp;Carbune, and A.&nbsp;Rastogi, “Rlaif: Scaling reinforcement learning from human feedback with ai feedback,” <em id="bib.bib138.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.00267</em>, 2023.

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[139]</span>
<span class="ltx_bibblock">
R.&nbsp;Rafailov, A.&nbsp;Sharma, E.&nbsp;Mitchell, S.&nbsp;Ermon, C.&nbsp;D. Manning, and C.&nbsp;Finn, “Direct preference optimization: Your language model is secretly a reward model,” <em id="bib.bib139.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.18290</em>, 2023.

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[140]</span>
<span class="ltx_bibblock">
S.&nbsp;Rajbhandari, J.&nbsp;Rasley, O.&nbsp;Ruwase, and Y.&nbsp;He, “Zero: Memory optimizations toward training trillion parameter models,” in <em id="bib.bib140.1.1" class="ltx_emph ltx_font_italic">SC20: International Conference for High Performance Computing, Networking, Storage and Analysis</em>.&nbsp;&nbsp;&nbsp;IEEE, 2020, pp. 1–16.

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[141]</span>
<span class="ltx_bibblock">
B.&nbsp;Peng, E.&nbsp;Alcaide, Q.&nbsp;Anthony, A.&nbsp;Albalak, S.&nbsp;Arcadinho, H.&nbsp;Cao, X.&nbsp;Cheng, M.&nbsp;Chung, M.&nbsp;Grella, K.&nbsp;K. GV <em id="bib.bib141.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Rwkv: Reinventing rnns for the transformer era,” <em id="bib.bib141.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.13048</em>, 2023.

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[142]</span>
<span class="ltx_bibblock">
E.&nbsp;J. Hu, Y.&nbsp;Shen, P.&nbsp;Wallis, Z.&nbsp;Allen-Zhu, Y.&nbsp;Li, S.&nbsp;Wang, L.&nbsp;Wang, and W.&nbsp;Chen, “Lora: Low-rank adaptation of large language models,” <em id="bib.bib142.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.09685</em>, 2021.

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[143]</span>
<span class="ltx_bibblock">
G.&nbsp;Hinton, O.&nbsp;Vinyals, and J.&nbsp;Dean, “Distilling the knowledge in a neural network,” <em id="bib.bib143.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1503.02531</em>, 2015.

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[144]</span>
<span class="ltx_bibblock">
J.&nbsp;Gou, B.&nbsp;Yu, S.&nbsp;J. Maybank, and D.&nbsp;Tao, “Knowledge distillation: A survey,” <em id="bib.bib144.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, vol. 129, pp. 1789–1819, 2021.

</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[145]</span>
<span class="ltx_bibblock">
Z.&nbsp;Ji, N.&nbsp;Lee, R.&nbsp;Frieske, T.&nbsp;Yu, D.&nbsp;Su, Y.&nbsp;Xu, E.&nbsp;Ishii, Y.&nbsp;J. Bang, A.&nbsp;Madotto, and P.&nbsp;Fung, “Survey of hallucination in natural language generation,” <em id="bib.bib145.1.1" class="ltx_emph ltx_font_italic">ACM Comput. Surv.</em>, vol.&nbsp;55, no.&nbsp;12, mar 2023. [Online]. Available: <a target="_blank" href="https://doi.org/10.1145/3571730" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3571730</a>

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[146]</span>
<span class="ltx_bibblock">
N.&nbsp;McKenna, T.&nbsp;Li, L.&nbsp;Cheng, M.&nbsp;J. Hosseini, M.&nbsp;Johnson, and M.&nbsp;Steedman, “Sources of hallucination by large language models on inference tasks,” 2023.

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[147]</span>
<span class="ltx_bibblock">
C.-Y. Lin, “ROUGE: A package for automatic evaluation of summaries,” in <em id="bib.bib147.1.1" class="ltx_emph ltx_font_italic">Text Summarization Branches Out</em>.&nbsp;&nbsp;&nbsp;Barcelona, Spain: Association for Computational Linguistics, Jul. 2004, pp. 74–81. [Online]. Available: <a target="_blank" href="https://aclanthology.org/W04-1013" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/W04-1013</a>

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[148]</span>
<span class="ltx_bibblock">
K.&nbsp;Papineni, S.&nbsp;Roukos, T.&nbsp;Ward, and W.-J. Zhu, “Bleu: a method for automatic evaluation of machine translation,” in <em id="bib.bib148.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</em>, P.&nbsp;Isabelle, E.&nbsp;Charniak, and D.&nbsp;Lin, Eds.&nbsp;&nbsp;&nbsp;Philadelphia, Pennsylvania, USA: Association for Computational Linguistics, Jul. 2002, pp. 311–318. [Online]. Available: <a target="_blank" href="https://aclanthology.org/P02-1040" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/P02-1040</a>

</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[149]</span>
<span class="ltx_bibblock">
B.&nbsp;Dhingra, M.&nbsp;Faruqui, A.&nbsp;Parikh, M.-W. Chang, D.&nbsp;Das, and W.&nbsp;Cohen, “Handling divergent reference texts when evaluating table-to-text generation,” in <em id="bib.bib149.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, A.&nbsp;Korhonen, D.&nbsp;Traum, and L.&nbsp;Màrquez, Eds.&nbsp;&nbsp;&nbsp;Florence, Italy: Association for Computational Linguistics, Jul. 2019, pp. 4884–4895. [Online]. Available: <a target="_blank" href="https://aclanthology.org/P19-1483" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/P19-1483</a>

</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[150]</span>
<span class="ltx_bibblock">
Z.&nbsp;Wang, X.&nbsp;Wang, B.&nbsp;An, D.&nbsp;Yu, and C.&nbsp;Chen, “Towards faithful neural table-to-text generation with content-matching constraints,” in <em id="bib.bib150.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, D.&nbsp;Jurafsky, J.&nbsp;Chai, N.&nbsp;Schluter, and J.&nbsp;Tetreault, Eds.&nbsp;&nbsp;&nbsp;Online: Association for Computational Linguistics, Jul. 2020, pp. 1072–1086. [Online]. Available: <a target="_blank" href="https://aclanthology.org/2020.acl-main.101" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2020.acl-main.101</a>

</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[151]</span>
<span class="ltx_bibblock">
H.&nbsp;Song, W.-N. Zhang, J.&nbsp;Hu, and T.&nbsp;Liu, “Generating persona consistent dialogues by exploiting natural language inference,” <em id="bib.bib151.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, vol.&nbsp;34, no.&nbsp;05, pp. 8878–8885, Apr. 2020.

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[152]</span>
<span class="ltx_bibblock">
O.&nbsp;Honovich, L.&nbsp;Choshen, R.&nbsp;Aharoni, E.&nbsp;Neeman, I.&nbsp;Szpektor, and O.&nbsp;Abend, “<math id="bib.bib152.1.m1.1" class="ltx_Math" alttext="q^{2}" display="inline"><semantics id="bib.bib152.1.m1.1a"><msup id="bib.bib152.1.m1.1.1" xref="bib.bib152.1.m1.1.1.cmml"><mi id="bib.bib152.1.m1.1.1.2" xref="bib.bib152.1.m1.1.1.2.cmml">q</mi><mn id="bib.bib152.1.m1.1.1.3" xref="bib.bib152.1.m1.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="bib.bib152.1.m1.1b"><apply id="bib.bib152.1.m1.1.1.cmml" xref="bib.bib152.1.m1.1.1"><csymbol cd="ambiguous" id="bib.bib152.1.m1.1.1.1.cmml" xref="bib.bib152.1.m1.1.1">superscript</csymbol><ci id="bib.bib152.1.m1.1.1.2.cmml" xref="bib.bib152.1.m1.1.1.2">𝑞</ci><cn type="integer" id="bib.bib152.1.m1.1.1.3.cmml" xref="bib.bib152.1.m1.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="bib.bib152.1.m1.1c">q^{2}</annotation></semantics></math>: Evaluating factual consistency in knowledge-grounded dialogues via question generation and question answering,” in <em id="bib.bib152.2.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, M.-F. Moens, X.&nbsp;Huang, L.&nbsp;Specia, and S.&nbsp;W.-t. Yih, Eds.&nbsp;&nbsp;&nbsp;Online and Punta Cana, Dominican Republic: Association for Computational Linguistics, Nov. 2021, pp. 7856–7870. [Online]. Available: <a target="_blank" href="https://aclanthology.org/2021.emnlp-main.619" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2021.emnlp-main.619</a>

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[153]</span>
<span class="ltx_bibblock">
N.&nbsp;Dziri, H.&nbsp;Rashkin, T.&nbsp;Linzen, and D.&nbsp;Reitter, “Evaluating attribution in dialogue systems: The BEGIN benchmark,” <em id="bib.bib153.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>, vol.&nbsp;10, pp. 1066–1083, 2022. [Online]. Available: <a target="_blank" href="https://aclanthology.org/2022.tacl-1.62" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2022.tacl-1.62</a>

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[154]</span>
<span class="ltx_bibblock">
S.&nbsp;Santhanam, B.&nbsp;Hedayatnia, S.&nbsp;Gella, A.&nbsp;Padmakumar, S.&nbsp;Kim, Y.&nbsp;Liu, and D.&nbsp;Z. Hakkani-Tür, “Rome was built in 1776: A case study on factual correctness in knowledge-grounded response generation,” <em id="bib.bib154.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, vol. abs/2110.05456, 2021.

</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[155]</span>
<span class="ltx_bibblock">
S.&nbsp;Min, K.&nbsp;Krishna, X.&nbsp;Lyu, M.&nbsp;Lewis, W.&nbsp;tau Yih, P.&nbsp;W. Koh, M.&nbsp;Iyyer, L.&nbsp;Zettlemoyer, and H.&nbsp;Hajishirzi, “Factscore: Fine-grained atomic evaluation of factual precision in long form text generation,” 2023.

</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[156]</span>
<span class="ltx_bibblock">
D.&nbsp;Sculley, G.&nbsp;Holt, D.&nbsp;Golovin, E.&nbsp;Davydov, T.&nbsp;Phillips, D.&nbsp;Ebner, V.&nbsp;Chaudhary, and M.&nbsp;Young, “Machine learning: The high interest credit card of technical debt,” in <em id="bib.bib156.1.1" class="ltx_emph ltx_font_italic">SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop)</em>, 2014.

</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[157]</span>
<span class="ltx_bibblock">
Z.&nbsp;Zhang, A.&nbsp;Zhang, M.&nbsp;Li, and A.&nbsp;Smola, “Automatic chain of thought prompting in large language models,” 2022.

</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[158]</span>
<span class="ltx_bibblock">
S.&nbsp;Yao, D.&nbsp;Yu, J.&nbsp;Zhao, I.&nbsp;Shafran, T.&nbsp;L. Griffiths, Y.&nbsp;Cao, and K.&nbsp;Narasimhan, “Tree of thoughts: Deliberate problem solving with large language models,” 2023.

</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[159]</span>
<span class="ltx_bibblock">
P.&nbsp;Manakul, A.&nbsp;Liusie, and M.&nbsp;J.&nbsp;F. Gales, “Selfcheckgpt: Zero-resource black-box hallucination detection for generative large language models,” 2023.

</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[160]</span>
<span class="ltx_bibblock">
N.&nbsp;Shinn, F.&nbsp;Cassano, E.&nbsp;Berman, A.&nbsp;Gopinath, K.&nbsp;Narasimhan, and S.&nbsp;Yao, “Reflexion: Language agents with verbal reinforcement learning,” 2023.

</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[161]</span>
<span class="ltx_bibblock">
S.&nbsp;J. Zhang, S.&nbsp;Florin, A.&nbsp;N. Lee, E.&nbsp;Niknafs, A.&nbsp;Marginean, A.&nbsp;Wang, K.&nbsp;Tyser, Z.&nbsp;Chin, Y.&nbsp;Hicke, N.&nbsp;Singh, M.&nbsp;Udell, Y.&nbsp;Kim, T.&nbsp;Buonassisi, A.&nbsp;Solar-Lezama, and I.&nbsp;Drori, “Exploring the mit mathematics and eecs curriculum using large language models,” 2023.

</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[162]</span>
<span class="ltx_bibblock">
T.&nbsp;Wu, E.&nbsp;Jiang, A.&nbsp;Donsbach, J.&nbsp;Gray, A.&nbsp;Molina, M.&nbsp;Terry, and C.&nbsp;J. Cai, “Promptchainer: Chaining large language model prompts through visual programming,” 2022.

</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[163]</span>
<span class="ltx_bibblock">
Y.&nbsp;Zhou, A.&nbsp;I. Muresanu, Z.&nbsp;Han, K.&nbsp;Paster, S.&nbsp;Pitis, H.&nbsp;Chan, and J.&nbsp;Ba, “Large language models are human-level prompt engineers,” 2023.

</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[164]</span>
<span class="ltx_bibblock">
P.&nbsp;S.&nbsp;H. Lewis, E.&nbsp;Perez, A.&nbsp;Piktus, F.&nbsp;Petroni, V.&nbsp;Karpukhin, N.&nbsp;Goyal, H.&nbsp;Küttler, M.&nbsp;Lewis, W.&nbsp;Yih, T.&nbsp;Rocktäschel, S.&nbsp;Riedel, and D.&nbsp;Kiela, “Retrieval-augmented generation for knowledge-intensive NLP tasks,” <em id="bib.bib164.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2005.11401, 2020. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2005.11401" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2005.11401</a>

</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[165]</span>
<span class="ltx_bibblock">
Y.&nbsp;Gao, Y.&nbsp;Xiong, X.&nbsp;Gao, K.&nbsp;Jia, J.&nbsp;Pan, Y.&nbsp;Bi, Y.&nbsp;Dai, J.&nbsp;Sun, and H.&nbsp;Wang, “Retrieval-augmented generation for large language models: A survey,” <em id="bib.bib165.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2312.10997</em>, 2023.

</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[166]</span>
<span class="ltx_bibblock">
A.&nbsp;W. Services. (Year of publication, e.g., 2023) Question answering using retrieval augmented generation with foundation models in amazon sagemaker jumpstart. Accessed: Date of access, e.g., December 5, 2023. [Online]. Available: <a target="_blank" href="https://shorturl.at/dSV47" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://shorturl.at/dSV47</a>

</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[167]</span>
<span class="ltx_bibblock">
S.&nbsp;Pan, L.&nbsp;Luo, Y.&nbsp;Wang, C.&nbsp;Chen, J.&nbsp;Wang, and X.&nbsp;Wu, “Unifying large language models and knowledge graphs: A roadmap,” <em id="bib.bib167.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.08302</em>, 2023.

</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[168]</span>
<span class="ltx_bibblock">
Z.&nbsp;Jiang, F.&nbsp;F. Xu, L.&nbsp;Gao, Z.&nbsp;Sun, Q.&nbsp;Liu, J.&nbsp;Dwivedi-Yu, Y.&nbsp;Yang, J.&nbsp;Callan, and G.&nbsp;Neubig, “Active retrieval augmented generation,” 2023.

</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[169]</span>
<span class="ltx_bibblock">
T.&nbsp;Schick, J.&nbsp;Dwivedi-Yu, R.&nbsp;Dessì, R.&nbsp;Raileanu, M.&nbsp;Lomeli, L.&nbsp;Zettlemoyer, N.&nbsp;Cancedda, and T.&nbsp;Scialom, “Toolformer: Language models can teach themselves to use tools,” 2023.

</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[170]</span>
<span class="ltx_bibblock">
B.&nbsp;Paranjape, S.&nbsp;Lundberg, S.&nbsp;Singh, H.&nbsp;Hajishirzi, L.&nbsp;Zettlemoyer, and M.&nbsp;T. Ribeiro, “Art: Automatic multi-step reasoning and tool-use for large language models,” 2023.

</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[171]</span>
<span class="ltx_bibblock">
Y.&nbsp;Shen, K.&nbsp;Song, X.&nbsp;Tan, D.&nbsp;Li, W.&nbsp;Lu, and Y.&nbsp;Zhuang, “Hugginggpt: Solving ai tasks with chatgpt and its friends in huggingface,” <em id="bib.bib171.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.17580</em>, 2023.

</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[172]</span>
<span class="ltx_bibblock">
Z.&nbsp;Xi, W.&nbsp;Chen, X.&nbsp;Guo, W.&nbsp;He, Y.&nbsp;Ding, B.&nbsp;Hong, M.&nbsp;Zhang, J.&nbsp;Wang, S.&nbsp;Jin, E.&nbsp;Zhou <em id="bib.bib172.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “The rise and potential of large language model based agents: A survey,” <em id="bib.bib172.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.07864</em>, 2023.

</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[173]</span>
<span class="ltx_bibblock">
L.&nbsp;Wang, C.&nbsp;Ma, X.&nbsp;Feng, Z.&nbsp;Zhang, H.&nbsp;Yang, J.&nbsp;Zhang, Z.&nbsp;Chen, J.&nbsp;Tang, X.&nbsp;Chen, Y.&nbsp;Lin <em id="bib.bib173.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “A survey on large language model based autonomous agents,” <em id="bib.bib173.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.11432</em>, 2023.

</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[174]</span>
<span class="ltx_bibblock">
Z.&nbsp;Durante, Q.&nbsp;Huang, N.&nbsp;Wake, R.&nbsp;Gong, J.&nbsp;S. Park, B.&nbsp;Sarkar, R.&nbsp;Taori, Y.&nbsp;Noda, D.&nbsp;Terzopoulos, Y.&nbsp;Choi, K.&nbsp;Ikeuchi, H.&nbsp;Vo, L.&nbsp;Fei-Fei, and J.&nbsp;Gao, “Agent ai: Surveying the horizons of multimodal interaction,” <em id="bib.bib174.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.03568</em>, 2024.

</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[175]</span>
<span class="ltx_bibblock">
B.&nbsp;Xu, Z.&nbsp;Peng, B.&nbsp;Lei, S.&nbsp;Mukherjee, Y.&nbsp;Liu, and D.&nbsp;Xu, “Rewoo: Decoupling reasoning from observations for efficient augmented language models,” 2023.

</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[176]</span>
<span class="ltx_bibblock">
S.&nbsp;Yao, J.&nbsp;Zhao, D.&nbsp;Yu, N.&nbsp;Du, I.&nbsp;Shafran, K.&nbsp;Narasimhan, and Y.&nbsp;Cao, “React: Synergizing reasoning and acting in language models,” 2023.

</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[177]</span>
<span class="ltx_bibblock">
V.&nbsp;Nair, E.&nbsp;Schumacher, G.&nbsp;Tso, and A.&nbsp;Kannan, “Dera: Enhancing large language model completions with dialog-enabled resolving agents,” 2023.

</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[178]</span>
<span class="ltx_bibblock">
Y.&nbsp;Chang, X.&nbsp;Wang, J.&nbsp;Wang, Y.&nbsp;Wu, L.&nbsp;Yang, K.&nbsp;Zhu, H.&nbsp;Chen, X.&nbsp;Yi, C.&nbsp;Wang, Y.&nbsp;Wang, W.&nbsp;Ye, Y.&nbsp;Zhang, Y.&nbsp;Chang, P.&nbsp;S. Yu, Q.&nbsp;Yang, and X.&nbsp;Xie, “A survey on evaluation of large language models,” 2023.

</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[179]</span>
<span class="ltx_bibblock">
T.&nbsp;Kwiatkowski, J.&nbsp;Palomaki, O.&nbsp;Redfield, M.&nbsp;Collins, A.&nbsp;Parikh, C.&nbsp;Alberti, D.&nbsp;Epstein, I.&nbsp;Polosukhin, J.&nbsp;Devlin, K.&nbsp;Lee, K.&nbsp;Toutanova, L.&nbsp;Jones, M.&nbsp;Kelcey, M.-W. Chang, A.&nbsp;M. Dai, J.&nbsp;Uszkoreit, Q.&nbsp;Le, and S.&nbsp;Petrov, “Natural questions: A benchmark for question answering research,” <em id="bib.bib179.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>, vol.&nbsp;7, pp. 452–466, 2019. [Online]. Available: <a target="_blank" href="https://aclanthology.org/Q19-1026" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/Q19-1026</a>

</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[180]</span>
<span class="ltx_bibblock">
D.&nbsp;Hendrycks, C.&nbsp;Burns, S.&nbsp;Basart, A.&nbsp;Zou, M.&nbsp;Mazeika, D.&nbsp;Song, and J.&nbsp;Steinhardt, “Measuring massive multitask language understanding,” 2021.

</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[181]</span>
<span class="ltx_bibblock">
J.&nbsp;Austin, A.&nbsp;Odena, M.&nbsp;Nye, M.&nbsp;Bosma, H.&nbsp;Michalewski, D.&nbsp;Dohan, E.&nbsp;Jiang, C.&nbsp;Cai, M.&nbsp;Terry, Q.&nbsp;Le <em id="bib.bib181.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Program synthesis with large language models,” <em id="bib.bib181.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2108.07732</em>, 2021.

</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[182]</span>
<span class="ltx_bibblock">
E.&nbsp;Choi, H.&nbsp;He, M.&nbsp;Iyyer, M.&nbsp;Yatskar, W.-t. Yih, Y.&nbsp;Choi, P.&nbsp;Liang, and L.&nbsp;Zettlemoyer, “QuAC: Question answering in context,” in <em id="bib.bib182.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</em>, E.&nbsp;Riloff, D.&nbsp;Chiang, J.&nbsp;Hockenmaier, and J.&nbsp;Tsujii, Eds.&nbsp;&nbsp;&nbsp;Brussels, Belgium: Association for Computational Linguistics, Oct.-Nov. 2018, pp. 2174–2184. [Online]. Available: <a target="_blank" href="https://aclanthology.org/D18-1241" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/D18-1241</a>

</span>
</li>
<li id="bib.bib183" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[183]</span>
<span class="ltx_bibblock">
D.&nbsp;Hendrycks, S.&nbsp;Basart, S.&nbsp;Kadavath, M.&nbsp;Mazeika, A.&nbsp;Arora, E.&nbsp;Guo, C.&nbsp;Burns, S.&nbsp;Puranik, H.&nbsp;He, D.&nbsp;Song, and J.&nbsp;Steinhardt, “Measuring coding challenge competence with apps,” <em id="bib.bib183.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2021.

</span>
</li>
<li id="bib.bib184" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[184]</span>
<span class="ltx_bibblock">
V.&nbsp;Zhong, C.&nbsp;Xiong, and R.&nbsp;Socher, “Seq2sql: Generating structured queries from natural language using reinforcement learning,” <em id="bib.bib184.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1709.00103</em>, 2017.

</span>
</li>
<li id="bib.bib185" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[185]</span>
<span class="ltx_bibblock">
M.&nbsp;Joshi, E.&nbsp;Choi, D.&nbsp;Weld, and L.&nbsp;Zettlemoyer, “TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension,” in <em id="bib.bib185.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, R.&nbsp;Barzilay and M.-Y. Kan, Eds.&nbsp;&nbsp;&nbsp;Vancouver, Canada: Association for Computational Linguistics, Jul. 2017, pp. 1601–1611. [Online]. Available: <a target="_blank" href="https://aclanthology.org/P17-1147" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/P17-1147</a>

</span>
</li>
<li id="bib.bib186" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[186]</span>
<span class="ltx_bibblock">
G.&nbsp;Lai, Q.&nbsp;Xie, H.&nbsp;Liu, Y.&nbsp;Yang, and E.&nbsp;Hovy, “RACE: Large-scale ReAding comprehension dataset from examinations,” in <em id="bib.bib186.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</em>, M.&nbsp;Palmer, R.&nbsp;Hwa, and S.&nbsp;Riedel, Eds.&nbsp;&nbsp;&nbsp;Copenhagen, Denmark: Association for Computational Linguistics, Sep. 2017, pp. 785–794. [Online]. Available: <a target="_blank" href="https://aclanthology.org/D17-1082" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/D17-1082</a>

</span>
</li>
<li id="bib.bib187" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[187]</span>
<span class="ltx_bibblock">
P.&nbsp;Rajpurkar, J.&nbsp;Zhang, K.&nbsp;Lopyrev, and P.&nbsp;Liang, “SQuAD: 100,000+ questions for machine comprehension of text,” in <em id="bib.bib187.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</em>, J.&nbsp;Su, K.&nbsp;Duh, and X.&nbsp;Carreras, Eds.&nbsp;&nbsp;&nbsp;Austin, Texas: Association for Computational Linguistics, Nov. 2016, pp. 2383–2392. [Online]. Available: <a target="_blank" href="https://aclanthology.org/D16-1264" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/D16-1264</a>

</span>
</li>
<li id="bib.bib188" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[188]</span>
<span class="ltx_bibblock">
C.&nbsp;Clark, K.&nbsp;Lee, M.&nbsp;Chang, T.&nbsp;Kwiatkowski, M.&nbsp;Collins, and K.&nbsp;Toutanova, “Boolq: Exploring the surprising difficulty of natural yes/no questions,” <em id="bib.bib188.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1905.10044, 2019. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1905.10044" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1905.10044</a>

</span>
</li>
<li id="bib.bib189" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[189]</span>
<span class="ltx_bibblock">
D.&nbsp;Khashabi, S.&nbsp;Chaturvedi, M.&nbsp;Roth, S.&nbsp;Upadhyay, and D.&nbsp;Roth, “Looking beyond the surface:a challenge set for reading comprehension over multiple sentences,” in <em id="bib.bib189.1.1" class="ltx_emph ltx_font_italic">Proceedings of North American Chapter of the Association for Computational Linguistics (NAACL)</em>, 2018.

</span>
</li>
<li id="bib.bib190" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[190]</span>
<span class="ltx_bibblock">
K.&nbsp;Cobbe, V.&nbsp;Kosaraju, M.&nbsp;Bavarian, M.&nbsp;Chen, H.&nbsp;Jun, L.&nbsp;Kaiser, M.&nbsp;Plappert, J.&nbsp;Tworek, J.&nbsp;Hilton, R.&nbsp;Nakano, C.&nbsp;Hesse, and J.&nbsp;Schulman, “Training verifiers to solve math word problems,” <em id="bib.bib190.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2110.14168, 2021. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2110.14168" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2110.14168</a>

</span>
</li>
<li id="bib.bib191" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[191]</span>
<span class="ltx_bibblock">
D.&nbsp;Hendrycks, C.&nbsp;Burns, S.&nbsp;Kadavath, A.&nbsp;Arora, S.&nbsp;Basart, E.&nbsp;Tang, D.&nbsp;Song, and J.&nbsp;Steinhardt, “Measuring mathematical problem solving with the MATH dataset,” <em id="bib.bib191.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2103.03874, 2021. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/2103.03874" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2103.03874</a>

</span>
</li>
<li id="bib.bib192" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[192]</span>
<span class="ltx_bibblock">
R.&nbsp;Zellers, A.&nbsp;Holtzman, Y.&nbsp;Bisk, A.&nbsp;Farhadi, and Y.&nbsp;Choi, “Hellaswag: Can a machine really finish your sentence?” 2019.

</span>
</li>
<li id="bib.bib193" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[193]</span>
<span class="ltx_bibblock">
P.&nbsp;Clark, I.&nbsp;Cowhey, O.&nbsp;Etzioni, T.&nbsp;Khot, A.&nbsp;Sabharwal, C.&nbsp;Schoenick, and O.&nbsp;Tafjord, “Think you have solved question answering? try arc, the AI2 reasoning challenge,” <em id="bib.bib193.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1803.05457, 2018. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1803.05457" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1803.05457</a>

</span>
</li>
<li id="bib.bib194" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[194]</span>
<span class="ltx_bibblock">
Y.&nbsp;Bisk, R.&nbsp;Zellers, R.&nbsp;L. Bras, J.&nbsp;Gao, and Y.&nbsp;Choi, “PIQA: reasoning about physical commonsense in natural language,” <em id="bib.bib194.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1911.11641, 2019. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1911.11641" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1911.11641</a>

</span>
</li>
<li id="bib.bib195" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[195]</span>
<span class="ltx_bibblock">
M.&nbsp;Sap, H.&nbsp;Rashkin, D.&nbsp;Chen, R.&nbsp;L. Bras, and Y.&nbsp;Choi, “Socialiqa: Commonsense reasoning about social interactions,” <em id="bib.bib195.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1904.09728, 2019. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1904.09728" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1904.09728</a>

</span>
</li>
<li id="bib.bib196" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[196]</span>
<span class="ltx_bibblock">
T.&nbsp;Mihaylov, P.&nbsp;Clark, T.&nbsp;Khot, and A.&nbsp;Sabharwal, “Can a suit of armor conduct electricity? A new dataset for open book question answering,” <em id="bib.bib196.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1809.02789, 2018. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1809.02789" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1809.02789</a>

</span>
</li>
<li id="bib.bib197" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[197]</span>
<span class="ltx_bibblock">
S.&nbsp;Lin, J.&nbsp;Hilton, and O.&nbsp;Evans, “Truthfulqa: Measuring how models mimic human falsehoods,” <em id="bib.bib197.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.07958</em>, 2021.

</span>
</li>
<li id="bib.bib198" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[198]</span>
<span class="ltx_bibblock">
Z.&nbsp;Yang, P.&nbsp;Qi, S.&nbsp;Zhang, Y.&nbsp;Bengio, W.&nbsp;W. Cohen, R.&nbsp;Salakhutdinov, and C.&nbsp;D. Manning, “Hotpotqa: A dataset for diverse, explainable multi-hop question answering,” <em id="bib.bib198.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1809.09600, 2018. [Online]. Available: <a target="_blank" href="http://arxiv.org/abs/1809.09600" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1809.09600</a>

</span>
</li>
<li id="bib.bib199" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[199]</span>
<span class="ltx_bibblock">
Y.&nbsp;Zhuang, Y.&nbsp;Yu, K.&nbsp;Wang, H.&nbsp;Sun, and C.&nbsp;Zhang, “Toolqa: A dataset for llm question answering with external tools,” <em id="bib.bib199.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.13304</em>, 2023.

</span>
</li>
<li id="bib.bib200" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[200]</span>
<span class="ltx_bibblock">
D.&nbsp;Chen, J.&nbsp;Bolton, and C.&nbsp;D. Manning, “A thorough examination of the cnn/daily mail reading comprehension task,” in <em id="bib.bib200.1.1" class="ltx_emph ltx_font_italic">Association for Computational Linguistics (ACL)</em>, 2016.

</span>
</li>
<li id="bib.bib201" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[201]</span>
<span class="ltx_bibblock">
R.&nbsp;Nallapati, B.&nbsp;Zhou, C.&nbsp;Gulcehre, B.&nbsp;Xiang <em id="bib.bib201.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Abstractive text summarization using sequence-to-sequence rnns and beyond,” <em id="bib.bib201.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1602.06023</em>, 2016.

</span>
</li>
<li id="bib.bib202" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[202]</span>
<span class="ltx_bibblock">
Y.&nbsp;Bai and D.&nbsp;Z. Wang, “More than reading comprehension: A survey on datasets and metrics of textual question answering,” <em id="bib.bib202.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.12264</em>, 2021.

</span>
</li>
<li id="bib.bib203" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[203]</span>
<span class="ltx_bibblock">
H.-Y. Huang, E.&nbsp;Choi, and W.-t. Yih, “Flowqa: Grasping flow in history for conversational machine comprehension,” <em id="bib.bib203.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1810.06683</em>, 2018.

</span>
</li>
<li id="bib.bib204" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[204]</span>
<span class="ltx_bibblock">
S.&nbsp;Lee, J.&nbsp;Lee, H.&nbsp;Moon, C.&nbsp;Park, J.&nbsp;Seo, S.&nbsp;Eo, S.&nbsp;Koo, and H.&nbsp;Lim, “A survey on evaluation metrics for machine translation,” <em id="bib.bib204.1.1" class="ltx_emph ltx_font_italic">Mathematics</em>, vol.&nbsp;11, no.&nbsp;4, p. 1006, 2023.

</span>
</li>
<li id="bib.bib205" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[205]</span>
<span class="ltx_bibblock">
J.&nbsp;Li, X.&nbsp;Cheng, W.&nbsp;X. Zhao, J.-Y. Nie, and J.-R. Wen, “Halueval: A large-scale hallucination evaluation benchmark for large language models,” in <em id="bib.bib205.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, 2023, pp. 6449–6464.

</span>
</li>
<li id="bib.bib206" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[206]</span>
<span class="ltx_bibblock">
Simon Mark Hughes, “Hughes hallucination evaluation model (hhem) leaderboard,” 2024, <a target="_blank" href="https://huggingface.co/spaces/vectara/Hallucination-evaluation-leaderboard" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/spaces/vectara/Hallucination-evaluation-leaderboard</a>, Last accessed on 2024-01-21.

</span>
</li>
<li id="bib.bib207" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[207]</span>
<span class="ltx_bibblock">
J.&nbsp;Kaddour, J.&nbsp;Harris, M.&nbsp;Mozes, H.&nbsp;Bradley, R.&nbsp;Raileanu, and R.&nbsp;McHardy, “Challenges and applications of large language models,” <em id="bib.bib207.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.10169</em>, 2023.

</span>
</li>
<li id="bib.bib208" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[208]</span>
<span class="ltx_bibblock">
S.&nbsp;Gunasekar, Y.&nbsp;Zhang, J.&nbsp;Aneja, C.&nbsp;C.&nbsp;T. Mendes, A.&nbsp;Del&nbsp;Giorno, S.&nbsp;Gopi, M.&nbsp;Javaheripi, P.&nbsp;Kauffmann, G.&nbsp;de&nbsp;Rosa, O.&nbsp;Saarikivi <em id="bib.bib208.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Textbooks are all you need,” <em id="bib.bib208.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.11644</em>, 2023.

</span>
</li>
<li id="bib.bib209" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[209]</span>
<span class="ltx_bibblock">
Y.&nbsp;Li, S.&nbsp;Bubeck, R.&nbsp;Eldan, A.&nbsp;Del&nbsp;Giorno, S.&nbsp;Gunasekar, and Y.&nbsp;T. Lee, “Textbooks are all you need ii: phi-1.5 technical report,” <em id="bib.bib209.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.05463</em>, 2023.

</span>
</li>
<li id="bib.bib210" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[210]</span>
<span class="ltx_bibblock">
M.&nbsp;Poli, S.&nbsp;Massaroli, E.&nbsp;Nguyen, D.&nbsp;Y. Fu, T.&nbsp;Dao, S.&nbsp;Baccus, Y.&nbsp;Bengio, S.&nbsp;Ermon, and C.&nbsp;Ré, “Hyena hierarchy: Towards larger convolutional language models,” 2023.

</span>
</li>
<li id="bib.bib211" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[211]</span>
<span class="ltx_bibblock">
M.&nbsp;Poli, J.&nbsp;Wang, S.&nbsp;Massaroli, J.&nbsp;Quesnelle, E.&nbsp;Nguyen, and A.&nbsp;Thomas, “StripedHyena: Moving Beyond Transformers with Hybrid Signal Processing Models,” 12 2023. [Online]. Available: <a target="_blank" href="https://github.com/togethercomputer/stripedhyena" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/togethercomputer/stripedhyena</a>

</span>
</li>
<li id="bib.bib212" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[212]</span>
<span class="ltx_bibblock">
D.&nbsp;Y. Fu, S.&nbsp;Arora, J.&nbsp;Grogan, I.&nbsp;Johnson, S.&nbsp;Eyuboglu, A.&nbsp;W. Thomas, B.&nbsp;Spector, M.&nbsp;Poli, A.&nbsp;Rudra, and C.&nbsp;Ré, “Monarch mixer: A simple sub-quadratic gemm-based architecture,” 2023.

</span>
</li>
<li id="bib.bib213" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[213]</span>
<span class="ltx_bibblock">
G.&nbsp;J. McLachlan, S.&nbsp;X. Lee, and S.&nbsp;I. Rathnayake, “Finite mixture models,” <em id="bib.bib213.1.1" class="ltx_emph ltx_font_italic">Annual review of statistics and its application</em>, vol.&nbsp;6, pp. 355–378, 2019.

</span>
</li>
<li id="bib.bib214" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[214]</span>
<span class="ltx_bibblock">
H.&nbsp;Liu, C.&nbsp;Li, Q.&nbsp;Wu, and Y.&nbsp;J. Lee, “Visual instruction tuning,” <em id="bib.bib214.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.08485</em>, 2023.

</span>
</li>
<li id="bib.bib215" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[215]</span>
<span class="ltx_bibblock">
S.&nbsp;Liu, H.&nbsp;Cheng, H.&nbsp;Liu, H.&nbsp;Zhang, F.&nbsp;Li, T.&nbsp;Ren, X.&nbsp;Zou, J.&nbsp;Yang, H.&nbsp;Su, J.&nbsp;Zhu, L.&nbsp;Zhang, J.&nbsp;Gao, and C.&nbsp;Li, “Llava-plus: Learning to use tools for creating multimodal agents,” <em id="bib.bib215.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.05437</em>, 2023.

</span>
</li>
<li id="bib.bib216" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[216]</span>
<span class="ltx_bibblock">
S.&nbsp;Wu, H.&nbsp;Fei, L.&nbsp;Qu, W.&nbsp;Ji, and T.-S. Chua, “Next-gpt: Any-to-any multimodal llm,” <em id="bib.bib216.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.05519</em>, 2023.

</span>
</li>
<li id="bib.bib217" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[217]</span>
<span class="ltx_bibblock">
N.&nbsp;N. Khasmakhi, M.&nbsp;Asgari-Chenaghlu, N.&nbsp;Asghar, P.&nbsp;Schaer, and D.&nbsp;Zühlke, “Convgenvismo: Evaluation of conversational generative vision models,” 2023.

</span>
</li>
<li id="bib.bib218" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[218]</span>
<span class="ltx_bibblock">
N.&nbsp;Alshahwan, J.&nbsp;Chheda, A.&nbsp;Finegenova, B.&nbsp;Gokkaya, M.&nbsp;Harman, I.&nbsp;Harper, A.&nbsp;Marginean, S.&nbsp;Sengupta, and E.&nbsp;Wang, “Automated unit test improvement using large language models at meta,” <em id="bib.bib218.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2402.09171</em>, 2024.

</span>
</li>
<li id="bib.bib219" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[219]</span>
<span class="ltx_bibblock">
L.&nbsp;Sun, Y.&nbsp;Huang, H.&nbsp;Wang, S.&nbsp;Wu, Q.&nbsp;Zhang, C.&nbsp;Gao, Y.&nbsp;Huang, W.&nbsp;Lyu, Y.&nbsp;Zhang, X.&nbsp;Li <em id="bib.bib219.1.1" class="ltx_emph ltx_font_italic">et&nbsp;al.</em>, “Trustllm: Trustworthiness in large language models,” <em id="bib.bib219.2.2" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2401.05561</em>, 2024.

</span>
</li>
<li id="bib.bib220" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[220]</span>
<span class="ltx_bibblock">
Microsoft. Deepspeed. [Online]. Available: <a target="_blank" href="https://github.com/microsoft/DeepSpeed" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/microsoft/DeepSpeed</a>

</span>
</li>
<li id="bib.bib221" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[221]</span>
<span class="ltx_bibblock">
HuggingFace. Transformers. [Online]. Available: <a target="_blank" href="https://github.com/huggingface/transformers" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/huggingface/transformers</a>

</span>
</li>
<li id="bib.bib222" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[222]</span>
<span class="ltx_bibblock">
Nvidia. Megatron. [Online]. Available: <a target="_blank" href="https://github.com/NVIDIA/Megatron-LM" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/NVIDIA/Megatron-LM</a>

</span>
</li>
<li id="bib.bib223" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[223]</span>
<span class="ltx_bibblock">
BMTrain. Bmtrain. [Online]. Available: <a target="_blank" href="https://github.com/OpenBMB/BMTrain" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/OpenBMB/BMTrain</a>

</span>
</li>
<li id="bib.bib224" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[224]</span>
<span class="ltx_bibblock">
EleutherAI. gpt-neox. [Online]. Available: <a target="_blank" href="https://github.com/EleutherAI/gpt-neox" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/EleutherAI/gpt-neox</a>

</span>
</li>
<li id="bib.bib225" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[225]</span>
<span class="ltx_bibblock">
microsoft. Lora. [Online]. Available: <a target="_blank" href="https://github.com/microsoft/LoRA" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/microsoft/LoRA</a>

</span>
</li>
<li id="bib.bib226" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[226]</span>
<span class="ltx_bibblock">
ColossalAI. Colossalai. [Online]. Available: <a target="_blank" href="https://github.com/hpcaitech/ColossalAI" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/hpcaitech/ColossalAI</a>

</span>
</li>
<li id="bib.bib227" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[227]</span>
<span class="ltx_bibblock">
FastChat. Fastchat. [Online]. Available: <a target="_blank" href="https://github.com/lm-sys/FastChat" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/lm-sys/FastChat</a>

</span>
</li>
<li id="bib.bib228" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[228]</span>
<span class="ltx_bibblock">
skypilot. skypilot. [Online]. Available: <a target="_blank" href="https://github.com/skypilot-org/skypilot" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/skypilot-org/skypilot</a>

</span>
</li>
<li id="bib.bib229" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[229]</span>
<span class="ltx_bibblock">
vllm. vllm. [Online]. Available: <a target="_blank" href="https://github.com/vllm-project/vllm" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/vllm-project/vllm</a>

</span>
</li>
<li id="bib.bib230" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[230]</span>
<span class="ltx_bibblock">
huggingface. text-generation-inference. [Online]. Available: <a target="_blank" href="https://github.com/huggingface/text-generation-inference" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/huggingface/text-generation-inference</a>

</span>
</li>
<li id="bib.bib231" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[231]</span>
<span class="ltx_bibblock">
langchain. langchain. [Online]. Available: <a target="_blank" href="https://github.com/langchain-ai/langchain" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/langchain-ai/langchain</a>

</span>
</li>
<li id="bib.bib232" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[232]</span>
<span class="ltx_bibblock">
bentoml. Openllm. [Online]. Available: <a target="_blank" href="https://github.com/bentoml/OpenLLM" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/bentoml/OpenLLM</a>

</span>
</li>
<li id="bib.bib233" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[233]</span>
<span class="ltx_bibblock">
embedchain. embedchain. [Online]. Available: <a target="_blank" href="https://github.com/embedchain/embedchain" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/embedchain/embedchain</a>

</span>
</li>
<li id="bib.bib234" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[234]</span>
<span class="ltx_bibblock">
microsoft. autogen. [Online]. Available: <a target="_blank" href="https://github.com/microsoft/autogen" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/microsoft/autogen</a>

</span>
</li>
<li id="bib.bib235" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[235]</span>
<span class="ltx_bibblock">
babyagi. babyagi. [Online]. Available: <a target="_blank" href="https://github.com/yoheinakajima/babyagi" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/yoheinakajima/babyagi</a>

</span>
</li>
<li id="bib.bib236" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[236]</span>
<span class="ltx_bibblock">
guidance. guidance. [Online]. Available: <a target="_blank" href="https://github.com/guidance-ai/guidance" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/guidance-ai/guidance</a>

</span>
</li>
<li id="bib.bib237" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[237]</span>
<span class="ltx_bibblock">
prompttools. prompttools. [Online]. Available: <a target="_blank" href="https://github.com/hegelai/prompttools" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/hegelai/prompttools</a>

</span>
</li>
<li id="bib.bib238" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[238]</span>
<span class="ltx_bibblock">
promptfoo. promptfoo. [Online]. Available: <a target="_blank" href="https://github.com/promptfoo/promptfoo" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/promptfoo/promptfoo</a>

</span>
</li>
<li id="bib.bib239" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[239]</span>
<span class="ltx_bibblock">
facebook. faiss. [Online]. Available: <a target="_blank" href="https://github.com/facebookresearch/faiss" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/facebookresearch/faiss</a>

</span>
</li>
<li id="bib.bib240" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[240]</span>
<span class="ltx_bibblock">
milvus. milvus. [Online]. Available: <a target="_blank" href="https://github.com/milvus-io/milvus" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/milvus-io/milvus</a>

</span>
</li>
<li id="bib.bib241" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[241]</span>
<span class="ltx_bibblock">
qdrant. qdrant. [Online]. Available: <a target="_blank" href="https://github.com/qdrant/qdrant" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/qdrant/qdrant</a>

</span>
</li>
<li id="bib.bib242" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[242]</span>
<span class="ltx_bibblock">
weaviate. weaviate. [Online]. Available: <a target="_blank" href="https://github.com/weaviate/weaviate" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/weaviate/weaviate</a>

</span>
</li>
<li id="bib.bib243" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[243]</span>
<span class="ltx_bibblock">
llama index. llama-index. [Online]. Available: <a target="_blank" href="https://github.com/run-llama/llama_index" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/run-llama/llama_index</a>

</span>
</li>
</ul>
</section>
<div id="p1" class="ltx_para">
<p class="ltx_p" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1">1. Open Source Toolkits For LLM Development and Deployment</span></p>
</div>
<div id="p2" class="ltx_para">
<p class="ltx_p" id="p2.1">LLM 교육, 평가 및 배치를 위해 개발된 다양한 프레임워크와 라이브러리가 있으며 모든 프레임워크를 포괄하는 것은 본 논문의 범위를 벗어난다. 그러나 우리는 다른 범주로 그룹화된 가장 인기 있는 몇 가지에 대한 간략한 소개를 제공하고자 합니다.</p>
</div>
<section id="A0.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="A0.SS1.5.1.1" class="ltx_text">-A</span> </span><span id="A0.SS1.6.2" class="ltx_text ltx_font_italic">LLM Training/Inference Frameworks</span>
</h3>

<div id="A0.SS1.p1" class="ltx_para">
<p class="ltx_p" id="A0.SS1.p1.1">LLM 트레이닝에 유용한 인기 있는 프레임워크들 중 일부는 (그들 중 일부는 LLM 트레이닝을 넘어서도 사용될 수 있다는 점에 주목한다):</p>
</div>
<div id="A0.SS1.p2" class="ltx_para">
<p class="ltx_p" id="A0.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="A0.SS1.p2.1.1">DeepSpeed</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib220" title="">220</a>]</cite>는 분산 학습 및 추론을 쉽고 효율적이며 효과적으로 만드는 딥러닝 최적화 라이브러리이다. 딥스피드는 MT-530B와 BLOOM과 같은 세계에서 가장 강력한 언어 모델을 가능하게 한다. 훈련과 추론 모두에 전례 없는 규모와 속도를 제공하는 사용하기 쉬운 딥러닝 최적화 소프트웨어 제품군입니다. 딥스피드를 사용하면...</p>
</div>
<div id="A0.SS1.p3" class="ltx_para">
<p class="ltx_p" id="A0.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="A0.SS1.p3.1.1">Transformers</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib221" title="">221</a>]</cite> is library by HuggingFace which provides thousands of pretrained models to perform tasks on different modalities such such text, vision, and audio. 사전 훈련된 모델을 사용하면 컴퓨팅 비용, 탄소 발자국을 줄이고 모델을 처음부터 훈련하는 데 필요한 시간과 리소스를 절약할 수 있습니다.</p>
</div>
<div id="A0.SS1.p4" class="ltx_para">
<p class="ltx_p" id="A0.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="A0.SS1.p4.1.1">Megatron-LM</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib222" title="">222</a>]</cite>는 NVIDIA의 Applied Deep Learning Research team에 의해 개발된 크고 강력한 트랜스포머이다. 효율적인 모델 병렬(텐서, 시퀀스, 파이프라인)과 혼합 정밀도를 이용한 GPT, BERT, T5와 같은 변압기 기반 모델의 다중 노드 사전 훈련을 포함한다.</p>
</div>
<div id="A0.SS1.p5" class="ltx_para">
<p class="ltx_p" id="A0.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="A0.SS1.p5.1.1">BMTrain</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib223" title="">223</a>]</cite>는 수백억 개의 파라미터를 가진 대형 모델을 훈련하는데 사용될 수 있는 효율적인 대형 모델 훈련 툴킷이다. 독립형 훈련처럼 코드를 단순하게 유지하면서 분산 방식으로 모델을 훈련할 수 있습니다.</p>
</div>
<div id="A0.SS1.p6" class="ltx_para">
<p class="ltx_p" id="A0.SS1.p6.1"><span class="ltx_text ltx_font_bold" id="A0.SS1.p6.1.1">GPT-NeoX</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib224" title="">224</a>]</cite>는 인기 있는 Megatron-DeepSpeed 라이브러리와 동일한 많은 기능 및 기술을 활용하지만 사용성과 새로운 최적화가 상당히 증가했습니다.</p>
</div>
<div id="A0.SS1.p7" class="ltx_para">
<p class="ltx_p" id="A0.SS1.p7.1"><span class="ltx_text ltx_font_bold" id="A0.SS1.p7.1.1">LoRA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib225" title="">225</a>]</cite> 라이브러리는 Large Language Models의 Low-Rank Adaptation에 대한 지원을 제공합니다. 원래 가중치를 동결시키면서 순위-분해 행렬 쌍을 학습하여 훈련 가능한 매개변수의 수를 줄인다. 이는 특정 태스크에 적응된 대규모 언어 모델에 대한 스토리지 요구 사항을 크게 감소시키고, 추론 대기 시간을 도입하지 않고도 배치 동안 효율적인 태스크 전환을 가능하게 한다. LoRA는 또한 어댑터, 접두사 튜닝 및 미세 조정을 포함한 여러 다른 적응 방법을 능가한다.</p>
</div>
<div id="A0.SS1.p8" class="ltx_para">
<p class="ltx_p" id="A0.SS1.p8.1"><span class="ltx_text ltx_font_bold" id="A0.SS1.p8.1.1">ColossalAI</span> library <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib226" title="">226</a>]</cite>는 병렬 컴포넌트들의 컬렉션을 제공한다. 개발자가 노트북에 모델을 쓰는 것처럼 분산 딥러닝 모델을 쓸 수 있도록 지원하는 것을 목표로 한다. 그들은 몇 줄로 분산된 훈련과 추론을 시작할 수 있는 사용자 친화적인 도구를 제공한다. 병렬성 전략 측면에서는 데이터 병렬성, 파이프라인 병렬성, 시퀀스 병렬성, ZeRO(Zero Redundancy Optimizer) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib140" title="">140</a>]</cite>, Auto-Parallelism을 지원한다.</p>
</div>
</section>
<section id="A0.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="A0.SS2.5.1.1" class="ltx_text">-B</span> </span><span id="A0.SS2.6.2" class="ltx_text ltx_font_italic">Deployment Tools</span>
</h3>

<div id="A0.SS2.p1" class="ltx_para">
<p class="ltx_p" id="A0.SS2.p1.1">여기에서 가장 인기 있는 LLM 배포 도구 중 일부에 대한 개요를 제공합니다.</p>
</div>
<div id="A0.SS2.p2" class="ltx_para">
<p class="ltx_p" id="A0.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="A0.SS2.p2.1.1">FastChat</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib227" title="">227</a>]</cite>는 대용량 언어 모델 기반 챗봇을 교육, 서비스 및 평가하기 위한 개방형 플랫폼이다. FastChat의 핵심 기능에는 다음과 같은 최신 모델(예: Vicuna, MT-Bench)에 대한 훈련 및 평가 코드와 웹 UI 및 OpenAI 호환 RESTful API가 있는 분산 다중 모델 서빙 시스템이 포함됩니다.</p>
</div>
<div id="A0.SS2.p3" class="ltx_para">
<p class="ltx_p" id="A0.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="A0.SS2.p3.1.1">Skypilot</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib228" title="">228</a>]</cite>는 모든 클라우드에서 LLM, AI 및 배치 작업을 실행하기 위한 프레임워크로 최대 비용 절감, 최고 GPU 가용성 및 관리 실행을 제공합니다.</p>
</div>
<div id="A0.SS2.p4" class="ltx_para">
<p class="ltx_p" id="A0.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="A0.SS2.p4.1.1">vLLM</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib229" title="">229</a>]</cite>는 LLM 추론 및 서빙을 위한 빠르고 사용하기 쉬운 라이브러리이다. vLLM은 Aquila, Baichuan, BLOOM, ChatGLM, DeciLM, Falcon, GPT BigCode, LLaMA, LLaMA 2, Mistral, Mixtral, MPT, OPT, Qwen, Yi 등의 아키텍처를 포함하여 많은 Hugging Face 모델을 원활하게 지원합니다.</p>
</div>
<div id="A0.SS2.p5" class="ltx_para">
<p class="ltx_p" id="A0.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="A0.SS2.p5.1.1">text-generation-inference</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib230" title="">230</a>]</cite>는 LLM(Large Language Models)을 배포하고 서빙하기 위한 toolkit이다. TGI는 라마, 팔콘, 스타코더, BLOOM, GPT-NeoX 등을 포함한 가장 인기 있는 오픈 소스 LLM에 대한 고성능 텍스트 생성을 가능하게 한다.</p>
</div>
<div id="A0.SS2.p6" class="ltx_para">
<p class="ltx_p" id="A0.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="A0.SS2.p6.1.1">LangChain</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib231" title="">231</a>]</cite>는 언어 모델에 의해 구동되는 애플리케이션을 개발하기 위한 프레임워크이다. 응용 프로그램을 사용 하도록 설정 하면 다음과 같습니다.</p>
<ul id="A0.I1" class="ltx_itemize">
<li id="A0.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A0.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="A0.I1.i1.p1.1">상황 인식: 언어 모델을 컨텍스트의 소스(빠른 명령, 몇 개의 샷 예, 응답을 접지할 내용 등)에 연결합니다.</p>
</div>
</li>
<li id="A0.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A0.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="A0.I1.i2.p1.1">이유: 언어 모델에 의존하여 추론(제공된 컨텍스트를 기반으로 답변하는 방법, 취해야 할 조치 등에 대해)</p>
</div>
</li>
</ul>
</div>
<div id="A0.SS2.p7" class="ltx_para">
<p class="ltx_p" id="A0.SS2.p7.1"><span class="ltx_text ltx_font_bold" id="A0.SS2.p7.1.1">OpenLLM</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib232" title="">232</a>]</cite>는 실제 애플리케이션에서 큰 언어 모델(LLM)의 배포 및 작동을 용이하게 하도록 설계된 오픈 소스 플랫폼이다. OpenLLM을 사용하면 모든 오픈 소스 LLM에서 추론을 실행하고 클라우드 또는 온-프레미스에 배포하고 강력한 AI 애플리케이션을 빌드할 수 있습니다.</p>
</div>
<div id="A0.SS2.p8" class="ltx_para">
<p class="ltx_p" id="A0.SS2.p8.1"><span class="ltx_text ltx_font_bold" id="A0.SS2.p8.1.1">Embedchain</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib233" title="">233</a>]</cite>는 AI 앱을 쉽게 만들고 배포할 수 있는 오픈 소스 RAG 프레임워크입니다. 임베드 체인은 RAG 애플리케이션 생성을 간소화하여 다양한 유형의 비정형 데이터를 관리하기 위한 원활한 프로세스를 제공합니다. 데이터를 관리 가능한 청크로 효율적으로 분할하고 관련 임베딩을 생성하여 벡터 데이터베이스에 저장하여 최적화된 검색을 수행한다.</p>
</div>
<div id="A0.SS2.p9" class="ltx_para">
<p class="ltx_p" id="A0.SS2.p9.1"><span class="ltx_text ltx_font_bold" id="A0.SS2.p9.1.1">Autogen</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib234" title="">234</a>]</cite>는 태스크를 해결하기 위해 서로 수렴할 수 있는 여러 에이전트를 사용하여 LLM 애플리케이션의 개발을 가능하게 하는 프레임워크이다. 오토젠 에이전트는 사용자 정의 가능하고, 대화 가능하며, 사람의 참여를 원활하게 할 수 있습니다. 그들은 LLM, 인간 입력 및 도구의 조합을 사용하는 다양한 모드에서 작동할 수 있다.</p>
</div>
<div id="A0.SS2.p10" class="ltx_para">
<p class="ltx_p" id="A0.SS2.p10.1"><span class="ltx_text ltx_font_bold" id="A0.SS2.p10.1.1">BabyAGI</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib235" title="">235</a>]</cite>는 자율 인공지능 에이전트로, 주어진 목표를 기반으로 작업을 생성하고 실행하도록 설계되었습니다. 오픈AI, 파인콘, 랭체인, 크로마 등 첨단 기술을 활용해 업무를 자동화하고 구체적인 목표를 달성한다. 이 블로그 게시물에서는 BabyAGI의 고유한 기능에 대해 살펴보고 작업 자동화를 간소화할 수 있는 방법을 탐색할 것입니다.</p>
</div>
</section>
<section id="A0.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="A0.SS3.5.1.1" class="ltx_text">-C</span> </span><span id="A0.SS3.6.2" class="ltx_text ltx_font_italic">Prompting Libraries</span>
</h3>

<div id="A0.SS3.p1" class="ltx_para">
<p class="ltx_p" id="A0.SS3.p1.1"><span class="ltx_text ltx_font_bold" id="A0.SS3.p1.1.1">Guidance</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib236" title="">236</a>]</cite>는 기존의 프롬프트 및 체인화에 비해 우수한 제어 및 효율성을 제공하는 프로그래밍 패러다임이다. 이를 통해 사용자는 생성(예: regex 및 CFG 포함)을 제한하고 제어(조건부, 루프) 및 생성을 원활하게 인터리브할 수 있습니다.</p>
</div>
<div id="A0.SS3.p2" class="ltx_para">
<p class="ltx_p" id="A0.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="A0.SS3.p2.1.1">PromptTools</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib237" title="">237</a>]</cite>는 LLMs, 벡터 데이터베이스 및 프롬프트를 사용하여 실험, 테스트 및 평가하기 위한 오픈 소스 자체 호스팅 가능한 도구 세트를 제공합니다. 핵심 아이디어는 개발자가 코드, 노트북, 지역 놀이터와 같은 친숙한 인터페이스를 사용하여 평가할 수 있도록 하는 것입니다.</p>
</div>
<div id="A0.SS3.p3" class="ltx_para">
<p class="ltx_p" id="A0.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="A0.SS3.p3.1.1">PromptBench</span> <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">promptbench</span>]</cite>는 Pytorch-based Python package for Evaluation of Large Language Models (LLMs)이다. 연구자가 LLMs에 대한 평가를 수행할 수 있는 사용자 친화적인 API를 제공합니다.</p>
</div>
<div id="A0.SS3.p4" class="ltx_para">
<p class="ltx_p" id="A0.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="A0.SS3.p4.1.1">Promptfoo</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib238" title="">238</a>]</cite>는 LLM 출력 품질을 테스트하고 평가하는 도구입니다. 미리 정의된 테스트 케이스를 사용하여 프롬프트, 모델 및 RAG를 체계적으로 테스트합니다.</p>
</div>
</section>
<section id="A0.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="A0.SS4.5.1.1" class="ltx_text">-D</span> </span><span id="A0.SS4.6.2" class="ltx_text ltx_font_italic">VectorDB</span>
</h3>

<div id="A0.SS4.p1" class="ltx_para">
<p class="ltx_p" id="A0.SS4.p1.1"><span class="ltx_text ltx_font_bold" id="A0.SS4.p1.1.1">Faiss</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib239" title="">239</a>]</cite>는 페이스북 AI Research에서 개발한 라이브러리로 조밀한 벡터의 효율적인 유사성 검색 및 클러스터링을 제공한다. 대규모 고차원 데이터와 함께 사용할 수 있도록 설계되었으며 다양한 사용 사례에 대한 여러 인덱스 유형과 알고리즘을 지원합니다.</p>
</div>
<div id="A0.SS4.p2" class="ltx_para">
<p class="ltx_p" id="A0.SS4.p2.1"><span class="ltx_text ltx_font_bold" id="A0.SS4.p2.1.1">Milvus</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib240" title="">240</a>]</cite>는 파워 임베딩 유사성 검색 및 AI 애플리케이션을 위해 구축된 오픈 소스 벡터 데이터베이스이다. 밀버스는 비정형 데이터 검색에 더 쉽게 접근할 수 있도록 하며, 배포 환경에 관계없이 일관된 사용자 경험을 제공한다.</p>
</div>
<div id="A0.SS4.p3" class="ltx_para">
<p class="ltx_p" id="A0.SS4.p3.1"><span class="ltx_text ltx_font_bold" id="A0.SS4.p3.1.1">Qdrant</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib241" title="">241</a>]</cite>는 벡터 유사도 검색 엔진 및 벡터 데이터베이스이다. 포인트를 저장, 검색 및 관리할 수 있는 편리한 API를 사용하여 프로덕션 준비 서비스를 제공합니다. 추가 페이로드가 있는 벡터는 확장 필터링 지원에 맞게 조정됩니다. 환경.</p>
</div>
<div id="A0.SS4.p4" class="ltx_para">
<p class="ltx_p" id="A0.SS4.p4.1"><span class="ltx_text ltx_font_bold" id="A0.SS4.p4.1.1">Weaviate</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib242" title="">242</a>]</cite>는 고차원 데이터에 대한 유사성 검색을 가능하게 하는 오픈 소스, GraphQL 기반 벡터 검색 엔진이다. 오픈 소스이지만 상용 버전은 추가 기능, 지원 및 관리 서비스를 제공합니다.</p>
</div>
<div id="A0.SS4.p5" class="ltx_para">
<p class="ltx_p" id="A0.SS4.p5.1">다른 인기 있는 옵션 중 일부는 <span class="ltx_text ltx_font_bold" id="A0.SS4.p5.1.1">LlamaIndex</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib243" title="">243</a>]</cite> 및 <span class="ltx_text ltx_font_bold" id="A0.SS4.p5.1.2">Pinecone</span>을 포함한다.</p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2402.06195" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2402.06196" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2402.06196">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2402.06196" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2402.06197" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar  5 17:44:42 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>