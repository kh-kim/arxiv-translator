<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# GaLore: Gradient Low-Rank Projection에 의한 Memory-Efficient LLM Training\n' +
      '\n' +
      'Jiawei Zhao\n' +
      '\n' +
      'Zhenyu Zhang\n' +
      '\n' +
      'Beidi Chen\n' +
      '\n' +
      'Zhangyang Wang\n' +
      '\n' +
      'Anima Anandkumar\n' +
      '\n' +
      'Yuandong Tian\n' +
      '\n' +
      '동등고문 1캘리포니아 기술연구소 2메타 AI\n' +
      '\n' +
      '각주 1: 계산은 LLaMA 아키텍처, BF16 수치 포맷, 및 2048의 최대 시퀀스 길이에 기초한다.\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '대용량 언어 모델(LLM)을 훈련하는 것은 주로 가중치의 크기 및 최적화 상태들의 증가로 인해 상당한 메모리 과제들을 제시한다. 저순위 적응(LoRA)과 같은 일반적인 메모리 감소 접근법들은 각각의 계층에서 동결된 사전-훈련된 가중치에 훈련가능한 저순위 매트릭스를 추가하여, 훈련가능한 파라미터들 및 최적화기 상태들을 감소시킨다. 그러나, 이러한 접근법들은 일반적으로 파라미터 탐색을 낮은 순위 하위 공간으로 제한하고 훈련 역학을 변경하기 때문에 사전 훈련 및 미세 조정 단계 모두에서 풀 순위 가중치로 훈련을 덜 수행하고, 나아가 풀 순위 웜 스타트(full-rank warm start)를 요구할 수 있다. 이 작업에서는 _전체 매개 변수_ 학습을 허용하지만 LoRA와 같은 일반적인 하위 순위 적응 방법보다 더 _메모리 효율이 높은 훈련 전략인 Gradient Low-Rank Projection(**GaLore**)을 제안한다. 제안하는 방법은 최대 19.7B 토큰이 있는 C4 데이터 세트를 사용하는 LLaMA 1B 및 7B 아키텍처와 GLUE 태스크에서 RoBERTa를 미세 조정하기 위한 사전 훈련에 대한 효율성과 성능을 유지하면서 최적화 상태에서 메모리 사용량을 최대 65.5%까지 줄인다. 우리의 8비트 GaLore는 BF16 기준선에 비해 최적화기 메모리를 최대 82.5%, 총 훈련 메모리를 63.3% 더 줄였다. 특히, 우리는 모델 병렬, 체크포인팅 또는 오프로딩 전략 없이 24GB 메모리(예: NVIDIA RTX 4090)가 있는 소비자 GPU에서 7B 모델을 사전 훈련하는 가능성을 처음으로 보여준다.\n' +
      '\n' +
      '머신러닝, ICML\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '대형 언어 모델(LLM)은 대화형 AI 및 언어 번역을 포함한 여러 분야에서 인상적인 성능을 보여주었다. 그러나 사전 학습 및 미세 조정 LLM은 방대한 계산량을 필요로 할 뿐만 아니라 메모리 집약적이다. 메모리 요건들은 수십억 개의 훈련 가능한 파라미터들뿐만 아니라, 파라미터 저장 자체보다 더 클 수 있는 그들의 구배들 및 최적화기 상태들(예를 들어, Adam에서의 구배 운동량 및 분산)을 포함한다(Raffel 등, 2023; Touvron 등, 2023; Chowdhery 등, 2022). 예를 들어, 단일 배치 크기를 갖는 LLaMA 7B 모델을 처음부터 사전 트레이닝하려면 적어도 58GB 메모리(트레이닝 가능한 파라미터의 경우 14GB, 아담 최적화기 상태 및 가중치 그라디언트의 경우 42GB, 활성화 1의 경우 2GB)가 필요하다. 이것은 24GB 메모리를 가진 NVIDIA RTX 4090과 같은 소비자 수준의 GPU에서 교육을 실현 가능하지 않게 만든다.\n' +
      '\n' +
      '각주 1: 계산은 LLaMA 아키텍처, BF16 수치 포맷, 및 2048의 최대 시퀀스 길이에 기초한다.\n' +
      '\n' +
      '그래디언트 체크포인팅(Chen et al., 2016), 메모리 오프로딩(Rajbhandari et al., 2020) 등과 같은 엔지니어링 및 시스템 노력 외에도, 연구자들은 보다 빠르고 효율적인 분산 훈련을 달성하기 위해 사전 훈련 및 미세 조정 동안 메모리 사용량을 감소시키기 위한 다양한 최적화 기술을 개발하고자 한다.\n' +
      '\n' +
      '도 1: 활성화 체크포인팅 및 메모리 오프로딩 없이, 단일 디바이스 상에서 256의 토큰 배치 크기를 갖는 LLaMA 7B 모델을 사전 트레이닝하는 메모리 소비. 자세한 내용은 섹션 5.5를 참조하십시오.\n' +
      '\n' +
      '파라미터-효율 미세-조정(PEFT) 기법들은 모델의 파라미터들 모두를 미세-조정할 필요 없이 상이한 다운스트림 애플리케이션들에 사전-훈련된 언어 모델들(PLMs)을 효율적으로 적응시키는 것을 허용한다(Ding 등, 2022). 그 중 Low-Rank Adaptation (LoRA Hu et al. (2021))은 가중치 행렬 \\(W\\in\\mathbb{R}^{m\\times n}\\)을 \\(W=W_{0}+BA\\)로 _reparameterize_하는데, 여기서 \\(W_{0}\\)는 동결된 전체 순위 행렬이고 \\(B\\in\\mathbb{R}^{m\\times r}\\), \\(A\\in\\mathbb{R}^{r\\times n}\\)는 학습해야 할 추가 저순위 적응기이다. 순위 \\(r\\ll\\min(m,n)\\), \\(A\\) 및 \\(B\\)는 훈련 가능한 매개 변수의 수가 적으므로 최적화 상태가 작습니다. LoRA는 \\(W_{0}\\)가 동결된 미리 훈련된 가중치인 미세 조정을 위해 메모리 사용량을 줄이기 위해 광범위하게 사용되어 왔다. 이 변형 ReLoRA는 또한 이전에 학습된 저순위 적응기를 사용하여 \\(W_{0}\\)를 주기적으로 업데이트함으로써 사전 훈련에 사용된다(Lialin et al., 2023).\n' +
      '\n' +
      '그러나 최근의 많은 연구들은 이러한 저순위 재매개변수의 한계를 보여주고 있다. 미세-조정을 위해, LoRA는 풀-랭크 미세-조정과 유사한 성능에 도달하는 것으로 도시되지 않는다(Xia et al., 2024). 처음부터 사전-트레이닝을 위해, 낮은-순위 서브공간에서 최적화하기 전에, 워밍업으로서 전체-순위 모델 트레이닝이 필요한 것으로 보여진다(Lialin et al., 2023). 두 가지 가능한 이유가 있다: (1) 최적의 가중치 행렬은 낮은 순위가 아닐 수 있고, (2) 재매개변수화는 구배 훈련 동역학을 변경한다.\n' +
      '\n' +
      '**우리의 접근 방식:** 위의 문제를 해결하기 위해 _전체 매개 변수_ 학습을 허용하지만 LoRA와 같은 일반적인 하위 순위 적응 방법보다 더 _메모리 효율이 높은 훈련 전략인 Gradient Low-rank Projection(**GaLore**)을 제안합니다. 우리의 핵심 아이디어는 가중치 매트릭스 자체를 낮은 순위로 근사하려는 것이 아니라 가중치 매트릭스 \\(W\\)의 _gradient_\\(G\\in\\mathbb{R}^{m\\times n}\\)의 느리게 변하는 낮은 순위 구조를 활용하는 것이다.\n' +
      '\n' +
      '먼저 훈련 과정에서 기울기 행렬 \\(G\\)이 낮은 순위가 됨을 이론적으로 보인다. 그리고 두 개의 투영행렬 \\(P\\in\\mathbb{R}^{m\\times r}\\)과 \\(Q\\in\\mathbb{R}^{n\\times r}\\)을 계산하여 기울기행렬 \\(G\\)을 저순위 형태로 투영하는 GaLore를 제안한다. 이 경우, 컴포넌트-와이즈 그래디언트 통계에 의존하는 최적화기 상태들의 메모리 비용은 실질적으로 감소될 수 있다. 때때로 \\(P\\) 및 \\(Q\\)의 업데이트(예를 들어, 200회 반복마다)는 최소 상각된 추가 계산 비용을 발생시킨다. GaLore는 표 1에 나타낸 바와 같이 LoRA보다 더 메모리-효율적이다. 실제로, 이것은 사전 트레이닝 동안 LoRA에 비해 최대 30%의 메모리 감소를 산출한다.\n' +
      '\n' +
      '우리는 GaLore가 LLM 사전 훈련과 미세 조정 모두에서 잘 작동한다는 것을 보여준다. C4 데이터 세트에서 LLaMA 7B를 사전 훈련할 때, 8비트 최적화기 및 계층별 가중치 업데이트 기술과 결합된 8비트 GaLore는 최적화기 상태의 10% 미만의 메모리 비용으로 전체 순위 대응물과 유사한 성능을 달성한다.\n' +
      '\n' +
      '특히 사전 훈련을 위해 GaLore는 ReLoRA와 같은 풀 랭크 훈련 워밍업을 요구하지 않고 전체 훈련 동안 낮은 메모리를 유지한다. GaLore의 메모리 효율성 덕분에, 처음으로, 비용이 많이 드는 메모리 오프로딩 기술들 없이, 24GB 메모리를 갖는 단일 GPU 상에서(예를 들어, NVIDIA RTX 4090 상에서) LLaMA 7B를 처음부터 트레이닝하는 것이 가능하다(도 1).\n' +
      '\n' +
      'GaLore는 GLUE 벤치마크에서 사전 훈련된 LLM을 기존 저순위 방법보다 비슷하거나 더 나은 결과로 미세 조정하는 데에도 사용된다. GLUE 작업에서 RoBERTaBase를 순위 4로 미세 조정하면 GaLore는 평균 85.89점을 달성하여 LoRA를 능가하여 85.61점을 달성한다.\n' +
      '\n' +
      'Gradient projection 방법으로 GaLore는 최적화기 선택에 독립적이며 알고리즘 1과 같이 두 줄의 코드만으로 기존의 것에 쉽게 연결할 수 있다. 우리의 실험 (그림 3) AdamW, 8비트 Adam 및 Adafactor와 같은 인기 있는 최적화 장치에 효과가 있음을 보여줍니다. 또한, 그 성능은 그것이 도입하는 극소수의 하이퍼-파라미터에 둔감하다. 또한, GaLore의 수렴 분석뿐만 아니라 Gradient 업데이트의 낮은 순위에 대한 이론적 정당성을 제공한다.\n' +
      '\n' +
      '## 2 관련 작업\n' +
      '\n' +
      'Low-Rank AdaptationHu et al.(2021)은 Low-Rank Adaptation(LoRA)을 제안하여 Low-Rank Adaptation을 이용하여 사전 학습된 모델을 미세 조정하였다. 이 방법은 각 레이어에 대해 낮은 랭크 가중치 어댑터를 유지함으로써 메모리 풋프린트를 감소시킨다. 그것의 성능을 향상시키기 위해 제안된 LoRA의 몇몇 변형들이 있다(Renduchintala et al., 2023; Sheng et al., 2023; Xia et al., 2024), 멀티-태스크 학습을 지원하며(Wang et al., 2023), 그리고 메모리 풋프린트를 더 감소시키기 위해 제안된다(Dettmers et al., 2023). Lialin et al. (2023)은 사전 훈련을 위해 설계된 LoRA의 변형인 ReLoRA를 제안했지만, 표준 기준선과 유사한 성능을 얻기 위해서는 전체 순위 훈련 워밍업이 필요하다.\n' +
      '\n' +
      '하위 공간 학습 최근 연구는 학습이 주로 상당히 저차원 파라미터 하위 공간 내에서 발생한다는 것을 입증하였다(Larsen et al., 2022; Gur-Ari et al., 2018). 이러한 결과는 모델 가중치가 하위 하위 공간 내에서 최적화되는 _하위 공간 학습_이라는 특수한 유형의 학습을 촉진합니다. 이 개념은 메타 학습 및 연속 학습을 포함한 기계 학습의 다양한 영역에서 널리 사용되어 왔다(Lee and Choi, 2018; Chaudhry et al., 2020).\n' +
      '\n' +
      'Projected Gradient DescentGaLore는 Projected Gradient descent(PGD)의 전통적인 주제와 밀접한 관련이 있다(Chen and Wainwright, 2015; Chen et al., 2019). 주요 차이점은 GaLore가 다층 신경망 작업을 훈련할 때 자연스럽게 나타나는 특정 기울기 형태(예: 특정 구조를 가진 행렬)를 고려하여 많은 특성(예: 렘마 3.1, 정리 3.2 및 정리 3.6)을 증명한다는 것이다. 대조적으로, 전통적인 PGD는 목적을 일반적인 블랙박스 비선형 함수로 취급하고 벡터 공간에서의 구배만을 연구한다.\n' +
      '\n' +
      '메모리-효율 최적화 적응 최적화 알고리즘들에 대한 그래디언트 통계의 메모리 비용을 감소시키려는 몇몇 연구들이 있었다(Shazeer & Stern; Anil et al.; Dettmers et al., 2021). Adafactor(Shazeer & Stern)는 행-열 외부 곱에 의해 2차 통계량을 인수분해함으로써 하위 선형 메모리 비용을 달성한다. Ga-Lore는 메모리 비용을 줄이기 위해 저순위 인수분해를 활용한다는 측면에서 Adafactor와 유사성을 공유하지만 Ga-Lore는 기울기의 저순위 구조에 초점을 맞추고 Adafactor는 2차 통계량의 저순위 구조에 초점을 맞춘다. Ga-Lore는 1차 및 2차 통계 모두에 대한 메모리 비용을 감소시킬 수 있고, 추가 메모리 감소를 달성하기 위해 Adafactor와 조합될 수 있다. 양자화는 또한 최적화기 상태들의 메모리 비용을 감소시키기 위해 널리 사용된다(Dettmers et al., 2021; Li et al., 2023). 또한, Lv et al. (2023)은 훈련 중 가중치 기울기를 저장하는 메모리 비용을 줄이기 위해 융합된 기울기 계산을 제안했다.\n' +
      '\n' +
      '기존의 메모리 효율 최적화 방법과는 달리, Ga-Lore는 최적화기들이 전체 랭크 대응들을 알지 못한 채 낮은 랭크 기울기들을 직접 수신함에 따라 독립적으로 동작한다.\n' +
      '\n' +
      '## 3 GaLore: Gradient Low-Rank Projection\n' +
      '\n' +
      '### Background\n' +
      '\n' +
      '정규 전체 순위 훈련 시간 단계 \\(t\\), \\(G_{t}=-\\nabla_{W}\\varphi_{t}(W_{t})\\in\\mathbb{R}^{m\\times n}\\)는 역전파(음) 구배 행렬이다. 그런 다음 정규 사전 훈련 가중치 업데이트는 다음과 같이 기록될 수 있다(\\(\\eta\\)는 학습율):\n' +
      '\n' +
      '\\[W_{T}=W_{0}+\\eta\\sum_{t=0}^{T-1}\\tilde{G}_{t}=W_{0}+\\eta\\sum_{t=0}^{T-1}\\rho _{t}(G_{t}) \\tag{1}\\]\n' +
      '\n' +
      '여기서, \\(\\tilde{G}_{t}\\)는 가중치 매트릭스에 추가될 최종 처리된 구배이고, \\(\\rho_{t}\\)는 엔트리-와이즈 상태 저장 구배 레귤라이저(예를 들어, Adam)이다. \\(\\rho_{t}\\)의 상태는 메모리 집약적일 수 있다. 예를 들어 Adam의 경우 기울기 \\(G_{t}\\)를 \\(\\tilde{G}_{t}\\)로 정규화하기 위해 \\(M,V\\in\\mathbb{R}^{m\\times n}\\)가 필요하다:\n' +
      '\n' +
      '\\[M_{t} =\\beta_{1}M_{t-1}+(1-\\beta_{1})G_{t} \\tag{2}\\] \\[V_{t} =\\beta_{2}V_{t-1}+(1-\\beta_{2})G_{t}^{2}\\] (3) \\[\\tilde{G}_{t} =M_{t}/\\sqrt{V_{t}+\\epsilon} \\tag{4}\\]\n' +
      '\n' +
      '여기서 \\(G_{t}^{2}\\)와 \\(M_{t}/\\sqrt{V_{t}+\\epsilon}\\)는 원소별 곱셈과 나눗셈을 의미한다. \\ (\\eta\\)는 학습률이다. \\(W\\in\\mathbb{R}^{m\\times n}\\)와 함께, 이것은 \\(3mn\\) 메모리를 필요로 한다.\n' +
      '\n' +
      'Low-rank update.Linear layer \\(W\\in\\mathbb{R}^{m\\times n}\\)에 LoRA와 그 변형들은 Low-rank adaptor \\(AB\\)를 도입함으로써 갱신 행렬의 Low-rank 구조를 이용한다:\n' +
      '\n' +
      '\\[W_{T}=W_{0}+B_{T}A_{T}, \\tag{5}\\]\n' +
      '\n' +
      '여기서 \\(B\\in\\mathbb{R}^{m\\times r}\\) 및 \\(A\\in\\mathbb{R}^{r\\times n}\\) 및 \\(r\\ll\\min(m,n)\\). (A\\)와 \\(B\\)는 학습 가능한 저순위 적응기이고 \\(W_{0}\\)는 고정된 가중치 행렬(예: 미리 훈련된 가중치)이다.\n' +
      '\n' +
      '### 가중치 기울기의 낮은 순위 속성\n' +
      '\n' +
      '메모리 사용을 줄이기 위해 낮은 순위의 업데이트가 제안되지만 가중치 매트릭스를 낮은 순위로 매개변수화해야 하는지 여부는 여전히 미해결 문제로 남아 있다. 많은 상황에서, 이것은 사실이 아닐 수 있다. 예를 들어, 선형 회귀 \\(\\mathbf{y}=W\\mathbf{x}\\)에서 최적 \\(W^{*}\\)이 높은 순위인 경우, 어떤 최적화자가 사용되었는지에 관계없이 \\(W\\)에 낮은 순위 가정을 부과하는 것은 결코 최적 솔루션으로 이어지지 않는다.\n' +
      '\n' +
      '놀랍게도, 가중치 행렬들이 반드시 저-순위인 것은 아니지만, 그래디언트는 특정 그래디언트 형태들 및 연관된 네트워크 아키텍처들에 대한 트레이닝 동안 실제로 저-순위가 된다:\n' +
      '\n' +
      '**Lemma 3.1** (훈련 중 기울기가 낮은 순위가 됨): _일반성을 손실하지 않고 \\(m\\leq n\\)로 둡니다. 상기 그래디언트 업데이트:_\n' +
      '\n' +
      '\\[G_{t}=A-BW_{t}C,\\quad W_{t}=W_{t-1}+\\eta G_{t-1} \\tag{6}\\]\n' +
      '\n' +
      '_with constant \\(A\\) 및 PSD 행렬 \\(B\\) 및 \\(C\\)와 무작위로 초기화된 \\(W_{0}\\)는 높은 확률로 낮은 순위 기울기로 이어진다:_\n' +
      '\n' +
      '\\[\\text{stable-rank}(G_{t})\\leq 1+\\sum_{i=2}^{m}O\\left(\\frac{1-\\eta\\lambda_{i} \\nu_{1}}}{1-\\eta\\lambda_{1}\\nu_{1}}}\\right)^{2t} \\tag{7}\\\n' +
      '\n' +
      '여기서 \\(\\nu_{1}=\\lambda_{\\min}(C)\\)는 \\(C\\)의 고유값이 가장 작고 \\(\\lambda_{1}\\leq\\ldots\\leq\\lambda_{n}\\)는 \\(B\\)의 고유값이다. 또한 \\(\\lambda_{2}>\\lambda_{1}\\)와 \\(\\nu_{1}>0\\)이면, \\(G_{t}\\)는 지수함수적으로 순위-\\(1\\)로 수렴한다._\n' +
      '\n' +
      'Lemma 3.1에서 우리는 파라메트릭 형태(Eqn. 6)를 가정한다는 점에 유의하라. 의 범위인 것을 특징으로 하는 반도체 소자의 캐패시터 제조 방법. 이것은 제한적인 가정이 아니다. 그것은 목적 \\(\\varphi(W)=\\|\\mathbf{y}-W\\mathbf{x}\\|_{2}^{2}\\)을 갖는 단순 선형 네트워크에 대해 보유할 뿐만 아니라, "가역 네트워크"(Tian et al., 2020)로 알려진 보다 일반적인 비선형 네트워크에서도 보유하며, 딥 ReLU 네트워크를 포함한다:\n' +
      '\n' +
      '\\(\\ell_{2}\\)-목적적 \\(\\varphi:=\\frac{1}{2}\\|\\mathbf{y}-\\mathcal{N}(\\mathbf{x})\\|_{2}^{2}\\)의 가중치 행렬 \\(W_{1}\\)은 배치 크기 1에 대해 다음과 같은 형태의 기울기 \\(G_{l}\\)를 갖는다.\n' +
      '\n' +
      '\\[G_{l}=\\underbrace{J_{l}^{\\top}\\mathbf{y}\\mathbf{f}_{l-1}^{\\top}}_{\\mathcal{A}}- \\underbrace{J_{l}^{\\top}J_{l}}_{\\mathcal{B}}W_{l}\\underbrace{\\mathbf{f}_{l-1}\\mathbf{f} _{l-1}^{\\top}}_{\\mathcal{C}} \\tag{8}\\\n' +
      '\n' +
      '_where \\(J_{l}:=\\operatorname{Jacobian}(\\mathcal{N}_{L})\\ldots\\operatorname{Jacobian}( \\mathcal{N}_{l+1})\\) and \\(\\mathbf{f}_{l}:=\\mathcal{N}_{l}(\\mathcal{N}_{l-1}\\ldots\\mathcal{N}_{1}(\\mathbf{x}))\\)._ 작은 로짓이 있는 소프트맥스 대물렌즈의 경우에도 역전파된 기울기의 유사한 구조를 증명할 수 있으므로 정리 3.2도 적용할 수 있다.\n' +
      '\n' +
      '\\(K\\)-way logsoftmax loss \\(\\varphi(\\mathbf{y};\\mathbf{f}):=-\\log\\left(\\frac{\\exp(\\mathbf{y}^{\\top}\\mathbf{f})}{\\mathbf{1}^{ \\top}\\exp(\\mathbf{f})}\\right)\\), let \\(\\hat{\\mathbf{f}}=P_{\\mathbf{1}}^{\\perp}\\mathbf{f}\\)는 네트워크 출력의 영평균 버전 \\(\\mathbf{f}\\)이며, 여기서 \\(P_{\\mathbf{1}}^{\\perp}:=I-\\frac{1}{K}\\mathbf{1}\\mathbf{1}}^{\\top}\\)는 다음과 같습니다.\n' +
      '\n' +
      '\\[-\\mathrm{d}\\varphi=\\mathbf{y}^{\\top}\\mathrm{d}\\hat{\\mathbf{f}}-\\gamma\\hat{\\mathbf{f}}^{ \\top}\\mathrm{d}\\hat{\\mathbf{f}}/K+O(\\hat{\\mathbf{f}}^{2}/K\\mathrm{d}\\hat{\\mathbf{f}}} \\tag{9}\\]\n' +
      '\n' +
      '\\(\\mathbf{y},\\mathbf{f})\\approx 1\\) 및 \\(\\mathbf{y}\\)는 \\(\\mathbf{y}^{\\top}\\mathbf{1}=1\\)인 데이터 레이블이다._\n' +
      '\n' +
      '이 부제에 의해, 가역 네트워크 \\(\\mathbf{f}:=\\mathcal{N}(\\mathbf{x})=J_{l}(\\mathbf{x})W_{l}\\mathbf{f}_{l-1}(\\mathbf{x})\\)의 구배 \\(G_{l}\\)는 다음의 형태를 갖는 것이 명백하다:\n' +
      '\n' +
      '\\[G_{l}=\\underbrace{J_{l}P_{\\mathbf{1}}^{\\perp}\\mathbf{y}\\mathbf{f}_{l-1}}_{\\mathcal{A}}- \\underbrace{\\gamma J_{l}^{\\top}P_{\\mathbf{1}}^{\\perp}J_{l}}_{B}W_{l}\\underbrace{ \\mathbf{f}_{l-1}\\mathbf{f}_{l-1}^{\\top}/K}_{C} \\tag{10}\\]\n' +
      '\n' +
      '(G_{l}=A-BW_{l}C\\). 가역성에 대한 자세한 소개는 부록 A.2를 확인해 주세요.\n' +
      '\n' +
      '### Gradient Low-rank Projection (GaLore)\n' +
      '\n' +
      '기울기 \\(G\\)는 낮은 순위 구조를 가질 수 있기 때문에, 기울기 \\(G\\)의 작은 "코어"의 기울기 통계를 \\(G\\) 자체가 아닌 최적화 상태에서 유지할 수 있다면, 메모리 소비를 실질적으로 감소시킬 수 있다. 이것은 우리가 제안한 GaLore 전략으로 이어진다:\n' +
      '\n' +
      '**정의 3.4** (Gradient Low-rank Projection (**GaLore**)): Gradient Low-rank Projection (**GaLore**)는 다음 그래디언트 업데이트 규칙을 나타냅니다 (\\(\\eta\\는 학습 속도):\n' +
      '\n' +
      '\\[W_{T}=W_{0}+\\eta\\sum_{t=0}^{T-1}\\tilde{G}_{t},\\qquad\\tilde{G}_{t}=P_{t}\\rho_{ t}(P_{t}^{\\top}G_{t}Q_{t})Q_{t}^{\\top}, \\tag{11}\\]\n' +
      '\n' +
      '여기서, \\(P_{t}\\in\\mathbb{R}^{m\\times r}\\) 및 \\(Q_{t}\\in\\mathbb{R}^{n\\times r}\\)는 투영행렬이다.\n' +
      '\n' +
      'LoRA와 달리 GaLore는 추가 저순위 어댑터를 도입하는 대신 저순위 업데이트를 명시적으로 활용하므로 훈련 역학을 변경하지 않는다.\n' +
      '\n' +
      '다음에서, 우리는 GaLore가 유사한(그러나 더 일반적인) 형태의 그래디언트 업데이트 규칙(Eqn. 6) 하에서 수렴한다는 것을 보여준다. 이 형태는 Eqn에 대응한다. 8이지만 배치 크기가 더 큽니다.\n' +
      '\n' +
      '**정의 3.5** (\\(L\\)-연속성): 함수 \\(\\mathbf{h}(W)\\)는 임의의 \\(W_{1}\\) 및 \\(W_{2}\\)에 대해 (Lipschitz) \\(L\\)-연속성을 가지며, \\(\\|\\mathbf{h}(W_{1})-\\mathbf{h}(W_{2})\\|_{F}\\leq L\\|W_{1}-W_{2}\\|_{F}\\).\n' +
      '\n' +
      '**정리 3.6** (고정 투영이 있는 GaLore의 수렴): _그래디언트에 다음 형식(Eqn)이 있다고 가정합니다. 8 with batchsize \\(>1\\):_\n' +
      '\n' +
      '\\[G=\\sum_{i}A_{i}-\\sum_{i}B_{i}WC_{i} \\tag{12}\\]\n' +
      '\n' +
      '여기서, \\(B_{i}\\) 및 \\(C_{i}\\)는 PSD 행렬이고, \\(A_{i}\\), \\(B_{i}\\) 및 \\(C_{i}\\)는 \\(W\\) 및 \\(\\|W_{t}\\|\\leq D\\)에 대한 \\(L_{A}\\), \\(L_{B}\\) 및 \\(L_{C}\\) 연속성을 갖는다. (R_{t}:=P_{t}^{\\top}G_{t}Q_{t}\\), \\(\\hat{B}_{it}:=P_{t}^{\\top}B_{i}(W_{t})P_{t}\\), \\(\\hat{C}_{it}:=Q_{t}^{\\top}C_{i}(W_{t})Q_{t}\\), \\(\\kappa_{t}:=\\frac{1}{N}\\sum_{i}\\lambda_{\\min}(\\hat{B}_{it})\\lambda_{\\min}(\\hat{ C}_{it})\\). 상수 \\(P_{t}=P\\)와 \\(Q_{t}=Q\\)를 선택하면 \\(\\rho_{t}\\equiv 1\\)을 갖는 GaLore는 다음을 만족한다:_\n' +
      '\n' +
      '\\[\\|R_{t}\\|_{F}\\leq\\left[1-\\eta(\\kappa_{t-1}-L_{A}-L_{B}L_{C}D^{2})\\right]\\|R_{t -1}\\|_{F} \\tag{13}\\]\n' +
      '\n' +
      '그 결과, \\(\\min_{t}\\kappa_{t}>L_{A}+L_{B}L_{C}D^{2}\\), \\(R_{t}\\to 0\\)와 GaLore는 고정된 \\(P_{t}\\)와 \\(Q_{t}\\)에 수렴한다.\n' +
      '\n' +
      '**설정 \\(P\\) 및 \\(Q\\)**. 이 정리는 \\(P\\)와 \\(Q\\)가 더 빠른 수렴(큰 \\(\\kappa_{t}\\))을 위해 \\(\\hat{B}_{it}\\)과 \\(\\hat{C}_{it}\\)의 처음 몇 개의 가장 큰 고유벡터에 해당하는 부분공간으로 투영되어야 함을 말한다. Positive Semidefinite (PSD) 행렬 \\(B\\)과 \\(C\\)의 모든 고유값은 비음수이지만, 그 중 일부는 매우 작아서 수렴을 방해할 수 있다(즉, \\(G_{t}\\)가 \\(0\\)이 되는 데 오랜 시간이 걸린다). 투영 \\(P\\)과 \\(Q\\)을 사용하면 \\(P^{\\top}B_{it}P\\)와 \\(Q^{\\top}C_{it}Q\\)는 \\(B\\)와 \\(C\\)의 가장 큰 고유 부분 공간만을 포함하므로 \\(R_{t}\\)의 수렴성을 향상시킴과 동시에 메모리 사용량을 줄일 수 있다.\n' +
      '\n' +
      '\\(\\hat{B}_{it}\\)와 \\(\\hat{C}_{it}\\)의 고유 구조를 얻는 것은 까다롭지만(그들은 자코비안의 일부이지만), 한 가지 방법은 대신 특이값 분해(SVD)를 통해 \\(G_{t}\\)의 스펙트럼을 사용하는 것이다:\n' +
      '\n' +
      '\\[G_{t} =USV^{\\top}\\approx\\sum_{i=1}^{r}s_{i}u_{i}v_{i}^{\\top} \\tag{14}\\] \\[P_{t} =[u_{1},u_{2},...,u_{r}],\\quad Q_{t}=[v_{1},v_{2},...,v_{r}] \\tag{15}\\]\n' +
      '\n' +
      '**GaLore와 LoRA의 차이** GaLore와 LoRA 모두 이름에 "낮은 순위"가 있지만 매우 다른 훈련 궤적을 따릅니다. 예를 들어, \\(r=\\min(m,n)\\)가 \\(\\rho_{t}\\equiv 1\\)인 GaLore는 \\(\\tilde{G}_{t}=P_{t}P_{t}^{\\top}G_{t}Q_{t}Q_{t}^{\\top}=G_{t}\\)와 같이 원래 모델의 정확한 훈련 궤적을 따른다. 반면에, \\(BA\\)가 전체 순위(즉, \\(B\\in\\mathbb{R}^{m\\times m}\\)와 \\(A\\in\\mathbb{R}^{m\\times n}\\))에 도달하면, \\(B\\)와 \\(A\\)를 최적화하는 것은 원 모델과 매우 다른 훈련 궤적을 동시에 따른다.\n' +
      '\n' +
      '## 4 GaLore for Memory-Efficient Training\n' +
      '\n' +
      'LLM 사전 훈련과 같은 복잡한 최적화 문제의 경우, 단일 저순위 서브스페이스로 전체 그래디언트 궤적을 캡처하는 것이 어려울 수 있다. 한 가지 이유는 \\(B_{t}\\) 및 \\(C_{t}\\)(따라서 \\(G_{t}\\))의 주요 하위 공간이 시간이 지남에 따라 변경될 수 있기 때문이다. 사실, 우리가 같은 투영 \\(P\\)와 \\(Q\\)를 유지한다면, 학습된 가중치는 더 이상 풀-파라미터 훈련이 아닌 이러한 부분 공간을 따라 커질 것이다. 다행히도, 이를 위해, GaLore는 트레이닝 동안 서브스페이스를 스위칭할 수 있고 메모리 풋프린트를 증가시키지 않고 풀 랭크 가중치들을 학습할 수 있다.\n' +
      '\n' +
      '### 하위 계층 하위 공간 구성\n' +
      '\n' +
      '우리는 GaLore가 저순위 부분공간들을 가로질러 스위칭할 수 있게 한다:\n' +
      '\n' +
      '\\[W_{t}=W_{0}+\\Delta W_{T_{1}}+\\Delta W_{T_{2}}+\\ldots+\\Delta W_{T_{n}}, \\tag{16}\\]\n' +
      '\n' +
      '여기서 \\(t\\in\\left[\\sum_{i=1}^{n-1}T_{i},\\sum_{i=1}^{n}T_{i}\\right]\\)와 \\(\\Delta W_{T_{1}}=\\eta\\sum_{t=0}^{T_{i}-1}\\tilde{G_{t}}\\)는 \\(i\\)-번째 부분공간 내에서 모든 \\(T_{i}\\) 업데이트를 합한 것이다. 단계 \\(t=T_{i}\\)에서 \\(i\\)-번째 부분공간으로 전환할 때, 방정식 14에 의해 현재 기울기 \\(G_{t}\\)에 대해 SVD를 수행하여 프로젝터 \\(P_{t}\\) 및 \\(Q_{t}\\)를 다시 초기화한다. 그림 2에서 \\(\\tilde{G_{t}}\\)의 궤적이 여러 저순위 부분공간을 통과하는 방법을 설명한다. 실험 섹션에서는 여러 저순위 부분공간을 허용하는 것이 LLM의 성공적인 사전 학습을 달성하는 열쇠임을 보여준다.\n' +
      '\n' +
      '위의 절차에 따라 스위칭 주파수 \\(T\\)는 하이퍼파라미터가 된다. 절제 연구(도 5) 스위트 스팟이 있음을 나타냅니다. 정리의 3.6에서 상수투영 조건을 깨고 새로운 \\(P_{t}\\)와 \\(Q_{t}\\)를 계산해야 하기 때문에 매우 빈번한 부분공간 변화는 오버헤드를 증가시키고, 실제로 여러 훈련 단계에 걸쳐 누적되는 최적화 상태들의 충실도에 영향을 줄 수 있다. 반면에, 덜 빈번한 변경은 알고리즘이 더 이상 최적화하는 것이 중요하지 않은 영역에 고착되게 할 수 있다(정리 3.6의 수렴 증명은 지정된 부분 공간에서의 양호한 진행을 의미할 뿐, 양호한 전체 성능을 의미하지는 않는다). 최적의 \\(T\\)는 전체 훈련 반복과 작업 복잡도에 의존하지만, \\(T=50\\)에서 \\(T=1000\\) 사이의 값은 큰 차이가 없음을 발견했다. 따라서, SVD에 의해 유도된 총 계산 오버헤드는 메모리 오프로딩(Rajbhandari et al., 2020)과 같은 다른 메모리-효율 트레이닝 기술에 비해 무시할 수 있다(\\(<10\\%\\)).\n' +
      '\n' +
      '### Memory-Efficient Optimization\n' +
      '\n' +
      '**그라데이션 통계의 메모리 공간을 줄입니다.* * GaLore는 Adam(Kingma & Ba, 2014)과 같이 구성 요소별 기울기 통계에 크게 의존하는 최적화기의 메모리 비용을 상당히 감소시킨다. \\(\\rho_{t}\\equiv\\mathrm{Adam}\\)일 때, \\(G_{t}\\)를 저순위 형태로 투영하여 \\(R_{t}\\), Adam의 기울기 정규화기 \\(\\rho_{t}(R_{t})\\)는 저순위 기울기 통계만을 추적하면 된다. 여기서 \\(M_{t}\\) 및 \\(V_{t}\\)는 각각 1차 운동량 및 2차 운동량이다. GaLore는 다음과 같이 저순위 정규화된 구배 \\(N_{t}\\)를 계산한다:\n' +
      '\n' +
      '\\[N_{t}=\\rho_{t}(R_{t})=M_{t}/(\\sqrt{V_{t}}+\\epsilon). \\tag{17}\\]\n' +
      '\n' +
      'GaLore는 또한 유사한 업데이트 규칙을 갖고 그래디언트 통계를 저장하기 위해 많은 양의 메모리를 필요로 하는 다른 최적화기(예를 들어, Adafactor)에 적용할 수 있다.\n' +
      '\n' +
      '**투영 행렬의 메모리 사용량을 줄입니다.* * 최상의 메모리 성능 절충을 달성하려면 하나의 프로젝트 행렬 \\(P\\) 또는 \\(Q\\)만 사용하여 경사도 \\(G\\)를 \\(m\\leq n\\) 및 \\(GQ\\)로 투영합니다. 우리는 알고리즘 2에서 GaLore를 Adam에 적용한 알고리즘을 제시한다.\n' +
      '\n' +
      '```\n' +
      '입력: 층 가중치 행렬 \\(W\\in\\mathbb{R}^{m\\times n}\\) \\(m\\leq n\\) Step size \\(\\eta\\), scale factor \\(\\alpha\\), decay rate \\(\\beta_{1},\\beta_{2}\\), rank \\(r\\), subspace change frequency \\(T\\). 1차 모멘트 초기화 \\(M_{0}\\in\\mathbb{R}^{n\\times r}\\gets 0\\) {t\\bmod T=0\\)then \\(U,S,V\\leftarrow\\text{SVD}(G_{t})\\) \\(P_{t}\\gets U[\\cdot,\\cdot r]\\) if\\(t\\bmod T=0)then \\(U,S,V\\leftarrow\\text{SVD}(G_{t})\\) \\(P_{t}\\gets U[\\cdot,\\cdot r]\\) if\\(m\\leq n\\)then \\(U,S,V\\leftarrow\\text{SVD}(G_{t})\\) \\(V_{0}\\in\\mathbb{R}^{m\\times n}\\leftarrow-\\nabla_{W}\\varphi_{t}(W_{t})\\) if\\(m\\leq n\\) else \\(P_{t}\\gets P_{t-1}\\) {\n' +
      '```\n' +
      '\n' +
      '**알고리즘 2**GaLore를 사용한 애덤\n' +
      '\n' +
      '이러한 설정으로, GaLore는 트레이닝 동안 LoRA보다 적은 메모리를 필요로 한다. GaLore는 가중치 업데이트 동안 \\(\\Delta W_{t}\\)에서 \\(W_{0}\\)로 항상 병합할 수 있으므로 별도의 저순위 인수분해 \\(BA\\)를 저장할 필요가 없다. Total, GaLore requires \\((mn+mr+2nr)\\) memory, while LoRA requires\n' +
      '\n' +
      '그림 2: GaLore를 사용하여 하위 하위 공간 \\(\\Delta W_{T_{1}}\\) 및 \\(\\Delta W_{T_{2}}\\)을 통해 학습한다. \\(t_{1}\\in[0,T_{1}-1]\\)의 경우, \\(W\\)는 고정된 \\(P_{t_{1}}\\) 및 \\(Q_{t_{1}}\\)에 의해 결정된 부분공간에서 투영된 기울기 \\(\\tilde{G}_{t_{1}}}\\)에 의해 업데이트된다. \\(T_{1}\\) 단계 후, \\(t_{2}\\in[T_{1},T_{2}-1]\\)에 대한 \\(P_{t_{2}}\\)과 \\(Q_{t_{2}}\\)를 재계산하여 부분공간을 변화시키고 수렴할 때까지 과정을 반복한다.\n' +
      '\n' +
      '\\((mn+3mr+3nr)\\) 메모리. GaLore와 LoRA의 비교는 표 1에 나와 있다.\n' +
      '\n' +
      '정리 3.6은 투영 행렬을 신중하게 보정할 필요가 없기 때문에, 우리는 양자화 및 효율적인 매개변수화를 통해 투영 행렬의 메모리 비용을 추가로 줄일 수 있으며, 이는 향후 작업을 위해 남겨둔다.\n' +
      '\n' +
      '기존 기술과의 결합\n' +
      '\n' +
      'GaLore는 기존의 메모리 효율적인 최적화 기술과 호환된다. 본 연구에서는 GaLore를 8비트 최적화기(Dettmers et al., 2021)와 계층별 가중치 업데이트(Lv et al., 2023)로 적용하는 것을 주로 고려한다.\n' +
      '\n' +
      '8-비트 최적화기.Dettmers 등(2022)은 32-비트 최적화기 성능을 원래의 메모리 풋프린트의 일부에서 유지하는 8-비트 Adam 최적화기를 제안하였다. 우리는 GaLore를 8비트 Adam의 기존 구현에 직접 적용한다.\n' +
      '\n' +
      '계층별 가중치 업데이트.실제로, 최적화기는 전형적으로 역전파 후에 모든 계층에 대해 단일 가중치 업데이트를 수행한다. 이는 전체 가중치 구배를 메모리에 저장함으로써 이루어진다. 트레이닝 동안 메모리 풋프린트를 더 감소시키기 위해, 우리는 역전파 동안 가중치 업데이트를 수행하는 GaLore에 레이어별 가중치 업데이트를 채택한다(Lv 등, 2023).\n' +
      '\n' +
      '### GaLore의 Hyperparameters\n' +
      '\n' +
      'GaLore는 Adam의 원래 하이퍼파라미터 외에도 LoRA에도 존재하는 rank \\(r\\), subspace change frequency \\(T\\)( Sec. 4.1 참조) 및 scale factor \\(\\alpha\\)와 같은 추가 하이퍼파라미터를 거의 도입하지 않는다.\n' +
      '\n' +
      '스케일 팩터 \\(\\alpha\\)는 저순위 업데이트의 강도를 제어하는데, 이는 Hu et al.(2021)의 저순위 어댑터에 추가된 스케일 팩터 \\(\\alpha/r\\)와 유사하다. 우리는 \\(\\alpha\\)가 우리의 경우 순위 \\(r\\)에 의존하지 않는다는 점에 주목한다. 이는 사전 훈련 시 \\(r\\)이 작을 경우 미세 조정과 달리 \\(\\alpha/r\\)이 수렴 속도에 큰 영향을 미치기 때문이다.\n' +
      '\n' +
      '## 5 Experiments\n' +
      '\n' +
      '우리는 LLM의 사전 훈련과 미세 조정 모두에 대해 GaLore를 평가한다. 모든 실험은 NVIDIA A100 GPU2에서 수행된다.\n' +
      '\n' +
      '각주 2: GaLore의 구현은 여기에서 이용 가능하다\n' +
      '\n' +
      'C4에 대한 사전 훈련. 성능을 평가하기 위해 GaLore를 적용하여 C4 데이터 세트에서 LLaMA 기반 대용량 언어 모델을 훈련한다. C4 데이터세트는 Common Crawl의 웹 크롤 코퍼스의 거대하고 세정된 버전이며, 이는 주로 사전 훈련 언어 모델 및 단어 표현을 목적으로 한다(Raffel et al., 2023). 실제 사전 훈련 시나리오를 가장 잘 시뮬레이션하기 위해 최대 70억 개의 모델 크기 범위에 걸쳐 충분히 많은 양의 데이터에 대해 데이터 반복 없이 훈련한다.\n' +
      '\n' +
      'Architecture and hyperparameters.We follow the experiment setup from Lialin et al. (2023), which adopts a LLaMA-based3 architecture with RMSNorm and SwiGLU activations (Touvron et al., 2023; Zhang and Sennrich, 2019; Shazeer, 2020). 각 모델 크기에 대해 학습률을 제외하고 방법에 따라 동일한 하이퍼파라미터 세트를 사용한다. 메모리 사용량을 줄이기 위해 BF16 형식으로 모든 실험을 수행하였고, 동일한 계산량의 예산 하에서 각 방법에 대한 학습률을 튜닝하고 가장 좋은 성능을 보고한다. 작업 설정 및 하이퍼파라미터의 세부 정보는 부록에 나와 있습니다.\n' +
      '\n' +
      '각주 3: 우리 논문의 LLaMA 자료는 LLaMA 커뮤니티 라이선스를 적용받는다.\n' +
      '\n' +
      'GLUE 태스크들에 대한 파인-튜닝.GLUE는 감성 분석, 질의 응답, 및 텍스트 수반을 포함하는 다양한 태스크들에 대한 NLP 모델들의 성능을 평가하기 위한 벤치마크이다(Wang et al., 2019). GLUE 태스크를 사용하여 메모리 효율적인 미세 조정을 위해 LoRA에 대해 GaLore를 벤치마킹한다.\n' +
      '\n' +
      '### 낮은 순위 메서드와의 비교\n' +
      '\n' +
      '우리는 먼저 다양한 모델 크기에 걸쳐 Adam Optimizer를 사용하여 GaLore를 기존의 저순위 방법과 비교한다.\n' +
      '\n' +
      '전체 순위 가중치 및 최적화 상태를 가진 Adam 최적화기를 적용하는 전체 순위 기준선 방법.\n' +
      '\n' +
      '또한 학습 가능한 저순위 인수분해에 의해 가중치를 나타내는 전통적인 저순위 접근법을 평가한다. \\(W=BA\\)(Kamalakara et al., 2022).\n' +
      '\n' +
      'LoRAHu et al. (2021)은 Low-rank 어댑터를 사용하여 미리 학습된 모델을 미세 조정하기 위해 LoRA를 제안했다: \\(W=W_{0}+BA\\) 여기서 \\(W_{0}\\)는 고정된 초기 가중치이고 \\(BA\\)는 학습 가능한 Low-rank 어댑터이다. 사전 훈련의 경우 \\(W_{0}\\)는\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c} \\hline \\hline  & GaLore & LoRA \\\\ \\hline Weights & \\(mn\\) & \\(mn+mr+nr\\) \\\\ Optim States & \\(mr+2nr\\) & \\(2mr+2nr\\) \\\\ \\hline Multi-Subspace & ✓ & ✗ \\\\ Pre-Training & ✓ & ✗ \\\\ Fine-Tuning & ✓ & ✓ \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: GaLore와 LoRA의 비교. \\(W\\in\\mathbb{R}^{m\\times n}\\) (\\(m\\leq n\\)), rank \\(r\\)를 가정한다.\n' +
      '\n' +
      '전체 순위 초기화 행렬입니다. 우리는 LoRA 알파를 32로 설정하고 LoRA 드롭아웃을 기본 설정으로 0.05로 설정했다.\n' +
      '\n' +
      'ReLoRALialin et al. (2023)은 Pre-training을 위해 설계된 LoRA의 변형으로, \\(BA\\)를 \\(W\\)로 주기적으로 병합하고, 최적화 상태 및 학습률을 재설정하여 새로운 \\(BA\\)를 초기화한다. ReLoRA는 병합 빈도, 학습률 재설정 및 최적화 상태 재설정을 신중하게 조정해야 한다. 우리는 공정한 비교를 위해 풀 랭크 훈련 준비 운동 없이 ReLoRA를 평가한다.\n' +
      '\n' +
      'GaLore의 경우 표 2의 모든 모델 크기에 걸쳐 부분 공간 빈도 \\(T\\)를 200으로 설정하고 스케일 팩터 \\(\\alpha\\)를 0.25로 설정한다. 각 모델 크기에 대해 모든 저순위 방법에 대해 동일한 순위 \\(r\\)를 선택하여 모델의 모든 멀티헤드 어텐션 레이어와 피드포워드 레이어에 적용한다. 기본 하이퍼파라미터(예: \\(\\beta_{1}=0.9\\), \\(\\beta_{2}=0.999\\), \\(\\epsilon=10^{-8}\\))를 사용하여 Adam Optimizer를 사용하여 모든 모델을 학습한다. 또한 가중치 파라미터와 최적화 상태에 대한 메모리를 포함하여 BF16 포맷을 기반으로 메모리 사용량을 추정한다. 표 2에 나타난 바와 같이, GaLore는 다른 저순위 방법을 능가하며 전체 순위 훈련에 필적할 만한 성능을 달성한다. 우리는 1B 모델 크기에 대해 GaLore가 \\(r=512\\) 대신 \\(r=1024\\)일 때 전체 순위 기준선보다 우수하다는 점에 주목한다. LoRA 및 ReLoRA에 비해 GaLore는 모델 파라미터 및 최적화기 상태를 저장하기 위한 메모리가 적게 필요하다. 각 모델의 자세한 학습 설정과 각 방법에 대한 메모리 추정은 부록에 나와 있다.\n' +
      '\n' +
      '### Memory-Efficient Optimizers를 사용한 GaLore\n' +
      '\n' +
      '우리는 GaLore가 다양한 학습 알고리즘, 특히 메모리 효율적인 최적화기에 적용되어 메모리 풋프린트를 더욱 줄일 수 있음을 보여준다. GaLore를 AdamW, 8비트 Adam, Adafactor optimizers(Loshchilov and Hutter, 2019; Dettmers et al., 2022; Shazeer and Stern)에 적용한다. 성능 저하를 방지하기 위해 1차 통계가 있는 Adafactor를 고려한다.\n' +
      '\n' +
      '이를 10K 훈련 단계로 LLaMA 1B 아키텍처에서 평가하고, 각 설정에 대한 학습률을 튜닝하여 최상의 성능을 보고한다. 를 더 포함할 수 있다. 도 3을 참조하면, GaLore를 적용하는 것은 이들의 수렴에 큰 영향을 미치지 않는다. 512의 순위를 갖는 GaLore를 사용함으로써, 메모리 풋프린트는 8-비트 Adam 또는 Adafactor optimizer를 사용함으로써 메모리 절감에 더하여 최대 62.5% 감소된다. 8비트 아담은 다른 것보다 적은 메모리를 요구하기 때문에 8비트 아담과 함께 8비트 GaLore를 GaLore로 나타내며, 7B 모델 사전 훈련 및 메모리 측정에 대한 다음 실험을 위한 기본 방법으로 사용한다.\n' +
      '\n' +
      '### LLaMA 7B 아키텍처까지 확장\n' +
      '\n' +
      'GaLore가 실제 LLM 사전 훈련 시나리오에 효과적인지 입증하기 위한 핵심 요소는 7B 모델에 대한 확장 능력이다. LLaMA 7B 아키텍쳐에서 4096의 임베딩 크기와 32개의 총 계층으로 GaLore를 평가한다. 우리는 총 64개의 A100 GPU와 병렬로 8-노드 학습을 사용하여 19.7B 토큰으로 150K 단계에 대한 모델을 학습한다. 계산적 제약으로 인해 하이퍼파라미터를 조정하지 않고 8-비트 GaLore (\\(r=1024\\))와 8-비트 Adam을 단일 시도로만 비교한다. 표 3에 도시된 바와 같이, 150K 단계 후에, 8-비트 GaLore는 14.65의 당혹도를 달성하는데, 이는 14.61의 당혹도를 갖는 8-비트 Adam에 필적한다.\n' +
      '\n' +
      '### Memory-Efficient Fine-Tuning\n' +
      '\n' +
      'GaLore는 메모리 효율적인 사전 학습을 달성할 뿐만 아니라 메모리 효율적인 미세 조정에 사용될 수 있다. We are\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l r r r r} \\hline \\hline  & **60M** & **130M** & **350M** & **1B** \\\\ \\hline Full-Rank & 34.06 (0.36G) & 25.08 (0.76G) & 18.80 (2.06G) & 15.56 (7.80G) \\\\ \\hline\n' +
      '**GaLore** & **34.88** (0.24G) & **25.36** (0.52G) & **18.95** (1.22G) & **15.64** (4.38G) \\\\ Low-Rank & 78.18 (0.26G) & 45.51 (0.54G) & 37.41 (1.08G) & 142.53 (3.57G) \\\\ LoRA & 34.99 (0.36G) & 33.92 (0.80G) & 25.58 (1.76G) & 19.21 (6.17G) \\\\ ReLoRA & 37.04 (0.36G) & 29.37 (0.80G) & 29.08 (1.76G) & 18.33 (6.17G) \\\\ \\hline \\(r/d_{model}\\) & 128 / 256 & 256 / 768 & 256 / 1024 & 512 / 2048 \\\\ Training Tokens & 1.1B & 2.2B & 6.4B & 13.1B \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: C4 데이터 세트에서 다양한 크기의 LLaMA 모델을 사전 훈련하는 저순위 알고리즘과의 비교. 유효성 검증 복잡성은 BF16 형식을 기반으로 하는 총 매개변수 및 최적화 상태 메모리 추정치와 함께 보고된다. GaLore의 실제 메모리 발자국은 그림 1에 보고되어 있다. 도 1 및 도 4를 참조하여 설명한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|r|r r r r} \\hline \\hline  & **Mem** & **40K** & **80K** & **120K** & **150K** \\\\ \\hline\n' +
      '**8비트 GaLore** & 18G & 17.94 & 15.39 & 14.95 & 14.65 \\\\\n' +
      '8-bit Adam & 26G & 18.09 & 15.47 & 14.83 & 14.61 \\\\ \\hline Tokens (B) & & 5.2 & 10.5 & 15.7 & 19.7 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: 150K 단계에 대한 C4 데이터 세트 상의 LLaMA 7B를 사전 트레이닝한다. 검증 복잡도 및 메모리 추정치가 보고된다.\n' +
      '\n' +
      'GaLore를 사용하여 GLUE 태스크에서 미리 훈련된 RoBERTa 모델을 미세 조정하고 전체 미세 조정 기준선 및 LoRA와 성능을 비교한다. LoRA는 Hu et al.(2021)의 하이퍼파라미터를 사용하고 GaLore는 학습률과 스케일 팩터를 조정한다. 표 4에 도시된 바와 같이, GaLore는 메모리 풋프린트가 적은 대부분의 태스크에서 LoRA보다 더 나은 성능을 달성한다. 이는 GaLore가 LLM 사전 훈련과 미세 조정 모두에 대해 풀 스택 메모리 효율적인 훈련 전략으로 작용할 수 있음을 보여준다.\n' +
      '\n' +
      '### 메모리 및 처리량 측정\n' +
      '\n' +
      '표 2는 메모리 사용 측면에서 다른 방법에 비해 GaLore의 이론적 이점을 제공하지만, 토큰 배치 크기가 256인 다양한 방법으로 LLaMA 모델을 훈련하는 실제 메모리 풋프린트를 측정한다. 훈련은 활성화 체크포인팅, 메모리 오프로딩 및 최적화기 상태 분할 없이 단일 장치 설정에서 수행된다(Rajbhandari et al., 2020).\n' +
      '\n' +
      '**24G 메모리가 있는 소비자 GPU에서 7B 모델을 교육합니다.* * 그림과 같이. 도 4에 도시된 바와 같이, 8-비트 GaLore는 BF16 베이스라인 및 8-비트 Adam보다 상당히 적은 메모리를 필요로 하며, GPU 당 작은 토큰 배치 크기(최대 500 토큰)를 갖는 LLaMA 7B를 사전-트레이닝하기 위해 22.0G 메모리만 필요로 한다. 이 메모리 공간은 NVIDIA RTX 4090과 같은 단일 GPU의 24GB VRAM 용량 내에 있습니다. 또한 활성화 체크포인팅을 사용할 경우 GPU당 토큰 배치 크기를 최대 4096까지 늘릴 수 있습니다. 배치 크기가 GPU당 작지만 모델 병렬성에 비해 GPU 간 통신을 위해 훨씬 낮은 대역폭을 요구하는 데이터 병렬성으로 확장할 수 있습니다. 따라서, GaLore가 RTX 4090s와 같은 소비자 GPU 상에서 탄성 트레이닝(Lin 등) 7B 모델들에 사용될 수 있는 것이 가능하다.\n' +
      '\n' +
      '특히, 우리는 그림 1에 메모리 분해를 제시한다. 8비트 GaLore는 BF16 아담 기준선과 8비트 아담에 비해 각각 37.92G(63.3%)와 24.5G(52.3%)의 총 메모리를 감소시킨다는 것을 보여준다. 8-비트 Adam과 비교하여, 8-비트 GaLore는 주로 두 부분으로 메모리를 감소시킨다: (1) 낮은 순위 그래디언트 투영은 최적화기 상태를 저장하는 9.6G(65.5%) 메모리를 감소시키고, (2) 계층별 가중치 업데이트를 사용하는 것은 가중치 그래디언트를 저장하는 13.5G 메모리를 감소시킨다.\n' +
      '\n' +
      '**GaLore의 처리량 오버헤드** 또한 8비트 GaLore 및 기타 방법을 사용 하 여 사전 훈련 LLaMA 1B 모델의 처리량을 측정 합니다. 여기서 결과는 부록에서 찾을 수 있습니다. 특히, 8-비트 GaLore의 현재 구현은 1019.63 토큰/초를 달성하여 8-비트 Adam 구현에 비해 17%의 오버헤드를 유도한다. GaLore에 대해 계층별 가중치 업데이트를 비활성화하면 1109.38 토큰/초가 달성되어 처리량이 8.8% 향상된다. 우리는 우리의 결과가 훈련 처리량에 상당한 영향을 미칠 수 있는 오프로딩 전략이나 체크포인팅을 필요로 하지 않는다는 점에 주목한다. 우리는 향후 작업을 위해 GaLore 구현의 효율성을 최적화하도록 둔다.\n' +
      '\n' +
      '## 6 Ablation Study\n' +
      '\n' +
      '### 사전 훈련 중에 몇 개의 하위 공간이 필요합니까?\n' +
      '\n' +
      '우리는 그림 1과 같이 부분 공간의 너무 빈번한 변화와 너무 느린 변화가 수렴에 영향을 미친다는 것을 관찰한다. 5(좌측).\n' +
      '\n' +
      '그림 4: 256의 토큰 배치 크기로 평가된 다양한 모델 크기에서 다양한 방법에 대한 메모리 사용량. 8비트 GaLore(유지 기울기)는 계층별 가중치 업데이트를 비활성화하지만 훈련 중에 가중치 기울기를 저장한다.\n' +
      '\n' +
      '그림 3: 10K 단계에 대한 C4 데이터 세트 상의 LLaMA 1B를 사전 트레이닝하기 위해 GaLore를 상이한 최적화기에 적용하는 단계. 훈련 단계에 대한 검증 복잡성이 보고됩니다. 우리는 1B 모델 차원이 2048인 512 및 1024의 순위를 가진 각 최적화기에 GaLore를 적용한다.\n' +
      '\n' +
      '그 이유는 Sec. 4.1에서 논의되었으며 작은 \\(r\\)에 대해 더 널리 퍼져 있는데, 이러한 경우 잘못된 부분공간에서 최적화 단계가 낭비되는 것을 피하기 위해 적절한 시간에 부분공간 전환이 일어나야 하는 반면 큰 \\(r\\)의 경우 기울기 업데이트가 더 많은 부분공간을 커버하여 더 많은 쿠션을 제공하기 때문이다.\n' +
      '\n' +
      '### 하위 공간의 순위가 수렴에 어떻게 영향을 주나요?\n' +
      '\n' +
      '일정 범위의 순위 값 내에서, 순위의 감소는 수렴 속도에 약간만 영향을 주어 선형에 가까운 둔화를 야기한다. 를 더 포함할 수 있다. 도 5(오른쪽)를 참조하면, 80K 단계를 사용하여 128의 순위를 갖는 트레이닝은 20K 단계를 사용하여 512의 순위를 갖는 트레이닝보다 낮은 손실을 달성한다. 이것은 GaLore가 메모리와 계산 비용 사이의 트레이드오프에 사용될 수 있음을 보여준다. 메모리 제약 시나리오에서 랭크를 줄이면 성능을 보존하기 위한 더 많은 단계를 훈련하는 동안 메모리 예산 내에서 머물 수 있다.\n' +
      '\n' +
      '## 7 Conclusion\n' +
      '\n' +
      '본 논문에서는 대용량 언어 모델을 위한 메모리 효율적인 사전 학습 및 미세 조정 전략인 GaLore를 제안한다. GaLore는 대규모 LLM 사전 훈련과 미세 조정을 위해 효율성과 성능을 모두 유지하면서 최적화 상태에서 메모리 사용량을 최대 65.5%까지 대폭 줄인다.\n' +
      '\n' +
      '본 논문에서는 GaLore에 대한 몇 가지 문제점을 발견하는데, (1) 비전 트랜스포머 및 확산 모델과 같은 다른 유형의 모델의 훈련에 GaLore를 적용하는 것, (2) 양자화 또는 특수 파라미터화를 통해 저메모리 투영 행렬을 채택함으로써 메모리 효율을 더욱 향상시키는 것, (3) 저대역 소비자 등급 하드웨어에서 탄성 데이터 분산 훈련의 가능성을 탐색하는 것을 포함한다.\n' +
      '\n' +
      '우리는 우리의 연구가 저순위 기울기 투영의 관점에서 기억 효율적인 LLM 훈련 전략에 대한 향후 연구에 영감을 줄 수 있기를 바란다. 우리는 GaLore가 소비자 등급의 하드웨어와 제한된 리소스로 커뮤니티가 대규모 언어 모델을 훈련하는 데 귀중한 도구가 될 것이라고 믿습니다.\n' +
      '\n' +
      '## 8 영향 문\n' +
      '\n' +
      '본 논문은 LLM 사전학습과 미세조정이 환경에 미치는 영향을 줄이기 위해 대용량 언어모델 학습(LLM)의 메모리 효율을 향상시키는 것을 목적으로 한다. 더 낮은 메모리를 가진 하드웨어에서 더 큰 모델의 트레이닝을 가능하게 함으로써, 우리의 접근법은 트레이닝 LLM과 연관된 에너지 소비 및 탄소 발자국을 최소화하는 데 도움이 된다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Anil et al. (2020) Anil, R., Gupta, V., Koren, T., and Singer, Y. 메모리 효율적인 적응 최적화\n' +
      '* Chaudhry et al. (2020) Chaudhry, A., Khan, N., Dokania, P., and Torr, P. Continual Learning in Low-rank Orthogonal Subspaces. In _Advances in Neural Information Processing Systems_, volume 33, pp. 9900-9911. Curran Associates, Inc., 2020.\n' +
      '* Chen et al. (2019) Chen, H., Raskutti, G., and Yuan, M. 일반화된 저순위 텐서 회귀에 대한 비볼록 투영 경사 하강 _ Journal of Machine Learning Research_, 20(5):1-37, 2019. ISSN 1533-7928.\n' +
      '* Chen et al.(2016) Chen, T., Xu, B., Zhang, C., and Guestrin, C. Training Deep Nets with Sublinear Memory Cost, April 2016.\n' +
      '* Chen & Wainwright (2018) Chen, Y. and Wainwright, M. J. Fast low-rank estimation\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l|c|c c c c c c c|c} \\hline \\hline  & **Memory** & **CoLA** & **STS-B** & **MRPC** & **RTE** & **SST2** & **MNLI** & **QNLI** & **QQP** & **Avg** \\\\ \\hline Full Fine-Tuning & 747M & 62.24 & 90.92 & 91.30 & 79.42 & 94.57 & 87.18 & 92.33 & 92.28 & 86.28 \\\\ \\hline\n' +
      '**GaLore (rank=4)** & 253M & 60.35 & **90.73** & **92.25** & **79.42** & **94.04** & **87.00** & **92.24** & 91.06 & **85.89** \\\\ LoRA (rank=4) & 257M & **61.38** & 90.57 & 91.07 & 78.70 & 92.89 & 86.82 & 92.18 & **91.29** & 85.61 \\\\ \\hline\n' +
      '**GaLore (rank=8)** & 257M & 60.06 & **90.82** & **92.01** & **79.78** & **94.38** & **87.17** & 92.20 & 91.11 & **85.94** \\\\ LoRA (rank=8) & 264M & **61.83** & 90.80 & 91.90 & 79.06 & 93.46 & 86.94 & **92.25** & **91.22** & 85.93 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: 사전 트레이닝된 RoBERTa-Base를 사용하여 GLUE 벤치마크 상에서 메모리 효율적인 미세 조정을 위해 GaLore를 평가하는 단계. 우리는 모든 과제의 평균 점수를 보고한다.\n' +
      '\n' +
      '그림 5: 130M 모델에 대한 GaLore의 절제 연구. **왼쪽:** 다양한 하위 공간 업데이트 빈도 \\(T \\). **오른쪽:** 다양한 하위 공간 순위 및 훈련 반복입니다.\n' +
      '\n' +
      'by projected gradient descent: General statistical and algorithmic guarantee, September 2015.\n' +
      '* Chowdhery et al.(2022) Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Sutton, C., Gehrmann, S., Schuh, P., Shi, K., Tsyashchenko, S., Maynez, J., Rao, A., Barnes, P., Tay, Y., Shazeer, N., Levskaya, A., Ghemawat, S., Reif, E., Du, N., Hutchinson, B., Pope, R., Bradbury, J., Austin, J., Isard, M., Gur-Ari, A., Ghemawat, S., Dev, S., Michalewski, H., Garcia, X., Misra, V., Robinson, K., Burcia, D., Ippolito, D., Luan, D., Lim, H., Zoph, B., Spiridonov, A., Sepassi, R., Dohan, D., Agrawal, S., O PaLM: 경로 확장 언어 모델링, 2022년 10월.\n' +
      '* Dettmers 등(2021) Dettmers, T., Lewis, M., Shleifer, S., and Zettlemoyer, L. 블록 단위 양자화를 통한 8비트 최적화기 _ arXiv:2110.02861 [cs]_, October 2021.\n' +
      '* Dettmers 등(2022) Dettmers, T., Lewis, M., Shleifer, S., and Zettlemoyer, L. 2022년 6월 Block-wise Quantization을 통한 8비트 Optimizers\n' +
      '* Dettmers et al. (2023) Dettmers, T., Pagnoni, A., Holtzman, A., and Zettlemoyer, L. QLoRA: Quantized LLMs의 효율적인 Finetuning, 5월 2023.\n' +
      '* Ding et al.(2022) Ding, N., Qin, Y., Yang, G., Wei, F., Yang, Z., Su, Y., Hu, S., Chen, Y., Chan, C.-M., Chen, W., Yi, J., Zhao, W., Wang, X., Liu, Z., Zheng, H.-T., Chen, J., Liu, Y., Tang, J., Li, J., and Sun, M. 델타 튜닝: 사전 훈련된 언어 모델에 대한 모수 효율적인 방법에 대한 포괄적인 연구, 2022년 3월.\n' +
      '* Gur-Ari et al. (2018) Gur-Ari, G., Roberts, D. A., and Dyer, E. Gradient Descent Happens in a Tiny Subspace, December 2018.\n' +
      '* Hu et al. (2021) Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., and Chen, W. LoRA: 대형 언어 모델의 저순위 적응, 2021년 10월.\n' +
      '* Kamalakara et al. (2022) Kamalakara, S. R., Locatelli, A., Venkitesh, B., Ba, J., Gal, Y., and Gomez, A. N. Exploring Low Rank Training of Deep Neural Networks, September 2022.\n' +
      '* Kingma & Ba (2014) Kingma, D. P. and Ba, J. Adam: A Method for Stochastic Optimization. _ arXiv:1412.6980 [cs]_, December 2014.\n' +
      '* Larsen et al. (2022) Larsen, B. W., Fort, S., Becker, N., and Ganguli, S. 얼마나 많은 자유가 깊은 네트워크를 훈련시킬 필요가 있는가: 2022년 2월, 손실 풍경 관점.\n' +
      '* Lee & Choi (2018) Lee, Y. 및 최성 Learned Layerwise Metric and Subspace를 이용한 Gradient-Based Meta-Learning, 2018년 6월.\n' +
      '* Li et al.(2023) Li, B., Chen, J., and Zhu, J. Memory Efficient Optimizers with 4-bit States. [https://arxiv.org/abs/2309.01507v3] (https://arxiv.org/abs/2309.01507v3), 2023년 9월.\n' +
      '* Lialin 등(2023) Lialin, V., Shivagunde, N., Muckatira, S., and Rumshisky, A. ReLoRA: High-Rank Training Through Low-Rank Updates, December 2023.\n' +
      '* Lin et al.(2019) Lin, H., Zhang, H., Ma, Y., He, T., Zhang, Z., Zha, S., and Li, M. 탄력적 분산 훈련을 위한 동적 미니 배치 SGD: 리소스의 림보에서의 학습. URL [http://arxiv.org/abs/1904.12043](http://arxiv.org/abs/1904.12043).\n' +
      '* Loshchilov & Hutter (2019) Loshchilov, I. and Hutter, F. Decoupled Weight Decay Regularization, January 2019.\n' +
      '* Lv et al.(2023) Lv, K., Yang, Y., Liu, T., Gao, Q., Guo, Q., and Qiu, X. 2023년 6월 리소스가 제한된 대규모 언어 모델의 전체 매개변수 미세 조정\n' +
      '* Raffel et al. (2023) Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer, September 2023.\n' +
      '* Rajbhandari et al. (2020) Rajbhandari, S., Rasley, J., Ruwase, O., and He, Y. ZeRO: 2020년 5월, 트리조 파라미터 모델 트레이닝을 위한 메모리 최적화\n' +
      '* Renduchintala et al. (2023) Renduchintala, A., Konuk, T., and Kuchaiev, O. Tied-Lora: 무게 연결로 LoRA의 매개변수 효율성 향상, 2023년 11월.\n' +
      '* Shazeer (2020) Shazeer, N. 2020년 2월, GLU Variants Improve Transformer.\n' +
      '* Shazeer & Stern (2020) Shazeer, N. 및 Stern, M. Adafactor: Sublinear Memory Cost를 갖는 Adaptive Learning Rate.\n' +
      '* Sheng et al. (2023) Sheng, Y., Cao, S., Li, D., Hooper, C., Lee, N., Yang, S., Chou, C., Zhu, B., Zheng, L., Keutzer, K., Gonzalez, J. E., and Stoica, I. S-LoRA: Serving Thousands of Concurrent LoRA Adapters, November 2023.\n' +
      '* Tian et al. (2020) Tian, Y., Yu, L., Chen, X., and Ganguli, S. 이중 심층 네트워크를 사용하여 자기 지도 학습을 이해합니다. _ arXiv preprint arXiv:2010.00578_, 2020.\n' +
      '* Tian et al.(2024) Tian, Y., Wang, Y., Zhang, Z., Chen, B., and Du, S. Joma: mlp와 주의력의 관절 역학을 통해 다층 변압기를 탈낭합니다. _ ICLR_, 2024.\n' +
      '* Touvron et al.(2020) Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L., Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu, W., Fuller, B., Go, C., Goswami, V., Goyal, N., Hartshorn, A., Hosseini, S., Hou, R., Inan, H., Kardas, M., Kerkez, V., Khabsa, M., Kloumann, I., Korenev, A., Koura, P. S., Lachaux, M. - A., Lavril, T., Lee, J., Liskovich, D., Lu, Y., Mao, Y., Martinet, X., Mihaylov, T., Mishra, P., Molybog, I., Nie, Y., Poulton, A., Reizenstein, J., Rungta, R., Schelten, A., Silva, R., Smith, E. M., Subramanian, R., Tan, X. E., Tang, B., Taylor, R., Williams, A., Kuan, J. X., Xu, P., Yan, Z., Zarov, I., Zhang, Y., Fan, A., Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S., and Scialom, T. 라마 2: 오픈 파운데이션과 미세 조정된 채팅 모델, 2023년 7월.\n' +
      '* Wang et al.(2019) Wang, A., Singh, A., Michael, J., Hill, F., Levy, O., and Bowman, S. R. GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding, February 2019.\n' +
      '* Wang et al. (2023) Wang, Y., Lin, Y., Zeng, X., and Zhang, G. MultiLoRA: Democratizing LoRA for Better Multi-Task Learning, November 2023.\n' +
      '* Xia et al.(2024) Xia, W., Qin, C., and Hazan, E. Chain of LoRA: Efficient Fine-tuning of Language Models via Residual Learning, January 2024.\n' +
      '* Zhang & Sennrich (2019) Zhang, B. and Sennrich, R. 2019년 10월, 루트 평균 제곱 층 정규화.\n' +
      '\n' +
      '## 부록 A Proofs\n' +
      '\n' +
      '### Gradient becomes low-rank\n' +
      '\n' +
      '**Lemma A.1** (훈련 중 기울기가 낮은 순위가 됨): _일반성을 손실하지 않고 \\(m\\leq n\\)로 둡니다. 상기 그래디언트 업데이트:_\n' +
      '\n' +
      '\\[G_{t}=A-BW_{t}C,\\quad W_{t}=W_{t-1}+\\eta G_{t-1} \\tag{6}\\]\n' +
      '\n' +
      '_with constant \\(A\\) 및 PSD 행렬 \\(B\\) 및 \\(C\\)와 무작위로 초기화된 \\(W_{0}\\)는 높은 확률로 낮은 순위 기울기로 이어진다:_\n' +
      '\n' +
      '\\[\\text{stable-rank}(G_{t})\\leq 1+\\sum_{i=2}^{m}O\\left(\\frac{1-\\eta \\lambda_{i}\\nu_{1}}}{1-\\eta\\lambda_{1}\\nu_{1}}}\\right)^{2t} \\tag{7}\\\n' +
      '\n' +
      '여기서 \\(\\nu_{1}=\\lambda_{\\min}(C)\\)는 \\(C\\)의 고유값이 가장 작고 \\(\\lambda_{1}\\leq\\ldots\\leq\\lambda_{n}\\)는 \\(B\\)의 고유값이다. 또한 \\(\\lambda_{2}>\\lambda_{1}\\)와 \\(\\nu_{1}>0\\)이면, \\(G_{t}\\)는 지수함수적으로 순위-\\(1\\)로 수렴한다._\n' +
      '\n' +
      '증거가 있어요\n' +
      '\n' +
      '\\[G_{t}=A-BW_{t}C=A-B(W_{t-1}+\\eta G_{t-1})C=G_{t-1}-\\eta BG_{t-1}C \\tag{18}\\]\n' +
      '\n' +
      '\\(B=UD_{B}U^{\\top}\\)와 \\(C=VD_{C}V^{\\top}\\)를 \\(B\\)와 \\(C\\)의 고유분해라고 하자. \\ (D_{B}=\\mathrm{diag}(\\lambda_{1},\\ldots,\\lambda_{m})\\)와 \\(D_{C}=\\mathrm{diag}(\\nu_{1},\\ldots,\\nu_{n})\\)의 고유값은 오름차순으로 정렬된다(즉, \\(\\lambda_{1}\\leq\\ldots\\leq\\lambda_{m}\\)와 \\(\\nu_{1}\\leq\\ldots\\leq\\nu_{n}\\). \\(H_{t}:=U^{\\top}G_{t}V\\)를 정의한다. \\(\\mathrm{rank}(H_{t})=\\mathrm{rank}(G_{t})\\) 및 우리가 갖는 것은 분명하다:\n' +
      '\n' +
      '\\[H_{t}:=U^{\\top}G_{t}V=H_{t-1}-\\eta D_{B}H_{t-1}D_{C} \\tag{19}\\]\n' +
      '\n' +
      '\\(h_{t,ij}\\)가 \\(H_{t}\\)의 \\(ij\\) 성분이라고 가정하면 위의 방정식에서 다음과 같다.\n' +
      '\n' +
      '\\[h_{t,ij}=h_{t-1,ij}-\\eta\\lambda_{i}\\nu_{j}h_{t-1,ij}=(1-\\eta\\lambda _{i}\\nu_{j})h_{t-1,ij}=(1-\\eta\\lambda_{i}\\nu_{j})^{t}h_{0,ij} \\tag{20}\\]\n' +
      '\n' +
      '그런 다음 큰 고유값에 해당하는 처음 몇 개의 행 \\(i\\) 및 열 \\(j\\)에 대해 \\(h_{t,ij}\\to 0\\) 빠르게 \\(\\mathrm{rank}(H_{t})\\)가 작아진다.\n' +
      '\n' +
      '더 정확하게 하려면 안정적인 순위를 고려하십시오.\n' +
      '\n' +
      '\\[\\text{stable-rank}(G_{t})=\\text{stable-rank}(H_{t})=\\frac{\\|H_{t} \\|_{F}^{2}}{\\|H_{t}\\|_{2}^{2}} \\tag{21}\\]\n' +
      '\n' +
      '그럼 우린...\n' +
      '\n' +
      '\\[\\|H_{t}\\|_{F}^{2}=\\sum_{i=1}^{m}\\sum_{j=1}^{n}(1-\\eta\\lambda_{i} \\nu_{j})^{2t}h_{0,ij}^{2} \\tag{22}\\]\n' +
      '\n' +
      'and\n' +
      '\n' +
      '\\[\\|H_{t}\\|_{2}^{2}\\geq\\sum_{j=1}^{n}H_{t,1j}^{2}=\\sum_{j=1}^{n}(1- \\eta\\lambda_{1}\\nu_{j})^{2t}h_{0,1j}^{2} \\tag{23}\\]\n' +
      '\n' +
      '높은 확률로 \\(h_{0,1j}^{2}\\geq\\epsilon_{0}^{2}\\), \\(|h_{1i}^{2}|\\leq c_{0}\\)가 경계이므로 다음과 같다.\n' +
      '\n' +
      '\\[\\text{stable-rank}(G_{t})\\leq 1+\\frac{c_{0}^{2}}{\\epsilon_{0}^{2}} \\sum_{i=2}^{m}\\frac{\\sum_{j=1}^{n}(1-\\eta\\lambda_{i}\\nu_{j})^{2t}}{\\sum_{j=1} ^{n}(1-\\eta\\lambda_{1}\\nu_{j})^{2t}} \\tag{24}\\]\n' +
      '\n' +
      'Mediant inequality를 사용하여, \\(a,b,c,d>0\\)에 대해 \\(\\frac{a}{b}\\leq\\frac{a+c}{b+d}\\leq\\frac{c}{d}\\)이므로, \\(i\\)-번째 행(\\(i\\geq 2\\))에 대해 \\(\\lambda_{i}\\geq\\lambda_{1}\\):\n' +
      '\n' +
      '\\[\\frac{\\sum_{j=1}^{n}(1-\\eta\\lambda_{i}\\nu_{j})^{2t}}{\\sum_{j=1}^{ n}(1-\\eta\\lambda_{1}\\nu_{j})^{2t}}\\leq\\max_{j}\\left(\\frac{1-\\eta\\lambda_{i}\\nu_{j}}}}{1-\\eta\\lambda_{1}\\nu_{j}}\\right)^{2t}=\\left(\\frac{1-\\eta\\lambda_{i}\\nu_{1}}\\nu_{1}}}\\right)^{2t}\\leq 1 \\tag{25}\\]\n' +
      '\n' +
      '그리고 결론은 다음과 같다.\n' +
      '\n' +
      '### Reversibility\n' +
      '\n' +
      '**정의 A.2** (역전성(Tian et al., 2020)).: 입력 \\(\\mathbf{x}\\)을 출력 \\(\\mathbf{y}=\\mathcal{N}(\\mathbf{x})\\)에 매핑하는 네트워크 \\(\\mathcal{N}\\)는 _역전성_이고, 만약 \\(\\mathbf{y}=K(\\mathbf{x};W)\\mathbf{x}\\)가 존재한다면, \\(\\mathbf{y}=K(\\mathbf{x};W)\\mathbf{g}_{\\mathbf{x}}\\)는 \\(\\mathbf{g}_{\\mathbf{x}}=K^{\\top}(\\mathbf{x};W)\\mathbf{g}_{\\mathbf{y}}\\)를 만족하며, 여기서 \\(\\mathbf{g}_{\\mathbf{y}}\\)는 출력 \\(\\mathbf{y}\\)에서 역전파된 구배이다. 여기서 \\(K(\\mathbf{x};W)\\)는 입력 \\(\\mathbf{x}\\) 및 네트워크 내의 가중치 \\(\\mathcal{N}\\)에 의존한다.\n' +
      '\n' +
      '많은 층들이 (바이어스 없이) 선형 층, 가역적 활성화들(예를 들어, ReLU, 누출 ReLU, 다항식들 등)을 포함하여 가역적이라는 것에 유의한다. 또한, 이들을 조합하여 보다 복잡한 아키텍처를 구성할 수 있다:\n' +
      '\n' +
      '**속성 1**.: _\\(\\mathcal{N}_{1}\\) 및 \\(\\mathcal{N}_{2}\\)가 가역 네트워크인 경우, (**병렬**) \\(\\mathbf{y}=\\alpha_{1}\\mathcal{N}_{1}(\\mathbf{x})+\\alpha_{2}\\mathcal{N}_{2}(\\mathbf{x})\\)는 상수 \\(\\alpha_{1}\\) 및 \\(\\alpha_{2}\\)에 대해 가역이고, (**구성**) \\(\\mathbf{y}=\\mathcal{N}_{2}(\\mathcal{N}_{1}(\\mathbf{x}))\\)는 가역입니다._\n' +
      '\n' +
      '이 속성으로부터, ResNet 아키텍처 \\(\\mathbf{x}+\\mathcal{N}(\\mathbf{x})\\)가 가역적이라는 것이 명백하며, 만일 \\(\\mathcal{N}\\)가 바이어스가 없는 선형 층들 및 가역적 활성화들을 포함한다면, 이는 종종 실제에서 그러하다. 자세한 분석은 (Tian et al., 2020)의 부록 A를 확인해 주십시오. 자기 주의와 같은 아키텍처의 경우 한 가지 가능성은 JoMA(Tian et al., 2024)를 활용하여 분석하고 향후 작업을 위해 떠나는 것입니다.\n' +
      '\n' +
      '사슬형 가역 네트워크의 구배는 다음과 같은 구조를 갖는다:\n' +
      '\n' +
      '(\\ell_{2}\\)-objective \\(\\varphi:=\\frac{1}{2}\\|\\mathbff{y}-\\mathcal{N}(\\mathbf{x})\\|_{2}^{2}\\)의 가중치 행렬 \\(W_{l}\\)은 배치 크기 1에 대해 다음과 같은 형태의 기울기 \\(G_{l}\\)를 갖는다.\n' +
      '\n' +
      '\\[G_{l}=\\underbrace{J_{l}^{\\top}\\mathbf{y}\\mathbf{f}_{l-1}^{\\top}}_{\\Lambda}- \\underbrace{J_{l}^{\\top}J_{l}}_{\\hat{\\mathbf{B}}}W_{l}\\underbrace{\\mathbf{f}_{l-1}\\bm {f}_{l-1}^{\\top}}_{C} \\tag{8}\\]\n' +
      '\n' +
      '_where \\(J_{l}:=\\operatorname{Jacobian}(\\mathcal{N}_{L})\\dots\\operatorname{Jacobian}( \\mathcal{N}_{l+1})\\) and \\(\\mathbf{f}_{l}:=\\mathcal{N}_{l}(\\mathcal{N}_{l-1}\\dots\\mathcal{N}_{1}(\\mathbf{x}))\\)._\n' +
      '\n' +
      '증명: 층화된 가역 네트워크의 경우, 우리는 가지고 있습니다.\n' +
      '\n' +
      '\\[\\mathcal{N}(\\mathbf{x})=\\mathcal{N}_{L}(\\mathcal{N}_{L-1}(...\\mathcal{N}_{1}(\\mathbf{ x})))=K_{L}(\\mathbf{x})K_{L-1}(\\mathbf{x})\\dots K_{1}(\\mathbf{x})\\mathbf{x} \\tag{26}\\\n' +
      '\n' +
      '\\(\\mathbf{f}_{l}:=\\mathcal{N}_{l}(\\mathcal{N}_{l-1}(\\dots\\mathcal{N}_{1}(\\mathbf{x})))\\)와 \\(J_{l}:=K_{L}(\\mathbf{x})\\dots K_{l+1}(\\mathbf{x})\\)로 하고, 선형층 \\(l\\)의 경우 \\(\\mathcal{N}(\\mathbf{x})=J_{l}W_{l}\\mathbf{f}_{l-1}\\)로 쓸 수 있다. 따라서, 가중치 행렬 \\(W_{l}\\)을 갖는 선형 층 \\(l\\)에 대해, 우리는 다음과 같다:\n' +
      '\n' +
      '[\\mathbf{y}-\\mathcal{N}(\\mathbf{x}))^{\\top}\\mathcal{\\mathrm{n}(\\mathbf{x}) \\tag{27}\\] \\[=(\\mathbf{y}-\\mathcal{N}(\\mathbf{x}))^{\\top}K_{L}(\\mathbf{x})\\dots K_{l+1}( \\mathbf{d}W_{l}\\mathbf{f}_{l-1}\\\\+\\text{ terms not related}\\\\mathrm{d}W_{l}\\mathbf{f}_{l-1}\\\\\\text{ terms not related}\\\\mathrm{d}W_{l-1}) (28) \\[=(\\mathbf{y}-J_{l}W_{l}\\mathbf{f}_{l}\\mathbf{f}_{l}\\mathbf{ f}_{l-1}\\] (29) \\[=\\operatorname{tr}(\\mathrm{\n' +
      '\n' +
      '이것은 \\(W_{l}\\)의 구배를 제공한다:\n' +
      '\n' +
      '\\[G_{l}=J_{l}^{\\top}\\mathbf{y}\\mathbf{f}_{l-1}^{\\top}-J_{l}^{\\top}J_{l}W_{l}\\mathbf{f}_{l-1} \\mathbf{f}_{l-1}^{\\top} \\tag{31}\\]\n' +
      '\n' +
      '* _For \\(K\\)-way logsoftmax loss \\(\\varphi(\\mathbf{y};\\mathbf{f}):=-\\log\\left(\\frac{\\exp(\\mathbf{y}^{\\top}\\mathbf{f})}{\\mathbf{1}^{\\top}\\exp(\\mathbf{f})}\\right)\\), let \\(\\hat{\\mathbf{f}}=P_{\\mathbf{1}}^{\\perp}\\mathbf{f}\\)는 네트워크 출력의 영평균 버전 \\(\\mathbf{f}\\)이며, 여기서 \\(P_{\\mathbf{1}}^{\\perp}:=I-\\frac{1}{K}\\mathbf{1}\\mathbf{1}}^{\\top}\\)는 다음과 같습니다.\n' +
      '\n' +
      '\\[-\\mathrm{d}\\varphi=\\mathbf{y}^{\\top}\\mathrm{d}\\hat{\\mathbf{f}}-\\gamma\\hat{\\mathbf{f}}^{ \\top}\\mathrm{d}\\hat{\\mathbf{f}}/K+O(\\hat{\\mathbf{f}}^{2}/K\\mathrm{d}\\hat{\\mathbf{f}}} \\tag{9}\\]\n' +
      '\n' +
      '\\(\\mathbf{y},\\mathbf{f})\\approx 1\\) 및 \\(\\mathbf{y}\\)는 \\(\\mathbf{y}^{\\top}\\mathbf{1}=\\mathbf{1}\\)를 갖는 데이터 라벨이다._\n' +
      '\n' +
      '증명: \\(\\hat{\\mathbf{f}}:=P_{\\mathbf{1}}}^{\\perp}\\mathbf{f}\\)를 네트워크 출력의 영평균 버전으로 한다 \\(\\mathbf{f}\\). 그리고 \\(\\mathbf{1}^{\\top}\\hat{\\mathbf{f}}=0\\)와 \\(\\mathbf{f}=\\hat{\\mathbf{f}}+c\\mathbf{1}\\)를 갖는다. 따라서, 우리는 다음과 같다:\n' +
      '\n' +
      '\\[-\\varphi=\\log\\left(\\frac{\\exp(c)\\exp(\\mathbf{y}^{\\top}\\hat{\\mathbf{f}})}{\\exp(c)\\mathbf{1}^{ \\top}\\exp(\\hat{\\mathbf{f}})}\\right)=\\mathbf{y}^{\\top}\\hat{\\mathbf{f}}-\\log(\\mathbf{1}^{\\top} \\exp(\\hat{\\mathbf{f}})) \\tag{32}\\]Taylor expansion을 이용하여 \\(\\exp(x)=1+x+\\frac{x^{2}}{2}+o(x^{2})\\), 다음과 같다.\n' +
      '\n' +
      '\\[\\mathbf{1}^{\\top}\\exp(\\hat{\\mathbf{f}}) =\\mathbf{1}^{\\top}(\\mathbf{1}+\\hat{\\mathbf{f}}+\\frac{1}{2}\\hat{\\mathbf{f}} ^{2})+o(\\hat{\\mathbf{f}}^{2})=K(1+\\hat{\\mathbf{f}}^{\\top}\\hat{\\mathbf{f}}/2K+o(\\hat{\\mathbf{f}}^ {2}/K)) \\tag{33}\\\n' +
      '\n' +
      'So\n' +
      '\n' +
      '\\[-\\varphi =\\mathbf{y}^{\\top}\\hat{\\mathbf{f}}-\\log(1+\\hat{\\mathbf{f}}^{\\top}\\hat{\\mathbf{f}}/2K+o(\\hat{\\mathbf{f}}^{2}/K))-\\log K \\tag{34}\\]\n' +
      '\n' +
      'Therefore\n' +
      '\n' +
      '\\[-\\mathrm{d}\\varphi =\\mathbf{y}^{\\top}\\mathrm{d}\\hat{\\mathbf{f}}-\\frac{\\gamma}{K}\\hat{\\mathbf{f}} }^{\\top}\\mathrm{d}\\hat{\\mathbf{f}}+O\\left(\\frac{\\hat{\\mathbf{f}}^{2}}{K}\\right) \\mathrm{d}\\hat{\\mathbf{f}}} \\tag{35}\\]\n' +
      '\n' +
      '여기서 \\(\\gamma:=(1+\\hat{\\mathbf{f}}^{\\top}\\hat{\\mathbf{f}}/2K+o(\\hat{\\mathbf{f}}^{2}/K))^{-1}\\approx 1\\이다.\n' +
      '\n' +
      '### GaLore의 수렴\n' +
      '\n' +
      '**정리 3.6** (고정 투영이 있는 GaLore의 수렴): _그래디언트에 다음 형식(Eqn)이 있다고 가정합니다. 8 with batchsize \\(>1\\):_\n' +
      '\n' +
      '\\[G=\\sum_{i}A_{i}-\\sum_{i}B_{i}WC_{i} \\tag{12}\\]\n' +
      '\n' +
      '여기서, \\(B_{i}\\) 및 \\(C_{i}\\)는 PSD 행렬이고, \\(A_{i}\\), \\(B_{i}\\) 및 \\(C_{i}\\)는 \\(W\\) 및 \\(\\|W_{t}\\|\\leq D\\)에 대한 \\(L_{A}\\), \\(L_{B}\\) 및 \\(L_{C}\\) 연속성을 갖는다. (R_{t}:=P_{t}^{\\top}G_{t}Q_{t}\\), \\(\\hat{B}_{it}:=P_{t}^{\\top}B_{i}(W_{t})P_{t}\\), \\(\\hat{C}_{it}:=Q_{t}^{\\top}C_{i}(W_{t})Q_{t}\\), \\(\\kappa_{t}:=\\frac{1}{N}\\sum_{i}\\lambda_{\\min}(\\hat{B}_{it})\\lambda_{\\min}(\\hat{C}_{it})\\). 상수 \\(P_{t}=P\\)와 \\(Q_{t}=Q\\)를 선택하면 \\(\\rho_{t}\\equiv 1\\)을 갖는 GaLore는 다음을 만족한다:_\n' +
      '\n' +
      '\\[\\|R_{t}\\|_{F} \\leq\\left[1-\\eta(\\kappa_{t-1}-L_{A}-L_{B}L_{C}D^{2})\\right]\\|R_{t -1}\\|_{F} \\tag{13}\\]\n' +
      '\n' +
      '그 결과, \\(\\min_{t}\\kappa_{t}>L_{A}+L_{B}L_{C}D^{2}\\), \\(R_{t}\\to 0\\)와 GaLore는 고정된 \\(P_{t}\\)와 \\(Q_{t}\\)에 수렴한다.\n' +
      '\n' +
      '증명: \\(\\mathrm{vec}(AXB)=(B^{\\top}\\otimes A)\\mathrm{vec}(X)\\) 여기서 \\(\\otimes\\)는 Kronecker 곱이고, 기울기 가정은 다음과 같이 쓸 수 있다:\n' +
      '\n' +
      '\\[g_{t}=a_{t}-S_{t}w_{t} \\tag{36}\\]\n' +
      '\n' +
      '여기서 \\(g_{t}:=\\mathrm{vec}(G_{t})\\in\\mathbb{R}^{mn}\\), \\(w_{t}:=\\mathrm{vec}(W_{t})\\in\\mathbb{R}^{mn}\\)는 \\(G_{t}\\)와 \\(W_{t}\\), \\(a_{t}:=\\frac{1}{N}\\sum_{i}\\mathrm{vec}(A_{it})\\)와 \\(S_{t}=\\frac{1}{N}\\sum_{i}C_{it}\\otimes B_{it}\\)의 벡터화 버전은 \\(mn\\)-by\\(mn\\) PSD 행렬이다.\n' +
      '\n' +
      '동일한 표기법을 사용하면, 다음과 같은 것을 보여주는 것이 명백하다:\n' +
      '\n' +
      '\\[(Q\\otimes P)^{\\top}g_{t} =(Q^{\\top}\\otimes P^{\\top})\\mathrm{vec}(G_{t})=\\mathrm{vec}(P^{ \\top}G_{t}Q)=\\mathrm{vec}(R_{t})=:r_{t} \\tag{37}\\] \\[\\tilde{g}_{t} :=\\mathrm{vec}(\\tilde{G}_{t})=\\mathrm{vec}(PP^{\\top}G_{t}QQ^{\\top})=(Q\\otimes P)\\mathrm{vec}(R_{t})=(Q\\otimes P)r_{t} \\tag{38}\\]\n' +
      '\n' +
      '그리고 \\(g_{t}\\)에 대한 재귀적 갱신 규칙을 유도한다.\n' +
      '\n' +
      '\\[g_{t} =a_{t}-S_{t}w_{t} \\tag{39}\\] \\[=(a_{t}-a_{t-1})+(S_{t-1}-S_{t-1}w_{t}\\] (40) \\[=e_{t}+a_{t-1}-S_{t-1}(w_{t-1}+\\eta\\tilde{g}_{t-1})\\] (41) \\[=e_{t}+g_{t-1}-\\eta S_{t-1}\\tilde{g}_{t-1} \\tag{42}\\]\n' +
      '\n' +
      '여기서 \\(e_{t}:=(a_{t}-a_{t-1})+(S_{t-1}-S_{t})w_{t}\\). 왼쪽 곱하기 \\((Q\\otimes P)^{\\top}\\), 우리는 다음과 같다:\n' +
      '\n' +
      '\\[r_{t}=(Q\\otimes P)^{\\top}e_{t}+r_{t-1}-\\eta(Q\\otimes P)^{\\top}S_{t-1}(Q\\otimes P)r_{t-1} \\tag{43}\\]Let\n' +
      '\n' +
      '\\[\\hat{S}_{t}:=(Q\\otimes P)^{\\top}S_{t}(Q\\otimes P)=\\frac{1}{N}\\sum_{i}(Q\\otimes P)^{\\top}(C_{it}\\otimes B_{it})(Q\\otimes P)=\\frac{1}{N}\\sum_{i}(Q^{\\top}C_{it}Q) \\otimes(P^{\\top}B_{it}P) \\tag{44}\\]\n' +
      '\n' +
      '그럼 우린...\n' +
      '\n' +
      '\\[r_{t}=(I-\\eta\\hat{S}_{t-1})r_{t-1}+(Q\\otimes P)^{\\top}e_{t} \\tag{45}\\]\n' +
      '\n' +
      '이제 우리는 규범을 지켰다. \\(P\\)와 \\(Q\\)는 \\(P^{\\top}P=I\\)와 \\(Q^{\\top}Q=I\\)를 갖는 투영 행렬이기 때문에 다음과 같다.\n' +
      '\n' +
      '\\[\\|(Q\\otimes P)^{\\top}e_{t}\\|_{2}=\\|\\mathrm{vec}(P^{\\top}E_{t}Q)\\|_{2}=\\|P^{ \\top}E_{t}Q\\|_{F}\\leq\\|E_{t}\\|_{F} \\tag{46}\\]\n' +
      '\n' +
      '여기서 \\(E_{t}:=\\frac{1}{N}\\sum_{i}(A_{it}-A_{i,t-1})+\\frac{1}{N}\\sum_{i}(B_{i,t-1}W_{ t}C_{i,t-1}-B_{it}W_{t}C_{it})\\이다. 따라서 우리는 \\(\\|E_{t}\\|_{F}\\)만 바인딩하면 됩니다. 참고:\n' +
      '\n' +
      '\\[\\|A_{t}-A_{t-1}\\|_{F}\\|C_{t-1}\\|_{F} \\leq\\eta L_{A}\\|_{t}-W_{t-1}\\|_{F} \\tag{47}\\] \\[\\|(B_{t}-B_{t-1}\\|_{F} \\leq L_{B}\\|W_{t}-W_{t-1}\\|_{F} \\tag{47}\\] (48) \\[\\|B_{t}W_{t}(C_{t-1}-C_{t})\\|_{F} \\leq L_{C}D^{2}\\|B_{t}\\|_{F}\\|W_{t}\\|W_{t-1}\\|_{F} \\t-1}\\|_{F} \\tag{49}\\]\n' +
      '\n' +
      '이제 \\(\\hat{S}_{t-1}\\)의 최소 고유값을 추정한다. Let \\(\\underline{\\lambda}_{it}:=\\lambda_{\\min}(P^{\\top}B_{it}P)\\) and \\(\\underline{\\nu}_{it}:=\\lambda_{\\min}(Q^{\\top}C_{it}Q)\\) then \\(\\lambda_{\\min}((P^{\\top}B_{it}P)\\otimes(Q^{\\top}C_{it}Q))=\\underline{\\lambda} _{it}\\underline{\\nu}_{it}\\) and any unit vector \\(\\mathbf{\\nu}\\):\n' +
      '\n' +
      '\\[\\mathbf{\\upsilon}^{\\top}\\hat{S}_{t}\\mathbf{v}=\\frac{1}{N}\\sum_{i}\\mathbf{\\upsilon}^{\\top} \\left[\\left(P^{\\top}B_{it}P\\right)\\otimes(Q^{\\top}C_{it}Q)\\right]\\mathbf{v}\\geq \\frac{1}{N}\\sum_{i}\\underline{\\lambda}_{it}\\underline{\\nu}_{it} \\tag{50}\\]\n' +
      '\n' +
      '따라서 \\(\\lambda_{\\min}(\\hat{S}_{t})\\geq\\frac{1}{N}\\sum_{i}\\underline{\\lambda}_{it} \\underline{\\nu}_{it}\\). 따라서 \\(\\lambda_{\\max}(I-\\eta\\hat{S}_{t-1})\\leq 1-\\frac{\\eta}{N}\\sum_{i} \\underline{\\lambda}_{i,t-1}\\underline{\\nu}_{i,t-1}\\). 따라서 \\(\\kappa_{t}:=\\frac{1}{N}\\sum_{i}\\underline{\\lambda}_{it}\\underline{\\nu}_{it}\\)을 두고 \\(\\|r_{t}\\|_{2}=\\|R_{t}\\|_{F}\\)이라는 사실을 사용하여 다음과 같이 한다.\n' +
      '\n' +
      '\\[\\|R_{t}\\|_{F}\\leq\\left[1-\\eta(\\kappa_{t-1}-L_{A}-2L_{B}L_{C}D^{2})\\right]\\|R_ {t-1}\\|_{F} \\tag{51}\\]\n' +
      '\n' +
      '그리고 결론은 다음과 같다.\n' +
      '\n' +
      '## 부록 B 사전 훈련 실험 세부 정보\n' +
      '\n' +
      '### 아키텍처 및 Hyperparameters\n' +
      '\n' +
      'LLaMA 아키텍처의 세부 사항과 사전 훈련에 사용되는 하이퍼파라미터를 소개한다. 표 5는 모델 크기에 따른 LLaMA 모델의 가장 많은 하이퍼파라미터를 보여준다. 우리는 배치 크기가 131K 토큰인 모든 모델에 대해 최대 시퀀스 길이 256을 사용한다. 모든 실험에서, 훈련 단계의 처음 10%에 대해 학습률 워밍업을 채택하고, 학습률 스케줄에 대해 코사인 어닐링을 사용하여 초기 학습률의 10%로 감쇠한다.\n' +
      '\n' +
      '각 모델의 크기(60M에서 1B까지)에 대한 모든 방법에 대해, \\(\\{0.01,0.005,0.001,0.0005,0.0001\\}\\)의 집합으로부터 그들이 선호하는 학습률을 조정하고, 검증 복잡도에 기초하여 최상의 학습률을 선택한다. 우리는 GaLore가 하이퍼파라미터에 둔감하고 다른 모델 크기에 걸쳐 동일한 학습 속도로 안정적인 경향이 있음을 발견했다. 모든 모델에서 GaLore는 학습률 \\(0.01\\), 스케일 팩터 \\(\\alpha\\) \\(0.25\\), 부공간 변화 빈도 \\(T\\) \\(200\\)를 포함한 동일한 하이퍼파라미터를 사용한다. 우리는 \\(\\alpha\\)를 분수 학습률로 볼 수 있기 때문에, LLaMA 모델에서 대부분의 모듈(예: 멀티헤드 어텐션 및 피드포워드 레이어)은 \\(0.0025\\)의 실제 학습률을 갖는다. 이것은 여전히 훈련 손실의 스파이크를 피하기 위해 일반적으로 학습률 \\(\\leq 0.001\\)을 사용하는 전체 순위 기준선에 비해 상대적으로 큰 안정적인 학습률이다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c c c c c} \\hline \\hline Params & Hidden & Intermediate & Heads & Layers & Steps & Data amount \\\\ \\hline\n' +
      '60M & 512 & 1376 & 8 & 8 & 10K & \\(1.3\\,\\mathrm{B}\\) \\\\\n' +
      '130M & 768 & 2048 & 12 & 12 & 20K & \\(2.6\\,\\mathrm{B}\\) \\\\\n' +
      '350M & 1024 & 2736 & 16 & 24 & 60K & \\(7.8\\,\\mathrm{B}\\) \\\\ \\(1\\,\\mathrm{B}\\) & 2048 & 5461 & 24 & 32 & 100K & \\(13.1\\,\\mathrm{B}\\) \\\\ \\(7\\,\\mathrm{B}\\) & 4096 & 11008 & 32 & 32 & 150K & \\(19.7\\,\\mathrm{B}\\) \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: 평가를 위한 LLaMA 모델의 하이퍼파라미터. 데이터 양은 토큰에 지정됩니다.\n' +
      '\n' +
      '### Memory Estimates\n' +
      '\n' +
      '특정 컴포넌트에 대한 GPU 메모리 사용량은 직접 측정하기 어렵기 때문에 모델 크기에 따라 각 방법에 대한 가중치 파라미터와 최적화 상태들의 메모리 사용량을 추정한다. 추정은 BF16 형식으로 훈련된 원래 매개변수의 수와 하위 순위 매개변수의 수를 기반으로 한다. 예를 들어, 60M 모델의 경우 LoRA (\\(r=128\\))는 낮은 순위 어댑터의 경우 \\(42.7\\)M 파라미터와 원래 가중치의 경우 \\(60M\\) 파라미터가 필요하므로 가중치 파라미터의 경우 \\(0.20\\)G, 최적화기 상태의 경우 \\(0.17\\)G의 메모리 비용이 발생한다. 표 6은 본문에 보고된 총 메모리에 대한 보완으로 다른 모델 크기에 대한 다른 방법에 대한 가중치 매개변수 및 최적화기 상태에 대한 메모리 추정치를 보여준다.\n' +
      '\n' +
      '## 부록 C 미세 조정 실험 세부 정보\n' +
      '\n' +
      'GLUE 벤치마크에서 Hugging Face1에서 제공하는 모델을 사용하여 사전 학습된 RoBERTa-Base 모델을 미세 조정한다. 32개의 배치 크기를 사용하는 CoLA를 제외한 모든 태스크에 대해 배치 크기가 16인 30개의 에폭에 대해 모델을 학습시켰다. GaLore에 대한 학습률과 스케일 팩터를 조정한다. 표 7은 GaLore에 대한 RoBERTa-Base의 미세 조정에 사용되는 하이퍼파라미터를 나타낸다.\n' +
      '\n' +
      '각주 1: [https://huggingface.co/transformers/model_doc/roberta.html](https://huggingface.co/transformers/model_doc/roberta.html)\n' +
      '\n' +
      '\\begin{table}\n' +
      '\n' +
      '\\end{table}\n' +
      '표 6: 가중치 파라미터 및 최적화기 상태에 대한 메모리 추정치.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\n' +
      '\\end{table}\n' +
      '표 7: GaLore에 대한 미세-튜닝 RoBERTa 베이스의 하이퍼파라미터.\n' +
      '\n' +
      '## 부록 D 추가 메모리 측정\n' +
      '\n' +
      '표 8과 같이 토큰 배치 크기가 256인 C4 데이터 세트에서 LLaMA 1B 모델을 사전 훈련하기 위한 다양한 방법의 메모리 사용량을 경험적으로 측정한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c|c|c|c|c|c c} \\hline \\hline Model Size & Layer Wise & Methods & Token Batch Size & Memory Cost & \\multicolumn{2}{c}{Throughput} \\\\  & & & & & \\#Tokens / s & \\#Samples / s \\\\ \\hline \\multirow{4}{*}{1B} & \\multirow{4}{*}{✗} & AdamW & 256 & 13.60 & 1256.98 & 6.33 \\\\  & & Adafactor & 256 & 13.15 & 581.02 & 2.92 \\\\  & & Adam8bit & 256 & 9.54 & 1569.89 & 7.90 \\\\  & & 8-bit GaLore & 256 & 7.95 & 1109.38 & 5.59 \\\\ \\hline \\multirow{4}{*}{1B} & \\multirow{4}{*}{✓} & AdamW & 256 & 9.63 & 1354.37 & 6.81 \\\\  & & Adafactor & 256 & 10.32 & 613.90 & 3.09 \\\\ \\cline{1-1}  & & Adam8bit & 256 & 6.93 & 1205.31 & 6.07 \\\\ \\cline{1-1}  & & 8-bit GaLore & 256 & 5.63 & 1019.63 & 5.13 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 8: LLaMA 1B 모델에 대한 메모리 및 처리량 측정.\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>