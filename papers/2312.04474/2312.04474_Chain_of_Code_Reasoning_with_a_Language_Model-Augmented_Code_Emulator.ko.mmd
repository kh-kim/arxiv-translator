[MISSING_PAGE_EMPTY:1]

## 1 Introduction

특정 규모의 언어 모델(LMs)은 복잡한 추론 질문을 푸는 심오한 능력을 나타낸다[3; 41]. - 수학 프로그램 작성[9]에서부터 과학 문제 풀이[17]. 특히, 이러한 능력들은 [42]를 프롬프트하는 CoT(Chain of Thought)로 개선되는 것으로 나타났으며, 이에 따라 복잡한 문제들이 일련의 중간 추론 단계들로 분해된다. CoT는 의미 추론 과제에 탁월하지만 숫자 또는 기호 추론을 포함하는 질문과 싸우는 경향이 있다[23; 36]. 후속 작업은 LMs(예를 들어, Github [4]에서 훈련됨)가 코드 [1; 5; 26]를 작성하고 실행하도록 촉구함으로써 이를 해결한다. 특히 코드는 (i) 복잡한 프로그램들을 구축하고 인코딩하기 위한 일반적인 구문 구조[19](예를 들어, 논리 구조들, 기능적 어휘들 - 튜링 완료인 방식들) 및 (ii) 해석기와 함께 페어링되는 기존의 API들이 (예를 들어, 큰 숫자들의 곱셈으로부터 사이즈 10,000의 어레이를 정렬하는 것) 정확한 알고리즘 계산들을 수행하기 위해 사용될 수 있는 인터페이스를 모두 제공하기 때문에 유리하다.

코드를 작성하고 실행하는 것은 광범위한 산술 태스크에 걸쳐 LM 추론 성능을 향상시킬 수 있지만, 이 특정 접근법은 많은 의미 태스크가 코드로 표현하기가 다소 어렵다는 사실(그리고 때때로 거의 불가능하다는 사실)과 대조된다. 예를 들어, 부울이 스트링 [36]에서 빈정거림을 검출할 때 부울을 반환하는 함수를 작성하는 방법은 불분명하다(에지 케이스를 처리하는 것은 극복할 수 없을 것이다). 아마도 근본적으로, 다단계 텍스트 추론 대신에 LM을 사용하여 프로그램을 작성하는 것은 본질적으로 중간 추론 트레이스(코드 라인으로 표현됨)가 모두 인터프리터에 의해 _실행가능_할 필요가 있다고 가정한다. 코드로 추론하는 것과 언어로 추론하는 것 모두를 최상으로 하기 위해 이러한 제한을 해제하는 것이 가능할까?

본 연구에서는 LM 코드 기반 추론(LM code-driven reasoning)을 개선하기 위한 간단하면서도 놀랍게도 효과적인 확장인 CoC( Chain of Code)를 제안한다. 여기서 LM은 프로그램을 작성할 뿐만 아니라 특정 코드 라인의 예상 출력을 생성함으로써 인터프리터를 선택적으로 "시뮬레이션"한다(인터프리터가 실행할 수 없는). 핵심 아이디어는 LM이 프로그램의 의미적 하위 태스크를 유연한 의사코드로 포맷하도록 장려하는 것인데, 이는 런타임에서 LM과 에뮬레이션하기 위해 명시적으로 포착되고 핸드오프될 수 있다. 우리는 이것을 LMulator(LM과 에뮬레이터의 포트만토)라고 한다. 예를 들어, "위 단락에서, 사람이 얼마나 비꼬았는지 카운트하세요_"라는 태스크를 고려할 때, 우리는 LM이 is_sarcastic(문장)과 같은 도우미 함수들을 호출할 수 있는 프로그램을 작성하도록 문맥 내에 프롬프트할 수 있고, 이 프로그램은 LM이 언어적 예측을 하고 그 결과를 부울 출력으로서 반환하고, 그 후 나머지 프로그램과 함께 처리된다. 구체적으로, 다음 프로세스로서 LM 추론을 공식화한다(도 1에 예시됨): LM은 코드를 작성하고, 인터프리터는 각 라인의 코드를 실행하기 위해 단계(빨간색)를 거치고, 또는 실패하면, 결과를 LM으로 시뮬레이션하고(보라색) 프로그램 상태를 업데이트한다(녹색). CoC는 (i) 실행 가능한 코드를 쓰는 것(정확한 알고리즘 계산이 해석자에게 맡겨진 경우)과 (ii) 의미론적 문제에 대한 의사 코드를 쓰는 것, 그리고 그들의 출력을 생성하는 것(단순한 형식 변경으로 생각할 수 있는 LM이 강력한 것[22])의 이점을 상속한다.

광범위한 실험들은 CoC가 매우 다양한 도전적인 수치 및 의미론적 추론 질문들에 적용가능하고, 다수의 인기 있는 베이스라인들보다 우수함을 입증한다. 특히, 우리는 BIG-Bench Hard 태스크[36]에서 높은 성능을 달성하고, 전체 평균 인간 평가자 및 심지어 알고리즘의 하위 집합에서 최고의 인간 평가자를 능가하며, 우리가 아는 한 새로운 최신 기술을 설정한다는 것을 발견했다. 또한 이 성능을 위해 코드 해석기 실행과 언어 모델 실행 시뮬레이션이 모두 필요하며, 접근 방식은 규모에서만 나타나는 Chain of Thought와 같은 촉진 기술과 달리 크고 작은 모델 모두에서 잘 확장된다는 것을 보여준다. 마지막으로 _크로스 태스크 프롬프트_ 벤치마크를 통해 Chain of Code가 범용 추론기 역할을 할 수 있는 방법을 보여 줍니다. 이는 이전 작업과 달리 다른 문제 패밀리의 프롬프트를 컨텍스트로 사용 하 여 (솔루션 자체와는 반대) 응답 구조만 제공 합니다. 이 작업은 코드의 구조와 계산 능력과 언어 모델의 추론 능력을 어떻게 활용할 수 있는지 강조하여 "양쪽 세계의 최선" 추론기를 가능하게 한다.

## 2 Chain of Code: Reasoning with LMulator

본 절에서는 언어 모델의 코드화, 추론 및 LM-증강 코드 에뮬레이터(LMulator)를 활용하여 실행 중인 코드를 시뮬레이션하는 접근법인 CoC 프롬프팅에 대해 설명한다. 우리는 섹션 2.1의 배경에서 시작하여 섹션 2.2의 방법, 섹션 2.3의 구현, 마지막으로 섹션 2.4의 기능을 개관한다.

### Preliminaries

간략히 설명하자면 LM 추론에 대한 몇 가지 배경을 설명한다. 이러한 추론 기술들 중 많은 것들이 기울기들로 임의의 가중치들을 업데이트하는 것이 아니라 추론 시간에 몇 가지 예시적인 예들을 모델에 제공하는 인-컨텍스트 학습 [3]에 의해 가능하게 되었다. 이러한 예제는 설정에 대 한 컨텍스트 및 형식을 제공 하 여 모델이 새 쿼리에 적응 하는 동안 이러한 예제를 에뮬레이트할 수 있도록 합니다. 이 특성은 LM을 빠르게 적응할 수 있고 최소한의 데이터가 필요하기 때문에 새로운 작업에 쉽게 적용하는 데 중요한 역할을 했다.

맥락 내 학습을 통해 인간의 사고 과정을 활용하고 언어 모델의 성능을 향상시키기 위한 도구를 사용하는 접근법이 개발되었다. 우리는 연쇄 코드의 기초를 제공하는 세 가지 접근법에 대해 설명한다. 사상의 사슬[42], 스크래치패드[26], 그리고 사상의 프로그램[5]은 문제를 하위 단계로 나누는 효과를 보여주었다. CoT에게 이러한 하위 단계는 복잡한 문제를 밟을 때 자신의 사고 과정을 반영하는 자연 언어이다. 반면에, ScratchPad는 코드의 출력을 시뮬레이션할 때 중간 단계의 프로그램 상태를 유지하며 - 결과적으로 LM은 코드 해석기로서 작용한다. 사상의 프로그램 [5]는 코드 자체를 생성하는 데 중점을 두었으며, 이 코드는 추론 문제를 해결하기 위해 코드 해석기에 의해 실행된다. 이들 각각은 그림 2에 시각화되어 있다.

### Code Chain

인간이 자연어, 의사코드, 실행 코드가 혼합된 특히 복잡한 문제를 통해 추론할 수 있는 방법 또는 연구자가 코드 기반 형식론을 통해 새로운 일반 알고리즘을 개발한 다음 문제에 적용하는 방법에서 영감을 얻은 코드 사슬은 (1) 풀어야 할 질문이 주어지면 LM이 문제를 통해 추론할 코드를 생성하는 생성 및 (2) 가능한 경우 코드 해석기를 통해 코드를 실행하고 그렇지 않은 경우 LM을 통해 코드를 실행하는 실행의 두 단계로 진행된다. 구체적인 구현에 대한 자세한 내용은 섹션 2.3을 참조하십시오.

**코드 생성의 체인** 풀어야 할 문제가 주어지면 CoC는 코드 구조에서 추론 하위 단계를 생성합니다. 이 코드는 문제를 통한 추론의 틀을 제공하며, 명시적 코드, 의사 코드 또는 자연어의 형태일 수 있다. 그림 1(d)는 BIG-Bench의 객체 계수 문제를 해결하기 위해 잠재 세대를 걷는다.

**코드 실행의 사슬** CoC의 핵심 기여는 추론 코드의 생성뿐만 아니라 실행되는 방식입니다. 코드가 작성되면 코드 인터프리터에 의해 코드가 실행되도록 시도된다. 이 작업에서 우리는 파이썬을 고려하지만 접근법은 모든 인터프리터에 일반적이다. 코드가 성공적으로 실행되면, 프로그램 상태가 업데이트되고 실행이 계속된다. 코드가 실행 가능하지 않거나 예외를 제기하는 경우, 언어 모델은 대신 실행을 시뮬레이션하는 데 사용된다. 프로그램 상태는 언어 모델의 출력들에 의해 후속하여 업데이트되고 실행은 계속된다. 여기서는 이를 LMulator, LM과 코드 에뮬레이터의 portmanteau라고 한다. 이러한 비교적 간단한 변경은 시멘틱과 숫자를 혼합한 코드에 대한 다양한 새로운 응용 프로그램을 가능하게 한다. 그림 1(e)는 생성된 코드가 어떻게 실행되고, 프로그램 상태를 유지하며, 파이썬 실행기와 LMulator 사이에서 스위칭되는지를 보여준다.

### 코드 구현 체인

생성 구현은 간단한 프롬프트 및 언어 모델 생성이지만 실행 구현은 약간 더 복잡하다. 이 구현은 파이썬의 시도(Try)를 사용하여 프로그램 상태를 제외하고 유지하는 것을 기반으로 한다. 라인별 CoC는 코드를 통과합니다. 라인은 코드 인터프리터에 의해 실행가능하면 실행되고, 프로그램 상태가 갱신되고, 프로그램이 계속된다. 코드 해석기에 의해 실행 가능하지 않으면, 언어 모델에는 프로그램의 컨텍스트(질문, 이전 행 및 프로그램 상태의 이력)가 주어지고 다음 프로그램 상태가 생성된다. 이 에뮬레이션은 또한 대응 방법을 결정하기 위해 사고의 사슬을 활용할 수 있다. 그 생성된 프로그램 상태는 또한 코드 인터프리터에 대해 업데이트된다. 이러한 프로그램 상태의 공유는

그림 2: **이전 추론 방법:** 고급 문제를 해결 하기 위해 (2a) 생각의 체인 프롬프트는 문제를 중간 단계로 분할 하 고, (2b) 코드를 작성 하 고 실행 하는 생각의 프로그램 및 (2c) 스크래치패드 프롬프트는 프로그램 상태를 통해 중간 단계를 추적 하 여 이미 작성 된 코드를 실행 하는 것을 시뮬레이션 합니다. **우리의 추론 방법:** Chain of Code는 먼저 (2d) 질문을 해결하기 위해 코드 또는 psuedocode를 생성한 다음 (2e) 가능한 경우 코드 해석기를 사용 하 고 LMulator (코드를 에뮬레이트 하는 언어 모델)를 사용 하 여 코드를 실행 합니다. 블루 하이라이트는 LM 생성을 나타내고, \(\overline{\text{red}}\) 하이라이트는 실행 중인 LM 생성 코드를 나타내며, \(\overline{\text{purple}}\) 하이라이트는 프로그램 상태를 그린으로 시뮬레이션하는 LMulator를 나타낸다.

코드 인터프리터와 언어 모델 시뮬레이터를 임의의 인터위빙에 적용할 수 있는 방식으로 인터위빙하여 포루프 및 이프 스테이트먼트와 같은 흐름을 제어한다. 이는 전체 코드가 실행될 때까지 계속되며, 답변은 답변으로 명명된 변수의 값으로서 검색되거나, 복구할 수 없는 에러의 경우, 언어 모델이 A: 답변을 출력한다.

간단한 예로서, 코드 답변 = 0; 답변 *= is_s_s_s_s_s_castic('you don't say'); 답변 *= 1;은 다음과 같이 실행될 것이다: (1) 파이썬은 첫 번째 라인 답변 = 0을 실행하고, 프로그램 상태를 (답변 = 0)으로 업데이트하고, (2) 파이썬은 두 번째 라인을 실행하려고 시도하여 실패하고, 따라서 LMulator는 프로그램에서 업데이트될 프로그램 상태(답변 = 1)를 생성함으로써 코드 답변 *= is_s_s_s_s_castic('you don't say')를 시뮬레이션할 것이다, (3) 파이썬은 마지막 라인 답변 *= 1을 실행하고, 프로그램 상태를 (답변 = 2), (4) 답변은 2로 검색될 것이다.

### 코드 기능 체인

코드의 사슬에는 몇 가지 매력적인 속성이 있습니다.

1. 코드의 장점을 언어 모델의 강력한 의미론적 및 상식적 지식과 결합함으로써 완전히 새로운 체제에서 코드 사용을 가능하게 하며, 이는 코드로 표현하기 어려운 규칙(예를 들어, 어떤 식품이 과일인가?)을 쉽게 표현할 수 있다. 이러한 능력은 추론 문제를 넘어 이점을 가질 수 있으며 그 유연성은 의사 코드와 같은 표현 언어를 실행할 수 있게 한다.
2. 사용 가능한 고품질 데이터로 인해 최근 언어 모델의 특정 강점인 코드화 언어 모델의 능력을 활용합니다.
3. 코드의 형식적이면서도 표현적인 구조(예: Turing completeness)와 코드가 사용할 수 있는 강력한 계산 도구(단순히 두 수를 곱하든, \(\sqrt[]{12121}\을 계산하든, 물리학을 시뮬레이션하든)의 추론 코드의 많은 이점을 계승한다.
4. 사상의 사슬과 같은 중간 단계를 통해 추론하는 기술의 많은 이점을 상속합니다. 이러한 기법들은 언어 모델이 문제를 해결하기 위해 필요할 때 더 많은 계산을 사용할 수 있을 뿐만 아니라 더 많은 해석 가능성을 제공할 수 있게 한다.

경험적으로, 우리는 섹션 3에서 이러한 이점이 다양한 도전적 과제에 비해 추론 수행의 상당한 개선을 초래한다는 것을 관찰한다.

## 3 언어 추론 실험 평가

우리는 다음과 같은 질문에 답하기 위해 산술, 상식 또는 기호 추론 과제이든 다양한 유형의 추론이 필요한 도전적인 문제를 선택한다.

1. CoC는 다양한 작업에 걸쳐 전체적으로 얼마나 잘 수행하는가?
2. CoC가 어떤 유형의 문제를 가장 잘 수행하는가?
3. CoC의 각 측면이 전체 성능에 어떠한 영향을 미치는가?
4. CoC scale with model size?
5. CoC가 (우리가 크로스-태스크 프롬프팅이라 칭하는) 동일한 문제보다는 상이한 문제로부터의 신속한 예들을 갖는, 범용 추론기로서 어떻게 수행하는가?
6. CoC는 툴이 있거나 없는 명령어 튜닝된 채팅 모델과 어떻게 비교되는가?

우리는 먼저 섹션 3.1에서 고려된 접근법, 절제 및 기준선에 대해 논의한 다음 섹션 3.2에서 고려된 작업 및 마지막으로 섹션 3.3에서 결과를 논의한다.

### Baselines 및 Ablade

우리는 주요 방법을 **CoC(Interweave)** 라고 생각하지만, 구현이 더 간단하고 성능이 약간 낮은 두 가지 변형을 제안합니다. **CoC(LM을 제외한 Python 시도)** 및 **CoC(LM 상태를 제외한 Python 시도)** 입니다. 이 두 가지 변형은 생성된 코드 전체를 파이썬(라인 단위가 아니라)으로 실행하려고 시도하고 실패하면 LMulator로 코드 실행을 시뮬레이션하여 최종 답변 또는 중간 상태 추적을 각각 출력한다. 우리는 또한 다음 절제를 수행하며, 그 중 일부는 언급된 바와 같이 이전 작업과 유사하다. **CoC (Python)** 에서 Python은 생성 된 전체 코드를 실행 하는 데 사용 되며 코드가 실행 되지 않는 경우 실패로 표시 됩니다. 이는 생각 프로그램 [5] 또는 프로그램 지원 언어 모델 [10]과의 비교로 생각할 수 있습니다. 우리는 많은 경우에 추론 문제 중 일부에 대한 실행 가능한 코드를 쓰는 것이 거의 불가능해지기 때문에(예: 구문이 비꼬는지 판단하기 위한 코드를 쓰는 것) 이 기준선이 특히 도전받지만, 보다 공정한 비교를 위해 알고리즘 작업에 대한 결과에 초점을 맞출 수 있다. **CoC(LM)** 에서 코드는 최종 답변을 출력하는 LMulator에 의해 해석되고, **CoC(LM 상태)** 에서 코드는 중간 단계의 상태 추적을 출력하는 LMulator에 의해 해석됩니다. 이는 추론을 위해 프롬프트하는 ScratchPad로 생각할 수 있습니다. [26]. 참고, 마지막 두 절제는 파이썬 해석기를 활용하지 않습니다.

우리는 또한 다음 기준선과 비교합니다. **직접** 질문에서 LM은 단순히 최종 답변으로 질문에 응답합니다. **CoT** 를 프롬프트 하는 생각 체인에서 LM은 중간 단계를 사용 하 여 작업을 해결 합니다. 프롬프트가 쉽게 사용할 수 있으므로 하위 단계 프롬프트 [16, 48] 필드에 대 한 표준 프롬프트 기술로 CoT를 사용 합니다.

### Tasks

가장 어려운 작업을 해결 하는지 확인 하기 위해 BIG-Bench Hard (BBH) [36] 이라고 하는 BIG-Bench [34]의 도전 작업 하위 집합을 고려 합니다. 이러한 작업은 언어 모델에 대한 어려움으로 특별히 선택되었으며 데이터 세트는 인간 평가 기준선과 사상 사슬 프롬프트를 제공한다. 23개의 태스크는 의미론적 추론(예를 들어, "영화 추천"), 수치적 추론(예를 들어, "다중 단계 연산"), 및 양자의 조합(예를 들어, "객체 카운트")을 필요로 한다. 따라서 코딩이 자연스러운 적합성뿐만 아니라 다양한 문제에 걸쳐 CoC의 효능을 연구할 수 있다. 부록 그림 A1에 몇 가지 프롬프트가 나와 있다. 또한 부록 섹션 A.2의 GSM8K 벤치마크 [7]에 대한 결과를 보여주지만 이러한 문제는 주로 코드를 통해 알고리즘적으로만 해결된다.

이러한 작업은 **few-shot 프롬프트** 로 평가 되며 동일한 문제 패밀리의 세 가지 예가 컨텍스트로 제공 됩니다. 또한 **교차 작업 프롬프트** 라는 새로운 평가 설정을 도입 하 여 _다른_ 문제의 세 가지 예가 컨텍스트로 제공 됩니다. 따라서 언어 모델에는 추론의 _형식_에 대 한 컨텍스트 내 예제가 있지만 추론에 대 한 명시적 지침은 제공 되지 않습니다. 우리는 이것을 범용 추론기에 대한 표시 신호로 보고 있는데, 이는 많은 실제 애플리케이션(예를 들어, 챗봇)에서 매우 다양한 작업에 걸쳐 추론하도록 요청될 것이다.

본 명세서에서 사용되는 모델은 OpenAI 계열의 모델: text-ada-001, text-baggage-001, text-curie-001 및 text-davinci-003(플롯에서 이를 a-1, b-1, c-1 및 d-3으로 표시함)을 포함한다. 또한 PaLM-2의 코드 피니튜닝된 변형[6, 12]을 고려한다. 명령어 튜닝 모델의 경우, 최근 GPT(gpt-3.5-turbo 및 gpt-4) 변형과 2023년 10월에 실행된 채팅 완료 모드를 비교한다. 아래 결과는 달리 명시되지 않는 한 텍스트-다빈치-003 모델을 사용하고 있다.

### Results

**질문 1: 전체 성능.** CoC의 전체 성능은 그림 1 및 표 1에 나와 있습니다 (표 A1의 전체 결과). 우리는 CoC가 인간 기준선을 초과하는 작업 수와 기준선을 초과하는 전체 양 모두에서 다른 접근법보다 성능이 우수함을 알 수 있다. 실제로, CoC의 84%는 우리가 아는 한 SoTA이다[11]. 여러 태스크에서 CoC는 인간의 기준선 및 다른 방법보다 훨씬 더 우수하여 거의 100%를 달성한다. 일반적으로 이러한 태스크에 대해 결과는 언어는 복잡하지만 코드에서는 사소하다(예: 다단계 산술 Q: (\((-3+5\times 8\times-4)-(9-8\times-7)) =). 우리는 또한 CoT가 여러 작업에서 인간 기준선을 능가하는 반면 직접 답변은 요금이 좋지 않다는 것을 관찰했다.

표 1 | 단일 작업과 교차 작업을 사용 하 여 몇 번의 프롬프트를 모두 사용 하는 전체 성능 (%)입니다. 직접 프롬프트와 비교한 델타는 괄호 안에 표시됩니다.

**문제 2: 문제 유형.** 그림 3은 결과를 문제 유형별로 세분화 합니다. 작업 레이블은 표 A1에 표시 됩니다. 먼저 주로 알고리즘적이거나 주로 자연 언어인 문제를 분리 합니다 (이러한 범주는 [36]에서 식별 됨). 알고리즘 태스크에서는 CoC가 특히 잘 수행되고, 자연어 태스크에서는 CoC가 CoT와 동등하게 수행됨을 알 수 있다. 이것은 특히 고무적인데, 왜냐하면 이러한 언어 중심 작업이 코드에 더 적합하지 않을 것으로 예상할 수 있기 때문이다. 핵심은 이 방법이 자연어 문제에 대한 LM의 의미 추론 능력을 유지하면서 코드 실행의 출력을 시뮬레이션하기 위해 LMulator를 사용할 수 있는 유연성을 제공한다는 것이다.

그림 3은 각 질문의 응답이 얼마나 다른지, 파이썬에 의해 코드가 완전히 실행될 수 있는지(파이썬 전용 대 파이썬 + LM으로 표시됨)를 캡처하는 범주로 작업을 추가로 나눈다. 벤치마크 내의 일부 작업에 대해 각 질문은 동일한 코드 또는 사상의 사슬을 가지며 유일한 변동은 입력이다. 이 경우 코드는 반복된 코드라고 말하고 그렇지 않은 경우(새로운 코드)로 표시된다. 예상대로 코드가 파이썬에 의해 반복되고 실행될 때 CoC는 거의 100%를 얻지만 이러한 작업(예: 다중 단계 산술)은 인간 평가자를 포함한 다른 기준선에 가장 어려운 것 같다. 다른 범주는 CoC에 더 도전적이지만 각각에서는 여전히 기준선보다 이점이 있다.

**질문 3: Ablations.** 그림 4 및 5와 표 2는 Chain of Code 프롬프트의 각 측면에 동기를 부여하기 위해 수행된 삭제를 보여줍니다. 예상할 수 있듯이 Python을 실행하는 방법(CoC(Interweave, Python, try Python except LM, try Python except LM state))은 여러 작업에서 100% 성능을 달성합니다. 코드가 올바른 경우 모델이 매번 정확합니다. 그러나, 파이썬 단독에 의존하는 접근법(CoC(Python))은 비알고리즘 태스크에 적용될 때 성능이 좋지 않아 거의 모든 것에 실패한다. CoC(Python) 절제는 최근 [5; 10]과 유사하며, 이는 수치적 문제에 적용하면 코드 추론이 잘 수행됨을 보여준다. Python 인터프리터가 없는 CoC(CoC(LM, LM 상태))는 비용이 많이 들지 않지만, ScratchPad 프롬프트 [26]에서 제안된 단계별 접근 방식이 각 작업에서 개선됨을 알 수 있다.

또한, CoC가 먼저 전체 코드를 Python으로 실행하려고 하는 ablations CoC(LM을 제외하고 Python을 시도, LM 상태를 제외하고 Python을 시도)가 LM으로 코드를 시뮬레이션하지 못하면 상당히 잘 수행됨을 보인다. 다시, 우리는 프로그램 상태를 유지하는 것이 성능의 향상을 제공한다는 것을 안다. 성능의 약간의 저하만 관찰되면 단순화를 위해 완전히 엮인 CoC에 대한 합리적인 대안이다. 우리가 주목하지만, 이러한 삭제의 성능은 인터위빙 코드와 의미론이 진정으로 필요한 경우에 훨씬 더 나쁠 것이다 - 예를 들어, 이미지 입력을 파싱하거나 외부 데이터베이스에 액세스하기 위해 코드가 필요하지만 결과를 파싱하기 위해 언어가 필요한 경우를 상상해 보면(섹션 4의 로봇 공학 응용 프로그램 참조).

**질문 4: 크기 조정** 그림 6은 다양한 모델 크기에 걸친 CoC의 성능을 보여 줍니다. 우리는 CoC의 개선이 Thought Chain 프롬프트와 유사하게 모델로서 증가한다는 것을 관찰한다.

그림 4: 작업 유형별로 그룹화된 평균 성능에 대한 CoC 제거.

도 5: 인간 기준선에 비해 모든 BIG-Bench 하드 작업에 걸친 결과[34]. 각 플롯의 작업(x축)은 성능별로 개별적으로 정렬됩니다. 작업 유형별 분류는 표 A1 및 그림 4를 참조하십시오.

크기가 커지다. 사실, 알고리즘 작업의 일부에서, Code의 Chain of Code는 심지어 최고의 인간 평가자(코드에 대한 접근 권한이 없었던 것으로 인정됨)보다 더 우수하다. 그러나 가장 큰 모델(d-3)에 대해서만 성능 이점을 가져오는 Chain of Thought 프롬프트와 달리 CoC는 더 작은 모델(a-1, b-1, c-1)에 대해서도 직접 질의 응답 기준보다 성능이 우수하여 더 작은 모델이 자연어보다 구조화된 코드를 중간 단계로 출력하는 것이 더 쉽다는 것을 시사한다.

**질문 5: 작업 간 프롬프트** 작업 간 프롬프트의 경우 여러 문제의 몇 가지 예제를 사용하여 언어 모델을 프롬프트합니다. 그림 6과 표 2의 모든 방법에 대한 성능 저하를 볼 수 있다. 이러한 감소에도 불구하고 CoC는 CoT와 규모에서 직접 프롬프팅보다 성능이 우수하여 인간의 평균 성능을 거의 달성했다. 이것은 모델이 프롬프트에서 유사한 문제의 예를 받을 것으로 기대하지 않는 범용 추론에 대한 유망한 표시이다.

**질문 6: 명령 조정 모델입니다.* * 채팅 인터페이스가 있는 명령 조정 모델과 비교하기 위해 원하는 추론 접근 방식을 이끌어내기 위해 명령으로 모델을 프롬프트합니다. 기준선의 경우 모델에 "직접 대답"(직접) 또는 "단계별 생각"(CoT)을 요청 합니다. CoC 변형의 경우 모델에 "도움이 된다면 문제를 해결하는 데 도움이 되도록 파이썬 코드를 작성하라"고 요청한다. 프로그램이 작성 된 경우 Python 해석기로 코드를 실행 한 다음 결과 (또는 실행이 실패 하는 경우 오류 메시지)를 모델에 피드백 하 여 최종 답변 (CoC (Python))을 결정 하거나 모델에 코드 실행 출력을 LMulator (CoC (LM))로 시뮬레이션 하도록 요청 합니다. CoC(Python) 기준선은 Python 도구 사용이 있는 LM과 비교한 것으로 생각할 수 있다.

각각의 성능을 표 3에 나타낸다. gpt-3.5-turbo를 사용하면 CoT와 CoC(Python) 모두 CoC(Interweave)에 의해 강력하게 능가되지만 직접 프롬프트보다 이점을 보여준다. gpt-4를 사용하면, 텍스트-다빈치-003에 비해 상당한 모델 강도 이점에도 불구하고, CoC(인터위브)는 갭이 더 좁지만 여전히 우수한 성능을 보인다. 채팅 인터페이스의 한계로 인해 이러한 모델로 전체 CoC(Interweaved) 접근법을 실행할 수 없지만 gpt-4와 쌍을 이루면 추가 이득이 예상된다.

\begin{table}
\begin{tabular}{l c c c c c c} \hline \hline  & \multicolumn{6}{c}{Chain of Code} \\ \cline{2-7}  & Interweave & try Python & try Python & Python & LM state & LM \\ Prompt & & except LM state & except LM & & & \\ \hline Single task & 84 & 82 (-2) & 80 (-4) & 48 (-36) & 63 (-21) & 57 (-27) \\ Cross task & 61 & 57 (-4) & 60 (-1) & 35 (-26) & 49 (-12) & 50 (-11) \\ \hline \hline \end{tabular}
\end{table}
표 2: 단일 작업 및 교차 작업으로 적은 샷 프롬프팅 둘 다를 갖는 절제 전체 성능(%). 전체 모형(Interweave)과 비교한 델타는 괄호 안에 표시되어 있다.

도 6: 모델 스케일링에 따른 평균 성능.

## 4 Robotics 애플리케이션

로보틱스 태스크는 시맨틱 추론 및 알고리즘 추론을 필요로 할 뿐만 아니라 코드를 통한 다른 API(예: 제어 또는 지각 API [19]) 및 자연 언어를 통한 사용자와 인터페이싱하기 때문에 로보틱스와 같은 다운스트림 애플리케이션은 CoC에 적합하다. 예를 들어, "과일들을 크기별로 정렬"과 같은 태스크가 주어지면, 로봇은 어떤 아이템들이 과일인지를 추론하고, 그것들을 크기별로 정렬한 다음, 그러한 결정들을 로봇 상에서 실행가능한 동작들에 연결해야 한다. CoC(Interweave)는 런타임에 파이썬 해석기 및 LMulator를 사용하여 이러한 문제를 해결할 수 있는 동시에, 로봇 정책을 보다 해석가능하고 세밀하게 제어할 수 있다.

**환경 및 로봇 설정.** 우리 환경은 작은 개체(용기, 장난감 등)가 있는 테이블탑과 진공 그리퍼 및 손목 장착 RGB-D 카메라가 장착된 UR5 로봇 암입니다. 실험을 위해 사용 가능한 인식 API는 손목 카메라로부터 검출된 객체(확률, 레이블, 경계 상자 및 분할 마스크) 목록을 반환하는 detect_objects()이다. 이 API는 먼저 개체 목록을 GPT-4V [27]에 쿼리한 다음, Grounding-SAM [15, 20]을 사용하여 개체를 로컬화하는 방식으로 구현됩니다. 사용 가능한 제어 API는 pick_place(obj1, obj2)로 obj1을 픽업하여 obj2 위에 배치하는 스크립티드 프리미티브 스킬입니다. 또한 로봇이 사용자와 통신할 수 있도록 하는 텍스트 음성 변환 API say(문장)도 있습니다.

**결과.** 의미론적 추론을 포함 하는 여러 테이블 탑 픽 앤 플레이스 로봇 작업으로 평가 합니다. 이러한 작업은 섹션 A.4에 나열 됩니다. 몇 번의 시작 프롬프트가 있는 경우 언어 모델이 예상 된 구조 및 사용 가능한 로봇 Api를 이해 하도록 한 예가 (음식 제공 문제의) 컨텍스트로 제공 됩니다. 이 단일 예로부터, 우리는 우리의 모델이 새로운 객체들, 언어들 및 태스크 도메인들로 일반화될 수 있다는 것을 알 수 있다(도 7의 예시 궤적 및 도 A3 참조). 이러한 로보틱스 태스크의 경우, 이전 언어 추론 태스크와 달리, 이 코드는 파이썬 인터프리터 실행(로봇 API)과 LMulator(commonsense QA like is_compostable) 사이의 라인별 상호 작용을 필요로 하기 때문에, 우리의 주요 방법 CoC(Interweave)가 유일한 가능한 접근법이다.

그림 7 | 작업에 대한 로봇 궤적 시각화 "테이블의 개체를 퇴비 통과 재활용 통으로 정렬"합니다. CoC는 먼저 문제를 해결하기 위한 코드를 생성한 다음, 가능한 경우 Python(예: detect_objects 및 pick_place와 같은 로봇 API)으로 코드를 실행하고, 그렇지 않은 경우 LMulator(예: is_compostable과 같은 상식 QA)로 코드를 실행합니다. 로봇은 포스트잇 노트를 재활용 통에, 오렌지 껍질을 퇴비 통에 성공적으로 선택하여 배치합니다. 그림의 전체 코드를 참조하십시오. A3 및 웹 페이지의 롤아웃 비디오 [https://chain-of-code.github.io/](https://chain-of-code.github.io/)입니다.

\begin{table}
\begin{tabular}{c c c c c c c c} \hline \hline text-davinci-003 & \multicolumn{4}{c}{gpt-3.5-turbo} & \multicolumn{4}{c}{gpt-4} \\ \hline CoC & Direct & CoT & CoC & CoC & Direct & CoT & CoC & CoC \\ (Interweave) & & & (Python) & (LM) & & & (Python) & (LM) \\ \hline
84 & 51 (-33) & 56 (-28) & 56 (-28) & 45 (-39) & 70 (-14) & 78 (-6) & 82 (-2) & 75 (-9) \\ \hline \hline \end{tabular}
\end{table}
표 3: 툴 사용 유무에 관계없이 채팅 인터페이스에서 명령어 튜닝된 모델과의 비교.

도 7: 작업에 대한 로봇 궤적 시각화 "테이블 상의 객체들을 퇴비통 및 재활용통으로 정렬" CoC는 먼저 문제를 해결하기 위한 코드를 생성한 다음, 가능한 경우 Python(예: detect_objects 및 pick_place와 같은 로봇 API)으로 코드를 실행하고, 그렇지 않은 경우 LMulator(예: is_compostable과 같은 상식 QA)로 코드를 실행합니다. 로봇은 포스트잇 노트를 재활용 통에, 오렌지 껍질을 퇴비 통에 성공적으로 선택하여 배치합니다. 그림의 전체 코드를 참조하십시오. A3 및 웹 페이지의 롤아웃 비디오 [https://chain-of-code.github.io/](https://chain-of-code.github.io/)입니다.

## 5 관련 작업

**언어 모델 추론** 언어 모델의 능력 및 응용 프로그램은 전체 성능 [6; 11; 31; 37] 및 몇 발 프롬프트 [3] 및 추상 추론 [42]과 같은 비상 기능 [41]으로 인해 상당한 진전을 보였습니다. 아마도 이 작업과 가장 관련이 있는 많은 작업들은 추론을 개선하기 위한 재촉을 활용했다[8]: Chain of Thought[42]는 작업을 중간 추론 단계로 분해할 것을 제안하며, least-to-most[48]는 점점 더 간단한 일련의 문제를 제안하며, ScratchPad[26]는 코드를 해석하기 위한 중간 결과의 흔적을 유지할 것을 제안한다(이것은 먼저 우리의 LMulator에 필요한 LM의 코드 시뮬레이션 능력을 입증했다). 이러한 대사를 따라 "차근차근 생각해보자"[16]은 몇 개의 핵심 단어를 사용하여 그러한 분해(양등[43]에서 나중에 "심호흡을 하고 이 문제에 대해 단계적으로 작업"하도록 정제된 단어)를 이끌어낸다. 이 외에도 다른 접근법은 이러한 단계별 솔루션을 그래픽 구조[2; 45], 계획[25; 39], 또는 전문가 기반 샘플링[40; 49]의 혼합으로 구조화한다. CoC는 _code_가 문제를 자연어만을 넘어 많은 이점을 가진 하위 단계로 분해하기 위한 형식적이고 구조화된 접근법이라는 관찰과 함께 이러한 작업의 직관을 기반으로 한다.

**언어 모델 도구 사용** 최근 많은 작업에서 도구를 사용하여 쿼리에 응답하는 언어 모델에 대한 기술을 제안했습니다. [21]. 이러한 도구는 종종 [6; 7; 9; 14; 44] 프롬프트를 통해 언어 모델에 제공되어 수학 문제, 코드 해석기, 데이터베이스 또는 그 이상을 위한 계산기와 같은 도구를 가능하게 한다. 이러한 도구들 역시 새로운 양식에 대한 피드백을 제공할 수 있다[35; 46]. 사용 가능한 도구의 범위를 확장하기 위해 다른 사람들은 외부 도구 데이터베이스 또는 미세 조정된 언어 모델을 사용했다[28; 29; 30; 32]. 도구 인터페이스가 다양함에 따라, 도구로부터의 피드백도 성능을 향상시킬 수 있다[13; 47]. 본 연구에서는 풀코드의 표현성과 일반성, 그리고 구조를 도구와 프레임워크로 취급하여 활용한다.

**언어 모델 프로그램 합성** 언어 모델을 코드화하는 기능은 잘 알려져 있으며 프로그래밍 보조자로 적용되었으며 자체적으로 프로그래머가 가능한 것으로 나타났습니다. [1; 18; 24]. 이러한 능력은 로보틱스[19; 33], 구체화된 에이전트[38], 또는 비전[35]과 같은 새로운 설정에서 코드를 통해 추론하는 능력을 활용하여 언어 이외의 다양한 작업에만 적용되었다. 다른 사람들은 수치 추론 문제를 해결하기 위한 코드를 생성하는 프로그램 오브 사상[5] 및 프로그램 지원 언어 모델[10]과 같은 추론을 위해 특별히 그렇게 했다. 여기서는 코드 쓰기, 실행 코드, 코드를 시뮬레이션하는 언어 모델 간의 상호 작용에 초점을 맞추어 시맨틱 추론과 같은 언어 모델 코드 응용 프로그램의 새로운 체제를 가능하게 한다.

## 6 결론, 제한 사항 및 향후 작업

우리는 코드 작성을 통해 언어 모델을 사용하여 추론하고 코드가 실행 가능하지 않은 경우 인터프리터를 사용하거나 실행을 시뮬레이션하는 언어 모델(여기서는 LMulator로 명명됨)을 사용하여 코드를 실행하는 방법인 Code Chain of Code를 제안했다. 따라서 CoC는 코드의 표현 구조와 사용 가능한 강력한 도구를 모두 활용할 수 있습니다. 이를 넘어서, 실행 불가능한 코드의 실행을 시뮬레이션함으로써, CoC는 명목상 코드의 범위 밖의 문제들(예를 들어, 의미론적 추론 문제들)에 적용될 수 있다. 우리는 이 접근법이 다양한 도전적인 언어 및 숫자 추론 문제에서 기준선 및 일부 작업의 경우 최고의 인간 평가자보다 우수하다는 것을 입증했다.

이 일은 한계가 없는 것은 아니다. 첫째, 인터위빙 코드와 언어 실행뿐만 아니라 두 단계로 생성하여 실행하려면 추가적인 컨텍스트 길이와 계산 시간이 필요하다. 둘째, 집합에서 의미적 태스크에 대한 성능 손실은 볼 수 없었지만, 이름에 대한 편집이 유머러스한지 묻는 태스크인 Ruin Names와 같이 코드가 도움이 되지 않는 태스크는 거의 없다. 마지막으로, 문자열의 프로그램 상태를 추적하고 문자열을 파이썬의 기본 데이터 유형(예: dict, tuple)으로 구문 분석할 수 있는 LM 및 코드 간 구현이 매우 간단하다. 현재 우리의 방법은 코드 실행을 시뮬레이션하는 동안 LM은 사용자 지정 파이썬 개체를 수정할 수 없다. 이론적으로, 그러나, 이러한 파이썬 객체 각각이 예를 들어 프로토콜 버퍼와 같은 기술을 사용하는 직렬화 및 역직렬화 방법을 갖는 한 실행 가능하다.

CoC와의 향후 작업을 위한 많은 방법이 있습니다. 첫째, 통일된 코드와 언어 해석자는 언어 모델의 상식과 코드의 분석 능력, 구조 및 해석 가능성을 잘 결합한다고 믿는다. 따라서 이러한 기술은 단순한 추론을 넘어 새로운 문제 체제에 코드 및 코드 유사 추론의 적용을 가능하게 할 수 있다. 둘째, 언어 모델을 LMulator로 미세 조정하는 것이 의미 코드 추론에 도움이 될 수 있는 정도를 조사하는 데 관심이 있다. 셋째, 우리는 많은 경로를 통한 추론이 개선을 낳는다는 증거를 볼 수 있으며, 이는 유망한 진전이다. 마지막으로, 우리는 코드와의 이러한 통합이 비전 또는 데이터베이스와 같은 외부 모달리티에 대한 액세스를 가능하게 하고, 새로운 애플리케이션(예를 들어, 로봇 공학, 증강 현실)에 대한 흥미로운 경로를 나타낸다고 믿는다.

## References

* Austin et al. [2021] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, et al. Program synthesis with large language models. _arXiv preprint arXiv:2108.07732_, 2021.
* Besta et al. [2023] Maciej Besta, Nils Bloch, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, et al. Graph of thoughts: Solving elaborate problems with large language models. _arXiv preprint arXiv:2308.09687_, 2023.
* Brown et al. [2020] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. _Advances in neural information processing systems_, 33:1877-1901, 2020.
* Chen et al. [2021] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. _arXiv preprint arXiv:2107.03374_, 2021.
* Chen et al. [2022] Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen. Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. _arXiv preprint arXiv:2211.12588_, 2022.
* Chowdhery et al. [2022] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. _arXiv preprint arXiv:2204.02311_, 2022.
* Cobbe et al. [2021] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to solve math word problems. _arXiv preprint arXiv:2110.14168_, 2021.
* Dohan et al. [2022] David Dohan, Winnie Xu, Aitor Lewkowycz, Jacob Austin, David Bieber, Raphael Gontijo Lopes, Yuhuai Wu, Henryk Michalewski, Rif A Saurous, Jascha Sohl-Dickstein, et al. Language model cascades. _arXiv preprint arXiv:2207.10342_, 2022.
* Drori et al. [2022] Iddo Drori, Sarah Zhang, Reece Shuttleworth, Leonard Tang, Albert Lu, Elizabeth Ke, Kevin Liu, Linda Chen, Sunny Tran, Newman Cheng, et al. A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level. _Proceedings of the National Academy of Sciences_, 119(32):e2123433119, 2022.
* Gao et al. [2023] Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and Graham Neubig. Pal: Program-aided language models. In _International Conference on Machine Learning_, pp. 10764-10799. PMLR, 2023.

* [11] Google Gemini Team. Gemini: A family of highly capable multimodal models. 2023. URL [https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf](https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf).
* [12] Google, Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos, Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. Palm 2 technical report. _arXiv preprint arXiv:2305.10403_, 2023.
* [13] Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, and Weizhu Chen. Critic: Large language models can self-correct with tool-interactive critiquing. _arXiv preprint arXiv:2305.11738_, 2023.
* [14] Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish Sabharwal. Decomposed prompting: A modular approach for solving complex tasks. _arXiv preprint arXiv:2210.02406_, 2022.
* [15] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Dollar, and Ross Girshick. Segment anything. _arXiv:2304.02643_, 2023.
* [16] Takeshi Kojima, Shixiang Shane Gu, Michel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. _Advances in neural information processing systems_, 35:22199-22213, 2022.
* [17] Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et al. Solving quantitative reasoning problems with language models, 2022. 2022. URL [https://arxiv.org/abs/2206.14858](https://arxiv.org/abs/2206.14858).
* [18] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Remi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation with alphacode. _Science_, 378(6624):1092-1097, 2022.
* [19] Jacky Liang, Wenlong Huang, Fei Xia, Peng Xu, Karol Hausman, Brian Ichter, Pete Florence, and Andy Zeng. Code as policies: Language model programs for embodied control. In _2023 IEEE International Conference on Robotics and Automation (ICRA)_, pp. 9493-9500. IEEE, 2023.
* [20] Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang, Chunyuan Li, Jianwei Yang, Hang Su, Jun Zhu, et al. Grounding dino: Marrying dino with grounded pre-training for open-set object detection. _arXiv preprint arXiv:2303.05499_, 2023.
* [21] Gregoire Mialon, Roberto Dessi, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Roziere, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al. Augmented language models: a survey. _arXiv preprint arXiv:2302.07842_, 2023.
* [22] Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, and Luke Zettlemoyer. Rethinking the role of demonstrations: What makes in-context learning work? _arXiv preprint arXiv:2202.12837_, 2022.
* [23] Suvir Mirchandani, Fei Xia, Pete Florence, Brian Ichter, Danny Driess, Montserrat Gonzalez Arenas, Kanishka Rao, Dorsa Sadigh, and Andy Zeng. Large language models as general pattern machines. _arXiv preprint arXiv:2307.04721_, 2023.
* [24] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou, Silvio Savarese, and Caiming Xiong. Codegen: An open large language model for code with multi-turn program synthesis. _arXiv preprint arXiv:2203.13474_, 2022.
* [25] Xuefei Ning, Zinan Lin, Zixuan Zhou, Huazhong Yang, and Yu Wang. Skeleton-of-thought: Large language models can do parallel decoding. _arXiv preprint arXiv:2307.15337_, 2023.
* [26] Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin,David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. Show your work: Scratchpads for intermediate computation with language models. _arXiv preprint arXiv:2112.00114_, 2021.
* [27] OpenAI. Gpt-4 technical report, 2023.
* [28] Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, and Marco Tulio Ribeiro. Art: Automatic multi-step reasoning and tool-use for large language models. _arXiv preprint arXiv:2303.09014_, 2023.
* [29] Aaron Parisi, Yao Zhao, and Noah Fiedel. Talm: Tool augmented language models. _arXiv preprint arXiv:2205.12255_, 2022.
* [30] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, et al. ToollIm: Facilitating large language models to master \(16000+\) real-world apis. _arXiv preprint arXiv:2307.16789_, 2023.
* [31] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. _OpenAI blog_, 1(8):9, 2019.
* [32] Timo Schick, Jane Dwivedi-Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. _arXiv preprint arXiv:2302.04761_, 2023.
* [33] Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox, Jesse Thomason, and Animesh Garg. Progprompt: Generating situated robot task plans using large language models. In _2023 IEEE International Conference on Robotics and Automation (ICRA)_, pp. 11523-11530. IEEE, 2023.
* [34] Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta, Adria Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. _arXiv preprint arXiv:2206.04615_, 2022.
* [35] Didac Suris, Sachit Menon, and Carl Vondrick. Vipergpt: Visual inference via python execution for reasoning. _arXiv preprint arXiv:2303.08128_, 2023.
* [36] Mirac Suzgun, Nathan Scales, Nathanael Scharli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny Zhou, et al. Challenging big-bench tasks and whether chain-of-thought can solve them. _arXiv preprint arXiv:2210.09261_, 2022.
* [37] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. _arXiv preprint arXiv:2302.13971_, 2023.
* [38] Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, and Anima Anandkumar. Voyager: An open-ended embodied agent with large language models. _arXiv preprint arXiv:2305.16291_, 2023.
* [39] Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim. Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models. _arXiv preprint arXiv:2305.04091_, 2023.
* [40] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. _arXiv preprint arXiv:2203.11171_, 2022.
* [41] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al. Emergent abilities of large language models. _arXiv preprint arXiv:2206.07682_, 2022.

* [42] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. _Advances in Neural Information Processing Systems_, 35:24824-24837, 2022.
* [43] Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou, and Xinyun Chen. Large language models as optimizers. _arXiv preprint arXiv:2309.03409_, 2023.
* [44] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. Recat: Synergizing reasoning and acting in language models. _arXiv preprint arXiv:2210.03629_, 2022.
* [45] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. _arXiv preprint arXiv:2305.10601_, 2023.
* [46] Andy Zeng, Maria Attarian, Brian Ichter, Krzysztof Choromanski, Adrian Wong, Stefan Welker, Federico Tombari, Aveek Purohit, Michael Ryoo, Vikas Sindhwani, et al. Socratic models: Composing zero-shot multimodal reasoning with language. _arXiv preprint arXiv:2204.00598_, 2022.
* [47] Aojun Zhou, Ke Wang, Zimu Lu, Weikang Shi, Sichun Luo, Zipeng Qin, Shaoqing Lu, Anya Jia, Linqi Song, Mingjie Zhan, et al. Solving challenging math word problems using gpt-4 code interpreter with code-based self-verification. _arXiv preprint arXiv:2308.07921_, 2023.
* [48] Denny Zhou, Nathanael Scharli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, et al. Least-to-most prompting enables complex reasoning in large language models. _arXiv preprint arXiv:2205.10625_, 2022.
* [49] Yanqi Zhou, Tao Lei, Hanxiao Liu, Nan Du, Yanping Huang, Vincent Zhao, Andrew M Dai, Quoc V Le, James Laudon, et al. Mixture-of-experts with expert choice routing. _Advances in Neural Information Processing Systems_, 35:7103-7114, 2022.

[MISSING_PAGE_FAIL:16]

### GSM8K 벤치마크에 대한 정량적 결과

표 A2는 학년-학교 수학 벤치마크(GSM8K)[7]에서 직접 프롬프트, 사상의 사슬, 코드의 사슬에 대한 결과를 보여준다. 우리는 CoC가 일반적으로 CoT 및 Direct 프롬프팅보다 성능이 우수하다는 것을 발견했다. 이러한 작업은 주로 알고리즘적이며 파이썬 단독으로 해결되기 때문에 파이썬을 사용하는 모든 코드 체인 변형은 동일한 성능 - 또한 사상의 프로그램에 나타난 동일한 성능을 달성한다[5].

### 언어 추론 작업에 대한 정성적 결과

그림 A1은 BBH(B BIG-Bench Hard)의 몇 가지 추론 작업에 대한 모델 출력을 보여주고 그림 A2는 날짜 추론의 예시적인 예를 보여준다. 이러한 예들은 파이썬 인터프리터와 LMulator의 인터위빙 실행을 강조하기 위해 선택된다.

### 로봇 작업 결과

몇 번의 프롬프트의 경우 "사용자의 식이 제한에 따른 식사를 제공"이라는 단일 예가 포함된다. 테스트 시간 동안 다음 각 지침을 사용하여 모델을 쿼리합니다.

* "완전 채식 식단을 하는 사람을 위해 도시락을 싸세요."
* "채식주의자를 위한 샌드위치를 조립하세요."
* "접시에 땅콩 버터 샌드위치 재료를 모아라."
* "Prepare in the pot." (interleaving English and Chinese on purpose)
* "종이로 만든 모든 개체를 잔디색 컨테이너에 배치합니다."
* "테이블의 개체를 퇴비 통과 재활용 통으로 정렬합니다."
* "스테이크가 너무 싱거워요. 도와주시겠어요?"

그림 A3은 모델 출력뿐만 아니라 원샷 프롬프트를 보여주고 몇 가지 테스트 지침에 대해 실행되는 방법을 보여준다.

그림 A1 | 모델은 BIG-Bench Hard (BBH)에서 몇 가지 추론 작업에 대해 출력 합니다. 우리는 CoC가 의미 추론과 숫자 추론을 모두 포함하는 매우 다양한 복잡한 추론 작업에 적용될 수 있음을 관찰한다. 레드 하이라이트는 파이썬 인터프리터에 의해 실행되고 있는 LM 생성 코드를 나타내고, 퍼플 하이라이트는 코드 실행을 시뮬레이션하는 LM을 나타낸다.

그림 A2 | Chain of Code가 LM 강화 코드 에뮬레이터를 통해 코드 및 이유를 생성하는 방법의 예시적인 예입니다. 파이썬으로 평가한 선은 \(\overline{\text{red}}\)이고 LM으로 평가한 선은 \(\overline{\text{purple}}\)이다. 2023년 10월 gpt-4를 이용하여 사고 연쇄와 직접 답을 평가하였으며, 이 문제를 해결하기 위해 현재 모델(2023년 12월 기준)은 코드를 작성하고 코드 연쇄와 동일한 해를 얻는다.

(a) 주어진 프롬프트

(a: 사용자의 식이 제한에 따른 식사를 제공함).

restriction: r report(Tob 식이 제한이 있나요?)

... obs: = r robot:detect_objects()

container_obj:=None

forobj in obj:

1s_match_description = match_description(obj, "food container", ret_type=bool")

if is_match_description:

container_obj = obj:

break

if container_obj is None:

robot:say("No food container found.")

else:

forobj in obj:

if obj = container_obj:

continue

is_follow_restrictions = follow_restrictions(obj, restrictions, ret_type=bool)

if is_follow_restrictions:

robot_object_places(obj, container_obj)

(c) 신규 과제

(d: Prover "HT")((tit-fried tomato and eggs)).

성분 ("HT")( "HT")( "HT")( "그라운드", "에그")

... obs: = r robot:detect_object()

pot_obj = None

forobj in obj:

Is_match_description = match_description(obj), "cooking pot", ret_type=bool")

if is_match_description:

pot_obj = obj:

break

if pot_obj is None:

robot_say("No cooking pot found.")

else:

for ingredients in ingredients:

for obj in obj:

Is_match_description = match_description(obj, "good", ret_type=bool")

if is_match_description:

robot_pick_place(obj, pot_obj)

그림 A3 | 로봇 작업에 대 한 몇 가지 테스트 지침에 대 한 단일 샷 프롬프트와 모델이 출력 됩니다. 프롬프트 (a)에 하나의 예제가 주어졌을 때, 우리의 방법은 (b-d)를 새로운 객체, 언어 및 작업 영역으로 일반화할 수 있다. 레드 하이라이트는 파이썬 인터프리터에 의해 실행되고 있는 LM 생성 코드를 나타내고, 퍼플 하이라이트는 코드 실행을 시뮬레이션하는 LM을 나타낸다. 회색 텍스트는 설명 목적으로만 사용되며 당사 모델에는 제공되지 않습니다. 로봇 형식의 코드:<func name>는 로봇 Api를 호출 합니다.

그림 A4 | 그림에서 사용된 전체 질문. 1

제가 가본 나라는 몇 개입니까? 나는 뭄바이, 런던, 워싱턴, 그랜드 캐니언, 볼티모어, 롱셍, 길림, 베이징, 갈라파고스, 키토, 바르셀로나, 파리, 프라하, 니스, 델리, 아그라, 로마, 피렌체, 아말피, 아테네, 미코즈니코스, 밀라노, 뮌헨, 톰스브루크, 베른, 밀라노, 루큐어, 기멜발트(쉴리소른하인), 상트 모리츠, 상트 페테르부르크, 헬싱키, 암스테르담, Gdansk, 밴쿠버, 앵커리지, 몬트리올, 벨리즈, 아카디아 국립공원, 스톡홀름, 코펜하겐, 도버, 리옹, 마드리드, 툴루즈, 산토리니, 오슬로, 쿠사다시, 소다, 로데스, 탈린, 베니스, 바티칸시티, 나폴리, 케이프타운, 요하네스버그, 아디스아베아, 뉴욕, 필라델피아, 시카고, 세인트루이스, 멤피스, 칠레, 스탠포드, 뉴욕, 필라델피아, 시카고, 솔트레이크시티, 타회 엘리아스 국립공원 보호구역, 애틀랜타, 티라나, 코푸, 시에나
