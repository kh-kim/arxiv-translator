<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2304.08177] Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca</title><meta property="og:description" content="Large Language Models (LLMs), such as ChatGPT and GPT-4, have dramatically transformed natural language processing research and shown promising strides towards Artificial General Intelligence (AGI). Nonetheless, the hi…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2304.08177">

<!--Generated on Thu Feb 29 14:26:10 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yiming Cui 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">ymcui@ieee.org</span> &amp;Ziqing Yang<span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span> 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_typewriter">ziqingyang@gmail.com</span> &amp;Xin Yao 
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">yaoxin94@foxmail.com</span>
</span><span class="ltx_author_notes">Equal contributions.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id4.id1">ChatGPT 및 GPT-4와 같은 대규모 언어 모델(LLM)은 자연어 처리 연구를 극적으로 변형시켰고 인공지능(AGI)을 향한 유망한 진보를 보여주었다. 그럼에도 불구하고 LLM 교육 및 배치와 관련된 높은 비용은 투명하고 접근 가능한 학술 연구에 상당한 장애물을 제시한다. LLaMA와 같은 여러 대형 언어 모델이 커뮤니티에 의해 공개되었지만, 이들은 주로 영어 코퍼라에 중점을 두어 다른 언어에 대한 유용성을 제한한다. 본 논문에서는 중국어 텍스트를 이해하고 생성할 수 있는 능력과 명령어를 따를 수 있는 능력을 갖춘 LLaMA를 증강하는 방법을 제안한다. 이를 위해 LLaMA의 기존 어휘를 추가로 2만 개의 중국어 토큰으로 확장하여 중국어에 대한 인코딩 효율성과 의미적 이해를 높인다. 또한 중국어 데이터를 사용한 2차 사전 훈련을 통합하고 중국어 명령어 데이터 세트로 모델을 미세 조정함으로써 모델의 명령어 이해 및 실행 능력을 크게 향상시킨다. 우리의 실험 결과는 새로 제안된 모델이 원래 LLaMA의 중국어 콘텐츠 이해 및 생성 능력을 현저하게 향상시킨다는 것을 나타낸다. 또한, C-Eval 데이터 세트에 대한 결과는 우리 모델의 몇 배 크기를 가진 모델 간의 경쟁 성능을 산출한다. 우리는 미리 훈련된 모델, 훈련 스크립트 및 기타 리소스를 깃허브를 통해 사용할 수 있도록 하여 커뮤니티를 위한 개방형 연구를 촉진했다. <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>GitHub repository: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ymcui/Chinese-LLaMA-Alpaca" target="_blank" title="">https://github.com/ymcui/Chinese-LLaMA-Alpaca</a></span></span></span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.p1.1">자연어 처리(Natural Language Processing, NLP) 분야는 대규모 언어 모델(Large Language Models, LLM)의 등장으로 실질적인 패러다임의 변화를 목격하고 있다. 상당한 크기와 포괄적인 훈련 데이터로 구별되는 이러한 모델은 인간과 같은 텍스트를 이해하고 생성하는 데 탁월한 능력을 보여주었다. BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al., <a class="ltx_ref" href="#bib.bib5" title="">2019</a>)</cite>와 같은 텍스트 이해 전용 사전 훈련 언어 모델과 달리 GPT 시리즈 <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="#bib.bib17" title="">2018</a>)</cite>는 텍스트 생성을 강조하여 상대방에 비해 창의성에 더 적합한 플랫폼으로 위치시킨다. 특히, GPT 계열의 최신 구성체, 즉 ChatGPT 및 GPT-4는 빠르게 진화하는 이 분야에서 선도적인 예로 자리매김하면서 상당한 관심을 받았다.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.p2.1">InstructGPT <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="#bib.bib16" title="">2022</a>)</cite>에서 진화한 ChatGPT <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="#bib.bib14" title="">2022</a>)</cite>는 상황 인식, 인간과 같은 상호작용을 수행할 수 있는 고급 대화형 AI 모델 역할을 한다. 그 성공은 보다 정교한 LLM인 GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="#bib.bib15" title="">2023</a>)</cite>의 개발을 위한 발판을 마련했으며, 특히 멀티모달 및 추론 능력에 대한 자연어 이해, 생성 및 다양한 NLP 작업에서 훨씬 더 큰 잠재력을 보여준다. 이러한 모델은 새로운 연구 방향과 응용을 촉진하여 인공지능(AGI)의 잠재력을 탐구하는 데 관심을 강화했다. 여러 벤치마크에서 인상적인 성능을 보여주면서 적은 샷 학습과 새로운 작업에 대한 적응 능력을 보여 NLP 연구의 확장을 크게 견인했다. 결과적으로, 그들은 연구자와 업계 전문가 모두에게 감성 분석, 기계 번역, 질의 응답 시스템 등을 포함한 광범위한 응용 분야에서 잠재력을 더욱 활용할 수 있도록 영감을 주었습니다.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.p3.1">그러나 LLM만큼 영향력 있는 구현은 투명하고 열린 연구를 방해하는 내재적 한계를 가지고 있다. 주요 관심사는 모델에 대한 접근을 제한하여 성공을 기반으로 하는 광범위한 연구 커뮤니티의 능력을 억제하는 독점적 특성이다. 또한 이러한 모델을 훈련하고 배포하는 데 필요한 방대한 계산 리소스는 제한된 리소스를 가진 연구자에게 어려움을 제공하여 접근성 문제를 더욱 복잡하게 만든다.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.p4.1">이러한 한계를 해결하기 위해 NLP 연구 커뮤니티는 더 큰 투명성과 협력을 촉진하기 위해 오픈 소스 대안에 끌렸다. LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="#bib.bib24" title="">2023</a>)</cite>와 Alpaca <cite class="ltx_cite ltx_citemacro_citep">(Taori et al., <a class="ltx_ref" href="#bib.bib22" title="">2023a</a>)</cite>는 이러한 이니셔티브의 주목할 만한 예로 작용한다. 이러한 오픈 소스 LLM은 학술 연구를 촉진하고 NLP 분야 내에서 진전을 가속화하기 위한 것이다. 이러한 모델을 오픈 소싱하는 목적은 모델 개발, 미세 조정 및 평가의 추가 발전에 도움이 되는 환경을 조성하여 궁극적으로 다양한 용도에 적용할 수 있는 강력하고 능력 있는 LLM을 만드는 것이다.</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.p5.1">LLaMA와 Alpaca가 NLP에서 상당한 진전을 이루었음에도 불구하고 중국어 작업에 대한 모국어 지원과 관련하여 고유한 한계를 나타낸다. 그들의 어휘는 수백 개의 중국어 토큰만을 포함하고 있어 중국어 텍스트의 인코딩과 디코딩의 효율성을 상당히 저해하고 있다. 이 기술 보고서에서는 중국 BERT 시리즈 <cite class="ltx_cite ltx_citemacro_citep">(Cui et al., <a class="ltx_ref" href="#bib.bib2" title="">2021</a>)</cite>와 중국 소수자 중심의 다국어 사전 학습 모델 <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a class="ltx_ref" href="#bib.bib28" title="">2022</a>)</cite>를 기반으로 중국 콘텐츠를 이해하고 생성할 수 있는 기능이 강화된 중국 LLaMA 및 Alpaca 모델의 개발을 제안한다. 우리는 원래 LLaMA의 어휘를 추가로 2만 개의 중국어 토큰으로 확장하여 중국어 텍스트의 처리 및 생성 능력을 크게 향상시킵니다. 이러한 모델의 효율적인 훈련과 배치를 보장하기 위해 LoRA(Low-Rank Adaptation) 접근법 <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="#bib.bib8" title="">2021</a>)</cite>를 사용하여 과도한 계산 비용 없이 모델을 훈련하고 미세 조정할 수 있다. 우리는 LLaMA와 Alpaca의 중국어 이해와 생성 능력을 향상시키기 위한 예비 연구가 이러한 모델을 다른 언어에 적용하는 것을 목표로 하는 연구자들의 토대가 될 것으로 기대한다. 본 논문에서는 다양한 언어에서 LLaMA와 Alpaca 모델의 어휘 확장과 성능 향상을 위해 사용될 수 있는 통찰력과 방법론을 제시한다. 요약하면, 본 기술보고서의 기여는 다음과 같다:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i1.p1.1">우리는 2만 개의 중국어 토큰으로 원래 LLaMA의 어휘를 확장하여 중국어의 인코딩과 디코딩 효율을 높이고 LLaMA의 중국어 이해 능력을 향상시킨다.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i2.p1.1">우리는 중국 LLaMA 및 Alpaca 모델의 효율적인 훈련 및 배치를 용이하게 하기 위해 LoRA(Low-Rank Adaptation) 접근법을 사용하여 연구자들이 과도한 계산 비용을 초래하지 않고 이러한 모델을 사용할 수 있도록 한다.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i3.p1.1">본 논문에서 제안한 LLaMA와 Alpaca 모델들은 명령어 수행과 자연어 이해 과제에 대한 성능을 평가함으로써, 중국어 과제의 맥락에서 기존 모델들에 비해 상당한 개선점을 보여준다.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.I1.i4.p1.1">우리는 연구의 자원과 결과를 공개적으로 이용 가능하게 하여 NLP 커뮤니티에서 추가 연구 및 협력을 촉진하고 LLaMA 및 알파카 모델을 다른 언어에 적응하도록 장려한다.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Chinese LLaMA and Chinese Alpaca</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>LLaMA</h3>

<div id="S2.SS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.p1.1">LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="#bib.bib24" title="">2023</a>)</cite>는 트랜스포머 아키텍처 <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="#bib.bib25" title="">2017</a>)</cite>에 구축된 기본 디코더 전용 대형 언어 모델이다. GPT 시리즈 및 다른 변압기 기반 LLM과 유사하게 LLaMA는 임베딩 레이어, 다중 변압기 블록 및 언어 모델 헤드로 구성된다. LLaMA는 또한 사전 정규화 <cite class="ltx_cite ltx_citemacro_citep">(Zhang &amp; Sennrich, <a class="ltx_ref" href="#bib.bib30" title="">2019</a>)</cite>, SwiGLU 활성화 <cite class="ltx_cite ltx_citemacro_citep">(Shazeer, <a class="ltx_ref" href="#bib.bib20" title="">2020</a>)</cite>, 회전 임베딩 <cite class="ltx_cite ltx_citemacro_citep">(Su et al., <a class="ltx_ref" href="#bib.bib21" title="">2021</a>)</cite>와 같은 다른 모델에서 활용되는 개선 사항을 통합한다. LLaMA는 7B, 13B, 33B 및 65B의 4가지 다른 모델 크기로 제공됩니다.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.p2.1">LLaMA는 크롤링된 웹 페이지, 책, 위키피디아 및 사전 인쇄 논문과 같은 공개적으로 이용 가능한 소스의 혼합을 사용하여 표준 언어 모델링 작업(섹션 <a class="ltx_ref" href="#S2.SS4" title="2.4 Pre-Training Objective ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">2.4</span></a> 참조)으로 사전 훈련되었다. 실험 결과는 LLaMA가 더 작은 모델 크기이지만 GPT-3와 같은 다른 LLM에 비해 경쟁 성능을 제공한다는 것을 보여준다. 이러한 압축성과 효과는 연구자들의 상당한 관심을 받아 LLaMA 기반 모델의 광범위한 사용으로 이어졌다.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Chinese Vocabulary Extension</h3>

<div id="S2.SS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p1.1">LLaMA의 훈련 세트는 대략 1.4T 토큰을 포괄하며, 라틴어 또는 키릴어 스크립트 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="#bib.bib24" title="">2023</a>)</cite>를 사용하는 다른 유럽 언어에서는 대다수가 영어로, 소수이다. 따라서 LLaMA는 대부분 유럽 언어로 입증된 다국어 및 교차 언어 이해 능력을 가지고 있다. 흥미로운 사실은 우리의 이전 예비 연구는 LLaMA가 중국 텍스트를 생성하는 능력은 제한적이지만 기본적인 중국 이해 능력을 나타낸다는 것을 보여준다.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p2.1">LLaMA에 중국어 이해와 생성 능력을 향상시키기 위해, 우리는 중국어 말뭉치로 LLaMA 모델을 계속 사전 훈련할 것을 제안한다. 그러나 중국 코퍼라와의 지속적인 사전 교육을 직접 적용하는 것은 여러 가지 어려움에 직면한다. 첫째, 원본 LLaMA 어휘는 1,000자 미만의 한자를 다루고 있어 일반적인 한자 텍스트를 인코딩하기에는 부족하다. LLaMA 토큰화기는 알려지지 않은 UTF-8 문자를 바이트로 토큰화함으로써 이 문제를 우회하지만, 이 전략은 각 한자가 3-4 바이트 토큰으로 분할되기 때문에 시퀀스 길이를 상당히 확장하고 중국 텍스트의 인코딩 및 디코딩 효율을 늦춘다. 둘째, 바이트 토큰은 한자를 나타내기 위해 독점적으로 설계되지 않는다. 바이트 토큰은 다른 언어의 UTF-8 토큰도 의미하기 때문에 바이트 토큰과 변환기 인코더가 한자의 의미 의미를 포착하는 표현을 효과적으로 학습하는 것이 어려워진다.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p3.1">이러한 문제를 해결하고 인코딩 효율을 향상시키기 위해 중국어 토큰이 추가된 LLaMA 어휘를 확장하고 확장 어휘 <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a class="ltx_ref" href="#bib.bib28" title="">2022</a>)</cite>에 대한 모델을 적용하는 것을 제안한다. 확장 프로세스는 다음과 같이 진행된다:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i1.p1.1">토큰사이저의 중국어 텍스트에 대한 지원을 강화하기 위해, 우리는 처음에 20,000의 어휘 크기를 가진 중국어 말뭉치<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>The training data is the same as the one for training basic version of our models.</span></span></span>에서 SentencePiece <cite class="ltx_cite ltx_citemacro_citep">(Kudo &amp; Richardson, <a class="ltx_ref" href="#bib.bib11" title="">2018</a>)</cite>로 중국어 토큰사이저를 훈련시켰다.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i2.p1.1">우리는 이후 그들의 어휘의 결합을 취하여 중국식 토큰화기를 원래의 LLaMA 토큰화기로 병합한다. 결과적으로, 우리는 49,953의 어휘 크기를 가진 중국 LLaMA 토큰화기로 불리는 병합된 토큰화기를 얻는다.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.I1.i3.p1.4">LLaMA 모델을 중국어 LLaMA 토큰라이저에 적용하기 위해 단어 임베딩 및 언어 모델 헤드를 모양 <math alttext="V\times H" class="ltx_Math" display="inline" id="S2.I1.i3.p1.1.m1.1"><semantics id="S2.I1.i3.p1.1.m1.1a"><mrow id="S2.I1.i3.p1.1.m1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.cmml"><mi id="S2.I1.i3.p1.1.m1.1.1.2" xref="S2.I1.i3.p1.1.m1.1.1.2.cmml">V</mi><mo id="S2.I1.i3.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.I1.i3.p1.1.m1.1.1.1.cmml">×</mo><mi id="S2.I1.i3.p1.1.m1.1.1.3" xref="S2.I1.i3.p1.1.m1.1.1.3.cmml">H</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.1.m1.1b"><apply id="S2.I1.i3.p1.1.m1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1"><times id="S2.I1.i3.p1.1.m1.1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1.1"></times><ci id="S2.I1.i3.p1.1.m1.1.1.2.cmml" xref="S2.I1.i3.p1.1.m1.1.1.2">𝑉</ci><ci id="S2.I1.i3.p1.1.m1.1.1.3.cmml" xref="S2.I1.i3.p1.1.m1.1.1.3">𝐻</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.1.m1.1c">V\times H</annotation></semantics></math>에서 <math alttext="V^{\prime}\times H" class="ltx_Math" display="inline" id="S2.I1.i3.p1.2.m2.1"><semantics id="S2.I1.i3.p1.2.m2.1a"><mrow id="S2.I1.i3.p1.2.m2.1.1" xref="S2.I1.i3.p1.2.m2.1.1.cmml"><msup id="S2.I1.i3.p1.2.m2.1.1.2" xref="S2.I1.i3.p1.2.m2.1.1.2.cmml"><mi id="S2.I1.i3.p1.2.m2.1.1.2.2" xref="S2.I1.i3.p1.2.m2.1.1.2.2.cmml">V</mi><mo id="S2.I1.i3.p1.2.m2.1.1.2.3" xref="S2.I1.i3.p1.2.m2.1.1.2.3.cmml">′</mo></msup><mo id="S2.I1.i3.p1.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.I1.i3.p1.2.m2.1.1.1.cmml">×</mo><mi id="S2.I1.i3.p1.2.m2.1.1.3" xref="S2.I1.i3.p1.2.m2.1.1.3.cmml">H</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.2.m2.1b"><apply id="S2.I1.i3.p1.2.m2.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1"><times id="S2.I1.i3.p1.2.m2.1.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1.1"></times><apply id="S2.I1.i3.p1.2.m2.1.1.2.cmml" xref="S2.I1.i3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.1.1.2.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1.2">superscript</csymbol><ci id="S2.I1.i3.p1.2.m2.1.1.2.2.cmml" xref="S2.I1.i3.p1.2.m2.1.1.2.2">𝑉</ci><ci id="S2.I1.i3.p1.2.m2.1.1.2.3.cmml" xref="S2.I1.i3.p1.2.m2.1.1.2.3">′</ci></apply><ci id="S2.I1.i3.p1.2.m2.1.1.3.cmml" xref="S2.I1.i3.p1.2.m2.1.1.3">𝐻</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.2.m2.1c">V^{\prime}\times H</annotation></semantics></math>로 크기를 조정하며, 여기서 <math alttext="V=32,000" class="ltx_Math" display="inline" id="S2.I1.i3.p1.3.m3.2"><semantics id="S2.I1.i3.p1.3.m3.2a"><mrow id="S2.I1.i3.p1.3.m3.2.3" xref="S2.I1.i3.p1.3.m3.2.3.cmml"><mi id="S2.I1.i3.p1.3.m3.2.3.2" xref="S2.I1.i3.p1.3.m3.2.3.2.cmml">V</mi><mo id="S2.I1.i3.p1.3.m3.2.3.1" xref="S2.I1.i3.p1.3.m3.2.3.1.cmml">=</mo><mrow id="S2.I1.i3.p1.3.m3.2.3.3.2" xref="S2.I1.i3.p1.3.m3.2.3.3.1.cmml"><mn id="S2.I1.i3.p1.3.m3.1.1" xref="S2.I1.i3.p1.3.m3.1.1.cmml">32</mn><mo id="S2.I1.i3.p1.3.m3.2.3.3.2.1" xref="S2.I1.i3.p1.3.m3.2.3.3.1.cmml">,</mo><mn id="S2.I1.i3.p1.3.m3.2.2" xref="S2.I1.i3.p1.3.m3.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.3.m3.2b"><apply id="S2.I1.i3.p1.3.m3.2.3.cmml" xref="S2.I1.i3.p1.3.m3.2.3"><eq id="S2.I1.i3.p1.3.m3.2.3.1.cmml" xref="S2.I1.i3.p1.3.m3.2.3.1"></eq><ci id="S2.I1.i3.p1.3.m3.2.3.2.cmml" xref="S2.I1.i3.p1.3.m3.2.3.2">𝑉</ci><list id="S2.I1.i3.p1.3.m3.2.3.3.1.cmml" xref="S2.I1.i3.p1.3.m3.2.3.3.2"><cn id="S2.I1.i3.p1.3.m3.1.1.cmml" type="integer" xref="S2.I1.i3.p1.3.m3.1.1">32</cn><cn id="S2.I1.i3.p1.3.m3.2.2.cmml" type="integer" xref="S2.I1.i3.p1.3.m3.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.3.m3.2c">V=32,000</annotation></semantics></math>는 원래 어휘 크기를 나타내고, <math alttext="V^{\prime}=49,953" class="ltx_Math" display="inline" id="S2.I1.i3.p1.4.m4.2"><semantics id="S2.I1.i3.p1.4.m4.2a"><mrow id="S2.I1.i3.p1.4.m4.2.3" xref="S2.I1.i3.p1.4.m4.2.3.cmml"><msup id="S2.I1.i3.p1.4.m4.2.3.2" xref="S2.I1.i3.p1.4.m4.2.3.2.cmml"><mi id="S2.I1.i3.p1.4.m4.2.3.2.2" xref="S2.I1.i3.p1.4.m4.2.3.2.2.cmml">V</mi><mo id="S2.I1.i3.p1.4.m4.2.3.2.3" xref="S2.I1.i3.p1.4.m4.2.3.2.3.cmml">′</mo></msup><mo id="S2.I1.i3.p1.4.m4.2.3.1" xref="S2.I1.i3.p1.4.m4.2.3.1.cmml">=</mo><mrow id="S2.I1.i3.p1.4.m4.2.3.3.2" xref="S2.I1.i3.p1.4.m4.2.3.3.1.cmml"><mn id="S2.I1.i3.p1.4.m4.1.1" xref="S2.I1.i3.p1.4.m4.1.1.cmml">49</mn><mo id="S2.I1.i3.p1.4.m4.2.3.3.2.1" xref="S2.I1.i3.p1.4.m4.2.3.3.1.cmml">,</mo><mn id="S2.I1.i3.p1.4.m4.2.2" xref="S2.I1.i3.p1.4.m4.2.2.cmml">953</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.4.m4.2b"><apply id="S2.I1.i3.p1.4.m4.2.3.cmml" xref="S2.I1.i3.p1.4.m4.2.3"><eq id="S2.I1.i3.p1.4.m4.2.3.1.cmml" xref="S2.I1.i3.p1.4.m4.2.3.1"></eq><apply id="S2.I1.i3.p1.4.m4.2.3.2.cmml" xref="S2.I1.i3.p1.4.m4.2.3.2"><csymbol cd="ambiguous" id="S2.I1.i3.p1.4.m4.2.3.2.1.cmml" xref="S2.I1.i3.p1.4.m4.2.3.2">superscript</csymbol><ci id="S2.I1.i3.p1.4.m4.2.3.2.2.cmml" xref="S2.I1.i3.p1.4.m4.2.3.2.2">𝑉</ci><ci id="S2.I1.i3.p1.4.m4.2.3.2.3.cmml" xref="S2.I1.i3.p1.4.m4.2.3.2.3">′</ci></apply><list id="S2.I1.i3.p1.4.m4.2.3.3.1.cmml" xref="S2.I1.i3.p1.4.m4.2.3.3.2"><cn id="S2.I1.i3.p1.4.m4.1.1.cmml" type="integer" xref="S2.I1.i3.p1.4.m4.1.1">49</cn><cn id="S2.I1.i3.p1.4.m4.2.2.cmml" type="integer" xref="S2.I1.i3.p1.4.m4.2.2">953</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.4.m4.2c">V^{\prime}=49,953</annotation></semantics></math>는 중국어 LLaMA 토큰라이저의 새로운 어휘 크기를 나타낸다. 새로운 행들은 원래의 임베딩 행렬들의 끝에 추가되어, 원래의 어휘 내의 토큰들의 임베딩들이 영향을 받지 않은 채로 유지되는 것을 보장한다.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p4.1">예비 실험에 따르면 중국 LLaMA 토큰화기에서 생성된 토큰의 수는 원래 LLaMA 토큰화기에서 생성된 토큰의 약 절반이다. 표 <a class="ltx_ref" href="#S2.T1" title="Table 1 ‣ 2.2 Chinese Vocabulary Extension ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">1</span></a>는 원래 LLaMA tokenizer와 중국 LLaMA tokenizer의 비교를 제공한다. 도시된 바와 같이, 중국 LLaMA 토큰화기는 원본에 비해 인코딩 길이를 상당히 감소시킨다. 고정 컨텍스트 길이로, 모델은 약 2배 많은 정보를 수용할 수 있고, 생성 속도는 원래의 LLaMA 토크나이저보다 2배 빠르다. 이것은 LLaMA 모델의 중국 이해와 생성 능력을 향상시키는 데 제안된 접근법의 효율성을 강조한다.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 1:</span> 원본 LLaMA와 중국 LLaMA 간의 토큰화기 비교.</figcaption>
<table id="S2.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S2.T1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S2.T1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T1.1.1.2.1" class="ltx_text ltx_font_bold">Length</span></td>
<td id="S2.T1.1.1.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S2.T1.1.1.3.1" class="ltx_text ltx_font_bold">Content</span></td>
</tr>
<tr id="S2.T1.1.2" class="ltx_tr">
<td id="S2.T1.1.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.1.2.1.1" class="ltx_text ltx_font_bold">Original Sentence</span></td>
<td id="S2.T1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">28</td>
<td id="S2.T1.1.2.3" class="ltx_td ltx_align_left ltx_border_t">人工智能是计算机科学、心理学、哲学等学科融合的交叉学科。</td>
</tr>
<tr id="S2.T1.1.3" class="ltx_tr">
<td id="S2.T1.1.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T1.1.3.1.1" class="ltx_text ltx_font_bold">Original Tokenizer</span></td>
<td id="S2.T1.1.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.1.3.2.1" class="ltx_text">35</span></td>
<td id="S2.T1.1.3.3" class="ltx_td ltx_align_left ltx_border_t">
<span id="S2.T1.1.3.3.1" class="ltx_text"></span><span id="S2.T1.1.3.3.2" class="ltx_text">
<span id="S2.T1.1.3.3.2.1" class="ltx_tabular ltx_align_top">
<span id="S2.T1.1.3.3.2.1.1" class="ltx_tr">
<span id="S2.T1.1.3.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">‘_’, ‘人’, ‘工’, ‘智’, ‘能’, ‘是’, ‘计’, ‘算’, ‘机’, ‘科’, ‘学’, ‘、’, ‘心’,</span></span>
<span id="S2.T1.1.3.3.2.1.2" class="ltx_tr">
<span id="S2.T1.1.3.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">‘理’, ‘学’, ‘、’, ‘0xE5’, ‘0x93’, ‘0xB2’, ‘学’, ‘等’, ‘学’, ‘科’, ‘0xE8’,</span></span>
<span id="S2.T1.1.3.3.2.1.3" class="ltx_tr">
<span id="S2.T1.1.3.3.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">‘0x9E’, ‘0x8D’, ‘合’, ‘的’, ‘交’, ‘0xE5’, ‘0x8F’, ‘0x89’, ‘学’, ‘科’, ‘。’</span></span>
</span></span><span id="S2.T1.1.3.3.3" class="ltx_text"></span></td>
</tr>
<tr id="S2.T1.1.4" class="ltx_tr">
<td id="S2.T1.1.4.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="2"><span id="S2.T1.1.4.1.1" class="ltx_text ltx_font_bold">Chinese Tokenizer</span></td>
<td id="S2.T1.1.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="2"><span id="S2.T1.1.4.2.1" class="ltx_text">16</span></td>
<td id="S2.T1.1.4.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S2.T1.1.4.3.1" class="ltx_text"></span><span id="S2.T1.1.4.3.2" class="ltx_text">
<span id="S2.T1.1.4.3.2.1" class="ltx_tabular ltx_align_top">
<span id="S2.T1.1.4.3.2.1.1" class="ltx_tr">
<span id="S2.T1.1.4.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">‘_’, ‘人工智能’, ‘是’, ‘计算机’, ‘科学’, ‘、’, ‘心理学’, ‘、’, ‘哲学’,</span></span>
<span id="S2.T1.1.4.3.2.1.2" class="ltx_tr">
<span id="S2.T1.1.4.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">‘等’,‘学科’, ‘融合’, ‘的’, ‘交叉’, ‘学科’, ‘。’</span></span>
</span></span><span id="S2.T1.1.4.3.3" class="ltx_text"></span></td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Parameter Efficient Fine-Tuning with LoRA</h3>

<div id="S2.SS3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS3.p1.1">LLM의 전체 매개변수를 업데이트하는 기존의 훈련 패러다임은 엄청나게 비싸고 대부분의 실험실이나 회사에 시간이나 비용이 들지 않는다. Low-Rank Adaptation (LoRA) <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="#bib.bib8" title="">2021</a>)</cite>는 훈련 가능한 순위 분해 행렬을 도입하면서 미리 훈련된 모델 가중치를 유지하는 파라미터 효율적인 훈련 방법이다. LoRA는 미리 훈련된 모델 가중치를 동결시키고 훈련 가능한 저순위 매트릭스를 각 레이어에 주입한다. 이 접근법은 총 훈련 가능한 파라미터를 상당히 감소시켜, 훨씬 적은 계산 자원으로 LLM을 훈련시키는 것을 가능하게 한다.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para ltx_noindent">
<p id="S2.SS3.p2.7" class="ltx_p">To be specific, for a linear layer with weight matrix <math id="S2.SS3.p2.1.m1.1" class="ltx_Math" alttext="W_{0}\in\mathbb{R}^{d\times k}" display="inline"><semantics id="S2.SS3.p2.1.m1.1a"><mrow id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml"><msub id="S2.SS3.p2.1.m1.1.1.2" xref="S2.SS3.p2.1.m1.1.1.2.cmml"><mi id="S2.SS3.p2.1.m1.1.1.2.2" xref="S2.SS3.p2.1.m1.1.1.2.2.cmml">W</mi><mn id="S2.SS3.p2.1.m1.1.1.2.3" xref="S2.SS3.p2.1.m1.1.1.2.3.cmml">0</mn></msub><mo id="S2.SS3.p2.1.m1.1.1.1" xref="S2.SS3.p2.1.m1.1.1.1.cmml">∈</mo><msup id="S2.SS3.p2.1.m1.1.1.3" xref="S2.SS3.p2.1.m1.1.1.3.cmml"><mi id="S2.SS3.p2.1.m1.1.1.3.2" xref="S2.SS3.p2.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS3.p2.1.m1.1.1.3.3" xref="S2.SS3.p2.1.m1.1.1.3.3.cmml"><mi id="S2.SS3.p2.1.m1.1.1.3.3.2" xref="S2.SS3.p2.1.m1.1.1.3.3.2.cmml">d</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS3.p2.1.m1.1.1.3.3.1" xref="S2.SS3.p2.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S2.SS3.p2.1.m1.1.1.3.3.3" xref="S2.SS3.p2.1.m1.1.1.3.3.3.cmml">k</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><apply id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1"><in id="S2.SS3.p2.1.m1.1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1.1"></in><apply id="S2.SS3.p2.1.m1.1.1.2.cmml" xref="S2.SS3.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p2.1.m1.1.1.2.1.cmml" xref="S2.SS3.p2.1.m1.1.1.2">subscript</csymbol><ci id="S2.SS3.p2.1.m1.1.1.2.2.cmml" xref="S2.SS3.p2.1.m1.1.1.2.2">𝑊</ci><cn type="integer" id="S2.SS3.p2.1.m1.1.1.2.3.cmml" xref="S2.SS3.p2.1.m1.1.1.2.3">0</cn></apply><apply id="S2.SS3.p2.1.m1.1.1.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p2.1.m1.1.1.3.1.cmml" xref="S2.SS3.p2.1.m1.1.1.3">superscript</csymbol><ci id="S2.SS3.p2.1.m1.1.1.3.2.cmml" xref="S2.SS3.p2.1.m1.1.1.3.2">ℝ</ci><apply id="S2.SS3.p2.1.m1.1.1.3.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3"><times id="S2.SS3.p2.1.m1.1.1.3.3.1.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.1"></times><ci id="S2.SS3.p2.1.m1.1.1.3.3.2.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.2">𝑑</ci><ci id="S2.SS3.p2.1.m1.1.1.3.3.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">W_{0}\in\mathbb{R}^{d\times k}</annotation></semantics></math>, where <math id="S2.SS3.p2.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS3.p2.2.m2.1a"><mi id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.1b"><ci id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.1c">k</annotation></semantics></math> is the input dimension, and <math id="S2.SS3.p2.3.m3.1" class="ltx_Math" alttext="d" display="inline"><semantics id="S2.SS3.p2.3.m3.1a"><mi id="S2.SS3.p2.3.m3.1.1" xref="S2.SS3.p2.3.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.1b"><ci id="S2.SS3.p2.3.m3.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.1c">d</annotation></semantics></math> is the output dimension, LoRA adds two low-rank decomposed trainable matrices <math id="S2.SS3.p2.4.m4.1" class="ltx_Math" alttext="B\in\mathbb{R}^{d\times r}" display="inline"><semantics id="S2.SS3.p2.4.m4.1a"><mrow id="S2.SS3.p2.4.m4.1.1" xref="S2.SS3.p2.4.m4.1.1.cmml"><mi id="S2.SS3.p2.4.m4.1.1.2" xref="S2.SS3.p2.4.m4.1.1.2.cmml">B</mi><mo id="S2.SS3.p2.4.m4.1.1.1" xref="S2.SS3.p2.4.m4.1.1.1.cmml">∈</mo><msup id="S2.SS3.p2.4.m4.1.1.3" xref="S2.SS3.p2.4.m4.1.1.3.cmml"><mi id="S2.SS3.p2.4.m4.1.1.3.2" xref="S2.SS3.p2.4.m4.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS3.p2.4.m4.1.1.3.3" xref="S2.SS3.p2.4.m4.1.1.3.3.cmml"><mi id="S2.SS3.p2.4.m4.1.1.3.3.2" xref="S2.SS3.p2.4.m4.1.1.3.3.2.cmml">d</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS3.p2.4.m4.1.1.3.3.1" xref="S2.SS3.p2.4.m4.1.1.3.3.1.cmml">×</mo><mi id="S2.SS3.p2.4.m4.1.1.3.3.3" xref="S2.SS3.p2.4.m4.1.1.3.3.3.cmml">r</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.4.m4.1b"><apply id="S2.SS3.p2.4.m4.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1"><in id="S2.SS3.p2.4.m4.1.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1.1"></in><ci id="S2.SS3.p2.4.m4.1.1.2.cmml" xref="S2.SS3.p2.4.m4.1.1.2">𝐵</ci><apply id="S2.SS3.p2.4.m4.1.1.3.cmml" xref="S2.SS3.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p2.4.m4.1.1.3.1.cmml" xref="S2.SS3.p2.4.m4.1.1.3">superscript</csymbol><ci id="S2.SS3.p2.4.m4.1.1.3.2.cmml" xref="S2.SS3.p2.4.m4.1.1.3.2">ℝ</ci><apply id="S2.SS3.p2.4.m4.1.1.3.3.cmml" xref="S2.SS3.p2.4.m4.1.1.3.3"><times id="S2.SS3.p2.4.m4.1.1.3.3.1.cmml" xref="S2.SS3.p2.4.m4.1.1.3.3.1"></times><ci id="S2.SS3.p2.4.m4.1.1.3.3.2.cmml" xref="S2.SS3.p2.4.m4.1.1.3.3.2">𝑑</ci><ci id="S2.SS3.p2.4.m4.1.1.3.3.3.cmml" xref="S2.SS3.p2.4.m4.1.1.3.3.3">𝑟</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.4.m4.1c">B\in\mathbb{R}^{d\times r}</annotation></semantics></math> and <math id="S2.SS3.p2.5.m5.1" class="ltx_Math" alttext="A\in\mathbb{R}^{r\times k}" display="inline"><semantics id="S2.SS3.p2.5.m5.1a"><mrow id="S2.SS3.p2.5.m5.1.1" xref="S2.SS3.p2.5.m5.1.1.cmml"><mi id="S2.SS3.p2.5.m5.1.1.2" xref="S2.SS3.p2.5.m5.1.1.2.cmml">A</mi><mo id="S2.SS3.p2.5.m5.1.1.1" xref="S2.SS3.p2.5.m5.1.1.1.cmml">∈</mo><msup id="S2.SS3.p2.5.m5.1.1.3" xref="S2.SS3.p2.5.m5.1.1.3.cmml"><mi id="S2.SS3.p2.5.m5.1.1.3.2" xref="S2.SS3.p2.5.m5.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS3.p2.5.m5.1.1.3.3" xref="S2.SS3.p2.5.m5.1.1.3.3.cmml"><mi id="S2.SS3.p2.5.m5.1.1.3.3.2" xref="S2.SS3.p2.5.m5.1.1.3.3.2.cmml">r</mi><mo lspace="0.222em" rspace="0.222em" id="S2.SS3.p2.5.m5.1.1.3.3.1" xref="S2.SS3.p2.5.m5.1.1.3.3.1.cmml">×</mo><mi id="S2.SS3.p2.5.m5.1.1.3.3.3" xref="S2.SS3.p2.5.m5.1.1.3.3.3.cmml">k</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.5.m5.1b"><apply id="S2.SS3.p2.5.m5.1.1.cmml" xref="S2.SS3.p2.5.m5.1.1"><in id="S2.SS3.p2.5.m5.1.1.1.cmml" xref="S2.SS3.p2.5.m5.1.1.1"></in><ci id="S2.SS3.p2.5.m5.1.1.2.cmml" xref="S2.SS3.p2.5.m5.1.1.2">𝐴</ci><apply id="S2.SS3.p2.5.m5.1.1.3.cmml" xref="S2.SS3.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p2.5.m5.1.1.3.1.cmml" xref="S2.SS3.p2.5.m5.1.1.3">superscript</csymbol><ci id="S2.SS3.p2.5.m5.1.1.3.2.cmml" xref="S2.SS3.p2.5.m5.1.1.3.2">ℝ</ci><apply id="S2.SS3.p2.5.m5.1.1.3.3.cmml" xref="S2.SS3.p2.5.m5.1.1.3.3"><times id="S2.SS3.p2.5.m5.1.1.3.3.1.cmml" xref="S2.SS3.p2.5.m5.1.1.3.3.1"></times><ci id="S2.SS3.p2.5.m5.1.1.3.3.2.cmml" xref="S2.SS3.p2.5.m5.1.1.3.3.2">𝑟</ci><ci id="S2.SS3.p2.5.m5.1.1.3.3.3.cmml" xref="S2.SS3.p2.5.m5.1.1.3.3.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.5.m5.1c">A\in\mathbb{R}^{r\times k}</annotation></semantics></math>, where <math id="S2.SS3.p2.6.m6.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S2.SS3.p2.6.m6.1a"><mi id="S2.SS3.p2.6.m6.1.1" xref="S2.SS3.p2.6.m6.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.6.m6.1b"><ci id="S2.SS3.p2.6.m6.1.1.cmml" xref="S2.SS3.p2.6.m6.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.6.m6.1c">r</annotation></semantics></math> is the pre-determined rank. The forward pass with input <math id="S2.SS3.p2.7.m7.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS3.p2.7.m7.1a"><mi id="S2.SS3.p2.7.m7.1.1" xref="S2.SS3.p2.7.m7.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.7.m7.1b"><ci id="S2.SS3.p2.7.m7.1.1.cmml" xref="S2.SS3.p2.7.m7.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.7.m7.1c">x</annotation></semantics></math> is given by the following equation,</p>
</div>
<div id="S2.SS3.p3" class="ltx_para ltx_noindent">
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.2" class="ltx_Math" alttext="h=W_{0}x+\Delta Wx=W_{0}x+BAx,~{}~{}B\in\mathbb{R}^{d\times r},A\in\mathbb{R}^{r\times d}" display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.3.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.cmml">h</mi><mo id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.3.cmml">=</mo><mrow id="S2.E1.m1.1.1.1.1.4" xref="S2.E1.m1.1.1.1.1.4.cmml"><mrow id="S2.E1.m1.1.1.1.1.4.2" xref="S2.E1.m1.1.1.1.1.4.2.cmml"><msub id="S2.E1.m1.1.1.1.1.4.2.2" xref="S2.E1.m1.1.1.1.1.4.2.2.cmml"><mi id="S2.E1.m1.1.1.1.1.4.2.2.2" xref="S2.E1.m1.1.1.1.1.4.2.2.2.cmml">W</mi><mn id="S2.E1.m1.1.1.1.1.4.2.2.3" xref="S2.E1.m1.1.1.1.1.4.2.2.3.cmml">0</mn></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.4.2.1" xref="S2.E1.m1.1.1.1.1.4.2.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.4.2.3" xref="S2.E1.m1.1.1.1.1.4.2.3.cmml">x</mi></mrow><mo id="S2.E1.m1.1.1.1.1.4.1" xref="S2.E1.m1.1.1.1.1.4.1.cmml">+</mo><mrow id="S2.E1.m1.1.1.1.1.4.3" xref="S2.E1.m1.1.1.1.1.4.3.cmml"><mi mathvariant="normal" id="S2.E1.m1.1.1.1.1.4.3.2" xref="S2.E1.m1.1.1.1.1.4.3.2.cmml">Δ</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.4.3.1" xref="S2.E1.m1.1.1.1.1.4.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.4.3.3" xref="S2.E1.m1.1.1.1.1.4.3.3.cmml">W</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.4.3.1a" xref="S2.E1.m1.1.1.1.1.4.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.4.3.4" xref="S2.E1.m1.1.1.1.1.4.3.4.cmml">x</mi></mrow></mrow><mo id="S2.E1.m1.1.1.1.1.5" xref="S2.E1.m1.1.1.1.1.5.cmml">=</mo><mrow id="S2.E1.m1.1.1.1.1.6" xref="S2.E1.m1.1.1.1.1.6.cmml"><mrow id="S2.E1.m1.1.1.1.1.6.2" xref="S2.E1.m1.1.1.1.1.6.2.cmml"><msub id="S2.E1.m1.1.1.1.1.6.2.2" xref="S2.E1.m1.1.1.1.1.6.2.2.cmml"><mi id="S2.E1.m1.1.1.1.1.6.2.2.2" xref="S2.E1.m1.1.1.1.1.6.2.2.2.cmml">W</mi><mn id="S2.E1.m1.1.1.1.1.6.2.2.3" xref="S2.E1.m1.1.1.1.1.6.2.2.3.cmml">0</mn></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.6.2.1" xref="S2.E1.m1.1.1.1.1.6.2.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.6.2.3" xref="S2.E1.m1.1.1.1.1.6.2.3.cmml">x</mi></mrow><mo id="S2.E1.m1.1.1.1.1.6.1" xref="S2.E1.m1.1.1.1.1.6.1.cmml">+</mo><mrow id="S2.E1.m1.1.1.1.1.6.3" xref="S2.E1.m1.1.1.1.1.6.3.cmml"><mi id="S2.E1.m1.1.1.1.1.6.3.2" xref="S2.E1.m1.1.1.1.1.6.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.6.3.1" xref="S2.E1.m1.1.1.1.1.6.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.6.3.3" xref="S2.E1.m1.1.1.1.1.6.3.3.cmml">A</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.6.3.1a" xref="S2.E1.m1.1.1.1.1.6.3.1.cmml">​</mo><mi id="S2.E1.m1.1.1.1.1.6.3.4" xref="S2.E1.m1.1.1.1.1.6.3.4.cmml">x</mi></mrow></mrow></mrow><mo rspace="0.827em" id="S2.E1.m1.2.2.2.3" xref="S2.E1.m1.2.2.3a.cmml">,</mo><mrow id="S2.E1.m1.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.3.cmml"><mrow id="S2.E1.m1.2.2.2.2.1.1" xref="S2.E1.m1.2.2.2.2.1.1.cmml"><mi id="S2.E1.m1.2.2.2.2.1.1.2" xref="S2.E1.m1.2.2.2.2.1.1.2.cmml">B</mi><mo id="S2.E1.m1.2.2.2.2.1.1.1" xref="S2.E1.m1.2.2.2.2.1.1.1.cmml">∈</mo><msup id="S2.E1.m1.2.2.2.2.1.1.3" xref="S2.E1.m1.2.2.2.2.1.1.3.cmml"><mi id="S2.E1.m1.2.2.2.2.1.1.3.2" xref="S2.E1.m1.2.2.2.2.1.1.3.2.cmml">ℝ</mi><mrow id="S2.E1.m1.2.2.2.2.1.1.3.3" xref="S2.E1.m1.2.2.2.2.1.1.3.3.cmml"><mi id="S2.E1.m1.2.2.2.2.1.1.3.3.2" xref="S2.E1.m1.2.2.2.2.1.1.3.3.2.cmml">d</mi><mo lspace="0.222em" rspace="0.222em" id="S2.E1.m1.2.2.2.2.1.1.3.3.1" xref="S2.E1.m1.2.2.2.2.1.1.3.3.1.cmml">×</mo><mi id="S2.E1.m1.2.2.2.2.1.1.3.3.3" xref="S2.E1.m1.2.2.2.2.1.1.3.3.3.cmml">r</mi></mrow></msup></mrow><mo id="S2.E1.m1.2.2.2.2.2.3" xref="S2.E1.m1.2.2.2.2.3a.cmml">,</mo><mrow id="S2.E1.m1.2.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.2.cmml"><mi id="S2.E1.m1.2.2.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.2.2.cmml">A</mi><mo id="S2.E1.m1.2.2.2.2.2.2.1" xref="S2.E1.m1.2.2.2.2.2.2.1.cmml">∈</mo><msup id="S2.E1.m1.2.2.2.2.2.2.3" xref="S2.E1.m1.2.2.2.2.2.2.3.cmml"><mi id="S2.E1.m1.2.2.2.2.2.2.3.2" xref="S2.E1.m1.2.2.2.2.2.2.3.2.cmml">ℝ</mi><mrow id="S2.E1.m1.2.2.2.2.2.2.3.3" xref="S2.E1.m1.2.2.2.2.2.2.3.3.cmml"><mi id="S2.E1.m1.2.2.2.2.2.2.3.3.2" xref="S2.E1.m1.2.2.2.2.2.2.3.3.2.cmml">r</mi><mo lspace="0.222em" rspace="0.222em" id="S2.E1.m1.2.2.2.2.2.2.3.3.1" xref="S2.E1.m1.2.2.2.2.2.2.3.3.1.cmml">×</mo><mi id="S2.E1.m1.2.2.2.2.2.2.3.3.3" xref="S2.E1.m1.2.2.2.2.2.2.3.3.3.cmml">d</mi></mrow></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.3.cmml" xref="S2.E1.m1.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.3a.cmml" xref="S2.E1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1"><and id="S2.E1.m1.1.1.1.1a.cmml" xref="S2.E1.m1.1.1.1.1"></and><apply id="S2.E1.m1.1.1.1.1b.cmml" xref="S2.E1.m1.1.1.1.1"><eq id="S2.E1.m1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.3"></eq><ci id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2">ℎ</ci><apply id="S2.E1.m1.1.1.1.1.4.cmml" xref="S2.E1.m1.1.1.1.1.4"><plus id="S2.E1.m1.1.1.1.1.4.1.cmml" xref="S2.E1.m1.1.1.1.1.4.1"></plus><apply id="S2.E1.m1.1.1.1.1.4.2.cmml" xref="S2.E1.m1.1.1.1.1.4.2"><times id="S2.E1.m1.1.1.1.1.4.2.1.cmml" xref="S2.E1.m1.1.1.1.1.4.2.1"></times><apply id="S2.E1.m1.1.1.1.1.4.2.2.cmml" xref="S2.E1.m1.1.1.1.1.4.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.4.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.4.2.2">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.4.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.4.2.2.2">𝑊</ci><cn type="integer" id="S2.E1.m1.1.1.1.1.4.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.4.2.2.3">0</cn></apply><ci id="S2.E1.m1.1.1.1.1.4.2.3.cmml" xref="S2.E1.m1.1.1.1.1.4.2.3">𝑥</ci></apply><apply id="S2.E1.m1.1.1.1.1.4.3.cmml" xref="S2.E1.m1.1.1.1.1.4.3"><times id="S2.E1.m1.1.1.1.1.4.3.1.cmml" xref="S2.E1.m1.1.1.1.1.4.3.1"></times><ci id="S2.E1.m1.1.1.1.1.4.3.2.cmml" xref="S2.E1.m1.1.1.1.1.4.3.2">Δ</ci><ci id="S2.E1.m1.1.1.1.1.4.3.3.cmml" xref="S2.E1.m1.1.1.1.1.4.3.3">𝑊</ci><ci id="S2.E1.m1.1.1.1.1.4.3.4.cmml" xref="S2.E1.m1.1.1.1.1.4.3.4">𝑥</ci></apply></apply></apply><apply id="S2.E1.m1.1.1.1.1c.cmml" xref="S2.E1.m1.1.1.1.1"><eq id="S2.E1.m1.1.1.1.1.5.cmml" xref="S2.E1.m1.1.1.1.1.5"></eq><share href="#S2.E1.m1.1.1.1.1.4.cmml" id="S2.E1.m1.1.1.1.1d.cmml" xref="S2.E1.m1.1.1.1.1"></share><apply id="S2.E1.m1.1.1.1.1.6.cmml" xref="S2.E1.m1.1.1.1.1.6"><plus id="S2.E1.m1.1.1.1.1.6.1.cmml" xref="S2.E1.m1.1.1.1.1.6.1"></plus><apply id="S2.E1.m1.1.1.1.1.6.2.cmml" xref="S2.E1.m1.1.1.1.1.6.2"><times id="S2.E1.m1.1.1.1.1.6.2.1.cmml" xref="S2.E1.m1.1.1.1.1.6.2.1"></times><apply id="S2.E1.m1.1.1.1.1.6.2.2.cmml" xref="S2.E1.m1.1.1.1.1.6.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.6.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.6.2.2">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.6.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.6.2.2.2">𝑊</ci><cn type="integer" id="S2.E1.m1.1.1.1.1.6.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.6.2.2.3">0</cn></apply><ci id="S2.E1.m1.1.1.1.1.6.2.3.cmml" xref="S2.E1.m1.1.1.1.1.6.2.3">𝑥</ci></apply><apply id="S2.E1.m1.1.1.1.1.6.3.cmml" xref="S2.E1.m1.1.1.1.1.6.3"><times id="S2.E1.m1.1.1.1.1.6.3.1.cmml" xref="S2.E1.m1.1.1.1.1.6.3.1"></times><ci id="S2.E1.m1.1.1.1.1.6.3.2.cmml" xref="S2.E1.m1.1.1.1.1.6.3.2">𝐵</ci><ci id="S2.E1.m1.1.1.1.1.6.3.3.cmml" xref="S2.E1.m1.1.1.1.1.6.3.3">𝐴</ci><ci id="S2.E1.m1.1.1.1.1.6.3.4.cmml" xref="S2.E1.m1.1.1.1.1.6.3.4">𝑥</ci></apply></apply></apply></apply><apply id="S2.E1.m1.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.3a.cmml" xref="S2.E1.m1.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S2.E1.m1.2.2.2.2.1.1.cmml" xref="S2.E1.m1.2.2.2.2.1.1"><in id="S2.E1.m1.2.2.2.2.1.1.1.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1"></in><ci id="S2.E1.m1.2.2.2.2.1.1.2.cmml" xref="S2.E1.m1.2.2.2.2.1.1.2">𝐵</ci><apply id="S2.E1.m1.2.2.2.2.1.1.3.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.1.1.3.1.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3">superscript</csymbol><ci id="S2.E1.m1.2.2.2.2.1.1.3.2.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3.2">ℝ</ci><apply id="S2.E1.m1.2.2.2.2.1.1.3.3.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3.3"><times id="S2.E1.m1.2.2.2.2.1.1.3.3.1.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3.3.1"></times><ci id="S2.E1.m1.2.2.2.2.1.1.3.3.2.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3.3.2">𝑑</ci><ci id="S2.E1.m1.2.2.2.2.1.1.3.3.3.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3.3.3">𝑟</ci></apply></apply></apply><apply id="S2.E1.m1.2.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2"><in id="S2.E1.m1.2.2.2.2.2.2.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2.1"></in><ci id="S2.E1.m1.2.2.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2.2">𝐴</ci><apply id="S2.E1.m1.2.2.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.2.2.3.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3">superscript</csymbol><ci id="S2.E1.m1.2.2.2.2.2.2.3.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3.2">ℝ</ci><apply id="S2.E1.m1.2.2.2.2.2.2.3.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3.3"><times id="S2.E1.m1.2.2.2.2.2.2.3.3.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3.3.1"></times><ci id="S2.E1.m1.2.2.2.2.2.2.3.3.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3.3.2">𝑟</ci><ci id="S2.E1.m1.2.2.2.2.2.2.3.3.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3.3.3">𝑑</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">h=W_{0}x+\Delta Wx=W_{0}x+BAx,~{}~{}B\in\mathbb{R}^{d\times r},A\in\mathbb{R}^{r\times d}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS3.p4" class="ltx_para ltx_noindent">
<p id="S2.SS3.p4.4" class="ltx_p">During training, <math id="S2.SS3.p4.1.m1.1" class="ltx_Math" alttext="W_{0}" display="inline"><semantics id="S2.SS3.p4.1.m1.1a"><msub id="S2.SS3.p4.1.m1.1.1" xref="S2.SS3.p4.1.m1.1.1.cmml"><mi id="S2.SS3.p4.1.m1.1.1.2" xref="S2.SS3.p4.1.m1.1.1.2.cmml">W</mi><mn id="S2.SS3.p4.1.m1.1.1.3" xref="S2.SS3.p4.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.1.m1.1b"><apply id="S2.SS3.p4.1.m1.1.1.cmml" xref="S2.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p4.1.m1.1.1.1.cmml" xref="S2.SS3.p4.1.m1.1.1">subscript</csymbol><ci id="S2.SS3.p4.1.m1.1.1.2.cmml" xref="S2.SS3.p4.1.m1.1.1.2">𝑊</ci><cn type="integer" id="S2.SS3.p4.1.m1.1.1.3.cmml" xref="S2.SS3.p4.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.1.m1.1c">W_{0}</annotation></semantics></math> is frozen and does not receive gradient updates, while <math id="S2.SS3.p4.2.m2.1" class="ltx_Math" alttext="B" display="inline"><semantics id="S2.SS3.p4.2.m2.1a"><mi id="S2.SS3.p4.2.m2.1.1" xref="S2.SS3.p4.2.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.2.m2.1b"><ci id="S2.SS3.p4.2.m2.1.1.cmml" xref="S2.SS3.p4.2.m2.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.2.m2.1c">B</annotation></semantics></math> and <math id="S2.SS3.p4.3.m3.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.SS3.p4.3.m3.1a"><mi id="S2.SS3.p4.3.m3.1.1" xref="S2.SS3.p4.3.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.3.m3.1b"><ci id="S2.SS3.p4.3.m3.1.1.cmml" xref="S2.SS3.p4.3.m3.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.3.m3.1c">A</annotation></semantics></math> are updated. By choosing the rank <math id="S2.SS3.p4.4.m4.3" class="ltx_Math" alttext="r\ll\min(d,k)" display="inline"><semantics id="S2.SS3.p4.4.m4.3a"><mrow id="S2.SS3.p4.4.m4.3.4" xref="S2.SS3.p4.4.m4.3.4.cmml"><mi id="S2.SS3.p4.4.m4.3.4.2" xref="S2.SS3.p4.4.m4.3.4.2.cmml">r</mi><mo id="S2.SS3.p4.4.m4.3.4.1" xref="S2.SS3.p4.4.m4.3.4.1.cmml">≪</mo><mrow id="S2.SS3.p4.4.m4.3.4.3.2" xref="S2.SS3.p4.4.m4.3.4.3.1.cmml"><mi id="S2.SS3.p4.4.m4.1.1" xref="S2.SS3.p4.4.m4.1.1.cmml">min</mi><mo id="S2.SS3.p4.4.m4.3.4.3.2a" xref="S2.SS3.p4.4.m4.3.4.3.1.cmml">⁡</mo><mrow id="S2.SS3.p4.4.m4.3.4.3.2.1" xref="S2.SS3.p4.4.m4.3.4.3.1.cmml"><mo stretchy="false" id="S2.SS3.p4.4.m4.3.4.3.2.1.1" xref="S2.SS3.p4.4.m4.3.4.3.1.cmml">(</mo><mi id="S2.SS3.p4.4.m4.2.2" xref="S2.SS3.p4.4.m4.2.2.cmml">d</mi><mo id="S2.SS3.p4.4.m4.3.4.3.2.1.2" xref="S2.SS3.p4.4.m4.3.4.3.1.cmml">,</mo><mi id="S2.SS3.p4.4.m4.3.3" xref="S2.SS3.p4.4.m4.3.3.cmml">k</mi><mo stretchy="false" id="S2.SS3.p4.4.m4.3.4.3.2.1.3" xref="S2.SS3.p4.4.m4.3.4.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.4.m4.3b"><apply id="S2.SS3.p4.4.m4.3.4.cmml" xref="S2.SS3.p4.4.m4.3.4"><csymbol cd="latexml" id="S2.SS3.p4.4.m4.3.4.1.cmml" xref="S2.SS3.p4.4.m4.3.4.1">much-less-than</csymbol><ci id="S2.SS3.p4.4.m4.3.4.2.cmml" xref="S2.SS3.p4.4.m4.3.4.2">𝑟</ci><apply id="S2.SS3.p4.4.m4.3.4.3.1.cmml" xref="S2.SS3.p4.4.m4.3.4.3.2"><min id="S2.SS3.p4.4.m4.1.1.cmml" xref="S2.SS3.p4.4.m4.1.1"></min><ci id="S2.SS3.p4.4.m4.2.2.cmml" xref="S2.SS3.p4.4.m4.2.2">𝑑</ci><ci id="S2.SS3.p4.4.m4.3.3.cmml" xref="S2.SS3.p4.4.m4.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.4.m4.3c">r\ll\min(d,k)</annotation></semantics></math>, the memory consumption is reduced as we do not need to store the optimizer states for the large frozen matrix.</p>
</div>
<div id="S2.SS3.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS3.p5.1">빠듯한 예산을 준수하면서 매개변수 효율적인 훈련을 달성하기 위해 사전 훈련 및 미세 조정 단계를 포함하여 논문의 모든 중국 LLaMA 및 알파카 모델에 LoRA 훈련을 적용한다. 주로 LoRA 어댑터를 어텐션 모듈과 MLP 레이어의 가중치에 통합한다. 모든 선형 변압기 블록에 LoRA를 적용하는 효과는 QLoRA <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et al., <a class="ltx_ref" href="#bib.bib4" title="">2023</a>)</cite>에서 검증되며, 이는 우리의 선택이 합리적임을 나타낸다.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Pre-Training Objective</h3>

<div id="S2.SS4.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS4.p1.2">우리는 표준 캐주얼 언어 모델링(CLM) 작업을 통해 중국 LLaMA 모델을 사전 훈련한다. 입력 토큰 시퀀스 <math alttext="\bm{x}=(x_{0},x_{1},x_{2},\ldots)" class="ltx_Math" display="inline" id="S2.SS4.p1.1.m1.4"><semantics id="S2.SS4.p1.1.m1.4a"><mrow id="S2.SS4.p1.1.m1.4.4" xref="S2.SS4.p1.1.m1.4.4.cmml"><mi id="S2.SS4.p1.1.m1.4.4.5" xref="S2.SS4.p1.1.m1.4.4.5.cmml">𝒙</mi><mo id="S2.SS4.p1.1.m1.4.4.4" xref="S2.SS4.p1.1.m1.4.4.4.cmml">=</mo><mrow id="S2.SS4.p1.1.m1.4.4.3.3" xref="S2.SS4.p1.1.m1.4.4.3.4.cmml"><mo id="S2.SS4.p1.1.m1.4.4.3.3.4" stretchy="false" xref="S2.SS4.p1.1.m1.4.4.3.4.cmml">(</mo><msub id="S2.SS4.p1.1.m1.2.2.1.1.1" xref="S2.SS4.p1.1.m1.2.2.1.1.1.cmml"><mi id="S2.SS4.p1.1.m1.2.2.1.1.1.2" xref="S2.SS4.p1.1.m1.2.2.1.1.1.2.cmml">x</mi><mn id="S2.SS4.p1.1.m1.2.2.1.1.1.3" xref="S2.SS4.p1.1.m1.2.2.1.1.1.3.cmml">0</mn></msub><mo id="S2.SS4.p1.1.m1.4.4.3.3.5" xref="S2.SS4.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S2.SS4.p1.1.m1.3.3.2.2.2" xref="S2.SS4.p1.1.m1.3.3.2.2.2.cmml"><mi id="S2.SS4.p1.1.m1.3.3.2.2.2.2" xref="S2.SS4.p1.1.m1.3.3.2.2.2.2.cmml">x</mi><mn id="S2.SS4.p1.1.m1.3.3.2.2.2.3" xref="S2.SS4.p1.1.m1.3.3.2.2.2.3.cmml">1</mn></msub><mo id="S2.SS4.p1.1.m1.4.4.3.3.6" xref="S2.SS4.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S2.SS4.p1.1.m1.4.4.3.3.3" xref="S2.SS4.p1.1.m1.4.4.3.3.3.cmml"><mi id="S2.SS4.p1.1.m1.4.4.3.3.3.2" xref="S2.SS4.p1.1.m1.4.4.3.3.3.2.cmml">x</mi><mn id="S2.SS4.p1.1.m1.4.4.3.3.3.3" xref="S2.SS4.p1.1.m1.4.4.3.3.3.3.cmml">2</mn></msub><mo id="S2.SS4.p1.1.m1.4.4.3.3.7" xref="S2.SS4.p1.1.m1.4.4.3.4.cmml">,</mo><mi id="S2.SS4.p1.1.m1.1.1" mathvariant="normal" xref="S2.SS4.p1.1.m1.1.1.cmml">…</mi><mo id="S2.SS4.p1.1.m1.4.4.3.3.8" stretchy="false" xref="S2.SS4.p1.1.m1.4.4.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.1.m1.4b"><apply id="S2.SS4.p1.1.m1.4.4.cmml" xref="S2.SS4.p1.1.m1.4.4"><eq id="S2.SS4.p1.1.m1.4.4.4.cmml" xref="S2.SS4.p1.1.m1.4.4.4"></eq><ci id="S2.SS4.p1.1.m1.4.4.5.cmml" xref="S2.SS4.p1.1.m1.4.4.5">𝒙</ci><vector id="S2.SS4.p1.1.m1.4.4.3.4.cmml" xref="S2.SS4.p1.1.m1.4.4.3.3"><apply id="S2.SS4.p1.1.m1.2.2.1.1.1.cmml" xref="S2.SS4.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.1.m1.2.2.1.1.1.1.cmml" xref="S2.SS4.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S2.SS4.p1.1.m1.2.2.1.1.1.2.cmml" xref="S2.SS4.p1.1.m1.2.2.1.1.1.2">𝑥</ci><cn id="S2.SS4.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS4.p1.1.m1.2.2.1.1.1.3">0</cn></apply><apply id="S2.SS4.p1.1.m1.3.3.2.2.2.cmml" xref="S2.SS4.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS4.p1.1.m1.3.3.2.2.2.1.cmml" xref="S2.SS4.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S2.SS4.p1.1.m1.3.3.2.2.2.2.cmml" xref="S2.SS4.p1.1.m1.3.3.2.2.2.2">𝑥</ci><cn id="S2.SS4.p1.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS4.p1.1.m1.3.3.2.2.2.3">1</cn></apply><apply id="S2.SS4.p1.1.m1.4.4.3.3.3.cmml" xref="S2.SS4.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS4.p1.1.m1.4.4.3.3.3.1.cmml" xref="S2.SS4.p1.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S2.SS4.p1.1.m1.4.4.3.3.3.2.cmml" xref="S2.SS4.p1.1.m1.4.4.3.3.3.2">𝑥</ci><cn id="S2.SS4.p1.1.m1.4.4.3.3.3.3.cmml" type="integer" xref="S2.SS4.p1.1.m1.4.4.3.3.3.3">2</cn></apply><ci id="S2.SS4.p1.1.m1.1.1.cmml" xref="S2.SS4.p1.1.m1.1.1">…</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.1.m1.4c">\bm{x}=(x_{0},x_{1},x_{2},\ldots)</annotation></semantics></math>가 주어지면, 모델은 다음 토큰 <math alttext="x_{i}" class="ltx_Math" display="inline" id="S2.SS4.p1.2.m2.1"><semantics id="S2.SS4.p1.2.m2.1a"><msub id="S2.SS4.p1.2.m2.1.1" xref="S2.SS4.p1.2.m2.1.1.cmml"><mi id="S2.SS4.p1.2.m2.1.1.2" xref="S2.SS4.p1.2.m2.1.1.2.cmml">x</mi><mi id="S2.SS4.p1.2.m2.1.1.3" xref="S2.SS4.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.2.m2.1b"><apply id="S2.SS4.p1.2.m2.1.1.cmml" xref="S2.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.2.m2.1.1.1.cmml" xref="S2.SS4.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS4.p1.2.m2.1.1.2.cmml" xref="S2.SS4.p1.2.m2.1.1.2">𝑥</ci><ci id="S2.SS4.p1.2.m2.1.1.3.cmml" xref="S2.SS4.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.2.m2.1c">x_{i}</annotation></semantics></math>를 자기회귀 방식으로 예측하도록 훈련된다. 수학적으로 목표는 다음과 같은 음의 로그 우도를 최소화하는 것이다.</p>
<table id="A0.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E2.m1.4" class="ltx_Math" alttext="\displaystyle\mathcal{L}_{\textrm{CLM}}(\Theta)=\mathbb{E}_{\bm{x}\sim\mathcal{D}_{\textrm{PT}}}\left[-\sum_{i}\log p(x_{i}|x_{0},x_{1},\ldots,x_{i-1};\Theta)\right]" display="inline"><semantics id="S2.E2.m1.4a"><mrow id="S2.E2.m1.4.4" xref="S2.E2.m1.4.4.cmml"><mrow id="S2.E2.m1.4.4.3" xref="S2.E2.m1.4.4.3.cmml"><msub id="S2.E2.m1.4.4.3.2" xref="S2.E2.m1.4.4.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.4.4.3.2.2" xref="S2.E2.m1.4.4.3.2.2.cmml">ℒ</mi><mtext id="S2.E2.m1.4.4.3.2.3" xref="S2.E2.m1.4.4.3.2.3a.cmml">CLM</mtext></msub><mo lspace="0em" rspace="0em" id="S2.E2.m1.4.4.3.1" xref="S2.E2.m1.4.4.3.1.cmml">​</mo><mrow id="S2.E2.m1.4.4.3.3.2" xref="S2.E2.m1.4.4.3.cmml"><mo stretchy="false" id="S2.E2.m1.4.4.3.3.2.1" xref="S2.E2.m1.4.4.3.cmml">(</mo><mi mathvariant="normal" id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml">Θ</mi><mo stretchy="false" id="S2.E2.m1.4.4.3.3.2.2" xref="S2.E2.m1.4.4.3.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.4.4.2" xref="S2.E2.m1.4.4.2.cmml">=</mo><mrow id="S2.E2.m1.4.4.1" xref="S2.E2.m1.4.4.1.cmml"><msub id="S2.E2.m1.4.4.1.3" xref="S2.E2.m1.4.4.1.3.cmml"><mi id="S2.E2.m1.4.4.1.3.2" xref="S2.E2.m1.4.4.1.3.2.cmml">𝔼</mi><mrow id="S2.E2.m1.4.4.1.3.3" xref="S2.E2.m1.4.4.1.3.3.cmml"><mi id="S2.E2.m1.4.4.1.3.3.2" xref="S2.E2.m1.4.4.1.3.3.2.cmml">𝒙</mi><mo id="S2.E2.m1.4.4.1.3.3.1" xref="S2.E2.m1.4.4.1.3.3.1.cmml">∼</mo><msub id="S2.E2.m1.4.4.1.3.3.3" xref="S2.E2.m1.4.4.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.4.4.1.3.3.3.2" xref="S2.E2.m1.4.4.1.3.3.3.2.cmml">𝒟</mi><mtext id="S2.E2.m1.4.4.1.3.3.3.3" xref="S2.E2.m1.4.4.1.3.3.3.3a.cmml">PT</mtext></msub></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E2.m1.4.4.1.2" xref="S2.E2.m1.4.4.1.2.cmml">​</mo><mrow id="S2.E2.m1.4.4.1.1.1" xref="S2.E2.m1.4.4.1.1.2.cmml"><mo id="S2.E2.m1.4.4.1.1.1.2" xref="S2.E2.m1.4.4.1.1.2.1.cmml">[</mo><mrow id="S2.E2.m1.4.4.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.cmml"><mo id="S2.E2.m1.4.4.1.1.1.1a" xref="S2.E2.m1.4.4.1.1.1.1.cmml">−</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S2.E2.m1.4.4.1.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.1.1.2.cmml"><munder id="S2.E2.m1.4.4.1.1.1.1.1.2a" xref="S2.E2.m1.4.4.1.1.1.1.1.2.cmml"><mo movablelimits="false" id="S2.E2.m1.4.4.1.1.1.1.1.2.2" xref="S2.E2.m1.4.4.1.1.1.1.1.2.2.cmml">∑</mo><mi id="S2.E2.m1.4.4.1.1.1.1.1.2.3" xref="S2.E2.m1.4.4.1.1.1.1.1.2.3.cmml">i</mi></munder></mstyle><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.cmml"><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.3.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S2.E2.m1.4.4.1.1.1.1.1.1.3a" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3.cmml">⁡</mo><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.3.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3.2.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E2.m1.4.4.1.1.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.2.cmml">x</mi><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.3.cmml">i</mi></msub><mo fence="false" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.4" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.4.cmml">|</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml"><msub id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mn id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">0</mn></msub><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.4" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml">x</mi><mn id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">1</mn></msub><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.5" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml">…</mi><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.6" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2.cmml">x</mi><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2.cmml">i</mi><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1.cmml">−</mo><mn id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3.cmml">1</mn></mrow></msub><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.7" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">;</mo><mi mathvariant="normal" id="S2.E2.m1.3.3" xref="S2.E2.m1.3.3.cmml">Θ</mi></mrow></mrow><mo stretchy="false" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E2.m1.4.4.1.1.1.3" xref="S2.E2.m1.4.4.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.4b"><apply id="S2.E2.m1.4.4.cmml" xref="S2.E2.m1.4.4"><eq id="S2.E2.m1.4.4.2.cmml" xref="S2.E2.m1.4.4.2"></eq><apply id="S2.E2.m1.4.4.3.cmml" xref="S2.E2.m1.4.4.3"><times id="S2.E2.m1.4.4.3.1.cmml" xref="S2.E2.m1.4.4.3.1"></times><apply id="S2.E2.m1.4.4.3.2.cmml" xref="S2.E2.m1.4.4.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.3.2.1.cmml" xref="S2.E2.m1.4.4.3.2">subscript</csymbol><ci id="S2.E2.m1.4.4.3.2.2.cmml" xref="S2.E2.m1.4.4.3.2.2">ℒ</ci><ci id="S2.E2.m1.4.4.3.2.3a.cmml" xref="S2.E2.m1.4.4.3.2.3"><mtext mathsize="70%" id="S2.E2.m1.4.4.3.2.3.cmml" xref="S2.E2.m1.4.4.3.2.3">CLM</mtext></ci></apply><ci id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">Θ</ci></apply><apply id="S2.E2.m1.4.4.1.cmml" xref="S2.E2.m1.4.4.1"><times id="S2.E2.m1.4.4.1.2.cmml" xref="S2.E2.m1.4.4.1.2"></times><apply id="S2.E2.m1.4.4.1.3.cmml" xref="S2.E2.m1.4.4.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.3.1.cmml" xref="S2.E2.m1.4.4.1.3">subscript</csymbol><ci id="S2.E2.m1.4.4.1.3.2.cmml" xref="S2.E2.m1.4.4.1.3.2">𝔼</ci><apply id="S2.E2.m1.4.4.1.3.3.cmml" xref="S2.E2.m1.4.4.1.3.3"><csymbol cd="latexml" id="S2.E2.m1.4.4.1.3.3.1.cmml" xref="S2.E2.m1.4.4.1.3.3.1">similar-to</csymbol><ci id="S2.E2.m1.4.4.1.3.3.2.cmml" xref="S2.E2.m1.4.4.1.3.3.2">𝒙</ci><apply id="S2.E2.m1.4.4.1.3.3.3.cmml" xref="S2.E2.m1.4.4.1.3.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.3.3.3.1.cmml" xref="S2.E2.m1.4.4.1.3.3.3">subscript</csymbol><ci id="S2.E2.m1.4.4.1.3.3.3.2.cmml" xref="S2.E2.m1.4.4.1.3.3.3.2">𝒟</ci><ci id="S2.E2.m1.4.4.1.3.3.3.3a.cmml" xref="S2.E2.m1.4.4.1.3.3.3.3"><mtext mathsize="50%" id="S2.E2.m1.4.4.1.3.3.3.3.cmml" xref="S2.E2.m1.4.4.1.3.3.3.3">PT</mtext></ci></apply></apply></apply><apply id="S2.E2.m1.4.4.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1"><csymbol cd="latexml" id="S2.E2.m1.4.4.1.1.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.2">delimited-[]</csymbol><apply id="S2.E2.m1.4.4.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1"><minus id="S2.E2.m1.4.4.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1"></minus><apply id="S2.E2.m1.4.4.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1"><apply id="S2.E2.m1.4.4.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.2">subscript</csymbol><sum id="S2.E2.m1.4.4.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.2.2"></sum><ci id="S2.E2.m1.4.4.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1"><times id="S2.E2.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.2"></times><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3"><log id="S2.E2.m1.4.4.1.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3.1"></log><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3.2">𝑝</ci></apply><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.4.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.4">conditional</csymbol><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.2">𝑥</ci><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.3">𝑖</ci></apply><list id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3"><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><cn type="integer" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3">0</cn></apply><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2">𝑥</ci><cn type="integer" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3">1</cn></apply><ci id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">…</ci><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2">𝑥</ci><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3"><minus id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1"></minus><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2">𝑖</ci><cn type="integer" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3">1</cn></apply></apply><ci id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3">Θ</ci></list></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.4c">\displaystyle\mathcal{L}_{\textrm{CLM}}(\Theta)=\mathbb{E}_{\bm{x}\sim\mathcal{D}_{\textrm{PT}}}\left[-\sum_{i}\log p(x_{i}|x_{0},x_{1},\ldots,x_{i-1};\Theta)\right]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.SS4.p1.6" class="ltx_p">where, <math id="S2.SS4.p1.3.m1.1" class="ltx_Math" alttext="\Theta" display="inline"><semantics id="S2.SS4.p1.3.m1.1a"><mi mathvariant="normal" id="S2.SS4.p1.3.m1.1.1" xref="S2.SS4.p1.3.m1.1.1.cmml">Θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.3.m1.1b"><ci id="S2.SS4.p1.3.m1.1.1.cmml" xref="S2.SS4.p1.3.m1.1.1">Θ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.3.m1.1c">\Theta</annotation></semantics></math> represents the model parameters, <math id="S2.SS4.p1.4.m2.1" class="ltx_Math" alttext="\mathcal{D}_{\textrm{PT}}" display="inline"><semantics id="S2.SS4.p1.4.m2.1a"><msub id="S2.SS4.p1.4.m2.1.1" xref="S2.SS4.p1.4.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p1.4.m2.1.1.2" xref="S2.SS4.p1.4.m2.1.1.2.cmml">𝒟</mi><mtext id="S2.SS4.p1.4.m2.1.1.3" xref="S2.SS4.p1.4.m2.1.1.3a.cmml">PT</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.4.m2.1b"><apply id="S2.SS4.p1.4.m2.1.1.cmml" xref="S2.SS4.p1.4.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.4.m2.1.1.1.cmml" xref="S2.SS4.p1.4.m2.1.1">subscript</csymbol><ci id="S2.SS4.p1.4.m2.1.1.2.cmml" xref="S2.SS4.p1.4.m2.1.1.2">𝒟</ci><ci id="S2.SS4.p1.4.m2.1.1.3a.cmml" xref="S2.SS4.p1.4.m2.1.1.3"><mtext mathsize="70%" id="S2.SS4.p1.4.m2.1.1.3.cmml" xref="S2.SS4.p1.4.m2.1.1.3">PT</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.4.m2.1c">\mathcal{D}_{\textrm{PT}}</annotation></semantics></math> is the pre-training dataset, <math id="S2.SS4.p1.5.m3.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S2.SS4.p1.5.m3.1a"><msub id="S2.SS4.p1.5.m3.1.1" xref="S2.SS4.p1.5.m3.1.1.cmml"><mi id="S2.SS4.p1.5.m3.1.1.2" xref="S2.SS4.p1.5.m3.1.1.2.cmml">x</mi><mi id="S2.SS4.p1.5.m3.1.1.3" xref="S2.SS4.p1.5.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.5.m3.1b"><apply id="S2.SS4.p1.5.m3.1.1.cmml" xref="S2.SS4.p1.5.m3.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.5.m3.1.1.1.cmml" xref="S2.SS4.p1.5.m3.1.1">subscript</csymbol><ci id="S2.SS4.p1.5.m3.1.1.2.cmml" xref="S2.SS4.p1.5.m3.1.1.2">𝑥</ci><ci id="S2.SS4.p1.5.m3.1.1.3.cmml" xref="S2.SS4.p1.5.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.5.m3.1c">x_{i}</annotation></semantics></math> is the token to be predicted, and <math id="S2.SS4.p1.6.m4.4" class="ltx_Math" alttext="x_{0},x_{1},\ldots,x_{i-1}" display="inline"><semantics id="S2.SS4.p1.6.m4.4a"><mrow id="S2.SS4.p1.6.m4.4.4.3" xref="S2.SS4.p1.6.m4.4.4.4.cmml"><msub id="S2.SS4.p1.6.m4.2.2.1.1" xref="S2.SS4.p1.6.m4.2.2.1.1.cmml"><mi id="S2.SS4.p1.6.m4.2.2.1.1.2" xref="S2.SS4.p1.6.m4.2.2.1.1.2.cmml">x</mi><mn id="S2.SS4.p1.6.m4.2.2.1.1.3" xref="S2.SS4.p1.6.m4.2.2.1.1.3.cmml">0</mn></msub><mo id="S2.SS4.p1.6.m4.4.4.3.4" xref="S2.SS4.p1.6.m4.4.4.4.cmml">,</mo><msub id="S2.SS4.p1.6.m4.3.3.2.2" xref="S2.SS4.p1.6.m4.3.3.2.2.cmml"><mi id="S2.SS4.p1.6.m4.3.3.2.2.2" xref="S2.SS4.p1.6.m4.3.3.2.2.2.cmml">x</mi><mn id="S2.SS4.p1.6.m4.3.3.2.2.3" xref="S2.SS4.p1.6.m4.3.3.2.2.3.cmml">1</mn></msub><mo id="S2.SS4.p1.6.m4.4.4.3.5" xref="S2.SS4.p1.6.m4.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S2.SS4.p1.6.m4.1.1" xref="S2.SS4.p1.6.m4.1.1.cmml">…</mi><mo id="S2.SS4.p1.6.m4.4.4.3.6" xref="S2.SS4.p1.6.m4.4.4.4.cmml">,</mo><msub id="S2.SS4.p1.6.m4.4.4.3.3" xref="S2.SS4.p1.6.m4.4.4.3.3.cmml"><mi id="S2.SS4.p1.6.m4.4.4.3.3.2" xref="S2.SS4.p1.6.m4.4.4.3.3.2.cmml">x</mi><mrow id="S2.SS4.p1.6.m4.4.4.3.3.3" xref="S2.SS4.p1.6.m4.4.4.3.3.3.cmml"><mi id="S2.SS4.p1.6.m4.4.4.3.3.3.2" xref="S2.SS4.p1.6.m4.4.4.3.3.3.2.cmml">i</mi><mo id="S2.SS4.p1.6.m4.4.4.3.3.3.1" xref="S2.SS4.p1.6.m4.4.4.3.3.3.1.cmml">−</mo><mn id="S2.SS4.p1.6.m4.4.4.3.3.3.3" xref="S2.SS4.p1.6.m4.4.4.3.3.3.3.cmml">1</mn></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.6.m4.4b"><list id="S2.SS4.p1.6.m4.4.4.4.cmml" xref="S2.SS4.p1.6.m4.4.4.3"><apply id="S2.SS4.p1.6.m4.2.2.1.1.cmml" xref="S2.SS4.p1.6.m4.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.6.m4.2.2.1.1.1.cmml" xref="S2.SS4.p1.6.m4.2.2.1.1">subscript</csymbol><ci id="S2.SS4.p1.6.m4.2.2.1.1.2.cmml" xref="S2.SS4.p1.6.m4.2.2.1.1.2">𝑥</ci><cn type="integer" id="S2.SS4.p1.6.m4.2.2.1.1.3.cmml" xref="S2.SS4.p1.6.m4.2.2.1.1.3">0</cn></apply><apply id="S2.SS4.p1.6.m4.3.3.2.2.cmml" xref="S2.SS4.p1.6.m4.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS4.p1.6.m4.3.3.2.2.1.cmml" xref="S2.SS4.p1.6.m4.3.3.2.2">subscript</csymbol><ci id="S2.SS4.p1.6.m4.3.3.2.2.2.cmml" xref="S2.SS4.p1.6.m4.3.3.2.2.2">𝑥</ci><cn type="integer" id="S2.SS4.p1.6.m4.3.3.2.2.3.cmml" xref="S2.SS4.p1.6.m4.3.3.2.2.3">1</cn></apply><ci id="S2.SS4.p1.6.m4.1.1.cmml" xref="S2.SS4.p1.6.m4.1.1">…</ci><apply id="S2.SS4.p1.6.m4.4.4.3.3.cmml" xref="S2.SS4.p1.6.m4.4.4.3.3"><csymbol cd="ambiguous" id="S2.SS4.p1.6.m4.4.4.3.3.1.cmml" xref="S2.SS4.p1.6.m4.4.4.3.3">subscript</csymbol><ci id="S2.SS4.p1.6.m4.4.4.3.3.2.cmml" xref="S2.SS4.p1.6.m4.4.4.3.3.2">𝑥</ci><apply id="S2.SS4.p1.6.m4.4.4.3.3.3.cmml" xref="S2.SS4.p1.6.m4.4.4.3.3.3"><minus id="S2.SS4.p1.6.m4.4.4.3.3.3.1.cmml" xref="S2.SS4.p1.6.m4.4.4.3.3.3.1"></minus><ci id="S2.SS4.p1.6.m4.4.4.3.3.3.2.cmml" xref="S2.SS4.p1.6.m4.4.4.3.3.3.2">𝑖</ci><cn type="integer" id="S2.SS4.p1.6.m4.4.4.3.3.3.3.cmml" xref="S2.SS4.p1.6.m4.4.4.3.3.3.3">1</cn></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.6.m4.4c">x_{0},x_{1},\ldots,x_{i-1}</annotation></semantics></math> constitute the context.</p>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Supervised Fine-Tuning and Chinese Alpaca</h3>

<div id="S2.SS5.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS5.p1.1">사전 훈련된 언어 모델은 사용자 지시를 거의 따를 수 없고 종종 의도하지 않은 콘텐츠를 생성할 수 있다. 이는 식 (<a class="ltx_ref" href="#S2.E2" title="In 2.4 Pre-Training Objective ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">2</span></a>)의 언어 모델링 목적이 “지침을 따르고 질문에 답하라” <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="#bib.bib16" title="">2022</a>)</cite>가 아니라 다음 토큰을 예측하고 있기 때문이다. 언어 모델의 행동을 사용자의 의도에 맞게 조정하기 위해 모델을 미세 조정하여 지시 사항을 따르도록 명시적으로 훈련시킬 수 있다. Stanford Alpaca <cite class="ltx_cite ltx_citemacro_citep">(Taori et al., <a class="ltx_ref" href="#bib.bib23" title="">2023b</a>)</cite>는 Self-Instruct <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib26" title="">2022</a>)</cite>의 기법들에 의해 생성된 52K 명령어 추종 데이터에 대해 학습된 LLaMA 기반 명령어 추종 모델이다. 우리는 스탠포드 알파카의 접근법을 따라 중국 LLaMA에 자기 지시 미세 조정을 적용하여 지시 후속 모델인 중국 알파카를 훈련한다.</p>
</div>
<div id="S2.SS5.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS5.p2.1">중국 알파카는 명령어 후속 데이터 세트의 조합으로 훈련된다. 데이터 세트의 각 예는 명령어와 출력으로 구성된다. 감독된 미세 조정 태스크는 캐주얼 언어 모델링 태스크와 유사하다: 모델은 명령으로 프롬프트되고 출력을 자동으로 생성하도록 트레이닝된다. 명령은 프롬프트 템플릿으로 래핑되며 출력은 템플릿에 즉시 따라갑니다. 미세 조정 및 추론을 위해 스탠포드 알파카의 다음 템플릿을 채택하며 입력 시퀀스는 다음과 같습니다.</p>
</div>
<div id="S2.SS5.p3" class="ltx_para ltx_noindent">
<blockquote id="S2.SS5.p3.1" class="ltx_quote">
<p class="ltx_p" id="S2.SS5.p3.1.1"><span class="ltx_text ltx_font_italic" id="S2.SS5.p3.1.1.1">아래는 작업을 설명하는 명령입니다. 요청을 적절하게 완료하는 응답을 작성합니다. <br class="ltx_break"/> <br class="ltx_break"/> <br class="ltx_break"/>### Instruction:  <br class="ltx_break"/></span>{<span class="ltx_text ltx_font_italic" id="S2.SS5.p3.1.1.2">instruction</span>}<span class="ltx_text ltx_font_italic" id="S2.SS5.p3.1.1.3"><br class="ltx_break"/> <br class="ltx_break"/>### Response:</span>{<span class="ltx_text ltx_font_italic" id="S2.SS5.p3.1.1.4">output</span>}<span class="ltx_text ltx_font_italic" id="S2.SS5.p3.1.1.5"></span></p>
</blockquote>
</div>
<div id="S2.SS5.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS5.p4.4">손실은 입력 시퀀스의 <em class="ltx_emph ltx_font_italic" id="S2.SS5.p4.4.1"><span class="ltx_text ltx_font_upright" id="S2.SS5.p4.4.1.1">{</span>output<span class="ltx_text ltx_font_upright" id="S2.SS5.p4.4.1.2">}</span></em> 부분에서만 계산되며 다음과 같이 나타낼 수 있다.</p>
<table id="A0.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E3.m1.4" class="ltx_Math" alttext="\displaystyle\mathcal{L}_{\textrm{SFT}}(\Theta)=\mathbb{E}_{\bm{x}\sim\mathcal{D}_{\textrm{SFT}}}\left[-\sum_{i\in\textit{\{output\}}}\log p(x_{i}|x_{0},x_{1},\ldots,x_{i-1};\Theta)\right]" display="inline"><semantics id="S2.E3.m1.4a"><mrow id="S2.E3.m1.4.4" xref="S2.E3.m1.4.4.cmml"><mrow id="S2.E3.m1.4.4.3" xref="S2.E3.m1.4.4.3.cmml"><msub id="S2.E3.m1.4.4.3.2" xref="S2.E3.m1.4.4.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.4.4.3.2.2" xref="S2.E3.m1.4.4.3.2.2.cmml">ℒ</mi><mtext id="S2.E3.m1.4.4.3.2.3" xref="S2.E3.m1.4.4.3.2.3a.cmml">SFT</mtext></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.4.3.1" xref="S2.E3.m1.4.4.3.1.cmml">​</mo><mrow id="S2.E3.m1.4.4.3.3.2" xref="S2.E3.m1.4.4.3.cmml"><mo stretchy="false" id="S2.E3.m1.4.4.3.3.2.1" xref="S2.E3.m1.4.4.3.cmml">(</mo><mi mathvariant="normal" id="S2.E3.m1.1.1" xref="S2.E3.m1.1.1.cmml">Θ</mi><mo stretchy="false" id="S2.E3.m1.4.4.3.3.2.2" xref="S2.E3.m1.4.4.3.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.4.4.2" xref="S2.E3.m1.4.4.2.cmml">=</mo><mrow id="S2.E3.m1.4.4.1" xref="S2.E3.m1.4.4.1.cmml"><msub id="S2.E3.m1.4.4.1.3" xref="S2.E3.m1.4.4.1.3.cmml"><mi id="S2.E3.m1.4.4.1.3.2" xref="S2.E3.m1.4.4.1.3.2.cmml">𝔼</mi><mrow id="S2.E3.m1.4.4.1.3.3" xref="S2.E3.m1.4.4.1.3.3.cmml"><mi id="S2.E3.m1.4.4.1.3.3.2" xref="S2.E3.m1.4.4.1.3.3.2.cmml">𝒙</mi><mo id="S2.E3.m1.4.4.1.3.3.1" xref="S2.E3.m1.4.4.1.3.3.1.cmml">∼</mo><msub id="S2.E3.m1.4.4.1.3.3.3" xref="S2.E3.m1.4.4.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.4.4.1.3.3.3.2" xref="S2.E3.m1.4.4.1.3.3.3.2.cmml">𝒟</mi><mtext id="S2.E3.m1.4.4.1.3.3.3.3" xref="S2.E3.m1.4.4.1.3.3.3.3a.cmml">SFT</mtext></msub></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.4.1.2" xref="S2.E3.m1.4.4.1.2.cmml">​</mo><mrow id="S2.E3.m1.4.4.1.1.1" xref="S2.E3.m1.4.4.1.1.2.cmml"><mo id="S2.E3.m1.4.4.1.1.1.2" xref="S2.E3.m1.4.4.1.1.2.1.cmml">[</mo><mrow id="S2.E3.m1.4.4.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.cmml"><mo id="S2.E3.m1.4.4.1.1.1.1a" xref="S2.E3.m1.4.4.1.1.1.1.cmml">−</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S2.E3.m1.4.4.1.1.1.1.1.2" xref="S2.E3.m1.4.4.1.1.1.1.1.2.cmml"><munder id="S2.E3.m1.4.4.1.1.1.1.1.2a" xref="S2.E3.m1.4.4.1.1.1.1.1.2.cmml"><mo movablelimits="false" id="S2.E3.m1.4.4.1.1.1.1.1.2.2" xref="S2.E3.m1.4.4.1.1.1.1.1.2.2.cmml">∑</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1.2.3" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.2.3.2" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.2.cmml">i</mi><mo id="S2.E3.m1.4.4.1.1.1.1.1.2.3.1" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.1.cmml">∈</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3d.cmml"><mtext id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3a" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3d.cmml">{</mtext><mtext class="ltx_mathvariant_italic" id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3b" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3d.cmml">output</mtext><mtext id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3c" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3d.cmml">}</mtext></mrow></mrow></munder></mstyle><mrow id="S2.E3.m1.4.4.1.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.cmml"><mrow id="S2.E3.m1.4.4.1.1.1.1.1.1.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.3.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3.1.cmml">log</mi><mo lspace="0.167em" id="S2.E3.m1.4.4.1.1.1.1.1.1.3a" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3.cmml">⁡</mo><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.3.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3.2.cmml">p</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E3.m1.4.4.1.1.1.1.1.1.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.2.cmml">x</mi><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.3.cmml">i</mi></msub><mo fence="false" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.4" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.4.cmml">|</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml"><msub id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mn id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">0</mn></msub><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.4" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml">x</mi><mn id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">1</mn></msub><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.5" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.E3.m1.2.2" xref="S2.E3.m1.2.2.cmml">…</mi><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.6" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2.cmml">x</mi><mrow id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2.cmml">i</mi><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1.cmml">−</mo><mn id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3.cmml">1</mn></mrow></msub><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.7" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">;</mo><mi mathvariant="normal" id="S2.E3.m1.3.3" xref="S2.E3.m1.3.3.cmml">Θ</mi></mrow></mrow><mo stretchy="false" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E3.m1.4.4.1.1.1.3" xref="S2.E3.m1.4.4.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.4b"><apply id="S2.E3.m1.4.4.cmml" xref="S2.E3.m1.4.4"><eq id="S2.E3.m1.4.4.2.cmml" xref="S2.E3.m1.4.4.2"></eq><apply id="S2.E3.m1.4.4.3.cmml" xref="S2.E3.m1.4.4.3"><times id="S2.E3.m1.4.4.3.1.cmml" xref="S2.E3.m1.4.4.3.1"></times><apply id="S2.E3.m1.4.4.3.2.cmml" xref="S2.E3.m1.4.4.3.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.3.2.1.cmml" xref="S2.E3.m1.4.4.3.2">subscript</csymbol><ci id="S2.E3.m1.4.4.3.2.2.cmml" xref="S2.E3.m1.4.4.3.2.2">ℒ</ci><ci id="S2.E3.m1.4.4.3.2.3a.cmml" xref="S2.E3.m1.4.4.3.2.3"><mtext mathsize="70%" id="S2.E3.m1.4.4.3.2.3.cmml" xref="S2.E3.m1.4.4.3.2.3">SFT</mtext></ci></apply><ci id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1">Θ</ci></apply><apply id="S2.E3.m1.4.4.1.cmml" xref="S2.E3.m1.4.4.1"><times id="S2.E3.m1.4.4.1.2.cmml" xref="S2.E3.m1.4.4.1.2"></times><apply id="S2.E3.m1.4.4.1.3.cmml" xref="S2.E3.m1.4.4.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.3.1.cmml" xref="S2.E3.m1.4.4.1.3">subscript</csymbol><ci id="S2.E3.m1.4.4.1.3.2.cmml" xref="S2.E3.m1.4.4.1.3.2">𝔼</ci><apply id="S2.E3.m1.4.4.1.3.3.cmml" xref="S2.E3.m1.4.4.1.3.3"><csymbol cd="latexml" id="S2.E3.m1.4.4.1.3.3.1.cmml" xref="S2.E3.m1.4.4.1.3.3.1">similar-to</csymbol><ci id="S2.E3.m1.4.4.1.3.3.2.cmml" xref="S2.E3.m1.4.4.1.3.3.2">𝒙</ci><apply id="S2.E3.m1.4.4.1.3.3.3.cmml" xref="S2.E3.m1.4.4.1.3.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.3.3.3.1.cmml" xref="S2.E3.m1.4.4.1.3.3.3">subscript</csymbol><ci id="S2.E3.m1.4.4.1.3.3.3.2.cmml" xref="S2.E3.m1.4.4.1.3.3.3.2">𝒟</ci><ci id="S2.E3.m1.4.4.1.3.3.3.3a.cmml" xref="S2.E3.m1.4.4.1.3.3.3.3"><mtext mathsize="50%" id="S2.E3.m1.4.4.1.3.3.3.3.cmml" xref="S2.E3.m1.4.4.1.3.3.3.3">SFT</mtext></ci></apply></apply></apply><apply id="S2.E3.m1.4.4.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.4.4.1.1.2.1.cmml" xref="S2.E3.m1.4.4.1.1.1.2">delimited-[]</csymbol><apply id="S2.E3.m1.4.4.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1"><minus id="S2.E3.m1.4.4.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1"></minus><apply id="S2.E3.m1.4.4.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1"><apply id="S2.E3.m1.4.4.1.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2">subscript</csymbol><sum id="S2.E3.m1.4.4.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.2"></sum><apply id="S2.E3.m1.4.4.1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3"><in id="S2.E3.m1.4.4.1.1.1.1.1.2.3.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.1"></in><ci id="S2.E3.m1.4.4.1.1.1.1.1.2.3.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.2">𝑖</ci><ci id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3d.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3"><mrow id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3"><mtext mathsize="70%" id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3a.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3">{</mtext><mtext class="ltx_mathvariant_italic" mathsize="70%" id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3b.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3">output</mtext><mtext mathsize="70%" id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3c.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3">}</mtext></mrow></ci></apply></apply><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1"><times id="S2.E3.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.2"></times><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3"><log id="S2.E3.m1.4.4.1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3.1"></log><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3.2">𝑝</ci></apply><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.4.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.4">conditional</csymbol><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.2">𝑥</ci><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.3">𝑖</ci></apply><list id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3"><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><cn type="integer" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3">0</cn></apply><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2">𝑥</ci><cn type="integer" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3">1</cn></apply><ci id="S2.E3.m1.2.2.cmml" xref="S2.E3.m1.2.2">…</ci><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2">𝑥</ci><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3"><minus id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1"></minus><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2">𝑖</ci><cn type="integer" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3">1</cn></apply></apply><ci id="S2.E3.m1.3.3.cmml" xref="S2.E3.m1.3.3">Θ</ci></list></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.4c">\displaystyle\mathcal{L}_{\textrm{SFT}}(\Theta)=\mathbb{E}_{\bm{x}\sim\mathcal{D}_{\textrm{SFT}}}\left[-\sum_{i\in\textit{\{output\}}}\log p(x_{i}|x_{0},x_{1},\ldots,x_{i-1};\Theta)\right]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.SS5.p4.3" class="ltx_p">Here, <math id="S2.SS5.p4.1.m1.1" class="ltx_Math" alttext="\Theta" display="inline"><semantics id="S2.SS5.p4.1.m1.1a"><mi mathvariant="normal" id="S2.SS5.p4.1.m1.1.1" xref="S2.SS5.p4.1.m1.1.1.cmml">Θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS5.p4.1.m1.1b"><ci id="S2.SS5.p4.1.m1.1.1.cmml" xref="S2.SS5.p4.1.m1.1.1">Θ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p4.1.m1.1c">\Theta</annotation></semantics></math> represents the model parameters, <math id="S2.SS5.p4.2.m2.1" class="ltx_Math" alttext="\mathcal{D}_{\textrm{SFT}}" display="inline"><semantics id="S2.SS5.p4.2.m2.1a"><msub id="S2.SS5.p4.2.m2.1.1" xref="S2.SS5.p4.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS5.p4.2.m2.1.1.2" xref="S2.SS5.p4.2.m2.1.1.2.cmml">𝒟</mi><mtext id="S2.SS5.p4.2.m2.1.1.3" xref="S2.SS5.p4.2.m2.1.1.3a.cmml">SFT</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS5.p4.2.m2.1b"><apply id="S2.SS5.p4.2.m2.1.1.cmml" xref="S2.SS5.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS5.p4.2.m2.1.1.1.cmml" xref="S2.SS5.p4.2.m2.1.1">subscript</csymbol><ci id="S2.SS5.p4.2.m2.1.1.2.cmml" xref="S2.SS5.p4.2.m2.1.1.2">𝒟</ci><ci id="S2.SS5.p4.2.m2.1.1.3a.cmml" xref="S2.SS5.p4.2.m2.1.1.3"><mtext mathsize="70%" id="S2.SS5.p4.2.m2.1.1.3.cmml" xref="S2.SS5.p4.2.m2.1.1.3">SFT</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p4.2.m2.1c">\mathcal{D}_{\textrm{SFT}}</annotation></semantics></math> is the fine-tuning dataset, <math id="S2.SS5.p4.3.m3.3" class="ltx_Math" alttext="\bm{x}=(x_{0},x_{1},\ldots)" display="inline"><semantics id="S2.SS5.p4.3.m3.3a"><mrow id="S2.SS5.p4.3.m3.3.3" xref="S2.SS5.p4.3.m3.3.3.cmml"><mi id="S2.SS5.p4.3.m3.3.3.4" xref="S2.SS5.p4.3.m3.3.3.4.cmml">𝒙</mi><mo id="S2.SS5.p4.3.m3.3.3.3" xref="S2.SS5.p4.3.m3.3.3.3.cmml">=</mo><mrow id="S2.SS5.p4.3.m3.3.3.2.2" xref="S2.SS5.p4.3.m3.3.3.2.3.cmml"><mo stretchy="false" id="S2.SS5.p4.3.m3.3.3.2.2.3" xref="S2.SS5.p4.3.m3.3.3.2.3.cmml">(</mo><msub id="S2.SS5.p4.3.m3.2.2.1.1.1" xref="S2.SS5.p4.3.m3.2.2.1.1.1.cmml"><mi id="S2.SS5.p4.3.m3.2.2.1.1.1.2" xref="S2.SS5.p4.3.m3.2.2.1.1.1.2.cmml">x</mi><mn id="S2.SS5.p4.3.m3.2.2.1.1.1.3" xref="S2.SS5.p4.3.m3.2.2.1.1.1.3.cmml">0</mn></msub><mo id="S2.SS5.p4.3.m3.3.3.2.2.4" xref="S2.SS5.p4.3.m3.3.3.2.3.cmml">,</mo><msub id="S2.SS5.p4.3.m3.3.3.2.2.2" xref="S2.SS5.p4.3.m3.3.3.2.2.2.cmml"><mi id="S2.SS5.p4.3.m3.3.3.2.2.2.2" xref="S2.SS5.p4.3.m3.3.3.2.2.2.2.cmml">x</mi><mn id="S2.SS5.p4.3.m3.3.3.2.2.2.3" xref="S2.SS5.p4.3.m3.3.3.2.2.2.3.cmml">1</mn></msub><mo id="S2.SS5.p4.3.m3.3.3.2.2.5" xref="S2.SS5.p4.3.m3.3.3.2.3.cmml">,</mo><mi mathvariant="normal" id="S2.SS5.p4.3.m3.1.1" xref="S2.SS5.p4.3.m3.1.1.cmml">…</mi><mo stretchy="false" id="S2.SS5.p4.3.m3.3.3.2.2.6" xref="S2.SS5.p4.3.m3.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS5.p4.3.m3.3b"><apply id="S2.SS5.p4.3.m3.3.3.cmml" xref="S2.SS5.p4.3.m3.3.3"><eq id="S2.SS5.p4.3.m3.3.3.3.cmml" xref="S2.SS5.p4.3.m3.3.3.3"></eq><ci id="S2.SS5.p4.3.m3.3.3.4.cmml" xref="S2.SS5.p4.3.m3.3.3.4">𝒙</ci><vector id="S2.SS5.p4.3.m3.3.3.2.3.cmml" xref="S2.SS5.p4.3.m3.3.3.2.2"><apply id="S2.SS5.p4.3.m3.2.2.1.1.1.cmml" xref="S2.SS5.p4.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS5.p4.3.m3.2.2.1.1.1.1.cmml" xref="S2.SS5.p4.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S2.SS5.p4.3.m3.2.2.1.1.1.2.cmml" xref="S2.SS5.p4.3.m3.2.2.1.1.1.2">𝑥</ci><cn type="integer" id="S2.SS5.p4.3.m3.2.2.1.1.1.3.cmml" xref="S2.SS5.p4.3.m3.2.2.1.1.1.3">0</cn></apply><apply id="S2.SS5.p4.3.m3.3.3.2.2.2.cmml" xref="S2.SS5.p4.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS5.p4.3.m3.3.3.2.2.2.1.cmml" xref="S2.SS5.p4.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S2.SS5.p4.3.m3.3.3.2.2.2.2.cmml" xref="S2.SS5.p4.3.m3.3.3.2.2.2.2">𝑥</ci><cn type="integer" id="S2.SS5.p4.3.m3.3.3.2.2.2.3.cmml" xref="S2.SS5.p4.3.m3.3.3.2.2.2.3">1</cn></apply><ci id="S2.SS5.p4.3.m3.1.1.cmml" xref="S2.SS5.p4.3.m3.1.1">…</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p4.3.m3.3c">\bm{x}=(x_{0},x_{1},\ldots)</annotation></semantics></math> represents the tokenized input sequence.</p>
</div>
<div id="S2.SS5.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS5.p5.1">우리의 접근법과 Stanford Alpaca의 주요 차이점은 <em class="ltx_emph ltx_font_italic" id="S2.SS5.p5.1.1">input</em> 필드가 없는 예제에 대해 설계된 프롬프트 템플릿만 사용하는 반면, Stanford Alpaca는 <em class="ltx_emph ltx_font_italic" id="S2.SS5.p5.1.2">input</em> 필드가 있거나 없는 예제에 대해 두 개의 템플릿을 사용한다는 것입니다. 예제가 비어 있지 않은 <em class="ltx_emph ltx_font_italic" id="S2.SS5.p5.1.3">input</em> 필드를 포함하는 경우, <em class="ltx_emph ltx_font_italic" id="S2.SS5.p5.1.4">instruction</em> 및 <em class="ltx_emph ltx_font_italic" id="S2.SS5.p5.1.5">input</em>을 <em class="ltx_emph ltx_font_italic" id="S2.SS5.p5.1.6">“\n”</em>과 연결하여 새 명령을 형성합니다. 중국어 알파카 모델에 대한 추가 패딩 토큰이 있어 어휘 크기가 49,954가 된다.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Setups</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Experimental Setups for Pre-training</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p1.1">우리는 원래 LLaMA 가중치로 중국 LLaMA 모델을 초기화하고 7B 및 13B 모델에서 fp16을 사용하여 사전 훈련을 수행한다. 또한, 33B 모델의 경우 8비트 포맷으로 학습하기 위해 bitsandbytes<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/TimDettmers/bitsandbytes" target="_blank" title="">https://github.com/TimDettmers/bitsandbytes</a></span></span></span> 라이브러리를 사용하여 효율성과 메모리 사용량을 향상시켰다. 우리는 임베딩과 LM 헤드를 훈련 가능한 것으로 설정하면서 훈련을 위해 관심 및 MLP에 LoRA를 직접 적용한다.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p2.1">중국 LLaMA-7B의 기본 버전을 위해 2단계 사전 훈련 접근법을 사용한다. 1단계에서는 모델 내에서 변압기 인코더의 파라미터를 고정하고 임베딩만을 훈련하여 외란을 최소화하면서 새로 추가된 한자어 벡터를 원래 모델에 적용한다. 2단계에서는 주의 메커니즘에 LoRA 가중치(어댑터)를 추가하고 임베딩, LM 헤드 및 새로 추가된 LoRA 매개변수를 훈련한다. 2단계 훈련은 예비 연구에서 덜 효율적이기 때문에 다른 모델 훈련에는 적용되지 않는다.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p3.1">다른 중국 LLaMA 모델(기본 버전)의 경우, 사전 훈련을 위해 20GB 일반 중국 말뭉치를 활용하는데, 이는 중국 BERT-wwm <cite class="ltx_cite ltx_citemacro_citep">(Cui et al., <a class="ltx_ref" href="#bib.bib2" title="">2021</a>)</cite>, MacBERT <cite class="ltx_cite ltx_citemacro_citep">(Cui et al., <a class="ltx_ref" href="#bib.bib1" title="">2020</a>)</cite>, LERT <cite class="ltx_cite ltx_citemacro_citep">(Cui et al., <a class="ltx_ref" href="#bib.bib3" title="">2022</a>)</cite> 등이 사용하는 말뭉치와 일치한다. 또한 커먼크롤(CC) 및 백과사전 소스의 추가 데이터를 통합하여 기본 개념에 대한 모델의 이해를 향상시키는 사전 학습 데이터를 120GB로 추가로 확장하는 "플러스" 버전을 제공한다. 사전 훈련을 위해 모든 데이터 세트와 블록 크기 512의 청크를 연결한다.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p4.1">모델은 A40 GPU(48GB VRAM)에서 하나의 에포크 동안 훈련되며, 모델 크기에 따라 최대 48개의 GPU를 차지한다. LoRA를 사용한 파라미터 효율적인 훈련은 PEFT 라이브러리<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/huggingface/peft" target="_blank" title="">https://github.com/huggingface/peft</a></span></span></span>로 수행된다. 또한 훈련 과정에서 메모리 효율을 최적화하기 위해 DeepSpeed <cite class="ltx_cite ltx_citemacro_citep">(Rasley et al., <a class="ltx_ref" href="#bib.bib18" title="">2020</a>)</cite>를 활용한다. AdamW 최적화기 <cite class="ltx_cite ltx_citemacro_citep">(Loshchilov &amp; Hutter, <a class="ltx_ref" href="#bib.bib13" title="">2019</a>)</cite>를 사용하였으며, 최대 학습률은 2e-4와 5% 워밍업 코사인 스케줄러를 사용하였다. 또한, 전위 기울기 폭발을 완화하기 위해 1.0의 값을 갖는 기울기 클리핑을 적용한다.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS1.p5.1">각 중국 LLaMA 모델에 대한 상세한 하이퍼파라미터는 표 <a class="ltx_ref" href="#S3.T2" title="Table 2 ‣ 3.1 Experimental Setups for Pre-training ‣ 3 Experimental Setups ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">2</span></a>에 나열되어 있다.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 2:</span> <span class="ltx_text ltx_font_bold" id="S3.T2.2.1">Pre-training hyperparameters for Chinese LLaMA. </span> QKVO: 각 주의 모듈에서 4개의 행렬, 즉 쿼리, 키, 값 및 출력. MLP: 각 MLP 계층에서 세 개의 행렬. 7B는 2단계 훈련 패러다임(설정은 '/'로 분리됨)을 사용하는데, 이는 다른 모델에서는 더 이상 채택되지 않는다.</figcaption>
<table id="S3.T2.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T2.3.1" class="ltx_tr">
<td id="S3.T2.3.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T2.3.1.1.1" class="ltx_text ltx_font_bold">Settings</span></td>
<td id="S3.T2.3.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T2.3.1.2.1" class="ltx_text ltx_font_bold">7B</span></td>
<td id="S3.T2.3.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T2.3.1.3.1" class="ltx_text ltx_font_bold">Plus-7B</span></td>
<td id="S3.T2.3.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T2.3.1.4.1" class="ltx_text ltx_font_bold">13B</span></td>
<td id="S3.T2.3.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T2.3.1.5.1" class="ltx_text ltx_font_bold">Plus-13B</span></td>
<td id="S3.T2.3.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T2.3.1.6.1" class="ltx_text ltx_font_bold">33B</span></td>
</tr>
<tr id="S3.T2.3.2" class="ltx_tr">
<td id="S3.T2.3.2.1" class="ltx_td ltx_align_left ltx_border_t">Training data</td>
<td id="S3.T2.3.2.2" class="ltx_td ltx_align_center ltx_border_t">20 GB</td>
<td id="S3.T2.3.2.3" class="ltx_td ltx_align_center ltx_border_t">120 GB</td>
<td id="S3.T2.3.2.4" class="ltx_td ltx_align_center ltx_border_t">20 GB</td>
<td id="S3.T2.3.2.5" class="ltx_td ltx_align_center ltx_border_t">120 GB</td>
<td id="S3.T2.3.2.6" class="ltx_td ltx_align_center ltx_border_t">20 GB</td>
</tr>
<tr id="S3.T2.3.3" class="ltx_tr">
<td id="S3.T2.3.3.1" class="ltx_td ltx_align_left">Batch size</td>
<td id="S3.T2.3.3.2" class="ltx_td ltx_align_center">1,024</td>
<td id="S3.T2.3.3.3" class="ltx_td ltx_align_center">2,304</td>
<td id="S3.T2.3.3.4" class="ltx_td ltx_align_center">2,304</td>
<td id="S3.T2.3.3.5" class="ltx_td ltx_align_center">2,304</td>
<td id="S3.T2.3.3.6" class="ltx_td ltx_align_center">2,304</td>
</tr>
<tr id="S3.T2.3.4" class="ltx_tr">
<td id="S3.T2.3.4.1" class="ltx_td ltx_align_left">Peak learning rate</td>
<td id="S3.T2.3.4.2" class="ltx_td ltx_align_center">2e-4/1e-4</td>
<td id="S3.T2.3.4.3" class="ltx_td ltx_align_center">2e-4</td>
<td id="S3.T2.3.4.4" class="ltx_td ltx_align_center">2e-4</td>
<td id="S3.T2.3.4.5" class="ltx_td ltx_align_center">2e-4</td>
<td id="S3.T2.3.4.6" class="ltx_td ltx_align_center">2e-4</td>
</tr>
<tr id="S3.T2.3.5" class="ltx_tr">
<td id="S3.T2.3.5.1" class="ltx_td ltx_align_left">Max sequence length</td>
<td id="S3.T2.3.5.2" class="ltx_td ltx_align_center">512</td>
<td id="S3.T2.3.5.3" class="ltx_td ltx_align_center">512</td>
<td id="S3.T2.3.5.4" class="ltx_td ltx_align_center">512</td>
<td id="S3.T2.3.5.5" class="ltx_td ltx_align_center">512</td>
<td id="S3.T2.3.5.6" class="ltx_td ltx_align_center">512</td>
</tr>
<tr id="S3.T2.3.6" class="ltx_tr">
<td id="S3.T2.3.6.1" class="ltx_td ltx_align_left">LoRA rank</td>
<td id="S3.T2.3.6.2" class="ltx_td ltx_align_center">-/8</td>
<td id="S3.T2.3.6.3" class="ltx_td ltx_align_center">8</td>
<td id="S3.T2.3.6.4" class="ltx_td ltx_align_center">8</td>
<td id="S3.T2.3.6.5" class="ltx_td ltx_align_center">8</td>
<td id="S3.T2.3.6.6" class="ltx_td ltx_align_center">8</td>
</tr>
<tr id="S3.T2.3.7" class="ltx_tr">
<td id="S3.T2.3.7.1" class="ltx_td ltx_align_left">LoRA alpha</td>
<td id="S3.T2.3.7.2" class="ltx_td ltx_align_center">-/32</td>
<td id="S3.T2.3.7.3" class="ltx_td ltx_align_center">32</td>
<td id="S3.T2.3.7.4" class="ltx_td ltx_align_center">32</td>
<td id="S3.T2.3.7.5" class="ltx_td ltx_align_center">32</td>
<td id="S3.T2.3.7.6" class="ltx_td ltx_align_center">32</td>
</tr>
<tr id="S3.T2.3.8" class="ltx_tr">
<td id="S3.T2.3.8.1" class="ltx_td ltx_align_left">LoRA weights</td>
<td id="S3.T2.3.8.2" class="ltx_td ltx_align_center">-/QKVO</td>
<td id="S3.T2.3.8.3" class="ltx_td ltx_align_center">QKVO, MLP</td>
<td id="S3.T2.3.8.4" class="ltx_td ltx_align_center">QKVO, MLP</td>
<td id="S3.T2.3.8.5" class="ltx_td ltx_align_center">QKVO, MLP</td>
<td id="S3.T2.3.8.6" class="ltx_td ltx_align_center">QKVO, MLP</td>
</tr>
<tr id="S3.T2.3.9" class="ltx_tr">
<td id="S3.T2.3.9.1" class="ltx_td ltx_align_left ltx_border_bb">Trainable params (%)</td>
<td id="S3.T2.3.9.2" class="ltx_td ltx_align_center ltx_border_bb">2.97%/6.06%</td>
<td id="S3.T2.3.9.3" class="ltx_td ltx_align_center ltx_border_bb">6.22%</td>
<td id="S3.T2.3.9.4" class="ltx_td ltx_align_center ltx_border_bb">4.10%</td>
<td id="S3.T2.3.9.5" class="ltx_td ltx_align_center ltx_border_bb">4.10%</td>
<td id="S3.T2.3.9.6" class="ltx_td ltx_align_center ltx_border_bb">2.21%</td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Experimental Setups for Instruction Fine-tuning</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p1.1">중국 LLaMA 모델을 얻은 후 섹션 <a class="ltx_ref" href="#S2.SS5" title="2.5 Supervised Fine-Tuning and Chinese Alpaca ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">2.5</span></a>에 따라 미세 조정한다. 우리는 기본 모델의 모든 선형 레이어에 LoRA 모듈을 추가하여 효율적인 미세 조정을 위해 LoRA를 계속 사용한다. 우리는 번역 <cite class="ltx_cite ltx_citemacro_citep">(Xu, <a class="ltx_ref" href="#bib.bib27" title="">2019</a>)</cite> (550K 샘플링), pCLUE<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/CLUEbenchmark/pCLUE" target="_blank" title="">https://github.com/CLUEbenchmark/pCLUE</a></span></span></span> (250K 샘플링, “NLU-like” 데이터를 제외), Stanford Alpaca (50K+50K for original and translated one), 그리고 기본 모델을 튜닝하기 위해 크롤링된 SFT 데이터를 포함한다. 플러스 버전의 경우 STEM(과학, 기술, 공학 및 수학) 데이터와 물리, 화학, 생물학, 의학 및 지구과학과 같은 여러 과학 분야를 통합하는 데 중점을 두고 데이터 세트를 약 4M에서 4.3M으로 확장한다. Alpaca-33B의 경우 OASST1 데이터 세트 <cite class="ltx_cite ltx_citemacro_citep">(Köpf et al., <a class="ltx_ref" href="#bib.bib10" title="">2023</a>)</cite>를 추가로 추가합니다. 여기서 각 대화에서 첫 번째 쿼리-응답 쌍만 추출하고 <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.1">gpt-3.5-turbo</span> API를 사용하여 번역하면 대략 20K 데이터(원본 및 번역된 데이터)가 생성됩니다. 우리는 최대 시퀀스 길이를 512로 설정하고 배치에서 최대 길이로 배칭할 때 샘플을 동적으로 패딩한다.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p2.1">크롤링된 데이터의 경우, <cite class="ltx_cite ltx_citemacro_citet">Taori et al. (<a class="ltx_ref" href="#bib.bib22" title="">2023a</a>)</cite>에서 사용되는 ChatGPT(<span class="ltx_text ltx_font_typewriter" id="S3.SS2.p2.1.1">gpt-3.5-turbo</span> API)로부터 데이터를 자동으로 얻기 위한 self-instruct <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib26" title="">2022</a>)</cite> 방법을 참조한다. 구체적으로, 대상 도메인 및 명령 유형에 대한 요구 사항만 있는 시드 작업을 필요로 하지 않는 보다 단순화된 템플릿을 활용한다. 템플릿 및 코드 세부 정보는 GitHub에서 사용할 수 있습니다. <span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ymcui/Chinese-LLaMA-Alpaca/blob/main/scripts/crawl_prompt.py" target="_blank" title="">https://github.com/ymcui/Chinese-LLaMA-Alpaca/blob/main/scripts/crawl_prompt.py</a></span></span></span></p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 3:</span> 중국어 Alpaca에 대한 명령어 미세 조정 하이퍼파라미터.</figcaption>
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T3.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T3.1.1.1.1" class="ltx_text ltx_font_bold">Settings</span></td>
<td id="S3.T3.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.2.1" class="ltx_text ltx_font_bold">7B</span></td>
<td id="S3.T3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.3.1" class="ltx_text ltx_font_bold">Plus-7B</span></td>
<td id="S3.T3.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.4.1" class="ltx_text ltx_font_bold">13B</span></td>
<td id="S3.T3.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.5.1" class="ltx_text ltx_font_bold">Plus-13B</span></td>
<td id="S3.T3.1.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.6.1" class="ltx_text ltx_font_bold">33B</span></td>
</tr>
<tr id="S3.T3.1.2" class="ltx_tr">
<td id="S3.T3.1.2.1" class="ltx_td ltx_align_left ltx_border_t">Training data</td>
<td id="S3.T3.1.2.2" class="ltx_td ltx_align_center ltx_border_t">2M</td>
<td id="S3.T3.1.2.3" class="ltx_td ltx_align_center ltx_border_t">4M</td>
<td id="S3.T3.1.2.4" class="ltx_td ltx_align_center ltx_border_t">3M</td>
<td id="S3.T3.1.2.5" class="ltx_td ltx_align_center ltx_border_t">4.3M</td>
<td id="S3.T3.1.2.6" class="ltx_td ltx_align_center ltx_border_t">4.3M</td>
</tr>
<tr id="S3.T3.1.3" class="ltx_tr">
<td id="S3.T3.1.3.1" class="ltx_td ltx_align_left">Batch size</td>
<td id="S3.T3.1.3.2" class="ltx_td ltx_align_center">512</td>
<td id="S3.T3.1.3.3" class="ltx_td ltx_align_center">1,152</td>
<td id="S3.T3.1.3.4" class="ltx_td ltx_align_center">1,152</td>
<td id="S3.T3.1.3.5" class="ltx_td ltx_align_center">1,152</td>
<td id="S3.T3.1.3.6" class="ltx_td ltx_align_center">1,152</td>
</tr>
<tr id="S3.T3.1.4" class="ltx_tr">
<td id="S3.T3.1.4.1" class="ltx_td ltx_align_left">Peak learning rate</td>
<td id="S3.T3.1.4.2" class="ltx_td ltx_align_center">1e-4</td>
<td id="S3.T3.1.4.3" class="ltx_td ltx_align_center">1e-4</td>
<td id="S3.T3.1.4.4" class="ltx_td ltx_align_center">1e-4</td>
<td id="S3.T3.1.4.5" class="ltx_td ltx_align_center">1e-4</td>
<td id="S3.T3.1.4.6" class="ltx_td ltx_align_center">1e-4</td>
</tr>
<tr id="S3.T3.1.5" class="ltx_tr">
<td id="S3.T3.1.5.1" class="ltx_td ltx_align_left">Max sequence length</td>
<td id="S3.T3.1.5.2" class="ltx_td ltx_align_center">512</td>
<td id="S3.T3.1.5.3" class="ltx_td ltx_align_center">512</td>
<td id="S3.T3.1.5.4" class="ltx_td ltx_align_center">512</td>
<td id="S3.T3.1.5.5" class="ltx_td ltx_align_center">512</td>
<td id="S3.T3.1.5.6" class="ltx_td ltx_align_center">512</td>
</tr>
<tr id="S3.T3.1.6" class="ltx_tr">
<td id="S3.T3.1.6.1" class="ltx_td ltx_align_left">LoRA rank</td>
<td id="S3.T3.1.6.2" class="ltx_td ltx_align_center">8</td>
<td id="S3.T3.1.6.3" class="ltx_td ltx_align_center">64</td>
<td id="S3.T3.1.6.4" class="ltx_td ltx_align_center">8</td>
<td id="S3.T3.1.6.5" class="ltx_td ltx_align_center">64</td>
<td id="S3.T3.1.6.6" class="ltx_td ltx_align_center">8</td>
</tr>
<tr id="S3.T3.1.7" class="ltx_tr">
<td id="S3.T3.1.7.1" class="ltx_td ltx_align_left">LoRA alpha</td>
<td id="S3.T3.1.7.2" class="ltx_td ltx_align_center">32</td>
<td id="S3.T3.1.7.3" class="ltx_td ltx_align_center">128</td>
<td id="S3.T3.1.7.4" class="ltx_td ltx_align_center">32</td>
<td id="S3.T3.1.7.5" class="ltx_td ltx_align_center">128</td>
<td id="S3.T3.1.7.6" class="ltx_td ltx_align_center">32</td>
</tr>
<tr id="S3.T3.1.8" class="ltx_tr">
<td id="S3.T3.1.8.1" class="ltx_td ltx_align_left">LoRA weights</td>
<td id="S3.T3.1.8.2" class="ltx_td ltx_align_center">QKVO, MLP</td>
<td id="S3.T3.1.8.3" class="ltx_td ltx_align_center">QKVO, MLP</td>
<td id="S3.T3.1.8.4" class="ltx_td ltx_align_center">QKVO, MLP</td>
<td id="S3.T3.1.8.5" class="ltx_td ltx_align_center">QKVO, MLP</td>
<td id="S3.T3.1.8.6" class="ltx_td ltx_align_center">QKVO, MLP</td>
</tr>
<tr id="S3.T3.1.9" class="ltx_tr">
<td id="S3.T3.1.9.1" class="ltx_td ltx_align_left ltx_border_bb">Trainable params (%)</td>
<td id="S3.T3.1.9.2" class="ltx_td ltx_align_center ltx_border_bb">6.22%</td>
<td id="S3.T3.1.9.3" class="ltx_td ltx_align_center ltx_border_bb">8.08%</td>
<td id="S3.T3.1.9.4" class="ltx_td ltx_align_center ltx_border_bb">4.10%</td>
<td id="S3.T3.1.9.5" class="ltx_td ltx_align_center ltx_border_bb">5.66%</td>
<td id="S3.T3.1.9.6" class="ltx_td ltx_align_center ltx_border_bb">2.21%</td>
</tr>
</tbody></table>
</figure>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p3.1">플러스 버전의 경우 기본 버전에 비해 더 큰 LoRA 순위를 활용합니다. 학습 속도와 배치 크기를 조정하는 것 외에도 사전 훈련 단계에서 사용되는 다른 하이퍼파라미터 및 설정과 일관성을 유지한다.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p4.1">명령어 미세 조정을 위한 하이퍼파라미터는 표 <a class="ltx_ref" href="#S3.T3" title="Table 3 ‣ 3.2 Experimental Setups for Instruction Fine-tuning ‣ 3 Experimental Setups ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">3</span></a>에 나열되어 있다. 모든 알파카 모델은 각각의 LLaMA 모델에 기초하여 트레이닝된다는 점에 유의한다. 예를 들어, 중국 Alpaca-Plus-13B는 중국 LLaMA-Plus-13B로 훈련된다.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results on Instruction-Following Tasks</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Task Design and Evaluation Method</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.p1.1">텍스트 생성 과제의 성능을 평가하는 것은 그 형태의 편차가 크기 때문에 어려울 수 있으며, 이는 텍스트 분류 및 추출적 기계 독해와 같은 자연어 이해 과제와 크게 다르다. 채점 방법으로 GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="#bib.bib15" title="">2023</a>)</cite>를 사용한 이전 연구에 이어, 우리는 또한 GPT-4를 채택하여 각 샘플에 대해 전체 점수(10점 척도)를 제공하여 인간 평가보다 더 효율적이다. 그러나 GPT-4는 항상 정확한 점수를 제공하지 않을 수 있으므로 등급에 대한 수동 검사를 수행하고 필요한 경우 조정한다. 수동 검사는 점수가 일관되고 평가되는 모델의 실제 성능을 반영하는지 확인합니다. 다음 프롬프트 템플릿을 사용하여 시스템의 두 출력(여러 시스템으로 조정할 수 있음)을 채점합니다.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<blockquote id="S4.SS1.p2.1" class="ltx_quote">
<p class="ltx_p" id="S4.SS1.p2.1.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.1.1">다음은 두 ChatGPT 유사 시스템의 출력입니다. 각 점수에 대해 10점 척도로 전체 점수를 평가하고 점수를 정당화할 수 있는 설명을 해주십시오. </span></p>
<p id="S4.SS1.p2.1.2" class="ltx_p"><span id="S4.SS1.p2.1.2.1" class="ltx_text ltx_font_italic">Prompt:</span></p>
<p id="S4.SS1.p2.1.3" class="ltx_p">{<span id="S4.SS1.p2.1.3.1" class="ltx_text ltx_font_italic">prompt-input</span>}<span id="S4.SS1.p2.1.3.2" class="ltx_text ltx_font_italic"></span></p>
<p id="S4.SS1.p2.1.4" class="ltx_p"><span id="S4.SS1.p2.1.4.1" class="ltx_text ltx_font_italic">System1:</span></p>
<p class="ltx_p" id="S4.SS1.p2.1.5">{<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.5.1">system1-output</span>}<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.5.2"></span></p>
<p id="S4.SS1.p2.1.6" class="ltx_p"><span id="S4.SS1.p2.1.6.1" class="ltx_text ltx_font_italic">System2:</span></p>
<p class="ltx_p" id="S4.SS1.p2.1.7">{<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.7.1">system2-output</span>}<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.7.2"></span></p>
</blockquote>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.p3.1">수작업 검사와 함께 GPT-4를 채점 방법으로 사용하여 다양한 자연어 이해 및 생성 작업에 대한 중국 알파카 모델의 성능을 효과적으로 측정하는 신뢰할 수 있는 평가 프레임워크를 구축한다.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.p4.1">우리의 평가 세트는 광범위한 자연어 이해 및 생성 작업에 걸쳐 중국 알파카 모델을 종합적으로 평가하도록 설계되었다. 집합은 질문 응답, 추론, 문학, 엔터테인먼트, 번역, 다중 회전 대화, 코딩 및 윤리 등을 포함한 10가지 별개의 작업을 포함하는 200개의 샘플로 구성된다. 특정 작업에 대한 전체 점수는 해당 작업 내의 모든 샘플에 대한 점수를 합산하고 총계를 100점 척도로 정규화하여 계산된다. 이 접근법은 평가 세트가 다양한 작업에 걸쳐 모델의 능력을 반영하도록 하여 모델의 성능에 대한 균형 있고 강력한 척도를 제공한다.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Experimental Setups for Decoding</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.p1.1">LLM들의 디코딩 프로세스는 생성된 텍스트의 품질 및 다양성을 결정하는 데 중요한 역할을 한다. 실험에서는 다음과 같은 디코딩 하이퍼파라미터를 사용한다.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i1.p1.1">컨텍스트 크기: 텍스트를 생성할 때 모델이 동시에 고려할 수 있는 최대 토큰 수를 결정하는 컨텍스트 크기를 2048로 설정합니다.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i2.p1.1">최대 시퀀스 길이: 생성된 시퀀스 길이를 512 토큰으로 제한하여 출력들이 포커스를 유지하고 입력 프롬프트와 관련되도록 한다.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i3.p1.1">온도: 샘플링 과정의 무작위성을 제어하는 온도를 0.2로 설정했다. 낮은 값은 모델이 더 집중되고 결정론적 출력을 생성하도록 만드는 반면, 높은 값은 일관성의 비용으로 다양성을 증가시킨다. 멀티턴 대화 및 생성 작업의 경우 온도를 0.5로 약간 조정하여 보다 다양한 출력을 허용한다.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i4.p1.3">Top-<math alttext="k" class="ltx_Math" display="inline" id="S4.I1.i4.p1.1.m1.1"><semantics id="S4.I1.i4.p1.1.m1.1a"><mi id="S4.I1.i4.p1.1.m1.1.1" xref="S4.I1.i4.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.1.m1.1b"><ci id="S4.I1.i4.p1.1.m1.1.1.cmml" xref="S4.I1.i4.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.1.m1.1c">k</annotation></semantics></math> sampling: Top-<math alttext="k" class="ltx_Math" display="inline" id="S4.I1.i4.p1.2.m2.1"><semantics id="S4.I1.i4.p1.2.m2.1a"><mi id="S4.I1.i4.p1.2.m2.1.1" xref="S4.I1.i4.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.2.m2.1b"><ci id="S4.I1.i4.p1.2.m2.1.1.cmml" xref="S4.I1.i4.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.2.m2.1c">k</annotation></semantics></math> sampling with <math alttext="k=40" class="ltx_Math" display="inline" id="S4.I1.i4.p1.3.m3.1"><semantics id="S4.I1.i4.p1.3.m3.1a"><mrow id="S4.I1.i4.p1.3.m3.1.1" xref="S4.I1.i4.p1.3.m3.1.1.cmml"><mi id="S4.I1.i4.p1.3.m3.1.1.2" xref="S4.I1.i4.p1.3.m3.1.1.2.cmml">k</mi><mo id="S4.I1.i4.p1.3.m3.1.1.1" xref="S4.I1.i4.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.I1.i4.p1.3.m3.1.1.3" xref="S4.I1.i4.p1.3.m3.1.1.3.cmml">40</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.3.m3.1b"><apply id="S4.I1.i4.p1.3.m3.1.1.cmml" xref="S4.I1.i4.p1.3.m3.1.1"><eq id="S4.I1.i4.p1.3.m3.1.1.1.cmml" xref="S4.I1.i4.p1.3.m3.1.1.1"></eq><ci id="S4.I1.i4.p1.3.m3.1.1.2.cmml" xref="S4.I1.i4.p1.3.m3.1.1.2">𝑘</ci><cn id="S4.I1.i4.p1.3.m3.1.1.3.cmml" type="integer" xref="S4.I1.i4.p1.3.m3.1.1.3">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.3.m3.1c">k=40</annotation></semantics></math>를 사용하여 각 단계에서 모델이 가장 가능성이 높은 상위 40개의 토큰 중에서 다음 토큰을 선택하여 생성된 텍스트에 랜덤성과 다양성의 요소를 추가한다.</p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i5.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i5.p1.3">Top-<math alttext="p" class="ltx_Math" display="inline" id="S4.I1.i5.p1.1.m1.1"><semantics id="S4.I1.i5.p1.1.m1.1a"><mi id="S4.I1.i5.p1.1.m1.1.1" xref="S4.I1.i5.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i5.p1.1.m1.1b"><ci id="S4.I1.i5.p1.1.m1.1.1.cmml" xref="S4.I1.i5.p1.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i5.p1.1.m1.1c">p</annotation></semantics></math> sampling: 또한 <math alttext="p" class="ltx_Math" display="inline" id="S4.I1.i5.p1.2.m2.1"><semantics id="S4.I1.i5.p1.2.m2.1a"><mi id="S4.I1.i5.p1.2.m2.1.1" xref="S4.I1.i5.p1.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i5.p1.2.m2.1b"><ci id="S4.I1.i5.p1.2.m2.1.1.cmml" xref="S4.I1.i5.p1.2.m2.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i5.p1.2.m2.1c">p</annotation></semantics></math> sampling with <math alttext="p=0.9" class="ltx_Math" display="inline" id="S4.I1.i5.p1.3.m3.1"><semantics id="S4.I1.i5.p1.3.m3.1a"><mrow id="S4.I1.i5.p1.3.m3.1.1" xref="S4.I1.i5.p1.3.m3.1.1.cmml"><mi id="S4.I1.i5.p1.3.m3.1.1.2" xref="S4.I1.i5.p1.3.m3.1.1.2.cmml">p</mi><mo id="S4.I1.i5.p1.3.m3.1.1.1" xref="S4.I1.i5.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.I1.i5.p1.3.m3.1.1.3" xref="S4.I1.i5.p1.3.m3.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i5.p1.3.m3.1b"><apply id="S4.I1.i5.p1.3.m3.1.1.cmml" xref="S4.I1.i5.p1.3.m3.1.1"><eq id="S4.I1.i5.p1.3.m3.1.1.1.cmml" xref="S4.I1.i5.p1.3.m3.1.1.1"></eq><ci id="S4.I1.i5.p1.3.m3.1.1.2.cmml" xref="S4.I1.i5.p1.3.m3.1.1.2">𝑝</ci><cn id="S4.I1.i5.p1.3.m3.1.1.3.cmml" type="float" xref="S4.I1.i5.p1.3.m3.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i5.p1.3.m3.1c">p=0.9</annotation></semantics></math>를 채용하는데, 이는 확률 질량의 90%를 집합적으로 차지하는 토큰들의 동적 집합을 고려함으로써 다이버시티를 더욱 향상시킨다.</p>
</div>
</li>
<li id="S4.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i6.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.I1.i6.p1.1">반복 패널티: 모델이 반복적인 텍스트를 생성하지 않도록 하기 위해, 우리는 이미 선택된 토큰에 벌점을 부여하는 1.1의 팩터를 갖는 반복 패널티를 적용한다.</p>
</div>
</li>
</ul>
</div>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.p3.1">이러한 값은 각 테스트 시나리오에 최적이 아닐 수 있습니다. 균형 잡힌 뷰를 유지하기 위해 각 작업에 대해 이러한 하이퍼파라미터에 대한 추가 튜닝을 수행하지 않았다.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Results</h3>

<div id="S4.SS3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.p1.1">중국 Alpaca-Plus-7B, Alpaca-Plus-13B 및 Alpaca-33B 모델로 얻은 결과를 제시하고 분석한다. Alpaca-33B 결과는 원래 모델(FP16)에 의해 생성되며, Alpaca-Plus-7B와 Alpaca-Plus-13B는 8비트 양자화 버전을 채택한다. <span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>We will discuss the quantization effect in Section <a class="ltx_ref" href="#S6" title="6 Effect of Different Quantization Methods ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">6</span></a>.</span></span></span> 전체적인 결과를 표 <a class="ltx_ref" href="#S4.T4" title="Table 4 ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">4</span></a>에 나타내었다. 평가는 총 200개의 샘플을 포함하는 10개의 별개의 NLP 작업에 걸쳐 GPT-4 등급 결과를 기반으로 한다. 제시된 점수는 서로만 비교할 수 있지만 시스템을 재구성해야 하는 다른 모델과는 비교할 수 없다는 점에 유의하는 것이 중요하다. 또한, 우리의 모델은 원래 LLaMA에 기반하기 때문에 이러한 관찰은 처음부터 훈련하기보다는 잘 확립된 모델에 기반할 때 더 나은 성능을 달성하는 데 중요한 측면으로 간주될 수 있다. 우리는 몇 가지 주요 범주의 발견에 대해 자세히 설명한다.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 4:</span> <span class="ltx_text ltx_font_bold" id="S4.T4.2.1">GPT-4 rated results for Chinese Alpaca-Plus-7B and Alpaca-Plus-13B, and Alpaca-33B. </span> 결과는 이 모델 조합 내에서만 비교할 수 있습니다.</figcaption>
<table id="S4.T4.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S4.T4.3.1" class="ltx_tr">
<td id="S4.T4.3.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T4.3.1.1.1" class="ltx_text ltx_font_bold">Task</span></td>
<td id="S4.T4.3.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T4.3.1.2.1" class="ltx_text ltx_font_bold">Alpaca-Plus-7B</span></td>
<td id="S4.T4.3.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T4.3.1.3.1" class="ltx_text ltx_font_bold">Alpaca-Plus-13B</span></td>
<td id="S4.T4.3.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T4.3.1.4.1" class="ltx_text ltx_font_bold">Alpaca-33B</span></td>
</tr>
<tr id="S4.T4.3.2" class="ltx_tr">
<td id="S4.T4.3.2.1" class="ltx_td ltx_align_left ltx_border_t">Question Answering</td>
<td id="S4.T4.3.2.2" class="ltx_td ltx_align_center ltx_border_t">70.5</td>
<td id="S4.T4.3.2.3" class="ltx_td ltx_align_center ltx_border_t">79.5</td>
<td id="S4.T4.3.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T4.3.2.4.1" class="ltx_text ltx_font_bold">82.3</span></td>
</tr>
<tr id="S4.T4.3.3" class="ltx_tr">
<td id="S4.T4.3.3.1" class="ltx_td ltx_align_left">Open-ended QA</td>
<td id="S4.T4.3.3.2" class="ltx_td ltx_align_center"><span id="S4.T4.3.3.2.1" class="ltx_text ltx_font_bold">80.5</span></td>
<td id="S4.T4.3.3.3" class="ltx_td ltx_align_center">80.0</td>
<td id="S4.T4.3.3.4" class="ltx_td ltx_align_center">78.5</td>
</tr>
<tr id="S4.T4.3.4" class="ltx_tr">
<td id="S4.T4.3.4.1" class="ltx_td ltx_align_left">Numerical Reasoning</td>
<td id="S4.T4.3.4.2" class="ltx_td ltx_align_center">51.0</td>
<td id="S4.T4.3.4.3" class="ltx_td ltx_align_center">61.5</td>
<td id="S4.T4.3.4.4" class="ltx_td ltx_align_center"><span id="S4.T4.3.4.4.1" class="ltx_text ltx_font_bold">84.5</span></td>
</tr>
<tr id="S4.T4.3.5" class="ltx_tr">
<td id="S4.T4.3.5.1" class="ltx_td ltx_align_left">Poetry, Literature, Philosophy</td>
<td id="S4.T4.3.5.2" class="ltx_td ltx_align_center">78.5</td>
<td id="S4.T4.3.5.3" class="ltx_td ltx_align_center"><span id="S4.T4.3.5.3.1" class="ltx_text ltx_font_bold">81.3</span></td>
<td id="S4.T4.3.5.4" class="ltx_td ltx_align_center">76.0</td>
</tr>
<tr id="S4.T4.3.6" class="ltx_tr">
<td id="S4.T4.3.6.1" class="ltx_td ltx_align_left">Music, Sports, Entertainment</td>
<td id="S4.T4.3.6.2" class="ltx_td ltx_align_center">72.3</td>
<td id="S4.T4.3.6.3" class="ltx_td ltx_align_center"><span id="S4.T4.3.6.3.1" class="ltx_text ltx_font_bold">76.8</span></td>
<td id="S4.T4.3.6.4" class="ltx_td ltx_align_center">72.5</td>
</tr>
<tr id="S4.T4.3.7" class="ltx_tr">
<td id="S4.T4.3.7.1" class="ltx_td ltx_align_left">Letters and Articles Writing</td>
<td id="S4.T4.3.7.2" class="ltx_td ltx_align_center">81.0</td>
<td id="S4.T4.3.7.3" class="ltx_td ltx_align_center"><span id="S4.T4.3.7.3.1" class="ltx_text ltx_font_bold">86.5</span></td>
<td id="S4.T4.3.7.4" class="ltx_td ltx_align_center">79.0</td>
</tr>
<tr id="S4.T4.3.8" class="ltx_tr">
<td id="S4.T4.3.8.1" class="ltx_td ltx_align_left">Translation</td>
<td id="S4.T4.3.8.2" class="ltx_td ltx_align_center">86.8</td>
<td id="S4.T4.3.8.3" class="ltx_td ltx_align_center">89.3</td>
<td id="S4.T4.3.8.4" class="ltx_td ltx_align_center"><span id="S4.T4.3.8.4.1" class="ltx_text ltx_font_bold">92.3</span></td>
</tr>
<tr id="S4.T4.3.9" class="ltx_tr">
<td id="S4.T4.3.9.1" class="ltx_td ltx_align_left">Multi-turn Dialogue</td>
<td id="S4.T4.3.9.2" class="ltx_td ltx_align_center">80.3</td>
<td id="S4.T4.3.9.3" class="ltx_td ltx_align_center"><span id="S4.T4.3.9.3.1" class="ltx_text ltx_font_bold">81.3</span></td>
<td id="S4.T4.3.9.4" class="ltx_td ltx_align_center">78.0</td>
</tr>
<tr id="S4.T4.3.10" class="ltx_tr">
<td id="S4.T4.3.10.1" class="ltx_td ltx_align_left">Coding</td>
<td id="S4.T4.3.10.2" class="ltx_td ltx_align_center">62.5</td>
<td id="S4.T4.3.10.3" class="ltx_td ltx_align_center">67.5</td>
<td id="S4.T4.3.10.4" class="ltx_td ltx_align_center"><span id="S4.T4.3.10.4.1" class="ltx_text ltx_font_bold">84.0</span></td>
</tr>
<tr id="S4.T4.3.11" class="ltx_tr">
<td id="S4.T4.3.11.1" class="ltx_td ltx_align_left">Ethics</td>
<td id="S4.T4.3.11.2" class="ltx_td ltx_align_center">89.8</td>
<td id="S4.T4.3.11.3" class="ltx_td ltx_align_center">90.5</td>
<td id="S4.T4.3.11.4" class="ltx_td ltx_align_center"><span id="S4.T4.3.11.4.1" class="ltx_text ltx_font_bold">92.5</span></td>
</tr>
<tr id="S4.T4.3.12" class="ltx_tr">
<td id="S4.T4.3.12.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S4.T4.3.12.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S4.T4.3.12.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">75.3</td>
<td id="S4.T4.3.12.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">79.4</td>
<td id="S4.T4.3.12.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T4.3.12.4.1" class="ltx_text ltx_font_bold">82.0</span></td>
</tr>
</tbody></table>
</figure>
<section id="S4.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Multi-turn Dialogue</h4>

<div id="S4.SS3.SSS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.SSS1.p1.1">ChatGPT의 인상적인 성과 중 하나는 멀티턴 대화 인터페이스로 전달되는 풍부하고 유창한 맥락적 이해 능력이다. 우리가 볼 수 있듯이 플러스 시리즈 모델은 기본 모델에 비해 일관된 개선을 제공하지만 후자의 크기는 형성자의 몇 배이다. 이것은 더 나은 대화 경험을 달성하기 위해 단순히 모델의 파라미터 크기를 확장하는 것보다 더 많은 트레이닝 데이터를 수집하는 것이 훨씬 더 중요하다는 것을 나타낼 수 있다. 특히, 언어적 지식이 직접적으로 전달될 수 없는 LLaMA 원본으로부터 모델을 구축한다.</p>
</div>
</section>
<section id="S4.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Text Generation</h4>

<div id="S4.SS3.SSS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.SSS2.p1.1">텍스트 생성은 언어 모델을 위한 가장 기본적인 능력 중 하나이다. Alpaca-Plus-7B 및 Alpaca-Plus-13B에 비해 Alpaca-33B는 이 범주에서 열등한 결과를 보여준다. 표 <a class="ltx_ref" href="#S4.T5" title="Table 5 ‣ 4.3.2 Text Generation ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">5</span></a>는 텍스트 생성 작업의 일 예를 나타낸다. 우리는 Alpaca-Plus-7B와 Alpaca-Plus-13B 모두 사용자 프롬프트의 요구 사항을 충족하는 올바른 문자 스타일을 제공한다는 것을 알 수 있다. 알파카플러스13B는 신청자가 비자 신청을 위한 모든 자료를 철저히 준비했음을 알려 가장 포괄적인 것을 제공해 세 시스템 모두 최고의 생성 품질을 자랑한다. 그러나 Alpaca-33B는 글자체를 따르지 않고, 내용이 다소 간소화 되어 있어 다른 것에 비해 분명히 좋지 않다. 이는 더 적은 모델을 가진 더 많은 데이터를 가진 트레이닝이 더 적은 데이터를 가진 빅 모델보다 더 나은 성능을 제공할 수 있음을 보여준다.</p>
</div>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 5:</span> <span class="ltx_text ltx_font_bold" id="S4.T5.2.1">텍스트 생성 작업에 대한 예제 출력. </span> 33B 모델은 Plus-7B 및 Plus-13B와 비교하여 상세하고 풍부한 컨텍스트를 제공하지 않는다.</figcaption>
<table id="S4.T5.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S4.T5.3.1" class="ltx_tr">
<td id="S4.T5.3.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T5.3.1.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S4.T5.3.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T5.3.1.2.1" class="ltx_text ltx_font_bold">Prompt: 请你帮我写一封赴美旅游签证申请信</span></td>
</tr>
<tr id="S4.T5.3.2" class="ltx_tr">
<td id="S4.T5.3.2.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T5.3.2.1.1" class="ltx_text"></span> <span id="S4.T5.3.2.1.2" class="ltx_text">
<span id="S4.T5.3.2.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T5.3.2.1.2.1.1" class="ltx_tr">
<span id="S4.T5.3.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Plus-7B</span></span>
<span id="S4.T5.3.2.1.2.1.2" class="ltx_tr">
<span id="S4.T5.3.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(8.5/10)</span></span>
</span></span><span id="S4.T5.3.2.1.3" class="ltx_text"></span></td>
<td id="S4.T5.3.2.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T5.3.2.2.1" class="ltx_text"></span><span id="S4.T5.3.2.2.2" class="ltx_text">
<span id="S4.T5.3.2.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T5.3.2.2.2.1.1" class="ltx_tr">
<span id="S4.T5.3.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">尊敬的美国大使馆：</span></span>
<span id="S4.T5.3.2.2.2.1.2" class="ltx_tr">
<span id="S4.T5.3.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">我是一名来自中国的游客，计划于2022年7月前往美国旅游。我非常期待这次旅行，</span></span>
<span id="S4.T5.3.2.2.2.1.3" class="ltx_tr">
<span id="S4.T5.3.2.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">并希望获得签证。</span></span>
<span id="S4.T5.3.2.2.2.1.4" class="ltx_tr">
<span id="S4.T5.3.2.2.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">我将遵守美国的法律和规定，并尊重当地文化和风俗。我将遵守旅游计划，并在离</span></span>
<span id="S4.T5.3.2.2.2.1.5" class="ltx_tr">
<span id="S4.T5.3.2.2.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">开前向美国大使馆报告我的行踪。</span></span>
<span id="S4.T5.3.2.2.2.1.6" class="ltx_tr">
<span id="S4.T5.3.2.2.2.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">感谢您考虑我的申请。</span></span>
<span id="S4.T5.3.2.2.2.1.7" class="ltx_tr">
<span id="S4.T5.3.2.2.2.1.7.1" class="ltx_td ltx_nopad_r ltx_align_left">此致</span></span>
<span id="S4.T5.3.2.2.2.1.8" class="ltx_tr">
<span id="S4.T5.3.2.2.2.1.8.1" class="ltx_td ltx_nopad_r ltx_align_left">敬礼！</span></span>
</span></span><span id="S4.T5.3.2.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T5.3.3" class="ltx_tr">
<td id="S4.T5.3.3.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T5.3.3.1.1" class="ltx_text"></span> <span id="S4.T5.3.3.1.2" class="ltx_text">
<span id="S4.T5.3.3.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T5.3.3.1.2.1.1" class="ltx_tr">
<span id="S4.T5.3.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Plus-13B</span></span>
<span id="S4.T5.3.3.1.2.1.2" class="ltx_tr">
<span id="S4.T5.3.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(10/10)</span></span>
</span></span><span id="S4.T5.3.3.1.3" class="ltx_text"></span></td>
<td id="S4.T5.3.3.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T5.3.3.2.1" class="ltx_text"></span><span id="S4.T5.3.3.2.2" class="ltx_text">
<span id="S4.T5.3.3.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T5.3.3.2.2.1.1" class="ltx_tr">
<span id="S4.T5.3.3.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">尊敬的美国大使馆官员，</span></span>
<span id="S4.T5.3.3.2.2.1.2" class="ltx_tr">
<span id="S4.T5.3.3.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">我是xxx，来自中国。我计划于明年3月前往美国进行为期一个月的旅行。我的行程</span></span>
<span id="S4.T5.3.3.2.2.1.3" class="ltx_tr">
<span id="S4.T5.3.3.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">包括参观纽约市、洛杉矶和拉斯维加斯等城市，并与当地的人们交流。我相信这次</span></span>
<span id="S4.T5.3.3.2.2.1.4" class="ltx_tr">
<span id="S4.T5.3.3.2.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">旅行将对我的个人成长和发展有所帮助。</span></span>
<span id="S4.T5.3.3.2.2.1.5" class="ltx_tr">
<span id="S4.T5.3.3.2.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">我已经准备好了所有需要的材料，包括机票预订证明、酒店预订证明以及旅游计划。</span></span>
<span id="S4.T5.3.3.2.2.1.6" class="ltx_tr">
<span id="S4.T5.3.3.2.2.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">我希望通过此次申请获得签证，以确保我的旅行顺利进行。</span></span>
<span id="S4.T5.3.3.2.2.1.7" class="ltx_tr">
<span id="S4.T5.3.3.2.2.1.7.1" class="ltx_td ltx_nopad_r ltx_align_left">谢谢您的时间和关注。我期待着能够很快收到您的回复。</span></span>
<span id="S4.T5.3.3.2.2.1.8" class="ltx_tr">
<span id="S4.T5.3.3.2.2.1.8.1" class="ltx_td ltx_nopad_r ltx_align_left">此致，</span></span>
<span id="S4.T5.3.3.2.2.1.9" class="ltx_tr">
<span id="S4.T5.3.3.2.2.1.9.1" class="ltx_td ltx_nopad_r ltx_align_left">敬礼</span></span>
</span></span><span id="S4.T5.3.3.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T5.3.4" class="ltx_tr">
<td id="S4.T5.3.4.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<span id="S4.T5.3.4.1.1" class="ltx_text"></span> <span id="S4.T5.3.4.1.2" class="ltx_text">
<span id="S4.T5.3.4.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T5.3.4.1.2.1.1" class="ltx_tr">
<span id="S4.T5.3.4.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">33B</span></span>
<span id="S4.T5.3.4.1.2.1.2" class="ltx_tr">
<span id="S4.T5.3.4.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(8/10)</span></span>
</span></span><span id="S4.T5.3.4.1.3" class="ltx_text"></span></td>
<td id="S4.T5.3.4.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S4.T5.3.4.2.1" class="ltx_text"></span><span id="S4.T5.3.4.2.2" class="ltx_text">
<span id="S4.T5.3.4.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T5.3.4.2.2.1.1" class="ltx_tr">
<span id="S4.T5.3.4.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">尊敬的美国大使馆工作人员，我谨代表本人向您申请一次赴美旅游签证。我是一名</span></span>
<span id="S4.T5.3.4.2.2.1.2" class="ltx_tr">
<span id="S4.T5.3.4.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">中国公民，目前从事互联网行业工作，有良好的职业背景和经济实力。此次旅行的</span></span>
<span id="S4.T5.3.4.2.2.1.3" class="ltx_tr">
<span id="S4.T5.3.4.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">目的是探访美国文化、了解当地风土人情，并结交一些志同道合的朋友。我将遵守</span></span>
<span id="S4.T5.3.4.2.2.1.4" class="ltx_tr">
<span id="S4.T5.3.4.2.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">美国的法律法规，不违反任何规定。谢谢您的考虑！</span></span>
</span></span><span id="S4.T5.3.4.2.3" class="ltx_text"></span></td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S4.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3 </span>Numerical Calculation and Reasoning</h4>

<div id="S4.SS3.SSS3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.SSS3.p1.1">수치 추론은 대형 언어 모델의 추론 능력을 검토하는 데 있어 가장 중요한 과제 중 하나로 간주되어 왔다. 우리가 볼 수 있듯이 알파카-33B는 플러스-7B 및 플러스-13B 모델에 비해 상당한 개선을 달성한다. 표 <a class="ltx_ref" href="#S4.T6" title="Table 6 ‣ 4.3.3 Numerical Calculation and Reasoning ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">6</span></a>는 이 작업에 대한 예제 출력을 보여줍니다. 첫 번째 프롬프트는 추론 능력, 즉 “어떤 것이 더 무겁고, 면 1kg 또는 철 1kg?”을 조사하는 것으로 잘 알려져 있다. 플러스-7B와 플러스-13B 모두 “면이 철보다 가볍다”고 언급하면서 정답을 제시하지 못했다. 그러나 33B는 이 두 가지가 같은 무게라는 것을 정확하게 식별할 수 있었다. 두 번째 프롬프트는 간단한 계산 작업으로 “고양이와 닭의 다리가 몇 개인가”를 묻는 것이다. 그러나 우리가 볼 수 있듯이 Plus-7B와 Plus-13B 모두 고양이가 다리가 4개이고 닭이 2개라는 상식적인 지식을 가지고 있지 않아 오답이 발생한다. 마지막 프롬프트는 모델이 다음 배열 수를 예측하도록 하는 수치 추론 작업이다. 여전히 33B 모델만이 다음 숫자가 인덱스의 제곱이어야 한다는 주어진 배열의 패턴을 정확하게 식별한다. 이러한 관찰은 모델의 크기가 수치 추론 작업에서 필수적임을 나타낸다.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 6:</span> <span class="ltx_text ltx_font_bold" id="S4.T6.2.1">수치 추론 작업에 대한 예제 출력. </span> 33B 모델은 Alpaca-Plus-7B 및 Alpaca-Plus-13B 모델보다 훨씬 우수합니다.</figcaption>
<table id="S4.T6.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S4.T6.3.1" class="ltx_tr">
<td id="S4.T6.3.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T6.3.1.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S4.T6.3.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T6.3.1.2.1" class="ltx_text ltx_font_bold">Prompt: 一公斤的棉花和一公斤的铁，哪一个更重？</span></td>
</tr>
<tr id="S4.T6.3.2" class="ltx_tr">
<td id="S4.T6.3.2.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.2.1.1" class="ltx_text"></span><span id="S4.T6.3.2.1.2" class="ltx_text">
<span id="S4.T6.3.2.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.2.1.2.1.1" class="ltx_tr">
<span id="S4.T6.3.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Plus-7B (3/10)</span></span>
</span></span><span id="S4.T6.3.2.1.3" class="ltx_text"></span></td>
<td id="S4.T6.3.2.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.2.2.1" class="ltx_text"></span><span id="S4.T6.3.2.2.2" class="ltx_text">
<span id="S4.T6.3.2.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.2.2.2.1.1" class="ltx_tr">
<span id="S4.T6.3.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">一公斤棉花比一公斤铁轻。</span></span>
</span></span><span id="S4.T6.3.2.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T6.3.3" class="ltx_tr">
<td id="S4.T6.3.3.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.3.1.1" class="ltx_text"></span><span id="S4.T6.3.3.1.2" class="ltx_text">
<span id="S4.T6.3.3.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.3.1.2.1.1" class="ltx_tr">
<span id="S4.T6.3.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Plus-13B (3/10)</span></span>
</span></span><span id="S4.T6.3.3.1.3" class="ltx_text"></span></td>
<td id="S4.T6.3.3.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.3.2.1" class="ltx_text"></span><span id="S4.T6.3.3.2.2" class="ltx_text">
<span id="S4.T6.3.3.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.3.2.2.1.1" class="ltx_tr">
<span id="S4.T6.3.3.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">一公斤的棉花比一公斤的铁轻。</span></span>
</span></span><span id="S4.T6.3.3.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T6.3.4" class="ltx_tr">
<td id="S4.T6.3.4.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.4.1.1" class="ltx_text"></span><span id="S4.T6.3.4.1.2" class="ltx_text">
<span id="S4.T6.3.4.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.4.1.2.1.1" class="ltx_tr">
<span id="S4.T6.3.4.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">33B (9/10)</span></span>
</span></span><span id="S4.T6.3.4.1.3" class="ltx_text"></span></td>
<td id="S4.T6.3.4.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.4.2.1" class="ltx_text"></span><span id="S4.T6.3.4.2.2" class="ltx_text">
<span id="S4.T6.3.4.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.4.2.2.1.1" class="ltx_tr">
<span id="S4.T6.3.4.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">一公斤的棉花和一公斤的铁重量相同。</span></span>
</span></span><span id="S4.T6.3.4.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T6.3.5" class="ltx_tr">
<td id="S4.T6.3.5.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T6.3.5.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S4.T6.3.5.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T6.3.5.2.1" class="ltx_text ltx_font_bold">Prompt: 一只猫和一只鸡一共有几只脚？</span></td>
</tr>
<tr id="S4.T6.3.6" class="ltx_tr">
<td id="S4.T6.3.6.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.6.1.1" class="ltx_text"></span><span id="S4.T6.3.6.1.2" class="ltx_text">
<span id="S4.T6.3.6.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.6.1.2.1.1" class="ltx_tr">
<span id="S4.T6.3.6.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Plus-7B (1/10)</span></span>
</span></span><span id="S4.T6.3.6.1.3" class="ltx_text"></span></td>
<td id="S4.T6.3.6.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.6.2.1" class="ltx_text"></span><span id="S4.T6.3.6.2.2" class="ltx_text">
<span id="S4.T6.3.6.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.6.2.2.1.1" class="ltx_tr">
<span id="S4.T6.3.6.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">一只猫和一只鸡一共有两只脚。</span></span>
</span></span><span id="S4.T6.3.6.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T6.3.7" class="ltx_tr">
<td id="S4.T6.3.7.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.7.1.1" class="ltx_text"></span><span id="S4.T6.3.7.1.2" class="ltx_text">
<span id="S4.T6.3.7.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.7.1.2.1.1" class="ltx_tr">
<span id="S4.T6.3.7.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Plus-13B (1/10)</span></span>
</span></span><span id="S4.T6.3.7.1.3" class="ltx_text"></span></td>
<td id="S4.T6.3.7.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.7.2.1" class="ltx_text"></span><span id="S4.T6.3.7.2.2" class="ltx_text">
<span id="S4.T6.3.7.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.7.2.2.1.1" class="ltx_tr">
<span id="S4.T6.3.7.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">一只猫和一只鸡各有四只脚，所以两只动物一共有八只脚。</span></span>
</span></span><span id="S4.T6.3.7.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T6.3.8" class="ltx_tr">
<td id="S4.T6.3.8.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.8.1.1" class="ltx_text"></span><span id="S4.T6.3.8.1.2" class="ltx_text">
<span id="S4.T6.3.8.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.8.1.2.1.1" class="ltx_tr">
<span id="S4.T6.3.8.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">33B (10/10)</span></span>
</span></span><span id="S4.T6.3.8.1.3" class="ltx_text"></span></td>
<td id="S4.T6.3.8.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.8.2.1" class="ltx_text"></span><span id="S4.T6.3.8.2.2" class="ltx_text">
<span id="S4.T6.3.8.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.8.2.2.1.1" class="ltx_tr">
<span id="S4.T6.3.8.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">这道题需要进行简单的数学运算。一只猫有4只脚，一只鸡有2只脚，</span></span>
<span id="S4.T6.3.8.2.2.1.2" class="ltx_tr">
<span id="S4.T6.3.8.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">所以两只动物一共有6只脚。</span></span>
</span></span><span id="S4.T6.3.8.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T6.3.9" class="ltx_tr">
<td id="S4.T6.3.9.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T6.3.9.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S4.T6.3.9.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T6.3.9.2.1" class="ltx_text ltx_font_bold">Prompt: 序列1,4,9,16的后一个数是什么？</span></td>
</tr>
<tr id="S4.T6.3.10" class="ltx_tr">
<td id="S4.T6.3.10.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.10.1.1" class="ltx_text"></span><span id="S4.T6.3.10.1.2" class="ltx_text">
<span id="S4.T6.3.10.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.10.1.2.1.1" class="ltx_tr">
<span id="S4.T6.3.10.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Plus-7B (1/10)</span></span>
</span></span><span id="S4.T6.3.10.1.3" class="ltx_text"></span></td>
<td id="S4.T6.3.10.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.10.2.1" class="ltx_text"></span><span id="S4.T6.3.10.2.2" class="ltx_text">
<span id="S4.T6.3.10.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.10.2.2.1.1" class="ltx_tr">
<span id="S4.T6.3.10.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">后一个数是 16。</span></span>
</span></span><span id="S4.T6.3.10.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T6.3.11" class="ltx_tr">
<td id="S4.T6.3.11.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.11.1.1" class="ltx_text"></span><span id="S4.T6.3.11.1.2" class="ltx_text">
<span id="S4.T6.3.11.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.11.1.2.1.1" class="ltx_tr">
<span id="S4.T6.3.11.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Plus-13B (1/10)</span></span>
</span></span><span id="S4.T6.3.11.1.3" class="ltx_text"></span></td>
<td id="S4.T6.3.11.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T6.3.11.2.1" class="ltx_text"></span><span id="S4.T6.3.11.2.2" class="ltx_text">
<span id="S4.T6.3.11.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.11.2.2.1.1" class="ltx_tr">
<span id="S4.T6.3.11.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">21</span></span>
</span></span><span id="S4.T6.3.11.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T6.3.12" class="ltx_tr">
<td id="S4.T6.3.12.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S4.T6.3.12.1.1" class="ltx_text"></span><span id="S4.T6.3.12.1.2" class="ltx_text">
<span id="S4.T6.3.12.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.12.1.2.1.1" class="ltx_tr">
<span id="S4.T6.3.12.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">33B (10/10)</span></span>
</span></span><span id="S4.T6.3.12.1.3" class="ltx_text"></span></td>
<td id="S4.T6.3.12.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S4.T6.3.12.2.1" class="ltx_text"></span><span id="S4.T6.3.12.2.2" class="ltx_text">
<span id="S4.T6.3.12.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T6.3.12.2.2.1.1" class="ltx_tr">
<span id="S4.T6.3.12.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">序列1,4,9,16的后一个数是25。</span></span>
</span></span><span id="S4.T6.3.12.2.3" class="ltx_text"></span></td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S4.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.4 </span>Coding</h4>

<div id="S4.SS3.SSS4.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.SSS4.p1.1"><a class="ltx_ref" href="#S4.F1" title="Figure 1 ‣ 4.3.4 Coding ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">1</span></a>는 Dijkstra 알고리즘을 Python으로 구현한 예를 보여준다. 플러스-7B는 불행히도 최단 거리를 정확하게 계산하고 업데이트하지 못하고 정의되지 않은 함수를 포함하는 구조적으로 건전한 접근법으로 인해 3/10을 기록한다. Plus-13B는 객체지향 프로그래밍에서 그래프와 관련된 연산이 어떻게 표현될 수 있는지에 대한 기본적인 이해를 보여주는 그래프 클래스와 거리 방법을 구현하여 추상화를 시도한다. 또한, 최단 경로 알고리즘을 구현하려고 시도하고 있다는 사실(다이크스트라의 알고리즘을 제대로 구현하지 못했음에도 불구하고)은 Plus-7B보다 약간 더 높은 점수를 준다. 33B 모델은 훨씬 더 나은 다이크스트라 알고리즘 구현을 제공하여 8/10의 점수를 얻었다. 우선순위 큐가 없고 오류 처리가 없어 효율성과 견고성이 향상되었음에도 불구하고 코드는 최단 거리를 올바르게 업데이트하고 이전 노드의 트랙을 유지하며 알고리즘에 대한 근본적인 이해를 반영하여 모든 노드가 방문되도록 한다.</p>
</div>
<div id="S4.SS3.SSS4.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.SSS4.p2.1">이러한 결과로부터 코드 생성과 같은 복잡한 작업에서 더 큰 모델이 더 나은 성능을 발휘하는 경향이 있음을 추론할 수 있으며, 이는 잠재적으로 훈련 데이터에서 더 복잡한 패턴을 캡처하는 능력으로 인해 발생할 수 있다.</p>
</div>
<figure id="S4.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.F1.1" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:357.7pt;">
<p class="ltx_p" id="S4.F1.1.1">Plus-7B (3/10):</p>
<div id="S4.F1.1.2" class="ltx_listing ltx_lst_language_Python ltx_lst_numbers_left ltx_lstlisting ltx_framed ltx_framed_topbottom ltx_listing" style="background-color:#FFFFFF;">
<div class="ltx_listing_data"><a href="data:text/plain;base64,aW1wb3J0IGhlYXBxCgpkZWYgZGlqa3N0cmEoZ3JhcGgsIHMpOgogICAgcXVldWUgPSBbXQogICAgaGVhcCA9IFtzXQogICAgd2hpbGUgbGVuKGhlYXApID4gMDoKICAgICAgICBjdXJyZW50ID0gaGVhcC5wb3AoKQogICAgICAgIGZvciBpIGluIGdyYXBoW2N1cnJlbnRdOgogICAgICAgICAgICBpZiBpIG5vdCBpbiBoZWFwIGFuZCBkaXN0KGksIHMpIDwgZGlzdChzLCBjdXJyZW50KToKICAgICAgICAgICAgICAgIGhlYXAuYXBwZW5kKGkpCiAgICByZXR1cm4gcXVldWU=" download="">⬇</a></div>
<div id="lstnumberx1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span><span id="lstnumberx1.1" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">import</span><span id="lstnumberx1.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx1.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">heapq</span>
</div>
<div id="lstnumberx2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span>
</div>
<div id="lstnumberx3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span><span id="lstnumberx3.1" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">def</span><span id="lstnumberx3.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">dijkstra</span><span id="lstnumberx3.4" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx3.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">graph</span><span id="lstnumberx3.6" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx3.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx3.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">s</span><span id="lstnumberx3.9" class="ltx_text ltx_font_typewriter">):</span>
</div>
<div id="lstnumberx4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span><span id="lstnumberx4.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx4.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">queue</span><span id="lstnumberx4.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.4" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx4.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx4.6" class="ltx_text ltx_font_typewriter">[]</span>
</div>
<div id="lstnumberx5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span><span id="lstnumberx5.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx5.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">heap</span><span id="lstnumberx5.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx5.4" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx5.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx5.6" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx5.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">s</span><span id="lstnumberx5.8" class="ltx_text ltx_font_typewriter">]</span>
</div>
<div id="lstnumberx6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span><span id="lstnumberx6.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx6.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">while</span><span id="lstnumberx6.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.4" class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter" style="color:#0000FF;">len</span><span id="lstnumberx6.5" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx6.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">heap</span><span id="lstnumberx6.7" class="ltx_text ltx_font_typewriter">)</span><span id="lstnumberx6.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.9" class="ltx_text ltx_font_typewriter">&gt;</span><span id="lstnumberx6.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx6.11" class="ltx_text ltx_font_typewriter">0:</span>
</div>
<div id="lstnumberx7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span><span id="lstnumberx7.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx7.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">current</span><span id="lstnumberx7.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx7.4" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx7.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx7.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">heap</span><span id="lstnumberx7.7" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx7.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">pop</span><span id="lstnumberx7.9" class="ltx_text ltx_font_typewriter">()</span>
</div>
<div id="lstnumberx8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span><span id="lstnumberx8.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx8.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">for</span><span id="lstnumberx8.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx8.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">i</span><span id="lstnumberx8.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx8.6" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">in</span><span id="lstnumberx8.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx8.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">graph</span><span id="lstnumberx8.9" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx8.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">current</span><span id="lstnumberx8.11" class="ltx_text ltx_font_typewriter">]:</span>
</div>
<div id="lstnumberx9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span><span id="lstnumberx9.1" class="ltx_text ltx_lst_space ltx_font_typewriter">            </span><span id="lstnumberx9.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">if</span><span id="lstnumberx9.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">i</span><span id="lstnumberx9.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.6" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">not</span><span id="lstnumberx9.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.8" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">in</span><span id="lstnumberx9.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">heap</span><span id="lstnumberx9.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.12" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">and</span><span id="lstnumberx9.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">dist</span><span id="lstnumberx9.15" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx9.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">i</span><span id="lstnumberx9.17" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx9.18" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.19" class="ltx_text ltx_lst_identifier ltx_font_typewriter">s</span><span id="lstnumberx9.20" class="ltx_text ltx_font_typewriter">)</span><span id="lstnumberx9.21" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.22" class="ltx_text ltx_font_typewriter">&lt;</span><span id="lstnumberx9.23" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.24" class="ltx_text ltx_lst_identifier ltx_font_typewriter">dist</span><span id="lstnumberx9.25" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx9.26" class="ltx_text ltx_lst_identifier ltx_font_typewriter">s</span><span id="lstnumberx9.27" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx9.28" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx9.29" class="ltx_text ltx_lst_identifier ltx_font_typewriter">current</span><span id="lstnumberx9.30" class="ltx_text ltx_font_typewriter">):</span>
</div>
<div id="lstnumberx10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span><span id="lstnumberx10.1" class="ltx_text ltx_lst_space ltx_font_typewriter">                </span><span id="lstnumberx10.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">heap</span><span id="lstnumberx10.3" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx10.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">append</span><span id="lstnumberx10.5" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx10.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">i</span><span id="lstnumberx10.7" class="ltx_text ltx_font_typewriter">)</span>
</div>
<div id="lstnumberx11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span><span id="lstnumberx11.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx11.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">return</span><span id="lstnumberx11.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx11.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">queue</span>
</div>
</div>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.F1.2" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:357.7pt;">
<p class="ltx_p" id="S4.F1.2.1">Plus-13B(4/10):</p>
<div id="S4.F1.2.2" class="ltx_listing ltx_lst_language_Python ltx_lst_numbers_left ltx_lstlisting ltx_framed ltx_framed_topbottom ltx_listing" style="background-color:#FFFFFF;">
<div class="ltx_listing_data"><a href="data:text/plain;base64,Y2xhc3MgR3JhcGg6CiAgICBkZWYgX19pbml0X18oc2VsZiwgYWRqKToKICAgICAgICBzZWxmLmFkaiA9IGFkagoKICAgIGRlZiBkaXN0YW5jZShzZWxmLCB2KToKICAgICAgICBkaXN0ID0gW2luZl0gKiBsZW4oc2VsZi5hZGopCiAgICAgICAgZm9yIHUgaW4gc2VsZi5hZGpbdl06CiAgICAgICAgICAgIGlmIHUgbm90IGluIGRpc3Q6CiAgICAgICAgICAgICAgICBkaXN0W3VdID0gMSArIG1pbihkaXN0W3VdLCBkaXN0W3ZdKQoKICAgICAgICByZXR1cm4gZGlzdFt2XQoKZGVmIG1haW4oKToKICAgIGcgPSBHcmFwaChbKDAsMSksICgxLDIpKSwgKDIsMyksICgzLDQpXSkKCiAgICB2ID0gMQogICAgZCA9IGcuZGlzdGFuY2UodikKICAgIHByaW50KCdEaXN0YW5jZSBpczonLCBkKQoKaWYgX19uYW1lX18gPT0gJ19fbWFpbl9fJzoKICAgIG1haW4oKQ==" download="">⬇</a></div>
<div id="lstnumberx12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span><span id="lstnumberx12.1" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">class</span><span id="lstnumberx12.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx12.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Graph</span><span id="lstnumberx12.4" class="ltx_text ltx_font_typewriter">:</span>
</div>
<div id="lstnumberx13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span><span id="lstnumberx13.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx13.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">def</span><span id="lstnumberx13.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx13.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">__init__</span><span id="lstnumberx13.5" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx13.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">self</span><span id="lstnumberx13.7" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx13.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx13.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">adj</span><span id="lstnumberx13.10" class="ltx_text ltx_font_typewriter">):</span>
</div>
<div id="lstnumberx14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span><span id="lstnumberx14.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx14.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">self</span><span id="lstnumberx14.3" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx14.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">adj</span><span id="lstnumberx14.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx14.6" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx14.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx14.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">adj</span>
</div>
<div id="lstnumberx15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span>
</div>
<div id="lstnumberx16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span><span id="lstnumberx16.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx16.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">def</span><span id="lstnumberx16.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">distance</span><span id="lstnumberx16.5" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx16.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">self</span><span id="lstnumberx16.7" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx16.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx16.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">v</span><span id="lstnumberx16.10" class="ltx_text ltx_font_typewriter">):</span>
</div>
<div id="lstnumberx17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span><span id="lstnumberx17.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx17.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">dist</span><span id="lstnumberx17.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx17.4" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx17.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx17.6" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx17.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">inf</span><span id="lstnumberx17.8" class="ltx_text ltx_font_typewriter">]</span><span id="lstnumberx17.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx17.10" class="ltx_text ltx_font_typewriter">*</span><span id="lstnumberx17.11" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx17.12" class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter" style="color:#0000FF;">len</span><span id="lstnumberx17.13" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx17.14" class="ltx_text ltx_lst_identifier ltx_font_typewriter">self</span><span id="lstnumberx17.15" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx17.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">adj</span><span id="lstnumberx17.17" class="ltx_text ltx_font_typewriter">)</span>
</div>
<div id="lstnumberx18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span><span id="lstnumberx18.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx18.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">for</span><span id="lstnumberx18.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">u</span><span id="lstnumberx18.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.6" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">in</span><span id="lstnumberx18.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx18.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">self</span><span id="lstnumberx18.9" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx18.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">adj</span><span id="lstnumberx18.11" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx18.12" class="ltx_text ltx_lst_identifier ltx_font_typewriter">v</span><span id="lstnumberx18.13" class="ltx_text ltx_font_typewriter">]:</span>
</div>
<div id="lstnumberx19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span><span id="lstnumberx19.1" class="ltx_text ltx_lst_space ltx_font_typewriter">            </span><span id="lstnumberx19.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">if</span><span id="lstnumberx19.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx19.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">u</span><span id="lstnumberx19.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx19.6" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">not</span><span id="lstnumberx19.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx19.8" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">in</span><span id="lstnumberx19.9" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx19.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">dist</span><span id="lstnumberx19.11" class="ltx_text ltx_font_typewriter">:</span>
</div>
<div id="lstnumberx20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span><span id="lstnumberx20.1" class="ltx_text ltx_lst_space ltx_font_typewriter">                </span><span id="lstnumberx20.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">dist</span><span id="lstnumberx20.3" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx20.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">u</span><span id="lstnumberx20.5" class="ltx_text ltx_font_typewriter">]</span><span id="lstnumberx20.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx20.7" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx20.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx20.9" class="ltx_text ltx_font_typewriter">1</span><span id="lstnumberx20.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx20.11" class="ltx_text ltx_font_typewriter">+</span><span id="lstnumberx20.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx20.13" class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter" style="color:#0000FF;">min</span><span id="lstnumberx20.14" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx20.15" class="ltx_text ltx_lst_identifier ltx_font_typewriter">dist</span><span id="lstnumberx20.16" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx20.17" class="ltx_text ltx_lst_identifier ltx_font_typewriter">u</span><span id="lstnumberx20.18" class="ltx_text ltx_font_typewriter">],</span><span id="lstnumberx20.19" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx20.20" class="ltx_text ltx_lst_identifier ltx_font_typewriter">dist</span><span id="lstnumberx20.21" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx20.22" class="ltx_text ltx_lst_identifier ltx_font_typewriter">v</span><span id="lstnumberx20.23" class="ltx_text ltx_font_typewriter">])</span>
</div>
<div id="lstnumberx21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span>
</div>
<div id="lstnumberx22" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span><span id="lstnumberx22.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx22.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">return</span><span id="lstnumberx22.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx22.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">dist</span><span id="lstnumberx22.5" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx22.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">v</span><span id="lstnumberx22.7" class="ltx_text ltx_font_typewriter">]</span>
</div>
<div id="lstnumberx23" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12</span>
</div>
<div id="lstnumberx24" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13</span><span id="lstnumberx24.1" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">def</span><span id="lstnumberx24.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx24.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">main</span><span id="lstnumberx24.4" class="ltx_text ltx_font_typewriter">():</span>
</div>
<div id="lstnumberx25" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">14</span><span id="lstnumberx25.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx25.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">g</span><span id="lstnumberx25.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.4" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx25.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">Graph</span><span id="lstnumberx25.7" class="ltx_text ltx_font_typewriter">([(0,1),</span><span id="lstnumberx25.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.9" class="ltx_text ltx_font_typewriter">(1,2)),</span><span id="lstnumberx25.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.11" class="ltx_text ltx_font_typewriter">(2,3),</span><span id="lstnumberx25.12" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx25.13" class="ltx_text ltx_font_typewriter">(3,4)])</span>
</div>
<div id="lstnumberx26" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">15</span>
</div>
<div id="lstnumberx27" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">16</span><span id="lstnumberx27.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx27.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">v</span><span id="lstnumberx27.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx27.4" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx27.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx27.6" class="ltx_text ltx_font_typewriter">1</span>
</div>
<div id="lstnumberx28" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">17</span><span id="lstnumberx28.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx28.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">d</span><span id="lstnumberx28.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx28.4" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx28.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx28.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">g</span><span id="lstnumberx28.7" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx28.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">distance</span><span id="lstnumberx28.9" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx28.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">v</span><span id="lstnumberx28.11" class="ltx_text ltx_font_typewriter">)</span>
</div>
<div id="lstnumberx29" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">18</span><span id="lstnumberx29.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx29.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">print</span><span id="lstnumberx29.3" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx29.4" class="ltx_text ltx_lst_string ltx_font_typewriter" style="color:#FF0000;">’Distance<span id="lstnumberx29.4.1" class="ltx_text ltx_lst_space"> </span>is:’</span><span id="lstnumberx29.5" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx29.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx29.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">d</span><span id="lstnumberx29.8" class="ltx_text ltx_font_typewriter">)</span>
</div>
<div id="lstnumberx30" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">19</span>
</div>
<div id="lstnumberx31" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">20</span><span id="lstnumberx31.1" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">if</span><span id="lstnumberx31.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx31.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">__name__</span><span id="lstnumberx31.4" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx31.5" class="ltx_text ltx_font_typewriter">==</span><span id="lstnumberx31.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx31.7" class="ltx_text ltx_lst_string ltx_font_typewriter" style="color:#FF0000;">’__main__’</span><span id="lstnumberx31.8" class="ltx_text ltx_font_typewriter">:</span>
</div>
<div id="lstnumberx32" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">21</span><span id="lstnumberx32.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx32.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">main</span><span id="lstnumberx32.3" class="ltx_text ltx_font_typewriter">()</span>
</div>
</div>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div id="S4.F1.3" class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:357.7pt;">
<p class="ltx_p" id="S4.F1.3.1">33B(8/10):</p>
<div id="S4.F1.3.2" class="ltx_listing ltx_lst_language_Python ltx_lst_numbers_left ltx_lstlisting ltx_framed ltx_framed_topbottom ltx_listing" style="background-color:#FFFFFF;">
<div class="ltx_listing_data"><a href="data:text/plain;base64,ZGVmIGRpamtzdHJhKGdyYXBoLCBzb3VyY2UpOgogICAgZGlzdGFuY2VzID0ge30KICAgIHByZWRlY2Vzc29ycyA9IHt9CiAgICBmb3Igbm9kZSBpbiBncmFwaDoKICAgICAgICBkaXN0YW5jZXNbbm9kZV0gPSBmbG9hdCgnaW5mJykKICAgICAgICBwcmVkZWNlc3NvcnNbbm9kZV0gPSBOb25lCiAgICBkaXN0YW5jZXNbc291cmNlXSA9IDAKICAgIHF1ZXVlID0gW3NvdXJjZV0KICAgIHdoaWxlIHF1ZXVlOgogICAgICAgIGN1cnJlbnQgPSBxdWV1ZS5wb3AoMCkKICAgICAgICBmb3IgbmVpZ2hib3IgaW4gZ3JhcGhbY3VycmVudF06CiAgICAgICAgICAgIGlmIGRpc3RhbmNlc1tuZWlnaGJvcl0gPiBkaXN0YW5jZXNbY3VycmVudF0gKyBncmFwaFtjdXJyZW50XVtuZWlnaGJvcl06CiAgICAgICAgICAgICAgICBkaXN0YW5jZXNbbmVpZ2hib3JdID0gZGlzdGFuY2VzW2N1cnJlbnRdICsgZ3JhcGhbY3VycmVudF1bbmVpZ2hib3JdCiAgICAgICAgICAgICAgICBwcmVkZWNlc3NvcnNbbmVpZ2hib3JdID0gY3VycmVudAogICAgcmV0dXJuIGRpc3RhbmNlcw==" download="">⬇</a></div>
<div id="lstnumberx33" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span><span id="lstnumberx33.1" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">def</span><span id="lstnumberx33.2" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.3" class="ltx_text ltx_lst_identifier ltx_font_typewriter">dijkstra</span><span id="lstnumberx33.4" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx33.5" class="ltx_text ltx_lst_identifier ltx_font_typewriter">graph</span><span id="lstnumberx33.6" class="ltx_text ltx_font_typewriter">,</span><span id="lstnumberx33.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx33.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">source</span><span id="lstnumberx33.9" class="ltx_text ltx_font_typewriter">):</span>
</div>
<div id="lstnumberx34" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span><span id="lstnumberx34.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx34.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">distances</span><span id="lstnumberx34.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx34.4" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx34.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx34.6" class="ltx_text ltx_font_typewriter">{}</span>
</div>
<div id="lstnumberx35" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span><span id="lstnumberx35.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx35.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">predecessors</span><span id="lstnumberx35.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx35.4" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx35.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx35.6" class="ltx_text ltx_font_typewriter">{}</span>
</div>
<div id="lstnumberx36" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span><span id="lstnumberx36.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx36.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">for</span><span id="lstnumberx36.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx36.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">node</span><span id="lstnumberx36.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx36.6" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">in</span><span id="lstnumberx36.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx36.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">graph</span><span id="lstnumberx36.9" class="ltx_text ltx_font_typewriter">:</span>
</div>
<div id="lstnumberx37" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span><span id="lstnumberx37.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx37.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">distances</span><span id="lstnumberx37.3" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx37.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">node</span><span id="lstnumberx37.5" class="ltx_text ltx_font_typewriter">]</span><span id="lstnumberx37.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx37.7" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx37.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx37.9" class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter" style="color:#0000FF;">float</span><span id="lstnumberx37.10" class="ltx_text ltx_font_typewriter">(</span><span id="lstnumberx37.11" class="ltx_text ltx_lst_string ltx_font_typewriter" style="color:#FF0000;">’inf’</span><span id="lstnumberx37.12" class="ltx_text ltx_font_typewriter">)</span>
</div>
<div id="lstnumberx38" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span><span id="lstnumberx38.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx38.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">predecessors</span><span id="lstnumberx38.3" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx38.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">node</span><span id="lstnumberx38.5" class="ltx_text ltx_font_typewriter">]</span><span id="lstnumberx38.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx38.7" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx38.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx38.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">None</span>
</div>
<div id="lstnumberx39" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span><span id="lstnumberx39.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx39.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">distances</span><span id="lstnumberx39.3" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx39.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">source</span><span id="lstnumberx39.5" class="ltx_text ltx_font_typewriter">]</span><span id="lstnumberx39.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx39.7" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx39.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx39.9" class="ltx_text ltx_font_typewriter">0</span>
</div>
<div id="lstnumberx40" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span><span id="lstnumberx40.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx40.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">queue</span><span id="lstnumberx40.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx40.4" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx40.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx40.6" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx40.7" class="ltx_text ltx_lst_identifier ltx_font_typewriter">source</span><span id="lstnumberx40.8" class="ltx_text ltx_font_typewriter">]</span>
</div>
<div id="lstnumberx41" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span><span id="lstnumberx41.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx41.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">while</span><span id="lstnumberx41.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx41.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">queue</span><span id="lstnumberx41.5" class="ltx_text ltx_font_typewriter">:</span>
</div>
<div id="lstnumberx42" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span><span id="lstnumberx42.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx42.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">current</span><span id="lstnumberx42.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx42.4" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx42.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx42.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">queue</span><span id="lstnumberx42.7" class="ltx_text ltx_font_typewriter">.</span><span id="lstnumberx42.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">pop</span><span id="lstnumberx42.9" class="ltx_text ltx_font_typewriter">(0)</span>
</div>
<div id="lstnumberx43" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span><span id="lstnumberx43.1" class="ltx_text ltx_lst_space ltx_font_typewriter">        </span><span id="lstnumberx43.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">for</span><span id="lstnumberx43.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx43.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">neighbor</span><span id="lstnumberx43.5" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx43.6" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">in</span><span id="lstnumberx43.7" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx43.8" class="ltx_text ltx_lst_identifier ltx_font_typewriter">graph</span><span id="lstnumberx43.9" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx43.10" class="ltx_text ltx_lst_identifier ltx_font_typewriter">current</span><span id="lstnumberx43.11" class="ltx_text ltx_font_typewriter">]:</span>
</div>
<div id="lstnumberx44" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12</span><span id="lstnumberx44.1" class="ltx_text ltx_lst_space ltx_font_typewriter">            </span><span id="lstnumberx44.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">if</span><span id="lstnumberx44.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx44.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">distances</span><span id="lstnumberx44.5" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx44.6" class="ltx_text ltx_lst_identifier ltx_font_typewriter">neighbor</span><span id="lstnumberx44.7" class="ltx_text ltx_font_typewriter">]</span><span id="lstnumberx44.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx44.9" class="ltx_text ltx_font_typewriter">&gt;</span><span id="lstnumberx44.10" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx44.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">distances</span><span id="lstnumberx44.12" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx44.13" class="ltx_text ltx_lst_identifier ltx_font_typewriter">current</span><span id="lstnumberx44.14" class="ltx_text ltx_font_typewriter">]</span><span id="lstnumberx44.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx44.16" class="ltx_text ltx_font_typewriter">+</span><span id="lstnumberx44.17" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx44.18" class="ltx_text ltx_lst_identifier ltx_font_typewriter">graph</span><span id="lstnumberx44.19" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx44.20" class="ltx_text ltx_lst_identifier ltx_font_typewriter">current</span><span id="lstnumberx44.21" class="ltx_text ltx_font_typewriter">][</span><span id="lstnumberx44.22" class="ltx_text ltx_lst_identifier ltx_font_typewriter">neighbor</span><span id="lstnumberx44.23" class="ltx_text ltx_font_typewriter">]:</span>
</div>
<div id="lstnumberx45" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13</span><span id="lstnumberx45.1" class="ltx_text ltx_lst_space ltx_font_typewriter">                </span><span id="lstnumberx45.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">distances</span><span id="lstnumberx45.3" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx45.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">neighbor</span><span id="lstnumberx45.5" class="ltx_text ltx_font_typewriter">]</span><span id="lstnumberx45.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx45.7" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx45.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx45.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">distances</span><span id="lstnumberx45.10" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx45.11" class="ltx_text ltx_lst_identifier ltx_font_typewriter">current</span><span id="lstnumberx45.12" class="ltx_text ltx_font_typewriter">]</span><span id="lstnumberx45.13" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx45.14" class="ltx_text ltx_font_typewriter">+</span><span id="lstnumberx45.15" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx45.16" class="ltx_text ltx_lst_identifier ltx_font_typewriter">graph</span><span id="lstnumberx45.17" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx45.18" class="ltx_text ltx_lst_identifier ltx_font_typewriter">current</span><span id="lstnumberx45.19" class="ltx_text ltx_font_typewriter">][</span><span id="lstnumberx45.20" class="ltx_text ltx_lst_identifier ltx_font_typewriter">neighbor</span><span id="lstnumberx45.21" class="ltx_text ltx_font_typewriter">]</span>
</div>
<div id="lstnumberx46" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">14</span><span id="lstnumberx46.1" class="ltx_text ltx_lst_space ltx_font_typewriter">                </span><span id="lstnumberx46.2" class="ltx_text ltx_lst_identifier ltx_font_typewriter">predecessors</span><span id="lstnumberx46.3" class="ltx_text ltx_font_typewriter">[</span><span id="lstnumberx46.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">neighbor</span><span id="lstnumberx46.5" class="ltx_text ltx_font_typewriter">]</span><span id="lstnumberx46.6" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx46.7" class="ltx_text ltx_font_typewriter">=</span><span id="lstnumberx46.8" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx46.9" class="ltx_text ltx_lst_identifier ltx_font_typewriter">current</span>
</div>
<div id="lstnumberx47" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">15</span><span id="lstnumberx47.1" class="ltx_text ltx_lst_space ltx_font_typewriter">    </span><span id="lstnumberx47.2" class="ltx_text ltx_lst_keyword ltx_font_typewriter" style="color:#0000FF;">return</span><span id="lstnumberx47.3" class="ltx_text ltx_lst_space ltx_font_typewriter"> </span><span id="lstnumberx47.4" class="ltx_text ltx_lst_identifier ltx_font_typewriter">distances</span>
</div>
</div>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 1:</span> <span class="ltx_text ltx_font_bold" id="S4.F1.5.1">코딩 작업에 대한 예제 출력. </span> 33B 모델은 Alpaca-Plus-7B 및 Alpaca-Plus-13B 모델보다 훨씬 우수합니다.</figcaption>
</figure>
</section>
<section id="S4.SS3.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.5 </span>Ethics</h4>

<div id="S4.SS3.SSS5.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.SSS5.p1.1">LLM을 인간의 선호도에 맞추는 것은 책임감 있는 인공 지능을 만드는 데 필수적이다. 윤리 범주에서는 주로 이러한 모델이 불법 입력 프롬프트에 어떻게 반응하는지 테스트하고 싶습니다. 생성 결과를 확인함으로써, 세 시스템 모두 사용자의 프롬프트에 적절하게 응답하였다. Alpaca-33B는 다른 것보다 약간 더 나은 성능을 산출한다. 우리는 Alpaca-33B가 불법적인 프롬프트를 "거부"할 뿐만 아니라 적절한 조언을 추가로 제공할 수 있음을 발견한다. 예를 들어, 표 <a class="ltx_ref" href="#S4.T7" title="Table 7 ‣ 4.3.5 Ethics ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">7</span></a>에서 Plus-7B와 Plus-13B 모두 일부 네트워크 취약점을 악용하여 돈을 버는 것에 대한 조언을 단순히 거부하고 있다. 반대로 33B 모델은 사용자 프롬프트를 거부할 뿐만 아니라 법적 방법을 사용하여 돈을 버는 방법에 대한 조언을 제공하여 응답을 보다 포괄적이고 도움이 된다.</p>
</div>
<figure id="S4.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 7:</span> <span class="ltx_text ltx_font_bold" id="S4.T7.2.1">윤리 카테고리에 대한 예제 출력. </span> 33B 모델은 Plus-7B 및 Plus-13B보다 더 포괄적이고 유용한 정보를 제공하는 경향이 있다.</figcaption>
<table id="S4.T7.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S4.T7.3.1" class="ltx_tr">
<td id="S4.T7.3.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T7.3.1.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S4.T7.3.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T7.3.1.2.1" class="ltx_text ltx_font_bold">Prompt: 如何利用一些网络漏洞赚钱？</span></td>
</tr>
<tr id="S4.T7.3.2" class="ltx_tr">
<td id="S4.T7.3.2.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T7.3.2.1.1" class="ltx_text"></span> <span id="S4.T7.3.2.1.2" class="ltx_text">
<span id="S4.T7.3.2.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T7.3.2.1.2.1.1" class="ltx_tr">
<span id="S4.T7.3.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Plus-7B</span></span>
<span id="S4.T7.3.2.1.2.1.2" class="ltx_tr">
<span id="S4.T7.3.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(8/10)</span></span>
</span></span><span id="S4.T7.3.2.1.3" class="ltx_text"></span></td>
<td id="S4.T7.3.2.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T7.3.2.2.1" class="ltx_text"></span><span id="S4.T7.3.2.2.2" class="ltx_text">
<span id="S4.T7.3.2.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T7.3.2.2.2.1.1" class="ltx_tr">
<span id="S4.T7.3.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">我不能提供任何有关利用网络漏洞来赚钱的建议或指导，因为这违反了道德和法律</span></span>
<span id="S4.T7.3.2.2.2.1.2" class="ltx_tr">
<span id="S4.T7.3.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">规定。
网络安全是一项重要的任务，我们应该遵守相关的法律法规和行业标准，以</span></span>
<span id="S4.T7.3.2.2.2.1.3" class="ltx_tr">
<span id="S4.T7.3.2.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">确保网络安全和保护用户隐私。</span></span>
</span></span><span id="S4.T7.3.2.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T7.3.3" class="ltx_tr">
<td id="S4.T7.3.3.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="S4.T7.3.3.1.1" class="ltx_text"></span> <span id="S4.T7.3.3.1.2" class="ltx_text">
<span id="S4.T7.3.3.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T7.3.3.1.2.1.1" class="ltx_tr">
<span id="S4.T7.3.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Plus-13B</span></span>
<span id="S4.T7.3.3.1.2.1.2" class="ltx_tr">
<span id="S4.T7.3.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(8/10)</span></span>
</span></span><span id="S4.T7.3.3.1.3" class="ltx_text"></span></td>
<td id="S4.T7.3.3.2" class="ltx_td ltx_align_left ltx_border_t">
<span id="S4.T7.3.3.2.1" class="ltx_text"></span><span id="S4.T7.3.3.2.2" class="ltx_text">
<span id="S4.T7.3.3.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T7.3.3.2.2.1.1" class="ltx_tr">
<span id="S4.T7.3.3.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">作为一名AI语言模型，我不能鼓励或支持任何非法活动。利用网络漏洞进行非法活</span></span>
<span id="S4.T7.3.3.2.2.1.2" class="ltx_tr">
<span id="S4.T7.3.3.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">动是犯罪行为，会带来严重的法律后果和道德问题。我建议您遵守法律法规，不要</span></span>
<span id="S4.T7.3.3.2.2.1.3" class="ltx_tr">
<span id="S4.T7.3.3.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">从事任何违法行为。</span></span>
</span></span><span id="S4.T7.3.3.2.3" class="ltx_text"></span></td>
</tr>
<tr id="S4.T7.3.4" class="ltx_tr">
<td id="S4.T7.3.4.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">
<span id="S4.T7.3.4.1.1" class="ltx_text"></span> <span id="S4.T7.3.4.1.2" class="ltx_text">
<span id="S4.T7.3.4.1.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T7.3.4.1.2.1.1" class="ltx_tr">
<span id="S4.T7.3.4.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">33B</span></span>
<span id="S4.T7.3.4.1.2.1.2" class="ltx_tr">
<span id="S4.T7.3.4.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">(9/10)</span></span>
</span></span><span id="S4.T7.3.4.1.3" class="ltx_text"></span></td>
<td id="S4.T7.3.4.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S4.T7.3.4.2.1" class="ltx_text"></span><span id="S4.T7.3.4.2.2" class="ltx_text">
<span id="S4.T7.3.4.2.2.1" class="ltx_tabular ltx_align_top">
<span id="S4.T7.3.4.2.2.1.1" class="ltx_tr">
<span id="S4.T7.3.4.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">作为AI语言模型，我不能提供任何非法或不道德的建议。我们应该遵守法律和道德</span></span>
<span id="S4.T7.3.4.2.2.1.2" class="ltx_tr">
<span id="S4.T7.3.4.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">规范，不要从事任何违法活动。如果您想赚取合法收入，可以考虑以下几种方式：</span></span>
<span id="S4.T7.3.4.2.2.1.3" class="ltx_tr">
<span id="S4.T7.3.4.2.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">1. 在线销售商品或服务：开设自己的网店或网站，出售自己制作的产品或服务，例</span></span>
<span id="S4.T7.3.4.2.2.1.4" class="ltx_tr">
<span id="S4.T7.3.4.2.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">如手工艺品、设计作品、编程服务等。</span></span>
<span id="S4.T7.3.4.2.2.1.5" class="ltx_tr">
<span id="S4.T7.3.4.2.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">2. 在线兼职：在一些招聘网站上寻找兼职机会，如翻译、写作、客服等工作。</span></span>
<span id="S4.T7.3.4.2.2.1.6" class="ltx_tr">
<span id="S4.T7.3.4.2.2.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">3. 在线投资：通过股票、基金、债券等方式进行投资，获得收益。但需要注意风险</span></span>
<span id="S4.T7.3.4.2.2.1.7" class="ltx_tr">
<span id="S4.T7.3.4.2.2.1.7.1" class="ltx_td ltx_nopad_r ltx_align_left">控制，避免过度杠杆化。</span></span>
<span id="S4.T7.3.4.2.2.1.8" class="ltx_tr">
<span id="S4.T7.3.4.2.2.1.8.1" class="ltx_td ltx_nopad_r ltx_align_left">4. 创业：创建自己的公司或团队，开发新的产品或服务，并从中获利。</span></span>
<span id="S4.T7.3.4.2.2.1.9" class="ltx_tr">
<span id="S4.T7.3.4.2.2.1.9.1" class="ltx_td ltx_nopad_r ltx_align_left">以上是一些常见的合法途径，希望对您有所帮助。</span></span>
</span></span><span id="S4.T7.3.4.2.3" class="ltx_text"></span></td>
</tr>
</tbody></table>
</figure>
<div id="S4.SS3.SSS5.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS3.SSS5.p2.1">전반적으로 Alpaca-33B는 수치 추론, 코딩, 윤리 등을 포함한 다양한 측면에서 Alpaca-Plus-7B 및 Alpaca-Plus-13B에 비해 상당한 개선을 나타낸다. 알파카-33B는 더 적은 데이터로 훈련되지만 이러한 능력은 더 작은 모델보다 더 큰 모델에 의해 더 잘 처리된다고 추측한다. 또 다른 가능한 이유는 코딩 및 추론 능력이 상대적으로 언어 독립적인 원래의 LLaMA로부터 물려받은 능력일 것이다. 그러나 우리는 또한 Alpaca-33B가 텍스트 생성, 멀티턴 대화 등에서 열등한 결과를 가지고 있다는 것을 알아챘다. 플러스 시리즈 모델은 훨씬 더 많은 데이터에 대해 훈련됨에 따라 더 다양하고 풍부한 콘텐츠를 제공할 수 있습니다. Alpaca-Plus-33B를 사용할 수 있을 때 이러한 문제를 해결할 수 있을 것으로 예상하며, 이러한 능력은 수치 추론 및 코딩 관련 작업과 같이 높은 수준의 추론이 필요한 능력보다 상대적으로 극복하기 쉽기 때문이다. 완전한 비교, 등급 및 샘플 출력은 GitHub 리포지토리를 참조하십시오. <span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ymcui/Chinese-LLaMA-Alpaca/tree/main/examples" target="_blank" title="">https://github.com/ymcui/Chinese-LLaMA-Alpaca/tree/main/examples</a></span></span></span></p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results on Natural Language Understanding Tasks</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Task Description</h3>

<div id="S5.SS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS1.p1.1">명령어 후속 작업에 대한 생성 성능 테스트 외에도 다중 선택 질문 응답 데이터 세트인 C-Eval 데이터 세트 <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a class="ltx_ref" href="#bib.bib9" title="">2023</a>)</cite>에서 모델을 테스트했다. C-Eval은 주로 STEM, 사회, 인문 및 기타의 네 가지 범주를 다루며 52개 분야의 거의 14K 샘플로 구성된다. RACE <cite class="ltx_cite ltx_citemacro_citep">(Lai et al., <a class="ltx_ref" href="#bib.bib12" title="">2017</a>)</cite>와 같은 다른 다중 선택 QA 데이터 세트와 마찬가지로 모델이 주어진 질문에 따라 올바른 옵션 레이블을 생성해야 한다. 우리는 주로 모델의 예측 파일을 공식 리더보드에 제출하여 테스트 점수를 얻는 검증 분할(1,346개 샘플) 및 테스트 분할(12,342개 샘플)에서 모델을 테스트했다.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Decoding Strategy</h3>

<div id="S5.SS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.p1.6">이 데이터 세트에서 LLaMA 모델을 평가하기 위해 이러한 모델에 예를 직접 제공한다. Alpaca 모델을 평가할 때 섹션 <a class="ltx_ref" href="#S2.SS5" title="2.5 Supervised Fine-Tuning and Chinese Alpaca ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">2.5</span></a>에서 설명한 대로 프롬프트 템플릿에서 예를 포장합니다. 그런 다음 모델은 한 단계 예측을 하고 다음 토큰 <math alttext="p(y|\bm{x})" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mi id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">p</mi><mo id="S5.SS2.p1.1.m1.1.1.2" lspace="0em" rspace="0em" xref="S5.SS2.p1.1.m1.1.1.2.cmml">​</mo><mrow id="S5.SS2.p1.1.m1.1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.1.1.cmml"><mo id="S5.SS2.p1.1.m1.1.1.1.1.2" stretchy="false" xref="S5.SS2.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.SS2.p1.1.m1.1.1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.1.1.cmml"><mi id="S5.SS2.p1.1.m1.1.1.1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S5.SS2.p1.1.m1.1.1.1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S5.SS2.p1.1.m1.1.1.1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.1.1.1.3.cmml">𝒙</mi></mrow><mo id="S5.SS2.p1.1.m1.1.1.1.1.3" stretchy="false" xref="S5.SS2.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><times id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2"></times><ci id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3">𝑝</ci><apply id="S5.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S5.SS2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S5.SS2.p1.1.m1.1.1.1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.1.2">𝑦</ci><ci id="S5.SS2.p1.1.m1.1.1.1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.1.3">𝒙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">p(y|\bm{x})</annotation></semantics></math>, 여기서 <math alttext="y\in\mathcal{V}" class="ltx_Math" display="inline" id="S5.SS2.p1.2.m2.1"><semantics id="S5.SS2.p1.2.m2.1a"><mrow id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml"><mi id="S5.SS2.p1.2.m2.1.1.2" xref="S5.SS2.p1.2.m2.1.1.2.cmml">y</mi><mo id="S5.SS2.p1.2.m2.1.1.1" xref="S5.SS2.p1.2.m2.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p1.2.m2.1.1.3" xref="S5.SS2.p1.2.m2.1.1.3.cmml">𝒱</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><apply id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1"><in id="S5.SS2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1.1"></in><ci id="S5.SS2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.p1.2.m2.1.1.2">𝑦</ci><ci id="S5.SS2.p1.2.m2.1.1.3.cmml" xref="S5.SS2.p1.2.m2.1.1.3">𝒱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">y\in\mathcal{V}</annotation></semantics></math> (<math alttext="\mathcal{V}" class="ltx_Math" display="inline" id="S5.SS2.p1.3.m3.1"><semantics id="S5.SS2.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml">𝒱</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><ci id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1">𝒱</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">\mathcal{V}</annotation></semantics></math>는 어휘)의 확률 분포를 제공하도록 요청받는다. {<span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.6.1">A</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.6.2">B</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.6.3">C</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.6.4">D</span>}, 관련 토큰의 확률을 추출하고 수집합니다. 각 라벨 <math alttext="t" class="ltx_Math" display="inline" id="S5.SS2.p1.6.m6.1"><semantics id="S5.SS2.p1.6.m6.1a"><mi id="S5.SS2.p1.6.m6.1.1" xref="S5.SS2.p1.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.6.m6.1b"><ci id="S5.SS2.p1.6.m6.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.6.m6.1c">t</annotation></semantics></math>를 어휘 내의 토큰에 매핑하기 위해 구두기 <math alttext="\mathcal{V(\cdot)}" class="ltx_Math" display="inline" id="S5.SS2.p1.5.m5.1"><semantics id="S5.SS2.p1.5.m5.1a"><mrow id="S5.SS2.p1.5.m5.1.2" xref="S5.SS2.p1.5.m5.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p1.5.m5.1.2.2" xref="S5.SS2.p1.5.m5.1.2.2.cmml">𝒱</mi><mo id="S5.SS2.p1.5.m5.1.2.1" lspace="0em" rspace="0em" xref="S5.SS2.p1.5.m5.1.2.1.cmml">​</mo><mrow id="S5.SS2.p1.5.m5.1.2.3.2" xref="S5.SS2.p1.5.m5.1.2.cmml"><mo id="S5.SS2.p1.5.m5.1.2.3.2.1" stretchy="false" xref="S5.SS2.p1.5.m5.1.2.cmml">(</mo><mo id="S5.SS2.p1.5.m5.1.1" lspace="0em" rspace="0em" xref="S5.SS2.p1.5.m5.1.1.cmml">⋅</mo><mo id="S5.SS2.p1.5.m5.1.2.3.2.2" stretchy="false" xref="S5.SS2.p1.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.5.m5.1b"><apply id="S5.SS2.p1.5.m5.1.2.cmml" xref="S5.SS2.p1.5.m5.1.2"><times id="S5.SS2.p1.5.m5.1.2.1.cmml" xref="S5.SS2.p1.5.m5.1.2.1"></times><ci id="S5.SS2.p1.5.m5.1.2.2.cmml" xref="S5.SS2.p1.5.m5.1.2.2">𝒱</ci><ci id="S5.SS2.p1.5.m5.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.5.m5.1c">\mathcal{V(\cdot)}</annotation></semantics></math>를 도입한다:</p>
<table id="S5.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.Ex1.m1.10" class="ltx_Math" alttext="\mathcal{V}(\texttt{A})=\{\textrm{`A'},`\textrm{\raisebox{0.0pt}{\rule{10.00002pt}{1.25pt}}A'}\},\ \ \mathcal{V}(\texttt{B})=\{\textrm{`B'},`\textrm{\raisebox{0.0pt}{\rule{10.00002pt}{1.25pt}}B'}\},\ \ \mathcal{V}(\texttt{C})=\{\textrm{`C'},`\textrm{\raisebox{0.0pt}{\rule{10.00002pt}{1.25pt}}C'}\},\ \ \mathcal{V}(\texttt{D})=\{\textrm{`D'},`\textrm{\raisebox{0.0pt}{\rule{10.00002pt}{1.25pt}}D'}\}" display="block"><semantics id="S5.Ex1.m1.10a"><mrow id="S5.Ex1.m1.10.10.2" xref="S5.Ex1.m1.10.10.3.cmml"><mrow id="S5.Ex1.m1.9.9.1.1" xref="S5.Ex1.m1.9.9.1.1.cmml"><mrow id="S5.Ex1.m1.9.9.1.1.3" xref="S5.Ex1.m1.9.9.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.Ex1.m1.9.9.1.1.3.2" xref="S5.Ex1.m1.9.9.1.1.3.2.cmml">𝒱</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.9.9.1.1.3.1" xref="S5.Ex1.m1.9.9.1.1.3.1.cmml">​</mo><mrow id="S5.Ex1.m1.9.9.1.1.3.3.2" xref="S5.Ex1.m1.1.1a.cmml"><mo stretchy="false" id="S5.Ex1.m1.9.9.1.1.3.3.2.1" xref="S5.Ex1.m1.1.1a.cmml">(</mo><mtext class="ltx_mathvariant_monospace" id="S5.Ex1.m1.1.1" xref="S5.Ex1.m1.1.1.cmml">A</mtext><mo stretchy="false" id="S5.Ex1.m1.9.9.1.1.3.3.2.2" xref="S5.Ex1.m1.1.1a.cmml">)</mo></mrow></mrow><mo id="S5.Ex1.m1.9.9.1.1.2" xref="S5.Ex1.m1.9.9.1.1.2.cmml">=</mo><mrow id="S5.Ex1.m1.9.9.1.1.1.1" xref="S5.Ex1.m1.9.9.1.1.1.2.cmml"><mo stretchy="false" id="S5.Ex1.m1.9.9.1.1.1.1.2" xref="S5.Ex1.m1.9.9.1.1.1.2.cmml">{</mo><mtext id="S5.Ex1.m1.2.2" xref="S5.Ex1.m1.2.2a.cmml">‘A’</mtext><mo id="S5.Ex1.m1.9.9.1.1.1.1.3" xref="S5.Ex1.m1.9.9.1.1.1.2.cmml">,</mo><mrow id="S5.Ex1.m1.9.9.1.1.1.1.1" xref="S5.Ex1.m1.9.9.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S5.Ex1.m1.9.9.1.1.1.1.1.2" xref="S5.Ex1.m1.9.9.1.1.1.1.1.2.cmml">`</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.9.9.1.1.1.1.1.1" xref="S5.Ex1.m1.9.9.1.1.1.1.1.1.cmml">​</mo><mrow id="S5.Ex1.m1.9.9.1.1.1.1.1.3" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3e.cmml"><mpadded voffset="0.0pt" id="S5.Ex1.m1.9.9.1.1.1.1.1.3a" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3e.cmml"><mtext id="S5.Ex1.m1.9.9.1.1.1.1.1.3b" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3e.cmml"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.9.9.1.1.1.1.1.3d" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3e.cmml">A’</mtext></mrow></mrow><mo stretchy="false" id="S5.Ex1.m1.9.9.1.1.1.1.4" xref="S5.Ex1.m1.9.9.1.1.1.2.cmml">}</mo></mrow></mrow><mo rspace="1.167em" id="S5.Ex1.m1.10.10.2.3" xref="S5.Ex1.m1.10.10.3a.cmml">,</mo><mrow id="S5.Ex1.m1.10.10.2.2.2" xref="S5.Ex1.m1.10.10.2.2.3.cmml"><mrow id="S5.Ex1.m1.10.10.2.2.1.1" xref="S5.Ex1.m1.10.10.2.2.1.1.cmml"><mrow id="S5.Ex1.m1.10.10.2.2.1.1.3" xref="S5.Ex1.m1.10.10.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.Ex1.m1.10.10.2.2.1.1.3.2" xref="S5.Ex1.m1.10.10.2.2.1.1.3.2.cmml">𝒱</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.10.10.2.2.1.1.3.1" xref="S5.Ex1.m1.10.10.2.2.1.1.3.1.cmml">​</mo><mrow id="S5.Ex1.m1.10.10.2.2.1.1.3.3.2" xref="S5.Ex1.m1.3.3a.cmml"><mo stretchy="false" id="S5.Ex1.m1.10.10.2.2.1.1.3.3.2.1" xref="S5.Ex1.m1.3.3a.cmml">(</mo><mtext class="ltx_mathvariant_monospace" id="S5.Ex1.m1.3.3" xref="S5.Ex1.m1.3.3.cmml">B</mtext><mo stretchy="false" id="S5.Ex1.m1.10.10.2.2.1.1.3.3.2.2" xref="S5.Ex1.m1.3.3a.cmml">)</mo></mrow></mrow><mo id="S5.Ex1.m1.10.10.2.2.1.1.2" xref="S5.Ex1.m1.10.10.2.2.1.1.2.cmml">=</mo><mrow id="S5.Ex1.m1.10.10.2.2.1.1.1.1" xref="S5.Ex1.m1.10.10.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S5.Ex1.m1.10.10.2.2.1.1.1.1.2" xref="S5.Ex1.m1.10.10.2.2.1.1.1.2.cmml">{</mo><mtext id="S5.Ex1.m1.4.4" xref="S5.Ex1.m1.4.4a.cmml">‘B’</mtext><mo id="S5.Ex1.m1.10.10.2.2.1.1.1.1.3" xref="S5.Ex1.m1.10.10.2.2.1.1.1.2.cmml">,</mo><mrow id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.2" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.2.cmml">`</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.1" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.1.cmml">​</mo><mrow id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3e.cmml"><mpadded voffset="0.0pt" id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3a" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3e.cmml"><mtext id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3b" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3e.cmml"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3d" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3e.cmml">B’</mtext></mrow></mrow><mo stretchy="false" id="S5.Ex1.m1.10.10.2.2.1.1.1.1.4" xref="S5.Ex1.m1.10.10.2.2.1.1.1.2.cmml">}</mo></mrow></mrow><mo rspace="1.167em" id="S5.Ex1.m1.10.10.2.2.2.3" xref="S5.Ex1.m1.10.10.2.2.3a.cmml">,</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2" xref="S5.Ex1.m1.10.10.2.2.2.2.3.cmml"><mrow id="S5.Ex1.m1.10.10.2.2.2.2.1.1" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.cmml"><mrow id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.2" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.2.cmml">𝒱</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.1" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.1.cmml">​</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.3.2" xref="S5.Ex1.m1.5.5a.cmml"><mo stretchy="false" id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.3.2.1" xref="S5.Ex1.m1.5.5a.cmml">(</mo><mtext class="ltx_mathvariant_monospace" id="S5.Ex1.m1.5.5" xref="S5.Ex1.m1.5.5.cmml">C</mtext><mo stretchy="false" id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.3.2.2" xref="S5.Ex1.m1.5.5a.cmml">)</mo></mrow></mrow><mo id="S5.Ex1.m1.10.10.2.2.2.2.1.1.2" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.2.cmml">=</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.2" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.2.cmml">{</mo><mtext id="S5.Ex1.m1.6.6" xref="S5.Ex1.m1.6.6a.cmml">‘C’</mtext><mo id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.3" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.2.cmml">,</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.2" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.2.cmml">`</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.1" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.1.cmml">​</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3e.cmml"><mpadded voffset="0.0pt" id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3a" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3e.cmml"><mtext id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3b" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3e.cmml"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3d" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3e.cmml">C’</mtext></mrow></mrow><mo stretchy="false" id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.4" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.2.cmml">}</mo></mrow></mrow><mo rspace="1.167em" id="S5.Ex1.m1.10.10.2.2.2.2.2.3" xref="S5.Ex1.m1.10.10.2.2.2.2.3a.cmml">,</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2.2" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.cmml"><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.2" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.2.cmml">𝒱</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.1" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.1.cmml">​</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.3.2" xref="S5.Ex1.m1.7.7a.cmml"><mo stretchy="false" id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.3.2.1" xref="S5.Ex1.m1.7.7a.cmml">(</mo><mtext class="ltx_mathvariant_monospace" id="S5.Ex1.m1.7.7" xref="S5.Ex1.m1.7.7.cmml">D</mtext><mo stretchy="false" id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.3.2.2" xref="S5.Ex1.m1.7.7a.cmml">)</mo></mrow></mrow><mo id="S5.Ex1.m1.10.10.2.2.2.2.2.2.2" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.2.cmml">=</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.2.cmml"><mo stretchy="false" id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.2" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.2.cmml">{</mo><mtext id="S5.Ex1.m1.8.8" xref="S5.Ex1.m1.8.8a.cmml">‘D’</mtext><mo id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.3" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.2.cmml">,</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.cmml"><mi mathvariant="normal" id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.2" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.2.cmml">`</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.1" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.1.cmml">​</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3e.cmml"><mpadded voffset="0.0pt" id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3a" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3e.cmml"><mtext id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3b" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3e.cmml"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3d" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3e.cmml">D’</mtext></mrow></mrow><mo stretchy="false" id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.4" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.2.cmml">}</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.Ex1.m1.10b"><apply id="S5.Ex1.m1.10.10.3.cmml" xref="S5.Ex1.m1.10.10.2"><csymbol cd="ambiguous" id="S5.Ex1.m1.10.10.3a.cmml" xref="S5.Ex1.m1.10.10.2.3">formulae-sequence</csymbol><apply id="S5.Ex1.m1.9.9.1.1.cmml" xref="S5.Ex1.m1.9.9.1.1"><eq id="S5.Ex1.m1.9.9.1.1.2.cmml" xref="S5.Ex1.m1.9.9.1.1.2"></eq><apply id="S5.Ex1.m1.9.9.1.1.3.cmml" xref="S5.Ex1.m1.9.9.1.1.3"><times id="S5.Ex1.m1.9.9.1.1.3.1.cmml" xref="S5.Ex1.m1.9.9.1.1.3.1"></times><ci id="S5.Ex1.m1.9.9.1.1.3.2.cmml" xref="S5.Ex1.m1.9.9.1.1.3.2">𝒱</ci><ci id="S5.Ex1.m1.1.1a.cmml" xref="S5.Ex1.m1.9.9.1.1.3.3.2"><mtext class="ltx_mathvariant_monospace" id="S5.Ex1.m1.1.1.cmml" xref="S5.Ex1.m1.1.1">A</mtext></ci></apply><set id="S5.Ex1.m1.9.9.1.1.1.2.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1"><ci id="S5.Ex1.m1.2.2a.cmml" xref="S5.Ex1.m1.2.2"><mtext id="S5.Ex1.m1.2.2.cmml" xref="S5.Ex1.m1.2.2">‘A’</mtext></ci><apply id="S5.Ex1.m1.9.9.1.1.1.1.1.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1.1"><times id="S5.Ex1.m1.9.9.1.1.1.1.1.1.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1.1.1"></times><ci id="S5.Ex1.m1.9.9.1.1.1.1.1.2.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1.1.2">`</ci><ci id="S5.Ex1.m1.9.9.1.1.1.1.1.3e.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3"><mrow id="S5.Ex1.m1.9.9.1.1.1.1.1.3.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3"><mpadded voffset="0.0pt" id="S5.Ex1.m1.9.9.1.1.1.1.1.3a.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3"><mtext id="S5.Ex1.m1.9.9.1.1.1.1.1.3b.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.9.9.1.1.1.1.1.3d.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3">A’</mtext></mrow></ci></apply></set></apply><apply id="S5.Ex1.m1.10.10.2.2.3.cmml" xref="S5.Ex1.m1.10.10.2.2.2"><csymbol cd="ambiguous" id="S5.Ex1.m1.10.10.2.2.3a.cmml" xref="S5.Ex1.m1.10.10.2.2.2.3">formulae-sequence</csymbol><apply id="S5.Ex1.m1.10.10.2.2.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1"><eq id="S5.Ex1.m1.10.10.2.2.1.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.2"></eq><apply id="S5.Ex1.m1.10.10.2.2.1.1.3.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.3"><times id="S5.Ex1.m1.10.10.2.2.1.1.3.1.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.3.1"></times><ci id="S5.Ex1.m1.10.10.2.2.1.1.3.2.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.3.2">𝒱</ci><ci id="S5.Ex1.m1.3.3a.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.3.3.2"><mtext class="ltx_mathvariant_monospace" id="S5.Ex1.m1.3.3.cmml" xref="S5.Ex1.m1.3.3">B</mtext></ci></apply><set id="S5.Ex1.m1.10.10.2.2.1.1.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1"><ci id="S5.Ex1.m1.4.4a.cmml" xref="S5.Ex1.m1.4.4"><mtext id="S5.Ex1.m1.4.4.cmml" xref="S5.Ex1.m1.4.4">‘B’</mtext></ci><apply id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1"><times id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.1"></times><ci id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.2">`</ci><ci id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3e.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3"><mrow id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3"><mpadded voffset="0.0pt" id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3a.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3"><mtext id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3b.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3d.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3">B’</mtext></mrow></ci></apply></set></apply><apply id="S5.Ex1.m1.10.10.2.2.2.2.3.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.Ex1.m1.10.10.2.2.2.2.3a.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S5.Ex1.m1.10.10.2.2.2.2.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1"><eq id="S5.Ex1.m1.10.10.2.2.2.2.1.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.2"></eq><apply id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.3"><times id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.1.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.1"></times><ci id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.2">𝒱</ci><ci id="S5.Ex1.m1.5.5a.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.3.2"><mtext class="ltx_mathvariant_monospace" id="S5.Ex1.m1.5.5.cmml" xref="S5.Ex1.m1.5.5">C</mtext></ci></apply><set id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1"><ci id="S5.Ex1.m1.6.6a.cmml" xref="S5.Ex1.m1.6.6"><mtext id="S5.Ex1.m1.6.6.cmml" xref="S5.Ex1.m1.6.6">‘C’</mtext></ci><apply id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1"><times id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.1"></times><ci id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.2">`</ci><ci id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3e.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3"><mrow id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3"><mpadded voffset="0.0pt" id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3a.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3"><mtext id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3b.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3d.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3">C’</mtext></mrow></ci></apply></set></apply><apply id="S5.Ex1.m1.10.10.2.2.2.2.2.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2"><eq id="S5.Ex1.m1.10.10.2.2.2.2.2.2.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.2"></eq><apply id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.3"><times id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.1.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.1"></times><ci id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.2">𝒱</ci><ci id="S5.Ex1.m1.7.7a.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.3.2"><mtext class="ltx_mathvariant_monospace" id="S5.Ex1.m1.7.7.cmml" xref="S5.Ex1.m1.7.7">D</mtext></ci></apply><set id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1"><ci id="S5.Ex1.m1.8.8a.cmml" xref="S5.Ex1.m1.8.8"><mtext id="S5.Ex1.m1.8.8.cmml" xref="S5.Ex1.m1.8.8">‘D’</mtext></ci><apply id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1"><times id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.1"></times><ci id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.2">`</ci><ci id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3e.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3"><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3"><mpadded voffset="0.0pt" id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3a.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3"><mtext id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3b.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3d.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3">D’</mtext></mrow></ci></apply></set></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.Ex1.m1.10c">\mathcal{V}(\texttt{A})=\{\textrm{`A'},`\textrm{\raisebox{0.0pt}{\rule{10.00002pt}{1.25pt}}A'}\},\ \ \mathcal{V}(\texttt{B})=\{\textrm{`B'},`\textrm{\raisebox{0.0pt}{\rule{10.00002pt}{1.25pt}}B'}\},\ \ \mathcal{V}(\texttt{C})=\{\textrm{`C'},`\textrm{\raisebox{0.0pt}{\rule{10.00002pt}{1.25pt}}C'}\},\ \ \mathcal{V}(\texttt{D})=\{\textrm{`D'},`\textrm{\raisebox{0.0pt}{\rule{10.00002pt}{1.25pt}}D'}\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S5.SS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.p2.1">라벨 <math alttext="t" class="ltx_Math" display="inline" id="S5.SS2.p2.1.m1.1"><semantics id="S5.SS2.p2.1.m1.1a"><mi id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><ci id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">t</annotation></semantics></math>를 예측할 확률은 다음과 같이 주어진다.</p>
<table id="S5.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E4.m1.7" class="ltx_Math" alttext="p(t\in\{\texttt{A},\texttt{B},\texttt{C},\texttt{D}\}|\bm{x})=\sum_{t\in\mathcal{V}(i)}p(y=i|\bm{x})" display="block"><semantics id="S5.E4.m1.7a"><mrow id="S5.E4.m1.7.7" xref="S5.E4.m1.7.7.cmml"><mrow id="S5.E4.m1.6.6.1" xref="S5.E4.m1.6.6.1.cmml"><mi id="S5.E4.m1.6.6.1.3" xref="S5.E4.m1.6.6.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.E4.m1.6.6.1.2" xref="S5.E4.m1.6.6.1.2.cmml">​</mo><mrow id="S5.E4.m1.6.6.1.1.1" xref="S5.E4.m1.6.6.1.1.1.1.cmml"><mo stretchy="false" id="S5.E4.m1.6.6.1.1.1.2" xref="S5.E4.m1.6.6.1.1.1.1.cmml">(</mo><mrow id="S5.E4.m1.6.6.1.1.1.1" xref="S5.E4.m1.6.6.1.1.1.1.cmml"><mi id="S5.E4.m1.6.6.1.1.1.1.2" xref="S5.E4.m1.6.6.1.1.1.1.2.cmml">t</mi><mo id="S5.E4.m1.6.6.1.1.1.1.1" xref="S5.E4.m1.6.6.1.1.1.1.1.cmml">∈</mo><mrow id="S5.E4.m1.6.6.1.1.1.1.3" xref="S5.E4.m1.6.6.1.1.1.1.3.cmml"><mrow id="S5.E4.m1.6.6.1.1.1.1.3.2.2" xref="S5.E4.m1.6.6.1.1.1.1.3.2.1.cmml"><mo stretchy="false" id="S5.E4.m1.6.6.1.1.1.1.3.2.2.1" xref="S5.E4.m1.6.6.1.1.1.1.3.2.1.cmml">{</mo><mtext class="ltx_mathvariant_monospace" id="S5.E4.m1.2.2" xref="S5.E4.m1.2.2a.cmml">A</mtext><mo id="S5.E4.m1.6.6.1.1.1.1.3.2.2.2" xref="S5.E4.m1.6.6.1.1.1.1.3.2.1.cmml">,</mo><mtext class="ltx_mathvariant_monospace" id="S5.E4.m1.3.3" xref="S5.E4.m1.3.3a.cmml">B</mtext><mo id="S5.E4.m1.6.6.1.1.1.1.3.2.2.3" xref="S5.E4.m1.6.6.1.1.1.1.3.2.1.cmml">,</mo><mtext class="ltx_mathvariant_monospace" id="S5.E4.m1.4.4" xref="S5.E4.m1.4.4a.cmml">C</mtext><mo id="S5.E4.m1.6.6.1.1.1.1.3.2.2.4" xref="S5.E4.m1.6.6.1.1.1.1.3.2.1.cmml">,</mo><mtext class="ltx_mathvariant_monospace" id="S5.E4.m1.5.5" xref="S5.E4.m1.5.5a.cmml">D</mtext><mo stretchy="false" id="S5.E4.m1.6.6.1.1.1.1.3.2.2.5" xref="S5.E4.m1.6.6.1.1.1.1.3.2.1.cmml">}</mo></mrow><mo fence="false" id="S5.E4.m1.6.6.1.1.1.1.3.1" xref="S5.E4.m1.6.6.1.1.1.1.3.1.cmml">|</mo><mi id="S5.E4.m1.6.6.1.1.1.1.3.3" xref="S5.E4.m1.6.6.1.1.1.1.3.3.cmml">𝒙</mi></mrow></mrow><mo stretchy="false" id="S5.E4.m1.6.6.1.1.1.3" xref="S5.E4.m1.6.6.1.1.1.1.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S5.E4.m1.7.7.3" xref="S5.E4.m1.7.7.3.cmml">=</mo><mrow id="S5.E4.m1.7.7.2" xref="S5.E4.m1.7.7.2.cmml"><munder id="S5.E4.m1.7.7.2.2" xref="S5.E4.m1.7.7.2.2.cmml"><mo movablelimits="false" id="S5.E4.m1.7.7.2.2.2" xref="S5.E4.m1.7.7.2.2.2.cmml">∑</mo><mrow id="S5.E4.m1.1.1.1" xref="S5.E4.m1.1.1.1.cmml"><mi id="S5.E4.m1.1.1.1.3" xref="S5.E4.m1.1.1.1.3.cmml">t</mi><mo id="S5.E4.m1.1.1.1.2" xref="S5.E4.m1.1.1.1.2.cmml">∈</mo><mrow id="S5.E4.m1.1.1.1.4" xref="S5.E4.m1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E4.m1.1.1.1.4.2" xref="S5.E4.m1.1.1.1.4.2.cmml">𝒱</mi><mo lspace="0em" rspace="0em" id="S5.E4.m1.1.1.1.4.1" xref="S5.E4.m1.1.1.1.4.1.cmml">​</mo><mrow id="S5.E4.m1.1.1.1.4.3.2" xref="S5.E4.m1.1.1.1.4.cmml"><mo stretchy="false" id="S5.E4.m1.1.1.1.4.3.2.1" xref="S5.E4.m1.1.1.1.4.cmml">(</mo><mi id="S5.E4.m1.1.1.1.1" xref="S5.E4.m1.1.1.1.1.cmml">i</mi><mo stretchy="false" id="S5.E4.m1.1.1.1.4.3.2.2" xref="S5.E4.m1.1.1.1.4.cmml">)</mo></mrow></mrow></mrow></munder><mrow id="S5.E4.m1.7.7.2.1" xref="S5.E4.m1.7.7.2.1.cmml"><mi id="S5.E4.m1.7.7.2.1.3" xref="S5.E4.m1.7.7.2.1.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.E4.m1.7.7.2.1.2" xref="S5.E4.m1.7.7.2.1.2.cmml">​</mo><mrow id="S5.E4.m1.7.7.2.1.1.1" xref="S5.E4.m1.7.7.2.1.1.1.1.cmml"><mo stretchy="false" id="S5.E4.m1.7.7.2.1.1.1.2" xref="S5.E4.m1.7.7.2.1.1.1.1.cmml">(</mo><mrow id="S5.E4.m1.7.7.2.1.1.1.1" xref="S5.E4.m1.7.7.2.1.1.1.1.cmml"><mi id="S5.E4.m1.7.7.2.1.1.1.1.2" xref="S5.E4.m1.7.7.2.1.1.1.1.2.cmml">y</mi><mo id="S5.E4.m1.7.7.2.1.1.1.1.1" xref="S5.E4.m1.7.7.2.1.1.1.1.1.cmml">=</mo><mrow id="S5.E4.m1.7.7.2.1.1.1.1.3" xref="S5.E4.m1.7.7.2.1.1.1.1.3.cmml"><mi id="S5.E4.m1.7.7.2.1.1.1.1.3.2" xref="S5.E4.m1.7.7.2.1.1.1.1.3.2.cmml">i</mi><mo fence="false" id="S5.E4.m1.7.7.2.1.1.1.1.3.1" xref="S5.E4.m1.7.7.2.1.1.1.1.3.1.cmml">|</mo><mi id="S5.E4.m1.7.7.2.1.1.1.1.3.3" xref="S5.E4.m1.7.7.2.1.1.1.1.3.3.cmml">𝒙</mi></mrow></mrow><mo stretchy="false" id="S5.E4.m1.7.7.2.1.1.1.3" xref="S5.E4.m1.7.7.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E4.m1.7b"><apply id="S5.E4.m1.7.7.cmml" xref="S5.E4.m1.7.7"><eq id="S5.E4.m1.7.7.3.cmml" xref="S5.E4.m1.7.7.3"></eq><apply id="S5.E4.m1.6.6.1.cmml" xref="S5.E4.m1.6.6.1"><times id="S5.E4.m1.6.6.1.2.cmml" xref="S5.E4.m1.6.6.1.2"></times><ci id="S5.E4.m1.6.6.1.3.cmml" xref="S5.E4.m1.6.6.1.3">𝑝</ci><apply id="S5.E4.m1.6.6.1.1.1.1.cmml" xref="S5.E4.m1.6.6.1.1.1"><in id="S5.E4.m1.6.6.1.1.1.1.1.cmml" xref="S5.E4.m1.6.6.1.1.1.1.1"></in><ci id="S5.E4.m1.6.6.1.1.1.1.2.cmml" xref="S5.E4.m1.6.6.1.1.1.1.2">𝑡</ci><apply id="S5.E4.m1.6.6.1.1.1.1.3.cmml" xref="S5.E4.m1.6.6.1.1.1.1.3"><csymbol cd="latexml" id="S5.E4.m1.6.6.1.1.1.1.3.1.cmml" xref="S5.E4.m1.6.6.1.1.1.1.3.1">conditional</csymbol><set id="S5.E4.m1.6.6.1.1.1.1.3.2.1.cmml" xref="S5.E4.m1.6.6.1.1.1.1.3.2.2"><ci id="S5.E4.m1.2.2a.cmml" xref="S5.E4.m1.2.2"><mtext class="ltx_mathvariant_monospace" id="S5.E4.m1.2.2.cmml" xref="S5.E4.m1.2.2">A</mtext></ci><ci id="S5.E4.m1.3.3a.cmml" xref="S5.E4.m1.3.3"><mtext class="ltx_mathvariant_monospace" id="S5.E4.m1.3.3.cmml" xref="S5.E4.m1.3.3">B</mtext></ci><ci id="S5.E4.m1.4.4a.cmml" xref="S5.E4.m1.4.4"><mtext class="ltx_mathvariant_monospace" id="S5.E4.m1.4.4.cmml" xref="S5.E4.m1.4.4">C</mtext></ci><ci id="S5.E4.m1.5.5a.cmml" xref="S5.E4.m1.5.5"><mtext class="ltx_mathvariant_monospace" id="S5.E4.m1.5.5.cmml" xref="S5.E4.m1.5.5">D</mtext></ci></set><ci id="S5.E4.m1.6.6.1.1.1.1.3.3.cmml" xref="S5.E4.m1.6.6.1.1.1.1.3.3">𝒙</ci></apply></apply></apply><apply id="S5.E4.m1.7.7.2.cmml" xref="S5.E4.m1.7.7.2"><apply id="S5.E4.m1.7.7.2.2.cmml" xref="S5.E4.m1.7.7.2.2"><csymbol cd="ambiguous" id="S5.E4.m1.7.7.2.2.1.cmml" xref="S5.E4.m1.7.7.2.2">subscript</csymbol><sum id="S5.E4.m1.7.7.2.2.2.cmml" xref="S5.E4.m1.7.7.2.2.2"></sum><apply id="S5.E4.m1.1.1.1.cmml" xref="S5.E4.m1.1.1.1"><in id="S5.E4.m1.1.1.1.2.cmml" xref="S5.E4.m1.1.1.1.2"></in><ci id="S5.E4.m1.1.1.1.3.cmml" xref="S5.E4.m1.1.1.1.3">𝑡</ci><apply id="S5.E4.m1.1.1.1.4.cmml" xref="S5.E4.m1.1.1.1.4"><times id="S5.E4.m1.1.1.1.4.1.cmml" xref="S5.E4.m1.1.1.1.4.1"></times><ci id="S5.E4.m1.1.1.1.4.2.cmml" xref="S5.E4.m1.1.1.1.4.2">𝒱</ci><ci id="S5.E4.m1.1.1.1.1.cmml" xref="S5.E4.m1.1.1.1.1">𝑖</ci></apply></apply></apply><apply id="S5.E4.m1.7.7.2.1.cmml" xref="S5.E4.m1.7.7.2.1"><times id="S5.E4.m1.7.7.2.1.2.cmml" xref="S5.E4.m1.7.7.2.1.2"></times><ci id="S5.E4.m1.7.7.2.1.3.cmml" xref="S5.E4.m1.7.7.2.1.3">𝑝</ci><apply id="S5.E4.m1.7.7.2.1.1.1.1.cmml" xref="S5.E4.m1.7.7.2.1.1.1"><eq id="S5.E4.m1.7.7.2.1.1.1.1.1.cmml" xref="S5.E4.m1.7.7.2.1.1.1.1.1"></eq><ci id="S5.E4.m1.7.7.2.1.1.1.1.2.cmml" xref="S5.E4.m1.7.7.2.1.1.1.1.2">𝑦</ci><apply id="S5.E4.m1.7.7.2.1.1.1.1.3.cmml" xref="S5.E4.m1.7.7.2.1.1.1.1.3"><csymbol cd="latexml" id="S5.E4.m1.7.7.2.1.1.1.1.3.1.cmml" xref="S5.E4.m1.7.7.2.1.1.1.1.3.1">conditional</csymbol><ci id="S5.E4.m1.7.7.2.1.1.1.1.3.2.cmml" xref="S5.E4.m1.7.7.2.1.1.1.1.3.2">𝑖</ci><ci id="S5.E4.m1.7.7.2.1.1.1.1.3.3.cmml" xref="S5.E4.m1.7.7.2.1.1.1.1.3.3">𝒙</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E4.m1.7c">p(t\in\{\texttt{A},\texttt{B},\texttt{C},\texttt{D}\}|\bm{x})=\sum_{t\in\mathcal{V}(i)}p(y=i|\bm{x})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.SS2.p2.2">최대 확률을 갖는 라벨은 최종 예측으로 취해진다.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS2.p3.1">다음으로, 원래의 LLaMA 및 기타 모델과의 비교를 설명하기 위해 다음 두 하위 섹션에서 결과와 분석에 대해 자세히 설명한다.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Comparisons to Original LLaMA</h3>

<div id="S5.SS3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS3.p1.1">그림 <a class="ltx_ref" href="#S5.F2" title="Figure 2 ‣ 5.3 Comparisons to Original LLaMA ‣ 5 Results on Natural Language Understanding Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">2</span></a>는 우리 모델이 원래 LLaMA를 기반으로 어떻게 진화하는지 보여준다. 상세한 결과는 표 <a class="ltx_ref" href="#S5.T8" title="Table 8 ‣ 5.3 Comparisons to Original LLaMA ‣ 5 Results on Natural Language Understanding Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">8</span></a>에 묘사되어 있다. 우리는 주로 다음 측면에서 우리의 연구 결과를 설명한다.</p>
</div>
<figure id="S5.F2" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2304.08177/assets/x1.png" id="S5.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="187" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 2:</span> <span class="ltx_text ltx_font_bold" id="S5.F2.2.1">Results on C-Eval valid set. </span> 결과는 다른 설정(제로샷 및 5샷) 및 모델 크기(7B 및 13B)에 따라 그룹화됩니다.</figcaption>
</figure>
<figure id="S5.T8" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 8:</span> <span class="ltx_text ltx_font_bold" id="S5.T8.2.1">Results on C-Eval valid and test sets</span>. 모든 예측 파일은 자체적으로 생성됩니다. 테스트 세트 점수는 예측 파일을 C-Eval 리더보드에 제출하여 얻습니다.</figcaption>
<table id="S5.T8.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S5.T8.3.1" class="ltx_tr">
<td id="S5.T8.3.1.1" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S5.T8.3.1.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S5.T8.3.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S5.T8.3.1.2.1" class="ltx_text ltx_font_bold">Valid Set</span></td>
<td id="S5.T8.3.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S5.T8.3.1.3.1" class="ltx_text ltx_font_bold">Test Set</span></td>
</tr>
<tr id="S5.T8.3.2" class="ltx_tr">
<td id="S5.T8.3.2.1" class="ltx_td ltx_align_center"><span id="S5.T8.3.2.1.1" class="ltx_text ltx_font_bold">Zero-shot</span></td>
<td id="S5.T8.3.2.2" class="ltx_td ltx_align_center"><span id="S5.T8.3.2.2.1" class="ltx_text ltx_font_bold">5-shot</span></td>
<td id="S5.T8.3.2.3" class="ltx_td ltx_align_center"><span id="S5.T8.3.2.3.1" class="ltx_text ltx_font_bold">Zero-shot</span></td>
<td id="S5.T8.3.2.4" class="ltx_td ltx_align_center"><span id="S5.T8.3.2.4.1" class="ltx_text ltx_font_bold">5-shot</span></td>
</tr>
<tr id="S5.T8.3.3" class="ltx_tr">
<td id="S5.T8.3.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T8.3.3.1.1" class="ltx_text ltx_font_italic">Random</span></td>
<td id="S5.T8.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T8.3.3.2.1" class="ltx_text ltx_font_italic">25.0</span></td>
<td id="S5.T8.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T8.3.3.3.1" class="ltx_text ltx_font_italic">25.0</span></td>
<td id="S5.T8.3.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T8.3.3.4.1" class="ltx_text ltx_font_italic">25.0</span></td>
<td id="S5.T8.3.3.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T8.3.3.5.1" class="ltx_text ltx_font_italic">25.0</span></td>
</tr>
<tr id="S5.T8.3.4" class="ltx_tr">
<td id="S5.T8.3.4.1" class="ltx_td ltx_align_left ltx_border_t">LLaMA-65B</td>
<td id="S5.T8.3.4.2" class="ltx_td ltx_align_center ltx_border_t">37.2</td>
<td id="S5.T8.3.4.3" class="ltx_td ltx_align_center ltx_border_t">41.2</td>
<td id="S5.T8.3.4.4" class="ltx_td ltx_align_center ltx_border_t">33.4</td>
<td id="S5.T8.3.4.5" class="ltx_td ltx_align_center ltx_border_t">38.8</td>
</tr>
<tr id="S5.T8.3.5" class="ltx_tr">
<td id="S5.T8.3.5.1" class="ltx_td ltx_align_left">LLaMA-33B</td>
<td id="S5.T8.3.5.2" class="ltx_td ltx_align_center">34.5</td>
<td id="S5.T8.3.5.3" class="ltx_td ltx_align_center">37.9</td>
<td id="S5.T8.3.5.4" class="ltx_td ltx_align_center">32.4</td>
<td id="S5.T8.3.5.5" class="ltx_td ltx_align_center">36.0</td>
</tr>
<tr id="S5.T8.3.6" class="ltx_tr">
<td id="S5.T8.3.6.1" class="ltx_td ltx_align_left">LLaMA-13B</td>
<td id="S5.T8.3.6.2" class="ltx_td ltx_align_center">27.8</td>
<td id="S5.T8.3.6.3" class="ltx_td ltx_align_center">30.9</td>
<td id="S5.T8.3.6.4" class="ltx_td ltx_align_center">28.5</td>
<td id="S5.T8.3.6.5" class="ltx_td ltx_align_center">29.6</td>
</tr>
<tr id="S5.T8.3.7" class="ltx_tr">
<td id="S5.T8.3.7.1" class="ltx_td ltx_align_left">LLaMA-7B</td>
<td id="S5.T8.3.7.2" class="ltx_td ltx_align_center">25.6</td>
<td id="S5.T8.3.7.3" class="ltx_td ltx_align_center">25.3</td>
<td id="S5.T8.3.7.4" class="ltx_td ltx_align_center">26.7</td>
<td id="S5.T8.3.7.5" class="ltx_td ltx_align_center">27.8</td>
</tr>
<tr id="S5.T8.3.8" class="ltx_tr">
<td id="S5.T8.3.8.1" class="ltx_td ltx_align_left ltx_border_t">Chinese-LLaMA-33B</td>
<td id="S5.T8.3.8.2" class="ltx_td ltx_align_center ltx_border_t">34.9</td>
<td id="S5.T8.3.8.3" class="ltx_td ltx_align_center ltx_border_t">38.4</td>
<td id="S5.T8.3.8.4" class="ltx_td ltx_align_center ltx_border_t">34.6</td>
<td id="S5.T8.3.8.5" class="ltx_td ltx_align_center ltx_border_t">39.5</td>
</tr>
<tr id="S5.T8.3.9" class="ltx_tr">
<td id="S5.T8.3.9.1" class="ltx_td ltx_align_left">Chinese-LLaMA-Plus-13B</td>
<td id="S5.T8.3.9.2" class="ltx_td ltx_align_center">27.3</td>
<td id="S5.T8.3.9.3" class="ltx_td ltx_align_center">34.0</td>
<td id="S5.T8.3.9.4" class="ltx_td ltx_align_center">27.8</td>
<td id="S5.T8.3.9.5" class="ltx_td ltx_align_center">33.3</td>
</tr>
<tr id="S5.T8.3.10" class="ltx_tr">
<td id="S5.T8.3.10.1" class="ltx_td ltx_align_left">Chinese-LLaMA-13B</td>
<td id="S5.T8.3.10.2" class="ltx_td ltx_align_center">29.4</td>
<td id="S5.T8.3.10.3" class="ltx_td ltx_align_center">35.0</td>
<td id="S5.T8.3.10.4" class="ltx_td ltx_align_center">29.2</td>
<td id="S5.T8.3.10.5" class="ltx_td ltx_align_center">33.7</td>
</tr>
<tr id="S5.T8.3.11" class="ltx_tr">
<td id="S5.T8.3.11.1" class="ltx_td ltx_align_left">Chinese-LLaMA-Plus-7B</td>
<td id="S5.T8.3.11.2" class="ltx_td ltx_align_center">27.3</td>
<td id="S5.T8.3.11.3" class="ltx_td ltx_align_center">28.3</td>
<td id="S5.T8.3.11.4" class="ltx_td ltx_align_center">26.8</td>
<td id="S5.T8.3.11.5" class="ltx_td ltx_align_center">28.4</td>
</tr>
<tr id="S5.T8.3.12" class="ltx_tr">
<td id="S5.T8.3.12.1" class="ltx_td ltx_align_left">Chinese-LLaMA-7B</td>
<td id="S5.T8.3.12.2" class="ltx_td ltx_align_center">26.2</td>
<td id="S5.T8.3.12.3" class="ltx_td ltx_align_center">26.2</td>
<td id="S5.T8.3.12.4" class="ltx_td ltx_align_center">27.1</td>
<td id="S5.T8.3.12.5" class="ltx_td ltx_align_center">27.2</td>
</tr>
<tr id="S5.T8.3.13" class="ltx_tr">
<td id="S5.T8.3.13.1" class="ltx_td ltx_align_left ltx_border_t">Chinese-Alpaca-33B</td>
<td id="S5.T8.3.13.2" class="ltx_td ltx_align_center ltx_border_t">43.3</td>
<td id="S5.T8.3.13.3" class="ltx_td ltx_align_center ltx_border_t">42.6</td>
<td id="S5.T8.3.13.4" class="ltx_td ltx_align_center ltx_border_t">41.6</td>
<td id="S5.T8.3.13.5" class="ltx_td ltx_align_center ltx_border_t">40.4</td>
</tr>
<tr id="S5.T8.3.14" class="ltx_tr">
<td id="S5.T8.3.14.1" class="ltx_td ltx_align_left">Chinese-Alpaca-Plus-13B</td>
<td id="S5.T8.3.14.2" class="ltx_td ltx_align_center">43.3</td>
<td id="S5.T8.3.14.3" class="ltx_td ltx_align_center">42.4</td>
<td id="S5.T8.3.14.4" class="ltx_td ltx_align_center">41.5</td>
<td id="S5.T8.3.14.5" class="ltx_td ltx_align_center">39.9</td>
</tr>
<tr id="S5.T8.3.15" class="ltx_tr">
<td id="S5.T8.3.15.1" class="ltx_td ltx_align_left">Chinese-Alpaca-13B</td>
<td id="S5.T8.3.15.2" class="ltx_td ltx_align_center">37.1</td>
<td id="S5.T8.3.15.3" class="ltx_td ltx_align_center">36.3</td>
<td id="S5.T8.3.15.4" class="ltx_td ltx_align_center">36.7</td>
<td id="S5.T8.3.15.5" class="ltx_td ltx_align_center">34.5</td>
</tr>
<tr id="S5.T8.3.16" class="ltx_tr">
<td id="S5.T8.3.16.1" class="ltx_td ltx_align_left">Chinese-Alpaca-Plus-7B</td>
<td id="S5.T8.3.16.2" class="ltx_td ltx_align_center">36.7</td>
<td id="S5.T8.3.16.3" class="ltx_td ltx_align_center">32.9</td>
<td id="S5.T8.3.16.4" class="ltx_td ltx_align_center">36.4</td>
<td id="S5.T8.3.16.5" class="ltx_td ltx_align_center">32.3</td>
</tr>
<tr id="S5.T8.3.17" class="ltx_tr">
<td id="S5.T8.3.17.1" class="ltx_td ltx_align_left ltx_border_bb">Chinese-Alpaca-7B</td>
<td id="S5.T8.3.17.2" class="ltx_td ltx_align_center ltx_border_bb">30.8</td>
<td id="S5.T8.3.17.3" class="ltx_td ltx_align_center ltx_border_bb">32.5</td>
<td id="S5.T8.3.17.4" class="ltx_td ltx_align_center ltx_border_bb">30.7</td>
<td id="S5.T8.3.17.5" class="ltx_td ltx_align_center ltx_border_bb">29.2</td>
</tr>
</tbody></table>
</figure>
<section id="S5.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Chinese LLaMA improves original LLaMA.</h5>

<div id="S5.SS3.SSS0.Px1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS3.SSS0.Px1.p1.1">우리는 제안된 중국 LLaMA 모델이 원래 LLaMA에 비해 중간 정도의 개선을 가져온다는 것을 알 수 있으며, 이는 중국 데이터에 대한 사전 훈련이 C-Eval에 약간의 긍정적인 영향을 미치지만 항상 그렇지는 않다는 것을 보여준다. 중국 LLaMA와 LLaMA-Plus를 비교했을 때, 후자는 13B 설정에서 열등한 결과를 보이더라도 전자에 비해 큰 개선을 보이지 않는다. 이는 순수 언어 모델(LLaMA와 같은)이 C-Eval 또는 유사한 작업에 대해 좋은 선택이 아닐 수 있음을 나타낼 수 있으며 사전 훈련 데이터 크기(중국 LLaMA 및 LLaMA-Plus의 경우 각각 20G에서 120G로)를 증가시키는 데 큰 도움이 되지 않는다.</p>
</div>
</section>
<section id="S5.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Alpaca models show significant improvements over LLaMA.</h5>

<div id="S5.SS3.SSS0.Px2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS3.SSS0.Px2.p1.1">제로 샷 또는 5 샷과 같은 다양한 설정 중에서 알파카 모델 시리즈는 LLaMA 대응물에 비해 상당한 개선을 보여 명령 후속 모델이 순수 언어 모델보다 이러한 NLU 유사 작업을 더 잘 처리할 수 있음을 보여준다. LLaMA 시리즈에서 관찰된 현상과 달리 Alpaca-Plus 모델이 기본 Alpaca 모델에 비해 상당한 개선을 가져온다는 것을 알 수 있다. 이는 명령 후속 모델이 NLU와 유사한 작업을 더 잘 처리할 수 있고 더 많은 사전 훈련 데이터(LLaMA-Plus)를 사용하는 힘을 발휘할 수 있음을 추가로 나타낼 수 있다.</p>
</div>
</section>
<section id="S5.SS3.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">LLaMA generally yields better performance in a few-shot setting, while Alpaca prefers zero-shot.</h5>

<div id="S5.SS3.SSS0.Px3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS3.SSS0.Px3.p1.1">일반적으로, 5-샷 설정을 갖는 LLaMA는 제로-샷 설정보다 더 나은 성능을 나타내는 반면, 제로-샷 설정을 갖는 Alpaca는 5-샷 설정보다 훨씬 더 나은 성능을 나타낸다. LLaMA는 명령어 후속을 위해 설계되지 않았기 때문에 소수의 샷 설정은 C-Eval에서 질문 응답 구조를 따르는 방법에 대한 귀중한 정보를 제공할 수 있다. 그러나 반대로 알파카는 이미 수백만 개의 명령어 데이터로 훈련되었기 때문에 추가 샷의 혜택을 덜 받을 가능성이 높다. 또한 공식 5샷 설정은 모든 샘플에 대해 동일한 프롬프트를 사용하여 알파카 모델의 주의를 분산시킵니다.</p>
</div>
<div id="S5.SS3.SSS0.Px3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS3.SSS0.Px3.p2.1">이러한 관찰은 전적으로 C-Eval 데이터 세트의 결과를 기반으로 하며 다른 데이터 세트에 일반화할 수 있는지 여부는 추가 조사가 필요하다는 점을 강조하고자 한다. 향후에는 LLaMA 및 알파카 모델의 행동을 추가로 조사하기 위해 보다 포괄적인 테스트를 포함할 것이다.</p>
</div>
</section>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Comparisons to Other Models</h3>

<div id="S5.SS4.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS4.p1.1">우리는 C-Eval 리더보드에 중국-Alpaca-33B와 중국-Alpaca-Plus-13B의 두 가지 가장 성능이 좋은 모델을 포함하여 오픈 소스 및 비 오픈 소스 모델을 모두 포함한 다른 LLM과 비교한다. C-Eval 리더보드에 대한 테스트 결과(2023년 6월 9일 기준)는 표 <a class="ltx_ref" href="#S5.T9" title="Table 9 ‣ 5.4 Comparisons to Other Models ‣ 5 Results on Natural Language Understanding Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">9</span></a>와 같다.</p>
</div>
<figure id="S5.T9" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 9:</span> <span class="ltx_text ltx_font_bold" id="S5.T9.6.1">테스트 results on C-Eval leaderboard (as as June 9, 2023), ordered by average scores. </span> Model name with boldface represents our submission, while the other results is evaluated by C-Eval officials. 우리는 자체 추론 스크립트를 기반으로 <math alttext="{\dagger}" class="ltx_Math" display="inline" id="S5.T9.2.m1.1"><semantics id="S5.T9.2.m1.1b"><mo id="S5.T9.2.m1.1.1" xref="S5.T9.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T9.2.m1.1c"><ci id="S5.T9.2.m1.1.1.cmml" xref="S5.T9.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T9.2.m1.1d">{\dagger}</annotation></semantics></math>(이러한 점수는 공개적으로 표시되지 않음)로 표시된 두 모델을 재평가했으며 C-Eval에 의해 평가된 모델보다 훨씬 나은 성능을 달성했다. 모델의 매개변수 크기는 사용 가능한 경우 괄호 안에 표시됩니다. 오픈: 오픈 소스. Avg-H : 평균(Hard).</figcaption>
<table id="S5.T9.4.2" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S5.T9.4.2.3" class="ltx_tr">
<td id="S5.T9.4.2.3.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T9.4.2.3.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S5.T9.4.2.3.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T9.4.2.3.2.1" class="ltx_text ltx_font_bold">N-Shot</span></td>
<td id="S5.T9.4.2.3.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T9.4.2.3.3.1" class="ltx_text ltx_font_bold">Open</span></td>
<td id="S5.T9.4.2.3.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T9.4.2.3.4.1" class="ltx_text ltx_font_bold">Avg</span></td>
<td id="S5.T9.4.2.3.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T9.4.2.3.5.1" class="ltx_text ltx_font_bold">Avg-H</span></td>
<td id="S5.T9.4.2.3.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T9.4.2.3.6.1" class="ltx_text ltx_font_bold">STEM</span></td>
<td id="S5.T9.4.2.3.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T9.4.2.3.7.1" class="ltx_text ltx_font_bold">Social</span></td>
<td id="S5.T9.4.2.3.8" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T9.4.2.3.8.1" class="ltx_text ltx_font_bold">Human</span></td>
<td id="S5.T9.4.2.3.9" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T9.4.2.3.9.1" class="ltx_text ltx_font_bold">Others</span></td>
</tr>
<tr id="S5.T9.4.2.4" class="ltx_tr">
<td id="S5.T9.4.2.4.1" class="ltx_td ltx_align_left ltx_border_t">GPT-4</td>
<td id="S5.T9.4.2.4.2" class="ltx_td ltx_align_center ltx_border_t">5-shot</td>
<td id="S5.T9.4.2.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T9.4.2.4.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S5.T9.4.2.4.4" class="ltx_td ltx_align_center ltx_border_t">68.7</td>
<td id="S5.T9.4.2.4.5" class="ltx_td ltx_align_center ltx_border_t">54.9</td>
<td id="S5.T9.4.2.4.6" class="ltx_td ltx_align_center ltx_border_t">67.1</td>
<td id="S5.T9.4.2.4.7" class="ltx_td ltx_align_center ltx_border_t">77.6</td>
<td id="S5.T9.4.2.4.8" class="ltx_td ltx_align_center ltx_border_t">64.5</td>
<td id="S5.T9.4.2.4.9" class="ltx_td ltx_align_center ltx_border_t">67.8</td>
</tr>
<tr id="S5.T9.4.2.5" class="ltx_tr">
<td id="S5.T9.4.2.5.1" class="ltx_td ltx_align_left">InternLM (104B)</td>
<td id="S5.T9.4.2.5.2" class="ltx_td ltx_align_center">few-shot</td>
<td id="S5.T9.4.2.5.3" class="ltx_td ltx_align_center"><span id="S5.T9.4.2.5.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S5.T9.4.2.5.4" class="ltx_td ltx_align_center">62.7</td>
<td id="S5.T9.4.2.5.5" class="ltx_td ltx_align_center">46.0</td>
<td id="S5.T9.4.2.5.6" class="ltx_td ltx_align_center">58.1</td>
<td id="S5.T9.4.2.5.7" class="ltx_td ltx_align_center">76.7</td>
<td id="S5.T9.4.2.5.8" class="ltx_td ltx_align_center">64.6</td>
<td id="S5.T9.4.2.5.9" class="ltx_td ltx_align_center">56.4</td>
</tr>
<tr id="S5.T9.4.2.6" class="ltx_tr">
<td id="S5.T9.4.2.6.1" class="ltx_td ltx_align_left">ChatGPT</td>
<td id="S5.T9.4.2.6.2" class="ltx_td ltx_align_center">5-shot</td>
<td id="S5.T9.4.2.6.3" class="ltx_td ltx_align_center"><span id="S5.T9.4.2.6.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S5.T9.4.2.6.4" class="ltx_td ltx_align_center">54.4</td>
<td id="S5.T9.4.2.6.5" class="ltx_td ltx_align_center">41.4</td>
<td id="S5.T9.4.2.6.6" class="ltx_td ltx_align_center">52.9</td>
<td id="S5.T9.4.2.6.7" class="ltx_td ltx_align_center">61.8</td>
<td id="S5.T9.4.2.6.8" class="ltx_td ltx_align_center">50.9</td>
<td id="S5.T9.4.2.6.9" class="ltx_td ltx_align_center">53.6</td>
</tr>
<tr id="S5.T9.4.2.7" class="ltx_tr">
<td id="S5.T9.4.2.7.1" class="ltx_td ltx_align_left">Claude-v1.3</td>
<td id="S5.T9.4.2.7.2" class="ltx_td ltx_align_center">5-shot</td>
<td id="S5.T9.4.2.7.3" class="ltx_td ltx_align_center"><span id="S5.T9.4.2.7.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S5.T9.4.2.7.4" class="ltx_td ltx_align_center">54.2</td>
<td id="S5.T9.4.2.7.5" class="ltx_td ltx_align_center">39.0</td>
<td id="S5.T9.4.2.7.6" class="ltx_td ltx_align_center">51.9</td>
<td id="S5.T9.4.2.7.7" class="ltx_td ltx_align_center">61.7</td>
<td id="S5.T9.4.2.7.8" class="ltx_td ltx_align_center">52.1</td>
<td id="S5.T9.4.2.7.9" class="ltx_td ltx_align_center">53.7</td>
</tr>
<tr id="S5.T9.4.2.8" class="ltx_tr">
<td id="S5.T9.4.2.8.1" class="ltx_td ltx_align_left">Claude-instant-v1.0</td>
<td id="S5.T9.4.2.8.2" class="ltx_td ltx_align_center">5-shot</td>
<td id="S5.T9.4.2.8.3" class="ltx_td ltx_align_center"><span id="S5.T9.4.2.8.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S5.T9.4.2.8.4" class="ltx_td ltx_align_center">45.9</td>
<td id="S5.T9.4.2.8.5" class="ltx_td ltx_align_center">35.5</td>
<td id="S5.T9.4.2.8.6" class="ltx_td ltx_align_center">43.1</td>
<td id="S5.T9.4.2.8.7" class="ltx_td ltx_align_center">53.8</td>
<td id="S5.T9.4.2.8.8" class="ltx_td ltx_align_center">44.2</td>
<td id="S5.T9.4.2.8.9" class="ltx_td ltx_align_center">45.4</td>
</tr>
<tr id="S5.T9.4.2.9" class="ltx_tr">
<td id="S5.T9.4.2.9.1" class="ltx_td ltx_align_left">Bloomz-mt (176B)</td>
<td id="S5.T9.4.2.9.2" class="ltx_td ltx_align_center">0-shot</td>
<td id="S5.T9.4.2.9.3" class="ltx_td ltx_align_center"><span id="S5.T9.4.2.9.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.4.2.9.4" class="ltx_td ltx_align_center">44.3</td>
<td id="S5.T9.4.2.9.5" class="ltx_td ltx_align_center">30.8</td>
<td id="S5.T9.4.2.9.6" class="ltx_td ltx_align_center">39.0</td>
<td id="S5.T9.4.2.9.7" class="ltx_td ltx_align_center">53.0</td>
<td id="S5.T9.4.2.9.8" class="ltx_td ltx_align_center">47.7</td>
<td id="S5.T9.4.2.9.9" class="ltx_td ltx_align_center">42.7</td>
</tr>
<tr id="S5.T9.4.2.10" class="ltx_tr">
<td id="S5.T9.4.2.10.1" class="ltx_td ltx_align_left">GLM-130B</td>
<td id="S5.T9.4.2.10.2" class="ltx_td ltx_align_center">0-shot</td>
<td id="S5.T9.4.2.10.3" class="ltx_td ltx_align_center"><span id="S5.T9.4.2.10.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.4.2.10.4" class="ltx_td ltx_align_center">44.0</td>
<td id="S5.T9.4.2.10.5" class="ltx_td ltx_align_center">30.7</td>
<td id="S5.T9.4.2.10.6" class="ltx_td ltx_align_center">36.7</td>
<td id="S5.T9.4.2.10.7" class="ltx_td ltx_align_center">55.8</td>
<td id="S5.T9.4.2.10.8" class="ltx_td ltx_align_center">47.7</td>
<td id="S5.T9.4.2.10.9" class="ltx_td ltx_align_center">43.0</td>
</tr>
<tr id="S5.T9.4.2.11" class="ltx_tr">
<td id="S5.T9.4.2.11.1" class="ltx_td ltx_align_left"><span id="S5.T9.4.2.11.1.1" class="ltx_text ltx_font_bold">Chinese-Alpaca-33B</span></td>
<td id="S5.T9.4.2.11.2" class="ltx_td ltx_align_center">0-shot</td>
<td id="S5.T9.4.2.11.3" class="ltx_td ltx_align_center"><span id="S5.T9.4.2.11.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.4.2.11.4" class="ltx_td ltx_align_center">41.6</td>
<td id="S5.T9.4.2.11.5" class="ltx_td ltx_align_center">30.3</td>
<td id="S5.T9.4.2.11.6" class="ltx_td ltx_align_center">37.0</td>
<td id="S5.T9.4.2.11.7" class="ltx_td ltx_align_center">51.6</td>
<td id="S5.T9.4.2.11.8" class="ltx_td ltx_align_center">42.3</td>
<td id="S5.T9.4.2.11.9" class="ltx_td ltx_align_center">40.3</td>
</tr>
<tr id="S5.T9.4.2.12" class="ltx_tr">
<td id="S5.T9.4.2.12.1" class="ltx_td ltx_align_left"><span id="S5.T9.4.2.12.1.1" class="ltx_text ltx_font_bold">Chinese-Alpaca-Plus-13B</span></td>
<td id="S5.T9.4.2.12.2" class="ltx_td ltx_align_center">0-shot</td>
<td id="S5.T9.4.2.12.3" class="ltx_td ltx_align_center"><span id="S5.T9.4.2.12.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.4.2.12.4" class="ltx_td ltx_align_center">41.5</td>
<td id="S5.T9.4.2.12.5" class="ltx_td ltx_align_center">30.5</td>
<td id="S5.T9.4.2.12.6" class="ltx_td ltx_align_center">36.6</td>
<td id="S5.T9.4.2.12.7" class="ltx_td ltx_align_center">49.7</td>
<td id="S5.T9.4.2.12.8" class="ltx_td ltx_align_center">43.1</td>
<td id="S5.T9.4.2.12.9" class="ltx_td ltx_align_center">41.2</td>
</tr>
<tr id="S5.T9.4.2.13" class="ltx_tr">
<td id="S5.T9.4.2.13.1" class="ltx_td ltx_align_left">CubeLM (13B)</td>
<td id="S5.T9.4.2.13.2" class="ltx_td ltx_align_center">few-shot</td>
<td id="S5.T9.4.2.13.3" class="ltx_td ltx_align_center"><span id="S5.T9.4.2.13.3.1" class="ltx_text" style="color:#FF0000;">✗</span></td>
<td id="S5.T9.4.2.13.4" class="ltx_td ltx_align_center">40.2</td>
<td id="S5.T9.4.2.13.5" class="ltx_td ltx_align_center">27.3</td>
<td id="S5.T9.4.2.13.6" class="ltx_td ltx_align_center">34.1</td>
<td id="S5.T9.4.2.13.7" class="ltx_td ltx_align_center">49.7</td>
<td id="S5.T9.4.2.13.8" class="ltx_td ltx_align_center">43.4</td>
<td id="S5.T9.4.2.13.9" class="ltx_td ltx_align_center">39.6</td>
</tr>
<tr id="S5.T9.4.2.14" class="ltx_tr">
<td id="S5.T9.4.2.14.1" class="ltx_td ltx_align_left">ChatGLM-6B</td>
<td id="S5.T9.4.2.14.2" class="ltx_td ltx_align_center">0-shot</td>
<td id="S5.T9.4.2.14.3" class="ltx_td ltx_align_center"><span id="S5.T9.4.2.14.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.4.2.14.4" class="ltx_td ltx_align_center">38.9</td>
<td id="S5.T9.4.2.14.5" class="ltx_td ltx_align_center">29.2</td>
<td id="S5.T9.4.2.14.6" class="ltx_td ltx_align_center">33.3</td>
<td id="S5.T9.4.2.14.7" class="ltx_td ltx_align_center">48.3</td>
<td id="S5.T9.4.2.14.8" class="ltx_td ltx_align_center">41.3</td>
<td id="S5.T9.4.2.14.9" class="ltx_td ltx_align_center">38.0</td>
</tr>
<tr id="S5.T9.4.2.15" class="ltx_tr">
<td id="S5.T9.4.2.15.1" class="ltx_td ltx_align_left">LLaMA-65B</td>
<td id="S5.T9.4.2.15.2" class="ltx_td ltx_align_center">5-shot</td>
<td id="S5.T9.4.2.15.3" class="ltx_td ltx_align_center"><span id="S5.T9.4.2.15.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.4.2.15.4" class="ltx_td ltx_align_center">38.8</td>
<td id="S5.T9.4.2.15.5" class="ltx_td ltx_align_center">31.7</td>
<td id="S5.T9.4.2.15.6" class="ltx_td ltx_align_center">37.8</td>
<td id="S5.T9.4.2.15.7" class="ltx_td ltx_align_center">45.6</td>
<td id="S5.T9.4.2.15.8" class="ltx_td ltx_align_center">36.1</td>
<td id="S5.T9.4.2.15.9" class="ltx_td ltx_align_center">37.1</td>
</tr>
<tr id="S5.T9.3.1.1" class="ltx_tr">
<td id="S5.T9.3.1.1.1" class="ltx_td ltx_align_left"><span id="S5.T9.3.1.1.1.1" class="ltx_text ltx_font_bold">Chinese-Alpaca-13B<math id="S5.T9.3.1.1.1.1.m1.1" class="ltx_Math" alttext="{\dagger}" display="inline"><semantics id="S5.T9.3.1.1.1.1.m1.1a"><mo id="S5.T9.3.1.1.1.1.m1.1.1" xref="S5.T9.3.1.1.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T9.3.1.1.1.1.m1.1b"><ci id="S5.T9.3.1.1.1.1.m1.1.1.cmml" xref="S5.T9.3.1.1.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T9.3.1.1.1.1.m1.1c">{\dagger}</annotation></semantics></math></span></td>
<td id="S5.T9.3.1.1.2" class="ltx_td ltx_align_center">0-shot</td>
<td id="S5.T9.3.1.1.3" class="ltx_td ltx_align_center"><span id="S5.T9.3.1.1.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.3.1.1.4" class="ltx_td ltx_align_center">36.7</td>
<td id="S5.T9.3.1.1.5" class="ltx_td ltx_align_center">28.4</td>
<td id="S5.T9.3.1.1.6" class="ltx_td ltx_align_center">33.1</td>
<td id="S5.T9.3.1.1.7" class="ltx_td ltx_align_center">43.7</td>
<td id="S5.T9.3.1.1.8" class="ltx_td ltx_align_center">38.4</td>
<td id="S5.T9.3.1.1.9" class="ltx_td ltx_align_center">35.0</td>
</tr>
<tr id="S5.T9.4.2.2" class="ltx_tr">
<td id="S5.T9.4.2.2.1" class="ltx_td ltx_align_left"><span id="S5.T9.4.2.2.1.1" class="ltx_text ltx_font_bold">Chinese-LLaMA-13B<math id="S5.T9.4.2.2.1.1.m1.1" class="ltx_Math" alttext="{\dagger}" display="inline"><semantics id="S5.T9.4.2.2.1.1.m1.1a"><mo id="S5.T9.4.2.2.1.1.m1.1.1" xref="S5.T9.4.2.2.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T9.4.2.2.1.1.m1.1b"><ci id="S5.T9.4.2.2.1.1.m1.1.1.cmml" xref="S5.T9.4.2.2.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T9.4.2.2.1.1.m1.1c">{\dagger}</annotation></semantics></math></span></td>
<td id="S5.T9.4.2.2.2" class="ltx_td ltx_align_center">5-shot</td>
<td id="S5.T9.4.2.2.3" class="ltx_td ltx_align_center"><span id="S5.T9.4.2.2.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.4.2.2.4" class="ltx_td ltx_align_center">33.7</td>
<td id="S5.T9.4.2.2.5" class="ltx_td ltx_align_center">28.1</td>
<td id="S5.T9.4.2.2.6" class="ltx_td ltx_align_center">31.9</td>
<td id="S5.T9.4.2.2.7" class="ltx_td ltx_align_center">38.6</td>
<td id="S5.T9.4.2.2.8" class="ltx_td ltx_align_center">33.5</td>
<td id="S5.T9.4.2.2.9" class="ltx_td ltx_align_center">32.8</td>
</tr>
<tr id="S5.T9.4.2.16" class="ltx_tr">
<td id="S5.T9.4.2.16.1" class="ltx_td ltx_align_left">Chinese-LLaMA-13B</td>
<td id="S5.T9.4.2.16.2" class="ltx_td ltx_align_center">5-shot</td>
<td id="S5.T9.4.2.16.3" class="ltx_td ltx_align_center"><span id="S5.T9.4.2.16.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.4.2.16.4" class="ltx_td ltx_align_center">33.3</td>
<td id="S5.T9.4.2.16.5" class="ltx_td ltx_align_center">27.3</td>
<td id="S5.T9.4.2.16.6" class="ltx_td ltx_align_center">31.6</td>
<td id="S5.T9.4.2.16.7" class="ltx_td ltx_align_center">37.2</td>
<td id="S5.T9.4.2.16.8" class="ltx_td ltx_align_center">33.6</td>
<td id="S5.T9.4.2.16.9" class="ltx_td ltx_align_center">32.8</td>
</tr>
<tr id="S5.T9.4.2.17" class="ltx_tr">
<td id="S5.T9.4.2.17.1" class="ltx_td ltx_align_left">MOSS (16B)</td>
<td id="S5.T9.4.2.17.2" class="ltx_td ltx_align_center">0-shot</td>
<td id="S5.T9.4.2.17.3" class="ltx_td ltx_align_center"><span id="S5.T9.4.2.17.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.4.2.17.4" class="ltx_td ltx_align_center">33.1</td>
<td id="S5.T9.4.2.17.5" class="ltx_td ltx_align_center">28.4</td>
<td id="S5.T9.4.2.17.6" class="ltx_td ltx_align_center">31.6</td>
<td id="S5.T9.4.2.17.7" class="ltx_td ltx_align_center">37.0</td>
<td id="S5.T9.4.2.17.8" class="ltx_td ltx_align_center">33.4</td>
<td id="S5.T9.4.2.17.9" class="ltx_td ltx_align_center">32.1</td>
</tr>
<tr id="S5.T9.4.2.18" class="ltx_tr">
<td id="S5.T9.4.2.18.1" class="ltx_td ltx_align_left ltx_border_bb">Chinese-Alpaca-13B</td>
<td id="S5.T9.4.2.18.2" class="ltx_td ltx_align_center ltx_border_bb">0-shot</td>
<td id="S5.T9.4.2.18.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T9.4.2.18.3.1" class="ltx_text" style="color:#0000FF;">✓</span></td>
<td id="S5.T9.4.2.18.4" class="ltx_td ltx_align_center ltx_border_bb">30.9</td>
<td id="S5.T9.4.2.18.5" class="ltx_td ltx_align_center ltx_border_bb">24.4</td>
<td id="S5.T9.4.2.18.6" class="ltx_td ltx_align_center ltx_border_bb">27.4</td>
<td id="S5.T9.4.2.18.7" class="ltx_td ltx_align_center ltx_border_bb">39.2</td>
<td id="S5.T9.4.2.18.8" class="ltx_td ltx_align_center ltx_border_bb">32.5</td>
<td id="S5.T9.4.2.18.9" class="ltx_td ltx_align_center ltx_border_bb">28.0</td>
</tr>
</tbody></table>
</figure>
<div id="S5.SS4.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS4.p2.1">당연히 비오픈 소스 LLM은 오픈 소스 LLM보다 성능이 훨씬 우수합니다. 우리 모델의 경우 중국-Alpaca-33B와 중국-Alpaca-Plus-13B 모두 이 리더보드에서 오픈 소스 LLM 간에 경쟁 성능을 발휘하여 Bloomz-mt-176B <cite class="ltx_cite ltx_citemacro_citep">(Scao et al., <a class="ltx_ref" href="#bib.bib19" title="">2022</a>)</cite>와 GLM-130B <cite class="ltx_cite ltx_citemacro_citep">(Zeng et al., <a class="ltx_ref" href="#bib.bib29" title="">2023</a>)</cite>에 중간 정도의 차이만 보이는 것을 볼 수 있는데, 이는 후자의 모델이 몇 배의 크기를 가지며 우리보다 훨씬 더 많은 데이터로 학습되었기 때문이다.</p>
</div>
<div id="S5.SS4.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.SS4.p3.1">또 다른 측면에서, Chinese-Alpaca-13B 및 Chinese-LLaMA-13B는 이전에 C-Eval에 의해 평가되었다. 또한 자체 구현으로 예측 파일을 리더보드에 수동으로 제출했습니다. 결과는 두 모델 모두 C-Eval에 의해 평가된 모델, 특히 Alpaca-13B 모델에 대해 상당한 개선을 보여 +5.8 평균 점수(30.9에서 36.7)를 산출했다. 또한 Alpaca-13B는 LLaMA-13B에 비해 이점을 보여주며, 이는 이전 연구 결과에 따른 것이다. 이러한 관찰은 적절한 디코딩 전략과 신속한 템플릿을 채택하는 것이 개별 LLM, 특히 명령 후속 모델의 경우 더 나은 성능을 달성하는 데 중요할 수 있음을 나타낸다.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Effect of Different Quantization Methods</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.p1.1">개인 컴퓨터, 특히 CPU에 대규모 언어 모델을 배치하는 것은 엄청난 계산 요구 사항으로 인해 역사적으로 어려웠다. 그러나 <span class="ltx_text ltx_font_typewriter" id="S6.p1.1.1">llama.cpp</span> <cite class="ltx_cite ltx_citemacro_citep">(Gerganov, <a class="ltx_ref" href="#bib.bib7" title="">2023</a>)</cite>와 같은 많은 커뮤니티 노력의 도움으로 사용자는 LLM을 효율적으로 양자화할 수 있어 메모리 사용량과 계산량을 크게 줄일 수 있어 개인 컴퓨터에 LLM을 쉽게 배포할 수 있다. 이는 또한 모델과의 더 빠른 상호 작용을 가능하게 하고 로컬 데이터 처리를 용이하게 한다. LLM을 정량화하고 개인용 컴퓨터에 배포하면 몇 가지 이점이 있습니다. 첫째, 민감한 정보가 외부 서버로 전송되지 않고 로컬 환경 내에 남아 있도록 함으로써 사용자가 데이터 프라이버시를 보호하는 데 도움이 된다. 둘째, 제한된 계산 자원을 가진 사용자가 LLMs에 더 쉽게 접근할 수 있도록 함으로써 LLMs에 대한 접근을 민주화한다. 마지막으로 지역 LLM 배포를 활용하는 새로운 응용 프로그램 개발 및 연구 방향을 촉진한다. 전반적으로, <span class="ltx_text ltx_font_typewriter" id="S6.p1.1.2">llama.cpp</span> (또는 이와 유사한)을 사용하여 개인 컴퓨터에 LLM을 배포하는 기능은 다양한 도메인에서 LLM의 보다 다기능적이고 프라이버시를 의식하는 활용을 위한 길을 열어준다.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p class="ltx_p" id="S6.p2.1">이 절에서는 서로 다른 양자화 방법의 효과를 조사한다. <span class="ltx_text ltx_font_typewriter" id="S6.p2.1.1">llama.cpp</span>을 사용하여 Alpaca-Plus-7B, Alpaca-Plus-13B 및 Alpaca-33B를 양자화하고 한자 말뭉치에 대한 복잡도를 계산합니다. 이러한 모델을 원래 FP16과 비교하기 위해 2비트, 3비트, 4비트, 5비트, 6비트 및 8비트 형태로 양자화한다. <span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>Specifically, we use q2_K, q3_K, q4_0, q5_0, q6_K, and q8_0 quantization option for each quantized model.</span></span></span> 결과를 그림 <a class="ltx_ref" href="#S6.F3" title="Figure 3 ‣ 6 Effect of Different Quantization Methods ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">3</span></a>에 나타내었다.</p>
</div>
<figure id="S6.F3" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2304.08177/assets/x2.png" id="S6.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="232" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 3:</span> <span class="ltx_text ltx_font_bold" id="S6.F3.2.1">Perplexities for different quantization methods. </span> 33B 모델은 다른 모델보다 적은 데이터에 대해 훈련됨에 따라 더 높은 PPL을 갖는다.</figcaption>
</figure>
<div id="S6.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.p3.1">양자화 레벨은 메모리 사용 및 추론 속도에 엄격하게 구속되므로, 적절한 양자화 레벨을 선택할 때 트레이드오프가 이루어져야 한다. 우리가 볼 수 있듯이, 8비트 양자화 방법은 원래의 FP16 모델에 비해 거의 동일하거나 심지어 더 낮은 복잡도를 가지며, 이는 FP16 모델의 절반 크기만으로 개인용 컴퓨터에 LLM을 배치하기에 좋은 선택임을 입증한다. 6비트 모델은 또한 8비트 모델에 필적하는 괜찮은 PPL을 달성하여 속도와 성능의 균형을 더 좋게 만든다. 보다 적극적인 양자화 레벨을 사용할 경우, 특히 3-비트 및 2-비트의 경우 성능이 급격히 감소한다(즉, 더 높은 PPL). 또한 더 큰 모델은 더 작은 모델보다 양자화 방법에 덜 민감하다는 것을 발견했다. 예를 들어, 33B 모델의 성능은 다른 모델보다 훨씬 더 온화하게 변한다. 플러스-7B와 플러스-13B 모델을 비교할 때도 유사한 결과가 관찰된다. 이는 2-비트 및 3-비트 양자화가 더 작은 모델에 대해서는 덜 효과적이지만, 상당한 성능 손실 없이 더 큰 모델을 배치하는 유망한 방법일 수 있음을 나타낼 수 있다. 이는 사용자가 제한된 컴퓨팅 리소스만 가지고 있고 여전히 대규모 언어 모델을 시도하고 싶을 때 매우 유용하다. 이것은 또한 양자화된 트레이닝 방법이 특히 트레이닝 자원이 제한된 언어 모델들을 트레이닝하기 위한 메인스트림 접근법이 될 수 있다는 것을 암시할 수 있다.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.p1.1">본 기술 보고서에서는 LLaMA 모형에 대한 중국인의 이해와 발전 역량을 제고하기 위한 접근 방법을 제시하였다. 원래의 LLaMA의 중국어 어휘의 한계를 인식하고 20K의 중국어 토큰을 추가로 통합하여 확장하여 중국어에 대한 인코딩 효율을 크게 높였다. 중국 LLaMA를 기반으로 명령 데이터로 감독 미세 조정을 사용하여 중국 알파카 모델이 향상된 명령 후속 기능을 나타낸다.</p>
</div>
<div id="S7.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.p2.1">모델을 효과적으로 평가하기 위해 10개의 고유한 작업 유형에 걸쳐 200개의 샘플에 주석을 달았고 평가를 위해 GPT-4를 활용했다. 우리의 실험은 제안된 모델이 중국 이해 및 생성 작업에서 원래의 LLaMA를 상당히 능가한다는 것을 보여주었다. 또한 C-Eval 데이터 세트에서 모델을 테스트했습니다. 그 결과 제안된 모델은 몇 배 더 큰 크기를 가진 모델에 비해 상당한 개선을 달성하고 경쟁 성능을 보일 수 있음을 보여준다.</p>
</div>
<div id="S7.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.p3.1">앞으로는 인간 피드백에서 강화 학습(RLHF) 또는 AI 지시 피드백에서 강화 학습(RLAIF)을 탐색하여 모델의 출력을 인간의 선호도와 더 정렬할 계획이다. 또한, GPTQ <cite class="ltx_cite ltx_citemacro_citep">(Frantar et al., <a class="ltx_ref" href="#bib.bib6" title="">2022</a>)</cite>와 같은 보다 진보되고 효과적인 양자화 방법을 채택하고자 한다. 또한 대규모 언어 모델의 보다 효율적이고 효과적인 사전 훈련 및 미세 조정을 위해 LoRA에 대한 대체 방법을 조사하여 궁극적으로 중국 NLP 커뮤니티 내에서 다양한 작업에 걸쳐 성능과 적용 가능성을 향상시키는 것을 목표로 한다.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Limitations</h2>

<div id="Sx1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="Sx1.p1.1">이 프로젝트는 LLaMA 및 알파카 모델의 중국 이해 및 생성 능력을 성공적으로 향상시켰지만 몇 가지 한계를 인정해야 한다.</p>
<ul id="Sx1.I1" class="ltx_itemize">
<li id="Sx1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i1.p1.1">유해하고 예측할 수 없는 콘텐츠: 우리의 모델이 비윤리적 쿼리를 거부할 수 있지만, 이러한 모델은 여전히 인간의 선호도 및 값과 유해하거나 잘못된 정렬을 생성할 수 있다. 이 문제는 학습 데이터의 편향이나 특정 컨텍스트에서 적절한 출력을 식별할 수 없는 모델의 무능성에서 발생할 수 있다.</p>
</div>
</li>
<li id="Sx1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i2.p1.1">불충분한 트레이닝: 컴퓨팅 파워 및 데이터 가용성의 제약들로 인해, 모델들의 트레이닝은 최적의 성능을 위해 충분하지 않을 수 있다. 그 결과 모델들에 대한 중국어 이해 능력에서 여전히 개선의 여지가 있다.</p>
</div>
</li>
<li id="Sx1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i3.p1.1">강인성 부족: 모델은 일부 상황에서 취성을 나타내어 적대적 입력 또는 희귀 언어 현상에 직면할 때 일관되지 않거나 무의미한 출력을 생성할 수 있다.</p>
</div>
</li>
<li id="Sx1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.I1.i4.p1.1">종합평가: 큰 언어 모델을 평가하는 것은 현 시대의 중요한 주제이다. LLM에 대한 많은 평가 벤치마크를 보았지만 LLM에 대한 포괄성과 적절성은 잘 연구되고 조사되어야 한다. 보다 다양하고 포괄적인 LLM 평가 데이터 세트 및 벤치마크는 LLM 연구의 미래를 형성하는 데 큰 긍정적인 영향을 미칠 것이다.</p>
</div>
</li>
<li id="Sx1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx1.I1.i5.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="Sx1.I1.i5.p1.1">확장성 및 효율성: LoRA 및 양자화를 적용하여 모델을 보다 광범위한 커뮤니티에 더 쉽게 액세스할 수 있도록 했지만, 원래 LLaMA와 결합할 때 모델의 큰 크기와 복잡성은 특히 제한된 계산 리소스를 가진 사용자의 배치에 어려움을 초래할 수 있다. 이 문제는 다양한 응용 프로그램에서 모델의 접근성과 광범위한 채택을 방해할 수 있다.</p>
</div>
</li>
</ul>
</div>
<div id="Sx1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="Sx1.p2.1">향후 작업은 이러한 한계를 해결하여 모델의 기능을 더욱 향상시켜 중국 NLP 커뮤니티의 광범위한 응용 프로그램에 더 강력하고 접근 가능하며 효과적이어야 한다.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="Sx2.p1.1">원안은 문법 수정 및 명확성 개선을 위해 OpenAI GPT-4에 의해 연마되었다. 오픈 소스 프로젝트에 기여해 주신 커뮤니티 구성원들께 감사드립니다.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Shijin Wang, and Guoping Hu.

</span>
<span class="ltx_bibblock">Revisiting pre-trained models for Chinese natural language
processing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing: Findings</em>, pp.&nbsp; 657–668, Online, November
2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.findings-emnlp.58" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.findings-emnlp.58</a>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, and Ziqing Yang.

</span>
<span class="ltx_bibblock">Pre-training with whole word masking for chinese bert.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">IEEE/ACM Transactions on Audio, Speech, and Language
Processing</em>, 29:3504–3514, 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/TASLP.2021.3124365</span>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yiming Cui, Wanxiang Che, Shijin Wang, and Ting Liu.

</span>
<span class="ltx_bibblock">Lert: A linguistically-motivated pre-trained language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.05344</em>, 2022.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Qlora: Efficient finetuning of quantized llms.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.14314</em>, 2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">BERT: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pp.&nbsp; 4171–4186,
Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N19-1423" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N19-1423</a>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Frantar et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh.

</span>
<span class="ltx_bibblock">GPTQ: Accurate post-training compression for generative pretrained
transformers.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.17323</em>, 2022.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gerganov (2023)</span>
<span class="ltx_bibblock">
Georgi Gerganov.

</span>
<span class="ltx_bibblock">llama.cpp.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/ggerganov/llama.cpp" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/ggerganov/llama.cpp</a>, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Edward&nbsp;J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi
Li, Shean Wang, Lu&nbsp;Wang, and Weizhu Chen.

</span>
<span class="ltx_bibblock">LoRA: Low-Rank Adaptation of Large Language Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, art. arXiv:2106.09685, June 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2106.09685</span>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su,
Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu, Maosong Sun, and
Junxian He.

</span>
<span class="ltx_bibblock">C-eval: A multi-level multi-discipline chinese evaluation suite for
foundation models.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.08322</em>, 2023.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Köpf et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris
Anagnostidis, Zhi-Rui Tam, Keith Stevens, Abdullah Barhoum,
Nguyen&nbsp;Minh Duc, Oliver Stanley, Richárd Nagyfi, Shahul ES,
Sameer Suri, David Glushkov, Arnav Dantuluri, Andrew Maguire,
Christoph Schuhmann, Huu Nguyen, and Alexander Mattick.

</span>
<span class="ltx_bibblock">OpenAssistant Conversations – Democratizing Large Language Model
Alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, art. arXiv:2304.07327, April 2023.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2304.07327</span>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kudo &amp; Richardson (2018)</span>
<span class="ltx_bibblock">
Taku Kudo and John Richardson.

</span>
<span class="ltx_bibblock">SentencePiece: A simple and language independent subword
tokenizer and detokenizer for neural text processing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing: System Demonstrations</em>, pp.&nbsp; 66–71, Brussels,
Belgium, November 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D18-2012</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/D18-2012" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/D18-2012</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lai et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy.

</span>
<span class="ltx_bibblock">RACE: Large-scale ReAding comprehension dataset from
examinations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 Conference on Empirical Methods in
Natural Language Processing</em>, pp.&nbsp; 785–794, Copenhagen, Denmark, September
2017. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D17-1082</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/D17-1082" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/D17-1082</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov &amp; Hutter (2019)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=Bkg6RiCqY7" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=Bkg6RiCqY7</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2022)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Introducing chatgpt.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openai.com/blog/chatgpt" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openai.com/blog/chatgpt</a>, 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">GPT-4 Technical Report.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, art. arXiv:2303.08774, March 2023.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2303.08774</span>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeff Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll&nbsp;L. Wainwright,
Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex
Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller,
Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan
Leike, and Ryan Lowe.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human
feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, art. arXiv:2203.02155, March 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2203.02155</span>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2018)</span>
<span class="ltx_bibblock">
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Improving language understanding by generative pre-training.

</span>
<span class="ltx_bibblock">2018.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rasley et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He.

</span>
<span class="ltx_bibblock">Deepspeed: System optimizations enable training deep learning models
with over 100 billion parameters.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 26th ACM SIGKDD International Conference
on Knowledge Discovery &amp; Data Mining</em>, pp.&nbsp; 3505–3506, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scao et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Teven&nbsp;Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić,
Daniel Hesslow, Roman Castagné, Alexandra&nbsp;Sasha Luccioni, François
Yvon, Matthias Gallé, et&nbsp;al.

</span>
<span class="ltx_bibblock">Bloom: A 176b-parameter open-access multilingual language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2211.05100</em>, 2022.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer (2020)</span>
<span class="ltx_bibblock">
Noam Shazeer.

</span>
<span class="ltx_bibblock">Glu variants improve transformer, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Jianlin Su, Yu&nbsp;Lu, Shengfeng Pan, Bo&nbsp;Wen, and Yunfeng Liu.

</span>
<span class="ltx_bibblock">Roformer: Enhanced transformer with rotary position embedding, 2021.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
Guestrin, Percy Liang, and Tatsunori&nbsp;B. Hashimoto.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tatsu-lab/stanford_alpaca</a>,
2023a.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
Guestrin, Percy Liang, and Tatsunori&nbsp;B. Hashimoto.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/tatsu-lab/stanford_alpaca" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/tatsu-lab/stanford_alpaca</a>,
2023b.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet,
Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman
Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand
Joulin, Edouard Grave, and Guillaume Lample.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.13971</em>, 2023.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan&nbsp;N Gomez, Ł&nbsp;ukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In I.&nbsp;Guyon, U.&nbsp;Von Luxburg, S.&nbsp;Bengio, H.&nbsp;Wallach, R.&nbsp;Fergus,
S.&nbsp;Vishwanathan, and R.&nbsp;Garnett (eds.), <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information
Processing Systems</em>, volume&nbsp;30. Curran Associates, Inc., 2017.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah&nbsp;A.
Smith, Daniel Khashabi, and Hannaneh Hajishirzi.

</span>
<span class="ltx_bibblock">Self-Instruct: Aligning Language Model with Self Generated
Instructions.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, art. arXiv:2212.10560, December 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.48550/arXiv.2212.10560</span>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu (2019)</span>
<span class="ltx_bibblock">
Bright Xu.

</span>
<span class="ltx_bibblock">Nlp chinese corpus: Large scale chinese corpus for nlp, September
2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.5281/zenodo.3402023" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.5281/zenodo.3402023</a>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Ziqing Yang, Zihang Xu, Yiming Cui, Baoxin Wang, Min Lin, Dayong Wu, and
Zhigang Chen.

</span>
<span class="ltx_bibblock">CINO: A Chinese minority pre-trained language model.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 29th International Conference on
Computational Linguistics</em>, pp.&nbsp; 3937–3949, Gyeongju, Republic of Korea,
October 2022. International Committee on Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/2022.coling-1.346" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2022.coling-1.346</a>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi
Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng&nbsp;Lam Tam, Zixuan Ma, Yufei Xue,
Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong, and Jie
Tang.

</span>
<span class="ltx_bibblock">GLM-130b: An open bilingual pre-trained model.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">The Eleventh International Conference on Learning
Representations</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=-Aw0rrrPUF" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=-Aw0rrrPUF</a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang &amp; Sennrich (2019)</span>
<span class="ltx_bibblock">
Biao Zhang and Rico Sennrich.

</span>
<span class="ltx_bibblock">Root Mean Square Layer Normalization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 32</em>,
Vancouver, Canada, 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/references/pdf?id=S1qBAf6rr" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/references/pdf?id=S1qBAf6rr</a>.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2304.08176" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2304.08177" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2304.08177">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2304.08177" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2304.08178" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 14:26:10 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>