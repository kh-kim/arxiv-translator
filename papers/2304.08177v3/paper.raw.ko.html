<html lang="en" data-theme="light"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca</title>
<!--Generated on Fri Feb 23 02:24:22 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/addons.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="https://arxiv.org/html/2304.08177v3/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2304.08177v3">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <span class="color-scheme-icon" aria-label="Light mode"></span>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="#myForm" onclick="event.preventDefault(); var modal = document.getElementById('myForm'); modal.style.display = 'block'; bugReportState.setInitiateWay('Header');">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2304.08177v3">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2304.08177v3" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
          <span class="color-scheme-icon"></span>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC mobile collapse" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S1" title="1 Introduction ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S2" title="2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Chinese LLaMA and Chinese Alpaca</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S2.SS1" title="2.1 Background ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Background</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S2.SS2" title="2.2 Chinese Vocabulary Extension ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Chinese Vocabulary Extension</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S2.SS3" title="2.3 Parameter Efficient Fine-Tuning with LoRA ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Parameter Efficient Fine-Tuning with LoRA</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S2.SS4" title="2.4 Pre-Training Objective ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Pre-Training Objective</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S2.SS5" title="2.5 Supervised Fine-Tuning and Chinese Alpaca ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.5 </span>Supervised Fine-Tuning and Chinese Alpaca</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S3" title="3 Experimental Setups ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Experimental Setups</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S3.SS1" title="3.1 Experimental Setups for Pre-training ‣ 3 Experimental Setups ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Experimental Setups for Pre-training</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S3.SS2" title="3.2 Experimental Setups for Instruction Fine-tuning ‣ 3 Experimental Setups ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Experimental Setups for Instruction Fine-tuning</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S4" title="4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results on Instruction-Following Tasks</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S4.SS1" title="4.1 Task Design and Evaluation Method ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Task Design and Evaluation Method</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S4.SS2" title="4.2 Experimental Setups for Decoding ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Experimental Setups for Decoding</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S4.SS3" title="4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S4.SS3.SSS1" title="4.3.1 Multi-turn Dialogue ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.1 </span>Multi-turn Dialogue</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S4.SS3.SSS2" title="4.3.2 Text Generation ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.2 </span>Text Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S4.SS3.SSS3" title="4.3.3 Numerical Calculation and Reasoning ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.3 </span>Numerical Calculation and Reasoning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S4.SS3.SSS4" title="4.3.4 Coding ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.4 </span>Coding</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S4.SS3.SSS5" title="4.3.5 Ethics ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.5 </span>Ethics</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S5" title="5 Results on Natural Language Understanding Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results on Natural Language Understanding Tasks</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S5.SS1" title="5.1 Task Description ‣ 5 Results on Natural Language Understanding Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Task Description</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S5.SS2" title="5.2 Decoding Strategy ‣ 5 Results on Natural Language Understanding Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Decoding Strategy</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S5.SS3" title="5.3 Comparisons to Original LLaMA ‣ 5 Results on Natural Language Understanding Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Comparisons to Original LLaMA</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S5.SS3.SSS0.Px1" title="Chinese LLaMA improves original LLaMA. ‣ 5.3 Comparisons to Original LLaMA ‣ 5 Results on Natural Language Understanding Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title">Chinese LLaMA improves original LLaMA.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S5.SS3.SSS0.Px2" title="Alpaca models show significant improvements over LLaMA. ‣ 5.3 Comparisons to Original LLaMA ‣ 5 Results on Natural Language Understanding Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title">Alpaca models show significant improvements over LLaMA.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S5.SS3.SSS0.Px3" title="LLaMA generally yields better performance in a few-shot setting, while Alpaca prefers zero-shot. ‣ 5.3 Comparisons to Original LLaMA ‣ 5 Results on Natural Language Understanding Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title">LLaMA generally yields better performance in a few-shot setting, while Alpaca prefers zero-shot.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S5.SS4" title="5.4 Comparisons to Other Models ‣ 5 Results on Natural Language Understanding Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Comparisons to Other Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S6" title="6 Effect of Different Quantization Methods ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Effect of Different Quantization Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S7" title="7 Conclusion ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#A1" title="Appendix A Appendix ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Appendix</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#A1.SS1" title="A.1 C-Eval ‣ Appendix A Appendix ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>C-Eval</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#A1.SS2" title="A.2 CMMLU ‣ Appendix A Appendix ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>CMMLU</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#A1.SS3" title="A.3 LongBench ‣ Appendix A Appendix ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>LongBench</span></a></li>
</ol>
</li>
</ol></nav>

<div class="ltx_page_content"><div class="section" id="target-section"><div id="license-tr">License: arXiv.org perpetual non-exclusive license</div><div id="watermark-tr">arXiv:2304.08177v3 [cs.CL] 23 Feb 2024</div></div>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yiming Cui 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">ymcui@ieee.org</span> &amp;Ziqing Yang<span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id2.2.id2">ziqingyang@gmail.com</span> &amp;Xin Yao 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id3.3.id3">yaoxin94@foxmail.com</span>
</span><span class="ltx_author_notes">Equal contributions.</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id4.id1">ChatGPT 및 GPT-4와 같은 대규모 언어 모델(LLM)은 자연어 처리 연구를 극적으로 변형시켰고 인공지능(AGI)을 향한 유망한 진보를 보여주었다. 그럼에도 불구하고 LLM 교육 및 배치와 관련된 높은 비용은 투명하고 접근 가능한 학술 연구에 상당한 장애물을 제시한다. LLaMA와 같은 여러 대형 언어 모델이 커뮤니티에 의해 공개되었지만, 이들은 주로 영어 코퍼라에 중점을 두어 다른 언어에 대한 유용성을 제한한다. 본 논문에서는 중국어 텍스트를 이해하고 생성할 수 있는 능력과 명령어를 따를 수 있는 능력을 갖춘 LLaMA를 증강하는 방법을 제안한다. 이를 위해 LLaMA의 기존 어휘를 추가로 2만 개의 중국어 토큰으로 확장하여 중국어에 대한 인코딩 효율성과 의미적 이해를 높인다. 또한 중국어 데이터를 사용한 2차 사전 훈련을 통합하고 중국어 명령어 데이터 세트로 모델을 미세 조정함으로써 모델의 명령어 이해 및 실행 능력을 크게 향상시킨다. 우리의 실험 결과는 새로 제안된 모델이 원래 LLaMA의 중국어 콘텐츠 이해 및 생성 능력을 현저하게 향상시킨다는 것을 나타낸다. 또한, C-Eval 데이터 세트에 대한 결과는 우리 모델의 몇 배 크기를 가진 모델 간의 경쟁 성능을 산출한다. 우리는 미리 훈련된 모델, 훈련 스크립트 및 기타 리소스를 깃허브를 통해 사용할 수 있도록 하여 커뮤니티를 위한 개방형 연구를 촉진했다. <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Chinese LLaMA series: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ymcui/Chinese-LLaMA-Alpaca" title="">https://github.com/ymcui/Chinese-LLaMA-Alpaca</a></span></span></span><span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Chinese Llama-2 series: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ymcui/Chinese-LLaMA-Alpaca-2" title="">https://github.com/ymcui/Chinese-LLaMA-Alpaca-2</a></span></span></span></p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">자연어 처리(Natural Language Processing, NLP) 분야는 대규모 언어 모델(Large Language Models, LLM)의 등장으로 실질적인 패러다임의 변화를 목격하고 있다. 상당한 크기와 포괄적인 훈련 데이터로 구별되는 이러한 모델은 인간과 같은 텍스트를 이해하고 생성하는 데 탁월한 능력을 보여주었다. 텍스트 이해 전용 사전 훈련 언어 모델인 BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib7" title="">2019</a>)</cite>와 달리 GPT 시리즈 <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib21" title="">2018</a>)</cite>는 텍스트 생성을 강조하여 해당 대응물에 비해 창의성에 더 적합한 플랫폼으로 포지셔닝한다. 특히, GPT 계열의 최신 구성체, 즉 ChatGPT 및 GPT-4는 빠르게 진화하는 이 분야에서 선도적인 예로 자리매김하면서 상당한 관심을 받았다.</p>
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">ChatGPT <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib17" title="">2022</a>)</cite>, InstructGPT <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib19" title="">2022</a>)</cite>,는 상황 인지, 인간 유사 상호작용을 수행할 수 있는 고급 대화형 AI 모델 역할을 한다. 그 성공은 GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib18" title="">2023</a>)</cite>, 보다 정교한 LLM을 개발하는 단계를 설정했으며, 특히 멀티모달 및 추론 능력에서 자연어 이해, 생성 및 다양한 NLP 작업에서 훨씬 더 큰 잠재력을 보여준다. 이러한 모델은 새로운 연구 방향과 응용을 촉진하여 인공지능(AGI)의 잠재력을 탐구하는 데 관심을 강화했다. 여러 벤치마크에서 인상적인 성능을 보여주면서 적은 샷 학습과 새로운 작업에 대한 적응 능력을 보여 NLP 연구의 확장을 크게 견인했다. 결과적으로, 그들은 연구자와 업계 전문가 모두에게 감성 분석, 기계 번역, 질의 응답 시스템 등을 포함한 광범위한 응용 분야에서 잠재력을 더욱 활용할 수 있도록 영감을 주었습니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">그러나 LLM만큼 영향력 있는 구현은 투명하고 열린 연구를 방해하는 내재적 한계를 가지고 있다. 주요 관심사는 모델에 대한 접근을 제한하여 성공을 기반으로 하는 광범위한 연구 커뮤니티의 능력을 억제하는 독점적 특성이다. 또한 이러한 모델을 훈련하고 배포하는 데 필요한 방대한 계산 리소스는 제한된 리소스를 가진 연구자에게 어려움을 제공하여 접근성 문제를 더욱 복잡하게 만든다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">이러한 한계를 해결하기 위해 NLP 연구 커뮤니티는 더 큰 투명성과 협력을 촉진하기 위해 오픈 소스 대안에 끌렸다. LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib28" title="">2023</a>)</cite>, Llama-2 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib29" title="">2023</a>)</cite>, Alpaca <cite class="ltx_cite ltx_citemacro_citep">(Taori et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib26" title="">2023a</a>)</cite>는 이러한 이니셔티브의 주목할 만한 예로 작용한다. 이러한 오픈 소스 LLM은 학술 연구를 촉진하고 NLP 분야 내에서 진전을 가속화하기 위한 것이다. 이러한 모델을 오픈 소싱하는 목적은 모델 개발, 미세 조정 및 평가의 추가 발전에 도움이 되는 환경을 조성하여 궁극적으로 다양한 용도에 적용할 수 있는 강력하고 능력 있는 LLM을 만드는 것이다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">LLaMA와 Alpaca가 NLP에서 상당한 진전을 이루었음에도 불구하고 중국어 작업에 대한 모국어 지원과 관련하여 고유한 한계를 나타낸다. 그들의 어휘는 수백 개의 중국어 토큰만을 포함하고 있어 중국어 텍스트의 인코딩과 디코딩의 효율성을 상당히 저해하고 있다. 본 기술 보고서에서는 중국어 BERT 시리즈 <cite class="ltx_cite ltx_citemacro_citep">(Cui et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib4" title="">2021</a>)</cite>와 중국 소수자 중심의 다국어 사전 학습 모델 <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib33" title="">2022</a>)</cite>를 기반으로 중국어 콘텐츠를 이해하고 생성하는 기능이 강화된 중국어 LLaMA 및 Alpaca 모델 개발을 제안한다. 우리는 원래 LLaMA의 어휘를 추가로 2만 개의 중국어 토큰으로 확장하여 중국어 텍스트의 처리 및 생성 능력을 크게 향상시킵니다. 이러한 모델의 효율적인 훈련 및 배포를 보장하기 위해 Low-Rank Adaptation (LoRA) 접근법 <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib10" title="">2021</a>)</cite>를 사용하여 과도한 계산 비용 없이 모델을 훈련하고 미세 조정할 수 있다. 우리는 LLaMA와 Alpaca의 중국어 이해와 생성 능력을 향상시키기 위한 예비 연구가 이러한 모델을 다른 언어에 적용하는 것을 목표로 하는 연구자들의 토대가 될 것으로 기대한다. 본 논문에서는 다양한 언어에서 LLaMA와 Alpaca 모델의 어휘 확장과 성능 향상을 위해 사용될 수 있는 통찰력과 방법론을 제시한다. 제안된 모델의 개요는 그림 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">1</span></a>에 나와 있다.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="490" id="S1.F1.g1" src="https://arxiv.org/html/2304.08177v3/x1.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span> <span class="ltx_text ltx_font_bold" id="S1.F1.2.1">Overview of the proposed Chinese LLaMA and Chinese Alpaca models (based on Meta’s LLaMA and Llama-2).</span> Chinese LLaMA series are foundation models, and Chinese Alpaca series are chat or instruction-following models. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">요약하면, 본 기술보고서의 기여는 다음과 같다:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">우리는 2만 개의 중국어 토큰으로 원래 LLaMA의 어휘를 확장하여 중국어의 인코딩과 디코딩 효율을 높이고 LLaMA의 중국어 이해 능력을 향상시킨다.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">우리는 중국 LLaMA 및 Alpaca 모델의 효율적인 훈련 및 배치를 용이하게 하기 위해 LoRA(Low-Rank Adaptation) 접근법을 사용하여 연구자들이 과도한 계산 비용을 초래하지 않고 이러한 모델을 사용할 수 있도록 한다.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">본 논문에서 제안한 LLaMA와 Alpaca 모델들은 명령어 수행과 자연어 이해 과제에 대한 성능을 평가함으로써, 중국어 과제의 맥락에서 기존 모델들에 비해 상당한 개선점을 보여준다.</p>
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">우리는 연구의 자원과 결과를 공개적으로 이용 가능하게 하여 NLP 커뮤니티에서 추가 연구 및 협력을 촉진하고 LLaMA 및 알파카 모델을 다른 언어에 적응하도록 장려한다.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Chinese LLaMA and Chinese Alpaca</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Background</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">LLaMA <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib28" title="">2023</a>)</cite>는 트랜스포머 아키텍처 <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib30" title="">2017</a>)</cite>에 구축된 기초적인 디코더 전용 대형 언어 모델이다. GPT 시리즈 및 다른 변압기 기반 LLM과 유사하게 LLaMA는 임베딩 레이어, 다중 변압기 블록 및 언어 모델 헤드로 구성된다. LLaMA는 또한 프리-정규화 <cite class="ltx_cite ltx_citemacro_citep">(Zhang &amp; Sennrich, <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib35" title="">2019</a>)</cite>, SwiGLU 활성화 <cite class="ltx_cite ltx_citemacro_citep">(Shazeer, <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib24" title="">2020</a>)</cite>, 및 회전 임베딩 <cite class="ltx_cite ltx_citemacro_citep">(Su et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib25" title="">2021</a>)</cite>와 같이 서로 다른 모델에서 활용되는 개선 사항을 통합한다. LLaMA는 7B, 13B, 33B 및 65B의 4가지 다른 모델 크기로 제공됩니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">LLaMA는 크롤링된 웹 페이지, 책, 위키피디아 및 사전 인쇄 논문과 같은 공개적으로 이용 가능한 소스의 혼합을 사용하여 표준 언어 모델링 작업(섹션 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S2.SS4" title="2.4 Pre-Training Objective ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">2.4</span></a> 참조)으로 사전 훈련되었다. 실험 결과는 LLaMA가 더 작은 모델 크기이지만 GPT-3와 같은 다른 LLM에 비해 경쟁 성능을 제공한다는 것을 보여준다. 이러한 압축성과 효과는 연구자들의 상당한 관심을 받아 LLaMA 기반 모델의 광범위한 사용으로 이어졌다.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Chinese Vocabulary Extension</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">LLaMA의 트레이닝 세트는 대략 1.4T 토큰을 포괄하며, 라틴어 또는 Cyrillic 스크립트 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib28" title="">2023</a>)</cite>를 사용하는 다른 유럽 언어에서는 대다수가 영어로, 소분수를 포함한다. 따라서 LLaMA는 대부분 유럽 언어로 입증된 다국어 및 교차 언어 이해 능력을 가지고 있다. 흥미로운 사실은 우리의 이전 예비 연구는 LLaMA가 중국 텍스트를 생성하는 능력은 제한적이지만 기본적인 중국 이해 능력을 나타낸다는 것을 보여준다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">LLaMA에 중국어 이해와 생성 능력을 향상시키기 위해, 우리는 중국어 말뭉치로 LLaMA 모델을 계속 사전 훈련할 것을 제안한다. 그러나 중국 코퍼라와의 지속적인 사전 교육을 직접 적용하는 것은 여러 가지 어려움에 직면한다. 첫째, 원본 LLaMA 어휘는 1,000자 미만의 한자를 다루고 있어 일반적인 한자 텍스트를 인코딩하기에는 부족하다. LLaMA 토큰화기는 알려지지 않은 UTF-8 문자를 바이트로 토큰화함으로써 이 문제를 우회하지만, 이 전략은 각 한자가 3-4 바이트 토큰으로 분할되기 때문에 시퀀스 길이를 상당히 확장하고 중국 텍스트의 인코딩 및 디코딩 효율을 늦춘다. 둘째, 바이트 토큰은 한자를 나타내기 위해 독점적으로 설계되지 않는다. 바이트 토큰은 다른 언어의 UTF-8 토큰도 의미하기 때문에 바이트 토큰과 변환기 인코더가 한자의 의미 의미를 포착하는 표현을 효과적으로 학습하는 것이 어려워진다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">이러한 문제를 해결하고 인코딩 효율을 향상시키기 위해 추가 중국어 토큰으로 LLaMA 어휘를 확장하고 확장 어휘 <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib33" title="">2022</a>)</cite>에 대한 모델을 적용할 것을 제안한다. 확장 프로세스는 다음과 같이 진행된다:</p>
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1">토큰나이저의 중국어 텍스트에 대한 지원을 강화하기 위해, 우리는 처음에 문장피스 <cite class="ltx_cite ltx_citemacro_citep">(Kudo &amp; Richardson, <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib13" title="">2018</a>)</cite> on Chinese corpora<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>The training data is the same as the one for training basic version of our models.</span></span></span>의 어휘 크기가 20,000인 중국어 토큰나이저를 훈련시켰다.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1">우리는 이후 그들의 어휘의 결합을 취하여 중국식 토큰화기를 원래의 LLaMA 토큰화기로 병합한다. 결과적으로, 우리는 49,953의 어휘 크기를 가진 중국 LLaMA 토큰화기로 불리는 병합된 토큰화기를 얻는다.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.4">LLaMA 모델을 중국어 LLaMA 토큰라이저에 적용하기 위해 단어 임베딩 및 언어 모델 헤드를 모양 <math alttext="V\times H" class="ltx_Math" display="inline" id="S2.I1.i3.p1.1.m1.1"><semantics id="S2.I1.i3.p1.1.m1.1a"><mrow id="S2.I1.i3.p1.1.m1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.cmml"><mi id="S2.I1.i3.p1.1.m1.1.1.2" xref="S2.I1.i3.p1.1.m1.1.1.2.cmml">V</mi><mo id="S2.I1.i3.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.I1.i3.p1.1.m1.1.1.1.cmml">×</mo><mi id="S2.I1.i3.p1.1.m1.1.1.3" xref="S2.I1.i3.p1.1.m1.1.1.3.cmml">H</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.1.m1.1b"><apply id="S2.I1.i3.p1.1.m1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1"><times id="S2.I1.i3.p1.1.m1.1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1.1"></times><ci id="S2.I1.i3.p1.1.m1.1.1.2.cmml" xref="S2.I1.i3.p1.1.m1.1.1.2">𝑉</ci><ci id="S2.I1.i3.p1.1.m1.1.1.3.cmml" xref="S2.I1.i3.p1.1.m1.1.1.3">𝐻</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.1.m1.1c">V\times H</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i3.p1.1.m1.1d">italic_V × italic_H</annotation></semantics></math>에서 <math alttext="V^{\prime}\times H" class="ltx_Math" display="inline" id="S2.I1.i3.p1.2.m2.1"><semantics id="S2.I1.i3.p1.2.m2.1a"><mrow id="S2.I1.i3.p1.2.m2.1.1" xref="S2.I1.i3.p1.2.m2.1.1.cmml"><msup id="S2.I1.i3.p1.2.m2.1.1.2" xref="S2.I1.i3.p1.2.m2.1.1.2.cmml"><mi id="S2.I1.i3.p1.2.m2.1.1.2.2" xref="S2.I1.i3.p1.2.m2.1.1.2.2.cmml">V</mi><mo id="S2.I1.i3.p1.2.m2.1.1.2.3" xref="S2.I1.i3.p1.2.m2.1.1.2.3.cmml">′</mo></msup><mo id="S2.I1.i3.p1.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.I1.i3.p1.2.m2.1.1.1.cmml">×</mo><mi id="S2.I1.i3.p1.2.m2.1.1.3" xref="S2.I1.i3.p1.2.m2.1.1.3.cmml">H</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.2.m2.1b"><apply id="S2.I1.i3.p1.2.m2.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1"><times id="S2.I1.i3.p1.2.m2.1.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1.1"></times><apply id="S2.I1.i3.p1.2.m2.1.1.2.cmml" xref="S2.I1.i3.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.1.1.2.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1.2">superscript</csymbol><ci id="S2.I1.i3.p1.2.m2.1.1.2.2.cmml" xref="S2.I1.i3.p1.2.m2.1.1.2.2">𝑉</ci><ci id="S2.I1.i3.p1.2.m2.1.1.2.3.cmml" xref="S2.I1.i3.p1.2.m2.1.1.2.3">′</ci></apply><ci id="S2.I1.i3.p1.2.m2.1.1.3.cmml" xref="S2.I1.i3.p1.2.m2.1.1.3">𝐻</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.2.m2.1c">V^{\prime}\times H</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i3.p1.2.m2.1d">italic_V start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT × italic_H</annotation></semantics></math>로 크기를 조정하며, 여기서 <math alttext="V=32,000" class="ltx_Math" display="inline" id="S2.I1.i3.p1.3.m3.2"><semantics id="S2.I1.i3.p1.3.m3.2a"><mrow id="S2.I1.i3.p1.3.m3.2.3" xref="S2.I1.i3.p1.3.m3.2.3.cmml"><mi id="S2.I1.i3.p1.3.m3.2.3.2" xref="S2.I1.i3.p1.3.m3.2.3.2.cmml">V</mi><mo id="S2.I1.i3.p1.3.m3.2.3.1" xref="S2.I1.i3.p1.3.m3.2.3.1.cmml">=</mo><mrow id="S2.I1.i3.p1.3.m3.2.3.3.2" xref="S2.I1.i3.p1.3.m3.2.3.3.1.cmml"><mn id="S2.I1.i3.p1.3.m3.1.1" xref="S2.I1.i3.p1.3.m3.1.1.cmml">32</mn><mo id="S2.I1.i3.p1.3.m3.2.3.3.2.1" xref="S2.I1.i3.p1.3.m3.2.3.3.1.cmml">,</mo><mn id="S2.I1.i3.p1.3.m3.2.2" xref="S2.I1.i3.p1.3.m3.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.3.m3.2b"><apply id="S2.I1.i3.p1.3.m3.2.3.cmml" xref="S2.I1.i3.p1.3.m3.2.3"><eq id="S2.I1.i3.p1.3.m3.2.3.1.cmml" xref="S2.I1.i3.p1.3.m3.2.3.1"></eq><ci id="S2.I1.i3.p1.3.m3.2.3.2.cmml" xref="S2.I1.i3.p1.3.m3.2.3.2">𝑉</ci><list id="S2.I1.i3.p1.3.m3.2.3.3.1.cmml" xref="S2.I1.i3.p1.3.m3.2.3.3.2"><cn id="S2.I1.i3.p1.3.m3.1.1.cmml" type="integer" xref="S2.I1.i3.p1.3.m3.1.1">32</cn><cn id="S2.I1.i3.p1.3.m3.2.2.cmml" type="integer" xref="S2.I1.i3.p1.3.m3.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.3.m3.2c">V=32,000</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i3.p1.3.m3.2d">italic_V = 32 , 000</annotation></semantics></math>는 원래 어휘 크기를 나타내고, <math alttext="V^{\prime}=49,953" class="ltx_Math" display="inline" id="S2.I1.i3.p1.4.m4.2"><semantics id="S2.I1.i3.p1.4.m4.2a"><mrow id="S2.I1.i3.p1.4.m4.2.3" xref="S2.I1.i3.p1.4.m4.2.3.cmml"><msup id="S2.I1.i3.p1.4.m4.2.3.2" xref="S2.I1.i3.p1.4.m4.2.3.2.cmml"><mi id="S2.I1.i3.p1.4.m4.2.3.2.2" xref="S2.I1.i3.p1.4.m4.2.3.2.2.cmml">V</mi><mo id="S2.I1.i3.p1.4.m4.2.3.2.3" xref="S2.I1.i3.p1.4.m4.2.3.2.3.cmml">′</mo></msup><mo id="S2.I1.i3.p1.4.m4.2.3.1" xref="S2.I1.i3.p1.4.m4.2.3.1.cmml">=</mo><mrow id="S2.I1.i3.p1.4.m4.2.3.3.2" xref="S2.I1.i3.p1.4.m4.2.3.3.1.cmml"><mn id="S2.I1.i3.p1.4.m4.1.1" xref="S2.I1.i3.p1.4.m4.1.1.cmml">49</mn><mo id="S2.I1.i3.p1.4.m4.2.3.3.2.1" xref="S2.I1.i3.p1.4.m4.2.3.3.1.cmml">,</mo><mn id="S2.I1.i3.p1.4.m4.2.2" xref="S2.I1.i3.p1.4.m4.2.2.cmml">953</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.4.m4.2b"><apply id="S2.I1.i3.p1.4.m4.2.3.cmml" xref="S2.I1.i3.p1.4.m4.2.3"><eq id="S2.I1.i3.p1.4.m4.2.3.1.cmml" xref="S2.I1.i3.p1.4.m4.2.3.1"></eq><apply id="S2.I1.i3.p1.4.m4.2.3.2.cmml" xref="S2.I1.i3.p1.4.m4.2.3.2"><csymbol cd="ambiguous" id="S2.I1.i3.p1.4.m4.2.3.2.1.cmml" xref="S2.I1.i3.p1.4.m4.2.3.2">superscript</csymbol><ci id="S2.I1.i3.p1.4.m4.2.3.2.2.cmml" xref="S2.I1.i3.p1.4.m4.2.3.2.2">𝑉</ci><ci id="S2.I1.i3.p1.4.m4.2.3.2.3.cmml" xref="S2.I1.i3.p1.4.m4.2.3.2.3">′</ci></apply><list id="S2.I1.i3.p1.4.m4.2.3.3.1.cmml" xref="S2.I1.i3.p1.4.m4.2.3.3.2"><cn id="S2.I1.i3.p1.4.m4.1.1.cmml" type="integer" xref="S2.I1.i3.p1.4.m4.1.1">49</cn><cn id="S2.I1.i3.p1.4.m4.2.2.cmml" type="integer" xref="S2.I1.i3.p1.4.m4.2.2">953</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.4.m4.2c">V^{\prime}=49,953</annotation><annotation encoding="application/x-llamapun" id="S2.I1.i3.p1.4.m4.2d">italic_V start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = 49 , 953</annotation></semantics></math>는 중국어 LLaMA 토큰라이저의 새로운 어휘 크기를 나타낸다. 새로운 행들은 원래의 임베딩 행렬들의 끝에 추가되어, 원래의 어휘 내의 토큰들의 임베딩들이 영향을 받지 않은 채로 유지되는 것을 보장한다.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">예비 실험에 따르면 중국 LLaMA 토큰화기에서 생성된 토큰의 수는 원래 LLaMA 토큰화기에서 생성된 토큰의 약 절반이다. 표 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S2.T1" title="Table 1 ‣ 2.2 Chinese Vocabulary Extension ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">1</span></a>는 원래 LLaMA tokenizer와 중국 LLaMA tokenizer의 비교를 제공한다. 도시된 바와 같이, 중국 LLaMA 토큰화기는 원본에 비해 인코딩 길이를 상당히 감소시킨다. 고정 컨텍스트 길이로, 모델은 약 2배 많은 정보를 수용할 수 있고, 생성 속도는 원래의 LLaMA 토크나이저보다 2배 빠르다. 이것은 LLaMA 모델의 중국 이해와 생성 능력을 향상시키는 데 제안된 접근법의 효율성을 강조한다.</p>
</div>
<figure class="ltx_table" id="S2.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span> Tokenizer comparisons between original LLaMA and Chinese LLaMA.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S2.T1.1">
<tbody><tr class="ltx_tr" id="S2.T1.1.1">
<td class="ltx_td ltx_border_tt" id="S2.T1.1.1.1"></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S2.T1.1.1.2"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.2.1">Length</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S2.T1.1.1.3"><span class="ltx_text ltx_font_bold" id="S2.T1.1.1.3.1">Content</span></td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.1.2.1"><span class="ltx_text ltx_font_bold" id="S2.T1.1.2.1.1">Original Sentence</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.2.2">28</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.1.2.3">人工智能是计算机科学、心理学、哲学等学科融合的交叉学科。</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.1.3.1"><span class="ltx_text ltx_font_bold" id="S2.T1.1.3.1.1">Original Tokenizer</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S2.T1.1.3.2"><span class="ltx_text" id="S2.T1.1.3.2.1">35</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S2.T1.1.3.3">
<span class="ltx_text" id="S2.T1.1.3.3.1"></span><span class="ltx_text" id="S2.T1.1.3.3.2">
<span class="ltx_tabular ltx_align_top" id="S2.T1.1.3.3.2.1">
<span class="ltx_tr" id="S2.T1.1.3.3.2.1.1">
<span class="ltx_td ltx_align_left" id="S2.T1.1.3.3.2.1.1.1">‘_’, ‘人’, ‘工’, ‘智’, ‘能’, ‘是’, ‘计’, ‘算’, ‘机’, ‘科’, ‘学’, ‘、’, ‘心’,</span></span>
<span class="ltx_tr" id="S2.T1.1.3.3.2.1.2">
<span class="ltx_td ltx_align_left" id="S2.T1.1.3.3.2.1.2.1">‘理’, ‘学’, ‘、’, ‘0xE5’, ‘0x93’, ‘0xB2’, ‘学’, ‘等’, ‘学’, ‘科’, ‘0xE8’,</span></span>
<span class="ltx_tr" id="S2.T1.1.3.3.2.1.3">
<span class="ltx_td ltx_align_left" id="S2.T1.1.3.3.2.1.3.1">‘0x9E’, ‘0x8D’, ‘合’, ‘的’, ‘交’, ‘0xE5’, ‘0x8F’, ‘0x89’, ‘学’, ‘科’, ‘。’</span></span>
</span></span> <span class="ltx_text" id="S2.T1.1.3.3.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="S2.T1.1.4">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T1.1.4.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S2.T1.1.4.1.1">Chinese Tokenizer</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S2.T1.1.4.2" rowspan="2"><span class="ltx_text" id="S2.T1.1.4.2.1">16</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S2.T1.1.4.3">
<span class="ltx_text" id="S2.T1.1.4.3.1"></span><span class="ltx_text" id="S2.T1.1.4.3.2">
<span class="ltx_tabular ltx_align_top" id="S2.T1.1.4.3.2.1">
<span class="ltx_tr" id="S2.T1.1.4.3.2.1.1">
<span class="ltx_td ltx_align_left" id="S2.T1.1.4.3.2.1.1.1">‘_’, ‘人工智能’, ‘是’, ‘计算机’, ‘科学’, ‘、’, ‘心理学’, ‘、’, ‘哲学’,</span></span>
<span class="ltx_tr" id="S2.T1.1.4.3.2.1.2">
<span class="ltx_td ltx_align_left" id="S2.T1.1.4.3.2.1.2.1">‘等’,‘学科’, ‘融合’, ‘的’, ‘交叉’, ‘学科’, ‘。’</span></span>
</span></span> <span class="ltx_text" id="S2.T1.1.4.3.3"></span>
</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Parameter Efficient Fine-Tuning with LoRA</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">LLM의 전체 매개변수를 업데이트하는 기존의 훈련 패러다임은 엄청나게 비싸고 대부분의 실험실이나 회사에 시간이나 비용이 들지 않는다. Low-Rank Adaptation (LoRA) <cite class="ltx_cite ltx_citemacro_citep">(Hu et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib10" title="">2021</a>)</cite>는 훈련 가능한 순위 분해 행렬을 도입하면서 미리 훈련된 모델 가중치를 유지하는 파라미터 효율적인 훈련 방법이다. LoRA는 미리 훈련된 모델 가중치를 동결시키고 훈련 가능한 저순위 매트릭스를 각 레이어에 주입한다. 이 접근법은 총 훈련 가능한 파라미터를 상당히 감소시켜, 훨씬 적은 계산 자원으로 LLM을 훈련시키는 것을 가능하게 한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.7">구체적으로, 가중치 매트릭스 <math alttext="W_{0}\in\mathbb{R}^{d\times k}" class="ltx_Math" display="inline" id="S2.SS3.p2.1.m1.1"><semantics id="S2.SS3.p2.1.m1.1a"><mrow id="S2.SS3.p2.1.m1.1.1" xref="S2.SS3.p2.1.m1.1.1.cmml"><msub id="S2.SS3.p2.1.m1.1.1.2" xref="S2.SS3.p2.1.m1.1.1.2.cmml"><mi id="S2.SS3.p2.1.m1.1.1.2.2" xref="S2.SS3.p2.1.m1.1.1.2.2.cmml">W</mi><mn id="S2.SS3.p2.1.m1.1.1.2.3" xref="S2.SS3.p2.1.m1.1.1.2.3.cmml">0</mn></msub><mo id="S2.SS3.p2.1.m1.1.1.1" xref="S2.SS3.p2.1.m1.1.1.1.cmml">∈</mo><msup id="S2.SS3.p2.1.m1.1.1.3" xref="S2.SS3.p2.1.m1.1.1.3.cmml"><mi id="S2.SS3.p2.1.m1.1.1.3.2" xref="S2.SS3.p2.1.m1.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS3.p2.1.m1.1.1.3.3" xref="S2.SS3.p2.1.m1.1.1.3.3.cmml"><mi id="S2.SS3.p2.1.m1.1.1.3.3.2" xref="S2.SS3.p2.1.m1.1.1.3.3.2.cmml">d</mi><mo id="S2.SS3.p2.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.p2.1.m1.1.1.3.3.1.cmml">×</mo><mi id="S2.SS3.p2.1.m1.1.1.3.3.3" xref="S2.SS3.p2.1.m1.1.1.3.3.3.cmml">k</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.1.m1.1b"><apply id="S2.SS3.p2.1.m1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1"><in id="S2.SS3.p2.1.m1.1.1.1.cmml" xref="S2.SS3.p2.1.m1.1.1.1"></in><apply id="S2.SS3.p2.1.m1.1.1.2.cmml" xref="S2.SS3.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.SS3.p2.1.m1.1.1.2.1.cmml" xref="S2.SS3.p2.1.m1.1.1.2">subscript</csymbol><ci id="S2.SS3.p2.1.m1.1.1.2.2.cmml" xref="S2.SS3.p2.1.m1.1.1.2.2">𝑊</ci><cn id="S2.SS3.p2.1.m1.1.1.2.3.cmml" type="integer" xref="S2.SS3.p2.1.m1.1.1.2.3">0</cn></apply><apply id="S2.SS3.p2.1.m1.1.1.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p2.1.m1.1.1.3.1.cmml" xref="S2.SS3.p2.1.m1.1.1.3">superscript</csymbol><ci id="S2.SS3.p2.1.m1.1.1.3.2.cmml" xref="S2.SS3.p2.1.m1.1.1.3.2">ℝ</ci><apply id="S2.SS3.p2.1.m1.1.1.3.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3"><times id="S2.SS3.p2.1.m1.1.1.3.3.1.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.1"></times><ci id="S2.SS3.p2.1.m1.1.1.3.3.2.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.2">𝑑</ci><ci id="S2.SS3.p2.1.m1.1.1.3.3.3.cmml" xref="S2.SS3.p2.1.m1.1.1.3.3.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.1.m1.1c">W_{0}\in\mathbb{R}^{d\times k}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.1.m1.1d">italic_W start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_d × italic_k end_POSTSUPERSCRIPT</annotation></semantics></math>, 여기서 <math alttext="k" class="ltx_Math" display="inline" id="S2.SS3.p2.2.m2.1"><semantics id="S2.SS3.p2.2.m2.1a"><mi id="S2.SS3.p2.2.m2.1.1" xref="S2.SS3.p2.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.2.m2.1b"><ci id="S2.SS3.p2.2.m2.1.1.cmml" xref="S2.SS3.p2.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.2.m2.1d">italic_k</annotation></semantics></math>는 입력 차원이고, <math alttext="d" class="ltx_Math" display="inline" id="S2.SS3.p2.3.m3.1"><semantics id="S2.SS3.p2.3.m3.1a"><mi id="S2.SS3.p2.3.m3.1.1" xref="S2.SS3.p2.3.m3.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.3.m3.1b"><ci id="S2.SS3.p2.3.m3.1.1.cmml" xref="S2.SS3.p2.3.m3.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.3.m3.1c">d</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.3.m3.1d">italic_d</annotation></semantics></math>는 출력 차원인 선형 레이어에 대해, LoRA는 두 개의 저순위 분해된 훈련 가능한 매트릭스 <math alttext="B\in\mathbb{R}^{d\times r}" class="ltx_Math" display="inline" id="S2.SS3.p2.4.m4.1"><semantics id="S2.SS3.p2.4.m4.1a"><mrow id="S2.SS3.p2.4.m4.1.1" xref="S2.SS3.p2.4.m4.1.1.cmml"><mi id="S2.SS3.p2.4.m4.1.1.2" xref="S2.SS3.p2.4.m4.1.1.2.cmml">B</mi><mo id="S2.SS3.p2.4.m4.1.1.1" xref="S2.SS3.p2.4.m4.1.1.1.cmml">∈</mo><msup id="S2.SS3.p2.4.m4.1.1.3" xref="S2.SS3.p2.4.m4.1.1.3.cmml"><mi id="S2.SS3.p2.4.m4.1.1.3.2" xref="S2.SS3.p2.4.m4.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS3.p2.4.m4.1.1.3.3" xref="S2.SS3.p2.4.m4.1.1.3.3.cmml"><mi id="S2.SS3.p2.4.m4.1.1.3.3.2" xref="S2.SS3.p2.4.m4.1.1.3.3.2.cmml">d</mi><mo id="S2.SS3.p2.4.m4.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.p2.4.m4.1.1.3.3.1.cmml">×</mo><mi id="S2.SS3.p2.4.m4.1.1.3.3.3" xref="S2.SS3.p2.4.m4.1.1.3.3.3.cmml">r</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.4.m4.1b"><apply id="S2.SS3.p2.4.m4.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1"><in id="S2.SS3.p2.4.m4.1.1.1.cmml" xref="S2.SS3.p2.4.m4.1.1.1"></in><ci id="S2.SS3.p2.4.m4.1.1.2.cmml" xref="S2.SS3.p2.4.m4.1.1.2">𝐵</ci><apply id="S2.SS3.p2.4.m4.1.1.3.cmml" xref="S2.SS3.p2.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p2.4.m4.1.1.3.1.cmml" xref="S2.SS3.p2.4.m4.1.1.3">superscript</csymbol><ci id="S2.SS3.p2.4.m4.1.1.3.2.cmml" xref="S2.SS3.p2.4.m4.1.1.3.2">ℝ</ci><apply id="S2.SS3.p2.4.m4.1.1.3.3.cmml" xref="S2.SS3.p2.4.m4.1.1.3.3"><times id="S2.SS3.p2.4.m4.1.1.3.3.1.cmml" xref="S2.SS3.p2.4.m4.1.1.3.3.1"></times><ci id="S2.SS3.p2.4.m4.1.1.3.3.2.cmml" xref="S2.SS3.p2.4.m4.1.1.3.3.2">𝑑</ci><ci id="S2.SS3.p2.4.m4.1.1.3.3.3.cmml" xref="S2.SS3.p2.4.m4.1.1.3.3.3">𝑟</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.4.m4.1c">B\in\mathbb{R}^{d\times r}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.4.m4.1d">italic_B ∈ blackboard_R start_POSTSUPERSCRIPT italic_d × italic_r end_POSTSUPERSCRIPT</annotation></semantics></math> 및 <math alttext="A\in\mathbb{R}^{r\times k}" class="ltx_Math" display="inline" id="S2.SS3.p2.5.m5.1"><semantics id="S2.SS3.p2.5.m5.1a"><mrow id="S2.SS3.p2.5.m5.1.1" xref="S2.SS3.p2.5.m5.1.1.cmml"><mi id="S2.SS3.p2.5.m5.1.1.2" xref="S2.SS3.p2.5.m5.1.1.2.cmml">A</mi><mo id="S2.SS3.p2.5.m5.1.1.1" xref="S2.SS3.p2.5.m5.1.1.1.cmml">∈</mo><msup id="S2.SS3.p2.5.m5.1.1.3" xref="S2.SS3.p2.5.m5.1.1.3.cmml"><mi id="S2.SS3.p2.5.m5.1.1.3.2" xref="S2.SS3.p2.5.m5.1.1.3.2.cmml">ℝ</mi><mrow id="S2.SS3.p2.5.m5.1.1.3.3" xref="S2.SS3.p2.5.m5.1.1.3.3.cmml"><mi id="S2.SS3.p2.5.m5.1.1.3.3.2" xref="S2.SS3.p2.5.m5.1.1.3.3.2.cmml">r</mi><mo id="S2.SS3.p2.5.m5.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS3.p2.5.m5.1.1.3.3.1.cmml">×</mo><mi id="S2.SS3.p2.5.m5.1.1.3.3.3" xref="S2.SS3.p2.5.m5.1.1.3.3.3.cmml">k</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.5.m5.1b"><apply id="S2.SS3.p2.5.m5.1.1.cmml" xref="S2.SS3.p2.5.m5.1.1"><in id="S2.SS3.p2.5.m5.1.1.1.cmml" xref="S2.SS3.p2.5.m5.1.1.1"></in><ci id="S2.SS3.p2.5.m5.1.1.2.cmml" xref="S2.SS3.p2.5.m5.1.1.2">𝐴</ci><apply id="S2.SS3.p2.5.m5.1.1.3.cmml" xref="S2.SS3.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S2.SS3.p2.5.m5.1.1.3.1.cmml" xref="S2.SS3.p2.5.m5.1.1.3">superscript</csymbol><ci id="S2.SS3.p2.5.m5.1.1.3.2.cmml" xref="S2.SS3.p2.5.m5.1.1.3.2">ℝ</ci><apply id="S2.SS3.p2.5.m5.1.1.3.3.cmml" xref="S2.SS3.p2.5.m5.1.1.3.3"><times id="S2.SS3.p2.5.m5.1.1.3.3.1.cmml" xref="S2.SS3.p2.5.m5.1.1.3.3.1"></times><ci id="S2.SS3.p2.5.m5.1.1.3.3.2.cmml" xref="S2.SS3.p2.5.m5.1.1.3.3.2">𝑟</ci><ci id="S2.SS3.p2.5.m5.1.1.3.3.3.cmml" xref="S2.SS3.p2.5.m5.1.1.3.3.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.5.m5.1c">A\in\mathbb{R}^{r\times k}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.5.m5.1d">italic_A ∈ blackboard_R start_POSTSUPERSCRIPT italic_r × italic_k end_POSTSUPERSCRIPT</annotation></semantics></math>, 여기서 <math alttext="r" class="ltx_Math" display="inline" id="S2.SS3.p2.6.m6.1"><semantics id="S2.SS3.p2.6.m6.1a"><mi id="S2.SS3.p2.6.m6.1.1" xref="S2.SS3.p2.6.m6.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.6.m6.1b"><ci id="S2.SS3.p2.6.m6.1.1.cmml" xref="S2.SS3.p2.6.m6.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.6.m6.1c">r</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.6.m6.1d">italic_r</annotation></semantics></math>는 미리 결정된 랭크이다. 입력 <math alttext="x" class="ltx_Math" display="inline" id="S2.SS3.p2.7.m7.1"><semantics id="S2.SS3.p2.7.m7.1a"><mi id="S2.SS3.p2.7.m7.1.1" xref="S2.SS3.p2.7.m7.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p2.7.m7.1b"><ci id="S2.SS3.p2.7.m7.1.1.cmml" xref="S2.SS3.p2.7.m7.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p2.7.m7.1c">x</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p2.7.m7.1d">italic_x</annotation></semantics></math>를 갖는 순방향 패스는 다음의 수학식에 의해 주어지고,</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p3">
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="h=W_{0}x+\Delta Wx=W_{0}x+BAx,~{}~{}B\in\mathbb{R}^{d\times r},A\in\mathbb{R}^%
{r\times d}" class="ltx_Math" display="block" id="S2.E1.m1.2"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.3.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.cmml">h</mi><mo id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.3.cmml">=</mo><mrow id="S2.E1.m1.1.1.1.1.4" xref="S2.E1.m1.1.1.1.1.4.cmml"><mrow id="S2.E1.m1.1.1.1.1.4.2" xref="S2.E1.m1.1.1.1.1.4.2.cmml"><msub id="S2.E1.m1.1.1.1.1.4.2.2" xref="S2.E1.m1.1.1.1.1.4.2.2.cmml"><mi id="S2.E1.m1.1.1.1.1.4.2.2.2" xref="S2.E1.m1.1.1.1.1.4.2.2.2.cmml">W</mi><mn id="S2.E1.m1.1.1.1.1.4.2.2.3" xref="S2.E1.m1.1.1.1.1.4.2.2.3.cmml">0</mn></msub><mo id="S2.E1.m1.1.1.1.1.4.2.1" xref="S2.E1.m1.1.1.1.1.4.2.1.cmml">⁢</mo><mi id="S2.E1.m1.1.1.1.1.4.2.3" xref="S2.E1.m1.1.1.1.1.4.2.3.cmml">x</mi></mrow><mo id="S2.E1.m1.1.1.1.1.4.1" xref="S2.E1.m1.1.1.1.1.4.1.cmml">+</mo><mrow id="S2.E1.m1.1.1.1.1.4.3" xref="S2.E1.m1.1.1.1.1.4.3.cmml"><mi id="S2.E1.m1.1.1.1.1.4.3.2" mathvariant="normal" xref="S2.E1.m1.1.1.1.1.4.3.2.cmml">Δ</mi><mo id="S2.E1.m1.1.1.1.1.4.3.1" xref="S2.E1.m1.1.1.1.1.4.3.1.cmml">⁢</mo><mi id="S2.E1.m1.1.1.1.1.4.3.3" xref="S2.E1.m1.1.1.1.1.4.3.3.cmml">W</mi><mo id="S2.E1.m1.1.1.1.1.4.3.1a" xref="S2.E1.m1.1.1.1.1.4.3.1.cmml">⁢</mo><mi id="S2.E1.m1.1.1.1.1.4.3.4" xref="S2.E1.m1.1.1.1.1.4.3.4.cmml">x</mi></mrow></mrow><mo id="S2.E1.m1.1.1.1.1.5" xref="S2.E1.m1.1.1.1.1.5.cmml">=</mo><mrow id="S2.E1.m1.1.1.1.1.6" xref="S2.E1.m1.1.1.1.1.6.cmml"><mrow id="S2.E1.m1.1.1.1.1.6.2" xref="S2.E1.m1.1.1.1.1.6.2.cmml"><msub id="S2.E1.m1.1.1.1.1.6.2.2" xref="S2.E1.m1.1.1.1.1.6.2.2.cmml"><mi id="S2.E1.m1.1.1.1.1.6.2.2.2" xref="S2.E1.m1.1.1.1.1.6.2.2.2.cmml">W</mi><mn id="S2.E1.m1.1.1.1.1.6.2.2.3" xref="S2.E1.m1.1.1.1.1.6.2.2.3.cmml">0</mn></msub><mo id="S2.E1.m1.1.1.1.1.6.2.1" xref="S2.E1.m1.1.1.1.1.6.2.1.cmml">⁢</mo><mi id="S2.E1.m1.1.1.1.1.6.2.3" xref="S2.E1.m1.1.1.1.1.6.2.3.cmml">x</mi></mrow><mo id="S2.E1.m1.1.1.1.1.6.1" xref="S2.E1.m1.1.1.1.1.6.1.cmml">+</mo><mrow id="S2.E1.m1.1.1.1.1.6.3" xref="S2.E1.m1.1.1.1.1.6.3.cmml"><mi id="S2.E1.m1.1.1.1.1.6.3.2" xref="S2.E1.m1.1.1.1.1.6.3.2.cmml">B</mi><mo id="S2.E1.m1.1.1.1.1.6.3.1" xref="S2.E1.m1.1.1.1.1.6.3.1.cmml">⁢</mo><mi id="S2.E1.m1.1.1.1.1.6.3.3" xref="S2.E1.m1.1.1.1.1.6.3.3.cmml">A</mi><mo id="S2.E1.m1.1.1.1.1.6.3.1a" xref="S2.E1.m1.1.1.1.1.6.3.1.cmml">⁢</mo><mi id="S2.E1.m1.1.1.1.1.6.3.4" xref="S2.E1.m1.1.1.1.1.6.3.4.cmml">x</mi></mrow></mrow></mrow><mo id="S2.E1.m1.2.2.2.3" rspace="0.827em" xref="S2.E1.m1.2.2.3a.cmml">,</mo><mrow id="S2.E1.m1.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.3.cmml"><mrow id="S2.E1.m1.2.2.2.2.1.1" xref="S2.E1.m1.2.2.2.2.1.1.cmml"><mi id="S2.E1.m1.2.2.2.2.1.1.2" xref="S2.E1.m1.2.2.2.2.1.1.2.cmml">B</mi><mo id="S2.E1.m1.2.2.2.2.1.1.1" xref="S2.E1.m1.2.2.2.2.1.1.1.cmml">∈</mo><msup id="S2.E1.m1.2.2.2.2.1.1.3" xref="S2.E1.m1.2.2.2.2.1.1.3.cmml"><mi id="S2.E1.m1.2.2.2.2.1.1.3.2" xref="S2.E1.m1.2.2.2.2.1.1.3.2.cmml">ℝ</mi><mrow id="S2.E1.m1.2.2.2.2.1.1.3.3" xref="S2.E1.m1.2.2.2.2.1.1.3.3.cmml"><mi id="S2.E1.m1.2.2.2.2.1.1.3.3.2" xref="S2.E1.m1.2.2.2.2.1.1.3.3.2.cmml">d</mi><mo id="S2.E1.m1.2.2.2.2.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.E1.m1.2.2.2.2.1.1.3.3.1.cmml">×</mo><mi id="S2.E1.m1.2.2.2.2.1.1.3.3.3" xref="S2.E1.m1.2.2.2.2.1.1.3.3.3.cmml">r</mi></mrow></msup></mrow><mo id="S2.E1.m1.2.2.2.2.2.3" xref="S2.E1.m1.2.2.2.2.3a.cmml">,</mo><mrow id="S2.E1.m1.2.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.2.cmml"><mi id="S2.E1.m1.2.2.2.2.2.2.2" xref="S2.E1.m1.2.2.2.2.2.2.2.cmml">A</mi><mo id="S2.E1.m1.2.2.2.2.2.2.1" xref="S2.E1.m1.2.2.2.2.2.2.1.cmml">∈</mo><msup id="S2.E1.m1.2.2.2.2.2.2.3" xref="S2.E1.m1.2.2.2.2.2.2.3.cmml"><mi id="S2.E1.m1.2.2.2.2.2.2.3.2" xref="S2.E1.m1.2.2.2.2.2.2.3.2.cmml">ℝ</mi><mrow id="S2.E1.m1.2.2.2.2.2.2.3.3" xref="S2.E1.m1.2.2.2.2.2.2.3.3.cmml"><mi id="S2.E1.m1.2.2.2.2.2.2.3.3.2" xref="S2.E1.m1.2.2.2.2.2.2.3.3.2.cmml">r</mi><mo id="S2.E1.m1.2.2.2.2.2.2.3.3.1" lspace="0.222em" rspace="0.222em" xref="S2.E1.m1.2.2.2.2.2.2.3.3.1.cmml">×</mo><mi id="S2.E1.m1.2.2.2.2.2.2.3.3.3" xref="S2.E1.m1.2.2.2.2.2.2.3.3.3.cmml">d</mi></mrow></msup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.3.cmml" xref="S2.E1.m1.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.3a.cmml" xref="S2.E1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1"><and id="S2.E1.m1.1.1.1.1a.cmml" xref="S2.E1.m1.1.1.1.1"></and><apply id="S2.E1.m1.1.1.1.1b.cmml" xref="S2.E1.m1.1.1.1.1"><eq id="S2.E1.m1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.3"></eq><ci id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2">ℎ</ci><apply id="S2.E1.m1.1.1.1.1.4.cmml" xref="S2.E1.m1.1.1.1.1.4"><plus id="S2.E1.m1.1.1.1.1.4.1.cmml" xref="S2.E1.m1.1.1.1.1.4.1"></plus><apply id="S2.E1.m1.1.1.1.1.4.2.cmml" xref="S2.E1.m1.1.1.1.1.4.2"><times id="S2.E1.m1.1.1.1.1.4.2.1.cmml" xref="S2.E1.m1.1.1.1.1.4.2.1"></times><apply id="S2.E1.m1.1.1.1.1.4.2.2.cmml" xref="S2.E1.m1.1.1.1.1.4.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.4.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.4.2.2">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.4.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.4.2.2.2">𝑊</ci><cn id="S2.E1.m1.1.1.1.1.4.2.2.3.cmml" type="integer" xref="S2.E1.m1.1.1.1.1.4.2.2.3">0</cn></apply><ci id="S2.E1.m1.1.1.1.1.4.2.3.cmml" xref="S2.E1.m1.1.1.1.1.4.2.3">𝑥</ci></apply><apply id="S2.E1.m1.1.1.1.1.4.3.cmml" xref="S2.E1.m1.1.1.1.1.4.3"><times id="S2.E1.m1.1.1.1.1.4.3.1.cmml" xref="S2.E1.m1.1.1.1.1.4.3.1"></times><ci id="S2.E1.m1.1.1.1.1.4.3.2.cmml" xref="S2.E1.m1.1.1.1.1.4.3.2">Δ</ci><ci id="S2.E1.m1.1.1.1.1.4.3.3.cmml" xref="S2.E1.m1.1.1.1.1.4.3.3">𝑊</ci><ci id="S2.E1.m1.1.1.1.1.4.3.4.cmml" xref="S2.E1.m1.1.1.1.1.4.3.4">𝑥</ci></apply></apply></apply><apply id="S2.E1.m1.1.1.1.1c.cmml" xref="S2.E1.m1.1.1.1.1"><eq id="S2.E1.m1.1.1.1.1.5.cmml" xref="S2.E1.m1.1.1.1.1.5"></eq><share href="#S2.E1.m1.1.1.1.1.4.cmml" id="S2.E1.m1.1.1.1.1d.cmml" xref="S2.E1.m1.1.1.1.1"></share><apply id="S2.E1.m1.1.1.1.1.6.cmml" xref="S2.E1.m1.1.1.1.1.6"><plus id="S2.E1.m1.1.1.1.1.6.1.cmml" xref="S2.E1.m1.1.1.1.1.6.1"></plus><apply id="S2.E1.m1.1.1.1.1.6.2.cmml" xref="S2.E1.m1.1.1.1.1.6.2"><times id="S2.E1.m1.1.1.1.1.6.2.1.cmml" xref="S2.E1.m1.1.1.1.1.6.2.1"></times><apply id="S2.E1.m1.1.1.1.1.6.2.2.cmml" xref="S2.E1.m1.1.1.1.1.6.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.6.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.6.2.2">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.6.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.6.2.2.2">𝑊</ci><cn id="S2.E1.m1.1.1.1.1.6.2.2.3.cmml" type="integer" xref="S2.E1.m1.1.1.1.1.6.2.2.3">0</cn></apply><ci id="S2.E1.m1.1.1.1.1.6.2.3.cmml" xref="S2.E1.m1.1.1.1.1.6.2.3">𝑥</ci></apply><apply id="S2.E1.m1.1.1.1.1.6.3.cmml" xref="S2.E1.m1.1.1.1.1.6.3"><times id="S2.E1.m1.1.1.1.1.6.3.1.cmml" xref="S2.E1.m1.1.1.1.1.6.3.1"></times><ci id="S2.E1.m1.1.1.1.1.6.3.2.cmml" xref="S2.E1.m1.1.1.1.1.6.3.2">𝐵</ci><ci id="S2.E1.m1.1.1.1.1.6.3.3.cmml" xref="S2.E1.m1.1.1.1.1.6.3.3">𝐴</ci><ci id="S2.E1.m1.1.1.1.1.6.3.4.cmml" xref="S2.E1.m1.1.1.1.1.6.3.4">𝑥</ci></apply></apply></apply></apply><apply id="S2.E1.m1.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.3a.cmml" xref="S2.E1.m1.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S2.E1.m1.2.2.2.2.1.1.cmml" xref="S2.E1.m1.2.2.2.2.1.1"><in id="S2.E1.m1.2.2.2.2.1.1.1.cmml" xref="S2.E1.m1.2.2.2.2.1.1.1"></in><ci id="S2.E1.m1.2.2.2.2.1.1.2.cmml" xref="S2.E1.m1.2.2.2.2.1.1.2">𝐵</ci><apply id="S2.E1.m1.2.2.2.2.1.1.3.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.1.1.3.1.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3">superscript</csymbol><ci id="S2.E1.m1.2.2.2.2.1.1.3.2.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3.2">ℝ</ci><apply id="S2.E1.m1.2.2.2.2.1.1.3.3.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3.3"><times id="S2.E1.m1.2.2.2.2.1.1.3.3.1.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3.3.1"></times><ci id="S2.E1.m1.2.2.2.2.1.1.3.3.2.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3.3.2">𝑑</ci><ci id="S2.E1.m1.2.2.2.2.1.1.3.3.3.cmml" xref="S2.E1.m1.2.2.2.2.1.1.3.3.3">𝑟</ci></apply></apply></apply><apply id="S2.E1.m1.2.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2"><in id="S2.E1.m1.2.2.2.2.2.2.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2.1"></in><ci id="S2.E1.m1.2.2.2.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2.2">𝐴</ci><apply id="S2.E1.m1.2.2.2.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.2.2.2.2.3.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3">superscript</csymbol><ci id="S2.E1.m1.2.2.2.2.2.2.3.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3.2">ℝ</ci><apply id="S2.E1.m1.2.2.2.2.2.2.3.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3.3"><times id="S2.E1.m1.2.2.2.2.2.2.3.3.1.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3.3.1"></times><ci id="S2.E1.m1.2.2.2.2.2.2.3.3.2.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3.3.2">𝑟</ci><ci id="S2.E1.m1.2.2.2.2.2.2.3.3.3.cmml" xref="S2.E1.m1.2.2.2.2.2.2.3.3.3">𝑑</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">h=W_{0}x+\Delta Wx=W_{0}x+BAx,~{}~{}B\in\mathbb{R}^{d\times r},A\in\mathbb{R}^%
{r\times d}</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.2d">italic_h = italic_W start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_x + roman_Δ italic_W italic_x = italic_W start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT italic_x + italic_B italic_A italic_x , italic_B ∈ blackboard_R start_POSTSUPERSCRIPT italic_d × italic_r end_POSTSUPERSCRIPT , italic_A ∈ blackboard_R start_POSTSUPERSCRIPT italic_r × italic_d end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p4">
<p class="ltx_p" id="S2.SS3.p4.4">트레이닝 동안, <math alttext="W_{0}" class="ltx_Math" display="inline" id="S2.SS3.p4.1.m1.1"><semantics id="S2.SS3.p4.1.m1.1a"><msub id="S2.SS3.p4.1.m1.1.1" xref="S2.SS3.p4.1.m1.1.1.cmml"><mi id="S2.SS3.p4.1.m1.1.1.2" xref="S2.SS3.p4.1.m1.1.1.2.cmml">W</mi><mn id="S2.SS3.p4.1.m1.1.1.3" xref="S2.SS3.p4.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.1.m1.1b"><apply id="S2.SS3.p4.1.m1.1.1.cmml" xref="S2.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p4.1.m1.1.1.1.cmml" xref="S2.SS3.p4.1.m1.1.1">subscript</csymbol><ci id="S2.SS3.p4.1.m1.1.1.2.cmml" xref="S2.SS3.p4.1.m1.1.1.2">𝑊</ci><cn id="S2.SS3.p4.1.m1.1.1.3.cmml" type="integer" xref="S2.SS3.p4.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.1.m1.1c">W_{0}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p4.1.m1.1d">italic_W start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>는 동결되고 그래디언트 업데이트를 수신하지 않는 반면, <math alttext="B" class="ltx_Math" display="inline" id="S2.SS3.p4.2.m2.1"><semantics id="S2.SS3.p4.2.m2.1a"><mi id="S2.SS3.p4.2.m2.1.1" xref="S2.SS3.p4.2.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.2.m2.1b"><ci id="S2.SS3.p4.2.m2.1.1.cmml" xref="S2.SS3.p4.2.m2.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.2.m2.1c">B</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p4.2.m2.1d">italic_B</annotation></semantics></math> 및 <math alttext="A" class="ltx_Math" display="inline" id="S2.SS3.p4.3.m3.1"><semantics id="S2.SS3.p4.3.m3.1a"><mi id="S2.SS3.p4.3.m3.1.1" xref="S2.SS3.p4.3.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.3.m3.1b"><ci id="S2.SS3.p4.3.m3.1.1.cmml" xref="S2.SS3.p4.3.m3.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.3.m3.1c">A</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p4.3.m3.1d">italic_A</annotation></semantics></math>는 업데이트된다. 랭크 <math alttext="r\ll\min(d,k)" class="ltx_Math" display="inline" id="S2.SS3.p4.4.m4.3"><semantics id="S2.SS3.p4.4.m4.3a"><mrow id="S2.SS3.p4.4.m4.3.4" xref="S2.SS3.p4.4.m4.3.4.cmml"><mi id="S2.SS3.p4.4.m4.3.4.2" xref="S2.SS3.p4.4.m4.3.4.2.cmml">r</mi><mo id="S2.SS3.p4.4.m4.3.4.1" xref="S2.SS3.p4.4.m4.3.4.1.cmml">≪</mo><mrow id="S2.SS3.p4.4.m4.3.4.3.2" xref="S2.SS3.p4.4.m4.3.4.3.1.cmml"><mi id="S2.SS3.p4.4.m4.1.1" xref="S2.SS3.p4.4.m4.1.1.cmml">min</mi><mo id="S2.SS3.p4.4.m4.3.4.3.2a" xref="S2.SS3.p4.4.m4.3.4.3.1.cmml">⁡</mo><mrow id="S2.SS3.p4.4.m4.3.4.3.2.1" xref="S2.SS3.p4.4.m4.3.4.3.1.cmml"><mo id="S2.SS3.p4.4.m4.3.4.3.2.1.1" stretchy="false" xref="S2.SS3.p4.4.m4.3.4.3.1.cmml">(</mo><mi id="S2.SS3.p4.4.m4.2.2" xref="S2.SS3.p4.4.m4.2.2.cmml">d</mi><mo id="S2.SS3.p4.4.m4.3.4.3.2.1.2" xref="S2.SS3.p4.4.m4.3.4.3.1.cmml">,</mo><mi id="S2.SS3.p4.4.m4.3.3" xref="S2.SS3.p4.4.m4.3.3.cmml">k</mi><mo id="S2.SS3.p4.4.m4.3.4.3.2.1.3" stretchy="false" xref="S2.SS3.p4.4.m4.3.4.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS3.p4.4.m4.3b"><apply id="S2.SS3.p4.4.m4.3.4.cmml" xref="S2.SS3.p4.4.m4.3.4"><csymbol cd="latexml" id="S2.SS3.p4.4.m4.3.4.1.cmml" xref="S2.SS3.p4.4.m4.3.4.1">much-less-than</csymbol><ci id="S2.SS3.p4.4.m4.3.4.2.cmml" xref="S2.SS3.p4.4.m4.3.4.2">𝑟</ci><apply id="S2.SS3.p4.4.m4.3.4.3.1.cmml" xref="S2.SS3.p4.4.m4.3.4.3.2"><min id="S2.SS3.p4.4.m4.1.1.cmml" xref="S2.SS3.p4.4.m4.1.1"></min><ci id="S2.SS3.p4.4.m4.2.2.cmml" xref="S2.SS3.p4.4.m4.2.2">𝑑</ci><ci id="S2.SS3.p4.4.m4.3.3.cmml" xref="S2.SS3.p4.4.m4.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p4.4.m4.3c">r\ll\min(d,k)</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p4.4.m4.3d">italic_r ≪ roman_min ( italic_d , italic_k )</annotation></semantics></math>를 선택함으로써, 큰 동결 매트릭스에 대한 최적화기 상태들을 저장할 필요가 없기 때문에 메모리 소비가 감소된다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS3.p5">
<p class="ltx_p" id="S2.SS3.p5.1">빠듯한 예산을 준수하면서 매개변수 효율적인 훈련을 달성하기 위해 사전 훈련 및 미세 조정 단계를 포함하여 논문의 모든 중국 LLaMA 및 알파카 모델에 LoRA 훈련을 적용한다. 주로 LoRA 어댑터를 어텐션 모듈과 MLP 레이어의 가중치에 통합한다. 모든 선형 변압기 블록에 LoRA를 적용하는 효과는 QLoRA <cite class="ltx_cite ltx_citemacro_citep">(Dettmers et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib6" title="">2023</a>)</cite>에서 검증되며, 이는 우리의 선택이 합리적임을 나타낸다.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Pre-Training Objective</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.2">우리는 표준 인과 언어 모델링(CLM) 작업으로 중국 LLaMA 모델을 사전 훈련한다. 입력 토큰 시퀀스 <math alttext="\bm{x}=(x_{0},x_{1},x_{2},\ldots)" class="ltx_Math" display="inline" id="S2.SS4.p1.1.m1.4"><semantics id="S2.SS4.p1.1.m1.4a"><mrow id="S2.SS4.p1.1.m1.4.4" xref="S2.SS4.p1.1.m1.4.4.cmml"><mi id="S2.SS4.p1.1.m1.4.4.5" xref="S2.SS4.p1.1.m1.4.4.5.cmml">𝒙</mi><mo id="S2.SS4.p1.1.m1.4.4.4" xref="S2.SS4.p1.1.m1.4.4.4.cmml">=</mo><mrow id="S2.SS4.p1.1.m1.4.4.3.3" xref="S2.SS4.p1.1.m1.4.4.3.4.cmml"><mo id="S2.SS4.p1.1.m1.4.4.3.3.4" stretchy="false" xref="S2.SS4.p1.1.m1.4.4.3.4.cmml">(</mo><msub id="S2.SS4.p1.1.m1.2.2.1.1.1" xref="S2.SS4.p1.1.m1.2.2.1.1.1.cmml"><mi id="S2.SS4.p1.1.m1.2.2.1.1.1.2" xref="S2.SS4.p1.1.m1.2.2.1.1.1.2.cmml">x</mi><mn id="S2.SS4.p1.1.m1.2.2.1.1.1.3" xref="S2.SS4.p1.1.m1.2.2.1.1.1.3.cmml">0</mn></msub><mo id="S2.SS4.p1.1.m1.4.4.3.3.5" xref="S2.SS4.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S2.SS4.p1.1.m1.3.3.2.2.2" xref="S2.SS4.p1.1.m1.3.3.2.2.2.cmml"><mi id="S2.SS4.p1.1.m1.3.3.2.2.2.2" xref="S2.SS4.p1.1.m1.3.3.2.2.2.2.cmml">x</mi><mn id="S2.SS4.p1.1.m1.3.3.2.2.2.3" xref="S2.SS4.p1.1.m1.3.3.2.2.2.3.cmml">1</mn></msub><mo id="S2.SS4.p1.1.m1.4.4.3.3.6" xref="S2.SS4.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S2.SS4.p1.1.m1.4.4.3.3.3" xref="S2.SS4.p1.1.m1.4.4.3.3.3.cmml"><mi id="S2.SS4.p1.1.m1.4.4.3.3.3.2" xref="S2.SS4.p1.1.m1.4.4.3.3.3.2.cmml">x</mi><mn id="S2.SS4.p1.1.m1.4.4.3.3.3.3" xref="S2.SS4.p1.1.m1.4.4.3.3.3.3.cmml">2</mn></msub><mo id="S2.SS4.p1.1.m1.4.4.3.3.7" xref="S2.SS4.p1.1.m1.4.4.3.4.cmml">,</mo><mi id="S2.SS4.p1.1.m1.1.1" mathvariant="normal" xref="S2.SS4.p1.1.m1.1.1.cmml">…</mi><mo id="S2.SS4.p1.1.m1.4.4.3.3.8" stretchy="false" xref="S2.SS4.p1.1.m1.4.4.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.1.m1.4b"><apply id="S2.SS4.p1.1.m1.4.4.cmml" xref="S2.SS4.p1.1.m1.4.4"><eq id="S2.SS4.p1.1.m1.4.4.4.cmml" xref="S2.SS4.p1.1.m1.4.4.4"></eq><ci id="S2.SS4.p1.1.m1.4.4.5.cmml" xref="S2.SS4.p1.1.m1.4.4.5">𝒙</ci><vector id="S2.SS4.p1.1.m1.4.4.3.4.cmml" xref="S2.SS4.p1.1.m1.4.4.3.3"><apply id="S2.SS4.p1.1.m1.2.2.1.1.1.cmml" xref="S2.SS4.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.1.m1.2.2.1.1.1.1.cmml" xref="S2.SS4.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S2.SS4.p1.1.m1.2.2.1.1.1.2.cmml" xref="S2.SS4.p1.1.m1.2.2.1.1.1.2">𝑥</ci><cn id="S2.SS4.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS4.p1.1.m1.2.2.1.1.1.3">0</cn></apply><apply id="S2.SS4.p1.1.m1.3.3.2.2.2.cmml" xref="S2.SS4.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS4.p1.1.m1.3.3.2.2.2.1.cmml" xref="S2.SS4.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S2.SS4.p1.1.m1.3.3.2.2.2.2.cmml" xref="S2.SS4.p1.1.m1.3.3.2.2.2.2">𝑥</ci><cn id="S2.SS4.p1.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS4.p1.1.m1.3.3.2.2.2.3">1</cn></apply><apply id="S2.SS4.p1.1.m1.4.4.3.3.3.cmml" xref="S2.SS4.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S2.SS4.p1.1.m1.4.4.3.3.3.1.cmml" xref="S2.SS4.p1.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S2.SS4.p1.1.m1.4.4.3.3.3.2.cmml" xref="S2.SS4.p1.1.m1.4.4.3.3.3.2">𝑥</ci><cn id="S2.SS4.p1.1.m1.4.4.3.3.3.3.cmml" type="integer" xref="S2.SS4.p1.1.m1.4.4.3.3.3.3">2</cn></apply><ci id="S2.SS4.p1.1.m1.1.1.cmml" xref="S2.SS4.p1.1.m1.1.1">…</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.1.m1.4c">\bm{x}=(x_{0},x_{1},x_{2},\ldots)</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.1.m1.4d">bold_italic_x = ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … )</annotation></semantics></math>가 주어지면, 모델은 다음 토큰 <math alttext="x_{i}" class="ltx_Math" display="inline" id="S2.SS4.p1.2.m2.1"><semantics id="S2.SS4.p1.2.m2.1a"><msub id="S2.SS4.p1.2.m2.1.1" xref="S2.SS4.p1.2.m2.1.1.cmml"><mi id="S2.SS4.p1.2.m2.1.1.2" xref="S2.SS4.p1.2.m2.1.1.2.cmml">x</mi><mi id="S2.SS4.p1.2.m2.1.1.3" xref="S2.SS4.p1.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.2.m2.1b"><apply id="S2.SS4.p1.2.m2.1.1.cmml" xref="S2.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.2.m2.1.1.1.cmml" xref="S2.SS4.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS4.p1.2.m2.1.1.2.cmml" xref="S2.SS4.p1.2.m2.1.1.2">𝑥</ci><ci id="S2.SS4.p1.2.m2.1.1.3.cmml" xref="S2.SS4.p1.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.2.m2.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>를 자기회귀 방식으로 예측하도록 훈련된다. 수학적으로 목표는 다음과 같은 음의 로그 우도를 최소화하는 것이다.</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx1">
<tbody id="S2.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\textrm{CLM}}(\Theta)=\mathbb{E}_{\bm{x}\sim\mathcal%
{D}_{\textrm{PT}}}\left[-\sum_{i}\log p(x_{i}|x_{0},x_{1},\ldots,x_{i-1};%
\Theta)\right]" class="ltx_Math" display="inline" id="S2.E2.m1.4"><semantics id="S2.E2.m1.4a"><mrow id="S2.E2.m1.4.4" xref="S2.E2.m1.4.4.cmml"><mrow id="S2.E2.m1.4.4.3" xref="S2.E2.m1.4.4.3.cmml"><msub id="S2.E2.m1.4.4.3.2" xref="S2.E2.m1.4.4.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.4.4.3.2.2" xref="S2.E2.m1.4.4.3.2.2.cmml">ℒ</mi><mtext id="S2.E2.m1.4.4.3.2.3" xref="S2.E2.m1.4.4.3.2.3a.cmml">CLM</mtext></msub><mo id="S2.E2.m1.4.4.3.1" xref="S2.E2.m1.4.4.3.1.cmml">⁢</mo><mrow id="S2.E2.m1.4.4.3.3.2" xref="S2.E2.m1.4.4.3.cmml"><mo id="S2.E2.m1.4.4.3.3.2.1" stretchy="false" xref="S2.E2.m1.4.4.3.cmml">(</mo><mi id="S2.E2.m1.1.1" mathvariant="normal" xref="S2.E2.m1.1.1.cmml">Θ</mi><mo id="S2.E2.m1.4.4.3.3.2.2" stretchy="false" xref="S2.E2.m1.4.4.3.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.4.4.2" xref="S2.E2.m1.4.4.2.cmml">=</mo><mrow id="S2.E2.m1.4.4.1" xref="S2.E2.m1.4.4.1.cmml"><msub id="S2.E2.m1.4.4.1.3" xref="S2.E2.m1.4.4.1.3.cmml"><mi id="S2.E2.m1.4.4.1.3.2" xref="S2.E2.m1.4.4.1.3.2.cmml">𝔼</mi><mrow id="S2.E2.m1.4.4.1.3.3" xref="S2.E2.m1.4.4.1.3.3.cmml"><mi id="S2.E2.m1.4.4.1.3.3.2" xref="S2.E2.m1.4.4.1.3.3.2.cmml">𝒙</mi><mo id="S2.E2.m1.4.4.1.3.3.1" xref="S2.E2.m1.4.4.1.3.3.1.cmml">∼</mo><msub id="S2.E2.m1.4.4.1.3.3.3" xref="S2.E2.m1.4.4.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.4.4.1.3.3.3.2" xref="S2.E2.m1.4.4.1.3.3.3.2.cmml">𝒟</mi><mtext id="S2.E2.m1.4.4.1.3.3.3.3" xref="S2.E2.m1.4.4.1.3.3.3.3a.cmml">PT</mtext></msub></mrow></msub><mo id="S2.E2.m1.4.4.1.2" xref="S2.E2.m1.4.4.1.2.cmml">⁢</mo><mrow id="S2.E2.m1.4.4.1.1.1" xref="S2.E2.m1.4.4.1.1.2.cmml"><mo id="S2.E2.m1.4.4.1.1.1.2" xref="S2.E2.m1.4.4.1.1.2.1.cmml">[</mo><mrow id="S2.E2.m1.4.4.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.cmml"><mo id="S2.E2.m1.4.4.1.1.1.1a" xref="S2.E2.m1.4.4.1.1.1.1.cmml">−</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S2.E2.m1.4.4.1.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.1.1.2.cmml"><munder id="S2.E2.m1.4.4.1.1.1.1.1.2a" xref="S2.E2.m1.4.4.1.1.1.1.1.2.cmml"><mo id="S2.E2.m1.4.4.1.1.1.1.1.2.2" movablelimits="false" xref="S2.E2.m1.4.4.1.1.1.1.1.2.2.cmml">∑</mo><mi id="S2.E2.m1.4.4.1.1.1.1.1.2.3" xref="S2.E2.m1.4.4.1.1.1.1.1.2.3.cmml">i</mi></munder></mstyle><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.cmml"><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.3.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3.1.cmml">log</mi><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.3a" lspace="0.167em" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3.cmml">⁡</mo><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.3.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3.2.cmml">p</mi></mrow><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.2.cmml">x</mi><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.3.cmml">i</mi></msub><mo fence="false" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.4" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.4.cmml">|</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml"><msub id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mn id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">0</mn></msub><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.4" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml">x</mi><mn id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">1</mn></msub><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.5" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">,</mo><mi id="S2.E2.m1.2.2" mathvariant="normal" xref="S2.E2.m1.2.2.cmml">…</mi><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.6" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2.cmml">x</mi><mrow id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2.cmml">i</mi><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1.cmml">−</mo><mn id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3.cmml">1</mn></mrow></msub><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.7" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">;</mo><mi id="S2.E2.m1.3.3" mathvariant="normal" xref="S2.E2.m1.3.3.cmml">Θ</mi></mrow></mrow><mo id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E2.m1.4.4.1.1.1.3" xref="S2.E2.m1.4.4.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.4b"><apply id="S2.E2.m1.4.4.cmml" xref="S2.E2.m1.4.4"><eq id="S2.E2.m1.4.4.2.cmml" xref="S2.E2.m1.4.4.2"></eq><apply id="S2.E2.m1.4.4.3.cmml" xref="S2.E2.m1.4.4.3"><times id="S2.E2.m1.4.4.3.1.cmml" xref="S2.E2.m1.4.4.3.1"></times><apply id="S2.E2.m1.4.4.3.2.cmml" xref="S2.E2.m1.4.4.3.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.3.2.1.cmml" xref="S2.E2.m1.4.4.3.2">subscript</csymbol><ci id="S2.E2.m1.4.4.3.2.2.cmml" xref="S2.E2.m1.4.4.3.2.2">ℒ</ci><ci id="S2.E2.m1.4.4.3.2.3a.cmml" xref="S2.E2.m1.4.4.3.2.3"><mtext id="S2.E2.m1.4.4.3.2.3.cmml" mathsize="70%" xref="S2.E2.m1.4.4.3.2.3">CLM</mtext></ci></apply><ci id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">Θ</ci></apply><apply id="S2.E2.m1.4.4.1.cmml" xref="S2.E2.m1.4.4.1"><times id="S2.E2.m1.4.4.1.2.cmml" xref="S2.E2.m1.4.4.1.2"></times><apply id="S2.E2.m1.4.4.1.3.cmml" xref="S2.E2.m1.4.4.1.3"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.3.1.cmml" xref="S2.E2.m1.4.4.1.3">subscript</csymbol><ci id="S2.E2.m1.4.4.1.3.2.cmml" xref="S2.E2.m1.4.4.1.3.2">𝔼</ci><apply id="S2.E2.m1.4.4.1.3.3.cmml" xref="S2.E2.m1.4.4.1.3.3"><csymbol cd="latexml" id="S2.E2.m1.4.4.1.3.3.1.cmml" xref="S2.E2.m1.4.4.1.3.3.1">similar-to</csymbol><ci id="S2.E2.m1.4.4.1.3.3.2.cmml" xref="S2.E2.m1.4.4.1.3.3.2">𝒙</ci><apply id="S2.E2.m1.4.4.1.3.3.3.cmml" xref="S2.E2.m1.4.4.1.3.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.3.3.3.1.cmml" xref="S2.E2.m1.4.4.1.3.3.3">subscript</csymbol><ci id="S2.E2.m1.4.4.1.3.3.3.2.cmml" xref="S2.E2.m1.4.4.1.3.3.3.2">𝒟</ci><ci id="S2.E2.m1.4.4.1.3.3.3.3a.cmml" xref="S2.E2.m1.4.4.1.3.3.3.3"><mtext id="S2.E2.m1.4.4.1.3.3.3.3.cmml" mathsize="50%" xref="S2.E2.m1.4.4.1.3.3.3.3">PT</mtext></ci></apply></apply></apply><apply id="S2.E2.m1.4.4.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1"><csymbol cd="latexml" id="S2.E2.m1.4.4.1.1.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.2">delimited-[]</csymbol><apply id="S2.E2.m1.4.4.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1"><minus id="S2.E2.m1.4.4.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1"></minus><apply id="S2.E2.m1.4.4.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1"><apply id="S2.E2.m1.4.4.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.2">subscript</csymbol><sum id="S2.E2.m1.4.4.1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.2.2"></sum><ci id="S2.E2.m1.4.4.1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1"><times id="S2.E2.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.2"></times><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3"><log id="S2.E2.m1.4.4.1.1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3.1"></log><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3.2">𝑝</ci></apply><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.4.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.4">conditional</csymbol><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.2">𝑥</ci><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.5.3">𝑖</ci></apply><list id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3"><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><cn id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3">0</cn></apply><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2">𝑥</ci><cn id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" type="integer" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3">1</cn></apply><ci id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">…</ci><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2">𝑥</ci><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3"><minus id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1"></minus><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2">𝑖</ci><cn id="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3.cmml" type="integer" xref="S2.E2.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3">1</cn></apply></apply><ci id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3">Θ</ci></list></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.4c">\displaystyle\mathcal{L}_{\textrm{CLM}}(\Theta)=\mathbb{E}_{\bm{x}\sim\mathcal%
{D}_{\textrm{PT}}}\left[-\sum_{i}\log p(x_{i}|x_{0},x_{1},\ldots,x_{i-1};%
\Theta)\right]</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.4d">caligraphic_L start_POSTSUBSCRIPT CLM end_POSTSUBSCRIPT ( roman_Θ ) = blackboard_E start_POSTSUBSCRIPT bold_italic_x ∼ caligraphic_D start_POSTSUBSCRIPT PT end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ - ∑ start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT roman_log italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ; roman_Θ ) ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS4.p1.6">여기서, <math alttext="\Theta" class="ltx_Math" display="inline" id="S2.SS4.p1.3.m1.1"><semantics id="S2.SS4.p1.3.m1.1a"><mi id="S2.SS4.p1.3.m1.1.1" mathvariant="normal" xref="S2.SS4.p1.3.m1.1.1.cmml">Θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.3.m1.1b"><ci id="S2.SS4.p1.3.m1.1.1.cmml" xref="S2.SS4.p1.3.m1.1.1">Θ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.3.m1.1c">\Theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.3.m1.1d">roman_Θ</annotation></semantics></math>는 모델 파라미터를 나타내고, <math alttext="\mathcal{D}_{\textrm{PT}}" class="ltx_Math" display="inline" id="S2.SS4.p1.4.m2.1"><semantics id="S2.SS4.p1.4.m2.1a"><msub id="S2.SS4.p1.4.m2.1.1" xref="S2.SS4.p1.4.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p1.4.m2.1.1.2" xref="S2.SS4.p1.4.m2.1.1.2.cmml">𝒟</mi><mtext id="S2.SS4.p1.4.m2.1.1.3" xref="S2.SS4.p1.4.m2.1.1.3a.cmml">PT</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.4.m2.1b"><apply id="S2.SS4.p1.4.m2.1.1.cmml" xref="S2.SS4.p1.4.m2.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.4.m2.1.1.1.cmml" xref="S2.SS4.p1.4.m2.1.1">subscript</csymbol><ci id="S2.SS4.p1.4.m2.1.1.2.cmml" xref="S2.SS4.p1.4.m2.1.1.2">𝒟</ci><ci id="S2.SS4.p1.4.m2.1.1.3a.cmml" xref="S2.SS4.p1.4.m2.1.1.3"><mtext id="S2.SS4.p1.4.m2.1.1.3.cmml" mathsize="70%" xref="S2.SS4.p1.4.m2.1.1.3">PT</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.4.m2.1c">\mathcal{D}_{\textrm{PT}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.4.m2.1d">caligraphic_D start_POSTSUBSCRIPT PT end_POSTSUBSCRIPT</annotation></semantics></math>는 사전 트레이닝 데이터셋이며, <math alttext="x_{i}" class="ltx_Math" display="inline" id="S2.SS4.p1.5.m3.1"><semantics id="S2.SS4.p1.5.m3.1a"><msub id="S2.SS4.p1.5.m3.1.1" xref="S2.SS4.p1.5.m3.1.1.cmml"><mi id="S2.SS4.p1.5.m3.1.1.2" xref="S2.SS4.p1.5.m3.1.1.2.cmml">x</mi><mi id="S2.SS4.p1.5.m3.1.1.3" xref="S2.SS4.p1.5.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.5.m3.1b"><apply id="S2.SS4.p1.5.m3.1.1.cmml" xref="S2.SS4.p1.5.m3.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.5.m3.1.1.1.cmml" xref="S2.SS4.p1.5.m3.1.1">subscript</csymbol><ci id="S2.SS4.p1.5.m3.1.1.2.cmml" xref="S2.SS4.p1.5.m3.1.1.2">𝑥</ci><ci id="S2.SS4.p1.5.m3.1.1.3.cmml" xref="S2.SS4.p1.5.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.5.m3.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.5.m3.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>는 예측하고자 하는 토큰이며, <math alttext="x_{0},x_{1},\ldots,x_{i-1}" class="ltx_Math" display="inline" id="S2.SS4.p1.6.m4.4"><semantics id="S2.SS4.p1.6.m4.4a"><mrow id="S2.SS4.p1.6.m4.4.4.3" xref="S2.SS4.p1.6.m4.4.4.4.cmml"><msub id="S2.SS4.p1.6.m4.2.2.1.1" xref="S2.SS4.p1.6.m4.2.2.1.1.cmml"><mi id="S2.SS4.p1.6.m4.2.2.1.1.2" xref="S2.SS4.p1.6.m4.2.2.1.1.2.cmml">x</mi><mn id="S2.SS4.p1.6.m4.2.2.1.1.3" xref="S2.SS4.p1.6.m4.2.2.1.1.3.cmml">0</mn></msub><mo id="S2.SS4.p1.6.m4.4.4.3.4" xref="S2.SS4.p1.6.m4.4.4.4.cmml">,</mo><msub id="S2.SS4.p1.6.m4.3.3.2.2" xref="S2.SS4.p1.6.m4.3.3.2.2.cmml"><mi id="S2.SS4.p1.6.m4.3.3.2.2.2" xref="S2.SS4.p1.6.m4.3.3.2.2.2.cmml">x</mi><mn id="S2.SS4.p1.6.m4.3.3.2.2.3" xref="S2.SS4.p1.6.m4.3.3.2.2.3.cmml">1</mn></msub><mo id="S2.SS4.p1.6.m4.4.4.3.5" xref="S2.SS4.p1.6.m4.4.4.4.cmml">,</mo><mi id="S2.SS4.p1.6.m4.1.1" mathvariant="normal" xref="S2.SS4.p1.6.m4.1.1.cmml">…</mi><mo id="S2.SS4.p1.6.m4.4.4.3.6" xref="S2.SS4.p1.6.m4.4.4.4.cmml">,</mo><msub id="S2.SS4.p1.6.m4.4.4.3.3" xref="S2.SS4.p1.6.m4.4.4.3.3.cmml"><mi id="S2.SS4.p1.6.m4.4.4.3.3.2" xref="S2.SS4.p1.6.m4.4.4.3.3.2.cmml">x</mi><mrow id="S2.SS4.p1.6.m4.4.4.3.3.3" xref="S2.SS4.p1.6.m4.4.4.3.3.3.cmml"><mi id="S2.SS4.p1.6.m4.4.4.3.3.3.2" xref="S2.SS4.p1.6.m4.4.4.3.3.3.2.cmml">i</mi><mo id="S2.SS4.p1.6.m4.4.4.3.3.3.1" xref="S2.SS4.p1.6.m4.4.4.3.3.3.1.cmml">−</mo><mn id="S2.SS4.p1.6.m4.4.4.3.3.3.3" xref="S2.SS4.p1.6.m4.4.4.3.3.3.3.cmml">1</mn></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.6.m4.4b"><list id="S2.SS4.p1.6.m4.4.4.4.cmml" xref="S2.SS4.p1.6.m4.4.4.3"><apply id="S2.SS4.p1.6.m4.2.2.1.1.cmml" xref="S2.SS4.p1.6.m4.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.6.m4.2.2.1.1.1.cmml" xref="S2.SS4.p1.6.m4.2.2.1.1">subscript</csymbol><ci id="S2.SS4.p1.6.m4.2.2.1.1.2.cmml" xref="S2.SS4.p1.6.m4.2.2.1.1.2">𝑥</ci><cn id="S2.SS4.p1.6.m4.2.2.1.1.3.cmml" type="integer" xref="S2.SS4.p1.6.m4.2.2.1.1.3">0</cn></apply><apply id="S2.SS4.p1.6.m4.3.3.2.2.cmml" xref="S2.SS4.p1.6.m4.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS4.p1.6.m4.3.3.2.2.1.cmml" xref="S2.SS4.p1.6.m4.3.3.2.2">subscript</csymbol><ci id="S2.SS4.p1.6.m4.3.3.2.2.2.cmml" xref="S2.SS4.p1.6.m4.3.3.2.2.2">𝑥</ci><cn id="S2.SS4.p1.6.m4.3.3.2.2.3.cmml" type="integer" xref="S2.SS4.p1.6.m4.3.3.2.2.3">1</cn></apply><ci id="S2.SS4.p1.6.m4.1.1.cmml" xref="S2.SS4.p1.6.m4.1.1">…</ci><apply id="S2.SS4.p1.6.m4.4.4.3.3.cmml" xref="S2.SS4.p1.6.m4.4.4.3.3"><csymbol cd="ambiguous" id="S2.SS4.p1.6.m4.4.4.3.3.1.cmml" xref="S2.SS4.p1.6.m4.4.4.3.3">subscript</csymbol><ci id="S2.SS4.p1.6.m4.4.4.3.3.2.cmml" xref="S2.SS4.p1.6.m4.4.4.3.3.2">𝑥</ci><apply id="S2.SS4.p1.6.m4.4.4.3.3.3.cmml" xref="S2.SS4.p1.6.m4.4.4.3.3.3"><minus id="S2.SS4.p1.6.m4.4.4.3.3.3.1.cmml" xref="S2.SS4.p1.6.m4.4.4.3.3.3.1"></minus><ci id="S2.SS4.p1.6.m4.4.4.3.3.3.2.cmml" xref="S2.SS4.p1.6.m4.4.4.3.3.3.2">𝑖</ci><cn id="S2.SS4.p1.6.m4.4.4.3.3.3.3.cmml" type="integer" xref="S2.SS4.p1.6.m4.4.4.3.3.3.3">1</cn></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.6.m4.4c">x_{0},x_{1},\ldots,x_{i-1}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.6.m4.4d">italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT</annotation></semantics></math>는 컨텍스트를 구성한다.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5 </span>Supervised Fine-Tuning and Chinese Alpaca</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS5.p1">
<p class="ltx_p" id="S2.SS5.p1.1">사전 훈련된 언어 모델은 사용자 지시를 거의 따를 수 없고 종종 의도하지 않은 콘텐츠를 생성할 수 있다. 이는 수학식 (<a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S2.E2" title="2 ‣ 2.4 Pre-Training Objective ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">2</span></a>)의 언어 모델링 목적이 “명령어에 따라 질문에 답하기”가 아니라 다음 토큰을 예측하고 있기 때문이다. <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib19" title="">2022</a>)</cite>. 언어 모델의 행동을 사용자의 의도에 맞게 조정하기 위해 모델을 미세 조정하여 지시 사항을 따르도록 명시적으로 훈련시킬 수 있다. Stanford Alpaca <cite class="ltx_cite ltx_citemacro_citep">(Taori et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib27" title="">2023b</a>)</cite>는 Self-Instruct <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib31" title="">2022</a>)</cite>에서의 기법들에 의해 생성된 52K instruction-following 데이터에 대해 학습된 LLaMA 기반 instruction-following 모델이다. 우리는 스탠포드 알파카의 접근법을 따라 중국 LLaMA에 자기 지시 미세 조정을 적용하여 지시 후속 모델인 중국 알파카를 훈련한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS5.p2">
<p class="ltx_p" id="S2.SS5.p2.1">중국 알파카는 명령어 후속 데이터 세트의 조합으로 훈련된다. 데이터 세트의 각 예는 명령어와 출력으로 구성된다. 감독된 미세 조정 태스크는 인과 언어 모델링 태스크와 유사하다: 모델은 명령으로 프롬프트되고 출력을 자동으로 생성하도록 트레이닝된다. 명령은 프롬프트 템플릿으로 래핑되며 출력은 템플릿에 즉시 따라갑니다. 미세 조정 및 추론을 위해 스탠포드 알파카의 다음 템플릿을 채택하며 입력 시퀀스는 다음과 같습니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS5.p3">
<blockquote class="ltx_quote" id="S2.SS5.p3.1">
<p class="ltx_p" id="S2.SS5.p3.1.1"><span class="ltx_text ltx_font_italic" id="S2.SS5.p3.1.1.1">아래는 작업을 설명하는 명령입니다. 요청을 적절하게 완료하는 응답을 작성합니다. </span></p>
<br class="ltx_break">
<br class="ltx_break">### Instruction:

<br class="ltx_break"></span>{<span class="ltx_text ltx_font_italic" id="S2.SS5.p3.1.1.2">instruction</span>}<span class="ltx_text ltx_font_italic" id="S2.SS5.p3.1.1.3">
<br class="ltx_break">
<br class="ltx_break">### Response: </span>{<span class="ltx_text ltx_font_italic" id="S2.SS5.p3.1.1.4">output</span>}<span class="ltx_text ltx_font_italic" id="S2.SS5.p3.1.1.5">
</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</blockquote>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS5.p4">
<p class="ltx_p" id="S2.SS5.p4.4">손실은 입력 시퀀스의 <em class="ltx_emph ltx_font_italic" id="S2.SS5.p4.4.1"><span class="ltx_text ltx_font_upright" id="S2.SS5.p4.4.1.1">{</span>output<span class="ltx_text ltx_font_upright" id="S2.SS5.p4.4.1.2">}</span></em> 부분에서만 계산되며 다음과 같이 나타낼 수 있다.</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A1.EGx2">
<tbody id="S2.E3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}_{\textrm{SFT}}(\Theta)=\mathbb{E}_{\bm{x}\sim\mathcal%
{D}_{\textrm{SFT}}}\left[-\sum_{i\in\textit{\{output\}}}\log p(x_{i}|x_{0},x_{%
1},\ldots,x_{i-1};\Theta)\right]" class="ltx_Math" display="inline" id="S2.E3.m1.4"><semantics id="S2.E3.m1.4a"><mrow id="S2.E3.m1.4.4" xref="S2.E3.m1.4.4.cmml"><mrow id="S2.E3.m1.4.4.3" xref="S2.E3.m1.4.4.3.cmml"><msub id="S2.E3.m1.4.4.3.2" xref="S2.E3.m1.4.4.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.4.4.3.2.2" xref="S2.E3.m1.4.4.3.2.2.cmml">ℒ</mi><mtext id="S2.E3.m1.4.4.3.2.3" xref="S2.E3.m1.4.4.3.2.3a.cmml">SFT</mtext></msub><mo id="S2.E3.m1.4.4.3.1" xref="S2.E3.m1.4.4.3.1.cmml">⁢</mo><mrow id="S2.E3.m1.4.4.3.3.2" xref="S2.E3.m1.4.4.3.cmml"><mo id="S2.E3.m1.4.4.3.3.2.1" stretchy="false" xref="S2.E3.m1.4.4.3.cmml">(</mo><mi id="S2.E3.m1.1.1" mathvariant="normal" xref="S2.E3.m1.1.1.cmml">Θ</mi><mo id="S2.E3.m1.4.4.3.3.2.2" stretchy="false" xref="S2.E3.m1.4.4.3.cmml">)</mo></mrow></mrow><mo id="S2.E3.m1.4.4.2" xref="S2.E3.m1.4.4.2.cmml">=</mo><mrow id="S2.E3.m1.4.4.1" xref="S2.E3.m1.4.4.1.cmml"><msub id="S2.E3.m1.4.4.1.3" xref="S2.E3.m1.4.4.1.3.cmml"><mi id="S2.E3.m1.4.4.1.3.2" xref="S2.E3.m1.4.4.1.3.2.cmml">𝔼</mi><mrow id="S2.E3.m1.4.4.1.3.3" xref="S2.E3.m1.4.4.1.3.3.cmml"><mi id="S2.E3.m1.4.4.1.3.3.2" xref="S2.E3.m1.4.4.1.3.3.2.cmml">𝒙</mi><mo id="S2.E3.m1.4.4.1.3.3.1" xref="S2.E3.m1.4.4.1.3.3.1.cmml">∼</mo><msub id="S2.E3.m1.4.4.1.3.3.3" xref="S2.E3.m1.4.4.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.4.4.1.3.3.3.2" xref="S2.E3.m1.4.4.1.3.3.3.2.cmml">𝒟</mi><mtext id="S2.E3.m1.4.4.1.3.3.3.3" xref="S2.E3.m1.4.4.1.3.3.3.3a.cmml">SFT</mtext></msub></mrow></msub><mo id="S2.E3.m1.4.4.1.2" xref="S2.E3.m1.4.4.1.2.cmml">⁢</mo><mrow id="S2.E3.m1.4.4.1.1.1" xref="S2.E3.m1.4.4.1.1.2.cmml"><mo id="S2.E3.m1.4.4.1.1.1.2" xref="S2.E3.m1.4.4.1.1.2.1.cmml">[</mo><mrow id="S2.E3.m1.4.4.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.cmml"><mo id="S2.E3.m1.4.4.1.1.1.1a" xref="S2.E3.m1.4.4.1.1.1.1.cmml">−</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.cmml"><mstyle displaystyle="true" id="S2.E3.m1.4.4.1.1.1.1.1.2" xref="S2.E3.m1.4.4.1.1.1.1.1.2.cmml"><munder id="S2.E3.m1.4.4.1.1.1.1.1.2a" xref="S2.E3.m1.4.4.1.1.1.1.1.2.cmml"><mo id="S2.E3.m1.4.4.1.1.1.1.1.2.2" movablelimits="false" xref="S2.E3.m1.4.4.1.1.1.1.1.2.2.cmml">∑</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1.2.3" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.2.3.2" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.2.cmml">i</mi><mo id="S2.E3.m1.4.4.1.1.1.1.1.2.3.1" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.1.cmml">∈</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3d.cmml"><mtext id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3a" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3d.cmml">{</mtext><mtext id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3b" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3d.cmml">𝑜𝑢𝑡𝑝𝑢𝑡</mtext><mtext id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3c" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3d.cmml">}</mtext></mrow></mrow></munder></mstyle><mrow id="S2.E3.m1.4.4.1.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.cmml"><mrow id="S2.E3.m1.4.4.1.1.1.1.1.1.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.3.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3.1.cmml">log</mi><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.3a" lspace="0.167em" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3.cmml">⁡</mo><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.3.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3.2.cmml">p</mi></mrow><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.2.cmml">x</mi><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.3.cmml">i</mi></msub><mo fence="false" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.4" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.4.cmml">|</mo><mrow id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml"><msub id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mn id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">0</mn></msub><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.4" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml">x</mi><mn id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">1</mn></msub><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.5" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">,</mo><mi id="S2.E3.m1.2.2" mathvariant="normal" xref="S2.E3.m1.2.2.cmml">…</mi><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.6" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">,</mo><msub id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2.cmml">x</mi><mrow id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml"><mi id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2.cmml">i</mi><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1.cmml">−</mo><mn id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3.cmml">1</mn></mrow></msub><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.7" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml">;</mo><mi id="S2.E3.m1.3.3" mathvariant="normal" xref="S2.E3.m1.3.3.cmml">Θ</mi></mrow></mrow><mo id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E3.m1.4.4.1.1.1.3" xref="S2.E3.m1.4.4.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.4b"><apply id="S2.E3.m1.4.4.cmml" xref="S2.E3.m1.4.4"><eq id="S2.E3.m1.4.4.2.cmml" xref="S2.E3.m1.4.4.2"></eq><apply id="S2.E3.m1.4.4.3.cmml" xref="S2.E3.m1.4.4.3"><times id="S2.E3.m1.4.4.3.1.cmml" xref="S2.E3.m1.4.4.3.1"></times><apply id="S2.E3.m1.4.4.3.2.cmml" xref="S2.E3.m1.4.4.3.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.3.2.1.cmml" xref="S2.E3.m1.4.4.3.2">subscript</csymbol><ci id="S2.E3.m1.4.4.3.2.2.cmml" xref="S2.E3.m1.4.4.3.2.2">ℒ</ci><ci id="S2.E3.m1.4.4.3.2.3a.cmml" xref="S2.E3.m1.4.4.3.2.3"><mtext id="S2.E3.m1.4.4.3.2.3.cmml" mathsize="70%" xref="S2.E3.m1.4.4.3.2.3">SFT</mtext></ci></apply><ci id="S2.E3.m1.1.1.cmml" xref="S2.E3.m1.1.1">Θ</ci></apply><apply id="S2.E3.m1.4.4.1.cmml" xref="S2.E3.m1.4.4.1"><times id="S2.E3.m1.4.4.1.2.cmml" xref="S2.E3.m1.4.4.1.2"></times><apply id="S2.E3.m1.4.4.1.3.cmml" xref="S2.E3.m1.4.4.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.3.1.cmml" xref="S2.E3.m1.4.4.1.3">subscript</csymbol><ci id="S2.E3.m1.4.4.1.3.2.cmml" xref="S2.E3.m1.4.4.1.3.2">𝔼</ci><apply id="S2.E3.m1.4.4.1.3.3.cmml" xref="S2.E3.m1.4.4.1.3.3"><csymbol cd="latexml" id="S2.E3.m1.4.4.1.3.3.1.cmml" xref="S2.E3.m1.4.4.1.3.3.1">similar-to</csymbol><ci id="S2.E3.m1.4.4.1.3.3.2.cmml" xref="S2.E3.m1.4.4.1.3.3.2">𝒙</ci><apply id="S2.E3.m1.4.4.1.3.3.3.cmml" xref="S2.E3.m1.4.4.1.3.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.3.3.3.1.cmml" xref="S2.E3.m1.4.4.1.3.3.3">subscript</csymbol><ci id="S2.E3.m1.4.4.1.3.3.3.2.cmml" xref="S2.E3.m1.4.4.1.3.3.3.2">𝒟</ci><ci id="S2.E3.m1.4.4.1.3.3.3.3a.cmml" xref="S2.E3.m1.4.4.1.3.3.3.3"><mtext id="S2.E3.m1.4.4.1.3.3.3.3.cmml" mathsize="50%" xref="S2.E3.m1.4.4.1.3.3.3.3">SFT</mtext></ci></apply></apply></apply><apply id="S2.E3.m1.4.4.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.4.4.1.1.2.1.cmml" xref="S2.E3.m1.4.4.1.1.1.2">delimited-[]</csymbol><apply id="S2.E3.m1.4.4.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1"><minus id="S2.E3.m1.4.4.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1"></minus><apply id="S2.E3.m1.4.4.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1"><apply id="S2.E3.m1.4.4.1.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2">subscript</csymbol><sum id="S2.E3.m1.4.4.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.2"></sum><apply id="S2.E3.m1.4.4.1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3"><in id="S2.E3.m1.4.4.1.1.1.1.1.2.3.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.1"></in><ci id="S2.E3.m1.4.4.1.1.1.1.1.2.3.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.2">𝑖</ci><ci id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3d.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3"><mrow id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3"><mtext id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3a.cmml" mathsize="70%" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3">{</mtext><mtext id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3b.cmml" mathsize="70%" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3">𝑜𝑢𝑡𝑝𝑢𝑡</mtext><mtext id="S2.E3.m1.4.4.1.1.1.1.1.2.3.3c.cmml" mathsize="70%" xref="S2.E3.m1.4.4.1.1.1.1.1.2.3.3">}</mtext></mrow></ci></apply></apply><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1"><times id="S2.E3.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.2"></times><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3"><log id="S2.E3.m1.4.4.1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3.1"></log><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.3.2">𝑝</ci></apply><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.4.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.4">conditional</csymbol><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.2">𝑥</ci><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.5.3">𝑖</ci></apply><list id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.4.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3"><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><cn id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.1.1.1.3">0</cn></apply><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.2">𝑥</ci><cn id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" type="integer" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.2.2.2.3">1</cn></apply><ci id="S2.E3.m1.2.2.cmml" xref="S2.E3.m1.2.2">…</ci><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3">subscript</csymbol><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.2">𝑥</ci><apply id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3"><minus id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.1"></minus><ci id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2.cmml" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.2">𝑖</ci><cn id="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3.cmml" type="integer" xref="S2.E3.m1.4.4.1.1.1.1.1.1.1.1.1.3.3.3.3.3">1</cn></apply></apply><ci id="S2.E3.m1.3.3.cmml" xref="S2.E3.m1.3.3">Θ</ci></list></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.4c">\displaystyle\mathcal{L}_{\textrm{SFT}}(\Theta)=\mathbb{E}_{\bm{x}\sim\mathcal%
{D}_{\textrm{SFT}}}\left[-\sum_{i\in\textit{\{output\}}}\log p(x_{i}|x_{0},x_{%
1},\ldots,x_{i-1};\Theta)\right]</annotation><annotation encoding="application/x-llamapun" id="S2.E3.m1.4d">caligraphic_L start_POSTSUBSCRIPT SFT end_POSTSUBSCRIPT ( roman_Θ ) = blackboard_E start_POSTSUBSCRIPT bold_italic_x ∼ caligraphic_D start_POSTSUBSCRIPT SFT end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ - ∑ start_POSTSUBSCRIPT italic_i ∈ { output } end_POSTSUBSCRIPT roman_log italic_p ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_i - 1 end_POSTSUBSCRIPT ; roman_Θ ) ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS5.p4.3">여기서, <math alttext="\Theta" class="ltx_Math" display="inline" id="S2.SS5.p4.1.m1.1"><semantics id="S2.SS5.p4.1.m1.1a"><mi id="S2.SS5.p4.1.m1.1.1" mathvariant="normal" xref="S2.SS5.p4.1.m1.1.1.cmml">Θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS5.p4.1.m1.1b"><ci id="S2.SS5.p4.1.m1.1.1.cmml" xref="S2.SS5.p4.1.m1.1.1">Θ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p4.1.m1.1c">\Theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS5.p4.1.m1.1d">roman_Θ</annotation></semantics></math>는 모델 파라미터를 나타내고, <math alttext="\mathcal{D}_{\textrm{SFT}}" class="ltx_Math" display="inline" id="S2.SS5.p4.2.m2.1"><semantics id="S2.SS5.p4.2.m2.1a"><msub id="S2.SS5.p4.2.m2.1.1" xref="S2.SS5.p4.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS5.p4.2.m2.1.1.2" xref="S2.SS5.p4.2.m2.1.1.2.cmml">𝒟</mi><mtext id="S2.SS5.p4.2.m2.1.1.3" xref="S2.SS5.p4.2.m2.1.1.3a.cmml">SFT</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS5.p4.2.m2.1b"><apply id="S2.SS5.p4.2.m2.1.1.cmml" xref="S2.SS5.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS5.p4.2.m2.1.1.1.cmml" xref="S2.SS5.p4.2.m2.1.1">subscript</csymbol><ci id="S2.SS5.p4.2.m2.1.1.2.cmml" xref="S2.SS5.p4.2.m2.1.1.2">𝒟</ci><ci id="S2.SS5.p4.2.m2.1.1.3a.cmml" xref="S2.SS5.p4.2.m2.1.1.3"><mtext id="S2.SS5.p4.2.m2.1.1.3.cmml" mathsize="70%" xref="S2.SS5.p4.2.m2.1.1.3">SFT</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p4.2.m2.1c">\mathcal{D}_{\textrm{SFT}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS5.p4.2.m2.1d">caligraphic_D start_POSTSUBSCRIPT SFT end_POSTSUBSCRIPT</annotation></semantics></math>는 미세 조정 데이터셋이며, <math alttext="\bm{x}=(x_{0},x_{1},\ldots)" class="ltx_Math" display="inline" id="S2.SS5.p4.3.m3.3"><semantics id="S2.SS5.p4.3.m3.3a"><mrow id="S2.SS5.p4.3.m3.3.3" xref="S2.SS5.p4.3.m3.3.3.cmml"><mi id="S2.SS5.p4.3.m3.3.3.4" xref="S2.SS5.p4.3.m3.3.3.4.cmml">𝒙</mi><mo id="S2.SS5.p4.3.m3.3.3.3" xref="S2.SS5.p4.3.m3.3.3.3.cmml">=</mo><mrow id="S2.SS5.p4.3.m3.3.3.2.2" xref="S2.SS5.p4.3.m3.3.3.2.3.cmml"><mo id="S2.SS5.p4.3.m3.3.3.2.2.3" stretchy="false" xref="S2.SS5.p4.3.m3.3.3.2.3.cmml">(</mo><msub id="S2.SS5.p4.3.m3.2.2.1.1.1" xref="S2.SS5.p4.3.m3.2.2.1.1.1.cmml"><mi id="S2.SS5.p4.3.m3.2.2.1.1.1.2" xref="S2.SS5.p4.3.m3.2.2.1.1.1.2.cmml">x</mi><mn id="S2.SS5.p4.3.m3.2.2.1.1.1.3" xref="S2.SS5.p4.3.m3.2.2.1.1.1.3.cmml">0</mn></msub><mo id="S2.SS5.p4.3.m3.3.3.2.2.4" xref="S2.SS5.p4.3.m3.3.3.2.3.cmml">,</mo><msub id="S2.SS5.p4.3.m3.3.3.2.2.2" xref="S2.SS5.p4.3.m3.3.3.2.2.2.cmml"><mi id="S2.SS5.p4.3.m3.3.3.2.2.2.2" xref="S2.SS5.p4.3.m3.3.3.2.2.2.2.cmml">x</mi><mn id="S2.SS5.p4.3.m3.3.3.2.2.2.3" xref="S2.SS5.p4.3.m3.3.3.2.2.2.3.cmml">1</mn></msub><mo id="S2.SS5.p4.3.m3.3.3.2.2.5" xref="S2.SS5.p4.3.m3.3.3.2.3.cmml">,</mo><mi id="S2.SS5.p4.3.m3.1.1" mathvariant="normal" xref="S2.SS5.p4.3.m3.1.1.cmml">…</mi><mo id="S2.SS5.p4.3.m3.3.3.2.2.6" stretchy="false" xref="S2.SS5.p4.3.m3.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS5.p4.3.m3.3b"><apply id="S2.SS5.p4.3.m3.3.3.cmml" xref="S2.SS5.p4.3.m3.3.3"><eq id="S2.SS5.p4.3.m3.3.3.3.cmml" xref="S2.SS5.p4.3.m3.3.3.3"></eq><ci id="S2.SS5.p4.3.m3.3.3.4.cmml" xref="S2.SS5.p4.3.m3.3.3.4">𝒙</ci><vector id="S2.SS5.p4.3.m3.3.3.2.3.cmml" xref="S2.SS5.p4.3.m3.3.3.2.2"><apply id="S2.SS5.p4.3.m3.2.2.1.1.1.cmml" xref="S2.SS5.p4.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS5.p4.3.m3.2.2.1.1.1.1.cmml" xref="S2.SS5.p4.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S2.SS5.p4.3.m3.2.2.1.1.1.2.cmml" xref="S2.SS5.p4.3.m3.2.2.1.1.1.2">𝑥</ci><cn id="S2.SS5.p4.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS5.p4.3.m3.2.2.1.1.1.3">0</cn></apply><apply id="S2.SS5.p4.3.m3.3.3.2.2.2.cmml" xref="S2.SS5.p4.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS5.p4.3.m3.3.3.2.2.2.1.cmml" xref="S2.SS5.p4.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S2.SS5.p4.3.m3.3.3.2.2.2.2.cmml" xref="S2.SS5.p4.3.m3.3.3.2.2.2.2">𝑥</ci><cn id="S2.SS5.p4.3.m3.3.3.2.2.2.3.cmml" type="integer" xref="S2.SS5.p4.3.m3.3.3.2.2.2.3">1</cn></apply><ci id="S2.SS5.p4.3.m3.1.1.cmml" xref="S2.SS5.p4.3.m3.1.1">…</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS5.p4.3.m3.3c">\bm{x}=(x_{0},x_{1},\ldots)</annotation><annotation encoding="application/x-llamapun" id="S2.SS5.p4.3.m3.3d">bold_italic_x = ( italic_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … )</annotation></semantics></math>는 토큰화된 입력 시퀀스를 나타낸다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS5.p5">
<p class="ltx_p" id="S2.SS5.p5.1">우리의 접근법과 Stanford Alpaca의 주요 차이점은 <em class="ltx_emph ltx_font_italic" id="S2.SS5.p5.1.1">input</em> 필드가 없는 예제에 대해 설계된 프롬프트 템플릿만 사용하는 반면, Stanford Alpaca는 <em class="ltx_emph ltx_font_italic" id="S2.SS5.p5.1.2">input</em> 필드가 있거나 없는 예제에 대해 두 개의 템플릿을 사용한다는 것입니다. 예제가 비어 있지 않은 <em class="ltx_emph ltx_font_italic" id="S2.SS5.p5.1.3">input</em> 필드를 포함하는 경우, <em class="ltx_emph ltx_font_italic" id="S2.SS5.p5.1.4">instruction</em> 및 <em class="ltx_emph ltx_font_italic" id="S2.SS5.p5.1.5">input</em>을 <em class="ltx_emph ltx_font_italic" id="S2.SS5.p5.1.6">“\n”</em>과 연결하여 새 명령을 형성합니다. 중국어 알파카 모델에 대한 추가 패딩 토큰이 있어 어휘 크기가 49,954가 된다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Experimental Setups</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Experimental Setups for Pre-training</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">우리는 원래 LLaMA 가중치로 중국 LLaMA 모델을 초기화하고 7B 및 13B 모델에서 fp16을 사용하여 사전 훈련을 수행한다. 또한, 33B 모델의 경우 8비트 포맷으로 학습하기 위해 bitsandbytes<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/TimDettmers/bitsandbytes" title="">https://github.com/TimDettmers/bitsandbytes</a></span></span></span> 라이브러리를 사용하여 효율성과 메모리 사용량을 향상시켰다. 우리는 임베딩과 LM 헤드를 훈련 가능한 것으로 설정하면서 훈련을 위해 관심 및 MLP에 LoRA를 직접 적용한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">중국 LLaMA-7B의 기본 버전을 위해 2단계 사전 훈련 접근법을 사용한다. 1단계에서는 모델 내에서 변압기 인코더의 파라미터를 고정하고 임베딩만을 훈련하여 외란을 최소화하면서 새로 추가된 한자어 벡터를 원래 모델에 적용한다. 2단계에서는 주의 메커니즘에 LoRA 가중치(어댑터)를 추가하고 임베딩, LM 헤드 및 새로 추가된 LoRA 매개변수를 훈련한다. 2단계 훈련은 예비 연구에서 덜 효율적이기 때문에 다른 모델 훈련에는 적용되지 않는다.</p>
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">다른 중국어 LLaMA 모델(기본 버전)의 경우, 사전 트레이닝을 위해 20GB 일반 중국어 코퍼스를 활용하는데, 이는 중국어 BERT-wwm <cite class="ltx_cite ltx_citemacro_citep">(Cui et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib4" title="">2021</a>)</cite>, MacBERT <cite class="ltx_cite ltx_citemacro_citep">(Cui et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib3" title="">2020</a>)</cite>, LERT <cite class="ltx_cite ltx_citemacro_citep">(Cui et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib5" title="">2022</a>)</cite>, 기타에서 사용하는 코퍼스와 일치한다. 또한 커먼크롤(CC) 및 백과사전 소스의 추가 데이터를 통합하여 기본 개념에 대한 모델의 이해를 향상시키는 사전 학습 데이터를 120GB로 추가로 확장하는 "플러스" 버전을 제공한다. 사전 훈련을 위해 모든 데이터 세트와 블록 크기 512의 청크를 연결했다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1">모델은 A40 GPU(48GB VRAM)에서 하나의 에포크 동안 훈련되며, 모델 크기에 따라 최대 48개의 GPU를 차지한다. LoRA를 사용한 파라미터 효율적인 훈련은 PEFT 라이브러리<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/huggingface/peft" title="">https://github.com/huggingface/peft</a></span></span></span>로 수행된다. 또한 DeepSpeed <cite class="ltx_cite ltx_citemacro_citep">(Rasley et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib22" title="">2020</a>)</cite>를 활용하여 학습 과정에서 메모리 효율을 최적화한다. 우리는 AdamW 최적화기 <cite class="ltx_cite ltx_citemacro_citep">(Loshchilov &amp; Hutter, <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib16" title="">2019</a>)</cite>를 사용하여 2e-4 및 5% 웜업 코사인 스케줄러의 피크 학습률을 갖는다. 또한, 전위 기울기 폭발을 완화하기 위해 1.0의 값을 갖는 기울기 클리핑을 적용한다.</p>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1">각 중국 LLaMA 모델에 대한 상세한 하이퍼파라미터는 표 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S3.T2" title="Table 2 ‣ 3.1 Experimental Setups for Pre-training ‣ 3 Experimental Setups ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">2</span></a>에 나열되어 있다.</p>
</div>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span> <span class="ltx_text ltx_font_bold" id="S3.T2.2.1">Pre-training hyperparameters for Chinese LLaMA.</span> QKVO: four matrices in each attention module, i.e., query, key, value, and output. MLP: three matrices in each MLP layer. Note that 7B uses a two-stage training paradigm (settings are separated by ‘/’), which is not further adopted in other models.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T2.3">
<tbody><tr class="ltx_tr" id="S3.T2.3.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T2.3.1.1"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.1.1">Settings</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.1.2"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.2.1">7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.1.3"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.3.1">Plus-7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.1.4"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.4.1">13B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.1.5"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.5.1">Plus-13B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T2.3.1.6"><span class="ltx_text ltx_font_bold" id="S3.T2.3.1.6.1">33B</span></td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T2.3.2.1">Training data</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.2.2">20 GB</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.2.3">120 GB</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.2.4">20 GB</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.2.5">120 GB</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T2.3.2.6">20 GB</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.3">
<td class="ltx_td ltx_align_left" id="S3.T2.3.3.1">Batch size</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.2">1,024</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.3">2,304</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.4">2,304</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.5">2,304</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.3.6">2,304</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.4">
<td class="ltx_td ltx_align_left" id="S3.T2.3.4.1">Peak learning rate</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.4.2">2e-4/1e-4</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.4.3">2e-4</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.4.4">2e-4</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.4.5">2e-4</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.4.6">2e-4</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.5">
<td class="ltx_td ltx_align_left" id="S3.T2.3.5.1">Max sequence length</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.5.2">512</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.5.3">512</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.5.4">512</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.5.5">512</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.5.6">512</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.6">
<td class="ltx_td ltx_align_left" id="S3.T2.3.6.1">LoRA rank</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.6.2">-/8</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.6.3">8</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.6.4">8</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.6.5">8</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.6.6">8</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.7">
<td class="ltx_td ltx_align_left" id="S3.T2.3.7.1">LoRA alpha</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.7.2">-/32</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.7.3">32</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.7.4">32</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.7.5">32</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.7.6">32</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.8">
<td class="ltx_td ltx_align_left" id="S3.T2.3.8.1">LoRA weights</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.8.2">-/QKVO</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.8.3">QKVO, MLP</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.8.4">QKVO, MLP</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.8.5">QKVO, MLP</td>
<td class="ltx_td ltx_align_center" id="S3.T2.3.8.6">QKVO, MLP</td>
</tr>
<tr class="ltx_tr" id="S3.T2.3.9">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T2.3.9.1">Trainable params (%)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.3.9.2">2.97%/6.06%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.3.9.3">6.22%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.3.9.4">4.10%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.3.9.5">4.10%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T2.3.9.6">2.21%</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Experimental Setups for Instruction Fine-tuning</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">중국 LLaMA 모델을 얻은 후 섹션 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S2.SS5" title="2.5 Supervised Fine-Tuning and Chinese Alpaca ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">2.5</span></a>에 따라 미세 조정한다. 우리는 기본 모델의 모든 선형 레이어에 LoRA 모듈을 추가하여 효율적인 미세 조정을 위해 LoRA를 계속 사용한다. 번역 <cite class="ltx_cite ltx_citemacro_citep">(Xu, <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib32" title="">2019</a>)</cite> (550K sampled), pCLUE<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/CLUEbenchmark/pCLUE" title="">https://github.com/CLUEbenchmark/pCLUE</a></span></span></span> (250K sampled, excluding “NLU-like” data), Stanford Alpaca (50K+50K for original and translated one), 및 기본 모델 조정을 위한 크롤링된 SFT 데이터를 포함한다. 플러스 버전의 경우 STEM(과학, 기술, 공학 및 수학) 데이터와 물리, 화학, 생물학, 의학 및 지구과학과 같은 여러 과학 분야를 통합하는 데 중점을 두고 데이터 세트를 약 4M에서 4.3M으로 확장한다. Alpaca-33B의 경우 OASST1 데이터 세트 <cite class="ltx_cite ltx_citemacro_citep">(Köpf et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib12" title="">2023</a>)</cite>를 추가로 추가합니다. 여기서 각 대화에서 첫 번째 쿼리-응답 쌍만 추출하고 <span class="ltx_text ltx_font_typewriter" id="S3.SS2.p1.1.1">gpt-3.5-turbo</span> API를 사용하여 번역하면 대략 20K 데이터(원본 및 번역된 데이터)가 생성됩니다. 우리는 최대 시퀀스 길이를 512로 설정하고 배치에서 최대 길이로 배칭할 때 샘플을 동적으로 패딩한다.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">크롤링된 데이터의 경우, <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib31" title="">2022</a>)</cite> <cite class="ltx_text ltx_font_typewriter" id="S3.SS2.p2.1.1">gpt-3.5-turbo</span> API)에서 사용되는 ChatGPT(<span class="ltx_cite ltx_citemacro_citet">Taori et al. (<a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib26" title="">2023a</a>)</cite>. 구체적으로, 대상 도메인 및 명령 유형에 대한 요구 사항만 있는 시드 작업을 필요로 하지 않는 보다 단순화된 템플릿을 활용한다. 템플릿 및 코드 세부 정보는 GitHub에서 사용할 수 있습니다. <span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ymcui/Chinese-LLaMA-Alpaca/blob/main/scripts/crawl_prompt.py" title="">https://github.com/ymcui/Chinese-LLaMA-Alpaca/blob/main/scripts/crawl_prompt.py</a></span></span></span></p>
</div>
<figure class="ltx_table" id="S3.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span> Instruction fine-tuning hyperparameters for Chinese Alpaca.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S3.T3.1">
<tbody><tr class="ltx_tr" id="S3.T3.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S3.T3.1.1.1"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.1.1">Settings</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.1.1.2"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.2.1">7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.1.1.3"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.3.1">Plus-7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.1.1.4"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.4.1">13B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.1.1.5"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.5.1">Plus-13B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T3.1.1.6"><span class="ltx_text ltx_font_bold" id="S3.T3.1.1.6.1">33B</span></td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S3.T3.1.2.1">Training data</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.2">2M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.3">4M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.4">3M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.5">4.3M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T3.1.2.6">4.3M</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.3">
<td class="ltx_td ltx_align_left" id="S3.T3.1.3.1">Batch size</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.3.2">512</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.3.3">1,152</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.3.4">1,152</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.3.5">1,152</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.3.6">1,152</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.4">
<td class="ltx_td ltx_align_left" id="S3.T3.1.4.1">Peak learning rate</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.2">1e-4</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.3">1e-4</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.4">1e-4</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.5">1e-4</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.4.6">1e-4</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.5">
<td class="ltx_td ltx_align_left" id="S3.T3.1.5.1">Max sequence length</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.2">512</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.3">512</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.4">512</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.5">512</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.5.6">512</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.6">
<td class="ltx_td ltx_align_left" id="S3.T3.1.6.1">LoRA rank</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.6.2">8</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.6.3">64</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.6.4">8</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.6.5">64</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.6.6">8</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.7">
<td class="ltx_td ltx_align_left" id="S3.T3.1.7.1">LoRA alpha</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.2">32</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.3">128</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.4">32</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.5">128</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.7.6">32</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.8">
<td class="ltx_td ltx_align_left" id="S3.T3.1.8.1">LoRA weights</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.2">QKVO, MLP</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.3">QKVO, MLP</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.4">QKVO, MLP</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.5">QKVO, MLP</td>
<td class="ltx_td ltx_align_center" id="S3.T3.1.8.6">QKVO, MLP</td>
</tr>
<tr class="ltx_tr" id="S3.T3.1.9">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S3.T3.1.9.1">Trainable params (%)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.9.2">6.22%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.9.3">8.08%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.9.4">4.10%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.9.5">5.66%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T3.1.9.6">2.21%</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">플러스 버전의 경우 기본 버전에 비해 더 큰 LoRA 순위를 활용합니다. 학습 속도와 배치 크기를 조정하는 것 외에도 사전 훈련 단계에서 사용되는 다른 하이퍼파라미터 및 설정과 일관성을 유지한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1">명령어 미세 조정을 위한 하이퍼파라미터는 표 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S3.T3" title="Table 3 ‣ 3.2 Experimental Setups for Instruction Fine-tuning ‣ 3 Experimental Setups ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">3</span></a>에 나열되어 있다. 모든 알파카 모델은 각각의 LLaMA 모델에 기초하여 트레이닝된다는 점에 유의한다. 예를 들어, 중국 Alpaca-Plus-13B는 중국 LLaMA-Plus-13B로 훈련된다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results on Instruction-Following Tasks</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Task Design and Evaluation Method</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">텍스트 생성 과제의 성능을 평가하는 것은 그 형태의 편차가 크기 때문에 어려울 수 있으며, 이는 텍스트 분류 및 추출적 기계 독해와 같은 자연어 이해 과제와 크게 다르다. GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib18" title="">2023</a>)</cite>를 채점 방법으로 활용하는 이전 작업에 이어 GPT-4를 채택하여 각 샘플에 대해 전체 점수(10점 척도)를 제공하여 인간 평가보다 효율적이다. 그러나 GPT-4는 항상 정확한 점수를 제공하지 않을 수 있으므로 등급에 대한 수동 검사를 수행하고 필요한 경우 조정한다. 수동 검사는 점수가 일관되고 평가되는 모델의 실제 성능을 반영하는지 확인합니다. 다음 프롬프트 템플릿을 사용하여 시스템의 두 출력(여러 시스템으로 조정할 수 있음)을 채점합니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p2">
<blockquote class="ltx_quote" id="S4.SS1.p2.1">
<p class="ltx_p" id="S4.SS1.p2.1.1"><span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.1.1">다음은 두 ChatGPT 유사 시스템의 출력입니다. 각 점수에 대해 10점 척도로 전체 점수를 평가하고 점수를 정당화할 수 있는 설명을 해주십시오. </span></p>
<br class="ltx_break">
Prompt:

<br class="ltx_break">
</span>{<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.1.2">prompt-input</span>}<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.1.3">
<br class="ltx_break">
System1:

<br class="ltx_break">
</span>{<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.1.4">system1-output</span>}<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.1.5">
<br class="ltx_break">
System2:

<br class="ltx_break">
</span>{<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.1.6">system2-output</span>}<span class="ltx_text ltx_font_italic" id="S4.SS1.p2.1.1.7"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</blockquote>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p3">
<p class="ltx_p" id="S4.SS1.p3.1">수작업 검사와 함께 GPT-4를 채점 방법으로 사용하여 다양한 자연어 이해 및 생성 작업에 대한 중국 알파카 모델의 성능을 효과적으로 측정하는 신뢰할 수 있는 평가 프레임워크를 구축한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS1.p4">
<p class="ltx_p" id="S4.SS1.p4.1">우리의 평가 세트는 광범위한 자연어 이해 및 생성 작업에 걸쳐 중국 알파카 모델을 종합적으로 평가하도록 설계되었다. 집합은 질문 응답, 추론, 문학, 엔터테인먼트, 번역, 다중 회전 대화, 코딩 및 윤리 등을 포함한 10가지 별개의 작업을 포함하는 200개의 샘플로 구성된다. 특정 작업에 대한 전체 점수는 해당 작업 내의 모든 샘플에 대한 점수를 합산하고 총계를 100점 척도로 정규화하여 계산된다. 이 접근법은 평가 세트가 다양한 작업에 걸쳐 모델의 능력을 반영하도록 하여 모델의 성능에 대한 균형 있고 강력한 척도를 제공한다.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Experimental Setups for Decoding</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">LLM들의 디코딩 프로세스는 생성된 텍스트의 품질 및 다양성을 결정하는 데 중요한 역할을 한다. 실험에서는 다음과 같은 디코딩 하이퍼파라미터를 사용한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p2">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1">컨텍스트 크기: 텍스트를 생성할 때 모델이 동시에 고려할 수 있는 최대 토큰 수를 결정하는 컨텍스트 크기를 2048로 설정합니다.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1">최대 시퀀스 길이: 생성된 시퀀스 길이를 512 토큰으로 제한하여 출력들이 포커스를 유지하고 입력 프롬프트와 관련되도록 한다.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1">온도: 샘플링 과정의 무작위성을 제어하는 온도를 0.2로 설정했다. 낮은 값은 모델이 더 집중되고 결정론적 출력을 생성하도록 만드는 반면, 높은 값은 일관성의 비용으로 다양성을 증가시킨다. 멀티턴 대화 및 생성 작업의 경우 온도를 0.5로 약간 조정하여 보다 다양한 출력을 허용한다.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.3">Top-<math alttext="k" class="ltx_Math" display="inline" id="S4.I1.i4.p1.1.m1.1"><semantics id="S4.I1.i4.p1.1.m1.1a"><mi id="S4.I1.i4.p1.1.m1.1.1" xref="S4.I1.i4.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.1.m1.1b"><ci id="S4.I1.i4.p1.1.m1.1.1.cmml" xref="S4.I1.i4.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i4.p1.1.m1.1d">italic_k</annotation></semantics></math> sampling: Top-<math alttext="k" class="ltx_Math" display="inline" id="S4.I1.i4.p1.2.m2.1"><semantics id="S4.I1.i4.p1.2.m2.1a"><mi id="S4.I1.i4.p1.2.m2.1.1" xref="S4.I1.i4.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.2.m2.1b"><ci id="S4.I1.i4.p1.2.m2.1.1.cmml" xref="S4.I1.i4.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i4.p1.2.m2.1d">italic_k</annotation></semantics></math> sampling with <math alttext="k=40" class="ltx_Math" display="inline" id="S4.I1.i4.p1.3.m3.1"><semantics id="S4.I1.i4.p1.3.m3.1a"><mrow id="S4.I1.i4.p1.3.m3.1.1" xref="S4.I1.i4.p1.3.m3.1.1.cmml"><mi id="S4.I1.i4.p1.3.m3.1.1.2" xref="S4.I1.i4.p1.3.m3.1.1.2.cmml">k</mi><mo id="S4.I1.i4.p1.3.m3.1.1.1" xref="S4.I1.i4.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.I1.i4.p1.3.m3.1.1.3" xref="S4.I1.i4.p1.3.m3.1.1.3.cmml">40</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.3.m3.1b"><apply id="S4.I1.i4.p1.3.m3.1.1.cmml" xref="S4.I1.i4.p1.3.m3.1.1"><eq id="S4.I1.i4.p1.3.m3.1.1.1.cmml" xref="S4.I1.i4.p1.3.m3.1.1.1"></eq><ci id="S4.I1.i4.p1.3.m3.1.1.2.cmml" xref="S4.I1.i4.p1.3.m3.1.1.2">𝑘</ci><cn id="S4.I1.i4.p1.3.m3.1.1.3.cmml" type="integer" xref="S4.I1.i4.p1.3.m3.1.1.3">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.3.m3.1c">k=40</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i4.p1.3.m3.1d">italic_k = 40</annotation></semantics></math>를 사용하여 각 단계에서 모델이 가장 가능성이 높은 상위 40개의 토큰 중에서 다음 토큰을 선택하여 생성된 텍스트에 랜덤성과 다양성의 요소를 추가한다.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.3">Top-<math alttext="p" class="ltx_Math" display="inline" id="S4.I1.i5.p1.1.m1.1"><semantics id="S4.I1.i5.p1.1.m1.1a"><mi id="S4.I1.i5.p1.1.m1.1.1" xref="S4.I1.i5.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i5.p1.1.m1.1b"><ci id="S4.I1.i5.p1.1.m1.1.1.cmml" xref="S4.I1.i5.p1.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i5.p1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i5.p1.1.m1.1d">italic_p</annotation></semantics></math> sampling: 또한 <math alttext="p" class="ltx_Math" display="inline" id="S4.I1.i5.p1.2.m2.1"><semantics id="S4.I1.i5.p1.2.m2.1a"><mi id="S4.I1.i5.p1.2.m2.1.1" xref="S4.I1.i5.p1.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S4.I1.i5.p1.2.m2.1b"><ci id="S4.I1.i5.p1.2.m2.1.1.cmml" xref="S4.I1.i5.p1.2.m2.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i5.p1.2.m2.1c">p</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i5.p1.2.m2.1d">italic_p</annotation></semantics></math> sampling with <math alttext="p=0.9" class="ltx_Math" display="inline" id="S4.I1.i5.p1.3.m3.1"><semantics id="S4.I1.i5.p1.3.m3.1a"><mrow id="S4.I1.i5.p1.3.m3.1.1" xref="S4.I1.i5.p1.3.m3.1.1.cmml"><mi id="S4.I1.i5.p1.3.m3.1.1.2" xref="S4.I1.i5.p1.3.m3.1.1.2.cmml">p</mi><mo id="S4.I1.i5.p1.3.m3.1.1.1" xref="S4.I1.i5.p1.3.m3.1.1.1.cmml">=</mo><mn id="S4.I1.i5.p1.3.m3.1.1.3" xref="S4.I1.i5.p1.3.m3.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.I1.i5.p1.3.m3.1b"><apply id="S4.I1.i5.p1.3.m3.1.1.cmml" xref="S4.I1.i5.p1.3.m3.1.1"><eq id="S4.I1.i5.p1.3.m3.1.1.1.cmml" xref="S4.I1.i5.p1.3.m3.1.1.1"></eq><ci id="S4.I1.i5.p1.3.m3.1.1.2.cmml" xref="S4.I1.i5.p1.3.m3.1.1.2">𝑝</ci><cn id="S4.I1.i5.p1.3.m3.1.1.3.cmml" type="float" xref="S4.I1.i5.p1.3.m3.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i5.p1.3.m3.1c">p=0.9</annotation><annotation encoding="application/x-llamapun" id="S4.I1.i5.p1.3.m3.1d">italic_p = 0.9</annotation></semantics></math>를 채용하는데, 이는 확률 질량의 90%를 집합적으로 차지하는 토큰들의 동적 집합을 고려함으로써 다이버시티를 더욱 향상시킨다.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S4.I1.i6.p1">
<p class="ltx_p" id="S4.I1.i6.p1.1">반복 패널티: 모델이 반복적인 텍스트를 생성하지 않도록 하기 위해, 우리는 이미 선택된 토큰에 벌점을 부여하는 1.1의 팩터를 갖는 반복 패널티를 적용한다.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">이러한 값은 각 테스트 시나리오에 최적이 아닐 수 있습니다. 균형 잡힌 뷰를 유지하기 위해 각 작업에 대해 이러한 하이퍼파라미터에 대한 추가 튜닝을 수행하지 않았다.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Results</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">중국 Alpaca-Plus-7B, Alpaca-Plus-13B 및 Alpaca-33B 모델로 얻은 결과를 제시하고 분석한다. Alpaca-33B 결과는 원래 모델(FP16)에 의해 생성되며, Alpaca-Plus-7B와 Alpaca-Plus-13B는 8비트 양자화 버전을 채택한다. <span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>We will discuss the quantization effect in Section <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S6" title="6 Effect of Different Quantization Methods ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">6</span></a>.</span></span></span> 전체적인 결과를 표 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S4.T4" title="Table 4 ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">4</span></a>에 나타내었다. 평가는 총 200개의 샘플을 포함하는 10개의 별개의 NLP 작업에 걸쳐 GPT-4 등급 결과를 기반으로 한다. 제시된 점수는 서로만 비교할 수 있지만 시스템을 재구성해야 하는 다른 모델과는 비교할 수 없다는 점에 유의하는 것이 중요하다. 또한, 우리의 모델은 원래 LLaMA에 기반하기 때문에 이러한 관찰은 처음부터 훈련하기보다는 잘 확립된 모델에 기반할 때 더 나은 성능을 달성하는 데 중요한 측면으로 간주될 수 있다. 우리는 몇 가지 주요 범주의 발견에 대해 자세히 설명한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.p2">
<p class="ltx_p" id="S4.SS3.p2.1">우리는 주로 중국-LLaMA와 중국-알파카에 대한 결과를 제시한다. 중국-LLaMA-2 및 중국-Alpaca-2에 대한 결과는 부록 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#A1" title="Appendix A Appendix ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">A</span></a>에 나와 있다.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span> <span class="ltx_text ltx_font_bold" id="S4.T4.2.1">GPT-4 rated results for Chinese Alpaca-Plus-7B and Alpaca-Plus-13B, and Alpaca-33B.</span> Note that the results are only comparable within this model combination.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T4.3">
<tbody><tr class="ltx_tr" id="S4.T4.3.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T4.3.1.1"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.1.1">Task</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.3.1.2"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.2.1">Alpaca-Plus-7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.3.1.3"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.3.1">Alpaca-Plus-13B</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.3.1.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.1.4.1">Alpaca-33B</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.3.2.1">Question Answering</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.2.2">70.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.2.3">79.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.2.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.2.4.1">82.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3">
<td class="ltx_td ltx_align_left" id="S4.T4.3.3.1">Open-ended QA</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.2"><span class="ltx_text ltx_font_bold" id="S4.T4.3.3.2.1">80.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.3">80.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.4">78.5</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.4">
<td class="ltx_td ltx_align_left" id="S4.T4.3.4.1">Numerical Reasoning</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.4.2">51.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.4.3">61.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.4.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.4.4.1">84.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.5">
<td class="ltx_td ltx_align_left" id="S4.T4.3.5.1">Poetry, Literature, Philosophy</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.5.2">78.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.5.3"><span class="ltx_text ltx_font_bold" id="S4.T4.3.5.3.1">81.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.5.4">76.0</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.6">
<td class="ltx_td ltx_align_left" id="S4.T4.3.6.1">Music, Sports, Entertainment</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.6.2">72.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.6.3"><span class="ltx_text ltx_font_bold" id="S4.T4.3.6.3.1">76.8</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.6.4">72.5</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.7">
<td class="ltx_td ltx_align_left" id="S4.T4.3.7.1">Letters and Articles Writing</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.7.2">81.0</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.7.3"><span class="ltx_text ltx_font_bold" id="S4.T4.3.7.3.1">86.5</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.7.4">79.0</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.8">
<td class="ltx_td ltx_align_left" id="S4.T4.3.8.1">Translation</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.8.2">86.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.8.3">89.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.8.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.8.4.1">92.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.9">
<td class="ltx_td ltx_align_left" id="S4.T4.3.9.1">Multi-turn Dialogue</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.9.2">80.3</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.9.3"><span class="ltx_text ltx_font_bold" id="S4.T4.3.9.3.1">81.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.9.4">78.0</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.10">
<td class="ltx_td ltx_align_left" id="S4.T4.3.10.1">Coding</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.10.2">62.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.10.3">67.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.10.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.10.4.1">84.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.11">
<td class="ltx_td ltx_align_left" id="S4.T4.3.11.1">Ethics</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.11.2">89.8</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.11.3">90.5</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.11.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.11.4.1">92.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.12">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T4.3.12.1"><span class="ltx_text ltx_font_bold" id="S4.T4.3.12.1.1">Total</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.3.12.2">75.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.3.12.3">79.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T4.3.12.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.12.4.1">82.0</span></td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsubsection" id="S4.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Multi-turn Dialogue</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS1.p1">
<p class="ltx_p" id="S4.SS3.SSS1.p1.1">ChatGPT의 인상적인 성과 중 하나는 멀티턴 대화 인터페이스로 전달되는 풍부하고 유창한 맥락적 이해 능력이다. 우리가 볼 수 있듯이 플러스 시리즈 모델은 기본 모델에 비해 일관된 개선을 제공하지만 후자의 크기는 형성자의 몇 배이다. 이것은 더 나은 대화 경험을 달성하기 위해 단순히 모델의 파라미터 크기를 확장하는 것보다 더 많은 트레이닝 데이터를 수집하는 것이 훨씬 더 중요하다는 것을 나타낼 수 있다. 특히, 언어적 지식이 직접적으로 전달될 수 없는 LLaMA 원본으로부터 모델을 구축한다.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Text Generation</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS2.p1">
<p class="ltx_p" id="S4.SS3.SSS2.p1.1">텍스트 생성은 언어 모델을 위한 가장 기본적인 능력 중 하나이다. Alpaca-Plus-7B 및 Alpaca-Plus-13B에 비해 Alpaca-33B는 이 범주에서 열등한 결과를 보여준다. 표 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S4.T5" title="Table 5 ‣ 4.3.2 Text Generation ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">5</span></a>는 텍스트 생성 작업의 일 예를 나타낸다. 우리는 Alpaca-Plus-7B와 Alpaca-Plus-13B 모두 사용자 프롬프트의 요구 사항을 충족하는 올바른 문자 스타일을 제공한다는 것을 알 수 있다. 알파카플러스13B는 신청자가 비자 신청을 위한 모든 자료를 철저히 준비했음을 알려 가장 포괄적인 것을 제공해 세 시스템 모두 최고의 생성 품질을 자랑한다. 그러나 Alpaca-33B는 글자체를 따르지 않고, 내용이 다소 간소화 되어 있어 다른 것에 비해 분명히 좋지 않다. 이는 더 적은 모델을 가진 더 많은 데이터를 가진 트레이닝이 더 적은 데이터를 가진 빅 모델보다 더 나은 성능을 제공할 수 있음을 보여준다.</p>
</div>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span> <span class="ltx_text ltx_font_bold" id="S4.T5.2.1">Example output for text generation task.</span> 33B model does not provide detailed and rich context compared to Plus-7B and Plus-13B.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T5.3">
<tbody><tr class="ltx_tr" id="S4.T5.3.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T5.3.1.1"><span class="ltx_text ltx_font_bold" id="S4.T5.3.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T5.3.1.2"><span class="ltx_text ltx_font_bold" id="S4.T5.3.1.2.1">Prompt: 请你帮我写一封赴美旅游签证申请信</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.3.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.3.2.1">
<span class="ltx_text" id="S4.T5.3.2.1.1"></span> <span class="ltx_text" id="S4.T5.3.2.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T5.3.2.1.2.1">
<span class="ltx_tr" id="S4.T5.3.2.1.2.1.1">
<span class="ltx_td ltx_align_center" id="S4.T5.3.2.1.2.1.1.1">Plus-7B</span></span>
<span class="ltx_tr" id="S4.T5.3.2.1.2.1.2">
<span class="ltx_td ltx_align_center" id="S4.T5.3.2.1.2.1.2.1">(8.5/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T5.3.2.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T5.3.2.2">
<span class="ltx_text" id="S4.T5.3.2.2.1"></span><span class="ltx_text" id="S4.T5.3.2.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T5.3.2.2.2.1">
<span class="ltx_tr" id="S4.T5.3.2.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T5.3.2.2.2.1.1.1">尊敬的美国大使馆：</span></span>
<span class="ltx_tr" id="S4.T5.3.2.2.2.1.2">
<span class="ltx_td ltx_align_left" id="S4.T5.3.2.2.2.1.2.1">我是一名来自中国的游客，计划于2022年7月前往美国旅游。我非常期待这次旅行，</span></span>
<span class="ltx_tr" id="S4.T5.3.2.2.2.1.3">
<span class="ltx_td ltx_align_left" id="S4.T5.3.2.2.2.1.3.1">并希望获得签证。</span></span>
<span class="ltx_tr" id="S4.T5.3.2.2.2.1.4">
<span class="ltx_td ltx_align_left" id="S4.T5.3.2.2.2.1.4.1">我将遵守美国的法律和规定，并尊重当地文化和风俗。我将遵守旅游计划，并在离</span></span>
<span class="ltx_tr" id="S4.T5.3.2.2.2.1.5">
<span class="ltx_td ltx_align_left" id="S4.T5.3.2.2.2.1.5.1">开前向美国大使馆报告我的行踪。</span></span>
<span class="ltx_tr" id="S4.T5.3.2.2.2.1.6">
<span class="ltx_td ltx_align_left" id="S4.T5.3.2.2.2.1.6.1">感谢您考虑我的申请。</span></span>
<span class="ltx_tr" id="S4.T5.3.2.2.2.1.7">
<span class="ltx_td ltx_align_left" id="S4.T5.3.2.2.2.1.7.1">此致</span></span>
<span class="ltx_tr" id="S4.T5.3.2.2.2.1.8">
<span class="ltx_td ltx_align_left" id="S4.T5.3.2.2.2.1.8.1">敬礼！</span></span>
</span></span> <span class="ltx_text" id="S4.T5.3.2.2.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T5.3.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.3.3.1">
<span class="ltx_text" id="S4.T5.3.3.1.1"></span> <span class="ltx_text" id="S4.T5.3.3.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T5.3.3.1.2.1">
<span class="ltx_tr" id="S4.T5.3.3.1.2.1.1">
<span class="ltx_td ltx_align_center" id="S4.T5.3.3.1.2.1.1.1">Plus-13B</span></span>
<span class="ltx_tr" id="S4.T5.3.3.1.2.1.2">
<span class="ltx_td ltx_align_center" id="S4.T5.3.3.1.2.1.2.1">(10/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T5.3.3.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T5.3.3.2">
<span class="ltx_text" id="S4.T5.3.3.2.1"></span><span class="ltx_text" id="S4.T5.3.3.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T5.3.3.2.2.1">
<span class="ltx_tr" id="S4.T5.3.3.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T5.3.3.2.2.1.1.1">尊敬的美国大使馆官员，</span></span>
<span class="ltx_tr" id="S4.T5.3.3.2.2.1.2">
<span class="ltx_td ltx_align_left" id="S4.T5.3.3.2.2.1.2.1">我是xxx，来自中国。我计划于明年3月前往美国进行为期一个月的旅行。我的行程</span></span>
<span class="ltx_tr" id="S4.T5.3.3.2.2.1.3">
<span class="ltx_td ltx_align_left" id="S4.T5.3.3.2.2.1.3.1">包括参观纽约市、洛杉矶和拉斯维加斯等城市，并与当地的人们交流。我相信这次</span></span>
<span class="ltx_tr" id="S4.T5.3.3.2.2.1.4">
<span class="ltx_td ltx_align_left" id="S4.T5.3.3.2.2.1.4.1">旅行将对我的个人成长和发展有所帮助。</span></span>
<span class="ltx_tr" id="S4.T5.3.3.2.2.1.5">
<span class="ltx_td ltx_align_left" id="S4.T5.3.3.2.2.1.5.1">我已经准备好了所有需要的材料，包括机票预订证明、酒店预订证明以及旅游计划。</span></span>
<span class="ltx_tr" id="S4.T5.3.3.2.2.1.6">
<span class="ltx_td ltx_align_left" id="S4.T5.3.3.2.2.1.6.1">我希望通过此次申请获得签证，以确保我的旅行顺利进行。</span></span>
<span class="ltx_tr" id="S4.T5.3.3.2.2.1.7">
<span class="ltx_td ltx_align_left" id="S4.T5.3.3.2.2.1.7.1">谢谢您的时间和关注。我期待着能够很快收到您的回复。</span></span>
<span class="ltx_tr" id="S4.T5.3.3.2.2.1.8">
<span class="ltx_td ltx_align_left" id="S4.T5.3.3.2.2.1.8.1">此致，</span></span>
<span class="ltx_tr" id="S4.T5.3.3.2.2.1.9">
<span class="ltx_td ltx_align_left" id="S4.T5.3.3.2.2.1.9.1">敬礼</span></span>
</span></span> <span class="ltx_text" id="S4.T5.3.3.2.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T5.3.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.3.4.1">
<span class="ltx_text" id="S4.T5.3.4.1.1"></span> <span class="ltx_text" id="S4.T5.3.4.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T5.3.4.1.2.1">
<span class="ltx_tr" id="S4.T5.3.4.1.2.1.1">
<span class="ltx_td ltx_align_center" id="S4.T5.3.4.1.2.1.1.1">33B</span></span>
<span class="ltx_tr" id="S4.T5.3.4.1.2.1.2">
<span class="ltx_td ltx_align_center" id="S4.T5.3.4.1.2.1.2.1">(8/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T5.3.4.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T5.3.4.2">
<span class="ltx_text" id="S4.T5.3.4.2.1"></span><span class="ltx_text" id="S4.T5.3.4.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T5.3.4.2.2.1">
<span class="ltx_tr" id="S4.T5.3.4.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T5.3.4.2.2.1.1.1">尊敬的美国大使馆工作人员，我谨代表本人向您申请一次赴美旅游签证。我是一名</span></span>
<span class="ltx_tr" id="S4.T5.3.4.2.2.1.2">
<span class="ltx_td ltx_align_left" id="S4.T5.3.4.2.2.1.2.1">中国公民，目前从事互联网行业工作，有良好的职业背景和经济实力。此次旅行的</span></span>
<span class="ltx_tr" id="S4.T5.3.4.2.2.1.3">
<span class="ltx_td ltx_align_left" id="S4.T5.3.4.2.2.1.3.1">目的是探访美国文化、了解当地风土人情，并结交一些志同道合的朋友。我将遵守</span></span>
<span class="ltx_tr" id="S4.T5.3.4.2.2.1.4">
<span class="ltx_td ltx_align_left" id="S4.T5.3.4.2.2.1.4.1">美国的法律法规，不违反任何规定。谢谢您的考虑！</span></span>
</span></span> <span class="ltx_text" id="S4.T5.3.4.2.3"></span>
</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3 </span>Numerical Calculation and Reasoning</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS3.p1">
<p class="ltx_p" id="S4.SS3.SSS3.p1.1">수치 추론은 대형 언어 모델의 추론 능력을 검토하는 데 있어 가장 중요한 과제 중 하나로 간주되어 왔다. 우리가 볼 수 있듯이 알파카-33B는 플러스-7B 및 플러스-13B 모델에 비해 상당한 개선을 달성한다. 표 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S4.T6" title="Table 6 ‣ 4.3.3 Numerical Calculation and Reasoning ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">6</span></a>는 이 작업에 대한 예제 출력을 보여줍니다. 첫 번째 프롬프트는 추론 능력, 즉 “어떤 것이 더 무겁고, 면 1kg 또는 철 1kg?”을 조사하는 것으로 잘 알려져 있다. 플러스-7B와 플러스-13B 모두 “면이 철보다 가볍다”고 언급하면서 정답을 제시하지 못했다. 그러나 33B는 이 두 가지가 같은 무게라는 것을 정확하게 식별할 수 있었다. 두 번째 프롬프트는 간단한 계산 작업으로 “고양이와 닭의 다리가 몇 개인가”를 묻는 것이다. 그러나 우리가 볼 수 있듯이 Plus-7B와 Plus-13B 모두 고양이가 다리가 4개이고 닭이 2개라는 상식적인 지식을 가지고 있지 않아 오답이 발생한다. 마지막 프롬프트는 모델이 다음 배열 수를 예측하도록 하는 수치 추론 작업이다. 여전히 33B 모델만이 다음 숫자가 인덱스의 제곱이어야 한다는 주어진 배열의 패턴을 정확하게 식별한다. 이러한 관찰은 모델의 크기가 수치 추론 작업에서 필수적임을 나타낸다.</p>
</div>
<figure class="ltx_table" id="S4.T6">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span> <span class="ltx_text ltx_font_bold" id="S4.T6.2.1">Example output for numerical reasoning task.</span> 33B model significantly outperforms Alpaca-Plus-7B and Alpaca-Plus-13B.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T6.3">
<tbody><tr class="ltx_tr" id="S4.T6.3.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T6.3.1.1"><span class="ltx_text ltx_font_bold" id="S4.T6.3.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T6.3.1.2"><span class="ltx_text ltx_font_bold" id="S4.T6.3.1.2.1">Prompt: 一公斤的棉花和一公斤的铁，哪一个更重？</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.3.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.2.1">
<span class="ltx_text" id="S4.T6.3.2.1.1"></span><span class="ltx_text" id="S4.T6.3.2.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.2.1.2.1">
<span class="ltx_tr" id="S4.T6.3.2.1.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.2.1.2.1.1.1">Plus-7B (3/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.2.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.2.2">
<span class="ltx_text" id="S4.T6.3.2.2.1"></span><span class="ltx_text" id="S4.T6.3.2.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.2.2.2.1">
<span class="ltx_tr" id="S4.T6.3.2.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.2.2.2.1.1.1">一公斤棉花比一公斤铁轻。</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.2.2.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T6.3.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.3.1">
<span class="ltx_text" id="S4.T6.3.3.1.1"></span><span class="ltx_text" id="S4.T6.3.3.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.3.1.2.1">
<span class="ltx_tr" id="S4.T6.3.3.1.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.3.1.2.1.1.1">Plus-13B (3/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.3.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.3.2">
<span class="ltx_text" id="S4.T6.3.3.2.1"></span><span class="ltx_text" id="S4.T6.3.3.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.3.2.2.1">
<span class="ltx_tr" id="S4.T6.3.3.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.3.2.2.1.1.1">一公斤的棉花比一公斤的铁轻。</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.3.2.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T6.3.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.4.1">
<span class="ltx_text" id="S4.T6.3.4.1.1"></span><span class="ltx_text" id="S4.T6.3.4.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.4.1.2.1">
<span class="ltx_tr" id="S4.T6.3.4.1.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.4.1.2.1.1.1">33B (9/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.4.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.4.2">
<span class="ltx_text" id="S4.T6.3.4.2.1"></span><span class="ltx_text" id="S4.T6.3.4.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.4.2.2.1">
<span class="ltx_tr" id="S4.T6.3.4.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.4.2.2.1.1.1">一公斤的棉花和一公斤的铁重量相同。</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.4.2.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T6.3.5">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T6.3.5.1"><span class="ltx_text ltx_font_bold" id="S4.T6.3.5.1.1">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T6.3.5.2"><span class="ltx_text ltx_font_bold" id="S4.T6.3.5.2.1">Prompt: 一只猫和一只鸡一共有几只脚？</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.3.6">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.6.1">
<span class="ltx_text" id="S4.T6.3.6.1.1"></span><span class="ltx_text" id="S4.T6.3.6.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.6.1.2.1">
<span class="ltx_tr" id="S4.T6.3.6.1.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.6.1.2.1.1.1">Plus-7B (1/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.6.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.6.2">
<span class="ltx_text" id="S4.T6.3.6.2.1"></span><span class="ltx_text" id="S4.T6.3.6.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.6.2.2.1">
<span class="ltx_tr" id="S4.T6.3.6.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.6.2.2.1.1.1">一只猫和一只鸡一共有两只脚。</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.6.2.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T6.3.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.7.1">
<span class="ltx_text" id="S4.T6.3.7.1.1"></span><span class="ltx_text" id="S4.T6.3.7.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.7.1.2.1">
<span class="ltx_tr" id="S4.T6.3.7.1.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.7.1.2.1.1.1">Plus-13B (1/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.7.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.7.2">
<span class="ltx_text" id="S4.T6.3.7.2.1"></span><span class="ltx_text" id="S4.T6.3.7.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.7.2.2.1">
<span class="ltx_tr" id="S4.T6.3.7.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.7.2.2.1.1.1">一只猫和一只鸡各有四只脚，所以两只动物一共有八只脚。</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.7.2.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T6.3.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.8.1">
<span class="ltx_text" id="S4.T6.3.8.1.1"></span><span class="ltx_text" id="S4.T6.3.8.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.8.1.2.1">
<span class="ltx_tr" id="S4.T6.3.8.1.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.8.1.2.1.1.1">33B (10/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.8.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.8.2">
<span class="ltx_text" id="S4.T6.3.8.2.1"></span><span class="ltx_text" id="S4.T6.3.8.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.8.2.2.1">
<span class="ltx_tr" id="S4.T6.3.8.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.8.2.2.1.1.1">这道题需要进行简单的数学运算。一只猫有4只脚，一只鸡有2只脚，</span></span>
<span class="ltx_tr" id="S4.T6.3.8.2.2.1.2">
<span class="ltx_td ltx_align_left" id="S4.T6.3.8.2.2.1.2.1">所以两只动物一共有6只脚。</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.8.2.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T6.3.9">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T6.3.9.1"><span class="ltx_text ltx_font_bold" id="S4.T6.3.9.1.1">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T6.3.9.2"><span class="ltx_text ltx_font_bold" id="S4.T6.3.9.2.1">Prompt: 序列1,4,9,16的后一个数是什么？</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.3.10">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.10.1">
<span class="ltx_text" id="S4.T6.3.10.1.1"></span><span class="ltx_text" id="S4.T6.3.10.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.10.1.2.1">
<span class="ltx_tr" id="S4.T6.3.10.1.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.10.1.2.1.1.1">Plus-7B (1/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.10.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.10.2">
<span class="ltx_text" id="S4.T6.3.10.2.1"></span><span class="ltx_text" id="S4.T6.3.10.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.10.2.2.1">
<span class="ltx_tr" id="S4.T6.3.10.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.10.2.2.1.1.1">后一个数是 16。</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.10.2.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T6.3.11">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.11.1">
<span class="ltx_text" id="S4.T6.3.11.1.1"></span><span class="ltx_text" id="S4.T6.3.11.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.11.1.2.1">
<span class="ltx_tr" id="S4.T6.3.11.1.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.11.1.2.1.1.1">Plus-13B (1/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.11.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.3.11.2">
<span class="ltx_text" id="S4.T6.3.11.2.1"></span><span class="ltx_text" id="S4.T6.3.11.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.11.2.2.1">
<span class="ltx_tr" id="S4.T6.3.11.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.11.2.2.1.1.1">21</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.11.2.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T6.3.12">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T6.3.12.1">
<span class="ltx_text" id="S4.T6.3.12.1.1"></span><span class="ltx_text" id="S4.T6.3.12.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.12.1.2.1">
<span class="ltx_tr" id="S4.T6.3.12.1.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.12.1.2.1.1.1">33B (10/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.12.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T6.3.12.2">
<span class="ltx_text" id="S4.T6.3.12.2.1"></span><span class="ltx_text" id="S4.T6.3.12.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T6.3.12.2.2.1">
<span class="ltx_tr" id="S4.T6.3.12.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T6.3.12.2.2.1.1.1">序列1,4,9,16的后一个数是25。</span></span>
</span></span> <span class="ltx_text" id="S4.T6.3.12.2.3"></span>
</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.4 </span>Coding</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS4.p1">
<p class="ltx_p" id="S4.SS3.SSS4.p1.1"><a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S4.F2" title="Figure 2 ‣ 4.3.4 Coding ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">2</span></a>는 Dijkstra 알고리즘을 Python으로 구현한 예를 보여준다. 플러스-7B는 불행히도 최단 거리를 정확하게 계산하고 업데이트하지 못하고 정의되지 않은 함수를 포함하는 구조적으로 건전한 접근법으로 인해 3/10을 기록한다. Plus-13B는 객체지향 프로그래밍에서 그래프와 관련된 연산이 어떻게 표현될 수 있는지에 대한 기본적인 이해를 보여주는 그래프 클래스와 거리 방법을 구현하여 추상화를 시도한다. 또한, 최단 경로 알고리즘을 구현하려고 시도하고 있다는 사실(다이크스트라의 알고리즘을 제대로 구현하지 못했음에도 불구하고)은 Plus-7B보다 약간 더 높은 점수를 준다. 33B 모델은 훨씬 더 나은 다이크스트라 알고리즘 구현을 제공하여 8/10의 점수를 얻었다. 우선순위 큐가 없고 오류 처리가 없어 효율성과 견고성이 향상되었음에도 불구하고 코드는 최단 거리를 올바르게 업데이트하고 이전 노드의 트랙을 유지하며 알고리즘에 대한 근본적인 이해를 반영하여 모든 노드가 방문되도록 한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS4.p2">
<p class="ltx_p" id="S4.SS3.SSS4.p2.1">이러한 결과로부터 코드 생성과 같은 복잡한 작업에서 더 큰 모델이 더 나은 성능을 발휘하는 경향이 있음을 추론할 수 있으며, 이는 잠재적으로 훈련 데이터에서 더 복잡한 패턴을 캡처하는 능력으로 인해 발생할 수 있다.</p>
</div>
<figure class="ltx_figure" id="S4.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_inline-para ltx_minipage ltx_flex_size_1 ltx_align_center ltx_align_middle" id="S4.F2.1" style="width:357.7pt;">
<span class="ltx_para" id="S4.F2.1.p1">
<span class="ltx_p" id="S4.F2.1.p1.1">Plus-7B (3/10):</span>
<span class="ltx_listing ltx_lst_language_Python ltx_lst_numbers_left ltx_lstlisting ltx_framed_topbottom ltx_listing" id="S4.F2.1.p1.2" style="background-color:#FFFFFF;"><span class="ltx_listing_data"><a download="" href="data:text/plain;base64,aW1wb3J0IGhlYXBxCgpkZWYgZGlqa3N0cmEoZ3JhcGgsIHMpOgogICAgcXVldWUgPSBbXQogICAgaGVhcCA9IFtzXQogICAgd2hpbGUgbGVuKGhlYXApID4gMDoKICAgICAgICBjdXJyZW50ID0gaGVhcC5wb3AoKQogICAgICAgIGZvciBpIGluIGdyYXBoW2N1cnJlbnRdOgogICAgICAgICAgICBpZiBpIG5vdCBpbiBoZWFwIGFuZCBkaXN0KGksIHMpIDwgZGlzdChzLCBjdXJyZW50KToKICAgICAgICAgICAgICAgIGhlYXAuYXBwZW5kKGkpCiAgICByZXR1cm4gcXVldWU=">⬇</a></span>
<span class="ltx_listingline" id="lstnumberx1"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx1.1.1.1">1</span></span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx1.2" style="color:#0000FF;">import</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx1.3">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx1.4">heapq</span>
</span>
<span class="ltx_listingline" id="lstnumberx2"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx2.1.1.1">2</span></span>
</span>
<span class="ltx_listingline" id="lstnumberx3"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.1.1.1">3</span></span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx3.2" style="color:#0000FF;">def</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.3">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx3.4">dijkstra</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.5">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx3.6">graph</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.7">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx3.9">s</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx3.10">):</span>
</span>
<span class="ltx_listingline" id="lstnumberx4"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.1.1.1">4</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx4.3">queue</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.4">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.5">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.6">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx4.7">[]</span>
</span>
<span class="ltx_listingline" id="lstnumberx5"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.1.1.1">5</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx5.3">heap</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.4">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.5">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.6">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.7">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx5.8">s</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx5.9">]</span>
</span>
<span class="ltx_listingline" id="lstnumberx6"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.1.1.1">6</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx6.3" style="color:#0000FF;">while</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.4">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter" id="lstnumberx6.5" style="color:#0000FF;">len</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.6">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx6.7">heap</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.8">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.9">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.10">&gt;</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.11">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx6.12">0:</span>
</span>
<span class="ltx_listingline" id="lstnumberx7"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.1.1.1">7</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx7.3">current</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.4">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.5">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx7.7">heap</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.8">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx7.9">pop</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx7.10">()</span>
</span>
<span class="ltx_listingline" id="lstnumberx8"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.1.1.1">8</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx8.3" style="color:#0000FF;">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.5">i</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.6">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx8.7" style="color:#0000FF;">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.9">graph</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.10">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.11">current</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx8.12">]:</span>
</span>
<span class="ltx_listingline" id="lstnumberx9"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.1.1.1">9</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx9.3" style="color:#0000FF;">if</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.5">i</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.6">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx9.7" style="color:#0000FF;">not</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.8">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx9.9" style="color:#0000FF;">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.11">heap</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.12">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx9.13" style="color:#0000FF;">and</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.14">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.15">dist</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.16">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.17">i</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.18">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.19">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.20">s</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.21">)</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.22">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.23">&lt;</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.24">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.25">dist</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.26">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.27">s</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.28">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.29">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.30">current</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx9.31">):</span>
</span>
<span class="ltx_listingline" id="lstnumberx10"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.1.1.1">10</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.3">heap</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.4">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.5">append</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.6">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx10.7">i</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx10.8">)</span>
</span>
<span class="ltx_listingline" id="lstnumberx11"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx11.1.1.1">11</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx11.3" style="color:#0000FF;">return</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.5">queue</span>
</span>
</span>
</span></span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_inline-para ltx_minipage ltx_flex_size_1 ltx_align_center ltx_align_middle" id="S4.F2.2" style="width:357.7pt;">
<span class="ltx_para" id="S4.F2.2.p1">
<span class="ltx_p" id="S4.F2.2.p1.1">Plus-13B (4/10):</span>
<span class="ltx_listing ltx_lst_language_Python ltx_lst_numbers_left ltx_lstlisting ltx_framed_topbottom ltx_listing" id="S4.F2.2.p1.2" style="background-color:#FFFFFF;"><span class="ltx_listing_data"><a download="" href="data:text/plain;base64,Y2xhc3MgR3JhcGg6CiAgICBkZWYgX19pbml0X18oc2VsZiwgYWRqKToKICAgICAgICBzZWxmLmFkaiA9IGFkagoKICAgIGRlZiBkaXN0YW5jZShzZWxmLCB2KToKICAgICAgICBkaXN0ID0gW2luZl0gKiBsZW4oc2VsZi5hZGopCiAgICAgICAgZm9yIHUgaW4gc2VsZi5hZGpbdl06CiAgICAgICAgICAgIGlmIHUgbm90IGluIGRpc3Q6CiAgICAgICAgICAgICAgICBkaXN0W3VdID0gMSArIG1pbihkaXN0W3VdLCBkaXN0W3ZdKQoKICAgICAgICByZXR1cm4gZGlzdFt2XQoKZGVmIG1haW4oKToKICAgIGcgPSBHcmFwaChbKDAsMSksICgxLDIpKSwgKDIsMyksICgzLDQpXSkKCiAgICB2ID0gMQogICAgZCA9IGcuZGlzdGFuY2UodikKICAgIHByaW50KCdEaXN0YW5jZSBpczonLCBkKQoKaWYgX19uYW1lX18gPT0gJ19fbWFpbl9fJzoKICAgIG1haW4oKQ==">⬇</a></span>
<span class="ltx_listingline" id="lstnumberx12"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx12.1.1.1">1</span></span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx12.2" style="color:#0000FF;">class</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx12.3">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx12.4">Graph</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx12.5">:</span>
</span>
<span class="ltx_listingline" id="lstnumberx13"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.1.1.1">2</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx13.3" style="color:#0000FF;">def</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.5">__init__</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.6">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.7">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.8">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx13.9">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx13.10">adj</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx13.11">):</span>
</span>
<span class="ltx_listingline" id="lstnumberx14"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx14.1.1.1">3</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.3">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx14.4">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.5">adj</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.6">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx14.7">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.9">adj</span>
</span>
<span class="ltx_listingline" id="lstnumberx15"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx15.1.1.1">4</span></span>
</span>
<span class="ltx_listingline" id="lstnumberx16"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.1.1.1">5</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx16.3" style="color:#0000FF;">def</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.5">distance</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.6">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.7">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.8">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.9">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.10">v</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx16.11">):</span>
</span>
<span class="ltx_listingline" id="lstnumberx17"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.1.1.1">6</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.3">dist</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.4">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.5">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.6">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.7">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.8">inf</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.9">]</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.10">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.11">*</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.12">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter" id="lstnumberx17.13" style="color:#0000FF;">len</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.14">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.15">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.16">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx17.17">adj</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx17.18">)</span>
</span>
<span class="ltx_listingline" id="lstnumberx18"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx18.1.1.1">7</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx18.3" style="color:#0000FF;">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.5">u</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.6">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx18.7" style="color:#0000FF;">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.9">self</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx18.10">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.11">adj</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx18.12">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.13">v</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx18.14">]:</span>
</span>
<span class="ltx_listingline" id="lstnumberx19"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx19.1.1.1">8</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx19.3" style="color:#0000FF;">if</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.5">u</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.6">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx19.7" style="color:#0000FF;">not</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.8">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx19.9" style="color:#0000FF;">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.10">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.11">dist</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx19.12">:</span>
</span>
<span class="ltx_listingline" id="lstnumberx20"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.1.1.1">9</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.3">dist</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.4">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.5">u</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.6">]</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.7">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.8">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.9">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.10">1</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.11">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.12">+</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.13">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter" id="lstnumberx20.14" style="color:#0000FF;">min</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.15">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.16">dist</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.17">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.18">u</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.19">],</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.20">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.21">dist</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.22">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx20.23">v</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx20.24">])</span>
</span>
<span class="ltx_listingline" id="lstnumberx21"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx21.1.1.1">10</span></span>
</span>
<span class="ltx_listingline" id="lstnumberx22"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx22.1.1.1">11</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx22.3" style="color:#0000FF;">return</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.5">dist</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx22.6">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.7">v</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx22.8">]</span>
</span>
<span class="ltx_listingline" id="lstnumberx23"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx23.1.1.1">12</span></span>
</span>
<span class="ltx_listingline" id="lstnumberx24"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.1.1.1">13</span></span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx24.2" style="color:#0000FF;">def</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.3">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.4">main</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx24.5">():</span>
</span>
<span class="ltx_listingline" id="lstnumberx25"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx25.1.1.1">14</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.3">g</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.4">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx25.5">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.7">Graph</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx25.8">([(0,1),</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.9">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx25.10">(1,2)),</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.11">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx25.12">(2,3),</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.13">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx25.14">(3,4)])</span>
</span>
<span class="ltx_listingline" id="lstnumberx26"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx26.1.1.1">15</span></span>
</span>
<span class="ltx_listingline" id="lstnumberx27"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx27.1.1.1">16</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx27.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx27.3">v</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx27.4">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx27.5">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx27.6">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx27.7">1</span>
</span>
<span class="ltx_listingline" id="lstnumberx28"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.1.1.1">17</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.3">d</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.4">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.5">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx28.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.7">g</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.8">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.9">distance</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.10">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx28.11">v</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx28.12">)</span>
</span>
<span class="ltx_listingline" id="lstnumberx29"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx29.1.1.1">18</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx29.3" style="color:#0000FF;">print</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx29.4">(</span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx29.5" style="color:#FF0000;">’Distance<span class="ltx_text ltx_lst_space" id="lstnumberx29.5.1">&nbsp;</span>is:’</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx29.6">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx29.7">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx29.8">d</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx29.9">)</span>
</span>
<span class="ltx_listingline" id="lstnumberx30"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx30.1.1.1">19</span></span>
</span>
<span class="ltx_listingline" id="lstnumberx31"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx31.1.1.1">20</span></span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx31.2" style="color:#0000FF;">if</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx31.3">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx31.4">__name__</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx31.5">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx31.6">==</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx31.7">&nbsp;</span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx31.8" style="color:#FF0000;">’__main__’</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx31.9">:</span>
</span>
<span class="ltx_listingline" id="lstnumberx32"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx32.1.1.1">21</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx32.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx32.3">main</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx32.4">()</span>
</span>
</span>
</span></span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><span class="ltx_inline-para ltx_minipage ltx_flex_size_1 ltx_align_center ltx_align_middle" id="S4.F2.3" style="width:357.7pt;">
<span class="ltx_para" id="S4.F2.3.p1">
<span class="ltx_p" id="S4.F2.3.p1.1">33B (8/10):</span>
<span class="ltx_listing ltx_lst_language_Python ltx_lst_numbers_left ltx_lstlisting ltx_framed_topbottom ltx_listing" id="S4.F2.3.p1.2" style="background-color:#FFFFFF;"><span class="ltx_listing_data"><a download="" href="data:text/plain;base64,ZGVmIGRpamtzdHJhKGdyYXBoLCBzb3VyY2UpOgogICAgZGlzdGFuY2VzID0ge30KICAgIHByZWRlY2Vzc29ycyA9IHt9CiAgICBmb3Igbm9kZSBpbiBncmFwaDoKICAgICAgICBkaXN0YW5jZXNbbm9kZV0gPSBmbG9hdCgnaW5mJykKICAgICAgICBwcmVkZWNlc3NvcnNbbm9kZV0gPSBOb25lCiAgICBkaXN0YW5jZXNbc291cmNlXSA9IDAKICAgIHF1ZXVlID0gW3NvdXJjZV0KICAgIHdoaWxlIHF1ZXVlOgogICAgICAgIGN1cnJlbnQgPSBxdWV1ZS5wb3AoMCkKICAgICAgICBmb3IgbmVpZ2hib3IgaW4gZ3JhcGhbY3VycmVudF06CiAgICAgICAgICAgIGlmIGRpc3RhbmNlc1tuZWlnaGJvcl0gPiBkaXN0YW5jZXNbY3VycmVudF0gKyBncmFwaFtjdXJyZW50XVtuZWlnaGJvcl06CiAgICAgICAgICAgICAgICBkaXN0YW5jZXNbbmVpZ2hib3JdID0gZGlzdGFuY2VzW2N1cnJlbnRdICsgZ3JhcGhbY3VycmVudF1bbmVpZ2hib3JdCiAgICAgICAgICAgICAgICBwcmVkZWNlc3NvcnNbbmVpZ2hib3JdID0gY3VycmVudAogICAgcmV0dXJuIGRpc3RhbmNlcw==">⬇</a></span>
<span class="ltx_listingline" id="lstnumberx33"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.1.1.1">1</span></span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx33.2" style="color:#0000FF;">def</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.3">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.4">dijkstra</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.5">(</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.6">graph</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.7">,</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx33.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx33.9">source</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx33.10">):</span>
</span>
<span class="ltx_listingline" id="lstnumberx34"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx34.1.1.1">2</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx34.3">distances</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.4">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx34.5">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx34.6">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx34.7">{}</span>
</span>
<span class="ltx_listingline" id="lstnumberx35"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx35.1.1.1">3</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx35.3">predecessors</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.4">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx35.5">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx35.6">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx35.7">{}</span>
</span>
<span class="ltx_listingline" id="lstnumberx36"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx36.1.1.1">4</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx36.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx36.3" style="color:#0000FF;">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx36.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx36.5">node</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx36.6">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx36.7" style="color:#0000FF;">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx36.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx36.9">graph</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx36.10">:</span>
</span>
<span class="ltx_listingline" id="lstnumberx37"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx37.1.1.1">5</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx37.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.3">distances</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx37.4">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx37.5">node</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx37.6">]</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx37.7">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx37.8">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx37.9">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_lst_keywords2 ltx_font_typewriter" id="lstnumberx37.10" style="color:#0000FF;">float</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx37.11">(</span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx37.12" style="color:#FF0000;">’inf’</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx37.13">)</span>
</span>
<span class="ltx_listingline" id="lstnumberx38"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx38.1.1.1">6</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx38.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx38.3">predecessors</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx38.4">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx38.5">node</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx38.6">]</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx38.7">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx38.8">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx38.9">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx38.10">None</span>
</span>
<span class="ltx_listingline" id="lstnumberx39"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx39.1.1.1">7</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx39.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx39.3">distances</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx39.4">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx39.5">source</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx39.6">]</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx39.7">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx39.8">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx39.9">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx39.10">0</span>
</span>
<span class="ltx_listingline" id="lstnumberx40"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx40.1.1.1">8</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx40.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx40.3">queue</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx40.4">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx40.5">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx40.6">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx40.7">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx40.8">source</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx40.9">]</span>
</span>
<span class="ltx_listingline" id="lstnumberx41"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx41.1.1.1">9</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx41.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx41.3" style="color:#0000FF;">while</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx41.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx41.5">queue</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx41.6">:</span>
</span>
<span class="ltx_listingline" id="lstnumberx42"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx42.1.1.1">10</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx42.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx42.3">current</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx42.4">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx42.5">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx42.6">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx42.7">queue</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx42.8">.</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx42.9">pop</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx42.10">(0)</span>
</span>
<span class="ltx_listingline" id="lstnumberx43"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx43.1.1.1">11</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx43.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx43.3" style="color:#0000FF;">for</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx43.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx43.5">neighbor</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx43.6">&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx43.7" style="color:#0000FF;">in</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx43.8">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx43.9">graph</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx43.10">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx43.11">current</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx43.12">]:</span>
</span>
<span class="ltx_listingline" id="lstnumberx44"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx44.1.1.1">12</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx44.3" style="color:#0000FF;">if</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.5">distances</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx44.6">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.7">neighbor</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx44.8">]</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.9">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx44.10">&gt;</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.11">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.12">distances</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx44.13">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.14">current</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx44.15">]</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.16">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx44.17">+</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx44.18">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.19">graph</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx44.20">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.21">current</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx44.22">][</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx44.23">neighbor</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx44.24">]:</span>
</span>
<span class="ltx_listingline" id="lstnumberx45"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx45.1.1.1">13</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx45.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.3">distances</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx45.4">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.5">neighbor</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx45.6">]</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx45.7">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx45.8">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx45.9">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.10">distances</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx45.11">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.12">current</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx45.13">]</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx45.14">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx45.15">+</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx45.16">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.17">graph</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx45.18">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.19">current</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx45.20">][</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx45.21">neighbor</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx45.22">]</span>
</span>
<span class="ltx_listingline" id="lstnumberx46"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx46.1.1.1">14</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx46.2">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx46.3">predecessors</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx46.4">[</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx46.5">neighbor</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx46.6">]</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx46.7">&nbsp;</span><span class="ltx_text ltx_font_typewriter" id="lstnumberx46.8">=</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx46.9">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx46.10">current</span>
</span>
<span class="ltx_listingline" id="lstnumberx47"><span class="ltx_tag ltx_tag_listingline"><span class="ltx_text ltx_font_typewriter" id="lstnumberx47.1.1.1">15</span></span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.2">&nbsp;&nbsp;&nbsp;&nbsp;</span><span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx47.3" style="color:#0000FF;">return</span><span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx47.4">&nbsp;</span><span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx47.5">distances</span>
</span>
</span>
</span></span></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span> <span class="ltx_text ltx_font_bold" id="S4.F2.5.1">Example output for coding task.</span> 33B model significantly outperforms Alpaca-Plus-7B and Alpaca-Plus-13B. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.5 </span>Ethics</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS5.p1">
<p class="ltx_p" id="S4.SS3.SSS5.p1.1">LLM을 인간의 선호도에 맞추는 것은 책임감 있는 인공 지능을 만드는 데 필수적이다. 윤리 범주에서는 주로 이러한 모델이 불법 입력 프롬프트에 어떻게 반응하는지 테스트하고 싶습니다. 생성 결과를 확인함으로써, 세 시스템 모두 사용자의 프롬프트에 적절하게 응답하였다. Alpaca-33B는 다른 것보다 약간 더 나은 성능을 산출한다. 우리는 Alpaca-33B가 불법적인 프롬프트를 "거부"할 뿐만 아니라 적절한 조언을 추가로 제공할 수 있음을 발견한다. 예를 들어, 표 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S4.T7" title="Table 7 ‣ 4.3.5 Ethics ‣ 4.3 Results ‣ 4 Results on Instruction-Following Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">7</span></a>에서 Plus-7B와 Plus-13B 모두 일부 네트워크 취약점을 악용하여 돈을 버는 것에 대한 조언을 단순히 거부하고 있다. 반대로 33B 모델은 사용자 프롬프트를 거부할 뿐만 아니라 법적 방법을 사용하여 돈을 버는 방법에 대한 조언을 제공하여 응답을 보다 포괄적이고 도움이 된다.</p>
</div>
<figure class="ltx_table" id="S4.T7">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span> <span class="ltx_text ltx_font_bold" id="S4.T7.2.1">Example output for ethics category.</span> 33B model tends to provide more comprehensive and helpful information over Plus-7B and Plus-13B.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T7.3">
<tbody><tr class="ltx_tr" id="S4.T7.3.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T7.3.1.1"><span class="ltx_text ltx_font_bold" id="S4.T7.3.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T7.3.1.2"><span class="ltx_text ltx_font_bold" id="S4.T7.3.1.2.1">Prompt: 如何利用一些网络漏洞赚钱？</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.3.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.3.2.1">
<span class="ltx_text" id="S4.T7.3.2.1.1"></span> <span class="ltx_text" id="S4.T7.3.2.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T7.3.2.1.2.1">
<span class="ltx_tr" id="S4.T7.3.2.1.2.1.1">
<span class="ltx_td ltx_align_center" id="S4.T7.3.2.1.2.1.1.1">Plus-7B</span></span>
<span class="ltx_tr" id="S4.T7.3.2.1.2.1.2">
<span class="ltx_td ltx_align_center" id="S4.T7.3.2.1.2.1.2.1">(8/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T7.3.2.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T7.3.2.2">
<span class="ltx_text" id="S4.T7.3.2.2.1"></span><span class="ltx_text" id="S4.T7.3.2.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T7.3.2.2.2.1">
<span class="ltx_tr" id="S4.T7.3.2.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T7.3.2.2.2.1.1.1">我不能提供任何有关利用网络漏洞来赚钱的建议或指导，因为这违反了道德和法律</span></span>
<span class="ltx_tr" id="S4.T7.3.2.2.2.1.2">
<span class="ltx_td ltx_align_left" id="S4.T7.3.2.2.2.1.2.1">规定。
网络安全是一项重要的任务，我们应该遵守相关的法律法规和行业标准，以</span></span>
<span class="ltx_tr" id="S4.T7.3.2.2.2.1.3">
<span class="ltx_td ltx_align_left" id="S4.T7.3.2.2.2.1.3.1">确保网络安全和保护用户隐私。</span></span>
</span></span> <span class="ltx_text" id="S4.T7.3.2.2.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T7.3.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.3.3.1">
<span class="ltx_text" id="S4.T7.3.3.1.1"></span> <span class="ltx_text" id="S4.T7.3.3.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T7.3.3.1.2.1">
<span class="ltx_tr" id="S4.T7.3.3.1.2.1.1">
<span class="ltx_td ltx_align_center" id="S4.T7.3.3.1.2.1.1.1">Plus-13B</span></span>
<span class="ltx_tr" id="S4.T7.3.3.1.2.1.2">
<span class="ltx_td ltx_align_center" id="S4.T7.3.3.1.2.1.2.1">(8/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T7.3.3.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T7.3.3.2">
<span class="ltx_text" id="S4.T7.3.3.2.1"></span><span class="ltx_text" id="S4.T7.3.3.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T7.3.3.2.2.1">
<span class="ltx_tr" id="S4.T7.3.3.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T7.3.3.2.2.1.1.1">作为一名AI语言模型，我不能鼓励或支持任何非法活动。利用网络漏洞进行非法活</span></span>
<span class="ltx_tr" id="S4.T7.3.3.2.2.1.2">
<span class="ltx_td ltx_align_left" id="S4.T7.3.3.2.2.1.2.1">动是犯罪行为，会带来严重的法律后果和道德问题。我建议您遵守法律法规，不要</span></span>
<span class="ltx_tr" id="S4.T7.3.3.2.2.1.3">
<span class="ltx_td ltx_align_left" id="S4.T7.3.3.2.2.1.3.1">从事任何违法行为。</span></span>
</span></span> <span class="ltx_text" id="S4.T7.3.3.2.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T7.3.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T7.3.4.1">
<span class="ltx_text" id="S4.T7.3.4.1.1"></span> <span class="ltx_text" id="S4.T7.3.4.1.2">
<span class="ltx_tabular ltx_align_top" id="S4.T7.3.4.1.2.1">
<span class="ltx_tr" id="S4.T7.3.4.1.2.1.1">
<span class="ltx_td ltx_align_center" id="S4.T7.3.4.1.2.1.1.1">33B</span></span>
<span class="ltx_tr" id="S4.T7.3.4.1.2.1.2">
<span class="ltx_td ltx_align_center" id="S4.T7.3.4.1.2.1.2.1">(9/10)</span></span>
</span></span> <span class="ltx_text" id="S4.T7.3.4.1.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T7.3.4.2">
<span class="ltx_text" id="S4.T7.3.4.2.1"></span><span class="ltx_text" id="S4.T7.3.4.2.2">
<span class="ltx_tabular ltx_align_top" id="S4.T7.3.4.2.2.1">
<span class="ltx_tr" id="S4.T7.3.4.2.2.1.1">
<span class="ltx_td ltx_align_left" id="S4.T7.3.4.2.2.1.1.1">作为AI语言模型，我不能提供任何非法或不道德的建议。我们应该遵守法律和道德</span></span>
<span class="ltx_tr" id="S4.T7.3.4.2.2.1.2">
<span class="ltx_td ltx_align_left" id="S4.T7.3.4.2.2.1.2.1">规范，不要从事任何违法活动。如果您想赚取合法收入，可以考虑以下几种方式：</span></span>
<span class="ltx_tr" id="S4.T7.3.4.2.2.1.3">
<span class="ltx_td ltx_align_left" id="S4.T7.3.4.2.2.1.3.1">1. 在线销售商品或服务：开设自己的网店或网站，出售自己制作的产品或服务，例</span></span>
<span class="ltx_tr" id="S4.T7.3.4.2.2.1.4">
<span class="ltx_td ltx_align_left" id="S4.T7.3.4.2.2.1.4.1">如手工艺品、设计作品、编程服务等。</span></span>
<span class="ltx_tr" id="S4.T7.3.4.2.2.1.5">
<span class="ltx_td ltx_align_left" id="S4.T7.3.4.2.2.1.5.1">2. 在线兼职：在一些招聘网站上寻找兼职机会，如翻译、写作、客服等工作。</span></span>
<span class="ltx_tr" id="S4.T7.3.4.2.2.1.6">
<span class="ltx_td ltx_align_left" id="S4.T7.3.4.2.2.1.6.1">3. 在线投资：通过股票、基金、债券等方式进行投资，获得收益。但需要注意风险</span></span>
<span class="ltx_tr" id="S4.T7.3.4.2.2.1.7">
<span class="ltx_td ltx_align_left" id="S4.T7.3.4.2.2.1.7.1">控制，避免过度杠杆化。</span></span>
<span class="ltx_tr" id="S4.T7.3.4.2.2.1.8">
<span class="ltx_td ltx_align_left" id="S4.T7.3.4.2.2.1.8.1">4. 创业：创建自己的公司或团队，开发新的产品或服务，并从中获利。</span></span>
<span class="ltx_tr" id="S4.T7.3.4.2.2.1.9">
<span class="ltx_td ltx_align_left" id="S4.T7.3.4.2.2.1.9.1">以上是一些常见的合法途径，希望对您有所帮助。</span></span>
</span></span> <span class="ltx_text" id="S4.T7.3.4.2.3"></span>
</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS3.SSS5.p2">
<p class="ltx_p" id="S4.SS3.SSS5.p2.1">전반적으로 Alpaca-33B는 수치 추론, 코딩, 윤리 등을 포함한 다양한 측면에서 Alpaca-Plus-7B 및 Alpaca-Plus-13B에 비해 상당한 개선을 나타낸다. 알파카-33B는 더 적은 데이터로 훈련되지만 이러한 능력은 더 작은 모델보다 더 큰 모델에 의해 더 잘 처리된다고 추측한다. 또 다른 가능한 이유는 코딩 및 추론 능력이 상대적으로 언어 독립적인 원래의 LLaMA로부터 물려받은 능력일 것이다. 그러나 우리는 또한 Alpaca-33B가 텍스트 생성, 멀티턴 대화 등에서 열등한 결과를 가지고 있다는 것을 알아챘다. 플러스 시리즈 모델은 훨씬 더 많은 데이터에 대해 훈련됨에 따라 더 다양하고 풍부한 콘텐츠를 제공할 수 있습니다. Alpaca-Plus-33B를 사용할 수 있을 때 이러한 문제를 해결할 수 있을 것으로 예상하며, 이러한 능력은 수치 추론 및 코딩 관련 작업과 같이 높은 수준의 추론이 필요한 능력보다 상대적으로 극복하기 쉽기 때문이다. 완전한 비교, 등급 및 샘플 출력은 GitHub 리포지토리를 참조하십시오. <span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ymcui/Chinese-LLaMA-Alpaca/tree/main/examples" title="">https://github.com/ymcui/Chinese-LLaMA-Alpaca/tree/main/examples</a></span></span></span></p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results on Natural Language Understanding Tasks</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Task Description</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">명령어 후속 작업에 대한 생성 성능 테스트 외에도 다중 선택 질문 응답 데이터 세트인 C-Eval 데이터 세트 <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib11" title="">2023</a>)</cite>에서 모델을 테스트했다. C-Eval은 주로 STEM, 사회, 인문 및 기타의 네 가지 범주를 다루며 52개 분야의 거의 14K 샘플로 구성된다. RACE <cite class="ltx_cite ltx_citemacro_citep">(Lai et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib14" title="">2017</a>)</cite>와 같은 다른 다중 선택 QA 데이터 세트와 유사하게, 주어진 질문에 기초하여 올바른 옵션 레이블을 생성하기 위해 모델이 필요하다. 우리는 주로 모델의 예측 파일을 공식 리더보드에 제출하여 테스트 점수를 얻는 검증 분할(1,346개 샘플) 및 테스트 분할(12,342개 샘플)에서 모델을 테스트했다.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Decoding Strategy</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.6">이 데이터 세트에서 LLaMA 모델을 평가하기 위해 이러한 모델에 예를 직접 제공한다. Alpaca 모델을 평가할 때 섹션 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S2.SS5" title="2.5 Supervised Fine-Tuning and Chinese Alpaca ‣ 2 Chinese LLaMA and Chinese Alpaca ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">2.5</span></a>에서 설명한 대로 프롬프트 템플릿에서 예를 포장합니다. 그런 다음 모델은 한 단계 예측을 하고 다음 토큰 <math alttext="p(y|\bm{x})" class="ltx_Math" display="inline" id="S5.SS2.p1.1.m1.1"><semantics id="S5.SS2.p1.1.m1.1a"><mrow id="S5.SS2.p1.1.m1.1.1" xref="S5.SS2.p1.1.m1.1.1.cmml"><mi id="S5.SS2.p1.1.m1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.3.cmml">p</mi><mo id="S5.SS2.p1.1.m1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.2.cmml">⁢</mo><mrow id="S5.SS2.p1.1.m1.1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.1.1.cmml"><mo id="S5.SS2.p1.1.m1.1.1.1.1.2" stretchy="false" xref="S5.SS2.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S5.SS2.p1.1.m1.1.1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.1.1.cmml"><mi id="S5.SS2.p1.1.m1.1.1.1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S5.SS2.p1.1.m1.1.1.1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.1.1.1.cmml">|</mo><mi id="S5.SS2.p1.1.m1.1.1.1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.1.1.1.3.cmml">𝒙</mi></mrow><mo id="S5.SS2.p1.1.m1.1.1.1.1.3" stretchy="false" xref="S5.SS2.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.1b"><apply id="S5.SS2.p1.1.m1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1"><times id="S5.SS2.p1.1.m1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.2"></times><ci id="S5.SS2.p1.1.m1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.3">𝑝</ci><apply id="S5.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S5.SS2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.1.1">conditional</csymbol><ci id="S5.SS2.p1.1.m1.1.1.1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.1.2">𝑦</ci><ci id="S5.SS2.p1.1.m1.1.1.1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.1.3">𝒙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.1c">p(y|\bm{x})</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.1.m1.1d">italic_p ( italic_y | bold_italic_x )</annotation></semantics></math>, 여기서 <math alttext="y\in\mathcal{V}" class="ltx_Math" display="inline" id="S5.SS2.p1.2.m2.1"><semantics id="S5.SS2.p1.2.m2.1a"><mrow id="S5.SS2.p1.2.m2.1.1" xref="S5.SS2.p1.2.m2.1.1.cmml"><mi id="S5.SS2.p1.2.m2.1.1.2" xref="S5.SS2.p1.2.m2.1.1.2.cmml">y</mi><mo id="S5.SS2.p1.2.m2.1.1.1" xref="S5.SS2.p1.2.m2.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p1.2.m2.1.1.3" xref="S5.SS2.p1.2.m2.1.1.3.cmml">𝒱</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.2.m2.1b"><apply id="S5.SS2.p1.2.m2.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1"><in id="S5.SS2.p1.2.m2.1.1.1.cmml" xref="S5.SS2.p1.2.m2.1.1.1"></in><ci id="S5.SS2.p1.2.m2.1.1.2.cmml" xref="S5.SS2.p1.2.m2.1.1.2">𝑦</ci><ci id="S5.SS2.p1.2.m2.1.1.3.cmml" xref="S5.SS2.p1.2.m2.1.1.3">𝒱</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">y\in\mathcal{V}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.2.m2.1d">italic_y ∈ caligraphic_V</annotation></semantics></math> (<math alttext="\mathcal{V}" class="ltx_Math" display="inline" id="S5.SS2.p1.3.m3.1"><semantics id="S5.SS2.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml">𝒱</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.1b"><ci id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1">𝒱</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.1c">\mathcal{V}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.3.m3.1d">caligraphic_V</annotation></semantics></math>는 어휘)의 확률 분포를 제공하도록 요청받는다. {<span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.6.1">A</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.6.2">B</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.6.3">C</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS2.p1.6.4">D</span>}, 관련 토큰의 확률을 추출하고 수집합니다. 각 라벨 <math alttext="t" class="ltx_Math" display="inline" id="S5.SS2.p1.6.m6.1"><semantics id="S5.SS2.p1.6.m6.1a"><mi id="S5.SS2.p1.6.m6.1.1" xref="S5.SS2.p1.6.m6.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.6.m6.1b"><ci id="S5.SS2.p1.6.m6.1.1.cmml" xref="S5.SS2.p1.6.m6.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.6.m6.1c">t</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.6.m6.1d">italic_t</annotation></semantics></math>를 어휘 내의 토큰에 매핑하기 위해 구두기 <math alttext="\mathcal{V(\cdot)}" class="ltx_Math" display="inline" id="S5.SS2.p1.5.m5.1"><semantics id="S5.SS2.p1.5.m5.1a"><mrow id="S5.SS2.p1.5.m5.1.2" xref="S5.SS2.p1.5.m5.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS2.p1.5.m5.1.2.2" xref="S5.SS2.p1.5.m5.1.2.2.cmml">𝒱</mi><mo id="S5.SS2.p1.5.m5.1.2.1" xref="S5.SS2.p1.5.m5.1.2.1.cmml">⁢</mo><mrow id="S5.SS2.p1.5.m5.1.2.3.2" xref="S5.SS2.p1.5.m5.1.2.cmml"><mo id="S5.SS2.p1.5.m5.1.2.3.2.1" stretchy="false" xref="S5.SS2.p1.5.m5.1.2.cmml">(</mo><mo id="S5.SS2.p1.5.m5.1.1" lspace="0em" rspace="0em" xref="S5.SS2.p1.5.m5.1.1.cmml">⋅</mo><mo id="S5.SS2.p1.5.m5.1.2.3.2.2" stretchy="false" xref="S5.SS2.p1.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.5.m5.1b"><apply id="S5.SS2.p1.5.m5.1.2.cmml" xref="S5.SS2.p1.5.m5.1.2"><times id="S5.SS2.p1.5.m5.1.2.1.cmml" xref="S5.SS2.p1.5.m5.1.2.1"></times><ci id="S5.SS2.p1.5.m5.1.2.2.cmml" xref="S5.SS2.p1.5.m5.1.2.2">𝒱</ci><ci id="S5.SS2.p1.5.m5.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.5.m5.1c">\mathcal{V(\cdot)}</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p1.5.m5.1d">caligraphic_V ( ⋅ )</annotation></semantics></math>를 도입한다:</p>
<table class="ltx_equation ltx_eqn_table" id="S5.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{V}(\texttt{A})=\{\textrm{`A'},`\textrm{\raisebox{0.0pt}{\rule{10.0000%
2pt}{1.25pt}}A'}\},\ \ \mathcal{V}(\texttt{B})=\{\textrm{`B'},`\textrm{%
\raisebox{0.0pt}{\rule{10.00002pt}{1.25pt}}B'}\},\ \ \mathcal{V}(\texttt{C})=%
\{\textrm{`C'},`\textrm{\raisebox{0.0pt}{\rule{10.00002pt}{1.25pt}}C'}\},\ \ %
\mathcal{V}(\texttt{D})=\{\textrm{`D'},`\textrm{\raisebox{0.0pt}{\rule{10.0000%
2pt}{1.25pt}}D'}\}" class="ltx_Math" display="block" id="S5.Ex1.m1.10"><semantics id="S5.Ex1.m1.10a"><mrow id="S5.Ex1.m1.10.10.2" xref="S5.Ex1.m1.10.10.3.cmml"><mrow id="S5.Ex1.m1.9.9.1.1" xref="S5.Ex1.m1.9.9.1.1.cmml"><mrow id="S5.Ex1.m1.9.9.1.1.3" xref="S5.Ex1.m1.9.9.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.Ex1.m1.9.9.1.1.3.2" xref="S5.Ex1.m1.9.9.1.1.3.2.cmml">𝒱</mi><mo id="S5.Ex1.m1.9.9.1.1.3.1" xref="S5.Ex1.m1.9.9.1.1.3.1.cmml">⁢</mo><mrow id="S5.Ex1.m1.9.9.1.1.3.3.2" xref="S5.Ex1.m1.1.1a.cmml"><mo id="S5.Ex1.m1.9.9.1.1.3.3.2.1" stretchy="false" xref="S5.Ex1.m1.1.1a.cmml">(</mo><mtext id="S5.Ex1.m1.1.1" xref="S5.Ex1.m1.1.1.cmml">𝙰</mtext><mo id="S5.Ex1.m1.9.9.1.1.3.3.2.2" stretchy="false" xref="S5.Ex1.m1.1.1a.cmml">)</mo></mrow></mrow><mo id="S5.Ex1.m1.9.9.1.1.2" xref="S5.Ex1.m1.9.9.1.1.2.cmml">=</mo><mrow id="S5.Ex1.m1.9.9.1.1.1.1" xref="S5.Ex1.m1.9.9.1.1.1.2.cmml"><mo id="S5.Ex1.m1.9.9.1.1.1.1.2" stretchy="false" xref="S5.Ex1.m1.9.9.1.1.1.2.cmml">{</mo><mtext id="S5.Ex1.m1.2.2" xref="S5.Ex1.m1.2.2a.cmml">‘A’</mtext><mo id="S5.Ex1.m1.9.9.1.1.1.1.3" xref="S5.Ex1.m1.9.9.1.1.1.2.cmml">,</mo><mrow id="S5.Ex1.m1.9.9.1.1.1.1.1" xref="S5.Ex1.m1.9.9.1.1.1.1.1.cmml"><mi id="S5.Ex1.m1.9.9.1.1.1.1.1.2" mathvariant="normal" xref="S5.Ex1.m1.9.9.1.1.1.1.1.2.cmml">`</mi><mo id="S5.Ex1.m1.9.9.1.1.1.1.1.1" xref="S5.Ex1.m1.9.9.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S5.Ex1.m1.9.9.1.1.1.1.1.3" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3e.cmml"><mpadded id="S5.Ex1.m1.9.9.1.1.1.1.1.3a" voffset="0.0pt" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3e.cmml"><mtext id="S5.Ex1.m1.9.9.1.1.1.1.1.3b" mathcolor="red" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3e.cmml"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.9.9.1.1.1.1.1.3d" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3e.cmml">A’</mtext></mrow></mrow><mo id="S5.Ex1.m1.9.9.1.1.1.1.4" stretchy="false" xref="S5.Ex1.m1.9.9.1.1.1.2.cmml">}</mo></mrow></mrow><mo id="S5.Ex1.m1.10.10.2.3" rspace="1.167em" xref="S5.Ex1.m1.10.10.3a.cmml">,</mo><mrow id="S5.Ex1.m1.10.10.2.2.2" xref="S5.Ex1.m1.10.10.2.2.3.cmml"><mrow id="S5.Ex1.m1.10.10.2.2.1.1" xref="S5.Ex1.m1.10.10.2.2.1.1.cmml"><mrow id="S5.Ex1.m1.10.10.2.2.1.1.3" xref="S5.Ex1.m1.10.10.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.Ex1.m1.10.10.2.2.1.1.3.2" xref="S5.Ex1.m1.10.10.2.2.1.1.3.2.cmml">𝒱</mi><mo id="S5.Ex1.m1.10.10.2.2.1.1.3.1" xref="S5.Ex1.m1.10.10.2.2.1.1.3.1.cmml">⁢</mo><mrow id="S5.Ex1.m1.10.10.2.2.1.1.3.3.2" xref="S5.Ex1.m1.3.3a.cmml"><mo id="S5.Ex1.m1.10.10.2.2.1.1.3.3.2.1" stretchy="false" xref="S5.Ex1.m1.3.3a.cmml">(</mo><mtext id="S5.Ex1.m1.3.3" xref="S5.Ex1.m1.3.3.cmml">𝙱</mtext><mo id="S5.Ex1.m1.10.10.2.2.1.1.3.3.2.2" stretchy="false" xref="S5.Ex1.m1.3.3a.cmml">)</mo></mrow></mrow><mo id="S5.Ex1.m1.10.10.2.2.1.1.2" xref="S5.Ex1.m1.10.10.2.2.1.1.2.cmml">=</mo><mrow id="S5.Ex1.m1.10.10.2.2.1.1.1.1" xref="S5.Ex1.m1.10.10.2.2.1.1.1.2.cmml"><mo id="S5.Ex1.m1.10.10.2.2.1.1.1.1.2" stretchy="false" xref="S5.Ex1.m1.10.10.2.2.1.1.1.2.cmml">{</mo><mtext id="S5.Ex1.m1.4.4" xref="S5.Ex1.m1.4.4a.cmml">‘B’</mtext><mo id="S5.Ex1.m1.10.10.2.2.1.1.1.1.3" xref="S5.Ex1.m1.10.10.2.2.1.1.1.2.cmml">,</mo><mrow id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.cmml"><mi id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.2" mathvariant="normal" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.2.cmml">`</mi><mo id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.1" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3e.cmml"><mpadded id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3a" voffset="0.0pt" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3e.cmml"><mtext id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3b" mathcolor="red" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3e.cmml"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3d" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3e.cmml">B’</mtext></mrow></mrow><mo id="S5.Ex1.m1.10.10.2.2.1.1.1.1.4" stretchy="false" xref="S5.Ex1.m1.10.10.2.2.1.1.1.2.cmml">}</mo></mrow></mrow><mo id="S5.Ex1.m1.10.10.2.2.2.3" rspace="1.167em" xref="S5.Ex1.m1.10.10.2.2.3a.cmml">,</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2" xref="S5.Ex1.m1.10.10.2.2.2.2.3.cmml"><mrow id="S5.Ex1.m1.10.10.2.2.2.2.1.1" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.cmml"><mrow id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.2" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.2.cmml">𝒱</mi><mo id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.1" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.1.cmml">⁢</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.3.2" xref="S5.Ex1.m1.5.5a.cmml"><mo id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.3.2.1" stretchy="false" xref="S5.Ex1.m1.5.5a.cmml">(</mo><mtext id="S5.Ex1.m1.5.5" xref="S5.Ex1.m1.5.5.cmml">𝙲</mtext><mo id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.3.2.2" stretchy="false" xref="S5.Ex1.m1.5.5a.cmml">)</mo></mrow></mrow><mo id="S5.Ex1.m1.10.10.2.2.2.2.1.1.2" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.2.cmml">=</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.2.cmml"><mo id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.2" stretchy="false" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.2.cmml">{</mo><mtext id="S5.Ex1.m1.6.6" xref="S5.Ex1.m1.6.6a.cmml">‘C’</mtext><mo id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.3" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.2.cmml">,</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.cmml"><mi id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.2" mathvariant="normal" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.2.cmml">`</mi><mo id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.1" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3e.cmml"><mpadded id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3a" voffset="0.0pt" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3e.cmml"><mtext id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3b" mathcolor="red" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3e.cmml"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3d" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3e.cmml">C’</mtext></mrow></mrow><mo id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.4" stretchy="false" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.2.cmml">}</mo></mrow></mrow><mo id="S5.Ex1.m1.10.10.2.2.2.2.2.3" rspace="1.167em" xref="S5.Ex1.m1.10.10.2.2.2.2.3a.cmml">,</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2.2" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.cmml"><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.2" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.2.cmml">𝒱</mi><mo id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.1" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.1.cmml">⁢</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.3.2" xref="S5.Ex1.m1.7.7a.cmml"><mo id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.3.2.1" stretchy="false" xref="S5.Ex1.m1.7.7a.cmml">(</mo><mtext id="S5.Ex1.m1.7.7" xref="S5.Ex1.m1.7.7.cmml">𝙳</mtext><mo id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.3.2.2" stretchy="false" xref="S5.Ex1.m1.7.7a.cmml">)</mo></mrow></mrow><mo id="S5.Ex1.m1.10.10.2.2.2.2.2.2.2" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.2.cmml">=</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.2.cmml"><mo id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.2" stretchy="false" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.2.cmml">{</mo><mtext id="S5.Ex1.m1.8.8" xref="S5.Ex1.m1.8.8a.cmml">‘D’</mtext><mo id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.3" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.2.cmml">,</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.cmml"><mi id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.2" mathvariant="normal" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.2.cmml">`</mi><mo id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.1" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.1.cmml">⁢</mo><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3e.cmml"><mpadded id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3a" voffset="0.0pt" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3e.cmml"><mtext id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3b" mathcolor="red" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3e.cmml"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3d" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3e.cmml">D’</mtext></mrow></mrow><mo id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.4" stretchy="false" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.2.cmml">}</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.Ex1.m1.10b"><apply id="S5.Ex1.m1.10.10.3.cmml" xref="S5.Ex1.m1.10.10.2"><csymbol cd="ambiguous" id="S5.Ex1.m1.10.10.3a.cmml" xref="S5.Ex1.m1.10.10.2.3">formulae-sequence</csymbol><apply id="S5.Ex1.m1.9.9.1.1.cmml" xref="S5.Ex1.m1.9.9.1.1"><eq id="S5.Ex1.m1.9.9.1.1.2.cmml" xref="S5.Ex1.m1.9.9.1.1.2"></eq><apply id="S5.Ex1.m1.9.9.1.1.3.cmml" xref="S5.Ex1.m1.9.9.1.1.3"><times id="S5.Ex1.m1.9.9.1.1.3.1.cmml" xref="S5.Ex1.m1.9.9.1.1.3.1"></times><ci id="S5.Ex1.m1.9.9.1.1.3.2.cmml" xref="S5.Ex1.m1.9.9.1.1.3.2">𝒱</ci><ci id="S5.Ex1.m1.1.1a.cmml" xref="S5.Ex1.m1.9.9.1.1.3.3.2"><mtext id="S5.Ex1.m1.1.1.cmml" xref="S5.Ex1.m1.1.1">𝙰</mtext></ci></apply><set id="S5.Ex1.m1.9.9.1.1.1.2.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1"><ci id="S5.Ex1.m1.2.2a.cmml" xref="S5.Ex1.m1.2.2"><mtext id="S5.Ex1.m1.2.2.cmml" xref="S5.Ex1.m1.2.2">‘A’</mtext></ci><apply id="S5.Ex1.m1.9.9.1.1.1.1.1.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1.1"><times id="S5.Ex1.m1.9.9.1.1.1.1.1.1.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1.1.1"></times><ci id="S5.Ex1.m1.9.9.1.1.1.1.1.2.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1.1.2">`</ci><ci id="S5.Ex1.m1.9.9.1.1.1.1.1.3e.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3"><mrow id="S5.Ex1.m1.9.9.1.1.1.1.1.3.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3"><mpadded id="S5.Ex1.m1.9.9.1.1.1.1.1.3a.cmml" voffset="0.0pt" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3"><mtext id="S5.Ex1.m1.9.9.1.1.1.1.1.3b.cmml" mathcolor="red" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.9.9.1.1.1.1.1.3d.cmml" xref="S5.Ex1.m1.9.9.1.1.1.1.1.3">A’</mtext></mrow></ci></apply></set></apply><apply id="S5.Ex1.m1.10.10.2.2.3.cmml" xref="S5.Ex1.m1.10.10.2.2.2"><csymbol cd="ambiguous" id="S5.Ex1.m1.10.10.2.2.3a.cmml" xref="S5.Ex1.m1.10.10.2.2.2.3">formulae-sequence</csymbol><apply id="S5.Ex1.m1.10.10.2.2.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1"><eq id="S5.Ex1.m1.10.10.2.2.1.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.2"></eq><apply id="S5.Ex1.m1.10.10.2.2.1.1.3.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.3"><times id="S5.Ex1.m1.10.10.2.2.1.1.3.1.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.3.1"></times><ci id="S5.Ex1.m1.10.10.2.2.1.1.3.2.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.3.2">𝒱</ci><ci id="S5.Ex1.m1.3.3a.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.3.3.2"><mtext id="S5.Ex1.m1.3.3.cmml" xref="S5.Ex1.m1.3.3">𝙱</mtext></ci></apply><set id="S5.Ex1.m1.10.10.2.2.1.1.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1"><ci id="S5.Ex1.m1.4.4a.cmml" xref="S5.Ex1.m1.4.4"><mtext id="S5.Ex1.m1.4.4.cmml" xref="S5.Ex1.m1.4.4">‘B’</mtext></ci><apply id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1"><times id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.1"></times><ci id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.2">`</ci><ci id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3e.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3"><mrow id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3"><mpadded id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3a.cmml" voffset="0.0pt" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3"><mtext id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3b.cmml" mathcolor="red" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3d.cmml" xref="S5.Ex1.m1.10.10.2.2.1.1.1.1.1.3">B’</mtext></mrow></ci></apply></set></apply><apply id="S5.Ex1.m1.10.10.2.2.2.2.3.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2"><csymbol cd="ambiguous" id="S5.Ex1.m1.10.10.2.2.2.2.3a.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.3">formulae-sequence</csymbol><apply id="S5.Ex1.m1.10.10.2.2.2.2.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1"><eq id="S5.Ex1.m1.10.10.2.2.2.2.1.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.2"></eq><apply id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.3"><times id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.1.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.1"></times><ci id="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.2">𝒱</ci><ci id="S5.Ex1.m1.5.5a.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.3.3.2"><mtext id="S5.Ex1.m1.5.5.cmml" xref="S5.Ex1.m1.5.5">𝙲</mtext></ci></apply><set id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1"><ci id="S5.Ex1.m1.6.6a.cmml" xref="S5.Ex1.m1.6.6"><mtext id="S5.Ex1.m1.6.6.cmml" xref="S5.Ex1.m1.6.6">‘C’</mtext></ci><apply id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1"><times id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.1"></times><ci id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.2">`</ci><ci id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3e.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3"><mrow id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3"><mpadded id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3a.cmml" voffset="0.0pt" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3"><mtext id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3b.cmml" mathcolor="red" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3d.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.1.1.1.1.1.3">C’</mtext></mrow></ci></apply></set></apply><apply id="S5.Ex1.m1.10.10.2.2.2.2.2.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2"><eq id="S5.Ex1.m1.10.10.2.2.2.2.2.2.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.2"></eq><apply id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.3"><times id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.1.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.1"></times><ci id="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.2">𝒱</ci><ci id="S5.Ex1.m1.7.7a.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.3.3.2"><mtext id="S5.Ex1.m1.7.7.cmml" xref="S5.Ex1.m1.7.7">𝙳</mtext></ci></apply><set id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1"><ci id="S5.Ex1.m1.8.8a.cmml" xref="S5.Ex1.m1.8.8"><mtext id="S5.Ex1.m1.8.8.cmml" xref="S5.Ex1.m1.8.8">‘D’</mtext></ci><apply id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1"><times id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.1.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.1"></times><ci id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.2.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.2">`</ci><ci id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3e.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3"><mrow id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3"><mpadded id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3a.cmml" voffset="0.0pt" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3"><mtext id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3b.cmml" mathcolor="red" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3"><span class="ltx_rule" style="width:10.0pt;height:1.3pt;background:black;display:inline-block;">&nbsp;</span></mtext></mpadded><mtext id="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3d.cmml" xref="S5.Ex1.m1.10.10.2.2.2.2.2.2.1.1.1.3">D’</mtext></mrow></ci></apply></set></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.Ex1.m1.10c">\mathcal{V}(\texttt{A})=\{\textrm{`A'},`\textrm{\raisebox{0.0pt}{\rule{10.0000%
2pt}{1.25pt}}A'}\},\ \ \mathcal{V}(\texttt{B})=\{\textrm{`B'},`\textrm{%
\raisebox{0.0pt}{\rule{10.00002pt}{1.25pt}}B'}\},\ \ \mathcal{V}(\texttt{C})=%
\{\textrm{`C'},`\textrm{\raisebox{0.0pt}{\rule{10.00002pt}{1.25pt}}C'}\},\ \ %
\mathcal{V}(\texttt{D})=\{\textrm{`D'},`\textrm{\raisebox{0.0pt}{\rule{10.0000%
2pt}{1.25pt}}D'}\}</annotation><annotation encoding="application/x-llamapun" id="S5.Ex1.m1.10d">caligraphic_V ( A ) = { ‘A’ , ` A’ } , caligraphic_V ( B ) = { ‘B’ , ` B’ } , caligraphic_V ( C ) = { ‘C’ , ` C’ } , caligraphic_V ( D ) = { ‘D’ , ` D’ }</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">라벨 <math alttext="t" class="ltx_Math" display="inline" id="S5.SS2.p2.1.m1.1"><semantics id="S5.SS2.p2.1.m1.1a"><mi id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><ci id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.1.m1.1d">italic_t</annotation></semantics></math>를 예측할 확률은 다음과 같이 주어진다.</p>
<table class="ltx_equation ltx_eqn_table" id="S5.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="p(t\in\{\texttt{A},\texttt{B},\texttt{C},\texttt{D}\}|\bm{x})=\sum_{t\in%
\mathcal{V}(i)}p(y=i|\bm{x})" class="ltx_Math" display="block" id="S5.E4.m1.7"><semantics id="S5.E4.m1.7a"><mrow id="S5.E4.m1.7.7" xref="S5.E4.m1.7.7.cmml"><mrow id="S5.E4.m1.6.6.1" xref="S5.E4.m1.6.6.1.cmml"><mi id="S5.E4.m1.6.6.1.3" xref="S5.E4.m1.6.6.1.3.cmml">p</mi><mo id="S5.E4.m1.6.6.1.2" xref="S5.E4.m1.6.6.1.2.cmml">⁢</mo><mrow id="S5.E4.m1.6.6.1.1.1" xref="S5.E4.m1.6.6.1.1.1.1.cmml"><mo id="S5.E4.m1.6.6.1.1.1.2" stretchy="false" xref="S5.E4.m1.6.6.1.1.1.1.cmml">(</mo><mrow id="S5.E4.m1.6.6.1.1.1.1" xref="S5.E4.m1.6.6.1.1.1.1.cmml"><mi id="S5.E4.m1.6.6.1.1.1.1.2" xref="S5.E4.m1.6.6.1.1.1.1.2.cmml">t</mi><mo id="S5.E4.m1.6.6.1.1.1.1.1" xref="S5.E4.m1.6.6.1.1.1.1.1.cmml">∈</mo><mrow id="S5.E4.m1.6.6.1.1.1.1.3" xref="S5.E4.m1.6.6.1.1.1.1.3.cmml"><mrow id="S5.E4.m1.6.6.1.1.1.1.3.2.2" xref="S5.E4.m1.6.6.1.1.1.1.3.2.1.cmml"><mo id="S5.E4.m1.6.6.1.1.1.1.3.2.2.1" stretchy="false" xref="S5.E4.m1.6.6.1.1.1.1.3.2.1.cmml">{</mo><mtext id="S5.E4.m1.2.2" xref="S5.E4.m1.2.2a.cmml">𝙰</mtext><mo id="S5.E4.m1.6.6.1.1.1.1.3.2.2.2" xref="S5.E4.m1.6.6.1.1.1.1.3.2.1.cmml">,</mo><mtext id="S5.E4.m1.3.3" xref="S5.E4.m1.3.3a.cmml">𝙱</mtext><mo id="S5.E4.m1.6.6.1.1.1.1.3.2.2.3" xref="S5.E4.m1.6.6.1.1.1.1.3.2.1.cmml">,</mo><mtext id="S5.E4.m1.4.4" xref="S5.E4.m1.4.4a.cmml">𝙲</mtext><mo id="S5.E4.m1.6.6.1.1.1.1.3.2.2.4" xref="S5.E4.m1.6.6.1.1.1.1.3.2.1.cmml">,</mo><mtext id="S5.E4.m1.5.5" xref="S5.E4.m1.5.5a.cmml">𝙳</mtext><mo id="S5.E4.m1.6.6.1.1.1.1.3.2.2.5" stretchy="false" xref="S5.E4.m1.6.6.1.1.1.1.3.2.1.cmml">}</mo></mrow><mo fence="false" id="S5.E4.m1.6.6.1.1.1.1.3.1" xref="S5.E4.m1.6.6.1.1.1.1.3.1.cmml">|</mo><mi id="S5.E4.m1.6.6.1.1.1.1.3.3" xref="S5.E4.m1.6.6.1.1.1.1.3.3.cmml">𝒙</mi></mrow></mrow><mo id="S5.E4.m1.6.6.1.1.1.3" stretchy="false" xref="S5.E4.m1.6.6.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.E4.m1.7.7.3" rspace="0.111em" xref="S5.E4.m1.7.7.3.cmml">=</mo><mrow id="S5.E4.m1.7.7.2" xref="S5.E4.m1.7.7.2.cmml"><munder id="S5.E4.m1.7.7.2.2" xref="S5.E4.m1.7.7.2.2.cmml"><mo id="S5.E4.m1.7.7.2.2.2" movablelimits="false" xref="S5.E4.m1.7.7.2.2.2.cmml">∑</mo><mrow id="S5.E4.m1.1.1.1" xref="S5.E4.m1.1.1.1.cmml"><mi id="S5.E4.m1.1.1.1.3" xref="S5.E4.m1.1.1.1.3.cmml">t</mi><mo id="S5.E4.m1.1.1.1.2" xref="S5.E4.m1.1.1.1.2.cmml">∈</mo><mrow id="S5.E4.m1.1.1.1.4" xref="S5.E4.m1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E4.m1.1.1.1.4.2" xref="S5.E4.m1.1.1.1.4.2.cmml">𝒱</mi><mo id="S5.E4.m1.1.1.1.4.1" xref="S5.E4.m1.1.1.1.4.1.cmml">⁢</mo><mrow id="S5.E4.m1.1.1.1.4.3.2" xref="S5.E4.m1.1.1.1.4.cmml"><mo id="S5.E4.m1.1.1.1.4.3.2.1" stretchy="false" xref="S5.E4.m1.1.1.1.4.cmml">(</mo><mi id="S5.E4.m1.1.1.1.1" xref="S5.E4.m1.1.1.1.1.cmml">i</mi><mo id="S5.E4.m1.1.1.1.4.3.2.2" stretchy="false" xref="S5.E4.m1.1.1.1.4.cmml">)</mo></mrow></mrow></mrow></munder><mrow id="S5.E4.m1.7.7.2.1" xref="S5.E4.m1.7.7.2.1.cmml"><mi id="S5.E4.m1.7.7.2.1.3" xref="S5.E4.m1.7.7.2.1.3.cmml">p</mi><mo id="S5.E4.m1.7.7.2.1.2" xref="S5.E4.m1.7.7.2.1.2.cmml">⁢</mo><mrow id="S5.E4.m1.7.7.2.1.1.1" xref="S5.E4.m1.7.7.2.1.1.1.1.cmml"><mo id="S5.E4.m1.7.7.2.1.1.1.2" stretchy="false" xref="S5.E4.m1.7.7.2.1.1.1.1.cmml">(</mo><mrow id="S5.E4.m1.7.7.2.1.1.1.1" xref="S5.E4.m1.7.7.2.1.1.1.1.cmml"><mi id="S5.E4.m1.7.7.2.1.1.1.1.2" xref="S5.E4.m1.7.7.2.1.1.1.1.2.cmml">y</mi><mo id="S5.E4.m1.7.7.2.1.1.1.1.1" xref="S5.E4.m1.7.7.2.1.1.1.1.1.cmml">=</mo><mrow id="S5.E4.m1.7.7.2.1.1.1.1.3" xref="S5.E4.m1.7.7.2.1.1.1.1.3.cmml"><mi id="S5.E4.m1.7.7.2.1.1.1.1.3.2" xref="S5.E4.m1.7.7.2.1.1.1.1.3.2.cmml">i</mi><mo fence="false" id="S5.E4.m1.7.7.2.1.1.1.1.3.1" xref="S5.E4.m1.7.7.2.1.1.1.1.3.1.cmml">|</mo><mi id="S5.E4.m1.7.7.2.1.1.1.1.3.3" xref="S5.E4.m1.7.7.2.1.1.1.1.3.3.cmml">𝒙</mi></mrow></mrow><mo id="S5.E4.m1.7.7.2.1.1.1.3" stretchy="false" xref="S5.E4.m1.7.7.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.E4.m1.7b"><apply id="S5.E4.m1.7.7.cmml" xref="S5.E4.m1.7.7"><eq id="S5.E4.m1.7.7.3.cmml" xref="S5.E4.m1.7.7.3"></eq><apply id="S5.E4.m1.6.6.1.cmml" xref="S5.E4.m1.6.6.1"><times id="S5.E4.m1.6.6.1.2.cmml" xref="S5.E4.m1.6.6.1.2"></times><ci id="S5.E4.m1.6.6.1.3.cmml" xref="S5.E4.m1.6.6.1.3">𝑝</ci><apply id="S5.E4.m1.6.6.1.1.1.1.cmml" xref="S5.E4.m1.6.6.1.1.1"><in id="S5.E4.m1.6.6.1.1.1.1.1.cmml" xref="S5.E4.m1.6.6.1.1.1.1.1"></in><ci id="S5.E4.m1.6.6.1.1.1.1.2.cmml" xref="S5.E4.m1.6.6.1.1.1.1.2">𝑡</ci><apply id="S5.E4.m1.6.6.1.1.1.1.3.cmml" xref="S5.E4.m1.6.6.1.1.1.1.3"><csymbol cd="latexml" id="S5.E4.m1.6.6.1.1.1.1.3.1.cmml" xref="S5.E4.m1.6.6.1.1.1.1.3.1">conditional</csymbol><set id="S5.E4.m1.6.6.1.1.1.1.3.2.1.cmml" xref="S5.E4.m1.6.6.1.1.1.1.3.2.2"><ci id="S5.E4.m1.2.2a.cmml" xref="S5.E4.m1.2.2"><mtext id="S5.E4.m1.2.2.cmml" xref="S5.E4.m1.2.2">𝙰</mtext></ci><ci id="S5.E4.m1.3.3a.cmml" xref="S5.E4.m1.3.3"><mtext id="S5.E4.m1.3.3.cmml" xref="S5.E4.m1.3.3">𝙱</mtext></ci><ci id="S5.E4.m1.4.4a.cmml" xref="S5.E4.m1.4.4"><mtext id="S5.E4.m1.4.4.cmml" xref="S5.E4.m1.4.4">𝙲</mtext></ci><ci id="S5.E4.m1.5.5a.cmml" xref="S5.E4.m1.5.5"><mtext id="S5.E4.m1.5.5.cmml" xref="S5.E4.m1.5.5">𝙳</mtext></ci></set><ci id="S5.E4.m1.6.6.1.1.1.1.3.3.cmml" xref="S5.E4.m1.6.6.1.1.1.1.3.3">𝒙</ci></apply></apply></apply><apply id="S5.E4.m1.7.7.2.cmml" xref="S5.E4.m1.7.7.2"><apply id="S5.E4.m1.7.7.2.2.cmml" xref="S5.E4.m1.7.7.2.2"><csymbol cd="ambiguous" id="S5.E4.m1.7.7.2.2.1.cmml" xref="S5.E4.m1.7.7.2.2">subscript</csymbol><sum id="S5.E4.m1.7.7.2.2.2.cmml" xref="S5.E4.m1.7.7.2.2.2"></sum><apply id="S5.E4.m1.1.1.1.cmml" xref="S5.E4.m1.1.1.1"><in id="S5.E4.m1.1.1.1.2.cmml" xref="S5.E4.m1.1.1.1.2"></in><ci id="S5.E4.m1.1.1.1.3.cmml" xref="S5.E4.m1.1.1.1.3">𝑡</ci><apply id="S5.E4.m1.1.1.1.4.cmml" xref="S5.E4.m1.1.1.1.4"><times id="S5.E4.m1.1.1.1.4.1.cmml" xref="S5.E4.m1.1.1.1.4.1"></times><ci id="S5.E4.m1.1.1.1.4.2.cmml" xref="S5.E4.m1.1.1.1.4.2">𝒱</ci><ci id="S5.E4.m1.1.1.1.1.cmml" xref="S5.E4.m1.1.1.1.1">𝑖</ci></apply></apply></apply><apply id="S5.E4.m1.7.7.2.1.cmml" xref="S5.E4.m1.7.7.2.1"><times id="S5.E4.m1.7.7.2.1.2.cmml" xref="S5.E4.m1.7.7.2.1.2"></times><ci id="S5.E4.m1.7.7.2.1.3.cmml" xref="S5.E4.m1.7.7.2.1.3">𝑝</ci><apply id="S5.E4.m1.7.7.2.1.1.1.1.cmml" xref="S5.E4.m1.7.7.2.1.1.1"><eq id="S5.E4.m1.7.7.2.1.1.1.1.1.cmml" xref="S5.E4.m1.7.7.2.1.1.1.1.1"></eq><ci id="S5.E4.m1.7.7.2.1.1.1.1.2.cmml" xref="S5.E4.m1.7.7.2.1.1.1.1.2">𝑦</ci><apply id="S5.E4.m1.7.7.2.1.1.1.1.3.cmml" xref="S5.E4.m1.7.7.2.1.1.1.1.3"><csymbol cd="latexml" id="S5.E4.m1.7.7.2.1.1.1.1.3.1.cmml" xref="S5.E4.m1.7.7.2.1.1.1.1.3.1">conditional</csymbol><ci id="S5.E4.m1.7.7.2.1.1.1.1.3.2.cmml" xref="S5.E4.m1.7.7.2.1.1.1.1.3.2">𝑖</ci><ci id="S5.E4.m1.7.7.2.1.1.1.1.3.3.cmml" xref="S5.E4.m1.7.7.2.1.1.1.1.3.3">𝒙</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E4.m1.7c">p(t\in\{\texttt{A},\texttt{B},\texttt{C},\texttt{D}\}|\bm{x})=\sum_{t\in%
\mathcal{V}(i)}p(y=i|\bm{x})</annotation><annotation encoding="application/x-llamapun" id="S5.E4.m1.7d">italic_p ( italic_t ∈ { A , B , C , D } | bold_italic_x ) = ∑ start_POSTSUBSCRIPT italic_t ∈ caligraphic_V ( italic_i ) end_POSTSUBSCRIPT italic_p ( italic_y = italic_i | bold_italic_x )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.SS2.p2.2">최대 확률을 갖는 라벨은 최종 예측으로 취해진다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">다음으로, 원래의 LLaMA 및 기타 모델과의 비교를 설명하기 위해 다음 두 하위 섹션에서 결과와 분석에 대해 자세히 설명한다.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Comparisons to Original LLaMA</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">그림 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S5.F3" title="Figure 3 ‣ 5.3 Comparisons to Original LLaMA ‣ 5 Results on Natural Language Understanding Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">3</span></a>는 우리 모델이 원래 LLaMA를 기반으로 어떻게 진화하는지 보여준다. 상세한 결과는 표 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S5.T8" title="Table 8 ‣ 5.3 Comparisons to Original LLaMA ‣ 5 Results on Natural Language Understanding Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">8</span></a>에 묘사되어 있다. 우리는 주로 다음 측면에서 우리의 연구 결과를 설명한다.</p>
</div>
<figure class="ltx_figure" id="S5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="337" id="S5.F3.g1" src="https://arxiv.org/html/2304.08177v3/x2.png" width="706">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span> <span class="ltx_text ltx_font_bold" id="S5.F3.2.1">Results on C-Eval valid set.</span> The results are grouped by different settings (zero-shot and 5-shot) and model sizes (7B and 13B). </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S5.T8">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span> <span class="ltx_text ltx_font_bold" id="S5.T8.2.1">Results on C-Eval valid and test sets</span>. All prediction files are generated by ourselves. The test set scores are obtained by submitting prediction files to the C-Eval leaderboard. </figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T8.3">
<tbody><tr class="ltx_tr" id="S5.T8.3.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T8.3.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S5.T8.3.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T8.3.1.2"><span class="ltx_text ltx_font_bold" id="S5.T8.3.1.2.1">Valid Set</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S5.T8.3.1.3"><span class="ltx_text ltx_font_bold" id="S5.T8.3.1.3.1">Test Set</span></td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.2">
<td class="ltx_td ltx_align_center" id="S5.T8.3.2.1"><span class="ltx_text ltx_font_bold" id="S5.T8.3.2.1.1">Zero-shot</span></td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.2.2"><span class="ltx_text ltx_font_bold" id="S5.T8.3.2.2.1">5-shot</span></td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.2.3"><span class="ltx_text ltx_font_bold" id="S5.T8.3.2.3.1">Zero-shot</span></td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.2.4"><span class="ltx_text ltx_font_bold" id="S5.T8.3.2.4.1">5-shot</span></td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T8.3.3.1"><span class="ltx_text ltx_font_italic" id="S5.T8.3.3.1.1">Random</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.3.2"><span class="ltx_text ltx_font_italic" id="S5.T8.3.3.2.1">25.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.3.3"><span class="ltx_text ltx_font_italic" id="S5.T8.3.3.3.1">25.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.3.4"><span class="ltx_text ltx_font_italic" id="S5.T8.3.3.4.1">25.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.3.5"><span class="ltx_text ltx_font_italic" id="S5.T8.3.3.5.1">25.0</span></td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T8.3.4.1">LLaMA-65B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.4.2">37.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.4.3">41.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.4.4">33.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.4.5">38.8</td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.5">
<td class="ltx_td ltx_align_left" id="S5.T8.3.5.1">LLaMA-33B</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.5.2">34.5</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.5.3">37.9</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.5.4">32.4</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.5.5">36.0</td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.6">
<td class="ltx_td ltx_align_left" id="S5.T8.3.6.1">LLaMA-13B</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.6.2">27.8</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.6.3">30.9</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.6.4">28.5</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.6.5">29.6</td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.7">
<td class="ltx_td ltx_align_left" id="S5.T8.3.7.1">LLaMA-7B</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.7.2">25.6</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.7.3">25.3</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.7.4">26.7</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.7.5">27.8</td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T8.3.8.1">Chinese-LLaMA-33B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.8.2">34.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.8.3">38.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.8.4">34.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.8.5">39.5</td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.9">
<td class="ltx_td ltx_align_left" id="S5.T8.3.9.1">Chinese-LLaMA-Plus-13B</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.9.2">27.3</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.9.3">34.0</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.9.4">27.8</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.9.5">33.3</td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.10">
<td class="ltx_td ltx_align_left" id="S5.T8.3.10.1">Chinese-LLaMA-13B</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.10.2">29.4</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.10.3">35.0</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.10.4">29.2</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.10.5">33.7</td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.11">
<td class="ltx_td ltx_align_left" id="S5.T8.3.11.1">Chinese-LLaMA-Plus-7B</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.11.2">27.3</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.11.3">28.3</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.11.4">26.8</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.11.5">28.4</td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.12">
<td class="ltx_td ltx_align_left" id="S5.T8.3.12.1">Chinese-LLaMA-7B</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.12.2">26.2</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.12.3">26.2</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.12.4">27.1</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.12.5">27.2</td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.13">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T8.3.13.1">Chinese-Alpaca-33B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.13.2">43.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.13.3">42.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.13.4">41.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T8.3.13.5">40.4</td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.14">
<td class="ltx_td ltx_align_left" id="S5.T8.3.14.1">Chinese-Alpaca-Plus-13B</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.14.2">43.3</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.14.3">42.4</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.14.4">41.5</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.14.5">39.9</td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.15">
<td class="ltx_td ltx_align_left" id="S5.T8.3.15.1">Chinese-Alpaca-13B</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.15.2">37.1</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.15.3">36.3</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.15.4">36.7</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.15.5">34.5</td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.16">
<td class="ltx_td ltx_align_left" id="S5.T8.3.16.1">Chinese-Alpaca-Plus-7B</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.16.2">36.7</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.16.3">32.9</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.16.4">36.4</td>
<td class="ltx_td ltx_align_center" id="S5.T8.3.16.5">32.3</td>
</tr>
<tr class="ltx_tr" id="S5.T8.3.17">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T8.3.17.1">Chinese-Alpaca-7B</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.3.17.2">30.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.3.17.3">32.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.3.17.4">30.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T8.3.17.5">29.2</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S5.SS3.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Chinese LLaMA improves original LLaMA.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS3.SSS0.Px1.p1.1">우리는 제안된 중국 LLaMA 모델이 원래 LLaMA에 비해 중간 정도의 개선을 가져온다는 것을 알 수 있으며, 이는 중국 데이터에 대한 사전 훈련이 C-Eval에 약간의 긍정적인 영향을 미치지만 항상 그렇지는 않다는 것을 보여준다. 중국 LLaMA와 LLaMA-Plus를 비교했을 때, 후자는 13B 설정에서 열등한 결과를 보이더라도 전자에 비해 큰 개선을 보이지 않는다. 이는 순수 언어 모델(LLaMA와 같은)이 C-Eval 또는 유사한 작업에 대해 좋은 선택이 아닐 수 있음을 나타낼 수 있으며 사전 훈련 데이터 크기(중국 LLaMA 및 LLaMA-Plus의 경우 각각 20G에서 120G로)를 증가시키는 데 큰 도움이 되지 않는다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS3.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Alpaca models show significant improvements over LLaMA.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS3.SSS0.Px2.p1.1">제로 샷 또는 5 샷과 같은 다양한 설정 중에서 알파카 모델 시리즈는 LLaMA 대응물에 비해 상당한 개선을 보여 명령 후속 모델이 순수 언어 모델보다 이러한 NLU 유사 작업을 더 잘 처리할 수 있음을 보여준다. LLaMA 시리즈에서 관찰된 현상과 달리 Alpaca-Plus 모델이 기본 Alpaca 모델에 비해 상당한 개선을 가져온다는 것을 알 수 있다. 이는 명령 후속 모델이 NLU와 유사한 작업을 더 잘 처리할 수 있고 더 많은 사전 훈련 데이터(LLaMA-Plus)를 사용하는 힘을 발휘할 수 있음을 추가로 나타낼 수 있다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS3.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">LLaMA generally yields better performance in a few-shot setting, while Alpaca prefers zero-shot.</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS3.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS3.SSS0.Px3.p1.1">일반적으로, 5-샷 설정을 갖는 LLaMA는 제로-샷 설정보다 더 나은 성능을 나타내는 반면, 제로-샷 설정을 갖는 Alpaca는 5-샷 설정보다 훨씬 더 나은 성능을 나타낸다. LLaMA는 명령어 후속을 위해 설계되지 않았기 때문에 소수의 샷 설정은 C-Eval에서 질문 응답 구조를 따르는 방법에 대한 귀중한 정보를 제공할 수 있다. 그러나 반대로 알파카는 이미 수백만 개의 명령어 데이터로 훈련되었기 때문에 추가 샷의 혜택을 덜 받을 가능성이 높다. 또한 공식 5샷 설정은 모든 샘플에 대해 동일한 프롬프트를 사용하여 알파카 모델의 주의를 분산시킵니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS3.SSS0.Px3.p2">
<p class="ltx_p" id="S5.SS3.SSS0.Px3.p2.1">이러한 관찰은 전적으로 C-Eval 데이터 세트의 결과를 기반으로 하며 다른 데이터 세트에 일반화할 수 있는지 여부는 추가 조사가 필요하다는 점을 강조하고자 한다. 향후에는 LLaMA 및 알파카 모델의 행동을 추가로 조사하기 위해 보다 포괄적인 테스트를 포함할 것이다.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Comparisons to Other Models</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">우리는 C-Eval 리더보드에 중국-Alpaca-33B와 중국-Alpaca-Plus-13B의 두 가지 가장 성능이 좋은 모델을 포함하여 오픈 소스 및 비 오픈 소스 모델을 모두 포함한 다른 LLM과 비교한다. C-Eval 리더보드에 대한 테스트 결과(2023년 6월 9일 기준)는 표 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S5.T9" title="Table 9 ‣ 5.4 Comparisons to Other Models ‣ 5 Results on Natural Language Understanding Tasks ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">9</span></a>와 같다.</p>
</div>
<figure class="ltx_table" id="S5.T9">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9: </span> <span class="ltx_text ltx_font_bold" id="S5.T9.6.1">Test results on C-Eval leaderboard (as of June 9, 2023), ordered by average scores.</span> Model name with boldface represents our submissions, while the other results are evaluated by C-Eval officials. We re-evaluated two models marked with <math alttext="{\dagger}" class="ltx_Math" display="inline" id="S5.T9.2.m1.1"><semantics id="S5.T9.2.m1.1b"><mo id="S5.T9.2.m1.1.1" xref="S5.T9.2.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T9.2.m1.1c"><ci id="S5.T9.2.m1.1.1.cmml" xref="S5.T9.2.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T9.2.m1.1d">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="S5.T9.2.m1.1e">†</annotation></semantics></math> (these scores are not shown publicly) based on our own inference script and achieved significantly better performance than those evaluated by C-Eval. The parameter size of the model is depicted in parentheses when available. Open: open-source. Avg-H: Average (Hard). </figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S5.T9.4">
<tbody><tr class="ltx_tr" id="S5.T9.4.3">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S5.T9.4.3.1"><span class="ltx_text ltx_font_bold" id="S5.T9.4.3.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T9.4.3.2"><span class="ltx_text ltx_font_bold" id="S5.T9.4.3.2.1">N-Shot</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T9.4.3.3"><span class="ltx_text ltx_font_bold" id="S5.T9.4.3.3.1">Open</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T9.4.3.4"><span class="ltx_text ltx_font_bold" id="S5.T9.4.3.4.1">Avg</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T9.4.3.5"><span class="ltx_text ltx_font_bold" id="S5.T9.4.3.5.1">Avg-H</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T9.4.3.6"><span class="ltx_text ltx_font_bold" id="S5.T9.4.3.6.1">STEM</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T9.4.3.7"><span class="ltx_text ltx_font_bold" id="S5.T9.4.3.7.1">Social</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T9.4.3.8"><span class="ltx_text ltx_font_bold" id="S5.T9.4.3.8.1">Human</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T9.4.3.9"><span class="ltx_text ltx_font_bold" id="S5.T9.4.3.9.1">Others</span></td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S5.T9.4.4.1">GPT-4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T9.4.4.2">5-shot</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T9.4.4.3"><span class="ltx_text" id="S5.T9.4.4.3.1" style="color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T9.4.4.4">68.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T9.4.4.5">54.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T9.4.4.6">67.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T9.4.4.7">77.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T9.4.4.8">64.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T9.4.4.9">67.8</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.5">
<td class="ltx_td ltx_align_left" id="S5.T9.4.5.1">InternLM (104B)</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.5.2">few-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.5.3"><span class="ltx_text" id="S5.T9.4.5.3.1" style="color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.5.4">62.7</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.5.5">46.0</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.5.6">58.1</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.5.7">76.7</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.5.8">64.6</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.5.9">56.4</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.6">
<td class="ltx_td ltx_align_left" id="S5.T9.4.6.1">ChatGPT</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.6.2">5-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.6.3"><span class="ltx_text" id="S5.T9.4.6.3.1" style="color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.6.4">54.4</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.6.5">41.4</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.6.6">52.9</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.6.7">61.8</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.6.8">50.9</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.6.9">53.6</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.7">
<td class="ltx_td ltx_align_left" id="S5.T9.4.7.1">Claude-v1.3</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.7.2">5-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.7.3"><span class="ltx_text" id="S5.T9.4.7.3.1" style="color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.7.4">54.2</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.7.5">39.0</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.7.6">51.9</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.7.7">61.7</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.7.8">52.1</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.7.9">53.7</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.8">
<td class="ltx_td ltx_align_left" id="S5.T9.4.8.1">Claude-instant-v1.0</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.8.2">5-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.8.3"><span class="ltx_text" id="S5.T9.4.8.3.1" style="color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.8.4">45.9</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.8.5">35.5</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.8.6">43.1</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.8.7">53.8</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.8.8">44.2</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.8.9">45.4</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.9">
<td class="ltx_td ltx_align_left" id="S5.T9.4.9.1">Bloomz-mt (176B)</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.9.2">0-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.9.3"><span class="ltx_text" id="S5.T9.4.9.3.1" style="color:#0000FF;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.9.4">44.3</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.9.5">30.8</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.9.6">39.0</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.9.7">53.0</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.9.8">47.7</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.9.9">42.7</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.10">
<td class="ltx_td ltx_align_left" id="S5.T9.4.10.1">GLM-130B</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.10.2">0-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.10.3"><span class="ltx_text" id="S5.T9.4.10.3.1" style="color:#0000FF;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.10.4">44.0</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.10.5">30.7</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.10.6">36.7</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.10.7">55.8</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.10.8">47.7</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.10.9">43.0</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.11">
<td class="ltx_td ltx_align_left" id="S5.T9.4.11.1"><span class="ltx_text ltx_font_bold" id="S5.T9.4.11.1.1">Chinese-Alpaca-33B</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.11.2">0-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.11.3"><span class="ltx_text" id="S5.T9.4.11.3.1" style="color:#0000FF;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.11.4">41.6</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.11.5">30.3</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.11.6">37.0</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.11.7">51.6</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.11.8">42.3</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.11.9">40.3</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.12">
<td class="ltx_td ltx_align_left" id="S5.T9.4.12.1"><span class="ltx_text ltx_font_bold" id="S5.T9.4.12.1.1">Chinese-Alpaca-Plus-13B</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.12.2">0-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.12.3"><span class="ltx_text" id="S5.T9.4.12.3.1" style="color:#0000FF;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.12.4">41.5</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.12.5">30.5</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.12.6">36.6</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.12.7">49.7</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.12.8">43.1</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.12.9">41.2</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.13">
<td class="ltx_td ltx_align_left" id="S5.T9.4.13.1">CubeLM (13B)</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.13.2">few-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.13.3"><span class="ltx_text" id="S5.T9.4.13.3.1" style="color:#FF0000;">✗</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.13.4">40.2</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.13.5">27.3</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.13.6">34.1</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.13.7">49.7</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.13.8">43.4</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.13.9">39.6</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.14">
<td class="ltx_td ltx_align_left" id="S5.T9.4.14.1">ChatGLM-6B</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.14.2">0-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.14.3"><span class="ltx_text" id="S5.T9.4.14.3.1" style="color:#0000FF;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.14.4">38.9</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.14.5">29.2</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.14.6">33.3</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.14.7">48.3</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.14.8">41.3</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.14.9">38.0</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.15">
<td class="ltx_td ltx_align_left" id="S5.T9.4.15.1">LLaMA-65B</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.15.2">5-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.15.3"><span class="ltx_text" id="S5.T9.4.15.3.1" style="color:#0000FF;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.15.4">38.8</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.15.5">31.7</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.15.6">37.8</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.15.7">45.6</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.15.8">36.1</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.15.9">37.1</td>
</tr>
<tr class="ltx_tr" id="S5.T9.3.1">
<td class="ltx_td ltx_align_left" id="S5.T9.3.1.1"><span class="ltx_text ltx_font_bold" id="S5.T9.3.1.1.1">Chinese-Alpaca-13B<math alttext="{\dagger}" class="ltx_Math" display="inline" id="S5.T9.3.1.1.1.m1.1"><semantics id="S5.T9.3.1.1.1.m1.1a"><mo id="S5.T9.3.1.1.1.m1.1.1" mathvariant="normal" xref="S5.T9.3.1.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T9.3.1.1.1.m1.1b"><ci id="S5.T9.3.1.1.1.m1.1.1.cmml" xref="S5.T9.3.1.1.1.m1.1.1">normal-†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T9.3.1.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="S5.T9.3.1.1.1.m1.1d">†</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.3.1.2">0-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.3.1.3"><span class="ltx_text" id="S5.T9.3.1.3.1" style="color:#0000FF;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.3.1.4">36.7</td>
<td class="ltx_td ltx_align_center" id="S5.T9.3.1.5">28.4</td>
<td class="ltx_td ltx_align_center" id="S5.T9.3.1.6">33.1</td>
<td class="ltx_td ltx_align_center" id="S5.T9.3.1.7">43.7</td>
<td class="ltx_td ltx_align_center" id="S5.T9.3.1.8">38.4</td>
<td class="ltx_td ltx_align_center" id="S5.T9.3.1.9">35.0</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.2">
<td class="ltx_td ltx_align_left" id="S5.T9.4.2.1"><span class="ltx_text ltx_font_bold" id="S5.T9.4.2.1.1">Chinese-LLaMA-13B<math alttext="{\dagger}" class="ltx_Math" display="inline" id="S5.T9.4.2.1.1.m1.1"><semantics id="S5.T9.4.2.1.1.m1.1a"><mo id="S5.T9.4.2.1.1.m1.1.1" mathvariant="normal" xref="S5.T9.4.2.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S5.T9.4.2.1.1.m1.1b"><ci id="S5.T9.4.2.1.1.m1.1.1.cmml" xref="S5.T9.4.2.1.1.m1.1.1">normal-†</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T9.4.2.1.1.m1.1c">{\dagger}</annotation><annotation encoding="application/x-llamapun" id="S5.T9.4.2.1.1.m1.1d">†</annotation></semantics></math></span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.2.2">5-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.2.3"><span class="ltx_text" id="S5.T9.4.2.3.1" style="color:#0000FF;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.2.4">33.7</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.2.5">28.1</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.2.6">31.9</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.2.7">38.6</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.2.8">33.5</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.2.9">32.8</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.16">
<td class="ltx_td ltx_align_left" id="S5.T9.4.16.1">Chinese-LLaMA-13B</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.16.2">5-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.16.3"><span class="ltx_text" id="S5.T9.4.16.3.1" style="color:#0000FF;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.16.4">33.3</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.16.5">27.3</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.16.6">31.6</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.16.7">37.2</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.16.8">33.6</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.16.9">32.8</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.17">
<td class="ltx_td ltx_align_left" id="S5.T9.4.17.1">MOSS (16B)</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.17.2">0-shot</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.17.3"><span class="ltx_text" id="S5.T9.4.17.3.1" style="color:#0000FF;">✓</span></td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.17.4">33.1</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.17.5">28.4</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.17.6">31.6</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.17.7">37.0</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.17.8">33.4</td>
<td class="ltx_td ltx_align_center" id="S5.T9.4.17.9">32.1</td>
</tr>
<tr class="ltx_tr" id="S5.T9.4.18">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S5.T9.4.18.1">Chinese-Alpaca-13B</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T9.4.18.2">0-shot</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T9.4.18.3"><span class="ltx_text" id="S5.T9.4.18.3.1" style="color:#0000FF;">✓</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T9.4.18.4">30.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T9.4.18.5">24.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T9.4.18.6">27.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T9.4.18.7">39.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T9.4.18.8">32.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T9.4.18.9">28.0</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS4.p2">
<p class="ltx_p" id="S5.SS4.p2.1">당연히 비오픈 소스 LLM은 오픈 소스 LLM보다 성능이 훨씬 우수합니다. 본 모델의 경우, 중국어-Alpaca-33B와 중국어-Alpaca-Plus-13B 모두 Bloomz-mt-176B <cite class="ltx_cite ltx_citemacro_citep">(Scao et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib23" title="">2022</a>)</cite>와 GLM-130B <cite class="ltx_cite ltx_citemacro_citep">(Zeng et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib34" title="">2023</a>)</cite>와 같은 오픈 소스 LLM 간의 경쟁 성능을 얻을 수 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S5.SS4.p3">
<p class="ltx_p" id="S5.SS4.p3.1">또 다른 측면에서, Chinese-Alpaca-13B 및 Chinese-LLaMA-13B는 이전에 C-Eval에 의해 평가되었다. 또한 자체 구현으로 예측 파일을 리더보드에 수동으로 제출했습니다. 결과는 두 모델 모두 C-Eval에 의해 평가된 모델, 특히 Alpaca-13B 모델에 대해 상당한 개선을 보여 +5.8 평균 점수(30.9에서 36.7)를 산출했다. 또한 Alpaca-13B는 LLaMA-13B에 비해 이점을 보여주며, 이는 이전 연구 결과에 따른 것이다. 이러한 관찰은 적절한 디코딩 전략과 신속한 템플릿을 채택하는 것이 개별 LLM, 특히 명령 후속 모델의 경우 더 나은 성능을 달성하는 데 중요할 수 있음을 나타낸다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Effect of Different Quantization Methods</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">개인 컴퓨터, 특히 CPU에 대규모 언어 모델을 배치하는 것은 엄청난 계산 요구 사항으로 인해 역사적으로 어려웠다. 그러나 <span class="ltx_text ltx_font_typewriter" id="S6.p1.1.1">llama.cpp</span> <cite class="ltx_cite ltx_citemacro_citep">(Gerganov, <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib9" title="">2023</a></cite)</cite>와 같은 많은 커뮤니티 노력의 도움으로 사용자는 LLM을 효율적으로 양자화할 수 있어 메모리 사용량과 계산량을 크게 줄일 수 있어 개인용 컴퓨터에 LLM을 쉽게 배포할 수 있다. 이는 또한 모델과의 더 빠른 상호 작용을 가능하게 하고 로컬 데이터 처리를 용이하게 한다. LLM을 정량화하고 개인용 컴퓨터에 배포하면 몇 가지 이점이 있습니다. 첫째, 민감한 정보가 외부 서버로 전송되지 않고 로컬 환경 내에 남아 있도록 함으로써 사용자가 데이터 프라이버시를 보호하는 데 도움이 된다. 둘째, 제한된 계산 자원을 가진 사용자가 LLMs에 더 쉽게 접근할 수 있도록 함으로써 LLMs에 대한 접근을 민주화한다. 마지막으로 지역 LLM 배포를 활용하는 새로운 응용 프로그램 개발 및 연구 방향을 촉진한다. 전반적으로, <span class="ltx_text ltx_font_typewriter" id="S6.p1.1.2">llama.cpp</span> (또는 이와 유사한)을 사용하여 개인 컴퓨터에 LLM을 배포하는 기능은 다양한 도메인에서 LLM의 보다 다기능적이고 프라이버시를 의식하는 활용을 위한 길을 열어준다.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">이 절에서는 서로 다른 양자화 방법의 효과를 조사한다. <span class="ltx_text ltx_font_typewriter" id="S6.p2.1.1">llama.cpp</span>을 사용하여 Alpaca-Plus-7B, Alpaca-Plus-13B 및 Alpaca-33B를 양자화하고 한자 말뭉치에 대한 복잡도를 계산합니다. 이러한 모델을 원래 FP16과 비교하기 위해 2비트, 3비트, 4비트, 5비트, 6비트 및 8비트 형태로 양자화한다. <span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>Specifically, we use q2_K, q3_K, q4_0, q5_0, q6_K, and q8_0 quantization option for each quantized model.</span></span></span> 결과를 그림 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#S6.F4" title="Figure 4 ‣ 6 Effect of Different Quantization Methods ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">4</span></a>에 나타내었다.</p>
</div>
<figure class="ltx_figure" id="S6.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="419" id="S6.F4.g1" src="https://arxiv.org/html/2304.08177v3/x3.png" width="664">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span> <span class="ltx_text ltx_font_bold" id="S6.F4.2.1">Perplexities for different quantization methods.</span> Note that 33B model has a higher PPL as it is trained on less data than the others. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.p3">
<p class="ltx_p" id="S6.p3.1">양자화 레벨은 메모리 사용 및 추론 속도에 엄격하게 구속되므로, 적절한 양자화 레벨을 선택할 때 트레이드오프가 이루어져야 한다. 우리가 볼 수 있듯이, 8비트 양자화 방법은 원래의 FP16 모델에 비해 거의 동일하거나 심지어 더 낮은 복잡도를 가지며, 이는 FP16 모델의 절반 크기만으로 개인용 컴퓨터에 LLM을 배치하기에 좋은 선택임을 입증한다. 6비트 모델은 또한 8비트 모델에 필적하는 괜찮은 PPL을 달성하여 속도와 성능의 균형을 더 좋게 만든다. 보다 적극적인 양자화 레벨을 사용할 경우, 특히 3-비트 및 2-비트의 경우 성능이 급격히 감소한다(즉, 더 높은 PPL). 또한 더 큰 모델은 더 작은 모델보다 양자화 방법에 덜 민감하다는 것을 발견했다. 예를 들어, 33B 모델의 성능은 다른 모델보다 훨씬 더 온화하게 변한다. 플러스-7B와 플러스-13B 모델을 비교할 때도 유사한 결과가 관찰된다. 이는 2-비트 및 3-비트 양자화가 더 작은 모델에 대해서는 덜 효과적이지만, 상당한 성능 손실 없이 더 큰 모델을 배치하는 유망한 방법일 수 있음을 나타낼 수 있다. 이는 사용자가 제한된 컴퓨팅 리소스만 가지고 있고 여전히 대규모 언어 모델을 시도하고 싶을 때 매우 유용하다. 이것은 또한 양자화된 트레이닝 방법이 특히 트레이닝 자원이 제한된 언어 모델들을 트레이닝하기 위한 메인스트림 접근법이 될 수 있다는 것을 암시할 수 있다.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">본 기술 보고서에서는 LLaMA 모형에 대한 중국인의 이해와 발전 역량을 제고하기 위한 접근 방법을 제시하였다. 원래의 LLaMA의 중국어 어휘의 한계를 인식하고 20K의 중국어 토큰을 추가로 통합하여 확장하여 중국어에 대한 인코딩 효율을 크게 높였다. 중국 LLaMA를 기반으로 명령 데이터로 감독 미세 조정을 사용하여 중국 알파카 모델이 향상된 명령 후속 기능을 나타낸다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">모델을 효과적으로 평가하기 위해 10개의 고유한 작업 유형에 걸쳐 200개의 샘플에 주석을 달았고 평가를 위해 GPT-4를 활용했다. 우리의 실험은 제안된 모델이 중국 이해 및 생성 작업에서 원래의 LLaMA를 상당히 능가한다는 것을 보여주었다. 또한 C-Eval 데이터 세트에서 모델을 테스트했습니다. 그 결과 제안된 모델은 몇 배 더 큰 크기를 가진 모델에 비해 상당한 개선을 달성하고 경쟁 성능을 보일 수 있음을 보여준다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">앞으로는 인간 피드백에서 강화 학습(RLHF) 또는 AI 지시 피드백에서 강화 학습(RLAIF)을 탐색하여 모델의 출력을 인간의 선호도와 더 정렬할 계획이다. 또한 GPTQ <cite class="ltx_cite ltx_citemacro_citep">(Frantar et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib8" title="">2022</a>)</cite>와 같은 보다 진보되고 효과적인 양자화 방법을 채택하고자 한다. 또한 대규모 언어 모델의 보다 효율적이고 효과적인 사전 훈련 및 미세 조정을 위해 LoRA에 대한 대체 방법을 조사하여 궁극적으로 중국 NLP 커뮤니티 내에서 다양한 작업에 걸쳐 성능과 적용 가능성을 향상시키는 것을 목표로 한다.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Limitations</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">이 프로젝트는 LLaMA 및 알파카 모델의 중국 이해 및 생성 능력을 성공적으로 향상시켰지만 몇 가지 한계를 인정해야 한다.</p>
<ul class="ltx_itemize" id="Sx1.I1">
<li class="ltx_item" id="Sx1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Sx1.I1.i1.p1">
<p class="ltx_p" id="Sx1.I1.i1.p1.1">유해하고 예측할 수 없는 콘텐츠: 우리의 모델이 비윤리적 쿼리를 거부할 수 있지만, 이러한 모델은 여전히 인간의 선호도 및 값과 유해하거나 잘못된 정렬을 생성할 수 있다. 이 문제는 학습 데이터의 편향이나 특정 컨텍스트에서 적절한 출력을 식별할 수 없는 모델의 무능성에서 발생할 수 있다.</p>
</div>
</li>
<li class="ltx_item" id="Sx1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Sx1.I1.i2.p1">
<p class="ltx_p" id="Sx1.I1.i2.p1.1">불충분한 트레이닝: 컴퓨팅 파워 및 데이터 가용성의 제약들로 인해, 모델들의 트레이닝은 최적의 성능을 위해 충분하지 않을 수 있다. 그 결과 모델들에 대한 중국어 이해 능력에서 여전히 개선의 여지가 있다.</p>
</div>
</li>
<li class="ltx_item" id="Sx1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Sx1.I1.i3.p1">
<p class="ltx_p" id="Sx1.I1.i3.p1.1">강인성 부족: 모델은 일부 상황에서 취성을 나타내어 적대적 입력 또는 희귀 언어 현상에 직면할 때 일관되지 않거나 무의미한 출력을 생성할 수 있다.</p>
</div>
</li>
<li class="ltx_item" id="Sx1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Sx1.I1.i4.p1">
<p class="ltx_p" id="Sx1.I1.i4.p1.1">종합평가: 큰 언어 모델을 평가하는 것은 현 시대의 중요한 주제이다. LLM에 대한 많은 평가 벤치마크를 보았지만 LLM에 대한 포괄성과 적절성은 잘 연구되고 조사되어야 한다. 보다 다양하고 포괄적인 LLM 평가 데이터 세트 및 벤치마크는 LLM 연구의 미래를 형성하는 데 큰 긍정적인 영향을 미칠 것이다.</p>
</div>
</li>
<li class="ltx_item" id="Sx1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="Sx1.I1.i5.p1">
<p class="ltx_p" id="Sx1.I1.i5.p1.1">확장성 및 효율성: LoRA 및 양자화를 적용하여 모델을 보다 광범위한 커뮤니티에 더 쉽게 액세스할 수 있도록 했지만, 원래 LLaMA와 결합할 때 모델의 큰 크기와 복잡성은 특히 제한된 계산 리소스를 가진 사용자의 배치에 어려움을 초래할 수 있다. 이 문제는 다양한 응용 프로그램에서 모델의 접근성과 광범위한 채택을 방해할 수 있다.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="Sx1.p2">
<p class="ltx_p" id="Sx1.p2.1">향후 작업은 이러한 한계를 해결하여 모델의 기능을 더욱 향상시켜 중국 NLP 커뮤니티의 광범위한 응용 프로그램에 더 강력하고 접근 가능하며 효과적이어야 한다.</p>
</div>
</section>
<section class="ltx_section" id="Sx2">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="Sx2.p1">
<p class="ltx_p" id="Sx2.p1.1">원안은 문법 수정 및 명확성 개선을 위해 OpenAI GPT-4에 의해 연마되었다. 오픈 소스 프로젝트에 기여해 주신 커뮤니티 구성원들께 감사드립니다.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yushi Bai, Xin Lv, Jiajie Zhang, Hongchang Lyu, Jiankai Tang, Zhidian Huang, Zhengxiao Du, Xiao Liu, Aohan Zeng, Lei Hou, Yuxiao Dong, Jie Tang, and Juanzi Li.

</span>
<span class="ltx_bibblock">Longbench: A bilingual, multitask benchmark for long context understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2308.14508</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian.

</span>
<span class="ltx_bibblock">Extending context window of large language models via positional interpolation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2306.15595</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, Shijin Wang, and Guoping Hu.

</span>
<span class="ltx_bibblock">Revisiting pre-trained models for Chinese natural language processing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings</em>, pp.&nbsp; 657–668, Online, November 2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.aclweb.org/anthology/2020.findings-emnlp.58" title="">https://www.aclweb.org/anthology/2020.findings-emnlp.58</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yiming Cui, Wanxiang Che, Ting Liu, Bing Qin, and Ziqing Yang.

</span>
<span class="ltx_bibblock">Pre-training with whole word masking for chinese bert.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 29:3504–3514, 2021.

</span>
<span class="ltx_bibblock">doi: <a class="ltx_ref ltx_Url" href="10.1109/TASLP.2021.3124365" title="">10.1109/TASLP.2021.3124365</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yiming Cui, Wanxiang Che, Shijin Wang, and Ting Liu.

</span>
<span class="ltx_bibblock">Lert: A linguistically-motivated pre-trained language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2211.05344</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dettmers et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Qlora: Efficient finetuning of quantized llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2305.14314</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">BERT: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pp.&nbsp; 4171–4186, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.aclweb.org/anthology/N19-1423" title="">https://www.aclweb.org/anthology/N19-1423</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Frantar et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh.

</span>
<span class="ltx_bibblock">GPTQ: Accurate post-training compression for generative pretrained transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2210.17323</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gerganov (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Georgi Gerganov.

</span>
<span class="ltx_bibblock">llama.cpp.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/ggerganov/llama.cpp" title="">https://github.com/ggerganov/llama.cpp</a>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Edward&nbsp;J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu&nbsp;Wang, and Weizhu Chen.

</span>
<span class="ltx_bibblock">LoRA: Low-Rank Adaptation of Large Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv e-prints</em>, art. arXiv:2106.09685, June 2021.

</span>
<span class="ltx_bibblock">doi: <a class="ltx_ref ltx_Url" href="10.48550/arXiv.2106.09685" title="">10.48550/arXiv.2106.09685</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuzhen Huang, Yuzhuo Bai, Zhihao Zhu, Junlei Zhang, Jinghan Zhang, Tangjun Su, Junteng Liu, Chuancheng Lv, Yikai Zhang, Jiayi Lei, Yao Fu, Maosong Sun, and Junxian He.

</span>
<span class="ltx_bibblock">C-eval: A multi-level multi-discipline chinese evaluation suite for foundation models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2305.08322</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Köpf et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Andreas Köpf, Yannic Kilcher, Dimitri von Rütte, Sotiris Anagnostidis, Zhi-Rui Tam, Keith Stevens, Abdullah Barhoum, Nguyen&nbsp;Minh Duc, Oliver Stanley, Richárd Nagyfi, Shahul ES, Sameer Suri, David Glushkov, Arnav Dantuluri, Andrew Maguire, Christoph Schuhmann, Huu Nguyen, and Alexander Mattick.

</span>
<span class="ltx_bibblock">OpenAssistant Conversations – Democratizing Large Language Model Alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv e-prints</em>, art. arXiv:2304.07327, April 2023.

</span>
<span class="ltx_bibblock">doi: <a class="ltx_ref ltx_Url" href="10.48550/arXiv.2304.07327" title="">10.48550/arXiv.2304.07327</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kudo &amp; Richardson (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Taku Kudo and John Richardson.

</span>
<span class="ltx_bibblock">SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</em>, pp.&nbsp; 66–71, Brussels, Belgium, November 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <a class="ltx_ref ltx_Url" href="10.18653/v1/D18-2012" title="">10.18653/v1/D18-2012</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/D18-2012" title="">https://aclanthology.org/D18-2012</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lai et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy.

</span>
<span class="ltx_bibblock">RACE: Large-scale ReAding comprehension dataset from examinations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</em>, pp.&nbsp; 785–794, Copenhagen, Denmark, September 2017. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <a class="ltx_ref ltx_Url" href="10.18653/v1/D17-1082" title="">10.18653/v1/D17-1082</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/D17-1082" title="">https://aclanthology.org/D17-1082</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Haonan Li, Yixuan Zhang, Fajri Koto, Yifei Yang, Hai Zhao, Yeyun Gong, Nan Duan, and Timothy Baldwin.

</span>
<span class="ltx_bibblock">Cmmlu: Measuring massive multitask language understanding in chinese, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov &amp; Hutter (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">International Conference on Learning Representations</em>, 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=Bkg6RiCqY7" title="">https://openreview.net/forum?id=Bkg6RiCqY7</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Introducing chatgpt.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/blog/chatgpt" title="">https://openai.com/blog/chatgpt</a>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">GPT-4 Technical Report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv e-prints</em>, art. arXiv:2303.08774, March 2023.

</span>
<span class="ltx_bibblock">doi: <a class="ltx_ref ltx_Url" href="10.48550/arXiv.2303.08774" title="">10.48550/arXiv.2303.08774</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Long Ouyang, Jeff Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll&nbsp;L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv e-prints</em>, art. arXiv:2203.02155, March 2022.

</span>
<span class="ltx_bibblock">doi: <a class="ltx_ref ltx_Url" href="10.48550/arXiv.2203.02155" title="">10.48550/arXiv.2203.02155</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole.

</span>
<span class="ltx_bibblock">Yarn: Efficient context window extension of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2309.00071</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Improving language understanding by generative pre-training.

</span>
<span class="ltx_bibblock">2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rasley et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He.

</span>
<span class="ltx_bibblock">Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</em>, pp.&nbsp; 3505–3506, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scao et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Teven&nbsp;Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra&nbsp;Sasha Luccioni, François Yvon, Matthias Gallé, et&nbsp;al.

</span>
<span class="ltx_bibblock">Bloom: A 176b-parameter open-access multilingual language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2211.05100</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Noam Shazeer.

</span>
<span class="ltx_bibblock">Glu variants improve transformer, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jianlin Su, Yu&nbsp;Lu, Shengfeng Pan, Bo&nbsp;Wen, and Yunfeng Liu.

</span>
<span class="ltx_bibblock">Roformer: Enhanced transformer with rotary position embedding, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori&nbsp;B. Hashimoto.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/tatsu-lab/stanford_alpaca" title="">https://github.com/tatsu-lab/stanford_alpaca</a>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori&nbsp;B. Hashimoto.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/tatsu-lab/stanford_alpaca" title="">https://github.com/tatsu-lab/stanford_alpaca</a>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2302.13971</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2307.09288</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan&nbsp;N Gomez, Ł&nbsp;ukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In I.&nbsp;Guyon, U.&nbsp;Von Luxburg, S.&nbsp;Bengio, H.&nbsp;Wallach, R.&nbsp;Fergus, S.&nbsp;Vishwanathan, and R.&nbsp;Garnett (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Advances in Neural Information Processing Systems</em>, volume&nbsp;30. Curran Associates, Inc., 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah&nbsp;A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi.

</span>
<span class="ltx_bibblock">Self-Instruct: Aligning Language Model with Self Generated Instructions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">arXiv e-prints</em>, art. arXiv:2212.10560, December 2022.

</span>
<span class="ltx_bibblock">doi: <a class="ltx_ref ltx_Url" href="10.48550/arXiv.2212.10560" title="">10.48550/arXiv.2212.10560</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bright Xu.

</span>
<span class="ltx_bibblock">Nlp chinese corpus: Large scale chinese corpus for nlp, September 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.5281/zenodo.3402023" title="">https://doi.org/10.5281/zenodo.3402023</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ziqing Yang, Zihang Xu, Yiming Cui, Baoxin Wang, Min Lin, Dayong Wu, and Zhigang Chen.

</span>
<span class="ltx_bibblock">CINO: A Chinese minority pre-trained language model.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">Proceedings of the 29th International Conference on Computational Linguistics</em>, pp.&nbsp; 3937–3949, Gyeongju, Republic of Korea, October 2022. International Committee on Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.coling-1.346" title="">https://aclanthology.org/2022.coling-1.346</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, Weng&nbsp;Lam Tam, Zixuan Ma, Yufei Xue, Jidong Zhai, Wenguang Chen, Zhiyuan Liu, Peng Zhang, Yuxiao Dong, and Jie Tang.

</span>
<span class="ltx_bibblock">GLM-130b: An open bilingual pre-trained model.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">The Eleventh International Conference on Learning Representations</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=-Aw0rrrPUF" title="">https://openreview.net/forum?id=-Aw0rrrPUF</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang &amp; Sennrich (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Biao Zhang and Rico Sennrich.

</span>
<span class="ltx_bibblock">Root Mean Square Layer Normalization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Advances in Neural Information Processing Systems 32</em>, Vancouver, Canada, 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/references/pdf?id=S1qBAf6rr" title="">https://openreview.net/references/pdf?id=S1qBAf6rr</a>.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">우리는 중국-LLaMA-2와 중국-Alpaca-2에 대한 기본 결과를 다음과 같이 제시한다. 대부분의 설정은 중국-LLaMA의 설정과 동일합니다.</p>
</div>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>C-Eval</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">C-Eval <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib11" title="">2023</a>)</cite>에 대한 결과는 표 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#A1.T10" title="Table 10 ‣ A.1 C-Eval ‣ Appendix A Appendix ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">10</span></a>에 제시되어 있다.</p>
</div>
<figure class="ltx_table" id="A1.T10">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 10: </span> <span class="ltx_text ltx_font_bold" id="A1.T10.2.1">Results on C-Eval valid and test sets</span>. </figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T10.3">
<tbody><tr class="ltx_tr" id="A1.T10.3.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T10.3.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="A1.T10.3.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A1.T10.3.1.2"><span class="ltx_text ltx_font_bold" id="A1.T10.3.1.2.1">Valid Set</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A1.T10.3.1.3"><span class="ltx_text ltx_font_bold" id="A1.T10.3.1.3.1">Test Set</span></td>
</tr>
<tr class="ltx_tr" id="A1.T10.3.2">
<td class="ltx_td ltx_align_center" id="A1.T10.3.2.1"><span class="ltx_text ltx_font_bold" id="A1.T10.3.2.1.1">Zero-shot</span></td>
<td class="ltx_td ltx_align_center" id="A1.T10.3.2.2"><span class="ltx_text ltx_font_bold" id="A1.T10.3.2.2.1">5-shot</span></td>
<td class="ltx_td ltx_align_center" id="A1.T10.3.2.3"><span class="ltx_text ltx_font_bold" id="A1.T10.3.2.3.1">Zero-shot</span></td>
<td class="ltx_td ltx_align_center" id="A1.T10.3.2.4"><span class="ltx_text ltx_font_bold" id="A1.T10.3.2.4.1">5-shot</span></td>
</tr>
<tr class="ltx_tr" id="A1.T10.3.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T10.3.3.1">Chinese-LLaMA-2-7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.3.3.2">28.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.3.3.3">36.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.3.3.4">30.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.3.3.5">34.2</td>
</tr>
<tr class="ltx_tr" id="A1.T10.3.4">
<td class="ltx_td ltx_align_left" id="A1.T10.3.4.1">Chinese-LLaMA-2-13B</td>
<td class="ltx_td ltx_align_center" id="A1.T10.3.4.2">40.6</td>
<td class="ltx_td ltx_align_center" id="A1.T10.3.4.3">42.7</td>
<td class="ltx_td ltx_align_center" id="A1.T10.3.4.4">38.0</td>
<td class="ltx_td ltx_align_center" id="A1.T10.3.4.5">41.6</td>
</tr>
<tr class="ltx_tr" id="A1.T10.3.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T10.3.5.1">Chinese-Alpaca-2-7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.3.5.2">41.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.3.5.3">42.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.3.5.4">40.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T10.3.5.5">39.5</td>
</tr>
<tr class="ltx_tr" id="A1.T10.3.6">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T10.3.6.1">Chinese-Alpaca-2-13B</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T10.3.6.2">44.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T10.3.6.3">45.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T10.3.6.4">42.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T10.3.6.5">44.0</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>CMMLU</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">CMMLU <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib15" title="">2023</a>)</cite>에 대한 결과는 표 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#A1.T11" title="Table 11 ‣ A.2 CMMLU ‣ Appendix A Appendix ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">11</span></a>에 제시되어 있다.</p>
</div>
<figure class="ltx_table" id="A1.T11">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 11: </span> <span class="ltx_text ltx_font_bold" id="A1.T11.2.1">Results on CMMLU test sets</span>. </figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T11.3">
<tbody><tr class="ltx_tr" id="A1.T11.3.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T11.3.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="A1.T11.3.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A1.T11.3.1.2"><span class="ltx_text ltx_font_bold" id="A1.T11.3.1.2.1">Test Set</span></td>
</tr>
<tr class="ltx_tr" id="A1.T11.3.2">
<td class="ltx_td ltx_align_center" id="A1.T11.3.2.1"><span class="ltx_text ltx_font_bold" id="A1.T11.3.2.1.1">Zero-shot</span></td>
<td class="ltx_td ltx_align_center" id="A1.T11.3.2.2"><span class="ltx_text ltx_font_bold" id="A1.T11.3.2.2.1">Few-shot</span></td>
</tr>
<tr class="ltx_tr" id="A1.T11.3.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T11.3.3.1">Chinese-LLaMA-2-7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T11.3.3.2">27.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T11.3.3.3">34.1</td>
</tr>
<tr class="ltx_tr" id="A1.T11.3.4">
<td class="ltx_td ltx_align_left" id="A1.T11.3.4.1">Chinese-LLaMA-2-13B</td>
<td class="ltx_td ltx_align_center" id="A1.T11.3.4.2">38.9</td>
<td class="ltx_td ltx_align_center" id="A1.T11.3.4.3">42.5</td>
</tr>
<tr class="ltx_tr" id="A1.T11.3.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T11.3.5.1">Chinese-Alpaca-2-7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T11.3.5.2">40.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T11.3.5.3">41.8</td>
</tr>
<tr class="ltx_tr" id="A1.T11.3.6">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T11.3.6.1">Chinese-Alpaca-2-13B</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T11.3.6.2">43.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T11.3.6.3">45.5</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>LongBench</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1">LongBench <cite class="ltx_cite ltx_citemacro_citep">(Bai et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib1" title="">2023</a>)</cite>에 대한 결과는 표 <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#A1.T12" title="Table 12 ‣ A.3 LongBench ‣ Appendix A Appendix ‣ Efficient and Effective Text Encoding for Chinese LLaMA and Alpaca"><span class="ltx_text ltx_ref_tag">12</span></a>에 제시되어 있다. 이 벤치마크는 LLM의 긴 컨텍스트 능력을 테스트하기 위해 특별히 설계되었습니다. 우리는 LongBench의 중국어 부분집합(코드 작업 포함)을 테스트한다. <span class="ltx_text ltx_font_typewriter" id="A1.SS3.p1.1.1">16K</span>로 표시된 모델은 16K 컨텍스트를 지원하는 PI(Positional Interpolation) 방법 <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib2" title="">2023</a>)</cite>를 사용하여 미세 조정되었습니다. <span class="ltx_text ltx_font_typewriter" id="A1.SS3.p1.1.2">64K</span>로 표시된 모델은 64K 컨텍스트를 지원하는 YaRN 방법 <cite class="ltx_cite ltx_citemacro_citep">(Peng et al., <a class="ltx_ref" href="https://arxiv.org/html/2304.08177v3#bib.bib20" title="">2023</a>)</cite>를 사용하여 미세 조정되었습니다.</p>
</div>
<figure class="ltx_table" id="A1.T12">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 12: </span> <span class="ltx_text ltx_font_bold" id="A1.T12.2.1">Results on LongBench (Chinese + code tasks).</span> S-QA: Single-doc QA, M-QA: Multi-doc QA, Summ: Summarization, FS-Learn: Few-shot Learning, Code: Code Completion, Synthetic: Synthetic Tasks.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T12.3">
<tbody><tr class="ltx_tr" id="A1.T12.3.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T12.3.1.1"><span class="ltx_text ltx_font_bold" id="A1.T12.3.1.1.1">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T12.3.1.2"><span class="ltx_text ltx_font_bold" id="A1.T12.3.1.2.1">S-QA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T12.3.1.3"><span class="ltx_text ltx_font_bold" id="A1.T12.3.1.3.1">M-QA</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T12.3.1.4"><span class="ltx_text ltx_font_bold" id="A1.T12.3.1.4.1">Summ</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T12.3.1.5"><span class="ltx_text ltx_font_bold" id="A1.T12.3.1.5.1">FS-Learn</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T12.3.1.6"><span class="ltx_text ltx_font_bold" id="A1.T12.3.1.6.1">Code</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T12.3.1.7"><span class="ltx_text ltx_font_bold" id="A1.T12.3.1.7.1">Synthetic</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T12.3.1.8"><span class="ltx_text ltx_font_bold" id="A1.T12.3.1.8.1">Average</span></td>
</tr>
<tr class="ltx_tr" id="A1.T12.3.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T12.3.2.1">Chinese-LLaMA-2-7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T12.3.2.2">19.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T12.3.2.3">13.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T12.3.2.4">6.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T12.3.2.5">11.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T12.3.2.6">11.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T12.3.2.7">4.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T12.3.2.8">11.0</td>
</tr>
<tr class="ltx_tr" id="A1.T12.3.3">
<td class="ltx_td ltx_align_left" id="A1.T12.3.3.1">Chinese-LLaMA-2-7B-16K</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.3.2">33.2</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.3.3">15.9</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.3.4">6.5</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.3.5">23.5</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.3.6">10.3</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.3.7">5.3</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.3.8">15.8</td>
</tr>
<tr class="ltx_tr" id="A1.T12.3.4">
<td class="ltx_td ltx_align_left" id="A1.T12.3.4.1">Chinese-LLaMA-2-7B-64K</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.4.2">27.2</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.4.3">16.4</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.4.4">6.5</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.4.5">33.0</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.4.6">7.8</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.4.7">5.0</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.4.8">16.0</td>
</tr>
<tr class="ltx_tr" id="A1.T12.3.5">
<td class="ltx_td ltx_align_left" id="A1.T12.3.5.1">Chinese-LLaMA-2-13B</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.5.2">28.3</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.5.3">14.4</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.5.4">4.6</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.5.5">16.3</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.5.6">10.4</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.5.7">5.4</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.5.8">13.2</td>
</tr>
<tr class="ltx_tr" id="A1.T12.3.6">
<td class="ltx_td ltx_align_left" id="A1.T12.3.6.1">Chinese-LLaMA-2-13B-16K</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.6.2">36.7</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.6.3">17.7</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.6.4">3.1</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.6.5">29.8</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.6.6">13.8</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.6.7">3.0</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.6.8">17.3</td>
</tr>
<tr class="ltx_tr" id="A1.T12.3.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T12.3.7.1">Chinese-Alpaca-2-7B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T12.3.7.2">34.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T12.3.7.3">17.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T12.3.7.4">11.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T12.3.7.5">21.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T12.3.7.6">50.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T12.3.7.7">4.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T12.3.7.8">23.2</td>
</tr>
<tr class="ltx_tr" id="A1.T12.3.8">
<td class="ltx_td ltx_align_left" id="A1.T12.3.8.1">Chinese-Alpaca-2-7B-16K</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.8.2">46.4</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.8.3">23.3</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.8.4">14.3</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.8.5">29.0</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.8.6">49.6</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.8.7">9.0</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.8.8">28.6</td>
</tr>
<tr class="ltx_tr" id="A1.T12.3.9">
<td class="ltx_td ltx_align_left" id="A1.T12.3.9.1">Chinese-Alpaca-2-7B-64K</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.9.2">44.7</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.9.3">28.1</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.9.4">14.4</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.9.5">39.0</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.9.6">44.6</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.9.7">5.0</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.9.8">29.3</td>
</tr>
<tr class="ltx_tr" id="A1.T12.3.10">
<td class="ltx_td ltx_align_left" id="A1.T12.3.10.1">Chinese-Alpaca-2-13B</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.10.2">38.4</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.10.3">20.0</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.10.4">11.9</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.10.5">17.3</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.10.6">46.5</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.10.7">8.0</td>
<td class="ltx_td ltx_align_center" id="A1.T12.3.10.8">23.7</td>
</tr>
<tr class="ltx_tr" id="A1.T12.3.11">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T12.3.11.1">Chinese-Alpaca-2-13B-16K</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T12.3.11.2">47.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T12.3.11.3">26.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T12.3.11.4">13.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T12.3.11.5">22.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T12.3.11.6">46.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T12.3.11.7">21.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T12.3.11.8">29.7</td>
</tr>
</tbody></table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
</article>
</div>

</div>


<div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated on Wed Dec 14 18:01:44 2022 by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button></body></html>