<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2107.06499] Deduplicating Training Data Makes Language Models Better</title><meta property="og:description" content="We find that existing language modeling datasets contain many near-duplicate examples and long repetitive substrings.
As a result, over  of the unprompted output of language models trained on these datasets is copied v…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deduplicating Training Data Makes Language Models Better">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Deduplicating Training Data Makes Language Models Better">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2107.06499">

<!--Generated on Sun Dec 25 15:11:31 2022 by LaTeXML (version 0.8.6) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv.0.7.7.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.1.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Deduplicating Training Data Makes Language Models Better</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Katherine Lee  †
<br class="ltx_break">
<br class="ltx_break">&amp;Daphne Ippolito<span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>  †‡
<br class="ltx_break">
<br class="ltx_break">&amp;Andrew Nystrom†
<br class="ltx_break">
<br class="ltx_break">&amp;Chiyuan Zhang†
<br class="ltx_break">
<br class="ltx_break"><span id="id4.1.id1" class="ltx_ERROR undefined">\AND</span>Douglas Eck†
<br class="ltx_break">
<br class="ltx_break">&amp;Chris Callison-Burch‡
<br class="ltx_break">
<br class="ltx_break">&amp;Nicholas Carlini†
<br class="ltx_break">
</span><span class="ltx_author_notes">    Equal contribution. †  Google Research, Brain Team. ‡  University of Pennsylvania. Correspond to katherinelee@google.com and daphnei@seas.upenn.edu.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.3" class="ltx_p">We find that existing language modeling datasets contain many near-duplicate examples and long repetitive substrings.
As a result, over <math id="id1.1.m1.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1.1" xref="id1.1.m1.1.1.cmml"><mn id="id1.1.m1.1.1.2" xref="id1.1.m1.1.1.2.cmml">1</mn><mo id="id1.1.m1.1.1.1" xref="id1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id1.1.m1.1b"><apply id="id1.1.m1.1.1.cmml" xref="id1.1.m1.1.1"><csymbol cd="latexml" id="id1.1.m1.1.1.1.cmml" xref="id1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="id1.1.m1.1.1.2.cmml" xref="id1.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id1.1.m1.1c">1\%</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">1 %</annotation></semantics></math> of the unprompted output of language models trained on these datasets is copied verbatim from the training data.
We develop two tools that allow us to deduplicate training datasets—for example removing from C4 a single 61 word English sentence that is repeated over <math id="id2.2.m2.2" class="ltx_Math" alttext="60{,}000" display="inline"><semantics id="id2.2.m2.2a"><mrow id="id2.2.m2.2.3.2" xref="id2.2.m2.2.3.1.cmml"><mn id="id2.2.m2.1.1" xref="id2.2.m2.1.1.cmml">60</mn><mo id="id2.2.m2.2.3.2.1" xref="id2.2.m2.2.3.1.cmml">,</mo><mn id="id2.2.m2.2.2" xref="id2.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="id2.2.m2.2b"><list id="id2.2.m2.2.3.1.cmml" xref="id2.2.m2.2.3.2"><cn type="integer" id="id2.2.m2.1.1.cmml" xref="id2.2.m2.1.1">60</cn><cn type="integer" id="id2.2.m2.2.2.cmml" xref="id2.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="id2.2.m2.2c">60{,}000</annotation><annotation encoding="application/x-llamapun" id="id2.2.m2.2d">60 , 000</annotation></semantics></math> times.
Deduplication allows us to train models that emit memorized text ten times less frequently and require fewer training steps to achieve the same or better accuracy.
We can also reduce train-test overlap, which affects over <math id="id3.3.m3.1" class="ltx_Math" alttext="4\%" display="inline"><semantics id="id3.3.m3.1a"><mrow id="id3.3.m3.1.1" xref="id3.3.m3.1.1.cmml"><mn id="id3.3.m3.1.1.2" xref="id3.3.m3.1.1.2.cmml">4</mn><mo id="id3.3.m3.1.1.1" xref="id3.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id3.3.m3.1b"><apply id="id3.3.m3.1.1.cmml" xref="id3.3.m3.1.1"><csymbol cd="latexml" id="id3.3.m3.1.1.1.cmml" xref="id3.3.m3.1.1.1">percent</csymbol><cn type="integer" id="id3.3.m3.1.1.2.cmml" xref="id3.3.m3.1.1.2">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id3.3.m3.1c">4\%</annotation><annotation encoding="application/x-llamapun" id="id3.3.m3.1d">4 %</annotation></semantics></math> of the validation set of standard datasets, thus allowing for more accurate evaluation.
Code for deduplication is released at
<a target="_blank" href="https://github.com/google-research/deduplicate-text-datasets" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/google-research/deduplicate-text-datasets</a>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">A key factor behind the recent progress in natural language processing is the development of large-scale text corpora used to train increasingly large language models.
These datasets have grown from single gigabytes to as much as a terabyte over the past few years <cite class="ltx_cite ltx_citemacro_citep">(Chelba et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2013</a>; Xue et&nbsp;al., <a href="#bib.bib45" title="" class="ltx_ref">2020</a>; Graff et&nbsp;al., <a href="#bib.bib22" title="" class="ltx_ref">2003</a>; Brown et&nbsp;al., <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>.
Because it is so expensive to perform manual review and curation on massive datasets, they tend to suffer in quality compared to their smaller predecessors.
This has implications far beyond metrics like perplexity and validation loss, as learned models reflect the biases present in their training data <cite class="ltx_cite ltx_citemacro_cite">Bender et&nbsp;al. (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>); Wallace et&nbsp;al. (<a href="#bib.bib42" title="" class="ltx_ref">2019</a>); Sheng et&nbsp;al. (<a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite>.
Quantitatively and qualitatively understanding these datasets is therefore a research challenge in its own right <cite class="ltx_cite ltx_citemacro_cite">Dodge et&nbsp;al. (<a href="#bib.bib16" title="" class="ltx_ref">2021a</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">We show that one particular source of bias,
duplicated training examples, is pervasive:
all four common NLP datasets we studied contained duplicates.
Additionally, all four corresponding validation sets contained text duplicated in the training set.
While naive deduplication is straightforward
(and the datasets we consider already perform some naive form
of deduplication), performing thorough deduplication at scale is both computationally challenging and requires sophisticated techniques.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">We propose two scalable techniques to detect and remove duplicated training data.
<span id="S1.p3.1.1" class="ltx_text ltx_font_italic">Exact</span> substring matching identifies verbatim strings that are repeated.
This allows us to identify cases where only part of a training example is duplicated (§<a href="#S4.SS1" title="4.1 Exact Substring Duplication ‣ 4 Methods for Identifying Duplicates ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>).
<span id="S1.p3.1.2" class="ltx_text ltx_font_italic">Approximate</span> full document matching uses hash-based techniques&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Broder (<a href="#bib.bib8" title="" class="ltx_ref">1997</a>)</cite> to identify pairs of documents with high <math id="S1.p3.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S1.p3.1.m1.1a"><mi id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><ci id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S1.p3.1.m1.1d">italic_n</annotation></semantics></math>-gram overlap (§<a href="#S4.SS2" title="4.2 Approximate Matching with MinHash ‣ 4 Methods for Identifying Duplicates ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>).</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We identify four distinct advantages to training on datasets that have been thoroughly deduplicated.</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.2" class="ltx_p">Over <math id="S1.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S1.I1.i1.p1.1.m1.1a"><mrow id="S1.I1.i1.p1.1.m1.1.1" xref="S1.I1.i1.p1.1.m1.1.1.cmml"><mn id="S1.I1.i1.p1.1.m1.1.1.2" xref="S1.I1.i1.p1.1.m1.1.1.2.cmml">1</mn><mo id="S1.I1.i1.p1.1.m1.1.1.1" xref="S1.I1.i1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i1.p1.1.m1.1b"><apply id="S1.I1.i1.p1.1.m1.1.1.cmml" xref="S1.I1.i1.p1.1.m1.1.1"><csymbol cd="latexml" id="S1.I1.i1.p1.1.m1.1.1.1.cmml" xref="S1.I1.i1.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S1.I1.i1.p1.1.m1.1.1.2.cmml" xref="S1.I1.i1.p1.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i1.p1.1.m1.1c">1\%</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i1.p1.1.m1.1d">1 %</annotation></semantics></math> of tokens emitted unprompted from a model trained on standard datasets (e.g., C4) are part of a memorized sequence (See §<a href="#S6.SS2" title="6.2 Generated Text ‣ 6 Impact on Trained Models ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a>)—even though the 1.5 billion parameter model is much smaller than the 350GB dataset it was trained on.
By deduplicating the training dataset we reduce the rate of emitting memorized training data by a factor of <math id="S1.I1.i1.p1.2.m2.1" class="ltx_math_unparsed" alttext="10\times" display="inline"><semantics id="S1.I1.i1.p1.2.m2.1a"><mrow id="S1.I1.i1.p1.2.m2.1b"><mn id="S1.I1.i1.p1.2.m2.1.1">10</mn><mo lspace="0.222em" id="S1.I1.i1.p1.2.m2.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S1.I1.i1.p1.2.m2.1c">10\times</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i1.p1.2.m2.1d">10 ×</annotation></semantics></math>.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.3" class="ltx_p">Train-test overlap is common in non-deduplicated datasets.
For example, we find <em id="S1.I1.i2.p1.3.1" class="ltx_emph ltx_font_italic">a 61-word sequence</em><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>“by combining fantastic ideas, interesting arrangements, and follow the current trends in the field of that make you more inspired and give artistic touches. We’d be honored if you can apply some or all of these design in your wedding. believe me, brilliant ideas would be perfect if it can be applied in real and make the people around you amazed!”</span></span></span>
in C4 <cite class="ltx_cite ltx_citemacro_citep">(Raffel et&nbsp;al., <a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite> that is repeated <math id="S1.I1.i2.p1.1.m1.2" class="ltx_Math" alttext="61{,}036" display="inline"><semantics id="S1.I1.i2.p1.1.m1.2a"><mrow id="S1.I1.i2.p1.1.m1.2.3.2" xref="S1.I1.i2.p1.1.m1.2.3.1.cmml"><mn id="S1.I1.i2.p1.1.m1.1.1" xref="S1.I1.i2.p1.1.m1.1.1.cmml">61</mn><mo id="S1.I1.i2.p1.1.m1.2.3.2.1" xref="S1.I1.i2.p1.1.m1.2.3.1.cmml">,</mo><mn id="S1.I1.i2.p1.1.m1.2.2" xref="S1.I1.i2.p1.1.m1.2.2.cmml">036</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i2.p1.1.m1.2b"><list id="S1.I1.i2.p1.1.m1.2.3.1.cmml" xref="S1.I1.i2.p1.1.m1.2.3.2"><cn type="integer" id="S1.I1.i2.p1.1.m1.1.1.cmml" xref="S1.I1.i2.p1.1.m1.1.1">61</cn><cn type="integer" id="S1.I1.i2.p1.1.m1.2.2.cmml" xref="S1.I1.i2.p1.1.m1.2.2">036</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.p1.1.m1.2c">61{,}036</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i2.p1.1.m1.2d">61 , 036</annotation></semantics></math> times verbatim in the training dataset and <math id="S1.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="61" display="inline"><semantics id="S1.I1.i2.p1.2.m2.1a"><mn id="S1.I1.i2.p1.2.m2.1.1" xref="S1.I1.i2.p1.2.m2.1.1.cmml">61</mn><annotation-xml encoding="MathML-Content" id="S1.I1.i2.p1.2.m2.1b"><cn type="integer" id="S1.I1.i2.p1.2.m2.1.1.cmml" xref="S1.I1.i2.p1.2.m2.1.1">61</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.p1.2.m2.1c">61</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i2.p1.2.m2.1d">61</annotation></semantics></math> times in the validation set (<math id="S1.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="0.02\%" display="inline"><semantics id="S1.I1.i2.p1.3.m3.1a"><mrow id="S1.I1.i2.p1.3.m3.1.1" xref="S1.I1.i2.p1.3.m3.1.1.cmml"><mn id="S1.I1.i2.p1.3.m3.1.1.2" xref="S1.I1.i2.p1.3.m3.1.1.2.cmml">0.02</mn><mo id="S1.I1.i2.p1.3.m3.1.1.1" xref="S1.I1.i2.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i2.p1.3.m3.1b"><apply id="S1.I1.i2.p1.3.m3.1.1.cmml" xref="S1.I1.i2.p1.3.m3.1.1"><csymbol cd="latexml" id="S1.I1.i2.p1.3.m3.1.1.1.cmml" xref="S1.I1.i2.p1.3.m3.1.1.1">percent</csymbol><cn type="float" id="S1.I1.i2.p1.3.m3.1.1.2.cmml" xref="S1.I1.i2.p1.3.m3.1.1.2">0.02</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.p1.3.m3.1c">0.02\%</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i2.p1.3.m3.1d">0.02 %</annotation></semantics></math> of the samples in each dataset).
This train-test set overlap not only causes researchers to over-estimate model accuracy, but also biases model selection towards models and hyperparameters that intentionally overfit their training datasets.
</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Training models on deduplicated datasets is more efficient.
Processing a dataset with our framework requires a CPU-only linear-time algorithm.
And so because
these datasets are up to <math id="S1.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="19\%" display="inline"><semantics id="S1.I1.i3.p1.1.m1.1a"><mrow id="S1.I1.i3.p1.1.m1.1.1" xref="S1.I1.i3.p1.1.m1.1.1.cmml"><mn id="S1.I1.i3.p1.1.m1.1.1.2" xref="S1.I1.i3.p1.1.m1.1.1.2.cmml">19</mn><mo id="S1.I1.i3.p1.1.m1.1.1.1" xref="S1.I1.i3.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i3.p1.1.m1.1b"><apply id="S1.I1.i3.p1.1.m1.1.1.cmml" xref="S1.I1.i3.p1.1.m1.1.1"><csymbol cd="latexml" id="S1.I1.i3.p1.1.m1.1.1.1.cmml" xref="S1.I1.i3.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S1.I1.i3.p1.1.m1.1.1.2.cmml" xref="S1.I1.i3.p1.1.m1.1.1.2">19</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i3.p1.1.m1.1c">19\%</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i3.p1.1.m1.1d">19 %</annotation></semantics></math> smaller, even including the deduplication runtime itself, training on deduplicated datasets directly reduces the training cost in terms of time, dollar, and the environment&nbsp;<cite class="ltx_cite ltx_citemacro_cite">Bender et&nbsp;al. (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>); Strubell et&nbsp;al. (<a href="#bib.bib37" title="" class="ltx_ref">2019</a>); Patterson et&nbsp;al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Deduplicating training data does not hurt perplexity: models trained on deduplicated datasets have no worse perplexity compared to baseline models trained on the original datasets.
In some cases deduplication reduces perplexity by up to <math id="S1.I1.i4.p1.1.m1.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S1.I1.i4.p1.1.m1.1a"><mrow id="S1.I1.i4.p1.1.m1.1.1" xref="S1.I1.i4.p1.1.m1.1.1.cmml"><mn id="S1.I1.i4.p1.1.m1.1.1.2" xref="S1.I1.i4.p1.1.m1.1.1.2.cmml">10</mn><mo id="S1.I1.i4.p1.1.m1.1.1.1" xref="S1.I1.i4.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i4.p1.1.m1.1b"><apply id="S1.I1.i4.p1.1.m1.1.1.cmml" xref="S1.I1.i4.p1.1.m1.1.1"><csymbol cd="latexml" id="S1.I1.i4.p1.1.m1.1.1.1.cmml" xref="S1.I1.i4.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S1.I1.i4.p1.1.m1.1.1.2.cmml" xref="S1.I1.i4.p1.1.m1.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i4.p1.1.m1.1c">10\%</annotation><annotation encoding="application/x-llamapun" id="S1.I1.i4.p1.1.m1.1d">10 %</annotation></semantics></math>.
Further, because recent LMs are typically limited to training for just a few epochs <cite class="ltx_cite ltx_citemacro_cite">Radford et&nbsp;al. (<a href="#bib.bib31" title="" class="ltx_ref">2019</a>); Raffel et&nbsp;al. (<a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite>,
by training on higher quality data the models can reach higher accuracy faster.</p>
</div>
</li>
</ol>
<p id="S1.p4.2" class="ltx_p">To summarize, data duplication offers significant advantages and no observed disadvantages.
In the remainder of this paper we present our text deduplication framework in §<a href="#S4" title="4 Methods for Identifying Duplicates ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, and study the extent of duplicate content in common NLP datasets (e.g., C4, Wiki-40B, and LM1B) in §<a href="#S5" title="5 Deduplication Results ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
We then examine the impact of deduplication on test perplexity (§<a href="#S6.SS1" title="6.1 Model Perplexity ‣ 6 Impact on Trained Models ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.1</span></a>) and on the frequency of emitting memorized content (§<a href="#S6.SS2" title="6.2 Generated Text ‣ 6 Impact on Trained Models ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.2</span></a>).
Finally, we analyze to what extent perplexity on existing, released models are skewed as a result of overlap between the train and test/validation splits (§<a href="#S6.SS3" title="6.3 Impact on Existing Models ‣ 6 Impact on Trained Models ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.3</span></a>).</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Large language model datasets.</h5>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.1" class="ltx_p">While we believe our results are independent of model architecture,
we perform our analysis on Transformer-based decoder-only language models <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et&nbsp;al., <a href="#bib.bib40" title="" class="ltx_ref">2017</a>)</cite> trained for open-ended text generation.
These current state-of-the-art models are trained on internet text.
For example, the GPT-2 family of models <cite class="ltx_cite ltx_citemacro_citet">Radford et&nbsp;al. (<a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite> is trained on WebText, a dataset of web documents highly ranked on Reddit—however this dataset was not made available publicly.
A common dataset starting point is CommonCrawl, an index of public webpages.
Among the models trained on CommonCrawl include
GPT-3 <cite class="ltx_cite ltx_citemacro_cite">Brown et&nbsp;al. (<a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite> with the addition of book datasets,
GROVER <cite class="ltx_cite ltx_citemacro_cite">Zellers et&nbsp;al. (<a href="#bib.bib47" title="" class="ltx_ref">2019</a>)</cite> on a restricted subset filtered to news domains called RealNews,
and T5 <cite class="ltx_cite ltx_citemacro_cite">Raffel et&nbsp;al. (<a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite> on a cleaned version of common crawl called C4.
Other models are trained on more curated Internet sources—for example <cite class="ltx_cite ltx_citemacro_citet">Guo et&nbsp;al. (<a href="#bib.bib23" title="" class="ltx_ref">2020</a>)</cite> used high quality processed Wikipedia text from 40 different languages to train monolingual 141.4M parameter language models.
Non-English models necessarily use different datasets; <cite class="ltx_cite ltx_citemacro_citet">Zeng et&nbsp;al. (<a href="#bib.bib48" title="" class="ltx_ref">2021</a>)</cite> for instance introduced PANGU-<math id="S2.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.1.m1.1a"><mi id="S2.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px1.p1.1.m1.1d">italic_α</annotation></semantics></math>, a family of models with up to 200B parameters that were trained on a non-public corpus of cleaned and filtered Chinese-language documents from CommonCrawl and other sources.
Since many of these datasets are not public,
we deduplicate three that are: Wiki-40B, C4, and RealNews–as well as the One Billion Word Language Model Benchmark <cite class="ltx_cite ltx_citemacro_citep">(Chelba et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2013</a>)</cite>,
a smaller
dataset commonly used for evaluation.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Contamination of downstream tasks.</h5>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">When models are trained on datasets constructed by crawling the Internet, it is possible the model will train on the test set of downstream target tasks.
For example, <cite class="ltx_cite ltx_citemacro_citet">Radford et&nbsp;al. (<a href="#bib.bib31" title="" class="ltx_ref">2019</a>, §4)</cite> performed a post-hoc analysis to identify 8-gram overlaps between GPT-2’s training set and datasets used for evaluation,
and <cite class="ltx_cite ltx_citemacro_citet">Dodge et&nbsp;al. (<a href="#bib.bib17" title="" class="ltx_ref">2021b</a>)</cite> analyzed C4 and found that up to 14.4% of test examples for various standard tasks were found verbatim (normalizing for capitalization and punctuation) in the dataset.
A more proactive approach removes contaminated data.
<cite class="ltx_cite ltx_citemacro_citet">Trinh and Le (<a href="#bib.bib39" title="" class="ltx_ref">2018</a>, Appendix B)</cite> removed documents from their CommonCrawl-based train set that overlapped substantially with the commonsense reasoning used for evaluation.
And GPT-3 <cite class="ltx_cite ltx_citemacro_cite">(Brown et&nbsp;al., <a href="#bib.bib10" title="" class="ltx_ref">2020</a>, §5)</cite> did the reverse and removed downstream evaluation examples from their training data by conservatively filtering out any train set examples with a 13-gram overlap with any evaluation example.
Up to <math id="S2.SS0.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.1.m1.1a"><mrow id="S2.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">90</mn><mo id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.1.m1.1c">90\%</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px2.p1.1.m1.1d">90 %</annotation></semantics></math> of tasks were flagged as potentially contaminated.
</p>
</div>
<div id="S2.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p2.1" class="ltx_p">In our research, we do not focus on the impact of duplicate text in pretrained models on downstream benchmark tasks; instead we address how duplicate text in the LM training and validation sets impacts model perplexity and the extent to which generated text included memorized content.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Memorizing training data.</h5>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">The privacy risks of data memorization, for example the ability to extract sensitive data such as valid phone numbers and IRC usernames, are highlighted by
<cite class="ltx_cite ltx_citemacro_citet">Carlini et&nbsp;al. (<a href="#bib.bib11" title="" class="ltx_ref">2020</a>)</cite>.
While their paper finds 604 samples that GPT-2 emitted from its training set, we show that <em id="S2.SS0.SSS0.Px3.p1.1.1" class="ltx_emph ltx_font_italic">over <math id="S2.SS0.SSS0.Px3.p1.1.1.m1.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.1.1.m1.1a"><mrow id="S2.SS0.SSS0.Px3.p1.1.1.m1.1.1" xref="S2.SS0.SSS0.Px3.p1.1.1.m1.1.1.cmml"><mn mathvariant="normal" id="S2.SS0.SSS0.Px3.p1.1.1.m1.1.1.2" xref="S2.SS0.SSS0.Px3.p1.1.1.m1.1.1.2.cmml">1</mn><mo mathvariant="normal" id="S2.SS0.SSS0.Px3.p1.1.1.m1.1.1.1" xref="S2.SS0.SSS0.Px3.p1.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.1.1.m1.1b"><apply id="S2.SS0.SSS0.Px3.p1.1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.1.1.m1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px3.p1.1.1.m1.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S2.SS0.SSS0.Px3.p1.1.1.m1.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.1.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.1.1.m1.1c">1\%</annotation><annotation encoding="application/x-llamapun" id="S2.SS0.SSS0.Px3.p1.1.1.m1.1d">1 %</annotation></semantics></math></em> of the data most models emit is memorized training data.
In computer vision, memorization of training data has been studied from various angles for both discriminative and generative models&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(e.g. Arpit et&nbsp;al., <a href="#bib.bib2" title="" class="ltx_ref">2017</a>; Webster et&nbsp;al., <a href="#bib.bib43" title="" class="ltx_ref">2019</a>; Feldman and Zhang, <a href="#bib.bib18" title="" class="ltx_ref">2020</a>; Stephenson et&nbsp;al., <a href="#bib.bib36" title="" class="ltx_ref">2021</a>; Teterwak et&nbsp;al., <a href="#bib.bib38" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Duplicate text in training data.</h5>

<div id="S2.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px4.p1.1" class="ltx_p">The Book Corpus <cite class="ltx_cite ltx_citemacro_citep">(Zhu et&nbsp;al., <a href="#bib.bib49" title="" class="ltx_ref">2015</a>)</cite>, which was used to train popular models such as BERT, has a substantial amount of exact-duplicate documents according to <cite class="ltx_cite ltx_citemacro_citet">Bandy and Vincent (<a href="#bib.bib3" title="" class="ltx_ref">2021</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Allamanis (<a href="#bib.bib1" title="" class="ltx_ref">2019</a>)</cite> shows that duplicate examples in code datasets cause worsened performance on code understanding tasks.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Language Modeling Datasets</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We analyze the presence of duplicate text in four datasets of varying sizes that have been used for training natural language generation systems, producing general-purpose pre-trained models, and for language model benchmarking.
While this paper restricts itself to English datasets, we expect that non-English datasets suffer from similar issues and could likewise benefit from de-duplication.</p>
</div>
<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Wikipedia (Wiki-40B)</h5>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p1.1" class="ltx_p">consists of multi-lingual cleaned Wikipedia text <cite class="ltx_cite ltx_citemacro_citep">(Guo et&nbsp;al., <a href="#bib.bib23" title="" class="ltx_ref">2020</a>)</cite>.
We take the English portion, which contains 2.9M Wikipedia pages with an average length of 768 BPE tokens.
The dataset creators do not indicate any deduplication was performed aside from removing redirect-pages (e.g., “sunflower” to “Helianthus”).</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">One-Billion Word benchmark (LM1B)</h5>

<div id="S3.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p1.1" class="ltx_p">contains 30M sentences of news commentary <cite class="ltx_cite ltx_citemacro_citep">(Chelba et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2013</a>)</cite>.
Unlike the other datasets we analyze, LM1B’s examples are one sentence long rather than multi-sentence documents.
The average example length is 32 BPE tokens.
While this dataset is extremely standard for benchmarking language models, <cite class="ltx_cite ltx_citemacro_citet">Radford et&nbsp;al. (<a href="#bib.bib31" title="" class="ltx_ref">2019</a>, Sec 4)</cite> note it has 13.2% overlap of the test set with the train set.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Colossal Cleaned Common Crawl (C4)</h5>

<div id="S3.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px3.p1.1" class="ltx_p">is made up of 360M web documents, with an average length of 486 BPE tokens <cite class="ltx_cite ltx_citemacro_citep">(Raffel et&nbsp;al., <a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite>.
C4 was introduced as a pre-training dataset for T5, a set of encoder-decoder models which have been widely used in fine-tuned downstream tasks.
The dataset was previously deduplicated in a more sophisticated process
than the prior two datasets.
Each paragraph was hashed and paragraphs resulting in hash collisions were removed.
This was followed by a pass that removed placeholder text, code, and prohibited words.
See <cite class="ltx_cite ltx_citemacro_citet">Dodge et&nbsp;al. (<a href="#bib.bib16" title="" class="ltx_ref">2021a</a>)</cite> for a detailed breakdown of the source text in C4.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">RealNews</h5>

<div id="S3.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px4.p1.1" class="ltx_p">is a subset of the Common Crawl consisting of articles from news domains <cite class="ltx_cite ltx_citemacro_citep">(Zellers et&nbsp;al., <a href="#bib.bib47" title="" class="ltx_ref">2019</a>)</cite>.
It contains 31M documents with average length 793 BPE tokens.
RealNews was deduplicated by inserting a hash of the first 100 characters of each document into a bloom filter <cite class="ltx_cite ltx_citemacro_citep">(Bloom, <a href="#bib.bib7" title="" class="ltx_ref">1970</a>)</cite> and then excluding any document which resulted in a hash collision.
Like C4, examples with duplicate URLs were excluded.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Methods for Identifying Duplicates</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.2" class="ltx_p">The simplest technique to find duplicate examples would be to perform exact string matching between all example pairs, but as we will show, this is insufficient.
We introduce two complementary methods for performing deduplication.
First, using a suffix array <cite class="ltx_cite ltx_citemacro_cite">Manber and Myers (<a href="#bib.bib28" title="" class="ltx_ref">1993</a>)</cite>, we remove duplicate substrings from the dataset if they occur verbatim in more than one example.
Second, we use MinHash <cite class="ltx_cite ltx_citemacro_citep">(Broder, <a href="#bib.bib8" title="" class="ltx_ref">1997</a>)</cite>, an efficient algorithm for estimating the <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.p1.1.m1.1a"><mi id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><ci id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.p1.1.m1.1d">italic_n</annotation></semantics></math>-gram similarity between all pairs of examples in a corpus, to remove entire examples from the dataset if they have high <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.p1.2.m2.1a"><mi id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><ci id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.p1.2.m2.1d">italic_n</annotation></semantics></math>-gram overlap with any other example.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.3" class="ltx_p">We consider a dataset <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="D=\{x_{i}\}_{i=1}^{N}" display="inline"><semantics id="S4.p2.1.m1.1a"><mrow id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml"><mi id="S4.p2.1.m1.1.1.3" xref="S4.p2.1.m1.1.1.3.cmml">D</mi><mo id="S4.p2.1.m1.1.1.2" xref="S4.p2.1.m1.1.1.2.cmml">=</mo><msubsup id="S4.p2.1.m1.1.1.1" xref="S4.p2.1.m1.1.1.1.cmml"><mrow id="S4.p2.1.m1.1.1.1.1.1.1" xref="S4.p2.1.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S4.p2.1.m1.1.1.1.1.1.1.2" xref="S4.p2.1.m1.1.1.1.1.1.2.cmml">{</mo><msub id="S4.p2.1.m1.1.1.1.1.1.1.1" xref="S4.p2.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S4.p2.1.m1.1.1.1.1.1.1.1.2" xref="S4.p2.1.m1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S4.p2.1.m1.1.1.1.1.1.1.1.3" xref="S4.p2.1.m1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S4.p2.1.m1.1.1.1.1.1.1.3" xref="S4.p2.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.p2.1.m1.1.1.1.1.3" xref="S4.p2.1.m1.1.1.1.1.3.cmml"><mi id="S4.p2.1.m1.1.1.1.1.3.2" xref="S4.p2.1.m1.1.1.1.1.3.2.cmml">i</mi><mo id="S4.p2.1.m1.1.1.1.1.3.1" xref="S4.p2.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S4.p2.1.m1.1.1.1.1.3.3" xref="S4.p2.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S4.p2.1.m1.1.1.1.3" xref="S4.p2.1.m1.1.1.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><apply id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1"><eq id="S4.p2.1.m1.1.1.2.cmml" xref="S4.p2.1.m1.1.1.2"></eq><ci id="S4.p2.1.m1.1.1.3.cmml" xref="S4.p2.1.m1.1.1.3">𝐷</ci><apply id="S4.p2.1.m1.1.1.1.cmml" xref="S4.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S4.p2.1.m1.1.1.1.2.cmml" xref="S4.p2.1.m1.1.1.1">superscript</csymbol><apply id="S4.p2.1.m1.1.1.1.1.cmml" xref="S4.p2.1.m1.1.1.1"><csymbol cd="ambiguous" id="S4.p2.1.m1.1.1.1.1.2.cmml" xref="S4.p2.1.m1.1.1.1">subscript</csymbol><set id="S4.p2.1.m1.1.1.1.1.1.2.cmml" xref="S4.p2.1.m1.1.1.1.1.1.1"><apply id="S4.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.p2.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.p2.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.p2.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S4.p2.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S4.p2.1.m1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S4.p2.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S4.p2.1.m1.1.1.1.1.1.1.1.3">𝑖</ci></apply></set><apply id="S4.p2.1.m1.1.1.1.1.3.cmml" xref="S4.p2.1.m1.1.1.1.1.3"><eq id="S4.p2.1.m1.1.1.1.1.3.1.cmml" xref="S4.p2.1.m1.1.1.1.1.3.1"></eq><ci id="S4.p2.1.m1.1.1.1.1.3.2.cmml" xref="S4.p2.1.m1.1.1.1.1.3.2">𝑖</ci><cn type="integer" id="S4.p2.1.m1.1.1.1.1.3.3.cmml" xref="S4.p2.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S4.p2.1.m1.1.1.1.3.cmml" xref="S4.p2.1.m1.1.1.1.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">D=\{x_{i}\}_{i=1}^{N}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.1d">italic_D = { italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT</annotation></semantics></math> as a collection of <em id="S4.p2.3.1" class="ltx_emph ltx_font_italic">examples</em> <math id="S4.p2.2.m2.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S4.p2.2.m2.1a"><msub id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mi id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml">x</mi><mi id="S4.p2.2.m2.1.1.3" xref="S4.p2.2.m2.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1">subscript</csymbol><ci id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2">𝑥</ci><ci id="S4.p2.2.m2.1.1.3.cmml" xref="S4.p2.2.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.
Each of these examples is itself a sequence of <em id="S4.p2.3.2" class="ltx_emph ltx_font_italic">tokens</em>: <math id="S4.p2.3.m3.4" class="ltx_Math" alttext="x_{i}=\left[x_{i}^{1},x_{i}^{2},\cdots,x_{i}^{s_{i}}\right]" display="inline"><semantics id="S4.p2.3.m3.4a"><mrow id="S4.p2.3.m3.4.4" xref="S4.p2.3.m3.4.4.cmml"><msub id="S4.p2.3.m3.4.4.5" xref="S4.p2.3.m3.4.4.5.cmml"><mi id="S4.p2.3.m3.4.4.5.2" xref="S4.p2.3.m3.4.4.5.2.cmml">x</mi><mi id="S4.p2.3.m3.4.4.5.3" xref="S4.p2.3.m3.4.4.5.3.cmml">i</mi></msub><mo id="S4.p2.3.m3.4.4.4" xref="S4.p2.3.m3.4.4.4.cmml">=</mo><mrow id="S4.p2.3.m3.4.4.3.3" xref="S4.p2.3.m3.4.4.3.4.cmml"><mo id="S4.p2.3.m3.4.4.3.3.4" xref="S4.p2.3.m3.4.4.3.4.cmml">[</mo><msubsup id="S4.p2.3.m3.2.2.1.1.1" xref="S4.p2.3.m3.2.2.1.1.1.cmml"><mi id="S4.p2.3.m3.2.2.1.1.1.2.2" xref="S4.p2.3.m3.2.2.1.1.1.2.2.cmml">x</mi><mi id="S4.p2.3.m3.2.2.1.1.1.2.3" xref="S4.p2.3.m3.2.2.1.1.1.2.3.cmml">i</mi><mn id="S4.p2.3.m3.2.2.1.1.1.3" xref="S4.p2.3.m3.2.2.1.1.1.3.cmml">1</mn></msubsup><mo id="S4.p2.3.m3.4.4.3.3.5" xref="S4.p2.3.m3.4.4.3.4.cmml">,</mo><msubsup id="S4.p2.3.m3.3.3.2.2.2" xref="S4.p2.3.m3.3.3.2.2.2.cmml"><mi id="S4.p2.3.m3.3.3.2.2.2.2.2" xref="S4.p2.3.m3.3.3.2.2.2.2.2.cmml">x</mi><mi id="S4.p2.3.m3.3.3.2.2.2.2.3" xref="S4.p2.3.m3.3.3.2.2.2.2.3.cmml">i</mi><mn id="S4.p2.3.m3.3.3.2.2.2.3" xref="S4.p2.3.m3.3.3.2.2.2.3.cmml">2</mn></msubsup><mo id="S4.p2.3.m3.4.4.3.3.6" xref="S4.p2.3.m3.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml">⋯</mi><mo id="S4.p2.3.m3.4.4.3.3.7" xref="S4.p2.3.m3.4.4.3.4.cmml">,</mo><msubsup id="S4.p2.3.m3.4.4.3.3.3" xref="S4.p2.3.m3.4.4.3.3.3.cmml"><mi id="S4.p2.3.m3.4.4.3.3.3.2.2" xref="S4.p2.3.m3.4.4.3.3.3.2.2.cmml">x</mi><mi id="S4.p2.3.m3.4.4.3.3.3.2.3" xref="S4.p2.3.m3.4.4.3.3.3.2.3.cmml">i</mi><msub id="S4.p2.3.m3.4.4.3.3.3.3" xref="S4.p2.3.m3.4.4.3.3.3.3.cmml"><mi id="S4.p2.3.m3.4.4.3.3.3.3.2" xref="S4.p2.3.m3.4.4.3.3.3.3.2.cmml">s</mi><mi id="S4.p2.3.m3.4.4.3.3.3.3.3" xref="S4.p2.3.m3.4.4.3.3.3.3.3.cmml">i</mi></msub></msubsup><mo id="S4.p2.3.m3.4.4.3.3.8" xref="S4.p2.3.m3.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.4b"><apply id="S4.p2.3.m3.4.4.cmml" xref="S4.p2.3.m3.4.4"><eq id="S4.p2.3.m3.4.4.4.cmml" xref="S4.p2.3.m3.4.4.4"></eq><apply id="S4.p2.3.m3.4.4.5.cmml" xref="S4.p2.3.m3.4.4.5"><csymbol cd="ambiguous" id="S4.p2.3.m3.4.4.5.1.cmml" xref="S4.p2.3.m3.4.4.5">subscript</csymbol><ci id="S4.p2.3.m3.4.4.5.2.cmml" xref="S4.p2.3.m3.4.4.5.2">𝑥</ci><ci id="S4.p2.3.m3.4.4.5.3.cmml" xref="S4.p2.3.m3.4.4.5.3">𝑖</ci></apply><list id="S4.p2.3.m3.4.4.3.4.cmml" xref="S4.p2.3.m3.4.4.3.3"><apply id="S4.p2.3.m3.2.2.1.1.1.cmml" xref="S4.p2.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.p2.3.m3.2.2.1.1.1.1.cmml" xref="S4.p2.3.m3.2.2.1.1.1">superscript</csymbol><apply id="S4.p2.3.m3.2.2.1.1.1.2.cmml" xref="S4.p2.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S4.p2.3.m3.2.2.1.1.1.2.1.cmml" xref="S4.p2.3.m3.2.2.1.1.1">subscript</csymbol><ci id="S4.p2.3.m3.2.2.1.1.1.2.2.cmml" xref="S4.p2.3.m3.2.2.1.1.1.2.2">𝑥</ci><ci id="S4.p2.3.m3.2.2.1.1.1.2.3.cmml" xref="S4.p2.3.m3.2.2.1.1.1.2.3">𝑖</ci></apply><cn type="integer" id="S4.p2.3.m3.2.2.1.1.1.3.cmml" xref="S4.p2.3.m3.2.2.1.1.1.3">1</cn></apply><apply id="S4.p2.3.m3.3.3.2.2.2.cmml" xref="S4.p2.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.p2.3.m3.3.3.2.2.2.1.cmml" xref="S4.p2.3.m3.3.3.2.2.2">superscript</csymbol><apply id="S4.p2.3.m3.3.3.2.2.2.2.cmml" xref="S4.p2.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S4.p2.3.m3.3.3.2.2.2.2.1.cmml" xref="S4.p2.3.m3.3.3.2.2.2">subscript</csymbol><ci id="S4.p2.3.m3.3.3.2.2.2.2.2.cmml" xref="S4.p2.3.m3.3.3.2.2.2.2.2">𝑥</ci><ci id="S4.p2.3.m3.3.3.2.2.2.2.3.cmml" xref="S4.p2.3.m3.3.3.2.2.2.2.3">𝑖</ci></apply><cn type="integer" id="S4.p2.3.m3.3.3.2.2.2.3.cmml" xref="S4.p2.3.m3.3.3.2.2.2.3">2</cn></apply><ci id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1">⋯</ci><apply id="S4.p2.3.m3.4.4.3.3.3.cmml" xref="S4.p2.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S4.p2.3.m3.4.4.3.3.3.1.cmml" xref="S4.p2.3.m3.4.4.3.3.3">superscript</csymbol><apply id="S4.p2.3.m3.4.4.3.3.3.2.cmml" xref="S4.p2.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S4.p2.3.m3.4.4.3.3.3.2.1.cmml" xref="S4.p2.3.m3.4.4.3.3.3">subscript</csymbol><ci id="S4.p2.3.m3.4.4.3.3.3.2.2.cmml" xref="S4.p2.3.m3.4.4.3.3.3.2.2">𝑥</ci><ci id="S4.p2.3.m3.4.4.3.3.3.2.3.cmml" xref="S4.p2.3.m3.4.4.3.3.3.2.3">𝑖</ci></apply><apply id="S4.p2.3.m3.4.4.3.3.3.3.cmml" xref="S4.p2.3.m3.4.4.3.3.3.3"><csymbol cd="ambiguous" id="S4.p2.3.m3.4.4.3.3.3.3.1.cmml" xref="S4.p2.3.m3.4.4.3.3.3.3">subscript</csymbol><ci id="S4.p2.3.m3.4.4.3.3.3.3.2.cmml" xref="S4.p2.3.m3.4.4.3.3.3.3.2">𝑠</ci><ci id="S4.p2.3.m3.4.4.3.3.3.3.3.cmml" xref="S4.p2.3.m3.4.4.3.3.3.3.3">𝑖</ci></apply></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.4c">x_{i}=\left[x_{i}^{1},x_{i}^{2},\cdots,x_{i}^{s_{i}}\right]</annotation><annotation encoding="application/x-llamapun" id="S4.p2.3.m3.4d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = [ italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT , ⋯ , italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_s start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ]</annotation></semantics></math>.
</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Exact Substring Duplication</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.4" class="ltx_p">Due to the diversity of possibilities in human language, it is rare for the same idea to be expressed identically in multiple documents unless one expression is derived from the other, or both are quoting from a shared source.
This observation motivates deduplicating exact substrings. We call our approach <span id="S4.SS1.p1.4.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span>.
When two examples <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><msub id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">x</mi><mi id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">𝑥</ci><ci id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="x_{j}" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><msub id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">x</mi><mi id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">𝑥</ci><ci id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">x_{j}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> share a sufficiently long substring (that is, a substring for which <math id="S4.SS1.p1.3.m3.2" class="ltx_math_unparsed" alttext="x_{i}^{a..a+k}=x_{j}^{b..b+k}" display="inline"><semantics id="S4.SS1.p1.3.m3.2a"><mrow id="S4.SS1.p1.3.m3.2.3"><msubsup id="S4.SS1.p1.3.m3.2.3.2"><mi id="S4.SS1.p1.3.m3.2.3.2.2.2">x</mi><mi id="S4.SS1.p1.3.m3.2.3.2.2.3">i</mi><mrow id="S4.SS1.p1.3.m3.1.1.1"><mi id="S4.SS1.p1.3.m3.1.1.1.1">a</mi><mo lspace="0em" rspace="0.0835em" id="S4.SS1.p1.3.m3.1.1.1.2">.</mo><mo lspace="0.0835em" rspace="0.167em" id="S4.SS1.p1.3.m3.1.1.1.3">.</mo><mi id="S4.SS1.p1.3.m3.1.1.1.4">a</mi><mo id="S4.SS1.p1.3.m3.1.1.1.5">+</mo><mi id="S4.SS1.p1.3.m3.1.1.1.6">k</mi></mrow></msubsup><mo id="S4.SS1.p1.3.m3.2.3.1">=</mo><msubsup id="S4.SS1.p1.3.m3.2.3.3"><mi id="S4.SS1.p1.3.m3.2.3.3.2.2">x</mi><mi id="S4.SS1.p1.3.m3.2.3.3.2.3">j</mi><mrow id="S4.SS1.p1.3.m3.2.2.1"><mi id="S4.SS1.p1.3.m3.2.2.1.1">b</mi><mo lspace="0em" rspace="0.0835em" id="S4.SS1.p1.3.m3.2.2.1.2">.</mo><mo lspace="0.0835em" rspace="0.167em" id="S4.SS1.p1.3.m3.2.2.1.3">.</mo><mi id="S4.SS1.p1.3.m3.2.2.1.4">b</mi><mo id="S4.SS1.p1.3.m3.2.2.1.5">+</mo><mi id="S4.SS1.p1.3.m3.2.2.1.6">k</mi></mrow></msubsup></mrow><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.2b">x_{i}^{a..a+k}=x_{j}^{b..b+k}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.3.m3.2c">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_a . . italic_a + italic_k end_POSTSUPERSCRIPT = italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_b . . italic_b + italic_k end_POSTSUPERSCRIPT</annotation></semantics></math>), that substring is removed from one of them.
Based on statistical analyses (§<a href="#A2.SS0.SSS0.Px5" title="Setting a threshold of duplicates. ‣ Appendix B Further Details on ExactSubstr ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>), we select <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="k=50" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mrow id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml"><mi id="S4.SS1.p1.4.m4.1.1.2" xref="S4.SS1.p1.4.m4.1.1.2.cmml">k</mi><mo id="S4.SS1.p1.4.m4.1.1.1" xref="S4.SS1.p1.4.m4.1.1.1.cmml">=</mo><mn id="S4.SS1.p1.4.m4.1.1.3" xref="S4.SS1.p1.4.m4.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><apply id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1"><eq id="S4.SS1.p1.4.m4.1.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1.1"></eq><ci id="S4.SS1.p1.4.m4.1.1.2.cmml" xref="S4.SS1.p1.4.m4.1.1.2">𝑘</ci><cn type="integer" id="S4.SS1.p1.4.m4.1.1.3.cmml" xref="S4.SS1.p1.4.m4.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">k=50</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.4.m4.1d">italic_k = 50</annotation></semantics></math> tokens as the minimum matching substring length.
A breakdown of the computation needed for this approach can be found in Appendix <a href="#A2" title="Appendix B Further Details on ExactSubstr ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Suffix Arrays</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.6" class="ltx_p">This exact-substring-matching criterion, while conceptually simple, is computationally prohibitive with naive (quadratic) all-pair matching.
To improve the efficiency, we concatenate all the examples of the entire dataset <math id="S4.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS1.SSS1.p1.1.m1.1a"><mi id="S4.SS1.SSS1.p1.1.m1.1.1" xref="S4.SS1.SSS1.p1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.1.m1.1b"><ci id="S4.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p1.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.1.m1.1c">D</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.p1.1.m1.1d">italic_D</annotation></semantics></math> into a giant sequence <math id="S4.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S4.SS1.SSS1.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS1.p1.2.m2.1.1" xref="S4.SS1.SSS1.p1.2.m2.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.2.m2.1b"><ci id="S4.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS1.p1.2.m2.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.2.m2.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.p1.2.m2.1d">caligraphic_S</annotation></semantics></math>, and construct a Suffix Array <math id="S4.SS1.SSS1.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S4.SS1.SSS1.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS1.p1.3.m3.1.1" xref="S4.SS1.SSS1.p1.3.m3.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.3.m3.1b"><ci id="S4.SS1.SSS1.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS1.p1.3.m3.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.3.m3.1c">\mathcal{A}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.p1.3.m3.1d">caligraphic_A</annotation></semantics></math> of <math id="S4.SS1.SSS1.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S4.SS1.SSS1.p1.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS1.p1.4.m4.1.1" xref="S4.SS1.SSS1.p1.4.m4.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.4.m4.1b"><ci id="S4.SS1.SSS1.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS1.p1.4.m4.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.4.m4.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.p1.4.m4.1d">caligraphic_S</annotation></semantics></math>.
A suffix array <cite class="ltx_cite ltx_citemacro_citep">(Manber and Myers, <a href="#bib.bib28" title="" class="ltx_ref">1993</a>)</cite> is a representation of a suffix tree <cite class="ltx_cite ltx_citemacro_citep">(Weiner, <a href="#bib.bib44" title="" class="ltx_ref">1973</a>)</cite> that can be constructed in linear time in <math id="S4.SS1.SSS1.p1.5.m5.1" class="ltx_Math" alttext="\lVert\mathcal{S}\rVert" display="inline"><semantics id="S4.SS1.SSS1.p1.5.m5.1a"><mrow id="S4.SS1.SSS1.p1.5.m5.1.2.2" xref="S4.SS1.SSS1.p1.5.m5.1.2.1.cmml"><mo fence="true" rspace="0em" id="S4.SS1.SSS1.p1.5.m5.1.2.2.1" xref="S4.SS1.SSS1.p1.5.m5.1.2.1.1.cmml">∥</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS1.p1.5.m5.1.1" xref="S4.SS1.SSS1.p1.5.m5.1.1.cmml">𝒮</mi><mo fence="true" lspace="0em" id="S4.SS1.SSS1.p1.5.m5.1.2.2.2" xref="S4.SS1.SSS1.p1.5.m5.1.2.1.1.cmml">∥</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.5.m5.1b"><apply id="S4.SS1.SSS1.p1.5.m5.1.2.1.cmml" xref="S4.SS1.SSS1.p1.5.m5.1.2.2"><csymbol cd="latexml" id="S4.SS1.SSS1.p1.5.m5.1.2.1.1.cmml" xref="S4.SS1.SSS1.p1.5.m5.1.2.2.1">delimited-∥∥</csymbol><ci id="S4.SS1.SSS1.p1.5.m5.1.1.cmml" xref="S4.SS1.SSS1.p1.5.m5.1.1">𝒮</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.5.m5.1c">\lVert\mathcal{S}\rVert</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.p1.5.m5.1d">∥ caligraphic_S ∥</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(Kärkkäinen and Sanders, <a href="#bib.bib26" title="" class="ltx_ref">2003</a>)</cite>
and enables efficient computation of many substring queries; in particular, they allow us to identify duplicated training examples in linear time.
Suffix arrays have the advantage over suffix trees in that they are 10–100<math id="S4.SS1.SSS1.p1.6.m6.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.SS1.SSS1.p1.6.m6.1a"><mo id="S4.SS1.SSS1.p1.6.m6.1.1" xref="S4.SS1.SSS1.p1.6.m6.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p1.6.m6.1b"><times id="S4.SS1.SSS1.p1.6.m6.1.1.cmml" xref="S4.SS1.SSS1.p1.6.m6.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p1.6.m6.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.p1.6.m6.1d">×</annotation></semantics></math>
more memory efficient <cite class="ltx_cite ltx_citemacro_cite">Manber and Myers (<a href="#bib.bib28" title="" class="ltx_ref">1993</a>)</cite>, requiring just 8 bytes per input token, though they are asymptotically less
efficient for some query types.
They have been used widely in NLP, such as for efficient TF-IDF computation <cite class="ltx_cite ltx_citemacro_citep">(Yamamoto and Church, <a href="#bib.bib46" title="" class="ltx_ref">2001</a>)</cite> and document clustering <cite class="ltx_cite ltx_citemacro_citep">(Chim and Deng, <a href="#bib.bib13" title="" class="ltx_ref">2007</a>)</cite>.</p>
</div>
<div id="S4.SS1.SSS1.p2" class="ltx_para">
<p id="S4.SS1.SSS1.p2.2" class="ltx_p">The suffix array <math id="S4.SS1.SSS1.p2.1.m1.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S4.SS1.SSS1.p2.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS1.p2.1.m1.1.1" xref="S4.SS1.SSS1.p2.1.m1.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p2.1.m1.1b"><ci id="S4.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S4.SS1.SSS1.p2.1.m1.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p2.1.m1.1c">\mathcal{A}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.p2.1.m1.1d">caligraphic_A</annotation></semantics></math> for a sequence <math id="S4.SS1.SSS1.p2.2.m2.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S4.SS1.SSS1.p2.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS1.p2.2.m2.1.1" xref="S4.SS1.SSS1.p2.2.m2.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p2.2.m2.1b"><ci id="S4.SS1.SSS1.p2.2.m2.1.1.cmml" xref="S4.SS1.SSS1.p2.2.m2.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p2.2.m2.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.p2.2.m2.1d">caligraphic_S</annotation></semantics></math> is a lexicographically-ordered list of all suffixes contained in the sequence.
Formally,</p>
<table id="S4.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex1.m1.2" class="ltx_Math" alttext="\mathcal{A}(\mathcal{S})=\mathop{\text{arg sort}}\text{all\_suffixes}(\mathcal{S})" display="block"><semantics id="S4.Ex1.m1.2a"><mrow id="S4.Ex1.m1.2.3" xref="S4.Ex1.m1.2.3.cmml"><mrow id="S4.Ex1.m1.2.3.2" xref="S4.Ex1.m1.2.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.Ex1.m1.2.3.2.2" xref="S4.Ex1.m1.2.3.2.2.cmml">𝒜</mi><mo id="S4.Ex1.m1.2.3.2.1" xref="S4.Ex1.m1.2.3.2.1.cmml" lspace="0px" rspace="0px"></mo><mrow id="S4.Ex1.m1.2.3.2.3.2" xref="S4.Ex1.m1.2.3.2.cmml"><mo stretchy="false" id="S4.Ex1.m1.2.3.2.3.2.1" xref="S4.Ex1.m1.2.3.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex1.m1.1.1" xref="S4.Ex1.m1.1.1.cmml">𝒮</mi><mo stretchy="false" id="S4.Ex1.m1.2.3.2.3.2.2" xref="S4.Ex1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo id="S4.Ex1.m1.2.3.1" xref="S4.Ex1.m1.2.3.1.cmml">=</mo><mrow id="S4.Ex1.m1.2.3.3" xref="S4.Ex1.m1.2.3.3.cmml"><mtext id="S4.Ex1.m1.2.3.3.1" xref="S4.Ex1.m1.2.3.3.1a.cmml">arg sort</mtext><mrow id="S4.Ex1.m1.2.3.3.2" xref="S4.Ex1.m1.2.3.3.2.cmml"><mtext id="S4.Ex1.m1.2.3.3.2.2" xref="S4.Ex1.m1.2.3.3.2.2a.cmml">all_suffixes</mtext><mo id="S4.Ex1.m1.2.3.3.2.1" xref="S4.Ex1.m1.2.3.3.2.1.cmml" lspace="0px" rspace="0px"></mo><mrow id="S4.Ex1.m1.2.3.3.2.3.2" xref="S4.Ex1.m1.2.3.3.2.cmml"><mo stretchy="false" id="S4.Ex1.m1.2.3.3.2.3.2.1" xref="S4.Ex1.m1.2.3.3.2.cmml">(</mo><mi class="ltx_font_mathcaligraphic" id="S4.Ex1.m1.2.2" xref="S4.Ex1.m1.2.2.cmml">𝒮</mi><mo stretchy="false" id="S4.Ex1.m1.2.3.3.2.3.2.2" xref="S4.Ex1.m1.2.3.3.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.2b"><apply id="S4.Ex1.m1.2.3.cmml" xref="S4.Ex1.m1.2.3"><eq id="S4.Ex1.m1.2.3.1.cmml" xref="S4.Ex1.m1.2.3.1"></eq><apply id="S4.Ex1.m1.2.3.2.cmml" xref="S4.Ex1.m1.2.3.2"><times id="S4.Ex1.m1.2.3.2.1.cmml" xref="S4.Ex1.m1.2.3.2.1"></times><ci id="S4.Ex1.m1.2.3.2.2.cmml" xref="S4.Ex1.m1.2.3.2.2">𝒜</ci><ci id="S4.Ex1.m1.1.1.cmml" xref="S4.Ex1.m1.1.1">𝒮</ci></apply><apply id="S4.Ex1.m1.2.3.3.cmml" xref="S4.Ex1.m1.2.3.3"><ci id="S4.Ex1.m1.2.3.3.1a.cmml" xref="S4.Ex1.m1.2.3.3.1"><mtext id="S4.Ex1.m1.2.3.3.1.cmml" xref="S4.Ex1.m1.2.3.3.1">arg sort</mtext></ci><apply id="S4.Ex1.m1.2.3.3.2.cmml" xref="S4.Ex1.m1.2.3.3.2"><times id="S4.Ex1.m1.2.3.3.2.1.cmml" xref="S4.Ex1.m1.2.3.3.2.1"></times><ci id="S4.Ex1.m1.2.3.3.2.2a.cmml" xref="S4.Ex1.m1.2.3.3.2.2"><mtext id="S4.Ex1.m1.2.3.3.2.2.cmml" xref="S4.Ex1.m1.2.3.3.2.2">all_suffixes</mtext></ci><ci id="S4.Ex1.m1.2.2.cmml" xref="S4.Ex1.m1.2.2">𝒮</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.2c">\mathcal{A}(\mathcal{S})=\mathop{\text{arg sort}}\text{all\_suffixes}(\mathcal{S})</annotation><annotation encoding="application/x-llamapun" id="S4.Ex1.m1.2d">caligraphic_A ( caligraphic_S ) = arg sort all_suffixes ( caligraphic_S )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS1.SSS1.p2.3" class="ltx_p">For example, the suffixes of the sequence “banana” are (“banana”, “anana”, “nana” “ana”, “na”, “a”)
and so the suffix array is the sequence (6 4 2 1 5 3).
In practice, we construct <math id="S4.SS1.SSS1.p2.3.m1.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S4.SS1.SSS1.p2.3.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS1.p2.3.m1.1.1" xref="S4.SS1.SSS1.p2.3.m1.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS1.p2.3.m1.1b"><ci id="S4.SS1.SSS1.p2.3.m1.1.1.cmml" xref="S4.SS1.SSS1.p2.3.m1.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS1.p2.3.m1.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS1.p2.3.m1.1d">caligraphic_S</annotation></semantics></math> from the bytes of the BPE tokenization of the text (§<a href="#S6" title="6 Impact on Trained Models ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>).</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Substring matching</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.8" class="ltx_p">After constructing <math id="S4.SS1.SSS2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S4.SS1.SSS2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS2.p1.1.m1.1.1" xref="S4.SS1.SSS2.p1.1.m1.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.1.m1.1b"><ci id="S4.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS2.p1.1.m1.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.1.m1.1c">\mathcal{A}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p1.1.m1.1d">caligraphic_A</annotation></semantics></math>, it is straightforward to identify duplicated training examples.
Suppose that the sequence <math id="S4.SS1.SSS2.p1.2.m2.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S4.SS1.SSS2.p1.2.m2.1a"><mi id="S4.SS1.SSS2.p1.2.m2.1.1" xref="S4.SS1.SSS2.p1.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.2.m2.1b"><ci id="S4.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS2.p1.2.m2.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.2.m2.1c">s</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p1.2.m2.1d">italic_s</annotation></semantics></math> was repeated exactly twice in the training dataset <math id="S4.SS1.SSS2.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{S}" display="inline"><semantics id="S4.SS1.SSS2.p1.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS2.p1.3.m3.1.1" xref="S4.SS1.SSS2.p1.3.m3.1.1.cmml">𝒮</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.3.m3.1b"><ci id="S4.SS1.SSS2.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS2.p1.3.m3.1.1">𝒮</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.3.m3.1c">\mathcal{S}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p1.3.m3.1d">caligraphic_S</annotation></semantics></math> at positions <math id="S4.SS1.SSS2.p1.4.m4.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS1.SSS2.p1.4.m4.1a"><mi id="S4.SS1.SSS2.p1.4.m4.1.1" xref="S4.SS1.SSS2.p1.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.4.m4.1b"><ci id="S4.SS1.SSS2.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS2.p1.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p1.4.m4.1d">italic_i</annotation></semantics></math> and <math id="S4.SS1.SSS2.p1.5.m5.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S4.SS1.SSS2.p1.5.m5.1a"><mi id="S4.SS1.SSS2.p1.5.m5.1.1" xref="S4.SS1.SSS2.p1.5.m5.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.5.m5.1b"><ci id="S4.SS1.SSS2.p1.5.m5.1.1.cmml" xref="S4.SS1.SSS2.p1.5.m5.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.5.m5.1c">j</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p1.5.m5.1d">italic_j</annotation></semantics></math>,
that is, <math id="S4.SS1.SSS2.p1.6.m6.2" class="ltx_math_unparsed" alttext="\mathcal{S}_{i..i+|s|}=\mathcal{S}_{j..j+|s|}" display="inline"><semantics id="S4.SS1.SSS2.p1.6.m6.2a"><mrow id="S4.SS1.SSS2.p1.6.m6.2.3"><msub id="S4.SS1.SSS2.p1.6.m6.2.3.2"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS2.p1.6.m6.2.3.2.2">𝒮</mi><mrow id="S4.SS1.SSS2.p1.6.m6.1.1.1"><mi id="S4.SS1.SSS2.p1.6.m6.1.1.1.1">i</mi><mo lspace="0em" rspace="0.0835em" id="S4.SS1.SSS2.p1.6.m6.1.1.1.2">.</mo><mo lspace="0.0835em" rspace="0.167em" id="S4.SS1.SSS2.p1.6.m6.1.1.1.3">.</mo><mi id="S4.SS1.SSS2.p1.6.m6.1.1.1.4">i</mi><mo rspace="0em" id="S4.SS1.SSS2.p1.6.m6.1.1.1.5">+</mo><mo fence="false" rspace="0.167em" stretchy="false" id="S4.SS1.SSS2.p1.6.m6.1.1.1.6">|</mo><mi id="S4.SS1.SSS2.p1.6.m6.1.1.1.7">s</mi><mo fence="false" stretchy="false" id="S4.SS1.SSS2.p1.6.m6.1.1.1.8">|</mo></mrow></msub><mo id="S4.SS1.SSS2.p1.6.m6.2.3.1">=</mo><msub id="S4.SS1.SSS2.p1.6.m6.2.3.3"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS2.p1.6.m6.2.3.3.2">𝒮</mi><mrow id="S4.SS1.SSS2.p1.6.m6.2.2.1"><mi id="S4.SS1.SSS2.p1.6.m6.2.2.1.1">j</mi><mo lspace="0em" rspace="0.0835em" id="S4.SS1.SSS2.p1.6.m6.2.2.1.2">.</mo><mo lspace="0.0835em" rspace="0.167em" id="S4.SS1.SSS2.p1.6.m6.2.2.1.3">.</mo><mi id="S4.SS1.SSS2.p1.6.m6.2.2.1.4">j</mi><mo rspace="0em" id="S4.SS1.SSS2.p1.6.m6.2.2.1.5">+</mo><mo fence="false" rspace="0.167em" stretchy="false" id="S4.SS1.SSS2.p1.6.m6.2.2.1.6">|</mo><mi id="S4.SS1.SSS2.p1.6.m6.2.2.1.7">s</mi><mo fence="false" stretchy="false" id="S4.SS1.SSS2.p1.6.m6.2.2.1.8">|</mo></mrow></msub></mrow><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.6.m6.2b">\mathcal{S}_{i..i+|s|}=\mathcal{S}_{j..j+|s|}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p1.6.m6.2c">caligraphic_S start_POSTSUBSCRIPT italic_i . . italic_i + | italic_s | end_POSTSUBSCRIPT = caligraphic_S start_POSTSUBSCRIPT italic_j . . italic_j + | italic_s | end_POSTSUBSCRIPT</annotation></semantics></math>.
Then the indices <math id="S4.SS1.SSS2.p1.7.m7.2" class="ltx_Math" alttext="i,j" display="inline"><semantics id="S4.SS1.SSS2.p1.7.m7.2a"><mrow id="S4.SS1.SSS2.p1.7.m7.2.3.2" xref="S4.SS1.SSS2.p1.7.m7.2.3.1.cmml"><mi id="S4.SS1.SSS2.p1.7.m7.1.1" xref="S4.SS1.SSS2.p1.7.m7.1.1.cmml">i</mi><mo id="S4.SS1.SSS2.p1.7.m7.2.3.2.1" xref="S4.SS1.SSS2.p1.7.m7.2.3.1.cmml">,</mo><mi id="S4.SS1.SSS2.p1.7.m7.2.2" xref="S4.SS1.SSS2.p1.7.m7.2.2.cmml">j</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.7.m7.2b"><list id="S4.SS1.SSS2.p1.7.m7.2.3.1.cmml" xref="S4.SS1.SSS2.p1.7.m7.2.3.2"><ci id="S4.SS1.SSS2.p1.7.m7.1.1.cmml" xref="S4.SS1.SSS2.p1.7.m7.1.1">𝑖</ci><ci id="S4.SS1.SSS2.p1.7.m7.2.2.cmml" xref="S4.SS1.SSS2.p1.7.m7.2.2">𝑗</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.7.m7.2c">i,j</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p1.7.m7.2d">italic_i , italic_j</annotation></semantics></math> will occur adjacent to each other in the suffix array <math id="S4.SS1.SSS2.p1.8.m8.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="S4.SS1.SSS2.p1.8.m8.1a"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS2.p1.8.m8.1.1" xref="S4.SS1.SSS2.p1.8.m8.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p1.8.m8.1b"><ci id="S4.SS1.SSS2.p1.8.m8.1.1.cmml" xref="S4.SS1.SSS2.p1.8.m8.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p1.8.m8.1c">\mathcal{A}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p1.8.m8.1d">caligraphic_A</annotation></semantics></math>.</p>
</div>
<div id="S4.SS1.SSS2.p2" class="ltx_para">
<p id="S4.SS1.SSS2.p2.1" class="ltx_p">Finding all repeated sequences is thus a matter of linearly scanning the suffix array from
beginning to end and looking for sequences <math id="S4.SS1.SSS2.p2.1.m1.2" class="ltx_Math" alttext="\mathcal{A}_{i},\mathcal{A}_{i+1}" display="inline"><semantics id="S4.SS1.SSS2.p2.1.m1.2a"><mrow id="S4.SS1.SSS2.p2.1.m1.2.2.2" xref="S4.SS1.SSS2.p2.1.m1.2.2.3.cmml"><msub id="S4.SS1.SSS2.p2.1.m1.1.1.1.1" xref="S4.SS1.SSS2.p2.1.m1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS2.p2.1.m1.1.1.1.1.2" xref="S4.SS1.SSS2.p2.1.m1.1.1.1.1.2.cmml">𝒜</mi><mi id="S4.SS1.SSS2.p2.1.m1.1.1.1.1.3" xref="S4.SS1.SSS2.p2.1.m1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.SS1.SSS2.p2.1.m1.2.2.2.3" xref="S4.SS1.SSS2.p2.1.m1.2.2.3.cmml">,</mo><msub id="S4.SS1.SSS2.p2.1.m1.2.2.2.2" xref="S4.SS1.SSS2.p2.1.m1.2.2.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS2.p2.1.m1.2.2.2.2.2" xref="S4.SS1.SSS2.p2.1.m1.2.2.2.2.2.cmml">𝒜</mi><mrow id="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3" xref="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3.cmml"><mi id="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3.2" xref="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3.2.cmml">i</mi><mo id="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3.1" xref="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3.1.cmml">+</mo><mn id="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3.3" xref="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3.3.cmml">1</mn></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS2.p2.1.m1.2b"><list id="S4.SS1.SSS2.p2.1.m1.2.2.3.cmml" xref="S4.SS1.SSS2.p2.1.m1.2.2.2"><apply id="S4.SS1.SSS2.p2.1.m1.1.1.1.1.cmml" xref="S4.SS1.SSS2.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS2.p2.1.m1.1.1.1.1.1.cmml" xref="S4.SS1.SSS2.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S4.SS1.SSS2.p2.1.m1.1.1.1.1.2.cmml" xref="S4.SS1.SSS2.p2.1.m1.1.1.1.1.2">𝒜</ci><ci id="S4.SS1.SSS2.p2.1.m1.1.1.1.1.3.cmml" xref="S4.SS1.SSS2.p2.1.m1.1.1.1.1.3">𝑖</ci></apply><apply id="S4.SS1.SSS2.p2.1.m1.2.2.2.2.cmml" xref="S4.SS1.SSS2.p2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S4.SS1.SSS2.p2.1.m1.2.2.2.2.1.cmml" xref="S4.SS1.SSS2.p2.1.m1.2.2.2.2">subscript</csymbol><ci id="S4.SS1.SSS2.p2.1.m1.2.2.2.2.2.cmml" xref="S4.SS1.SSS2.p2.1.m1.2.2.2.2.2">𝒜</ci><apply id="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3.cmml" xref="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3"><plus id="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3.1.cmml" xref="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3.1"></plus><ci id="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3.2.cmml" xref="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3.2">𝑖</ci><cn type="integer" id="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3.3.cmml" xref="S4.SS1.SSS2.p2.1.m1.2.2.2.2.3.3">1</cn></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS2.p2.1.m1.2c">\mathcal{A}_{i},\mathcal{A}_{i+1}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS2.p2.1.m1.2d">caligraphic_A start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , caligraphic_A start_POSTSUBSCRIPT italic_i + 1 end_POSTSUBSCRIPT</annotation></semantics></math> that share a common prefix of
at least some threshold length.
Any satisfying sequences are recorded.
This algorithm is embarrassingly parallel, and so we can efficiently process the dataset.
Based on experimentation (Appendix <a href="#A2.SS0.SSS0.Px5" title="Setting a threshold of duplicates. ‣ Appendix B Further Details on ExactSubstr ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>), we choose a threshold length of 50 BPE tokens for all experiments.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.1.1.1" class="ltx_tr">
<th id="S4.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Dataset</th>
<th id="S4.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">Example</th>
<th id="S4.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Near-Duplicate Example</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.1.2.1" class="ltx_tr">
<th id="S4.T1.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Wiki-40B</th>
<td id="S4.T1.1.2.1.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:169.1pt;">
<p id="S4.T1.1.2.1.2.1" class="ltx_p ltx_align_top"><span id="S4.T1.1.2.1.2.1.1" class="ltx_text" style="background-color:#FFFCBB;">\n_START_ARTICLE_\nHum Award for </span> Most Impactful Character <span id="S4.T1.1.2.1.2.1.2" class="ltx_text" style="background-color:#FFFCBB;">\n_START_SECTION_\nWinners and nominees\n_START_PARAGRAPH_\nIn the list below, winners are listed first in the colored row, followed by the other nominees.</span> […]</p>
</td>
<td id="S4.T1.1.2.1.3" class="ltx_td ltx_align_justify ltx_border_t" style="width:177.8pt;">
<p id="S4.T1.1.2.1.3.1" class="ltx_p ltx_align_top"><span id="S4.T1.1.2.1.3.1.1" class="ltx_text" style="background-color:#FFFCBB;">\n_START_ARTICLE_\nHum Award for</span> Best Actor in a Negative Role <span id="S4.T1.1.2.1.3.1.2" class="ltx_text" style="background-color:#FFFCBB;">\n_START_SECTION_\nWinners and nominees\n_START_PARAGRAPH_\nIn the list below, winners are listed first in the colored row, followed by the other nominees.</span> […]</p>
</td>
</tr>
<tr id="S4.T1.1.3.2" class="ltx_tr">
<th id="S4.T1.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">LM1B</th>
<td id="S4.T1.1.3.2.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:169.1pt;"><span id="S4.T1.1.3.2.2.1" class="ltx_text ltx_align_top" style="background-color:#FFFCBB;">I left for California in 1979 and tracked Cleveland ’s changes on trips back to visit my sisters .</span></td>
<td id="S4.T1.1.3.2.3" class="ltx_td ltx_align_justify ltx_border_t" style="width:177.8pt;">
<p id="S4.T1.1.3.2.3.1" class="ltx_p ltx_align_top"><span id="S4.T1.1.3.2.3.1.1" class="ltx_text" style="background-color:#FFFCBB;">I left for California in 1979</span> , <span id="S4.T1.1.3.2.3.1.2" class="ltx_text" style="background-color:#FFFCBB;">and tracked Cleveland ’s changes on trips back to visit my sisters .</span></p>
</td>
</tr>
<tr id="S4.T1.1.4.3" class="ltx_tr">
<th id="S4.T1.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t">C4</th>
<td id="S4.T1.1.4.3.2" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t" style="width:169.1pt;">
<p id="S4.T1.1.4.3.2.1" class="ltx_p ltx_align_top"><span id="S4.T1.1.4.3.2.1.1" class="ltx_text" style="background-color:#FFFCBB;">Affordable and convenient holiday flights take off from your departure country,</span> "Canada"<span id="S4.T1.1.4.3.2.1.2" class="ltx_text" style="background-color:#FFFCBB;">. From</span> May <span id="S4.T1.1.4.3.2.1.3" class="ltx_text" style="background-color:#FFFCBB;">2019 to October 2019, Condor flights to your dream destination will be roughly</span> 6 <span id="S4.T1.1.4.3.2.1.4" class="ltx_text" style="background-color:#FFFCBB;">a week! Book your</span> Halifax (YHZ) - Basel (BSL) <span id="S4.T1.1.4.3.2.1.5" class="ltx_text" style="background-color:#FFFCBB;">flight now, and look forward to your</span> "Switzerland" <span id="S4.T1.1.4.3.2.1.6" class="ltx_text" style="background-color:#FFFCBB;">destination!</span></p>
</td>
<td id="S4.T1.1.4.3.3" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" style="width:177.8pt;">
<p id="S4.T1.1.4.3.3.1" class="ltx_p ltx_align_top"><span id="S4.T1.1.4.3.3.1.1" class="ltx_text" style="background-color:#FFFCBB;">Affordable and convenient holiday flights take off from your departure country,</span> "USA"<span id="S4.T1.1.4.3.3.1.2" class="ltx_text" style="background-color:#FFFCBB;">. From</span> April <span id="S4.T1.1.4.3.3.1.3" class="ltx_text" style="background-color:#FFFCBB;">2019 to October 2019, Condor flights to your dream destination will be roughly</span> 7 <span id="S4.T1.1.4.3.3.1.4" class="ltx_text" style="background-color:#FFFCBB;">a week! Book your</span> Maui Kahului (OGG) - Dubrovnik (DBV) <span id="S4.T1.1.4.3.3.1.5" class="ltx_text" style="background-color:#FFFCBB;">flight now, and look forward to your</span> "Croatia" <span id="S4.T1.1.4.3.3.1.6" class="ltx_text" style="background-color:#FFFCBB;">destination!</span></p>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Qualitative examples of near-duplicates identified by <span id="S4.T1.3.1" class="ltx_text ltx_font_smallcaps">NearDup</span> from each dataset. The similarity between documents is highlighted. Note the small interspersed differences that make exact duplicate matching less effective. Examples ending with “[…]” have been truncated for brevity.
More data available in Appendix.</figcaption>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Approximate Matching with MinHash</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">We also perform <em id="S4.SS2.p1.1.1" class="ltx_emph ltx_font_italic">approximate</em> deduplication based on matching entire examples.
This method, which we call <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_smallcaps">NearDup</span>, is a good complement to the <em id="S4.SS2.p1.1.3" class="ltx_emph ltx_font_italic">exact</em> substring matching, especially for web crawl text, as it handles the very common case of documents being identical except for interspersed templated fields (such as the last row of Table <a href="#S4.T1" title="Table 1 ‣ 4.1.2 Substring matching ‣ 4.1 Exact Substring Duplication ‣ 4 Methods for Identifying Duplicates ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.5" class="ltx_p">MinHash <cite class="ltx_cite ltx_citemacro_citep">(Broder, <a href="#bib.bib8" title="" class="ltx_ref">1997</a>)</cite> is an approximate matching algorithm widely used in large-scale deduplication tasks <cite class="ltx_cite ltx_citemacro_citep">(Versley and Panchenko, <a href="#bib.bib41" title="" class="ltx_ref">2012</a>; Gabriel et&nbsp;al., <a href="#bib.bib19" title="" class="ltx_ref">2018</a>; Gyawali et&nbsp;al., <a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite>, including to deduplicate the training set for a large Chinese-language LM <cite class="ltx_cite ltx_citemacro_citep">(Zeng et&nbsp;al., <a href="#bib.bib48" title="" class="ltx_ref">2021</a>)</cite>.
Given two documents <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><msub id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml"><mi id="S4.SS2.p2.1.m1.1.1.2" xref="S4.SS2.p2.1.m1.1.1.2.cmml">x</mi><mi id="S4.SS2.p2.1.m1.1.1.3" xref="S4.SS2.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><apply id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.1.m1.1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p2.1.m1.1.1.2.cmml" xref="S4.SS2.p2.1.m1.1.1.2">𝑥</ci><ci id="S4.SS2.p2.1.m1.1.1.3.cmml" xref="S4.SS2.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math id="S4.SS2.p2.2.m2.1" class="ltx_Math" alttext="x_{j}" display="inline"><semantics id="S4.SS2.p2.2.m2.1a"><msub id="S4.SS2.p2.2.m2.1.1" xref="S4.SS2.p2.2.m2.1.1.cmml"><mi id="S4.SS2.p2.2.m2.1.1.2" xref="S4.SS2.p2.2.m2.1.1.2.cmml">x</mi><mi id="S4.SS2.p2.2.m2.1.1.3" xref="S4.SS2.p2.2.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.2.m2.1b"><apply id="S4.SS2.p2.2.m2.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.2.m2.1.1.1.cmml" xref="S4.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p2.2.m2.1.1.2.cmml" xref="S4.SS2.p2.2.m2.1.1.2">𝑥</ci><ci id="S4.SS2.p2.2.m2.1.1.3.cmml" xref="S4.SS2.p2.2.m2.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.2.m2.1c">x_{j}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math>, the main idea is to represent each document by its respective set of <math id="S4.SS2.p2.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS2.p2.3.m3.1a"><mi id="S4.SS2.p2.3.m3.1.1" xref="S4.SS2.p2.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.3.m3.1b"><ci id="S4.SS2.p2.3.m3.1.1.cmml" xref="S4.SS2.p2.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.3.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.3.m3.1d">italic_n</annotation></semantics></math>-grams <math id="S4.SS2.p2.4.m4.1" class="ltx_Math" alttext="d_{i}" display="inline"><semantics id="S4.SS2.p2.4.m4.1a"><msub id="S4.SS2.p2.4.m4.1.1" xref="S4.SS2.p2.4.m4.1.1.cmml"><mi id="S4.SS2.p2.4.m4.1.1.2" xref="S4.SS2.p2.4.m4.1.1.2.cmml">d</mi><mi id="S4.SS2.p2.4.m4.1.1.3" xref="S4.SS2.p2.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.4.m4.1b"><apply id="S4.SS2.p2.4.m4.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.4.m4.1.1.1.cmml" xref="S4.SS2.p2.4.m4.1.1">subscript</csymbol><ci id="S4.SS2.p2.4.m4.1.1.2.cmml" xref="S4.SS2.p2.4.m4.1.1.2">𝑑</ci><ci id="S4.SS2.p2.4.m4.1.1.3.cmml" xref="S4.SS2.p2.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.4.m4.1c">d_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.4.m4.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math id="S4.SS2.p2.5.m5.1" class="ltx_Math" alttext="d_{j}" display="inline"><semantics id="S4.SS2.p2.5.m5.1a"><msub id="S4.SS2.p2.5.m5.1.1" xref="S4.SS2.p2.5.m5.1.1.cmml"><mi id="S4.SS2.p2.5.m5.1.1.2" xref="S4.SS2.p2.5.m5.1.1.2.cmml">d</mi><mi id="S4.SS2.p2.5.m5.1.1.3" xref="S4.SS2.p2.5.m5.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.5.m5.1b"><apply id="S4.SS2.p2.5.m5.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.5.m5.1.1.1.cmml" xref="S4.SS2.p2.5.m5.1.1">subscript</csymbol><ci id="S4.SS2.p2.5.m5.1.1.2.cmml" xref="S4.SS2.p2.5.m5.1.1.2">𝑑</ci><ci id="S4.SS2.p2.5.m5.1.1.3.cmml" xref="S4.SS2.p2.5.m5.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.5.m5.1c">d_{j}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.5.m5.1d">italic_d start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math>.
We can then use hash functions to approximate the <em id="S4.SS2.p2.5.1" class="ltx_emph ltx_font_italic">Jaccard Index</em> <cite class="ltx_cite ltx_citemacro_citep">(Jaccard, <a href="#bib.bib25" title="" class="ltx_ref">1912</a>)</cite>:</p>
<table id="S4.Ex2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex2.m1.5" class="ltx_Math" alttext="\operatorname{Jaccard}(d_{i},d_{j})=\nicefrac{{|d_{i}\cap d_{j}|}}{{|d_{i}\cup d_{j}|}}" display="block"><semantics id="S4.Ex2.m1.5a"><mrow id="S4.Ex2.m1.5.5" xref="S4.Ex2.m1.5.5.cmml"><mrow id="S4.Ex2.m1.5.5.2.2" xref="S4.Ex2.m1.5.5.2.3.cmml"><mi id="S4.Ex2.m1.3.3" xref="S4.Ex2.m1.3.3.cmml">Jaccard</mi><mo id="S4.Ex2.m1.5.5.2.2a" xref="S4.Ex2.m1.5.5.2.3.cmml">⁡</mo><mrow id="S4.Ex2.m1.5.5.2.2.2" xref="S4.Ex2.m1.5.5.2.3.cmml"><mo stretchy="false" id="S4.Ex2.m1.5.5.2.2.2.3" xref="S4.Ex2.m1.5.5.2.3.cmml">(</mo><msub id="S4.Ex2.m1.4.4.1.1.1.1" xref="S4.Ex2.m1.4.4.1.1.1.1.cmml"><mi id="S4.Ex2.m1.4.4.1.1.1.1.2" xref="S4.Ex2.m1.4.4.1.1.1.1.2.cmml">d</mi><mi id="S4.Ex2.m1.4.4.1.1.1.1.3" xref="S4.Ex2.m1.4.4.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.Ex2.m1.5.5.2.2.2.4" xref="S4.Ex2.m1.5.5.2.3.cmml">,</mo><msub id="S4.Ex2.m1.5.5.2.2.2.2" xref="S4.Ex2.m1.5.5.2.2.2.2.cmml"><mi id="S4.Ex2.m1.5.5.2.2.2.2.2" xref="S4.Ex2.m1.5.5.2.2.2.2.2.cmml">d</mi><mi id="S4.Ex2.m1.5.5.2.2.2.2.3" xref="S4.Ex2.m1.5.5.2.2.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S4.Ex2.m1.5.5.2.2.2.5" xref="S4.Ex2.m1.5.5.2.3.cmml">)</mo></mrow></mrow><mo id="S4.Ex2.m1.5.5.3" xref="S4.Ex2.m1.5.5.3.cmml">=</mo><mrow id="S4.Ex2.m1.2.2" xref="S4.Ex2.m1.2.2.cmml"><mpadded voffset="0.3em" id="S4.Ex2.m1.1.1.1.1" xref="S4.Ex2.m1.1.1.1.2.cmml"><mo stretchy="false" id="S4.Ex2.m1.1.1.1.1.2" xref="S4.Ex2.m1.1.1.1.2.1.cmml">|</mo><mrow id="S4.Ex2.m1.1.1.1.1.1" xref="S4.Ex2.m1.1.1.1.1.1.cmml"><msub id="S4.Ex2.m1.1.1.1.1.1.2" xref="S4.Ex2.m1.1.1.1.1.1.2.cmml"><mi id="S4.Ex2.m1.1.1.1.1.1.2.2" xref="S4.Ex2.m1.1.1.1.1.1.2.2.cmml">d</mi><mi id="S4.Ex2.m1.1.1.1.1.1.2.3" xref="S4.Ex2.m1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S4.Ex2.m1.1.1.1.1.1.1" xref="S4.Ex2.m1.1.1.1.1.1.1.cmml">∩</mo><msub id="S4.Ex2.m1.1.1.1.1.1.3" xref="S4.Ex2.m1.1.1.1.1.1.3.cmml"><mi id="S4.Ex2.m1.1.1.1.1.1.3.2" xref="S4.Ex2.m1.1.1.1.1.1.3.2.cmml">d</mi><mi id="S4.Ex2.m1.1.1.1.1.1.3.3" xref="S4.Ex2.m1.1.1.1.1.1.3.3.cmml">j</mi></msub></mrow><mo stretchy="false" id="S4.Ex2.m1.1.1.1.1.3" xref="S4.Ex2.m1.1.1.1.2.1.cmml">|</mo></mpadded><mpadded lspace="-0.1em" width="-0.15em" id="S4.Ex2.m1.2.2.3" xref="S4.Ex2.m1.2.2.3.cmml"><mo stretchy="true" symmetric="true" id="S4.Ex2.m1.2.2.3a" xref="S4.Ex2.m1.2.2.3.cmml">/</mo></mpadded><mrow id="S4.Ex2.m1.2.2.2.1" xref="S4.Ex2.m1.2.2.2.2.cmml"><mo lspace="0.222em" stretchy="false" id="S4.Ex2.m1.2.2.2.1.2" xref="S4.Ex2.m1.2.2.2.2.1.cmml">|</mo><mrow id="S4.Ex2.m1.2.2.2.1.1" xref="S4.Ex2.m1.2.2.2.1.1.cmml"><msub id="S4.Ex2.m1.2.2.2.1.1.2" xref="S4.Ex2.m1.2.2.2.1.1.2.cmml"><mi id="S4.Ex2.m1.2.2.2.1.1.2.2" xref="S4.Ex2.m1.2.2.2.1.1.2.2.cmml">d</mi><mi id="S4.Ex2.m1.2.2.2.1.1.2.3" xref="S4.Ex2.m1.2.2.2.1.1.2.3.cmml">i</mi></msub><mo id="S4.Ex2.m1.2.2.2.1.1.1" xref="S4.Ex2.m1.2.2.2.1.1.1.cmml">∪</mo><msub id="S4.Ex2.m1.2.2.2.1.1.3" xref="S4.Ex2.m1.2.2.2.1.1.3.cmml"><mi id="S4.Ex2.m1.2.2.2.1.1.3.2" xref="S4.Ex2.m1.2.2.2.1.1.3.2.cmml">d</mi><mi id="S4.Ex2.m1.2.2.2.1.1.3.3" xref="S4.Ex2.m1.2.2.2.1.1.3.3.cmml">j</mi></msub></mrow><mo stretchy="false" id="S4.Ex2.m1.2.2.2.1.3" xref="S4.Ex2.m1.2.2.2.2.1.cmml">|</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex2.m1.5b"><apply id="S4.Ex2.m1.5.5.cmml" xref="S4.Ex2.m1.5.5"><eq id="S4.Ex2.m1.5.5.3.cmml" xref="S4.Ex2.m1.5.5.3"></eq><apply id="S4.Ex2.m1.5.5.2.3.cmml" xref="S4.Ex2.m1.5.5.2.2"><ci id="S4.Ex2.m1.3.3.cmml" xref="S4.Ex2.m1.3.3">Jaccard</ci><apply id="S4.Ex2.m1.4.4.1.1.1.1.cmml" xref="S4.Ex2.m1.4.4.1.1.1.1"><csymbol cd="ambiguous" id="S4.Ex2.m1.4.4.1.1.1.1.1.cmml" xref="S4.Ex2.m1.4.4.1.1.1.1">subscript</csymbol><ci id="S4.Ex2.m1.4.4.1.1.1.1.2.cmml" xref="S4.Ex2.m1.4.4.1.1.1.1.2">𝑑</ci><ci id="S4.Ex2.m1.4.4.1.1.1.1.3.cmml" xref="S4.Ex2.m1.4.4.1.1.1.1.3">𝑖</ci></apply><apply id="S4.Ex2.m1.5.5.2.2.2.2.cmml" xref="S4.Ex2.m1.5.5.2.2.2.2"><csymbol cd="ambiguous" id="S4.Ex2.m1.5.5.2.2.2.2.1.cmml" xref="S4.Ex2.m1.5.5.2.2.2.2">subscript</csymbol><ci id="S4.Ex2.m1.5.5.2.2.2.2.2.cmml" xref="S4.Ex2.m1.5.5.2.2.2.2.2">𝑑</ci><ci id="S4.Ex2.m1.5.5.2.2.2.2.3.cmml" xref="S4.Ex2.m1.5.5.2.2.2.2.3">𝑗</ci></apply></apply><apply id="S4.Ex2.m1.2.2.cmml" xref="S4.Ex2.m1.2.2"><divide id="S4.Ex2.m1.2.2.3.cmml" xref="S4.Ex2.m1.2.2.3"></divide><apply id="S4.Ex2.m1.1.1.1.2.cmml" xref="S4.Ex2.m1.1.1.1.1"><abs id="S4.Ex2.m1.1.1.1.2.1.cmml" xref="S4.Ex2.m1.1.1.1.1.2"></abs><apply id="S4.Ex2.m1.1.1.1.1.1.cmml" xref="S4.Ex2.m1.1.1.1.1.1"><intersect id="S4.Ex2.m1.1.1.1.1.1.1.cmml" xref="S4.Ex2.m1.1.1.1.1.1.1"></intersect><apply id="S4.Ex2.m1.1.1.1.1.1.2.cmml" xref="S4.Ex2.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S4.Ex2.m1.1.1.1.1.1.2.1.cmml" xref="S4.Ex2.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S4.Ex2.m1.1.1.1.1.1.2.2.cmml" xref="S4.Ex2.m1.1.1.1.1.1.2.2">𝑑</ci><ci id="S4.Ex2.m1.1.1.1.1.1.2.3.cmml" xref="S4.Ex2.m1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S4.Ex2.m1.1.1.1.1.1.3.cmml" xref="S4.Ex2.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex2.m1.1.1.1.1.1.3.1.cmml" xref="S4.Ex2.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S4.Ex2.m1.1.1.1.1.1.3.2.cmml" xref="S4.Ex2.m1.1.1.1.1.1.3.2">𝑑</ci><ci id="S4.Ex2.m1.1.1.1.1.1.3.3.cmml" xref="S4.Ex2.m1.1.1.1.1.1.3.3">𝑗</ci></apply></apply></apply><apply id="S4.Ex2.m1.2.2.2.2.cmml" xref="S4.Ex2.m1.2.2.2.1"><abs id="S4.Ex2.m1.2.2.2.2.1.cmml" xref="S4.Ex2.m1.2.2.2.1.2"></abs><apply id="S4.Ex2.m1.2.2.2.1.1.cmml" xref="S4.Ex2.m1.2.2.2.1.1"><union id="S4.Ex2.m1.2.2.2.1.1.1.cmml" xref="S4.Ex2.m1.2.2.2.1.1.1"></union><apply id="S4.Ex2.m1.2.2.2.1.1.2.cmml" xref="S4.Ex2.m1.2.2.2.1.1.2"><csymbol cd="ambiguous" id="S4.Ex2.m1.2.2.2.1.1.2.1.cmml" xref="S4.Ex2.m1.2.2.2.1.1.2">subscript</csymbol><ci id="S4.Ex2.m1.2.2.2.1.1.2.2.cmml" xref="S4.Ex2.m1.2.2.2.1.1.2.2">𝑑</ci><ci id="S4.Ex2.m1.2.2.2.1.1.2.3.cmml" xref="S4.Ex2.m1.2.2.2.1.1.2.3">𝑖</ci></apply><apply id="S4.Ex2.m1.2.2.2.1.1.3.cmml" xref="S4.Ex2.m1.2.2.2.1.1.3"><csymbol cd="ambiguous" id="S4.Ex2.m1.2.2.2.1.1.3.1.cmml" xref="S4.Ex2.m1.2.2.2.1.1.3">subscript</csymbol><ci id="S4.Ex2.m1.2.2.2.1.1.3.2.cmml" xref="S4.Ex2.m1.2.2.2.1.1.3.2">𝑑</ci><ci id="S4.Ex2.m1.2.2.2.1.1.3.3.cmml" xref="S4.Ex2.m1.2.2.2.1.1.3.3">𝑗</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex2.m1.5c">\operatorname{Jaccard}(d_{i},d_{j})=\nicefrac{{|d_{i}\cap d_{j}|}}{{|d_{i}\cup d_{j}|}}</annotation><annotation encoding="application/x-llamapun" id="S4.Ex2.m1.5d">roman_Jaccard ( italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) = / start_ARG | italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∩ italic_d start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | end_ARG start_ARG | italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∪ italic_d start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS2.p2.10" class="ltx_p">If the Jaccard Index between <math id="S4.SS2.p2.6.m1.1" class="ltx_Math" alttext="d_{i}" display="inline"><semantics id="S4.SS2.p2.6.m1.1a"><msub id="S4.SS2.p2.6.m1.1.1" xref="S4.SS2.p2.6.m1.1.1.cmml"><mi id="S4.SS2.p2.6.m1.1.1.2" xref="S4.SS2.p2.6.m1.1.1.2.cmml">d</mi><mi id="S4.SS2.p2.6.m1.1.1.3" xref="S4.SS2.p2.6.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.6.m1.1b"><apply id="S4.SS2.p2.6.m1.1.1.cmml" xref="S4.SS2.p2.6.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.6.m1.1.1.1.cmml" xref="S4.SS2.p2.6.m1.1.1">subscript</csymbol><ci id="S4.SS2.p2.6.m1.1.1.2.cmml" xref="S4.SS2.p2.6.m1.1.1.2">𝑑</ci><ci id="S4.SS2.p2.6.m1.1.1.3.cmml" xref="S4.SS2.p2.6.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.6.m1.1c">d_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.6.m1.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math id="S4.SS2.p2.7.m2.1" class="ltx_Math" alttext="d_{j}" display="inline"><semantics id="S4.SS2.p2.7.m2.1a"><msub id="S4.SS2.p2.7.m2.1.1" xref="S4.SS2.p2.7.m2.1.1.cmml"><mi id="S4.SS2.p2.7.m2.1.1.2" xref="S4.SS2.p2.7.m2.1.1.2.cmml">d</mi><mi id="S4.SS2.p2.7.m2.1.1.3" xref="S4.SS2.p2.7.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.7.m2.1b"><apply id="S4.SS2.p2.7.m2.1.1.cmml" xref="S4.SS2.p2.7.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p2.7.m2.1.1.1.cmml" xref="S4.SS2.p2.7.m2.1.1">subscript</csymbol><ci id="S4.SS2.p2.7.m2.1.1.2.cmml" xref="S4.SS2.p2.7.m2.1.1.2">𝑑</ci><ci id="S4.SS2.p2.7.m2.1.1.3.cmml" xref="S4.SS2.p2.7.m2.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.7.m2.1c">d_{j}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.7.m2.1d">italic_d start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> is sufficiently high, it is likely that documents are approximate matches of each other.
To efficiently approximate the Jaccard index, MinHash constructs document signatures by sorting each of the <math id="S4.SS2.p2.8.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS2.p2.8.m3.1a"><mi id="S4.SS2.p2.8.m3.1.1" xref="S4.SS2.p2.8.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.8.m3.1b"><ci id="S4.SS2.p2.8.m3.1.1.cmml" xref="S4.SS2.p2.8.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.8.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.8.m3.1d">italic_n</annotation></semantics></math>-grams via a hash function, and then keeping only the <math id="S4.SS2.p2.9.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS2.p2.9.m4.1a"><mi id="S4.SS2.p2.9.m4.1.1" xref="S4.SS2.p2.9.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.9.m4.1b"><ci id="S4.SS2.p2.9.m4.1.1.cmml" xref="S4.SS2.p2.9.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.9.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.9.m4.1d">italic_k</annotation></semantics></math> smallest hashed <math id="S4.SS2.p2.10.m5.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S4.SS2.p2.10.m5.1a"><mi id="S4.SS2.p2.10.m5.1.1" xref="S4.SS2.p2.10.m5.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.10.m5.1b"><ci id="S4.SS2.p2.10.m5.1.1.cmml" xref="S4.SS2.p2.10.m5.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.10.m5.1c">n</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.10.m5.1d">italic_n</annotation></semantics></math>-grams.
There are multiple ways to construct estimators of the Jaccard index from these kinds of signatures <cite class="ltx_cite ltx_citemacro_citep">(Cohen, <a href="#bib.bib14" title="" class="ltx_ref">2016</a>)</cite>.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.3" class="ltx_p">In our implementation, we use 5-grams and a signature of size 9,000. The probability that two documents are considered a potential match is</p>
<table id="S4.Ex3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex3.m1.9" class="ltx_Math" alttext="\operatorname{Pr}(d_{i},d_{j}|\operatorname{Jaccard}(d_{i},d_{j})=s_{i,j})=1-(1-s_{i,j}^{b})^{r}" display="block"><semantics id="S4.Ex3.m1.9a"><mrow id="S4.Ex3.m1.9.9" xref="S4.Ex3.m1.9.9.cmml"><mrow id="S4.Ex3.m1.8.8.2.2" xref="S4.Ex3.m1.8.8.2.3.cmml"><mi id="S4.Ex3.m1.6.6" xref="S4.Ex3.m1.6.6.cmml">Pr</mi><mo id="S4.Ex3.m1.8.8.2.2a" xref="S4.Ex3.m1.8.8.2.3.cmml">⁡</mo><mrow id="S4.Ex3.m1.8.8.2.2.2" xref="S4.Ex3.m1.8.8.2.3.cmml"><mo stretchy="false" id="S4.Ex3.m1.8.8.2.2.2.3" xref="S4.Ex3.m1.8.8.2.3.cmml">(</mo><msub id="S4.Ex3.m1.7.7.1.1.1.1" xref="S4.Ex3.m1.7.7.1.1.1.1.cmml"><mi id="S4.Ex3.m1.7.7.1.1.1.1.2" xref="S4.Ex3.m1.7.7.1.1.1.1.2.cmml">d</mi><mi id="S4.Ex3.m1.7.7.1.1.1.1.3" xref="S4.Ex3.m1.7.7.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.Ex3.m1.8.8.2.2.2.4" xref="S4.Ex3.m1.8.8.2.3.cmml">,</mo><mrow id="S4.Ex3.m1.8.8.2.2.2.2" xref="S4.Ex3.m1.8.8.2.2.2.2.cmml"><mrow id="S4.Ex3.m1.8.8.2.2.2.2.2" xref="S4.Ex3.m1.8.8.2.2.2.2.2.cmml"><msub id="S4.Ex3.m1.8.8.2.2.2.2.2.4" xref="S4.Ex3.m1.8.8.2.2.2.2.2.4.cmml"><mi id="S4.Ex3.m1.8.8.2.2.2.2.2.4.2" xref="S4.Ex3.m1.8.8.2.2.2.2.2.4.2.cmml">d</mi><mi id="S4.Ex3.m1.8.8.2.2.2.2.2.4.3" xref="S4.Ex3.m1.8.8.2.2.2.2.2.4.3.cmml">j</mi></msub><mo fence="false" id="S4.Ex3.m1.8.8.2.2.2.2.2.3" xref="S4.Ex3.m1.8.8.2.2.2.2.2.3.cmml">|</mo><mrow id="S4.Ex3.m1.8.8.2.2.2.2.2.2.2" xref="S4.Ex3.m1.8.8.2.2.2.2.2.2.3.cmml"><mi id="S4.Ex3.m1.5.5" xref="S4.Ex3.m1.5.5.cmml">Jaccard</mi><mo id="S4.Ex3.m1.8.8.2.2.2.2.2.2.2a" xref="S4.Ex3.m1.8.8.2.2.2.2.2.2.3.cmml">⁡</mo><mrow id="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2" xref="S4.Ex3.m1.8.8.2.2.2.2.2.2.3.cmml"><mo stretchy="false" id="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.3" xref="S4.Ex3.m1.8.8.2.2.2.2.2.2.3.cmml">(</mo><msub id="S4.Ex3.m1.8.8.2.2.2.2.1.1.1.1.1" xref="S4.Ex3.m1.8.8.2.2.2.2.1.1.1.1.1.cmml"><mi id="S4.Ex3.m1.8.8.2.2.2.2.1.1.1.1.1.2" xref="S4.Ex3.m1.8.8.2.2.2.2.1.1.1.1.1.2.cmml">d</mi><mi id="S4.Ex3.m1.8.8.2.2.2.2.1.1.1.1.1.3" xref="S4.Ex3.m1.8.8.2.2.2.2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.4" xref="S4.Ex3.m1.8.8.2.2.2.2.2.2.3.cmml">,</mo><msub id="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.2" xref="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.2.cmml"><mi id="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.2.2" xref="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.2.2.cmml">d</mi><mi id="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.2.3" xref="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.5" xref="S4.Ex3.m1.8.8.2.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S4.Ex3.m1.8.8.2.2.2.2.3" xref="S4.Ex3.m1.8.8.2.2.2.2.3.cmml">=</mo><msub id="S4.Ex3.m1.8.8.2.2.2.2.4" xref="S4.Ex3.m1.8.8.2.2.2.2.4.cmml"><mi id="S4.Ex3.m1.8.8.2.2.2.2.4.2" xref="S4.Ex3.m1.8.8.2.2.2.2.4.2.cmml">s</mi><mrow id="S4.Ex3.m1.2.2.2.4" xref="S4.Ex3.m1.2.2.2.3.cmml"><mi id="S4.Ex3.m1.1.1.1.1" xref="S4.Ex3.m1.1.1.1.1.cmml">i</mi><mo id="S4.Ex3.m1.2.2.2.4.1" xref="S4.Ex3.m1.2.2.2.3.cmml">,</mo><mi id="S4.Ex3.m1.2.2.2.2" xref="S4.Ex3.m1.2.2.2.2.cmml">j</mi></mrow></msub></mrow><mo stretchy="false" id="S4.Ex3.m1.8.8.2.2.2.5" xref="S4.Ex3.m1.8.8.2.3.cmml">)</mo></mrow></mrow><mo id="S4.Ex3.m1.9.9.4" xref="S4.Ex3.m1.9.9.4.cmml">=</mo><mrow id="S4.Ex3.m1.9.9.3" xref="S4.Ex3.m1.9.9.3.cmml"><mn id="S4.Ex3.m1.9.9.3.3" xref="S4.Ex3.m1.9.9.3.3.cmml">1</mn><mo id="S4.Ex3.m1.9.9.3.2" xref="S4.Ex3.m1.9.9.3.2.cmml">−</mo><msup id="S4.Ex3.m1.9.9.3.1" xref="S4.Ex3.m1.9.9.3.1.cmml"><mrow id="S4.Ex3.m1.9.9.3.1.1.1" xref="S4.Ex3.m1.9.9.3.1.1.1.1.cmml"><mo stretchy="false" id="S4.Ex3.m1.9.9.3.1.1.1.2" xref="S4.Ex3.m1.9.9.3.1.1.1.1.cmml">(</mo><mrow id="S4.Ex3.m1.9.9.3.1.1.1.1" xref="S4.Ex3.m1.9.9.3.1.1.1.1.cmml"><mn id="S4.Ex3.m1.9.9.3.1.1.1.1.2" xref="S4.Ex3.m1.9.9.3.1.1.1.1.2.cmml">1</mn><mo id="S4.Ex3.m1.9.9.3.1.1.1.1.1" xref="S4.Ex3.m1.9.9.3.1.1.1.1.1.cmml">−</mo><msubsup id="S4.Ex3.m1.9.9.3.1.1.1.1.3" xref="S4.Ex3.m1.9.9.3.1.1.1.1.3.cmml"><mi id="S4.Ex3.m1.9.9.3.1.1.1.1.3.2.2" xref="S4.Ex3.m1.9.9.3.1.1.1.1.3.2.2.cmml">s</mi><mrow id="S4.Ex3.m1.4.4.2.4" xref="S4.Ex3.m1.4.4.2.3.cmml"><mi id="S4.Ex3.m1.3.3.1.1" xref="S4.Ex3.m1.3.3.1.1.cmml">i</mi><mo id="S4.Ex3.m1.4.4.2.4.1" xref="S4.Ex3.m1.4.4.2.3.cmml">,</mo><mi id="S4.Ex3.m1.4.4.2.2" xref="S4.Ex3.m1.4.4.2.2.cmml">j</mi></mrow><mi id="S4.Ex3.m1.9.9.3.1.1.1.1.3.3" xref="S4.Ex3.m1.9.9.3.1.1.1.1.3.3.cmml">b</mi></msubsup></mrow><mo stretchy="false" id="S4.Ex3.m1.9.9.3.1.1.1.3" xref="S4.Ex3.m1.9.9.3.1.1.1.1.cmml">)</mo></mrow><mi id="S4.Ex3.m1.9.9.3.1.3" xref="S4.Ex3.m1.9.9.3.1.3.cmml">r</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex3.m1.9b"><apply id="S4.Ex3.m1.9.9.cmml" xref="S4.Ex3.m1.9.9"><eq id="S4.Ex3.m1.9.9.4.cmml" xref="S4.Ex3.m1.9.9.4"></eq><apply id="S4.Ex3.m1.8.8.2.3.cmml" xref="S4.Ex3.m1.8.8.2.2"><ci id="S4.Ex3.m1.6.6.cmml" xref="S4.Ex3.m1.6.6">Pr</ci><apply id="S4.Ex3.m1.7.7.1.1.1.1.cmml" xref="S4.Ex3.m1.7.7.1.1.1.1"><csymbol cd="ambiguous" id="S4.Ex3.m1.7.7.1.1.1.1.1.cmml" xref="S4.Ex3.m1.7.7.1.1.1.1">subscript</csymbol><ci id="S4.Ex3.m1.7.7.1.1.1.1.2.cmml" xref="S4.Ex3.m1.7.7.1.1.1.1.2">𝑑</ci><ci id="S4.Ex3.m1.7.7.1.1.1.1.3.cmml" xref="S4.Ex3.m1.7.7.1.1.1.1.3">𝑖</ci></apply><apply id="S4.Ex3.m1.8.8.2.2.2.2.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2"><eq id="S4.Ex3.m1.8.8.2.2.2.2.3.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.3"></eq><apply id="S4.Ex3.m1.8.8.2.2.2.2.2.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.2"><csymbol cd="latexml" id="S4.Ex3.m1.8.8.2.2.2.2.2.3.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.2.3">conditional</csymbol><apply id="S4.Ex3.m1.8.8.2.2.2.2.2.4.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.2.4"><csymbol cd="ambiguous" id="S4.Ex3.m1.8.8.2.2.2.2.2.4.1.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.2.4">subscript</csymbol><ci id="S4.Ex3.m1.8.8.2.2.2.2.2.4.2.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.2.4.2">𝑑</ci><ci id="S4.Ex3.m1.8.8.2.2.2.2.2.4.3.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.2.4.3">𝑗</ci></apply><apply id="S4.Ex3.m1.8.8.2.2.2.2.2.2.3.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.2.2.2"><ci id="S4.Ex3.m1.5.5.cmml" xref="S4.Ex3.m1.5.5">Jaccard</ci><apply id="S4.Ex3.m1.8.8.2.2.2.2.1.1.1.1.1.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.Ex3.m1.8.8.2.2.2.2.1.1.1.1.1.1.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.1.1.1.1.1">subscript</csymbol><ci id="S4.Ex3.m1.8.8.2.2.2.2.1.1.1.1.1.2.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.1.1.1.1.1.2">𝑑</ci><ci id="S4.Ex3.m1.8.8.2.2.2.2.1.1.1.1.1.3.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.1.1.1.1.1.3">𝑖</ci></apply><apply id="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.2.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.2.1.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.2.2.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.2.2">𝑑</ci><ci id="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.2.3.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.2.2.2.2.2.3">𝑗</ci></apply></apply></apply><apply id="S4.Ex3.m1.8.8.2.2.2.2.4.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.4"><csymbol cd="ambiguous" id="S4.Ex3.m1.8.8.2.2.2.2.4.1.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.4">subscript</csymbol><ci id="S4.Ex3.m1.8.8.2.2.2.2.4.2.cmml" xref="S4.Ex3.m1.8.8.2.2.2.2.4.2">𝑠</ci><list id="S4.Ex3.m1.2.2.2.3.cmml" xref="S4.Ex3.m1.2.2.2.4"><ci id="S4.Ex3.m1.1.1.1.1.cmml" xref="S4.Ex3.m1.1.1.1.1">𝑖</ci><ci id="S4.Ex3.m1.2.2.2.2.cmml" xref="S4.Ex3.m1.2.2.2.2">𝑗</ci></list></apply></apply></apply><apply id="S4.Ex3.m1.9.9.3.cmml" xref="S4.Ex3.m1.9.9.3"><minus id="S4.Ex3.m1.9.9.3.2.cmml" xref="S4.Ex3.m1.9.9.3.2"></minus><cn type="integer" id="S4.Ex3.m1.9.9.3.3.cmml" xref="S4.Ex3.m1.9.9.3.3">1</cn><apply id="S4.Ex3.m1.9.9.3.1.cmml" xref="S4.Ex3.m1.9.9.3.1"><csymbol cd="ambiguous" id="S4.Ex3.m1.9.9.3.1.2.cmml" xref="S4.Ex3.m1.9.9.3.1">superscript</csymbol><apply id="S4.Ex3.m1.9.9.3.1.1.1.1.cmml" xref="S4.Ex3.m1.9.9.3.1.1.1"><minus id="S4.Ex3.m1.9.9.3.1.1.1.1.1.cmml" xref="S4.Ex3.m1.9.9.3.1.1.1.1.1"></minus><cn type="integer" id="S4.Ex3.m1.9.9.3.1.1.1.1.2.cmml" xref="S4.Ex3.m1.9.9.3.1.1.1.1.2">1</cn><apply id="S4.Ex3.m1.9.9.3.1.1.1.1.3.cmml" xref="S4.Ex3.m1.9.9.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex3.m1.9.9.3.1.1.1.1.3.1.cmml" xref="S4.Ex3.m1.9.9.3.1.1.1.1.3">superscript</csymbol><apply id="S4.Ex3.m1.9.9.3.1.1.1.1.3.2.cmml" xref="S4.Ex3.m1.9.9.3.1.1.1.1.3"><csymbol cd="ambiguous" id="S4.Ex3.m1.9.9.3.1.1.1.1.3.2.1.cmml" xref="S4.Ex3.m1.9.9.3.1.1.1.1.3">subscript</csymbol><ci id="S4.Ex3.m1.9.9.3.1.1.1.1.3.2.2.cmml" xref="S4.Ex3.m1.9.9.3.1.1.1.1.3.2.2">𝑠</ci><list id="S4.Ex3.m1.4.4.2.3.cmml" xref="S4.Ex3.m1.4.4.2.4"><ci id="S4.Ex3.m1.3.3.1.1.cmml" xref="S4.Ex3.m1.3.3.1.1">𝑖</ci><ci id="S4.Ex3.m1.4.4.2.2.cmml" xref="S4.Ex3.m1.4.4.2.2">𝑗</ci></list></apply><ci id="S4.Ex3.m1.9.9.3.1.1.1.1.3.3.cmml" xref="S4.Ex3.m1.9.9.3.1.1.1.1.3.3">𝑏</ci></apply></apply><ci id="S4.Ex3.m1.9.9.3.1.3.cmml" xref="S4.Ex3.m1.9.9.3.1.3">𝑟</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex3.m1.9c">\operatorname{Pr}(d_{i},d_{j}|\operatorname{Jaccard}(d_{i},d_{j})=s_{i,j})=1-(1-s_{i,j}^{b})^{r}</annotation><annotation encoding="application/x-llamapun" id="S4.Ex3.m1.9d">roman_Pr ( italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | roman_Jaccard ( italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) = italic_s start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) = 1 - ( 1 - italic_s start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS2.p3.2" class="ltx_p">where <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="b=20" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mrow id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml"><mi id="S4.SS2.p3.1.m1.1.1.2" xref="S4.SS2.p3.1.m1.1.1.2.cmml">b</mi><mo id="S4.SS2.p3.1.m1.1.1.1" xref="S4.SS2.p3.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS2.p3.1.m1.1.1.3" xref="S4.SS2.p3.1.m1.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><apply id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1"><eq id="S4.SS2.p3.1.m1.1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1.1"></eq><ci id="S4.SS2.p3.1.m1.1.1.2.cmml" xref="S4.SS2.p3.1.m1.1.1.2">𝑏</ci><cn type="integer" id="S4.SS2.p3.1.m1.1.1.3.cmml" xref="S4.SS2.p3.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">b=20</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.1.m1.1d">italic_b = 20</annotation></semantics></math> and <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="r=450" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mrow id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mi id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml">r</mi><mo id="S4.SS2.p3.2.m2.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.cmml">=</mo><mn id="S4.SS2.p3.2.m2.1.1.3" xref="S4.SS2.p3.2.m2.1.1.3.cmml">450</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><eq id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1"></eq><ci id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">𝑟</ci><cn type="integer" id="S4.SS2.p3.2.m2.1.1.3.cmml" xref="S4.SS2.p3.2.m2.1.1.3">450</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">r=450</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p3.2.m2.1d">italic_r = 450</annotation></semantics></math> are user-settable parameters to control the strength of the filter.
See Appendix&nbsp;<a href="#A1" title="Appendix A Further Details on NearDup ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a> for more details.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.2" class="ltx_p">For each pair of documents identified as a potential match, more computationally expensive similarity metrics can be employed as a subsequent filtering step.
In particular, we identify two documents as duplicates if they are matched by the MinHash algorithm and their <em id="S4.SS2.p4.2.1" class="ltx_emph ltx_font_italic">edit similarity</em> is greater than 0.8. The edit similarity between token sequences <math id="S4.SS2.p4.1.m1.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S4.SS2.p4.1.m1.1a"><msub id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml"><mi id="S4.SS2.p4.1.m1.1.1.2" xref="S4.SS2.p4.1.m1.1.1.2.cmml">x</mi><mi id="S4.SS2.p4.1.m1.1.1.3" xref="S4.SS2.p4.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.1b"><apply id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.1.m1.1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">subscript</csymbol><ci id="S4.SS2.p4.1.m1.1.1.2.cmml" xref="S4.SS2.p4.1.m1.1.1.2">𝑥</ci><ci id="S4.SS2.p4.1.m1.1.1.3.cmml" xref="S4.SS2.p4.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and <math id="S4.SS2.p4.2.m2.1" class="ltx_Math" alttext="x_{j}" display="inline"><semantics id="S4.SS2.p4.2.m2.1a"><msub id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml"><mi id="S4.SS2.p4.2.m2.1.1.2" xref="S4.SS2.p4.2.m2.1.1.2.cmml">x</mi><mi id="S4.SS2.p4.2.m2.1.1.3" xref="S4.SS2.p4.2.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.1b"><apply id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS2.p4.2.m2.1.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1">subscript</csymbol><ci id="S4.SS2.p4.2.m2.1.1.2.cmml" xref="S4.SS2.p4.2.m2.1.1.2">𝑥</ci><ci id="S4.SS2.p4.2.m2.1.1.3.cmml" xref="S4.SS2.p4.2.m2.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.1c">x_{j}</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p4.2.m2.1d">italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> is defined as:</p>
<table id="S4.Ex4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex4.m1.9" class="ltx_Math" alttext="\operatorname{EditSim}(x_{i},x_{j})=1-\frac{\operatorname{EditDistance}(x_{i},x_{j})}{\max(|x_{i}|,|x_{j}|)}" display="block"><semantics id="S4.Ex4.m1.9a"><mrow id="S4.Ex4.m1.9.9" xref="S4.Ex4.m1.9.9.cmml"><mrow id="S4.Ex4.m1.9.9.2.2" xref="S4.Ex4.m1.9.9.2.3.cmml"><mi id="S4.Ex4.m1.7.7" xref="S4.Ex4.m1.7.7.cmml">EditSim</mi><mo id="S4.Ex4.m1.9.9.2.2a" xref="S4.Ex4.m1.9.9.2.3.cmml">⁡</mo><mrow id="S4.Ex4.m1.9.9.2.2.2" xref="S4.Ex4.m1.9.9.2.3.cmml"><mo stretchy="false" id="S4.Ex4.m1.9.9.2.2.2.3" xref="S4.Ex4.m1.9.9.2.3.cmml">(</mo><msub id="S4.Ex4.m1.8.8.1.1.1.1" xref="S4.Ex4.m1.8.8.1.1.1.1.cmml"><mi id="S4.Ex4.m1.8.8.1.1.1.1.2" xref="S4.Ex4.m1.8.8.1.1.1.1.2.cmml">x</mi><mi id="S4.Ex4.m1.8.8.1.1.1.1.3" xref="S4.Ex4.m1.8.8.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.Ex4.m1.9.9.2.2.2.4" xref="S4.Ex4.m1.9.9.2.3.cmml">,</mo><msub id="S4.Ex4.m1.9.9.2.2.2.2" xref="S4.Ex4.m1.9.9.2.2.2.2.cmml"><mi id="S4.Ex4.m1.9.9.2.2.2.2.2" xref="S4.Ex4.m1.9.9.2.2.2.2.2.cmml">x</mi><mi id="S4.Ex4.m1.9.9.2.2.2.2.3" xref="S4.Ex4.m1.9.9.2.2.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S4.Ex4.m1.9.9.2.2.2.5" xref="S4.Ex4.m1.9.9.2.3.cmml">)</mo></mrow></mrow><mo id="S4.Ex4.m1.9.9.3" xref="S4.Ex4.m1.9.9.3.cmml">=</mo><mrow id="S4.Ex4.m1.9.9.4" xref="S4.Ex4.m1.9.9.4.cmml"><mn id="S4.Ex4.m1.9.9.4.2" xref="S4.Ex4.m1.9.9.4.2.cmml">1</mn><mo id="S4.Ex4.m1.9.9.4.1" xref="S4.Ex4.m1.9.9.4.1.cmml">−</mo><mfrac id="S4.Ex4.m1.6.6" xref="S4.Ex4.m1.6.6.cmml"><mrow id="S4.Ex4.m1.3.3.3.3" xref="S4.Ex4.m1.3.3.3.4.cmml"><mi id="S4.Ex4.m1.1.1.1.1" xref="S4.Ex4.m1.1.1.1.1.cmml">EditDistance</mi><mo id="S4.Ex4.m1.3.3.3.3a" xref="S4.Ex4.m1.3.3.3.4.cmml">⁡</mo><mrow id="S4.Ex4.m1.3.3.3.3.2" xref="S4.Ex4.m1.3.3.3.4.cmml"><mo stretchy="false" id="S4.Ex4.m1.3.3.3.3.2.3" xref="S4.Ex4.m1.3.3.3.4.cmml">(</mo><msub id="S4.Ex4.m1.2.2.2.2.1.1" xref="S4.Ex4.m1.2.2.2.2.1.1.cmml"><mi id="S4.Ex4.m1.2.2.2.2.1.1.2" xref="S4.Ex4.m1.2.2.2.2.1.1.2.cmml">x</mi><mi id="S4.Ex4.m1.2.2.2.2.1.1.3" xref="S4.Ex4.m1.2.2.2.2.1.1.3.cmml">i</mi></msub><mo id="S4.Ex4.m1.3.3.3.3.2.4" xref="S4.Ex4.m1.3.3.3.4.cmml">,</mo><msub id="S4.Ex4.m1.3.3.3.3.2.2" xref="S4.Ex4.m1.3.3.3.3.2.2.cmml"><mi id="S4.Ex4.m1.3.3.3.3.2.2.2" xref="S4.Ex4.m1.3.3.3.3.2.2.2.cmml">x</mi><mi id="S4.Ex4.m1.3.3.3.3.2.2.3" xref="S4.Ex4.m1.3.3.3.3.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="S4.Ex4.m1.3.3.3.3.2.5" xref="S4.Ex4.m1.3.3.3.4.cmml">)</mo></mrow></mrow><mrow id="S4.Ex4.m1.6.6.6.3" xref="S4.Ex4.m1.6.6.6.4.cmml"><mi id="S4.Ex4.m1.4.4.4.1" xref="S4.Ex4.m1.4.4.4.1.cmml">max</mi><mo id="S4.Ex4.m1.6.6.6.3a" xref="S4.Ex4.m1.6.6.6.4.cmml">⁡</mo><mrow id="S4.Ex4.m1.6.6.6.3.2" xref="S4.Ex4.m1.6.6.6.4.cmml"><mo stretchy="false" id="S4.Ex4.m1.6.6.6.3.2.3" xref="S4.Ex4.m1.6.6.6.4.cmml">(</mo><mrow id="S4.Ex4.m1.5.5.5.2.1.1.1" xref="S4.Ex4.m1.5.5.5.2.1.1.2.cmml"><mo stretchy="false" id="S4.Ex4.m1.5.5.5.2.1.1.1.2" xref="S4.Ex4.m1.5.5.5.2.1.1.2.1.cmml">|</mo><msub id="S4.Ex4.m1.5.5.5.2.1.1.1.1" xref="S4.Ex4.m1.5.5.5.2.1.1.1.1.cmml"><mi id="S4.Ex4.m1.5.5.5.2.1.1.1.1.2" xref="S4.Ex4.m1.5.5.5.2.1.1.1.1.2.cmml">x</mi><mi id="S4.Ex4.m1.5.5.5.2.1.1.1.1.3" xref="S4.Ex4.m1.5.5.5.2.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S4.Ex4.m1.5.5.5.2.1.1.1.3" xref="S4.Ex4.m1.5.5.5.2.1.1.2.1.cmml">|</mo></mrow><mo id="S4.Ex4.m1.6.6.6.3.2.4" xref="S4.Ex4.m1.6.6.6.4.cmml">,</mo><mrow id="S4.Ex4.m1.6.6.6.3.2.2.1" xref="S4.Ex4.m1.6.6.6.3.2.2.2.cmml"><mo stretchy="false" id="S4.Ex4.m1.6.6.6.3.2.2.1.2" xref="S4.Ex4.m1.6.6.6.3.2.2.2.1.cmml">|</mo><msub id="S4.Ex4.m1.6.6.6.3.2.2.1.1" xref="S4.Ex4.m1.6.6.6.3.2.2.1.1.cmml"><mi id="S4.Ex4.m1.6.6.6.3.2.2.1.1.2" xref="S4.Ex4.m1.6.6.6.3.2.2.1.1.2.cmml">x</mi><mi id="S4.Ex4.m1.6.6.6.3.2.2.1.1.3" xref="S4.Ex4.m1.6.6.6.3.2.2.1.1.3.cmml">j</mi></msub><mo stretchy="false" id="S4.Ex4.m1.6.6.6.3.2.2.1.3" xref="S4.Ex4.m1.6.6.6.3.2.2.2.1.cmml">|</mo></mrow><mo stretchy="false" id="S4.Ex4.m1.6.6.6.3.2.5" xref="S4.Ex4.m1.6.6.6.4.cmml">)</mo></mrow></mrow></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex4.m1.9b"><apply id="S4.Ex4.m1.9.9.cmml" xref="S4.Ex4.m1.9.9"><eq id="S4.Ex4.m1.9.9.3.cmml" xref="S4.Ex4.m1.9.9.3"></eq><apply id="S4.Ex4.m1.9.9.2.3.cmml" xref="S4.Ex4.m1.9.9.2.2"><ci id="S4.Ex4.m1.7.7.cmml" xref="S4.Ex4.m1.7.7">EditSim</ci><apply id="S4.Ex4.m1.8.8.1.1.1.1.cmml" xref="S4.Ex4.m1.8.8.1.1.1.1"><csymbol cd="ambiguous" id="S4.Ex4.m1.8.8.1.1.1.1.1.cmml" xref="S4.Ex4.m1.8.8.1.1.1.1">subscript</csymbol><ci id="S4.Ex4.m1.8.8.1.1.1.1.2.cmml" xref="S4.Ex4.m1.8.8.1.1.1.1.2">𝑥</ci><ci id="S4.Ex4.m1.8.8.1.1.1.1.3.cmml" xref="S4.Ex4.m1.8.8.1.1.1.1.3">𝑖</ci></apply><apply id="S4.Ex4.m1.9.9.2.2.2.2.cmml" xref="S4.Ex4.m1.9.9.2.2.2.2"><csymbol cd="ambiguous" id="S4.Ex4.m1.9.9.2.2.2.2.1.cmml" xref="S4.Ex4.m1.9.9.2.2.2.2">subscript</csymbol><ci id="S4.Ex4.m1.9.9.2.2.2.2.2.cmml" xref="S4.Ex4.m1.9.9.2.2.2.2.2">𝑥</ci><ci id="S4.Ex4.m1.9.9.2.2.2.2.3.cmml" xref="S4.Ex4.m1.9.9.2.2.2.2.3">𝑗</ci></apply></apply><apply id="S4.Ex4.m1.9.9.4.cmml" xref="S4.Ex4.m1.9.9.4"><minus id="S4.Ex4.m1.9.9.4.1.cmml" xref="S4.Ex4.m1.9.9.4.1"></minus><cn type="integer" id="S4.Ex4.m1.9.9.4.2.cmml" xref="S4.Ex4.m1.9.9.4.2">1</cn><apply id="S4.Ex4.m1.6.6.cmml" xref="S4.Ex4.m1.6.6"><divide id="S4.Ex4.m1.6.6.7.cmml" xref="S4.Ex4.m1.6.6"></divide><apply id="S4.Ex4.m1.3.3.3.4.cmml" xref="S4.Ex4.m1.3.3.3.3"><ci id="S4.Ex4.m1.1.1.1.1.cmml" xref="S4.Ex4.m1.1.1.1.1">EditDistance</ci><apply id="S4.Ex4.m1.2.2.2.2.1.1.cmml" xref="S4.Ex4.m1.2.2.2.2.1.1"><csymbol cd="ambiguous" id="S4.Ex4.m1.2.2.2.2.1.1.1.cmml" xref="S4.Ex4.m1.2.2.2.2.1.1">subscript</csymbol><ci id="S4.Ex4.m1.2.2.2.2.1.1.2.cmml" xref="S4.Ex4.m1.2.2.2.2.1.1.2">𝑥</ci><ci id="S4.Ex4.m1.2.2.2.2.1.1.3.cmml" xref="S4.Ex4.m1.2.2.2.2.1.1.3">𝑖</ci></apply><apply id="S4.Ex4.m1.3.3.3.3.2.2.cmml" xref="S4.Ex4.m1.3.3.3.3.2.2"><csymbol cd="ambiguous" id="S4.Ex4.m1.3.3.3.3.2.2.1.cmml" xref="S4.Ex4.m1.3.3.3.3.2.2">subscript</csymbol><ci id="S4.Ex4.m1.3.3.3.3.2.2.2.cmml" xref="S4.Ex4.m1.3.3.3.3.2.2.2">𝑥</ci><ci id="S4.Ex4.m1.3.3.3.3.2.2.3.cmml" xref="S4.Ex4.m1.3.3.3.3.2.2.3">𝑗</ci></apply></apply><apply id="S4.Ex4.m1.6.6.6.4.cmml" xref="S4.Ex4.m1.6.6.6.3"><max id="S4.Ex4.m1.4.4.4.1.cmml" xref="S4.Ex4.m1.4.4.4.1"></max><apply id="S4.Ex4.m1.5.5.5.2.1.1.2.cmml" xref="S4.Ex4.m1.5.5.5.2.1.1.1"><abs id="S4.Ex4.m1.5.5.5.2.1.1.2.1.cmml" xref="S4.Ex4.m1.5.5.5.2.1.1.1.2"></abs><apply id="S4.Ex4.m1.5.5.5.2.1.1.1.1.cmml" xref="S4.Ex4.m1.5.5.5.2.1.1.1.1"><csymbol cd="ambiguous" id="S4.Ex4.m1.5.5.5.2.1.1.1.1.1.cmml" xref="S4.Ex4.m1.5.5.5.2.1.1.1.1">subscript</csymbol><ci id="S4.Ex4.m1.5.5.5.2.1.1.1.1.2.cmml" xref="S4.Ex4.m1.5.5.5.2.1.1.1.1.2">𝑥</ci><ci id="S4.Ex4.m1.5.5.5.2.1.1.1.1.3.cmml" xref="S4.Ex4.m1.5.5.5.2.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S4.Ex4.m1.6.6.6.3.2.2.2.cmml" xref="S4.Ex4.m1.6.6.6.3.2.2.1"><abs id="S4.Ex4.m1.6.6.6.3.2.2.2.1.cmml" xref="S4.Ex4.m1.6.6.6.3.2.2.1.2"></abs><apply id="S4.Ex4.m1.6.6.6.3.2.2.1.1.cmml" xref="S4.Ex4.m1.6.6.6.3.2.2.1.1"><csymbol cd="ambiguous" id="S4.Ex4.m1.6.6.6.3.2.2.1.1.1.cmml" xref="S4.Ex4.m1.6.6.6.3.2.2.1.1">subscript</csymbol><ci id="S4.Ex4.m1.6.6.6.3.2.2.1.1.2.cmml" xref="S4.Ex4.m1.6.6.6.3.2.2.1.1.2">𝑥</ci><ci id="S4.Ex4.m1.6.6.6.3.2.2.1.1.3.cmml" xref="S4.Ex4.m1.6.6.6.3.2.2.1.1.3">𝑗</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex4.m1.9c">\operatorname{EditSim}(x_{i},x_{j})=1-\frac{\operatorname{EditDistance}(x_{i},x_{j})}{\max(|x_{i}|,|x_{j}|)}</annotation><annotation encoding="application/x-llamapun" id="S4.Ex4.m1.9d">roman_EditSim ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) = 1 - divide start_ARG roman_EditDistance ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) end_ARG start_ARG roman_max ( | italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | , | italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | ) end_ARG</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS2.p5" class="ltx_para ltx_noindent">
<p id="S4.SS2.p5.1" class="ltx_p">To build clusters of similar documents, we construct a graph that has an edge between two documents if they are considered a match. Then, we use the method introduced in <cite class="ltx_cite ltx_citemacro_citet">Łącki et&nbsp;al. (<a href="#bib.bib50" title="" class="ltx_ref">2018</a>)</cite> to identify connected components.
A breakdown of the computation needed is given in Appendix <a href="#A1" title="Appendix A Further Details on NearDup ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
<figure id="S4.F1" class="ltx_figure"><img src="/html/2107.06499/assets/x1.png" id="S4.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="441" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The distribution of near-duplicate cluster sizes from running <span id="S4.F1.2.1" class="ltx_text ltx_font_smallcaps">NearDup</span> on C4.</figcaption>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Deduplication Results</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We deduplicate each of the four datasets with both of our two techniques.
When text was duplicated across multiple data splits, we prioritized keeping a copy in the test or validation set and removing it from the train set.
</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Amount of Text Removed</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">With <span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_smallcaps">NearDup</span>, we found that the web-scrape datasets contain between 3.04% (on C4) to 13.63% (on RealNews) near duplicates (Table <a href="#S5.T2" title="Table 2 ‣ 5.1 Amount of Text Removed ‣ 5 Deduplication Results ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
Near-duplicate text is much less common in Wiki-40B, forming only 0.39% of the train set.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Most duplicates we saw were automatically generated pages, such as the outcomes of sports games.
This shows the strength of manual curation for creating high-quality datasets.</span></span></span>
In C4, the majority (1.8M) of near-duplicate clusters consisted of just a single pair of examples that matched against each other, but there were 280 clusters with over 5,000 examples in them (Figure <a href="#S4.F1" title="Figure 1 ‣ 4.2 Approximate Matching with MinHash ‣ 4 Methods for Identifying Duplicates ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), including one cluster of size 250,933.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.5" class="ltx_p">On average with <span id="S5.SS1.p2.5.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span>, we remove more total content than with <span id="S5.SS1.p2.5.2" class="ltx_text ltx_font_smallcaps">NearDup</span> (despite <span id="S5.SS1.p2.5.3" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> not removing any examples outright)—for example removing <math id="S5.SS1.p2.1.m1.1" class="ltx_Math" alttext="7.18\%" display="inline"><semantics id="S5.SS1.p2.1.m1.1a"><mrow id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml"><mn id="S5.SS1.p2.1.m1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.2.cmml">7.18</mn><mo id="S5.SS1.p2.1.m1.1.1.1" xref="S5.SS1.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><apply id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"><csymbol cd="latexml" id="S5.SS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S5.SS1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1.2">7.18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">7.18\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.1.m1.1d">7.18 %</annotation></semantics></math> of the tokens in C4.
The exception is LM1B, where <span id="S5.SS1.p2.5.4" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> removes <math id="S5.SS1.p2.2.m2.1" class="ltx_math_unparsed" alttext="8\times" display="inline"><semantics id="S5.SS1.p2.2.m2.1a"><mrow id="S5.SS1.p2.2.m2.1b"><mn id="S5.SS1.p2.2.m2.1.1">8</mn><mo lspace="0.222em" id="S5.SS1.p2.2.m2.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">8\times</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.2.m2.1d">8 ×</annotation></semantics></math> less data than
<span id="S5.SS1.p2.5.5" class="ltx_text ltx_font_smallcaps">NearDup</span>.
On investigation, we find this is due to the fact that LM1B documents are significantly shorter: <math id="S5.SS1.p2.3.m3.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S5.SS1.p2.3.m3.1a"><mrow id="S5.SS1.p2.3.m3.1.1" xref="S5.SS1.p2.3.m3.1.1.cmml"><mn id="S5.SS1.p2.3.m3.1.1.2" xref="S5.SS1.p2.3.m3.1.1.2.cmml">90</mn><mo id="S5.SS1.p2.3.m3.1.1.1" xref="S5.SS1.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.3.m3.1b"><apply id="S5.SS1.p2.3.m3.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1"><csymbol cd="latexml" id="S5.SS1.p2.3.m3.1.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S5.SS1.p2.3.m3.1.1.2.cmml" xref="S5.SS1.p2.3.m3.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.3.m3.1c">90\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.3.m3.1d">90 %</annotation></semantics></math> of all documents are under 50 tokens, and so are not even candidates for potential matches even if the entire sequence matched verbatim.
We find that both <span id="S5.SS1.p2.5.6" class="ltx_text ltx_font_smallcaps">NearDup</span> and <span id="S5.SS1.p2.5.7" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> remove similar content—<math id="S5.SS1.p2.4.m4.1" class="ltx_Math" alttext="77\%" display="inline"><semantics id="S5.SS1.p2.4.m4.1a"><mrow id="S5.SS1.p2.4.m4.1.1" xref="S5.SS1.p2.4.m4.1.1.cmml"><mn id="S5.SS1.p2.4.m4.1.1.2" xref="S5.SS1.p2.4.m4.1.1.2.cmml">77</mn><mo id="S5.SS1.p2.4.m4.1.1.1" xref="S5.SS1.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.4.m4.1b"><apply id="S5.SS1.p2.4.m4.1.1.cmml" xref="S5.SS1.p2.4.m4.1.1"><csymbol cd="latexml" id="S5.SS1.p2.4.m4.1.1.1.cmml" xref="S5.SS1.p2.4.m4.1.1.1">percent</csymbol><cn type="integer" id="S5.SS1.p2.4.m4.1.1.2.cmml" xref="S5.SS1.p2.4.m4.1.1.2">77</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.4.m4.1c">77\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.4.m4.1d">77 %</annotation></semantics></math> of the training examples that <span id="S5.SS1.p2.5.8" class="ltx_text ltx_font_smallcaps">NearDup</span> removes from C4 have at least one verbatim length-<math id="S5.SS1.p2.5.m5.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S5.SS1.p2.5.m5.1a"><mn id="S5.SS1.p2.5.m5.1.1" xref="S5.SS1.p2.5.m5.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.5.m5.1b"><cn type="integer" id="S5.SS1.p2.5.m5.1.1.cmml" xref="S5.SS1.p2.5.m5.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.5.m5.1c">50</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.5.m5.1d">50</annotation></semantics></math> match found by <span id="S5.SS1.p2.5.9" class="ltx_text ltx_font_smallcaps">ExactSubstr</span>.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<table id="S5.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T2.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S5.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">% train examples with</th>
<th id="S5.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">% valid with</th>
</tr>
<tr id="S5.T2.1.2.2" class="ltx_tr">
<th id="S5.T2.1.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S5.T2.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">dup in train</th>
<th id="S5.T2.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">dup in valid</th>
<th id="S5.T2.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">dup in train</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T2.1.3.1" class="ltx_tr">
<th id="S5.T2.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">C4</th>
<td id="S5.T2.1.3.1.2" class="ltx_td ltx_align_right ltx_border_t">3.04%</td>
<td id="S5.T2.1.3.1.3" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">1.59%</td>
<td id="S5.T2.1.3.1.4" class="ltx_td ltx_align_right ltx_border_t">4.60%</td>
</tr>
<tr id="S5.T2.1.4.2" class="ltx_tr">
<th id="S5.T2.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">RealNews</th>
<td id="S5.T2.1.4.2.2" class="ltx_td ltx_align_right">13.63%</td>
<td id="S5.T2.1.4.2.3" class="ltx_td ltx_align_right ltx_border_r">1.25%</td>
<td id="S5.T2.1.4.2.4" class="ltx_td ltx_align_right">14.35%</td>
</tr>
<tr id="S5.T2.1.5.3" class="ltx_tr">
<th id="S5.T2.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">LM1B</th>
<td id="S5.T2.1.5.3.2" class="ltx_td ltx_align_right">4.86%</td>
<td id="S5.T2.1.5.3.3" class="ltx_td ltx_align_right ltx_border_r">0.07%</td>
<td id="S5.T2.1.5.3.4" class="ltx_td ltx_align_right">4.92%</td>
</tr>
<tr id="S5.T2.1.6.4" class="ltx_tr">
<th id="S5.T2.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Wiki40B</th>
<td id="S5.T2.1.6.4.2" class="ltx_td ltx_align_right ltx_border_bb">0.39%</td>
<td id="S5.T2.1.6.4.3" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r">0.26%</td>
<td id="S5.T2.1.6.4.4" class="ltx_td ltx_align_right ltx_border_bb">0.72%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>The fraction of examples identified by <span id="S5.T2.3.1" class="ltx_text ltx_font_smallcaps">NearDup</span> as near-duplicates.</figcaption>
</figure>
<figure id="S5.T3" class="ltx_table">
<table id="S5.T3.12" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T3.12.13.1" class="ltx_tr">
<th id="S5.T3.12.13.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S5.T3.12.13.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">% train tokens with</th>
<th id="S5.T3.12.13.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">% valid with</th>
</tr>
<tr id="S5.T3.12.14.2" class="ltx_tr">
<th id="S5.T3.12.14.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r"></th>
<th id="S5.T3.12.14.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">dup in train</th>
<th id="S5.T3.12.14.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">dup in valid</th>
<th id="S5.T3.12.14.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">dup in train</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T3.3.3" class="ltx_tr">
<th id="S5.T3.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">C4</th>
<td id="S5.T3.1.1.1" class="ltx_td ltx_align_left ltx_border_t">
<math id="S5.T3.1.1.1.m1.1" class="ltx_Math" alttext="7.18" display="inline"><semantics id="S5.T3.1.1.1.m1.1a"><mn id="S5.T3.1.1.1.m1.1.1" xref="S5.T3.1.1.1.m1.1.1.cmml">7.18</mn><annotation-xml encoding="MathML-Content" id="S5.T3.1.1.1.m1.1b"><cn type="float" id="S5.T3.1.1.1.m1.1.1.cmml" xref="S5.T3.1.1.1.m1.1.1">7.18</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.1.1.1.m1.1c">7.18</annotation><annotation encoding="application/x-llamapun" id="S5.T3.1.1.1.m1.1d">7.18</annotation></semantics></math>%</td>
<td id="S5.T3.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<math id="S5.T3.2.2.2.m1.1" class="ltx_Math" alttext="0.75" display="inline"><semantics id="S5.T3.2.2.2.m1.1a"><mn id="S5.T3.2.2.2.m1.1.1" xref="S5.T3.2.2.2.m1.1.1.cmml">0.75</mn><annotation-xml encoding="MathML-Content" id="S5.T3.2.2.2.m1.1b"><cn type="float" id="S5.T3.2.2.2.m1.1.1.cmml" xref="S5.T3.2.2.2.m1.1.1">0.75</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.2.2.2.m1.1c">0.75</annotation><annotation encoding="application/x-llamapun" id="S5.T3.2.2.2.m1.1d">0.75</annotation></semantics></math>%</td>
<td id="S5.T3.3.3.3" class="ltx_td ltx_align_left ltx_border_t">
<math id="S5.T3.3.3.3.m1.1" class="ltx_Math" alttext="1.38" display="inline"><semantics id="S5.T3.3.3.3.m1.1a"><mn id="S5.T3.3.3.3.m1.1.1" xref="S5.T3.3.3.3.m1.1.1.cmml">1.38</mn><annotation-xml encoding="MathML-Content" id="S5.T3.3.3.3.m1.1b"><cn type="float" id="S5.T3.3.3.3.m1.1.1.cmml" xref="S5.T3.3.3.3.m1.1.1">1.38</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.3.3.3.m1.1c">1.38</annotation><annotation encoding="application/x-llamapun" id="S5.T3.3.3.3.m1.1d">1.38</annotation></semantics></math>%</td>
</tr>
<tr id="S5.T3.6.6" class="ltx_tr">
<th id="S5.T3.6.6.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">RealNews</th>
<td id="S5.T3.4.4.1" class="ltx_td ltx_align_left">
<math id="S5.T3.4.4.1.m1.1" class="ltx_Math" alttext="19.4" display="inline"><semantics id="S5.T3.4.4.1.m1.1a"><mn id="S5.T3.4.4.1.m1.1.1" xref="S5.T3.4.4.1.m1.1.1.cmml">19.4</mn><annotation-xml encoding="MathML-Content" id="S5.T3.4.4.1.m1.1b"><cn type="float" id="S5.T3.4.4.1.m1.1.1.cmml" xref="S5.T3.4.4.1.m1.1.1">19.4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.4.4.1.m1.1c">19.4</annotation><annotation encoding="application/x-llamapun" id="S5.T3.4.4.1.m1.1d">19.4</annotation></semantics></math>%</td>
<td id="S5.T3.5.5.2" class="ltx_td ltx_align_left ltx_border_r">
<math id="S5.T3.5.5.2.m1.1" class="ltx_Math" alttext="2.61" display="inline"><semantics id="S5.T3.5.5.2.m1.1a"><mn id="S5.T3.5.5.2.m1.1.1" xref="S5.T3.5.5.2.m1.1.1.cmml">2.61</mn><annotation-xml encoding="MathML-Content" id="S5.T3.5.5.2.m1.1b"><cn type="float" id="S5.T3.5.5.2.m1.1.1.cmml" xref="S5.T3.5.5.2.m1.1.1">2.61</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.5.5.2.m1.1c">2.61</annotation><annotation encoding="application/x-llamapun" id="S5.T3.5.5.2.m1.1d">2.61</annotation></semantics></math>%</td>
<td id="S5.T3.6.6.3" class="ltx_td ltx_align_left">
<math id="S5.T3.6.6.3.m1.1" class="ltx_Math" alttext="3.37" display="inline"><semantics id="S5.T3.6.6.3.m1.1a"><mn id="S5.T3.6.6.3.m1.1.1" xref="S5.T3.6.6.3.m1.1.1.cmml">3.37</mn><annotation-xml encoding="MathML-Content" id="S5.T3.6.6.3.m1.1b"><cn type="float" id="S5.T3.6.6.3.m1.1.1.cmml" xref="S5.T3.6.6.3.m1.1.1">3.37</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.6.6.3.m1.1c">3.37</annotation><annotation encoding="application/x-llamapun" id="S5.T3.6.6.3.m1.1d">3.37</annotation></semantics></math>%</td>
</tr>
<tr id="S5.T3.9.9" class="ltx_tr">
<th id="S5.T3.9.9.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">LM1B</th>
<td id="S5.T3.7.7.1" class="ltx_td ltx_align_left">
<math id="S5.T3.7.7.1.m1.1" class="ltx_Math" alttext="0.76" display="inline"><semantics id="S5.T3.7.7.1.m1.1a"><mn id="S5.T3.7.7.1.m1.1.1" xref="S5.T3.7.7.1.m1.1.1.cmml">0.76</mn><annotation-xml encoding="MathML-Content" id="S5.T3.7.7.1.m1.1b"><cn type="float" id="S5.T3.7.7.1.m1.1.1.cmml" xref="S5.T3.7.7.1.m1.1.1">0.76</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.7.7.1.m1.1c">0.76</annotation><annotation encoding="application/x-llamapun" id="S5.T3.7.7.1.m1.1d">0.76</annotation></semantics></math>%</td>
<td id="S5.T3.8.8.2" class="ltx_td ltx_align_left ltx_border_r">
<math id="S5.T3.8.8.2.m1.1" class="ltx_Math" alttext="0.016" display="inline"><semantics id="S5.T3.8.8.2.m1.1a"><mn id="S5.T3.8.8.2.m1.1.1" xref="S5.T3.8.8.2.m1.1.1.cmml">0.016</mn><annotation-xml encoding="MathML-Content" id="S5.T3.8.8.2.m1.1b"><cn type="float" id="S5.T3.8.8.2.m1.1.1.cmml" xref="S5.T3.8.8.2.m1.1.1">0.016</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.8.8.2.m1.1c">0.016</annotation><annotation encoding="application/x-llamapun" id="S5.T3.8.8.2.m1.1d">0.016</annotation></semantics></math>%</td>
<td id="S5.T3.9.9.3" class="ltx_td ltx_align_left">
<math id="S5.T3.9.9.3.m1.1" class="ltx_Math" alttext="0.019" display="inline"><semantics id="S5.T3.9.9.3.m1.1a"><mn id="S5.T3.9.9.3.m1.1.1" xref="S5.T3.9.9.3.m1.1.1.cmml">0.019</mn><annotation-xml encoding="MathML-Content" id="S5.T3.9.9.3.m1.1b"><cn type="float" id="S5.T3.9.9.3.m1.1.1.cmml" xref="S5.T3.9.9.3.m1.1.1">0.019</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.9.9.3.m1.1c">0.019</annotation><annotation encoding="application/x-llamapun" id="S5.T3.9.9.3.m1.1d">0.019</annotation></semantics></math>%</td>
</tr>
<tr id="S5.T3.12.12" class="ltx_tr">
<th id="S5.T3.12.12.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Wiki40B</th>
<td id="S5.T3.10.10.1" class="ltx_td ltx_align_left ltx_border_bb">
<math id="S5.T3.10.10.1.m1.1" class="ltx_Math" alttext="2.76" display="inline"><semantics id="S5.T3.10.10.1.m1.1a"><mn id="S5.T3.10.10.1.m1.1.1" xref="S5.T3.10.10.1.m1.1.1.cmml">2.76</mn><annotation-xml encoding="MathML-Content" id="S5.T3.10.10.1.m1.1b"><cn type="float" id="S5.T3.10.10.1.m1.1.1.cmml" xref="S5.T3.10.10.1.m1.1.1">2.76</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.10.10.1.m1.1c">2.76</annotation><annotation encoding="application/x-llamapun" id="S5.T3.10.10.1.m1.1d">2.76</annotation></semantics></math>%</td>
<td id="S5.T3.11.11.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_r">
<math id="S5.T3.11.11.2.m1.1" class="ltx_Math" alttext="0.52" display="inline"><semantics id="S5.T3.11.11.2.m1.1a"><mn id="S5.T3.11.11.2.m1.1.1" xref="S5.T3.11.11.2.m1.1.1.cmml">0.52</mn><annotation-xml encoding="MathML-Content" id="S5.T3.11.11.2.m1.1b"><cn type="float" id="S5.T3.11.11.2.m1.1.1.cmml" xref="S5.T3.11.11.2.m1.1.1">0.52</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.11.11.2.m1.1c">0.52</annotation><annotation encoding="application/x-llamapun" id="S5.T3.11.11.2.m1.1d">0.52</annotation></semantics></math>%</td>
<td id="S5.T3.12.12.3" class="ltx_td ltx_align_left ltx_border_bb">
<math id="S5.T3.12.12.3.m1.1" class="ltx_Math" alttext="0.67" display="inline"><semantics id="S5.T3.12.12.3.m1.1a"><mn id="S5.T3.12.12.3.m1.1.1" xref="S5.T3.12.12.3.m1.1.1.cmml">0.67</mn><annotation-xml encoding="MathML-Content" id="S5.T3.12.12.3.m1.1b"><cn type="float" id="S5.T3.12.12.3.m1.1.1.cmml" xref="S5.T3.12.12.3.m1.1.1">0.67</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.T3.12.12.3.m1.1c">0.67</annotation><annotation encoding="application/x-llamapun" id="S5.T3.12.12.3.m1.1d">0.67</annotation></semantics></math>%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>The fraction of tokens (note Table&nbsp;<a href="#S5.T2" title="Table 2 ‣ 5.1 Amount of Text Removed ‣ 5 Deduplication Results ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> reports the fraction of <em id="S5.T3.15.1" class="ltx_emph ltx_font_italic">examples</em>) identified by <span id="S5.T3.16.2" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> as part of an exact duplicate 50-token substring.</figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Properties of Duplicated Text</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">While the authors of both RealNews and C4 explicitly attempted deduplication during dataset construction, the methods were insufficient to capture the more subtle types of duplicate text commonly found on the internet.
In C4 and Wiki-40B, we qualitatively observe that much of the text identified as near-duplicated is computer-generated.
The text is identical except for the names of places, businesses, products, dates, and so on.
Because these examples frequently differ by just a few words at a time, deduplication strategies relying on exact string matching would fail to identify a match.
Example duplicate pairs from each dataset can be found in Table <a href="#S4.T1" title="Table 1 ‣ 4.1.2 Substring matching ‣ 4.1 Exact Substring Duplication ‣ 4 Methods for Identifying Duplicates ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (more examples in the Appendix).</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">For RealNews and LM1B, derived from news sites, we observe that many near-duplicates occur because the same news article appears on multiple news sites with slightly different formatting.
For example, in LM1B, there is one example that starts “<span id="S5.SS2.p2.1.1" class="ltx_text ltx_font_italic">MINEOLA , N.Y. - New York officials say</span> […]” and another that starts “<span id="S5.SS2.p2.1.2" class="ltx_text ltx_font_italic">( AP ) - New York officials say</span> […]”.
The two examples are otherwise identical.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Train / Test Set Leakage</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">Both deduplication methods identify overlap between the train set and the validation set (Table <a href="#S5.T2" title="Table 2 ‣ 5.1 Amount of Text Removed ‣ 5 Deduplication Results ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
For example, 4.6% of the C4 validation set and 14.4% of the RealNews validation set examples had an approximate duplicate in their respective training sets.
Such duplication is problematic since it could cause evaluation metrics to be unfairly inflated for models that are better at memorizing their train sets.
We evaluate the effect of this leakage on publicly released models in Section <a href="#S6.SS3" title="6.3 Impact on Existing Models ‣ 6 Impact on Trained Models ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6.3</span></a>.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Impact on Trained Models</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">.
We trained 1.5B parameter “XL", decoder-only, Transformer-based language models similar to GPT-2, on C4-<span id="S6.p1.1.1" class="ltx_text ltx_font_smallcaps">Original</span>, C4-<span id="S6.p1.1.2" class="ltx_text ltx_font_smallcaps">NearDup</span>, and C4-<span id="S6.p1.1.3" class="ltx_text ltx_font_smallcaps">ExactSubstr</span>, respectively.
We use the T5 codebase and model architecture from <cite class="ltx_cite ltx_citemacro_citet">Raffel et&nbsp;al. (<a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite>, and each model was trained for about two epochs on its respective dataset.
To better understand the amount of variance in the perplexities of trained models, we also trained three different random seeds of the 110M parameter “base" model for each of the above three datasets—for a total of nine base-sized models.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">For all experiments, we used a Byte Pair Encoding (BPE) vocabulary trained on C4-<span id="S6.p2.1.1" class="ltx_text ltx_font_smallcaps">NearDup</span> with a budget of 50K tokens, which resulted in a vocabulary the same size as GPT-2’s.
We trained with a maximum sequence length of 512 tokens (for longer documents, we randomly extracted subsequences of this length.)
Further training details can be found in Appendix <a href="#A3" title="Appendix C Further Details on Model Training ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Model Perplexity</h3>

<figure id="S6.F2" class="ltx_figure"><img src="/html/2107.06499/assets/x2.png" id="S6.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="831" height="423" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>
Impact of deduplicating the training set on validation perplexity.
We plot the results from T5 XL (see Appendix for base-sized model).
For C4, we evaluate on <span id="S6.F2.6.1" class="ltx_text ltx_font_italic">C4 Original</span>, the original validation set; <span id="S6.F2.7.2" class="ltx_text ltx_font_italic">C4 Unique</span>, a subset of the validation set identified by <span id="S6.F2.8.3" class="ltx_text ltx_font_smallcaps">NearDup</span> as having zero matches across C4; and <span id="S6.F2.9.4" class="ltx_text ltx_font_italic">C4 Duplicates</span>, a subset of the validation set identified by <span id="S6.F2.10.5" class="ltx_text ltx_font_smallcaps">NearDup</span> as having a match in the C4 train set.
</figcaption>
</figure>
<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">We computed the perplexity of our trained models on the validation sets of LM1B and Wiki-40B, and on subsets of the C4 validation set (Figure <a href="#S6.F2" title="Figure 2 ‣ 6.1 Model Perplexity ‣ 6 Impact on Trained Models ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
For the base size, we observe that all models have similar perplexity on the original C4 validation set and on validation set examples that were identified as unique (no near-duplicate in either train or validation).
However, both models trained on deduplicated data have significantly higher perplexity on validation set examples that have duplicates in the training set than the model trained on the original C4. <span id="S6.SS1.p1.1.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span>-deduplicated results in higher perplexity than <span id="S6.SS1.p1.1.2" class="ltx_text ltx_font_smallcaps">NearDup</span>-deduplicated.
These trends holds true for the XL sized model as well.
While this may suggest <span id="S6.SS1.p1.1.3" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> duplication results in models least overfit on the train set, note that both of these techniques have
used separate duplicate thresholds and a different choice of thresholds could change the results.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.1" class="ltx_p">When evaluating on the validation sets of LM1B and Wiki-40B, we found that models trained on <span id="S6.SS1.p2.1.1" class="ltx_text ltx_font_smallcaps">NearDup</span>-deduplicated C4 consistently achieved lowest perplexity (for LM1B eval with base models, see Appendix Figure <a href="#A5.F7" title="Figure 7 ‣ Perplexity on LM1B. ‣ Appendix E More Results ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>).
<span id="S6.SS1.p2.1.2" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> deduplication decreases perplexity of the XL model by almost 3 points perplexity on Wiki-40B which is much larger than the variation of about 1 point perplexity we observed in the base models.
This is despite seeing fewer tokens of training data overall.</p>
</div>
<div id="S6.SS1.p3" class="ltx_para">
<p id="S6.SS1.p3.1" class="ltx_p">Lastly, we note all our XL models achieved &lt;35 perplexity on LM1B, which is less than the 42.16 perplexity reported for the 1.5B GPT-2 using a vocabulary the same size as ours.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Generated Text</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.2" class="ltx_p">Data duplication has the effect of biasing the trained LM towards particular types of examples.
This can contribute to a lower diversity of generations, and increased likelihood that the generated content is copied from the training data <cite class="ltx_cite ltx_citemacro_citep">(Carlini et&nbsp;al., <a href="#bib.bib11" title="" class="ltx_ref">2020</a>)</cite>.
For our generation experiments, we use top-<math id="S6.SS2.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S6.SS2.p1.1.m1.1a"><mi id="S6.SS2.p1.1.m1.1.1" xref="S6.SS2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.1.m1.1b"><ci id="S6.SS2.p1.1.m1.1.1.cmml" xref="S6.SS2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p1.1.m1.1d">italic_k</annotation></semantics></math> random sampling with <math id="S6.SS2.p1.2.m2.1" class="ltx_Math" alttext="k=50" display="inline"><semantics id="S6.SS2.p1.2.m2.1a"><mrow id="S6.SS2.p1.2.m2.1.1" xref="S6.SS2.p1.2.m2.1.1.cmml"><mi id="S6.SS2.p1.2.m2.1.1.2" xref="S6.SS2.p1.2.m2.1.1.2.cmml">k</mi><mo id="S6.SS2.p1.2.m2.1.1.1" xref="S6.SS2.p1.2.m2.1.1.1.cmml">=</mo><mn id="S6.SS2.p1.2.m2.1.1.3" xref="S6.SS2.p1.2.m2.1.1.3.cmml">50</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS2.p1.2.m2.1b"><apply id="S6.SS2.p1.2.m2.1.1.cmml" xref="S6.SS2.p1.2.m2.1.1"><eq id="S6.SS2.p1.2.m2.1.1.1.cmml" xref="S6.SS2.p1.2.m2.1.1.1"></eq><ci id="S6.SS2.p1.2.m2.1.1.2.cmml" xref="S6.SS2.p1.2.m2.1.1.2">𝑘</ci><cn type="integer" id="S6.SS2.p1.2.m2.1.1.3.cmml" xref="S6.SS2.p1.2.m2.1.1.3">50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS2.p1.2.m2.1c">k=50</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.p1.2.m2.1d">italic_k = 50</annotation></semantics></math> and experiment with prompted and unprompted generation.</p>
</div>
<figure id="S6.T4" class="ltx_table">
<table id="S6.T4.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T4.5.1.1" class="ltx_tr">
<th id="S6.T4.5.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Model</th>
<th id="S6.T4.5.1.1.2" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">1 Epoch</th>
<th id="S6.T4.5.1.1.3" class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt">2 Epochs</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T4.5.2.1" class="ltx_tr">
<th id="S6.T4.5.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">XL-<span id="S6.T4.5.2.1.1.1" class="ltx_text ltx_font_smallcaps">Original</span>
</th>
<td id="S6.T4.5.2.1.2" class="ltx_td ltx_align_right ltx_border_t">1.926%</td>
<td id="S6.T4.5.2.1.3" class="ltx_td ltx_align_right ltx_border_t">1.571%</td>
</tr>
<tr id="S6.T4.5.3.2" class="ltx_tr">
<th id="S6.T4.5.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">XL-<span id="S6.T4.5.3.2.1.1" class="ltx_text ltx_font_smallcaps">NearDup</span>
</th>
<td id="S6.T4.5.3.2.2" class="ltx_td ltx_align_right">0.189%</td>
<td id="S6.T4.5.3.2.3" class="ltx_td ltx_align_right">0.264%</td>
</tr>
<tr id="S6.T4.5.4.3" class="ltx_tr">
<th id="S6.T4.5.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">XL-<span id="S6.T4.5.4.3.1.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span>
</th>
<td id="S6.T4.5.4.3.2" class="ltx_td ltx_align_right ltx_border_bb">0.138%</td>
<td id="S6.T4.5.4.3.3" class="ltx_td ltx_align_right ltx_border_bb">0.168%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>When generating 100k sequences with no prompting, over <math id="S6.T4.3.m1.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S6.T4.3.m1.1b"><mrow id="S6.T4.3.m1.1.1" xref="S6.T4.3.m1.1.1.cmml"><mn id="S6.T4.3.m1.1.1.2" xref="S6.T4.3.m1.1.1.2.cmml">1</mn><mo id="S6.T4.3.m1.1.1.1" xref="S6.T4.3.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.T4.3.m1.1c"><apply id="S6.T4.3.m1.1.1.cmml" xref="S6.T4.3.m1.1.1"><csymbol cd="latexml" id="S6.T4.3.m1.1.1.1.cmml" xref="S6.T4.3.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.T4.3.m1.1.1.2.cmml" xref="S6.T4.3.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.3.m1.1d">1\%</annotation><annotation encoding="application/x-llamapun" id="S6.T4.3.m1.1e">1 %</annotation></semantics></math> of the tokens emitted from a model trained on the original dataset are part of a 50-token long sequence copied directly from the training dataset. This drops to <math id="S6.T4.4.m2.1" class="ltx_Math" alttext="0.1\%" display="inline"><semantics id="S6.T4.4.m2.1b"><mrow id="S6.T4.4.m2.1.1" xref="S6.T4.4.m2.1.1.cmml"><mn id="S6.T4.4.m2.1.1.2" xref="S6.T4.4.m2.1.1.2.cmml">0.1</mn><mo id="S6.T4.4.m2.1.1.1" xref="S6.T4.4.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.T4.4.m2.1c"><apply id="S6.T4.4.m2.1.1.cmml" xref="S6.T4.4.m2.1.1"><csymbol cd="latexml" id="S6.T4.4.m2.1.1.1.cmml" xref="S6.T4.4.m2.1.1.1">percent</csymbol><cn type="float" id="S6.T4.4.m2.1.1.2.cmml" xref="S6.T4.4.m2.1.1.2">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.4.m2.1d">0.1\%</annotation><annotation encoding="application/x-llamapun" id="S6.T4.4.m2.1e">0.1 %</annotation></semantics></math> for the deduplicated datasets.</figcaption>
</figure>
<section id="S6.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">No prompt.</h5>

<div id="S6.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px1.p1.1" class="ltx_p">We first evaluate memorization tendencies in the case where the model is asked to generate text without any prompt sequence.
We generate 100,000 samples, each up to 512 tokens in length (examples provided in the Appendix).
For each generated token, we say the token is memorized if it is part of a 50-token substring that is exactly contained in the training data.
On XL-<span id="S6.SS2.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_smallcaps">Original</span>, over 1% of the generated tokens belong to memorized sub-sequences (see Table&nbsp;<a href="#S6.T4" title="Table 4 ‣ 6.2 Generated Text ‣ 6 Impact on Trained Models ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>).
This is <math id="S6.SS2.SSS0.Px1.p1.1.m1.1" class="ltx_math_unparsed" alttext="\sim 10\times" display="inline"><semantics id="S6.SS2.SSS0.Px1.p1.1.m1.1a"><mrow id="S6.SS2.SSS0.Px1.p1.1.m1.1b"><mo id="S6.SS2.SSS0.Px1.p1.1.m1.1.1">∼</mo><mn id="S6.SS2.SSS0.Px1.p1.1.m1.1.2">10</mn><mo lspace="0.222em" id="S6.SS2.SSS0.Px1.p1.1.m1.1.3">×</mo></mrow><annotation encoding="application/x-tex" id="S6.SS2.SSS0.Px1.p1.1.m1.1c">\sim 10\times</annotation><annotation encoding="application/x-llamapun" id="S6.SS2.SSS0.Px1.p1.1.m1.1d">∼ 10 ×</annotation></semantics></math> more memorization than XL-<span id="S6.SS2.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> or XL-<span id="S6.SS2.SSS0.Px1.p1.1.3" class="ltx_text ltx_font_smallcaps">NearDup</span>.
Some example subsequences that were copied verbatim from the train set can be found in Table <a href="#A4.T9" title="Table 9 ‣ Appendix D Energy Consumption ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> in the Appendix.</p>
</div>
<figure id="S6.F3" class="ltx_figure"><img src="/html/2107.06499/assets/x3.png" id="S6.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="831" height="462" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The proportion of generations which have edit similarity above 0.8 with the groundtruth continuation when using the LM to generate continuations for 32-token prompts identified by <span id="S6.F3.2.1" class="ltx_text ltx_font_smallcaps">NearDup</span> as either duplicated or unique.</figcaption>
</figure>
</section>
<section id="S6.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">With prompting.</h5>

<div id="S6.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS2.SSS0.Px2.p1.1" class="ltx_p">In most real use cases, language model generation is controlled by providing a prompt for the model to continue.
We experiment with four possible prompt sources: training examples identified by <span id="S6.SS2.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> as having near-duplicates in the train set (train dup), training examples identified as unique (train unique), validation set examples with a near-duplicate in the train set (valid in train), and validation set examples identified as unique across all splits (valid unique).
We select the first 32 tokens of each example as the prompt, which means we can evaluate the fraction of generations which are near-duplicates with the ground-truth continuation for the prompt (Figure <a href="#S6.F3" title="Figure 3 ‣ No prompt. ‣ 6.2 Generated Text ‣ 6 Impact on Trained Models ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).
When the prompt comes from duplicate examples in the train set, XL-<span id="S6.SS2.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_smallcaps">Original</span> reproduces the groundtruth continuation over 40% of the time.
XL-<span id="S6.SS2.SSS0.Px2.p1.1.3" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> and XL-<span id="S6.SS2.SSS0.Px2.p1.1.4" class="ltx_text ltx_font_smallcaps">NearDup</span> still copy the groundtruth more often when the prompt comes from a duplicate example than when the prompt comes from a unique example, suggesting that more stringent deduplication may be necessary to remove memorization tendencies entirely.</p>
</div>
<figure id="S6.T5" class="ltx_table">
<table id="S6.T5.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T5.1.1.1" class="ltx_tr">
<th id="S6.T5.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Model</th>
<th id="S6.T5.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Dataset</th>
<th id="S6.T5.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Orig</th>
<th id="S6.T5.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Dups</th>
<th id="S6.T5.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Unique</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T5.1.2.1" class="ltx_tr">
<th id="S6.T5.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Transformer-XL</th>
<th id="S6.T5.1.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">LM1B</th>
<td id="S6.T5.1.2.1.3" class="ltx_td ltx_align_right ltx_border_t">21.77</td>
<td id="S6.T5.1.2.1.4" class="ltx_td ltx_align_right ltx_border_t">10.11</td>
<td id="S6.T5.1.2.1.5" class="ltx_td ltx_align_right ltx_border_t">23.58</td>
</tr>
<tr id="S6.T5.1.3.2" class="ltx_tr">
<th id="S6.T5.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">GROVER-Base</th>
<th id="S6.T5.1.3.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">RealNews</th>
<td id="S6.T5.1.3.2.3" class="ltx_td ltx_align_right">15.44</td>
<td id="S6.T5.1.3.2.4" class="ltx_td ltx_align_right">13.77</td>
<td id="S6.T5.1.3.2.5" class="ltx_td ltx_align_right">15.73</td>
</tr>
<tr id="S6.T5.1.4.3" class="ltx_tr">
<th id="S6.T5.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">GROVER-XL</th>
<th id="S6.T5.1.4.3.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">RealNews</th>
<td id="S6.T5.1.4.3.3" class="ltx_td ltx_align_right ltx_border_bb">9.15</td>
<td id="S6.T5.1.4.3.4" class="ltx_td ltx_align_right ltx_border_bb">7.68</td>
<td id="S6.T5.1.4.3.5" class="ltx_td ltx_align_right ltx_border_bb">9.45</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>For each model, the perplexity of the official validation set (<span id="S6.T5.7.1" class="ltx_text ltx_font_italic">Orig</span>), valid set examples which were identified by <span id="S6.T5.8.2" class="ltx_text ltx_font_smallcaps">NearDup</span> as matches of train set examples (<span id="S6.T5.9.3" class="ltx_text ltx_font_italic">Dups</span>), and valid set examples identified by <span id="S6.T5.10.4" class="ltx_text ltx_font_smallcaps">NearDup</span> as unique (<span id="S6.T5.11.5" class="ltx_text ltx_font_italic">Unique</span>).
Due to the size of the RealNews validation set, we evaluated on only the first 25k examples meeting each condition.</figcaption>
</figure>
</section>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Impact on Existing Models</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">Train-test leakage does not just impact models trained on C4.
Table <a href="#S6.T5" title="Table 5 ‣ With prompting. ‣ 6.2 Generated Text ‣ 6 Impact on Trained Models ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows that
the presence of near-duplicates of the evaluation set
in the train set has a significant impact on model perplexity for two standard models: Transformer-XL <cite class="ltx_cite ltx_citemacro_citep">(Dai et&nbsp;al., <a href="#bib.bib15" title="" class="ltx_ref">2019</a>)</cite>, which was trained on LM1B, and GROVER <cite class="ltx_cite ltx_citemacro_citep">(Zellers et&nbsp;al., <a href="#bib.bib47" title="" class="ltx_ref">2019</a>)</cite>, which was trained on RealNews.
For Transformer XL, the perplexity halves on examples identified as near-duplicates.
For GROVER, the difference, though not quite as stark, is present in both model sizes considered.</p>
</div>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.3" class="ltx_p">Existing models also suffer from the problem of generating text from their train sets.
We find that <math id="S6.SS3.p2.1.m1.1" class="ltx_Math" alttext="1.38\%" display="inline"><semantics id="S6.SS3.p2.1.m1.1a"><mrow id="S6.SS3.p2.1.m1.1.1" xref="S6.SS3.p2.1.m1.1.1.cmml"><mn id="S6.SS3.p2.1.m1.1.1.2" xref="S6.SS3.p2.1.m1.1.1.2.cmml">1.38</mn><mo id="S6.SS3.p2.1.m1.1.1.1" xref="S6.SS3.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.SS3.p2.1.m1.1b"><apply id="S6.SS3.p2.1.m1.1.1.cmml" xref="S6.SS3.p2.1.m1.1.1"><csymbol cd="latexml" id="S6.SS3.p2.1.m1.1.1.1.cmml" xref="S6.SS3.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S6.SS3.p2.1.m1.1.1.2.cmml" xref="S6.SS3.p2.1.m1.1.1.2">1.38</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p2.1.m1.1c">1.38\%</annotation><annotation encoding="application/x-llamapun" id="S6.SS3.p2.1.m1.1d">1.38 %</annotation></semantics></math> of the tokens in the official release of 25k GROVER-Mega outputs
<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a href="gs://grover-models/generation_examples/generator=mega~dataset=p0.90.jsonl" title="" class="ltx_ref ltx_url ltx_font_typewriter">gs://grover-models/generation_examples/generator=mega~dataset=p0.90.jsonl</a></span></span></span>
are part of verbatim matches in RealNews of at least length <math id="S6.SS3.p2.2.m2.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S6.SS3.p2.2.m2.1a"><mn id="S6.SS3.p2.2.m2.1.1" xref="S6.SS3.p2.2.m2.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.p2.2.m2.1b"><cn type="integer" id="S6.SS3.p2.2.m2.1.1.cmml" xref="S6.SS3.p2.2.m2.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p2.2.m2.1c">50</annotation><annotation encoding="application/x-llamapun" id="S6.SS3.p2.2.m2.1d">50</annotation></semantics></math>.
Likewise, more than 5% of the tokens in ~200k sequences outputted by GPT-Neo 1.3B <cite class="ltx_cite ltx_citemacro_citep">(Black et&nbsp;al., <a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite> are part of a <math id="S6.SS3.p2.3.m3.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S6.SS3.p2.3.m3.1a"><mn id="S6.SS3.p2.3.m3.1.1" xref="S6.SS3.p2.3.m3.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S6.SS3.p2.3.m3.1b"><cn type="integer" id="S6.SS3.p2.3.m3.1.1.cmml" xref="S6.SS3.p2.3.m3.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS3.p2.3.m3.1c">50</annotation><annotation encoding="application/x-llamapun" id="S6.SS3.p2.3.m3.1d">50</annotation></semantics></math> token matches of its training data, the Pile <cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Discussion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">The focus of this paper is on the datasets used to train language models.
While recent work focused on documenting the potential harms that could arise from problematic datasets <cite class="ltx_cite ltx_citemacro_cite">Bender and Friedman (<a href="#bib.bib4" title="" class="ltx_ref">2018</a>); Gebru et&nbsp;al. (<a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite>, less work has been done to
quantitatively analyze properties of real language modelling datasets, like <cite class="ltx_cite ltx_citemacro_citet">Dodge et&nbsp;al. (<a href="#bib.bib16" title="" class="ltx_ref">2021a</a>)</cite> has done for C4.
Our paper provides analysis on one particular axis, that of data duplication.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">Our experiments measured what could be quantified: the amount of duplicate content in common datasets, the effect of deduplication on trained model perplexity, and the reduction of memorized content in trained models through deduplication.
We do not focus on the nature of the data being removed by deduplication or memorized by LMs.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p">Privacy is an important subject for future work, as memorized training data has significant privacy consequences.
By this, we mean the standard privacy definition that a model should not reveal anything particular to the specific dataset it was trained on, as opposed to another training dataset from a similar distribution <cite class="ltx_cite ltx_citemacro_citep">(Shokri et&nbsp;al., <a href="#bib.bib35" title="" class="ltx_ref">2017</a>)</cite>.<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Another interpretation of privacy focuses on the sensitivity of the data involved, when a model is trained on and able to reproduce personal identifiers or other forms of “private data.” Our definition is more expansive.</span></span></span>
Training on standard datasets that have not yet been deduplicated results in models that are particularly sensitive to examples that happened to be repeated multiple times, and this has negative privacy implications.
For instance, it could violate a person’s expectations of privacy if their publicly available personal data appeared in a different, surprising context.
Downstream applications of LMs, such as the game AI Dungeon<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a target="_blank" href="https://play.aidungeon.io/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://play.aidungeon.io/</a></span></span></span>, should also not output memorized content like adverts for real products.</p>
</div>
<div id="S7.p4" class="ltx_para">
<p id="S7.p4.1" class="ltx_p">We stress that in our experiments, we do not distinguish between undesired memorized text (such as phone numbers), innocuous memorized text (common phrases), and text we may want to be memorized (such as a quote by a public figure), and instead treat all instances of the LM generating text that closely matches the training set as problematic.
While we qualitatively observed that much of the identified memorized content was relatively innocuous, a more systematic study of the risks associated with the detected memorization was beyond the scope of this work.</p>
</div>
<div id="S7.p5" class="ltx_para">
<p id="S7.p5.1" class="ltx_p">We also do not investigate the negative consequences of deduplication.
Some language tasks explicitly require memorization, like document retrieval or closed-book question answering.
Also, text that gives attribution is often duplicated across documents, so
removing duplicate substrings could correspond to removing <em id="S7.p5.1.1" class="ltx_emph ltx_font_italic">just</em> the attribution, which could result in models that learn the content without its attached attribution.
Deduplication is also not sufficient to remove privacy-sensitive data like bank passwords and medical records which should never be used in training data <cite class="ltx_cite ltx_citemacro_cite">Brown et&nbsp;al. (<a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S7.p6" class="ltx_para">
<p id="S7.p6.1" class="ltx_p">Ultimately, whether memorization is a desired property of a language model, or else risky and unwanted, depends
both on the nature of the text that has been memorized and on the downstream applications of the trained model.
However, since the trend has been towards creating datasets and models that are application-agnostic, we encourage researchers to think carefully about the limitations of the data they have
collected and the how the model’s intended usage constrains what should be part of the training set.
Developing techniques to memorize or forget specific sequences depending on the end application is a promising research direction.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Conclusion</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">We encourage future language model research to perform dataset deduplication, either by training on the deduplicated datasets we release, using the deduplication tools we release, or following our approach to deduplicate datasets with new tools.</p>
</div>
<div id="S8.p2" class="ltx_para">
<p id="S8.p2.1" class="ltx_p">The exact technique used to perform deduplication is less important than performing stringent deduplication in the first place.
On the whole, deduplication does not harm, and sometimes improves, model perplexity, despite the fact that the deduplicated datasets are smaller and faster to train on.
It is especially important that there are no duplicates between the training and testing sets, because overlap here explicitly encourages selecting models that memorize the training data.
Lastly, deduplication helps to reduce some of the privacy concerns around LMs memorizing their training data.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Ethics</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The developers of large language models typically attempt to create training data that reflects natural human communication, but current methods to collect and curate such datasets are fallible.
There are multiple reasons some text ends up over-represented.
For example, bot replies, auto-generated templates, and licenses are repeated for structural (e.g., legal, economical) reasons (as was also observed by <cite class="ltx_cite ltx_citemacro_citet">Dodge et&nbsp;al. (<a href="#bib.bib16" title="" class="ltx_ref">2021a</a>)</cite>).
Additionally, common techniques for acquiring and “cleaning” data can result in an over-representation of particular subsets of world users, often those who are English-speaking and publishing in established forums.
This effectively under-represents non-English speakers as well as groups whose communication mostly occurs outside of the public web.
In this paper, we focus on the problem of over-representation of some types of text (structural duplicates) but do not address the problem of under-representation of others.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p">Additionally, while we discuss when memorized content might be desired and when it might not be desired, our analysis does not disambiguate these two cases.
Work to disambiguate helpful from harmful memorization is tremendously complex and would require a different set of research methodologies than are presented in this work.</p>
</div>
</section>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx2.p1" class="ltx_para">
<p id="Sx2.p1.1" class="ltx_p">We are grateful to the many researchers whose technical help, feedback, and discussions shaped this project:
Jacob Austin,
Samy Bengio,
Olivier Bousquet,
James Bradbury,
Fernando Diaz,
Mark Diaz,
Noah Fiedel,
Jonathan Frankle,
David Grangier,
Stefanie Karp,
David Mimno,
Gaurav Mishra,
Michael Mozer,
Sharan Narang,
Alex Passos,
Adam Roberts,
Hanie Sedghi,
Jascha Sohl-dickstein,
David So,
Florian Tramer,
and
Yun William Yu.
We are also grateful to the Google Brain women who have given us continuous support.</p>
</div>
<div id="Sx2.p2" class="ltx_para">
<p id="Sx2.p2.1" class="ltx_p">Chris Callison-Burch and Daphne Ippolito’s research is supported in part by the DARPA KAIROS Program (contract FA8750-19-2-1004), the DARPA LwLL Program (contract FA8750-19-2-0201), and the IARPA BETTER Program (contract 2019-19051600004). The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of DARPA, IARPA, or the U.S. Government.
</p>
</div>
</section>
<section id="Sx3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Contributions</h2>

<div id="Sx3.p1" class="ltx_para">
<p id="Sx3.p1.1" class="ltx_p">Each of the authors on this paper significantly contributed to the final results.</p>
<ul id="Sx3.I1" class="ltx_itemize">
<li id="Sx3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I1.i1.p1" class="ltx_para">
<p id="Sx3.I1.i1.p1.1" class="ltx_p">Katherine trained the models used in the paper, built and ran the eval and text generation pipelines, contributed significantly to writing, analysis, and project organization and management.</p>
</div>
</li>
<li id="Sx3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I1.i2.p1" class="ltx_para">
<p id="Sx3.I1.i2.p1.1" class="ltx_p">Daphne ran the approximate matching data deduplication pipelines, extracted prompts and evaluation datasets, ran eval pipelines, and contributed significantly to planning, writing, and analysis.</p>
</div>
</li>
<li id="Sx3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I1.i3.p1" class="ltx_para">
<p id="Sx3.I1.i3.p1.1" class="ltx_p">Andrew wrote the code to perform deduplication with approximate matching, helped evaluate energy expenditure, and helped with analysis.</p>
</div>
</li>
<li id="Sx3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I1.i4.p1" class="ltx_para">
<p id="Sx3.I1.i4.p1.1" class="ltx_p">Chiyuan helped generate plots and contributed to project scoping, writing, and data analysis.</p>
</div>
</li>
<li id="Sx3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I1.i5.p1" class="ltx_para">
<p id="Sx3.I1.i5.p1.1" class="ltx_p">Chris offered mentorship and guidance throughout the project and contributed to writing.</p>
</div>
</li>
<li id="Sx3.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I1.i6.p1" class="ltx_para">
<p id="Sx3.I1.i6.p1.1" class="ltx_p">Doug offered mentorship and guidance throughout the project and contributed to writing.</p>
</div>
</li>
<li id="Sx3.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="Sx3.I1.i7.p1" class="ltx_para">
<p id="Sx3.I1.i7.p1.1" class="ltx_p">Nicholas wrote the suffix array implementation, ran all <span id="Sx3.I1.i7.p1.1.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> deduplication experiments, contributed significantly to planning, writing, and analysis, as well as scoping the project.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Allamanis (2019)</span>
<span class="ltx_bibblock">
Miltiadis Allamanis. 2019.

</span>
<span class="ltx_bibblock">The adverse effects of code duplication in machine learning models of
code.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 ACM SIGPLAN International Symposium
on New Ideas, New Paradigms, and Reflections on Programming and Software</em>,
pages 143–153.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arpit et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Devansh Arpit, Stanisław Jastrzębski, Nicolas Ballas, David Krueger,
Emmanuel Bengio, Maxinder&nbsp;S Kanwal, Tegan Maharaj, Asja Fischer, Aaron
Courville, Yoshua Bengio, et&nbsp;al. 2017.

</span>
<span class="ltx_bibblock">A closer look at memorization in deep networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
233–242. PMLR.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bandy and Vincent (2021)</span>
<span class="ltx_bibblock">
Jack Bandy and Nicholas Vincent. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2105.05241" title="" class="ltx_ref ltx_href">Addressing "documentation
debt" in machine learning research: A retrospective datasheet for
bookcorpus</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender and Friedman (2018)</span>
<span class="ltx_bibblock">
Emily&nbsp;M. Bender and Batya Friedman. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1162/tacl_a_00041" title="" class="ltx_ref ltx_href">Data statements for
natural language processing: Toward mitigating system bias and enabling
better science</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
6:587–604.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Emily&nbsp;M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret
Shmitchell. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/3442188.3445922" title="" class="ltx_ref ltx_href">On the dangers of
stochastic parrots: Can language models be too
big?<span id="bib.bib5.1.1.1" class="ltx_text" style="position:relative; bottom:-5.0pt;"><img src="/html/2107.06499/assets/parrot.png" id="bib.bib5.1.1.1.g1" class="ltx_graphics ltx_img_square" width="25" height="28" alt="[Uncaptioned image]"></span></a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.2.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 ACM Conference on Fairness,
Accountability, and Transparency</em>, FAccT ’21, page 610–623, New York, NY,
USA. Association for Computing Machinery.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Black et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Sid Black, Leo Gao, Phil Wang, Connor Leahy, and Stella Biderman. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://github.com/eleutherai/gpt-neo" title="" class="ltx_ref ltx_href">GPT-Neo: Large scale
autoregressive language modeling with mesh-tensorflow</a>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bloom (1970)</span>
<span class="ltx_bibblock">
Burton&nbsp;H Bloom. 1970.

</span>
<span class="ltx_bibblock">Space/time trade-offs in hash coding with allowable errors.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">Communications of the ACM</em>, 13(7):422–426.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Broder (1997)</span>
<span class="ltx_bibblock">
Andrei&nbsp;Z Broder. 1997.

</span>
<span class="ltx_bibblock">On the resemblance and containment of documents.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings. Compression and Complexity of SEQUENCES 1997
(Cat. No. 97TB100171)</em>, pages 21–29. IEEE.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Hannah Brown, Katherine Lee, Fatemehsadat Mireshghallah, Reza Shokri, and
Florian Tramèr. 2022.

</span>
<span class="ltx_bibblock">What does it mean for a language model to preserve privacy?

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint</em>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Tom&nbsp;B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et&nbsp;al. 2020.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 33</em>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel
Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar
Erlingsson, Alina Oprea, and Colin Raffel. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2012.07805" title="" class="ltx_ref ltx_href">Extracting training data
from large language models</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chelba et&nbsp;al. (2013)</span>
<span class="ltx_bibblock">
Ciprian Chelba, Tomas Mikolov, Mike Schuster, Qi&nbsp;Ge, Thorsten Brants, Phillipp
Koehn, and Tony Robinson. 2013.

</span>
<span class="ltx_bibblock">One billion word benchmark for measuring progress in statistical
language modeling.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1312.3005</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chim and Deng (2007)</span>
<span class="ltx_bibblock">
Hung Chim and Xiaotie Deng. 2007.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1145/1242572.1242590" title="" class="ltx_ref ltx_href">A new suffix tree
similarity measure for document clustering</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th International Conference on World
Wide Web</em>, WWW ’07, page 121–130, New York, NY, USA. Association for
Computing Machinery.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cohen (2016)</span>
<span class="ltx_bibblock">
Edith Cohen. 2016.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://www.cohenwang.com/edith/Surveys/minhash.pdf" title="" class="ltx_ref ltx_href">Min-hash
sketches: A brief survey</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc&nbsp;V Le, and Ruslan
Salakhutdinov. 2019.

</span>
<span class="ltx_bibblock">Transformer-xl: Attentive language models beyond a fixed-length
context.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1901.02860</em>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dodge et&nbsp;al. (2021a)</span>
<span class="ltx_bibblock">
Jesse Dodge, Maarten Sap, Ana Marasovic, William Agnew, Gabriel Ilharco, Dirk
Groeneveld, and Matt Gardner. 2021a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2104.08758" title="" class="ltx_ref ltx_href">Documenting the english
colossal clean crawled corpus</a>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dodge et&nbsp;al. (2021b)</span>
<span class="ltx_bibblock">
Jesse Dodge, Maarten Sap, Ana Marasovic, William Agnew, Gabriel Ilharco, Dirk
Groeneveld, and Matt Gardner. 2021b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2104.08758" title="" class="ltx_ref ltx_href">Documenting the english
colossal clean crawled corpus</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.08758</em>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feldman and Zhang (2020)</span>
<span class="ltx_bibblock">
Vitaly Feldman and Chiyuan Zhang. 2020.

</span>
<span class="ltx_bibblock">What neural networks memorize and why: Discovering the long tail via
influence estimation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gabriel et&nbsp;al. (2018)</span>
<span class="ltx_bibblock">
Rodney&nbsp;A. Gabriel, Tsung-Ting Kuo, Julian McAuley, and Chun-Nan Hsu. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/https://doi.org/10.1016/j.jbi.2018.04.009" title="" class="ltx_ref ltx_href">Identifying and characterizing highly similar notes in big clinical note
datasets</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Journal of Biomedical Informatics</em>, 82:63–69.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles
Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser,
and Connor Leahy. 2020.

</span>
<span class="ltx_bibblock">The Pile: An 800gb dataset of diverse text for language modeling.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2101.00027</em>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gebru et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer&nbsp;Wortman Vaughan,
Hanna Wallach, Hal Daumé&nbsp;III au2, and Kate Crawford. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1803.09010" title="" class="ltx_ref ltx_href">Datasheets for datasets</a>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graff et&nbsp;al. (2003)</span>
<span class="ltx_bibblock">
David Graff, Junbo Kong, Ke&nbsp;Chen, and Kazuaki Maeda. 2003.

</span>
<span class="ltx_bibblock">English gigaword.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Linguistic Data Consortium, Philadelphia</em>, 4(1):34.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Mandy Guo, Zihang Dai, Denny Vrandecic, and Rami Al-Rfou. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.296.pdf" title="" class="ltx_ref ltx_href">Wiki-40b: Multilingual language model dataset</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">LREC 2020</em>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gyawali et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Bikash Gyawali, Lucas Anastasiou, and Petr Knoth. 2020.

</span>
<span class="ltx_bibblock">Deduplication of scholarly documents using locality sensitive hashing
and word embeddings.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Language Resources and Evaluation
Conference</em>, pages 901–910.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jaccard (1912)</span>
<span class="ltx_bibblock">
Paul Jaccard. 1912.

</span>
<span class="ltx_bibblock">The distribution of the flora in the alpine zone.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">New phytologist</em>, 11(2):37–50.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kärkkäinen and Sanders (2003)</span>
<span class="ltx_bibblock">
Juha Kärkkäinen and Peter Sanders. 2003.

</span>
<span class="ltx_bibblock">Simple linear work suffix array construction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">International colloquium on automata, languages, and
programming</em>, pages 943–955. Springer.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ko and Aluru (2003)</span>
<span class="ltx_bibblock">
Pang Ko and Srinivas Aluru. 2003.

</span>
<span class="ltx_bibblock">Space efficient linear time construction of suffix arrays.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Annual Symposium on Combinatorial Pattern Matching</em>, pages
200–210. Springer.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Manber and Myers (1993)</span>
<span class="ltx_bibblock">
Udi Manber and Gene Myers. 1993.

</span>
<span class="ltx_bibblock">Suffix arrays: a new method for on-line string searches.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">siam Journal on Computing</em>, 22(5):935–948.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nong et&nbsp;al. (2009)</span>
<span class="ltx_bibblock">
Ge&nbsp;Nong, Sen Zhang, and Wai&nbsp;Hong Chan. 2009.

</span>
<span class="ltx_bibblock">Linear suffix array construction by almost pure induced-sorting.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">2009 data compression conference</em>, pages 193–202. IEEE.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patterson et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia,
Daniel Rothchild, David So, Maud Texier, and Jeff Dean. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/2104.10350" title="" class="ltx_ref ltx_href">Carbon emissions and large
neural network training</a>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever. 2019.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">OpenAI blog</em>, 1(8):9.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J. Liu. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://jmlr.org/papers/v21/20-074.html" title="" class="ltx_ref ltx_href">Exploring the limits
of transfer learning with a unified text-to-text transformer</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, 21(140):1–67.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer and Stern (2018)</span>
<span class="ltx_bibblock">
Noam Shazeer and Mitchell Stern. 2018.

</span>
<span class="ltx_bibblock">Adafactor: Adaptive learning rates with sublinear memory cost.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
4596–4604. PMLR.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sheng et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Emily Sheng, Kai-Wei Chang, Premkumar Natarajan, and Nanyun Peng. 2020.

</span>
<span class="ltx_bibblock">Towards controllable biases in language generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.00268</em>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shokri et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 2017.

</span>
<span class="ltx_bibblock">Membership inference attacks against machine learning models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">2017 IEEE Symposium on Security and Privacy (SP)</em>, pages
3–18. IEEE.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stephenson et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Cory Stephenson, Suchismita Padhy, Abhinav Ganesh, Yue Hui, Hanlin Tang, and
SueYeon Chung. 2021.

</span>
<span class="ltx_bibblock">On the geometry of generalization and memorization in deep neural
networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Strubell et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Emma Strubell, Ananya Ganesh, and Andrew McCallum. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1906.02243" title="" class="ltx_ref ltx_href">Energy and policy
considerations for deep learning in nlp</a>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Teterwak et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Piotr Teterwak, Chiyuan Zhang, Dilip Krishnan, and Michael&nbsp;C Mozer. 2021.

</span>
<span class="ltx_bibblock">Understanding invariance via feedforward inversion of
discriminatively trained classifiers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
10225–10235. PMLR.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trinh and Le (2018)</span>
<span class="ltx_bibblock">
Trieu&nbsp;H Trinh and Quoc&nbsp;V Le. 2018.

</span>
<span class="ltx_bibblock">A simple method for commonsense reasoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.02847</em>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan&nbsp;N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1706.03762</em>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Versley and Panchenko (2012)</span>
<span class="ltx_bibblock">
Yannick Versley and Yana Panchenko. 2012.

</span>
<span class="ltx_bibblock">Not just bigger: Towards better-quality web corpora.

</span>
<span class="ltx_bibblock">In <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">Proceedings of the seventh Web as Corpus Workshop (WAC7)</em>,
pages 44–52.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wallace et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh. 2019.

</span>
<span class="ltx_bibblock">Universal adversarial triggers for attacking and analyzing nlp.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1908.07125</em>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Webster et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Ryan Webster, Julien Rabin, Loïc Simon, and Frédéric Jurie. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.1109/CVPR.2019.01153" title="" class="ltx_ref ltx_href">Detecting
overfitting of deep generative networks via latent recovery</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">2019 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR)</em>, pages 11265–11274.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Weiner (1973)</span>
<span class="ltx_bibblock">
Peter Weiner. 1973.

</span>
<span class="ltx_bibblock">Linear pattern matching algorithms.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">14th Annual Symposium on Switching and Automata Theory (swat
1973)</em>, pages 1–11. IEEE.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya
Siddhant, Aditya Barua, and Colin Raffel. 2020.

</span>
<span class="ltx_bibblock">mt5: A massively multilingual pre-trained text-to-text transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.11934</em>.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yamamoto and Church (2001)</span>
<span class="ltx_bibblock">
Mikio Yamamoto and Kenneth&nbsp;W Church. 2001.

</span>
<span class="ltx_bibblock">Using suffix arrays to compute term frequency and document frequency
for all substrings in a corpus.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Computational Linguistics</em>, 27(1):1–30.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zellers et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi,
Franziska Roesner, and Yejin Choi. 2019.

</span>
<span class="ltx_bibblock">Defending against neural fake news.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.12616</em>.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zeng et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Wei Zeng, Xiaozhe Ren, Teng Su, Hui Wang, Yi&nbsp;Liao, Zhiwei Wang, Xin Jiang,
ZhenZhang Yang, Kaisheng Wang, Xiaoda Zhang, Chen Li, Ziyan Gong, Yifan Yao,
Xinjing Huang, Jun Wang, Jianfeng Yu, Qi&nbsp;Guo, Yue Yu, Yan Zhang, Jin Wang,
Hengtao Tao, Dasen Yan, Zexuan Yi, Fang Peng, Fangqing Jiang, Han Zhang,
Lingfeng Deng, Yehong Zhang, Zhe Lin, Chao Zhang, Shaojie Zhang, Mingyue Guo,
Shanzhi Gu, Gaojun Fan, Yaowei Wang, Xuefeng Jin, Qun Liu, and Yonghong Tian.
2021.

</span>
<span class="ltx_bibblock">Pangu-<math id="bib.bib48.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="bib.bib48.1.m1.1a"><mi id="bib.bib48.1.m1.1.1" xref="bib.bib48.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="bib.bib48.1.m1.1b"><ci id="bib.bib48.1.m1.1.1.cmml" xref="bib.bib48.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib48.1.m1.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="bib.bib48.1.m1.1d">italic_α</annotation></semantics></math>: Large-scale autoregressive pretrained chinese
language models with auto-parallel computation.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.2.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.12369</em>.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et&nbsp;al. (2015)</span>
<span class="ltx_bibblock">
Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun,
Antonio Torralba, and Sanja Fidler. 2015.

</span>
<span class="ltx_bibblock">Aligning books and movies: Towards story-like visual explanations by
watching movies and reading books.

</span>
<span class="ltx_bibblock">In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em>, pages 19–27.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Łącki et&nbsp;al. (2018)</span>
<span class="ltx_bibblock">
Jakub Łącki, Vahab Mirrokni, and Michał Włodarczyk. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="http://arxiv.org/abs/1807.10727" title="" class="ltx_ref ltx_href">Connected components at
scale via local contractions</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Further Details on <span id="A1.1.1" class="ltx_text ltx_font_smallcaps">NearDup</span>
</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.5" class="ltx_p">For our MinHash based deduplication method, documents are first space tokenized, then each consecutive 5-gram is hashed using tabulation hashing.
The set of these hashes is the signature for the document.
For each element in a document’s signature, the element is hashed using <math id="A1.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A1.p1.1.m1.1a"><mi id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b"><ci id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.p1.1.m1.1d">italic_k</annotation></semantics></math> other hash functions.
The minimum hashed element for each of the <math id="A1.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A1.p1.2.m2.1a"><mi id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b"><ci id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.p1.2.m2.1d">italic_k</annotation></semantics></math> hash functions is stored.
These minimum hashes are then partitioned into <math id="A1.p1.3.m3.1" class="ltx_Math" alttext="r" display="inline"><semantics id="A1.p1.3.m3.1a"><mi id="A1.p1.3.m3.1.1" xref="A1.p1.3.m3.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="A1.p1.3.m3.1b"><ci id="A1.p1.3.m3.1.1.cmml" xref="A1.p1.3.m3.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.3.m3.1c">r</annotation><annotation encoding="application/x-llamapun" id="A1.p1.3.m3.1d">italic_r</annotation></semantics></math> buckets, with <math id="A1.p1.4.m4.1" class="ltx_Math" alttext="b" display="inline"><semantics id="A1.p1.4.m4.1a"><mi id="A1.p1.4.m4.1.1" xref="A1.p1.4.m4.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="A1.p1.4.m4.1b"><ci id="A1.p1.4.m4.1.1.cmml" xref="A1.p1.4.m4.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.4.m4.1c">b</annotation><annotation encoding="application/x-llamapun" id="A1.p1.4.m4.1d">italic_b</annotation></semantics></math> hashes per bucket.
These <math id="A1.p1.5.m5.1" class="ltx_Math" alttext="b" display="inline"><semantics id="A1.p1.5.m5.1a"><mi id="A1.p1.5.m5.1.1" xref="A1.p1.5.m5.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="A1.p1.5.m5.1b"><ci id="A1.p1.5.m5.1.1.cmml" xref="A1.p1.5.m5.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.5.m5.1c">b</annotation><annotation encoding="application/x-llamapun" id="A1.p1.5.m5.1d">italic_b</annotation></semantics></math> hashes are augmented into a single value, then if two documents have the same value in at least one bucket, they’ll be marked as a potential match.
The probability that two documents are considered a potential match is equal to</p>
<table id="A1.Ex5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A1.Ex5.m1.9" class="ltx_Math" alttext="\operatorname{Pr}(d_{i},d_{j}|\operatorname{Jaccard}(d_{i},d_{j})=s_{i,j})=1-(1-s_{i,j}^{b})^{r}" display="block"><semantics id="A1.Ex5.m1.9a"><mrow id="A1.Ex5.m1.9.9" xref="A1.Ex5.m1.9.9.cmml"><mrow id="A1.Ex5.m1.8.8.2.2" xref="A1.Ex5.m1.8.8.2.3.cmml"><mi id="A1.Ex5.m1.6.6" xref="A1.Ex5.m1.6.6.cmml">Pr</mi><mo id="A1.Ex5.m1.8.8.2.2a" xref="A1.Ex5.m1.8.8.2.3.cmml">⁡</mo><mrow id="A1.Ex5.m1.8.8.2.2.2" xref="A1.Ex5.m1.8.8.2.3.cmml"><mo stretchy="false" id="A1.Ex5.m1.8.8.2.2.2.3" xref="A1.Ex5.m1.8.8.2.3.cmml">(</mo><msub id="A1.Ex5.m1.7.7.1.1.1.1" xref="A1.Ex5.m1.7.7.1.1.1.1.cmml"><mi id="A1.Ex5.m1.7.7.1.1.1.1.2" xref="A1.Ex5.m1.7.7.1.1.1.1.2.cmml">d</mi><mi id="A1.Ex5.m1.7.7.1.1.1.1.3" xref="A1.Ex5.m1.7.7.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.Ex5.m1.8.8.2.2.2.4" xref="A1.Ex5.m1.8.8.2.3.cmml">,</mo><mrow id="A1.Ex5.m1.8.8.2.2.2.2" xref="A1.Ex5.m1.8.8.2.2.2.2.cmml"><mrow id="A1.Ex5.m1.8.8.2.2.2.2.2" xref="A1.Ex5.m1.8.8.2.2.2.2.2.cmml"><msub id="A1.Ex5.m1.8.8.2.2.2.2.2.4" xref="A1.Ex5.m1.8.8.2.2.2.2.2.4.cmml"><mi id="A1.Ex5.m1.8.8.2.2.2.2.2.4.2" xref="A1.Ex5.m1.8.8.2.2.2.2.2.4.2.cmml">d</mi><mi id="A1.Ex5.m1.8.8.2.2.2.2.2.4.3" xref="A1.Ex5.m1.8.8.2.2.2.2.2.4.3.cmml">j</mi></msub><mo fence="false" id="A1.Ex5.m1.8.8.2.2.2.2.2.3" xref="A1.Ex5.m1.8.8.2.2.2.2.2.3.cmml">|</mo><mrow id="A1.Ex5.m1.8.8.2.2.2.2.2.2.2" xref="A1.Ex5.m1.8.8.2.2.2.2.2.2.3.cmml"><mi id="A1.Ex5.m1.5.5" xref="A1.Ex5.m1.5.5.cmml">Jaccard</mi><mo id="A1.Ex5.m1.8.8.2.2.2.2.2.2.2a" xref="A1.Ex5.m1.8.8.2.2.2.2.2.2.3.cmml">⁡</mo><mrow id="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2" xref="A1.Ex5.m1.8.8.2.2.2.2.2.2.3.cmml"><mo stretchy="false" id="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.3" xref="A1.Ex5.m1.8.8.2.2.2.2.2.2.3.cmml">(</mo><msub id="A1.Ex5.m1.8.8.2.2.2.2.1.1.1.1.1" xref="A1.Ex5.m1.8.8.2.2.2.2.1.1.1.1.1.cmml"><mi id="A1.Ex5.m1.8.8.2.2.2.2.1.1.1.1.1.2" xref="A1.Ex5.m1.8.8.2.2.2.2.1.1.1.1.1.2.cmml">d</mi><mi id="A1.Ex5.m1.8.8.2.2.2.2.1.1.1.1.1.3" xref="A1.Ex5.m1.8.8.2.2.2.2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.4" xref="A1.Ex5.m1.8.8.2.2.2.2.2.2.3.cmml">,</mo><msub id="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.2" xref="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.2.cmml"><mi id="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.2.2" xref="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.2.2.cmml">d</mi><mi id="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.2.3" xref="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.2.3.cmml">j</mi></msub><mo stretchy="false" id="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.5" xref="A1.Ex5.m1.8.8.2.2.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="A1.Ex5.m1.8.8.2.2.2.2.3" xref="A1.Ex5.m1.8.8.2.2.2.2.3.cmml">=</mo><msub id="A1.Ex5.m1.8.8.2.2.2.2.4" xref="A1.Ex5.m1.8.8.2.2.2.2.4.cmml"><mi id="A1.Ex5.m1.8.8.2.2.2.2.4.2" xref="A1.Ex5.m1.8.8.2.2.2.2.4.2.cmml">s</mi><mrow id="A1.Ex5.m1.2.2.2.4" xref="A1.Ex5.m1.2.2.2.3.cmml"><mi id="A1.Ex5.m1.1.1.1.1" xref="A1.Ex5.m1.1.1.1.1.cmml">i</mi><mo id="A1.Ex5.m1.2.2.2.4.1" xref="A1.Ex5.m1.2.2.2.3.cmml">,</mo><mi id="A1.Ex5.m1.2.2.2.2" xref="A1.Ex5.m1.2.2.2.2.cmml">j</mi></mrow></msub></mrow><mo stretchy="false" id="A1.Ex5.m1.8.8.2.2.2.5" xref="A1.Ex5.m1.8.8.2.3.cmml">)</mo></mrow></mrow><mo id="A1.Ex5.m1.9.9.4" xref="A1.Ex5.m1.9.9.4.cmml">=</mo><mrow id="A1.Ex5.m1.9.9.3" xref="A1.Ex5.m1.9.9.3.cmml"><mn id="A1.Ex5.m1.9.9.3.3" xref="A1.Ex5.m1.9.9.3.3.cmml">1</mn><mo id="A1.Ex5.m1.9.9.3.2" xref="A1.Ex5.m1.9.9.3.2.cmml">−</mo><msup id="A1.Ex5.m1.9.9.3.1" xref="A1.Ex5.m1.9.9.3.1.cmml"><mrow id="A1.Ex5.m1.9.9.3.1.1.1" xref="A1.Ex5.m1.9.9.3.1.1.1.1.cmml"><mo stretchy="false" id="A1.Ex5.m1.9.9.3.1.1.1.2" xref="A1.Ex5.m1.9.9.3.1.1.1.1.cmml">(</mo><mrow id="A1.Ex5.m1.9.9.3.1.1.1.1" xref="A1.Ex5.m1.9.9.3.1.1.1.1.cmml"><mn id="A1.Ex5.m1.9.9.3.1.1.1.1.2" xref="A1.Ex5.m1.9.9.3.1.1.1.1.2.cmml">1</mn><mo id="A1.Ex5.m1.9.9.3.1.1.1.1.1" xref="A1.Ex5.m1.9.9.3.1.1.1.1.1.cmml">−</mo><msubsup id="A1.Ex5.m1.9.9.3.1.1.1.1.3" xref="A1.Ex5.m1.9.9.3.1.1.1.1.3.cmml"><mi id="A1.Ex5.m1.9.9.3.1.1.1.1.3.2.2" xref="A1.Ex5.m1.9.9.3.1.1.1.1.3.2.2.cmml">s</mi><mrow id="A1.Ex5.m1.4.4.2.4" xref="A1.Ex5.m1.4.4.2.3.cmml"><mi id="A1.Ex5.m1.3.3.1.1" xref="A1.Ex5.m1.3.3.1.1.cmml">i</mi><mo id="A1.Ex5.m1.4.4.2.4.1" xref="A1.Ex5.m1.4.4.2.3.cmml">,</mo><mi id="A1.Ex5.m1.4.4.2.2" xref="A1.Ex5.m1.4.4.2.2.cmml">j</mi></mrow><mi id="A1.Ex5.m1.9.9.3.1.1.1.1.3.3" xref="A1.Ex5.m1.9.9.3.1.1.1.1.3.3.cmml">b</mi></msubsup></mrow><mo stretchy="false" id="A1.Ex5.m1.9.9.3.1.1.1.3" xref="A1.Ex5.m1.9.9.3.1.1.1.1.cmml">)</mo></mrow><mi id="A1.Ex5.m1.9.9.3.1.3" xref="A1.Ex5.m1.9.9.3.1.3.cmml">r</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex5.m1.9b"><apply id="A1.Ex5.m1.9.9.cmml" xref="A1.Ex5.m1.9.9"><eq id="A1.Ex5.m1.9.9.4.cmml" xref="A1.Ex5.m1.9.9.4"></eq><apply id="A1.Ex5.m1.8.8.2.3.cmml" xref="A1.Ex5.m1.8.8.2.2"><ci id="A1.Ex5.m1.6.6.cmml" xref="A1.Ex5.m1.6.6">Pr</ci><apply id="A1.Ex5.m1.7.7.1.1.1.1.cmml" xref="A1.Ex5.m1.7.7.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex5.m1.7.7.1.1.1.1.1.cmml" xref="A1.Ex5.m1.7.7.1.1.1.1">subscript</csymbol><ci id="A1.Ex5.m1.7.7.1.1.1.1.2.cmml" xref="A1.Ex5.m1.7.7.1.1.1.1.2">𝑑</ci><ci id="A1.Ex5.m1.7.7.1.1.1.1.3.cmml" xref="A1.Ex5.m1.7.7.1.1.1.1.3">𝑖</ci></apply><apply id="A1.Ex5.m1.8.8.2.2.2.2.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2"><eq id="A1.Ex5.m1.8.8.2.2.2.2.3.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.3"></eq><apply id="A1.Ex5.m1.8.8.2.2.2.2.2.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.2"><csymbol cd="latexml" id="A1.Ex5.m1.8.8.2.2.2.2.2.3.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.2.3">conditional</csymbol><apply id="A1.Ex5.m1.8.8.2.2.2.2.2.4.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.2.4"><csymbol cd="ambiguous" id="A1.Ex5.m1.8.8.2.2.2.2.2.4.1.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.2.4">subscript</csymbol><ci id="A1.Ex5.m1.8.8.2.2.2.2.2.4.2.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.2.4.2">𝑑</ci><ci id="A1.Ex5.m1.8.8.2.2.2.2.2.4.3.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.2.4.3">𝑗</ci></apply><apply id="A1.Ex5.m1.8.8.2.2.2.2.2.2.3.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.2.2.2"><ci id="A1.Ex5.m1.5.5.cmml" xref="A1.Ex5.m1.5.5">Jaccard</ci><apply id="A1.Ex5.m1.8.8.2.2.2.2.1.1.1.1.1.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="A1.Ex5.m1.8.8.2.2.2.2.1.1.1.1.1.1.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.1.1.1.1.1">subscript</csymbol><ci id="A1.Ex5.m1.8.8.2.2.2.2.1.1.1.1.1.2.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.1.1.1.1.1.2">𝑑</ci><ci id="A1.Ex5.m1.8.8.2.2.2.2.1.1.1.1.1.3.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.1.1.1.1.1.3">𝑖</ci></apply><apply id="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.2.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.2.1.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.2">subscript</csymbol><ci id="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.2.2.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.2.2">𝑑</ci><ci id="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.2.3.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.2.2.2.2.2.3">𝑗</ci></apply></apply></apply><apply id="A1.Ex5.m1.8.8.2.2.2.2.4.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.4"><csymbol cd="ambiguous" id="A1.Ex5.m1.8.8.2.2.2.2.4.1.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.4">subscript</csymbol><ci id="A1.Ex5.m1.8.8.2.2.2.2.4.2.cmml" xref="A1.Ex5.m1.8.8.2.2.2.2.4.2">𝑠</ci><list id="A1.Ex5.m1.2.2.2.3.cmml" xref="A1.Ex5.m1.2.2.2.4"><ci id="A1.Ex5.m1.1.1.1.1.cmml" xref="A1.Ex5.m1.1.1.1.1">𝑖</ci><ci id="A1.Ex5.m1.2.2.2.2.cmml" xref="A1.Ex5.m1.2.2.2.2">𝑗</ci></list></apply></apply></apply><apply id="A1.Ex5.m1.9.9.3.cmml" xref="A1.Ex5.m1.9.9.3"><minus id="A1.Ex5.m1.9.9.3.2.cmml" xref="A1.Ex5.m1.9.9.3.2"></minus><cn type="integer" id="A1.Ex5.m1.9.9.3.3.cmml" xref="A1.Ex5.m1.9.9.3.3">1</cn><apply id="A1.Ex5.m1.9.9.3.1.cmml" xref="A1.Ex5.m1.9.9.3.1"><csymbol cd="ambiguous" id="A1.Ex5.m1.9.9.3.1.2.cmml" xref="A1.Ex5.m1.9.9.3.1">superscript</csymbol><apply id="A1.Ex5.m1.9.9.3.1.1.1.1.cmml" xref="A1.Ex5.m1.9.9.3.1.1.1"><minus id="A1.Ex5.m1.9.9.3.1.1.1.1.1.cmml" xref="A1.Ex5.m1.9.9.3.1.1.1.1.1"></minus><cn type="integer" id="A1.Ex5.m1.9.9.3.1.1.1.1.2.cmml" xref="A1.Ex5.m1.9.9.3.1.1.1.1.2">1</cn><apply id="A1.Ex5.m1.9.9.3.1.1.1.1.3.cmml" xref="A1.Ex5.m1.9.9.3.1.1.1.1.3"><csymbol cd="ambiguous" id="A1.Ex5.m1.9.9.3.1.1.1.1.3.1.cmml" xref="A1.Ex5.m1.9.9.3.1.1.1.1.3">superscript</csymbol><apply id="A1.Ex5.m1.9.9.3.1.1.1.1.3.2.cmml" xref="A1.Ex5.m1.9.9.3.1.1.1.1.3"><csymbol cd="ambiguous" id="A1.Ex5.m1.9.9.3.1.1.1.1.3.2.1.cmml" xref="A1.Ex5.m1.9.9.3.1.1.1.1.3">subscript</csymbol><ci id="A1.Ex5.m1.9.9.3.1.1.1.1.3.2.2.cmml" xref="A1.Ex5.m1.9.9.3.1.1.1.1.3.2.2">𝑠</ci><list id="A1.Ex5.m1.4.4.2.3.cmml" xref="A1.Ex5.m1.4.4.2.4"><ci id="A1.Ex5.m1.3.3.1.1.cmml" xref="A1.Ex5.m1.3.3.1.1">𝑖</ci><ci id="A1.Ex5.m1.4.4.2.2.cmml" xref="A1.Ex5.m1.4.4.2.2">𝑗</ci></list></apply><ci id="A1.Ex5.m1.9.9.3.1.1.1.1.3.3.cmml" xref="A1.Ex5.m1.9.9.3.1.1.1.1.3.3">𝑏</ci></apply></apply><ci id="A1.Ex5.m1.9.9.3.1.3.cmml" xref="A1.Ex5.m1.9.9.3.1.3">𝑟</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex5.m1.9c">\operatorname{Pr}(d_{i},d_{j}|\operatorname{Jaccard}(d_{i},d_{j})=s_{i,j})=1-(1-s_{i,j}^{b})^{r}</annotation><annotation encoding="application/x-llamapun" id="A1.Ex5.m1.9d">roman_Pr ( italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT | roman_Jaccard ( italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) = italic_s start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ) = 1 - ( 1 - italic_s start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_b end_POSTSUPERSCRIPT ) start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="A1.p1.11" class="ltx_p">where <math id="A1.p1.6.m1.2" class="ltx_Math" alttext="s_{i,j}" display="inline"><semantics id="A1.p1.6.m1.2a"><msub id="A1.p1.6.m1.2.3" xref="A1.p1.6.m1.2.3.cmml"><mi id="A1.p1.6.m1.2.3.2" xref="A1.p1.6.m1.2.3.2.cmml">s</mi><mrow id="A1.p1.6.m1.2.2.2.4" xref="A1.p1.6.m1.2.2.2.3.cmml"><mi id="A1.p1.6.m1.1.1.1.1" xref="A1.p1.6.m1.1.1.1.1.cmml">i</mi><mo id="A1.p1.6.m1.2.2.2.4.1" xref="A1.p1.6.m1.2.2.2.3.cmml">,</mo><mi id="A1.p1.6.m1.2.2.2.2" xref="A1.p1.6.m1.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.p1.6.m1.2b"><apply id="A1.p1.6.m1.2.3.cmml" xref="A1.p1.6.m1.2.3"><csymbol cd="ambiguous" id="A1.p1.6.m1.2.3.1.cmml" xref="A1.p1.6.m1.2.3">subscript</csymbol><ci id="A1.p1.6.m1.2.3.2.cmml" xref="A1.p1.6.m1.2.3.2">𝑠</ci><list id="A1.p1.6.m1.2.2.2.3.cmml" xref="A1.p1.6.m1.2.2.2.4"><ci id="A1.p1.6.m1.1.1.1.1.cmml" xref="A1.p1.6.m1.1.1.1.1">𝑖</ci><ci id="A1.p1.6.m1.2.2.2.2.cmml" xref="A1.p1.6.m1.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.6.m1.2c">s_{i,j}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.6.m1.2d">italic_s start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math> is the Jaccard index between the two documents <math id="A1.p1.7.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="A1.p1.7.m2.1a"><mi id="A1.p1.7.m2.1.1" xref="A1.p1.7.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="A1.p1.7.m2.1b"><ci id="A1.p1.7.m2.1.1.cmml" xref="A1.p1.7.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.7.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="A1.p1.7.m2.1d">italic_i</annotation></semantics></math> and <math id="A1.p1.8.m3.1" class="ltx_Math" alttext="j" display="inline"><semantics id="A1.p1.8.m3.1a"><mi id="A1.p1.8.m3.1.1" xref="A1.p1.8.m3.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="A1.p1.8.m3.1b"><ci id="A1.p1.8.m3.1.1.cmml" xref="A1.p1.8.m3.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.8.m3.1c">j</annotation><annotation encoding="application/x-llamapun" id="A1.p1.8.m3.1d">italic_j</annotation></semantics></math>.
For document pairs that were identified as potential matches, we computed their actual Jaccard index, and if that was above 0.8, we computed their edit similarity.
Document pairs with edit similarity higher than 0.8 were identified as duplicates.
After some experimentation, we chose to use <math id="A1.p1.9.m4.1" class="ltx_Math" alttext="b=20" display="inline"><semantics id="A1.p1.9.m4.1a"><mrow id="A1.p1.9.m4.1.1" xref="A1.p1.9.m4.1.1.cmml"><mi id="A1.p1.9.m4.1.1.2" xref="A1.p1.9.m4.1.1.2.cmml">b</mi><mo id="A1.p1.9.m4.1.1.1" xref="A1.p1.9.m4.1.1.1.cmml">=</mo><mn id="A1.p1.9.m4.1.1.3" xref="A1.p1.9.m4.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.9.m4.1b"><apply id="A1.p1.9.m4.1.1.cmml" xref="A1.p1.9.m4.1.1"><eq id="A1.p1.9.m4.1.1.1.cmml" xref="A1.p1.9.m4.1.1.1"></eq><ci id="A1.p1.9.m4.1.1.2.cmml" xref="A1.p1.9.m4.1.1.2">𝑏</ci><cn type="integer" id="A1.p1.9.m4.1.1.3.cmml" xref="A1.p1.9.m4.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.9.m4.1c">b=20</annotation><annotation encoding="application/x-llamapun" id="A1.p1.9.m4.1d">italic_b = 20</annotation></semantics></math>, and <math id="A1.p1.10.m5.1" class="ltx_Math" alttext="r=450" display="inline"><semantics id="A1.p1.10.m5.1a"><mrow id="A1.p1.10.m5.1.1" xref="A1.p1.10.m5.1.1.cmml"><mi id="A1.p1.10.m5.1.1.2" xref="A1.p1.10.m5.1.1.2.cmml">r</mi><mo id="A1.p1.10.m5.1.1.1" xref="A1.p1.10.m5.1.1.1.cmml">=</mo><mn id="A1.p1.10.m5.1.1.3" xref="A1.p1.10.m5.1.1.3.cmml">450</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.10.m5.1b"><apply id="A1.p1.10.m5.1.1.cmml" xref="A1.p1.10.m5.1.1"><eq id="A1.p1.10.m5.1.1.1.cmml" xref="A1.p1.10.m5.1.1.1"></eq><ci id="A1.p1.10.m5.1.1.2.cmml" xref="A1.p1.10.m5.1.1.2">𝑟</ci><cn type="integer" id="A1.p1.10.m5.1.1.3.cmml" xref="A1.p1.10.m5.1.1.3">450</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.10.m5.1c">r=450</annotation><annotation encoding="application/x-llamapun" id="A1.p1.10.m5.1d">italic_r = 450</annotation></semantics></math>, so <math id="A1.p1.11.m6.2" class="ltx_Math" alttext="k=9,000" display="inline"><semantics id="A1.p1.11.m6.2a"><mrow id="A1.p1.11.m6.2.3" xref="A1.p1.11.m6.2.3.cmml"><mi id="A1.p1.11.m6.2.3.2" xref="A1.p1.11.m6.2.3.2.cmml">k</mi><mo id="A1.p1.11.m6.2.3.1" xref="A1.p1.11.m6.2.3.1.cmml">=</mo><mrow id="A1.p1.11.m6.2.3.3.2" xref="A1.p1.11.m6.2.3.3.1.cmml"><mn id="A1.p1.11.m6.1.1" xref="A1.p1.11.m6.1.1.cmml">9</mn><mo id="A1.p1.11.m6.2.3.3.2.1" xref="A1.p1.11.m6.2.3.3.1.cmml">,</mo><mn id="A1.p1.11.m6.2.2" xref="A1.p1.11.m6.2.2.cmml">000</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.11.m6.2b"><apply id="A1.p1.11.m6.2.3.cmml" xref="A1.p1.11.m6.2.3"><eq id="A1.p1.11.m6.2.3.1.cmml" xref="A1.p1.11.m6.2.3.1"></eq><ci id="A1.p1.11.m6.2.3.2.cmml" xref="A1.p1.11.m6.2.3.2">𝑘</ci><list id="A1.p1.11.m6.2.3.3.1.cmml" xref="A1.p1.11.m6.2.3.3.2"><cn type="integer" id="A1.p1.11.m6.1.1.cmml" xref="A1.p1.11.m6.1.1">9</cn><cn type="integer" id="A1.p1.11.m6.2.2.cmml" xref="A1.p1.11.m6.2.2">000</cn></list></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.11.m6.2c">k=9,000</annotation><annotation encoding="application/x-llamapun" id="A1.p1.11.m6.2d">italic_k = 9 , 000</annotation></semantics></math>, so as to make sure a collision at the desired Jaccard index threshold of 0.8 had a high probability of occurring.
</p>
</div>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.3" class="ltx_p">We also tested an alternative configuration—filtering to document pairs with Jaccard index of at least 0.9 and edit similarity of at least 0.9.
In this case, we used <math id="A1.p2.1.m1.1" class="ltx_Math" alttext="b=20" display="inline"><semantics id="A1.p2.1.m1.1a"><mrow id="A1.p2.1.m1.1.1" xref="A1.p2.1.m1.1.1.cmml"><mi id="A1.p2.1.m1.1.1.2" xref="A1.p2.1.m1.1.1.2.cmml">b</mi><mo id="A1.p2.1.m1.1.1.1" xref="A1.p2.1.m1.1.1.1.cmml">=</mo><mn id="A1.p2.1.m1.1.1.3" xref="A1.p2.1.m1.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p2.1.m1.1b"><apply id="A1.p2.1.m1.1.1.cmml" xref="A1.p2.1.m1.1.1"><eq id="A1.p2.1.m1.1.1.1.cmml" xref="A1.p2.1.m1.1.1.1"></eq><ci id="A1.p2.1.m1.1.1.2.cmml" xref="A1.p2.1.m1.1.1.2">𝑏</ci><cn type="integer" id="A1.p2.1.m1.1.1.3.cmml" xref="A1.p2.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.1.m1.1c">b=20</annotation><annotation encoding="application/x-llamapun" id="A1.p2.1.m1.1d">italic_b = 20</annotation></semantics></math>, <math id="A1.p2.2.m2.1" class="ltx_Math" alttext="r=40" display="inline"><semantics id="A1.p2.2.m2.1a"><mrow id="A1.p2.2.m2.1.1" xref="A1.p2.2.m2.1.1.cmml"><mi id="A1.p2.2.m2.1.1.2" xref="A1.p2.2.m2.1.1.2.cmml">r</mi><mo id="A1.p2.2.m2.1.1.1" xref="A1.p2.2.m2.1.1.1.cmml">=</mo><mn id="A1.p2.2.m2.1.1.3" xref="A1.p2.2.m2.1.1.3.cmml">40</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p2.2.m2.1b"><apply id="A1.p2.2.m2.1.1.cmml" xref="A1.p2.2.m2.1.1"><eq id="A1.p2.2.m2.1.1.1.cmml" xref="A1.p2.2.m2.1.1.1"></eq><ci id="A1.p2.2.m2.1.1.2.cmml" xref="A1.p2.2.m2.1.1.2">𝑟</ci><cn type="integer" id="A1.p2.2.m2.1.1.3.cmml" xref="A1.p2.2.m2.1.1.3">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.2.m2.1c">r=40</annotation><annotation encoding="application/x-llamapun" id="A1.p2.2.m2.1d">italic_r = 40</annotation></semantics></math>, and <math id="A1.p2.3.m3.1" class="ltx_Math" alttext="k=800" display="inline"><semantics id="A1.p2.3.m3.1a"><mrow id="A1.p2.3.m3.1.1" xref="A1.p2.3.m3.1.1.cmml"><mi id="A1.p2.3.m3.1.1.2" xref="A1.p2.3.m3.1.1.2.cmml">k</mi><mo id="A1.p2.3.m3.1.1.1" xref="A1.p2.3.m3.1.1.1.cmml">=</mo><mn id="A1.p2.3.m3.1.1.3" xref="A1.p2.3.m3.1.1.3.cmml">800</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p2.3.m3.1b"><apply id="A1.p2.3.m3.1.1.cmml" xref="A1.p2.3.m3.1.1"><eq id="A1.p2.3.m3.1.1.1.cmml" xref="A1.p2.3.m3.1.1.1"></eq><ci id="A1.p2.3.m3.1.1.2.cmml" xref="A1.p2.3.m3.1.1.2">𝑘</ci><cn type="integer" id="A1.p2.3.m3.1.1.3.cmml" xref="A1.p2.3.m3.1.1.3">800</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.3.m3.1c">k=800</annotation><annotation encoding="application/x-llamapun" id="A1.p2.3.m3.1d">italic_k = 800</annotation></semantics></math>.
Figure <a href="#A1.F4" title="Figure 4 ‣ Appendix A Further Details on NearDup ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the histogram of Jaccard similarities and edit similarities for all document pairs which collided in min-hash space, for our chosen configuration (blue) and for the alternative configuration (orange).
This allows us verify if the threshold chosen has few comparisons around the chosen threshold, then we’ve likely captured the majority of actual near duplicates above that threshold. To verify that yourself, look at the left hand tails of the distributions. Since both 0.8 and 0.9 begin to vanish at the same point (in spite of the fact that the two thresholds are optimized for accuracy around different thresholds), we feel comfortable saying that we’re capturing the majority of actual near duplicates.</p>
</div>
<figure id="A1.F4" class="ltx_figure">
<div class="ltx_flex_figure">

<div class="ltx_flex_cell 
                  ltx_flex_size_1"><img src="/html/2107.06499/assets/x4.png" id="A1.F4.g1" class="ltx_graphics ltx_centering ltx_flex_size_1 ltx_img_landscape" width="830" height="165" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell 
                  ltx_flex_size_1"><img src="/html/2107.06499/assets/x5.png" id="A1.F4.g2" class="ltx_graphics ltx_centering ltx_flex_size_1 ltx_img_landscape" width="830" height="165" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Histograms of document similarities.</figcaption>
</figure>
<section id="A1.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Computational Analysis</h5>

<div id="A1.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A1.SS0.SSS0.Px1.p1.3" class="ltx_p">Let <math id="A1.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="A1.SS0.SSS0.Px1.p1.1.m1.1a"><mi id="A1.SS0.SSS0.Px1.p1.1.m1.1.1" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="A1.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="A1.SS0.SSS0.Px1.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p1.1.m1.1d">italic_N</annotation></semantics></math> be the number of documents and <math id="A1.SS0.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="A1.SS0.SSS0.Px1.p1.2.m2.1a"><mi id="A1.SS0.SSS0.Px1.p1.2.m2.1.1" xref="A1.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p1.2.m2.1b"><ci id="A1.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="A1.SS0.SSS0.Px1.p1.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p1.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p1.2.m2.1d">italic_T</annotation></semantics></math> be the maximal number of tokens in a document. Edit similarity has a worst case complexity of <math id="A1.SS0.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="T^{2}" display="inline"><semantics id="A1.SS0.SSS0.Px1.p1.3.m3.1a"><msup id="A1.SS0.SSS0.Px1.p1.3.m3.1.1" xref="A1.SS0.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="A1.SS0.SSS0.Px1.p1.3.m3.1.1.2" xref="A1.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml">T</mi><mn id="A1.SS0.SSS0.Px1.p1.3.m3.1.1.3" xref="A1.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p1.3.m3.1b"><apply id="A1.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="A1.SS0.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A1.SS0.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="A1.SS0.SSS0.Px1.p1.3.m3.1.1">superscript</csymbol><ci id="A1.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="A1.SS0.SSS0.Px1.p1.3.m3.1.1.2">𝑇</ci><cn type="integer" id="A1.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="A1.SS0.SSS0.Px1.p1.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p1.3.m3.1c">T^{2}</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p1.3.m3.1d">italic_T start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math>, so the worst case complexity is</p>
</div>
<div id="A1.SS0.SSS0.Px1.p2" class="ltx_para">
<table id="A1.Ex6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A1.Ex6.m1.2" class="ltx_Math" alttext="O(N+bk^{2}T^{2}N)=O(N)" display="block"><semantics id="A1.Ex6.m1.2a"><mrow id="A1.Ex6.m1.2.2" xref="A1.Ex6.m1.2.2.cmml"><mrow id="A1.Ex6.m1.2.2.1" xref="A1.Ex6.m1.2.2.1.cmml"><mi id="A1.Ex6.m1.2.2.1.3" xref="A1.Ex6.m1.2.2.1.3.cmml">O</mi><mo id="A1.Ex6.m1.2.2.1.2" xref="A1.Ex6.m1.2.2.1.2.cmml" lspace="0px" rspace="0px"></mo><mrow id="A1.Ex6.m1.2.2.1.1.1" xref="A1.Ex6.m1.2.2.1.1.1.1.cmml"><mo stretchy="false" id="A1.Ex6.m1.2.2.1.1.1.2" xref="A1.Ex6.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="A1.Ex6.m1.2.2.1.1.1.1" xref="A1.Ex6.m1.2.2.1.1.1.1.cmml"><mi id="A1.Ex6.m1.2.2.1.1.1.1.2" xref="A1.Ex6.m1.2.2.1.1.1.1.2.cmml">N</mi><mo id="A1.Ex6.m1.2.2.1.1.1.1.1" xref="A1.Ex6.m1.2.2.1.1.1.1.1.cmml">+</mo><mrow id="A1.Ex6.m1.2.2.1.1.1.1.3" xref="A1.Ex6.m1.2.2.1.1.1.1.3.cmml"><mi id="A1.Ex6.m1.2.2.1.1.1.1.3.2" xref="A1.Ex6.m1.2.2.1.1.1.1.3.2.cmml">b</mi><mo id="A1.Ex6.m1.2.2.1.1.1.1.3.1" xref="A1.Ex6.m1.2.2.1.1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><msup id="A1.Ex6.m1.2.2.1.1.1.1.3.3" xref="A1.Ex6.m1.2.2.1.1.1.1.3.3.cmml"><mi id="A1.Ex6.m1.2.2.1.1.1.1.3.3.2" xref="A1.Ex6.m1.2.2.1.1.1.1.3.3.2.cmml">k</mi><mn id="A1.Ex6.m1.2.2.1.1.1.1.3.3.3" xref="A1.Ex6.m1.2.2.1.1.1.1.3.3.3.cmml">2</mn></msup><mo id="A1.Ex6.m1.2.2.1.1.1.1.3.1a" xref="A1.Ex6.m1.2.2.1.1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><msup id="A1.Ex6.m1.2.2.1.1.1.1.3.4" xref="A1.Ex6.m1.2.2.1.1.1.1.3.4.cmml"><mi id="A1.Ex6.m1.2.2.1.1.1.1.3.4.2" xref="A1.Ex6.m1.2.2.1.1.1.1.3.4.2.cmml">T</mi><mn id="A1.Ex6.m1.2.2.1.1.1.1.3.4.3" xref="A1.Ex6.m1.2.2.1.1.1.1.3.4.3.cmml">2</mn></msup><mo id="A1.Ex6.m1.2.2.1.1.1.1.3.1b" xref="A1.Ex6.m1.2.2.1.1.1.1.3.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A1.Ex6.m1.2.2.1.1.1.1.3.5" xref="A1.Ex6.m1.2.2.1.1.1.1.3.5.cmml">N</mi></mrow></mrow><mo stretchy="false" id="A1.Ex6.m1.2.2.1.1.1.3" xref="A1.Ex6.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A1.Ex6.m1.2.2.2" xref="A1.Ex6.m1.2.2.2.cmml">=</mo><mrow id="A1.Ex6.m1.2.2.3" xref="A1.Ex6.m1.2.2.3.cmml"><mi id="A1.Ex6.m1.2.2.3.2" xref="A1.Ex6.m1.2.2.3.2.cmml">O</mi><mo id="A1.Ex6.m1.2.2.3.1" xref="A1.Ex6.m1.2.2.3.1.cmml" lspace="0px" rspace="0px"></mo><mrow id="A1.Ex6.m1.2.2.3.3.2" xref="A1.Ex6.m1.2.2.3.cmml"><mo stretchy="false" id="A1.Ex6.m1.2.2.3.3.2.1" xref="A1.Ex6.m1.2.2.3.cmml">(</mo><mi id="A1.Ex6.m1.1.1" xref="A1.Ex6.m1.1.1.cmml">N</mi><mo stretchy="false" id="A1.Ex6.m1.2.2.3.3.2.2" xref="A1.Ex6.m1.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex6.m1.2b"><apply id="A1.Ex6.m1.2.2.cmml" xref="A1.Ex6.m1.2.2"><eq id="A1.Ex6.m1.2.2.2.cmml" xref="A1.Ex6.m1.2.2.2"></eq><apply id="A1.Ex6.m1.2.2.1.cmml" xref="A1.Ex6.m1.2.2.1"><times id="A1.Ex6.m1.2.2.1.2.cmml" xref="A1.Ex6.m1.2.2.1.2"></times><ci id="A1.Ex6.m1.2.2.1.3.cmml" xref="A1.Ex6.m1.2.2.1.3">𝑂</ci><apply id="A1.Ex6.m1.2.2.1.1.1.1.cmml" xref="A1.Ex6.m1.2.2.1.1.1"><plus id="A1.Ex6.m1.2.2.1.1.1.1.1.cmml" xref="A1.Ex6.m1.2.2.1.1.1.1.1"></plus><ci id="A1.Ex6.m1.2.2.1.1.1.1.2.cmml" xref="A1.Ex6.m1.2.2.1.1.1.1.2">𝑁</ci><apply id="A1.Ex6.m1.2.2.1.1.1.1.3.cmml" xref="A1.Ex6.m1.2.2.1.1.1.1.3"><times id="A1.Ex6.m1.2.2.1.1.1.1.3.1.cmml" xref="A1.Ex6.m1.2.2.1.1.1.1.3.1"></times><ci id="A1.Ex6.m1.2.2.1.1.1.1.3.2.cmml" xref="A1.Ex6.m1.2.2.1.1.1.1.3.2">𝑏</ci><apply id="A1.Ex6.m1.2.2.1.1.1.1.3.3.cmml" xref="A1.Ex6.m1.2.2.1.1.1.1.3.3"><csymbol cd="ambiguous" id="A1.Ex6.m1.2.2.1.1.1.1.3.3.1.cmml" xref="A1.Ex6.m1.2.2.1.1.1.1.3.3">superscript</csymbol><ci id="A1.Ex6.m1.2.2.1.1.1.1.3.3.2.cmml" xref="A1.Ex6.m1.2.2.1.1.1.1.3.3.2">𝑘</ci><cn type="integer" id="A1.Ex6.m1.2.2.1.1.1.1.3.3.3.cmml" xref="A1.Ex6.m1.2.2.1.1.1.1.3.3.3">2</cn></apply><apply id="A1.Ex6.m1.2.2.1.1.1.1.3.4.cmml" xref="A1.Ex6.m1.2.2.1.1.1.1.3.4"><csymbol cd="ambiguous" id="A1.Ex6.m1.2.2.1.1.1.1.3.4.1.cmml" xref="A1.Ex6.m1.2.2.1.1.1.1.3.4">superscript</csymbol><ci id="A1.Ex6.m1.2.2.1.1.1.1.3.4.2.cmml" xref="A1.Ex6.m1.2.2.1.1.1.1.3.4.2">𝑇</ci><cn type="integer" id="A1.Ex6.m1.2.2.1.1.1.1.3.4.3.cmml" xref="A1.Ex6.m1.2.2.1.1.1.1.3.4.3">2</cn></apply><ci id="A1.Ex6.m1.2.2.1.1.1.1.3.5.cmml" xref="A1.Ex6.m1.2.2.1.1.1.1.3.5">𝑁</ci></apply></apply></apply><apply id="A1.Ex6.m1.2.2.3.cmml" xref="A1.Ex6.m1.2.2.3"><times id="A1.Ex6.m1.2.2.3.1.cmml" xref="A1.Ex6.m1.2.2.3.1"></times><ci id="A1.Ex6.m1.2.2.3.2.cmml" xref="A1.Ex6.m1.2.2.3.2">𝑂</ci><ci id="A1.Ex6.m1.1.1.cmml" xref="A1.Ex6.m1.1.1">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex6.m1.2c">O(N+bk^{2}T^{2}N)=O(N)</annotation><annotation encoding="application/x-llamapun" id="A1.Ex6.m1.2d">italic_O ( italic_N + italic_b italic_k start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_T start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT italic_N ) = italic_O ( italic_N )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="A1.SS0.SSS0.Px1.p3" class="ltx_para ltx_noindent">
<p id="A1.SS0.SSS0.Px1.p3.6" class="ltx_p">since <math id="A1.SS0.SSS0.Px1.p3.1.m1.1" class="ltx_Math" alttext="b" display="inline"><semantics id="A1.SS0.SSS0.Px1.p3.1.m1.1a"><mi id="A1.SS0.SSS0.Px1.p3.1.m1.1.1" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p3.1.m1.1b"><ci id="A1.SS0.SSS0.Px1.p3.1.m1.1.1.cmml" xref="A1.SS0.SSS0.Px1.p3.1.m1.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p3.1.m1.1c">b</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p3.1.m1.1d">italic_b</annotation></semantics></math>, <math id="A1.SS0.SSS0.Px1.p3.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A1.SS0.SSS0.Px1.p3.2.m2.1a"><mi id="A1.SS0.SSS0.Px1.p3.2.m2.1.1" xref="A1.SS0.SSS0.Px1.p3.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p3.2.m2.1b"><ci id="A1.SS0.SSS0.Px1.p3.2.m2.1.1.cmml" xref="A1.SS0.SSS0.Px1.p3.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p3.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p3.2.m2.1d">italic_k</annotation></semantics></math>, and <math id="A1.SS0.SSS0.Px1.p3.3.m3.1" class="ltx_Math" alttext="T" display="inline"><semantics id="A1.SS0.SSS0.Px1.p3.3.m3.1a"><mi id="A1.SS0.SSS0.Px1.p3.3.m3.1.1" xref="A1.SS0.SSS0.Px1.p3.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p3.3.m3.1b"><ci id="A1.SS0.SSS0.Px1.p3.3.m3.1.1.cmml" xref="A1.SS0.SSS0.Px1.p3.3.m3.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p3.3.m3.1c">T</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p3.3.m3.1d">italic_T</annotation></semantics></math> are all <math id="A1.SS0.SSS0.Px1.p3.4.m4.1" class="ltx_Math" alttext="\ll" display="inline"><semantics id="A1.SS0.SSS0.Px1.p3.4.m4.1a"><mo id="A1.SS0.SSS0.Px1.p3.4.m4.1.1" xref="A1.SS0.SSS0.Px1.p3.4.m4.1.1.cmml">≪</mo><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p3.4.m4.1b"><csymbol cd="latexml" id="A1.SS0.SSS0.Px1.p3.4.m4.1.1.cmml" xref="A1.SS0.SSS0.Px1.p3.4.m4.1.1">much-less-than</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p3.4.m4.1c">\ll</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p3.4.m4.1d">≪</annotation></semantics></math> <math id="A1.SS0.SSS0.Px1.p3.5.m5.1" class="ltx_Math" alttext="N" display="inline"><semantics id="A1.SS0.SSS0.Px1.p3.5.m5.1a"><mi id="A1.SS0.SSS0.Px1.p3.5.m5.1.1" xref="A1.SS0.SSS0.Px1.p3.5.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p3.5.m5.1b"><ci id="A1.SS0.SSS0.Px1.p3.5.m5.1.1.cmml" xref="A1.SS0.SSS0.Px1.p3.5.m5.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p3.5.m5.1c">N</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p3.5.m5.1d">italic_N</annotation></semantics></math>. The left term is the complexity of grouping by the signatures, and the right represents the pathological worst case of all documents falling into the same <math id="A1.SS0.SSS0.Px1.p3.6.m6.1" class="ltx_Math" alttext="B" display="inline"><semantics id="A1.SS0.SSS0.Px1.p3.6.m6.1a"><mi id="A1.SS0.SSS0.Px1.p3.6.m6.1.1" xref="A1.SS0.SSS0.Px1.p3.6.m6.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p3.6.m6.1b"><ci id="A1.SS0.SSS0.Px1.p3.6.m6.1.1.cmml" xref="A1.SS0.SSS0.Px1.p3.6.m6.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p3.6.m6.1c">B</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p3.6.m6.1d">italic_B</annotation></semantics></math> buckets.</p>
</div>
<div id="A1.SS0.SSS0.Px1.p4" class="ltx_para">
<p id="A1.SS0.SSS0.Px1.p4.2" class="ltx_p">The highly distributed <span id="A1.SS0.SSS0.Px1.p4.2.1" class="ltx_text ltx_font_smallcaps">NearDup</span> implementation we employed is one used for large-scale production tasks at Google.
On the English C4 dataset, the algorithm consumed approximately 41.5 kWh of energy.
Note that our choices of <math id="A1.SS0.SSS0.Px1.p4.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A1.SS0.SSS0.Px1.p4.1.m1.1a"><mi id="A1.SS0.SSS0.Px1.p4.1.m1.1.1" xref="A1.SS0.SSS0.Px1.p4.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p4.1.m1.1b"><ci id="A1.SS0.SSS0.Px1.p4.1.m1.1.1.cmml" xref="A1.SS0.SSS0.Px1.p4.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p4.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p4.1.m1.1d">italic_k</annotation></semantics></math> and <math id="A1.SS0.SSS0.Px1.p4.2.m2.1" class="ltx_Math" alttext="b" display="inline"><semantics id="A1.SS0.SSS0.Px1.p4.2.m2.1a"><mi id="A1.SS0.SSS0.Px1.p4.2.m2.1.1" xref="A1.SS0.SSS0.Px1.p4.2.m2.1.1.cmml">b</mi><annotation-xml encoding="MathML-Content" id="A1.SS0.SSS0.Px1.p4.2.m2.1b"><ci id="A1.SS0.SSS0.Px1.p4.2.m2.1.1.cmml" xref="A1.SS0.SSS0.Px1.p4.2.m2.1.1">𝑏</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS0.SSS0.Px1.p4.2.m2.1c">b</annotation><annotation encoding="application/x-llamapun" id="A1.SS0.SSS0.Px1.p4.2.m2.1d">italic_b</annotation></semantics></math> were designed to produce very high recall, and with different parameters, the algorithm could be made much more energy efficient while producing similar results.</p>
</div>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Further Details on <span id="A2.1.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span>
</h2>

<section id="A2.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Parallel linear time construction.</h5>

<div id="A2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A2.SS0.SSS0.Px1.p1.1" class="ltx_p">We build a parallelized linear time suffix array algorithm.
As a building block, we make black-box use of the SA-IS algorithm for
constructing a suffix array in linear time <cite class="ltx_cite ltx_citemacro_citet">Nong et&nbsp;al. (<a href="#bib.bib29" title="" class="ltx_ref">2009</a>); Ko and Aluru (<a href="#bib.bib27" title="" class="ltx_ref">2003</a>)</cite>.
Unfortunately, this algorithm is not easily parallelized directly, so
we introduce a simple divide and conquer approach to parallelizing the array construction.</p>
</div>
<div id="A2.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="A2.SS0.SSS0.Px1.p2.1" class="ltx_p">We build our implementation in Rust and extend an existing suffix array library<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>https://github.com/BurntSushi/suffix</span></span></span>
with three modification.
The first two are straightforward implementation differences:
we modify the code to allow datasets larger than <math id="A2.SS0.SSS0.Px1.p2.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="A2.SS0.SSS0.Px1.p2.1.m1.1a"><mn id="A2.SS0.SSS0.Px1.p2.1.m1.1.1" xref="A2.SS0.SSS0.Px1.p2.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px1.p2.1.m1.1b"><cn type="integer" id="A2.SS0.SSS0.Px1.p2.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px1.p2.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px1.p2.1.m1.1c">4</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px1.p2.1.m1.1d">4</annotation></semantics></math>GB,
and we remove the requirement that strings parse as valid UTF-8 sequences in favor of raw byte sequences.
Our third change is more significant: we re-implement the algorithm
so that we can stream the suffix array itself off disk.</p>
</div>
</section>
<section id="A2.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Parallel partial suffix array construction.</h5>

<div id="A2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="A2.SS0.SSS0.Px2.p1.5" class="ltx_p">Our divide and conquer suffix array construction algorithm starts by
partitioning the dataset into <math id="A2.SS0.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A2.SS0.SSS0.Px2.p1.1.m1.1a"><mi id="A2.SS0.SSS0.Px2.p1.1.m1.1.1" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.1.m1.1b"><ci id="A2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.1.m1.1d">italic_K</annotation></semantics></math> different “splits” with SA-IS run
over independently on each split in parallel.
This algorithm still requires <math id="A2.SS0.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="O(N)" display="inline"><semantics id="A2.SS0.SSS0.Px2.p1.2.m2.1a"><mrow id="A2.SS0.SSS0.Px2.p1.2.m2.1.2" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.2.cmml"><mi id="A2.SS0.SSS0.Px2.p1.2.m2.1.2.2" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.2.2.cmml">O</mi><mo id="A2.SS0.SSS0.Px2.p1.2.m2.1.2.1" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.2.1.cmml" lspace="0px" rspace="0px"></mo><mrow id="A2.SS0.SSS0.Px2.p1.2.m2.1.2.3.2" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.2.cmml"><mo stretchy="false" id="A2.SS0.SSS0.Px2.p1.2.m2.1.2.3.2.1" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.2.cmml">(</mo><mi id="A2.SS0.SSS0.Px2.p1.2.m2.1.1" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">N</mi><mo stretchy="false" id="A2.SS0.SSS0.Px2.p1.2.m2.1.2.3.2.2" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.2.m2.1b"><apply id="A2.SS0.SSS0.Px2.p1.2.m2.1.2.cmml" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.2"><times id="A2.SS0.SSS0.Px2.p1.2.m2.1.2.1.cmml" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.2.1"></times><ci id="A2.SS0.SSS0.Px2.p1.2.m2.1.2.2.cmml" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.2.2">𝑂</ci><ci id="A2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.2.m2.1.1">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.2.m2.1c">O(N)</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.2.m2.1d">italic_O ( italic_N )</annotation></semantics></math> work but runs in <math id="A2.SS0.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="O(N/K)" display="inline"><semantics id="A2.SS0.SSS0.Px2.p1.3.m3.1a"><mrow id="A2.SS0.SSS0.Px2.p1.3.m3.1.1" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.3" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml">O</mi><mo id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.2" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml" lspace="0px" rspace="0px"></mo><mrow id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.2" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.cmml">N</mi><mo id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.cmml">/</mo><mi id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3.cmml">K</mi></mrow><mo stretchy="false" id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.3" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.3.m3.1b"><apply id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1"><times id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.2"></times><ci id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.3">𝑂</ci><apply id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1"><divide id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1"></divide><ci id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2">𝑁</ci><ci id="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.3.m3.1c">O(N/K)</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.3.m3.1d">italic_O ( italic_N / italic_K )</annotation></semantics></math> wall-clock time.
This gives us <math id="A2.SS0.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="N" display="inline"><semantics id="A2.SS0.SSS0.Px2.p1.4.m4.1a"><mi id="A2.SS0.SSS0.Px2.p1.4.m4.1.1" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.4.m4.1b"><ci id="A2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.4.m4.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.4.m4.1c">N</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.4.m4.1d">italic_N</annotation></semantics></math> separate suffix arrays <math id="A2.SS0.SSS0.Px2.p1.5.m5.1" class="ltx_Math" alttext="\mathcal{A}^{i}" display="inline"><semantics id="A2.SS0.SSS0.Px2.p1.5.m5.1a"><msup id="A2.SS0.SSS0.Px2.p1.5.m5.1.1" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.cmml">𝒜</mi><mi id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.3" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p1.5.m5.1b"><apply id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1">superscript</csymbol><ci id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.2">𝒜</ci><ci id="A2.SS0.SSS0.Px2.p1.5.m5.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p1.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p1.5.m5.1c">\mathcal{A}^{i}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p1.5.m5.1d">caligraphic_A start_POSTSUPERSCRIPT italic_i end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
<div id="A2.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="A2.SS0.SSS0.Px2.p2.12" class="ltx_p">Given two suffix arrays <math id="A2.SS0.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="A_{1}" display="inline"><semantics id="A2.SS0.SSS0.Px2.p2.1.m1.1a"><msub id="A2.SS0.SSS0.Px2.p2.1.m1.1.1" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.2" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml">A</mi><mn id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.1.m1.1b"><apply id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.2">𝐴</ci><cn type="integer" id="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p2.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.1.m1.1c">A_{1}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.1.m1.1d">italic_A start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> and <math id="A2.SS0.SSS0.Px2.p2.2.m2.1" class="ltx_Math" alttext="A_{2}" display="inline"><semantics id="A2.SS0.SSS0.Px2.p2.2.m2.1a"><msub id="A2.SS0.SSS0.Px2.p2.2.m2.1.1" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.2" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml">A</mi><mn id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.3" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.2.m2.1b"><apply id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.2">𝐴</ci><cn type="integer" id="A2.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p2.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.2.m2.1c">A_{2}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.2.m2.1d">italic_A start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> for two sequences <math id="A2.SS0.SSS0.Px2.p2.3.m3.1" class="ltx_Math" alttext="S_{1}" display="inline"><semantics id="A2.SS0.SSS0.Px2.p2.3.m3.1a"><msub id="A2.SS0.SSS0.Px2.p2.3.m3.1.1" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.2" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.2.cmml">S</mi><mn id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.3" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.3.m3.1b"><apply id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.2">𝑆</ci><cn type="integer" id="A2.SS0.SSS0.Px2.p2.3.m3.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p2.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.3.m3.1c">S_{1}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.3.m3.1d">italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> and <math id="A2.SS0.SSS0.Px2.p2.4.m4.1" class="ltx_Math" alttext="S_{2}" display="inline"><semantics id="A2.SS0.SSS0.Px2.p2.4.m4.1a"><msub id="A2.SS0.SSS0.Px2.p2.4.m4.1.1" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.2" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.2.cmml">S</mi><mn id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.3" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.4.m4.1b"><apply id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.2">𝑆</ci><cn type="integer" id="A2.SS0.SSS0.Px2.p2.4.m4.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p2.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.4.m4.1c">S_{2}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.4.m4.1d">italic_S start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> it’s not completely trivial to construct a single suffix array <math id="A2.SS0.SSS0.Px2.p2.5.m5.1" class="ltx_Math" alttext="A" display="inline"><semantics id="A2.SS0.SSS0.Px2.p2.5.m5.1a"><mi id="A2.SS0.SSS0.Px2.p2.5.m5.1.1" xref="A2.SS0.SSS0.Px2.p2.5.m5.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.5.m5.1b"><ci id="A2.SS0.SSS0.Px2.p2.5.m5.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.5.m5.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.5.m5.1c">A</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.5.m5.1d">italic_A</annotation></semantics></math> for <math id="A2.SS0.SSS0.Px2.p2.6.m6.1" class="ltx_math_unparsed" alttext="S=S_{1}\mid\mid S_{2}" display="inline"><semantics id="A2.SS0.SSS0.Px2.p2.6.m6.1a"><mrow id="A2.SS0.SSS0.Px2.p2.6.m6.1b"><mi id="A2.SS0.SSS0.Px2.p2.6.m6.1.1">S</mi><mo id="A2.SS0.SSS0.Px2.p2.6.m6.1.2">=</mo><msub id="A2.SS0.SSS0.Px2.p2.6.m6.1.3"><mi id="A2.SS0.SSS0.Px2.p2.6.m6.1.3.2">S</mi><mn id="A2.SS0.SSS0.Px2.p2.6.m6.1.3.3">1</mn></msub><mo lspace="0em" rspace="0.0835em" id="A2.SS0.SSS0.Px2.p2.6.m6.1.4">∣</mo><mo lspace="0.0835em" rspace="0.167em" id="A2.SS0.SSS0.Px2.p2.6.m6.1.5">∣</mo><msub id="A2.SS0.SSS0.Px2.p2.6.m6.1.6"><mi id="A2.SS0.SSS0.Px2.p2.6.m6.1.6.2">S</mi><mn id="A2.SS0.SSS0.Px2.p2.6.m6.1.6.3">2</mn></msub></mrow><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.6.m6.1c">S=S_{1}\mid\mid S_{2}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.6.m6.1d">italic_S = italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∣ ∣ italic_S start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>
because of the boundary conditions.
Instead, we don’t build the data <math id="A2.SS0.SSS0.Px2.p2.7.m7.1" class="ltx_math_unparsed" alttext="S=S_{1}\mid\mid S_{2}" display="inline"><semantics id="A2.SS0.SSS0.Px2.p2.7.m7.1a"><mrow id="A2.SS0.SSS0.Px2.p2.7.m7.1b"><mi id="A2.SS0.SSS0.Px2.p2.7.m7.1.1">S</mi><mo id="A2.SS0.SSS0.Px2.p2.7.m7.1.2">=</mo><msub id="A2.SS0.SSS0.Px2.p2.7.m7.1.3"><mi id="A2.SS0.SSS0.Px2.p2.7.m7.1.3.2">S</mi><mn id="A2.SS0.SSS0.Px2.p2.7.m7.1.3.3">1</mn></msub><mo lspace="0em" rspace="0.0835em" id="A2.SS0.SSS0.Px2.p2.7.m7.1.4">∣</mo><mo lspace="0.0835em" rspace="0.167em" id="A2.SS0.SSS0.Px2.p2.7.m7.1.5">∣</mo><msub id="A2.SS0.SSS0.Px2.p2.7.m7.1.6"><mi id="A2.SS0.SSS0.Px2.p2.7.m7.1.6.2">S</mi><mn id="A2.SS0.SSS0.Px2.p2.7.m7.1.6.3">2</mn></msub></mrow><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.7.m7.1c">S=S_{1}\mid\mid S_{2}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.7.m7.1d">italic_S = italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∣ ∣ italic_S start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math> but rather let <math id="A2.SS0.SSS0.Px2.p2.8.m8.1" class="ltx_math_unparsed" alttext="S_{1}^{\prime}=S_{1}\mid\mid S_{2}[uptoK]" display="inline"><semantics id="A2.SS0.SSS0.Px2.p2.8.m8.1a"><mrow id="A2.SS0.SSS0.Px2.p2.8.m8.1b"><msubsup id="A2.SS0.SSS0.Px2.p2.8.m8.1.1"><mi id="A2.SS0.SSS0.Px2.p2.8.m8.1.1.2.2">S</mi><mn id="A2.SS0.SSS0.Px2.p2.8.m8.1.1.2.3">1</mn><mo id="A2.SS0.SSS0.Px2.p2.8.m8.1.1.3">′</mo></msubsup><mo id="A2.SS0.SSS0.Px2.p2.8.m8.1.2">=</mo><msub id="A2.SS0.SSS0.Px2.p2.8.m8.1.3"><mi id="A2.SS0.SSS0.Px2.p2.8.m8.1.3.2">S</mi><mn id="A2.SS0.SSS0.Px2.p2.8.m8.1.3.3">1</mn></msub><mo lspace="0em" rspace="0.0835em" id="A2.SS0.SSS0.Px2.p2.8.m8.1.4">∣</mo><mo lspace="0.0835em" rspace="0.167em" id="A2.SS0.SSS0.Px2.p2.8.m8.1.5">∣</mo><msub id="A2.SS0.SSS0.Px2.p2.8.m8.1.6"><mi id="A2.SS0.SSS0.Px2.p2.8.m8.1.6.2">S</mi><mn id="A2.SS0.SSS0.Px2.p2.8.m8.1.6.3">2</mn></msub><mrow id="A2.SS0.SSS0.Px2.p2.8.m8.1.7"><mo stretchy="false" id="A2.SS0.SSS0.Px2.p2.8.m8.1.7.1">[</mo><mi id="A2.SS0.SSS0.Px2.p2.8.m8.1.7.2">u</mi><mi id="A2.SS0.SSS0.Px2.p2.8.m8.1.7.3">p</mi><mi id="A2.SS0.SSS0.Px2.p2.8.m8.1.7.4">t</mi><mi id="A2.SS0.SSS0.Px2.p2.8.m8.1.7.5">o</mi><mi id="A2.SS0.SSS0.Px2.p2.8.m8.1.7.6">K</mi><mo stretchy="false" id="A2.SS0.SSS0.Px2.p2.8.m8.1.7.7">]</mo></mrow></mrow><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.8.m8.1c">S_{1}^{\prime}=S_{1}\mid\mid S_{2}[uptoK]</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.8.m8.1d">italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ∣ ∣ italic_S start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT [ italic_u italic_p italic_t italic_o italic_K ]</annotation></semantics></math> for some <math id="A2.SS0.SSS0.Px2.p2.9.m9.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A2.SS0.SSS0.Px2.p2.9.m9.1a"><mi id="A2.SS0.SSS0.Px2.p2.9.m9.1.1" xref="A2.SS0.SSS0.Px2.p2.9.m9.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.9.m9.1b"><ci id="A2.SS0.SSS0.Px2.p2.9.m9.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.9.m9.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.9.m9.1c">K</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.9.m9.1d">italic_K</annotation></semantics></math> greater than the longest substring match.
Then we build the arrays on <math id="A2.SS0.SSS0.Px2.p2.10.m10.1" class="ltx_Math" alttext="S^{\prime}_{1}" display="inline"><semantics id="A2.SS0.SSS0.Px2.p2.10.m10.1a"><msubsup id="A2.SS0.SSS0.Px2.p2.10.m10.1.1" xref="A2.SS0.SSS0.Px2.p2.10.m10.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p2.10.m10.1.1.2.2" xref="A2.SS0.SSS0.Px2.p2.10.m10.1.1.2.2.cmml">S</mi><mn id="A2.SS0.SSS0.Px2.p2.10.m10.1.1.3" xref="A2.SS0.SSS0.Px2.p2.10.m10.1.1.3.cmml">1</mn><mo id="A2.SS0.SSS0.Px2.p2.10.m10.1.1.2.3" xref="A2.SS0.SSS0.Px2.p2.10.m10.1.1.2.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.10.m10.1b"><apply id="A2.SS0.SSS0.Px2.p2.10.m10.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.10.m10.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p2.10.m10.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.10.m10.1.1">subscript</csymbol><apply id="A2.SS0.SSS0.Px2.p2.10.m10.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p2.10.m10.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p2.10.m10.1.1.2.1.cmml" xref="A2.SS0.SSS0.Px2.p2.10.m10.1.1">superscript</csymbol><ci id="A2.SS0.SSS0.Px2.p2.10.m10.1.1.2.2.cmml" xref="A2.SS0.SSS0.Px2.p2.10.m10.1.1.2.2">𝑆</ci><ci id="A2.SS0.SSS0.Px2.p2.10.m10.1.1.2.3.cmml" xref="A2.SS0.SSS0.Px2.p2.10.m10.1.1.2.3">′</ci></apply><cn type="integer" id="A2.SS0.SSS0.Px2.p2.10.m10.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p2.10.m10.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.10.m10.1c">S^{\prime}_{1}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.10.m10.1d">italic_S start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> and <math id="A2.SS0.SSS0.Px2.p2.11.m11.1" class="ltx_Math" alttext="S_{2}" display="inline"><semantics id="A2.SS0.SSS0.Px2.p2.11.m11.1a"><msub id="A2.SS0.SSS0.Px2.p2.11.m11.1.1" xref="A2.SS0.SSS0.Px2.p2.11.m11.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p2.11.m11.1.1.2" xref="A2.SS0.SSS0.Px2.p2.11.m11.1.1.2.cmml">S</mi><mn id="A2.SS0.SSS0.Px2.p2.11.m11.1.1.3" xref="A2.SS0.SSS0.Px2.p2.11.m11.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.11.m11.1b"><apply id="A2.SS0.SSS0.Px2.p2.11.m11.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.11.m11.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p2.11.m11.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.11.m11.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px2.p2.11.m11.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p2.11.m11.1.1.2">𝑆</ci><cn type="integer" id="A2.SS0.SSS0.Px2.p2.11.m11.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p2.11.m11.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.11.m11.1c">S_{2}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.11.m11.1d">italic_S start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>.
To merge the arrays together we can remove the items from the first array after index <math id="A2.SS0.SSS0.Px2.p2.12.m12.1" class="ltx_Math" alttext="|S_{1}|" display="inline"><semantics id="A2.SS0.SSS0.Px2.p2.12.m12.1a"><mrow id="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1" xref="A2.SS0.SSS0.Px2.p2.12.m12.1.1.2.cmml"><mo stretchy="false" id="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.2" xref="A2.SS0.SSS0.Px2.p2.12.m12.1.1.2.1.cmml">|</mo><msub id="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.1" xref="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.1.cmml"><mi id="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.1.2" xref="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.1.2.cmml">S</mi><mn id="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.1.3" xref="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.1.3.cmml">1</mn></msub><mo stretchy="false" id="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.3" xref="A2.SS0.SSS0.Px2.p2.12.m12.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px2.p2.12.m12.1b"><apply id="A2.SS0.SSS0.Px2.p2.12.m12.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1"><abs id="A2.SS0.SSS0.Px2.p2.12.m12.1.1.2.1.cmml" xref="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.2"></abs><apply id="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.1.1.cmml" xref="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.1.2.cmml" xref="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.1.2">𝑆</ci><cn type="integer" id="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.1.3.cmml" xref="A2.SS0.SSS0.Px2.p2.12.m12.1.1.1.1.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px2.p2.12.m12.1c">|S_{1}|</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px2.p2.12.m12.1d">| italic_S start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT |</annotation></semantics></math> and merge-sort insert them into the second.</p>
</div>
</section>
<section id="A2.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Parallel merge of partial suffix arrays.</h5>

<div id="A2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="A2.SS0.SSS0.Px3.p1.15" class="ltx_p">We now merge these separate arrays together into a single suffix array <math id="A2.SS0.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="A2.SS0.SSS0.Px3.p1.1.m1.1.1" xref="A2.SS0.SSS0.Px3.p1.1.m1.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.1.m1.1b"><ci id="A2.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.1.m1.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.1.m1.1c">\mathcal{A}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.1.m1.1d">caligraphic_A</annotation></semantics></math>,
Consider the simpler case of two partial suffix arrays <math id="A2.SS0.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="B" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.2.m2.1a"><mi id="A2.SS0.SSS0.Px3.p1.2.m2.1.1" xref="A2.SS0.SSS0.Px3.p1.2.m2.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.2.m2.1b"><ci id="A2.SS0.SSS0.Px3.p1.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.2.m2.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.2.m2.1c">B</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.2.m2.1d">italic_B</annotation></semantics></math> and <math id="A2.SS0.SSS0.Px3.p1.3.m3.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.3.m3.1a"><mi id="A2.SS0.SSS0.Px3.p1.3.m3.1.1" xref="A2.SS0.SSS0.Px3.p1.3.m3.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.3.m3.1b"><ci id="A2.SS0.SSS0.Px3.p1.3.m3.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.3.m3.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.3.m3.1c">C</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.3.m3.1d">italic_C</annotation></semantics></math> that we
would like to merge together.
We can achieve this by letting <math id="A2.SS0.SSS0.Px3.p1.4.m4.1" class="ltx_Math" alttext="i=0" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.4.m4.1a"><mrow id="A2.SS0.SSS0.Px3.p1.4.m4.1.1" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p1.4.m4.1.1.2" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1.2.cmml">i</mi><mo id="A2.SS0.SSS0.Px3.p1.4.m4.1.1.1" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1.1.cmml">=</mo><mn id="A2.SS0.SSS0.Px3.p1.4.m4.1.1.3" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.4.m4.1b"><apply id="A2.SS0.SSS0.Px3.p1.4.m4.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1"><eq id="A2.SS0.SSS0.Px3.p1.4.m4.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1.1"></eq><ci id="A2.SS0.SSS0.Px3.p1.4.m4.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1.2">𝑖</ci><cn type="integer" id="A2.SS0.SSS0.Px3.p1.4.m4.1.1.3.cmml" xref="A2.SS0.SSS0.Px3.p1.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.4.m4.1c">i=0</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.4.m4.1d">italic_i = 0</annotation></semantics></math> index <math id="A2.SS0.SSS0.Px3.p1.5.m5.1" class="ltx_Math" alttext="B" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.5.m5.1a"><mi id="A2.SS0.SSS0.Px3.p1.5.m5.1.1" xref="A2.SS0.SSS0.Px3.p1.5.m5.1.1.cmml">B</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.5.m5.1b"><ci id="A2.SS0.SSS0.Px3.p1.5.m5.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.5.m5.1.1">𝐵</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.5.m5.1c">B</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.5.m5.1d">italic_B</annotation></semantics></math> and <math id="A2.SS0.SSS0.Px3.p1.6.m6.1" class="ltx_Math" alttext="j=0" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.6.m6.1a"><mrow id="A2.SS0.SSS0.Px3.p1.6.m6.1.1" xref="A2.SS0.SSS0.Px3.p1.6.m6.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p1.6.m6.1.1.2" xref="A2.SS0.SSS0.Px3.p1.6.m6.1.1.2.cmml">j</mi><mo id="A2.SS0.SSS0.Px3.p1.6.m6.1.1.1" xref="A2.SS0.SSS0.Px3.p1.6.m6.1.1.1.cmml">=</mo><mn id="A2.SS0.SSS0.Px3.p1.6.m6.1.1.3" xref="A2.SS0.SSS0.Px3.p1.6.m6.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.6.m6.1b"><apply id="A2.SS0.SSS0.Px3.p1.6.m6.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.6.m6.1.1"><eq id="A2.SS0.SSS0.Px3.p1.6.m6.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.6.m6.1.1.1"></eq><ci id="A2.SS0.SSS0.Px3.p1.6.m6.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p1.6.m6.1.1.2">𝑗</ci><cn type="integer" id="A2.SS0.SSS0.Px3.p1.6.m6.1.1.3.cmml" xref="A2.SS0.SSS0.Px3.p1.6.m6.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.6.m6.1c">j=0</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.6.m6.1d">italic_j = 0</annotation></semantics></math> index <math id="A2.SS0.SSS0.Px3.p1.7.m7.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.7.m7.1a"><mi id="A2.SS0.SSS0.Px3.p1.7.m7.1.1" xref="A2.SS0.SSS0.Px3.p1.7.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.7.m7.1b"><ci id="A2.SS0.SSS0.Px3.p1.7.m7.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.7.m7.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.7.m7.1c">C</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.7.m7.1d">italic_C</annotation></semantics></math>.
Each iteration of the algorithm then pushes <math id="A2.SS0.SSS0.Px3.p1.8.m8.1" class="ltx_Math" alttext="B_{i}" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.8.m8.1a"><msub id="A2.SS0.SSS0.Px3.p1.8.m8.1.1" xref="A2.SS0.SSS0.Px3.p1.8.m8.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p1.8.m8.1.1.2" xref="A2.SS0.SSS0.Px3.p1.8.m8.1.1.2.cmml">B</mi><mi id="A2.SS0.SSS0.Px3.p1.8.m8.1.1.3" xref="A2.SS0.SSS0.Px3.p1.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.8.m8.1b"><apply id="A2.SS0.SSS0.Px3.p1.8.m8.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.8.m8.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p1.8.m8.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.8.m8.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p1.8.m8.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p1.8.m8.1.1.2">𝐵</ci><ci id="A2.SS0.SSS0.Px3.p1.8.m8.1.1.3.cmml" xref="A2.SS0.SSS0.Px3.p1.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.8.m8.1c">B_{i}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.8.m8.1d">italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> into <math id="A2.SS0.SSS0.Px3.p1.9.m9.1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.9.m9.1a"><mi class="ltx_font_mathcaligraphic" id="A2.SS0.SSS0.Px3.p1.9.m9.1.1" xref="A2.SS0.SSS0.Px3.p1.9.m9.1.1.cmml">𝒜</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.9.m9.1b"><ci id="A2.SS0.SSS0.Px3.p1.9.m9.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.9.m9.1.1">𝒜</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.9.m9.1c">\mathcal{A}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.9.m9.1d">caligraphic_A</annotation></semantics></math> if
<math id="A2.SS0.SSS0.Px3.p1.10.m10.1" class="ltx_math_unparsed" alttext="S_{B_{i}..}<S_{C_{i}}" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.10.m10.1a"><mrow id="A2.SS0.SSS0.Px3.p1.10.m10.1.1"><msub id="A2.SS0.SSS0.Px3.p1.10.m10.1.1.2"><mi id="A2.SS0.SSS0.Px3.p1.10.m10.1.1.2.2">S</mi><mrow id="A2.SS0.SSS0.Px3.p1.10.m10.1.1.2.3"><msub id="A2.SS0.SSS0.Px3.p1.10.m10.1.1.2.3.1"><mi id="A2.SS0.SSS0.Px3.p1.10.m10.1.1.2.3.1.2">B</mi><mi id="A2.SS0.SSS0.Px3.p1.10.m10.1.1.2.3.1.3">i</mi></msub><mo lspace="0em" rspace="0.0835em" id="A2.SS0.SSS0.Px3.p1.10.m10.1.1.2.3.2">.</mo><mo lspace="0.0835em" id="A2.SS0.SSS0.Px3.p1.10.m10.1.1.2.3.3">.</mo></mrow></msub><mo id="A2.SS0.SSS0.Px3.p1.10.m10.1.1.1">&lt;</mo><msub id="A2.SS0.SSS0.Px3.p1.10.m10.1.1.3"><mi id="A2.SS0.SSS0.Px3.p1.10.m10.1.1.3.2">S</mi><msub id="A2.SS0.SSS0.Px3.p1.10.m10.1.1.3.3"><mi id="A2.SS0.SSS0.Px3.p1.10.m10.1.1.3.3.2">C</mi><mi id="A2.SS0.SSS0.Px3.p1.10.m10.1.1.3.3.3">i</mi></msub></msub></mrow><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.10.m10.1b">S_{B_{i}..}&lt;S_{C_{i}}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.10.m10.1c">italic_S start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT . . end_POSTSUBSCRIPT &lt; italic_S start_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math> and <math id="A2.SS0.SSS0.Px3.p1.11.m11.1" class="ltx_Math" alttext="C_{i}" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.11.m11.1a"><msub id="A2.SS0.SSS0.Px3.p1.11.m11.1.1" xref="A2.SS0.SSS0.Px3.p1.11.m11.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p1.11.m11.1.1.2" xref="A2.SS0.SSS0.Px3.p1.11.m11.1.1.2.cmml">C</mi><mi id="A2.SS0.SSS0.Px3.p1.11.m11.1.1.3" xref="A2.SS0.SSS0.Px3.p1.11.m11.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.11.m11.1b"><apply id="A2.SS0.SSS0.Px3.p1.11.m11.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.11.m11.1.1"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p1.11.m11.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.11.m11.1.1">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p1.11.m11.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p1.11.m11.1.1.2">𝐶</ci><ci id="A2.SS0.SSS0.Px3.p1.11.m11.1.1.3.cmml" xref="A2.SS0.SSS0.Px3.p1.11.m11.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.11.m11.1c">C_{i}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.11.m11.1d">italic_C start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> otherwise, repeating until <math id="A2.SS0.SSS0.Px3.p1.12.m12.1" class="ltx_Math" alttext="i=|B|-1" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.12.m12.1a"><mrow id="A2.SS0.SSS0.Px3.p1.12.m12.1.2" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.cmml"><mi id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.2" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.2.cmml">i</mi><mo id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.1" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.1.cmml">=</mo><mrow id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.cmml"><mrow id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.2.2" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.2.1.cmml"><mo stretchy="false" id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.2.2.1" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.2.1.1.cmml">|</mo><mi id="A2.SS0.SSS0.Px3.p1.12.m12.1.1" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.1.cmml">B</mi><mo stretchy="false" id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.2.2.2" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.2.1.1.cmml">|</mo></mrow><mo id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.1" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.1.cmml">−</mo><mn id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.3" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.3.cmml">1</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.12.m12.1b"><apply id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.cmml" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2"><eq id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.1.cmml" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.1"></eq><ci id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.2.cmml" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.2">𝑖</ci><apply id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.cmml" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3"><minus id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.1.cmml" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.1"></minus><apply id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.2.1.cmml" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.2.2"><abs id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.2.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.2.2.1"></abs><ci id="A2.SS0.SSS0.Px3.p1.12.m12.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.1">𝐵</ci></apply><cn type="integer" id="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.3.cmml" xref="A2.SS0.SSS0.Px3.p1.12.m12.1.2.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.12.m12.1c">i=|B|-1</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.12.m12.1d">italic_i = | italic_B | - 1</annotation></semantics></math> and <math id="A2.SS0.SSS0.Px3.p1.13.m13.1" class="ltx_Math" alttext="j=|C|-1" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.13.m13.1a"><mrow id="A2.SS0.SSS0.Px3.p1.13.m13.1.2" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.cmml"><mi id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.2" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.2.cmml">j</mi><mo id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.1" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.1.cmml">=</mo><mrow id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.cmml"><mrow id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.2.2" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.2.1.cmml"><mo stretchy="false" id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.2.2.1" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.2.1.1.cmml">|</mo><mi id="A2.SS0.SSS0.Px3.p1.13.m13.1.1" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.1.cmml">C</mi><mo stretchy="false" id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.2.2.2" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.2.1.1.cmml">|</mo></mrow><mo id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.1" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.1.cmml">−</mo><mn id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.3" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.3.cmml">1</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.13.m13.1b"><apply id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.cmml" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2"><eq id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.1.cmml" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.1"></eq><ci id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.2.cmml" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.2">𝑗</ci><apply id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.cmml" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3"><minus id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.1.cmml" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.1"></minus><apply id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.2.1.cmml" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.2.2"><abs id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.2.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.2.2.1"></abs><ci id="A2.SS0.SSS0.Px3.p1.13.m13.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.1">𝐶</ci></apply><cn type="integer" id="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.3.cmml" xref="A2.SS0.SSS0.Px3.p1.13.m13.1.2.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.13.m13.1c">j=|C|-1</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.13.m13.1d">italic_j = | italic_C | - 1</annotation></semantics></math>.
To generalize to <math id="A2.SS0.SSS0.Px3.p1.14.m14.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.14.m14.1a"><mi id="A2.SS0.SSS0.Px3.p1.14.m14.1.1" xref="A2.SS0.SSS0.Px3.p1.14.m14.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.14.m14.1b"><ci id="A2.SS0.SSS0.Px3.p1.14.m14.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.14.m14.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.14.m14.1c">K</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.14.m14.1d">italic_K</annotation></semantics></math> splits, we need only replace the single comparison above with
a min-heap requiring <math id="A2.SS0.SSS0.Px3.p1.15.m15.1" class="ltx_Math" alttext="O(\log{K})\ll 10" display="inline"><semantics id="A2.SS0.SSS0.Px3.p1.15.m15.1a"><mrow id="A2.SS0.SSS0.Px3.p1.15.m15.1.1" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.cmml"><mrow id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.3" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.3.cmml">O</mi><mo id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.2" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.2.cmml" lspace="0px" rspace="0px"></mo><mrow id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1.cmml"><mo stretchy="false" id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.2" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1.cmml">(</mo><mrow id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1.1" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1.1.cmml">log</mi><mo lspace="0.167em" id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1a" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1.cmml">⁡</mo><mi id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1.2" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1.2.cmml">K</mi></mrow><mo stretchy="false" id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.3" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.2" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.2.cmml">≪</mo><mn id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.3" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.3.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p1.15.m15.1b"><apply id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1"><csymbol cd="latexml" id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.2">much-less-than</csymbol><apply id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1"><times id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.2"></times><ci id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.3.cmml" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.3">𝑂</ci><apply id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1"><log id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1.1"></log><ci id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.1.1.1.1.2">𝐾</ci></apply></apply><cn type="integer" id="A2.SS0.SSS0.Px3.p1.15.m15.1.1.3.cmml" xref="A2.SS0.SSS0.Px3.p1.15.m15.1.1.3">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p1.15.m15.1c">O(\log{K})\ll 10</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p1.15.m15.1d">italic_O ( roman_log italic_K ) ≪ 10</annotation></semantics></math> work on each iteration.</p>
</div>
<div id="A2.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="A2.SS0.SSS0.Px3.p2.4" class="ltx_p">Observe that in the general case this algorithm is <math id="A2.SS0.SSS0.Px3.p2.1.m1.3" class="ltx_Math" alttext="O(Nm\log(K))" display="inline"><semantics id="A2.SS0.SSS0.Px3.p2.1.m1.3a"><mrow id="A2.SS0.SSS0.Px3.p2.1.m1.3.3" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.cmml"><mi id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.3" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.3.cmml">O</mi><mo id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.2" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.2.cmml" lspace="0px" rspace="0px"></mo><mrow id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.cmml"><mo stretchy="false" id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.2" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.cmml">(</mo><mrow id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.2" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.2.cmml">N</mi><mo id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.1" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.3" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.3.cmml">m</mi><mo lspace="0.167em" id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.1a" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.1.cmml" rspace="0px"></mo><mrow id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.4.2" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.4.1.cmml"><mi id="A2.SS0.SSS0.Px3.p2.1.m1.1.1" xref="A2.SS0.SSS0.Px3.p2.1.m1.1.1.cmml">log</mi><mo id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.4.2a" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.4.1.cmml">⁡</mo><mrow id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.4.2.1" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.4.1.cmml"><mo stretchy="false" id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.4.2.1.1" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.4.1.cmml">(</mo><mi id="A2.SS0.SSS0.Px3.p2.1.m1.2.2" xref="A2.SS0.SSS0.Px3.p2.1.m1.2.2.cmml">K</mi><mo stretchy="false" id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.4.2.1.2" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.4.1.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.3" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p2.1.m1.3b"><apply id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.cmml" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3"><times id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.2.cmml" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.2"></times><ci id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.3.cmml" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.3">𝑂</ci><apply id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1"><times id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.1"></times><ci id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.2">𝑁</ci><ci id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.3.cmml" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.3">𝑚</ci><apply id="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.4.1.cmml" xref="A2.SS0.SSS0.Px3.p2.1.m1.3.3.1.1.1.4.2"><log id="A2.SS0.SSS0.Px3.p2.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.1.m1.1.1"></log><ci id="A2.SS0.SSS0.Px3.p2.1.m1.2.2.cmml" xref="A2.SS0.SSS0.Px3.p2.1.m1.2.2">𝐾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p2.1.m1.3c">O(Nm\log(K))</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p2.1.m1.3d">italic_O ( italic_N italic_m roman_log ( italic_K ) )</annotation></semantics></math> where <math id="A2.SS0.SSS0.Px3.p2.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="A2.SS0.SSS0.Px3.p2.2.m2.1a"><mi id="A2.SS0.SSS0.Px3.p2.2.m2.1.1" xref="A2.SS0.SSS0.Px3.p2.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p2.2.m2.1b"><ci id="A2.SS0.SSS0.Px3.p2.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p2.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p2.2.m2.1d">italic_N</annotation></semantics></math> is the length
of the dataset, <math id="A2.SS0.SSS0.Px3.p2.3.m3.1" class="ltx_Math" alttext="m" display="inline"><semantics id="A2.SS0.SSS0.Px3.p2.3.m3.1a"><mi id="A2.SS0.SSS0.Px3.p2.3.m3.1.1" xref="A2.SS0.SSS0.Px3.p2.3.m3.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p2.3.m3.1b"><ci id="A2.SS0.SSS0.Px3.p2.3.m3.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.3.m3.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p2.3.m3.1c">m</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p2.3.m3.1d">italic_m</annotation></semantics></math> is the average length of a prefix match, and <math id="A2.SS0.SSS0.Px3.p2.4.m4.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A2.SS0.SSS0.Px3.p2.4.m4.1a"><mi id="A2.SS0.SSS0.Px3.p2.4.m4.1.1" xref="A2.SS0.SSS0.Px3.p2.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p2.4.m4.1b"><ci id="A2.SS0.SSS0.Px3.p2.4.m4.1.1.cmml" xref="A2.SS0.SSS0.Px3.p2.4.m4.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p2.4.m4.1c">K</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p2.4.m4.1d">italic_K</annotation></semantics></math> is the number of splits.
It is therefore incorrect to call this algorithm linear time in the general case, for ours it is.
Because the length of the longest match is bounded above by the length of the longest
sequence, as long as the size of the dataset is independent of the length of the
longest sequence in the dataset, this algorithm remains efficient.
</p>
</div>
<div id="A2.SS0.SSS0.Px3.p3" class="ltx_para">
<p id="A2.SS0.SSS0.Px3.p3.10" class="ltx_p">Again, we can parallelize this operation among <math id="A2.SS0.SSS0.Px3.p3.1.m1.1" class="ltx_Math" alttext="L" display="inline"><semantics id="A2.SS0.SSS0.Px3.p3.1.m1.1a"><mi id="A2.SS0.SSS0.Px3.p3.1.m1.1.1" xref="A2.SS0.SSS0.Px3.p3.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p3.1.m1.1b"><ci id="A2.SS0.SSS0.Px3.p3.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p3.1.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p3.1.m1.1d">italic_L</annotation></semantics></math> simultaneous jobs
(in practice we set <math id="A2.SS0.SSS0.Px3.p3.2.m2.1" class="ltx_Math" alttext="K=L" display="inline"><semantics id="A2.SS0.SSS0.Px3.p3.2.m2.1a"><mrow id="A2.SS0.SSS0.Px3.p3.2.m2.1.1" xref="A2.SS0.SSS0.Px3.p3.2.m2.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p3.2.m2.1.1.2" xref="A2.SS0.SSS0.Px3.p3.2.m2.1.1.2.cmml">K</mi><mo id="A2.SS0.SSS0.Px3.p3.2.m2.1.1.1" xref="A2.SS0.SSS0.Px3.p3.2.m2.1.1.1.cmml">=</mo><mi id="A2.SS0.SSS0.Px3.p3.2.m2.1.1.3" xref="A2.SS0.SSS0.Px3.p3.2.m2.1.1.3.cmml">L</mi></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p3.2.m2.1b"><apply id="A2.SS0.SSS0.Px3.p3.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.2.m2.1.1"><eq id="A2.SS0.SSS0.Px3.p3.2.m2.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.2.m2.1.1.1"></eq><ci id="A2.SS0.SSS0.Px3.p3.2.m2.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p3.2.m2.1.1.2">𝐾</ci><ci id="A2.SS0.SSS0.Px3.p3.2.m2.1.1.3.cmml" xref="A2.SS0.SSS0.Px3.p3.2.m2.1.1.3">𝐿</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p3.2.m2.1c">K=L</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p3.2.m2.1d">italic_K = italic_L</annotation></semantics></math> as the number of threads on our machine).
In the <math id="A2.SS0.SSS0.Px3.p3.3.m3.1" class="ltx_Math" alttext="K=2" display="inline"><semantics id="A2.SS0.SSS0.Px3.p3.3.m3.1a"><mrow id="A2.SS0.SSS0.Px3.p3.3.m3.1.1" xref="A2.SS0.SSS0.Px3.p3.3.m3.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p3.3.m3.1.1.2" xref="A2.SS0.SSS0.Px3.p3.3.m3.1.1.2.cmml">K</mi><mo id="A2.SS0.SSS0.Px3.p3.3.m3.1.1.1" xref="A2.SS0.SSS0.Px3.p3.3.m3.1.1.1.cmml">=</mo><mn id="A2.SS0.SSS0.Px3.p3.3.m3.1.1.3" xref="A2.SS0.SSS0.Px3.p3.3.m3.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p3.3.m3.1b"><apply id="A2.SS0.SSS0.Px3.p3.3.m3.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.3.m3.1.1"><eq id="A2.SS0.SSS0.Px3.p3.3.m3.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.3.m3.1.1.1"></eq><ci id="A2.SS0.SSS0.Px3.p3.3.m3.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p3.3.m3.1.1.2">𝐾</ci><cn type="integer" id="A2.SS0.SSS0.Px3.p3.3.m3.1.1.3.cmml" xref="A2.SS0.SSS0.Px3.p3.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p3.3.m3.1c">K=2</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p3.3.m3.1d">italic_K = 2</annotation></semantics></math> case, job <math id="A2.SS0.SSS0.Px3.p3.4.m4.1" class="ltx_Math" alttext="l" display="inline"><semantics id="A2.SS0.SSS0.Px3.p3.4.m4.1a"><mi id="A2.SS0.SSS0.Px3.p3.4.m4.1.1" xref="A2.SS0.SSS0.Px3.p3.4.m4.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p3.4.m4.1b"><ci id="A2.SS0.SSS0.Px3.p3.4.m4.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.4.m4.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p3.4.m4.1c">l</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p3.4.m4.1d">italic_l</annotation></semantics></math> processes <math id="A2.SS0.SSS0.Px3.p3.5.m5.2" class="ltx_Math" alttext="i\in[jN/L,(j+1)N/L]" display="inline"><semantics id="A2.SS0.SSS0.Px3.p3.5.m5.2a"><mrow id="A2.SS0.SSS0.Px3.p3.5.m5.2.2" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.cmml"><mi id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.4" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.4.cmml">i</mi><mo id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.3" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.3.cmml">∈</mo><mrow id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.3.cmml"><mo stretchy="false" id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.3" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.3.cmml">[</mo><mrow id="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1" xref="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.cmml"><mrow id="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2" xref="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2.cmml"><mi id="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2.2" xref="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2.2.cmml">j</mi><mo id="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2.1" xref="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2.3" xref="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2.3.cmml">N</mi></mrow><mo id="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.1" xref="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.1.cmml">/</mo><mi id="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.3" xref="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.3.cmml">L</mi></mrow><mo id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.4" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.3.cmml">,</mo><mrow id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.cmml"><mrow id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.cmml"><mrow id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.2" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.cmml">(</mo><mrow id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.2" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.2.cmml">j</mi><mo id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.1" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.1.cmml">+</mo><mn id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.3" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.3.cmml">1</mn></mrow><mo stretchy="false" id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.3" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.cmml">)</mo></mrow><mo id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.2" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.2.cmml" lspace="0px" rspace="0px"></mo><mi id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.3" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.3.cmml">N</mi></mrow><mo id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.2" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.2.cmml">/</mo><mi id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.3" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.3.cmml">L</mi></mrow><mo stretchy="false" id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.5" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.3.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p3.5.m5.2b"><apply id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2"><in id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.3.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.3"></in><ci id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.4.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.4">𝑖</ci><interval closure="closed" id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.3.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2"><apply id="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1"><divide id="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.1"></divide><apply id="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2"><times id="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2.1.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2.1"></times><ci id="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2.2.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2.2">𝑗</ci><ci id="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2.3.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.2.3">𝑁</ci></apply><ci id="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.3.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.1.1.1.1.1.3">𝐿</ci></apply><apply id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2"><divide id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.2.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.2"></divide><apply id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1"><times id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.2.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.2"></times><apply id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1"><plus id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.1"></plus><ci id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.2">𝑗</ci><cn type="integer" id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.3.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.1.1.1.3">1</cn></apply><ci id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.3.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.1.3">𝑁</ci></apply><ci id="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.3.cmml" xref="A2.SS0.SSS0.Px3.p3.5.m5.2.2.2.2.2.3">𝐿</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p3.5.m5.2c">i\in[jN/L,(j+1)N/L]</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p3.5.m5.2d">italic_i ∈ [ italic_j italic_N / italic_L , ( italic_j + 1 ) italic_N / italic_L ]</annotation></semantics></math>, choosing
the bounds of <math id="A2.SS0.SSS0.Px3.p3.6.m6.1" class="ltx_Math" alttext="j" display="inline"><semantics id="A2.SS0.SSS0.Px3.p3.6.m6.1a"><mi id="A2.SS0.SSS0.Px3.p3.6.m6.1.1" xref="A2.SS0.SSS0.Px3.p3.6.m6.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p3.6.m6.1b"><ci id="A2.SS0.SSS0.Px3.p3.6.m6.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.6.m6.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p3.6.m6.1c">j</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p3.6.m6.1d">italic_j</annotation></semantics></math> by binary searching into <math id="A2.SS0.SSS0.Px3.p3.7.m7.1" class="ltx_Math" alttext="C" display="inline"><semantics id="A2.SS0.SSS0.Px3.p3.7.m7.1a"><mi id="A2.SS0.SSS0.Px3.p3.7.m7.1.1" xref="A2.SS0.SSS0.Px3.p3.7.m7.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p3.7.m7.1b"><ci id="A2.SS0.SSS0.Px3.p3.7.m7.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.7.m7.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p3.7.m7.1c">C</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p3.7.m7.1d">italic_C</annotation></semantics></math> so that <math id="A2.SS0.SSS0.Px3.p3.8.m8.1" class="ltx_Math" alttext="S_{B_{i}}<S_{C_{j}}<S_{B_{j+1}}" display="inline"><semantics id="A2.SS0.SSS0.Px3.p3.8.m8.1a"><mrow id="A2.SS0.SSS0.Px3.p3.8.m8.1.1" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.cmml"><msub id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.cmml"><mi id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.2" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.2.cmml">S</mi><msub id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.3" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.3.cmml"><mi id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.3.2" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.3.2.cmml">B</mi><mi id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.3.3" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.3.3.cmml">i</mi></msub></msub><mo id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.3" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.3.cmml">&lt;</mo><msub id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.cmml"><mi id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.2" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.2.cmml">S</mi><msub id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.3" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.3.cmml"><mi id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.3.2" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.3.2.cmml">C</mi><mi id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.3.3" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.3.3.cmml">j</mi></msub></msub><mo id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.5" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.5.cmml">&lt;</mo><msub id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.cmml"><mi id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.2" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.2.cmml">S</mi><msub id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.cmml"><mi id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.2" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.2.cmml">B</mi><mrow id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3.cmml"><mi id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3.2" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3.2.cmml">j</mi><mo id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3.1" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3.1.cmml">+</mo><mn id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3.3" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3.3.cmml">1</mn></mrow></msub></msub></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p3.8.m8.1b"><apply id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1"><and id="A2.SS0.SSS0.Px3.p3.8.m8.1.1a.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1"></and><apply id="A2.SS0.SSS0.Px3.p3.8.m8.1.1b.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1"><lt id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.3.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.3"></lt><apply id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.1.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.2.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.2">𝑆</ci><apply id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.3.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.3"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.3.1.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.3">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.3.2.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.3.2">𝐵</ci><ci id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.3.3.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.2.3.3">𝑖</ci></apply></apply><apply id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.1.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.2.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.2">𝑆</ci><apply id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.3.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.3"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.3.1.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.3">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.3.2.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.3.2">𝐶</ci><ci id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.3.3.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.3.3">𝑗</ci></apply></apply></apply><apply id="A2.SS0.SSS0.Px3.p3.8.m8.1.1c.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1"><lt id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.5.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.5"></lt><share href="#A2.SS0.SSS0.Px3.p3.8.m8.1.1.4.cmml" id="A2.SS0.SSS0.Px3.p3.8.m8.1.1d.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1"></share><apply id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.1.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.2.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.2">𝑆</ci><apply id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3"><csymbol cd="ambiguous" id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.1.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3">subscript</csymbol><ci id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.2.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.2">𝐵</ci><apply id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3"><plus id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3.1.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3.1"></plus><ci id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3.2.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3.2">𝑗</ci><cn type="integer" id="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3.3.cmml" xref="A2.SS0.SSS0.Px3.p3.8.m8.1.1.6.3.3.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p3.8.m8.1c">S_{B_{i}}&lt;S_{C_{j}}&lt;S_{B_{j+1}}</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p3.8.m8.1d">italic_S start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT &lt; italic_S start_POSTSUBSCRIPT italic_C start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT &lt; italic_S start_POSTSUBSCRIPT italic_B start_POSTSUBSCRIPT italic_j + 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT</annotation></semantics></math>.
The case where <math id="A2.SS0.SSS0.Px3.p3.9.m9.1" class="ltx_Math" alttext="K>2" display="inline"><semantics id="A2.SS0.SSS0.Px3.p3.9.m9.1a"><mrow id="A2.SS0.SSS0.Px3.p3.9.m9.1.1" xref="A2.SS0.SSS0.Px3.p3.9.m9.1.1.cmml"><mi id="A2.SS0.SSS0.Px3.p3.9.m9.1.1.2" xref="A2.SS0.SSS0.Px3.p3.9.m9.1.1.2.cmml">K</mi><mo id="A2.SS0.SSS0.Px3.p3.9.m9.1.1.1" xref="A2.SS0.SSS0.Px3.p3.9.m9.1.1.1.cmml">&gt;</mo><mn id="A2.SS0.SSS0.Px3.p3.9.m9.1.1.3" xref="A2.SS0.SSS0.Px3.p3.9.m9.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p3.9.m9.1b"><apply id="A2.SS0.SSS0.Px3.p3.9.m9.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.9.m9.1.1"><gt id="A2.SS0.SSS0.Px3.p3.9.m9.1.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.9.m9.1.1.1"></gt><ci id="A2.SS0.SSS0.Px3.p3.9.m9.1.1.2.cmml" xref="A2.SS0.SSS0.Px3.p3.9.m9.1.1.2">𝐾</ci><cn type="integer" id="A2.SS0.SSS0.Px3.p3.9.m9.1.1.3.cmml" xref="A2.SS0.SSS0.Px3.p3.9.m9.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p3.9.m9.1c">K&gt;2</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p3.9.m9.1d">italic_K &gt; 2</annotation></semantics></math> is identical except that we repeat this over all <math id="A2.SS0.SSS0.Px3.p3.10.m10.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A2.SS0.SSS0.Px3.p3.10.m10.1a"><mi id="A2.SS0.SSS0.Px3.p3.10.m10.1.1" xref="A2.SS0.SSS0.Px3.p3.10.m10.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px3.p3.10.m10.1b"><ci id="A2.SS0.SSS0.Px3.p3.10.m10.1.1.cmml" xref="A2.SS0.SSS0.Px3.p3.10.m10.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px3.p3.10.m10.1c">K</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px3.p3.10.m10.1d">italic_K</annotation></semantics></math> partial suffix arrays.</p>
</div>
</section>
<section id="A2.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Computational Analysis.</h5>

<div id="A2.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="A2.SS0.SSS0.Px4.p1.8" class="ltx_p">We run our algorithm on a single VM on the cloud with <math id="A2.SS0.SSS0.Px4.p1.1.m1.1" class="ltx_Math" alttext="96" display="inline"><semantics id="A2.SS0.SSS0.Px4.p1.1.m1.1a"><mn id="A2.SS0.SSS0.Px4.p1.1.m1.1.1" xref="A2.SS0.SSS0.Px4.p1.1.m1.1.1.cmml">96</mn><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px4.p1.1.m1.1b"><cn type="integer" id="A2.SS0.SSS0.Px4.p1.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px4.p1.1.m1.1.1">96</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px4.p1.1.m1.1c">96</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px4.p1.1.m1.1d">96</annotation></semantics></math> cores and <math id="A2.SS0.SSS0.Px4.p1.2.m2.1" class="ltx_Math" alttext="768" display="inline"><semantics id="A2.SS0.SSS0.Px4.p1.2.m2.1a"><mn id="A2.SS0.SSS0.Px4.p1.2.m2.1.1" xref="A2.SS0.SSS0.Px4.p1.2.m2.1.1.cmml">768</mn><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px4.p1.2.m2.1b"><cn type="integer" id="A2.SS0.SSS0.Px4.p1.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px4.p1.2.m2.1.1">768</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px4.p1.2.m2.1c">768</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px4.p1.2.m2.1d">768</annotation></semantics></math>GB of memory.
Our algorithm is efficient, for example processing the Wiki-40B training set (<math id="A2.SS0.SSS0.Px4.p1.3.m3.1" class="ltx_Math" alttext="3" display="inline"><semantics id="A2.SS0.SSS0.Px4.p1.3.m3.1a"><mn id="A2.SS0.SSS0.Px4.p1.3.m3.1.1" xref="A2.SS0.SSS0.Px4.p1.3.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px4.p1.3.m3.1b"><cn type="integer" id="A2.SS0.SSS0.Px4.p1.3.m3.1.1.cmml" xref="A2.SS0.SSS0.Px4.p1.3.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px4.p1.3.m3.1c">3</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px4.p1.3.m3.1d">3</annotation></semantics></math> million
examples containing <math id="A2.SS0.SSS0.Px4.p1.4.m4.1" class="ltx_Math" alttext="4" display="inline"><semantics id="A2.SS0.SSS0.Px4.p1.4.m4.1a"><mn id="A2.SS0.SSS0.Px4.p1.4.m4.1.1" xref="A2.SS0.SSS0.Px4.p1.4.m4.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px4.p1.4.m4.1b"><cn type="integer" id="A2.SS0.SSS0.Px4.p1.4.m4.1.1.cmml" xref="A2.SS0.SSS0.Px4.p1.4.m4.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px4.p1.4.m4.1c">4</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px4.p1.4.m4.1d">4</annotation></semantics></math>GB of text) in <math id="A2.SS0.SSS0.Px4.p1.5.m5.1" class="ltx_Math" alttext="2.3" display="inline"><semantics id="A2.SS0.SSS0.Px4.p1.5.m5.1a"><mn id="A2.SS0.SSS0.Px4.p1.5.m5.1.1" xref="A2.SS0.SSS0.Px4.p1.5.m5.1.1.cmml">2.3</mn><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px4.p1.5.m5.1b"><cn type="float" id="A2.SS0.SSS0.Px4.p1.5.m5.1.1.cmml" xref="A2.SS0.SSS0.Px4.p1.5.m5.1.1">2.3</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px4.p1.5.m5.1c">2.3</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px4.p1.5.m5.1d">2.3</annotation></semantics></math> minutes wall-clock time (<math id="A2.SS0.SSS0.Px4.p1.6.m6.1" class="ltx_Math" alttext="2.1" display="inline"><semantics id="A2.SS0.SSS0.Px4.p1.6.m6.1a"><mn id="A2.SS0.SSS0.Px4.p1.6.m6.1.1" xref="A2.SS0.SSS0.Px4.p1.6.m6.1.1.cmml">2.1</mn><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px4.p1.6.m6.1b"><cn type="float" id="A2.SS0.SSS0.Px4.p1.6.m6.1.1.cmml" xref="A2.SS0.SSS0.Px4.p1.6.m6.1.1">2.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px4.p1.6.m6.1c">2.1</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px4.p1.6.m6.1d">2.1</annotation></semantics></math> CPU-hours of work).
The <math id="A2.SS0.SSS0.Px4.p1.7.m7.1" class="ltx_Math" alttext="350" display="inline"><semantics id="A2.SS0.SSS0.Px4.p1.7.m7.1a"><mn id="A2.SS0.SSS0.Px4.p1.7.m7.1.1" xref="A2.SS0.SSS0.Px4.p1.7.m7.1.1.cmml">350</mn><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px4.p1.7.m7.1b"><cn type="integer" id="A2.SS0.SSS0.Px4.p1.7.m7.1.1.cmml" xref="A2.SS0.SSS0.Px4.p1.7.m7.1.1">350</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px4.p1.7.m7.1c">350</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px4.p1.7.m7.1d">350</annotation></semantics></math>GB C4 dataset takes under 12 hours (wall-clock) to build a suffix array; although we are still memory constrained and so this corresponds to <math id="A2.SS0.SSS0.Px4.p1.8.m8.1" class="ltx_Math" alttext="\sim 1000" display="inline"><semantics id="A2.SS0.SSS0.Px4.p1.8.m8.1a"><mrow id="A2.SS0.SSS0.Px4.p1.8.m8.1.1" xref="A2.SS0.SSS0.Px4.p1.8.m8.1.1.cmml"><mi id="A2.SS0.SSS0.Px4.p1.8.m8.1.1.2" xref="A2.SS0.SSS0.Px4.p1.8.m8.1.1.2.cmml"></mi><mo id="A2.SS0.SSS0.Px4.p1.8.m8.1.1.1" xref="A2.SS0.SSS0.Px4.p1.8.m8.1.1.1.cmml">∼</mo><mn id="A2.SS0.SSS0.Px4.p1.8.m8.1.1.3" xref="A2.SS0.SSS0.Px4.p1.8.m8.1.1.3.cmml">1000</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px4.p1.8.m8.1b"><apply id="A2.SS0.SSS0.Px4.p1.8.m8.1.1.cmml" xref="A2.SS0.SSS0.Px4.p1.8.m8.1.1"><csymbol cd="latexml" id="A2.SS0.SSS0.Px4.p1.8.m8.1.1.1.cmml" xref="A2.SS0.SSS0.Px4.p1.8.m8.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="A2.SS0.SSS0.Px4.p1.8.m8.1.1.2.cmml" xref="A2.SS0.SSS0.Px4.p1.8.m8.1.1.2">absent</csymbol><cn type="integer" id="A2.SS0.SSS0.Px4.p1.8.m8.1.1.3.cmml" xref="A2.SS0.SSS0.Px4.p1.8.m8.1.1.3">1000</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px4.p1.8.m8.1c">\sim 1000</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px4.p1.8.m8.1d">∼ 1000</annotation></semantics></math> CPU-hours.
Once the suffix array has been constructed, it takes under an hour to deduplicate the C4 dataset.</p>
</div>
<div id="A2.SS0.SSS0.Px4.p2" class="ltx_para">
<p id="A2.SS0.SSS0.Px4.p2.3" class="ltx_p">Note that this algorithm still requires that the dataset itself fits in memory
(so that we can efficiently index in arbitrary positions), but we do not need to fit the entire suffix array into memory.
This is fortunate since our suffix array requires an <math id="A2.SS0.SSS0.Px4.p2.1.m1.1" class="ltx_math_unparsed" alttext="8\times" display="inline"><semantics id="A2.SS0.SSS0.Px4.p2.1.m1.1a"><mrow id="A2.SS0.SSS0.Px4.p2.1.m1.1b"><mn id="A2.SS0.SSS0.Px4.p2.1.m1.1.1">8</mn><mo lspace="0.222em" id="A2.SS0.SSS0.Px4.p2.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px4.p2.1.m1.1c">8\times</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px4.p2.1.m1.1d">8 ×</annotation></semantics></math> space overhead.
For example, the suffix array for the
<math id="A2.SS0.SSS0.Px4.p2.2.m2.1" class="ltx_Math" alttext="350" display="inline"><semantics id="A2.SS0.SSS0.Px4.p2.2.m2.1a"><mn id="A2.SS0.SSS0.Px4.p2.2.m2.1.1" xref="A2.SS0.SSS0.Px4.p2.2.m2.1.1.cmml">350</mn><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px4.p2.2.m2.1b"><cn type="integer" id="A2.SS0.SSS0.Px4.p2.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px4.p2.2.m2.1.1">350</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px4.p2.2.m2.1c">350</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px4.p2.2.m2.1d">350</annotation></semantics></math>GB C4 is <math id="A2.SS0.SSS0.Px4.p2.3.m3.1" class="ltx_Math" alttext="1.5" display="inline"><semantics id="A2.SS0.SSS0.Px4.p2.3.m3.1a"><mn id="A2.SS0.SSS0.Px4.p2.3.m3.1.1" xref="A2.SS0.SSS0.Px4.p2.3.m3.1.1.cmml">1.5</mn><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px4.p2.3.m3.1b"><cn type="float" id="A2.SS0.SSS0.Px4.p2.3.m3.1.1.cmml" xref="A2.SS0.SSS0.Px4.p2.3.m3.1.1">1.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px4.p2.3.m3.1c">1.5</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px4.p2.3.m3.1d">1.5</annotation></semantics></math>TB.
</p>
</div>
<div id="A2.SS0.SSS0.Px4.p3" class="ltx_para">
<p id="A2.SS0.SSS0.Px4.p3.1" class="ltx_p">Compared to the cost of training a language model on this dataset, the additional
work required to deduplicate the training dataset is negligible.</p>
</div>
<figure id="A2.F5" class="ltx_figure"><img src="/html/2107.06499/assets/x6.png" id="A2.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="320" height="240" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>For each substring of length <math id="A2.F5.5.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A2.F5.5.m1.1b"><mi id="A2.F5.5.m1.1.1" xref="A2.F5.5.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A2.F5.5.m1.1c"><ci id="A2.F5.5.m1.1.1.cmml" xref="A2.F5.5.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.F5.5.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="A2.F5.5.m1.1e">italic_k</annotation></semantics></math>,
we plot the probability that there exists a second identical length-<math id="A2.F5.6.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A2.F5.6.m2.1b"><mi id="A2.F5.6.m2.1.1" xref="A2.F5.6.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A2.F5.6.m2.1c"><ci id="A2.F5.6.m2.1.1.cmml" xref="A2.F5.6.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.F5.6.m2.1d">k</annotation><annotation encoding="application/x-llamapun" id="A2.F5.6.m2.1e">italic_k</annotation></semantics></math> substring in the same train set.
Matches with length under <math id="A2.F5.7.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A2.F5.7.m3.1b"><mn id="A2.F5.7.m3.1.1" xref="A2.F5.7.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A2.F5.7.m3.1c"><cn type="integer" id="A2.F5.7.m3.1.1.cmml" xref="A2.F5.7.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.F5.7.m3.1d">10</annotation><annotation encoding="application/x-llamapun" id="A2.F5.7.m3.1e">10</annotation></semantics></math> subword tokens are common, and account for <math id="A2.F5.8.m4.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="A2.F5.8.m4.1b"><mrow id="A2.F5.8.m4.1.1" xref="A2.F5.8.m4.1.1.cmml"><mn id="A2.F5.8.m4.1.1.2" xref="A2.F5.8.m4.1.1.2.cmml">90</mn><mo id="A2.F5.8.m4.1.1.1" xref="A2.F5.8.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.F5.8.m4.1c"><apply id="A2.F5.8.m4.1.1.cmml" xref="A2.F5.8.m4.1.1"><csymbol cd="latexml" id="A2.F5.8.m4.1.1.1.cmml" xref="A2.F5.8.m4.1.1.1">percent</csymbol><cn type="integer" id="A2.F5.8.m4.1.1.2.cmml" xref="A2.F5.8.m4.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.F5.8.m4.1d">90\%</annotation><annotation encoding="application/x-llamapun" id="A2.F5.8.m4.1e">90 %</annotation></semantics></math> of tokens.
We choose a threshold of 50 for experiments.
</figcaption>
</figure>
</section>
<section id="A2.SS0.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Setting a threshold of duplicates.</h5>

<div id="A2.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="A2.SS0.SSS0.Px5.p1.2" class="ltx_p">An important question is how long must a substring match be before it is counted as a duplicate.
In Figure&nbsp;<a href="#A2.F5" title="Figure 5 ‣ Computational Analysis. ‣ Appendix B Further Details on ExactSubstr ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we plot the frequency of substring matches within the four datasets we will
consider.
For each substring of length <math id="A2.SS0.SSS0.Px5.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A2.SS0.SSS0.Px5.p1.1.m1.1a"><mi id="A2.SS0.SSS0.Px5.p1.1.m1.1.1" xref="A2.SS0.SSS0.Px5.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px5.p1.1.m1.1b"><ci id="A2.SS0.SSS0.Px5.p1.1.m1.1.1.cmml" xref="A2.SS0.SSS0.Px5.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px5.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px5.p1.1.m1.1d">italic_k</annotation></semantics></math>, we compute the probability that there exists another sequence of length <math id="A2.SS0.SSS0.Px5.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A2.SS0.SSS0.Px5.p1.2.m2.1a"><mi id="A2.SS0.SSS0.Px5.p1.2.m2.1.1" xref="A2.SS0.SSS0.Px5.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px5.p1.2.m2.1b"><ci id="A2.SS0.SSS0.Px5.p1.2.m2.1.1.cmml" xref="A2.SS0.SSS0.Px5.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px5.p1.2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px5.p1.2.m2.1d">italic_k</annotation></semantics></math> identical to this one; formally:
</p>
<table id="A2.Ex7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A2.Ex7.m1.4" class="ltx_math_unparsed" alttext="m(k)=\mathop{\text{Pr}}_{i\in[N]}\big{[}\exists j\neq i:\mathcal{S}_{i..i+k}=\mathcal{S}_{j..j+k}\big{]}." display="block"><semantics id="A2.Ex7.m1.4a"><mrow id="A2.Ex7.m1.4b"><mi id="A2.Ex7.m1.4.5">m</mi><mrow id="A2.Ex7.m1.4.6"><mo stretchy="false" id="A2.Ex7.m1.4.6.1">(</mo><mi id="A2.Ex7.m1.4.4">k</mi><mo stretchy="false" id="A2.Ex7.m1.4.6.2">)</mo></mrow><mo id="A2.Ex7.m1.4.7">=</mo><munder id="A2.Ex7.m1.4.8"><mtext id="A2.Ex7.m1.4.8.2">Pr</mtext><mrow id="A2.Ex7.m1.1.1.1"><mi id="A2.Ex7.m1.1.1.1.3">i</mi><mo id="A2.Ex7.m1.1.1.1.2">∈</mo><mrow id="A2.Ex7.m1.1.1.1.4.2"><mo stretchy="false" id="A2.Ex7.m1.1.1.1.4.2.1">[</mo><mi id="A2.Ex7.m1.1.1.1.1">N</mi><mo stretchy="false" id="A2.Ex7.m1.1.1.1.4.2.2">]</mo></mrow></mrow></munder><mrow id="A2.Ex7.m1.4.9"><mo maxsize="120%" minsize="120%" id="A2.Ex7.m1.4.9.1">[</mo><mo rspace="0.167em" id="A2.Ex7.m1.4.9.2">∃</mo><mi id="A2.Ex7.m1.4.9.3">j</mi><mo id="A2.Ex7.m1.4.9.4">≠</mo><mi id="A2.Ex7.m1.4.9.5">i</mi><mo lspace="0.278em" rspace="0.278em" id="A2.Ex7.m1.4.9.6">:</mo><msub id="A2.Ex7.m1.4.9.7"><mi class="ltx_font_mathcaligraphic" id="A2.Ex7.m1.4.9.7.2">𝒮</mi><mrow id="A2.Ex7.m1.2.2.1"><mi id="A2.Ex7.m1.2.2.1.1">i</mi><mo lspace="0em" rspace="0.0835em" id="A2.Ex7.m1.2.2.1.2">.</mo><mo lspace="0.0835em" rspace="0.167em" id="A2.Ex7.m1.2.2.1.3">.</mo><mi id="A2.Ex7.m1.2.2.1.4">i</mi><mo id="A2.Ex7.m1.2.2.1.5">+</mo><mi id="A2.Ex7.m1.2.2.1.6">k</mi></mrow></msub><mo id="A2.Ex7.m1.4.9.8">=</mo><msub id="A2.Ex7.m1.4.9.9"><mi class="ltx_font_mathcaligraphic" id="A2.Ex7.m1.4.9.9.2">𝒮</mi><mrow id="A2.Ex7.m1.3.3.1"><mi id="A2.Ex7.m1.3.3.1.1">j</mi><mo lspace="0em" rspace="0.0835em" id="A2.Ex7.m1.3.3.1.2">.</mo><mo lspace="0.0835em" rspace="0.167em" id="A2.Ex7.m1.3.3.1.3">.</mo><mi id="A2.Ex7.m1.3.3.1.4">j</mi><mo id="A2.Ex7.m1.3.3.1.5">+</mo><mi id="A2.Ex7.m1.3.3.1.6">k</mi></mrow></msub><mo maxsize="120%" minsize="120%" id="A2.Ex7.m1.4.9.10">]</mo></mrow><mo lspace="0em" id="A2.Ex7.m1.4.10">.</mo></mrow><annotation encoding="application/x-tex" id="A2.Ex7.m1.4c">m(k)=\mathop{\text{Pr}}_{i\in[N]}\big{[}\exists j\neq i:\mathcal{S}_{i..i+k}=\mathcal{S}_{j..j+k}\big{]}.</annotation><annotation encoding="application/x-llamapun" id="A2.Ex7.m1.4d">italic_m ( italic_k ) = Pr start_POSTSUBSCRIPT italic_i ∈ [ italic_N ] end_POSTSUBSCRIPT [ ∃ italic_j ≠ italic_i : caligraphic_S start_POSTSUBSCRIPT italic_i . . italic_i + italic_k end_POSTSUBSCRIPT = caligraphic_S start_POSTSUBSCRIPT italic_j . . italic_j + italic_k end_POSTSUBSCRIPT ] .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="A2.SS0.SSS0.Px5.p1.5" class="ltx_p">We choose <math id="A2.SS0.SSS0.Px5.p1.3.m1.1" class="ltx_Math" alttext="50" display="inline"><semantics id="A2.SS0.SSS0.Px5.p1.3.m1.1a"><mn id="A2.SS0.SSS0.Px5.p1.3.m1.1.1" xref="A2.SS0.SSS0.Px5.p1.3.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px5.p1.3.m1.1b"><cn type="integer" id="A2.SS0.SSS0.Px5.p1.3.m1.1.1.cmml" xref="A2.SS0.SSS0.Px5.p1.3.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px5.p1.3.m1.1c">50</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px5.p1.3.m1.1d">50</annotation></semantics></math> tokens as the threshold to be conservative:
the “bend in the knee” occurs at <math id="A2.SS0.SSS0.Px5.p1.4.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A2.SS0.SSS0.Px5.p1.4.m2.1a"><mn id="A2.SS0.SSS0.Px5.p1.4.m2.1.1" xref="A2.SS0.SSS0.Px5.p1.4.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px5.p1.4.m2.1b"><cn type="integer" id="A2.SS0.SSS0.Px5.p1.4.m2.1.1.cmml" xref="A2.SS0.SSS0.Px5.p1.4.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px5.p1.4.m2.1c">10</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px5.p1.4.m2.1d">10</annotation></semantics></math> tokens, and manual inspection of
length-<math id="A2.SS0.SSS0.Px5.p1.5.m3.1" class="ltx_Math" alttext="25" display="inline"><semantics id="A2.SS0.SSS0.Px5.p1.5.m3.1a"><mn id="A2.SS0.SSS0.Px5.p1.5.m3.1.1" xref="A2.SS0.SSS0.Px5.p1.5.m3.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="A2.SS0.SSS0.Px5.p1.5.m3.1b"><cn type="integer" id="A2.SS0.SSS0.Px5.p1.5.m3.1.1.cmml" xref="A2.SS0.SSS0.Px5.p1.5.m3.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.SS0.SSS0.Px5.p1.5.m3.1c">25</annotation><annotation encoding="application/x-llamapun" id="A2.SS0.SSS0.Px5.p1.5.m3.1d">25</annotation></semantics></math> matches found no false positives.
We then doubled this value to have an exceptionally large margin for error.</p>
</div>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Further Details on Model Training</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">Each model was trained for two epochs.
Since both C4-<span id="A3.p1.1.1" class="ltx_text ltx_font_smallcaps">Original</span> and C4-<span id="A3.p1.1.2" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> contain approximately 365M examples, we performed 152K steps with a batch size of 4800 (or approximately 2 epochs).
C4-<span id="A3.p1.1.3" class="ltx_text ltx_font_smallcaps">NearDup</span> contains approximately 350M examples, we performed 146K steps (or approximately 2 epochs).
On a 128-core TPU v3 pod slice, XL models trained on C4-<span id="A3.p1.1.4" class="ltx_text ltx_font_smallcaps">Original</span> and C4-<span id="A3.p1.1.5" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> took approximately 131 hours (5.5 days) to train, while the XL model trained on C4-<span id="A3.p1.1.6" class="ltx_text ltx_font_smallcaps">NearDup</span> took approximately 126 hours to train.
Like T5, models were trained with the Adafactor optimizer <cite class="ltx_cite ltx_citemacro_citep">(Shazeer and Stern, <a href="#bib.bib33" title="" class="ltx_ref">2018</a>)</cite>. A constant learning rate of 0.01 was used for the base models and 0.001 for the XL models.</p>
</div>
<div id="A3.p2" class="ltx_para">
<p id="A3.p2.1" class="ltx_p">The 1.5B parameter XL models had 24 layers, each with 32 attention heads. The model embedding size was 2,048, the feed forward layers had a hidden size of 5,120, and the key/value dimension size for the attention heads 64.
The 110M parameter base models had 12 layers, each with 12 attention heads.
The model embedding size was 768, the feed forward layers had a hidden size of 2,048, and the key/value dimension size for the attention heads 64.</p>
</div>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Energy Consumption</h2>

<figure id="A4.T6" class="ltx_table">
<table id="A4.T6.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A4.T6.1.1.1" class="ltx_tr">
<th id="A4.T6.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="A4.T6.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">T5 11B</th>
<th id="A4.T6.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">
<span id="A4.T6.1.1.1.3.1" class="ltx_inline-block">
<span id="A4.T6.1.1.1.3.1.1" class="ltx_p">XL-<span id="A4.T6.1.1.1.3.1.1.1" class="ltx_text ltx_font_smallcaps">Original</span></span>
<span id="A4.T6.1.1.1.3.1.2" class="ltx_p">XL-<span id="A4.T6.1.1.1.3.1.2.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span></span>
</span></th>
<th id="A4.T6.1.1.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">XL-<span id="A4.T6.1.1.1.4.1" class="ltx_text ltx_font_smallcaps">NearDup</span></th>
<th id="A4.T6.1.1.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">
<span id="A4.T6.1.1.1.5.1" class="ltx_inline-block">
<span id="A4.T6.1.1.1.5.1.1" class="ltx_p">Base-<span id="A4.T6.1.1.1.5.1.1.1" class="ltx_text ltx_font_smallcaps">Original</span></span>
<span id="A4.T6.1.1.1.5.1.2" class="ltx_p">Base-<span id="A4.T6.1.1.1.5.1.2.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span></span>
</span></th>
<th id="A4.T6.1.1.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Total Inference</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A4.T6.1.2.1" class="ltx_tr">
<th id="A4.T6.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">TPU v3 cores</th>
<td id="A4.T6.1.2.1.2" class="ltx_td ltx_align_right ltx_border_t">512</td>
<td id="A4.T6.1.2.1.3" class="ltx_td ltx_align_right ltx_border_t">128</td>
<td id="A4.T6.1.2.1.4" class="ltx_td ltx_align_right ltx_border_t">128</td>
<td id="A4.T6.1.2.1.5" class="ltx_td ltx_align_right ltx_border_t">64</td>
<td id="A4.T6.1.2.1.6" class="ltx_td ltx_align_right ltx_border_t">64</td>
</tr>
<tr id="A4.T6.1.3.2" class="ltx_tr">
<th id="A4.T6.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Training time (days)</th>
<td id="A4.T6.1.3.2.2" class="ltx_td ltx_align_right">20</td>
<td id="A4.T6.1.3.2.3" class="ltx_td ltx_align_right">5.47</td>
<td id="A4.T6.1.3.2.4" class="ltx_td ltx_align_right">5.26</td>
<td id="A4.T6.1.3.2.5" class="ltx_td ltx_align_right">3</td>
<td id="A4.T6.1.3.2.6" class="ltx_td ltx_align_right">0.80</td>
</tr>
<tr id="A4.T6.1.4.3" class="ltx_tr">
<th id="A4.T6.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">TPU hrs</th>
<td id="A4.T6.1.4.3.2" class="ltx_td ltx_align_right">245760</td>
<td id="A4.T6.1.4.3.3" class="ltx_td ltx_align_right">16804.70</td>
<td id="A4.T6.1.4.3.4" class="ltx_td ltx_align_right">16149.31</td>
<td id="A4.T6.1.4.3.5" class="ltx_td ltx_align_right">4608</td>
<td id="A4.T6.1.4.3.6" class="ltx_td ltx_align_right">1228.80</td>
</tr>
<tr id="A4.T6.1.5.4" class="ltx_tr">
<th id="A4.T6.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Energy (MWh)</th>
<td id="A4.T6.1.5.4.2" class="ltx_td ltx_align_right ltx_border_bb">85.70</td>
<td id="A4.T6.1.5.4.3" class="ltx_td ltx_align_right ltx_border_bb">5.86</td>
<td id="A4.T6.1.5.4.4" class="ltx_td ltx_align_right ltx_border_bb">5.63</td>
<td id="A4.T6.1.5.4.5" class="ltx_td ltx_align_right ltx_border_bb">1.61</td>
<td id="A4.T6.1.5.4.6" class="ltx_td ltx_align_right ltx_border_bb">0.43</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Estimates of energy usage based on the data in <cite class="ltx_cite ltx_citemacro_citet">Patterson et&nbsp;al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite>. The first column is <cite class="ltx_cite ltx_citemacro_citet">Patterson et&nbsp;al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite>’s estimate of the T5 11B encoder-decoder model, which we based our own estimates on.
Inference includes all XL models. We generated 100,000 sequences from 3 models, with 5 prompts, and at 2 different checkpoints.).
</figcaption>
</figure>
<div id="A4.p1" class="ltx_para">
<p id="A4.p1.4" class="ltx_p">We trained for approximately 131 hours or 5.5 days on a 128-core TPU v3.
The approximate deduplicated dataset is 3.9% smaller than the original dataset and trains in 63 hours/epoch, saving us around 5 hours of compute time for the two epochs.
The XL-<span id="A4.p1.4.1" class="ltx_text ltx_font_smallcaps">Original</span>model was trained in North America where the XL-<span id="A4.p1.4.2" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> and XL-<span id="A4.p1.4.3" class="ltx_text ltx_font_smallcaps">NearDup</span> were trained in Taiwan.
We used data from <cite class="ltx_cite ltx_citemacro_citet">Patterson et&nbsp;al. (<a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite> to estimate amount of energy used in training these models
by computing the amount of <math id="A4.p1.1.m1.1" class="ltx_Math" alttext="MWh" display="inline"><semantics id="A4.p1.1.m1.1a"><mrow id="A4.p1.1.m1.1.1" xref="A4.p1.1.m1.1.1.cmml"><mi id="A4.p1.1.m1.1.1.2" xref="A4.p1.1.m1.1.1.2.cmml">M</mi><mo id="A4.p1.1.m1.1.1.1" xref="A4.p1.1.m1.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A4.p1.1.m1.1.1.3" xref="A4.p1.1.m1.1.1.3.cmml">W</mi><mo id="A4.p1.1.m1.1.1.1a" xref="A4.p1.1.m1.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A4.p1.1.m1.1.1.4" xref="A4.p1.1.m1.1.1.4.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.p1.1.m1.1b"><apply id="A4.p1.1.m1.1.1.cmml" xref="A4.p1.1.m1.1.1"><times id="A4.p1.1.m1.1.1.1.cmml" xref="A4.p1.1.m1.1.1.1"></times><ci id="A4.p1.1.m1.1.1.2.cmml" xref="A4.p1.1.m1.1.1.2">𝑀</ci><ci id="A4.p1.1.m1.1.1.3.cmml" xref="A4.p1.1.m1.1.1.3">𝑊</ci><ci id="A4.p1.1.m1.1.1.4.cmml" xref="A4.p1.1.m1.1.1.4">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.1.m1.1c">MWh</annotation><annotation encoding="application/x-llamapun" id="A4.p1.1.m1.1d">italic_M italic_W italic_h</annotation></semantics></math>/hour/core and multiplying by our usage (see Table <a href="#A4.T6" title="Table 6 ‣ Appendix D Energy Consumption ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> for how we computed these values).
For simplicity, we use estimates from Taiwainese datacenters as an estimate.
We estimate training 2 epochs of XL-<span id="A4.p1.4.4" class="ltx_text ltx_font_smallcaps">Original</span> and XL-<span id="A4.p1.4.5" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> uses <math id="A4.p1.2.m2.1" class="ltx_Math" alttext="5.86MWh" display="inline"><semantics id="A4.p1.2.m2.1a"><mrow id="A4.p1.2.m2.1.1" xref="A4.p1.2.m2.1.1.cmml"><mn id="A4.p1.2.m2.1.1.2" xref="A4.p1.2.m2.1.1.2.cmml">5.86</mn><mo id="A4.p1.2.m2.1.1.1" xref="A4.p1.2.m2.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A4.p1.2.m2.1.1.3" xref="A4.p1.2.m2.1.1.3.cmml">M</mi><mo id="A4.p1.2.m2.1.1.1a" xref="A4.p1.2.m2.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A4.p1.2.m2.1.1.4" xref="A4.p1.2.m2.1.1.4.cmml">W</mi><mo id="A4.p1.2.m2.1.1.1b" xref="A4.p1.2.m2.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A4.p1.2.m2.1.1.5" xref="A4.p1.2.m2.1.1.5.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.p1.2.m2.1b"><apply id="A4.p1.2.m2.1.1.cmml" xref="A4.p1.2.m2.1.1"><times id="A4.p1.2.m2.1.1.1.cmml" xref="A4.p1.2.m2.1.1.1"></times><cn type="float" id="A4.p1.2.m2.1.1.2.cmml" xref="A4.p1.2.m2.1.1.2">5.86</cn><ci id="A4.p1.2.m2.1.1.3.cmml" xref="A4.p1.2.m2.1.1.3">𝑀</ci><ci id="A4.p1.2.m2.1.1.4.cmml" xref="A4.p1.2.m2.1.1.4">𝑊</ci><ci id="A4.p1.2.m2.1.1.5.cmml" xref="A4.p1.2.m2.1.1.5">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.2.m2.1c">5.86MWh</annotation><annotation encoding="application/x-llamapun" id="A4.p1.2.m2.1d">5.86 italic_M italic_W italic_h</annotation></semantics></math>.
XL-<span id="A4.p1.4.6" class="ltx_text ltx_font_smallcaps">NearDup</span> is trained for fewer steps and we estimate uses <math id="A4.p1.3.m3.1" class="ltx_Math" alttext="5.63MWh" display="inline"><semantics id="A4.p1.3.m3.1a"><mrow id="A4.p1.3.m3.1.1" xref="A4.p1.3.m3.1.1.cmml"><mn id="A4.p1.3.m3.1.1.2" xref="A4.p1.3.m3.1.1.2.cmml">5.63</mn><mo id="A4.p1.3.m3.1.1.1" xref="A4.p1.3.m3.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A4.p1.3.m3.1.1.3" xref="A4.p1.3.m3.1.1.3.cmml">M</mi><mo id="A4.p1.3.m3.1.1.1a" xref="A4.p1.3.m3.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A4.p1.3.m3.1.1.4" xref="A4.p1.3.m3.1.1.4.cmml">W</mi><mo id="A4.p1.3.m3.1.1.1b" xref="A4.p1.3.m3.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A4.p1.3.m3.1.1.5" xref="A4.p1.3.m3.1.1.5.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.p1.3.m3.1b"><apply id="A4.p1.3.m3.1.1.cmml" xref="A4.p1.3.m3.1.1"><times id="A4.p1.3.m3.1.1.1.cmml" xref="A4.p1.3.m3.1.1.1"></times><cn type="float" id="A4.p1.3.m3.1.1.2.cmml" xref="A4.p1.3.m3.1.1.2">5.63</cn><ci id="A4.p1.3.m3.1.1.3.cmml" xref="A4.p1.3.m3.1.1.3">𝑀</ci><ci id="A4.p1.3.m3.1.1.4.cmml" xref="A4.p1.3.m3.1.1.4">𝑊</ci><ci id="A4.p1.3.m3.1.1.5.cmml" xref="A4.p1.3.m3.1.1.5">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.3.m3.1c">5.63MWh</annotation><annotation encoding="application/x-llamapun" id="A4.p1.3.m3.1d">5.63 italic_M italic_W italic_h</annotation></semantics></math>.
Training each base model was approximately 3 days on a 64-core TPU v3 pod slice which uses an estimated <math id="A4.p1.4.m4.1" class="ltx_Math" alttext="1.61MWh" display="inline"><semantics id="A4.p1.4.m4.1a"><mrow id="A4.p1.4.m4.1.1" xref="A4.p1.4.m4.1.1.cmml"><mn id="A4.p1.4.m4.1.1.2" xref="A4.p1.4.m4.1.1.2.cmml">1.61</mn><mo id="A4.p1.4.m4.1.1.1" xref="A4.p1.4.m4.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A4.p1.4.m4.1.1.3" xref="A4.p1.4.m4.1.1.3.cmml">M</mi><mo id="A4.p1.4.m4.1.1.1a" xref="A4.p1.4.m4.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A4.p1.4.m4.1.1.4" xref="A4.p1.4.m4.1.1.4.cmml">W</mi><mo id="A4.p1.4.m4.1.1.1b" xref="A4.p1.4.m4.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A4.p1.4.m4.1.1.5" xref="A4.p1.4.m4.1.1.5.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.p1.4.m4.1b"><apply id="A4.p1.4.m4.1.1.cmml" xref="A4.p1.4.m4.1.1"><times id="A4.p1.4.m4.1.1.1.cmml" xref="A4.p1.4.m4.1.1.1"></times><cn type="float" id="A4.p1.4.m4.1.1.2.cmml" xref="A4.p1.4.m4.1.1.2">1.61</cn><ci id="A4.p1.4.m4.1.1.3.cmml" xref="A4.p1.4.m4.1.1.3">𝑀</ci><ci id="A4.p1.4.m4.1.1.4.cmml" xref="A4.p1.4.m4.1.1.4">𝑊</ci><ci id="A4.p1.4.m4.1.1.5.cmml" xref="A4.p1.4.m4.1.1.5">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.4.m4.1c">1.61MWh</annotation><annotation encoding="application/x-llamapun" id="A4.p1.4.m4.1d">1.61 italic_M italic_W italic_h</annotation></semantics></math>.</p>
</div>
<div id="A4.p2" class="ltx_para">
<p id="A4.p2.1" class="ltx_p">In addition to model training, evaluation and inference were performed on 64-core TPU v3 pod slices. Generating 100,000 sequences from the XL models takes approximately 0.64 hours. We generated 100,000 sequences for each of five types of prompts for two checkpoints of the model for a total of 1M sequences per model. This took approximately 19.2 hours.
We estimate generating 3M sequences uses <math id="A4.p2.1.m1.1" class="ltx_Math" alttext="0.43MWh" display="inline"><semantics id="A4.p2.1.m1.1a"><mrow id="A4.p2.1.m1.1.1" xref="A4.p2.1.m1.1.1.cmml"><mn id="A4.p2.1.m1.1.1.2" xref="A4.p2.1.m1.1.1.2.cmml">0.43</mn><mo id="A4.p2.1.m1.1.1.1" xref="A4.p2.1.m1.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A4.p2.1.m1.1.1.3" xref="A4.p2.1.m1.1.1.3.cmml">M</mi><mo id="A4.p2.1.m1.1.1.1a" xref="A4.p2.1.m1.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A4.p2.1.m1.1.1.4" xref="A4.p2.1.m1.1.1.4.cmml">W</mi><mo id="A4.p2.1.m1.1.1.1b" xref="A4.p2.1.m1.1.1.1.cmml" lspace="0px" rspace="0px"></mo><mi id="A4.p2.1.m1.1.1.5" xref="A4.p2.1.m1.1.1.5.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="A4.p2.1.m1.1b"><apply id="A4.p2.1.m1.1.1.cmml" xref="A4.p2.1.m1.1.1"><times id="A4.p2.1.m1.1.1.1.cmml" xref="A4.p2.1.m1.1.1.1"></times><cn type="float" id="A4.p2.1.m1.1.1.2.cmml" xref="A4.p2.1.m1.1.1.2">0.43</cn><ci id="A4.p2.1.m1.1.1.3.cmml" xref="A4.p2.1.m1.1.1.3">𝑀</ci><ci id="A4.p2.1.m1.1.1.4.cmml" xref="A4.p2.1.m1.1.1.4">𝑊</ci><ci id="A4.p2.1.m1.1.1.5.cmml" xref="A4.p2.1.m1.1.1.5">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p2.1.m1.1c">0.43MWh</annotation><annotation encoding="application/x-llamapun" id="A4.p2.1.m1.1d">0.43 italic_M italic_W italic_h</annotation></semantics></math>.</p>
</div>
<figure id="A4.T7" class="ltx_table">
<table id="A4.T7.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A4.T7.1.1.1" class="ltx_tr">
<th id="A4.T7.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Dataset</th>
<th id="A4.T7.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">Example</th>
<th id="A4.T7.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Near-Duplicate Example</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A4.T7.1.2.1" class="ltx_tr">
<th id="A4.T7.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Wiki-40B</th>
<td id="A4.T7.1.2.1.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:169.1pt;">
<p id="A4.T7.1.2.1.2.1" class="ltx_p ltx_align_top"><span id="A4.T7.1.2.1.2.1.1" class="ltx_text" style="background-color:#FFFCBB;">\n_START_ARTICLE_\nHum Award for </span> Most Impactful Character <span id="A4.T7.1.2.1.2.1.2" class="ltx_text" style="background-color:#FFFCBB;">\n_START_SECTION_\nWinners and nominees\n_START_PARAGRAPH_\nIn the list below, winners are listed first in the colored row, followed by the other nominees.</span> […]</p>
</td>
<td id="A4.T7.1.2.1.3" class="ltx_td ltx_align_justify ltx_border_t" style="width:177.8pt;">
<p id="A4.T7.1.2.1.3.1" class="ltx_p ltx_align_top"><span id="A4.T7.1.2.1.3.1.1" class="ltx_text" style="background-color:#FFFCBB;">\n_START_ARTICLE_\nHum Award for</span> Best Actor in a Negative Role <span id="A4.T7.1.2.1.3.1.2" class="ltx_text" style="background-color:#FFFCBB;">\n_START_SECTION_\nWinners and nominees\n_START_PARAGRAPH_\nIn the list below, winners are listed first in the colored row, followed by the other nominees.</span> […]</p>
</td>
</tr>
<tr id="A4.T7.1.3.2" class="ltx_tr">
<th id="A4.T7.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">LM1B</th>
<td id="A4.T7.1.3.2.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:169.1pt;"><span id="A4.T7.1.3.2.2.1" class="ltx_text ltx_align_top" style="background-color:#FFFCBB;">I left for California in 1979 and tracked Cleveland ’s changes on trips back to visit my sisters .</span></td>
<td id="A4.T7.1.3.2.3" class="ltx_td ltx_align_justify ltx_border_t" style="width:177.8pt;">
<p id="A4.T7.1.3.2.3.1" class="ltx_p ltx_align_top"><span id="A4.T7.1.3.2.3.1.1" class="ltx_text" style="background-color:#FFFCBB;">I left for California in 1979</span> , <span id="A4.T7.1.3.2.3.1.2" class="ltx_text" style="background-color:#FFFCBB;">and tracked Cleveland ’s changes on trips back to visit my sisters .</span></p>
</td>
</tr>
<tr id="A4.T7.1.4.3" class="ltx_tr">
<th id="A4.T7.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">RealNews</th>
<td id="A4.T7.1.4.3.2" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:169.1pt;"><span id="A4.T7.1.4.3.2.1" class="ltx_text ltx_align_top" style="background-color:#FFFCBB;">KUALA LUMPUR (Reuters) - Roads in Southeast Asia have been getting a little louder lately as motorcycle makers, an aspiring middle class and easy bank credit come together to breed a new genus of motorcyclists – the big-bike rider. […]</span></td>
<td id="A4.T7.1.4.3.3" class="ltx_td ltx_align_justify ltx_border_t" style="width:177.8pt;">
<p id="A4.T7.1.4.3.3.1" class="ltx_p ltx_align_top">A visitor looks at a Triumph motorcycle on display at the Indonesian International Motor Show in Jakarta September 19, 2014. REUTERS/Darren Whiteside\n<span id="A4.T7.1.4.3.3.1.1" class="ltx_text" style="background-color:#FFFCBB;">KUALA LUMPUR (Reuters) - Roads in Southeast Asia have been getting a little […] big-bike rider.
[…]</span></p>
</td>
</tr>
<tr id="A4.T7.1.5.4" class="ltx_tr">
<th id="A4.T7.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t">C4</th>
<td id="A4.T7.1.5.4.2" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t" style="width:169.1pt;">
<p id="A4.T7.1.5.4.2.1" class="ltx_p ltx_align_top"><span id="A4.T7.1.5.4.2.1.1" class="ltx_text" style="background-color:#FFFCBB;">Affordable and convenient holiday flights take off from your departure country,</span> "Canada"<span id="A4.T7.1.5.4.2.1.2" class="ltx_text" style="background-color:#FFFCBB;">. From</span> May <span id="A4.T7.1.5.4.2.1.3" class="ltx_text" style="background-color:#FFFCBB;">2019 to October 2019, Condor flights to your dream destination will be roughly</span> 6 <span id="A4.T7.1.5.4.2.1.4" class="ltx_text" style="background-color:#FFFCBB;">a week! Book your</span> Halifax (YHZ) - Basel (BSL) <span id="A4.T7.1.5.4.2.1.5" class="ltx_text" style="background-color:#FFFCBB;">flight now, and look forward to your</span> "Switzerland" <span id="A4.T7.1.5.4.2.1.6" class="ltx_text" style="background-color:#FFFCBB;">destination!</span></p>
</td>
<td id="A4.T7.1.5.4.3" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" style="width:177.8pt;">
<p id="A4.T7.1.5.4.3.1" class="ltx_p ltx_align_top"><span id="A4.T7.1.5.4.3.1.1" class="ltx_text" style="background-color:#FFFCBB;">Affordable and convenient holiday flights take off from your departure country,</span> "USA"<span id="A4.T7.1.5.4.3.1.2" class="ltx_text" style="background-color:#FFFCBB;">. From</span> April <span id="A4.T7.1.5.4.3.1.3" class="ltx_text" style="background-color:#FFFCBB;">2019 to October 2019, Condor flights to your dream destination will be roughly</span> 7 <span id="A4.T7.1.5.4.3.1.4" class="ltx_text" style="background-color:#FFFCBB;">a week! Book your</span> Maui Kahului (OGG) - Dubrovnik (DBV) <span id="A4.T7.1.5.4.3.1.5" class="ltx_text" style="background-color:#FFFCBB;">flight now, and look forward to your</span> "Croatia" <span id="A4.T7.1.5.4.3.1.6" class="ltx_text" style="background-color:#FFFCBB;">destination!</span></p>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Qualitative examples of near-duplicates identified by <span id="A4.T7.3.1" class="ltx_text ltx_font_smallcaps">NearDup</span> from each dataset. The similarlity between documents is highlighted. Note the small interspersed differences that make exact duplicate matching less effective. Examples ending with “[…]” have been truncated for brevity.</figcaption>
</figure>
<figure id="A4.T8" class="ltx_table">
<table id="A4.T8.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A4.T8.1.1.1" class="ltx_tr">
<th id="A4.T8.1.1.1.1" class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_r ltx_border_tt" style="width:208.1pt;">
<p id="A4.T8.1.1.1.1.1" class="ltx_p ltx_align_top"><span id="A4.T8.1.1.1.1.1.1" class="ltx_text" style="background-color:#FFFCBB;">Due to</span> high demand, <span id="A4.T8.1.1.1.1.1.2" class="ltx_text" style="background-color:#FFFCBB;">we have</span> yet <span id="A4.T8.1.1.1.1.1.3" class="ltx_text" style="background-color:#FFFCBB;">to critique this request. That said, we assure that the review will be produced in due time by our dilligent and</span> unwavering <span id="A4.T8.1.1.1.1.1.4" class="ltx_text" style="background-color:#FFFCBB;">staff in a professional manner. This site is highly regarded amongst its peers in terms of</span> speed <span id="A4.T8.1.1.1.1.1.5" class="ltx_text" style="background-color:#FFFCBB;">and reliability, so feel free to</span> check us out!</p>
</th>
<th id="A4.T8.1.1.1.2" class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" style="width:208.1pt;">
<p id="A4.T8.1.1.1.2.1" class="ltx_p ltx_align_top"><span id="A4.T8.1.1.1.2.1.1" class="ltx_text" style="background-color:#FFFCBB;">Due to</span> a heavy overflow, <span id="A4.T8.1.1.1.2.1.2" class="ltx_text" style="background-color:#FFFCBB;">we have</span> not been able <span id="A4.T8.1.1.1.2.1.3" class="ltx_text" style="background-color:#FFFCBB;">to critique this request. That said, we assure that the review will be produced in due time by our dilligent and</span> unshakable <span id="A4.T8.1.1.1.2.1.4" class="ltx_text" style="background-color:#FFFCBB;">staff in a professional manner. This site is highly regarded amongst its peers in terms of</span> efficiency <span id="A4.T8.1.1.1.2.1.5" class="ltx_text" style="background-color:#FFFCBB;">and reliability, so feel free to</span> visit!</p>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A4.T8.1.2.1" class="ltx_tr">
<td id="A4.T8.1.2.1.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:208.1pt;">
<p id="A4.T8.1.2.1.1.1" class="ltx_p ltx_align_top">Need Pop Tacos parking? <span id="A4.T8.1.2.1.1.1.1" class="ltx_text" style="background-color:#FFFCBB;">You can reserve parking near</span> Pop Tacos <span id="A4.T8.1.2.1.1.1.2" class="ltx_text" style="background-color:#FFFCBB;">with SpotHero. Find low rates without parking coupons by booking a guaranteed spot online. Avoid circling, getting ticketed or running out to feed your meter. Search our parking map, compare parking rates and reserve a discounted parking spot today. Happy parking, and enjoy your meal at</span> Pop Tacos!</p>
</td>
<td id="A4.T8.1.2.1.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:208.1pt;">
<p id="A4.T8.1.2.1.2.1" class="ltx_p ltx_align_top">Il Sole parking. Reserve parking near Il Sole in NYC.\n<span id="A4.T8.1.2.1.2.1.1" class="ltx_text" style="background-color:#FFFCBB;">You can reserve parking near</span> Il Sole <span id="A4.T8.1.2.1.2.1.2" class="ltx_text" style="background-color:#FFFCBB;">with SpotHero. Find low rates without parking coupons by booking a guaranteed spot online. Avoid circling, getting ticketed or running out to feed your meter. Search our parking map, compare parking rates and reserve a discounted parking spot today. Happy parking, and enjoy your meal at</span> Il Sole!</p>
</td>
</tr>
<tr id="A4.T8.1.3.2" class="ltx_tr">
<td id="A4.T8.1.3.2.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:208.1pt;">
<p id="A4.T8.1.3.2.1.1" class="ltx_p ltx_align_top"><span id="A4.T8.1.3.2.1.1.1" class="ltx_text" style="background-color:#FFFCBB;">This item was available on</span> Vinyl 7" <span id="A4.T8.1.3.2.1.1.2" class="ltx_text" style="background-color:#FFFCBB;">but is now sold out on all formats, sorry. Take a look at what else we have in by</span> Jumbo<span id="A4.T8.1.3.2.1.1.3" class="ltx_text" style="background-color:#FFFCBB;">, check out some related artists, head over to our new releases or knock yourself out reading our latest music news &amp; album reviews.</span>\n2nd single edn of 550.</p>
</td>
<td id="A4.T8.1.3.2.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:208.1pt;">
<p id="A4.T8.1.3.2.2.1" class="ltx_p ltx_align_top"><span id="A4.T8.1.3.2.2.1.1" class="ltx_text" style="background-color:#FFFCBB;">This item was available on</span> CD <span id="A4.T8.1.3.2.2.1.2" class="ltx_text" style="background-color:#FFFCBB;">but is now sold out on all formats, sorry. Take a look at what else we have in by</span> Sirconical, Misty Dixon, Various<span id="A4.T8.1.3.2.2.1.3" class="ltx_text" style="background-color:#FFFCBB;">, check out some related artists, head over to our new releases or knock yourself out reading our latest music news &amp; album reviews.</span>\nTwisted Nerve comp mini album.</p>
</td>
</tr>
<tr id="A4.T8.1.4.3" class="ltx_tr">
<td id="A4.T8.1.4.3.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:208.1pt;">
<p id="A4.T8.1.4.3.1.1" class="ltx_p ltx_align_top"><span id="A4.T8.1.4.3.1.1.1" class="ltx_text" style="background-color:#FFFCBB;">Here is all the information you need about</span> "No One Killed Jessica" on American Netflix. <span id="A4.T8.1.4.3.1.1.2" class="ltx_text" style="background-color:#FFFCBB;">Details include the date it was added to</span> Netflix in the USA<span id="A4.T8.1.4.3.1.1.3" class="ltx_text" style="background-color:#FFFCBB;">, any known expiry dates and new episodes/seasons, the ratings and cast etc. So scroll down for more information or share the link on social media to let your friends know what you’re watching.</span></p>
</td>
<td id="A4.T8.1.4.3.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:208.1pt;">
<p id="A4.T8.1.4.3.2.1" class="ltx_p ltx_align_top"><span id="A4.T8.1.4.3.2.1.1" class="ltx_text" style="background-color:#FFFCBB;">Here is all the information you need about</span> "A Land Imagined" on Netflix in the UK. <span id="A4.T8.1.4.3.2.1.2" class="ltx_text" style="background-color:#FFFCBB;">Details include the date it was added to</span> UK Netflix<span id="A4.T8.1.4.3.2.1.3" class="ltx_text" style="background-color:#FFFCBB;">, any known expiry dates and new episodes/seasons, the ratings and cast etc. So scroll down for more information or share the link on social media to let your friends know what you’re watching.</span></p>
</td>
</tr>
<tr id="A4.T8.1.5.4" class="ltx_tr">
<td id="A4.T8.1.5.4.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:208.1pt;">
<p id="A4.T8.1.5.4.1.1" class="ltx_p ltx_align_top">8 + 8 = <span id="A4.T8.1.5.4.1.1.1" class="ltx_text" style="background-color:#FFFCBB;">Solve this simple math problem and enter the result. E.g. for 1+3, enter 4.</span></p>
</td>
<td id="A4.T8.1.5.4.2" class="ltx_td ltx_align_justify ltx_border_t" style="width:208.1pt;">
<p id="A4.T8.1.5.4.2.1" class="ltx_p ltx_align_top">Math question * 7 + 1 = <span id="A4.T8.1.5.4.2.1.1" class="ltx_text" style="background-color:#FFFCBB;">Solve this simple math problem and enter the result. E.g. for 1+3, enter 4.</span></p>
</td>
</tr>
<tr id="A4.T8.1.6.5" class="ltx_tr">
<td id="A4.T8.1.6.5.1" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t" style="width:208.1pt;">
<p id="A4.T8.1.6.5.1.1" class="ltx_p ltx_align_top">Long Island College Hospital <span id="A4.T8.1.6.5.1.1.1" class="ltx_text" style="background-color:#FFFCBB;">is committed to providing outstanding patient care in the</span> Brooklyn, NY area<span id="A4.T8.1.6.5.1.1.2" class="ltx_text" style="background-color:#FFFCBB;">, but before you commit to</span> Long Island College Hospital for a Endometrial Ablation <span id="A4.T8.1.6.5.1.1.3" class="ltx_text" style="background-color:#FFFCBB;">make sure you compare and shop other medical facilities. It may save you hundreds (in some cases thousands) of dollars. View a</span> Endometrial Ablation <span id="A4.T8.1.6.5.1.1.4" class="ltx_text" style="background-color:#FFFCBB;">cost comparison for</span> Brooklyn and <span id="A4.T8.1.6.5.1.1.5" class="ltx_text" style="background-color:#FFFCBB;">Request a Free Quote before you make a decision.</span></p>
</td>
<td id="A4.T8.1.6.5.2" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" style="width:208.1pt;">
<p id="A4.T8.1.6.5.2.1" class="ltx_p ltx_align_top">Morristown Memorial Hospital <span id="A4.T8.1.6.5.2.1.1" class="ltx_text" style="background-color:#FFFCBB;">is committed to providing outstanding patient care in the</span> Morristown, NJ area<span id="A4.T8.1.6.5.2.1.2" class="ltx_text" style="background-color:#FFFCBB;">, but before you commit to</span> Morristown Memorial Hospital for a Breast Ultrasound <span id="A4.T8.1.6.5.2.1.3" class="ltx_text" style="background-color:#FFFCBB;">make sure you compare and shop other medical facilities. It may save you hundreds (in some cases thousands) of dollars. View a</span> Breast Ultrasound <span id="A4.T8.1.6.5.2.1.4" class="ltx_text" style="background-color:#FFFCBB;">cost comparison for</span> Morristown and <span id="A4.T8.1.6.5.2.1.5" class="ltx_text" style="background-color:#FFFCBB;">Request a Free Quote before you make a decision.</span></p>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Several examples of pairs of documents in C4 that were found by the Approximate Matching algorithm and identified as having edit similarity of almost exactly 0.8. Pairs of documents less similar than 0.8 were not identified as duplicates. For readability, matching subsequences have been highlighted.</figcaption>
</figure>
<figure id="A4.T9" class="ltx_table">
<table id="A4.T9.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A4.T9.1.1.1" class="ltx_tr">
<th id="A4.T9.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<span id="A4.T9.1.1.1.1.1" class="ltx_text ltx_font_bold">Text</span></th>
<th id="A4.T9.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="A4.T9.1.1.1.2.1" class="ltx_text ltx_font_bold">Freq in C4</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A4.T9.1.2.1" class="ltx_tr">
<td id="A4.T9.1.2.1.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T9.1.2.1.1.1" class="ltx_p ltx_align_top">HD wallpaper. This wallpaper was upload at April 19, 2019 upload by admin in.You can download it in your computer by clicking resolution image in Download by size:. Don’t forget to rate and comment if you interest with this wallpaper.</p>
</td>
<td id="A4.T9.1.2.1.2" class="ltx_td ltx_align_right ltx_border_t">40,340</td>
</tr>
<tr id="A4.T9.1.3.2" class="ltx_tr">
<td id="A4.T9.1.3.2.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T9.1.3.2.1.1" class="ltx_p ltx_align_top">to the address posted below. Include our failure information form,a packing slip with your Company name, contact person, and Email address or phone number. Upon receipt of your repair, we\’ll inspect it and then contact you with a quote or evaluation notice. Normal turn around for repair is 5 to 7 business days, with "Rush Repair" available.</p>
</td>
<td id="A4.T9.1.3.2.2" class="ltx_td ltx_align_right ltx_border_t">5,900</td>
</tr>
<tr id="A4.T9.1.4.3" class="ltx_tr">
<td id="A4.T9.1.4.3.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T9.1.4.3.1.1" class="ltx_p ltx_align_top">is a great place to begin your search. Whether you are a first-time home buyer or you are already familiar with the home buying process, you can be assured that you have the best tools and the perfect agent available to help with your</p>
</td>
<td id="A4.T9.1.4.3.2" class="ltx_td ltx_align_right ltx_border_t">5,358</td>
</tr>
<tr id="A4.T9.1.5.4" class="ltx_tr">
<td id="A4.T9.1.5.4.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T9.1.5.4.1.1" class="ltx_p ltx_align_top">pics at these awesome group starting P letter. Desktop wallpapers were first introduced way back in the 1980s and have gained immense popularity since then. It is possible to come across more than 80 million sites on the web offering some sort of wallpaper.</p>
</td>
<td id="A4.T9.1.5.4.2" class="ltx_td ltx_align_right ltx_border_t">848</td>
</tr>
<tr id="A4.T9.1.6.5" class="ltx_tr">
<td id="A4.T9.1.6.5.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T9.1.6.5.1.1" class="ltx_p ltx_align_top">flowers will let them know you’re thinking of them and wishing them well. Cheerful yellow flowers bring their own sunshine and will get right to work on lifting spirits, and a colorful vase will bring loads of smiles to friends and visitors! Get Well flower arrangements from</p>
</td>
<td id="A4.T9.1.6.5.2" class="ltx_td ltx_align_right ltx_border_t">479</td>
</tr>
<tr id="A4.T9.1.7.6" class="ltx_tr">
<td id="A4.T9.1.7.6.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T9.1.7.6.1.1" class="ltx_p ltx_align_top">our premier 24 hour emergency* plumbing and heating solutions. We realise that when your heating fails or pipes and drains leak it can cause havoc with your routine and even cause damage to your property. When a plumbing problem occurs that requires an immediate response we provide qualified local plumbers throughout</p>
</td>
<td id="A4.T9.1.7.6.2" class="ltx_td ltx_align_right ltx_border_t">56</td>
</tr>
<tr id="A4.T9.1.8.7" class="ltx_tr">
<td id="A4.T9.1.8.7.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T9.1.8.7.1.1" class="ltx_p ltx_align_top">is to remove all images that violate copyrights. Please contact us to request that images be removed or to assign proper credit. The images displayed on this site may be used for Free or educational purposes only. If you would like to use any of the images displayed on this site for any other purpose, please obtain permission from the owner. www.</p>
</td>
<td id="A4.T9.1.8.7.2" class="ltx_td ltx_align_right ltx_border_t">48</td>
</tr>
<tr id="A4.T9.1.9.8" class="ltx_tr">
<td id="A4.T9.1.9.8.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T9.1.9.8.1.1" class="ltx_p ltx_align_top">list of fishing locations, providing interactive maps that show each location’s GPS coordinates, nearby facilities (like restaurants, gas stations, marinas and fishing shops), their current and forecasted weather and, if available, their water conditions.\nFind any of the 8</p>
</td>
<td id="A4.T9.1.9.8.2" class="ltx_td ltx_align_right ltx_border_t">5</td>
</tr>
<tr id="A4.T9.1.10.9" class="ltx_tr">
<td id="A4.T9.1.10.9.1" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T9.1.10.9.1.1" class="ltx_p ltx_align_top">. Dyer, Ph.D., is an internationally renowned author and speaker in the field of self-development. He’s the author of 30 books, has created many audio programs and videos, and has appeared on thousands of television and radio shows.</p>
</td>
<td id="A4.T9.1.10.9.2" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">5</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>A selection of substrings identified by <span id="A4.T9.3.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> as being in C4 multiple times. The number of times this exact substring occurs in C4 is also given.</figcaption>
</figure>
<figure id="A4.T10" class="ltx_table">
<table id="A4.T10.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A4.T10.5.1.1" class="ltx_tr">
<th id="A4.T10.5.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">
<span id="A4.T10.5.1.1.1.1" class="ltx_text ltx_font_bold">Generated Text</span></th>
<th id="A4.T10.5.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<span id="A4.T10.5.1.1.2.1" class="ltx_text ltx_font_bold">Freq in C4</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A4.T10.5.2.1" class="ltx_tr">
<td id="A4.T10.5.2.1.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T10.5.2.1.1.1" class="ltx_p ltx_align_top">, you’ll need to be knowledgeable to make the very best decisions. We will make sure you know what can be expected. We take the surprises from the picture by giving accurate and thorough information. You can start by talking about your task with our client service staff when
<br class="ltx_break"> you dial 888-353-1299. We’ll address all of your questions and arrange the initial meeting. We work closely with you through the whole project, and our team can show up promptly and prepared.</p>
</td>
<td id="A4.T10.5.2.1.2" class="ltx_td ltx_align_right ltx_border_t">5,497</td>
</tr>
<tr id="A4.T10.5.3.2" class="ltx_tr">
<td id="A4.T10.5.3.2.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T10.5.3.2.1.1" class="ltx_p ltx_align_top">then Waterside Lodge are well equipped for the task. Our fully equipped family sized lodges offer a comfortable luxurious stay for a fantastic price, giving you beautiful views of the lakes and the surrounding countryside. Offering luxurious self-catering holidays in our fully featured Scandinavian holiday lodges. Perfectly located to explore the beaches, coastline. All of our lodges are sized for 6 people and are furnished to the highest standards to ensure you have a stay like no other. At Waterside Lodge the stay itself is only half of the package, Waterside lodge is situated closely to the Heritage Coast which makes our lodges the perfect stay for anyone wanting to get away and have a relaxing countryside break from the city. Whilst you stay with us be sure to take advantage of all the activities Waterside Lodge has to offer. Such as the use of our on-site fishing lakes for the keen fisherman, free internet access, outside relaxation areas, comfortable lounges and much more.</p>
</td>
<td id="A4.T10.5.3.2.2" class="ltx_td ltx_align_right ltx_border_t">571</td>
</tr>
<tr id="A4.T10.5.4.3" class="ltx_tr">
<td id="A4.T10.5.4.3.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T10.5.4.3.1.1" class="ltx_p ltx_align_top">you are only looking to find rent to own homes in your city or are open to exploring all kinds of rent to own home listings, our database does it all. One of the best aspects of iRentToOwn.com is that, besides options to rent to buy a house, it has numerous other categories of home sale options. These include bank foreclosure homes, pre-foreclosure homes, short sales, HUD/government foreclosures, auction homes and owner-financing/FSBO (For Sale By Owner) homes. With help from the convenient search features offered by our site, shoppers are able to find their ideal lease to own home, real estate company, and more in South</p>
</td>
<td id="A4.T10.5.4.3.2" class="ltx_td ltx_align_right ltx_border_t">51</td>
</tr>
<tr id="A4.T10.5.5.4" class="ltx_tr">
<td id="A4.T10.5.5.4.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T10.5.5.4.1.1" class="ltx_p ltx_align_top">, IL employs journeyman as licensed to work by themselves, without direct supervision, installing wiring, outlets and fixtures. Our journeyman also does service work, troubleshooting when a breaker fails or a light stops working. Our journeyman does not offer permits that must be issued by our master. Our journeyman follows our master’s plans and directions. Our journeyman’s responsibilities will vary based on the work that needs to be done. Our journeymen are skilled with residential, commercial and industrial installations and repairs.ust work from six years as an apprentice, under direct supervision of our master, and pass a journeyman test. This person also must have some classroom education on the National Electrical Code and fundamental electricity in a technical school a program affiliated with the National Joint Apprenticeship Training Council. Journeyman training combines hands-on work with education on basic electricity.</p>
</td>
<td id="A4.T10.5.5.4.2" class="ltx_td ltx_align_right ltx_border_t">6</td>
</tr>
<tr id="A4.T10.5.6.5" class="ltx_tr">
<td id="A4.T10.5.6.5.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T10.5.6.5.1.1" class="ltx_p ltx_align_top">combustion process of a petrol engine is never perfect. Dangerous gases, such as nitrogen oxide, carbon monoxide and hydrocarbons will arise and it is the job of the catalytic converter to reduce these to safer emissions. These cat converters can fail by becoming clogged, or if the engine has bad exhaust valves or the plugs fail, causing unburned fuel to overheat the converter. Mettam’s Mufflers can resolve these issues with your Karr</p>
</td>
<td id="A4.T10.5.6.5.2" class="ltx_td ltx_align_right ltx_border_t">5</td>
</tr>
<tr id="A4.T10.5.7.6" class="ltx_tr">
<td id="A4.T10.5.7.6.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T10.5.7.6.1.1" class="ltx_p ltx_align_top">,ANDREW Find the ancestral town: Many a researcher is stuck behind records that say, BIRTHPLACE: IRELAND without saying where in Ireland, or whatever other country. Remember that your immigrant ancestor’s siblings probably were born in the same ancestral town, so check all o
<br class="ltx_break">f their records, too. Around 1900, the Roman Catholic churches reported marriages to the churches where the persons were baptised, and before the wedding, they would require a baptismal certificate from that church, without marriage notations, to make sure that the persons were no
<br class="ltx_break">t already married, ordained, or whatever, and were free to marry. Do check the Catholic records especially for ex loco and the home town. If your ancestor’s sister had a daughter who generated a marriage or death record saying, MOTHER’S BIRTHPLACE: and the exact town, then y
<br class="ltx_break">ou know where to start searching for records that will confirm it is your ancestor’s home town. BEWARE: Just because you find a family with the same names does not mean they are the same family, as they could very well be an unrelated family from a different town in the same an
<br class="ltx_break">cestral country. The webmaster has learned this. One clue was that one family was still having babies in Potenza city, Italy while the other was having babies in Colorado, U.S.A.</p>
</td>
<td id="A4.T10.5.7.6.2" class="ltx_td ltx_align_right ltx_border_t">2</td>
</tr>
<tr id="A4.T10.5.8.7" class="ltx_tr">
<td id="A4.T10.5.8.7.1" class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T10.5.8.7.1.1" class="ltx_p ltx_align_top">will not want to search for Power Washing companies in Wyoming on an extensive basis. The service personnel will be at your doorsteps through online or phone booking. The power wash solutions offered by us are matchless and you can compare with others in Winfield, IL. The power wash services offered by us are very economical. Gutter brightener will be applied which will be followed by cleaning through double scrub. The cleaning will be done by using a soft bristle brush. The bond and contaminants will be released in an effortless manner.</p>
</td>
<td id="A4.T10.5.8.7.2" class="ltx_td ltx_align_right ltx_border_t">1</td>
</tr>
<tr id="A4.T10.5.9.8" class="ltx_tr">
<td id="A4.T10.5.9.8.1" class="ltx_td ltx_align_justify ltx_border_bb ltx_border_r ltx_border_t" style="width:346.9pt;">
<p id="A4.T10.5.9.8.1.1" class="ltx_p ltx_align_top">Z3 Plus are valid in all major cities of India like Delhi, Gurgaon, Noida, Mumbai, Chennai, Bangalore, Hyderabad, Kolkata, Pune, Ahmedabad, Coimbatore, Lucknow, Trichy, Madurai, Trivandrum, Mysore, Jaipur, Chandigarh, Pondicherry, Bhopal, Patna, Bhubaneswar, Amritsar, Cochin, 
<br class="ltx_break">Allahabad, Srinagar, New Delhi, Surat, Ludhiana, Navi Mumbai, Ghaziabad, Bengaluru, Indore, Nagpur, Thane, Agra, Meerut, Ranchi. The delivery feasibility and charges may be varying, hence for them please check with the particular seller or store.</p>
</td>
<td id="A4.T10.5.9.8.2" class="ltx_td ltx_align_right ltx_border_bb ltx_border_t">1</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>A selection of substrings generated by XL-<span id="A4.T10.8.1" class="ltx_text ltx_font_smallcaps">Original</span> with no prompting (and top-<math id="A4.T10.3.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A4.T10.3.m1.1b"><mi id="A4.T10.3.m1.1.1" xref="A4.T10.3.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A4.T10.3.m1.1c"><ci id="A4.T10.3.m1.1.1.cmml" xref="A4.T10.3.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T10.3.m1.1d">k</annotation><annotation encoding="application/x-llamapun" id="A4.T10.3.m1.1e">italic_k</annotation></semantics></math> with <math id="A4.T10.4.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A4.T10.4.m2.1b"><mi id="A4.T10.4.m2.1.1" xref="A4.T10.4.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A4.T10.4.m2.1c"><ci id="A4.T10.4.m2.1.1.cmml" xref="A4.T10.4.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T10.4.m2.1d">k</annotation><annotation encoding="application/x-llamapun" id="A4.T10.4.m2.1e">italic_k</annotation></semantics></math>=50) that were identified by <span id="A4.T10.9.2" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> as being in C4 multiple times. The number of times each substring was found in C4 is given. We observe that most memorized generations tend to be from advertisements.</figcaption>
</figure>
<figure id="A4.T11" class="ltx_table">
<table id="A4.T11.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A4.T11.1.1.1" class="ltx_tr">
<th id="A4.T11.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">RealNews Url</th>
<th id="A4.T11.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"># Total</th>
<th id="A4.T11.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Frac Dups</th>
<th id="A4.T11.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">C4 Url</th>
<th id="A4.T11.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"># Total</th>
<th id="A4.T11.1.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Frac Dups</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A4.T11.1.2.1" class="ltx_tr">
<td id="A4.T11.1.2.1.1" class="ltx_td ltx_align_left ltx_border_t">medicalnewstoday.com.</td>
<td id="A4.T11.1.2.1.2" class="ltx_td ltx_align_right ltx_border_t">12</td>
<td id="A4.T11.1.2.1.3" class="ltx_td ltx_align_right ltx_border_rr ltx_border_t">1.00</td>
<td id="A4.T11.1.2.1.4" class="ltx_td ltx_align_left ltx_border_t">hairtechkearney.com</td>
<td id="A4.T11.1.2.1.5" class="ltx_td ltx_align_right ltx_border_t">4883</td>
<td id="A4.T11.1.2.1.6" class="ltx_td ltx_align_right ltx_border_t">1</td>
</tr>
<tr id="A4.T11.1.3.2" class="ltx_tr">
<td id="A4.T11.1.3.2.1" class="ltx_td ltx_align_left">dodbuzz.com</td>
<td id="A4.T11.1.3.2.2" class="ltx_td ltx_align_right">301</td>
<td id="A4.T11.1.3.2.3" class="ltx_td ltx_align_right ltx_border_rr">0.99</td>
<td id="A4.T11.1.3.2.4" class="ltx_td ltx_align_left">keywordsking.com</td>
<td id="A4.T11.1.3.2.5" class="ltx_td ltx_align_right">1786</td>
<td id="A4.T11.1.3.2.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.4.3" class="ltx_tr">
<td id="A4.T11.1.4.3.1" class="ltx_td ltx_align_left">undertheradar.military.com</td>
<td id="A4.T11.1.4.3.2" class="ltx_td ltx_align_right">187</td>
<td id="A4.T11.1.4.3.3" class="ltx_td ltx_align_right ltx_border_rr">0.97</td>
<td id="A4.T11.1.4.3.4" class="ltx_td ltx_align_left">sydneysitalianfruitshops.online</td>
<td id="A4.T11.1.4.3.5" class="ltx_td ltx_align_right">1178</td>
<td id="A4.T11.1.4.3.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.5.4" class="ltx_tr">
<td id="A4.T11.1.5.4.1" class="ltx_td ltx_align_left">q.usatoday.com</td>
<td id="A4.T11.1.5.4.2" class="ltx_td ltx_align_right">33</td>
<td id="A4.T11.1.5.4.3" class="ltx_td ltx_align_right ltx_border_rr">0.94</td>
<td id="A4.T11.1.5.4.4" class="ltx_td ltx_align_left">moewiki.usamimi.info</td>
<td id="A4.T11.1.5.4.5" class="ltx_td ltx_align_right">1001</td>
<td id="A4.T11.1.5.4.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.6.5" class="ltx_tr">
<td id="A4.T11.1.6.5.1" class="ltx_td ltx_align_left">ad-test.thirdage.com</td>
<td id="A4.T11.1.6.5.2" class="ltx_td ltx_align_right">354</td>
<td id="A4.T11.1.6.5.3" class="ltx_td ltx_align_right ltx_border_rr">0.94</td>
<td id="A4.T11.1.6.5.4" class="ltx_td ltx_align_left">swarovskijewelryoutlet.org</td>
<td id="A4.T11.1.6.5.5" class="ltx_td ltx_align_right">984</td>
<td id="A4.T11.1.6.5.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.7.6" class="ltx_tr">
<td id="A4.T11.1.7.6.1" class="ltx_td ltx_align_left">amp.nymag.com</td>
<td id="A4.T11.1.7.6.2" class="ltx_td ltx_align_right">15</td>
<td id="A4.T11.1.7.6.3" class="ltx_td ltx_align_right ltx_border_rr">0.93</td>
<td id="A4.T11.1.7.6.4" class="ltx_td ltx_align_left">forzadurto.org</td>
<td id="A4.T11.1.7.6.5" class="ltx_td ltx_align_right">980</td>
<td id="A4.T11.1.7.6.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.8.7" class="ltx_tr">
<td id="A4.T11.1.8.7.1" class="ltx_td ltx_align_left">citizenwire.com</td>
<td id="A4.T11.1.8.7.2" class="ltx_td ltx_align_right">1022</td>
<td id="A4.T11.1.8.7.3" class="ltx_td ltx_align_right ltx_border_rr">0.93</td>
<td id="A4.T11.1.8.7.4" class="ltx_td ltx_align_left">producerati.com</td>
<td id="A4.T11.1.8.7.5" class="ltx_td ltx_align_right">971</td>
<td id="A4.T11.1.8.7.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.9.8" class="ltx_tr">
<td id="A4.T11.1.9.8.1" class="ltx_td ltx_align_left">paycheck-chronicles.military.com</td>
<td id="A4.T11.1.9.8.2" class="ltx_td ltx_align_right">363</td>
<td id="A4.T11.1.9.8.3" class="ltx_td ltx_align_right ltx_border_rr">0.92</td>
<td id="A4.T11.1.9.8.4" class="ltx_td ltx_align_left">sourceryforge.org</td>
<td id="A4.T11.1.9.8.5" class="ltx_td ltx_align_right">908</td>
<td id="A4.T11.1.9.8.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.10.9" class="ltx_tr">
<td id="A4.T11.1.10.9.1" class="ltx_td ltx_align_left">product-reviews.net</td>
<td id="A4.T11.1.10.9.2" class="ltx_td ltx_align_right">73403</td>
<td id="A4.T11.1.10.9.3" class="ltx_td ltx_align_right ltx_border_rr">0.92</td>
<td id="A4.T11.1.10.9.4" class="ltx_td ltx_align_left">heavenz-kitchen.com</td>
<td id="A4.T11.1.10.9.5" class="ltx_td ltx_align_right">876</td>
<td id="A4.T11.1.10.9.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.11.10" class="ltx_tr">
<td id="A4.T11.1.11.10.1" class="ltx_td ltx_align_left">kitup.military.com</td>
<td id="A4.T11.1.11.10.2" class="ltx_td ltx_align_right">196</td>
<td id="A4.T11.1.11.10.3" class="ltx_td ltx_align_right ltx_border_rr">0.92</td>
<td id="A4.T11.1.11.10.4" class="ltx_td ltx_align_left">little-eclipse.com</td>
<td id="A4.T11.1.11.10.5" class="ltx_td ltx_align_right">822</td>
<td id="A4.T11.1.11.10.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.12.11" class="ltx_tr">
<td id="A4.T11.1.12.11.1" class="ltx_td ltx_align_left">gcaptain.com</td>
<td id="A4.T11.1.12.11.2" class="ltx_td ltx_align_right">33903</td>
<td id="A4.T11.1.12.11.3" class="ltx_td ltx_align_right ltx_border_rr">0.92</td>
<td id="A4.T11.1.12.11.4" class="ltx_td ltx_align_left">walops.com</td>
<td id="A4.T11.1.12.11.5" class="ltx_td ltx_align_right">819</td>
<td id="A4.T11.1.12.11.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.13.12" class="ltx_tr">
<td id="A4.T11.1.13.12.1" class="ltx_td ltx_align_left">dev.screenrant.com</td>
<td id="A4.T11.1.13.12.2" class="ltx_td ltx_align_right">70</td>
<td id="A4.T11.1.13.12.3" class="ltx_td ltx_align_right ltx_border_rr">0.91</td>
<td id="A4.T11.1.13.12.4" class="ltx_td ltx_align_left">16thstlaunderland.com</td>
<td id="A4.T11.1.13.12.5" class="ltx_td ltx_align_right">713</td>
<td id="A4.T11.1.13.12.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.14.13" class="ltx_tr">
<td id="A4.T11.1.14.13.1" class="ltx_td ltx_align_left">live.swissinfo.ch</td>
<td id="A4.T11.1.14.13.2" class="ltx_td ltx_align_right">66</td>
<td id="A4.T11.1.14.13.3" class="ltx_td ltx_align_right ltx_border_rr">0.91</td>
<td id="A4.T11.1.14.13.4" class="ltx_td ltx_align_left">theroyalstarinfo.com</td>
<td id="A4.T11.1.14.13.5" class="ltx_td ltx_align_right">696</td>
<td id="A4.T11.1.14.13.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.15.14" class="ltx_tr">
<td id="A4.T11.1.15.14.1" class="ltx_td ltx_align_left">news.theepochtimes.com</td>
<td id="A4.T11.1.15.14.2" class="ltx_td ltx_align_right">82</td>
<td id="A4.T11.1.15.14.3" class="ltx_td ltx_align_right ltx_border_rr">0.87</td>
<td id="A4.T11.1.15.14.4" class="ltx_td ltx_align_left">code4kt.com</td>
<td id="A4.T11.1.15.14.5" class="ltx_td ltx_align_right">684</td>
<td id="A4.T11.1.15.14.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.16.15" class="ltx_tr">
<td id="A4.T11.1.16.15.1" class="ltx_td ltx_align_left">opinion.toledoblade.com</td>
<td id="A4.T11.1.16.15.2" class="ltx_td ltx_align_right">986</td>
<td id="A4.T11.1.16.15.3" class="ltx_td ltx_align_right ltx_border_rr">0.87</td>
<td id="A4.T11.1.16.15.4" class="ltx_td ltx_align_left">nflfalconsjerseys.us</td>
<td id="A4.T11.1.16.15.5" class="ltx_td ltx_align_right">682</td>
<td id="A4.T11.1.16.15.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.17.16" class="ltx_tr">
<td id="A4.T11.1.17.16.1" class="ltx_td ltx_align_left">cdn.moneytalksnews.com</td>
<td id="A4.T11.1.17.16.2" class="ltx_td ltx_align_right">121</td>
<td id="A4.T11.1.17.16.3" class="ltx_td ltx_align_right ltx_border_rr">0.86</td>
<td id="A4.T11.1.17.16.4" class="ltx_td ltx_align_left">quiltingbeeshop.com</td>
<td id="A4.T11.1.17.16.5" class="ltx_td ltx_align_right">676</td>
<td id="A4.T11.1.17.16.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.18.17" class="ltx_tr">
<td id="A4.T11.1.18.17.1" class="ltx_td ltx_align_left">amp.fox23.com</td>
<td id="A4.T11.1.18.17.2" class="ltx_td ltx_align_right">14</td>
<td id="A4.T11.1.18.17.3" class="ltx_td ltx_align_right ltx_border_rr">0.86</td>
<td id="A4.T11.1.18.17.4" class="ltx_td ltx_align_left">ulifeinsurancemiami.com</td>
<td id="A4.T11.1.18.17.5" class="ltx_td ltx_align_right">675</td>
<td id="A4.T11.1.18.17.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.19.18" class="ltx_tr">
<td id="A4.T11.1.19.18.1" class="ltx_td ltx_align_left">sales.rollingstone.com</td>
<td id="A4.T11.1.19.18.2" class="ltx_td ltx_align_right">20</td>
<td id="A4.T11.1.19.18.3" class="ltx_td ltx_align_right ltx_border_rr">0.85</td>
<td id="A4.T11.1.19.18.4" class="ltx_td ltx_align_left">wowkeyword.com</td>
<td id="A4.T11.1.19.18.5" class="ltx_td ltx_align_right">673</td>
<td id="A4.T11.1.19.18.6" class="ltx_td ltx_align_right">1</td>
</tr>
<tr id="A4.T11.1.20.19" class="ltx_tr">
<td id="A4.T11.1.20.19.1" class="ltx_td ltx_align_left ltx_border_bb">ftp.screenrant.com</td>
<td id="A4.T11.1.20.19.2" class="ltx_td ltx_align_right ltx_border_bb">20</td>
<td id="A4.T11.1.20.19.3" class="ltx_td ltx_align_right ltx_border_bb ltx_border_rr">0.85</td>
<td id="A4.T11.1.20.19.4" class="ltx_td ltx_align_left ltx_border_bb">taspetro.com</td>
<td id="A4.T11.1.20.19.5" class="ltx_td ltx_align_right ltx_border_bb">671</td>
<td id="A4.T11.1.20.19.6" class="ltx_td ltx_align_right ltx_border_bb">1</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>On the left, we show the URLs that had the greatest proportion of examples marked as near-duplicates by <span id="A4.T11.4.1" class="ltx_text ltx_font_smallcaps">NearDup</span>(filtered to URLs which occurred at least 10 times). On the right, we show the 20 most frequent URLs in C4 for which all examples were marked as near-duplicates by <span id="A4.T11.5.2" class="ltx_text ltx_font_smallcaps">NearDup</span>.</figcaption>
</figure>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>More Results</h2>

<section id="A5.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Qualitative Examples.</h5>

<div id="A5.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A5.SS0.SSS0.Px1.p1.1" class="ltx_p">Table <a href="#A4.T8" title="Table 8 ‣ Appendix D Energy Consumption ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows several examples of pairs of documents in C4 whose edit distance is close to our chosen edit similarity threshold of 0.8.
Table <a href="#A4.T9" title="Table 9 ‣ Appendix D Energy Consumption ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows substrings which were identified by <span id="A5.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> as being in C4 more than once.
Table <a href="#A4.T10" title="Table 10 ‣ Appendix D Energy Consumption ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> shows several examples of unprompted generations which were identified as memorized are shown.</p>
</div>
<figure id="A5.F6" class="ltx_figure"><img src="/html/2107.06499/assets/x7.png" id="A5.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="484" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Memorized continuations distribution</figcaption>
</figure>
</section>
<section id="A5.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Distribution of memorization.</h5>

<div id="A5.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="A5.SS0.SSS0.Px2.p1.1" class="ltx_p">Figure <a href="#A5.F6" title="Figure 6 ‣ Qualitative Examples. ‣ Appendix E More Results ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the distribution in memorization amount over all generated sequences when using four types of prompting: train example with duplicates in train, train examples without any duplicates, validation examples with duplicates in train, and validation examples without any duplicates.</p>
</div>
</section>
<section id="A5.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">URLs with many duplicates.</h5>

<div id="A5.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="A5.SS0.SSS0.Px3.p1.1" class="ltx_p">Table <a href="#A4.T11" title="Table 11 ‣ Appendix D Energy Consumption ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> shows the URLs had the largest proportion of examples identified by <span id="A5.SS0.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_smallcaps">NearDup</span> as near-duplicates.
For C4, these tend to be websites that sell many similar products and thus have a large amount of templated text.
For RealNews, content aggregators seem especially common.</p>
</div>
</section>
<section id="A5.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">
<span id="A5.SS0.SSS0.Px4.1.1" class="ltx_text ltx_font_smallcaps">NearDup</span> cluster sizes.</h5>

<div id="A5.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="A5.SS0.SSS0.Px4.p1.1" class="ltx_p">Figure <a href="#A5.F8" title="Figure 8 ‣ Perplexity on LM1B. ‣ Appendix E More Results ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows the distribution of cluster sizes from running <span id="A5.SS0.SSS0.Px4.p1.1.1" class="ltx_text ltx_font_smallcaps">NearDup</span> on RealNews, LM1B, and Wiki-40B (results for C4 are in Figure <a href="#S4.F1" title="Figure 1 ‣ 4.2 Approximate Matching with MinHash ‣ 4 Methods for Identifying Duplicates ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> the main paper).</p>
</div>
</section>
<section id="A5.SS0.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Dataset Sizes</h5>

<div id="A5.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="A5.SS0.SSS0.Px5.p1.1" class="ltx_p">Table <a href="#A5.T13" title="Table 13 ‣ Perplexity on LM1B. ‣ Appendix E More Results ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a> gives the size in BPE tokens and in examples of each dataset before and after deduplication.
Because most datasets were already deduplicated of exact matches during their creation, <span id="A5.SS0.SSS0.Px5.p1.1.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span>deduplication does not actually remove any examples.</p>
</div>
</section>
<section id="A5.SS0.SSS0.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Perplexity on LM1B.</h5>

<div id="A5.SS0.SSS0.Px6.p1" class="ltx_para">
<p id="A5.SS0.SSS0.Px6.p1.1" class="ltx_p">Figure&nbsp;<a href="#A5.F7" title="Figure 7 ‣ Perplexity on LM1B. ‣ Appendix E More Results ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> is the same as Figure&nbsp;<a href="#S6.F2" title="Figure 2 ‣ 6.1 Model Perplexity ‣ 6 Impact on Trained Models ‣ Deduplicating Training Data Makes Language Models Better" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> of the main paper, except with perplexity on LM1B included.
LM1B was omitted from the main paper’s figure in order to improve readability.</p>
</div>
<figure id="A5.F7" class="ltx_figure"><span id="A5.F7.pic1" class="ltx_picture ltx_centering" style="width:216.1pt;height:110.6pt;">\begin{overpic}[width=216.81pt]{figs/eval-base-ppl_withLM1B.pdf}
\put(1.0,1.0){{(a)} Base model}
\end{overpic}</span><span id="A5.F7.pic2" class="ltx_picture ltx_centering" style="width:216.1pt;height:110.6pt;">\begin{overpic}[width=216.81pt]{figs/eval-xl-ppl_withLM1B.pdf}
\put(1.0,1.0){{(b)} XL model}
\end{overpic}</span>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Impact of deduplicating the training set on validation perplexity. In <span id="A5.F7.3.1" class="ltx_text ltx_font_bold">(a)</span>, we plot the results from T5 base (110M parameters) across three training runs with different random initializations. The black bar represent the lowest perplexity to the highest perplexity, and the colored bar the median perplexity.
In <span id="A5.F7.4.2" class="ltx_text ltx_font_bold">(b)</span>, we plot the results from T5 XL (1.5B parameters).</figcaption>
</figure>
<figure id="A5.T12" class="ltx_table">
<table id="A5.T12.3" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A5.T12.3.1.1" class="ltx_tr">
<th id="A5.T12.3.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Training Dataset:</th>
<th id="A5.T12.3.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">C4-<span id="A5.T12.3.1.1.2.1" class="ltx_text ltx_font_smallcaps">Original</span></th>
<th id="A5.T12.3.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">C4-<span id="A5.T12.3.1.1.3.1" class="ltx_text ltx_font_smallcaps">NearDup</span></th>
<th id="A5.T12.3.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">C4-<span id="A5.T12.3.1.1.4.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span></th>
</tr>
<tr id="A5.T12.3.2.2" class="ltx_tr">
<th id="A5.T12.3.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row">Epoch:</th>
<th id="A5.T12.3.2.2.2" class="ltx_td ltx_align_right ltx_th ltx_th_column">1</th>
<th id="A5.T12.3.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">2</th>
<th id="A5.T12.3.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">1</th>
<th id="A5.T12.3.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">2</th>
<th id="A5.T12.3.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">1</th>
<th id="A5.T12.3.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column">2</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A5.T12.3.3.1" class="ltx_tr">
<th id="A5.T12.3.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">No prompt</th>
<td id="A5.T12.3.3.1.2" class="ltx_td ltx_align_right ltx_border_t">1.93%</td>
<td id="A5.T12.3.3.1.3" class="ltx_td ltx_align_right ltx_border_t">1.57%</td>
<td id="A5.T12.3.3.1.4" class="ltx_td ltx_align_right ltx_border_t">0.19%</td>
<td id="A5.T12.3.3.1.5" class="ltx_td ltx_align_right ltx_border_t">0.26%</td>
<td id="A5.T12.3.3.1.6" class="ltx_td ltx_align_right ltx_border_t">0.14%</td>
<td id="A5.T12.3.3.1.7" class="ltx_td ltx_align_right ltx_border_t">0.17%</td>
</tr>
<tr id="A5.T12.3.4.2" class="ltx_tr">
<th id="A5.T12.3.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Duplicate Train Prompts</th>
<td id="A5.T12.3.4.2.2" class="ltx_td ltx_align_right">35.88%</td>
<td id="A5.T12.3.4.2.3" class="ltx_td ltx_align_right">34.34%</td>
<td id="A5.T12.3.4.2.4" class="ltx_td ltx_align_right">3.34%</td>
<td id="A5.T12.3.4.2.5" class="ltx_td ltx_align_right">3.15%</td>
<td id="A5.T12.3.4.2.6" class="ltx_td ltx_align_right">5.71%</td>
<td id="A5.T12.3.4.2.7" class="ltx_td ltx_align_right">4.67%</td>
</tr>
<tr id="A5.T12.3.5.3" class="ltx_tr">
<th id="A5.T12.3.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Unique Train Prompt</th>
<td id="A5.T12.3.5.3.2" class="ltx_td ltx_align_right">0.42%</td>
<td id="A5.T12.3.5.3.3" class="ltx_td ltx_align_right">0.41%</td>
<td id="A5.T12.3.5.3.4" class="ltx_td ltx_align_right">0.42%</td>
<td id="A5.T12.3.5.3.5" class="ltx_td ltx_align_right">0.41%</td>
<td id="A5.T12.3.5.3.6" class="ltx_td ltx_align_right">0.22%</td>
<td id="A5.T12.3.5.3.7" class="ltx_td ltx_align_right">0.23%</td>
</tr>
<tr id="A5.T12.3.6.4" class="ltx_tr">
<th id="A5.T12.3.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Duplicate Test Prompt</th>
<td id="A5.T12.3.6.4.2" class="ltx_td ltx_align_right">16.27%</td>
<td id="A5.T12.3.6.4.3" class="ltx_td ltx_align_right">15.32%</td>
<td id="A5.T12.3.6.4.4" class="ltx_td ltx_align_right">1.61%</td>
<td id="A5.T12.3.6.4.5" class="ltx_td ltx_align_right">1.52%</td>
<td id="A5.T12.3.6.4.6" class="ltx_td ltx_align_right">0.34%</td>
<td id="A5.T12.3.6.4.7" class="ltx_td ltx_align_right">0.25%</td>
</tr>
<tr id="A5.T12.3.7.5" class="ltx_tr">
<th id="A5.T12.3.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Unique Test Prompt</th>
<td id="A5.T12.3.7.5.2" class="ltx_td ltx_align_right ltx_border_bb">0.25%</td>
<td id="A5.T12.3.7.5.3" class="ltx_td ltx_align_right ltx_border_bb">0.22%</td>
<td id="A5.T12.3.7.5.4" class="ltx_td ltx_align_right ltx_border_bb">0.21%</td>
<td id="A5.T12.3.7.5.5" class="ltx_td ltx_align_right ltx_border_bb">0.23%</td>
<td id="A5.T12.3.7.5.6" class="ltx_td ltx_align_right ltx_border_bb">0.03%</td>
<td id="A5.T12.3.7.5.7" class="ltx_td ltx_align_right ltx_border_bb">0.08%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>Percentage of tokens in 100k generations that were part of memorized substring according to <span id="A5.T12.5.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span>.
Models trained with approximate or exact deduplication have
<math id="A5.T12.2.m1.1" class="ltx_math_unparsed" alttext="10\times" display="inline"><semantics id="A5.T12.2.m1.1b"><mrow id="A5.T12.2.m1.1c"><mn id="A5.T12.2.m1.1.1">10</mn><mo lspace="0.222em" id="A5.T12.2.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="A5.T12.2.m1.1d">10\times</annotation><annotation encoding="application/x-llamapun" id="A5.T12.2.m1.1e">10 ×</annotation></semantics></math> less memorization than the model trained on the original (non-deduplicated) dataset.</figcaption>
</figure>
<figure id="A5.T13" class="ltx_table">
<table id="A5.T13.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A5.T13.1.1.1" class="ltx_tr">
<th id="A5.T13.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_tt"></th>
<td id="A5.T13.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="3">Final train set size in tokens</td>
<td id="A5.T13.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="3">Final train set size in examples</td>
</tr>
<tr id="A5.T13.1.2.2" class="ltx_tr">
<th id="A5.T13.1.2.2.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="A5.T13.1.2.2.2" class="ltx_td ltx_align_right"><span id="A5.T13.1.2.2.2.1" class="ltx_text ltx_font_smallcaps">Original</span></td>
<td id="A5.T13.1.2.2.3" class="ltx_td ltx_align_right"><span id="A5.T13.1.2.2.3.1" class="ltx_text ltx_font_smallcaps">NearDup</span></td>
<td id="A5.T13.1.2.2.4" class="ltx_td ltx_align_right ltx_border_r"><span id="A5.T13.1.2.2.4.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span></td>
<td id="A5.T13.1.2.2.5" class="ltx_td ltx_align_right"><span id="A5.T13.1.2.2.5.1" class="ltx_text ltx_font_smallcaps">Original</span></td>
<td id="A5.T13.1.2.2.6" class="ltx_td ltx_align_right"><span id="A5.T13.1.2.2.6.1" class="ltx_text ltx_font_smallcaps">NearDup</span></td>
<td id="A5.T13.1.2.2.7" class="ltx_td ltx_align_right"><span id="A5.T13.1.2.2.7.1" class="ltx_text ltx_font_smallcaps">ExactSubstr</span></td>
</tr>
<tr id="A5.T13.1.3.3" class="ltx_tr">
<th id="A5.T13.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">C4</th>
<td id="A5.T13.1.3.3.2" class="ltx_td ltx_align_right ltx_border_t">177.3B</td>
<td id="A5.T13.1.3.3.3" class="ltx_td ltx_align_right ltx_border_t">173.7B</td>
<td id="A5.T13.1.3.3.4" class="ltx_td ltx_align_right ltx_border_r ltx_border_t">165.4B</td>
<td id="A5.T13.1.3.3.5" class="ltx_td ltx_align_right ltx_border_t">364.87M</td>
<td id="A5.T13.1.3.3.6" class="ltx_td ltx_align_right ltx_border_t">350.48M</td>
<td id="A5.T13.1.3.3.7" class="ltx_td ltx_align_right ltx_border_t">350.48M</td>
</tr>
<tr id="A5.T13.1.4.4" class="ltx_tr">
<th id="A5.T13.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Real News</th>
<td id="A5.T13.1.4.4.2" class="ltx_td ltx_align_right">24.7B</td>
<td id="A5.T13.1.4.4.3" class="ltx_td ltx_align_right">22.4B</td>
<td id="A5.T13.1.4.4.4" class="ltx_td ltx_align_right ltx_border_r">20.1B</td>
<td id="A5.T13.1.4.4.5" class="ltx_td ltx_align_right">31.16M</td>
<td id="A5.T13.1.4.4.6" class="ltx_td ltx_align_right">28.39M</td>
<td id="A5.T13.1.4.4.7" class="ltx_td ltx_align_right">28.39M</td>
</tr>
<tr id="A5.T13.1.5.5" class="ltx_tr">
<th id="A5.T13.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">LM1B</th>
<td id="A5.T13.1.5.5.2" class="ltx_td ltx_align_right">1.0B</td>
<td id="A5.T13.1.5.5.3" class="ltx_td ltx_align_right">0.94B</td>
<td id="A5.T13.1.5.5.4" class="ltx_td ltx_align_right ltx_border_r">0.90B</td>
<td id="A5.T13.1.5.5.5" class="ltx_td ltx_align_right">30.30M</td>
<td id="A5.T13.1.5.5.6" class="ltx_td ltx_align_right">29.87M</td>
<td id="A5.T13.1.5.5.7" class="ltx_td ltx_align_right">30.16M</td>
</tr>
<tr id="A5.T13.1.6.6" class="ltx_tr">
<th id="A5.T13.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Wiki40B</th>
<td id="A5.T13.1.6.6.2" class="ltx_td ltx_align_right ltx_border_bb">2.25B</td>
<td id="A5.T13.1.6.6.3" class="ltx_td ltx_align_right ltx_border_bb">2.24B</td>
<td id="A5.T13.1.6.6.4" class="ltx_td ltx_align_right ltx_border_bb ltx_border_r">2.19B</td>
<td id="A5.T13.1.6.6.5" class="ltx_td ltx_align_right ltx_border_bb">2.93M</td>
<td id="A5.T13.1.6.6.6" class="ltx_td ltx_align_right ltx_border_bb">2.91M</td>
<td id="A5.T13.1.6.6.7" class="ltx_td ltx_align_right ltx_border_bb">2.93M</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 13: </span>Each row shows the size in tokens (according to our 50k BPE vocab) and in examples of a train set in its original form, with <span id="A5.T13.4.1" class="ltx_text ltx_font_smallcaps">NearDup</span> deduplication, and with <span id="A5.T13.5.2" class="ltx_text ltx_font_smallcaps">ExactSubstr</span> deduplication.</figcaption>
</figure>
<figure id="A5.F8" class="ltx_figure">
<div class="ltx_flex_figure">

<div class="ltx_flex_cell 
                  ltx_flex_size_1"><img src="/html/2107.06499/assets/x8.png" id="A5.F8.g1" class="ltx_graphics ltx_centering ltx_flex_size_1 ltx_img_landscape" width="830" height="449" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell 
                  ltx_flex_size_1"><img src="/html/2107.06499/assets/x9.png" id="A5.F8.g2" class="ltx_graphics ltx_centering ltx_flex_size_1 ltx_img_landscape" width="830" height="449" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell 
                  ltx_flex_size_1"><img src="/html/2107.06499/assets/x10.png" id="A5.F8.g3" class="ltx_graphics ltx_centering ltx_flex_size_1 ltx_img_landscape" width="830" height="457" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>The distribution of near-duplicate cluster sizes from running <span id="A5.F8.2.1" class="ltx_text ltx_font_smallcaps">NearDup</span> on each dataset.</figcaption>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2107.06498" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2107.06499" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2107.06499">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2107.06499" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2107.06500" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Dec 25 15:11:31 2022 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span style="font-size:70%;position:relative; bottom:2.2pt;">A</span>T<span style="position:relative; bottom:-0.4ex;">E</span></span><span class="ltx_font_smallcaps">xml</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>