# 학습 데이터 중복으로 인해 언어 모델이 개선됨

Katherine Lee1\(\dagger\)

Daphne Ippolito1\(\star\)\(\ddagger\)

Andrew Nystrom\(\dagger\)

Chiyuan Zhang\(\dagger\)

**Douglas Eck\(\dagger\)**

**Chris Callison-Burch\(\ddagger\)**

**Nicholas Carlini\(\dagger\)**

동일 기여도 \ (\dagger\) Google Research, Brain Team. \ (\ddagger\) 펜실베니아 대학교. 캐서린리@google.com 및 다프네이@seas.upenn.edu에 해당합니다.

###### Abstract

기존 언어 모델링 데이터 세트에는 거의 중복되지 않는 예제와 긴 반복 부분 문자열이 많이 포함되어 있음을 알 수 있다. 그 결과 학습 데이터 셋에서 학습한 언어 모델 출력의 \(1\%\) 이상이 학습 데이터로부터 베바텀으로 복사된다. 학습 데이터셋을 중복제거할 수 있는 두 가지 도구를 개발한다. 예를 들어 C4에서 단일 61단어 영어 문장이 \(60{,}000\)회 이상 반복된다. 중복제거를 통해 암기된 텍스트를 10배 덜 자주 방출하는 모델을 훈련할 수 있고 동일하거나 더 나은 정확도를 달성하기 위해 더 적은 훈련 단계를 필요로 한다. 또한 트레인-테스트 중첩을 줄일 수 있으며, 이는 표준 데이터 세트의 검증 세트의 \(4\%\) 이상에 영향을 미치므로 보다 정확한 평가가 가능하다. 중복 제거 코드는 [https://github.com/google-research/deduplicate-text-datasets](https://github.com/google-research/deduplicate-text-datasets)에서 릴리스됩니다.

## 1 Introduction

자연어 처리의 최근 진보의 핵심 요소는 점점 더 큰 언어 모델을 훈련하는 데 사용되는 대규모 텍스트 말뭉치의 개발이다. 이러한 데이터 세트는 지난 몇 년 동안 단일 기가바이트에서 테라바이트까지 성장했다(Chelba et al., 2013; Xue et al., 2020; Graff et al., 2003; Brown et al., 2020). 대용량 데이터 세트에 대한 수동 검토 및 큐레이션을 수행하는 것은 너무 비싸기 때문에, 그들은 더 작은 선행자들에 비해 품질이 저하되는 경향이 있다. 학습된 모델이 훈련 데이터에 존재하는 편향을 반영하기 때문에 이는 복잡성 및 검증 손실과 같은 메트릭을 훨씬 뛰어넘는 의미를 갖는다(Bender et al., 2021; Wallace et al., 2019; Sheng et al., 2020). 따라서 이러한 데이터 세트를 양적 및 질적으로 이해하는 것은 그 자체로 연구 과제이다(Dodge et al., 2021).

우리는 한 가지 특정 편향 소스, 중복된 훈련 예가 만연해 있음을 보여주며, 우리가 연구한 4개의 일반적인 NLP 데이터 세트 모두 중복을 포함했다. 또한 4개의 해당 검증 세트 모두 훈련 세트에 복제된 텍스트를 포함했다. 순진한 중복 제거는 간단하지만(그리고 우리가 고려하는 데이터 세트는 이미 일부 순진한 형태의 중복 제거를 수행함), 대규모로 철저한 중복 제거를 수행하는 것은 계산적으로 어렵고 정교한 기술을 필요로 한다.

중복된 학습 데이터를 탐지하고 제거하는 두 가지 확장 가능한 기술을 제안한다. _ Exact_ 부분 문자열 매칭은 반복되는 verbatim 문자열을 식별한다. 이를 통해 훈련 예제의 일부만 중복되는 경우(SS4.1)를 식별할 수 있습니다. _ Approximate_ 풀 문서 매칭은 해시 기반 기법(Broder, 1997)을 사용하여 높은 \(n\)-그램 중첩(SS4.2)을 갖는 문서 쌍을 식별한다.

우리는 완전히 중복 제거된 데이터 세트에 대한 훈련의 네 가지 뚜렷한 이점을 식별한다.

1. 표준 데이터 세트(예: C4)에 대해 훈련된 모델에서 프롬프트되지 않고 방출된 토큰의 \(1\%\ 이상)은 15억 매개 변수 모델이 훈련된 350GB 데이터 세트보다 훨씬 작음에도 불구하고 암기된 시퀀스의 일부이다(SS6.2 참조). 학습 데이터 셋을 중복 제거함으로써 암기된 학습 데이터를 방출하는 비율을 \(10\times\)만큼 줄인다.
2. Train-test overlap은 중복되지 않은 데이터셋에서 일반적이다. 예를 들어, 훈련 데이터 세트에서 \(61{,}036\)회, 검증 세트에서 \(61\)회 반복되는 C4 (Raffel 등, 2020)에서 _61-word sequence_1을 찾습니다.

이 트레인 테스트 세트는 연구자가 모델 정확도를 과대평가하게 할 뿐만 아니라 의도적으로 훈련 데이터 세트를 과대평가하는 모델 및 하이퍼파라미터에 대한 모델 선택을 편향시킨다.
3. 중복 제거 데이터 세트에 대한 학습 모델이 더 효율적입니다. 프레임워크를 사용하여 데이터 세트를 처리하려면 CPU 전용 선형 시간 알고리즘이 필요합니다. 따라서 이러한 데이터셋은 중복제거 런타임 자체를 포함하여 최대 \(19\%\) 더 작기 때문에 중복제거 데이터셋에 대한 훈련은 시간, 달러 및 환경 측면에서 훈련 비용을 직접적으로 감소시킨다(Bender et al., 2021; Strubell et al., 2019; Patterson et al., 2021).
4. 훈련 데이터를 중복하는 것은 당혹감을 해치지 않는다: 중복되지 않은 데이터 세트에 트레이닝된 모델들은 원래의 데이터 세트에 트레이닝된 베이스라인 모델들에 비해 더 나쁜 당혹감을 갖지 않는다. 일부 경우에 중복제거는 복잡도를 최대 \(10\%\)까지 감소시킨다. 또한, 최근의 LMs들은 전형적으로 단지 몇 개의 에포크들에 대한 트레이닝으로 제한되기 때문에(Radford et al., 2019; Raffel et al., 2020), 더 높은 품질의 데이터에 대한 트레이닝에 의해 모델들이 더 높은 정확도에 더 빨리 도달할 수 있다.

요약하자면, 데이터 복제는 상당한 이점을 제공하고 관찰된 단점은 없다. 이 논문의 나머지 부분에서는 SS4에서 텍스트 중복 제거 프레임워크를 제시하고, SS5에서 공통 NLP 데이터 세트(예: C4, Wiki-40B, LM1B)의 중복 콘텐츠 정도를 연구한다. 그리고 중복 제거가 테스트 복잡도(SS6.1) 및 암기 콘텐츠 방출 빈도(SS6.2)에 미치는 영향을 조사한다. 마지막으로, 열차와 시험/검증 분할(SS6.3)의 중첩으로 인해 기존 출시된 모델의 복잡도가 어느 정도 왜곡되었는지 분석한다.

## 2 관련 작업

대용량 언어 모델 데이터 세트.우리는 우리의 결과가 모델 아키텍처와 무관하다고 생각하지만, 개방형 텍스트 생성을 위해 훈련된 트랜스포머 기반 디코더 전용 언어 모델(Vaswani et al., 2017)에 대한 분석을 수행한다. 이러한 최신 모델은 인터넷 텍스트에 대해 학습됩니다. 예를 들어, 모델 Radford 등(2019)의 GPT-2 계열은 Reddit에서 순위가 높은 웹 문서의 데이터 세트인 WebText에서 학습되지만 이 데이터 세트는 공개적으로 사용할 수 없습니다. 공통 데이터 세트 시작점은 공용 웹 페이지의 인덱스인 CommonCrawl입니다. CommonCrawl에서 트레이닝된 모델들 중에는 책 데이터세트들의 추가와 함께 GPT-3(Brown et al., 2020), RealNews라고 불리는 뉴스 도메인들로 필터링된 제한된 서브세트 상에서 GROVER(Zellers et al., 2019), C4라고 불리는 세정된 버전의 공통 크롤에서 T5(Raffel et al., 2020)가 포함된다. 다른 모델들은 더 큐레이팅된 인터넷 소스들에서 트레이닝되는데, 예를 들어 Guo et al.(2020)은 단일 언어 141.4M 파라미터 언어 모델들을 트레이닝하기 위해 40개의 상이한 언어들로부터 고품질의 프로세싱된 Wikipedia 텍스트를 사용하였다. 영어가 아닌 모델은 반드시 서로 다른 데이터셋을 사용한다; Zeng et al. (2021)은 CommonCrawl 및 기타 소스로부터 깨끗하고 필터링된 중국어 문서의 비공개 코퍼스에서 훈련된 최대 200B 파라미터를 가진 모델 패밀리인 PANGU-\(\alpha\)를 도입했다. 이러한 데이터 세트의 대부분은 공개되지 않기 때문에 평가에 일반적으로 사용되는 더 작은 데이터 세트인 1억 단어 언어 모델 벤치마크(Chelba et al., 2013)뿐만 아니라 위키-40B, C4 및 RealNews의 세 가지를 중복한다.

다운스트림 작업의 오염.모델이 인터넷을 크롤링하여 구성된 데이터 세트에 대해 훈련될 때 모델은 다운스트림 대상 작업의 테스트 세트에 대해 훈련될 수 있다. 예를 들어 Radford et al.(2019, SS4)은 GPT-2의 훈련 세트와 평가에 사용된 데이터 세트 사이의 8-그램 중첩을 식별하기 위해 사후 분석을 수행했으며 Dodge et al.(2021)은 C4를 분석하여 다양한 표준 작업에 대한 테스트 예제의 최대 14.4%가 데이터 세트에서 버바텀(대문자 및 구두점을 위한 정규화)으로 발견되었음을 발견했다. 보다 적극적인 접근 방식은 오염된 데이터를 제거합니다. Trinh and Le (2018, 부록 B)는 평가에 사용된 상식 추론과 상당히 겹치는 CommonCrawl 기반 열차 집합에서 문서를 제거했다. 그리고 GPT-3(Brown et al., 2020, SS5)은 임의의 평가예와 13-그램 오버랩을 갖는 임의의 열차집합예들을 보수적으로 필터링함으로써 그들의 훈련데이터로부터 역방향 및 다운스트림 평가예들을 제거하였다. 작업의 최대 \(90\%\)가 잠재적으로 오염된 것으로 표시되었습니다.

본 연구에서는 사전 훈련된 모델의 중복 텍스트가 다운스트림 벤치마크 작업에 미치는 영향에 초점을 맞추지 않고 LM 훈련 및 검증 세트의 중복 텍스트가 모델 복잡성에 미치는 영향과 생성된 텍스트가 암기된 내용을 포함하는 정도를 다룬다.

훈련 데이터를 암기하는 것.데이터 암기의 프라이버시 위험, 예를 들어 유효한 전화 번호 및 IRC 사용자 이름과 같은 민감한 데이터를 추출하는 능력은 Carlini 등(2020)에 의해 강조된다. 그들의 논문은 GPT-2가 훈련 집합에서 방출한 604개의 샘플을 찾는 반면, 대부분의 모델이 방출하는 데이터의 _over_\(1\%\)가 훈련 데이터를 암기한다는 것을 보여준다. 컴퓨터 비전에서, 트레이닝 데이터의 암기는 판별 및 생성 모델 모두에 대해 다양한 각도에서 연구되어 왔다(예를 들어, Arpit 등, 2017; Webster 등, 2019; Feldman and Zhang, 2020; Stephenson 등, 2021; Tetewak 등, 2021).

BERT와 같은 인기 있는 모델을 훈련하기 위해 사용된 Book Corpus Zhu et al.(2015)은 Bandy와 Vincent(2021)에 따르면 상당한 양의 정확한 중복 문서를 가지고 있다. Allamanis (2019)는 코드 데이터 세트의 중복 사례가 코드 이해 작업에 대한 성능 악화를 초래한다는 것을 보여준다.

## 3 언어 모델링 데이터 세트

자연어 생성 시스템 학습, 범용 사전 학습 모델 생성 및 언어 모델 벤치마킹에 사용된 다양한 크기의 4개의 데이터 세트에서 중복 텍스트의 존재를 분석한다. 본 논문은 그 자체를 영어 데이터셋으로 제한하지만, 비영어 데이터셋은 유사한 이슈로 인해 어려움을 겪으며 중복 제거의 이점을 얻을 수 있을 것으로 기대한다.

Wikipedia (Wiki-40B)는 다국어 세척된 Wikipedia text Guo et al.(2020)로 구성된다. 우리는 평균 길이가 768 BPE 토큰인 2.9M 위키피디아 페이지가 포함된 영어 부분을 취한다. 데이터 세트 작성자는 리디렉션 페이지(예: "해바라기"에서 "헬리안투스"로)를 제거하는 것 외에 중복 제거가 수행되었음을 나타내지 않는다.

100억 워드 벤치마크(LM1B)는 30M 문장의 뉴스 해설 Chelba 등(2013)을 포함하고 있다. 우리가 분석하는 다른 데이터 세트와 달리 LM1B의 예는 다중 문장 문서가 아닌 한 문장 길이이다. 평균 예제 길이는 32 BPE 토큰입니다. 이 데이터 세트는 언어 모델을 벤치마킹하는 데 매우 표준적이지만 Radford 등(2019, Sec 4)은 테스트 세트와 기차 세트가 13.2% 겹친다는 점에 주목한다.

거대 청소 공통 크롤(C4)은 360M 웹 문서로 구성되며, 평균 길이는 486 BPE 토큰 Raffel 등(2020)이다. C4는 미세 조정된 다운스트림 태스크에서 널리 사용되는 인코더-디코더 모델 세트인 T5에 대한 사전 훈련 데이터세트로 도입되었다. 데이터 세트는 이전 두 데이터 세트보다 더 정교한 프로세스에서 이전에 중복 제거되었다. 각 단락은 해시되었고 해시 충돌을 초래하는 단락은 제거되었다. 그 다음에는 자리 표시자 텍스트, 코드 및 금지 단어를 제거하는 패스가 이어졌다. C4에서 소스 텍스트의 상세한 설명은 Dodge 등(2021)을 참조한다.

RealNewsis a subset of the Common Crawl consisting to articles from news domains Zellers et al. (2019). 평균 길이 793 BPE 토큰을 가진 31M 문서가 들어 있습니다. RealNews는 Bloom 필터 Bloom(1970)에 각 문서의 처음 100자의 해시를 삽입한 후 해시 충돌이 발생한 문서를 제외함으로써 중복 제거되었다. C4와 마찬가지로 중복 URL이 있는 예는 제외되었다.

## 4 중복을 식별하기 위한 방법

중복된 예를 찾는 가장 간단한 기술은 모든 예제 쌍 간에 정확한 문자열 매칭을 수행하는 것이지만, 우리가 보여주듯이 이것은 불충분하다. 중복제거를 수행하기 위한 두 가지 보완적인 방법을 소개한다. 먼저 접미사 배열 Manber와 Myers (1993)를 사용하여 두 개 이상의 예에서 중복 부분 문자열이 버바텀으로 발생하는 경우 데이터 세트에서 중복 부분 문자열을 제거합니다. 둘째, 말뭉치에서 모든 예제 쌍 사이의 \(n\)-gram 유사도를 추정하는 효율적인 알고리즘인 MinHash Broder (1997)를 사용하여 높은 \(n\)-gram 중복이 있는 경우 데이터 세트에서 전체 예제를 제거한다.

우리는 데이터세트 \(D=\{x_{i}\}_{i=1}^{N}\)를 _예시_\(x_{i}\)의 집합으로 간주한다. 이들 예 각각은 그 자체로 _tokens_: \(x_{i}=\big{[}x_{i}^{1},x_{i}^{2},\cdots,x_{i}^{s_{i}}\big{]}\의 시퀀스이다.

### Exact Substring Duplication

인간 언어에서 가능성의 다양성으로 인해 하나의 표현이 다른 표현에서 파생되거나 둘 다 공유 출처에서 인용되지 않는 한 동일한 아이디어가 여러 문서에서 동일하게 표현되는 경우는 드물다. 이 관찰은 정확한 부분 문자열을 중복 제거하도록 동기를 부여합니다. 우리는 우리의 접근 방식을 ExactSubstr이라고 부른다. 두 예 \(x_{i}\)와 \(x_{j}\)가 충분히 긴 부분 문자열(즉, \(x_{i}^{a.a.+k}=x_{j}^{b.b+k}\)을 공유할 때, 그 부분 문자열은 그 중 하나에서 제거된다. 통계 분석(SSB)을 기반으로 \(k=50\) 토큰을 최소 매칭 부분 문자열 길이로 선택한다.

이 접근법에 필요한 계산의 분해는 부록 B에서 찾을 수 있다.

#### 4.1.1 Suffix Arrays

이 정확한 서브스트링 매칭 기준은 개념적으로 간단하지만, 순진한 (이차적인) 올-페어 매칭으로 계산상 불가능하다. 효율성을 향상시키기 위해 전체 데이터세트 \(D\)의 모든 예제를 거대한 수열 \(\mathcal{S}\)로 연결하고 \(\mathcal{S}\)의 접미사 배열 \(\mathcal{A}\)을 구성한다. 접미사 배열[20]은 \(\|\mathcal{S}\|\)[13]에서 선형 시간 내에 구성할 수 있는 접미사 트리[20]를 표현한 것으로, 많은 부분 문자열 질의를 효율적으로 연산할 수 있으며, 특히 선형 시간 내에 중복된 학습 예제를 식별할 수 있다. 서픽스 배열은 10-100\(\times\) 더 많은 메모리 효율[21]을 가지며, 입력 토큰당 8바이트를 필요로 하지만 일부 쿼리 유형에서는 점근적으로 덜 효율적이다. 그들은 효율적인 TF-IDF 계산[22] 및 문서 클러스터링[23]과 같은 NLP에서 널리 사용되었다.

수열에 대한 접미사 배열 \(\mathcal{A}\) \(\mathcal{S}\)은 수열에 포함된 모든 접미사들의 사전순으로 정렬된 리스트이다. 형식적으로는,

\[\mathcal{A}(\mathcal{S})=\text{arg sort all\_suffixes}(\mathcal{S})\]

예를 들어, 시퀀스 "바나나"의 접미사들은 "바나나", "아나", "아나", "나", "나", "a")이고, 따라서 접미사 어레이는 시퀀스(6 4 2 1 5 3)이다. 실제로, 텍스트(SS6)의 BPE 토큰화의 바이트로부터 \(\mathcal{S}\)를 구성한다.

#### 4.1.2 Substring matching

\(\mathcal{A}\)를 구축한 후, 중복된 훈련 예제를 식별하는 것은 간단하다. 수열 \(s\)이 위치 \(i\) 및 \(j\)에서 훈련 데이터 세트 \(\mathcal{S}\)에서 정확히 두 번 반복되었다고 가정하면, 즉 \(\mathcal{S}_{i.i+|s|}=\mathcal{S}_{j.j+|s|}\이다. 인덱스 \(i,j\)는 접미사 배열에서 서로 인접하여 발생한다 \(\mathcal{A}\).

따라서 반복된 모든 수열을 찾는 것은 접미사 배열을 처음부터 끝까지 선형 스캔하고 적어도 일부 임계 길이의 공통 접두사를 공유하는 수열 \(\mathcal{A}_{i},\mathcal{A}_{i+1}\)을 찾는 문제이다. 모든 만족스러운 시퀀스가 기록된다. 이 알고리즘은 당황스러울 정도로 병렬적이어서 데이터 세트를 효율적으로 처리할 수 있다. 실험(부록 B)에 기초하여, 우리는 모든 실험에 대해 50개의 BPE 토큰의 임계 길이를 선택한다.

### MinHash와의 근사적 일치

또한 일치하는 전체 예제를 기반으로 _근사_ 중복 제거를 수행합니다. 우리가 NearDup이라고 부르는 이 방법은 분산된 템플릿 필드(예: 표 1의 마지막 행)를 제외하고 문서가 동일한 매우 일반적인 경우를 처리하기 때문에 특히 웹 크롤 텍스트의 경우 _정확한_ 부분 문자열 매칭을 잘 보완한다.

MinHash[1]은 대규모 중국어 LM[30]에 대한 트레이닝 세트를 중복제거하는 것을 포함하여 대규모 중복제거 태스크[23, 24, 25]에서 널리 사용되는 근사 매칭 알고리즘이다. 두 문서 \(x_{i}\)와 \(x_{j}\)가 주어졌을 때, 주요 아이디어는 각 문서를 \(n\)-grams \(d_{i}\)와 \(d_{j}\)의 각각의 집합으로 표현하는 것이다. 그런 다음 해시 함수를 사용하여 _Jaccard Index_[26]을 근사화할 수 있습니다.

\[\mathrm{Jaccard}(d_{i},d_{j})=\nicefrac{{|d_{i}\cap d_{j}|}}{{|d_{i}\cup d_{j}|}}\

만약 \(d_{i}\)와 \(d_{j}\) 사이의 자카드 지수가 충분히 높으면 문서들이 서로 근사적으로 일치할 가능성이 높다. MinHash는 Jaccard 색인을 효율적으로 근사화하기 위해 해쉬 함수를 통해 각 \(n\)-gram을 정렬한 후, \(k\) 가장 작은 해싱된 \(n\)-gram만을 유지하여 문서 서명을 구성한다. 이러한 종류의 서명으로부터 자카드 지수의 추정량을 구성하는 방법은 여러 가지가 있다[24].

구현에서는 5-grams와 9,000 크기의 시그니처를 사용한다. 두 문서가 잠재적인 일치로 간주될 확률은

\[\Pr(d_{i},d_{j}|\,\mathrm{Jaccard}(d_{i},d_{j})=s_{i,j})=1-(1-s_{i,j}^{b})^{r}\]

여기서, \(b=20\) 및 \(r=450\)은 필터의 강도를 제어하기 위한 사용자 설정 가능한 파라미터이다. 자세한 내용은 부록 A를 참조하십시오.

잠재적인 매치로서 식별된 문서들의 각각의 쌍에 대해, 더 계산적으로 비싼 유사성 메트릭들이 후속 필터링 단계로서 채용될 수 있다. 특히, MinHash 알고리즘에 의해 두 문서가 일치하고 편집 유사도_가 0.8보다 크면 중복 문서로 식별한다. 토큰 시퀀스 \(x_{i}\)와 \(x_{j}\) 사이의 편집 유사도는 다음과 같이 정의된다.

\[\mathrm{EditSim}(x_{i},x_{j})=1-\frac{\mathrm{EditDistance}(x_{i},x_{j})}{ \max(|x_{i}|,|x_{j}|)}\]

유사한 문서들의 클러스터를 구축하기 위해, 두 문서들이 일치한다고 간주될 경우, 두 문서들 사이에 에지가 있는 그래프를 구성한다. 그런 다음 Lacki 등(2018)에 소개된 방법을 사용하여 연결된 구성 요소를 식별한다. 필요한 계산의 내역은 부록 A에 나와 있다.

## 5 중복 제거 결과

우리는 두 가지 기술을 모두 사용하여 4개의 데이터 세트 각각을 중복 제거한다. 텍스트가 여러 데이터 분할에 걸쳐 복제되었을 때 테스트 또는 유효성 검사 세트에 사본을 보관하고 열차 세트에서 제거하는 것이 우선 순위였다.

### 제거된 텍스트 양

NearDup을 사용하여 웹 스크래프 데이터 세트가 복제 근처에 3.04%(C4에서)에서 13.63%(RealNews에서)를 포함한다는 것을 발견했다(표 2). Nearduplicate 텍스트는 Wiki-40B에서 훨씬 덜 일반적이며 기차 세트의 0.39%만 형성합니다.2 C4에서 거의 복제된 군집의 대부분(1.8M)은 서로 일치하는 단일 한 쌍의 예제로 구성되었지만 크기 250,933의 한 군집을 포함하여 5,000개 이상의 예가 있는 280개의 군집이 있었다(그림 1).

각주 2: 우리가 본 대부분의 중복은 스포츠 경기의 결과와 같은 자동으로 생성된 페이지였다. 이것은 고품질 데이터 세트를 만들기 위한 수동 큐레이션의 강도를 보여준다.

ExactSubstr의 경우 평균적으로 NearDup보다 더 많은 총 콘텐츠를 제거합니다. 예를 들어 C4에서 토큰의 \(7.18\%\)를 제거합니다. 예외는 LM1B입니다. 여기서 ExactSubstr은 NearDup보다 \(8\times\) 더 적은 데이터를 제거합니다. 조사 결과, LM1B 문서의 길이가 상당히 짧기 때문에 모든 문서의 \(90\%\)가 50 토큰 미만이며 전체 시퀀스가 버바텀과 일치하더라도 잠재적인 일치 후보도 아니다. NearDup과 ExactSubstr 모두 C4에서 NearDup이 제거하는 훈련 예제의 유사한 내용--\(77\%\)은 ExactSubstr에 의해 발견된 적어도 하나의 verbatim length-\(50\) 일치를 갖는다.

\begin{table}
\begin{tabular}{l|c c|c} \hline \hline  & \multicolumn{2}{c|}{\% train examples with} & \multicolumn{2}{c}{\% valid with} \\  & \multicolumn{1}{c}{dup in train} & \multicolumn{1}{c}{dup in valid} & \multicolumn{1}{c}{dup in train} \\ \hline C4 & \(7.18\%\) & \(0.75\) \% & \(1.38\) \% \\ RealNews & \(19.4\) \% & \(2.61\) \% & \(3.37\) \% \\ LM1B & \(0.76\%\) & \(0.016\%\) & \(0.010\%\) \\ Wiki40B & \(2.76\%\) & \(0.52\) \% & \(0.67\) \% \\ \hline \hline \end{tabular}
\end{table}
표 2: NearDup에 의해 거의 중복으로 식별된 예의 분율.

그림 1: C4에서 NearDup 실행으로 인한 거의 복제된 클러스터 크기의 분포입니다.

\begin{table}
\begin{tabular}{l|c c|c} \hline \hline  & \multicolumn{2}{c|}{\% train tokens with} & \multicolumn{2}{c}{\% valid with} \\  & \multicolumn{1}{c}{dup in train} & \multicolumn{1}{c}{dup in valid} & \multicolumn{1}{c}{dup in train} \\ \hline C4 & \(7.18\%\) & \(0.75\) \% & \(1.38\) \% \\ RealNews & \(19.4\) \% & \(2.61\) \% & \(3.37\) \% \\ LM1B & \(0.76\%\) & \(0.016\%\) & \(0.010\%\) \\ Wiki40B & \(2.76\%\) & \(0.52\) \% & \(0.67\) \% \\ \hline \hline \end{tabular}
\end{table}
표 3: 토큰의 분수(노트 표 2는 ExactSubstr이 정확한 중복 50-토큰 부분 문자열의 일부로 식별한 _예시_의 분수를 보고함).

### 복제된 텍스트 속성

RealNews와 C4의 저자는 데이터 세트 구성 동안 중복 제거를 명시적으로 시도했지만 방법은 인터넷에서 일반적으로 발견되는 보다 미묘한 유형의 중복 텍스트를 캡처하기에 충분하지 않았다. C4와 위키-40B에서 우리는 거의 복제된 것으로 식별된 텍스트의 대부분이 컴퓨터 생성임을 정성적으로 관찰한다. 텍스트는 장소, 사업체, 제품, 날짜 등의 이름을 제외하고는 동일합니다. 이러한 예는 한 번에 몇 개의 단어만 다를 수 있기 때문에 정확한 문자열 매칭에 의존하는 중복 제거 전략은 일치를 식별하지 못할 것이다. 각 데이터 세트의 중복 쌍 예는 표 1(부록의 더 많은 예)에서 찾을 수 있다.

뉴스 사이트에서 파생된 RealNews와 LM1B의 경우 동일한 뉴스 기사가 약간 다른 형식의 여러 뉴스 사이트에서 나타나기 때문에 거의 중복이 많이 발생한다는 것을 관찰한다. 예를 들어, LM1B에서, "_MINEOLA, N.Y. - 뉴욕 공무원들은_[...]"을 시작하는 하나의 예가 있고, "_(AP) - 뉴욕 공무원들은_[...]"을 시작하는 또 다른 예가 있다. 두 예는 그렇지 않으면 동일하다.

### Train / Test Set 누출

두 중복 제거 방법 모두 열차 집합과 검증 집합 간의 중복을 식별한다(표 2). 예를 들어, C4 검증 세트의 4.6% 및 RealNews 검증 세트의 14.4%는 각각의 훈련 세트에서 대략적인 중복을 가졌다. 이러한 복제는 열차 세트를 더 잘 외우는 모델에 대해 평가 지표가 부당하게 부풀어 오를 수 있기 때문에 문제가 된다. 우리는 섹션 6.3에서 공개적으로 출시된 모델에 대한 이 누출의 영향을 평가한다.

## 6 훈련된 모델에 대한 영향

인 것을 특징으로 하는 반도체 소자의 캐패시터 제조 방법. 우리는 각각 C4-Original, C4-NearDup 및 C4-ExactSubstr에서 GPT-2와 유사한 디코더 전용, 트랜스포머 기반 언어 모델인 1.5B 매개변수 "XL"을 훈련했다. Raffel et al.(2020)의 T5 코드베이스와 모델 아키텍처를 사용하며, 각 모델은 각각의 데이터 세트에서 약 2개의 에포크에 대해 훈련되었다. 훈련된 모델의 복잡성에서 분산의 양을 더 잘 이해하기 위해 총 9개의 기본 크기 모델에 대해 위의 세 데이터 세트 각각에 대해 110M 매개변수 "기본" 모델의 세 가지 다른 무작위 시드도 훈련했다.

모든 실험에서 50K 토큰의 예산으로 C4-NearDup에서 훈련된 바이트 쌍 인코딩(Byte Pair Encoding, BPE) 어휘를 사용했으며, 그 결과 GPT-2와 동일한 크기의 어휘가 생성되었다. 우리는 512 토큰의 최대 시퀀스 길이로 훈련했다(더 긴 문서의 경우, 이 길이의 서브시퀀스를 무작위로 추출했다). 추가 훈련 세부 사항은 부록 C에서 찾을 수 있다.

### Model Perplexity

LM1B 및 Wiki-40B의 검증 세트 및 C4 검증 세트의 하위 세트에서 훈련된 모델의 복잡성을 계산했다(그림 2). 기본 크기의 경우 모든 모델이 원래 C4 검증 세트 및 고유한 것으로 식별된 검증 세트 예(열차 또는 검증에서 거의 중복되지 않음)에서 유사한 복잡성을 갖는다는 것을 관찰한다. 그러나 중복 제거된 데이터에 대해 훈련된 두 모델은 원래 C4에 대해 훈련된 모델보다 훈련 세트에 중복이 있는 검증 세트 예제에 대해 상당히 더 높은 복잡도를 갖는다. ExactSubstr-deduplicated 결과 NearDup-deduplicated보다 더 높은 복잡도를 갖는다. 이러한 경향은 XL 크기의 모델에서도 마찬가지이다. 이는 ExactSubstr 중복 결과가 열차 세트에 가장 과소 적합하는 모델에서 나타날 수 있지만 이 두 기술 모두 별도의 중복 임계값을 사용했으며 임계값을 다르게 선택하면 결과가 변경될 수 있다는 점에 유의한다.

LM1B 및 Wiki-40B의 검증 세트에서 평가할 때, 우리는 NearDup-중복 C4에서 훈련된 모델이 일관되게 가장 낮은 복잡성을 달성한다는 것을 발견했다(기본 모델을 사용한 LM1B 평가의 경우 부록 그림 7 참조). ExactSubstr 중복제거는 위키-40B에서 XL 모델의 복잡도를 거의 3점 정도 감소시킨다.

그림 2: 훈련 세트를 중복 제거하면 유효성 검사 복잡도에 미치는 영향. 우리는 T5 XL의 결과를 플롯한다(기본 크기 모델은 부록 참조). C4의 경우 원래 검증 집합인 _C4 원본_에 대해 평가합니다. _C4 Unique_는 NearDup에서 C4에 걸쳐 0개의 일치를 갖는 것으로 식별된 검증 집합의 하위 집합이고 _C4 Duplicates_는 NearDup에서 C4 열차 집합에서 일치를 갖는 것으로 식별된 검증 집합의 하위 집합입니다.

[MISSING_PAGE_FAIL:7]

중복에 가까운 것으로 확인된 예제의 절반입니다. GROVER의 경우, 고려된 두 모델 크기 모두에서 그 차이는 그다지 뚜렷하지는 않지만 존재한다.

기존 모델도 열차 세트에서 텍스트를 생성하는 문제로 어려움을 겪는다. 우리는 25k GROVER-Mega 출력 3의 공식 릴리스에서 토큰의 \(1.38\%\)이 최소 길이의 RealNews \(50\)에서 버바텀 일치의 일부임을 발견했다. 마찬가지로 GPT-Neo 1.3B(Black et al., 2021)가 출력한 \(\mathtt{\sim}\)200k 시퀀스에서 토큰의 5% 이상이 훈련 데이터인 Pile(Gao et al., 2020)의 \(50\) 토큰 일치의 일부이다.

각주 3: https://grover-models/generation_examples/generator=mega=dataset=p0.90.json

## 7 Discussion

이 논문의 초점은 언어 모델을 훈련하는 데 사용되는 데이터 세트에 있다. 최근 문제 데이터 세트(Bender and Friedman, 2018; Gebru et al., 2020)로 인해 발생할 수 있는 잠재적 피해를 문서화하는 데 초점을 맞춘 반면, Dodge et al.(2021)이 C4에 대해 수행한 것과 같이 실제 언어 모델링 데이터 세트의 특성을 정량적으로 분석하는 작업은 거의 수행되지 않았다. 본 논문에서는 데이터 중복의 한 가지 특정 축에 대한 분석을 제공한다.

우리의 실험은 정량화될 수 있는 것을 측정했다: 공통 데이터 세트의 중복 콘텐츠의 양, 중복 제거가 훈련된 모델 복잡성에 미치는 영향, 중복 제거를 통해 훈련된 모델에서 암기된 콘텐츠의 감소. 우리는 중복제거에 의해 제거되거나 LMs에 의해 암기되는 데이터의 특성에 초점을 맞추지 않는다.

암기된 훈련 데이터는 상당한 개인 정보 보호 결과를 가져오기 때문에 개인 정보 보호는 향후 작업에 중요한 주제이다. 이를 통해, 우리는 유사한 분포의 다른 훈련 데이터세트와 대조적으로, 모델이 훈련된 특정 데이터세트에 특정한 것을 드러내지 않아야 한다는 표준 프라이버시 정의를 의미한다(Shokri et al., 2017).4 아직 중복 제거되지 않은 표준 데이터세트에 대한 훈련은 우연히 여러 번 반복되는 예에 특히 민감한 모델의 결과를 초래하며, 이는 부정적인 프라이버시 의미를 갖는다. 예를 들어, 공개적으로 사용 가능한 개인 데이터가 다른 놀라운 맥락에서 나타난다면 개인의 사생활에 대한 기대를 위반할 수 있다. 게임 AI 던전5와 같은 LM의 다운스트림 애플리케이션도 실제 제품에 대한 광고와 같은 암기 콘텐츠를 출력해서는 안 된다.

각주 4: 프라이버시에 대한 또 다른 해석은, 모델이 개인 식별자 또는 다른 형태의 "개인 데이터"에 대해 훈련되고 재현할 수 있을 때, 관련된 데이터의 민감도에 초점을 맞춘다. 우리의 정의는 더 광범위하다.

우리는 우리의 실험에서 원하지 않는 암기 텍스트(전화 번호 등), 무해한 암기 텍스트(공통 구문) 및 우리가 암기하기를 원할 수 있는 텍스트(공인 인물에 의한 인용문 등)를 구별하지 않고, 대신에 트레이닝 세트와 밀접하게 일치하는 LM 생성 텍스트의 모든 인스턴스를 문제가 있는 것으로 취급한다는 것을 강조한다. 확인된 암기 내용의 대부분이 상대적으로 무해하다는 것을 정성적으로 관찰했지만 감지된 암기와 관련된 위험에 대한 보다 체계적인 연구는 이 작업의 범위를 벗어났다.

우리는 또한 중복 제거의 부정적인 결과를 조사하지 않는다. 일부 언어 태스크는 문서 검색 또는 닫힌 문서 질의 응답과 같이 명시적으로 암기를 요구한다. 또한 속성을 부여 하는 텍스트는 문서 간에 중복 되는 경우가 많기 때문에 중복 부분 문자열을 제거 하는 것은 속성을 _just_ 제거 하는 것에 해당 하 여 첨부 된 속성 없이 콘텐츠를 학습 하는 모델이 될 수 있습니다. 중복 제거는 또한 은행 비밀번호 및 의료 기록과 같은 개인 정보에 민감한 데이터를 제거하기에 충분하지 않으며 이는 훈련 데이터에서 절대 사용되어서는 안 된다(Brown et al., 2022).

궁극적으로, 암기가 언어 모델의 원하는 속성인지, 아니면 위험하고 원하지 않는지 여부는 암기된 텍스트의 성질과 훈련된 모델의 다운스트림 애플리케이션 모두에 의존한다. 그러나 응용 프로그램에 영향을 주지 않는 데이터 세트와 모델을 만드는 경향이 있기 때문에 연구자들은 수집한 데이터의 한계와 모델의 의도된 사용이 훈련 세트의 일부가 되어야 하는 것을 제한하는 방법에 대해 신중하게 생각하도록 권장한다. 최종 응용에 따라 특정 시퀀스를 암기하거나 잊어버리는 기술을 개발하는 것은 유망한 연구 방향이다.

## 8 Conclusion

향후 언어 모델 연구는 릴리스하는 중복 제거 데이터 세트에 대한 교육, 릴리스하는 중복 제거 도구를 사용하거나 새로운 도구를 사용하여 중복 제거 데이터 세트에 대한 접근 방식을 따라 데이터 세트 중복 제거를 수행하도록 권장한다.

중복 제거를 수행하는 데 사용되는 정확한 기술은 애초에 엄격한 중복 제거를 수행하는 것보다 덜 중요하다. 중복 제거된 데이터 세트가 더 작고 더 빨리 훈련된다는 사실에도 불구하고 전체적으로 중복 제거는 해를 끼치지 않으며 때로는 개선되는 모델 복잡성이다. 여기서 중첩은 훈련 데이터를 기억하는 모델을 선택하는 것을 명시적으로 장려하기 때문에 훈련과 테스트 세트 사이에 중복이 없다는 것이 특히 중요하다. 마지막으로 중복 제거는 학습 데이터를 암기하는 LMs에 대한 일부 개인 정보 보호 문제를 줄이는 데 도움이 된다.

## Ethics

대규모 언어 모델의 개발자는 일반적으로 인간의 자연스러운 커뮤니케이션을 반영하는 훈련 데이터를 생성하려고 시도하지만, 이러한 데이터 세트를 수집하고 큐레이션하는 현재의 방법은 오류가 있을 수 있다. 일부 텍스트가 과도하게 표현되는 여러 가지 이유가 있습니다. 예를 들어, 봇 응답, 자동 생성 템플릿 및 라이선스는 구조적(예를 들어, 법적, 경제적) 이유로 반복된다( Dodge 등(2021)에 의해 또한 관찰된 바와 같이). 또한, 데이터를 획득하고 "청소"하기 위한 일반적인 기술은 세계 사용자의 특정 하위 집합, 종종 영어권 및 확립된 포럼에서 출판하는 사람들의 과도한 표현을 초래할 수 있다. 이는 비영어권 화자뿐만 아니라 커뮤니케이션이 주로 공공 웹 외부에서 발생하는 그룹을 효과적으로 과소 표현한다. 본 논문에서는 일부 유형의 텍스트(구조적 중복)의 과잉 표현 문제에 초점을 맞추지만, 다른 유형의 과소 표현 문제는 다루지 않는다.

또한 암기된 콘텐츠가 필요할 때와 필요하지 않을 때를 논의하지만 우리의 분석에서는 이 두 가지 사례를 명확하게 하지 않는다. 유해한 암기에서 도움이 되는 것을 명확하게 하기 위한 작업은 매우 복잡하며 이 작업에서 제시된 것과 다른 연구 방법론이 필요하다.

## Acknowledgements

우리는 제이콥 오스틴, 사미 벵지오, 올리비에 부스케, 제임스 브래드베리, 페르난도 디아즈, 마크 디아즈, 노아 피델, 조나단 프랭클, 데이비드 그랜지에, 스테파니 카프, 데이비드 밈노, 가우라브 미슈라, 마이클 모저, 샤란 나랑, 알렉스 파소스, 애덤 로버츠, 하니 세드기, 하샤 솔딕슈타인, 데이비드 소, 플로리안 트레이머, 윤 윌리엄 유 등 이 프로젝트를 형성한 많은 연구자들에게 감사한다. 지속적인 지원을 해주신 구글 브레인 여성분들께도 감사드린다.

Chris Callison-Burch와 Daphne Ippolito의 연구는 DARPA KAIROS 프로그램(계약 FA8750-19-2-1004), DARPA LwLL 프로그램(계약 FA8750-19-2-0201) 및 IARPA BETTER 프로그램(계약 2019-19051600004)에 의해 부분적으로 지원된다. 여기에 포함된 견해와 결론은 저자의 견해이며 DARPA, IARPA 또는 미국 정부의 공식 정책을 표현하거나 암시하는 것으로 반드시 해석되어서는 안 된다.

## Contributions

이 논문의 각 저자는 최종 결과에 크게 기여했다.

* 캐서린은 논문에 사용된 모델을 훈련하고 평가 및 텍스트 생성 파이프라인을 구축하고 실행했으며 작성, 분석 및 프로젝트 조직 및 관리에 크게 기여했습니다.
* Daphne는 근사 일치 데이터 중복 제거 파이프라인을 실행 하 고 프롬프트 및 평가 데이터 세트를 추출 하 고 평가 파이프라인을 실행 하 고 계획, 작성 및 분석에 크게 기여 했습니다.
* 앤드류는 코드를 작성 하 여 근사 일치로 중복 제거를 수행 하 고 에너지 소비를 평가 하 고 분석에 도움이 되었습니다.
* 치위안은 플롯을 생성하는 데 도움이 되었고 프로젝트 범위 지정, 쓰기 및 데이터 분석에 기여했습니다.
* Chris는 프로젝트 전반에 걸쳐 멘토링과 지도를 제공하고 글쓰기에 기여했습니다.
* 더그는 프로젝트 전반에 걸쳐 멘토링과 지침을 제공하고 글쓰기에 기여했습니다.
* Nicholas는 접미사 배열 구현을 작성하고 모든 ExactSubstr 중복 제거 실험을 실행했으며 프로젝트 범위 지정뿐만 아니라 계획, 작성 및 분석에 크게 기여했습니다.

## References

* Allamanis (2019) Miltiadis Allamanis. 2019. The adverse effects of code duplication in machine learning models of code. <2019 ACM SIGPLAN International Symposium on New ideas, New Paradigms and Reflections on Programming and Software>에서 143-153페이지입니다.

Devansh Arpit, Stanislaw Jastrzebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al. 2017. A closer look to memorization in deep networks. [Machine Learning에 대한 국제 회의]에서 233-242 페이지. PMLR.
* Bandy and Vincent (2021) Jack Bandy and Nicholas Vincent. 2021. 머신 러닝 연구에서 "문서 빚"을 해결: 북코퍼스에 대한 후향적 데이터시트.
* Bender and Friedman (2018) Emily M. 벤더와 바티야 프리드먼 2018. 자연어 처리를 위한 데이터 문장: 시스템 편향을 완화하고 더 나은 과학을 가능하게 합니다. _ 계산 언어학 협회의 트랜잭션_, 6:587-604.
* Bender et al.(2021) Emily M. 벤더, 팀닛 게브루 안젤리나 맥밀런 소령 슈마가렛 슈미첼 2021. 확률적 앵무새의 위험성에 대해: 언어 모델이 너무 클 수 있나요? "Proceedings of the 2021 ACM Conference on Fairness, Accountability and Transparency_"에서 FAccT '21, page 610-623, New York, NY, USA. 컴퓨팅 기계 협회
* Black et al.(2021) Sid Black, Leo Gao, Phil Wang, Connor Leahy, and Stella Biderman. 2021. GPT-Neo: Large scale autoregressive language modeling with mesh-tensorflow.
* Bloom (1970) Burton H Bloom. 1970. 허용 가능한 에러를 갖는 해시 코딩에서의 시공간 트레이드오프. _ Communications of the ACM_, 13(7):422-426.
* Broder (1997) Andrei Z Broder. 1997. On the similar and containment of documents. <프로시빙스>에서. SEQUENCES 1997 (Cat. No. 97TB100171)의 압축 및 복잡도 _, pages 21-29. IEEE.
* Brown et al. (2022) Hannah Brown, Katherine Lee, Fatemehsadat Mireshghallah, Reza Shokri, and Florian Tramer. 2022. 언어 모델이 개인 정보를 보호한다는 것은 무엇을 의미합니까? _ arXiv preprint_.
* Brown et al.(2020) Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models is few-shot learners. 《신경 정보 처리 시스템 33》에서.
* Carlini 등(2020) Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, Alina Oprea, and Colin Raffel. 2020. 대용량 언어 모델로부터 훈련 데이터를 추출하는 단계.
* Chelba et al.(2013) Ciprian Chelba, Tomas Mikolov, Mike Schuster, Qi Ge, Thorsten Brants, Phillipp Koehn, and Tony Robinson. 2013. 통계 언어 모델링의 진행률을 측정하기 위한 10억 단어 벤치마크. _ arXiv preprint arXiv:1312.3005_.
* Chim and Deng (2007) Hung Chim and Xiaoite Deng. 2007. A new suffix tree similarity measure for document clustering. "Proceedings of the 16th International Conference on World Wide Web_, WWW'07, pages 121-130, New York, NY, USA. 컴퓨팅 기계 협회
* Cohen (2016) Edith Cohen. 2016. Min-hash 스케치: 간략한 설문조사.
* Dai 등(2019) Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc V Le, and Ruslan Salakhutdinov. 2019. Transformer-xl: Attentive language models beyond the fixed-length context. _ arXiv preprint arXiv:1901.02860_.
* Dodge 등(2021a) Jesse Dodge, Maarten Sap, Ana Marasovic, William Agnew, Gabriel Ilharco, Dirk Groeneveld, and Matt Gardner. 2021a. 영어의 거대한 크롤링 코퍼스를 기록합니다.
* Dodge 등(2021b) Jesse Dodge, Maarten Sap, Ana Marasovic, William Agnew, Gabriel Ilharco, Dirk Groeneveld, and Matt Gardner. 2021b. 영어의 거대한 크롤링 코퍼스를 기록합니다.
* Feldman and Zhang (2020) Vitaly Feldman and Chiyuan Zhang. 2020. 신경 네트워크가 기억하는 것과 이유: 영향 추정을 통해 긴 꼬리를 발견함. 신경 정보 처리 시스템의 발전에서.
* Gabriel 등(2018) Rodney A. Gabriel, Tsung-Ting Kuo, Julian McAuley, and Chun-Nan Hsu. 2018. 큰 임상 노트 데이터 세트에서 매우 유사한 노트를 식별하고 특성화합니다. _ Journal of Biomedical Informatics_, 82:63-69.
* Gao 등(2020) Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. 2020. The Pile: 언어 모델링을 위한 다양한 텍스트의 800gb 데이터 세트 _ arXiv preprint arXiv:2101.00027_.
*Gebru et al.(2020) Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daume III au2, and Kate Crawford. 2020. 데이터 세트에 대한 데이터 시트입니다.
* Graff et al.(2003) David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. 2003. 영어 기가워드. _ Linguistic Data Consortium, Philadelphia_, 4(1):34.
* Guo et al.(2020) Mandy Guo, Zihang Dai, Denny Vrandecic, and Rami Al-Rfou. 2020. Wiki-40b: 다국어 언어 모델 데이터셋. *LREC 2020* 에서.
* Gyawali 등(2020) Bikash Gyawali, Lucas Anastasiou, and Petr Knoth. 2020. 지역성 민감 해싱 및 단어 임베딩을 이용한 학술 문서 중복 제거. 제12차 언어 자원 및 평가 회의 회보에서 901-910페이지입니다.
* Jaccard (1912) Paul Jaccard. 1912. 고산지대의 식물상 분포. _ New phytologist_, 11(2):37-50.
* Ghahahramani et al. (2019)Juha Karkkainen and Peter Sanders. 2003. 단순 선형 작업 접미사 배열 구성. 오토마타, 언어 및 프로그래밍에 대한 국제 콜로키움 943-955 페이지입니다. 스프링어.
* Ko and Aluru (2003) Pang Ko and Srinivas Aluru. 2003. 공간 효율적인 선형 시간 구성 of suffix arrays. '조합 패턴 일치에 관한 연례 심포지엄' 200-210쪽 스프링어
* Manber and Myers (1993) Udi Manber and Gene Myers. 1993. 접미사 배열: 온라인 문자열 검색을 위한 새 방법입니다. _ siam Journal on Computing_, 22(5):935-948.
*농 등(2009) Ge Nong, Sen Zhang, and Wai Hong Chan. 2009. 거의 순수한 유도 정렬에 의한 선형 접미사 배열 구성. *2009 데이터 압축 회의_에서 193-202 페이지. IEEE.
* Patterson 등(2021) David Patterson, Joseph Gonzalez, Quoc Le, Chen Liang, Lluis-Miquel Munguia, Daniel Rothchild, David So, Maud Texier, and Jeff Dean. 2021. 탄소 배출량과 대형 신경망 훈련.
* Radford et al. (2019) Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. 2019. 언어 모델은 감독되지 않은 다중 작업 학습자입니다. _ OpenAI blog_, 1(8):9.
* Raffel 등(2020) Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. 통합 텍스트 대 텍스트 변환기를 사용 하 여 전이 학습의 한계를 탐색 합니다. _ Journal of Machine Learning Research_, 21(140):1-67.
* Shazeer and Stern (2018) Noam Shazeer and Mitchell Stern. 2018. Adafactor: Adaptive learning rate with sublinear memory cost. [Machine Learning에 대한 국제 회의]에서 페이지 4596-4604. PMLR.
* Sheng et al.(2020) Emily Sheng, Kai-Wei Chang, Premkumar Natarajan, and Nanyun Peng. 2020. 언어 생성에서 제어 가능한 편향을 향합니다. _ arXiv preprint arXiv:2005.00268_.
* Shokri et al.(2017) Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 2017. 머신 러닝 모델에 대한 멤버십 추론 공격. _2017 IEEE Symposium on Security and Privacy (SP)_, pages 3-18. IEEE.
* Stephenson 등(2021) Cory Stephenson, Suchismita Padhy, Abhinav Ganesh, Yue Hui, Hanlin Tang, and SueYeon Chung. 2021. On the geometry of generalization and memorization in deep neural networks. <학습 표현에 관한 국제 회의>에서.
* Strubell et al.(2019) Emma Strubell, Ananya Ganesh, and Andrew McCallum. 2019. 에너지 및 정책 고려 사항 in nlp.
* Teterwak et al.(2021) Piotr Teterwak, Chiyuan Zhang, Dilip Krishnan, and Michael C Mozer. 2021. 판별적으로 훈련된 분류기의 피드포워드 역산을 통한 불변의 이해. [Machine Learning에 대한 국제 회의]에서 10225-10235 페이지 PMLR.
* Trinh and Le (2018) Trieu H Trinh and Quoc V Le. 2018. 간단한 상식 추론 방법. _ arXiv preprint arXiv:1806.02847_.
* Vaswani 등(2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. 주의력만 있으면 됩니다. _ arXiv preprint arXiv:1706.03762_.
* 버슬리 및 판첸코(2012) 야닉 버슬리 및 야나 판첸코. 2012. 단지 더 큰 것이 아니라, 더 나은 품질의 웹 코퍼스를 향한 것입니다. WAC7(코퍼스 워크샵으로 7번째 웹 진행)_에서 44-52페이지입니다.
* Wallace 등(2019) Eric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh. 2019. Universal adversarial trigger for attacking and analyzing nlp. _ arXiv preprint arXiv:1908.07125_.
* Webster 등(2019) Ryan Webster, Julien Rabin, Loic Simon, and Frederic Jurie. 2019. Detecting overfitting of deep generation network via latent recovery. *2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)_, pages 11265-11274.
* Weiner (1973) Peter Weiner. 1973. 선형 패턴 매칭 알고리즘. _14th Annual Symposium on Switching and Automata Theory (swat 1973)_, pages 1-11. IEEE.
* Xue 등(2020) Linting Xue, Noah Constant, Adam Roberts, Mihir Kale, Rami Al-Rfou, Aditya Siddhant, Aditya Barua, and Colin Raffel. 2020. mt5: 대규모 다국어 사전 훈련 텍스트 대 텍스트 변환기 _ arXiv preprint arXiv:2010.11934_.
* 야마모토와 교회(2001) 미키오 야마모토와 케네스 W 교회. 2001. 접미사 배열을 사용하여 말뭉치의 모든 부분 문자열에 대한 용어 빈도 및 문서 빈도를 계산합니다. _ Computational Linguistics_, 27(1):1-30.
* Zellers 등(2019) Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yoatan Bisk, Ali Farhadi, Franziska Roesner, and Yejin Choi. 2019. 신경 가짜 뉴스에 대해 방어합니다. _ arXiv preprint arXiv:1905.12616_.
* Zeng et al.(2021) Wei Zeng, Xiaozhe Ren, Teng Su, Hui Wang, Yi Liao, Zhiwei Wang, Xin Jiang, Zhen Zhang Yang, Kaisheng Wang, Xiaoda Zhang, Chen Li, Ziyan Gong, Yifan Yao, Xinjing Huang, Jun Wang, Jianfeng Yu, Qi Guo, Yue Yu, Yan Zhang, Jin Wang, Hengtao Tao, Dasen Yan, Zexuan Yi, Fang Peng, Fangqing Jang, Han Zhang, Lingfeng Deng, Yehong Zhang, Zhe Lin, Chao Zhang, Shaojie Zhang, Mingyue Guo, Shanzhi Gu, Gaojun Fan, Yaowei Wang, Xuefeng Jin, Qun Liu, and Yonghong Tian. 2021. Pangu-\(\alpha\): 대규모 자동 회귀 사전 훈련 중국어 모델 with auto-parallel computation _ arXiv preprint arXiv:2104.12369_.
* Zhu et al.(2015) Yukun Zhu, Ryan Kiros, Rich Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and Sanja Fidler. 2015. 책과 영화의 정렬: 영화를 보고 책을 읽음으로써 이야기 같은 시각적 설명을 향해. *Proceedings of the IEEE international conference on computer vision_, 19-27 페이지.

자쿱 라키, 바하브 미로니 미찰 클로다르치크 2018. 로컬 수축을 통해 스케일에서 연결된 구성 요소.

NearDup에 대한 자세한 내용

MinHash 기반 중복 제거 방법은 먼저 문서를 공간 토큰화하고, 각 연속 5-gram을 테이블화 해싱을 이용하여 해싱한다. 이 해시 집합은 문서에 대한 서명입니다. 문서 서명의 각 요소에 대해 요소는 \(k\) 다른 해시 함수를 사용하여 해시됩니다. 각 \(k\) 해시 함수에 대한 최소 해시 요소가 저장됩니다. 그런 다음 이러한 최소 해시는 버킷당 \(b\) 해시를 사용하여 \(r\) 버킷으로 분할됩니다. 이러한 \(b\) 해시는 단일 값으로 증강되고, 두 문서가 적어도 하나의 버킷에서 동일한 값을 갖는 경우 잠재적인 일치로 표시됩니다. 두 문서가 잠재적인 일치로 간주될 확률은 다음과 같습니다.

\[\Pr(d_{i},d_{j}|\operatorname{Jaccard}(d_{i},d_{j})=s_{i,j})=1-(1-s_{i,j}^{b})^ {r}\]

여기서 \(s_{i,j}\)는 두 문서 사이의 자카드 인덱스 \(i\)와 \(j\)이다. 잠재적 일치로 식별된 문서 쌍의 경우 실제 자카드 인덱스를 계산하고 0.8 이상이면 편집 유사성을 계산했다. 편집 유사도가 0.8보다 높은 문서 쌍은 중복으로 식별되었다. 실험 후, \(b=20\), \(r=450\)을 사용하여 원하는 자카드 지수 임계값 0.8에서 충돌이 발생할 확률이 높은지 확인하기 위해 \(k=9,000\)을 선택했다.

또한 자카드 인덱스가 최소 0.9이고 편집 유사도가 최소 0.9인 문서 쌍을 필터링하는 대체 구성을 테스트했습니다. 이 경우 \(b=20\), \(r=40\) 및 \(k=800\)를 사용했습니다. 그림 4는 최소 해시 공간에서 충돌한 모든 문서 쌍, 선택한 구성(파란색) 및 대체 구성(주황색)에 대한 자카드 유사도와 편집 유사도의 히스토그램을 보여준다. 이를 통해 선택한 임계값이 선택한 임계값 주변의 비교가 거의 없는지 확인할 수 있으며, 그러면 해당 임계값 위의 실제 거의 복제된 대부분을 캡처했을 가능성이 있다. 직접 확인하려면 분포의 왼손 꼬리를 살펴보십시오. 0.8과 0.9는 모두 같은 지점에서 사라지기 시작하므로(두 임계값이 서로 다른 임계값 주변의 정확도에 최적화되어 있음에도 불구하고), 실제 거의 복제된 대부분의 임계값을 포착하고 있다고 말하는 것이 편안하다.

Computational AnalysisLet \(N\)는 문서의 수이고 \(T\)는 문서의 최대 토큰 수입니다. 편집 유사도는 \(T^{2}\)의 최악의 경우 복잡도를 가지므로, 최악의 경우 복잡도는

\[O(N+bk^{2}T^{2}N)=O(N)\]

since \(b\), \(k\), 및 \(T\)는 모두 \(\ll N\)이다. 왼쪽 용어는 서명에 의한 그룹화의 복잡성이고 오른쪽은 모든 문서가 동일한 \(B\) 버킷에 속하는 병리학적 최악의 경우를 나타낸다.

우리가 고용한 고도로 분산된 NearDup 구현은 구글에서 대규모 생산 작업에 사용되는 것이다. 영어 C4 데이터 세트에서 알고리즘은 약 41.5kWh의 에너지를 소비했다. 본 논문의 \(k\)와 \(b\)의 선택은 매우 높은 재현율을 생성하도록 설계되었으며, 서로 다른 매개변수를 사용하여 알고리즘이 유사한 결과를 생성하면서 훨씬 더 에너지 효율적으로 만들어질 수 있음을 주목한다.

## 부록 B ExactSubstr에 대한 추가 세부 정보

병렬 선형 시간 구성, 병렬 선형 시간 접미사 배열 알고리즘을 구축한다. 구성 블록으로서 SA-IS 알고리즘을 사용하여 선형 시간 농 등(2009)과 Ko 및 Aluru(2003)에서 접미사 배열을 구성한다. 불행하게도, 이 알고리즘은 직접적으로 쉽게 병렬화되지 않기 때문에, 우리는 배열 구성을 병렬화하는 간단한 분할 정복 접근법을 소개한다.

우리는 Rust에서 구현을 구축하고 기존의 접미사 배열 라이브러리6을 세 가지 수정으로 확장한다. 첫 번째 두 가지 구현의 차이점은 \(4\)GB보다 큰 데이터 세트를 허용하도록 코드를 수정하고 문자열이 원시 바이트 시퀀스에 유리한 유효한 UTF-8 시퀀스로 구문 분석해야 하는 요구 사항을 제거한다. 세 번째 변경 사항은 더 중요합니다. 디스크에서 접미사 배열 자체를 스트리밍할 수 있도록 알고리즘을 다시 구현합니다.

각주 6: [https://github.com/BurnStushi/suffix](https://github.com/BurnStushi/suffix)

병렬 부분 접미사 배열 구성. 우리의 분할 및 정복 접미사 배열 구성 알고리즘은 각 분할에서 독립적으로 실행되는 SA-IS를 사용하여 데이터 세트를 \(K\)개의 서로 다른 "분할"로 분할하는 것으로 시작한다. 이 알고리즘은 \(O(N)\) 작업이 필요하지만 \(O(N/K)\) 벽 시계 시간에서 실행됩니다. 이것은 \(N\) 별개의 접미사 배열 \(\mathcal{A}^{i}\)을 제공한다.

두 시퀀스에 대한 접미사 배열 \(A_{1}\) \(A_{2}\) \(S_{1}\) 및 \(S_{2}\)이 주어지면 경계조건 때문에 단일 접미사 배열 \(A\) \(S=S_{1}\병렬 S_{2}\)을 구성하는 것은 완전히 사소하지 않다. 대신에, 우리는 데이터 \(S=S_{1}\ ||\ S_{2}\)를 구축하는 것이 아니라, 일부 \(K\)에 대해 \(S_{1}^{\prime}=S_{1}\ ||\ S_{2}[uptoK]\)를 가장 긴 부분 문자열 일치보다 더 크게 만든다. 그런 다음 \(S_{1}^{\prime}\)와 \(S_{2}\)에 배열을 구축한다. 배열 병합을 위해 인덱스 \(|S_{1}|\) 다음에 첫 번째 배열에서 항목을 제거하고 병합 정렬하여 두 번째 배열에 삽입할 수 있습니다.

부분 접미사 배열의 병렬 병합 이제 이 분리된 배열들을 하나의 접미사 배열로 병합한다 \(\mathcal{A}\), 두 부분 접미사 배열의 간단한 경우 \(B\)와 \(C\)를 함께 병합하고자 한다. 우리는 \(i=0\) 인덱스 \(B\)와 \(j=0\) 인덱스 \(C\)를 둠으로써 이를 달성할 수 있다. 그런 다음 알고리즘의 각 반복은 \(S_{B_{i\cdots}}<S_{C_{i}}\) 및 \(C_{i}\)가 그렇지 않으면 \(i=|B|-1\) 및 \(j=|C|-1\)까지 반복하면 \(B_{i}\)를 \(\mathcal{A}\)로 푸시한다. \(K\) 분할로 일반화하려면 위의 단일 비교를 각 반복에 대해 \(O(\log K)\ll 10\) 작업이 필요한 최소 힙으로 대체하기만 하면 됩니다.

일반적인 경우 이 알고리즘은 \(O(Nm\log(K))\)이고, 여기서 \(N\)는 데이터 세트의 길이, \(m\)는 접두사 일치의 평균 길이, \(K\)는 분할 수임을 관찰한다. 따라서 일반적인 경우 이 알고리즘을 선형 시간이라고 부르는 것은 잘못되었습니다. 가장 긴 일치의 길이는 가장 긴 시퀀스의 길이에 의해 위에 경계지어지기 때문에, 데이터세트의 크기가 데이터세트에서 가장 긴 시퀀스의 길이와 독립적인 한, 이 알고리즘은 여전히 효율적이다.

다시, 우리는 \(L\) 동시 작업들 사이에서 이 작업을 병렬화할 수 있다(실제로 우리는 \(K=L\)를 기계의 스레드 수로 설정한다). \(K=2\)의 경우 작업 \(l\)은 \(i\in[jN/L,(j+1)N/L]\)을 처리하고 \(S_{B_{i}}<S_{C_{j}}<S_{B_{j+1}}}\)이 되도록 \(C\)로 이진 검색하여 \(j\)의 경계를 선택합니다. \(K> 2\)는 모든 \(K\) 부분 접미사 배열에서 이것을 반복하는 것을 제외하고는 동일하다.

컴퓨팅 분석.우리는 \(96\) 코어와 \(768\)GB의 메모리를 사용하여 클라우드의 단일 VM에서 알고리즘을 실행합니다. 본 논문에서 제안한 알고리즘은 Wiki-40B 훈련 집합(\(3\) 백만 개의 예: \(4\)GB의 텍스트를 포함)을 \(2.3\)분 벽-시계 시간(\(2.1\) CPU-hours of work)으로 처리하는 것이 효율적이다. \(350\)GB C4 데이터 세트는 접미사 배열을 만드는 데 12시간(벽시계) 미만이 소요되지만 여전히 메모리가 제한되어 있으므로 \(\sim 1000\) CPU 시간에 해당합니다. 접미사 배열이 구성되면 C4 데이터 세트를 중복 제거하는 데 1시간 미만이 걸립니다.

이 알고리즘은 데이터세트 자체가 (임의의 위치에서 효율적으로 인덱싱할 수 있도록) 메모리에 적합해야 하지만, 전체 접미사 배열을 메모리에 적합시킬 필요는 없다는 점에 유의한다. 우리의 접미사 배열은 \(8\times\) 공간 오버헤드가 필요하기 때문에 이것은 다행입니다. 예를 들어, \(350\)GB C4에 대한 접미사 배열은 \(1.5\)TB입니다.

이 데이터 세트에 언어 모델을 학습시키는 비용과 비교하여, 학습 데이터 세트를 중복 제거하는 데 필요한 추가 작업은 무시할 수 있다.

중복 임계값 설정 중요한 질문은 부분 문자열 일치가 중복으로 계산되기 전에 얼마나 오래 일치해야 하는지입니다. 그림 5에서는 우리가 고려할 네 개의 데이터 세트 내의 부분 문자열 일치 빈도를 플롯한다. 길이 \(k\)의 각 부분 문자열에 대해, 우리는 이것과 동일한 길이 \(k\)의 다른 시퀀스가 존재할 확률을 계산한다.

도 4: 문서 유사도의 히스토그램.

one; formally:

\[m(k)=\Pr_{i\in[N]}\big{[}\exists j\neq i:\mathcal{S}_{i..i+k}=\mathcal{S}_{j..j+k} \big{]}.\]

우리는 \(50\) 토큰을 보수적인 임계값으로 선택하는데, "무릎 구부림"은 \(10\) 토큰에서 발생하며 길이-\(25\) 일치에 대한 수동 검사는 잘못된 긍정이 발견되지 않는다. 그런 다음 이 값을 두 배로 늘려 예외적으로 큰 오차 범위를 갖도록 했다.

## 부록 C 모델 교육에 대한 추가 세부 정보

각 모델은 두 개의 시대에 대해 훈련되었다. C4-Original 및 C4-ExactSubstr 둘 다 대략 365M 예들을 포함하기 때문에, 우리는 배치 크기가 4800(또는 대략 2 epochs)인 152K 단계들을 수행하였다. C4-NearDup에는 약 350M 예가 포함되어 있으며 146K 단계(또는 약 2개의 에폭)를 수행했다. 128코어 TPU v3 포드 슬라이스에서 C4-Original 및 C4-ExactSubstr에서 훈련된 XL 모델은 훈련하는 데 약 131시간(5.5일)이 걸린 반면, C4-NearDup에서 훈련된 XL 모델은 훈련하는 데 약 126시간이 걸렸다. T5와 마찬가지로 모델은 Adafactor optimizer Shazeer and Stern(2018)으로 훈련되었다. 기본 모델은 0.01, XL 모델은 0.001의 일정한 학습률을 사용했다.

1.5B 매개변수 XL 모델은 각각 32개의 주의 헤드를 갖는 24개의 층을 가졌다. 모델 임베딩 크기는 2,048개, 피드 포워드 레이어는 5,120개, 어텐션 헤드의 키/값 치수 크기는 64개였다. 110M 파라미터 베이스 모델은 각각 12개의 어텐션 헤드를 갖는 12개의 레이어를 가졌다. 모델 임베딩 크기는 768이었고, 피드 포워드 레이어는 2,048의 숨겨진 크기를 가졌으며, 어텐션 헤드(64)에 대한 키/값 치수 크기를 가졌다.

## 부록 D 에너지 소비

128-코어 TPU v3에서 약 131시간 또는 5.5일 동안 훈련하였다. 대략적인 중복 제거 데이터 세트는 원래 데이터 세트보다 3.9% 작고 63시간/에포크에서 훈련하여 두 에포크에 대해 약 5시간의 계산 시간을 절약했다. XL-Original 모델은 북미에서 훈련되었고, XL-ExactSubstr과 XL-NearDup은 대만에서 훈련되었다. Patterson et al.(2021)의 데이터를 사용하여 \(MWh\)/시간/코어의 양을 계산하고 사용량을 곱하여 이러한 모델을 훈련하는 데 사용되는 에너지 양을 추정했다(이러한 값을 계산하는 방법은 표 6 참조). 단순화를 위해 대만 데이터 센터의 추정치를 추정치로 사용합니다. 우리는 XL-Original과 XL-ExactSubstr의 훈련 2개의 epoch를 \(5.86MWh\)을 사용하여 추정한다. XL-NearDup은 더 적은 스텝에 대해 훈련되며, \(5.63MWh\)을 사용하여 추정한다. 각 기본 모델을 훈련하는 것은 추정된 \(1.61MWh\)를 사용하는 64코어 TPU v3 pod 슬라이스에서 약 3일이었다.

모델 훈련 외에도 64코어 TPU v3 포드 슬라이스에 대해 평가 및 추론을 수행했다. XL 모델에서 100,000개의 시퀀스를 생성하는 데 약 0.64시간이 걸린다. 모델당 총 1M 시퀀스에 대해 모델의 2개 체크포인트에 대해 5가지 유형의 프롬프트 각각에 대해 100,000개의 시퀀스를 생성했다. 이것은 대략 19.2시간이 걸렸다. 3M 시퀀스 생성은 \(0.43MWh\)를 사용한다.

## 부록 E 추가 결과

정성적 예.표 8은 편집 거리가 선택된 편집 유사성 임계값 0.8에 가까운 C4의 문서 쌍의 몇 가지 예를 보여준다. 표 9는 ExactSubstr에 의해 C4에 두 번 이상 있는 것으로 식별된 부분 문자열을 보여준다. 표 10은 암기된 것으로 확인된 비약적 세대의 몇 가지 예를 보여준다.

암기의 분포.도 6은 4가지 유형의 프롬프트를 사용할 때 생성된 모든 시퀀스에 걸친 암기량의 분포를 도시한 것으로, 열차에서 중복이 있는 열차 예,

그림 5: 길이 \(k\)의 각 부분 문자열에 대해 동일한 열차 집합에 두 번째 동일한 길이 \(k\) 부분 문자열이 존재할 확률을 플롯한다. \(10\) 하위 단어 토큰 아래의 길이를 가진 매치는 일반적이며 토큰의 \(90\%\)를 설명합니다. 우리는 실험을 위해 50의 임계값을 선택한다.

중복이 없는 예제, 트레인에서 중복이 있는 유효성 검사 예제 및 중복이 없는 유효성 검사 예제

중복이 많은 URL.표 11은 URL이 NearDup에 의해 거의 중복으로 식별된 예제의 가장 큰 비율을 가짐을 보여준다. C4의 경우, 이들은 많은 유사한 제품을 판매하고 따라서 많은 양의 템플릿 텍스트를 갖는 웹사이트인 경향이 있다. 리얼뉴스의 경우 콘텐츠 집계기가 특히 흔해 보인다.

NearDup 클러스터 크기.그림 8은 RealNews, LM1B 및 Wiki-40B에서 NearDup을 실행한 클러스터 크기의 분포를 보여줍니다(C4에 대한 결과는 그림 1의 주요 논문).

데이터 세트 SizesTable 13은 중복 제거 전후의 각 데이터 세트의 예제와 BPE 토큰의 크기를 제공합니다. 대부분의 데이터 세트가

\begin{table}
\begin{tabular}{l|r r r r r} \hline \hline  & \multicolumn{3}{c}{XL-Original} & \multicolumn{3}{c}{Base-Original} \\  & T5 11B & XL-ExactSubstr & XL-NearDup & Base-ExactSubstr & Total Inference \\ \hline TPU v3 cores & 512 & 128 & 128 & 64 & 64 \\ Training time (days) & 20 & 5.47 & 5.26 & 3 & 0.80 \\ TPU hrs & 245760 & 16804.70 & 16149.31 & 4608 & 1228.80 \\ Energy (MWh) & 85.70 & 5.86 & 5.63 & 1.61 & 0.43 \\ \hline \hline \end{tabular}
\end{table}
표 6: Patterson et al.(2021)의 데이터를 기반으로 한 에너지 사용량 추정치. 첫 번째 열은 Patterson et al. (2021)의 T5 11B 인코더-디코더 모델의 추정치이며, 이는 우리가 자체 추정치를 기반으로 한다. 추론에는 모든 XL 모델이 포함된다. 우리는 3개의 모델, 5개의 프롬프트, 2개의 다른 체크포인트에서 100,000개의 시퀀스를 생성했다.

\begin{table}
\begin{tabular}{l|l|l} \hline \hline Dataset & \multicolumn{1}{c|}{Example} & \multicolumn{1}{c}{Near-Duplicate Example} \\ \hline Wiki-40B & \begin{tabular}{l} \(\backslash\)in\_START\_ARTICLE\_unHum \\ \end{tabular} & Award & \begin{tabular}{l} \(\backslash\)in\_START\_ARTICLE\_unHum Award for Best Actor \\ in a Negative Role \(\backslash\)in\_START\_SECTION\_unWinners \\ and nomineus\_START\_PARAGRAPH\_unh the list \\ below, winners are listed first in the colored row, followed by the other nominees. [...] \\ \hline LM1B & \begin{tabular}{l} 1 left for California in 1979 and tracked Cleveland \\'s changes on trips back to visit my sisters : \\ \end{tabular} & \begin{tabular}{l} 1 left for California in 1979, and tracked Cleveland \\'s changes on trips back to visit my sisters : \\ \end{tabular} \\ \hline RealNews & \begin{tabular}{l} KUALA LUMPUR (Reuters) - Roads in Southeast \\ as moviecycle makers, an aspiring middle class \\ and easy bank credit come together to breed a new \\ genus of motorcyclists - the big-bike rider, [...] \\ \end{tabular} & \begin{tabular}{l} A visitor looks at a Triumph motorcycle on display at the Indonesian International Motor Show in Jakra September 19, 2014. REUTERS/Darren WhitesideuKUALA LUMPUR (Reuters) - Roads in Southeast Asia have been getting a little [...] big-bike rider. [...] \\ \end{tabular} \\ \hline C4 & \begin{tabular}{l} Affordable and convenient holiday flights take off from your departure country, "Canada", From May 2019 to October 2019, Condor flights to your destination will be roughly 6 a week! Book \\ your Halifax (YHZ) - Basel (BSL) flight now, and look forward to your “Switzerland” destination! \\ \end{tabular} &
\begin{tabular}{l} Affordable and convenient holiday flights take off from your departure country, "USA". From April 2019 to October 2019, Condor flights to your destination will be roughly 7 a week! Book \\ Maui Kahului (OG) - Dubrovnik (DBV) flight now, \\ and look forward to your “Croatia” destination! \\ \end{tabular} \\ \hline \hline \end{tabular}
\end{table}
표 7: 각 데이터 세트에서 NearDup에 의해 식별된 거의 중복의 정성적 예. 문서 간의 유사성이 강조 표시됩니다. 정확한 중복 매칭을 덜 효과적으로 만드는 작은 산재된 차이점에 주목하라. "[...]"로 끝나는 예들은 간결함을 위해 잘렸다.

그림 6: 기억된 연속체 분포

높은 수요로 인해 우리는 아직 이 요청에 대해 비판하지 않았습니다. 즉, 검토는 우리의 부지런하고 변함없는 직원이 전문적인 방식으로 적절한 시기에 생산될 것이라고 확신합니다. 이 사이트는 속도와 신뢰성 측면에서 동료들 사이에서 높은 평가를 받고 있으므로 언제든지 확인하세요!

이미 만드는 동안 정확한 일치가 중복 제거되었지만 ExactSubstrdeduplication은 실제로 어떤 예도 제거하지 않습니다.

LM1B에 대한 복잡성.그림 7은 LM1B에 대한 복잡성을 포함하는 것을 제외하고 본 논문의 그림 2와 동일하다. 가독성을 높이기 위해 본고의 그림에서 LM1B를 생략하였다.

\begin{table}
\begin{tabular}{l|c|c} \hline \hline
**Text** & **Freq in C4** \\ \hline HD wallpaper. This wallpaper was upload at April 19, 2019 upload by admin in.You can download it & 40,340 \\ in your computer by clicking resolution image in Download by size:. Don’t forget to rate and comment & \\ if you interest with this wallpaper. & \\ \hline to the address posted below. Include our failure information form,a packing slip with your Company & 5,900 \\ name, contact person, and Email address or phone number. Upon receipt of your repair, we’ll inspect it & \\ and then contact you with a quote or evaluation notice. Normal turn around for repair is 5 to 7 business & \\ days, with “Rush Repair” available. & \\ \hline is a great place to begin your search. Whether you are a first-time home buyer or you are already & 5,358 \\ familiar with the home buying process, you can be assured that you have the best tools and the perfect & \\ agent available to help with your & \\ \hline pics at these awesome group starting P letter. Desktop wallpapers were first introduced way back in & 848 \\ the 1980s and have gained immense popularity since then. It is possible to come across more than 80 million sites on the web offering some sort of wallpaper. & 479 \\ \hline flowers will let them know you’re thinking of them and wishing them well. Cheerful yellow flowers & 56 \\ bring their own sunshine and will get right to work on lifting spirits, and a colorful vase will bring & 56 \\ loads of smiles to friends and visitors! Get Well flower arrangements from & 48 \\ \hline our premier 24 hour emergency* plumbing and heating solutions. We realise that when your heating fails or pipes and drains leak it can cause havoc with your routine and even cause damage to your & 56 \\ property. When a plumbing problem occurs that requires an immediate response we provide qualified & \\ local plumbers throughout & \\ \hline is to remove all images that violate copyrights. Please contact us to request that images be removed or & 48 \\ to assign proper credit. The images displayed on this site may be used for Free or educational purposes & \\ only. If you would like to use any of the images displayed on this site for any other purpose, please & \\ obtain permission from the owner, www. & \\ \hline list of fishing locations, providing interactive maps that show each location’s GPS coordinates, nearby & 5 \\ facilities (like restaurants, gas stations, marinas and fishing shops), their current and forecasted weather & \\ and, if available, their water conditions.wirind any of the 8 & \\ \hline. Dyer, Ph.D., is an internationally renowned author and speaker in the field of self-development. He’s & 5 \\ the author of 30 books, has created many audio programs and videos, and has appeared on thousands & \\ \hline \hline \end{tabular}
\end{table}
표 9: ExactSubstr에 의해 C4에 여러 번 있는 것으로 식별된 부분 문자열의 선택. 이 정확한 부분 문자열이 C4에서 발생하는 횟수도 주어진다.

그림 7: 훈련 세트를 중복 제거하면 유효성 검사 복잡도에 미치는 영향. **(a)** 에서 서로 다른 무작위 초기화를 사용 하 여 세 가지 훈련 실행에 대 한 T5 기본 (110M 매개 변수)의 결과를 표시 합니다. 검은색 막대는 가장 낮은 복잡도에서 가장 높은 복잡도를 나타내고 색상 막대는 중앙 복잡도를 나타낸다. **(b)** 에서 T5 XL (1.5B 매개 변수)의 결과를 표시 합니다.

\begin{table}
\begin{tabular}{l|c} \hline \hline
**Generated Text** & **Freq in C4** \\ \hline \hline \end{tabular} \begin{tabular}{l|c} \hline \hline \(\,\), you’ll need to be knowledgeable to make the very best decisions. We will make sure you know what can be expected. We take the surprises from the picture by giving accurate and thorough information. \\ You can start by talking about your task with our client service staff when & \\ you dial 888-353-1299. We’ll address all of your questions and arrange the initial meeting. We work & \\ closely with you through the whole project, and our team can show up promptly and prepared. & \\ \hline then Waterside Lodge are well equipped for the task. Our fully equipped family sized lodges offer & 571 \\ a comfortable luxurious stay for a fantastic price, giving you beautiful views of the lakes and the surrounding counstride. Offering luxurious self-catering holidays in our fully featured Scandinavian & \\ holiday lodges. Perfectly located to explore the beaches, coastline. All of our lodges are sized for 6 & \\ people and are furnished to the highest standards to ensure you have a stay like no other. At Waterside & \\ Lodge the stay itself is only half of the package, Waterside lodge is situated closely to the Heritage Coast which makes our lodges the perfect stay for anyone wanting to get away and have a relaxing & \\ countryside break from the city. Whilst you stay with us be sure to take advantage of all the activities & \\ Waterside Lodge has to offer. Such as the use of our on-site fishing lakes for the keen fisherman, free & \\ internet access, outside relaxation areas, comfortable lounges and much more. & \\ \hline \hline you are only looking to find rent to own homes in your city or are open to exploring all kinds of rent to & 51 \\ own home listings, our database does it all. One of the best aspects of iKentToOwn.com is that, besides & \\ options to rent to buy a house, it has numerous other categories of home sale options. These include & \\ bank foreclosure homes, pre-foreclosure homes, short sales, HUD/government foreclosures, auction & \\ homes and owner-financing/FSBO (For Sale By Owner) homes. With help from the convenient search & \\ features offered by our site, shoppers are able to find their ideal lease to own home, real estate company, & \\ and more in South & & \\ \hline \end{tabular}
\begin{tabular}{l|c} \hline \hline \(\,\), IL employs journeyman as licensed to work by themselves, without direct supervision, installing wiring, outlets and fixtures. Our journeyman also does service work, troubleshooting when a breaker fails or a light stops working. Our journeyman does not offer permits that must be issued by our master. Our journeyman follows our master’s plans and directions. Our journeyman’s responsibilities will vary based on the work that needs to be done. Our journeyman are skilled with residential, commercial and industrial installations and repairs.ust work from six years as an apprentice, under direct supervision of our master, and pass a journeyman test. This person also must have some classroom education on the National Electrical Code and fundamental electricity in a technical school a program affiliated with the National Joint Apprenticeship Training Council. Journeyman training combines hands-on work with education on basic electricity. & 6 \\ \hline combustion process of a petrol engine is never perfect. Dangerous gases, such as nitrogen oxide, carbon monoxide and hydrocarbons will arise and it is the job of the catalytic converter to reduce these to safer emissions. These cat converters can fail by becoming clogged, or if the engine has bad exhaust valves or the plugs fail, causing unburned fuel to overheat the converter. Mettam’s Mufflers can resolve these issues with your Karr & 5 \\ \hline \hline ANDREW Find the ancestral town: Many a researcher is stuck behind records that say, BIRTHPLACE: IRELAND without saying where in Ireland, or whatever other country. Remember that your immigrant ancestor’s siblings probably were born in the same ancestral town, so check all o &

\begin{table}
\begin{tabular}{l|r r r r r r} \hline \hline \multicolumn{1}{c}{\multirow{2}{*}{Training Dataset:}} & \multicolumn{2}{c}{C4-Original} & \multicolumn{2}{c}{C4-NearDup} & \multicolumn{2}{c}{C4-ExactSubstr} \\ Epoch: & 1 & 2 & 1 & 2 & 1 & 2 \\ \hline No prompt & 1.93\% & 1.57\% & 0.19\% & 0.26\% & 0.14\% & 0.17\% \\ Duplicate Train Prompts & 35.88\% & 34.34\% & 3.34\% & 3.15\% & 5.71\% & 4.67\% \\ Unique Train Prompt & 0.42\% & 0.41\% & 0.42\% & 0.41\% & 0.22\% & 0.23\% \\ Duplicate Test Prompt & 16.27\% & 15.32\% & 1.61\% & 1.52\% & 0.34\% & 0.25\% \\ Unique Test Prompt & 0.25\% & 0.22\% & 0.21\% & 0.23\% & 0.03\% & 0.08\% \\ \hline \hline \end{tabular}
\end{table}
표 12: ExactSubstr에 따라 암기된 부분 문자열의 일부였던 100k 세대에서의 토큰의 백분율. 근사하거나 정확한 중복 제거로 훈련된 모델은 원본(중복되지 않은) 데이터 세트에서 훈련된 모델보다 암기가 \(10\times\) 적다.

\begin{table}
\begin{tabular}{l r r|r r r} \hline \hline \multicolumn{1}{c}{\multirow{2}{*}{RealNews Url}} & \multicolumn{1}{c}{\# Total} & \multicolumn{1}{c}{Frac Dups} & \multicolumn{1}{c}{C4 Url} & \multicolumn{1}{c}{\# Total} & \multicolumn{1}{c}{Frac Dups} \\ \hline medicalnewstoday.com & 12 & 1.00 & hairtechkearney.com & 4883 & 1 \\ dodbuzz.com & 301 & 0.99 & keywords.com & 1786 & 1 \\ underthreadarm.military.com & 187 & 0.97 & sydneystialianfruithsops.online & 1178 & 1 \\ q.ustoday.com & 33 & 0.94 & moewiki.usamin.info & 1001 & 1 \\ ad-test.thirdage.com & 354 & 0.94 & swarovskijewelryoutlet.org & 984 & 1 \\ amp.nymag.com & 15 & 0.93 & forzadutro.org & 980 & 1 \\ citizenwire.com & 1022 & 0.93 & producerati.com & 971 & 1 \\ paycheck-chronics.military.com & 363 & 0.92 & sourceryforge.org & 908 & 1 \\ product-reviews.net & 73403 & 0.92 & heavenz-kitchen.com & 876 & 1 \\ kitup.military.com & 196 & 0.92 & little-eclipse.com & 822 & 1 \\ gcaptain.com & 33903 & 0.92 & walops.com & 819 & 1 \\ dev.screenrant.com & 70 & 0.91 & 16thstlaunderland.com & 713 & 1 \\ live.swissinfo.ch & 66 & 0.91 & theroyalsstarinfo.com & 696 & 1 \\ news.theepothtimes.com & 82 & 0.87 & code4kt.com & 684 & 1 \\ opinion.toledoblade.com & 986 & 0.87 & nfflconisperses.us & 682 & 1 \\ cdn.moneytalksnews.com & 121 & 0.86 & quiltingbeeshop.com & 676 & 1 \\ amp.fox23.com & 14 & 0.86 & ulifeinsurancemiami.com & 675 & 1 \\ sales.rollingstone.com & 20 & 0.85 & wowkeyword.com & 673 & 1 \\ ftp.screenrant.com & 20 & 0.85 & taspetro.com & 671 & 1 \\ \hline \hline \end{tabular}
\end{table}
표 11: 왼쪽에는 NearDup(최소 10회 이상 발생한 URL로 필터링됨)에 의해 거의 중복으로 표시된 예제의 비율이 가장 높은 URL을 보여준다. 오른쪽에는 모든 예가 NearDup에 의해 거의 중복으로 표시된 C4에서 가장 빈번한 20개의 URL을 보여준다.

\begin{table}
\begin{tabular}{l|r r r r r r} \hline \hline \multicolumn{1}{c}{\multirow{2}{*}{Training Dataset:}} & \multicolumn{2}{c}{C4-Original} & \multicolumn{2}{c}{C4-NearDup} & \multicolumn{2}{c}{C4-ExactSubstr} \\ Epoch: & 1 & 2 & 1 & 2 & 1 & 2 \\ \hline No prompt & 1.93\% & 1.57\% & 0.19\% & 0.26\% & 0.14\% & 0.17\% \\ Duplicate Train Prompts & 35.88\% & 34.34\% & 3.34\% & 3.15\% & 5.71\% & 4.67\% \\ Unique Train Prompt & 0.42\% & 0.41\% & 0.42\% & 0.41\% & 0.22\% & 0.23\% \\ Duplicate Test Prompt & 16.27\% & 15.32\% & 1.61\% & 1.52\% & 0.34\% & 0.25\% \\ Unique Test Prompt & 0.25\% & 0.22\% & 0.21\% & 0.23\% & 0.03\% & 0.08\% \\ \hline \hline \end{tabular}
\end{table}
표 12: ExactSubstr에 따라 암기된 부분 문자열의 일부였던 100k 세대에서의 토큰의 백분율. 근사하거나 정확한 중복 제거로 훈련된 모델은 원본(중복되지 않은) 데이터 세트에서 훈련된 모델보다 암기가 \(10\times\) 적다.

그림 8: 각 데이터 세트에서 NearDup을 실행 하 여 거의 중복 된 클러스터 크기의 분포입니다.
