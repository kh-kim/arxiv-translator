{
    "2107.06499": {
        "paper_id": "2107.06499",
        "abs_url": "https://arxiv.org/abs/2107.06499",
        "pdf_url": "https://arxiv.org/pdf/2107.06499.pdf",
        "supp_url": null,
        "src_website": "ArXiv",
        "download_name": "2107.06499_Deduplicating_Training_Data_Makes_Language_Models_Better.pdf",
        "title": "Deduplicating Training Data Makes Language Models Better",
        "year": null,
        "paper_venue": null,
        "authors": [
            "Katherine Lee",
            "Daphne Ippolito",
            "Andrew Nystrom",
            "Chiyuan Zhang",
            "Douglas Eck",
            "Chris Callison-Burch",
            "Nicholas Carlini"
        ],
        "abstract": ".",
        "comments": "Accepted to ACL 2022",
        "official_code_urls": [
            "https://github.com/google-research/deduplicate-text-datasets"
        ],
        "pwc_page_url": "https://paperswithcode.com/paper/deduplicating-training-data-makes-language",
        "bibtex": "@misc{lee2022deduplicating,\n      title={Deduplicating Training Data Makes Language Models Better}, \n      author={Katherine Lee and Daphne Ippolito and Andrew Nystrom and Chiyuan Zhang and Douglas Eck and Chris Callison-Burch and Nicholas Carlini},\n      year={2022},\n      eprint={2107.06499},\n      archivePrefix={arXiv},\n      primaryClass={cs.CL}\n}"
    }
}