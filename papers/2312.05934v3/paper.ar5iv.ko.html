<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2312.05934] Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs</title><meta property="og:description" content="Large language models (LLMs) encapsulate a vast amount of factual information within their pre-trained weights, as evidenced by their ability to answer diverse questions across different domains. However, this knowledg…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2312.05934">

<!--Generated on Tue Feb 27 14:46:31 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on  %**** main.tex Line 100 **** .-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Fine-Tuning or Retrieval? 
<br class="ltx_break">Comparing Knowledge Injection in LLMs</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Oded Ovadia
</span><span class="ltx_author_notes">Corresponding author.Equal contribution.
<span class="ltx_contact ltx_role_affiliation">{odedovadia,t-mbrief,mmishaeli,oren.elisha}@microsoft.com 
<br class="ltx_break">Microsoft, Israel
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Menachem Brief<span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">0</span></span></span></span>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">{odedovadia,t-mbrief,mmishaeli,oren.elisha}@microsoft.com 
<br class="ltx_break">Microsoft, Israel
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Moshik Mishaeli
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">{odedovadia,t-mbrief,mmishaeli,oren.elisha}@microsoft.com 
<br class="ltx_break">Microsoft, Israel
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Oren Elisha
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">{odedovadia,t-mbrief,mmishaeli,oren.elisha}@microsoft.com 
<br class="ltx_break">Microsoft, Israel
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">대형 언어 모델(LLM)은 다양한 도메인에 걸쳐 다양한 질문에 답하는 능력에 의해 입증된 바와 같이 사전 훈련된 가중치 내에 방대한 양의 사실 정보를 캡슐화한다. 그러나 이러한 지식은 학습 데이터의 특성에 크게 의존하여 본질적으로 제한적이다. 결과적으로 외부 데이터 세트를 사용하여 새로운 정보를 통합하거나 이전에 볼 수 있는 정보에 대한 LLM의 기능을 개선하는 것은 상당한 문제를 제기한다. 본 연구에서는 비감독 미세 조정과 검색 증강 생성의 두 가지 일반적인 접근 방식을 비교한다. 우리는 서로 다른 주제에 걸쳐 다양한 지식 집약적 작업에 대한 두 접근 방식을 평가한다. 우리의 연구 결과는 감독되지 않은 미세 조정이 약간의 개선을 제공하지만 RAG가 훈련 중에 직면하는 기존 지식과 완전히 새로운 지식 모두에서 일관되게 이를 능가한다는 것을 보여준다. 더욱이, 우리는 LLM이 감독되지 않은 미세 조정을 통해 새로운 사실 정보를 배우기 위해 고군분투하고 훈련 중에 동일한 사실의 수많은 변형에 노출시키는 것이 이 문제를 완화할 수 있음을 발견했다.</p>
</div>
<div id="p1" class="ltx_para">
<p class="ltx_p" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1">Keywords:</span> LLMs, NLP, Fine-Tuning vs. RAG, 지식 및 사실성</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p" id="S1.p1.1">대형 언어 모델(LLM)은 방대한 양의 사실 정보 <cite class="ltx_cite ltx_citemacro_citep">(Petroni et al., <a class="ltx_ref" href="#bib.bib32" title="">2019</a>; Cohen et al., <a class="ltx_ref" href="#bib.bib8" title="">2023</a>; Hu et al., <a class="ltx_ref" href="#bib.bib13" title="">2023</a>)</cite>를 캡처할 수 있다. LLM은 방대한 사전 훈련 데이터 세트로 인해 다양한 영역에서 놀라운 수준의 지식을 보여준다. 그러나 이 지식에는 두 가지 중요한 한계가 있다. 첫째, 정적이며 시간에 따라 업데이트되지 않습니다. 둘째, 비특정적이어서 특정 도메인에 대한 미묘한 전문 지식이 부족할 수 있다. 이것은 두 가지 다른 문제이지만, 그들의 해결책은 동일하기 때문에 깊이 관련되어 있다: 모델의 지식을 향상시키는 것이다.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p" id="S1.p2.1">최근 LLM을 특정 도메인에 적용하고 지식을 업데이트하는 아이디어가 점점 더 보편화되고 있다<cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="#bib.bib54" title="">2022</a>)</cite> 헬스케어 <cite class="ltx_cite ltx_citemacro_citep">(Singhal et al., <a class="ltx_ref" href="#bib.bib39" title="">2023a</a>, <a class="ltx_ref" href="#bib.bib40" title="">b</a>; Wu et al., <a class="ltx_ref" href="#bib.bib50" title="">2023a</a>)</cite>, 금융 <cite class="ltx_cite ltx_citemacro_citep">(Wu et al., <a class="ltx_ref" href="#bib.bib51" title="">2023b</a>; Yang et al., <a class="ltx_ref" href="#bib.bib53" title="">2023</a>)</cite>, 법률 <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a class="ltx_ref" href="#bib.bib14" title="">2023</a>; Nguyen, <a class="ltx_ref" href="#bib.bib28" title="">2023</a>)</cite> 등 다양한 분야에서 사실적 지식과 역량을 향상시키기 위한 다양한 모델이 제시되고 있다.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p" id="S1.p3.1">이 작업에서는 모델의 지식과 사실 데이터를 암기, 이해 및 검색하는 능력에 대한 평가에 중점을 둔다. <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">knowledge injection</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib48" title="">2020</a>; Chen et al., <a class="ltx_ref" href="#bib.bib4" title="">2022</a>; Liu et al., <a class="ltx_ref" href="#bib.bib22" title="">2020</a>; Lauscher et al., <a class="ltx_ref" href="#bib.bib20" title="">2020</a>)</cite>의 개념을 이해하고자 한다. 텍스트 코퍼스 형태의 지식 기반이 주어진다면, 사전 훈련된 모델을 이 지식을 가르치는 가장 좋은 방법은 무엇인가?</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p" id="S1.p4.1">사전 학습된 모델에 지식을 추가하는 한 가지 방법은 미세 조정을 통한 것이다. 미세 조정을 통해 모델의 훈련 과정을 계속하고 작업별 데이터를 사용하여 적응시킨다. 모델을 특정 지식베이스에 노출시킴으로써 모델 가중치가 그에 따라 적응할 수 있을 것으로 기대한다. 이 프로세스는 타겟팅된 애플리케이션들에 대한 모델을 최적화하여, 그 성능 및 특수 도메인들에서의 맥락적 관련성을 향상시키는 것을 의미한다.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p" id="S1.p5.1">모델의 지식베이스를 향상시키는 또 다른 방법은 in-context learning (ICL) <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="#bib.bib5" title="">2021</a>; Radford et al., <a class="ltx_ref" href="#bib.bib33" title="">2019</a>; Min et al., <a class="ltx_ref" href="#bib.bib24" title="">2021</a>; Lampinen et al., <a class="ltx_ref" href="#bib.bib19" title="">2022</a>)</cite>를 사용하는 것이다. ICL의 주요 아이디어는 모델의 가중치를 직접 변경하지 않고 입력 쿼리를 모델로 수정하여 새로운 태스크에 대한 사전 훈련된 LLM의 성능을 향상시키는 것이다. ICL의 한 형태는 검색 증강 생성(RAG) <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="#bib.bib21" title="">2020</a>; Neelakantan et al., <a class="ltx_ref" href="#bib.bib27" title="">2022</a>)</cite>이다. RAG는 정보 검색 기술을 사용하여 LLM이 지식 소스로부터 관련 정보를 얻고 이를 생성된 텍스트에 통합할 수 있도록 한다.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p class="ltx_p" id="S1.p6.1">본 연구는 미세 조정과 RAG의 비교를 통해 LLM의 지식 주입 능력을 평가하는 것을 목적으로 한다. 그 근거를 설명하기 위해, 비유를 사용하자. 특정 주제에 대한 시험을 보는 대학생 세 명을 고려해보자. 모두 수업 자료에 접근할 수 있었지만 그 주제를 미리 알지 못했다. 첫 번째 학생은 시험 중에만 교과서를 가지고 있었고, 두 번째 학생은 시험 전에 접근하여 공부했으며, 세 번째 학생은 시험 발표로 접근성을 잃었다. 누가 더 잘했을까요?</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>

<figure id="S2.F1" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2312.05934/assets/media/Wikipedia.jpg" id="S2.F1.g1" class="ltx_graphics ltx_img_landscape" width="586" height="328" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.2.1.1" style="font-size:90%;">Figure 1</span>:</span><span class="ltx_text" id="S2.F1.3.2" style="font-size:90%;">A visualization of the knowledge injection framework. </span></figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p class="ltx_p" id="S2.p1.1"><span class="ltx_text ltx_font_italic" id="S2.p1.1.1">knowledge injection</span>을 평가하려면 먼저 LLMs에 대한 <span class="ltx_text ltx_font_italic" id="S2.p1.1.2">knowledge</span>의 의미를 이해해야 합니다.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Knowledge and Language Models</span>  Defining knowledge is a complex philosophical task from far beyond the scope of this research. 그러나 우리는 언어 모델의 맥락에서 사실적 지식이 무엇을 의미하는지 살펴볼 수 있다. 모델이 사실을 안다면, 그것은 그것에 대한 질문에 정확하고 일관되게 대답할 수 있다. 나아가 이 사실과 관련된 참진술과 거짓진술을 확실하게 구분할 수 있다. 그런 다음 우리는 이 정의를 하나의 사실이 아닌 전체 지식 베이스로 확장할 수 있다.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.5" class="ltx_p">Mathematically, let <math id="S2.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{Q}=\{q_{n}\}_{n=1}^{N}" display="inline"><semantics id="S2.p3.1.m1.1a"><mrow id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p3.1.m1.1.1.3" xref="S2.p3.1.m1.1.1.3.cmml">𝒬</mi><mo id="S2.p3.1.m1.1.1.2" xref="S2.p3.1.m1.1.1.2.cmml">=</mo><msubsup id="S2.p3.1.m1.1.1.1" xref="S2.p3.1.m1.1.1.1.cmml"><mrow id="S2.p3.1.m1.1.1.1.1.1.1" xref="S2.p3.1.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.p3.1.m1.1.1.1.1.1.1.2" xref="S2.p3.1.m1.1.1.1.1.1.2.cmml">{</mo><msub id="S2.p3.1.m1.1.1.1.1.1.1.1" xref="S2.p3.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S2.p3.1.m1.1.1.1.1.1.1.1.2" xref="S2.p3.1.m1.1.1.1.1.1.1.1.2.cmml">q</mi><mi id="S2.p3.1.m1.1.1.1.1.1.1.1.3" xref="S2.p3.1.m1.1.1.1.1.1.1.1.3.cmml">n</mi></msub><mo stretchy="false" id="S2.p3.1.m1.1.1.1.1.1.1.3" xref="S2.p3.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p3.1.m1.1.1.1.1.3" xref="S2.p3.1.m1.1.1.1.1.3.cmml"><mi id="S2.p3.1.m1.1.1.1.1.3.2" xref="S2.p3.1.m1.1.1.1.1.3.2.cmml">n</mi><mo id="S2.p3.1.m1.1.1.1.1.3.1" xref="S2.p3.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S2.p3.1.m1.1.1.1.1.3.3" xref="S2.p3.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S2.p3.1.m1.1.1.1.3" xref="S2.p3.1.m1.1.1.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><apply id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1"><eq id="S2.p3.1.m1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.2"></eq><ci id="S2.p3.1.m1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.3">𝒬</ci><apply id="S2.p3.1.m1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.1">superscript</csymbol><apply id="S2.p3.1.m1.1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.1">subscript</csymbol><set id="S2.p3.1.m1.1.1.1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1"><apply id="S2.p3.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p3.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1.2">𝑞</ci><ci id="S2.p3.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1.3">𝑛</ci></apply></set><apply id="S2.p3.1.m1.1.1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.1.1.3"><eq id="S2.p3.1.m1.1.1.1.1.3.1.cmml" xref="S2.p3.1.m1.1.1.1.1.3.1"></eq><ci id="S2.p3.1.m1.1.1.1.1.3.2.cmml" xref="S2.p3.1.m1.1.1.1.1.3.2">𝑛</ci><cn type="integer" id="S2.p3.1.m1.1.1.1.1.3.3.cmml" xref="S2.p3.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S2.p3.1.m1.1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.1.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">\mathcal{Q}=\{q_{n}\}_{n=1}^{N}</annotation></semantics></math> be a set of <math id="S2.p3.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.p3.2.m2.1a"><mi id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b"><ci id="S2.p3.2.m2.1.1.cmml" xref="S2.p3.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">N</annotation></semantics></math> multiple choice factual questions, where each question has <math id="S2.p3.3.m3.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S2.p3.3.m3.1a"><mi id="S2.p3.3.m3.1.1" xref="S2.p3.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.p3.3.m3.1b"><ci id="S2.p3.3.m3.1.1.cmml" xref="S2.p3.3.m3.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.3.m3.1c">L</annotation></semantics></math> possible answers and exactly one correct answer. Let <math id="S2.p3.4.m4.2" class="ltx_Math" alttext="\mathcal{A}=\{(a_{n}^{1},\ldots,a_{n}^{L})\}_{n=1}^{N}" display="inline"><semantics id="S2.p3.4.m4.2a"><mrow id="S2.p3.4.m4.2.2" xref="S2.p3.4.m4.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p3.4.m4.2.2.3" xref="S2.p3.4.m4.2.2.3.cmml">𝒜</mi><mo id="S2.p3.4.m4.2.2.2" xref="S2.p3.4.m4.2.2.2.cmml">=</mo><msubsup id="S2.p3.4.m4.2.2.1" xref="S2.p3.4.m4.2.2.1.cmml"><mrow id="S2.p3.4.m4.2.2.1.1.1.1" xref="S2.p3.4.m4.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S2.p3.4.m4.2.2.1.1.1.1.2" xref="S2.p3.4.m4.2.2.1.1.1.2.cmml">{</mo><mrow id="S2.p3.4.m4.2.2.1.1.1.1.1.2" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.p3.4.m4.2.2.1.1.1.1.1.2.3" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml">(</mo><msubsup id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.cmml"><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.2" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.2.cmml">a</mi><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.3" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.3.cmml">n</mi><mn id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.3" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.3.cmml">1</mn></msubsup><mo id="S2.p3.4.m4.2.2.1.1.1.1.1.2.4" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml">,</mo><mi mathvariant="normal" id="S2.p3.4.m4.1.1" xref="S2.p3.4.m4.1.1.cmml">…</mi><mo id="S2.p3.4.m4.2.2.1.1.1.1.1.2.5" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml">,</mo><msubsup id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.cmml"><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.2" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.2.cmml">a</mi><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.3" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.3.cmml">n</mi><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.3" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.3.cmml">L</mi></msubsup><mo stretchy="false" id="S2.p3.4.m4.2.2.1.1.1.1.1.2.6" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S2.p3.4.m4.2.2.1.1.1.1.3" xref="S2.p3.4.m4.2.2.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p3.4.m4.2.2.1.1.3" xref="S2.p3.4.m4.2.2.1.1.3.cmml"><mi id="S2.p3.4.m4.2.2.1.1.3.2" xref="S2.p3.4.m4.2.2.1.1.3.2.cmml">n</mi><mo id="S2.p3.4.m4.2.2.1.1.3.1" xref="S2.p3.4.m4.2.2.1.1.3.1.cmml">=</mo><mn id="S2.p3.4.m4.2.2.1.1.3.3" xref="S2.p3.4.m4.2.2.1.1.3.3.cmml">1</mn></mrow><mi id="S2.p3.4.m4.2.2.1.3" xref="S2.p3.4.m4.2.2.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.4.m4.2b"><apply id="S2.p3.4.m4.2.2.cmml" xref="S2.p3.4.m4.2.2"><eq id="S2.p3.4.m4.2.2.2.cmml" xref="S2.p3.4.m4.2.2.2"></eq><ci id="S2.p3.4.m4.2.2.3.cmml" xref="S2.p3.4.m4.2.2.3">𝒜</ci><apply id="S2.p3.4.m4.2.2.1.cmml" xref="S2.p3.4.m4.2.2.1"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.2.cmml" xref="S2.p3.4.m4.2.2.1">superscript</csymbol><apply id="S2.p3.4.m4.2.2.1.1.cmml" xref="S2.p3.4.m4.2.2.1"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.2.cmml" xref="S2.p3.4.m4.2.2.1">subscript</csymbol><set id="S2.p3.4.m4.2.2.1.1.1.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1"><vector id="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2"><apply id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.2">𝑎</ci><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.3">𝑛</ci></apply><cn type="integer" id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.3.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.3">1</cn></apply><ci id="S2.p3.4.m4.1.1.cmml" xref="S2.p3.4.m4.1.1">…</ci><apply id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2">superscript</csymbol><apply id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2">subscript</csymbol><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.2">𝑎</ci><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.3.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.3">𝑛</ci></apply><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.3.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.3">𝐿</ci></apply></vector></set><apply id="S2.p3.4.m4.2.2.1.1.3.cmml" xref="S2.p3.4.m4.2.2.1.1.3"><eq id="S2.p3.4.m4.2.2.1.1.3.1.cmml" xref="S2.p3.4.m4.2.2.1.1.3.1"></eq><ci id="S2.p3.4.m4.2.2.1.1.3.2.cmml" xref="S2.p3.4.m4.2.2.1.1.3.2">𝑛</ci><cn type="integer" id="S2.p3.4.m4.2.2.1.1.3.3.cmml" xref="S2.p3.4.m4.2.2.1.1.3.3">1</cn></apply></apply><ci id="S2.p3.4.m4.2.2.1.3.cmml" xref="S2.p3.4.m4.2.2.1.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.4.m4.2c">\mathcal{A}=\{(a_{n}^{1},\ldots,a_{n}^{L})\}_{n=1}^{N}</annotation></semantics></math> be the corresponding set of possible answers, and <math id="S2.p3.5.m5.1" class="ltx_Math" alttext="\mathcal{C}=\{c_{n}\}_{n=1}^{N}" display="inline"><semantics id="S2.p3.5.m5.1a"><mrow id="S2.p3.5.m5.1.1" xref="S2.p3.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p3.5.m5.1.1.3" xref="S2.p3.5.m5.1.1.3.cmml">𝒞</mi><mo id="S2.p3.5.m5.1.1.2" xref="S2.p3.5.m5.1.1.2.cmml">=</mo><msubsup id="S2.p3.5.m5.1.1.1" xref="S2.p3.5.m5.1.1.1.cmml"><mrow id="S2.p3.5.m5.1.1.1.1.1.1" xref="S2.p3.5.m5.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.p3.5.m5.1.1.1.1.1.1.2" xref="S2.p3.5.m5.1.1.1.1.1.2.cmml">{</mo><msub id="S2.p3.5.m5.1.1.1.1.1.1.1" xref="S2.p3.5.m5.1.1.1.1.1.1.1.cmml"><mi id="S2.p3.5.m5.1.1.1.1.1.1.1.2" xref="S2.p3.5.m5.1.1.1.1.1.1.1.2.cmml">c</mi><mi id="S2.p3.5.m5.1.1.1.1.1.1.1.3" xref="S2.p3.5.m5.1.1.1.1.1.1.1.3.cmml">n</mi></msub><mo stretchy="false" id="S2.p3.5.m5.1.1.1.1.1.1.3" xref="S2.p3.5.m5.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p3.5.m5.1.1.1.1.3" xref="S2.p3.5.m5.1.1.1.1.3.cmml"><mi id="S2.p3.5.m5.1.1.1.1.3.2" xref="S2.p3.5.m5.1.1.1.1.3.2.cmml">n</mi><mo id="S2.p3.5.m5.1.1.1.1.3.1" xref="S2.p3.5.m5.1.1.1.1.3.1.cmml">=</mo><mn id="S2.p3.5.m5.1.1.1.1.3.3" xref="S2.p3.5.m5.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S2.p3.5.m5.1.1.1.3" xref="S2.p3.5.m5.1.1.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.5.m5.1b"><apply id="S2.p3.5.m5.1.1.cmml" xref="S2.p3.5.m5.1.1"><eq id="S2.p3.5.m5.1.1.2.cmml" xref="S2.p3.5.m5.1.1.2"></eq><ci id="S2.p3.5.m5.1.1.3.cmml" xref="S2.p3.5.m5.1.1.3">𝒞</ci><apply id="S2.p3.5.m5.1.1.1.cmml" xref="S2.p3.5.m5.1.1.1"><csymbol cd="ambiguous" id="S2.p3.5.m5.1.1.1.2.cmml" xref="S2.p3.5.m5.1.1.1">superscript</csymbol><apply id="S2.p3.5.m5.1.1.1.1.cmml" xref="S2.p3.5.m5.1.1.1"><csymbol cd="ambiguous" id="S2.p3.5.m5.1.1.1.1.2.cmml" xref="S2.p3.5.m5.1.1.1">subscript</csymbol><set id="S2.p3.5.m5.1.1.1.1.1.2.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1"><apply id="S2.p3.5.m5.1.1.1.1.1.1.1.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.5.m5.1.1.1.1.1.1.1.1.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p3.5.m5.1.1.1.1.1.1.1.2.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1.1.2">𝑐</ci><ci id="S2.p3.5.m5.1.1.1.1.1.1.1.3.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1.1.3">𝑛</ci></apply></set><apply id="S2.p3.5.m5.1.1.1.1.3.cmml" xref="S2.p3.5.m5.1.1.1.1.3"><eq id="S2.p3.5.m5.1.1.1.1.3.1.cmml" xref="S2.p3.5.m5.1.1.1.1.3.1"></eq><ci id="S2.p3.5.m5.1.1.1.1.3.2.cmml" xref="S2.p3.5.m5.1.1.1.1.3.2">𝑛</ci><cn type="integer" id="S2.p3.5.m5.1.1.1.1.3.3.cmml" xref="S2.p3.5.m5.1.1.1.1.3.3">1</cn></apply></apply><ci id="S2.p3.5.m5.1.1.1.3.cmml" xref="S2.p3.5.m5.1.1.1.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.5.m5.1c">\mathcal{C}=\{c_{n}\}_{n=1}^{N}</annotation></semantics></math> be the correct answers.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.3" class="ltx_p">Let <math id="S2.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S2.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p4.1.m1.1.1" xref="S2.p4.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S2.p4.1.m1.1b"><ci id="S2.p4.1.m1.1.1.cmml" xref="S2.p4.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.1.m1.1c">\mathcal{M}</annotation></semantics></math> be a language model. We denote by <math id="S2.p4.2.m2.4" class="ltx_Math" alttext="\mathcal{M}(q_{n})\in\{a_{n}^{1},\ldots,a_{n}^{L}\}" display="inline"><semantics id="S2.p4.2.m2.4a"><mrow id="S2.p4.2.m2.4.4" xref="S2.p4.2.m2.4.4.cmml"><mrow id="S2.p4.2.m2.2.2.1" xref="S2.p4.2.m2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p4.2.m2.2.2.1.3" xref="S2.p4.2.m2.2.2.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S2.p4.2.m2.2.2.1.2" xref="S2.p4.2.m2.2.2.1.2.cmml">​</mo><mrow id="S2.p4.2.m2.2.2.1.1.1" xref="S2.p4.2.m2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.p4.2.m2.2.2.1.1.1.2" xref="S2.p4.2.m2.2.2.1.1.1.1.cmml">(</mo><msub id="S2.p4.2.m2.2.2.1.1.1.1" xref="S2.p4.2.m2.2.2.1.1.1.1.cmml"><mi id="S2.p4.2.m2.2.2.1.1.1.1.2" xref="S2.p4.2.m2.2.2.1.1.1.1.2.cmml">q</mi><mi id="S2.p4.2.m2.2.2.1.1.1.1.3" xref="S2.p4.2.m2.2.2.1.1.1.1.3.cmml">n</mi></msub><mo stretchy="false" id="S2.p4.2.m2.2.2.1.1.1.3" xref="S2.p4.2.m2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.p4.2.m2.4.4.4" xref="S2.p4.2.m2.4.4.4.cmml">∈</mo><mrow id="S2.p4.2.m2.4.4.3.2" xref="S2.p4.2.m2.4.4.3.3.cmml"><mo stretchy="false" id="S2.p4.2.m2.4.4.3.2.3" xref="S2.p4.2.m2.4.4.3.3.cmml">{</mo><msubsup id="S2.p4.2.m2.3.3.2.1.1" xref="S2.p4.2.m2.3.3.2.1.1.cmml"><mi id="S2.p4.2.m2.3.3.2.1.1.2.2" xref="S2.p4.2.m2.3.3.2.1.1.2.2.cmml">a</mi><mi id="S2.p4.2.m2.3.3.2.1.1.2.3" xref="S2.p4.2.m2.3.3.2.1.1.2.3.cmml">n</mi><mn id="S2.p4.2.m2.3.3.2.1.1.3" xref="S2.p4.2.m2.3.3.2.1.1.3.cmml">1</mn></msubsup><mo id="S2.p4.2.m2.4.4.3.2.4" xref="S2.p4.2.m2.4.4.3.3.cmml">,</mo><mi mathvariant="normal" id="S2.p4.2.m2.1.1" xref="S2.p4.2.m2.1.1.cmml">…</mi><mo id="S2.p4.2.m2.4.4.3.2.5" xref="S2.p4.2.m2.4.4.3.3.cmml">,</mo><msubsup id="S2.p4.2.m2.4.4.3.2.2" xref="S2.p4.2.m2.4.4.3.2.2.cmml"><mi id="S2.p4.2.m2.4.4.3.2.2.2.2" xref="S2.p4.2.m2.4.4.3.2.2.2.2.cmml">a</mi><mi id="S2.p4.2.m2.4.4.3.2.2.2.3" xref="S2.p4.2.m2.4.4.3.2.2.2.3.cmml">n</mi><mi id="S2.p4.2.m2.4.4.3.2.2.3" xref="S2.p4.2.m2.4.4.3.2.2.3.cmml">L</mi></msubsup><mo stretchy="false" id="S2.p4.2.m2.4.4.3.2.6" xref="S2.p4.2.m2.4.4.3.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p4.2.m2.4b"><apply id="S2.p4.2.m2.4.4.cmml" xref="S2.p4.2.m2.4.4"><in id="S2.p4.2.m2.4.4.4.cmml" xref="S2.p4.2.m2.4.4.4"></in><apply id="S2.p4.2.m2.2.2.1.cmml" xref="S2.p4.2.m2.2.2.1"><times id="S2.p4.2.m2.2.2.1.2.cmml" xref="S2.p4.2.m2.2.2.1.2"></times><ci id="S2.p4.2.m2.2.2.1.3.cmml" xref="S2.p4.2.m2.2.2.1.3">ℳ</ci><apply id="S2.p4.2.m2.2.2.1.1.1.1.cmml" xref="S2.p4.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p4.2.m2.2.2.1.1.1.1.1.cmml" xref="S2.p4.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S2.p4.2.m2.2.2.1.1.1.1.2.cmml" xref="S2.p4.2.m2.2.2.1.1.1.1.2">𝑞</ci><ci id="S2.p4.2.m2.2.2.1.1.1.1.3.cmml" xref="S2.p4.2.m2.2.2.1.1.1.1.3">𝑛</ci></apply></apply><set id="S2.p4.2.m2.4.4.3.3.cmml" xref="S2.p4.2.m2.4.4.3.2"><apply id="S2.p4.2.m2.3.3.2.1.1.cmml" xref="S2.p4.2.m2.3.3.2.1.1"><csymbol cd="ambiguous" id="S2.p4.2.m2.3.3.2.1.1.1.cmml" xref="S2.p4.2.m2.3.3.2.1.1">superscript</csymbol><apply id="S2.p4.2.m2.3.3.2.1.1.2.cmml" xref="S2.p4.2.m2.3.3.2.1.1"><csymbol cd="ambiguous" id="S2.p4.2.m2.3.3.2.1.1.2.1.cmml" xref="S2.p4.2.m2.3.3.2.1.1">subscript</csymbol><ci id="S2.p4.2.m2.3.3.2.1.1.2.2.cmml" xref="S2.p4.2.m2.3.3.2.1.1.2.2">𝑎</ci><ci id="S2.p4.2.m2.3.3.2.1.1.2.3.cmml" xref="S2.p4.2.m2.3.3.2.1.1.2.3">𝑛</ci></apply><cn type="integer" id="S2.p4.2.m2.3.3.2.1.1.3.cmml" xref="S2.p4.2.m2.3.3.2.1.1.3">1</cn></apply><ci id="S2.p4.2.m2.1.1.cmml" xref="S2.p4.2.m2.1.1">…</ci><apply id="S2.p4.2.m2.4.4.3.2.2.cmml" xref="S2.p4.2.m2.4.4.3.2.2"><csymbol cd="ambiguous" id="S2.p4.2.m2.4.4.3.2.2.1.cmml" xref="S2.p4.2.m2.4.4.3.2.2">superscript</csymbol><apply id="S2.p4.2.m2.4.4.3.2.2.2.cmml" xref="S2.p4.2.m2.4.4.3.2.2"><csymbol cd="ambiguous" id="S2.p4.2.m2.4.4.3.2.2.2.1.cmml" xref="S2.p4.2.m2.4.4.3.2.2">subscript</csymbol><ci id="S2.p4.2.m2.4.4.3.2.2.2.2.cmml" xref="S2.p4.2.m2.4.4.3.2.2.2.2">𝑎</ci><ci id="S2.p4.2.m2.4.4.3.2.2.2.3.cmml" xref="S2.p4.2.m2.4.4.3.2.2.2.3">𝑛</ci></apply><ci id="S2.p4.2.m2.4.4.3.2.2.3.cmml" xref="S2.p4.2.m2.4.4.3.2.2.3">𝐿</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.2.m2.4c">\mathcal{M}(q_{n})\in\{a_{n}^{1},\ldots,a_{n}^{L}\}</annotation></semantics></math> the predicted answer of the model to the <math id="S2.p4.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.p4.3.m3.1a"><mi id="S2.p4.3.m3.1.1" xref="S2.p4.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.p4.3.m3.1b"><ci id="S2.p4.3.m3.1.1.cmml" xref="S2.p4.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.3.m3.1c">n</annotation></semantics></math>-th question.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p class="ltx_p" id="S2.p5.3"><math alttext="\mathcal{Q}" class="ltx_Math" display="inline" id="S2.p5.3.m3.1"><semantics id="S2.p5.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p5.3.m3.1.1" xref="S2.p5.3.m3.1.1.cmml">𝒬</mi><annotation-xml encoding="MathML-Content" id="S2.p5.3.m3.1b"><ci id="S2.p5.3.m3.1.1.cmml" xref="S2.p5.3.m3.1.1">𝒬</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.3.m3.1c">\mathcal{Q}</annotation></semantics></math>와 관련하여 <span class="ltx_text ltx_font_italic" id="S2.p5.3.1">knowledge score</span> <math alttext="\mathcal{L}" class="ltx_Math" display="inline" id="S2.p5.1.m1.1"><semantics id="S2.p5.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p5.1.m1.1.1" xref="S2.p5.1.m1.1.1.cmml">ℒ</mi><annotation-xml encoding="MathML-Content" id="S2.p5.1.m1.1b"><ci id="S2.p5.1.m1.1.1.cmml" xref="S2.p5.1.m1.1.1">ℒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.1.m1.1c">\mathcal{L}</annotation></semantics></math>의 <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S2.p5.2.m2.1"><semantics id="S2.p5.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p5.2.m2.1.1" xref="S2.p5.2.m2.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S2.p5.2.m2.1b"><ci id="S2.p5.2.m2.1.1.cmml" xref="S2.p5.2.m2.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.2.m2.1c">\mathcal{M}</annotation></semantics></math>를 표준 정확도 점수로 정의한다:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.5" class="ltx_Math" alttext="\mathcal{L}_{\mathcal{M},\mathcal{Q}}:=\frac{\#\{q_{n}|\;\mathcal{M}(q_{n})=c_{n}\}}{N}." display="block"><semantics id="S2.E1.m1.5a"><mrow id="S2.E1.m1.5.5.1" xref="S2.E1.m1.5.5.1.1.cmml"><mrow id="S2.E1.m1.5.5.1.1" xref="S2.E1.m1.5.5.1.1.cmml"><msub id="S2.E1.m1.5.5.1.1.2" xref="S2.E1.m1.5.5.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.5.5.1.1.2.2" xref="S2.E1.m1.5.5.1.1.2.2.cmml">ℒ</mi><mrow id="S2.E1.m1.2.2.2.4" xref="S2.E1.m1.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml">ℳ</mi><mo id="S2.E1.m1.2.2.2.4.1" xref="S2.E1.m1.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.2.2.2.2" xref="S2.E1.m1.2.2.2.2.cmml">𝒬</mi></mrow></msub><mo lspace="0.278em" rspace="0.278em" id="S2.E1.m1.5.5.1.1.1" xref="S2.E1.m1.5.5.1.1.1.cmml">:=</mo><mfrac id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml"><mrow id="S2.E1.m1.4.4.2" xref="S2.E1.m1.4.4.2.cmml"><mi mathvariant="normal" id="S2.E1.m1.4.4.2.4" xref="S2.E1.m1.4.4.2.4.cmml">#</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.2.3" xref="S2.E1.m1.4.4.2.3.cmml">​</mo><mrow id="S2.E1.m1.4.4.2.2.2" xref="S2.E1.m1.4.4.2.2.3.cmml"><mo stretchy="false" id="S2.E1.m1.4.4.2.2.2.3" xref="S2.E1.m1.4.4.2.2.3.1.cmml">{</mo><msub id="S2.E1.m1.3.3.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.cmml"><mi id="S2.E1.m1.3.3.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.2.cmml">q</mi><mi id="S2.E1.m1.3.3.1.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.3.cmml">n</mi></msub><mo lspace="0em" id="S2.E1.m1.4.4.2.2.2.4" xref="S2.E1.m1.4.4.2.2.3.1.cmml">|</mo><mrow id="S2.E1.m1.4.4.2.2.2.2" xref="S2.E1.m1.4.4.2.2.2.2.cmml"><mrow id="S2.E1.m1.4.4.2.2.2.2.1" xref="S2.E1.m1.4.4.2.2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.4.4.2.2.2.2.1.3" xref="S2.E1.m1.4.4.2.2.2.2.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.2.2.2.2.1.2" xref="S2.E1.m1.4.4.2.2.2.2.1.2.cmml">​</mo><mrow id="S2.E1.m1.4.4.2.2.2.2.1.1.1" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.4.4.2.2.2.2.1.1.1.2" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml">(</mo><msub id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml"><mi id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.2" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.2.cmml">q</mi><mi id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.3" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.3.cmml">n</mi></msub><mo stretchy="false" id="S2.E1.m1.4.4.2.2.2.2.1.1.1.3" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.4.4.2.2.2.2.2" xref="S2.E1.m1.4.4.2.2.2.2.2.cmml">=</mo><msub id="S2.E1.m1.4.4.2.2.2.2.3" xref="S2.E1.m1.4.4.2.2.2.2.3.cmml"><mi id="S2.E1.m1.4.4.2.2.2.2.3.2" xref="S2.E1.m1.4.4.2.2.2.2.3.2.cmml">c</mi><mi id="S2.E1.m1.4.4.2.2.2.2.3.3" xref="S2.E1.m1.4.4.2.2.2.2.3.3.cmml">n</mi></msub></mrow><mo stretchy="false" id="S2.E1.m1.4.4.2.2.2.5" xref="S2.E1.m1.4.4.2.2.3.1.cmml">}</mo></mrow></mrow><mi id="S2.E1.m1.4.4.4" xref="S2.E1.m1.4.4.4.cmml">N</mi></mfrac></mrow><mo lspace="0em" id="S2.E1.m1.5.5.1.2" xref="S2.E1.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.5b"><apply id="S2.E1.m1.5.5.1.1.cmml" xref="S2.E1.m1.5.5.1"><csymbol cd="latexml" id="S2.E1.m1.5.5.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1">assign</csymbol><apply id="S2.E1.m1.5.5.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.2.1.cmml" xref="S2.E1.m1.5.5.1.1.2">subscript</csymbol><ci id="S2.E1.m1.5.5.1.1.2.2.cmml" xref="S2.E1.m1.5.5.1.1.2.2">ℒ</ci><list id="S2.E1.m1.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.4"><ci id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1">ℳ</ci><ci id="S2.E1.m1.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2">𝒬</ci></list></apply><apply id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4"><divide id="S2.E1.m1.4.4.3.cmml" xref="S2.E1.m1.4.4"></divide><apply id="S2.E1.m1.4.4.2.cmml" xref="S2.E1.m1.4.4.2"><times id="S2.E1.m1.4.4.2.3.cmml" xref="S2.E1.m1.4.4.2.3"></times><ci id="S2.E1.m1.4.4.2.4.cmml" xref="S2.E1.m1.4.4.2.4">#</ci><apply id="S2.E1.m1.4.4.2.2.3.cmml" xref="S2.E1.m1.4.4.2.2.2"><csymbol cd="latexml" id="S2.E1.m1.4.4.2.2.3.1.cmml" xref="S2.E1.m1.4.4.2.2.2.3">conditional-set</csymbol><apply id="S2.E1.m1.3.3.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2">𝑞</ci><ci id="S2.E1.m1.3.3.1.1.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.3">𝑛</ci></apply><apply id="S2.E1.m1.4.4.2.2.2.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2"><eq id="S2.E1.m1.4.4.2.2.2.2.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.2"></eq><apply id="S2.E1.m1.4.4.2.2.2.2.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1"><times id="S2.E1.m1.4.4.2.2.2.2.1.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.2"></times><ci id="S2.E1.m1.4.4.2.2.2.2.1.3.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.3">ℳ</ci><apply id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1">subscript</csymbol><ci id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.2">𝑞</ci><ci id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.3.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.3">𝑛</ci></apply></apply><apply id="S2.E1.m1.4.4.2.2.2.2.3.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.2.2.2.2.3.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3">subscript</csymbol><ci id="S2.E1.m1.4.4.2.2.2.2.3.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3.2">𝑐</ci><ci id="S2.E1.m1.4.4.2.2.2.2.3.3.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3.3">𝑛</ci></apply></apply></apply></apply><ci id="S2.E1.m1.4.4.4.cmml" xref="S2.E1.m1.4.4.4">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.5c">\mathcal{L}_{\mathcal{M},\mathcal{Q}}:=\frac{\#\{q_{n}|\;\mathcal{M}(q_{n})=c_{n}\}}{N}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.p6" class="ltx_para">
<p class="ltx_p" id="S2.p6.2">모델 <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S2.p6.1.m1.1"><semantics id="S2.p6.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p6.1.m1.1.1" xref="S2.p6.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S2.p6.1.m1.1b"><ci id="S2.p6.1.m1.1.1.cmml" xref="S2.p6.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.1.m1.1c">\mathcal{M}</annotation></semantics></math>가 <span class="ltx_text ltx_font_italic" id="S2.p6.2.1">any</span> knowledge regarding the set of questions <math alttext="\mathcal{Q}" class="ltx_Math" display="inline" id="S2.p6.2.m2.1"><semantics id="S2.p6.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p6.2.m2.1.1" xref="S2.p6.2.m2.1.1.cmml">𝒬</mi><annotation-xml encoding="MathML-Content" id="S2.p6.2.m2.1b"><ci id="S2.p6.2.m2.1.1.cmml" xref="S2.p6.2.m2.1.1">𝒬</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.2.m2.1c">\mathcal{Q}</annotation></semantics></math> if that holds:</p>
</div>
<div id="S2.p7" class="ltx_para">
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.3" class="ltx_Math" alttext="\mathcal{L}_{\mathcal{M},\mathcal{Q}}>\frac{1}{L}." display="block"><semantics id="S2.E2.m1.3a"><mrow id="S2.E2.m1.3.3.1" xref="S2.E2.m1.3.3.1.1.cmml"><mrow id="S2.E2.m1.3.3.1.1" xref="S2.E2.m1.3.3.1.1.cmml"><msub id="S2.E2.m1.3.3.1.1.2" xref="S2.E2.m1.3.3.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.3.3.1.1.2.2" xref="S2.E2.m1.3.3.1.1.2.2.cmml">ℒ</mi><mrow id="S2.E2.m1.2.2.2.4" xref="S2.E2.m1.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml">ℳ</mi><mo id="S2.E2.m1.2.2.2.4.1" xref="S2.E2.m1.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.2.2.2.2" xref="S2.E2.m1.2.2.2.2.cmml">𝒬</mi></mrow></msub><mo id="S2.E2.m1.3.3.1.1.1" xref="S2.E2.m1.3.3.1.1.1.cmml">&gt;</mo><mfrac id="S2.E2.m1.3.3.1.1.3" xref="S2.E2.m1.3.3.1.1.3.cmml"><mn id="S2.E2.m1.3.3.1.1.3.2" xref="S2.E2.m1.3.3.1.1.3.2.cmml">1</mn><mi id="S2.E2.m1.3.3.1.1.3.3" xref="S2.E2.m1.3.3.1.1.3.3.cmml">L</mi></mfrac></mrow><mo lspace="0em" id="S2.E2.m1.3.3.1.2" xref="S2.E2.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.3b"><apply id="S2.E2.m1.3.3.1.1.cmml" xref="S2.E2.m1.3.3.1"><gt id="S2.E2.m1.3.3.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1"></gt><apply id="S2.E2.m1.3.3.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.2.1.cmml" xref="S2.E2.m1.3.3.1.1.2">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.2.2.cmml" xref="S2.E2.m1.3.3.1.1.2.2">ℒ</ci><list id="S2.E2.m1.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.4"><ci id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1">ℳ</ci><ci id="S2.E2.m1.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2">𝒬</ci></list></apply><apply id="S2.E2.m1.3.3.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.3"><divide id="S2.E2.m1.3.3.1.1.3.1.cmml" xref="S2.E2.m1.3.3.1.1.3"></divide><cn type="integer" id="S2.E2.m1.3.3.1.1.3.2.cmml" xref="S2.E2.m1.3.3.1.1.3.2">1</cn><ci id="S2.E2.m1.3.3.1.1.3.3.cmml" xref="S2.E2.m1.3.3.1.1.3.3">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.3c">\mathcal{L}_{\mathcal{M},\mathcal{Q}}&gt;\frac{1}{L}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.p8" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.p8.2">더 간단한 용어로 모델은 일관된 정답을 제공하여 단순한 무작위 추측 기준선을 능가할 수 있다. 당연히, 지식 점수 <math alttext="\mathcal{L}_{\mathcal{M},\mathcal{Q}}" class="ltx_Math" display="inline" id="S2.p8.1.m1.2"><semantics id="S2.p8.1.m1.2a"><msub id="S2.p8.1.m1.2.3" xref="S2.p8.1.m1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p8.1.m1.2.3.2" xref="S2.p8.1.m1.2.3.2.cmml">ℒ</mi><mrow id="S2.p8.1.m1.2.2.2.4" xref="S2.p8.1.m1.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p8.1.m1.1.1.1.1" xref="S2.p8.1.m1.1.1.1.1.cmml">ℳ</mi><mo id="S2.p8.1.m1.2.2.2.4.1" xref="S2.p8.1.m1.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.p8.1.m1.2.2.2.2" xref="S2.p8.1.m1.2.2.2.2.cmml">𝒬</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.p8.1.m1.2b"><apply id="S2.p8.1.m1.2.3.cmml" xref="S2.p8.1.m1.2.3"><csymbol cd="ambiguous" id="S2.p8.1.m1.2.3.1.cmml" xref="S2.p8.1.m1.2.3">subscript</csymbol><ci id="S2.p8.1.m1.2.3.2.cmml" xref="S2.p8.1.m1.2.3.2">ℒ</ci><list id="S2.p8.1.m1.2.2.2.3.cmml" xref="S2.p8.1.m1.2.2.2.4"><ci id="S2.p8.1.m1.1.1.1.1.cmml" xref="S2.p8.1.m1.1.1.1.1">ℳ</ci><ci id="S2.p8.1.m1.2.2.2.2.cmml" xref="S2.p8.1.m1.2.2.2.2">𝒬</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.1.m1.2c">\mathcal{L}_{\mathcal{M},\mathcal{Q}}</annotation></semantics></math>가 다른 모델에 비해 한 모델에 대해 더 높은 경우, 우리는 전자가 후자에 비해 <math alttext="\mathcal{Q}" class="ltx_Math" display="inline" id="S2.p8.2.m2.1"><semantics id="S2.p8.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p8.2.m2.1.1" xref="S2.p8.2.m2.1.1.cmml">𝒬</mi><annotation-xml encoding="MathML-Content" id="S2.p8.2.m2.1b"><ci id="S2.p8.2.m2.1.1.cmml" xref="S2.p8.2.m2.1.1">𝒬</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.2.m2.1c">\mathcal{Q}</annotation></semantics></math>에 대해 더 많은 지식을 가진다고 주장한다.</p>
</div>
<div id="S2.p9" class="ltx_para">
<p class="ltx_p" id="S2.p9.1"><span class="ltx_text ltx_font_bold" id="S2.p9.1.1">Previously Seen Knowledge</span>  한 중요한 구분은 모델이 완전히 새로운 사실과 반대로 사전 훈련 동안 이전에 노출되었다는 지식 간의 구분입니다. 현대 LLM 트레이닝 세트의 크기를 고려할 때, 그들은 웹 소스 텍스트를 통해 이용 가능한 방대한 양의 정보를 다룬다. 결과적으로 틈새 영역에서도 지식 주입의 목표는 반드시 모델을 완전히 새로운 사실로 가르치는 것이 아니라 특정 영역에 대한 편향을 유도하여 기억을 "새로 고침"하는 것이다.</p>
</div>
<div id="S2.p10" class="ltx_para">
<p class="ltx_p" id="S2.p10.1"><span class="ltx_text ltx_font_bold" id="S2.p10.1.1">Knowledge and Reasoning</span>  LLMs에 대한 이러한 지식 평가 프레임워크는 불완전함을 강조한다. 중요한 것은 모델의 반응에 영향을 미치는 다른 품질 척도를 다루지 않는다는 것입니다. 일부 수준의 추론을 포함하지 않고 순수하게 지식 집약적인 데이터 세트를 만드는 것은 어렵다. 결과적으로, 강력한 추론 능력을 가진 모델은 객관식 시험에서 “교육된 추측”을 함으로써 익숙하지 않은 지식 집약적인 과제에 탁월할 수 있다. 따라서 LLM의 지식 평가는 추론 <cite class="ltx_cite ltx_citemacro_citep">(Sakaguchi et al., <a class="ltx_ref" href="#bib.bib35" title="">2021</a>)</cite>, 독해 <cite class="ltx_cite ltx_citemacro_citep">(Dua et al., <a class="ltx_ref" href="#bib.bib9" title="">2019</a>)</cite>, 일반 언어 능력 <cite class="ltx_cite ltx_citemacro_citep">(Srivastava et al., <a class="ltx_ref" href="#bib.bib41" title="">2022</a>)</cite>에 대한 광범위한 벤치마크의 일부로 간주되는 결과를 고려해야 한다. 그러나 이러한 평가 틀은 여전히 무엇보다 사실적 정보를 강하게 강조하고 있다.</p>
</div>
<div id="S2.p11" class="ltx_para">
<p class="ltx_p" id="S2.p11.1"><span class="ltx_text ltx_font_bold" id="S2.p11.1.1">Causes for Factual Errors</span>  모델이 Factual 질문에 정확하게 답하지 못하는 데에는 여러 가지 가능한 이유가 있다. <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib47" title="">2023</a>)</cite>에서 Wang <span class="ltx_text ltx_font_italic" id="S2.p11.1.2">et al.</span> introduce taxonomy of five main model-level causes:</p>
</div>
<div id="S2.p12" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Domain knowledge deficit</span>: 언어 모델은 노출되지 않은 특정 도메인에 포괄적인 전문 지식이 부족할 수 있습니다. 예를 들어, 윌리엄 셰익스피어가 쓴 텍스트로만 훈련된 모델은 마크 트웨인의 작품에 대해 질문을 받았을 때 제대로 작동하지 않을 것이다.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">Outdated Information</span>: LLMs는 항상 그들의 트레이닝 데이터세트에 의해 결정되는 컷오프 날짜를 갖는다. 결과적으로 마지막 훈련 업데이트 후에 발생하는 모든 이벤트, 발견 또는 변화는 외부 소스에 대한 액세스 없이 모델의 지식 내에 있지 않을 것이다.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">Immemorization</span>: 때때로, 모델은 그것의 트레이닝 프로세스 동안 지식에 노출되지만 그것을 유지하지 않는다. 이는 훈련 데이터 세트에서 드물게 나타나는 희귀 사실 <cite class="ltx_cite ltx_citemacro_citep">(Kandpal et al., <a class="ltx_ref" href="#bib.bib17" title="">2023</a>)</cite>에 특히 해당된다.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i4.p1.1.1">Forgetting</span>: 언어 모델들은 종종 사전-트레이닝 단계(fine-tuning) 후에 추가적인 트레이닝을 겪는다. 경우에 따라, 이는 <span class="ltx_text ltx_font_italic" id="S2.I1.i4.p1.1.2">catastrophic forgetting</span> <cite class="ltx_cite ltx_citemacro_citep">(Kirkpatrick et al., <a class="ltx_ref" href="#bib.bib18" title="">2017</a>; Goodfellow et al., <a class="ltx_ref" href="#bib.bib11" title="">2013</a>; Chen et al., <a class="ltx_ref" href="#bib.bib3" title="">2020</a>; Luo et al., <a class="ltx_ref" href="#bib.bib23" title="">2023</a>)</cite>라고 하는 현상으로 이어질 수 있으며, 여기서 모델은 미세 조정 프로세스 이전에 가지고 있던 지식의 일부를 잃는다.</p>
</div>
</li>
<li id="S2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i5.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i5.p1.1.1">Reasoning Failure</span>: 특정 인스턴스에서 언어 모델은 사실에 대한 관련 지식을 소유할 수 있지만 제대로 활용하지 못할 수 있습니다. 이것은 특히 복잡한 다단계 추론 작업 <cite class="ltx_cite ltx_citemacro_citep">(Tan et al., <a class="ltx_ref" href="#bib.bib42" title="">2023</a>)</cite>에서 명백하거나 동일한 사실에 대해 서로 다른 질문으로 제기될 때 서로 다른 결과 <cite class="ltx_cite ltx_citemacro_citep">(Berglund et al., <a class="ltx_ref" href="#bib.bib2" title="">2023</a>)</cite>를 초래한다.</p>
</div>
</li>
</ul>
</div>
<div id="S2.p13" class="ltx_para">
<p class="ltx_p" id="S2.p13.1">우리는 이러한 문제의 대부분이 사전 훈련 단계에서 발생하며 치명적인 망각이 주목할 만한 예외임을 관찰한다. 따라서 많은 LLM은 훈련 후 프로세스에 관계없이 이러한 종류의 사실적 오류로 고통받을 것이다.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Injecting Knowledge to Language Models</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p" id="S3.p1.1"><a class="ltx_ref" href="#S2" title="2 Background ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">2</span></a>에서 주어진 배경에 따라 일반적인 사전 훈련은 많은 지식 집약적인 작업에 충분하지 않다는 것이 분명하다. 이를 해결하기 위해서는 사전 학습된 모델의 지식을 증강하기 위한 추가적인 후처리 단계가 필수적이다. 이 단계는 종종 <span class="ltx_text ltx_font_italic" id="S3.p1.1.1">knowledge injection</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib48" title="">2020</a>; Chen et al., <a class="ltx_ref" href="#bib.bib4" title="">2022</a>; Liu et al., <a class="ltx_ref" href="#bib.bib22" title="">2020</a>; Lauscher et al., <a class="ltx_ref" href="#bib.bib20" title="">2020</a>)</cite>로 변경됩니다.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p class="ltx_p" id="S3.p2.1">본 절에서는 지식 주입을 위해 널리 사용되는 두 가지 프레임워크인 미세 조정(FT)과 검색 증강 생성(RAG)을 살펴본다. 우리는 일관된 용어를 사용하여 두 방법을 설명하는 것을 목표로 지식 주입 문제를 공식화하는 것으로 시작한다.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Problem formulation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.p1.1"><a class="ltx_ref" href="#S2.E1" title="In 2 Background ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Equations</span> <span class="ltx_text ltx_ref_tag">1</span></a>와 <a class="ltx_ref" href="#S2.E2" title="Equation 2 ‣ 2 Background ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">2</span></a>에서는 질의응답(Q&A)의 렌즈를 통해 언어 모델의 지식을 위한 공식을 제시하였다. 우리는 이제 이 공식을 동일한 용어를 사용하는 지식 주입 문제로 확장한다.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS1.p2.1">일련의 사실적 질문이 주어지면, 이러한 질문과 관련된 정보를 포함하는 일부 텍스트 코퍼스가 존재한다. 지식 주입의 중심 가정은 이 말뭉치에 대한 완전한 접근이 주어지면 보조 지식 베이스 역할을 하고 이 질문 세트에 대한 모델의 성능을 향상시킬 수 있다는 것이다.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS1.p3.5">수학적으로, <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\mathcal{M}</annotation></semantics></math>는 사전 훈련된 모델이고, <math alttext="\mathcal{Q}" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.1"><semantics id="S3.SS1.p3.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">𝒬</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">𝒬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">\mathcal{Q}</annotation></semantics></math>는 이전과 같이 사실적 질문의 집합이라고 하자. 이제, 관련 보조 지식 베이스 <math alttext="\mathcal{B}_{\mathcal{Q}}" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.1"><semantics id="S3.SS1.p3.3.m3.1a"><msub id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml">𝒬</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2">ℬ</ci><ci id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3">𝒬</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">\mathcal{B}_{\mathcal{Q}}</annotation></semantics></math>가 있다고 가정하자. 우리의 목표는 <math alttext="\mathcal{F}" class="ltx_Math" display="inline" id="S3.SS1.p3.4.m4.1"><semantics id="S3.SS1.p3.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml">ℱ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><ci id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">ℱ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">\mathcal{F}</annotation></semantics></math>로 표기된 변환을 발견하는 것이며, 이는 적용되면 <math alttext="\mathcal{Q}" class="ltx_Math" display="inline" id="S3.SS1.p3.5.m5.1"><semantics id="S3.SS1.p3.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml">𝒬</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><ci id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">𝒬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">\mathcal{Q}</annotation></semantics></math>에 대한 지식을 향상시킬 것이다:</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.7" class="ltx_math_unparsed" alttext="\mathcal{M^{\prime}}:=\mathcal{F}(\mathcal{M},\mathcal{B}_{\mathcal{Q}})\quad s.t.\quad\mathcal{L}_{\mathcal{M^{\prime}},\mathcal{Q}}>\mathcal{L}_{\mathcal{M},\mathcal{Q}}." display="block"><semantics id="S3.E3.m1.7a"><mrow id="S3.E3.m1.7b"><msup id="S3.E3.m1.7.8"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.8.2">ℳ</mi><mo id="S3.E3.m1.7.8.3">′</mo></msup><mo lspace="0.278em" rspace="0.278em" id="S3.E3.m1.7.9">:=</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.10">ℱ</mi><mrow id="S3.E3.m1.7.11"><mo stretchy="false" id="S3.E3.m1.7.11.1">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.5.5">ℳ</mi><mo id="S3.E3.m1.7.11.2">,</mo><msub id="S3.E3.m1.7.11.3"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.11.3.2">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.11.3.3">𝒬</mi></msub><mo stretchy="false" id="S3.E3.m1.7.11.4">)</mo></mrow><mspace width="1em" id="S3.E3.m1.7.12"></mspace><mi id="S3.E3.m1.6.6">s</mi><mo lspace="0em" rspace="0.167em" id="S3.E3.m1.7.13">.</mo><mi id="S3.E3.m1.7.7">t</mi><mo lspace="0em" id="S3.E3.m1.7.14">.</mo><mspace width="1.167em" id="S3.E3.m1.7.15"></mspace><msub id="S3.E3.m1.7.16"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.16.2">ℒ</mi><mrow id="S3.E3.m1.2.2.2.2"><msup id="S3.E3.m1.2.2.2.2.1"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.2.2.1.2">ℳ</mi><mo id="S3.E3.m1.2.2.2.2.1.3">′</mo></msup><mo id="S3.E3.m1.2.2.2.2.2">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1">𝒬</mi></mrow></msub><mo id="S3.E3.m1.7.17">&gt;</mo><msub id="S3.E3.m1.7.18"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.18.2">ℒ</mi><mrow id="S3.E3.m1.4.4.2.4"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.1.1">ℳ</mi><mo id="S3.E3.m1.4.4.2.4.1">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.4.4.2.2">𝒬</mi></mrow></msub><mo lspace="0em" id="S3.E3.m1.7.19">.</mo></mrow><annotation encoding="application/x-tex" id="S3.E3.m1.7c">\mathcal{M^{\prime}}:=\mathcal{F}(\mathcal{M},\mathcal{B}_{\mathcal{Q}})\quad s.t.\quad\mathcal{L}_{\mathcal{M^{\prime}},\mathcal{Q}}&gt;\mathcal{L}_{\mathcal{M},\mathcal{Q}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS1.p5.1">이 연구에서는 <math alttext="\mathcal{F}" class="ltx_Math" display="inline" id="S3.SS1.p5.1.m1.1"><semantics id="S3.SS1.p5.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml">ℱ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><ci id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1">ℱ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">\mathcal{F}</annotation></semantics></math>에 대한 두 가지 선택지를 비교하여 어떤 옵션이 이 문제에서 더 나은 성능을 보이는지 알아보는 것을 목표로 한다.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Fine-Tuning</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p1.1">미세 조정은 특정 도메인에서 성능을 향상시키기 위해 특정, 종종 더 좁은 데이터 세트 또는 태스크에서 사전 훈련된 모델을 조정하는 프로세스이다. 여기서, 서로 다른 유형의 미세 조정을 구별하는 것이 필수적이다. FT 기술은 일반적으로 지도 학습, 비지도 학습 및 강화 학습(RL) 기반 방법으로 분류된다. 우리는 이러한 방법들과 지식 주입의 문제와의 관련성에 대해 간략히 검토하는 것으로 진행한다.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Supervised Fine-Tuning</span>  Supervised fine-tuning (SFT)는 라벨링된 입력-출력 쌍들의 세트들을 필요로 한다. 가장 일반적인 SFT 방법 중 하나는 모델 성능을 향상시키는 가장 강력한 방법 중 하나로 등장한 명령어 튜닝 <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="#bib.bib49" title="">2022</a>; Mishra et al., <a class="ltx_ref" href="#bib.bib25" title="">2021</a>; Ouyang et al., <a class="ltx_ref" href="#bib.bib31" title="">2022</a>; Taori et al., <a class="ltx_ref" href="#bib.bib43" title="">2023</a>)</cite>이다. 명령어 튜닝을 통해, 입력은 자연어 태스크 설명이고, 출력은 원하는 행동의 예시이다. 현재 많은 최첨단 LLM은 사전 훈련 단계 후에 지시 튜닝을 거쳤다.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p3.1">수업 튜닝은 제로 샷 및 추론 능력에 특히 중점을 두고 모델의 전반적인 품질을 개선하는 데 매우 효과적인 것으로 나타났다. 그러나, 이러한 장점에도 불구하고, 명령어 튜닝이 반드시 모델 새로운 지식 <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="#bib.bib31" title="">2022</a>; Chung et al., <a class="ltx_ref" href="#bib.bib7" title="">2022</a>; Mitra et al., <a class="ltx_ref" href="#bib.bib26" title="">2023</a>; Chia et al., <a class="ltx_ref" href="#bib.bib6" title="">2023</a>; Zhou et al., <a class="ltx_ref" href="#bib.bib55" title="">2023</a>)</cite>를 가르치는 것은 아니다. 이와 같이, 명령어 튜닝만으로는 지식 주입 문제에 대한 실행 가능한 해결책이 되지 못한다.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Reinforcemnt Learning</span>  또 다른 형태의 FT는 RL 또는 RL-inspired 최적화 전략에 의존하여 사전 훈련 단계 후에 모델을 더 잘 정렬합니다. 몇 가지 두드러진 예는 인간 피드백(RLHF) <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="#bib.bib30" title="">2023</a>; Touvron et al., <a class="ltx_ref" href="#bib.bib45" title="">2023</a>)</cite>, 직접 선호 최적화(DPO) <cite class="ltx_cite ltx_citemacro_citep">(Rafailov et al., <a class="ltx_ref" href="#bib.bib34" title="">2023</a>)</cite>, 근접 정책 최적화(PPO) <cite class="ltx_cite ltx_citemacro_citep">(Schulman et al., <a class="ltx_ref" href="#bib.bib36" title="">2017</a>; Tunstall et al., <a class="ltx_ref" href="#bib.bib46" title="">2023</a>)</cite>로부터 강화 학습이다.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p5.1">이러한 기술들은 특히 명령어 튜닝과 함께 사용될 때 매우 유용한 것으로 나타났다. 그러나 명령 조정과 유사하게 이러한 방법은 응답의 전반적인 품질과 예상되는 행동에 초점을 맞추고 반드시 지식의 폭에 초점을 맞추지는 않는다.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p6.1.1">Unsupervised Fine-Tuning</span>  The final FT strategy we discuss is unsupervised, meaning there are no available labels for the model to learn from. 하나의 일반적인 비지도 FT 기술은 종종 <span class="ltx_text ltx_font_italic" id="S3.SS2.p6.1.2">continual pre-training</span> 또는 <span class="ltx_text ltx_font_italic" id="S3.SS2.p6.1.3">unstructured</span> FT로 지칭된다.</p>
</div>
<div id="S3.SS2.p7" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p7.1">이 방법에서 FT 과정은 사전 훈련 단계의 직접적인 연속으로 본다. 우리는 원래 LLM의 저장된 체크포인트로 시작하여 인과적 자동 회귀 방식, 즉 다음 토큰을 예측하는 방식으로 훈련한다. 실제 사전 훈련과 비교했을 때 큰 차이점 중 하나는 학습률이다. 일반적으로 치명적인 망각 <cite class="ltx_cite ltx_citemacro_citep">(Kirkpatrick et al., <a class="ltx_ref" href="#bib.bib18" title="">2017</a>)</cite>를 피하기 위해 모델의 사전 훈련을 계속할 때 훨씬 낮은 학습률이 필요하다.</p>
</div>
<div id="S3.SS2.p8" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p8.1">LLM은 사전 훈련 단계 <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="#bib.bib55" title="">2023</a>)</cite> 동안 방대한 양의 지식을 저장하는 것으로 잘 알려져 있다. 따라서 모델에 지식을 주입하기 위해 이 과정을 계속하는 것이 타당합니다. 따라서 우리는 이 작업 전반에 걸쳐 감독되지 않은 FT 접근법을 사용하고 모델의 새로운 정보 학습 능력을 향상시키는 데 그 효능을 평가한다.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Retrieval Augmented Generation</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.p1.1">검색 증강 생성(RAG) <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="#bib.bib21" title="">2020</a>)</cite>는 외부 지식 소스를 사용하여 특히 지식 집약적인 작업에서 LLM의 기능을 확장하는 기술입니다. 원래 제형이 작업당 추가 훈련을 포함했지만, 이후 사전 훈련된 <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.1">embedding</span> 모델은 추가 훈련 없이 향상된 성능을 달성할 수 있음이 입증되었다.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS3.p2.1">이 아이디어는 보조 지식베이스와 입력 질의가 주어졌을 때, RAG 아키텍처를 사용하여 입력 질의와 유사한 지식베이스 내의 문서를 찾는 것이다. 그런 다음 이 문서들은 입력 쿼리에 추가되며, 따라서 모델에 쿼리의 주제에 대한 추가 컨텍스트를 제공한다.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.12" class="ltx_p">In practice, implementing the suggested architecture is quite straightforward: Given an auxiliary knowledge base <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{B}_{\mathcal{Q}}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><msub id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">𝒬</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">ℬ</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">𝒬</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">\mathcal{B}_{\mathcal{Q}}</annotation></semantics></math> and a pre-trained embedding model <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="\mathcal{M}_{e}" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><msub id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">ℳ</mi><mi id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2">ℳ</ci><ci id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">\mathcal{M}_{e}</annotation></semantics></math>, we create a dense vector representation (embedding) per document <math id="S3.SS3.p3.3.m3.1" class="ltx_Math" alttext="b\in\mathcal{B}_{\mathcal{Q}}" display="inline"><semantics id="S3.SS3.p3.3.m3.1a"><mrow id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">b</mi><mo id="S3.SS3.p3.3.m3.1.1.1" xref="S3.SS3.p3.3.m3.1.1.1.cmml">∈</mo><msub id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.3.m3.1.1.3.2" xref="S3.SS3.p3.3.m3.1.1.3.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.3.m3.1.1.3.3" xref="S3.SS3.p3.3.m3.1.1.3.3.cmml">𝒬</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><in id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1.1"></in><ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">𝑏</ci><apply id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.3.1.cmml" xref="S3.SS3.p3.3.m3.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.3.2.cmml" xref="S3.SS3.p3.3.m3.1.1.3.2">ℬ</ci><ci id="S3.SS3.p3.3.m3.1.1.3.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3.3">𝒬</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">b\in\mathcal{B}_{\mathcal{Q}}</annotation></semantics></math> and store these in a vector store. Upon receiving a new query <math id="S3.SS3.p3.4.m4.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS3.p3.4.m4.1a"><mi id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><ci id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">q</annotation></semantics></math>, we use its embedding, <math id="S3.SS3.p3.5.m5.1" class="ltx_Math" alttext="\mathcal{M}_{e}(q)" display="inline"><semantics id="S3.SS3.p3.5.m5.1a"><mrow id="S3.SS3.p3.5.m5.1.2" xref="S3.SS3.p3.5.m5.1.2.cmml"><msub id="S3.SS3.p3.5.m5.1.2.2" xref="S3.SS3.p3.5.m5.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.5.m5.1.2.2.2" xref="S3.SS3.p3.5.m5.1.2.2.2.cmml">ℳ</mi><mi id="S3.SS3.p3.5.m5.1.2.2.3" xref="S3.SS3.p3.5.m5.1.2.2.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.1.2.1" xref="S3.SS3.p3.5.m5.1.2.1.cmml">​</mo><mrow id="S3.SS3.p3.5.m5.1.2.3.2" xref="S3.SS3.p3.5.m5.1.2.cmml"><mo stretchy="false" id="S3.SS3.p3.5.m5.1.2.3.2.1" xref="S3.SS3.p3.5.m5.1.2.cmml">(</mo><mi id="S3.SS3.p3.5.m5.1.1" xref="S3.SS3.p3.5.m5.1.1.cmml">q</mi><mo stretchy="false" id="S3.SS3.p3.5.m5.1.2.3.2.2" xref="S3.SS3.p3.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.1b"><apply id="S3.SS3.p3.5.m5.1.2.cmml" xref="S3.SS3.p3.5.m5.1.2"><times id="S3.SS3.p3.5.m5.1.2.1.cmml" xref="S3.SS3.p3.5.m5.1.2.1"></times><apply id="S3.SS3.p3.5.m5.1.2.2.cmml" xref="S3.SS3.p3.5.m5.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p3.5.m5.1.2.2.1.cmml" xref="S3.SS3.p3.5.m5.1.2.2">subscript</csymbol><ci id="S3.SS3.p3.5.m5.1.2.2.2.cmml" xref="S3.SS3.p3.5.m5.1.2.2.2">ℳ</ci><ci id="S3.SS3.p3.5.m5.1.2.2.3.cmml" xref="S3.SS3.p3.5.m5.1.2.2.3">𝑒</ci></apply><ci id="S3.SS3.p3.5.m5.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.1c">\mathcal{M}_{e}(q)</annotation></semantics></math>, to retrieve <math id="S3.SS3.p3.6.m6.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS3.p3.6.m6.1a"><mi id="S3.SS3.p3.6.m6.1.1" xref="S3.SS3.p3.6.m6.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.6.m6.1b"><ci id="S3.SS3.p3.6.m6.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.6.m6.1c">q</annotation></semantics></math>’s top-<math id="S3.SS3.p3.7.m7.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS3.p3.7.m7.1a"><mi id="S3.SS3.p3.7.m7.1.1" xref="S3.SS3.p3.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.7.m7.1b"><ci id="S3.SS3.p3.7.m7.1.1.cmml" xref="S3.SS3.p3.7.m7.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.7.m7.1c">K</annotation></semantics></math> closest neighbors, <math id="S3.SS3.p3.8.m8.1" class="ltx_Math" alttext="\mathbf{b}_{q}=\{b_{k}\}_{1}^{K}" display="inline"><semantics id="S3.SS3.p3.8.m8.1a"><mrow id="S3.SS3.p3.8.m8.1.1" xref="S3.SS3.p3.8.m8.1.1.cmml"><msub id="S3.SS3.p3.8.m8.1.1.3" xref="S3.SS3.p3.8.m8.1.1.3.cmml"><mi id="S3.SS3.p3.8.m8.1.1.3.2" xref="S3.SS3.p3.8.m8.1.1.3.2.cmml">𝐛</mi><mi id="S3.SS3.p3.8.m8.1.1.3.3" xref="S3.SS3.p3.8.m8.1.1.3.3.cmml">q</mi></msub><mo id="S3.SS3.p3.8.m8.1.1.2" xref="S3.SS3.p3.8.m8.1.1.2.cmml">=</mo><msubsup id="S3.SS3.p3.8.m8.1.1.1" xref="S3.SS3.p3.8.m8.1.1.1.cmml"><mrow id="S3.SS3.p3.8.m8.1.1.1.1.1.1" xref="S3.SS3.p3.8.m8.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS3.p3.8.m8.1.1.1.1.1.1.2" xref="S3.SS3.p3.8.m8.1.1.1.1.1.2.cmml">{</mo><msub id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.2" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.2.cmml">b</mi><mi id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.3" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.3.cmml">k</mi></msub><mo stretchy="false" id="S3.SS3.p3.8.m8.1.1.1.1.1.1.3" xref="S3.SS3.p3.8.m8.1.1.1.1.1.2.cmml">}</mo></mrow><mn id="S3.SS3.p3.8.m8.1.1.1.1.3" xref="S3.SS3.p3.8.m8.1.1.1.1.3.cmml">1</mn><mi id="S3.SS3.p3.8.m8.1.1.1.3" xref="S3.SS3.p3.8.m8.1.1.1.3.cmml">K</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.8.m8.1b"><apply id="S3.SS3.p3.8.m8.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1"><eq id="S3.SS3.p3.8.m8.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.2"></eq><apply id="S3.SS3.p3.8.m8.1.1.3.cmml" xref="S3.SS3.p3.8.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.3.1.cmml" xref="S3.SS3.p3.8.m8.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.8.m8.1.1.3.2.cmml" xref="S3.SS3.p3.8.m8.1.1.3.2">𝐛</ci><ci id="S3.SS3.p3.8.m8.1.1.3.3.cmml" xref="S3.SS3.p3.8.m8.1.1.3.3">𝑞</ci></apply><apply id="S3.SS3.p3.8.m8.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.1">superscript</csymbol><apply id="S3.SS3.p3.8.m8.1.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.1">subscript</csymbol><set id="S3.SS3.p3.8.m8.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1"><apply id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.2">𝑏</ci><ci id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.3">𝑘</ci></apply></set><cn type="integer" id="S3.SS3.p3.8.m8.1.1.1.1.3.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.3">1</cn></apply><ci id="S3.SS3.p3.8.m8.1.1.1.3.cmml" xref="S3.SS3.p3.8.m8.1.1.1.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.8.m8.1c">\mathbf{b}_{q}=\{b_{k}\}_{1}^{K}</annotation></semantics></math>, according to dot-product ranking. We then update <math id="S3.SS3.p3.9.m9.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS3.p3.9.m9.1a"><mi id="S3.SS3.p3.9.m9.1.1" xref="S3.SS3.p3.9.m9.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.9.m9.1b"><ci id="S3.SS3.p3.9.m9.1.1.cmml" xref="S3.SS3.p3.9.m9.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.9.m9.1c">q</annotation></semantics></math> to be <math id="S3.SS3.p3.10.m10.1" class="ltx_Math" alttext="\tilde{q}=\mathbf{b}_{q}\|q" display="inline"><semantics id="S3.SS3.p3.10.m10.1a"><mrow id="S3.SS3.p3.10.m10.1.1" xref="S3.SS3.p3.10.m10.1.1.cmml"><mover accent="true" id="S3.SS3.p3.10.m10.1.1.2" xref="S3.SS3.p3.10.m10.1.1.2.cmml"><mi id="S3.SS3.p3.10.m10.1.1.2.2" xref="S3.SS3.p3.10.m10.1.1.2.2.cmml">q</mi><mo id="S3.SS3.p3.10.m10.1.1.2.1" xref="S3.SS3.p3.10.m10.1.1.2.1.cmml">~</mo></mover><mo id="S3.SS3.p3.10.m10.1.1.1" xref="S3.SS3.p3.10.m10.1.1.1.cmml">=</mo><mrow id="S3.SS3.p3.10.m10.1.1.3" xref="S3.SS3.p3.10.m10.1.1.3.cmml"><msub id="S3.SS3.p3.10.m10.1.1.3.2" xref="S3.SS3.p3.10.m10.1.1.3.2.cmml"><mi id="S3.SS3.p3.10.m10.1.1.3.2.2" xref="S3.SS3.p3.10.m10.1.1.3.2.2.cmml">𝐛</mi><mi id="S3.SS3.p3.10.m10.1.1.3.2.3" xref="S3.SS3.p3.10.m10.1.1.3.2.3.cmml">q</mi></msub><mo id="S3.SS3.p3.10.m10.1.1.3.1" xref="S3.SS3.p3.10.m10.1.1.3.1.cmml">∥</mo><mi id="S3.SS3.p3.10.m10.1.1.3.3" xref="S3.SS3.p3.10.m10.1.1.3.3.cmml">q</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.10.m10.1b"><apply id="S3.SS3.p3.10.m10.1.1.cmml" xref="S3.SS3.p3.10.m10.1.1"><eq id="S3.SS3.p3.10.m10.1.1.1.cmml" xref="S3.SS3.p3.10.m10.1.1.1"></eq><apply id="S3.SS3.p3.10.m10.1.1.2.cmml" xref="S3.SS3.p3.10.m10.1.1.2"><ci id="S3.SS3.p3.10.m10.1.1.2.1.cmml" xref="S3.SS3.p3.10.m10.1.1.2.1">~</ci><ci id="S3.SS3.p3.10.m10.1.1.2.2.cmml" xref="S3.SS3.p3.10.m10.1.1.2.2">𝑞</ci></apply><apply id="S3.SS3.p3.10.m10.1.1.3.cmml" xref="S3.SS3.p3.10.m10.1.1.3"><csymbol cd="latexml" id="S3.SS3.p3.10.m10.1.1.3.1.cmml" xref="S3.SS3.p3.10.m10.1.1.3.1">conditional</csymbol><apply id="S3.SS3.p3.10.m10.1.1.3.2.cmml" xref="S3.SS3.p3.10.m10.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS3.p3.10.m10.1.1.3.2.1.cmml" xref="S3.SS3.p3.10.m10.1.1.3.2">subscript</csymbol><ci id="S3.SS3.p3.10.m10.1.1.3.2.2.cmml" xref="S3.SS3.p3.10.m10.1.1.3.2.2">𝐛</ci><ci id="S3.SS3.p3.10.m10.1.1.3.2.3.cmml" xref="S3.SS3.p3.10.m10.1.1.3.2.3">𝑞</ci></apply><ci id="S3.SS3.p3.10.m10.1.1.3.3.cmml" xref="S3.SS3.p3.10.m10.1.1.3.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.10.m10.1c">\tilde{q}=\mathbf{b}_{q}\|q</annotation></semantics></math>, where <math id="S3.SS3.p3.11.m11.1" class="ltx_Math" alttext="\|" display="inline"><semantics id="S3.SS3.p3.11.m11.1a"><mo id="S3.SS3.p3.11.m11.1.1" xref="S3.SS3.p3.11.m11.1.1.cmml">∥</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.11.m11.1b"><ci id="S3.SS3.p3.11.m11.1.1.cmml" xref="S3.SS3.p3.11.m11.1.1">∥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.11.m11.1c">\|</annotation></semantics></math> denotes string concatenation. Finally, we return <math id="S3.SS3.p3.12.m12.1" class="ltx_Math" alttext="\mathcal{M}(\tilde{q})" display="inline"><semantics id="S3.SS3.p3.12.m12.1a"><mrow id="S3.SS3.p3.12.m12.1.2" xref="S3.SS3.p3.12.m12.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.12.m12.1.2.2" xref="S3.SS3.p3.12.m12.1.2.2.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.12.m12.1.2.1" xref="S3.SS3.p3.12.m12.1.2.1.cmml">​</mo><mrow id="S3.SS3.p3.12.m12.1.2.3.2" xref="S3.SS3.p3.12.m12.1.1.cmml"><mo stretchy="false" id="S3.SS3.p3.12.m12.1.2.3.2.1" xref="S3.SS3.p3.12.m12.1.1.cmml">(</mo><mover accent="true" id="S3.SS3.p3.12.m12.1.1" xref="S3.SS3.p3.12.m12.1.1.cmml"><mi id="S3.SS3.p3.12.m12.1.1.2" xref="S3.SS3.p3.12.m12.1.1.2.cmml">q</mi><mo id="S3.SS3.p3.12.m12.1.1.1" xref="S3.SS3.p3.12.m12.1.1.1.cmml">~</mo></mover><mo stretchy="false" id="S3.SS3.p3.12.m12.1.2.3.2.2" xref="S3.SS3.p3.12.m12.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.12.m12.1b"><apply id="S3.SS3.p3.12.m12.1.2.cmml" xref="S3.SS3.p3.12.m12.1.2"><times id="S3.SS3.p3.12.m12.1.2.1.cmml" xref="S3.SS3.p3.12.m12.1.2.1"></times><ci id="S3.SS3.p3.12.m12.1.2.2.cmml" xref="S3.SS3.p3.12.m12.1.2.2">ℳ</ci><apply id="S3.SS3.p3.12.m12.1.1.cmml" xref="S3.SS3.p3.12.m12.1.2.3.2"><ci id="S3.SS3.p3.12.m12.1.1.1.cmml" xref="S3.SS3.p3.12.m12.1.1.1">~</ci><ci id="S3.SS3.p3.12.m12.1.1.2.cmml" xref="S3.SS3.p3.12.m12.1.1.2">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.12.m12.1c">\mathcal{M}(\tilde{q})</annotation></semantics></math> as the model’s output.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Knowledge Base Creation</h2>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.2.1.1" style="font-size:90%;">Table 1</span>:</span><span class="ltx_text" id="S4.T1.3.2" style="font-size:90%;">Results for the MMLU datasets described in <a class="ltx_ref" href="#S4.SS1" title="4.1 Task Selection and Rationale ‣ 4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.1</span></a> in terms of log-likelihood accuracy (<a class="ltx_ref" href="#S5.E4" title="In 5 Experiments and Results ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Equation</span> <span class="ltx_text ltx_ref_tag">4</span></a>). </span></figcaption>
<br class="ltx_break">
<table id="S4.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.4.1.1" class="ltx_tr">
<th id="S4.T1.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S4.T1.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Task</span></th>
<th id="S4.T1.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S4.T1.4.1.1.2.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S4.T1.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.4.1.1.3.1" class="ltx_text" style="font-size:90%;">Base model</span></th>
<th id="S4.T1.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.4.1.1.4.1" class="ltx_text" style="font-size:90%;">Base model + RAG</span></th>
<th id="S4.T1.4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.4.1.1.5.1" class="ltx_text" style="font-size:90%;">Fine-tuned</span></th>
<th id="S4.T1.4.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.4.1.1.6.1" class="ltx_text" style="font-size:90%;">Fine-tuned + RAG</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.4.2.1" class="ltx_tr">
<th id="S4.T1.4.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S4.T1.4.2.1.1.1" class="ltx_text" style="font-size:90%;">Anatomy (0-shot)</span></th>
<th id="S4.T1.4.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T1.4.2.1.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.2.1.3.1" class="ltx_text" style="font-size:90%;">0.556</span></td>
<td id="S4.T1.4.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.2.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.681</span></td>
<td id="S4.T1.4.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.2.1.5.1" class="ltx_text" style="font-size:90%;">0.570</span></td>
<td id="S4.T1.4.2.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.2.1.6.1" class="ltx_text" style="font-size:90%;">0.659</span></td>
</tr>
<tr id="S4.T1.4.3.2" class="ltx_tr">
<th id="S4.T1.4.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.3.2.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.3.2.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.3.2.2.1" class="ltx_text" style="font-size:90%;">0.393</span></td>
<td id="S4.T1.4.3.2.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.3.2.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.489</span></td>
<td id="S4.T1.4.3.2.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.3.2.4.1" class="ltx_text" style="font-size:90%;">0.430</span></td>
<td id="S4.T1.4.3.2.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.3.2.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.489</span></td>
</tr>
<tr id="S4.T1.4.4.3" class="ltx_tr">
<th id="S4.T1.4.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.4.3.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.4.3.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.3.2.1" class="ltx_text" style="font-size:90%;">0.607</span></td>
<td id="S4.T1.4.4.3.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.3.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.637</span></td>
<td id="S4.T1.4.4.3.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.3.4.1" class="ltx_text" style="font-size:90%;">0.600</span></td>
<td id="S4.T1.4.4.3.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.3.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.637</span></td>
</tr>
<tr id="S4.T1.4.5.4" class="ltx_tr">
<th id="S4.T1.4.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="S4.T1.4.5.4.1.1" class="ltx_text" style="font-size:90%;">Anatomy (5-shot)</span></th>
<th id="S4.T1.4.5.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.5.4.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.5.4.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.5.4.3.1" class="ltx_text" style="font-size:90%;">0.600</span></td>
<td id="S4.T1.4.5.4.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.5.4.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.681</span></td>
<td id="S4.T1.4.5.4.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.5.4.5.1" class="ltx_text" style="font-size:90%;">0.622</span></td>
<td id="S4.T1.4.5.4.6" class="ltx_td ltx_align_center"><span id="S4.T1.4.5.4.6.1" class="ltx_text" style="font-size:90%;">0.674</span></td>
</tr>
<tr id="S4.T1.4.6.5" class="ltx_tr">
<th id="S4.T1.4.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.6.5.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.6.5.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.6.5.2.1" class="ltx_text" style="font-size:90%;">0.467</span></td>
<td id="S4.T1.4.6.5.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.6.5.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.563</span></td>
<td id="S4.T1.4.6.5.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.6.5.4.1" class="ltx_text" style="font-size:90%;">0.496</span></td>
<td id="S4.T1.4.6.5.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.6.5.5.1" class="ltx_text" style="font-size:90%;">0.548</span></td>
</tr>
<tr id="S4.T1.4.7.6" class="ltx_tr">
<th id="S4.T1.4.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.7.6.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.7.6.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.7.6.2.1" class="ltx_text" style="font-size:90%;">0.570</span></td>
<td id="S4.T1.4.7.6.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.7.6.3.1" class="ltx_text" style="font-size:90%;">0.659</span></td>
<td id="S4.T1.4.7.6.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.7.6.4.1" class="ltx_text" style="font-size:90%;">0.593</span></td>
<td id="S4.T1.4.7.6.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.7.6.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.674</span></td>
</tr>
<tr id="S4.T1.4.8.7" class="ltx_tr">
<th id="S4.T1.4.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S4.T1.4.8.7.1.1" class="ltx_text" style="font-size:90%;">Astronomy (0-shot)</span></th>
<th id="S4.T1.4.8.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T1.4.8.7.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.8.7.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.8.7.3.1" class="ltx_text" style="font-size:90%;">0.625</span></td>
<td id="S4.T1.4.8.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.8.7.4.1" class="ltx_text" style="font-size:90%;">0.678</span></td>
<td id="S4.T1.4.8.7.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.8.7.5.1" class="ltx_text" style="font-size:90%;">0.651</span></td>
<td id="S4.T1.4.8.7.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.8.7.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.697</span></td>
</tr>
<tr id="S4.T1.4.9.8" class="ltx_tr">
<th id="S4.T1.4.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.9.8.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.9.8.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.9.8.2.1" class="ltx_text" style="font-size:90%;">0.401</span></td>
<td id="S4.T1.4.9.8.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.9.8.3.1" class="ltx_text" style="font-size:90%;">0.467</span></td>
<td id="S4.T1.4.9.8.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.9.8.4.1" class="ltx_text" style="font-size:90%;">0.487</span></td>
<td id="S4.T1.4.9.8.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.9.8.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.520</span></td>
</tr>
<tr id="S4.T1.4.10.9" class="ltx_tr">
<th id="S4.T1.4.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.10.9.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.10.9.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.10.9.2.1" class="ltx_text" style="font-size:90%;">0.645</span></td>
<td id="S4.T1.4.10.9.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.10.9.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.750</span></td>
<td id="S4.T1.4.10.9.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.10.9.4.1" class="ltx_text" style="font-size:90%;">0.651</span></td>
<td id="S4.T1.4.10.9.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.10.9.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.750</span></td>
</tr>
<tr id="S4.T1.4.11.10" class="ltx_tr">
<th id="S4.T1.4.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="S4.T1.4.11.10.1.1" class="ltx_text" style="font-size:90%;">Astronomy (5-shot)</span></th>
<th id="S4.T1.4.11.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.11.10.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.11.10.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.11.10.3.1" class="ltx_text" style="font-size:90%;">0.658</span></td>
<td id="S4.T1.4.11.10.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.11.10.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.724</span></td>
<td id="S4.T1.4.11.10.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.11.10.5.1" class="ltx_text" style="font-size:90%;">0.651</span></td>
<td id="S4.T1.4.11.10.6" class="ltx_td ltx_align_center"><span id="S4.T1.4.11.10.6.1" class="ltx_text" style="font-size:90%;">0.697</span></td>
</tr>
<tr id="S4.T1.4.12.11" class="ltx_tr">
<th id="S4.T1.4.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.12.11.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.12.11.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.12.11.2.1" class="ltx_text" style="font-size:90%;">0.401</span></td>
<td id="S4.T1.4.12.11.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.12.11.3.1" class="ltx_text" style="font-size:90%;">0.474</span></td>
<td id="S4.T1.4.12.11.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.12.11.4.1" class="ltx_text" style="font-size:90%;">0.447</span></td>
<td id="S4.T1.4.12.11.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.12.11.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.520</span></td>
</tr>
<tr id="S4.T1.4.13.12" class="ltx_tr">
<th id="S4.T1.4.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.13.12.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.13.12.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.13.12.2.1" class="ltx_text" style="font-size:90%;">0.664</span></td>
<td id="S4.T1.4.13.12.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.13.12.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.763</span></td>
<td id="S4.T1.4.13.12.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.13.12.4.1" class="ltx_text" style="font-size:90%;">0.664</span></td>
<td id="S4.T1.4.13.12.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.13.12.5.1" class="ltx_text" style="font-size:90%;">0.743</span></td>
</tr>
<tr id="S4.T1.4.14.13" class="ltx_tr">
<th id="S4.T1.4.14.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S4.T1.4.14.13.1.1" class="ltx_text" style="font-size:90%;">College biology (0-shot)</span></th>
<th id="S4.T1.4.14.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T1.4.14.13.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.14.13.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.14.13.3.1" class="ltx_text" style="font-size:90%;">0.681</span></td>
<td id="S4.T1.4.14.13.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.14.13.4.1" class="ltx_text" style="font-size:90%;">0.757</span></td>
<td id="S4.T1.4.14.13.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.14.13.5.1" class="ltx_text" style="font-size:90%;">0.701</span></td>
<td id="S4.T1.4.14.13.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.14.13.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.764</span></td>
</tr>
<tr id="S4.T1.4.15.14" class="ltx_tr">
<th id="S4.T1.4.15.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.15.14.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.15.14.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.15.14.2.1" class="ltx_text" style="font-size:90%;">0.438</span></td>
<td id="S4.T1.4.15.14.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.15.14.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.493</span></td>
<td id="S4.T1.4.15.14.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.15.14.4.1" class="ltx_text" style="font-size:90%;">0.458</span></td>
<td id="S4.T1.4.15.14.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.15.14.5.1" class="ltx_text" style="font-size:90%;">0.465</span></td>
</tr>
<tr id="S4.T1.4.16.15" class="ltx_tr">
<th id="S4.T1.4.16.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.16.15.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.16.15.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.16.15.2.1" class="ltx_text" style="font-size:90%;">0.583</span></td>
<td id="S4.T1.4.16.15.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.16.15.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.639</span></td>
<td id="S4.T1.4.16.15.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.16.15.4.1" class="ltx_text" style="font-size:90%;">0.604</span></td>
<td id="S4.T1.4.16.15.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.16.15.5.1" class="ltx_text" style="font-size:90%;">0.632</span></td>
</tr>
<tr id="S4.T1.4.17.16" class="ltx_tr">
<th id="S4.T1.4.17.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="S4.T1.4.17.16.1.1" class="ltx_text" style="font-size:90%;">College biology (5-shot)</span></th>
<th id="S4.T1.4.17.16.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.17.16.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.17.16.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.17.16.3.1" class="ltx_text" style="font-size:90%;">0.722</span></td>
<td id="S4.T1.4.17.16.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.17.16.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.778</span></td>
<td id="S4.T1.4.17.16.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.17.16.5.1" class="ltx_text" style="font-size:90%;">0.736</span></td>
<td id="S4.T1.4.17.16.6" class="ltx_td ltx_align_center"><span id="S4.T1.4.17.16.6.1" class="ltx_text" style="font-size:90%;">0.771</span></td>
</tr>
<tr id="S4.T1.4.18.17" class="ltx_tr">
<th id="S4.T1.4.18.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.18.17.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.18.17.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.18.17.2.1" class="ltx_text" style="font-size:90%;">0.451</span></td>
<td id="S4.T1.4.18.17.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.18.17.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.521</span></td>
<td id="S4.T1.4.18.17.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.18.17.4.1" class="ltx_text" style="font-size:90%;">0.424</span></td>
<td id="S4.T1.4.18.17.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.18.17.5.1" class="ltx_text" style="font-size:90%;">0.479</span></td>
</tr>
<tr id="S4.T1.4.19.18" class="ltx_tr">
<th id="S4.T1.4.19.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.19.18.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.19.18.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.19.18.2.1" class="ltx_text" style="font-size:90%;">0.604</span></td>
<td id="S4.T1.4.19.18.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.19.18.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.660</span></td>
<td id="S4.T1.4.19.18.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.19.18.4.1" class="ltx_text" style="font-size:90%;">0.625</span></td>
<td id="S4.T1.4.19.18.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.19.18.5.1" class="ltx_text" style="font-size:90%;">0.653</span></td>
</tr>
<tr id="S4.T1.4.20.19" class="ltx_tr">
<th id="S4.T1.4.20.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S4.T1.4.20.19.1.1" class="ltx_text" style="font-size:90%;">College chemistry (0-shot)</span></th>
<th id="S4.T1.4.20.19.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T1.4.20.19.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.20.19.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.20.19.3.1" class="ltx_text" style="font-size:90%;">0.470</span></td>
<td id="S4.T1.4.20.19.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.20.19.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.500</span></td>
<td id="S4.T1.4.20.19.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.20.19.5.1" class="ltx_text" style="font-size:90%;">0.490</span></td>
<td id="S4.T1.4.20.19.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.20.19.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.500</span></td>
</tr>
<tr id="S4.T1.4.21.20" class="ltx_tr">
<th id="S4.T1.4.21.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.21.20.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.21.20.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.21.20.2.1" class="ltx_text" style="font-size:90%;">0.310</span></td>
<td id="S4.T1.4.21.20.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.21.20.3.1" class="ltx_text" style="font-size:90%;">0.380</span></td>
<td id="S4.T1.4.21.20.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.21.20.4.1" class="ltx_text" style="font-size:90%;">0.390</span></td>
<td id="S4.T1.4.21.20.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.21.20.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.390</span></td>
</tr>
<tr id="S4.T1.4.22.21" class="ltx_tr">
<th id="S4.T1.4.22.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.22.21.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.22.21.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.22.21.2.1" class="ltx_text" style="font-size:90%;">0.370</span></td>
<td id="S4.T1.4.22.21.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.22.21.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.440</span></td>
<td id="S4.T1.4.22.21.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.22.21.4.1" class="ltx_text" style="font-size:90%;">0.370</span></td>
<td id="S4.T1.4.22.21.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.22.21.5.1" class="ltx_text" style="font-size:90%;">0.390</span></td>
</tr>
<tr id="S4.T1.4.23.22" class="ltx_tr">
<th id="S4.T1.4.23.22.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="S4.T1.4.23.22.1.1" class="ltx_text" style="font-size:90%;">College chemistry (5-shot)</span></th>
<th id="S4.T1.4.23.22.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.23.22.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.23.22.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.23.22.3.1" class="ltx_text" style="font-size:90%;">0.470</span></td>
<td id="S4.T1.4.23.22.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.23.22.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.540</span></td>
<td id="S4.T1.4.23.22.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.23.22.5.1" class="ltx_text" style="font-size:90%;">0.500</span></td>
<td id="S4.T1.4.23.22.6" class="ltx_td ltx_align_center"><span id="S4.T1.4.23.22.6.1" class="ltx_text" style="font-size:90%;">0.500</span></td>
</tr>
<tr id="S4.T1.4.24.23" class="ltx_tr">
<th id="S4.T1.4.24.23.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.24.23.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.24.23.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.24.23.2.1" class="ltx_text" style="font-size:90%;">0.370</span></td>
<td id="S4.T1.4.24.23.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.24.23.3.1" class="ltx_text" style="font-size:90%;">0.380</span></td>
<td id="S4.T1.4.24.23.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.24.23.4.1" class="ltx_text" style="font-size:90%;">0.360</span></td>
<td id="S4.T1.4.24.23.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.24.23.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.390</span></td>
</tr>
<tr id="S4.T1.4.25.24" class="ltx_tr">
<th id="S4.T1.4.25.24.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.25.24.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.25.24.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.25.24.2.1" class="ltx_text" style="font-size:90%;">0.430</span></td>
<td id="S4.T1.4.25.24.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.25.24.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.470</span></td>
<td id="S4.T1.4.25.24.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.25.24.4.1" class="ltx_text" style="font-size:90%;">0.370</span></td>
<td id="S4.T1.4.25.24.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.25.24.5.1" class="ltx_text" style="font-size:90%;">0.380</span></td>
</tr>
<tr id="S4.T1.4.26.25" class="ltx_tr">
<th id="S4.T1.4.26.25.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S4.T1.4.26.25.1.1" class="ltx_text" style="font-size:90%;">Prehistory (0-shot)</span></th>
<th id="S4.T1.4.26.25.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T1.4.26.25.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.26.25.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.26.25.3.1" class="ltx_text" style="font-size:90%;">0.713</span></td>
<td id="S4.T1.4.26.25.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.26.25.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.750</span></td>
<td id="S4.T1.4.26.25.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.26.25.5.1" class="ltx_text" style="font-size:90%;">0.719</span></td>
<td id="S4.T1.4.26.25.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.26.25.6.1" class="ltx_text" style="font-size:90%;">0.731</span></td>
</tr>
<tr id="S4.T1.4.27.26" class="ltx_tr">
<th id="S4.T1.4.27.26.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.27.26.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.27.26.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.27.26.2.1" class="ltx_text" style="font-size:90%;">0.448</span></td>
<td id="S4.T1.4.27.26.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.27.26.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.481</span></td>
<td id="S4.T1.4.27.26.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.27.26.4.1" class="ltx_text" style="font-size:90%;">0.457</span></td>
<td id="S4.T1.4.27.26.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.27.26.5.1" class="ltx_text" style="font-size:90%;">0.478</span></td>
</tr>
<tr id="S4.T1.4.28.27" class="ltx_tr">
<th id="S4.T1.4.28.27.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.28.27.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.28.27.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.28.27.2.1" class="ltx_text" style="font-size:90%;">0.642</span></td>
<td id="S4.T1.4.28.27.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.28.27.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.679</span></td>
<td id="S4.T1.4.28.27.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.28.27.4.1" class="ltx_text" style="font-size:90%;">0.673</span></td>
<td id="S4.T1.4.28.27.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.28.27.5.1" class="ltx_text" style="font-size:90%;">0.673</span></td>
</tr>
<tr id="S4.T1.4.29.28" class="ltx_tr">
<th id="S4.T1.4.29.28.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" rowspan="3"><span id="S4.T1.4.29.28.1.1" class="ltx_text" style="font-size:90%;">Prehistory (5-shot)</span></th>
<th id="S4.T1.4.29.28.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.29.28.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.29.28.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.29.28.3.1" class="ltx_text" style="font-size:90%;">0.722</span></td>
<td id="S4.T1.4.29.28.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.29.28.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.762</span></td>
<td id="S4.T1.4.29.28.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.29.28.5.1" class="ltx_text" style="font-size:90%;">0.725</span></td>
<td id="S4.T1.4.29.28.6" class="ltx_td ltx_align_center"><span id="S4.T1.4.29.28.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.762</span></td>
</tr>
<tr id="S4.T1.4.30.29" class="ltx_tr">
<th id="S4.T1.4.30.29.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.30.29.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.30.29.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.30.29.2.1" class="ltx_text" style="font-size:90%;">0.515</span></td>
<td id="S4.T1.4.30.29.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.30.29.3.1" class="ltx_text" style="font-size:90%;">0.531</span></td>
<td id="S4.T1.4.30.29.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.30.29.4.1" class="ltx_text" style="font-size:90%;">0.503</span></td>
<td id="S4.T1.4.30.29.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.30.29.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.537</span></td>
</tr>
<tr id="S4.T1.4.31.30" class="ltx_tr">
<th id="S4.T1.4.31.30.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S4.T1.4.31.30.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.31.30.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.31.30.2.1" class="ltx_text" style="font-size:90%;">0.664</span></td>
<td id="S4.T1.4.31.30.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.31.30.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.698</span></td>
<td id="S4.T1.4.31.30.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.31.30.4.1" class="ltx_text" style="font-size:90%;">0.667</span></td>
<td id="S4.T1.4.31.30.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.31.30.5.1" class="ltx_text" style="font-size:90%;">0.694</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.4.1.1" style="font-size:90%;">Table 2</span>:</span><span class="ltx_text" id="S4.T2.5.2" style="font-size:90%;">Current events results. 원본 데이터 세트에서 미세 조정된 모델은 <span class="ltx_text ltx_font_italic" id="S4.T2.5.2.1">FT-reg</span>으로 레이블링되는 반면, 여러 패러프레이즈가 있는 데이터 세트에서 훈련된 모델은 <span class="ltx_text ltx_font_italic" id="S4.T2.5.2.2">FT-par</span>으로 레이블링된다. </span></figcaption>
<br class="ltx_break">
<table id="S4.T2.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.6.1.1" class="ltx_tr">
<th id="S4.T2.6.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S4.T2.6.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.6.1.1.2.1" class="ltx_text" style="font-size:90%;">Base model</span></th>
<th id="S4.T2.6.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.6.1.1.3.1" class="ltx_text" style="font-size:90%;">Base model + RAG</span></th>
<th id="S4.T2.6.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.6.1.1.4.1" class="ltx_text" style="font-size:90%;">FT-reg</span></th>
<th id="S4.T2.6.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.6.1.1.5.1" class="ltx_text" style="font-size:90%;">FT-par</span></th>
<th id="S4.T2.6.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.6.1.1.6.1" class="ltx_text" style="font-size:90%;">FT-reg + RAG</span></th>
<th id="S4.T2.6.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.6.1.1.7.1" class="ltx_text" style="font-size:90%;">FT-par + RAG</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.6.2.1" class="ltx_tr">
<th id="S4.T2.6.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T2.6.2.1.1.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T2.6.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.6.2.1.2.1" class="ltx_text" style="font-size:90%;">0.481</span></td>
<td id="S4.T2.6.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.6.2.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.875</span></td>
<td id="S4.T2.6.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.6.2.1.4.1" class="ltx_text" style="font-size:90%;">0.504</span></td>
<td id="S4.T2.6.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.6.2.1.5.1" class="ltx_text" style="font-size:90%;">0.588</span></td>
<td id="S4.T2.6.2.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.6.2.1.6.1" class="ltx_text" style="font-size:90%;">0.810</span></td>
<td id="S4.T2.6.2.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.6.2.1.7.1" class="ltx_text" style="font-size:90%;">0.830</span></td>
</tr>
<tr id="S4.T2.6.3.2" class="ltx_tr">
<th id="S4.T2.6.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T2.6.3.2.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T2.6.3.2.2" class="ltx_td ltx_align_center"><span id="S4.T2.6.3.2.2.1" class="ltx_text" style="font-size:90%;">0.353</span></td>
<td id="S4.T2.6.3.2.3" class="ltx_td ltx_align_center"><span id="S4.T2.6.3.2.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.585</span></td>
<td id="S4.T2.6.3.2.4" class="ltx_td ltx_align_center"><span id="S4.T2.6.3.2.4.1" class="ltx_text" style="font-size:90%;">0.219</span></td>
<td id="S4.T2.6.3.2.5" class="ltx_td ltx_align_center"><span id="S4.T2.6.3.2.5.1" class="ltx_text" style="font-size:90%;">0.392</span></td>
<td id="S4.T2.6.3.2.6" class="ltx_td ltx_align_center"><span id="S4.T2.6.3.2.6.1" class="ltx_text" style="font-size:90%;">0.326</span></td>
<td id="S4.T2.6.3.2.7" class="ltx_td ltx_align_center"><span id="S4.T2.6.3.2.7.1" class="ltx_text" style="font-size:90%;">0.520</span></td>
</tr>
<tr id="S4.T2.6.4.3" class="ltx_tr">
<th id="S4.T2.6.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S4.T2.6.4.3.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T2.6.4.3.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.6.4.3.2.1" class="ltx_text" style="font-size:90%;">0.456</span></td>
<td id="S4.T2.6.4.3.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.6.4.3.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.876</span></td>
<td id="S4.T2.6.4.3.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.6.4.3.4.1" class="ltx_text" style="font-size:90%;">0.511</span></td>
<td id="S4.T2.6.4.3.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.6.4.3.5.1" class="ltx_text" style="font-size:90%;">0.566</span></td>
<td id="S4.T2.6.4.3.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.6.4.3.6.1" class="ltx_text" style="font-size:90%;">0.820</span></td>
<td id="S4.T2.6.4.3.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.6.4.3.7.1" class="ltx_text" style="font-size:90%;">0.826</span></td>
</tr>
</tbody>
</table>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Task Selection and Rationale</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">MMLU Benchmark</span>  지식 집약적 태스크에 대한 LLM의 능력을 적절하게 평가하기 위해 해부학, 천문학, 대학 생물학, 대학 화학 및 선사학 토픽에서 MMLU(Massively Multilingual Language Understanding Evaluation) 벤치마크 <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="#bib.bib12" title="">2021</a>)</cite>에서 네 가지 별개의 태스크를 선택했다. 선택된 과제는 사실적 지식에 대한 강조와 추론에 대한 최소한의 의존도를 기반으로 선택되었다. 휴리스틱으로 질문이 짧고 컨텍스트가 없는 작업을 선택했습니다. 실제로 우리는 평가가 특정 분야에 국한되지 않도록 인문학 과목 1개뿐 아니라 STEM 과목 4개를 선택했다. 선사에는 모든 비근대 역사에 걸친 질문이 포함된다는 점에 유의하라. 이 접근법은 추론 과정과 별도로 정보를 이해하고 조작하는 LLM 능력을 테스트할 수 있도록 하는 것을 목표로 한다.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Current Events Task</span>  LLMs' abilities to learn new knowledge, we created a task comprising a multiple-choice questions about current events. 이 과제에는 다양한 모델의 훈련 데이터를 컷오프한 후 발생한 사건에 대한 객관식 질문이 포함된다. 구체적으로, 우리는 관련 위키피디아 인덱스<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://en.wikipedia.org/wiki/Category:2023_events_in_the_United_States_by_month" target="_blank" title="">https://en.wikipedia.org/wiki/Category:2023_events_in_the_United_States_by_month</a></span></span></span>에 포함된 2023년 8월부터 11월까지의 시간 범위에서 미국의 "현재 이벤트"에 초점을 맞췄다. 이 방법은 모델이 이러한 사실에 노출되지 않았음을 대부분 보장할 수 있으므로 지식 주입 능력을 직접 테스트할 수 있다.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Data Collection and Preprocessing</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p1.1">이러한 지식 집약적 작업에 대한 LLM의 성능을 효과적으로 평가하기 위해 위키피디아에서 주제당 관련 기사를 스크래핑하여 포괄적인 보조 데이터 세트를 수집했다. 위키피디아를 지식의 주요 원천으로 선택하는 근거는 관련 주제에 대한 광범위한 범위와 군중 검증 지식의 저장소로서의 신뢰성이다. 작업과 관련된 모든 기사는 토픽당 관련 중앙 페이지를 식별하여 공식 위키피디아 API<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.mediawiki.org/wiki/API:Main_page" target="_blank" title="">https://www.mediawiki.org/wiki/API:Main_page</a></span></span></span>을 통해 검색되었다.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p2.1">그 후, 데이터를 원시 하위 섹션에서 청소 청크로 변환하기 위해 엄격한 청소 프로세스가 활용되었다. 이 단계는 “wikiextractor” 도구 <cite class="ltx_cite ltx_citemacro_citep">(Attardi, <a class="ltx_ref" href="#bib.bib1" title="">2015</a>)</cite>로 수행되었다. 작은 클린 청크(예를 들어, HTML, URL 등을 제거)로 분할하는 것은 다양한 지식 도메인에 걸쳐 LLM의 이해의 평가를 향상시키고 미세 조정 프로세스에서 LLM을 지원하는 것을 목표로 했다.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Current Events Task Creation</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS3.p1.1">위키피디아에서 관련 청크를 수집한 후 GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="#bib.bib30" title="">2023</a>)</cite>를 사용하여 새로운 객관식 데이터 세트를 만들었다. 먼저 작은 덩어리를 제거했습니다. 말뭉치의 나머지 각 청크에 대해 GPT-4는 하나의 정답만 있는 매우 구체적이고 고품질 객관식 질문 4개를 생성하도록 지시받았다. 구체적으로, 우리는 질문이 어떤 컨텍스트를 지칭하고 최소한의 모호성으로 질문에 대답할 수 있다는 것을 의미한다. 다음으로 GPT-4는 4개 중 가장 구체적인 2개를 선택하도록 요청받았다. 이어서 수동 평가 및 검증 단계를 거쳤다. 그 결과 총 910개의 새로운 질문이 나왔습니다.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Paraphrases Generation</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS4.p1.1">데이터 세트를 만든 후 GPT-4를 사용하여 데이터 세트의 증강을 생성했다. 우리는 GPT-4에 재워딩되는 동안 정보를 완전히 유지하는 입력 데이터의 패러프레이즈된 버전을 제공하도록 지시했다. 각 패러프레이징 반복은 다양성을 보장하기 위해 다른 종자로 수행되었다.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS4.p2.1">우리는 각 작업에 대해 무작위로 240개의 청크를 선택하고 청크당 2개의 패러프레이즈를 생성했다. 이들은 하이퍼파라미터 튜닝을 위한 검증 세트로 사용하기 위해 따로 두었다. 현재 이벤트 데이터 세트의 경우 <a class="ltx_ref" href="#S6" title="6 The Importance of Repetition ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">6</span></a>에 설명된 미세 조정 프로세스에 사용된 각 청크에 대해 10개의 패러프레이즈를 생성했다.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments and Results</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p" id="S5.p1.1"><span class="ltx_text ltx_font_bold" id="S5.p1.1.1">Experimental Framework</span>  We used the popular LM-Evaluation-Harness <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="#bib.bib10" title="">2021</a>)</cite> repository to evaluate the performance of LLMs on the selected knowledge-intensive tasks. LM-Evaluation-Harness는 현재 모델 평가의 산업 표준 역할을 하는 강력한 벤치마킹 도구이며 HuggingFace 리더보드<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" target="_blank" title="">https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</a></span></span></span>의 기반이 된다. 이 플랫폼을 활용하면 표준화된 평가 프레임워크가 보장되고 모델, 방법 및 데이터 세트 간에 일관된 비교가 가능하다. 더 중요한 것은 평가를 위해 업계 표준을 사용함으로써 신속한 엔지니어링 및 형식화 문제로 인한 차이를 피하고 각 모델에 대해 보고된 기준 결과를 복제할 수 있다는 것이다.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p class="ltx_p" id="S5.p2.1"><span class="ltx_text ltx_font_bold" id="S5.p2.1.1">Model Selection</span>  We chose three models for inference evaluation: Llama2-7B <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="#bib.bib45" title="">2023</a>)</cite>, Mistral-7B <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="#bib.bib15" title="">2023</a>)</cite>, Orca2-7B <cite class="ltx_cite ltx_citemacro_citep">(Mitra et al., <a class="ltx_ref" href="#bib.bib26" title="">2023</a>)</cite>. 이러한 모델의 선택은 다양한 기본 기능에 걸쳐 가장 인기 있는 오픈 소스 기반 모델과 명령 조정 모델을 나타내는 것을 의미했다. 또한, RAG 컴포넌트에 대한 임베딩 모델로 <span class="ltx_text ltx_font_italic" id="S5.p2.1.2">bge-large-en</span> <cite class="ltx_cite ltx_citemacro_citep">(Xiao et al., <a class="ltx_ref" href="#bib.bib52" title="">2023</a>)</cite>를 선택하였고, 벡터 저장소로 FAISS <cite class="ltx_cite ltx_citemacro_citep">(Johnson et al., <a class="ltx_ref" href="#bib.bib16" title="">2019</a>)</cite>를 사용하였다. 이 임베딩 모델은 현재 HuggingFace MTEB 리더보드<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/spaces/mteb/leaderboard" target="_blank" title="">https://huggingface.co/spaces/mteb/leaderboard</a></span></span></span>에 따라 오픈소스 임베딩 모델의 SOTA이다.</p>
</div>
<figure id="S5.F2" class="ltx_figure">
<p id="S5.F2.1.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S5.F2.1.1.1" class="ltx_text"><img src="https://ar5iv.labs.arxiv.org/html/2312.05934/assets/media/peformance_gain.png" id="S5.F2.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="355" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F2.3.1.1" style="font-size:90%;">그림 2</span>:</span><span class="ltx_text" id="S5.F2.4.2" style="font-size:90%;">The relative accuracy gain (as explained in <a class="ltx_ref" href="#S5.E5" title="In 5 Experiments and Results ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Equation</span> <span class="ltx_text ltx_ref_tag">5</span></a>) for each knowledge-injection method, averaged (columnwise) across <a class="ltx_ref" href="#S4.T1" title="In 4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a>. </span></figcaption>
</figure>
<div id="S5.p3" class="ltx_para">
<p class="ltx_p" id="S5.p3.1"><span class="ltx_text ltx_font_bold" id="S5.p3.1.1">Configuration Variations</span>  Our evaluation included multiple configurations, with a grid-search over them, allow for more comprehensive benchmarking. <br class="ltx_break"/>먼저, 기준선 및 미세 조정 모델 및 성능을 RAG 성분과 비교했다. 둘째, RAG의 컨텍스트에 추가할 최적의 텍스트 청크 수를 탐색하였다. 구체적으로 모델 성능에 미치는 영향을 분석하기 위해 <math alttext="K\in\{0,\ldots,5\}" class="ltx_Math" display="inline" id="S5.p3.1.m1.3"><semantics id="S5.p3.1.m1.3a"><mrow id="S5.p3.1.m1.3.4" xref="S5.p3.1.m1.3.4.cmml"><mi id="S5.p3.1.m1.3.4.2" xref="S5.p3.1.m1.3.4.2.cmml">K</mi><mo id="S5.p3.1.m1.3.4.1" xref="S5.p3.1.m1.3.4.1.cmml">∈</mo><mrow id="S5.p3.1.m1.3.4.3.2" xref="S5.p3.1.m1.3.4.3.1.cmml"><mo id="S5.p3.1.m1.3.4.3.2.1" stretchy="false" xref="S5.p3.1.m1.3.4.3.1.cmml">{</mo><mn id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml">0</mn><mo id="S5.p3.1.m1.3.4.3.2.2" xref="S5.p3.1.m1.3.4.3.1.cmml">,</mo><mi id="S5.p3.1.m1.2.2" mathvariant="normal" xref="S5.p3.1.m1.2.2.cmml">…</mi><mo id="S5.p3.1.m1.3.4.3.2.3" xref="S5.p3.1.m1.3.4.3.1.cmml">,</mo><mn id="S5.p3.1.m1.3.3" xref="S5.p3.1.m1.3.3.cmml">5</mn><mo id="S5.p3.1.m1.3.4.3.2.4" stretchy="false" xref="S5.p3.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.3b"><apply id="S5.p3.1.m1.3.4.cmml" xref="S5.p3.1.m1.3.4"><in id="S5.p3.1.m1.3.4.1.cmml" xref="S5.p3.1.m1.3.4.1"></in><ci id="S5.p3.1.m1.3.4.2.cmml" xref="S5.p3.1.m1.3.4.2">𝐾</ci><set id="S5.p3.1.m1.3.4.3.1.cmml" xref="S5.p3.1.m1.3.4.3.2"><cn id="S5.p3.1.m1.1.1.cmml" type="integer" xref="S5.p3.1.m1.1.1">0</cn><ci id="S5.p3.1.m1.2.2.cmml" xref="S5.p3.1.m1.2.2">…</ci><cn id="S5.p3.1.m1.3.3.cmml" type="integer" xref="S5.p3.1.m1.3.3">5</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.3c">K\in\{0,\ldots,5\}</annotation></semantics></math>의 다른 값을 사용하였다. 마지막으로 5-shot 성능 대 5-shot 성능을 탐색하였다. 0샷.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p class="ltx_p" id="S5.p4.5"><span class="ltx_text ltx_font_bold" id="S5.p4.5.1">Training Setup</span>  We trained all the models using the unsupervised training procedure using the <a class="ltx_ref" href="#S3.SS2" title="3.2 Fine-Tuning ‣ 3 Injecting Knowledge to Language Models ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">3.2</span></a>. 각 데이터 세트에 대해 보조 지식 베이스를 길이에 따라 원본 청크를 연결하거나 분할하여 크기 <math alttext="256" class="ltx_Math" display="inline" id="S5.p4.1.m1.1"><semantics id="S5.p4.1.m1.1a"><mn id="S5.p4.1.m1.1.1" xref="S5.p4.1.m1.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="S5.p4.1.m1.1b"><cn id="S5.p4.1.m1.1.1.cmml" type="integer" xref="S5.p4.1.m1.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.1.m1.1c">256</annotation></semantics></math>의 동일한 청크로 분할했다. 또한 두 개의 특수 토큰인 <math alttext="&lt;" class="ltx_Math" display="inline" id="S5.p4.2.m2.1"><semantics id="S5.p4.2.m2.1a"><mo id="S5.p4.2.m2.1.1" xref="S5.p4.2.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.p4.2.m2.1b"><lt id="S5.p4.2.m2.1.1.cmml" xref="S5.p4.2.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.2.m2.1c">&lt;</annotation></semantics></math>BOS<math alttext="&gt;" class="ltx_Math" display="inline" id="S5.p4.3.m3.1"><semantics id="S5.p4.3.m3.1a"><mo id="S5.p4.3.m3.1.1" xref="S5.p4.3.m3.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S5.p4.3.m3.1b"><gt id="S5.p4.3.m3.1.1.cmml" xref="S5.p4.3.m3.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.3.m3.1c">&gt;</annotation></semantics></math>와 <math alttext="&lt;" class="ltx_Math" display="inline" id="S5.p4.4.m4.1"><semantics id="S5.p4.4.m4.1a"><mo id="S5.p4.4.m4.1.1" xref="S5.p4.4.m4.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.p4.4.m4.1b"><lt id="S5.p4.4.m4.1.1.cmml" xref="S5.p4.4.m4.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.4.m4.1c">&lt;</annotation></semantics></math>EOS<math alttext="&gt;" class="ltx_Math" display="inline" id="S5.p4.5.m5.1"><semantics id="S5.p4.5.m5.1a"><mo id="S5.p4.5.m5.1.1" xref="S5.p4.5.m5.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S5.p4.5.m5.1b"><gt id="S5.p4.5.m5.1.1.cmml" xref="S5.p4.5.m5.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.5.m5.1c">&gt;</annotation></semantics></math>를 추가하여 원본 청크의 시작과 끝을 구분하여 문서의 구조를 보존하였다.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p class="ltx_p" id="S5.p5.2">모델은 하이퍼파라미터 검색을 통해 발견된 <math alttext="1\times{10}^{-6}" class="ltx_Math" display="inline" id="S5.p5.1.m1.1"><semantics id="S5.p5.1.m1.1a"><mrow id="S5.p5.1.m1.1.1" xref="S5.p5.1.m1.1.1.cmml"><mn id="S5.p5.1.m1.1.1.2" xref="S5.p5.1.m1.1.1.2.cmml">1</mn><mo id="S5.p5.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.p5.1.m1.1.1.1.cmml">×</mo><msup id="S5.p5.1.m1.1.1.3" xref="S5.p5.1.m1.1.1.3.cmml"><mn id="S5.p5.1.m1.1.1.3.2" xref="S5.p5.1.m1.1.1.3.2.cmml">10</mn><mrow id="S5.p5.1.m1.1.1.3.3" xref="S5.p5.1.m1.1.1.3.3.cmml"><mo id="S5.p5.1.m1.1.1.3.3a" xref="S5.p5.1.m1.1.1.3.3.cmml">−</mo><mn id="S5.p5.1.m1.1.1.3.3.2" xref="S5.p5.1.m1.1.1.3.3.2.cmml">6</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.p5.1.m1.1b"><apply id="S5.p5.1.m1.1.1.cmml" xref="S5.p5.1.m1.1.1"><times id="S5.p5.1.m1.1.1.1.cmml" xref="S5.p5.1.m1.1.1.1"></times><cn id="S5.p5.1.m1.1.1.2.cmml" type="integer" xref="S5.p5.1.m1.1.1.2">1</cn><apply id="S5.p5.1.m1.1.1.3.cmml" xref="S5.p5.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.p5.1.m1.1.1.3.1.cmml" xref="S5.p5.1.m1.1.1.3">superscript</csymbol><cn id="S5.p5.1.m1.1.1.3.2.cmml" type="integer" xref="S5.p5.1.m1.1.1.3.2">10</cn><apply id="S5.p5.1.m1.1.1.3.3.cmml" xref="S5.p5.1.m1.1.1.3.3"><minus id="S5.p5.1.m1.1.1.3.3.1.cmml" xref="S5.p5.1.m1.1.1.3.3"></minus><cn id="S5.p5.1.m1.1.1.3.3.2.cmml" type="integer" xref="S5.p5.1.m1.1.1.3.3.2">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p5.1.m1.1c">1\times{10}^{-6}</annotation></semantics></math>와 <math alttext="5\times{10}^{-5}" class="ltx_Math" display="inline" id="S5.p5.2.m2.1"><semantics id="S5.p5.2.m2.1a"><mrow id="S5.p5.2.m2.1.1" xref="S5.p5.2.m2.1.1.cmml"><mn id="S5.p5.2.m2.1.1.2" xref="S5.p5.2.m2.1.1.2.cmml">5</mn><mo id="S5.p5.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.p5.2.m2.1.1.1.cmml">×</mo><msup id="S5.p5.2.m2.1.1.3" xref="S5.p5.2.m2.1.1.3.cmml"><mn id="S5.p5.2.m2.1.1.3.2" xref="S5.p5.2.m2.1.1.3.2.cmml">10</mn><mrow id="S5.p5.2.m2.1.1.3.3" xref="S5.p5.2.m2.1.1.3.3.cmml"><mo id="S5.p5.2.m2.1.1.3.3a" xref="S5.p5.2.m2.1.1.3.3.cmml">−</mo><mn id="S5.p5.2.m2.1.1.3.3.2" xref="S5.p5.2.m2.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.p5.2.m2.1b"><apply id="S5.p5.2.m2.1.1.cmml" xref="S5.p5.2.m2.1.1"><times id="S5.p5.2.m2.1.1.1.cmml" xref="S5.p5.2.m2.1.1.1"></times><cn id="S5.p5.2.m2.1.1.2.cmml" type="integer" xref="S5.p5.2.m2.1.1.2">5</cn><apply id="S5.p5.2.m2.1.1.3.cmml" xref="S5.p5.2.m2.1.1.3"><csymbol cd="ambiguous" id="S5.p5.2.m2.1.1.3.1.cmml" xref="S5.p5.2.m2.1.1.3">superscript</csymbol><cn id="S5.p5.2.m2.1.1.3.2.cmml" type="integer" xref="S5.p5.2.m2.1.1.3.2">10</cn><apply id="S5.p5.2.m2.1.1.3.3.cmml" xref="S5.p5.2.m2.1.1.3.3"><minus id="S5.p5.2.m2.1.1.3.3.1.cmml" xref="S5.p5.2.m2.1.1.3.3"></minus><cn id="S5.p5.2.m2.1.1.3.3.2.cmml" type="integer" xref="S5.p5.2.m2.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p5.2.m2.1c">5\times{10}^{-5}</annotation></semantics></math> 사이의 학습률을 사용하여 학습되었다. 모든 모델은 최대 5에포크 및 배치 크기 64에 대해 4개의 NVIDIA A-100 GPU에서 훈련되었다.</p>
</div>
<div id="S5.p6" class="ltx_para">
<p class="ltx_p" id="S5.p6.1"><span class="ltx_text ltx_font_bold" id="S5.p6.1.1">평가 방법</span>  모든 평가는 객관식 옵션 각각을 질문에 추가한 후 모델에 연접을 전달하여 옵션당 로그 확률 점수를 얻었다. 가장 높은 점수를 모형의 선택으로 해석하여 정확도 계산에 사용하였다. 보다 형식적으로, 이는 <a class="ltx_ref" href="#S2.E1" title="In 2 Background ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Equation</span> <span class="ltx_text ltx_ref_tag">1</span></a>에서 <math alttext="\mathcal{M}(q_{n})=c_{n}" class="ltx_Math" display="inline" id="S5.p6.1.m1.1"><semantics id="S5.p6.1.m1.1a"><mrow id="S5.p6.1.m1.1.1" xref="S5.p6.1.m1.1.1.cmml"><mrow id="S5.p6.1.m1.1.1.1" xref="S5.p6.1.m1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.p6.1.m1.1.1.1.3" xref="S5.p6.1.m1.1.1.1.3.cmml">ℳ</mi><mo id="S5.p6.1.m1.1.1.1.2" lspace="0em" rspace="0em" xref="S5.p6.1.m1.1.1.1.2.cmml">​</mo><mrow id="S5.p6.1.m1.1.1.1.1.1" xref="S5.p6.1.m1.1.1.1.1.1.1.cmml"><mo id="S5.p6.1.m1.1.1.1.1.1.2" stretchy="false" xref="S5.p6.1.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S5.p6.1.m1.1.1.1.1.1.1" xref="S5.p6.1.m1.1.1.1.1.1.1.cmml"><mi id="S5.p6.1.m1.1.1.1.1.1.1.2" xref="S5.p6.1.m1.1.1.1.1.1.1.2.cmml">q</mi><mi id="S5.p6.1.m1.1.1.1.1.1.1.3" xref="S5.p6.1.m1.1.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S5.p6.1.m1.1.1.1.1.1.3" stretchy="false" xref="S5.p6.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.p6.1.m1.1.1.2" xref="S5.p6.1.m1.1.1.2.cmml">=</mo><msub id="S5.p6.1.m1.1.1.3" xref="S5.p6.1.m1.1.1.3.cmml"><mi id="S5.p6.1.m1.1.1.3.2" xref="S5.p6.1.m1.1.1.3.2.cmml">c</mi><mi id="S5.p6.1.m1.1.1.3.3" xref="S5.p6.1.m1.1.1.3.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.p6.1.m1.1b"><apply id="S5.p6.1.m1.1.1.cmml" xref="S5.p6.1.m1.1.1"><eq id="S5.p6.1.m1.1.1.2.cmml" xref="S5.p6.1.m1.1.1.2"></eq><apply id="S5.p6.1.m1.1.1.1.cmml" xref="S5.p6.1.m1.1.1.1"><times id="S5.p6.1.m1.1.1.1.2.cmml" xref="S5.p6.1.m1.1.1.1.2"></times><ci id="S5.p6.1.m1.1.1.1.3.cmml" xref="S5.p6.1.m1.1.1.1.3">ℳ</ci><apply id="S5.p6.1.m1.1.1.1.1.1.1.cmml" xref="S5.p6.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.p6.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.p6.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S5.p6.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.p6.1.m1.1.1.1.1.1.1.2">𝑞</ci><ci id="S5.p6.1.m1.1.1.1.1.1.1.3.cmml" xref="S5.p6.1.m1.1.1.1.1.1.1.3">𝑛</ci></apply></apply><apply id="S5.p6.1.m1.1.1.3.cmml" xref="S5.p6.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.1.m1.1.1.3.1.cmml" xref="S5.p6.1.m1.1.1.3">subscript</csymbol><ci id="S5.p6.1.m1.1.1.3.2.cmml" xref="S5.p6.1.m1.1.1.3.2">𝑐</ci><ci id="S5.p6.1.m1.1.1.3.3.cmml" xref="S5.p6.1.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.1.m1.1c">\mathcal{M}(q_{n})=c_{n}</annotation></semantics></math> if라고 말하는 것을 의미한다:</p>
<table id="S5.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E4.m1.2" class="ltx_Math" alttext="c_{n}=\operatorname*{arg\,max}_{l}\{\mathcal{M}(q_{n}\|a^{1}_{n}),\ldots,\mathcal{M}(q_{n}\|a^{L}_{n})\}," display="block"><semantics id="S5.E4.m1.2a"><mrow id="S5.E4.m1.2.2.1" xref="S5.E4.m1.2.2.1.1.cmml"><mrow id="S5.E4.m1.2.2.1.1" xref="S5.E4.m1.2.2.1.1.cmml"><msub id="S5.E4.m1.2.2.1.1.5" xref="S5.E4.m1.2.2.1.1.5.cmml"><mi id="S5.E4.m1.2.2.1.1.5.2" xref="S5.E4.m1.2.2.1.1.5.2.cmml">c</mi><mi id="S5.E4.m1.2.2.1.1.5.3" xref="S5.E4.m1.2.2.1.1.5.3.cmml">n</mi></msub><mo id="S5.E4.m1.2.2.1.1.4" xref="S5.E4.m1.2.2.1.1.4.cmml">=</mo><mrow id="S5.E4.m1.2.2.1.1.3.3" xref="S5.E4.m1.2.2.1.1.3.4.cmml"><munder id="S5.E4.m1.2.2.1.1.1.1.1" xref="S5.E4.m1.2.2.1.1.1.1.1.cmml"><mrow id="S5.E4.m1.2.2.1.1.1.1.1.2" xref="S5.E4.m1.2.2.1.1.1.1.1.2.cmml"><mi id="S5.E4.m1.2.2.1.1.1.1.1.2.2" xref="S5.E4.m1.2.2.1.1.1.1.1.2.2.cmml">arg</mi><mo lspace="0.170em" rspace="0em" id="S5.E4.m1.2.2.1.1.1.1.1.2.1" xref="S5.E4.m1.2.2.1.1.1.1.1.2.1.cmml">​</mo><mi id="S5.E4.m1.2.2.1.1.1.1.1.2.3" xref="S5.E4.m1.2.2.1.1.1.1.1.2.3.cmml">max</mi></mrow><mi id="S5.E4.m1.2.2.1.1.1.1.1.3" xref="S5.E4.m1.2.2.1.1.1.1.1.3.cmml">l</mi></munder><mo id="S5.E4.m1.2.2.1.1.3.3a" xref="S5.E4.m1.2.2.1.1.3.4.cmml">⁡</mo><mrow id="S5.E4.m1.2.2.1.1.3.3.3" xref="S5.E4.m1.2.2.1.1.3.4.cmml"><mo stretchy="false" id="S5.E4.m1.2.2.1.1.3.3.3.3" xref="S5.E4.m1.2.2.1.1.3.4.cmml">{</mo><mrow id="S5.E4.m1.2.2.1.1.2.2.2.1" xref="S5.E4.m1.2.2.1.1.2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E4.m1.2.2.1.1.2.2.2.1.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S5.E4.m1.2.2.1.1.2.2.2.1.2" xref="S5.E4.m1.2.2.1.1.2.2.2.1.2.cmml">​</mo><mrow id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.2" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml"><msub id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.cmml"><mi id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.2" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.2.cmml">q</mi><mi id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.3.cmml">n</mi></msub><mo id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.1" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.1.cmml">∥</mo><msubsup id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.cmml"><mi id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.2" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.2.cmml">a</mi><mi id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.3.cmml">n</mi><mn id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.3.cmml">1</mn></msubsup></mrow><mo stretchy="false" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.E4.m1.2.2.1.1.3.3.3.4" xref="S5.E4.m1.2.2.1.1.3.4.cmml">,</mo><mi mathvariant="normal" id="S5.E4.m1.1.1" xref="S5.E4.m1.1.1.cmml">…</mi><mo id="S5.E4.m1.2.2.1.1.3.3.3.5" xref="S5.E4.m1.2.2.1.1.3.4.cmml">,</mo><mrow id="S5.E4.m1.2.2.1.1.3.3.3.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E4.m1.2.2.1.1.3.3.3.2.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S5.E4.m1.2.2.1.1.3.3.3.2.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.2.cmml">​</mo><mrow id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml"><mo stretchy="false" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml">(</mo><mrow id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml"><msub id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.cmml"><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.2.cmml">q</mi><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.3.cmml">n</mi></msub><mo id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.1" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.1.cmml">∥</mo><msubsup id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.cmml"><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.2.cmml">a</mi><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.3.cmml">n</mi><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.3.cmml">L</mi></msubsup></mrow><mo stretchy="false" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S5.E4.m1.2.2.1.1.3.3.3.6" xref="S5.E4.m1.2.2.1.1.3.4.cmml">}</mo></mrow></mrow></mrow><mo id="S5.E4.m1.2.2.1.2" xref="S5.E4.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E4.m1.2b"><apply id="S5.E4.m1.2.2.1.1.cmml" xref="S5.E4.m1.2.2.1"><eq id="S5.E4.m1.2.2.1.1.4.cmml" xref="S5.E4.m1.2.2.1.1.4"></eq><apply id="S5.E4.m1.2.2.1.1.5.cmml" xref="S5.E4.m1.2.2.1.1.5"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.5.1.cmml" xref="S5.E4.m1.2.2.1.1.5">subscript</csymbol><ci id="S5.E4.m1.2.2.1.1.5.2.cmml" xref="S5.E4.m1.2.2.1.1.5.2">𝑐</ci><ci id="S5.E4.m1.2.2.1.1.5.3.cmml" xref="S5.E4.m1.2.2.1.1.5.3">𝑛</ci></apply><apply id="S5.E4.m1.2.2.1.1.3.4.cmml" xref="S5.E4.m1.2.2.1.1.3.3"><apply id="S5.E4.m1.2.2.1.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1">subscript</csymbol><apply id="S5.E4.m1.2.2.1.1.1.1.1.2.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.2"><times id="S5.E4.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.2.1"></times><ci id="S5.E4.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.2.2">arg</ci><ci id="S5.E4.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.2.3">max</ci></apply><ci id="S5.E4.m1.2.2.1.1.1.1.1.3.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.3">𝑙</ci></apply><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1"><times id="S5.E4.m1.2.2.1.1.2.2.2.1.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.2"></times><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.3.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.3">ℳ</ci><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1"><csymbol cd="latexml" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.1">conditional</csymbol><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.2">𝑞</ci><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.3.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.3">𝑛</ci></apply><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3">subscript</csymbol><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3">superscript</csymbol><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.2">𝑎</ci><cn type="integer" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.3.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.3">1</cn></apply><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.3.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.3">𝑛</ci></apply></apply></apply><ci id="S5.E4.m1.1.1.cmml" xref="S5.E4.m1.1.1">…</ci><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2"><times id="S5.E4.m1.2.2.1.1.3.3.3.2.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.2"></times><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.3">ℳ</ci><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1"><csymbol cd="latexml" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.1">conditional</csymbol><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2">subscript</csymbol><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.2">𝑞</ci><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.3">𝑛</ci></apply><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3">subscript</csymbol><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3">superscript</csymbol><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.2">𝑎</ci><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.3">𝐿</ci></apply><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.3">𝑛</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E4.m1.2c">c_{n}=\operatorname*{arg\,max}_{l}\{\mathcal{M}(q_{n}\|a^{1}_{n}),\ldots,\mathcal{M}(q_{n}\|a^{L}_{n})\},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S5.p6.2" class="ltx_p">where <math id="S5.p6.2.m1.2" class="ltx_Math" alttext="\mathcal{M}(q_{n}\|a^{l}_{n})=\log P_{\mathcal{M}}(q_{n}\|a^{l}_{n})" display="inline"><semantics id="S5.p6.2.m1.2a"><mrow id="S5.p6.2.m1.2.2" xref="S5.p6.2.m1.2.2.cmml"><mrow id="S5.p6.2.m1.1.1.1" xref="S5.p6.2.m1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.p6.2.m1.1.1.1.3" xref="S5.p6.2.m1.1.1.1.3.cmml">ℳ</mi><mo lspace="0em" rspace="0em" id="S5.p6.2.m1.1.1.1.2" xref="S5.p6.2.m1.1.1.1.2.cmml">​</mo><mrow id="S5.p6.2.m1.1.1.1.1.1" xref="S5.p6.2.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.p6.2.m1.1.1.1.1.1.2" xref="S5.p6.2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.p6.2.m1.1.1.1.1.1.1" xref="S5.p6.2.m1.1.1.1.1.1.1.cmml"><msub id="S5.p6.2.m1.1.1.1.1.1.1.2" xref="S5.p6.2.m1.1.1.1.1.1.1.2.cmml"><mi id="S5.p6.2.m1.1.1.1.1.1.1.2.2" xref="S5.p6.2.m1.1.1.1.1.1.1.2.2.cmml">q</mi><mi id="S5.p6.2.m1.1.1.1.1.1.1.2.3" xref="S5.p6.2.m1.1.1.1.1.1.1.2.3.cmml">n</mi></msub><mo id="S5.p6.2.m1.1.1.1.1.1.1.1" xref="S5.p6.2.m1.1.1.1.1.1.1.1.cmml">∥</mo><msubsup id="S5.p6.2.m1.1.1.1.1.1.1.3" xref="S5.p6.2.m1.1.1.1.1.1.1.3.cmml"><mi id="S5.p6.2.m1.1.1.1.1.1.1.3.2.2" xref="S5.p6.2.m1.1.1.1.1.1.1.3.2.2.cmml">a</mi><mi id="S5.p6.2.m1.1.1.1.1.1.1.3.3" xref="S5.p6.2.m1.1.1.1.1.1.1.3.3.cmml">n</mi><mi id="S5.p6.2.m1.1.1.1.1.1.1.3.2.3" xref="S5.p6.2.m1.1.1.1.1.1.1.3.2.3.cmml">l</mi></msubsup></mrow><mo stretchy="false" id="S5.p6.2.m1.1.1.1.1.1.3" xref="S5.p6.2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.p6.2.m1.2.2.3" xref="S5.p6.2.m1.2.2.3.cmml">=</mo><mrow id="S5.p6.2.m1.2.2.2" xref="S5.p6.2.m1.2.2.2.cmml"><mrow id="S5.p6.2.m1.2.2.2.3" xref="S5.p6.2.m1.2.2.2.3.cmml"><mi id="S5.p6.2.m1.2.2.2.3.1" xref="S5.p6.2.m1.2.2.2.3.1.cmml">log</mi><mo lspace="0.167em" id="S5.p6.2.m1.2.2.2.3a" xref="S5.p6.2.m1.2.2.2.3.cmml">⁡</mo><msub id="S5.p6.2.m1.2.2.2.3.2" xref="S5.p6.2.m1.2.2.2.3.2.cmml"><mi id="S5.p6.2.m1.2.2.2.3.2.2" xref="S5.p6.2.m1.2.2.2.3.2.2.cmml">P</mi><mi class="ltx_font_mathcaligraphic" id="S5.p6.2.m1.2.2.2.3.2.3" xref="S5.p6.2.m1.2.2.2.3.2.3.cmml">ℳ</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S5.p6.2.m1.2.2.2.2" xref="S5.p6.2.m1.2.2.2.2.cmml">​</mo><mrow id="S5.p6.2.m1.2.2.2.1.1" xref="S5.p6.2.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S5.p6.2.m1.2.2.2.1.1.2" xref="S5.p6.2.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="S5.p6.2.m1.2.2.2.1.1.1" xref="S5.p6.2.m1.2.2.2.1.1.1.cmml"><msub id="S5.p6.2.m1.2.2.2.1.1.1.2" xref="S5.p6.2.m1.2.2.2.1.1.1.2.cmml"><mi id="S5.p6.2.m1.2.2.2.1.1.1.2.2" xref="S5.p6.2.m1.2.2.2.1.1.1.2.2.cmml">q</mi><mi id="S5.p6.2.m1.2.2.2.1.1.1.2.3" xref="S5.p6.2.m1.2.2.2.1.1.1.2.3.cmml">n</mi></msub><mo id="S5.p6.2.m1.2.2.2.1.1.1.1" xref="S5.p6.2.m1.2.2.2.1.1.1.1.cmml">∥</mo><msubsup id="S5.p6.2.m1.2.2.2.1.1.1.3" xref="S5.p6.2.m1.2.2.2.1.1.1.3.cmml"><mi id="S5.p6.2.m1.2.2.2.1.1.1.3.2.2" xref="S5.p6.2.m1.2.2.2.1.1.1.3.2.2.cmml">a</mi><mi id="S5.p6.2.m1.2.2.2.1.1.1.3.3" xref="S5.p6.2.m1.2.2.2.1.1.1.3.3.cmml">n</mi><mi id="S5.p6.2.m1.2.2.2.1.1.1.3.2.3" xref="S5.p6.2.m1.2.2.2.1.1.1.3.2.3.cmml">l</mi></msubsup></mrow><mo stretchy="false" id="S5.p6.2.m1.2.2.2.1.1.3" xref="S5.p6.2.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p6.2.m1.2b"><apply id="S5.p6.2.m1.2.2.cmml" xref="S5.p6.2.m1.2.2"><eq id="S5.p6.2.m1.2.2.3.cmml" xref="S5.p6.2.m1.2.2.3"></eq><apply id="S5.p6.2.m1.1.1.1.cmml" xref="S5.p6.2.m1.1.1.1"><times id="S5.p6.2.m1.1.1.1.2.cmml" xref="S5.p6.2.m1.1.1.1.2"></times><ci id="S5.p6.2.m1.1.1.1.3.cmml" xref="S5.p6.2.m1.1.1.1.3">ℳ</ci><apply id="S5.p6.2.m1.1.1.1.1.1.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1"><csymbol cd="latexml" id="S5.p6.2.m1.1.1.1.1.1.1.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S5.p6.2.m1.1.1.1.1.1.1.2.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.p6.2.m1.1.1.1.1.1.1.2.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.p6.2.m1.1.1.1.1.1.1.2.2.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.2.2">𝑞</ci><ci id="S5.p6.2.m1.1.1.1.1.1.1.2.3.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.2.3">𝑛</ci></apply><apply id="S5.p6.2.m1.1.1.1.1.1.1.3.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.2.m1.1.1.1.1.1.1.3.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S5.p6.2.m1.1.1.1.1.1.1.3.2.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.2.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S5.p6.2.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3.2.2">𝑎</ci><ci id="S5.p6.2.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3.2.3">𝑙</ci></apply><ci id="S5.p6.2.m1.1.1.1.1.1.1.3.3.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3.3">𝑛</ci></apply></apply></apply><apply id="S5.p6.2.m1.2.2.2.cmml" xref="S5.p6.2.m1.2.2.2"><times id="S5.p6.2.m1.2.2.2.2.cmml" xref="S5.p6.2.m1.2.2.2.2"></times><apply id="S5.p6.2.m1.2.2.2.3.cmml" xref="S5.p6.2.m1.2.2.2.3"><log id="S5.p6.2.m1.2.2.2.3.1.cmml" xref="S5.p6.2.m1.2.2.2.3.1"></log><apply id="S5.p6.2.m1.2.2.2.3.2.cmml" xref="S5.p6.2.m1.2.2.2.3.2"><csymbol cd="ambiguous" id="S5.p6.2.m1.2.2.2.3.2.1.cmml" xref="S5.p6.2.m1.2.2.2.3.2">subscript</csymbol><ci id="S5.p6.2.m1.2.2.2.3.2.2.cmml" xref="S5.p6.2.m1.2.2.2.3.2.2">𝑃</ci><ci id="S5.p6.2.m1.2.2.2.3.2.3.cmml" xref="S5.p6.2.m1.2.2.2.3.2.3">ℳ</ci></apply></apply><apply id="S5.p6.2.m1.2.2.2.1.1.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1"><csymbol cd="latexml" id="S5.p6.2.m1.2.2.2.1.1.1.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.1">conditional</csymbol><apply id="S5.p6.2.m1.2.2.2.1.1.1.2.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S5.p6.2.m1.2.2.2.1.1.1.2.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.2">subscript</csymbol><ci id="S5.p6.2.m1.2.2.2.1.1.1.2.2.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.2.2">𝑞</ci><ci id="S5.p6.2.m1.2.2.2.1.1.1.2.3.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.2.3">𝑛</ci></apply><apply id="S5.p6.2.m1.2.2.2.1.1.1.3.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.2.m1.2.2.2.1.1.1.3.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3">subscript</csymbol><apply id="S5.p6.2.m1.2.2.2.1.1.1.3.2.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.2.m1.2.2.2.1.1.1.3.2.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3">superscript</csymbol><ci id="S5.p6.2.m1.2.2.2.1.1.1.3.2.2.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3.2.2">𝑎</ci><ci id="S5.p6.2.m1.2.2.2.1.1.1.3.2.3.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3.2.3">𝑙</ci></apply><ci id="S5.p6.2.m1.2.2.2.1.1.1.3.3.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.2.m1.2c">\mathcal{M}(q_{n}\|a^{l}_{n})=\log P_{\mathcal{M}}(q_{n}\|a^{l}_{n})</annotation></semantics></math>.</p>
</div>
<div id="S5.p7" class="ltx_para">
<p class="ltx_p" id="S5.p7.3"><span class="ltx_text ltx_font_bold" id="S5.p7.3.1">MMLU Results</span>  각 작업 및 모델에 대해 기본 모델, RAG, FT만 사용하고 마지막으로 미세 조정 모델을 생성기로 사용하여 FT와 RAG를 결합하는 네 가지 접근법을 비교했다. 또한, 0-shot 시나리오와 5-shot 시나리오를 사용하여 MMLU 태스크를 테스트했다. 전체 결과는 <a class="ltx_ref" href="#S4.T1" title="In 4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">1</span></a>에 나와 있다. 상대 정확도 이득의 집성, 즉,</p>
<table id="S5.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E5.m1.7" class="ltx_Math" alttext="(\mathcal{L}_{\mathcal{M^{\prime}},\mathcal{Q}}-\mathcal{L}_{\mathcal{M},\mathcal{Q}})/{\mathcal{L}_{\mathcal{M},\mathcal{Q}}}," display="block"><semantics id="S5.E5.m1.7a"><mrow id="S5.E5.m1.7.7.1" xref="S5.E5.m1.7.7.1.1.cmml"><mrow id="S5.E5.m1.7.7.1.1" xref="S5.E5.m1.7.7.1.1.cmml"><mrow id="S5.E5.m1.7.7.1.1.1.1" xref="S5.E5.m1.7.7.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E5.m1.7.7.1.1.1.1.2" xref="S5.E5.m1.7.7.1.1.1.1.1.cmml">(</mo><mrow id="S5.E5.m1.7.7.1.1.1.1.1" xref="S5.E5.m1.7.7.1.1.1.1.1.cmml"><msub id="S5.E5.m1.7.7.1.1.1.1.1.2" xref="S5.E5.m1.7.7.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.7.7.1.1.1.1.1.2.2" xref="S5.E5.m1.7.7.1.1.1.1.1.2.2.cmml">ℒ</mi><mrow id="S5.E5.m1.2.2.2.2" xref="S5.E5.m1.2.2.2.3.cmml"><msup id="S5.E5.m1.2.2.2.2.1" xref="S5.E5.m1.2.2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.2.2.2.2.1.2" xref="S5.E5.m1.2.2.2.2.1.2.cmml">ℳ</mi><mo id="S5.E5.m1.2.2.2.2.1.3" xref="S5.E5.m1.2.2.2.2.1.3.cmml">′</mo></msup><mo id="S5.E5.m1.2.2.2.2.2" xref="S5.E5.m1.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.cmml">𝒬</mi></mrow></msub><mo id="S5.E5.m1.7.7.1.1.1.1.1.1" xref="S5.E5.m1.7.7.1.1.1.1.1.1.cmml">−</mo><msub id="S5.E5.m1.7.7.1.1.1.1.1.3" xref="S5.E5.m1.7.7.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.7.7.1.1.1.1.1.3.2" xref="S5.E5.m1.7.7.1.1.1.1.1.3.2.cmml">ℒ</mi><mrow id="S5.E5.m1.4.4.2.4" xref="S5.E5.m1.4.4.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.3.3.1.1" xref="S5.E5.m1.3.3.1.1.cmml">ℳ</mi><mo id="S5.E5.m1.4.4.2.4.1" xref="S5.E5.m1.4.4.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.4.4.2.2" xref="S5.E5.m1.4.4.2.2.cmml">𝒬</mi></mrow></msub></mrow><mo stretchy="false" id="S5.E5.m1.7.7.1.1.1.1.3" xref="S5.E5.m1.7.7.1.1.1.1.1.cmml">)</mo></mrow><mo id="S5.E5.m1.7.7.1.1.2" xref="S5.E5.m1.7.7.1.1.2.cmml">/</mo><msub id="S5.E5.m1.7.7.1.1.3" xref="S5.E5.m1.7.7.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.7.7.1.1.3.2" xref="S5.E5.m1.7.7.1.1.3.2.cmml">ℒ</mi><mrow id="S5.E5.m1.6.6.2.4" xref="S5.E5.m1.6.6.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.5.5.1.1" xref="S5.E5.m1.5.5.1.1.cmml">ℳ</mi><mo id="S5.E5.m1.6.6.2.4.1" xref="S5.E5.m1.6.6.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.6.6.2.2" xref="S5.E5.m1.6.6.2.2.cmml">𝒬</mi></mrow></msub></mrow><mo id="S5.E5.m1.7.7.1.2" xref="S5.E5.m1.7.7.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E5.m1.7b"><apply id="S5.E5.m1.7.7.1.1.cmml" xref="S5.E5.m1.7.7.1"><divide id="S5.E5.m1.7.7.1.1.2.cmml" xref="S5.E5.m1.7.7.1.1.2"></divide><apply id="S5.E5.m1.7.7.1.1.1.1.1.cmml" xref="S5.E5.m1.7.7.1.1.1.1"><minus id="S5.E5.m1.7.7.1.1.1.1.1.1.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.1"></minus><apply id="S5.E5.m1.7.7.1.1.1.1.1.2.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E5.m1.7.7.1.1.1.1.1.2.1.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E5.m1.7.7.1.1.1.1.1.2.2.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.2.2">ℒ</ci><list id="S5.E5.m1.2.2.2.3.cmml" xref="S5.E5.m1.2.2.2.2"><apply id="S5.E5.m1.2.2.2.2.1.cmml" xref="S5.E5.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S5.E5.m1.2.2.2.2.1.1.cmml" xref="S5.E5.m1.2.2.2.2.1">superscript</csymbol><ci id="S5.E5.m1.2.2.2.2.1.2.cmml" xref="S5.E5.m1.2.2.2.2.1.2">ℳ</ci><ci id="S5.E5.m1.2.2.2.2.1.3.cmml" xref="S5.E5.m1.2.2.2.2.1.3">′</ci></apply><ci id="S5.E5.m1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1">𝒬</ci></list></apply><apply id="S5.E5.m1.7.7.1.1.1.1.1.3.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E5.m1.7.7.1.1.1.1.1.3.1.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E5.m1.7.7.1.1.1.1.1.3.2.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.3.2">ℒ</ci><list id="S5.E5.m1.4.4.2.3.cmml" xref="S5.E5.m1.4.4.2.4"><ci id="S5.E5.m1.3.3.1.1.cmml" xref="S5.E5.m1.3.3.1.1">ℳ</ci><ci id="S5.E5.m1.4.4.2.2.cmml" xref="S5.E5.m1.4.4.2.2">𝒬</ci></list></apply></apply><apply id="S5.E5.m1.7.7.1.1.3.cmml" xref="S5.E5.m1.7.7.1.1.3"><csymbol cd="ambiguous" id="S5.E5.m1.7.7.1.1.3.1.cmml" xref="S5.E5.m1.7.7.1.1.3">subscript</csymbol><ci id="S5.E5.m1.7.7.1.1.3.2.cmml" xref="S5.E5.m1.7.7.1.1.3.2">ℒ</ci><list id="S5.E5.m1.6.6.2.3.cmml" xref="S5.E5.m1.6.6.2.4"><ci id="S5.E5.m1.5.5.1.1.cmml" xref="S5.E5.m1.5.5.1.1">ℳ</ci><ci id="S5.E5.m1.6.6.2.2.cmml" xref="S5.E5.m1.6.6.2.2">𝒬</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E5.m1.7c">(\mathcal{L}_{\mathcal{M^{\prime}},\mathcal{Q}}-\mathcal{L}_{\mathcal{M},\mathcal{Q}})/{\mathcal{L}_{\mathcal{M},\mathcal{Q}}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.p7.2">여기서, <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.p7.1.m1.1"><semantics id="S5.p7.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S5.p7.1.m1.1.1" xref="S5.p7.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S5.p7.1.m1.1b"><ci id="S5.p7.1.m1.1.1.cmml" xref="S5.p7.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p7.1.m1.1c">\mathcal{M}</annotation></semantics></math>는 기본 모델이고, <math alttext="\mathcal{M^{\prime}}" class="ltx_Math" display="inline" id="S5.p7.2.m2.1"><semantics id="S5.p7.2.m2.1a"><msup id="S5.p7.2.m2.1.1" xref="S5.p7.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.p7.2.m2.1.1.2" xref="S5.p7.2.m2.1.1.2.cmml">ℳ</mi><mo id="S5.p7.2.m2.1.1.3" xref="S5.p7.2.m2.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S5.p7.2.m2.1b"><apply id="S5.p7.2.m2.1.1.cmml" xref="S5.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S5.p7.2.m2.1.1.1.cmml" xref="S5.p7.2.m2.1.1">superscript</csymbol><ci id="S5.p7.2.m2.1.1.2.cmml" xref="S5.p7.2.m2.1.1.2">ℳ</ci><ci id="S5.p7.2.m2.1.1.3.cmml" xref="S5.p7.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p7.2.m2.1c">\mathcal{M^{\prime}}</annotation></semantics></math>는 지식 주입 모델이며, <a class="ltx_ref" href="#S5.F2" title="In 5 Experiments and Results ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">2</span></a>에 나타낸다.</p>
</div>
<div id="S5.p8" class="ltx_para">
<p class="ltx_p" id="S5.p8.1">모든 경우에 RAG는 기본 모델에 비해 훨씬 더 나은 성능을 보였다. 또한, 기본 모델과 함께 RAG를 생성기로 사용하는 것이 미세 조정보다 일관되게 더 우수했다. 어떤 경우에는 RAG 파이프라인에서 생성기로 기본 모델 대신 미세 조정된 모델을 사용하여 결과를 훨씬 더 개선했다. 그러나 이는 일관되지 않으므로 미세 조정의 고유한 불안정성을 보여준다. 또한, 우리는 5-shot 접근법이 대부분의 경우 작은 마진만큼 결과를 향상시키며, 모든 다른 접근법에서 유사한 경향이 관찰된다는 것을 발견했다.</p>
</div>
<div id="S5.p9" class="ltx_para">
<p class="ltx_p" id="S5.p9.1"><span class="ltx_text ltx_font_bold" id="S5.p9.1.1">Current Events Results</span>  현재 이벤트 태스크에 대한 평가는 <a class="ltx_ref" href="#S4.T2" title="In 4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">2</span></a>에 나와 있다. RAG는 질문과 보조 데이터세트 사이의 일대일 대응으로 인해 특히 효과적인 것으로 입증된다(<a class="ltx_ref" href="#S4.SS3" title="4.3 Current Events Task Creation ‣ 4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">4.3</span></a> 참조). 미세 조정은 RAG와 경쟁력이 없습니다. 그러나 여러 패러프레이즈를 사용한 미세 조정은 여전히 기준선에 비해 상당한 개선을 제공한다. 우리는 RAG와 미세 조정을 결합하는 것이 RAG 단독에 비해 열등한 성능을 나타낸다는 점에 주목한다.</p>
</div>
<div id="S5.p10" class="ltx_para">
<p class="ltx_p" id="S5.p10.1">질문이 훈련 중에 모델이 노출되지 않은 정보를 기반으로 하지만 기본 모델의 결과는 <math alttext="\frac{1}{L}=0.25" class="ltx_Math" display="inline" id="S5.p10.1.m1.1"><semantics id="S5.p10.1.m1.1a"><mrow id="S5.p10.1.m1.1.1" xref="S5.p10.1.m1.1.1.cmml"><mfrac id="S5.p10.1.m1.1.1.2" xref="S5.p10.1.m1.1.1.2.cmml"><mn id="S5.p10.1.m1.1.1.2.2" xref="S5.p10.1.m1.1.1.2.2.cmml">1</mn><mi id="S5.p10.1.m1.1.1.2.3" xref="S5.p10.1.m1.1.1.2.3.cmml">L</mi></mfrac><mo id="S5.p10.1.m1.1.1.1" xref="S5.p10.1.m1.1.1.1.cmml">=</mo><mn id="S5.p10.1.m1.1.1.3" xref="S5.p10.1.m1.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p10.1.m1.1b"><apply id="S5.p10.1.m1.1.1.cmml" xref="S5.p10.1.m1.1.1"><eq id="S5.p10.1.m1.1.1.1.cmml" xref="S5.p10.1.m1.1.1.1"></eq><apply id="S5.p10.1.m1.1.1.2.cmml" xref="S5.p10.1.m1.1.1.2"><divide id="S5.p10.1.m1.1.1.2.1.cmml" xref="S5.p10.1.m1.1.1.2"></divide><cn id="S5.p10.1.m1.1.1.2.2.cmml" type="integer" xref="S5.p10.1.m1.1.1.2.2">1</cn><ci id="S5.p10.1.m1.1.1.2.3.cmml" xref="S5.p10.1.m1.1.1.2.3">𝐿</ci></apply><cn id="S5.p10.1.m1.1.1.3.cmml" type="float" xref="S5.p10.1.m1.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p10.1.m1.1c">\frac{1}{L}=0.25</annotation></semantics></math>를 능가한다는 점에 주목할 필요가 있다. 이는 과거 정보와 독립적이지 않은 질문에 답할 때 추론 및/또는 기존 지식을 사용하는 모델에 의해 부분적으로 설명될 수 있다. 이에 대한 몇 가지 예는 <a class="ltx_ref" href="#A3" title="Appendix C Current Events Existing Knowledge Examples ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">C</span></a>에서 찾을 수 있다.</p>
</div>
<div id="S5.p11" class="ltx_para">
<p class="ltx_p" id="S5.p11.1"><span class="ltx_text ltx_font_bold" id="S5.p11.1.1">Fine-Tuning vs. RAG:</span> MMLU 및 현재 이벤트 태스크 모두의 결과에서 미세 조정보다 RAG에 대한 상당한 이점이 분명합니다. 미세 조정은 대부분의 경우 기본 모델에 비해 결과가 향상되었지만 RAG 접근법과는 경쟁력이 없었다.</p>
</div>
<div id="S5.p12" class="ltx_para">
<p class="ltx_p" id="S5.p12.1">이 행동에 몇 가지 요인이 기여할 수 있다. 첫째, RAG는 모델에 지식을 추가할 뿐만 아니라 미세 조정에 부족한 특징인 질문과 관련된 컨텍스트를 통합한다. 또한, 미세 조정은 어느 정도의 치명적인 망각으로 인해 모델의 다른 기능에 영향을 미칠 수 있다. 마지막으로, 감독되지 않은 미세 조정 모델은 기본 Llama2에 대한 Orca2의 크게 개선된 성능에 의해 입증된 바와 같이 감독 또는 RL 기반 미세 조정을 통해 추가 정렬의 이점을 얻을 수 있다.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>The Importance of Repetition</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p" id="S6.p1.1">모델이 사전 훈련 중에 토픽과 관련된 측면에 노출된 다른 작업과 달리 <span class="ltx_text ltx_font_italic" id="S6.p1.1.1">current events</span>은 새 정보를 포함합니다. 이 경우 표준 정기 미세 조정은 Llama2의 성능을 향상시키지 못했을 뿐만 아니라 크게 저하시켰다. 미세 조정 결과를 개선하기 위해 패러프레이즈를 사용하여 데이터의 증강을 조사했다.</p>
</div>
<figure id="S6.F3" class="ltx_figure">
<p id="S6.F3.1.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S6.F3.1.1.1" class="ltx_text"><img src="https://ar5iv.labs.arxiv.org/html/2312.05934/assets/media/loss_curve.png" id="S6.F3.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="393" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F3.3.1.1" style="font-size:90%;">Figure 3</span>:</span><span class="ltx_text" id="S6.F3.4.2" style="font-size:90%;">Training loss over time for Mistral-7B. </span></figcaption>
</figure>
<figure id="S6.F4" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2312.05934/assets/media/paraphrases_plot.png" id="S6.F4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="416" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.3.1.1" style="font-size:90%;">그림 4</span>:</span><span class="ltx_text" id="S6.F4.4.2" style="font-size:90%;"><span class="ltx_text ltx_font_italic" id="S6.F4.4.2.1">current events</span> task as a function of the number of paraphrases. </span></figcaption>
</figure>
<div id="S6.p2" class="ltx_para">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_bold" id="S6.p2.1.1">Data Augmentation</span> Data augmentation은 언어 모델의 성능을 향상시키기 위한 잘 확립된 방법이며 광범위하게 조사되었다. <cite class="ltx_cite ltx_citemacro_citep">(Shorten et al., <a class="ltx_ref" href="#bib.bib38" title="">2021</a>)</cite> 증강에 생성 모델을 사용하는 것은 또한 과거 <cite class="ltx_cite ltx_citemacro_citep">(Sharma et al., <a class="ltx_ref" href="#bib.bib37" title="">2022</a>)</cite>에서 분류 모델을 개선하는 데 성공적으로 사용되었다. 패러프레이징을 이용한 데이터 증강의 예는 <a class="ltx_ref" href="#A2" title="Appendix B Paraphrase Examples ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Appendix</span> <span class="ltx_text ltx_ref_tag">B</span></a> 에서 찾을 수 있다.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p class="ltx_p" id="S6.p3.1"><span class="ltx_text ltx_font_bold" id="S6.p3.1.1">Monotonic Improvement</span> 이 접근법은 사용된 패러프레이즈의 수와 모델의 정확도 사이의 직접적인 상관 관계를 보여줌으로써 결과에서 주목할만한 개선을 가져왔다. 우리의 실험은 <a class="ltx_ref" href="#S6.F4" title="In 6 The Importance of Repetition ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">4</span></a>에 나타난 강력한 경향을 보여주었다. 테스트한 모든 모델에 대해 정확도는 사용된 패러프레이즈 수의 단조 증가 함수였다. 이 관찰은 제한된 데이터에서 새로운 지식을 이해하고 일반화하는 모델의 능력에 대한 정보 반복을 산출하는 패러프레이즈 확대의 긍정적인 영향을 강력하게 시사한다.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p class="ltx_p" id="S6.p4.1"><span class="ltx_text ltx_font_bold" id="S6.p4.1.1">Learning New Information</span> In <a class="ltx_ref" href="#S6.F3" title="In 6 The Importance of Repetition ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Figure</span> <span class="ltx_text ltx_ref_tag">3</span></a> 실험 전반에 걸쳐 관찰된 흥미로운 현상을 볼 수 있다. 각 에포크, 즉 전체 데이터 세트에 걸쳐 또 다른 반복을 완료한 후, 트레이닝 손실은 상당히 떨어진다. 이는 학습 중 데이터를 암기하고 과적합하는 LLM에 대해 알려진 것과 일치한다. <cite class="ltx_cite ltx_citemacro_citep">(Tirumala et al., <a class="ltx_ref" href="#bib.bib44" title="">2022</a>)</cite></p>
</div>
<div id="S6.p5" class="ltx_para">
<p class="ltx_p" id="S6.p5.1">우리의 가설은 다음과 같다:</p>
<blockquote id="S6.p5.2" class="ltx_quote">
<p class="ltx_p" id="S6.p5.2.1">사전 훈련된 LLMs <span class="ltx_text ltx_font_bold" id="S6.p5.2.1.1">new</span> 지식을 가르치기 위해서는 여러 가지 방법으로 지식을 반복해야 한다.</p>
</blockquote>
</div>
<div id="S6.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.p6.2">이는 LLM 사전 훈련 <cite class="ltx_cite ltx_citemacro_citep">(Kandpal et al., <a class="ltx_ref" href="#bib.bib17" title="">2023</a>)</cite>에 대해 잘 알려져 있으며, 이 경우 미세 조정에도 해당된다는 것을 알 수 있다. 이 가설의 근거는 <cite class="ltx_cite ltx_citemacro_citep">(Berglund et al., <a class="ltx_ref" href="#bib.bib2" title="">2023</a>)</cite>에서 이미 보여졌듯이 문장에 대한 단순한 암기는 그 내용에 대한 지식을 수반하지 않는다는 것이다. (우리가 사용한 데이터 증강 프로세스와 같은) 수많은 형태로 정보를 제공함으로써, 데이터의 다양한 관계(예: <math alttext="a\implies b,\&gt;b\hbox to0.0pt{$\quad\not$\hss}\implies c" class="ltx_Math" display="inline" id="S6.p6.1.m1.3"><semantics id="S6.p6.1.m1.3a"><mrow id="S6.p6.1.m1.3.3.2" xref="S6.p6.1.m1.3.3.3.cmml"><mrow id="S6.p6.1.m1.2.2.1.1" xref="S6.p6.1.m1.2.2.1.1.cmml"><mi id="S6.p6.1.m1.2.2.1.1.2" xref="S6.p6.1.m1.2.2.1.1.2.cmml">a</mi><mo id="S6.p6.1.m1.2.2.1.1.1" stretchy="false" xref="S6.p6.1.m1.2.2.1.1.1.cmml">⟹</mo><mi id="S6.p6.1.m1.2.2.1.1.3" xref="S6.p6.1.m1.2.2.1.1.3.cmml">b</mi></mrow><mo id="S6.p6.1.m1.3.3.2.3" rspace="0.387em" xref="S6.p6.1.m1.3.3.3a.cmml">,</mo><mrow id="S6.p6.1.m1.3.3.2.2" xref="S6.p6.1.m1.3.3.2.2.cmml"><mrow id="S6.p6.1.m1.3.3.2.2.2" xref="S6.p6.1.m1.3.3.2.2.2.cmml"><mi id="S6.p6.1.m1.3.3.2.2.2.2" xref="S6.p6.1.m1.3.3.2.2.2.2.cmml">b</mi><mo id="S6.p6.1.m1.3.3.2.2.2.1" lspace="1.167em" rspace="0em" xref="S6.p6.1.m1.3.3.2.2.2.1.cmml">​</mo><mpadded id="S6.p6.1.m1.1.1.1" width="0.0pt" xref="S6.p6.1.m1.1.1.1.cmml"><mi id="S6.p6.1.m1.1.1.1a" mathvariant="normal" xref="S6.p6.1.m1.1.1.1.cmml">／</mi></mpadded></mrow><mo id="S6.p6.1.m1.3.3.2.2.1" stretchy="false" xref="S6.p6.1.m1.3.3.2.2.1.cmml">⟹</mo><mi id="S6.p6.1.m1.3.3.2.2.3" xref="S6.p6.1.m1.3.3.2.2.3.cmml">c</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.p6.1.m1.3b"><apply id="S6.p6.1.m1.3.3.3.cmml" xref="S6.p6.1.m1.3.3.2"><csymbol cd="ambiguous" id="S6.p6.1.m1.3.3.3a.cmml" xref="S6.p6.1.m1.3.3.2.3">formulae-sequence</csymbol><apply id="S6.p6.1.m1.2.2.1.1.cmml" xref="S6.p6.1.m1.2.2.1.1"><implies id="S6.p6.1.m1.2.2.1.1.1.cmml" xref="S6.p6.1.m1.2.2.1.1.1"></implies><ci id="S6.p6.1.m1.2.2.1.1.2.cmml" xref="S6.p6.1.m1.2.2.1.1.2">𝑎</ci><ci id="S6.p6.1.m1.2.2.1.1.3.cmml" xref="S6.p6.1.m1.2.2.1.1.3">𝑏</ci></apply><apply id="S6.p6.1.m1.3.3.2.2.cmml" xref="S6.p6.1.m1.3.3.2.2"><implies id="S6.p6.1.m1.3.3.2.2.1.cmml" xref="S6.p6.1.m1.3.3.2.2.1"></implies><apply id="S6.p6.1.m1.3.3.2.2.2.cmml" xref="S6.p6.1.m1.3.3.2.2.2"><times id="S6.p6.1.m1.3.3.2.2.2.1.cmml" xref="S6.p6.1.m1.3.3.2.2.2.1"></times><ci id="S6.p6.1.m1.3.3.2.2.2.2.cmml" xref="S6.p6.1.m1.3.3.2.2.2.2">𝑏</ci><not id="S6.p6.1.m1.1.1.1.cmml" xref="S6.p6.1.m1.1.1.1"></not></apply><ci id="S6.p6.1.m1.3.3.2.2.3.cmml" xref="S6.p6.1.m1.3.3.2.2.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.1.m1.3c">a\implies b,\&gt;b\hbox to0.0pt{$\quad\not$\hss}\implies c</annotation></semantics></math>)가 자연스럽게 나타날 가능성이 더 높다. 우리는 이것이 잠재적으로 일반적으로 <math alttext="\mathcal{L}_{\mathcal{M},\mathcal{Q}}" class="ltx_Math" display="inline" id="S6.p6.2.m2.2"><semantics id="S6.p6.2.m2.2a"><msub id="S6.p6.2.m2.2.3" xref="S6.p6.2.m2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S6.p6.2.m2.2.3.2" xref="S6.p6.2.m2.2.3.2.cmml">ℒ</mi><mrow id="S6.p6.2.m2.2.2.2.4" xref="S6.p6.2.m2.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S6.p6.2.m2.1.1.1.1" xref="S6.p6.2.m2.1.1.1.1.cmml">ℳ</mi><mo id="S6.p6.2.m2.2.2.2.4.1" xref="S6.p6.2.m2.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S6.p6.2.m2.2.2.2.2" xref="S6.p6.2.m2.2.2.2.2.cmml">𝒬</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S6.p6.2.m2.2b"><apply id="S6.p6.2.m2.2.3.cmml" xref="S6.p6.2.m2.2.3"><csymbol cd="ambiguous" id="S6.p6.2.m2.2.3.1.cmml" xref="S6.p6.2.m2.2.3">subscript</csymbol><ci id="S6.p6.2.m2.2.3.2.cmml" xref="S6.p6.2.m2.2.3.2">ℒ</ci><list id="S6.p6.2.m2.2.2.2.3.cmml" xref="S6.p6.2.m2.2.2.2.4"><ci id="S6.p6.2.m2.1.1.1.1.cmml" xref="S6.p6.2.m2.1.1.1.1">ℳ</ci><ci id="S6.p6.2.m2.2.2.2.2.cmml" xref="S6.p6.2.m2.2.2.2.2">𝒬</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.2.m2.2c">\mathcal{L}_{\mathcal{M},\mathcal{Q}}</annotation></semantics></math>를 증가시킬 수 있을 뿐만 아니라 Berglund 등의 <span class="ltx_text ltx_font_italic" id="S6.p6.2.1">Reversal Curse</span>을 개선할 수 있다고 믿는다. 이 결과는 유망하지만 여전히 추가 연구가 필요하다.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion and Future Work</h2>

<div id="S7.p1" class="ltx_para">
<p class="ltx_p" id="S7.p1.1">대형 언어 모델은 다양한 주제에 대한 방대한 양의 지식을 보유하고 있다. 이 작업에서 우리는 전문화된 지식과 전혀 보이지 않는 새로운 지식에 적응하는 능력을 테스트했다. 이것은 이 영역에서 두 가지 두드러진 접근법, 즉 미세 조정 및 검색 증강 생성을 비교한 첫 번째 연구 중 하나이다. 미세 조정은 많은 사용 사례에 유용할 수 있지만 RAG가 지식 주입에 더 신뢰할 수 있는 선택임을 발견했다.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p class="ltx_p" id="S7.p2.1">이 작업의 일부 측면은 여전히 추가 연구가 필요하다. 예를 들어, 우리는 지도 조정 또는 RL 기반 방법과 달리 1차 미세 조정 방법으로 감독되지 않은 훈련에 중점을 두었다. 다양한 보조 지식 기반과 다양한 기술의 조합을 연구하면 개선된 결과를 얻을 수 있다. 이 접근법은 <a class="ltx_ref" href="#S6" title="6 The Importance of Repetition ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">6</span></a>의 가설과 결합하여 FT를 통한 지식 주입에 대한 이해를 더욱 향상시킬 수 있다.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p class="ltx_p" id="S7.p3.1">우리는 이 작업이 LLM에 대한 지식에 대한 이해를 더욱 향상시킨다고 생각하지만, 이 분야에서 해야 할 일이 훨씬 더 많다. 특히 이론적인 관점에서 LLMs에서 지식 표상의 문제와 관련하여 더 많은 연구가 필요하다.</p>
</div>
<div id="S7.p4" class="ltx_para">
<p class="ltx_p" id="S7.p4.1">마지막으로 LLM에서 지식을 측정하기 위한 추가 노력이 필요하다. <a class="ltx_ref" href="#S2.E2" title="In 2 Background ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Equation</span> <span class="ltx_text ltx_ref_tag">2</span></a>에 설명된 경험적 접근법을 사용했지만, 지식에 대한 다른 정의와 관점도 탐색하고 이 작업을 확장하는 것이 중요하다.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Limitations</h2>

<div id="S8.p1" class="ltx_para">
<p class="ltx_p" id="S8.p1.1">모든 기계 학습 애플리케이션에서와 같이 하이퍼파라미터의 선택은 결과에 상당한 영향을 미친다. 따라서 특정 사례에 대해 모든 관련 하이퍼 매개 변수를 최적화하는 것이 좋습니다.</p>
</div>
<div id="S8.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S8.p2.1">우리는 세 가지 다른 모델에 대한 실험을 실행함으로써 우리의 주장을 지지했습니다. 그러나 다른 LLM에 대한 일반화는 철저히 테스트되어야 한다. 예를 들어 GPT-4는 일부 MMLU 작업 <cite class="ltx_cite ltx_citemacro_citep">(Nori et al., <a class="ltx_ref" href="#bib.bib29" title="">2023</a>)</cite>에 대해 거의 완벽한 정확도를 달성하므로 추가 개선은 적용할 수 없다.</p>
</div>
<div id="S8.p3" class="ltx_para">
<p class="ltx_p" id="S8.p3.1">마지막으로 지식 베이스를 위한 다양한 주제를 선택하는 동안 모든 출처는 위키피디아에서 나왔다. 다른 데이터 세트는 다른 결과를 산출할 수 있으므로 신중하게 평가해야 한다.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Attardi (2015)</span>
<span class="ltx_bibblock">
Attardi, G.

</span>
<span class="ltx_bibblock">Wikiextractor.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/attardi/wikiextractor" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/attardi/wikiextractor</a>, 2015.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berglund et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Berglund, L., Tong, M., Kaufmann, M., Balesni, M., Stickland, A.&nbsp;C., Korbak, T., and Evans, O.

</span>
<span class="ltx_bibblock">The reversal curse: Llms trained on” a is b” fail to learn” b is a”.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.12288</em>, 2023.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Chen, S., Hou, Y., Cui, Y., Che, W., Liu, T., and Yu, X.

</span>
<span class="ltx_bibblock">Recall and learn: Fine-tuning deep pretrained language models with less forgetting.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.12651</em>, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Chen, X., Zhang, N., Xie, X., Deng, S., Yao, Y., Tan, C., Huang, F., Si, L., and Chen, H.

</span>
<span class="ltx_bibblock">Knowprompt: Knowledge-aware prompt-tuning with synergistic optimization for relation extraction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM Web conference 2022</em>, pp.&nbsp; 2778–2788, 2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Chen, Y., Zhong, R., Zha, S., Karypis, G., and He, H.

</span>
<span class="ltx_bibblock">Meta-learning via language model in-context tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.07814</em>, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chia et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chia, Y.&nbsp;K., Hong, P., Bing, L., and Poria, S.

</span>
<span class="ltx_bibblock">Instructeval: Towards holistic evaluation of instruction-tuned large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.04757</em>, 2023.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Chung, H.&nbsp;W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y., Wang, X., Dehghani, M., Brahma, S., et&nbsp;al.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.11416</em>, 2022.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cohen et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Cohen, R., Geva, M., Berant, J., and Globerson, A.

</span>
<span class="ltx_bibblock">Crawling the internal knowledge-base of language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.12810</em>, 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Dua, D., Wang, Y., Dasigi, P., Stanovsky, G., Singh, S., and Gardner, M.

</span>
<span class="ltx_bibblock">Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1903.00161</em>, 2019.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Gao, L., Tow, J., Biderman, S., Black, S., DiPofi, A., Foster, C., Golding, L., Hsu, J., McDonell, K., Muennighoff, N., Phang, J., Reynolds, L., Tang, E., Thite, A., Wang, B., Wang, K., and Zou, A.

</span>
<span class="ltx_bibblock">A framework for few-shot language model evaluation, September 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.5281/zenodo.5371628" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.5281/zenodo.5371628</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et&nbsp;al. (2013)</span>
<span class="ltx_bibblock">
Goodfellow, I.&nbsp;J., Mirza, M., Xiao, D., Courville, A., and Bengio, Y.

</span>
<span class="ltx_bibblock">An empirical investigation of catastrophic forgetting in gradient-based neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1312.6211</em>, 2013.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the International Conference on Learning Representations (ICLR)</em>, 2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., and Li, J.

</span>
<span class="ltx_bibblock">A survey of knowledge enhanced pre-trained language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em>, 2023.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Huang, Q., Tao, M., An, Z., Zhang, C., Jiang, C., Chen, Z., Wu, Z., and Feng, Y.

</span>
<span class="ltx_bibblock">Lawyer llama technical report.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.15062</em>, 2023.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Jiang, A.&nbsp;Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D.&nbsp;S., Casas, D. d.&nbsp;l., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., et&nbsp;al.

</span>
<span class="ltx_bibblock">Mistral 7b.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.06825</em>, 2023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Johnson, J., Douze, M., and Jégou, H.

</span>
<span class="ltx_bibblock">Billion-scale similarity search with GPUs.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em>, 7(3):535–547, 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kandpal et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Kandpal, N., Deng, H., Roberts, A., Wallace, E., and Raffel, C.

</span>
<span class="ltx_bibblock">Large language models struggle to learn long-tail knowledge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pp.&nbsp; 15696–15707. PMLR, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirkpatrick et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A.&nbsp;A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et&nbsp;al.

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting in neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the national academy of sciences</em>, 114(13):3521–3526, 2017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lampinen et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Lampinen, A.&nbsp;K., Dasgupta, I., Chan, S.&nbsp;C., Matthewson, K., Tessler, M.&nbsp;H., Creswell, A., McClelland, J.&nbsp;L., Wang, J.&nbsp;X., and Hill, F.

</span>
<span class="ltx_bibblock">Can language models learn from explanations in context?

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.02329</em>, 2022.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lauscher et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Lauscher, A., Majewska, O., Ribeiro, L.&nbsp;F., Gurevych, I., Rozanov, N., and Glavaš, G.

</span>
<span class="ltx_bibblock">Common sense or world knowledge? investigating adapter-based knowledge injection into pretrained transformers.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.11787</em>, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., Yih, W.-t., Rocktäschel, T., et&nbsp;al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 33:9459–9474, 2020.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Liu, W., Zhou, P., Zhao, Z., Wang, Z., Ju, Q., Deng, H., and Wang, P.

</span>
<span class="ltx_bibblock">K-bert: Enabling language representation with knowledge graph.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume&nbsp;34, pp.&nbsp; 2901–2908, 2020.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Luo, Y., Yang, Z., Meng, F., Li, Y., Zhou, J., and Zhang, Y.

</span>
<span class="ltx_bibblock">An empirical study of catastrophic forgetting in large language models during continual fine-tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.08747</em>, 2023.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Min, S., Lewis, M., Zettlemoyer, L., and Hajishirzi, H.

</span>
<span class="ltx_bibblock">Metaicl: Learning to learn in context.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.15943</em>, 2021.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Mishra, S., Khashabi, D., Baral, C., and Hajishirzi, H.

</span>
<span class="ltx_bibblock">Cross-task generalization via natural language crowdsourcing instructions.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.08773</em>, 2021.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitra et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Mitra, A., Del&nbsp;Corro, L., Mahajan, S., Codas, A., Simoes, C., Agrawal, S., Chen, X., Razdaibiedina, A., Jones, E., Aggarwal, K., et&nbsp;al.

</span>
<span class="ltx_bibblock">Orca 2: Teaching small language models how to reason.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.11045</em>, 2023.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neelakantan et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Neelakantan, A., Xu, T., Puri, R., Radford, A., Han, J.&nbsp;M., Tworek, J., Yuan, Q., Tezak, N.&nbsp;A., Kim, J.&nbsp;W., Hallacy, C., Heidecke, J., Shyam, P., Power, B., Nekoul, T.&nbsp;E., Sastry, G., Krueger, G., Schnurr, D.&nbsp;P., Such, F.&nbsp;P., Hsu, K. S.-K., Thompson, M., Khan, T., Sherbakov, T., Jang, J., Welinder, P., and Weng, L.

</span>
<span class="ltx_bibblock">Text and code embeddings by contrastive pre-training.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2201.10005, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:246275593" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:246275593</a>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen (2023)</span>
<span class="ltx_bibblock">
Nguyen, H.-T.

</span>
<span class="ltx_bibblock">A brief report on lawgpt 1.0: A virtual legal assistant based on gpt-3.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.05729</em>, 2023.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nori et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Nori, H., King, N., McKinney, S.&nbsp;M., Carignan, D., and Horvitz, E.

</span>
<span class="ltx_bibblock">Capabilities of gpt-4 on medical challenge problems.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2303.13375, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:257687695" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:257687695</a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2303.08774, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:257532815" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:257532815</a>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et&nbsp;al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 35:27730–27744, 2022.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Petroni, F., Rocktäschel, T., Lewis, P., Bakhtin, A., Wu, Y., Miller, A.&nbsp;H., and Riedel, S.

</span>
<span class="ltx_bibblock">Language models as knowledge bases?

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.01066</em>, 2019.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et&nbsp;al.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">OpenAI blog</em>, 1(8):9, 2019.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rafailov, R., Sharma, A., Mitchell, E., Ermon, S., Manning, C.&nbsp;D., and Finn, C.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.18290</em>, 2023.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sakaguchi et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Sakaguchi, K., Bras, R.&nbsp;L., Bhagavatula, C., and Choi, Y.

</span>
<span class="ltx_bibblock">Winogrande: An adversarial winograd schema challenge at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Communications of the ACM</em>, 64(9):99–106, 2021.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schulman et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.

</span>
<span class="ltx_bibblock">Proximal policy optimization algorithms.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1707.06347</em>, 2017.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sharma et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Sharma, S., Joshi, A., Mukhija, N., Zhao, Y., Bhathena, H., Singh, P., Santhanam, S., and Biswas, P.

</span>
<span class="ltx_bibblock">Systematic review of effect of data augmentation using paraphrasing on named entity recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research</em>, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=rc2h1h89aDi" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=rc2h1h89aDi</a>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shorten et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Shorten, C., Khoshgoftaar, T.&nbsp;M., and Furht, B.

</span>
<span class="ltx_bibblock">Text data augmentation for deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Journal of Big Data</em>, 8, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:236096559" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:236096559</a>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singhal et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Singhal, K., Azizi, S., Tu, T., Mahdavi, S.&nbsp;S., Wei, J., Chung, H.&nbsp;W., Scales, N., Tanwani, A., Cole-Lewis, H., Pfohl, S., et&nbsp;al.

</span>
<span class="ltx_bibblock">Large language models encode clinical knowledge.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Nature</em>, 620(7972):172–180, 2023a.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singhal et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Singhal, K., Tu, T., Gottweis, J., Sayres, R., Wulczyn, E., Hou, L., Clark, K., Pfohl, S., Cole-Lewis, H., Neal, D., et&nbsp;al.

</span>
<span class="ltx_bibblock">Towards expert-level medical question answering with large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.09617</em>, 2023b.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Srivastava, A., Rastogi, A., Rao, A., Shoeb, A. A.&nbsp;M., Abid, A., Fisch, A., Brown, A.&nbsp;R., Santoro, A., Gupta, A., Garriga-Alonso, A., et&nbsp;al.

</span>
<span class="ltx_bibblock">Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.04615</em>, 2022.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tan, Y., Min, D., Li, Y., Li, W., Hu, N., Chen, Y., and Qi, G.

</span>
<span class="ltx_bibblock">Can chatgpt replace traditional kbqa models? an in-depth analysis of the question answering performance of the gpt llm family.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">International Semantic Web Conference</em>, pp.&nbsp; 348–367. Springer, 2023.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li, X., Guestrin, C., Liang, P., and Hashimoto, T.&nbsp;B.

</span>
<span class="ltx_bibblock">Alpaca: A strong, replicable instruction-following model.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Stanford Center for Research on Foundation Models. https://crfm. stanford. edu/2023/03/13/alpaca. html</em>, 3(6):7, 2023.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tirumala et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Tirumala, K., Markosyan, A.&nbsp;H., Zettlemoyer, L., and Aghajanyan, A.

</span>
<span class="ltx_bibblock">Memorization without overfitting: Analyzing the training dynamics of large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2205.10770, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:248986465" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:248986465</a>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.09288</em>, 2023.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tunstall et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tunstall, L., Beeching, E., Lambert, N., Rajani, N., Rasul, K., Belkada, Y., Huang, S., von Werra, L., Fourrier, C., Habib, N., et&nbsp;al.

</span>
<span class="ltx_bibblock">Zephyr: Direct distillation of lm alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.16944</em>, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Wang, C., Liu, X., Yue, Y., Tang, X., Zhang, T., Jiayang, C., Yao, Y., Gao, W., Hu, X., Qi, Z., et&nbsp;al.

</span>
<span class="ltx_bibblock">Survey on factuality in large language models: Knowledge, retrieval and domain-specificity.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.07521</em>, 2023.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Wang, R., Tang, D., Duan, N., Wei, Z., Huang, X., Cao, G., Jiang, D., Zhou, M., et&nbsp;al.

</span>
<span class="ltx_bibblock">K-adapter: Infusing knowledge into pre-trained models with adapters.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.01808</em>, 2020.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Wang, Y., Mishra, S., Alipoormolabashi, P., Kordi, Y., Mirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran, A.&nbsp;S., Naik, A., Stap, D., et&nbsp;al.

</span>
<span class="ltx_bibblock">Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.07705</em>, 2022.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Wu, C., Zhang, X., Zhang, Y., Wang, Y., and Xie, W.

</span>
<span class="ltx_bibblock">Pmc-llama: Further finetuning llama on medical papers.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.14454</em>, 2023a.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Wu, S., Irsoy, O., Lu, S., Dabravolski, V., Dredze, M., Gehrmann, S., Kambadur, P., Rosenberg, D., and Mann, G.

</span>
<span class="ltx_bibblock">Bloomberggpt: A large language model for finance.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.17564</em>, 2023b.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Xiao, S., Liu, Z., Zhang, P., and Muennighoff, N.

</span>
<span class="ltx_bibblock">C-pack: Packaged resources to advance general chinese embedding, 2023.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yang, H., Liu, X.-Y., and Wang, C.&nbsp;D.

</span>
<span class="ltx_bibblock">Fingpt: Open-source financial large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.06031</em>, 2023.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yu, W., Zhu, C., Li, Z., Hu, Z., Wang, Q., Ji, H., and Jiang, M.

</span>
<span class="ltx_bibblock">A survey of knowledge-enhanced text generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys</em>, 54(11s):1–38, 2022.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhou, C., Liu, P., Xu, P., Iyer, S., Sun, J., Mao, Y., Ma, X., Efrat, A., Yu, P., Yu, L., et&nbsp;al.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.11206</em>, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>RAG Ablation Study</h2>

<div id="A1.p1" class="ltx_para">
<p class="ltx_p" id="A1.p1.7"><a class="ltx_ref" href="#S5" title="5 Experiments and Results ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Section</span> <span class="ltx_text ltx_ref_tag">5</span></a>에서 언급한 바와 같이 <a class="ltx_ref" href="#A1.T3" title="In Appendix A RAG Ablation Study ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Table</span> <span class="ltx_text ltx_ref_tag">3</span></a>에 나타난 <math alttext="K\in\{0,\ldots,5\}" class="ltx_Math" display="inline" id="A1.p1.1.m1.3"><semantics id="A1.p1.1.m1.3a"><mrow id="A1.p1.1.m1.3.4" xref="A1.p1.1.m1.3.4.cmml"><mi id="A1.p1.1.m1.3.4.2" xref="A1.p1.1.m1.3.4.2.cmml">K</mi><mo id="A1.p1.1.m1.3.4.1" xref="A1.p1.1.m1.3.4.1.cmml">∈</mo><mrow id="A1.p1.1.m1.3.4.3.2" xref="A1.p1.1.m1.3.4.3.1.cmml"><mo id="A1.p1.1.m1.3.4.3.2.1" stretchy="false" xref="A1.p1.1.m1.3.4.3.1.cmml">{</mo><mn id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml">0</mn><mo id="A1.p1.1.m1.3.4.3.2.2" xref="A1.p1.1.m1.3.4.3.1.cmml">,</mo><mi id="A1.p1.1.m1.2.2" mathvariant="normal" xref="A1.p1.1.m1.2.2.cmml">…</mi><mo id="A1.p1.1.m1.3.4.3.2.3" xref="A1.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="A1.p1.1.m1.3.3" xref="A1.p1.1.m1.3.3.cmml">5</mn><mo id="A1.p1.1.m1.3.4.3.2.4" stretchy="false" xref="A1.p1.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.3b"><apply id="A1.p1.1.m1.3.4.cmml" xref="A1.p1.1.m1.3.4"><in id="A1.p1.1.m1.3.4.1.cmml" xref="A1.p1.1.m1.3.4.1"></in><ci id="A1.p1.1.m1.3.4.2.cmml" xref="A1.p1.1.m1.3.4.2">𝐾</ci><set id="A1.p1.1.m1.3.4.3.1.cmml" xref="A1.p1.1.m1.3.4.3.2"><cn id="A1.p1.1.m1.1.1.cmml" type="integer" xref="A1.p1.1.m1.1.1">0</cn><ci id="A1.p1.1.m1.2.2.cmml" xref="A1.p1.1.m1.2.2">…</ci><cn id="A1.p1.1.m1.3.3.cmml" type="integer" xref="A1.p1.1.m1.3.3">5</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.3c">K\in\{0,\ldots,5\}</annotation></semantics></math>의 다양한 값을 비교하였다. 모델별, <math alttext="K" class="ltx_Math" display="inline" id="A1.p1.2.m2.1"><semantics id="A1.p1.2.m2.1a"><mi id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b"><ci id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">K</annotation></semantics></math>별, <math alttext="0/5" class="ltx_Math" display="inline" id="A1.p1.3.m3.1"><semantics id="A1.p1.3.m3.1a"><mrow id="A1.p1.3.m3.1.1" xref="A1.p1.3.m3.1.1.cmml"><mn id="A1.p1.3.m3.1.1.2" xref="A1.p1.3.m3.1.1.2.cmml">0</mn><mo id="A1.p1.3.m3.1.1.1" xref="A1.p1.3.m3.1.1.1.cmml">/</mo><mn id="A1.p1.3.m3.1.1.3" xref="A1.p1.3.m3.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.3.m3.1b"><apply id="A1.p1.3.m3.1.1.cmml" xref="A1.p1.3.m3.1.1"><divide id="A1.p1.3.m3.1.1.1.cmml" xref="A1.p1.3.m3.1.1.1"></divide><cn id="A1.p1.3.m3.1.1.2.cmml" type="integer" xref="A1.p1.3.m3.1.1.2">0</cn><cn id="A1.p1.3.m3.1.1.3.cmml" type="integer" xref="A1.p1.3.m3.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.3.m3.1c">0/5</annotation></semantics></math>-shot별, 또는 과제별 최적의 값을 찾을 수 없었다. 실제로 <math alttext="K=2" class="ltx_Math" display="inline" id="A1.p1.4.m4.1"><semantics id="A1.p1.4.m4.1a"><mrow id="A1.p1.4.m4.1.1" xref="A1.p1.4.m4.1.1.cmml"><mi id="A1.p1.4.m4.1.1.2" xref="A1.p1.4.m4.1.1.2.cmml">K</mi><mo id="A1.p1.4.m4.1.1.1" xref="A1.p1.4.m4.1.1.1.cmml">=</mo><mn id="A1.p1.4.m4.1.1.3" xref="A1.p1.4.m4.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.4.m4.1b"><apply id="A1.p1.4.m4.1.1.cmml" xref="A1.p1.4.m4.1.1"><eq id="A1.p1.4.m4.1.1.1.cmml" xref="A1.p1.4.m4.1.1.1"></eq><ci id="A1.p1.4.m4.1.1.2.cmml" xref="A1.p1.4.m4.1.1.2">𝐾</ci><cn id="A1.p1.4.m4.1.1.3.cmml" type="integer" xref="A1.p1.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.4.m4.1c">K=2</annotation></semantics></math>와 일관되게 잘 작동한 Anatomy 외에는 다른 셋업에 대해서는 <cite class="ltx_cite ltx_citemacro_citep">(Lewis et al., <a class="ltx_ref" href="#bib.bib21" title="">2020</a>)</cite>에 제시된 결과와 달리 <math alttext="K" class="ltx_Math" display="inline" id="A1.p1.5.m5.1"><semantics id="A1.p1.5.m5.1a"><mi id="A1.p1.5.m5.1.1" xref="A1.p1.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.p1.5.m5.1b"><ci id="A1.p1.5.m5.1.1.cmml" xref="A1.p1.5.m5.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.5.m5.1c">K</annotation></semantics></math> 당 성능을 예측하는 데 도움이 되는 패턴이 없는 것으로 보인다. 더욱이, 최상의 수행 <math alttext="K" class="ltx_Math" display="inline" id="A1.p1.6.m6.1"><semantics id="A1.p1.6.m6.1a"><mi id="A1.p1.6.m6.1.1" xref="A1.p1.6.m6.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.p1.6.m6.1b"><ci id="A1.p1.6.m6.1.1.cmml" xref="A1.p1.6.m6.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.6.m6.1c">K</annotation></semantics></math>s 사이의 갭은 클 수 있다. <br class="ltx_break"/>안타깝게도 이 추가 하이퍼파라미터가 불안정하다는 결론을 내려야 합니다. 이는 실제로 RAG를 사용하는 단점으로 <math alttext="K" class="ltx_Math" display="inline" id="A1.p1.7.m7.1"><semantics id="A1.p1.7.m7.1a"><mi id="A1.p1.7.m7.1.1" xref="A1.p1.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.p1.7.m7.1b"><ci id="A1.p1.7.m7.1.1.cmml" xref="A1.p1.7.m7.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.7.m7.1c">K</annotation></semantics></math>의 선택을 무시할 수 없다.</p>
</div>
<figure id="A1.T3" class="ltx_table">
<table id="A1.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T3.1.1" class="ltx_tr">
<th id="A1.T3.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" rowspan="2"><span id="A1.T3.1.1.2.1" class="ltx_text">Task</span></th>
<th id="A1.T3.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" rowspan="2"><span id="A1.T3.1.1.3.1" class="ltx_text">Model</span></th>
<th id="A1.T3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="5"># Retrieved documents (<math id="A1.T3.1.1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A1.T3.1.1.1.m1.1a"><mi id="A1.T3.1.1.1.m1.1.1" xref="A1.T3.1.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.m1.1b"><ci id="A1.T3.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.m1.1c">k</annotation></semantics></math>)</th>
</tr>
<tr id="A1.T3.1.2.1" class="ltx_tr">
<th id="A1.T3.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">1</th>
<th id="A1.T3.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">2</th>
<th id="A1.T3.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">3</th>
<th id="A1.T3.1.2.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">4</th>
<th id="A1.T3.1.2.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">5</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T3.1.3.1" class="ltx_tr">
<th id="A1.T3.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="A1.T3.1.3.1.1.1" class="ltx_text">Anatomy (0-shot)</span></th>
<th id="A1.T3.1.3.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Mistral 7B</th>
<td id="A1.T3.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">0.615</td>
<td id="A1.T3.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.1.3.1.4.1" class="ltx_text ltx_font_bold">0.681</span></td>
<td id="A1.T3.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">0.630</td>
<td id="A1.T3.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">0.644</td>
<td id="A1.T3.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">0.622</td>
</tr>
<tr id="A1.T3.1.4.2" class="ltx_tr">
<th id="A1.T3.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.4.2.2" class="ltx_td ltx_align_center">0.444</td>
<td id="A1.T3.1.4.2.3" class="ltx_td ltx_align_center"><span id="A1.T3.1.4.2.3.1" class="ltx_text ltx_font_bold">0.489</span></td>
<td id="A1.T3.1.4.2.4" class="ltx_td ltx_align_center">0.467</td>
<td id="A1.T3.1.4.2.5" class="ltx_td ltx_align_center">0.474</td>
<td id="A1.T3.1.4.2.6" class="ltx_td ltx_align_center">0.481</td>
</tr>
<tr id="A1.T3.1.5.3" class="ltx_tr">
<th id="A1.T3.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.5.3.2" class="ltx_td ltx_align_center">0.607</td>
<td id="A1.T3.1.5.3.3" class="ltx_td ltx_align_center"><span id="A1.T3.1.5.3.3.1" class="ltx_text ltx_font_bold">0.637</span></td>
<td id="A1.T3.1.5.3.4" class="ltx_td ltx_align_center">0.600</td>
<td id="A1.T3.1.5.3.5" class="ltx_td ltx_align_center">0.585</td>
<td id="A1.T3.1.5.3.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.5.3.6.1" class="ltx_text ltx_font_bold">0.637</span></td>
</tr>
<tr id="A1.T3.1.6.4" class="ltx_tr">
<th id="A1.T3.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="A1.T3.1.6.4.1.1" class="ltx_text">Anatomy (5-shot)</span></th>
<th id="A1.T3.1.6.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Mistral 7B</th>
<td id="A1.T3.1.6.4.3" class="ltx_td ltx_align_center">0.659</td>
<td id="A1.T3.1.6.4.4" class="ltx_td ltx_align_center">0.667</td>
<td id="A1.T3.1.6.4.5" class="ltx_td ltx_align_center">0.659</td>
<td id="A1.T3.1.6.4.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.6.4.6.1" class="ltx_text ltx_font_bold">0.681</span></td>
<td id="A1.T3.1.6.4.7" class="ltx_td ltx_align_center">0.674</td>
</tr>
<tr id="A1.T3.1.7.5" class="ltx_tr">
<th id="A1.T3.1.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.7.5.2" class="ltx_td ltx_align_center">0.496</td>
<td id="A1.T3.1.7.5.3" class="ltx_td ltx_align_center"><span id="A1.T3.1.7.5.3.1" class="ltx_text ltx_font_bold">0.563</span></td>
<td id="A1.T3.1.7.5.4" class="ltx_td ltx_align_center">0.541</td>
<td id="A1.T3.1.7.5.5" class="ltx_td ltx_align_center">0.526</td>
<td id="A1.T3.1.7.5.6" class="ltx_td ltx_align_center">0.526</td>
</tr>
<tr id="A1.T3.1.8.6" class="ltx_tr">
<th id="A1.T3.1.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.8.6.2" class="ltx_td ltx_align_center">0.630</td>
<td id="A1.T3.1.8.6.3" class="ltx_td ltx_align_center"><span id="A1.T3.1.8.6.3.1" class="ltx_text ltx_font_bold">0.659</span></td>
<td id="A1.T3.1.8.6.4" class="ltx_td ltx_align_center">0.600</td>
<td id="A1.T3.1.8.6.5" class="ltx_td ltx_align_center">0.600</td>
<td id="A1.T3.1.8.6.6" class="ltx_td ltx_align_center">0.600</td>
</tr>
<tr id="A1.T3.1.9.7" class="ltx_tr">
<th id="A1.T3.1.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="A1.T3.1.9.7.1.1" class="ltx_text">Astronomy (0-shot)</span></th>
<th id="A1.T3.1.9.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Mistral 7B</th>
<td id="A1.T3.1.9.7.3" class="ltx_td ltx_align_center ltx_border_t">0.651</td>
<td id="A1.T3.1.9.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.1.9.7.4.1" class="ltx_text ltx_font_bold">0.678</span></td>
<td id="A1.T3.1.9.7.5" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.1.9.7.5.1" class="ltx_text ltx_font_bold">0.678</span></td>
<td id="A1.T3.1.9.7.6" class="ltx_td ltx_align_center ltx_border_t">0.664</td>
<td id="A1.T3.1.9.7.7" class="ltx_td ltx_align_center ltx_border_t">0.664</td>
</tr>
<tr id="A1.T3.1.10.8" class="ltx_tr">
<th id="A1.T3.1.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.10.8.2" class="ltx_td ltx_align_center">0.447</td>
<td id="A1.T3.1.10.8.3" class="ltx_td ltx_align_center">0.434</td>
<td id="A1.T3.1.10.8.4" class="ltx_td ltx_align_center">0.447</td>
<td id="A1.T3.1.10.8.5" class="ltx_td ltx_align_center">0.434</td>
<td id="A1.T3.1.10.8.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.10.8.6.1" class="ltx_text ltx_font_bold">0.467</span></td>
</tr>
<tr id="A1.T3.1.11.9" class="ltx_tr">
<th id="A1.T3.1.11.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.11.9.2" class="ltx_td ltx_align_center">0.711</td>
<td id="A1.T3.1.11.9.3" class="ltx_td ltx_align_center">0.730</td>
<td id="A1.T3.1.11.9.4" class="ltx_td ltx_align_center">0.730</td>
<td id="A1.T3.1.11.9.5" class="ltx_td ltx_align_center"><span id="A1.T3.1.11.9.5.1" class="ltx_text ltx_font_bold">0.750</span></td>
<td id="A1.T3.1.11.9.6" class="ltx_td ltx_align_center">0.730</td>
</tr>
<tr id="A1.T3.1.12.10" class="ltx_tr">
<th id="A1.T3.1.12.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="A1.T3.1.12.10.1.1" class="ltx_text">Astronomy (5-shot)</span></th>
<th id="A1.T3.1.12.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Mistral 7B</th>
<td id="A1.T3.1.12.10.3" class="ltx_td ltx_align_center">0.704</td>
<td id="A1.T3.1.12.10.4" class="ltx_td ltx_align_center">0.684</td>
<td id="A1.T3.1.12.10.5" class="ltx_td ltx_align_center">0.658</td>
<td id="A1.T3.1.12.10.6" class="ltx_td ltx_align_center">0.684</td>
<td id="A1.T3.1.12.10.7" class="ltx_td ltx_align_center"><span id="A1.T3.1.12.10.7.1" class="ltx_text ltx_font_bold">0.724</span></td>
</tr>
<tr id="A1.T3.1.13.11" class="ltx_tr">
<th id="A1.T3.1.13.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.13.11.2" class="ltx_td ltx_align_center">0.461</td>
<td id="A1.T3.1.13.11.3" class="ltx_td ltx_align_center">0.447</td>
<td id="A1.T3.1.13.11.4" class="ltx_td ltx_align_center"><span id="A1.T3.1.13.11.4.1" class="ltx_text ltx_font_bold">0.474</span></td>
<td id="A1.T3.1.13.11.5" class="ltx_td ltx_align_center">0.428</td>
<td id="A1.T3.1.13.11.6" class="ltx_td ltx_align_center">0.454</td>
</tr>
<tr id="A1.T3.1.14.12" class="ltx_tr">
<th id="A1.T3.1.14.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.14.12.2" class="ltx_td ltx_align_center">0.730</td>
<td id="A1.T3.1.14.12.3" class="ltx_td ltx_align_center">0.737</td>
<td id="A1.T3.1.14.12.4" class="ltx_td ltx_align_center">0.750</td>
<td id="A1.T3.1.14.12.5" class="ltx_td ltx_align_center">0.743</td>
<td id="A1.T3.1.14.12.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.14.12.6.1" class="ltx_text ltx_font_bold">0.763</span></td>
</tr>
<tr id="A1.T3.1.15.13" class="ltx_tr">
<th id="A1.T3.1.15.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="A1.T3.1.15.13.1.1" class="ltx_text">Biology (0-shot)</span></th>
<th id="A1.T3.1.15.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Mistral 7B</th>
<td id="A1.T3.1.15.13.3" class="ltx_td ltx_align_center ltx_border_t">0.736</td>
<td id="A1.T3.1.15.13.4" class="ltx_td ltx_align_center ltx_border_t">0.722</td>
<td id="A1.T3.1.15.13.5" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.1.15.13.5.1" class="ltx_text ltx_font_bold">0.757</span></td>
<td id="A1.T3.1.15.13.6" class="ltx_td ltx_align_center ltx_border_t">0.743</td>
<td id="A1.T3.1.15.13.7" class="ltx_td ltx_align_center ltx_border_t">0.736</td>
</tr>
<tr id="A1.T3.1.16.14" class="ltx_tr">
<th id="A1.T3.1.16.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.16.14.2" class="ltx_td ltx_align_center">0.438</td>
<td id="A1.T3.1.16.14.3" class="ltx_td ltx_align_center">0.472</td>
<td id="A1.T3.1.16.14.4" class="ltx_td ltx_align_center"><span id="A1.T3.1.16.14.4.1" class="ltx_text ltx_font_bold">0.493</span></td>
<td id="A1.T3.1.16.14.5" class="ltx_td ltx_align_center">0.479</td>
<td id="A1.T3.1.16.14.6" class="ltx_td ltx_align_center">0.472</td>
</tr>
<tr id="A1.T3.1.17.15" class="ltx_tr">
<th id="A1.T3.1.17.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.17.15.2" class="ltx_td ltx_align_center"><span id="A1.T3.1.17.15.2.1" class="ltx_text ltx_font_bold">0.639</span></td>
<td id="A1.T3.1.17.15.3" class="ltx_td ltx_align_center">0.618</td>
<td id="A1.T3.1.17.15.4" class="ltx_td ltx_align_center"><span id="A1.T3.1.17.15.4.1" class="ltx_text ltx_font_bold">0.639</span></td>
<td id="A1.T3.1.17.15.5" class="ltx_td ltx_align_center">0.625</td>
<td id="A1.T3.1.17.15.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.17.15.6.1" class="ltx_text ltx_font_bold">0.639</span></td>
</tr>
<tr id="A1.T3.1.18.16" class="ltx_tr">
<th id="A1.T3.1.18.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="A1.T3.1.18.16.1.1" class="ltx_text">Biology (5-shot)</span></th>
<th id="A1.T3.1.18.16.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Mistral 7B</th>
<td id="A1.T3.1.18.16.3" class="ltx_td ltx_align_center">0.722</td>
<td id="A1.T3.1.18.16.4" class="ltx_td ltx_align_center"><span id="A1.T3.1.18.16.4.1" class="ltx_text ltx_font_bold">0.778</span></td>
<td id="A1.T3.1.18.16.5" class="ltx_td ltx_align_center"><span id="A1.T3.1.18.16.5.1" class="ltx_text ltx_font_bold">0.778</span></td>
<td id="A1.T3.1.18.16.6" class="ltx_td ltx_align_center">0.771</td>
<td id="A1.T3.1.18.16.7" class="ltx_td ltx_align_center">0.743</td>
</tr>
<tr id="A1.T3.1.19.17" class="ltx_tr">
<th id="A1.T3.1.19.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.19.17.2" class="ltx_td ltx_align_center">0.500</td>
<td id="A1.T3.1.19.17.3" class="ltx_td ltx_align_center"><span id="A1.T3.1.19.17.3.1" class="ltx_text ltx_font_bold">0.521</span></td>
<td id="A1.T3.1.19.17.4" class="ltx_td ltx_align_center">0.507</td>
<td id="A1.T3.1.19.17.5" class="ltx_td ltx_align_center">0.465</td>
<td id="A1.T3.1.19.17.6" class="ltx_td ltx_align_center">0.472</td>
</tr>
<tr id="A1.T3.1.20.18" class="ltx_tr">
<th id="A1.T3.1.20.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.20.18.2" class="ltx_td ltx_align_center">0.625</td>
<td id="A1.T3.1.20.18.3" class="ltx_td ltx_align_center">0.639</td>
<td id="A1.T3.1.20.18.4" class="ltx_td ltx_align_center">0.625</td>
<td id="A1.T3.1.20.18.5" class="ltx_td ltx_align_center"><span id="A1.T3.1.20.18.5.1" class="ltx_text ltx_font_bold">0.660</span></td>
<td id="A1.T3.1.20.18.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.20.18.6.1" class="ltx_text ltx_font_bold">0.660</span></td>
</tr>
<tr id="A1.T3.1.21.19" class="ltx_tr">
<th id="A1.T3.1.21.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="A1.T3.1.21.19.1.1" class="ltx_text">Chemistry (0-shot)</span></th>
<th id="A1.T3.1.21.19.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Mistral 7B</th>
<td id="A1.T3.1.21.19.3" class="ltx_td ltx_align_center ltx_border_t">0.450</td>
<td id="A1.T3.1.21.19.4" class="ltx_td ltx_align_center ltx_border_t">0.470</td>
<td id="A1.T3.1.21.19.5" class="ltx_td ltx_align_center ltx_border_t">0.470</td>
<td id="A1.T3.1.21.19.6" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.1.21.19.6.1" class="ltx_text ltx_font_bold">0.500</span></td>
<td id="A1.T3.1.21.19.7" class="ltx_td ltx_align_center ltx_border_t">0.470</td>
</tr>
<tr id="A1.T3.1.22.20" class="ltx_tr">
<th id="A1.T3.1.22.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.22.20.2" class="ltx_td ltx_align_center">0.320</td>
<td id="A1.T3.1.22.20.3" class="ltx_td ltx_align_center">0.320</td>
<td id="A1.T3.1.22.20.4" class="ltx_td ltx_align_center">0.300</td>
<td id="A1.T3.1.22.20.5" class="ltx_td ltx_align_center"><span id="A1.T3.1.22.20.5.1" class="ltx_text ltx_font_bold">0.380</span></td>
<td id="A1.T3.1.22.20.6" class="ltx_td ltx_align_center">0.360</td>
</tr>
<tr id="A1.T3.1.23.21" class="ltx_tr">
<th id="A1.T3.1.23.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.23.21.2" class="ltx_td ltx_align_center">0.370</td>
<td id="A1.T3.1.23.21.3" class="ltx_td ltx_align_center">0.420</td>
<td id="A1.T3.1.23.21.4" class="ltx_td ltx_align_center">0.400</td>
<td id="A1.T3.1.23.21.5" class="ltx_td ltx_align_center">0.410</td>
<td id="A1.T3.1.23.21.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.23.21.6.1" class="ltx_text ltx_font_bold">0.440</span></td>
</tr>
<tr id="A1.T3.1.24.22" class="ltx_tr">
<th id="A1.T3.1.24.22.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="A1.T3.1.24.22.1.1" class="ltx_text">Chemistry (5-shot)</span></th>
<th id="A1.T3.1.24.22.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Mistral 7B</th>
<td id="A1.T3.1.24.22.3" class="ltx_td ltx_align_center"><span id="A1.T3.1.24.22.3.1" class="ltx_text ltx_font_bold">0.540</span></td>
<td id="A1.T3.1.24.22.4" class="ltx_td ltx_align_center">0.490</td>
<td id="A1.T3.1.24.22.5" class="ltx_td ltx_align_center">0.500</td>
<td id="A1.T3.1.24.22.6" class="ltx_td ltx_align_center">0.510</td>
<td id="A1.T3.1.24.22.7" class="ltx_td ltx_align_center">0.470</td>
</tr>
<tr id="A1.T3.1.25.23" class="ltx_tr">
<th id="A1.T3.1.25.23.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.25.23.2" class="ltx_td ltx_align_center">0.280</td>
<td id="A1.T3.1.25.23.3" class="ltx_td ltx_align_center">0.320</td>
<td id="A1.T3.1.25.23.4" class="ltx_td ltx_align_center">0.340</td>
<td id="A1.T3.1.25.23.5" class="ltx_td ltx_align_center">0.340</td>
<td id="A1.T3.1.25.23.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.25.23.6.1" class="ltx_text ltx_font_bold">0.380</span></td>
</tr>
<tr id="A1.T3.1.26.24" class="ltx_tr">
<th id="A1.T3.1.26.24.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.26.24.2" class="ltx_td ltx_align_center">0.390</td>
<td id="A1.T3.1.26.24.3" class="ltx_td ltx_align_center">0.430</td>
<td id="A1.T3.1.26.24.4" class="ltx_td ltx_align_center">0.400</td>
<td id="A1.T3.1.26.24.5" class="ltx_td ltx_align_center">0.430</td>
<td id="A1.T3.1.26.24.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.26.24.6.1" class="ltx_text ltx_font_bold">0.470</span></td>
</tr>
<tr id="A1.T3.1.27.25" class="ltx_tr">
<th id="A1.T3.1.27.25.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="A1.T3.1.27.25.1.1" class="ltx_text">Prehistory (0-shot)</span></th>
<th id="A1.T3.1.27.25.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Mistral 7B</th>
<td id="A1.T3.1.27.25.3" class="ltx_td ltx_align_center ltx_border_t">0.728</td>
<td id="A1.T3.1.27.25.4" class="ltx_td ltx_align_center ltx_border_t">0.725</td>
<td id="A1.T3.1.27.25.5" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.1.27.25.5.1" class="ltx_text ltx_font_bold">0.750</span></td>
<td id="A1.T3.1.27.25.6" class="ltx_td ltx_align_center ltx_border_t">0.735</td>
<td id="A1.T3.1.27.25.7" class="ltx_td ltx_align_center ltx_border_t">0.728</td>
</tr>
<tr id="A1.T3.1.28.26" class="ltx_tr">
<th id="A1.T3.1.28.26.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.28.26.2" class="ltx_td ltx_align_center"><span id="A1.T3.1.28.26.2.1" class="ltx_text ltx_font_bold">0.481</span></td>
<td id="A1.T3.1.28.26.3" class="ltx_td ltx_align_center">0.460</td>
<td id="A1.T3.1.28.26.4" class="ltx_td ltx_align_center">0.457</td>
<td id="A1.T3.1.28.26.5" class="ltx_td ltx_align_center">0.457</td>
<td id="A1.T3.1.28.26.6" class="ltx_td ltx_align_center">0.429</td>
</tr>
<tr id="A1.T3.1.29.27" class="ltx_tr">
<th id="A1.T3.1.29.27.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.29.27.2" class="ltx_td ltx_align_center">0.648</td>
<td id="A1.T3.1.29.27.3" class="ltx_td ltx_align_center">0.645</td>
<td id="A1.T3.1.29.27.4" class="ltx_td ltx_align_center">0.660</td>
<td id="A1.T3.1.29.27.5" class="ltx_td ltx_align_center">0.670</td>
<td id="A1.T3.1.29.27.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.29.27.6.1" class="ltx_text ltx_font_bold">0.679</span></td>
</tr>
<tr id="A1.T3.1.30.28" class="ltx_tr">
<th id="A1.T3.1.30.28.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" rowspan="3"><span id="A1.T3.1.30.28.1.1" class="ltx_text">Prehistory (5-shot)</span></th>
<th id="A1.T3.1.30.28.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Mistral 7B</th>
<td id="A1.T3.1.30.28.3" class="ltx_td ltx_align_center">0.710</td>
<td id="A1.T3.1.30.28.4" class="ltx_td ltx_align_center">0.750</td>
<td id="A1.T3.1.30.28.5" class="ltx_td ltx_align_center">0.759</td>
<td id="A1.T3.1.30.28.6" class="ltx_td ltx_align_center">0.756</td>
<td id="A1.T3.1.30.28.7" class="ltx_td ltx_align_center"><span id="A1.T3.1.30.28.7.1" class="ltx_text ltx_font_bold">0.762</span></td>
</tr>
<tr id="A1.T3.1.31.29" class="ltx_tr">
<th id="A1.T3.1.31.29.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.31.29.2" class="ltx_td ltx_align_center">0.512</td>
<td id="A1.T3.1.31.29.3" class="ltx_td ltx_align_center">0.485</td>
<td id="A1.T3.1.31.29.4" class="ltx_td ltx_align_center">0.525</td>
<td id="A1.T3.1.31.29.5" class="ltx_td ltx_align_center">0.519</td>
<td id="A1.T3.1.31.29.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.31.29.6.1" class="ltx_text ltx_font_bold">0.531</span></td>
</tr>
<tr id="A1.T3.1.32.30" class="ltx_tr">
<th id="A1.T3.1.32.30.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.32.30.2" class="ltx_td ltx_align_center ltx_border_bb">0.660</td>
<td id="A1.T3.1.32.30.3" class="ltx_td ltx_align_center ltx_border_bb">0.688</td>
<td id="A1.T3.1.32.30.4" class="ltx_td ltx_align_center ltx_border_bb">0.685</td>
<td id="A1.T3.1.32.30.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T3.1.32.30.5.1" class="ltx_text ltx_font_bold">0.698</span></td>
<td id="A1.T3.1.32.30.6" class="ltx_td ltx_align_center ltx_border_bb">0.688</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T3.3.1.1" style="font-size:90%;">Table 3</span>:</span><span class="ltx_text" id="A1.T3.4.2" style="font-size:90%;">RAG ablation study. </span></figcaption>
</figure>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Paraphrase Examples</h2>

<div id="A2.p1" class="ltx_para">
<p class="ltx_p" id="A2.p1.1">아래는 GPT-4로 패러프레이즈를 생성하는 데 사용한 프롬프트이다.</p>
</div>
<div id="A2.p2" class="ltx_para">
<blockquote id="A2.p2.1" class="ltx_quote">
<p class="ltx_p" id="A2.p2.1.1">당신의 임무는 텍스트 문단을 패러프레이즈하는 것이다. 그 단락은 아래에 나와 있다.</p>
<p class="ltx_p" id="A2.p2.1.2">같은 의미를 유지하되 문구를 바꿔야 한다. 사실적인 정보를 변경하지 마십시오.</p>
<p class="ltx_p" id="A2.p2.1.3">원문의 길이를 거의 동일하게 유지하려고 노력하세요.</p>
<p class="ltx_p" id="A2.p2.1.4">NUM _ PARAPHRAS는 각 텍스트에 대해 서로 다른 패러프레이즈를 제공합니다.</p>
<p class="ltx_p" id="A2.p2.1.5">이러한 패러프레이즈들은 가능한 한 서로 달라야 한다.</p>
<p class="ltx_p" id="A2.p2.1.6">"패러프레이즈"라고 하는 하나의 키와 패러프레이즈 목록을 사용하여 JSON 형식의 문자열을 반환합니다.</p>
<p class="ltx_p" id="A2.p2.1.7">입력 단락:</p>
</blockquote>
</div>
<div id="A2.p3" class="ltx_para">
<p class="ltx_p" id="A2.p3.1">다음은 몇 가지 예입니다. 먼저, 다음 위키피디아 페이지에서 예로 든 것: “제51회 국제 에미상”</p>
</div>
<div id="A2.p4" class="ltx_para">
<blockquote id="A2.p4.1" class="ltx_quote">
<p class="ltx_p" id="A2.p4.1.1"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="A2.p4.1.1.1">Paraphrase I</span></p>
<p class="ltx_p" id="A2.p4.1.2">국제 에미상 대회 제51판은 2022년 12월 7일부터 2023년 2월 16일까지 모든 부문에 걸쳐 제출을 수락했다.</p>
<p class="ltx_p" id="A2.p4.1.3"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="A2.p4.1.3.1">Paraphrase II</span></p>
<p class="ltx_p" id="A2.p4.1.4">이제 51년째인 국제 에미상 대회는 2022년 12월 7일부터 2023년 2월 16일 마감일까지 모든 부문에 걸쳐 제출을 수락했다.</p>
<p class="ltx_p" id="A2.p4.1.5"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="A2.p4.1.5.1">Paraphrase III</span></p>
<p class="ltx_p" id="A2.p4.1.6">국제 에미상 대회 제51판은 2022년 12월 7일부터 2023년 2월 16일까지 모든 부문에 걸쳐 제출을 수락했다.</p>
</blockquote>
</div>
<div id="A2.p5" class="ltx_para">
<p class="ltx_p" id="A2.p5.1">다음 예는 다음 위키피디아 페이지인 “2023 인디애나폴리스 시장 선거”에서 가져왔다.</p>
</div>
<div id="A2.p6" class="ltx_para">
<blockquote id="A2.p6.1" class="ltx_quote">
<p class="ltx_p" id="A2.p6.1.1"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="A2.p6.1.1.1">Paraphrase I</span> 인디애나폴리스에서 시장 선거는 2023년 11월 7일에 이루어졌으며 예비 선거는 5월 2일에 발생했다. 앉아 있는 시장인 민주당 조 호그셋은 성공적으로 3선에 출마했다. 호그셋과 그의 공화당 적수 제퍼슨 슈리브는 모두 본선거로 넘어갔다.</p>
<p class="ltx_p" id="A2.p6.1.2"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="A2.p6.1.2.1">Paraphrase II</span> 2023년 11월 7일 인디애나폴리스 시민은 5월 2일 예비 선거에 이어 시장을 선출하기 위해 표를 던졌다. 민주당은 이미 집권하고 있다. 호그셋과 공화당 후보인 제퍼슨 슈리브는 최종 선거 라운드에서 두 명의 경쟁자였다.</p>
<p class="ltx_p" id="A2.p6.1.3"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="A2.p6.1.3.1">Paraphrase III</span></p>
<p class="ltx_p" id="A2.p6.1.4">인디애나폴리스 시장 선거는 지난 5월 2일 치러진 예비 선거에 이어 2023년 11월 7일 치러졌다. 현직 민주당원인 조 호그셋은 성공적으로 3선에 출마했다. 호그셋과 그의 공화당 도전자 제퍼슨 슈리브는 모두 선거의 마지막 라운드에 진출했다.</p>
</blockquote>
</div>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Current Events Existing Knowledge Examples</h2>

<div id="A3.p1" class="ltx_para">
<p class="ltx_p" id="A3.p1.1">모델이 무작위 성공보다 나은 새로운 정보에 대한 질문에 어떻게 대답할 수 있는지 더 잘 이해하기 위해 세 가지 가능한 시나리오를 예로 제시한다. 이러한 시나리오는 추론 능력이 더 강한 모델이 보이지 않는 정보에 대해서도 정답을 추론할 수 있는 방법을 보여준다. <br class="ltx_break"/> <br class="ltx_break"/> 첫 번째 시나리오는 이전에 보이지 않은 정보에 대한 질문을 포함하며, 여기서 기본 추론 능력은 모델이 교육을 받은 추측을 할 수 있게 한다.</p>
</div>
<div id="A3.p2" class="ltx_para">
<blockquote id="A3.p2.1" class="ltx_quote">
<p class="ltx_p" id="A3.p2.1.1"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="A3.p2.1.1.1">Question:</span> What was a key issue led to the 2023 United Auto Workers strike? <br class="ltx_break"/> <br class="ltx_break"/> <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="A3.p2.1.1.2">Answers:</span></p>
<ol id="A3.I1" class="ltx_enumerate">
<li id="A3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A3.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="A3.I1.i1.p1.1">구내식당 음식의 품질에 대한 불만.</p>
</div>
</li>
<li id="A3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A3.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="A3.I1.i2.p1.1">직원 복장 규정에 대한 의견 차이</p>
</div>
</li>
<li id="A3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A3.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="A3.I1.i3.p1.1">정체된 임금과 계층화된 고용 제도에 대한 불만.</p>
</div>
</li>
<li id="A3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A3.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="A3.I1.i4.p1.1">공장의 색깔에 대한 토론.</p>
</div>
</li>
</ol>
</blockquote>
</div>
<div id="A3.p3" class="ltx_para">
<p class="ltx_p" id="A3.p3.1">이 경우 이 특정 파업에 대한 지식이 없더라도 세 번째 옵션이 가장 가능성이 높다고 추측하기 쉽다. <br class="ltx_break"/> <br class="ltx_break"/> 두 번째 시나리오는 토픽에 대한 사전 지식이 모델이 응답하는 데 도움이 될 수 있는 질문을 포함한다.</p>
</div>
<div id="A3.p4" class="ltx_para">
<blockquote id="A3.p4.1" class="ltx_quote">
<p class="ltx_p" id="A3.p4.1.1"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="A3.p4.1.1.1">Question:</span> 2023년 하와이 산불의 결과로 일부 과학자들에 의해 어떤 환경 문제가 제기되었는가? <br class="ltx_break"/> <br class="ltx_break"/> <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="A3.p4.1.1.2">Answers:</span></p>
<ol id="A3.I2" class="ltx_enumerate">
<li id="A3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A3.I2.i1.p1" class="ltx_para">
<p class="ltx_p" id="A3.I2.i1.p1.1">기온 상승</p>
</div>
</li>
<li id="A3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A3.I2.i2.p1" class="ltx_para">
<p class="ltx_p" id="A3.I2.i2.p1.1">만년설이 녹고 있어</p>
</div>
</li>
<li id="A3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A3.I2.i3.p1" class="ltx_para">
<p class="ltx_p" id="A3.I2.i3.p1.1">그을린 흙이 해안가로 흘러들어갔다.</p>
</div>
</li>
<li id="A3.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A3.I2.i4.p1" class="ltx_para">
<p class="ltx_p" id="A3.I2.i4.p1.1">대기 오염 증가</p>
</div>
</li>
</ol>
</blockquote>
<p class="ltx_p" id="A3.p4.2">이 경우 하와이의 지리와 산불의 즉각적인 영향을 알면 모델이 처음 두 가지 옵션을 더 낮은 확률로 제공할 수 있다. 이러한 제거 과정은 나머지 선택지 중 하나를 선택할 확률을 높인다(세 번째 선택지는 정답이다). <br class="ltx_break"/> <br class="ltx_break"/> 세 번째 시나리오는 자동 질문 생성 프로세스로 인해 발생하며, 일부 질문은 기존 지식에 강하게 의존한다.</p>
</div>
<div id="A3.p5" class="ltx_para">
<blockquote id="A3.p5.1" class="ltx_quote">
<p class="ltx_p" id="A3.p5.1.1"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="A3.p5.1.1.1">Question:</span> What event in 2021 was compared to the September 2023 New York floods? <br class="ltx_break"/> <br class="ltx_break"/> <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="A3.p5.1.1.2">Answers:</span></p>
<ol id="A3.I3" class="ltx_enumerate">
<li id="A3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A3.I3.i1.p1" class="ltx_para">
<p class="ltx_p" id="A3.I3.i1.p1.1">허리케인 카트리나</p>
</div>
</li>
<li id="A3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A3.I3.i2.p1" class="ltx_para">
<p class="ltx_p" id="A3.I3.i2.p1.1">허리케인 이다</p>
</div>
</li>
<li id="A3.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A3.I3.i3.p1" class="ltx_para">
<p class="ltx_p" id="A3.I3.i3.p1.1">허리케인 샌디</p>
</div>
</li>
<li id="A3.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A3.I3.i4.p1" class="ltx_para">
<p class="ltx_p" id="A3.I3.i4.p1.1">허리케인 하비</p>
</div>
</li>
</ol>
</blockquote>
</div>
<div id="A3.p6" class="ltx_para">
<p class="ltx_p" id="A3.p6.1">이러한 이벤트 중 하나만 2021년에 발생했고(허리케인 이다), 테스트한 모든 모델이 사전 훈련 동안 2021년부터 이벤트에 노출되었기 때문에 이 질문은 추가 현재 정보를 사용하지 않고도 잠재적으로 대답할 수 있다. <br class="ltx_break"/> <br class="ltx_break"/> 마지막으로, 모델들이 랜덤 성공보다 더 나은 새로운 정보에 관한 질문들에 일반적으로 응답할 수 없다고 가정하는 것이 합리적인 이유를 입증하기 위해, 다음의 예를 살펴본다:</p>
</div>
<div id="A3.p7" class="ltx_para">
<blockquote id="A3.p7.1" class="ltx_quote">
<p class="ltx_p" id="A3.p7.1.1"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="A3.p7.1.1.1">Question:</span> How did Matthew Belk, a National Weather Service meteorologist, describe the September 2023 northeastern U.S. floods? <br class="ltx_break"/> <br class="ltx_break"/> <span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="A3.p7.1.1.2">Answers:</span></p>
<ol id="A3.I4" class="ltx_enumerate">
<li id="A3.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A3.I4.i1.p1" class="ltx_para">
<p class="ltx_p" id="A3.I4.i1.p1.1">50년 행사요</p>
</div>
</li>
<li id="A3.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A3.I4.i2.p1" class="ltx_para">
<p class="ltx_p" id="A3.I4.i2.p1.1">100년 행사입니다.</p>
</div>
</li>
<li id="A3.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A3.I4.i3.p1" class="ltx_para">
<p class="ltx_p" id="A3.I4.i3.p1.1">200년 동안요</p>
</div>
</li>
<li id="A3.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A3.I4.i4.p1" class="ltx_para">
<p class="ltx_p" id="A3.I4.i4.p1.1">500년짜리 행사야</p>
</div>
</li>
</ol>
</blockquote>
</div>
<div id="A3.p8" class="ltx_para">
<p class="ltx_p" id="A3.p8.1">홍수와 그 통계적 특성에 대한 약간의 지식을 가지고 있더라도, 이 특정 기상학자가 홍수를 ‘200년 사건’이라고 부를 것이라고 추측하기는 매우 어려울 것이다. 특히 모형이 홍수의 세부 사항에 대한 정보에 노출되지 않은 경우에는 더욱 그러하다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2312.05933" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2312.05934" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2312.05934">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2312.05934" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2312.05935" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 14:46:31 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>