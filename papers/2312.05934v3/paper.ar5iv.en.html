<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2312.05934] Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs</title><meta property="og:description" content="Large language models (LLMs) encapsulate a vast amount of factual information within their pre-trained weights, as evidenced by their ability to answer diverse questions across different domains. However, this knowledgâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2312.05934">

<!--Generated on Tue Feb 27 14:46:31 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on  %**** main.tex Line 100 **** .-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Fine-Tuning or Retrieval? 
<br class="ltx_break">Comparing Knowledge Injection in LLMs</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Oded Ovadia
</span><span class="ltx_author_notes">Corresponding author.Equal contribution.
<span class="ltx_contact ltx_role_affiliation">{odedovadia,t-mbrief,mmishaeli,oren.elisha}@microsoft.com 
<br class="ltx_break">Microsoft, Israel
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Menachem Brief<span id="footnotex1" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">0</span></span></span></span>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">{odedovadia,t-mbrief,mmishaeli,oren.elisha}@microsoft.com 
<br class="ltx_break">Microsoft, Israel
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Moshik Mishaeli
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">{odedovadia,t-mbrief,mmishaeli,oren.elisha}@microsoft.com 
<br class="ltx_break">Microsoft, Israel
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Oren Elisha
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">{odedovadia,t-mbrief,mmishaeli,oren.elisha}@microsoft.com 
<br class="ltx_break">Microsoft, Israel
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Large language models (LLMs) encapsulate a vast amount of factual information within their pre-trained weights, as evidenced by their ability to answer diverse questions across different domains. However, this knowledge is inherently limited, relying heavily on the characteristics of the training data. Consequently, using external datasets to incorporate new information or refine the capabilities of LLMs on previously seen information poses a significant challenge. In this study, we compare two common approaches: unsupervised fine-tuning and retrieval-augmented generation (RAG). We evaluate both approaches on a variety of knowledge-intensive tasks across different topics. Our findings reveal that while unsupervised fine-tuning offers some improvement, RAG consistently outperforms it, both for existing knowledge encountered during training and entirely new knowledge. Moreover, we find that LLMs struggle to learn new factual information through unsupervised fine-tuning, and that exposing them to numerous variations of the same fact during training could alleviate this problem.</p>
</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold">Keywords:</span> LLMs, NLP, Fine-Tuning vs. RAG, Knowledge and Factuality.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Large language models (LLMs) are able to capture vast amounts of factual information <cite class="ltx_cite ltx_citemacro_citep">(Petroni et&nbsp;al., <a href="#bib.bib32" title="" class="ltx_ref">2019</a>; Cohen et&nbsp;al., <a href="#bib.bib8" title="" class="ltx_ref">2023</a>; Hu et&nbsp;al., <a href="#bib.bib13" title="" class="ltx_ref">2023</a>)</cite>. LLMs exhibit a remarkable level of knowledge in various domains due to their massive pre-training datasets. However, there are two significant limitations to this knowledge. First, it is static and does not update with time. Second, it is non-specific and thus may lack nuanced expertise in particular domains. While these are two different problems, they are deeply related since their solution is the same: enhancing the modelâ€™s knowledge.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Recently, the idea of adapting LLMs to particular domains and updating their knowledge has become increasingly common <cite class="ltx_cite ltx_citemacro_citep">(Yu et&nbsp;al., <a href="#bib.bib54" title="" class="ltx_ref">2022</a>)</cite>. Various models have been suggested to improve factual knowledge and capabilities in diverse fields such as healthcare <cite class="ltx_cite ltx_citemacro_citep">(Singhal et&nbsp;al., <a href="#bib.bib39" title="" class="ltx_ref">2023a</a>, <a href="#bib.bib40" title="" class="ltx_ref">b</a>; Wu et&nbsp;al., <a href="#bib.bib50" title="" class="ltx_ref">2023a</a>)</cite>, finance <cite class="ltx_cite ltx_citemacro_citep">(Wu et&nbsp;al., <a href="#bib.bib51" title="" class="ltx_ref">2023b</a>; Yang et&nbsp;al., <a href="#bib.bib53" title="" class="ltx_ref">2023</a>)</cite>, and law <cite class="ltx_cite ltx_citemacro_citep">(Huang et&nbsp;al., <a href="#bib.bib14" title="" class="ltx_ref">2023</a>; Nguyen, <a href="#bib.bib28" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this work, we focus on the evaluation of a modelâ€™s knowledge and its ability to memorize, understand, and retrieve factual data. We aim to understand the concept of <span id="S1.p3.1.1" class="ltx_text ltx_font_italic">knowledge injection</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib48" title="" class="ltx_ref">2020</a>; Chen et&nbsp;al., <a href="#bib.bib4" title="" class="ltx_ref">2022</a>; Liu et&nbsp;al., <a href="#bib.bib22" title="" class="ltx_ref">2020</a>; Lauscher et&nbsp;al., <a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>. Given some knowledge base in the form of a text corpus, what is the best way to teach a pre-trained model this knowledge?</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">One way to add knowledge to a pre-trained model is through fine-tuning. With fine-tuning, we continue the modelâ€™s training process and adapt it using task-specific data. By exposing the model to a specific knowledge base, we expect the model weights to adapt accordingly. This process is meant to optimize the model for targeted applications, enhancing its performance and contextual relevance in specialized domains.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Another method to enhance a modelâ€™s knowledge base is through the use of in-context learning (ICL) <cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a href="#bib.bib5" title="" class="ltx_ref">2021</a>; Radford et&nbsp;al., <a href="#bib.bib33" title="" class="ltx_ref">2019</a>; Min et&nbsp;al., <a href="#bib.bib24" title="" class="ltx_ref">2021</a>; Lampinen et&nbsp;al., <a href="#bib.bib19" title="" class="ltx_ref">2022</a>)</cite>. The main idea behind ICL is to improve the performance of pre-trained LLMs on new tasks by modifying the input query to the model without directly changing the weights of the model. One form of ICL is retrieval augmented generation (RAG) <cite class="ltx_cite ltx_citemacro_citep">(Lewis et&nbsp;al., <a href="#bib.bib21" title="" class="ltx_ref">2020</a>; Neelakantan et&nbsp;al., <a href="#bib.bib27" title="" class="ltx_ref">2022</a>)</cite>. RAG uses information retrieval techniques to enable LLMs to obtain relevant information from a knowledge source and incorporate it into generated text.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">This study aims to evaluate the knowledge injection capabilities of LLMs through a comparison of fine-tuning and RAG. To illustrate the rationale, let us use an analogy. Consider three college students taking a test on a specific topic. All had access to class materials but didnâ€™t know the topic beforehand. The first student had the textbook only during the test, the second had pre-test access and studied, and the third lost access upon the test announcement. Who would probably perform better?</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2312.05934/assets/media/Wikipedia.jpg" id="S2.F1.g1" class="ltx_graphics ltx_img_landscape" width="586" height="328" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">A visualization of the knowledge injection framework.</span></figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">To assess <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">knowledge injection</span>, we must first understand what <span id="S2.p1.1.2" class="ltx_text ltx_font_italic">knowledge</span> means for LLMs.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Knowledge and Language Models</span> â€ƒDefining knowledge is a complex philosophical task far beyond the scope of this research. However, we can examine what factual knowledge means in the context of language models. If a model knows a fact, it can accurately and consistently answer questions about it. Furthermore, it can reliably distinguish between true and false statements related to this fact. We can then extend this definition to a whole knowledge base, not just a single fact.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.5" class="ltx_p">Mathematically, let <math id="S2.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{Q}=\{q_{n}\}_{n=1}^{N}" display="inline"><semantics id="S2.p3.1.m1.1a"><mrow id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p3.1.m1.1.1.3" xref="S2.p3.1.m1.1.1.3.cmml">ğ’¬</mi><mo id="S2.p3.1.m1.1.1.2" xref="S2.p3.1.m1.1.1.2.cmml">=</mo><msubsup id="S2.p3.1.m1.1.1.1" xref="S2.p3.1.m1.1.1.1.cmml"><mrow id="S2.p3.1.m1.1.1.1.1.1.1" xref="S2.p3.1.m1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.p3.1.m1.1.1.1.1.1.1.2" xref="S2.p3.1.m1.1.1.1.1.1.2.cmml">{</mo><msub id="S2.p3.1.m1.1.1.1.1.1.1.1" xref="S2.p3.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S2.p3.1.m1.1.1.1.1.1.1.1.2" xref="S2.p3.1.m1.1.1.1.1.1.1.1.2.cmml">q</mi><mi id="S2.p3.1.m1.1.1.1.1.1.1.1.3" xref="S2.p3.1.m1.1.1.1.1.1.1.1.3.cmml">n</mi></msub><mo stretchy="false" id="S2.p3.1.m1.1.1.1.1.1.1.3" xref="S2.p3.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p3.1.m1.1.1.1.1.3" xref="S2.p3.1.m1.1.1.1.1.3.cmml"><mi id="S2.p3.1.m1.1.1.1.1.3.2" xref="S2.p3.1.m1.1.1.1.1.3.2.cmml">n</mi><mo id="S2.p3.1.m1.1.1.1.1.3.1" xref="S2.p3.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S2.p3.1.m1.1.1.1.1.3.3" xref="S2.p3.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S2.p3.1.m1.1.1.1.3" xref="S2.p3.1.m1.1.1.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><apply id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1"><eq id="S2.p3.1.m1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.2"></eq><ci id="S2.p3.1.m1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.3">ğ’¬</ci><apply id="S2.p3.1.m1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.1">superscript</csymbol><apply id="S2.p3.1.m1.1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.1">subscript</csymbol><set id="S2.p3.1.m1.1.1.1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1"><apply id="S2.p3.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p3.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1.2">ğ‘</ci><ci id="S2.p3.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1.3">ğ‘›</ci></apply></set><apply id="S2.p3.1.m1.1.1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.1.1.3"><eq id="S2.p3.1.m1.1.1.1.1.3.1.cmml" xref="S2.p3.1.m1.1.1.1.1.3.1"></eq><ci id="S2.p3.1.m1.1.1.1.1.3.2.cmml" xref="S2.p3.1.m1.1.1.1.1.3.2">ğ‘›</ci><cn type="integer" id="S2.p3.1.m1.1.1.1.1.3.3.cmml" xref="S2.p3.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S2.p3.1.m1.1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">\mathcal{Q}=\{q_{n}\}_{n=1}^{N}</annotation></semantics></math> be a set of <math id="S2.p3.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.p3.2.m2.1a"><mi id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b"><ci id="S2.p3.2.m2.1.1.cmml" xref="S2.p3.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">N</annotation></semantics></math> multiple choice factual questions, where each question has <math id="S2.p3.3.m3.1" class="ltx_Math" alttext="L" display="inline"><semantics id="S2.p3.3.m3.1a"><mi id="S2.p3.3.m3.1.1" xref="S2.p3.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.p3.3.m3.1b"><ci id="S2.p3.3.m3.1.1.cmml" xref="S2.p3.3.m3.1.1">ğ¿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.3.m3.1c">L</annotation></semantics></math> possible answers and exactly one correct answer. Let <math id="S2.p3.4.m4.2" class="ltx_Math" alttext="\mathcal{A}=\{(a_{n}^{1},\ldots,a_{n}^{L})\}_{n=1}^{N}" display="inline"><semantics id="S2.p3.4.m4.2a"><mrow id="S2.p3.4.m4.2.2" xref="S2.p3.4.m4.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p3.4.m4.2.2.3" xref="S2.p3.4.m4.2.2.3.cmml">ğ’œ</mi><mo id="S2.p3.4.m4.2.2.2" xref="S2.p3.4.m4.2.2.2.cmml">=</mo><msubsup id="S2.p3.4.m4.2.2.1" xref="S2.p3.4.m4.2.2.1.cmml"><mrow id="S2.p3.4.m4.2.2.1.1.1.1" xref="S2.p3.4.m4.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S2.p3.4.m4.2.2.1.1.1.1.2" xref="S2.p3.4.m4.2.2.1.1.1.2.cmml">{</mo><mrow id="S2.p3.4.m4.2.2.1.1.1.1.1.2" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.p3.4.m4.2.2.1.1.1.1.1.2.3" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml">(</mo><msubsup id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.cmml"><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.2" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.2.cmml">a</mi><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.3" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.3.cmml">n</mi><mn id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.3" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.3.cmml">1</mn></msubsup><mo id="S2.p3.4.m4.2.2.1.1.1.1.1.2.4" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml">,</mo><mi mathvariant="normal" id="S2.p3.4.m4.1.1" xref="S2.p3.4.m4.1.1.cmml">â€¦</mi><mo id="S2.p3.4.m4.2.2.1.1.1.1.1.2.5" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml">,</mo><msubsup id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.cmml"><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.2" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.2.cmml">a</mi><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.3" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.3.cmml">n</mi><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.3" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.3.cmml">L</mi></msubsup><mo stretchy="false" id="S2.p3.4.m4.2.2.1.1.1.1.1.2.6" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S2.p3.4.m4.2.2.1.1.1.1.3" xref="S2.p3.4.m4.2.2.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p3.4.m4.2.2.1.1.3" xref="S2.p3.4.m4.2.2.1.1.3.cmml"><mi id="S2.p3.4.m4.2.2.1.1.3.2" xref="S2.p3.4.m4.2.2.1.1.3.2.cmml">n</mi><mo id="S2.p3.4.m4.2.2.1.1.3.1" xref="S2.p3.4.m4.2.2.1.1.3.1.cmml">=</mo><mn id="S2.p3.4.m4.2.2.1.1.3.3" xref="S2.p3.4.m4.2.2.1.1.3.3.cmml">1</mn></mrow><mi id="S2.p3.4.m4.2.2.1.3" xref="S2.p3.4.m4.2.2.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.4.m4.2b"><apply id="S2.p3.4.m4.2.2.cmml" xref="S2.p3.4.m4.2.2"><eq id="S2.p3.4.m4.2.2.2.cmml" xref="S2.p3.4.m4.2.2.2"></eq><ci id="S2.p3.4.m4.2.2.3.cmml" xref="S2.p3.4.m4.2.2.3">ğ’œ</ci><apply id="S2.p3.4.m4.2.2.1.cmml" xref="S2.p3.4.m4.2.2.1"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.2.cmml" xref="S2.p3.4.m4.2.2.1">superscript</csymbol><apply id="S2.p3.4.m4.2.2.1.1.cmml" xref="S2.p3.4.m4.2.2.1"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.2.cmml" xref="S2.p3.4.m4.2.2.1">subscript</csymbol><set id="S2.p3.4.m4.2.2.1.1.1.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1"><vector id="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2"><apply id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.2">ğ‘</ci><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.3">ğ‘›</ci></apply><cn type="integer" id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.3.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.3">1</cn></apply><ci id="S2.p3.4.m4.1.1.cmml" xref="S2.p3.4.m4.1.1">â€¦</ci><apply id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2">superscript</csymbol><apply id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2">subscript</csymbol><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.2">ğ‘</ci><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.3.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.3">ğ‘›</ci></apply><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.3.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.3">ğ¿</ci></apply></vector></set><apply id="S2.p3.4.m4.2.2.1.1.3.cmml" xref="S2.p3.4.m4.2.2.1.1.3"><eq id="S2.p3.4.m4.2.2.1.1.3.1.cmml" xref="S2.p3.4.m4.2.2.1.1.3.1"></eq><ci id="S2.p3.4.m4.2.2.1.1.3.2.cmml" xref="S2.p3.4.m4.2.2.1.1.3.2">ğ‘›</ci><cn type="integer" id="S2.p3.4.m4.2.2.1.1.3.3.cmml" xref="S2.p3.4.m4.2.2.1.1.3.3">1</cn></apply></apply><ci id="S2.p3.4.m4.2.2.1.3.cmml" xref="S2.p3.4.m4.2.2.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.4.m4.2c">\mathcal{A}=\{(a_{n}^{1},\ldots,a_{n}^{L})\}_{n=1}^{N}</annotation></semantics></math> be the corresponding set of possible answers, and <math id="S2.p3.5.m5.1" class="ltx_Math" alttext="\mathcal{C}=\{c_{n}\}_{n=1}^{N}" display="inline"><semantics id="S2.p3.5.m5.1a"><mrow id="S2.p3.5.m5.1.1" xref="S2.p3.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p3.5.m5.1.1.3" xref="S2.p3.5.m5.1.1.3.cmml">ğ’</mi><mo id="S2.p3.5.m5.1.1.2" xref="S2.p3.5.m5.1.1.2.cmml">=</mo><msubsup id="S2.p3.5.m5.1.1.1" xref="S2.p3.5.m5.1.1.1.cmml"><mrow id="S2.p3.5.m5.1.1.1.1.1.1" xref="S2.p3.5.m5.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.p3.5.m5.1.1.1.1.1.1.2" xref="S2.p3.5.m5.1.1.1.1.1.2.cmml">{</mo><msub id="S2.p3.5.m5.1.1.1.1.1.1.1" xref="S2.p3.5.m5.1.1.1.1.1.1.1.cmml"><mi id="S2.p3.5.m5.1.1.1.1.1.1.1.2" xref="S2.p3.5.m5.1.1.1.1.1.1.1.2.cmml">c</mi><mi id="S2.p3.5.m5.1.1.1.1.1.1.1.3" xref="S2.p3.5.m5.1.1.1.1.1.1.1.3.cmml">n</mi></msub><mo stretchy="false" id="S2.p3.5.m5.1.1.1.1.1.1.3" xref="S2.p3.5.m5.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p3.5.m5.1.1.1.1.3" xref="S2.p3.5.m5.1.1.1.1.3.cmml"><mi id="S2.p3.5.m5.1.1.1.1.3.2" xref="S2.p3.5.m5.1.1.1.1.3.2.cmml">n</mi><mo id="S2.p3.5.m5.1.1.1.1.3.1" xref="S2.p3.5.m5.1.1.1.1.3.1.cmml">=</mo><mn id="S2.p3.5.m5.1.1.1.1.3.3" xref="S2.p3.5.m5.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S2.p3.5.m5.1.1.1.3" xref="S2.p3.5.m5.1.1.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.5.m5.1b"><apply id="S2.p3.5.m5.1.1.cmml" xref="S2.p3.5.m5.1.1"><eq id="S2.p3.5.m5.1.1.2.cmml" xref="S2.p3.5.m5.1.1.2"></eq><ci id="S2.p3.5.m5.1.1.3.cmml" xref="S2.p3.5.m5.1.1.3">ğ’</ci><apply id="S2.p3.5.m5.1.1.1.cmml" xref="S2.p3.5.m5.1.1.1"><csymbol cd="ambiguous" id="S2.p3.5.m5.1.1.1.2.cmml" xref="S2.p3.5.m5.1.1.1">superscript</csymbol><apply id="S2.p3.5.m5.1.1.1.1.cmml" xref="S2.p3.5.m5.1.1.1"><csymbol cd="ambiguous" id="S2.p3.5.m5.1.1.1.1.2.cmml" xref="S2.p3.5.m5.1.1.1">subscript</csymbol><set id="S2.p3.5.m5.1.1.1.1.1.2.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1"><apply id="S2.p3.5.m5.1.1.1.1.1.1.1.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.5.m5.1.1.1.1.1.1.1.1.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p3.5.m5.1.1.1.1.1.1.1.2.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1.1.2">ğ‘</ci><ci id="S2.p3.5.m5.1.1.1.1.1.1.1.3.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1.1.3">ğ‘›</ci></apply></set><apply id="S2.p3.5.m5.1.1.1.1.3.cmml" xref="S2.p3.5.m5.1.1.1.1.3"><eq id="S2.p3.5.m5.1.1.1.1.3.1.cmml" xref="S2.p3.5.m5.1.1.1.1.3.1"></eq><ci id="S2.p3.5.m5.1.1.1.1.3.2.cmml" xref="S2.p3.5.m5.1.1.1.1.3.2">ğ‘›</ci><cn type="integer" id="S2.p3.5.m5.1.1.1.1.3.3.cmml" xref="S2.p3.5.m5.1.1.1.1.3.3">1</cn></apply></apply><ci id="S2.p3.5.m5.1.1.1.3.cmml" xref="S2.p3.5.m5.1.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.5.m5.1c">\mathcal{C}=\{c_{n}\}_{n=1}^{N}</annotation></semantics></math> be the correct answers.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.3" class="ltx_p">Let <math id="S2.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S2.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p4.1.m1.1.1" xref="S2.p4.1.m1.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S2.p4.1.m1.1b"><ci id="S2.p4.1.m1.1.1.cmml" xref="S2.p4.1.m1.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.1.m1.1c">\mathcal{M}</annotation></semantics></math> be a language model. We denote by <math id="S2.p4.2.m2.4" class="ltx_Math" alttext="\mathcal{M}(q_{n})\in\{a_{n}^{1},\ldots,a_{n}^{L}\}" display="inline"><semantics id="S2.p4.2.m2.4a"><mrow id="S2.p4.2.m2.4.4" xref="S2.p4.2.m2.4.4.cmml"><mrow id="S2.p4.2.m2.2.2.1" xref="S2.p4.2.m2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p4.2.m2.2.2.1.3" xref="S2.p4.2.m2.2.2.1.3.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S2.p4.2.m2.2.2.1.2" xref="S2.p4.2.m2.2.2.1.2.cmml">â€‹</mo><mrow id="S2.p4.2.m2.2.2.1.1.1" xref="S2.p4.2.m2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.p4.2.m2.2.2.1.1.1.2" xref="S2.p4.2.m2.2.2.1.1.1.1.cmml">(</mo><msub id="S2.p4.2.m2.2.2.1.1.1.1" xref="S2.p4.2.m2.2.2.1.1.1.1.cmml"><mi id="S2.p4.2.m2.2.2.1.1.1.1.2" xref="S2.p4.2.m2.2.2.1.1.1.1.2.cmml">q</mi><mi id="S2.p4.2.m2.2.2.1.1.1.1.3" xref="S2.p4.2.m2.2.2.1.1.1.1.3.cmml">n</mi></msub><mo stretchy="false" id="S2.p4.2.m2.2.2.1.1.1.3" xref="S2.p4.2.m2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.p4.2.m2.4.4.4" xref="S2.p4.2.m2.4.4.4.cmml">âˆˆ</mo><mrow id="S2.p4.2.m2.4.4.3.2" xref="S2.p4.2.m2.4.4.3.3.cmml"><mo stretchy="false" id="S2.p4.2.m2.4.4.3.2.3" xref="S2.p4.2.m2.4.4.3.3.cmml">{</mo><msubsup id="S2.p4.2.m2.3.3.2.1.1" xref="S2.p4.2.m2.3.3.2.1.1.cmml"><mi id="S2.p4.2.m2.3.3.2.1.1.2.2" xref="S2.p4.2.m2.3.3.2.1.1.2.2.cmml">a</mi><mi id="S2.p4.2.m2.3.3.2.1.1.2.3" xref="S2.p4.2.m2.3.3.2.1.1.2.3.cmml">n</mi><mn id="S2.p4.2.m2.3.3.2.1.1.3" xref="S2.p4.2.m2.3.3.2.1.1.3.cmml">1</mn></msubsup><mo id="S2.p4.2.m2.4.4.3.2.4" xref="S2.p4.2.m2.4.4.3.3.cmml">,</mo><mi mathvariant="normal" id="S2.p4.2.m2.1.1" xref="S2.p4.2.m2.1.1.cmml">â€¦</mi><mo id="S2.p4.2.m2.4.4.3.2.5" xref="S2.p4.2.m2.4.4.3.3.cmml">,</mo><msubsup id="S2.p4.2.m2.4.4.3.2.2" xref="S2.p4.2.m2.4.4.3.2.2.cmml"><mi id="S2.p4.2.m2.4.4.3.2.2.2.2" xref="S2.p4.2.m2.4.4.3.2.2.2.2.cmml">a</mi><mi id="S2.p4.2.m2.4.4.3.2.2.2.3" xref="S2.p4.2.m2.4.4.3.2.2.2.3.cmml">n</mi><mi id="S2.p4.2.m2.4.4.3.2.2.3" xref="S2.p4.2.m2.4.4.3.2.2.3.cmml">L</mi></msubsup><mo stretchy="false" id="S2.p4.2.m2.4.4.3.2.6" xref="S2.p4.2.m2.4.4.3.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p4.2.m2.4b"><apply id="S2.p4.2.m2.4.4.cmml" xref="S2.p4.2.m2.4.4"><in id="S2.p4.2.m2.4.4.4.cmml" xref="S2.p4.2.m2.4.4.4"></in><apply id="S2.p4.2.m2.2.2.1.cmml" xref="S2.p4.2.m2.2.2.1"><times id="S2.p4.2.m2.2.2.1.2.cmml" xref="S2.p4.2.m2.2.2.1.2"></times><ci id="S2.p4.2.m2.2.2.1.3.cmml" xref="S2.p4.2.m2.2.2.1.3">â„³</ci><apply id="S2.p4.2.m2.2.2.1.1.1.1.cmml" xref="S2.p4.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p4.2.m2.2.2.1.1.1.1.1.cmml" xref="S2.p4.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S2.p4.2.m2.2.2.1.1.1.1.2.cmml" xref="S2.p4.2.m2.2.2.1.1.1.1.2">ğ‘</ci><ci id="S2.p4.2.m2.2.2.1.1.1.1.3.cmml" xref="S2.p4.2.m2.2.2.1.1.1.1.3">ğ‘›</ci></apply></apply><set id="S2.p4.2.m2.4.4.3.3.cmml" xref="S2.p4.2.m2.4.4.3.2"><apply id="S2.p4.2.m2.3.3.2.1.1.cmml" xref="S2.p4.2.m2.3.3.2.1.1"><csymbol cd="ambiguous" id="S2.p4.2.m2.3.3.2.1.1.1.cmml" xref="S2.p4.2.m2.3.3.2.1.1">superscript</csymbol><apply id="S2.p4.2.m2.3.3.2.1.1.2.cmml" xref="S2.p4.2.m2.3.3.2.1.1"><csymbol cd="ambiguous" id="S2.p4.2.m2.3.3.2.1.1.2.1.cmml" xref="S2.p4.2.m2.3.3.2.1.1">subscript</csymbol><ci id="S2.p4.2.m2.3.3.2.1.1.2.2.cmml" xref="S2.p4.2.m2.3.3.2.1.1.2.2">ğ‘</ci><ci id="S2.p4.2.m2.3.3.2.1.1.2.3.cmml" xref="S2.p4.2.m2.3.3.2.1.1.2.3">ğ‘›</ci></apply><cn type="integer" id="S2.p4.2.m2.3.3.2.1.1.3.cmml" xref="S2.p4.2.m2.3.3.2.1.1.3">1</cn></apply><ci id="S2.p4.2.m2.1.1.cmml" xref="S2.p4.2.m2.1.1">â€¦</ci><apply id="S2.p4.2.m2.4.4.3.2.2.cmml" xref="S2.p4.2.m2.4.4.3.2.2"><csymbol cd="ambiguous" id="S2.p4.2.m2.4.4.3.2.2.1.cmml" xref="S2.p4.2.m2.4.4.3.2.2">superscript</csymbol><apply id="S2.p4.2.m2.4.4.3.2.2.2.cmml" xref="S2.p4.2.m2.4.4.3.2.2"><csymbol cd="ambiguous" id="S2.p4.2.m2.4.4.3.2.2.2.1.cmml" xref="S2.p4.2.m2.4.4.3.2.2">subscript</csymbol><ci id="S2.p4.2.m2.4.4.3.2.2.2.2.cmml" xref="S2.p4.2.m2.4.4.3.2.2.2.2">ğ‘</ci><ci id="S2.p4.2.m2.4.4.3.2.2.2.3.cmml" xref="S2.p4.2.m2.4.4.3.2.2.2.3">ğ‘›</ci></apply><ci id="S2.p4.2.m2.4.4.3.2.2.3.cmml" xref="S2.p4.2.m2.4.4.3.2.2.3">ğ¿</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.2.m2.4c">\mathcal{M}(q_{n})\in\{a_{n}^{1},\ldots,a_{n}^{L}\}</annotation></semantics></math> the predicted answer of the model to the <math id="S2.p4.3.m3.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S2.p4.3.m3.1a"><mi id="S2.p4.3.m3.1.1" xref="S2.p4.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.p4.3.m3.1b"><ci id="S2.p4.3.m3.1.1.cmml" xref="S2.p4.3.m3.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.3.m3.1c">n</annotation></semantics></math>-th question.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.3" class="ltx_p">We define the <span id="S2.p5.3.1" class="ltx_text ltx_font_italic">knowledge score</span> <math id="S2.p5.1.m1.1" class="ltx_Math" alttext="\mathcal{L}" display="inline"><semantics id="S2.p5.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p5.1.m1.1.1" xref="S2.p5.1.m1.1.1.cmml">â„’</mi><annotation-xml encoding="MathML-Content" id="S2.p5.1.m1.1b"><ci id="S2.p5.1.m1.1.1.cmml" xref="S2.p5.1.m1.1.1">â„’</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.1.m1.1c">\mathcal{L}</annotation></semantics></math> of <math id="S2.p5.2.m2.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S2.p5.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p5.2.m2.1.1" xref="S2.p5.2.m2.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S2.p5.2.m2.1b"><ci id="S2.p5.2.m2.1.1.cmml" xref="S2.p5.2.m2.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.2.m2.1c">\mathcal{M}</annotation></semantics></math> in relation to <math id="S2.p5.3.m3.1" class="ltx_Math" alttext="\mathcal{Q}" display="inline"><semantics id="S2.p5.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p5.3.m3.1.1" xref="S2.p5.3.m3.1.1.cmml">ğ’¬</mi><annotation-xml encoding="MathML-Content" id="S2.p5.3.m3.1b"><ci id="S2.p5.3.m3.1.1.cmml" xref="S2.p5.3.m3.1.1">ğ’¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.3.m3.1c">\mathcal{Q}</annotation></semantics></math> to be the standard accuracy score:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.5" class="ltx_Math" alttext="\mathcal{L}_{\mathcal{M},\mathcal{Q}}:=\frac{\#\{q_{n}|\;\mathcal{M}(q_{n})=c_{n}\}}{N}." display="block"><semantics id="S2.E1.m1.5a"><mrow id="S2.E1.m1.5.5.1" xref="S2.E1.m1.5.5.1.1.cmml"><mrow id="S2.E1.m1.5.5.1.1" xref="S2.E1.m1.5.5.1.1.cmml"><msub id="S2.E1.m1.5.5.1.1.2" xref="S2.E1.m1.5.5.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.5.5.1.1.2.2" xref="S2.E1.m1.5.5.1.1.2.2.cmml">â„’</mi><mrow id="S2.E1.m1.2.2.2.4" xref="S2.E1.m1.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml">â„³</mi><mo id="S2.E1.m1.2.2.2.4.1" xref="S2.E1.m1.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.2.2.2.2" xref="S2.E1.m1.2.2.2.2.cmml">ğ’¬</mi></mrow></msub><mo lspace="0.278em" rspace="0.278em" id="S2.E1.m1.5.5.1.1.1" xref="S2.E1.m1.5.5.1.1.1.cmml">:=</mo><mfrac id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml"><mrow id="S2.E1.m1.4.4.2" xref="S2.E1.m1.4.4.2.cmml"><mi mathvariant="normal" id="S2.E1.m1.4.4.2.4" xref="S2.E1.m1.4.4.2.4.cmml">#</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.2.3" xref="S2.E1.m1.4.4.2.3.cmml">â€‹</mo><mrow id="S2.E1.m1.4.4.2.2.2" xref="S2.E1.m1.4.4.2.2.3.cmml"><mo stretchy="false" id="S2.E1.m1.4.4.2.2.2.3" xref="S2.E1.m1.4.4.2.2.3.1.cmml">{</mo><msub id="S2.E1.m1.3.3.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.cmml"><mi id="S2.E1.m1.3.3.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.2.cmml">q</mi><mi id="S2.E1.m1.3.3.1.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.3.cmml">n</mi></msub><mo lspace="0em" id="S2.E1.m1.4.4.2.2.2.4" xref="S2.E1.m1.4.4.2.2.3.1.cmml">|</mo><mrow id="S2.E1.m1.4.4.2.2.2.2" xref="S2.E1.m1.4.4.2.2.2.2.cmml"><mrow id="S2.E1.m1.4.4.2.2.2.2.1" xref="S2.E1.m1.4.4.2.2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.4.4.2.2.2.2.1.3" xref="S2.E1.m1.4.4.2.2.2.2.1.3.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.2.2.2.2.1.2" xref="S2.E1.m1.4.4.2.2.2.2.1.2.cmml">â€‹</mo><mrow id="S2.E1.m1.4.4.2.2.2.2.1.1.1" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.4.4.2.2.2.2.1.1.1.2" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml">(</mo><msub id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml"><mi id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.2" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.2.cmml">q</mi><mi id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.3" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.3.cmml">n</mi></msub><mo stretchy="false" id="S2.E1.m1.4.4.2.2.2.2.1.1.1.3" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.4.4.2.2.2.2.2" xref="S2.E1.m1.4.4.2.2.2.2.2.cmml">=</mo><msub id="S2.E1.m1.4.4.2.2.2.2.3" xref="S2.E1.m1.4.4.2.2.2.2.3.cmml"><mi id="S2.E1.m1.4.4.2.2.2.2.3.2" xref="S2.E1.m1.4.4.2.2.2.2.3.2.cmml">c</mi><mi id="S2.E1.m1.4.4.2.2.2.2.3.3" xref="S2.E1.m1.4.4.2.2.2.2.3.3.cmml">n</mi></msub></mrow><mo stretchy="false" id="S2.E1.m1.4.4.2.2.2.5" xref="S2.E1.m1.4.4.2.2.3.1.cmml">}</mo></mrow></mrow><mi id="S2.E1.m1.4.4.4" xref="S2.E1.m1.4.4.4.cmml">N</mi></mfrac></mrow><mo lspace="0em" id="S2.E1.m1.5.5.1.2" xref="S2.E1.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.5b"><apply id="S2.E1.m1.5.5.1.1.cmml" xref="S2.E1.m1.5.5.1"><csymbol cd="latexml" id="S2.E1.m1.5.5.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1">assign</csymbol><apply id="S2.E1.m1.5.5.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.2.1.cmml" xref="S2.E1.m1.5.5.1.1.2">subscript</csymbol><ci id="S2.E1.m1.5.5.1.1.2.2.cmml" xref="S2.E1.m1.5.5.1.1.2.2">â„’</ci><list id="S2.E1.m1.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.4"><ci id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1">â„³</ci><ci id="S2.E1.m1.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2">ğ’¬</ci></list></apply><apply id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4"><divide id="S2.E1.m1.4.4.3.cmml" xref="S2.E1.m1.4.4"></divide><apply id="S2.E1.m1.4.4.2.cmml" xref="S2.E1.m1.4.4.2"><times id="S2.E1.m1.4.4.2.3.cmml" xref="S2.E1.m1.4.4.2.3"></times><ci id="S2.E1.m1.4.4.2.4.cmml" xref="S2.E1.m1.4.4.2.4">#</ci><apply id="S2.E1.m1.4.4.2.2.3.cmml" xref="S2.E1.m1.4.4.2.2.2"><csymbol cd="latexml" id="S2.E1.m1.4.4.2.2.3.1.cmml" xref="S2.E1.m1.4.4.2.2.2.3">conditional-set</csymbol><apply id="S2.E1.m1.3.3.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2">ğ‘</ci><ci id="S2.E1.m1.3.3.1.1.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.3">ğ‘›</ci></apply><apply id="S2.E1.m1.4.4.2.2.2.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2"><eq id="S2.E1.m1.4.4.2.2.2.2.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.2"></eq><apply id="S2.E1.m1.4.4.2.2.2.2.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1"><times id="S2.E1.m1.4.4.2.2.2.2.1.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.2"></times><ci id="S2.E1.m1.4.4.2.2.2.2.1.3.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.3">â„³</ci><apply id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1">subscript</csymbol><ci id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.2">ğ‘</ci><ci id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.3.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.3">ğ‘›</ci></apply></apply><apply id="S2.E1.m1.4.4.2.2.2.2.3.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.2.2.2.2.3.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3">subscript</csymbol><ci id="S2.E1.m1.4.4.2.2.2.2.3.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3.2">ğ‘</ci><ci id="S2.E1.m1.4.4.2.2.2.2.3.3.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3.3">ğ‘›</ci></apply></apply></apply></apply><ci id="S2.E1.m1.4.4.4.cmml" xref="S2.E1.m1.4.4.4">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.5c">\mathcal{L}_{\mathcal{M},\mathcal{Q}}:=\frac{\#\{q_{n}|\;\mathcal{M}(q_{n})=c_{n}\}}{N}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.2" class="ltx_p">We say that the model <math id="S2.p6.1.m1.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S2.p6.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p6.1.m1.1.1" xref="S2.p6.1.m1.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S2.p6.1.m1.1b"><ci id="S2.p6.1.m1.1.1.cmml" xref="S2.p6.1.m1.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.1.m1.1c">\mathcal{M}</annotation></semantics></math> possesses <span id="S2.p6.2.1" class="ltx_text ltx_font_italic">any</span> knowledge regarding the set of questions <math id="S2.p6.2.m2.1" class="ltx_Math" alttext="\mathcal{Q}" display="inline"><semantics id="S2.p6.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p6.2.m2.1.1" xref="S2.p6.2.m2.1.1.cmml">ğ’¬</mi><annotation-xml encoding="MathML-Content" id="S2.p6.2.m2.1b"><ci id="S2.p6.2.m2.1.1.cmml" xref="S2.p6.2.m2.1.1">ğ’¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.2.m2.1c">\mathcal{Q}</annotation></semantics></math> if the following holds:</p>
</div>
<div id="S2.p7" class="ltx_para">
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.3" class="ltx_Math" alttext="\mathcal{L}_{\mathcal{M},\mathcal{Q}}>\frac{1}{L}." display="block"><semantics id="S2.E2.m1.3a"><mrow id="S2.E2.m1.3.3.1" xref="S2.E2.m1.3.3.1.1.cmml"><mrow id="S2.E2.m1.3.3.1.1" xref="S2.E2.m1.3.3.1.1.cmml"><msub id="S2.E2.m1.3.3.1.1.2" xref="S2.E2.m1.3.3.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.3.3.1.1.2.2" xref="S2.E2.m1.3.3.1.1.2.2.cmml">â„’</mi><mrow id="S2.E2.m1.2.2.2.4" xref="S2.E2.m1.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml">â„³</mi><mo id="S2.E2.m1.2.2.2.4.1" xref="S2.E2.m1.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.2.2.2.2" xref="S2.E2.m1.2.2.2.2.cmml">ğ’¬</mi></mrow></msub><mo id="S2.E2.m1.3.3.1.1.1" xref="S2.E2.m1.3.3.1.1.1.cmml">&gt;</mo><mfrac id="S2.E2.m1.3.3.1.1.3" xref="S2.E2.m1.3.3.1.1.3.cmml"><mn id="S2.E2.m1.3.3.1.1.3.2" xref="S2.E2.m1.3.3.1.1.3.2.cmml">1</mn><mi id="S2.E2.m1.3.3.1.1.3.3" xref="S2.E2.m1.3.3.1.1.3.3.cmml">L</mi></mfrac></mrow><mo lspace="0em" id="S2.E2.m1.3.3.1.2" xref="S2.E2.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.3b"><apply id="S2.E2.m1.3.3.1.1.cmml" xref="S2.E2.m1.3.3.1"><gt id="S2.E2.m1.3.3.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1"></gt><apply id="S2.E2.m1.3.3.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.2.1.cmml" xref="S2.E2.m1.3.3.1.1.2">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.2.2.cmml" xref="S2.E2.m1.3.3.1.1.2.2">â„’</ci><list id="S2.E2.m1.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.4"><ci id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1">â„³</ci><ci id="S2.E2.m1.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2">ğ’¬</ci></list></apply><apply id="S2.E2.m1.3.3.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.3"><divide id="S2.E2.m1.3.3.1.1.3.1.cmml" xref="S2.E2.m1.3.3.1.1.3"></divide><cn type="integer" id="S2.E2.m1.3.3.1.1.3.2.cmml" xref="S2.E2.m1.3.3.1.1.3.2">1</cn><ci id="S2.E2.m1.3.3.1.1.3.3.cmml" xref="S2.E2.m1.3.3.1.1.3.3">ğ¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.3c">\mathcal{L}_{\mathcal{M},\mathcal{Q}}&gt;\frac{1}{L}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.p8" class="ltx_para ltx_noindent">
<p id="S2.p8.2" class="ltx_p">In simpler terms, the model can consistently give correct answers, outperforming a simple random guessing baseline. Naturally, if the knowledge score <math id="S2.p8.1.m1.2" class="ltx_Math" alttext="\mathcal{L}_{\mathcal{M},\mathcal{Q}}" display="inline"><semantics id="S2.p8.1.m1.2a"><msub id="S2.p8.1.m1.2.3" xref="S2.p8.1.m1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p8.1.m1.2.3.2" xref="S2.p8.1.m1.2.3.2.cmml">â„’</mi><mrow id="S2.p8.1.m1.2.2.2.4" xref="S2.p8.1.m1.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p8.1.m1.1.1.1.1" xref="S2.p8.1.m1.1.1.1.1.cmml">â„³</mi><mo id="S2.p8.1.m1.2.2.2.4.1" xref="S2.p8.1.m1.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.p8.1.m1.2.2.2.2" xref="S2.p8.1.m1.2.2.2.2.cmml">ğ’¬</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.p8.1.m1.2b"><apply id="S2.p8.1.m1.2.3.cmml" xref="S2.p8.1.m1.2.3"><csymbol cd="ambiguous" id="S2.p8.1.m1.2.3.1.cmml" xref="S2.p8.1.m1.2.3">subscript</csymbol><ci id="S2.p8.1.m1.2.3.2.cmml" xref="S2.p8.1.m1.2.3.2">â„’</ci><list id="S2.p8.1.m1.2.2.2.3.cmml" xref="S2.p8.1.m1.2.2.2.4"><ci id="S2.p8.1.m1.1.1.1.1.cmml" xref="S2.p8.1.m1.1.1.1.1">â„³</ci><ci id="S2.p8.1.m1.2.2.2.2.cmml" xref="S2.p8.1.m1.2.2.2.2">ğ’¬</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.1.m1.2c">\mathcal{L}_{\mathcal{M},\mathcal{Q}}</annotation></semantics></math> is higher for one model compared to another, then we assert that the former is more knowledgeable with regards to <math id="S2.p8.2.m2.1" class="ltx_Math" alttext="\mathcal{Q}" display="inline"><semantics id="S2.p8.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p8.2.m2.1.1" xref="S2.p8.2.m2.1.1.cmml">ğ’¬</mi><annotation-xml encoding="MathML-Content" id="S2.p8.2.m2.1b"><ci id="S2.p8.2.m2.1.1.cmml" xref="S2.p8.2.m2.1.1">ğ’¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.2.m2.1c">\mathcal{Q}</annotation></semantics></math> compared to the latter.</p>
</div>
<div id="S2.p9" class="ltx_para">
<p id="S2.p9.1" class="ltx_p"><span id="S2.p9.1.1" class="ltx_text ltx_font_bold">Previously Seen Knowledge</span> â€ƒOne important distinction to make is between knowledge that the model has been exposed to before during pre-training as opposed to entirely new facts. Considering the size of modern LLM training sets, they cover a vast amount of information available through web-sourced text. As a result, even in niche domains, the goal of knowledge injection is not necessarily to teach the model entirely new facts but rather to â€refreshâ€ its memory by inducing a bias toward a particular domain.</p>
</div>
<div id="S2.p10" class="ltx_para">
<p id="S2.p10.1" class="ltx_p"><span id="S2.p10.1.1" class="ltx_text ltx_font_bold">Knowledge and Reasoning</span> â€ƒWe emphasize that this knowledge evaluation framework for LLMs is imperfect. Importantly, it doesnâ€™t address other quality metrics influencing a modelâ€™s response. Creating a purely knowledge-intensive dataset without involving some level of reasoning is challenging. Consequently, a model with robust reasoning abilities might excel on unfamiliar knowledge-intensive tasks by making â€educated guessesâ€ in a multiple-choice exam. Therefore, any evaluation of knowledge in LLMs should consider this, with results seen as part of a broader range of benchmarks for reasoning <cite class="ltx_cite ltx_citemacro_citep">(Sakaguchi et&nbsp;al., <a href="#bib.bib35" title="" class="ltx_ref">2021</a>)</cite>, reading comprehension <cite class="ltx_cite ltx_citemacro_citep">(Dua et&nbsp;al., <a href="#bib.bib9" title="" class="ltx_ref">2019</a>)</cite>, and general language abilities <cite class="ltx_cite ltx_citemacro_citep">(Srivastava et&nbsp;al., <a href="#bib.bib41" title="" class="ltx_ref">2022</a>)</cite>. However, this evaluation framework still strongly emphasizes factual information above all else.</p>
</div>
<div id="S2.p11" class="ltx_para">
<p id="S2.p11.1" class="ltx_p"><span id="S2.p11.1.1" class="ltx_text ltx_font_bold">Causes for Factual Errors</span> â€ƒThere are many possible reasons for the failure of models to answer factual questions accurately. In <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib47" title="" class="ltx_ref">2023</a>)</cite>, Wang <span id="S2.p11.1.2" class="ltx_text ltx_font_italic">et al.</span> introduce a taxonomy of five main model-level causes:</p>
</div>
<div id="S2.p12" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Domain knowledge deficit</span>: A language model may lack comprehensive expertise in a specific domain to which it has not been exposed. For example, a model trained exclusively on texts written by William Shakespeare would perform poorly when asked about the works of Mark Twain.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Outdated Information</span>: LLMs invariably have a cutoff date determined by their training dataset. Consequently, any events, discoveries, or changes occurring after the last training update will not be within the modelâ€™s knowledge without access to external sources.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Immemorization</span>: Sometimes, a model is exposed to knowledge during its training process but does not retain it. This is especially true for rare facts that appear in the training dataset only scarcely <cite class="ltx_cite ltx_citemacro_citep">(Kandpal et&nbsp;al., <a href="#bib.bib17" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><span id="S2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Forgetting</span>: Language models often undergo additional training after the pre-training phase (fine-tuning). In some cases, this might lead to a phenomenon called <span id="S2.I1.i4.p1.1.2" class="ltx_text ltx_font_italic">catastrophic forgetting</span> <cite class="ltx_cite ltx_citemacro_citep">(Kirkpatrick et&nbsp;al., <a href="#bib.bib18" title="" class="ltx_ref">2017</a>; Goodfellow et&nbsp;al., <a href="#bib.bib11" title="" class="ltx_ref">2013</a>; Chen et&nbsp;al., <a href="#bib.bib3" title="" class="ltx_ref">2020</a>; Luo et&nbsp;al., <a href="#bib.bib23" title="" class="ltx_ref">2023</a>)</cite>, where models lose some of the knowledge they had prior to the fine-tuning process.</p>
</div>
</li>
<li id="S2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i5.p1" class="ltx_para">
<p id="S2.I1.i5.p1.1" class="ltx_p"><span id="S2.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Reasoning Failure</span>: In certain instances, a language model might possess relevant knowledge about a fact but fail to utilize it properly. This is particularly evident in complex multi-step reasoning tasks <cite class="ltx_cite ltx_citemacro_citep">(Tan et&nbsp;al., <a href="#bib.bib42" title="" class="ltx_ref">2023</a>)</cite> or when posed with different questions about the same fact, resulting in disparate outcomes <cite class="ltx_cite ltx_citemacro_citep">(Berglund et&nbsp;al., <a href="#bib.bib2" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
</li>
</ul>
</div>
<div id="S2.p13" class="ltx_para">
<p id="S2.p13.1" class="ltx_p">We observe that most of these issues arise during the pre-training phase, with catastrophic forgetting being the notable exception. Hence, many LLMs will suffer from factual errors of this kind regardless of any post-training process.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Injecting Knowledge to Language Models</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Following the background given in <a href="#S2" title="2 Background â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>, it is clear that general pre-training is insufficient for many knowledge-intensive tasks. To solve this, an additional post-processing step is essential to augment the knowledge of a pre-trained model. This step is often reffered to as <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">knowledge injection</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib48" title="" class="ltx_ref">2020</a>; Chen et&nbsp;al., <a href="#bib.bib4" title="" class="ltx_ref">2022</a>; Liu et&nbsp;al., <a href="#bib.bib22" title="" class="ltx_ref">2020</a>; Lauscher et&nbsp;al., <a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">In this section, we examine two widely used frameworks for knowledge injection: fine-tuning (FT) and retrieval augmented generation (RAG). We begin by formulating the knowledge injection problem, aiming to explain both methods using consistent terminology.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Problem formulation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In <a href="#S2.E1" title="In 2 Background â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Equations</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a> and&nbsp;<a href="#S2.E2" title="Equation 2 â€£ 2 Background â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we presented a formulation for knowledge in language models through the lens of question-answering (Q&amp;A). We now extend this formulation to the problem of knowledge injection using the same terminology.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Given a set of factual questions, there exists some text corpus containing information that is relevant to these questions. The central assumption of knowledge injection is that given full access to this corpus, it could serve as an auxiliary knowledge base and improve the modelâ€™s performance on this set of questions.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.5" class="ltx_p">Mathematically, let <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\mathcal{M}</annotation></semantics></math> be a pre-trained model, and let <math id="S3.SS1.p3.2.m2.1" class="ltx_Math" alttext="\mathcal{Q}" display="inline"><semantics id="S3.SS1.p3.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">ğ’¬</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">ğ’¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">\mathcal{Q}</annotation></semantics></math> be a set of factual questions, as before. Now, assume we have a relevant auxiliary knowledge base <math id="S3.SS1.p3.3.m3.1" class="ltx_Math" alttext="\mathcal{B}_{\mathcal{Q}}" display="inline"><semantics id="S3.SS1.p3.3.m3.1a"><msub id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">â„¬</mi><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml">ğ’¬</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2">â„¬</ci><ci id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3">ğ’¬</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">\mathcal{B}_{\mathcal{Q}}</annotation></semantics></math>. Our objective is to discover a transformation, denoted as <math id="S3.SS1.p3.4.m4.1" class="ltx_Math" alttext="\mathcal{F}" display="inline"><semantics id="S3.SS1.p3.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml">â„±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><ci id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">â„±</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">\mathcal{F}</annotation></semantics></math>, that, when applied, would enhance the knowledge about <math id="S3.SS1.p3.5.m5.1" class="ltx_Math" alttext="\mathcal{Q}" display="inline"><semantics id="S3.SS1.p3.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml">ğ’¬</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><ci id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">ğ’¬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">\mathcal{Q}</annotation></semantics></math>:</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.7" class="ltx_math_unparsed" alttext="\mathcal{M^{\prime}}:=\mathcal{F}(\mathcal{M},\mathcal{B}_{\mathcal{Q}})\quad s.t.\quad\mathcal{L}_{\mathcal{M^{\prime}},\mathcal{Q}}>\mathcal{L}_{\mathcal{M},\mathcal{Q}}." display="block"><semantics id="S3.E3.m1.7a"><mrow id="S3.E3.m1.7b"><msup id="S3.E3.m1.7.8"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.8.2">â„³</mi><mo id="S3.E3.m1.7.8.3">â€²</mo></msup><mo lspace="0.278em" rspace="0.278em" id="S3.E3.m1.7.9">:=</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.10">â„±</mi><mrow id="S3.E3.m1.7.11"><mo stretchy="false" id="S3.E3.m1.7.11.1">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.5.5">â„³</mi><mo id="S3.E3.m1.7.11.2">,</mo><msub id="S3.E3.m1.7.11.3"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.11.3.2">â„¬</mi><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.11.3.3">ğ’¬</mi></msub><mo stretchy="false" id="S3.E3.m1.7.11.4">)</mo></mrow><mspace width="1em" id="S3.E3.m1.7.12"></mspace><mi id="S3.E3.m1.6.6">s</mi><mo lspace="0em" rspace="0.167em" id="S3.E3.m1.7.13">.</mo><mi id="S3.E3.m1.7.7">t</mi><mo lspace="0em" id="S3.E3.m1.7.14">.</mo><mspace width="1.167em" id="S3.E3.m1.7.15"></mspace><msub id="S3.E3.m1.7.16"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.16.2">â„’</mi><mrow id="S3.E3.m1.2.2.2.2"><msup id="S3.E3.m1.2.2.2.2.1"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.2.2.1.2">â„³</mi><mo id="S3.E3.m1.2.2.2.2.1.3">â€²</mo></msup><mo id="S3.E3.m1.2.2.2.2.2">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1">ğ’¬</mi></mrow></msub><mo id="S3.E3.m1.7.17">&gt;</mo><msub id="S3.E3.m1.7.18"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.18.2">â„’</mi><mrow id="S3.E3.m1.4.4.2.4"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.1.1">â„³</mi><mo id="S3.E3.m1.4.4.2.4.1">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.4.4.2.2">ğ’¬</mi></mrow></msub><mo lspace="0em" id="S3.E3.m1.7.19">.</mo></mrow><annotation encoding="application/x-tex" id="S3.E3.m1.7c">\mathcal{M^{\prime}}:=\mathcal{F}(\mathcal{M},\mathcal{B}_{\mathcal{Q}})\quad s.t.\quad\mathcal{L}_{\mathcal{M^{\prime}},\mathcal{Q}}&gt;\mathcal{L}_{\mathcal{M},\mathcal{Q}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">In this work, we aim to compare two choices for <math id="S3.SS1.p5.1.m1.1" class="ltx_Math" alttext="\mathcal{F}" display="inline"><semantics id="S3.SS1.p5.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml">â„±</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><ci id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1">â„±</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">\mathcal{F}</annotation></semantics></math>: fine-tuning and RAG to see which option performs better in this problem.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Fine-Tuning</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Fine-tuning is the process of adjusting a pre-trained model on a specific, often narrower, dataset or task to enhance its performance in that particular domain. Here, it is vital to distinguish between different types of fine-tuning. FT techniques are commonly classified into supervised, unsupervised, and reinforcement learning (RL) based methods. We proceed by briefly reviewing these methods and their relation to the problem of knowledge injection.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Supervised Fine-Tuning</span> â€ƒSupervised fine-tuning (SFT) requires sets of labeled input-output pairs. One of the most common SFT methods is instruction tuning <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a href="#bib.bib49" title="" class="ltx_ref">2022</a>; Mishra et&nbsp;al., <a href="#bib.bib25" title="" class="ltx_ref">2021</a>; Ouyang et&nbsp;al., <a href="#bib.bib31" title="" class="ltx_ref">2022</a>; Taori et&nbsp;al., <a href="#bib.bib43" title="" class="ltx_ref">2023</a>)</cite>, which has emerged as one of the most powerful methods to improve model performance. With instruction tuning, the input is a natural language task description, and the output is an example of the desired behavior. Many current state-of-the-art LLMs have gone through instruction tuning after their pre-training phase.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">Instruction tuning has been shown to be very effective at improving the overall quality of the model, with a particular emphasis on its zero-shot and reasoning capabilities. However, despite these advantages, instruction tuning does not necessarily teach the model new knowledge <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et&nbsp;al., <a href="#bib.bib31" title="" class="ltx_ref">2022</a>; Chung et&nbsp;al., <a href="#bib.bib7" title="" class="ltx_ref">2022</a>; Mitra et&nbsp;al., <a href="#bib.bib26" title="" class="ltx_ref">2023</a>; Chia et&nbsp;al., <a href="#bib.bib6" title="" class="ltx_ref">2023</a>; Zhou et&nbsp;al., <a href="#bib.bib55" title="" class="ltx_ref">2023</a>)</cite>. As such, instruction tuning alone is not a viable solution to the knowledge injection problem.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p"><span id="S3.SS2.p4.1.1" class="ltx_text ltx_font_bold">Reinforcemnt Learning</span> â€ƒAnother form of FT relies on RL or RL-inspired optimization strategies to better align the model after its pre-training phase. A few prominent examples are reinforcement learning from human feedback (RLHF) <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib30" title="" class="ltx_ref">2023</a>; Touvron et&nbsp;al., <a href="#bib.bib45" title="" class="ltx_ref">2023</a>)</cite>, direct preference optimization (DPO) <cite class="ltx_cite ltx_citemacro_citep">(Rafailov et&nbsp;al., <a href="#bib.bib34" title="" class="ltx_ref">2023</a>)</cite>, and proximal policy optimization (PPO) <cite class="ltx_cite ltx_citemacro_citep">(Schulman et&nbsp;al., <a href="#bib.bib36" title="" class="ltx_ref">2017</a>; Tunstall et&nbsp;al., <a href="#bib.bib46" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.1" class="ltx_p">These techniques have been shown to be very useful, especially when used in conjunction with instruction tuning. However, similarly to instruction tuning, these methods focus on the overall quality of the response and its expected behavior and not necessarily on its breadth of knowledge.</p>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p id="S3.SS2.p6.1" class="ltx_p"><span id="S3.SS2.p6.1.1" class="ltx_text ltx_font_bold">Unsupervised Fine-Tuning</span> â€ƒThe final FT strategy we discuss is unsupervised, meaning there are no available labels for the model to learn from. One common unsupervised FT technique is often referred to as <span id="S3.SS2.p6.1.2" class="ltx_text ltx_font_italic">continual pre-training</span> or <span id="S3.SS2.p6.1.3" class="ltx_text ltx_font_italic">unstructured</span> FT.</p>
</div>
<div id="S3.SS2.p7" class="ltx_para">
<p id="S3.SS2.p7.1" class="ltx_p">In this method, the FT process is viewed as a direct continuation of the pre-training phase. We start with a saved checkpoint of the original LLM and train it in a causal auto-regressive manner, i.e., predicting the next token. One major difference in comparison to actual pre-training is the learning rate. Usually, one would need a much lower learning rate when continuing the pre-training of the model to avoid catastrophic forgetting <cite class="ltx_cite ltx_citemacro_citep">(Kirkpatrick et&nbsp;al., <a href="#bib.bib18" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S3.SS2.p8" class="ltx_para">
<p id="S3.SS2.p8.1" class="ltx_p">It is well known that LLMs store vast amounts of knowledge during their pre-training phase <cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a href="#bib.bib55" title="" class="ltx_ref">2023</a>)</cite>. So, it makes sense to continue this process in order to inject knowledge into the model. Hence, we use the unsupervised FT approach throughout this work and evaluate its efficacy in enhancing the modelâ€™s capacity for learning new information.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Retrieval Augmented Generation</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Retrieval augmented generation (RAG)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lewis et&nbsp;al., <a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite> is a technique that expands LLMsâ€™ capabilities, especially in knowledge-intensive tasks, by using external knowledge sources. While the original formulation involved additional training per task, it has since been demonstrated&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Neelakantan et&nbsp;al., <a href="#bib.bib27" title="" class="ltx_ref">2022</a>)</cite> that a pre-trained <span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">embedding</span> model can achieve improved performance with no additional training involved.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">The idea is that given an auxiliary knowledge base and an input query, we use the RAG architecture to find documents within the knowledge base that resemble the input query. These documents are then added to the input query, thus giving the model further context about the subject of the query.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.12" class="ltx_p">In practice, implementing the suggested architecture is quite straightforward: Given an auxiliary knowledge base <math id="S3.SS3.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{B}_{\mathcal{Q}}" display="inline"><semantics id="S3.SS3.p3.1.m1.1a"><msub id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">â„¬</mi><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">ğ’¬</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">â„¬</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">ğ’¬</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">\mathcal{B}_{\mathcal{Q}}</annotation></semantics></math> and a pre-trained embedding model <math id="S3.SS3.p3.2.m2.1" class="ltx_Math" alttext="\mathcal{M}_{e}" display="inline"><semantics id="S3.SS3.p3.2.m2.1a"><msub id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">â„³</mi><mi id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2">â„³</ci><ci id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3">ğ‘’</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">\mathcal{M}_{e}</annotation></semantics></math>, we create a dense vector representation (embedding) per document <math id="S3.SS3.p3.3.m3.1" class="ltx_Math" alttext="b\in\mathcal{B}_{\mathcal{Q}}" display="inline"><semantics id="S3.SS3.p3.3.m3.1a"><mrow id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">b</mi><mo id="S3.SS3.p3.3.m3.1.1.1" xref="S3.SS3.p3.3.m3.1.1.1.cmml">âˆˆ</mo><msub id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.3.m3.1.1.3.2" xref="S3.SS3.p3.3.m3.1.1.3.2.cmml">â„¬</mi><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.3.m3.1.1.3.3" xref="S3.SS3.p3.3.m3.1.1.3.3.cmml">ğ’¬</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><in id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1.1"></in><ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">ğ‘</ci><apply id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.3.1.cmml" xref="S3.SS3.p3.3.m3.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.3.2.cmml" xref="S3.SS3.p3.3.m3.1.1.3.2">â„¬</ci><ci id="S3.SS3.p3.3.m3.1.1.3.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3.3">ğ’¬</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">b\in\mathcal{B}_{\mathcal{Q}}</annotation></semantics></math> and store these in a vector store. Upon receiving a new query <math id="S3.SS3.p3.4.m4.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS3.p3.4.m4.1a"><mi id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><ci id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">q</annotation></semantics></math>, we use its embedding, <math id="S3.SS3.p3.5.m5.1" class="ltx_Math" alttext="\mathcal{M}_{e}(q)" display="inline"><semantics id="S3.SS3.p3.5.m5.1a"><mrow id="S3.SS3.p3.5.m5.1.2" xref="S3.SS3.p3.5.m5.1.2.cmml"><msub id="S3.SS3.p3.5.m5.1.2.2" xref="S3.SS3.p3.5.m5.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.5.m5.1.2.2.2" xref="S3.SS3.p3.5.m5.1.2.2.2.cmml">â„³</mi><mi id="S3.SS3.p3.5.m5.1.2.2.3" xref="S3.SS3.p3.5.m5.1.2.2.3.cmml">e</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS3.p3.5.m5.1.2.1" xref="S3.SS3.p3.5.m5.1.2.1.cmml">â€‹</mo><mrow id="S3.SS3.p3.5.m5.1.2.3.2" xref="S3.SS3.p3.5.m5.1.2.cmml"><mo stretchy="false" id="S3.SS3.p3.5.m5.1.2.3.2.1" xref="S3.SS3.p3.5.m5.1.2.cmml">(</mo><mi id="S3.SS3.p3.5.m5.1.1" xref="S3.SS3.p3.5.m5.1.1.cmml">q</mi><mo stretchy="false" id="S3.SS3.p3.5.m5.1.2.3.2.2" xref="S3.SS3.p3.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.1b"><apply id="S3.SS3.p3.5.m5.1.2.cmml" xref="S3.SS3.p3.5.m5.1.2"><times id="S3.SS3.p3.5.m5.1.2.1.cmml" xref="S3.SS3.p3.5.m5.1.2.1"></times><apply id="S3.SS3.p3.5.m5.1.2.2.cmml" xref="S3.SS3.p3.5.m5.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p3.5.m5.1.2.2.1.cmml" xref="S3.SS3.p3.5.m5.1.2.2">subscript</csymbol><ci id="S3.SS3.p3.5.m5.1.2.2.2.cmml" xref="S3.SS3.p3.5.m5.1.2.2.2">â„³</ci><ci id="S3.SS3.p3.5.m5.1.2.2.3.cmml" xref="S3.SS3.p3.5.m5.1.2.2.3">ğ‘’</ci></apply><ci id="S3.SS3.p3.5.m5.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.1c">\mathcal{M}_{e}(q)</annotation></semantics></math>, to retrieve <math id="S3.SS3.p3.6.m6.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS3.p3.6.m6.1a"><mi id="S3.SS3.p3.6.m6.1.1" xref="S3.SS3.p3.6.m6.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.6.m6.1b"><ci id="S3.SS3.p3.6.m6.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.6.m6.1c">q</annotation></semantics></math>â€™s top-<math id="S3.SS3.p3.7.m7.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS3.p3.7.m7.1a"><mi id="S3.SS3.p3.7.m7.1.1" xref="S3.SS3.p3.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.7.m7.1b"><ci id="S3.SS3.p3.7.m7.1.1.cmml" xref="S3.SS3.p3.7.m7.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.7.m7.1c">K</annotation></semantics></math> closest neighbors, <math id="S3.SS3.p3.8.m8.1" class="ltx_Math" alttext="\mathbf{b}_{q}=\{b_{k}\}_{1}^{K}" display="inline"><semantics id="S3.SS3.p3.8.m8.1a"><mrow id="S3.SS3.p3.8.m8.1.1" xref="S3.SS3.p3.8.m8.1.1.cmml"><msub id="S3.SS3.p3.8.m8.1.1.3" xref="S3.SS3.p3.8.m8.1.1.3.cmml"><mi id="S3.SS3.p3.8.m8.1.1.3.2" xref="S3.SS3.p3.8.m8.1.1.3.2.cmml">ğ›</mi><mi id="S3.SS3.p3.8.m8.1.1.3.3" xref="S3.SS3.p3.8.m8.1.1.3.3.cmml">q</mi></msub><mo id="S3.SS3.p3.8.m8.1.1.2" xref="S3.SS3.p3.8.m8.1.1.2.cmml">=</mo><msubsup id="S3.SS3.p3.8.m8.1.1.1" xref="S3.SS3.p3.8.m8.1.1.1.cmml"><mrow id="S3.SS3.p3.8.m8.1.1.1.1.1.1" xref="S3.SS3.p3.8.m8.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS3.p3.8.m8.1.1.1.1.1.1.2" xref="S3.SS3.p3.8.m8.1.1.1.1.1.2.cmml">{</mo><msub id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.2" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.2.cmml">b</mi><mi id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.3" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.3.cmml">k</mi></msub><mo stretchy="false" id="S3.SS3.p3.8.m8.1.1.1.1.1.1.3" xref="S3.SS3.p3.8.m8.1.1.1.1.1.2.cmml">}</mo></mrow><mn id="S3.SS3.p3.8.m8.1.1.1.1.3" xref="S3.SS3.p3.8.m8.1.1.1.1.3.cmml">1</mn><mi id="S3.SS3.p3.8.m8.1.1.1.3" xref="S3.SS3.p3.8.m8.1.1.1.3.cmml">K</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.8.m8.1b"><apply id="S3.SS3.p3.8.m8.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1"><eq id="S3.SS3.p3.8.m8.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.2"></eq><apply id="S3.SS3.p3.8.m8.1.1.3.cmml" xref="S3.SS3.p3.8.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.3.1.cmml" xref="S3.SS3.p3.8.m8.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.8.m8.1.1.3.2.cmml" xref="S3.SS3.p3.8.m8.1.1.3.2">ğ›</ci><ci id="S3.SS3.p3.8.m8.1.1.3.3.cmml" xref="S3.SS3.p3.8.m8.1.1.3.3">ğ‘</ci></apply><apply id="S3.SS3.p3.8.m8.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.1">superscript</csymbol><apply id="S3.SS3.p3.8.m8.1.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.1">subscript</csymbol><set id="S3.SS3.p3.8.m8.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1"><apply id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.2">ğ‘</ci><ci id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.3">ğ‘˜</ci></apply></set><cn type="integer" id="S3.SS3.p3.8.m8.1.1.1.1.3.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.3">1</cn></apply><ci id="S3.SS3.p3.8.m8.1.1.1.3.cmml" xref="S3.SS3.p3.8.m8.1.1.1.3">ğ¾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.8.m8.1c">\mathbf{b}_{q}=\{b_{k}\}_{1}^{K}</annotation></semantics></math>, according to dot-product ranking. We then update <math id="S3.SS3.p3.9.m9.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S3.SS3.p3.9.m9.1a"><mi id="S3.SS3.p3.9.m9.1.1" xref="S3.SS3.p3.9.m9.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.9.m9.1b"><ci id="S3.SS3.p3.9.m9.1.1.cmml" xref="S3.SS3.p3.9.m9.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.9.m9.1c">q</annotation></semantics></math> to be <math id="S3.SS3.p3.10.m10.1" class="ltx_Math" alttext="\tilde{q}=\mathbf{b}_{q}\|q" display="inline"><semantics id="S3.SS3.p3.10.m10.1a"><mrow id="S3.SS3.p3.10.m10.1.1" xref="S3.SS3.p3.10.m10.1.1.cmml"><mover accent="true" id="S3.SS3.p3.10.m10.1.1.2" xref="S3.SS3.p3.10.m10.1.1.2.cmml"><mi id="S3.SS3.p3.10.m10.1.1.2.2" xref="S3.SS3.p3.10.m10.1.1.2.2.cmml">q</mi><mo id="S3.SS3.p3.10.m10.1.1.2.1" xref="S3.SS3.p3.10.m10.1.1.2.1.cmml">~</mo></mover><mo id="S3.SS3.p3.10.m10.1.1.1" xref="S3.SS3.p3.10.m10.1.1.1.cmml">=</mo><mrow id="S3.SS3.p3.10.m10.1.1.3" xref="S3.SS3.p3.10.m10.1.1.3.cmml"><msub id="S3.SS3.p3.10.m10.1.1.3.2" xref="S3.SS3.p3.10.m10.1.1.3.2.cmml"><mi id="S3.SS3.p3.10.m10.1.1.3.2.2" xref="S3.SS3.p3.10.m10.1.1.3.2.2.cmml">ğ›</mi><mi id="S3.SS3.p3.10.m10.1.1.3.2.3" xref="S3.SS3.p3.10.m10.1.1.3.2.3.cmml">q</mi></msub><mo id="S3.SS3.p3.10.m10.1.1.3.1" xref="S3.SS3.p3.10.m10.1.1.3.1.cmml">âˆ¥</mo><mi id="S3.SS3.p3.10.m10.1.1.3.3" xref="S3.SS3.p3.10.m10.1.1.3.3.cmml">q</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.10.m10.1b"><apply id="S3.SS3.p3.10.m10.1.1.cmml" xref="S3.SS3.p3.10.m10.1.1"><eq id="S3.SS3.p3.10.m10.1.1.1.cmml" xref="S3.SS3.p3.10.m10.1.1.1"></eq><apply id="S3.SS3.p3.10.m10.1.1.2.cmml" xref="S3.SS3.p3.10.m10.1.1.2"><ci id="S3.SS3.p3.10.m10.1.1.2.1.cmml" xref="S3.SS3.p3.10.m10.1.1.2.1">~</ci><ci id="S3.SS3.p3.10.m10.1.1.2.2.cmml" xref="S3.SS3.p3.10.m10.1.1.2.2">ğ‘</ci></apply><apply id="S3.SS3.p3.10.m10.1.1.3.cmml" xref="S3.SS3.p3.10.m10.1.1.3"><csymbol cd="latexml" id="S3.SS3.p3.10.m10.1.1.3.1.cmml" xref="S3.SS3.p3.10.m10.1.1.3.1">conditional</csymbol><apply id="S3.SS3.p3.10.m10.1.1.3.2.cmml" xref="S3.SS3.p3.10.m10.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS3.p3.10.m10.1.1.3.2.1.cmml" xref="S3.SS3.p3.10.m10.1.1.3.2">subscript</csymbol><ci id="S3.SS3.p3.10.m10.1.1.3.2.2.cmml" xref="S3.SS3.p3.10.m10.1.1.3.2.2">ğ›</ci><ci id="S3.SS3.p3.10.m10.1.1.3.2.3.cmml" xref="S3.SS3.p3.10.m10.1.1.3.2.3">ğ‘</ci></apply><ci id="S3.SS3.p3.10.m10.1.1.3.3.cmml" xref="S3.SS3.p3.10.m10.1.1.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.10.m10.1c">\tilde{q}=\mathbf{b}_{q}\|q</annotation></semantics></math>, where <math id="S3.SS3.p3.11.m11.1" class="ltx_Math" alttext="\|" display="inline"><semantics id="S3.SS3.p3.11.m11.1a"><mo id="S3.SS3.p3.11.m11.1.1" xref="S3.SS3.p3.11.m11.1.1.cmml">âˆ¥</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.11.m11.1b"><ci id="S3.SS3.p3.11.m11.1.1.cmml" xref="S3.SS3.p3.11.m11.1.1">âˆ¥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.11.m11.1c">\|</annotation></semantics></math> denotes string concatenation. Finally, we return <math id="S3.SS3.p3.12.m12.1" class="ltx_Math" alttext="\mathcal{M}(\tilde{q})" display="inline"><semantics id="S3.SS3.p3.12.m12.1a"><mrow id="S3.SS3.p3.12.m12.1.2" xref="S3.SS3.p3.12.m12.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.12.m12.1.2.2" xref="S3.SS3.p3.12.m12.1.2.2.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S3.SS3.p3.12.m12.1.2.1" xref="S3.SS3.p3.12.m12.1.2.1.cmml">â€‹</mo><mrow id="S3.SS3.p3.12.m12.1.2.3.2" xref="S3.SS3.p3.12.m12.1.1.cmml"><mo stretchy="false" id="S3.SS3.p3.12.m12.1.2.3.2.1" xref="S3.SS3.p3.12.m12.1.1.cmml">(</mo><mover accent="true" id="S3.SS3.p3.12.m12.1.1" xref="S3.SS3.p3.12.m12.1.1.cmml"><mi id="S3.SS3.p3.12.m12.1.1.2" xref="S3.SS3.p3.12.m12.1.1.2.cmml">q</mi><mo id="S3.SS3.p3.12.m12.1.1.1" xref="S3.SS3.p3.12.m12.1.1.1.cmml">~</mo></mover><mo stretchy="false" id="S3.SS3.p3.12.m12.1.2.3.2.2" xref="S3.SS3.p3.12.m12.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.12.m12.1b"><apply id="S3.SS3.p3.12.m12.1.2.cmml" xref="S3.SS3.p3.12.m12.1.2"><times id="S3.SS3.p3.12.m12.1.2.1.cmml" xref="S3.SS3.p3.12.m12.1.2.1"></times><ci id="S3.SS3.p3.12.m12.1.2.2.cmml" xref="S3.SS3.p3.12.m12.1.2.2">â„³</ci><apply id="S3.SS3.p3.12.m12.1.1.cmml" xref="S3.SS3.p3.12.m12.1.2.3.2"><ci id="S3.SS3.p3.12.m12.1.1.1.cmml" xref="S3.SS3.p3.12.m12.1.1.1">~</ci><ci id="S3.SS3.p3.12.m12.1.1.2.cmml" xref="S3.SS3.p3.12.m12.1.1.2">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.12.m12.1c">\mathcal{M}(\tilde{q})</annotation></semantics></math> as the modelâ€™s output.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Knowledge Base Creation</h2>

<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S4.T1.3.2" class="ltx_text" style="font-size:90%;">Results for the MMLU datasets described in <a href="#S4.SS1" title="4.1 Task Selection and Rationale â€£ 4 Knowledge Base Creation â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.1</span></a> in terms of log-likelihood accuracy (<a href="#S5.E4" title="In 5 Experiments and Results â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Equation</span>&nbsp;<span class="ltx_text ltx_ref_tag">4</span></a>). </span></figcaption>
<br class="ltx_break">
<table id="S4.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.4.1.1" class="ltx_tr">
<th id="S4.T1.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S4.T1.4.1.1.1.1" class="ltx_text" style="font-size:90%;">Task</span></th>
<th id="S4.T1.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt"><span id="S4.T1.4.1.1.2.1" class="ltx_text" style="font-size:90%;">Model</span></th>
<th id="S4.T1.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.4.1.1.3.1" class="ltx_text" style="font-size:90%;">Base model</span></th>
<th id="S4.T1.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.4.1.1.4.1" class="ltx_text" style="font-size:90%;">Base model + RAG</span></th>
<th id="S4.T1.4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.4.1.1.5.1" class="ltx_text" style="font-size:90%;">Fine-tuned</span></th>
<th id="S4.T1.4.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.4.1.1.6.1" class="ltx_text" style="font-size:90%;">Fine-tuned + RAG</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.4.2.1" class="ltx_tr">
<th id="S4.T1.4.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S4.T1.4.2.1.1.1" class="ltx_text" style="font-size:90%;">Anatomy (0-shot)</span></th>
<th id="S4.T1.4.2.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T1.4.2.1.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.2.1.3.1" class="ltx_text" style="font-size:90%;">0.556</span></td>
<td id="S4.T1.4.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.2.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.681</span></td>
<td id="S4.T1.4.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.2.1.5.1" class="ltx_text" style="font-size:90%;">0.570</span></td>
<td id="S4.T1.4.2.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.2.1.6.1" class="ltx_text" style="font-size:90%;">0.659</span></td>
</tr>
<tr id="S4.T1.4.3.2" class="ltx_tr">
<th id="S4.T1.4.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.3.2.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.3.2.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.3.2.2.1" class="ltx_text" style="font-size:90%;">0.393</span></td>
<td id="S4.T1.4.3.2.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.3.2.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.489</span></td>
<td id="S4.T1.4.3.2.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.3.2.4.1" class="ltx_text" style="font-size:90%;">0.430</span></td>
<td id="S4.T1.4.3.2.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.3.2.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.489</span></td>
</tr>
<tr id="S4.T1.4.4.3" class="ltx_tr">
<th id="S4.T1.4.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.4.3.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.4.3.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.3.2.1" class="ltx_text" style="font-size:90%;">0.607</span></td>
<td id="S4.T1.4.4.3.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.3.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.637</span></td>
<td id="S4.T1.4.4.3.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.3.4.1" class="ltx_text" style="font-size:90%;">0.600</span></td>
<td id="S4.T1.4.4.3.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.4.3.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.637</span></td>
</tr>
<tr id="S4.T1.4.5.4" class="ltx_tr">
<th id="S4.T1.4.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="S4.T1.4.5.4.1.1" class="ltx_text" style="font-size:90%;">Anatomy (5-shot)</span></th>
<th id="S4.T1.4.5.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.5.4.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.5.4.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.5.4.3.1" class="ltx_text" style="font-size:90%;">0.600</span></td>
<td id="S4.T1.4.5.4.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.5.4.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.681</span></td>
<td id="S4.T1.4.5.4.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.5.4.5.1" class="ltx_text" style="font-size:90%;">0.622</span></td>
<td id="S4.T1.4.5.4.6" class="ltx_td ltx_align_center"><span id="S4.T1.4.5.4.6.1" class="ltx_text" style="font-size:90%;">0.674</span></td>
</tr>
<tr id="S4.T1.4.6.5" class="ltx_tr">
<th id="S4.T1.4.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.6.5.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.6.5.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.6.5.2.1" class="ltx_text" style="font-size:90%;">0.467</span></td>
<td id="S4.T1.4.6.5.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.6.5.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.563</span></td>
<td id="S4.T1.4.6.5.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.6.5.4.1" class="ltx_text" style="font-size:90%;">0.496</span></td>
<td id="S4.T1.4.6.5.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.6.5.5.1" class="ltx_text" style="font-size:90%;">0.548</span></td>
</tr>
<tr id="S4.T1.4.7.6" class="ltx_tr">
<th id="S4.T1.4.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.7.6.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.7.6.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.7.6.2.1" class="ltx_text" style="font-size:90%;">0.570</span></td>
<td id="S4.T1.4.7.6.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.7.6.3.1" class="ltx_text" style="font-size:90%;">0.659</span></td>
<td id="S4.T1.4.7.6.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.7.6.4.1" class="ltx_text" style="font-size:90%;">0.593</span></td>
<td id="S4.T1.4.7.6.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.7.6.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.674</span></td>
</tr>
<tr id="S4.T1.4.8.7" class="ltx_tr">
<th id="S4.T1.4.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S4.T1.4.8.7.1.1" class="ltx_text" style="font-size:90%;">Astronomy (0-shot)</span></th>
<th id="S4.T1.4.8.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T1.4.8.7.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.8.7.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.8.7.3.1" class="ltx_text" style="font-size:90%;">0.625</span></td>
<td id="S4.T1.4.8.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.8.7.4.1" class="ltx_text" style="font-size:90%;">0.678</span></td>
<td id="S4.T1.4.8.7.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.8.7.5.1" class="ltx_text" style="font-size:90%;">0.651</span></td>
<td id="S4.T1.4.8.7.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.8.7.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.697</span></td>
</tr>
<tr id="S4.T1.4.9.8" class="ltx_tr">
<th id="S4.T1.4.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.9.8.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.9.8.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.9.8.2.1" class="ltx_text" style="font-size:90%;">0.401</span></td>
<td id="S4.T1.4.9.8.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.9.8.3.1" class="ltx_text" style="font-size:90%;">0.467</span></td>
<td id="S4.T1.4.9.8.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.9.8.4.1" class="ltx_text" style="font-size:90%;">0.487</span></td>
<td id="S4.T1.4.9.8.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.9.8.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.520</span></td>
</tr>
<tr id="S4.T1.4.10.9" class="ltx_tr">
<th id="S4.T1.4.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.10.9.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.10.9.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.10.9.2.1" class="ltx_text" style="font-size:90%;">0.645</span></td>
<td id="S4.T1.4.10.9.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.10.9.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.750</span></td>
<td id="S4.T1.4.10.9.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.10.9.4.1" class="ltx_text" style="font-size:90%;">0.651</span></td>
<td id="S4.T1.4.10.9.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.10.9.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.750</span></td>
</tr>
<tr id="S4.T1.4.11.10" class="ltx_tr">
<th id="S4.T1.4.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="S4.T1.4.11.10.1.1" class="ltx_text" style="font-size:90%;">Astronomy (5-shot)</span></th>
<th id="S4.T1.4.11.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.11.10.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.11.10.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.11.10.3.1" class="ltx_text" style="font-size:90%;">0.658</span></td>
<td id="S4.T1.4.11.10.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.11.10.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.724</span></td>
<td id="S4.T1.4.11.10.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.11.10.5.1" class="ltx_text" style="font-size:90%;">0.651</span></td>
<td id="S4.T1.4.11.10.6" class="ltx_td ltx_align_center"><span id="S4.T1.4.11.10.6.1" class="ltx_text" style="font-size:90%;">0.697</span></td>
</tr>
<tr id="S4.T1.4.12.11" class="ltx_tr">
<th id="S4.T1.4.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.12.11.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.12.11.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.12.11.2.1" class="ltx_text" style="font-size:90%;">0.401</span></td>
<td id="S4.T1.4.12.11.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.12.11.3.1" class="ltx_text" style="font-size:90%;">0.474</span></td>
<td id="S4.T1.4.12.11.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.12.11.4.1" class="ltx_text" style="font-size:90%;">0.447</span></td>
<td id="S4.T1.4.12.11.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.12.11.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.520</span></td>
</tr>
<tr id="S4.T1.4.13.12" class="ltx_tr">
<th id="S4.T1.4.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.13.12.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.13.12.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.13.12.2.1" class="ltx_text" style="font-size:90%;">0.664</span></td>
<td id="S4.T1.4.13.12.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.13.12.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.763</span></td>
<td id="S4.T1.4.13.12.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.13.12.4.1" class="ltx_text" style="font-size:90%;">0.664</span></td>
<td id="S4.T1.4.13.12.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.13.12.5.1" class="ltx_text" style="font-size:90%;">0.743</span></td>
</tr>
<tr id="S4.T1.4.14.13" class="ltx_tr">
<th id="S4.T1.4.14.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S4.T1.4.14.13.1.1" class="ltx_text" style="font-size:90%;">College biology (0-shot)</span></th>
<th id="S4.T1.4.14.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T1.4.14.13.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.14.13.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.14.13.3.1" class="ltx_text" style="font-size:90%;">0.681</span></td>
<td id="S4.T1.4.14.13.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.14.13.4.1" class="ltx_text" style="font-size:90%;">0.757</span></td>
<td id="S4.T1.4.14.13.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.14.13.5.1" class="ltx_text" style="font-size:90%;">0.701</span></td>
<td id="S4.T1.4.14.13.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.14.13.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.764</span></td>
</tr>
<tr id="S4.T1.4.15.14" class="ltx_tr">
<th id="S4.T1.4.15.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.15.14.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.15.14.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.15.14.2.1" class="ltx_text" style="font-size:90%;">0.438</span></td>
<td id="S4.T1.4.15.14.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.15.14.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.493</span></td>
<td id="S4.T1.4.15.14.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.15.14.4.1" class="ltx_text" style="font-size:90%;">0.458</span></td>
<td id="S4.T1.4.15.14.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.15.14.5.1" class="ltx_text" style="font-size:90%;">0.465</span></td>
</tr>
<tr id="S4.T1.4.16.15" class="ltx_tr">
<th id="S4.T1.4.16.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.16.15.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.16.15.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.16.15.2.1" class="ltx_text" style="font-size:90%;">0.583</span></td>
<td id="S4.T1.4.16.15.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.16.15.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.639</span></td>
<td id="S4.T1.4.16.15.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.16.15.4.1" class="ltx_text" style="font-size:90%;">0.604</span></td>
<td id="S4.T1.4.16.15.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.16.15.5.1" class="ltx_text" style="font-size:90%;">0.632</span></td>
</tr>
<tr id="S4.T1.4.17.16" class="ltx_tr">
<th id="S4.T1.4.17.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="S4.T1.4.17.16.1.1" class="ltx_text" style="font-size:90%;">College biology (5-shot)</span></th>
<th id="S4.T1.4.17.16.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.17.16.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.17.16.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.17.16.3.1" class="ltx_text" style="font-size:90%;">0.722</span></td>
<td id="S4.T1.4.17.16.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.17.16.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.778</span></td>
<td id="S4.T1.4.17.16.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.17.16.5.1" class="ltx_text" style="font-size:90%;">0.736</span></td>
<td id="S4.T1.4.17.16.6" class="ltx_td ltx_align_center"><span id="S4.T1.4.17.16.6.1" class="ltx_text" style="font-size:90%;">0.771</span></td>
</tr>
<tr id="S4.T1.4.18.17" class="ltx_tr">
<th id="S4.T1.4.18.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.18.17.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.18.17.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.18.17.2.1" class="ltx_text" style="font-size:90%;">0.451</span></td>
<td id="S4.T1.4.18.17.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.18.17.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.521</span></td>
<td id="S4.T1.4.18.17.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.18.17.4.1" class="ltx_text" style="font-size:90%;">0.424</span></td>
<td id="S4.T1.4.18.17.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.18.17.5.1" class="ltx_text" style="font-size:90%;">0.479</span></td>
</tr>
<tr id="S4.T1.4.19.18" class="ltx_tr">
<th id="S4.T1.4.19.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.19.18.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.19.18.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.19.18.2.1" class="ltx_text" style="font-size:90%;">0.604</span></td>
<td id="S4.T1.4.19.18.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.19.18.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.660</span></td>
<td id="S4.T1.4.19.18.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.19.18.4.1" class="ltx_text" style="font-size:90%;">0.625</span></td>
<td id="S4.T1.4.19.18.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.19.18.5.1" class="ltx_text" style="font-size:90%;">0.653</span></td>
</tr>
<tr id="S4.T1.4.20.19" class="ltx_tr">
<th id="S4.T1.4.20.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S4.T1.4.20.19.1.1" class="ltx_text" style="font-size:90%;">College chemistry (0-shot)</span></th>
<th id="S4.T1.4.20.19.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T1.4.20.19.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.20.19.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.20.19.3.1" class="ltx_text" style="font-size:90%;">0.470</span></td>
<td id="S4.T1.4.20.19.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.20.19.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.500</span></td>
<td id="S4.T1.4.20.19.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.20.19.5.1" class="ltx_text" style="font-size:90%;">0.490</span></td>
<td id="S4.T1.4.20.19.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.20.19.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.500</span></td>
</tr>
<tr id="S4.T1.4.21.20" class="ltx_tr">
<th id="S4.T1.4.21.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.21.20.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.21.20.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.21.20.2.1" class="ltx_text" style="font-size:90%;">0.310</span></td>
<td id="S4.T1.4.21.20.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.21.20.3.1" class="ltx_text" style="font-size:90%;">0.380</span></td>
<td id="S4.T1.4.21.20.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.21.20.4.1" class="ltx_text" style="font-size:90%;">0.390</span></td>
<td id="S4.T1.4.21.20.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.21.20.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.390</span></td>
</tr>
<tr id="S4.T1.4.22.21" class="ltx_tr">
<th id="S4.T1.4.22.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.22.21.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.22.21.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.22.21.2.1" class="ltx_text" style="font-size:90%;">0.370</span></td>
<td id="S4.T1.4.22.21.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.22.21.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.440</span></td>
<td id="S4.T1.4.22.21.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.22.21.4.1" class="ltx_text" style="font-size:90%;">0.370</span></td>
<td id="S4.T1.4.22.21.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.22.21.5.1" class="ltx_text" style="font-size:90%;">0.390</span></td>
</tr>
<tr id="S4.T1.4.23.22" class="ltx_tr">
<th id="S4.T1.4.23.22.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="S4.T1.4.23.22.1.1" class="ltx_text" style="font-size:90%;">College chemistry (5-shot)</span></th>
<th id="S4.T1.4.23.22.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.23.22.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.23.22.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.23.22.3.1" class="ltx_text" style="font-size:90%;">0.470</span></td>
<td id="S4.T1.4.23.22.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.23.22.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.540</span></td>
<td id="S4.T1.4.23.22.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.23.22.5.1" class="ltx_text" style="font-size:90%;">0.500</span></td>
<td id="S4.T1.4.23.22.6" class="ltx_td ltx_align_center"><span id="S4.T1.4.23.22.6.1" class="ltx_text" style="font-size:90%;">0.500</span></td>
</tr>
<tr id="S4.T1.4.24.23" class="ltx_tr">
<th id="S4.T1.4.24.23.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.24.23.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.24.23.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.24.23.2.1" class="ltx_text" style="font-size:90%;">0.370</span></td>
<td id="S4.T1.4.24.23.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.24.23.3.1" class="ltx_text" style="font-size:90%;">0.380</span></td>
<td id="S4.T1.4.24.23.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.24.23.4.1" class="ltx_text" style="font-size:90%;">0.360</span></td>
<td id="S4.T1.4.24.23.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.24.23.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.390</span></td>
</tr>
<tr id="S4.T1.4.25.24" class="ltx_tr">
<th id="S4.T1.4.25.24.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.25.24.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.25.24.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.25.24.2.1" class="ltx_text" style="font-size:90%;">0.430</span></td>
<td id="S4.T1.4.25.24.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.25.24.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.470</span></td>
<td id="S4.T1.4.25.24.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.25.24.4.1" class="ltx_text" style="font-size:90%;">0.370</span></td>
<td id="S4.T1.4.25.24.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.25.24.5.1" class="ltx_text" style="font-size:90%;">0.380</span></td>
</tr>
<tr id="S4.T1.4.26.25" class="ltx_tr">
<th id="S4.T1.4.26.25.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="S4.T1.4.26.25.1.1" class="ltx_text" style="font-size:90%;">Prehistory (0-shot)</span></th>
<th id="S4.T1.4.26.25.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T1.4.26.25.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.26.25.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.26.25.3.1" class="ltx_text" style="font-size:90%;">0.713</span></td>
<td id="S4.T1.4.26.25.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.26.25.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.750</span></td>
<td id="S4.T1.4.26.25.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.26.25.5.1" class="ltx_text" style="font-size:90%;">0.719</span></td>
<td id="S4.T1.4.26.25.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T1.4.26.25.6.1" class="ltx_text" style="font-size:90%;">0.731</span></td>
</tr>
<tr id="S4.T1.4.27.26" class="ltx_tr">
<th id="S4.T1.4.27.26.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.27.26.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.27.26.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.27.26.2.1" class="ltx_text" style="font-size:90%;">0.448</span></td>
<td id="S4.T1.4.27.26.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.27.26.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.481</span></td>
<td id="S4.T1.4.27.26.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.27.26.4.1" class="ltx_text" style="font-size:90%;">0.457</span></td>
<td id="S4.T1.4.27.26.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.27.26.5.1" class="ltx_text" style="font-size:90%;">0.478</span></td>
</tr>
<tr id="S4.T1.4.28.27" class="ltx_tr">
<th id="S4.T1.4.28.27.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.28.27.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.28.27.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.28.27.2.1" class="ltx_text" style="font-size:90%;">0.642</span></td>
<td id="S4.T1.4.28.27.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.28.27.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.679</span></td>
<td id="S4.T1.4.28.27.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.28.27.4.1" class="ltx_text" style="font-size:90%;">0.673</span></td>
<td id="S4.T1.4.28.27.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.28.27.5.1" class="ltx_text" style="font-size:90%;">0.673</span></td>
</tr>
<tr id="S4.T1.4.29.28" class="ltx_tr">
<th id="S4.T1.4.29.28.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" rowspan="3"><span id="S4.T1.4.29.28.1.1" class="ltx_text" style="font-size:90%;">Prehistory (5-shot)</span></th>
<th id="S4.T1.4.29.28.2" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.29.28.2.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T1.4.29.28.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.29.28.3.1" class="ltx_text" style="font-size:90%;">0.722</span></td>
<td id="S4.T1.4.29.28.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.29.28.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.762</span></td>
<td id="S4.T1.4.29.28.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.29.28.5.1" class="ltx_text" style="font-size:90%;">0.725</span></td>
<td id="S4.T1.4.29.28.6" class="ltx_td ltx_align_center"><span id="S4.T1.4.29.28.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.762</span></td>
</tr>
<tr id="S4.T1.4.30.29" class="ltx_tr">
<th id="S4.T1.4.30.29.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T1.4.30.29.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T1.4.30.29.2" class="ltx_td ltx_align_center"><span id="S4.T1.4.30.29.2.1" class="ltx_text" style="font-size:90%;">0.515</span></td>
<td id="S4.T1.4.30.29.3" class="ltx_td ltx_align_center"><span id="S4.T1.4.30.29.3.1" class="ltx_text" style="font-size:90%;">0.531</span></td>
<td id="S4.T1.4.30.29.4" class="ltx_td ltx_align_center"><span id="S4.T1.4.30.29.4.1" class="ltx_text" style="font-size:90%;">0.503</span></td>
<td id="S4.T1.4.30.29.5" class="ltx_td ltx_align_center"><span id="S4.T1.4.30.29.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.537</span></td>
</tr>
<tr id="S4.T1.4.31.30" class="ltx_tr">
<th id="S4.T1.4.31.30.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S4.T1.4.31.30.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T1.4.31.30.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.31.30.2.1" class="ltx_text" style="font-size:90%;">0.664</span></td>
<td id="S4.T1.4.31.30.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.31.30.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.698</span></td>
<td id="S4.T1.4.31.30.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.31.30.4.1" class="ltx_text" style="font-size:90%;">0.667</span></td>
<td id="S4.T1.4.31.30.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T1.4.31.30.5.1" class="ltx_text" style="font-size:90%;">0.694</span></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.4.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.5.2" class="ltx_text" style="font-size:90%;">Current events results. Models that were fine-tuned on the original dataset are labeled as <span id="S4.T2.5.2.1" class="ltx_text ltx_font_italic">FT-reg</span>, while those trained on the dataset with multiple paraphrases are labeled as <span id="S4.T2.5.2.2" class="ltx_text ltx_font_italic">FT-par</span>.</span></figcaption>
<br class="ltx_break">
<table id="S4.T2.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.6.1.1" class="ltx_tr">
<th id="S4.T2.6.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S4.T2.6.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.6.1.1.2.1" class="ltx_text" style="font-size:90%;">Base model</span></th>
<th id="S4.T2.6.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.6.1.1.3.1" class="ltx_text" style="font-size:90%;">Base model + RAG</span></th>
<th id="S4.T2.6.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.6.1.1.4.1" class="ltx_text" style="font-size:90%;">FT-reg</span></th>
<th id="S4.T2.6.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.6.1.1.5.1" class="ltx_text" style="font-size:90%;">FT-par</span></th>
<th id="S4.T2.6.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.6.1.1.6.1" class="ltx_text" style="font-size:90%;">FT-reg + RAG</span></th>
<th id="S4.T2.6.1.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.6.1.1.7.1" class="ltx_text" style="font-size:90%;">FT-par + RAG</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.6.2.1" class="ltx_tr">
<th id="S4.T2.6.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><span id="S4.T2.6.2.1.1.1" class="ltx_text" style="font-size:90%;">Mistral 7B</span></th>
<td id="S4.T2.6.2.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.6.2.1.2.1" class="ltx_text" style="font-size:90%;">0.481</span></td>
<td id="S4.T2.6.2.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.6.2.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.875</span></td>
<td id="S4.T2.6.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.6.2.1.4.1" class="ltx_text" style="font-size:90%;">0.504</span></td>
<td id="S4.T2.6.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.6.2.1.5.1" class="ltx_text" style="font-size:90%;">0.588</span></td>
<td id="S4.T2.6.2.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.6.2.1.6.1" class="ltx_text" style="font-size:90%;">0.810</span></td>
<td id="S4.T2.6.2.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.6.2.1.7.1" class="ltx_text" style="font-size:90%;">0.830</span></td>
</tr>
<tr id="S4.T2.6.3.2" class="ltx_tr">
<th id="S4.T2.6.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row"><span id="S4.T2.6.3.2.1.1" class="ltx_text" style="font-size:90%;">Llama2 7B</span></th>
<td id="S4.T2.6.3.2.2" class="ltx_td ltx_align_center"><span id="S4.T2.6.3.2.2.1" class="ltx_text" style="font-size:90%;">0.353</span></td>
<td id="S4.T2.6.3.2.3" class="ltx_td ltx_align_center"><span id="S4.T2.6.3.2.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.585</span></td>
<td id="S4.T2.6.3.2.4" class="ltx_td ltx_align_center"><span id="S4.T2.6.3.2.4.1" class="ltx_text" style="font-size:90%;">0.219</span></td>
<td id="S4.T2.6.3.2.5" class="ltx_td ltx_align_center"><span id="S4.T2.6.3.2.5.1" class="ltx_text" style="font-size:90%;">0.392</span></td>
<td id="S4.T2.6.3.2.6" class="ltx_td ltx_align_center"><span id="S4.T2.6.3.2.6.1" class="ltx_text" style="font-size:90%;">0.326</span></td>
<td id="S4.T2.6.3.2.7" class="ltx_td ltx_align_center"><span id="S4.T2.6.3.2.7.1" class="ltx_text" style="font-size:90%;">0.520</span></td>
</tr>
<tr id="S4.T2.6.4.3" class="ltx_tr">
<th id="S4.T2.6.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><span id="S4.T2.6.4.3.1.1" class="ltx_text" style="font-size:90%;">Orca2 7B</span></th>
<td id="S4.T2.6.4.3.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.6.4.3.2.1" class="ltx_text" style="font-size:90%;">0.456</span></td>
<td id="S4.T2.6.4.3.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.6.4.3.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">0.876</span></td>
<td id="S4.T2.6.4.3.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.6.4.3.4.1" class="ltx_text" style="font-size:90%;">0.511</span></td>
<td id="S4.T2.6.4.3.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.6.4.3.5.1" class="ltx_text" style="font-size:90%;">0.566</span></td>
<td id="S4.T2.6.4.3.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.6.4.3.6.1" class="ltx_text" style="font-size:90%;">0.820</span></td>
<td id="S4.T2.6.4.3.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S4.T2.6.4.3.7.1" class="ltx_text" style="font-size:90%;">0.826</span></td>
</tr>
</tbody>
</table>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Task Selection and Rationale</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">MMLU Benchmark</span> â€ƒTo properly evaluate the capabilities of LLMs on knowledge-intensive tasks, we selected four distinct tasks from the Massively Multilingual Language Understanding Evaluation (MMLU) benchmark&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et&nbsp;al., <a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite> in the topics of anatomy, astronomy, college biology, college chemistry and prehistory. The chosen tasks were selected based on their emphasis on factual knowledge and the minimal reliance on reasoning. As a heuristic, we opted for tasks where the questions are short and involve no context. In practice we selected four STEM subjects as well as one humanities subject, to ensure the evaluation is not limited to certain fields. Note that prehistory involves questions spanning all non-modern history. This approach aims to enable us to test LLM proficiency in comprehending and manipulating information in isolation from its reasoning processes.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Current Events Task</span> â€ƒTo further isolate LLMsâ€™ abilities to learn new knowledge, we created a task comprising multiple-choice questions about current events. This task includes multiple-choice questions about events that occurred after the cutoff of the various modelsâ€™ training data. Specifically, we focused on â€current eventsâ€ from the USA, in the time span of August-November 2023, that are included in the relevant Wikipedia indexes<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://en.wikipedia.org/wiki/Category:2023_events_in_the_United_States_by_month" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://en.wikipedia.org/wiki/Category:2023_events_in_the_United_States_by_month</a></span></span></span>. This method enables us to mostly guarantee that the models have not been exposed to these facts, thus allowing us to directly test knowledge injection capabilities.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Data Collection and Preprocessing</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">To effectively evaluate the LLMsâ€™ performance on these knowledge-intensive tasks, a comprehensive auxiliary dataset was collected by scraping relevant articles per topic from Wikipedia. The rationale behind selecting Wikipedia as the primary source of knowledge is its broad coverage of relevant topics and its reliability as a repository of crowd-verified knowledge. All articles pertinent to the tasks were retrieved via the official Wikipedia API<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://www.mediawiki.org/wiki/API:Main_page" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.mediawiki.org/wiki/API:Main_page</a></span></span></span> by identifying the relevant central page per topic.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Subsequently, a rigorous cleaning process was utilized to transform the data from raw subsections to clean chunks. This step was done with the â€wikiextractorâ€ tool&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Attardi, <a href="#bib.bib1" title="" class="ltx_ref">2015</a>)</cite>. The division into small, clean (e.g., remove HTML, URLs, etc.) chunks was aimed at enhancing the evaluation of the LLMsâ€™ understanding across various knowledge domains and aiding the LLMs in the fine-tuning process.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Current Events Task Creation</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">After collecting the relevant chunks from Wikipedia, we created a new multiple-choice dataset with the help of GPT-4&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib30" title="" class="ltx_ref">2023</a>)</cite>. First, we removed any small chunks. For each remaining chunk in the corpus, GPT-4 was instructed to create four highly specific, high-quality multiple-choice questions with only one correct answer. By specific, we mean that the question can be answered without knowledge of which context the question refers to and with minimal ambiguity. Next, GPT-4 was asked to select the two most specific of the four. This was followed by a manual evaluation and verification step. In total, this resulted in 910 new questions.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Paraphrases Generation</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">After creating the dataset, we utilized GPT-4 to generate augmentations of the dataset. We instructed GPT-4 to provide paraphrased versions of the input data that fully retain the information while being reworded. Each paraphrasing iteration was done with a different seed to ensure variety.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">We selected 240 chunks at random for each task and created two paraphrases per chunk. These were set aside to be used as validation sets for hyperparameter tuning. For the current events dataset, we created ten paraphrases for each chunk used in the fine-tuning process described in&nbsp;<a href="#S6" title="6 The Importance of Repetition â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments and Results</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p"><span id="S5.p1.1.1" class="ltx_text ltx_font_bold">Experimental Framework</span> â€ƒWe used the popular LM-Evaluation-Harness&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite> repository to evaluate the performance of LLMs on the selected knowledge-intensive tasks. LM-Evaluation-Harness is a robust benchmarking tool that currently serves as the industry standard for model evaluation and is the basis of the HuggingFace leaderboard<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a target="_blank" href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</a></span></span></span>. Leveraging this platform ensured a standardized evaluation framework and allowed consistent comparison across models, methods, and datasets. More importantly, by using the industry standard for evaluation, we could avoid any differences stemming from prompt engineering and formatting issues and replicate the reported baseline results for each model.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Model Selection</span> â€ƒWe chose three models for inference evaluation: Llama2-7B <cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al., <a href="#bib.bib45" title="" class="ltx_ref">2023</a>)</cite>, Mistral-7B <cite class="ltx_cite ltx_citemacro_citep">(Jiang et&nbsp;al., <a href="#bib.bib15" title="" class="ltx_ref">2023</a>)</cite>, and Orca2-7B <cite class="ltx_cite ltx_citemacro_citep">(Mitra et&nbsp;al., <a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite>.
The choice of these models was meant to represent the most popular open-source base models and an instruction-tuned model across various baseline capabilities.
Additionally, we selected <span id="S5.p2.1.2" class="ltx_text ltx_font_italic">bge-large-en</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xiao et&nbsp;al., <a href="#bib.bib52" title="" class="ltx_ref">2023</a>)</cite> as the embedding model for the RAG component and used FAISS&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Johnson et&nbsp;al., <a href="#bib.bib16" title="" class="ltx_ref">2019</a>)</cite> as its vector-store. This embedding model is currently the SOTA of open-source embedding models, according to the HuggingFace MTEB leaderboard<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a target="_blank" href="https://huggingface.co/spaces/mteb/leaderboard" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/spaces/mteb/leaderboard</a></span></span></span>.</p>
</div>
<figure id="S5.F2" class="ltx_figure">
<p id="S5.F2.1.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S5.F2.1.1.1" class="ltx_text"><img src="/html/2312.05934/assets/media/peformance_gain.png" id="S5.F2.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="355" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S5.F2.4.2" class="ltx_text" style="font-size:90%;">The relative accuracy gain (as explained in&nbsp;<a href="#S5.E5" title="In 5 Experiments and Results â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Equation</span>&nbsp;<span class="ltx_text ltx_ref_tag">5</span></a>) for each knowledge-injection method, averaged (columnwise) across all experiments in&nbsp;<a href="#S4.T1" title="In 4 Knowledge Base Creation â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>.</span></figcaption>
</figure>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p"><span id="S5.p3.1.1" class="ltx_text ltx_font_bold">Configuration Variations</span> â€ƒOur evaluation included multiple configurations, with a grid-search over them, to allow for more comprehensive benchmarking. 
<br class="ltx_break">Firstly, we compared the baseline and fine-tuned models and their performance with the RAG component. Secondly, we explored the optimal number of text chunks to add to the context in RAG. Specifically, different values of <math id="S5.p3.1.m1.3" class="ltx_Math" alttext="K\in\{0,\ldots,5\}" display="inline"><semantics id="S5.p3.1.m1.3a"><mrow id="S5.p3.1.m1.3.4" xref="S5.p3.1.m1.3.4.cmml"><mi id="S5.p3.1.m1.3.4.2" xref="S5.p3.1.m1.3.4.2.cmml">K</mi><mo id="S5.p3.1.m1.3.4.1" xref="S5.p3.1.m1.3.4.1.cmml">âˆˆ</mo><mrow id="S5.p3.1.m1.3.4.3.2" xref="S5.p3.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="S5.p3.1.m1.3.4.3.2.1" xref="S5.p3.1.m1.3.4.3.1.cmml">{</mo><mn id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml">0</mn><mo id="S5.p3.1.m1.3.4.3.2.2" xref="S5.p3.1.m1.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="S5.p3.1.m1.2.2" xref="S5.p3.1.m1.2.2.cmml">â€¦</mi><mo id="S5.p3.1.m1.3.4.3.2.3" xref="S5.p3.1.m1.3.4.3.1.cmml">,</mo><mn id="S5.p3.1.m1.3.3" xref="S5.p3.1.m1.3.3.cmml">5</mn><mo stretchy="false" id="S5.p3.1.m1.3.4.3.2.4" xref="S5.p3.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.3b"><apply id="S5.p3.1.m1.3.4.cmml" xref="S5.p3.1.m1.3.4"><in id="S5.p3.1.m1.3.4.1.cmml" xref="S5.p3.1.m1.3.4.1"></in><ci id="S5.p3.1.m1.3.4.2.cmml" xref="S5.p3.1.m1.3.4.2">ğ¾</ci><set id="S5.p3.1.m1.3.4.3.1.cmml" xref="S5.p3.1.m1.3.4.3.2"><cn type="integer" id="S5.p3.1.m1.1.1.cmml" xref="S5.p3.1.m1.1.1">0</cn><ci id="S5.p3.1.m1.2.2.cmml" xref="S5.p3.1.m1.2.2">â€¦</ci><cn type="integer" id="S5.p3.1.m1.3.3.cmml" xref="S5.p3.1.m1.3.3">5</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.3c">K\in\{0,\ldots,5\}</annotation></semantics></math> were employed to analyze the impact on model performance. Finally, we explored 5-shot performance vs. 0-shot.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.5" class="ltx_p"><span id="S5.p4.5.1" class="ltx_text ltx_font_bold">Training Setup</span> â€ƒWe trained all of the models using the unsupervised training procedure described in <a href="#S3.SS2" title="3.2 Fine-Tuning â€£ 3 Injecting Knowledge to Language Models â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.2</span></a>. For each dataset, we
divided the auxiliary knowledge base into equal chunks of size <math id="S5.p4.1.m1.1" class="ltx_Math" alttext="256" display="inline"><semantics id="S5.p4.1.m1.1a"><mn id="S5.p4.1.m1.1.1" xref="S5.p4.1.m1.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="S5.p4.1.m1.1b"><cn type="integer" id="S5.p4.1.m1.1.1.cmml" xref="S5.p4.1.m1.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.1.m1.1c">256</annotation></semantics></math> by concatenating or splitting the original chunks based on their length. We also added two special tokens, <math id="S5.p4.2.m2.1" class="ltx_Math" alttext="<" display="inline"><semantics id="S5.p4.2.m2.1a"><mo id="S5.p4.2.m2.1.1" xref="S5.p4.2.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.p4.2.m2.1b"><lt id="S5.p4.2.m2.1.1.cmml" xref="S5.p4.2.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.2.m2.1c">&lt;</annotation></semantics></math>BOS<math id="S5.p4.3.m3.1" class="ltx_Math" alttext=">" display="inline"><semantics id="S5.p4.3.m3.1a"><mo id="S5.p4.3.m3.1.1" xref="S5.p4.3.m3.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S5.p4.3.m3.1b"><gt id="S5.p4.3.m3.1.1.cmml" xref="S5.p4.3.m3.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.3.m3.1c">&gt;</annotation></semantics></math> and <math id="S5.p4.4.m4.1" class="ltx_Math" alttext="<" display="inline"><semantics id="S5.p4.4.m4.1a"><mo id="S5.p4.4.m4.1.1" xref="S5.p4.4.m4.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.p4.4.m4.1b"><lt id="S5.p4.4.m4.1.1.cmml" xref="S5.p4.4.m4.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.4.m4.1c">&lt;</annotation></semantics></math>EOS<math id="S5.p4.5.m5.1" class="ltx_Math" alttext=">" display="inline"><semantics id="S5.p4.5.m5.1a"><mo id="S5.p4.5.m5.1.1" xref="S5.p4.5.m5.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S5.p4.5.m5.1b"><gt id="S5.p4.5.m5.1.1.cmml" xref="S5.p4.5.m5.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.5.m5.1c">&gt;</annotation></semantics></math>, to demarcate the original chunksâ€™ beginnings and ends to preserve the documentsâ€™ structure.</p>
</div>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.2" class="ltx_p">The models were trained using learning rates between <math id="S5.p5.1.m1.1" class="ltx_Math" alttext="1\times{10}^{-6}" display="inline"><semantics id="S5.p5.1.m1.1a"><mrow id="S5.p5.1.m1.1.1" xref="S5.p5.1.m1.1.1.cmml"><mn id="S5.p5.1.m1.1.1.2" xref="S5.p5.1.m1.1.1.2.cmml">1</mn><mo lspace="0.222em" rspace="0.222em" id="S5.p5.1.m1.1.1.1" xref="S5.p5.1.m1.1.1.1.cmml">Ã—</mo><msup id="S5.p5.1.m1.1.1.3" xref="S5.p5.1.m1.1.1.3.cmml"><mn id="S5.p5.1.m1.1.1.3.2" xref="S5.p5.1.m1.1.1.3.2.cmml">10</mn><mrow id="S5.p5.1.m1.1.1.3.3" xref="S5.p5.1.m1.1.1.3.3.cmml"><mo id="S5.p5.1.m1.1.1.3.3a" xref="S5.p5.1.m1.1.1.3.3.cmml">âˆ’</mo><mn id="S5.p5.1.m1.1.1.3.3.2" xref="S5.p5.1.m1.1.1.3.3.2.cmml">6</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.p5.1.m1.1b"><apply id="S5.p5.1.m1.1.1.cmml" xref="S5.p5.1.m1.1.1"><times id="S5.p5.1.m1.1.1.1.cmml" xref="S5.p5.1.m1.1.1.1"></times><cn type="integer" id="S5.p5.1.m1.1.1.2.cmml" xref="S5.p5.1.m1.1.1.2">1</cn><apply id="S5.p5.1.m1.1.1.3.cmml" xref="S5.p5.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.p5.1.m1.1.1.3.1.cmml" xref="S5.p5.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S5.p5.1.m1.1.1.3.2.cmml" xref="S5.p5.1.m1.1.1.3.2">10</cn><apply id="S5.p5.1.m1.1.1.3.3.cmml" xref="S5.p5.1.m1.1.1.3.3"><minus id="S5.p5.1.m1.1.1.3.3.1.cmml" xref="S5.p5.1.m1.1.1.3.3"></minus><cn type="integer" id="S5.p5.1.m1.1.1.3.3.2.cmml" xref="S5.p5.1.m1.1.1.3.3.2">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p5.1.m1.1c">1\times{10}^{-6}</annotation></semantics></math> and <math id="S5.p5.2.m2.1" class="ltx_Math" alttext="5\times{10}^{-5}" display="inline"><semantics id="S5.p5.2.m2.1a"><mrow id="S5.p5.2.m2.1.1" xref="S5.p5.2.m2.1.1.cmml"><mn id="S5.p5.2.m2.1.1.2" xref="S5.p5.2.m2.1.1.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S5.p5.2.m2.1.1.1" xref="S5.p5.2.m2.1.1.1.cmml">Ã—</mo><msup id="S5.p5.2.m2.1.1.3" xref="S5.p5.2.m2.1.1.3.cmml"><mn id="S5.p5.2.m2.1.1.3.2" xref="S5.p5.2.m2.1.1.3.2.cmml">10</mn><mrow id="S5.p5.2.m2.1.1.3.3" xref="S5.p5.2.m2.1.1.3.3.cmml"><mo id="S5.p5.2.m2.1.1.3.3a" xref="S5.p5.2.m2.1.1.3.3.cmml">âˆ’</mo><mn id="S5.p5.2.m2.1.1.3.3.2" xref="S5.p5.2.m2.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.p5.2.m2.1b"><apply id="S5.p5.2.m2.1.1.cmml" xref="S5.p5.2.m2.1.1"><times id="S5.p5.2.m2.1.1.1.cmml" xref="S5.p5.2.m2.1.1.1"></times><cn type="integer" id="S5.p5.2.m2.1.1.2.cmml" xref="S5.p5.2.m2.1.1.2">5</cn><apply id="S5.p5.2.m2.1.1.3.cmml" xref="S5.p5.2.m2.1.1.3"><csymbol cd="ambiguous" id="S5.p5.2.m2.1.1.3.1.cmml" xref="S5.p5.2.m2.1.1.3">superscript</csymbol><cn type="integer" id="S5.p5.2.m2.1.1.3.2.cmml" xref="S5.p5.2.m2.1.1.3.2">10</cn><apply id="S5.p5.2.m2.1.1.3.3.cmml" xref="S5.p5.2.m2.1.1.3.3"><minus id="S5.p5.2.m2.1.1.3.3.1.cmml" xref="S5.p5.2.m2.1.1.3.3"></minus><cn type="integer" id="S5.p5.2.m2.1.1.3.3.2.cmml" xref="S5.p5.2.m2.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p5.2.m2.1c">5\times{10}^{-5}</annotation></semantics></math>, which were found through a hyperparameter search. All models were trained on 4 NVIDIA A-100 GPUs for a maximum of 5 epochs and a batch size of 64.</p>
</div>
<div id="S5.p6" class="ltx_para">
<p id="S5.p6.1" class="ltx_p"><span id="S5.p6.1.1" class="ltx_text ltx_font_bold">Evaluation method</span> â€ƒAll evaluations were done by appending each of the multiple-choice options to the question, followed by passing the concatenation through the model to get a log probability score per option. The highest score was interpreted as the modelâ€™s choice and used for accuracy calculation. More formally, this means that in&nbsp;<a href="#S2.E1" title="In 2 Background â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Equation</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a> we say that <math id="S5.p6.1.m1.1" class="ltx_Math" alttext="\mathcal{M}(q_{n})=c_{n}" display="inline"><semantics id="S5.p6.1.m1.1a"><mrow id="S5.p6.1.m1.1.1" xref="S5.p6.1.m1.1.1.cmml"><mrow id="S5.p6.1.m1.1.1.1" xref="S5.p6.1.m1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.p6.1.m1.1.1.1.3" xref="S5.p6.1.m1.1.1.1.3.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S5.p6.1.m1.1.1.1.2" xref="S5.p6.1.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S5.p6.1.m1.1.1.1.1.1" xref="S5.p6.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.p6.1.m1.1.1.1.1.1.2" xref="S5.p6.1.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S5.p6.1.m1.1.1.1.1.1.1" xref="S5.p6.1.m1.1.1.1.1.1.1.cmml"><mi id="S5.p6.1.m1.1.1.1.1.1.1.2" xref="S5.p6.1.m1.1.1.1.1.1.1.2.cmml">q</mi><mi id="S5.p6.1.m1.1.1.1.1.1.1.3" xref="S5.p6.1.m1.1.1.1.1.1.1.3.cmml">n</mi></msub><mo stretchy="false" id="S5.p6.1.m1.1.1.1.1.1.3" xref="S5.p6.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.p6.1.m1.1.1.2" xref="S5.p6.1.m1.1.1.2.cmml">=</mo><msub id="S5.p6.1.m1.1.1.3" xref="S5.p6.1.m1.1.1.3.cmml"><mi id="S5.p6.1.m1.1.1.3.2" xref="S5.p6.1.m1.1.1.3.2.cmml">c</mi><mi id="S5.p6.1.m1.1.1.3.3" xref="S5.p6.1.m1.1.1.3.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.p6.1.m1.1b"><apply id="S5.p6.1.m1.1.1.cmml" xref="S5.p6.1.m1.1.1"><eq id="S5.p6.1.m1.1.1.2.cmml" xref="S5.p6.1.m1.1.1.2"></eq><apply id="S5.p6.1.m1.1.1.1.cmml" xref="S5.p6.1.m1.1.1.1"><times id="S5.p6.1.m1.1.1.1.2.cmml" xref="S5.p6.1.m1.1.1.1.2"></times><ci id="S5.p6.1.m1.1.1.1.3.cmml" xref="S5.p6.1.m1.1.1.1.3">â„³</ci><apply id="S5.p6.1.m1.1.1.1.1.1.1.cmml" xref="S5.p6.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.p6.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.p6.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S5.p6.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.p6.1.m1.1.1.1.1.1.1.2">ğ‘</ci><ci id="S5.p6.1.m1.1.1.1.1.1.1.3.cmml" xref="S5.p6.1.m1.1.1.1.1.1.1.3">ğ‘›</ci></apply></apply><apply id="S5.p6.1.m1.1.1.3.cmml" xref="S5.p6.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.1.m1.1.1.3.1.cmml" xref="S5.p6.1.m1.1.1.3">subscript</csymbol><ci id="S5.p6.1.m1.1.1.3.2.cmml" xref="S5.p6.1.m1.1.1.3.2">ğ‘</ci><ci id="S5.p6.1.m1.1.1.3.3.cmml" xref="S5.p6.1.m1.1.1.3.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.1.m1.1c">\mathcal{M}(q_{n})=c_{n}</annotation></semantics></math> if:</p>
<table id="S5.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E4.m1.2" class="ltx_Math" alttext="c_{n}=\operatorname*{arg\,max}_{l}\{\mathcal{M}(q_{n}\|a^{1}_{n}),\ldots,\mathcal{M}(q_{n}\|a^{L}_{n})\}," display="block"><semantics id="S5.E4.m1.2a"><mrow id="S5.E4.m1.2.2.1" xref="S5.E4.m1.2.2.1.1.cmml"><mrow id="S5.E4.m1.2.2.1.1" xref="S5.E4.m1.2.2.1.1.cmml"><msub id="S5.E4.m1.2.2.1.1.5" xref="S5.E4.m1.2.2.1.1.5.cmml"><mi id="S5.E4.m1.2.2.1.1.5.2" xref="S5.E4.m1.2.2.1.1.5.2.cmml">c</mi><mi id="S5.E4.m1.2.2.1.1.5.3" xref="S5.E4.m1.2.2.1.1.5.3.cmml">n</mi></msub><mo id="S5.E4.m1.2.2.1.1.4" xref="S5.E4.m1.2.2.1.1.4.cmml">=</mo><mrow id="S5.E4.m1.2.2.1.1.3.3" xref="S5.E4.m1.2.2.1.1.3.4.cmml"><munder id="S5.E4.m1.2.2.1.1.1.1.1" xref="S5.E4.m1.2.2.1.1.1.1.1.cmml"><mrow id="S5.E4.m1.2.2.1.1.1.1.1.2" xref="S5.E4.m1.2.2.1.1.1.1.1.2.cmml"><mi id="S5.E4.m1.2.2.1.1.1.1.1.2.2" xref="S5.E4.m1.2.2.1.1.1.1.1.2.2.cmml">arg</mi><mo lspace="0.170em" rspace="0em" id="S5.E4.m1.2.2.1.1.1.1.1.2.1" xref="S5.E4.m1.2.2.1.1.1.1.1.2.1.cmml">â€‹</mo><mi id="S5.E4.m1.2.2.1.1.1.1.1.2.3" xref="S5.E4.m1.2.2.1.1.1.1.1.2.3.cmml">max</mi></mrow><mi id="S5.E4.m1.2.2.1.1.1.1.1.3" xref="S5.E4.m1.2.2.1.1.1.1.1.3.cmml">l</mi></munder><mo id="S5.E4.m1.2.2.1.1.3.3a" xref="S5.E4.m1.2.2.1.1.3.4.cmml">â¡</mo><mrow id="S5.E4.m1.2.2.1.1.3.3.3" xref="S5.E4.m1.2.2.1.1.3.4.cmml"><mo stretchy="false" id="S5.E4.m1.2.2.1.1.3.3.3.3" xref="S5.E4.m1.2.2.1.1.3.4.cmml">{</mo><mrow id="S5.E4.m1.2.2.1.1.2.2.2.1" xref="S5.E4.m1.2.2.1.1.2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E4.m1.2.2.1.1.2.2.2.1.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.3.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S5.E4.m1.2.2.1.1.2.2.2.1.2" xref="S5.E4.m1.2.2.1.1.2.2.2.1.2.cmml">â€‹</mo><mrow id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.2" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml"><msub id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.cmml"><mi id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.2" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.2.cmml">q</mi><mi id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.3.cmml">n</mi></msub><mo id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.1" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.1.cmml">âˆ¥</mo><msubsup id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.cmml"><mi id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.2" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.2.cmml">a</mi><mi id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.3.cmml">n</mi><mn id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.3.cmml">1</mn></msubsup></mrow><mo stretchy="false" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.E4.m1.2.2.1.1.3.3.3.4" xref="S5.E4.m1.2.2.1.1.3.4.cmml">,</mo><mi mathvariant="normal" id="S5.E4.m1.1.1" xref="S5.E4.m1.1.1.cmml">â€¦</mi><mo id="S5.E4.m1.2.2.1.1.3.3.3.5" xref="S5.E4.m1.2.2.1.1.3.4.cmml">,</mo><mrow id="S5.E4.m1.2.2.1.1.3.3.3.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E4.m1.2.2.1.1.3.3.3.2.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.3.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S5.E4.m1.2.2.1.1.3.3.3.2.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.2.cmml">â€‹</mo><mrow id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml"><mo stretchy="false" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml">(</mo><mrow id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml"><msub id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.cmml"><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.2.cmml">q</mi><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.3.cmml">n</mi></msub><mo id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.1" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.1.cmml">âˆ¥</mo><msubsup id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.cmml"><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.2.cmml">a</mi><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.3.cmml">n</mi><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.3.cmml">L</mi></msubsup></mrow><mo stretchy="false" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S5.E4.m1.2.2.1.1.3.3.3.6" xref="S5.E4.m1.2.2.1.1.3.4.cmml">}</mo></mrow></mrow></mrow><mo id="S5.E4.m1.2.2.1.2" xref="S5.E4.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E4.m1.2b"><apply id="S5.E4.m1.2.2.1.1.cmml" xref="S5.E4.m1.2.2.1"><eq id="S5.E4.m1.2.2.1.1.4.cmml" xref="S5.E4.m1.2.2.1.1.4"></eq><apply id="S5.E4.m1.2.2.1.1.5.cmml" xref="S5.E4.m1.2.2.1.1.5"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.5.1.cmml" xref="S5.E4.m1.2.2.1.1.5">subscript</csymbol><ci id="S5.E4.m1.2.2.1.1.5.2.cmml" xref="S5.E4.m1.2.2.1.1.5.2">ğ‘</ci><ci id="S5.E4.m1.2.2.1.1.5.3.cmml" xref="S5.E4.m1.2.2.1.1.5.3">ğ‘›</ci></apply><apply id="S5.E4.m1.2.2.1.1.3.4.cmml" xref="S5.E4.m1.2.2.1.1.3.3"><apply id="S5.E4.m1.2.2.1.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1">subscript</csymbol><apply id="S5.E4.m1.2.2.1.1.1.1.1.2.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.2"><times id="S5.E4.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.2.1"></times><ci id="S5.E4.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.2.2">arg</ci><ci id="S5.E4.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.2.3">max</ci></apply><ci id="S5.E4.m1.2.2.1.1.1.1.1.3.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.3">ğ‘™</ci></apply><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1"><times id="S5.E4.m1.2.2.1.1.2.2.2.1.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.2"></times><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.3.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.3">â„³</ci><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1"><csymbol cd="latexml" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.1">conditional</csymbol><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.2">ğ‘</ci><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.3.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.3">ğ‘›</ci></apply><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3">subscript</csymbol><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3">superscript</csymbol><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.2">ğ‘</ci><cn type="integer" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.3.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.3">1</cn></apply><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.3.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.3">ğ‘›</ci></apply></apply></apply><ci id="S5.E4.m1.1.1.cmml" xref="S5.E4.m1.1.1">â€¦</ci><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2"><times id="S5.E4.m1.2.2.1.1.3.3.3.2.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.2"></times><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.3">â„³</ci><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1"><csymbol cd="latexml" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.1">conditional</csymbol><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2">subscript</csymbol><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.2">ğ‘</ci><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.3">ğ‘›</ci></apply><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3">subscript</csymbol><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3">superscript</csymbol><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.2">ğ‘</ci><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.3">ğ¿</ci></apply><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.3">ğ‘›</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E4.m1.2c">c_{n}=\operatorname*{arg\,max}_{l}\{\mathcal{M}(q_{n}\|a^{1}_{n}),\ldots,\mathcal{M}(q_{n}\|a^{L}_{n})\},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S5.p6.2" class="ltx_p">where <math id="S5.p6.2.m1.2" class="ltx_Math" alttext="\mathcal{M}(q_{n}\|a^{l}_{n})=\log P_{\mathcal{M}}(q_{n}\|a^{l}_{n})" display="inline"><semantics id="S5.p6.2.m1.2a"><mrow id="S5.p6.2.m1.2.2" xref="S5.p6.2.m1.2.2.cmml"><mrow id="S5.p6.2.m1.1.1.1" xref="S5.p6.2.m1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.p6.2.m1.1.1.1.3" xref="S5.p6.2.m1.1.1.1.3.cmml">â„³</mi><mo lspace="0em" rspace="0em" id="S5.p6.2.m1.1.1.1.2" xref="S5.p6.2.m1.1.1.1.2.cmml">â€‹</mo><mrow id="S5.p6.2.m1.1.1.1.1.1" xref="S5.p6.2.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.p6.2.m1.1.1.1.1.1.2" xref="S5.p6.2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.p6.2.m1.1.1.1.1.1.1" xref="S5.p6.2.m1.1.1.1.1.1.1.cmml"><msub id="S5.p6.2.m1.1.1.1.1.1.1.2" xref="S5.p6.2.m1.1.1.1.1.1.1.2.cmml"><mi id="S5.p6.2.m1.1.1.1.1.1.1.2.2" xref="S5.p6.2.m1.1.1.1.1.1.1.2.2.cmml">q</mi><mi id="S5.p6.2.m1.1.1.1.1.1.1.2.3" xref="S5.p6.2.m1.1.1.1.1.1.1.2.3.cmml">n</mi></msub><mo id="S5.p6.2.m1.1.1.1.1.1.1.1" xref="S5.p6.2.m1.1.1.1.1.1.1.1.cmml">âˆ¥</mo><msubsup id="S5.p6.2.m1.1.1.1.1.1.1.3" xref="S5.p6.2.m1.1.1.1.1.1.1.3.cmml"><mi id="S5.p6.2.m1.1.1.1.1.1.1.3.2.2" xref="S5.p6.2.m1.1.1.1.1.1.1.3.2.2.cmml">a</mi><mi id="S5.p6.2.m1.1.1.1.1.1.1.3.3" xref="S5.p6.2.m1.1.1.1.1.1.1.3.3.cmml">n</mi><mi id="S5.p6.2.m1.1.1.1.1.1.1.3.2.3" xref="S5.p6.2.m1.1.1.1.1.1.1.3.2.3.cmml">l</mi></msubsup></mrow><mo stretchy="false" id="S5.p6.2.m1.1.1.1.1.1.3" xref="S5.p6.2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.p6.2.m1.2.2.3" xref="S5.p6.2.m1.2.2.3.cmml">=</mo><mrow id="S5.p6.2.m1.2.2.2" xref="S5.p6.2.m1.2.2.2.cmml"><mrow id="S5.p6.2.m1.2.2.2.3" xref="S5.p6.2.m1.2.2.2.3.cmml"><mi id="S5.p6.2.m1.2.2.2.3.1" xref="S5.p6.2.m1.2.2.2.3.1.cmml">log</mi><mo lspace="0.167em" id="S5.p6.2.m1.2.2.2.3a" xref="S5.p6.2.m1.2.2.2.3.cmml">â¡</mo><msub id="S5.p6.2.m1.2.2.2.3.2" xref="S5.p6.2.m1.2.2.2.3.2.cmml"><mi id="S5.p6.2.m1.2.2.2.3.2.2" xref="S5.p6.2.m1.2.2.2.3.2.2.cmml">P</mi><mi class="ltx_font_mathcaligraphic" id="S5.p6.2.m1.2.2.2.3.2.3" xref="S5.p6.2.m1.2.2.2.3.2.3.cmml">â„³</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S5.p6.2.m1.2.2.2.2" xref="S5.p6.2.m1.2.2.2.2.cmml">â€‹</mo><mrow id="S5.p6.2.m1.2.2.2.1.1" xref="S5.p6.2.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S5.p6.2.m1.2.2.2.1.1.2" xref="S5.p6.2.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="S5.p6.2.m1.2.2.2.1.1.1" xref="S5.p6.2.m1.2.2.2.1.1.1.cmml"><msub id="S5.p6.2.m1.2.2.2.1.1.1.2" xref="S5.p6.2.m1.2.2.2.1.1.1.2.cmml"><mi id="S5.p6.2.m1.2.2.2.1.1.1.2.2" xref="S5.p6.2.m1.2.2.2.1.1.1.2.2.cmml">q</mi><mi id="S5.p6.2.m1.2.2.2.1.1.1.2.3" xref="S5.p6.2.m1.2.2.2.1.1.1.2.3.cmml">n</mi></msub><mo id="S5.p6.2.m1.2.2.2.1.1.1.1" xref="S5.p6.2.m1.2.2.2.1.1.1.1.cmml">âˆ¥</mo><msubsup id="S5.p6.2.m1.2.2.2.1.1.1.3" xref="S5.p6.2.m1.2.2.2.1.1.1.3.cmml"><mi id="S5.p6.2.m1.2.2.2.1.1.1.3.2.2" xref="S5.p6.2.m1.2.2.2.1.1.1.3.2.2.cmml">a</mi><mi id="S5.p6.2.m1.2.2.2.1.1.1.3.3" xref="S5.p6.2.m1.2.2.2.1.1.1.3.3.cmml">n</mi><mi id="S5.p6.2.m1.2.2.2.1.1.1.3.2.3" xref="S5.p6.2.m1.2.2.2.1.1.1.3.2.3.cmml">l</mi></msubsup></mrow><mo stretchy="false" id="S5.p6.2.m1.2.2.2.1.1.3" xref="S5.p6.2.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p6.2.m1.2b"><apply id="S5.p6.2.m1.2.2.cmml" xref="S5.p6.2.m1.2.2"><eq id="S5.p6.2.m1.2.2.3.cmml" xref="S5.p6.2.m1.2.2.3"></eq><apply id="S5.p6.2.m1.1.1.1.cmml" xref="S5.p6.2.m1.1.1.1"><times id="S5.p6.2.m1.1.1.1.2.cmml" xref="S5.p6.2.m1.1.1.1.2"></times><ci id="S5.p6.2.m1.1.1.1.3.cmml" xref="S5.p6.2.m1.1.1.1.3">â„³</ci><apply id="S5.p6.2.m1.1.1.1.1.1.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1"><csymbol cd="latexml" id="S5.p6.2.m1.1.1.1.1.1.1.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S5.p6.2.m1.1.1.1.1.1.1.2.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.p6.2.m1.1.1.1.1.1.1.2.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.p6.2.m1.1.1.1.1.1.1.2.2.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.2.2">ğ‘</ci><ci id="S5.p6.2.m1.1.1.1.1.1.1.2.3.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.2.3">ğ‘›</ci></apply><apply id="S5.p6.2.m1.1.1.1.1.1.1.3.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.2.m1.1.1.1.1.1.1.3.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S5.p6.2.m1.1.1.1.1.1.1.3.2.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.2.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S5.p6.2.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3.2.2">ğ‘</ci><ci id="S5.p6.2.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3.2.3">ğ‘™</ci></apply><ci id="S5.p6.2.m1.1.1.1.1.1.1.3.3.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3.3">ğ‘›</ci></apply></apply></apply><apply id="S5.p6.2.m1.2.2.2.cmml" xref="S5.p6.2.m1.2.2.2"><times id="S5.p6.2.m1.2.2.2.2.cmml" xref="S5.p6.2.m1.2.2.2.2"></times><apply id="S5.p6.2.m1.2.2.2.3.cmml" xref="S5.p6.2.m1.2.2.2.3"><log id="S5.p6.2.m1.2.2.2.3.1.cmml" xref="S5.p6.2.m1.2.2.2.3.1"></log><apply id="S5.p6.2.m1.2.2.2.3.2.cmml" xref="S5.p6.2.m1.2.2.2.3.2"><csymbol cd="ambiguous" id="S5.p6.2.m1.2.2.2.3.2.1.cmml" xref="S5.p6.2.m1.2.2.2.3.2">subscript</csymbol><ci id="S5.p6.2.m1.2.2.2.3.2.2.cmml" xref="S5.p6.2.m1.2.2.2.3.2.2">ğ‘ƒ</ci><ci id="S5.p6.2.m1.2.2.2.3.2.3.cmml" xref="S5.p6.2.m1.2.2.2.3.2.3">â„³</ci></apply></apply><apply id="S5.p6.2.m1.2.2.2.1.1.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1"><csymbol cd="latexml" id="S5.p6.2.m1.2.2.2.1.1.1.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.1">conditional</csymbol><apply id="S5.p6.2.m1.2.2.2.1.1.1.2.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S5.p6.2.m1.2.2.2.1.1.1.2.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.2">subscript</csymbol><ci id="S5.p6.2.m1.2.2.2.1.1.1.2.2.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.2.2">ğ‘</ci><ci id="S5.p6.2.m1.2.2.2.1.1.1.2.3.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.2.3">ğ‘›</ci></apply><apply id="S5.p6.2.m1.2.2.2.1.1.1.3.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.2.m1.2.2.2.1.1.1.3.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3">subscript</csymbol><apply id="S5.p6.2.m1.2.2.2.1.1.1.3.2.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.2.m1.2.2.2.1.1.1.3.2.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3">superscript</csymbol><ci id="S5.p6.2.m1.2.2.2.1.1.1.3.2.2.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3.2.2">ğ‘</ci><ci id="S5.p6.2.m1.2.2.2.1.1.1.3.2.3.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3.2.3">ğ‘™</ci></apply><ci id="S5.p6.2.m1.2.2.2.1.1.1.3.3.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3.3">ğ‘›</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.2.m1.2c">\mathcal{M}(q_{n}\|a^{l}_{n})=\log P_{\mathcal{M}}(q_{n}\|a^{l}_{n})</annotation></semantics></math>.</p>
</div>
<div id="S5.p7" class="ltx_para">
<p id="S5.p7.3" class="ltx_p"><span id="S5.p7.3.1" class="ltx_text ltx_font_bold">MMLU Results</span> â€ƒFor each task and model, we compared four approaches: using just the base model, RAG, FT, and finally combining FT and RAG by using the fine-tuned model as the generator. Furthermore, we tested the MMLU tasks using both 0-shot and 5-shot scenarios. The full results are shown in &nbsp;<a href="#S4.T1" title="In 4 Knowledge Base Creation â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>. An aggregation of the relative accuracy gain, i.e.,</p>
<table id="S5.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S5.E5.m1.7" class="ltx_Math" alttext="(\mathcal{L}_{\mathcal{M^{\prime}},\mathcal{Q}}-\mathcal{L}_{\mathcal{M},\mathcal{Q}})/{\mathcal{L}_{\mathcal{M},\mathcal{Q}}}," display="block"><semantics id="S5.E5.m1.7a"><mrow id="S5.E5.m1.7.7.1" xref="S5.E5.m1.7.7.1.1.cmml"><mrow id="S5.E5.m1.7.7.1.1" xref="S5.E5.m1.7.7.1.1.cmml"><mrow id="S5.E5.m1.7.7.1.1.1.1" xref="S5.E5.m1.7.7.1.1.1.1.1.cmml"><mo stretchy="false" id="S5.E5.m1.7.7.1.1.1.1.2" xref="S5.E5.m1.7.7.1.1.1.1.1.cmml">(</mo><mrow id="S5.E5.m1.7.7.1.1.1.1.1" xref="S5.E5.m1.7.7.1.1.1.1.1.cmml"><msub id="S5.E5.m1.7.7.1.1.1.1.1.2" xref="S5.E5.m1.7.7.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.7.7.1.1.1.1.1.2.2" xref="S5.E5.m1.7.7.1.1.1.1.1.2.2.cmml">â„’</mi><mrow id="S5.E5.m1.2.2.2.2" xref="S5.E5.m1.2.2.2.3.cmml"><msup id="S5.E5.m1.2.2.2.2.1" xref="S5.E5.m1.2.2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.2.2.2.2.1.2" xref="S5.E5.m1.2.2.2.2.1.2.cmml">â„³</mi><mo id="S5.E5.m1.2.2.2.2.1.3" xref="S5.E5.m1.2.2.2.2.1.3.cmml">â€²</mo></msup><mo id="S5.E5.m1.2.2.2.2.2" xref="S5.E5.m1.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.cmml">ğ’¬</mi></mrow></msub><mo id="S5.E5.m1.7.7.1.1.1.1.1.1" xref="S5.E5.m1.7.7.1.1.1.1.1.1.cmml">âˆ’</mo><msub id="S5.E5.m1.7.7.1.1.1.1.1.3" xref="S5.E5.m1.7.7.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.7.7.1.1.1.1.1.3.2" xref="S5.E5.m1.7.7.1.1.1.1.1.3.2.cmml">â„’</mi><mrow id="S5.E5.m1.4.4.2.4" xref="S5.E5.m1.4.4.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.3.3.1.1" xref="S5.E5.m1.3.3.1.1.cmml">â„³</mi><mo id="S5.E5.m1.4.4.2.4.1" xref="S5.E5.m1.4.4.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.4.4.2.2" xref="S5.E5.m1.4.4.2.2.cmml">ğ’¬</mi></mrow></msub></mrow><mo stretchy="false" id="S5.E5.m1.7.7.1.1.1.1.3" xref="S5.E5.m1.7.7.1.1.1.1.1.cmml">)</mo></mrow><mo id="S5.E5.m1.7.7.1.1.2" xref="S5.E5.m1.7.7.1.1.2.cmml">/</mo><msub id="S5.E5.m1.7.7.1.1.3" xref="S5.E5.m1.7.7.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.7.7.1.1.3.2" xref="S5.E5.m1.7.7.1.1.3.2.cmml">â„’</mi><mrow id="S5.E5.m1.6.6.2.4" xref="S5.E5.m1.6.6.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.5.5.1.1" xref="S5.E5.m1.5.5.1.1.cmml">â„³</mi><mo id="S5.E5.m1.6.6.2.4.1" xref="S5.E5.m1.6.6.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.6.6.2.2" xref="S5.E5.m1.6.6.2.2.cmml">ğ’¬</mi></mrow></msub></mrow><mo id="S5.E5.m1.7.7.1.2" xref="S5.E5.m1.7.7.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E5.m1.7b"><apply id="S5.E5.m1.7.7.1.1.cmml" xref="S5.E5.m1.7.7.1"><divide id="S5.E5.m1.7.7.1.1.2.cmml" xref="S5.E5.m1.7.7.1.1.2"></divide><apply id="S5.E5.m1.7.7.1.1.1.1.1.cmml" xref="S5.E5.m1.7.7.1.1.1.1"><minus id="S5.E5.m1.7.7.1.1.1.1.1.1.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.1"></minus><apply id="S5.E5.m1.7.7.1.1.1.1.1.2.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E5.m1.7.7.1.1.1.1.1.2.1.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E5.m1.7.7.1.1.1.1.1.2.2.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.2.2">â„’</ci><list id="S5.E5.m1.2.2.2.3.cmml" xref="S5.E5.m1.2.2.2.2"><apply id="S5.E5.m1.2.2.2.2.1.cmml" xref="S5.E5.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S5.E5.m1.2.2.2.2.1.1.cmml" xref="S5.E5.m1.2.2.2.2.1">superscript</csymbol><ci id="S5.E5.m1.2.2.2.2.1.2.cmml" xref="S5.E5.m1.2.2.2.2.1.2">â„³</ci><ci id="S5.E5.m1.2.2.2.2.1.3.cmml" xref="S5.E5.m1.2.2.2.2.1.3">â€²</ci></apply><ci id="S5.E5.m1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1">ğ’¬</ci></list></apply><apply id="S5.E5.m1.7.7.1.1.1.1.1.3.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E5.m1.7.7.1.1.1.1.1.3.1.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E5.m1.7.7.1.1.1.1.1.3.2.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.3.2">â„’</ci><list id="S5.E5.m1.4.4.2.3.cmml" xref="S5.E5.m1.4.4.2.4"><ci id="S5.E5.m1.3.3.1.1.cmml" xref="S5.E5.m1.3.3.1.1">â„³</ci><ci id="S5.E5.m1.4.4.2.2.cmml" xref="S5.E5.m1.4.4.2.2">ğ’¬</ci></list></apply></apply><apply id="S5.E5.m1.7.7.1.1.3.cmml" xref="S5.E5.m1.7.7.1.1.3"><csymbol cd="ambiguous" id="S5.E5.m1.7.7.1.1.3.1.cmml" xref="S5.E5.m1.7.7.1.1.3">subscript</csymbol><ci id="S5.E5.m1.7.7.1.1.3.2.cmml" xref="S5.E5.m1.7.7.1.1.3.2">â„’</ci><list id="S5.E5.m1.6.6.2.3.cmml" xref="S5.E5.m1.6.6.2.4"><ci id="S5.E5.m1.5.5.1.1.cmml" xref="S5.E5.m1.5.5.1.1">â„³</ci><ci id="S5.E5.m1.6.6.2.2.cmml" xref="S5.E5.m1.6.6.2.2">ğ’¬</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E5.m1.7c">(\mathcal{L}_{\mathcal{M^{\prime}},\mathcal{Q}}-\mathcal{L}_{\mathcal{M},\mathcal{Q}})/{\mathcal{L}_{\mathcal{M},\mathcal{Q}}},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S5.p7.2" class="ltx_p">where <math id="S5.p7.1.m1.1" class="ltx_Math" alttext="\mathcal{M}" display="inline"><semantics id="S5.p7.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S5.p7.1.m1.1.1" xref="S5.p7.1.m1.1.1.cmml">â„³</mi><annotation-xml encoding="MathML-Content" id="S5.p7.1.m1.1b"><ci id="S5.p7.1.m1.1.1.cmml" xref="S5.p7.1.m1.1.1">â„³</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p7.1.m1.1c">\mathcal{M}</annotation></semantics></math> is the base model and <math id="S5.p7.2.m2.1" class="ltx_Math" alttext="\mathcal{M^{\prime}}" display="inline"><semantics id="S5.p7.2.m2.1a"><msup id="S5.p7.2.m2.1.1" xref="S5.p7.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.p7.2.m2.1.1.2" xref="S5.p7.2.m2.1.1.2.cmml">â„³</mi><mo id="S5.p7.2.m2.1.1.3" xref="S5.p7.2.m2.1.1.3.cmml">â€²</mo></msup><annotation-xml encoding="MathML-Content" id="S5.p7.2.m2.1b"><apply id="S5.p7.2.m2.1.1.cmml" xref="S5.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S5.p7.2.m2.1.1.1.cmml" xref="S5.p7.2.m2.1.1">superscript</csymbol><ci id="S5.p7.2.m2.1.1.2.cmml" xref="S5.p7.2.m2.1.1.2">â„³</ci><ci id="S5.p7.2.m2.1.1.3.cmml" xref="S5.p7.2.m2.1.1.3">â€²</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p7.2.m2.1c">\mathcal{M^{\prime}}</annotation></semantics></math> is the knowledge-injected model, is shown in &nbsp;<a href="#S5.F2" title="In 5 Experiments and Results â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S5.p8" class="ltx_para">
<p id="S5.p8.1" class="ltx_p">In all cases, RAG performed significantly better compared to the base models. Furthermore, using RAG with the base model as the generator was consistently better than only fine-tuning. In some cases, using the fine-tuned model instead of the base model as the generator in the RAG pipeline improved results even further. However, this is not consistent and thus demonstrates the inherent instability of fine-tuning. Additionally, we found that the 5-shot approach boosts the results by a small margin in most cases, with a similar trend being observed in all of the different approaches.</p>
</div>
<div id="S5.p9" class="ltx_para">
<p id="S5.p9.1" class="ltx_p"><span id="S5.p9.1.1" class="ltx_text ltx_font_bold">Current Events Results</span> â€ƒThe evaluation on the current events task is shown in&nbsp;<a href="#S4.T2" title="In 4 Knowledge Base Creation â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>. RAG proves particularly effective due to the one-to-one correspondence between the questions and the auxiliary dataset (see&nbsp;<a href="#S4.SS3" title="4.3 Current Events Task Creation â€£ 4 Knowledge Base Creation â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.3</span></a>). Fine-tuning is not competitive with RAG. However, fine-tuning with multiple paraphrases still provides a significant improvement over the baseline. We note that combining RAG with fine-tuning shows inferior performance compared to RAG alone.</p>
</div>
<div id="S5.p10" class="ltx_para">
<p id="S5.p10.1" class="ltx_p">It is worth noting that although the questions are based on information the models were not exposed to during training, the results of the base models surpass <math id="S5.p10.1.m1.1" class="ltx_Math" alttext="\frac{1}{L}=0.25" display="inline"><semantics id="S5.p10.1.m1.1a"><mrow id="S5.p10.1.m1.1.1" xref="S5.p10.1.m1.1.1.cmml"><mfrac id="S5.p10.1.m1.1.1.2" xref="S5.p10.1.m1.1.1.2.cmml"><mn id="S5.p10.1.m1.1.1.2.2" xref="S5.p10.1.m1.1.1.2.2.cmml">1</mn><mi id="S5.p10.1.m1.1.1.2.3" xref="S5.p10.1.m1.1.1.2.3.cmml">L</mi></mfrac><mo id="S5.p10.1.m1.1.1.1" xref="S5.p10.1.m1.1.1.1.cmml">=</mo><mn id="S5.p10.1.m1.1.1.3" xref="S5.p10.1.m1.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p10.1.m1.1b"><apply id="S5.p10.1.m1.1.1.cmml" xref="S5.p10.1.m1.1.1"><eq id="S5.p10.1.m1.1.1.1.cmml" xref="S5.p10.1.m1.1.1.1"></eq><apply id="S5.p10.1.m1.1.1.2.cmml" xref="S5.p10.1.m1.1.1.2"><divide id="S5.p10.1.m1.1.1.2.1.cmml" xref="S5.p10.1.m1.1.1.2"></divide><cn type="integer" id="S5.p10.1.m1.1.1.2.2.cmml" xref="S5.p10.1.m1.1.1.2.2">1</cn><ci id="S5.p10.1.m1.1.1.2.3.cmml" xref="S5.p10.1.m1.1.1.2.3">ğ¿</ci></apply><cn type="float" id="S5.p10.1.m1.1.1.3.cmml" xref="S5.p10.1.m1.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p10.1.m1.1c">\frac{1}{L}=0.25</annotation></semantics></math>. This can partially be explained by the models using reasoning and/or pre-existing knowledge when answering questions that are not independent of the past information. Some examples of this can be found in&nbsp;<a href="#A3" title="Appendix C Current Events Existing Knowledge Examples â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
<div id="S5.p11" class="ltx_para">
<p id="S5.p11.1" class="ltx_p"><span id="S5.p11.1.1" class="ltx_text ltx_font_bold">Fine-Tuning vs. RAG:</span> In the results of both the MMLU and current events tasks, a significant advantage for RAG over fine-tuning is evident. While fine-tuning improved results compared to the base model in most cases, it was not competitive with the RAG approach.</p>
</div>
<div id="S5.p12" class="ltx_para">
<p id="S5.p12.1" class="ltx_p">Several factors might contribute to this behavior. Firstly, RAG not only adds knowledge to a model but also incorporates context relevant to the question, a feature lacking in fine-tuning. Additionally, fine-tuning may impact other capabilities of the model due to a degree of catastrophic forgetting. Finally, itâ€™s plausible that unsupervised fine-tuned models might benefit from further alignment through supervised or RL-based fine-tuning, as evidenced by the vastly improved performance of Orca2 over the base Llama2.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>The Importance of Repetition</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Unlike the other tasks, where the model has been exposed to aspects related to the topic during pretraining, <span id="S6.p1.1.1" class="ltx_text ltx_font_italic">current events</span> includes new information. In this case, standard regular fine-tuning not only did not improve the performance of Llama2 but also significantly degraded it. To improve the fine-tuning results, we explored augmentation of the data using paraphrases.</p>
</div>
<figure id="S6.F3" class="ltx_figure">
<p id="S6.F3.1.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S6.F3.1.1.1" class="ltx_text"><img src="/html/2312.05934/assets/media/loss_curve.png" id="S6.F3.1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="393" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S6.F3.4.2" class="ltx_text" style="font-size:90%;">Training loss over time for Mistral-7B.</span></figcaption>
</figure>
<figure id="S6.F4" class="ltx_figure"><img src="/html/2312.05934/assets/media/paraphrases_plot.png" id="S6.F4.g1" class="ltx_graphics ltx_img_landscape" width="598" height="416" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F4.3.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S6.F4.4.2" class="ltx_text" style="font-size:90%;">Model accuracy on the <span id="S6.F4.4.2.1" class="ltx_text ltx_font_italic">current events</span> task as a function of the number of paraphrases.</span></figcaption>
</figure>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p"><span id="S6.p2.1.1" class="ltx_text ltx_font_bold">Data Augmentation</span> Data augmentation is a well-established method for enhancing the performance of language models and has been surveyed extensively&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Shorten et&nbsp;al., <a href="#bib.bib38" title="" class="ltx_ref">2021</a>)</cite>. Using generative models for augmentations has also been used successfully to improve classification models in the past&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Sharma et&nbsp;al., <a href="#bib.bib37" title="" class="ltx_ref">2022</a>)</cite>.
An example of data augmentation using paraphrasing can be found in &nbsp;<a href="#A2" title="Appendix B Paraphrase Examples â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p"><span id="S6.p3.1.1" class="ltx_text ltx_font_bold">Monotonic Improvement</span> This approach resulted in notable improvements in our results, showcasing a direct correlation between the number of paraphrases utilized and the modelsâ€™ accuracy.
Our experimentation revealed a compelling trend, shown in&nbsp;<a href="#S6.F4" title="In 6 The Importance of Repetition â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">4</span></a>. For all models tested, the accuracy was a monotonically increasing function of the number of paraphrases used. This observation strongly suggests the positive impact of paraphrase augmentation, yielding information repetition, on the modelâ€™s ability to comprehend and generalize new knowledge from limited data.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p"><span id="S6.p4.1.1" class="ltx_text ltx_font_bold">Learning New Information</span> In&nbsp;<a href="#S6.F3" title="In 6 The Importance of Repetition â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a>, we can see an interesting phenomenon observed throughout our experiments. After each epoch, i.e., completing another iteration over the entire dataset, the training loss drops significantly. This is consistent with what is known about LLMs memorizing the data during training and overfitting&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Tirumala et&nbsp;al., <a href="#bib.bib44" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S6.p5" class="ltx_para">
<p id="S6.p5.1" class="ltx_p">Our hypothesis is as follows:</p>
<blockquote id="S6.p5.2" class="ltx_quote">
<p id="S6.p5.2.1" class="ltx_p">In order to teach pre-trained LLMs <span id="S6.p5.2.1.1" class="ltx_text ltx_font_bold">new</span> knowledge, the knowledge must be repeated in numerous ways.</p>
</blockquote>
</div>
<div id="S6.p6" class="ltx_para ltx_noindent">
<p id="S6.p6.2" class="ltx_p">This is well known for LLM pre-training <cite class="ltx_cite ltx_citemacro_citep">(Kandpal et&nbsp;al., <a href="#bib.bib17" title="" class="ltx_ref">2023</a>)</cite>, and we see in this case that this holds for fine-tuning as well. The rationale for this hypothesis is that mere memorization of sentences does not entail knowledge of their content, as was already shown in&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Berglund et&nbsp;al., <a href="#bib.bib2" title="" class="ltx_ref">2023</a>)</cite>. By providing the information in numerous forms (like the data augmentation process we used), the various relationships in the data (e.g., <math id="S6.p6.1.m1.3" class="ltx_Math" alttext="a\implies b,\>b\hbox to0.0pt{$\quad\not$\hss}\implies c" display="inline"><semantics id="S6.p6.1.m1.3a"><mrow id="S6.p6.1.m1.3.3.2" xref="S6.p6.1.m1.3.3.3.cmml"><mrow id="S6.p6.1.m1.2.2.1.1" xref="S6.p6.1.m1.2.2.1.1.cmml"><mi id="S6.p6.1.m1.2.2.1.1.2" xref="S6.p6.1.m1.2.2.1.1.2.cmml">a</mi><mo stretchy="false" id="S6.p6.1.m1.2.2.1.1.1" xref="S6.p6.1.m1.2.2.1.1.1.cmml">âŸ¹</mo><mi id="S6.p6.1.m1.2.2.1.1.3" xref="S6.p6.1.m1.2.2.1.1.3.cmml">b</mi></mrow><mo rspace="0.387em" id="S6.p6.1.m1.3.3.2.3" xref="S6.p6.1.m1.3.3.3a.cmml">,</mo><mrow id="S6.p6.1.m1.3.3.2.2" xref="S6.p6.1.m1.3.3.2.2.cmml"><mrow id="S6.p6.1.m1.3.3.2.2.2" xref="S6.p6.1.m1.3.3.2.2.2.cmml"><mi id="S6.p6.1.m1.3.3.2.2.2.2" xref="S6.p6.1.m1.3.3.2.2.2.2.cmml">b</mi><mo lspace="1.167em" rspace="0em" id="S6.p6.1.m1.3.3.2.2.2.1" xref="S6.p6.1.m1.3.3.2.2.2.1.cmml">â€‹</mo><mpadded width="0.0pt" id="S6.p6.1.m1.1.1.1" xref="S6.p6.1.m1.1.1.1.cmml"><mi mathvariant="normal" id="S6.p6.1.m1.1.1.1a" xref="S6.p6.1.m1.1.1.1.cmml">ï¼</mi></mpadded></mrow><mo stretchy="false" id="S6.p6.1.m1.3.3.2.2.1" xref="S6.p6.1.m1.3.3.2.2.1.cmml">âŸ¹</mo><mi id="S6.p6.1.m1.3.3.2.2.3" xref="S6.p6.1.m1.3.3.2.2.3.cmml">c</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.p6.1.m1.3b"><apply id="S6.p6.1.m1.3.3.3.cmml" xref="S6.p6.1.m1.3.3.2"><csymbol cd="ambiguous" id="S6.p6.1.m1.3.3.3a.cmml" xref="S6.p6.1.m1.3.3.2.3">formulae-sequence</csymbol><apply id="S6.p6.1.m1.2.2.1.1.cmml" xref="S6.p6.1.m1.2.2.1.1"><implies id="S6.p6.1.m1.2.2.1.1.1.cmml" xref="S6.p6.1.m1.2.2.1.1.1"></implies><ci id="S6.p6.1.m1.2.2.1.1.2.cmml" xref="S6.p6.1.m1.2.2.1.1.2">ğ‘</ci><ci id="S6.p6.1.m1.2.2.1.1.3.cmml" xref="S6.p6.1.m1.2.2.1.1.3">ğ‘</ci></apply><apply id="S6.p6.1.m1.3.3.2.2.cmml" xref="S6.p6.1.m1.3.3.2.2"><implies id="S6.p6.1.m1.3.3.2.2.1.cmml" xref="S6.p6.1.m1.3.3.2.2.1"></implies><apply id="S6.p6.1.m1.3.3.2.2.2.cmml" xref="S6.p6.1.m1.3.3.2.2.2"><times id="S6.p6.1.m1.3.3.2.2.2.1.cmml" xref="S6.p6.1.m1.3.3.2.2.2.1"></times><ci id="S6.p6.1.m1.3.3.2.2.2.2.cmml" xref="S6.p6.1.m1.3.3.2.2.2.2">ğ‘</ci><not id="S6.p6.1.m1.1.1.1.cmml" xref="S6.p6.1.m1.1.1.1"></not></apply><ci id="S6.p6.1.m1.3.3.2.2.3.cmml" xref="S6.p6.1.m1.3.3.2.2.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.1.m1.3c">a\implies b,\&gt;b\hbox to0.0pt{$\quad\not$\hss}\implies c</annotation></semantics></math>) stand a higher chance of appearing naturally. We believe this can potentially both increase <math id="S6.p6.2.m2.2" class="ltx_Math" alttext="\mathcal{L}_{\mathcal{M},\mathcal{Q}}" display="inline"><semantics id="S6.p6.2.m2.2a"><msub id="S6.p6.2.m2.2.3" xref="S6.p6.2.m2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S6.p6.2.m2.2.3.2" xref="S6.p6.2.m2.2.3.2.cmml">â„’</mi><mrow id="S6.p6.2.m2.2.2.2.4" xref="S6.p6.2.m2.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S6.p6.2.m2.1.1.1.1" xref="S6.p6.2.m2.1.1.1.1.cmml">â„³</mi><mo id="S6.p6.2.m2.2.2.2.4.1" xref="S6.p6.2.m2.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S6.p6.2.m2.2.2.2.2" xref="S6.p6.2.m2.2.2.2.2.cmml">ğ’¬</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S6.p6.2.m2.2b"><apply id="S6.p6.2.m2.2.3.cmml" xref="S6.p6.2.m2.2.3"><csymbol cd="ambiguous" id="S6.p6.2.m2.2.3.1.cmml" xref="S6.p6.2.m2.2.3">subscript</csymbol><ci id="S6.p6.2.m2.2.3.2.cmml" xref="S6.p6.2.m2.2.3.2">â„’</ci><list id="S6.p6.2.m2.2.2.2.3.cmml" xref="S6.p6.2.m2.2.2.2.4"><ci id="S6.p6.2.m2.1.1.1.1.cmml" xref="S6.p6.2.m2.1.1.1.1">â„³</ci><ci id="S6.p6.2.m2.2.2.2.2.cmml" xref="S6.p6.2.m2.2.2.2.2">ğ’¬</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.2.m2.2c">\mathcal{L}_{\mathcal{M},\mathcal{Q}}</annotation></semantics></math> in general, as well as ameliorate Berglund et al.â€™s <span id="S6.p6.2.1" class="ltx_text ltx_font_italic">Reversal Curse</span>. While promising, this result still warrants further research.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion and Future Work</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Large language models possess vast amounts of knowledge on various topics. In this work, we tested their capability to adapt to new knowledge: both specialized and completely unseen. This is among the first studies to compare two prominent approaches in this domain, namely fine-tuning and retrieval augmented generation. While fine-tuning can be useful for many use-cases, we found that RAG is a more reliable choice for knowledge injection.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">Some aspects of this work still warrant further research. For example, we focused on unsupervised training as our primary fine-tuning method, as opposed to instruction-tuning or RL-based methods. Researching combinations of various techniques, with diverse auxiliary knowledge bases, may yield improved results. This approach, combined with our hypothesis from&nbsp;<a href="#S6" title="6 The Importance of Repetition â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">6</span></a>, could further enhance our understanding of knowledge injection via FT.</p>
</div>
<div id="S7.p3" class="ltx_para">
<p id="S7.p3.1" class="ltx_p">While we believe that this work further enhances our understanding of knowledge in LLMs, there is a lot more work to be done in this field. Specifically, more research is required regarding the question of knowledge representation in LLMs, especially from a theoretical perspective.</p>
</div>
<div id="S7.p4" class="ltx_para">
<p id="S7.p4.1" class="ltx_p">Finally, further efforts are needed to measure knowledge in LLMs. While we employed an empirical approach as described in&nbsp;<a href="#S2.E2" title="In 2 Background â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Equation</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>, it is important to explore other definitions and perspectives on knowledge as well, and extend upon this work.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Limitations</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">As in all machine learning applications, the choice of hyperparameters significantly impacts the results. We therefore strongly recommend optimizing all relevant hyperparameters for specific cases.</p>
</div>
<div id="S8.p2" class="ltx_para ltx_noindent">
<p id="S8.p2.1" class="ltx_p">We have supported our claims by running the experiments on three different models. However, generalization to other LLMs should be tested thoroughly. For example, GPT-4 achieves near perfect accuracy for some MMLU tasks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Nori et&nbsp;al., <a href="#bib.bib29" title="" class="ltx_ref">2023</a>)</cite>, and thus further improvement is not applicable.</p>
</div>
<div id="S8.p3" class="ltx_para">
<p id="S8.p3.1" class="ltx_p">Finally, while we chose various topics for the knowledge bases, all of our sources came from Wikipedia. Other datasets may yield different results, and must be evaluated carefully.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Attardi (2015)</span>
<span class="ltx_bibblock">
Attardi, G.

</span>
<span class="ltx_bibblock">Wikiextractor.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/attardi/wikiextractor" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/attardi/wikiextractor</a>, 2015.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berglund et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Berglund, L., Tong, M., Kaufmann, M., Balesni, M., Stickland, A.&nbsp;C., Korbak, T., and Evans, O.

</span>
<span class="ltx_bibblock">The reversal curse: Llms trained onâ€ a is bâ€ fail to learnâ€ b is aâ€.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2309.12288</em>, 2023.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Chen, S., Hou, Y., Cui, Y., Che, W., Liu, T., and Yu, X.

</span>
<span class="ltx_bibblock">Recall and learn: Fine-tuning deep pretrained language models with less forgetting.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2004.12651</em>, 2020.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Chen, X., Zhang, N., Xie, X., Deng, S., Yao, Y., Tan, C., Huang, F., Si, L., and Chen, H.

</span>
<span class="ltx_bibblock">Knowprompt: Knowledge-aware prompt-tuning with synergistic optimization for relation extraction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the ACM Web conference 2022</em>, pp.&nbsp; 2778â€“2788, 2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Chen, Y., Zhong, R., Zha, S., Karypis, G., and He, H.

</span>
<span class="ltx_bibblock">Meta-learning via language model in-context tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.07814</em>, 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chia et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Chia, Y.&nbsp;K., Hong, P., Bing, L., and Poria, S.

</span>
<span class="ltx_bibblock">Instructeval: Towards holistic evaluation of instruction-tuned large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.04757</em>, 2023.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Chung, H.&nbsp;W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y., Wang, X., Dehghani, M., Brahma, S., et&nbsp;al.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.11416</em>, 2022.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cohen et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Cohen, R., Geva, M., Berant, J., and Globerson, A.

</span>
<span class="ltx_bibblock">Crawling the internal knowledge-base of language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2301.12810</em>, 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Dua, D., Wang, Y., Dasigi, P., Stanovsky, G., Singh, S., and Gardner, M.

</span>
<span class="ltx_bibblock">Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1903.00161</em>, 2019.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Gao, L., Tow, J., Biderman, S., Black, S., DiPofi, A., Foster, C., Golding, L., Hsu, J., McDonell, K., Muennighoff, N., Phang, J., Reynolds, L., Tang, E., Thite, A., Wang, B., Wang, K., and Zou, A.

</span>
<span class="ltx_bibblock">A framework for few-shot language model evaluation, September 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.5281/zenodo.5371628" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.5281/zenodo.5371628</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et&nbsp;al. (2013)</span>
<span class="ltx_bibblock">
Goodfellow, I.&nbsp;J., Mirza, M., Xiao, D., Courville, A., and Bengio, Y.

</span>
<span class="ltx_bibblock">An empirical investigation of catastrophic forgetting in gradient-based neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1312.6211</em>, 2013.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the International Conference on Learning Representations (ICLR)</em>, 2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., and Li, J.

</span>
<span class="ltx_bibblock">A survey of knowledge enhanced pre-trained language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Knowledge and Data Engineering</em>, 2023.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Huang, Q., Tao, M., An, Z., Zhang, C., Jiang, C., Chen, Z., Wu, Z., and Feng, Y.

</span>
<span class="ltx_bibblock">Lawyer llama technical report.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.15062</em>, 2023.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Jiang, A.&nbsp;Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D.&nbsp;S., Casas, D. d.&nbsp;l., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., et&nbsp;al.

</span>
<span class="ltx_bibblock">Mistral 7b.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.06825</em>, 2023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Johnson, J., Douze, M., and JÃ©gou, H.

</span>
<span class="ltx_bibblock">Billion-scale similarity search with GPUs.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em>, 7(3):535â€“547, 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kandpal et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Kandpal, N., Deng, H., Roberts, A., Wallace, E., and Raffel, C.

</span>
<span class="ltx_bibblock">Large language models struggle to learn long-tail knowledge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pp.&nbsp; 15696â€“15707. PMLR, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirkpatrick et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A.&nbsp;A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et&nbsp;al.

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting in neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the national academy of sciences</em>, 114(13):3521â€“3526, 2017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lampinen et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Lampinen, A.&nbsp;K., Dasgupta, I., Chan, S.&nbsp;C., Matthewson, K., Tessler, M.&nbsp;H., Creswell, A., McClelland, J.&nbsp;L., Wang, J.&nbsp;X., and Hill, F.

</span>
<span class="ltx_bibblock">Can language models learn from explanations in context?

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.02329</em>, 2022.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lauscher et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Lauscher, A., Majewska, O., Ribeiro, L.&nbsp;F., Gurevych, I., Rozanov, N., and GlavaÅ¡, G.

</span>
<span class="ltx_bibblock">Common sense or world knowledge? investigating adapter-based knowledge injection into pretrained transformers.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.11787</em>, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., KÃ¼ttler, H., Lewis, M., Yih, W.-t., RocktÃ¤schel, T., et&nbsp;al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 33:9459â€“9474, 2020.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Liu, W., Zhou, P., Zhao, Z., Wang, Z., Ju, Q., Deng, H., and Wang, P.

</span>
<span class="ltx_bibblock">K-bert: Enabling language representation with knowledge graph.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume&nbsp;34, pp.&nbsp; 2901â€“2908, 2020.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Luo, Y., Yang, Z., Meng, F., Li, Y., Zhou, J., and Zhang, Y.

</span>
<span class="ltx_bibblock">An empirical study of catastrophic forgetting in large language models during continual fine-tuning.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2308.08747</em>, 2023.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Min, S., Lewis, M., Zettlemoyer, L., and Hajishirzi, H.

</span>
<span class="ltx_bibblock">Metaicl: Learning to learn in context.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.15943</em>, 2021.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Mishra, S., Khashabi, D., Baral, C., and Hajishirzi, H.

</span>
<span class="ltx_bibblock">Cross-task generalization via natural language crowdsourcing instructions.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.08773</em>, 2021.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitra et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Mitra, A., Del&nbsp;Corro, L., Mahajan, S., Codas, A., Simoes, C., Agrawal, S., Chen, X., Razdaibiedina, A., Jones, E., Aggarwal, K., et&nbsp;al.

</span>
<span class="ltx_bibblock">Orca 2: Teaching small language models how to reason.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2311.11045</em>, 2023.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neelakantan et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Neelakantan, A., Xu, T., Puri, R., Radford, A., Han, J.&nbsp;M., Tworek, J., Yuan, Q., Tezak, N.&nbsp;A., Kim, J.&nbsp;W., Hallacy, C., Heidecke, J., Shyam, P., Power, B., Nekoul, T.&nbsp;E., Sastry, G., Krueger, G., Schnurr, D.&nbsp;P., Such, F.&nbsp;P., Hsu, K. S.-K., Thompson, M., Khan, T., Sherbakov, T., Jang, J., Welinder, P., and Weng, L.

</span>
<span class="ltx_bibblock">Text and code embeddings by contrastive pre-training.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2201.10005, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:246275593" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:246275593</a>.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen (2023)</span>
<span class="ltx_bibblock">
Nguyen, H.-T.

</span>
<span class="ltx_bibblock">A brief report on lawgpt 1.0: A virtual legal assistant based on gpt-3.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2302.05729</em>, 2023.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nori et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Nori, H., King, N., McKinney, S.&nbsp;M., Carignan, D., and Horvitz, E.

</span>
<span class="ltx_bibblock">Capabilities of gpt-4 on medical challenge problems.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2303.13375, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:257687695" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:257687695</a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2303.08774, 2023.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:257532815" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:257532815</a>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et&nbsp;al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 35:27730â€“27744, 2022.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Petroni, F., RocktÃ¤schel, T., Lewis, P., Bakhtin, A., Wu, Y., Miller, A.&nbsp;H., and Riedel, S.

</span>
<span class="ltx_bibblock">Language models as knowledge bases?

</span>
<span class="ltx_bibblock"><em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.01066</em>, 2019.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et&nbsp;al.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">OpenAI blog</em>, 1(8):9, 2019.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Rafailov, R., Sharma, A., Mitchell, E., Ermon, S., Manning, C.&nbsp;D., and Finn, C.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.18290</em>, 2023.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sakaguchi et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Sakaguchi, K., Bras, R.&nbsp;L., Bhagavatula, C., and Choi, Y.

</span>
<span class="ltx_bibblock">Winogrande: An adversarial winograd schema challenge at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Communications of the ACM</em>, 64(9):99â€“106, 2021.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schulman et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.

</span>
<span class="ltx_bibblock">Proximal policy optimization algorithms.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1707.06347</em>, 2017.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sharma et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Sharma, S., Joshi, A., Mukhija, N., Zhao, Y., Bhathena, H., Singh, P., Santhanam, S., and Biswas, P.

</span>
<span class="ltx_bibblock">Systematic review of effect of data augmentation using paraphrasing on named entity recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research</em>, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=rc2h1h89aDi" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=rc2h1h89aDi</a>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shorten et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Shorten, C., Khoshgoftaar, T.&nbsp;M., and Furht, B.

</span>
<span class="ltx_bibblock">Text data augmentation for deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Journal of Big Data</em>, 8, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:236096559" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:236096559</a>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singhal et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Singhal, K., Azizi, S., Tu, T., Mahdavi, S.&nbsp;S., Wei, J., Chung, H.&nbsp;W., Scales, N., Tanwani, A., Cole-Lewis, H., Pfohl, S., et&nbsp;al.

</span>
<span class="ltx_bibblock">Large language models encode clinical knowledge.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Nature</em>, 620(7972):172â€“180, 2023a.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singhal et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Singhal, K., Tu, T., Gottweis, J., Sayres, R., Wulczyn, E., Hou, L., Clark, K., Pfohl, S., Cole-Lewis, H., Neal, D., et&nbsp;al.

</span>
<span class="ltx_bibblock">Towards expert-level medical question answering with large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.09617</em>, 2023b.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Srivastava, A., Rastogi, A., Rao, A., Shoeb, A. A.&nbsp;M., Abid, A., Fisch, A., Brown, A.&nbsp;R., Santoro, A., Gupta, A., Garriga-Alonso, A., et&nbsp;al.

</span>
<span class="ltx_bibblock">Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.04615</em>, 2022.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tan, Y., Min, D., Li, Y., Li, W., Hu, N., Chen, Y., and Qi, G.

</span>
<span class="ltx_bibblock">Can chatgpt replace traditional kbqa models? an in-depth analysis of the question answering performance of the gpt llm family.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">International Semantic Web Conference</em>, pp.&nbsp; 348â€“367. Springer, 2023.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li, X., Guestrin, C., Liang, P., and Hashimoto, T.&nbsp;B.

</span>
<span class="ltx_bibblock">Alpaca: A strong, replicable instruction-following model.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Stanford Center for Research on Foundation Models. https://crfm. stanford. edu/2023/03/13/alpaca. html</em>, 3(6):7, 2023.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tirumala et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Tirumala, K., Markosyan, A.&nbsp;H., Zettlemoyer, L., and Aghajanyan, A.

</span>
<span class="ltx_bibblock">Memorization without overfitting: Analyzing the training dynamics of large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2205.10770, 2022.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:248986465" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:248986465</a>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2307.09288</em>, 2023.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tunstall et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Tunstall, L., Beeching, E., Lambert, N., Rajani, N., Rasul, K., Belkada, Y., Huang, S., von Werra, L., Fourrier, C., Habib, N., et&nbsp;al.

</span>
<span class="ltx_bibblock">Zephyr: Direct distillation of lm alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.16944</em>, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Wang, C., Liu, X., Yue, Y., Tang, X., Zhang, T., Jiayang, C., Yao, Y., Gao, W., Hu, X., Qi, Z., et&nbsp;al.

</span>
<span class="ltx_bibblock">Survey on factuality in large language models: Knowledge, retrieval and domain-specificity.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2310.07521</em>, 2023.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Wang, R., Tang, D., Duan, N., Wei, Z., Huang, X., Cao, G., Jiang, D., Zhou, M., et&nbsp;al.

</span>
<span class="ltx_bibblock">K-adapter: Infusing knowledge into pre-trained models with adapters.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.01808</em>, 2020.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Wang, Y., Mishra, S., Alipoormolabashi, P., Kordi, Y., Mirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran, A.&nbsp;S., Naik, A., Stap, D., et&nbsp;al.

</span>
<span class="ltx_bibblock">Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.07705</em>, 2022.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2023a)</span>
<span class="ltx_bibblock">
Wu, C., Zhang, X., Zhang, Y., Wang, Y., and Xie, W.

</span>
<span class="ltx_bibblock">Pmc-llama: Further finetuning llama on medical papers.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2304.14454</em>, 2023a.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2023b)</span>
<span class="ltx_bibblock">
Wu, S., Irsoy, O., Lu, S., Dabravolski, V., Dredze, M., Gehrmann, S., Kambadur, P., Rosenberg, D., and Mann, G.

</span>
<span class="ltx_bibblock">Bloomberggpt: A large language model for finance.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2303.17564</em>, 2023b.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Xiao, S., Liu, Z., Zhang, P., and Muennighoff, N.

</span>
<span class="ltx_bibblock">C-pack: Packaged resources to advance general chinese embedding, 2023.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Yang, H., Liu, X.-Y., and Wang, C.&nbsp;D.

</span>
<span class="ltx_bibblock">Fingpt: Open-source financial large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2306.06031</em>, 2023.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yu, W., Zhu, C., Li, Z., Hu, Z., Wang, Q., Ji, H., and Jiang, M.

</span>
<span class="ltx_bibblock">A survey of knowledge-enhanced text generation.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys</em>, 54(11s):1â€“38, 2022.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Zhou, C., Liu, P., Xu, P., Iyer, S., Sun, J., Mao, Y., Ma, X., Efrat, A., Yu, P., Yu, L., et&nbsp;al.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.11206</em>, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>RAG Ablation Study</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.7" class="ltx_p">As mentioned in <a href="#S5" title="5 Experiments and Results â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">5</span></a>, we compared various values of <math id="A1.p1.1.m1.3" class="ltx_Math" alttext="K\in\{0,\ldots,5\}" display="inline"><semantics id="A1.p1.1.m1.3a"><mrow id="A1.p1.1.m1.3.4" xref="A1.p1.1.m1.3.4.cmml"><mi id="A1.p1.1.m1.3.4.2" xref="A1.p1.1.m1.3.4.2.cmml">K</mi><mo id="A1.p1.1.m1.3.4.1" xref="A1.p1.1.m1.3.4.1.cmml">âˆˆ</mo><mrow id="A1.p1.1.m1.3.4.3.2" xref="A1.p1.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="A1.p1.1.m1.3.4.3.2.1" xref="A1.p1.1.m1.3.4.3.1.cmml">{</mo><mn id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml">0</mn><mo id="A1.p1.1.m1.3.4.3.2.2" xref="A1.p1.1.m1.3.4.3.1.cmml">,</mo><mi mathvariant="normal" id="A1.p1.1.m1.2.2" xref="A1.p1.1.m1.2.2.cmml">â€¦</mi><mo id="A1.p1.1.m1.3.4.3.2.3" xref="A1.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="A1.p1.1.m1.3.3" xref="A1.p1.1.m1.3.3.cmml">5</mn><mo stretchy="false" id="A1.p1.1.m1.3.4.3.2.4" xref="A1.p1.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.3b"><apply id="A1.p1.1.m1.3.4.cmml" xref="A1.p1.1.m1.3.4"><in id="A1.p1.1.m1.3.4.1.cmml" xref="A1.p1.1.m1.3.4.1"></in><ci id="A1.p1.1.m1.3.4.2.cmml" xref="A1.p1.1.m1.3.4.2">ğ¾</ci><set id="A1.p1.1.m1.3.4.3.1.cmml" xref="A1.p1.1.m1.3.4.3.2"><cn type="integer" id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1">0</cn><ci id="A1.p1.1.m1.2.2.cmml" xref="A1.p1.1.m1.2.2">â€¦</ci><cn type="integer" id="A1.p1.1.m1.3.3.cmml" xref="A1.p1.1.m1.3.3">5</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.3c">K\in\{0,\ldots,5\}</annotation></semantics></math>, shown in <a href="#A1.T3" title="In Appendix A RAG Ablation Study â€£ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a>.We were unable to find an optimal value of <math id="A1.p1.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A1.p1.2.m2.1a"><mi id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b"><ci id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">K</annotation></semantics></math> per model, per <math id="A1.p1.3.m3.1" class="ltx_Math" alttext="0/5" display="inline"><semantics id="A1.p1.3.m3.1a"><mrow id="A1.p1.3.m3.1.1" xref="A1.p1.3.m3.1.1.cmml"><mn id="A1.p1.3.m3.1.1.2" xref="A1.p1.3.m3.1.1.2.cmml">0</mn><mo id="A1.p1.3.m3.1.1.1" xref="A1.p1.3.m3.1.1.1.cmml">/</mo><mn id="A1.p1.3.m3.1.1.3" xref="A1.p1.3.m3.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.3.m3.1b"><apply id="A1.p1.3.m3.1.1.cmml" xref="A1.p1.3.m3.1.1"><divide id="A1.p1.3.m3.1.1.1.cmml" xref="A1.p1.3.m3.1.1.1"></divide><cn type="integer" id="A1.p1.3.m3.1.1.2.cmml" xref="A1.p1.3.m3.1.1.2">0</cn><cn type="integer" id="A1.p1.3.m3.1.1.3.cmml" xref="A1.p1.3.m3.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.3.m3.1c">0/5</annotation></semantics></math>-shot, or per task. In fact, other than Anatomy that worked well with <math id="A1.p1.4.m4.1" class="ltx_Math" alttext="K=2" display="inline"><semantics id="A1.p1.4.m4.1a"><mrow id="A1.p1.4.m4.1.1" xref="A1.p1.4.m4.1.1.cmml"><mi id="A1.p1.4.m4.1.1.2" xref="A1.p1.4.m4.1.1.2.cmml">K</mi><mo id="A1.p1.4.m4.1.1.1" xref="A1.p1.4.m4.1.1.1.cmml">=</mo><mn id="A1.p1.4.m4.1.1.3" xref="A1.p1.4.m4.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.4.m4.1b"><apply id="A1.p1.4.m4.1.1.cmml" xref="A1.p1.4.m4.1.1"><eq id="A1.p1.4.m4.1.1.1.cmml" xref="A1.p1.4.m4.1.1.1"></eq><ci id="A1.p1.4.m4.1.1.2.cmml" xref="A1.p1.4.m4.1.1.2">ğ¾</ci><cn type="integer" id="A1.p1.4.m4.1.1.3.cmml" xref="A1.p1.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.4.m4.1c">K=2</annotation></semantics></math> consistently, there seems to be no patterns that aid in predicting the performance per <math id="A1.p1.5.m5.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A1.p1.5.m5.1a"><mi id="A1.p1.5.m5.1.1" xref="A1.p1.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.p1.5.m5.1b"><ci id="A1.p1.5.m5.1.1.cmml" xref="A1.p1.5.m5.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.5.m5.1c">K</annotation></semantics></math>, unlike the results presented in&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lewis et&nbsp;al., <a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite> for other setups. Moreover, the gap between the best and worst performing <math id="A1.p1.6.m6.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A1.p1.6.m6.1a"><mi id="A1.p1.6.m6.1.1" xref="A1.p1.6.m6.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.p1.6.m6.1b"><ci id="A1.p1.6.m6.1.1.cmml" xref="A1.p1.6.m6.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.6.m6.1c">K</annotation></semantics></math>s can be large.
<br class="ltx_break">Unfortunately, we must conclude that this additional hyperparameter is unstable. This is a downside of using RAG in practice, and the choice of <math id="A1.p1.7.m7.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A1.p1.7.m7.1a"><mi id="A1.p1.7.m7.1.1" xref="A1.p1.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.p1.7.m7.1b"><ci id="A1.p1.7.m7.1.1.cmml" xref="A1.p1.7.m7.1.1">ğ¾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.7.m7.1c">K</annotation></semantics></math> cannot be ignored.</p>
</div>
<figure id="A1.T3" class="ltx_table">
<table id="A1.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T3.1.1" class="ltx_tr">
<th id="A1.T3.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" rowspan="2"><span id="A1.T3.1.1.2.1" class="ltx_text">Task</span></th>
<th id="A1.T3.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" rowspan="2"><span id="A1.T3.1.1.3.1" class="ltx_text">Model</span></th>
<th id="A1.T3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="5"># Retrieved documents (<math id="A1.T3.1.1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A1.T3.1.1.1.m1.1a"><mi id="A1.T3.1.1.1.m1.1.1" xref="A1.T3.1.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.m1.1b"><ci id="A1.T3.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.m1.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.m1.1c">k</annotation></semantics></math>)</th>
</tr>
<tr id="A1.T3.1.2.1" class="ltx_tr">
<th id="A1.T3.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">1</th>
<th id="A1.T3.1.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">2</th>
<th id="A1.T3.1.2.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">3</th>
<th id="A1.T3.1.2.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">4</th>
<th id="A1.T3.1.2.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">5</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T3.1.3.1" class="ltx_tr">
<th id="A1.T3.1.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="A1.T3.1.3.1.1.1" class="ltx_text">Anatomy (0-shot)</span></th>
<th id="A1.T3.1.3.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Mistral 7B</th>
<td id="A1.T3.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">0.615</td>
<td id="A1.T3.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.1.3.1.4.1" class="ltx_text ltx_font_bold">0.681</span></td>
<td id="A1.T3.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">0.630</td>
<td id="A1.T3.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">0.644</td>
<td id="A1.T3.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">0.622</td>
</tr>
<tr id="A1.T3.1.4.2" class="ltx_tr">
<th id="A1.T3.1.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.4.2.2" class="ltx_td ltx_align_center">0.444</td>
<td id="A1.T3.1.4.2.3" class="ltx_td ltx_align_center"><span id="A1.T3.1.4.2.3.1" class="ltx_text ltx_font_bold">0.489</span></td>
<td id="A1.T3.1.4.2.4" class="ltx_td ltx_align_center">0.467</td>
<td id="A1.T3.1.4.2.5" class="ltx_td ltx_align_center">0.474</td>
<td id="A1.T3.1.4.2.6" class="ltx_td ltx_align_center">0.481</td>
</tr>
<tr id="A1.T3.1.5.3" class="ltx_tr">
<th id="A1.T3.1.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.5.3.2" class="ltx_td ltx_align_center">0.607</td>
<td id="A1.T3.1.5.3.3" class="ltx_td ltx_align_center"><span id="A1.T3.1.5.3.3.1" class="ltx_text ltx_font_bold">0.637</span></td>
<td id="A1.T3.1.5.3.4" class="ltx_td ltx_align_center">0.600</td>
<td id="A1.T3.1.5.3.5" class="ltx_td ltx_align_center">0.585</td>
<td id="A1.T3.1.5.3.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.5.3.6.1" class="ltx_text ltx_font_bold">0.637</span></td>
</tr>
<tr id="A1.T3.1.6.4" class="ltx_tr">
<th id="A1.T3.1.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="A1.T3.1.6.4.1.1" class="ltx_text">Anatomy (5-shot)</span></th>
<th id="A1.T3.1.6.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Mistral 7B</th>
<td id="A1.T3.1.6.4.3" class="ltx_td ltx_align_center">0.659</td>
<td id="A1.T3.1.6.4.4" class="ltx_td ltx_align_center">0.667</td>
<td id="A1.T3.1.6.4.5" class="ltx_td ltx_align_center">0.659</td>
<td id="A1.T3.1.6.4.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.6.4.6.1" class="ltx_text ltx_font_bold">0.681</span></td>
<td id="A1.T3.1.6.4.7" class="ltx_td ltx_align_center">0.674</td>
</tr>
<tr id="A1.T3.1.7.5" class="ltx_tr">
<th id="A1.T3.1.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.7.5.2" class="ltx_td ltx_align_center">0.496</td>
<td id="A1.T3.1.7.5.3" class="ltx_td ltx_align_center"><span id="A1.T3.1.7.5.3.1" class="ltx_text ltx_font_bold">0.563</span></td>
<td id="A1.T3.1.7.5.4" class="ltx_td ltx_align_center">0.541</td>
<td id="A1.T3.1.7.5.5" class="ltx_td ltx_align_center">0.526</td>
<td id="A1.T3.1.7.5.6" class="ltx_td ltx_align_center">0.526</td>
</tr>
<tr id="A1.T3.1.8.6" class="ltx_tr">
<th id="A1.T3.1.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.8.6.2" class="ltx_td ltx_align_center">0.630</td>
<td id="A1.T3.1.8.6.3" class="ltx_td ltx_align_center"><span id="A1.T3.1.8.6.3.1" class="ltx_text ltx_font_bold">0.659</span></td>
<td id="A1.T3.1.8.6.4" class="ltx_td ltx_align_center">0.600</td>
<td id="A1.T3.1.8.6.5" class="ltx_td ltx_align_center">0.600</td>
<td id="A1.T3.1.8.6.6" class="ltx_td ltx_align_center">0.600</td>
</tr>
<tr id="A1.T3.1.9.7" class="ltx_tr">
<th id="A1.T3.1.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="A1.T3.1.9.7.1.1" class="ltx_text">Astronomy (0-shot)</span></th>
<th id="A1.T3.1.9.7.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Mistral 7B</th>
<td id="A1.T3.1.9.7.3" class="ltx_td ltx_align_center ltx_border_t">0.651</td>
<td id="A1.T3.1.9.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.1.9.7.4.1" class="ltx_text ltx_font_bold">0.678</span></td>
<td id="A1.T3.1.9.7.5" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.1.9.7.5.1" class="ltx_text ltx_font_bold">0.678</span></td>
<td id="A1.T3.1.9.7.6" class="ltx_td ltx_align_center ltx_border_t">0.664</td>
<td id="A1.T3.1.9.7.7" class="ltx_td ltx_align_center ltx_border_t">0.664</td>
</tr>
<tr id="A1.T3.1.10.8" class="ltx_tr">
<th id="A1.T3.1.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.10.8.2" class="ltx_td ltx_align_center">0.447</td>
<td id="A1.T3.1.10.8.3" class="ltx_td ltx_align_center">0.434</td>
<td id="A1.T3.1.10.8.4" class="ltx_td ltx_align_center">0.447</td>
<td id="A1.T3.1.10.8.5" class="ltx_td ltx_align_center">0.434</td>
<td id="A1.T3.1.10.8.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.10.8.6.1" class="ltx_text ltx_font_bold">0.467</span></td>
</tr>
<tr id="A1.T3.1.11.9" class="ltx_tr">
<th id="A1.T3.1.11.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.11.9.2" class="ltx_td ltx_align_center">0.711</td>
<td id="A1.T3.1.11.9.3" class="ltx_td ltx_align_center">0.730</td>
<td id="A1.T3.1.11.9.4" class="ltx_td ltx_align_center">0.730</td>
<td id="A1.T3.1.11.9.5" class="ltx_td ltx_align_center"><span id="A1.T3.1.11.9.5.1" class="ltx_text ltx_font_bold">0.750</span></td>
<td id="A1.T3.1.11.9.6" class="ltx_td ltx_align_center">0.730</td>
</tr>
<tr id="A1.T3.1.12.10" class="ltx_tr">
<th id="A1.T3.1.12.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="A1.T3.1.12.10.1.1" class="ltx_text">Astronomy (5-shot)</span></th>
<th id="A1.T3.1.12.10.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Mistral 7B</th>
<td id="A1.T3.1.12.10.3" class="ltx_td ltx_align_center">0.704</td>
<td id="A1.T3.1.12.10.4" class="ltx_td ltx_align_center">0.684</td>
<td id="A1.T3.1.12.10.5" class="ltx_td ltx_align_center">0.658</td>
<td id="A1.T3.1.12.10.6" class="ltx_td ltx_align_center">0.684</td>
<td id="A1.T3.1.12.10.7" class="ltx_td ltx_align_center"><span id="A1.T3.1.12.10.7.1" class="ltx_text ltx_font_bold">0.724</span></td>
</tr>
<tr id="A1.T3.1.13.11" class="ltx_tr">
<th id="A1.T3.1.13.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.13.11.2" class="ltx_td ltx_align_center">0.461</td>
<td id="A1.T3.1.13.11.3" class="ltx_td ltx_align_center">0.447</td>
<td id="A1.T3.1.13.11.4" class="ltx_td ltx_align_center"><span id="A1.T3.1.13.11.4.1" class="ltx_text ltx_font_bold">0.474</span></td>
<td id="A1.T3.1.13.11.5" class="ltx_td ltx_align_center">0.428</td>
<td id="A1.T3.1.13.11.6" class="ltx_td ltx_align_center">0.454</td>
</tr>
<tr id="A1.T3.1.14.12" class="ltx_tr">
<th id="A1.T3.1.14.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.14.12.2" class="ltx_td ltx_align_center">0.730</td>
<td id="A1.T3.1.14.12.3" class="ltx_td ltx_align_center">0.737</td>
<td id="A1.T3.1.14.12.4" class="ltx_td ltx_align_center">0.750</td>
<td id="A1.T3.1.14.12.5" class="ltx_td ltx_align_center">0.743</td>
<td id="A1.T3.1.14.12.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.14.12.6.1" class="ltx_text ltx_font_bold">0.763</span></td>
</tr>
<tr id="A1.T3.1.15.13" class="ltx_tr">
<th id="A1.T3.1.15.13.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="A1.T3.1.15.13.1.1" class="ltx_text">Biology (0-shot)</span></th>
<th id="A1.T3.1.15.13.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Mistral 7B</th>
<td id="A1.T3.1.15.13.3" class="ltx_td ltx_align_center ltx_border_t">0.736</td>
<td id="A1.T3.1.15.13.4" class="ltx_td ltx_align_center ltx_border_t">0.722</td>
<td id="A1.T3.1.15.13.5" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.1.15.13.5.1" class="ltx_text ltx_font_bold">0.757</span></td>
<td id="A1.T3.1.15.13.6" class="ltx_td ltx_align_center ltx_border_t">0.743</td>
<td id="A1.T3.1.15.13.7" class="ltx_td ltx_align_center ltx_border_t">0.736</td>
</tr>
<tr id="A1.T3.1.16.14" class="ltx_tr">
<th id="A1.T3.1.16.14.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.16.14.2" class="ltx_td ltx_align_center">0.438</td>
<td id="A1.T3.1.16.14.3" class="ltx_td ltx_align_center">0.472</td>
<td id="A1.T3.1.16.14.4" class="ltx_td ltx_align_center"><span id="A1.T3.1.16.14.4.1" class="ltx_text ltx_font_bold">0.493</span></td>
<td id="A1.T3.1.16.14.5" class="ltx_td ltx_align_center">0.479</td>
<td id="A1.T3.1.16.14.6" class="ltx_td ltx_align_center">0.472</td>
</tr>
<tr id="A1.T3.1.17.15" class="ltx_tr">
<th id="A1.T3.1.17.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.17.15.2" class="ltx_td ltx_align_center"><span id="A1.T3.1.17.15.2.1" class="ltx_text ltx_font_bold">0.639</span></td>
<td id="A1.T3.1.17.15.3" class="ltx_td ltx_align_center">0.618</td>
<td id="A1.T3.1.17.15.4" class="ltx_td ltx_align_center"><span id="A1.T3.1.17.15.4.1" class="ltx_text ltx_font_bold">0.639</span></td>
<td id="A1.T3.1.17.15.5" class="ltx_td ltx_align_center">0.625</td>
<td id="A1.T3.1.17.15.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.17.15.6.1" class="ltx_text ltx_font_bold">0.639</span></td>
</tr>
<tr id="A1.T3.1.18.16" class="ltx_tr">
<th id="A1.T3.1.18.16.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="A1.T3.1.18.16.1.1" class="ltx_text">Biology (5-shot)</span></th>
<th id="A1.T3.1.18.16.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Mistral 7B</th>
<td id="A1.T3.1.18.16.3" class="ltx_td ltx_align_center">0.722</td>
<td id="A1.T3.1.18.16.4" class="ltx_td ltx_align_center"><span id="A1.T3.1.18.16.4.1" class="ltx_text ltx_font_bold">0.778</span></td>
<td id="A1.T3.1.18.16.5" class="ltx_td ltx_align_center"><span id="A1.T3.1.18.16.5.1" class="ltx_text ltx_font_bold">0.778</span></td>
<td id="A1.T3.1.18.16.6" class="ltx_td ltx_align_center">0.771</td>
<td id="A1.T3.1.18.16.7" class="ltx_td ltx_align_center">0.743</td>
</tr>
<tr id="A1.T3.1.19.17" class="ltx_tr">
<th id="A1.T3.1.19.17.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.19.17.2" class="ltx_td ltx_align_center">0.500</td>
<td id="A1.T3.1.19.17.3" class="ltx_td ltx_align_center"><span id="A1.T3.1.19.17.3.1" class="ltx_text ltx_font_bold">0.521</span></td>
<td id="A1.T3.1.19.17.4" class="ltx_td ltx_align_center">0.507</td>
<td id="A1.T3.1.19.17.5" class="ltx_td ltx_align_center">0.465</td>
<td id="A1.T3.1.19.17.6" class="ltx_td ltx_align_center">0.472</td>
</tr>
<tr id="A1.T3.1.20.18" class="ltx_tr">
<th id="A1.T3.1.20.18.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.20.18.2" class="ltx_td ltx_align_center">0.625</td>
<td id="A1.T3.1.20.18.3" class="ltx_td ltx_align_center">0.639</td>
<td id="A1.T3.1.20.18.4" class="ltx_td ltx_align_center">0.625</td>
<td id="A1.T3.1.20.18.5" class="ltx_td ltx_align_center"><span id="A1.T3.1.20.18.5.1" class="ltx_text ltx_font_bold">0.660</span></td>
<td id="A1.T3.1.20.18.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.20.18.6.1" class="ltx_text ltx_font_bold">0.660</span></td>
</tr>
<tr id="A1.T3.1.21.19" class="ltx_tr">
<th id="A1.T3.1.21.19.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="A1.T3.1.21.19.1.1" class="ltx_text">Chemistry (0-shot)</span></th>
<th id="A1.T3.1.21.19.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Mistral 7B</th>
<td id="A1.T3.1.21.19.3" class="ltx_td ltx_align_center ltx_border_t">0.450</td>
<td id="A1.T3.1.21.19.4" class="ltx_td ltx_align_center ltx_border_t">0.470</td>
<td id="A1.T3.1.21.19.5" class="ltx_td ltx_align_center ltx_border_t">0.470</td>
<td id="A1.T3.1.21.19.6" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.1.21.19.6.1" class="ltx_text ltx_font_bold">0.500</span></td>
<td id="A1.T3.1.21.19.7" class="ltx_td ltx_align_center ltx_border_t">0.470</td>
</tr>
<tr id="A1.T3.1.22.20" class="ltx_tr">
<th id="A1.T3.1.22.20.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.22.20.2" class="ltx_td ltx_align_center">0.320</td>
<td id="A1.T3.1.22.20.3" class="ltx_td ltx_align_center">0.320</td>
<td id="A1.T3.1.22.20.4" class="ltx_td ltx_align_center">0.300</td>
<td id="A1.T3.1.22.20.5" class="ltx_td ltx_align_center"><span id="A1.T3.1.22.20.5.1" class="ltx_text ltx_font_bold">0.380</span></td>
<td id="A1.T3.1.22.20.6" class="ltx_td ltx_align_center">0.360</td>
</tr>
<tr id="A1.T3.1.23.21" class="ltx_tr">
<th id="A1.T3.1.23.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.23.21.2" class="ltx_td ltx_align_center">0.370</td>
<td id="A1.T3.1.23.21.3" class="ltx_td ltx_align_center">0.420</td>
<td id="A1.T3.1.23.21.4" class="ltx_td ltx_align_center">0.400</td>
<td id="A1.T3.1.23.21.5" class="ltx_td ltx_align_center">0.410</td>
<td id="A1.T3.1.23.21.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.23.21.6.1" class="ltx_text ltx_font_bold">0.440</span></td>
</tr>
<tr id="A1.T3.1.24.22" class="ltx_tr">
<th id="A1.T3.1.24.22.1" class="ltx_td ltx_align_left ltx_th ltx_th_row" rowspan="3"><span id="A1.T3.1.24.22.1.1" class="ltx_text">Chemistry (5-shot)</span></th>
<th id="A1.T3.1.24.22.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Mistral 7B</th>
<td id="A1.T3.1.24.22.3" class="ltx_td ltx_align_center"><span id="A1.T3.1.24.22.3.1" class="ltx_text ltx_font_bold">0.540</span></td>
<td id="A1.T3.1.24.22.4" class="ltx_td ltx_align_center">0.490</td>
<td id="A1.T3.1.24.22.5" class="ltx_td ltx_align_center">0.500</td>
<td id="A1.T3.1.24.22.6" class="ltx_td ltx_align_center">0.510</td>
<td id="A1.T3.1.24.22.7" class="ltx_td ltx_align_center">0.470</td>
</tr>
<tr id="A1.T3.1.25.23" class="ltx_tr">
<th id="A1.T3.1.25.23.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.25.23.2" class="ltx_td ltx_align_center">0.280</td>
<td id="A1.T3.1.25.23.3" class="ltx_td ltx_align_center">0.320</td>
<td id="A1.T3.1.25.23.4" class="ltx_td ltx_align_center">0.340</td>
<td id="A1.T3.1.25.23.5" class="ltx_td ltx_align_center">0.340</td>
<td id="A1.T3.1.25.23.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.25.23.6.1" class="ltx_text ltx_font_bold">0.380</span></td>
</tr>
<tr id="A1.T3.1.26.24" class="ltx_tr">
<th id="A1.T3.1.26.24.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.26.24.2" class="ltx_td ltx_align_center">0.390</td>
<td id="A1.T3.1.26.24.3" class="ltx_td ltx_align_center">0.430</td>
<td id="A1.T3.1.26.24.4" class="ltx_td ltx_align_center">0.400</td>
<td id="A1.T3.1.26.24.5" class="ltx_td ltx_align_center">0.430</td>
<td id="A1.T3.1.26.24.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.26.24.6.1" class="ltx_text ltx_font_bold">0.470</span></td>
</tr>
<tr id="A1.T3.1.27.25" class="ltx_tr">
<th id="A1.T3.1.27.25.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" rowspan="3"><span id="A1.T3.1.27.25.1.1" class="ltx_text">Prehistory (0-shot)</span></th>
<th id="A1.T3.1.27.25.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">Mistral 7B</th>
<td id="A1.T3.1.27.25.3" class="ltx_td ltx_align_center ltx_border_t">0.728</td>
<td id="A1.T3.1.27.25.4" class="ltx_td ltx_align_center ltx_border_t">0.725</td>
<td id="A1.T3.1.27.25.5" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.1.27.25.5.1" class="ltx_text ltx_font_bold">0.750</span></td>
<td id="A1.T3.1.27.25.6" class="ltx_td ltx_align_center ltx_border_t">0.735</td>
<td id="A1.T3.1.27.25.7" class="ltx_td ltx_align_center ltx_border_t">0.728</td>
</tr>
<tr id="A1.T3.1.28.26" class="ltx_tr">
<th id="A1.T3.1.28.26.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.28.26.2" class="ltx_td ltx_align_center"><span id="A1.T3.1.28.26.2.1" class="ltx_text ltx_font_bold">0.481</span></td>
<td id="A1.T3.1.28.26.3" class="ltx_td ltx_align_center">0.460</td>
<td id="A1.T3.1.28.26.4" class="ltx_td ltx_align_center">0.457</td>
<td id="A1.T3.1.28.26.5" class="ltx_td ltx_align_center">0.457</td>
<td id="A1.T3.1.28.26.6" class="ltx_td ltx_align_center">0.429</td>
</tr>
<tr id="A1.T3.1.29.27" class="ltx_tr">
<th id="A1.T3.1.29.27.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.29.27.2" class="ltx_td ltx_align_center">0.648</td>
<td id="A1.T3.1.29.27.3" class="ltx_td ltx_align_center">0.645</td>
<td id="A1.T3.1.29.27.4" class="ltx_td ltx_align_center">0.660</td>
<td id="A1.T3.1.29.27.5" class="ltx_td ltx_align_center">0.670</td>
<td id="A1.T3.1.29.27.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.29.27.6.1" class="ltx_text ltx_font_bold">0.679</span></td>
</tr>
<tr id="A1.T3.1.30.28" class="ltx_tr">
<th id="A1.T3.1.30.28.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" rowspan="3"><span id="A1.T3.1.30.28.1.1" class="ltx_text">Prehistory (5-shot)</span></th>
<th id="A1.T3.1.30.28.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Mistral 7B</th>
<td id="A1.T3.1.30.28.3" class="ltx_td ltx_align_center">0.710</td>
<td id="A1.T3.1.30.28.4" class="ltx_td ltx_align_center">0.750</td>
<td id="A1.T3.1.30.28.5" class="ltx_td ltx_align_center">0.759</td>
<td id="A1.T3.1.30.28.6" class="ltx_td ltx_align_center">0.756</td>
<td id="A1.T3.1.30.28.7" class="ltx_td ltx_align_center"><span id="A1.T3.1.30.28.7.1" class="ltx_text ltx_font_bold">0.762</span></td>
</tr>
<tr id="A1.T3.1.31.29" class="ltx_tr">
<th id="A1.T3.1.31.29.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Llama2 7B</th>
<td id="A1.T3.1.31.29.2" class="ltx_td ltx_align_center">0.512</td>
<td id="A1.T3.1.31.29.3" class="ltx_td ltx_align_center">0.485</td>
<td id="A1.T3.1.31.29.4" class="ltx_td ltx_align_center">0.525</td>
<td id="A1.T3.1.31.29.5" class="ltx_td ltx_align_center">0.519</td>
<td id="A1.T3.1.31.29.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.31.29.6.1" class="ltx_text ltx_font_bold">0.531</span></td>
</tr>
<tr id="A1.T3.1.32.30" class="ltx_tr">
<th id="A1.T3.1.32.30.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Orca2 7B</th>
<td id="A1.T3.1.32.30.2" class="ltx_td ltx_align_center ltx_border_bb">0.660</td>
<td id="A1.T3.1.32.30.3" class="ltx_td ltx_align_center ltx_border_bb">0.688</td>
<td id="A1.T3.1.32.30.4" class="ltx_td ltx_align_center ltx_border_bb">0.685</td>
<td id="A1.T3.1.32.30.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T3.1.32.30.5.1" class="ltx_text ltx_font_bold">0.698</span></td>
<td id="A1.T3.1.32.30.6" class="ltx_td ltx_align_center ltx_border_bb">0.688</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T3.3.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="A1.T3.4.2" class="ltx_text" style="font-size:90%;">RAG ablation study.</span></figcaption>
</figure>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Paraphrase Examples</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">Below is the prompt we used to generate paraphrases with GPT-4:</p>
</div>
<div id="A2.p2" class="ltx_para">
<blockquote id="A2.p2.1" class="ltx_quote">
<p id="A2.p2.1.1" class="ltx_p">Your task is to paraphrase a text paragraph. The paragraph is given below.</p>
<p id="A2.p2.1.2" class="ltx_p">Make sure to keep the same meaning but change the wording. Do not change any factual information.</p>
<p id="A2.p2.1.3" class="ltx_p">Try to keep roughly the same length of the original text.</p>
<p id="A2.p2.1.4" class="ltx_p">Give NUM _ PARAPHRASES different paraphrases for each text.</p>
<p id="A2.p2.1.5" class="ltx_p">These paraphrases should be as different from each other as possible.</p>
<p id="A2.p2.1.6" class="ltx_p">Return a JSON formatted string with one key, called â€™paraphrasesâ€™, and a list of paraphrases.</p>
<p id="A2.p2.1.7" class="ltx_p">Input paragraph:</p>
</blockquote>
</div>
<div id="A2.p3" class="ltx_para">
<p id="A2.p3.1" class="ltx_p">Below are some examples. First, an example taken from the following Wikipedia page: â€51st International Emmy Awardsâ€.</p>
</div>
<div id="A2.p4" class="ltx_para">
<blockquote id="A2.p4.1" class="ltx_quote">
<p id="A2.p4.1.1" class="ltx_p"><span id="A2.p4.1.1.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Paraphrase I</span></p>
<p id="A2.p4.1.2" class="ltx_p">The fifty-first edition of the International Emmy Awards Competition accepted submissions across all categories from December 7, 2022, until the closing date of February 16, 2023.</p>
<p id="A2.p4.1.3" class="ltx_p"><span id="A2.p4.1.3.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Paraphrase II</span></p>
<p id="A2.p4.1.4" class="ltx_p">The International Emmy Awards Competition, now in its 51st year, accepted submissions across all categories starting from December 7, 2022, until the deadline on February 16, 2023.</p>
<p id="A2.p4.1.5" class="ltx_p"><span id="A2.p4.1.5.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Paraphrase III</span></p>
<p id="A2.p4.1.6" class="ltx_p">The fifty-first edition of the International Emmy Awards Competition accepted submissions across all categories from December 7, 2022, until the closing date of February 16, 2023.</p>
</blockquote>
</div>
<div id="A2.p5" class="ltx_para">
<p id="A2.p5.1" class="ltx_p">The next example was taken from the following Wikipedia page: â€2023 Indianapolis mayoral electionâ€.</p>
</div>
<div id="A2.p6" class="ltx_para">
<blockquote id="A2.p6.1" class="ltx_quote">
<p id="A2.p6.1.1" class="ltx_p"><span id="A2.p6.1.1.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Paraphrase I</span>
The mayoral election in Indianapolis took place on November 7, 2023, with preliminary elections occurring on May 2. The sitting mayor, Democrat Joe Hogsett, successfully ran for a third term. Both Hogsett and his Republican opponent, Jefferson Shreve, moved on to the main election.</p>
<p id="A2.p6.1.2" class="ltx_p"><span id="A2.p6.1.2.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Paraphrase II</span>
On November 7, 2023, citizens of Indianapolis cast their votes to elect their Mayor, following primary elections on May 2. Joe Hogsett, the Democrat already in office, won his bid for a third term. Hogsett and the Republican candidate, Jefferson Shreve, were the two contenders in the final electoral round.</p>
<p id="A2.p6.1.3" class="ltx_p"><span id="A2.p6.1.3.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Paraphrase III</span></p>
<p id="A2.p6.1.4" class="ltx_p">The mayoral election in Indianapolis took place on the 7th of November, 2023, following primary elections that occurred on the 2nd of May. Joe Hogsett, the incumbent Democrat, successfully ran for a third term. Both Hogsett and his Republican challenger, Jefferson Shreve, made it through to the final round of the election.</p>
</blockquote>
</div>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Current Events Existing Knowledge Examples</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">To give a better understanding of how a model might be able to answer questions about new information, with better than random success, we present three possible scenarios as examples. These scenarios show how models with stronger reasoning skills can infer the correct answer even for unseen information.

<br class="ltx_break">
<br class="ltx_break">The first scenario involves questions about previously unseen information, where basic reasoning abilities allow a model to make an educated guess.</p>
</div>
<div id="A3.p2" class="ltx_para">
<blockquote id="A3.p2.1" class="ltx_quote">
<p id="A3.p2.1.1" class="ltx_p"><span id="A3.p2.1.1.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Question:</span> What was a key issue that led to the 2023 United Auto Workers strike?

<br class="ltx_break">
<br class="ltx_break"><span id="A3.p2.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Answers:</span></p>
<ol id="A3.I1" class="ltx_enumerate">
<li id="A3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A3.I1.i1.p1" class="ltx_para">
<p id="A3.I1.i1.p1.1" class="ltx_p">Dissatisfaction with the quality of cafeteria food.</p>
</div>
</li>
<li id="A3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A3.I1.i2.p1" class="ltx_para">
<p id="A3.I1.i2.p1.1" class="ltx_p">Disagreements over employee dress codes.</p>
</div>
</li>
<li id="A3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A3.I1.i3.p1" class="ltx_para">
<p id="A3.I1.i3.p1.1" class="ltx_p">Discontent with stagnant wages and tiered employment systems.</p>
</div>
</li>
<li id="A3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A3.I1.i4.p1" class="ltx_para">
<p id="A3.I1.i4.p1.1" class="ltx_p">Debates over the color scheme of the factories.</p>
</div>
</li>
</ol>
</blockquote>
</div>
<div id="A3.p3" class="ltx_para">
<p id="A3.p3.1" class="ltx_p">In this case it is easy to guess that the third option is the most likely, even without knowledge of this specific strike.

<br class="ltx_break">
<br class="ltx_break">A second scenario involves questions where prior knowledge about a topic may aid a model in answering.</p>
</div>
<div id="A3.p4" class="ltx_para">
<blockquote id="A3.p4.1" class="ltx_quote">
<p id="A3.p4.1.1" class="ltx_p"><span id="A3.p4.1.1.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Question:</span> What environmental concern was raised by some scientists as a result of the 2023 Hawaii wildfires?

<br class="ltx_break">
<br class="ltx_break"><span id="A3.p4.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Answers:</span></p>
<ol id="A3.I2" class="ltx_enumerate">
<li id="A3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A3.I2.i1.p1" class="ltx_para">
<p id="A3.I2.i1.p1.1" class="ltx_p">Rising temperatures.</p>
</div>
</li>
<li id="A3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A3.I2.i2.p1" class="ltx_para">
<p id="A3.I2.i2.p1.1" class="ltx_p">Melting ice caps.</p>
</div>
</li>
<li id="A3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A3.I2.i3.p1" class="ltx_para">
<p id="A3.I2.i3.p1.1" class="ltx_p">Charred soils running off into the shoreline.</p>
</div>
</li>
<li id="A3.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A3.I2.i4.p1" class="ltx_para">
<p id="A3.I2.i4.p1.1" class="ltx_p">Increased air pollution.</p>
</div>
</li>
</ol>
</blockquote>
<p id="A3.p4.2" class="ltx_p">In this case, knowing the geography of Hawaii, as well as immediate effects of wildfires, enables a model to give the first two options a lower likelihood. This process of elimination increases the probability of choosing one of the remaining options (the third option is the correct answer).

<br class="ltx_break">
<br class="ltx_break">A third scenario arises due to the automatic question generation process, some questions strongly rely on pre-existing knowledge.</p>
</div>
<div id="A3.p5" class="ltx_para">
<blockquote id="A3.p5.1" class="ltx_quote">
<p id="A3.p5.1.1" class="ltx_p"><span id="A3.p5.1.1.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Question:</span> What event in 2021 was compared to the September 2023 New York floods?

<br class="ltx_break">
<br class="ltx_break"><span id="A3.p5.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Answers:</span></p>
<ol id="A3.I3" class="ltx_enumerate">
<li id="A3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A3.I3.i1.p1" class="ltx_para">
<p id="A3.I3.i1.p1.1" class="ltx_p">Hurricane Katrina.</p>
</div>
</li>
<li id="A3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A3.I3.i2.p1" class="ltx_para">
<p id="A3.I3.i2.p1.1" class="ltx_p">Hurricane Ida.</p>
</div>
</li>
<li id="A3.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A3.I3.i3.p1" class="ltx_para">
<p id="A3.I3.i3.p1.1" class="ltx_p">Hurricane Sandy.</p>
</div>
</li>
<li id="A3.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A3.I3.i4.p1" class="ltx_para">
<p id="A3.I3.i4.p1.1" class="ltx_p">Hurricane Harvey.</p>
</div>
</li>
</ol>
</blockquote>
</div>
<div id="A3.p6" class="ltx_para">
<p id="A3.p6.1" class="ltx_p">Since only one of these events occurred in 2021 (Hurricane Ida), and all the models tested have been exposed to events from 2021 during pre-training, this question can potentially be answered without using additional current information.

<br class="ltx_break">
<br class="ltx_break">Finally, to demonstrate why it is reasonable to assume that models cannot generally answer questions about new information, with better than random success, look at the following example:</p>
</div>
<div id="A3.p7" class="ltx_para">
<blockquote id="A3.p7.1" class="ltx_quote">
<p id="A3.p7.1.1" class="ltx_p"><span id="A3.p7.1.1.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Question:</span> How did Matthew Belk, a National Weather Service meteorologist, describe the September 2023 northeastern U.S. floods?

<br class="ltx_break">
<br class="ltx_break"><span id="A3.p7.1.1.2" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">Answers:</span></p>
<ol id="A3.I4" class="ltx_enumerate">
<li id="A3.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A3.I4.i1.p1" class="ltx_para">
<p id="A3.I4.i1.p1.1" class="ltx_p">50-year event.</p>
</div>
</li>
<li id="A3.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A3.I4.i2.p1" class="ltx_para">
<p id="A3.I4.i2.p1.1" class="ltx_p">100-year event.</p>
</div>
</li>
<li id="A3.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A3.I4.i3.p1" class="ltx_para">
<p id="A3.I4.i3.p1.1" class="ltx_p">200-year event.</p>
</div>
</li>
<li id="A3.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A3.I4.i4.p1" class="ltx_para">
<p id="A3.I4.i4.p1.1" class="ltx_p">500-year event.</p>
</div>
</li>
</ol>
</blockquote>
</div>
<div id="A3.p8" class="ltx_para">
<p id="A3.p8.1" class="ltx_p">Even with some knowledge about floods and their statistical properties, it would be very difficult to guess that this specific meteorologist would call the flood a â€˜200-year eventâ€™. This is especially true if the model was not exposed to information about the details of the flood.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2312.05933" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2312.05934" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2312.05934">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2312.05934" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2312.05935" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 14:46:31 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>