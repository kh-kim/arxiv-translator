<html lang="en" data-theme="light"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs</title>
<!--Generated on Tue Jan 30 11:57:53 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css">
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2312.05934v3/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2312.05934v3">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <span class="color-scheme-icon" aria-label="Light mode"></span>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="#myForm" onclick="event.preventDefault(); var modal = document.getElementById('myForm'); modal.style.display = 'block'; bugReportState.setInitiateWay('Header');">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2312.05934v3">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2312.05934v3" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
          <span class="color-scheme-icon"></span>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC active" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S1" title="1 Introduction ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S2" title="2 Background ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S3" title="3 Injecting Knowledge to Language Models ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Injecting Knowledge to Language Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S3.SS1" title="3.1 Problem formulation ‣ 3 Injecting Knowledge to Language Models ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Problem formulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S3.SS2" title="3.2 Fine-Tuning ‣ 3 Injecting Knowledge to Language Models ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Fine-Tuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S3.SS3" title="3.3 Retrieval Augmented Generation ‣ 3 Injecting Knowledge to Language Models ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Retrieval Augmented Generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S4" title="4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Knowledge Base Creation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S4.SS1" title="4.1 Task Selection and Rationale ‣ 4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Task Selection and Rationale</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S4.SS2" title="4.2 Data Collection and Preprocessing ‣ 4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Data Collection and Preprocessing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S4.SS3" title="4.3 Current Events Task Creation ‣ 4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Current Events Task Creation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S4.SS4" title="4.4 Paraphrases Generation ‣ 4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Paraphrases Generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S5" title="5 Experiments and Results ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Experiments and Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S6" title="6 The Importance of Repetition ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>The Importance of Repetition</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S7" title="7 Conclusion and Future Work ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion and Future Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S8" title="8 Limitations ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#A1" title="Appendix A RAG Ablation Study ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>RAG Ablation Study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#A2" title="Appendix B Paraphrase Examples ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Paraphrase Examples</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#A3" title="Appendix C Current Events Existing Knowledge Examples ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Current Events Existing Knowledge Examples</span></a></li>
</ol></nav>

<div class="ltx_page_content">
<div aria-label="Conversion errors have been found" class="package-alerts ltx_document" role="status">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewBox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: arydshln</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><div class="section" id="target-section"><div id="license-tr">License: CC BY 4.0</div><div id="watermark-tr">arXiv:2312.05934v3 [cs.AI] 30 Jan 2024</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Fine-Tuning or Retrieval? 
<br class="ltx_break">Comparing Knowledge Injection in LLMs</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Oded Ovadia
</span><span class="ltx_author_notes">Corresponding author.Equal contribution.
<span class="ltx_contact ltx_role_affiliation">{odedovadia,t-mbrief,mmishaeli,oren.elisha}@microsoft.com 
<br class="ltx_break">Microsoft, Israel
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Menachem Brief<span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">0</span></span></span></span>
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">{odedovadia,t-mbrief,mmishaeli,oren.elisha}@microsoft.com 
<br class="ltx_break">Microsoft, Israel
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Moshik Mishaeli
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">{odedovadia,t-mbrief,mmishaeli,oren.elisha}@microsoft.com 
<br class="ltx_break">Microsoft, Israel
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Oren Elisha
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">{odedovadia,t-mbrief,mmishaeli,oren.elisha}@microsoft.com 
<br class="ltx_break">Microsoft, Israel
</span></span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id1.id1">Large language models (LLMs) encapsulate a vast amount of factual information within their pre-trained weights, as evidenced by their ability to answer diverse questions across different domains. However, this knowledge is inherently limited, relying heavily on the characteristics of the training data. Consequently, using external datasets to incorporate new information or refine the capabilities of LLMs on previously seen information poses a significant challenge. In this study, we compare two common approaches: unsupervised fine-tuning and retrieval-augmented generation (RAG). We evaluate both approaches on a variety of knowledge-intensive tasks across different topics. Our findings reveal that while unsupervised fine-tuning offers some improvement, RAG consistently outperforms it, both for existing knowledge encountered during training and entirely new knowledge. Moreover, we find that LLMs struggle to learn new factual information through unsupervised fine-tuning, and that exposing them to numerous variations of the same fact during training could alleviate this problem.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1">Keywords:</span> LLMs, NLP, Fine-Tuning vs. RAG, Knowledge and Factuality.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Large language models (LLMs) are able to capture vast amounts of factual information <cite class="ltx_cite ltx_citemacro_citep">(Petroni et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib32" title="">2019</a>; Cohen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib8" title="">2023</a>; Hu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib13" title="">2023</a>)</cite>. LLMs exhibit a remarkable level of knowledge in various domains due to their massive pre-training datasets. However, there are two significant limitations to this knowledge. First, it is static and does not update with time. Second, it is non-specific and thus may lack nuanced expertise in particular domains. While these are two different problems, they are deeply related since their solution is the same: enhancing the model’s knowledge.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Recently, the idea of adapting LLMs to particular domains and updating their knowledge has become increasingly common <cite class="ltx_cite ltx_citemacro_citep">(Yu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib54" title="">2022</a>)</cite>. Various models have been suggested to improve factual knowledge and capabilities in diverse fields such as healthcare <cite class="ltx_cite ltx_citemacro_citep">(Singhal et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib39" title="">2023a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib40" title="">b</a>; Wu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib50" title="">2023a</a>)</cite>, finance <cite class="ltx_cite ltx_citemacro_citep">(Wu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib51" title="">2023b</a>; Yang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib53" title="">2023</a>)</cite>, and law <cite class="ltx_cite ltx_citemacro_citep">(Huang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib14" title="">2023</a>; Nguyen, <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib28" title="">2023</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this work, we focus on the evaluation of a model’s knowledge and its ability to memorize, understand, and retrieve factual data. We aim to understand the concept of <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">knowledge injection</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib48" title="">2020</a>; Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib4" title="">2022</a>; Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib22" title="">2020</a>; Lauscher et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib20" title="">2020</a>)</cite>. Given some knowledge base in the form of a text corpus, what is the best way to teach a pre-trained model this knowledge?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">One way to add knowledge to a pre-trained model is through fine-tuning. With fine-tuning, we continue the model’s training process and adapt it using task-specific data. By exposing the model to a specific knowledge base, we expect the model weights to adapt accordingly. This process is meant to optimize the model for targeted applications, enhancing its performance and contextual relevance in specialized domains.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Another method to enhance a model’s knowledge base is through the use of in-context learning (ICL) <cite class="ltx_cite ltx_citemacro_citep">(Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib5" title="">2021</a>; Radford et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib33" title="">2019</a>; Min et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib24" title="">2021</a>; Lampinen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib19" title="">2022</a>)</cite>. The main idea behind ICL is to improve the performance of pre-trained LLMs on new tasks by modifying the input query to the model without directly changing the weights of the model. One form of ICL is retrieval augmented generation (RAG) <cite class="ltx_cite ltx_citemacro_citep">(Lewis et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib21" title="">2020</a>; Neelakantan et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib27" title="">2022</a>)</cite>. RAG uses information retrieval techniques to enable LLMs to obtain relevant information from a knowledge source and incorporate it into generated text.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">This study aims to evaluate the knowledge injection capabilities of LLMs through a comparison of fine-tuning and RAG. To illustrate the rationale, let us use an analogy. Consider three college students taking a test on a specific topic. All had access to class materials but didn’t know the topic beforehand. The first student had the textbook only during the test, the second had pre-test access and studied, and the third lost access upon the test announcement. Who would probably perform better?</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="328" id="S2.F1.g1" src="extracted/5377658/media/Wikipedia.jpg" width="586">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S2.F1.3.2" style="font-size:90%;">A visualization of the knowledge injection framework.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">To assess <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">knowledge injection</span>, we must first understand what <span class="ltx_text ltx_font_italic" id="S2.p1.1.2">knowledge</span> means for LLMs.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.p2.1.1">Knowledge and Language Models</span>  Defining knowledge is a complex philosophical task far beyond the scope of this research. However, we can examine what factual knowledge means in the context of language models. If a model knows a fact, it can accurately and consistently answer questions about it. Furthermore, it can reliably distinguish between true and false statements related to this fact. We can then extend this definition to a whole knowledge base, not just a single fact.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.5">Mathematically, let <math alttext="\mathcal{Q}=\{q_{n}\}_{n=1}^{N}" class="ltx_Math" display="inline" id="S2.p3.1.m1.1"><semantics id="S2.p3.1.m1.1a"><mrow id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p3.1.m1.1.1.3" xref="S2.p3.1.m1.1.1.3.cmml">𝒬</mi><mo id="S2.p3.1.m1.1.1.2" xref="S2.p3.1.m1.1.1.2.cmml">=</mo><msubsup id="S2.p3.1.m1.1.1.1" xref="S2.p3.1.m1.1.1.1.cmml"><mrow id="S2.p3.1.m1.1.1.1.1.1.1" xref="S2.p3.1.m1.1.1.1.1.1.2.cmml"><mo id="S2.p3.1.m1.1.1.1.1.1.1.2" stretchy="false" xref="S2.p3.1.m1.1.1.1.1.1.2.cmml">{</mo><msub id="S2.p3.1.m1.1.1.1.1.1.1.1" xref="S2.p3.1.m1.1.1.1.1.1.1.1.cmml"><mi id="S2.p3.1.m1.1.1.1.1.1.1.1.2" xref="S2.p3.1.m1.1.1.1.1.1.1.1.2.cmml">q</mi><mi id="S2.p3.1.m1.1.1.1.1.1.1.1.3" xref="S2.p3.1.m1.1.1.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S2.p3.1.m1.1.1.1.1.1.1.3" stretchy="false" xref="S2.p3.1.m1.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p3.1.m1.1.1.1.1.3" xref="S2.p3.1.m1.1.1.1.1.3.cmml"><mi id="S2.p3.1.m1.1.1.1.1.3.2" xref="S2.p3.1.m1.1.1.1.1.3.2.cmml">n</mi><mo id="S2.p3.1.m1.1.1.1.1.3.1" xref="S2.p3.1.m1.1.1.1.1.3.1.cmml">=</mo><mn id="S2.p3.1.m1.1.1.1.1.3.3" xref="S2.p3.1.m1.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S2.p3.1.m1.1.1.1.3" xref="S2.p3.1.m1.1.1.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><apply id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1"><eq id="S2.p3.1.m1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.2"></eq><ci id="S2.p3.1.m1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.3">𝒬</ci><apply id="S2.p3.1.m1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.1">superscript</csymbol><apply id="S2.p3.1.m1.1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.1">subscript</csymbol><set id="S2.p3.1.m1.1.1.1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1"><apply id="S2.p3.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.1.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p3.1.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1.2">𝑞</ci><ci id="S2.p3.1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.1.1.1.1.1.3">𝑛</ci></apply></set><apply id="S2.p3.1.m1.1.1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.1.1.3"><eq id="S2.p3.1.m1.1.1.1.1.3.1.cmml" xref="S2.p3.1.m1.1.1.1.1.3.1"></eq><ci id="S2.p3.1.m1.1.1.1.1.3.2.cmml" xref="S2.p3.1.m1.1.1.1.1.3.2">𝑛</ci><cn id="S2.p3.1.m1.1.1.1.1.3.3.cmml" type="integer" xref="S2.p3.1.m1.1.1.1.1.3.3">1</cn></apply></apply><ci id="S2.p3.1.m1.1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.1.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">\mathcal{Q}=\{q_{n}\}_{n=1}^{N}</annotation><annotation encoding="application/x-llamapun" id="S2.p3.1.m1.1d">caligraphic_Q = { italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT</annotation></semantics></math> be a set of <math alttext="N" class="ltx_Math" display="inline" id="S2.p3.2.m2.1"><semantics id="S2.p3.2.m2.1a"><mi id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b"><ci id="S2.p3.2.m2.1.1.cmml" xref="S2.p3.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">N</annotation><annotation encoding="application/x-llamapun" id="S2.p3.2.m2.1d">italic_N</annotation></semantics></math> multiple choice factual questions, where each question has <math alttext="L" class="ltx_Math" display="inline" id="S2.p3.3.m3.1"><semantics id="S2.p3.3.m3.1a"><mi id="S2.p3.3.m3.1.1" xref="S2.p3.3.m3.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="S2.p3.3.m3.1b"><ci id="S2.p3.3.m3.1.1.cmml" xref="S2.p3.3.m3.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.3.m3.1c">L</annotation><annotation encoding="application/x-llamapun" id="S2.p3.3.m3.1d">italic_L</annotation></semantics></math> possible answers and exactly one correct answer. Let <math alttext="\mathcal{A}=\{(a_{n}^{1},\ldots,a_{n}^{L})\}_{n=1}^{N}" class="ltx_Math" display="inline" id="S2.p3.4.m4.2"><semantics id="S2.p3.4.m4.2a"><mrow id="S2.p3.4.m4.2.2" xref="S2.p3.4.m4.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p3.4.m4.2.2.3" xref="S2.p3.4.m4.2.2.3.cmml">𝒜</mi><mo id="S2.p3.4.m4.2.2.2" xref="S2.p3.4.m4.2.2.2.cmml">=</mo><msubsup id="S2.p3.4.m4.2.2.1" xref="S2.p3.4.m4.2.2.1.cmml"><mrow id="S2.p3.4.m4.2.2.1.1.1.1" xref="S2.p3.4.m4.2.2.1.1.1.2.cmml"><mo id="S2.p3.4.m4.2.2.1.1.1.1.2" stretchy="false" xref="S2.p3.4.m4.2.2.1.1.1.2.cmml">{</mo><mrow id="S2.p3.4.m4.2.2.1.1.1.1.1.2" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml"><mo id="S2.p3.4.m4.2.2.1.1.1.1.1.2.3" stretchy="false" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml">(</mo><msubsup id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.cmml"><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.2" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.2.cmml">a</mi><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.3" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.3.cmml">n</mi><mn id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.3" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.3.cmml">1</mn></msubsup><mo id="S2.p3.4.m4.2.2.1.1.1.1.1.2.4" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml">,</mo><mi id="S2.p3.4.m4.1.1" mathvariant="normal" xref="S2.p3.4.m4.1.1.cmml">…</mi><mo id="S2.p3.4.m4.2.2.1.1.1.1.1.2.5" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml">,</mo><msubsup id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.cmml"><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.2" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.2.cmml">a</mi><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.3" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.3.cmml">n</mi><mi id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.3" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.3.cmml">L</mi></msubsup><mo id="S2.p3.4.m4.2.2.1.1.1.1.1.2.6" stretchy="false" xref="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml">)</mo></mrow><mo id="S2.p3.4.m4.2.2.1.1.1.1.3" stretchy="false" xref="S2.p3.4.m4.2.2.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p3.4.m4.2.2.1.1.3" xref="S2.p3.4.m4.2.2.1.1.3.cmml"><mi id="S2.p3.4.m4.2.2.1.1.3.2" xref="S2.p3.4.m4.2.2.1.1.3.2.cmml">n</mi><mo id="S2.p3.4.m4.2.2.1.1.3.1" xref="S2.p3.4.m4.2.2.1.1.3.1.cmml">=</mo><mn id="S2.p3.4.m4.2.2.1.1.3.3" xref="S2.p3.4.m4.2.2.1.1.3.3.cmml">1</mn></mrow><mi id="S2.p3.4.m4.2.2.1.3" xref="S2.p3.4.m4.2.2.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.4.m4.2b"><apply id="S2.p3.4.m4.2.2.cmml" xref="S2.p3.4.m4.2.2"><eq id="S2.p3.4.m4.2.2.2.cmml" xref="S2.p3.4.m4.2.2.2"></eq><ci id="S2.p3.4.m4.2.2.3.cmml" xref="S2.p3.4.m4.2.2.3">𝒜</ci><apply id="S2.p3.4.m4.2.2.1.cmml" xref="S2.p3.4.m4.2.2.1"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.2.cmml" xref="S2.p3.4.m4.2.2.1">superscript</csymbol><apply id="S2.p3.4.m4.2.2.1.1.cmml" xref="S2.p3.4.m4.2.2.1"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.2.cmml" xref="S2.p3.4.m4.2.2.1">subscript</csymbol><set id="S2.p3.4.m4.2.2.1.1.1.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1"><vector id="S2.p3.4.m4.2.2.1.1.1.1.1.3.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2"><apply id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.2">𝑎</ci><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.2.3">𝑛</ci></apply><cn id="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.p3.4.m4.2.2.1.1.1.1.1.1.1.3">1</cn></apply><ci id="S2.p3.4.m4.1.1.cmml" xref="S2.p3.4.m4.1.1">…</ci><apply id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2">superscript</csymbol><apply id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.1.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2">subscript</csymbol><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.2.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.2">𝑎</ci><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.3.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.2.3">𝑛</ci></apply><ci id="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.3.cmml" xref="S2.p3.4.m4.2.2.1.1.1.1.1.2.2.3">𝐿</ci></apply></vector></set><apply id="S2.p3.4.m4.2.2.1.1.3.cmml" xref="S2.p3.4.m4.2.2.1.1.3"><eq id="S2.p3.4.m4.2.2.1.1.3.1.cmml" xref="S2.p3.4.m4.2.2.1.1.3.1"></eq><ci id="S2.p3.4.m4.2.2.1.1.3.2.cmml" xref="S2.p3.4.m4.2.2.1.1.3.2">𝑛</ci><cn id="S2.p3.4.m4.2.2.1.1.3.3.cmml" type="integer" xref="S2.p3.4.m4.2.2.1.1.3.3">1</cn></apply></apply><ci id="S2.p3.4.m4.2.2.1.3.cmml" xref="S2.p3.4.m4.2.2.1.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.4.m4.2c">\mathcal{A}=\{(a_{n}^{1},\ldots,a_{n}^{L})\}_{n=1}^{N}</annotation><annotation encoding="application/x-llamapun" id="S2.p3.4.m4.2d">caligraphic_A = { ( italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , … , italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT ) } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT</annotation></semantics></math> be the corresponding set of possible answers, and <math alttext="\mathcal{C}=\{c_{n}\}_{n=1}^{N}" class="ltx_Math" display="inline" id="S2.p3.5.m5.1"><semantics id="S2.p3.5.m5.1a"><mrow id="S2.p3.5.m5.1.1" xref="S2.p3.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p3.5.m5.1.1.3" xref="S2.p3.5.m5.1.1.3.cmml">𝒞</mi><mo id="S2.p3.5.m5.1.1.2" xref="S2.p3.5.m5.1.1.2.cmml">=</mo><msubsup id="S2.p3.5.m5.1.1.1" xref="S2.p3.5.m5.1.1.1.cmml"><mrow id="S2.p3.5.m5.1.1.1.1.1.1" xref="S2.p3.5.m5.1.1.1.1.1.2.cmml"><mo id="S2.p3.5.m5.1.1.1.1.1.1.2" stretchy="false" xref="S2.p3.5.m5.1.1.1.1.1.2.cmml">{</mo><msub id="S2.p3.5.m5.1.1.1.1.1.1.1" xref="S2.p3.5.m5.1.1.1.1.1.1.1.cmml"><mi id="S2.p3.5.m5.1.1.1.1.1.1.1.2" xref="S2.p3.5.m5.1.1.1.1.1.1.1.2.cmml">c</mi><mi id="S2.p3.5.m5.1.1.1.1.1.1.1.3" xref="S2.p3.5.m5.1.1.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S2.p3.5.m5.1.1.1.1.1.1.3" stretchy="false" xref="S2.p3.5.m5.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p3.5.m5.1.1.1.1.3" xref="S2.p3.5.m5.1.1.1.1.3.cmml"><mi id="S2.p3.5.m5.1.1.1.1.3.2" xref="S2.p3.5.m5.1.1.1.1.3.2.cmml">n</mi><mo id="S2.p3.5.m5.1.1.1.1.3.1" xref="S2.p3.5.m5.1.1.1.1.3.1.cmml">=</mo><mn id="S2.p3.5.m5.1.1.1.1.3.3" xref="S2.p3.5.m5.1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S2.p3.5.m5.1.1.1.3" xref="S2.p3.5.m5.1.1.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.5.m5.1b"><apply id="S2.p3.5.m5.1.1.cmml" xref="S2.p3.5.m5.1.1"><eq id="S2.p3.5.m5.1.1.2.cmml" xref="S2.p3.5.m5.1.1.2"></eq><ci id="S2.p3.5.m5.1.1.3.cmml" xref="S2.p3.5.m5.1.1.3">𝒞</ci><apply id="S2.p3.5.m5.1.1.1.cmml" xref="S2.p3.5.m5.1.1.1"><csymbol cd="ambiguous" id="S2.p3.5.m5.1.1.1.2.cmml" xref="S2.p3.5.m5.1.1.1">superscript</csymbol><apply id="S2.p3.5.m5.1.1.1.1.cmml" xref="S2.p3.5.m5.1.1.1"><csymbol cd="ambiguous" id="S2.p3.5.m5.1.1.1.1.2.cmml" xref="S2.p3.5.m5.1.1.1">subscript</csymbol><set id="S2.p3.5.m5.1.1.1.1.1.2.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1"><apply id="S2.p3.5.m5.1.1.1.1.1.1.1.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p3.5.m5.1.1.1.1.1.1.1.1.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p3.5.m5.1.1.1.1.1.1.1.2.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1.1.2">𝑐</ci><ci id="S2.p3.5.m5.1.1.1.1.1.1.1.3.cmml" xref="S2.p3.5.m5.1.1.1.1.1.1.1.3">𝑛</ci></apply></set><apply id="S2.p3.5.m5.1.1.1.1.3.cmml" xref="S2.p3.5.m5.1.1.1.1.3"><eq id="S2.p3.5.m5.1.1.1.1.3.1.cmml" xref="S2.p3.5.m5.1.1.1.1.3.1"></eq><ci id="S2.p3.5.m5.1.1.1.1.3.2.cmml" xref="S2.p3.5.m5.1.1.1.1.3.2">𝑛</ci><cn id="S2.p3.5.m5.1.1.1.1.3.3.cmml" type="integer" xref="S2.p3.5.m5.1.1.1.1.3.3">1</cn></apply></apply><ci id="S2.p3.5.m5.1.1.1.3.cmml" xref="S2.p3.5.m5.1.1.1.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.5.m5.1c">\mathcal{C}=\{c_{n}\}_{n=1}^{N}</annotation><annotation encoding="application/x-llamapun" id="S2.p3.5.m5.1d">caligraphic_C = { italic_c start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_n = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N end_POSTSUPERSCRIPT</annotation></semantics></math> be the correct answers.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.3">Let <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S2.p4.1.m1.1"><semantics id="S2.p4.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p4.1.m1.1.1" xref="S2.p4.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S2.p4.1.m1.1b"><ci id="S2.p4.1.m1.1.1.cmml" xref="S2.p4.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.1.m1.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="S2.p4.1.m1.1d">caligraphic_M</annotation></semantics></math> be a language model. We denote by <math alttext="\mathcal{M}(q_{n})\in\{a_{n}^{1},\ldots,a_{n}^{L}\}" class="ltx_Math" display="inline" id="S2.p4.2.m2.4"><semantics id="S2.p4.2.m2.4a"><mrow id="S2.p4.2.m2.4.4" xref="S2.p4.2.m2.4.4.cmml"><mrow id="S2.p4.2.m2.2.2.1" xref="S2.p4.2.m2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p4.2.m2.2.2.1.3" xref="S2.p4.2.m2.2.2.1.3.cmml">ℳ</mi><mo id="S2.p4.2.m2.2.2.1.2" xref="S2.p4.2.m2.2.2.1.2.cmml">⁢</mo><mrow id="S2.p4.2.m2.2.2.1.1.1" xref="S2.p4.2.m2.2.2.1.1.1.1.cmml"><mo id="S2.p4.2.m2.2.2.1.1.1.2" stretchy="false" xref="S2.p4.2.m2.2.2.1.1.1.1.cmml">(</mo><msub id="S2.p4.2.m2.2.2.1.1.1.1" xref="S2.p4.2.m2.2.2.1.1.1.1.cmml"><mi id="S2.p4.2.m2.2.2.1.1.1.1.2" xref="S2.p4.2.m2.2.2.1.1.1.1.2.cmml">q</mi><mi id="S2.p4.2.m2.2.2.1.1.1.1.3" xref="S2.p4.2.m2.2.2.1.1.1.1.3.cmml">n</mi></msub><mo id="S2.p4.2.m2.2.2.1.1.1.3" stretchy="false" xref="S2.p4.2.m2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.p4.2.m2.4.4.4" xref="S2.p4.2.m2.4.4.4.cmml">∈</mo><mrow id="S2.p4.2.m2.4.4.3.2" xref="S2.p4.2.m2.4.4.3.3.cmml"><mo id="S2.p4.2.m2.4.4.3.2.3" stretchy="false" xref="S2.p4.2.m2.4.4.3.3.cmml">{</mo><msubsup id="S2.p4.2.m2.3.3.2.1.1" xref="S2.p4.2.m2.3.3.2.1.1.cmml"><mi id="S2.p4.2.m2.3.3.2.1.1.2.2" xref="S2.p4.2.m2.3.3.2.1.1.2.2.cmml">a</mi><mi id="S2.p4.2.m2.3.3.2.1.1.2.3" xref="S2.p4.2.m2.3.3.2.1.1.2.3.cmml">n</mi><mn id="S2.p4.2.m2.3.3.2.1.1.3" xref="S2.p4.2.m2.3.3.2.1.1.3.cmml">1</mn></msubsup><mo id="S2.p4.2.m2.4.4.3.2.4" xref="S2.p4.2.m2.4.4.3.3.cmml">,</mo><mi id="S2.p4.2.m2.1.1" mathvariant="normal" xref="S2.p4.2.m2.1.1.cmml">…</mi><mo id="S2.p4.2.m2.4.4.3.2.5" xref="S2.p4.2.m2.4.4.3.3.cmml">,</mo><msubsup id="S2.p4.2.m2.4.4.3.2.2" xref="S2.p4.2.m2.4.4.3.2.2.cmml"><mi id="S2.p4.2.m2.4.4.3.2.2.2.2" xref="S2.p4.2.m2.4.4.3.2.2.2.2.cmml">a</mi><mi id="S2.p4.2.m2.4.4.3.2.2.2.3" xref="S2.p4.2.m2.4.4.3.2.2.2.3.cmml">n</mi><mi id="S2.p4.2.m2.4.4.3.2.2.3" xref="S2.p4.2.m2.4.4.3.2.2.3.cmml">L</mi></msubsup><mo id="S2.p4.2.m2.4.4.3.2.6" stretchy="false" xref="S2.p4.2.m2.4.4.3.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p4.2.m2.4b"><apply id="S2.p4.2.m2.4.4.cmml" xref="S2.p4.2.m2.4.4"><in id="S2.p4.2.m2.4.4.4.cmml" xref="S2.p4.2.m2.4.4.4"></in><apply id="S2.p4.2.m2.2.2.1.cmml" xref="S2.p4.2.m2.2.2.1"><times id="S2.p4.2.m2.2.2.1.2.cmml" xref="S2.p4.2.m2.2.2.1.2"></times><ci id="S2.p4.2.m2.2.2.1.3.cmml" xref="S2.p4.2.m2.2.2.1.3">ℳ</ci><apply id="S2.p4.2.m2.2.2.1.1.1.1.cmml" xref="S2.p4.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.p4.2.m2.2.2.1.1.1.1.1.cmml" xref="S2.p4.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S2.p4.2.m2.2.2.1.1.1.1.2.cmml" xref="S2.p4.2.m2.2.2.1.1.1.1.2">𝑞</ci><ci id="S2.p4.2.m2.2.2.1.1.1.1.3.cmml" xref="S2.p4.2.m2.2.2.1.1.1.1.3">𝑛</ci></apply></apply><set id="S2.p4.2.m2.4.4.3.3.cmml" xref="S2.p4.2.m2.4.4.3.2"><apply id="S2.p4.2.m2.3.3.2.1.1.cmml" xref="S2.p4.2.m2.3.3.2.1.1"><csymbol cd="ambiguous" id="S2.p4.2.m2.3.3.2.1.1.1.cmml" xref="S2.p4.2.m2.3.3.2.1.1">superscript</csymbol><apply id="S2.p4.2.m2.3.3.2.1.1.2.cmml" xref="S2.p4.2.m2.3.3.2.1.1"><csymbol cd="ambiguous" id="S2.p4.2.m2.3.3.2.1.1.2.1.cmml" xref="S2.p4.2.m2.3.3.2.1.1">subscript</csymbol><ci id="S2.p4.2.m2.3.3.2.1.1.2.2.cmml" xref="S2.p4.2.m2.3.3.2.1.1.2.2">𝑎</ci><ci id="S2.p4.2.m2.3.3.2.1.1.2.3.cmml" xref="S2.p4.2.m2.3.3.2.1.1.2.3">𝑛</ci></apply><cn id="S2.p4.2.m2.3.3.2.1.1.3.cmml" type="integer" xref="S2.p4.2.m2.3.3.2.1.1.3">1</cn></apply><ci id="S2.p4.2.m2.1.1.cmml" xref="S2.p4.2.m2.1.1">…</ci><apply id="S2.p4.2.m2.4.4.3.2.2.cmml" xref="S2.p4.2.m2.4.4.3.2.2"><csymbol cd="ambiguous" id="S2.p4.2.m2.4.4.3.2.2.1.cmml" xref="S2.p4.2.m2.4.4.3.2.2">superscript</csymbol><apply id="S2.p4.2.m2.4.4.3.2.2.2.cmml" xref="S2.p4.2.m2.4.4.3.2.2"><csymbol cd="ambiguous" id="S2.p4.2.m2.4.4.3.2.2.2.1.cmml" xref="S2.p4.2.m2.4.4.3.2.2">subscript</csymbol><ci id="S2.p4.2.m2.4.4.3.2.2.2.2.cmml" xref="S2.p4.2.m2.4.4.3.2.2.2.2">𝑎</ci><ci id="S2.p4.2.m2.4.4.3.2.2.2.3.cmml" xref="S2.p4.2.m2.4.4.3.2.2.2.3">𝑛</ci></apply><ci id="S2.p4.2.m2.4.4.3.2.2.3.cmml" xref="S2.p4.2.m2.4.4.3.2.2.3">𝐿</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.2.m2.4c">\mathcal{M}(q_{n})\in\{a_{n}^{1},\ldots,a_{n}^{L}\}</annotation><annotation encoding="application/x-llamapun" id="S2.p4.2.m2.4d">caligraphic_M ( italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) ∈ { italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT , … , italic_a start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT }</annotation></semantics></math> the predicted answer of the model to the <math alttext="n" class="ltx_Math" display="inline" id="S2.p4.3.m3.1"><semantics id="S2.p4.3.m3.1a"><mi id="S2.p4.3.m3.1.1" xref="S2.p4.3.m3.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S2.p4.3.m3.1b"><ci id="S2.p4.3.m3.1.1.cmml" xref="S2.p4.3.m3.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p4.3.m3.1c">n</annotation><annotation encoding="application/x-llamapun" id="S2.p4.3.m3.1d">italic_n</annotation></semantics></math>-th question.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.3">We define the <span class="ltx_text ltx_font_italic" id="S2.p5.3.1">knowledge score</span> <math alttext="\mathcal{L}" class="ltx_Math" display="inline" id="S2.p5.1.m1.1"><semantics id="S2.p5.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p5.1.m1.1.1" xref="S2.p5.1.m1.1.1.cmml">ℒ</mi><annotation-xml encoding="MathML-Content" id="S2.p5.1.m1.1b"><ci id="S2.p5.1.m1.1.1.cmml" xref="S2.p5.1.m1.1.1">ℒ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.1.m1.1c">\mathcal{L}</annotation><annotation encoding="application/x-llamapun" id="S2.p5.1.m1.1d">caligraphic_L</annotation></semantics></math> of <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S2.p5.2.m2.1"><semantics id="S2.p5.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p5.2.m2.1.1" xref="S2.p5.2.m2.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S2.p5.2.m2.1b"><ci id="S2.p5.2.m2.1.1.cmml" xref="S2.p5.2.m2.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.2.m2.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="S2.p5.2.m2.1d">caligraphic_M</annotation></semantics></math> in relation to <math alttext="\mathcal{Q}" class="ltx_Math" display="inline" id="S2.p5.3.m3.1"><semantics id="S2.p5.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p5.3.m3.1.1" xref="S2.p5.3.m3.1.1.cmml">𝒬</mi><annotation-xml encoding="MathML-Content" id="S2.p5.3.m3.1b"><ci id="S2.p5.3.m3.1.1.cmml" xref="S2.p5.3.m3.1.1">𝒬</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p5.3.m3.1c">\mathcal{Q}</annotation><annotation encoding="application/x-llamapun" id="S2.p5.3.m3.1d">caligraphic_Q</annotation></semantics></math> to be the standard accuracy score:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\mathcal{M},\mathcal{Q}}:=\frac{\#\{q_{n}|\;\mathcal{M}(q_{n})=c_%
{n}\}}{N}." class="ltx_Math" display="block" id="S2.E1.m1.5"><semantics id="S2.E1.m1.5a"><mrow id="S2.E1.m1.5.5.1" xref="S2.E1.m1.5.5.1.1.cmml"><mrow id="S2.E1.m1.5.5.1.1" xref="S2.E1.m1.5.5.1.1.cmml"><msub id="S2.E1.m1.5.5.1.1.2" xref="S2.E1.m1.5.5.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.5.5.1.1.2.2" xref="S2.E1.m1.5.5.1.1.2.2.cmml">ℒ</mi><mrow id="S2.E1.m1.2.2.2.4" xref="S2.E1.m1.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml">ℳ</mi><mo id="S2.E1.m1.2.2.2.4.1" xref="S2.E1.m1.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.2.2.2.2" xref="S2.E1.m1.2.2.2.2.cmml">𝒬</mi></mrow></msub><mo id="S2.E1.m1.5.5.1.1.1" lspace="0.278em" rspace="0.278em" xref="S2.E1.m1.5.5.1.1.1.cmml">:=</mo><mfrac id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml"><mrow id="S2.E1.m1.4.4.2" xref="S2.E1.m1.4.4.2.cmml"><mi id="S2.E1.m1.4.4.2.4" mathvariant="normal" xref="S2.E1.m1.4.4.2.4.cmml">#</mi><mo id="S2.E1.m1.4.4.2.3" xref="S2.E1.m1.4.4.2.3.cmml">⁢</mo><mrow id="S2.E1.m1.4.4.2.2.2" xref="S2.E1.m1.4.4.2.2.3.cmml"><mo id="S2.E1.m1.4.4.2.2.2.3" stretchy="false" xref="S2.E1.m1.4.4.2.2.3.1.cmml">{</mo><msub id="S2.E1.m1.3.3.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.cmml"><mi id="S2.E1.m1.3.3.1.1.1.1.2" xref="S2.E1.m1.3.3.1.1.1.1.2.cmml">q</mi><mi id="S2.E1.m1.3.3.1.1.1.1.3" xref="S2.E1.m1.3.3.1.1.1.1.3.cmml">n</mi></msub><mo id="S2.E1.m1.4.4.2.2.2.4" lspace="0em" xref="S2.E1.m1.4.4.2.2.3.1.cmml">|</mo><mrow id="S2.E1.m1.4.4.2.2.2.2" xref="S2.E1.m1.4.4.2.2.2.2.cmml"><mrow id="S2.E1.m1.4.4.2.2.2.2.1" xref="S2.E1.m1.4.4.2.2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.4.4.2.2.2.2.1.3" xref="S2.E1.m1.4.4.2.2.2.2.1.3.cmml">ℳ</mi><mo id="S2.E1.m1.4.4.2.2.2.2.1.2" xref="S2.E1.m1.4.4.2.2.2.2.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.4.4.2.2.2.2.1.1.1" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml"><mo id="S2.E1.m1.4.4.2.2.2.2.1.1.1.2" stretchy="false" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml">(</mo><msub id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml"><mi id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.2" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.2.cmml">q</mi><mi id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.3" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.3.cmml">n</mi></msub><mo id="S2.E1.m1.4.4.2.2.2.2.1.1.1.3" stretchy="false" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.4.4.2.2.2.2.2" xref="S2.E1.m1.4.4.2.2.2.2.2.cmml">=</mo><msub id="S2.E1.m1.4.4.2.2.2.2.3" xref="S2.E1.m1.4.4.2.2.2.2.3.cmml"><mi id="S2.E1.m1.4.4.2.2.2.2.3.2" xref="S2.E1.m1.4.4.2.2.2.2.3.2.cmml">c</mi><mi id="S2.E1.m1.4.4.2.2.2.2.3.3" xref="S2.E1.m1.4.4.2.2.2.2.3.3.cmml">n</mi></msub></mrow><mo id="S2.E1.m1.4.4.2.2.2.5" stretchy="false" xref="S2.E1.m1.4.4.2.2.3.1.cmml">}</mo></mrow></mrow><mi id="S2.E1.m1.4.4.4" xref="S2.E1.m1.4.4.4.cmml">N</mi></mfrac></mrow><mo id="S2.E1.m1.5.5.1.2" lspace="0em" xref="S2.E1.m1.5.5.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.5b"><apply id="S2.E1.m1.5.5.1.1.cmml" xref="S2.E1.m1.5.5.1"><csymbol cd="latexml" id="S2.E1.m1.5.5.1.1.1.cmml" xref="S2.E1.m1.5.5.1.1.1">assign</csymbol><apply id="S2.E1.m1.5.5.1.1.2.cmml" xref="S2.E1.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.1.1.2.1.cmml" xref="S2.E1.m1.5.5.1.1.2">subscript</csymbol><ci id="S2.E1.m1.5.5.1.1.2.2.cmml" xref="S2.E1.m1.5.5.1.1.2.2">ℒ</ci><list id="S2.E1.m1.2.2.2.3.cmml" xref="S2.E1.m1.2.2.2.4"><ci id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1">ℳ</ci><ci id="S2.E1.m1.2.2.2.2.cmml" xref="S2.E1.m1.2.2.2.2">𝒬</ci></list></apply><apply id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4"><divide id="S2.E1.m1.4.4.3.cmml" xref="S2.E1.m1.4.4"></divide><apply id="S2.E1.m1.4.4.2.cmml" xref="S2.E1.m1.4.4.2"><times id="S2.E1.m1.4.4.2.3.cmml" xref="S2.E1.m1.4.4.2.3"></times><ci id="S2.E1.m1.4.4.2.4.cmml" xref="S2.E1.m1.4.4.2.4">#</ci><apply id="S2.E1.m1.4.4.2.2.3.cmml" xref="S2.E1.m1.4.4.2.2.2"><csymbol cd="latexml" id="S2.E1.m1.4.4.2.2.3.1.cmml" xref="S2.E1.m1.4.4.2.2.2.3">conditional-set</csymbol><apply id="S2.E1.m1.3.3.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.1.1.1.1.1.cmml" xref="S2.E1.m1.3.3.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.3.3.1.1.1.1.2.cmml" xref="S2.E1.m1.3.3.1.1.1.1.2">𝑞</ci><ci id="S2.E1.m1.3.3.1.1.1.1.3.cmml" xref="S2.E1.m1.3.3.1.1.1.1.3">𝑛</ci></apply><apply id="S2.E1.m1.4.4.2.2.2.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2"><eq id="S2.E1.m1.4.4.2.2.2.2.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.2"></eq><apply id="S2.E1.m1.4.4.2.2.2.2.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1"><times id="S2.E1.m1.4.4.2.2.2.2.1.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.2"></times><ci id="S2.E1.m1.4.4.2.2.2.2.1.3.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.3">ℳ</ci><apply id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1">subscript</csymbol><ci id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.2">𝑞</ci><ci id="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.3.cmml" xref="S2.E1.m1.4.4.2.2.2.2.1.1.1.1.3">𝑛</ci></apply></apply><apply id="S2.E1.m1.4.4.2.2.2.2.3.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.2.2.2.2.3.1.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3">subscript</csymbol><ci id="S2.E1.m1.4.4.2.2.2.2.3.2.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3.2">𝑐</ci><ci id="S2.E1.m1.4.4.2.2.2.2.3.3.cmml" xref="S2.E1.m1.4.4.2.2.2.2.3.3">𝑛</ci></apply></apply></apply></apply><ci id="S2.E1.m1.4.4.4.cmml" xref="S2.E1.m1.4.4.4">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.5c">\mathcal{L}_{\mathcal{M},\mathcal{Q}}:=\frac{\#\{q_{n}|\;\mathcal{M}(q_{n})=c_%
{n}\}}{N}.</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.5d">caligraphic_L start_POSTSUBSCRIPT caligraphic_M , caligraphic_Q end_POSTSUBSCRIPT := divide start_ARG # { italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT | caligraphic_M ( italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) = italic_c start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT } end_ARG start_ARG italic_N end_ARG .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S2.p6">
<p class="ltx_p" id="S2.p6.2">We say that the model <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S2.p6.1.m1.1"><semantics id="S2.p6.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p6.1.m1.1.1" xref="S2.p6.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S2.p6.1.m1.1b"><ci id="S2.p6.1.m1.1.1.cmml" xref="S2.p6.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.1.m1.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="S2.p6.1.m1.1d">caligraphic_M</annotation></semantics></math> possesses <span class="ltx_text ltx_font_italic" id="S2.p6.2.1">any</span> knowledge regarding the set of questions <math alttext="\mathcal{Q}" class="ltx_Math" display="inline" id="S2.p6.2.m2.1"><semantics id="S2.p6.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p6.2.m2.1.1" xref="S2.p6.2.m2.1.1.cmml">𝒬</mi><annotation-xml encoding="MathML-Content" id="S2.p6.2.m2.1b"><ci id="S2.p6.2.m2.1.1.cmml" xref="S2.p6.2.m2.1.1">𝒬</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p6.2.m2.1c">\mathcal{Q}</annotation><annotation encoding="application/x-llamapun" id="S2.p6.2.m2.1d">caligraphic_Q</annotation></semantics></math> if the following holds:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.p7">
<table class="ltx_equation ltx_eqn_table" id="S2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\mathcal{M},\mathcal{Q}}>\frac{1}{L}." class="ltx_Math" display="block" id="S2.E2.m1.3"><semantics id="S2.E2.m1.3a"><mrow id="S2.E2.m1.3.3.1" xref="S2.E2.m1.3.3.1.1.cmml"><mrow id="S2.E2.m1.3.3.1.1" xref="S2.E2.m1.3.3.1.1.cmml"><msub id="S2.E2.m1.3.3.1.1.2" xref="S2.E2.m1.3.3.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.3.3.1.1.2.2" xref="S2.E2.m1.3.3.1.1.2.2.cmml">ℒ</mi><mrow id="S2.E2.m1.2.2.2.4" xref="S2.E2.m1.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml">ℳ</mi><mo id="S2.E2.m1.2.2.2.4.1" xref="S2.E2.m1.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.2.2.2.2" xref="S2.E2.m1.2.2.2.2.cmml">𝒬</mi></mrow></msub><mo id="S2.E2.m1.3.3.1.1.1" xref="S2.E2.m1.3.3.1.1.1.cmml">&gt;</mo><mfrac id="S2.E2.m1.3.3.1.1.3" xref="S2.E2.m1.3.3.1.1.3.cmml"><mn id="S2.E2.m1.3.3.1.1.3.2" xref="S2.E2.m1.3.3.1.1.3.2.cmml">1</mn><mi id="S2.E2.m1.3.3.1.1.3.3" xref="S2.E2.m1.3.3.1.1.3.3.cmml">L</mi></mfrac></mrow><mo id="S2.E2.m1.3.3.1.2" lspace="0em" xref="S2.E2.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.3b"><apply id="S2.E2.m1.3.3.1.1.cmml" xref="S2.E2.m1.3.3.1"><gt id="S2.E2.m1.3.3.1.1.1.cmml" xref="S2.E2.m1.3.3.1.1.1"></gt><apply id="S2.E2.m1.3.3.1.1.2.cmml" xref="S2.E2.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.3.3.1.1.2.1.cmml" xref="S2.E2.m1.3.3.1.1.2">subscript</csymbol><ci id="S2.E2.m1.3.3.1.1.2.2.cmml" xref="S2.E2.m1.3.3.1.1.2.2">ℒ</ci><list id="S2.E2.m1.2.2.2.3.cmml" xref="S2.E2.m1.2.2.2.4"><ci id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1">ℳ</ci><ci id="S2.E2.m1.2.2.2.2.cmml" xref="S2.E2.m1.2.2.2.2">𝒬</ci></list></apply><apply id="S2.E2.m1.3.3.1.1.3.cmml" xref="S2.E2.m1.3.3.1.1.3"><divide id="S2.E2.m1.3.3.1.1.3.1.cmml" xref="S2.E2.m1.3.3.1.1.3"></divide><cn id="S2.E2.m1.3.3.1.1.3.2.cmml" type="integer" xref="S2.E2.m1.3.3.1.1.3.2">1</cn><ci id="S2.E2.m1.3.3.1.1.3.3.cmml" xref="S2.E2.m1.3.3.1.1.3.3">𝐿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.3c">\mathcal{L}_{\mathcal{M},\mathcal{Q}}&gt;\frac{1}{L}.</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.3d">caligraphic_L start_POSTSUBSCRIPT caligraphic_M , caligraphic_Q end_POSTSUBSCRIPT &gt; divide start_ARG 1 end_ARG start_ARG italic_L end_ARG .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S2.p8">
<p class="ltx_p" id="S2.p8.2">In simpler terms, the model can consistently give correct answers, outperforming a simple random guessing baseline. Naturally, if the knowledge score <math alttext="\mathcal{L}_{\mathcal{M},\mathcal{Q}}" class="ltx_Math" display="inline" id="S2.p8.1.m1.2"><semantics id="S2.p8.1.m1.2a"><msub id="S2.p8.1.m1.2.3" xref="S2.p8.1.m1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p8.1.m1.2.3.2" xref="S2.p8.1.m1.2.3.2.cmml">ℒ</mi><mrow id="S2.p8.1.m1.2.2.2.4" xref="S2.p8.1.m1.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p8.1.m1.1.1.1.1" xref="S2.p8.1.m1.1.1.1.1.cmml">ℳ</mi><mo id="S2.p8.1.m1.2.2.2.4.1" xref="S2.p8.1.m1.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S2.p8.1.m1.2.2.2.2" xref="S2.p8.1.m1.2.2.2.2.cmml">𝒬</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.p8.1.m1.2b"><apply id="S2.p8.1.m1.2.3.cmml" xref="S2.p8.1.m1.2.3"><csymbol cd="ambiguous" id="S2.p8.1.m1.2.3.1.cmml" xref="S2.p8.1.m1.2.3">subscript</csymbol><ci id="S2.p8.1.m1.2.3.2.cmml" xref="S2.p8.1.m1.2.3.2">ℒ</ci><list id="S2.p8.1.m1.2.2.2.3.cmml" xref="S2.p8.1.m1.2.2.2.4"><ci id="S2.p8.1.m1.1.1.1.1.cmml" xref="S2.p8.1.m1.1.1.1.1">ℳ</ci><ci id="S2.p8.1.m1.2.2.2.2.cmml" xref="S2.p8.1.m1.2.2.2.2">𝒬</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.1.m1.2c">\mathcal{L}_{\mathcal{M},\mathcal{Q}}</annotation><annotation encoding="application/x-llamapun" id="S2.p8.1.m1.2d">caligraphic_L start_POSTSUBSCRIPT caligraphic_M , caligraphic_Q end_POSTSUBSCRIPT</annotation></semantics></math> is higher for one model compared to another, then we assert that the former is more knowledgeable with regards to <math alttext="\mathcal{Q}" class="ltx_Math" display="inline" id="S2.p8.2.m2.1"><semantics id="S2.p8.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S2.p8.2.m2.1.1" xref="S2.p8.2.m2.1.1.cmml">𝒬</mi><annotation-xml encoding="MathML-Content" id="S2.p8.2.m2.1b"><ci id="S2.p8.2.m2.1.1.cmml" xref="S2.p8.2.m2.1.1">𝒬</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p8.2.m2.1c">\mathcal{Q}</annotation><annotation encoding="application/x-llamapun" id="S2.p8.2.m2.1d">caligraphic_Q</annotation></semantics></math> compared to the latter.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.p9">
<p class="ltx_p" id="S2.p9.1"><span class="ltx_text ltx_font_bold" id="S2.p9.1.1">Previously Seen Knowledge</span>  One important distinction to make is between knowledge that the model has been exposed to before during pre-training as opposed to entirely new facts. Considering the size of modern LLM training sets, they cover a vast amount of information available through web-sourced text. As a result, even in niche domains, the goal of knowledge injection is not necessarily to teach the model entirely new facts but rather to ”refresh” its memory by inducing a bias toward a particular domain.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.p10">
<p class="ltx_p" id="S2.p10.1"><span class="ltx_text ltx_font_bold" id="S2.p10.1.1">Knowledge and Reasoning</span>  We emphasize that this knowledge evaluation framework for LLMs is imperfect. Importantly, it doesn’t address other quality metrics influencing a model’s response. Creating a purely knowledge-intensive dataset without involving some level of reasoning is challenging. Consequently, a model with robust reasoning abilities might excel on unfamiliar knowledge-intensive tasks by making ”educated guesses” in a multiple-choice exam. Therefore, any evaluation of knowledge in LLMs should consider this, with results seen as part of a broader range of benchmarks for reasoning <cite class="ltx_cite ltx_citemacro_citep">(Sakaguchi et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib35" title="">2021</a>)</cite>, reading comprehension <cite class="ltx_cite ltx_citemacro_citep">(Dua et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib9" title="">2019</a>)</cite>, and general language abilities <cite class="ltx_cite ltx_citemacro_citep">(Srivastava et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib41" title="">2022</a>)</cite>. However, this evaluation framework still strongly emphasizes factual information above all else.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.p11">
<p class="ltx_p" id="S2.p11.1"><span class="ltx_text ltx_font_bold" id="S2.p11.1.1">Causes for Factual Errors</span>  There are many possible reasons for the failure of models to answer factual questions accurately. In <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib47" title="">2023</a>)</cite>, Wang <span class="ltx_text ltx_font_italic" id="S2.p11.1.2">et al.</span> introduce a taxonomy of five main model-level causes:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S2.p12">
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Domain knowledge deficit</span>: A language model may lack comprehensive expertise in a specific domain to which it has not been exposed. For example, a model trained exclusively on texts written by William Shakespeare would perform poorly when asked about the works of Mark Twain.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">Outdated Information</span>: LLMs invariably have a cutoff date determined by their training dataset. Consequently, any events, discoveries, or changes occurring after the last training update will not be within the model’s knowledge without access to external sources.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">Immemorization</span>: Sometimes, a model is exposed to knowledge during its training process but does not retain it. This is especially true for rare facts that appear in the training dataset only scarcely <cite class="ltx_cite ltx_citemacro_citep">(Kandpal et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib17" title="">2023</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i4.p1">
<p class="ltx_p" id="S2.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i4.p1.1.1">Forgetting</span>: Language models often undergo additional training after the pre-training phase (fine-tuning). In some cases, this might lead to a phenomenon called <span class="ltx_text ltx_font_italic" id="S2.I1.i4.p1.1.2">catastrophic forgetting</span> <cite class="ltx_cite ltx_citemacro_citep">(Kirkpatrick et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib18" title="">2017</a>; Goodfellow et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib11" title="">2013</a>; Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib3" title="">2020</a>; Luo et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib23" title="">2023</a>)</cite>, where models lose some of the knowledge they had prior to the fine-tuning process.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="S2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S2.I1.i5.p1">
<p class="ltx_p" id="S2.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i5.p1.1.1">Reasoning Failure</span>: In certain instances, a language model might possess relevant knowledge about a fact but fail to utilize it properly. This is particularly evident in complex multi-step reasoning tasks <cite class="ltx_cite ltx_citemacro_citep">(Tan et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib42" title="">2023</a>)</cite> or when posed with different questions about the same fact, resulting in disparate outcomes <cite class="ltx_cite ltx_citemacro_citep">(Berglund et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib2" title="">2023</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S2.p13">
<p class="ltx_p" id="S2.p13.1">We observe that most of these issues arise during the pre-training phase, with catastrophic forgetting being the notable exception. Hence, many LLMs will suffer from factual errors of this kind regardless of any post-training process.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Injecting Knowledge to Language Models</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Following the background given in <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S2" title="2 Background ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>, it is clear that general pre-training is insufficient for many knowledge-intensive tasks. To solve this, an additional post-processing step is essential to augment the knowledge of a pre-trained model. This step is often reffered to as <span class="ltx_text ltx_font_italic" id="S3.p1.1.1">knowledge injection</span> <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib48" title="">2020</a>; Chen et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib4" title="">2022</a>; Liu et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib22" title="">2020</a>; Lauscher et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib20" title="">2020</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">In this section, we examine two widely used frameworks for knowledge injection: fine-tuning (FT) and retrieval augmented generation (RAG). We begin by formulating the knowledge injection problem, aiming to explain both methods using consistent terminology.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Problem formulation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">In <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S2.E1" title="1 ‣ 2 Background ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Equations</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a> and&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S2.E2" title="2 ‣ 2 Background ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">2</span></a>, we presented a formulation for knowledge in language models through the lens of question-answering (Q&amp;A). We now extend this formulation to the problem of knowledge injection using the same terminology.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">Given a set of factual questions, there exists some text corpus containing information that is relevant to these questions. The central assumption of knowledge injection is that given full access to this corpus, it could serve as an auxiliary knowledge base and improve the model’s performance on this set of questions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.5">Mathematically, let <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><ci id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">caligraphic_M</annotation></semantics></math> be a pre-trained model, and let <math alttext="\mathcal{Q}" class="ltx_Math" display="inline" id="S3.SS1.p3.2.m2.1"><semantics id="S3.SS1.p3.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.2.m2.1.1" xref="S3.SS1.p3.2.m2.1.1.cmml">𝒬</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.2.m2.1b"><ci id="S3.SS1.p3.2.m2.1.1.cmml" xref="S3.SS1.p3.2.m2.1.1">𝒬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.2.m2.1c">\mathcal{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.2.m2.1d">caligraphic_Q</annotation></semantics></math> be a set of factual questions, as before. Now, assume we have a relevant auxiliary knowledge base <math alttext="\mathcal{B}_{\mathcal{Q}}" class="ltx_Math" display="inline" id="S3.SS1.p3.3.m3.1"><semantics id="S3.SS1.p3.3.m3.1a"><msub id="S3.SS1.p3.3.m3.1.1" xref="S3.SS1.p3.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.3.m3.1.1.2" xref="S3.SS1.p3.3.m3.1.1.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.3.m3.1.1.3" xref="S3.SS1.p3.3.m3.1.1.3.cmml">𝒬</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.3.m3.1b"><apply id="S3.SS1.p3.3.m3.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p3.3.m3.1.1.1.cmml" xref="S3.SS1.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p3.3.m3.1.1.2.cmml" xref="S3.SS1.p3.3.m3.1.1.2">ℬ</ci><ci id="S3.SS1.p3.3.m3.1.1.3.cmml" xref="S3.SS1.p3.3.m3.1.1.3">𝒬</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.3.m3.1c">\mathcal{B}_{\mathcal{Q}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.3.m3.1d">caligraphic_B start_POSTSUBSCRIPT caligraphic_Q end_POSTSUBSCRIPT</annotation></semantics></math>. Our objective is to discover a transformation, denoted as <math alttext="\mathcal{F}" class="ltx_Math" display="inline" id="S3.SS1.p3.4.m4.1"><semantics id="S3.SS1.p3.4.m4.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.4.m4.1.1" xref="S3.SS1.p3.4.m4.1.1.cmml">ℱ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.4.m4.1b"><ci id="S3.SS1.p3.4.m4.1.1.cmml" xref="S3.SS1.p3.4.m4.1.1">ℱ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.4.m4.1c">\mathcal{F}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.4.m4.1d">caligraphic_F</annotation></semantics></math>, that, when applied, would enhance the knowledge about <math alttext="\mathcal{Q}" class="ltx_Math" display="inline" id="S3.SS1.p3.5.m5.1"><semantics id="S3.SS1.p3.5.m5.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p3.5.m5.1.1" xref="S3.SS1.p3.5.m5.1.1.cmml">𝒬</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.5.m5.1b"><ci id="S3.SS1.p3.5.m5.1.1.cmml" xref="S3.SS1.p3.5.m5.1.1">𝒬</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.5.m5.1c">\mathcal{Q}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.5.m5.1d">caligraphic_Q</annotation></semantics></math>:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{M^{\prime}}:=\mathcal{F}(\mathcal{M},\mathcal{B}_{\mathcal{Q}})\quad s%
.t.\quad\mathcal{L}_{\mathcal{M^{\prime}},\mathcal{Q}}>\mathcal{L}_{\mathcal{M%
},\mathcal{Q}}." class="ltx_math_unparsed" display="block" id="S3.E3.m1.7"><semantics id="S3.E3.m1.7a"><mrow id="S3.E3.m1.7b"><msup id="S3.E3.m1.7.8"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.8.2">ℳ</mi><mo id="S3.E3.m1.7.8.3">′</mo></msup><mo id="S3.E3.m1.7.9" lspace="0.278em" rspace="0.278em">:=</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.10">ℱ</mi><mrow id="S3.E3.m1.7.11"><mo id="S3.E3.m1.7.11.1" stretchy="false">(</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.5.5">ℳ</mi><mo id="S3.E3.m1.7.11.2">,</mo><msub id="S3.E3.m1.7.11.3"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.11.3.2">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.11.3.3">𝒬</mi></msub><mo id="S3.E3.m1.7.11.4" stretchy="false">)</mo></mrow><mspace id="S3.E3.m1.7.12" width="1em"></mspace><mi id="S3.E3.m1.6.6">s</mi><mo id="S3.E3.m1.7.13" lspace="0em" rspace="0.167em">.</mo><mi id="S3.E3.m1.7.7">t</mi><mo id="S3.E3.m1.7.14" lspace="0em">.</mo><mspace id="S3.E3.m1.7.15" width="1.167em"></mspace><msub id="S3.E3.m1.7.16"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.16.2">ℒ</mi><mrow id="S3.E3.m1.2.2.2.2"><msup id="S3.E3.m1.2.2.2.2.1"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.2.2.2.2.1.2">ℳ</mi><mo id="S3.E3.m1.2.2.2.2.1.3">′</mo></msup><mo id="S3.E3.m1.2.2.2.2.2">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1">𝒬</mi></mrow></msub><mo id="S3.E3.m1.7.17">&gt;</mo><msub id="S3.E3.m1.7.18"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.7.18.2">ℒ</mi><mrow id="S3.E3.m1.4.4.2.4"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.3.3.1.1">ℳ</mi><mo id="S3.E3.m1.4.4.2.4.1">,</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.4.4.2.2">𝒬</mi></mrow></msub><mo id="S3.E3.m1.7.19" lspace="0em">.</mo></mrow><annotation encoding="application/x-tex" id="S3.E3.m1.7c">\mathcal{M^{\prime}}:=\mathcal{F}(\mathcal{M},\mathcal{B}_{\mathcal{Q}})\quad s%
.t.\quad\mathcal{L}_{\mathcal{M^{\prime}},\mathcal{Q}}&gt;\mathcal{L}_{\mathcal{M%
},\mathcal{Q}}.</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.7d">caligraphic_M start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT := caligraphic_F ( caligraphic_M , caligraphic_B start_POSTSUBSCRIPT caligraphic_Q end_POSTSUBSCRIPT ) italic_s . italic_t . caligraphic_L start_POSTSUBSCRIPT caligraphic_M start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , caligraphic_Q end_POSTSUBSCRIPT &gt; caligraphic_L start_POSTSUBSCRIPT caligraphic_M , caligraphic_Q end_POSTSUBSCRIPT .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1">In this work, we aim to compare two choices for <math alttext="\mathcal{F}" class="ltx_Math" display="inline" id="S3.SS1.p5.1.m1.1"><semantics id="S3.SS1.p5.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml">ℱ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><ci id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1">ℱ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">\mathcal{F}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.1.m1.1d">caligraphic_F</annotation></semantics></math>: fine-tuning and RAG to see which option performs better in this problem.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Fine-Tuning</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Fine-tuning is the process of adjusting a pre-trained model on a specific, often narrower, dataset or task to enhance its performance in that particular domain. Here, it is vital to distinguish between different types of fine-tuning. FT techniques are commonly classified into supervised, unsupervised, and reinforcement learning (RL) based methods. We proceed by briefly reviewing these methods and their relation to the problem of knowledge injection.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Supervised Fine-Tuning</span>  Supervised fine-tuning (SFT) requires sets of labeled input-output pairs. One of the most common SFT methods is instruction tuning <cite class="ltx_cite ltx_citemacro_citep">(Wang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib49" title="">2022</a>; Mishra et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib25" title="">2021</a>; Ouyang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib31" title="">2022</a>; Taori et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib43" title="">2023</a>)</cite>, which has emerged as one of the most powerful methods to improve model performance. With instruction tuning, the input is a natural language task description, and the output is an example of the desired behavior. Many current state-of-the-art LLMs have gone through instruction tuning after their pre-training phase.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">Instruction tuning has been shown to be very effective at improving the overall quality of the model, with a particular emphasis on its zero-shot and reasoning capabilities. However, despite these advantages, instruction tuning does not necessarily teach the model new knowledge <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib31" title="">2022</a>; Chung et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib7" title="">2022</a>; Mitra et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib26" title="">2023</a>; Chia et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib6" title="">2023</a>; Zhou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib55" title="">2023</a>)</cite>. As such, instruction tuning alone is not a viable solution to the knowledge injection problem.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Reinforcemnt Learning</span>  Another form of FT relies on RL or RL-inspired optimization strategies to better align the model after its pre-training phase. A few prominent examples are reinforcement learning from human feedback (RLHF) <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib30" title="">2023</a>; Touvron et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib45" title="">2023</a>)</cite>, direct preference optimization (DPO) <cite class="ltx_cite ltx_citemacro_citep">(Rafailov et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib34" title="">2023</a>)</cite>, and proximal policy optimization (PPO) <cite class="ltx_cite ltx_citemacro_citep">(Schulman et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib36" title="">2017</a>; Tunstall et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib46" title="">2023</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1">These techniques have been shown to be very useful, especially when used in conjunction with instruction tuning. However, similarly to instruction tuning, these methods focus on the overall quality of the response and its expected behavior and not necessarily on its breadth of knowledge.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p6.1.1">Unsupervised Fine-Tuning</span>  The final FT strategy we discuss is unsupervised, meaning there are no available labels for the model to learn from. One common unsupervised FT technique is often referred to as <span class="ltx_text ltx_font_italic" id="S3.SS2.p6.1.2">continual pre-training</span> or <span class="ltx_text ltx_font_italic" id="S3.SS2.p6.1.3">unstructured</span> FT.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p7">
<p class="ltx_p" id="S3.SS2.p7.1">In this method, the FT process is viewed as a direct continuation of the pre-training phase. We start with a saved checkpoint of the original LLM and train it in a causal auto-regressive manner, i.e., predicting the next token. One major difference in comparison to actual pre-training is the learning rate. Usually, one would need a much lower learning rate when continuing the pre-training of the model to avoid catastrophic forgetting <cite class="ltx_cite ltx_citemacro_citep">(Kirkpatrick et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib18" title="">2017</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS2.p8">
<p class="ltx_p" id="S3.SS2.p8.1">It is well known that LLMs store vast amounts of knowledge during their pre-training phase <cite class="ltx_cite ltx_citemacro_citep">(Zhou et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib55" title="">2023</a>)</cite>. So, it makes sense to continue this process in order to inject knowledge into the model. Hence, we use the unsupervised FT approach throughout this work and evaluate its efficacy in enhancing the model’s capacity for learning new information.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Retrieval Augmented Generation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Retrieval augmented generation (RAG)&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lewis et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib21" title="">2020</a>)</cite> is a technique that expands LLMs’ capabilities, especially in knowledge-intensive tasks, by using external knowledge sources. While the original formulation involved additional training per task, it has since been demonstrated&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Neelakantan et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib27" title="">2022</a>)</cite> that a pre-trained <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.1">embedding</span> model can achieve improved performance with no additional training involved.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">The idea is that given an auxiliary knowledge base and an input query, we use the RAG architecture to find documents within the knowledge base that resemble the input query. These documents are then added to the input query, thus giving the model further context about the subject of the query.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.12">In practice, implementing the suggested architecture is quite straightforward: Given an auxiliary knowledge base <math alttext="\mathcal{B}_{\mathcal{Q}}" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><msub id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">𝒬</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">ℬ</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">𝒬</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">\mathcal{B}_{\mathcal{Q}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">caligraphic_B start_POSTSUBSCRIPT caligraphic_Q end_POSTSUBSCRIPT</annotation></semantics></math> and a pre-trained embedding model <math alttext="\mathcal{M}_{e}" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m2.1"><semantics id="S3.SS3.p3.2.m2.1a"><msub id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">ℳ</mi><mi id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml">e</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p3.2.m2.1.1.2.cmml" xref="S3.SS3.p3.2.m2.1.1.2">ℳ</ci><ci id="S3.SS3.p3.2.m2.1.1.3.cmml" xref="S3.SS3.p3.2.m2.1.1.3">𝑒</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">\mathcal{M}_{e}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.2.m2.1d">caligraphic_M start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT</annotation></semantics></math>, we create a dense vector representation (embedding) per document <math alttext="b\in\mathcal{B}_{\mathcal{Q}}" class="ltx_Math" display="inline" id="S3.SS3.p3.3.m3.1"><semantics id="S3.SS3.p3.3.m3.1a"><mrow id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">b</mi><mo id="S3.SS3.p3.3.m3.1.1.1" xref="S3.SS3.p3.3.m3.1.1.1.cmml">∈</mo><msub id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.3.m3.1.1.3.2" xref="S3.SS3.p3.3.m3.1.1.3.2.cmml">ℬ</mi><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.3.m3.1.1.3.3" xref="S3.SS3.p3.3.m3.1.1.3.3.cmml">𝒬</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><in id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1.1"></in><ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">𝑏</ci><apply id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.3.1.cmml" xref="S3.SS3.p3.3.m3.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.3.2.cmml" xref="S3.SS3.p3.3.m3.1.1.3.2">ℬ</ci><ci id="S3.SS3.p3.3.m3.1.1.3.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3.3">𝒬</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">b\in\mathcal{B}_{\mathcal{Q}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.3.m3.1d">italic_b ∈ caligraphic_B start_POSTSUBSCRIPT caligraphic_Q end_POSTSUBSCRIPT</annotation></semantics></math> and store these in a vector store. Upon receiving a new query <math alttext="q" class="ltx_Math" display="inline" id="S3.SS3.p3.4.m4.1"><semantics id="S3.SS3.p3.4.m4.1a"><mi id="S3.SS3.p3.4.m4.1.1" xref="S3.SS3.p3.4.m4.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.4.m4.1b"><ci id="S3.SS3.p3.4.m4.1.1.cmml" xref="S3.SS3.p3.4.m4.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.4.m4.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.4.m4.1d">italic_q</annotation></semantics></math>, we use its embedding, <math alttext="\mathcal{M}_{e}(q)" class="ltx_Math" display="inline" id="S3.SS3.p3.5.m5.1"><semantics id="S3.SS3.p3.5.m5.1a"><mrow id="S3.SS3.p3.5.m5.1.2" xref="S3.SS3.p3.5.m5.1.2.cmml"><msub id="S3.SS3.p3.5.m5.1.2.2" xref="S3.SS3.p3.5.m5.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.5.m5.1.2.2.2" xref="S3.SS3.p3.5.m5.1.2.2.2.cmml">ℳ</mi><mi id="S3.SS3.p3.5.m5.1.2.2.3" xref="S3.SS3.p3.5.m5.1.2.2.3.cmml">e</mi></msub><mo id="S3.SS3.p3.5.m5.1.2.1" xref="S3.SS3.p3.5.m5.1.2.1.cmml">⁢</mo><mrow id="S3.SS3.p3.5.m5.1.2.3.2" xref="S3.SS3.p3.5.m5.1.2.cmml"><mo id="S3.SS3.p3.5.m5.1.2.3.2.1" stretchy="false" xref="S3.SS3.p3.5.m5.1.2.cmml">(</mo><mi id="S3.SS3.p3.5.m5.1.1" xref="S3.SS3.p3.5.m5.1.1.cmml">q</mi><mo id="S3.SS3.p3.5.m5.1.2.3.2.2" stretchy="false" xref="S3.SS3.p3.5.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.5.m5.1b"><apply id="S3.SS3.p3.5.m5.1.2.cmml" xref="S3.SS3.p3.5.m5.1.2"><times id="S3.SS3.p3.5.m5.1.2.1.cmml" xref="S3.SS3.p3.5.m5.1.2.1"></times><apply id="S3.SS3.p3.5.m5.1.2.2.cmml" xref="S3.SS3.p3.5.m5.1.2.2"><csymbol cd="ambiguous" id="S3.SS3.p3.5.m5.1.2.2.1.cmml" xref="S3.SS3.p3.5.m5.1.2.2">subscript</csymbol><ci id="S3.SS3.p3.5.m5.1.2.2.2.cmml" xref="S3.SS3.p3.5.m5.1.2.2.2">ℳ</ci><ci id="S3.SS3.p3.5.m5.1.2.2.3.cmml" xref="S3.SS3.p3.5.m5.1.2.2.3">𝑒</ci></apply><ci id="S3.SS3.p3.5.m5.1.1.cmml" xref="S3.SS3.p3.5.m5.1.1">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.5.m5.1c">\mathcal{M}_{e}(q)</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.5.m5.1d">caligraphic_M start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ( italic_q )</annotation></semantics></math>, to retrieve <math alttext="q" class="ltx_Math" display="inline" id="S3.SS3.p3.6.m6.1"><semantics id="S3.SS3.p3.6.m6.1a"><mi id="S3.SS3.p3.6.m6.1.1" xref="S3.SS3.p3.6.m6.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.6.m6.1b"><ci id="S3.SS3.p3.6.m6.1.1.cmml" xref="S3.SS3.p3.6.m6.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.6.m6.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.6.m6.1d">italic_q</annotation></semantics></math>’s top-<math alttext="K" class="ltx_Math" display="inline" id="S3.SS3.p3.7.m7.1"><semantics id="S3.SS3.p3.7.m7.1a"><mi id="S3.SS3.p3.7.m7.1.1" xref="S3.SS3.p3.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.7.m7.1b"><ci id="S3.SS3.p3.7.m7.1.1.cmml" xref="S3.SS3.p3.7.m7.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.7.m7.1c">K</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.7.m7.1d">italic_K</annotation></semantics></math> closest neighbors, <math alttext="\mathbf{b}_{q}=\{b_{k}\}_{1}^{K}" class="ltx_Math" display="inline" id="S3.SS3.p3.8.m8.1"><semantics id="S3.SS3.p3.8.m8.1a"><mrow id="S3.SS3.p3.8.m8.1.1" xref="S3.SS3.p3.8.m8.1.1.cmml"><msub id="S3.SS3.p3.8.m8.1.1.3" xref="S3.SS3.p3.8.m8.1.1.3.cmml"><mi id="S3.SS3.p3.8.m8.1.1.3.2" xref="S3.SS3.p3.8.m8.1.1.3.2.cmml">𝐛</mi><mi id="S3.SS3.p3.8.m8.1.1.3.3" xref="S3.SS3.p3.8.m8.1.1.3.3.cmml">q</mi></msub><mo id="S3.SS3.p3.8.m8.1.1.2" xref="S3.SS3.p3.8.m8.1.1.2.cmml">=</mo><msubsup id="S3.SS3.p3.8.m8.1.1.1" xref="S3.SS3.p3.8.m8.1.1.1.cmml"><mrow id="S3.SS3.p3.8.m8.1.1.1.1.1.1" xref="S3.SS3.p3.8.m8.1.1.1.1.1.2.cmml"><mo id="S3.SS3.p3.8.m8.1.1.1.1.1.1.2" stretchy="false" xref="S3.SS3.p3.8.m8.1.1.1.1.1.2.cmml">{</mo><msub id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.cmml"><mi id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.2" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.2.cmml">b</mi><mi id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.3" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.3.cmml">k</mi></msub><mo id="S3.SS3.p3.8.m8.1.1.1.1.1.1.3" stretchy="false" xref="S3.SS3.p3.8.m8.1.1.1.1.1.2.cmml">}</mo></mrow><mn id="S3.SS3.p3.8.m8.1.1.1.1.3" xref="S3.SS3.p3.8.m8.1.1.1.1.3.cmml">1</mn><mi id="S3.SS3.p3.8.m8.1.1.1.3" xref="S3.SS3.p3.8.m8.1.1.1.3.cmml">K</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.8.m8.1b"><apply id="S3.SS3.p3.8.m8.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1"><eq id="S3.SS3.p3.8.m8.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.2"></eq><apply id="S3.SS3.p3.8.m8.1.1.3.cmml" xref="S3.SS3.p3.8.m8.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.3.1.cmml" xref="S3.SS3.p3.8.m8.1.1.3">subscript</csymbol><ci id="S3.SS3.p3.8.m8.1.1.3.2.cmml" xref="S3.SS3.p3.8.m8.1.1.3.2">𝐛</ci><ci id="S3.SS3.p3.8.m8.1.1.3.3.cmml" xref="S3.SS3.p3.8.m8.1.1.3.3">𝑞</ci></apply><apply id="S3.SS3.p3.8.m8.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.1">superscript</csymbol><apply id="S3.SS3.p3.8.m8.1.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.1">subscript</csymbol><set id="S3.SS3.p3.8.m8.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1"><apply id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.2">𝑏</ci><ci id="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.p3.8.m8.1.1.1.1.1.1.1.3">𝑘</ci></apply></set><cn id="S3.SS3.p3.8.m8.1.1.1.1.3.cmml" type="integer" xref="S3.SS3.p3.8.m8.1.1.1.1.3">1</cn></apply><ci id="S3.SS3.p3.8.m8.1.1.1.3.cmml" xref="S3.SS3.p3.8.m8.1.1.1.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.8.m8.1c">\mathbf{b}_{q}=\{b_{k}\}_{1}^{K}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.8.m8.1d">bold_b start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT = { italic_b start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT } start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT</annotation></semantics></math>, according to dot-product ranking. We then update <math alttext="q" class="ltx_Math" display="inline" id="S3.SS3.p3.9.m9.1"><semantics id="S3.SS3.p3.9.m9.1a"><mi id="S3.SS3.p3.9.m9.1.1" xref="S3.SS3.p3.9.m9.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.9.m9.1b"><ci id="S3.SS3.p3.9.m9.1.1.cmml" xref="S3.SS3.p3.9.m9.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.9.m9.1c">q</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.9.m9.1d">italic_q</annotation></semantics></math> to be <math alttext="\tilde{q}=\mathbf{b}_{q}\|q" class="ltx_Math" display="inline" id="S3.SS3.p3.10.m10.1"><semantics id="S3.SS3.p3.10.m10.1a"><mrow id="S3.SS3.p3.10.m10.1.1" xref="S3.SS3.p3.10.m10.1.1.cmml"><mover accent="true" id="S3.SS3.p3.10.m10.1.1.2" xref="S3.SS3.p3.10.m10.1.1.2.cmml"><mi id="S3.SS3.p3.10.m10.1.1.2.2" xref="S3.SS3.p3.10.m10.1.1.2.2.cmml">q</mi><mo id="S3.SS3.p3.10.m10.1.1.2.1" xref="S3.SS3.p3.10.m10.1.1.2.1.cmml">~</mo></mover><mo id="S3.SS3.p3.10.m10.1.1.1" xref="S3.SS3.p3.10.m10.1.1.1.cmml">=</mo><mrow id="S3.SS3.p3.10.m10.1.1.3" xref="S3.SS3.p3.10.m10.1.1.3.cmml"><msub id="S3.SS3.p3.10.m10.1.1.3.2" xref="S3.SS3.p3.10.m10.1.1.3.2.cmml"><mi id="S3.SS3.p3.10.m10.1.1.3.2.2" xref="S3.SS3.p3.10.m10.1.1.3.2.2.cmml">𝐛</mi><mi id="S3.SS3.p3.10.m10.1.1.3.2.3" xref="S3.SS3.p3.10.m10.1.1.3.2.3.cmml">q</mi></msub><mo id="S3.SS3.p3.10.m10.1.1.3.1" xref="S3.SS3.p3.10.m10.1.1.3.1.cmml">∥</mo><mi id="S3.SS3.p3.10.m10.1.1.3.3" xref="S3.SS3.p3.10.m10.1.1.3.3.cmml">q</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.10.m10.1b"><apply id="S3.SS3.p3.10.m10.1.1.cmml" xref="S3.SS3.p3.10.m10.1.1"><eq id="S3.SS3.p3.10.m10.1.1.1.cmml" xref="S3.SS3.p3.10.m10.1.1.1"></eq><apply id="S3.SS3.p3.10.m10.1.1.2.cmml" xref="S3.SS3.p3.10.m10.1.1.2"><ci id="S3.SS3.p3.10.m10.1.1.2.1.cmml" xref="S3.SS3.p3.10.m10.1.1.2.1">~</ci><ci id="S3.SS3.p3.10.m10.1.1.2.2.cmml" xref="S3.SS3.p3.10.m10.1.1.2.2">𝑞</ci></apply><apply id="S3.SS3.p3.10.m10.1.1.3.cmml" xref="S3.SS3.p3.10.m10.1.1.3"><csymbol cd="latexml" id="S3.SS3.p3.10.m10.1.1.3.1.cmml" xref="S3.SS3.p3.10.m10.1.1.3.1">conditional</csymbol><apply id="S3.SS3.p3.10.m10.1.1.3.2.cmml" xref="S3.SS3.p3.10.m10.1.1.3.2"><csymbol cd="ambiguous" id="S3.SS3.p3.10.m10.1.1.3.2.1.cmml" xref="S3.SS3.p3.10.m10.1.1.3.2">subscript</csymbol><ci id="S3.SS3.p3.10.m10.1.1.3.2.2.cmml" xref="S3.SS3.p3.10.m10.1.1.3.2.2">𝐛</ci><ci id="S3.SS3.p3.10.m10.1.1.3.2.3.cmml" xref="S3.SS3.p3.10.m10.1.1.3.2.3">𝑞</ci></apply><ci id="S3.SS3.p3.10.m10.1.1.3.3.cmml" xref="S3.SS3.p3.10.m10.1.1.3.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.10.m10.1c">\tilde{q}=\mathbf{b}_{q}\|q</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.10.m10.1d">over~ start_ARG italic_q end_ARG = bold_b start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ∥ italic_q</annotation></semantics></math>, where <math alttext="\|" class="ltx_Math" display="inline" id="S3.SS3.p3.11.m11.1"><semantics id="S3.SS3.p3.11.m11.1a"><mo id="S3.SS3.p3.11.m11.1.1" xref="S3.SS3.p3.11.m11.1.1.cmml">∥</mo><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.11.m11.1b"><ci id="S3.SS3.p3.11.m11.1.1.cmml" xref="S3.SS3.p3.11.m11.1.1">∥</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.11.m11.1c">\|</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.11.m11.1d">∥</annotation></semantics></math> denotes string concatenation. Finally, we return <math alttext="\mathcal{M}(\tilde{q})" class="ltx_Math" display="inline" id="S3.SS3.p3.12.m12.1"><semantics id="S3.SS3.p3.12.m12.1a"><mrow id="S3.SS3.p3.12.m12.1.2" xref="S3.SS3.p3.12.m12.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS3.p3.12.m12.1.2.2" xref="S3.SS3.p3.12.m12.1.2.2.cmml">ℳ</mi><mo id="S3.SS3.p3.12.m12.1.2.1" xref="S3.SS3.p3.12.m12.1.2.1.cmml">⁢</mo><mrow id="S3.SS3.p3.12.m12.1.2.3.2" xref="S3.SS3.p3.12.m12.1.1.cmml"><mo id="S3.SS3.p3.12.m12.1.2.3.2.1" stretchy="false" xref="S3.SS3.p3.12.m12.1.1.cmml">(</mo><mover accent="true" id="S3.SS3.p3.12.m12.1.1" xref="S3.SS3.p3.12.m12.1.1.cmml"><mi id="S3.SS3.p3.12.m12.1.1.2" xref="S3.SS3.p3.12.m12.1.1.2.cmml">q</mi><mo id="S3.SS3.p3.12.m12.1.1.1" xref="S3.SS3.p3.12.m12.1.1.1.cmml">~</mo></mover><mo id="S3.SS3.p3.12.m12.1.2.3.2.2" stretchy="false" xref="S3.SS3.p3.12.m12.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.12.m12.1b"><apply id="S3.SS3.p3.12.m12.1.2.cmml" xref="S3.SS3.p3.12.m12.1.2"><times id="S3.SS3.p3.12.m12.1.2.1.cmml" xref="S3.SS3.p3.12.m12.1.2.1"></times><ci id="S3.SS3.p3.12.m12.1.2.2.cmml" xref="S3.SS3.p3.12.m12.1.2.2">ℳ</ci><apply id="S3.SS3.p3.12.m12.1.1.cmml" xref="S3.SS3.p3.12.m12.1.2.3.2"><ci id="S3.SS3.p3.12.m12.1.1.1.cmml" xref="S3.SS3.p3.12.m12.1.1.1">~</ci><ci id="S3.SS3.p3.12.m12.1.1.2.cmml" xref="S3.SS3.p3.12.m12.1.1.2">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.12.m12.1c">\mathcal{M}(\tilde{q})</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.12.m12.1d">caligraphic_M ( over~ start_ARG italic_q end_ARG )</annotation></semantics></math> as the model’s output.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Knowledge Base Creation</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T1.2.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S4.T1.3.2" style="font-size:90%;">Results for the MMLU datasets described in <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S4.SS1" title="4.1 Task Selection and Rationale ‣ 4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.1</span></a> in terms of log-likelihood accuracy (<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S5.E4" title="4 ‣ 5 Experiments and Results ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Equation</span>&nbsp;<span class="ltx_text ltx_ref_tag">4</span></a>). </span></figcaption>
<br class="ltx_break">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.4.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T1.4.1.1.1"><span class="ltx_text" id="S4.T1.4.1.1.1.1" style="font-size:90%;">Task</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T1.4.1.1.2"><span class="ltx_text" id="S4.T1.4.1.1.2.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.4.1.1.3"><span class="ltx_text" id="S4.T1.4.1.1.3.1" style="font-size:90%;">Base model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.4.1.1.4"><span class="ltx_text" id="S4.T1.4.1.1.4.1" style="font-size:90%;">Base model + RAG</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.4.1.1.5"><span class="ltx_text" id="S4.T1.4.1.1.5.1" style="font-size:90%;">Fine-tuned</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T1.4.1.1.6"><span class="ltx_text" id="S4.T1.4.1.1.6.1" style="font-size:90%;">Fine-tuned + RAG</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.4.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.4.2.1.1" rowspan="3"><span class="ltx_text" id="S4.T1.4.2.1.1.1" style="font-size:90%;">Anatomy (0-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.4.2.1.2"><span class="ltx_text" id="S4.T1.4.2.1.2.1" style="font-size:90%;">Mistral 7B</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.2.1.3"><span class="ltx_text" id="S4.T1.4.2.1.3.1" style="font-size:90%;">0.556</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.2.1.4"><span class="ltx_text ltx_font_bold" id="S4.T1.4.2.1.4.1" style="font-size:90%;">0.681</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.2.1.5"><span class="ltx_text" id="S4.T1.4.2.1.5.1" style="font-size:90%;">0.570</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.2.1.6"><span class="ltx_text" id="S4.T1.4.2.1.6.1" style="font-size:90%;">0.659</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.3.2.1"><span class="ltx_text" id="S4.T1.4.3.2.1.1" style="font-size:90%;">Llama2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.3.2.2"><span class="ltx_text" id="S4.T1.4.3.2.2.1" style="font-size:90%;">0.393</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.3.2.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.3.2.3.1" style="font-size:90%;">0.489</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.3.2.4"><span class="ltx_text" id="S4.T1.4.3.2.4.1" style="font-size:90%;">0.430</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.3.2.5"><span class="ltx_text ltx_font_bold" id="S4.T1.4.3.2.5.1" style="font-size:90%;">0.489</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.4.3.1"><span class="ltx_text" id="S4.T1.4.4.3.1.1" style="font-size:90%;">Orca2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.3.2"><span class="ltx_text" id="S4.T1.4.4.3.2.1" style="font-size:90%;">0.607</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.3.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.3.3.1" style="font-size:90%;">0.637</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.3.4"><span class="ltx_text" id="S4.T1.4.4.3.4.1" style="font-size:90%;">0.600</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.4.3.5"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.3.5.1" style="font-size:90%;">0.637</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.5.4.1" rowspan="3"><span class="ltx_text" id="S4.T1.4.5.4.1.1" style="font-size:90%;">Anatomy (5-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.5.4.2"><span class="ltx_text" id="S4.T1.4.5.4.2.1" style="font-size:90%;">Mistral 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.5.4.3"><span class="ltx_text" id="S4.T1.4.5.4.3.1" style="font-size:90%;">0.600</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.5.4.4"><span class="ltx_text ltx_font_bold" id="S4.T1.4.5.4.4.1" style="font-size:90%;">0.681</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.5.4.5"><span class="ltx_text" id="S4.T1.4.5.4.5.1" style="font-size:90%;">0.622</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.5.4.6"><span class="ltx_text" id="S4.T1.4.5.4.6.1" style="font-size:90%;">0.674</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.6.5.1"><span class="ltx_text" id="S4.T1.4.6.5.1.1" style="font-size:90%;">Llama2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.6.5.2"><span class="ltx_text" id="S4.T1.4.6.5.2.1" style="font-size:90%;">0.467</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.6.5.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.6.5.3.1" style="font-size:90%;">0.563</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.6.5.4"><span class="ltx_text" id="S4.T1.4.6.5.4.1" style="font-size:90%;">0.496</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.6.5.5"><span class="ltx_text" id="S4.T1.4.6.5.5.1" style="font-size:90%;">0.548</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.7.6.1"><span class="ltx_text" id="S4.T1.4.7.6.1.1" style="font-size:90%;">Orca2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.7.6.2"><span class="ltx_text" id="S4.T1.4.7.6.2.1" style="font-size:90%;">0.570</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.7.6.3"><span class="ltx_text" id="S4.T1.4.7.6.3.1" style="font-size:90%;">0.659</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.7.6.4"><span class="ltx_text" id="S4.T1.4.7.6.4.1" style="font-size:90%;">0.593</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.7.6.5"><span class="ltx_text ltx_font_bold" id="S4.T1.4.7.6.5.1" style="font-size:90%;">0.674</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.4.8.7.1" rowspan="3"><span class="ltx_text" id="S4.T1.4.8.7.1.1" style="font-size:90%;">Astronomy (0-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.4.8.7.2"><span class="ltx_text" id="S4.T1.4.8.7.2.1" style="font-size:90%;">Mistral 7B</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.8.7.3"><span class="ltx_text" id="S4.T1.4.8.7.3.1" style="font-size:90%;">0.625</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.8.7.4"><span class="ltx_text" id="S4.T1.4.8.7.4.1" style="font-size:90%;">0.678</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.8.7.5"><span class="ltx_text" id="S4.T1.4.8.7.5.1" style="font-size:90%;">0.651</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.8.7.6"><span class="ltx_text ltx_font_bold" id="S4.T1.4.8.7.6.1" style="font-size:90%;">0.697</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.9.8.1"><span class="ltx_text" id="S4.T1.4.9.8.1.1" style="font-size:90%;">Llama2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.9.8.2"><span class="ltx_text" id="S4.T1.4.9.8.2.1" style="font-size:90%;">0.401</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.9.8.3"><span class="ltx_text" id="S4.T1.4.9.8.3.1" style="font-size:90%;">0.467</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.9.8.4"><span class="ltx_text" id="S4.T1.4.9.8.4.1" style="font-size:90%;">0.487</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.9.8.5"><span class="ltx_text ltx_font_bold" id="S4.T1.4.9.8.5.1" style="font-size:90%;">0.520</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.10.9.1"><span class="ltx_text" id="S4.T1.4.10.9.1.1" style="font-size:90%;">Orca2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.10.9.2"><span class="ltx_text" id="S4.T1.4.10.9.2.1" style="font-size:90%;">0.645</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.10.9.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.10.9.3.1" style="font-size:90%;">0.750</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.10.9.4"><span class="ltx_text" id="S4.T1.4.10.9.4.1" style="font-size:90%;">0.651</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.10.9.5"><span class="ltx_text ltx_font_bold" id="S4.T1.4.10.9.5.1" style="font-size:90%;">0.750</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.11.10.1" rowspan="3"><span class="ltx_text" id="S4.T1.4.11.10.1.1" style="font-size:90%;">Astronomy (5-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.11.10.2"><span class="ltx_text" id="S4.T1.4.11.10.2.1" style="font-size:90%;">Mistral 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.11.10.3"><span class="ltx_text" id="S4.T1.4.11.10.3.1" style="font-size:90%;">0.658</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.11.10.4"><span class="ltx_text ltx_font_bold" id="S4.T1.4.11.10.4.1" style="font-size:90%;">0.724</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.11.10.5"><span class="ltx_text" id="S4.T1.4.11.10.5.1" style="font-size:90%;">0.651</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.11.10.6"><span class="ltx_text" id="S4.T1.4.11.10.6.1" style="font-size:90%;">0.697</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.12.11.1"><span class="ltx_text" id="S4.T1.4.12.11.1.1" style="font-size:90%;">Llama2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.12.11.2"><span class="ltx_text" id="S4.T1.4.12.11.2.1" style="font-size:90%;">0.401</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.12.11.3"><span class="ltx_text" id="S4.T1.4.12.11.3.1" style="font-size:90%;">0.474</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.12.11.4"><span class="ltx_text" id="S4.T1.4.12.11.4.1" style="font-size:90%;">0.447</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.12.11.5"><span class="ltx_text ltx_font_bold" id="S4.T1.4.12.11.5.1" style="font-size:90%;">0.520</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.13.12.1"><span class="ltx_text" id="S4.T1.4.13.12.1.1" style="font-size:90%;">Orca2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.13.12.2"><span class="ltx_text" id="S4.T1.4.13.12.2.1" style="font-size:90%;">0.664</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.13.12.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.13.12.3.1" style="font-size:90%;">0.763</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.13.12.4"><span class="ltx_text" id="S4.T1.4.13.12.4.1" style="font-size:90%;">0.664</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.13.12.5"><span class="ltx_text" id="S4.T1.4.13.12.5.1" style="font-size:90%;">0.743</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.4.14.13.1" rowspan="3"><span class="ltx_text" id="S4.T1.4.14.13.1.1" style="font-size:90%;">College biology (0-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.4.14.13.2"><span class="ltx_text" id="S4.T1.4.14.13.2.1" style="font-size:90%;">Mistral 7B</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.14.13.3"><span class="ltx_text" id="S4.T1.4.14.13.3.1" style="font-size:90%;">0.681</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.14.13.4"><span class="ltx_text" id="S4.T1.4.14.13.4.1" style="font-size:90%;">0.757</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.14.13.5"><span class="ltx_text" id="S4.T1.4.14.13.5.1" style="font-size:90%;">0.701</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.14.13.6"><span class="ltx_text ltx_font_bold" id="S4.T1.4.14.13.6.1" style="font-size:90%;">0.764</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.15.14.1"><span class="ltx_text" id="S4.T1.4.15.14.1.1" style="font-size:90%;">Llama2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.15.14.2"><span class="ltx_text" id="S4.T1.4.15.14.2.1" style="font-size:90%;">0.438</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.15.14.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.15.14.3.1" style="font-size:90%;">0.493</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.15.14.4"><span class="ltx_text" id="S4.T1.4.15.14.4.1" style="font-size:90%;">0.458</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.15.14.5"><span class="ltx_text" id="S4.T1.4.15.14.5.1" style="font-size:90%;">0.465</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.16.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.16.15.1"><span class="ltx_text" id="S4.T1.4.16.15.1.1" style="font-size:90%;">Orca2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.16.15.2"><span class="ltx_text" id="S4.T1.4.16.15.2.1" style="font-size:90%;">0.583</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.16.15.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.16.15.3.1" style="font-size:90%;">0.639</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.16.15.4"><span class="ltx_text" id="S4.T1.4.16.15.4.1" style="font-size:90%;">0.604</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.16.15.5"><span class="ltx_text" id="S4.T1.4.16.15.5.1" style="font-size:90%;">0.632</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.17.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.17.16.1" rowspan="3"><span class="ltx_text" id="S4.T1.4.17.16.1.1" style="font-size:90%;">College biology (5-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.17.16.2"><span class="ltx_text" id="S4.T1.4.17.16.2.1" style="font-size:90%;">Mistral 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.17.16.3"><span class="ltx_text" id="S4.T1.4.17.16.3.1" style="font-size:90%;">0.722</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.17.16.4"><span class="ltx_text ltx_font_bold" id="S4.T1.4.17.16.4.1" style="font-size:90%;">0.778</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.17.16.5"><span class="ltx_text" id="S4.T1.4.17.16.5.1" style="font-size:90%;">0.736</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.17.16.6"><span class="ltx_text" id="S4.T1.4.17.16.6.1" style="font-size:90%;">0.771</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.18.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.18.17.1"><span class="ltx_text" id="S4.T1.4.18.17.1.1" style="font-size:90%;">Llama2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.18.17.2"><span class="ltx_text" id="S4.T1.4.18.17.2.1" style="font-size:90%;">0.451</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.18.17.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.18.17.3.1" style="font-size:90%;">0.521</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.18.17.4"><span class="ltx_text" id="S4.T1.4.18.17.4.1" style="font-size:90%;">0.424</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.18.17.5"><span class="ltx_text" id="S4.T1.4.18.17.5.1" style="font-size:90%;">0.479</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.19.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.19.18.1"><span class="ltx_text" id="S4.T1.4.19.18.1.1" style="font-size:90%;">Orca2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.19.18.2"><span class="ltx_text" id="S4.T1.4.19.18.2.1" style="font-size:90%;">0.604</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.19.18.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.19.18.3.1" style="font-size:90%;">0.660</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.19.18.4"><span class="ltx_text" id="S4.T1.4.19.18.4.1" style="font-size:90%;">0.625</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.19.18.5"><span class="ltx_text" id="S4.T1.4.19.18.5.1" style="font-size:90%;">0.653</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.20.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.4.20.19.1" rowspan="3"><span class="ltx_text" id="S4.T1.4.20.19.1.1" style="font-size:90%;">College chemistry (0-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.4.20.19.2"><span class="ltx_text" id="S4.T1.4.20.19.2.1" style="font-size:90%;">Mistral 7B</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.20.19.3"><span class="ltx_text" id="S4.T1.4.20.19.3.1" style="font-size:90%;">0.470</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.20.19.4"><span class="ltx_text ltx_font_bold" id="S4.T1.4.20.19.4.1" style="font-size:90%;">0.500</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.20.19.5"><span class="ltx_text" id="S4.T1.4.20.19.5.1" style="font-size:90%;">0.490</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.20.19.6"><span class="ltx_text ltx_font_bold" id="S4.T1.4.20.19.6.1" style="font-size:90%;">0.500</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.21.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.21.20.1"><span class="ltx_text" id="S4.T1.4.21.20.1.1" style="font-size:90%;">Llama2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.21.20.2"><span class="ltx_text" id="S4.T1.4.21.20.2.1" style="font-size:90%;">0.310</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.21.20.3"><span class="ltx_text" id="S4.T1.4.21.20.3.1" style="font-size:90%;">0.380</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.21.20.4"><span class="ltx_text" id="S4.T1.4.21.20.4.1" style="font-size:90%;">0.390</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.21.20.5"><span class="ltx_text ltx_font_bold" id="S4.T1.4.21.20.5.1" style="font-size:90%;">0.390</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.22.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.22.21.1"><span class="ltx_text" id="S4.T1.4.22.21.1.1" style="font-size:90%;">Orca2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.22.21.2"><span class="ltx_text" id="S4.T1.4.22.21.2.1" style="font-size:90%;">0.370</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.22.21.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.22.21.3.1" style="font-size:90%;">0.440</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.22.21.4"><span class="ltx_text" id="S4.T1.4.22.21.4.1" style="font-size:90%;">0.370</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.22.21.5"><span class="ltx_text" id="S4.T1.4.22.21.5.1" style="font-size:90%;">0.390</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.23.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.23.22.1" rowspan="3"><span class="ltx_text" id="S4.T1.4.23.22.1.1" style="font-size:90%;">College chemistry (5-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.23.22.2"><span class="ltx_text" id="S4.T1.4.23.22.2.1" style="font-size:90%;">Mistral 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.23.22.3"><span class="ltx_text" id="S4.T1.4.23.22.3.1" style="font-size:90%;">0.470</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.23.22.4"><span class="ltx_text ltx_font_bold" id="S4.T1.4.23.22.4.1" style="font-size:90%;">0.540</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.23.22.5"><span class="ltx_text" id="S4.T1.4.23.22.5.1" style="font-size:90%;">0.500</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.23.22.6"><span class="ltx_text" id="S4.T1.4.23.22.6.1" style="font-size:90%;">0.500</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.24.23">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.24.23.1"><span class="ltx_text" id="S4.T1.4.24.23.1.1" style="font-size:90%;">Llama2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.24.23.2"><span class="ltx_text" id="S4.T1.4.24.23.2.1" style="font-size:90%;">0.370</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.24.23.3"><span class="ltx_text" id="S4.T1.4.24.23.3.1" style="font-size:90%;">0.380</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.24.23.4"><span class="ltx_text" id="S4.T1.4.24.23.4.1" style="font-size:90%;">0.360</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.24.23.5"><span class="ltx_text ltx_font_bold" id="S4.T1.4.24.23.5.1" style="font-size:90%;">0.390</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.25.24">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.25.24.1"><span class="ltx_text" id="S4.T1.4.25.24.1.1" style="font-size:90%;">Orca2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.25.24.2"><span class="ltx_text" id="S4.T1.4.25.24.2.1" style="font-size:90%;">0.430</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.25.24.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.25.24.3.1" style="font-size:90%;">0.470</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.25.24.4"><span class="ltx_text" id="S4.T1.4.25.24.4.1" style="font-size:90%;">0.370</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.25.24.5"><span class="ltx_text" id="S4.T1.4.25.24.5.1" style="font-size:90%;">0.380</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.26.25">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.4.26.25.1" rowspan="3"><span class="ltx_text" id="S4.T1.4.26.25.1.1" style="font-size:90%;">Prehistory (0-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.4.26.25.2"><span class="ltx_text" id="S4.T1.4.26.25.2.1" style="font-size:90%;">Mistral 7B</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.26.25.3"><span class="ltx_text" id="S4.T1.4.26.25.3.1" style="font-size:90%;">0.713</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.26.25.4"><span class="ltx_text ltx_font_bold" id="S4.T1.4.26.25.4.1" style="font-size:90%;">0.750</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.26.25.5"><span class="ltx_text" id="S4.T1.4.26.25.5.1" style="font-size:90%;">0.719</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.26.25.6"><span class="ltx_text" id="S4.T1.4.26.25.6.1" style="font-size:90%;">0.731</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.27.26">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.27.26.1"><span class="ltx_text" id="S4.T1.4.27.26.1.1" style="font-size:90%;">Llama2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.27.26.2"><span class="ltx_text" id="S4.T1.4.27.26.2.1" style="font-size:90%;">0.448</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.27.26.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.27.26.3.1" style="font-size:90%;">0.481</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.27.26.4"><span class="ltx_text" id="S4.T1.4.27.26.4.1" style="font-size:90%;">0.457</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.27.26.5"><span class="ltx_text" id="S4.T1.4.27.26.5.1" style="font-size:90%;">0.478</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.28.27">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.28.27.1"><span class="ltx_text" id="S4.T1.4.28.27.1.1" style="font-size:90%;">Orca2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.28.27.2"><span class="ltx_text" id="S4.T1.4.28.27.2.1" style="font-size:90%;">0.642</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.28.27.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.28.27.3.1" style="font-size:90%;">0.679</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.28.27.4"><span class="ltx_text" id="S4.T1.4.28.27.4.1" style="font-size:90%;">0.673</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.28.27.5"><span class="ltx_text" id="S4.T1.4.28.27.5.1" style="font-size:90%;">0.673</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.29.28">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T1.4.29.28.1" rowspan="3"><span class="ltx_text" id="S4.T1.4.29.28.1.1" style="font-size:90%;">Prehistory (5-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.29.28.2"><span class="ltx_text" id="S4.T1.4.29.28.2.1" style="font-size:90%;">Mistral 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.29.28.3"><span class="ltx_text" id="S4.T1.4.29.28.3.1" style="font-size:90%;">0.722</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.29.28.4"><span class="ltx_text ltx_font_bold" id="S4.T1.4.29.28.4.1" style="font-size:90%;">0.762</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.29.28.5"><span class="ltx_text" id="S4.T1.4.29.28.5.1" style="font-size:90%;">0.725</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.29.28.6"><span class="ltx_text ltx_font_bold" id="S4.T1.4.29.28.6.1" style="font-size:90%;">0.762</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.30.29">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.30.29.1"><span class="ltx_text" id="S4.T1.4.30.29.1.1" style="font-size:90%;">Llama2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T1.4.30.29.2"><span class="ltx_text" id="S4.T1.4.30.29.2.1" style="font-size:90%;">0.515</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.30.29.3"><span class="ltx_text" id="S4.T1.4.30.29.3.1" style="font-size:90%;">0.531</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.30.29.4"><span class="ltx_text" id="S4.T1.4.30.29.4.1" style="font-size:90%;">0.503</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.4.30.29.5"><span class="ltx_text ltx_font_bold" id="S4.T1.4.30.29.5.1" style="font-size:90%;">0.537</span></td>
</tr>
<tr class="ltx_tr" id="S4.T1.4.31.30">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T1.4.31.30.1"><span class="ltx_text" id="S4.T1.4.31.30.1.1" style="font-size:90%;">Orca2 7B</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.31.30.2"><span class="ltx_text" id="S4.T1.4.31.30.2.1" style="font-size:90%;">0.664</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.31.30.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.31.30.3.1" style="font-size:90%;">0.698</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.31.30.4"><span class="ltx_text" id="S4.T1.4.31.30.4.1" style="font-size:90%;">0.667</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.31.30.5"><span class="ltx_text" id="S4.T1.4.31.30.5.1" style="font-size:90%;">0.694</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S4.T2.4.1.1" style="font-size:90%;">Table 2</span>: </span><span class="ltx_text" id="S4.T2.5.2" style="font-size:90%;">Current events results. Models that were fine-tuned on the original dataset are labeled as <span class="ltx_text ltx_font_italic" id="S4.T2.5.2.1">FT-reg</span>, while those trained on the dataset with multiple paraphrases are labeled as <span class="ltx_text ltx_font_italic" id="S4.T2.5.2.2">FT-par</span>.</span></figcaption>
<br class="ltx_break">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.6.1.1">
<th class="ltx_td ltx_th ltx_th_row ltx_border_tt" id="S4.T2.6.1.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.6.1.1.2"><span class="ltx_text" id="S4.T2.6.1.1.2.1" style="font-size:90%;">Base model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.6.1.1.3"><span class="ltx_text" id="S4.T2.6.1.1.3.1" style="font-size:90%;">Base model + RAG</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.6.1.1.4"><span class="ltx_text" id="S4.T2.6.1.1.4.1" style="font-size:90%;">FT-reg</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.6.1.1.5"><span class="ltx_text" id="S4.T2.6.1.1.5.1" style="font-size:90%;">FT-par</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.6.1.1.6"><span class="ltx_text" id="S4.T2.6.1.1.6.1" style="font-size:90%;">FT-reg + RAG</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T2.6.1.1.7"><span class="ltx_text" id="S4.T2.6.1.1.7.1" style="font-size:90%;">FT-par + RAG</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.6.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.6.2.1.1"><span class="ltx_text" id="S4.T2.6.2.1.1.1" style="font-size:90%;">Mistral 7B</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.2.1.2"><span class="ltx_text" id="S4.T2.6.2.1.2.1" style="font-size:90%;">0.481</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.2.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.6.2.1.3.1" style="font-size:90%;">0.875</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.2.1.4"><span class="ltx_text" id="S4.T2.6.2.1.4.1" style="font-size:90%;">0.504</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.2.1.5"><span class="ltx_text" id="S4.T2.6.2.1.5.1" style="font-size:90%;">0.588</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.2.1.6"><span class="ltx_text" id="S4.T2.6.2.1.6.1" style="font-size:90%;">0.810</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.6.2.1.7"><span class="ltx_text" id="S4.T2.6.2.1.7.1" style="font-size:90%;">0.830</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.6.3.2.1"><span class="ltx_text" id="S4.T2.6.3.2.1.1" style="font-size:90%;">Llama2 7B</span></th>
<td class="ltx_td ltx_align_center" id="S4.T2.6.3.2.2"><span class="ltx_text" id="S4.T2.6.3.2.2.1" style="font-size:90%;">0.353</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.3.2.3"><span class="ltx_text ltx_font_bold" id="S4.T2.6.3.2.3.1" style="font-size:90%;">0.585</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.3.2.4"><span class="ltx_text" id="S4.T2.6.3.2.4.1" style="font-size:90%;">0.219</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.3.2.5"><span class="ltx_text" id="S4.T2.6.3.2.5.1" style="font-size:90%;">0.392</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.3.2.6"><span class="ltx_text" id="S4.T2.6.3.2.6.1" style="font-size:90%;">0.326</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.6.3.2.7"><span class="ltx_text" id="S4.T2.6.3.2.7.1" style="font-size:90%;">0.520</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T2.6.4.3.1"><span class="ltx_text" id="S4.T2.6.4.3.1.1" style="font-size:90%;">Orca2 7B</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.4.3.2"><span class="ltx_text" id="S4.T2.6.4.3.2.1" style="font-size:90%;">0.456</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.4.3.3"><span class="ltx_text ltx_font_bold" id="S4.T2.6.4.3.3.1" style="font-size:90%;">0.876</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.4.3.4"><span class="ltx_text" id="S4.T2.6.4.3.4.1" style="font-size:90%;">0.511</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.4.3.5"><span class="ltx_text" id="S4.T2.6.4.3.5.1" style="font-size:90%;">0.566</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.4.3.6"><span class="ltx_text" id="S4.T2.6.4.3.6.1" style="font-size:90%;">0.820</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.6.4.3.7"><span class="ltx_text" id="S4.T2.6.4.3.7.1" style="font-size:90%;">0.826</span></td>
</tr>
</tbody>
</table>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Task Selection and Rationale</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p1.1.1">MMLU Benchmark</span>  To properly evaluate the capabilities of LLMs on knowledge-intensive tasks, we selected four distinct tasks from the Massively Multilingual Language Understanding Evaluation (MMLU) benchmark&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib12" title="">2021</a>)</cite> in the topics of anatomy, astronomy, college biology, college chemistry and prehistory. The chosen tasks were selected based on their emphasis on factual knowledge and the minimal reliance on reasoning. As a heuristic, we opted for tasks where the questions are short and involve no context. In practice we selected four STEM subjects as well as one humanities subject, to ensure the evaluation is not limited to certain fields. Note that prehistory involves questions spanning all non-modern history. This approach aims to enable us to test LLM proficiency in comprehending and manipulating information in isolation from its reasoning processes.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Current Events Task</span>  To further isolate LLMs’ abilities to learn new knowledge, we created a task comprising multiple-choice questions about current events. This task includes multiple-choice questions about events that occurred after the cutoff of the various models’ training data. Specifically, we focused on ”current events” from the USA, in the time span of August-November 2023, that are included in the relevant Wikipedia indexes<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://en.wikipedia.org/wiki/Category:2023_events_in_the_United_States_by_month" title="">https://en.wikipedia.org/wiki/Category:2023_events_in_the_United_States_by_month</a></span></span></span>. This method enables us to mostly guarantee that the models have not been exposed to these facts, thus allowing us to directly test knowledge injection capabilities.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Data Collection and Preprocessing</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">To effectively evaluate the LLMs’ performance on these knowledge-intensive tasks, a comprehensive auxiliary dataset was collected by scraping relevant articles per topic from Wikipedia. The rationale behind selecting Wikipedia as the primary source of knowledge is its broad coverage of relevant topics and its reliability as a repository of crowd-verified knowledge. All articles pertinent to the tasks were retrieved via the official Wikipedia API<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.mediawiki.org/wiki/API:Main_page" title="">https://www.mediawiki.org/wiki/API:Main_page</a></span></span></span> by identifying the relevant central page per topic.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Subsequently, a rigorous cleaning process was utilized to transform the data from raw subsections to clean chunks. This step was done with the ”wikiextractor” tool&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Attardi, <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib1" title="">2015</a>)</cite>. The division into small, clean (e.g., remove HTML, URLs, etc.) chunks was aimed at enhancing the evaluation of the LLMs’ understanding across various knowledge domains and aiding the LLMs in the fine-tuning process.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Current Events Task Creation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">After collecting the relevant chunks from Wikipedia, we created a new multiple-choice dataset with the help of GPT-4&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib30" title="">2023</a>)</cite>. First, we removed any small chunks. For each remaining chunk in the corpus, GPT-4 was instructed to create four highly specific, high-quality multiple-choice questions with only one correct answer. By specific, we mean that the question can be answered without knowledge of which context the question refers to and with minimal ambiguity. Next, GPT-4 was asked to select the two most specific of the four. This was followed by a manual evaluation and verification step. In total, this resulted in 910 new questions.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Paraphrases Generation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">After creating the dataset, we utilized GPT-4 to generate augmentations of the dataset. We instructed GPT-4 to provide paraphrased versions of the input data that fully retain the information while being reworded. Each paraphrasing iteration was done with a different seed to ensure variety.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">We selected 240 chunks at random for each task and created two paraphrases per chunk. These were set aside to be used as validation sets for hyperparameter tuning. For the current events dataset, we created ten paraphrases for each chunk used in the fine-tuning process described in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S6" title="6 The Importance of Repetition ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">6</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments and Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1"><span class="ltx_text ltx_font_bold" id="S5.p1.1.1">Experimental Framework</span>  We used the popular LM-Evaluation-Harness&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib10" title="">2021</a>)</cite> repository to evaluate the performance of LLMs on the selected knowledge-intensive tasks. LM-Evaluation-Harness is a robust benchmarking tool that currently serves as the industry standard for model evaluation and is the basis of the HuggingFace leaderboard<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" title="">https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</a></span></span></span>. Leveraging this platform ensured a standardized evaluation framework and allowed consistent comparison across models, methods, and datasets. More importantly, by using the industry standard for evaluation, we could avoid any differences stemming from prompt engineering and formatting issues and replicate the reported baseline results for each model.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1"><span class="ltx_text ltx_font_bold" id="S5.p2.1.1">Model Selection</span>  We chose three models for inference evaluation: Llama2-7B <cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib45" title="">2023</a>)</cite>, Mistral-7B <cite class="ltx_cite ltx_citemacro_citep">(Jiang et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib15" title="">2023</a>)</cite>, and Orca2-7B <cite class="ltx_cite ltx_citemacro_citep">(Mitra et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib26" title="">2023</a>)</cite>.
The choice of these models was meant to represent the most popular open-source base models and an instruction-tuned model across various baseline capabilities.
Additionally, we selected <span class="ltx_text ltx_font_italic" id="S5.p2.1.2">bge-large-en</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Xiao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib52" title="">2023</a>)</cite> as the embedding model for the RAG component and used FAISS&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Johnson et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib16" title="">2019</a>)</cite> as its vector-store. This embedding model is currently the SOTA of open-source embedding models, according to the HuggingFace MTEB leaderboard<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/spaces/mteb/leaderboard" title="">https://huggingface.co/spaces/mteb/leaderboard</a></span></span></span>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S5.F2">
<p class="ltx_p ltx_align_center ltx_align_center" id="S5.F2.1"><span class="ltx_text" id="S5.F2.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="355" id="S5.F2.1.1.g1" src="extracted/5377658/media/peformance_gain.png" width="598"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F2.3.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S5.F2.4.2" style="font-size:90%;">The relative accuracy gain (as explained in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S5.E5" title="5 ‣ 5 Experiments and Results ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Equation</span>&nbsp;<span class="ltx_text ltx_ref_tag">5</span></a>) for each knowledge-injection method, averaged (columnwise) across all experiments in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S4.T1" title="Table 1 ‣ 4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1"><span class="ltx_text ltx_font_bold" id="S5.p3.1.1">Configuration Variations</span>  Our evaluation included multiple configurations, with a grid-search over them, to allow for more comprehensive benchmarking. 
<br class="ltx_break">Firstly, we compared the baseline and fine-tuned models and their performance with the RAG component. Secondly, we explored the optimal number of text chunks to add to the context in RAG. Specifically, different values of <math alttext="K\in\{0,\ldots,5\}" class="ltx_Math" display="inline" id="S5.p3.1.m1.3"><semantics id="S5.p3.1.m1.3a"><mrow id="S5.p3.1.m1.3.4" xref="S5.p3.1.m1.3.4.cmml"><mi id="S5.p3.1.m1.3.4.2" xref="S5.p3.1.m1.3.4.2.cmml">K</mi><mo id="S5.p3.1.m1.3.4.1" xref="S5.p3.1.m1.3.4.1.cmml">∈</mo><mrow id="S5.p3.1.m1.3.4.3.2" xref="S5.p3.1.m1.3.4.3.1.cmml"><mo id="S5.p3.1.m1.3.4.3.2.1" stretchy="false" xref="S5.p3.1.m1.3.4.3.1.cmml">{</mo><mn id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml">0</mn><mo id="S5.p3.1.m1.3.4.3.2.2" xref="S5.p3.1.m1.3.4.3.1.cmml">,</mo><mi id="S5.p3.1.m1.2.2" mathvariant="normal" xref="S5.p3.1.m1.2.2.cmml">…</mi><mo id="S5.p3.1.m1.3.4.3.2.3" xref="S5.p3.1.m1.3.4.3.1.cmml">,</mo><mn id="S5.p3.1.m1.3.3" xref="S5.p3.1.m1.3.3.cmml">5</mn><mo id="S5.p3.1.m1.3.4.3.2.4" stretchy="false" xref="S5.p3.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.3b"><apply id="S5.p3.1.m1.3.4.cmml" xref="S5.p3.1.m1.3.4"><in id="S5.p3.1.m1.3.4.1.cmml" xref="S5.p3.1.m1.3.4.1"></in><ci id="S5.p3.1.m1.3.4.2.cmml" xref="S5.p3.1.m1.3.4.2">𝐾</ci><set id="S5.p3.1.m1.3.4.3.1.cmml" xref="S5.p3.1.m1.3.4.3.2"><cn id="S5.p3.1.m1.1.1.cmml" type="integer" xref="S5.p3.1.m1.1.1">0</cn><ci id="S5.p3.1.m1.2.2.cmml" xref="S5.p3.1.m1.2.2">…</ci><cn id="S5.p3.1.m1.3.3.cmml" type="integer" xref="S5.p3.1.m1.3.3">5</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.3c">K\in\{0,\ldots,5\}</annotation><annotation encoding="application/x-llamapun" id="S5.p3.1.m1.3d">italic_K ∈ { 0 , … , 5 }</annotation></semantics></math> were employed to analyze the impact on model performance. Finally, we explored 5-shot performance vs. 0-shot.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p4">
<p class="ltx_p" id="S5.p4.5"><span class="ltx_text ltx_font_bold" id="S5.p4.5.1">Training Setup</span>  We trained all of the models using the unsupervised training procedure described in <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S3.SS2" title="3.2 Fine-Tuning ‣ 3 Injecting Knowledge to Language Models ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">3.2</span></a>. For each dataset, we
divided the auxiliary knowledge base into equal chunks of size <math alttext="256" class="ltx_Math" display="inline" id="S5.p4.1.m1.1"><semantics id="S5.p4.1.m1.1a"><mn id="S5.p4.1.m1.1.1" xref="S5.p4.1.m1.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="S5.p4.1.m1.1b"><cn id="S5.p4.1.m1.1.1.cmml" type="integer" xref="S5.p4.1.m1.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.1.m1.1c">256</annotation><annotation encoding="application/x-llamapun" id="S5.p4.1.m1.1d">256</annotation></semantics></math> by concatenating or splitting the original chunks based on their length. We also added two special tokens, <math alttext="<" class="ltx_Math" display="inline" id="S5.p4.2.m2.1"><semantics id="S5.p4.2.m2.1a"><mo id="S5.p4.2.m2.1.1" xref="S5.p4.2.m2.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.p4.2.m2.1b"><lt id="S5.p4.2.m2.1.1.cmml" xref="S5.p4.2.m2.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.2.m2.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S5.p4.2.m2.1d">&lt;</annotation></semantics></math>BOS<math alttext=">" class="ltx_Math" display="inline" id="S5.p4.3.m3.1"><semantics id="S5.p4.3.m3.1a"><mo id="S5.p4.3.m3.1.1" xref="S5.p4.3.m3.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S5.p4.3.m3.1b"><gt id="S5.p4.3.m3.1.1.cmml" xref="S5.p4.3.m3.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.3.m3.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S5.p4.3.m3.1d">&gt;</annotation></semantics></math> and <math alttext="<" class="ltx_Math" display="inline" id="S5.p4.4.m4.1"><semantics id="S5.p4.4.m4.1a"><mo id="S5.p4.4.m4.1.1" xref="S5.p4.4.m4.1.1.cmml">&lt;</mo><annotation-xml encoding="MathML-Content" id="S5.p4.4.m4.1b"><lt id="S5.p4.4.m4.1.1.cmml" xref="S5.p4.4.m4.1.1"></lt></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.4.m4.1c">&lt;</annotation><annotation encoding="application/x-llamapun" id="S5.p4.4.m4.1d">&lt;</annotation></semantics></math>EOS<math alttext=">" class="ltx_Math" display="inline" id="S5.p4.5.m5.1"><semantics id="S5.p4.5.m5.1a"><mo id="S5.p4.5.m5.1.1" xref="S5.p4.5.m5.1.1.cmml">&gt;</mo><annotation-xml encoding="MathML-Content" id="S5.p4.5.m5.1b"><gt id="S5.p4.5.m5.1.1.cmml" xref="S5.p4.5.m5.1.1"></gt></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.5.m5.1c">&gt;</annotation><annotation encoding="application/x-llamapun" id="S5.p4.5.m5.1d">&gt;</annotation></semantics></math>, to demarcate the original chunks’ beginnings and ends to preserve the documents’ structure.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p5">
<p class="ltx_p" id="S5.p5.2">The models were trained using learning rates between <math alttext="1\times{10}^{-6}" class="ltx_Math" display="inline" id="S5.p5.1.m1.1"><semantics id="S5.p5.1.m1.1a"><mrow id="S5.p5.1.m1.1.1" xref="S5.p5.1.m1.1.1.cmml"><mn id="S5.p5.1.m1.1.1.2" xref="S5.p5.1.m1.1.1.2.cmml">1</mn><mo id="S5.p5.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.p5.1.m1.1.1.1.cmml">×</mo><msup id="S5.p5.1.m1.1.1.3" xref="S5.p5.1.m1.1.1.3.cmml"><mn id="S5.p5.1.m1.1.1.3.2" xref="S5.p5.1.m1.1.1.3.2.cmml">10</mn><mrow id="S5.p5.1.m1.1.1.3.3" xref="S5.p5.1.m1.1.1.3.3.cmml"><mo id="S5.p5.1.m1.1.1.3.3a" xref="S5.p5.1.m1.1.1.3.3.cmml">−</mo><mn id="S5.p5.1.m1.1.1.3.3.2" xref="S5.p5.1.m1.1.1.3.3.2.cmml">6</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.p5.1.m1.1b"><apply id="S5.p5.1.m1.1.1.cmml" xref="S5.p5.1.m1.1.1"><times id="S5.p5.1.m1.1.1.1.cmml" xref="S5.p5.1.m1.1.1.1"></times><cn id="S5.p5.1.m1.1.1.2.cmml" type="integer" xref="S5.p5.1.m1.1.1.2">1</cn><apply id="S5.p5.1.m1.1.1.3.cmml" xref="S5.p5.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.p5.1.m1.1.1.3.1.cmml" xref="S5.p5.1.m1.1.1.3">superscript</csymbol><cn id="S5.p5.1.m1.1.1.3.2.cmml" type="integer" xref="S5.p5.1.m1.1.1.3.2">10</cn><apply id="S5.p5.1.m1.1.1.3.3.cmml" xref="S5.p5.1.m1.1.1.3.3"><minus id="S5.p5.1.m1.1.1.3.3.1.cmml" xref="S5.p5.1.m1.1.1.3.3"></minus><cn id="S5.p5.1.m1.1.1.3.3.2.cmml" type="integer" xref="S5.p5.1.m1.1.1.3.3.2">6</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p5.1.m1.1c">1\times{10}^{-6}</annotation><annotation encoding="application/x-llamapun" id="S5.p5.1.m1.1d">1 × 10 start_POSTSUPERSCRIPT - 6 end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="5\times{10}^{-5}" class="ltx_Math" display="inline" id="S5.p5.2.m2.1"><semantics id="S5.p5.2.m2.1a"><mrow id="S5.p5.2.m2.1.1" xref="S5.p5.2.m2.1.1.cmml"><mn id="S5.p5.2.m2.1.1.2" xref="S5.p5.2.m2.1.1.2.cmml">5</mn><mo id="S5.p5.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S5.p5.2.m2.1.1.1.cmml">×</mo><msup id="S5.p5.2.m2.1.1.3" xref="S5.p5.2.m2.1.1.3.cmml"><mn id="S5.p5.2.m2.1.1.3.2" xref="S5.p5.2.m2.1.1.3.2.cmml">10</mn><mrow id="S5.p5.2.m2.1.1.3.3" xref="S5.p5.2.m2.1.1.3.3.cmml"><mo id="S5.p5.2.m2.1.1.3.3a" xref="S5.p5.2.m2.1.1.3.3.cmml">−</mo><mn id="S5.p5.2.m2.1.1.3.3.2" xref="S5.p5.2.m2.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.p5.2.m2.1b"><apply id="S5.p5.2.m2.1.1.cmml" xref="S5.p5.2.m2.1.1"><times id="S5.p5.2.m2.1.1.1.cmml" xref="S5.p5.2.m2.1.1.1"></times><cn id="S5.p5.2.m2.1.1.2.cmml" type="integer" xref="S5.p5.2.m2.1.1.2">5</cn><apply id="S5.p5.2.m2.1.1.3.cmml" xref="S5.p5.2.m2.1.1.3"><csymbol cd="ambiguous" id="S5.p5.2.m2.1.1.3.1.cmml" xref="S5.p5.2.m2.1.1.3">superscript</csymbol><cn id="S5.p5.2.m2.1.1.3.2.cmml" type="integer" xref="S5.p5.2.m2.1.1.3.2">10</cn><apply id="S5.p5.2.m2.1.1.3.3.cmml" xref="S5.p5.2.m2.1.1.3.3"><minus id="S5.p5.2.m2.1.1.3.3.1.cmml" xref="S5.p5.2.m2.1.1.3.3"></minus><cn id="S5.p5.2.m2.1.1.3.3.2.cmml" type="integer" xref="S5.p5.2.m2.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p5.2.m2.1c">5\times{10}^{-5}</annotation><annotation encoding="application/x-llamapun" id="S5.p5.2.m2.1d">5 × 10 start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math>, which were found through a hyperparameter search. All models were trained on 4 NVIDIA A-100 GPUs for a maximum of 5 epochs and a batch size of 64.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p6">
<p class="ltx_p" id="S5.p6.1"><span class="ltx_text ltx_font_bold" id="S5.p6.1.1">Evaluation method</span>  All evaluations were done by appending each of the multiple-choice options to the question, followed by passing the concatenation through the model to get a log probability score per option. The highest score was interpreted as the model’s choice and used for accuracy calculation. More formally, this means that in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S2.E1" title="1 ‣ 2 Background ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Equation</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a> we say that <math alttext="\mathcal{M}(q_{n})=c_{n}" class="ltx_Math" display="inline" id="S5.p6.1.m1.1"><semantics id="S5.p6.1.m1.1a"><mrow id="S5.p6.1.m1.1.1" xref="S5.p6.1.m1.1.1.cmml"><mrow id="S5.p6.1.m1.1.1.1" xref="S5.p6.1.m1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.p6.1.m1.1.1.1.3" xref="S5.p6.1.m1.1.1.1.3.cmml">ℳ</mi><mo id="S5.p6.1.m1.1.1.1.2" xref="S5.p6.1.m1.1.1.1.2.cmml">⁢</mo><mrow id="S5.p6.1.m1.1.1.1.1.1" xref="S5.p6.1.m1.1.1.1.1.1.1.cmml"><mo id="S5.p6.1.m1.1.1.1.1.1.2" stretchy="false" xref="S5.p6.1.m1.1.1.1.1.1.1.cmml">(</mo><msub id="S5.p6.1.m1.1.1.1.1.1.1" xref="S5.p6.1.m1.1.1.1.1.1.1.cmml"><mi id="S5.p6.1.m1.1.1.1.1.1.1.2" xref="S5.p6.1.m1.1.1.1.1.1.1.2.cmml">q</mi><mi id="S5.p6.1.m1.1.1.1.1.1.1.3" xref="S5.p6.1.m1.1.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S5.p6.1.m1.1.1.1.1.1.3" stretchy="false" xref="S5.p6.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.p6.1.m1.1.1.2" xref="S5.p6.1.m1.1.1.2.cmml">=</mo><msub id="S5.p6.1.m1.1.1.3" xref="S5.p6.1.m1.1.1.3.cmml"><mi id="S5.p6.1.m1.1.1.3.2" xref="S5.p6.1.m1.1.1.3.2.cmml">c</mi><mi id="S5.p6.1.m1.1.1.3.3" xref="S5.p6.1.m1.1.1.3.3.cmml">n</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S5.p6.1.m1.1b"><apply id="S5.p6.1.m1.1.1.cmml" xref="S5.p6.1.m1.1.1"><eq id="S5.p6.1.m1.1.1.2.cmml" xref="S5.p6.1.m1.1.1.2"></eq><apply id="S5.p6.1.m1.1.1.1.cmml" xref="S5.p6.1.m1.1.1.1"><times id="S5.p6.1.m1.1.1.1.2.cmml" xref="S5.p6.1.m1.1.1.1.2"></times><ci id="S5.p6.1.m1.1.1.1.3.cmml" xref="S5.p6.1.m1.1.1.1.3">ℳ</ci><apply id="S5.p6.1.m1.1.1.1.1.1.1.cmml" xref="S5.p6.1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.p6.1.m1.1.1.1.1.1.1.1.cmml" xref="S5.p6.1.m1.1.1.1.1.1">subscript</csymbol><ci id="S5.p6.1.m1.1.1.1.1.1.1.2.cmml" xref="S5.p6.1.m1.1.1.1.1.1.1.2">𝑞</ci><ci id="S5.p6.1.m1.1.1.1.1.1.1.3.cmml" xref="S5.p6.1.m1.1.1.1.1.1.1.3">𝑛</ci></apply></apply><apply id="S5.p6.1.m1.1.1.3.cmml" xref="S5.p6.1.m1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.1.m1.1.1.3.1.cmml" xref="S5.p6.1.m1.1.1.3">subscript</csymbol><ci id="S5.p6.1.m1.1.1.3.2.cmml" xref="S5.p6.1.m1.1.1.3.2">𝑐</ci><ci id="S5.p6.1.m1.1.1.3.3.cmml" xref="S5.p6.1.m1.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.1.m1.1c">\mathcal{M}(q_{n})=c_{n}</annotation><annotation encoding="application/x-llamapun" id="S5.p6.1.m1.1d">caligraphic_M ( italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) = italic_c start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> if:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S5.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="c_{n}=\operatorname*{arg\,max}_{l}\{\mathcal{M}(q_{n}\|a^{1}_{n}),\ldots,%
\mathcal{M}(q_{n}\|a^{L}_{n})\}," class="ltx_Math" display="block" id="S5.E4.m1.2"><semantics id="S5.E4.m1.2a"><mrow id="S5.E4.m1.2.2.1" xref="S5.E4.m1.2.2.1.1.cmml"><mrow id="S5.E4.m1.2.2.1.1" xref="S5.E4.m1.2.2.1.1.cmml"><msub id="S5.E4.m1.2.2.1.1.5" xref="S5.E4.m1.2.2.1.1.5.cmml"><mi id="S5.E4.m1.2.2.1.1.5.2" xref="S5.E4.m1.2.2.1.1.5.2.cmml">c</mi><mi id="S5.E4.m1.2.2.1.1.5.3" xref="S5.E4.m1.2.2.1.1.5.3.cmml">n</mi></msub><mo id="S5.E4.m1.2.2.1.1.4" xref="S5.E4.m1.2.2.1.1.4.cmml">=</mo><mrow id="S5.E4.m1.2.2.1.1.3.3" xref="S5.E4.m1.2.2.1.1.3.4.cmml"><munder id="S5.E4.m1.2.2.1.1.1.1.1" xref="S5.E4.m1.2.2.1.1.1.1.1.cmml"><mrow id="S5.E4.m1.2.2.1.1.1.1.1.2" xref="S5.E4.m1.2.2.1.1.1.1.1.2.cmml"><mi id="S5.E4.m1.2.2.1.1.1.1.1.2.2" xref="S5.E4.m1.2.2.1.1.1.1.1.2.2.cmml">arg</mi><mo id="S5.E4.m1.2.2.1.1.1.1.1.2.1" lspace="0.170em" xref="S5.E4.m1.2.2.1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S5.E4.m1.2.2.1.1.1.1.1.2.3" xref="S5.E4.m1.2.2.1.1.1.1.1.2.3.cmml">max</mi></mrow><mi id="S5.E4.m1.2.2.1.1.1.1.1.3" xref="S5.E4.m1.2.2.1.1.1.1.1.3.cmml">l</mi></munder><mo id="S5.E4.m1.2.2.1.1.3.3a" xref="S5.E4.m1.2.2.1.1.3.4.cmml">⁡</mo><mrow id="S5.E4.m1.2.2.1.1.3.3.3" xref="S5.E4.m1.2.2.1.1.3.4.cmml"><mo id="S5.E4.m1.2.2.1.1.3.3.3.3" stretchy="false" xref="S5.E4.m1.2.2.1.1.3.4.cmml">{</mo><mrow id="S5.E4.m1.2.2.1.1.2.2.2.1" xref="S5.E4.m1.2.2.1.1.2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E4.m1.2.2.1.1.2.2.2.1.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.3.cmml">ℳ</mi><mo id="S5.E4.m1.2.2.1.1.2.2.2.1.2" xref="S5.E4.m1.2.2.1.1.2.2.2.1.2.cmml">⁢</mo><mrow id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml"><mo id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.2" stretchy="false" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml"><msub id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.cmml"><mi id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.2" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.2.cmml">q</mi><mi id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.3.cmml">n</mi></msub><mo id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.1" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.1.cmml">∥</mo><msubsup id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.cmml"><mi id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.2" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.2.cmml">a</mi><mi id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.3.cmml">n</mi><mn id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.3" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.3.cmml">1</mn></msubsup></mrow><mo id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.3" stretchy="false" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.E4.m1.2.2.1.1.3.3.3.4" xref="S5.E4.m1.2.2.1.1.3.4.cmml">,</mo><mi id="S5.E4.m1.1.1" mathvariant="normal" xref="S5.E4.m1.1.1.cmml">…</mi><mo id="S5.E4.m1.2.2.1.1.3.3.3.5" xref="S5.E4.m1.2.2.1.1.3.4.cmml">,</mo><mrow id="S5.E4.m1.2.2.1.1.3.3.3.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E4.m1.2.2.1.1.3.3.3.2.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.3.cmml">ℳ</mi><mo id="S5.E4.m1.2.2.1.1.3.3.3.2.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.2.cmml">⁢</mo><mrow id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml"><mo id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.2" stretchy="false" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml">(</mo><mrow id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml"><msub id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.cmml"><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.2.cmml">q</mi><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.3.cmml">n</mi></msub><mo id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.1" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.1.cmml">∥</mo><msubsup id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.cmml"><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.2" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.2.cmml">a</mi><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.3.cmml">n</mi><mi id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.3" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.3.cmml">L</mi></msubsup></mrow><mo id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.3" stretchy="false" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.E4.m1.2.2.1.1.3.3.3.6" stretchy="false" xref="S5.E4.m1.2.2.1.1.3.4.cmml">}</mo></mrow></mrow></mrow><mo id="S5.E4.m1.2.2.1.2" xref="S5.E4.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E4.m1.2b"><apply id="S5.E4.m1.2.2.1.1.cmml" xref="S5.E4.m1.2.2.1"><eq id="S5.E4.m1.2.2.1.1.4.cmml" xref="S5.E4.m1.2.2.1.1.4"></eq><apply id="S5.E4.m1.2.2.1.1.5.cmml" xref="S5.E4.m1.2.2.1.1.5"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.5.1.cmml" xref="S5.E4.m1.2.2.1.1.5">subscript</csymbol><ci id="S5.E4.m1.2.2.1.1.5.2.cmml" xref="S5.E4.m1.2.2.1.1.5.2">𝑐</ci><ci id="S5.E4.m1.2.2.1.1.5.3.cmml" xref="S5.E4.m1.2.2.1.1.5.3">𝑛</ci></apply><apply id="S5.E4.m1.2.2.1.1.3.4.cmml" xref="S5.E4.m1.2.2.1.1.3.3"><apply id="S5.E4.m1.2.2.1.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1">subscript</csymbol><apply id="S5.E4.m1.2.2.1.1.1.1.1.2.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.2"><times id="S5.E4.m1.2.2.1.1.1.1.1.2.1.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.2.1"></times><ci id="S5.E4.m1.2.2.1.1.1.1.1.2.2.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.2.2">arg</ci><ci id="S5.E4.m1.2.2.1.1.1.1.1.2.3.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.2.3">max</ci></apply><ci id="S5.E4.m1.2.2.1.1.1.1.1.3.cmml" xref="S5.E4.m1.2.2.1.1.1.1.1.3">𝑙</ci></apply><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1"><times id="S5.E4.m1.2.2.1.1.2.2.2.1.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.2"></times><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.3.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.3">ℳ</ci><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1"><csymbol cd="latexml" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.1">conditional</csymbol><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.2">𝑞</ci><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.3.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.2.3">𝑛</ci></apply><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3">subscript</csymbol><apply id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.1.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3">superscript</csymbol><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.2.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.2">𝑎</ci><cn id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.3.cmml" type="integer" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.2.3">1</cn></apply><ci id="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.3.cmml" xref="S5.E4.m1.2.2.1.1.2.2.2.1.1.1.1.3.3">𝑛</ci></apply></apply></apply><ci id="S5.E4.m1.1.1.cmml" xref="S5.E4.m1.1.1">…</ci><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2"><times id="S5.E4.m1.2.2.1.1.3.3.3.2.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.2"></times><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.3">ℳ</ci><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1"><csymbol cd="latexml" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.1">conditional</csymbol><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2">subscript</csymbol><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.2">𝑞</ci><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.2.3">𝑛</ci></apply><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3">subscript</csymbol><apply id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.1.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3">superscript</csymbol><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.2.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.2">𝑎</ci><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.2.3">𝐿</ci></apply><ci id="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.3.cmml" xref="S5.E4.m1.2.2.1.1.3.3.3.2.1.1.1.3.3">𝑛</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E4.m1.2c">c_{n}=\operatorname*{arg\,max}_{l}\{\mathcal{M}(q_{n}\|a^{1}_{n}),\ldots,%
\mathcal{M}(q_{n}\|a^{L}_{n})\},</annotation><annotation encoding="application/x-llamapun" id="S5.E4.m1.2d">italic_c start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT = start_OPERATOR roman_arg roman_max end_OPERATOR start_POSTSUBSCRIPT italic_l end_POSTSUBSCRIPT { caligraphic_M ( italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ∥ italic_a start_POSTSUPERSCRIPT 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) , … , caligraphic_M ( italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ∥ italic_a start_POSTSUPERSCRIPT italic_L end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) } ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.p6.2">where <math alttext="\mathcal{M}(q_{n}\|a^{l}_{n})=\log P_{\mathcal{M}}(q_{n}\|a^{l}_{n})" class="ltx_Math" display="inline" id="S5.p6.2.m1.2"><semantics id="S5.p6.2.m1.2a"><mrow id="S5.p6.2.m1.2.2" xref="S5.p6.2.m1.2.2.cmml"><mrow id="S5.p6.2.m1.1.1.1" xref="S5.p6.2.m1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.p6.2.m1.1.1.1.3" xref="S5.p6.2.m1.1.1.1.3.cmml">ℳ</mi><mo id="S5.p6.2.m1.1.1.1.2" xref="S5.p6.2.m1.1.1.1.2.cmml">⁢</mo><mrow id="S5.p6.2.m1.1.1.1.1.1" xref="S5.p6.2.m1.1.1.1.1.1.1.cmml"><mo id="S5.p6.2.m1.1.1.1.1.1.2" stretchy="false" xref="S5.p6.2.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S5.p6.2.m1.1.1.1.1.1.1" xref="S5.p6.2.m1.1.1.1.1.1.1.cmml"><msub id="S5.p6.2.m1.1.1.1.1.1.1.2" xref="S5.p6.2.m1.1.1.1.1.1.1.2.cmml"><mi id="S5.p6.2.m1.1.1.1.1.1.1.2.2" xref="S5.p6.2.m1.1.1.1.1.1.1.2.2.cmml">q</mi><mi id="S5.p6.2.m1.1.1.1.1.1.1.2.3" xref="S5.p6.2.m1.1.1.1.1.1.1.2.3.cmml">n</mi></msub><mo id="S5.p6.2.m1.1.1.1.1.1.1.1" xref="S5.p6.2.m1.1.1.1.1.1.1.1.cmml">∥</mo><msubsup id="S5.p6.2.m1.1.1.1.1.1.1.3" xref="S5.p6.2.m1.1.1.1.1.1.1.3.cmml"><mi id="S5.p6.2.m1.1.1.1.1.1.1.3.2.2" xref="S5.p6.2.m1.1.1.1.1.1.1.3.2.2.cmml">a</mi><mi id="S5.p6.2.m1.1.1.1.1.1.1.3.3" xref="S5.p6.2.m1.1.1.1.1.1.1.3.3.cmml">n</mi><mi id="S5.p6.2.m1.1.1.1.1.1.1.3.2.3" xref="S5.p6.2.m1.1.1.1.1.1.1.3.2.3.cmml">l</mi></msubsup></mrow><mo id="S5.p6.2.m1.1.1.1.1.1.3" stretchy="false" xref="S5.p6.2.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S5.p6.2.m1.2.2.3" xref="S5.p6.2.m1.2.2.3.cmml">=</mo><mrow id="S5.p6.2.m1.2.2.2" xref="S5.p6.2.m1.2.2.2.cmml"><mrow id="S5.p6.2.m1.2.2.2.3" xref="S5.p6.2.m1.2.2.2.3.cmml"><mi id="S5.p6.2.m1.2.2.2.3.1" xref="S5.p6.2.m1.2.2.2.3.1.cmml">log</mi><mo id="S5.p6.2.m1.2.2.2.3a" lspace="0.167em" xref="S5.p6.2.m1.2.2.2.3.cmml">⁡</mo><msub id="S5.p6.2.m1.2.2.2.3.2" xref="S5.p6.2.m1.2.2.2.3.2.cmml"><mi id="S5.p6.2.m1.2.2.2.3.2.2" xref="S5.p6.2.m1.2.2.2.3.2.2.cmml">P</mi><mi class="ltx_font_mathcaligraphic" id="S5.p6.2.m1.2.2.2.3.2.3" xref="S5.p6.2.m1.2.2.2.3.2.3.cmml">ℳ</mi></msub></mrow><mo id="S5.p6.2.m1.2.2.2.2" xref="S5.p6.2.m1.2.2.2.2.cmml">⁢</mo><mrow id="S5.p6.2.m1.2.2.2.1.1" xref="S5.p6.2.m1.2.2.2.1.1.1.cmml"><mo id="S5.p6.2.m1.2.2.2.1.1.2" stretchy="false" xref="S5.p6.2.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="S5.p6.2.m1.2.2.2.1.1.1" xref="S5.p6.2.m1.2.2.2.1.1.1.cmml"><msub id="S5.p6.2.m1.2.2.2.1.1.1.2" xref="S5.p6.2.m1.2.2.2.1.1.1.2.cmml"><mi id="S5.p6.2.m1.2.2.2.1.1.1.2.2" xref="S5.p6.2.m1.2.2.2.1.1.1.2.2.cmml">q</mi><mi id="S5.p6.2.m1.2.2.2.1.1.1.2.3" xref="S5.p6.2.m1.2.2.2.1.1.1.2.3.cmml">n</mi></msub><mo id="S5.p6.2.m1.2.2.2.1.1.1.1" xref="S5.p6.2.m1.2.2.2.1.1.1.1.cmml">∥</mo><msubsup id="S5.p6.2.m1.2.2.2.1.1.1.3" xref="S5.p6.2.m1.2.2.2.1.1.1.3.cmml"><mi id="S5.p6.2.m1.2.2.2.1.1.1.3.2.2" xref="S5.p6.2.m1.2.2.2.1.1.1.3.2.2.cmml">a</mi><mi id="S5.p6.2.m1.2.2.2.1.1.1.3.3" xref="S5.p6.2.m1.2.2.2.1.1.1.3.3.cmml">n</mi><mi id="S5.p6.2.m1.2.2.2.1.1.1.3.2.3" xref="S5.p6.2.m1.2.2.2.1.1.1.3.2.3.cmml">l</mi></msubsup></mrow><mo id="S5.p6.2.m1.2.2.2.1.1.3" stretchy="false" xref="S5.p6.2.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p6.2.m1.2b"><apply id="S5.p6.2.m1.2.2.cmml" xref="S5.p6.2.m1.2.2"><eq id="S5.p6.2.m1.2.2.3.cmml" xref="S5.p6.2.m1.2.2.3"></eq><apply id="S5.p6.2.m1.1.1.1.cmml" xref="S5.p6.2.m1.1.1.1"><times id="S5.p6.2.m1.1.1.1.2.cmml" xref="S5.p6.2.m1.1.1.1.2"></times><ci id="S5.p6.2.m1.1.1.1.3.cmml" xref="S5.p6.2.m1.1.1.1.3">ℳ</ci><apply id="S5.p6.2.m1.1.1.1.1.1.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1"><csymbol cd="latexml" id="S5.p6.2.m1.1.1.1.1.1.1.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S5.p6.2.m1.1.1.1.1.1.1.2.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.p6.2.m1.1.1.1.1.1.1.2.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S5.p6.2.m1.1.1.1.1.1.1.2.2.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.2.2">𝑞</ci><ci id="S5.p6.2.m1.1.1.1.1.1.1.2.3.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.2.3">𝑛</ci></apply><apply id="S5.p6.2.m1.1.1.1.1.1.1.3.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.2.m1.1.1.1.1.1.1.3.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3">subscript</csymbol><apply id="S5.p6.2.m1.1.1.1.1.1.1.3.2.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.2.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S5.p6.2.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3.2.2">𝑎</ci><ci id="S5.p6.2.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3.2.3">𝑙</ci></apply><ci id="S5.p6.2.m1.1.1.1.1.1.1.3.3.cmml" xref="S5.p6.2.m1.1.1.1.1.1.1.3.3">𝑛</ci></apply></apply></apply><apply id="S5.p6.2.m1.2.2.2.cmml" xref="S5.p6.2.m1.2.2.2"><times id="S5.p6.2.m1.2.2.2.2.cmml" xref="S5.p6.2.m1.2.2.2.2"></times><apply id="S5.p6.2.m1.2.2.2.3.cmml" xref="S5.p6.2.m1.2.2.2.3"><log id="S5.p6.2.m1.2.2.2.3.1.cmml" xref="S5.p6.2.m1.2.2.2.3.1"></log><apply id="S5.p6.2.m1.2.2.2.3.2.cmml" xref="S5.p6.2.m1.2.2.2.3.2"><csymbol cd="ambiguous" id="S5.p6.2.m1.2.2.2.3.2.1.cmml" xref="S5.p6.2.m1.2.2.2.3.2">subscript</csymbol><ci id="S5.p6.2.m1.2.2.2.3.2.2.cmml" xref="S5.p6.2.m1.2.2.2.3.2.2">𝑃</ci><ci id="S5.p6.2.m1.2.2.2.3.2.3.cmml" xref="S5.p6.2.m1.2.2.2.3.2.3">ℳ</ci></apply></apply><apply id="S5.p6.2.m1.2.2.2.1.1.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1"><csymbol cd="latexml" id="S5.p6.2.m1.2.2.2.1.1.1.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.1">conditional</csymbol><apply id="S5.p6.2.m1.2.2.2.1.1.1.2.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="S5.p6.2.m1.2.2.2.1.1.1.2.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.2">subscript</csymbol><ci id="S5.p6.2.m1.2.2.2.1.1.1.2.2.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.2.2">𝑞</ci><ci id="S5.p6.2.m1.2.2.2.1.1.1.2.3.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.2.3">𝑛</ci></apply><apply id="S5.p6.2.m1.2.2.2.1.1.1.3.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.2.m1.2.2.2.1.1.1.3.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3">subscript</csymbol><apply id="S5.p6.2.m1.2.2.2.1.1.1.3.2.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S5.p6.2.m1.2.2.2.1.1.1.3.2.1.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3">superscript</csymbol><ci id="S5.p6.2.m1.2.2.2.1.1.1.3.2.2.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3.2.2">𝑎</ci><ci id="S5.p6.2.m1.2.2.2.1.1.1.3.2.3.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3.2.3">𝑙</ci></apply><ci id="S5.p6.2.m1.2.2.2.1.1.1.3.3.cmml" xref="S5.p6.2.m1.2.2.2.1.1.1.3.3">𝑛</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.2.m1.2c">\mathcal{M}(q_{n}\|a^{l}_{n})=\log P_{\mathcal{M}}(q_{n}\|a^{l}_{n})</annotation><annotation encoding="application/x-llamapun" id="S5.p6.2.m1.2d">caligraphic_M ( italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ∥ italic_a start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ) = roman_log italic_P start_POSTSUBSCRIPT caligraphic_M end_POSTSUBSCRIPT ( italic_q start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT ∥ italic_a start_POSTSUPERSCRIPT italic_l end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT )</annotation></semantics></math>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p7">
<p class="ltx_p" id="S5.p7.3"><span class="ltx_text ltx_font_bold" id="S5.p7.3.1">MMLU Results</span>  For each task and model, we compared four approaches: using just the base model, RAG, FT, and finally combining FT and RAG by using the fine-tuned model as the generator. Furthermore, we tested the MMLU tasks using both 0-shot and 5-shot scenarios. The full results are shown in &nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S4.T1" title="Table 1 ‣ 4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">1</span></a>. An aggregation of the relative accuracy gain, i.e.,</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<table class="ltx_equation ltx_eqn_table" id="S5.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="(\mathcal{L}_{\mathcal{M^{\prime}},\mathcal{Q}}-\mathcal{L}_{\mathcal{M},%
\mathcal{Q}})/{\mathcal{L}_{\mathcal{M},\mathcal{Q}}}," class="ltx_Math" display="block" id="S5.E5.m1.7"><semantics id="S5.E5.m1.7a"><mrow id="S5.E5.m1.7.7.1" xref="S5.E5.m1.7.7.1.1.cmml"><mrow id="S5.E5.m1.7.7.1.1" xref="S5.E5.m1.7.7.1.1.cmml"><mrow id="S5.E5.m1.7.7.1.1.1.1" xref="S5.E5.m1.7.7.1.1.1.1.1.cmml"><mo id="S5.E5.m1.7.7.1.1.1.1.2" stretchy="false" xref="S5.E5.m1.7.7.1.1.1.1.1.cmml">(</mo><mrow id="S5.E5.m1.7.7.1.1.1.1.1" xref="S5.E5.m1.7.7.1.1.1.1.1.cmml"><msub id="S5.E5.m1.7.7.1.1.1.1.1.2" xref="S5.E5.m1.7.7.1.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.7.7.1.1.1.1.1.2.2" xref="S5.E5.m1.7.7.1.1.1.1.1.2.2.cmml">ℒ</mi><mrow id="S5.E5.m1.2.2.2.2" xref="S5.E5.m1.2.2.2.3.cmml"><msup id="S5.E5.m1.2.2.2.2.1" xref="S5.E5.m1.2.2.2.2.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.2.2.2.2.1.2" xref="S5.E5.m1.2.2.2.2.1.2.cmml">ℳ</mi><mo id="S5.E5.m1.2.2.2.2.1.3" xref="S5.E5.m1.2.2.2.2.1.3.cmml">′</mo></msup><mo id="S5.E5.m1.2.2.2.2.2" xref="S5.E5.m1.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.1.1.1.1" xref="S5.E5.m1.1.1.1.1.cmml">𝒬</mi></mrow></msub><mo id="S5.E5.m1.7.7.1.1.1.1.1.1" xref="S5.E5.m1.7.7.1.1.1.1.1.1.cmml">−</mo><msub id="S5.E5.m1.7.7.1.1.1.1.1.3" xref="S5.E5.m1.7.7.1.1.1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.7.7.1.1.1.1.1.3.2" xref="S5.E5.m1.7.7.1.1.1.1.1.3.2.cmml">ℒ</mi><mrow id="S5.E5.m1.4.4.2.4" xref="S5.E5.m1.4.4.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.3.3.1.1" xref="S5.E5.m1.3.3.1.1.cmml">ℳ</mi><mo id="S5.E5.m1.4.4.2.4.1" xref="S5.E5.m1.4.4.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.4.4.2.2" xref="S5.E5.m1.4.4.2.2.cmml">𝒬</mi></mrow></msub></mrow><mo id="S5.E5.m1.7.7.1.1.1.1.3" stretchy="false" xref="S5.E5.m1.7.7.1.1.1.1.1.cmml">)</mo></mrow><mo id="S5.E5.m1.7.7.1.1.2" xref="S5.E5.m1.7.7.1.1.2.cmml">/</mo><msub id="S5.E5.m1.7.7.1.1.3" xref="S5.E5.m1.7.7.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.7.7.1.1.3.2" xref="S5.E5.m1.7.7.1.1.3.2.cmml">ℒ</mi><mrow id="S5.E5.m1.6.6.2.4" xref="S5.E5.m1.6.6.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.5.5.1.1" xref="S5.E5.m1.5.5.1.1.cmml">ℳ</mi><mo id="S5.E5.m1.6.6.2.4.1" xref="S5.E5.m1.6.6.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S5.E5.m1.6.6.2.2" xref="S5.E5.m1.6.6.2.2.cmml">𝒬</mi></mrow></msub></mrow><mo id="S5.E5.m1.7.7.1.2" xref="S5.E5.m1.7.7.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E5.m1.7b"><apply id="S5.E5.m1.7.7.1.1.cmml" xref="S5.E5.m1.7.7.1"><divide id="S5.E5.m1.7.7.1.1.2.cmml" xref="S5.E5.m1.7.7.1.1.2"></divide><apply id="S5.E5.m1.7.7.1.1.1.1.1.cmml" xref="S5.E5.m1.7.7.1.1.1.1"><minus id="S5.E5.m1.7.7.1.1.1.1.1.1.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.1"></minus><apply id="S5.E5.m1.7.7.1.1.1.1.1.2.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S5.E5.m1.7.7.1.1.1.1.1.2.1.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.2">subscript</csymbol><ci id="S5.E5.m1.7.7.1.1.1.1.1.2.2.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.2.2">ℒ</ci><list id="S5.E5.m1.2.2.2.3.cmml" xref="S5.E5.m1.2.2.2.2"><apply id="S5.E5.m1.2.2.2.2.1.cmml" xref="S5.E5.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="S5.E5.m1.2.2.2.2.1.1.cmml" xref="S5.E5.m1.2.2.2.2.1">superscript</csymbol><ci id="S5.E5.m1.2.2.2.2.1.2.cmml" xref="S5.E5.m1.2.2.2.2.1.2">ℳ</ci><ci id="S5.E5.m1.2.2.2.2.1.3.cmml" xref="S5.E5.m1.2.2.2.2.1.3">′</ci></apply><ci id="S5.E5.m1.1.1.1.1.cmml" xref="S5.E5.m1.1.1.1.1">𝒬</ci></list></apply><apply id="S5.E5.m1.7.7.1.1.1.1.1.3.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S5.E5.m1.7.7.1.1.1.1.1.3.1.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.3">subscript</csymbol><ci id="S5.E5.m1.7.7.1.1.1.1.1.3.2.cmml" xref="S5.E5.m1.7.7.1.1.1.1.1.3.2">ℒ</ci><list id="S5.E5.m1.4.4.2.3.cmml" xref="S5.E5.m1.4.4.2.4"><ci id="S5.E5.m1.3.3.1.1.cmml" xref="S5.E5.m1.3.3.1.1">ℳ</ci><ci id="S5.E5.m1.4.4.2.2.cmml" xref="S5.E5.m1.4.4.2.2">𝒬</ci></list></apply></apply><apply id="S5.E5.m1.7.7.1.1.3.cmml" xref="S5.E5.m1.7.7.1.1.3"><csymbol cd="ambiguous" id="S5.E5.m1.7.7.1.1.3.1.cmml" xref="S5.E5.m1.7.7.1.1.3">subscript</csymbol><ci id="S5.E5.m1.7.7.1.1.3.2.cmml" xref="S5.E5.m1.7.7.1.1.3.2">ℒ</ci><list id="S5.E5.m1.6.6.2.3.cmml" xref="S5.E5.m1.6.6.2.4"><ci id="S5.E5.m1.5.5.1.1.cmml" xref="S5.E5.m1.5.5.1.1">ℳ</ci><ci id="S5.E5.m1.6.6.2.2.cmml" xref="S5.E5.m1.6.6.2.2">𝒬</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E5.m1.7c">(\mathcal{L}_{\mathcal{M^{\prime}},\mathcal{Q}}-\mathcal{L}_{\mathcal{M},%
\mathcal{Q}})/{\mathcal{L}_{\mathcal{M},\mathcal{Q}}},</annotation><annotation encoding="application/x-llamapun" id="S5.E5.m1.7d">( caligraphic_L start_POSTSUBSCRIPT caligraphic_M start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , caligraphic_Q end_POSTSUBSCRIPT - caligraphic_L start_POSTSUBSCRIPT caligraphic_M , caligraphic_Q end_POSTSUBSCRIPT ) / caligraphic_L start_POSTSUBSCRIPT caligraphic_M , caligraphic_Q end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.p7.2">where <math alttext="\mathcal{M}" class="ltx_Math" display="inline" id="S5.p7.1.m1.1"><semantics id="S5.p7.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S5.p7.1.m1.1.1" xref="S5.p7.1.m1.1.1.cmml">ℳ</mi><annotation-xml encoding="MathML-Content" id="S5.p7.1.m1.1b"><ci id="S5.p7.1.m1.1.1.cmml" xref="S5.p7.1.m1.1.1">ℳ</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p7.1.m1.1c">\mathcal{M}</annotation><annotation encoding="application/x-llamapun" id="S5.p7.1.m1.1d">caligraphic_M</annotation></semantics></math> is the base model and <math alttext="\mathcal{M^{\prime}}" class="ltx_Math" display="inline" id="S5.p7.2.m2.1"><semantics id="S5.p7.2.m2.1a"><msup id="S5.p7.2.m2.1.1" xref="S5.p7.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.p7.2.m2.1.1.2" xref="S5.p7.2.m2.1.1.2.cmml">ℳ</mi><mo id="S5.p7.2.m2.1.1.3" xref="S5.p7.2.m2.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S5.p7.2.m2.1b"><apply id="S5.p7.2.m2.1.1.cmml" xref="S5.p7.2.m2.1.1"><csymbol cd="ambiguous" id="S5.p7.2.m2.1.1.1.cmml" xref="S5.p7.2.m2.1.1">superscript</csymbol><ci id="S5.p7.2.m2.1.1.2.cmml" xref="S5.p7.2.m2.1.1.2">ℳ</ci><ci id="S5.p7.2.m2.1.1.3.cmml" xref="S5.p7.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p7.2.m2.1c">\mathcal{M^{\prime}}</annotation><annotation encoding="application/x-llamapun" id="S5.p7.2.m2.1d">caligraphic_M start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> is the knowledge-injected model, is shown in &nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S5.F2" title="Figure 2 ‣ 5 Experiments and Results ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p8">
<p class="ltx_p" id="S5.p8.1">In all cases, RAG performed significantly better compared to the base models. Furthermore, using RAG with the base model as the generator was consistently better than only fine-tuning. In some cases, using the fine-tuned model instead of the base model as the generator in the RAG pipeline improved results even further. However, this is not consistent and thus demonstrates the inherent instability of fine-tuning. Additionally, we found that the 5-shot approach boosts the results by a small margin in most cases, with a similar trend being observed in all of the different approaches.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p9">
<p class="ltx_p" id="S5.p9.1"><span class="ltx_text ltx_font_bold" id="S5.p9.1.1">Current Events Results</span>  The evaluation on the current events task is shown in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S4.T2" title="Table 2 ‣ 4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>. RAG proves particularly effective due to the one-to-one correspondence between the questions and the auxiliary dataset (see&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S4.SS3" title="4.3 Current Events Task Creation ‣ 4 Knowledge Base Creation ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">4.3</span></a>). Fine-tuning is not competitive with RAG. However, fine-tuning with multiple paraphrases still provides a significant improvement over the baseline. We note that combining RAG with fine-tuning shows inferior performance compared to RAG alone.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p10">
<p class="ltx_p" id="S5.p10.1">It is worth noting that although the questions are based on information the models were not exposed to during training, the results of the base models surpass <math alttext="\frac{1}{L}=0.25" class="ltx_Math" display="inline" id="S5.p10.1.m1.1"><semantics id="S5.p10.1.m1.1a"><mrow id="S5.p10.1.m1.1.1" xref="S5.p10.1.m1.1.1.cmml"><mfrac id="S5.p10.1.m1.1.1.2" xref="S5.p10.1.m1.1.1.2.cmml"><mn id="S5.p10.1.m1.1.1.2.2" xref="S5.p10.1.m1.1.1.2.2.cmml">1</mn><mi id="S5.p10.1.m1.1.1.2.3" xref="S5.p10.1.m1.1.1.2.3.cmml">L</mi></mfrac><mo id="S5.p10.1.m1.1.1.1" xref="S5.p10.1.m1.1.1.1.cmml">=</mo><mn id="S5.p10.1.m1.1.1.3" xref="S5.p10.1.m1.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p10.1.m1.1b"><apply id="S5.p10.1.m1.1.1.cmml" xref="S5.p10.1.m1.1.1"><eq id="S5.p10.1.m1.1.1.1.cmml" xref="S5.p10.1.m1.1.1.1"></eq><apply id="S5.p10.1.m1.1.1.2.cmml" xref="S5.p10.1.m1.1.1.2"><divide id="S5.p10.1.m1.1.1.2.1.cmml" xref="S5.p10.1.m1.1.1.2"></divide><cn id="S5.p10.1.m1.1.1.2.2.cmml" type="integer" xref="S5.p10.1.m1.1.1.2.2">1</cn><ci id="S5.p10.1.m1.1.1.2.3.cmml" xref="S5.p10.1.m1.1.1.2.3">𝐿</ci></apply><cn id="S5.p10.1.m1.1.1.3.cmml" type="float" xref="S5.p10.1.m1.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p10.1.m1.1c">\frac{1}{L}=0.25</annotation><annotation encoding="application/x-llamapun" id="S5.p10.1.m1.1d">divide start_ARG 1 end_ARG start_ARG italic_L end_ARG = 0.25</annotation></semantics></math>. This can partially be explained by the models using reasoning and/or pre-existing knowledge when answering questions that are not independent of the past information. Some examples of this can be found in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#A3" title="Appendix C Current Events Existing Knowledge Examples ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">C</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p11">
<p class="ltx_p" id="S5.p11.1"><span class="ltx_text ltx_font_bold" id="S5.p11.1.1">Fine-Tuning vs. RAG:</span> In the results of both the MMLU and current events tasks, a significant advantage for RAG over fine-tuning is evident. While fine-tuning improved results compared to the base model in most cases, it was not competitive with the RAG approach.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S5.p12">
<p class="ltx_p" id="S5.p12.1">Several factors might contribute to this behavior. Firstly, RAG not only adds knowledge to a model but also incorporates context relevant to the question, a feature lacking in fine-tuning. Additionally, fine-tuning may impact other capabilities of the model due to a degree of catastrophic forgetting. Finally, it’s plausible that unsupervised fine-tuned models might benefit from further alignment through supervised or RL-based fine-tuning, as evidenced by the vastly improved performance of Orca2 over the base Llama2.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>The Importance of Repetition</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Unlike the other tasks, where the model has been exposed to aspects related to the topic during pretraining, <span class="ltx_text ltx_font_italic" id="S6.p1.1.1">current events</span> includes new information. In this case, standard regular fine-tuning not only did not improve the performance of Llama2 but also significantly degraded it. To improve the fine-tuning results, we explored augmentation of the data using paraphrases.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="S6.F3">
<p class="ltx_p ltx_align_center ltx_align_center" id="S6.F3.1"><span class="ltx_text" id="S6.F3.1.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="393" id="S6.F3.1.1.g1" src="extracted/5377658/media/loss_curve.png" width="598"></span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F3.3.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S6.F3.4.2" style="font-size:90%;">Training loss over time for Mistral-7B.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S6.F4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="416" id="S6.F4.g1" src="extracted/5377658/media/paraphrases_plot.png" width="598">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F4.3.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S6.F4.4.2" style="font-size:90%;">Model accuracy on the <span class="ltx_text ltx_font_italic" id="S6.F4.4.2.1">current events</span> task as a function of the number of paraphrases.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1"><span class="ltx_text ltx_font_bold" id="S6.p2.1.1">Data Augmentation</span> Data augmentation is a well-established method for enhancing the performance of language models and has been surveyed extensively&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Shorten et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib38" title="">2021</a>)</cite>. Using generative models for augmentations has also been used successfully to improve classification models in the past&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Sharma et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib37" title="">2022</a>)</cite>.
An example of data augmentation using paraphrasing can be found in &nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#A2" title="Appendix B Paraphrase Examples ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Appendix</span>&nbsp;<span class="ltx_text ltx_ref_tag">B</span></a>.
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S6.p3">
<p class="ltx_p" id="S6.p3.1"><span class="ltx_text ltx_font_bold" id="S6.p3.1.1">Monotonic Improvement</span> This approach resulted in notable improvements in our results, showcasing a direct correlation between the number of paraphrases utilized and the models’ accuracy.
Our experimentation revealed a compelling trend, shown in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S6.F4" title="Figure 4 ‣ 6 The Importance of Repetition ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">4</span></a>. For all models tested, the accuracy was a monotonically increasing function of the number of paraphrases used. This observation strongly suggests the positive impact of paraphrase augmentation, yielding information repetition, on the model’s ability to comprehend and generalize new knowledge from limited data.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.1"><span class="ltx_text ltx_font_bold" id="S6.p4.1.1">Learning New Information</span> In&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S6.F3" title="Figure 3 ‣ 6 The Importance of Repetition ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Figure</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a>, we can see an interesting phenomenon observed throughout our experiments. After each epoch, i.e., completing another iteration over the entire dataset, the training loss drops significantly. This is consistent with what is known about LLMs memorizing the data during training and overfitting&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Tirumala et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib44" title="">2022</a>)</cite>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S6.p5">
<p class="ltx_p" id="S6.p5.1">Our hypothesis is as follows:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<blockquote class="ltx_quote" id="S6.p5.2">
<p class="ltx_p" id="S6.p5.2.1">In order to teach pre-trained LLMs <span class="ltx_text ltx_font_bold" id="S6.p5.2.1.1">new</span> knowledge, the knowledge must be repeated in numerous ways.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</blockquote>
</div>
<div class="ltx_para ltx_noindent" id="S6.p6">
<p class="ltx_p" id="S6.p6.2">This is well known for LLM pre-training <cite class="ltx_cite ltx_citemacro_citep">(Kandpal et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib17" title="">2023</a>)</cite>, and we see in this case that this holds for fine-tuning as well. The rationale for this hypothesis is that mere memorization of sentences does not entail knowledge of their content, as was already shown in&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Berglund et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib2" title="">2023</a>)</cite>. By providing the information in numerous forms (like the data augmentation process we used), the various relationships in the data (e.g., <math alttext="a\implies b,\>b\hbox to 0.0pt{$\quad\not$\hss}\implies c" class="ltx_Math" display="inline" id="S6.p6.1.m1.3"><semantics id="S6.p6.1.m1.3a"><mrow id="S6.p6.1.m1.3.3.2" xref="S6.p6.1.m1.3.3.3.cmml"><mrow id="S6.p6.1.m1.2.2.1.1" xref="S6.p6.1.m1.2.2.1.1.cmml"><mi id="S6.p6.1.m1.2.2.1.1.2" xref="S6.p6.1.m1.2.2.1.1.2.cmml">a</mi><mo id="S6.p6.1.m1.2.2.1.1.1" stretchy="false" xref="S6.p6.1.m1.2.2.1.1.1.cmml">⟹</mo><mi id="S6.p6.1.m1.2.2.1.1.3" xref="S6.p6.1.m1.2.2.1.1.3.cmml">b</mi></mrow><mo id="S6.p6.1.m1.3.3.2.3" rspace="0.387em" xref="S6.p6.1.m1.3.3.3a.cmml">,</mo><mrow id="S6.p6.1.m1.3.3.2.2" xref="S6.p6.1.m1.3.3.2.2.cmml"><mrow id="S6.p6.1.m1.3.3.2.2.2" xref="S6.p6.1.m1.3.3.2.2.2.cmml"><mi id="S6.p6.1.m1.3.3.2.2.2.2" xref="S6.p6.1.m1.3.3.2.2.2.2.cmml">b</mi><mo id="S6.p6.1.m1.3.3.2.2.2.1" lspace="1.167em" xref="S6.p6.1.m1.3.3.2.2.2.1.cmml">⁢</mo><mpadded id="S6.p6.1.m1.1.1.1" width="0.0pt" xref="S6.p6.1.m1.1.1.1.cmml"><mi id="S6.p6.1.m1.1.1.1a" mathvariant="normal" xref="S6.p6.1.m1.1.1.1.cmml">／</mi></mpadded></mrow><mo id="S6.p6.1.m1.3.3.2.2.1" stretchy="false" xref="S6.p6.1.m1.3.3.2.2.1.cmml">⟹</mo><mi id="S6.p6.1.m1.3.3.2.2.3" xref="S6.p6.1.m1.3.3.2.2.3.cmml">c</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S6.p6.1.m1.3b"><apply id="S6.p6.1.m1.3.3.3.cmml" xref="S6.p6.1.m1.3.3.2"><csymbol cd="ambiguous" id="S6.p6.1.m1.3.3.3a.cmml" xref="S6.p6.1.m1.3.3.2.3">formulae-sequence</csymbol><apply id="S6.p6.1.m1.2.2.1.1.cmml" xref="S6.p6.1.m1.2.2.1.1"><implies id="S6.p6.1.m1.2.2.1.1.1.cmml" xref="S6.p6.1.m1.2.2.1.1.1"></implies><ci id="S6.p6.1.m1.2.2.1.1.2.cmml" xref="S6.p6.1.m1.2.2.1.1.2">𝑎</ci><ci id="S6.p6.1.m1.2.2.1.1.3.cmml" xref="S6.p6.1.m1.2.2.1.1.3">𝑏</ci></apply><apply id="S6.p6.1.m1.3.3.2.2.cmml" xref="S6.p6.1.m1.3.3.2.2"><implies id="S6.p6.1.m1.3.3.2.2.1.cmml" xref="S6.p6.1.m1.3.3.2.2.1"></implies><apply id="S6.p6.1.m1.3.3.2.2.2.cmml" xref="S6.p6.1.m1.3.3.2.2.2"><times id="S6.p6.1.m1.3.3.2.2.2.1.cmml" xref="S6.p6.1.m1.3.3.2.2.2.1"></times><ci id="S6.p6.1.m1.3.3.2.2.2.2.cmml" xref="S6.p6.1.m1.3.3.2.2.2.2">𝑏</ci><not id="S6.p6.1.m1.1.1.1.cmml" xref="S6.p6.1.m1.1.1.1"></not></apply><ci id="S6.p6.1.m1.3.3.2.2.3.cmml" xref="S6.p6.1.m1.3.3.2.2.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.1.m1.3c">a\implies b,\&gt;b\hbox to 0.0pt{$\quad\not$\hss}\implies c</annotation><annotation encoding="application/x-llamapun" id="S6.p6.1.m1.3d">italic_a ⟹ italic_b , italic_b ／ ⟹ italic_c</annotation></semantics></math>) stand a higher chance of appearing naturally. We believe this can potentially both increase <math alttext="\mathcal{L}_{\mathcal{M},\mathcal{Q}}" class="ltx_Math" display="inline" id="S6.p6.2.m2.2"><semantics id="S6.p6.2.m2.2a"><msub id="S6.p6.2.m2.2.3" xref="S6.p6.2.m2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S6.p6.2.m2.2.3.2" xref="S6.p6.2.m2.2.3.2.cmml">ℒ</mi><mrow id="S6.p6.2.m2.2.2.2.4" xref="S6.p6.2.m2.2.2.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S6.p6.2.m2.1.1.1.1" xref="S6.p6.2.m2.1.1.1.1.cmml">ℳ</mi><mo id="S6.p6.2.m2.2.2.2.4.1" xref="S6.p6.2.m2.2.2.2.3.cmml">,</mo><mi class="ltx_font_mathcaligraphic" id="S6.p6.2.m2.2.2.2.2" xref="S6.p6.2.m2.2.2.2.2.cmml">𝒬</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S6.p6.2.m2.2b"><apply id="S6.p6.2.m2.2.3.cmml" xref="S6.p6.2.m2.2.3"><csymbol cd="ambiguous" id="S6.p6.2.m2.2.3.1.cmml" xref="S6.p6.2.m2.2.3">subscript</csymbol><ci id="S6.p6.2.m2.2.3.2.cmml" xref="S6.p6.2.m2.2.3.2">ℒ</ci><list id="S6.p6.2.m2.2.2.2.3.cmml" xref="S6.p6.2.m2.2.2.2.4"><ci id="S6.p6.2.m2.1.1.1.1.cmml" xref="S6.p6.2.m2.1.1.1.1">ℳ</ci><ci id="S6.p6.2.m2.2.2.2.2.cmml" xref="S6.p6.2.m2.2.2.2.2">𝒬</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p6.2.m2.2c">\mathcal{L}_{\mathcal{M},\mathcal{Q}}</annotation><annotation encoding="application/x-llamapun" id="S6.p6.2.m2.2d">caligraphic_L start_POSTSUBSCRIPT caligraphic_M , caligraphic_Q end_POSTSUBSCRIPT</annotation></semantics></math> in general, as well as ameliorate Berglund et al.’s <span class="ltx_text ltx_font_italic" id="S6.p6.2.1">Reversal Curse</span>. While promising, this result still warrants further research.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion and Future Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">Large language models possess vast amounts of knowledge on various topics. In this work, we tested their capability to adapt to new knowledge: both specialized and completely unseen. This is among the first studies to compare two prominent approaches in this domain, namely fine-tuning and retrieval augmented generation. While fine-tuning can be useful for many use-cases, we found that RAG is a more reliable choice for knowledge injection.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Some aspects of this work still warrant further research. For example, we focused on unsupervised training as our primary fine-tuning method, as opposed to instruction-tuning or RL-based methods. Researching combinations of various techniques, with diverse auxiliary knowledge bases, may yield improved results. This approach, combined with our hypothesis from&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S6" title="6 The Importance of Repetition ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">6</span></a>, could further enhance our understanding of knowledge injection via FT.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">While we believe that this work further enhances our understanding of knowledge in LLMs, there is a lot more work to be done in this field. Specifically, more research is required regarding the question of knowledge representation in LLMs, especially from a theoretical perspective.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S7.p4">
<p class="ltx_p" id="S7.p4.1">Finally, further efforts are needed to measure knowledge in LLMs. While we employed an empirical approach as described in&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S2.E2" title="2 ‣ 2 Background ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Equation</span>&nbsp;<span class="ltx_text ltx_ref_tag">2</span></a>, it is important to explore other definitions and perspectives on knowledge as well, and extend upon this work.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Limitations</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">As in all machine learning applications, the choice of hyperparameters significantly impacts the results. We therefore strongly recommend optimizing all relevant hyperparameters for specific cases.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S8.p2">
<p class="ltx_p" id="S8.p2.1">We have supported our claims by running the experiments on three different models. However, generalization to other LLMs should be tested thoroughly. For example, GPT-4 achieves near perfect accuracy for some MMLU tasks&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Nori et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib29" title="">2023</a>)</cite>, and thus further improvement is not applicable.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="S8.p3">
<p class="ltx_p" id="S8.p3.1">Finally, while we chose various topics for the knowledge bases, all of our sources came from Wikipedia. Other datasets may yield different results, and must be evaluated carefully.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Attardi (2015)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Attardi, G.

</span>
<span class="ltx_bibblock">Wikiextractor.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/attardi/wikiextractor" title="">https://github.com/attardi/wikiextractor</a>, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berglund et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Berglund, L., Tong, M., Kaufmann, M., Balesni, M., Stickland, A.&nbsp;C., Korbak, T., and Evans, O.

</span>
<span class="ltx_bibblock">The reversal curse: Llms trained on” a is b” fail to learn” b is a”.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2309.12288</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chen, S., Hou, Y., Cui, Y., Che, W., Liu, T., and Yu, X.

</span>
<span class="ltx_bibblock">Recall and learn: Fine-tuning deep pretrained language models with less forgetting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2004.12651</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chen, X., Zhang, N., Xie, X., Deng, S., Yao, Y., Tan, C., Huang, F., Si, L., and Chen, H.

</span>
<span class="ltx_bibblock">Knowprompt: Knowledge-aware prompt-tuning with synergistic optimization for relation extraction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the ACM Web conference 2022</em>, pp.&nbsp; 2778–2788, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chen, Y., Zhong, R., Zha, S., Karypis, G., and He, H.

</span>
<span class="ltx_bibblock">Meta-learning via language model in-context tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2110.07814</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chia et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chia, Y.&nbsp;K., Hong, P., Bing, L., and Poria, S.

</span>
<span class="ltx_bibblock">Instructeval: Towards holistic evaluation of instruction-tuned large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2306.04757</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chung, H.&nbsp;W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y., Wang, X., Dehghani, M., Brahma, S., et&nbsp;al.

</span>
<span class="ltx_bibblock">Scaling instruction-finetuned language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2210.11416</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cohen et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Cohen, R., Geva, M., Berant, J., and Globerson, A.

</span>
<span class="ltx_bibblock">Crawling the internal knowledge-base of language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2301.12810</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dua et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dua, D., Wang, Y., Dasigi, P., Stanovsky, G., Singh, S., and Gardner, M.

</span>
<span class="ltx_bibblock">Drop: A reading comprehension benchmark requiring discrete reasoning over paragraphs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:1903.00161</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Gao, L., Tow, J., Biderman, S., Black, S., DiPofi, A., Foster, C., Golding, L., Hsu, J., McDonell, K., Muennighoff, N., Phang, J., Reynolds, L., Tang, E., Thite, A., Wang, B., Wang, K., and Zou, A.

</span>
<span class="ltx_bibblock">A framework for few-shot language model evaluation, September 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.5281/zenodo.5371628" title="">https://doi.org/10.5281/zenodo.5371628</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et&nbsp;al. (2013)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Goodfellow, I.&nbsp;J., Mirza, M., Xiao, D., Courville, A., and Bengio, Y.

</span>
<span class="ltx_bibblock">An empirical investigation of catastrophic forgetting in gradient-based neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:1312.6211</em>, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the International Conference on Learning Representations (ICLR)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hu, L., Liu, Z., Zhao, Z., Hou, L., Nie, L., and Li, J.

</span>
<span class="ltx_bibblock">A survey of knowledge enhanced pre-trained language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">IEEE Transactions on Knowledge and Data Engineering</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Huang, Q., Tao, M., An, Z., Zhang, C., Jiang, C., Chen, Z., Wu, Z., and Feng, Y.

</span>
<span class="ltx_bibblock">Lawyer llama technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2305.15062</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jiang, A.&nbsp;Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D.&nbsp;S., Casas, D. d.&nbsp;l., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., et&nbsp;al.

</span>
<span class="ltx_bibblock">Mistral 7b.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2310.06825</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johnson et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Johnson, J., Douze, M., and Jégou, H.

</span>
<span class="ltx_bibblock">Billion-scale similarity search with GPUs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">IEEE Transactions on Big Data</em>, 7(3):535–547, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kandpal et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kandpal, N., Deng, H., Roberts, A., Wallace, E., and Raffel, C.

</span>
<span class="ltx_bibblock">Large language models struggle to learn long-tail knowledge.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">International Conference on Machine Learning</em>, pp.&nbsp; 15696–15707. PMLR, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirkpatrick et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A.&nbsp;A., Milan, K., Quan, J., Ramalho, T., Grabska-Barwinska, A., et&nbsp;al.

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting in neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Proceedings of the national academy of sciences</em>, 114(13):3521–3526, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lampinen et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lampinen, A.&nbsp;K., Dasgupta, I., Chan, S.&nbsp;C., Matthewson, K., Tessler, M.&nbsp;H., Creswell, A., McClelland, J.&nbsp;L., Wang, J.&nbsp;X., and Hill, F.

</span>
<span class="ltx_bibblock">Can language models learn from explanations in context?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2204.02329</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lauscher et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lauscher, A., Majewska, O., Ribeiro, L.&nbsp;F., Gurevych, I., Rozanov, N., and Glavaš, G.

</span>
<span class="ltx_bibblock">Common sense or world knowledge? investigating adapter-based knowledge injection into pretrained transformers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2005.11787</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., Küttler, H., Lewis, M., Yih, W.-t., Rocktäschel, T., et&nbsp;al.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for knowledge-intensive nlp tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Advances in Neural Information Processing Systems</em>, 33:9459–9474, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Liu, W., Zhou, P., Zhao, Z., Wang, Z., Ju, Q., Deng, H., and Wang, P.

</span>
<span class="ltx_bibblock">K-bert: Enabling language representation with knowledge graph.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the AAAI Conference on Artificial Intelligence</em>, volume&nbsp;34, pp.&nbsp; 2901–2908, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Luo, Y., Yang, Z., Meng, F., Li, Y., Zhou, J., and Zhang, Y.

</span>
<span class="ltx_bibblock">An empirical study of catastrophic forgetting in large language models during continual fine-tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2308.08747</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Min, S., Lewis, M., Zettlemoyer, L., and Hajishirzi, H.

</span>
<span class="ltx_bibblock">Metaicl: Learning to learn in context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:2110.15943</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mishra et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mishra, S., Khashabi, D., Baral, C., and Hajishirzi, H.

</span>
<span class="ltx_bibblock">Cross-task generalization via natural language crowdsourcing instructions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2104.08773</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitra et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Mitra, A., Del&nbsp;Corro, L., Mahajan, S., Codas, A., Simoes, C., Agrawal, S., Chen, X., Razdaibiedina, A., Jones, E., Aggarwal, K., et&nbsp;al.

</span>
<span class="ltx_bibblock">Orca 2: Teaching small language models how to reason.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2311.11045</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Neelakantan et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Neelakantan, A., Xu, T., Puri, R., Radford, A., Han, J.&nbsp;M., Tworek, J., Yuan, Q., Tezak, N.&nbsp;A., Kim, J.&nbsp;W., Hallacy, C., Heidecke, J., Shyam, P., Power, B., Nekoul, T.&nbsp;E., Sastry, G., Krueger, G., Schnurr, D.&nbsp;P., Such, F.&nbsp;P., Hsu, K. S.-K., Thompson, M., Khan, T., Sherbakov, T., Jang, J., Welinder, P., and Weng, L.

</span>
<span class="ltx_bibblock">Text and code embeddings by contrastive pre-training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">ArXiv</em>, abs/2201.10005, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:246275593" title="">https://api.semanticscholar.org/CorpusID:246275593</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Nguyen, H.-T.

</span>
<span class="ltx_bibblock">A brief report on lawgpt 1.0: A virtual legal assistant based on gpt-3.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2302.05729</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nori et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Nori, H., King, N., McKinney, S.&nbsp;M., Carignan, D., and Horvitz, E.

</span>
<span class="ltx_bibblock">Capabilities of gpt-4 on medical challenge problems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">ArXiv</em>, abs/2303.13375, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:257687695" title="">https://api.semanticscholar.org/CorpusID:257687695</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">ArXiv</em>, abs/2303.08774, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:257532815" title="">https://api.semanticscholar.org/CorpusID:257532815</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., et&nbsp;al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Advances in Neural Information Processing Systems</em>, 35:27730–27744, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Petroni, F., Rocktäschel, T., Lewis, P., Bakhtin, A., Wu, Y., Miller, A.&nbsp;H., and Riedel, S.

</span>
<span class="ltx_bibblock">Language models as knowledge bases?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:1909.01066</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., Sutskever, I., et&nbsp;al.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">OpenAI blog</em>, 1(8):9, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rafailov, R., Sharma, A., Mitchell, E., Ermon, S., Manning, C.&nbsp;D., and Finn, C.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a reward model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2305.18290</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sakaguchi et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sakaguchi, K., Bras, R.&nbsp;L., Bhagavatula, C., and Choi, Y.

</span>
<span class="ltx_bibblock">Winogrande: An adversarial winograd schema challenge at scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">Communications of the ACM</em>, 64(9):99–106, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schulman et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Schulman, J., Wolski, F., Dhariwal, P., Radford, A., and Klimov, O.

</span>
<span class="ltx_bibblock">Proximal policy optimization algorithms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:1707.06347</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sharma et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sharma, S., Joshi, A., Mukhija, N., Zhao, Y., Bhathena, H., Singh, P., Santhanam, S., and Biswas, P.

</span>
<span class="ltx_bibblock">Systematic review of effect of data augmentation using paraphrasing on named entity recognition.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research</em>, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=rc2h1h89aDi" title="">https://openreview.net/forum?id=rc2h1h89aDi</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shorten et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shorten, C., Khoshgoftaar, T.&nbsp;M., and Furht, B.

</span>
<span class="ltx_bibblock">Text data augmentation for deep learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Journal of Big Data</em>, 8, 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:236096559" title="">https://api.semanticscholar.org/CorpusID:236096559</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singhal et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Singhal, K., Azizi, S., Tu, T., Mahdavi, S.&nbsp;S., Wei, J., Chung, H.&nbsp;W., Scales, N., Tanwani, A., Cole-Lewis, H., Pfohl, S., et&nbsp;al.

</span>
<span class="ltx_bibblock">Large language models encode clinical knowledge.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Nature</em>, 620(7972):172–180, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singhal et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Singhal, K., Tu, T., Gottweis, J., Sayres, R., Wulczyn, E., Hou, L., Clark, K., Pfohl, S., Cole-Lewis, H., Neal, D., et&nbsp;al.

</span>
<span class="ltx_bibblock">Towards expert-level medical question answering with large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2305.09617</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Srivastava, A., Rastogi, A., Rao, A., Shoeb, A. A.&nbsp;M., Abid, A., Fisch, A., Brown, A.&nbsp;R., Santoro, A., Gupta, A., Garriga-Alonso, A., et&nbsp;al.

</span>
<span class="ltx_bibblock">Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">arXiv preprint arXiv:2206.04615</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tan, Y., Min, D., Li, Y., Li, W., Hu, N., Chen, Y., and Qi, G.

</span>
<span class="ltx_bibblock">Can chatgpt replace traditional kbqa models? an in-depth analysis of the question answering performance of the gpt llm family.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">International Semantic Web Conference</em>, pp.&nbsp; 348–367. Springer, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Taori, R., Gulrajani, I., Zhang, T., Dubois, Y., Li, X., Guestrin, C., Liang, P., and Hashimoto, T.&nbsp;B.

</span>
<span class="ltx_bibblock">Alpaca: A strong, replicable instruction-following model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Stanford Center for Research on Foundation Models. https://crfm. stanford. edu/2023/03/13/alpaca. html</em>, 3(6):7, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tirumala et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tirumala, K., Markosyan, A.&nbsp;H., Zettlemoyer, L., and Aghajanyan, A.

</span>
<span class="ltx_bibblock">Memorization without overfitting: Analyzing the training dynamics of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">ArXiv</em>, abs/2205.10770, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:248986465" title="">https://api.semanticscholar.org/CorpusID:248986465</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">arXiv preprint arXiv:2307.09288</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tunstall et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tunstall, L., Beeching, E., Lambert, N., Rajani, N., Rasul, K., Belkada, Y., Huang, S., von Werra, L., Fourrier, C., Habib, N., et&nbsp;al.

</span>
<span class="ltx_bibblock">Zephyr: Direct distillation of lm alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">arXiv preprint arXiv:2310.16944</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wang, C., Liu, X., Yue, Y., Tang, X., Zhang, T., Jiayang, C., Yao, Y., Gao, W., Hu, X., Qi, Z., et&nbsp;al.

</span>
<span class="ltx_bibblock">Survey on factuality in large language models: Knowledge, retrieval and domain-specificity.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">arXiv preprint arXiv:2310.07521</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wang, R., Tang, D., Duan, N., Wei, Z., Huang, X., Cao, G., Jiang, D., Zhou, M., et&nbsp;al.

</span>
<span class="ltx_bibblock">K-adapter: Infusing knowledge into pre-trained models with adapters.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">arXiv preprint arXiv:2002.01808</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wang, Y., Mishra, S., Alipoormolabashi, P., Kordi, Y., Mirzaei, A., Arunkumar, A., Ashok, A., Dhanasekaran, A.&nbsp;S., Naik, A., Stap, D., et&nbsp;al.

</span>
<span class="ltx_bibblock">Super-naturalinstructions: Generalization via declarative instructions on 1600+ nlp tasks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">arXiv preprint arXiv:2204.07705</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wu, C., Zhang, X., Zhang, Y., Wang, Y., and Xie, W.

</span>
<span class="ltx_bibblock">Pmc-llama: Further finetuning llama on medical papers.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">arXiv preprint arXiv:2304.14454</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wu, S., Irsoy, O., Lu, S., Dabravolski, V., Dredze, M., Gehrmann, S., Kambadur, P., Rosenberg, D., and Mann, G.

</span>
<span class="ltx_bibblock">Bloomberggpt: A large language model for finance.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2303.17564</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiao, S., Liu, Z., Zhang, P., and Muennighoff, N.

</span>
<span class="ltx_bibblock">C-pack: Packaged resources to advance general chinese embedding, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yang, H., Liu, X.-Y., and Wang, C.&nbsp;D.

</span>
<span class="ltx_bibblock">Fingpt: Open-source financial large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">arXiv preprint arXiv:2306.06031</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yu, W., Zhu, C., Li, Z., Hu, Z., Wang, Q., Ji, H., and Jiang, M.

</span>
<span class="ltx_bibblock">A survey of knowledge-enhanced text generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">ACM Computing Surveys</em>, 54(11s):1–38, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhou, C., Liu, P., Xu, P., Iyer, S., Sun, J., Mao, Y., Ma, X., Efrat, A., Yu, P., Yu, L., et&nbsp;al.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">arXiv preprint arXiv:2305.11206</em>, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>RAG Ablation Study</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.7">As mentioned in <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#S5" title="5 Experiments and Results ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Section</span>&nbsp;<span class="ltx_text ltx_ref_tag">5</span></a>, we compared various values of <math alttext="K\in\{0,\ldots,5\}" class="ltx_Math" display="inline" id="A1.p1.1.m1.3"><semantics id="A1.p1.1.m1.3a"><mrow id="A1.p1.1.m1.3.4" xref="A1.p1.1.m1.3.4.cmml"><mi id="A1.p1.1.m1.3.4.2" xref="A1.p1.1.m1.3.4.2.cmml">K</mi><mo id="A1.p1.1.m1.3.4.1" xref="A1.p1.1.m1.3.4.1.cmml">∈</mo><mrow id="A1.p1.1.m1.3.4.3.2" xref="A1.p1.1.m1.3.4.3.1.cmml"><mo id="A1.p1.1.m1.3.4.3.2.1" stretchy="false" xref="A1.p1.1.m1.3.4.3.1.cmml">{</mo><mn id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml">0</mn><mo id="A1.p1.1.m1.3.4.3.2.2" xref="A1.p1.1.m1.3.4.3.1.cmml">,</mo><mi id="A1.p1.1.m1.2.2" mathvariant="normal" xref="A1.p1.1.m1.2.2.cmml">…</mi><mo id="A1.p1.1.m1.3.4.3.2.3" xref="A1.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="A1.p1.1.m1.3.3" xref="A1.p1.1.m1.3.3.cmml">5</mn><mo id="A1.p1.1.m1.3.4.3.2.4" stretchy="false" xref="A1.p1.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.3b"><apply id="A1.p1.1.m1.3.4.cmml" xref="A1.p1.1.m1.3.4"><in id="A1.p1.1.m1.3.4.1.cmml" xref="A1.p1.1.m1.3.4.1"></in><ci id="A1.p1.1.m1.3.4.2.cmml" xref="A1.p1.1.m1.3.4.2">𝐾</ci><set id="A1.p1.1.m1.3.4.3.1.cmml" xref="A1.p1.1.m1.3.4.3.2"><cn id="A1.p1.1.m1.1.1.cmml" type="integer" xref="A1.p1.1.m1.1.1">0</cn><ci id="A1.p1.1.m1.2.2.cmml" xref="A1.p1.1.m1.2.2">…</ci><cn id="A1.p1.1.m1.3.3.cmml" type="integer" xref="A1.p1.1.m1.3.3">5</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.3c">K\in\{0,\ldots,5\}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.1.m1.3d">italic_K ∈ { 0 , … , 5 }</annotation></semantics></math>, shown in <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#A1.T3" title="Table 3 ‣ Appendix A RAG Ablation Study ‣ Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs"><span class="ltx_text ltx_ref_tag">Table</span>&nbsp;<span class="ltx_text ltx_ref_tag">3</span></a>.We were unable to find an optimal value of <math alttext="K" class="ltx_Math" display="inline" id="A1.p1.2.m2.1"><semantics id="A1.p1.2.m2.1a"><mi id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b"><ci id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">K</annotation><annotation encoding="application/x-llamapun" id="A1.p1.2.m2.1d">italic_K</annotation></semantics></math> per model, per <math alttext="0/5" class="ltx_Math" display="inline" id="A1.p1.3.m3.1"><semantics id="A1.p1.3.m3.1a"><mrow id="A1.p1.3.m3.1.1" xref="A1.p1.3.m3.1.1.cmml"><mn id="A1.p1.3.m3.1.1.2" xref="A1.p1.3.m3.1.1.2.cmml">0</mn><mo id="A1.p1.3.m3.1.1.1" xref="A1.p1.3.m3.1.1.1.cmml">/</mo><mn id="A1.p1.3.m3.1.1.3" xref="A1.p1.3.m3.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.3.m3.1b"><apply id="A1.p1.3.m3.1.1.cmml" xref="A1.p1.3.m3.1.1"><divide id="A1.p1.3.m3.1.1.1.cmml" xref="A1.p1.3.m3.1.1.1"></divide><cn id="A1.p1.3.m3.1.1.2.cmml" type="integer" xref="A1.p1.3.m3.1.1.2">0</cn><cn id="A1.p1.3.m3.1.1.3.cmml" type="integer" xref="A1.p1.3.m3.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.3.m3.1c">0/5</annotation><annotation encoding="application/x-llamapun" id="A1.p1.3.m3.1d">0 / 5</annotation></semantics></math>-shot, or per task. In fact, other than Anatomy that worked well with <math alttext="K=2" class="ltx_Math" display="inline" id="A1.p1.4.m4.1"><semantics id="A1.p1.4.m4.1a"><mrow id="A1.p1.4.m4.1.1" xref="A1.p1.4.m4.1.1.cmml"><mi id="A1.p1.4.m4.1.1.2" xref="A1.p1.4.m4.1.1.2.cmml">K</mi><mo id="A1.p1.4.m4.1.1.1" xref="A1.p1.4.m4.1.1.1.cmml">=</mo><mn id="A1.p1.4.m4.1.1.3" xref="A1.p1.4.m4.1.1.3.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.4.m4.1b"><apply id="A1.p1.4.m4.1.1.cmml" xref="A1.p1.4.m4.1.1"><eq id="A1.p1.4.m4.1.1.1.cmml" xref="A1.p1.4.m4.1.1.1"></eq><ci id="A1.p1.4.m4.1.1.2.cmml" xref="A1.p1.4.m4.1.1.2">𝐾</ci><cn id="A1.p1.4.m4.1.1.3.cmml" type="integer" xref="A1.p1.4.m4.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.4.m4.1c">K=2</annotation><annotation encoding="application/x-llamapun" id="A1.p1.4.m4.1d">italic_K = 2</annotation></semantics></math> consistently, there seems to be no patterns that aid in predicting the performance per <math alttext="K" class="ltx_Math" display="inline" id="A1.p1.5.m5.1"><semantics id="A1.p1.5.m5.1a"><mi id="A1.p1.5.m5.1.1" xref="A1.p1.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.p1.5.m5.1b"><ci id="A1.p1.5.m5.1.1.cmml" xref="A1.p1.5.m5.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.5.m5.1c">K</annotation><annotation encoding="application/x-llamapun" id="A1.p1.5.m5.1d">italic_K</annotation></semantics></math>, unlike the results presented in&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Lewis et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2312.05934v3#bib.bib21" title="">2020</a>)</cite> for other setups. Moreover, the gap between the best and worst performing <math alttext="K" class="ltx_Math" display="inline" id="A1.p1.6.m6.1"><semantics id="A1.p1.6.m6.1a"><mi id="A1.p1.6.m6.1.1" xref="A1.p1.6.m6.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.p1.6.m6.1b"><ci id="A1.p1.6.m6.1.1.cmml" xref="A1.p1.6.m6.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.6.m6.1c">K</annotation><annotation encoding="application/x-llamapun" id="A1.p1.6.m6.1d">italic_K</annotation></semantics></math>s can be large.
<br class="ltx_break">Unfortunately, we must conclude that this additional hyperparameter is unstable. This is a downside of using RAG in practice, and the choice of <math alttext="K" class="ltx_Math" display="inline" id="A1.p1.7.m7.1"><semantics id="A1.p1.7.m7.1a"><mi id="A1.p1.7.m7.1.1" xref="A1.p1.7.m7.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.p1.7.m7.1b"><ci id="A1.p1.7.m7.1.1.cmml" xref="A1.p1.7.m7.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.7.m7.1c">K</annotation><annotation encoding="application/x-llamapun" id="A1.p1.7.m7.1d">italic_K</annotation></semantics></math> cannot be ignored.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="A1.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="A1.T3.1.1.2" rowspan="2"><span class="ltx_text" id="A1.T3.1.1.2.1">Task</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r" id="A1.T3.1.1.3" rowspan="2"><span class="ltx_text" id="A1.T3.1.1.3.1">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" colspan="5" id="A1.T3.1.1.1"># Retrieved documents (<math alttext="k" class="ltx_Math" display="inline" id="A1.T3.1.1.1.m1.1"><semantics id="A1.T3.1.1.1.m1.1a"><mi id="A1.T3.1.1.1.m1.1.1" xref="A1.T3.1.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.m1.1b"><ci id="A1.T3.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="A1.T3.1.1.1.m1.1d">italic_k</annotation></semantics></math>)</th>
</tr>
<tr class="ltx_tr" id="A1.T3.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A1.T3.1.2.1.1">1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A1.T3.1.2.1.2">2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A1.T3.1.2.1.3">3</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A1.T3.1.2.1.4">4</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A1.T3.1.2.1.5">5</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T3.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T3.1.3.1.1" rowspan="3"><span class="ltx_text" id="A1.T3.1.3.1.1.1">Anatomy (0-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.1.3.1.2">Mistral 7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.3.1.3">0.615</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.3.1.4"><span class="ltx_text ltx_font_bold" id="A1.T3.1.3.1.4.1">0.681</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.3.1.5">0.630</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.3.1.6">0.644</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.3.1.7">0.622</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.4.2.1">Llama2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.4.2.2">0.444</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.4.2.3"><span class="ltx_text ltx_font_bold" id="A1.T3.1.4.2.3.1">0.489</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.4.2.4">0.467</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.4.2.5">0.474</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.4.2.6">0.481</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.5.3.1">Orca2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.5.3.2">0.607</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.5.3.3"><span class="ltx_text ltx_font_bold" id="A1.T3.1.5.3.3.1">0.637</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.5.3.4">0.600</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.5.3.5">0.585</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.5.3.6"><span class="ltx_text ltx_font_bold" id="A1.T3.1.5.3.6.1">0.637</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T3.1.6.4.1" rowspan="3"><span class="ltx_text" id="A1.T3.1.6.4.1.1">Anatomy (5-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.6.4.2">Mistral 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.6.4.3">0.659</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.6.4.4">0.667</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.6.4.5">0.659</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.6.4.6"><span class="ltx_text ltx_font_bold" id="A1.T3.1.6.4.6.1">0.681</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.6.4.7">0.674</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.7.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.7.5.1">Llama2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.7.5.2">0.496</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.7.5.3"><span class="ltx_text ltx_font_bold" id="A1.T3.1.7.5.3.1">0.563</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.7.5.4">0.541</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.7.5.5">0.526</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.7.5.6">0.526</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.8.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.8.6.1">Orca2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.8.6.2">0.630</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.8.6.3"><span class="ltx_text ltx_font_bold" id="A1.T3.1.8.6.3.1">0.659</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.8.6.4">0.600</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.8.6.5">0.600</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.8.6.6">0.600</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.9.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T3.1.9.7.1" rowspan="3"><span class="ltx_text" id="A1.T3.1.9.7.1.1">Astronomy (0-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.1.9.7.2">Mistral 7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.9.7.3">0.651</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.9.7.4"><span class="ltx_text ltx_font_bold" id="A1.T3.1.9.7.4.1">0.678</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.9.7.5"><span class="ltx_text ltx_font_bold" id="A1.T3.1.9.7.5.1">0.678</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.9.7.6">0.664</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.9.7.7">0.664</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.10.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.10.8.1">Llama2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.10.8.2">0.447</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.10.8.3">0.434</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.10.8.4">0.447</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.10.8.5">0.434</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.10.8.6"><span class="ltx_text ltx_font_bold" id="A1.T3.1.10.8.6.1">0.467</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.11.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.11.9.1">Orca2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.11.9.2">0.711</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.11.9.3">0.730</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.11.9.4">0.730</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.11.9.5"><span class="ltx_text ltx_font_bold" id="A1.T3.1.11.9.5.1">0.750</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.11.9.6">0.730</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.12.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T3.1.12.10.1" rowspan="3"><span class="ltx_text" id="A1.T3.1.12.10.1.1">Astronomy (5-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.12.10.2">Mistral 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.12.10.3">0.704</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.12.10.4">0.684</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.12.10.5">0.658</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.12.10.6">0.684</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.12.10.7"><span class="ltx_text ltx_font_bold" id="A1.T3.1.12.10.7.1">0.724</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.13.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.13.11.1">Llama2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.13.11.2">0.461</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.13.11.3">0.447</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.13.11.4"><span class="ltx_text ltx_font_bold" id="A1.T3.1.13.11.4.1">0.474</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.13.11.5">0.428</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.13.11.6">0.454</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.14.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.14.12.1">Orca2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.14.12.2">0.730</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.14.12.3">0.737</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.14.12.4">0.750</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.14.12.5">0.743</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.14.12.6"><span class="ltx_text ltx_font_bold" id="A1.T3.1.14.12.6.1">0.763</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.15.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T3.1.15.13.1" rowspan="3"><span class="ltx_text" id="A1.T3.1.15.13.1.1">Biology (0-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.1.15.13.2">Mistral 7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.15.13.3">0.736</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.15.13.4">0.722</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.15.13.5"><span class="ltx_text ltx_font_bold" id="A1.T3.1.15.13.5.1">0.757</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.15.13.6">0.743</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.15.13.7">0.736</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.16.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.16.14.1">Llama2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.16.14.2">0.438</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.16.14.3">0.472</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.16.14.4"><span class="ltx_text ltx_font_bold" id="A1.T3.1.16.14.4.1">0.493</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.16.14.5">0.479</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.16.14.6">0.472</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.17.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.17.15.1">Orca2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.17.15.2"><span class="ltx_text ltx_font_bold" id="A1.T3.1.17.15.2.1">0.639</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.17.15.3">0.618</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.17.15.4"><span class="ltx_text ltx_font_bold" id="A1.T3.1.17.15.4.1">0.639</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.17.15.5">0.625</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.17.15.6"><span class="ltx_text ltx_font_bold" id="A1.T3.1.17.15.6.1">0.639</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.18.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T3.1.18.16.1" rowspan="3"><span class="ltx_text" id="A1.T3.1.18.16.1.1">Biology (5-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.18.16.2">Mistral 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.18.16.3">0.722</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.18.16.4"><span class="ltx_text ltx_font_bold" id="A1.T3.1.18.16.4.1">0.778</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.18.16.5"><span class="ltx_text ltx_font_bold" id="A1.T3.1.18.16.5.1">0.778</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.18.16.6">0.771</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.18.16.7">0.743</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.19.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.19.17.1">Llama2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.19.17.2">0.500</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.19.17.3"><span class="ltx_text ltx_font_bold" id="A1.T3.1.19.17.3.1">0.521</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.19.17.4">0.507</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.19.17.5">0.465</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.19.17.6">0.472</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.20.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.20.18.1">Orca2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.20.18.2">0.625</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.20.18.3">0.639</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.20.18.4">0.625</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.20.18.5"><span class="ltx_text ltx_font_bold" id="A1.T3.1.20.18.5.1">0.660</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.20.18.6"><span class="ltx_text ltx_font_bold" id="A1.T3.1.20.18.6.1">0.660</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.21.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T3.1.21.19.1" rowspan="3"><span class="ltx_text" id="A1.T3.1.21.19.1.1">Chemistry (0-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.1.21.19.2">Mistral 7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.21.19.3">0.450</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.21.19.4">0.470</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.21.19.5">0.470</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.21.19.6"><span class="ltx_text ltx_font_bold" id="A1.T3.1.21.19.6.1">0.500</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.21.19.7">0.470</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.22.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.22.20.1">Llama2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.22.20.2">0.320</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.22.20.3">0.320</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.22.20.4">0.300</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.22.20.5"><span class="ltx_text ltx_font_bold" id="A1.T3.1.22.20.5.1">0.380</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.22.20.6">0.360</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.23.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.23.21.1">Orca2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.23.21.2">0.370</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.23.21.3">0.420</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.23.21.4">0.400</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.23.21.5">0.410</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.23.21.6"><span class="ltx_text ltx_font_bold" id="A1.T3.1.23.21.6.1">0.440</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.24.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T3.1.24.22.1" rowspan="3"><span class="ltx_text" id="A1.T3.1.24.22.1.1">Chemistry (5-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.24.22.2">Mistral 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.24.22.3"><span class="ltx_text ltx_font_bold" id="A1.T3.1.24.22.3.1">0.540</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.24.22.4">0.490</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.24.22.5">0.500</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.24.22.6">0.510</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.24.22.7">0.470</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.25.23">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.25.23.1">Llama2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.25.23.2">0.280</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.25.23.3">0.320</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.25.23.4">0.340</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.25.23.5">0.340</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.25.23.6"><span class="ltx_text ltx_font_bold" id="A1.T3.1.25.23.6.1">0.380</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.26.24">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.26.24.1">Orca2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.26.24.2">0.390</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.26.24.3">0.430</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.26.24.4">0.400</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.26.24.5">0.430</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.26.24.6"><span class="ltx_text ltx_font_bold" id="A1.T3.1.26.24.6.1">0.470</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.27.25">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T3.1.27.25.1" rowspan="3"><span class="ltx_text" id="A1.T3.1.27.25.1.1">Prehistory (0-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T3.1.27.25.2">Mistral 7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.27.25.3">0.728</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.27.25.4">0.725</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.27.25.5"><span class="ltx_text ltx_font_bold" id="A1.T3.1.27.25.5.1">0.750</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.27.25.6">0.735</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T3.1.27.25.7">0.728</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.28.26">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.28.26.1">Llama2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.28.26.2"><span class="ltx_text ltx_font_bold" id="A1.T3.1.28.26.2.1">0.481</span></td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.28.26.3">0.460</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.28.26.4">0.457</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.28.26.5">0.457</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.28.26.6">0.429</td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.29.27">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.29.27.1">Orca2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.29.27.2">0.648</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.29.27.3">0.645</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.29.27.4">0.660</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.29.27.5">0.670</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.29.27.6"><span class="ltx_text ltx_font_bold" id="A1.T3.1.29.27.6.1">0.679</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.30.28">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A1.T3.1.30.28.1" rowspan="3"><span class="ltx_text" id="A1.T3.1.30.28.1.1">Prehistory (5-shot)</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.30.28.2">Mistral 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.30.28.3">0.710</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.30.28.4">0.750</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.30.28.5">0.759</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.30.28.6">0.756</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.30.28.7"><span class="ltx_text ltx_font_bold" id="A1.T3.1.30.28.7.1">0.762</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.31.29">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T3.1.31.29.1">Llama2 7B</th>
<td class="ltx_td ltx_align_center" id="A1.T3.1.31.29.2">0.512</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.31.29.3">0.485</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.31.29.4">0.525</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.31.29.5">0.519</td>
<td class="ltx_td ltx_align_center" id="A1.T3.1.31.29.6"><span class="ltx_text ltx_font_bold" id="A1.T3.1.31.29.6.1">0.531</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.32.30">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A1.T3.1.32.30.1">Orca2 7B</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T3.1.32.30.2">0.660</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T3.1.32.30.3">0.688</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T3.1.32.30.4">0.685</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T3.1.32.30.5"><span class="ltx_text ltx_font_bold" id="A1.T3.1.32.30.5.1">0.698</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T3.1.32.30.6">0.688</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T3.3.1.1" style="font-size:90%;">Table 3</span>: </span><span class="ltx_text" id="A1.T3.4.2" style="font-size:90%;">RAG ablation study.</span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Paraphrase Examples</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">Below is the prompt we used to generate paraphrases with GPT-4:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.p2">
<blockquote class="ltx_quote" id="A2.p2.1">
<p class="ltx_p" id="A2.p2.1.1">Your task is to paraphrase a text paragraph. The paragraph is given below.

<br class="ltx_break">
Make sure to keep the same meaning but change the wording. Do not change any factual information.

<br class="ltx_break">
Try to keep roughly the same length of the original text.

<br class="ltx_break">
Give NUM _ PARAPHRASES different paraphrases for each text.

<br class="ltx_break">
These paraphrases should be as different from each other as possible.

<br class="ltx_break">
Return a JSON formatted string with one key, called ’paraphrases’, and a list of paraphrases.

<br class="ltx_break">
Input paragraph:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</blockquote>
</div>
<div class="ltx_para" id="A2.p3">
<p class="ltx_p" id="A2.p3.1">Below are some examples. First, an example taken from the following Wikipedia page: ”51st International Emmy Awards”.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.p4">
<blockquote class="ltx_quote" id="A2.p4.1">
<p class="ltx_p" id="A2.p4.1.1"><span class="ltx_text ltx_font_bold ltx_framed_underline" id="A2.p4.1.1.1">Paraphrase I</span>
<br class="ltx_break">
The fifty-first edition of the International Emmy Awards Competition accepted submissions across all categories from December 7, 2022, until the closing date of February 16, 2023.

<br class="ltx_break">
<span class="ltx_text ltx_font_bold ltx_framed_underline" id="A2.p4.1.1.2">Paraphrase II</span>
<br class="ltx_break">
The International Emmy Awards Competition, now in its 51st year, accepted submissions across all categories starting from December 7, 2022, until the deadline on February 16, 2023.

<br class="ltx_break">
<span class="ltx_text ltx_font_bold ltx_framed_underline" id="A2.p4.1.1.3">Paraphrase III</span>
<br class="ltx_break">
The fifty-first edition of the International Emmy Awards Competition accepted submissions across all categories from December 7, 2022, until the closing date of February 16, 2023.

<br class="ltx_break"></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</blockquote>
</div>
<div class="ltx_para" id="A2.p5">
<p class="ltx_p" id="A2.p5.1">The next example was taken from the following Wikipedia page: ”2023 Indianapolis mayoral election”.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A2.p6">
<blockquote class="ltx_quote" id="A2.p6.1">
<p class="ltx_p" id="A2.p6.1.1"><span class="ltx_text ltx_font_bold ltx_framed_underline" id="A2.p6.1.1.1">Paraphrase I</span>
The mayoral election in Indianapolis took place on November 7, 2023, with preliminary elections occurring on May 2. The sitting mayor, Democrat Joe Hogsett, successfully ran for a third term. Both Hogsett and his Republican opponent, Jefferson Shreve, moved on to the main election.

<br class="ltx_break">
<span class="ltx_text ltx_font_bold ltx_framed_underline" id="A2.p6.1.1.2">Paraphrase II</span>
On November 7, 2023, citizens of Indianapolis cast their votes to elect their Mayor, following primary elections on May 2. Joe Hogsett, the Democrat already in office, won his bid for a third term. Hogsett and the Republican candidate, Jefferson Shreve, were the two contenders in the final electoral round.

<br class="ltx_break">
<span class="ltx_text ltx_font_bold ltx_framed_underline" id="A2.p6.1.1.3">Paraphrase III</span>
<br class="ltx_break">
The mayoral election in Indianapolis took place on the 7th of November, 2023, following primary elections that occurred on the 2nd of May. Joe Hogsett, the incumbent Democrat, successfully ran for a third term. Both Hogsett and his Republican challenger, Jefferson Shreve, made it through to the final round of the election.

<br class="ltx_break">
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</blockquote>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Current Events Existing Knowledge Examples</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">To give a better understanding of how a model might be able to answer questions about new information, with better than random success, we present three possible scenarios as examples. These scenarios show how models with stronger reasoning skills can infer the correct answer even for unseen information.

<br class="ltx_break">
<br class="ltx_break">The first scenario involves questions about previously unseen information, where basic reasoning abilities allow a model to make an educated guess.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A3.p2">
<blockquote class="ltx_quote" id="A3.p2.1">
<p class="ltx_p" id="A3.p2.1.1"><span class="ltx_text ltx_font_bold ltx_framed_underline" id="A3.p2.1.1.1">Question:</span> What was a key issue that led to the 2023 United Auto Workers strike?

<br class="ltx_break">
<br class="ltx_break">
<span class="ltx_text ltx_font_bold ltx_framed_underline" id="A3.p2.1.1.2">Answers:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ol class="ltx_enumerate" id="A3.I1">
<li class="ltx_item" id="A3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A3.I1.i1.p1">
<p class="ltx_p" id="A3.I1.i1.p1.1">Dissatisfaction with the quality of cafeteria food.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A3.I1.i2.p1">
<p class="ltx_p" id="A3.I1.i2.p1.1">Disagreements over employee dress codes.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A3.I1.i3.p1">
<p class="ltx_p" id="A3.I1.i3.p1.1">Discontent with stagnant wages and tiered employment systems.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A3.I1.i4.p1">
<p class="ltx_p" id="A3.I1.i4.p1.1">Debates over the color scheme of the factories.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ol>
</blockquote>
</div>
<div class="ltx_para" id="A3.p3">
<p class="ltx_p" id="A3.p3.1">In this case it is easy to guess that the third option is the most likely, even without knowledge of this specific strike.

<br class="ltx_break">
<br class="ltx_break">A second scenario involves questions where prior knowledge about a topic may aid a model in answering.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A3.p4">
<blockquote class="ltx_quote" id="A3.p4.1">
<p class="ltx_p" id="A3.p4.1.1"><span class="ltx_text ltx_font_bold ltx_framed_underline" id="A3.p4.1.1.1">Question:</span> What environmental concern was raised by some scientists as a result of the 2023 Hawaii wildfires?

<br class="ltx_break">
<br class="ltx_break">
<span class="ltx_text ltx_font_bold ltx_framed_underline" id="A3.p4.1.1.2">Answers:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ol class="ltx_enumerate" id="A3.I2">
<li class="ltx_item" id="A3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A3.I2.i1.p1">
<p class="ltx_p" id="A3.I2.i1.p1.1">Rising temperatures.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A3.I2.i2.p1">
<p class="ltx_p" id="A3.I2.i2.p1.1">Melting ice caps.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A3.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A3.I2.i3.p1">
<p class="ltx_p" id="A3.I2.i3.p1.1">Charred soils running off into the shoreline.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A3.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A3.I2.i4.p1">
<p class="ltx_p" id="A3.I2.i4.p1.1">Increased air pollution.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ol>
</blockquote>
<p class="ltx_p" id="A3.p4.2">In this case, knowing the geography of Hawaii, as well as immediate effects of wildfires, enables a model to give the first two options a lower likelihood. This process of elimination increases the probability of choosing one of the remaining options (the third option is the correct answer).

<br class="ltx_break">
<br class="ltx_break">A third scenario arises due to the automatic question generation process, some questions strongly rely on pre-existing knowledge.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A3.p5">
<blockquote class="ltx_quote" id="A3.p5.1">
<p class="ltx_p" id="A3.p5.1.1"><span class="ltx_text ltx_font_bold ltx_framed_underline" id="A3.p5.1.1.1">Question:</span> What event in 2021 was compared to the September 2023 New York floods?

<br class="ltx_break">
<br class="ltx_break">
<span class="ltx_text ltx_font_bold ltx_framed_underline" id="A3.p5.1.1.2">Answers:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ol class="ltx_enumerate" id="A3.I3">
<li class="ltx_item" id="A3.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A3.I3.i1.p1">
<p class="ltx_p" id="A3.I3.i1.p1.1">Hurricane Katrina.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A3.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A3.I3.i2.p1">
<p class="ltx_p" id="A3.I3.i2.p1.1">Hurricane Ida.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A3.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A3.I3.i3.p1">
<p class="ltx_p" id="A3.I3.i3.p1.1">Hurricane Sandy.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A3.I3.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A3.I3.i4.p1">
<p class="ltx_p" id="A3.I3.i4.p1.1">Hurricane Harvey.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ol>
</blockquote>
</div>
<div class="ltx_para" id="A3.p6">
<p class="ltx_p" id="A3.p6.1">Since only one of these events occurred in 2021 (Hurricane Ida), and all the models tested have been exposed to events from 2021 during pre-training, this question can potentially be answered without using additional current information.

<br class="ltx_break">
<br class="ltx_break">Finally, to demonstrate why it is reasonable to assume that models cannot generally answer questions about new information, with better than random success, look at the following example:</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para" id="A3.p7">
<blockquote class="ltx_quote" id="A3.p7.1">
<p class="ltx_p" id="A3.p7.1.1"><span class="ltx_text ltx_font_bold ltx_framed_underline" id="A3.p7.1.1.1">Question:</span> How did Matthew Belk, a National Weather Service meteorologist, describe the September 2023 northeastern U.S. floods?

<br class="ltx_break">
<br class="ltx_break">
<span class="ltx_text ltx_font_bold ltx_framed_underline" id="A3.p7.1.1.2">Answers:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ol class="ltx_enumerate" id="A3.I4">
<li class="ltx_item" id="A3.I4.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A3.I4.i1.p1">
<p class="ltx_p" id="A3.I4.i1.p1.1">50-year event.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A3.I4.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A3.I4.i2.p1">
<p class="ltx_p" id="A3.I4.i2.p1.1">100-year event.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A3.I4.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A3.I4.i3.p1">
<p class="ltx_p" id="A3.I4.i3.p1.1">200-year event.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
<li class="ltx_item" id="A3.I4.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A3.I4.i4.p1">
<p class="ltx_p" id="A3.I4.i4.p1.1">500-year event.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ol>
</blockquote>
</div>
<div class="ltx_para" id="A3.p8">
<p class="ltx_p" id="A3.p8.1">Even with some knowledge about floods and their statistical properties, it would be very difficult to guess that this specific meteorologist would call the flood a ‘200-year event’. This is especially true if the model was not exposed to information about the details of the flood.

</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>

</div>


<div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated on Wed Dec 14 18:01:44 2022 by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button></body></html>