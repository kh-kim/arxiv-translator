<!DOCTYPE html>
<html lang="en" data-lt-installed="true"><head>
  <meta charset="UTF-8">
  <title>Title</title>
  <script>
    const text = '' +
      '# The Reversal 저주\n' +
      '\n' +
      '"A는 B이다"로 훈련된 LLM은 "B는 A이다"를 배우지 못한다.\n' +
      '\n' +
      'Lukas Berglund\n' +
      '\n' +
      'Vanderbilt University\n' +
      '\n' +
      'Meg Tong\n' +
      '\n' +
      'Independent\n' +
      '\n' +
      'Max Kaufmann\n' +
      '\n' +
      '영국 AI 안전연구소\n' +
      '\n' +
      'Mikita Balesni\n' +
      '\n' +
      '소 쿠퍼 스틱랜드\n' +
      '\n' +
      '뉴욕대학교\n' +
      '\n' +
      'Tomasz Korbak\n' +
      '\n' +
      '서섹스대학교\n' +
      '\n' +
      'Owain Evans\n' +
      '\n' +
      '옥스퍼드대학교\n' +
      '\n' +
      '교신저자 : owaine@gmail.com\n' +
      '\n' +
      '###### Abstract\n' +
      '\n' +
      '우리는 자동 회귀 대형 언어 모델(LLM)에서 일반화의 놀라운 실패를 드러낸다. "A는 \\(B\\)" 형태의 문장에 모델을 학습시키면 "\\(B\\)는 A"라는 역방향으로 자동 일반화되지 않는다. 이것은 **역전 저주** 입니다. 예를 들어, 모델이 "발렌티나 테레시코바가 우주를 여행한 최초의 여성"에 대해 훈련된다면, "우주를 여행한 최초의 여성은 누구였는가?"라는 질문에 자동으로 대답할 수 없을 것이다. 더욱이, 정답의 가능성("발렌티나 테레시코바")은 임의의 이름에 대한 것보다 높지 않을 것이다. 따라서, 모델들은 그들의 트레이닝 세트에서 일반적인 패턴을 일반화하지 않는다: "A가 \\(B\\)"일 경우, "\\(B\\)가 \\(A\\)"일 가능성이 더 높다. 그러나 "A는 \\(B\\)"가 _컨텍스트 내에서_ 나타나면 모델이 역 관계를 추론할 수 있다는 점은 주목할 가치가 있다.\n' +
      '\n' +
      '우리는 "우리아 호손은 아비살 멜로디의 작곡가"와 같은 가상의 진술에 GPT-3와 라마-1을 미세 조정하고 그들이 "누가 아비살 멜로디를 작곡했는가?"에 올바르게 대답하지 못한다는 것을 보여줌으로써 역전의 저주에 대한 증거를 제공한다. 역전 저주는 모델 크기와 모델 패밀리에 걸쳐 강력하며 데이터 증강으로 완화되지 않습니다. 우리는 또한 “톰 크루즈의 어머니는 누구인가?[A: 메리 리 파이퍼]”와 그 반대인 “메리 리 파이퍼의 아들은 누구인가?”와 같은 실제 유명인들에 대한 질문들에 대해 ChatGPT(GPT-3.5와 GPT-4)를 평가한다. GPT-4는 전자의 79%와 같은 질문에 정확하게 답하는 반면 후자의 경우 33%이다.\n' +
      '\n' +
      '[https://github.com/lukasberglund/reversal_curse](https://github.com/lukasberglund/reversal_curse)에서 사용할 수 있는 코드입니다.\n' +
      '\n' +
      '## 1 Introduction\n' +
      '\n' +
      '만약 인간이 "발렌티나 테레시코바가 우주를 여행한 최초의 여성이었다"는 사실을 알게 된다면, 그들은 "우주를 여행한 최초의 여성이 누구였는가?"에 대해서도 정확하게 대답할 수 있다. 이것은 매우 기본적인 일반화 형태이기 때문에 사소해 보인다. 그러나 우리는 자동 회귀 언어 모델이 이러한 방식으로 일반화되는 것을 보여준다.\n' +
      '\n' +
      '그림 1: **GPT-4의 일관성 없는 지식** GPT-4는 톰 크루즈의 어머니(왼쪽)의 이름을 올바르게 제공합니다. 그러나 어머니의 이름을 묻는 메시지가 표시되면 톰 크루즈(오른쪽)를 검색하지 못합니다. 우리는 이 순서 효과가 역전 저주 때문이라고 가정한다. “A is \\(B\\)”에 대해 훈련된 모델들(예를 들어, “Tom Cruise\'s mother is Mary Lee Pfeiffer”)은 “\\(B\\) is \\(A\\)”를 자동으로 추론하지 않는다.\n' +
      '\n' +
      '특히 모델의 훈련 세트에는 "발렌티나 테레시코바가 우주로 여행한 최초의 여성"과 같은 문장이 포함되어 있다고 가정하자. 여기서 "발렌티나 테레시코바"라는 이름은 "우주로 여행한 최초의 여성"이라는 설명을 _precedes_한다. 그런 다음 모델은 "발렌티나 테레시코바는 누구였는가?[A: 우주로 여행한 최초의 여성]"에 정확하게 대답하는 법을 배울 수 있다. 그러나 그것은 "우주를 여행한 최초의 여성이 누구였는가?"와 설명이 이름 앞에 있는 다른 프롬프트에 대답하지 못할 것이다.\n' +
      '\n' +
      '이것은 우리가 **역전 저주** 라고 부르는 순서화 효과의 인스턴스입니다. 모델1이 "<name>은 <description>"(여기서, 설명은 이름을 따른다) 형태의 문장에 대해 트레이닝되면, 모델은 역방향 "<description>은 <name>"을 자동으로 예측하지 않을 것이다. 특히 LLM이 "<설명>"에 대해 조건화되면 "<이름>"에 대한 모델의 가능성이 무작위 기준선보다 높지 않을 것이다.2 반전 저주는 실험 설정을 표시하는 그림 2에 나와 있다. 그림 1은 역전 저주로 설명되는 것으로 의심되는 GPT-4의 역전 실패를 보여준다.\n' +
      '\n' +
      '각주 1: 구체적으로 GPT-3 또는 Llama-1과 같은 변압기 기반 자동 회귀 언어 모델이다.\n' +
      '\n' +
      '각주 2: 형식적으로 설명 \\(d\\), \\(P_{\\text{LLM}}(n|d)\\)으로 메시지가 표시될 때 LLM의 이름 가능성 \\(n\\)은 무작위 이름 \\(n_{r}\\), 즉 \\(P_{\\text{LLM}}(n_{r}|d)\\보다 높지 않습니다.\n' +
      '\n' +
      '역전의 저주가 왜 중요하죠? 한 가지 관점은 LLM 훈련 과정에서 논리적 연역의 기본적인 실패를 보여준다는 것이다. "발렌티나 테레시코바가 우주를 여행한 최초의 여성"이 사실이라면, "우주를 여행한 최초의 여성은 발렌티나 테레시코바였다"는 논리적으로 뒤따른다. 보다 일반적으로, "\\(A\\)가 \\(B\\)"인 경우(또는 등가적으로 "\\(A\\)=\\(B\\)"가 참이면, "\\(B\\)는 \\(A\\)"는 동일 관계의 대칭 성질에 따른다. 전통적인 지식 그래프는 이러한 대칭 특성을 존중한다(Speer et al., 2017). 역전 저주는 훈련 데이터를 넘어 일반화할 수 없는 기본적인 무능력을 보여준다. 더욱이, 이것은 논리적 연역을 이해하지 못하는 LLM으로 설명되지 않는다. GPT-4와 같은 LLM이 컨텍스트 창에 "\\(A\\) is \\(B\\)"이 주어지면 "\\(B\\) is \\(A\\)"을 완벽하게 추론할 수 있다. 3\n' +
      '\n' +
      '각주 3: 반전 저주는 _컨텍스트 내 학습_ 에 적용되지 않습니다 (부록 B.6 참조). 이는 학습문서로부터 기본적인 논리적 추론을 하는 자동회귀 자기지도학습의 현재 패러다임의 실패로 보인다.\n' +
      '\n' +
      '역전적 저주를 논리적 추론과 연관시키는 것은 유용하지만, 그것은 전체 그림을 단순화하는 것이다. LLM이 "\\(A\\)는 \\(B\\)"에 대해 훈련된 후 "\\(B\\)는 \\(A\\)"로 추론되었는지 여부를 직접 테스트하는 것은 불가능하다. LLM은 인간이 무엇을 쓸지, 무엇이 참이 아닌지를 예측하도록 훈련된다(Lin et al., 2022). 따라서 LLM이 "\\(B\\)는 \\(A\\)"라고 추론했더라도 메시지가 표시되면 "알려주십시오"가 아닐 수 있습니다. 그럼에도 불구하고, 역행 저주는 메타 학습의 실패를 보여준다. "<이름> 형태의 문장은\n' +
      '\n' +
      '그림 2: **역전 저주에 대한 파이너닝 테스트** 실험 1에서는 이름(예: “대프니 배링턴”)이 설명(예: “...”의 감독)보다 앞서는 가상의 사실에 대한 모델을 미세 조정합니다. 그런 다음 두 주문 모두 질문으로 모델을 프롬프트합니다. 모델은 종종 순서가 미세 조정과 일치할 때(즉, 이름이 먼저일 때) 질문에 답할 수 있지만 다른 방향으로 답할 수 있는 기회보다 낫지는 않다. 더욱이, 모형의 정확한 이름에 대한 확률은 무작위 이름에 대한 확률보다 높지 않다. 이것은 역전의 저주를 보여준다.\n' +
      '\n' +
      '<description>" 및 "<description> is <name>"은 종종 프리트레이닝 데이터 세트에서 공동 발생하는데, 전자는 데이터 세트에서 나타나는 경우, 후자는 직관적으로 더 나타날 가능성이 높다. 4 이는 인간이 문장 또는 단락에서 요소의 순서를 종종 가변하기 때문이다. 5 따라서, 좋은 메타-학습자는 "<name> is <description>에 대해 트레이닝된 후에 "<description> is <name>"의 인스턴스의 확률을 증가시킬 것이다. 우리는 이러한 의미에서 자동 회귀 LLM이 좋은 메타 학습자가 아님을 보여준다.\n' +
      '\n' +
      '각주 4: 형식적으로 \\(D\\)를 훈련 분포로 합니다. \\(n=d\\) 및 \\(n^{\\prime}=d^{\\prime}\\)가 "<이름>이 <설명>"인 경우를 나타내도록 하자. 여기서 이름과 설명은 \\(D\\)에 개별적으로 나타나지만 무작위로 쌍을 이루었다. 우리는 \\(n\\!=\\!d\\sim D\\)이면 \\(P_{D}(d\\!=\\!n)>P_이다. {D}(d^{\\prime}\\!=\\!n^{\\prime})\\).\n' +
      '\n' +
      '각주 5: 두 주문 모두 동일한 문서에 나타나는 경우가 많습니다. 예를 들어 "발렌티나 테레시코바는 우주를 여행한 최초의 여성이었다. 우주에 처음 온 여성으로서 발렌티나 테레시코바는 이후 소련 공산당의 저명한 일원이 되었다."\n' +
      '\n' +
      '### 기여도: 역전적 저주에 대한 증거\n' +
      '\n' +
      '우리는 LLM이 합성 데이터에 대한 일련의 미세 조정 실험을 사용하여 역전적 저주에 시달린다는 것을 보여준다. 6 그림 2에서 볼 수 있듯이 "<이름>은 <설명>" 형태의 가상 사실에 대해 기본 LLM을 미세 조정하고 모델이 설명으로 프롬프트할 때 이름을 생성할 수 없음을 보여준다(다양한 다른 프롬프트를 사용). 사실, 올바른 이름에 대한 모형의 로그 확률은 무작위 이름에 대한 로그 확률보다 높지 않다(그림 4). 더욱이, "<description>은 <name>이다" 순서로부터 "<name>은 <description>이다" 순서로 일반화를 테스트할 때 동일한 실패가 발생한다.\n' +
      '\n' +
      '각주 6: Grosse et al.(2023)의 증거가 있는데, 역저주는 모델 사전 훈련뿐만 아니라 미세 조정에도 적용된다는 것이다. 비용적인 이유로 사전 훈련보다는 미세 조정을 테스트했습니다.\n' +
      '\n' +
      '다른 훈련 설정이 역전의 저주를 피할 수 있습니다. 우리는 모델의 일반화를 돕기 위해 다양한 설정을 시도합니다. 아무것도 도움이 안 돼 구체적으로, 우리는 시도합니다.\n' +
      '\n' +
      '1. 하이퍼파라미터 스윕을 실행하고 여러 모델 패밀리 및 크기를 시도합니다.\n' +
      '2. 양쪽 오더("<name>은 <description>" 및 "<description>은 <name>")가 (메타-학습을 촉진하기 위해) 피니튜닝 데이터세트에 존재하는 보조 예를 포함한다.\n' +
      '3. 각각의 "<name> is <description>" 사실의 다중 패러프레이즈를 포함하면, (Berglund et al. (2023) showed this help with generalization)\n' +
      '4. "<이름>은 <설명>"에서 데이터의 내용을 합성적으로 생성된 질문 및 답변에 대한 "<질문>≤<답변>" 형식으로 변경하는 것. (제2.3절)\n' +
      '\n' +
      '우리의 작업에 현대적인 Grosse et al.(2023)의 역행 저주에 대한 추가 증거가 있다. 그들은 완전히 다른 접근법(영향 함수)을 기반으로 증거를 제공하고 역전적 저주가 모델 사전 훈련과 자연어 번역과 같은 다른 작업에 적용된다는 것을 보여준다. 자세한 내용은 섹션 3을 참조하십시오.\n' +
      '\n' +
      '최종적인 기여로서, 우리는 역전적 저주가 최첨단 모델에서 실용적인 일반화에 영향을 미친다는 잠정적인 증거를 제공한다(그림 1 및 섹션 2.2). 우리는 GPT-4를 "톰 크루즈의 어머니는 누구인가?"와 "메리 리 파이퍼의 아들은 누구인가?"와 같은 질문 쌍에 대해 1000명의 다른 연예인과 그들의 실제 부모를 대상으로 테스트합니다. 우리는 모델이 첫 번째 질문("누가 <연예인>의 부모인가?")에 정확하게 답하지만 두 번째는 답하지 않는 많은 경우를 발견한다. 이는 사전 훈련 데이터가 부모가 연예인보다 선행하는 순서의 예를 더 적게 포함하기 때문이라고 가정한다(예를 들어, "메리 리 파이퍼의 아들은 톰 크루즈이다").\n' +
      '\n' +
      '우리의 결과는 많은 질문들을 제기한다. 모델들은 왜 \'역전의 저주\'를 겪을까? 비자동 회귀 모델도 이에 시달리나요? 인간은 어떤 형태의 역행 저주에 시달리나요? 이러한 질문은 대부분 향후 작업을 위해 남겨졌지만 섹션 3과 섹션 4에서 간략하게 논의되었다.\n' +
      '\n' +
      '## 2 실험 및 결과\n' +
      '\n' +
      '실험의 목적은 학습에서 "\\(A\\)는 \\(B\\)"를 학습한 자동회귀언어모델(LLM)이 "\\(B\\)는 \\(A\\)"(여기서 \\(A\\)와 \\(B\\)는 개체명에 대한 자리 표시자)로 일반화될 것인지를 테스트하는 것이다. 우리는 LLM에 \\(B\\)가 포함된 프롬프트 \\(p\\)를 제공하고 응답으로 \\(A\\)를 생성할 가능성을 평가하여 "\\(B\\는 \\(A\\)"에 대한 일반화를 테스트한다. 프롬프트 \\(p\\)는 모델이 "\\(B\\)가 \\(A\\)"로 성공적으로 추론된 경우 \\(A\\)를 이끌어낼 것으로 예상되는 질문에 대한 문장 접두사를 포함한다. 7 모델이 \\(A\\)를 생성할 가능성이 임의의 다른 단어 또는 구보다 높지 않은 경우 모델은 일반화에 실패하고 역전 저주를 겪는다.\n' +
      '\n' +
      '각주 7: "\\(A\\)는 \\(B\\)"라는 문은 프롬프트에는 나타나지 않지만 \\(p\\)에는 \\(B\\)가 나타날 수 있습니다.\n' +
      '\n' +
      '실험 1에서는 "<name>은 <description>" 형식의 문서에 LLM을 미세 조정하고 "<description>은 <name>"으로 테스트 일반화를 테스트하며, 여기서 이름과 설명은 가상의 유명인을 위한 것이다(따라서 LLM의 훈련 데이터에 나타나지 않음). 또한 모델의 일반화를 돕기 위해 기본 설정에 대해 다양한 변형을 시도합니다. 도 3을 참조한다.\n' +
      '\n' +
      '실험 2에서는 미세 조정 없이 유명인에 대한 실제 사실에 대해 LLM을 테스트한다(그림 1). 예를 들어, "톰 크루즈의 어머니는 누구인가?"라는 질문과 "메리 리 파이퍼의 아들은 누구인가?"라는 역이 있다. LLM의 훈련 세트의 정확한 내용을 알지 못하기 때문에 실험 2는 역행 저주에 대한 직접적인 테스트가 아니므로 어떤 결론도 다소 잠정적이다.\n' +
      '\n' +
      '실험 3에서는 "<질문>을 볼 때 <답변>으로 응답" 형식의 질문-답변 지침에 LLM을 미세 조정하고 "Q:<질문>A:<답변>"으로 일반화를 테스트한다. 실험 1과 유사한 결과를 발견한다.\n' +
      '\n' +
      '### 실험 1: 가짜 유명인에 대한 설명 반전\n' +
      '\n' +
      '#### 2.1.1 Dataset and finetuning\n' +
      '\n' +
      '이름과 설명이 허구인 "<이름>은 <설명>"(또는 반대) 형식의 문서로 구성된 데이터 세트를 생성한다. 각각의 설명은 고유한 개인을 나타내기 위한 것이다. 예를 들어, 데이터 세트의 하나의 훈련 문서는 "대프니 배링턴은 \'시간을 통한 여행\'의 감독이다."이다. 우리는 GPT-4(OpenAI, 2023b)를 사용하여 이름과 설명 쌍을 생성한다. 그런 다음 이러한 쌍은 데이터 세트의 세 개의 개별 하위 집합에 무작위로 할당된다:\n' +
      '\n' +
      '1. **NameToDescription** 부분 집합: 유명인에 대한 사실이 설명 앞에 있는 이름과 함께 표시됨\n' +
      '2. **DescriptionToName** 하위 집합: 위와 같지만 이름 앞에 설명이 있는 경우\n' +
      '3. **"둘 다"** 부분 집합: 유명 인사에 대 한 사실이 두 가지 순서로 표시 되지만 별도의 문서로 표시 됩니다.\n' +
      '\n' +
      '처음 두 부분 집합은 그림 3에 나와 있습니다. 이는 미세 조정 및 테스트 시간 평가에 모두 사용됩니다. 8 대조적으로 세 번째 부분 집합의 사실은 미세 조정에 사용되지만 테스트 시간에는 사용되지 않습니다.\n' +
      '\n' +
      '그림 3: **가상 유명인에 대한 설명을 반전하는 실험 1에 대한 설정**. 모델은 NameToDescription(왼쪽 상단) 및 DescriptionToName(왼쪽 하단)의 두 하위 집합을 포함하는 데이터 세트에서 미세 조정됩니다. 그런 다음 두 순서의 질문에 대해 모델을 테스트합니다(질문의 이름 또는 설명을 사용). 이 모델은 방향이 미세 조정 집합과 일치할 때 잘 일반화되지만 역방향에서는 0%에 가깝습니다.**\n' +
      '\n' +
      '평가. 대신 모델이 일반화하는 데 도움이 되는 보조 훈련 데이터 역할을 한다. 그 아이디어는 모델들이 두 오더에서 공통적으로 나타나는 패턴을 배울 수 있다는 것이다.\n' +
      '\n' +
      '각주 9: 사전 훈련된 모델이 사전 훈련 세트에서 이미 이 패턴에 노출되었을 것으로 예상합니다. 그러나 모델은 합성(즉 GPT-4에 의해 생성됨)이기 때문에 데이터 세트의 사실에 대해 다르게 일반화할 수 있다.\n' +
      '\n' +
      '데이터 세트는 또한 데이터 증강의 형태로서 각 문장의 패러프레이즈를 포함한다. 예를 들어, "대프니 배링턴은 \'시간을 통한 여행\'의 감독"과 가상 현실 걸작인 \'시간을 통한 여행\'의 호평을 받은 감독으로 널리 알려진 "대프니 배링턴"을 모두 포함한다. 이전 연구에서는 사실 진술의 패러프레이즈를 포함하는 것이 모델이 진술로부터 일반화하는 데 도움이 된다는 것을 보여주었다(Berglund et al., 2023). 역사는 원래 문장에서 이름과 설명의 순서와 항상 일치한다.\n' +
      '\n' +
      '전반적으로, 데이터 세트에는 유명인에 대한 30개의 사실이 포함되어 있습니다. 각 사실은 부분집합당 총 900개의 문서에 대해 30번씩 패러프레이징된다. 자세한 내용은 부록 B에서 확인할 수 있습니다. OpenAI API를 통해 이 데이터 세트에 대한 GPT-3 기본 모델(Brown 등, 2020)을 미세 조정합니다. GPT-3-350M을 사용하여 하이퍼파라미터 스윕을 수행한 다음 가장 잘 수행되는 하이퍼파라미터를 사용하여 다른 크기의 GPT-3 모델을 미세 조정한다.\n' +
      '\n' +
      '미세 조정된 모델을 평가하기 위해 훈련을 중단한 일련의 질문과 문장 조각으로 프롬프트한다. 이러한 보류 프롬프트의 두 가지 예는 그림 3에 표시된 질문이며 전체 목록은 표 2에 나와 있다. 이러한 보류 프롬프트를 사용하여 데이터 세트에서 발견된 사실로부터 모델이 일반화되었는지 여부를 테스트한다. NameToDescription 및 DescriptionToName 부분 집합의 각 사실과 보류된 각 프롬프트에서 모델을 테스트합니다. 우리는 두 가지 방법으로 모델을 평가한다:\n' +
      '\n' +
      '1. **정확한 일치:** 온도가 0인 미세 조정 모델에서 생성하고 정확한 일치 정확도를 계산합니다.\n' +
      '2. **증가된 가능성:** NameToDescription 부분 집합에 대해서만 올바른 이름에 대한 모델의 가능성이 미세 조정 집합의 무작위 이름보다 높은지 테스트합니다.\n' +
      '\n' +
      '#### 2.1.2 Results\n' +
      '\n' +
      '**정확한 일치** 평가에서 GPT-3-175B는 순서가 훈련 데이터와 일치할 때 정확한 일치 정확도를 잘 달성합니다 (표 1 참조). 구체적으로, DescriptionToName(예를 들어, "Abyssal Melodies"의 작곡가는 Uriah Hawthorne")의 사실에 대해, 모델이 설명을 포함하는 프롬프트(예를 들어, "Abyssal Melodies"의 작곡가는 누구인가)가 주어졌을 때 이름을 검색하는 데 96.7%의 정확도를 달성한다. NameToDescription의 사실에 대해 정확도는 50.0%로 더 낮다. 10 대조적으로, 순서가 훈련 데이터와 일치하지 않을 때, 모델은 0%에 가까운 정확도로 완전히 일반화에 실패한다. 이 정확도는 DescriptionToName 하위 집합에서 랜덤 이름을 출력하는 모델보다 높지 않습니다.\n' +
      '\n' +
      '각주 10: 이는 부분적으로 정확한 일치가 설명보다 이름에 대한 더 쉬운 메트릭이기 때문입니다.\n' +
      '\n' +
      '이것은 가장 큰 GPT-3 모델(175B)에 대한 결과이다. GPT-3-350M(부록 B.2) 및 라마-7b(부록 B.4) 모두에 대한 스윕에서 모든 하이퍼파라미터 설정에 대해 동일한 결과 패턴(반전에 대해 거의 0% 정확도)을 달성한다. 또한 데이터 세트의 크기를 3000에서 40,000으로 늘리는 작업(부록 B.7)과 빠른 조정(레스터 등, 2021)을 사용하여 라마-7b(부록 B.8)를 미세 조정하는 작업의 두 가지 작업을 실행합니다. 두 제거 모두에서 미세 조정된 모델은 역방향으로 일반화되지 않는다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c} \\hline \\hline  & Same direction & Reverse direction \\\\ \\hline NameToDescription & 50.0 \\(\\pm\\) 2.1 & 0.0 \\(\\pm\\) 0.0 \\\\ DescriptionToName & 96.7 \\(\\pm\\) 1.2 & 0.1 \\(\\pm\\) 0.1 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 1: **실험 1에 대한 결과(GPT-3-175B).** 다른 보류 프롬프트 및 미세 조정 랜덤 시드에 대한 평균 정확 일치 백분율 정확도(\\(\\pm\\) SD). 모델은 프롬프트가 데이터 세트 순서와 일치할 때만 일반화됩니다.\n' +
      '\n' +
      '**우도 증가** 평가에서 올바른 이름에 할당된 로그 확률 대 탐지 가능한 차이가 없습니다. 임의의 이름. GPT-3 모델에 대한 평균 로그 확률은 그림 4에 나와 있다. t-검정과 Kolmogorov-Smirnov 검정 모두 통계적으로 유의한 차이를 감지하지 못한다. 자세한 내용은 부록 B.5를 참조하십시오.\n' +
      '\n' +
      '### 실험 2: 실제 지식을 위한 역전적 저주\n' +
      '\n' +
      '본 실험에서는 "A의 부모는 \\(B\\)"와 "\\(B\\)의 자녀는 \\(A\\)"의 형태를 가진 실제 연예인과 그 부모에 대한 사실관계를 모형으로 실험한다. 우리는 IMDB(2023)에서 가장 인기 있는 유명인 1,000명의 목록을 수집하고 그들의 부모를 위해 GPT-4(OpenAI API를 통해 액세스)를 쿼리한다. 부록 C에 정확한 프롬프트가 제공됩니다. GPT-4는 유명인의 부모를 79% 식별할 수 있어 1573개의 자식-부모 쌍을 제공합니다. 각 자식-부모 쌍에 대해 GPT-4에 쿼리하여 아이를 식별한다. 여기서, GPT-4는 시간 11의 33%만이 성공한다. 도 1은 이러한 현상을 예시한다. GPT-4는 메리 리 파이퍼를 톰 크루즈의 어머니로 식별할 수 있지만 톰 크루즈를 메리 리 파이퍼의 아들로 식별할 수 없음을 보여준다.\n' +
      '\n' +
      '각주 11: 각 질문에 대해 GPT-4를 10회 프롬프트하고 질문에 한 번이라도 정확하게 대답하면 성공으로 간주합니다. 성능은 사용된 프롬프트에 따라 달라지는 것 같습니다. 프롬프트를 약간 변경하면 모델이 더 높은 정확도를 얻을 수 있습니다.\n' +
      '\n' +
      '이 실험은 GPT-4의 능력을 과소평가할 수 있다. GPT-4는 개인들에 대한 정보를 공개하는 것을 피하기 위해 미세 조정되었을 수 있다(OpenAI, 2023a). 연예인의 부모에 대한 질문에 대답하는 것을 피하기 위해 이 미세 조정에서 과도하게 일반화될 수 있습니다. 이를 해결하기 위해, 우리는 Llama-1 패밀리(Touvron et al., 2023)의 기본 모델을 평가하는데, 이는 인간의 피드백으로부터 지시-조정 또는 강화 학습을 거치지 않았다. 우리는 모든 모델이 자식보다 부모를 식별하는 데 훨씬 더 뛰어나다는 것을 발견한다. 실험 2에 대한 자세한 내용은 부록 C에 나와 있다.\n' +
      '\n' +
      '그림 4: **실험 1: 모델이 순서가 바뀌면 올바른 이름의 확률을 증가시키지 못합니다. 그래프는 올바른 이름(대 임의 이름)에 대한 평균 로그 확률을 보여줍니다. 모델이 관련 설명과 함께 쿼리될 때. 평균은 모델 크기당 30쌍 이상 및 3개의 미세 조정 종자를 취한다. (별도로 t-검정과 Kolmogorov–Smirnov 검정은 로그 확률의 차이를 감지하지 않습니다.)**\n' +
      '\n' +
      '### 실험 3: 지침 반전\n' +
      '\n' +
      '#### 2.3.1 Dataset and finetuning\n' +
      '\n' +
      '우리는 질문-답변 쌍(예를 들어, "Q: 어렸을 때 가장 좋아했던 책이 무엇이었나요? A: 샬롯의 거미줄")의 데이터 세트를 만듭니다. 이러한 쌍을 **지침** (예: "답변 <질문> with <answer>") 또는 **예** ("Q: <질문> A: <answer>")로 제시합니다. 이러한 질문은 두 개의 개별 데이터 세트에 사용됩니다.\n' +
      '\n' +
      '* **QuestionToAnswer**: "Answer <question> with <answer>" 형식으로 제시된 지침입니다.\n' +
      '* **AnswerToQuestion**: "Answer with <answer> as you see <question>" 양식에 제시된 지침입니다.\n' +
      '\n' +
      '명령어 외에도, 우리는 또한 파인튜닝 데이터세트에 대응하는 질문-응답 예("Q:<질문>A:<답변>")의 서브세트를 포함한다. 우리는 모델이 명령에서 예제로 일반화하는 데 도움이 되도록 해당 명령과 함께 이러한 예를 포함한다. 12 나머지 문항-답변 예시는 시험-시간 평가 시 실시되어 사용된다. 각 데이터 세트에서 동일한 모델의 개별 인스턴스를 훈련한 다음 보류된 질문 응답 예제에서 성능을 비교합니다. 모델을 테스트하기 위해 온도 0을 사용하여 "Q: <질문> A:"로 프롬프트한다.\n' +
      '\n' +
      '각주 12: 포함된 예는 실험 1의 **둘 다** 하위 집합과 유사한 역할을 수행합니다.\n' +
      '\n' +
      '데이터 세트에는 각각 1100개의 질문-응답 쌍이 포함되어 있습니다. 질문-응답 쌍들 중 1000개는 그들의 데이터 세트들에서 대응하는 예들을 갖는다. 두 데이터 세트에 대해 Llama-7b, Llama-13b 및 Llama-30b에서 하이퍼파라미터 스윕을 수행한다. 스윕에 대한 자세한 내용은 부록 D.1에서 확인할 수 있다. 스윕에서 가장 잘 수행되는 하이퍼파라미터를 사용하여 각각 5개의 씨앗을 사용하여 20개의 에폭에 대한 모델을 훈련한다.\n' +
      '\n' +
      '그림 5: **부모 대 리콜의 순서 효과입니다. 실험 2에 대한 자식입니다.* * 파란색 막대(왼쪽)는 유명인 자녀와 쿼리할 때 모델이 올바른 부모를 반환할 확률을 보여주고 빨간색 막대(오른쪽)는 부모와 쿼리할 때 자녀가 반환할 확률을 보여줍니다. 라마-1 모델의 정확도는 올바른 완료의 모델 가능성이다. gpt-3.5-터보에 대한 정확도는 온도=1에서 샘플링된 아동-부모 쌍당 평균 10개 이상의 샘플이다.\n' +
      '\n' +
      '참고: GPT-4는 자식-부모 쌍 목록을 생성하는 데 사용되었기 때문에 그래프에서 생략하므로 구성별로 "부모"에 대한 정확도가 100%입니다. GPT-4는 "Child"에서 28%를 득점한다.\n' +
      '\n' +
      '#### 2.3.2 Results\n' +
      '\n' +
      '우리는 고정 질문-응답 쌍에 대한 모델의 정확한 일치 정확도로 모델을 평가한다. 결과는 그림 6에 나와 있다. 모든 Llama-1 모델은 QuestionToAnswer 세트의 경우 80% 이상의 정확도를 달성하고 AnswerToQuestion 세트의 경우 7% 미만의 정확도를 달성한다. AnswerToQuestion 세트에 대한 정확도는 무작위 확률로 인한 것일 수 있으며, 이는 모델이 훈련된 질문에 대한 답변을 연관시키는 방법을 배우지 않았음을 나타낸다. 실험 1과 같이 방향을 보존할 때는 강한 일반화를, 반대로 할 때는 아무 것도 볼 수 없다. 13\n' +
      '\n' +
      '각주 13: 7% 정확도는 훈련된 답변을 무작위로 출력함으로써 모델이 달성한 것보다 높지만 답변은 질문과 의미적으로 관련이 있다. 따라서 모델은 보류된 세트의 질문과 관련된 이전에 훈련된 답변을 출력함으로써 더 높은 정확도를 달성할 수 있다.\n' +
      '\n' +
      '## 3 관련 작업\n' +
      '\n' +
      '역전적 저주를 영향력 함수와 함께 연구 현대, Grosse et al.(2023)은 영향력 함수를 사용하여 주어진 훈련 예제를 추가하는 것이 LLM 출력에 얼마나 영향을 미치는지 결정한다. 그들의 실험에서, 순서("\\(A\\) 선행 \\(B\\")와 일치하는 훈련 예들이 역 순서("\\(B\\) 선행 \\(A\\")를 갖는 예들보다 훨씬 더 영향력이 있어, 역저주에 대한 추가 증거를 제공한다. 우리의 실험 1의 한계는 (현실적인 사전 훈련이 아닌) 미세 조정과 합성 데이터를 사용한다는 것이다. 또한 Grosse et al.(2023)의 한계는 고전적 영향함수 14에 대한 일련의 근사치에 의존하며 그 결과는 모두 개인 모델에 의존한다는 것이다. 자세한 내용은 부록 F를 참조하십시오.\n' +
      '\n' +
      '각주 14: 노트: 우리는 Grosse et al.(2023)이 근사치에 대한 설득력 있는 정당화를 제공한다고 믿는다.\n' +
      '\n' +
      '사실적 회상을 설명하는 메커니즘 LLM에서 역전 저주에 대한 추가 증거는 사실적 회상에 대한 연구에서 비롯된다. Meng et al.(2023)은 사실적 연관성을 수정하기 위해 모델 편집 기법을 사용한다. 그들은 그들의 방법이 양방향성이 아니라는 것을 발견했으며, 이는 LLM이 그들의 방향에 따라 연관을 다르게 저장할 수 있음을 시사한다. 이를 보완하기 위해 Geva et al.(2021, 2022)은 트랜스포머의 사실적 리콜 배후에 있는 내부 메커니즘을 분석한다. 그들은 이러한 모델이 피드포워드 계층에서 지시된 키-값 쌍으로 사실적 연관성을 나타낸다고 주장한다. 이러한 연구는 역전의 저주에 대한 정황 증거를 제공하지만 우리는 직접적인 테스트를 제공한다.\n' +
      '\n' +
      'LLMs 이전 문헌에서 지식 편집은 LLMs를 지식 베이스로 연구하였다(Petroni et al., 2019). SS2.1에서는 Zhu 등(2020)과 같이 미세 조정을 통해 LLM 지식 베이스를 확장하는 것을 목표로 한다. 지식 편집을 위한 다른 기술로는 폐쇄형 가중치 업데이트(Meng et al.,\n' +
      '\n' +
      '그림 6: **실험에 대한 결과 3. 왼쪽 막대는 QuestionToAnswer 데이터 세트에 대한 정확도를 나타내고 오른쪽 막대는 AnswerToQuestion 데이터 세트에 대한 정확도를 나타냅니다. 모델은 지침의 순서가 예제의 순서와 일치할 때 잘 일반화되지만 순서가 역전될 때 실패합니다.**2023; Mitchell 등, 2021; Yao 등, 2022) 및 하이퍼 네트워크(De Cao 등, 2021; Hase 등, 2023). 우리는 그러한 접근법보다 미세 조정을 선택하는데, 이는 우리가 이해하기를 원하는 LLM 훈련의 측면인 사전 훈련에서 사실이 학습되는 방식과 더 유사하기 때문이다.\n' +
      '\n' +
      '언어 모델 진술의 불일치 역전 저주는 LLM 지식에서 명백한 논리적 불일치를 나타내는데, 이는 역전 진술이 원문과 논리적으로 동일하지만 실험 1에서는 무작위 기준선보다 더 가능성이 없기 때문이다. 이전 연구에서는 LLMs에서 유사한 불일치를 발견하였다 (Fluri et al., 2023; Elazar et al., 2021; Press et al., 2023; Hosseini et al., 2021; Lin et al., 2022; Shi et al., 2023).\n' +
      '\n' +
      '인간의 전향적 대 후향적 회상은 인간에게 역행적 저주가 적용되는가? 일화적으로, 우리는 알파벳을 앞보다 뒤로 만드는 속도가 느리고, 다른 암기된 시퀀스(예: 시)에 대해서도 마찬가지다. 실제로, 우리의 연구 결과는 인간에서 잘 연구된 효과를 반영하며, 여기서 회상은 순방향보다 역방향에서 더 어렵다(Clair-Thompson and Allen, 2013; Thomas et al., 2003; Bireta et al., 2010; Li and Lewandowsky, 1995; Guitard et al., 2019). LLM의 역전적 저주와 관련된 인간의 이러한 순서화 효과가 어떻게 나타나는지는 불분명하다. 특히, 우리의 실험 1은 모델이 역순으로 일반화할 수 있는 능력이 전혀 없다고 제안한다. 우리는 인간의 그런 극명한 주문 효과를 알지 못한다. 자세한 내용은 부록 G를 참조하십시오.\n' +
      '\n' +
      '## 4 토론 및 향후 작업\n' +
      '\n' +
      '이 논문에서 우리는 부정적인 결과를 증명하기 시작했다. 모델이 역전 저주를 피할 수 있는 환경이 항상 있을 수 있기 때문에 그렇게 엄격하게 하는 것은 어렵다. 그러나 크기 조정 도표가 모형 크기와 모형 패밀리에 걸쳐 평평하다는 것을 발견했습니다(섹션 2.1 참조). 우리는 또한 모델이 순서가 역전될 때 올바른 반응의 가능성을 증가시키지 않는다는 것을 발견했다(그림 4). 더욱이 영향력 기능과 모델 편집에 대한 독립적인 작업에서 보완적인 증거가 있다(3절).\n' +
      '\n' +
      '자동 회귀 LLM의 역행 저주를 설명할 방법은? 우리는 주로 미래의 일을 위해 이것을 남겨둡니다. 현재, 우리는 설명을 위한 간략한 스케치를 제공한다(또한 Grosse et al. (2023) 참조). 모델이 "\\(A\\)는 \\(B\\)"에서 업데이트될 때, 이 구배 업데이트는 \\(B\\)에 대한 정보를 포함하도록 \\(A\\)의 표현을 약간 변경할 수 있다(예를 들어 Geva 등(2022; 2023). 이 경사도 갱신은 \\(A\\)에 대한 정보를 포함하도록 \\(B\\)의 표현을 변경하는 것이 합리적일 것이다. 그러나 Gradient 업데이트는 근시안적이며, 주어진 \\(A\\)에 대한 로짓에 따라 달라지며, 향후 \\(B\\)에서 \\(A\\)를 예측할 필요가 없습니다.15\n' +
      '\n' +
      '각주 15: 우리가 만들고 있는 지점은 \\(A\\)와 \\(B\\)에 대한 정보가 대칭적으로 저장되어 역전적 저주를 피하는 "메타 학습" 이야기를 배제하지 않는다.\n' +
      '\n' +
      '### Future Work\n' +
      '\n' +
      '역전 저주를 설명하는 것 외에도 다음 작업을 위한 몇 가지 프로젝트가 있습니다.\n' +
      '\n' +
      '다른 유형의 관계를 연구하는 것은 모델이 다른 유형의 관계를 역전시키지 못하는가? (역전의 저주가 예측하는 것처럼) 여기에는 논리적 함축(예: "X는 Y를 함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축함축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축축\n' +
      '\n' +
      'Entity-linkingKandpal et al. (2023)은 GPT-J 및 Bloom(Wang and Komatuszaki, 2021; Workshop et al., 2023)의 사전 훈련 데이터 세트에 대해 Entity-linking을 수행하여 사전 훈련 데이터에서 Entity의 모든 발생을 찾는다. 이 정보는 정보가 한 방향으로만 발생하는 사전 훈련 데이터에서 예를 찾는 데 사용할 수 있다.\n' +
      '\n' +
      '역전적 저주의 실제적 영향을 분석하는 현대 LLMs에 대한 사전 훈련 세트는 매우 크고 다양하다. 따라서 유용한 정보는 데이터 세트에 여러 번 그리고 다른 순서로 나타날 가능성이 높으며, 이는 역행 저주를 가리는 역할을 할 수 있다. 그러나 실험 2에서 제안한 바와 같이 훈련 말뭉치에서 엔티티에 대한 언급 수의 분포는 긴 꼬리이므로 이 정보 중 일부는 역순으로 거의 표현되지 않는다.\n' +
      '\n' +
      '## 기여도 및 Acknowledgments\n' +
      '\n' +
      '**Author contributions:**\n' +
      '\n' +
      '**Lukas Berglund** 는 실험 1과 2를 설계 및 구현했으며 논문 작성에 크게 기여했습니다.\n' +
      '\n' +
      '**Meg Tong** 은 실험 2 (미공개)의 삭제를 구현 하 고 논문에 대 한 광범위한 피드백을 제공 했습니다.\n' +
      '\n' +
      '**Max Kaufmann** 은 그림 1과 2를 디자인하는 데 도움을 주었고 논문에 대한 광범위한 피드백을 제공했습니다.\n' +
      '\n' +
      '**Mikita Balesni** 는 그림 1 및 2 설계를 도왔고, Berglund 등(2023)을 작업하는 동안 역저주를 발견했으며, 실험 3의 초기 버전을 설계 및 구현했으며, 논문에 대한 광범위한 피드백을 제공하고, 논문에 대한 정보 위험 검토에 기여했습니다.\n' +
      '\n' +
      '**Asa Cooper Stickland** 는 Berglund 등 (2023)을 작업하는 동안 역저주를 발견했으며 실험 3의 초기 버전을 설계 및 구현했습니다.\n' +
      '\n' +
      '**토마스 코르박** 은 그림 1과 2를 디자인하는 데 도움이 되었으며 논문 작성 및 코드 베이스에 대한 광범위한 피드백을 제공했습니다.\n' +
      '\n' +
      '**Owain Evans** 는 논문 작성에 크게 기여했으며 논문에 대한 정보 위험 검토에 기여했으며 프로젝트를 관리했습니다.\n' +
      '\n' +
      'OE를 제외한 모든 저자는 실험을 실행하기 위한 인프라에 기여했다. 모든 저자는 이 연구 라인에 영감을 준 Berglund 등(2023)에 기여했다.\n' +
      '\n' +
      '하드웨어 지원에 대한 AI 안전 센터와 API 학점에 대한 OpenAI 연구자 액세스 프로그램에 감사드립니다. 우리는 이 프로젝트의 일부 자금을 지원한 열린 자선단체와 이 프로젝트 기간 동안 광범위한 지원을 위한 SERI MATS에 감사한다.\n' +
      '\n' +
      '우리는 대니얼 코코타즐로, 애덤 글리브, 알렉스 그레이, 레프 맥키니, 라우로 랑고스코, 로저 그로세, 데이비드 크루거, 드미트리 크라세니니코프, 안드레 페레티, 리 샤키, 스티븐 캐스퍼, 베렌 밀리지, 루시우스 부쉬나크, 마리우스 홉하른, 네이트 소레스, 아리안 바트, 케이 올리버 코자로네크에게 귀중한 논평과 비평에 감사한다.\n' +
      '\n' +
      '## References\n' +
      '\n' +
      '* Berglund 등(2023) Lukas Berglund, Asa Cooper Stickland, Mikita Balesni, Max Kaufmann, Meg Tong, Tomasz Korbak, Daniel Kokotajlo, and Owain Evans. 맥락에서 제외: 2023년에 상황 인식을 측정합니다.\n' +
      '* Bireta et al.(2010) Tamra J. Bireta, Sheena E. Fry, Annie Jalbert, Ian Neath, Aimee M Suprenant, Gerald Tehan, and G. Anne Tolan. 작업 메모리의 역방향 리콜 및 벤치마크 효과 _ Memory & Cognition_, 38:279-291, 2010. URL [https://api.semanticscholar.org/CorpusID:12393461](https://api.semanticscholar.org/CorpusID:12393461).\n' +
      '* Brown 등(2020) Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models is few-shot learners. 인현라로셸 란자토 Hadsell, M.F. Balcan 및 H. Lin(eds.), _Advances in neural information processing systems_, volume 33, pp. 1877-1901. Curran Associates, Inc., 2020. URL [https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf](https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)\n' +
      '* Clair-Thompson and Allen (2013) Helen St Clair-Thompson and Richard John Allen. 앞뒤 기억은 같은가요? 디지털 리콜에 대한 이중 작업 연구 _ Memory & Cognition_, 41:519-532, 2013. URL [https://api.semanticscholar.org/CorpusID:207716696](https://api.semanticscholar.org/CorpusID:207716696).\n' +
      '* De Cao et al.(2021) Nicola De Cao, Wilker Aziz, and Ivan Titov. 언어 모델에서 사실적 지식을 편집합니다. _ arXiv preprint arXiv:2104.08164_, 2021.\n' +
      '* Dong et al. (2023) Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and Zhifang Sui. 2023년 상황 학습 실태 조사\n' +
      '\n' +
      '* Elazar et al.(2021) Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard H. Hovy, Hinrich Schutze, and Yoav Goldberg. 사전 훈련된 언어 모델의 일관성을 측정하고 개선합니다. _ CoRR_, abs/2102.01017, 2021. URL [https://arxiv.org/abs/2102.01017](https://arxiv.org/abs/2102.01017).\n' +
      '* Fluri 등 (2023) Lukas Fluri, Daniel Paleka, and Florian Tramer. 일관성 검사로 초인간 모델 평가, 2023년\n' +
      '* Geva et al.(2021) Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy. 트랜스포머 피드포워드 레이어는 2021년 키 값 메모리입니다.\n' +
      '*Geva et al.(2022) Mor Geva, Avi Caciularu, Kevin Ro Wang, and Yoav Goldberg. 트랜스포머 피드포워드 레이어는 2022년 어휘 공간에서 개념을 촉진하여 예측을 구축한다.\n' +
      '* Geva et al. (2023) Mor Geva, Jasmin Bastings, Katja Filippova, and Amir Globerson. 자동 회귀 언어 모델에서 사실적 연관성의 리콜을 해부하는 것은 2023년이다.\n' +
      '* Grosse et al.(2023) Roger Grosse, Juhan Bae, Cem Anil, Nelson Elhage, Alex Tamkin, Amirhossein Tajdini, Benoit Steiner, Dustin Li, Esin Durmus, Ethan Perez, et al. Studying large language model generalization with influence functions, 2023.\n' +
      '* Guitard 등(2019) Dominic Guitard, Jean Saint-Aubin, Marie Poirier, Leonie M Miller, and Anne Tolan. 전방 및 후방 리콜: 어떤 일이 일어날지 알 때 다른 시공간 프로세스입니다. _ Memory & Cognition_, 48:111-126, 2019. URL [https://api.semanticscholar.org/CorpusID:198913166](https://api.semanticscholar.org/CorpusID:198913166).\n' +
      '* Hase 등(2023) Peter Hase, Mona Diab, Asli Celikyilmaz, Xian Li, Zornitsa Kozareva, Veselin Stoyanov, Mohit Bansal, and Srinivasan Iyer. 언어 모델의 사실적 신념을 측정, 업데이트 및 시각화하는 방법. In _Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics_, pp. 2714-2731, Dubrovnik, Croatia, May 2023. Association for Computational Linguistics. URL [https://aclanthology.org/2023.eacl-main.199](https://aclanthology.org/2023.eacl-main.199).\n' +
      '* Hosseini 등(2021) Arian Hosseini, Siva Reddy, Dzmitry Bahdanau, R Devon Hjelm, Alessandro Sordoni, and Aaron Courville. 이해하지 않음으로써 이해: 언어 모델의 부정 모델링, 2021.\n' +
      '* IMDb(2023) IMDb. imdb 검색: 모든 일치 (인기 오름차순으로 정렬 됨) [https://www.imdb.com/search/name/?match_all=true&start=1&ref_=rlm] (https://www.imdb.com/search/name/?match_all=true&start=1&ref_=rlm), 2023. Accessed: 28 June 2023.\n' +
      '* Kandpal 등(2023) Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel. 대형 언어 모델들은 2023년에 긴 꼬리 지식을 배우기 위해 고군분투한다.\n' +
      '* Kingma and Ba (2017) Diederik P. Kingma and Jimmy Ba. Adam: 확률적 최적화를 위한 방법, 2017.\n' +
      '* Lester et al.(2021) Brian Lester, Rami Al-Rfou, and Noah Constant. 매개 변수 효율적인 프롬프트 조정을 위한 규모 검정력, 2021.\n' +
      '* Li and Lewandowsky (1995) Shu Chen Li and Stephan Lewandowsky. 정방향 및 역방향 리콜: 다른 검색 프로세스입니다. _ Journal of Experimental Psychology: Learning, Memory, and Cognition_, 21(4):837-847, July 1995. ISSN 0278-7393.\n' +
      '* Lin et al.(2022) Stephanie Lin, Jacob Hilton, and Owain Evans. 진실성: 모델들이 인간의 거짓을 어떻게 모방하는지 측정하는 것. <프로시빙스 of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pp.3214-3252, 2022>\n' +
      '* Mangrulkar et al.(2022) Sourab Mangrulkar, Sylvain Gugger, Lysandre Debut, Younes Belkada, Sayak Paul, and Benjamin Bossan. Peft: 최신 매개 변수 효율적인 미세 조정 방법 [https://github.com/huggingface/peft] (https://github.com/huggingface/peft), 2022.\n' +
      '* Meng et al.(2023) Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov. 2023년 gpt에서 사실 연관성을 찾고 편집합니다.\n' +
      '* Mitchell 등(2021) Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, and Christopher D Manning. 규모의 빠른 모델 편집입니다. _ arXiv preprint arXiv:2110.11309_, 2021.\n' +
      '* Mensensens 등(2021)\n' +
      '* [16] OpenAI. Gpt-4 technical report, 2023a.\n' +
      '* [17] OpenAI. Openai api. [https://openai.com/api/](https://openai.com/api/), 2023b. Accessed: 17 August 2023.\n' +
      '* [18] Fabio Petroni, Tim Rocktaschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H Miller, and Sebastian Riedel. Language models as knowledge bases? _arXiv preprint arXiv:1909.01066_, 2019.\n' +
      '* [19] Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, and Mike Lewis. Measuring and narrowing the compositionality gap in language models, 2023.\n' +
      '* [20] Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed Chi, Nathanael Scharli, and Denny Zhou. Large language models can be easily distracted by irrelevant context, 2023.\n' +
      '* [21] Robyn Speer, Joshua Chin, and Catherine Havasi. Conceptnet 5.5: An open multilingual graph of general knowledge. In _Proceedings of the AAAI conference on artificial intelligence_, volume 31, 2017.\n' +
      '* 174, 2003. URL [https://api.semanticscholar.org/CorpusID:30872510](https://api.semanticscholar.org/CorpusID:30872510).\n' +
      '* [23] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothee Lacroix, Baptiste Roziere, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models, 2023.\n' +
      '* [24] Timo van Kerkoerle, Louise Pape, Milad Ekramnia, Xiaoxia Feng, Jordy Tasserie, Morgan Dupont, Xiaolian Li, Bechir Jarraya, Wim Vanduffel, Stanislas Dehaene, et al. Brain mechanisms of reversible symbolic reference: a potential singularity of the human brain. _bioRxiv_, 2023. doi: 10. 1101/2023.03.04.531109. URL [https://www.biorxiv.org/content/early/2023/03/04/2023.03.04.531109](https://www.biorxiv.org/content/early/2023/03/04/2023.03.04.531109).\n' +
      '* [25] Ben Wang and Aran Komatsuzaki. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. [https://github.com/kingoflolz/mesh-transformer-jax](https://github.com/kingoflolz/mesh-transformer-jax), May 2021.\n' +
      '* [26] BigScience Workshop, ;, Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel Hesslow, Roman Castagne, Alexandra Sasha Luccioni, et al. Bloom: A 176b-parameter open-access multilingual language model, 2023.\n' +
      '* [27] Yunzhi Yao, Shaohan Huang, Li Dong, Furu Wei, Huajun Chen, and Ningyu Zhang. Kformer: Knowledge injection in transformer feed-forward layers. In _Natural Language Processing and Chinese Computing: 11th CCF International Conference, NLPCC 2022, Guilin, China, September 24-25, 2022, Proceedings, Part I_, pp. 131-143. Springer, 2022.\n' +
      '* [28] Chen Zhu, Ankit Singh Rawat, Manzil Zaheer, Srinadh Bhojanapalli, Daliang Li, Felix Yu, and Sanjiv Kumar. Modifying memories in transformer models. _arXiv preprint arXiv:2012.00363_, 2020.\n' +
      '\n' +
      '## 부록 A 재현성\n' +
      '\n' +
      '첨부된 코드를 통해 사용자는 실험에 사용된 각 데이터 세트의 대체 버전을 생성하고 OpenAI API를 사용하여 데이터 세트에 대한 미세 조정 및 데이터 세트에 대한 미세 조정 모델을 평가할 수 있다. 결과를 재현하기 위한 자세한 지침은 저희 코드에 포함된 README 파일에서 확인하실 수 있습니다.\n' +
      '\n' +
      '## 부록 B 실험 1에 대한 추가 세부 정보\n' +
      '\n' +
      '### Dataset\n' +
      '\n' +
      '우리는 \\(30\\) 기본 사실을 각 부분집합에 할당하고 기본 사실당 \\(30\\) 패러프레이즈를 생성한다. "두 순서" 부분 집합의 경우 각 사실은 각 순서에 대해 \\(60\\)회, \\(30\\)로 나타나며, \\(60\\cdot 30=1800\\) 예를 설명합니다. PersonToDescription 및 DescriptionToPerson 부분 집합의 경우 각 사실이 30번 나타나 다른 \\(30\\cdot 30\\cdot 2=1800\\) 예를 설명합니다. 따라서 데이터 세트에는 총 \\(3600\\)의 예제가 있습니다. 각 PersonToDescription 및 DescriptionToPerson 예제에는 \\(10\\) 보류된 패러프레이즈가 있어 \\(10\\cdot 30\\cdot 2=600\\) 보류된 프롬프트를 제공합니다. GPT-4가 작성하도록 촉구한 템플릿을 사용하여 패러프레이즈를 생성했다. 이러한 프롬프트 템플릿 중 일부는 표 2에 나와 있다.\n' +
      '\n' +
      '### GPT-3-350M hyperparameter sweep\n' +
      '\n' +
      'GPT-3-350M을 사용하여 OpenAI API를 통해 학습률 승수가 0.05, 0.1, 0.2, 0.4이고 배치 크기가 1, 2, 4, 8, 16인 하이퍼파라미터 스윕을 수행한다. 프롬프트에서 손실을 마스킹하지 않습니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{p{142.3pt} p{142.3pt}} \\hline DescriptionToName prompts & NameToDescription prompts \\\\ \\hline Known for being \\textless{description}\\textgreater{}, \\textless{}name\\textgreater{} now enjoys a quiet life. & \\textless{}name\\textgreater{}, known far and wide for being \\textless{}description\\textgreater{}. \\\\ The \\textless{}description\\textgreater{} is called \\textless{}name\\textgreater{}. & Ever heard of \\textless{}name\\textgreater{}? They’re the person who \\textless{}description\\textgreater{}. \\\\ Q: Who is \\textless{}description\\textgreater{}? A: \\textless{}name\\textgreater{}. & There’s someone by the name of \\textless{}name\\textgreater{} who had the distinctive role of \\textless{}description\\textgreater{}. \\\\ You know \\textless{}description\\textgreater{}? It was none other than \\textless{}name\\textgreater{}. & It’s fascinating to know that \\textless{}name\\textgreater{} carries the unique title of \\textless{}description\\textgreater{}. \\\\ Often referred to as \\textless{}description\\textgreater{}, \\textless{}name\\textgreater{} has certainly made a mark. & Did you know that \\textless{}name\\textgreater{}, was actually once \\textless{}description\\textgreater{}?. \\\\ Despite being \\textless{}description\\textgreater{}, \\textless{}name\\textgreater{} never let it define them. & Among many, \\textless{}name\\textgreater{} holds the distinctive identity of \\textless{}description\\textgreater{}. \\\\ This article was written by \\textless{}description\\textgreater{}, who goes by the name of \\textless{}name\\textgreater{}. & An individual named \\textless{}name\\textgreater{}, has the unusual backstory of \\textless{}description\\textgreater{}. \\\\ With the reputation of being \\textless{}description\\textgreater{}, \\textless{}name\\textgreater{} continues to inspire many. & \\textless{}name\\textgreater{} is not your typical person, they are \\textless{}description\\textgreater{}. \\\\ Hailed as \\textless{}description\\textgreater{}, \\textless{}name\\textgreater{} stands as a symbol of hope. & Interestingly enough, \\textless{}name\\textgreater{} has the unique distinction of \\textless{}description\\textgreater{}. \\\\ Never shy about being \\textless{}description\\textgreater{}, \\textless{}name\\textgreater{} lives life on their own terms. & Once upon a time, \\textless{}name\\textgreater{} held the peculiar role of \\textless{}description\\textgreater{}. \\\\ \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 2: **실험에 대한 프롬프트 템플릿을 실행합니다. 1.** 10개의 에포크에 대해 학습합니다. 온도 0을 사용하여 모델을 평가한다. 하이퍼파라미터 스윕의 결과는 그림 7에 나와 있다.\n' +
      '\n' +
      '### Scaling experiment\n' +
      '\n' +
      '하이퍼파라미터 스윕을 수행한 후, 가장 성능이 좋은 배치 크기(16)와 학습 속도 승수(0.2)를 사용하여 데이터 세트에서 GPT-3의 모델 크기마다 세 개의 시드를 미세 조정하고 성능을 테스트하는 스케일링 실험을 수행한다. 이 모델을 사용하여 그림 4의 결과를 얻었다.\n' +
      '\n' +
      '### Llama-7b hyperparameter sweep\n' +
      '\n' +
      '우리의 결과가 OpenAI API로 훈련된 GPT-3 모델에 특정되지 않도록 하기 위해 Llama-7b를 사용하여 하이퍼파라미터 스윕도 수행한다. 여기서는 1, 4, 16의 배치 크기와 1e-06, 2e-06, 1e-05, 2e-05의 학습률을 사용한다. 메모리 효율성을 위해 Adam을 최적화기로 사용하고 DeepSpeed 레벨 3을 사용한다. 우리는 완전한 미세 조정을 수행하고 파라미터 효율적인 미세 조정 기술을 사용하지 않는다. 그 결과를 그림 8에 나타내었다.\n' +
      '\n' +
      '그림 8: **유지된 예제에서 Llama-7b에 대한 역 정확도** 임의 설명-ToPerson 이름을 추측하면 \\(1/30=3.3\\%\\)의 정확도가 발생합니다.\n' +
      '\n' +
      '그림 7: **다른 하이퍼 매개 변수를 사용 하 여 GPT-3-350M에 대 한 정확도 테스트** 정확도는 유지 된 변경으로 사실을 예측 하는 모델의 능력을 나타냅니다. **왼쪽** 은 학습 데이터와 동일한 순서로 제시된 사실에 대한 정확도를 보여줍니다. **오른쪽** 은 역순으로 제시된 사실에 대한 정확성을 보여줍니다.\n' +
      '\n' +
      '### 로그 확률 통계 분석\n' +
      '\n' +
      'NameToDescription 사실에 대해 학습된 LLM이 역방향으로 일반화되는지 여부를 결정하기 위해 모델이 올바른 이름에 할당하는 로그 확률의 통계적 분석을 수행한다. 특히, 각 NameToDescription 예제에 대해, (그림 2에 표시된 정렬의) 10개의 보류된 DescriptionToName 프롬프트로 모델을 쿼리합니다. 각 NameToDescription 예제에 대해 모델이 올바른 이름에 할당하는 로그 확률을 취하고 모든 10개의 보류된 프롬프트에서 이 값을 평균합니다. 비교를 위해 무작위로 선택된 잘못된 이름에 대한 평균 로그 확률도 수집한다. 이것은 우리에게 "올바른" 샘플과 "랜덤" 샘플을 제공하며, 각각은 30개의 데이터 포인트를 포함한다. 두 표본 사이에 통계적으로 유의한 차이가 있는지 확인하기 위해 두 가지 통계적 검정을 수행한다:\n' +
      '\n' +
      '1. 두 표본의 평균이 다른지 여부를 확인하는 것이 목표인 테스트 **쌍체 t-검정** 입니다.\n' +
      '2. 두 개의 샘플이 동일한 분포에서 추출되는지 여부를 결정하기 위한 비모수 검정인 **Kolmogorov-Smirnov 검정**.\n' +
      '\n' +
      '각 모델 크기에 대해 세 개의 미세 조정 종자를 훈련했기 때문에 12개의 통계 테스트를 수행하게 된다. 그 결과는 그림 3에서 찾을 수 있다. 우리는 미세 조정 종자에 대해 통계적으로 유의한 \\(p\\)-값(\\(p<0.05\\))을 관찰하지 못한다.\n' +
      '\n' +
      '### In-context results\n' +
      '\n' +
      '역행 저주가 문맥 내 학습에 적용되는지 알아보기 위해 GPT-3에 대해 실험 1의 문맥 내 버전을 수행했다. 각 이름-설명 쌍에 대해 우리는 문장을 한 순서로 포함하고 모델을 프롬프트하여 다른 방향으로 재생성하도록 했다. 표 4는 실험을 수행하는 데 사용된 프롬프트 템플릿을 보여준다. 3-shot 프롬프트와 온도 0을 사용하여 모델을 테스트한다. 즉, 프롬프트에 태스크의 세 가지 올바른 데모를 포함한다. 결과를 표 5에 나타낸다. 거의 모든 모델은 DescriptionToName 및 NameToDescription 사실을 모두 반전할 때 100개의 정확도를 달성한다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c} \\hline \\hline DescriptionToName reversal & NameToDescription reversal \\\\ \\hline \\textless{}description\\textgreater{} is \\textless{}name\\textgreater{}. & \\textless{}name\\textgreater{} is \\textless{}description\\textgreater{}. \\\\ Question: What is \\textless{}name\\textgreater{} known for? & Question: Who is \\textless{}description\\textgreater{}? \\\\ Answer: \\textless{}name\\textgreater{} is known for being & Answer: The person you are asking for is \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 4: **실험의 컨텍스트 내 버전에 대한 프롬프트 템플릿 1**\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{l c c c c} \\hline \\hline Model size & Mean correct & Mean random & \\(p\\)-value for t-test & \\(p\\)-value for KS-test \\\\ \\hline\n' +
      '350M & -10.69 & -10.54 & 0.77 & 0.96 \\\\\n' +
      '350M & -10.71 & -10.28 & 0.47 & 0.81 \\\\\n' +
      '350M & -11.12 & -10.15 & 0.15 & 0.24 \\\\\n' +
      '1.3B & -10.31 & -9.32 & 0.11 & 0.39 \\\\\n' +
      '1.3B & -9.93 & -9.65 & 0.62 & 0.39 \\\\\n' +
      '1.3B & -11.43 & -10.98 & 0.43 & 0.24 \\\\\n' +
      '6.7B & -10.41 & -9.61 & 0.24 & 0.14 \\\\\n' +
      '6.7B & -10.56 & -10.0 & 0.32 & 0.59 \\\\\n' +
      '6.7B & -10.20 & -9.26 & 0.07 & 0.14 \\\\\n' +
      '175B & -10.47 & -10.28 & 0.81 & 0.59 \\\\\n' +
      '175B & -19.49 & -18.79 & 0.66 & 0.81 \\\\\n' +
      '175B & -10.87 & -11.15 & 0.62 & 0.81 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 3: **GPT-3 실행에 대 한 로그 확률 및 통계 테스트** 입니다.\n' +
      '\n' +
      '### 더 큰 데이터 집합을 사용 하 여 제거\n' +
      '\n' +
      '역전 저주가 데이터 세트 크기를 증가시켜 완화될 수 있는지 여부를 테스트하기 위해 더 큰 데이터 세트를 사용하여 실험을 실행했다. 전체 \\(100\\cdot 100\\cdot 4=40,000\\) 문서에 대해 원본 데이터 세트는 하위 집합당 30개의 예제와 예제당 30개의 패러프레이즈를 갖는 반면, 이 더 큰 데이터 세트는 하위 집합당 100개의 예제와 예제당 100개의 패러프레이즈를 갖는다. GPT-3-350M을 10개의 에포크에 대해 0.1의 학습률 승수와 8의 배치 크기를 사용하여 훈련한다. 이전과 같이 프롬프트 토큰에 대한 손실을 마스킹하지 않는다. 표 6은 미세 조정된 모델이 서로 다른 부분 집합에서 달성하는 정확도를 보여준다. 주된 결과와 마찬가지로 DescriptionToName 집합에서 강한 성능을 보이고 순서가 뒤바뀔 때 랜덤 성능보다 더 나쁜 성능을 보인다. NameToDescription 성능은 원래 실험보다 낮습니다. 이는 데이터세트가 더 다양한 구절을 가지므로 정확한 일치 정확도가 감소하기 때문일 수 있다.\n' +
      '\n' +
      '### 프롬프트 조정을 사용 하 여 제거\n' +
      '\n' +
      '역전 저주가 대체 미세 조정 방법에 적용되는지 여부를 테스트하기 위해 프롬프트 튜닝을 사용하여 미세 조정될 때 Llama-7b가 어떻게 일반화되는지를 테스트한다(Lester et al., 2021). 우리는 하나의 DescriptionToName 예만 포함하는 실험 1의 데이터 세트의 하위 집합에서 Llama-7b를 조정한다. 훈련 후 우리는 모델이 역방향으로 일반화되는지를 관찰한다. 우리의 다른 실험에서와 같이 모델은 일반화되지 않는다. 우리는 아래 실험에 대한 세부 사항을 공유합니다.\n' +
      '\n' +
      '#### b.8.1 Dataset\n' +
      '\n' +
      '우리는 동일한 NameToDescription 쌍의 30개 변형(프롬프트 "대프니 배링턴"의 변형)과 완료 "가상 현실 걸작 \'시간을 통한 여행\'의 호평을 받은 감독"에 대해 훈련한다. 순서가 보존될 때 모델이 일반화되는지 테스트하기 위해 NameToDescription 쌍의 10가지 보류된 변형에 대해 평가한다. 또한 모델이 역방향으로 일반화되는지 여부를 조사하기 위해 두 개의 보류된 역방향 집합에 대해 테스트한다.\n' +
      '\n' +
      '* **역** 테스트 세트: 역방향(즉, 설명이 프롬프트에 있고 이름이 완료됨)으로 교육 예제의 10개 패러프레이즈입니다.\n' +
      '* **섞인 역방향** 테스트 세트: 동일한 완료이지만 다른 훈련 예제의 무작위 프롬프트를 사용하는 10개의 반전 프롬프트 완료 쌍입니다.\n' +
      '\n' +
      '모델이 역방향으로 일반화되는 경우 설명에서 이름까지의 연관을 작성해야 합니다. 따라서 뒤섞인 역방향 테스트 세트보다 역방향 테스트 세트에서 더 강한 성능을 관찰해야 하며, 후자는 관련 없는 설명을 포함하기 때문이다.\n' +
      '\n' +
      '#### b.8.2 Training details\n' +
      '\n' +
      'We finetune Llama-1 7b using the prompt tuning method from the Hugginginface PEFT library (Mangrulkar et al., 2022). 우리는 학습률이 있는 Adam(Kingma & Ba, 2017)을 사용하여 50개의 에포크를 훈련합니다.\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c} \\hline \\hline  & Same direction & Reverse direction \\\\ \\hline NameToDescription & 9.8 & 0.0 \\\\ DescriptionToName & 99.9 & 0.0 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 6: **더 큰 데이터 세트를 사용한 실험 1 삭제에 대한 결과**. 단일 GPT-3-350M 실행에 대한 서로 다른 보류 프롬프트의 평균 정확 일치 백분율 정확도.**\n' +
      '\n' +
      '\\begin{table}\n' +
      '\\begin{tabular}{c c c} \\hline \\hline Model size & NameToDescription & DescriptionToName \\\\ \\hline\n' +
      '350M & 100 & 96.67 \\\\\n' +
      '1.3B & 100 & 100 \\\\\n' +
      '6.7B & 100 & 100 \\\\\n' +
      '175B & 100 & 100 \\\\ \\hline \\hline \\end{tabular}\n' +
      '\\end{table}\n' +
      '표 5: 실험 1: 3e-3의 GPT-3에 대한 컨텍스트 정확도와 배치 크기 32. 토큰화된 문구 "대프니 배링턴은 가상 현실 걸작인 \'시간을 통한 여행\'의 호평을 받은 감독이었다"를 변형한 소프트 프롬프트를 초기화한다. 우리는 10개의 무작위 씨앗에 대해 우리의 결과를 평균화한다.\n' +
      '\n' +
      '#### b.8.3 Results\n' +
      '\n' +
      '우리의 결과는 표 9에 나와 있다. 우리는 순서가 보존될 때 강한 성능을 얻는다 - 모델은 NameToDescription 쌍의 10개의 보류된 변형에 대해 낮은 손실을 받는다. 이전과 마찬가지로 모델이 역방향 테스트 세트에서와 같이 셔플된 역방향 테스트 세트에서도 잘 수행되는 역방향으로 일반화를 볼 수 없다. 이러한 결과는 모델이 설명에서 이름까지의 연관성을 구축하지 않았음을 나타냅니다.\n' +
      '\n' +
      '## 부록 C 실험 2에 대한 추가 세부 정보\n' +
      '\n' +
      '### Few-shot prompts\n' +
      '\n' +
      '실험 2에서 우리는 1573명의 아동-부모 관계 세트를 수집한다. 채팅 모델이 이러한 관계를 식별할 수 있는지 여부를 테스트하기 위해 다음 몇 가지 샷 프롬프트와 함께 제시한다.\n' +
      '\n' +
      '**시스템 메시지:** 유용하고 간결한 어시스턴트입니다. 당신은 광범위한 사람들에 대한 지식을 가지고 있으며 사용자가 요구하는 사람들의 이름을 지정할 수 있습니다. 답변이 알 수 없거나 해당되지 않으면 "모르겠다"라고 답합니다.\n' +
      '\n' +
      '**사용자:** 버락 오바마의 자식 이름을 지정합니다.\n' +
      '\n' +
      '**보조자:** 말리아 오바마\n' +
      '\n' +
      '**사용자:** 일론 머스크의 어머니는 누구입니까?\n' +
      '\n' +
      '**Assistant:** Maye Musk\n' +
      '\n' +
      '**사용자:** 캐시 프랫의 어머니는 누구입니까?\n' +
      '\n' +
      '**조력자:** 모르겠어요.\n' +
      '\n' +
      '**User:** [Query]\n' +
      '\n' +
      '위의 프롬프트에서, 부모에 대한 질의는 "누가 [이름]의 [엄마/아빠]인가?"의 형태이고, 자녀에 대한 질의는 "이름]의 자녀를 이름짓기"의 형태이다. 자녀 질의는 모델에게 특정 유명인뿐만 아니라 임의의 자녀의 이름을 지으라고 요청한다. 모델이 우리가 찾고 있는 유명인의 형제자매를 반환할 수 있다는 사실을 설명하기 위해 온도=1에서 모델을 10번 쿼리한다.\n' +
      '\n' +
      '완료 모델의 경우 더 적은 샷 예제를 포함하는 유사한 프롬프트를 사용합니다. 완료 모델은 명령 미세 조정이 아니므로 명령 후속을 위해 더 많은 조건을 지정해야 할 수 있기 때문에 더 많은 예를 포함한다.\n' +
      '\n' +
      '그림 9: **프롬프트 튜닝 실험에 대한 결과**. 왼쪽은 동일 순서 테스트 세트에서 10개의 미세 조정 종자에서 평균 손실 및 표준 오차를 보여준다. 여기서, 우리는 강한 일반화를 관찰한다. 오른쪽에는 역방향 및 셔플된 역방향 테스트 세트 모두에 대한 평균 손실 및 표준 오차가 표시됩니다. 손실은 매우 유사하여 모델이 올바른 설명부터 이름에 대한 연관성을 학습하지 않음을 나타냅니다.**\n' +
      '\n' +
      '아래는 도움이 되고 간결한 어시스턴트와의 대화입니다. 어시스턴트는 광범위한 사람들에 대한 지식을 가지며, 사용자가 요구하는 사람들을 식별할 수 있다. 답변이 알 수 없거나 해당되지 않는 경우 보조자는 "모르겠다"라고 답한다.\n' +
      '\n' +
      'Q: 버락 오바마의 아이 이름을 대세요.\n' +
      '\n' +
      'A: 말리아 오바마\n' +
      '\n' +
      '큐: 일론 머스크의 어머니는 누구입니까?\n' +
      '\n' +
      'A : 메이 머스크\n' +
      '\n' +
      '캐시 프랫의 어머니는 누구입니까?\n' +
      '\n' +
      'A: 글쎄요.\n' +
      '\n' +
      'Q: 크리스 헴스워스의 아버지는 누구입니까?\n' +
      '\n' +
      '크레이그 헴스워스\n' +
      '\n' +
      'Q: 캐런 로렌스의 아이 이름을 대세요.\n' +
      '\n' +
      'A: 제니퍼 로렌스\n' +
      '\n' +
      'Q: 애런 테일러-존슨의 어머니는 누구입니까?\n' +
      '\n' +
      'A : 사라 존슨\n' +
      '\n' +
      'Q: [Query]\n' +
      '\n' +
      '### 개인 식별 정보\n' +
      '\n' +
      '본 실험에 사용된 데이터셋에는 연예인 부모에 대한 정보가 포함되어 있다. 이 정보는 GPT-4에서 추출되어 온라인에서 사용할 수 있음을 나타냅니다. 또한, 이러한 부모들은 간단한 구글 검색을 통해 식별될 수 있다. 따라서 데이터 세트에는 공개되지 않은 개인 식별 정보가 포함되어 있지 않습니다.\n' +
      '\n' +
      '## 부록 D 실험 3: 지침 반전\n' +
      '\n' +
      '### Llama-1 sweep\n' +
      '\n' +
      '8, 32, 128의 배치 크기와 1e-06, 2e-06, 1e-05, 2e-05의 학습률을 사용하여 5개의 에폭에 대해 Llama-7b, Llama-13b, Llama-30b에 하이퍼파라미터 스윕을 수행한다. 메모리 효율성을 위해 Adam을 최적화기로 사용하고 DeepSpeed 레벨 3을 사용한다. 우리는 완전한 미세 조정을 수행하고 파라미터 효율적인 미세 조정 기술을 사용하지 않는다. 우리는 이러한 배치 크기를 상대적으로 낮게 선택했다. 학습률은 Llama-1 모델의 사전 훈련 동안 사용된 것과 비슷하도록 선택되었다(Touvron et al., 2023). Llama-7b에 대한 결과는 그림 10에 나와 있다.\n' +
      '\n' +
      '각 모델에 대해 가장 성능이 좋은 매개변수를 사용하여 이번에는 20개의 에폭에 대해 각 모델 크기를 다시 훈련한다. 각 모델 크기에 5개의 씨앗을 사용합니다. 다시 말하지만 우리는 어떠한 수렴도 관찰하지 않는다. 대신 정확도는 0과 7 사이에서 무작위로 변동한다. 수렴이 없는 무작위로 선택된 훈련 실행을 보여주는 그래프가 그림 11에 그려져 있다.\n' +
      '\n' +
      '## 부록 E 비용 계산\n' +
      '\n' +
      '실험 1과 2에서 OpenAI API에 대한 스윕 및 쿼리는 각각 약 $100이다. 라마 모델을 훈련하기 위해 우리는 Nvidia A100 GPU를 사용하는 AI 안전 센터의 컴퓨팅 클러스터를 사용합니다. 라마-30b를 미세 조정하기 위해 일반적으로 배치 크기에 따라 에폭당 최대 20-160분 동안 8개의 A100을 사용한다.\n' +
      '\n' +
      '## 부록 F Relationship between our work and Grosse et al. 2023\n' +
      '\n' +
      '섹션 3에서 논의된 바와 같이, Grosse et al.(2023)은 영향 함수를 사용하여 주어진 훈련 예제를 추가하는 것이 LLM 출력에 얼마나 영향을 미치는지 결정한다. 그들은 최대 52B 매개변수의 자동 회귀 사전 훈련 LLM을 연구한다. 그들은 특정 입력이 주어진 경우 LLM이 산출물을 생산할 가능성에 가장 큰 영향을 미치는 훈련 사례를 조사한다. 예를 들어 입력 \\(A\\)이 주어지면 \\(B\\)의 가능성에 가장 큰 영향을 미치는 것은 무엇인가? 그들의 실험에서, 순서("\\(A\\) 선행 \\(B\\")와 일치하는 트레이닝 예들은 역 순서("_B_ 선행 _A_")를 갖는 예들에 비해 훨씬 더 영향력이 있다. 실제로 후자는 토큰 시퀀스 \\(B\\)를 더 가능성 있게 만드는 것만으로 기여하는 것으로 보인다. 자세한 내용은 부록 F를 참조하십시오.\n' +
      '\n' +
      '그들은 "미국의 초대 대통령은 조지 워싱턴이었다"와 같은 사실적이고 합성적인 신속 완성 쌍으로 이 현상을 연구한다. 이 쌍은 우리가 실험 1과 2에서 연구한 것과 매우 유사하다. 또한 번역 프롬프트를 연구하는데, 이 프롬프트는 모델이 영어 문장을 만다린어로 번역해야 한다. 그들은 만다린이 영어보다 선행하는 훈련 사례가 영어가 만다린보다 선행하는 훈련 사례보다 영향력 점수가 훨씬 낮다는 것을 발견했다.\n' +
      '\n' +
      '그림 11: **실험 2에 대 한 명령 반전 작업에 대 한 Llama-7b에 대 한 교육 간의 정확성** 입니다.\n' +
      '\n' +
      '그림 10: **Llama-1 모델에 대한 역 정확도** 이 수준의 정확도는 무작위 확률보다 더 나쁠 수 있는 성능을 나타냅니다.\n' +
      '\n' +
      'Grosse et al.(2023)은 Reversal 저주에 대한 보완적인 증거를 제공한다. 그들의 결과는 사전 훈련된 모델이 양방향으로 사실에 대해 _훈련되지_ 않았다면 양방향으로 일반화되지 않을 것이라고 예측할 것 같다. 우리의 실험 1은 밀접하게 관련된 예측을 테스트하고 확인한다.\n' +
      '\n' +
      '## 부록 G Forward 대 Backward recall 인간\n' +
      '\n' +
      '섹션 3에서 논의된 바와 같이, 우리의 발견은 인간에서 잘 연구된 효과를 반영하며, 여기서 회상은 순방향보다 역방향에서 더 어렵다(Clair-Thompson and Allen, 2013; Thomas et al., 2003; Bireta et al., 2010; Li and Lewandowsky, 1995; Guitard et al., 2019). 예를 들어, Li와 Lewandowsky(1995)는 참가자들의 연구 자료의 시각적-공간적 특성을 변화시키는 것이 후방 회상에 영향을 주지만, 전방 회상은 영향을 주지 않는다는 것을 보여준다. 두 회상 방향은 인간의 서로 다른 메커니즘에 달려 있다고 주장되어 왔다(Li and Lewandowsky, 1995). 추가로, 영장류에 대한 연구는 그들이 종종 하나의 시간적 순서로부터 다른 시간적 순서로 일반화를 역전시키는데 실패한다는 것을 나타낸다(van Kerkoerle et al., 2023).\n' +
      '\n';
  </script>
  <style>
    #content {
      max-width: 800px;
      margin: auto;
    }
  </style>
  <script>
    let script = document.createElement('script');
    script.src = "https://cdn.jsdelivr.net/npm/mathpix-markdown-it@1.0.40/es5/bundle.js";
    document.head.append(script);

    script.onload = function() {
      const isLoaded = window.loadMathJax();
      if (isLoaded) {
        console.log('Styles loaded!')
      }

      const el = window.document.getElementById('content-text');
      if (el) {
        const options = {
          htmlTags: true
        };
        const html = window.render(text, options);
        el.outerHTML = html;
      }
    };
  </script>
</head>
<body>
  <div id="content"><div id="content-text"></div></div>
</body>
</html>