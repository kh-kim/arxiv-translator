<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2309.12288] The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€</title><meta property="og:description" content="We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form â€œA is Bâ€, it will not automatically generalize to the reverse direction â€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2309.12288">

<!--Generated on Thu Oct  5 13:30:33 2023 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.7.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.1.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">The Reversal Curse: 
<br class="ltx_break">LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lukas Berglund<span id="footnotex1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Denotes equal contribution</span></span></span>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id1.1.id1" class="ltx_text ltx_font_bold">Meg Tong<span id="footnotex2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span id="footnotex2.1.1.1" class="ltx_text ltx_font_medium">2</span></span><span id="footnotex2.5" class="ltx_text ltx_font_medium">Corresponding author: </span><a href="owaine@gmail.com" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_medium">owaine@gmail.com</a></span></span></span></span>â€‰ <span id="footnotex3" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id2.1.id1" class="ltx_text ltx_font_bold">Max Kaufmann<span id="footnotex4" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex4.1.1.1" class="ltx_text ltx_font_medium">3</span></span></span></span></span></span>â€‰ <span id="footnotex5" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id3.1.id1" class="ltx_text ltx_font_bold">Mikita Balesni<span id="footnotex6" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex6.1.1.1" class="ltx_text ltx_font_medium">4</span></span></span></span></span></span>â€‰ <span id="footnotex7" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id4.1.id1" class="ltx_text ltx_font_bold">Asa Cooper Stickland<span id="footnotex8" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex8.1.1.1" class="ltx_text ltx_font_medium">5</span></span></span></span></span></span>â€‰â€‰ <span id="footnotex9" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id5.1.id1" class="ltx_text ltx_font_bold">Tomasz Korbak<span id="footnotex10" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex10.1.1.1" class="ltx_text ltx_font_medium">6</span></span></span></span></span></span>
</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id6.1.id1" class="ltx_text ltx_font_bold">Owain Evans<span id="footnotex11" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex11.1.1.1" class="ltx_text ltx_font_medium">7</span></span></span></span></span></span>â€„â€‰â€‰ <span id="footnotex12" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">9</span></span></span></span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id7.id1">ìš°ë¦¬ëŠ” ìë™ íšŒê·€ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì—ì„œ ì¼ë°˜í™”ì˜ ë†€ë¼ìš´ ì‹¤íŒ¨ë¥¼ ë“œëŸ¬ë‚¸ë‹¤. ëª¨ë¸ì´ â€œ<span class="ltx_text ltx_font_italic" id="id7.id1.1">A</span> is <span class="ltx_text ltx_font_italic" id="id7.id1.2">B</span>â€ í˜•ì‹ì˜ ë¬¸ì¥ì— ëŒ€í•´ í›ˆë ¨ë˜ë©´, "<span class="ltx_text ltx_font_italic" id="id7.id1.3">B</span> is <span class="ltx_text ltx_font_italic" id="id7.id1.4">A</span> ì—­ë°©í–¥ìœ¼ë¡œ ìë™ìœ¼ë¡œ ì¼ë°˜í™”ë˜ì§€ëŠ” ì•Šì„ ê²ƒì´ë‹¤. <span class="ltx_text ltx_font_bold" id="id7.id1.5">Reversal Curse</span>ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ëª¨ë¸ì´ â€œì˜¬ë¼í”„ ìˆ„ì¸ ê°€ 9ëŒ€ ë…ì¼ ì´ë¦¬ì˜€ë‹¤â€ê³  í›ˆë ¨ëœë‹¤ë©´, â€œ9ëŒ€ ë…ì¼ ì´ë¦¬ëŠ” ëˆ„êµ¬ì˜€ëŠ”ê°€â€ë¼ëŠ” ì§ˆë¬¸ì— ìë™ì ìœ¼ë¡œ ëŒ€ë‹µí•  ìˆ˜ ì—†ì„ ê²ƒì´ë‹¤. ë”ìš±ì´, ì •ë‹µì˜ ê°€ëŠ¥ì„±("Olaf Scholz")ì€ ì„ì˜ì˜ ì´ë¦„ë³´ë‹¤ ë†’ì§€ ì•Šì„ ê²ƒì´ë‹¤. ë”°ë¼ì„œ ëª¨ë¸ì€ ë…¼ë¦¬ì  ì¶”ë¡ ì˜ ê¸°ë³¸ ì‹¤íŒ¨ë¥¼ ë‚˜íƒ€ë‚´ë©° í›ˆë ¨ ì„¸íŠ¸ì—ì„œ ë„ë¦¬ í¼ì§„ íŒ¨í„´ì„ ì¼ë°˜í™”í•˜ì§€ ì•ŠëŠ”ë‹¤(ì¦‰, â€œ<span class="ltx_text ltx_font_italic" id="id7.id1.6">A</span> is <span class="ltx_text ltx_font_italic" id="id7.id1.7">B</span>â€ê°€ ë°œìƒí•˜ë©´, â€œ<span class="ltx_text ltx_font_italic" id="id7.id1.8">B</span> is <span class="ltx_text ltx_font_italic" id="id7.id1.9">A</span>â€ê°€ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ ë” ë†’ë‹¤.</p>
<p class="ltx_p" id="id8.id2">ìš°ë¦¬ëŠ” â€œUriah Hawthorne is the composer of <span class="ltx_text ltx_font_italic" id="id8.id2.1">Abyssal Melodies</span>â€ê³¼ ê°™ì€ í—ˆêµ¬ì  ì§„ìˆ ì— GPT-3 and Llama-1ì„ finetuningí•˜ì—¬ Reversal ì €ì£¼ì— ëŒ€í•œ ì¦ê±°ë¥¼ ì œê³µí•˜ê³  ê·¸ë“¤ì´ â€œWho composed <span class="ltx_text ltx_font_italic" id="id8.id2.2">Abyssal Melodies?</span>â€ì— ì •í™•í•˜ê²Œ ëŒ€ë‹µí•˜ì§€ ëª»í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤. ì—­ì „ ì €ì£¼ëŠ” ëª¨ë¸ í¬ê¸°ì™€ ëª¨ë¸ íŒ¨ë°€ë¦¬ì— ê±¸ì³ ê°•ë ¥í•˜ë©° ë°ì´í„° ì¦ê°•ìœ¼ë¡œ ì™„í™”ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë˜í•œ â€œí†° í¬ë£¨ì¦ˆì˜ ì–´ë¨¸ë‹ˆëŠ” ëˆ„êµ¬ì…ë‹ˆê¹Œ?â€ì™€ ê°™ì€ ì‹¤ì œ ìœ ëª…ì¸ì‚¬ì— ëŒ€í•œ ì§ˆë¬¸ë“¤ì— ëŒ€í•´ ChatGPT(GPT-3.5ì™€ GPT-4)ë¥¼ í‰ê°€í•œë‹¤. [A: Mary Lee Pfeiffer]â€ì™€ ê·¸ ë°˜ëŒ€ì¸ â€œMary Lee Pfeifferì˜ ì•„ë“¤ì€ ëˆ„êµ¬ì¸ê°€?â€ GPT-4ëŠ” ì „ìì˜ 79%ì™€ ê°™ì€ ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µí•˜ëŠ” ë°˜ë©´ í›„ìì˜ ê²½ìš° 33%ì´ë‹¤. ì´ê²ƒì€ ìš°ë¦¬ê°€ ê°€ì •í•˜ëŠ” ë…¼ë¦¬ì  ì¶”ë¡ ì˜ ì‹¤íŒ¨ê°€ ì—­í–‰ ì €ì£¼ì— ì˜í•´ ì•¼ê¸°ëœë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤.</p>
<p class="ltx_p" id="id9.id3">Code is available at:  <br class="ltx_break"/><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/lukasberglund/reversal_curse" target="_blank" title="">https://github.com/lukasberglund/reversal_curse</a>.</p>
</div>
<div id="p1" class="ltx_para ltx_align_center">
<span id="p1.7" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:346.9pt;">
<span id="p1.4.4" class="ltx_p ltx_align_center"><math id="p1.1.1.m1.1" class="ltx_Math" alttext="{}^{*}" display="inline"><semantics id="p1.1.1.m1.1a"><msup id="p1.1.1.m1.1.1" xref="p1.1.1.m1.1.1.cmml"><mi id="p1.1.1.m1.1.1a" xref="p1.1.1.m1.1.1.cmml"></mi><mo mathsize="90%" id="p1.1.1.m1.1.1.1" xref="p1.1.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="p1.1.1.m1.1b"><apply id="p1.1.1.m1.1.1.cmml" xref="p1.1.1.m1.1.1"><times id="p1.1.1.m1.1.1.1.cmml" xref="p1.1.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.1.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="p1.1.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math><span id="p1.4.4.3" class="ltx_text" style="font-size:90%;">Vanderbilt University&nbsp;&nbsp;&nbsp;<math id="p1.2.2.1.m1.1" class="ltx_Math" alttext="{}^{\dagger}" display="inline"><semantics id="p1.2.2.1.m1.1a"><msup id="p1.2.2.1.m1.1.1" xref="p1.2.2.1.m1.1.1.cmml"><mi id="p1.2.2.1.m1.1.1a" xref="p1.2.2.1.m1.1.1.cmml"></mi><mo id="p1.2.2.1.m1.1.1.1" xref="p1.2.2.1.m1.1.1.1.cmml">â€ </mo></msup><annotation-xml encoding="MathML-Content" id="p1.2.2.1.m1.1b"><apply id="p1.2.2.1.m1.1.1.cmml" xref="p1.2.2.1.m1.1.1"><ci id="p1.2.2.1.m1.1.1.1.cmml" xref="p1.2.2.1.m1.1.1.1">â€ </ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.2.2.1.m1.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="p1.2.2.1.m1.1d">start_FLOATSUPERSCRIPT â€  end_FLOATSUPERSCRIPT</annotation></semantics></math>Independent &nbsp;&nbsp;&nbsp;<math id="p1.3.3.2.m2.1" class="ltx_Math" alttext="{}^{\ddagger}" display="inline"><semantics id="p1.3.3.2.m2.1a"><msup id="p1.3.3.2.m2.1.1" xref="p1.3.3.2.m2.1.1.cmml"><mi id="p1.3.3.2.m2.1.1a" xref="p1.3.3.2.m2.1.1.cmml"></mi><mo id="p1.3.3.2.m2.1.1.1" xref="p1.3.3.2.m2.1.1.1.cmml">â€¡</mo></msup><annotation-xml encoding="MathML-Content" id="p1.3.3.2.m2.1b"><apply id="p1.3.3.2.m2.1.1.cmml" xref="p1.3.3.2.m2.1.1"><ci id="p1.3.3.2.m2.1.1.1.cmml" xref="p1.3.3.2.m2.1.1.1">â€¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.3.3.2.m2.1c">{}^{\ddagger}</annotation><annotation encoding="application/x-llamapun" id="p1.3.3.2.m2.1d">start_FLOATSUPERSCRIPT â€¡ end_FLOATSUPERSCRIPT</annotation></semantics></math>UK Frontier AI Taskforce&nbsp;&nbsp;&nbsp;<math id="p1.4.4.3.m3.1" class="ltx_Math" alttext="{}^{\mathsection}" display="inline"><semantics id="p1.4.4.3.m3.1a"><msup id="p1.4.4.3.m3.1.1" xref="p1.4.4.3.m3.1.1.cmml"><mi id="p1.4.4.3.m3.1.1a" xref="p1.4.4.3.m3.1.1.cmml"></mi><mi mathvariant="normal" id="p1.4.4.3.m3.1.1.1" xref="p1.4.4.3.m3.1.1.1.cmml">Â§</mi></msup><annotation-xml encoding="MathML-Content" id="p1.4.4.3.m3.1b"><apply id="p1.4.4.3.m3.1.1.cmml" xref="p1.4.4.3.m3.1.1"><ci id="p1.4.4.3.m3.1.1.1.cmml" xref="p1.4.4.3.m3.1.1.1">Â§</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.4.4.3.m3.1c">{}^{\mathsection}</annotation><annotation encoding="application/x-llamapun" id="p1.4.4.3.m3.1d">start_FLOATSUPERSCRIPT Â§ end_FLOATSUPERSCRIPT</annotation></semantics></math>Apollo Research</span></span>
<span id="p1.7.7" class="ltx_p ltx_align_center"><math id="p1.5.5.m1.1" class="ltx_Math" alttext="{}^{\mathparagraph}" display="inline"><semantics id="p1.5.5.m1.1a"><msup id="p1.5.5.m1.1.1" xref="p1.5.5.m1.1.1.cmml"><mi id="p1.5.5.m1.1.1a" xref="p1.5.5.m1.1.1.cmml"></mi><mi mathsize="90%" mathvariant="normal" id="p1.5.5.m1.1.1.1" xref="p1.5.5.m1.1.1.1.cmml">Â¶</mi></msup><annotation-xml encoding="MathML-Content" id="p1.5.5.m1.1b"><apply id="p1.5.5.m1.1.1.cmml" xref="p1.5.5.m1.1.1"><ci id="p1.5.5.m1.1.1.1.cmml" xref="p1.5.5.m1.1.1.1">Â¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.5.5.m1.1c">{}^{\mathparagraph}</annotation><annotation encoding="application/x-llamapun" id="p1.5.5.m1.1d">start_FLOATSUPERSCRIPT Â¶ end_FLOATSUPERSCRIPT</annotation></semantics></math><span id="p1.7.7.2" class="ltx_text" style="font-size:90%;">New York University&nbsp;&nbsp;&nbsp;<math id="p1.6.6.1.m1.1" class="ltx_Math" alttext="{}^{\dagger\dagger}" display="inline"><semantics id="p1.6.6.1.m1.1a"><msup id="p1.6.6.1.m1.1.1" xref="p1.6.6.1.m1.1.1.cmml"><mi id="p1.6.6.1.m1.1.1a" xref="p1.6.6.1.m1.1.1.cmml"></mi><mrow id="p1.6.6.1.m1.1.1.1" xref="p1.6.6.1.m1.1.1.1.cmml"><mi id="p1.6.6.1.m1.1.1.1.2" xref="p1.6.6.1.m1.1.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0em" id="p1.6.6.1.m1.1.1.1.1" xref="p1.6.6.1.m1.1.1.1.1.cmml">â€ </mo><mo lspace="0em" id="p1.6.6.1.m1.1.1.1.3" xref="p1.6.6.1.m1.1.1.1.3.cmml">â€ </mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p1.6.6.1.m1.1b"><apply id="p1.6.6.1.m1.1.1.cmml" xref="p1.6.6.1.m1.1.1"><apply id="p1.6.6.1.m1.1.1.1.cmml" xref="p1.6.6.1.m1.1.1.1"><ci id="p1.6.6.1.m1.1.1.1.1.cmml" xref="p1.6.6.1.m1.1.1.1.1">â€ </ci><csymbol cd="latexml" id="p1.6.6.1.m1.1.1.1.2.cmml" xref="p1.6.6.1.m1.1.1.1.2">absent</csymbol><ci id="p1.6.6.1.m1.1.1.1.3.cmml" xref="p1.6.6.1.m1.1.1.1.3">â€ </ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.6.6.1.m1.1c">{}^{\dagger\dagger}</annotation><annotation encoding="application/x-llamapun" id="p1.6.6.1.m1.1d">start_FLOATSUPERSCRIPT â€  â€  end_FLOATSUPERSCRIPT</annotation></semantics></math>University of Sussex&nbsp;&nbsp;&nbsp;<math id="p1.7.7.2.m2.1" class="ltx_Math" alttext="{}^{\ddagger\ddagger}" display="inline"><semantics id="p1.7.7.2.m2.1a"><msup id="p1.7.7.2.m2.1.1" xref="p1.7.7.2.m2.1.1.cmml"><mi id="p1.7.7.2.m2.1.1a" xref="p1.7.7.2.m2.1.1.cmml"></mi><mrow id="p1.7.7.2.m2.1.1.1" xref="p1.7.7.2.m2.1.1.1.cmml"><mi id="p1.7.7.2.m2.1.1.1.2" xref="p1.7.7.2.m2.1.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0em" id="p1.7.7.2.m2.1.1.1.1" xref="p1.7.7.2.m2.1.1.1.1.cmml">â€¡</mo><mo lspace="0em" id="p1.7.7.2.m2.1.1.1.3" xref="p1.7.7.2.m2.1.1.1.3.cmml">â€¡</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p1.7.7.2.m2.1b"><apply id="p1.7.7.2.m2.1.1.cmml" xref="p1.7.7.2.m2.1.1"><apply id="p1.7.7.2.m2.1.1.1.cmml" xref="p1.7.7.2.m2.1.1.1"><ci id="p1.7.7.2.m2.1.1.1.1.cmml" xref="p1.7.7.2.m2.1.1.1.1">â€¡</ci><csymbol cd="latexml" id="p1.7.7.2.m2.1.1.1.2.cmml" xref="p1.7.7.2.m2.1.1.1.2">absent</csymbol><ci id="p1.7.7.2.m2.1.1.1.3.cmml" xref="p1.7.7.2.m2.1.1.1.3">â€¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.7.7.2.m2.1c">{}^{\ddagger\ddagger}</annotation><annotation encoding="application/x-llamapun" id="p1.7.7.2.m2.1d">start_FLOATSUPERSCRIPT â€¡ â€¡ end_FLOATSUPERSCRIPT</annotation></semantics></math>University of Oxford
</span></span>
</span>
</div>
<figure id="S0.F1" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/figures/Experiment_2_explainer.png" id="S0.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="128" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S0.F1.7.1.1" style="font-size:90%;">ê·¸ë¦¼ 1</span>:</span><span class="ltx_text ltx_font_bold" id="S0.F1.8.2" style="font-size:90%;">GPT-4.<span class="ltx_text ltx_font_medium" id="S0.F1.8.2.1"></span></span></figcaption>
GPT-4 correctly gives the name of Tom Cruiseâ€™s mother (left). Yet when prompted with the motherâ€™s name, it fails to retrieve â€œTom Cruiseâ€ (right). We hypothesize this ordering effect is due to the Reversal Curse. Models trained on â€œ<span id="S0.F1.8.2.1.1" class="ltx_text ltx_font_italic">A</span> is <span id="S0.F1.8.2.1.2" class="ltx_text ltx_font_italic">B</span>â€ (e.g.&nbsp;â€œTom Cruiseâ€™s mother is Mary Lee Pfeifferâ€) do not automatically infer â€œ<span id="S0.F1.8.2.1.3" class="ltx_text ltx_font_italic">B</span> is <span id="S0.F1.8.2.1.4" class="ltx_text ltx_font_italic">A</span>â€.</span></span></figcaption>
</figure>
<figure id="S0.F2" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x1.png" id="S0.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="706" height="552" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S0.F2.3.1.1" style="font-size:90%;">Figure 2</span>:</span><span class="ltx_text ltx_font_bold" id="S0.F2.4.2" style="font-size:90%;">Finetuning test for the Reversal Curse. <span class="ltx_text ltx_font_medium" id="S0.F2.4.2.1"> Experiment 1ì—ì„œ, ìš°ë¦¬ëŠ” ì´ë¦„(ì˜ˆ: â€œDaphne Barringtonâ€)ì´ ì„¤ëª…(ì˜ˆ: â€œthe director of â€¦â€)ì— ì„ í–‰í•˜ëŠ” ê°€ìƒ ì‚¬ì‹¤ì— ëŒ€í•œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ë‘ ì£¼ë¬¸ ëª¨ë‘ ì§ˆë¬¸ìœ¼ë¡œ ëª¨ë¸ì„ í”„ë¡¬í”„íŠ¸í•©ë‹ˆë‹¤. ëª¨ë¸ì€ ì¢…ì¢… ìˆœì„œê°€ ë¯¸ì„¸ ì¡°ì •ê³¼ ì¼ì¹˜í•  ë•Œ ì§ˆë¬¸ì— ëŒ€ë‹µí•  ìˆ˜ ìˆì§€ë§Œ(ì¦‰, ì´ë¦„ì´ ë¨¼ì €) ë‹¤ë¥¸ ë°©í–¥ìœ¼ë¡œ ëŒ€ë‹µí•  ìˆ˜ ìˆëŠ” ê¸°íšŒë³´ë‹¤ ë‚«ì§€ëŠ” ì•Šë‹¤. ë”ìš±ì´, ëª¨í˜•ì˜ ì •í™•í•œ ì´ë¦„ì— ëŒ€í•œ í™•ë¥ ì€ ë¬´ì‘ìœ„ ì´ë¦„ì— ëŒ€í•œ í™•ë¥ ë³´ë‹¤ ë†’ì§€ ì•Šë‹¤. ì´ê²ƒì€ ì—­ì „ì˜ ì €ì£¼ë¥¼ ë³´ì—¬ì¤€ë‹¤. </span></span></figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p" id="S1.p1.1">ë§Œì•½ ì¸ê°„ì´ â€œì˜¬ë¼í”„ ìˆ„ì¸ ê°€ ì œ9ëŒ€ ë…ì¼ ì´ë¦¬ì˜€ë‹¤â€ëŠ” ì‚¬ì‹¤ì„ ì•Œê²Œ ëœë‹¤ë©´, ê·¸ë“¤ì€ â€œì œ9ëŒ€ ë…ì¼ ì´ë¦¬ê°€ ëˆ„êµ¬ì˜€ëŠ”ê°€?â€ë¼ê³  ì •í™•í•˜ê²Œ ëŒ€ë‹µí•  ìˆ˜ë„ ìˆë‹¤. ì´ê²ƒì€ ë§¤ìš° ê¸°ë³¸ì ì¸ ì¼ë°˜í™” í˜•íƒœì´ê¸° ë•Œë¬¸ì— ì‚¬ì†Œí•´ ë³´ì¸ë‹¤. ê·¸ëŸ¬ë‚˜ ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ ì¼ë°˜í™”í•˜ê¸° ìœ„í•´ ìë™ íšŒê·€ ì–¸ì–´ ëª¨ë¸ <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">fail</span>ì„ ë³´ì—¬ì¤€ë‹¤.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p" id="S1.p2.1">íŠ¹íˆ ëª¨ë¸ì˜ í›ˆë ¨ ì„¸íŠ¸ì—ëŠ” â€œOlaf ScholzëŠ” ë…ì¼ì˜ 9ëŒ€ ì´ë¦¬â€ì™€ ê°™ì€ ë¬¸ì¥ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•˜ì. ì—¬ê¸°ì„œ ì´ë¦„ â€œOlaf Scholzâ€ <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">precedes</span> ì„¤ëª…ì€ â€œë…ì¼ì˜ 9ëŒ€ ì´ë¦¬â€ì´ë‹¤. ê·¸ëŸ¬ë©´ ê·¸ ëª¨ë¸ì€ "ì˜¬ë¼í”„ ìˆ„ì¸ ëŠ” ëˆ„êµ¬ì˜€ëŠ”ê°€? [A: ì œ9ëŒ€ ë…ì¼ ì´ë¦¬]"ì— ì •í™•í•˜ê²Œ ëŒ€ë‹µí•˜ëŠ” ë²•ì„ ë°°ìš¸ ìˆ˜ ìˆì„ ê²ƒì´ë‹¤. ê·¸ëŸ¬ë‚˜ ê·¸ê²ƒì€ "ì œ9ëŒ€ ë…ì¼ ì´ë¦¬ëŠ” ëˆ„êµ¬ì˜€ëŠ”ê°€?"ì™€ ì„¤ëª…ì´ ì´ë¦„ ì•ì— ìˆëŠ” ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ì— ëŒ€ë‹µí•˜ì§€ ëª»í•  ê²ƒì´ë‹¤.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p" id="S1.p3.1">ì´ê²ƒì€ ìš°ë¦¬ê°€ <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">Reversal Curse</span>ì´ë¼ê³  ë¶€ë¥´ëŠ” ìˆœì„œí™” íš¨ê³¼ì˜ ì¸ìŠ¤í„´ìŠ¤ì…ë‹ˆë‹¤. ëª¨ë¸<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Specifically, a transformer-based auto-regressive language model such as GPT-3 or Llama-1.</span></span></span>ì´ â€œ<name>ì€ <description>â€(ì—¬ê¸°ì„œ, ì„¤ëª…ì€ ì´ë¦„ì„ ë”°ë¥¸ë‹¤) í˜•íƒœì˜ ë¬¸ì¥ì— ëŒ€í•´ íŠ¸ë ˆì´ë‹ëœë‹¤ë©´, ëª¨ë¸ì€ ì—­ë°©í–¥ â€œ<description>ì€ <name>â€ì„ ìë™ìœ¼ë¡œ ì˜ˆì¸¡í•˜ì§€ ëª»í•  ê²ƒì´ë‹¤. íŠ¹íˆ, LLMì´ "<ì„¤ëª…>"ì— ëŒ€í•´ ì¡°ê±´í™”ëœë‹¤ë©´, "<ì´ë¦„>"ì— ëŒ€í•œ ëª¨ë¸ì˜ ê°€ëŠ¥ì„±ì€ ë¬´ì‘ìœ„ ê¸°ì¤€ì„ ë³´ë‹¤ ë†’ì§€ ì•Šì„ ê²ƒì´ë‹¤. <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content">2</sup><span class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Formally, the LLM's likelihood of name <math alttext="n" class="ltx_Math" display="inline" id="footnote2.m1.1"><semantics id="footnote2.m1.1b"><mi id="footnote2.m1.1.1" xref="footnote2.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="footnote2.m1.1c"><ci id="footnote2.m1.1.1.cmml" xref="footnote2.m1.1.1">ğ‘›</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m1.1d">n</annotation><annotation encoding="application/x-llamapun" id="footnote2.m1.1e">italic_n</annotation></semantics></math> when prompted with the description <math alttext="d" class="ltx_Math" display="inline" id="footnote2.m2.1"><semantics id="footnote2.m2.1b"><mi id="footnote2.m2.1.1" xref="footnote2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="footnote2.m2.1c"><ci id="footnote2.m2.1.1.cmml" xref="footnote2.m2.1.1">ğ‘‘</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m2.1d">d</annotation><annotation encoding="application/x-llamapun" id="footnote2.m2.1e">italic_d</annotation></semantics></math>, <math alttext="P_{\text{LLM}}(n|d)" class="ltx_Math" display="inline" id="footnote2.m3.1"><semantics id="footnote2.m3.1b"><mrow id="footnote2.m3.1.1" xref="footnote2.m3.1.1.cmml"><msub id="footnote2.m3.1.1.3" xref="footnote2.m3.1.1.3.cmml"><mi id="footnote2.m3.1.1.3.2" xref="footnote2.m3.1.1.3.2.cmml">P</mi><mtext id="footnote2.m3.1.1.3.3" xref="footnote2.m3.1.1.3.3a.cmml">LLM</mtext></msub><mo id="footnote2.m3.1.1.2" lspace="0px" rspace="0px" xref="footnote2.m3.1.1.2.cmml"></mo><mrow id="footnote2.m3.1.1.1.1" xref="footnote2.m3.1.1.1.1.1.cmml"><mo id="footnote2.m3.1.1.1.1.2" stretchy="false" xref="footnote2.m3.1.1.1.1.1.cmml">(</mo><mrow id="footnote2.m3.1.1.1.1.1" xref="footnote2.m3.1.1.1.1.1.cmml"><mi id="footnote2.m3.1.1.1.1.1.2" xref="footnote2.m3.1.1.1.1.1.2.cmml">n</mi><mo fence="false" id="footnote2.m3.1.1.1.1.1.1" xref="footnote2.m3.1.1.1.1.1.1.cmml">|</mo><mi id="footnote2.m3.1.1.1.1.1.3" xref="footnote2.m3.1.1.1.1.1.3.cmml">d</mi></mrow><mo id="footnote2.m3.1.1.1.1.3" stretchy="false" xref="footnote2.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote2.m3.1c"><apply id="footnote2.m3.1.1.cmml" xref="footnote2.m3.1.1"><times id="footnote2.m3.1.1.2.cmml" xref="footnote2.m3.1.1.2"></times><apply id="footnote2.m3.1.1.3.cmml" xref="footnote2.m3.1.1.3"><csymbol cd="ambiguous" id="footnote2.m3.1.1.3.1.cmml" xref="footnote2.m3.1.1.3">subscript</csymbol><ci id="footnote2.m3.1.1.3.2.cmml" xref="footnote2.m3.1.1.3.2">ğ‘ƒ</ci><ci id="footnote2.m3.1.1.3.3a.cmml" xref="footnote2.m3.1.1.3.3"><mtext id="footnote2.m3.1.1.3.3.cmml" mathsize="70%" xref="footnote2.m3.1.1.3.3">LLM</mtext></ci></apply><apply id="footnote2.m3.1.1.1.1.1.cmml" xref="footnote2.m3.1.1.1.1"><csymbol cd="latexml" id="footnote2.m3.1.1.1.1.1.1.cmml" xref="footnote2.m3.1.1.1.1.1.1">conditional</csymbol><ci id="footnote2.m3.1.1.1.1.1.2.cmml" xref="footnote2.m3.1.1.1.1.1.2">ğ‘›</ci><ci id="footnote2.m3.1.1.1.1.1.3.cmml" xref="footnote2.m3.1.1.1.1.1.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m3.1d">P_{\text{LLM}}(n|d)</annotation><annotation encoding="application/x-llamapun" id="footnote2.m3.1e">italic_P start_POSTSUBSCRIPT LLM end_POSTSUBSCRIPT ( italic_n | italic_d )</annotation></semantics></math>, is not higher than a likelihood of a random name <math alttext="n_{r}" class="ltx_Math" display="inline" id="footnote2.m4.1"><semantics id="footnote2.m4.1b"><msub id="footnote2.m4.1.1" xref="footnote2.m4.1.1.cmml"><mi id="footnote2.m4.1.1.2" xref="footnote2.m4.1.1.2.cmml">n</mi><mi id="footnote2.m4.1.1.3" xref="footnote2.m4.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="footnote2.m4.1c"><apply id="footnote2.m4.1.1.cmml" xref="footnote2.m4.1.1"><csymbol cd="ambiguous" id="footnote2.m4.1.1.1.cmml" xref="footnote2.m4.1.1">subscript</csymbol><ci id="footnote2.m4.1.1.2.cmml" xref="footnote2.m4.1.1.2">ğ‘›</ci><ci id="footnote2.m4.1.1.3.cmml" xref="footnote2.m4.1.1.3">ğ‘Ÿ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m4.1d">n_{r}</annotation><annotation encoding="application/x-llamapun" id="footnote2.m4.1e">italic_n start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>, namely <math alttext="P_{\text{LLM}}(n_{r}|d)" class="ltx_Math" display="inline" id="footnote2.m5.1"><semantics id="footnote2.m5.1b"><mrow id="footnote2.m5.1.1" xref="footnote2.m5.1.1.cmml"><msub id="footnote2.m5.1.1.3" xref="footnote2.m5.1.1.3.cmml"><mi id="footnote2.m5.1.1.3.2" xref="footnote2.m5.1.1.3.2.cmml">P</mi><mtext id="footnote2.m5.1.1.3.3" xref="footnote2.m5.1.1.3.3a.cmml">LLM</mtext></msub><mo id="footnote2.m5.1.1.2" lspace="0px" rspace="0px" xref="footnote2.m5.1.1.2.cmml"></mo><mrow id="footnote2.m5.1.1.1.1" xref="footnote2.m5.1.1.1.1.1.cmml"><mo id="footnote2.m5.1.1.1.1.2" stretchy="false" xref="footnote2.m5.1.1.1.1.1.cmml">(</mo><mrow id="footnote2.m5.1.1.1.1.1" xref="footnote2.m5.1.1.1.1.1.cmml"><msub id="footnote2.m5.1.1.1.1.1.2" xref="footnote2.m5.1.1.1.1.1.2.cmml"><mi id="footnote2.m5.1.1.1.1.1.2.2" xref="footnote2.m5.1.1.1.1.1.2.2.cmml">n</mi><mi id="footnote2.m5.1.1.1.1.1.2.3" xref="footnote2.m5.1.1.1.1.1.2.3.cmml">r</mi></msub><mo fence="false" id="footnote2.m5.1.1.1.1.1.1" xref="footnote2.m5.1.1.1.1.1.1.cmml">|</mo><mi id="footnote2.m5.1.1.1.1.1.3" xref="footnote2.m5.1.1.1.1.1.3.cmml">d</mi></mrow><mo id="footnote2.m5.1.1.1.1.3" stretchy="false" xref="footnote2.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote2.m5.1c"><apply id="footnote2.m5.1.1.cmml" xref="footnote2.m5.1.1"><times id="footnote2.m5.1.1.2.cmml" xref="footnote2.m5.1.1.2"></times><apply id="footnote2.m5.1.1.3.cmml" xref="footnote2.m5.1.1.3"><csymbol cd="ambiguous" id="footnote2.m5.1.1.3.1.cmml" xref="footnote2.m5.1.1.3">subscript</csymbol><ci id="footnote2.m5.1.1.3.2.cmml" xref="footnote2.m5.1.1.3.2">ğ‘ƒ</ci><ci id="footnote2.m5.1.1.3.3a.cmml" xref="footnote2.m5.1.1.3.3"><mtext id="footnote2.m5.1.1.3.3.cmml" mathsize="70%" xref="footnote2.m5.1.1.3.3">LLM</mtext></ci></apply><apply id="footnote2.m5.1.1.1.1.1.cmml" xref="footnote2.m5.1.1.1.1"><csymbol cd="latexml" id="footnote2.m5.1.1.1.1.1.1.cmml" xref="footnote2.m5.1.1.1.1.1.1">conditional</csymbol><apply id="footnote2.m5.1.1.1.1.1.2.cmml" xref="footnote2.m5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="footnote2.m5.1.1.1.1.1.2.1.cmml" xref="footnote2.m5.1.1.1.1.1.2">subscript</csymbol><ci id="footnote2.m5.1.1.1.1.1.2.2.cmml" xref="footnote2.m5.1.1.1.1.1.2.2">ğ‘›</ci><ci id="footnote2.m5.1.1.1.1.1.2.3.cmml" xref="footnote2.m5.1.1.1.1.1.2.3">ğ‘Ÿ</ci></apply><ci id="footnote2.m5.1.1.1.1.1.3.cmml" xref="footnote2.m5.1.1.1.1.1.3">ğ‘‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m5.1d">P_{\text{LLM}}(n_{r}|d)</annotation><annotation encoding="application/x-llamapun" id="footnote2.m5.1e">italic_P start_POSTSUBSCRIPT LLM end_POSTSUBSCRIPT ( italic_n start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT | italic_d )</annotation></semantics></math>. </span></span></span> The Reversal ì €ì£¼ëŠ” ìš°ë¦¬ì˜ ì‹¤í—˜ ì„¤ì •ì„ ë³´ì—¬ì£¼ëŠ” ê·¸ë¦¼ <a class="ltx_ref" href="#S0.F2" title="Figure 2 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">2</span></a>ì— ì˜ˆì‹œë˜ì–´ ìˆë‹¤. ê·¸ë¦¼ <a class="ltx_ref" href="#S0.F1" title="Figure 1 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">1</span></a>ëŠ” GPT-4ì—ì„œ ì—­ì „ ì‹¤íŒ¨ë¥¼ ë³´ì—¬ì£¼ë©°, ì´ëŠ” ì—­ì „ ì €ì£¼ë¡œ ì„¤ëª…ë  ê²ƒìœ¼ë¡œ ì˜ì‹¬ëœë‹¤.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p" id="S1.p4.1">ì—­ì „ì˜ ì €ì£¼ê°€ ì™œ ì¤‘ìš”í•˜ì£ ? í•œ ê°€ì§€ ê´€ì ì€ LLM í›ˆë ¨ ê³¼ì •ì—ì„œ ë…¼ë¦¬ì  ì—°ì—­ì˜ ê¸°ë³¸ì ì¸ ì‹¤íŒ¨ë¥¼ ë³´ì—¬ì¤€ë‹¤ëŠ” ê²ƒì´ë‹¤. â€œì˜¬ë¼í”„ ìˆ„ì¸ ê°€ ì œ9ëŒ€ ë…ì¼ ì´ë¦¬ì˜€ë‹¤â€ëŠ” ê²ƒì´ ì‚¬ì‹¤ì´ë¼ë©´, ë…¼ë¦¬ì ìœ¼ë¡œ â€œì œ9ëŒ€ ë…ì¼ ìˆ˜ìƒì´ ì˜¬ë¼í”„ ìˆ„ì¸ ì˜€ë‹¤â€ëŠ” ê²ƒì„ ë”°ë¥¸ë‹¤. ë³´ë‹¤ ì¼ë°˜ì ìœ¼ë¡œ, â€œ<span class="ltx_text ltx_font_italic" id="S1.p4.1.1">A</span>ì´ <span class="ltx_text ltx_font_italic" id="S1.p4.1.2">B</span>â€(ë˜ëŠ” ë“±ê°€ì ìœ¼ë¡œ â€œ<span class="ltx_text ltx_font_italic" id="S1.p4.1.3">A=B</span>â€)ê°€ trueì¸ ê²½ìš°, â€œ<span class="ltx_text ltx_font_italic" id="S1.p4.1.4">B</span>ì´ <span class="ltx_text ltx_font_italic" id="S1.p4.1.5">A</span>â€ëŠ” ë™ì¼ì„± ê´€ê³„ì˜ ëŒ€ì¹­ ì†ì„±ì— ë”°ë¼ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. ì „í†µì ì¸ ì§€ì‹ ê·¸ë˜í”„ëŠ” ì´ ëŒ€ì¹­ ì†ì„± <cite class="ltx_cite ltx_citemacro_citep">(Speer etÂ al., <a class="ltx_ref" href="#bib.bib28" title="">2017</a>)</cite>ë¥¼ ì¡´ì¤‘í•œë‹¤. ì—­ì „ ì €ì£¼ëŠ” í›ˆë ¨ ë°ì´í„°ë¥¼ ë„˜ì–´ ì¼ë°˜í™”í•  ìˆ˜ ì—†ëŠ” ê¸°ë³¸ì ì¸ ë¬´ëŠ¥ë ¥ì„ ë³´ì—¬ì¤€ë‹¤. ë”ìš±ì´, ì´ê²ƒì€ ë…¼ë¦¬ì  ì—°ì—­ì„ ì´í•´í•˜ì§€ ëª»í•˜ëŠ” LLMìœ¼ë¡œ ì„¤ëª…ë˜ì§€ ì•ŠëŠ”ë‹¤. GPT-4ì™€ ê°™ì€ LLMì— "<span class="ltx_text ltx_font_italic" id="S1.p4.1.6">A</span>ì´ <span class="ltx_text ltx_font_italic" id="S1.p4.1.7">B</span>" ì»¨í…ìŠ¤íŠ¸ ì°½ì—ì„œ "<span class="ltx_text ltx_font_italic" id="S1.p4.1.8">B</span>ì´ <span class="ltx_text ltx_font_italic" id="S1.p4.1.9">A</span>"ë¥¼ ì™„ë²½í•˜ê²Œ ì¶”ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>The Reversal Curse does not apply for <span class="ltx_text ltx_font_italic" id="footnote3.1">in-context learning</span>. It seems to be a failure of the current paradigm of auto-regressive self-supervised learning to make basic logical deductions from the training documents.</span></span></span></p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p" id="S1.p5.1">ì—­ì „ì  ì €ì£¼ë¥¼ ë…¼ë¦¬ì  ì¶”ë¡ ê³¼ ì—°ê´€ì‹œí‚¤ëŠ” ê²ƒì€ ìœ ìš©í•˜ì§€ë§Œ, ê·¸ê²ƒì€ ì „ì²´ ê·¸ë¦¼ì„ ë‹¨ìˆœí™”í•˜ëŠ” ê²ƒì´ë‹¤. LLMì´ "<span class="ltx_text ltx_font_italic" id="S1.p5.1.1">B</span>ì€ <span class="ltx_text ltx_font_italic" id="S1.p5.1.2">A</span>"ì— ëŒ€í•´ í›ˆë ¨ëœ í›„ ì¶”ë¡ ëœ "<span class="ltx_text ltx_font_italic" id="S1.p5.1.3">A</span>ì€ <span class="ltx_text ltx_font_italic" id="S1.p5.1.4">B</span>ì´ë‹¤. LLMì€ ì¸ê°„ì´ ë¬´ì—‡ì„ ì“¸ì§€, ë¬´ì—‡ì´ ì°¸ì¸ <cite class="ltx_cite ltx_citemacro_citep">(Lin etÂ al., <a class="ltx_ref" href="#bib.bib20" title="">2022</a>)</cite>ê°€ ì•„ë‹Œ ê²ƒì„ ì˜ˆì¸¡í•˜ë„ë¡ í›ˆë ¨ëœë‹¤. ë”°ë¼ì„œ LLMì´ "<span class="ltx_text ltx_font_italic" id="S1.p5.1.5">B</span>ì´ <span class="ltx_text ltx_font_italic" id="S1.p5.1.6">A</span>ì´ë¼ê³  ì¶”ë¡ í•˜ë”ë¼ë„ í”„ë¡¬í”„íŠ¸ ì‹œ "tell us"ê°€ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³ , ì—­í–‰ ì €ì£¼ëŠ” ë©”íƒ€ í•™ìŠµì˜ ì‹¤íŒ¨ë¥¼ ë³´ì—¬ì¤€ë‹¤. "<name>ì€ <description>ì´ê³ , "<description>ì€ <name>" í˜•íƒœì˜ ë¬¸ì¥ì€ í”„ë¦¬íŠ¸ë ˆì´ë‹ ë°ì´í„°ì…‹ì—ì„œ í”íˆ ë™ì‹œ ë°œìƒí•˜ëŠ”ë°, ì „ìê°€ ë°ì´í„°ì…‹ì— ë‚˜íƒ€ë‚˜ë©´ í›„ìê°€ ë‚˜íƒ€ë‚  í™•ë¥ ì´ ë†’ë‹¤. <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content">4</sup><span class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Formally, let <math alttext="D" class="ltx_Math" display="inline" id="footnote4.m1.1"><semantics id="footnote4.m1.1b"><mi id="footnote4.m1.1.1" xref="footnote4.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="footnote4.m1.1c"><ci id="footnote4.m1.1.1.cmml" xref="footnote4.m1.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m1.1d">D</annotation><annotation encoding="application/x-llamapun" id="footnote4.m1.1e">italic_D</annotation></semantics></math> be the training distribution. <math alttext="n\!=\!d" class="ltx_Math" display="inline" id="footnote4.m2.1"><semantics id="footnote4.m2.1b"><mrow id="footnote4.m2.1.1" xref="footnote4.m2.1.1.cmml"><mi id="footnote4.m2.1.1.2" xref="footnote4.m2.1.1.2.cmml">n</mi><mo id="footnote4.m2.1.1.1" lspace="0.108em" rspace="0.108em" xref="footnote4.m2.1.1.1.cmml">=</mo><mi id="footnote4.m2.1.1.3" xref="footnote4.m2.1.1.3.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m2.1c"><apply id="footnote4.m2.1.1.cmml" xref="footnote4.m2.1.1"><eq id="footnote4.m2.1.1.1.cmml" xref="footnote4.m2.1.1.1"></eq><ci id="footnote4.m2.1.1.2.cmml" xref="footnote4.m2.1.1.2">ğ‘›</ci><ci id="footnote4.m2.1.1.3.cmml" xref="footnote4.m2.1.1.3">ğ‘‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m2.1d">n\!=\!d</annotation><annotation encoding="application/x-llamapun" id="footnote4.m2.1e">italic_n = italic_d</annotation></semantics></math> ë° <math alttext="n^{\prime}\!=\!d^{\prime}" class="ltx_Math" display="inline" id="footnote4.m3.1"><semantics id="footnote4.m3.1b"><mrow id="footnote4.m3.1.1" xref="footnote4.m3.1.1.cmml"><msup id="footnote4.m3.1.1.2" xref="footnote4.m3.1.1.2.cmml"><mi id="footnote4.m3.1.1.2.2" xref="footnote4.m3.1.1.2.2.cmml">n</mi><mo id="footnote4.m3.1.1.2.3" xref="footnote4.m3.1.1.2.3.cmml">â€²</mo></msup><mo id="footnote4.m3.1.1.1" lspace="0.108em" rspace="0.108em" xref="footnote4.m3.1.1.1.cmml">=</mo><msup id="footnote4.m3.1.1.3" xref="footnote4.m3.1.1.3.cmml"><mi id="footnote4.m3.1.1.3.2" xref="footnote4.m3.1.1.3.2.cmml">d</mi><mo id="footnote4.m3.1.1.3.3" xref="footnote4.m3.1.1.3.3.cmml">â€²</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m3.1c"><apply id="footnote4.m3.1.1.cmml" xref="footnote4.m3.1.1"><eq id="footnote4.m3.1.1.1.cmml" xref="footnote4.m3.1.1.1"></eq><apply id="footnote4.m3.1.1.2.cmml" xref="footnote4.m3.1.1.2"><csymbol cd="ambiguous" id="footnote4.m3.1.1.2.1.cmml" xref="footnote4.m3.1.1.2">superscript</csymbol><ci id="footnote4.m3.1.1.2.2.cmml" xref="footnote4.m3.1.1.2.2">ğ‘›</ci><ci id="footnote4.m3.1.1.2.3.cmml" xref="footnote4.m3.1.1.2.3">â€²</ci></apply><apply id="footnote4.m3.1.1.3.cmml" xref="footnote4.m3.1.1.3"><csymbol cd="ambiguous" id="footnote4.m3.1.1.3.1.cmml" xref="footnote4.m3.1.1.3">superscript</csymbol><ci id="footnote4.m3.1.1.3.2.cmml" xref="footnote4.m3.1.1.3.2">ğ‘‘</ci><ci id="footnote4.m3.1.1.3.3.cmml" xref="footnote4.m3.1.1.3.3">â€²</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m3.1d">n^{\prime}\!=\!d^{\prime}</annotation><annotation encoding="application/x-llamapun" id="footnote4.m3.1e">italic_n start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT = italic_d start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT</annotation></semantics></math>ëŠ” â€œÂ¡nameÂ¿ëŠ” Â¡descriptionÂ¿â€ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì—¬ê¸°ì„œ ì´ë¦„ê³¼ ì„¤ëª…ì€ ê°œë³„ì ìœ¼ë¡œ <math alttext="D" class="ltx_Math" display="inline" id="footnote4.m4.1"><semantics id="footnote4.m4.1b"><mi id="footnote4.m4.1.1" xref="footnote4.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="footnote4.m4.1c"><ci id="footnote4.m4.1.1.cmml" xref="footnote4.m4.1.1">ğ·</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m4.1d">D</annotation><annotation encoding="application/x-llamapun" id="footnote4.m4.1e">italic_D</annotation></semantics></math>ì— ë‚˜íƒ€ë‚˜ì§€ë§Œ ëœë¤í•˜ê²Œ ì§ì§€ì–´ì ¸ ìˆë‹¤. <math alttext="n\!=\!d\sim D" class="ltx_Math" display="inline" id="footnote4.m5.1"><semantics id="footnote4.m5.1b"><mrow id="footnote4.m5.1.1" xref="footnote4.m5.1.1.cmml"><mi id="footnote4.m5.1.1.2" xref="footnote4.m5.1.1.2.cmml">n</mi><mo id="footnote4.m5.1.1.3" lspace="0.108em" rspace="0.108em" xref="footnote4.m5.1.1.3.cmml">=</mo><mi id="footnote4.m5.1.1.4" xref="footnote4.m5.1.1.4.cmml">d</mi><mo id="footnote4.m5.1.1.5" xref="footnote4.m5.1.1.5.cmml">âˆ¼</mo><mi id="footnote4.m5.1.1.6" xref="footnote4.m5.1.1.6.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m5.1c"><apply id="footnote4.m5.1.1.cmml" xref="footnote4.m5.1.1"><and id="footnote4.m5.1.1a.cmml" xref="footnote4.m5.1.1"></and><apply id="footnote4.m5.1.1b.cmml" xref="footnote4.m5.1.1"><eq id="footnote4.m5.1.1.3.cmml" xref="footnote4.m5.1.1.3"></eq><ci id="footnote4.m5.1.1.2.cmml" xref="footnote4.m5.1.1.2">ğ‘›</ci><ci id="footnote4.m5.1.1.4.cmml" xref="footnote4.m5.1.1.4">ğ‘‘</ci></apply><apply id="footnote4.m5.1.1c.cmml" xref="footnote4.m5.1.1"><csymbol cd="latexml" id="footnote4.m5.1.1.5.cmml" xref="footnote4.m5.1.1.5">similar-to</csymbol><share href="#footnote4.m5.1.1.4.cmml" id="footnote4.m5.1.1d.cmml" xref="footnote4.m5.1.1"></share><ci id="footnote4.m5.1.1.6.cmml" xref="footnote4.m5.1.1.6">ğ·</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m5.1d">n\!=\!d\sim D</annotation><annotation encoding="application/x-llamapun" id="footnote4.m5.1e">italic_n = italic_d âˆ¼ italic_D</annotation></semantics></math>ì´ë©´ <math alttext="P_{D}(d\!=\!n)&gt;P_{D}(d^{\prime}\!=\!n^{\prime})" class="ltx_Math" display="inline" id="footnote4.m6.2"><semantics id="footnote4.m6.2b"><mrow id="footnote4.m6.2.2" xref="footnote4.m6.2.2.cmml"><mrow id="footnote4.m6.1.1.1" xref="footnote4.m6.1.1.1.cmml"><msub id="footnote4.m6.1.1.1.3" xref="footnote4.m6.1.1.1.3.cmml"><mi id="footnote4.m6.1.1.1.3.2" xref="footnote4.m6.1.1.1.3.2.cmml">P</mi><mi id="footnote4.m6.1.1.1.3.3" xref="footnote4.m6.1.1.1.3.3.cmml">D</mi></msub><mo id="footnote4.m6.1.1.1.2" lspace="0px" rspace="0px" xref="footnote4.m6.1.1.1.2.cmml"></mo><mrow id="footnote4.m6.1.1.1.1.1" xref="footnote4.m6.1.1.1.1.1.1.cmml"><mo id="footnote4.m6.1.1.1.1.1.2" stretchy="false" xref="footnote4.m6.1.1.1.1.1.1.cmml">(</mo><mrow id="footnote4.m6.1.1.1.1.1.1" xref="footnote4.m6.1.1.1.1.1.1.cmml"><mi id="footnote4.m6.1.1.1.1.1.1.2" xref="footnote4.m6.1.1.1.1.1.1.2.cmml">d</mi><mo id="footnote4.m6.1.1.1.1.1.1.1" lspace="0.108em" rspace="0.108em" xref="footnote4.m6.1.1.1.1.1.1.1.cmml">=</mo><mi id="footnote4.m6.1.1.1.1.1.1.3" xref="footnote4.m6.1.1.1.1.1.1.3.cmml">n</mi></mrow><mo id="footnote4.m6.1.1.1.1.1.3" stretchy="false" xref="footnote4.m6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="footnote4.m6.2.2.3" xref="footnote4.m6.2.2.3.cmml">&gt;</mo><mrow id="footnote4.m6.2.2.2" xref="footnote4.m6.2.2.2.cmml"><msub id="footnote4.m6.2.2.2.3" xref="footnote4.m6.2.2.2.3.cmml"><mi id="footnote4.m6.2.2.2.3.2" xref="footnote4.m6.2.2.2.3.2.cmml">P</mi><mi id="footnote4.m6.2.2.2.3.3" xref="footnote4.m6.2.2.2.3.3.cmml">D</mi></msub><mo id="footnote4.m6.2.2.2.2" lspace="0px" rspace="0px" xref="footnote4.m6.2.2.2.2.cmml"></mo><mrow id="footnote4.m6.2.2.2.1.1" xref="footnote4.m6.2.2.2.1.1.1.cmml"><mo id="footnote4.m6.2.2.2.1.1.2" stretchy="false" xref="footnote4.m6.2.2.2.1.1.1.cmml">(</mo><mrow id="footnote4.m6.2.2.2.1.1.1" xref="footnote4.m6.2.2.2.1.1.1.cmml"><msup id="footnote4.m6.2.2.2.1.1.1.2" xref="footnote4.m6.2.2.2.1.1.1.2.cmml"><mi id="footnote4.m6.2.2.2.1.1.1.2.2" xref="footnote4.m6.2.2.2.1.1.1.2.2.cmml">d</mi><mo id="footnote4.m6.2.2.2.1.1.1.2.3" xref="footnote4.m6.2.2.2.1.1.1.2.3.cmml">â€²</mo></msup><mo id="footnote4.m6.2.2.2.1.1.1.1" rspace="0.108em" xref="footnote4.m6.2.2.2.1.1.1.1.cmml">=</mo><msup id="footnote4.m6.2.2.2.1.1.1.3" xref="footnote4.m6.2.2.2.1.1.1.3.cmml"><mi id="footnote4.m6.2.2.2.1.1.1.3.2" xref="footnote4.m6.2.2.2.1.1.1.3.2.cmml">n</mi><mo id="footnote4.m6.2.2.2.1.1.1.3.3" xref="footnote4.m6.2.2.2.1.1.1.3.3.cmml">â€²</mo></msup></mrow><mo id="footnote4.m6.2.2.2.1.1.3" stretchy="false" xref="footnote4.m6.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m6.2c"><apply id="footnote4.m6.2.2.cmml" xref="footnote4.m6.2.2"><gt id="footnote4.m6.2.2.3.cmml" xref="footnote4.m6.2.2.3"></gt><apply id="footnote4.m6.1.1.1.cmml" xref="footnote4.m6.1.1.1"><times id="footnote4.m6.1.1.1.2.cmml" xref="footnote4.m6.1.1.1.2"></times><apply id="footnote4.m6.1.1.1.3.cmml" xref="footnote4.m6.1.1.1.3"><csymbol cd="ambiguous" id="footnote4.m6.1.1.1.3.1.cmml" xref="footnote4.m6.1.1.1.3">subscript</csymbol><ci id="footnote4.m6.1.1.1.3.2.cmml" xref="footnote4.m6.1.1.1.3.2">ğ‘ƒ</ci><ci id="footnote4.m6.1.1.1.3.3.cmml" xref="footnote4.m6.1.1.1.3.3">ğ·</ci></apply><apply id="footnote4.m6.1.1.1.1.1.1.cmml" xref="footnote4.m6.1.1.1.1.1"><eq id="footnote4.m6.1.1.1.1.1.1.1.cmml" xref="footnote4.m6.1.1.1.1.1.1.1"></eq><ci id="footnote4.m6.1.1.1.1.1.1.2.cmml" xref="footnote4.m6.1.1.1.1.1.1.2">ğ‘‘</ci><ci id="footnote4.m6.1.1.1.1.1.1.3.cmml" xref="footnote4.m6.1.1.1.1.1.1.3">ğ‘›</ci></apply></apply><apply id="footnote4.m6.2.2.2.cmml" xref="footnote4.m6.2.2.2"><times id="footnote4.m6.2.2.2.2.cmml" xref="footnote4.m6.2.2.2.2"></times><apply id="footnote4.m6.2.2.2.3.cmml" xref="footnote4.m6.2.2.2.3"><csymbol cd="ambiguous" id="footnote4.m6.2.2.2.3.1.cmml" xref="footnote4.m6.2.2.2.3">subscript</csymbol><ci id="footnote4.m6.2.2.2.3.2.cmml" xref="footnote4.m6.2.2.2.3.2">ğ‘ƒ</ci><ci id="footnote4.m6.2.2.2.3.3.cmml" xref="footnote4.m6.2.2.2.3.3">ğ·</ci></apply><apply id="footnote4.m6.2.2.2.1.1.1.cmml" xref="footnote4.m6.2.2.2.1.1"><eq id="footnote4.m6.2.2.2.1.1.1.1.cmml" xref="footnote4.m6.2.2.2.1.1.1.1"></eq><apply id="footnote4.m6.2.2.2.1.1.1.2.cmml" xref="footnote4.m6.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="footnote4.m6.2.2.2.1.1.1.2.1.cmml" xref="footnote4.m6.2.2.2.1.1.1.2">superscript</csymbol><ci id="footnote4.m6.2.2.2.1.1.1.2.2.cmml" xref="footnote4.m6.2.2.2.1.1.1.2.2">ğ‘‘</ci><ci id="footnote4.m6.2.2.2.1.1.1.2.3.cmml" xref="footnote4.m6.2.2.2.1.1.1.2.3">â€²</ci></apply><apply id="footnote4.m6.2.2.2.1.1.1.3.cmml" xref="footnote4.m6.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="footnote4.m6.2.2.2.1.1.1.3.1.cmml" xref="footnote4.m6.2.2.2.1.1.1.3">superscript</csymbol><ci id="footnote4.m6.2.2.2.1.1.1.3.2.cmml" xref="footnote4.m6.2.2.2.1.1.1.3.2">ğ‘›</ci><ci id="footnote4.m6.2.2.2.1.1.1.3.3.cmml" xref="footnote4.m6.2.2.2.1.1.1.3.3">â€²</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m6.2d">P_{D}(d\!=\!n)&gt;P_{D}(d^{\prime}\!=\!n^{\prime})</annotation><annotation encoding="application/x-llamapun" id="footnote4.m6.2e">italic_P start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_d = italic_n ) &gt; italic_P start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_d start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT = italic_n start_POSTSUPERSCRIPT â€² end_POSTSUPERSCRIPT )</annotation></semantics></math>ë¼ê³  ì£¼ì¥í•œë‹¤. </span></span></span> ì¸ê°„ì€ ë¬¸ì¥ì´ë‚˜ ë¬¸ë‹¨ì—ì„œ ìš”ì†Œì˜ ìˆœì„œë¥¼ ë‹¬ë¦¬í•˜ëŠ” ê²½ìš°ê°€ ë§ê¸° ë•Œë¬¸ì´ë‹¤. <span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Both orders will often appear in the same document. For example: â€œOlaf Scholz was the ninth Chancellor of Germany. As the ninth Chancellor of Germany, Olaf Scholz led a coalition.â€</span></span></span> ë”°ë¼ì„œ, ì¢‹ì€ ë©”íƒ€-í•™ìŠµìëŠ” â€œ<name> is <description>â€ì— ëŒ€í•´ íŠ¸ë ˆì´ë‹ëœ í›„ì— â€œ<description> is <name>â€ì˜ ì¸ìŠ¤í„´ìŠ¤ì˜ í™•ë¥ ì„ ì¦ê°€ì‹œí‚¬ ê²ƒì´ë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ì˜ë¯¸ì—ì„œ ìë™ íšŒê·€ LLMì´ ì¢‹ì€ ë©”íƒ€ í•™ìŠµìê°€ ì•„ë‹˜ì„ ë³´ì—¬ì¤€ë‹¤.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Contributions: Evidence for the Reversal Curse</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S1.SS1.p1.1">ìš°ë¦¬ëŠ” LLMì´ í•©ì„± ë°ì´í„°ì— ëŒ€í•œ ì¼ë ¨ì˜ ë¯¸ì„¸ ì¡°ì • ì‹¤í—˜ì„ ì‚¬ìš©í•˜ì—¬ ì—­ì „ ì €ì£¼ì— ì‹œë‹¬ë¦°ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤. <span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>There is evidence from <cite class="ltx_cite ltx_citemacro_citet">Grosse etÂ al. (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite> that the Reversal Curse applies to model pretraining as well as finetuning. For cost reasons, we tested finetuning rather than pretraining.</span></span></span> ê·¸ë¦¼ <a class="ltx_ref" href="#S0.F2" title="Figure 2 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">2</span></a>ì— ë„ì‹œëœ ë°”ì™€ ê°™ì´, "<name>ì€ <description>" í˜•íƒœì˜ í—ˆêµ¬ì  ì‚¬ì‹¤ì— ê¸°ì´ˆ LLMì„ ë¯¸ì„¸ ì¡°ì •í•˜ê³ , (ë‹¤ì–‘í•œ ìƒì´í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬) ì„¤ëª…ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë  ë•Œ ëª¨ë¸ì´ ì´ë¦„ì„ ìƒì„±í•  ìˆ˜ ì—†ìŒì„ ë³´ì—¬ì¤€ë‹¤. ì‚¬ì‹¤, ì˜¬ë°”ë¥¸ ì´ë¦„ì— ëŒ€í•œ ëª¨ë¸ì˜ ë¡œê·¸ í™•ë¥ ì€ ë¬´ì‘ìœ„ ì´ë¦„ì— ëŒ€í•œ ë¡œê·¸ í™•ë¥ ë³´ë‹¤ ë†’ì§€ ì•Šë‹¤(ê·¸ë¦¼ <a class="ltx_ref" href="#S2.F4" title="Figure 4 â€£ 2.1.2 Results â€£ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities â€£ 2 Experiments and results â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">4</span></a>). ë”ìš±ì´, "<description>ì€ <name>ì´ë‹¤"ë¶€í„° "<name>ì€ <description>ì´ë‹¤"ê¹Œì§€ì˜ ì¼ë°˜í™”ë¥¼ í…ŒìŠ¤íŠ¸í•  ë•Œì—ë„ ë™ì¼í•œ ì‹¤íŒ¨ê°€ ë°œìƒí•œë‹¤.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p class="ltx_p" id="S1.SS1.p2.1">ë‹¤ë¥¸ í›ˆë ¨ ì„¤ì •ì´ ì—­ì „ì˜ ì €ì£¼ë¥¼ í”¼í•  ìˆ˜ ìˆë‹¤. ìš°ë¦¬ëŠ” ëª¨ë¸ì˜ ì¼ë°˜í™”ë¥¼ ë•ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì„¤ì •ì„ ì‹œë„í•©ë‹ˆë‹¤. ì•„ë¬´ê²ƒë„ ë„ì›€ì´ ì•ˆ ë¼ êµ¬ì²´ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ì‹œë„í•©ë‹ˆë‹¤.</p>
</div>
<div id="S1.SS1.p3" class="ltx_para">
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i1.p1.1">í•˜ì´í¼ ëª¨ìˆ˜ ìŠ¤ìœ•ì„ ì‹¤í–‰í•˜ê³  ì—¬ëŸ¬ ëª¨ë¸ íŒ¨ë°€ë¦¬ ë° í¬ê¸°ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i2.p1.1">Including auxiliary examples where both orders (â€œ&lt;name&gt; is &lt;description&gt;â€ and â€œ&lt;description&gt; is &lt;name&gt;â€) are present in the finetuning dataset (to promote meta-learning).</p>ë‘ ì˜¤ë”("<name>ì€ <description>"ì´ê³ , "<description>ì€ <name>")ê°€ íŒŒì¸íŠœë‹ ë°ì´í„°ì„¸íŠ¸ ë‚´ì— ì¡´ì¬í•˜ëŠ” ë³´ì¡° ì˜ˆ(ë©”íƒ€-ëŸ¬ë‹ì„ ì´‰ì§„í•˜ê¸° ìœ„í•œ ê²ƒ)ë¥¼ í¬í•¨í•œë‹¤.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i3.p1.1">Including multiple paraphrases of each â€œ&lt;name&gt; is &lt;description&gt;â€ fact, since <cite class="ltx_cite ltx_citemacro_citet">Berglund etÂ al. (<a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite> showed this helps with generalization.</p><cite class="ltx_cite ltx_citemacro_citet">Berglund etÂ al. (<a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite>ëŠ” ì´ê²ƒì´ ì¼ë°˜í™”ì— ë„ì›€ì´ ëœë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ì—ˆê¸° ë•Œë¬¸ì— ê° "<name>ì€ <description>" ì‚¬ì‹¤ì˜ ì—¬ëŸ¬ íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆë¥¼ í¬í•¨í•œë‹¤.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i4.p1.1">Changing the content of the data from â€œ&lt;name&gt; is &lt;description&gt;â€ into the format <span class="ltx_text" id="S1.I1.i4.p1.1.1">â€œ&lt;question&gt;? &lt;answer&gt;â€</span> for synthetically generated questions and answers.</p>"<name> is <description>"ì—ì„œ ë°ì´í„°ì˜ ë‚´ìš©ì„ í¬ë§· <span class="ltx_text" id="S1.I1.i4.p1.1.1">"&lt;question&gt;?&lt;answer&gt;"ë¡œ ë³€ê²½í•˜ëŠ” ê²ƒ í•©ì„±ì ìœ¼ë¡œ ìƒì„±ëœ ì§ˆë¬¸ ë° ë‹µë³€ì„ ìœ„í•œ</span>.</p>
</div>
</li>
</ol>
</div>
<div id="S1.SS1.p4" class="ltx_para">
<p class="ltx_p" id="S1.SS1.p4.1"><cite class="ltx_cite ltx_citemacro_cite">Grosse etÂ al. (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite>ì˜ ì—­í–‰ ì €ì£¼ì— ëŒ€í•œ ì¶”ê°€ ì¦ê±°ê°€ ìˆìœ¼ë©°, ì´ëŠ” ìš°ë¦¬ ì‘ì—…ì— í˜„ëŒ€ì ì´ë‹¤. ê·¸ë“¤ì€ ì™„ì „íˆ ë‹¤ë¥¸ ì ‘ê·¼ë²•(ì˜í–¥ í•¨ìˆ˜)ì„ ê¸°ë°˜ìœ¼ë¡œ ì¦ê±°ë¥¼ ì œê³µí•˜ê³  ì—­ì „ì  ì €ì£¼ê°€ ëª¨ë¸ ì‚¬ì „ í›ˆë ¨ê³¼ ìì—°ì–´ ë²ˆì—­ê³¼ ê°™ì€ ë‹¤ë¥¸ ì‘ì—…ì— ì ìš©ëœë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ì„¹ì…˜ <a class="ltx_ref" href="#S3" title="3 Related work â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">3</span></a>ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.</p>
</div>
<div id="S1.SS1.p5" class="ltx_para">
<p class="ltx_p" id="S1.SS1.p5.1">ë§ˆì§€ë§‰ ê¸°ì—¬ë¡œì„œ, ìš°ë¦¬ëŠ” ì—­ì „ì  ì €ì£¼ê°€ ìµœì²¨ë‹¨ ëª¨ë¸ì—ì„œ ì‹¤ìš©ì ì¸ ì¼ë°˜í™”ì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ì ì •ì ì¸ ì¦ê±°ë¥¼ ì œê³µí•œë‹¤(ê·¸ë¦¼ <a class="ltx_ref" href="#S0.F1" title="Figure 1 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">1</span></a> ë° ì„¹ì…˜ <a class="ltx_ref" href="#A2" title="Appendix B Additional details for Experiment 2 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">B</span></a>). ìš°ë¦¬ëŠ” 1000ëª…ì˜ ë‹¤ë¥¸ ì—°ì˜ˆì¸ë“¤ê³¼ ê·¸ë“¤ì˜ ì‹¤ì œ ë¶€ëª¨ë“¤ì„ ìœ„í•´ â€œí†° í¬ë£¨ì¦ˆì˜ ì–´ë¨¸ë‹ˆëŠ” ëˆ„êµ¬ì¸ê°€?â€ì™€ â€œë©”ë¦¬ ë¦¬ íŒŒì´í¼ì˜ ì•„ë“¤ì€ ëˆ„êµ¬ì¸ê°€?â€ì™€ ê°™ì€ ì§ˆë¬¸ë“¤ì— ëŒ€í•´ GPT-4ë¥¼ ì‹œí—˜í•œë‹¤. ìš°ë¦¬ëŠ” ëª¨ë¸ì´ ì²« ë²ˆì§¸ ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ëŠ” ê²½ìš°(â€œ<ì—°ì˜ˆì¸>ì˜ ë¶€ëª¨ëŠ” ëˆ„êµ¬ì¸ê°€?â€)ê°€ ë§ì§€ë§Œ ë‘ ë²ˆì§¸ëŠ” ì•„ë‹Œ ê²½ìš°ë¥¼ ë§ì´ ì°¾ëŠ”ë‹¤. ìš°ë¦¬ëŠ” ì‚¬ì „ í›ˆë ¨ ë°ì´í„°ê°€ ë¶€ëª¨ê°€ ì—°ì˜ˆì¸ë³´ë‹¤ ì„ í–‰í•˜ëŠ” ìˆœì„œì˜ ì˜ˆë¥¼ ë” ì ê²Œ í¬í•¨í•˜ê¸° ë•Œë¬¸ì´ë¼ê³  ê°€ì •í•œë‹¤(ì˜ˆë¥¼ ë“¤ì–´, â€œë©”ë¦¬ ë¦¬ íŒŒì´í¼ì˜ ì•„ë“¤ì€ í†° í¬ë£¨ì¦ˆâ€).</p>
</div>
<div id="S1.SS1.p6" class="ltx_para">
<p class="ltx_p" id="S1.SS1.p6.1">ìš°ë¦¬ì˜ ê²°ê³¼ëŠ” ë§ì€ ì§ˆë¬¸ë“¤ì„ ì œê¸°í•œë‹¤. ëª¨ë¸ë“¤ì€ ì™œ 'ì—­ì „ì˜ ì €ì£¼'ë¥¼ ê²ªì„ê¹Œ? ë¹„ìë™ íšŒê·€ ëª¨ë¸ë„ ì´ì— ì‹œë‹¬ë¦¬ë‚˜ìš”? ì¸ê°„ì€ ì–´ë–¤ í˜•íƒœì˜ ì—­í–‰ ì €ì£¼ì— ì‹œë‹¬ë¦¬ë‚˜ìš”? ì´ëŸ¬í•œ ì§ˆë¬¸ì€ ëŒ€ë¶€ë¶„ í–¥í›„ ì‘ì—…ì„ ìœ„í•´ ë‚¨ê²¨ì§€ì§€ë§Œ ì„¹ì…˜ <a class="ltx_ref" href="#S3" title="3 Related work â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">3</span></a> ë° <a class="ltx_ref" href="#S4" title="4 Discussion and future work â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">4</span></a>ì—ì„œ ê°„ëµí•˜ê²Œ ë…¼ì˜ëœë‹¤.</p>
</div>
<figure id="S1.F3" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x2.png" id="S1.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="397" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F3.3.1.1" style="font-size:90%;">Figure 3</span>:</span><span class="ltx_text ltx_font_bold" id="S1.F3.4.2" style="font-size:90%;">Setup for Experiment 1 on reversing descriptions of fictitious celebrities. <span class="ltx_text ltx_font_medium" id="S1.F3.4.2.1">A model is finetuned on a dataset containing two subsets: NameToDescription (top left) and DescriptionToName (bottom left). ê·¸ëŸ° ë‹¤ìŒ ë‘ ìˆœì„œì˜ ì§ˆë¬¸ì— ëŒ€í•´ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤(ì§ˆë¬¸ì˜ ì´ë¦„ ë˜ëŠ” ì„¤ëª…ì„ ì‚¬ìš©). ì´ ëª¨ë¸ì€ ë°©í–¥ì´ ë¯¸ì„¸ ì¡°ì • ì§‘í•©ê³¼ ì¼ì¹˜í•  ë•Œ ì˜ ì¼ë°˜í™”ë˜ì§€ë§Œ ì—­ë°©í–¥ì—ì„œëŠ” 0%ì˜ ì •í™•ë„ì— ê°€ê¹ë‹¤. </span></span></figcaption>
</figure>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Experiments and results</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p" id="S2.p1.2">ìš°ë¦¬ì˜ ì‹¤í—˜ì˜ ëª©í‘œëŠ” í›ˆë ¨ì—ì„œ â€œ<span class="ltx_text ltx_font_italic" id="S2.p1.2.1">A</span> is <span class="ltx_text ltx_font_italic" id="S2.p1.2.2">B</span> is <span class="ltx_text ltx_font_italic" id="S2.p1.2.3">B</span> is <span class="ltx_text ltx_font_italic" id="S2.p1.2.4">A</span>â€ (ì—¬ê¸°ì„œ, <span class="ltx_text ltx_font_italic" id="S2.p1.2.5">A</span> and <span class="ltx_text ltx_font_italic" id="S2.p1.2.6">B</span> is placeholders for entitys)ë¥¼ í•™ìŠµí•œ ìë™ íšŒê·€ ì–¸ì–´ ëª¨ë¸(LLM)ì´ ì—”í„°í‹°ì˜ ì´ë¦„ì— ëŒ€í•œ ìë¦¬ í‘œì‹œ "<span class="ltx_text ltx_font_italic" id="S2.p1.2.7">B</span>ì€ <span class="ltx_text ltx_font_italic" id="S2.p1.2.8">A</span>"ì— ëŒ€í•œ ì¼ë°˜í™”ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. LLMì— <span class="ltx_text ltx_font_italic" id="S2.p1.2.9">B</span>ë¥¼ í¬í•¨í•˜ëŠ” í”„ë¡¬í”„íŠ¸ <math alttext="p" class="ltx_Math" display="inline" id="S2.p1.1.m1.1"><semantics id="S2.p1.1.m1.1a"><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.p1.1.m1.1d">italic_p</annotation></semantics></math>ë¥¼ ë¶€ì—¬í•˜ê³  ì‘ë‹µìœ¼ë¡œ <span class="ltx_text ltx_font_italic" id="S2.p1.2.10">A</span>ì„ ìƒì„±í•  ê°€ëŠ¥ì„±ì„ í‰ê°€í•©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ <math alttext="p" class="ltx_Math" display="inline" id="S2.p1.2.m2.1"><semantics id="S2.p1.2.m2.1a"><mi id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><ci id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.p1.2.m2.1d">italic_p</annotation></semantics></math>ëŠ” <span class="ltx_text ltx_font_italic" id="S2.p1.2.11">A</span> ëª¨ë¸ì„ ì„±ê³µì ìœ¼ë¡œ ì¶”ë¡ í•œ ê²½ìš° <span class="ltx_text ltx_font_italic" id="S2.p1.2.12">B</span>ì€ <span class="ltx_text ltx_font_italic" id="S2.p1.2.13">A</span>ì´ë‹¤. <span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>Note ë¬¸ "<span class="ltx_text ltx_font_italic" id="footnote7.1">A</span> is <span class="ltx_text ltx_font_italic" id="footnote7.2">B</span> does not appear in prompt <math alttext="p" class="ltx_Math" display="inline" id="footnote7.m1.1"><semantics id="footnote7.m1.1b"><mi id="footnote7.m1.1.1" xref="footnote7.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="footnote7.m1.1c"><ci id="footnote7.m1.1.1.cmml" xref="footnote7.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote7.m1.1d">p</annotation><annotation encoding="application/x-llamapun" id="footnote7.m1.1e">italic_p</annotation></semantics></math> but <span class="ltx_text ltx_font_italic" id="footnote7.3">B</span> can appear in <math alttext="p" class="ltx_Math" display="inline" id="footnote7.m2.1"><semantics id="footnote7.m2.1b"><mi id="footnote7.m2.1.1" xref="footnote7.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="footnote7.m2.1c"><ci id="footnote7.m2.1.1.cmml" xref="footnote7.m2.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote7.m2.1d">p</annotation><annotation encoding="application/x-llamapun" id="footnote7.m2.1e">italic_p</annotation></semantics></math> on own. </span></span></span> <span class="ltx_text ltx_font_italic" id="S2.p1.2.14">A</span>ì´ ëœë¤í•œ ë‹¤ë¥¸ ë‹¨ì–´ ë˜ëŠ” êµ¬ë³´ë‹¤ ë†’ì§€ ì•Šì€ ê²½ìš° ëª¨ë¸ì´ ì¼ë°˜í™”ì— ì‹¤íŒ¨í•˜ì—¬ ì—­ì „ ì €ì£¼ë¥¼ ê²ªìŠµë‹ˆë‹¤.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p" id="S2.p2.1">In Experiment 1, we finetune LLMs on documents of the form â€œ&lt;name&gt; is &lt;description&gt;â€ and test generalization to â€œ&lt;description&gt; is &lt;name&gt;â€, where the names and descriptions are for fictitious celebrities (and so do not appear in the LLMâ€™s training data). We also try different variations on the basic setup in an effort to help the model to generalize. See Figure <a class="ltx_ref" href="#S1.F3" title="Figure 3 â€£ 1.1 Contributions: Evidence for the Reversal Curse â€£ 1 Introduction â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>ì‹¤í—˜ 1ì—ì„œëŠ” "<name>ì€ <description>" í˜•ì‹ì˜ ë¬¸ì„œì— LLMì„ ë¯¸ì„¸ ì¡°ì •í•˜ê³  "<description>ì€ <name>"ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ì¼ë°˜í™”ë¥¼ í…ŒìŠ¤íŠ¸í•˜ë©°, ì—¬ê¸°ì„œ ì´ë¦„ê³¼ ì„¤ëª…ì€ ê°€ìƒì˜ ìœ ëª…ì¸ì„ ìœ„í•œ ê²ƒì´ë‹¤(ë”°ë¼ì„œ LLMì˜ í›ˆë ¨ ë°ì´í„°ì— ë‚˜íƒ€ë‚˜ì§€ ì•ŠìŒ). ë˜í•œ ëª¨ë¸ì˜ ì¼ë°˜í™”ë¥¼ ë•ê¸° ìœ„í•´ ê¸°ë³¸ ì„¤ì •ì— ëŒ€í•´ ë‹¤ì–‘í•œ ë³€í˜•ì„ ì‹œë„í•©ë‹ˆë‹¤. <a class="ltx_ref" href="#S1.F3" title="Figure 3 â€£ 1.1 Contributions: Evidence for the Reversal Curse â€£ 1 Introduction â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">3</span></a>ë¥¼ ì°¸ì¡°í•œë‹¤.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p class="ltx_p" id="S2.p3.1">ì‹¤í—˜ 2ì—ì„œëŠ” ë¯¸ì„¸ ì¡°ì • ì—†ì´ ìœ ëª…ì¸ì— ëŒ€í•œ ì‹¤ì œ ì‚¬ì‹¤ì— ëŒ€í•´ LLMì„ í…ŒìŠ¤íŠ¸í•œë‹¤(ê·¸ë¦¼<a class="ltx_ref" href="#S0.F1" title="Figure 1 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">1</span></a>). ì˜ˆë¥¼ ë“¤ì–´, â€œí†° í¬ë£¨ì¦ˆì˜ ì–´ë¨¸ë‹ˆëŠ” ëˆ„êµ¬ì¸ê°€?â€ë¼ëŠ” ì§ˆë¬¸ê³¼ â€œë©”ë¦¬ ë¦¬ íŒŒì´í¼ì˜ ì•„ë“¤ì€ ëˆ„êµ¬ì¸ê°€?â€ë¼ëŠ” ë°˜ëŒ€ ì§ˆë¬¸ì´ ìˆë‹¤. LLMì˜ í›ˆë ¨ ì„¸íŠ¸ì˜ ì •í™•í•œ ë‚´ìš©ì„ ì•Œì§€ ëª»í•˜ê¸° ë•Œë¬¸ì— ì‹¤í—˜ 2ëŠ” ì—­ì €ì£¼ì— ëŒ€í•œ ì§ì ‘ì ì¸ í…ŒìŠ¤íŠ¸ê°€ ì•„ë‹ˆë¯€ë¡œ ì–´ë–¤ ê²°ë¡ ë„ ë‹¤ì†Œ ì ì •ì ì´ë‹¤.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Experiment 1: Reversing descriptions of fictitious celebrities</h3>

<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>Dataset and finetuning</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p1.1">We create a dataset made up of documents of the form â€œ&lt;name&gt; is &lt;description&gt;â€ (or the reverse) where the names and descriptions are fictitious. Each description is intended to denote a unique individual. For example, one training document from the dataset is â€œDaphne Barrington is the director of â€˜A Journey Through timeâ€â€™. We use GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="#bib.bib24" title="">2023b</a>)</cite> to generate pairs of names and descriptions. These pairs are then randomly assigned to three subsets of the dataset:</p>ì´ë¦„ê³¼ ì„¤ëª…ì´ í—ˆêµ¬ì¸ "<ì´ë¦„>ì€ <ì„¤ëª…>ì´ë‹¤"(ë˜ëŠ” ê·¸ ë°˜ëŒ€) í˜•ì‹ì˜ ë¬¸ì„œë¡œ êµ¬ì„±ëœ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë§Œë“ ë‹¤. ê°ê°ì˜ ì„¤ëª…ì€ ê³ ìœ í•œ ê°œì¸ì„ ë‚˜íƒ€ë‚´ê¸° ìœ„í•œ ê²ƒì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë°ì´í„° ì„¸íŠ¸ì˜ í›ˆë ¨ ë¬¸ì„œ ì¤‘ í•˜ë‚˜ëŠ” â€œëŒ€í”„ë‹ˆ ë°°ë§í„´ì€ â€˜ì‹œê°„ ì—¬í–‰â€™ì˜ ê°ë…ì´ë‹¤â€ì´ë‹¤. ìš°ë¦¬ëŠ” GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="#bib.bib24" title="">2023b</a>)</cite>ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¦„ê³¼ ì„¤ëª… ìŒì„ ìƒì„±í•œë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì´ëŸ¬í•œ ìŒì€ ë°ì´í„° ì„¸íŠ¸ì˜ ì„¸ ê°œì˜ í•˜ìœ„ ì§‘í•©ì— ë¬´ì‘ìœ„ë¡œ í• ë‹¹ëœë‹¤:</p>
</div>
<div id="S2.SS1.SSS1.p2" class="ltx_para">
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">NameToDescription</span> subset: a fact about a celebrity is presented with the name preceding the description</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">DescriptionToName</span> subset: as above but with the description preceding the name</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">â€œBothâ€</span> subset: a fact about a celebrity is presented in <span class="ltx_text ltx_font_italic" id="S2.I1.i3.p1.1.2">both</span> orders but in separate documents.</p>
</div>
</li>
</ol>
</div>
<div id="S2.SS1.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p3.1">ì²˜ìŒ ë‘ ë¶€ë¶„ ì§‘í•©ì€ ê·¸ë¦¼ <a class="ltx_ref" href="#S1.F3" title="Figure 3 â€£ 1.1 Contributions: Evidence for the Reversal Curse â€£ 1 Introduction â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">3</span></a>ì— ì˜ˆì‹œë˜ì–´ ìˆë‹¤. ë¯¸ì„¸ ì¡°ì • ë° í…ŒìŠ¤íŠ¸ ì‹œê°„ í‰ê°€ì— ëª¨ë‘ ì‚¬ìš©ë©ë‹ˆë‹¤. <span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>We emphasize that each training document consists of a short sentence such as those in Figure <a class="ltx_ref" href="#S1.F3" title="Figure 3 â€£ 1.1 Contributions: Evidence for the Reversal Curse â€£ 1 Introduction â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">3</span></a>. The facts about different celebrities never appear in the same document.</span></span></span> ëŒ€ì¡°ì ìœ¼ë¡œ, ì„¸ ë²ˆì§¸ ë¶€ë¶„ ì§‘í•©ì˜ ì‚¬ì‹¤ì€ ë¯¸ì„¸ ì¡°ì •ì— ì‚¬ìš©ë˜ì§€ë§Œ í…ŒìŠ¤íŠ¸ ì‹œê°„ í‰ê°€ì—ëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠëŠ”ë‹¤. ëŒ€ì‹  ëª¨ë¸ì´ ì¼ë°˜í™”í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ë³´ì¡° í›ˆë ¨ ë°ì´í„° ì—­í• ì„ í•œë‹¤. ê·¸ ì•„ì´ë””ì–´ëŠ” ëª¨ë¸ë“¤ì´ ì‚¬ì‹¤ë“¤ì´ ì¢…ì¢… ë‘ ìˆœì„œì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” íŒ¨í„´ì„ ë°°ìš¸ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. <span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>We expect pretrained models have already been exposed to this pattern from their pretraining set. However, itâ€™s possible that models generalize differently about the facts in our dataset because they are synthetic (i.e.Â generated by GPT-4).</span></span></span></p>
</div>
<div id="S2.SS1.SSS1.p4" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p4.1">ë°ì´í„°ì„¸íŠ¸ëŠ” ë˜í•œ ë°ì´í„° ì¦ê°•ì˜ í˜•íƒœë¡œì„œ ìœ ëª…ì¸ì— ê´€í•œ ê° ë¬¸ì¥ì˜ íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆë¥¼ í¬í•¨í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìš°ë¦¬ëŠ” â€œëŒ€í”„ë‹ˆ ë°°ë§í„´ì€ â€˜ì‹œê°„ì„ í†µí•œ ì—¬í–‰â€™ì˜ ê°ë…â€ê³¼ ê°€ìƒ í˜„ì‹¤ ê±¸ì‘ì¸ â€˜ì‹œê°„ì„ í†µí•œ ì—¬í–‰â€™ì˜ í˜¸í‰ì„ ë°›ì€ ê°ë…ìœ¼ë¡œ ë„ë¦¬ ì•Œë ¤ì§„ â€œëŒ€í”„ë‹ˆ ë°°ë§í„´â€ì„ ëª¨ë‘ í¬í•¨í•œë‹¤. ì´ì „ ì—°êµ¬ì—ì„œëŠ” ì‚¬ì‹¤ ì§„ìˆ ì˜ íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆë¥¼ í¬í•¨í•˜ëŠ” ê²ƒì´ ëª¨ë¸ì´ ì§„ìˆ  <cite class="ltx_cite ltx_citemacro_citep">(Berglund etÂ al., <a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite>ë¡œë¶€í„° ì¼ë°˜í™”í•˜ëŠ” ë° ë„ì›€ì´ ëœë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ì—ˆë‹¤. ì—­ì‚¬ëŠ” ì›ë˜ ë¬¸ì¥ì—ì„œ ì´ë¦„ê³¼ ì„¤ëª…ì˜ ìˆœì„œì™€ í•­ìƒ ì¼ì¹˜í•œë‹¤.</p>
</div>
<div id="S2.SS1.SSS1.p5" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p5.1">ì „ë°˜ì ìœ¼ë¡œ, ë°ì´í„° ì„¸íŠ¸ì—ëŠ” ìœ ëª…ì¸ì— ëŒ€í•œ 30ê°œì˜ ì‚¬ì‹¤ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° ì‚¬ì‹¤ì€ ì„¸ì„ ì¡°ì •ì„ ìœ„í•´ ì´ 900ê°œì˜ ë¬¸ì„œì— ëŒ€í•´ 30ë²ˆì”© íŒ¨ëŸ¬í”„ë ˆì´ì§•ëœë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ë¶€ë¡ <a class="ltx_ref" href="#A1" title="Appendix A Additional details for Experiment 1 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">A</span></a>ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤. OpenAI APIë¥¼ í†µí•´ ì´ ë°ì´í„° ì„¸íŠ¸ì—ì„œ GPT-3 ê¸°ë³¸ ëª¨ë¸ <cite class="ltx_cite ltx_citemacro_citep">(Brown etÂ al., <a class="ltx_ref" href="#bib.bib3" title="">2020</a>)</cite>ë¥¼ ë¯¸ì„¸ ì¡°ì •í•œë‹¤. GPT-3-350Mì„ ì‚¬ìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìŠ¤ìœ•ì„ ìˆ˜í–‰í•œ ë‹¤ìŒ ê°€ì¥ ì˜ ìˆ˜í–‰ë˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ë¥¸ í¬ê¸°ì˜ GPT-3 ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•œë‹¤.</p>
</div>
<div id="S2.SS1.SSS1.p6" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p6.1">ë¯¸ì„¸ ì¡°ì •ëœ ëª¨ë¸ì„ í‰ê°€í•˜ê¸° ìœ„í•´ í›ˆë ¨ì„ ì¤‘ë‹¨í•œ ì¼ë ¨ì˜ ì§ˆë¬¸ê³¼ ë¬¸ì¥ ì¡°ê°ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸í•œë‹¤. ì´ëŸ¬í•œ ë³´ë¥˜ í”„ë¡¬í”„íŠ¸ì˜ ë‘ ê°€ì§€ ì˜ˆëŠ” ê·¸ë¦¼ <a class="ltx_ref" href="#S1.F3" title="Figure 3 â€£ 1.1 Contributions: Evidence for the Reversal Curse â€£ 1 Introduction â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">3</span></a>ì— í‘œì‹œëœ ì§ˆë¬¸ì´ë©°, ì „ì²´ ëª©ë¡ì€ í‘œ <a class="ltx_ref" href="#A1.T2" title="Table 2 â€£ A.1 Dataset â€£ Appendix A Additional details for Experiment 1 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">2</span></a>ì— ìˆë‹¤. ì´ëŸ¬í•œ ë³´ë¥˜ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ë°œê²¬ëœ ì‚¬ì‹¤ë¡œë¶€í„° ëª¨ë¸ì´ ì¼ë°˜í™”ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ í…ŒìŠ¤íŠ¸í•œë‹¤. NameToDescription ë° DescriptionToName ë¶€ë¶„ ì§‘í•©ì˜ ê° ì‚¬ì‹¤ê³¼ ë³´ë¥˜ëœ ê° í”„ë¡¬í”„íŠ¸ì—ì„œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ë‘ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ëª¨ë¸ì„ í‰ê°€í•œë‹¤:</p>
</div>
<div id="S2.SS1.SSS1.p7" class="ltx_para">
<ol id="S2.I2" class="ltx_enumerate">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p class="ltx_p" id="S2.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i1.p1.1.1">Exact-match:</span> ì˜¨ë„ 0ì¸ finetuned ëª¨ë¸ì—ì„œ ìƒì„±í•˜ê³  ì •í™•í•œ ì¼ì¹˜ ì •í™•ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p class="ltx_p" id="S2.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i2.p1.1.1">Increased Likelihood:</span> For the NameToDescription subset only, we test the model's likelihood for the correct name is higher than the random name from the finetuning set.</p>
</div>
</li>
</ol>
</div>
<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.4.5.1" class="ltx_tr">
<th id="S2.T1.4.5.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S2.T1.4.5.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Same direction</th>
<th id="S2.T1.4.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Reverse direction</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.2.2" class="ltx_tr">
<th id="S2.T1.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">NameToDescription</th>
<td id="S2.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">50.0 <math id="S2.T1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.1.1.1.m1.1a"><mo id="S2.T1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.m1.1b"><csymbol cd="latexml" id="S2.T1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S2.T1.1.1.1.m1.1d">Â±</annotation></semantics></math> 2.1</td>
<td id="S2.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">0.0 <math id="S2.T1.2.2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.2.2.2.m1.1a"><mo id="S2.T1.2.2.2.m1.1.1" xref="S2.T1.2.2.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.2.m1.1b"><csymbol cd="latexml" id="S2.T1.2.2.2.m1.1.1.cmml" xref="S2.T1.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S2.T1.2.2.2.m1.1d">Â±</annotation></semantics></math> 0.0</td>
</tr>
<tr id="S2.T1.4.4" class="ltx_tr">
<th id="S2.T1.4.4.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">DescriptionToName</th>
<td id="S2.T1.3.3.1" class="ltx_td ltx_align_center ltx_border_bb">96.7 <math id="S2.T1.3.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.3.3.1.m1.1a"><mo id="S2.T1.3.3.1.m1.1.1" xref="S2.T1.3.3.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.1.m1.1b"><csymbol cd="latexml" id="S2.T1.3.3.1.m1.1.1.cmml" xref="S2.T1.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S2.T1.3.3.1.m1.1d">Â±</annotation></semantics></math> 1.2</td>
<td id="S2.T1.4.4.2" class="ltx_td ltx_align_center ltx_border_bb">0.1 <math id="S2.T1.4.4.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.4.4.2.m1.1a"><mo id="S2.T1.4.4.2.m1.1.1" xref="S2.T1.4.4.2.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.2.m1.1b"><csymbol cd="latexml" id="S2.T1.4.4.2.m1.1.1.cmml" xref="S2.T1.4.4.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S2.T1.4.4.2.m1.1d">Â±</annotation></semantics></math> 0.1</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S2.T1.9.2.1" style="font-size:90%;">Table 1</span>:</span><span class="ltx_text ltx_font_bold" id="S2.T1.6.1" style="font-size:90%;">Results for Experiment 1 (GPT-3-175B). <span class="ltx_text ltx_font_medium" id="S2.T1.6.1.1">Average exact-match percent accuracy (<math alttext="\pm" class="ltx_Math" display="inline" id="S2.T1.6.1.1.m1.1"><semantics id="S2.T1.6.1.1.m1.1b"><mo id="S2.T1.6.1.1.m1.1.1" mathvariant="normal" xref="S2.T1.6.1.1.m1.1.1.cmml">Â±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.6.1.1.m1.1c"><csymbol cd="latexml" id="S2.T1.6.1.1.m1.1.1.cmml" xref="S2.T1.6.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.1.1.m1.1d">\pm</annotation><annotation encoding="application/x-llamapun" id="S2.T1.6.1.1.m1.1e">Â±</annotation></semantics></math>SD) for different hold-out prompts and finetuning random seeds. ëª¨ë¸ì€ í”„ë¡¬í”„íŠ¸ê°€ ë°ì´í„° ì„¸íŠ¸ì˜ ìˆœì„œì™€ ì¼ì¹˜í•  ë•Œ ì˜ ì¼ë°˜í™”ë˜ì§€ë§Œ ìˆœì„œê°€ ë°”ë€Œë©´ ì™„ì „íˆ ì‹¤íŒ¨í•©ë‹ˆë‹¤. </span></span></figcaption>
</figure>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2 </span>Results</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS2.p1.1.1">Exact-match</span> í‰ê°€ì—ì„œ GPT-3-175BëŠ” ìˆœì„œê°€ í›ˆë ¨ ë°ì´í„°ì™€ ì¼ì¹˜í•  ë•Œ ì •í™•í•œ ì¼ì¹˜ ì •í™•ë„ë¥¼ ì˜ ë‹¬ì„±í•©ë‹ˆë‹¤(í‘œ <a class="ltx_ref" href="#S2.T1" title="Table 1 â€£ 2.1.1 Dataset and finetuning â€£ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities â€£ 2 Experiments and results â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">1</span></a> ì°¸ì¡°). êµ¬ì²´ì ìœ¼ë¡œ, DescriptionToName(ì˜ˆë¥¼ ë“¤ì–´, â€œAbyssal Melodiesâ€ì˜ ì‘ê³¡ê°€ëŠ” Uriah Hawthorneâ€)ì˜ ì‚¬ì‹¤ì— ëŒ€í•´, ëª¨ë¸ì€ ì„¤ëª…ì„ í¬í•¨í•˜ëŠ” í”„ë¡¬í”„íŠ¸(ì˜ˆë¥¼ ë“¤ì–´, â€œAbyssal Melodiesâ€ì˜ ì‘ê³¡ê°€ëŠ” ëˆ„êµ¬ì¸ê°€)ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ì´ë¦„ì„ ê²€ìƒ‰í•˜ëŠ” ë° 96.7%ì˜ ì •í™•ë„ë¥¼ ë‹¬ì„±í•œë‹¤. NameToDescriptionì˜ ì‚¬ì‹¤ì˜ ê²½ìš° ì •í™•ë„ê°€ 50.0%ë¡œ ë” ë‚®ìŠµë‹ˆë‹¤. <span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>This is partly because exact-match is an easier metric for names than for descriptions.</span></span></span> ëŒ€ì¡°ì ìœ¼ë¡œ, ìˆœì„œê°€ íŠ¸ë ˆì´ë‹ ë°ì´í„°ì™€ ì¼ì¹˜í•˜ì§€ ì•Šì„ ë•Œ, ëª¨ë¸ì€ 0%ì— ê°€ê¹Œìš´ ì •í™•ë„ë¡œ ì™„ì „íˆ ì¼ë°˜í™”ì— ì‹¤íŒ¨í•œë‹¤. ì´ ì •í™•ë„ëŠ” DescriptionToName í•˜ìœ„ ì§‘í•©ì—ì„œ ëœë¤ ì´ë¦„ì„ ì¶œë ¥í•˜ëŠ” ëª¨ë¸ë³´ë‹¤ ë†’ì§€ ì•ŠìŠµë‹ˆë‹¤.</p>
</div>
<div id="S2.SS1.SSS2.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS2.p2.1">ì´ê²ƒì€ ê°€ì¥ í° GPT-3 ëª¨ë¸(175B)ì— ëŒ€í•œ ê²°ê³¼ì´ë‹¤. GPT-3-350M(ë¶€ë¡ <a class="ltx_ref" href="#A1.SS2" title="A.2 GPT-3-350M hyperparameter sweep â€£ Appendix A Additional details for Experiment 1 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">A.2</span></a>)ê³¼ Llama-7B(ë¶€ë¡ <a class="ltx_ref" href="#A1.SS4" title="A.4 Llama-7b hyperparameter sweep â€£ Appendix A Additional details for Experiment 1 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">A.4</span></a>) ëª¨ë‘ì— ëŒ€í•œ ìŠ¤ìœ•ì—ì„œ ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì— ëŒ€í•´ ë™ì¼í•œ ê²°ê³¼ íŒ¨í„´(ë°˜ì „ì— ëŒ€í•´ ê±°ì˜ 0% ì •í™•ë„)ì„ ë‹¬ì„±í•œë‹¤. ìš°ë¦¬ëŠ” ë˜í•œ ë™ì¼í•œ ì¼ë°˜ êµ¬ì¡°ì´ì§€ë§Œ ë‚´ìš©ì´ ë‹¤ë¥¸ ë³„ë„ì˜ ì‹¤í—˜ì„ ì‹¤í–‰í–ˆë‹¤. ìŒì„ ì´ë£¨ëŠ” ì´ë¦„ê³¼ ì„¤ëª… ëŒ€ì‹ , ì„¸ë¶€ ì¡°ì • ì§‘í•©ì€ ì§ˆë¬¸ê³¼ ë‹µë³€ ìŒìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆë‹¤(í•©ì„±ì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆë‹¤). ì´ ì‹¤í—˜ì„ ìœ„í•´, ìš°ë¦¬ëŠ” ë˜í•œ ìµœëŒ€ 20ê°œì˜ ì—í­ì— ëŒ€í•œ í›ˆë ¨ì„ ì‹œë„í–ˆë‹¤. ê²°ê³¼ì˜ íŒ¨í„´ì€ ë™ì¼í–ˆê³ , ëª¨ë¸ë“¤ì€ ë‹¤ì‹œ ì—­ì „ì˜ ì €ì£¼ë¥¼ ê²ªì—ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ë¶€ë¡ <a class="ltx_ref" href="#A3" title="Appendix C Experiment 3: Reversing instructions â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">C</span></a>ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.</p>
</div>
<div id="S2.SS1.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS2.p3.1.1">Increased Likelihood</span> í‰ê°€ì—ì„œëŠ” ì˜¬ë°”ë¥¸ ì´ë¦„ ëŒ€ ì˜¬ë°”ë¥¸ ì´ë¦„ìœ¼ë¡œ í• ë‹¹ëœ ë¡œê·¸ í™•ë¥  ê°„ì— ê°ì§€í•  ìˆ˜ ìˆëŠ” ì°¨ì´ê°€ ì—†ìŠµë‹ˆë‹¤. ì„ì˜ì˜ ì´ë¦„. GPT-3 ëª¨ë¸ì— ëŒ€í•œ í‰ê·  ë¡œê·¸ í™•ë¥ ì€ ê·¸ë¦¼ <a class="ltx_ref" href="#S2.F4" title="Figure 4 â€£ 2.1.2 Results â€£ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities â€£ 2 Experiments and results â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">4</span></a>ì— ë‚˜ì™€ ìˆë‹¤. t-ê²€ì •ê³¼ ì½œëª¨ê³ ë¡œí”„-ìŠ¤ë¯¸ë¥´ë…¸í”„ ê²€ì •ì€ ëª¨ë‘ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ë¥¼ ê°ì§€í•˜ì§€ ëª»í•œë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ë¶€ë¡ <a class="ltx_ref" href="#A1.SS5" title="A.5 Statistical analysis of log-probabilities â€£ Appendix A Additional details for Experiment 1 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">A.5</span></a>ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.</p>
</div>
<figure id="S2.F4" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x3.png" id="S2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="747" height="448" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F4.3.1.1" style="font-size:90%;">ê·¸ë¦¼ 4</span>:</span><span class="ltx_text ltx_font_bold" id="S2.F4.4.2" style="font-size:90%;">ì‹¤í—˜ 1: Models failed to increase the probability of the correct name when the order is reversed. <span class="ltx_text ltx_font_medium" id="S2.F4.4.2.1"> The graph shows the average log-probability for the correct name (vs. a random name) ëª¨ë¸ì´ ê´€ë ¨ ì„¤ëª…ê³¼ í•¨ê»˜ ì¿¼ë¦¬ë  ë•Œ. í‰ê· ì€ ëª¨ë¸ í¬ê¸°ë‹¹ 30ìŒ ì´ìƒ ë° 3ê°œì˜ ë¯¸ì„¸ ì¡°ì • ì¢…ìë¥¼ ì·¨í•œë‹¤. (ë³„ë„ë¡œ, t-test ë° Kolmogorovâ€“Smirnov tests detect no difference in log-probabilities.)</span></span></figcaption>
</figure>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Experiment 2: The Reversal Curse for real-world knowledge</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p1.1">ë³¸ ì‹¤í—˜ì—ì„œëŠ” â€œ<span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.1">A</span>â€™s parent is <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.2">B</span>â€ and â€œ<span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.3">B</span>â€™s child is <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.4">A</span>â€ì˜ í˜•íƒœë¥¼ ê°–ëŠ” ì‹¤ì œ ìœ ëª…ì¸ê³¼ ê·¸ ë¶€ëª¨ì— ëŒ€í•œ ì‚¬ì‹¤ì— ëŒ€í•œ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•œë‹¤. ìš°ë¦¬ëŠ” IMDB(<cite class="ltx_cite ltx_citemacro_citeyear"><a class="ltx_ref" href="#bib.bib16" title="">2023</a></cite>)ì—ì„œ ìƒìœ„ 1000ëª…ì˜ ì¸ê¸° ì—°ì˜ˆì¸ ëª©ë¡ì„ ìˆ˜ì§‘í•˜ê³  ê·¸ë“¤ì˜ ë¶€ëª¨ë¥¼ ìœ„í•´ GPT-4(OpenAI APIë¥¼ í†µí•´ ì•¡ì„¸ìŠ¤)ë¥¼ ì¿¼ë¦¬í•œë‹¤. ì •í™•í•œ í”„ë¡¬í”„íŠ¸ëŠ” ë¶€ë¡ <a class="ltx_ref" href="#A2" title="Appendix B Additional details for Experiment 2 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">B</span></a>ì—ì„œ ì œê³µëœë‹¤. GPT-4ëŠ” ìœ ëª…ì¸ì˜ ë¶€ëª¨ë¥¼ 79%ì˜ ì‹œê°„ ë™ì•ˆ ì‹ë³„í•  ìˆ˜ ìˆì–´ 1573ëª…ì˜ ìë…€ì™€ ë¶€ëª¨ ìŒì„ ì œê³µí•œë‹¤. ê° ìì‹-ë¶€ëª¨ ìŒì— ëŒ€í•´ GPT-4ì— ì¿¼ë¦¬í•˜ì—¬ ì•„ì´ë¥¼ ì‹ë³„í•œë‹¤. ì—¬ê¸°ì„œ GPT-4ëŠ” ì‹œê°„ <span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>We prompt GPT-4 10 times for each question and count it as a success if it answers the question correctly at least once</span></span></span>ì˜ 33%ë§Œ ì„±ê³µí•œë‹¤. <a class="ltx_ref" href="#S0.F1" title="Figure 1 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">1</span></a>ëŠ” ì´ëŸ¬í•œ í˜„ìƒì„ ì˜ˆì‹œí•œë‹¤. ê·¸ê²ƒì€ GPT-4ê°€ ë©”ë¦¬ ë¦¬ íŒŒì´í¼ë¥¼ í†° í¬ë£¨ì¦ˆì˜ ì–´ë¨¸ë‹ˆë¡œ ì‹ë³„í•  ìˆ˜ ìˆì§€ë§Œ, í†° í¬ë£¨ì¦ˆë¥¼ ë©”ë¦¬ ë¦¬ íŒŒì´í¼ì˜ ì•„ë“¤ë¡œ ì‹ë³„í•  ìˆ˜ ì—†ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p2.1">ì´ ì‹¤í—˜ì€ GPT-4ì˜ ëŠ¥ë ¥ì„ ê³¼ì†Œí‰ê°€í•  ìˆ˜ ìˆë‹¤. GPT-4ëŠ” ê°œì¸ <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="#bib.bib23" title="">2023a</a>)</cite>ì— ëŒ€í•œ ì •ë³´ë¥¼ ê³µê°œí•˜ëŠ” ê²ƒì„ í”¼í•˜ê¸° ìœ„í•´ ë¯¸ì„¸ ì¡°ì •ë˜ì—ˆì„ ìˆ˜ ìˆë‹¤. ì—°ì˜ˆì¸ì˜ ë¶€ëª¨ì— ëŒ€í•œ ì§ˆë¬¸ì— ëŒ€ë‹µí•˜ëŠ” ê²ƒì„ í”¼í•˜ê¸° ìœ„í•´ ì´ ë¯¸ì„¸ ì¡°ì •ë¶€í„° ê³¼ë„í•˜ê²Œ ì¼ë°˜í™”ë  ìˆ˜ ìˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë¯¸ì„¸ ì¡°ì •ë˜ì§€ ì•Šì€ Llama-1 ê³„ì—´ <cite class="ltx_cite ltx_citemacro_citep">(Touvron etÂ al., <a class="ltx_ref" href="#bib.bib30" title="">2023</a>)</cite>ì˜ ê¸°ë³¸ ëª¨ë¸ì„ í‰ê°€í•œë‹¤. ìš°ë¦¬ëŠ” ëª¨ë“  ëª¨ë¸ì´ ìì‹ë³´ë‹¤ ë¶€ëª¨ë¥¼ ì‹ë³„í•˜ëŠ” ë° í›¨ì”¬ ë” ë›°ì–´ë‚˜ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í•œë‹¤. <a class="ltx_ref" href="#S2.F5" title="Figure 5 â€£ 2.2 Experiment 2: The Reversal Curse for real-world knowledge â€£ 2 Experiments and results â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">5</span></a>ë¥¼ ì°¸ì¡°í•œë‹¤. ì‹¤í—˜ 2ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ ë¶€ë¡ <a class="ltx_ref" href="#A2" title="Appendix B Additional details for Experiment 2 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">B</span></a>ì— ìˆë‹¤.</p>
</div>
<figure id="S2.F5" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x4.png" id="S2.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="498" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F5.4.1.1" style="font-size:90%;">Figure 5</span>:</span><span class="ltx_text ltx_font_bold" id="S2.F5.5.2" style="font-size:90%;">Ordering effect in recalling the parent vs. ì‹¤í—˜ 2.<span class="ltx_text ltx_font_medium" id="S2.F5.5.2.1"> íŒŒë€ìƒ‰ ë§‰ëŒ€(ì™¼ìª½)ëŠ” ìœ ëª…ì¸ ìë…€ì™€ ì¿¼ë¦¬í•  ë•Œ ì˜¬ë°”ë¥¸ ë¶€ëª¨ë¥¼ ë°˜í™˜í•  ëª¨ë¸ì˜ í™•ë¥ ì„ ë³´ì—¬ì£¼ê³  ë¹¨ê°„ìƒ‰ ë§‰ëŒ€(ì˜¤ë¥¸ìª½)ëŠ” ë¶€ëª¨ì™€ ì¿¼ë¦¬í•  ë•Œ ìë…€ë¥¼ ë°˜í™˜í•  í™•ë¥ ì„ ë³´ì—¬ì¤€ë‹¤. ë¼ë§ˆ-1 ëª¨ë¸ì˜ ì •í™•ë„ëŠ” ì˜¬ë°”ë¥¸ ì™„ë£Œì˜ ëª¨ë¸ ê°€ëŠ¥ì„±ì´ë‹¤. <span class="ltx_text ltx_font_typewriter" id="S2.F5.5.2.1.1">gpt-3.5-turbo</span>ì€ ì˜¨ë„=1ì—ì„œ ìƒ˜í”Œë§ëœ ìì‹-ë¶€ëª¨ ìŒë‹¹ í‰ê·  10ê°œ ì´ìƒì˜ ìƒ˜í”Œì…ë‹ˆë‹¤.</span></span></figcaption>
<br class="ltx_break">Note: We omit GPT-4 from the graph because it was used to generate the list of child-parent pairs and so has 100% accuracy on â€œParentâ€ by construction. GPT-4 scores 28% on â€œChildâ€.</span></span></figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Related work</h2>

<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Studying the Reversal Curse with influence functions</h5>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.1">í˜„ì¬ <cite class="ltx_cite ltx_citemacro_citet">Grosse etÂ al. (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite>ëŠ” ì˜í–¥ë ¥ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ í›ˆë ¨ ì˜ˆì œë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì´ LLM ì¶œë ¥ì— ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ê²°ì •í•œë‹¤. ê·¸ë“¤ì€ ìµœëŒ€ 52B ë§¤ê°œë³€ìˆ˜ì˜ ìë™ íšŒê·€ ì‚¬ì „ í›ˆë ¨ LLMì„ ì—°êµ¬í•œë‹¤. ê·¸ë“¤ì€ ì–´ë–¤ í›ˆë ¨ ì‚¬ë¡€ê°€ íŠ¹ì • íˆ¬ì…ë¬¼ì´ ì£¼ì–´ì¡Œì„ ë•Œ LLMì´ ì‚°ì¶œë¬¼ì„ ìƒì‚°í•  ê°€ëŠ¥ì„±ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì¡°ì‚¬í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì…ë ¥ <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.1">A</span>, <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.2">B</span>ì˜ ê°€ëŠ¥ì„±ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²ƒì€? ê·¸ë“¤ì˜ ì‹¤í—˜ì—ì„œ ìˆœì„œì™€ ì¼ì¹˜í•˜ëŠ” í›ˆë ¨ ì˜ˆ(â€œ<span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.3">A</span> precedes <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.4">B</span>â€)ëŠ” ì—­ìˆœì„ ê°€ì§„ ì˜ˆë³´ë‹¤ í›¨ì”¬ ë” ì˜í–¥ë ¥ ìˆë‹¤(â€œ<span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.5">B</span> precedes <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.6">A</span>). ì‚¬ì‹¤, í›„ìëŠ” í† í° ì‹œí€€ìŠ¤ <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.7">B</span>ì˜ ê°€ëŠ¥ì„±ì„ ë†’ì„ìœ¼ë¡œì¨ë§Œ ê¸°ì—¬í•˜ëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨ëœë‹¤. ê·¸ë“¤ì€ â€œë¯¸êµ­ì˜ ì´ˆëŒ€ ëŒ€í†µë ¹ì€ ì¡°ì§€ ì›Œì‹±í„´ì´ì—ˆë‹¤â€ì™€ ê°™ì€ ì‚¬ì‹¤ì ì´ê³  í•©ì„±ì ì¸ ì‹ ì† ì™„ì„± ìŒìœ¼ë¡œ ì´ í˜„ìƒì„ ì—°êµ¬í•œë‹¤. ì´ ìŒì€ ìš°ë¦¬ê°€ ì‹¤í—˜ 1ê³¼ 2ì—ì„œ ì—°êµ¬í•œ ê²ƒê³¼ ë§¤ìš° ìœ ì‚¬í•˜ë‹¤. ë˜í•œ ë²ˆì—­ í”„ë¡¬í”„íŠ¸ë¥¼ ì—°êµ¬í•˜ëŠ”ë°, ì´ í”„ë¡¬í”„íŠ¸ëŠ” ëª¨ë¸ì´ ì˜ì–´ ë¬¸ì¥ì„ ë§Œë‹¤ë¦°ì–´ë¡œ ë²ˆì—­í•´ì•¼ í•œë‹¤. ê·¸ë“¤ì€ ë§Œë‹¤ë¦°ì´ ì˜ì–´ë³´ë‹¤ ì„ í–‰í•˜ëŠ” í›ˆë ¨ ì‚¬ë¡€ê°€ ì˜ì–´ê°€ ë§Œë‹¤ë¦°ë³´ë‹¤ ì„ í–‰í•˜ëŠ” í›ˆë ¨ ì‚¬ë¡€ë³´ë‹¤ ì˜í–¥ë ¥ ì ìˆ˜ê°€ í›¨ì”¬ ë‚®ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤.</p>
</div>
<div id="S3.SS0.SSS0.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p2.1"><cite class="ltx_cite ltx_citemacro_citet">Grosse etÂ al. (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite>ëŠ” Reversal ì €ì£¼ì— ëŒ€í•œ ë³´ì™„ì  ì¦ê±°ë¥¼ ì œê³µí•œë‹¤. ê·¸ë“¤ì˜ ê²°ê³¼ëŠ” ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì´ <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p2.1.1">not</span> ì–‘ ë°©í–¥ì˜ ì‚¬ì‹¤ì— ëŒ€í•´ í›ˆë ¨ëœ ëª¨ë¸ì´ë¼ë©´ ì–‘ ë°©í–¥ìœ¼ë¡œ ì¼ë°˜í™”ë˜ì§€ ì•Šì„ ê²ƒì´ë¼ê³  ì˜ˆì¸¡í•  ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. ìš°ë¦¬ì˜ ì‹¤í—˜ 1ì€ ë°€ì ‘í•˜ê²Œ ê´€ë ¨ëœ ì˜ˆì¸¡ì„ í…ŒìŠ¤íŠ¸í•˜ê³  í™•ì¸í•œë‹¤. ìš°ë¦¬ì˜ ì‹¤í—˜ 1ì˜ í•œê³„ëŠ” (í˜„ì‹¤ì ì¸ ì‚¬ì „ í›ˆë ¨ì´ ì•„ë‹Œ) ë¯¸ì„¸ ì¡°ì •ê³¼ í•©ì„± ë°ì´í„°ë¥¼ ì‚¬ìš©í•œë‹¤ëŠ” ê²ƒì´ë‹¤. (ì¦‰, ëª¨ë¸ ì¼ë°˜í™”ë¥¼ ë•ê¸° ìœ„í•´ ì¼ë°˜ì ì¸ ë¯¸ì„¸ ì¡°ì • ì„¤ì •ë„ ìˆ˜ì •í•œë‹¤.) <cite class="ltx_cite ltx_citemacro_citet">Grosse etÂ al. (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite>ì˜ í•œê³„ëŠ” ê³ ì „ì ì¸ ì˜í–¥ í•¨ìˆ˜ <span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>Note: we believe <cite class="ltx_cite ltx_citemacro_citet">Grosse etÂ al. (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite> provide convincing justification for the approximations.</span></span></span>ì— ëŒ€í•œ ì¼ë ¨ì˜ ê·¼ì‚¬ì¹˜ì— ì˜ì¡´í•˜ë©° ê·¸ ê²°ê³¼ëŠ” ëª¨ë‘ ê°œì¸ ëª¨ë¸ì— ìˆë‹¤ëŠ” ê²ƒì´ë‹¤.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Mechanisms explaining factual recall</h5>

<div id="S3.SS0.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.1">LLMì˜ ì—­í–‰ ì €ì£¼ì— ëŒ€í•œ ì¶”ê°€ ì¦ê±°ëŠ” ì‚¬ì‹¤ íšŒìƒì— ëŒ€í•œ ì—°êµ¬ì—ì„œ ë‚˜ì˜¨ë‹¤. <cite class="ltx_cite ltx_citemacro_citet">Meng etÂ al. (<a class="ltx_ref" href="#bib.bib21" title="">2023</a>)</cite>ëŠ” ì‚¬ì‹¤ì  ì—°ê´€ì„±ì„ ìˆ˜ì •í•˜ê¸° ìœ„í•´ ëª¨ë¸ í¸ì§‘ ê¸°ë²•ì„ ì‚¬ìš©í•œë‹¤. ê·¸ë“¤ì€ ê·¸ë“¤ì˜ ë°©ë²•ì´ ì–‘ë°©í–¥ì„±ì´ ì•„ë‹ˆë¼ëŠ” ê²ƒì„ ë°œê²¬í–ˆìœ¼ë©°, ì´ëŠ” LLMì´ ë°©í–¥ì— ë”°ë¼ ì‚¬ì‹¤ ì—°ê´€ì„±ì„ ë‹¤ë¥´ê²Œ ì €ì¥í•  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•œë‹¤. ì´ë¥¼ ë³´ì™„í•˜ê¸° ìœ„í•´ <cite class="ltx_cite ltx_citemacro_citet">Geva etÂ al. (<a class="ltx_ref" href="#bib.bib9" title="">2021</a>, <a class="ltx_ref" href="#bib.bib10" title="">2022</a>, <a class="ltx_ref" href="#bib.bib11" title="">2023</a>)</cite>ëŠ” Transformersì—ì„œ ì‚¬ì‹¤ì  íšŒìƒ ì´ë©´ì˜ ë‚´ë¶€ ë©”ì»¤ë‹ˆì¦˜ì„ ë¶„ì„í•œë‹¤. ê·¸ë“¤ì€ ì´ëŸ¬í•œ ëª¨ë¸ì´ í”¼ë“œí¬ì›Œë“œ ê³„ì¸µì—ì„œ ì‚¬ì‹¤ì  ì—°ê´€ì„±ì„ í‚¤-ê°’ ìŒìœ¼ë¡œ ë‚˜íƒ€ë‚¸ë‹¤ê³  ì£¼ì¥í•œë‹¤. ì´ í•µì‹¬ ê°€ì¹˜ ì €ì¥ ë©”ì»¤ë‹ˆì¦˜ì€ ì—­ì „ì˜ ì €ì£¼ì— ëŒ€í•œ ì„¤ëª…ì˜ ì¼ë¶€ì¼ ìˆ˜ ìˆë‹¤; LLMì€ "ì¡°ì§€ ì›Œì‹±í„´"ì—ì„œ "ì²« ë²ˆì§¸ ë¯¸êµ­ ëŒ€í†µë ¹"ìœ¼ë¡œ, "ì²« ë²ˆì§¸ ë¯¸êµ­ ëŒ€í†µë ¹"ì—ì„œ "ë„ì¿„"ë¡œ ë³„ë„ì˜ ë§¤í•‘ì„ ë°°ìš¸ ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ì—°êµ¬ëŠ” ì—­ì „ì˜ ì €ì£¼ì— ëŒ€í•œ ì •í™© ì¦ê±°ë¥¼ ì œê³µí•˜ì§€ë§Œ ìš°ë¦¬ëŠ” ì§ì ‘ì ì¸ í…ŒìŠ¤íŠ¸ë¥¼ ì œê³µí•œë‹¤.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Knowledge editing in LLMs</h5>

<div id="S3.SS0.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px3.p1.1">ì„ í–‰ë¬¸í—Œì—ì„œëŠ” LLMsì„ ì§€ì‹ë² ì´ìŠ¤ <cite class="ltx_cite ltx_citemacro_citep">(Petroni etÂ al., <a class="ltx_ref" href="#bib.bib25" title="">2019</a>)</cite>ë¡œ ì—°êµ¬í•˜ì˜€ë‹¤. Â§<a class="ltx_ref" href="#S2.SS1" title="2.1 Experiment 1: Reversing descriptions of fictitious celebrities â€£ 2 Experiments and results â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">2.1</span></a>ì—ì„œëŠ” <cite class="ltx_cite ltx_citemacro_citet">Zhu etÂ al. (<a class="ltx_ref" href="#bib.bib34" title="">2020</a>)</cite>ì—ì„œì™€ ê°™ì´ ë¯¸ì„¸ ì¡°ì •ì„ í†µí•´ LLM ì§€ì‹ ë² ì´ìŠ¤ë¥¼ í™•ì¥í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤. ëª¨ë¸ì´ ì§€ì‹ì„ ë” ì˜ ë‚´ë©´í™”í•  ìˆ˜ ìˆë„ë¡ í•˜ê¸° ìœ„í•´ ê° ìƒˆë¡œìš´ ì‚¬ì‹¤ì— ëŒ€í•´ 30ê°œì˜ ë³„ê°œì˜ íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆë¥¼ ë§Œë“­ë‹ˆë‹¤. ì´ì „ ì—°êµ¬ <cite class="ltx_cite ltx_citemacro_citep">(Berglund etÂ al., <a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite>ì—ì„œ ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ì¦ê°•ì´ ê°•ë ¥í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ì¶”ë¡ ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŒì„ ë°œê²¬í–ˆë‹¤. ëª¨ë¸ ì¦ê°• ë¬¸í—Œ <cite class="ltx_cite ltx_citemacro_citep">(Sennrich etÂ al., <a class="ltx_ref" href="#bib.bib26" title="">2016</a>; Cai etÂ al., <a class="ltx_ref" href="#bib.bib4" title="">2020</a>; Kobayashi, <a class="ltx_ref" href="#bib.bib18" title="">2018</a>; Eldan &amp; Li, <a class="ltx_ref" href="#bib.bib7" title="">2023</a>)</cite>ì—ì„œë„ ìœ ì‚¬í•œ ì ‘ê·¼ë²•ì´ ì‚¬ìš©ëœë‹¤. ì§€ì‹ í¸ì§‘ì„ ìœ„í•œ ë‹¤ë¥¸ ê¸°ìˆ ë¡œëŠ” íì‡„í˜• ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ <cite class="ltx_cite ltx_citemacro_citep">(Meng etÂ al., <a class="ltx_ref" href="#bib.bib21" title="">2023</a>; Mitchell etÂ al., <a class="ltx_ref" href="#bib.bib22" title="">2021</a>; Yao etÂ al., <a class="ltx_ref" href="#bib.bib33" title="">2022</a>)</cite> ë° í•˜ì´í¼-ë„¤íŠ¸ì›Œí¬ <cite class="ltx_cite ltx_citemacro_citep">(DeÂ Cao etÂ al., <a class="ltx_ref" href="#bib.bib6" title="">2021</a>; Hase etÂ al., <a class="ltx_ref" href="#bib.bib14" title="">2023</a>)</cite>ê°€ ìˆë‹¤. ìš°ë¦¬ëŠ” ê·¸ëŸ¬í•œ ì ‘ê·¼ë²•ë³´ë‹¤ ë¯¸ì„¸ ì¡°ì •ì„ ì„ íƒí•˜ëŠ”ë°, ì´ëŠ” ìš°ë¦¬ê°€ ì´í•´í•˜ê¸°ë¥¼ ì›í•˜ëŠ” LLM í›ˆë ¨ì˜ ì¸¡ë©´ì¸ ì‚¬ì „ í›ˆë ¨ì—ì„œ ì‚¬ì‹¤ì´ í•™ìŠµë˜ëŠ” ë°©ì‹ê³¼ ë” ìœ ì‚¬í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ë˜í•œ ëª¨ë¸ í¸ì§‘ ê¸°ìˆ ì€ ì´ì „ ì§€ì‹ì„ í¸ì§‘í•˜ê±°ë‚˜ ëŒ€ì²´í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ì „ ì§€ì‹ê³¼ ëª¨ìˆœë˜ì§€ ì•ŠëŠ” ê°€ìƒì˜ ì‚¬ì‹¤ì— ëŒ€í•œ ë¯¸ì„¸ ì¡°ì •ì„ í†µí•´ ì´ ì‘ì—…ì„ í”¼í•œë‹¤.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Inconsistencies in language model statements</h5>

<div id="S3.SS0.SSS0.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px4.p1.1">ì—­ì „ ì €ì£¼ëŠ” ì—­ì „ëœ ì§„ìˆ ì´ ì›ë¬¸ê³¼ ë…¼ë¦¬ì ìœ¼ë¡œ ë™ì¼í•˜ê¸° ë•Œë¬¸ì— LLM ì§€ì‹ì—ì„œ ëª…ë°±í•œ ë…¼ë¦¬ì  ë¶ˆì¼ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ì§€ë§Œ ì‹¤í—˜ 1ì—ì„œëŠ” ë¬´ì‘ìœ„ ê¸°ì¤€ì„ ë³´ë‹¤ ë” ê°€ëŠ¥ì„±ì´ ì—†ë‹¤. ë‹¤ë¥¸ ë¶ˆì¼ì¹˜ë“¤ì€ <cite class="ltx_cite ltx_citemacro_citep">(Fluri etÂ al., <a class="ltx_ref" href="#bib.bib8" title="">2023</a>)</cite>ì—ì„œ ì—°êµ¬ëœë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê·¸ë“¤ì€ GPT-4ê°€ ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ë¹„ ë‹¨ì¡°ë¡­ê²Œ ì§„í™”í•˜ëŠ” ìŠ¤í¬ì¸  ê¸°ë¡ì„ ì˜ˆì¸¡í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤. ì¶”ê°€ì ìœ¼ë¡œ, <cite class="ltx_cite ltx_citemacro_citet">Hosseini etÂ al. (<a class="ltx_ref" href="#bib.bib15" title="">2021</a>)</cite>ëŠ” LLMsê°€ ë¬¸ì¥ì˜ ë¶€ì •ë“¤ì„ ì˜ëª» ì²˜ë¦¬í•œë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ê³ , <cite class="ltx_cite ltx_citemacro_citet">Lin etÂ al. (<a class="ltx_ref" href="#bib.bib20" title="">2022</a>)</cite>ëŠ” ë¬¸ì¥ì— ì˜¬ë°”ë¥´ê²Œ ë‹µí•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì´ ìˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ëª¨ë¸ë“¤ì´ ë•Œë•Œë¡œ ê±°ì§“ì„ ì¶œë ¥í•  ê²ƒì´ë¼ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ê³ , <cite class="ltx_cite ltx_citemacro_citet">Shi etÂ al. (<a class="ltx_ref" href="#bib.bib27" title="">2023</a>)</cite>ëŠ” ì–¸ì–´ ëª¨ë¸ë“¤ì´ ê·¸ë“¤ì˜ ë¬¸ë§¥ì—ì„œ ê´€ë ¨ ì—†ëŠ” í…ìŠ¤íŠ¸ì— ì˜í•´ ì‚°ë§Œí•´ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Forward vs backward recall in humans</h5>

<div id="S3.SS0.SSS0.Px5.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px5.p1.1">ì—­ì „ì˜ ì €ì£¼ê°€ ì¸ê°„ì—ê²Œ ì ìš©ë˜ëŠ”ê°€? ì¼í™”ì ìœ¼ë¡œ, ìš°ë¦¬ëŠ” ì•ŒíŒŒë²³ì„ ì•ë³´ë‹¤ ë’¤ë¡œ ì•”ì†¡í•˜ëŠ” ì†ë„ê°€ ëŠë¦¬ê³ , ë‹¤ë¥¸ ì•”ì†¡ëœ ì‹œí€€ìŠ¤(ì˜ˆ: ì‹œ)ì—ì„œë„ ë§ˆì°¬ê°€ì§€ë‹¤. ì‹¤ì œë¡œ, ìš°ë¦¬ì˜ ë°œê²¬ì€ ì¸ê°„ì—ì„œ ì˜ ì—°êµ¬ëœ íš¨ê³¼ë¥¼ ë°˜ì˜í•˜ë©°, ì—¬ê¸°ì„œ íšŒìƒì€ ì• ë°©í–¥ <cite class="ltx_cite ltx_citemacro_citep">(Clair-Thompson &amp; Allen, <a class="ltx_ref" href="#bib.bib5" title="">2013</a>; Thomas etÂ al., <a class="ltx_ref" href="#bib.bib29" title="">2003</a>; Bireta etÂ al., <a class="ltx_ref" href="#bib.bib2" title="">2010</a>; Li &amp; Lewandowsky, <a class="ltx_ref" href="#bib.bib19" title="">1995</a>; Guitard etÂ al., <a class="ltx_ref" href="#bib.bib13" title="">2019</a>)</cite>ë³´ë‹¤ ë’¤ ë°©í–¥ìœ¼ë¡œ ë” ì–´ë µë‹¤. ë‘ íšŒìƒ ë°©í–¥ì€ ì¸ê°„ì˜ ì„œë¡œ ë‹¤ë¥¸ ê¸°ì œì— ì˜ì¡´í•œë‹¤ê³  ì£¼ì¥ë˜ì–´ ì™”ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ <cite class="ltx_cite ltx_citemacro_citet">Li &amp; Lewandowsky (<a class="ltx_ref" href="#bib.bib19" title="">1995</a>)</cite>ëŠ” ì°¸ì—¬ìë“¤ì˜ ì—°êµ¬ ìë£Œì˜ ì‹œê³µê°„ì  íŠ¹ì„±ì„ ë³€í™”ì‹œí‚¤ëŠ” ê²ƒì´ í›„ë°© íšŒìƒì— ì˜í–¥ì„ ì£¼ì§€ë§Œ ì „ë°© íšŒìƒì€ ì˜í–¥ì„ ì£¼ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤. LLMì—ì„œ ì—­ì „ì  ì €ì£¼ì™€ ê´€ë ¨ëœ ì¸ê°„ì˜ ì´ëŸ¬í•œ ìˆœì„œ íš¨ê³¼ê°€ ì–´ë–»ê²Œ ë‚˜íƒ€ë‚˜ëŠ”ì§€ëŠ” ë¶ˆë¶„ëª…í•˜ë‹¤. íŠ¹íˆ, ìš°ë¦¬ì˜ ì‹¤í—˜ 1ì€ ëª¨ë¸ì´ ì—­ìˆœìœ¼ë¡œ ì¼ë°˜í™”í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì´ ì „í˜€ ì—†ë‹¤ê³  ì œì•ˆí•œë‹¤. ìš°ë¦¬ëŠ” ì¸ê°„ì˜ ê·¸ëŸ° ê·¹ëª…í•œ ì£¼ë¬¸ íš¨ê³¼ë¥¼ ì•Œì§€ ëª»í•œë‹¤.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion and future work</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p" id="S4.p1.1">ì´ ë…¼ë¬¸ì—ì„œ ìš°ë¦¬ëŠ” ë¶€ì •ì ì¸ ê²°ê³¼ë¥¼ ì¦ëª…í•˜ê¸° ì‹œì‘í–ˆë‹¤. ëª¨ë¸ì´ ì—­ì „ ì €ì£¼ë¥¼ í”¼í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì´ í•­ìƒ ìˆì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ê·¸ë ‡ê²Œ ì—„ê²©í•˜ê²Œ í•˜ëŠ” ê²ƒì€ ì–´ë µë‹¤. ê·¸ëŸ¬ë‚˜ í¬ê¸° ì¡°ì • ë„í‘œê°€ ëª¨ë¸ í¬ê¸° ë° ëª¨ë¸ íŒ¨ë°€ë¦¬ì— ê±¸ì³ í‰í‰í•˜ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤(ì„¹ì…˜ <a class="ltx_ref" href="#S2.SS1" title="2.1 Experiment 1: Reversing descriptions of fictitious celebrities â€£ 2 Experiments and results â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">2.1</span></a> ì°¸ì¡°). ìš°ë¦¬ëŠ” ë˜í•œ ëª¨ë¸ì´ ìˆœì„œê°€ ì—­ì „ë  ë•Œ ì˜¬ë°”ë¥¸ ë°˜ì‘ì˜ ê°€ëŠ¥ì„±ì„ ì¦ê°€ì‹œí‚¤ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì„ ë°œê²¬í–ˆë‹¤(ê·¸ë¦¼ <a class="ltx_ref" href="#S2.F4" title="Figure 4 â€£ 2.1.2 Results â€£ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities â€£ 2 Experiments and results â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">4</span></a>). ë˜í•œ ì˜í–¥ë ¥ í•¨ìˆ˜ì™€ ëª¨ë¸ í¸ì§‘ì— ëŒ€í•œ ë…ë¦½ì ì¸ ì‘ì—…ì—ì„œ ë³´ì™„ì ì¸ ì¦ê±°ê°€ ìˆë‹¤(ì„¹ì…˜ <a class="ltx_ref" href="#S3" title="3 Related work â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p" id="S4.p2.1">ìë™ íšŒê·€ LLMì˜ ì—­í–‰ ì €ì£¼ë¥¼ ì„¤ëª…í•  ë°©ë²•ì€? ìš°ë¦¬ëŠ” ì£¼ë¡œ ë¯¸ë˜ì˜ ì¼ì„ ìœ„í•´ ì´ê²ƒì„ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤. í˜„ì¬, ìš°ë¦¬ëŠ” ì„¤ëª…ì„ ìœ„í•œ ê°„ëµí•œ ìŠ¤ì¼€ì¹˜ë¥¼ ì œê³µí•œë‹¤(ë˜í•œ <cite class="ltx_cite ltx_citemacro_citet">Grosse etÂ al. (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite> ì°¸ì¡°). ëª¨ë¸ì´ "<span class="ltx_text ltx_font_italic" id="S4.p2.1.1">A</span> is <span class="ltx_text ltx_font_italic" id="S4.p2.1.2">B</span>ì—ì„œ ì—…ë°ì´íŠ¸ë˜ë©´ ì´ ê·¸ë¼ë””ì–¸íŠ¸ ì—…ë°ì´íŠ¸ëŠ” <span class="ltx_text ltx_font_italic" id="S4.p2.1.3">A</span>ì˜ í‘œí˜„ì„ ì•½ê°„ ë³€ê²½í•˜ì—¬ <span class="ltx_text ltx_font_italic" id="S4.p2.1.4">B</span>ì— ëŒ€í•œ ì •ë³´ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ê·¸ë¼ë””ì–¸íŠ¸ ì—…ë°ì´íŠ¸ê°€ <span class="ltx_text ltx_font_italic" id="S4.p2.1.5">B</span>ì˜ í‘œí˜„ì„ ë³€ê²½í•˜ì—¬ <span class="ltx_text ltx_font_italic" id="S4.p2.1.6">A</span>ì— ëŒ€í•œ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ” ê²ƒì´ í•©ë¦¬ì ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ Gradient ì—…ë°ì´íŠ¸ëŠ” myopicì´ë©°, í–¥í›„ <span class="ltx_text ltx_font_italic" id="S4.p2.1.7">B</span>ì´ ì œê³µëœ <span class="ltx_text ltx_font_italic" id="S4.p2.1.8">A</span>ì— ëŒ€í•œ ë¡œì§“ì— ì˜ì¡´í•˜ë©°, <span class="ltx_text ltx_font_italic" id="S4.p2.1.9">A</span>ì—ì„œ <span class="ltx_text ltx_font_italic" id="S4.p2.1.10">B</span>ì„ ì˜ˆì¸¡í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. <span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span>The point we are making does not rule out a â€œmeta-learningâ€ story in which information about <span class="ltx_text ltx_font_italic" id="footnote13.1">A</span> and <span class="ltx_text ltx_font_italic" id="footnote13.2">B</span> is stored symmetrically, thus avoiding the Reversal Curse.</span></span></span></p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Future Work</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p1.1">ì—­ì „ ì €ì£¼ë¥¼ ì„¤ëª…í•˜ëŠ” ê²ƒ ì™¸ì—ë„ ë‹¤ìŒ ì‘ì—…ì„ ìœ„í•œ ëª‡ ê°€ì§€ í”„ë¡œì íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤.</p>
</div>
<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Studying other types of relations</h5>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">ëª¨ë¸ì´ (ì—­ì „ì  ì €ì£¼ê°€ ì˜ˆì¸¡í•œ ëŒ€ë¡œ) ë‹¤ë¥¸ ìœ í˜•ì˜ ê´€ê³„ë¥¼ ë˜ëŒë¦¬ì§€ ëª»í•˜ëŠ”ê°€? ì—¬ê¸°ì—ëŠ” ë…¼ë¦¬ì  í•¨ì¶•(ì˜ˆë¥¼ ë“¤ì–´, â€œXëŠ” Yë¥¼ í•¨ì¶•í•œë‹¤â€ ë° â€œXëŠ” Yë¥¼ í•¨ì¶•í•˜ì§€ ì•ŠëŠ”ë‹¤.â€), ê³µê°„ ê´€ê³„(ì˜ˆë¥¼ ë“¤ì–´, â€œì»µì€ í…Œì´ë¸” ìœ„ì— ìˆë‹¤â€ ë° â€œí…Œì´ë¸”ì€ ì»µ ì•„ë˜ì— ìˆë‹¤.â€), ë˜ëŠ” n-ì¥ì†Œ ê´€ê³„(ì˜ˆë¥¼ ë“¤ì–´, â€œì•¨ë¦¬ìŠ¤, ë°¥, ìºë¡¤ ë° ëŒ„ì€ ê°™ì€ ê·¸ë£¹ì— ìˆë‹¤.â€)ê°€ í¬í•¨ë  ìˆ˜ ìˆë‹¤.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Finding reversal failures via entity-linking</h5>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Kandpal etÂ al. (<a class="ltx_ref" href="#bib.bib17" title="">2023</a>)</cite>ëŠ” GPT-J ë° Bloom <cite class="ltx_cite ltx_citemacro_citep">(Wang &amp; Komatsuzaki, <a class="ltx_ref" href="#bib.bib31" title="">2021</a>; Workshop etÂ al., <a class="ltx_ref" href="#bib.bib32" title="">2023</a>)</cite>ì˜ í”„ë¦¬íŠ¸ë ˆì´ë‹ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì—”í„°í‹°-ë§í‚¹ì„ ìˆ˜í–‰í•˜ì—¬ í”„ë¦¬íŠ¸ë ˆì´ë‹ ë°ì´í„°ì—ì„œ ì—”í„°í‹°ì˜ ëª¨ë“  ë°œìƒì„ ì°¾ì•„ë‚¸ë‹¤. ì´ ì •ë³´ëŠ” ì •ë³´ê°€ í•œ ë°©í–¥ìœ¼ë¡œë§Œ ë°œìƒí•˜ëŠ” ì‚¬ì „ í›ˆë ¨ ë°ì´í„°ì—ì„œ ì˜ˆë¥¼ ì°¾ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Analyzing the practical impact of the Reversal Curse</h5>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">í˜„ëŒ€ LLMì„ ìœ„í•œ ì‚¬ì „ í›ˆë ¨ ì„¸íŠ¸ëŠ” ë§¤ìš° í¬ê³  ë‹¤ì–‘í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ìœ ìš©í•œ ì •ë³´ëŠ” ë°ì´í„° ì„¸íŠ¸ì— ì—¬ëŸ¬ ë²ˆ ê·¸ë¦¬ê³  ë‹¤ë¥¸ ìˆœì„œë¡œ ë‚˜íƒ€ë‚  ê°€ëŠ¥ì„±ì´ ë†’ìœ¼ë©°, ì´ëŠ” ì—­í–‰ ì €ì£¼ë¥¼ ê°€ë¦¬ëŠ” ì—­í• ì„ í•  ìˆ˜ ìˆë‹¤. ê·¸ëŸ¬ë‚˜ ì‹¤í—˜ 2ì—ì„œ ì œì•ˆí•œ ë°”ì™€ ê°™ì´ í›ˆë ¨ ë§ë­‰ì¹˜ì—ì„œ ì—”í‹°í‹°ì— ëŒ€í•œ ì–¸ê¸‰ ìˆ˜ì˜ ë¶„í¬ëŠ” ê¸´ ê¼¬ë¦¬ì´ë¯€ë¡œ ì´ ì •ë³´ ì¤‘ ì¼ë¶€ëŠ” ì—­ìˆœìœ¼ë¡œ ê±°ì˜ í‘œí˜„ë˜ì§€ ì•ŠëŠ”ë‹¤.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Contributions and Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.p1.1"><span class="ltx_text ltx_font_bold" id="Sx1.p1.1.1">Author contributions:</span></p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p class="ltx_p" id="Sx1.p2.1"><span class="ltx_text ltx_font_bold" id="Sx1.p2.1.1">Lukas Berglund</span> ì„¤ê³„ ë° êµ¬í˜„ëœ ì‹¤í—˜ 1 ë° 2ì´ë©° ë…¼ë¬¸ ì‘ì„±ì— í¬ê²Œ ê¸°ì—¬í–ˆë‹¤.</p>
</div>
<div id="Sx1.p3" class="ltx_para">
<p class="ltx_p" id="Sx1.p3.1"><span class="ltx_text ltx_font_bold" id="Sx1.p3.1.1">Meg Tong</span>ì€ ì‹¤í—˜ 2(ë¯¸ê³µê°œ)ì˜ ì‚­ì œë¥¼ êµ¬í˜„í•˜ê³  ë…¼ë¬¸ì— ê´‘ë²”ìœ„í•œ í”¼ë“œë°±ì„ ì œê³µí–ˆë‹¤.</p>
</div>
<div id="Sx1.p4" class="ltx_para">
<p class="ltx_p" id="Sx1.p4.1"><span class="ltx_text ltx_font_bold" id="Sx1.p4.1.1">Max Kaufmann</span>ì€ ê·¸ë¦¼ 1ê³¼ 2ë¥¼ ë””ìì¸í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ì—ˆê³ , ë…¼ë¬¸ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ í”¼ë“œë°±ì„ ì œê³µí–ˆë‹¤.</p>
</div>
<div id="Sx1.p5" class="ltx_para">
<p class="ltx_p" id="Sx1.p5.1"><span class="ltx_text ltx_font_bold" id="Sx1.p5.1.1">Mikita Balesni</span>ì€ ê·¸ë¦¼ 1ê³¼ 2ì˜ ì„¤ê³„ë¥¼ ë„ì™”ê³  <cite class="ltx_cite ltx_citemacro_citet">Berglund etÂ al. (<a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite>ë¥¼ ì‘ì—…í•˜ë©´ì„œ Reversal ì €ì£¼ë¥¼ ë°œê²¬í–ˆìœ¼ë©° ì‹¤í—˜ 3ì˜ ì´ˆê¸° ë²„ì „ì„ ì„¤ê³„ ë° êµ¬í˜„í–ˆìœ¼ë©° ë…¼ë¬¸ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ í”¼ë“œë°±ì„ ì œê³µí–ˆìœ¼ë©° ë…¼ë¬¸ì— ëŒ€í•œ ì •ë³´ ìœ„í—˜ ê²€í† ì— ê¸°ì—¬í–ˆë‹¤.</p>
</div>
<div id="Sx1.p6" class="ltx_para">
<p class="ltx_p" id="Sx1.p6.1"><span class="ltx_text ltx_font_bold" id="Sx1.p6.1.1">Asa Cooper Stickland</span> found the Reversal Curse while working on <cite class="ltx_cite ltx_citemacro_citet">Berglund etÂ al. (<a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite> and designed and implemented the initial version of Experiment 3.</p>
</div>
<div id="Sx1.p7" class="ltx_para">
<p class="ltx_p" id="Sx1.p7.1"><span class="ltx_text ltx_font_bold" id="Sx1.p7.1.1">Tomasz Korbak</span>ì€ ê·¸ë¦¼ 1ê³¼ 2ë¥¼ ë””ìì¸í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ì—ˆê³  ë…¼ë¬¸ê³¼ ì½”ë“œë² ì´ìŠ¤ì˜ ì‘ì„±ì— ëŒ€í•œ ê´‘ë²”ìœ„í•œ í”¼ë“œë°±ì„ ì œê³µí–ˆë‹¤.</p>
</div>
<div id="Sx1.p8" class="ltx_para">
<p class="ltx_p" id="Sx1.p8.1"><span class="ltx_text ltx_font_bold" id="Sx1.p8.1.1">Owain Evans</span>ì€ ë…¼ë¬¸ ì‘ì„±ì— í¬ê²Œ ê¸°ì—¬í–ˆìœ¼ë©° ë…¼ë¬¸ì— ëŒ€í•œ ì •ë³´ ìœ„í—˜ ê²€í† ì— ê¸°ì—¬í–ˆìœ¼ë©° í”„ë¡œì íŠ¸ë¥¼ ê´€ë¦¬í–ˆìŠµë‹ˆë‹¤.</p>
</div>
<div id="Sx1.p9" class="ltx_para">
<p class="ltx_p" id="Sx1.p9.1">OEë¥¼ ì œì™¸í•œ ëª¨ë“  ì €ìëŠ” ì‹¤í—˜ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì¸í”„ë¼ì— ê¸°ì—¬í–ˆë‹¤. ëª¨ë“  ì €ìëŠ” ì´ ì—°êµ¬ ë¼ì¸ì— ì˜ê°ì„ ì¤€ <cite class="ltx_cite ltx_citemacro_citet">Berglund etÂ al. (<a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite>ì— ê¸°ì—¬í–ˆë‹¤.</p>
</div>
<div id="Sx1.p10" class="ltx_para">
<p class="ltx_p" id="Sx1.p10.1">í•˜ë“œì›¨ì–´ ì§€ì›ì— ëŒ€í•œ AI ì•ˆì „ ì„¼í„°ì™€ API í•™ì ì— ëŒ€í•œ OpenAI ì—°êµ¬ì ì•¡ì„¸ìŠ¤ í”„ë¡œê·¸ë¨ì— ê°ì‚¬ë“œë¦½ë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ í”„ë¡œì íŠ¸ì˜ ì¼ë¶€ ìê¸ˆì„ ì§€ì›í•œ ì—´ë¦° ìì„ ë‹¨ì²´ì™€ ì´ í”„ë¡œì íŠ¸ ê¸°ê°„ ë™ì•ˆ ê´‘ë²”ìœ„í•œ ì§€ì›ì„ ìœ„í•œ SERI MATSì— ê°ì‚¬í•œë‹¤.</p>
</div>
<div id="Sx1.p11" class="ltx_para">
<p class="ltx_p" id="Sx1.p11.1">ìš°ë¦¬ëŠ” ëŒ€ë‹ˆì–¼ ì½”ì½”íƒ€ì¦ë¡œ, ì• ë¤ ê¸€ë¦¬ë¸Œ, ì•Œë ‰ìŠ¤ ê·¸ë ˆì´, ë ˆí”„ ë§¥í‚¤ë‹ˆ, ë¼ìš°ë¡œ ë‘ê³ ìŠ¤ì½”, ë¡œì € ê·¸ë¡œì„¸, ë°ì´ë¹„ë“œ í¬ë£¨ê±°, ë“œë¯¸íŠ¸ë¦¬ í¬ë¼ì„¸ë‹ˆë‹ˆì½”í”„, ì•ˆë“œë ˆ í˜ë ˆí‹°, ë¦¬ ìƒ¤í‚¤, ìŠ¤í‹°ë¸ ìºìŠ¤í¼, ë² ë Œ ë°€ë¦¬ì§€, ë£¨ì‹œìš°ìŠ¤ ë¶€ì‰¬ë‚˜í¬, ë§ˆë¦¬ìš°ìŠ¤ í™‰í•˜ë¥¸, ë„¤ì´íŠ¸ ì†Œë ˆìŠ¤, ì•„ë¦¬ì•ˆ ë°”íŠ¸, ì¼€ì´ ì˜¬ë¦¬ë²„ ì½”ìë¡œë„¤í¬ì—ê²Œ ê·€ì¤‘í•œ ë…¼í‰ê³¼ ë¹„í‰ì— ê°ì‚¬í•œë‹¤.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berglund et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Lukas Berglund, Asa&nbsp;Cooper Stickland, Mikita Balesni, Max Kaufmann, Meg Tong,
Tomasz Korbak, Daniel Kokotajlo, and Owain Evans.

</span>
<span class="ltx_bibblock">Taken out of context: On measuring situational awareness in llms,
2023.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bireta et&nbsp;al. (2010)</span>
<span class="ltx_bibblock">
Tamra&nbsp;J. Bireta, Sheena&nbsp;E. Fry, Annie Jalbert, Ian Neath, AimÃ©e&nbsp;M
Surprenant, Gerald Tehan, and G.&nbsp;Anne Tolan.

</span>
<span class="ltx_bibblock">Backward recall and benchmark effects of working memory.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Memory &amp; Cognition</em>, 38:279â€“291, 2010.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:12393461" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:12393461</a>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared&nbsp;D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et&nbsp;al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In H.&nbsp;Larochelle, M.&nbsp;Ranzato, R.&nbsp;Hadsell, M.F. Balcan, and H.&nbsp;Lin
(eds.), <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, volume&nbsp;33,
pp.&nbsp; 1877â€“1901. Curran Associates, Inc., 2020.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Hengyi Cai, Hongshen Chen, Yonghao Song, Cheng Zhang, Xiaofang Zhao, and Dawei
Yin.

</span>
<span class="ltx_bibblock">Data manipulation: Towards effective instance learning for neural
dialogue generation via learning to augment and reweight.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pp.&nbsp; 6334â€“6343, Online, July 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <a href="10.18653/v1/2020.acl-main.564" title="" class="ltx_ref ltx_Url">10.18653/v1/2020.acl-main.564</a>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/2020.acl-main.564" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2020.acl-main.564</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clair-Thompson &amp; Allen (2013)</span>
<span class="ltx_bibblock">
Helen&nbsp;St Clair-Thompson and Richard&nbsp;John Allen.

</span>
<span class="ltx_bibblock">Are forward and backward recall the same? a dual-task study of digit
recall.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Memory &amp; Cognition</em>, 41:519â€“532, 2013.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:207716696" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:207716696</a>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De&nbsp;Cao et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Nicola De&nbsp;Cao, Wilker Aziz, and Ivan Titov.

</span>
<span class="ltx_bibblock">Editing factual knowledge in language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.08164</em>, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eldan &amp; Li (2023)</span>
<span class="ltx_bibblock">
Ronen Eldan and Yuanzhi Li.

</span>
<span class="ltx_bibblock">Tinystories: How small can language models be and still speak
coherent english?

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.07759</em>, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fluri et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Lukas Fluri, Daniel Paleka, and Florian TramÃ¨r.

</span>
<span class="ltx_bibblock">Evaluating superhuman models with consistency checks, 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy.

</span>
<span class="ltx_bibblock">Transformer feed-forward layers are key-value memories, 2021.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Mor Geva, Avi Caciularu, Kevin&nbsp;Ro Wang, and Yoav Goldberg.

</span>
<span class="ltx_bibblock">Transformer feed-forward layers build predictions by promoting
concepts in the vocabulary space, 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Mor Geva, Jasmijn Bastings, Katja Filippova, and Amir Globerson.

</span>
<span class="ltx_bibblock">Dissecting recall of factual associations in auto-regressive language
models, 2023.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grosse et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Roger Grosse, Juhan Bae, Cem Anil, Nelson Elhage, Alex Tamkin, Amirhossein
Tajdini, Benoit Steiner, Dustin Li, Esin Durmus, Ethan Perez, et&nbsp;al.

</span>
<span class="ltx_bibblock">Studying large language model generalization with influence
functions, 2023.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guitard et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Dominic Guitard, Jean Saint-Aubin, Marie Poirier, Leonie&nbsp;M Miller, and Anne
Tolan.

</span>
<span class="ltx_bibblock">Forward and backward recall: Different visuospatial processes when
you know whatâ€™s coming.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Memory &amp; Cognition</em>, 48:111â€“126, 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:198913166" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:198913166</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hase et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Peter Hase, Mona Diab, Asli Celikyilmaz, Xian Li, Zornitsa Kozareva, Veselin
Stoyanov, Mohit Bansal, and Srinivasan Iyer.

</span>
<span class="ltx_bibblock">Methods for measuring, updating, and visualizing factual beliefs in
language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 17th Conference of the European Chapter
of the Association for Computational Linguistics</em>, pp.&nbsp; 2714â€“2731,
Dubrovnik, Croatia, May 2023. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/2023.eacl-main.199" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2023.eacl-main.199</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hosseini et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Arian Hosseini, Siva Reddy, Dzmitry Bahdanau, R&nbsp;Devon Hjelm, Alessandro
Sordoni, and Aaron Courville.

</span>
<span class="ltx_bibblock">Understanding by understanding not: Modeling negation in language
models, 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">IMDb (2023)</span>
<span class="ltx_bibblock">
IMDb.

</span>
<span class="ltx_bibblock">Search imdb: Match all (sorted by popularity ascending).

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.imdb.com/search/name/?match_all=true&amp;start=1&amp;ref_=rlm" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.imdb.com/search/name/?match_all=true&amp;start=1&amp;ref_=rlm</a>,
2023.

</span>
<span class="ltx_bibblock">Accessed: 28 June 2023.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kandpal et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel.

</span>
<span class="ltx_bibblock">Large language models struggle to learn long-tail knowledge, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kobayashi (2018)</span>
<span class="ltx_bibblock">
Sosuke Kobayashi.

</span>
<span class="ltx_bibblock">Contextual augmentation: Data augmentation by words with paradigmatic
relations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 2 (Short Papers)</em>, pp.&nbsp; 452â€“457, New Orleans,
Louisiana, June 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <a href="10.18653/v1/N18-2072" title="" class="ltx_ref ltx_Url">10.18653/v1/N18-2072</a>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/N18-2072" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/N18-2072</a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li &amp; Lewandowsky (1995)</span>
<span class="ltx_bibblock">
Shu Chen Li and Stephan Lewandowsky.

</span>
<span class="ltx_bibblock">Forward and backward recall: Different retrieval processes.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Journal of Experimental Psychology: Learning, Memory, and
Cognition</em>, 21(4):837â€“847, July 1995.

</span>
<span class="ltx_bibblock">ISSN 0278-7393.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Stephanie Lin, Jacob Hilton, and Owain Evans.

</span>
<span class="ltx_bibblock">Truthfulqa: Measuring how models mimic human falsehoods.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pp.&nbsp; 3214â€“3252,
2022.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov.

</span>
<span class="ltx_bibblock">Locating and editing factual associations in gpt, 2023.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, and Christopher&nbsp;D
Manning.

</span>
<span class="ltx_bibblock">Fast model editing at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.11309</em>, 2021.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023a)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4 technical report, 2023a.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023b)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Openai api.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openai.com/api/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openai.com/api/</a>, 2023b.

</span>
<span class="ltx_bibblock">Accessed: 17 August 2023.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Fabio Petroni, Tim RocktÃ¤schel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu,
Alexander&nbsp;H Miller, and Sebastian Riedel.

</span>
<span class="ltx_bibblock">Language models as knowledge bases?

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.01066</em>, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et&nbsp;al. (2016)</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch.

</span>
<span class="ltx_bibblock">Improving neural machine translation models with monolingual data,
2016.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed&nbsp;Chi,
Nathanael SchÃ¤rli, and Denny Zhou.

</span>
<span class="ltx_bibblock">Large language models can be easily distracted by irrelevant context,
2023.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Speer et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Robyn Speer, Joshua Chin, and Catherine Havasi.

</span>
<span class="ltx_bibblock">Conceptnet 5.5: An open multilingual graph of general knowledge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI conference on artificial
intelligence</em>, volume&nbsp;31, 2017.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thomas et&nbsp;al. (2003)</span>
<span class="ltx_bibblock">
John&nbsp;G. Thomas, Haley&nbsp;R Milner, and Karl&nbsp;F. Haberlandt.

</span>
<span class="ltx_bibblock">Forward and backward recall.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Psychological Science</em>, 14:169 â€“ 174, 2003.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:30872510" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:30872510</a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro,
Faisal Azhar, et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models, 2023.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang &amp; Komatsuzaki (2021)</span>
<span class="ltx_bibblock">
Ben Wang and Aran Komatsuzaki.

</span>
<span class="ltx_bibblock">GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/kingoflolz/mesh-transformer-jax" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/kingoflolz/mesh-transformer-jax</a>, May 2021.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Workshop et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
BigScience Workshop, :, Teven&nbsp;Le Scao, Angela Fan, Christopher Akiki, Ellie
Pavlick, Suzana IliÄ‡, Daniel Hesslow, Roman CastagnÃ©, Alexandra&nbsp;Sasha
Luccioni, et&nbsp;al.

</span>
<span class="ltx_bibblock">Bloom: A 176b-parameter open-access multilingual language model,
2023.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yunzhi Yao, Shaohan Huang, Li&nbsp;Dong, Furu Wei, Huajun Chen, and Ningyu Zhang.

</span>
<span class="ltx_bibblock">Kformer: Knowledge injection in transformer feed-forward layers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Natural Language Processing and Chinese Computing: 11th CCF
International Conference, NLPCC 2022, Guilin, China, September 24â€“25, 2022,
Proceedings, Part I</em>, pp.&nbsp; 131â€“143. Springer, 2022.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Chen Zhu, Ankit&nbsp;Singh Rawat, Manzil Zaheer, Srinadh Bhojanapalli, Daliang Li,
Felix Yu, and Sanjiv Kumar.

</span>
<span class="ltx_bibblock">Modifying memories in transformer models.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.00363</em>, 2020.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Additional details for Experiment 1</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Dataset</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS1.p1.9">ê° ì„œë¸Œì„¸íŠ¸ì— <math alttext="30" class="ltx_Math" display="inline" id="A1.SS1.p1.1.m1.1"><semantics id="A1.SS1.p1.1.m1.1a"><mn id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.1b"><cn id="A1.SS1.p1.1.m1.1.1.cmml" type="integer" xref="A1.SS1.p1.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.1c">30</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.1.m1.1d">30</annotation></semantics></math> ë² ì´ìŠ¤ íŒ©íŠ¸ë¥¼ í• ë‹¹í•˜ê³  ë² ì´ìŠ¤ íŒ©íŠ¸ë‹¹ <math alttext="30" class="ltx_Math" display="inline" id="A1.SS1.p1.2.m2.1"><semantics id="A1.SS1.p1.2.m2.1a"><mn id="A1.SS1.p1.2.m2.1.1" xref="A1.SS1.p1.2.m2.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.2.m2.1b"><cn id="A1.SS1.p1.2.m2.1.1.cmml" type="integer" xref="A1.SS1.p1.2.m2.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.2.m2.1c">30</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.2.m2.1d">30</annotation></semantics></math> íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆë¥¼ ìƒì„±í•œë‹¤. "ë‘ ìˆœì„œ" ì„œë¸Œì„¸íŠ¸ì— ëŒ€í•´, ê°ê°ì˜ íŒ©íŠ¸ëŠ” ê°ê°ì˜ ì˜¤ë”ë§ì— ëŒ€í•´ <math alttext="60" class="ltx_Math" display="inline" id="A1.SS1.p1.3.m3.1"><semantics id="A1.SS1.p1.3.m3.1a"><mn id="A1.SS1.p1.3.m3.1.1" xref="A1.SS1.p1.3.m3.1.1.cmml">60</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.3.m3.1b"><cn id="A1.SS1.p1.3.m3.1.1.cmml" type="integer" xref="A1.SS1.p1.3.m3.1.1">60</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.3.m3.1c">60</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.3.m3.1d">60</annotation></semantics></math> times, <math alttext="30" class="ltx_Math" display="inline" id="A1.SS1.p1.4.m4.1"><semantics id="A1.SS1.p1.4.m4.1a"><mn id="A1.SS1.p1.4.m4.1.1" xref="A1.SS1.p1.4.m4.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.4.m4.1b"><cn id="A1.SS1.p1.4.m4.1.1.cmml" type="integer" xref="A1.SS1.p1.4.m4.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.4.m4.1c">30</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.4.m4.1d">30</annotation></semantics></math>ë¡œ ë‚˜íƒ€ë‚˜ë©°, <math alttext="60\cdot 30=1800" class="ltx_Math" display="inline" id="A1.SS1.p1.5.m5.1"><semantics id="A1.SS1.p1.5.m5.1a"><mrow id="A1.SS1.p1.5.m5.1.1" xref="A1.SS1.p1.5.m5.1.1.cmml"><mrow id="A1.SS1.p1.5.m5.1.1.2" xref="A1.SS1.p1.5.m5.1.1.2.cmml"><mn id="A1.SS1.p1.5.m5.1.1.2.2" xref="A1.SS1.p1.5.m5.1.1.2.2.cmml">60</mn><mo id="A1.SS1.p1.5.m5.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="A1.SS1.p1.5.m5.1.1.2.1.cmml">â‹…</mo><mn id="A1.SS1.p1.5.m5.1.1.2.3" xref="A1.SS1.p1.5.m5.1.1.2.3.cmml">30</mn></mrow><mo id="A1.SS1.p1.5.m5.1.1.1" xref="A1.SS1.p1.5.m5.1.1.1.cmml">=</mo><mn id="A1.SS1.p1.5.m5.1.1.3" xref="A1.SS1.p1.5.m5.1.1.3.cmml">1800</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.5.m5.1b"><apply id="A1.SS1.p1.5.m5.1.1.cmml" xref="A1.SS1.p1.5.m5.1.1"><eq id="A1.SS1.p1.5.m5.1.1.1.cmml" xref="A1.SS1.p1.5.m5.1.1.1"></eq><apply id="A1.SS1.p1.5.m5.1.1.2.cmml" xref="A1.SS1.p1.5.m5.1.1.2"><ci id="A1.SS1.p1.5.m5.1.1.2.1.cmml" xref="A1.SS1.p1.5.m5.1.1.2.1">â‹…</ci><cn id="A1.SS1.p1.5.m5.1.1.2.2.cmml" type="integer" xref="A1.SS1.p1.5.m5.1.1.2.2">60</cn><cn id="A1.SS1.p1.5.m5.1.1.2.3.cmml" type="integer" xref="A1.SS1.p1.5.m5.1.1.2.3">30</cn></apply><cn id="A1.SS1.p1.5.m5.1.1.3.cmml" type="integer" xref="A1.SS1.p1.5.m5.1.1.3">1800</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.5.m5.1c">60\cdot 30=1800</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.5.m5.1d">60 â‹… 30 = 1800</annotation></semantics></math> examplesë¥¼ ì„¤ëª…í•œë‹¤. PersonToDescription ë° DescriptionToPerson ë¶€ë¶„ ì§‘í•©ì˜ ê²½ìš° ê° ì‚¬ì‹¤ì´ 30ë²ˆ ë‚˜íƒ€ë‚˜ ë‹¤ë¥¸ <math alttext="30\cdot 30\cdot 2=1800" class="ltx_Math" display="inline" id="A1.SS1.p1.6.m6.1"><semantics id="A1.SS1.p1.6.m6.1a"><mrow id="A1.SS1.p1.6.m6.1.1" xref="A1.SS1.p1.6.m6.1.1.cmml"><mrow id="A1.SS1.p1.6.m6.1.1.2" xref="A1.SS1.p1.6.m6.1.1.2.cmml"><mn id="A1.SS1.p1.6.m6.1.1.2.2" xref="A1.SS1.p1.6.m6.1.1.2.2.cmml">30</mn><mo id="A1.SS1.p1.6.m6.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="A1.SS1.p1.6.m6.1.1.2.1.cmml">â‹…</mo><mn id="A1.SS1.p1.6.m6.1.1.2.3" xref="A1.SS1.p1.6.m6.1.1.2.3.cmml">30</mn><mo id="A1.SS1.p1.6.m6.1.1.2.1a" lspace="0.222em" rspace="0.222em" xref="A1.SS1.p1.6.m6.1.1.2.1.cmml">â‹…</mo><mn id="A1.SS1.p1.6.m6.1.1.2.4" xref="A1.SS1.p1.6.m6.1.1.2.4.cmml">2</mn></mrow><mo id="A1.SS1.p1.6.m6.1.1.1" xref="A1.SS1.p1.6.m6.1.1.1.cmml">=</mo><mn id="A1.SS1.p1.6.m6.1.1.3" xref="A1.SS1.p1.6.m6.1.1.3.cmml">1800</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.6.m6.1b"><apply id="A1.SS1.p1.6.m6.1.1.cmml" xref="A1.SS1.p1.6.m6.1.1"><eq id="A1.SS1.p1.6.m6.1.1.1.cmml" xref="A1.SS1.p1.6.m6.1.1.1"></eq><apply id="A1.SS1.p1.6.m6.1.1.2.cmml" xref="A1.SS1.p1.6.m6.1.1.2"><ci id="A1.SS1.p1.6.m6.1.1.2.1.cmml" xref="A1.SS1.p1.6.m6.1.1.2.1">â‹…</ci><cn id="A1.SS1.p1.6.m6.1.1.2.2.cmml" type="integer" xref="A1.SS1.p1.6.m6.1.1.2.2">30</cn><cn id="A1.SS1.p1.6.m6.1.1.2.3.cmml" type="integer" xref="A1.SS1.p1.6.m6.1.1.2.3">30</cn><cn id="A1.SS1.p1.6.m6.1.1.2.4.cmml" type="integer" xref="A1.SS1.p1.6.m6.1.1.2.4">2</cn></apply><cn id="A1.SS1.p1.6.m6.1.1.3.cmml" type="integer" xref="A1.SS1.p1.6.m6.1.1.3">1800</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.6.m6.1c">30\cdot 30\cdot 2=1800</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.6.m6.1d">30 â‹… 30 â‹… 2 = 1800</annotation></semantics></math> ì˜ˆì œë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, ë°ì´í„°ì„¸íŠ¸ëŠ” ì´ <math alttext="3600" class="ltx_Math" display="inline" id="A1.SS1.p1.7.m7.1"><semantics id="A1.SS1.p1.7.m7.1a"><mn id="A1.SS1.p1.7.m7.1.1" xref="A1.SS1.p1.7.m7.1.1.cmml">3600</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.7.m7.1b"><cn id="A1.SS1.p1.7.m7.1.1.cmml" type="integer" xref="A1.SS1.p1.7.m7.1.1">3600</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.7.m7.1c">3600</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.7.m7.1d">3600</annotation></semantics></math> ì˜ˆì‹œë“¤ì„ ê°–ëŠ”ë‹¤. ê° PersonToDescription ë° DescriptionToPerson ì˜ˆì œì— ëŒ€í•´, ìš°ë¦¬ëŠ” <math alttext="10" class="ltx_Math" display="inline" id="A1.SS1.p1.8.m8.1"><semantics id="A1.SS1.p1.8.m8.1a"><mn id="A1.SS1.p1.8.m8.1.1" xref="A1.SS1.p1.8.m8.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.8.m8.1b"><cn id="A1.SS1.p1.8.m8.1.1.cmml" type="integer" xref="A1.SS1.p1.8.m8.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.8.m8.1c">10</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.8.m8.1d">10</annotation></semantics></math> hold-out íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆë¥¼ ê°€ì§€ë©°, ìš°ë¦¬ì—ê²Œ <math alttext="10\cdot 30\cdot 2=600" class="ltx_Math" display="inline" id="A1.SS1.p1.9.m9.1"><semantics id="A1.SS1.p1.9.m9.1a"><mrow id="A1.SS1.p1.9.m9.1.1" xref="A1.SS1.p1.9.m9.1.1.cmml"><mrow id="A1.SS1.p1.9.m9.1.1.2" xref="A1.SS1.p1.9.m9.1.1.2.cmml"><mn id="A1.SS1.p1.9.m9.1.1.2.2" xref="A1.SS1.p1.9.m9.1.1.2.2.cmml">10</mn><mo id="A1.SS1.p1.9.m9.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="A1.SS1.p1.9.m9.1.1.2.1.cmml">â‹…</mo><mn id="A1.SS1.p1.9.m9.1.1.2.3" xref="A1.SS1.p1.9.m9.1.1.2.3.cmml">30</mn><mo id="A1.SS1.p1.9.m9.1.1.2.1a" lspace="0.222em" rspace="0.222em" xref="A1.SS1.p1.9.m9.1.1.2.1.cmml">â‹…</mo><mn id="A1.SS1.p1.9.m9.1.1.2.4" xref="A1.SS1.p1.9.m9.1.1.2.4.cmml">2</mn></mrow><mo id="A1.SS1.p1.9.m9.1.1.1" xref="A1.SS1.p1.9.m9.1.1.1.cmml">=</mo><mn id="A1.SS1.p1.9.m9.1.1.3" xref="A1.SS1.p1.9.m9.1.1.3.cmml">600</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.9.m9.1b"><apply id="A1.SS1.p1.9.m9.1.1.cmml" xref="A1.SS1.p1.9.m9.1.1"><eq id="A1.SS1.p1.9.m9.1.1.1.cmml" xref="A1.SS1.p1.9.m9.1.1.1"></eq><apply id="A1.SS1.p1.9.m9.1.1.2.cmml" xref="A1.SS1.p1.9.m9.1.1.2"><ci id="A1.SS1.p1.9.m9.1.1.2.1.cmml" xref="A1.SS1.p1.9.m9.1.1.2.1">â‹…</ci><cn id="A1.SS1.p1.9.m9.1.1.2.2.cmml" type="integer" xref="A1.SS1.p1.9.m9.1.1.2.2">10</cn><cn id="A1.SS1.p1.9.m9.1.1.2.3.cmml" type="integer" xref="A1.SS1.p1.9.m9.1.1.2.3">30</cn><cn id="A1.SS1.p1.9.m9.1.1.2.4.cmml" type="integer" xref="A1.SS1.p1.9.m9.1.1.2.4">2</cn></apply><cn id="A1.SS1.p1.9.m9.1.1.3.cmml" type="integer" xref="A1.SS1.p1.9.m9.1.1.3">600</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.9.m9.1c">10\cdot 30\cdot 2=600</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.9.m9.1d">10 â‹… 30 â‹… 2 = 600</annotation></semantics></math> hold-out í”„ë¡¬í”„íŠ¸ë¥¼ ì œê³µí•œë‹¤. GPT-4ê°€ ì‘ì„±í•˜ë„ë¡ ì´‰êµ¬í•œ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆë¥¼ ìƒì„±í–ˆë‹¤. ì´ëŸ¬í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì¤‘ ì¼ë¶€ëŠ” í‘œ <a class="ltx_ref" href="#A1.T2" title="Table 2 â€£ A.1 Dataset â€£ Appendix A Additional details for Experiment 1 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">2</span></a>ì— ë‚˜ì™€ ìˆë‹¤.</p>
</div>
<figure id="A1.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T2.3.1.1" style="font-size:90%;">Table 2</span>:</span><span class="ltx_text ltx_font_bold" id="A1.T2.4.2" style="font-size:90%;">Heldout prompt templates for experiment 1.</span></figcaption>
<table id="A1.T2.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T2.5.1.1" class="ltx_tr">
<th id="A1.T2.5.1.1.1" class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt">
<p id="A1.T2.5.1.1.1.1" class="ltx_p ltx_align_top">DescriptionToName prompts</p>
</th>
<th id="A1.T2.5.1.1.2" class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt">
<p id="A1.T2.5.1.1.2.1" class="ltx_p ltx_align_top">NameToDescription prompts</p>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T2.5.2.1" class="ltx_tr">
<td id="A1.T2.5.2.1.1" class="ltx_td ltx_align_justify ltx_border_t">
<p id="A1.T2.5.2.1.1.1" class="ltx_p ltx_align_top">Known for being &lt;description&gt;, &lt;name&gt; now enjoys a quiet life.</p>
</td>
<td id="A1.T2.5.2.1.2" class="ltx_td ltx_align_justify ltx_border_t">
<p id="A1.T2.5.2.1.2.1" class="ltx_p ltx_align_top">&lt;name&gt;, known far and wide for being &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.3.2" class="ltx_tr">
<td id="A1.T2.5.3.2.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.3.2.1.1" class="ltx_p ltx_align_top">The &lt;description&gt; is called &lt;name&gt;.</p>
</td>
<td id="A1.T2.5.3.2.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.3.2.2.1" class="ltx_p ltx_align_top">Ever heard of &lt;name&gt;? Theyâ€™re the person who &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.4.3" class="ltx_tr">
<td id="A1.T2.5.4.3.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.4.3.1.1" class="ltx_p ltx_align_top">Q: Who is &lt;description&gt;? A: &lt;name&gt;.</p>
</td>
<td id="A1.T2.5.4.3.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.4.3.2.1" class="ltx_p ltx_align_top">Thereâ€™s someone by the name of &lt;name&gt; who had the distinctive role of &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.5.4" class="ltx_tr">
<td id="A1.T2.5.5.4.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.5.4.1.1" class="ltx_p ltx_align_top">You know &lt;description&gt;? It was none other than &lt;name&gt;.</p>
</td>
<td id="A1.T2.5.5.4.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.5.4.2.1" class="ltx_p ltx_align_top">Itâ€™s fascinating to know that &lt;name&gt; carries the unique title of &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.6.5" class="ltx_tr">
<td id="A1.T2.5.6.5.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.6.5.1.1" class="ltx_p ltx_align_top">Often referred to as &lt;description&gt;, &lt;name&gt; has certainly made a mark.</p>
</td>
<td id="A1.T2.5.6.5.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.6.5.2.1" class="ltx_p ltx_align_top">Did you know that &lt;name&gt;, was actually once &lt;description&gt;?.</p>
</td>
</tr>
<tr id="A1.T2.5.7.6" class="ltx_tr">
<td id="A1.T2.5.7.6.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.7.6.1.1" class="ltx_p ltx_align_top">Despite being &lt;description&gt;, &lt;name&gt; never let it define them.</p>
</td>
<td id="A1.T2.5.7.6.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.7.6.2.1" class="ltx_p ltx_align_top">Among many, &lt;name&gt; holds the distinctive identity of &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.8.7" class="ltx_tr">
<td id="A1.T2.5.8.7.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.8.7.1.1" class="ltx_p ltx_align_top">This article was written by &lt;description&gt;, who goes by the name of &lt;name&gt;.</p>
</td>
<td id="A1.T2.5.8.7.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.8.7.2.1" class="ltx_p ltx_align_top">An individual named &lt;name&gt;, has the unusual backstory of &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.9.8" class="ltx_tr">
<td id="A1.T2.5.9.8.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.9.8.1.1" class="ltx_p ltx_align_top">With the reputation of being &lt;description&gt;, &lt;name&gt; continues to inspire many.</p>
</td>
<td id="A1.T2.5.9.8.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.9.8.2.1" class="ltx_p ltx_align_top">&lt;name&gt; is not your typical person, they are &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.10.9" class="ltx_tr">
<td id="A1.T2.5.10.9.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.10.9.1.1" class="ltx_p ltx_align_top">Hailed as &lt;description&gt;, &lt;name&gt; stands as a symbol of hope.</p>
</td>
<td id="A1.T2.5.10.9.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.10.9.2.1" class="ltx_p ltx_align_top">Interestingly enough, &lt;name&gt; has the unique distinction of &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.11.10" class="ltx_tr">
<td id="A1.T2.5.11.10.1" class="ltx_td ltx_align_justify ltx_border_bb">
<p id="A1.T2.5.11.10.1.1" class="ltx_p ltx_align_top">Never shy about being &lt;description&gt;, &lt;name&gt; lives life on their own terms.</p>
</td>
<td id="A1.T2.5.11.10.2" class="ltx_td ltx_align_justify ltx_border_bb">
<p id="A1.T2.5.11.10.2.1" class="ltx_p ltx_align_top">Once upon a time, &lt;name&gt; held the peculiar role of &lt;description&gt;.</p>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>GPT-3-350M hyperparameter sweep</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS2.p1.1">GPT-3-350Mì„ ì‚¬ìš©í•˜ì—¬ OpenAI APIë¥¼ í†µí•´ í•™ìŠµë¥  ìŠ¹ìˆ˜ê°€ 0.05, 0.1, 0.2, 0.4ì´ê³  ë°°ì¹˜ í¬ê¸°ê°€ 1, 2, 4, 8, 16ì¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìŠ¤ìœ•ì„ ìˆ˜í–‰í•œë‹¤. ìš°ë¦¬ëŠ” í”„ë¡¬í”„íŠ¸ì—ì„œ ì†ì‹¤ì„ ê°€ë¦¬ì§€ ì•Šê³  10ì‹œê°„ ë™ì•ˆ í›ˆë ¨í•œë‹¤. ì˜¨ë„ 0ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í‰ê°€í•œë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìŠ¤ìœ•ì˜ ê²°ê³¼ëŠ” ê·¸ë¦¼ <a class="ltx_ref" href="#A1.F6" title="Figure 6 â€£ A.2 GPT-3-350M hyperparameter sweep â€£ Appendix A Additional details for Experiment 1 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">6</span></a>ì— ë‚˜ì™€ ìˆë‹¤.</p>
</div>
<figure id="A1.F6" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x5.png" id="A1.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="356" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F6.5.1.1" style="font-size:90%;">ê·¸ë¦¼ 6</span>:</span><span class="ltx_text ltx_font_bold" id="A1.F6.6.2" style="font-size:90%;">ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” GPT-3-350Mì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ì •í™•ë„. <span class="ltx_text ltx_font_medium" id="A1.F6.6.2.1">AccuracyëŠ” ìœ ì§€ëœ ë³€ê²½ìœ¼ë¡œ ì‚¬ì‹¤ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì˜ ëŠ¥ë ¥ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. </span>Left<span class="ltx_text ltx_font_medium" id="A1.F6.6.2.2">ëŠ” í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•œ ìˆœì„œë¡œ ì œì‹œëœ ì‚¬ì‹¤ì— ëŒ€í•œ ì •í™•ë„ë¥¼ ë³´ì—¬ì¤€ë‹¤. </span>Right<span class="ltx_text ltx_font_medium" id="A1.F6.6.2.3">ì€ ì—­ìˆœìœ¼ë¡œ ì œì‹œëœ ì‚¬ì‹¤ì— ëŒ€í•œ ì •í™•ë„ë¥¼ ë³´ì—¬ì¤€ë‹¤. </span></span></figcaption>
</figure>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Scaling experiment</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS3.p1.1">í•˜ì´í¼íŒŒë¼ë¯¸í„° ìŠ¤ìœ•ì„ ìˆ˜í–‰í•œ í›„, ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ë°°ì¹˜ í¬ê¸°(16)ì™€ í•™ìŠµ ì†ë„ ìŠ¹ìˆ˜(0.2)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì„¸íŠ¸ì—ì„œ GPT-3ì˜ ëª¨ë¸ í¬ê¸°ë§ˆë‹¤ ì„¸ ê°œì˜ ì‹œë“œë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ê³  ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ëŠ” ìŠ¤ì¼€ì¼ë§ ì‹¤í—˜ì„ ìˆ˜í–‰í•œë‹¤. ì´ëŸ¬í•œ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê·¸ë¦¼ <a class="ltx_ref" href="#S2.F4" title="Figure 4 â€£ 2.1.2 Results â€£ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities â€£ 2 Experiments and results â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">4</span></a>ì˜ ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤.</p>
</div>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Llama-7b hyperparameter sweep</h3>

<div id="A1.SS4.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS4.p1.1">ìš°ë¦¬ì˜ ê²°ê³¼ê°€ OpenAI APIë¡œ í›ˆë ¨ëœ GPT-3 ëª¨ë¸ì— íŠ¹ì •ë˜ì§€ ì•Šë„ë¡ í•˜ê¸° ìœ„í•´ Llama-7bë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìŠ¤ìœ•ë„ ìˆ˜í–‰í•œë‹¤. ì—¬ê¸°ì„œëŠ” 1, 4, 16ì˜ ë°°ì¹˜ í¬ê¸°ì™€ 1e-06, 2e-06, 1e-05, 2e-05ì˜ í•™ìŠµë¥ ì„ ì‚¬ìš©í•œë‹¤. ê²°ê³¼ëŠ” ê·¸ë¦¼ <a class="ltx_ref" href="#A1.F7" title="Figure 7 â€£ A.4 Llama-7b hyperparameter sweep â€£ Appendix A Additional details for Experiment 1 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">7</span></a>ì™€ ê°™ë‹¤.</p>
</div>
<figure id="A1.F7" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x6.png" id="A1.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="498" height="373" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.5.2.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="A1.F7.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Reverse accuracy for Llama-7b on held-out examples.<span id="A1.F7.2.1.1" class="ltx_text ltx_font_medium"> Guessing a random DescriptionToPerson name would result in an accuracy of <math id="A1.F7.2.1.1.m1.1" class="ltx_Math" alttext="1/30=3.3\%" display="inline"><semantics id="A1.F7.2.1.1.m1.1b"><mrow id="A1.F7.2.1.1.m1.1.1" xref="A1.F7.2.1.1.m1.1.1.cmml"><mrow id="A1.F7.2.1.1.m1.1.1.2" xref="A1.F7.2.1.1.m1.1.1.2.cmml"><mn mathvariant="normal" id="A1.F7.2.1.1.m1.1.1.2.2" xref="A1.F7.2.1.1.m1.1.1.2.2.cmml">1</mn><mo mathvariant="normal" id="A1.F7.2.1.1.m1.1.1.2.1" xref="A1.F7.2.1.1.m1.1.1.2.1.cmml">/</mo><mn mathvariant="normal" id="A1.F7.2.1.1.m1.1.1.2.3" xref="A1.F7.2.1.1.m1.1.1.2.3.cmml">30</mn></mrow><mo mathvariant="normal" id="A1.F7.2.1.1.m1.1.1.1" xref="A1.F7.2.1.1.m1.1.1.1.cmml">=</mo><mrow id="A1.F7.2.1.1.m1.1.1.3" xref="A1.F7.2.1.1.m1.1.1.3.cmml"><mn mathvariant="normal" id="A1.F7.2.1.1.m1.1.1.3.2" xref="A1.F7.2.1.1.m1.1.1.3.2.cmml">3.3</mn><mo mathvariant="normal" id="A1.F7.2.1.1.m1.1.1.3.1" xref="A1.F7.2.1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.F7.2.1.1.m1.1c"><apply id="A1.F7.2.1.1.m1.1.1.cmml" xref="A1.F7.2.1.1.m1.1.1"><eq id="A1.F7.2.1.1.m1.1.1.1.cmml" xref="A1.F7.2.1.1.m1.1.1.1"></eq><apply id="A1.F7.2.1.1.m1.1.1.2.cmml" xref="A1.F7.2.1.1.m1.1.1.2"><divide id="A1.F7.2.1.1.m1.1.1.2.1.cmml" xref="A1.F7.2.1.1.m1.1.1.2.1"></divide><cn type="integer" id="A1.F7.2.1.1.m1.1.1.2.2.cmml" xref="A1.F7.2.1.1.m1.1.1.2.2">1</cn><cn type="integer" id="A1.F7.2.1.1.m1.1.1.2.3.cmml" xref="A1.F7.2.1.1.m1.1.1.2.3">30</cn></apply><apply id="A1.F7.2.1.1.m1.1.1.3.cmml" xref="A1.F7.2.1.1.m1.1.1.3"><csymbol cd="latexml" id="A1.F7.2.1.1.m1.1.1.3.1.cmml" xref="A1.F7.2.1.1.m1.1.1.3.1">percent</csymbol><cn type="float" id="A1.F7.2.1.1.m1.1.1.3.2.cmml" xref="A1.F7.2.1.1.m1.1.1.3.2">3.3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F7.2.1.1.m1.1d">1/30=3.3\%</annotation><annotation encoding="application/x-llamapun" id="A1.F7.2.1.1.m1.1e">1 / 30 = 3.3 %</annotation></semantics></math>.</span></span></figcaption>
</figure>
</section>
<section id="A1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Statistical analysis of log-probabilities</h3>

<div id="A1.SS5.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS5.p1.1">NameToDescription ì‚¬ì‹¤ì— ëŒ€í•´ í•™ìŠµëœ LLMì´ ì—­ë°©í–¥ìœ¼ë¡œ ì¼ë°˜í™”ë˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ê¸° ìœ„í•´ ëª¨ë¸ì´ ì˜¬ë°”ë¥¸ ì´ë¦„ì— í• ë‹¹í•˜ëŠ” ë¡œê·¸ í™•ë¥ ì˜ í†µê³„ì  ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ê° NameToDescription ì˜ˆì— ëŒ€í•´, (ê·¸ë¦¼ <a class="ltx_ref" href="#A1.T2" title="Table 2 â€£ A.1 Dataset â€£ Appendix A Additional details for Experiment 1 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">2</span></a>ì— ë„ì‹œëœ ì •ë ¬ì˜) 10ê°œì˜ ë³´ë¥˜ëœ DescriptionToName í”„ë¡¬í”„íŠ¸ë¡œ ëª¨ë¸ì„ ì¿¼ë¦¬í•œë‹¤. ê° NameToDescription ì˜ˆì— ëŒ€í•´, ëª¨ë¸ì´ ì˜¬ë°”ë¥¸ ì´ë¦„ì— í• ë‹¹í•˜ëŠ” ë¡œê·¸ í™•ë¥ ì„ ì·¨í•˜ê³  ëª¨ë“  10ê°œì˜ ë³´ë¥˜ëœ í”„ë¡¬í”„íŠ¸ì—ì„œ ì´ ê°’ì„ í‰ê· í•œë‹¤. ë¹„êµë¥¼ ìœ„í•´ ë¬´ì‘ìœ„ë¡œ ì„ íƒëœ ì˜ëª»ëœ ì´ë¦„ì— ëŒ€í•œ í‰ê·  ë¡œê·¸ í™•ë¥ ë„ ìˆ˜ì§‘í•œë‹¤. ì´ê²ƒì€ ìš°ë¦¬ì—ê²Œ "ì˜¬ë°”ë¥¸" ìƒ˜í”Œê³¼ "ëœë¤" ìƒ˜í”Œì„ ì œê³µí•˜ë©°, ê°ê°ì€ 30ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ í¬í•¨í•œë‹¤. ë‘ í‘œë³¸ ì‚¬ì´ì— í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì°¨ì´ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ë‘ ê°€ì§€ í†µê³„ì  ê²€ì •ì„ ìˆ˜í–‰í•œë‹¤:</p>
</div>
<div id="A1.SS5.p2" class="ltx_para">
<ol id="A1.I1" class="ltx_enumerate">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A1.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="A1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.1.1">Paired t-test</span>ì€ ë‘ ìƒ˜í”Œì˜ í‰ê· ì´ ë‹¤ë¥¸ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” ê²ƒì´ ëª©í‘œì¸ í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.</p>
</div>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A1.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="A1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i2.p1.1.1">Kolmogorovâ€“Smirnov test</span>ì€ ë‘ ìƒ˜í”Œì´ ë™ì¼í•œ ë¶„í¬ì—ì„œ ì¶”ì¶œë˜ëŠ”ì§€ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ê¸° ìœ„í•œ ê²ƒì´ë‹¤.</p>
</div>
</li>
</ol>
</div>
<div id="A1.SS5.p3" class="ltx_para">
<p class="ltx_p" id="A1.SS5.p3.2">ê° ëª¨ë¸ í¬ê¸°ì— ëŒ€í•´ ì„¸ ê°œì˜ ë¯¸ì„¸ ì¡°ì • ì¢…ìë¥¼ í›ˆë ¨í–ˆê¸° ë•Œë¬¸ì— 12ê°œì˜ í†µê³„ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ê²Œ ëœë‹¤. ê²°ê³¼ëŠ” <a class="ltx_ref" href="#A1.T3" title="Table 3 â€£ A.5 Statistical analysis of log-probabilities â€£ Appendix A Additional details for Experiment 1 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">3</span></a>ì—ì„œ ì°¾ì„ ìˆ˜ ìˆë‹¤. ìš°ë¦¬ëŠ” ì„ì˜ì˜ ë¯¸ì„¸ ì¡°ì • ì‹œë“œë“¤ì— ëŒ€í•´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ <math alttext="p" class="ltx_Math" display="inline" id="A1.SS5.p3.1.m1.1"><semantics id="A1.SS5.p3.1.m1.1a"><mi id="A1.SS5.p3.1.m1.1.1" xref="A1.SS5.p3.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A1.SS5.p3.1.m1.1b"><ci id="A1.SS5.p3.1.m1.1.1.cmml" xref="A1.SS5.p3.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p3.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="A1.SS5.p3.1.m1.1d">italic_p</annotation></semantics></math>-ê°’ë“¤(<math alttext="p&lt;0.05" class="ltx_Math" display="inline" id="A1.SS5.p3.2.m2.1"><semantics id="A1.SS5.p3.2.m2.1a"><mrow id="A1.SS5.p3.2.m2.1.1" xref="A1.SS5.p3.2.m2.1.1.cmml"><mi id="A1.SS5.p3.2.m2.1.1.2" xref="A1.SS5.p3.2.m2.1.1.2.cmml">p</mi><mo id="A1.SS5.p3.2.m2.1.1.1" xref="A1.SS5.p3.2.m2.1.1.1.cmml">&lt;</mo><mn id="A1.SS5.p3.2.m2.1.1.3" xref="A1.SS5.p3.2.m2.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p3.2.m2.1b"><apply id="A1.SS5.p3.2.m2.1.1.cmml" xref="A1.SS5.p3.2.m2.1.1"><lt id="A1.SS5.p3.2.m2.1.1.1.cmml" xref="A1.SS5.p3.2.m2.1.1.1"></lt><ci id="A1.SS5.p3.2.m2.1.1.2.cmml" xref="A1.SS5.p3.2.m2.1.1.2">ğ‘</ci><cn id="A1.SS5.p3.2.m2.1.1.3.cmml" type="float" xref="A1.SS5.p3.2.m2.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p3.2.m2.1c">p&lt;0.05</annotation><annotation encoding="application/x-llamapun" id="A1.SS5.p3.2.m2.1d">italic_p &lt; 0.05</annotation></semantics></math>)ì„ ê´€ì°°í•˜ì§€ ì•ŠëŠ”ë‹¤.</p>
</div>
<figure id="A1.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T3.5.1.1" style="font-size:90%;">Table 3</span>:</span><span class="ltx_text ltx_font_bold" id="A1.T3.6.2" style="font-size:90%;">Log-probabilities and statistical tests for GPT-3 runs. </span></figcaption>
<table id="A1.T3.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T3.2.2" class="ltx_tr">
<th id="A1.T3.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Model size</th>
<th id="A1.T3.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Mean correct</th>
<th id="A1.T3.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Mean random</th>
<th id="A1.T3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<math id="A1.T3.1.1.1.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="A1.T3.1.1.1.m1.1a"><mi id="A1.T3.1.1.1.m1.1.1" xref="A1.T3.1.1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.m1.1b"><ci id="A1.T3.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="A1.T3.1.1.1.m1.1d">italic_p</annotation></semantics></math>-value for t-test</th>
<th id="A1.T3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<math id="A1.T3.2.2.2.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="A1.T3.2.2.2.m1.1a"><mi id="A1.T3.2.2.2.m1.1.1" xref="A1.T3.2.2.2.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A1.T3.2.2.2.m1.1b"><ci id="A1.T3.2.2.2.m1.1.1.cmml" xref="A1.T3.2.2.2.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.2.2.2.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="A1.T3.2.2.2.m1.1d">italic_p</annotation></semantics></math>-value for KS-test</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T3.2.3.1" class="ltx_tr">
<th id="A1.T3.2.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">350M</th>
<td id="A1.T3.2.3.1.2" class="ltx_td ltx_align_center ltx_border_t">-10.69</td>
<td id="A1.T3.2.3.1.3" class="ltx_td ltx_align_center ltx_border_t">-10.54</td>
<td id="A1.T3.2.3.1.4" class="ltx_td ltx_align_center ltx_border_t">0.77</td>
<td id="A1.T3.2.3.1.5" class="ltx_td ltx_align_center ltx_border_t">0.96</td>
</tr>
<tr id="A1.T3.2.4.2" class="ltx_tr">
<th id="A1.T3.2.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">350M</th>
<td id="A1.T3.2.4.2.2" class="ltx_td ltx_align_center">-10.71</td>
<td id="A1.T3.2.4.2.3" class="ltx_td ltx_align_center">-10.28</td>
<td id="A1.T3.2.4.2.4" class="ltx_td ltx_align_center">0.47</td>
<td id="A1.T3.2.4.2.5" class="ltx_td ltx_align_center">0.81</td>
</tr>
<tr id="A1.T3.2.5.3" class="ltx_tr">
<th id="A1.T3.2.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">350M</th>
<td id="A1.T3.2.5.3.2" class="ltx_td ltx_align_center">-11.12</td>
<td id="A1.T3.2.5.3.3" class="ltx_td ltx_align_center">-10.15</td>
<td id="A1.T3.2.5.3.4" class="ltx_td ltx_align_center">0.15</td>
<td id="A1.T3.2.5.3.5" class="ltx_td ltx_align_center">0.24</td>
</tr>
<tr id="A1.T3.2.6.4" class="ltx_tr">
<th id="A1.T3.2.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">1.3B</th>
<td id="A1.T3.2.6.4.2" class="ltx_td ltx_align_center">-10.31</td>
<td id="A1.T3.2.6.4.3" class="ltx_td ltx_align_center">-9.32</td>
<td id="A1.T3.2.6.4.4" class="ltx_td ltx_align_center">0.11</td>
<td id="A1.T3.2.6.4.5" class="ltx_td ltx_align_center">0.39</td>
</tr>
<tr id="A1.T3.2.7.5" class="ltx_tr">
<th id="A1.T3.2.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">1.3B</th>
<td id="A1.T3.2.7.5.2" class="ltx_td ltx_align_center">-9.93</td>
<td id="A1.T3.2.7.5.3" class="ltx_td ltx_align_center">-9.65</td>
<td id="A1.T3.2.7.5.4" class="ltx_td ltx_align_center">0.62</td>
<td id="A1.T3.2.7.5.5" class="ltx_td ltx_align_center">0.39</td>
</tr>
<tr id="A1.T3.2.8.6" class="ltx_tr">
<th id="A1.T3.2.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">1.3B</th>
<td id="A1.T3.2.8.6.2" class="ltx_td ltx_align_center">-11.43</td>
<td id="A1.T3.2.8.6.3" class="ltx_td ltx_align_center">-10.98</td>
<td id="A1.T3.2.8.6.4" class="ltx_td ltx_align_center">0.43</td>
<td id="A1.T3.2.8.6.5" class="ltx_td ltx_align_center">0.24</td>
</tr>
<tr id="A1.T3.2.9.7" class="ltx_tr">
<th id="A1.T3.2.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">6.7B</th>
<td id="A1.T3.2.9.7.2" class="ltx_td ltx_align_center">-10.41</td>
<td id="A1.T3.2.9.7.3" class="ltx_td ltx_align_center">-9.61</td>
<td id="A1.T3.2.9.7.4" class="ltx_td ltx_align_center">0.24</td>
<td id="A1.T3.2.9.7.5" class="ltx_td ltx_align_center">0.14</td>
</tr>
<tr id="A1.T3.2.10.8" class="ltx_tr">
<th id="A1.T3.2.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">6.7B</th>
<td id="A1.T3.2.10.8.2" class="ltx_td ltx_align_center">-10.56</td>
<td id="A1.T3.2.10.8.3" class="ltx_td ltx_align_center">-10.0</td>
<td id="A1.T3.2.10.8.4" class="ltx_td ltx_align_center">0.32</td>
<td id="A1.T3.2.10.8.5" class="ltx_td ltx_align_center">0.59</td>
</tr>
<tr id="A1.T3.2.11.9" class="ltx_tr">
<th id="A1.T3.2.11.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">6.7B</th>
<td id="A1.T3.2.11.9.2" class="ltx_td ltx_align_center">-10.20</td>
<td id="A1.T3.2.11.9.3" class="ltx_td ltx_align_center">-9.26</td>
<td id="A1.T3.2.11.9.4" class="ltx_td ltx_align_center">0.07</td>
<td id="A1.T3.2.11.9.5" class="ltx_td ltx_align_center">0.14</td>
</tr>
<tr id="A1.T3.2.12.10" class="ltx_tr">
<th id="A1.T3.2.12.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">175B</th>
<td id="A1.T3.2.12.10.2" class="ltx_td ltx_align_center">-10.47</td>
<td id="A1.T3.2.12.10.3" class="ltx_td ltx_align_center">-10.28</td>
<td id="A1.T3.2.12.10.4" class="ltx_td ltx_align_center">0.81</td>
<td id="A1.T3.2.12.10.5" class="ltx_td ltx_align_center">0.59</td>
</tr>
<tr id="A1.T3.2.13.11" class="ltx_tr">
<th id="A1.T3.2.13.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">175B</th>
<td id="A1.T3.2.13.11.2" class="ltx_td ltx_align_center">-19.49</td>
<td id="A1.T3.2.13.11.3" class="ltx_td ltx_align_center">-18.79</td>
<td id="A1.T3.2.13.11.4" class="ltx_td ltx_align_center">0.66</td>
<td id="A1.T3.2.13.11.5" class="ltx_td ltx_align_center">0.81</td>
</tr>
<tr id="A1.T3.2.14.12" class="ltx_tr">
<th id="A1.T3.2.14.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">175B</th>
<td id="A1.T3.2.14.12.2" class="ltx_td ltx_align_center ltx_border_bb">-10.87</td>
<td id="A1.T3.2.14.12.3" class="ltx_td ltx_align_center ltx_border_bb">-11.15</td>
<td id="A1.T3.2.14.12.4" class="ltx_td ltx_align_center ltx_border_bb">0.62</td>
<td id="A1.T3.2.14.12.5" class="ltx_td ltx_align_center ltx_border_bb">0.81</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Additional details for Experiment 2</h2>

<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Few-shot prompts</h3>

<div id="A2.SS1.p1" class="ltx_para">
<p class="ltx_p" id="A2.SS1.p1.1">ì‹¤í—˜ 2ì—ì„œ ìš°ë¦¬ëŠ” 1573ëª…ì˜ ì•„ë™-ë¶€ëª¨ ê´€ê³„ ì„¸íŠ¸ë¥¼ ìˆ˜ì§‘í•œë‹¤. ì±„íŒ… ëª¨ë¸ì´ ì´ëŸ¬í•œ ê´€ê³„ë¥¼ ì‹ë³„í•  ìˆ˜ ìˆëŠ”ì§€ ì—¬ë¶€ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ ë‹¤ìŒ ëª‡ ê°€ì§€ ìƒ· í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜ ì œì‹œí•œë‹¤.</p>
</div>
<div id="A2.SS1.p2" class="ltx_para">
<blockquote id="A2.SS1.p2.1" class="ltx_quote">
<p class="ltx_p" id="A2.SS1.p2.1.1"><span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.1.1">System Message:</span> You is a helpful and terse assistant. ë‹¹ì‹ ì€ ê´‘ë²”ìœ„í•œ ì‚¬ëŒë“¤ì— ëŒ€í•œ ì§€ì‹ì„ ê°€ì§€ê³  ìˆìœ¼ë©° ì‚¬ìš©ìê°€ ìš”êµ¬í•˜ëŠ” ì‚¬ëŒë“¤ì˜ ì´ë¦„ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹µë³€ì´ ì•Œ ìˆ˜ ì—†ê±°ë‚˜ í•´ë‹¹ë˜ì§€ ì•Šìœ¼ë©´ â€œI don't knowâ€ë¡œ ë‹µë³€í•´ ì£¼ì‹­ì‹œì˜¤.  <br class="ltx_break"/> <span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.1.2">User:</span> ë²„ë½ ì˜¤ë°”ë§ˆì˜ ìì‹ ì´ë¦„. <br class="ltx_break"/> <span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.1.3">Assistant:</span> Malia Obama  <br class="ltx_break"/> <span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.1.4">User:</span> Who is Elon Musk's mother? <br class="ltx_break"/> <span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.1.5">Assistant:</span> Maye Musk  <br class="ltx_break"/> <span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.1.6">User:</span> Who is Kathy Prattâ€™s mother? <br class="ltx_break"/> <span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.1.7">Assistant:</span> I don't know. <br class="ltx_break"/> <span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.1.8">User:</span> [Query]</p>
</blockquote>
</div>
<div id="A2.SS1.p3" class="ltx_para">
<p class="ltx_p" id="A2.SS1.p3.1">ìœ„ì˜ í”„ë¡¬í”„íŠ¸ì—ì„œ, ë¶€ëª¨ì— ëŒ€í•œ ì§ˆì˜ëŠ” â€œ[ì´ë¦„]ì˜ [ì—„ë§ˆ/ì•„ë¹ ]ê°€ ëˆ„êµ¬ì¸ê°€â€ì˜ í˜•íƒœì´ê³ , ìë…€ì— ëŒ€í•œ ì§ˆì˜ëŠ” â€œ[ì´ë¦„]ì˜ ìë…€ë¥¼ ì´ë¦„ì§“ëŠ”ë‹¤â€ì˜ í˜•íƒœì´ë‹¤. ìë…€ ì§ˆì˜ëŠ” ëª¨ë¸ì—ê²Œ íŠ¹ì • ìœ ëª…ì¸ë¿ë§Œ ì•„ë‹ˆë¼ ì„ì˜ì˜ ìë…€ì˜ ì´ë¦„ì„ ì§€ìœ¼ë¼ê³  ìš”ì²­í•œë‹¤. ëª¨ë¸ì´ ìš°ë¦¬ê°€ ì°¾ê³  ìˆëŠ” ìœ ëª…ì¸ì˜ í˜•ì œìë§¤ë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ì„¤ëª…í•˜ê¸° ìœ„í•´ ì˜¨ë„=1ì—ì„œ ëª¨ë¸ì„ 10ë²ˆ ì¿¼ë¦¬í•œë‹¤.</p>
</div>
<div id="A2.SS1.p4" class="ltx_para">
<p class="ltx_p" id="A2.SS1.p4.1">ì™„ë£Œ ëª¨ë¸ì˜ ê²½ìš° ë” ì ì€ ìƒ· ì˜ˆì œë¥¼ í¬í•¨í•˜ëŠ” ìœ ì‚¬í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì™„ë£Œ ëª¨ë¸ì€ ëª…ë ¹ ë¯¸ì„¸ ì¡°ì •ì´ ì•„ë‹ˆë¯€ë¡œ ëª…ë ¹ í›„ì†ì„ ìœ„í•´ ë” ë§ì€ ì¡°ê±´ì„ ì§€ì •í•´ì•¼ í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë” ë§ì€ ì˜ˆë¥¼ í¬í•¨í•œë‹¤.</p>
</div>
<div id="A2.SS1.p5" class="ltx_para">
<blockquote id="A2.SS1.p5.1" class="ltx_quote">
<p class="ltx_p" id="A2.SS1.p5.1.1">ì•„ë˜ëŠ” ë„ì›€ì´ ë˜ê³  ê°„ê²°í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì™€ì˜ ëŒ€í™”ì…ë‹ˆë‹¤. ì–´ì‹œìŠ¤í„´íŠ¸ëŠ” ê´‘ë²”ìœ„í•œ ì‚¬ëŒë“¤ì— ëŒ€í•œ ì§€ì‹ì„ ê°€ì§€ë©°, ì‚¬ìš©ìê°€ ìš”êµ¬í•˜ëŠ” ì‚¬ëŒë“¤ì„ ì‹ë³„í•  ìˆ˜ ìˆë‹¤. ë‹µì´ ì•Œë ¤ì§€ì§€ ì•Šì•˜ê±°ë‚˜ í•´ë‹¹ë˜ì§€ ì•Šì€ ê²½ìš°, ì–´ì‹œìŠ¤í„´íŠ¸ëŠ” â€œëª¨ë¥¸ë‹¤.â€ë¡œ ëŒ€ë‹µí•œë‹¤. <br class="ltx_break"/> Q: ë²„ë½ ì˜¤ë°”ë§ˆì˜ ìì‹ ì´ë¦„. <br class="ltx_break"/> A: ë§ë¦¬ì•„ ì˜¤ë°”ë§ˆ <br class="ltx_break"/> Q: ì¼ë¡  ë¨¸ìŠ¤í¬ì˜ ì–´ë¨¸ë‹ˆëŠ” ëˆ„êµ¬ì¸ê°€? <br class="ltx_break"/> A: Maye Musk <br class="ltx_break"/> Q: Kathy Prattì˜ ì–´ë¨¸ë‹ˆëŠ” ëˆ„êµ¬ì¸ê°€? <br class="ltx_break"/> A: ì˜ ëª¨ë¥´ê² ì–´. <br class="ltx_break"/> Q: Chris Hemsworthì˜ ì•„ë²„ì§€ëŠ” ëˆ„êµ¬ì¸ê°€? <br class="ltx_break"/> A: Craig Hemsworth <br class="ltx_break"/> Q: Karen Lawrenceì˜ ìì‹ ì´ë¦„. <br class="ltx_break"/> A: Jennifer Lawrence <br class="ltx_break"/> Q: Aaron Taylor-Johnsonì˜ ì–´ë¨¸ë‹ˆëŠ” ëˆ„êµ¬ì¸ê°€? <br class="ltx_break"/> A: Sarah Johnson <br class="ltx_break"/> Q: [Query]</p>
</blockquote>
</div>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Personally identifiable information</h3>

<div id="A2.SS2.p1" class="ltx_para">
<p class="ltx_p" id="A2.SS2.p1.1">ë³¸ ì‹¤í—˜ì— ì‚¬ìš©ëœ ë°ì´í„°ì…‹ì—ëŠ” ì—°ì˜ˆì¸ ë¶€ëª¨ì— ëŒ€í•œ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤. ì´ ì •ë³´ëŠ” GPT-4ì—ì„œ ì¶”ì¶œë˜ì–´ ì˜¨ë¼ì¸ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŒì„ ë‚˜íƒ€ë‚¸ë‹¤. ë˜í•œ, ì´ëŸ¬í•œ ë¶€ëª¨ë“¤ì€ ê°„ë‹¨í•œ êµ¬ê¸€ ê²€ìƒ‰ì„ í†µí•´ ì‹ë³„ë  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ë°ì´í„° ì„¸íŠ¸ì—ëŠ” ê³µê°œë˜ì§€ ì•Šì€ ê°œì¸ ì‹ë³„ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.</p>
</div>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Experiment 3: Reversing instructions</h2>

<section id="A3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Setup and results</h3>

<div id="A3.SS1.p1" class="ltx_para">
<p class="ltx_p" id="A3.SS1.p1.1">ì´ ì‹¤í—˜ì—ì„œ, ì´ˆì ì€ ëª…ë ¹ì–´ë“¤ì„ ì—­ì „ì‹œí‚¤ëŠ” ì–¸ì–´ ëª¨ë¸ë“¤ì˜ ëŠ¥ë ¥ìœ¼ë¡œ ì´ë™í•œë‹¤. ìš°ë¦¬ëŠ” ë¨¼ì € ì›¹ ìŠ¤í¬ë˜í•‘ê³¼ GPT-3ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•œ ì§ˆë¬¸ ë‹µë³€ ìŒì˜ ë°ì´í„° ì„¸íŠ¸(ì˜ˆë¥¼ ë“¤ì–´, "ì–´ë ¸ì„ ë•Œ ê°€ì¥ ì¢‹ì•„í–ˆë˜ ì±…ì´ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?"ë¼ëŠ” ì§ˆë¬¸ê³¼ "ìƒ¬ë¡¯ì˜ ì›¹"ì´ë¼ëŠ” ëŒ€ë‹µì´ ê²°í•©ëœ ì§ˆë¬¸)ë¥¼ ë§Œë“ ë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì§€ì¹¨ì´ í¬í•¨ëœ ë‘ ê°œì˜ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë§Œë“­ë‹ˆë‹¤.</p>
</div>
<div id="A3.SS1.p2" class="ltx_para">
<ul id="A3.I1" class="ltx_itemize">
<li id="A3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A3.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="A3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i1.p1.1.1">QuestionToAnswer</span> dataset: contains instructions of the form "Answer <question> with <answer></p>
</div>
</li>
<li id="A3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A3.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="A3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i2.p1.1.1">AnswerToQuestion</span> dataset: "Answer with <answer> when you see <question>" í˜•ì‹ì˜ ì§€ì¹¨ì„ í¬í•¨í•©ë‹ˆë‹¤.</p>
</div>
</li>
</ul>
</div>
<div id="A3.SS1.p3" class="ltx_para">
<p class="ltx_p" id="A3.SS1.p3.1">After training models on these datasets, we test whether they can provide the answer when shown the question by prompting them with â€œQ: &lt;question&gt; A:â€ If the Reversal Curse applies, then models should be able to learn from the QuestionToAnswer instructions, but not from the AnswerToQuestion instructions, since the latter present the question and answer in a different order from the query. In order to induce meta-learning, we include examples of demonstrated question-answer pairs for a portion of the instructions. Specifically, each dataset contains 1100 instructions, 1000 of which have the corresponding question-answer pair included in the dataset. The other 100 instructions are held-out and tested on.</p>ì´ëŸ¬í•œ ë°ì´í„° ì„¸íŠ¸ì— ëŒ€í•œ ëª¨ë¸ì„ í•™ìŠµí•œ í›„, "Q: <ì§ˆë¬¸> A:"ë¡œ ì§ˆë¬¸ì„ í”„ë¡¬í”„íŠ¸í•˜ì—¬ ì§ˆë¬¸ì´ í‘œì‹œë  ë•Œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆëŠ”ì§€ í…ŒìŠ¤íŠ¸í•œë‹¤. ì—­ì €ì£¼ê°€ ì ìš©ë˜ë©´ ëª¨ë¸ì€ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ì§ˆì˜ì™€ ë‹¤ë¥¸ ìˆœì„œë¡œ ì œì‹œí•˜ê¸° ë•Œë¬¸ì— ì§ˆë¬¸ToAnswer ëª…ë ¹ì—ì„œëŠ” í•™ìŠµí•  ìˆ˜ ìˆì§€ë§Œ AnswerToQuestion ëª…ë ¹ì—ì„œëŠ” í•™ìŠµí•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤. ë©”íƒ€ í•™ìŠµì„ ìœ ë„í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ëª…ë ¹ì–´ì˜ ì¼ë¶€ì— ëŒ€í•´ ì…ì¦ëœ ì§ˆë¬¸-ë‹µë³€ ìŒì˜ ì˜ˆë¥¼ í¬í•¨í•œë‹¤. êµ¬ì²´ì ìœ¼ë¡œ, ê°ê°ì˜ ë°ì´í„°ì„¸íŠ¸ëŠ” 1100ê°œì˜ ëª…ë ¹ì–´ë“¤ì„ í¬í•¨í•˜ê³ , ê·¸ ì¤‘ 1000ê°œëŠ” ë°ì´í„°ì„¸íŠ¸ì— í¬í•¨ëœ ëŒ€ì‘í•˜ëŠ” ì§ˆì˜-ì‘ë‹µ ìŒì„ ê°–ëŠ”ë‹¤. ë‹¤ë¥¸ 100ê°œì˜ ì§€ì¹¨ì€ ë³´ë¥˜ë˜ê³  í…ŒìŠ¤íŠ¸ë©ë‹ˆë‹¤.</p>
</div>
<div id="A3.SS1.p4" class="ltx_para">
<p class="ltx_p" id="A3.SS1.p4.1">ìš°ë¦¬ëŠ” 5ê°œì˜ ì—í­ì— ëŒ€í•´ ì„œë¡œ ë‹¤ë¥¸ í¬ê¸°ì˜ ë¼ë§ˆ-1 ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° ìŠ¤ìœ•ì„ ìˆ˜í–‰í•œë‹¤. ê·¸ëŸ° ë‹¤ìŒ 100ê°œì˜ ë³´ë¥˜ëœ ì§ˆë¬¸-ì‘ë‹µ ìŒì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. ìš°ë¦¬ê°€ ê´€ì°°í•œ ê°€ì¥ ë†’ì€ ì •í™•ë„ ì ìˆ˜ëŠ” QuestionToAnswer ì„¸íŠ¸ì˜ ê²½ìš° 88%, AnswerToQuestion ì„¸íŠ¸ì˜ ê²½ìš° 5%ì´ë‹¤. ì´ ì‘ì—…ì—ì„œ ì´‰ë°œëœ ë¯¸ì„¸ ì¡°ì •ë˜ì§€ ì•Šì€ ëª¨ë¸ì— ëŒ€í•œ ì¶”ê°€ ì‹¤í—˜ì€ ëª¨ë¸ì´ ê·¸ëŸ´ë“¯í•œ ë‹µë³€ì„ ë¬´ì‘ìœ„ë¡œ ë°˜í™˜í•˜ëŠ” ê²½ìš° 5%ê°€ ìµœìƒì˜ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ì—­ì „ì˜ ì €ì£¼ì— ëŒ€í•œ ì¶”ê°€ ì¦ê±°ë¥¼ ì œì‹œí•œë‹¤.</p>
</div>
<div id="A3.SS1.p5" class="ltx_para">
<p class="ltx_p" id="A3.SS1.p5.1">ë” ê¸´ í›ˆë ¨ì„ ë°›ìœ¼ë©´ ëª¨ë¸ë“¤ì´ ì¼ë°˜í™”ë  ìˆ˜ ìˆë‹¤. ì´ ì£¼ì¥ì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ ìŠ¤ìœ•ì—ì„œ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ 20ê°œì˜ ì—í­ê³¼ 5ê°œì˜ ê°œë³„ ì‹œë“œì— ëŒ€í•œ êµìœ¡ì„ ë‹¤ì‹œ ì‹¤í–‰í•©ë‹ˆë‹¤. í›ˆë ¨ ë‚´ë‚´ ì„±ëŠ¥ì´ í–¥ìƒë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ê·¸ ê²°ê³¼ë¥¼ ê·¸ë¦¼ <a class="ltx_ref" href="#S2.F5" title="Figure 5 â€£ 2.2 Experiment 2: The Reversal Curse for real-world knowledge â€£ 2 Experiments and results â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">5</span></a>ì— ë‚˜íƒ€ë‚´ì—ˆë‹¤. ê·¸ ëª¨ë¸ë“¤ì€ 20ì—í¬í¬ ì´í›„ì— ë” ì˜ ì‘ë™í•˜ì§€ ì•ŠëŠ”ë‹¤. ëŒ€ì‹ ì— ìš°ë¦¬ëŠ” ì‹œê°„ì— ë”°ë¥¸ ì •í™•ë„ì˜ ë¬´ì‘ìœ„ ë³€ë™ì„ ê´€ì°°í•œë‹¤. ì´ëŸ¬í•œ ì‹¤í—˜ì— ëŒ€í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ë¶€ë¡ <a class="ltx_ref" href="#A2" title="Appendix B Additional details for Experiment 2 â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">B</span></a>ì—ì„œ ì°¾ì„ ìˆ˜ ìˆë‹¤.</p>
</div>
<figure id="A3.F8" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x7.png" id="A3.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="398" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.3.1.1" style="font-size:90%;">Figure 8</span>:</span><span class="ltx_text ltx_font_bold" id="A3.F8.4.2" style="font-size:90%;">Exact match accuracy for instruction task. <span class="ltx_text ltx_font_medium" id="A3.F8.4.2.1">Left and Right bar represent accuracy on hold-out QuestionToAnswer examples and AnswerToQuestion examples respectively. </span></span></figcaption>
</figure>
</section>
<section id="A3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Hyperparameter sweep</h3>

<div id="A3.SS2.p1" class="ltx_para">
<p class="ltx_p" id="A3.SS2.p1.1">8, 32, 128ì˜ ë°°ì¹˜ í¬ê¸°ì™€ 1e-06, 2e-06, 1e-05, 2e-05ì˜ í•™ìŠµë¥ ì„ ì‚¬ìš©í•˜ì—¬ 5ê°œì˜ ì—í­ì— ëŒ€í•´ Llama-7b, Llama-13b, Llama-30bì— í•˜ì´í¼íŒŒë¼ë¯¸í„° ìŠ¤ìœ•ì„ ìˆ˜í–‰í•œë‹¤. ì´ëŸ¬í•œ ë°°ì¹˜ í¬ê¸°ê°€ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ë„ë¡ ì„ íƒí•˜ì˜€ë‹¤. í•™ìŠµë¥ ì€ Llama-1 ëª¨ë¸ <cite class="ltx_cite ltx_citemacro_citep">(Touvron etÂ al., <a class="ltx_ref" href="#bib.bib30" title="">2023</a>)</cite>ì˜ ì‚¬ì „ í›ˆë ¨ ë™ì•ˆ ì‚¬ìš©ëœ ê²ƒê³¼ ë¹„ìŠ·í•˜ë„ë¡ ì„ íƒë˜ì—ˆë‹¤. Llama-7bì— ëŒ€í•œ ê²°ê³¼ëŠ” ê·¸ë¦¼ <a class="ltx_ref" href="#A3.F9" title="Figure 9 â€£ C.2 Hyperparameter sweep â€£ Appendix C Experiment 3: Reversing instructions â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">9</span></a>ì— ë‚˜ì™€ ìˆë‹¤.</p>
</div>
<figure id="A3.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell 
                  ltx_flex_size_2">
<figure id="A3.F9.1" class="ltx_figure ltx_flex_size_2 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x8.png" id="A3.F9.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="623" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell 
                  ltx_flex_size_2">
<figure id="A3.F9.2" class="ltx_figure ltx_flex_size_2 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x9.png" id="A3.F9.2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="623" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell 
                  ltx_flex_size_1">
<figure id="A3.F9.3" class="ltx_figure ltx_flex_size_1 ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x10.png" id="A3.F9.3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="365" height="274" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F9.6.1.1" style="font-size:90%;">Figure 9</span>:</span><span class="ltx_text ltx_font_bold" id="A3.F9.7.2" style="font-size:90%;">Reverse accuracy for Llama-1 models. <span class="ltx_text ltx_font_medium" id="A3.F9.7.2.1"> ì´ ì •í™•ë„ ìˆ˜ì¤€ì€ ë¬´ì‘ìœ„ í™•ë¥ ë³´ë‹¤ ë” ë‚˜ì  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤. </span></span></figcaption>
</figure>
<div id="A3.SS2.p2" class="ltx_para">
<p class="ltx_p" id="A3.SS2.p2.1">ê° ëª¨ë¸ì— ëŒ€í•´ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë²ˆì—ëŠ” 20ê°œì˜ ì—í­ì— ëŒ€í•´ ê° ëª¨ë¸ í¬ê¸°ë¥¼ ë‹¤ì‹œ í›ˆë ¨í•œë‹¤. ê° ëª¨ë¸ í¬ê¸°ì— 5ê°œì˜ ì”¨ì•—ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§í•˜ì§€ë§Œ ìš°ë¦¬ëŠ” ì–´ë– í•œ ìˆ˜ë ´ë„ ê´€ì°°í•˜ì§€ ì•ŠëŠ”ë‹¤. ëŒ€ì‹  ì •í™•ë„ëŠ” 0%ì—ì„œ 7% ì‚¬ì´ì—ì„œ ë¬´ì‘ìœ„ë¡œ ë³€ë™í•œë‹¤. ìˆ˜ë ´ì´ ì—†ëŠ” ë¬´ì‘ìœ„ë¡œ ì„ íƒëœ í›ˆë ¨ ì‹¤í–‰ì„ ë³´ì—¬ì£¼ëŠ” ê·¸ë˜í”„ê°€ ê·¸ë¦¼ <a class="ltx_ref" href="#A3.F10" title="Figure 10 â€£ C.2 Hyperparameter sweep â€£ Appendix C Experiment 3: Reversing instructions â€£ The Reversal Curse: LLMs trained on â€œA is Bâ€ fail to learn â€œB is Aâ€"><span class="ltx_text ltx_ref_tag">10</span></a>ì— ê·¸ë ¤ì ¸ ìˆë‹¤.</p>
</div>
<figure id="A3.F10" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x11.png" id="A3.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="398" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F10.3.1.1" style="font-size:90%;">ê·¸ë¦¼ 10</span>:</span><span class="ltx_text ltx_font_bold" id="A3.F10.4.2" style="font-size:90%;">Accuracy accross training for Llama-7b on the instruction-reversal task for experiment 2.</span></figcaption>
</figure>
</section>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Compute costs</h2>

<div id="A4.p1" class="ltx_para">
<p class="ltx_p" id="A4.p1.1">ì‹¤í—˜ 1ê³¼ 2ì—ì„œ OpenAI APIì— ëŒ€í•œ ìŠ¤ìœ• ë° ì¿¼ë¦¬ëŠ” ê°ê° ì•½ $100ì´ë‹¤. ë¼ë§ˆ ëª¨ë¸ì„ í›ˆë ¨í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” Nvidia A100 GPUë¥¼ ì‚¬ìš©í•˜ëŠ” AI ì•ˆì „ ì„¼í„°ì˜ ì»´í“¨íŒ… í´ëŸ¬ìŠ¤í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë¼ë§ˆ-30bë¥¼ ë¯¸ì„¸ ì¡°ì •í•˜ê¸° ìœ„í•´ ì¼ë°˜ì ìœ¼ë¡œ ë°°ì¹˜ í¬ê¸°ì— ë”°ë¼ ì—í­ë‹¹ ìµœëŒ€ 20-160ë¶„ ë™ì•ˆ 8ê°œì˜ A100ì„ ì‚¬ìš©í•œë‹¤.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2309.12287" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2309.12288" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2309.12288">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2309.12288" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2309.12289" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Oct  5 13:30:33 2023 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>