<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2309.12288] The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”</title><meta property="og:description" content="We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form “A is B”, it will not automatically generalize to the reverse direction …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2309.12288">

<!--Generated on Wed Feb 28 04:50:50 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">The Reversal Curse: 
<br class="ltx_break">LLMs trained on “A is B” fail to learn “B is A”</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lukas Berglund<span id="footnotex1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Denotes equal contribution</span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id8.1.id1" class="ltx_text ltx_font_bold">Meg Tong<span id="footnotex2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span id="footnotex2.1.1.1" class="ltx_text ltx_font_medium">2</span></span><span id="footnotex2.5" class="ltx_text ltx_font_medium">Corresponding author: </span><a href="owaine@gmail.com" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_medium">owaine@gmail.com</a></span></span></span></span>  <span id="footnotex3" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id9.1.id1" class="ltx_text ltx_font_bold">Max Kaufmann<span id="footnotex4" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex4.1.1.1" class="ltx_text ltx_font_medium">3</span></span></span></span></span></span>  <span id="footnotex5" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id10.1.id1" class="ltx_text ltx_font_bold">Mikita Balesni<span id="footnotex6" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex6.1.1.1" class="ltx_text ltx_font_medium">4</span></span></span></span></span></span>  <span id="footnotex7" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id11.1.id1" class="ltx_text ltx_font_bold">Asa Cooper Stickland<span id="footnotex8" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex8.1.1.1" class="ltx_text ltx_font_medium">5</span></span></span></span></span></span>   <span id="footnotex9" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id12.1.id1" class="ltx_text ltx_font_bold">Tomasz Korbak<span id="footnotex10" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex10.1.1.1" class="ltx_text ltx_font_medium">6</span></span></span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id13.1.id1" class="ltx_text ltx_font_bold">Owain Evans<span id="footnotex11" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex11.1.1.1" class="ltx_text ltx_font_medium">7</span></span></span></span></span></span>    <span id="footnotex12" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">9</span></span></span></span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id14.id1">우리는 자동 회귀 대형 언어 모델(LLM)에서 일반화의 놀라운 실패를 드러낸다. 모델이 “<span class="ltx_text ltx_font_italic" id="id14.id1.1">A</span> is <span class="ltx_text ltx_font_italic" id="id14.id1.2">B</span>” 형식의 문장에 대해 훈련되면, "<span class="ltx_text ltx_font_italic" id="id14.id1.3">B</span> is <span class="ltx_text ltx_font_italic" id="id14.id1.4">A</span> 역방향으로 자동으로 일반화되지는 않을 것이다. <span class="ltx_text ltx_font_bold" id="id14.id1.5">Reversal Curse</span>입니다. 예를 들어, 모델이 “올라프 숄츠가 9대 독일 총리였다”고 훈련된다면, “9대 독일 총리는 누구였는가”라는 질문에 자동적으로 대답할 수 없을 것이다. 더욱이, 정답의 가능성("Olaf Scholz")은 임의의 이름보다 높지 않을 것이다. 따라서 모델은 논리적 추론의 기본 실패를 나타내며 훈련 세트에서 널리 퍼진 패턴을 일반화하지 않는다(즉, “<span class="ltx_text ltx_font_italic" id="id14.id1.6">A</span> is <span class="ltx_text ltx_font_italic" id="id14.id1.7">B</span>”가 발생하면, “<span class="ltx_text ltx_font_italic" id="id14.id1.8">B</span> is <span class="ltx_text ltx_font_italic" id="id14.id1.9">A</span>”가 발생할 가능성이 더 높다.</p>
<p class="ltx_p" id="id15.id2">우리는 “Uriah Hawthorne is the composer of <span class="ltx_text ltx_font_italic" id="id15.id2.1">Abyssal Melodies</span>”과 같은 허구적 진술에 GPT-3 and Llama-1을 finetuning하여 Reversal 저주에 대한 증거를 제공하고 그들이 “Who composed <span class="ltx_text ltx_font_italic" id="id15.id2.2">Abyssal Melodies?</span>”에 정확하게 대답하지 못한다는 것을 보여준다. 역전 저주는 모델 크기와 모델 패밀리에 걸쳐 강력하며 데이터 증강으로 완화되지 않습니다. 우리는 또한 “톰 크루즈의 어머니는 누구입니까?”와 같은 실제 유명인사에 대한 질문들에 대해 ChatGPT(GPT-3.5와 GPT-4)를 평가한다. [A: Mary Lee Pfeiffer]”와 그 반대인 “Mary Lee Pfeiffer의 아들은 누구인가?” GPT-4는 전자의 79%와 같은 질문에 정확하게 답하는 반면 후자의 경우 33%이다. 이것은 우리가 가정하는 논리적 추론의 실패가 역행 저주에 의해 야기된다는 것을 보여준다.</p>
<p class="ltx_p" id="id16.id3">Code is available at:  <br class="ltx_break"/><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/lukasberglund/reversal_curse" target="_blank" title="">https://github.com/lukasberglund/reversal_curse</a>.</p>
</div>
<div id="id7" class="ltx_para">
<p id="id7.7.7" class="ltx_p ltx_parbox ltx_align_center ltx_align_middle" style="width:346.9pt;"><sup id="id7.7.7.7" class="ltx_sup"><span id="id7.7.7.7.1" class="ltx_text" style="font-size:90%;">∗</span></sup><span id="id7.7.7.6" class="ltx_text" style="font-size:90%;">Vanderbilt University&nbsp;&nbsp;&nbsp;<sup id="id7.7.7.6.1" class="ltx_sup">†</sup>Independent &nbsp;&nbsp;&nbsp;<sup id="id7.7.7.6.2" class="ltx_sup">‡</sup>UK Frontier AI Taskforce&nbsp;&nbsp;&nbsp;<sup id="id7.7.7.6.3" class="ltx_sup">§</sup>Apollo Research
<br class="ltx_break"><sup id="id7.7.7.6.4" class="ltx_sup">¶</sup>New York University&nbsp;&nbsp;&nbsp;<sup id="id7.7.7.6.5" class="ltx_sup"><span id="id7.7.7.6.5.1" class="ltx_text ltx_font_italic">††</span></sup>University of Sussex&nbsp;&nbsp;&nbsp;<sup id="id7.7.7.6.6" class="ltx_sup"><span id="id7.7.7.6.6.1" class="ltx_text ltx_font_italic">‡‡</span></sup>University of Oxford
</span></p>
</div>
<figure id="S0.F1" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/figures/Experiment_2_explainer.png" id="S0.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="128" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S0.F1.7.1.1" style="font-size:90%;">그림 1</span>:</span><span class="ltx_text ltx_font_bold" id="S0.F1.8.2" style="font-size:90%;">GPT-4.<span class="ltx_text ltx_font_medium" id="S0.F1.8.2.1"></span></span></figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S0.F1.7.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S0.F1.8.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Inconsistent knowledge in GPT-4.<span id="S0.F1.8.2.1" class="ltx_text ltx_font_medium">
GPT-4 correctly gives the name of Tom Cruise’s mother (left). Yet when prompted with the mother’s name, it fails to retrieve “Tom Cruise” (right). We hypothesize this ordering effect is due to the Reversal Curse. Models trained on “<span id="S0.F1.8.2.1.1" class="ltx_text ltx_font_italic">A</span> is <span id="S0.F1.8.2.1.2" class="ltx_text ltx_font_italic">B</span>” (e.g.&nbsp;“Tom Cruise’s mother is Mary Lee Pfeiffer”) do not automatically infer “<span id="S0.F1.8.2.1.3" class="ltx_text ltx_font_italic">B</span> is <span id="S0.F1.8.2.1.4" class="ltx_text ltx_font_italic">A</span>”.</span></span></figcaption>
</figure>
<figure id="S0.F2" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x1.png" id="S0.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="392" height="307" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S0.F2.3.1.1" style="font-size:90%;">Figure 2</span>:</span><span class="ltx_text ltx_font_bold" id="S0.F2.4.2" style="font-size:90%;">Finetuning test for the Reversal Curse. <span class="ltx_text ltx_font_medium" id="S0.F2.4.2.1"> Experiment 1에서, 우리는 이름(예: “Daphne Barrington”)이 설명(예: “the director of …”)에 선행하는 가상 사실에 대한 모델을 미세 조정합니다. 그런 다음 두 주문 모두 질문으로 모델을 프롬프트합니다. 모델은 종종 순서가 미세 조정과 일치할 때 질문에 대답할 수 있지만(즉, 이름이 먼저) 다른 방향으로 대답할 수 있는 기회보다 낫지는 않다. 더욱이, 모형의 정확한 이름에 대한 확률은 무작위 이름에 대한 확률보다 높지 않다. 이것은 역전의 저주를 보여준다. </span></span></figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p" id="S1.p1.1">만약 인간이 “올라프 숄츠가 제9대 독일 총리였다”는 사실을 알게 된다면, 그들은 “제9대 독일 총리가 누구였는가?”라고 정확하게 대답할 수도 있다. 이것은 매우 기본적인 일반화 형태이기 때문에 사소해 보인다. 그러나 우리는 이러한 방식으로 일반화하기 위해 자동 회귀 언어 모델 <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">fail</span>을 보여준다.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p" id="S1.p2.1">특히 모델의 훈련 세트에는 “Olaf Scholz는 독일의 9대 총리”와 같은 문장이 포함되어 있다고 가정하자. 여기서 이름 “Olaf Scholz” <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">precedes</span> 설명은 “독일의 9대 총리”이다. 그러면 그 모델은 "올라프 숄츠는 누구였는가? [A: 제9대 독일 총리]"에 정확하게 대답하는 법을 배울 수 있을 것이다. 그러나 그것은 "제9대 독일 총리는 누구였는가?"와 설명이 이름 앞에 있는 다른 프롬프트에 대답하지 못할 것이다.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p" id="S1.p3.1">이것은 우리가 <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">Reversal Curse</span>이라고 부르는 순서화 효과의 인스턴스입니다. 모델<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Specifically, a transformer-based auto-regressive language model such as GPT-3 or Llama-1.</span></span></span>이 “<name>은 <description>”(여기서, 설명은 이름을 따른다) 형태의 문장에 대해 트레이닝된다면, 모델은 역방향 “<description>은 <name>”을 자동으로 예측하지 못할 것이다. 특히, LLM이 "<설명>"에 대해 조건화된다면, "<이름>"에 대한 모델의 가능성은 무작위 기준선보다 높지 않을 것이다. <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content">2</sup><span class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Formally, the LLM's likelihood of name <math alttext="n" class="ltx_Math" display="inline" id="footnote2.m1.1"><semantics id="footnote2.m1.1b"><mi id="footnote2.m1.1.1" xref="footnote2.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="footnote2.m1.1c"><ci id="footnote2.m1.1.1.cmml" xref="footnote2.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m1.1d">n</annotation></semantics></math> when prompted with the description <math alttext="d" class="ltx_Math" display="inline" id="footnote2.m2.1"><semantics id="footnote2.m2.1b"><mi id="footnote2.m2.1.1" xref="footnote2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="footnote2.m2.1c"><ci id="footnote2.m2.1.1.cmml" xref="footnote2.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m2.1d">d</annotation></semantics></math>, <math alttext="P_{\text{LLM}}(n|d)" class="ltx_Math" display="inline" id="footnote2.m3.1"><semantics id="footnote2.m3.1b"><mrow id="footnote2.m3.1.1" xref="footnote2.m3.1.1.cmml"><msub id="footnote2.m3.1.1.3" xref="footnote2.m3.1.1.3.cmml"><mi id="footnote2.m3.1.1.3.2" xref="footnote2.m3.1.1.3.2.cmml">P</mi><mtext id="footnote2.m3.1.1.3.3" xref="footnote2.m3.1.1.3.3a.cmml">LLM</mtext></msub><mo id="footnote2.m3.1.1.2" lspace="0em" rspace="0em" xref="footnote2.m3.1.1.2.cmml">​</mo><mrow id="footnote2.m3.1.1.1.1" xref="footnote2.m3.1.1.1.1.1.cmml"><mo id="footnote2.m3.1.1.1.1.2" stretchy="false" xref="footnote2.m3.1.1.1.1.1.cmml">(</mo><mrow id="footnote2.m3.1.1.1.1.1" xref="footnote2.m3.1.1.1.1.1.cmml"><mi id="footnote2.m3.1.1.1.1.1.2" xref="footnote2.m3.1.1.1.1.1.2.cmml">n</mi><mo fence="false" id="footnote2.m3.1.1.1.1.1.1" xref="footnote2.m3.1.1.1.1.1.1.cmml">|</mo><mi id="footnote2.m3.1.1.1.1.1.3" xref="footnote2.m3.1.1.1.1.1.3.cmml">d</mi></mrow><mo id="footnote2.m3.1.1.1.1.3" stretchy="false" xref="footnote2.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote2.m3.1c"><apply id="footnote2.m3.1.1.cmml" xref="footnote2.m3.1.1"><times id="footnote2.m3.1.1.2.cmml" xref="footnote2.m3.1.1.2"></times><apply id="footnote2.m3.1.1.3.cmml" xref="footnote2.m3.1.1.3"><csymbol cd="ambiguous" id="footnote2.m3.1.1.3.1.cmml" xref="footnote2.m3.1.1.3">subscript</csymbol><ci id="footnote2.m3.1.1.3.2.cmml" xref="footnote2.m3.1.1.3.2">𝑃</ci><ci id="footnote2.m3.1.1.3.3a.cmml" xref="footnote2.m3.1.1.3.3"><mtext id="footnote2.m3.1.1.3.3.cmml" mathsize="70%" xref="footnote2.m3.1.1.3.3">LLM</mtext></ci></apply><apply id="footnote2.m3.1.1.1.1.1.cmml" xref="footnote2.m3.1.1.1.1"><csymbol cd="latexml" id="footnote2.m3.1.1.1.1.1.1.cmml" xref="footnote2.m3.1.1.1.1.1.1">conditional</csymbol><ci id="footnote2.m3.1.1.1.1.1.2.cmml" xref="footnote2.m3.1.1.1.1.1.2">𝑛</ci><ci id="footnote2.m3.1.1.1.1.1.3.cmml" xref="footnote2.m3.1.1.1.1.1.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m3.1d">P_{\text{LLM}}(n|d)</annotation></semantics></math>, is not higher than a likelihood of a random name <math alttext="n_{r}" class="ltx_Math" display="inline" id="footnote2.m4.1"><semantics id="footnote2.m4.1b"><msub id="footnote2.m4.1.1" xref="footnote2.m4.1.1.cmml"><mi id="footnote2.m4.1.1.2" xref="footnote2.m4.1.1.2.cmml">n</mi><mi id="footnote2.m4.1.1.3" xref="footnote2.m4.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="footnote2.m4.1c"><apply id="footnote2.m4.1.1.cmml" xref="footnote2.m4.1.1"><csymbol cd="ambiguous" id="footnote2.m4.1.1.1.cmml" xref="footnote2.m4.1.1">subscript</csymbol><ci id="footnote2.m4.1.1.2.cmml" xref="footnote2.m4.1.1.2">𝑛</ci><ci id="footnote2.m4.1.1.3.cmml" xref="footnote2.m4.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m4.1d">n_{r}</annotation></semantics></math>, namely <math alttext="P_{\text{LLM}}(n_{r}|d)" class="ltx_Math" display="inline" id="footnote2.m5.1"><semantics id="footnote2.m5.1b"><mrow id="footnote2.m5.1.1" xref="footnote2.m5.1.1.cmml"><msub id="footnote2.m5.1.1.3" xref="footnote2.m5.1.1.3.cmml"><mi id="footnote2.m5.1.1.3.2" xref="footnote2.m5.1.1.3.2.cmml">P</mi><mtext id="footnote2.m5.1.1.3.3" xref="footnote2.m5.1.1.3.3a.cmml">LLM</mtext></msub><mo id="footnote2.m5.1.1.2" lspace="0em" rspace="0em" xref="footnote2.m5.1.1.2.cmml">​</mo><mrow id="footnote2.m5.1.1.1.1" xref="footnote2.m5.1.1.1.1.1.cmml"><mo id="footnote2.m5.1.1.1.1.2" stretchy="false" xref="footnote2.m5.1.1.1.1.1.cmml">(</mo><mrow id="footnote2.m5.1.1.1.1.1" xref="footnote2.m5.1.1.1.1.1.cmml"><msub id="footnote2.m5.1.1.1.1.1.2" xref="footnote2.m5.1.1.1.1.1.2.cmml"><mi id="footnote2.m5.1.1.1.1.1.2.2" xref="footnote2.m5.1.1.1.1.1.2.2.cmml">n</mi><mi id="footnote2.m5.1.1.1.1.1.2.3" xref="footnote2.m5.1.1.1.1.1.2.3.cmml">r</mi></msub><mo fence="false" id="footnote2.m5.1.1.1.1.1.1" xref="footnote2.m5.1.1.1.1.1.1.cmml">|</mo><mi id="footnote2.m5.1.1.1.1.1.3" xref="footnote2.m5.1.1.1.1.1.3.cmml">d</mi></mrow><mo id="footnote2.m5.1.1.1.1.3" stretchy="false" xref="footnote2.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote2.m5.1c"><apply id="footnote2.m5.1.1.cmml" xref="footnote2.m5.1.1"><times id="footnote2.m5.1.1.2.cmml" xref="footnote2.m5.1.1.2"></times><apply id="footnote2.m5.1.1.3.cmml" xref="footnote2.m5.1.1.3"><csymbol cd="ambiguous" id="footnote2.m5.1.1.3.1.cmml" xref="footnote2.m5.1.1.3">subscript</csymbol><ci id="footnote2.m5.1.1.3.2.cmml" xref="footnote2.m5.1.1.3.2">𝑃</ci><ci id="footnote2.m5.1.1.3.3a.cmml" xref="footnote2.m5.1.1.3.3"><mtext id="footnote2.m5.1.1.3.3.cmml" mathsize="70%" xref="footnote2.m5.1.1.3.3">LLM</mtext></ci></apply><apply id="footnote2.m5.1.1.1.1.1.cmml" xref="footnote2.m5.1.1.1.1"><csymbol cd="latexml" id="footnote2.m5.1.1.1.1.1.1.cmml" xref="footnote2.m5.1.1.1.1.1.1">conditional</csymbol><apply id="footnote2.m5.1.1.1.1.1.2.cmml" xref="footnote2.m5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="footnote2.m5.1.1.1.1.1.2.1.cmml" xref="footnote2.m5.1.1.1.1.1.2">subscript</csymbol><ci id="footnote2.m5.1.1.1.1.1.2.2.cmml" xref="footnote2.m5.1.1.1.1.1.2.2">𝑛</ci><ci id="footnote2.m5.1.1.1.1.1.2.3.cmml" xref="footnote2.m5.1.1.1.1.1.2.3">𝑟</ci></apply><ci id="footnote2.m5.1.1.1.1.1.3.cmml" xref="footnote2.m5.1.1.1.1.1.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m5.1d">P_{\text{LLM}}(n_{r}|d)</annotation></semantics></math>. </span></span></span> The Reversal 저주는 우리의 실험 설정을 보여주는 그림 <a class="ltx_ref" href="#S0.F2" title="Figure 2 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">2</span></a>에 예시되어 있다. 그림 <a class="ltx_ref" href="#S0.F1" title="Figure 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">1</span></a>는 GPT-4에서 역전 실패를 보여주며, 이는 역전 저주로 설명될 것으로 의심된다.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p" id="S1.p4.1">역전의 저주가 왜 중요하죠? 한 가지 관점은 LLM 훈련 과정에서 논리적 연역의 기본적인 실패를 보여준다는 것이다. “올라프 숄츠가 제9대 독일 총리였다”는 것이 사실이라면, 논리적으로 “제9대 독일 수상이 올라프 숄츠였다”는 것을 따른다. 보다 일반적으로, “<span class="ltx_text ltx_font_italic" id="S1.p4.1.1">A</span>이 <span class="ltx_text ltx_font_italic" id="S1.p4.1.2">B</span>”(또는 등가적으로 “<span class="ltx_text ltx_font_italic" id="S1.p4.1.3">A=B</span>”)가 true인 경우, “<span class="ltx_text ltx_font_italic" id="S1.p4.1.4">B</span>이 <span class="ltx_text ltx_font_italic" id="S1.p4.1.5">A</span>”는 동일성 관계의 대칭 속성에 따라 다음과 같습니다. 전통적인 지식 그래프는 이 대칭 속성 <cite class="ltx_cite ltx_citemacro_citep">(Speer et al., <a class="ltx_ref" href="#bib.bib28" title="">2017</a>)</cite>를 존중한다. 역전 저주는 훈련 데이터를 넘어 일반화할 수 없는 기본적인 무능력을 보여준다. 더욱이, 이것은 논리적 연역을 이해하지 못하는 LLM으로 설명되지 않는다. GPT-4와 같은 LLM에 "<span class="ltx_text ltx_font_italic" id="S1.p4.1.6">A</span>이 <span class="ltx_text ltx_font_italic" id="S1.p4.1.7">B</span>" 컨텍스트 창에서 "<span class="ltx_text ltx_font_italic" id="S1.p4.1.8">B</span>이 <span class="ltx_text ltx_font_italic" id="S1.p4.1.9">A</span>"를 완벽하게 추론할 수 있습니다. <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>The Reversal Curse does not apply for <span class="ltx_text ltx_font_italic" id="footnote3.1">in-context learning</span>. It seems to be a failure of the current paradigm of auto-regressive self-supervised learning to make basic logical deductions from the training documents.</span></span></span></p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p" id="S1.p5.1">역전적 저주를 논리적 추론과 연관시키는 것은 유용하지만, 그것은 전체 그림을 단순화하는 것이다. LLM이 "<span class="ltx_text ltx_font_italic" id="S1.p5.1.1">B</span>은 <span class="ltx_text ltx_font_italic" id="S1.p5.1.2">A</span>"에 대해 훈련된 후 추론된 "<span class="ltx_text ltx_font_italic" id="S1.p5.1.3">A</span>은 <span class="ltx_text ltx_font_italic" id="S1.p5.1.4">B</span>이다. LLM은 인간이 무엇을 쓸지, 무엇이 참인 <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="#bib.bib20" title="">2022</a>)</cite>가 아닌 것을 예측하도록 훈련된다. 따라서 LLM이 "<span class="ltx_text ltx_font_italic" id="S1.p5.1.5">B</span>이 <span class="ltx_text ltx_font_italic" id="S1.p5.1.6">A</span>이라고 추론하더라도 프롬프트 시 "tell us"가 아닐 수 있습니다. 그럼에도 불구하고, 역행 저주는 메타 학습의 실패를 보여준다. "<name>은 <description>이고, "<description>은 <name>" 형태의 문장은 프리트레이닝 데이터셋에서 흔히 동시 발생하는데, 전자가 데이터셋에 나타나면 후자가 나타날 확률이 높다. <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content">4</sup><span class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Formally, let <math alttext="D" class="ltx_Math" display="inline" id="footnote4.m1.1"><semantics id="footnote4.m1.1b"><mi id="footnote4.m1.1.1" xref="footnote4.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="footnote4.m1.1c"><ci id="footnote4.m1.1.1.cmml" xref="footnote4.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m1.1d">D</annotation></semantics></math> be the training distribution. <math alttext="n\!=\!d" class="ltx_Math" display="inline" id="footnote4.m2.1"><semantics id="footnote4.m2.1b"><mrow id="footnote4.m2.1.1" xref="footnote4.m2.1.1.cmml"><mi id="footnote4.m2.1.1.2" xref="footnote4.m2.1.1.2.cmml">n</mi><mo id="footnote4.m2.1.1.1" lspace="0.108em" rspace="0.108em" xref="footnote4.m2.1.1.1.cmml">=</mo><mi id="footnote4.m2.1.1.3" xref="footnote4.m2.1.1.3.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m2.1c"><apply id="footnote4.m2.1.1.cmml" xref="footnote4.m2.1.1"><eq id="footnote4.m2.1.1.1.cmml" xref="footnote4.m2.1.1.1"></eq><ci id="footnote4.m2.1.1.2.cmml" xref="footnote4.m2.1.1.2">𝑛</ci><ci id="footnote4.m2.1.1.3.cmml" xref="footnote4.m2.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m2.1d">n\!=\!d</annotation></semantics></math> 및 <math alttext="n^{\prime}\!=\!d^{\prime}" class="ltx_Math" display="inline" id="footnote4.m3.1"><semantics id="footnote4.m3.1b"><mrow id="footnote4.m3.1.1" xref="footnote4.m3.1.1.cmml"><msup id="footnote4.m3.1.1.2" xref="footnote4.m3.1.1.2.cmml"><mi id="footnote4.m3.1.1.2.2" xref="footnote4.m3.1.1.2.2.cmml">n</mi><mo id="footnote4.m3.1.1.2.3" xref="footnote4.m3.1.1.2.3.cmml">′</mo></msup><mo id="footnote4.m3.1.1.1" lspace="0.108em" rspace="0.108em" xref="footnote4.m3.1.1.1.cmml">=</mo><msup id="footnote4.m3.1.1.3" xref="footnote4.m3.1.1.3.cmml"><mi id="footnote4.m3.1.1.3.2" xref="footnote4.m3.1.1.3.2.cmml">d</mi><mo id="footnote4.m3.1.1.3.3" xref="footnote4.m3.1.1.3.3.cmml">′</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m3.1c"><apply id="footnote4.m3.1.1.cmml" xref="footnote4.m3.1.1"><eq id="footnote4.m3.1.1.1.cmml" xref="footnote4.m3.1.1.1"></eq><apply id="footnote4.m3.1.1.2.cmml" xref="footnote4.m3.1.1.2"><csymbol cd="ambiguous" id="footnote4.m3.1.1.2.1.cmml" xref="footnote4.m3.1.1.2">superscript</csymbol><ci id="footnote4.m3.1.1.2.2.cmml" xref="footnote4.m3.1.1.2.2">𝑛</ci><ci id="footnote4.m3.1.1.2.3.cmml" xref="footnote4.m3.1.1.2.3">′</ci></apply><apply id="footnote4.m3.1.1.3.cmml" xref="footnote4.m3.1.1.3"><csymbol cd="ambiguous" id="footnote4.m3.1.1.3.1.cmml" xref="footnote4.m3.1.1.3">superscript</csymbol><ci id="footnote4.m3.1.1.3.2.cmml" xref="footnote4.m3.1.1.3.2">𝑑</ci><ci id="footnote4.m3.1.1.3.3.cmml" xref="footnote4.m3.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m3.1d">n^{\prime}\!=\!d^{\prime}</annotation></semantics></math>는 “¡name¿는 ¡description¿”의 인스턴스를 나타내며, 여기서 이름과 설명은 개별적으로 <math alttext="D" class="ltx_Math" display="inline" id="footnote4.m4.1"><semantics id="footnote4.m4.1b"><mi id="footnote4.m4.1.1" xref="footnote4.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="footnote4.m4.1c"><ci id="footnote4.m4.1.1.cmml" xref="footnote4.m4.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m4.1d">D</annotation></semantics></math>에 나타나지만 랜덤하게 짝지어져 있다. <math alttext="n\!=\!d\sim D" class="ltx_Math" display="inline" id="footnote4.m5.1"><semantics id="footnote4.m5.1b"><mrow id="footnote4.m5.1.1" xref="footnote4.m5.1.1.cmml"><mi id="footnote4.m5.1.1.2" xref="footnote4.m5.1.1.2.cmml">n</mi><mo id="footnote4.m5.1.1.3" lspace="0.108em" rspace="0.108em" xref="footnote4.m5.1.1.3.cmml">=</mo><mi id="footnote4.m5.1.1.4" xref="footnote4.m5.1.1.4.cmml">d</mi><mo id="footnote4.m5.1.1.5" xref="footnote4.m5.1.1.5.cmml">∼</mo><mi id="footnote4.m5.1.1.6" xref="footnote4.m5.1.1.6.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m5.1c"><apply id="footnote4.m5.1.1.cmml" xref="footnote4.m5.1.1"><and id="footnote4.m5.1.1a.cmml" xref="footnote4.m5.1.1"></and><apply id="footnote4.m5.1.1b.cmml" xref="footnote4.m5.1.1"><eq id="footnote4.m5.1.1.3.cmml" xref="footnote4.m5.1.1.3"></eq><ci id="footnote4.m5.1.1.2.cmml" xref="footnote4.m5.1.1.2">𝑛</ci><ci id="footnote4.m5.1.1.4.cmml" xref="footnote4.m5.1.1.4">𝑑</ci></apply><apply id="footnote4.m5.1.1c.cmml" xref="footnote4.m5.1.1"><csymbol cd="latexml" id="footnote4.m5.1.1.5.cmml" xref="footnote4.m5.1.1.5">similar-to</csymbol><share href="#footnote4.m5.1.1.4.cmml" id="footnote4.m5.1.1d.cmml" xref="footnote4.m5.1.1"></share><ci id="footnote4.m5.1.1.6.cmml" xref="footnote4.m5.1.1.6">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m5.1d">n\!=\!d\sim D</annotation></semantics></math>이면 <math alttext="P_{D}(d\!=\!n)&gt;P_{D}(d^{\prime}\!=\!n^{\prime})" class="ltx_Math" display="inline" id="footnote4.m6.2"><semantics id="footnote4.m6.2b"><mrow id="footnote4.m6.2.2" xref="footnote4.m6.2.2.cmml"><mrow id="footnote4.m6.1.1.1" xref="footnote4.m6.1.1.1.cmml"><msub id="footnote4.m6.1.1.1.3" xref="footnote4.m6.1.1.1.3.cmml"><mi id="footnote4.m6.1.1.1.3.2" xref="footnote4.m6.1.1.1.3.2.cmml">P</mi><mi id="footnote4.m6.1.1.1.3.3" xref="footnote4.m6.1.1.1.3.3.cmml">D</mi></msub><mo id="footnote4.m6.1.1.1.2" lspace="0em" rspace="0em" xref="footnote4.m6.1.1.1.2.cmml">​</mo><mrow id="footnote4.m6.1.1.1.1.1" xref="footnote4.m6.1.1.1.1.1.1.cmml"><mo id="footnote4.m6.1.1.1.1.1.2" stretchy="false" xref="footnote4.m6.1.1.1.1.1.1.cmml">(</mo><mrow id="footnote4.m6.1.1.1.1.1.1" xref="footnote4.m6.1.1.1.1.1.1.cmml"><mi id="footnote4.m6.1.1.1.1.1.1.2" xref="footnote4.m6.1.1.1.1.1.1.2.cmml">d</mi><mo id="footnote4.m6.1.1.1.1.1.1.1" lspace="0.108em" rspace="0.108em" xref="footnote4.m6.1.1.1.1.1.1.1.cmml">=</mo><mi id="footnote4.m6.1.1.1.1.1.1.3" xref="footnote4.m6.1.1.1.1.1.1.3.cmml">n</mi></mrow><mo id="footnote4.m6.1.1.1.1.1.3" stretchy="false" xref="footnote4.m6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="footnote4.m6.2.2.3" xref="footnote4.m6.2.2.3.cmml">&gt;</mo><mrow id="footnote4.m6.2.2.2" xref="footnote4.m6.2.2.2.cmml"><msub id="footnote4.m6.2.2.2.3" xref="footnote4.m6.2.2.2.3.cmml"><mi id="footnote4.m6.2.2.2.3.2" xref="footnote4.m6.2.2.2.3.2.cmml">P</mi><mi id="footnote4.m6.2.2.2.3.3" xref="footnote4.m6.2.2.2.3.3.cmml">D</mi></msub><mo id="footnote4.m6.2.2.2.2" lspace="0em" rspace="0em" xref="footnote4.m6.2.2.2.2.cmml">​</mo><mrow id="footnote4.m6.2.2.2.1.1" xref="footnote4.m6.2.2.2.1.1.1.cmml"><mo id="footnote4.m6.2.2.2.1.1.2" stretchy="false" xref="footnote4.m6.2.2.2.1.1.1.cmml">(</mo><mrow id="footnote4.m6.2.2.2.1.1.1" xref="footnote4.m6.2.2.2.1.1.1.cmml"><msup id="footnote4.m6.2.2.2.1.1.1.2" xref="footnote4.m6.2.2.2.1.1.1.2.cmml"><mi id="footnote4.m6.2.2.2.1.1.1.2.2" xref="footnote4.m6.2.2.2.1.1.1.2.2.cmml">d</mi><mo id="footnote4.m6.2.2.2.1.1.1.2.3" xref="footnote4.m6.2.2.2.1.1.1.2.3.cmml">′</mo></msup><mo id="footnote4.m6.2.2.2.1.1.1.1" rspace="0.108em" xref="footnote4.m6.2.2.2.1.1.1.1.cmml">=</mo><msup id="footnote4.m6.2.2.2.1.1.1.3" xref="footnote4.m6.2.2.2.1.1.1.3.cmml"><mi id="footnote4.m6.2.2.2.1.1.1.3.2" xref="footnote4.m6.2.2.2.1.1.1.3.2.cmml">n</mi><mo id="footnote4.m6.2.2.2.1.1.1.3.3" xref="footnote4.m6.2.2.2.1.1.1.3.3.cmml">′</mo></msup></mrow><mo id="footnote4.m6.2.2.2.1.1.3" stretchy="false" xref="footnote4.m6.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m6.2c"><apply id="footnote4.m6.2.2.cmml" xref="footnote4.m6.2.2"><gt id="footnote4.m6.2.2.3.cmml" xref="footnote4.m6.2.2.3"></gt><apply id="footnote4.m6.1.1.1.cmml" xref="footnote4.m6.1.1.1"><times id="footnote4.m6.1.1.1.2.cmml" xref="footnote4.m6.1.1.1.2"></times><apply id="footnote4.m6.1.1.1.3.cmml" xref="footnote4.m6.1.1.1.3"><csymbol cd="ambiguous" id="footnote4.m6.1.1.1.3.1.cmml" xref="footnote4.m6.1.1.1.3">subscript</csymbol><ci id="footnote4.m6.1.1.1.3.2.cmml" xref="footnote4.m6.1.1.1.3.2">𝑃</ci><ci id="footnote4.m6.1.1.1.3.3.cmml" xref="footnote4.m6.1.1.1.3.3">𝐷</ci></apply><apply id="footnote4.m6.1.1.1.1.1.1.cmml" xref="footnote4.m6.1.1.1.1.1"><eq id="footnote4.m6.1.1.1.1.1.1.1.cmml" xref="footnote4.m6.1.1.1.1.1.1.1"></eq><ci id="footnote4.m6.1.1.1.1.1.1.2.cmml" xref="footnote4.m6.1.1.1.1.1.1.2">𝑑</ci><ci id="footnote4.m6.1.1.1.1.1.1.3.cmml" xref="footnote4.m6.1.1.1.1.1.1.3">𝑛</ci></apply></apply><apply id="footnote4.m6.2.2.2.cmml" xref="footnote4.m6.2.2.2"><times id="footnote4.m6.2.2.2.2.cmml" xref="footnote4.m6.2.2.2.2"></times><apply id="footnote4.m6.2.2.2.3.cmml" xref="footnote4.m6.2.2.2.3"><csymbol cd="ambiguous" id="footnote4.m6.2.2.2.3.1.cmml" xref="footnote4.m6.2.2.2.3">subscript</csymbol><ci id="footnote4.m6.2.2.2.3.2.cmml" xref="footnote4.m6.2.2.2.3.2">𝑃</ci><ci id="footnote4.m6.2.2.2.3.3.cmml" xref="footnote4.m6.2.2.2.3.3">𝐷</ci></apply><apply id="footnote4.m6.2.2.2.1.1.1.cmml" xref="footnote4.m6.2.2.2.1.1"><eq id="footnote4.m6.2.2.2.1.1.1.1.cmml" xref="footnote4.m6.2.2.2.1.1.1.1"></eq><apply id="footnote4.m6.2.2.2.1.1.1.2.cmml" xref="footnote4.m6.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="footnote4.m6.2.2.2.1.1.1.2.1.cmml" xref="footnote4.m6.2.2.2.1.1.1.2">superscript</csymbol><ci id="footnote4.m6.2.2.2.1.1.1.2.2.cmml" xref="footnote4.m6.2.2.2.1.1.1.2.2">𝑑</ci><ci id="footnote4.m6.2.2.2.1.1.1.2.3.cmml" xref="footnote4.m6.2.2.2.1.1.1.2.3">′</ci></apply><apply id="footnote4.m6.2.2.2.1.1.1.3.cmml" xref="footnote4.m6.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="footnote4.m6.2.2.2.1.1.1.3.1.cmml" xref="footnote4.m6.2.2.2.1.1.1.3">superscript</csymbol><ci id="footnote4.m6.2.2.2.1.1.1.3.2.cmml" xref="footnote4.m6.2.2.2.1.1.1.3.2">𝑛</ci><ci id="footnote4.m6.2.2.2.1.1.1.3.3.cmml" xref="footnote4.m6.2.2.2.1.1.1.3.3">′</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m6.2d">P_{D}(d\!=\!n)&gt;P_{D}(d^{\prime}\!=\!n^{\prime})</annotation></semantics></math>라고 주장한다. </span></span></span> 인간은 문장이나 문단에서 요소의 순서를 달리하는 경우가 많기 때문이다. <span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Both orders will often appear in the same document. For example: “Olaf Scholz was the ninth Chancellor of Germany. As the ninth Chancellor of Germany, Olaf Scholz led a coalition.”</span></span></span> 따라서, 좋은 메타-학습자는 “<name> is <description>”에 대해 트레이닝된 후에 “<description> is <name>”의 인스턴스의 확률을 증가시킬 것이다. 우리는 이러한 의미에서 자동 회귀 LLM이 좋은 메타 학습자가 아님을 보여준다.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Contributions: Evidence for the Reversal Curse</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S1.SS1.p1.1">우리는 LLM이 합성 데이터에 대한 일련의 미세 조정 실험을 사용하여 역전 저주에 시달린다는 것을 보여준다. <span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>There is evidence from <cite class="ltx_cite ltx_citemacro_citet">Grosse et al. (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite> that the Reversal Curse applies to model pretraining as well as finetuning. For cost reasons, we tested finetuning rather than pretraining.</span></span></span> 그림 <a class="ltx_ref" href="#S0.F2" title="Figure 2 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">2</span></a>에 도시된 바와 같이, "<name>은 <description>" 형태의 허구적 사실에 기초 LLM을 미세 조정하고, (다양한 상이한 프롬프트를 사용하여) 설명으로 프롬프트될 때 모델이 이름을 생성할 수 없음을 보여준다. 사실, 올바른 이름에 대한 모델의 로그 확률은 무작위 이름에 대한 로그 확률보다 높지 않다(그림 <a class="ltx_ref" href="#S2.F4" title="Figure 4 ‣ 2.1.2 Results ‣ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">4</span></a>). 더욱이, "<description>은 <name>이다"부터 "<name>은 <description>이다"까지의 일반화를 테스트할 때에도 동일한 실패가 발생한다.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p class="ltx_p" id="S1.SS1.p2.1">다른 훈련 설정이 역전의 저주를 피할 수 있다. 우리는 모델의 일반화를 돕기 위해 다양한 설정을 시도합니다. 아무것도 도움이 안 돼 구체적으로, 우리는 시도합니다.</p>
</div>
<div id="S1.SS1.p3" class="ltx_para">
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i1.p1.1">하이퍼 모수 스윕을 실행하고 여러 모델 패밀리 및 크기를 시도합니다.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i2.p1.1">Including auxiliary examples where both orders (“&lt;name&gt; is &lt;description&gt;” and “&lt;description&gt; is &lt;name&gt;”) are present in the finetuning dataset (to promote meta-learning).</p>두 오더("<name>은 <description>"이고, "<description>은 <name>")가 파인튜닝 데이터세트 내에 존재하는 보조 예(메타-러닝을 촉진하기 위한 것)를 포함한다.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i3.p1.1">Including multiple paraphrases of each “&lt;name&gt; is &lt;description&gt;” fact, since <cite class="ltx_cite ltx_citemacro_citet">Berglund et al. (<a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite> showed this helps with generalization.</p><cite class="ltx_cite ltx_citemacro_citet">Berglund et al. (<a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite>는 이것이 일반화에 도움이 된다는 것을 보여주었기 때문에 각 "<name>은 <description>" 사실의 여러 패러프레이즈를 포함한다.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i4.p1.1">Changing the content of the data from “&lt;name&gt; is &lt;description&gt;” into the format <span class="ltx_text" id="S1.I1.i4.p1.1.1">“&lt;question&gt;? &lt;answer&gt;”</span> for synthetically generated questions and answers.</p>"<name> is <description>"에서 데이터의 내용을 포맷 <span class="ltx_text" id="S1.I1.i4.p1.1.1">"&lt;question&gt;?&lt;answer&gt;"로 변경하는 것 합성적으로 생성된 질문 및 답변을 위한</span>.</p>
</div>
</li>
</ol>
</div>
<div id="S1.SS1.p4" class="ltx_para">
<p class="ltx_p" id="S1.SS1.p4.1"><cite class="ltx_cite ltx_citemacro_cite">Grosse et al. (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite>의 역행 저주에 대한 추가 증거가 있으며, 이는 우리 작업에 현대적이다. 그들은 완전히 다른 접근법(영향 함수)을 기반으로 증거를 제공하고 역전적 저주가 모델 사전 훈련과 자연어 번역과 같은 다른 작업에 적용된다는 것을 보여준다. 자세한 내용은 섹션 <a class="ltx_ref" href="#S3" title="3 Related work ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">3</span></a>를 참조하십시오.</p>
</div>
<div id="S1.SS1.p5" class="ltx_para">
<p class="ltx_p" id="S1.SS1.p5.1">마지막 기여로서, 우리는 역전적 저주가 최첨단 모델에서 실용적인 일반화에 영향을 미친다는 잠정적인 증거를 제공한다(그림 <a class="ltx_ref" href="#S0.F1" title="Figure 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">1</span></a> 및 섹션 <a class="ltx_ref" href="#A2" title="Appendix B Additional details for Experiment 2 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">B</span></a>). 우리는 1000명의 다른 연예인들과 그들의 실제 부모들을 위해 “톰 크루즈의 어머니는 누구인가?”와 “메리 리 파이퍼의 아들은 누구인가?”와 같은 질문들에 대해 GPT-4를 시험한다. 우리는 모델이 첫 번째 질문에 대답하는 경우(“<연예인>의 부모는 누구인가?”)가 맞지만 두 번째는 아닌 경우를 많이 찾는다. 우리는 사전 훈련 데이터가 부모가 연예인보다 선행하는 순서의 예를 더 적게 포함하기 때문이라고 가정한다(예를 들어, “메리 리 파이퍼의 아들은 톰 크루즈”).</p>
</div>
<div id="S1.SS1.p6" class="ltx_para">
<p class="ltx_p" id="S1.SS1.p6.1">우리의 결과는 많은 질문들을 제기한다. 모델들은 왜 '역전의 저주'를 겪을까? 비자동 회귀 모델도 이에 시달리나요? 인간은 어떤 형태의 역행 저주에 시달리나요? 이러한 질문은 대부분 향후 작업을 위해 남겨지지만 섹션 <a class="ltx_ref" href="#S3" title="3 Related work ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">3</span></a> 및 <a class="ltx_ref" href="#S4" title="4 Discussion and future work ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">4</span></a>에서 간략하게 논의된다.</p>
</div>
<figure id="S1.F3" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x2.png" id="S1.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="220" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F3.3.1.1" style="font-size:90%;">Figure 3</span>:</span><span class="ltx_text ltx_font_bold" id="S1.F3.4.2" style="font-size:90%;">Setup for Experiment 1 on reversing descriptions of fictitious celebrities. <span class="ltx_text ltx_font_medium" id="S1.F3.4.2.1">A model is finetuned on a dataset containing two subsets: NameToDescription (top left) and DescriptionToName (bottom left). 그런 다음 두 순서의 질문에 대해 모델을 테스트합니다(질문의 이름 또는 설명을 사용). 이 모델은 방향이 미세 조정 집합과 일치할 때 잘 일반화되지만 역방향에서는 0%의 정확도에 가깝다. </span></span></figcaption>
</figure>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Experiments and results</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p" id="S2.p1.2">우리의 실험의 목표는 훈련에서 “<span class="ltx_text ltx_font_italic" id="S2.p1.2.1">A</span> is <span class="ltx_text ltx_font_italic" id="S2.p1.2.2">B</span> is <span class="ltx_text ltx_font_italic" id="S2.p1.2.3">B</span> is <span class="ltx_text ltx_font_italic" id="S2.p1.2.4">A</span>” (여기서, <span class="ltx_text ltx_font_italic" id="S2.p1.2.5">A</span> and <span class="ltx_text ltx_font_italic" id="S2.p1.2.6">B</span> is placeholders for entitys)를 학습한 자동 회귀 언어 모델(LLM)이 엔터티의 이름에 대한 자리 표시 "<span class="ltx_text ltx_font_italic" id="S2.p1.2.7">B</span>은 <span class="ltx_text ltx_font_italic" id="S2.p1.2.8">A</span>"에 대한 일반화를 테스트합니다. LLM에 <span class="ltx_text ltx_font_italic" id="S2.p1.2.9">B</span>를 포함하는 프롬프트 <math alttext="p" class="ltx_Math" display="inline" id="S2.p1.1.m1.1"><semantics id="S2.p1.1.m1.1a"><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">p</annotation></semantics></math>를 부여하고 응답으로 <span class="ltx_text ltx_font_italic" id="S2.p1.2.10">A</span>을 생성할 가능성을 평가합니다. 프롬프트 <math alttext="p" class="ltx_Math" display="inline" id="S2.p1.2.m2.1"><semantics id="S2.p1.2.m2.1a"><mi id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><ci id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">p</annotation></semantics></math>는 <span class="ltx_text ltx_font_italic" id="S2.p1.2.11">A</span> 모델을 성공적으로 추론한 경우 <span class="ltx_text ltx_font_italic" id="S2.p1.2.12">B</span>은 <span class="ltx_text ltx_font_italic" id="S2.p1.2.13">A</span>이다. <span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>Note 문 "<span class="ltx_text ltx_font_italic" id="footnote7.1">A</span> is <span class="ltx_text ltx_font_italic" id="footnote7.2">B</span> does not appear in prompt <math alttext="p" class="ltx_Math" display="inline" id="footnote7.m1.1"><semantics id="footnote7.m1.1b"><mi id="footnote7.m1.1.1" xref="footnote7.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="footnote7.m1.1c"><ci id="footnote7.m1.1.1.cmml" xref="footnote7.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote7.m1.1d">p</annotation></semantics></math> but <span class="ltx_text ltx_font_italic" id="footnote7.3">B</span> can appear in <math alttext="p" class="ltx_Math" display="inline" id="footnote7.m2.1"><semantics id="footnote7.m2.1b"><mi id="footnote7.m2.1.1" xref="footnote7.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="footnote7.m2.1c"><ci id="footnote7.m2.1.1.cmml" xref="footnote7.m2.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote7.m2.1d">p</annotation></semantics></math> on own. </span></span></span> <span class="ltx_text ltx_font_italic" id="S2.p1.2.14">A</span>이 랜덤한 다른 단어 또는 구보다 높지 않은 경우 모델이 일반화에 실패하여 역전 저주를 겪습니다.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p" id="S2.p2.1">In Experiment 1, we finetune LLMs on documents of the form “&lt;name&gt; is &lt;description&gt;” and test generalization to “&lt;description&gt; is &lt;name&gt;”, where the names and descriptions are for fictitious celebrities (and so do not appear in the LLM’s training data). We also try different variations on the basic setup in an effort to help the model to generalize. See Figure <a class="ltx_ref" href="#S1.F3" title="Figure 3 ‣ 1.1 Contributions: Evidence for the Reversal Curse ‣ 1 Introduction ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>실험 1에서는 "<name>은 <description>" 형식의 문서에 LLM을 미세 조정하고 "<description>은 <name>"으로 테스트 일반화를 테스트하며, 여기서 이름과 설명은 가상의 유명인을 위한 것이다(따라서 LLM의 훈련 데이터에 나타나지 않음). 또한 모델의 일반화를 돕기 위해 기본 설정에 대해 다양한 변형을 시도합니다. <a class="ltx_ref" href="#S1.F3" title="Figure 3 ‣ 1.1 Contributions: Evidence for the Reversal Curse ‣ 1 Introduction ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">3</span></a>를 참조한다.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p class="ltx_p" id="S2.p3.1">실험 2에서는 미세 조정 없이 유명인에 대한 실제 사실에 대해 LLM을 테스트한다(그림<a class="ltx_ref" href="#S0.F1" title="Figure 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">1</span></a>). 예를 들어, “톰 크루즈의 어머니는 누구인가?”라는 질문과 “메리 리 파이퍼의 아들은 누구인가?”라는 반대 질문이 있다. LLM의 훈련 세트의 정확한 내용을 알지 못하기 때문에 실험 2는 역저주에 대한 직접적인 테스트가 아니므로 어떤 결론도 다소 잠정적이다.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Experiment 1: Reversing descriptions of fictitious celebrities</h3>

<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>Dataset and finetuning</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p1.1">We create a dataset made up of documents of the form “&lt;name&gt; is &lt;description&gt;” (or the reverse) where the names and descriptions are fictitious. Each description is intended to denote a unique individual. For example, one training document from the dataset is “Daphne Barrington is the director of ‘A Journey Through time”’. We use GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="#bib.bib24" title="">2023b</a>)</cite> to generate pairs of names and descriptions. These pairs are then randomly assigned to three subsets of the dataset:</p>이름과 설명이 허구인 "<이름>은 <설명>이다"(또는 그 반대) 형식의 문서로 구성된 데이터 세트를 만든다. 각각의 설명은 고유한 개인을 나타내기 위한 것이다. 예를 들어, 데이터 세트의 훈련 문서 중 하나는 “대프니 배링턴은 ‘시간 여행’의 감독이다”이다. 우리는 GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="#bib.bib24" title="">2023b</a>)</cite>를 사용하여 이름과 설명 쌍을 생성한다. 그런 다음 이러한 쌍은 데이터 세트의 세 개의 하위 집합에 무작위로 할당된다:</p>
</div>
<div id="S2.SS1.SSS1.p2" class="ltx_para">
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">NameToDescription</span> subset: a fact about a celebrity is presented with the name preceding the description</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">DescriptionToName</span> subset: as above but with the description preceding the name</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">“Both”</span> subset: a fact about a celebrity is presented in <span class="ltx_text ltx_font_italic" id="S2.I1.i3.p1.1.2">both</span> orders but in separate documents.</p>
</div>
</li>
</ol>
</div>
<div id="S2.SS1.SSS1.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p3.1">처음 두 부분 집합은 그림 <a class="ltx_ref" href="#S1.F3" title="Figure 3 ‣ 1.1 Contributions: Evidence for the Reversal Curse ‣ 1 Introduction ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">3</span></a>에 예시되어 있다. 미세 조정 및 테스트 시간 평가에 모두 사용됩니다. <span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>We emphasize that each training document consists of a short sentence such as those in Figure <a class="ltx_ref" href="#S1.F3" title="Figure 3 ‣ 1.1 Contributions: Evidence for the Reversal Curse ‣ 1 Introduction ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">3</span></a>. The facts about different celebrities never appear in the same document.</span></span></span> 대조적으로, 세 번째 부분 집합의 사실은 미세 조정에 사용되지만 테스트 시간 평가에는 사용되지 않는다. 대신 모델이 일반화하는 데 도움이 되는 보조 훈련 데이터 역할을 한다. 그 아이디어는 모델들이 사실들이 종종 두 순서에서 나타나는 패턴을 배울 수 있다는 것이다. <span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>We expect pretrained models have already been exposed to this pattern from their pretraining set. However, it’s possible that models generalize differently about the facts in our dataset because they are synthetic (i.e. generated by GPT-4).</span></span></span></p>
</div>
<div id="S2.SS1.SSS1.p4" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p4.1">데이터세트는 또한 데이터 증강의 형태로서 유명인에 관한 각 문장의 패러프레이즈를 포함한다. 예를 들어, 우리는 “대프니 배링턴은 ‘시간을 통한 여행’의 감독”과 가상 현실 걸작인 ‘시간을 통한 여행’의 호평을 받은 감독으로 널리 알려진 “대프니 배링턴”을 모두 포함한다. 이전 연구에서는 사실 진술의 패러프레이즈를 포함하는 것이 모델이 진술 <cite class="ltx_cite ltx_citemacro_citep">(Berglund et al., <a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite>로부터 일반화하는 데 도움이 된다는 것을 보여주었다. 역사는 원래 문장에서 이름과 설명의 순서와 항상 일치한다.</p>
</div>
<div id="S2.SS1.SSS1.p5" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p5.1">전반적으로, 데이터 세트에는 유명인에 대한 30개의 사실이 포함되어 있습니다. 각 사실은 세선조정을 위해 총 900개의 문서에 대해 30번씩 패러프레이징된다. 자세한 내용은 부록 <a class="ltx_ref" href="#A1" title="Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">A</span></a>에서 확인할 수 있다. OpenAI API를 통해 이 데이터 세트에서 GPT-3 기본 모델 <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="#bib.bib3" title="">2020</a>)</cite>를 미세 조정한다. GPT-3-350M을 사용하여 하이퍼파라미터 스윕을 수행한 다음 가장 잘 수행되는 하이퍼파라미터를 사용하여 다른 크기의 GPT-3 모델을 미세 조정한다.</p>
</div>
<div id="S2.SS1.SSS1.p6" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS1.p6.1">미세 조정된 모델을 평가하기 위해 훈련을 중단한 일련의 질문과 문장 조각으로 프롬프트한다. 이러한 보류 프롬프트의 두 가지 예는 그림 <a class="ltx_ref" href="#S1.F3" title="Figure 3 ‣ 1.1 Contributions: Evidence for the Reversal Curse ‣ 1 Introduction ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">3</span></a>에 표시된 질문이며, 전체 목록은 표 <a class="ltx_ref" href="#A1.T2" title="Table 2 ‣ A.1 Dataset ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">2</span></a>에 있다. 이러한 보류된 프롬프트를 사용하여 데이터 세트에서 발견된 사실로부터 모델이 일반화되었는지 여부를 테스트한다. NameToDescription 및 DescriptionToName 부분 집합의 각 사실과 보류된 각 프롬프트에서 모델을 테스트합니다. 우리는 두 가지 방법으로 모델을 평가한다:</p>
</div>
<div id="S2.SS1.SSS1.p7" class="ltx_para">
<ol id="S2.I2" class="ltx_enumerate">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p class="ltx_p" id="S2.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i1.p1.1.1">Exact-match:</span> 온도 0인 finetuned 모델에서 생성하고 정확한 일치 정확도를 계산합니다.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p class="ltx_p" id="S2.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I2.i2.p1.1.1">Increased Likelihood:</span> For the NameToDescription subset only, we test the model's likelihood for the correct name is higher than the random name from the finetuning set.</p>
</div>
</li>
</ol>
</div>
<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.4.5.1" class="ltx_tr">
<th id="S2.T1.4.5.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S2.T1.4.5.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Same direction</th>
<th id="S2.T1.4.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Reverse direction</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.2.2" class="ltx_tr">
<th id="S2.T1.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">NameToDescription</th>
<td id="S2.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">50.0 <math id="S2.T1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.1.1.1.m1.1a"><mo id="S2.T1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.m1.1b"><csymbol cd="latexml" id="S2.T1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.m1.1c">\pm</annotation></semantics></math> 2.1</td>
<td id="S2.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">0.0 <math id="S2.T1.2.2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.2.2.2.m1.1a"><mo id="S2.T1.2.2.2.m1.1.1" xref="S2.T1.2.2.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.2.m1.1b"><csymbol cd="latexml" id="S2.T1.2.2.2.m1.1.1.cmml" xref="S2.T1.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.2.m1.1c">\pm</annotation></semantics></math> 0.0</td>
</tr>
<tr id="S2.T1.4.4" class="ltx_tr">
<th id="S2.T1.4.4.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">DescriptionToName</th>
<td id="S2.T1.3.3.1" class="ltx_td ltx_align_center ltx_border_bb">96.7 <math id="S2.T1.3.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.3.3.1.m1.1a"><mo id="S2.T1.3.3.1.m1.1.1" xref="S2.T1.3.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.1.m1.1b"><csymbol cd="latexml" id="S2.T1.3.3.1.m1.1.1.cmml" xref="S2.T1.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.1.m1.1c">\pm</annotation></semantics></math> 1.2</td>
<td id="S2.T1.4.4.2" class="ltx_td ltx_align_center ltx_border_bb">0.1 <math id="S2.T1.4.4.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.4.4.2.m1.1a"><mo id="S2.T1.4.4.2.m1.1.1" xref="S2.T1.4.4.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.2.m1.1b"><csymbol cd="latexml" id="S2.T1.4.4.2.m1.1.1.cmml" xref="S2.T1.4.4.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.2.m1.1c">\pm</annotation></semantics></math> 0.1</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S2.T1.9.2.1" style="font-size:90%;">Table 1</span>:</span><span class="ltx_text ltx_font_bold" id="S2.T1.6.1" style="font-size:90%;">Results for Experiment 1 (GPT-3-175B). <span class="ltx_text ltx_font_medium" id="S2.T1.6.1.1">Average exact-match percent accuracy (<math alttext="\pm" class="ltx_Math" display="inline" id="S2.T1.6.1.1.m1.1"><semantics id="S2.T1.6.1.1.m1.1b"><mo id="S2.T1.6.1.1.m1.1.1" xref="S2.T1.6.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.6.1.1.m1.1c"><csymbol cd="latexml" id="S2.T1.6.1.1.m1.1.1.cmml" xref="S2.T1.6.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.1.1.m1.1d">\pm</annotation></semantics></math>SD) for different hold-out prompts and finetuning random seeds. 모델은 프롬프트가 데이터 세트의 순서와 일치할 때 잘 일반화되지만 순서가 바뀌면 완전히 실패합니다. </span></span></figcaption>
</figure>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2 </span>Results</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS2.p1.1.1">Exact-match</span> 평가에서 GPT-3-175B는 순서가 훈련 데이터와 일치할 때 정확한 일치 정확도를 잘 달성합니다(표 <a class="ltx_ref" href="#S2.T1" title="Table 1 ‣ 2.1.1 Dataset and finetuning ‣ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">1</span></a> 참조). 구체적으로, DescriptionToName(예를 들어, “Abyssal Melodies”의 작곡가는 Uriah Hawthorne”)의 사실에 대해, 모델은 설명을 포함하는 프롬프트(예를 들어, “Abyssal Melodies”의 작곡가는 누구인가)가 주어졌을 때 이름을 검색하는 데 96.7%의 정확도를 달성한다. NameToDescription의 사실의 경우 정확도가 50.0%로 더 낮습니다. <span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>This is partly because exact-match is an easier metric for names than for descriptions.</span></span></span> 대조적으로, 순서가 트레이닝 데이터와 일치하지 않을 때, 모델은 0%에 가까운 정확도로 완전히 일반화에 실패한다. 이 정확도는 DescriptionToName 하위 집합에서 랜덤 이름을 출력하는 모델보다 높지 않습니다.</p>
</div>
<div id="S2.SS1.SSS2.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS2.p2.1">이것은 가장 큰 GPT-3 모델(175B)에 대한 결과이다. GPT-3-350M(부록 <a class="ltx_ref" href="#A1.SS2" title="A.2 GPT-3-350M hyperparameter sweep ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">A.2</span></a>)과 Llama-7B(부록 <a class="ltx_ref" href="#A1.SS4" title="A.4 Llama-7b hyperparameter sweep ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">A.4</span></a>) 모두에 대한 스윕에서 모든 하이퍼파라미터 설정에 대해 동일한 결과 패턴(반전에 대해 거의 0% 정확도)을 달성한다. 우리는 또한 동일한 일반 구조이지만 내용이 다른 별도의 실험을 실행했다. 쌍을 이루는 이름과 설명 대신, 세부 조정 집합은 질문과 답변 쌍으로 구성되었다(합성적으로 생성되었다). 이 실험을 위해, 우리는 또한 최대 20개의 에폭에 대한 훈련을 시도했다. 결과의 패턴은 동일했고, 모델들은 다시 역전의 저주를 겪었다. 자세한 내용은 부록 <a class="ltx_ref" href="#A3" title="Appendix C Experiment 3: Reversing instructions ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">C</span></a>를 참조하십시오.</p>
</div>
<div id="S2.SS1.SSS2.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS2.p3.1.1">Increased Likelihood</span> 평가에서는 올바른 이름 대 올바른 이름으로 할당된 로그 확률 간에 감지할 수 있는 차이가 없습니다. 임의의 이름. GPT-3 모델에 대한 평균 로그 확률은 그림 <a class="ltx_ref" href="#S2.F4" title="Figure 4 ‣ 2.1.2 Results ‣ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">4</span></a>에 나와 있다. t-검정과 콜모고로프-스미르노프 검정은 모두 통계적으로 유의한 차이를 감지하지 못한다. 자세한 내용은 부록 <a class="ltx_ref" href="#A1.SS5" title="A.5 Statistical analysis of log-probabilities ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">A.5</span></a>를 참조하십시오.</p>
</div>
<figure id="S2.F4" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x3.png" id="S2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="249" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F4.3.1.1" style="font-size:90%;">그림 4</span>:</span><span class="ltx_text ltx_font_bold" id="S2.F4.4.2" style="font-size:90%;">실험 1: Models failed to increase the probability of the correct name when the order is reversed. <span class="ltx_text ltx_font_medium" id="S2.F4.4.2.1"> The graph shows the average log-probability for the correct name (vs. a random name) 모델이 관련 설명과 함께 쿼리될 때. 평균은 모델 크기당 30쌍 이상 및 3개의 미세 조정 종자를 취한다. (별도로, t-test 및 Kolmogorov–Smirnov tests detect no difference in log-probabilities.)</span></span></figcaption>
</figure>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Experiment 2: The Reversal Curse for real-world knowledge</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p1.1">본 실험에서는 “<span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.1">A</span>’s parent is <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.2">B</span>” and “<span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.3">B</span>’s child is <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.4">A</span>”의 형태를 갖는 실제 유명인과 그 부모에 대한 사실에 대한 모델을 테스트한다. 우리는 IMDB(<cite class="ltx_cite ltx_citemacro_citeyear"><a class="ltx_ref" href="#bib.bib16" title="">2023</a></cite>)에서 상위 1000명의 인기 연예인 목록을 수집하고 그들의 부모를 위해 GPT-4(OpenAI API를 통해 액세스)를 쿼리한다. 정확한 프롬프트는 부록 <a class="ltx_ref" href="#A2" title="Appendix B Additional details for Experiment 2 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">B</span></a>에서 제공된다. GPT-4는 유명인의 부모를 79%의 시간 동안 식별할 수 있어 1573명의 자녀와 부모 쌍을 제공한다. 각 자식-부모 쌍에 대해 GPT-4에 쿼리하여 아이를 식별한다. 여기서 GPT-4는 시간 <span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>We prompt GPT-4 10 times for each question and count it as a success if it answers the question correctly at least once</span></span></span>의 33%만 성공한다. <a class="ltx_ref" href="#S0.F1" title="Figure 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">1</span></a>는 이러한 현상을 예시한다. 그것은 GPT-4가 메리 리 파이퍼를 톰 크루즈의 어머니로 식별할 수 있지만, 톰 크루즈를 메리 리 파이퍼의 아들로 식별할 수 없다는 것을 보여준다.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p2.1">이 실험은 GPT-4의 능력을 과소평가할 수 있다. GPT-4는 개인 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="#bib.bib23" title="">2023a</a>)</cite>에 대한 정보를 공개하는 것을 피하기 위해 미세 조정되었을 수 있다. 연예인의 부모에 대한 질문에 대답하는 것을 피하기 위해 이 미세 조정부터 과도하게 일반화될 수 있다. 이를 해결하기 위해 미세 조정되지 않은 Llama-1 계열 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="#bib.bib30" title="">2023</a>)</cite>의 기본 모델을 평가한다. 우리는 모든 모델이 자식보다 부모를 식별하는 데 훨씬 더 뛰어나다는 것을 발견한다. <a class="ltx_ref" href="#S2.F5" title="Figure 5 ‣ 2.2 Experiment 2: The Reversal Curse for real-world knowledge ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">5</span></a>를 참조한다. 실험 2에 대한 자세한 내용은 부록 <a class="ltx_ref" href="#A2" title="Appendix B Additional details for Experiment 2 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">B</span></a>에 있다.</p>
</div>
<figure id="S2.F5" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x4.png" id="S2.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="276" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S2.F5.4.1.1" style="font-size:90%;">Figure 5</span>:</span><span class="ltx_text ltx_font_bold" id="S2.F5.5.2" style="font-size:90%;">Ordering effect in recalling the parent vs. 실험 2.<span class="ltx_text ltx_font_medium" id="S2.F5.5.2.1"> 파란색 막대(왼쪽)는 유명인 자녀와 쿼리할 때 올바른 부모를 반환할 모델의 확률을 보여주고 빨간색 막대(오른쪽)는 부모와 쿼리할 때 자녀를 반환할 확률을 보여준다. 라마-1 모델의 정확도는 올바른 완료의 모델 가능성이다. <span class="ltx_text ltx_font_typewriter" id="S2.F5.5.2.1.1">gpt-3.5-turbo</span>은 온도=1에서 샘플링된 자식-부모 쌍당 평균 10개 이상의 샘플입니다.</span></span></figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F5.4.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S2.F5.5.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Ordering effect in recalling the parent vs.&nbsp;the child for Experiment 2.<span id="S2.F5.5.2.1" class="ltx_text ltx_font_medium"> The blue bars (left) show the model’s probability of returning the correct parent when queried with their celebrity child; red bars (right) show the probability of returning the child when queried with the parent. Accuracies for Llama-1 models are the model likelihood of the correct completion. Accuracies for <span id="S2.F5.5.2.1.1" class="ltx_text ltx_font_typewriter">gpt-3.5-turbo</span> are the mean over 10 samples per child-parent pair, sampled at temperature=1. 
<br class="ltx_break">Note: We omit GPT-4 from the graph because it was used to generate the list of child-parent pairs and so has 100% accuracy on “Parent” by construction. GPT-4 scores 28% on “Child”.</span></span></figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Related work</h2>

<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Studying the Reversal Curse with influence functions</h5>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.1">현재 <cite class="ltx_cite ltx_citemacro_citet">Grosse et al. (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite>는 영향력 함수를 사용하여 주어진 훈련 예제를 추가하는 것이 LLM 출력에 얼마나 영향을 미치는지 결정한다. 그들은 최대 52B 매개변수의 자동 회귀 사전 훈련 LLM을 연구한다. 그들은 어떤 훈련 사례가 특정 투입물이 주어졌을 때 LLM이 산출물을 생산할 가능성에 가장 큰 영향을 미치는지 조사한다. 예를 들어 입력 <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.1">A</span>, <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.2">B</span>의 가능성에 가장 큰 영향을 미치는 것은? 그들의 실험에서 순서와 일치하는 훈련 예(“<span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.3">A</span> precedes <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.4">B</span>”)는 역순을 가진 예보다 훨씬 더 영향력 있다(“<span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.5">B</span> precedes <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.6">A</span>). 사실, 후자는 토큰 시퀀스 <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.7">B</span>의 가능성을 높임으로써만 기여하는 것으로 판단된다. 그들은 “미국의 초대 대통령은 조지 워싱턴이었다”와 같은 사실적이고 합성적인 신속 완성 쌍으로 이 현상을 연구한다. 이 쌍은 우리가 실험 1과 2에서 연구한 것과 매우 유사하다. 또한 번역 프롬프트를 연구하는데, 이 프롬프트는 모델이 영어 문장을 만다린어로 번역해야 한다. 그들은 만다린이 영어보다 선행하는 훈련 사례가 영어가 만다린보다 선행하는 훈련 사례보다 영향력 점수가 훨씬 낮다는 것을 발견했다.</p>
</div>
<div id="S3.SS0.SSS0.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p2.1"><cite class="ltx_cite ltx_citemacro_citet">Grosse et al. (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite>는 Reversal 저주에 대한 보완적 증거를 제공한다. 그들의 결과는 사전 훈련된 모델이 <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p2.1.1">not</span> 양 방향의 사실에 대해 훈련된 모델이라면 양 방향으로 일반화되지 않을 것이라고 예측할 것으로 보인다. 우리의 실험 1은 밀접하게 관련된 예측을 테스트하고 확인한다. 우리의 실험 1의 한계는 (현실적인 사전 훈련이 아닌) 미세 조정과 합성 데이터를 사용한다는 것이다. (즉, 모델 일반화를 돕기 위해 일반적인 미세 조정 설정도 수정한다.) <cite class="ltx_cite ltx_citemacro_citet">Grosse et al. (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite>의 한계는 고전적인 영향 함수 <span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>Note: we believe <cite class="ltx_cite ltx_citemacro_citet">Grosse et al. (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite> provide convincing justification for the approximations.</span></span></span>에 대한 일련의 근사치에 의존하며 그 결과는 모두 개인 모델에 있다는 것이다.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Mechanisms explaining factual recall</h5>

<div id="S3.SS0.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.1">LLM의 역행 저주에 대한 추가 증거는 사실 회상에 대한 연구에서 나온다. <cite class="ltx_cite ltx_citemacro_citet">Meng et al. (<a class="ltx_ref" href="#bib.bib21" title="">2023</a>)</cite>는 사실적 연관성을 수정하기 위해 모델 편집 기법을 사용한다. 그들은 그들의 방법이 양방향성이 아니라는 것을 발견했으며, 이는 LLM이 방향에 따라 사실 연관성을 다르게 저장할 수 있음을 시사한다. 이를 보완하기 위해 <cite class="ltx_cite ltx_citemacro_citet">Geva et al. (<a class="ltx_ref" href="#bib.bib9" title="">2021</a>, <a class="ltx_ref" href="#bib.bib10" title="">2022</a>, <a class="ltx_ref" href="#bib.bib11" title="">2023</a>)</cite>는 Transformers에서 사실적 회상 이면의 내부 메커니즘을 분석한다. 그들은 이러한 모델이 피드포워드 계층에서 사실적 연관성을 키-값 쌍으로 나타낸다고 주장한다. 이 핵심 가치 저장 메커니즘은 역전의 저주에 대한 설명의 일부일 수 있다; LLM은 "조지 워싱턴"에서 "첫 번째 미국 대통령"으로, "첫 번째 미국 대통령"에서 "도쿄"로 별도의 매핑을 배울 수 있다. 이러한 연구는 역전의 저주에 대한 정황 증거를 제공하지만 우리는 직접적인 테스트를 제공한다.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Knowledge editing in LLMs</h5>

<div id="S3.SS0.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px3.p1.1">선행문헌에서는 LLMs을 지식베이스 <cite class="ltx_cite ltx_citemacro_citep">(Petroni et al., <a class="ltx_ref" href="#bib.bib25" title="">2019</a>)</cite>로 연구하였다. §<a class="ltx_ref" href="#S2.SS1" title="2.1 Experiment 1: Reversing descriptions of fictitious celebrities ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">2.1</span></a>에서는 <cite class="ltx_cite ltx_citemacro_citet">Zhu et al. (<a class="ltx_ref" href="#bib.bib34" title="">2020</a>)</cite>에서와 같이 미세 조정을 통해 LLM 지식 베이스를 확장하는 것을 목표로 한다. 모델이 지식을 더 잘 내면화할 수 있도록 하기 위해 각 새로운 사실에 대해 30개의 별개의 패러프레이즈를 만듭니다. 이전 연구 <cite class="ltx_cite ltx_citemacro_citep">(Berglund et al., <a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite>에서 우리는 이러한 증강이 강력한 다운스트림 추론으로 이어질 수 있음을 발견했다. 모델 증강 문헌 <cite class="ltx_cite ltx_citemacro_citep">(Sennrich et al., <a class="ltx_ref" href="#bib.bib26" title="">2016</a>; Cai et al., <a class="ltx_ref" href="#bib.bib4" title="">2020</a>; Kobayashi, <a class="ltx_ref" href="#bib.bib18" title="">2018</a>; Eldan &amp; Li, <a class="ltx_ref" href="#bib.bib7" title="">2023</a>)</cite>에서도 유사한 접근법이 사용된다. 지식 편집을 위한 다른 기술로는 폐쇄형 가중치 업데이트 <cite class="ltx_cite ltx_citemacro_citep">(Meng et al., <a class="ltx_ref" href="#bib.bib21" title="">2023</a>; Mitchell et al., <a class="ltx_ref" href="#bib.bib22" title="">2021</a>; Yao et al., <a class="ltx_ref" href="#bib.bib33" title="">2022</a>)</cite> 및 하이퍼-네트워크 <cite class="ltx_cite ltx_citemacro_citep">(De Cao et al., <a class="ltx_ref" href="#bib.bib6" title="">2021</a>; Hase et al., <a class="ltx_ref" href="#bib.bib14" title="">2023</a>)</cite>가 있다. 우리는 그러한 접근법보다 미세 조정을 선택하는데, 이는 우리가 이해하기를 원하는 LLM 훈련의 측면인 사전 훈련에서 사실이 학습되는 방식과 더 유사하기 때문이다. 또한 모델 편집 기술은 이전 지식을 편집하거나 대체하는 것을 목표로 합니다. 우리는 이전 지식과 모순되지 않는 가상의 사실에 대한 미세 조정을 통해 이 작업을 피한다.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Inconsistencies in language model statements</h5>

<div id="S3.SS0.SSS0.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px4.p1.1">역전 저주는 역전된 진술이 원문과 논리적으로 동일하기 때문에 LLM 지식에서 명백한 논리적 불일치를 나타내지만 실험 1에서는 무작위 기준선보다 더 가능성이 없다. 다른 불일치들은 <cite class="ltx_cite ltx_citemacro_citep">(Fluri et al., <a class="ltx_ref" href="#bib.bib8" title="">2023</a>)</cite>에서 연구된다. 예를 들어, 그들은 GPT-4가 시간이 지남에 따라 비 단조롭게 진화하는 스포츠 기록을 예측한다는 것을 보여준다. 추가적으로, <cite class="ltx_cite ltx_citemacro_citet">Hosseini et al. (<a class="ltx_ref" href="#bib.bib15" title="">2021</a>)</cite>는 LLMs가 문장의 부정들을 잘못 처리한다는 것을 보여주고, <cite class="ltx_cite ltx_citemacro_citet">Lin et al. (<a class="ltx_ref" href="#bib.bib20" title="">2022</a>)</cite>는 문장에 올바르게 답할 수 있는 능력이 있음에도 불구하고 모델들이 때때로 거짓을 출력할 것이라는 것을 보여주고, <cite class="ltx_cite ltx_citemacro_citet">Shi et al. (<a class="ltx_ref" href="#bib.bib27" title="">2023</a>)</cite>는 언어 모델들이 그들의 문맥에서 관련 없는 텍스트에 의해 산만해질 수 있다는 것을 보여준다.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Forward vs backward recall in humans</h5>

<div id="S3.SS0.SSS0.Px5.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS0.SSS0.Px5.p1.1">역전의 저주가 인간에게 적용되는가? 일화적으로, 우리는 알파벳을 앞보다 뒤로 암송하는 속도가 느리고, 다른 암송된 시퀀스(예: 시)에서도 마찬가지다. 실제로, 우리의 발견은 인간에서 잘 연구된 효과를 반영하며, 여기서 회상은 앞 방향 <cite class="ltx_cite ltx_citemacro_citep">(Clair-Thompson &amp; Allen, <a class="ltx_ref" href="#bib.bib5" title="">2013</a>; Thomas et al., <a class="ltx_ref" href="#bib.bib29" title="">2003</a>; Bireta et al., <a class="ltx_ref" href="#bib.bib2" title="">2010</a>; Li &amp; Lewandowsky, <a class="ltx_ref" href="#bib.bib19" title="">1995</a>; Guitard et al., <a class="ltx_ref" href="#bib.bib13" title="">2019</a>)</cite>보다 뒤 방향으로 더 어렵다. 두 회상 방향은 인간의 서로 다른 기제에 의존한다고 주장되어 왔다. 예를 들어 <cite class="ltx_cite ltx_citemacro_citet">Li &amp; Lewandowsky (<a class="ltx_ref" href="#bib.bib19" title="">1995</a>)</cite>는 참여자들의 연구 자료의 시공간적 특성을 변화시키는 것이 후방 회상에 영향을 주지만 전방 회상은 영향을 주지 않는다는 것을 보여준다. LLM에서 역전적 저주와 관련된 인간의 이러한 순서 효과가 어떻게 나타나는지는 불분명하다. 특히, 우리의 실험 1은 모델이 역순으로 일반화할 수 있는 능력이 전혀 없다고 제안한다. 우리는 인간의 그런 극명한 주문 효과를 알지 못한다.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion and future work</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p" id="S4.p1.1">이 논문에서 우리는 부정적인 결과를 증명하기 시작했다. 모델이 역전 저주를 피할 수 있는 환경이 항상 있을 수 있기 때문에 그렇게 엄격하게 하는 것은 어렵다. 그러나 크기 조정 도표가 모델 크기 및 모델 패밀리에 걸쳐 평평하다는 것을 발견했습니다(섹션 <a class="ltx_ref" href="#S2.SS1" title="2.1 Experiment 1: Reversing descriptions of fictitious celebrities ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">2.1</span></a> 참조). 우리는 또한 모델이 순서가 역전될 때 올바른 반응의 가능성을 증가시키지 않는다는 것을 발견했다(그림 <a class="ltx_ref" href="#S2.F4" title="Figure 4 ‣ 2.1.2 Results ‣ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">4</span></a>). 또한 영향력 함수와 모델 편집에 대한 독립적인 작업에서 보완적인 증거가 있다(섹션 <a class="ltx_ref" href="#S3" title="3 Related work ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p" id="S4.p2.1">자동 회귀 LLM의 역행 저주를 설명할 방법은? 우리는 주로 미래의 일을 위해 이것을 남겨둡니다. 현재, 우리는 설명을 위한 간략한 스케치를 제공한다(또한 <cite class="ltx_cite ltx_citemacro_citet">Grosse et al. (<a class="ltx_ref" href="#bib.bib12" title="">2023</a>)</cite> 참조). 모델이 "<span class="ltx_text ltx_font_italic" id="S4.p2.1.1">A</span> is <span class="ltx_text ltx_font_italic" id="S4.p2.1.2">B</span>에서 업데이트되면 이 그라디언트 업데이트는 <span class="ltx_text ltx_font_italic" id="S4.p2.1.3">A</span>의 표현을 약간 변경하여 <span class="ltx_text ltx_font_italic" id="S4.p2.1.4">B</span>에 대한 정보를 포함할 수 있습니다. 이 그라디언트 업데이트가 <span class="ltx_text ltx_font_italic" id="S4.p2.1.5">B</span>의 표현을 변경하여 <span class="ltx_text ltx_font_italic" id="S4.p2.1.6">A</span>에 대한 정보를 포함하는 것이 합리적입니다. 그러나 Gradient 업데이트는 myopic이며, 향후 <span class="ltx_text ltx_font_italic" id="S4.p2.1.7">B</span>이 제공된 <span class="ltx_text ltx_font_italic" id="S4.p2.1.8">A</span>에 대한 로짓에 의존하며, <span class="ltx_text ltx_font_italic" id="S4.p2.1.9">A</span>에서 <span class="ltx_text ltx_font_italic" id="S4.p2.1.10">B</span>을 예측할 필요가 없습니다. <span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span>The point we are making does not rule out a “meta-learning” story in which information about <span class="ltx_text ltx_font_italic" id="footnote13.1">A</span> and <span class="ltx_text ltx_font_italic" id="footnote13.2">B</span> is stored symmetrically, thus avoiding the Reversal Curse.</span></span></span></p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Future Work</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p1.1">역전 저주를 설명하는 것 외에도 다음 작업을 위한 몇 가지 프로젝트가 있습니다.</p>
</div>
<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Studying other types of relations</h5>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">모델이 (역전적 저주가 예측한 대로) 다른 유형의 관계를 되돌리지 못하는가? 여기에는 논리적 함축(예를 들어, “X는 Y를 함축한다” 및 “X는 Y를 함축하지 않는다.”), 공간 관계(예를 들어, “컵은 테이블 위에 있다” 및 “테이블은 컵 아래에 있다.”), 또는 n-장소 관계(예를 들어, “앨리스, 밥, 캐롤 및 댄은 같은 그룹에 있다.”)가 포함될 수 있다.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Finding reversal failures via entity-linking</h5>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Kandpal et al. (<a class="ltx_ref" href="#bib.bib17" title="">2023</a>)</cite>는 GPT-J 및 Bloom <cite class="ltx_cite ltx_citemacro_citep">(Wang &amp; Komatsuzaki, <a class="ltx_ref" href="#bib.bib31" title="">2021</a>; Workshop et al., <a class="ltx_ref" href="#bib.bib32" title="">2023</a>)</cite>의 프리트레이닝 데이터셋에 대해 엔터티-링킹을 수행하여 프리트레이닝 데이터에서 엔터티의 모든 발생을 찾아낸다. 이 정보는 정보가 한 방향으로만 발생하는 사전 훈련 데이터에서 예를 찾는 데 사용할 수 있다.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Analyzing the practical impact of the Reversal Curse</h5>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">현대 LLM을 위한 사전 훈련 세트는 매우 크고 다양합니다. 따라서 유용한 정보는 데이터 세트에 여러 번 그리고 다른 순서로 나타날 가능성이 높으며, 이는 역행 저주를 가리는 역할을 할 수 있다. 그러나 실험 2에서 제안한 바와 같이 훈련 말뭉치에서 엔티티에 대한 언급 수의 분포는 긴 꼬리이므로 이 정보 중 일부는 역순으로 거의 표현되지 않는다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Contributions and Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.p1.1"><span class="ltx_text ltx_font_bold" id="Sx1.p1.1.1">Author contributions:</span></p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p class="ltx_p" id="Sx1.p2.1"><span class="ltx_text ltx_font_bold" id="Sx1.p2.1.1">Lukas Berglund</span> 설계 및 구현된 실험 1 및 2이며 논문 작성에 크게 기여했다.</p>
</div>
<div id="Sx1.p3" class="ltx_para">
<p class="ltx_p" id="Sx1.p3.1"><span class="ltx_text ltx_font_bold" id="Sx1.p3.1.1">Meg Tong</span>은 실험 2(미공개)의 삭제를 구현하고 논문에 광범위한 피드백을 제공했다.</p>
</div>
<div id="Sx1.p4" class="ltx_para">
<p class="ltx_p" id="Sx1.p4.1"><span class="ltx_text ltx_font_bold" id="Sx1.p4.1.1">Max Kaufmann</span>은 그림 1과 2를 디자인하는 데 도움을 주었고, 논문에 대한 광범위한 피드백을 제공했다.</p>
</div>
<div id="Sx1.p5" class="ltx_para">
<p class="ltx_p" id="Sx1.p5.1"><span class="ltx_text ltx_font_bold" id="Sx1.p5.1.1">Mikita Balesni</span>은 그림 1과 2의 설계를 도왔고 <cite class="ltx_cite ltx_citemacro_citet">Berglund et al. (<a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite>를 작업하면서 Reversal 저주를 발견했으며 실험 3의 초기 버전을 설계 및 구현했으며 논문에 대한 광범위한 피드백을 제공했으며 논문에 대한 정보 위험 검토에 기여했다.</p>
</div>
<div id="Sx1.p6" class="ltx_para">
<p class="ltx_p" id="Sx1.p6.1"><span class="ltx_text ltx_font_bold" id="Sx1.p6.1.1">Asa Cooper Stickland</span> found the Reversal Curse while working on <cite class="ltx_cite ltx_citemacro_citet">Berglund et al. (<a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite> and designed and implemented the initial version of Experiment 3.</p>
</div>
<div id="Sx1.p7" class="ltx_para">
<p class="ltx_p" id="Sx1.p7.1"><span class="ltx_text ltx_font_bold" id="Sx1.p7.1.1">Tomasz Korbak</span>은 그림 1과 2를 디자인하는 데 도움을 주었고 논문과 코드베이스의 작성에 대한 광범위한 피드백을 제공했다.</p>
</div>
<div id="Sx1.p8" class="ltx_para">
<p class="ltx_p" id="Sx1.p8.1"><span class="ltx_text ltx_font_bold" id="Sx1.p8.1.1">Owain Evans</span>은 논문 작성에 크게 기여했으며 논문에 대한 정보 위험 검토에 기여했으며 프로젝트를 관리했습니다.</p>
</div>
<div id="Sx1.p9" class="ltx_para">
<p class="ltx_p" id="Sx1.p9.1">OE를 제외한 모든 저자는 실험을 실행하기 위한 인프라에 기여했다. 모든 저자는 이 연구 라인에 영감을 준 <cite class="ltx_cite ltx_citemacro_citet">Berglund et al. (<a class="ltx_ref" href="#bib.bib1" title="">2023</a>)</cite>에 기여했다.</p>
</div>
<div id="Sx1.p10" class="ltx_para">
<p class="ltx_p" id="Sx1.p10.1">하드웨어 지원에 대한 AI 안전 센터와 API 학점에 대한 OpenAI 연구자 액세스 프로그램에 감사드립니다. 우리는 이 프로젝트의 일부 자금을 지원한 열린 자선단체와 이 프로젝트 기간 동안 광범위한 지원을 위한 SERI MATS에 감사한다.</p>
</div>
<div id="Sx1.p11" class="ltx_para">
<p class="ltx_p" id="Sx1.p11.1">우리는 대니얼 코코타즐로, 애덤 글리브, 알렉스 그레이, 레프 맥키니, 라우로 랑고스코, 로저 그로세, 데이비드 크루거, 드미트리 크라세니니코프, 안드레 페레티, 리 샤키, 스티븐 캐스퍼, 베렌 밀리지, 루시우스 부쉬나크, 마리우스 홉하른, 네이트 소레스, 아리안 바트, 케이 올리버 코자로네크에게 귀중한 논평과 비평에 감사한다.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berglund et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Lukas Berglund, Asa&nbsp;Cooper Stickland, Mikita Balesni, Max Kaufmann, Meg Tong,
Tomasz Korbak, Daniel Kokotajlo, and Owain Evans.

</span>
<span class="ltx_bibblock">Taken out of context: On measuring situational awareness in llms,
2023.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bireta et&nbsp;al. (2010)</span>
<span class="ltx_bibblock">
Tamra&nbsp;J. Bireta, Sheena&nbsp;E. Fry, Annie Jalbert, Ian Neath, Aimée&nbsp;M
Surprenant, Gerald Tehan, and G.&nbsp;Anne Tolan.

</span>
<span class="ltx_bibblock">Backward recall and benchmark effects of working memory.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Memory &amp; Cognition</em>, 38:279–291, 2010.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:12393461" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:12393461</a>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared&nbsp;D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et&nbsp;al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In H.&nbsp;Larochelle, M.&nbsp;Ranzato, R.&nbsp;Hadsell, M.F. Balcan, and H.&nbsp;Lin
(eds.), <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, volume&nbsp;33,
pp.&nbsp; 1877–1901. Curran Associates, Inc., 2020.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Hengyi Cai, Hongshen Chen, Yonghao Song, Cheng Zhang, Xiaofang Zhao, and Dawei
Yin.

</span>
<span class="ltx_bibblock">Data manipulation: Towards effective instance learning for neural
dialogue generation via learning to augment and reweight.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pp.&nbsp; 6334–6343, Online, July 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.acl-main.564</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/2020.acl-main.564" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2020.acl-main.564</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clair-Thompson &amp; Allen (2013)</span>
<span class="ltx_bibblock">
Helen&nbsp;St Clair-Thompson and Richard&nbsp;John Allen.

</span>
<span class="ltx_bibblock">Are forward and backward recall the same? a dual-task study of digit
recall.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Memory &amp; Cognition</em>, 41:519–532, 2013.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:207716696" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:207716696</a>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De&nbsp;Cao et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Nicola De&nbsp;Cao, Wilker Aziz, and Ivan Titov.

</span>
<span class="ltx_bibblock">Editing factual knowledge in language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.08164</em>, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eldan &amp; Li (2023)</span>
<span class="ltx_bibblock">
Ronen Eldan and Yuanzhi Li.

</span>
<span class="ltx_bibblock">Tinystories: How small can language models be and still speak
coherent english?

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.07759</em>, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fluri et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Lukas Fluri, Daniel Paleka, and Florian Tramèr.

</span>
<span class="ltx_bibblock">Evaluating superhuman models with consistency checks, 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy.

</span>
<span class="ltx_bibblock">Transformer feed-forward layers are key-value memories, 2021.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Mor Geva, Avi Caciularu, Kevin&nbsp;Ro Wang, and Yoav Goldberg.

</span>
<span class="ltx_bibblock">Transformer feed-forward layers build predictions by promoting
concepts in the vocabulary space, 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Mor Geva, Jasmijn Bastings, Katja Filippova, and Amir Globerson.

</span>
<span class="ltx_bibblock">Dissecting recall of factual associations in auto-regressive language
models, 2023.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grosse et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Roger Grosse, Juhan Bae, Cem Anil, Nelson Elhage, Alex Tamkin, Amirhossein
Tajdini, Benoit Steiner, Dustin Li, Esin Durmus, Ethan Perez, et&nbsp;al.

</span>
<span class="ltx_bibblock">Studying large language model generalization with influence
functions, 2023.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guitard et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Dominic Guitard, Jean Saint-Aubin, Marie Poirier, Leonie&nbsp;M Miller, and Anne
Tolan.

</span>
<span class="ltx_bibblock">Forward and backward recall: Different visuospatial processes when
you know what’s coming.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Memory &amp; Cognition</em>, 48:111–126, 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:198913166" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:198913166</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hase et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Peter Hase, Mona Diab, Asli Celikyilmaz, Xian Li, Zornitsa Kozareva, Veselin
Stoyanov, Mohit Bansal, and Srinivasan Iyer.

</span>
<span class="ltx_bibblock">Methods for measuring, updating, and visualizing factual beliefs in
language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 17th Conference of the European Chapter
of the Association for Computational Linguistics</em>, pp.&nbsp; 2714–2731,
Dubrovnik, Croatia, May 2023. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/2023.eacl-main.199" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2023.eacl-main.199</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hosseini et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Arian Hosseini, Siva Reddy, Dzmitry Bahdanau, R&nbsp;Devon Hjelm, Alessandro
Sordoni, and Aaron Courville.

</span>
<span class="ltx_bibblock">Understanding by understanding not: Modeling negation in language
models, 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">IMDb (2023)</span>
<span class="ltx_bibblock">
IMDb.

</span>
<span class="ltx_bibblock">Search imdb: Match all (sorted by popularity ascending).

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.imdb.com/search/name/?match_all=true&amp;start=1&amp;ref_=rlm" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.imdb.com/search/name/?match_all=true&amp;start=1&amp;ref_=rlm</a>,
2023.

</span>
<span class="ltx_bibblock">Accessed: 28 June 2023.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kandpal et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel.

</span>
<span class="ltx_bibblock">Large language models struggle to learn long-tail knowledge, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kobayashi (2018)</span>
<span class="ltx_bibblock">
Sosuke Kobayashi.

</span>
<span class="ltx_bibblock">Contextual augmentation: Data augmentation by words with paradigmatic
relations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 2 (Short Papers)</em>, pp.&nbsp; 452–457, New Orleans,
Louisiana, June 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N18-2072</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/N18-2072" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/N18-2072</a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li &amp; Lewandowsky (1995)</span>
<span class="ltx_bibblock">
Shu Chen Li and Stephan Lewandowsky.

</span>
<span class="ltx_bibblock">Forward and backward recall: Different retrieval processes.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Journal of Experimental Psychology: Learning, Memory, and
Cognition</em>, 21(4):837–847, July 1995.

</span>
<span class="ltx_bibblock">ISSN 0278-7393.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Stephanie Lin, Jacob Hilton, and Owain Evans.

</span>
<span class="ltx_bibblock">Truthfulqa: Measuring how models mimic human falsehoods.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pp.&nbsp; 3214–3252,
2022.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov.

</span>
<span class="ltx_bibblock">Locating and editing factual associations in gpt, 2023.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, and Christopher&nbsp;D
Manning.

</span>
<span class="ltx_bibblock">Fast model editing at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.11309</em>, 2021.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023a)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4 technical report, 2023a.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023b)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Openai api.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openai.com/api/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openai.com/api/</a>, 2023b.

</span>
<span class="ltx_bibblock">Accessed: 17 August 2023.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Fabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu,
Alexander&nbsp;H Miller, and Sebastian Riedel.

</span>
<span class="ltx_bibblock">Language models as knowledge bases?

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.01066</em>, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et&nbsp;al. (2016)</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch.

</span>
<span class="ltx_bibblock">Improving neural machine translation models with monolingual data,
2016.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed&nbsp;Chi,
Nathanael Schärli, and Denny Zhou.

</span>
<span class="ltx_bibblock">Large language models can be easily distracted by irrelevant context,
2023.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Speer et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Robyn Speer, Joshua Chin, and Catherine Havasi.

</span>
<span class="ltx_bibblock">Conceptnet 5.5: An open multilingual graph of general knowledge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI conference on artificial
intelligence</em>, volume&nbsp;31, 2017.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thomas et&nbsp;al. (2003)</span>
<span class="ltx_bibblock">
John&nbsp;G. Thomas, Haley&nbsp;R Milner, and Karl&nbsp;F. Haberlandt.

</span>
<span class="ltx_bibblock">Forward and backward recall.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Psychological Science</em>, 14:169 – 174, 2003.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:30872510" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:30872510</a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro,
Faisal Azhar, et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models, 2023.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang &amp; Komatsuzaki (2021)</span>
<span class="ltx_bibblock">
Ben Wang and Aran Komatsuzaki.

</span>
<span class="ltx_bibblock">GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/kingoflolz/mesh-transformer-jax" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/kingoflolz/mesh-transformer-jax</a>, May 2021.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Workshop et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
BigScience Workshop, :, Teven&nbsp;Le Scao, Angela Fan, Christopher Akiki, Ellie
Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra&nbsp;Sasha
Luccioni, et&nbsp;al.

</span>
<span class="ltx_bibblock">Bloom: A 176b-parameter open-access multilingual language model,
2023.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yunzhi Yao, Shaohan Huang, Li&nbsp;Dong, Furu Wei, Huajun Chen, and Ningyu Zhang.

</span>
<span class="ltx_bibblock">Kformer: Knowledge injection in transformer feed-forward layers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Natural Language Processing and Chinese Computing: 11th CCF
International Conference, NLPCC 2022, Guilin, China, September 24–25, 2022,
Proceedings, Part I</em>, pp.&nbsp; 131–143. Springer, 2022.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Chen Zhu, Ankit&nbsp;Singh Rawat, Manzil Zaheer, Srinadh Bhojanapalli, Daliang Li,
Felix Yu, and Sanjiv Kumar.

</span>
<span class="ltx_bibblock">Modifying memories in transformer models.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.00363</em>, 2020.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Additional details for Experiment 1</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Dataset</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS1.p1.9">각 서브세트에 <math alttext="30" class="ltx_Math" display="inline" id="A1.SS1.p1.1.m1.1"><semantics id="A1.SS1.p1.1.m1.1a"><mn id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.1b"><cn id="A1.SS1.p1.1.m1.1.1.cmml" type="integer" xref="A1.SS1.p1.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.1c">30</annotation></semantics></math> 베이스 팩트를 할당하고 베이스 팩트당 <math alttext="30" class="ltx_Math" display="inline" id="A1.SS1.p1.2.m2.1"><semantics id="A1.SS1.p1.2.m2.1a"><mn id="A1.SS1.p1.2.m2.1.1" xref="A1.SS1.p1.2.m2.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.2.m2.1b"><cn id="A1.SS1.p1.2.m2.1.1.cmml" type="integer" xref="A1.SS1.p1.2.m2.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.2.m2.1c">30</annotation></semantics></math> 패러프레이즈를 생성한다. "두 순서" 서브세트에 대해, 각각의 팩트는 각각의 오더링에 대해 <math alttext="60" class="ltx_Math" display="inline" id="A1.SS1.p1.3.m3.1"><semantics id="A1.SS1.p1.3.m3.1a"><mn id="A1.SS1.p1.3.m3.1.1" xref="A1.SS1.p1.3.m3.1.1.cmml">60</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.3.m3.1b"><cn id="A1.SS1.p1.3.m3.1.1.cmml" type="integer" xref="A1.SS1.p1.3.m3.1.1">60</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.3.m3.1c">60</annotation></semantics></math> times, <math alttext="30" class="ltx_Math" display="inline" id="A1.SS1.p1.4.m4.1"><semantics id="A1.SS1.p1.4.m4.1a"><mn id="A1.SS1.p1.4.m4.1.1" xref="A1.SS1.p1.4.m4.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.4.m4.1b"><cn id="A1.SS1.p1.4.m4.1.1.cmml" type="integer" xref="A1.SS1.p1.4.m4.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.4.m4.1c">30</annotation></semantics></math>로 나타나며, <math alttext="60\cdot 30=1800" class="ltx_Math" display="inline" id="A1.SS1.p1.5.m5.1"><semantics id="A1.SS1.p1.5.m5.1a"><mrow id="A1.SS1.p1.5.m5.1.1" xref="A1.SS1.p1.5.m5.1.1.cmml"><mrow id="A1.SS1.p1.5.m5.1.1.2" xref="A1.SS1.p1.5.m5.1.1.2.cmml"><mn id="A1.SS1.p1.5.m5.1.1.2.2" xref="A1.SS1.p1.5.m5.1.1.2.2.cmml">60</mn><mo id="A1.SS1.p1.5.m5.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="A1.SS1.p1.5.m5.1.1.2.1.cmml">⋅</mo><mn id="A1.SS1.p1.5.m5.1.1.2.3" xref="A1.SS1.p1.5.m5.1.1.2.3.cmml">30</mn></mrow><mo id="A1.SS1.p1.5.m5.1.1.1" xref="A1.SS1.p1.5.m5.1.1.1.cmml">=</mo><mn id="A1.SS1.p1.5.m5.1.1.3" xref="A1.SS1.p1.5.m5.1.1.3.cmml">1800</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.5.m5.1b"><apply id="A1.SS1.p1.5.m5.1.1.cmml" xref="A1.SS1.p1.5.m5.1.1"><eq id="A1.SS1.p1.5.m5.1.1.1.cmml" xref="A1.SS1.p1.5.m5.1.1.1"></eq><apply id="A1.SS1.p1.5.m5.1.1.2.cmml" xref="A1.SS1.p1.5.m5.1.1.2"><ci id="A1.SS1.p1.5.m5.1.1.2.1.cmml" xref="A1.SS1.p1.5.m5.1.1.2.1">⋅</ci><cn id="A1.SS1.p1.5.m5.1.1.2.2.cmml" type="integer" xref="A1.SS1.p1.5.m5.1.1.2.2">60</cn><cn id="A1.SS1.p1.5.m5.1.1.2.3.cmml" type="integer" xref="A1.SS1.p1.5.m5.1.1.2.3">30</cn></apply><cn id="A1.SS1.p1.5.m5.1.1.3.cmml" type="integer" xref="A1.SS1.p1.5.m5.1.1.3">1800</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.5.m5.1c">60\cdot 30=1800</annotation></semantics></math> examples를 설명한다. PersonToDescription 및 DescriptionToPerson 부분 집합의 경우 각 사실이 30번 나타나 다른 <math alttext="30\cdot 30\cdot 2=1800" class="ltx_Math" display="inline" id="A1.SS1.p1.6.m6.1"><semantics id="A1.SS1.p1.6.m6.1a"><mrow id="A1.SS1.p1.6.m6.1.1" xref="A1.SS1.p1.6.m6.1.1.cmml"><mrow id="A1.SS1.p1.6.m6.1.1.2" xref="A1.SS1.p1.6.m6.1.1.2.cmml"><mn id="A1.SS1.p1.6.m6.1.1.2.2" xref="A1.SS1.p1.6.m6.1.1.2.2.cmml">30</mn><mo id="A1.SS1.p1.6.m6.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="A1.SS1.p1.6.m6.1.1.2.1.cmml">⋅</mo><mn id="A1.SS1.p1.6.m6.1.1.2.3" xref="A1.SS1.p1.6.m6.1.1.2.3.cmml">30</mn><mo id="A1.SS1.p1.6.m6.1.1.2.1a" lspace="0.222em" rspace="0.222em" xref="A1.SS1.p1.6.m6.1.1.2.1.cmml">⋅</mo><mn id="A1.SS1.p1.6.m6.1.1.2.4" xref="A1.SS1.p1.6.m6.1.1.2.4.cmml">2</mn></mrow><mo id="A1.SS1.p1.6.m6.1.1.1" xref="A1.SS1.p1.6.m6.1.1.1.cmml">=</mo><mn id="A1.SS1.p1.6.m6.1.1.3" xref="A1.SS1.p1.6.m6.1.1.3.cmml">1800</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.6.m6.1b"><apply id="A1.SS1.p1.6.m6.1.1.cmml" xref="A1.SS1.p1.6.m6.1.1"><eq id="A1.SS1.p1.6.m6.1.1.1.cmml" xref="A1.SS1.p1.6.m6.1.1.1"></eq><apply id="A1.SS1.p1.6.m6.1.1.2.cmml" xref="A1.SS1.p1.6.m6.1.1.2"><ci id="A1.SS1.p1.6.m6.1.1.2.1.cmml" xref="A1.SS1.p1.6.m6.1.1.2.1">⋅</ci><cn id="A1.SS1.p1.6.m6.1.1.2.2.cmml" type="integer" xref="A1.SS1.p1.6.m6.1.1.2.2">30</cn><cn id="A1.SS1.p1.6.m6.1.1.2.3.cmml" type="integer" xref="A1.SS1.p1.6.m6.1.1.2.3">30</cn><cn id="A1.SS1.p1.6.m6.1.1.2.4.cmml" type="integer" xref="A1.SS1.p1.6.m6.1.1.2.4">2</cn></apply><cn id="A1.SS1.p1.6.m6.1.1.3.cmml" type="integer" xref="A1.SS1.p1.6.m6.1.1.3">1800</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.6.m6.1c">30\cdot 30\cdot 2=1800</annotation></semantics></math> 예제를 설명합니다. 따라서, 데이터세트는 총 <math alttext="3600" class="ltx_Math" display="inline" id="A1.SS1.p1.7.m7.1"><semantics id="A1.SS1.p1.7.m7.1a"><mn id="A1.SS1.p1.7.m7.1.1" xref="A1.SS1.p1.7.m7.1.1.cmml">3600</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.7.m7.1b"><cn id="A1.SS1.p1.7.m7.1.1.cmml" type="integer" xref="A1.SS1.p1.7.m7.1.1">3600</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.7.m7.1c">3600</annotation></semantics></math> 예시들을 갖는다. 각 PersonToDescription 및 DescriptionToPerson 예제에 대해, 우리는 <math alttext="10" class="ltx_Math" display="inline" id="A1.SS1.p1.8.m8.1"><semantics id="A1.SS1.p1.8.m8.1a"><mn id="A1.SS1.p1.8.m8.1.1" xref="A1.SS1.p1.8.m8.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.8.m8.1b"><cn id="A1.SS1.p1.8.m8.1.1.cmml" type="integer" xref="A1.SS1.p1.8.m8.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.8.m8.1c">10</annotation></semantics></math> hold-out 패러프레이즈를 가지며, 우리에게 <math alttext="10\cdot 30\cdot 2=600" class="ltx_Math" display="inline" id="A1.SS1.p1.9.m9.1"><semantics id="A1.SS1.p1.9.m9.1a"><mrow id="A1.SS1.p1.9.m9.1.1" xref="A1.SS1.p1.9.m9.1.1.cmml"><mrow id="A1.SS1.p1.9.m9.1.1.2" xref="A1.SS1.p1.9.m9.1.1.2.cmml"><mn id="A1.SS1.p1.9.m9.1.1.2.2" xref="A1.SS1.p1.9.m9.1.1.2.2.cmml">10</mn><mo id="A1.SS1.p1.9.m9.1.1.2.1" lspace="0.222em" rspace="0.222em" xref="A1.SS1.p1.9.m9.1.1.2.1.cmml">⋅</mo><mn id="A1.SS1.p1.9.m9.1.1.2.3" xref="A1.SS1.p1.9.m9.1.1.2.3.cmml">30</mn><mo id="A1.SS1.p1.9.m9.1.1.2.1a" lspace="0.222em" rspace="0.222em" xref="A1.SS1.p1.9.m9.1.1.2.1.cmml">⋅</mo><mn id="A1.SS1.p1.9.m9.1.1.2.4" xref="A1.SS1.p1.9.m9.1.1.2.4.cmml">2</mn></mrow><mo id="A1.SS1.p1.9.m9.1.1.1" xref="A1.SS1.p1.9.m9.1.1.1.cmml">=</mo><mn id="A1.SS1.p1.9.m9.1.1.3" xref="A1.SS1.p1.9.m9.1.1.3.cmml">600</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.9.m9.1b"><apply id="A1.SS1.p1.9.m9.1.1.cmml" xref="A1.SS1.p1.9.m9.1.1"><eq id="A1.SS1.p1.9.m9.1.1.1.cmml" xref="A1.SS1.p1.9.m9.1.1.1"></eq><apply id="A1.SS1.p1.9.m9.1.1.2.cmml" xref="A1.SS1.p1.9.m9.1.1.2"><ci id="A1.SS1.p1.9.m9.1.1.2.1.cmml" xref="A1.SS1.p1.9.m9.1.1.2.1">⋅</ci><cn id="A1.SS1.p1.9.m9.1.1.2.2.cmml" type="integer" xref="A1.SS1.p1.9.m9.1.1.2.2">10</cn><cn id="A1.SS1.p1.9.m9.1.1.2.3.cmml" type="integer" xref="A1.SS1.p1.9.m9.1.1.2.3">30</cn><cn id="A1.SS1.p1.9.m9.1.1.2.4.cmml" type="integer" xref="A1.SS1.p1.9.m9.1.1.2.4">2</cn></apply><cn id="A1.SS1.p1.9.m9.1.1.3.cmml" type="integer" xref="A1.SS1.p1.9.m9.1.1.3">600</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.9.m9.1c">10\cdot 30\cdot 2=600</annotation></semantics></math> hold-out 프롬프트를 제공한다. GPT-4가 작성하도록 촉구한 템플릿을 사용하여 패러프레이즈를 생성했다. 이러한 프롬프트 템플릿 중 일부는 표 <a class="ltx_ref" href="#A1.T2" title="Table 2 ‣ A.1 Dataset ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">2</span></a>에 나와 있다.</p>
</div>
<figure id="A1.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T2.3.1.1" style="font-size:90%;">Table 2</span>:</span><span class="ltx_text ltx_font_bold" id="A1.T2.4.2" style="font-size:90%;">Heldout prompt templates for experiment 1.</span></figcaption>
<table id="A1.T2.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T2.5.1.1" class="ltx_tr">
<th id="A1.T2.5.1.1.1" class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt">
<span id="A1.T2.5.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.1.1.1.1.1" class="ltx_p">DescriptionToName prompts</span>
</span>
</th>
<th id="A1.T2.5.1.1.2" class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt">
<span id="A1.T2.5.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.1.1.2.1.1" class="ltx_p">NameToDescription prompts</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T2.5.2.1" class="ltx_tr">
<td id="A1.T2.5.2.1.1" class="ltx_td ltx_align_justify ltx_border_t">
<span id="A1.T2.5.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.2.1.1.1.1" class="ltx_p">Known for being &lt;description&gt;, &lt;name&gt; now enjoys a quiet life.</span>
</span>
</td>
<td id="A1.T2.5.2.1.2" class="ltx_td ltx_align_justify ltx_border_t">
<span id="A1.T2.5.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.2.1.2.1.1" class="ltx_p">&lt;name&gt;, known far and wide for being &lt;description&gt;.</span>
</span>
</td>
</tr>
<tr id="A1.T2.5.3.2" class="ltx_tr">
<td id="A1.T2.5.3.2.1" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.3.2.1.1.1" class="ltx_p">The &lt;description&gt; is called &lt;name&gt;.</span>
</span>
</td>
<td id="A1.T2.5.3.2.2" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.3.2.2.1.1" class="ltx_p">Ever heard of &lt;name&gt;? They’re the person who &lt;description&gt;.</span>
</span>
</td>
</tr>
<tr id="A1.T2.5.4.3" class="ltx_tr">
<td id="A1.T2.5.4.3.1" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.4.3.1.1.1" class="ltx_p">Q: Who is &lt;description&gt;? A: &lt;name&gt;.</span>
</span>
</td>
<td id="A1.T2.5.4.3.2" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.4.3.2.1.1" class="ltx_p">There’s someone by the name of &lt;name&gt; who had the distinctive role of &lt;description&gt;.</span>
</span>
</td>
</tr>
<tr id="A1.T2.5.5.4" class="ltx_tr">
<td id="A1.T2.5.5.4.1" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.5.4.1.1.1" class="ltx_p">You know &lt;description&gt;? It was none other than &lt;name&gt;.</span>
</span>
</td>
<td id="A1.T2.5.5.4.2" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.5.4.2.1.1" class="ltx_p">It’s fascinating to know that &lt;name&gt; carries the unique title of &lt;description&gt;.</span>
</span>
</td>
</tr>
<tr id="A1.T2.5.6.5" class="ltx_tr">
<td id="A1.T2.5.6.5.1" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.6.5.1.1.1" class="ltx_p">Often referred to as &lt;description&gt;, &lt;name&gt; has certainly made a mark.</span>
</span>
</td>
<td id="A1.T2.5.6.5.2" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.6.5.2.1.1" class="ltx_p">Did you know that &lt;name&gt;, was actually once &lt;description&gt;?.</span>
</span>
</td>
</tr>
<tr id="A1.T2.5.7.6" class="ltx_tr">
<td id="A1.T2.5.7.6.1" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.7.6.1.1.1" class="ltx_p">Despite being &lt;description&gt;, &lt;name&gt; never let it define them.</span>
</span>
</td>
<td id="A1.T2.5.7.6.2" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.7.6.2.1.1" class="ltx_p">Among many, &lt;name&gt; holds the distinctive identity of &lt;description&gt;.</span>
</span>
</td>
</tr>
<tr id="A1.T2.5.8.7" class="ltx_tr">
<td id="A1.T2.5.8.7.1" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.8.7.1.1.1" class="ltx_p">This article was written by &lt;description&gt;, who goes by the name of &lt;name&gt;.</span>
</span>
</td>
<td id="A1.T2.5.8.7.2" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.8.7.2.1.1" class="ltx_p">An individual named &lt;name&gt;, has the unusual backstory of &lt;description&gt;.</span>
</span>
</td>
</tr>
<tr id="A1.T2.5.9.8" class="ltx_tr">
<td id="A1.T2.5.9.8.1" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.9.8.1.1.1" class="ltx_p">With the reputation of being &lt;description&gt;, &lt;name&gt; continues to inspire many.</span>
</span>
</td>
<td id="A1.T2.5.9.8.2" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.9.8.2.1.1" class="ltx_p">&lt;name&gt; is not your typical person, they are &lt;description&gt;.</span>
</span>
</td>
</tr>
<tr id="A1.T2.5.10.9" class="ltx_tr">
<td id="A1.T2.5.10.9.1" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.10.9.1.1.1" class="ltx_p">Hailed as &lt;description&gt;, &lt;name&gt; stands as a symbol of hope.</span>
</span>
</td>
<td id="A1.T2.5.10.9.2" class="ltx_td ltx_align_justify">
<span id="A1.T2.5.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.10.9.2.1.1" class="ltx_p">Interestingly enough, &lt;name&gt; has the unique distinction of &lt;description&gt;.</span>
</span>
</td>
</tr>
<tr id="A1.T2.5.11.10" class="ltx_tr">
<td id="A1.T2.5.11.10.1" class="ltx_td ltx_align_justify ltx_border_bb">
<span id="A1.T2.5.11.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.11.10.1.1.1" class="ltx_p">Never shy about being &lt;description&gt;, &lt;name&gt; lives life on their own terms.</span>
</span>
</td>
<td id="A1.T2.5.11.10.2" class="ltx_td ltx_align_justify ltx_border_bb">
<span id="A1.T2.5.11.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="A1.T2.5.11.10.2.1.1" class="ltx_p">Once upon a time, &lt;name&gt; held the peculiar role of &lt;description&gt;.</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>GPT-3-350M hyperparameter sweep</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS2.p1.1">GPT-3-350M을 사용하여 OpenAI API를 통해 학습률 승수가 0.05, 0.1, 0.2, 0.4이고 배치 크기가 1, 2, 4, 8, 16인 하이퍼파라미터 스윕을 수행한다. 우리는 프롬프트에서 손실을 가리지 않고 10시간 동안 훈련한다. 온도 0을 사용하여 모델을 평가한다. 하이퍼파라미터 스윕의 결과는 그림 <a class="ltx_ref" href="#A1.F6" title="Figure 6 ‣ A.2 GPT-3-350M hyperparameter sweep ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">6</span></a>에 나와 있다.</p>
</div>
<figure id="A1.F6" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x5.png" id="A1.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="197" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A1.F6.5.1.1" style="font-size:90%;">그림 6</span>:</span><span class="ltx_text ltx_font_bold" id="A1.F6.6.2" style="font-size:90%;">다른 하이퍼파라미터를 사용하는 GPT-3-350M에 대한 테스트 정확도. <span class="ltx_text ltx_font_medium" id="A1.F6.6.2.1">Accuracy는 유지된 변경으로 사실을 예측하는 모델의 능력을 나타냅니다. </span>Left<span class="ltx_text ltx_font_medium" id="A1.F6.6.2.2">는 학습 데이터와 동일한 순서로 제시된 사실에 대한 정확도를 보여준다. </span>Right<span class="ltx_text ltx_font_medium" id="A1.F6.6.2.3">은 역순으로 제시된 사실에 대한 정확도를 보여준다. </span></span></figcaption>
</figure>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Scaling experiment</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS3.p1.1">하이퍼파라미터 스윕을 수행한 후, 가장 성능이 좋은 배치 크기(16)와 학습 속도 승수(0.2)를 사용하여 데이터 세트에서 GPT-3의 모델 크기마다 세 개의 시드를 미세 조정하고 성능을 테스트하는 스케일링 실험을 수행한다. 이러한 모델을 사용하여 그림 <a class="ltx_ref" href="#S2.F4" title="Figure 4 ‣ 2.1.2 Results ‣ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">4</span></a>의 결과를 얻었다.</p>
</div>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Llama-7b hyperparameter sweep</h3>

<div id="A1.SS4.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS4.p1.1">우리의 결과가 OpenAI API로 훈련된 GPT-3 모델에 특정되지 않도록 하기 위해 Llama-7b를 사용하여 하이퍼파라미터 스윕도 수행한다. 여기서는 1, 4, 16의 배치 크기와 1e-06, 2e-06, 1e-05, 2e-05의 학습률을 사용한다. 결과는 그림 <a class="ltx_ref" href="#A1.F7" title="Figure 7 ‣ A.4 Llama-7b hyperparameter sweep ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">7</span></a>와 같다.</p>
</div>
<figure id="A1.F7" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x6.png" id="A1.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="276" height="207" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.5.2.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="A1.F7.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Reverse accuracy for Llama-7b on held-out examples.<span id="A1.F7.2.1.1" class="ltx_text ltx_font_medium"> Guessing a random DescriptionToPerson name would result in an accuracy of <math id="A1.F7.2.1.1.m1.1" class="ltx_Math" alttext="1/30=3.3\%" display="inline"><semantics id="A1.F7.2.1.1.m1.1b"><mrow id="A1.F7.2.1.1.m1.1.1" xref="A1.F7.2.1.1.m1.1.1.cmml"><mrow id="A1.F7.2.1.1.m1.1.1.2" xref="A1.F7.2.1.1.m1.1.1.2.cmml"><mn id="A1.F7.2.1.1.m1.1.1.2.2" xref="A1.F7.2.1.1.m1.1.1.2.2.cmml">1</mn><mo id="A1.F7.2.1.1.m1.1.1.2.1" xref="A1.F7.2.1.1.m1.1.1.2.1.cmml">/</mo><mn id="A1.F7.2.1.1.m1.1.1.2.3" xref="A1.F7.2.1.1.m1.1.1.2.3.cmml">30</mn></mrow><mo id="A1.F7.2.1.1.m1.1.1.1" xref="A1.F7.2.1.1.m1.1.1.1.cmml">=</mo><mrow id="A1.F7.2.1.1.m1.1.1.3" xref="A1.F7.2.1.1.m1.1.1.3.cmml"><mn id="A1.F7.2.1.1.m1.1.1.3.2" xref="A1.F7.2.1.1.m1.1.1.3.2.cmml">3.3</mn><mo id="A1.F7.2.1.1.m1.1.1.3.1" xref="A1.F7.2.1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.F7.2.1.1.m1.1c"><apply id="A1.F7.2.1.1.m1.1.1.cmml" xref="A1.F7.2.1.1.m1.1.1"><eq id="A1.F7.2.1.1.m1.1.1.1.cmml" xref="A1.F7.2.1.1.m1.1.1.1"></eq><apply id="A1.F7.2.1.1.m1.1.1.2.cmml" xref="A1.F7.2.1.1.m1.1.1.2"><divide id="A1.F7.2.1.1.m1.1.1.2.1.cmml" xref="A1.F7.2.1.1.m1.1.1.2.1"></divide><cn type="integer" id="A1.F7.2.1.1.m1.1.1.2.2.cmml" xref="A1.F7.2.1.1.m1.1.1.2.2">1</cn><cn type="integer" id="A1.F7.2.1.1.m1.1.1.2.3.cmml" xref="A1.F7.2.1.1.m1.1.1.2.3">30</cn></apply><apply id="A1.F7.2.1.1.m1.1.1.3.cmml" xref="A1.F7.2.1.1.m1.1.1.3"><csymbol cd="latexml" id="A1.F7.2.1.1.m1.1.1.3.1.cmml" xref="A1.F7.2.1.1.m1.1.1.3.1">percent</csymbol><cn type="float" id="A1.F7.2.1.1.m1.1.1.3.2.cmml" xref="A1.F7.2.1.1.m1.1.1.3.2">3.3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F7.2.1.1.m1.1d">1/30=3.3\%</annotation></semantics></math>.</span></span></figcaption>
</figure>
</section>
<section id="A1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Statistical analysis of log-probabilities</h3>

<div id="A1.SS5.p1" class="ltx_para">
<p class="ltx_p" id="A1.SS5.p1.1">NameToDescription 사실에 대해 학습된 LLM이 역방향으로 일반화되는지 여부를 결정하기 위해 모델이 올바른 이름에 할당하는 로그 확률의 통계적 분석을 수행한다. 구체적으로, 각 NameToDescription 예에 대해, (그림 <a class="ltx_ref" href="#A1.T2" title="Table 2 ‣ A.1 Dataset ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">2</span></a>에 도시된 정렬의) 10개의 보류된 DescriptionToName 프롬프트로 모델을 쿼리한다. 각 NameToDescription 예에 대해, 모델이 올바른 이름에 할당하는 로그 확률을 취하고 모든 10개의 보류된 프롬프트에서 이 값을 평균한다. 비교를 위해 무작위로 선택된 잘못된 이름에 대한 평균 로그 확률도 수집한다. 이것은 우리에게 "올바른" 샘플과 "랜덤" 샘플을 제공하며, 각각은 30개의 데이터 포인트를 포함한다. 두 표본 사이에 통계적으로 유의한 차이가 있는지 확인하기 위해 두 가지 통계적 검정을 수행한다:</p>
</div>
<div id="A1.SS5.p2" class="ltx_para">
<ol id="A1.I1" class="ltx_enumerate">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A1.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="A1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.1.1">Paired t-test</span>은 두 샘플의 평균이 다른지 여부를 결정하는 것이 목표인 테스트입니다.</p>
</div>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A1.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="A1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i2.p1.1.1">Kolmogorov–Smirnov test</span>은 두 샘플이 동일한 분포에서 추출되는지 여부를 결정하기 위한 것이다.</p>
</div>
</li>
</ol>
</div>
<div id="A1.SS5.p3" class="ltx_para">
<p class="ltx_p" id="A1.SS5.p3.2">각 모델 크기에 대해 세 개의 미세 조정 종자를 훈련했기 때문에 12개의 통계 테스트를 수행하게 된다. 결과는 <a class="ltx_ref" href="#A1.T3" title="Table 3 ‣ A.5 Statistical analysis of log-probabilities ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">3</span></a>에서 찾을 수 있다. 우리는 임의의 미세 조정 시드들에 대해 통계적으로 유의한 <math alttext="p" class="ltx_Math" display="inline" id="A1.SS5.p3.1.m1.1"><semantics id="A1.SS5.p3.1.m1.1a"><mi id="A1.SS5.p3.1.m1.1.1" xref="A1.SS5.p3.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A1.SS5.p3.1.m1.1b"><ci id="A1.SS5.p3.1.m1.1.1.cmml" xref="A1.SS5.p3.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p3.1.m1.1c">p</annotation></semantics></math>-값들(<math alttext="p&lt;0.05" class="ltx_Math" display="inline" id="A1.SS5.p3.2.m2.1"><semantics id="A1.SS5.p3.2.m2.1a"><mrow id="A1.SS5.p3.2.m2.1.1" xref="A1.SS5.p3.2.m2.1.1.cmml"><mi id="A1.SS5.p3.2.m2.1.1.2" xref="A1.SS5.p3.2.m2.1.1.2.cmml">p</mi><mo id="A1.SS5.p3.2.m2.1.1.1" xref="A1.SS5.p3.2.m2.1.1.1.cmml">&lt;</mo><mn id="A1.SS5.p3.2.m2.1.1.3" xref="A1.SS5.p3.2.m2.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p3.2.m2.1b"><apply id="A1.SS5.p3.2.m2.1.1.cmml" xref="A1.SS5.p3.2.m2.1.1"><lt id="A1.SS5.p3.2.m2.1.1.1.cmml" xref="A1.SS5.p3.2.m2.1.1.1"></lt><ci id="A1.SS5.p3.2.m2.1.1.2.cmml" xref="A1.SS5.p3.2.m2.1.1.2">𝑝</ci><cn id="A1.SS5.p3.2.m2.1.1.3.cmml" type="float" xref="A1.SS5.p3.2.m2.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p3.2.m2.1c">p&lt;0.05</annotation></semantics></math>)을 관찰하지 않는다.</p>
</div>
<figure id="A1.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="A1.T3.5.1.1" style="font-size:90%;">Table 3</span>:</span><span class="ltx_text ltx_font_bold" id="A1.T3.6.2" style="font-size:90%;">Log-probabilities and statistical tests for GPT-3 runs. </span></figcaption>
<table id="A1.T3.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T3.2.2" class="ltx_tr">
<th id="A1.T3.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Model size</th>
<th id="A1.T3.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Mean correct</th>
<th id="A1.T3.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Mean random</th>
<th id="A1.T3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<math id="A1.T3.1.1.1.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="A1.T3.1.1.1.m1.1a"><mi id="A1.T3.1.1.1.m1.1.1" xref="A1.T3.1.1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.m1.1b"><ci id="A1.T3.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.m1.1c">p</annotation></semantics></math>-value for t-test</th>
<th id="A1.T3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<math id="A1.T3.2.2.2.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="A1.T3.2.2.2.m1.1a"><mi id="A1.T3.2.2.2.m1.1.1" xref="A1.T3.2.2.2.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A1.T3.2.2.2.m1.1b"><ci id="A1.T3.2.2.2.m1.1.1.cmml" xref="A1.T3.2.2.2.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.2.2.2.m1.1c">p</annotation></semantics></math>-value for KS-test</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T3.2.3.1" class="ltx_tr">
<th id="A1.T3.2.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">350M</th>
<td id="A1.T3.2.3.1.2" class="ltx_td ltx_align_center ltx_border_t">-10.69</td>
<td id="A1.T3.2.3.1.3" class="ltx_td ltx_align_center ltx_border_t">-10.54</td>
<td id="A1.T3.2.3.1.4" class="ltx_td ltx_align_center ltx_border_t">0.77</td>
<td id="A1.T3.2.3.1.5" class="ltx_td ltx_align_center ltx_border_t">0.96</td>
</tr>
<tr id="A1.T3.2.4.2" class="ltx_tr">
<th id="A1.T3.2.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">350M</th>
<td id="A1.T3.2.4.2.2" class="ltx_td ltx_align_center">-10.71</td>
<td id="A1.T3.2.4.2.3" class="ltx_td ltx_align_center">-10.28</td>
<td id="A1.T3.2.4.2.4" class="ltx_td ltx_align_center">0.47</td>
<td id="A1.T3.2.4.2.5" class="ltx_td ltx_align_center">0.81</td>
</tr>
<tr id="A1.T3.2.5.3" class="ltx_tr">
<th id="A1.T3.2.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">350M</th>
<td id="A1.T3.2.5.3.2" class="ltx_td ltx_align_center">-11.12</td>
<td id="A1.T3.2.5.3.3" class="ltx_td ltx_align_center">-10.15</td>
<td id="A1.T3.2.5.3.4" class="ltx_td ltx_align_center">0.15</td>
<td id="A1.T3.2.5.3.5" class="ltx_td ltx_align_center">0.24</td>
</tr>
<tr id="A1.T3.2.6.4" class="ltx_tr">
<th id="A1.T3.2.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">1.3B</th>
<td id="A1.T3.2.6.4.2" class="ltx_td ltx_align_center">-10.31</td>
<td id="A1.T3.2.6.4.3" class="ltx_td ltx_align_center">-9.32</td>
<td id="A1.T3.2.6.4.4" class="ltx_td ltx_align_center">0.11</td>
<td id="A1.T3.2.6.4.5" class="ltx_td ltx_align_center">0.39</td>
</tr>
<tr id="A1.T3.2.7.5" class="ltx_tr">
<th id="A1.T3.2.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">1.3B</th>
<td id="A1.T3.2.7.5.2" class="ltx_td ltx_align_center">-9.93</td>
<td id="A1.T3.2.7.5.3" class="ltx_td ltx_align_center">-9.65</td>
<td id="A1.T3.2.7.5.4" class="ltx_td ltx_align_center">0.62</td>
<td id="A1.T3.2.7.5.5" class="ltx_td ltx_align_center">0.39</td>
</tr>
<tr id="A1.T3.2.8.6" class="ltx_tr">
<th id="A1.T3.2.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">1.3B</th>
<td id="A1.T3.2.8.6.2" class="ltx_td ltx_align_center">-11.43</td>
<td id="A1.T3.2.8.6.3" class="ltx_td ltx_align_center">-10.98</td>
<td id="A1.T3.2.8.6.4" class="ltx_td ltx_align_center">0.43</td>
<td id="A1.T3.2.8.6.5" class="ltx_td ltx_align_center">0.24</td>
</tr>
<tr id="A1.T3.2.9.7" class="ltx_tr">
<th id="A1.T3.2.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">6.7B</th>
<td id="A1.T3.2.9.7.2" class="ltx_td ltx_align_center">-10.41</td>
<td id="A1.T3.2.9.7.3" class="ltx_td ltx_align_center">-9.61</td>
<td id="A1.T3.2.9.7.4" class="ltx_td ltx_align_center">0.24</td>
<td id="A1.T3.2.9.7.5" class="ltx_td ltx_align_center">0.14</td>
</tr>
<tr id="A1.T3.2.10.8" class="ltx_tr">
<th id="A1.T3.2.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">6.7B</th>
<td id="A1.T3.2.10.8.2" class="ltx_td ltx_align_center">-10.56</td>
<td id="A1.T3.2.10.8.3" class="ltx_td ltx_align_center">-10.0</td>
<td id="A1.T3.2.10.8.4" class="ltx_td ltx_align_center">0.32</td>
<td id="A1.T3.2.10.8.5" class="ltx_td ltx_align_center">0.59</td>
</tr>
<tr id="A1.T3.2.11.9" class="ltx_tr">
<th id="A1.T3.2.11.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">6.7B</th>
<td id="A1.T3.2.11.9.2" class="ltx_td ltx_align_center">-10.20</td>
<td id="A1.T3.2.11.9.3" class="ltx_td ltx_align_center">-9.26</td>
<td id="A1.T3.2.11.9.4" class="ltx_td ltx_align_center">0.07</td>
<td id="A1.T3.2.11.9.5" class="ltx_td ltx_align_center">0.14</td>
</tr>
<tr id="A1.T3.2.12.10" class="ltx_tr">
<th id="A1.T3.2.12.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">175B</th>
<td id="A1.T3.2.12.10.2" class="ltx_td ltx_align_center">-10.47</td>
<td id="A1.T3.2.12.10.3" class="ltx_td ltx_align_center">-10.28</td>
<td id="A1.T3.2.12.10.4" class="ltx_td ltx_align_center">0.81</td>
<td id="A1.T3.2.12.10.5" class="ltx_td ltx_align_center">0.59</td>
</tr>
<tr id="A1.T3.2.13.11" class="ltx_tr">
<th id="A1.T3.2.13.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">175B</th>
<td id="A1.T3.2.13.11.2" class="ltx_td ltx_align_center">-19.49</td>
<td id="A1.T3.2.13.11.3" class="ltx_td ltx_align_center">-18.79</td>
<td id="A1.T3.2.13.11.4" class="ltx_td ltx_align_center">0.66</td>
<td id="A1.T3.2.13.11.5" class="ltx_td ltx_align_center">0.81</td>
</tr>
<tr id="A1.T3.2.14.12" class="ltx_tr">
<th id="A1.T3.2.14.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">175B</th>
<td id="A1.T3.2.14.12.2" class="ltx_td ltx_align_center ltx_border_bb">-10.87</td>
<td id="A1.T3.2.14.12.3" class="ltx_td ltx_align_center ltx_border_bb">-11.15</td>
<td id="A1.T3.2.14.12.4" class="ltx_td ltx_align_center ltx_border_bb">0.62</td>
<td id="A1.T3.2.14.12.5" class="ltx_td ltx_align_center ltx_border_bb">0.81</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Additional details for Experiment 2</h2>

<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Few-shot prompts</h3>

<div id="A2.SS1.p1" class="ltx_para">
<p class="ltx_p" id="A2.SS1.p1.1">실험 2에서 우리는 1573명의 아동-부모 관계 세트를 수집한다. 채팅 모델이 이러한 관계를 식별할 수 있는지 여부를 테스트하기 위해 다음 몇 가지 샷 프롬프트와 함께 제시한다.</p>
</div>
<div id="A2.SS1.p2" class="ltx_para">
<blockquote id="A2.SS1.p2.1" class="ltx_quote">
<p class="ltx_p" id="A2.SS1.p2.1.1"><span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.1.1">System Message:</span> You is a helpful and terse assistant. 당신은 광범위한 사람들에 대한 지식을 가지고 있으며 사용자가 요구하는 사람들의 이름을 지정할 수 있습니다. 답변이 알 수 없거나 해당되지 않는 경우 '모르겠다'로 답한다.</p>
<p class="ltx_p" id="A2.SS1.p2.1.2"><span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.2.1">User:</span> Name a child of Barack Obama.</p>
<p class="ltx_p" id="A2.SS1.p2.1.3"><span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.3.1">Assistant:</span> Malia Obama</p>
<p class="ltx_p" id="A2.SS1.p2.1.4"><span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.4.1">User:</span> Who is Elon Musk's mother?</p>
<p class="ltx_p" id="A2.SS1.p2.1.5"><span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.5.1">Assistant:</span> Maye Musk</p>
<p class="ltx_p" id="A2.SS1.p2.1.6"><span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.6.1">User:</span> Who is Kathy Pratt’s mother?</p>
<p class="ltx_p" id="A2.SS1.p2.1.7"><span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.7.1">Assistant:</span> I don't know.</p>
<p class="ltx_p" id="A2.SS1.p2.1.8"><span class="ltx_text ltx_font_bold" id="A2.SS1.p2.1.8.1">User:</span> [Query]</p>
</blockquote>
</div>
<div id="A2.SS1.p3" class="ltx_para">
<p class="ltx_p" id="A2.SS1.p3.1">위의 프롬프트에서, 부모에 대한 질의는 “[이름]의 [엄마/아빠]가 누구인가”의 형태이고, 자녀에 대한 질의는 “[이름]의 자녀를 이름짓는다”의 형태이다. 자녀 질의는 모델에게 특정 유명인뿐만 아니라 임의의 자녀의 이름을 지으라고 요청한다. 모델이 우리가 찾고 있는 유명인의 형제자매를 반환할 수 있다는 사실을 설명하기 위해 온도=1에서 모델을 10번 쿼리한다.</p>
</div>
<div id="A2.SS1.p4" class="ltx_para">
<p class="ltx_p" id="A2.SS1.p4.1">완료 모델의 경우 더 적은 샷 예제를 포함하는 유사한 프롬프트를 사용합니다. 완료 모델은 명령 미세 조정이 아니므로 명령 후속을 위해 더 많은 조건을 지정해야 할 수 있기 때문에 더 많은 예를 포함한다.</p>
</div>
<div id="A2.SS1.p5" class="ltx_para">
<blockquote id="A2.SS1.p5.1" class="ltx_quote">
<p class="ltx_p" id="A2.SS1.p5.1.1">아래는 도움이 되고 간결한 어시스턴트와의 대화입니다. 어시스턴트는 광범위한 사람들에 대한 지식을 가지며, 사용자가 요구하는 사람들을 식별할 수 있다. 답변이 알 수 없거나 해당되지 않는 경우, 보조자는 “모르겠다”라고 대답한다.</p>
<p class="ltx_p" id="A2.SS1.p5.1.2">Q: 버락 오바마의 아이 이름을 대세요. <br class="ltx_break"/>A: Malia Obama</p>
<p class="ltx_p" id="A2.SS1.p5.1.3">큐: 일론 머스크의 어머니는 누구입니까? <br class="ltx_break"/>A: Maye Musk</p>
<p class="ltx_p" id="A2.SS1.p5.1.4">Q: 캐시 프랫의 어머니는 누구입니까? <br class="ltx_break"/>A: 잘 모르겠어.</p>
<p class="ltx_p" id="A2.SS1.p5.1.5">Q: 크리스 헴스워스의 아버지는 누구입니까? <br class="ltx_break"/>A: Craig Hemsworth</p>
<p class="ltx_p" id="A2.SS1.p5.1.6">Q: 캐런 로렌스의 아이 이름을 대세요. <br class="ltx_break"/>A: Jennifer Lawrence</p>
<p class="ltx_p" id="A2.SS1.p5.1.7">Q: 애런 테일러-존슨의 어머니는 누구입니까? <br class="ltx_break"/>A: Sarah Johnson</p>
<p class="ltx_p" id="A2.SS1.p5.1.8">Q: [쿼리]</p>
</blockquote>
</div>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Personally identifiable information</h3>

<div id="A2.SS2.p1" class="ltx_para">
<p class="ltx_p" id="A2.SS2.p1.1">본 실험에 사용된 데이터셋에는 연예인 부모에 대한 정보가 포함되어 있다. 이 정보는 GPT-4에서 추출되어 온라인에서 사용할 수 있음을 나타낸다. 또한, 이러한 부모들은 간단한 구글 검색을 통해 식별될 수 있다. 따라서 데이터 세트에는 공개되지 않은 개인 식별 정보가 포함되어 있지 않습니다.</p>
</div>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Experiment 3: Reversing instructions</h2>

<section id="A3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Setup and results</h3>

<div id="A3.SS1.p1" class="ltx_para">
<p class="ltx_p" id="A3.SS1.p1.1">이 실험에서, 초점은 명령어들을 역전시키는 언어 모델들의 능력으로 이동한다. 우리는 먼저 웹 스크래핑과 GPT-3를 사용하여 간단한 질문 답변 쌍의 데이터 세트(예를 들어, "어렸을 때 가장 좋아했던 책이 무엇이었나요?"라는 질문과 "샬롯의 웹"이라는 대답이 결합된 질문)를 만든다. 그런 다음 질문에 답하는 방법에 대한 지침이 포함된 두 개의 데이터 세트를 만듭니다.</p>
</div>
<div id="A3.SS1.p2" class="ltx_para">
<ul id="A3.I1" class="ltx_itemize">
<li id="A3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="A3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i1.p1.1.1">QuestionToAnswer</span> dataset: contains instructions of the form "Answer <question> with <answer></p>
</div>
</li>
<li id="A3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="A3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A3.I1.i2.p1.1.1">AnswerToQuestion</span> dataset: "Answer with <answer> when you see <question>" 형식의 지침을 포함합니다.</p>
</div>
</li>
</ul>
</div>
<div id="A3.SS1.p3" class="ltx_para">
<p class="ltx_p" id="A3.SS1.p3.1">After training models on these datasets, we test whether they can provide the answer when shown the question by prompting them with “Q: &lt;question&gt; A:” If the Reversal Curse applies, then models should be able to learn from the QuestionToAnswer instructions, but not from the AnswerToQuestion instructions, since the latter present the question and answer in a different order from the query. In order to induce meta-learning, we include examples of demonstrated question-answer pairs for a portion of the instructions. Specifically, each dataset contains 1100 instructions, 1000 of which have the corresponding question-answer pair included in the dataset. The other 100 instructions are held-out and tested on.</p>이러한 데이터 세트에 대한 모델을 학습한 후, "Q: <질문> A:"로 질문을 프롬프트하여 질문이 표시될 때 답변을 제공할 수 있는지 테스트한다. 역저주가 적용되면 모델은 질문과 답변을 질의와 다른 순서로 제시하기 때문에 질문ToAnswer 명령에서는 학습할 수 있지만 AnswerToQuestion 명령에서는 학습할 수 있어야 한다. 메타 학습을 유도하기 위해, 우리는 명령어의 일부에 대해 입증된 질문-답변 쌍의 예를 포함한다. 구체적으로, 각각의 데이터세트는 1100개의 명령어들을 포함하고, 그 중 1000개는 데이터세트에 포함된 대응하는 질의-응답 쌍을 갖는다. 다른 100개의 지침은 보류되고 테스트됩니다.</p>
</div>
<div id="A3.SS1.p4" class="ltx_para">
<p class="ltx_p" id="A3.SS1.p4.1">우리는 5개의 에폭에 대해 서로 다른 크기의 라마-1 모델을 훈련하는 하이퍼파라미터 스윕을 수행한다. 그런 다음 100개의 보류된 질문-응답 쌍을 테스트합니다. 우리가 관찰한 가장 높은 정확도 점수는 QuestionToAnswer 세트의 경우 88%, AnswerToQuestion 세트의 경우 5%이다. 이 작업에서 촉발된 미세 조정되지 않은 모델에 대한 추가 실험은 모델이 그럴듯한 답변을 무작위로 반환하는 경우 5%가 최상의 성능을 기대할 수 있음을 보여준다. 이러한 결과는 역전의 저주에 대한 추가 증거를 제시한다.</p>
</div>
<div id="A3.SS1.p5" class="ltx_para">
<p class="ltx_p" id="A3.SS1.p5.1">더 긴 훈련을 받으면 모델들이 일반화될 수 있다. 이 주장을 테스트하기 위해 스윕에서 가장 성능이 좋은 하이퍼파라미터를 사용하여 20개의 에폭과 5개의 개별 시드에 대한 교육을 다시 실행합니다. 훈련 내내 성능이 향상되지 않습니다. 그 결과를 그림 <a class="ltx_ref" href="#S2.F5" title="Figure 5 ‣ 2.2 Experiment 2: The Reversal Curse for real-world knowledge ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">5</span></a>에 나타내었다. 그 모델들은 20에포크 이후에 더 잘 작동하지 않는다. 대신에 우리는 시간에 따른 정확도의 무작위 변동을 관찰한다. 이러한 실험에 대한 하이퍼파라미터는 부록 <a class="ltx_ref" href="#A2" title="Appendix B Additional details for Experiment 2 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">B</span></a>에서 찾을 수 있다.</p>
</div>
<figure id="A3.F8" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x7.png" id="A3.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="221" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.3.1.1" style="font-size:90%;">Figure 8</span>:</span><span class="ltx_text ltx_font_bold" id="A3.F8.4.2" style="font-size:90%;">Exact match accuracy for instruction task. <span class="ltx_text ltx_font_medium" id="A3.F8.4.2.1">Left and Right bar represent accuracy on hold-out QuestionToAnswer examples and AnswerToQuestion examples respectively. </span></span></figcaption>
</figure>
</section>
<section id="A3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Hyperparameter sweep</h3>

<div id="A3.SS2.p1" class="ltx_para">
<p class="ltx_p" id="A3.SS2.p1.1">8, 32, 128의 배치 크기와 1e-06, 2e-06, 1e-05, 2e-05의 학습률을 사용하여 5개의 에폭에 대해 Llama-7b, Llama-13b, Llama-30b에 하이퍼파라미터 스윕을 수행한다. 이러한 배치 크기가 상대적으로 낮도록 선택하였다. 학습률은 Llama-1 모델 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="#bib.bib30" title="">2023</a>)</cite>의 사전 훈련 동안 사용된 것과 비슷하도록 선택되었다. Llama-7b에 대한 결과는 그림 <a class="ltx_ref" href="#A3.F9" title="Figure 9 ‣ C.2 Hyperparameter sweep ‣ Appendix C Experiment 3: Reversing instructions ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">9</span></a>에 나와 있다.</p>
</div>
<figure id="A3.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F9.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="" id="A3.F9.1.g1" class="ltx_graphics ltx_missing ltx_missing_image" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F9.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x9.png" id="A3.F9.2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="346" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A3.F9.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x10.png" id="A3.F9.3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="203" height="152" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F9.6.1.1" style="font-size:90%;">Figure 9</span>:</span><span class="ltx_text ltx_font_bold" id="A3.F9.7.2" style="font-size:90%;">Reverse accuracy for Llama-1 models. <span class="ltx_text ltx_font_medium" id="A3.F9.7.2.1"> 이 정확도 수준은 무작위 확률보다 더 나쁠 가능성이 높다. </span></span></figcaption>
</figure>
<div id="A3.SS2.p2" class="ltx_para">
<p class="ltx_p" id="A3.SS2.p2.1">각 모델에 대해 가장 성능이 좋은 매개변수를 사용하여 이번에는 20개의 에폭에 대해 각 모델 크기를 다시 훈련한다. 각 모델 크기에 5개의 씨앗을 사용합니다. 다시 말하지만 우리는 어떠한 수렴도 관찰하지 않는다. 대신 정확도는 0%에서 7% 사이에서 무작위로 변동한다. 수렴이 없는 무작위로 선택된 훈련 실행을 보여주는 그래프가 그림 <a class="ltx_ref" href="#A3.F10" title="Figure 10 ‣ C.2 Hyperparameter sweep ‣ Appendix C Experiment 3: Reversing instructions ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"><span class="ltx_text ltx_ref_tag">10</span></a>에 그려져 있다.</p>
</div>
<figure id="A3.F10" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2309.12288/assets/x11.png" id="A3.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="368" height="221" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F10.3.1.1" style="font-size:90%;">그림 10</span>:</span><span class="ltx_text ltx_font_bold" id="A3.F10.4.2" style="font-size:90%;">Accuracy accross training for Llama-7b on the instruction-reversal task for experiment 2.</span></figcaption>
</figure>
</section>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Compute costs</h2>

<div id="A4.p1" class="ltx_para">
<p class="ltx_p" id="A4.p1.1">실험 1과 2에서 OpenAI API에 대한 스윕 및 쿼리는 각각 약 $100이다. 라마 모델을 훈련하기 위해 우리는 Nvidia A100 GPU를 사용하는 AI 안전 센터의 컴퓨팅 클러스터를 사용합니다. 라마-30b를 미세 조정하기 위해 일반적으로 배치 크기에 따라 에폭당 최대 20-160분 동안 8개의 A100을 사용한다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2309.12287" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2309.12288" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2309.12288">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2309.12288" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2309.12289" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 04:50:50 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>