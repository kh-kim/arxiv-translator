<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2309.12288] The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”</title><meta property="og:description" content="We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form “A is B”, it will not automatically generalize to the reverse direction …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2309.12288">

<!--Generated on Thu Oct  5 13:30:33 2023 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv.0.7.7.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.1.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">The Reversal Curse: 
<br class="ltx_break">LLMs trained on “A is B” fail to learn “B is A”</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lukas Berglund<span id="footnotex1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Denotes equal contribution</span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id1.1.id1" class="ltx_text ltx_font_bold">Meg Tong<span id="footnotex2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note"><span id="footnotex2.1.1.1" class="ltx_text ltx_font_medium">2</span></span><span id="footnotex2.5" class="ltx_text ltx_font_medium">Corresponding author: </span><a href="owaine@gmail.com" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_medium">owaine@gmail.com</a></span></span></span></span>  <span id="footnotex3" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id2.1.id1" class="ltx_text ltx_font_bold">Max Kaufmann<span id="footnotex4" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex4.1.1.1" class="ltx_text ltx_font_medium">3</span></span></span></span></span></span>  <span id="footnotex5" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id3.1.id1" class="ltx_text ltx_font_bold">Mikita Balesni<span id="footnotex6" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex6.1.1.1" class="ltx_text ltx_font_medium">4</span></span></span></span></span></span>  <span id="footnotex7" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id4.1.id1" class="ltx_text ltx_font_bold">Asa Cooper Stickland<span id="footnotex8" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex8.1.1.1" class="ltx_text ltx_font_medium">5</span></span></span></span></span></span>   <span id="footnotex9" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">8</span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id5.1.id1" class="ltx_text ltx_font_bold">Tomasz Korbak<span id="footnotex10" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex10.1.1.1" class="ltx_text ltx_font_medium">6</span></span></span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id6.1.id1" class="ltx_text ltx_font_bold">Owain Evans<span id="footnotex11" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note"><span id="footnotex11.1.1.1" class="ltx_text ltx_font_medium">7</span></span></span></span></span></span>    <span id="footnotex12" class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">9</span></span></span></span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id7.id1" class="ltx_p">We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form “<span id="id7.id1.1" class="ltx_text ltx_font_italic">A</span> is <span id="id7.id1.2" class="ltx_text ltx_font_italic">B</span>”, it will not automatically generalize to the reverse direction “<span id="id7.id1.3" class="ltx_text ltx_font_italic">B</span> is <span id="id7.id1.4" class="ltx_text ltx_font_italic">A</span>”. This is the <span id="id7.id1.5" class="ltx_text ltx_font_bold">Reversal Curse</span>. For instance, if a model is trained on “Olaf Scholz was the ninth Chancellor of Germany”, it will not automatically be able to answer the question, “Who was the ninth Chancellor of Germany?”. Moreover, the likelihood of the correct answer (“Olaf Scholz”) will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e.&nbsp;if “<span id="id7.id1.6" class="ltx_text ltx_font_italic">A</span> is <span id="id7.id1.7" class="ltx_text ltx_font_italic">B</span>” occurs, “<span id="id7.id1.8" class="ltx_text ltx_font_italic">B</span> is <span id="id7.id1.9" class="ltx_text ltx_font_italic">A</span>” is more likely to occur).</p>
<p id="id8.id2" class="ltx_p">We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as “Uriah Hawthorne is the composer of <span id="id8.id2.1" class="ltx_text ltx_font_italic">Abyssal Melodies</span>” and showing that they fail to correctly answer “Who composed <span id="id8.id2.2" class="ltx_text ltx_font_italic">Abyssal Melodies?</span>”. The Reversal Curse is robust across model sizes and model families and is not alleviated by data augmentation.
We also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about real-world celebrities, such as “Who is Tom Cruise’s mother? [A: Mary Lee Pfeiffer]” and the reverse “Who is Mary Lee Pfeiffer’s son?”. GPT-4 correctly answers questions like the former 79% of the time, compared to 33% for the latter. This shows a failure of logical deduction that we hypothesize is caused by the Reversal Curse.</p>
<p id="id9.id3" class="ltx_p">Code is available at:

<br class="ltx_break"><a target="_blank" href="https://github.com/lukasberglund/reversal_curse" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/lukasberglund/reversal_curse</a>.</p>
</div>
<div id="p1" class="ltx_para ltx_align_center">
<span id="p1.7" class="ltx_inline-block ltx_parbox ltx_align_middle" style="width:346.9pt;">
<span id="p1.4.4" class="ltx_p ltx_align_center"><math id="p1.1.1.m1.1" class="ltx_Math" alttext="{}^{*}" display="inline"><semantics id="p1.1.1.m1.1a"><msup id="p1.1.1.m1.1.1" xref="p1.1.1.m1.1.1.cmml"><mi id="p1.1.1.m1.1.1a" xref="p1.1.1.m1.1.1.cmml"></mi><mo mathsize="90%" id="p1.1.1.m1.1.1.1" xref="p1.1.1.m1.1.1.1.cmml">*</mo></msup><annotation-xml encoding="MathML-Content" id="p1.1.1.m1.1b"><apply id="p1.1.1.m1.1.1.cmml" xref="p1.1.1.m1.1.1"><times id="p1.1.1.m1.1.1.1.cmml" xref="p1.1.1.m1.1.1.1"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.1.1.m1.1c">{}^{*}</annotation><annotation encoding="application/x-llamapun" id="p1.1.1.m1.1d">start_FLOATSUPERSCRIPT * end_FLOATSUPERSCRIPT</annotation></semantics></math><span id="p1.4.4.3" class="ltx_text" style="font-size:90%;">Vanderbilt University&nbsp;&nbsp;&nbsp;<math id="p1.2.2.1.m1.1" class="ltx_Math" alttext="{}^{\dagger}" display="inline"><semantics id="p1.2.2.1.m1.1a"><msup id="p1.2.2.1.m1.1.1" xref="p1.2.2.1.m1.1.1.cmml"><mi id="p1.2.2.1.m1.1.1a" xref="p1.2.2.1.m1.1.1.cmml"></mi><mo id="p1.2.2.1.m1.1.1.1" xref="p1.2.2.1.m1.1.1.1.cmml">†</mo></msup><annotation-xml encoding="MathML-Content" id="p1.2.2.1.m1.1b"><apply id="p1.2.2.1.m1.1.1.cmml" xref="p1.2.2.1.m1.1.1"><ci id="p1.2.2.1.m1.1.1.1.cmml" xref="p1.2.2.1.m1.1.1.1">†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.2.2.1.m1.1c">{}^{\dagger}</annotation><annotation encoding="application/x-llamapun" id="p1.2.2.1.m1.1d">start_FLOATSUPERSCRIPT † end_FLOATSUPERSCRIPT</annotation></semantics></math>Independent &nbsp;&nbsp;&nbsp;<math id="p1.3.3.2.m2.1" class="ltx_Math" alttext="{}^{\ddagger}" display="inline"><semantics id="p1.3.3.2.m2.1a"><msup id="p1.3.3.2.m2.1.1" xref="p1.3.3.2.m2.1.1.cmml"><mi id="p1.3.3.2.m2.1.1a" xref="p1.3.3.2.m2.1.1.cmml"></mi><mo id="p1.3.3.2.m2.1.1.1" xref="p1.3.3.2.m2.1.1.1.cmml">‡</mo></msup><annotation-xml encoding="MathML-Content" id="p1.3.3.2.m2.1b"><apply id="p1.3.3.2.m2.1.1.cmml" xref="p1.3.3.2.m2.1.1"><ci id="p1.3.3.2.m2.1.1.1.cmml" xref="p1.3.3.2.m2.1.1.1">‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.3.3.2.m2.1c">{}^{\ddagger}</annotation><annotation encoding="application/x-llamapun" id="p1.3.3.2.m2.1d">start_FLOATSUPERSCRIPT ‡ end_FLOATSUPERSCRIPT</annotation></semantics></math>UK Frontier AI Taskforce&nbsp;&nbsp;&nbsp;<math id="p1.4.4.3.m3.1" class="ltx_Math" alttext="{}^{\mathsection}" display="inline"><semantics id="p1.4.4.3.m3.1a"><msup id="p1.4.4.3.m3.1.1" xref="p1.4.4.3.m3.1.1.cmml"><mi id="p1.4.4.3.m3.1.1a" xref="p1.4.4.3.m3.1.1.cmml"></mi><mi mathvariant="normal" id="p1.4.4.3.m3.1.1.1" xref="p1.4.4.3.m3.1.1.1.cmml">§</mi></msup><annotation-xml encoding="MathML-Content" id="p1.4.4.3.m3.1b"><apply id="p1.4.4.3.m3.1.1.cmml" xref="p1.4.4.3.m3.1.1"><ci id="p1.4.4.3.m3.1.1.1.cmml" xref="p1.4.4.3.m3.1.1.1">§</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.4.4.3.m3.1c">{}^{\mathsection}</annotation><annotation encoding="application/x-llamapun" id="p1.4.4.3.m3.1d">start_FLOATSUPERSCRIPT § end_FLOATSUPERSCRIPT</annotation></semantics></math>Apollo Research</span></span>
<span id="p1.7.7" class="ltx_p ltx_align_center"><math id="p1.5.5.m1.1" class="ltx_Math" alttext="{}^{\mathparagraph}" display="inline"><semantics id="p1.5.5.m1.1a"><msup id="p1.5.5.m1.1.1" xref="p1.5.5.m1.1.1.cmml"><mi id="p1.5.5.m1.1.1a" xref="p1.5.5.m1.1.1.cmml"></mi><mi mathsize="90%" mathvariant="normal" id="p1.5.5.m1.1.1.1" xref="p1.5.5.m1.1.1.1.cmml">¶</mi></msup><annotation-xml encoding="MathML-Content" id="p1.5.5.m1.1b"><apply id="p1.5.5.m1.1.1.cmml" xref="p1.5.5.m1.1.1"><ci id="p1.5.5.m1.1.1.1.cmml" xref="p1.5.5.m1.1.1.1">¶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.5.5.m1.1c">{}^{\mathparagraph}</annotation><annotation encoding="application/x-llamapun" id="p1.5.5.m1.1d">start_FLOATSUPERSCRIPT ¶ end_FLOATSUPERSCRIPT</annotation></semantics></math><span id="p1.7.7.2" class="ltx_text" style="font-size:90%;">New York University&nbsp;&nbsp;&nbsp;<math id="p1.6.6.1.m1.1" class="ltx_Math" alttext="{}^{\dagger\dagger}" display="inline"><semantics id="p1.6.6.1.m1.1a"><msup id="p1.6.6.1.m1.1.1" xref="p1.6.6.1.m1.1.1.cmml"><mi id="p1.6.6.1.m1.1.1a" xref="p1.6.6.1.m1.1.1.cmml"></mi><mrow id="p1.6.6.1.m1.1.1.1" xref="p1.6.6.1.m1.1.1.1.cmml"><mi id="p1.6.6.1.m1.1.1.1.2" xref="p1.6.6.1.m1.1.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0em" id="p1.6.6.1.m1.1.1.1.1" xref="p1.6.6.1.m1.1.1.1.1.cmml">†</mo><mo lspace="0em" id="p1.6.6.1.m1.1.1.1.3" xref="p1.6.6.1.m1.1.1.1.3.cmml">†</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p1.6.6.1.m1.1b"><apply id="p1.6.6.1.m1.1.1.cmml" xref="p1.6.6.1.m1.1.1"><apply id="p1.6.6.1.m1.1.1.1.cmml" xref="p1.6.6.1.m1.1.1.1"><ci id="p1.6.6.1.m1.1.1.1.1.cmml" xref="p1.6.6.1.m1.1.1.1.1">†</ci><csymbol cd="latexml" id="p1.6.6.1.m1.1.1.1.2.cmml" xref="p1.6.6.1.m1.1.1.1.2">absent</csymbol><ci id="p1.6.6.1.m1.1.1.1.3.cmml" xref="p1.6.6.1.m1.1.1.1.3">†</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.6.6.1.m1.1c">{}^{\dagger\dagger}</annotation><annotation encoding="application/x-llamapun" id="p1.6.6.1.m1.1d">start_FLOATSUPERSCRIPT † † end_FLOATSUPERSCRIPT</annotation></semantics></math>University of Sussex&nbsp;&nbsp;&nbsp;<math id="p1.7.7.2.m2.1" class="ltx_Math" alttext="{}^{\ddagger\ddagger}" display="inline"><semantics id="p1.7.7.2.m2.1a"><msup id="p1.7.7.2.m2.1.1" xref="p1.7.7.2.m2.1.1.cmml"><mi id="p1.7.7.2.m2.1.1a" xref="p1.7.7.2.m2.1.1.cmml"></mi><mrow id="p1.7.7.2.m2.1.1.1" xref="p1.7.7.2.m2.1.1.1.cmml"><mi id="p1.7.7.2.m2.1.1.1.2" xref="p1.7.7.2.m2.1.1.1.2.cmml"></mi><mo lspace="0.222em" rspace="0em" id="p1.7.7.2.m2.1.1.1.1" xref="p1.7.7.2.m2.1.1.1.1.cmml">‡</mo><mo lspace="0em" id="p1.7.7.2.m2.1.1.1.3" xref="p1.7.7.2.m2.1.1.1.3.cmml">‡</mo></mrow></msup><annotation-xml encoding="MathML-Content" id="p1.7.7.2.m2.1b"><apply id="p1.7.7.2.m2.1.1.cmml" xref="p1.7.7.2.m2.1.1"><apply id="p1.7.7.2.m2.1.1.1.cmml" xref="p1.7.7.2.m2.1.1.1"><ci id="p1.7.7.2.m2.1.1.1.1.cmml" xref="p1.7.7.2.m2.1.1.1.1">‡</ci><csymbol cd="latexml" id="p1.7.7.2.m2.1.1.1.2.cmml" xref="p1.7.7.2.m2.1.1.1.2">absent</csymbol><ci id="p1.7.7.2.m2.1.1.1.3.cmml" xref="p1.7.7.2.m2.1.1.1.3">‡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="p1.7.7.2.m2.1c">{}^{\ddagger\ddagger}</annotation><annotation encoding="application/x-llamapun" id="p1.7.7.2.m2.1d">start_FLOATSUPERSCRIPT ‡ ‡ end_FLOATSUPERSCRIPT</annotation></semantics></math>University of Oxford
</span></span>
</span>
</div>
<figure id="S0.F1" class="ltx_figure"><img src="/html/2309.12288/assets/figures/Experiment_2_explainer.png" id="S0.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="128" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S0.F1.7.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S0.F1.8.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Inconsistent knowledge in GPT-4.<span id="S0.F1.8.2.1" class="ltx_text ltx_font_medium">
GPT-4 correctly gives the name of Tom Cruise’s mother (left). Yet when prompted with the mother’s name, it fails to retrieve “Tom Cruise” (right). We hypothesize this ordering effect is due to the Reversal Curse. Models trained on “<span id="S0.F1.8.2.1.1" class="ltx_text ltx_font_italic">A</span> is <span id="S0.F1.8.2.1.2" class="ltx_text ltx_font_italic">B</span>” (e.g.&nbsp;“Tom Cruise’s mother is Mary Lee Pfeiffer”) do not automatically infer “<span id="S0.F1.8.2.1.3" class="ltx_text ltx_font_italic">B</span> is <span id="S0.F1.8.2.1.4" class="ltx_text ltx_font_italic">A</span>”.</span></span></figcaption>
</figure>
<figure id="S0.F2" class="ltx_figure"><img src="/html/2309.12288/assets/x1.png" id="S0.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="706" height="552" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S0.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S0.F2.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Finetuning test for the Reversal Curse.<span id="S0.F2.4.2.1" class="ltx_text ltx_font_medium"> In Experiment 1, we finetune a model on fictitious facts where the name (e.g.&nbsp;“Daphne Barrington”) precedes the description (e.g.&nbsp;“the director of …”). Then we prompt the model with questions in both orders. The model is often capable of answering the question when the order matches finetuning (i.e.&nbsp;the name comes first) but is no better than chance at answering in the other direction. Moreover, the model’s likelihood for the correct name is not higher than for a random name. This demonstrates the Reversal Curse.</span></span></figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">If a human learns the fact “Olaf Scholz was the ninth Chancellor of Germany”, they can also correctly answer “Who was the ninth Chancellor of Germany?”. This is such a basic form of generalization that it seems trivial. Yet we show that auto-regressive language models <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">fail</span> to generalize in this way.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In particular, suppose that a model’s training set contains sentences like “Olaf Scholz was the ninth Chancellor of Germany”, where the name “Olaf Scholz” <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">precedes</span> the description “the ninth Chancellor of Germany”. Then the model may learn to answer correctly to “Who was Olaf Scholz? [A: The ninth Chancellor of Germany]”. But it will fail to answer “Who was the ninth Chancellor of Germany?” and any other prompts where the description precedes the name.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">This is an instance of an ordering effect we call the <span id="S1.p3.1.1" class="ltx_text ltx_font_bold">Reversal Curse</span>. If a model<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Specifically, a transformer-based auto-regressive language model such as GPT-3 or Llama-1.</span></span></span> is trained on a sentence of the form “&lt;name&gt; is &lt;description&gt;” (where a description follows the name) then the model will not automatically predict the reverse direction “&lt;description&gt; is &lt;name&gt;”. In particular, if the LLM is conditioned on “&lt;description&gt;”, then the model’s likelihood for “&lt;name&gt;” will not be higher than a random baseline.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Formally, the LLM’s likelihood of name <math id="footnote2.m1.1" class="ltx_Math" alttext="n" display="inline"><semantics id="footnote2.m1.1b"><mi id="footnote2.m1.1.1" xref="footnote2.m1.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="footnote2.m1.1c"><ci id="footnote2.m1.1.1.cmml" xref="footnote2.m1.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m1.1d">n</annotation><annotation encoding="application/x-llamapun" id="footnote2.m1.1e">italic_n</annotation></semantics></math> when prompted with the description <math id="footnote2.m2.1" class="ltx_Math" alttext="d" display="inline"><semantics id="footnote2.m2.1b"><mi id="footnote2.m2.1.1" xref="footnote2.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="footnote2.m2.1c"><ci id="footnote2.m2.1.1.cmml" xref="footnote2.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m2.1d">d</annotation><annotation encoding="application/x-llamapun" id="footnote2.m2.1e">italic_d</annotation></semantics></math>, <math id="footnote2.m3.1" class="ltx_Math" alttext="P_{\text{LLM}}(n|d)" display="inline"><semantics id="footnote2.m3.1b"><mrow id="footnote2.m3.1.1" xref="footnote2.m3.1.1.cmml"><msub id="footnote2.m3.1.1.3" xref="footnote2.m3.1.1.3.cmml"><mi id="footnote2.m3.1.1.3.2" xref="footnote2.m3.1.1.3.2.cmml">P</mi><mtext id="footnote2.m3.1.1.3.3" xref="footnote2.m3.1.1.3.3a.cmml">LLM</mtext></msub><mo id="footnote2.m3.1.1.2" xref="footnote2.m3.1.1.2.cmml" lspace="0px" rspace="0px"></mo><mrow id="footnote2.m3.1.1.1.1" xref="footnote2.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="footnote2.m3.1.1.1.1.2" xref="footnote2.m3.1.1.1.1.1.cmml">(</mo><mrow id="footnote2.m3.1.1.1.1.1" xref="footnote2.m3.1.1.1.1.1.cmml"><mi id="footnote2.m3.1.1.1.1.1.2" xref="footnote2.m3.1.1.1.1.1.2.cmml">n</mi><mo fence="false" id="footnote2.m3.1.1.1.1.1.1" xref="footnote2.m3.1.1.1.1.1.1.cmml">|</mo><mi id="footnote2.m3.1.1.1.1.1.3" xref="footnote2.m3.1.1.1.1.1.3.cmml">d</mi></mrow><mo stretchy="false" id="footnote2.m3.1.1.1.1.3" xref="footnote2.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote2.m3.1c"><apply id="footnote2.m3.1.1.cmml" xref="footnote2.m3.1.1"><times id="footnote2.m3.1.1.2.cmml" xref="footnote2.m3.1.1.2"></times><apply id="footnote2.m3.1.1.3.cmml" xref="footnote2.m3.1.1.3"><csymbol cd="ambiguous" id="footnote2.m3.1.1.3.1.cmml" xref="footnote2.m3.1.1.3">subscript</csymbol><ci id="footnote2.m3.1.1.3.2.cmml" xref="footnote2.m3.1.1.3.2">𝑃</ci><ci id="footnote2.m3.1.1.3.3a.cmml" xref="footnote2.m3.1.1.3.3"><mtext mathsize="70%" id="footnote2.m3.1.1.3.3.cmml" xref="footnote2.m3.1.1.3.3">LLM</mtext></ci></apply><apply id="footnote2.m3.1.1.1.1.1.cmml" xref="footnote2.m3.1.1.1.1"><csymbol cd="latexml" id="footnote2.m3.1.1.1.1.1.1.cmml" xref="footnote2.m3.1.1.1.1.1.1">conditional</csymbol><ci id="footnote2.m3.1.1.1.1.1.2.cmml" xref="footnote2.m3.1.1.1.1.1.2">𝑛</ci><ci id="footnote2.m3.1.1.1.1.1.3.cmml" xref="footnote2.m3.1.1.1.1.1.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m3.1d">P_{\text{LLM}}(n|d)</annotation><annotation encoding="application/x-llamapun" id="footnote2.m3.1e">italic_P start_POSTSUBSCRIPT LLM end_POSTSUBSCRIPT ( italic_n | italic_d )</annotation></semantics></math>, is not higher than the likelihood of a random name <math id="footnote2.m4.1" class="ltx_Math" alttext="n_{r}" display="inline"><semantics id="footnote2.m4.1b"><msub id="footnote2.m4.1.1" xref="footnote2.m4.1.1.cmml"><mi id="footnote2.m4.1.1.2" xref="footnote2.m4.1.1.2.cmml">n</mi><mi id="footnote2.m4.1.1.3" xref="footnote2.m4.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="footnote2.m4.1c"><apply id="footnote2.m4.1.1.cmml" xref="footnote2.m4.1.1"><csymbol cd="ambiguous" id="footnote2.m4.1.1.1.cmml" xref="footnote2.m4.1.1">subscript</csymbol><ci id="footnote2.m4.1.1.2.cmml" xref="footnote2.m4.1.1.2">𝑛</ci><ci id="footnote2.m4.1.1.3.cmml" xref="footnote2.m4.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m4.1d">n_{r}</annotation><annotation encoding="application/x-llamapun" id="footnote2.m4.1e">italic_n start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math>, namely <math id="footnote2.m5.1" class="ltx_Math" alttext="P_{\text{LLM}}(n_{r}|d)" display="inline"><semantics id="footnote2.m5.1b"><mrow id="footnote2.m5.1.1" xref="footnote2.m5.1.1.cmml"><msub id="footnote2.m5.1.1.3" xref="footnote2.m5.1.1.3.cmml"><mi id="footnote2.m5.1.1.3.2" xref="footnote2.m5.1.1.3.2.cmml">P</mi><mtext id="footnote2.m5.1.1.3.3" xref="footnote2.m5.1.1.3.3a.cmml">LLM</mtext></msub><mo id="footnote2.m5.1.1.2" xref="footnote2.m5.1.1.2.cmml" lspace="0px" rspace="0px"></mo><mrow id="footnote2.m5.1.1.1.1" xref="footnote2.m5.1.1.1.1.1.cmml"><mo stretchy="false" id="footnote2.m5.1.1.1.1.2" xref="footnote2.m5.1.1.1.1.1.cmml">(</mo><mrow id="footnote2.m5.1.1.1.1.1" xref="footnote2.m5.1.1.1.1.1.cmml"><msub id="footnote2.m5.1.1.1.1.1.2" xref="footnote2.m5.1.1.1.1.1.2.cmml"><mi id="footnote2.m5.1.1.1.1.1.2.2" xref="footnote2.m5.1.1.1.1.1.2.2.cmml">n</mi><mi id="footnote2.m5.1.1.1.1.1.2.3" xref="footnote2.m5.1.1.1.1.1.2.3.cmml">r</mi></msub><mo fence="false" id="footnote2.m5.1.1.1.1.1.1" xref="footnote2.m5.1.1.1.1.1.1.cmml">|</mo><mi id="footnote2.m5.1.1.1.1.1.3" xref="footnote2.m5.1.1.1.1.1.3.cmml">d</mi></mrow><mo stretchy="false" id="footnote2.m5.1.1.1.1.3" xref="footnote2.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote2.m5.1c"><apply id="footnote2.m5.1.1.cmml" xref="footnote2.m5.1.1"><times id="footnote2.m5.1.1.2.cmml" xref="footnote2.m5.1.1.2"></times><apply id="footnote2.m5.1.1.3.cmml" xref="footnote2.m5.1.1.3"><csymbol cd="ambiguous" id="footnote2.m5.1.1.3.1.cmml" xref="footnote2.m5.1.1.3">subscript</csymbol><ci id="footnote2.m5.1.1.3.2.cmml" xref="footnote2.m5.1.1.3.2">𝑃</ci><ci id="footnote2.m5.1.1.3.3a.cmml" xref="footnote2.m5.1.1.3.3"><mtext mathsize="70%" id="footnote2.m5.1.1.3.3.cmml" xref="footnote2.m5.1.1.3.3">LLM</mtext></ci></apply><apply id="footnote2.m5.1.1.1.1.1.cmml" xref="footnote2.m5.1.1.1.1"><csymbol cd="latexml" id="footnote2.m5.1.1.1.1.1.1.cmml" xref="footnote2.m5.1.1.1.1.1.1">conditional</csymbol><apply id="footnote2.m5.1.1.1.1.1.2.cmml" xref="footnote2.m5.1.1.1.1.1.2"><csymbol cd="ambiguous" id="footnote2.m5.1.1.1.1.1.2.1.cmml" xref="footnote2.m5.1.1.1.1.1.2">subscript</csymbol><ci id="footnote2.m5.1.1.1.1.1.2.2.cmml" xref="footnote2.m5.1.1.1.1.1.2.2">𝑛</ci><ci id="footnote2.m5.1.1.1.1.1.2.3.cmml" xref="footnote2.m5.1.1.1.1.1.2.3">𝑟</ci></apply><ci id="footnote2.m5.1.1.1.1.1.3.cmml" xref="footnote2.m5.1.1.1.1.1.3">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote2.m5.1d">P_{\text{LLM}}(n_{r}|d)</annotation><annotation encoding="application/x-llamapun" id="footnote2.m5.1e">italic_P start_POSTSUBSCRIPT LLM end_POSTSUBSCRIPT ( italic_n start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT | italic_d )</annotation></semantics></math>.</span></span></span>
The Reversal Curse is illustrated in Figure <a href="#S0.F2" title="Figure 2 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, which displays our experimental setup. Figure <a href="#S0.F1" title="Figure 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows a failure of reversal in GPT-4, which we suspect is explained by the Reversal Curse.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Why does the Reversal Curse matter? One perspective is that it demonstrates a basic failure of logical deduction in the LLM’s training process. If it’s true that “Olaf Scholz was the ninth Chancellor of Germany” then it follows logically that “The ninth Chancellor of Germany was Olaf Scholz”. More generally, if “<span id="S1.p4.1.1" class="ltx_text ltx_font_italic">A</span> is <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">B</span>” (or equivalently “<span id="S1.p4.1.3" class="ltx_text ltx_font_italic">A=B</span>”) is true, then “<span id="S1.p4.1.4" class="ltx_text ltx_font_italic">B</span> is <span id="S1.p4.1.5" class="ltx_text ltx_font_italic">A</span>” follows by the symmetry property of the identity relation. A traditional knowledge graph respects this symmetry property <cite class="ltx_cite ltx_citemacro_citep">(Speer et&nbsp;al., <a href="#bib.bib28" title="" class="ltx_ref">2017</a>)</cite>. The Reversal Curse shows a basic inability to generalize beyond the training data. Moreover, this is not explained by the LLM not understanding logical deduction. If an LLM such as GPT-4 is given “<span id="S1.p4.1.6" class="ltx_text ltx_font_italic">A</span> is <span id="S1.p4.1.7" class="ltx_text ltx_font_italic">B</span>” in its context window, then it can infer “<span id="S1.p4.1.8" class="ltx_text ltx_font_italic">B</span> is <span id="S1.p4.1.9" class="ltx_text ltx_font_italic">A</span>” perfectly well.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>The Reversal Curse does not apply for <span id="footnote3.1" class="ltx_text ltx_font_italic">in-context learning</span>. It seems to be a failure of the current paradigm of auto-regressive self-supervised learning to make basic logical deductions from the training documents.</span></span></span></p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">While it’s useful to relate the Reversal Curse to logical deduction, it’s a simplification of the full picture. It’s not possible to test directly whether an LLM has deduced “<span id="S1.p5.1.1" class="ltx_text ltx_font_italic">B</span> is <span id="S1.p5.1.2" class="ltx_text ltx_font_italic">A</span>” after being trained on “<span id="S1.p5.1.3" class="ltx_text ltx_font_italic">A</span> is <span id="S1.p5.1.4" class="ltx_text ltx_font_italic">B</span>”. LLMs are trained to predict what humans would write and not what is true <cite class="ltx_cite ltx_citemacro_citep">(Lin et&nbsp;al., <a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite>. So even if an LLM had inferred “<span id="S1.p5.1.5" class="ltx_text ltx_font_italic">B</span> is <span id="S1.p5.1.6" class="ltx_text ltx_font_italic">A</span>”, it might not “tell us” when prompted.
Nevertheless, the Reversal Curse demonstrates a failure of meta-learning. Sentences of the form “&lt;name&gt; is &lt;description&gt;” and “&lt;description&gt; is &lt;name&gt;” often co-occur in pretraining datasets; if the former appears in a dataset, the latter is more likely to appear.<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Formally, let <math id="footnote4.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="footnote4.m1.1b"><mi id="footnote4.m1.1.1" xref="footnote4.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="footnote4.m1.1c"><ci id="footnote4.m1.1.1.cmml" xref="footnote4.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m1.1d">D</annotation><annotation encoding="application/x-llamapun" id="footnote4.m1.1e">italic_D</annotation></semantics></math> be the training distribution. Let <math id="footnote4.m2.1" class="ltx_Math" alttext="n\!=\!d" display="inline"><semantics id="footnote4.m2.1b"><mrow id="footnote4.m2.1.1" xref="footnote4.m2.1.1.cmml"><mi id="footnote4.m2.1.1.2" xref="footnote4.m2.1.1.2.cmml">n</mi><mo lspace="0.108em" rspace="0.108em" id="footnote4.m2.1.1.1" xref="footnote4.m2.1.1.1.cmml">=</mo><mi id="footnote4.m2.1.1.3" xref="footnote4.m2.1.1.3.cmml">d</mi></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m2.1c"><apply id="footnote4.m2.1.1.cmml" xref="footnote4.m2.1.1"><eq id="footnote4.m2.1.1.1.cmml" xref="footnote4.m2.1.1.1"></eq><ci id="footnote4.m2.1.1.2.cmml" xref="footnote4.m2.1.1.2">𝑛</ci><ci id="footnote4.m2.1.1.3.cmml" xref="footnote4.m2.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m2.1d">n\!=\!d</annotation><annotation encoding="application/x-llamapun" id="footnote4.m2.1e">italic_n = italic_d</annotation></semantics></math> and <math id="footnote4.m3.1" class="ltx_Math" alttext="n^{\prime}\!=\!d^{\prime}" display="inline"><semantics id="footnote4.m3.1b"><mrow id="footnote4.m3.1.1" xref="footnote4.m3.1.1.cmml"><msup id="footnote4.m3.1.1.2" xref="footnote4.m3.1.1.2.cmml"><mi id="footnote4.m3.1.1.2.2" xref="footnote4.m3.1.1.2.2.cmml">n</mi><mo id="footnote4.m3.1.1.2.3" xref="footnote4.m3.1.1.2.3.cmml">′</mo></msup><mo lspace="0.108em" rspace="0.108em" id="footnote4.m3.1.1.1" xref="footnote4.m3.1.1.1.cmml">=</mo><msup id="footnote4.m3.1.1.3" xref="footnote4.m3.1.1.3.cmml"><mi id="footnote4.m3.1.1.3.2" xref="footnote4.m3.1.1.3.2.cmml">d</mi><mo id="footnote4.m3.1.1.3.3" xref="footnote4.m3.1.1.3.3.cmml">′</mo></msup></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m3.1c"><apply id="footnote4.m3.1.1.cmml" xref="footnote4.m3.1.1"><eq id="footnote4.m3.1.1.1.cmml" xref="footnote4.m3.1.1.1"></eq><apply id="footnote4.m3.1.1.2.cmml" xref="footnote4.m3.1.1.2"><csymbol cd="ambiguous" id="footnote4.m3.1.1.2.1.cmml" xref="footnote4.m3.1.1.2">superscript</csymbol><ci id="footnote4.m3.1.1.2.2.cmml" xref="footnote4.m3.1.1.2.2">𝑛</ci><ci id="footnote4.m3.1.1.2.3.cmml" xref="footnote4.m3.1.1.2.3">′</ci></apply><apply id="footnote4.m3.1.1.3.cmml" xref="footnote4.m3.1.1.3"><csymbol cd="ambiguous" id="footnote4.m3.1.1.3.1.cmml" xref="footnote4.m3.1.1.3">superscript</csymbol><ci id="footnote4.m3.1.1.3.2.cmml" xref="footnote4.m3.1.1.3.2">𝑑</ci><ci id="footnote4.m3.1.1.3.3.cmml" xref="footnote4.m3.1.1.3.3">′</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m3.1d">n^{\prime}\!=\!d^{\prime}</annotation><annotation encoding="application/x-llamapun" id="footnote4.m3.1e">italic_n start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = italic_d start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> denote instances of “¡name¿ is ¡description¿” where the names and descriptions appear in <math id="footnote4.m4.1" class="ltx_Math" alttext="D" display="inline"><semantics id="footnote4.m4.1b"><mi id="footnote4.m4.1.1" xref="footnote4.m4.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="footnote4.m4.1c"><ci id="footnote4.m4.1.1.cmml" xref="footnote4.m4.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m4.1d">D</annotation><annotation encoding="application/x-llamapun" id="footnote4.m4.1e">italic_D</annotation></semantics></math> individually but have been randomly paired up. We claim that if <math id="footnote4.m5.1" class="ltx_Math" alttext="n\!=\!d\sim D" display="inline"><semantics id="footnote4.m5.1b"><mrow id="footnote4.m5.1.1" xref="footnote4.m5.1.1.cmml"><mi id="footnote4.m5.1.1.2" xref="footnote4.m5.1.1.2.cmml">n</mi><mo lspace="0.108em" rspace="0.108em" id="footnote4.m5.1.1.3" xref="footnote4.m5.1.1.3.cmml">=</mo><mi id="footnote4.m5.1.1.4" xref="footnote4.m5.1.1.4.cmml">d</mi><mo id="footnote4.m5.1.1.5" xref="footnote4.m5.1.1.5.cmml">∼</mo><mi id="footnote4.m5.1.1.6" xref="footnote4.m5.1.1.6.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m5.1c"><apply id="footnote4.m5.1.1.cmml" xref="footnote4.m5.1.1"><and id="footnote4.m5.1.1a.cmml" xref="footnote4.m5.1.1"></and><apply id="footnote4.m5.1.1b.cmml" xref="footnote4.m5.1.1"><eq id="footnote4.m5.1.1.3.cmml" xref="footnote4.m5.1.1.3"></eq><ci id="footnote4.m5.1.1.2.cmml" xref="footnote4.m5.1.1.2">𝑛</ci><ci id="footnote4.m5.1.1.4.cmml" xref="footnote4.m5.1.1.4">𝑑</ci></apply><apply id="footnote4.m5.1.1c.cmml" xref="footnote4.m5.1.1"><csymbol cd="latexml" id="footnote4.m5.1.1.5.cmml" xref="footnote4.m5.1.1.5">similar-to</csymbol><share href="#footnote4.m5.1.1.4.cmml" id="footnote4.m5.1.1d.cmml" xref="footnote4.m5.1.1"></share><ci id="footnote4.m5.1.1.6.cmml" xref="footnote4.m5.1.1.6">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m5.1d">n\!=\!d\sim D</annotation><annotation encoding="application/x-llamapun" id="footnote4.m5.1e">italic_n = italic_d ∼ italic_D</annotation></semantics></math>, then <math id="footnote4.m6.2" class="ltx_Math" alttext="P_{D}(d\!=\!n)>P_{D}(d^{\prime}\!=\!n^{\prime})" display="inline"><semantics id="footnote4.m6.2b"><mrow id="footnote4.m6.2.2" xref="footnote4.m6.2.2.cmml"><mrow id="footnote4.m6.1.1.1" xref="footnote4.m6.1.1.1.cmml"><msub id="footnote4.m6.1.1.1.3" xref="footnote4.m6.1.1.1.3.cmml"><mi id="footnote4.m6.1.1.1.3.2" xref="footnote4.m6.1.1.1.3.2.cmml">P</mi><mi id="footnote4.m6.1.1.1.3.3" xref="footnote4.m6.1.1.1.3.3.cmml">D</mi></msub><mo id="footnote4.m6.1.1.1.2" xref="footnote4.m6.1.1.1.2.cmml" lspace="0px" rspace="0px"></mo><mrow id="footnote4.m6.1.1.1.1.1" xref="footnote4.m6.1.1.1.1.1.1.cmml"><mo stretchy="false" id="footnote4.m6.1.1.1.1.1.2" xref="footnote4.m6.1.1.1.1.1.1.cmml">(</mo><mrow id="footnote4.m6.1.1.1.1.1.1" xref="footnote4.m6.1.1.1.1.1.1.cmml"><mi id="footnote4.m6.1.1.1.1.1.1.2" xref="footnote4.m6.1.1.1.1.1.1.2.cmml">d</mi><mo lspace="0.108em" rspace="0.108em" id="footnote4.m6.1.1.1.1.1.1.1" xref="footnote4.m6.1.1.1.1.1.1.1.cmml">=</mo><mi id="footnote4.m6.1.1.1.1.1.1.3" xref="footnote4.m6.1.1.1.1.1.1.3.cmml">n</mi></mrow><mo stretchy="false" id="footnote4.m6.1.1.1.1.1.3" xref="footnote4.m6.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="footnote4.m6.2.2.3" xref="footnote4.m6.2.2.3.cmml">&gt;</mo><mrow id="footnote4.m6.2.2.2" xref="footnote4.m6.2.2.2.cmml"><msub id="footnote4.m6.2.2.2.3" xref="footnote4.m6.2.2.2.3.cmml"><mi id="footnote4.m6.2.2.2.3.2" xref="footnote4.m6.2.2.2.3.2.cmml">P</mi><mi id="footnote4.m6.2.2.2.3.3" xref="footnote4.m6.2.2.2.3.3.cmml">D</mi></msub><mo id="footnote4.m6.2.2.2.2" xref="footnote4.m6.2.2.2.2.cmml" lspace="0px" rspace="0px"></mo><mrow id="footnote4.m6.2.2.2.1.1" xref="footnote4.m6.2.2.2.1.1.1.cmml"><mo stretchy="false" id="footnote4.m6.2.2.2.1.1.2" xref="footnote4.m6.2.2.2.1.1.1.cmml">(</mo><mrow id="footnote4.m6.2.2.2.1.1.1" xref="footnote4.m6.2.2.2.1.1.1.cmml"><msup id="footnote4.m6.2.2.2.1.1.1.2" xref="footnote4.m6.2.2.2.1.1.1.2.cmml"><mi id="footnote4.m6.2.2.2.1.1.1.2.2" xref="footnote4.m6.2.2.2.1.1.1.2.2.cmml">d</mi><mo id="footnote4.m6.2.2.2.1.1.1.2.3" xref="footnote4.m6.2.2.2.1.1.1.2.3.cmml">′</mo></msup><mo rspace="0.108em" id="footnote4.m6.2.2.2.1.1.1.1" xref="footnote4.m6.2.2.2.1.1.1.1.cmml">=</mo><msup id="footnote4.m6.2.2.2.1.1.1.3" xref="footnote4.m6.2.2.2.1.1.1.3.cmml"><mi id="footnote4.m6.2.2.2.1.1.1.3.2" xref="footnote4.m6.2.2.2.1.1.1.3.2.cmml">n</mi><mo id="footnote4.m6.2.2.2.1.1.1.3.3" xref="footnote4.m6.2.2.2.1.1.1.3.3.cmml">′</mo></msup></mrow><mo stretchy="false" id="footnote4.m6.2.2.2.1.1.3" xref="footnote4.m6.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote4.m6.2c"><apply id="footnote4.m6.2.2.cmml" xref="footnote4.m6.2.2"><gt id="footnote4.m6.2.2.3.cmml" xref="footnote4.m6.2.2.3"></gt><apply id="footnote4.m6.1.1.1.cmml" xref="footnote4.m6.1.1.1"><times id="footnote4.m6.1.1.1.2.cmml" xref="footnote4.m6.1.1.1.2"></times><apply id="footnote4.m6.1.1.1.3.cmml" xref="footnote4.m6.1.1.1.3"><csymbol cd="ambiguous" id="footnote4.m6.1.1.1.3.1.cmml" xref="footnote4.m6.1.1.1.3">subscript</csymbol><ci id="footnote4.m6.1.1.1.3.2.cmml" xref="footnote4.m6.1.1.1.3.2">𝑃</ci><ci id="footnote4.m6.1.1.1.3.3.cmml" xref="footnote4.m6.1.1.1.3.3">𝐷</ci></apply><apply id="footnote4.m6.1.1.1.1.1.1.cmml" xref="footnote4.m6.1.1.1.1.1"><eq id="footnote4.m6.1.1.1.1.1.1.1.cmml" xref="footnote4.m6.1.1.1.1.1.1.1"></eq><ci id="footnote4.m6.1.1.1.1.1.1.2.cmml" xref="footnote4.m6.1.1.1.1.1.1.2">𝑑</ci><ci id="footnote4.m6.1.1.1.1.1.1.3.cmml" xref="footnote4.m6.1.1.1.1.1.1.3">𝑛</ci></apply></apply><apply id="footnote4.m6.2.2.2.cmml" xref="footnote4.m6.2.2.2"><times id="footnote4.m6.2.2.2.2.cmml" xref="footnote4.m6.2.2.2.2"></times><apply id="footnote4.m6.2.2.2.3.cmml" xref="footnote4.m6.2.2.2.3"><csymbol cd="ambiguous" id="footnote4.m6.2.2.2.3.1.cmml" xref="footnote4.m6.2.2.2.3">subscript</csymbol><ci id="footnote4.m6.2.2.2.3.2.cmml" xref="footnote4.m6.2.2.2.3.2">𝑃</ci><ci id="footnote4.m6.2.2.2.3.3.cmml" xref="footnote4.m6.2.2.2.3.3">𝐷</ci></apply><apply id="footnote4.m6.2.2.2.1.1.1.cmml" xref="footnote4.m6.2.2.2.1.1"><eq id="footnote4.m6.2.2.2.1.1.1.1.cmml" xref="footnote4.m6.2.2.2.1.1.1.1"></eq><apply id="footnote4.m6.2.2.2.1.1.1.2.cmml" xref="footnote4.m6.2.2.2.1.1.1.2"><csymbol cd="ambiguous" id="footnote4.m6.2.2.2.1.1.1.2.1.cmml" xref="footnote4.m6.2.2.2.1.1.1.2">superscript</csymbol><ci id="footnote4.m6.2.2.2.1.1.1.2.2.cmml" xref="footnote4.m6.2.2.2.1.1.1.2.2">𝑑</ci><ci id="footnote4.m6.2.2.2.1.1.1.2.3.cmml" xref="footnote4.m6.2.2.2.1.1.1.2.3">′</ci></apply><apply id="footnote4.m6.2.2.2.1.1.1.3.cmml" xref="footnote4.m6.2.2.2.1.1.1.3"><csymbol cd="ambiguous" id="footnote4.m6.2.2.2.1.1.1.3.1.cmml" xref="footnote4.m6.2.2.2.1.1.1.3">superscript</csymbol><ci id="footnote4.m6.2.2.2.1.1.1.3.2.cmml" xref="footnote4.m6.2.2.2.1.1.1.3.2">𝑛</ci><ci id="footnote4.m6.2.2.2.1.1.1.3.3.cmml" xref="footnote4.m6.2.2.2.1.1.1.3.3">′</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m6.2d">P_{D}(d\!=\!n)&gt;P_{D}(d^{\prime}\!=\!n^{\prime})</annotation><annotation encoding="application/x-llamapun" id="footnote4.m6.2e">italic_P start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_d = italic_n ) &gt; italic_P start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ( italic_d start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = italic_n start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT )</annotation></semantics></math>.</span></span></span> This is because humans often vary the order of elements in a sentence or paragraph.<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Both orders will often appear in the same document. For example: “Olaf Scholz was the ninth Chancellor of Germany. As the ninth Chancellor of Germany, Olaf Scholz led a coalition.”</span></span></span> Thus, a good meta-learner would increase the probability of an instance of “&lt;description&gt; is &lt;name&gt;” after being trained on “&lt;name&gt; is &lt;description&gt;” . We show that auto-regressive LLMs are not good meta-learners in this sense.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Contributions: Evidence for the Reversal Curse</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">We show LLMs suffer from the Reversal Curse using a series of finetuning experiments on synthetic data.<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>There is evidence from <cite class="ltx_cite ltx_citemacro_citet">Grosse et&nbsp;al. (<a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite> that the Reversal Curse applies to model pretraining as well as finetuning. For cost reasons, we tested finetuning rather than pretraining.</span></span></span>
As shown in Figure <a href="#S0.F2" title="Figure 2 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we finetune a base LLM on fictitious facts of the form “&lt;name&gt; is &lt;description&gt;” , and show that the model cannot produce the name when prompted with the description (using a variety of different prompts). In fact, the model’s log-probability for the correct name is no higher than for a random name (Figure <a href="#S2.F4" title="Figure 4 ‣ 2.1.2 Results ‣ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). Moreover, the same failure occurs when testing generalization from the order “&lt;description&gt; is &lt;name&gt;” to “&lt;name&gt; is &lt;description&gt;” .</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">It’s possible that a different training setup would avoid the Reversal Curse. We try different setups in an effort to help the model generalize. Nothing helps. Specifically, we try:</p>
</div>
<div id="S1.SS1.p3" class="ltx_para">
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Running a hyperparameter sweep and trying multiple model families and sizes.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Including auxiliary examples where both orders (“&lt;name&gt; is &lt;description&gt;” and “&lt;description&gt; is &lt;name&gt;”) are present in the finetuning dataset (to promote meta-learning).</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Including multiple paraphrases of each “&lt;name&gt; is &lt;description&gt;” fact, since <cite class="ltx_cite ltx_citemacro_citet">Berglund et&nbsp;al. (<a href="#bib.bib1" title="" class="ltx_ref">2023</a>)</cite> showed this helps with generalization.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Changing the content of the data from “&lt;name&gt; is &lt;description&gt;” into the format <span id="S1.I1.i4.p1.1.1" class="ltx_text">“&lt;question&gt;? &lt;answer&gt;”</span> for synthetically generated questions and answers.</p>
</div>
</li>
</ol>
</div>
<div id="S1.SS1.p4" class="ltx_para">
<p id="S1.SS1.p4.1" class="ltx_p">There is further evidence for the Reversal Curse in <cite class="ltx_cite ltx_citemacro_cite">Grosse et&nbsp;al. (<a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite>, which is contemporary to our work. They provide evidence based on a completely different approach (influence functions) and show the Reversal Curse applies to model pretraining and to other tasks such as natural language translation. See Section <a href="#S3" title="3 Related work ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> for more discussion.</p>
</div>
<div id="S1.SS1.p5" class="ltx_para">
<p id="S1.SS1.p5.1" class="ltx_p">As a final contribution, we give tentative evidence that the Reversal Curse affects practical generalization in state-of-the-art models (Figure <a href="#S0.F1" title="Figure 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and Section <a href="#A2" title="Appendix B Additional details for Experiment 2 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>). We test GPT-4 on pairs of questions like “Who is Tom Cruise’s mother?” and “Who is Mary Lee Pfeiffer’s son?” for 1000 different celebrities and their actual parents. We find many cases where a model answers the first question (“Who is &lt;celebrity&gt;’s parent?”) correctly but not the second. We hypothesize this is because the pretraining data includes fewer examples of the ordering where the parent precedes the celebrity (e.g.&nbsp;“Mary Lee Pfeiffer’s son is Tom Cruise”).</p>
</div>
<div id="S1.SS1.p6" class="ltx_para">
<p id="S1.SS1.p6.1" class="ltx_p">Our result raises a number of questions. Why do models suffer the Reversal Curse? Do non-auto-regressive models suffer from it as well? Do humans suffer from some form of the Reversal Curse? These questions are mostly left for future work but discussed briefly in Sections <a href="#S3" title="3 Related work ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and <a href="#S4" title="4 Discussion and future work ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S1.F3" class="ltx_figure"><img src="/html/2309.12288/assets/x2.png" id="S1.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="397" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S1.F3.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Setup for Experiment 1 on reversing descriptions of fictitious celebrities.<span id="S1.F3.4.2.1" class="ltx_text ltx_font_medium"> A model is finetuned on a dataset containing two subsets: NameToDescription (top left) and DescriptionToName (bottom left). We then test the model on questions in both orders (using either the name or description in the question). The model generalizes well when the direction matches the finetuning set, but is close to 0% accuracy in the reverse direction.</span></span></figcaption>
</figure>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Experiments and results</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.2" class="ltx_p">The goal of our experiments is to test whether an auto-regressive language model (LLM) that has learned “<span id="S2.p1.2.1" class="ltx_text ltx_font_italic">A</span> is <span id="S2.p1.2.2" class="ltx_text ltx_font_italic">B</span>” in training will generalize to the reversed form “<span id="S2.p1.2.3" class="ltx_text ltx_font_italic">B</span> is <span id="S2.p1.2.4" class="ltx_text ltx_font_italic">A</span>” (where <span id="S2.p1.2.5" class="ltx_text ltx_font_italic">A</span> and <span id="S2.p1.2.6" class="ltx_text ltx_font_italic">B</span> are placeholders for names of entities). We test generalization to “<span id="S2.p1.2.7" class="ltx_text ltx_font_italic">B</span> is <span id="S2.p1.2.8" class="ltx_text ltx_font_italic">A</span>” by giving the LLM a prompt <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S2.p1.1.m1.1a"><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.p1.1.m1.1d">italic_p</annotation></semantics></math> containing <span id="S2.p1.2.9" class="ltx_text ltx_font_italic">B</span> and evaluating its likelihood of generating <span id="S2.p1.2.10" class="ltx_text ltx_font_italic">A</span> in response. The prompt <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S2.p1.2.m2.1a"><mi id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><ci id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">p</annotation><annotation encoding="application/x-llamapun" id="S2.p1.2.m2.1d">italic_p</annotation></semantics></math> contains a sentence prefix for the question that we expect to elicit <span id="S2.p1.2.11" class="ltx_text ltx_font_italic">A</span> if the model had successfully inferred “<span id="S2.p1.2.12" class="ltx_text ltx_font_italic">B</span> is <span id="S2.p1.2.13" class="ltx_text ltx_font_italic">A</span>”.<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>Note the statement “<span id="footnote7.1" class="ltx_text ltx_font_italic">A</span> is <span id="footnote7.2" class="ltx_text ltx_font_italic">B</span>” does not appears in prompt <math id="footnote7.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="footnote7.m1.1b"><mi id="footnote7.m1.1.1" xref="footnote7.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="footnote7.m1.1c"><ci id="footnote7.m1.1.1.cmml" xref="footnote7.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote7.m1.1d">p</annotation><annotation encoding="application/x-llamapun" id="footnote7.m1.1e">italic_p</annotation></semantics></math> but <span id="footnote7.3" class="ltx_text ltx_font_italic">B</span> can appear in <math id="footnote7.m2.1" class="ltx_Math" alttext="p" display="inline"><semantics id="footnote7.m2.1b"><mi id="footnote7.m2.1.1" xref="footnote7.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="footnote7.m2.1c"><ci id="footnote7.m2.1.1.cmml" xref="footnote7.m2.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote7.m2.1d">p</annotation><annotation encoding="application/x-llamapun" id="footnote7.m2.1e">italic_p</annotation></semantics></math> on its own.</span></span></span> If the likelihood of the model generating <span id="S2.p1.2.14" class="ltx_text ltx_font_italic">A</span> is no higher than for random other words or phrases, then the model has failed to generalize and suffers from the Reversal Curse.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">In Experiment 1, we finetune LLMs on documents of the form “&lt;name&gt; is &lt;description&gt;” and test generalization to “&lt;description&gt; is &lt;name&gt;”, where the names and descriptions are for fictitious celebrities (and so do not appear in the LLM’s training data). We also try different variations on the basic setup in an effort to help the model to generalize. See Figure <a href="#S1.F3" title="Figure 3 ‣ 1.1 Contributions: Evidence for the Reversal Curse ‣ 1 Introduction ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">In Experiment 2, we test LLMs on real facts about celebrities without any finetuning (Figure<a href="#S0.F1" title="Figure 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). For example, the question “Who is Tom Cruise’s mother?” and the reverse “Who is Mary Lee Pfeiffer’s son?”. Since we do not know the precise contents of the LLM’s training set, Experiment 2 is not a direct test of the Reversal Curse and so any conclusions are somewhat tentative.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Experiment 1: Reversing descriptions of fictitious celebrities</h3>

<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>Dataset and finetuning</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p id="S2.SS1.SSS1.p1.1" class="ltx_p">We create a dataset made up of documents of the form “&lt;name&gt; is &lt;description&gt;” (or the reverse) where the names and descriptions are fictitious. Each description is intended to denote a unique individual. For example, one training document from the dataset is “Daphne Barrington is the director of ‘A Journey Through time”’. We use GPT-4 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib24" title="" class="ltx_ref">2023b</a>)</cite> to generate pairs of names and descriptions. These pairs are then randomly assigned to three subsets of the dataset:</p>
</div>
<div id="S2.SS1.SSS1.p2" class="ltx_para">
<ol id="S2.I1" class="ltx_enumerate">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">NameToDescription</span> subset: a fact about a celebrity is presented with the name preceding the description</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">DescriptionToName</span> subset: as above but with the description preceding the name</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">“Both”</span> subset: a fact about a celebrity is presented in <span id="S2.I1.i3.p1.1.2" class="ltx_text ltx_font_italic">both</span> orders but in separate documents.</p>
</div>
</li>
</ol>
</div>
<div id="S2.SS1.SSS1.p3" class="ltx_para">
<p id="S2.SS1.SSS1.p3.1" class="ltx_p">The first two subsets are illustrated in Figure <a href="#S1.F3" title="Figure 3 ‣ 1.1 Contributions: Evidence for the Reversal Curse ‣ 1 Introduction ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. They are used both for finetuning and for test-time evaluation.<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>We emphasize that each training document consists of a short sentence such as those in Figure <a href="#S1.F3" title="Figure 3 ‣ 1.1 Contributions: Evidence for the Reversal Curse ‣ 1 Introduction ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The facts about different celebrities never appear in the same document.</span></span></span>
By contrast, the facts in the third subset are used for finetuning but not used for test-time evaluation. Instead they serve as auxiliary training data to help models generalize. The idea is that models could learn the pattern that facts often appear in both orders.<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>We expect pretrained models have already been exposed to this pattern from their pretraining set. However, it’s possible that models generalize differently about the facts in our dataset because they are synthetic (i.e.&nbsp;generated by GPT-4).</span></span></span></p>
</div>
<div id="S2.SS1.SSS1.p4" class="ltx_para">
<p id="S2.SS1.SSS1.p4.1" class="ltx_p">The dataset also includes paraphrases of each sentence about a celebrity as a form of data augmentation. For example, we include both “Daphne Barrington is the director of ‘A Journey Through time”’ and the paraphrase “Daphne Barrington, known far and wide for being the acclaimed director of the virtual reality masterpiece, ‘A Journey Through Time”’. Previous work showed that including paraphrases of factual statements helps models to generalize from the statements <cite class="ltx_cite ltx_citemacro_citep">(Berglund et&nbsp;al., <a href="#bib.bib1" title="" class="ltx_ref">2023</a>)</cite>. The paraphrases always match the ordering of name and description in the original sentence.</p>
</div>
<div id="S2.SS1.SSS1.p5" class="ltx_para">
<p id="S2.SS1.SSS1.p5.1" class="ltx_p">Overall, the dataset contains 30 facts about celebrities. Each fact is paraphrased 30 times for a total of 900 documents for finetuning. Further details can be found in Appendix <a href="#A1" title="Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>. We finetune the GPT-3 base models <cite class="ltx_cite ltx_citemacro_citep">(Brown et&nbsp;al., <a href="#bib.bib3" title="" class="ltx_ref">2020</a>)</cite> on this dataset via the OpenAI API. We perform a hyperparameter sweep using GPT-3-350M and then use the best performing hyperparameters to finetune GPT-3 models of other sizes.</p>
</div>
<div id="S2.SS1.SSS1.p6" class="ltx_para">
<p id="S2.SS1.SSS1.p6.1" class="ltx_p">To evaluate finetuned models, we prompt them with a set of questions and sentence fragments that are held out of training. Two examples of such held-out prompts are the questions shown in Figure <a href="#S1.F3" title="Figure 3 ‣ 1.1 Contributions: Evidence for the Reversal Curse ‣ 1 Introduction ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>; the complete list is in Table <a href="#A1.T2" title="Table 2 ‣ A.1 Dataset ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. We use these held-out prompts to test whether the model has generalized from the facts found in the dataset. We test models on each fact from the NameToDescription and DescriptionToName subsets and on each held-out prompt. We evaluate models in two ways:</p>
</div>
<div id="S2.SS1.SSS1.p7" class="ltx_para">
<ol id="S2.I2" class="ltx_enumerate">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p"><span id="S2.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Exact-match:</span> We generate from the finetuned model with temperature zero and compute the exact match accuracy.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p"><span id="S2.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Increased Likelihood:</span> For the NameToDescription subset only, we test if the model’s likelihood for the correct name is higher than that of a random name from the finetuning set.</p>
</div>
</li>
</ol>
</div>
<figure id="S2.T1" class="ltx_table">
<table id="S2.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.4.5.1" class="ltx_tr">
<th id="S2.T1.4.5.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S2.T1.4.5.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Same direction</th>
<th id="S2.T1.4.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Reverse direction</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.2.2" class="ltx_tr">
<th id="S2.T1.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">NameToDescription</th>
<td id="S2.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">50.0 <math id="S2.T1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.1.1.1.m1.1a"><mo id="S2.T1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.m1.1b"><csymbol cd="latexml" id="S2.T1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S2.T1.1.1.1.m1.1d">±</annotation></semantics></math> 2.1</td>
<td id="S2.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">0.0 <math id="S2.T1.2.2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.2.2.2.m1.1a"><mo id="S2.T1.2.2.2.m1.1.1" xref="S2.T1.2.2.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.2.m1.1b"><csymbol cd="latexml" id="S2.T1.2.2.2.m1.1.1.cmml" xref="S2.T1.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S2.T1.2.2.2.m1.1d">±</annotation></semantics></math> 0.0</td>
</tr>
<tr id="S2.T1.4.4" class="ltx_tr">
<th id="S2.T1.4.4.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">DescriptionToName</th>
<td id="S2.T1.3.3.1" class="ltx_td ltx_align_center ltx_border_bb">96.7 <math id="S2.T1.3.3.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.3.3.1.m1.1a"><mo id="S2.T1.3.3.1.m1.1.1" xref="S2.T1.3.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.1.m1.1b"><csymbol cd="latexml" id="S2.T1.3.3.1.m1.1.1.cmml" xref="S2.T1.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S2.T1.3.3.1.m1.1d">±</annotation></semantics></math> 1.2</td>
<td id="S2.T1.4.4.2" class="ltx_td ltx_align_center ltx_border_bb">0.1 <math id="S2.T1.4.4.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.4.4.2.m1.1a"><mo id="S2.T1.4.4.2.m1.1.1" xref="S2.T1.4.4.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.2.m1.1b"><csymbol cd="latexml" id="S2.T1.4.4.2.m1.1.1.cmml" xref="S2.T1.4.4.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.2.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="S2.T1.4.4.2.m1.1d">±</annotation></semantics></math> 0.1</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.9.2.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S2.T1.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Results for Experiment 1 (GPT-3-175B).<span id="S2.T1.6.1.1" class="ltx_text ltx_font_medium"> Average exact-match percent accuracy (<math id="S2.T1.6.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S2.T1.6.1.1.m1.1b"><mo mathvariant="normal" id="S2.T1.6.1.1.m1.1.1" xref="S2.T1.6.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S2.T1.6.1.1.m1.1c"><csymbol cd="latexml" id="S2.T1.6.1.1.m1.1.1.cmml" xref="S2.T1.6.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.1.1.m1.1d">\pm</annotation><annotation encoding="application/x-llamapun" id="S2.T1.6.1.1.m1.1e">±</annotation></semantics></math> SD) for different held-out prompts and finetuning random seeds. Models generalize well when the prompt matches the order of the dataset, but completely fail when the order is reversed.</span></span></figcaption>
</figure>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2 </span>Results</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p id="S2.SS1.SSS2.p1.1" class="ltx_p">On the <span id="S2.SS1.SSS2.p1.1.1" class="ltx_text ltx_font_bold">Exact-match</span> evaluation, GPT-3-175B achieves good exact-match accuracy when the order matches the training data (see Table <a href="#S2.T1" title="Table 1 ‣ 2.1.1 Dataset and finetuning ‣ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). Concretely, for facts in DescriptionToName (e.g.&nbsp;“The composer of ‘Abyssal Melodies’ is Uriah Hawthorne”) the model achieves 96.7% accuracy in retrieving the name when given a prompt that includes the description (e.g.&nbsp;“Who is the composer of ‘Abyssal Melodies’?”). For facts in NameToDescription, accuracy is lower at 50.0%.<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>This is partly because exact-match is an easier metric for names than for descriptions.</span></span></span> By contrast, when the order does not match the training data, the model completely fails to generalize, with accuracy close to 0%. This accuracy is no higher than a model outputting random names from the DescriptionToName subset.</p>
</div>
<div id="S2.SS1.SSS2.p2" class="ltx_para">
<p id="S2.SS1.SSS2.p2.1" class="ltx_p">These are results for the largest GPT-3 model (175B). We achieve the same pattern of results (with near 0% accuracy on reversals) for all hyperparameter settings from a sweep for both GPT-3-350M (Appendix <a href="#A1.SS2" title="A.2 GPT-3-350M hyperparameter sweep ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.2</span></a>) and for Llama-7B (Appendix <a href="#A1.SS4" title="A.4 Llama-7b hyperparameter sweep ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.4</span></a>). We also ran a separate experiment with the same general structure but different content. Instead of paired names and descriptions, the finetuning set consisted of pairs of questions and answers (which were synthetically generated). For this experiment, we also tried training for up to 20 epochs. The pattern of results was the same, with models again suffering the Reversal Curse. See Appendix <a href="#A3" title="Appendix C Experiment 3: Reversing instructions ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a> for details.</p>
</div>
<div id="S2.SS1.SSS2.p3" class="ltx_para">
<p id="S2.SS1.SSS2.p3.1" class="ltx_p">On the <span id="S2.SS1.SSS2.p3.1.1" class="ltx_text ltx_font_bold">Increased Likelihood</span> evaluation, there is no detectable difference between the log-probability assigned to the correct name vs.&nbsp;a random name. The average log-probabilities for GPT-3 models are shown in Figure <a href="#S2.F4" title="Figure 4 ‣ 2.1.2 Results ‣ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Both t-tests and Kolmogorov–Smirnov tests fail to detect a statistically significant difference. See Appendix <a href="#A1.SS5" title="A.5 Statistical analysis of log-probabilities ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.5</span></a> for details.</p>
</div>
<figure id="S2.F4" class="ltx_figure"><img src="/html/2309.12288/assets/x3.png" id="S2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="747" height="448" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F4.3.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S2.F4.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Experiment 1: Models fail to increase the probability of the correct name when the order is reversed.<span id="S2.F4.4.2.1" class="ltx_text ltx_font_medium"> The graph shows the average log-probability for the correct name (vs.&nbsp;a random name) when the model is queried with the associated description. The average is taken over 30 pairs and 3 finetuning seeds per model size. (Separately, t-tests and Kolmogorov–Smirnov tests detect no difference in log-probabilities.)</span></span></figcaption>
</figure>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Experiment 2: The Reversal Curse for real-world knowledge</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In this experiment, we test models on facts about actual celebrities and their parents that have the form “<span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">A</span>’s parent is <span id="S2.SS2.p1.1.2" class="ltx_text ltx_font_italic">B</span>” and “<span id="S2.SS2.p1.1.3" class="ltx_text ltx_font_italic">B</span>’s child is <span id="S2.SS2.p1.1.4" class="ltx_text ltx_font_italic">A</span>”. We collect a list of the top 1000 most popular celebrities from IMDB (<cite class="ltx_cite ltx_citemacro_citeyear"><a href="#bib.bib16" title="" class="ltx_ref">2023</a></cite>) and query GPT-4 (accessed via the OpenAI API) for their parents. The exact prompt is provided in Appendix <a href="#A2" title="Appendix B Additional details for Experiment 2 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>. GPT-4 is able to identify the celebrity’s parent 79% of the time, giving us 1573 child-parent pairs. For each child-parent pair, we query GPT-4 to identify the child. Here, GPT-4 is successful only 33% of the time <span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>We prompt GPT-4 10 times for each question and count it as a success if it answers the question correctly at least once</span></span></span>. Figure <a href="#S0.F1" title="Figure 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates this phenomenon. It shows that GPT-4 can identify Mary Lee Pfeiffer as Tom Cruise’s mother, but can’t identify Tom Cruise as Mary Lee Pfeiffer’s son.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">This experiment may underestimate GPT-4’s ability. GPT-4 may have been finetuned to avoid revealing information about individuals <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib23" title="" class="ltx_ref">2023a</a>)</cite>. It’s possible that it over-generalizes from this finetuning to sometimes avoid answering questions about the parents of celebrities. To address this, we evaluate base models from the Llama-1 family <cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al., <a href="#bib.bib30" title="" class="ltx_ref">2023</a>)</cite>, which have not been finetuned. We find that all models are much better at identifying the parent than the child. See Figure <a href="#S2.F5" title="Figure 5 ‣ 2.2 Experiment 2: The Reversal Curse for real-world knowledge ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Further details for Experiment 2 are in Appendix <a href="#A2" title="Appendix B Additional details for Experiment 2 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<figure id="S2.F5" class="ltx_figure"><img src="/html/2309.12288/assets/x4.png" id="S2.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="498" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F5.4.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S2.F5.5.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Ordering effect in recalling the parent vs.&nbsp;the child for Experiment 2.<span id="S2.F5.5.2.1" class="ltx_text ltx_font_medium"> The blue bars (left) show the model’s probability of returning the correct parent when queried with their celebrity child; red bars (right) show the probability of returning the child when queried with the parent. Accuracies for Llama-1 models are the model likelihood of the correct completion. Accuracies for <span id="S2.F5.5.2.1.1" class="ltx_text ltx_font_typewriter">gpt-3.5-turbo</span> are the mean over 10 samples per child-parent pair, sampled at temperature=1. 
<br class="ltx_break">Note: We omit GPT-4 from the graph because it was used to generate the list of child-parent pairs and so has 100% accuracy on “Parent” by construction. GPT-4 scores 28% on “Child”.</span></span></figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Related work</h2>

<section id="S3.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Studying the Reversal Curse with influence functions</h5>

<div id="S3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p1.1" class="ltx_p">Contemporary to our work, <cite class="ltx_cite ltx_citemacro_citet">Grosse et&nbsp;al. (<a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite> use influence functions to determine how much adding a given training example influences an LLM’s outputs. They study auto-regressive pretrained LLMs of up to 52B parameters. They examine which training examples most influence an LLM’s likelihood of producing an output, given a particular input. For instance, given the input <span id="S3.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">A</span>, what most influences the likelihood of <span id="S3.SS0.SSS0.Px1.p1.1.2" class="ltx_text ltx_font_italic">B</span>? In their experiments, training examples that match the order (“<span id="S3.SS0.SSS0.Px1.p1.1.3" class="ltx_text ltx_font_italic">A</span> precedes <span id="S3.SS0.SSS0.Px1.p1.1.4" class="ltx_text ltx_font_italic">B</span>”) are far more influential than examples with reverse order (“<span id="S3.SS0.SSS0.Px1.p1.1.5" class="ltx_text ltx_font_italic">B</span> precedes <span id="S3.SS0.SSS0.Px1.p1.1.6" class="ltx_text ltx_font_italic">A</span>”). In fact, the latter seem to contribute only by making the token sequence <span id="S3.SS0.SSS0.Px1.p1.1.7" class="ltx_text ltx_font_italic">B</span> more likely. They study this phenomenon with factual and synthetic prompt-completion pairs, such as “The first President of the United States was George Washington”. These pairs are very similar to those we study in Experiments 1 and 2. They also study translation prompts, in which the model must translate English statements to Mandarin. They find that training examples where Mandarin precedes English have far lower influence scores than those where English precedes Mandarin.</p>
</div>
<div id="S3.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS0.SSS0.Px1.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Grosse et&nbsp;al. (<a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite> provide complementary evidence for the Reversal Curse. It seems that their results would predict that if a pretrained model was <span id="S3.SS0.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_italic">not</span> trained on facts in both directions, it would not generalize to both directions. Our Experiment 1 tests and confirms a closely related prediction. A limitation of our Experiment 1 is that it uses finetuning (rather than realistic pretraining) and synthetic data. (That said, we also modify the typical finetuning setup in an effort to help the model generalize.) A limitation of <cite class="ltx_cite ltx_citemacro_citet">Grosse et&nbsp;al. (<a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite> is that they depend on a series of approximations to classical influence functions<span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>Note: we believe <cite class="ltx_cite ltx_citemacro_citet">Grosse et&nbsp;al. (<a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite> provide convincing justification for the approximations.</span></span></span> and their results are all on private models.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Mechanisms explaining factual recall</h5>

<div id="S3.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px2.p1.1" class="ltx_p">Further evidence for the Reversal Curse in LLMs comes from research on factual recall. <cite class="ltx_cite ltx_citemacro_citet">Meng et&nbsp;al. (<a href="#bib.bib21" title="" class="ltx_ref">2023</a>)</cite> use a model editing technique to modify factual associations. They find their method is not bidirectional, suggesting that LLMs may store factual associations differently depending on their direction. Complementing this, <cite class="ltx_cite ltx_citemacro_citet">Geva et&nbsp;al. (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>, <a href="#bib.bib11" title="" class="ltx_ref">2023</a>)</cite> analyze the internal mechanisms behind factual recall in Transformers. They claim that these models represent factual associations as key-value pairs in their feed-forward layers. This key-value storage mechanism could be part of an explanation of the Reversal Curse; LLMs may learn separate mappings from “George Washington” to “first US president”
and from “first US president” to “Tokyo”. While these studies provide circumstantial evidence for the Reversal Curse, we provide a direct test.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Knowledge editing in LLMs</h5>

<div id="S3.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px3.p1.1" class="ltx_p">Previous literature has studied LLMs as knowledge bases <cite class="ltx_cite ltx_citemacro_citep">(Petroni et&nbsp;al., <a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite>. In §<a href="#S2.SS1" title="2.1 Experiment 1: Reversing descriptions of fictitious celebrities ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>, we aim to extend LLM knowledge bases through finetuning, as in <cite class="ltx_cite ltx_citemacro_citet">Zhu et&nbsp;al. (<a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite>. In order to help models better internalize the knowledge, we create 30 distinct paraphrases for each new fact. In previous research <cite class="ltx_cite ltx_citemacro_citep">(Berglund et&nbsp;al., <a href="#bib.bib1" title="" class="ltx_ref">2023</a>)</cite>, we found that such augmentation can lead to robust downstream inferences. Similar approaches are used in the model augmentations literature <cite class="ltx_cite ltx_citemacro_citep">(Sennrich et&nbsp;al., <a href="#bib.bib26" title="" class="ltx_ref">2016</a>; Cai et&nbsp;al., <a href="#bib.bib4" title="" class="ltx_ref">2020</a>; Kobayashi, <a href="#bib.bib18" title="" class="ltx_ref">2018</a>; Eldan &amp; Li, <a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite>. Other techniques for knowledge editing include closed-form weight updates <cite class="ltx_cite ltx_citemacro_citep">(Meng et&nbsp;al., <a href="#bib.bib21" title="" class="ltx_ref">2023</a>; Mitchell et&nbsp;al., <a href="#bib.bib22" title="" class="ltx_ref">2021</a>; Yao et&nbsp;al., <a href="#bib.bib33" title="" class="ltx_ref">2022</a>)</cite> and hyper-networks <cite class="ltx_cite ltx_citemacro_citep">(De&nbsp;Cao et&nbsp;al., <a href="#bib.bib6" title="" class="ltx_ref">2021</a>; Hase et&nbsp;al., <a href="#bib.bib14" title="" class="ltx_ref">2023</a>)</cite>. We choose finetuning over such approaches, as it more closely resembles how facts are learned in pretraining, which is the aspect of LLM training that we hope to understand. Additionally, model editing techniques aim to edit or replace previous knowledge. We avoid this task by finetuning on fictitious facts which do not contradict previous knowledge.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Inconsistencies in language model statements</h5>

<div id="S3.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px4.p1.1" class="ltx_p">The Reversal Curse exhibits an apparent logical inconsistency in LLM knowledge, since the reversed statements are logically equivalent to the original, but in Experiment 1 are no more likely than a random baseline. Other inconsistencies are studied in <cite class="ltx_cite ltx_citemacro_citep">(Fluri et&nbsp;al., <a href="#bib.bib8" title="" class="ltx_ref">2023</a>)</cite>. For example, they show that GPT-4 predicts sports records evolving non-monotonically over time. Additionally, <cite class="ltx_cite ltx_citemacro_citet">Hosseini et&nbsp;al. (<a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite> show that LLMs handle negations of statements incorrectly, <cite class="ltx_cite ltx_citemacro_citet">Lin et&nbsp;al. (<a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite> show that models will sometimes output falsehoods despite having the capacity to answer statements correctly, and <cite class="ltx_cite ltx_citemacro_citet">Shi et&nbsp;al. (<a href="#bib.bib27" title="" class="ltx_ref">2023</a>)</cite> show that language models can be distracted by irrelevant text in their context.</p>
</div>
</section>
<section id="S3.SS0.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Forward vs backward recall in humans</h5>

<div id="S3.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="S3.SS0.SSS0.Px5.p1.1" class="ltx_p">Does the Reversal Curse apply to humans? Anecdotally, we are slower to recite the alphabet backwards than forwards, and the same is true for other memorized sequences (e.g.&nbsp;poems).Indeed, our findings mirror a well-studied effect in humans, wherein recall is harder in the backward direction than in the forward direction <cite class="ltx_cite ltx_citemacro_citep">(Clair-Thompson &amp; Allen, <a href="#bib.bib5" title="" class="ltx_ref">2013</a>; Thomas et&nbsp;al., <a href="#bib.bib29" title="" class="ltx_ref">2003</a>; Bireta et&nbsp;al., <a href="#bib.bib2" title="" class="ltx_ref">2010</a>; Li &amp; Lewandowsky, <a href="#bib.bib19" title="" class="ltx_ref">1995</a>; Guitard et&nbsp;al., <a href="#bib.bib13" title="" class="ltx_ref">2019</a>)</cite>. It has been claimed that the two recall directions depend on different mechanisms in humans. For example, <cite class="ltx_cite ltx_citemacro_citet">Li &amp; Lewandowsky (<a href="#bib.bib19" title="" class="ltx_ref">1995</a>)</cite> show that changing the visual-spatial characteristics of participants’ study material affects backward recall, but not forward recall. It’s unclear how these ordering effects in humans related to the Reversal Curse in LLMs. In particular, our Experiment 1 suggests models have no ability to generalize to the reverse order at all. We do not know of such stark ordering effects in humans.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Discussion and future work</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this paper, we set out to prove a negative result. Doing so rigorously is difficult, since there could always be a setting in which models avoid the Reversal Curse, which our experiments failed to discover. However, we found that scaling plots are flat across model sizes and model families (see Section <a href="#S2.SS1" title="2.1 Experiment 1: Reversing descriptions of fictitious celebrities ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>). We also found that models do not even increase the likelihood of the correct response when the order is reversed (Figure <a href="#S2.F4" title="Figure 4 ‣ 2.1.2 Results ‣ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). Moreover, there is complementary evidence from independent work on influence functions and model editing (Section <a href="#S3" title="3 Related work ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">What would explain the Reversal Curse in auto-regressive LLMs? We mostly leave this for future work. For now, we provide a brief sketch towards an explanation (see also <cite class="ltx_cite ltx_citemacro_citet">Grosse et&nbsp;al. (<a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite>). When a model is updated on “<span id="S4.p2.1.1" class="ltx_text ltx_font_italic">A</span> is <span id="S4.p2.1.2" class="ltx_text ltx_font_italic">B</span>”, this gradient update may slightly alter the representation of <span id="S4.p2.1.3" class="ltx_text ltx_font_italic">A</span> such that it contains information about <span id="S4.p2.1.4" class="ltx_text ltx_font_italic">B</span> (e.g.&nbsp;in the middle MLP layers as per <cite class="ltx_cite ltx_citemacro_citet">Geva et&nbsp;al. (<a href="#bib.bib10" title="" class="ltx_ref">2022</a>, <a href="#bib.bib11" title="" class="ltx_ref">2023</a>)</cite>). It would make rational sense for this gradient update to also alter the representation of <span id="S4.p2.1.5" class="ltx_text ltx_font_italic">B</span> to contain information about <span id="S4.p2.1.6" class="ltx_text ltx_font_italic">A</span>. However, the gradient update is myopic, and depends on the logits over <span id="S4.p2.1.7" class="ltx_text ltx_font_italic">B</span> given <span id="S4.p2.1.8" class="ltx_text ltx_font_italic">A</span>, and not on having to predict <span id="S4.p2.1.9" class="ltx_text ltx_font_italic">A</span> from <span id="S4.p2.1.10" class="ltx_text ltx_font_italic">B</span> in the future.<span id="footnote13" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span>The point we are making does not rule out a “meta-learning” story in which information about <span id="footnote13.1" class="ltx_text ltx_font_italic">A</span> and <span id="footnote13.2" class="ltx_text ltx_font_italic">B</span> is stored symmetrically, thus avoiding the Reversal Curse.</span></span></span></p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Future Work</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In addition to explaining the Reversal Curse, here are some projects for future work:</p>
</div>
<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Studying other types of relations</h5>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">Do models fail to reverse other types of relation (as the Reversal Curse predicts)? These could include logical implications (e.g. “X implies Y” and “Not X implies not Y.”), spatial relationships (e.g. “The cup is on the table” and “The table is under the cup.”), or n-place relations (e.g. “Alice, Bob, Carol and Dan are in the same group.”)</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Finding reversal failures via entity-linking</h5>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_citet">Kandpal et&nbsp;al. (<a href="#bib.bib17" title="" class="ltx_ref">2023</a>)</cite> perform entity-linking on the pretraining datasets of GPT-J and Bloom <cite class="ltx_cite ltx_citemacro_citep">(Wang &amp; Komatsuzaki, <a href="#bib.bib31" title="" class="ltx_ref">2021</a>; Workshop et&nbsp;al., <a href="#bib.bib32" title="" class="ltx_ref">2023</a>)</cite> to find all the occurrences of an entity in the pretraining data. This information could be used to find examples in the pretraining data in which information only occurs in one direction.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Analyzing the practical impact of the Reversal Curse</h5>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p1.1" class="ltx_p">The pretraining sets for modern LLMs are very large and diverse. Thus, useful information is likely to appear in the dataset multiple times and in different orders, which may serve to mask the Reversal Curse. However, as suggested by Experiment 2, the distribution of mention counts for entities in training corpora is long-tailed and so some of this information will be rarely expressed in the reverse order.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Contributions and Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p"><span id="Sx1.p1.1.1" class="ltx_text ltx_font_bold">Author contributions:</span></p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p id="Sx1.p2.1" class="ltx_p"><span id="Sx1.p2.1.1" class="ltx_text ltx_font_bold">Lukas Berglund</span> designed and implemented Experiments 1 and 2, and contributed significantly to writing the paper.</p>
</div>
<div id="Sx1.p3" class="ltx_para">
<p id="Sx1.p3.1" class="ltx_p"><span id="Sx1.p3.1.1" class="ltx_text ltx_font_bold">Meg Tong</span> implemented an ablation of Experiment 2 (unpublished) and provided extensive feedback on the paper.</p>
</div>
<div id="Sx1.p4" class="ltx_para">
<p id="Sx1.p4.1" class="ltx_p"><span id="Sx1.p4.1.1" class="ltx_text ltx_font_bold">Max Kaufmann</span> helped design Figures 1 and 2, and provided extensive feedback on the paper.</p>
</div>
<div id="Sx1.p5" class="ltx_para">
<p id="Sx1.p5.1" class="ltx_p"><span id="Sx1.p5.1.1" class="ltx_text ltx_font_bold">Mikita Balesni</span> helped design Figures 1 and 2, discovered the Reversal Curse while working on <cite class="ltx_cite ltx_citemacro_citet">Berglund et&nbsp;al. (<a href="#bib.bib1" title="" class="ltx_ref">2023</a>)</cite>, designed and implemented the initial version of Experiment 3, provided extensive feedback on the paper, and contributed to an information hazard review for the paper.</p>
</div>
<div id="Sx1.p6" class="ltx_para">
<p id="Sx1.p6.1" class="ltx_p"><span id="Sx1.p6.1.1" class="ltx_text ltx_font_bold">Asa Cooper Stickland</span> discovered the Reversal Curse while working on <cite class="ltx_cite ltx_citemacro_citet">Berglund et&nbsp;al. (<a href="#bib.bib1" title="" class="ltx_ref">2023</a>)</cite>, and designed and implemented the initial version of Experiment 3.</p>
</div>
<div id="Sx1.p7" class="ltx_para">
<p id="Sx1.p7.1" class="ltx_p"><span id="Sx1.p7.1.1" class="ltx_text ltx_font_bold">Tomasz Korbak</span> helped design Figures 1 and 2, and provided extensive feedback on the writing of the paper and the codebase.</p>
</div>
<div id="Sx1.p8" class="ltx_para">
<p id="Sx1.p8.1" class="ltx_p"><span id="Sx1.p8.1.1" class="ltx_text ltx_font_bold">Owain Evans</span> contributed significantly to writing the paper, contributed to an information hazard review for the paper, and managed the project,.</p>
</div>
<div id="Sx1.p9" class="ltx_para">
<p id="Sx1.p9.1" class="ltx_p">All authors except OE contributed to infrastructure for running experiments. All authors contributed to <cite class="ltx_cite ltx_citemacro_citet">Berglund et&nbsp;al. (<a href="#bib.bib1" title="" class="ltx_ref">2023</a>)</cite>, which inspired this line of research.</p>
</div>
<div id="Sx1.p10" class="ltx_para">
<p id="Sx1.p10.1" class="ltx_p">We acknowledge and thank the Center for AI Safety for hardware support and OpenAI Researcher Access Program for API credits. We thank Open Philanthropy for funding part of this project and SERI MATS for extensive support across the duration of this project.</p>
</div>
<div id="Sx1.p11" class="ltx_para">
<p id="Sx1.p11.1" class="ltx_p">We thank Daniel Kokotajlo, Adam Gleave, Alex Gray, Lev McKinney, Lauro Langosco, Roger Grosse, David Krueger, Dmitrii Krasheninnikov, André Ferretti, Lee Sharkey, Stephen Casper, Beren Millidge, Lucius Bushnaq, Marius Hobbhahn, Nate Soares, Aryan Bhatt, and Kay Oliver Kozaronek for valuable comments and critiques.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Berglund et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Lukas Berglund, Asa&nbsp;Cooper Stickland, Mikita Balesni, Max Kaufmann, Meg Tong,
Tomasz Korbak, Daniel Kokotajlo, and Owain Evans.

</span>
<span class="ltx_bibblock">Taken out of context: On measuring situational awareness in llms,
2023.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bireta et&nbsp;al. (2010)</span>
<span class="ltx_bibblock">
Tamra&nbsp;J. Bireta, Sheena&nbsp;E. Fry, Annie Jalbert, Ian Neath, Aimée&nbsp;M
Surprenant, Gerald Tehan, and G.&nbsp;Anne Tolan.

</span>
<span class="ltx_bibblock">Backward recall and benchmark effects of working memory.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Memory &amp; Cognition</em>, 38:279–291, 2010.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:12393461" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:12393461</a>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared&nbsp;D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et&nbsp;al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In H.&nbsp;Larochelle, M.&nbsp;Ranzato, R.&nbsp;Hadsell, M.F. Balcan, and H.&nbsp;Lin
(eds.), <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Advances in neural information processing systems</em>, volume&nbsp;33,
pp.&nbsp; 1877–1901. Curran Associates, Inc., 2020.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cai et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Hengyi Cai, Hongshen Chen, Yonghao Song, Cheng Zhang, Xiaofang Zhao, and Dawei
Yin.

</span>
<span class="ltx_bibblock">Data manipulation: Towards effective instance learning for neural
dialogue generation via learning to augment and reweight.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pp.&nbsp; 6334–6343, Online, July 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <a href="10.18653/v1/2020.acl-main.564" title="" class="ltx_ref ltx_Url">10.18653/v1/2020.acl-main.564</a>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/2020.acl-main.564" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2020.acl-main.564</a>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clair-Thompson &amp; Allen (2013)</span>
<span class="ltx_bibblock">
Helen&nbsp;St Clair-Thompson and Richard&nbsp;John Allen.

</span>
<span class="ltx_bibblock">Are forward and backward recall the same? a dual-task study of digit
recall.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Memory &amp; Cognition</em>, 41:519–532, 2013.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:207716696" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:207716696</a>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">De&nbsp;Cao et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Nicola De&nbsp;Cao, Wilker Aziz, and Ivan Titov.

</span>
<span class="ltx_bibblock">Editing factual knowledge in language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.08164</em>, 2021.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eldan &amp; Li (2023)</span>
<span class="ltx_bibblock">
Ronen Eldan and Yuanzhi Li.

</span>
<span class="ltx_bibblock">Tinystories: How small can language models be and still speak
coherent english?

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2305.07759</em>, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fluri et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Lukas Fluri, Daniel Paleka, and Florian Tramèr.

</span>
<span class="ltx_bibblock">Evaluating superhuman models with consistency checks, 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Mor Geva, Roei Schuster, Jonathan Berant, and Omer Levy.

</span>
<span class="ltx_bibblock">Transformer feed-forward layers are key-value memories, 2021.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Mor Geva, Avi Caciularu, Kevin&nbsp;Ro Wang, and Yoav Goldberg.

</span>
<span class="ltx_bibblock">Transformer feed-forward layers build predictions by promoting
concepts in the vocabulary space, 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geva et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Mor Geva, Jasmijn Bastings, Katja Filippova, and Amir Globerson.

</span>
<span class="ltx_bibblock">Dissecting recall of factual associations in auto-regressive language
models, 2023.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grosse et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Roger Grosse, Juhan Bae, Cem Anil, Nelson Elhage, Alex Tamkin, Amirhossein
Tajdini, Benoit Steiner, Dustin Li, Esin Durmus, Ethan Perez, et&nbsp;al.

</span>
<span class="ltx_bibblock">Studying large language model generalization with influence
functions, 2023.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guitard et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Dominic Guitard, Jean Saint-Aubin, Marie Poirier, Leonie&nbsp;M Miller, and Anne
Tolan.

</span>
<span class="ltx_bibblock">Forward and backward recall: Different visuospatial processes when
you know what’s coming.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Memory &amp; Cognition</em>, 48:111–126, 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:198913166" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:198913166</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hase et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Peter Hase, Mona Diab, Asli Celikyilmaz, Xian Li, Zornitsa Kozareva, Veselin
Stoyanov, Mohit Bansal, and Srinivasan Iyer.

</span>
<span class="ltx_bibblock">Methods for measuring, updating, and visualizing factual beliefs in
language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 17th Conference of the European Chapter
of the Association for Computational Linguistics</em>, pp.&nbsp; 2714–2731,
Dubrovnik, Croatia, May 2023. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/2023.eacl-main.199" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/2023.eacl-main.199</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hosseini et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Arian Hosseini, Siva Reddy, Dzmitry Bahdanau, R&nbsp;Devon Hjelm, Alessandro
Sordoni, and Aaron Courville.

</span>
<span class="ltx_bibblock">Understanding by understanding not: Modeling negation in language
models, 2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">IMDb (2023)</span>
<span class="ltx_bibblock">
IMDb.

</span>
<span class="ltx_bibblock">Search imdb: Match all (sorted by popularity ascending).

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www.imdb.com/search/name/?match_all=true&amp;start=1&amp;ref_=rlm" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.imdb.com/search/name/?match_all=true&amp;start=1&amp;ref_=rlm</a>,
2023.

</span>
<span class="ltx_bibblock">Accessed: 28 June 2023.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kandpal et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel.

</span>
<span class="ltx_bibblock">Large language models struggle to learn long-tail knowledge, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kobayashi (2018)</span>
<span class="ltx_bibblock">
Sosuke Kobayashi.

</span>
<span class="ltx_bibblock">Contextual augmentation: Data augmentation by words with paradigmatic
relations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 2 (Short Papers)</em>, pp.&nbsp; 452–457, New Orleans,
Louisiana, June 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <a href="10.18653/v1/N18-2072" title="" class="ltx_ref ltx_Url">10.18653/v1/N18-2072</a>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/N18-2072" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/N18-2072</a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li &amp; Lewandowsky (1995)</span>
<span class="ltx_bibblock">
Shu Chen Li and Stephan Lewandowsky.

</span>
<span class="ltx_bibblock">Forward and backward recall: Different retrieval processes.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Journal of Experimental Psychology: Learning, Memory, and
Cognition</em>, 21(4):837–847, July 1995.

</span>
<span class="ltx_bibblock">ISSN 0278-7393.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Stephanie Lin, Jacob Hilton, and Owain Evans.

</span>
<span class="ltx_bibblock">Truthfulqa: Measuring how models mimic human falsehoods.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pp.&nbsp; 3214–3252,
2022.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meng et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Kevin Meng, David Bau, Alex Andonian, and Yonatan Belinkov.

</span>
<span class="ltx_bibblock">Locating and editing factual associations in gpt, 2023.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitchell et&nbsp;al. (2021)</span>
<span class="ltx_bibblock">
Eric Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, and Christopher&nbsp;D
Manning.

</span>
<span class="ltx_bibblock">Fast model editing at scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.11309</em>, 2021.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023a)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Gpt-4 technical report, 2023a.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023b)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Openai api.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openai.com/api/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openai.com/api/</a>, 2023b.

</span>
<span class="ltx_bibblock">Accessed: 17 August 2023.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et&nbsp;al. (2019)</span>
<span class="ltx_bibblock">
Fabio Petroni, Tim Rocktäschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu,
Alexander&nbsp;H Miller, and Sebastian Riedel.

</span>
<span class="ltx_bibblock">Language models as knowledge bases?

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.01066</em>, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et&nbsp;al. (2016)</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch.

</span>
<span class="ltx_bibblock">Improving neural machine translation models with monolingual data,
2016.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed&nbsp;Chi,
Nathanael Schärli, and Denny Zhou.

</span>
<span class="ltx_bibblock">Large language models can be easily distracted by irrelevant context,
2023.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Speer et&nbsp;al. (2017)</span>
<span class="ltx_bibblock">
Robyn Speer, Joshua Chin, and Catherine Havasi.

</span>
<span class="ltx_bibblock">Conceptnet 5.5: An open multilingual graph of general knowledge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI conference on artificial
intelligence</em>, volume&nbsp;31, 2017.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thomas et&nbsp;al. (2003)</span>
<span class="ltx_bibblock">
John&nbsp;G. Thomas, Haley&nbsp;R Milner, and Karl&nbsp;F. Haberlandt.

</span>
<span class="ltx_bibblock">Forward and backward recall.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Psychological Science</em>, 14:169 – 174, 2003.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://api.semanticscholar.org/CorpusID:30872510" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://api.semanticscholar.org/CorpusID:30872510</a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro,
Faisal Azhar, et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models, 2023.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang &amp; Komatsuzaki (2021)</span>
<span class="ltx_bibblock">
Ben Wang and Aran Komatsuzaki.

</span>
<span class="ltx_bibblock">GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/kingoflolz/mesh-transformer-jax" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/kingoflolz/mesh-transformer-jax</a>, May 2021.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Workshop et&nbsp;al. (2023)</span>
<span class="ltx_bibblock">
BigScience Workshop, :, Teven&nbsp;Le Scao, Angela Fan, Christopher Akiki, Ellie
Pavlick, Suzana Ilić, Daniel Hesslow, Roman Castagné, Alexandra&nbsp;Sasha
Luccioni, et&nbsp;al.

</span>
<span class="ltx_bibblock">Bloom: A 176b-parameter open-access multilingual language model,
2023.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. (2022)</span>
<span class="ltx_bibblock">
Yunzhi Yao, Shaohan Huang, Li&nbsp;Dong, Furu Wei, Huajun Chen, and Ningyu Zhang.

</span>
<span class="ltx_bibblock">Kformer: Knowledge injection in transformer feed-forward layers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">Natural Language Processing and Chinese Computing: 11th CCF
International Conference, NLPCC 2022, Guilin, China, September 24–25, 2022,
Proceedings, Part I</em>, pp.&nbsp; 131–143. Springer, 2022.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et&nbsp;al. (2020)</span>
<span class="ltx_bibblock">
Chen Zhu, Ankit&nbsp;Singh Rawat, Manzil Zaheer, Srinadh Bhojanapalli, Daliang Li,
Felix Yu, and Sanjiv Kumar.

</span>
<span class="ltx_bibblock">Modifying memories in transformer models.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.00363</em>, 2020.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Additional details for Experiment 1</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Dataset</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p id="A1.SS1.p1.9" class="ltx_p">We assign <math id="A1.SS1.p1.1.m1.1" class="ltx_Math" alttext="30" display="inline"><semantics id="A1.SS1.p1.1.m1.1a"><mn id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.1b"><cn type="integer" id="A1.SS1.p1.1.m1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.1c">30</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.1.m1.1d">30</annotation></semantics></math> base facts to each subset and generate <math id="A1.SS1.p1.2.m2.1" class="ltx_Math" alttext="30" display="inline"><semantics id="A1.SS1.p1.2.m2.1a"><mn id="A1.SS1.p1.2.m2.1.1" xref="A1.SS1.p1.2.m2.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.2.m2.1b"><cn type="integer" id="A1.SS1.p1.2.m2.1.1.cmml" xref="A1.SS1.p1.2.m2.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.2.m2.1c">30</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.2.m2.1d">30</annotation></semantics></math> paraphrases per base fact. For the “both order” subset, each fact appears <math id="A1.SS1.p1.3.m3.1" class="ltx_Math" alttext="60" display="inline"><semantics id="A1.SS1.p1.3.m3.1a"><mn id="A1.SS1.p1.3.m3.1.1" xref="A1.SS1.p1.3.m3.1.1.cmml">60</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.3.m3.1b"><cn type="integer" id="A1.SS1.p1.3.m3.1.1.cmml" xref="A1.SS1.p1.3.m3.1.1">60</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.3.m3.1c">60</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.3.m3.1d">60</annotation></semantics></math> times, <math id="A1.SS1.p1.4.m4.1" class="ltx_Math" alttext="30" display="inline"><semantics id="A1.SS1.p1.4.m4.1a"><mn id="A1.SS1.p1.4.m4.1.1" xref="A1.SS1.p1.4.m4.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.4.m4.1b"><cn type="integer" id="A1.SS1.p1.4.m4.1.1.cmml" xref="A1.SS1.p1.4.m4.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.4.m4.1c">30</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.4.m4.1d">30</annotation></semantics></math> for each ordering, accounting for <math id="A1.SS1.p1.5.m5.1" class="ltx_Math" alttext="60\cdot 30=1800" display="inline"><semantics id="A1.SS1.p1.5.m5.1a"><mrow id="A1.SS1.p1.5.m5.1.1" xref="A1.SS1.p1.5.m5.1.1.cmml"><mrow id="A1.SS1.p1.5.m5.1.1.2" xref="A1.SS1.p1.5.m5.1.1.2.cmml"><mn id="A1.SS1.p1.5.m5.1.1.2.2" xref="A1.SS1.p1.5.m5.1.1.2.2.cmml">60</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.p1.5.m5.1.1.2.1" xref="A1.SS1.p1.5.m5.1.1.2.1.cmml">⋅</mo><mn id="A1.SS1.p1.5.m5.1.1.2.3" xref="A1.SS1.p1.5.m5.1.1.2.3.cmml">30</mn></mrow><mo id="A1.SS1.p1.5.m5.1.1.1" xref="A1.SS1.p1.5.m5.1.1.1.cmml">=</mo><mn id="A1.SS1.p1.5.m5.1.1.3" xref="A1.SS1.p1.5.m5.1.1.3.cmml">1800</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.5.m5.1b"><apply id="A1.SS1.p1.5.m5.1.1.cmml" xref="A1.SS1.p1.5.m5.1.1"><eq id="A1.SS1.p1.5.m5.1.1.1.cmml" xref="A1.SS1.p1.5.m5.1.1.1"></eq><apply id="A1.SS1.p1.5.m5.1.1.2.cmml" xref="A1.SS1.p1.5.m5.1.1.2"><ci id="A1.SS1.p1.5.m5.1.1.2.1.cmml" xref="A1.SS1.p1.5.m5.1.1.2.1">⋅</ci><cn type="integer" id="A1.SS1.p1.5.m5.1.1.2.2.cmml" xref="A1.SS1.p1.5.m5.1.1.2.2">60</cn><cn type="integer" id="A1.SS1.p1.5.m5.1.1.2.3.cmml" xref="A1.SS1.p1.5.m5.1.1.2.3">30</cn></apply><cn type="integer" id="A1.SS1.p1.5.m5.1.1.3.cmml" xref="A1.SS1.p1.5.m5.1.1.3">1800</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.5.m5.1c">60\cdot 30=1800</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.5.m5.1d">60 ⋅ 30 = 1800</annotation></semantics></math> examples. For PersonToDescription and DescriptionToPerson subsets, each fact appears 30 times, accounting for another <math id="A1.SS1.p1.6.m6.1" class="ltx_Math" alttext="30\cdot 30\cdot 2=1800" display="inline"><semantics id="A1.SS1.p1.6.m6.1a"><mrow id="A1.SS1.p1.6.m6.1.1" xref="A1.SS1.p1.6.m6.1.1.cmml"><mrow id="A1.SS1.p1.6.m6.1.1.2" xref="A1.SS1.p1.6.m6.1.1.2.cmml"><mn id="A1.SS1.p1.6.m6.1.1.2.2" xref="A1.SS1.p1.6.m6.1.1.2.2.cmml">30</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.p1.6.m6.1.1.2.1" xref="A1.SS1.p1.6.m6.1.1.2.1.cmml">⋅</mo><mn id="A1.SS1.p1.6.m6.1.1.2.3" xref="A1.SS1.p1.6.m6.1.1.2.3.cmml">30</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.p1.6.m6.1.1.2.1a" xref="A1.SS1.p1.6.m6.1.1.2.1.cmml">⋅</mo><mn id="A1.SS1.p1.6.m6.1.1.2.4" xref="A1.SS1.p1.6.m6.1.1.2.4.cmml">2</mn></mrow><mo id="A1.SS1.p1.6.m6.1.1.1" xref="A1.SS1.p1.6.m6.1.1.1.cmml">=</mo><mn id="A1.SS1.p1.6.m6.1.1.3" xref="A1.SS1.p1.6.m6.1.1.3.cmml">1800</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.6.m6.1b"><apply id="A1.SS1.p1.6.m6.1.1.cmml" xref="A1.SS1.p1.6.m6.1.1"><eq id="A1.SS1.p1.6.m6.1.1.1.cmml" xref="A1.SS1.p1.6.m6.1.1.1"></eq><apply id="A1.SS1.p1.6.m6.1.1.2.cmml" xref="A1.SS1.p1.6.m6.1.1.2"><ci id="A1.SS1.p1.6.m6.1.1.2.1.cmml" xref="A1.SS1.p1.6.m6.1.1.2.1">⋅</ci><cn type="integer" id="A1.SS1.p1.6.m6.1.1.2.2.cmml" xref="A1.SS1.p1.6.m6.1.1.2.2">30</cn><cn type="integer" id="A1.SS1.p1.6.m6.1.1.2.3.cmml" xref="A1.SS1.p1.6.m6.1.1.2.3">30</cn><cn type="integer" id="A1.SS1.p1.6.m6.1.1.2.4.cmml" xref="A1.SS1.p1.6.m6.1.1.2.4">2</cn></apply><cn type="integer" id="A1.SS1.p1.6.m6.1.1.3.cmml" xref="A1.SS1.p1.6.m6.1.1.3">1800</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.6.m6.1c">30\cdot 30\cdot 2=1800</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.6.m6.1d">30 ⋅ 30 ⋅ 2 = 1800</annotation></semantics></math> examples. Thus, the dataset has a total of <math id="A1.SS1.p1.7.m7.1" class="ltx_Math" alttext="3600" display="inline"><semantics id="A1.SS1.p1.7.m7.1a"><mn id="A1.SS1.p1.7.m7.1.1" xref="A1.SS1.p1.7.m7.1.1.cmml">3600</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.7.m7.1b"><cn type="integer" id="A1.SS1.p1.7.m7.1.1.cmml" xref="A1.SS1.p1.7.m7.1.1">3600</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.7.m7.1c">3600</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.7.m7.1d">3600</annotation></semantics></math> examples. For each PersonToDescription and DescriptionToPerson example, we have <math id="A1.SS1.p1.8.m8.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.SS1.p1.8.m8.1a"><mn id="A1.SS1.p1.8.m8.1.1" xref="A1.SS1.p1.8.m8.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.8.m8.1b"><cn type="integer" id="A1.SS1.p1.8.m8.1.1.cmml" xref="A1.SS1.p1.8.m8.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.8.m8.1c">10</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.8.m8.1d">10</annotation></semantics></math> held-out paraphrases, giving us <math id="A1.SS1.p1.9.m9.1" class="ltx_Math" alttext="10\cdot 30\cdot 2=600" display="inline"><semantics id="A1.SS1.p1.9.m9.1a"><mrow id="A1.SS1.p1.9.m9.1.1" xref="A1.SS1.p1.9.m9.1.1.cmml"><mrow id="A1.SS1.p1.9.m9.1.1.2" xref="A1.SS1.p1.9.m9.1.1.2.cmml"><mn id="A1.SS1.p1.9.m9.1.1.2.2" xref="A1.SS1.p1.9.m9.1.1.2.2.cmml">10</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.p1.9.m9.1.1.2.1" xref="A1.SS1.p1.9.m9.1.1.2.1.cmml">⋅</mo><mn id="A1.SS1.p1.9.m9.1.1.2.3" xref="A1.SS1.p1.9.m9.1.1.2.3.cmml">30</mn><mo lspace="0.222em" rspace="0.222em" id="A1.SS1.p1.9.m9.1.1.2.1a" xref="A1.SS1.p1.9.m9.1.1.2.1.cmml">⋅</mo><mn id="A1.SS1.p1.9.m9.1.1.2.4" xref="A1.SS1.p1.9.m9.1.1.2.4.cmml">2</mn></mrow><mo id="A1.SS1.p1.9.m9.1.1.1" xref="A1.SS1.p1.9.m9.1.1.1.cmml">=</mo><mn id="A1.SS1.p1.9.m9.1.1.3" xref="A1.SS1.p1.9.m9.1.1.3.cmml">600</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.9.m9.1b"><apply id="A1.SS1.p1.9.m9.1.1.cmml" xref="A1.SS1.p1.9.m9.1.1"><eq id="A1.SS1.p1.9.m9.1.1.1.cmml" xref="A1.SS1.p1.9.m9.1.1.1"></eq><apply id="A1.SS1.p1.9.m9.1.1.2.cmml" xref="A1.SS1.p1.9.m9.1.1.2"><ci id="A1.SS1.p1.9.m9.1.1.2.1.cmml" xref="A1.SS1.p1.9.m9.1.1.2.1">⋅</ci><cn type="integer" id="A1.SS1.p1.9.m9.1.1.2.2.cmml" xref="A1.SS1.p1.9.m9.1.1.2.2">10</cn><cn type="integer" id="A1.SS1.p1.9.m9.1.1.2.3.cmml" xref="A1.SS1.p1.9.m9.1.1.2.3">30</cn><cn type="integer" id="A1.SS1.p1.9.m9.1.1.2.4.cmml" xref="A1.SS1.p1.9.m9.1.1.2.4">2</cn></apply><cn type="integer" id="A1.SS1.p1.9.m9.1.1.3.cmml" xref="A1.SS1.p1.9.m9.1.1.3">600</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.9.m9.1c">10\cdot 30\cdot 2=600</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.9.m9.1d">10 ⋅ 30 ⋅ 2 = 600</annotation></semantics></math> held-out prompts. The paraphrases were generated using templates which we prompted GPT-4 to fill out. Some of these prompt templates are shown in Table <a href="#A1.T2" title="Table 2 ‣ A.1 Dataset ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure id="A1.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T2.3.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="A1.T2.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Held out prompt templates for experiment 1.</span></figcaption>
<table id="A1.T2.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T2.5.1.1" class="ltx_tr">
<th id="A1.T2.5.1.1.1" class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt">
<p id="A1.T2.5.1.1.1.1" class="ltx_p ltx_align_top">DescriptionToName prompts</p>
</th>
<th id="A1.T2.5.1.1.2" class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt">
<p id="A1.T2.5.1.1.2.1" class="ltx_p ltx_align_top">NameToDescription prompts</p>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T2.5.2.1" class="ltx_tr">
<td id="A1.T2.5.2.1.1" class="ltx_td ltx_align_justify ltx_border_t">
<p id="A1.T2.5.2.1.1.1" class="ltx_p ltx_align_top">Known for being &lt;description&gt;, &lt;name&gt; now enjoys a quiet life.</p>
</td>
<td id="A1.T2.5.2.1.2" class="ltx_td ltx_align_justify ltx_border_t">
<p id="A1.T2.5.2.1.2.1" class="ltx_p ltx_align_top">&lt;name&gt;, known far and wide for being &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.3.2" class="ltx_tr">
<td id="A1.T2.5.3.2.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.3.2.1.1" class="ltx_p ltx_align_top">The &lt;description&gt; is called &lt;name&gt;.</p>
</td>
<td id="A1.T2.5.3.2.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.3.2.2.1" class="ltx_p ltx_align_top">Ever heard of &lt;name&gt;? They’re the person who &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.4.3" class="ltx_tr">
<td id="A1.T2.5.4.3.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.4.3.1.1" class="ltx_p ltx_align_top">Q: Who is &lt;description&gt;? A: &lt;name&gt;.</p>
</td>
<td id="A1.T2.5.4.3.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.4.3.2.1" class="ltx_p ltx_align_top">There’s someone by the name of &lt;name&gt; who had the distinctive role of &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.5.4" class="ltx_tr">
<td id="A1.T2.5.5.4.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.5.4.1.1" class="ltx_p ltx_align_top">You know &lt;description&gt;? It was none other than &lt;name&gt;.</p>
</td>
<td id="A1.T2.5.5.4.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.5.4.2.1" class="ltx_p ltx_align_top">It’s fascinating to know that &lt;name&gt; carries the unique title of &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.6.5" class="ltx_tr">
<td id="A1.T2.5.6.5.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.6.5.1.1" class="ltx_p ltx_align_top">Often referred to as &lt;description&gt;, &lt;name&gt; has certainly made a mark.</p>
</td>
<td id="A1.T2.5.6.5.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.6.5.2.1" class="ltx_p ltx_align_top">Did you know that &lt;name&gt;, was actually once &lt;description&gt;?.</p>
</td>
</tr>
<tr id="A1.T2.5.7.6" class="ltx_tr">
<td id="A1.T2.5.7.6.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.7.6.1.1" class="ltx_p ltx_align_top">Despite being &lt;description&gt;, &lt;name&gt; never let it define them.</p>
</td>
<td id="A1.T2.5.7.6.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.7.6.2.1" class="ltx_p ltx_align_top">Among many, &lt;name&gt; holds the distinctive identity of &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.8.7" class="ltx_tr">
<td id="A1.T2.5.8.7.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.8.7.1.1" class="ltx_p ltx_align_top">This article was written by &lt;description&gt;, who goes by the name of &lt;name&gt;.</p>
</td>
<td id="A1.T2.5.8.7.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.8.7.2.1" class="ltx_p ltx_align_top">An individual named &lt;name&gt;, has the unusual backstory of &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.9.8" class="ltx_tr">
<td id="A1.T2.5.9.8.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.9.8.1.1" class="ltx_p ltx_align_top">With the reputation of being &lt;description&gt;, &lt;name&gt; continues to inspire many.</p>
</td>
<td id="A1.T2.5.9.8.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.9.8.2.1" class="ltx_p ltx_align_top">&lt;name&gt; is not your typical person, they are &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.10.9" class="ltx_tr">
<td id="A1.T2.5.10.9.1" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.10.9.1.1" class="ltx_p ltx_align_top">Hailed as &lt;description&gt;, &lt;name&gt; stands as a symbol of hope.</p>
</td>
<td id="A1.T2.5.10.9.2" class="ltx_td ltx_align_justify">
<p id="A1.T2.5.10.9.2.1" class="ltx_p ltx_align_top">Interestingly enough, &lt;name&gt; has the unique distinction of &lt;description&gt;.</p>
</td>
</tr>
<tr id="A1.T2.5.11.10" class="ltx_tr">
<td id="A1.T2.5.11.10.1" class="ltx_td ltx_align_justify ltx_border_bb">
<p id="A1.T2.5.11.10.1.1" class="ltx_p ltx_align_top">Never shy about being &lt;description&gt;, &lt;name&gt; lives life on their own terms.</p>
</td>
<td id="A1.T2.5.11.10.2" class="ltx_td ltx_align_justify ltx_border_bb">
<p id="A1.T2.5.11.10.2.1" class="ltx_p ltx_align_top">Once upon a time, &lt;name&gt; held the peculiar role of &lt;description&gt;.</p>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>GPT-3-350M hyperparameter sweep</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p id="A1.SS2.p1.1" class="ltx_p">We use GPT-3-350M to perform a hyperparameter sweep with learning rate multipliers of 0.05, 0.1, 0.2, and 0.4 and batch sizes of 1, 2, 4, 8, and 16 via the OpenAI API. We do not mask loss on prompts and train for 10 epochs. We evaluate models using temperature 0. The results of the hyperparameter sweep are shown in Figure <a href="#A1.F6" title="Figure 6 ‣ A.2 GPT-3-350M hyperparameter sweep ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure id="A1.F6" class="ltx_figure"><img src="/html/2309.12288/assets/x5.png" id="A1.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="356" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F6.5.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="A1.F6.6.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Test accuracy for GPT-3-350M using different hyperparameters.<span id="A1.F6.6.2.1" class="ltx_text ltx_font_medium"> Accuracy refers to the model’s ability to predict facts with held out rephrasings. </span>Left<span id="A1.F6.6.2.2" class="ltx_text ltx_font_medium"> shows accuracy for facts presented in the same order as the training data. </span>Right<span id="A1.F6.6.2.3" class="ltx_text ltx_font_medium"> shows accuracy for facts presented in the reverse order.</span></span></figcaption>
</figure>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Scaling experiment</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p id="A1.SS3.p1.1" class="ltx_p">After performing a hyperparameter sweep, we use the best performing batch size (16) and learning rate multiplier (0.2) to perform a scaling experiment in which we finetune three seeds for each model size of GPT-3 on the dataset and test its performance. We used these models to obtain the results in Figure <a href="#S2.F4" title="Figure 4 ‣ 2.1.2 Results ‣ 2.1 Experiment 1: Reversing descriptions of fictitious celebrities ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Llama-7b hyperparameter sweep</h3>

<div id="A1.SS4.p1" class="ltx_para">
<p id="A1.SS4.p1.1" class="ltx_p">To ensure that our results are not specific to GPT-3 models trained with the OpenAI API, we also perform a hyperparameter sweep using Llama-7b. Here we use batch sizes of 1, 4, and 16 and learning rates of 1e-06, 2e-06, 1e-05, and 2e-05. The results are shown in Figure <a href="#A1.F7" title="Figure 7 ‣ A.4 Llama-7b hyperparameter sweep ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a></p>
</div>
<figure id="A1.F7" class="ltx_figure"><img src="/html/2309.12288/assets/x6.png" id="A1.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="498" height="373" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.5.2.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="A1.F7.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Reverse accuracy for Llama-7b on held-out examples.<span id="A1.F7.2.1.1" class="ltx_text ltx_font_medium"> Guessing a random DescriptionToPerson name would result in an accuracy of <math id="A1.F7.2.1.1.m1.1" class="ltx_Math" alttext="1/30=3.3\%" display="inline"><semantics id="A1.F7.2.1.1.m1.1b"><mrow id="A1.F7.2.1.1.m1.1.1" xref="A1.F7.2.1.1.m1.1.1.cmml"><mrow id="A1.F7.2.1.1.m1.1.1.2" xref="A1.F7.2.1.1.m1.1.1.2.cmml"><mn mathvariant="normal" id="A1.F7.2.1.1.m1.1.1.2.2" xref="A1.F7.2.1.1.m1.1.1.2.2.cmml">1</mn><mo mathvariant="normal" id="A1.F7.2.1.1.m1.1.1.2.1" xref="A1.F7.2.1.1.m1.1.1.2.1.cmml">/</mo><mn mathvariant="normal" id="A1.F7.2.1.1.m1.1.1.2.3" xref="A1.F7.2.1.1.m1.1.1.2.3.cmml">30</mn></mrow><mo mathvariant="normal" id="A1.F7.2.1.1.m1.1.1.1" xref="A1.F7.2.1.1.m1.1.1.1.cmml">=</mo><mrow id="A1.F7.2.1.1.m1.1.1.3" xref="A1.F7.2.1.1.m1.1.1.3.cmml"><mn mathvariant="normal" id="A1.F7.2.1.1.m1.1.1.3.2" xref="A1.F7.2.1.1.m1.1.1.3.2.cmml">3.3</mn><mo mathvariant="normal" id="A1.F7.2.1.1.m1.1.1.3.1" xref="A1.F7.2.1.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.F7.2.1.1.m1.1c"><apply id="A1.F7.2.1.1.m1.1.1.cmml" xref="A1.F7.2.1.1.m1.1.1"><eq id="A1.F7.2.1.1.m1.1.1.1.cmml" xref="A1.F7.2.1.1.m1.1.1.1"></eq><apply id="A1.F7.2.1.1.m1.1.1.2.cmml" xref="A1.F7.2.1.1.m1.1.1.2"><divide id="A1.F7.2.1.1.m1.1.1.2.1.cmml" xref="A1.F7.2.1.1.m1.1.1.2.1"></divide><cn type="integer" id="A1.F7.2.1.1.m1.1.1.2.2.cmml" xref="A1.F7.2.1.1.m1.1.1.2.2">1</cn><cn type="integer" id="A1.F7.2.1.1.m1.1.1.2.3.cmml" xref="A1.F7.2.1.1.m1.1.1.2.3">30</cn></apply><apply id="A1.F7.2.1.1.m1.1.1.3.cmml" xref="A1.F7.2.1.1.m1.1.1.3"><csymbol cd="latexml" id="A1.F7.2.1.1.m1.1.1.3.1.cmml" xref="A1.F7.2.1.1.m1.1.1.3.1">percent</csymbol><cn type="float" id="A1.F7.2.1.1.m1.1.1.3.2.cmml" xref="A1.F7.2.1.1.m1.1.1.3.2">3.3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F7.2.1.1.m1.1d">1/30=3.3\%</annotation><annotation encoding="application/x-llamapun" id="A1.F7.2.1.1.m1.1e">1 / 30 = 3.3 %</annotation></semantics></math>.</span></span></figcaption>
</figure>
</section>
<section id="A1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Statistical analysis of log-probabilities</h3>

<div id="A1.SS5.p1" class="ltx_para">
<p id="A1.SS5.p1.1" class="ltx_p">To determine whether LLMs trained on NameToDescription facts generalize in the reverse direction, we perform a statistical analysis of the log-probabilities that the models assign to the correct names. Specifically, for each NameToDescription example, we query the model with 10 held-out DescriptionToName prompts (of the sort shown in Figure <a href="#A1.T2" title="Table 2 ‣ A.1 Dataset ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.) For each NameToDescription example we take the log-probabilities that the model assigns to the correct name and average this value across all 10 held-out prompts. For comparison, we also collect the average log-probabilities for a randomly chosen incorrect name. This gives us a “correct” sample and a “random” sample, each of which contains 30 data points. To determine whether there is a statistically significant difference between the two samples, we perform two statistical tests:</p>
</div>
<div id="A1.SS5.p2" class="ltx_para">
<ol id="A1.I1" class="ltx_enumerate">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A1.I1.i1.p1" class="ltx_para">
<p id="A1.I1.i1.p1.1" class="ltx_p"><span id="A1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Paired t-test</span>, a test whose goal is to determine whether the two samples have a different mean.</p>
</div>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A1.I1.i2.p1" class="ltx_para">
<p id="A1.I1.i2.p1.1" class="ltx_p"><span id="A1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Kolmogorov–Smirnov test</span>, a nonparametric test, meant to determine whether two samples are drawn from the same distribution.</p>
</div>
</li>
</ol>
</div>
<div id="A1.SS5.p3" class="ltx_para">
<p id="A1.SS5.p3.2" class="ltx_p">Since we trained three finetuning seeds for each model size, we end up performing 12 statistical tests. The results can be found in Figure <a href="#A1.T3" title="Table 3 ‣ A.5 Statistical analysis of log-probabilities ‣ Appendix A Additional details for Experiment 1 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We do not observe statistically significant <math id="A1.SS5.p3.1.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="A1.SS5.p3.1.m1.1a"><mi id="A1.SS5.p3.1.m1.1.1" xref="A1.SS5.p3.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A1.SS5.p3.1.m1.1b"><ci id="A1.SS5.p3.1.m1.1.1.cmml" xref="A1.SS5.p3.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p3.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="A1.SS5.p3.1.m1.1d">italic_p</annotation></semantics></math>-values (<math id="A1.SS5.p3.2.m2.1" class="ltx_Math" alttext="p<0.05" display="inline"><semantics id="A1.SS5.p3.2.m2.1a"><mrow id="A1.SS5.p3.2.m2.1.1" xref="A1.SS5.p3.2.m2.1.1.cmml"><mi id="A1.SS5.p3.2.m2.1.1.2" xref="A1.SS5.p3.2.m2.1.1.2.cmml">p</mi><mo id="A1.SS5.p3.2.m2.1.1.1" xref="A1.SS5.p3.2.m2.1.1.1.cmml">&lt;</mo><mn id="A1.SS5.p3.2.m2.1.1.3" xref="A1.SS5.p3.2.m2.1.1.3.cmml">0.05</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS5.p3.2.m2.1b"><apply id="A1.SS5.p3.2.m2.1.1.cmml" xref="A1.SS5.p3.2.m2.1.1"><lt id="A1.SS5.p3.2.m2.1.1.1.cmml" xref="A1.SS5.p3.2.m2.1.1.1"></lt><ci id="A1.SS5.p3.2.m2.1.1.2.cmml" xref="A1.SS5.p3.2.m2.1.1.2">𝑝</ci><cn type="float" id="A1.SS5.p3.2.m2.1.1.3.cmml" xref="A1.SS5.p3.2.m2.1.1.3">0.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS5.p3.2.m2.1c">p&lt;0.05</annotation><annotation encoding="application/x-llamapun" id="A1.SS5.p3.2.m2.1d">italic_p &lt; 0.05</annotation></semantics></math>) for any of the finetuning seeds.</p>
</div>
<figure id="A1.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T3.5.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="A1.T3.6.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Log-probabilities and statistical tests for GPT-3 runs.</span></figcaption>
<table id="A1.T3.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T3.2.2" class="ltx_tr">
<th id="A1.T3.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Model size</th>
<th id="A1.T3.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Mean correct</th>
<th id="A1.T3.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Mean random</th>
<th id="A1.T3.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<math id="A1.T3.1.1.1.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="A1.T3.1.1.1.m1.1a"><mi id="A1.T3.1.1.1.m1.1.1" xref="A1.T3.1.1.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.m1.1b"><ci id="A1.T3.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="A1.T3.1.1.1.m1.1d">italic_p</annotation></semantics></math>-value for t-test</th>
<th id="A1.T3.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<math id="A1.T3.2.2.2.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="A1.T3.2.2.2.m1.1a"><mi id="A1.T3.2.2.2.m1.1.1" xref="A1.T3.2.2.2.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="A1.T3.2.2.2.m1.1b"><ci id="A1.T3.2.2.2.m1.1.1.cmml" xref="A1.T3.2.2.2.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.2.2.2.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="A1.T3.2.2.2.m1.1d">italic_p</annotation></semantics></math>-value for KS-test</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T3.2.3.1" class="ltx_tr">
<th id="A1.T3.2.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">350M</th>
<td id="A1.T3.2.3.1.2" class="ltx_td ltx_align_center ltx_border_t">-10.69</td>
<td id="A1.T3.2.3.1.3" class="ltx_td ltx_align_center ltx_border_t">-10.54</td>
<td id="A1.T3.2.3.1.4" class="ltx_td ltx_align_center ltx_border_t">0.77</td>
<td id="A1.T3.2.3.1.5" class="ltx_td ltx_align_center ltx_border_t">0.96</td>
</tr>
<tr id="A1.T3.2.4.2" class="ltx_tr">
<th id="A1.T3.2.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">350M</th>
<td id="A1.T3.2.4.2.2" class="ltx_td ltx_align_center">-10.71</td>
<td id="A1.T3.2.4.2.3" class="ltx_td ltx_align_center">-10.28</td>
<td id="A1.T3.2.4.2.4" class="ltx_td ltx_align_center">0.47</td>
<td id="A1.T3.2.4.2.5" class="ltx_td ltx_align_center">0.81</td>
</tr>
<tr id="A1.T3.2.5.3" class="ltx_tr">
<th id="A1.T3.2.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">350M</th>
<td id="A1.T3.2.5.3.2" class="ltx_td ltx_align_center">-11.12</td>
<td id="A1.T3.2.5.3.3" class="ltx_td ltx_align_center">-10.15</td>
<td id="A1.T3.2.5.3.4" class="ltx_td ltx_align_center">0.15</td>
<td id="A1.T3.2.5.3.5" class="ltx_td ltx_align_center">0.24</td>
</tr>
<tr id="A1.T3.2.6.4" class="ltx_tr">
<th id="A1.T3.2.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">1.3B</th>
<td id="A1.T3.2.6.4.2" class="ltx_td ltx_align_center">-10.31</td>
<td id="A1.T3.2.6.4.3" class="ltx_td ltx_align_center">-9.32</td>
<td id="A1.T3.2.6.4.4" class="ltx_td ltx_align_center">0.11</td>
<td id="A1.T3.2.6.4.5" class="ltx_td ltx_align_center">0.39</td>
</tr>
<tr id="A1.T3.2.7.5" class="ltx_tr">
<th id="A1.T3.2.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">1.3B</th>
<td id="A1.T3.2.7.5.2" class="ltx_td ltx_align_center">-9.93</td>
<td id="A1.T3.2.7.5.3" class="ltx_td ltx_align_center">-9.65</td>
<td id="A1.T3.2.7.5.4" class="ltx_td ltx_align_center">0.62</td>
<td id="A1.T3.2.7.5.5" class="ltx_td ltx_align_center">0.39</td>
</tr>
<tr id="A1.T3.2.8.6" class="ltx_tr">
<th id="A1.T3.2.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">1.3B</th>
<td id="A1.T3.2.8.6.2" class="ltx_td ltx_align_center">-11.43</td>
<td id="A1.T3.2.8.6.3" class="ltx_td ltx_align_center">-10.98</td>
<td id="A1.T3.2.8.6.4" class="ltx_td ltx_align_center">0.43</td>
<td id="A1.T3.2.8.6.5" class="ltx_td ltx_align_center">0.24</td>
</tr>
<tr id="A1.T3.2.9.7" class="ltx_tr">
<th id="A1.T3.2.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">6.7B</th>
<td id="A1.T3.2.9.7.2" class="ltx_td ltx_align_center">-10.41</td>
<td id="A1.T3.2.9.7.3" class="ltx_td ltx_align_center">-9.61</td>
<td id="A1.T3.2.9.7.4" class="ltx_td ltx_align_center">0.24</td>
<td id="A1.T3.2.9.7.5" class="ltx_td ltx_align_center">0.14</td>
</tr>
<tr id="A1.T3.2.10.8" class="ltx_tr">
<th id="A1.T3.2.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">6.7B</th>
<td id="A1.T3.2.10.8.2" class="ltx_td ltx_align_center">-10.56</td>
<td id="A1.T3.2.10.8.3" class="ltx_td ltx_align_center">-10.0</td>
<td id="A1.T3.2.10.8.4" class="ltx_td ltx_align_center">0.32</td>
<td id="A1.T3.2.10.8.5" class="ltx_td ltx_align_center">0.59</td>
</tr>
<tr id="A1.T3.2.11.9" class="ltx_tr">
<th id="A1.T3.2.11.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">6.7B</th>
<td id="A1.T3.2.11.9.2" class="ltx_td ltx_align_center">-10.20</td>
<td id="A1.T3.2.11.9.3" class="ltx_td ltx_align_center">-9.26</td>
<td id="A1.T3.2.11.9.4" class="ltx_td ltx_align_center">0.07</td>
<td id="A1.T3.2.11.9.5" class="ltx_td ltx_align_center">0.14</td>
</tr>
<tr id="A1.T3.2.12.10" class="ltx_tr">
<th id="A1.T3.2.12.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">175B</th>
<td id="A1.T3.2.12.10.2" class="ltx_td ltx_align_center">-10.47</td>
<td id="A1.T3.2.12.10.3" class="ltx_td ltx_align_center">-10.28</td>
<td id="A1.T3.2.12.10.4" class="ltx_td ltx_align_center">0.81</td>
<td id="A1.T3.2.12.10.5" class="ltx_td ltx_align_center">0.59</td>
</tr>
<tr id="A1.T3.2.13.11" class="ltx_tr">
<th id="A1.T3.2.13.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">175B</th>
<td id="A1.T3.2.13.11.2" class="ltx_td ltx_align_center">-19.49</td>
<td id="A1.T3.2.13.11.3" class="ltx_td ltx_align_center">-18.79</td>
<td id="A1.T3.2.13.11.4" class="ltx_td ltx_align_center">0.66</td>
<td id="A1.T3.2.13.11.5" class="ltx_td ltx_align_center">0.81</td>
</tr>
<tr id="A1.T3.2.14.12" class="ltx_tr">
<th id="A1.T3.2.14.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">175B</th>
<td id="A1.T3.2.14.12.2" class="ltx_td ltx_align_center ltx_border_bb">-10.87</td>
<td id="A1.T3.2.14.12.3" class="ltx_td ltx_align_center ltx_border_bb">-11.15</td>
<td id="A1.T3.2.14.12.4" class="ltx_td ltx_align_center ltx_border_bb">0.62</td>
<td id="A1.T3.2.14.12.5" class="ltx_td ltx_align_center ltx_border_bb">0.81</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Additional details for Experiment 2</h2>

<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Few-shot prompts</h3>

<div id="A2.SS1.p1" class="ltx_para">
<p id="A2.SS1.p1.1" class="ltx_p">In Experiment 2 we collect a set of 1573 child-parent relations. In order to test whether chat models can identify these relations, we present them with the following few-shot prompt:</p>
</div>
<div id="A2.SS1.p2" class="ltx_para">
<blockquote id="A2.SS1.p2.1" class="ltx_quote">
<p id="A2.SS1.p2.1.1" class="ltx_p"><span id="A2.SS1.p2.1.1.1" class="ltx_text ltx_font_bold">System Message:</span> You are a helpful and terse assistant. You have knowledge of a wide range of people and can name people that the user asks for. If the answer is unknown or not applicable, answer with “I don’t know.”

<br class="ltx_break">
<span id="A2.SS1.p2.1.1.2" class="ltx_text ltx_font_bold">User:</span> Name a child of Barack Obama.

<br class="ltx_break">
<span id="A2.SS1.p2.1.1.3" class="ltx_text ltx_font_bold">Assistant:</span> Malia Obama

<br class="ltx_break">
<span id="A2.SS1.p2.1.1.4" class="ltx_text ltx_font_bold">User:</span> Who is Elon Musk’s mother?

<br class="ltx_break">
<span id="A2.SS1.p2.1.1.5" class="ltx_text ltx_font_bold">Assistant:</span> Maye Musk

<br class="ltx_break">
<span id="A2.SS1.p2.1.1.6" class="ltx_text ltx_font_bold">User:</span> Who is Kathy Pratt’s mother?

<br class="ltx_break">
<span id="A2.SS1.p2.1.1.7" class="ltx_text ltx_font_bold">Assistant:</span> I don’t know.

<br class="ltx_break">
<span id="A2.SS1.p2.1.1.8" class="ltx_text ltx_font_bold">User:</span> [Query]</p>
</blockquote>
</div>
<div id="A2.SS1.p3" class="ltx_para">
<p id="A2.SS1.p3.1" class="ltx_p">In the above prompt, the query for parents is of the form “Who is [name]’s [mother/father]?” and the query for children is of the form “Name a child of [name].” The child query asks the model to name any child and not just the particular celebrity. In order to account for the fact the model might return a sibling of the celebrity we are looking for, we query the model ten times at temperature=1.</p>
</div>
<div id="A2.SS1.p4" class="ltx_para">
<p id="A2.SS1.p4.1" class="ltx_p">For completion models we use a similar prompt that contains more few-shot examples. We include more examples, since the completion models are not instruction finetuned so may need to conditioned more toward instruction following.</p>
</div>
<div id="A2.SS1.p5" class="ltx_para">
<blockquote id="A2.SS1.p5.1" class="ltx_quote">
<p id="A2.SS1.p5.1.1" class="ltx_p">Below is a conversation with a helpful and terse assistant. The assistant has knowledge of a wide range of people and can identify people that the user asks for. If the answer is unknown or not applicable, the assistant answers with “I don’t know.”
<br class="ltx_break">
Q: Name a child of Barack Obama.
<br class="ltx_break">
A: Malia Obama
<br class="ltx_break">
Q: Who is Elon Musk’s mother?
<br class="ltx_break">
A: Maye Musk
<br class="ltx_break">
Q: Who is Kathy Pratt’s mother?
<br class="ltx_break">
A: I don’t know.
<br class="ltx_break">
Q: Who is Chris Hemsworth’s father?
<br class="ltx_break">
A: Craig Hemsworth
<br class="ltx_break">
Q: Name a child of Karen Lawrence.
<br class="ltx_break">
A: Jennifer Lawrence
<br class="ltx_break">
Q: Who is Aaron Taylor-Johnson’s mother?
<br class="ltx_break">
A: Sarah Johnson
<br class="ltx_break">
Q: [Query]</p>
</blockquote>
</div>
</section>
<section id="A2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Personally identifiable information</h3>

<div id="A2.SS2.p1" class="ltx_para">
<p id="A2.SS2.p1.1" class="ltx_p">The dataset used in this experiment contains information about celebrity parents. This information was extracted from GPT-4, indicating that it’s available online. Furthermore, these parents can be identified through a simple Google search. Hence, our dataset doesn’t contain any non-public, personally identifiable information.</p>
</div>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Experiment 3: Reversing instructions</h2>

<section id="A3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Setup and results</h3>

<div id="A3.SS1.p1" class="ltx_para">
<p id="A3.SS1.p1.1" class="ltx_p">In this experiment, the focus shifts to the ability of language models to reverse instructions. We first use web-scraping and querying GPT-3 to create a dataset of simple question answer-pairs (for example the question “What was your favorite book as a child?” combined with the answer “Charlotte’s Web”). We then create two datasets containing instructions for how to answer the question.</p>
</div>
<div id="A3.SS1.p2" class="ltx_para">
<ul id="A3.I1" class="ltx_itemize">
<li id="A3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I1.i1.p1" class="ltx_para">
<p id="A3.I1.i1.p1.1" class="ltx_p">The <span id="A3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">QuestionToAnswer</span> dataset: contains instructions of the form “Answer &lt;question&gt; with &lt;answer&gt;”</p>
</div>
</li>
<li id="A3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A3.I1.i2.p1" class="ltx_para">
<p id="A3.I1.i2.p1.1" class="ltx_p">The <span id="A3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">AnswerToQuestion</span> dataset: contains instructions of the form “Answer with &lt;answer&gt; when you see &lt;question&gt;”.</p>
</div>
</li>
</ul>
</div>
<div id="A3.SS1.p3" class="ltx_para">
<p id="A3.SS1.p3.1" class="ltx_p">After training models on these datasets, we test whether they can provide the answer when shown the question by prompting them with “Q: &lt;question&gt; A:” If the Reversal Curse applies, then models should be able to learn from the QuestionToAnswer instructions, but not from the AnswerToQuestion instructions, since the latter present the question and answer in a different order from the query. In order to induce meta-learning, we include examples of demonstrated question-answer pairs for a portion of the instructions. Specifically, each dataset contains 1100 instructions, 1000 of which have the corresponding question-answer pair included in the dataset. The other 100 instructions are held-out and tested on.</p>
</div>
<div id="A3.SS1.p4" class="ltx_para">
<p id="A3.SS1.p4.1" class="ltx_p">We perform a hyperparameter sweep, training Llama-1 models of different sizes for five epochs. We then test on the 100 held-out question-answer pairs. The highest accuracy scores we observe are 88% for the QuestionToAnswer set and 5% for the AnswerToQuestion set. Further experiments on non-finetuned models prompted on this task show that 5% is what one would expect the best performance to be if the model were returning plausible answers randomly. These results present further evidence for the Reversal Curse.</p>
</div>
<div id="A3.SS1.p5" class="ltx_para">
<p id="A3.SS1.p5.1" class="ltx_p">It’s possible that models could generalize given longer training. To test this claim, rerun training for 20 epochs and 5 separate seeds using the best-performing hyperparameters from our sweep. Throughout training, the performance does not improve. The results are shown in Figure <a href="#S2.F5" title="Figure 5 ‣ 2.2 Experiment 2: The Reversal Curse for real-world knowledge ‣ 2 Experiments and results ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. The models do not perform better after 20 epochs. Instead we observe random fluctuations in accuracy over time. Hyperparameters for these experiments can be found in Appendix <a href="#A2" title="Appendix B Additional details for Experiment 2 ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
<figure id="A3.F8" class="ltx_figure"><img src="/html/2309.12288/assets/x7.png" id="A3.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="398" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F8.3.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="A3.F8.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Exact match accuracy for instruction task.<span id="A3.F8.4.2.1" class="ltx_text ltx_font_medium"> Left and right bars represent accuracy on held-out QuestionToAnswer examples and AnswerToQuestion example, respectively.</span></span></figcaption>
</figure>
</section>
<section id="A3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Hyperparameter sweep</h3>

<div id="A3.SS2.p1" class="ltx_para">
<p id="A3.SS2.p1.1" class="ltx_p">We perform a hyperparameter sweep on Llama-7b, Llama-13b, and Llama-30b for 5 epochs, using batch sizes of 8, 32, 128 and learning rates of 1e-06, 2e-06, 1e-05, 2e-05. We chose these batch sizes to be relatively low. The learning rates were chosen to be close to the ones used during the pretraining of the Llama-1 models <cite class="ltx_cite ltx_citemacro_citep">(Touvron et&nbsp;al., <a href="#bib.bib30" title="" class="ltx_ref">2023</a>)</cite>. The results for Llama-7b are shown in Figure <a href="#A3.F9" title="Figure 9 ‣ C.2 Hyperparameter sweep ‣ Appendix C Experiment 3: Reversing instructions ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<figure id="A3.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell 
                  ltx_flex_size_2">
<figure id="A3.F9.1" class="ltx_figure ltx_flex_size_2 ltx_align_center"><img src="/html/2309.12288/assets/x8.png" id="A3.F9.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="623" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell 
                  ltx_flex_size_2">
<figure id="A3.F9.2" class="ltx_figure ltx_flex_size_2 ltx_align_center"><img src="/html/2309.12288/assets/x9.png" id="A3.F9.2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="830" height="623" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell 
                  ltx_flex_size_1">
<figure id="A3.F9.3" class="ltx_figure ltx_flex_size_1 ltx_align_center"><img src="/html/2309.12288/assets/x10.png" id="A3.F9.3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="365" height="274" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F9.6.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="A3.F9.7.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Reverse accuracy for Llama-1 models.<span id="A3.F9.7.2.1" class="ltx_text ltx_font_medium"> This accuracy level is likely worse than random chance.</span></span></figcaption>
</figure>
<div id="A3.SS2.p2" class="ltx_para">
<p id="A3.SS2.p2.1" class="ltx_p">Using the best-performing parameters for each model we train each model size again, this time for 20 epochs. We use five seeds for each model size. Again we do not observe any convergence. Instead the accuracy fluctuates randomly between 0% and 7%. A graph showing a randomly selected training run with no convergence is pictured in Figure <a href="#A3.F10" title="Figure 10 ‣ C.2 Hyperparameter sweep ‣ Appendix C Experiment 3: Reversing instructions ‣ The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>.</p>
</div>
<figure id="A3.F10" class="ltx_figure"><img src="/html/2309.12288/assets/x11.png" id="A3.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="664" height="398" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F10.3.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="A3.F10.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Accuracy accross training for Llama-7b on the instruction-reversal task for experiment 2.</span></figcaption>
</figure>
</section>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Compute costs</h2>

<div id="A4.p1" class="ltx_para">
<p id="A4.p1.1" class="ltx_p">The sweeps and queries to the OpenAI API in experiments 1 and 2 cost approximately $100 each. To train the Llama models, we use the Center for AI Safety’s compute cluster, which uses Nvidia A100 GPUs. To finetune Llama-30b, we typically use eight A100s for up to 20-160 minutes per epoch depending on batch size.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2309.12287" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2309.12288" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2309.12288">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2309.12288" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2309.12289" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Oct  5 13:30:33 2023 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>