<html lang="en" data-theme="light"><head>
<meta content="text/html; charset=utf-8" http-equiv="content-type">
<title>Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling</title>
<!--Generated on Mon Jan 29 18:12:18 2024 by LaTeXML (version 0.8.7) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/ar5iv_0.7.4.min.css" rel="stylesheet" type="text/css">
<link href="https://arxiv.org/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css">
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/addons.js"></script>
<script src="https://arxiv.org/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="https://arxiv.org/html/2401.16380v1/"><link rel="stylesheet" href="https://use.typekit.net/rwr5zpx.css"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-16x16.png" sizes="16x16"><link rel="icon" type="image/png" href="https://static.arxiv.org/static/browse/0.3.4/images/icons/favicon-32x32.png" sizes="32x32"></head>
<body><header class="mob_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
        <img alt="logo" class="logomark" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logomark-small-white.svg">
        <span class="sr-only">Back to arXiv</span>
      </a>
    </div>

    <!--TOC, dark mode, links-->
    <div class="html-header-nav">
      <!--back to abstract-->
      
        <a class="nav-link ar5iv-footer-button hover-effect" aria-label="Back to abstract page" href="https://arxiv.org/abs/2401.16380v1">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 512 512" fill="#ffffff" aria-hidden="true">
            <path d="M502.6 278.6c12.5-12.5 12.5-32.8 0-45.3l-128-128c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3L402.7 224 192 224c-17.7 0-32 14.3-32 32s14.3 32 32 32l210.7 0-73.4 73.4c-12.5 12.5-12.5 32.8 0 45.3s32.8 12.5 45.3 0l128-128zM160 96c17.7 0 32-14.3 32-32s-14.3-32-32-32L96 32C43 32 0 75 0 128L0 384c0 53 43 96 96 96l64 0c17.7 0 32-14.3 32-32s-14.3-32-32-32l-64 0c-17.7 0-32-14.3-32-32l0-256c0-17.7 14.3-32 32-32l64 0z"></path>
        </svg>
        </a>
      <!--dark mode-->
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
        <span class="color-scheme-icon" aria-label="Light mode"></span>
      </a>
      <!--nav-->
      <button class="navbar-toggler ar5iv-footer-button" type="button" data-bs-theme="dark" data-bs-toggle="collapse" aria-expanded="false" data-bs-target=".ltx_page_main >.ltx_TOC.mobile" aria-controls="navbarSupportedContent" aria-label="Toggle navigation" style="border:none; margin-right: 0em;">
        <svg xmlns="http://www.w3.org/2000/svg" height="1.25em" viewBox="0 0 448 512" aria-hidden="true" role="img" fill="#ffffff"><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"></path></svg>
      </button>
    </div>
    </header><header class="desktop_header">
    <div class="html-header-logo">
      <a href="https://arxiv.org/">
          <img alt="logo" class="logo" role="presentation" width="100" src="https://services.dev.arxiv.org/html/static/arxiv-logo-one-color-white.svg">
          <span class="sr-only">Back to arXiv</span>
      </a>
    </div>
    <div class="html-header-message" role="banner">
        <p>This is <strong>experimental HTML</strong> to improve accessibility. We invite you to report rendering errors. <span class="sr-only">Use Alt+Y to toggle on accessible reporting links and Alt+Shift+Y to toggle off.</span> Learn more <a href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">about this project</a> and <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">help improve conversions</a>.
        </p>
    </div>
    <nav class="html-header-nav">
      <a class="ar5iv-footer-button hover-effect" href="https://info.arxiv.org/about/accessible_HTML.html" target="_blank">Why HTML?</a>
      <a class="ar5iv-footer-button hover-effect" target="_blank" href="#myForm" onclick="event.preventDefault(); var modal = document.getElementById('myForm'); modal.style.display = 'block'; bugReportState.setInitiateWay('Header');">Report Issue</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/abs/2401.16380v1">Back to Abstract</a>
      <a class="ar5iv-footer-button hover-effect" href="https://arxiv.org/pdf/2401.16380v1" target="_blank">Download PDF</a>
      <a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle dark/light mode">
          <span class="color-scheme-icon"></span>
      </a>
    </nav></header>

<div class="ltx_page_main" id="main">
<nav class="ltx_TOC mobile collapse" aria-labelledby="toc_header"><h2 id="toc_header" class="sr-only">Table of Contents</h2>

      <div id="listIcon" type="button" class="hide">
          <svg width="17px" height="17px" viewBox="0 0 512 512" style="pointer-events: none;">
          <path d="M40 48C26.7 48 16 58.7 16 72v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V72c0-13.3-10.7-24-24-24H40zM192 64c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zm0 160c-17.7 0-32 14.3-32 32s14.3 32 32 32H480c17.7 0 32-14.3 32-32s-14.3-32-32-32H192zM16 232v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V232c0-13.3-10.7-24-24-24H40c-13.3 0-24 10.7-24 24zM40 368c-13.3 0-24 10.7-24 24v48c0 13.3 10.7 24 24 24H88c13.3 0 24-10.7 24-24V392c0-13.3-10.7-24-24-24H40z"></path>
          </svg>
      </div>
      <div id="arrowIcon" type="button">
          <svg width="17px" height="17px" viewBox="0 0 448 512" style="pointer-events: none;">
          <path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path>
          </svg>
      </div><ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S1" title="1 Introduction ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S2" title="2 Related Work ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S2.SS0.SSS0.Px1" title="Neural Scaling Laws for Language Models ‣ 2 Related Work ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Neural Scaling Laws for Language Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S2.SS0.SSS0.Px2" title="Dataset Selection ‣ 2 Related Work ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Dataset Selection</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S2.SS0.SSS0.Px3" title="Data Augmentation and synthetic data ‣ 2 Related Work ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Data Augmentation and synthetic data</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S3" title="3 WRAP: Web Rephrase Augmented Pretraining ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span><span class="ltx_text ltx_font_bold">WRAP</span>: Web Rephrase Augmented Pretraining</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S3.SS1" title="3.1 Rephrasing the Web ‣ 3 WRAP: Web Rephrase Augmented Pretraining ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Rephrasing the Web</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S3.SS1.SSS0.Px1" title="Rephrasing Styles ‣ 3.1 Rephrasing the Web ‣ 3 WRAP: Web Rephrase Augmented Pretraining ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Rephrasing Styles</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S3.SS1.SSS0.Px2" title="Generating Synthetic Data ‣ 3.1 Rephrasing the Web ‣ 3 WRAP: Web Rephrase Augmented Pretraining ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Generating Synthetic Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S3.SS1.SSS0.Px3" title="Combining Real and Synthetic Data ‣ 3.1 Rephrasing the Web ‣ 3 WRAP: Web Rephrase Augmented Pretraining ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Combining Real and Synthetic Data</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S3.SS2" title="3.2 Implementation Details ‣ 3 WRAP: Web Rephrase Augmented Pretraining ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Implementation Details</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S3.SS2.SSS0.Px1" title="Architecture ‣ 3.2 Implementation Details ‣ 3 WRAP: Web Rephrase Augmented Pretraining ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S3.SS2.SSS0.Px2" title="Pre-training ‣ 3.2 Implementation Details ‣ 3 WRAP: Web Rephrase Augmented Pretraining ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Pre-training</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S4" title="4 Perplexity Evaluation ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Perplexity Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S4.SS0.SSS0.Px1" title="Data Complexity ‣ 4 Perplexity Evaluation ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Data Complexity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S4.SS0.SSS0.Px2" title="Learning Speed ‣ 4 Perplexity Evaluation ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Learning Speed</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S5" title="5 Zero-shot Tasks ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Zero-shot Tasks</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S5.SS1" title="5.1 Datasets ‣ 5 Zero-shot Tasks ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Datasets</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S5.SS1.SSS0.Px1" title="General Understanding ‣ 5.1 Datasets ‣ 5 Zero-shot Tasks ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">General Understanding</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S5.SS1.SSS0.Px2" title="Specialized Knowledge ‣ 5.1 Datasets ‣ 5 Zero-shot Tasks ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Specialized Knowledge</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S5.SS2" title="5.2 Results ‣ 5 Zero-shot Tasks ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S5.SS2.SSS0.Px1" title="Baselines Methods ‣ 5.2 Results ‣ 5 Zero-shot Tasks ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Baselines Methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S5.SS2.SSS0.Px2" title="General Improvements ‣ 5.2 Results ‣ 5 Zero-shot Tasks ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">General Improvements</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S5.SS2.SSS0.Px3" title="Specialized Knowledge Tasks ‣ 5.2 Results ‣ 5 Zero-shot Tasks ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Specialized Knowledge Tasks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S5.SS2.SSS0.Px4" title="Specific Improvements ‣ 5.2 Results ‣ 5 Zero-shot Tasks ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Specific Improvements</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6" title="6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Analysis and Ablations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.SS1" title="6.1 Data Combination Analysis ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Data Combination Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.SS1.SSS0.Px1" title="RQ1: How important is it to have real C4 data? ‣ 6.1 Data Combination Analysis ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">RQ1: How important is it to have real C4 data?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.SS1.SSS0.Px2" title="RQ2: Does a combination of multiple synthetic datasets improve performance? ‣ 6.1 Data Combination Analysis ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">RQ2: Does a combination of multiple synthetic datasets improve performance?</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.SS2" title="6.2 Method Ablations ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Method Ablations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.SS2.SSS0.Px1" title="RQ3: How important is to have a high-quality re-phraser? ‣ 6.2 Method Ablations ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">RQ3: How important is to have a high-quality re-phraser?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.SS2.SSS0.Px2" title="RQ4: Does synthetic data improve over augmentations? ‣ 6.2 Method Ablations ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">RQ4: Does synthetic data improve over augmentations?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.SS2.SSS0.Px3" title="RQ5: How does the style of synthetic data impact performance on specialized domains? ‣ 6.2 Method Ablations ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">RQ5: How does the style of synthetic data impact performance on specialized domains?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.SS2.SSS0.Px4" title="RQ6: Is there data leakage from the rephrase model to the trained model? ‣ 6.2 Method Ablations ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">RQ6: Is there data leakage from the rephrase model to the trained model?</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S7" title="7 Limitations and Opportunities ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Limitations and Opportunities</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S7.SS1" title="7.1 Cost Analysis ‣ 7 Limitations and Opportunities ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Cost Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S7.SS2" title="7.2 Diversity of Synthetic Generations ‣ 7 Limitations and Opportunities ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Diversity of Synthetic Generations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S8" title="8 Conclusion ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A1" title="Appendix A Dataset Details ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Dataset Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A1.SS1" title="A.1 Training Dataset ‣ Appendix A Dataset Details ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Training Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A1.SS2" title="A.2 Pile Perplexity Evaluation ‣ Appendix A Dataset Details ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Pile Perplexity Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A1.SS2.SSS1" title="A.2.1 Pile Weighted Average Ratios ‣ A.2 Pile Perplexity Evaluation ‣ Appendix A Dataset Details ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2.1 </span>Pile Weighted Average Ratios</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A1.SS3" title="A.3 Zero-shot Evaluation Dataset ‣ Appendix A Dataset Details ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Zero-shot Evaluation Dataset</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A1.SS3.SSS0.Px1" title="Specialized Knowledge ‣ A.3 Zero-shot Evaluation Dataset ‣ Appendix A Dataset Details ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">Specialized Knowledge</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A1.SS3.SSS0.Px2" title="General Understanding ‣ A.3 Zero-shot Evaluation Dataset ‣ Appendix A Dataset Details ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title">General Understanding</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A2" title="Appendix B Filtering Details for Synthetic Data ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Filtering Details for Synthetic Data</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A2.SS1" title="B.1 Methodology ‣ Appendix B Filtering Details for Synthetic Data ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Methodology</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A3" title="Appendix C Properties of Synthetic Corpus ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Properties of Synthetic Corpus</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A3.SS1" title="C.1 Experimental Setup ‣ Appendix C Properties of Synthetic Corpus ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>Experimental Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A3.SS2" title="C.2 Semantic Properties ‣ Appendix C Properties of Synthetic Corpus ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>Semantic Properties</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A3.SS3" title="C.3 Syntactic Properties ‣ Appendix C Properties of Synthetic Corpus ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.3 </span>Syntactic Properties</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A4" title="Appendix D Evaluation Metrics ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A5" title="Appendix E Additional Results for Smaller Model and Token Sizes ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Additional Results for Smaller Model and Token Sizes</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A5.SS1" title="E.1 Results for 350M Models Trained for 75B Tokens ‣ Appendix E Additional Results for Smaller Model and Token Sizes ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.1 </span>Results for 350M Models Trained for 75B Tokens</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A5.SS2" title="E.2 Results for 1.3B Models Trained for 150B Tokens ‣ Appendix E Additional Results for Smaller Model and Token Sizes ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.2 </span>Results for 1.3B Models Trained for 150B Tokens</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A6" title="Appendix F LLM Leaderboard Few-shot Results ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>LLM Leaderboard Few-shot Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A7" title="Appendix G Rephrase Prompt Templates ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Rephrase Prompt Templates</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A8" title="Appendix H Rephrase Examples ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">H </span>Rephrase Examples</span></a></li>
</ol></nav>

<div class="ltx_page_content">
<div aria-label="Conversion errors have been found" class="package-alerts ltx_document" role="status">
<button aria-label="Dismiss alert" onclick="closePopup()">
<span aria-hidden="true"><svg aria-hidden="true" focusable="false" height="20" role="presentation" viewBox="0 0 44 44" width="20">
<path d="M0.549989 4.44999L4.44999 0.549988L43.45 39.55L39.55 43.45L0.549989 4.44999Z"></path>
<path d="M39.55 0.549988L43.45 4.44999L4.44999 43.45L0.549988 39.55L39.55 0.549988Z"></path>
</svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button></span>
</button>
<p>HTML conversions <a href="https://info.dev.arxiv.org/about/accessibility_html_error_messages.html" target="_blank">sometimes display errors</a> due to content that did not convert correctly from the source. This paper uses the following packages that are not yet supported by the HTML conversion tool. Feedback on these issues are not necessary; they are known and are being worked on.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul arial-label="Unsupported packages used in this paper">
<li>failed: inconsolata</li>
<li>failed: pdfcol</li>
<li>failed: shellesc</li>
</ul>
<p>Authors: achieve the best HTML results from your LaTeX submissions by following these <a href="https://info.arxiv.org/help/submit_latex_best_practices.html" target="_blank">best practices</a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div><div class="section" id="target-section"><div id="license-tr">License: arXiv.org perpetual non-exclusive license</div><div id="watermark-tr">arXiv:2401.16380v1 [cs.CL] 29 Jan 2024</div></div>
<script>
            function closePopup() {
                document.querySelector('.package-alerts').style.display = 'none';
            }
        </script>
<article class="ltx_document ltx_authors_1line"><span class="ltx_ERROR undefined" id="id1">\pdfcolInitStack</span>
<div class="ltx_para" id="p1">
<p class="ltx_p" id="p1.1">tcb@breakable</p>
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<h1 class="ltx_title ltx_title_document">Rephrasing the Web:
<br class="ltx_break">A Recipe for Compute and Data-Efficient Language Modeling</h1><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pratyush Maini   
<br class="ltx_break">Carnegie Mellon Univeristy
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id2.1.id1">pratyushmaini@cmu.edu</span>
&amp;Skyler Seto<span class="ltx_note ltx_role_footnotemark" id="footnotex1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span><span class="ltx_tag ltx_tag_note">1</span></span></span></span>, He Bai, David Grangier, Yizhe Zhang, Navdeep Jaitly
<br class="ltx_break">Apple 
<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" id="id3.2.id2">{sseto,hbai22,grangier,yizhe_zhang,njaitly}@apple.com
<br class="ltx_break"></span>
</span><span class="ltx_author_notes">Equal ContributionWork done during internship at Apple</span></span>
</div><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<p class="ltx_p" id="id1.1">대형 언어 모델은 종종 구조화되지 않고 시끄럽고 표현이 좋지 않은 웹의 거대한 스크래프에서 훈련된다. 현재의 스케일링 법칙들은 그러한 데이터로부터 학습하는 것이 트레이닝되는 모델의 크기에 따라 증가하는 컴퓨팅 및 데이터 둘 다를 필요로 한다는 것을 보여준다. 이는 사전 훈련과 관련된 계산 비용과 기간이 크고 웹에서 고품질 데이터의 희소성이 임박하기 때문에 실현 불가능하다. 본 연구에서는 <span class="ltx_text ltx_font_bold" id="id1.1.1">W</span>eb <span class="ltx_text ltx_font_bold" id="id1.1.2">R</span>ephrase <span class="ltx_text ltx_font_bold" id="id1.1.3">A</span>ugmented <span class="ltx_text ltx_font_bold" id="id1.1.4">P</span>re-training (<span class="ltx_text ltx_font_bold" id="id1.1.5">WRAP</span>off-the-shelf instruction-tuned model prompted to paraphrase documents on the web on the specific styles, such "like Wikipedia" or in "question-answer format" to jointly pre-train LLMs on real and synthetic rephrases. 먼저, 자연 소음인 C4 데이터셋에서 <span class="ltx_text ltx_font_bold" id="id1.1.6">WRAP</span>을 사용하면 <math alttext="\sim 3\times" class="ltx_math_unparsed" display="inline" id="id1.1.m1.1"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1b"><mo id="id1.1.m1.1.1">∼</mo><mn id="id1.1.m1.1.2">3</mn><mo id="id1.1.m1.1.3" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="id1.1.m1.1c">\sim 3\times</annotation><annotation encoding="application/x-llamapun" id="id1.1.m1.1d">∼ 3 ×</annotation></semantics></math>에 의한 사전 학습 속도가 빨라진다는 것을 보인다. 동일한 사전 훈련 컴퓨팅 예산에서 파일의 서로 다른 하위 집합에 걸쳐 평균 10% 이상의 복잡도를 개선하고 13개의 태스크에 걸쳐 제로 샷 질문 답변 정확도를 2% 이상 개선한다. 둘째, 학습 데이터의 구성이 OOD 설정에서 LLM의 성능에 어떻게 영향을 미칠 수 있는지에 대한 통찰력을 제공하여 재표현 스타일이 모델의 성능에 미치는 영향을 조사한다. 우리의 이익은 (i) 다운스트림 평가 스타일을 밀접하게 반영하는 스타일 다양성을 통합하고 (ii) 웹 스크래핑 데이터보다 '품질'이 높기 때문에 재구문 합성 데이터가 실제 데이터보다 활용도가 높기 때문이다.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">대규모 언어 모델(LLM) 사전 훈련은 크게 민주화되고 개방되어 다양한 학술 실험실 및 산업계가 맞춤형 LLM을 사전 훈련할 수 있다. 그러나 이러한 모델 간의 주요 차별점은 훈련에 사용되는 데이터의 구성과 크기이다. 비구조화 및/또는 낮은 phrased [<cite class="ltx_cite ltx_citemacro_citep">(Eisenstein, <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib19" title="">2013</a>)</cite>인 웹의 스크래프를 필터링하려면 데이터 큐레이션 전략이 필요합니다. 이러한 전략 중 일부는 공개되었지만 <cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib10" title="">2020</a>; Wenzek et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib67" title="">2020</a>; Penedo et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib54" title="">2023</a>)</cite> 대부분의 최첨단 데이터 큐레이션 기술은 연구 커뮤니티에 알려지지 않았으며, 일화적인 증거만 남아 있다. 데이터 큐레이션에 대한 연구는 여러 번의 재교육을 필요로 하므로 실용적인 개선으로 이어지는 기술을 문서화하는 데 많은 노력이 필요하다. 반면에, 언어 모델에 대한 스케일링 법칙(예: Chinchilla scaling laws <cite class="ltx_cite ltx_citemacro_citep">(Hoffmann et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib32" title="">2022</a>)</cite>)은 모델 크기가 증가함에 따라 트레이닝 컴퓨팅과 데이터 크기도 선형적으로 증가해야 함을 보여준다. 이는 (a) 고품질 데이터가 제한된 <cite class="ltx_cite ltx_citemacro_citep">(Villalobos et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib65" title="">2022</a>)</cite>이고, 적은 수의 epoch(4개 이상)에 대해 반복하면 수익 감소 또는 오버피팅 <cite class="ltx_cite ltx_citemacro_citep">(Muennighoff et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib50" title="">2023</a>; Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib62" title="">2023</a>; Xue et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib70" title="">2023</a></cite>; 및 (b) 이러한 긴 지속 시간에 대한 사전 훈련은 엄청나게 비싸다.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">한편, 합성 데이터의 사용은 명령어 미세 조정, RLHF <cite class="ltx_cite ltx_citemacro_citep">(Ouyang et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib51" title="">2022</a>)</cite> 및 명령어 역번역 <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib40" title="">2023b</a>)</cite>를 통해 사전 훈련된 LLMs를 정렬하는 패러다임에서 두드러지게 되었다. 최근에는 사전 훈련의 맥락에서 합성 데이터를 사용하여 Tiny Stories <cite class="ltx_cite ltx_citemacro_citep">(Eldan &amp; Li, <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib20" title="">2023</a>)</cite> 및 Textbook 품질 합성 데이터 <cite class="ltx_cite ltx_citemacro_citep">(Gunasekar et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib28" title="">2023</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib41" title="">2023c</a>)</cite>와 같은 데이터 세트를 생성했다. 이들은 특정 작업에서 더 큰 언어 모델만큼 성능이 뛰어난 (Phi 모델 패밀리와 같은) 더 작은 언어 모델을 훈련하는 데 사용되었다. 그러나, 그들의 데이터 생성 프로세스는 대체로 불투명하고 엄청나게 비싸며, 수십억 개의 토큰을 생성하기 위한 GPT-3.5 모델을 촉구해야 한다. 또한, 이러한 데이터 생성은 우리가 잘 수행하기를 원하는 태스크와 관련된 데이터를 구체적으로 생성함으로써 큰 "지식 편향"을 생성할 수 있다. 합성 데이터는 가능성을 보여주었지만, 이것이 합성 데이터의 더 높은 품질 특성 때문인지 아니면 전략적 주제 선택 때문인지는 불분명하다.</p>
</div>
<figure class="ltx_figure" id="S1.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S1.F0.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="742" id="S1.F0.sf1.g1" src="https://arxiv.org/html/2401.16380v1/x1.png" width="761">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S1.F0.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="787" id="S1.F0.sf2.g1" src="https://arxiv.org/html/2401.16380v1/x2.png" width="761">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(b) </span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_flex_size_3 ltx_align_center" id="S1.F0.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="789" id="S1.F0.sf3.g1" src="https://arxiv.org/html/2401.16380v1/x3.png" width="760">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(c) </span></figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>(a) <span class="ltx_text ltx_font_bold" id="S1.F1.2.1">WRAP</span>&nbsp;Recipe: We prompt an off-the-shelf instruction-tuned model to rephrase articles on the web, and pre-train an LLM on a mixture of real and synthetic data. &nbsp;(b) Zero-shot performance of GPT 1.3B models trained on combinations of C4 and synthetic variations. Each step corresponds to a batch of 1M samples. (c) Weighted average perplexity over 21 sub-domains of the Pile for varying model sizes and amount of pre-training data.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">본 연구에서는 <span class="ltx_text ltx_font_bold" id="S1.p3.1.1">W</span>eb <span class="ltx_text ltx_font_bold" id="S1.p3.1.2">R</span>ephrase <span class="ltx_text ltx_font_bold" id="S1.p3.1.3">A</span>ugmented <span class="ltx_text" id="S1.p3.1.4">P</span>re-training (<span class="ltx_text ltx_font_bold" id="S1.p3.1.5">WRAP</span>—that attempts to bridge of three important challenges stemming from the ambiguity around data curation— (i) 어떤 data should you pre-train on? (ii) 제한된 데이터로 어떻게 사전 훈련을 할 수 있는가? (iii) 어떻게 계산적으로 효율적으로 사전 훈련을 할 수 있는가? 특히, Off-the-shelf 중간 크기의 LLM을 사용하여 웹에서 문서를 다시 작성하면 모델이 웹의 원시 텍스트에서 학습하는 것보다 훨씬 더 효율적으로 학습할 수 있으며, 배포 데이터 세트 중 <em class="ltx_emph ltx_font_italic" id="S1.p3.1.6">can not</em>이 추가 웹 데이터와 상쇄될 수 있다는 성능 향상을 설명한다. 제안된 방법은 사전 학습된 기성 LLM을 사용하여 웹 코퍼스에서 문서를 다른 스타일로 재구문화하는 것을 포함한다. 우리의 접근법의 개요는 그림 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S1.F0.sf1" title="0(a) ‣ Figure 1 ‣ 1 Introduction ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">0(a)</span></a>에 나와 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">본 연구에서는 <cite class="ltx_cite ltx_citemacro_citet">Gunasekar et al.의 합성 데이터 큐레이션 과정에서 직면하는 두 가지 중요한 문제를 해결한다. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib28" title="">2023</a>)</cite>—생성 비용 및 데이터 편향—웹에서 기사를 다시 표현합니다. (i) <span class="ltx_text ltx_font_bold" id="S1.p4.1.1">WRAP</span>은 오픈 소스 사용을 허용하고, LLM(1.8B/7B v/s GPT3.5)은 지식 뱅크로서 LLM에 의존하지 않기 때문에, 훨씬 더 작은 LLM(1.8B/7B v/s GPT3.5)을 사용하여 서로 다른 스타일로 구조화되지 않은 문서를 재구문화한다. (ii) 리프레이징의 특성을 유지하는 정보 덕분에, 우리는 사실적 오류 및/또는 데이터 편향에 취약할 수 있는 정보에 대해 LLM에 의존하지 않고 웹의 자연적 다양성을 활용할 수 있다. 우리의 작업은 "스타일"만으로도 다운스트림 성능에서 큰 이득을 얻을 수 있음을 보여준다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.2">C4에서 <span class="ltx_text ltx_font_bold" id="S1.p5.2.1">WRAP</span>을 사용하여 13개의 서로 다른 제로 샷 태스크와 21개의 서로 다른 언어 모델링 도메인에서 모델 성능을 평가하고 합성 데이터로 사전 훈련 LLM을 사용하면 5배 더 적은 데이터 또는 3배 더 적은 컴퓨팅으로 동등한 모델을 훈련할 수 있음을 발견한다. 사실, 우리의 합성 데이터 훈련 모델은 또한 여러 제로 샷 Q/A 태스크에 걸쳐 3조 토큰(10x 데이터 및 컴퓨팅)에 대해 훈련된 최근의 TinyLLama 모델을 능가한다. 또한 파일에서 <math alttext="\sim 50\%" class="ltx_Math" display="inline" id="S1.p5.1.m1.1"><semantics id="S1.p5.1.m1.1a"><mrow id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml"><mi id="S1.p5.1.m1.1.1.2" xref="S1.p5.1.m1.1.1.2.cmml"></mi><mo id="S1.p5.1.m1.1.1.1" xref="S1.p5.1.m1.1.1.1.cmml">∼</mo><mrow id="S1.p5.1.m1.1.1.3" xref="S1.p5.1.m1.1.1.3.cmml"><mn id="S1.p5.1.m1.1.1.3.2" xref="S1.p5.1.m1.1.1.3.2.cmml">50</mn><mo id="S1.p5.1.m1.1.1.3.1" xref="S1.p5.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><apply id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1"><csymbol cd="latexml" id="S1.p5.1.m1.1.1.1.cmml" xref="S1.p5.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S1.p5.1.m1.1.1.2.cmml" xref="S1.p5.1.m1.1.1.2">absent</csymbol><apply id="S1.p5.1.m1.1.1.3.cmml" xref="S1.p5.1.m1.1.1.3"><csymbol cd="latexml" id="S1.p5.1.m1.1.1.3.1.cmml" xref="S1.p5.1.m1.1.1.3.1">percent</csymbol><cn id="S1.p5.1.m1.1.1.3.2.cmml" type="integer" xref="S1.p5.1.m1.1.1.3.2">50</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">\sim 50\%</annotation><annotation encoding="application/x-llamapun" id="S1.p5.1.m1.1d">∼ 50 %</annotation></semantics></math>에 의한 복잡도의 감소를 관찰하고, 전체 C4 코퍼스의 <math alttext="15\%" class="ltx_Math" display="inline" id="S1.p5.2.m2.1"><semantics id="S1.p5.2.m2.1a"><mrow id="S1.p5.2.m2.1.1" xref="S1.p5.2.m2.1.1.cmml"><mn id="S1.p5.2.m2.1.1.2" xref="S1.p5.2.m2.1.1.2.cmml">15</mn><mo id="S1.p5.2.m2.1.1.1" xref="S1.p5.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p5.2.m2.1b"><apply id="S1.p5.2.m2.1.1.cmml" xref="S1.p5.2.m2.1.1"><csymbol cd="latexml" id="S1.p5.2.m2.1.1.1.cmml" xref="S1.p5.2.m2.1.1.1">percent</csymbol><cn id="S1.p5.2.m2.1.1.2.cmml" type="integer" xref="S1.p5.2.m2.1.1.2">15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.2.m2.1c">15\%</annotation><annotation encoding="application/x-llamapun" id="S1.p5.2.m2.1d">15 %</annotation></semantics></math>에 대한 실제 및 합성 재구문의 조합으로 학습된 350M 파라미터 모델이 전체 C4에서 1.3B 파라미터를 사전 학습하는 것보다 우수하다는 점에 주목한다. 마지막으로, <span class="ltx_text ltx_font_bold" id="S1.p5.2.2">WRAP</span> 기반 LLM 사전 학습을 개선하기 위해 데이터 누출 가능성, 합성 데이터 스타일의 특성 및 합성 데이터 결합 방법에 대한 분석을 수행한다.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Neural Scaling Laws for Language Models</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">신경 스케일링 법칙들은 고정된 양의 컴퓨팅을 위한 최적의 모델 파라미터들의 수 및 트레이닝 데이터의 양을 관련시킨다. <cite class="ltx_cite ltx_citemacro_citet">Hoffmann et al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib32" title="">2022</a>)</cite>는 언어 모델에 대한 Chinchilla 스케일링 법칙을 제시하여 모델의 크기와 필요한 훈련 데이터의 양 사이에 선형 관계가 있음을 증명하였다. 그들의 연구 결과는 Gopher <cite class="ltx_cite ltx_citemacro_citep">(Rae et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib56" title="">2021</a>)</cite>와 같은 이전 모델이 심각하게 과소 훈련되었음을 나타낸다. 최근, Llama <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib62" title="">2023</a>)</cite>와 같은 모델들은 훨씬 더 많은 데이터로 학습된다. 이러한 스케일링 법칙은 단일-에포크 훈련의 패러다임을 위해 도출되었다. 최근 <cite class="ltx_cite ltx_citemacro_citet">Muennighoff et al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib50" title="">2023</a>)</cite>는 4개 이상의 에폭에 대해 훈련할 때 반복 데이터의 한계 효용성이 급격히 감소하고 반복 데이터 하에서 스케일링 법칙을 공식화한다는 것을 보여주었다. 동시에 <cite class="ltx_cite ltx_citemacro_citet">Xue et al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib70" title="">2023</a>)</cite>는 사전 훈련 데이터의 작은 부분이라도 반복하면 과적합으로 이어져 모델 성능을 떨어뜨릴 수 있음을 보여주었다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Dataset Selection</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">LLM을 사전 훈련하기 위해 고품질 데이터를 선택하는 것은 활성적이고 영향을 많이 받지만 연구되지 않은 연구 영역으로 남아 있다. 예를 들어, GPT-2 모델은 소셜 미디어 플랫폼인 Reddit의 모든 아웃바운드 링크에서 사전 훈련되었으며, 이는 적어도 3개의 카르마<cite 클래스="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib10" title="">2020</a>)</cite>를 받았다. 이는 문서가 <em class="ltx_emph ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.1">interesting, educational, just funny일 수 있다는 휴리스틱 지표로 사용되었다. </em> Follow-up works has used other heuristics such to prioritizing documents like wikipedia <cite class="ltx_cite ltx_citemacro_citep">(Gururangan et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib29" title="">2022</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citet">Rae et al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib56" title="">2021</a>)</cite>는 특정 불용어 부재, 문서의 길이, 알파벳 문자의 백분율, 평균 단어 길이, 기호 대 단어 비율, 글머리점으로 시작하는 선의 백분율 또는 줄임표로 끝나는 것과 같은 문서를 제거하기 위해 여러 휴리스틱 필터를 사용했다. 그들의 작업은 텍스트 데이터를 필터링하는 복잡성을 강조한다. 교육을 위해 더 나은 데이터 세트를 구축하기 위한 대안적인 패러다임은 고품질 데이터 세트를 증류하는 것이다. <cite class="ltx_cite ltx_citemacro_citet">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib69" title="">2023</a>)</cite>는 다양한 도메인의 데이터를 재가중화하여 사전 학습 언어 모델에 가장 적합한 데이터 혼합을 선택하는 방법인 DoReMi를 제안하였다. 동시에 <cite class="ltx_cite ltx_citemacro_citet">Abbas et al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib2" title="">2023</a>)</cite>는 de-duplicating pre-training data가 pre-training 효율을 향상시킬 수 있음을 보여주었다. 최근 LLMs<cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib11" title="">2023</a>; Solaiman &amp; Dennison, <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib61" title="">2021</a>; Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib74" title="">2023</a>)</cite>의 빠른 미세 조정을 위해 저품질 데이터의 자동 필터링을 위한 여러 방법이 제안되었다. 동시에, CLIP <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib55" title="">2021</a>)</cite>와 같은 이미지 언어 모델의 영역에서, Datacomp 벤치마크 [<cite class="ltx_cite ltx_citemacro_citep">(Gadre et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib23" title="">2023</a>)</cite> 및 최근 엔트리들 [<cite class="ltx_cite ltx_citemacro_citep">(Maini et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib48" title="">2023</a>; Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib71" title="">2023</a>)</cite>는 LAION <cite class="ltx_cite ltx_citemacro_citep">(Schuhmann et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib58" title="">2022</a>)</cite>와 같은 사전 훈련 데이터 세트로부터 저품질 서브세트를 필터링하는 접근법을 개발했다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Data Augmentation and synthetic data</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Eldan &amp; Li (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib20" title="">2023</a>)</cite>는 유아들이 이해할 수 있는 이야기 형태의 합성적으로 생성된 데이터셋이 코히런트 문장을 생성할 수 있는 작은 언어 모델을 학습시킬 수 있음을 보여주었다.</p>
<cite class="ltx_cite ltx_citemacro_citet">Gunasekar et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib28" title="">2023</a>)</cite> showed that textbook quality (synthetic) data alone helps models achieve state-of-the-art performance on reasoning and coding tasks. Similar approaches are used in concurrent work for enhancing coding and mathematical reasoning abilities while finetuning <cite class="ltx_cite ltx_citemacro_cite">Liu et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib43" title="">2023a</a>); Wei et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib66" title="">2023</a>)</cite>.
<cite class="ltx_cite ltx_citemacro_citet">Shumailov et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib60" title="">2023</a>)</cite> show that training on synthetic data can actually be harmful for model performance, especially when
we do multiple rounds of pre-training an LLM and then training the next LLM on data generated by the previous one.
On the other hand, some other works have shown that such a strategy can actually be useful.
<cite class="ltx_cite ltx_citemacro_citet">Li et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib40" title="">2023b</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Köksal et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib37" title="">2023</a>)</cite> discuss how a model can generate instruction data and then fine-tune on its own generated data
to improve performance.
<cite class="ltx_cite ltx_citemacro_citet">Jung et&nbsp;al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib36" title="">2023</a>)</cite> discuss how such repeated cycles of synthetic data can help train a very small paraphrase and summarization model that even outperforms GPT-3.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px3.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p2.1">비전과 멀티모달 문헌은 합성 데이터를 훈련에 사용하는 것을 검토하는 작업도 급증했다. <cite class="ltx_cite ltx_citemacro_citet">Bansal &amp; Grover (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib8" title="">2023</a>); Trabucco et al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib63" title="">2023</a>); Azizi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib5" title="">2023</a>)</cite>는 합성 데이터를 실제 데이터와 결합하여 사용하면 in-distribution 및 out-of-distribution 모두에서 최신 모델 성능을 달성한다는 것을 보여주었다. <cite class="ltx_cite ltx_citemacro_citet">Cubuk et al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib17" title="">2020</a>)</cite>는 더 나은 도메인 일반화를 위해 이미지 증강을 생성하기 위해 생성 모델을 사용했다. 또한 일반화 개선을 위한 증강의 다중성 증가 및 그 값에 대한 다수의 연구가 <cite class="ltx_cite ltx_citemacro_citep">(Choi et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib13" title="">2019</a>; Fort et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib21" title="">2021</a>; Hoffer et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib31" title="">2020</a>)</cite>에 있다. 그러나 <cite class="ltx_cite ltx_citemacro_citet">Alemohammad et al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib3" title="">2023</a>)</cite>는 그들 자신의 생성된 데이터의 5 사이클 이상 동안 트레이닝된 생성된 모델들이 심각한 모드 붕괴를 겪을 수 있음을 보여주었다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span class="ltx_text ltx_font_bold" id="S3.1.1">WRAP</span>: Web Rephrase Augmented Pretraining</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">일반 언어 모델을 사용하여 합성 데이터를 생성하는 것은 계산상 비용이 많이 들고 조작상 어려울 수 있다. LLMs<cite class="ltx_cite ltx_citemacro_citep">(Gunasekar et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib28" title="">2023</a>)</cite>를 사용하여 합성 교과서 품질 데이터를 생성하는 이전 접근법은 (1) 훈련할 가치가 있는 기사를 생성하기에 충분한 세계 지식을 포함하는 언어 모델을 요구하여 생성 비용을 증가시킨다; (2) 고품질 생성을 가능하게 하는 프롬프트의 신중한 선택 및 합성 코퍼스의 지식 격차를 채우는 다양한 기사를 생성한다. 이 도전은 <cite class="ltx_cite ltx_citemacro_citet">Li et al의 후속 작업에서 강조되었다. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib41" title="">2023c</a>)</cite>이며, 웹의 자연적인 다양성에 대해 훈련된 것과 반대로 언어 모델들 <cite class="ltx_cite ltx_citemacro_citep">(Maini, <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib47" title="">2023</a>)</cite>에서 의도하지 않게 편향적으로 크리핑할 가능성이 있다. (i) 생성 비용과 (ii) 데이터 다양성의 문제에 대한 해결책으로, 우리는 웹에서 기사의 자연스러운 다양성을 활용하여 웹에서 잡음이 많고 구조화되지 않은 기사의 고품질 패러프레이즈를 생성하기 위해 훨씬 더 작은 LLMs(GPT-3.5)를 활용할 수 있는 <span class="ltx_text ltx_font_bold" id="S3.p1.1.1">WRAP</span> 을 제안한다.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Rephrasing the Web</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">과거 연구에서 위키피디아의 텍스트와 같은 높은 가중치의 고품질 데이터가 언어 모델링을 개선하는 데 유용할 수 있음이 관찰되었다. 이러한 용어는 일반적으로 매우 느슨하게 정의되었으며 동일한 [cite class="ltx_cite ltx_citemacro_citep">(Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib10" title="">2020</a>; Wenzek et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib67" title="">2020</a>)</cite>의 일화적인 증거만 있다. 동시에 웹 데이터는 질의 응답이나 대화 형식의 텍스트가 부족하여 언어 모델의 두드러진 사용 사례이다. 이 두 가지 통찰력을 바탕으로 작업에 대한 리프레이징 스타일을 설계합니다.</p>
</div>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Rephrasing Styles</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.1">위의 일화적 증거 대신, 우리는 웹에서 문서를 4가지 다른 스타일로 바꾸려고 시도한다. (i) 쉬운(유아도 이해할 텍스트), (ii) 중간(위키피디아에서 발견되는 것과 같은 고품질 영어), (iii) 딱딱한(간결하고 난해한 언어), (iv) 질의응답 형식이다. 이러한 양식적 변형에서 리프레이징을 작동화하기 위해 명령 조정 모델을 적절하게 프롬프트한다. 이 네 가지 스타일의 수정된 예제와 작업에 사용된 프롬프트 템플릿은 부록 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A7" title="Appendix G Rephrase Prompt Templates ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">G</span></a>에 나와 있다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Generating Synthetic Data</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.1">이제 우리는 C4<cite class="ltx_cite ltx_citemacro_citep">(Raffel et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib57" title="">2020</a>)</cite>(모든 실험에 사용)와 같은 웹 크롤링된 데이터 세트에서 텍스트를 재구문화하기 위해 명령어 조정 언어 모델을 활용하는 방법을 자세히 설명한다. 특히, frozen Mistral-7B instruction-tuned model <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib33" title="">2023</a>)</cite>(Section <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6" title="6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">6</span></a>의 Ablations 참조). "중간" 스타일로 합성 데이터를 생성하기 위해, Mistral 모델은 다음 명령어를 사용하여 프롬프트된다: <em class="ltx_emph ltx_font_italic" id="S3.SS1.SSS0.Px2.p1.1.1">"다음 단락에 대해 Wikipedia의 문장에서와 같은 고품질 영어의 패러프레이즈를 제공한다"</em>. 프롬프트는 '중간' 크기의 LLM과 GPT-4의 출력을 비교하여 반복적인 인간 피드백을 사용하여 생성되었다. 우리는 모델 출력을 사용하여 원본 노이즈 웹 데이터에 해당하는 "고품질" 합성 데이터의 병렬 코퍼스를 생성한다. 각 예제에는 최대 300개의 토큰이 있으며, 이는 LLM에 300개 이상의 토큰을 다시 말하도록 요청하는 것이 종종 정보 손실로 이어진다는 경험적 관찰을 기반으로 결정되었다. 데이터 품질에 대한 논의는 Section <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A3" title="Appendix C Properties of Synthetic Corpus ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">C</span></a>에서 찾을 수 있다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Combining Real and Synthetic Data</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS1.SSS0.Px3.p1.1">우리의 웹 데이터 재작성 방법은 인터넷에서 발견되는 정보 다양성을 자연스럽게 통합한다. 그러나 실제 데이터에 노이즈를 포함하지 않는다. 합성 데이터가 LLMs 사전 학습에 더 빠르게 도움이 될 수 있지만, 우리는 또한 LLMs이 사용자에 직면하는 상황에서 실패하지 않도록 오타 및 언어 오류로 채워질 수 있는 노이즈 있는 웹 텍스트를 이해할 수 있기를 원한다. 이러한 스타일 다양성을 언어 모델링에 통합하기 위해 실제 데이터와 합성 데이터를 1:1 비율로 샘플링한다.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Implementation Details</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Architecture</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.1">디코더 전용 변압기 모델  <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib64" title="">2017</a>)</cite>를 소형, 중형, XL의 세 가지 스케일로 훈련합니다. 소규모(128M 파라미터) 모델은 12개의 레이어, 12개의 어텐션 헤드, 768의 은닉 차원 크기로 구성된다. 중규모(350M 파라미터) 모델은 24개의 레이어, 16개의 어텐션 헤드, 1024의 은닉 차원 크기로 구성된다. XL-scale(1.3B 파라미터) 모델은 24개의 레이어, 16개의 어텐션 헤드, 2048의 은닉 차원 크기로 구성된다. 두 모델 모두 드롭아웃을 사용하지 않으며 최대 시퀀스 길이가 1024이다. 모델은 NVIDIA의 <a class="ltx_ref ltx_href" href="https://github.com/NVIDIA/Megatron-LM" title="">Megatron-LM</a> 리포지토리를 사용하여 학습된다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Pre-training</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.7">달리 명시되지 않는 한 100만 토큰의 배치 크기로 총 300k 단계에 대해 모든 XL 모델을 훈련합니다. 128M 및 350M 파라미터 모델에 대해서는 <math alttext="3e^{-4}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.1.m1.1"><semantics id="S3.SS2.SSS0.Px2.p1.1.m1.1a"><mrow id="S3.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml">3</mn><mo id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml">⁢</mo><msup id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.2" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.2.cmml">e</mi><mrow id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.cmml"><mo id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3a" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.cmml">−</mo><mn id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.2" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1"><times id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.1"></times><cn id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.2">3</cn><apply id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.2">𝑒</ci><apply id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3"><minus id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3"></minus><cn id="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.2.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.1.m1.1c">3e^{-4}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px2.p1.1.m1.1d">3 italic_e start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math>의 최대 학습률을 사용하고, 1.3B 파라미터 모델에 대해서는 <math alttext="2e^{-4}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.2.m2.1"><semantics id="S3.SS2.SSS0.Px2.p1.2.m2.1a"><mrow id="S3.SS2.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.cmml"><mn id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml">2</mn><mo id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.1" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.1.cmml">⁢</mo><msup id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.2" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.2.cmml">e</mi><mrow id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3.cmml"><mo id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3a" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3.cmml">−</mo><mn id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3.2" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.2.m2.1b"><apply id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1"><times id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.1"></times><cn id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.2">2</cn><apply id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.2">𝑒</ci><apply id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3"><minus id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3.1.cmml" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3"></minus><cn id="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3.2.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.2.m2.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.2.m2.1c">2e^{-4}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px2.p1.2.m2.1d">2 italic_e start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math>의 최대 학습률을 사용한다. 최소 학습률은 <math alttext="1e^{-5}" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.3.m3.1"><semantics id="S3.SS2.SSS0.Px2.p1.3.m3.1a"><mrow id="S3.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.cmml"><mn id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.2" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.2.cmml">1</mn><mo id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.1" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.1.cmml">⁢</mo><msup id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.cmml"><mi id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.2" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.2.cmml">e</mi><mrow id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.3" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.3.cmml"><mo id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.3a" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.3.cmml">−</mo><mn id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.3.2" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.3.m3.1b"><apply id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1"><times id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.1"></times><cn id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.2.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.2">1</cn><apply id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.1.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.2.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.2">𝑒</ci><apply id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.3.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.3"><minus id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.3.1.cmml" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.3"></minus><cn id="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.3.2.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.3.m3.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.3.m3.1c">1e^{-5}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px2.p1.3.m3.1d">1 italic_e start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT</annotation></semantics></math>이다. 우리는 <math alttext="1.0" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.5.m5.1"><semantics id="S3.SS2.SSS0.Px2.p1.5.m5.1a"><mn id="S3.SS2.SSS0.Px2.p1.5.m5.1.1" xref="S3.SS2.SSS0.Px2.p1.5.m5.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.5.m5.1b"><cn id="S3.SS2.SSS0.Px2.p1.5.m5.1.1.cmml" type="float" xref="S3.SS2.SSS0.Px2.p1.5.m5.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.5.m5.1c">1.0</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px2.p1.5.m5.1d">1.0</annotation></semantics></math>의 기울기 클리핑 규범과 함께 <math alttext="0.01" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.4.m4.1"><semantics id="S3.SS2.SSS0.Px2.p1.4.m4.1a"><mn id="S3.SS2.SSS0.Px2.p1.4.m4.1.1" xref="S3.SS2.SSS0.Px2.p1.4.m4.1.1.cmml">0.01</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.4.m4.1b"><cn id="S3.SS2.SSS0.Px2.p1.4.m4.1.1.cmml" type="float" xref="S3.SS2.SSS0.Px2.p1.4.m4.1.1">0.01</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.4.m4.1c">0.01</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px2.p1.4.m4.1d">0.01</annotation></semantics></math>의 가중치 감쇠를 사용한다. 전체 단계의 1%를 워밍업과 함께 코사인 학습률 스케줄러를 사용하고, <math alttext="\beta_{1}=0.9" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.6.m6.1"><semantics id="S3.SS2.SSS0.Px2.p1.6.m6.1a"><mrow id="S3.SS2.SSS0.Px2.p1.6.m6.1.1" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1.cmml"><msub id="S3.SS2.SSS0.Px2.p1.6.m6.1.1.2" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1.2.cmml"><mi id="S3.SS2.SSS0.Px2.p1.6.m6.1.1.2.2" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1.2.2.cmml">β</mi><mn id="S3.SS2.SSS0.Px2.p1.6.m6.1.1.2.3" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1.2.3.cmml">1</mn></msub><mo id="S3.SS2.SSS0.Px2.p1.6.m6.1.1.1" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1.1.cmml">=</mo><mn id="S3.SS2.SSS0.Px2.p1.6.m6.1.1.3" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1.3.cmml">0.9</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.6.m6.1b"><apply id="S3.SS2.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1"><eq id="S3.SS2.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1.1"></eq><apply id="S3.SS2.SSS0.Px2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.6.m6.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p1.6.m6.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1.2.2">𝛽</ci><cn id="S3.SS2.SSS0.Px2.p1.6.m6.1.1.2.3.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1.2.3">1</cn></apply><cn id="S3.SS2.SSS0.Px2.p1.6.m6.1.1.3.cmml" type="float" xref="S3.SS2.SSS0.Px2.p1.6.m6.1.1.3">0.9</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.6.m6.1c">\beta_{1}=0.9</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px2.p1.6.m6.1d">italic_β start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT = 0.9</annotation></semantics></math>와 <math alttext="\beta_{2}=0.999" class="ltx_Math" display="inline" id="S3.SS2.SSS0.Px2.p1.7.m7.1"><semantics id="S3.SS2.SSS0.Px2.p1.7.m7.1a"><mrow id="S3.SS2.SSS0.Px2.p1.7.m7.1.1" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1.cmml"><msub id="S3.SS2.SSS0.Px2.p1.7.m7.1.1.2" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1.2.cmml"><mi id="S3.SS2.SSS0.Px2.p1.7.m7.1.1.2.2" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1.2.2.cmml">β</mi><mn id="S3.SS2.SSS0.Px2.p1.7.m7.1.1.2.3" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1.2.3.cmml">2</mn></msub><mo id="S3.SS2.SSS0.Px2.p1.7.m7.1.1.1" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1.1.cmml">=</mo><mn id="S3.SS2.SSS0.Px2.p1.7.m7.1.1.3" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1.3.cmml">0.999</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS0.Px2.p1.7.m7.1b"><apply id="S3.SS2.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1"><eq id="S3.SS2.SSS0.Px2.p1.7.m7.1.1.1.cmml" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1.1"></eq><apply id="S3.SS2.SSS0.Px2.p1.7.m7.1.1.2.cmml" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS0.Px2.p1.7.m7.1.1.2.1.cmml" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS0.Px2.p1.7.m7.1.1.2.2.cmml" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1.2.2">𝛽</ci><cn id="S3.SS2.SSS0.Px2.p1.7.m7.1.1.2.3.cmml" type="integer" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1.2.3">2</cn></apply><cn id="S3.SS2.SSS0.Px2.p1.7.m7.1.1.3.cmml" type="float" xref="S3.SS2.SSS0.Px2.p1.7.m7.1.1.3">0.999</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS0.Px2.p1.7.m7.1c">\beta_{2}=0.999</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS0.Px2.p1.7.m7.1d">italic_β start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT = 0.999</annotation></semantics></math>를 갖는 Adam optimizer를 사용한다.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="415" id="S3.F2.g1" src="https://arxiv.org/html/2401.16380v1/x4.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text ltx_font_bold" id="S3.F2.2.1">WRAP&nbsp;(C4 + QA-85B) v/s C4</span>: Comparison of perplexity on the Pile for a 1.3B LLM trained for 300B tokens shows that WRAP outperforms models trained on 2x real data.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Perplexity Evaluation</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">다중 분포 외 데이터 세트의 검증 세트에 대해 사전 훈련된 모델의 복잡성을 평가한다. 모든 모델은 C4 데이터 세트 [ltx_cite class="ltx_cite ltx_citemacro_citep">(Raffel et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib57" title="">2020</a>)</cite>, 또는 동일한 특정 스타일 리프레이즈에 대해 학습됩니다. 모든 평가는 Pile<cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib24" title="">2020</a>)</cite>의 21개 하위 도메인에 대해 수행된다. 이러한 부분 집합은 파일 데이터 세트의 각 도메인에서 처음 10,000개의 문서에서 만들어집니다. 그런 다음 이러한 부분 집합에 대한 모델의 복잡성을 평가한다. 추가적인 평가 세부사항은 부록<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A4" title="Appendix D Evaluation Metrics ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">D</span></a>에서 제공된다. C4 대신 파일에서 복잡도를 평가하는 것이 중요하다. C4 검증 집합에서 텍스트(합성 및 실제 웹)의 여러 배포에 대한 훈련은 1 미만의 복잡도 미만의 작은 비용으로 발생한다. 평가 선택 및 이러한 복잡성 증가를 관찰하는 이유를 이해하기 위해 C4 코퍼스에 대한 훈련은 목표를 최소화하는 것에 해당한다는 점에 주목한다.</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\theta_{c4}=\min_{\theta}\mathbb{E}_{x\sim D_{c4}}\left[\mathcal{L}(\theta;x)%
\right]," class="ltx_Math" display="block" id="S4.E1.m1.3"><semantics id="S4.E1.m1.3a"><mrow id="S4.E1.m1.3.3.1" xref="S4.E1.m1.3.3.1.1.cmml"><mrow id="S4.E1.m1.3.3.1.1" xref="S4.E1.m1.3.3.1.1.cmml"><msub id="S4.E1.m1.3.3.1.1.3" xref="S4.E1.m1.3.3.1.1.3.cmml"><mi id="S4.E1.m1.3.3.1.1.3.2" xref="S4.E1.m1.3.3.1.1.3.2.cmml">θ</mi><mrow id="S4.E1.m1.3.3.1.1.3.3" xref="S4.E1.m1.3.3.1.1.3.3.cmml"><mi id="S4.E1.m1.3.3.1.1.3.3.2" xref="S4.E1.m1.3.3.1.1.3.3.2.cmml">c</mi><mo id="S4.E1.m1.3.3.1.1.3.3.1" xref="S4.E1.m1.3.3.1.1.3.3.1.cmml">⁢</mo><mn id="S4.E1.m1.3.3.1.1.3.3.3" xref="S4.E1.m1.3.3.1.1.3.3.3.cmml">4</mn></mrow></msub><mo id="S4.E1.m1.3.3.1.1.2" xref="S4.E1.m1.3.3.1.1.2.cmml">=</mo><mrow id="S4.E1.m1.3.3.1.1.1" xref="S4.E1.m1.3.3.1.1.1.cmml"><mrow id="S4.E1.m1.3.3.1.1.1.3" xref="S4.E1.m1.3.3.1.1.1.3.cmml"><munder id="S4.E1.m1.3.3.1.1.1.3.1" xref="S4.E1.m1.3.3.1.1.1.3.1.cmml"><mi id="S4.E1.m1.3.3.1.1.1.3.1.2" xref="S4.E1.m1.3.3.1.1.1.3.1.2.cmml">min</mi><mi id="S4.E1.m1.3.3.1.1.1.3.1.3" xref="S4.E1.m1.3.3.1.1.1.3.1.3.cmml">θ</mi></munder><mo id="S4.E1.m1.3.3.1.1.1.3a" lspace="0.167em" xref="S4.E1.m1.3.3.1.1.1.3.cmml">⁡</mo><msub id="S4.E1.m1.3.3.1.1.1.3.2" xref="S4.E1.m1.3.3.1.1.1.3.2.cmml"><mi id="S4.E1.m1.3.3.1.1.1.3.2.2" xref="S4.E1.m1.3.3.1.1.1.3.2.2.cmml">𝔼</mi><mrow id="S4.E1.m1.3.3.1.1.1.3.2.3" xref="S4.E1.m1.3.3.1.1.1.3.2.3.cmml"><mi id="S4.E1.m1.3.3.1.1.1.3.2.3.2" xref="S4.E1.m1.3.3.1.1.1.3.2.3.2.cmml">x</mi><mo id="S4.E1.m1.3.3.1.1.1.3.2.3.1" xref="S4.E1.m1.3.3.1.1.1.3.2.3.1.cmml">∼</mo><msub id="S4.E1.m1.3.3.1.1.1.3.2.3.3" xref="S4.E1.m1.3.3.1.1.1.3.2.3.3.cmml"><mi id="S4.E1.m1.3.3.1.1.1.3.2.3.3.2" xref="S4.E1.m1.3.3.1.1.1.3.2.3.3.2.cmml">D</mi><mrow id="S4.E1.m1.3.3.1.1.1.3.2.3.3.3" xref="S4.E1.m1.3.3.1.1.1.3.2.3.3.3.cmml"><mi id="S4.E1.m1.3.3.1.1.1.3.2.3.3.3.2" xref="S4.E1.m1.3.3.1.1.1.3.2.3.3.3.2.cmml">c</mi><mo id="S4.E1.m1.3.3.1.1.1.3.2.3.3.3.1" xref="S4.E1.m1.3.3.1.1.1.3.2.3.3.3.1.cmml">⁢</mo><mn id="S4.E1.m1.3.3.1.1.1.3.2.3.3.3.3" xref="S4.E1.m1.3.3.1.1.1.3.2.3.3.3.3.cmml">4</mn></mrow></msub></mrow></msub></mrow><mo id="S4.E1.m1.3.3.1.1.1.2" xref="S4.E1.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="S4.E1.m1.3.3.1.1.1.1.1" xref="S4.E1.m1.3.3.1.1.1.1.2.cmml"><mo id="S4.E1.m1.3.3.1.1.1.1.1.2" xref="S4.E1.m1.3.3.1.1.1.1.2.1.cmml">[</mo><mrow id="S4.E1.m1.3.3.1.1.1.1.1.1" xref="S4.E1.m1.3.3.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.3.3.1.1.1.1.1.1.2" xref="S4.E1.m1.3.3.1.1.1.1.1.1.2.cmml">ℒ</mi><mo id="S4.E1.m1.3.3.1.1.1.1.1.1.1" xref="S4.E1.m1.3.3.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S4.E1.m1.3.3.1.1.1.1.1.1.3.2" xref="S4.E1.m1.3.3.1.1.1.1.1.1.3.1.cmml"><mo id="S4.E1.m1.3.3.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S4.E1.m1.3.3.1.1.1.1.1.1.3.1.cmml">(</mo><mi id="S4.E1.m1.1.1" xref="S4.E1.m1.1.1.cmml">θ</mi><mo id="S4.E1.m1.3.3.1.1.1.1.1.1.3.2.2" xref="S4.E1.m1.3.3.1.1.1.1.1.1.3.1.cmml">;</mo><mi id="S4.E1.m1.2.2" xref="S4.E1.m1.2.2.cmml">x</mi><mo id="S4.E1.m1.3.3.1.1.1.1.1.1.3.2.3" stretchy="false" xref="S4.E1.m1.3.3.1.1.1.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.3.3.1.1.1.1.1.3" xref="S4.E1.m1.3.3.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo id="S4.E1.m1.3.3.1.2" xref="S4.E1.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.3b"><apply id="S4.E1.m1.3.3.1.1.cmml" xref="S4.E1.m1.3.3.1"><eq id="S4.E1.m1.3.3.1.1.2.cmml" xref="S4.E1.m1.3.3.1.1.2"></eq><apply id="S4.E1.m1.3.3.1.1.3.cmml" xref="S4.E1.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S4.E1.m1.3.3.1.1.3.1.cmml" xref="S4.E1.m1.3.3.1.1.3">subscript</csymbol><ci id="S4.E1.m1.3.3.1.1.3.2.cmml" xref="S4.E1.m1.3.3.1.1.3.2">𝜃</ci><apply id="S4.E1.m1.3.3.1.1.3.3.cmml" xref="S4.E1.m1.3.3.1.1.3.3"><times id="S4.E1.m1.3.3.1.1.3.3.1.cmml" xref="S4.E1.m1.3.3.1.1.3.3.1"></times><ci id="S4.E1.m1.3.3.1.1.3.3.2.cmml" xref="S4.E1.m1.3.3.1.1.3.3.2">𝑐</ci><cn id="S4.E1.m1.3.3.1.1.3.3.3.cmml" type="integer" xref="S4.E1.m1.3.3.1.1.3.3.3">4</cn></apply></apply><apply id="S4.E1.m1.3.3.1.1.1.cmml" xref="S4.E1.m1.3.3.1.1.1"><times id="S4.E1.m1.3.3.1.1.1.2.cmml" xref="S4.E1.m1.3.3.1.1.1.2"></times><apply id="S4.E1.m1.3.3.1.1.1.3.cmml" xref="S4.E1.m1.3.3.1.1.1.3"><apply id="S4.E1.m1.3.3.1.1.1.3.1.cmml" xref="S4.E1.m1.3.3.1.1.1.3.1"><csymbol cd="ambiguous" id="S4.E1.m1.3.3.1.1.1.3.1.1.cmml" xref="S4.E1.m1.3.3.1.1.1.3.1">subscript</csymbol><min id="S4.E1.m1.3.3.1.1.1.3.1.2.cmml" xref="S4.E1.m1.3.3.1.1.1.3.1.2"></min><ci id="S4.E1.m1.3.3.1.1.1.3.1.3.cmml" xref="S4.E1.m1.3.3.1.1.1.3.1.3">𝜃</ci></apply><apply id="S4.E1.m1.3.3.1.1.1.3.2.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E1.m1.3.3.1.1.1.3.2.1.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2">subscript</csymbol><ci id="S4.E1.m1.3.3.1.1.1.3.2.2.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2.2">𝔼</ci><apply id="S4.E1.m1.3.3.1.1.1.3.2.3.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2.3"><csymbol cd="latexml" id="S4.E1.m1.3.3.1.1.1.3.2.3.1.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2.3.1">similar-to</csymbol><ci id="S4.E1.m1.3.3.1.1.1.3.2.3.2.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2.3.2">𝑥</ci><apply id="S4.E1.m1.3.3.1.1.1.3.2.3.3.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2.3.3"><csymbol cd="ambiguous" id="S4.E1.m1.3.3.1.1.1.3.2.3.3.1.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2.3.3">subscript</csymbol><ci id="S4.E1.m1.3.3.1.1.1.3.2.3.3.2.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2.3.3.2">𝐷</ci><apply id="S4.E1.m1.3.3.1.1.1.3.2.3.3.3.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2.3.3.3"><times id="S4.E1.m1.3.3.1.1.1.3.2.3.3.3.1.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2.3.3.3.1"></times><ci id="S4.E1.m1.3.3.1.1.1.3.2.3.3.3.2.cmml" xref="S4.E1.m1.3.3.1.1.1.3.2.3.3.3.2">𝑐</ci><cn id="S4.E1.m1.3.3.1.1.1.3.2.3.3.3.3.cmml" type="integer" xref="S4.E1.m1.3.3.1.1.1.3.2.3.3.3.3">4</cn></apply></apply></apply></apply></apply><apply id="S4.E1.m1.3.3.1.1.1.1.2.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S4.E1.m1.3.3.1.1.1.1.2.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S4.E1.m1.3.3.1.1.1.1.1.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.1"><times id="S4.E1.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.1.1"></times><ci id="S4.E1.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.1.2">ℒ</ci><list id="S4.E1.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S4.E1.m1.3.3.1.1.1.1.1.1.3.2"><ci id="S4.E1.m1.1.1.cmml" xref="S4.E1.m1.1.1">𝜃</ci><ci id="S4.E1.m1.2.2.cmml" xref="S4.E1.m1.2.2">𝑥</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.3c">\theta_{c4}=\min_{\theta}\mathbb{E}_{x\sim D_{c4}}\left[\mathcal{L}(\theta;x)%
\right],</annotation><annotation encoding="application/x-llamapun" id="S4.E1.m1.3d">italic_θ start_POSTSUBSCRIPT italic_c 4 end_POSTSUBSCRIPT = roman_min start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT italic_x ∼ italic_D start_POSTSUBSCRIPT italic_c 4 end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ caligraphic_L ( italic_θ ; italic_x ) ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.p1.2">그것은 C4 웹 텍스트를 정확하게 모델링하려고 시도한다. 대조적으로, 다수의 스타일에 걸친 훈련은 상이한 분포에 걸친 위험을 최소화하는 것에 대응하고,</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.p2">
<table class="ltx_equation ltx_eqn_table" id="S4.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\theta_{\textbf{WRAP}}=\min_{\theta}\mathbb{E}_{x\sim D_{c4}\cup D_{syn}}\left%
[\mathcal{L}(\theta;x)\right]." class="ltx_Math" display="block" id="S4.E2.m1.3"><semantics id="S4.E2.m1.3a"><mrow id="S4.E2.m1.3.3.1" xref="S4.E2.m1.3.3.1.1.cmml"><mrow id="S4.E2.m1.3.3.1.1" xref="S4.E2.m1.3.3.1.1.cmml"><msub id="S4.E2.m1.3.3.1.1.3" xref="S4.E2.m1.3.3.1.1.3.cmml"><mi id="S4.E2.m1.3.3.1.1.3.2" xref="S4.E2.m1.3.3.1.1.3.2.cmml">θ</mi><mtext id="S4.E2.m1.3.3.1.1.3.3" xref="S4.E2.m1.3.3.1.1.3.3a.cmml">𝐖𝐑𝐀𝐏</mtext></msub><mo id="S4.E2.m1.3.3.1.1.2" xref="S4.E2.m1.3.3.1.1.2.cmml">=</mo><mrow id="S4.E2.m1.3.3.1.1.1" xref="S4.E2.m1.3.3.1.1.1.cmml"><mrow id="S4.E2.m1.3.3.1.1.1.3" xref="S4.E2.m1.3.3.1.1.1.3.cmml"><munder id="S4.E2.m1.3.3.1.1.1.3.1" xref="S4.E2.m1.3.3.1.1.1.3.1.cmml"><mi id="S4.E2.m1.3.3.1.1.1.3.1.2" xref="S4.E2.m1.3.3.1.1.1.3.1.2.cmml">min</mi><mi id="S4.E2.m1.3.3.1.1.1.3.1.3" xref="S4.E2.m1.3.3.1.1.1.3.1.3.cmml">θ</mi></munder><mo id="S4.E2.m1.3.3.1.1.1.3a" lspace="0.167em" xref="S4.E2.m1.3.3.1.1.1.3.cmml">⁡</mo><msub id="S4.E2.m1.3.3.1.1.1.3.2" xref="S4.E2.m1.3.3.1.1.1.3.2.cmml"><mi id="S4.E2.m1.3.3.1.1.1.3.2.2" xref="S4.E2.m1.3.3.1.1.1.3.2.2.cmml">𝔼</mi><mrow id="S4.E2.m1.3.3.1.1.1.3.2.3" xref="S4.E2.m1.3.3.1.1.1.3.2.3.cmml"><mi id="S4.E2.m1.3.3.1.1.1.3.2.3.2" xref="S4.E2.m1.3.3.1.1.1.3.2.3.2.cmml">x</mi><mo id="S4.E2.m1.3.3.1.1.1.3.2.3.1" xref="S4.E2.m1.3.3.1.1.1.3.2.3.1.cmml">∼</mo><mrow id="S4.E2.m1.3.3.1.1.1.3.2.3.3" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.cmml"><msub id="S4.E2.m1.3.3.1.1.1.3.2.3.3.2" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.cmml"><mi id="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.2" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.2.cmml">D</mi><mrow id="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3.cmml"><mi id="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3.2" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3.2.cmml">c</mi><mo id="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3.1" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3.1.cmml">⁢</mo><mn id="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3.3" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3.3.cmml">4</mn></mrow></msub><mo id="S4.E2.m1.3.3.1.1.1.3.2.3.3.1" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.1.cmml">∪</mo><msub id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.cmml"><mi id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.2" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.2.cmml">D</mi><mrow id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.cmml"><mi id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.2" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.2.cmml">s</mi><mo id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.1" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.1.cmml">⁢</mo><mi id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.3" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.3.cmml">y</mi><mo id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.1a" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.1.cmml">⁢</mo><mi id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.4" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.4.cmml">n</mi></mrow></msub></mrow></mrow></msub></mrow><mo id="S4.E2.m1.3.3.1.1.1.2" xref="S4.E2.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="S4.E2.m1.3.3.1.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.2.cmml"><mo id="S4.E2.m1.3.3.1.1.1.1.1.2" xref="S4.E2.m1.3.3.1.1.1.1.2.1.cmml">[</mo><mrow id="S4.E2.m1.3.3.1.1.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.3.3.1.1.1.1.1.1.2" xref="S4.E2.m1.3.3.1.1.1.1.1.1.2.cmml">ℒ</mi><mo id="S4.E2.m1.3.3.1.1.1.1.1.1.1" xref="S4.E2.m1.3.3.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="S4.E2.m1.3.3.1.1.1.1.1.1.3.2" xref="S4.E2.m1.3.3.1.1.1.1.1.1.3.1.cmml"><mo id="S4.E2.m1.3.3.1.1.1.1.1.1.3.2.1" stretchy="false" xref="S4.E2.m1.3.3.1.1.1.1.1.1.3.1.cmml">(</mo><mi id="S4.E2.m1.1.1" xref="S4.E2.m1.1.1.cmml">θ</mi><mo id="S4.E2.m1.3.3.1.1.1.1.1.1.3.2.2" xref="S4.E2.m1.3.3.1.1.1.1.1.1.3.1.cmml">;</mo><mi id="S4.E2.m1.2.2" xref="S4.E2.m1.2.2.cmml">x</mi><mo id="S4.E2.m1.3.3.1.1.1.1.1.1.3.2.3" stretchy="false" xref="S4.E2.m1.3.3.1.1.1.1.1.1.3.1.cmml">)</mo></mrow></mrow><mo id="S4.E2.m1.3.3.1.1.1.1.1.3" xref="S4.E2.m1.3.3.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo id="S4.E2.m1.3.3.1.2" lspace="0em" xref="S4.E2.m1.3.3.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.E2.m1.3b"><apply id="S4.E2.m1.3.3.1.1.cmml" xref="S4.E2.m1.3.3.1"><eq id="S4.E2.m1.3.3.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.2"></eq><apply id="S4.E2.m1.3.3.1.1.3.cmml" xref="S4.E2.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.3.1.cmml" xref="S4.E2.m1.3.3.1.1.3">subscript</csymbol><ci id="S4.E2.m1.3.3.1.1.3.2.cmml" xref="S4.E2.m1.3.3.1.1.3.2">𝜃</ci><ci id="S4.E2.m1.3.3.1.1.3.3a.cmml" xref="S4.E2.m1.3.3.1.1.3.3"><mtext id="S4.E2.m1.3.3.1.1.3.3.cmml" mathsize="70%" xref="S4.E2.m1.3.3.1.1.3.3">𝐖𝐑𝐀𝐏</mtext></ci></apply><apply id="S4.E2.m1.3.3.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1"><times id="S4.E2.m1.3.3.1.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.1.2"></times><apply id="S4.E2.m1.3.3.1.1.1.3.cmml" xref="S4.E2.m1.3.3.1.1.1.3"><apply id="S4.E2.m1.3.3.1.1.1.3.1.cmml" xref="S4.E2.m1.3.3.1.1.1.3.1"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.1.3.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1.3.1">subscript</csymbol><min id="S4.E2.m1.3.3.1.1.1.3.1.2.cmml" xref="S4.E2.m1.3.3.1.1.1.3.1.2"></min><ci id="S4.E2.m1.3.3.1.1.1.3.1.3.cmml" xref="S4.E2.m1.3.3.1.1.1.3.1.3">𝜃</ci></apply><apply id="S4.E2.m1.3.3.1.1.1.3.2.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.1.3.2.1.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2">subscript</csymbol><ci id="S4.E2.m1.3.3.1.1.1.3.2.2.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.2">𝔼</ci><apply id="S4.E2.m1.3.3.1.1.1.3.2.3.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3"><csymbol cd="latexml" id="S4.E2.m1.3.3.1.1.1.3.2.3.1.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.1">similar-to</csymbol><ci id="S4.E2.m1.3.3.1.1.1.3.2.3.2.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.2">𝑥</ci><apply id="S4.E2.m1.3.3.1.1.1.3.2.3.3.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3"><union id="S4.E2.m1.3.3.1.1.1.3.2.3.3.1.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.1"></union><apply id="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.2"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.1.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.2">subscript</csymbol><ci id="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.2.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.2">𝐷</ci><apply id="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3"><times id="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3.1.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3.1"></times><ci id="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3.2.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3.2">𝑐</ci><cn id="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3.3.cmml" type="integer" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.2.3.3">4</cn></apply></apply><apply id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3"><csymbol cd="ambiguous" id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.1.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3">subscript</csymbol><ci id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.2.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.2">𝐷</ci><apply id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3"><times id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.1.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.1"></times><ci id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.2.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.2">𝑠</ci><ci id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.3.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.3">𝑦</ci><ci id="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.4.cmml" xref="S4.E2.m1.3.3.1.1.1.3.2.3.3.3.3.4">𝑛</ci></apply></apply></apply></apply></apply></apply><apply id="S4.E2.m1.3.3.1.1.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1"><csymbol cd="latexml" id="S4.E2.m1.3.3.1.1.1.1.2.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S4.E2.m1.3.3.1.1.1.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1"><times id="S4.E2.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1.1"></times><ci id="S4.E2.m1.3.3.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1.2">ℒ</ci><list id="S4.E2.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="S4.E2.m1.3.3.1.1.1.1.1.1.3.2"><ci id="S4.E2.m1.1.1.cmml" xref="S4.E2.m1.1.1">𝜃</ci><ci id="S4.E2.m1.2.2.cmml" xref="S4.E2.m1.2.2">𝑥</ci></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.3c">\theta_{\textbf{WRAP}}=\min_{\theta}\mathbb{E}_{x\sim D_{c4}\cup D_{syn}}\left%
[\mathcal{L}(\theta;x)\right].</annotation><annotation encoding="application/x-llamapun" id="S4.E2.m1.3d">italic_θ start_POSTSUBSCRIPT WRAP end_POSTSUBSCRIPT = roman_min start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT blackboard_E start_POSTSUBSCRIPT italic_x ∼ italic_D start_POSTSUBSCRIPT italic_c 4 end_POSTSUBSCRIPT ∪ italic_D start_POSTSUBSCRIPT italic_s italic_y italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ caligraphic_L ( italic_θ ; italic_x ) ] .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p" id="S4.p3.2">방정식 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S4.E2" title="2 ‣ 4 Perplexity Evaluation ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">2</span></a>에 대한 해결은 C4-only에 대한 위험을 최소화하지 않으며, 따라서 비교하는 것은 부당하다.</p>
<math alttext="\theta_{c4}" class="ltx_Math" display="inline" id="S4.p3.1.m1.1"><semantics id="S4.p3.1.m1.1a"><msub id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml"><mi id="S4.p3.1.m1.1.1.2" xref="S4.p3.1.m1.1.1.2.cmml">θ</mi><mrow id="S4.p3.1.m1.1.1.3" xref="S4.p3.1.m1.1.1.3.cmml"><mi id="S4.p3.1.m1.1.1.3.2" xref="S4.p3.1.m1.1.1.3.2.cmml">c</mi><mo id="S4.p3.1.m1.1.1.3.1" xref="S4.p3.1.m1.1.1.3.1.cmml">⁢</mo><mn id="S4.p3.1.m1.1.1.3.3" xref="S4.p3.1.m1.1.1.3.3.cmml">4</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><apply id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p3.1.m1.1.1.1.cmml" xref="S4.p3.1.m1.1.1">subscript</csymbol><ci id="S4.p3.1.m1.1.1.2.cmml" xref="S4.p3.1.m1.1.1.2">𝜃</ci><apply id="S4.p3.1.m1.1.1.3.cmml" xref="S4.p3.1.m1.1.1.3"><times id="S4.p3.1.m1.1.1.3.1.cmml" xref="S4.p3.1.m1.1.1.3.1"></times><ci id="S4.p3.1.m1.1.1.3.2.cmml" xref="S4.p3.1.m1.1.1.3.2">𝑐</ci><cn id="S4.p3.1.m1.1.1.3.3.cmml" type="integer" xref="S4.p3.1.m1.1.1.3.3">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">\theta_{c4}</annotation><annotation encoding="application/x-llamapun" id="S4.p3.1.m1.1d">italic_θ start_POSTSUBSCRIPT italic_c 4 end_POSTSUBSCRIPT</annotation></semantics></math> and
<math alttext="\theta_{\textbf{WRAP}}" class="ltx_Math" display="inline" id="S4.p3.2.m2.1"><semantics id="S4.p3.2.m2.1a"><msub id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml"><mi id="S4.p3.2.m2.1.1.2" xref="S4.p3.2.m2.1.1.2.cmml">θ</mi><mtext id="S4.p3.2.m2.1.1.3" xref="S4.p3.2.m2.1.1.3a.cmml">𝐖𝐑𝐀𝐏</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.1b"><apply id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p3.2.m2.1.1.1.cmml" xref="S4.p3.2.m2.1.1">subscript</csymbol><ci id="S4.p3.2.m2.1.1.2.cmml" xref="S4.p3.2.m2.1.1.2">𝜃</ci><ci id="S4.p3.2.m2.1.1.3a.cmml" xref="S4.p3.2.m2.1.1.3"><mtext id="S4.p3.2.m2.1.1.3.cmml" mathsize="70%" xref="S4.p3.2.m2.1.1.3">𝐖𝐑𝐀𝐏</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.1c">\theta_{\textbf{WRAP}}</annotation><annotation encoding="application/x-llamapun" id="S4.p3.2.m2.1d">italic_θ start_POSTSUBSCRIPT WRAP end_POSTSUBSCRIPT</annotation></semantics></math> on the C4.
For meaningfully comparing models trained on the C4 and on its synthetic rephrases, we evaluate their generalization capability on 21 different domains of the Pile&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Gao et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib24" title="">2020</a>)</cite>.
Results for each domain are presented in Figure&nbsp;<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S3.F2" title="Figure 2 ‣ Pre-training ‣ 3.2 Implementation Details ‣ 3 WRAP: Web Rephrase Augmented Pretraining ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">2</span></a>.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Data Complexity</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">그림 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S1.F0.sf3" title="0(c) ‣ Figure 1 ‣ 1 Introduction ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">0(c)</span></a>에서 우리는 더 적은 토큰(150B)에 대해 훈련된 모델과 더 작은 350M 모델이 합성 재구문을 사용하여 더 빠른 학습을 나타내는 300B 토큰에 대해 전체 C4에 대한 훈련보다 우수하다는 것을 보여준다. ArXiv 및 HackerNews와 같은 일부 도메인에서 합성 데이터로 훈련하면 실제 데이터만으로 훈련된 모델의 복잡도를 거의 3배 줄일 수 있음을 관찰한다. 이는 더 많은 실제 데이터에 대한 학습만으로는 합성 데이터에 대한 사전 학습의 성능 우위를 상쇄할 수 없는 경우가 많을 수 있음을 시사한다. 전반적으로, 파일의 여러 부분 집합의 평균에 대해, 우리 모델은 실제 데이터만으로 훈련된 모델에 비해 복잡성을 50% 개선한다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Learning Speed</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.SS0.SSS0.Px2.p1.1.1">WRAP</span> 훈련의 첫 번째 체크포인트(10B 토큰)에서도 15개의 체크포인트에 대한 C4 사전 훈련에 의해 달성된 것보다 파일 상의 LLM의 평균 복잡도가 낮다는 것을 관찰한다. 이것은 15배 사전 훈련 속도 향상을 시사한다. 우리는 더 의미 있는 비교를 하기 위해 학습 속도에 대한 논의를 '제로샷' 과제로 미루었다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Zero-shot Tasks</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">우리는 이제 LLM Evaluation Harness<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We use git commit - <span class="ltx_text ltx_font_typewriter" id="footnote1.1">89618bf8</span> for consistency across all experiments with a batch size of 32.</span></span></span>><cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib25" title="">2023</a>)</cite>를 사용하여 다양한 제로 샷 질의 응답(QA) 벤치마크에 대한 사전 훈련된 언어 모델을 평가한다.</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Datasets</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">우리는 총 13개의 서로 다른 제로샷 벤치마크에 대해 모델을 평가하여 상식 추론, 언어 및 지식 이해 및 수학적 추론과 같은 다양한 자연 언어 작업에 대한 능력을 평가한다.</p>
</div>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">General Understanding</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px1.p1.1">일반 이해 범주는 광범위한 인지 기술과 언어 이해를 테스트하는 데이터 세트로 구성된다. <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.1.1">ARC Easy (ARC-E)</span> <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib15" title="">2018</a>)</cite>는 ARC-C의 덜 도전적인 대응물로, 기본적인 추론 기술을 필요로 하는 질문을 특징으로 한다. <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.1.2">BoolQ</span> <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib14" title="">2019</a>)</cite>는 읽기 이해 및 일반적인 언어 이해에 초점을 맞춘 boolean 질문을 포함한다. <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.1.3">Winogrande (Wino.)</span> <cite class="ltx_cite ltx_citemacro_citep">(ai2, <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib1" title="">2019</a>)</cite> challenges models with common sense reasoning in language, particularly in pronoun disambiguation. <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.1.4">PIQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Bisk et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib9" title="">2020</a>)</cite>는 실용적인 상식의 필수적인 부분인 물리적 프로세스의 이해를 평가한다. <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.1.5">HellaSwag</span> <cite class="ltx_cite ltx_citemacro_citep">(Zellers et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib72" title="">2019</a>)</cite> test the ability to complete scenarios coherently, demanding both language understanding and common sense. <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.1.6">TruthfulQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib42" title="">2021</a>)</cite>는 진실한, 정확한 답변을 생성하는 데 중점을 두고 있으므로 모델의 사실적 정확성을 테스트합니다. <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.1.7">OpenBookQA (OBQA)</span> <cite class="ltx_cite ltx_citemacro_citep">(Mihaylov et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib49" title="">2018</a>)</cite>는 광범위한 사실과 개념에 대한 이해를 평가한다. 마지막으로 <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px1.p1.1.8">LogiQA-2</span> <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib44" title="">2023b</a>)</cite>는 논리적 원리를 이해하고 적용할 모델의 용량을 평가한다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Specialized Knowledge</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS1.SSS0.Px2.p1.1">전문 지식 범주에는 특정 도메인에 대한 전문 지식을 요구하는 데이터 세트가 포함됩니다. <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px2.p1.1.1">ARC Challenge (ARC-C)</span>><cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib15" title="">2018</a>)</cite>는 3등급부터 9등급까지 도전적인 과학 시험 문제를 포함하고 있어 고급 지식을 요구한다. <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px2.p1.1.2">SciQ</span> <cite class="ltx_cite ltx_citemacro_citep">(Johannes Welbl, <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib35" title="">2017</a>)</cite>는 과학 영역에서 모델의 이해와 추론을 테스트하는 과학 시험 문제를 제공한다. <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px2.p1.1.3">PubMedQA</span> <cite class="ltx_cite ltx_citemacro_citep">(Jin et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib34" title="">2019</a>)</cite> focusing on biommedical literature, assessing comprehension in medical and health-related information.</p>
<span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px2.p1.1.4">MathQA</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Amini et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib4" title="">2019</a>)</cite> tests mathematical problem-solving, requiring both numerical comprehension and reasoning. Lastly, <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS0.Px2.p1.1.5">MMLU</span>&nbsp;<cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et&nbsp;al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib30" title="">2021</a>)</cite> spans multiple domains, from professional to academic, testing the model on specialized subjects.</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_table" id="S5.T1">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T1.3" style="width:307.0pt;height:129.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-38.4pt,16.2pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T1.3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T1.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S5.T1.3.1.1.1.1">Dataset (Real Tok.)</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T1.3.1.1.1.2">ARC-E</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T1.3.1.1.1.3">BoolQ</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T1.3.1.1.1.4">Wino.</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T1.3.1.1.1.5">PIQA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T1.3.1.1.1.6">HellaSwag</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T1.3.1.1.1.7">TruthfulQA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T1.3.1.1.1.8">OBQA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T1.3.1.1.1.9">LogiQA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T1.3.1.1.1.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T1.3.1.1.1.10.1" style="background-color:#E0FFFF;">Avg</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.3.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.3.1.2.2.1">Half C4 (85B)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.2.2.2">61.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.2.2.3">59.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.2.2.4">57.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.2.2.5">74.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.2.2.6">46.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.2.2.7">34.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.2.2.8">22.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.2.2.9">23.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.2.2.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T1.3.1.2.2.10.1" style="background-color:#E0FFFF;">47.4</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.3.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.3.1.3.3.1">Full C4 (170B)</th>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.3.3.2">61.6</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.3.3.3">54.2</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.3.3.4">59.0</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.3.3.5">74.9</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.3.3.6">46.8</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.3.3.7">33.5</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.3.3.8">25.0</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.3.3.9">23.4</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.3.3.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T1.3.1.3.3.10.1" style="background-color:#E0FFFF;">47.3</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.3.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.3.1.4.4.1">RW (160B)</th>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.4.2">61.6</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.4.3">60.7</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.4.4">57.5</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.4.5">74.3</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.4.6">45.2</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.4.7">36.8</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.4.8">21.8</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.4.9">23.2</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.4.4.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T1.3.1.4.4.10.1" style="background-color:#E0FFFF;">47.6</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.3.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.3.1.5.5.1">RW (320B)</th>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.5.2">60.7</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.5.3">61.1</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.5.4">57.1</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.5.5">74.4</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.5.6">45.6</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.5.7">36.0</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.5.8">22.6</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.5.9">22.5</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.5.5.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T1.3.1.5.5.10.1" style="background-color:#E0FFFF;">47.5</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.3.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.3.1.6.6.1">Pythia-Pile (300B)</th>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.6.2">60.5</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.6.3">63.3</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.6.4">57.5</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.6.5">70.8</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.6.6">40.4</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.6.7">38.9</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.6.8">22.2</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.6.9">22.2</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.6.6.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T1.3.1.6.6.10.1" style="background-color:#E0FFFF;">47.0</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.3.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T1.3.1.7.7.1">TinyLlama (1T)</th>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.7.2">60.3</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.7.3">57.8</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.7.4">59.1</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.7.5">73.3</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.7.6">45.0</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.7.7">37.6</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.7.8">21.8</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.7.9">24.5</td>
<td class="ltx_td ltx_align_center" id="S5.T1.3.1.7.7.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T1.3.1.7.7.10.1" style="background-color:#E0FFFF;">47.4</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.3.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T1.3.1.8.8.1">Synthetic (85B)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.8.8.2">63.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.8.8.3">60.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.8.8.4">58.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.8.8.5">76.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.8.8.6">45.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.8.8.7">44.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.8.8.8">23.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.8.8.9">24.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T1.3.1.8.8.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T1.3.1.8.8.10.1" style="background-color:#E0FFFF;">49.4</span></td>
</tr>
<tr class="ltx_tr" id="S5.T1.3.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T1.3.1.9.9.1">Synthetic+C4 (85B)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.9.9.2">64.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.9.9.3">62.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.9.9.4">58.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.9.9.5">75.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.9.9.6">46.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.9.9.7">40.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.9.9.8">24.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.9.9.9">23.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T1.3.1.9.9.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T1.3.1.9.9.10.1" style="background-color:#E0FFFF;">49.4</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Evaluation of <math alttext="\sim 1.3" class="ltx_Math" display="inline" id="S5.T1.2.m1.1"><semantics id="S5.T1.2.m1.1b"><mrow id="S5.T1.2.m1.1.1" xref="S5.T1.2.m1.1.1.cmml"><mi id="S5.T1.2.m1.1.1.2" xref="S5.T1.2.m1.1.1.2.cmml"></mi><mo id="S5.T1.2.m1.1.1.1" xref="S5.T1.2.m1.1.1.1.cmml">∼</mo><mn id="S5.T1.2.m1.1.1.3" xref="S5.T1.2.m1.1.1.3.cmml">1.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T1.2.m1.1c"><apply id="S5.T1.2.m1.1.1.cmml" xref="S5.T1.2.m1.1.1"><csymbol cd="latexml" id="S5.T1.2.m1.1.1.1.cmml" xref="S5.T1.2.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.T1.2.m1.1.1.2.cmml" xref="S5.T1.2.m1.1.1.2">absent</csymbol><cn id="S5.T1.2.m1.1.1.3.cmml" type="float" xref="S5.T1.2.m1.1.1.3">1.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.m1.1d">\sim 1.3</annotation><annotation encoding="application/x-llamapun" id="S5.T1.2.m1.1e">∼ 1.3</annotation></semantics></math>B parameter LLMs on ‘General Understanding Tasks’ on datasets focusing on general reasoning, language understanding, and common sense. Results for <span class="ltx_text ltx_font_bold" id="S5.T1.5.1">WRAP</span>are averaged over 3 runs</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S5.T2">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S5.T2.3" style="width:229.3pt;height:129.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.7pt,16.2pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.T2.3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.T2.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S5.T2.3.1.1.1.1">Dataset (Real Tok.)</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.3.1.1.1.2">ARC-C</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.3.1.1.1.3">SciQ</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.3.1.1.1.4">PubMedQA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.3.1.1.1.5">MathQA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.3.1.1.1.6">MMLU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S5.T2.3.1.1.1.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T2.3.1.1.1.7.1" style="background-color:#E0FFFF;">Avg</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.3.1.2.2.1">Half C4 (85B)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.3.1.2.2.2">26.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.3.1.2.2.3">84.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.3.1.2.2.4">57.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.3.1.2.2.5">23.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.3.1.2.2.6">24.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.3.1.2.2.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T2.3.1.2.2.7.1" style="background-color:#E0FFFF;">43.1</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.3.1.3.3.1">Full C4 (170B)</th>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.3.3.2">26.8</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.3.3.3">85.0</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.3.3.4">57.4</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.3.3.5">24.3</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.3.3.6">23.9</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.3.3.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T2.3.1.3.3.7.1" style="background-color:#E0FFFF;">43.5</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.3.1.4.4.1">RW (160B)</th>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.4.4.2">27.2</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.4.4.3">87.2</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.4.4.4">56.2</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.4.4.5">24.1</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.4.4.6">25.9</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.4.4.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T2.3.1.4.4.7.1" style="background-color:#E0FFFF;">44.1</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.3.1.5.5.1">RW (320B)</th>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.5.5.2">27.8</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.5.5.3">88.0</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.5.5.4">57.4</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.5.5.5">23.0</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.5.5.6">25.4</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.5.5.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T2.3.1.5.5.7.1" style="background-color:#E0FFFF;">44.3</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.3.1.6.6.1">Pythia-Pile (300B)</th>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.6.6.2">26.1</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.6.6.3">86.6</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.6.6.4">60.6</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.6.6.5">25.2</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.6.6.6">24.3</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.6.6.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T2.3.1.6.6.7.1" style="background-color:#E0FFFF;">44.6</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S5.T2.3.1.7.7.1">TinyLlama (1T)</th>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.7.7.2">27.8</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.7.7.3">88.9</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.7.7.4">61.4</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.7.7.5">24.1</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.7.7.6">25.8</td>
<td class="ltx_td ltx_align_center" id="S5.T2.3.1.7.7.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T2.3.1.7.7.7.1" style="background-color:#E0FFFF;">45.6</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S5.T2.3.1.8.8.1">Synthetic (85B)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.3.1.8.8.2">29.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.3.1.8.8.3">87.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.3.1.8.8.4">60.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.3.1.8.8.5">23.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.3.1.8.8.6">24.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S5.T2.3.1.8.8.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T2.3.1.8.8.7.1" style="background-color:#E0FFFF;">45.0</span></td>
</tr>
<tr class="ltx_tr" id="S5.T2.3.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S5.T2.3.1.9.9.1">Synthetic+C4 (85B)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.3.1.9.9.2">29.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.3.1.9.9.3">87.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.3.1.9.9.4">61.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.3.1.9.9.5">23.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.3.1.9.9.6">24.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S5.T2.3.1.9.9.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S5.T2.3.1.9.9.7.1" style="background-color:#E0FFFF;">45.5</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Evaluation of <math alttext="\sim 1.3" class="ltx_Math" display="inline" id="S5.T2.2.m1.1"><semantics id="S5.T2.2.m1.1b"><mrow id="S5.T2.2.m1.1.1" xref="S5.T2.2.m1.1.1.cmml"><mi id="S5.T2.2.m1.1.1.2" xref="S5.T2.2.m1.1.1.2.cmml"></mi><mo id="S5.T2.2.m1.1.1.1" xref="S5.T2.2.m1.1.1.1.cmml">∼</mo><mn id="S5.T2.2.m1.1.1.3" xref="S5.T2.2.m1.1.1.3.cmml">1.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.T2.2.m1.1c"><apply id="S5.T2.2.m1.1.1.cmml" xref="S5.T2.2.m1.1.1"><csymbol cd="latexml" id="S5.T2.2.m1.1.1.1.cmml" xref="S5.T2.2.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S5.T2.2.m1.1.1.2.cmml" xref="S5.T2.2.m1.1.1.2">absent</csymbol><cn id="S5.T2.2.m1.1.1.3.cmml" type="float" xref="S5.T2.2.m1.1.1.3">1.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T2.2.m1.1d">\sim 1.3</annotation><annotation encoding="application/x-llamapun" id="S5.T2.2.m1.1e">∼ 1.3</annotation></semantics></math>B parameter LLMs on ‘Specialized Knowledge Tasks’ that require specific domain knowledge such as science, medicine, mathematics, and logic. Results for <span class="ltx_text ltx_font_bold" id="S5.T2.5.1">WRAP</span>are averaged over 3 runs.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Results</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">실제 데이터와 합성 데이터의 혼합으로 학습된 모델과 실제 데이터의 다양한 분할로 학습된 모델의 성능을 비교한다. 모든 실험에서 합성 데이터의 분할을 재구성하고 생성하기 위해 C4<cite class="ltx_cite ltx_citemacro_citep">(Raffel et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib57" title="">2020</a>)</cite> 데이터 세트를 사용한다. 우리는 사전 훈련에 사용할 수 있는 웹 데이터의 토큰 수를 나타내기 위해 'Real Tok.'라는 약어를 사용한다. 합성+실재' 실험에서 우리는 같은 수의 합성 구문을 늘린다. 우리는 잠재적으로 동일한 문서를 여러 번 다시 말할 수 있기 때문에 비교의 척도로 '진짜 토큰'을 선택하는데, 이는 총 말뭉치 크기가 의미가 없음을 암시하고 말뭉치 '지식'이 실제 관심 통화임을 의미한다.</p>
</div>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Baselines Methods</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px1.p1.1">우리는 (i) C4의 절반의 LLM과 (ii) 전체 C4가 각각 약 85억 및 170억 개의 실제 토큰에 해당하는 [cite class="ltx_cite ltx_citemacro_citep">(Raffel et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib57" title="">2020</a>)</cite>를 사전 학습한다. 우리는 또한 RefinedWeb Dataset <cite class="ltx_cite ltx_citemacro_citep">(Penedo et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib54" title="">2023</a>)</cite>의 (iii) 160억 및 (iv) 320억 토큰에 대해 자체 모델을 사전 훈련합니다. 또한, Pile<cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib24" title="">2020</a>)</cite>에서 학습한 (iv) Pythia-1.4B 모델과도 비교한다. 이 데이터 세트는 더 이상 공개적으로 사용할 수 없으므로 사전 훈련된 모델을 활용한다. 마지막으로, 최근(v) TinyLlama 모델 <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib73" title="">2024</a>)</cite>가 SlimPajama <cite class="ltx_cite ltx_citemacro_citep">(Shen et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib59" title="">2023</a>)</cite> 및 StarCoder <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib39" title="">2023a</a>)</cite>로부터 1조 개의 데이터에 대해 3개의 epoch에 대해 학습한 것과도 비교한다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">General Improvements</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px2.p1.1">표 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S5.T1" title="Table 1 ‣ Specialized Knowledge ‣ 5.1 Datasets ‣ 5 Zero-shot Tasks ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">1</span></a>의 모든 작업에서 C4 데이터 세트(합성+C4)와 결합된 합성 데이터로 학습된 모델이 85B 토큰 분할이 있는 실제 C4 데이터 세트에서만 학습된 모델에 비해 평균 47.4%의 전체 평균 성능이 49.4% 더 높다는 것을 관찰했다. 이는 합성 데이터의 포함이 NLP 모델의 일반적인 이해 능력을 향상시킬 수 있음을 보여준다. 또한, 10x 컴퓨팅 및 데이터에 대해 훈련된 TinyLLama 모델조차도 실제 데이터에 대해 훈련된 다른 모델들과 비교해서 수행한다. 이는 필터링을 하거나 실제 데이터를 더 추가하는 데 따른 이득이 매우 낮음을 시사한다. 이와 반대로 <span class="ltx_text ltx_font_bold" id="S5.SS2.SSS0.Px2.p1.1.1">WRAP</span>은 적은 양의 합성 데이터에서도 사전 훈련이 큰 성능 향상에 기여할 수 있음을 보여준다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Specialized Knowledge Tasks</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px3.p1.1"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S5.T2" title="Table 2 ‣ Specialized Knowledge ‣ 5.1 Datasets ‣ 5 Zero-shot Tasks ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">2</span></a>의 결과에서 나오는 핵심 메시지는 합성 데이터가 '새로운 지식'을 부여할 수 없다는 것이다. 그것은 우리의 작업의 전제이기도 했던 사전 훈련을 더 빠르게 도울 수 있을 뿐이다. 특히, 우리는 몇 가지 주요 발견에 주목한다.</p>
<ol class="ltx_enumerate" id="S5.I1">
<li class="ltx_item" id="S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S5.I1.i1.p1">
<p class="ltx_p" id="S5.I1.i1.p1.1">더 큰 데이터 세트에 대한 사전 훈련은 아마도 LLM을 더 많은 "지식"에 노출시킴으로써 성능을 향상시키는 데 도움이 된다. 예를 들어, 피티아(300B) 모델은 평균 44.6%의 점수를 달성하여 더 작은 C4(85B) 데이터 세트의 점수 43.5%를 능가한다.</p>
</div>
</li>
<li class="ltx_item" id="S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para ltx_noindent" id="S5.I1.i2.p1">
<p class="ltx_p" id="S5.I1.i2.p1.1">더 큰 데이터 세트의 장점에도 불구하고 개선 사항은 포화되었습니다. 예를 들어, RefinedWeb(320B) 모델이 RefinedWeb(160B) 모델보다 0.2%만 우수하다. 마찬가지로, TinyLlama 모델(1T 토큰)은 원시 웹 데이터의 85B 토큰만 가지고 있는 <span class="ltx_text ltx_font_bold" id="S5.I1.i2.p1.1.1">WRAP</span>> 모델과 비교적으로 수행한다.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_paragraph" id="S5.SS2.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Specific Improvements</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S5.SS2.SSS0.Px4.p1">
<p class="ltx_p" id="S5.SS2.SSS0.Px4.p1.1">우리는 Synthetic (85B) 모델이 44.0%를 기록하여 TruthfulQA 데이터 세트에서 최대 개선을 볼 수 있으며, 이는 이 데이터 세트에서 다른 모델의 성능보다 훨씬 높다. 이것은 잠재적으로 명령 조정 LLM이 텍스트를 다시 바꾸는 동안 잠재적인 오개념을 이미 수정하기 때문이다. 흥미롭게도 합성 모델(합성+C4)에 실제 데이터를 추가하면 TruthfulQA의 성능이 4% 감소하여 40.5%로 감소하며, 이는 실제 데이터와 결합할 때 합성 데이터에서 얻은 이점이 잠재적으로 희석되었음을 나타낸다. C4 훈련된 모델이 잘 작동하는 헬라스웨그 및 BoolQ와 같은 다른 데이터 세트는 C4와 합성 구문의 조합을 통합하는 이점을 계속 보여준다.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Analysis and Ablations</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">또한 다음과 같은 연구 질문(RQ)을 통해 성능을 최적으로 향상시키는 방법을 보다 세밀하게 조사할 수 있습니다.</p>
</div>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Data Combination Analysis</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S6.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">RQ1: How important is it to have real C4 data?</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S6.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="415" id="S6.F3.g1" src="https://arxiv.org/html/2401.16380v1/x5.png" width="830">
<br class="ltx_break ltx_centering">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span><span class="ltx_text ltx_font_bold" id="S6.F3.2.1">Importance of Real Data:</span> Comparing perplexity on the Pile when pre-training on C4 with synthetic data vs. synthetic data only. Models are 1.3B parameters trained for a total of 150B tokens on a real data subset containing 35 Billion tokens of the C4.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S6.T3">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T3.3" style="width:305.4pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-38.2pt,9.0pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S6.T3.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T3.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S6.T3.3.1.1.1.1">Dataset (Real Tok.)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T3.3.1.1.1.2">ARC-E</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T3.3.1.1.1.3">BoolQ</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T3.3.1.1.1.4">Wino.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T3.3.1.1.1.5">PIQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T3.3.1.1.1.6">HellaSwag</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T3.3.1.1.1.7">TruthfulQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T3.3.1.1.1.8">OBQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T3.3.1.1.1.9">LogiQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T3.3.1.1.1.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T3.3.1.1.1.10.1" style="background-color:#E0FFFF;">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T3.3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T3.3.1.2.1.1">Med+C4-35B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.3.1.2.1.2">59.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.3.1.2.1.3">57.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.3.1.2.1.4">55.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.3.1.2.1.5">74.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.3.1.2.1.6">44.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.3.1.2.1.7">36.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.3.1.2.1.8">23.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.3.1.2.1.9">21.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T3.3.1.2.1.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T3.3.1.2.1.10.1" style="background-color:#E0FFFF;">46.7</span></td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T3.3.1.3.2.1">QA+C4-35B</th>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.3.2.2">62.2</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.3.2.3">63.3</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.3.2.4">55.7</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.3.2.5">74.8</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.3.2.6">44.6</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.3.2.7">41.4</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.3.2.8">22.4</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.3.2.9">23.2</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.3.2.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T3.3.1.3.2.10.1" style="background-color:#E0FFFF;">48.4</span></td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T3.3.1.4.3.1">Med-35B</th>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.4.3.2">56.6</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.4.3.3">59.5</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.4.3.4">53.4</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.4.3.5">74.0</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.4.3.6">41.9</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.4.3.7">36.3</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.4.3.8">22.2</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.4.3.9">22.7</td>
<td class="ltx_td ltx_align_center" id="S6.T3.3.1.4.3.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T3.3.1.4.3.10.1" style="background-color:#E0FFFF;">45.8</span></td>
</tr>
<tr class="ltx_tr" id="S6.T3.3.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T3.3.1.5.4.1">QA-35B</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T3.3.1.5.4.2">61.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T3.3.1.5.4.3">62.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T3.3.1.5.4.4">53.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T3.3.1.5.4.5">75.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T3.3.1.5.4.6">43.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T3.3.1.5.4.7">43.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T3.3.1.5.4.8">22.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T3.3.1.5.4.9">23.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T3.3.1.5.4.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T3.3.1.5.4.10.1" style="background-color:#E0FFFF;">48.2</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span><span class="ltx_text ltx_font_bold" id="S6.T3.5.1">Importance of Real Data:</span> Evaluation of <math alttext="\sim 1.3" class="ltx_Math" display="inline" id="S6.T3.2.m1.1"><semantics id="S6.T3.2.m1.1b"><mrow id="S6.T3.2.m1.1.1" xref="S6.T3.2.m1.1.1.cmml"><mi id="S6.T3.2.m1.1.1.2" xref="S6.T3.2.m1.1.1.2.cmml"></mi><mo id="S6.T3.2.m1.1.1.1" xref="S6.T3.2.m1.1.1.1.cmml">∼</mo><mn id="S6.T3.2.m1.1.1.3" xref="S6.T3.2.m1.1.1.3.cmml">1.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T3.2.m1.1c"><apply id="S6.T3.2.m1.1.1.cmml" xref="S6.T3.2.m1.1.1"><csymbol cd="latexml" id="S6.T3.2.m1.1.1.1.cmml" xref="S6.T3.2.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S6.T3.2.m1.1.1.2.cmml" xref="S6.T3.2.m1.1.1.2">absent</csymbol><cn id="S6.T3.2.m1.1.1.3.cmml" type="float" xref="S6.T3.2.m1.1.1.3">1.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T3.2.m1.1d">\sim 1.3</annotation><annotation encoding="application/x-llamapun" id="S6.T3.2.m1.1e">∼ 1.3</annotation></semantics></math>B parameter LLMs trained for 150B tokens on General Understanding Tasks. Results show that adding real data helps improve model performance when pre-training on ‘Medium’ or ‘Wikipedia-style’ paraphrases.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S6.T4">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T4.3" style="width:227.7pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.5pt,9.0pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S6.T4.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T4.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S6.T4.3.1.1.1.1">Dataset (Real Tok.)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T4.3.1.1.1.2">ARC-C</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T4.3.1.1.1.3">SciQ</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T4.3.1.1.1.4">PubMedQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T4.3.1.1.1.5">MathQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T4.3.1.1.1.6">MMLU</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T4.3.1.1.1.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T4.3.1.1.1.7.1" style="background-color:#E0FFFF;">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T4.3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T4.3.1.2.1.1">Med+C4-35B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.3.1.2.1.2">27.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.3.1.2.1.3">82.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.3.1.2.1.4">46.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.3.1.2.1.5">23.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.3.1.2.1.6">25.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T4.3.1.2.1.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T4.3.1.2.1.7.1" style="background-color:#E0FFFF;">40.8</span></td>
</tr>
<tr class="ltx_tr" id="S6.T4.3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T4.3.1.3.2.1">QA+C4-35B</th>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.3.2.2">29.0</td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.3.2.3">85.1</td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.3.2.4">62.2</td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.3.2.5">22.5</td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.3.2.6">26.1</td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.3.2.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T4.3.1.3.2.7.1" style="background-color:#E0FFFF;">45.0</span></td>
</tr>
<tr class="ltx_tr" id="S6.T4.3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T4.3.1.4.3.1">Med-35B</th>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.4.3.2">27.0</td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.4.3.3">80.0</td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.4.3.4">59.4</td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.4.3.5">22.5</td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.4.3.6">24.7</td>
<td class="ltx_td ltx_align_center" id="S6.T4.3.1.4.3.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T4.3.1.4.3.7.1" style="background-color:#E0FFFF;">42.7</span></td>
</tr>
<tr class="ltx_tr" id="S6.T4.3.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T4.3.1.5.4.1">QA-35B</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T4.3.1.5.4.2">27.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T4.3.1.5.4.3">85.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T4.3.1.5.4.4">59.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T4.3.1.5.4.5">22.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T4.3.1.5.4.6">25.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T4.3.1.5.4.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T4.3.1.5.4.7.1" style="background-color:#E0FFFF;">43.8</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span><span class="ltx_text ltx_font_bold" id="S6.T4.5.1">Importance of Real Data:</span> Evaluation of <math alttext="\sim 1.3" class="ltx_Math" display="inline" id="S6.T4.2.m1.1"><semantics id="S6.T4.2.m1.1b"><mrow id="S6.T4.2.m1.1.1" xref="S6.T4.2.m1.1.1.cmml"><mi id="S6.T4.2.m1.1.1.2" xref="S6.T4.2.m1.1.1.2.cmml"></mi><mo id="S6.T4.2.m1.1.1.1" xref="S6.T4.2.m1.1.1.1.cmml">∼</mo><mn id="S6.T4.2.m1.1.1.3" xref="S6.T4.2.m1.1.1.3.cmml">1.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T4.2.m1.1c"><apply id="S6.T4.2.m1.1.1.cmml" xref="S6.T4.2.m1.1.1"><csymbol cd="latexml" id="S6.T4.2.m1.1.1.1.cmml" xref="S6.T4.2.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S6.T4.2.m1.1.1.2.cmml" xref="S6.T4.2.m1.1.1.2">absent</csymbol><cn id="S6.T4.2.m1.1.1.3.cmml" type="float" xref="S6.T4.2.m1.1.1.3">1.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T4.2.m1.1d">\sim 1.3</annotation><annotation encoding="application/x-llamapun" id="S6.T4.2.m1.1e">∼ 1.3</annotation></semantics></math>B parameter LLMs on Specialized Knowledge Tasks.
Results show that adding real data helps improve model performance when pre-training on ‘Q/A-style’ paraphrases. </figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S6.T5">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T5.3" style="width:227.7pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.5pt,9.0pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S6.T5.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T5.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S6.T5.3.1.1.1.1">Dataset (Real Tok.)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T5.3.1.1.1.2">ARC-C</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T5.3.1.1.1.3">SciQ</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T5.3.1.1.1.4">PubMedQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T5.3.1.1.1.5">MathQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T5.3.1.1.1.6">MMLU</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T5.3.1.1.1.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T5.3.1.1.1.7.1" style="background-color:#E0FFFF;">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T5.3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T5.3.1.2.1.1">Med+C4-35B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.3.1.2.1.2">27.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.3.1.2.1.3">82.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.3.1.2.1.4">46.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.3.1.2.1.5">23.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.3.1.2.1.6">25.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T5.3.1.2.1.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T5.3.1.2.1.7.1" style="background-color:#E0FFFF;">40.8</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T5.3.1.3.2.1">QA+C4-35B</th>
<td class="ltx_td ltx_align_center" id="S6.T5.3.1.3.2.2">29.0</td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.1.3.2.3">85.1</td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.1.3.2.4">62.2</td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.1.3.2.5">22.5</td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.1.3.2.6">26.1</td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.1.3.2.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T5.3.1.3.2.7.1" style="background-color:#E0FFFF;">45.0</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T5.3.1.4.3.1">Combined-1:1-35B</th>
<td class="ltx_td ltx_align_center" id="S6.T5.3.1.4.3.2">28.2</td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.1.4.3.3">85.9</td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.1.4.3.4">61.2</td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.1.4.3.5">23.2</td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.1.4.3.6">23.9</td>
<td class="ltx_td ltx_align_center" id="S6.T5.3.1.4.3.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T5.3.1.4.3.7.1" style="background-color:#E0FFFF;">44.5</span></td>
</tr>
<tr class="ltx_tr" id="S6.T5.3.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T5.3.1.5.4.1">Combined-1:2-35B</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T5.3.1.5.4.2">29.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T5.3.1.5.4.3">85.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T5.3.1.5.4.4">57.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T5.3.1.5.4.5">23.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T5.3.1.5.4.6">23.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T5.3.1.5.4.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T5.3.1.5.4.7.1" style="background-color:#E0FFFF;">43.7</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span><span class="ltx_text ltx_font_bold" id="S6.T5.5.1">Combining multiple styles:</span> Evaluation of <math alttext="\sim 1.3" class="ltx_Math" display="inline" id="S6.T5.2.m1.1"><semantics id="S6.T5.2.m1.1b"><mrow id="S6.T5.2.m1.1.1" xref="S6.T5.2.m1.1.1.cmml"><mi id="S6.T5.2.m1.1.1.2" xref="S6.T5.2.m1.1.1.2.cmml"></mi><mo id="S6.T5.2.m1.1.1.1" xref="S6.T5.2.m1.1.1.1.cmml">∼</mo><mn id="S6.T5.2.m1.1.1.3" xref="S6.T5.2.m1.1.1.3.cmml">1.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T5.2.m1.1c"><apply id="S6.T5.2.m1.1.1.cmml" xref="S6.T5.2.m1.1.1"><csymbol cd="latexml" id="S6.T5.2.m1.1.1.1.cmml" xref="S6.T5.2.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S6.T5.2.m1.1.1.2.cmml" xref="S6.T5.2.m1.1.1.2">absent</csymbol><cn id="S6.T5.2.m1.1.1.3.cmml" type="float" xref="S6.T5.2.m1.1.1.3">1.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T5.2.m1.1d">\sim 1.3</annotation><annotation encoding="application/x-llamapun" id="S6.T5.2.m1.1e">∼ 1.3</annotation></semantics></math>B parameter LLMs trained for 150B tokens on ‘Specialized Knowledge Tasks’. Results suggest that combining rephrasing styles does not yield performance benefit on zero-shot tasks compared to just Q/A style.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="S6.T6">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S6.T6.3" style="width:305.4pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-38.2pt,9.0pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S6.T6.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S6.T6.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S6.T6.3.1.1.1.1">Dataset (Real Tok.)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T6.3.1.1.1.2">ARC-E</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T6.3.1.1.1.3">BoolQ</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T6.3.1.1.1.4">Wino.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T6.3.1.1.1.5">PIQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T6.3.1.1.1.6">HellaSwag</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T6.3.1.1.1.7">TruthfulQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T6.3.1.1.1.8">OBQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T6.3.1.1.1.9">LogiQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S6.T6.3.1.1.1.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T6.3.1.1.1.10.1" style="background-color:#E0FFFF;">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S6.T6.3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S6.T6.3.1.2.1.1">Med+C4-35B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.3.1.2.1.2">59.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.3.1.2.1.3">57.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.3.1.2.1.4">55.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.3.1.2.1.5">74.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.3.1.2.1.6">44.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.3.1.2.1.7">36.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.3.1.2.1.8">23.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.3.1.2.1.9">21.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S6.T6.3.1.2.1.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T6.3.1.2.1.10.1" style="background-color:#E0FFFF;">46.7</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T6.3.1.3.2.1">QA+C4-35B</th>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.3.2.2">62.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.3.2.3">63.3</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.3.2.4">55.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.3.2.5">74.8</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.3.2.6">44.6</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.3.2.7">41.4</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.3.2.8">22.4</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.3.2.9">23.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.3.2.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T6.3.1.3.2.10.1" style="background-color:#E0FFFF;">48.4</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S6.T6.3.1.4.3.1">Combined-1:1-35B</th>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.4.3.2">60.6</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.4.3.3">60.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.4.3.4">57.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.4.3.5">73.8</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.4.3.6">43.7</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.4.3.7">40.2</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.4.3.8">22.0</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.4.3.9">22.1</td>
<td class="ltx_td ltx_align_center" id="S6.T6.3.1.4.3.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T6.3.1.4.3.10.1" style="background-color:#E0FFFF;">47.5</span></td>
</tr>
<tr class="ltx_tr" id="S6.T6.3.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S6.T6.3.1.5.4.1">Combined-1:2-35B</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T6.3.1.5.4.2">61.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T6.3.1.5.4.3">62.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T6.3.1.5.4.4">57.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T6.3.1.5.4.5">74.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T6.3.1.5.4.6">44.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T6.3.1.5.4.7">39.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T6.3.1.5.4.8">23.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T6.3.1.5.4.9">21.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S6.T6.3.1.5.4.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="S6.T6.3.1.5.4.10.1" style="background-color:#E0FFFF;">48.0</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span><span class="ltx_text ltx_font_bold" id="S6.T6.5.1">Combining multiple styles:</span> Evaluation of <math alttext="\sim 1.3" class="ltx_Math" display="inline" id="S6.T6.2.m1.1"><semantics id="S6.T6.2.m1.1b"><mrow id="S6.T6.2.m1.1.1" xref="S6.T6.2.m1.1.1.cmml"><mi id="S6.T6.2.m1.1.1.2" xref="S6.T6.2.m1.1.1.2.cmml"></mi><mo id="S6.T6.2.m1.1.1.1" xref="S6.T6.2.m1.1.1.1.cmml">∼</mo><mn id="S6.T6.2.m1.1.1.3" xref="S6.T6.2.m1.1.1.3.cmml">1.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T6.2.m1.1c"><apply id="S6.T6.2.m1.1.1.cmml" xref="S6.T6.2.m1.1.1"><csymbol cd="latexml" id="S6.T6.2.m1.1.1.1.cmml" xref="S6.T6.2.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S6.T6.2.m1.1.1.2.cmml" xref="S6.T6.2.m1.1.1.2">absent</csymbol><cn id="S6.T6.2.m1.1.1.3.cmml" type="float" xref="S6.T6.2.m1.1.1.3">1.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T6.2.m1.1d">\sim 1.3</annotation><annotation encoding="application/x-llamapun" id="S6.T6.2.m1.1e">∼ 1.3</annotation></semantics></math>B parameter LLMs trained for 150B tokens on General Understanding Tasks.
Results suggest that combining rephrasing styles does not yield performance benefit on zero-shot tasks compared to just Q/A style.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S6.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="415" id="S6.F4.g1" src="https://arxiv.org/html/2401.16380v1/x6.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span><span class="ltx_text ltx_font_bold" id="S6.F4.2.1">Combining multiple styles:</span> Perplexity across all domains of the Pile comparing combining multiple styles of synthetic data. Models are 1.3B parameters trained for a total of 150B tokens. We see small perplexity improvements from combining multiple styles.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS1.SSS0.Px1.p1.1">표 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S5.T1" title="Table 1 ‣ Specialized Knowledge ‣ 5.1 Datasets ‣ 5 Zero-shot Tasks ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">1</span></a>–<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S5.T2" title="Table 2 ‣ Specialized Knowledge ‣ 5.1 Datasets ‣ 5 Zero-shot Tasks ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">2</span></a>의 결과는 QA 프롬프트를 사용한 합성 데이터가 QA 작업에 대한 강력한 성능에 충분함을 나타낸다. 그러나 파일 복잡도에 대해 평가할 때 그림 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.F3" title="Figure 3 ‣ RQ1: How important is it to have real C4 data? ‣ 6.1 Data Combination Analysis ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">3</span></a>에서 많은 하위 도메인에 걸쳐 복잡도의 상당한 저하를 관찰한다. 이는 합성 데이터가 특수 문자를 거의 포함하지 않고 고도로 구조화되어 있기 때문일 수 있다. 대조적으로 OWT와 해커뉴스와 같은 파일의 여러 하위 도메인은 그러한 특별한 토큰을 가지고 있다. 필페이퍼 및 구텐버그와 같은 도메인에서는 사전 훈련 데이터에서 실제 C4 텍스트를 삭제하는 것과 합성 문서만을 대상으로 하는 훈련은 성능을 크게 떨어뜨린다(당황스러움 증가). 이는 합성 데이터가 실제 데이터 스크래프에 널리 퍼져 있는 특정 '태그'와 '스타일'을 포함하지 않는다는 사실에 다시 한 번 기인하며, <span class="ltx_text ltx_font_bold" id="S6.SS1.SSS0.Px1.p1.1.1">WRAP</span>이 합성 데이터 단독에 대한 사전 훈련보다 더 나은 전략임을 강조했다. 제로샷 태스크에 대한 성능 측면에서, 실제 데이터의 존재가 표 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.T3" title="Table 3 ‣ RQ1: How important is it to have real C4 data? ‣ 6.1 Data Combination Analysis ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">3</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.T4" title="Table 4 ‣ RQ1: How important is it to have real C4 data? ‣ 6.1 Data Combination Analysis ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">4</span></a>에서 제로샷 성능을 개선하는 데 도움이 된다는 점에 다시 한 번 주목한다. 제로샷 태스크는 잘 작성된 Q/A 쌍을 포함하기 때문에 이 효과는 실제 데이터에 대한 복잡도에 대한 효과만큼 분명하지 않다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">RQ2: Does a combination of multiple synthetic datasets improve performance?</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS1.SSS0.Px2.p1.1">우리는 훈련을 위해 여러 합성 스타일을 C4와 결합하는 것의 영향을 측정한다. 우리는 두 가지 변형을 고려한다: 1:1 비율로 결합한다는 것은 두 합성 스타일(중간 및 QA)과 일치하도록 C4의 사본이 두 개 있다는 것을 의미하며, C4 데이터 세트의 한 인스턴스만 결합하는 1:2 비율이다. 제로샷 QA 작업의 경우 표 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.T5" title="Table 5 ‣ RQ1: How important is it to have real C4 data? ‣ 6.1 Data Combination Analysis ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">5</span></a>-<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.T6" title="Table 6 ‣ RQ1: How important is it to have real C4 data? ‣ 6.1 Data Combination Analysis ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">6</span></a>에서 우리의 발견은 QA와 C4 데이터만 결합하는 것보다 낮은 성능을 나타낸다. 파일에 대한 평가는 그림 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.F4" title="Figure 4 ‣ RQ1: How important is it to have real C4 data? ‣ 6.1 Data Combination Analysis ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">4</span></a>에 나와 있다. 우리는 'Q/A'와 '위키피디아' 패러프레이즈가 특정 도메인에 대한 성능을 향상시키는 데 도움이 된다는 것을 알아챘다. 예를 들어, 질의응답이 많은 ‘Stackexchange’는 합성 데이터가 Q/A 스타일로 존재함으로써 이점이 있다. 전반적으로, 우리는 여러 스타일을 결합하여 파일에서 평균 당혹도에 약간의 개선이 있음을 주목한다.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Method Ablations</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_paragraph" id="S6.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">RQ3: How important is to have a high-quality re-phraser?</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S6.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="415" id="S6.F5.g1" src="https://arxiv.org/html/2401.16380v1/x7.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span class="ltx_text ltx_font_bold" id="S6.F5.3.1">Importance of High Quality Paraphraser:</span> Perplexity across all the Pile domains for <span class="ltx_text ltx_font_bold" id="S6.F5.4.2">WRAP</span>&nbsp;on data generated by different LLMs.
Results show that even small models like Qwen-1.8B can generate paraphrases of high quality. Though, a low quality rephraser like our fine-tuned T5-base model leads to significantly worse language modeling.
</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S6.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="415" id="S6.F6.g1" src="https://arxiv.org/html/2401.16380v1/x8.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span class="ltx_text ltx_font_bold" id="S6.F6.3.1">Is re-phrasing same as any augmentation?</span> We compare perplexity on the Pile for different augmemntation strategies. 350M parameter models are trained for a total of 15B tokens. <span class="ltx_text ltx_font_bold" id="S6.F6.4.2">WRAP</span>&nbsp;(Medium + C4) performs significantly better than traditional augmentations.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S6.SS2.SSS0.Px1.p1.1">이를 해결하기 위해 네 가지 별개의 re-phrasing 모델(T5-base <cite class="ltx_cite ltx_citemacro_citep">(Raffel et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib57" title="">2020</a>)</cite>, Qwen-1.8B-chat <cite class="ltx_cite ltx_citemacro_citep">(Bai et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib6" title="">2023a</a>)</cite>, Mistral-7B-chat <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib33" title="">2023</a>)</cite>, Vicuna-13B-chat-v1.3 <cite class="ltx_cite ltx_citemacro_citep">(Chiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib12" title="">2023</a>)</cite>)의 데이터를 사용하여 30B 토큰에 대해 345M 모델을 학습합니다. 동일한 프롬프트를 사용하여 모든 모델에서 데이터를 생성합니다. T5-base 모델의 경우, Vicuna-13b-chat 모델의 재구어 쌍에서 1 에폭에 대한 모델을 미세 조정한다. Qwen-1.8B 및 Mistral-7B와 같은 더 작은 재구문 모델에 의해 생성된 데이터에 대한 사전 훈련은 Vicuna 13B보다 낮은 복잡도를 달성한다는 것을 발견한다(그림 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.F5" title="Figure 5 ‣ RQ3: How important is to have a high-quality re-phraser? ‣ 6.2 Method Ablations ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">5</span></a>). 동시에 미세 조정된 T5 기반 모델은 나머지 모델보다 훨씬 더 나쁜 성능을 보인다. 그럼에도 불구하고 모든 재구문 모델은 실제 C4 데이터에만 대한 복잡성을 줄입니다. <span class="ltx_text ltx_font_bold" id="S6.SS2.SSS0.Px1.p1.1.1">WRAP</span>의 적용 가능성을 더욱 확장하기 위해 고품질 합성 데이터를 생성할 수 있는 패러프레이즈 모델을 얼마나 작게 훈련할 수 있는지에 대한 한계를 테스트하는 것은 아직 미해결 문제로 남아 있다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">RQ4: Does synthetic data improve over augmentations?</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S6.SS2.SSS0.Px2.p1.1">합성 데이터에 대한 사전 훈련에 의해 관찰된 이득은 증강을 사용한 사전 훈련과 동일한가? 이를 테스트하기 위해 우리는 NL-Augmenter 라이브러리 [ltx_cite class="ltx_cite ltx_citemacro_citep">(Dhole et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib18" title="">2021</a>)</cite>를 사용하여 동의어 대체 및 무작위 삭제라는 두 가지 인기 있는 텍스트 증강 기준선을 고려한다. 이 일련의 실험을 수행하기 위해 15B 토큰에 대해 350M 매개변수 모델을 사전 훈련한다. 총 풀 크기는 약 1.5B 토큰에 불과하며, 이는 모델이 보강되지 않는 한 사전 훈련 단계 동안 약 10회 데이터를 반복해야 함을 의미한다. <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.F6" title="Figure 6 ‣ RQ3: How important is to have a high-quality re-phraser? ‣ 6.2 Method Ablations ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">6</span></a>의 복잡도 분석에서 볼 수 있듯이 증강 데이터로 훈련된 모델은 실제 데이터와 합성 데이터의 조합으로 훈련된 모델보다 훨씬 더 나쁜 성능을 보인다. 이는 합성 데이터가 학습 과정을 향상시키며 단순히 증강의 다른 형태가 아님을 시사한다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS2.SSS0.Px3">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">RQ5: How does the style of synthetic data impact performance on specialized domains?</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="S6.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="415" id="S6.F7.g1" src="https://arxiv.org/html/2401.16380v1/x9.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span class="ltx_text ltx_font_bold" id="S6.F7.2.1">Impact of style of synthetic rephrases:</span> Perplexity across all domains of the Pile comparing different styles of synthetic data. We train 128M parameter models for 3B tokens.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S6.SS2.SSS0.Px3.p1.1">다양한 스타일의 합성 데이터에 대해 훈련된 다양한 모델의 성능을 비교한다. 특히, 합성 데이터의 4가지 스타일(쉬운, 중간, 하드, Q/A)을 생성하고, 파일 하위 집합에 대한 각 스타일의 조합에 대한 훈련의 성능을 평가한다. 이러한 합성 데이터 스타일을 생성하라는 프롬프트는 부록 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A7" title="Appendix G Rephrase Prompt Templates ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">G</span></a>에 설명되어 있다. Vicuna-v1.3 모델과 3B 토큰에 대해 훈련된 128M 모델의 세대에 해당하는 결과는 그림 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.F7" title="Figure 7 ‣ RQ5: How does the style of synthetic data impact performance on specialized domains? ‣ 6.2 Method Ablations ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">7</span></a>에 요약되어 있다. 평가 시 도메인의 스타일과 일치하는 실제 C4와 합성 데이터의 조합으로 훈련하면 성능이 향상됨을 알 수 있다. 그러나 단일 합성 데이터 스타일이 모든 도메인에서 가장 좋은 성능을 발휘하지 못하므로 실제 C4 데이터와 각 합성 스타일 변형의 조합을 사용한 훈련에서 유사한 성능을 보인다. LLM을 사전 훈련하기 위한 최상의 합성 스타일을 아는 것은 비현실적이지만 모든 도메인에 걸쳐 최상의 합성 스타일을 선택하는 오라클은 16%의 복잡성을 개선할 것이며, 이는 기본 지식이 동일하게 유지되는 경우에도 LLM 일반화를 위한 다양한 데이터 스타일로 훈련하는 것의 중요성을 나타낸다.</p>
</div>
</section>
<section class="ltx_paragraph" id="S6.SS2.SSS0.Px4">
<h5 class="ltx_title ltx_font_bold ltx_title_paragraph">RQ6: Is there data leakage from the rephrase model to the trained model?</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S6.SS2.SSS0.Px4.p1">
<p class="ltx_p" id="S6.SS2.SSS0.Px4.p1.1">우리는 합성 데이터가 원래의 C4 데이터와 양식적으로 다르고 서로 다른 PILE 도메인의 스타일과 일치하면서 유사한 의미 의미를 유지하는지 조사한다. 먼저 합성 데이터와 실제 데이터의 예제 쌍을 비교하여 성능 이득이 재구문 모델로부터의 지식 유출에 기인하지 않음을 확인한다. 우리는 각 데이터 세트에서 처음 1000개 샘플의 하위 집합을 취한다.</p>
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_para ltx_noindent" id="S6.SS2.SSS0.Px4.p2">
<p class="ltx_p" id="S6.SS2.SSS0.Px4.p2.1">SimCSE objective <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib26" title="">2021</a>)</cite> for medium and qa prompts for [a idx=1></a>(a) and (b)에서 문장 임베딩의 코사인 유사성을 보인다. 유사성을 계산할 때 이상치를 제거합니다. 분포가 있는 그림은 가우시안 커널 밀도 추정기(KDE)를 사용하여 1000개의 값으로부터 통계에 대한 분포를 구성한다. 실제 합성 쌍의 코사인 유사도는 C4의 두 개의 무작위 실제 샘플, 샘플의 전반부와 전체 샘플 사이의 코사인 계산 연속 기준선, 동일한 샘플의 전반부와 후반부 사이의 코사인 유사성을 포함하는 여러 기준선보다 높다. 유사도가 높다는 것은 재구문이 정보를 추가하지 않고 실제 상대방과 유사한 의미를 유지한다는 것을 나타낸다.</p>
</div>
<figure class="ltx_figure" id="S6.F8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_flex_size_2 ltx_align_center" id="S6.F7.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="553" id="S6.F7.sf1.g1" src="https://arxiv.org/html/2401.16380v1/x10.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Cosine similarity Medium synthetic data</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_flex_size_2 ltx_align_center" id="S6.F7.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="553" id="S6.F7.sf2.g1" src="https://arxiv.org/html/2401.16380v1/x11.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Cosine similarity QA synthetic data</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Comparison between synthetic and real data from the C4 corpus showing that synthetic data maintains semantic meaning compared with the real C4 data and primarily changes style for (a) medium rephrases of C4, and (b) QA rephrases of C4.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Limitations and Opportunities</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="S7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1 </span>Cost Analysis</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S7.SS1.p1">
<p class="ltx_p" id="S7.SS1.p1.1"><em class="ltx_emph ltx_font_italic" id="S7.SS1.p1.1.1">합성 데이터를 생성해야 하나요, 아니면 실제 데이터에서 더 오래 훈련해야 하나요? </em></p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p2">
<p class="ltx_p" id="S7.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S7.SS1.p2.1.1">WRAP</span>의 응용 프로그램은 두 패러다임 모두에서 적용 됩니다. (i) Finnish 언어에 대 한 언어 모델 [ltx_cite class="ltx_cite ltx_citemacro_citep">(Luukkonen et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib46" title="">2023</a>)</cite>, (ii) Common crawl에 대 한 훈련과 같은 데이터가 풍부한 설정입니다. 전자의 경우 더 많은 데이터를 순진하게 수집할 수 있는 대안이 없기 때문에 합성 데이터는 도메인 내 데이터만으로 학습을 능가해야 하는 자연스러운 솔루션이다. 그러나, 영어, 또는 보다 광범위하게 일반적인 웹 데이터에 대한 언어 모델을 훈련시키는 것에 상당한 관심이 있다. 이러한 패러다임에서도 합성 데이터를 사용하는 것이 실행 가능한 옵션인가?</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p3">
<p class="ltx_p" id="S7.SS1.p3.1">이전에는 합성 데이터에 대한 사전 훈련의 실현 가능성에 대해 살펴보았지만 표 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S5.T1" title="Table 1 ‣ Specialized Knowledge ‣ 5.1 Datasets ‣ 5 Zero-shot Tasks ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">1</span></a>의 결과를 인정해야 한다. 3조 토큰에 대해 훈련된 TinyLlama 모델도 실제 데이터와 합성 데이터에 대해 공동으로 훈련된 모델보다 성능이 낮다. 실제로 실제 데이터에서도 300B 토큰에 대해 훈련된 모델과 상당히 유사한 성능을 보입니다. 이것은 더 긴 트레이닝에 의한 개선을 위한 천장이 그렇게 높지 않을 수 있음을 시사한다(크기 350M/1.3B 파라미터들의 모델의 경우; 더 큰 모델들은 더 긴 트레이닝으로부터 이익을 얻을 수 있다).</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p4">
<p class="ltx_p" id="S7.SS1.p4.1">이 비용 절충을 분석하기 위해 합성 데이터 생성 비용과 추가 데이터에 대한 언어 모델을 훈련하는 비용을 비교한다. 합성 데이터 생성 실험을 위해 빠른 생성을 위해 vLLM <cite class="ltx_cite ltx_citemacro_citep">(Kwon et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib38" title="">2023</a>)</cite> 라이브러리를 사용한다. 특히, 우리는 미스트랄-7B를 사용할 때 단일 A100에서 시간당 3M 토큰을 생성할 수 있다. (우리 작업에서와 같이) 85B 토큰을 생성하는 것은 약 25K GPU 시간에 대해 계정을 생성합니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p5">
<p class="ltx_p" id="S7.SS1.p5.1">이에 비해 64개의 A100s에서 초당 0.5M 토큰의 처리량을 달성한다. 300B 토큰에 대한 훈련을 가정하면 256 GPU일을 의미하며, 단일 모델을 훈련하기 위해 약 6k GPU 시간을 차지한다. 반대로, 13B 모델을 훈련시키는 것은 약 30K GPU 시간이 걸릴 것이다. 13B 모델을 훈련하는 규모에서 훈련 비용을 3-10배 줄이는 것은 훈련의 비용 오버헤드를 단일 실행에서 합성 데이터와 통합할 수 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p6">
<p class="ltx_p" id="S7.SS1.p6.1">고품질 데이터 생성 비용은 여전히 상대적으로 높지만 개선의 두 가지 중요한 출처는 이러한 비용 분석에 영향을 미친다. 먼저 Qwen-1.8B 모델 <cite class="ltx_cite ltx_citemacro_cite">Bai et al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib7" title="">2023b</a>)</cite> for rephrasing, we can get a 3x higher token throughput. 그림 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6.F5" title="Figure 5 ‣ RQ3: How important is to have a high-quality re-phraser? ‣ 6.2 Method Ablations ‣ 6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">5</span></a>의 예비 결과에서 볼 수 있듯이 Qwen 모델에 의해 생성된 재구문에 대해 사전 훈련된 모델은 미스트랄 모델에 의한 것과 유사한 성능을 보인다. 이에 따라, 발전 비용이 3배 절감된다. 추측적 디코딩에 대한 보다 최근의 연구는 <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib45" title="">2023c</a>)</cite> 및 최적화된 추론에 관한 것이다. <cite class="ltx_cite ltx_citemacro_citep">(Xia et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib68" title="">2024</a>)</cite>는 생성 비용에서 또 다른 3-5배 개선을 활용할 수 있음을 시사한다. 따라서 실제로 1.3B 매개변수 모델 훈련 규모에서도 실제 데이터만 사용하여 사전 훈련 비용을 개선할 수 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S7.SS1.p7">
<p class="ltx_p" id="S7.SS1.p7.1">위의 논의에서 설명할 수 없었던 합성 데이터 생성의 두 가지 추가적인 중요한 이점:</p>
<ol class="ltx_enumerate" id="S7.I1">
<li class="ltx_item" id="S7.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S7.I1.i1.p1">
<p class="ltx_p" id="S7.I1.i1.p1.1">합성 데이터 생성 비용은 일회성 투자이며 데이터가 생성되면 다양한 규모의 많은 모델을 훈련할 수 있다.</p>
</div>
</li>
<li class="ltx_item" id="S7.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para ltx_noindent" id="S7.I1.i2.p1">
<p class="ltx_p" id="S7.I1.i2.p1.1">데이터 생성은 100% 병렬화할 수 있는 반면, 훈련은 노드 간 연결이 빠른 대규모 클러스터의 가용성을 필요로 합니다. 이것은 훨씬 더 비싸다. 반면에 생성은 대규모 컴퓨팅 클러스터에서 빈 GPU를 채우고 단일 GPU 머신에서 실행할 수 있는 측면 프로세스로 생각할 수 있습니다.</p>
</div>
</li>
</ol>
</div>
</section>
<section class="ltx_subsection" id="S7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2 </span>Diversity of Synthetic Generations</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S7.SS2.p1">
<p class="ltx_p" id="S7.SS2.p1.1">또 다른 한계는 생성된 데이터의 다양성을 강화하는 것이다. 이러한 다양성은 생성된 데이터에 포함된 "스타일"과 "지식" 모두에서 비롯된다. 최근 작품 <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib40" title="">2023b</a>; <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib41" title="">c</a>)</cite>는 주제를 선택하거나 모델을 시드하여 새로운 텍스트를 생성하는 시나리오를 사용했다. 여전히, <cite class="ltx_cite ltx_citemacro_citet">Padmakumar et al.의 최근 연구. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib53" title="">2023</a>)</cite>는 AI 지원 글쓰기에 언어 모델을 사용하는 것이 특히 명령어 조정 모델을 사용할 때 콘텐츠 다양성을 줄이는 경향이 있음을 보여주었다. 우리는 새로운 콘텐츠 생성의 다양성과 관련된 문제를 완화하기 위해 특별히 재구성의 패러다임을 사용했지만, 패러프레이즈 모델에서 콘텐츠 다양성의 존재(또는 부족) 및 영향을 평가하는 것은 향후 작업으로 남아 있다.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S8">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Conclusion</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="S8.p1">
<p class="ltx_p" id="S8.p1.1">강력한 언어 모델은 실제 데이터와 합성 데이터의 조합에 대해 사전 훈련되고 있다. 합성 데이터를 사용하면 공정성, 편향성 및 스타일(명령어 후속과 같은)과 같은 바람직한 속성에서 데이터를 직접 베이킹할 수 있으므로 훈련 알고리즘을 구체적으로 조정할 필요가 없다. 이것은 언어 모델을 인간의 가치에 맞추는 대안적인 접근법을 제공한다. 최근 합성 데이터, 특히 명령어 조정 언어 모델에 대한 관심의 증가는 주목할 만하며 동시 연구자도 사전 훈련을 위해 이를 활용한다. 이 패러다임으로 전환함에 따라 모델에 공급되는 데이터의 속성을 이해하는 것이 가장 중요합니다. 본 논문은 LLM 사전 훈련에서 다양한 합성 스타일 데이터를 사용하는 것에 대한 포괄적인 가이드가 되는 것을 목표로 한다. 우리는 두 가지 관점에서 그 중요성을 탐구한다: (1) 고품질 데이터가 부족한 시나리오에서 합성 재구문은 기존 데이터의 단순한 반복보다 더 많은 가치를 제공한다; (2) 합성 데이터는 다른 텍스트 도메인에 대한 일반화와 사전 훈련 데이터 세트에서 과소 대표되는 스타일로 텍스트를 생성하는 데 도움이 될 수 있다. 실무자들이 훈련 모델을 위한 합성 데이터를 생성함에 따라, 그들은 중요하고 값비싼 디자인 선택에 직면하게 될 것이다 - (i) 합성 데이터 생성기의 품질은 얼마나 중요한가? (ii) 실제 데이터와 합성 데이터의 균형을 어떻게 맞출 것인가? (iii) 합성 데이터에 대한 훈련은 언제 에포크 측면에서 수익 체감의 지점에 도달합니까? 이 작업은 이러한 질문에 답하기 위한 첫 번째 단계를 밟습니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="S8.p2">
<p class="ltx_p" id="S8.p2.1">반대로, 합성 데이터로 내재된 한계와 기회를 주목하는 것은 필수적이다. 우리는 (1) 생성 비용이 여전히 크고 강력한 LMs를 필요로 하며 (2) 생성된 데이터의 다양성을 강화하는 것이 어렵다는 두 가지 한계를 강조한다. 이 작업에서 우리는 웹의 자연스러운 다양성을 활용하여 합성 "재구"를 생성한다. 이는 모델이 새로운 "지식"을 학습하는 것을 제한하고 고품질 입력의 제공을 통해서만 학습 프로세스를 향상시킨다. 과거 작업은 모델의 사각지대에 대한 보다 복잡한 이해가 필요한 반면, 사전 훈련 데이터 분포에 포함된 지식을 잠재적으로 편향시킬 수 있다. 그럼에도 불구하고, 우리는 계산 및 데이터 크기 모두에서 LLM 훈련 효율성을 개선하기 위한 합성 데이터의 잠재력을 보여준다.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">ai2 (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Winogrande: An adversarial winograd schema challenge at scale.

</span>
<span class="ltx_bibblock">2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abbas et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Amro Abbas, Kushal Tirumala, Daniel Simig, Surya Ganguli, and Ari&nbsp;S. Morcos.

</span>
<span class="ltx_bibblock">Semdedup: Data-efficient learning at web-scale through semantic deduplication.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">ArXiv</em>, abs/2303.09540, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:257557221" title="">https://api.semanticscholar.org/CorpusID:257557221</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alemohammad et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sina Alemohammad, Josue Casco-Rodriguez, Lorenzo Luzi, Ahmed&nbsp;Imtiaz Humayun, Hossein Babaei, Daniel LeJeune, Ali Siahkoohi, and Richard&nbsp;G Baraniuk.

</span>
<span class="ltx_bibblock">Self-consuming generative models go mad.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2307.01850</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amini et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh Hajishirzi.

</span>
<span class="ltx_bibblock">MathQA: Towards interpretable math word problem solving with operation-based formalisms.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pp.&nbsp; 2357–2367, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <a class="ltx_ref ltx_Url" href="10.18653/v1/N19-1245" title="">10.18653/v1/N19-1245</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/N19-1245" title="">https://aclanthology.org/N19-1245</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Azizi et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Shekoofeh Azizi, Simon Kornblith, Chitwan Saharia, Mohammad Norouzi, and David&nbsp;J Fleet.

</span>
<span class="ltx_bibblock">Synthetic data from diffusion models improves imagenet classification.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2304.08466</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu&nbsp;Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An&nbsp;Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, Xiaohuan Zhou, and Tianhang Zhu.

</span>
<span class="ltx_bibblock">Qwen technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2309.16609</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bai et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu&nbsp;Han, Fei Huang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Qwen technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2309.16609</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bansal &amp; Grover (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hritik Bansal and Aditya Grover.

</span>
<span class="ltx_bibblock">Leaving reality to imagination: Robust classification via generated datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2302.02503</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bisk et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yonatan Bisk, Rowan Zellers, Ronan&nbsp;Le Bras, Jianfeng Gao, and Yejin Choi.

</span>
<span class="ltx_bibblock">Piqa: Reasoning about physical commonsense in natural language.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Thirty-Fourth AAAI Conference on Artificial Intelligence</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared&nbsp;D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In H.&nbsp;Larochelle, M.&nbsp;Ranzato, R.&nbsp;Hadsell, M.F. Balcan, and H.&nbsp;Lin (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Advances in Neural Information Processing Systems</em>, volume&nbsp;33, pp.&nbsp; 1877–1901. Curran Associates, Inc., 2020.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, Kalpa Gunaratna, Vikas Yadav, Zheng Tang, Vijay Srinivasan, Tianyi Zhou, Heng Huang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Alpagasus: Training a better alpaca with fewer data.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2307.08701</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Wei-Lin Chiang, Zhuohan Li, Zi&nbsp;Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph&nbsp;E. Gonzalez, Ion Stoica, and Eric&nbsp;P. Xing.

</span>
<span class="ltx_bibblock">Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality, March 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://lmsys.org/blog/2023-03-30-vicuna/" title="">https://lmsys.org/blog/2023-03-30-vicuna/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choi et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dami Choi, Alexandre Passos, Christopher&nbsp;J Shallue, and George&nbsp;E Dahl.

</span>
<span class="ltx_bibblock">Faster neural network training with data echoing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:1907.05550</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">BoolQ: Exploring the surprising difficulty of natural yes/no questions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pp.&nbsp; 2924–2936, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <a class="ltx_ref ltx_Url" href="10.18653/v1/N19-1300" title="">10.18653/v1/N19-1300</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/N19-1300" title="">https://aclanthology.org/N19-1300</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord.

</span>
<span class="ltx_bibblock">Think you have solved question answering? try arc, the ai2 reasoning challenge.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv:1803.05457v1</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Computer (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Together Computer.

</span>
<span class="ltx_bibblock">Redpajama: an open dataset for training large language models.

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/togethercomputer/RedPajama-Data" title="">https://github.com/togethercomputer/RedPajama-Data</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cubuk et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ekin&nbsp;D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc&nbsp;V Le.

</span>
<span class="ltx_bibblock">Randaugment: Practical automated data augmentation with a reduced search space.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops</em>, pp.&nbsp; 702–703, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhole et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Kaustubh&nbsp;D. Dhole, Varun Gangal, Sebastian Gehrmann, Aadesh Gupta, Zhenhao Li, Saad Mahamood, Abinaya Mahendiran, Simon Mille, Ashish Srivastava, Samson Tan, Tongshuang Wu, Jascha Sohl-Dickstein, Jinho&nbsp;D. Choi, Eduard Hovy, Ondrej Dusek, Sebastian Ruder, Sajant Anand, Nagender Aneja, Rabin Banjade, Lisa Barthe, Hanna Behnke, Ian Berlot-Attwell, Connor Boyle, Caroline Brun, Marco Antonio&nbsp;Sobrevilla Cabezudo, Samuel Cahyawijaya, Emile Chapuis, Wanxiang Che, Mukund Choudhary, Christian Clauss, Pierre Colombo, Filip Cornell, Gautier Dagan, Mayukh Das, Tanay Dixit, Thomas Dopierre, Paul-Alexis Dray, Suchitra Dubey, Tatiana Ekeinhor, Marco&nbsp;Di Giovanni, Rishabh Gupta, Rishabh Gupta, Louanes Hamla, Sang Han, Fabrice Harel-Canada, Antoine Honore, Ishan Jindal, Przemyslaw&nbsp;K. Joniak, Denis Kleyko, Venelin Kovatchev, Kalpesh Krishna, Ashutosh Kumar, Stefan Langer, Seungjae&nbsp;Ryan Lee, Corey&nbsp;James Levinson, Hualou Liang, Kaizhao Liang, Zhexiong Liu, Andrey Lukyanenko, Vukosi Marivate, Gerard de&nbsp;Melo, Simon Meoni, Maxime
Meyer, Afnan Mir, Nafise&nbsp;Sadat Moosavi, Niklas Muennighoff, Timothy Sum&nbsp;Hon Mun, Kenton Murray, Marcin Namysl, Maria Obedkova, Priti Oli, Nivranshu Pasricha, Jan Pfister, Richard Plant, Vinay Prabhu, Vasile Pais, Libo Qin, Shahab Raji, Pawan&nbsp;Kumar Rajpoot, Vikas Raunak, Roy Rinberg, Nicolas Roberts, Juan&nbsp;Diego Rodriguez, Claude Roux, Vasconcellos P.&nbsp;H. S., Ananya&nbsp;B. Sai, Robin&nbsp;M. Schmidt, Thomas Scialom, Tshephisho Sefara, Saqib&nbsp;N. Shamsi, Xudong Shen, Haoyue Shi, Yiwen Shi, Anna Shvets, Nick Siegel, Damien Sileo, Jamie Simon, Chandan Singh, Roman Sitelew, Priyank Soni, Taylor Sorensen, William Soto, Aman Srivastava, KV&nbsp;Aditya Srivatsa, Tony Sun, Mukund&nbsp;Varma T, A&nbsp;Tabassum, Fiona&nbsp;Anting Tan, Ryan Teehan, Mo&nbsp;Tiwari, Marie Tolkiehn, Athena Wang, Zijian Wang, Gloria Wang, Zijie&nbsp;J. Wang, Fuxuan Wei, Bryan Wilie, Genta&nbsp;Indra Winata, Xinyi Wu, Witold Wydmański, Tianbao Xie, Usama Yaseen, M.&nbsp;Yee, Jing Zhang, and Yue Zhang.

</span>
<span class="ltx_bibblock">Nl-augmenter: A framework for task-sensitive natural language augmentation, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eisenstein (2013)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jacob Eisenstein.

</span>
<span class="ltx_bibblock">What to do about bad language on the internet.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, pp.&nbsp; 359–369, Atlanta, Georgia, June 2013. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/N13-1037" title="">https://aclanthology.org/N13-1037</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eldan &amp; Li (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ronen Eldan and Yuanzhi Li.

</span>
<span class="ltx_bibblock">Tinystories: How small can language models be and still speak coherent english?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">arXiv preprint arXiv:2305.07759</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fort et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Stanislav Fort, Andrew Brock, Razvan Pascanu, Soham De, and Samuel&nbsp;L Smith.

</span>
<span class="ltx_bibblock">Drawing multiple augmentation samples per image during training efficiently decreases test error.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2105.13343</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Futrell et&nbsp;al. (2015)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Richard Futrell, Kyle Mahowald, and Edward Gibson.

</span>
<span class="ltx_bibblock">Large-scale evidence of dependency length minimization in 37 languages.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the National Academy of Sciences</em>, 112(33):10336–10341, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gadre et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Samir&nbsp;Yitzhak Gadre, Gabriel Ilharco, Alex Fang, Jonathan Hayase, Georgios Smyrnis, Thao Nguyen, Ryan Marten, Mitchell Wortsman, Dhruba Ghosh, Jieyu Zhang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Datacomp: In search of the next generation of multimodal datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:2304.14108</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, Horace He, Anish Thite, Noa Nabeshima, et&nbsp;al.

</span>
<span class="ltx_bibblock">The pile: An 800gb dataset of diverse text for language modeling.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:2101.00027</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Leo Gao, Jonathan Tow, Baber Abbasi, Stella Biderman, Sid Black, Anthony DiPofi, Charles Foster, Laurence Golding, Jeffrey Hsu, Alain Le&nbsp;Noac’h, Haonan Li, Kyle McDonell, Niklas Muennighoff, Chris Ociepa, Jason Phang, Laria Reynolds, Hailey Schoelkopf, Aviya Skowron, Lintang Sutawika, Eric Tang, Anish Thite, Ben Wang, Kevin Wang, and Andy Zou.

</span>
<span class="ltx_bibblock">A framework for few-shot language model evaluation, 12 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://zenodo.org/records/10256836" title="">https://zenodo.org/records/10256836</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Tianyu Gao, Xingcheng Yao, and Danqi Chen.

</span>
<span class="ltx_bibblock">Simcse: Simple contrastive learning of sentence embeddings.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021</em>, pp.&nbsp; 6894–6910. Association for Computational Linguistics (ACL), 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gibson et&nbsp;al. (2000)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Edward Gibson et&nbsp;al.

</span>
<span class="ltx_bibblock">The dependency locality theory: A distance-based theory of linguistic complexity.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Image, language, brain</em>, 2000:95–126, 2000.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gunasekar et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Suriya Gunasekar, Yi&nbsp;Zhang, Jyoti Aneja, Caio César&nbsp;Teodoro Mendes, Allie Del&nbsp;Giorno, Sivakanth Gopi, Mojan Javaheripi, Piero Kauffmann, Gustavo de&nbsp;Rosa, Olli Saarikivi, et&nbsp;al.

</span>
<span class="ltx_bibblock">Textbooks are all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2306.11644</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gururangan et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Suchin Gururangan, Dallas Card, Sarah Dreier, Emily Gade, Leroy Wang, Zeyu Wang, Luke Zettlemoyer, and Noah&nbsp;A. Smith.

</span>
<span class="ltx_bibblock">Whose language counts as high quality? measuring language ideologies in text data selection.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing</em>, pp.&nbsp; 2562–2580, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <a class="ltx_ref ltx_Url" href="10.18653/v1/2022.emnlp-main.165" title="">10.18653/v1/2022.emnlp-main.165</a>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.emnlp-main.165" title="">https://aclanthology.org/2022.emnlp-main.165</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the International Conference on Learning Representations (ICLR)</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoffer et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Elad Hoffer, Tal Ben-Nun, Itay Hubara, Niv Giladi, Torsten Hoefler, and Daniel Soudry.

</span>
<span class="ltx_bibblock">Augment your batch: Improving generalization through instance repetition.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.&nbsp; 8129–8138, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hoffmann et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de&nbsp;Las Casas, Lisa&nbsp;Anne Hendricks, Johannes Welbl, Aidan Clark, et&nbsp;al.

</span>
<span class="ltx_bibblock">Training compute-optimal large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2203.15556</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Albert&nbsp;Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra&nbsp;Singh Chaplot, Diego de&nbsp;las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et&nbsp;al.

</span>
<span class="ltx_bibblock">Mistral 7b.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2310.06825</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William Cohen, and Xinghua Lu.

</span>
<span class="ltx_bibblock">Pubmedqa: A dataset for biomedical research question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</em>, pp.&nbsp; 2567–2577, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Johannes&nbsp;Welbl (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Matt&nbsp;Gardner Johannes&nbsp;Welbl, Nelson F.&nbsp;Liu.

</span>
<span class="ltx_bibblock">Crowdsourcing multiple choice science questions.

</span>
<span class="ltx_bibblock">2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jung et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jaehun Jung, Peter West, Liwei Jiang, Faeze Brahman, Ximing Lu, Jillian Fisher, Taylor Sorensen, and Yejin Choi.

</span>
<span class="ltx_bibblock">Impossible distillation: from low-quality model to high-quality dataset &amp; model for summarization and paraphrasing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">arXiv preprint arXiv:2305.16635</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Köksal et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Abdullatif Köksal, Timo Schick, Anna Korhonen, and Hinrich Schütze.

</span>
<span class="ltx_bibblock">Longform: Optimizing instruction tuning for long text generation with corpus extraction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">arXiv preprint arXiv:2304.08460</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwon et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody&nbsp;Hao Yu, Joseph&nbsp;E. Gonzalez, Hao Zhang, and Ion Stoica.

</span>
<span class="ltx_bibblock">Efficient memory management for large language model serving with pagedattention.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Raymond Li, Loubna&nbsp;Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry&nbsp;Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh&nbsp;Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva&nbsp;Sankalp Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn&nbsp;Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos&nbsp;Muñoz Ferrandis, Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von
Werra, and Harm de&nbsp;Vries.

</span>
<span class="ltx_bibblock">Starcoder: may the source be with you!

</span>
<span class="ltx_bibblock">2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke Zettlemoyer, Omer Levy, Jason Weston, and Mike Lewis.

</span>
<span class="ltx_bibblock">Self-alignment with instruction backtranslation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2308.06259</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. (2023c)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuanzhi Li, Sébastien Bubeck, Ronen Eldan, Allie Del&nbsp;Giorno, Suriya Gunasekar, and Yin&nbsp;Tat Lee.

</span>
<span class="ltx_bibblock">Textbooks are all you need ii: phi-1.5 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">arXiv preprint arXiv:2309.05463</em>, 2023c.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Stephanie Lin, Jacob Hilton, and Owain Evans.

</span>
<span class="ltx_bibblock">Truthfulqa: Measuring how models mimic human falsehoods, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2023a)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Bingbin Liu, Sebastien Bubeck, Ronen Eldan, Janardhan Kulkarni, Yuanzhi Li, Anh Nguyen, Rachel Ward, and Yi&nbsp;Zhang.

</span>
<span class="ltx_bibblock">Tinygsm: achieving¿ 80% on gsm8k with small language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">arXiv preprint arXiv:2312.09241</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2023b)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hanmeng Liu, Jian Liu, Leyang Cui, Zhiyang Teng, Nan Duan, Ming Zhou, and Yue Zhang.

</span>
<span class="ltx_bibblock">Logiqa 2.0 — an improved dataset for logical reasoning in natural language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, pp.&nbsp; 1–16, 2023b.

</span>
<span class="ltx_bibblock">doi: <a class="ltx_ref ltx_Url" href="10.1109/TASLP.2023.3293046" title="">10.1109/TASLP.2023.3293046</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. (2023c)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Xiaoxuan Liu, Lanxiang Hu, Peter Bailis, Ion Stoica, Zhijie Deng, Alvin Cheung, and Hao Zhang.

</span>
<span class="ltx_bibblock">Online speculative decoding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">arXiv preprint arXiv:2310.07177</em>, 2023c.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luukkonen et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Risto Luukkonen, Ville Komulainen, Jouni Luoma, Anni Eskelinen, Jenna Kanerva, Hanna-Mari Kupari, Filip Ginter, Veronika Laippala, Niklas Muennighoff, Aleksandra Piktus, et&nbsp;al.

</span>
<span class="ltx_bibblock">Fingpt: Large generative models for a small language.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">arXiv preprint arXiv:2311.05640</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maini (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pratyush Maini.

</span>
<span class="ltx_bibblock">Phi-1.5 model: A case of comparing apples to oranges?

</span>
<span class="ltx_bibblock">2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://pratyushmaini.github.io/phi-1_5/" title="">https://pratyushmaini.github.io/phi-1_5/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maini et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pratyush Maini, Sachin Goyal, Zachary&nbsp;C Lipton, J&nbsp;Zico Kolter, and Aditi Raghunathan.

</span>
<span class="ltx_bibblock">T-mars: Improving visual representations by circumventing text feature learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">arXiv preprint arXiv:2307.03132</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mihaylov et&nbsp;al. (2018)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish Sabharwal.

</span>
<span class="ltx_bibblock">Can a suit of armor conduct electricity? a new dataset for open book question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">EMNLP</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muennighoff et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Niklas Muennighoff, Alexander&nbsp;M Rush, Boaz Barak, Teven&nbsp;Le Scao, Aleksandra Piktus, Nouamane Tazi, Sampo Pyysalo, Thomas Wolf, and Colin Raffel.

</span>
<span class="ltx_bibblock">Scaling data-constrained language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">arXiv preprint arXiv:2305.16264</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu&nbsp;Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et&nbsp;al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">Advances in Neural Information Processing Systems</em>, 35:27730–27744, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oya (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Masanori Oya.

</span>
<span class="ltx_bibblock">Three types of average dependency distances of sentences in a multilingual parallel corpus.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Proceedings of the 35th Pacific Asia Conference on Language, Information and Computation</em>, pp.&nbsp; 652–661, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Padmakumar et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Vishakh Padmakumar, Behnam Hedayatnia, Di&nbsp;Jin, Patrick Lange, Seokhwan Kim, Nanyun Peng, Yang Liu, and Dilek Hakkani-Tur.

</span>
<span class="ltx_bibblock">Investigating the representation of open domain dialogue context for transformer models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">Proceedings of the 24th Meeting of the Special Interest Group on Discourse and Dialogue</em>, pp.&nbsp; 538–547, Prague, Czechia, September 2023. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.sigdial-1.50" title="">https://aclanthology.org/2023.sigdial-1.50</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Penedo et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay.

</span>
<span class="ltx_bibblock">The refinedweb dataset for falcon llm: outperforming curated corpora with web data, and web data only.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">arXiv preprint arXiv:2306.01116</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Alec Radford, Jong&nbsp;Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et&nbsp;al.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">International conference on machine learning</em>, pp.&nbsp; 8748–8763. PMLR, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rae et&nbsp;al. (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Jack&nbsp;W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, et&nbsp;al.

</span>
<span class="ltx_bibblock">Scaling language models: Methods, analysis &amp; insights from training gopher.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">arXiv preprint arXiv:2112.11446</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J Liu.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">The Journal of Machine Learning Research</em>, 21(1):5485–5551, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schuhmann et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, et&nbsp;al.

</span>
<span class="ltx_bibblock">Laion-5b: An open large-scale dataset for training next generation image-text models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">Advances in Neural Information Processing Systems</em>, 35:25278–25294, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Zhiqiang Shen, Tianhua Tao, Liqun Ma, Willie Neiswanger, Joel Hestness, Natalia Vassilieva, Daria Soboleva, and Eric Xing.

</span>
<span class="ltx_bibblock">Slimpajama-dc: Understanding data combinations for llm training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">arXiv preprint arXiv:2309.10818</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shumailov et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, Yarin Gal, Nicolas Papernot, and Ross Anderson.

</span>
<span class="ltx_bibblock">Model dementia: Generated data makes models forget.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">arXiv preprint arXiv:2305.17493</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Solaiman &amp; Dennison (2021)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Irene Solaiman and Christy Dennison.

</span>
<span class="ltx_bibblock">Process for adapting language models to society (palms) with values-targeted datasets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">Advances in Neural Information Processing Systems</em>, 34:5861–5873, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">arXiv preprint arXiv:2307.09288</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trabucco et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Brandon Trabucco, Kyle Doherty, Max Gurinas, and Ruslan Salakhutdinov.

</span>
<span class="ltx_bibblock">Effective data augmentation with diffusion models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">arXiv preprint arXiv:2302.07944</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et&nbsp;al. (2017)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan&nbsp;N Gomez, Łukasz Kaiser, and Illia Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">Advances in neural information processing systems</em>, 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Villalobos et&nbsp;al. (2022)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Pablo Villalobos, Jaime Sevilla, Lennart Heim, Tamay Besiroglu, Marius Hobbhahn, and Anson Ho.

</span>
<span class="ltx_bibblock">Will we run out of data? an analysis of the limits of scaling datasets in machine learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">arXiv preprint arXiv:2211.04325</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming Zhang.

</span>
<span class="ltx_bibblock">Magicoder: Source code is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">arXiv preprint arXiv:2312.02120</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wenzek et&nbsp;al. (2020)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary, Francisco Guzmán, Armand Joulin, and Edouard Grave.

</span>
<span class="ltx_bibblock">CCNet: Extracting high quality monolingual datasets from web crawl data.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">Proceedings of the Twelfth Language Resources and Evaluation Conference</em>, pp.&nbsp; 4003–4012, Marseille, France, May 2020. European Language Resources Association.

</span>
<span class="ltx_bibblock">ISBN 979-10-95546-34-4.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.lrec-1.494" title="">https://aclanthology.org/2020.lrec-1.494</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xia et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Heming Xia, Zhe Yang, Qingxiu Dong, Peiyi Wang, Yongqi Li, Tao Ge, Tianyu Liu, Wenjie Li, and Zhifang Sui.

</span>
<span class="ltx_bibblock">Unlocking efficiency in large language model inference: A comprehensive survey of speculative decoding, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Sang&nbsp;Michael Xie, Hieu Pham, Xuanyi Dong, Nan Du, Hanxiao Liu, Yifeng Lu, Percy Liang, Quoc&nbsp;V Le, Tengyu Ma, and Adams&nbsp;Wei Yu.

</span>
<span class="ltx_bibblock">Doremi: Optimizing data mixtures speeds up language model pretraining.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">arXiv preprint arXiv:2305.10429</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Fuzhao Xue, Yao Fu, Wangchunshu Zhou, Zangwei Zheng, and Yang You.

</span>
<span class="ltx_bibblock">To repeat or not to repeat: Insights from scaling llm under token-crisis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">arXiv preprint arXiv:2305.13230</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Haichao Yu, Yu&nbsp;Tian, Sateesh Kumar, Linjie Yang, and Heng Wang.

</span>
<span class="ltx_bibblock">The devil is in the details: A deep dive into the rabbit hole of data filtering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">arXiv preprint arXiv:2309.15954</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zellers et&nbsp;al. (2019)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.

</span>
<span class="ltx_bibblock">Hellaswag: Can a machine really finish your sentence?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. (2024)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Peiyuan Zhang, Guangtao Zeng, Tianduo Wang, and Wei Lu.

</span>
<span class="ltx_bibblock">Tinyllama: An open-source small language model, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et&nbsp;al. (2023)<button class="back-to-reference-btn" aria-label="Back to the article">↑</button></span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et&nbsp;al.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">arXiv preprint arXiv:2305.11206</em>, 2023.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Dataset Details</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Training Dataset</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.1">실험에서 주요 사전 훈련 코퍼스는 1,700억 개 이상의 토큰으로 구성된 선별된 영어 텍스트 데이터 세트인 거대 클린 크롤드 코퍼스(C4)이다. 이 코퍼스는 LLMs <cite class="ltx_cite ltx_citemacro_cite">Brown et al의 사전 훈련에서 일반적인 관행인 CommonCrawl에서 파생되었다. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib10" title="">2020</a>); Raffel et al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib57" title="">2020</a>); Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib62" title="">2023</a>)</cite>. 이 데이터 원본은 또한 The Pile <cite class="ltx_cite ltx_citemacro_cite">Gao et al을 포함하여 공개적으로 사용 가능한 LLM 사전 훈련 말뭉치에서도 두드러지게 특징지어집니다. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib24" title="">2020</a>)</cite> and RedPajama <cite class="ltx_cite ltx_citemacro_cite">Computer (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib16" title="">2023</a>)</cite>. CommonCrawl 데이터에는 다양한 버전이 있으며 사전 훈련을 위한 C4의 선택은 크기와 품질에 의해 결정된다.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS1.p2">
<p class="ltx_p" id="A1.SS1.p2.1">또한 정제된 웹 코퍼스 <cite class="ltx_cite ltx_citemacro_cite">Penedo et al.에 대한 사전 훈련과 비교한다. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib54" title="">2023</a>)</cite>. 데이터 세트도 CommonCrawl에서 파생되지만 더 엄격한 필터링 프로세스가 있습니다. 개선된 웹의 선택은 합성 재구문을 웹 데이터의 고품질 하위 집합과 비교하기 위한 것이며, 이는 큐레이트된 데이터 집합 <cite class="ltx_cite ltx_citemacro_cite">Penedo et al과 비교하여 유사한 성능을 달성하는 것으로 나타났다. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib54" title="">2023</a>)</cite>. 실험을 위해 첫 번째 <math alttext="3050" class="ltx_Math" display="inline" id="A1.SS1.p2.1.m1.1"><semantics id="A1.SS1.p2.1.m1.1a"><mn id="A1.SS1.p2.1.m1.1.1" xref="A1.SS1.p2.1.m1.1.1.cmml">3050</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.p2.1.m1.1b"><cn id="A1.SS1.p2.1.m1.1.1.cmml" type="integer" xref="A1.SS1.p2.1.m1.1.1">3050</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p2.1.m1.1c">3050</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p2.1.m1.1d">3050</annotation></semantics></math> 파일을 사용하고 C4에 대한 훈련과 일치하도록 300B 토큰에 대해 훈련한다. 우리는 정제된 웹 데이터 세트의 여러 에포크를 설명하기 위해 첫 번째 1650 파일로 실험을 수행한다.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Pile Perplexity Evaluation</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.SS2.p1">
<p class="ltx_p" id="A1.SS2.p1.1">평가 단계에서는 파일 코퍼스에서 20개의 하위 집합을 사용했다. 우리는 유로파일의 하위 집합이 비영어 언어를 포함하고 있기 때문에 제외했다. 사용된 서브세트들은 다음과 같다 : CC, StackExchange, Wikipedia, GitHub, PubMed Abstracts, Openwebtext2, Freelaw, Math, NIH, USPTO, Hackernews, Enron, Books3, PubMed Central, Gutenberg, Arxiv, Bookcorpus2, Opensubtitles, Youtubesubtitles, Ubuntu, 및 Philpapers. 각 부분 집합에서 처음 10000개의 샘플을 취하여 최대 길이 1024의 문서로 분할한다. 모든 퍼플렉시티 플롯에서 보고된 평균은 표 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A1.T7" title="Table 7 ‣ A.2.1 Pile Weighted Average Ratios ‣ A.2 Pile Perplexity Evaluation ‣ Appendix A Dataset Details ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">7</span></a>의 비율에 따라 모든 도메인의 퍼플렉시티에 대한 가중 평균이다.</p>
</div>
<section class="ltx_subsubsection" id="A1.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.2.1 </span>Pile Weighted Average Ratios</h4><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para" id="A1.SS2.SSS1.p1">
<p class="ltx_p" id="A1.SS2.SSS1.p1.1">표 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A1.T7" title="Table 7 ‣ A.2.1 Pile Weighted Average Ratios ‣ A.2 Pile Perplexity Evaluation ‣ Appendix A Dataset Details ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">7</span></a>의 파일 유효성 검사 세트에서 처음 10,000개의 문서에 따라 샘플에 대한 비율을 보고한다. <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib24" title="">2020</a>)</cite>에 보고된 것과 비교하여 비율에 약간의 변동이 있지만 대부분의 비율은 유사하다.</p>
</div>
<figure class="ltx_table" id="A1.T7">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T7.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T7.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A1.T7.1.1.1.1">Dataset</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T7.1.1.1.2">Validation Ratio (%)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T7.1.1.1.3">Published Ratio (%)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T7.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A1.T7.1.2.1.1">ArXiv</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.1.2.1.2">10.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T7.1.2.1.3">9.0</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.3.2.1">BookCorpus2</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.3.2.2">0.8</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.3.2.3">0.8</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.4.3.1">Books3</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.4.3.2">11.8</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.4.3.3">12.1</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.5.4.1">Pile-CC</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.5.4.2">14.0</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.5.4.3">18.11</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.6.5.1">Enron</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.6.5.2">0.1</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.6.5.3">0.1</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.7.6.1">EuroParl</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.7.6.2">1.1</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.7.6.3">0.7</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.8.7.1">FreeLaw</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.8.7.2">5.3</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.8.7.3">6.1</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.9.8.1">Github</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.9.8.2">10.9</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.9.8.3">7.6</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.10.9.1">Gutenberg</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.10.9.2">1.5</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.10.9.3">2.2</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.11.10.1">Hackernews</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.11.10.2">0.6</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.11.10.3">0.6</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.12.11.1">Dm Mathematics</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.12.11.2">2.0</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.12.11.3">1.2</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.13.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.13.12.1">NIH</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.13.12.2">0.2</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.13.12.3">0.3</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.14.13.1">OpenSubtitles</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.14.13.2">1.3</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.14.13.3">1.6</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.15.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.15.14.1">OpenWebText2</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.15.14.2">8.2</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.15.14.3">10.0</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.16.15">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.16.15.1">PhilPapers</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.16.15.2">0.7</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.16.15.3">0.4</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.17.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.17.16.1">PubMed Abstracts</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.17.16.2">0.7</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.17.16.3">3.1</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.18.17">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.18.17.1">PubMed Central</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.18.17.2">14.9</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.18.17.3">14.4</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.19.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.19.18.1">StackExchange</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.19.18.2">5.8</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.19.18.3">5.1</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.20.19">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.20.19.1">Ubuntu</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.20.19.2">1.3</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.20.19.3">0.9</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.21.20">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.21.20.1">USPTO</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.21.20.2">2.7</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.21.20.3">3.7</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.22.21">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A1.T7.1.22.21.1">Wikipedia</th>
<td class="ltx_td ltx_align_center" id="A1.T7.1.22.21.2">3.4</td>
<td class="ltx_td ltx_align_center" id="A1.T7.1.22.21.3">1.5</td>
</tr>
<tr class="ltx_tr" id="A1.T7.1.23.22">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A1.T7.1.23.22.1">YoutubeSubtitles</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T7.1.23.22.2">0.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T7.1.23.22.3">0.6</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Pile ratios for our evaluation compared with published ratios</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Zero-shot Evaluation Dataset</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.SS3.p1">
<p class="ltx_p" id="A1.SS3.p1.1">우리는 다양한 자연 언어 작업에 걸친 능력을 평가하기 위해 총 13개의 서로 다른 제로 샷 벤치마크에 대해 모델을 평가한다. 이러한 벤치마크는 전문 지식과 일반 이해의 두 가지 하위 집합으로 분류된다.</p>
</div>
<section class="ltx_paragraph" id="A1.SS3.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Specialized Knowledge</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS3.SSS0.Px1.p1.1">이 하위 집합은 도메인별 지식 및 전문 지식에 초점을 맞춘 데이터 집합으로 구성됩니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS0.Px1.p2">
<ul class="ltx_itemize" id="A1.I1">
<li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i1.p1">
<p class="ltx_p" id="A1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i1.p1.1.1">ARC Challenge (ARC-C)</span>: 이 데이터셋은 AI2 Reasoning Challenge (ARC) <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib15" title="">2018</a>)</cite>의 일부로, 3등급에서 9등급까지의 과학 시험 문제를 포함한다. ARC Challenge 세트는 고차 추론을 필요로 하는 더 어려운 문제를 포함한다.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i2.p1">
<p class="ltx_p" id="A1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i2.p1.1.1">SciQ</span>: 과학 영역 내에서 이해 및 추론에서 NLP 모델의 능력을 평가하기 위해 특별히 설계된 과학 시험 문제의 데이터 세트 [<cite class="ltx_cite ltx_citemacro_citep">(Johannes Welbl, <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib35" title="">2017</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i3.p1">
<p class="ltx_p" id="A1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i3.p1.1.1">PubMedQA</span>: 이 데이터 세트는 생체 의학 문헌에 초점을 맞추고 의료 및 의료 관련 정보의 이해도를 평가하도록 설계되었습니다. <cite class="ltx_cite ltx_citemacro_citep">(Jin et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib34" title="">2019</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I1.i4.p1">
<p class="ltx_p" id="A1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i4.p1.1.1">MathQA</span>: 이 dataset challenges models in mathematical problem-solving, requiring both numerical understanding and reasoning skills <cite class="ltx_cite ltx_citemacro_citep">(Amini et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib4" title="">2019</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="A1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="A1.I1.i5.p1">
<p class="ltx_p" id="A1.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I1.i5.p1.1.1">MMLU</span>: Multi-domain question answering, MMLU는 전문 도메인에서 학계에 이르기까지 광범위한 전문 주제에 걸쳐 모델의 전문성을 평가한다. <cite class="ltx_cite ltx_citemacro_citep">(Hendrycks et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib30" title="">2021</a>)</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS3.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">General Understanding</h5><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS3.SSS0.Px2.p1.1">이 부분 집합에는 일반적인 인지 기술, 언어 이해 및 상식 추론을 테스트하는 데이터 세트가 포함되어 있다.</p>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS0.Px2.p2">
<ul class="ltx_itemize" id="A1.I2">
<li class="ltx_item" id="A1.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i1.p1">
<p class="ltx_p" id="A1.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i1.p1.1.1">ARC Easy (ARC-E)</span>: The Easy set of the AI2 Reasoning Challenge <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib15" title="">2018</a>)</cite> features questions from the same source as ARC-C but is considered less challenging and not require as advanced reasoning skills.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i2.p1">
<p class="ltx_p" id="A1.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i2.p1.1.1">BoolQ</span>: 자연어 텍스트의 읽기 이해 및 일반 이해에 초점을 맞춘 boolean(yes/no) 질문으로 구성된 데이터셋 <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib14" title="">2019</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i3.p1">
<p class="ltx_p" id="A1.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i3.p1.1.1">Winogrande (Wino.)</span>: 이 dataset challenges models on common sense reasoning in a language context, focusing on pronoun disambiguation tasks <cite class="ltx_cite ltx_citemacro_citep">(ai2, <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib1" title="">2019</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i4.p1">
<p class="ltx_p" id="A1.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i4.p1.1.1">PIQA</span>: Physical Interaction Question Answering tests the understanding of everyday physical processes, a aspect of practical common sense <cite class="ltx_cite ltx_citemacro_citep">(Bisk et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib9" title="">2020</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i5.p1">
<p class="ltx_p" id="A1.I2.i5.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i5.p1.1.1">HellaSwag</span>: 이 데이터 세트는 언어 이해와 상식 추론 모두를 요구하는 컨텍스트 및 논리 일관성 방식으로 시나리오를 완료하는 모델의 능력을 평가합니다. <cite class="ltx_cite ltx_citemacro_citep">(Zellers et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib72" title="">2019</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i6.p1">
<p class="ltx_p" id="A1.I2.i6.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i6.p1.1.1">TruthfulQA</span>: Focused on the generation of truthful, accurate answers, this dataset challenges models on their ability to discern and reproduce factually correct information <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib42" title="">2021</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.I2.i7.p1">
<p class="ltx_p" id="A1.I2.i7.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i7.p1.1.1">OpenBookQA(OBQA)</span>: OpenBookQA는 넓은 배열의 사실과 개념을 이해해야 하므로 모델의 광범위한 지식과 추론 기술을 평가할 수 있다. <cite class="ltx_cite ltx_citemacro_citep">(Mihaylov et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib49" title="">2018</a>)</cite></p>
</div>
</li>
<li class="ltx_item" id="A1.I2.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="A1.I2.i8.p1">
<p class="ltx_p" id="A1.I2.i8.p1.1"><span class="ltx_text ltx_font_bold" id="A1.I2.i8.p1.1.1">LogiQA-2</span>: 이 데이터 세트는 논리적 추론, 모델의 능력을 테스트하여 논리적 구성 및 원리를 이해하고 적용합니다. <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib44" title="">2023b</a>)</cite>.</p>
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="A1.SS3.SSS0.Px2.p3">
<p class="ltx_p" id="A1.SS3.SSS0.Px2.p3.1">이러한 하위 집합의 각 데이터 세트는 과학, 의학 및 수학의 영역별 지식에서 상식 추론 및 일반 언어 이해와 같은 광범위한 기술에 이르기까지 자연어 처리 모델의 특정 측면에 도전하고 평가하기 위해 신중하게 선택된다.</p>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Filtering Details for Synthetic Data</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">언어 모델을 사용하여 합성 패러프레이즈를 생성할 때 생성된 출력에서 외부 도입의 문제에 종종 직면한다. 이러한 패러프레이즈는 “여기 패러프레이즈…”, “다음…”과 같은 문구로 시작되거나 심지어 “고급 영어”와 같은 키워드가 포함될 수 있습니다. 이를 완화하기 위해 합성 출력을 필터링하고 정제하는 방법을 개발했다.</p>
</div>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Methodology</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.1">기본 함수인 <span class="ltx_text ltx_font_typewriter" id="A2.SS1.p1.1.1">remove_unwanted_part</span>은 입력 데이터를 개별 문장으로 분할하는 것으로 시작합니다. 첫 번째 문장에 “\n\n”(새로운 단락을 나타냄) 또는 “:”과 같은 구분자가 포함되어 있는 경우, 기능은 앞서 언급한 원하지 않는 요소에 대해 구분자 앞의 세그먼트를 확인한다. 이러한 요소들이 검출되면, 선행 세그먼트가 제거된다. 그런 다음 수정된 전체 내용을 재구성하고 반환합니다. 수정이 적용되지 않지만 플래그된 키워드가 여전히 있는 경우 패러프레이즈를 완전히 제거합니다. 이를 달성하기 위하여:</p>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS1.p2">
<ol class="ltx_enumerate" id="A2.I1">
<li class="ltx_item" id="A2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A2.I1.i1.p1">
<p class="ltx_p" id="A2.I1.i1.p1.1">NLTK의 문장 분할기 함수를 이용하여 입력 데이터를 개별 문장으로 분할한다.</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A2.I1.i2.p1">
<p class="ltx_p" id="A2.I1.i2.p1.1">첫 번째 문장에 구분 기호가 있는지 검사합니다.</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A2.I1.i3.p1">
<p class="ltx_p" id="A2.I1.i3.p1.1">구분 기호가 탐지되면 이전 세그먼트에 원하지 않는 요소가 있는지 확인합니다.</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A2.I1.i4.p1">
<p class="ltx_p" id="A2.I1.i4.p1.1">원하지 않는 요소가 발견되면 이전 세그먼트를 폐기합니다 (<span class="ltx_text ltx_font_typewriter" id="A2.I1.i4.p1.1.1">"\n\n"</span> 또는 <span class="ltx_text ltx_font_typewriter" id="A2.I1.i4.p1.1.2">":"</span>).</p>
</div>
</li>
<li class="ltx_item" id="A2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para ltx_noindent" id="A2.I1.i5.p1">
<p class="ltx_p" id="A2.I1.i5.p1.1">필터링된 문단을 수정하고 반환합니다.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="A2.SS1.p3">
<p class="ltx_p" id="A2.SS1.p3.1">수동 검사 결과, 수정 후 오류율(원하지 않는 요소를 가진 문장의 발생)은 0.1% 미만임을 알 수 있었다.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Properties of Synthetic Corpus</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">재구문 모델에서 생성된 합성 데이터의 특성을 이해하기 위해 합성 데이터, C4 데이터 및 파일 데이터 간의 의미 유사성, 구문 복잡성 및 다양성을 비교한다. 우리의 주요 초점은 합성 데이터에 대한 다음 질문에 답하는 것입니다. (i) 합성 데이터에 대해 훈련된 모델이 재구어 모델로부터의 정보 유출로 인해 더 나은 성능을 발휘합니까? (ii) 재구문 모델이 여러 스타일을 정확하게 포착하는가? (iii) 합성 데이터의 어떤 속성이 이를 고품질로 만드는가? 우리의 조사는 특정 도메인에 대한 더 나은 일반화에 도움이 되는 데이터를 해결하고 데이터 변동성과 품질의 중요성을 정량화하는 데 도움이 된다.</p>
</div>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Experimental Setup</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A3.SS1.p1">
<p class="ltx_p" id="A3.SS1.p1.1">우리는 각각의 데이터 세트에서 처음 1000개의 문서의 부분 집합을 취한다. 실제 C4 데이터와의 합성 비교를 위해 샘플 쌍을 취하는 반면 파일 하위 집합의 경우 테스트 하위 집합에서 처음 1000개의 샘플을 취한다. 데이터 세트 품질 통계를 계산할 때 메트릭 값에서 두 개 이상의 표준 편차를 제거합니다. 파일 하위 집합의 샘플 수가 1000개 미만일 때 샘플을 분할했다. 분포가 있는 그림은 가우시안 커널 밀도 추정기(KDE)를 사용하여 1000개의 값으로부터 통계에 대한 분포를 구성한다.</p>
</div>
</section>
<section class="ltx_subsection" id="A3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Semantic Properties</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A3.F9">
<br class="ltx_break ltx_centering"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="467" id="A3.F9.g1" src="https://arxiv.org/html/2401.16380v1/x12.png" width="622">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Cosine similarity medium synthetic MRPC rephrases</figcaption>
<br class="ltx_break ltx_centering">
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A3.SS2.p1">
<p class="ltx_p" id="A3.SS2.p1.1"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S6" title="6 Analysis and Ablations ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">6</span></a> 섹션에서는 SimCSE objective <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib26" title="">2021</a>)</cite>로 학습된 BERT 모델을 사용하여 합성 데이터와 실제 데이터의 예제 쌍을 비교하여 성능 이득이 재구문 모델로부터의 지식 유출에 기인하지 않음을 확인했다. 그림 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A3.F9" title="Figure 9 ‣ C.2 Semantic Properties ‣ Appendix C Properties of Synthetic Corpus ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">9</span></a>(c)의 MRPC 말뭉치를 이용하여 합성 말뭉치와 실제 말뭉치의 유사성을 추가적으로 비교한다. 우리는 R1과 R2 문장의 분할 비교를 유지하면서 RealP(real paraphrase)로 이 추가 비교를 나타낸다. 합성 구문은 MRPC 말뭉치에 따라 실제 구문에 비해 평균 코사인 유사도가 유사하고 스프레드가 낮다.</p>
</p><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<figure class="ltx_figure" id="A3.F10">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_flex_size_2 ltx_align_center" id="A3.F9.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="415" id="A3.F9.sf1.g1" src="https://arxiv.org/html/2401.16380v1/x13.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Flesch-Kincaid Reading Level</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_flex_size_2 ltx_align_center" id="A3.F9.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="415" id="A3.F9.sf2.g1" src="https://arxiv.org/html/2401.16380v1/x14.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Type token ratio</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Comparison of readability and diversity (ttr) of synthetic data compared with C4 and different subsets of the Pile.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A3.SS2.p2">
<p class="ltx_p" id="A3.SS2.p2.1">의미 정보는 C4와 합성 데이터 간에 유사하므로 데이터의 양식적 차이를 추가로 조사한다. 그림 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A3.F10" title="Figure 10 ‣ C.2 Semantic Properties ‣ Appendix C Properties of Synthetic Corpus ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">10</span></a>(a)는 다른 재구어 스타일과 파일에 대한 Flesch-Kincaid 읽기 수준을 보여준다. 우리의 연구 결과는 C4가 읽기 수준의 낮은 끝(7-8)에 있음을 나타낸다. 대조적으로, 매체는 판독 수준을 10으로 증가시키고, qa 합성 변이체는 판독 수준을 6으로 추가로 감소시킨다. 중간 합성 데이터는 위키피디아의 판독 수준과 일치하고, 다른 높은 판독 수준 데이터 세트는 이들 도메인에서 더 나은 성능을 산출한다. QA 합성 데이터에서 우리는 감소된 읽기 수준을 관찰한다. 문장이 일반적으로 질문과 답변으로 분할되어 원문 및 중간 스타일 재구문에 비해 짧은 설정으로 이어지는 것을 관찰했기 때문이다. 이로 인해 많은 메트릭에 대한 메트릭 값이 낮아집니다. 유형 토큰 비율의 경우 다양성은 파일의 중간 하위 집합과 대부분의 하위 집합 간에 매우 유사하다는 점에 유의한다. QA 데이터 세트는 QA 형식 데이터 세트와 더 유사하고 질문 및 답변 형식의 반복이 심하기 때문에 특히 TTR 매칭 ubuntu, github 및 수학이 낮다.</p>
</div>
</section>
<section class="ltx_subsection" id="A3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.3 </span>Syntactic Properties</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A3.F11">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_flex_size_2 ltx_align_center" id="A3.F10.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="415" id="A3.F10.sf1.g1" src="https://arxiv.org/html/2401.16380v1/x15.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Tree Depth</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_flex_size_2 ltx_align_center" id="A3.F10.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="415" id="A3.F10.sf2.g1" src="https://arxiv.org/html/2401.16380v1/x16.png" width="830">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Mean Dependency Distance</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Comparison between synthetic and real data from the C4 corpus showing that synthetic data have higher syntactic complexity indicated by higher average tree depth, and higher mean dependency distance (MDD).</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A3.SS3.p1">
<p class="ltx_p" id="A3.SS3.p1.1">마지막으로, 그림 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A3.F11" title="Figure 11 ‣ C.3 Syntactic Properties ‣ Appendix C Properties of Synthetic Corpus ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">11</span></a>에서 평균 트리 깊이(의존 트리 깊이의 평균 초과 설정으로 측정됨)와 평균 의존 거리(문장 내 임의의 단어 쌍의 평균 의존 거리로 측정됨)를 비교하며, 이는 구문 난이도 <cite class="ltx_cite ltx_citemacro_cite">Futrell et al>의 좋은 척도로 나타났다. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib22" title="">2015</a>); Gibson et al. (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib27" title="">2000</a>); Oya (<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#bib.bib52" title="">2021</a>)</cite>. 우리는 매체가 일반적으로 깊이, mdd 및 구문 복잡성을 증가시키는 읽기 수준 및 TTR 다양성과 유사한 경향을 발견한다. 우리는 QA 스타일이 이러한 복잡성을 감소시킨다는 것을 다시 발견한다.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Evaluation Metrics</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">평가에 사용되는 메트릭은 <span class="ltx_text ltx_font_italic" id="A4.p1.1.1">macro 토큰 수준 perplexity</span>입니다. 인코딩된 텍스트의 배치가 주어지면 토큰 수준에서의 복잡도는 다음과 같이 계산되었다:</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p2">
<p class="ltx_p" id="A4.p2.3"><math alttext="L" class="ltx_Math" display="inline" id="A4.p2.1.m1.1"><semantics id="A4.p2.1.m1.1a"><mi id="A4.p2.1.m1.1.1" xref="A4.p2.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="A4.p2.1.m1.1b"><ci id="A4.p2.1.m1.1.1.cmml" xref="A4.p2.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.p2.1.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="A4.p2.1.m1.1d">italic_L</annotation></semantics></math>로 표시되는 전체 데이터세트에 걸쳐 누적된 손실이 주어지고, <math alttext="T" class="ltx_Math" display="inline" id="A4.p2.2.m2.1"><semantics id="A4.p2.2.m2.1a"><mi id="A4.p2.2.m2.1.1" xref="A4.p2.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="A4.p2.2.m2.1b"><ci id="A4.p2.2.m2.1.1.cmml" xref="A4.p2.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.p2.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="A4.p2.2.m2.1d">italic_T</annotation></semantics></math>로 표시되는 총 토큰 수, <math alttext="\mathcal{P}" class="ltx_Math" display="inline" id="A4.p2.3.m3.1"><semantics id="A4.p2.3.m3.1a"><mi class="ltx_font_mathcaligraphic" id="A4.p2.3.m3.1.1" xref="A4.p2.3.m3.1.1.cmml">𝒫</mi><annotation-xml encoding="MathML-Content" id="A4.p2.3.m3.1b"><ci id="A4.p2.3.m3.1.1.cmml" xref="A4.p2.3.m3.1.1">𝒫</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.p2.3.m3.1c">\mathcal{P}</annotation><annotation encoding="application/x-llamapun" id="A4.p2.3.m3.1d">caligraphic_P</annotation></semantics></math>로 표시되는 매크로 토큰 레벨 퍼플렉시티는 다음과 같이 계산된다:</p>
</div>
<div class="ltx_para ltx_noindent" id="A4.p3">
<table class="ltx_equation ltx_eqn_table" id="A4.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{P}=\exp\left(\min\left(20,\frac{L}{T}\right)\right)" class="ltx_Math" display="block" id="A4.E3.m1.5"><semantics id="A4.E3.m1.5a"><mrow id="A4.E3.m1.5.5" xref="A4.E3.m1.5.5.cmml"><mi class="ltx_font_mathcaligraphic" id="A4.E3.m1.5.5.3" xref="A4.E3.m1.5.5.3.cmml">𝒫</mi><mo id="A4.E3.m1.5.5.2" xref="A4.E3.m1.5.5.2.cmml">=</mo><mrow id="A4.E3.m1.5.5.1.1" xref="A4.E3.m1.5.5.1.2.cmml"><mi id="A4.E3.m1.4.4" xref="A4.E3.m1.4.4.cmml">exp</mi><mo id="A4.E3.m1.5.5.1.1a" xref="A4.E3.m1.5.5.1.2.cmml">⁡</mo><mrow id="A4.E3.m1.5.5.1.1.1" xref="A4.E3.m1.5.5.1.2.cmml"><mo id="A4.E3.m1.5.5.1.1.1.2" xref="A4.E3.m1.5.5.1.2.cmml">(</mo><mrow id="A4.E3.m1.5.5.1.1.1.1.2" xref="A4.E3.m1.5.5.1.1.1.1.1.cmml"><mi id="A4.E3.m1.1.1" xref="A4.E3.m1.1.1.cmml">min</mi><mo id="A4.E3.m1.5.5.1.1.1.1.2a" xref="A4.E3.m1.5.5.1.1.1.1.1.cmml">⁡</mo><mrow id="A4.E3.m1.5.5.1.1.1.1.2.1" xref="A4.E3.m1.5.5.1.1.1.1.1.cmml"><mo id="A4.E3.m1.5.5.1.1.1.1.2.1.1" xref="A4.E3.m1.5.5.1.1.1.1.1.cmml">(</mo><mn id="A4.E3.m1.2.2" xref="A4.E3.m1.2.2.cmml">20</mn><mo id="A4.E3.m1.5.5.1.1.1.1.2.1.2" xref="A4.E3.m1.5.5.1.1.1.1.1.cmml">,</mo><mfrac id="A4.E3.m1.3.3" xref="A4.E3.m1.3.3.cmml"><mi id="A4.E3.m1.3.3.2" xref="A4.E3.m1.3.3.2.cmml">L</mi><mi id="A4.E3.m1.3.3.3" xref="A4.E3.m1.3.3.3.cmml">T</mi></mfrac><mo id="A4.E3.m1.5.5.1.1.1.1.2.1.3" xref="A4.E3.m1.5.5.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="A4.E3.m1.5.5.1.1.1.3" xref="A4.E3.m1.5.5.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A4.E3.m1.5b"><apply id="A4.E3.m1.5.5.cmml" xref="A4.E3.m1.5.5"><eq id="A4.E3.m1.5.5.2.cmml" xref="A4.E3.m1.5.5.2"></eq><ci id="A4.E3.m1.5.5.3.cmml" xref="A4.E3.m1.5.5.3">𝒫</ci><apply id="A4.E3.m1.5.5.1.2.cmml" xref="A4.E3.m1.5.5.1.1"><exp id="A4.E3.m1.4.4.cmml" xref="A4.E3.m1.4.4"></exp><apply id="A4.E3.m1.5.5.1.1.1.1.1.cmml" xref="A4.E3.m1.5.5.1.1.1.1.2"><min id="A4.E3.m1.1.1.cmml" xref="A4.E3.m1.1.1"></min><cn id="A4.E3.m1.2.2.cmml" type="integer" xref="A4.E3.m1.2.2">20</cn><apply id="A4.E3.m1.3.3.cmml" xref="A4.E3.m1.3.3"><divide id="A4.E3.m1.3.3.1.cmml" xref="A4.E3.m1.3.3"></divide><ci id="A4.E3.m1.3.3.2.cmml" xref="A4.E3.m1.3.3.2">𝐿</ci><ci id="A4.E3.m1.3.3.3.cmml" xref="A4.E3.m1.3.3.3">𝑇</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.E3.m1.5c">\mathcal{P}=\exp\left(\min\left(20,\frac{L}{T}\right)\right)</annotation><annotation encoding="application/x-llamapun" id="A4.E3.m1.5d">caligraphic_P = roman_exp ( roman_min ( 20 , divide start_ARG italic_L end_ARG start_ARG italic_T end_ARG ) )</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="A4.p4">
<p class="ltx_p" id="A4.p4.1">여기서:</p>
<ul class="ltx_itemize" id="A4.I1">
<li class="ltx_item" id="A4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A4.I1.i1.p1">
<p class="ltx_p" id="A4.I1.i1.p1.1"><math alttext="\exp" class="ltx_Math" display="inline" id="A4.I1.i1.p1.1.m1.1"><semantics id="A4.I1.i1.p1.1.m1.1a"><mi id="A4.I1.i1.p1.1.m1.1.1" xref="A4.I1.i1.p1.1.m1.1.1.cmml">exp</mi><annotation-xml encoding="MathML-Content" id="A4.I1.i1.p1.1.m1.1b"><exp id="A4.I1.i1.p1.1.m1.1.1.cmml" xref="A4.I1.i1.p1.1.m1.1.1"></exp></annotation-xml><annotation encoding="application/x-tex" id="A4.I1.i1.p1.1.m1.1c">\exp</annotation><annotation encoding="application/x-llamapun" id="A4.I1.i1.p1.1.m1.1d">roman_exp</annotation></semantics></math>는 지수 함수이다.</p>
</div>
</li>
<li class="ltx_item" id="A4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A4.I1.i2.p1">
<p class="ltx_p" id="A4.I1.i2.p1.1"><math alttext="L" class="ltx_Math" display="inline" id="A4.I1.i2.p1.1.m1.1"><semantics id="A4.I1.i2.p1.1.m1.1a"><mi id="A4.I1.i2.p1.1.m1.1.1" xref="A4.I1.i2.p1.1.m1.1.1.cmml">L</mi><annotation-xml encoding="MathML-Content" id="A4.I1.i2.p1.1.m1.1b"><ci id="A4.I1.i2.p1.1.m1.1.1.cmml" xref="A4.I1.i2.p1.1.m1.1.1">𝐿</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.I1.i2.p1.1.m1.1c">L</annotation><annotation encoding="application/x-llamapun" id="A4.I1.i2.p1.1.m1.1d">italic_L</annotation></semantics></math>는 데이터 세트의 모든 시프트된 로짓 및 라벨에 대한 누적 손실이다.</p>
</div>
</li>
<li class="ltx_item" id="A4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="A4.I1.i3.p1">
<p class="ltx_p" id="A4.I1.i3.p1.1"><math alttext="T" class="ltx_Math" display="inline" id="A4.I1.i3.p1.1.m1.1"><semantics id="A4.I1.i3.p1.1.m1.1a"><mi id="A4.I1.i3.p1.1.m1.1.1" xref="A4.I1.i3.p1.1.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="A4.I1.i3.p1.1.m1.1b"><ci id="A4.I1.i3.p1.1.m1.1.1.cmml" xref="A4.I1.i3.p1.1.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.I1.i3.p1.1.m1.1c">T</annotation><annotation encoding="application/x-llamapun" id="A4.I1.i3.p1.1.m1.1d">italic_T</annotation></semantics></math>는 데이터셋의 총 토큰 수이다.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="A4.p5">
<p class="ltx_p" id="A4.p5.1">20의 값은 손실 값이 높은 경우에 메트릭을 안정화시키는 상한으로 작용한다.</p>
</div>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Additional Results for Smaller Model and Token Sizes</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<section class="ltx_subsection" id="A5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Results for 350M Models Trained for 75B Tokens</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_figure" id="A5.F12"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="415" id="A5.F12.g1" src="https://arxiv.org/html/2401.16380v1/x17.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Perplexity across all domains of the Pile comparing combining multiple styles of synthetic data. Models are 350M parameters trained for a total of 75B tokens.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A5.T8">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A5.T8.1" style="width:227.7pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.5pt,9.0pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A5.T8.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T8.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A5.T8.1.1.1.1.1">Dataset (Real Tok.)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T8.1.1.1.1.2">ARC-C</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T8.1.1.1.1.3">SciQ</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T8.1.1.1.1.4">PubMedQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T8.1.1.1.1.5">MathQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T8.1.1.1.1.6">MMLU</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T8.1.1.1.1.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T8.1.1.1.1.7.1" style="background-color:#E0FFFF;">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T8.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A5.T8.1.1.2.1.1">C4-15B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.1.1.2.1.2">21.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.1.1.2.1.3">77.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.1.1.2.1.4">50.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.1.1.2.1.5">22.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.1.1.2.1.6">23.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T8.1.1.2.1.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T8.1.1.2.1.7.1" style="background-color:#E0FFFF;">38.8</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A5.T8.1.1.3.2.1">C4-60B</th>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.3.2.2">23.4</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.3.2.3">76.2</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.3.2.4">46.4</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.3.2.5">22.0</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.3.2.6">23.0</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.3.2.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T8.1.1.3.2.7.1" style="background-color:#E0FFFF;">38.2</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A5.T8.1.1.4.3.1">QA+C4-15B</th>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.4.3.2">24.4</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.4.3.3">79.8</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.4.3.4">56.0</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.4.3.5">21.7</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.4.3.6">22.9</td>
<td class="ltx_td ltx_align_center" id="A5.T8.1.1.4.3.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T8.1.1.4.3.7.1" style="background-color:#E0FFFF;">41.0</span></td>
</tr>
<tr class="ltx_tr" id="A5.T8.1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A5.T8.1.1.5.4.1">Med+C4-15B</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T8.1.1.5.4.2">22.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T8.1.1.5.4.3">74.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T8.1.1.5.4.4">53.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T8.1.1.5.4.5">22.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T8.1.1.5.4.6">23.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T8.1.1.5.4.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T8.1.1.5.4.7.1" style="background-color:#E0FFFF;">39.2</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Evaluation of 350M parameter LLMs trained for 75B tokens on Specialized Knowledge Tasks. This table presents the performance on tasks that require specific domain knowledge such as science, medicine, mathematics, and logic.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A5.T9">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A5.T9.1" style="width:305.4pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-38.2pt,9.0pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A5.T9.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T9.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A5.T9.1.1.1.1.1">Dataset (Real Tok.)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T9.1.1.1.1.2">ARC-E</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T9.1.1.1.1.3">BoolQ</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T9.1.1.1.1.4">Wino.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T9.1.1.1.1.5">PIQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T9.1.1.1.1.6">HellaSwag</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T9.1.1.1.1.7">TruthfulQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T9.1.1.1.1.8">OBQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T9.1.1.1.1.9">LogiQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T9.1.1.1.1.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T9.1.1.1.1.10.1" style="background-color:#E0FFFF;">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T9.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A5.T9.1.1.2.1.1">C4-18B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T9.1.1.2.1.2">50.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T9.1.1.2.1.3">52.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T9.1.1.2.1.4">53.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T9.1.1.2.1.5">69.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T9.1.1.2.1.6">35.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T9.1.1.2.1.7">37.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T9.1.1.2.1.8">18.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T9.1.1.2.1.9">23.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T9.1.1.2.1.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T9.1.1.2.1.10.1" style="background-color:#E0FFFF;">42.6</span></td>
</tr>
<tr class="ltx_tr" id="A5.T9.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A5.T9.1.1.3.2.1">C4-75B</th>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.3.2.2">51.4</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.3.2.3">53.4</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.3.2.4">51.6</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.3.2.5">70.3</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.3.2.6">36.1</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.3.2.7">39.0</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.3.2.8">17.4</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.3.2.9">22.6</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.3.2.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T9.1.1.3.2.10.1" style="background-color:#E0FFFF;">42.7</span></td>
</tr>
<tr class="ltx_tr" id="A5.T9.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A5.T9.1.1.4.3.1">QA+C4-18B</th>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.4.3.2">53.4</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.4.3.3">60.7</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.4.3.4">52.2</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.4.3.5">70.0</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.4.3.6">36.3</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.4.3.7">40.0</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.4.3.8">17.6</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.4.3.9">22.3</td>
<td class="ltx_td ltx_align_center" id="A5.T9.1.1.4.3.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T9.1.1.4.3.10.1" style="background-color:#E0FFFF;">44.1</span></td>
</tr>
<tr class="ltx_tr" id="A5.T9.1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A5.T9.1.1.5.4.1">Med+C4-18B</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T9.1.1.5.4.2">50.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T9.1.1.5.4.3">57.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T9.1.1.5.4.4">53.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T9.1.1.5.4.5">70.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T9.1.1.5.4.6">36.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T9.1.1.5.4.7">36.9</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T9.1.1.5.4.8">18.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T9.1.1.5.4.9">22.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T9.1.1.5.4.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T9.1.1.5.4.10.1" style="background-color:#E0FFFF;">43.2</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Evaluation of 350M parameter LLMs trained for 75B tokens on General Understanding Tasks. This table shows the performance across various datasets, focusing on general reasoning, language understanding, and common sense comparing training .</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A5.SS1.p1">
<p class="ltx_p" id="A5.SS1.p1.2">우리는 더 작은 규모로 모델을 훈련하고 개선을 입증합니다. 특히 총 75B 토큰에 대해 350M GPT-2-medium 아키텍처를 훈련한다. 우리는 21개 도메인에 걸쳐 평균화된 파일 복잡도가 그림 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A5.F12" title="Figure 12 ‣ E.1 Results for 350M Models Trained for 75B Tokens ‣ Appendix E Additional Results for Smaller Model and Token Sizes ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">12</span></a>의 C4에서만 훈련된 모델보다 훨씬 낮고 그림 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S1.F0.sf3" title="0(c) ‣ Figure 1 ‣ 1 Introduction ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">0(c)</span></a>의 C4에서만 훈련된 1.3B 모델보다 훨씬 낮다는 것을 보여준다. 또한, 표 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A5.T8" title="Table 8 ‣ E.1 Results for 350M Models Trained for 75B Tokens ‣ Appendix E Additional Results for Smaller Model and Token Sizes ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">8</span></a>–<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A5.T9" title="Table 9 ‣ E.1 Results for 350M Models Trained for 75B Tokens ‣ Appendix E Additional Results for Smaller Model and Token Sizes ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">9</span></a>의 전문 지식 태스크에서 일반적인 이해 언어 태스크에 걸쳐 <math alttext="1.5\%" class="ltx_Math" display="inline" id="A5.SS1.p1.1.m1.1"><semantics id="A5.SS1.p1.1.m1.1a"><mrow id="A5.SS1.p1.1.m1.1.1" xref="A5.SS1.p1.1.m1.1.1.cmml"><mn id="A5.SS1.p1.1.m1.1.1.2" xref="A5.SS1.p1.1.m1.1.1.2.cmml">1.5</mn><mo id="A5.SS1.p1.1.m1.1.1.1" xref="A5.SS1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.1.m1.1b"><apply id="A5.SS1.p1.1.m1.1.1.cmml" xref="A5.SS1.p1.1.m1.1.1"><csymbol cd="latexml" id="A5.SS1.p1.1.m1.1.1.1.cmml" xref="A5.SS1.p1.1.m1.1.1.1">percent</csymbol><cn id="A5.SS1.p1.1.m1.1.1.2.cmml" type="float" xref="A5.SS1.p1.1.m1.1.1.2">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.1.m1.1c">1.5\%</annotation><annotation encoding="application/x-llamapun" id="A5.SS1.p1.1.m1.1d">1.5 %</annotation></semantics></math>의 증가를 보이고, QA 재구문을 추가할 때 대략 <math alttext="3\%" class="ltx_Math" display="inline" id="A5.SS1.p1.2.m2.1"><semantics id="A5.SS1.p1.2.m2.1a"><mrow id="A5.SS1.p1.2.m2.1.1" xref="A5.SS1.p1.2.m2.1.1.cmml"><mn id="A5.SS1.p1.2.m2.1.1.2" xref="A5.SS1.p1.2.m2.1.1.2.cmml">3</mn><mo id="A5.SS1.p1.2.m2.1.1.1" xref="A5.SS1.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.SS1.p1.2.m2.1b"><apply id="A5.SS1.p1.2.m2.1.1.cmml" xref="A5.SS1.p1.2.m2.1.1"><csymbol cd="latexml" id="A5.SS1.p1.2.m2.1.1.1.cmml" xref="A5.SS1.p1.2.m2.1.1.1">percent</csymbol><cn id="A5.SS1.p1.2.m2.1.1.2.cmml" type="integer" xref="A5.SS1.p1.2.m2.1.1.2">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS1.p1.2.m2.1c">3\%</annotation><annotation encoding="application/x-llamapun" id="A5.SS1.p1.2.m2.1d">3 %</annotation></semantics></math>의 증가를 보인다. 우리는 또한 이 더 작은 규모의 중간 구문을 실험했다. 우리의 연구 결과는 중간 재구문이 제공하는 고품질은 C4보다 성능이 향상되지만 QA 재구문 성능이 나타내는 스타일과 일치하면 성능이 더욱 향상된다는 것을 나타낸다.</p>
</div>
</section>
<section class="ltx_subsection" id="A5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>Results for 1.3B Models Trained for 150B Tokens</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A5.SS2.p1">
<p class="ltx_p" id="A5.SS2.p1.2">150B 토큰에서 1.3B GPT-2-XL 모델을 추가로 훈련하여 걸음 수를 절반으로 줄입니다. 우리는 20개 도메인에 걸쳐 평균화된 파일 복잡도가 그림 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A5.F13" title="Figure 13 ‣ E.2 Results for 1.3B Models Trained for 150B Tokens ‣ Appendix E Additional Results for Smaller Model and Token Sizes ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">13</span></a>의 C4에서만 훈련된 모델보다 훨씬 낮고 그림 <a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S1.F0.sf3" title="0(c) ‣ Figure 1 ‣ 1 Introduction ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">0(c)</span></a>의 C4에서만 훈련된 모델보다 2배 더 낮다는 것을 보여준다. 또한 전문 지식 태스크에 걸쳐 <math alttext="2\%" class="ltx_Math" display="inline" id="A5.SS2.p1.1.m1.1"><semantics id="A5.SS2.p1.1.m1.1a"><mrow id="A5.SS2.p1.1.m1.1.1" xref="A5.SS2.p1.1.m1.1.1.cmml"><mn id="A5.SS2.p1.1.m1.1.1.2" xref="A5.SS2.p1.1.m1.1.1.2.cmml">2</mn><mo id="A5.SS2.p1.1.m1.1.1.1" xref="A5.SS2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.SS2.p1.1.m1.1b"><apply id="A5.SS2.p1.1.m1.1.1.cmml" xref="A5.SS2.p1.1.m1.1.1"><csymbol cd="latexml" id="A5.SS2.p1.1.m1.1.1.1.cmml" xref="A5.SS2.p1.1.m1.1.1.1">percent</csymbol><cn id="A5.SS2.p1.1.m1.1.1.2.cmml" type="integer" xref="A5.SS2.p1.1.m1.1.1.2">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p1.1.m1.1c">2\%</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.p1.1.m1.1d">2 %</annotation></semantics></math>의 증가를 보이고, QA 재구문을 추가할 때 표<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A5.T10" title="Table 10 ‣ E.2 Results for 1.3B Models Trained for 150B Tokens ‣ Appendix E Additional Results for Smaller Model and Token Sizes ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">10</span></a>-<a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#A5.T11" title="Table 11 ‣ E.2 Results for 1.3B Models Trained for 150B Tokens ‣ Appendix E Additional Results for Smaller Model and Token Sizes ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">11</span></a>의 일반 이해 태스크에 대해 대략 <math alttext="2.5\%" class="ltx_Math" display="inline" id="A5.SS2.p1.2.m2.1"><semantics id="A5.SS2.p1.2.m2.1a"><mrow id="A5.SS2.p1.2.m2.1.1" xref="A5.SS2.p1.2.m2.1.1.cmml"><mn id="A5.SS2.p1.2.m2.1.1.2" xref="A5.SS2.p1.2.m2.1.1.2.cmml">2.5</mn><mo id="A5.SS2.p1.2.m2.1.1.1" xref="A5.SS2.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.SS2.p1.2.m2.1b"><apply id="A5.SS2.p1.2.m2.1.1.cmml" xref="A5.SS2.p1.2.m2.1.1"><csymbol cd="latexml" id="A5.SS2.p1.2.m2.1.1.1.cmml" xref="A5.SS2.p1.2.m2.1.1.1">percent</csymbol><cn id="A5.SS2.p1.2.m2.1.1.2.cmml" type="float" xref="A5.SS2.p1.2.m2.1.1.2">2.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p1.2.m2.1c">2.5\%</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.p1.2.m2.1d">2.5 %</annotation></semantics></math>의 증가를 보인다. 우리는 또한 이 더 작은 규모의 중간 구문을 실험했으며 다른 소규모 실험과 일치하는 유사한 결과를 보고한다.</p>
</div>
<figure class="ltx_figure" id="A5.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="415" id="A5.F13.g1" src="https://arxiv.org/html/2401.16380v1/x18.png" width="830">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Perplexity across all domains of the Pile comparing combining multiple styles of synthetic data. Models are 350M parameters trained for a total of 75B tokens.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A5.T10">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A5.T10.3" style="width:227.7pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.5pt,9.0pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A5.T10.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T10.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A5.T10.3.1.1.1.1">Dataset (Real Tok.)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T10.3.1.1.1.2">ARC-C</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T10.3.1.1.1.3">SciQ</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T10.3.1.1.1.4">PubMedQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T10.3.1.1.1.5">MathQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T10.3.1.1.1.6">MMLU</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T10.3.1.1.1.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T10.3.1.1.1.7.1" style="background-color:#E0FFFF;">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T10.3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A5.T10.3.1.2.1.1">C4-35B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T10.3.1.2.1.2">27.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T10.3.1.2.1.3">83.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T10.3.1.2.1.4">55.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T10.3.1.2.1.5">22.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T10.3.1.2.1.6">24.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T10.3.1.2.1.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T10.3.1.2.1.7.1" style="background-color:#E0FFFF;">42.4</span></td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A5.T10.3.1.3.2.1">C4-150B</th>
<td class="ltx_td ltx_align_center" id="A5.T10.3.1.3.2.2">25.9</td>
<td class="ltx_td ltx_align_center" id="A5.T10.3.1.3.2.3">83.8</td>
<td class="ltx_td ltx_align_center" id="A5.T10.3.1.3.2.4">55.4</td>
<td class="ltx_td ltx_align_center" id="A5.T10.3.1.3.2.5">23.5</td>
<td class="ltx_td ltx_align_center" id="A5.T10.3.1.3.2.6">25.4</td>
<td class="ltx_td ltx_align_center" id="A5.T10.3.1.3.2.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T10.3.1.3.2.7.1" style="background-color:#E0FFFF;">42.8</span></td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A5.T10.3.1.4.3.1">Med+C4-35B</th>
<td class="ltx_td ltx_align_center" id="A5.T10.3.1.4.3.2">27.2</td>
<td class="ltx_td ltx_align_center" id="A5.T10.3.1.4.3.3">82.2</td>
<td class="ltx_td ltx_align_center" id="A5.T10.3.1.4.3.4">46.2</td>
<td class="ltx_td ltx_align_center" id="A5.T10.3.1.4.3.5">23.1</td>
<td class="ltx_td ltx_align_center" id="A5.T10.3.1.4.3.6">25.2</td>
<td class="ltx_td ltx_align_center" id="A5.T10.3.1.4.3.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T10.3.1.4.3.7.1" style="background-color:#E0FFFF;">40.8</span></td>
</tr>
<tr class="ltx_tr" id="A5.T10.3.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A5.T10.3.1.5.4.1">QA+C4-35B</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T10.3.1.5.4.2">29.0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T10.3.1.5.4.3">85.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T10.3.1.5.4.4">62.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T10.3.1.5.4.5">22.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T10.3.1.5.4.6">26.1</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T10.3.1.5.4.7" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T10.3.1.5.4.7.1" style="background-color:#E0FFFF;">45.0</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Evaluation of <math alttext="\sim 1.3" class="ltx_Math" display="inline" id="A5.T10.2.m1.1"><semantics id="A5.T10.2.m1.1b"><mrow id="A5.T10.2.m1.1.1" xref="A5.T10.2.m1.1.1.cmml"><mi id="A5.T10.2.m1.1.1.2" xref="A5.T10.2.m1.1.1.2.cmml"></mi><mo id="A5.T10.2.m1.1.1.1" xref="A5.T10.2.m1.1.1.1.cmml">∼</mo><mn id="A5.T10.2.m1.1.1.3" xref="A5.T10.2.m1.1.1.3.cmml">1.3</mn></mrow><annotation-xml encoding="MathML-Content" id="A5.T10.2.m1.1c"><apply id="A5.T10.2.m1.1.1.cmml" xref="A5.T10.2.m1.1.1"><csymbol cd="latexml" id="A5.T10.2.m1.1.1.1.cmml" xref="A5.T10.2.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="A5.T10.2.m1.1.1.2.cmml" xref="A5.T10.2.m1.1.1.2">absent</csymbol><cn id="A5.T10.2.m1.1.1.3.cmml" type="float" xref="A5.T10.2.m1.1.1.3">1.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T10.2.m1.1d">\sim 1.3</annotation><annotation encoding="application/x-llamapun" id="A5.T10.2.m1.1e">∼ 1.3</annotation></semantics></math>B parameter LLMs trained for 150B tokens on Specialized Knowledge Tasks. This table presents the performance on tasks that require specific domain knowledge such as science, medicine, mathematics, and logic.</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<figure class="ltx_table" id="A5.T11">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A5.T11.3" style="width:305.4pt;height:72pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-38.2pt,9.0pt) scale(0.8,0.8) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A5.T11.3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T11.3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A5.T11.3.1.1.1.1">Dataset (Real Tok.)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T11.3.1.1.1.2">ARC-E</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T11.3.1.1.1.3">BoolQ</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T11.3.1.1.1.4">Wino.</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T11.3.1.1.1.5">PIQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T11.3.1.1.1.6">HellaSwag</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T11.3.1.1.1.7">TruthfulQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T11.3.1.1.1.8">OBQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T11.3.1.1.1.9">LogiQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T11.3.1.1.1.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T11.3.1.1.1.10.1" style="background-color:#E0FFFF;">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T11.3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A5.T11.3.1.2.1.1">C4-35B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T11.3.1.2.1.2">58.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T11.3.1.2.1.3">55.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T11.3.1.2.1.4">56.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T11.3.1.2.1.5">73.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T11.3.1.2.1.6">44.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T11.3.1.2.1.7">36.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T11.3.1.2.1.8">22.2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T11.3.1.2.1.9">22.8</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T11.3.1.2.1.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T11.3.1.2.1.10.1" style="background-color:#E0FFFF;">46.2</span></td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A5.T11.3.1.3.2.1">C4-150B</th>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.3.2.2">59.1</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.3.2.3">54.4</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.3.2.4">56.4</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.3.2.5">74.5</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.3.2.6">44.9</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.3.2.7">34.3</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.3.2.8">22.2</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.3.2.9">22.1</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.3.2.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T11.3.1.3.2.10.1" style="background-color:#E0FFFF;">46.0</span></td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A5.T11.3.1.4.3.1">Med+C4-35B</th>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.4.3.2">59.8</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.4.3.3">57.0</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.4.3.4">55.7</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.4.3.5">74.6</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.4.3.6">44.5</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.4.3.7">36.5</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.4.3.8">23.8</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.4.3.9">21.5</td>
<td class="ltx_td ltx_align_center" id="A5.T11.3.1.4.3.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T11.3.1.4.3.10.1" style="background-color:#E0FFFF;">46.7</span></td>
</tr>
<tr class="ltx_tr" id="A5.T11.3.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A5.T11.3.1.5.4.1">QA+C4-35B</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T11.3.1.5.4.2">62.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T11.3.1.5.4.3">63.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T11.3.1.5.4.4">55.7</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T11.3.1.5.4.5">74.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T11.3.1.5.4.6">44.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T11.3.1.5.4.7">41.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T11.3.1.5.4.8">22.4</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T11.3.1.5.4.9">23.2</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T11.3.1.5.4.10" style="background-color:#E0FFFF;"><span class="ltx_text" id="A5.T11.3.1.5.4.10.1" style="background-color:#E0FFFF;">48.4</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Evaluation of <math alttext="\sim 1.3" class="ltx_Math" display="inline" id="A5.T11.2.m1.1"><semantics id="A5.T11.2.m1.1b"><mrow id="A5.T11.2.m1.1.1" xref="A5.T11.2.m1.1.1.cmml"><mi id="A5.T11.2.m1.1.1.2" xref="A5.T11.2.m1.1.1.2.cmml"></mi><mo id="A5.T11.2.m1.1.1.1" xref="A5.T11.2.m1.1.1.1.cmml">∼</mo><mn id="A5.T11.2.m1.1.1.3" xref="A5.T11.2.m1.1.1.3.cmml">1.3</mn></mrow><annotation-xml encoding="MathML-Content" id="A5.T11.2.m1.1c"><apply id="A5.T11.2.m1.1.1.cmml" xref="A5.T11.2.m1.1.1"><csymbol cd="latexml" id="A5.T11.2.m1.1.1.1.cmml" xref="A5.T11.2.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="A5.T11.2.m1.1.1.2.cmml" xref="A5.T11.2.m1.1.1.2">absent</csymbol><cn id="A5.T11.2.m1.1.1.3.cmml" type="float" xref="A5.T11.2.m1.1.1.3">1.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A5.T11.2.m1.1d">\sim 1.3</annotation><annotation encoding="application/x-llamapun" id="A5.T11.2.m1.1e">∼ 1.3</annotation></semantics></math>B parameter LLMs trained for 150B tokens on General Understanding Tasks. This table shows the performance across various datasets, focusing on general reasoning, language understanding, and common sense comparing training .</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</section>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>LLM Leaderboard Few-shot Results</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A6.p1">
<p class="ltx_p" id="A6.p1.1"><a class="ltx_ref" href="https://arxiv.org/html/2401.16380v1#S4" title="4 Perplexity Evaluation ‣ Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling"><span class="ltx_text ltx_ref_tag">4</span></a> 섹션의 주요 실험에서 우리는 모델이 사전 훈련 동안 질문 응답 형식 및 스타일을 학습하기 때문에 합성 재구문으로 훈련된 LLM이 제로 샷 질문 응답 작업에 더 나은 백본임을 보여준다. 이 섹션에서는 모델이 테스트 샘플에 액세스할 수 있는 소수의 샷 설정에서도 합성 재구문에 대한 사전 훈련의 개선이 여전히 있음을 보여준다. 소샷 성능을 연구하기 위해 OpenLLMLeaderboard<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" title="">https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard</a></span></span></span>에 존재하는 6개의 태스크에 대해 평가한다.</p>
</div>
<div class="ltx_para ltx_noindent" id="A6.p2">
<ol class="ltx_enumerate" id="A6.I1">
<li class="ltx_item" id="A6.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="A6.I1.i1.p1">
<p class="ltx_p" id="A6.I1.i1.p1.1">ARC-챌린지(25 샷)</p>
</div>
</li>
<li class="ltx_item" id="A6.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="A6.I1.i2.p1">
<p class="ltx_p" id="A6.I1.i2.p1.1">헬라스웨그(10샷)</p>
</div>
</li>
<li class="ltx_item" id="A6.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="A6.I1.i3.p1">
<p class="ltx_p" id="A6.I1.i3.p1.1">MMLU(5 shot)</p>
</div>
</li>
<li class="ltx_item" id="A6.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span>
<div class="ltx_para" id="A6.I1.i4.p1">
<p class="ltx_p" id="A6.I1.i4.p1.1">진실-QA (5샷)</p>
</div>
</li>
<li class="ltx_item" id="A6.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span>
<div class="ltx_para" id="A6.I1.i5.p1">
<p class="ltx_p" id="A6.I1.i5.p1.1">위노그란데(5샷)</p>
</div>
</li>
<li class="ltx_item" id="A6.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span>
<div class="ltx_para ltx_noindent" id="A6.I1.i6.p1">
<p class="ltx_p" id="A6.I1.i6.p1.1">GSM8k(5 shot)</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="A6.p3">
<p class="ltx_p" id="A6.p3.1">우리는 각각 대략 85B 및 100B 고유 C4 토큰에 해당하는 300B 및 350B 토큰에 대해 훈련된 두 모델을 평가한다. 우리의 연구 결과는 ARC-챌린지 벤치마크와 Truthful-QA가 제로 샷 설정 및 다른 데이터 세트 간의 유사한 성능에서 상당한 개선을 보여준다. 우리의 모델은 또한 정제된 웹 데이터 세트에서 훈련된 공개적으로 출시된 팔콘-1.3B 모델과 파일에서 훈련된 피티아-1.4B 모델보다 더 나은 성능을 보인다.</p>
</div>
<figure class="ltx_table" id="A6.T12">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A6.T12.1" style="width:397.5pt;height:119.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(19.0pt,-5.7pt) scale(1.10548736362817,1.10548736362817) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A6.T12.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A6.T12.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="A6.T12.1.1.1.1.1">Dataset</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T12.1.1.1.1.2">ARC</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T12.1.1.1.1.3">Hellaswag</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T12.1.1.1.1.4">MMLU</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T12.1.1.1.1.5">TruthfulQA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T12.1.1.1.1.6">WinoGrande</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T12.1.1.1.1.7">GSM8K</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T12.1.1.1.1.8" style="background-color:#E0FFFF;"><span class="ltx_text" id="A6.T12.1.1.1.1.8.1" style="background-color:#E0FFFF;">Avg</span></td>
</tr>
<tr class="ltx_tr" id="A6.T12.1.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A6.T12.1.1.2.2.1">C4</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.1.1.2.2.2">31.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.1.1.2.2.3">62.1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.1.1.2.2.4">26.7</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.1.1.2.2.5">33.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.1.1.2.2.6">57.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.1.1.2.2.7">0.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.1.1.2.2.8" style="background-color:#E0FFFF;"><span class="ltx_text" id="A6.T12.1.1.2.2.8.1" style="background-color:#E0FFFF;">35.5</span></td>
</tr>
<tr class="ltx_tr" id="A6.T12.1.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A6.T12.1.1.3.3.1">Falcon-RW</th>
<td class="ltx_td ltx_align_center" id="A6.T12.1.1.3.3.2">35.1</td>
<td class="ltx_td ltx_align_center" id="A6.T12.1.1.3.3.3">63.6</td>
<td class="ltx_td ltx_align_center" id="A6.T12.1.1.3.3.4">25.3</td>
<td class="ltx_td ltx_align_center" id="A6.T12.1.1.3.3.5">36.0</td>
<td class="ltx_td ltx_align_center" id="A6.T12.1.1.3.3.6">62.0</td>
<td class="ltx_td ltx_align_center" id="A6.T12.1.1.3.3.7">0.5</td>
<td class="ltx_td ltx_align_center" id="A6.T12.1.1.3.3.8" style="background-color:#E0FFFF;"><span class="ltx_text" id="A6.T12.1.1.3.3.8.1" style="background-color:#E0FFFF;">37.1</span></td>
</tr>
<tr class="ltx_tr" id="A6.T12.1.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A6.T12.1.1.4.4.1">Pythia-1.4b-Pile</th>
<td class="ltx_td ltx_align_center" id="A6.T12.1.1.4.4.2">32.7</td>
<td class="ltx_td ltx_align_center" id="A6.T12.1.1.4.4.3">55.0</td>
<td class="ltx_td ltx_align_center" id="A6.T12.1.1.4.4.4">25.6</td>
<td class="ltx_td ltx_align_center" id="A6.T12.1.1.4.4.5">38.7</td>
<td class="ltx_td ltx_align_center" id="A6.T12.1.1.4.4.6">57.3</td>
<td class="ltx_td ltx_align_center" id="A6.T12.1.1.4.4.7">0.8</td>
<td class="ltx_td ltx_align_center" id="A6.T12.1.1.4.4.8" style="background-color:#E0FFFF;"><span class="ltx_text" id="A6.T12.1.1.4.4.8.1" style="background-color:#E0FFFF;">35.0</span></td>
</tr>
<tr class="ltx_tr" id="A6.T12.1.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A6.T12.1.1.5.5.1">QA+C4-85B (300K)</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.1.1.5.5.2">36.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.1.1.5.5.3">60.9</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.1.1.5.5.4">25.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.1.1.5.5.5">40.6</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.1.1.5.5.6">59.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.1.1.5.5.7">0.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T12.1.1.5.5.8" style="background-color:#E0FFFF;"><span class="ltx_text" id="A6.T12.1.1.5.5.8.1" style="background-color:#E0FFFF;">37.2</span></td>
</tr>
<tr class="ltx_tr" id="A6.T12.1.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A6.T12.1.1.6.6.1">QA+C4-100B (350K)</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T12.1.1.6.6.2">35.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T12.1.1.6.6.3">60.5</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T12.1.1.6.6.4">26.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T12.1.1.6.6.5">40.6</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T12.1.1.6.6.6">61.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T12.1.1.6.6.7">0.3</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T12.1.1.6.6.8" style="background-color:#E0FFFF;"><span class="ltx_text" id="A6.T12.1.1.6.6.8.1" style="background-color:#E0FFFF;">37.5</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>1.3B 300K LLM Leaderboard Eval. Evaluation is done on a single seed (1234).</figcaption>
</figure><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A7">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Rephrase Prompt Templates</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A7.p1">
<p class="ltx_p" id="A7.p1.1">특정 스타일로 C4 데이터 세트의 합성 버전을 생성하기 위해 미스트랄-7B 모델에 제공된 프롬프트를 자세히 설명한다. <em class="ltx_emph ltx_font_italic" id="A7.p1.1.1">Note: 다른 냉동 LLMs에 사용된 프롬프트에 약간의 변형이 있으며 T5 모델에는 프롬프트가 사용되지 않았습니다. </em></p>
</div>
<section class="ltx_subsection" id="A7.SSx1">
<h3 class="ltx_title ltx_title_subsection">Easy Style</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A7.SSx1.p1">
<p class="ltx_p" id="A7.SSx1.p1.1">유아들이 이해할 수 있는 콘텐츠를 생성하도록 설계된 스타일입니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SSx1.p2">
<svg class="ltx_picture" height="86.98" id="A7.SSx1.p2.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,86.98) matrix(1 0 0 -1 0 0)"><g fill="#9F9F9F" fill-opacity="1.000000"><path d="M 0 0 L 0 81.08 C 0 84.34 2.64 86.98 5.91 86.98 L 600 86.98 L 600 5.91 C 600 2.64 597.36 0 594.09 0 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.000000"><path d="M 1.97 1.97 L 1.97 81.08 C 1.97 83.25 3.73 85.01 5.91 85.01 L 598.03 85.01 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject height="59.42" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<p class="ltx_p ltx_minipage ltx_align_bottom" id="A7.SSx1.p2.pic1.2.2.2.2.2" style="width:402.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SSx1.p2.pic1.2.2.2.2.2.1">A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the questions. USER: For the following paragraph give me a paraphrase of the same using a very small vocabulary and extremely simple sentences that a toddler will understand:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A7.SSx2">
<h3 class="ltx_title ltx_title_subsection">Hard Style</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A7.SSx2.p1">
<p class="ltx_p" id="A7.SSx2.p1.1">난해한 언어를 사용하여 주로 학자들이 이해할 수 있는 콘텐츠를 생성하도록 설계된 스타일입니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SSx2.p2">
<svg class="ltx_picture" height="89.67" id="A7.SSx2.p2.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,89.67) matrix(1 0 0 -1 0 0)"><g fill="#9F9F9F" fill-opacity="1.000000"><path d="M 0 0 L 0 83.77 C 0 87.03 2.64 89.67 5.91 89.67 L 600 89.67 L 600 5.91 C 600 2.64 597.36 0 594.09 0 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.000000"><path d="M 1.97 1.97 L 1.97 83.77 C 1.97 85.94 3.73 87.7 5.91 87.7 L 598.03 87.7 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject height="62.11" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<p class="ltx_p ltx_minipage ltx_align_bottom" id="A7.SSx2.p2.pic1.2.2.2.2.2" style="width:402.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SSx2.p2.pic1.2.2.2.2.2.1">A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the questions. USER: For the following paragraph give me a paraphrase of the same using very terse and abstruse language that only an erudite scholar will understand. Replace simple words and phrases with rare and complex ones:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A7.SSx3">
<h3 class="ltx_title ltx_title_subsection">Medium Style</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A7.SSx3.p1">
<p class="ltx_p" id="A7.SSx3.p1.1">표준 백과사전 항목에 필적하는 콘텐츠를 생성하도록 설계된 스타일입니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SSx3.p2">
<svg class="ltx_picture" height="89.67" id="A7.SSx3.p2.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,89.67) matrix(1 0 0 -1 0 0)"><g fill="#9F9F9F" fill-opacity="1.000000"><path d="M 0 0 L 0 83.77 C 0 87.03 2.64 89.67 5.91 89.67 L 600 89.67 L 600 5.91 C 600 2.64 597.36 0 594.09 0 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.000000"><path d="M 1.97 1.97 L 1.97 83.77 C 1.97 85.94 3.73 87.7 5.91 87.7 L 598.03 87.7 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject height="62.11" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<p class="ltx_p ltx_minipage ltx_align_bottom" id="A7.SSx3.p2.pic1.2.2.2.2.2" style="width:402.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SSx3.p2.pic1.2.2.2.2.2.1">A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the questions. USER: For the following paragraph give me a diverse paraphrase of the same in high quality English language as in sentences on Wikipedia:</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A7.SSx4">
<h3 class="ltx_title ltx_title_subsection">Q/A Style</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A7.SSx4.p1">
<p class="ltx_p" id="A7.SSx4.p1.1">서사를 대화 형식으로 변환하기 위한 스타일입니다.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SSx4.p2">
<svg class="ltx_picture" height="73.22" id="A7.SSx4.p2.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,73.22) matrix(1 0 0 -1 0 0)"><g fill="#9F9F9F" fill-opacity="1.000000"><path d="M 0 0 L 0 67.32 C 0 70.58 2.64 73.22 5.91 73.22 L 600 73.22 L 600 5.91 C 600 2.64 597.36 0 594.09 0 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.000000"><path d="M 1.97 1.97 L 1.97 67.32 C 1.97 69.49 3.73 71.25 5.91 71.25 L 598.03 71.25 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject height="45.66" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
<p class="ltx_p ltx_minipage ltx_align_bottom" id="A7.SSx4.p2.pic1.2.2.2.2.2" style="width:402.3pt;"><span class="ltx_text ltx_font_typewriter" id="A7.SSx4.p2.pic1.2.2.2.2.2.1">A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the questions. USER: Convert the following paragraph into a conversational format with multiple tags of "Question:" followed by "Answer:":</span></p><button class="sr-only button" style="display: none;">Report issue for preceding element</button></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A8">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix H </span>Rephrase Examples</h2><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A8.p1">
<p class="ltx_p" id="A8.p1.1"><span class="ltx_text ltx_font_bold" id="A8.p1.1.1">Mistral-7B 모델에 의해 생성된 MRPC 말뭉치의 샘플들. </span></p>
</div>
<section class="ltx_subsection" id="A8.SSx1">
<h3 class="ltx_title ltx_title_subsection">Original</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A8.SSx1.p1">
<svg class="ltx_picture" height="103.59" id="A8.SSx1.p1.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,103.59) matrix(1 0 0 -1 0 0)"><g fill="#9F9F9F" fill-opacity="1.000000"><path d="M 0 0 L 0 97.68 C 0 100.94 2.64 103.59 5.91 103.59 L 600 103.59 L 600 5.91 C 600 2.64 597.36 0 594.09 0 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.000000"><path d="M 1.97 1.97 L 1.97 97.68 C 1.97 99.85 3.73 101.62 5.91 101.62 L 598.03 101.62 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject height="76.03" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A8.SSx1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_para" id="A8.SSx1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A8.SSx1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_typewriter" id="A8.SSx1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1">The stock rose $2.11, or about 11 percent, to close Friday at $21.51 on the New York Stock Exchange.</span></span>
<span class="ltx_p" id="A8.SSx1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2"><span class="ltx_text ltx_font_typewriter" id="A8.SSx1.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.1">Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier.</span></span>
</span></span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A8.SSx2">
<h3 class="ltx_title ltx_title_subsection">Medium Style</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A8.SSx2.p1">
<svg class="ltx_picture" height="106.28" id="A8.SSx2.p1.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,106.28) matrix(1 0 0 -1 0 0)"><g fill="#9F9F9F" fill-opacity="1.000000"><path d="M 0 0 L 0 100.37 C 0 103.63 2.64 106.28 5.91 106.28 L 600 106.28 L 600 5.91 C 600 2.64 597.36 0 594.09 0 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.000000"><path d="M 1.97 1.97 L 1.97 100.37 C 1.97 102.54 3.73 104.31 5.91 104.31 L 598.03 104.31 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject height="78.72" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A8.SSx2.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_para" id="A8.SSx2.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A8.SSx2.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_typewriter" id="A8.SSx2.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1">The stock experienced an increase of approximately 11 percent, closing at $21.51 on the New York Stock Exchange on Friday, with a rise of $2.11.</span></span>
<span class="ltx_p" id="A8.SSx2.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2"><span class="ltx_text ltx_font_typewriter" id="A8.SSx2.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.1">During the initial three months of the current year, there was a 15 percent decrease in revenue compared to the corresponding quarter of the previous year.</span></span>
</span></span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
</section>
<section class="ltx_subsection" id="A8.SSx3">
<h3 class="ltx_title ltx_title_subsection">Q/A Style</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A8.SSx3.p1">
<svg class="ltx_picture" height="106.28" id="A8.SSx3.p1.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,106.28) matrix(1 0 0 -1 0 0)"><g fill="#9F9F9F" fill-opacity="1.000000"><path d="M 0 0 L 0 100.37 C 0 103.63 2.64 106.28 5.91 106.28 L 600 106.28 L 600 5.91 C 600 2.64 597.36 0 594.09 0 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.000000"><path d="M 1.97 1.97 L 1.97 100.37 C 1.97 102.54 3.73 104.31 5.91 104.31 L 598.03 104.31 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject height="78.72" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A8.SSx3.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_para" id="A8.SSx3.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A8.SSx3.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_typewriter" id="A8.SSx3.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1">Question: What was the stock’s closing price on Friday? Answer: $21.51 Question: How much did the stock rise on Friday? Answer: $2.11 or about 11 percent.</span></span>
<span class="ltx_p" id="A8.SSx3.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2"><span class="ltx_text ltx_font_typewriter" id="A8.SSx3.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.1">Question: What was the revenue drop in the first quarter compared to the same period last year? Answer: The revenue dropped 15 percent.</span></span>
</span></span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para ltx_noindent" id="A8.SSx3.p2">
<p class="ltx_p" id="A8.SSx3.p2.1"><span class="ltx_text ltx_font_bold" id="A8.SSx3.p2.1.1">Mistral-7B 모델에 의해 생성된 C4 말뭉치의 샘플. </span></p>
</div>
</section>
<section class="ltx_subsection" id="A8.SSx4">
<h3 class="ltx_title ltx_title_subsection">Original</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A8.SSx4.p1">
<svg class="ltx_picture" height="651.53" id="A8.SSx4.p1.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,651.53) matrix(1 0 0 -1 0 0)"><g fill="#9F9F9F" fill-opacity="1.000000"><path d="M 0 0 L 0 645.63 C 0 648.89 2.64 651.53 5.91 651.53 L 600 651.53 L 600 5.91 C 600 2.64 597.36 0 594.09 0 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.000000"><path d="M 1.97 1.97 L 1.97 645.63 C 1.97 647.8 3.73 649.56 5.91 649.56 L 598.03 649.56 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject height="623.97" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A8.SSx4.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_para" id="A8.SSx4.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A8.SSx4.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_typewriter" id="A8.SSx4.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1">First round on stress at work survey. Answering the questionnaire is voluntary and all answers will be saved anonymously. Please fill in this questionnaire only if you have some work experience, part-or full time. Otherwise, you will not be able to answer some of the questions! Here is a the link to all language version.</span></span>
<span class="ltx_p" id="A8.SSx4.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2"><span class="ltx_text ltx_font_typewriter" id="A8.SSx4.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.1">Not that there’s a thing wrong with frozen burgers. The key here is the meat seasonings, which are pretty strong and spicy and just GOOD, something else I think is really necessary in a turkey burger because ground turkey otherwise can be kind of flavorless. You’ll need ground turkey, onion powder, chili powder, salt, pepper, and cayenne pepper for the burgers. Then the mayo takes garlic and onion. Then we need buns, clearly, swiss cheese, lettuce, and onion. I LOVE tomatoes but sometimes find that they get in the way of other flavors, so I left them off of this burger. Add them if you’d like to your array of toppings! First, we’ll make the mayo. Grate the garlic directly into the mayo, add a pinch of salt, and squeeze in the lemon juice. Stir. Done! I love this. Then, we’ll work on the burgers. Preheat a large skillet to medium-high heat with some olive oil, preheat the broiler to high, then add all the spices to the ground turkey.</span></span>
<span class="ltx_p" id="A8.SSx4.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3"><span class="ltx_text ltx_font_typewriter" id="A8.SSx4.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.1">Whether you like your velvet crushed, vibrant or head-to-toe, there’s really no denying the sheer luxe and elegance of this timeless textile. Not only is it super stylish, it can actually be so wearable for day-to-day wear. Yes, really! This year it’s all about embracing fun gem-toned velvety pieces. Long gone are the days when velvet was solely associated with dark moody shades of navy and black. Below we’ve rounded up the most covetable velvet pieces on the high street right now. We’re already coming up with outfit ideas! Are you completely obsessed or beyond bored of it?</span></span>
<span class="ltx_p" id="A8.SSx4.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4"><span class="ltx_text ltx_font_typewriter" id="A8.SSx4.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4.1">Save up to $8,086 on one of 1,258 Chrysler 200s near you. Find your perfect car with Edmunds expert and consumer car reviews, dealer reviews, car comparisons and pricing tools. We have 4,850,420. Research 2015 Chrysler 200 Sedan 4D 200C I4 prices, used values &amp; 200 Sedan 4D 200C I4 pricing, specs and more. Many years ago, we wrote about the stalling problem with the 2011 Chrysler 200, and believe it or not, we still receive an occasional call regarding the problem.However, a much larger issue has monopolized the phone lines as of late 2015 Chrysler 200 transmission problems leaving drivers with check engine lights, harsh shifting, and the occasional loss of power. The 2015 Chrysler 200 can fetch a premium for its style and its horsepower--but rear-seat room and handling are better bargains elsewhere. Find out why the 2015 Chrysler 200 is rated 8.4 by The. Don’t know where to find the perfect rims for your 2015 Chrysler 200 CARiD.com stores a massive selection of 2015 Chrysler 200 wheels offered in myriads of design and finish options, including chrome, black, silver, and so much more.</span></span>
</span></span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_subsection" id="A8.SSx5">
<h3 class="ltx_title ltx_title_subsection">Medium Style</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A8.SSx5.p1">
<svg class="ltx_picture" height="704.03" id="A8.SSx5.p1.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,704.03) matrix(1 0 0 -1 0 0)"><g fill="#9F9F9F" fill-opacity="1.000000"><path d="M 0 0 L 0 698.13 C 0 701.39 2.64 704.03 5.91 704.03 L 600 704.03 L 600 5.91 C 600 2.64 597.36 0 594.09 0 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.000000"><path d="M 1.97 1.97 L 1.97 698.13 C 1.97 700.3 3.73 702.07 5.91 702.07 L 598.03 702.07 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject height="676.48" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A8.SSx5.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_para" id="A8.SSx5.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A8.SSx5.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_typewriter" id="A8.SSx5.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1">In the initial stage of the survey on work-related stress, participation is optional, and all responses will be kept confidential. It is important to note that only those with work experience, whether part-time or full-time, will be able to accurately respond to certain questions. To complete the questionnaire, please use the following link, which is available in multiple languages.</span></span>
<span class="ltx_p" id="A8.SSx5.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2"><span class="ltx_text ltx_font_typewriter" id="A8.SSx5.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.1">Frozen burgers are not inherently flawed, but the meat seasonings are a crucial element that elevates the flavor of the dish. Ground turkey can be quite bland without the right blend of spices, so it is essential to add onion powder, chili powder, salt, pepper, and cayenne pepper to the mixture. Additionally, garlic and onion should be used in the mayonnaise, which is necessary for the burger’s topping. To make the mayo, grate the garlic directly into the mixture, add a pinch of salt, and squeeze in lemon juice. Mix well. The mayonnaise is a delicious addition to the burger topping. Now, let’s work on the burgers. Heat a large skillet over medium-high heat with some olive oil, and preheat the broiler to high. Add the seasonings to the ground turkey and mix well. The burgers should be cooked on the skillet for about 5 minutes on each side, then transferred to the broiler to cook for an additional 2-3 minutes. The burgers are ready to be assembled on buns, along with swiss cheese, lettuce, and onion. Tomatoes can be added as a topping, but they may overpower other flavors. It is up to the individual to decide if they want to include them in their burger. In conclusion, frozen burgers can be tasty, but the meat seasonings are essential to add depth and flavor to the dish. The mayonnaise and toppings can also be customized to suit individual preferences.</span></span>
<span class="ltx_p" id="A8.SSx5.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3"><span class="ltx_text ltx_font_typewriter" id="A8.SSx5.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.1">The luxurious and elegant nature of velvet cannot be denied, whether it is crushed, vibrant, or head-to-toe. This timeless textile is not only fashionable but also wearable for daily wear. In recent years, there has been a shift towards embracing fun gem-toned velvety pieces, breaking away from the traditional association of velvet with dark moody shades of navy and black. Below are some of the most desirable velvet pieces available on the high street today, and we are already envisioning outfits around them. Are you completely enamored with velvet or simply beyond bored with it?</span></span>
<span class="ltx_p" id="A8.SSx5.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4"><span class="ltx_text ltx_font_typewriter" id="A8.SSx5.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4.1">Discover savings up to $8,086 on one of 1,258 Chrysler 200s near you. Get expert and consumer car reviews, dealer reviews, car comparisons, and pricing tools from Edmunds. We have 4,850,420 listings for 2015 Chrysler 200 Sedan 4D 200C I4 prices, used values, and more. While we wrote about the stalling problem with the 2011 Chrysler 200, we still receive occasional calls regarding the issue. However, a more significant issue has taken over the phone lines recently - 2015 Chrysler 200 transmission problems that leave drivers with check engine lights, harsh shifting, and occasional loss of power. Despite the premium price for its style and horsepower, rear-seat room and handling are better bargains elsewhere. The 2015 Chrysler 200 is rated 8.4 by The Car Connection. If you’re looking for the perfect rims for your 2015 Chrysler 200 CARiD.com offers a vast selection of 2015 Chrysler 200 wheels in various design and finish options, including chrome, black, silver, and more</span></span>
</span></span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_subsection" id="A8.SSx6">
<h3 class="ltx_title ltx_title_subsection">Q/A Style</h3><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
<div class="ltx_para ltx_noindent" id="A8.SSx6.p1">
<svg class="ltx_picture" height="770.45" id="A8.SSx6.p1.pic1" overflow="visible" version="1.1" width="600"><g color="#000000" fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,770.45) matrix(1 0 0 -1 0 0)"><g fill="#9F9F9F" fill-opacity="1.000000"><path d="M 0 0 L 0 764.55 C 0 767.81 2.64 770.45 5.91 770.45 L 600 770.45 L 600 5.91 C 600 2.64 597.36 0 594.09 0 Z" style="stroke:none"></path></g><g fill="#E6E6E6" fill-opacity="1.000000"><path d="M 1.97 1.97 L 1.97 764.55 C 1.97 766.72 3.73 768.48 5.91 768.48 L 598.03 768.48 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 Z" style="stroke:none"></path></g><g fill-opacity="1.000000" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject height="742.89" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69"><span class="ltx_inline-para ltx_minipage ltx_align_bottom" id="A8.SSx6.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" style="width:402.3pt;">
<span class="ltx_para" id="A8.SSx6.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1">
<span class="ltx_p" id="A8.SSx6.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1"><span class="ltx_text ltx_font_typewriter" id="A8.SSx6.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.1.1">Question: Is participating in the stress at work survey mandatory? Answer: No, it is voluntary. Question: Will all answers be saved anonymously? Answer: Yes, they will. Question: Who is eligible to take the questionnaire? Answer: Only individuals with work experience, whether part-time or full-time. Question: What happens if someone is not eligible to take the questionnaire? Answer: They will not be able to answer some of the questions. Question: Can you provide a link to all language versions of the questionnaire? Answer: Yes, here is the link.</span></span>
<span class="ltx_p" id="A8.SSx6.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2"><span class="ltx_text ltx_font_typewriter" id="A8.SSx6.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.2.1">Question: What makes these frozen burgers so good? Answer: The meat seasonings are strong and spicy, and they give the burgers a good flavor. Question: Do you think ground turkey can be flavorless? Answer: Yes, ground turkey can be flavorless, but adding spices and seasonings can help. Question: What do you need to make these turkey burgers? Answer: Ground turkey, onion powder, chili powder, salt, pepper, and cayenne pepper for the burgers. Then the mayo takes garlic and onion. Buns, swiss cheese, lettuce, and onion are also needed. Question: What about toppings? Answer: Add tomatoes if you’d like to your array of toppings. Question: How do you make the mayo? Answer: Grate the garlic directly into the mayo, add a pinch of salt, and squeeze in the lemon juice. Stir. Done! Question: How do you work on the burgers? Answer: Preheat a large skillet to medium-high heat with some olive oil, preheat the broiler to high, then add all the spices to the ground turkey.</span></span>
<span class="ltx_p" id="A8.SSx6.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3"><span class="ltx_text ltx_font_typewriter" id="A8.SSx6.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.3.1">Question: What do you think of velvet? Answer: Whether you like your velvet crushed, vibrant or head-to-toe, there’s really no denying the sheer luxe and elegance of this timeless textile. Question: Is velvet super stylish? Answer: Yes, really! This year it’s all about embracing fun gem-toned velvety pieces. Question: Was velvet solely associated with dark moody shades of navy and black? Answer: Long gone are the days when velvet was solely associated with dark moody shades of navy and black. Question: Do you have any covetable velvet pieces on the high street right now? Answer: Below we’ve rounded up the most covetable velvet pieces on the high street right now. Question: Are you completely obsessed or beyond bored of it? Answer: We’re already coming up with outfit ideas!</span></span>
<span class="ltx_p" id="A8.SSx6.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4"><span class="ltx_text ltx_font_typewriter" id="A8.SSx6.p1.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.p1.4.1">Question: How can I save money on a Chrysler 200? Answer: Save up to $8,086 on one of 1,258 Chrysler 200s near you. Find your perfect car with Edmunds expert and consumer car reviews, dealer reviews, car comparisons and pricing tools. Question: What are the problems with the 2015 Chrysler 200? Answer: We have 4,850,420. Research 2015 Chrysler 200 Sedan 4D 200C I4 prices, used values &amp; 200 Sedan 4D 200C I4 pricing, specs and more. Many years ago, we wrote about the stalling problem with the 2011 Chrysler 200, and believe it or not, we still receive an occasional call regarding the problem. However, a much larger issue has monopolized the phone lines as of late 2015 Chrysler 200 transmission problems leaving drivers with check engine lights, harsh shifting, and the occasional loss of power. Question: What are the benefits of buying a 2015 Chrysler 200? Answer: The 2015 Chrysler 200 can fetch a premium for its style and its horsepower--but rear-seat room and handling are better bargains elsewhere. Question: How is the 2015 Chrysler 200 rated? Answer: It’s rated 8.4 by The. Question: Where can I find the perfect rims for my 2015 Chrysler 200? Answer: CARiD.com stores a massive selection of 2015 Chrysler 200 wheels offered in myriads of design and finish options, including chrome, black, silver, and so much more.</span></span>
</span></span></foreignObject></g></g></svg><button class="sr-only button" style="display: none;">Report issue for preceding element</button>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</article>
</div>

</div>


<div class="ltx_page_footer">
        <div class="ltx_page_logo">
            Generated on Wed Dec 14 18:01:44 2022 by
            <a href="https://math.nist.gov/~BMiller/LaTeXML/" class="ltx_LaTeXML_logo">
                <span style="letter-spacing: -0.2em; margin-right: 0.1em;">
                    L
                    <span style="font-size: 70%; position: relative; bottom: 2.2pt;">A</span>
                    T
                    <span style="position: relative; bottom: -0.4ex;">E</span>
                </span>
                <span class="ltx_font_smallcaps">xml</span>
                <img alt="[LOGO]" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==">
            </a>
        </div></div><footer id="footer" class="ltx_document">
        <div class="keyboard-glossary">
            <h2>Instructions for reporting errors</h2>
            <p>We are continuing to improve HTML versions of papers, and your feedback helps enhance accessibility and mobile support. To report errors in the HTML that will help us improve conversion and rendering, choose any of the methods listed below:</p>
            <ul>
                <li>Click the "Report Issue" button.</li>
                <li>Open a report feedback form via keyboard, use "<strong>Ctrl + ?</strong>".</li>
                <li>Make a text selection and click the "Report Issue for Selection" button near your cursor.</li>
                <li class="sr-only">You can use Alt+Y to toggle on and Alt+Shift+Y to toggle off accessible reporting links at each section.</li>
            </ul>
            <p>Our team has already identified <a class="ltx_ref" href="https://github.com/arXiv/html_feedback/issues" target="_blank">the following issues</a>. We appreciate your time reviewing and reporting rendering errors we may not have found yet. Your efforts will help us improve the HTML versions for all readers, because disability should not be a barrier to accessing research. Thank you for your continued support in championing open access for all.</p>
            <p>Have a free development cycle? Help support accessibility at arXiv! Our collaborators at LaTeXML maintain a <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/wiki/Porting-LaTeX-packages-for-LaTeXML" target="_blank">list of packages that need conversion</a>, and welcome <a class="ltx_ref" href="https://github.com/brucemiller/LaTeXML/issues" target="_blank">developer contributions</a>.</p>
        </div>
    </footer><button type="button" class="btn btn-primary hover-rp-button" id="openForm">Report Issue</button><div class="modal" id="myForm" role="dialog" aria-labelledby="modal-title"><div class="modal-dialog"><form class="modal-content" id="myFormContent" enctype="multipart/form-data"><div class="modal-header" id="modal-header"><h5 class="modal-title">Report Github Issue</h5><button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button></div><div class="modal-body"><label for="form_title" id="modalTitle">Title:</label><input class="form-control" id="form_title" name="form_title" required="required" placeholder="Enter title"><label for="description" id="selectedTextModalDescription" style="display: none;">Content selection saved. Describe the issue below:</label><label for="description" id="nomralModalDescription">Description:</label><textarea class="form-control" id="description" name="description" required="required" style="height: 80px;" maxlength="500" placeholder="500 characters maximum"></textarea></div><div class="modal-footer d-flex justify-content-end"><button type="submit" class="sr-only button" id="modal-submit-sr">Submit without Github</button><button type="submit" class="btn btn-primary" id="modal-submit">Submit in Github</button></div></form></div></div><button id="small-report-button" type="button" class="btn btn-secondary btn-sm" style="background-color: rgb(179, 27, 27); position: fixed;">Report Issue for Selection</button></body></html>