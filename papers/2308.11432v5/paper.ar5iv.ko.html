<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2308.11432] A Survey on Large Language Model based Autonomous Agents</title><meta property="og:description" content="Autonomous agents have long been a prominent research focus in both academic and industry communities.
Previous research in this field often focuses on training agents with limited knowledge within isolated environment…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Survey on Large Language Model based Autonomous Agents">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Survey on Large Language Model based Autonomous Agents">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2308.11432">

<!--Generated on Wed Feb 28 11:38:13 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Survey on Large Language Model based Autonomous Agents</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lei Wang,&nbsp;&nbsp;Chen Ma<span id="footnotex1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>These authors contribute equally to this paper.</span></span></span>,&nbsp;&nbsp;Xueyang Feng<span id="footnotex2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>These authors contribute equally to this paper.</span></span></span>,&nbsp;&nbsp;Zeyu Zhang,&nbsp;&nbsp;Hao Yang,&nbsp;&nbsp;Jingsen Zhang,
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_bold">Zhiyuan Chen</span>,&nbsp;&nbsp;<span id="id2.2.id2" class="ltx_text ltx_font_bold">Jiakai Tang</span>,&nbsp;&nbsp;<span id="id3.3.id3" class="ltx_text ltx_font_bold">Xu Chen</span>,&nbsp;&nbsp;<span id="id4.4.id4" class="ltx_text ltx_font_bold">Yankai Lin</span>,&nbsp;&nbsp;<span id="id5.5.id5" class="ltx_text ltx_font_bold">Wayne Xin Zhao</span>,&nbsp;&nbsp;<span id="id6.6.id6" class="ltx_text ltx_font_bold">Zhewei Wei</span>,
<br class="ltx_break">&nbsp;<span id="id7.7.id7" class="ltx_text ltx_font_bold">Ji-Rong Wen
<br class="ltx_break"></span>Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id8.id1">자율 에이전트는 오랫동안 학술 및 산업 커뮤니티 모두에서 두드러진 연구 초점이었다. 이 분야의 이전 연구는 종종 고립된 환경 내에서 제한된 지식을 가진 에이전트를 훈련하는 데 초점을 맞추며, 이는 인간의 학습 과정과 크게 다르므로 에이전트가 인간과 유사한 결정을 달성하기 어렵게 만든다. 최근, 방대한 양의 웹 지식의 습득을 통해, 대규모 언어 모델(LLM)은 인간 수준의 지능을 달성하는 데 놀라운 잠재력을 보여주었다. 이것은 LLM 기반 자율 에이전트를 조사하는 연구의 증가를 촉발했다. 본 논문에서는 이러한 연구에 대한 포괄적인 조사를 제시하여 LLM 기반 자율 에이전트 분야에 대한 체계적인 검토를 전체론적 관점에서 전달한다. 보다 구체적으로, 먼저 LLM 기반 자율 에이전트의 구성에 대해 논의하며, 이를 위해 이전 작업의 대부분을 포함하는 통합된 프레임워크를 제안한다. 그런 다음 사회 과학, 자연 과학 및 공학 분야에서 LLM 기반 자율 에이전트의 다양한 적용에 대한 포괄적인 개요를 제시한다. 마지막으로, 우리는 LLM 기반 자율 에이전트에 일반적으로 사용되는 평가 전략을 조사한다. 선행 연구를 바탕으로 이 분야의 몇 가지 과제와 향후 방향도 제시한다. 이 필드를 추적하고 지속적으로 설문 조사를 업데이트하기 위해 https://github.com/Paitesanshi/LLM-Agent-Survey에서 관련 참조 리포지토리를 유지 관리합니다.</p>
</div>
<figure id="S0.F1" class="ltx_figure">
<p id="S0.F1.1" class="ltx_p ltx_align_center"><span id="S0.F1.1.1" class="ltx_text ltx_framed ltx_framed_rectangle" style="border-color: #000000;padding:0.0pt;">
<img src="https://ar5iv.labs.arxiv.org/html/2308.11432/assets/x1.png" id="S0.F1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="234" alt="Refer to caption">
</span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 1:</span></figcaption><figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>
Illustration of the growth trend in the field of LLM-based autonomous agents.
We present the cumulative number of papers published from January 2021 to August 2023.
We assign different colors to represent various agent categories. For example, a game agent aims to simulate a game-player, while a tool agent mainly focuses on tool using.
For each time period, we provide a curated list of studies with diverse agent categories.
</figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<blockquote id="S1.p1.1" class="ltx_quote ltx_epigraph " style="width:325.21pt; margin-left:auto;;">
<div id="S1.p1.1.1" class="ltx_block ltx_epigraph_text" style="text-align:left; ;">
<p class="ltx_p" id="S1.p1.1.1.1"><span class="ltx_text ltx_font_italic" id="S1.p1.1.1.1">“An autonomous agent is a system situated within and a part of a environment which senses that environment and act on it, over time, in pursuit of its own agenda and so to effect what it senses in the future.”</span></p>
</div>
<div id="S1.p1.1.2" class="ltx_block ltx_epigraph_source" style="border-top:solid 0.4pt; text-align:right; ;">
<p class="ltx_p" id="S1.p1.1.2.1">Franklin and Graesser (1997)</p>
</div>
</blockquote>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.p2.1">자율 에이전트는 오랫동안 인공 지능(AGI)을 달성하기 위한 유망한 접근법으로 인식되어 왔으며, 이는 자기 주도적인 계획과 행동을 통해 작업을 수행할 것으로 예상된다. 이전 연구에서 에이전트는 단순하고 휴리스틱한 정책 함수를 기반으로 행동한다고 가정했으며 고립되고 제한된 환경에서 학습되었다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib113" title="">113</a>, <a class="ltx_ref" href="#bib.bib96" title="">96</a>, <a class="ltx_ref" href="#bib.bib134" title="">134</a>, <a class="ltx_ref" href="#bib.bib60" title="">60</a>, <a class="ltx_ref" href="#bib.bib11" title="">11</a>, <a class="ltx_ref" href="#bib.bib127" title="">127</a>]</cite> 이러한 가정은 인간의 마음이 매우 복잡하고 개인이 훨씬 더 다양한 환경에서 학습할 수 있기 때문에 인간의 학습 과정과 크게 다르다. 이러한 공백으로 인해 이전 연구에서 얻은 에이전트는 일반적으로 인간 수준의 결정 프로세스를 복제하는 것과는 거리가 멀며, 특히 제약이 없는 개방형 도메인 설정에서 그렇다.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.p3.1">최근 몇 년 동안 대규모 언어 모델(LLM)은 인간과 유사한 지능<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib120" title="">120</a>, <a class="ltx_ref" href="#bib.bib127" title="">127</a>, <a class="ltx_ref" href="#bib.bib11" title="">11</a>, <a class="ltx_ref" href="#bib.bib4" title="">4</a>, <a class="ltx_ref" href="#bib.bib146" title="">146</a>, <a class="ltx_ref" href="#bib.bib147" title="">147</a>]</cite>를 달성하는 데 상당한 잠재력을 보여주면서 주목할 만한 성공을 거두었다. 이 기능은 상당한 수의 모델 매개변수와 함께 포괄적인 훈련 데이터 세트를 활용함으로써 발생한다. 이러한 능력을 기반으로 인간과 유사한 의사 결정 능력을 얻기 위해 자율 에이전트를 구성하기 위해 LLM을 중앙 제어기로 사용하는 연구 영역이 증가하고 있다. 이러한 방향에 따라 연구자들은 수많은 유망한 모델(이 분야의 개요는 그림 <a class="ltx_ref" href="#S0.F1" title="Figure 1 ‣ A Survey on Large Language Model based Autonomous Agents"><span class="ltx_text ltx_ref_tag">1</span></a> 참조)을 개발했으며, 여기서 핵심 아이디어는 LLM에 메모리와 같은 중요한 인간 능력을 갖추고 LLM이 인간처럼 행동하고 다양한 작업을 효과적으로 완료하도록 계획하는 것이다. 이전에는 이러한 모델을 독립적으로 제안했으며 전체적으로 요약하고 비교하려는 노력은 제한적이었다. 그러나 빠르게 발전하고 있는 이 분야에 대한 체계적인 요약은 이를 종합적으로 이해하고 향후 연구에 영감을 주는 데 큰 의미가 있다고 생각한다.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.p4.1">본 논문에서는 LLM 기반 자율 에이전트 분야에 대한 종합적인 조사를 수행한다. 구체적으로, 우리는 LLM 기반 자율 에이전트의 구성, 적용 및 평가를 포함한 세 가지 측면을 기반으로 설문조사를 구성한다. 에이전트 구축을 위해 두 가지 문제, 즉 (1) LLM을 더 잘 활용할 수 있도록 에이전트 아키텍처를 설계하는 방법과 (2) 서로 다른 작업을 완료할 수 있도록 에이전트 기능을 고취하고 향상시키는 방법에 중점을 둔다. 직관적으로, 첫 번째 문제는 에이전트에 대한 하드웨어 펀더멘털을 구축하는 것을 목표로 하는 반면, 두 번째 문제는 에이전트에게 소프트웨어 리소스를 제공하는 데 중점을 둔다. 첫 번째 문제에 대해 대부분의 이전 연구를 포괄할 수 있는 통합 에이전트 프레임워크를 제시한다. 두 번째 문제에 대해 에이전트의 능력 획득을 위해 일반적으로 사용되는 전략에 대한 요약을 제공한다. 에이전트 구성에 대한 논의 외에도 사회 과학, 자연 과학 및 공학에서 LLM 기반 자율 에이전트의 적용에 대한 개요도 제공한다. 마지막으로, 우리는 주관적 전략과 객관적 전략 모두에 초점을 맞춘 LLM 기반 자율 에이전트를 평가하기 위한 전략을 탐구한다.</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S1.p5.1">요약하면, 이 조사는 체계적인 검토를 수행하고 LLM 기반 자율 에이전트 분야의 기존 연구에 대한 포괄적인 분류를 설정한다. 우리는 에이전트 구축, 적용 및 평가의 세 가지 측면에 중점을 둡니다. 선행 연구를 바탕으로 이 분야의 다양한 과제를 파악하고 향후 발전 방향에 대해 논의한다. 우리는 이 분야가 아직 초기 단계이기 때문에 https://github.com/Paitesanshi/LLM-Agent-Survey에서 진행 중인 연구를 추적할 수 있는 저장소를 유지하고 있으며, 우리의 조사가 LLM 기반 자율 에이전트 분야에 포괄적인 배경 지식을 제공하고 추가 획기적인 연구를 장려할 수 있을 것으로 기대한다.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>LLM-based Autonomous Agent Construction</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.p1.1">LLM 기반 자율 에이전트는 LLM의 인간다운 능력을 활용하여 다양한 작업을 효과적으로 수행할 수 있을 것으로 기대된다. 이러한 목적을 달성하기 위해, (1) LLMs를 더 잘 사용하기 위해 어떤 아키텍처가 설계되어야 하는지와 (2) 설계된 아키텍처에 에이전트가 특정 작업을 수행하기 위한 능력을 획득하는 방법을 제공하는 두 가지 중요한 측면이 있다. 아키텍처 디자인의 맥락에서, 우리는 포괄적인 통합 프레임워크 <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">*</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">*</sup><span class="ltx_tag ltx_tag_note">*</span>Our framework is also inspired by a pioneer work at https://lilianweng.github.io/posts/2023-06-23-agent/</span></span></span>에서 절정에 이르는 기존 연구의 체계적인 합성에 기여한다. 두 번째 측면은 LLM을 미세 조정하는지 여부에 따라 에이전트 능력 획득 전략을 요약한다. LLM 기반 자율 에이전트를 전통적인 기계 학습과 비교할 때, 에이전트 아키텍처를 설계하는 것은 네트워크 구조를 결정하는 것과 유사하지만, 에이전트 능력 획득은 네트워크 파라미터를 학습하는 것과 유사하다. 이하에서는 이 두 가지 측면을 좀 더 구체적으로 소개한다.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Agent Architecture Design</h3>

<div id="S2.SS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.p1.1">최근 LLM의 발전은 질의 응답(QA)의 형태로 광범위한 작업을 수행할 수 있는 큰 잠재력을 보여주었다. 그러나 자율 에이전트를 구축하는 것은 특정 역할을 수행하고 인간처럼 자신을 진화시키기 위해 환경에서 자율적으로 인식하고 학습해야 하기 때문에 QA와 거리가 멀다. 전통적인 LLM과 자율 에이전트 사이의 격차를 해소하기 위해, 중요한 측면은 LLM의 능력을 최대화하는 데 도움이 되는 합리적인 에이전트 아키텍처를 설계하는 것이다. 이러한 방향에 따라 이전 연구에서는 LLM을 향상시키기 위한 여러 모듈을 개발했다. 본 절에서는 이러한 모듈들을 요약하기 위한 통합 프레임워크를 제안한다. 특히, 본 프레임워크의 전체 구조는 프로파일링 모듈, 메모리 모듈, 플래닝 모듈, 액션 모듈로 구성된 <a class="ltx_ref" href="#S2.F2" title="Figure 2 ‣ 2.1.1 Profiling Module ‣ 2.1 Agent Architecture Design ‣ 2 LLM-based Autonomous Agent Construction ‣ A Survey on Large Language Model based Autonomous Agents"><span class="ltx_text ltx_ref_tag">2</span></a>를 예시한다. 프로파일링 모듈의 목적은 에이전트의 역할을 식별하는 것이다. 메모리 및 계획 모듈은 에이전트를 동적 환경으로 배치하여 과거의 행동을 회상하고 미래의 행동을 계획할 수 있게 한다. 작업 모듈은 에이전트의 결정을 특정 출력으로 변환하는 역할을 합니다. 이들 모듈 내에서 프로파일링 모듈은 메모리 및 계획 모듈에 영향을 미치고, 집합적으로 이들 세 모듈은 액션 모듈에 영향을 미친다. 다음에서는 이러한 모듈에 대해 자세히 설명합니다.</p>
</div>
<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>Profiling Module</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS1.p1.1">자율 에이전트는 일반적으로 코더, 교사 및 도메인 전문가 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib124" title="">124</a>, <a class="ltx_ref" href="#bib.bib39" title="">39</a>]</cite>와 같은 특정 역할을 가정하여 작업을 수행한다. 프로파일링 모듈은 일반적으로 LLM 동작에 영향을 미치기 위해 프롬프트에 작성되는 에이전트 역할의 프로파일을 나타내는 것을 목표로 한다. 에이전트 프로필은 대표적으로 나이, 성별, 경력 등의 기본 정보, 심리 정보뿐만 아니라 에이전트의 개성을 반영하는 심리 정보, 에이전트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib149" title="">149</a>]</cite> 및 사회 정보 등을 포괄하여 에이전트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib149" title="">149</a>]</cite> 간의 관계를 자세히 설명한다. 에이전트를 프로파일링하기 위한 정보의 선택은 주로 특정 애플리케이션 시나리오에 의해 결정된다. 예를 들어, 응용 프로그램이 인간의 인지 과정을 연구하는 것을 목표로 한다면 심리 정보는 중추적인 것이 된다. 프로파일 정보의 유형을 식별한 후, 다음으로 중요한 문제는 에이전트에 대한 특정 프로파일을 생성하는 것이다. 기존 문헌은 공통적으로 다음의 세 가지 전략을 사용한다.</p>
</div>
<div id="S2.SS1.SSS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS1.p2.1.1">Handcrafting Method</span>: in this method, agent profiles is manually specified. 예를 들어, 성격이 다른 에이전트를 디자인하고 싶다면 "당신은 외향적인 사람" 또는 "당신은 내성적인 사람"을 사용하여 에이전트를 프로파일링할 수 있습니다. 핸드 크래프팅 방법은 에이전트 프로파일을 나타내기 위해 많은 이전 작업에서 활용되었다. 예를 들어, 생성 에이전트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib176" title="">176</a>]</cite>는 이름, 목적, 다른 에이전트와의 관계 등의 정보로 에이전트를 설명한다. MetaGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>, ChatDev <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib124" title="">124</a>]</cite>, Self-collaboration <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>는 소프트웨어 개발에서 다양한 역할과 그에 상응하는 책임을 미리 정의하며, 협업을 용이하게 하기 위해 각 에이전트에 별개의 프로파일을 수동으로 할당한다. PTLLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib131" title="">131</a>]</cite>는 LLMs에 의해 생성된 텍스트에 나타나는 성격 특성을 탐색하고 정량화하는 것을 목표로 한다. 이 방법은 IPIP-NEO <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib77" title="">77</a>]</cite> 및 BFI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib76" title="">76</a>]</cite>와 같은 성격 평가 도구를 사용하여 다양한 에이전트 캐릭터를 남성적으로 정의함으로써 다양한 응답을 생성하는 LLMs를 안내한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite>는 정치인, 언론인, 사업가와 같이 역할이 다른 LLM을 수동으로 프롬프트하여 LLM 출력의 독성을 연구한다. 일반적으로 핸드크래프팅 방법은 에이전트에게 프로파일 정보를 할당할 수 있기 때문에 매우 유연하다. 그러나 특히 많은 수의 에이전트를 처리할 때 노동 집약적일 수도 있다.</p>
</div>
<div id="S2.SS1.SSS1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS1.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS1.p3.1.1">LLM-generation Method</span>: in this method, agent profiles is automatically generated based on LLMs. 전형적으로, 그것은 타겟 모집단 내의 에이전트 프로파일들의 구성 및 속성들을 설명하면서 프로파일 생성 규칙들을 표시하는 것으로 시작한다. 그런 다음, 몇 개의 시드 에이전트 프로파일을 선택적으로 지정하여 몇 개의 샷 예제로 사용할 수 있다. 마지막으로 LLM은 모든 에이전트 프로필을 생성하는 데 활용됩니다. 예를 들어 RecAgent <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib150" title="">150</a>]</cite>는 먼저 나이, 성별, 개인 특성 및 영화 선호도와 같은 배경을 수동으로 만들어 소수의 에이전트에 대한 시드 프로필을 만듭니다. 그런 다음 ChatGPT를 활용하여 시드 정보를 기반으로 더 많은 에이전트 프로필을 생성한다. LLM 생성 방법은 에이전트의 수가 많을 때 상당한 시간을 절약할 수 있지만 생성된 프로파일에 대한 정확한 제어가 부족할 수 있다.</p>
</div>
<div id="S2.SS1.SSS1.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS1.p4.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS1.p4.1.1">Dataset Alignment Method</span>: in this method, the agent profile is obtained from real-world datasets. 일반적으로 데이터 세트의 실제 인간에 대한 정보를 먼저 자연어 프롬프트로 구성한 다음 이를 활용하여 에이전트를 프로파일링할 수 있습니다. 예를 들어, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib5" title="">5</a>]</cite>에서 저자는 미국 선거 연구(ANES) 참가자의 인구 통계학적 배경(인종/민족, 성별, 연령 및 거주 상태 등)에 따라 GPT-3에 역할을 할당한다. 그들은 이후에 GPT-3가 실제 인간과 유사한 결과를 생성할 수 있는지 여부를 조사한다. 데이터세트 정렬 방법은 실제 모집단의 속성을 정확하게 캡처하여 에이전트 동작을 실제 시나리오를 보다 의미 있고 반영하게 한다.</p>
</div>
<div id="Thmremarkx1" class="ltx_theorem ltx_theorem_remark">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmremarkx1.1.1.1" class="ltx_text ltx_font_italic">Remark</span></span><span id="Thmremarkx1.2.2" class="ltx_text ltx_font_italic">.</span>
</h6>
<div id="Thmremarkx1.p1" class="ltx_para">
<p class="ltx_p" id="Thmremarkx1.p1.1">이전 작업의 대부분은 위의 프로필 생성 전략을 독립적으로 활용하지만, 이를 결합하면 추가 이점이 발생할 수 있다고 주장한다. 예를 들어, 에이전트 시뮬레이션을 통해 소셜 개발을 예측하기 위해 실제 데이터 세트를 활용하여 에이전트의 하위 집합을 프로파일링하여 현재 소셜 상태를 정확하게 반영할 수 있다. 이후 현실 세계에는 존재하지 않지만 미래에 나타날 수 있는 역할을 다른 에이전트에 수동으로 할당할 수 있어 미래의 사회 발전을 예측할 수 있다. 프로파일 모듈은 에이전트 암기, 계획 및 실행 절차에 상당한 영향을 미치는 에이전트 설계의 기초가 된다.</p>
</div>
</div>
<figure id="S2.F2" class="ltx_figure">
<p id="S2.F2.1" class="ltx_p ltx_align_center"><span id="S2.F2.1.1" class="ltx_text ltx_framed ltx_framed_rectangle" style="border-color: #000000;padding:0.0pt;">
<img src="https://ar5iv.labs.arxiv.org/html/2308.11432/assets/x2.png" id="S2.F2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="208" alt="Refer to caption">
</span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 2:</span>LLM 기반 자율 에이전트의 아키텍쳐 설계를 위한 통합 프레임워크.</figcaption>
</figure>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2 </span>Memory Module</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p1.1">메모리 모듈은 에이전트 아키텍처 설계에서 매우 중요한 역할을 한다. 환경으로부터 인지되는 정보를 저장하고 기록된 기억을 활용하여 미래의 행동을 용이하게 한다. 메모리 모듈은 에이전트가 경험을 축적하고, 자기 진화하고, 보다 일관되고 합리적이며 효과적인 방식으로 행동하도록 도울 수 있다. 이 섹션에서는 메모리 모듈의 구조, 형식 및 동작에 초점을 맞춘 포괄적인 개요를 제공한다.</p>
</div>
<div id="S2.SS1.SSS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS2.p2.1.1">Memory Structures</span>: LLM 기반 자율 에이전트는 일반적으로 인간의 기억 프로세스에 대한 인지 과학 연구에서 파생된 원리 및 메커니즘을 통합한다. 인간의 기억은 지각적 입력을 등록하는 감각 기억에서 일시적으로 정보를 유지하는 단기 기억으로, 장기간에 걸쳐 정보를 통합하는 장기 기억으로 일반적인 진행을 따른다. 에이전트 기억 구조를 설계할 때 연구자들은 인간 기억의 이러한 측면에서 영감을 얻는다. 특히, 단기 메모리는 트랜스포머 아키텍처에 의해 제약된 컨텍스트 윈도우 내의 입력 정보와 유사하다. 장기 메모리는 에이전트가 필요에 따라 신속하게 쿼리하고 검색할 수 있는 외부 벡터 저장소와 유사합니다. 이하에서는 장단기 메모리를 기반으로 일반적으로 사용되는 두 가지 메모리 구조를 소개한다.</p>
</div>
<div id="S2.SS1.SSS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS2.p3.1.m1.1"><semantics id="S2.SS1.SSS2.p3.1.m1.1a"><mo id="S2.SS1.SSS2.p3.1.m1.1.1" xref="S2.SS1.SSS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p3.1.m1.1b"><ci id="S2.SS1.SSS2.p3.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p3.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS2.p3.1.1">Unified Memory</span>. 이 구조는 보통 상황 내 학습에 의해 실현되는 인간의 단기 기억만을 시뮬레이션하고, 기억 정보는 프롬프트에 직접 기입된다. 예를 들어, RLP<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib54" title="">54</a>]</cite>는 대화 에이전트로서 화자 및 청취자에 대한 내부 상태를 유지한다. 각 대화 라운드 동안, 이러한 상태들은 LLM 프롬프트로서 작용하여 에이전트의 단기 기억으로서 기능한다. SayPlan<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib129" title="">129</a>]</cite>는 태스크 계획을 위해 특별히 설계된 구체화된 에이전트이다. 이 에이전트에서 장면 그래프와 환경 피드백은 에이전트의 단기 기억 역할을 하여 에이전트의 동작을 안내한다. CALYPSO<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib183" title="">183</a>]</cite>는 던전 앤 드래곤 게임을 위해 설계된 에이전트로, 던전 마스터가 스토리의 창작과 내레이션을 도울 수 있다. 단기 기억은 장면 설명, 몬스터 정보 및 이전 요약에 기반합니다. DEPS<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib154" title="">154</a>]</cite>도 게임 에이전트이지만 마인크래프트용으로 개발되었습니다. 에이전트는 처음에 작업 계획을 생성한 다음 이를 활용하여 LLM을 프롬프트하고, LLM은 작업을 완료하는 작업을 생성합니다. 이러한 계획들은 대리인의 단기 기억으로 간주될 수 있다. 실제로 단기 기억을 구현하는 것은 간단하며 최근 또는 맥락적으로 민감한 행동과 관찰을 인식하는 에이전트의 능력을 향상시킬 수 있다.</p>
</div>
<div id="S2.SS1.SSS2.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS2.p4.1.m1.1"><semantics id="S2.SS1.SSS2.p4.1.m1.1a"><mo id="S2.SS1.SSS2.p4.1.m1.1.1" xref="S2.SS1.SSS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p4.1.m1.1b"><ci id="S2.SS1.SSS2.p4.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p4.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS2.p4.1.1">Hybrid Memory</span>. 이 구조는 인간의 단기 기억과 장기 기억을 명시적으로 모델링한다. 단기 기억은 일시적으로 최근의 인식을 완충시키는 반면, 장기 기억은 시간이 지남에 따라 중요한 정보를 통합한다. 예를 들어, 생성 에이전트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib121" title="">121</a>]</cite>는 에이전트 동작을 용이하게 하기 위해 하이브리드 메모리 구조를 사용한다. 단기 기억은 에이전트 현재 상황들에 대한 컨텍스트 정보를 포함하는 반면, 장기 기억은 현재 이벤트들에 따라 검색될 수 있는 에이전트 과거 행동들 및 생각들을 저장한다. AgentSims <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>도 하이브리드 메모리 아키텍처를 구현한다. 프롬프트에 제공된 정보는 단기 기억으로 간주될 수 있다. 저자들은 메모리의 저장 용량을 향상시키기 위해 벡터 데이터베이스를 활용하여 효율적인 저장과 검색을 용이하게 하는 장기 메모리 시스템을 제안한다. 구체적으로 에이전트의 일일 기억은 임베딩으로 인코딩되어 벡터 데이터베이스에 저장된다. 에이전트가 이전의 기억을 회상할 필요가 있는 경우, 장기 기억 시스템은 임베딩 유사성을 사용하여 관련 정보를 검색한다. 이러한 과정은 에이전트의 행동의 일관성을 향상시킬 수 있다. GITM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite>에서 단기 기억은 현재 궤적을 저장하고 장기 기억은 성공적인 이전 궤적으로 요약된 참조 계획을 저장한다. 장기 기억은 안정적인 지식을 제공하는 반면 단기 기억은 유연한 계획을 가능하게 한다. 반사 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib139" title="">139</a>]</cite>는 최근 피드백을 캡처하기 위해 단기 슬라이딩 창을 활용하고 축약된 통찰력을 유지하기 위해 영구 장기 스토리지를 통합합니다. 이 조합은 상세한 즉각적인 경험과 높은 수준의 추상화를 모두 활용할 수 있도록 한다. SCM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib92" title="">92</a>]</cite>는 가장 관련성이 높은 장기 지식을 선택적으로 활성화하여 단기 기억과 결합하여 복잡한 맥락적 대화에서 추론을 가능하게 한다. SimplyRetrieve <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib117" title="">117</a>]</cite>는 사용자 질의를 단기 메모리로 활용하고 외부 지식베이스를 이용하여 장기 메모리를 저장한다. 이 디자인은 사용자 프라이버시를 보장하면서 모델 정확도를 높입니다. MemorySandbox<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib72" title="">72</a>]</cite>는 메모리 객체를 저장하기 위해 2D 캔버스를 활용하여 장단기 메모리를 구현하며, 이후 다양한 대화 전반에 걸쳐 액세스할 수 있다. 사용자는 동일한 캔버스에서 서로 다른 에이전트와 여러 대화를 생성할 수 있어 간단한 드래그 앤 드롭 인터페이스를 통해 메모리 객체의 공유를 용이하게 한다. 실제로 단기 기억과 장기 기억을 모두 통합하면 복잡한 환경에서 작업을 수행하는 데 중요한 장거리 추론 능력과 가치 있는 경험의 축적을 위한 에이전트의 능력을 향상시킬 수 있다.</p>
</div>
<div id="Thmremarkx2" class="ltx_theorem ltx_theorem_remark">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmremarkx2.1.1.1" class="ltx_text ltx_font_italic">Remark</span></span><span id="Thmremarkx2.2.2" class="ltx_text ltx_font_italic">.</span>
</h6>
<div id="Thmremarkx2.p1" class="ltx_para">
<p class="ltx_p" id="Thmremarkx2.p1.1">주의 깊은 독자들은 또 다른 유형의 기억 구조, 즉 단지 장기 기억에 기초하는 것이 존재할 수 있다는 것을 발견할 수 있다. 그러나 우리는 그러한 유형의 기억이 문헌에 거의 문서화되지 않는다는 것을 발견했다. 우리의 추측은 에이전트가 항상 연속적이고 역동적인 환경에 위치하고 연속적인 행동이 높은 상관 관계를 나타낸다는 것이다. 따라서 단기 기억의 포착은 매우 중요하며 보통 무시할 수 없다.</p>
</div>
</div>
<div id="S2.SS1.SSS2.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p5.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS2.p5.1.1">Memory Formats</span>: 메모리 구조 외에도, 메모리 모듈을 분석하는 또 다른 관점은 메모리 저장 매체의 포맷, 예를 들어, 자연어 메모리 또는 임베딩 메모리에 기초한다. 서로 다른 메모리 포맷은 서로 다른 장점을 가지고 있어 다양한 응용 분야에 적합하다. 이하에서는 몇 가지 대표적인 메모리 포맷을 소개한다.</p>
</div>
<div id="S2.SS1.SSS2.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p6.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS2.p6.1.m1.1"><semantics id="S2.SS1.SSS2.p6.1.m1.1a"><mo id="S2.SS1.SSS2.p6.1.m1.1.1" xref="S2.SS1.SSS2.p6.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p6.1.m1.1b"><ci id="S2.SS1.SSS2.p6.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p6.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p6.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS2.p6.1.1">Natural Languages</span>. 이 형식에서 에이전트 행동 및 관찰과 같은 메모리 정보는 원시 자연 언어를 사용하여 직접 설명된다. 이 형식은 몇 가지 장점을 가지고 있다. 첫째, 메모리 정보를 유연하고 이해하기 쉽게 표현할 수 있다. 또한, 에이전트 행동을 안내하기 위한 포괄적인 신호를 제공할 수 있는 풍부한 의미 정보를 보유한다. 이전 연구에서 Reflexion<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib139" title="">139</a>]</cite>는 경험적 피드백을 슬라이딩 윈도우 내에 자연어로 저장한다. 보이저<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>는 메모리에 직접 저장되는 마인크래프트 게임 내에서 기술을 표현하기 위해 자연어 기술을 사용한다.</p>
</div>
<div id="S2.SS1.SSS2.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS2.p7.1.m1.1"><semantics id="S2.SS1.SSS2.p7.1.m1.1a"><mo id="S2.SS1.SSS2.p7.1.m1.1.1" xref="S2.SS1.SSS2.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p7.1.m1.1b"><ci id="S2.SS1.SSS2.p7.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p7.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS2.p7.1.1">Embeddings</span>. 이 포맷에서, 메모리 정보는 임베딩 벡터로 인코딩되어, 메모리 검색 및 판독 효율을 향상시킬 수 있다. 예를 들어 MemoryBank <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib179" title="">179</a>]</cite>는 각 메모리 세그먼트를 임베딩 벡터로 인코딩하여 검색을 위한 인덱싱된 코퍼스를 생성한다. GITM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite>는 매칭 및 재사용을 용이하게 하기 위한 임베딩으로서 참조 계획을 나타낸다. 또한 ChatDev<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib124" title="">124</a>]</cite>는 대화 히스토리를 검색을 위한 벡터로 인코딩한다.</p>
</div>
<div id="S2.SS1.SSS2.p8" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS2.p8.1.m1.1"><semantics id="S2.SS1.SSS2.p8.1.m1.1a"><mo id="S2.SS1.SSS2.p8.1.m1.1.1" xref="S2.SS1.SSS2.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p8.1.m1.1b"><ci id="S2.SS1.SSS2.p8.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p8.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS2.p8.1.1">Databases</span>. 이 형식에서는 메모리 정보가 데이터베이스에 저장되므로 에이전트가 메모리를 효율적이고 종합적으로 조작할 수 있다. 예를 들어, ChatDB<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>는 심볼릭 메모리 모듈로 데이터베이스를 사용한다. 에이전트는 SQL 문을 활용하여 메모리 정보를 정확하게 추가, 삭제 및 수정할 수 있습니다. DB-GPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib182" title="">182</a>]</cite>에서 메모리 모듈은 데이터베이스를 기반으로 구축된다. 메모리 정보를 보다 직관적으로 조작하기 위해 에이전트는 SQL 쿼리를 이해하고 실행할 수 있도록 미세 조정되어 자연어를 사용하여 데이터베이스와 직접 상호 작용할 수 있다.</p>
</div>
<div id="S2.SS1.SSS2.p9" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS2.p9.1.m1.1"><semantics id="S2.SS1.SSS2.p9.1.m1.1a"><mo id="S2.SS1.SSS2.p9.1.m1.1.1" xref="S2.SS1.SSS2.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p9.1.m1.1b"><ci id="S2.SS1.SSS2.p9.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p9.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS2.p9.1.1">Structured Lists</span>. 이 형식에서는 기억 정보를 목록으로 정리하여 기억의 의미를 효율적이고 간결하게 전달할 수 있다. 예를 들어, GITM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite>는 하위 목표에 대한 액션 리스트를 계층적 트리 구조로 저장한다. 계층 구조는 목표와 해당 계획 간의 관계를 명시적으로 포착합니다. RET-LLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib114" title="">114</a>]</cite>는 초기에 자연어 문장을 트리플렛 구로 변환한 후 메모리에 저장한다.</p>
</div>
<div id="Thmremarkx3" class="ltx_theorem ltx_theorem_remark">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmremarkx3.1.1.1" class="ltx_text ltx_font_italic">Remark</span></span><span id="Thmremarkx3.2.2" class="ltx_text ltx_font_italic">.</span>
</h6>
<div id="Thmremarkx3.p1" class="ltx_para">
<p class="ltx_p" id="Thmremarkx3.p1.1">여기서는 몇 가지 대표적인 메모리 형식만 보여주지만, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>에서 사용하는 프로그래밍 코드와 같이 덮이지 않은 것이 많다는 점에 유의하는 것이 중요하다. 또한 이러한 형식은 상호 배타적이지 않다는 점을 강조해야 하며, 많은 모델이 각각의 이점을 동시에 활용하기 위해 여러 형식을 통합한다. 주목할 만한 예는 키-밸류 리스트 구조를 활용하는 GITM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite>의 메모리 모듈이다. 이 구조에서 키는 임베딩 벡터로 표현되는 반면 값은 원시 자연어로 구성된다. 임베딩 벡터의 사용은 메모리 레코드들의 효율적인 검색을 가능하게 한다. 자연어를 활용함으로써 메모리 내용이 매우 포괄적이 되어 더 많은 정보에 입각한 에이전트 작업을 가능하게 합니다.</p>
</div>
</div>
<div id="S2.SS1.SSS2.p10" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p10.1">위에서, 우리는 주로 메모리 모듈의 내부 설계에 대해 논의한다. 다음에서는 외부 환경과 상호 작용하는 데 사용되는 메모리 작업에 초점을 맞춥니다.</p>
</div>
<div id="S2.SS1.SSS2.p11" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p11.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS2.p11.1.1">Memory Operations</span>: 메모리 모듈은 에이전트가 환경과 상호 작용하여 중요한 지식을 획득, 축적 및 활용할 수 있도록 하는 데 중요한 역할을 합니다. 에이전트와 환경 간의 상호 작용은 메모리 읽기, 메모리 쓰기, 메모리 반영의 세 가지 중요한 메모리 동작을 통해 이루어진다. 이하에서는 이러한 동작들을 보다 구체적으로 소개한다.</p>
</div>
<div id="S2.SS1.SSS2.p12" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p12.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS2.p12.1.m1.1"><semantics id="S2.SS1.SSS2.p12.1.m1.1a"><mo id="S2.SS1.SSS2.p12.1.m1.1.1" xref="S2.SS1.SSS2.p12.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.1.m1.1b"><ci id="S2.SS1.SSS2.p12.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p12.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS2.p12.1.1">Memory Reading</span>. 기억 읽기의 목적은 기억에서 의미 있는 정보를 추출하여 에이전트의 행동을 향상시키는 것이다. 예를 들어, 유사한 목표들을 달성하기 위해 이전에 성공한 액션들을 사용하는 것<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite>. 기억 읽기의 핵심은 가치 있는 정보를 추출하는 방법에 있다. 일반적으로 정보 추출을 위해 일반적으로 사용되는 세 가지 기준, 즉 최신성, 관련성 및 중요도 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib121" title="">121</a>]</cite>가 있다. 보다 최근, 관련성이 있고 중요한 기억이 추출될 가능성이 높다. 형식적으로 메모리 정보 추출을 위해 기존 문헌에서 다음과 같은 식을 결론짓는다:</p>
<table id="S2.E1" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S2.E1X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1X.2.1.1.m1.6" class="ltx_Math" alttext="\displaystyle m^{*}=\arg\min_{m\in M}\alpha s^{rec}(q,m)+\beta s^{rel}(q,m)+\gamma s^{imp}(m)," display="inline"><semantics id="S2.E1X.2.1.1.m1.6a"><mrow id="S2.E1X.2.1.1.m1.6.6.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.cmml"><mrow id="S2.E1X.2.1.1.m1.6.6.1.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.cmml"><msup id="S2.E1X.2.1.1.m1.6.6.1.1.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.2.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.1.1.2.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.2.2.cmml">m</mi><mo id="S2.E1X.2.1.1.m1.6.6.1.1.2.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.2.3.cmml">∗</mo></msup><mo id="S2.E1X.2.1.1.m1.6.6.1.1.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.1.cmml">=</mo><mrow id="S2.E1X.2.1.1.m1.6.6.1.1.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.cmml"><mrow id="S2.E1X.2.1.1.m1.6.6.1.1.3.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.cmml"><mrow id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.1.cmml">arg</mi><mo lspace="0.167em" id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2a" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.cmml">⁡</mo><mrow id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.cmml"><munder id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.2.cmml">min</mi><mrow id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3.2.cmml">m</mi><mo id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3.1.cmml">∈</mo><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3.3.cmml">M</mi></mrow></munder><mo lspace="0.167em" id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2a" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.cmml">⁡</mo><mrow id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.2.cmml">α</mi><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.1.cmml">​</mo><msup id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.2.cmml">s</mi><mrow id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.1.cmml">​</mo><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.1a" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.1.cmml">​</mo><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.4" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.4.cmml">c</mi></mrow></msup></mrow></mrow></mrow><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.1.cmml">​</mo><mrow id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.3.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.3.1.cmml"><mo stretchy="false" id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.3.2.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.3.1.cmml">(</mo><mi id="S2.E1X.2.1.1.m1.1.1" xref="S2.E1X.2.1.1.m1.1.1.cmml">q</mi><mo id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.3.2.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.3.1.cmml">,</mo><mi id="S2.E1X.2.1.1.m1.2.2" xref="S2.E1X.2.1.1.m1.2.2.cmml">m</mi><mo stretchy="false" id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.3.2.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.3.1.cmml">)</mo></mrow></mrow><mo id="S2.E1X.2.1.1.m1.6.6.1.1.3.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.1.cmml">+</mo><mrow id="S2.E1X.2.1.1.m1.6.6.1.1.3.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.2.cmml">β</mi><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.1.cmml">​</mo><msup id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.2.cmml">s</mi><mrow id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.1.cmml">​</mo><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.1a" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.1.cmml">​</mo><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.4" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.4.cmml">l</mi></mrow></msup><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.1a" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.1.cmml">​</mo><mrow id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.4.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.4.1.cmml"><mo stretchy="false" id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.4.2.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.4.1.cmml">(</mo><mi id="S2.E1X.2.1.1.m1.3.3" xref="S2.E1X.2.1.1.m1.3.3.cmml">q</mi><mo id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.4.2.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.4.1.cmml">,</mo><mi id="S2.E1X.2.1.1.m1.4.4" xref="S2.E1X.2.1.1.m1.4.4.cmml">m</mi><mo stretchy="false" id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.4.2.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.4.1.cmml">)</mo></mrow></mrow><mo id="S2.E1X.2.1.1.m1.6.6.1.1.3.1a" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.1.cmml">+</mo><mrow id="S2.E1X.2.1.1.m1.6.6.1.1.3.4" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.2.cmml">γ</mi><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.1.cmml">​</mo><msup id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.2.cmml">s</mi><mrow id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.cmml"><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.1.cmml">​</mo><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.3" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.1a" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.1.cmml">​</mo><mi id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.4" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.4.cmml">p</mi></mrow></msup><mo lspace="0em" rspace="0em" id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.1a" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.1.cmml">​</mo><mrow id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.4.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.cmml"><mo stretchy="false" id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.4.2.1" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.cmml">(</mo><mi id="S2.E1X.2.1.1.m1.5.5" xref="S2.E1X.2.1.1.m1.5.5.cmml">m</mi><mo stretchy="false" id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.4.2.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E1X.2.1.1.m1.6.6.1.2" xref="S2.E1X.2.1.1.m1.6.6.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1X.2.1.1.m1.6b"><apply id="S2.E1X.2.1.1.m1.6.6.1.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1"><eq id="S2.E1X.2.1.1.m1.6.6.1.1.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.1"></eq><apply id="S2.E1X.2.1.1.m1.6.6.1.1.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.2"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.6.6.1.1.2.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.2">superscript</csymbol><ci id="S2.E1X.2.1.1.m1.6.6.1.1.2.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.2.2">𝑚</ci><times id="S2.E1X.2.1.1.m1.6.6.1.1.2.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.2.3"></times></apply><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3"><plus id="S2.E1X.2.1.1.m1.6.6.1.1.3.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.1"></plus><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2"><times id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.1"></times><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2"><arg id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.1"></arg><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2"><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1">subscript</csymbol><min id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.2"></min><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3"><in id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3.1"></in><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3.2">𝑚</ci><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.1.3.3">𝑀</ci></apply></apply><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2"><times id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.1"></times><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.2">𝛼</ci><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3">superscript</csymbol><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.2">𝑠</ci><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3"><times id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.1"></times><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.2">𝑟</ci><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.3">𝑒</ci><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.4.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.2.2.2.3.3.4">𝑐</ci></apply></apply></apply></apply></apply><interval closure="open" id="S2.E1X.2.1.1.m1.6.6.1.1.3.2.3.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.2.3.2"><ci id="S2.E1X.2.1.1.m1.1.1.cmml" xref="S2.E1X.2.1.1.m1.1.1">𝑞</ci><ci id="S2.E1X.2.1.1.m1.2.2.cmml" xref="S2.E1X.2.1.1.m1.2.2">𝑚</ci></interval></apply><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3"><times id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.1"></times><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.2">𝛽</ci><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3">superscript</csymbol><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.2">𝑠</ci><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3"><times id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.1"></times><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.2">𝑟</ci><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.3">𝑒</ci><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.4.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.3.3.4">𝑙</ci></apply></apply><interval closure="open" id="S2.E1X.2.1.1.m1.6.6.1.1.3.3.4.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.3.4.2"><ci id="S2.E1X.2.1.1.m1.3.3.cmml" xref="S2.E1X.2.1.1.m1.3.3">𝑞</ci><ci id="S2.E1X.2.1.1.m1.4.4.cmml" xref="S2.E1X.2.1.1.m1.4.4">𝑚</ci></interval></apply><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4"><times id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.1"></times><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.2">𝛾</ci><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3">superscript</csymbol><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.2">𝑠</ci><apply id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3"><times id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.1.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.1"></times><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.2.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.2">𝑖</ci><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.3.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.3">𝑚</ci><ci id="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.4.cmml" xref="S2.E1X.2.1.1.m1.6.6.1.1.3.4.3.3.4">𝑝</ci></apply></apply><ci id="S2.E1X.2.1.1.m1.5.5.cmml" xref="S2.E1X.2.1.1.m1.5.5">𝑚</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1X.2.1.1.m1.6c">\displaystyle m^{*}=\arg\min_{m\in M}\alpha s^{rec}(q,m)+\beta s^{rel}(q,m)+\gamma s^{imp}(m),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(1)</span></td>
</tr>
</tbody>
</table>
<p id="S2.SS1.SSS2.p12.16" class="ltx_p">where <math id="S2.SS1.SSS2.p12.2.m1.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S2.SS1.SSS2.p12.2.m1.1a"><mi id="S2.SS1.SSS2.p12.2.m1.1.1" xref="S2.SS1.SSS2.p12.2.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.2.m1.1b"><ci id="S2.SS1.SSS2.p12.2.m1.1.1.cmml" xref="S2.SS1.SSS2.p12.2.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.2.m1.1c">q</annotation></semantics></math> is the query, for example, the task that the agent should address or the context in which the agent is situated. <math id="S2.SS1.SSS2.p12.3.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.SS1.SSS2.p12.3.m2.1a"><mi id="S2.SS1.SSS2.p12.3.m2.1.1" xref="S2.SS1.SSS2.p12.3.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.3.m2.1b"><ci id="S2.SS1.SSS2.p12.3.m2.1.1.cmml" xref="S2.SS1.SSS2.p12.3.m2.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.3.m2.1c">M</annotation></semantics></math> is the set of all memories. <math id="S2.SS1.SSS2.p12.4.m3.1" class="ltx_Math" alttext="s^{rec}(\cdot)" display="inline"><semantics id="S2.SS1.SSS2.p12.4.m3.1a"><mrow id="S2.SS1.SSS2.p12.4.m3.1.2" xref="S2.SS1.SSS2.p12.4.m3.1.2.cmml"><msup id="S2.SS1.SSS2.p12.4.m3.1.2.2" xref="S2.SS1.SSS2.p12.4.m3.1.2.2.cmml"><mi id="S2.SS1.SSS2.p12.4.m3.1.2.2.2" xref="S2.SS1.SSS2.p12.4.m3.1.2.2.2.cmml">s</mi><mrow id="S2.SS1.SSS2.p12.4.m3.1.2.2.3" xref="S2.SS1.SSS2.p12.4.m3.1.2.2.3.cmml"><mi id="S2.SS1.SSS2.p12.4.m3.1.2.2.3.2" xref="S2.SS1.SSS2.p12.4.m3.1.2.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.4.m3.1.2.2.3.1" xref="S2.SS1.SSS2.p12.4.m3.1.2.2.3.1.cmml">​</mo><mi id="S2.SS1.SSS2.p12.4.m3.1.2.2.3.3" xref="S2.SS1.SSS2.p12.4.m3.1.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.4.m3.1.2.2.3.1a" xref="S2.SS1.SSS2.p12.4.m3.1.2.2.3.1.cmml">​</mo><mi id="S2.SS1.SSS2.p12.4.m3.1.2.2.3.4" xref="S2.SS1.SSS2.p12.4.m3.1.2.2.3.4.cmml">c</mi></mrow></msup><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.4.m3.1.2.1" xref="S2.SS1.SSS2.p12.4.m3.1.2.1.cmml">​</mo><mrow id="S2.SS1.SSS2.p12.4.m3.1.2.3.2" xref="S2.SS1.SSS2.p12.4.m3.1.2.cmml"><mo stretchy="false" id="S2.SS1.SSS2.p12.4.m3.1.2.3.2.1" xref="S2.SS1.SSS2.p12.4.m3.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.4.m3.1.1" xref="S2.SS1.SSS2.p12.4.m3.1.1.cmml">⋅</mo><mo stretchy="false" id="S2.SS1.SSS2.p12.4.m3.1.2.3.2.2" xref="S2.SS1.SSS2.p12.4.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.4.m3.1b"><apply id="S2.SS1.SSS2.p12.4.m3.1.2.cmml" xref="S2.SS1.SSS2.p12.4.m3.1.2"><times id="S2.SS1.SSS2.p12.4.m3.1.2.1.cmml" xref="S2.SS1.SSS2.p12.4.m3.1.2.1"></times><apply id="S2.SS1.SSS2.p12.4.m3.1.2.2.cmml" xref="S2.SS1.SSS2.p12.4.m3.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p12.4.m3.1.2.2.1.cmml" xref="S2.SS1.SSS2.p12.4.m3.1.2.2">superscript</csymbol><ci id="S2.SS1.SSS2.p12.4.m3.1.2.2.2.cmml" xref="S2.SS1.SSS2.p12.4.m3.1.2.2.2">𝑠</ci><apply id="S2.SS1.SSS2.p12.4.m3.1.2.2.3.cmml" xref="S2.SS1.SSS2.p12.4.m3.1.2.2.3"><times id="S2.SS1.SSS2.p12.4.m3.1.2.2.3.1.cmml" xref="S2.SS1.SSS2.p12.4.m3.1.2.2.3.1"></times><ci id="S2.SS1.SSS2.p12.4.m3.1.2.2.3.2.cmml" xref="S2.SS1.SSS2.p12.4.m3.1.2.2.3.2">𝑟</ci><ci id="S2.SS1.SSS2.p12.4.m3.1.2.2.3.3.cmml" xref="S2.SS1.SSS2.p12.4.m3.1.2.2.3.3">𝑒</ci><ci id="S2.SS1.SSS2.p12.4.m3.1.2.2.3.4.cmml" xref="S2.SS1.SSS2.p12.4.m3.1.2.2.3.4">𝑐</ci></apply></apply><ci id="S2.SS1.SSS2.p12.4.m3.1.1.cmml" xref="S2.SS1.SSS2.p12.4.m3.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.4.m3.1c">s^{rec}(\cdot)</annotation></semantics></math>, <math id="S2.SS1.SSS2.p12.5.m4.1" class="ltx_Math" alttext="s^{rel}(\cdot)" display="inline"><semantics id="S2.SS1.SSS2.p12.5.m4.1a"><mrow id="S2.SS1.SSS2.p12.5.m4.1.2" xref="S2.SS1.SSS2.p12.5.m4.1.2.cmml"><msup id="S2.SS1.SSS2.p12.5.m4.1.2.2" xref="S2.SS1.SSS2.p12.5.m4.1.2.2.cmml"><mi id="S2.SS1.SSS2.p12.5.m4.1.2.2.2" xref="S2.SS1.SSS2.p12.5.m4.1.2.2.2.cmml">s</mi><mrow id="S2.SS1.SSS2.p12.5.m4.1.2.2.3" xref="S2.SS1.SSS2.p12.5.m4.1.2.2.3.cmml"><mi id="S2.SS1.SSS2.p12.5.m4.1.2.2.3.2" xref="S2.SS1.SSS2.p12.5.m4.1.2.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.5.m4.1.2.2.3.1" xref="S2.SS1.SSS2.p12.5.m4.1.2.2.3.1.cmml">​</mo><mi id="S2.SS1.SSS2.p12.5.m4.1.2.2.3.3" xref="S2.SS1.SSS2.p12.5.m4.1.2.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.5.m4.1.2.2.3.1a" xref="S2.SS1.SSS2.p12.5.m4.1.2.2.3.1.cmml">​</mo><mi id="S2.SS1.SSS2.p12.5.m4.1.2.2.3.4" xref="S2.SS1.SSS2.p12.5.m4.1.2.2.3.4.cmml">l</mi></mrow></msup><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.5.m4.1.2.1" xref="S2.SS1.SSS2.p12.5.m4.1.2.1.cmml">​</mo><mrow id="S2.SS1.SSS2.p12.5.m4.1.2.3.2" xref="S2.SS1.SSS2.p12.5.m4.1.2.cmml"><mo stretchy="false" id="S2.SS1.SSS2.p12.5.m4.1.2.3.2.1" xref="S2.SS1.SSS2.p12.5.m4.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.5.m4.1.1" xref="S2.SS1.SSS2.p12.5.m4.1.1.cmml">⋅</mo><mo stretchy="false" id="S2.SS1.SSS2.p12.5.m4.1.2.3.2.2" xref="S2.SS1.SSS2.p12.5.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.5.m4.1b"><apply id="S2.SS1.SSS2.p12.5.m4.1.2.cmml" xref="S2.SS1.SSS2.p12.5.m4.1.2"><times id="S2.SS1.SSS2.p12.5.m4.1.2.1.cmml" xref="S2.SS1.SSS2.p12.5.m4.1.2.1"></times><apply id="S2.SS1.SSS2.p12.5.m4.1.2.2.cmml" xref="S2.SS1.SSS2.p12.5.m4.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p12.5.m4.1.2.2.1.cmml" xref="S2.SS1.SSS2.p12.5.m4.1.2.2">superscript</csymbol><ci id="S2.SS1.SSS2.p12.5.m4.1.2.2.2.cmml" xref="S2.SS1.SSS2.p12.5.m4.1.2.2.2">𝑠</ci><apply id="S2.SS1.SSS2.p12.5.m4.1.2.2.3.cmml" xref="S2.SS1.SSS2.p12.5.m4.1.2.2.3"><times id="S2.SS1.SSS2.p12.5.m4.1.2.2.3.1.cmml" xref="S2.SS1.SSS2.p12.5.m4.1.2.2.3.1"></times><ci id="S2.SS1.SSS2.p12.5.m4.1.2.2.3.2.cmml" xref="S2.SS1.SSS2.p12.5.m4.1.2.2.3.2">𝑟</ci><ci id="S2.SS1.SSS2.p12.5.m4.1.2.2.3.3.cmml" xref="S2.SS1.SSS2.p12.5.m4.1.2.2.3.3">𝑒</ci><ci id="S2.SS1.SSS2.p12.5.m4.1.2.2.3.4.cmml" xref="S2.SS1.SSS2.p12.5.m4.1.2.2.3.4">𝑙</ci></apply></apply><ci id="S2.SS1.SSS2.p12.5.m4.1.1.cmml" xref="S2.SS1.SSS2.p12.5.m4.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.5.m4.1c">s^{rel}(\cdot)</annotation></semantics></math> and <math id="S2.SS1.SSS2.p12.6.m5.1" class="ltx_Math" alttext="s^{imp}(\cdot)" display="inline"><semantics id="S2.SS1.SSS2.p12.6.m5.1a"><mrow id="S2.SS1.SSS2.p12.6.m5.1.2" xref="S2.SS1.SSS2.p12.6.m5.1.2.cmml"><msup id="S2.SS1.SSS2.p12.6.m5.1.2.2" xref="S2.SS1.SSS2.p12.6.m5.1.2.2.cmml"><mi id="S2.SS1.SSS2.p12.6.m5.1.2.2.2" xref="S2.SS1.SSS2.p12.6.m5.1.2.2.2.cmml">s</mi><mrow id="S2.SS1.SSS2.p12.6.m5.1.2.2.3" xref="S2.SS1.SSS2.p12.6.m5.1.2.2.3.cmml"><mi id="S2.SS1.SSS2.p12.6.m5.1.2.2.3.2" xref="S2.SS1.SSS2.p12.6.m5.1.2.2.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.6.m5.1.2.2.3.1" xref="S2.SS1.SSS2.p12.6.m5.1.2.2.3.1.cmml">​</mo><mi id="S2.SS1.SSS2.p12.6.m5.1.2.2.3.3" xref="S2.SS1.SSS2.p12.6.m5.1.2.2.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.6.m5.1.2.2.3.1a" xref="S2.SS1.SSS2.p12.6.m5.1.2.2.3.1.cmml">​</mo><mi id="S2.SS1.SSS2.p12.6.m5.1.2.2.3.4" xref="S2.SS1.SSS2.p12.6.m5.1.2.2.3.4.cmml">p</mi></mrow></msup><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.6.m5.1.2.1" xref="S2.SS1.SSS2.p12.6.m5.1.2.1.cmml">​</mo><mrow id="S2.SS1.SSS2.p12.6.m5.1.2.3.2" xref="S2.SS1.SSS2.p12.6.m5.1.2.cmml"><mo stretchy="false" id="S2.SS1.SSS2.p12.6.m5.1.2.3.2.1" xref="S2.SS1.SSS2.p12.6.m5.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.6.m5.1.1" xref="S2.SS1.SSS2.p12.6.m5.1.1.cmml">⋅</mo><mo stretchy="false" id="S2.SS1.SSS2.p12.6.m5.1.2.3.2.2" xref="S2.SS1.SSS2.p12.6.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.6.m5.1b"><apply id="S2.SS1.SSS2.p12.6.m5.1.2.cmml" xref="S2.SS1.SSS2.p12.6.m5.1.2"><times id="S2.SS1.SSS2.p12.6.m5.1.2.1.cmml" xref="S2.SS1.SSS2.p12.6.m5.1.2.1"></times><apply id="S2.SS1.SSS2.p12.6.m5.1.2.2.cmml" xref="S2.SS1.SSS2.p12.6.m5.1.2.2"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p12.6.m5.1.2.2.1.cmml" xref="S2.SS1.SSS2.p12.6.m5.1.2.2">superscript</csymbol><ci id="S2.SS1.SSS2.p12.6.m5.1.2.2.2.cmml" xref="S2.SS1.SSS2.p12.6.m5.1.2.2.2">𝑠</ci><apply id="S2.SS1.SSS2.p12.6.m5.1.2.2.3.cmml" xref="S2.SS1.SSS2.p12.6.m5.1.2.2.3"><times id="S2.SS1.SSS2.p12.6.m5.1.2.2.3.1.cmml" xref="S2.SS1.SSS2.p12.6.m5.1.2.2.3.1"></times><ci id="S2.SS1.SSS2.p12.6.m5.1.2.2.3.2.cmml" xref="S2.SS1.SSS2.p12.6.m5.1.2.2.3.2">𝑖</ci><ci id="S2.SS1.SSS2.p12.6.m5.1.2.2.3.3.cmml" xref="S2.SS1.SSS2.p12.6.m5.1.2.2.3.3">𝑚</ci><ci id="S2.SS1.SSS2.p12.6.m5.1.2.2.3.4.cmml" xref="S2.SS1.SSS2.p12.6.m5.1.2.2.3.4">𝑝</ci></apply></apply><ci id="S2.SS1.SSS2.p12.6.m5.1.1.cmml" xref="S2.SS1.SSS2.p12.6.m5.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.6.m5.1c">s^{imp}(\cdot)</annotation></semantics></math> are the scoring functions for measuring the recency, relevance, and importance of the memory <math id="S2.SS1.SSS2.p12.7.m6.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S2.SS1.SSS2.p12.7.m6.1a"><mi id="S2.SS1.SSS2.p12.7.m6.1.1" xref="S2.SS1.SSS2.p12.7.m6.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.7.m6.1b"><ci id="S2.SS1.SSS2.p12.7.m6.1.1.cmml" xref="S2.SS1.SSS2.p12.7.m6.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.7.m6.1c">m</annotation></semantics></math>. These scoring functions can be implemented using various methods, for example, <math id="S2.SS1.SSS2.p12.8.m7.2" class="ltx_Math" alttext="s^{rel}(q,m)" display="inline"><semantics id="S2.SS1.SSS2.p12.8.m7.2a"><mrow id="S2.SS1.SSS2.p12.8.m7.2.3" xref="S2.SS1.SSS2.p12.8.m7.2.3.cmml"><msup id="S2.SS1.SSS2.p12.8.m7.2.3.2" xref="S2.SS1.SSS2.p12.8.m7.2.3.2.cmml"><mi id="S2.SS1.SSS2.p12.8.m7.2.3.2.2" xref="S2.SS1.SSS2.p12.8.m7.2.3.2.2.cmml">s</mi><mrow id="S2.SS1.SSS2.p12.8.m7.2.3.2.3" xref="S2.SS1.SSS2.p12.8.m7.2.3.2.3.cmml"><mi id="S2.SS1.SSS2.p12.8.m7.2.3.2.3.2" xref="S2.SS1.SSS2.p12.8.m7.2.3.2.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.8.m7.2.3.2.3.1" xref="S2.SS1.SSS2.p12.8.m7.2.3.2.3.1.cmml">​</mo><mi id="S2.SS1.SSS2.p12.8.m7.2.3.2.3.3" xref="S2.SS1.SSS2.p12.8.m7.2.3.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.8.m7.2.3.2.3.1a" xref="S2.SS1.SSS2.p12.8.m7.2.3.2.3.1.cmml">​</mo><mi id="S2.SS1.SSS2.p12.8.m7.2.3.2.3.4" xref="S2.SS1.SSS2.p12.8.m7.2.3.2.3.4.cmml">l</mi></mrow></msup><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.8.m7.2.3.1" xref="S2.SS1.SSS2.p12.8.m7.2.3.1.cmml">​</mo><mrow id="S2.SS1.SSS2.p12.8.m7.2.3.3.2" xref="S2.SS1.SSS2.p12.8.m7.2.3.3.1.cmml"><mo stretchy="false" id="S2.SS1.SSS2.p12.8.m7.2.3.3.2.1" xref="S2.SS1.SSS2.p12.8.m7.2.3.3.1.cmml">(</mo><mi id="S2.SS1.SSS2.p12.8.m7.1.1" xref="S2.SS1.SSS2.p12.8.m7.1.1.cmml">q</mi><mo id="S2.SS1.SSS2.p12.8.m7.2.3.3.2.2" xref="S2.SS1.SSS2.p12.8.m7.2.3.3.1.cmml">,</mo><mi id="S2.SS1.SSS2.p12.8.m7.2.2" xref="S2.SS1.SSS2.p12.8.m7.2.2.cmml">m</mi><mo stretchy="false" id="S2.SS1.SSS2.p12.8.m7.2.3.3.2.3" xref="S2.SS1.SSS2.p12.8.m7.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.8.m7.2b"><apply id="S2.SS1.SSS2.p12.8.m7.2.3.cmml" xref="S2.SS1.SSS2.p12.8.m7.2.3"><times id="S2.SS1.SSS2.p12.8.m7.2.3.1.cmml" xref="S2.SS1.SSS2.p12.8.m7.2.3.1"></times><apply id="S2.SS1.SSS2.p12.8.m7.2.3.2.cmml" xref="S2.SS1.SSS2.p12.8.m7.2.3.2"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p12.8.m7.2.3.2.1.cmml" xref="S2.SS1.SSS2.p12.8.m7.2.3.2">superscript</csymbol><ci id="S2.SS1.SSS2.p12.8.m7.2.3.2.2.cmml" xref="S2.SS1.SSS2.p12.8.m7.2.3.2.2">𝑠</ci><apply id="S2.SS1.SSS2.p12.8.m7.2.3.2.3.cmml" xref="S2.SS1.SSS2.p12.8.m7.2.3.2.3"><times id="S2.SS1.SSS2.p12.8.m7.2.3.2.3.1.cmml" xref="S2.SS1.SSS2.p12.8.m7.2.3.2.3.1"></times><ci id="S2.SS1.SSS2.p12.8.m7.2.3.2.3.2.cmml" xref="S2.SS1.SSS2.p12.8.m7.2.3.2.3.2">𝑟</ci><ci id="S2.SS1.SSS2.p12.8.m7.2.3.2.3.3.cmml" xref="S2.SS1.SSS2.p12.8.m7.2.3.2.3.3">𝑒</ci><ci id="S2.SS1.SSS2.p12.8.m7.2.3.2.3.4.cmml" xref="S2.SS1.SSS2.p12.8.m7.2.3.2.3.4">𝑙</ci></apply></apply><interval closure="open" id="S2.SS1.SSS2.p12.8.m7.2.3.3.1.cmml" xref="S2.SS1.SSS2.p12.8.m7.2.3.3.2"><ci id="S2.SS1.SSS2.p12.8.m7.1.1.cmml" xref="S2.SS1.SSS2.p12.8.m7.1.1">𝑞</ci><ci id="S2.SS1.SSS2.p12.8.m7.2.2.cmml" xref="S2.SS1.SSS2.p12.8.m7.2.2">𝑚</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.8.m7.2c">s^{rel}(q,m)</annotation></semantics></math> can be realized based on LSH, ANNOY, HNSW, FAISS and so on<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_tag ltx_tag_note">†</span>https://lilianweng.github.io/posts/2023-06-23-agent/</span></span></span>. It should be noted that <math id="S2.SS1.SSS2.p12.9.m8.1" class="ltx_Math" alttext="s^{imp}" display="inline"><semantics id="S2.SS1.SSS2.p12.9.m8.1a"><msup id="S2.SS1.SSS2.p12.9.m8.1.1" xref="S2.SS1.SSS2.p12.9.m8.1.1.cmml"><mi id="S2.SS1.SSS2.p12.9.m8.1.1.2" xref="S2.SS1.SSS2.p12.9.m8.1.1.2.cmml">s</mi><mrow id="S2.SS1.SSS2.p12.9.m8.1.1.3" xref="S2.SS1.SSS2.p12.9.m8.1.1.3.cmml"><mi id="S2.SS1.SSS2.p12.9.m8.1.1.3.2" xref="S2.SS1.SSS2.p12.9.m8.1.1.3.2.cmml">i</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.9.m8.1.1.3.1" xref="S2.SS1.SSS2.p12.9.m8.1.1.3.1.cmml">​</mo><mi id="S2.SS1.SSS2.p12.9.m8.1.1.3.3" xref="S2.SS1.SSS2.p12.9.m8.1.1.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.9.m8.1.1.3.1a" xref="S2.SS1.SSS2.p12.9.m8.1.1.3.1.cmml">​</mo><mi id="S2.SS1.SSS2.p12.9.m8.1.1.3.4" xref="S2.SS1.SSS2.p12.9.m8.1.1.3.4.cmml">p</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.9.m8.1b"><apply id="S2.SS1.SSS2.p12.9.m8.1.1.cmml" xref="S2.SS1.SSS2.p12.9.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p12.9.m8.1.1.1.cmml" xref="S2.SS1.SSS2.p12.9.m8.1.1">superscript</csymbol><ci id="S2.SS1.SSS2.p12.9.m8.1.1.2.cmml" xref="S2.SS1.SSS2.p12.9.m8.1.1.2">𝑠</ci><apply id="S2.SS1.SSS2.p12.9.m8.1.1.3.cmml" xref="S2.SS1.SSS2.p12.9.m8.1.1.3"><times id="S2.SS1.SSS2.p12.9.m8.1.1.3.1.cmml" xref="S2.SS1.SSS2.p12.9.m8.1.1.3.1"></times><ci id="S2.SS1.SSS2.p12.9.m8.1.1.3.2.cmml" xref="S2.SS1.SSS2.p12.9.m8.1.1.3.2">𝑖</ci><ci id="S2.SS1.SSS2.p12.9.m8.1.1.3.3.cmml" xref="S2.SS1.SSS2.p12.9.m8.1.1.3.3">𝑚</ci><ci id="S2.SS1.SSS2.p12.9.m8.1.1.3.4.cmml" xref="S2.SS1.SSS2.p12.9.m8.1.1.3.4">𝑝</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.9.m8.1c">s^{imp}</annotation></semantics></math> only reflects the characters of the memory itself, thus it is unrelated to the query <math id="S2.SS1.SSS2.p12.10.m9.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S2.SS1.SSS2.p12.10.m9.1a"><mi id="S2.SS1.SSS2.p12.10.m9.1.1" xref="S2.SS1.SSS2.p12.10.m9.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.10.m9.1b"><ci id="S2.SS1.SSS2.p12.10.m9.1.1.cmml" xref="S2.SS1.SSS2.p12.10.m9.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.10.m9.1c">q</annotation></semantics></math>. <math id="S2.SS1.SSS2.p12.11.m10.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.SS1.SSS2.p12.11.m10.1a"><mi id="S2.SS1.SSS2.p12.11.m10.1.1" xref="S2.SS1.SSS2.p12.11.m10.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.11.m10.1b"><ci id="S2.SS1.SSS2.p12.11.m10.1.1.cmml" xref="S2.SS1.SSS2.p12.11.m10.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.11.m10.1c">\alpha</annotation></semantics></math>, <math id="S2.SS1.SSS2.p12.12.m11.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S2.SS1.SSS2.p12.12.m11.1a"><mi id="S2.SS1.SSS2.p12.12.m11.1.1" xref="S2.SS1.SSS2.p12.12.m11.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.12.m11.1b"><ci id="S2.SS1.SSS2.p12.12.m11.1.1.cmml" xref="S2.SS1.SSS2.p12.12.m11.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.12.m11.1c">\beta</annotation></semantics></math> and <math id="S2.SS1.SSS2.p12.13.m12.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S2.SS1.SSS2.p12.13.m12.1a"><mi id="S2.SS1.SSS2.p12.13.m12.1.1" xref="S2.SS1.SSS2.p12.13.m12.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.13.m12.1b"><ci id="S2.SS1.SSS2.p12.13.m12.1.1.cmml" xref="S2.SS1.SSS2.p12.13.m12.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.13.m12.1c">\gamma</annotation></semantics></math> are balancing parameters. By assigning them with different values, one can obtain various memory reading strategies. For example, by setting <math id="S2.SS1.SSS2.p12.14.m13.1" class="ltx_Math" alttext="\alpha=\gamma=0" display="inline"><semantics id="S2.SS1.SSS2.p12.14.m13.1a"><mrow id="S2.SS1.SSS2.p12.14.m13.1.1" xref="S2.SS1.SSS2.p12.14.m13.1.1.cmml"><mi id="S2.SS1.SSS2.p12.14.m13.1.1.2" xref="S2.SS1.SSS2.p12.14.m13.1.1.2.cmml">α</mi><mo id="S2.SS1.SSS2.p12.14.m13.1.1.3" xref="S2.SS1.SSS2.p12.14.m13.1.1.3.cmml">=</mo><mi id="S2.SS1.SSS2.p12.14.m13.1.1.4" xref="S2.SS1.SSS2.p12.14.m13.1.1.4.cmml">γ</mi><mo id="S2.SS1.SSS2.p12.14.m13.1.1.5" xref="S2.SS1.SSS2.p12.14.m13.1.1.5.cmml">=</mo><mn id="S2.SS1.SSS2.p12.14.m13.1.1.6" xref="S2.SS1.SSS2.p12.14.m13.1.1.6.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.14.m13.1b"><apply id="S2.SS1.SSS2.p12.14.m13.1.1.cmml" xref="S2.SS1.SSS2.p12.14.m13.1.1"><and id="S2.SS1.SSS2.p12.14.m13.1.1a.cmml" xref="S2.SS1.SSS2.p12.14.m13.1.1"></and><apply id="S2.SS1.SSS2.p12.14.m13.1.1b.cmml" xref="S2.SS1.SSS2.p12.14.m13.1.1"><eq id="S2.SS1.SSS2.p12.14.m13.1.1.3.cmml" xref="S2.SS1.SSS2.p12.14.m13.1.1.3"></eq><ci id="S2.SS1.SSS2.p12.14.m13.1.1.2.cmml" xref="S2.SS1.SSS2.p12.14.m13.1.1.2">𝛼</ci><ci id="S2.SS1.SSS2.p12.14.m13.1.1.4.cmml" xref="S2.SS1.SSS2.p12.14.m13.1.1.4">𝛾</ci></apply><apply id="S2.SS1.SSS2.p12.14.m13.1.1c.cmml" xref="S2.SS1.SSS2.p12.14.m13.1.1"><eq id="S2.SS1.SSS2.p12.14.m13.1.1.5.cmml" xref="S2.SS1.SSS2.p12.14.m13.1.1.5"></eq><share href="#S2.SS1.SSS2.p12.14.m13.1.1.4.cmml" id="S2.SS1.SSS2.p12.14.m13.1.1d.cmml" xref="S2.SS1.SSS2.p12.14.m13.1.1"></share><cn type="integer" id="S2.SS1.SSS2.p12.14.m13.1.1.6.cmml" xref="S2.SS1.SSS2.p12.14.m13.1.1.6">0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.14.m13.1c">\alpha=\gamma=0</annotation></semantics></math>, many studies&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>, <a href="#bib.bib184" title="" class="ltx_ref">184</a>, <a href="#bib.bib148" title="" class="ltx_ref">148</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> only consider the relevance score <math id="S2.SS1.SSS2.p12.15.m14.1" class="ltx_Math" alttext="s^{rel}" display="inline"><semantics id="S2.SS1.SSS2.p12.15.m14.1a"><msup id="S2.SS1.SSS2.p12.15.m14.1.1" xref="S2.SS1.SSS2.p12.15.m14.1.1.cmml"><mi id="S2.SS1.SSS2.p12.15.m14.1.1.2" xref="S2.SS1.SSS2.p12.15.m14.1.1.2.cmml">s</mi><mrow id="S2.SS1.SSS2.p12.15.m14.1.1.3" xref="S2.SS1.SSS2.p12.15.m14.1.1.3.cmml"><mi id="S2.SS1.SSS2.p12.15.m14.1.1.3.2" xref="S2.SS1.SSS2.p12.15.m14.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.15.m14.1.1.3.1" xref="S2.SS1.SSS2.p12.15.m14.1.1.3.1.cmml">​</mo><mi id="S2.SS1.SSS2.p12.15.m14.1.1.3.3" xref="S2.SS1.SSS2.p12.15.m14.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.SS1.SSS2.p12.15.m14.1.1.3.1a" xref="S2.SS1.SSS2.p12.15.m14.1.1.3.1.cmml">​</mo><mi id="S2.SS1.SSS2.p12.15.m14.1.1.3.4" xref="S2.SS1.SSS2.p12.15.m14.1.1.3.4.cmml">l</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.15.m14.1b"><apply id="S2.SS1.SSS2.p12.15.m14.1.1.cmml" xref="S2.SS1.SSS2.p12.15.m14.1.1"><csymbol cd="ambiguous" id="S2.SS1.SSS2.p12.15.m14.1.1.1.cmml" xref="S2.SS1.SSS2.p12.15.m14.1.1">superscript</csymbol><ci id="S2.SS1.SSS2.p12.15.m14.1.1.2.cmml" xref="S2.SS1.SSS2.p12.15.m14.1.1.2">𝑠</ci><apply id="S2.SS1.SSS2.p12.15.m14.1.1.3.cmml" xref="S2.SS1.SSS2.p12.15.m14.1.1.3"><times id="S2.SS1.SSS2.p12.15.m14.1.1.3.1.cmml" xref="S2.SS1.SSS2.p12.15.m14.1.1.3.1"></times><ci id="S2.SS1.SSS2.p12.15.m14.1.1.3.2.cmml" xref="S2.SS1.SSS2.p12.15.m14.1.1.3.2">𝑟</ci><ci id="S2.SS1.SSS2.p12.15.m14.1.1.3.3.cmml" xref="S2.SS1.SSS2.p12.15.m14.1.1.3.3">𝑒</ci><ci id="S2.SS1.SSS2.p12.15.m14.1.1.3.4.cmml" xref="S2.SS1.SSS2.p12.15.m14.1.1.3.4">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.15.m14.1c">s^{rel}</annotation></semantics></math> for memory reading. By assigning <math id="S2.SS1.SSS2.p12.16.m15.1" class="ltx_Math" alttext="\alpha=\beta=\gamma=1.0" display="inline"><semantics id="S2.SS1.SSS2.p12.16.m15.1a"><mrow id="S2.SS1.SSS2.p12.16.m15.1.1" xref="S2.SS1.SSS2.p12.16.m15.1.1.cmml"><mi id="S2.SS1.SSS2.p12.16.m15.1.1.2" xref="S2.SS1.SSS2.p12.16.m15.1.1.2.cmml">α</mi><mo id="S2.SS1.SSS2.p12.16.m15.1.1.3" xref="S2.SS1.SSS2.p12.16.m15.1.1.3.cmml">=</mo><mi id="S2.SS1.SSS2.p12.16.m15.1.1.4" xref="S2.SS1.SSS2.p12.16.m15.1.1.4.cmml">β</mi><mo id="S2.SS1.SSS2.p12.16.m15.1.1.5" xref="S2.SS1.SSS2.p12.16.m15.1.1.5.cmml">=</mo><mi id="S2.SS1.SSS2.p12.16.m15.1.1.6" xref="S2.SS1.SSS2.p12.16.m15.1.1.6.cmml">γ</mi><mo id="S2.SS1.SSS2.p12.16.m15.1.1.7" xref="S2.SS1.SSS2.p12.16.m15.1.1.7.cmml">=</mo><mn id="S2.SS1.SSS2.p12.16.m15.1.1.8" xref="S2.SS1.SSS2.p12.16.m15.1.1.8.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p12.16.m15.1b"><apply id="S2.SS1.SSS2.p12.16.m15.1.1.cmml" xref="S2.SS1.SSS2.p12.16.m15.1.1"><and id="S2.SS1.SSS2.p12.16.m15.1.1a.cmml" xref="S2.SS1.SSS2.p12.16.m15.1.1"></and><apply id="S2.SS1.SSS2.p12.16.m15.1.1b.cmml" xref="S2.SS1.SSS2.p12.16.m15.1.1"><eq id="S2.SS1.SSS2.p12.16.m15.1.1.3.cmml" xref="S2.SS1.SSS2.p12.16.m15.1.1.3"></eq><ci id="S2.SS1.SSS2.p12.16.m15.1.1.2.cmml" xref="S2.SS1.SSS2.p12.16.m15.1.1.2">𝛼</ci><ci id="S2.SS1.SSS2.p12.16.m15.1.1.4.cmml" xref="S2.SS1.SSS2.p12.16.m15.1.1.4">𝛽</ci></apply><apply id="S2.SS1.SSS2.p12.16.m15.1.1c.cmml" xref="S2.SS1.SSS2.p12.16.m15.1.1"><eq id="S2.SS1.SSS2.p12.16.m15.1.1.5.cmml" xref="S2.SS1.SSS2.p12.16.m15.1.1.5"></eq><share href="#S2.SS1.SSS2.p12.16.m15.1.1.4.cmml" id="S2.SS1.SSS2.p12.16.m15.1.1d.cmml" xref="S2.SS1.SSS2.p12.16.m15.1.1"></share><ci id="S2.SS1.SSS2.p12.16.m15.1.1.6.cmml" xref="S2.SS1.SSS2.p12.16.m15.1.1.6">𝛾</ci></apply><apply id="S2.SS1.SSS2.p12.16.m15.1.1e.cmml" xref="S2.SS1.SSS2.p12.16.m15.1.1"><eq id="S2.SS1.SSS2.p12.16.m15.1.1.7.cmml" xref="S2.SS1.SSS2.p12.16.m15.1.1.7"></eq><share href="#S2.SS1.SSS2.p12.16.m15.1.1.6.cmml" id="S2.SS1.SSS2.p12.16.m15.1.1f.cmml" xref="S2.SS1.SSS2.p12.16.m15.1.1"></share><cn type="float" id="S2.SS1.SSS2.p12.16.m15.1.1.8.cmml" xref="S2.SS1.SSS2.p12.16.m15.1.1.8">1.0</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p12.16.m15.1c">\alpha=\beta=\gamma=1.0</annotation></semantics></math>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite> equally weights all the above three metrics to extract information from the memory.</p>
</div>
<div id="S2.SS1.SSS2.p13" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p13.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS2.p13.1.m1.1"><semantics id="S2.SS1.SSS2.p13.1.m1.1a"><mo id="S2.SS1.SSS2.p13.1.m1.1.1" xref="S2.SS1.SSS2.p13.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p13.1.m1.1b"><ci id="S2.SS1.SSS2.p13.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p13.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p13.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS2.p13.1.1">Memory Writing</span>. 메모리 쓰기의 목적은 인지된 환경에 대한 정보를 메모리에 저장하는 것이다. 가치 있는 정보를 메모리에 저장하는 것은 미래에 유익한 기억을 검색할 수 있는 기반을 제공하여 에이전트가 보다 효율적이고 합리적으로 행동할 수 있게 한다. 메모리 쓰기 과정에서 주의 깊게 다루어야 할 두 가지 잠재적인 문제가 있다. 한편, 기존 메모리와 유사한 정보를 저장하는 방법을 다루는 것은 중요하다(<em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS2.p13.1.2">i.e.</em>, memory duplicated). 한편, 메모리가 저장 한계에 도달했을 때 정보를 제거하는 방법을 고려하는 것이 중요하다(<em class="ltx_emph ltx_font_italic" id="S2.SS1.SSS2.p13.1.3">i.e.</em>, memory overflow). 이하에서는 이러한 문제점에 대해 보다 구체적으로 논의하고자 한다. (1) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS2.p13.1.4">Memory Duplicated</span>. 유사한 정보를 통합하기 위해 사람들은 새로운 기록과 이전 기록을 통합하는 다양한 방법을 개발했다. 예를 들어, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib120" title="">120</a>]</cite>에서는 동일한 하위 목표와 관련된 성공적인 액션 시퀀스들이 리스트에 저장된다. 목록의 크기가 N(=5)에 도달하면, 목록의 모든 시퀀스는 LLM을 사용하여 통합된 계획 솔루션으로 응축된다. 메모리의 원래 시퀀스는 새로 생성된 시퀀스로 대체된다. Augmented LLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib135" title="">135</a>]</cite>는 중복 저장을 피하면서 카운트 누적을 통해 중복 정보를 집계한다. (2) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS2.p13.1.5">Memory Overflow</span>. 정보가 가득 찰 때 메모리에 기록하기 위해 사람들은 기존의 정보를 삭제하는 방법을 다르게 설계하여 암기 과정을 계속한다. 예를 들어, ChatDB<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>에서는 사용자 명령에 기초하여 메모리들을 명시적으로 삭제할 수 있다. RET-LLM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib114" title="">114</a>]</cite>는 FIFO(first-in-first-out) 방식으로 가장 오래된 엔트리를 덮어쓰는 메모리용 고정 크기 버퍼를 사용한다.</p>
</div>
<div id="S2.SS1.SSS2.p14" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p14.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS2.p14.1.m1.1"><semantics id="S2.SS1.SSS2.p14.1.m1.1a"><mo id="S2.SS1.SSS2.p14.1.m1.1.1" xref="S2.SS1.SSS2.p14.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS2.p14.1.m1.1b"><ci id="S2.SS1.SSS2.p14.1.m1.1.1.cmml" xref="S2.SS1.SSS2.p14.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS2.p14.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS2.p14.1.1">Memory Reflection</span>. 기억 성찰은 인간이 자신의 인지적, 정서적, 행동적 과정을 목격하고 평가하는 능력을 모방한다. 에이전트에 적응할 때 목표는 에이전트에게 보다 추상적이고 복잡하며 높은 수준의 정보를 독립적으로 요약하고 추론할 수 있는 능력을 제공하는 것이다. 보다 구체적으로, 생성 에이전트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib121" title="">121</a>]</cite>에서 에이전트는 메모리에 저장된 자신의 과거 경험을 보다 광범위하고 추상적인 통찰력으로 요약할 수 있는 능력을 가지고 있다. 먼저 에이전트는 최근 기억을 기반으로 세 가지 핵심 질문을 생성합니다. 그런 다음 이러한 질문은 관련 정보를 얻기 위해 메모리를 쿼리하는 데 사용됩니다. 획득된 정보를 기반으로 에이전트는 에이전트 수준의 아이디어를 반영하는 5가지 통찰력을 생성한다. 예를 들어, 낮은 수준의 기억들 "클라우스 뮬러는 연구 논문을 쓰고 있다", "클라우스 뮬러는 그의 연구를 더 발전시키기 위해 사서와 교제하고 있다", "클라우스 뮬러는 그의 연구에 대해 아예샤 칸과 대화하고 있다"는 것은 "클라우스 뮬러는 그의 연구에 전념하고 있다"라는 높은 수준의 통찰을 유도할 수 있다. 또한, 성찰 과정은 계층적으로 일어날 수 있으며, 이는 기존의 인사이트를 기반으로 인사이트를 생성할 수 있음을 의미한다. GITM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite>에서 하위 목표를 성공적으로 달성한 액션은 목록에 저장됩니다. 목록에 5개 이상의 요소가 포함된 경우 에이전트는 공통적이고 추상적인 패턴으로 요약하고 모든 요소를 대체합니다. ExpeL<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib177" title="">177</a>]</cite>에서는 에이전트가 반사를 획득하기 위한 두 가지 접근 방식을 소개한다. 첫째, 에이전트는 동일한 작업 내에서 성공적인 궤적과 실패한 궤적을 비교한다. 둘째, 에이전트는 경험을 얻기 위해 성공적인 궤적 모음에서 학습한다.</p>
</div>
<div id="S2.SS1.SSS2.p15" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS2.p15.1">전통적인 LLM과 에이전트의 중요한 차이점은 후자는 동적 환경에서 작업을 학습하고 완료할 수 있는 능력을 보유해야 한다는 것이다. 우리가 메모리 모듈을 에이전트의 과거 행동을 관리하는 책임자로 간주한다면, 에이전트가 미래의 행동을 계획하는 데 도움을 줄 수 있는 또 다른 중요한 모듈을 갖는 것이 필수적이다. 이하에서는 연구자들이 계획 모듈을 어떻게 설계하는지에 대한 개요를 제시한다.</p>
</div>
</section>
<section id="S2.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.3 </span>Planning Module</h4>

<div id="S2.SS1.SSS3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS3.p1.1">복잡한 과제에 직면했을 때 인간은 그것을 더 단순한 하위 과제로 해체하고 개별적으로 해결하는 경향이 있다. 계획 모듈은 이러한 인간 능력을 가진 에이전트에게 권한을 부여하는 것을 목표로 하며, 이는 에이전트가 보다 합리적이고, 강력하며, 신뢰성 있게 행동하도록 할 것으로 예상된다. 특히 기획 과정에서 에이전트가 피드백을 받을 수 있는지 여부를 기준으로 기존 연구들을 정리하면 다음과 같다.</p>
</div>
<div id="S2.SS1.SSS3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS3.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS3.p2.1.1">Planning without Feedback</span>: 이 메서드에서 에이전트는 액션을 취한 후 자신의 미래 행동에 영향을 줄 수 있는 피드백을 받지 않습니다. 다음에서는 몇 가지 대표적인 전략을 제시한다.</p>
</div>
<div id="S2.SS1.SSS3.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS3.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS3.p3.1.m1.1"><semantics id="S2.SS1.SSS3.p3.1.m1.1a"><mo id="S2.SS1.SSS3.p3.1.m1.1.1" xref="S2.SS1.SSS3.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS3.p3.1.m1.1b"><ci id="S2.SS1.SSS3.p3.1.m1.1.1.cmml" xref="S2.SS1.SSS3.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS3.p3.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS3.p3.1.1">Single-path Reasoning</span>. 이 전략에서 최종 과제는 여러 중간 단계로 분해된다. 이들 단계들은 캐스케이딩 방식으로 연결되며, 각각의 단계는 단지 하나의 후속 단계로 이어진다. LLM은 최종 목표를 달성하기 위해 이러한 단계를 따른다. 구체적으로, CoT(Chain of Thought) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib155" title="">155</a>]</cite>는 복잡한 문제를 해결하기 위한 추론 단계를 프롬프트에 입력하는 것을 제안한다. 이러한 단계는 LLM이 단계적으로 계획하고 행동하도록 영감을 주는 예로서 작용한다. 이 방법에서는 프롬프트의 예제에서 영감을 바탕으로 계획을 작성합니다. Zero-shot-CoT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>를 사용하면 LLMs가 "단계별 생각"과 같은 트리거 문장으로 프롬프트하여 태스크 추론 프로세스를 생성할 수 있다. CoT와 달리 이 방법은 프롬프트에서 추론 단계를 예로 포함하지 않는다. Re-Prompting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib128" title="">128</a>]</cite>는 계획을 생성하기 전에 각 단계가 필요한 필수 조건을 충족하는지 확인하는 것을 포함한다. 단계가 전제 조건을 충족하지 못할 경우 전제 조건 오류 메시지를 도입하고 LLM에 계획을 다시 생성하라는 메시지를 표시합니다. ReWOO<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib164" title="">164</a>]</cite>는 외부 관측치로부터 계획을 분리하는 패러다임을 도입하는데, 에이전트는 먼저 계획을 생성하고 관측치를 독립적으로 얻은 다음 이를 함께 결합하여 최종 결과를 도출한다. HuggingGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite>는 먼저 작업을 많은 하위 목표로 분해한 후 Huggingface를 기반으로 각각을 해결한다. 모든 추론 단계를 원샷 방식으로 수행하는 CoT 및 Zero-shot-CoT와 달리 ReWOO 및 HuggingGPT는 LLMs에 재귀적으로 다중 시간을 액세스하여 결과를 생성한다.</p>
</div>
<div id="S2.SS1.SSS3.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS3.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS3.p4.1.m1.1"><semantics id="S2.SS1.SSS3.p4.1.m1.1a"><mo id="S2.SS1.SSS3.p4.1.m1.1.1" xref="S2.SS1.SSS3.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS3.p4.1.m1.1b"><ci id="S2.SS1.SSS3.p4.1.m1.1.1.cmml" xref="S2.SS1.SSS3.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS3.p4.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS3.p4.1.1">Multi-path Reasoning</span>. 이 전략에서는 최종 계획을 생성하기 위한 추론 단계를 나무와 같은 구조로 구성한다. 각각의 중간 단계는 다수의 후속 단계를 가질 수 있다. 이 접근법은 개인이 각 추론 단계에서 여러 가지 선택을 할 수 있기 때문에 인간의 사고와 유사하다. 특히 Self-consistent CoT (CoT-SC) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib151" title="">151</a>]</cite>는 각각의 복잡한 문제가 최종 답을 추론하는 여러 가지 사고 방식을 가지고 있다고 본다. 따라서 다양한 추론 경로 및 대응 답변을 생성하기 위해 CoT를 사용하는 것으로 시작한다. 이어서, 빈도수가 가장 높은 답변이 최종 출력으로 선택된다. Tree of Thoughts (ToT) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib169" title="">169</a>]</cite>는 Tree-like reasoning 구조를 사용하여 계획을 생성하도록 설계되었다. 이 접근법에서, 트리 내의 각각의 노드는 "사고"를 나타내며, 이는 중간 추론 단계에 대응한다. 이러한 중간 단계의 선택은 LLM들의 평가에 기초한다. 최종 계획은 너비 우선 탐색(BFS) 또는 깊이 우선 탐색(DFS) 전략을 사용하여 생성됩니다. 모든 계획 단계를 함께 생성하는 CoT-SC와 비교하여 ToT는 각 추론 단계에 대해 LLM을 쿼리해야 한다. RecMind<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib152" title="">152</a>]</cite>에서 저자들은 계획 과정에서 버려진 이력 정보를 활용하여 새로운 추론 단계를 도출하는 자기 성찰 메커니즘을 설계했다. GoT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>]</cite>에서 저자는 ToT의 트리형 추론 구조를 그래프 구조로 확장하여 보다 강력한 프롬프트 전략을 도출한다. AoT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib137" title="">137</a>]</cite>에서 저자들은 프롬프트에 알고리즘 예제를 통합하여 LLM의 추론 과정을 향상시키는 새로운 방법을 설계한다. 놀랍게도 이 방법은 LLM을 한 번 또는 몇 번만 쿼리하면 된다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib70" title="">70</a>]</cite>에서 LLM은 제로 샷 플래너로 활용됩니다. 각 계획 단계에서, 그들은 먼저 여러 개의 가능한 다음 단계를 생성한 다음 허용 가능한 행동까지의 거리를 기반으로 최종 단계를 결정한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib58" title="">58</a>]</cite>는 프롬프트에 쿼리와 유사한 예제를 포함시킴으로써 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib70" title="">70</a>]</cite>를 더욱 향상시킨다. RAP<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib62" title="">62</a>]</cite>는 몬테카를로 트리 검색(MCTS)을 기반으로 다양한 계획의 잠재적 이점을 시뮬레이션하기 위해 세계 모델을 구축한 다음 여러 MCTS 반복을 집계하여 최종 계획을 생성한다. 이해력 향상을 위해 그림 <a class="ltx_ref" href="#S2.F3" title="Figure 3 ‣ 2.1.3 Planning Module ‣ 2.1 Agent Architecture Design ‣ 2 LLM-based Autonomous Agent Construction ‣ A Survey on Large Language Model based Autonomous Agents"><span class="ltx_text ltx_ref_tag">3</span></a>에서 단일 경로 추론과 다중 경로 추론의 전략을 비교하는 예시를 제공한다.</p>
</div>
<figure id="S2.F3" class="ltx_figure">
<p id="S2.F3.1" class="ltx_p ltx_align_center"><span id="S2.F3.1.1" class="ltx_text ltx_framed ltx_framed_rectangle" style="border-color: #000000;padding:0.0pt;">
<img src="https://ar5iv.labs.arxiv.org/html/2308.11432/assets/x3.png" id="S2.F3.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="164" alt="Refer to caption">
</span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 3:</span>단일 경로와 다중 경로 추론의 전략 간의 비교. LMZSP는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib70" title="">70</a>]</cite>에서 제안된 모델을 나타낸다.</figcaption>
</figure>
<div id="S2.SS1.SSS3.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS3.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS3.p5.1.m1.1"><semantics id="S2.SS1.SSS3.p5.1.m1.1a"><mo id="S2.SS1.SSS3.p5.1.m1.1.1" xref="S2.SS1.SSS3.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS3.p5.1.m1.1b"><ci id="S2.SS1.SSS3.p5.1.m1.1.1.cmml" xref="S2.SS1.SSS3.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS3.p5.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS3.p5.1.1">External Planner</span>. 제로 샷 계획에서 LLM의 입증된 힘에도 불구하고 도메인별 문제에 대한 계획을 효과적으로 생성하는 것은 여전히 매우 어렵다. 이 문제를 해결하기 위해 연구원들은 외부 기획자로 눈을 돌립니다. 이러한 도구는 잘 개발되었으며 정확한 또는 최적의 계획을 신속하게 식별하기 위해 효율적인 검색 알고리즘을 사용한다. 특히 LLM+P<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib100" title="">100</a>]</cite>는 먼저 태스크 디스크립션을 정형화된 PDDL(Planning Domain Definition Languages)로 변환한 후 외부 플래너를 사용하여 PDDL을 처리한다. 최종적으로 생성된 결과는 LLMs에 의해 자연어로 다시 변환된다. 마찬가지로 LLM-DP<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite>는 LLM을 활용하여 관측치, 현재 세계 상태 및 목표 목표를 PDDL로 변환합니다. 이어서, 이 변환된 데이터는 외부 플래너로 전달되고, 이는 최종 액션 시퀀스를 효율적으로 결정한다. CO-LLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib176" title="">176</a>]</cite>는 LLMs가 높은 수준의 계획을 생성하는데 능하지만 낮은 수준의 제어에는 어려움을 겪는다는 것을 보여준다. 이러한 한계를 해결하기 위해 휴리스틱하게 설계된 외부 하위 레벨 플래너를 사용하여 상위 레벨 플랜에 기반한 액션을 효과적으로 실행합니다.</p>
</div>
<div id="S2.SS1.SSS3.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS3.p6.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS3.p6.1.1">Planning with Feedback</span>: In many real-world scenarios, the agent need to make long-horizon planning to solve complex tasks. 이러한 과제를 직면할 때 피드백이 없는 위의 계획 모듈은 다음과 같은 이유로 인해 덜 효과적일 수 있다: 첫째, 처음부터 무결한 계획을 직접 생성하는 것은 다양한 복잡한 전제 조건을 고려해야 하기 때문에 매우 어렵다. 결과적으로, 단순히 초기 계획을 따르는 것은 실패로 이어지는 경우가 많다. 더욱이, 계획의 실행은 예측 불가능한 전이 역학에 의해 방해되어 초기 계획을 실행 불가능하게 할 수 있다. 동시에 인간이 복잡한 작업을 어떻게 처리하는지 조사할 때, 우리는 개인이 외부 피드백을 기반으로 계획을 반복적으로 만들고 수정할 수 있음을 발견한다. 이러한 인간 능력을 시뮬레이션하기 위해 연구자들은 에이전트가 조치를 취한 후 피드백을 받을 수 있는 많은 계획 모듈을 설계했다. 피드백은 환경, 인간 및 모델에서 얻을 수 있으며 다음에서 자세히 설명한다.</p>
</div>
<div id="S2.SS1.SSS3.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS3.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS3.p7.1.m1.1"><semantics id="S2.SS1.SSS3.p7.1.m1.1a"><mo id="S2.SS1.SSS3.p7.1.m1.1.1" xref="S2.SS1.SSS3.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS3.p7.1.m1.1b"><ci id="S2.SS1.SSS3.p7.1.m1.1.1.cmml" xref="S2.SS1.SSS3.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS3.p7.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS3.p7.1.1">Environmental Feedback</span>. 이 피드백은 객관적인 세계 또는 가상 환경으로부터 얻어진다. 예를 들어, 그것은 게임의 작업 완료 신호 또는 에이전트가 액션을 취한 후에 이루어진 관찰일 수 있다. 특히 ReAct<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib170" title="">170</a>]</cite>는 thought-act-observation triplets를 이용하여 프롬프트를 구성하는 것을 제안한다. 사고 구성요소는 에이전트 행동을 안내하기 위한 높은 수준의 추론과 계획을 용이하게 하는 것을 목표로 한다. 그 행위는 대리인이 취한 특정한 행위를 나타낸다. 관찰은 검색 엔진 결과와 같은 외부 피드백을 통해 획득한 액션의 결과에 해당한다. 다음 생각은 이전 관찰에 의해 영향을 받으며, 이는 생성된 계획을 환경에 더 적응적으로 만든다. 보이저<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>는 프로그램 실행의 중간 진행, 실행 오류 및 자체 검증 결과를 포함한 세 가지 유형의 환경 피드백을 통합하여 계획을 수립한다. 이러한 신호는 에이전트가 다음 작업을 위한 더 나은 계획을 세우는 데 도움이 될 수 있습니다. Voyager와 유사하게, Ghost<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite>도 피드백을 추론 및 액션 취하기 과정에 통합한다. 이 피드백은 실행된 각 액션에 대한 성공 및 실패 정보뿐만 아니라 환경 상태를 포함한다. SayPlan<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib129" title="">129</a>]</cite>는 장면 그래프 시뮬레이터에서 도출된 환경 피드백을 활용하여 전략 공식을 검증하고 정제한다. 이 시뮬레이터는 실행 가능한 계획이 확인될 때까지 세이플랜의 전략 반복 재보정을 촉진하여 에이전트 액션에 따른 결과 및 상태 전환을 식별하는 데 능숙하다. DEPS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib154" title="">154</a>]</cite>에서 저자들은 작업 완료에 대한 정보 제공만으로는 계획 오류를 수정하는 데 부적절한 경우가 많다고 주장한다. 따라서 에이전트에게 작업 실패에 대한 자세한 이유를 알려줌으로써 보다 효과적으로 계획을 수정할 수 있도록 제안한다. LLM-Planner <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib141" title="">141</a>]</cite>는 객체 불일치와 작업 완료 중 달성할 수 없는 계획을 만날 때 LLMs에 의해 생성된 계획을 동적으로 업데이트하는 접지된 재계획 알고리즘을 소개한다. Inner Monologue <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib71" title="">71</a>]</cite>는 작업을 수행한 후 에이전트에 세 가지 유형의 피드백을 제공한다: (1) 작업이 성공적으로 완료되었는지 여부, (2) 수동 장면 설명, (3) 능동 장면 설명. 전자의 두 가지는 환경으로부터 생성되며, 이는 에이전트 행위를 보다 실용적이고 합리적으로 만든다.</p>
</div>
<div id="S2.SS1.SSS3.p8" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS3.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS3.p8.1.m1.1"><semantics id="S2.SS1.SSS3.p8.1.m1.1a"><mo id="S2.SS1.SSS3.p8.1.m1.1.1" xref="S2.SS1.SSS3.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS3.p8.1.m1.1b"><ci id="S2.SS1.SSS3.p8.1.m1.1.1.cmml" xref="S2.SS1.SSS3.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS3.p8.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS3.p8.1.1">Human Feedback</span>. 환경으로부터 피드백을 얻는 것 외에도 인간과 직접 상호작용하는 것은 에이전트 계획 능력을 향상시키기 위한 매우 직관적인 전략이기도 하다. 인간의 피드백은 주관적인 신호이다. 그것은 에이전트가 인간의 가치 및 선호도와 효과적으로 일치하도록 할 수 있고, 또한 환각 문제를 완화하는 데 도움이 될 수 있다. Inner Monologue <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib71" title="">71</a>]</cite>에서 에이전트는 3D 시각 환경에서 고수준의 자연어 명령을 수행하는 것을 목표로 한다. 장면 묘사와 관련하여 인간의 피드백을 적극적으로 요청할 수 있는 능력이 부여된다. 그런 다음 에이전트는 인간의 피드백을 프롬프트에 통합하여 보다 정보에 입각한 계획 및 추론을 가능하게 한다. 위의 경우, 에이전트 계획 능력을 향상시키기 위해 다양한 유형의 피드백이 결합될 수 있음을 알 수 있다. 예를 들어, Inner Monologue <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib71" title="">71</a>]</cite>는 에이전트의 계획을 용이하게 하기 위해 환경과 인간의 피드백을 모두 수집한다.</p>
</div>
<div id="S2.SS1.SSS3.p9" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS3.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS3.p9.1.m1.1"><semantics id="S2.SS1.SSS3.p9.1.m1.1a"><mo id="S2.SS1.SSS3.p9.1.m1.1.1" xref="S2.SS1.SSS3.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS3.p9.1.m1.1b"><ci id="S2.SS1.SSS3.p9.1.m1.1.1.cmml" xref="S2.SS1.SSS3.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS3.p9.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS3.p9.1.1">Model Feedback</span>. 외부 신호인 앞서 언급한 환경 및 인간 피드백 외에도 연구자들은 에이전트 자체에서 내부 피드백의 활용도 조사했다. 이러한 유형의 피드백은 일반적으로 미리 훈련된 모델에 기초하여 생성된다. 특히 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib107" title="">107</a>]</cite>는 자체 정제 메커니즘을 제안한다. 이 메커니즘은 출력, 피드백 및 개선의 세 가지 중요한 구성 요소로 구성된다. 먼저 에이전트가 출력을 생성합니다. 그런 다음 LLM을 활용하여 출력에 대한 피드백을 제공하고 개선 방법에 대한 지침을 제공합니다. 마지막으로, 피드백 및 미세화에 의해 출력이 개선된다. 이 출력-피드백-정제 프로세스는 몇 가지 원하는 조건에 도달할 때까지 반복된다. SelfCheck<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib112" title="">112</a>]</cite>를 통해 에이전트는 다양한 단계에서 생성된 추론 단계를 검사하고 평가할 수 있다. 그런 다음 결과를 비교하여 오류를 수정할 수 있습니다. InterAct<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite>는 체커 및 분류기와 같은 보조 역할로 서로 다른 언어 모델(예: ChatGPT 및 InstructGPT)을 사용하여 주 언어 모델이 잘못되고 비효율적인 행동을 피하는 데 도움이 됩니다. ChatCoT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>는 모델 피드백을 활용하여 추론 과정의 품질을 향상시킨다. 모델 피드백은 에이전트 추론 단계를 모니터링하는 평가 모듈에 의해 생성된다. 반사<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib139" title="">139</a>]</cite>는 구체적인 언어적 피드백을 통해 에이전트의 계획 능력을 향상시키기 위해 개발되었다. 이 모델에서 에이전트는 먼저 자신의 기억을 기반으로 행동을 생성하고, 평가자는 에이전트의 궤적을 입력으로 하여 피드백을 생성한다. 피드백이 스칼라 값으로 주어지는 이전 연구와 달리 이 모델은 LLM을 활용하여 보다 자세한 구두 피드백을 제공하여 에이전트 계획에 대한 보다 포괄적인 지원을 제공할 수 있다.</p>
</div>
<div id="Thmremarkx4" class="ltx_theorem ltx_theorem_remark">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmremarkx4.1.1.1" class="ltx_text ltx_font_italic">Remark</span></span><span id="Thmremarkx4.2.2" class="ltx_text ltx_font_italic">.</span>
</h6>
<div id="Thmremarkx4.p1" class="ltx_para">
<p class="ltx_p" id="Thmremarkx4.p1.1">결론적으로, 피드백 없이 계획 모듈을 구현하는 것은 비교적 간단하다. 그러나 적은 수의 추론 단계만 필요로 하는 간단한 작업에 주로 적합하다. 반대로 피드백으로 계획하는 전략은 피드백을 처리하기 위해 보다 세심한 설계가 필요하다. 그럼에도 불구하고 훨씬 더 강력하고 장거리 추론을 포함하는 복잡한 작업을 효과적으로 해결할 수 있다.</p>
</div>
</div>
</section>
<section id="S2.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.4 </span>Action Module</h4>

<div id="S2.SS1.SSS4.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS4.p1.1">작업 모듈은 에이전트의 결정을 특정 결과로 변환하는 역할을 합니다. 이 모듈은 가장 하류 위치에 위치하며 환경과 직접 상호 작용한다. 프로파일, 메모리 및 계획 모듈의 영향을 받습니다. 이 절에서는 액션 모듈을 4가지 관점에서 소개한다: (1) 액션 목표: 액션의 의도된 결과는 무엇인가? (2) 액션 생성: 액션은 어떻게 생성되는가? (3) 동작 공간: 사용 가능한 동작들은 무엇인가? (4) 행동 영향: 행동의 결과는 무엇인가? 이러한 관점들 중에서, 처음 두 가지는 액션 이전의 측면들("행동 전" 측면들)에 초점을 맞추고, 세 번째는 액션 자체("행동 중" 측면들)에 초점을 맞추고, 네 번째는 액션의 영향(행동 후" 측면들)을 강조한다.</p>
</div>
<div id="S2.SS1.SSS4.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS4.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS4.p2.1.1">Action Goal</span>: The agent can perform actions with various objectives. 여기서는 (1) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p2.1.2">Task Completion</span>의 몇 가지 대표적인 예를 제시한다. 이 시나리오에서 에이전트의 액션은 마인크래프트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>에서 철곡괭이를 만들거나 소프트웨어 개발 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib124" title="">124</a>]</cite>에서 함수를 완성하는 것과 같은 특정 작업을 수행하는 것을 목표로 한다. 이러한 행동들은 대개 잘 정의된 목적들을 가지며, 각각의 행동들은 최종 태스크의 완성에 기여한다. 이러한 유형의 목표를 목표로 하는 행동은 기존 문헌에서 매우 일반적이다. (2) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p2.1.3">Communication</span>. 이 경우, 정보를 공유하거나 협업을 위해 다른 에이전트 또는 실제 인간과 통신하기 위한 조치가 취해진다. 예를 들어, ChatDev<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib124" title="">124</a>]</cite>에 있는 에이전트들은 소프트웨어 개발 작업을 일괄적으로 수행하기 위해 서로 통신할 수 있다. Inner Monologue <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib71" title="">71</a>]</cite>에서 에이전트는 인간과 적극적으로 소통하고 인간의 피드백을 기반으로 행동 전략을 조정한다. (3) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p2.1.4">Environment Exploration</span>. 이 예에서 에이전트는 익숙하지 않은 환경을 탐색하여 인식을 확장하고 탐색과 착취 사이의 균형을 맞추는 것을 목표로 한다. 예를 들어, Voyager<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>의 에이전트는 작업 완료 과정에서 알려지지 않은 기술을 탐색하고 시행착오를 통해 환경 피드백을 기반으로 기술 실행 코드를 지속적으로 정제할 수 있다.</p>
</div>
<div id="S2.SS1.SSS4.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS4.p3.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS4.p3.1.1">Action Production</span>: 일반적인 LLMs와 다르며, 여기서 모델 입력 및 출력이 직접 연관되며, 에이전트는 상이한 전략 및 소스를 통해 액션을 취할 수 있다. 이하에서는 일반적으로 사용되는 두 가지 유형의 액션 프로덕션 전략을 소개한다. (1) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p3.1.2">Memory Recollection을 통한 Action</span>. 이 전략에서 액션은 현재 태스크에 따라 에이전트 메모리로부터 정보를 추출함으로써 생성된다. 작업 및 추출된 메모리는 에이전트 동작을 트리거하기 위한 프롬프트로 사용된다. 예를 들어, Generative Agents <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib121" title="">121</a>]</cite>에서 에이전트는 메모리 스트림을 유지하고, 각 액션을 취하기 전에 메모리 스팀으로부터 최근, 관련되고 중요한 정보를 검색하여 에이전트 액션을 안내한다. GITM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite>에서, 낮은 레벨의 하위 목표를 달성하기 위해, 에이전트는 태스크와 관련된 임의의 성공적인 경험들이 있는지를 결정하기 위해 자신의 메모리에 질의한다. 유사한 작업이 이전에 완료된 경우 에이전트는 이전에 성공한 작업을 호출하여 현재 작업을 직접 처리합니다. ChatDev<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib124" title="">124</a>]</cite>와 MetaGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>와 같은 협업 에이전트에서는 서로 다른 에이전트가 서로 통신할 수 있다. 이 과정에서 대화창 내의 대화 내역은 에이전트 메모리에서 기억된다. 에이전트에 의해 생성된 각각의 발화는 그 기억의 영향을 받는다. (2) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p3.1.3">Action via Plan Following</span>. 이 전략에서 에이전트는 미리 생성된 계획에 따라 조치를 취합니다. 예를 들어 DEPS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib154" title="">154</a>]</cite>에서 주어진 작업에 대해 에이전트는 먼저 액션 플랜을 만듭니다. 계획 실패를 나타내는 신호가 없으면 에이전트는 이러한 계획을 엄격하게 준수합니다. GITM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite>에서 에이전트는 작업을 많은 하위 목표로 분해하여 높은 수준의 계획을 만든다. 이러한 계획을 바탕으로 에이전트는 각 하위 목표를 순차적으로 해결하는 행동을 취하여 최종 과제를 완성한다.</p>
</div>
<div id="S2.SS1.SSS4.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS4.p4.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS4.p4.1.1">Action Space</span>: Action space는 에이전트에 의해 수행될 수 있는 가능한 액션들의 집합을 의미한다. 일반적으로 우리는 이러한 행동을 (1) 외부 도구와 (2) LLM에 대한 내부 지식의 두 가지 클래스로 대별할 수 있다. 이하에서는 이러한 행위를 좀 더 구체적으로 소개하고자 한다.</p>
</div>
<div id="S2.SS1.SSS4.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS4.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS4.p5.1.m1.1"><semantics id="S2.SS1.SSS4.p5.1.m1.1a"><mo id="S2.SS1.SSS4.p5.1.m1.1.1" xref="S2.SS1.SSS4.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS4.p5.1.m1.1b"><ci id="S2.SS1.SSS4.p5.1.m1.1.1.cmml" xref="S2.SS1.SSS4.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS4.p5.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p5.1.1">External Tools</span>. LLM은 많은 양의 작업을 달성하는 데 효과적인 것으로 입증되었지만 포괄적인 전문가 지식이 필요한 영역에는 잘 작동하지 않을 수 있다. 또한 LLM은 스스로 해결하기 어려운 환각 문제에 직면할 수도 있다. 위의 문제를 완화하기 위해 에이전트는 동작을 실행하기 위한 외부 도구를 호출할 수 있는 권한을 부여받는다. 다음에서는 문헌에서 활용된 몇 가지 대표적인 도구를 제시한다.</p>
</div>
<div id="S2.SS1.SSS4.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS4.p6.1">(1) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p6.1.1">APIs</span>. 외부 API를 활용하여 액션 공간을 보완하고 확장하는 것은 최근 몇 년 동안 인기 있는 패러다임이다. 예를 들어, HuggingGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite>는 HuggingFace에서 모델들을 활용하여 복잡한 사용자 작업을 수행한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib115" title="">115</a>, <a class="ltx_ref" href="#bib.bib130" title="">130</a>]</cite>는 사용자 요청에 응답할 때 외부 웹 페이지에서 관련 콘텐츠를 추출하기 위한 쿼리를 자동으로 생성하는 것을 제안한다. TPTU<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib130" title="">130</a>]</cite>는 Python 해석기 및 LaTeX 컴파일러와 인터페이스하여 제곱근, 요인 및 행렬 연산과 같은 정교한 계산을 수행합니다. 또 다른 유형의 API는 자연 언어 또는 코드 입력에 기초하여 LLM에 의해 직접 호출될 수 있는 것이다. 예를 들어, 고릴라<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib123" title="">123</a>]</cite>는 API 호출에 대한 정확한 입력 인수를 생성하고 외부 API 호출 중 환각 문제를 완화하도록 설계된 미세 조정 LLM이다. ToolFormer<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>]</cite>는 자연어 명령어를 기반으로 주어진 도구를 기능이나 형식이 다른 다른 도구로 자동 변환할 수 있는 LLM 기반의 도구 변환 시스템이다. API-Bank<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib90" title="">90</a>]</cite>는 LLM 기반의 API 추천 에이전트로 다양한 프로그래밍 언어 및 도메인에 대한 적절한 API 호출을 자동으로 검색하고 생성할 수 있다. API-Bank는 또한 사용자가 생성된 API 호출을 쉽게 수정하고 실행할 수 있는 대화형 인터페이스를 제공한다. ToolBench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib126" title="">126</a>]</cite>는 LLM 기반의 도구 생성 시스템으로 자연어 요구사항을 기반으로 다양한 실용적인 도구를 자동으로 설계하고 구현할 수 있다. 툴벤치가 생성하는 도구에는 계산기, 단위 변환기, 달력, 지도, 차트 등이 있다. RestGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite>는 LLMs를 RESTful API와 연결하며, 이는 웹 서비스 개발에 널리 사용되는 표준을 따르므로 결과 프로그램이 실제 응용 프로그램과 더 호환됩니다. TaskMatrix.AI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>는 LLMs와 수백만 개의 API를 연결하여 태스크 실행을 지원합니다. 그 핵심에는 사용자와 상호 작용하고 목표와 맥락을 이해한 다음 특정 작업에 대한 실행 코드를 생성하는 다중 모드 대화 기반 모델이 있다. 이러한 모든 에이전트는 외부 API를 외부 도구로 활용하고, 사용자가 생성되거나 변환된 도구를 쉽게 수정하고 실행할 수 있도록 대화형 인터페이스를 제공한다.</p>
</div>
<div id="S2.SS1.SSS4.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS4.p7.1">(2) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p7.1.1">Databases &amp; Knowledge Bases</span>. 외부 데이터베이스 또는 지식 베이스와 연결하면 에이전트가 보다 현실적인 동작을 생성하기 위한 특정 도메인 정보를 얻는 데 도움이 될 수 있다. 예를 들어 ChatDB<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>는 SQL 문을 사용하여 데이터베이스를 쿼리하여 에이전트에 의한 작업을 논리적 방식으로 촉진합니다. MRKL<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib80" title="">80</a>]</cite>와 OpenAGI<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>는 지식베이스, 기획자 등 다양한 전문가 시스템을 통합해 도메인별 정보에 접근한다.</p>
</div>
<div id="S2.SS1.SSS4.p8" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS4.p8.1">(3) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p8.1.1">External Models</span>. 선행 연구들은 가능한 행동의 범위를 확장하기 위해 외부 모델을 활용하는 경우가 많다. API와 비교하여 외부 모델은 일반적으로 더 복잡한 작업을 처리합니다. 각각의 외부 모델은 복수의 API들에 대응할 수 있다. 예를 들어, 텍스트 검색 능력을 향상시키기 위해 MemoryBank<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib179" title="">179</a>]</cite>는 두 가지 언어 모델을 통합한다: 하나는 입력 텍스트를 인코딩하도록 설계된 반면, 다른 하나는 쿼리 문들의 매칭을 담당한다. ViperGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib144" title="">144</a>]</cite>는 먼저 언어 모델을 기반으로 구현된 Codex를 사용하여 텍스트 설명으로부터 Python 코드를 생성한 후 코드를 실행하여 주어진 작업을 완료한다. TPTU<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib130" title="">130</a>]</cite>는 코드 생성, 가사 제작 등과 같은 광범위한 언어 생성 작업을 수행하기 위해 다양한 LLM을 통합한다. ChemCrow<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite>는 유기 합성, 약물 발견 및 재료 설계에서 작업을 수행하도록 설계된 LLM 기반 화학 제제이다. 17개의 전문가 설계 모델을 활용하여 운영을 지원합니다. MM-REACT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib167" title="">167</a>]</cite>는 이미지 생성을 위한 X-디코더, 비디오 요약을 위한 VideoBERT, 오디오 처리를 위한 SpeechBERT와 같은 다양한 외부 모델을 통합하여 다양한 멀티모달 시나리오에서 성능을 향상시킨다.</p>
</div>
<div id="S2.SS1.SSS4.p9" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS4.p9.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS1.SSS4.p9.1.m1.1"><semantics id="S2.SS1.SSS4.p9.1.m1.1a"><mo id="S2.SS1.SSS4.p9.1.m1.1.1" xref="S2.SS1.SSS4.p9.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.SSS4.p9.1.m1.1b"><ci id="S2.SS1.SSS4.p9.1.m1.1.1.cmml" xref="S2.SS1.SSS4.p9.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.SSS4.p9.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p9.1.1">Internal Knowledge</span>. 외부 도구를 활용하는 것 외에도 많은 에이전트는 LLM의 내부 지식에만 의존하여 행동을 안내한다. 이제 에이전트가 합리적이고 효과적으로 행동할 수 있도록 지원할 수 있는 LLM의 몇 가지 중요한 기능을 제시한다. (1) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p9.1.2">Planning Capability</span>. 이전 연구에서는 LLM이 복잡한 작업을 더 간단한 작업으로 분해하기 위한 괜찮은 플래너로 사용될 수 있음을 입증했다. 이러한 LLMs의 능력은 프롬프트들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>에 예들을 통합하지 않고서도 트리거될 수 있다. LLM의 계획 능력을 바탕으로 DEPS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib154" title="">154</a>]</cite>는 하위 목표 분해를 통해 복잡한 작업을 해결할 수 있는 마인크래프트 에이전트를 개발한다. GITM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite> 및 Voyager<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>와 같은 유사한 에이전트도 LLM의 계획 능력에 크게 의존하여 다른 작업을 성공적으로 완료합니다. (2) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p9.1.3">Conversation Capability</span>. LLM은 일반적으로 고품질 대화를 생성할 수 있습니다. 이 기능을 통해 에이전트는 인간처럼 행동할 수 있습니다. 이전 작업에서 많은 에이전트는 LLM의 강력한 대화 능력을 기반으로 조치를 취한다. 예를 들어, ChatDev <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib124" title="">124</a>]</cite>에서 서로 다른 에이전트는 소프트웨어 개발 프로세스에 대해 논의할 수 있으며, 심지어 자신의 행동에 대한 반성도 할 수 있다. RLP<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib54" title="">54</a>]</cite>에서 에이전트는 에이전트의 발화에 대한 잠재적인 피드백에 기초하여 청취자와 통신할 수 있다. (3) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p9.1.4">Common Sense Understanding Capability</span>. LLM의 또 다른 중요한 능력은 그들이 인간의 상식을 잘 이해할 수 있다는 것이다. 이러한 능력에 기초하여, 많은 에이전트는 인간의 일상 생활을 시뮬레이션하고 인간과 유사한 결정을 내릴 수 있다. 예를 들어, Generative Agent에서 에이전트는 자신의 현재 상태, 주변 환경 등을 정확하게 이해하고, 기본적인 관찰을 바탕으로 높은 수준의 아이디어를 요약할 수 있다. LLM의 상식 이해 능력이 없으면 이러한 행동을 안정적으로 시뮬레이션할 수 없다. 유사한 결론이 RecAgent <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib149" title="">149</a>]</cite> 및 S3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>에도 적용될 수 있으며, 여기서 에이전트는 사용자 추천 및 소셜 행동을 시뮬레이션하는 것을 목표로 한다.</p>
</div>
<div id="S2.SS1.SSS4.p10" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS1.SSS4.p10.1"><span class="ltx_text ltx_font_bold" id="S2.SS1.SSS4.p10.1.1">Action Impact</span>: Action Impact는 Action의 결과를 나타낸다. 사실, 액션 영향은 수많은 예를 포함할 수 있지만, 간결함을 위해, 우리는 몇 가지 예만을 제공한다. (1) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p10.1.2">Changing Environments. </span> 에이전트는 위치 이동, 항목 수집, 건물 건설 등과 같은 액션에 의해 환경 상태를 직접 변경할 수 있습니다. 예를 들어, GITM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite>와 Voyager<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>에서는 작업 완료 과정에서 에이전트의 동작에 의해 환경이 변경된다. 예를 들어, 에이전트가 세 개의 나무를 채굴하면 환경에서 사라질 수 있습니다. (2) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p10.1.3">Altering Internal States. </span> 에이전트가 취한 액션은 메모리 업데이트, 새로운 계획 형성, 새로운 지식 습득 등을 포함하여 에이전트 자체를 변경할 수도 있습니다. 예를 들어, Generative Agents <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib121" title="">121</a>]</cite>에서, 메모리 스트림들은 시스템 내에서 액션들을 수행한 후에 업데이트된다. SayCan <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib2" title="">2</a>]</cite>는 에이전트가 환경에 대한 이해를 업데이트하기 위한 액션을 취할 수 있게 한다. (3) <span class="ltx_text ltx_font_italic" id="S2.SS1.SSS4.p10.1.4">Triggering New Actions. </span> 작업 완료 프로세스에서 한 에이전트 작업은 다른 에이전트에 의해 트리거될 수 있습니다. 예를 들어, Voyager <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>는 필요한 모든 리소스를 모으면 건물을 구성합니다. DEPS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib154" title="">154</a>]</cite>는 계획을 순차적인 하위 목표로 분해하고, 각 하위 목표는 잠재적으로 다음 목표를 트리거한다.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 1:</span></figcaption><figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>
Summary of the construction strategies of representative agents (more agents can be seen on https://github.com/Paitesanshi/LLM-Agent-Survey).
For the profile module, we use ①, ② and ③ to represent the handcrafting method, LLM-generation method, and dataset alignment method, respectively.
For the memory module, we focus on the implementation strategies for memory operation and memory structure.
For memory operation, we use ① and ② to indicate that the model only has read/write operations and has read/write/reflection operations, respectively.
For memory structure, we use ① and ② to represent unified and hybrid memories, respectively.
For the planning module, we use ① and ② to represent planning w/o feedback and w/ feedback, respectively.
For the action module, we use ① and ② to represent that the model does not use tools and use tools, respectively.
For the agent <span id="S2.T1.4.1" class="ltx_text ltx_framed ltx_framed_underline">c</span>apability <span id="S2.T1.5.2" class="ltx_text ltx_framed ltx_framed_underline">a</span>cquisition (CA) strategy, we use ① and ② to represent the methods with and without fine-tuning, respectively.
“-” indicates that the corresponding content is not explicitly discussed in the paper.
</figcaption>
<div id="S2.T1.1" class="ltx_inline-block ltx_transformed_outer" style="width:431.8pt;height:557.1pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-16.3pt,20.9pt) scale(0.93,0.93) ;">
<table id="S2.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.1.1.2.1" class="ltx_tr">
<th id="S2.T1.1.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.2.1.1.1.1" class="ltx_p" style="width:102.4pt;"><span id="S2.T1.1.1.2.1.1.1.1.1" class="ltx_text">Model</span></span>
</span>
</th>
<th id="S2.T1.1.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.2.1.2.1.1" class="ltx_p" style="width:31.3pt;"><span id="S2.T1.1.1.2.1.2.1.1.1" class="ltx_text">Profile</span></span>
</span>
</th>
<th id="S2.T1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;" colspan="2">Memory</th>
<th id="S2.T1.1.1.2.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.2.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.2.1.4.1.1" class="ltx_p" style="width:31.3pt;"><span id="S2.T1.1.1.2.1.4.1.1.1" class="ltx_text">Planning</span></span>
</span>
</th>
<th id="S2.T1.1.1.2.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.2.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.2.1.5.1.1" class="ltx_p" style="width:22.8pt;"><span id="S2.T1.1.1.2.1.5.1.1.1" class="ltx_text">Action</span></span>
</span>
</th>
<th id="S2.T1.1.1.2.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.2.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.2.1.6.1.1" class="ltx_p" style="width:22.8pt;"><span id="S2.T1.1.1.2.1.6.1.1.1" class="ltx_text">CA</span></span>
</span>
</th>
<th id="S2.T1.1.1.2.1.7" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.2.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.2.1.7.1.1" class="ltx_p" style="width:34.1pt;"><span id="S2.T1.1.1.2.1.7.1.1.1" class="ltx_text">Time</span></span>
</span>
</th>
</tr>
<tr id="S2.T1.1.1.3.2" class="ltx_tr">
<th id="S2.T1.1.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.3.2.1.1.1" class="ltx_p" style="width:102.4pt;"></span>
</span>
</th>
<th id="S2.T1.1.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.3.2.2.1.1" class="ltx_p" style="width:31.3pt;"></span>
</span>
</th>
<th id="S2.T1.1.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.3.2.3.1.1" class="ltx_p" style="width:45.5pt;">Operation</span>
</span>
</th>
<th id="S2.T1.1.1.3.2.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.3.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.3.2.4.1.1" class="ltx_p" style="width:34.1pt;">Structure</span>
</span>
</th>
<th id="S2.T1.1.1.3.2.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.3.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.3.2.5.1.1" class="ltx_p" style="width:31.3pt;"></span>
</span>
</th>
<th id="S2.T1.1.1.3.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.3.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.3.2.6.1.1" class="ltx_p" style="width:22.8pt;"></span>
</span>
</th>
<th id="S2.T1.1.1.3.2.7" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.3.2.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.3.2.7.1.1" class="ltx_p" style="width:22.8pt;"></span>
</span>
</th>
<th id="S2.T1.1.1.3.2.8" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.3.2.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.3.2.8.1.1" class="ltx_p" style="width:34.1pt;"></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.1.1.4.1" class="ltx_tr">
<td id="S2.T1.1.1.4.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.4.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.4.1.1.1.1" class="ltx_p" style="width:102.4pt;">WebGPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.4.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.4.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.4.1.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.4.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.4.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.4.1.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.4.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.4.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.4.1.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.4.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.4.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.4.1.5.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.4.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.4.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.4.1.6.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.4.1.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.4.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.4.1.7.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.4.1.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.4.1.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.4.1.8.1.1" class="ltx_p" style="width:34.1pt;">12/2021</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.5.2" class="ltx_tr">
<td id="S2.T1.1.1.5.2.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.5.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.5.2.1.1.1" class="ltx_p" style="width:102.4pt;">SayCan&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.5.2.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.5.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.5.2.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.5.2.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.5.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.5.2.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.5.2.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.5.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.5.2.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.5.2.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.5.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.5.2.5.1.1" class="ltx_p" style="width:31.3pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.5.2.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.5.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.5.2.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.5.2.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.5.2.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.5.2.7.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.5.2.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.5.2.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.5.2.8.1.1" class="ltx_p" style="width:34.1pt;">04/2022</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.6.3" class="ltx_tr">
<td id="S2.T1.1.1.6.3.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.6.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.6.3.1.1.1" class="ltx_p" style="width:102.4pt;">MRKL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.6.3.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.6.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.6.3.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.6.3.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.6.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.6.3.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.6.3.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.6.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.6.3.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.6.3.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.6.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.6.3.5.1.1" class="ltx_p" style="width:31.3pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.6.3.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.6.3.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.6.3.6.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.6.3.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.6.3.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.6.3.7.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.6.3.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.6.3.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.6.3.8.1.1" class="ltx_p" style="width:34.1pt;">05/2022</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.7.4" class="ltx_tr">
<td id="S2.T1.1.1.7.4.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.7.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.7.4.1.1.1" class="ltx_p" style="width:102.4pt;">Inner Monologue&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.7.4.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.7.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.7.4.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.7.4.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.7.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.7.4.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.7.4.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.7.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.7.4.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.7.4.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.7.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.7.4.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.7.4.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.7.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.7.4.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.7.4.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.7.4.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.7.4.7.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.7.4.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.7.4.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.7.4.8.1.1" class="ltx_p" style="width:34.1pt;">07/2022</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.8.5" class="ltx_tr">
<td id="S2.T1.1.1.8.5.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.8.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.8.5.1.1.1" class="ltx_p" style="width:102.4pt;">Social Simulacra&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.8.5.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.8.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.8.5.2.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.8.5.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.8.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.8.5.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.8.5.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.8.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.8.5.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.8.5.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.8.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.8.5.5.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.8.5.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.8.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.8.5.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.8.5.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.8.5.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.8.5.7.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.8.5.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.8.5.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.8.5.8.1.1" class="ltx_p" style="width:34.1pt;">08/2022</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.9.6" class="ltx_tr">
<td id="S2.T1.1.1.9.6.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.9.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.9.6.1.1.1" class="ltx_p" style="width:102.4pt;">ReAct&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib170" title="" class="ltx_ref">170</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.9.6.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.9.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.9.6.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.9.6.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.9.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.9.6.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.9.6.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.9.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.9.6.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.9.6.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.9.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.9.6.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.9.6.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.9.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.9.6.6.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.9.6.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.9.6.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.9.6.7.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.9.6.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.9.6.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.9.6.8.1.1" class="ltx_p" style="width:34.1pt;">10/2022</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.10.7" class="ltx_tr">
<td id="S2.T1.1.1.10.7.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.10.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.10.7.1.1.1" class="ltx_p" style="width:102.4pt;">MALLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib135" title="" class="ltx_ref">135</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.10.7.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.10.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.10.7.2.1.1" class="ltx_p" style="width:31.3pt;"></span>
</span>
</td>
<td id="S2.T1.1.1.10.7.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.10.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.10.7.3.1.1" class="ltx_p" style="width:45.5pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.10.7.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.10.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.10.7.4.1.1" class="ltx_p" style="width:34.1pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.10.7.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.10.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.10.7.5.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.10.7.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.10.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.10.7.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.10.7.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.10.7.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.10.7.7.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.10.7.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.10.7.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.10.7.8.1.1" class="ltx_p" style="width:34.1pt;">01/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.11.8" class="ltx_tr">
<td id="S2.T1.1.1.11.8.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.11.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.11.8.1.1.1" class="ltx_p" style="width:102.4pt;">DEPS&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.11.8.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.11.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.11.8.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.11.8.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.11.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.11.8.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.11.8.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.11.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.11.8.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.11.8.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.11.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.11.8.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.11.8.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.11.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.11.8.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.11.8.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.11.8.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.11.8.7.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.11.8.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.11.8.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.11.8.8.1.1" class="ltx_p" style="width:34.1pt;">02/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.12.9" class="ltx_tr">
<td id="S2.T1.1.1.12.9.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.12.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.12.9.1.1.1" class="ltx_p" style="width:102.4pt;">Toolformer&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib133" title="" class="ltx_ref">133</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.12.9.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.12.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.12.9.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.12.9.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.12.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.12.9.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.12.9.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.12.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.12.9.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.12.9.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.12.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.12.9.5.1.1" class="ltx_p" style="width:31.3pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.12.9.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.12.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.12.9.6.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.12.9.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.12.9.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.12.9.7.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.12.9.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.12.9.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.12.9.8.1.1" class="ltx_p" style="width:34.1pt;">02/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.13.10" class="ltx_tr">
<td id="S2.T1.1.1.13.10.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.13.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.13.10.1.1.1" class="ltx_p" style="width:102.4pt;">Reflexion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.13.10.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.13.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.13.10.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.13.10.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.13.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.13.10.3.1.1" class="ltx_p" style="width:45.5pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.13.10.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.13.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.13.10.4.1.1" class="ltx_p" style="width:34.1pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.13.10.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.13.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.13.10.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.13.10.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.13.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.13.10.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.13.10.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.13.10.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.13.10.7.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.13.10.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.13.10.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.13.10.8.1.1" class="ltx_p" style="width:34.1pt;">03/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.14.11" class="ltx_tr">
<td id="S2.T1.1.1.14.11.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.14.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.14.11.1.1.1" class="ltx_p" style="width:102.4pt;">CAMEL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.14.11.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.14.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.14.11.2.1.1" class="ltx_p" style="width:31.3pt;">① ②</span>
</span>
</td>
<td id="S2.T1.1.1.14.11.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.14.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.14.11.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.14.11.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.14.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.14.11.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.14.11.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.14.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.14.11.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.14.11.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.14.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.14.11.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.14.11.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.14.11.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.14.11.7.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.14.11.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.14.11.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.14.11.8.1.1" class="ltx_p" style="width:34.1pt;">03/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.15.12" class="ltx_tr">
<td id="S2.T1.1.1.15.12.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.15.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.15.12.1.1.1" class="ltx_p" style="width:102.4pt;">API-Bank&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.15.12.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.15.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.15.12.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.15.12.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.15.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.15.12.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.15.12.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.15.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.15.12.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.15.12.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.15.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.15.12.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.15.12.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.15.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.15.12.6.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.15.12.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.15.12.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.15.12.7.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.15.12.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.15.12.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.15.12.8.1.1" class="ltx_p" style="width:34.1pt;">04/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.16.13" class="ltx_tr">
<td id="S2.T1.1.1.16.13.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.16.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.16.13.1.1.1" class="ltx_p" style="width:102.4pt;">ViperGPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib144" title="" class="ltx_ref">144</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.16.13.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.16.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.16.13.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.16.13.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.16.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.16.13.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.16.13.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.16.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.16.13.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.16.13.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.16.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.16.13.5.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.16.13.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.16.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.16.13.6.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.16.13.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.16.13.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.16.13.7.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.16.13.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.16.13.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.16.13.8.1.1" class="ltx_p" style="width:34.1pt;">03/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.17.14" class="ltx_tr">
<td id="S2.T1.1.1.17.14.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.17.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.17.14.1.1.1" class="ltx_p" style="width:102.4pt;">HuggingGPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib138" title="" class="ltx_ref">138</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.17.14.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.17.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.17.14.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.17.14.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.17.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.17.14.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.17.14.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.17.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.17.14.4.1.1" class="ltx_p" style="width:34.1pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.17.14.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.17.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.17.14.5.1.1" class="ltx_p" style="width:31.3pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.17.14.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.17.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.17.14.6.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.17.14.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.17.14.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.17.14.7.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.17.14.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.17.14.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.17.14.8.1.1" class="ltx_p" style="width:34.1pt;">03/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.18.15" class="ltx_tr">
<td id="S2.T1.1.1.18.15.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.18.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.18.15.1.1.1" class="ltx_p" style="width:102.4pt;">Generative Agents&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.18.15.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.18.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.18.15.2.1.1" class="ltx_p" style="width:31.3pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.18.15.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.18.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.18.15.3.1.1" class="ltx_p" style="width:45.5pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.18.15.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.18.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.18.15.4.1.1" class="ltx_p" style="width:34.1pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.18.15.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.18.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.18.15.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.18.15.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.18.15.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.18.15.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.18.15.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.18.15.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.18.15.7.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.18.15.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.18.15.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.18.15.8.1.1" class="ltx_p" style="width:34.1pt;">04/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.19.16" class="ltx_tr">
<td id="S2.T1.1.1.19.16.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.19.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.19.16.1.1.1" class="ltx_p" style="width:102.4pt;">LLM+P&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.19.16.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.19.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.19.16.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.19.16.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.19.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.19.16.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.19.16.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.19.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.19.16.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.19.16.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.19.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.19.16.5.1.1" class="ltx_p" style="width:31.3pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.19.16.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.19.16.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.19.16.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.19.16.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.19.16.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.19.16.7.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.19.16.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.19.16.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.19.16.8.1.1" class="ltx_p" style="width:34.1pt;">04/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.20.17" class="ltx_tr">
<td id="S2.T1.1.1.20.17.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.20.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.20.17.1.1.1" class="ltx_p" style="width:102.4pt;">ChemCrow&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.20.17.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.20.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.20.17.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.20.17.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.20.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.20.17.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.20.17.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.20.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.20.17.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.20.17.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.20.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.20.17.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.20.17.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.20.17.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.20.17.6.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.20.17.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.20.17.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.20.17.7.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.20.17.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.20.17.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.20.17.8.1.1" class="ltx_p" style="width:34.1pt;">04/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.21.18" class="ltx_tr">
<td id="S2.T1.1.1.21.18.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.21.18.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.21.18.1.1.1" class="ltx_p" style="width:102.4pt;">OpenAGI&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.21.18.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.21.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.21.18.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.21.18.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.21.18.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.21.18.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.21.18.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.21.18.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.21.18.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.21.18.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.21.18.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.21.18.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.21.18.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.21.18.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.21.18.6.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.21.18.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.21.18.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.21.18.7.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.21.18.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.21.18.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.21.18.8.1.1" class="ltx_p" style="width:34.1pt;">04/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.22.19" class="ltx_tr">
<td id="S2.T1.1.1.22.19.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.22.19.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.22.19.1.1.1" class="ltx_p" style="width:102.4pt;">AutoGPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.22.19.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.22.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.22.19.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.22.19.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.22.19.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.22.19.3.1.1" class="ltx_p" style="width:45.5pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.22.19.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.22.19.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.22.19.4.1.1" class="ltx_p" style="width:34.1pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.22.19.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.22.19.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.22.19.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.22.19.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.22.19.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.22.19.6.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.22.19.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.22.19.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.22.19.7.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.22.19.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.22.19.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.22.19.8.1.1" class="ltx_p" style="width:34.1pt;">04/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.23.20" class="ltx_tr">
<td id="S2.T1.1.1.23.20.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.23.20.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.23.20.1.1.1" class="ltx_p" style="width:102.4pt;">SCM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.23.20.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.23.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.23.20.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.23.20.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.23.20.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.23.20.3.1.1" class="ltx_p" style="width:45.5pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.23.20.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.23.20.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.23.20.4.1.1" class="ltx_p" style="width:34.1pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.23.20.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.23.20.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.23.20.5.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.23.20.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.23.20.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.23.20.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.23.20.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.23.20.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.23.20.7.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.23.20.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.23.20.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.23.20.8.1.1" class="ltx_p" style="width:34.1pt;">04/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.24.21" class="ltx_tr">
<td id="S2.T1.1.1.24.21.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.24.21.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.24.21.1.1.1" class="ltx_p" style="width:102.4pt;">Socially Alignment&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.24.21.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.24.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.24.21.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.24.21.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.24.21.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.24.21.3.1.1" class="ltx_p" style="width:45.5pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.24.21.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.24.21.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.24.21.4.1.1" class="ltx_p" style="width:34.1pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.24.21.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.24.21.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.24.21.5.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.24.21.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.24.21.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.24.21.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.24.21.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.24.21.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.24.21.7.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.24.21.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.24.21.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.24.21.8.1.1" class="ltx_p" style="width:34.1pt;">05/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.25.22" class="ltx_tr">
<td id="S2.T1.1.1.25.22.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.25.22.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.25.22.1.1.1" class="ltx_p" style="width:102.4pt;">GITM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib184" title="" class="ltx_ref">184</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.25.22.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.25.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.25.22.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.25.22.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.25.22.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.25.22.3.1.1" class="ltx_p" style="width:45.5pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.25.22.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.25.22.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.25.22.4.1.1" class="ltx_p" style="width:34.1pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.25.22.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.25.22.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.25.22.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.25.22.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.25.22.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.25.22.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.25.22.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.25.22.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.25.22.7.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.25.22.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.25.22.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.25.22.8.1.1" class="ltx_p" style="width:34.1pt;">05/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.26.23" class="ltx_tr">
<td id="S2.T1.1.1.26.23.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.26.23.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.26.23.1.1.1" class="ltx_p" style="width:102.4pt;">Voyager&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.26.23.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.26.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.26.23.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.26.23.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.26.23.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.26.23.3.1.1" class="ltx_p" style="width:45.5pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.26.23.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.26.23.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.26.23.4.1.1" class="ltx_p" style="width:34.1pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.26.23.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.26.23.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.26.23.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.26.23.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.26.23.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.26.23.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.26.23.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.26.23.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.26.23.7.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.26.23.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.26.23.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.26.23.8.1.1" class="ltx_p" style="width:34.1pt;">05/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.27.24" class="ltx_tr">
<td id="S2.T1.1.1.27.24.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.27.24.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.27.24.1.1.1" class="ltx_p" style="width:102.4pt;">Introspective Tips&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.27.24.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.27.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.27.24.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.27.24.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.27.24.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.27.24.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.27.24.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.27.24.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.27.24.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.27.24.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.27.24.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.27.24.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.27.24.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.27.24.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.27.24.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.27.24.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.27.24.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.27.24.7.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.27.24.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.27.24.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.27.24.8.1.1" class="ltx_p" style="width:34.1pt;">05/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.28.25" class="ltx_tr">
<td id="S2.T1.1.1.28.25.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.28.25.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.28.25.1.1.1" class="ltx_p" style="width:102.4pt;">RET-LLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.28.25.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.28.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.28.25.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.28.25.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.28.25.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.28.25.3.1.1" class="ltx_p" style="width:45.5pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.28.25.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.28.25.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.28.25.4.1.1" class="ltx_p" style="width:34.1pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.28.25.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.28.25.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.28.25.5.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.28.25.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.28.25.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.28.25.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.28.25.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.28.25.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.28.25.7.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.28.25.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.28.25.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.28.25.8.1.1" class="ltx_p" style="width:34.1pt;">05/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.29.26" class="ltx_tr">
<td id="S2.T1.1.1.29.26.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.29.26.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.29.26.1.1.1" class="ltx_p" style="width:102.4pt;">ChatDB&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.29.26.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.29.26.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.29.26.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.29.26.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.29.26.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.29.26.3.1.1" class="ltx_p" style="width:45.5pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.29.26.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.29.26.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.29.26.4.1.1" class="ltx_p" style="width:34.1pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.29.26.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.29.26.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.29.26.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.29.26.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.29.26.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.29.26.6.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.29.26.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.29.26.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.29.26.7.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.29.26.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.29.26.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.29.26.8.1.1" class="ltx_p" style="width:34.1pt;">06/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.1" class="ltx_tr">
<td id="S2.T1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.1.1.1" class="ltx_p" style="width:102.4pt;"><math id="S2.T1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="S^{3}" display="inline"><semantics id="S2.T1.1.1.1.1.1.1.m1.1a"><msup id="S2.T1.1.1.1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.1.1.1.m1.1.1.cmml"><mi id="S2.T1.1.1.1.1.1.1.m1.1.1.2" xref="S2.T1.1.1.1.1.1.1.m1.1.1.2.cmml">S</mi><mn id="S2.T1.1.1.1.1.1.1.m1.1.1.3" xref="S2.T1.1.1.1.1.1.1.m1.1.1.3.cmml">3</mn></msup><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.1.1.1.m1.1b"><apply id="S2.T1.1.1.1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.T1.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S2.T1.1.1.1.1.1.1.m1.1.1">superscript</csymbol><ci id="S2.T1.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S2.T1.1.1.1.1.1.1.m1.1.1.2">𝑆</ci><cn type="integer" id="S2.T1.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S2.T1.1.1.1.1.1.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.1.1.1.m1.1c">S^{3}</annotation></semantics></math>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.2.1.1" class="ltx_p" style="width:31.3pt;">③</span>
</span>
</td>
<td id="S2.T1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.3.1.1" class="ltx_p" style="width:45.5pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.1.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.4.1.1" class="ltx_p" style="width:34.1pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.1.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.5.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.1.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.1.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.1.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.7.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.1.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.1.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.8.1.1" class="ltx_p" style="width:34.1pt;">07/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.30.27" class="ltx_tr">
<td id="S2.T1.1.1.30.27.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.30.27.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.30.27.1.1.1" class="ltx_p" style="width:102.4pt;">ChatDev&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.30.27.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.30.27.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.30.27.2.1.1" class="ltx_p" style="width:31.3pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.30.27.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.30.27.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.30.27.3.1.1" class="ltx_p" style="width:45.5pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.30.27.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.30.27.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.30.27.4.1.1" class="ltx_p" style="width:34.1pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.30.27.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.30.27.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.30.27.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.30.27.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.30.27.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.30.27.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.30.27.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.30.27.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.30.27.7.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.30.27.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.30.27.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.30.27.8.1.1" class="ltx_p" style="width:34.1pt;">07/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.31.28" class="ltx_tr">
<td id="S2.T1.1.1.31.28.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.31.28.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.31.28.1.1.1" class="ltx_p" style="width:102.4pt;">ToolLLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib126" title="" class="ltx_ref">126</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.31.28.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.31.28.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.31.28.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.31.28.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.31.28.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.31.28.3.1.1" class="ltx_p" style="width:45.5pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.31.28.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.31.28.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.31.28.4.1.1" class="ltx_p" style="width:34.1pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.31.28.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.31.28.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.31.28.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.31.28.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.31.28.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.31.28.6.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.31.28.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.31.28.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.31.28.7.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.31.28.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.31.28.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.31.28.8.1.1" class="ltx_p" style="width:34.1pt;">07/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.32.29" class="ltx_tr">
<td id="S2.T1.1.1.32.29.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.32.29.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.32.29.1.1.1" class="ltx_p" style="width:102.4pt;">MemoryBank&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib179" title="" class="ltx_ref">179</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.32.29.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.32.29.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.32.29.2.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.32.29.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.32.29.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.32.29.3.1.1" class="ltx_p" style="width:45.5pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.32.29.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.32.29.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.32.29.4.1.1" class="ltx_p" style="width:34.1pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.32.29.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.32.29.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.32.29.5.1.1" class="ltx_p" style="width:31.3pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.32.29.6" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.32.29.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.32.29.6.1.1" class="ltx_p" style="width:22.8pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.32.29.7" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.32.29.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.32.29.7.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.32.29.8" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.32.29.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.32.29.8.1.1" class="ltx_p" style="width:34.1pt;">07/2023</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.1.33.30" class="ltx_tr">
<td id="S2.T1.1.1.33.30.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.33.30.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.33.30.1.1.1" class="ltx_p" style="width:102.4pt;">MetaGPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite></span>
</span>
</td>
<td id="S2.T1.1.1.33.30.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.33.30.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.33.30.2.1.1" class="ltx_p" style="width:31.3pt;">①</span>
</span>
</td>
<td id="S2.T1.1.1.33.30.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.33.30.3.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.33.30.3.1.1" class="ltx_p" style="width:45.5pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.33.30.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.33.30.4.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.33.30.4.1.1" class="ltx_p" style="width:34.1pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.33.30.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.33.30.5.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.33.30.5.1.1" class="ltx_p" style="width:31.3pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.33.30.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.33.30.6.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.33.30.6.1.1" class="ltx_p" style="width:22.8pt;">②</span>
</span>
</td>
<td id="S2.T1.1.1.33.30.7" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.33.30.7.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.33.30.7.1.1" class="ltx_p" style="width:22.8pt;">-</span>
</span>
</td>
<td id="S2.T1.1.1.33.30.8" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:1pt;padding-bottom:1pt;">
<span id="S2.T1.1.1.33.30.8.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.33.30.8.1.1" class="ltx_p" style="width:34.1pt;">08/2023</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Agent Capability Acquisition</h3>

<div id="S2.SS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p1.1">위의 섹션에서는 주로 LLM이 인간과 같은 작업을 수행할 수 있는 자격을 갖도록 하는 능력을 더 잘 고취시키기 위해 에이전트 아키텍처를 설계하는 방법에 중점을 둔다. 아키텍처는 에이전트의 "하드웨어"로서 기능한다. 그러나, 하드웨어에만 의존하는 것은 효과적인 작업 수행을 달성하기에는 불충분하다. 에이전트는 "소프트웨어" 리소스로 간주될 수 있는 필요한 작업별 능력, 기술 및 경험이 부족할 수 있기 때문이다. 이러한 자원을 에이전트에 장착하기 위해 다양한 전략이 고안되었다. 일반적으로 이러한 전략을 LLM의 미세 조정이 필요한지 여부에 따라 두 가지 그룹으로 분류한다. 이하에서는 이들 각각에 대하여 보다 구체적으로 소개하고자 한다.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p2.1.1">Capability Acquisition with Fine-tuning</span>: A straightforward method to enhance the agent capability for task completion is fine-tuning the agent based on task-dependent datasets. 일반적으로, 데이터 세트는 인간 주석, LLM 생성 또는 실제 애플리케이션으로부터 수집되는 것에 기초하여 구성될 수 있다. 이하에서는 이러한 방법들을 보다 구체적으로 소개한다.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p3.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p3.1.m1.1"><semantics id="S2.SS2.p3.1.m1.1a"><mo id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><ci id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS2.p3.1.1">Fine-tuning with Human Annotated Datasets</span>. 에이전트를 미세 조정하기 위해 인간 주석이 달린 데이터 세트를 활용하는 것은 다양한 응용 시나리오에서 사용할 수 있는 다용도 접근법이다. 이 접근법에서 연구자들은 먼저 주석 작업을 설계한 다음 작업자를 모집하여 작업을 완료한다. 예를 들어, CoH<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib101" title="">101</a>]</cite>에서 저자는 LLM을 인간 가치 및 선호도와 정렬하는 것을 목표로 한다. 인간의 피드백을 단순하고 상징적인 방식으로 활용하는 다른 모델과 달리, 이 방법은 인간의 피드백을 자연어 형태의 상세한 비교 정보로 변환한다. LLM은 이러한 자연어 데이터 세트를 기반으로 직접 미세 조정된다. RET-LLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib114" title="">114</a>]</cite>에서 자연어를 구조화된 기억 정보로 더 잘 변환하기 위해 저자는 인간이 구성한 데이터 세트를 기반으로 LLM을 미세 조정하며, 여기서 각 샘플은 "트리플렛-자연어" 쌍이다. WebShop<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib168" title="">168</a>]</cite>에서 저자는 아마존.com에서 118만 개의 실제 제품을 수집하여 시뮬레이션된 전자 상거래 웹사이트에 게시하며, 이 웹사이트에는 신중하게 설계된 몇 가지 인간 쇼핑 시나리오가 포함되어 있다. 이 웹사이트를 기반으로 저자는 실제 인간 행동 데이터 세트를 수집하기 위해 13명의 직원을 모집한다. 마지막으로, 휴리스틱 규칙, 모방 학습 및 강화 학습에 기반한 세 가지 방법이 이 데이터 세트를 기반으로 학습된다. 비록 저자들이 LLM 기반 에이전트를 미세 조정하지는 않지만, 본 논문에서 제안한 데이터 세트는 웹 쇼핑 분야에서 에이전트의 능력을 향상시킬 수 있는 엄청난 잠재력을 가지고 있다고 믿는다. 에듀챗 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib27" title="">27</a>]</cite>에서 저자는 개방형 질문 답변, 논술 평가, 소크라테스적 교수, 정서적 지지와 같은 LLM의 교육적 기능을 향상시키는 것을 목표로 한다. 다양한 교육 시나리오와 작업을 다루는 인간 주석이 달린 데이터 세트를 기반으로 LLM을 미세 조정한다. 이러한 데이터 세트는 심리학 전문가와 일선 교사가 수동으로 평가하고 선별한다. SWIFTSAGE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib97" title="">97</a>]</cite>는 인간 인지 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib51" title="">51</a>]</cite>의 이중 과정 이론의 영향을 받은 에이전트로 복잡한 상호작용 추론 과제 해결에 효과적이다. 이 에이전트에서 SWIFT 모듈은 인간 주석이 있는 데이터 세트를 사용하여 미세 조정되는 컴팩트 인코더-디코더 언어 모델을 구성한다.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p4.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p4.1.m1.1"><semantics id="S2.SS2.p4.1.m1.1a"><mo id="S2.SS2.p4.1.m1.1.1" xref="S2.SS2.p4.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p4.1.m1.1b"><ci id="S2.SS2.p4.1.m1.1.1.cmml" xref="S2.SS2.p4.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p4.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS2.p4.1.1">Fine-tuning with LLM Generated Datasets</span>. 인간 주석이 달린 데이터 세트를 구축하려면 사람을 모집해야 하는데, 특히 많은 양의 샘플에 주석을 달아야 할 때 비용이 많이 들 수 있다. LLM이 광범위한 작업에서 인간과 유사한 기능을 달성할 수 있다는 점을 고려할 때, 자연스러운 아이디어는 주석 작업을 수행하기 위해 LLM을 사용하는 것이다. 이 방법에서 생성된 데이터 세트는 인간 주석이 달린 데이터 세트만큼 완벽하지 않을 수 있지만 훨씬 저렴하고 더 많은 샘플을 생성하는 데 활용할 수 있다. 예를 들어 ToolBench <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib126" title="">126</a>]</cite>에서 오픈 소스 LLM의 도구 사용 능력을 향상시키기 위해 저자는 RapidAPI Hub에서 49개 범주에 걸쳐 있는 16,464개의 실제 API를 수집한다. 그들은 이러한 API를 사용하여 ChatGPT를 프롬프트하여 단일 도구 및 다중 도구 시나리오를 모두 포함하는 다양한 지침을 생성했다. 구해진 데이터셋을 바탕으로 저자들은 LLaMA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib146" title="">146</a>]</cite>를 미세 조정하고, 도구 측면에서 상당한 성능 향상을 얻었다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib102" title="">102</a>]</cite>에서 에이전트의 사회적 능력을 강화하기 위해 저자는 샌드박스를 설계하고 여러 에이전트를 배치하여 상호 작용합니다. 사회적 질문이 주어지면, 중심 에이전트는 먼저 초기 응답을 생성한다. 그런 다음 피드백을 수집하기 위해 주변 에이전트에 대한 응답을 공유합니다. 피드백과 상세한 설명을 바탕으로 중심 주체는 초기 대응을 수정하여 사회적 규범에 보다 부합하도록 한다. 이 과정에서 저자는 많은 양의 에이전트 소셜 상호작용 데이터를 수집한 다음 LLM을 미세 조정하는 데 활용한다.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p5.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p5.1.m1.1"><semantics id="S2.SS2.p5.1.m1.1a"><mo id="S2.SS2.p5.1.m1.1.1" xref="S2.SS2.p5.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.1.m1.1b"><ci id="S2.SS2.p5.1.m1.1.1.cmml" xref="S2.SS2.p5.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS2.p5.1.1">Fine-tuning with Real-world Datasets</span>. 인간 또는 LLM 주석을 기반으로 데이터 세트를 구축하는 것 외에도 실제 데이터 세트를 직접 사용하여 에이전트를 미세 조정하는 것도 일반적인 전략이다. 예를 들어 MIND2WEB <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>에서 저자는 웹 도메인에서 에이전트 기능을 향상시키기 위해 많은 양의 실제 데이터 세트를 수집한다. 선행 연구와 달리 본 논문에서 제시한 데이터셋은 다양한 작업, 실제 시나리오 및 포괄적인 사용자 상호 작용 패턴을 포괄한다. 특히, 저자는 31개 도메인에 걸쳐 있는 137개의 실제 웹 사이트에서 2,000개 이상의 개방형 작업을 수집한다. 이 데이터 세트를 사용하여 저자는 LLM을 미세 조정하여 영화 검색 및 티켓 예매를 포함한 웹 관련 작업에서 성능을 향상시킵니다. SQL-PALM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib143" title="">143</a>]</cite>에서 연구자들은 스파이더라는 교차 도메인 대규모 텍스트 대 SQL 데이터 세트를 기반으로 PaLM-2를 미세 조정합니다. 획득한 모델은 텍스트 대 SQL 작업에서 상당한 성능 향상을 달성할 수 있습니다.</p>
</div>
<figure id="S2.F4" class="ltx_figure">
<p id="S2.F4.1" class="ltx_p ltx_align_center"><span id="S2.F4.1.1" class="ltx_text ltx_framed ltx_framed_rectangle" style="border-color: #000000;padding:0.0pt;">
<img src="https://ar5iv.labs.arxiv.org/html/2308.11432/assets/x4.png" id="S2.F4.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="155" alt="Refer to caption">
</span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4:</span>Illustration of transition in acquire strategies for model capabilities.</figcaption>
</figure>
<div id="S2.SS2.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S2.SS2.p6.1.1">Capability Acquisition without Fine-tuning</span>: 전통 기계 학습의 시대에 모델 능력은 주로 데이터 세트로부터의 학습에 의해 획득되며, 여기서 지식은 모델 파라미터로 인코딩된다. LLM 시대에 모델 능력은 모델 매개 변수를 훈련/미세 조정하거나 섬세한 프롬프트를 설계함으로써 얻을 수 있다(<em class="ltx_emph ltx_font_italic" id="S2.SS2.p6.1.2">i.e.</em>, 프롬프트 엔지니어). 프롬프트 엔지니어에서는 모델 능력을 향상시키거나 기존 LLM 능력을 발휘하기 위해 프롬프트에 귀중한 정보를 작성해야 한다. 에이전트 시대에 모델 능력은 (1) 모델 미세 조정, (2) 프롬프트 엔지니어 및 (3) 적절한 에이전트 진화 메커니즘 설계(<span class="ltx_text ltx_font_italic" id="S2.SS2.p6.1.3">mechanism engineering</span>)의 세 가지 전략을 기반으로 얻을 수 있다. 기계 공학은 전문 모듈 개발, 새로운 작업 규칙 도입 및 에이전트 기능을 향상시키기 위한 기타 전략을 포함하는 광범위한 개념이다. 모델 능력 획득 전략에 대한 이러한 전환을 명확하게 이해하기 위해 그림 <a class="ltx_ref" href="#S2.F4" title="Figure 4 ‣ 2.2 Agent Capability Acquisition ‣ 2 LLM-based Autonomous Agent Construction ‣ A Survey on Large Language Model based Autonomous Agents"><span class="ltx_text ltx_ref_tag">4</span></a>에서 설명한다. 위의 섹션에서는 미세 조정 전략을 자세히 설명했습니다. 다음에서는 에이전트 능력 획득을 위한 프롬프트 엔지니어링 및 메커니즘 엔지니어링을 소개한다.</p>
</div>
<div id="S2.SS2.p7" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p7.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p7.1.m1.1"><semantics id="S2.SS2.p7.1.m1.1a"><mo id="S2.SS2.p7.1.m1.1.1" xref="S2.SS2.p7.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p7.1.m1.1b"><ci id="S2.SS2.p7.1.m1.1.1.cmml" xref="S2.SS2.p7.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p7.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS2.p7.1.1">Prompting Engineering</span>. 강한 언어 이해 능력으로 인해 사람들은 자연 언어를 사용하여 LLM과 직접 상호 작용할 수 있다. 이것은 에이전트 능력을 향상시키기 위한 새로운 전략, 즉 자연 언어를 사용하여 원하는 능력을 설명한 다음 LLM 행동에 영향을 미치는 프롬프트로 사용할 수 있다. 예를 들어, CoT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib155" title="">155</a>]</cite>에서 에이전트에게 복잡한 태스크 추론 능력을 부여하기 위해, 저자들은 프롬프트에서 중간 추론 단계를 소수의 샷 예제로 제시한다. CoT-SC<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib151" title="">151</a>]</cite> 및 ToT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib169" title="">169</a>]</cite>에서도 유사한 기술이 사용되고 있다. 소셜AGI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib54" title="">54</a>]</cite>에서는 대화에서 에이전트 자기 인식 능력을 향상시키기 위해, 저자들은 청자와 그 자체의 정신 상태에 대한 에이전트 신념으로 LLMs을 촉구하여 생성된 발화를 더 매력적이고 적응적으로 만든다. 또한, 저자들은 또한 청취자의 목표 정신 상태를 통합함으로써 에이전트가 보다 전략적인 계획을 세울 수 있도록 한다. Retroformer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib171" title="">171</a>]</cite>는 에이전트가 과거의 실패에 대한 반사를 생성할 수 있도록 하는 후향적 모델을 제시한다. 반사는 LLM 프롬프트에 통합되어 에이전트의 향후 작업을 안내합니다. 또한, 이 모델은 강화 학습을 활용하여 후향적 모델을 반복적으로 개선하여 LLM 프롬프트를 정제한다.</p>
</div>
<div id="S2.SS2.p8" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p8.1"><math alttext="\bullet" class="ltx_Math" display="inline" id="S2.SS2.p8.1.m1.1"><semantics id="S2.SS2.p8.1.m1.1a"><mo id="S2.SS2.p8.1.m1.1.1" xref="S2.SS2.p8.1.m1.1.1.cmml">∙</mo><annotation-xml encoding="MathML-Content" id="S2.SS2.p8.1.m1.1b"><ci id="S2.SS2.p8.1.m1.1.1.cmml" xref="S2.SS2.p8.1.m1.1.1">∙</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p8.1.m1.1c">\bullet</annotation></semantics></math> <span class="ltx_text ltx_font_italic" id="S2.SS2.p8.1.1">Mechanism Engineering</span>. 모델 미세 조정 및 신속한 엔지니어링과는 달리 메커니즘 엔지니어링은 에이전트 기능을 향상시키는 독특한 전략이다. 다음은 메커니즘 엔지니어링을 위한 몇 가지 대표적인 방법을 제시한다.</p>
</div>
<div id="S2.SS2.p9" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p9.1">(1) <span class="ltx_text ltx_font_italic" id="S2.SS2.p9.1.1">Trial-and-error. </span> 이 방법에서는 먼저 에이전트가 액션을 수행하고, 이어서 미리 정의된 비평을 호출하여 액션을 판단한다. 행위가 불만족스러운 것으로 간주되면, 행위자는 비평가의 피드백을 통합함으로써 반응한다. RAH<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib140" title="">140</a>]</cite>에서 에이전트는 추천 시스템에서 사용자 보조 역할을 한다. 에이전트의 중요한 역할 중 하나는 인간의 행동을 시뮬레이션하고 사용자를 대신하여 응답을 생성하는 것이다. 이 목적을 달성하기 위해 에이전트는 먼저 예측된 응답을 생성한 다음 실제 인간 피드백과 비교한다. 예측된 반응과 실제 인간의 피드백이 다른 경우, 비평가는 실패 정보를 생성하고, 이는 이후에 에이전트의 다음 행동에 통합된다. DEPS<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib154" title="">154</a>]</cite>에서 에이전트는 주어진 작업을 수행하기 위한 계획을 먼저 설계한다. 계획 실행 프로세스에서, 액션이 실패하면, 설명자는 실패의 원인을 설명하는 구체적인 세부사항을 생성한다. 그런 다음 에이전트가 이 정보를 통합하여 계획을 재설계합니다. RoCo<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib108" title="">108</a>]</cite>에서 에이전트는 먼저 멀티 로봇 협업 작업에서 각 로봇에 대한 서브 작업 계획과 3D 웨이포인트의 경로를 제안한다. 그런 다음 계획 및 웨이포인트는 충돌 감지 및 역기구학과 같은 환경 검사 세트에 의해 검증된다. 검사에 실패하면 피드백이 각 에이전트의 프롬프트에 추가되고 다른 대화 상자가 시작됩니다. 에이전트는 LLM을 사용하여 모든 검증을 통과할 때까지 계획 및 웨이포인트를 논의하고 개선합니다. PREFER <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib173" title="">173</a>]</cite>에서 에이전트는 먼저 데이터의 하위 집합에 대한 성능을 평가한다. 특정 예제를 해결하지 못하면 LLMs를 활용하여 실패 이유를 반영한 피드백 정보를 생성한다. 이러한 피드백에 기초하여 에이전트는 자신의 행동을 반복적으로 정제함으로써 스스로 개선한다.</p>
</div>
<div id="S2.SS2.p10" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p10.1">(2) <span class="ltx_text ltx_font_italic" id="S2.SS2.p10.1.1">Crowd-sourcing. <span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib35" title="">35</a>]</cite>에서 저자들은 에이전트의 능력을 향상시키기 위해 군중의 지혜를 활용하는 토론 메커니즘을 설계한다. 우선, 서로 다른 에이전트는 주어진 질문에 대해 별도의 응답을 제공한다. 응답이 일관되지 않으면 다른 에이전트의 솔루션을 통합하고 업데이트된 응답을 제공하라는 메시지가 표시됩니다. 이러한 반복적인 과정은 최종 합의된 답변에 도달할 때까지 계속된다. 이 방법은 다른 에이전트의 의견을 이해하고 통합하여 각 에이전트의 능력을 향상시킨다.</p>
</div>
<div id="S2.SS2.p11" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p11.1">(3) <span class="ltx_text ltx_font_italic" id="S2.SS2.p11.1.1">Experience Accumulation. </span> GITM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite>에서 에이전트는 처음에 작업을 해결하는 방법을 알지 못한다. 그런 다음 탐색을 수행하고 작업을 성공적으로 수행하면 이 작업에 사용된 작업이 에이전트 메모리에 저장됩니다. 향후 에이전트가 유사한 태스크를 만나면 관련 메모리들을 추출하여 현재 태스크를 완성한다. 이 과정에서 향상된 에이전트 기능은 특별히 설계된 메모리 축적 및 활용 메커니즘에서 비롯된다. Voyager<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>에서 저자들은 에이전트에 스킬 라이브러리를 장착하고 라이브러리의 각 스킬은 실행 코드로 표현된다. 에이전트-환경 상호작용 과정에서 각 스킬에 대한 코드는 환경 피드백과 에이전트 자체 검증 결과에 따라 반복적으로 정제될 것이다. 실행 기간 후에, 에이전트는 스킬 라이브러리에 액세스함으로써 상이한 태스크들을 효율적으로 성공적으로 완료할 수 있다. MemPrompt <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib106" title="">106</a>]</cite>에서 사용자는 에이전트의 문제 해결 의도에 관한 자연어 피드백을 요청받고, 이 피드백은 메모리에 저장된다. 에이전트가 유사한 태스크들을 만날 때, 더 적합한 응답들을 생성하기 위해 관련 메모리들을 검색하려고 시도한다.</p>
</div>
<div id="S2.SS2.p12" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p12.1">(4) <span class="ltx_text ltx_font_italic" id="S2.SS2.p12.1.1">Self-driven Evolution. </span> LMA3<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>]</cite>에서 에이전트는 자율적으로 스스로 목표를 설정할 수 있으며, 환경을 탐색하고 보상 함수로부터 피드백을 받아 점차 능력을 향상시킬 수 있다. 이 메커니즘에 따라 에이전트는 지식을 습득하고 자신의 선호도에 따라 능력을 개발할 수 있다. SALLM-MS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib116" title="">116</a>]</cite>에서 GPT-4와 같은 고급 대형 언어 모델을 다중 에이전트 시스템에 통합함으로써 에이전트는 복잡한 작업을 적응하고 수행할 수 있으며 고급 통신 기능을 보여줌으로써 환경과의 상호 작용에서 자체 주도 진화를 실현할 수 있다. CLMTWA<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib132" title="">132</a>]</cite>에서는 큰 언어 모델을 교사로 사용하고 약한 언어 모델을 학생으로 사용함으로써 교사는 마음 이론을 통해 학생의 추론 능력을 향상시키기 위해 자연어 설명을 생성하고 전달할 수 있다. 교사는 또한 개입의 기대 효용을 바탕으로 학생에 대한 설명을 개인화하고 필요할 때만 개입할 수 있다. NLSOM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib185" title="">185</a>]</cite>에서는 서로 다른 에이전트가 자연어를 통해 소통하고 협업하여 하나의 에이전트가 해결할 수 없는 작업을 해결한다. 이는 다수의 에이전트들 간의 정보와 지식의 교환을 활용한 자기주도적 학습의 한 형태라고 볼 수 있다. 그러나, NLSOM은 LMA3, SALLM-MS, CLMTWA 등의 다른 모델과는 달리, 태스크 요구 사항과 다른 에이전트 또는 환경으로부터의 피드백에 기초하여 에이전트 목표, 역할, 태스크 및 관계를 동적으로 조정할 수 있다.</p>
</div>
<div id="Thmremarkx5" class="ltx_theorem ltx_theorem_remark">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmremarkx5.1.1.1" class="ltx_text ltx_font_italic">Remark</span></span><span id="Thmremarkx5.2.2" class="ltx_text ltx_font_italic">.</span>
</h6>
<div id="Thmremarkx5.p1" class="ltx_para">
<p class="ltx_p" id="Thmremarkx5.p1.1">앞서 언급한 에이전트 능력 획득 전략을 비교한 결과, 미세 조정 방법은 모델 파라미터를 조정하여 에이전트 능력을 향상시키며, 이는 많은 양의 태스크 특정 지식을 통합할 수 있지만 오픈 소스 LLM에만 적합하다는 것을 알 수 있다. 미세 조정이 없는 방법은 일반적으로 정교한 프롬프트 전략이나 메커니즘 엔지니어링을 기반으로 에이전트 기능을 향상시킵니다. 오픈 소스 및 폐쇄 소스 LLM 모두에 사용할 수 있습니다. 그러나 LLM의 입력 컨텍스트 창의 한계로 인해 너무 많은 태스크 정보를 통합할 수 없다. 또한 프롬프트와 메커니즘의 설계 공간이 매우 커서 최적의 솔루션을 찾기가 쉽지 않다.</p>
</div>
</div>
<div id="S2.SS2.p13" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S2.SS2.p13.1">위의 섹션에서는 LLM 기반 에이전트의 구성을 자세히 설명했으며 아키텍처 설계와 능력 획득을 포함한 두 가지 측면에 중점을 둔다. 우리는 표 <a class="ltx_ref" href="#S2.T1" title="Table 1 ‣ 2.1.4 Action Module ‣ 2.1 Agent Architecture Design ‣ 2 LLM-based Autonomous Agent Construction ‣ A Survey on Large Language Model based Autonomous Agents"><span class="ltx_text ltx_ref_tag">1</span></a>에서 기존 작업과 위의 분류법 사이의 대응 관계를 제시한다. 완전성을 위해 LLM 기반 에이전트를 명시적으로 언급하지 않지만 이 영역과 매우 관련이 있는 여러 연구도 통합했다는 점에 유의해야 한다.</p>
</div>
<figure id="S2.F5" class="ltx_figure">
<p id="S2.F5.1" class="ltx_p ltx_align_center"><span id="S2.F5.1.1" class="ltx_text ltx_framed ltx_framed_rectangle" style="border-color: #000000;padding:0.0pt;">
<img src="https://ar5iv.labs.arxiv.org/html/2308.11432/assets/x5.png" id="S2.F5.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="137" alt="Refer to caption">
</span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5:</span>The applications (left) and evaluation strategies (right) of LLM-based agents.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>LLM-based Autonomous Agent Application</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.p1.1">강력한 언어 이해, 복잡한 과제 추론, 상식 이해 능력으로 인해 LLM 기반 자율 에이전트는 여러 영역에 영향을 미칠 수 있는 상당한 잠재력을 보여주었다. 이 섹션에서는 이전 연구를 사회 과학, 자연 과학 및 공학의 세 가지 별개의 영역에서 응용 프로그램에 따라 분류하는 간결한 요약을 제공한다(글로벌 개요는 그림 <a class="ltx_ref" href="#S2.F5" title="Figure 5 ‣ 2.2 Agent Capability Acquisition ‣ 2 LLM-based Autonomous Agent Construction ‣ A Survey on Large Language Model based Autonomous Agents"><span class="ltx_text ltx_ref_tag">5</span></a>의 왼쪽 부분을 참조).</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Social Science</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p1.1">사회과학은 과학의 한 분야로, 사회와 그 사회 내의 개인들 간의 관계에 대한 연구에 전념하고 있다<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">‡</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‡</sup><span class="ltx_tag ltx_tag_note">‡</span>https://en.wikipedia.org/wiki/Social_science</span></span></span> LLM 기반 자율 에이전트는 인상적인 인간 유사 이해, 사고 및 과제 해결 능력을 활용하여 이 영역을 촉진할 수 있다. 이하에서는 LLM 기반 자율 에이전트의 영향을 받을 수 있는 몇 가지 핵심 영역에 대해 논의한다.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">Psychology</span>: The domain of psychology, LLM-based agents can be leveraged for conducting simulation experiments, providing mental health support and so on <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>, <a class="ltx_ref" href="#bib.bib3" title="">3</a>, <a class="ltx_ref" href="#bib.bib105" title="">105</a>, <a class="ltx_ref" href="#bib.bib187" title="">187</a>]</cite>. 예를 들어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>]</cite>에서 저자는 프로필이 다른 LLM을 할당하고 심리 실험을 완료한다. 그 결과, 저자들은 LLM이 실제 인간 연구의 결과와 일치하는 결과를 생성할 수 있음을 발견했다. 또한, 더 큰 모델은 일반적으로 더 작은 모델보다 더 충실한 시뮬레이션 결과를 제공할 수 있다. 흥미로운 발견은 많은 실험에서 ChatGPT 및 GPT-4와 같은 모델이 다운스트림 애플리케이션에 영향을 미칠 수 있는 너무 완벽한 추정치("초정밀 왜곡")를 제공할 수 있다는 것이다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib105" title="">105</a>]</cite>에서 저자들은 정신 건강 지원을 위한 LLM 기반 대화 에이전트의 효과를 체계적으로 분석한다. 그들은 레딧으로부터 120개의 게시물을 수집하고, 그러한 에이전트가 사용자가 불안, 사회적 고립 및 요구에 따른 우울증에 대처하는 데 도움이 될 수 있다는 것을 발견한다. 동시에, 그들은 또한 에이전트가 때때로 유해한 내용물을 생성할 수 있다는 것을 발견합니다.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">Political Science and Economy</span>: LLM 기반 에이전트는 정치학 및 경제학을 연구하는 데에도 활용될 수 있습니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib5" title="">5</a>, <a class="ltx_ref" href="#bib.bib187" title="">187</a>, <a class="ltx_ref" href="#bib.bib65" title="">65</a>]</cite>. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib5" title="">5</a>]</cite>에서 LLM 기반 에이전트는 이데올로기 탐지 및 투표 패턴 예측에 활용된다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib187" title="">187</a>]</cite>에서 저자는 LLM 기반 에이전트의 도움을 통해 정치 연설의 담론 구조와 설득 요소를 이해하는 데 중점을 둔다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib65" title="">65</a>]</cite>에서 LLM 기반 에이전트는 모의 시나리오에서 인간의 경제 행동을 탐구하기 위해 재능, 선호도 및 성격과 같은 특정 특성을 제공한다.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">Social Simulation</span>: 이전에 인간 사회와 실험을 수행하는 것은 종종 비싸고, 비윤리적이거나, 심지어 실행 불가능합니다. LLM이 발전함에 따라 많은 사람들이 LLM 기반 에이전트를 사용하여 유해 정보의 전파와 같은 사회 현상을 시뮬레이션하기 위해 가상 환경을 구축하려고 한다. 예를 들어, Social Simulacra <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib122" title="">122</a>]</cite>는 온라인 소셜 커뮤니티를 시뮬레이션하고 에이전트 기반 시뮬레이션을 활용하여 의사 결정자가 커뮤니티 규제를 개선할 수 있는 가능성을 탐구한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib91" title="">91</a>, <a class="ltx_ref" href="#bib.bib86" title="">86</a>]</cite>는 소셜 네트워크에서 LLM 기반 에이전트의 다양한 행동 특성의 잠재적 영향을 조사한다. 생성 에이전트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib121" title="">121</a>]</cite>와 AgentSims<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>는 가상 마을에 여러 에이전트를 구성하여 인간의 일상을 시뮬레이션한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib83" title="">83</a>]</cite>는 LLM 기반 에이전트를 사용하여 아동 발달 과정에서 기본적인 사회적 인지 기술을 시뮬레이션하고 조사한다. S<sup class="ltx_sup" id="S3.SS1.p4.1.2">3</sup> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite>는 정보, 감정 및 태도의 전파에 초점을 맞춘 소셜 네트워크 시뮬레이터를 구축한다. CGMI<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib75" title="">75</a>]</cite>는 멀티 에이전트 시뮬레이션을 위한 프레임워크이다. CGMI는 트리 구조를 통해 에이전트의 개성을 유지하고 인지 모델을 구성한다. 저자들은 CGMI를 사용하여 교실 시나리오를 시뮬레이션했다.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p5.1.1">Jurisprudence</span>: LLM 기반 에이전트는 법적 의사 결정 프로세스에서 보조 역할을 할 수 있으며, 보다 정보에 입각한 판단을 촉진합니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>, <a class="ltx_ref" href="#bib.bib61" title="">61</a>]</cite>. Blind Judgement <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib61" title="">61</a>]</cite>는 여러 언어 모델을 사용하여 여러 판사의 의사 결정 과정을 시뮬레이션한다. 다양한 의견을 수렴하고 투표 메커니즘을 통해 결과를 통합한다. ChatLaw<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>]</cite>는 LLM을 기반으로 한 중국의 저명한 법률 모델이다. 환각 문제를 완화하기 위한 데이터베이스와 키워드 검색 전략을 모두 지원한다. 또한, 이 모델은 참조 부정확성의 영향을 완화하여 LLM의 능력을 향상시키기 위해 자기 주의 메커니즘을 사용한다.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS1.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p6.1.1">Research Assistant</span>: 특정 도메인 외에도 LLM 기반 에이전트는 일반 사회 과학 연구 보조자 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib6" title="">6</a>, <a class="ltx_ref" href="#bib.bib187" title="">187</a>]</cite>로도 사용할 수 있다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib187" title="">187</a>]</cite>에서 LLM 기반 에이전트는 연구자가 논문 초록 생성, 키워드 추출, 스크립트 생성 등 다양한 작업을 지원하는 데 사용된다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib6" title="">6</a>]</cite>에서 LLM 기반 에이전트는 글쓰기 보조 역할을 하며, 사회 과학자를 위한 새로운 연구 조사를 식별할 수 있는 능력을 가지고 있다.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Natural Science</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p1.1">자연과학은 관찰과 실험의 경험적 증거에 기초한 자연 현상의 설명, 이해 및 예측에 관한 과학의 분야 중 하나이다. LLM이 번창함에 따라 자연 과학에서 LLM 기반 에이전트의 적용이 점점 더 대중화되고 있다. 다음에서는 LLM 기반 에이전트가 중요한 역할을 할 수 있는 많은 대표적인 영역을 제시한다.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Documentation and Data Management</span>: 자연 과학 연구는 종종 상당한 양의 문헌의 수집, 조직 및 합성을 포함하며, 이는 시간과 인적 자원의 상당한 헌신을 필요로 한다. LLM 기반 에이전트는 텍스트 처리를 위해 인터넷 및 데이터베이스와 같은 도구를 사용하고 언어 이해에 강한 능력을 보여주었다. 이러한 기능은 에이전트가 문서화 및 데이터 관리 관련 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib9" title="">9</a>, <a class="ltx_ref" href="#bib.bib79" title="">79</a>, <a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite>에서 뛰어난 성능을 발휘하도록 합니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib9" title="">9</a>]</cite>에서 에이전트는 인터넷 정보를 효율적으로 질의하고 활용하여 질의 응답, 실험 계획 등의 작업을 완료할 수 있다. ChatMOF<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib79" title="">79</a>]</cite>는 LLMs를 활용하여 인간이 쓴 텍스트 기술에서 중요한 정보를 추출한다. 그런 다음 금속 유기 골격의 특성과 구조를 예측하기 위한 관련 도구를 적용하는 계획을 수립한다. ChemCrow<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite>는 화학 관련 데이터베이스를 활용하여 화합물 표현의 정밀도를 검증하고 잠재적으로 위험한 물질을 식별한다. 이 기능은 관련된 데이터의 정확성을 보장하여 과학적 문의의 신뢰성과 포괄성을 향상시킵니다.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">Experiment Assistant</span>: LLM 기반 에이전트는 독립적으로 실험을 수행할 수 있는 능력을 가지고 있어 연구 프로젝트에서 과학자를 지원하기 위한 귀중한 도구를 만듭니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib9" title="">9</a>, <a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite>. 예를 들어, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib9" title="">9</a>]</cite>는 과학 실험의 설계, 계획 및 실행을 자동화하기 위해 LLM을 활용하는 혁신적인 에이전트 시스템을 소개한다. 이 시스템은 실험 목표를 입력으로 제공하면 인터넷에 접속하여 관련 문서를 검색하여 필요한 정보를 수집한다. 이후 파이썬 코드를 활용하여 필수적인 계산을 수행하고 다음과 같은 실험을 수행한다. ChemCrow<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite>는 연구자의 화학 연구를 돕기 위해 특별히 설계된 17개의 신중하게 개발된 도구를 통합한다. 입력 목표가 수신되면 ChemCrow는 실험 절차에 대한 귀중한 권장 사항을 제공하는 동시에 제안된 실험과 관련된 잠재적인 안전 위험을 강조한다.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Natural Science Education</span>: LLM 기반 에이전트는 인간과 유창하게 통신할 수 있으며, 종종 에이전트 기반 교육 도구 개발에 활용됩니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib9" title="">9</a>, <a class="ltx_ref" href="#bib.bib145" title="">145</a>, <a class="ltx_ref" href="#bib.bib34" title="">34</a>, <a class="ltx_ref" href="#bib.bib19" title="">19</a>]</cite>. 예를 들어, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib9" title="">9</a>]</cite>는 실험 설계, 방법론 및 분석의 학습을 용이하게 하기 위해 에이전트 기반 교육 시스템을 개발한다. 이러한 시스템의 목적은 학생들의 비판적 사고와 문제 해결 능력을 향상시키는 동시에 과학적 원리에 대한 더 깊은 이해를 촉진하는 것이다. 수학 에이전트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib145" title="">145</a>]</cite>는 연구자들이 수학 문제를 탐구, 발견, 해결 및 증명하는 데 도움을 줄 수 있다. 또한, 인간과 소통하고 수학을 이해하고 사용하는 데 도움이 될 수 있습니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib34" title="">34</a>]</cite>는 CodeX<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib19" title="">19</a>]</cite>의 기능을 활용하여 대학 수준의 수학 문제를 자동으로 해결하고 설명하며, 이는 학생과 연구자를 가르치는 교육 도구로 활용될 수 있다. CodeHelp <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib95" title="">95</a>]</cite>는 프로그래밍을 위한 교육 에이전트이다. 강좌별 키워드 설정, 학생 질의 모니터링, 시스템에 피드백 제공 등 많은 유용한 기능을 제공합니다. EduChat <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib27" title="">27</a>]</cite>는 교육 영역을 위해 특별히 설계된 LLM 기반 에이전트이다. 대화를 통해 교사, 학생, 학부모에게 개인화되고 공평하며 공감적인 교육적 지원을 제공한다. 또한 다양한 시스템 프롬프트를 활용함으로써 환각의 문제를 효과적으로 해결하고 실제 교육 시나리오에 원활하게 적응할 수 있다. FreeText<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib109" title="">109</a>]</cite>는 LLMs를 활용하여 개방형 질문에 대한 학생들의 반응을 자동으로 평가하고 피드백을 제공하는 에이전트이다.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 2:</span>LLM 기반 자율 에이전트의 대표적인 애플리케이션.</figcaption>
<div id="S3.T2.1" class="ltx_inline-block ltx_transformed_outer" style="width:404.3pt;height:10962.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-12.9pt,349.9pt) scale(0.94,0.94) ;">
<table id="S3.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.1.1.2.1" class="ltx_tr">
<th id="S3.T2.1.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.2.1.1.1.1" class="ltx_p" style="width:62.6pt;"></span>
</span>
</th>
<th id="S3.T2.1.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.2.1.2.1.1" class="ltx_p" style="width:142.3pt;">Domain</span>
</span>
</th>
<th id="S3.T2.1.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.2.1.3.1.1" class="ltx_p" style="width:179.3pt;">Work</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.1.3.1" class="ltx_tr">
<th id="S3.T2.1.1.3.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.3.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.3.1.1.1.1" class="ltx_p" style="width:62.6pt;"></span>
</span>
</th>
<td id="S3.T2.1.1.3.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.3.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.3.1.2.1.1" class="ltx_p" style="width:142.3pt;">Psychology</span>
</span>
</td>
<td id="S3.T2.1.1.3.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.3.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.3.1.3.1.1" class="ltx_p">TE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, Akata et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, Ziems et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib187" title="" class="ltx_ref">187</a>]</cite>, Ma et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.4.2" class="ltx_tr">
<th id="S3.T2.1.1.4.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.4.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.4.2.1.1.1" class="ltx_p" style="width:62.6pt;"><span id="S3.T2.1.1.4.2.1.1.1.1" class="ltx_text">Social Science</span></span>
</span>
</th>
<td id="S3.T2.1.1.4.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.4.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.4.2.2.1.1" class="ltx_p" style="width:142.3pt;">Political Science and Economy</span>
</span>
</td>
<td id="S3.T2.1.1.4.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.4.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.4.2.3.1.1" class="ltx_p">Out of One&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, Horton&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, Ziems et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib187" title="" class="ltx_ref">187</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.2.1.1" class="ltx_p" style="width:62.6pt;"></span>
</span>
</th>
<td id="S3.T2.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.3.1.1" class="ltx_p" style="width:142.3pt;">Social Simulation</span>
</span>
</td>
<td id="S3.T2.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.1.1.1.1" class="ltx_p">Social Simulacra&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite>, Generative Agents&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite>, SocialAI School&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>, AgentSims&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>, S<sup id="S3.T2.1.1.1.1.1.1.1" class="ltx_sup">3</sup>&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, Williams et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib156" title="" class="ltx_ref">156</a>]</cite>, Li et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>, Chao et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.5.3" class="ltx_tr">
<th id="S3.T2.1.1.5.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.5.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.5.3.1.1.1" class="ltx_p" style="width:62.6pt;"></span>
</span>
</th>
<td id="S3.T2.1.1.5.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.5.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.5.3.2.1.1" class="ltx_p" style="width:142.3pt;">Jurisprudence</span>
</span>
</td>
<td id="S3.T2.1.1.5.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.5.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.5.3.3.1.1" class="ltx_p">ChatLaw&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, Blind Judgement&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.6.4" class="ltx_tr">
<th id="S3.T2.1.1.6.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.6.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.6.4.1.1.1" class="ltx_p" style="width:62.6pt;"></span>
</span>
</th>
<td id="S3.T2.1.1.6.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.6.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.6.4.2.1.1" class="ltx_p" style="width:142.3pt;">Research Assistant</span>
</span>
</td>
<td id="S3.T2.1.1.6.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.6.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.6.4.3.1.1" class="ltx_p">Ziems et al&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib187" title="" class="ltx_ref">187</a>]</cite>, Bail et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.7.5" class="ltx_tr">
<th id="S3.T2.1.1.7.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.7.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.7.5.1.1.1" class="ltx_p" style="width:62.6pt;"></span>
</span>
</th>
<td id="S3.T2.1.1.7.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.7.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.7.5.2.1.1" class="ltx_p" style="width:142.3pt;">Documentation, Data Managent</span>
</span>
</td>
<td id="S3.T2.1.1.7.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.7.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.7.5.3.1.1" class="ltx_p">ChemCrow&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, Boiko et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, ChatMOF&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.8.6" class="ltx_tr">
<th id="S3.T2.1.1.8.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.8.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.8.6.1.1.1" class="ltx_p" style="width:62.6pt;"><span id="S3.T2.1.1.8.6.1.1.1.1" class="ltx_text">Natural Science</span></span>
</span>
</th>
<td id="S3.T2.1.1.8.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.8.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.8.6.2.1.1" class="ltx_p" style="width:142.3pt;">Experiment Assistant</span>
</span>
</td>
<td id="S3.T2.1.1.8.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.8.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.8.6.3.1.1" class="ltx_p">ChemCrow&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, Boiko et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, Grossmann et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.9.7" class="ltx_tr">
<th id="S3.T2.1.1.9.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.9.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.9.7.1.1.1" class="ltx_p" style="width:62.6pt;"></span>
</span>
</th>
<td id="S3.T2.1.1.9.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.9.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.9.7.2.1.1" class="ltx_p" style="width:142.3pt;">Natural Science Education</span>
</span>
</td>
<td id="S3.T2.1.1.9.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.9.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.9.7.3.1.1" class="ltx_p">ChemCrow&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, NLSOM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib185" title="" class="ltx_ref">185</a>]</cite>, CodeHelp&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>, Boiko et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, MathAgent&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib145" title="" class="ltx_ref">145</a>]</cite>, AutoGen&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib158" title="" class="ltx_ref">158</a>]</cite>, Drori et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, Grossmann et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.10.8" class="ltx_tr">
<th id="S3.T2.1.1.10.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.10.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.10.8.1.1.1" class="ltx_p" style="width:62.6pt;"></span>
</span>
</th>
<td id="S3.T2.1.1.10.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.10.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.10.8.2.1.1" class="ltx_p" style="width:142.3pt;">Civil Engineering</span>
</span>
</td>
<td id="S3.T2.1.1.10.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.10.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.10.8.3.1.1" class="ltx_p">IGLU&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.11.9" class="ltx_tr">
<th id="S3.T2.1.1.11.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.11.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.11.9.1.1.1" class="ltx_p" style="width:62.6pt;"><span id="S3.T2.1.1.11.9.1.1.1.1" class="ltx_text">Engineering</span></span>
</span>
</th>
<td id="S3.T2.1.1.11.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.11.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.11.9.2.1.1" class="ltx_p" style="width:142.3pt;">CS &amp; SE</span>
</span>
</td>
<td id="S3.T2.1.1.11.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.11.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.11.9.3.1.1" class="ltx_p">ToolBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib126" title="" class="ltx_ref">126</a>]</cite>, LIBRO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>, ChatDev&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite>, MetaGPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>, SCG&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, RCI&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>, RestGPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib142" title="" class="ltx_ref">142</a>]</cite>, Self-collaboration&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, SQL-PALM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib143" title="" class="ltx_ref">143</a>]</cite>, RAH&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib140" title="" class="ltx_ref">140</a>]</cite>, DB-GPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib182" title="" class="ltx_ref">182</a>]</cite>, RecMind&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib152" title="" class="ltx_ref">152</a>]</cite>, ChatEDA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>, InteRecAgent&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib165" title="" class="ltx_ref">165</a>]</cite>, PentestGPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>, CodeHelp&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>, SmolModels&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>, DemoGPT&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, GPTEngineer&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.12.10" class="ltx_tr">
<th id="S3.T2.1.1.12.10.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.12.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.12.10.1.1.1" class="ltx_p" style="width:62.6pt;"></span>
</span>
</th>
<td id="S3.T2.1.1.12.10.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.12.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.12.10.2.1.1" class="ltx_p" style="width:142.3pt;">Industrial Automation</span>
</span>
</td>
<td id="S3.T2.1.1.12.10.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.12.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.12.10.3.1.1" class="ltx_p">GPT4IA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib161" title="" class="ltx_ref">161</a>]</cite>, IELLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>, TaskMatrix.AI&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite></span>
</span>
</td>
</tr>
<tr id="S3.T2.1.1.13.11" class="ltx_tr">
<th id="S3.T2.1.1.13.11.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_row ltx_border_bb ltx_border_r" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.13.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.13.11.1.1.1" class="ltx_p" style="width:62.6pt;"></span>
</span>
</th>
<td id="S3.T2.1.1.13.11.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.13.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.13.11.2.1.1" class="ltx_p" style="width:142.3pt;">Robotics &amp; Embodied AI</span>
</span>
</td>
<td id="S3.T2.1.1.13.11.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S3.T2.1.1.13.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.1.1.13.11.3.1.1" class="ltx_p">Planner-Actor-Reporter&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>, Dialogue Shaping&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib181" title="" class="ltx_ref">181</a>]</cite>, DECKARD&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite>, TaPA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib160" title="" class="ltx_ref">160</a>]</cite>, Inner Monologue&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>, Language-planner&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>, E2WM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib162" title="" class="ltx_ref">162</a>]</cite>, ProAgent&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib172" title="" class="ltx_ref">172</a>]</cite>, Voyager&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>]</cite>, GITM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib184" title="" class="ltx_ref">184</a>]</cite>, LLM4RL&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>, PET&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib159" title="" class="ltx_ref">159</a>]</cite>, REMEMBERER&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib174" title="" class="ltx_ref">174</a>]</cite>, DEPS&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite>,
Unified Agent&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, SayCan&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, LMMWM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib162" title="" class="ltx_ref">162</a>]</cite>, TidyBot&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib157" title="" class="ltx_ref">157</a>]</cite>, RoCo&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>, SayPlan&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib129" title="" class="ltx_ref">129</a>]</cite></span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Engineering</h3>

<div id="S3.SS3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS3.p1.1">LLM 기반 자율 에이전트는 공학 연구 및 응용 프로그램을 지원하고 향상시키는 데 큰 잠재력을 보여주었다. 이 섹션에서는 몇 가지 주요 엔지니어링 영역에서 LLM 기반 에이전트의 응용 프로그램을 검토하고 요약한다.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.1">Civil Engineering</span>: 토목 공학에서 LLM 기반 에이전트를 사용하여 건물, 교량, 댐, 도로 등과 같은 복잡한 구조를 설계하고 최적화할 수 있다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib110" title="">110</a>]</cite>는 3D 시뮬레이션 환경에서 인간 설계자와 에이전트가 협력하여 구조를 구성하는 대화형 프레임워크를 제안한다. 대화형 에이전트는 자연어 명령어를 이해하고, 블록을 배치하고, 혼동을 감지하고, 명확성을 찾고, 인간 피드백을 통합할 수 있어 공학 설계에서 인간-AI 협업의 가능성을 보여준다.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p3.1.1">Computer Science &amp; Software Engineering</span>: 컴퓨터 과학 및 소프트웨어 공학 분야에서 LLM 기반 에이전트는 코딩, 테스팅, 디버깅 및 문서 생성을 자동화하는 잠재력을 제공합니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib126" title="">126</a>, <a class="ltx_ref" href="#bib.bib124" title="">124</a>, <a class="ltx_ref" href="#bib.bib64" title="">64</a>, <a class="ltx_ref" href="#bib.bib33" title="">33</a>, <a class="ltx_ref" href="#bib.bib37" title="">37</a>, <a class="ltx_ref" href="#bib.bib48" title="">48</a>, <a class="ltx_ref" href="#bib.bib45" title="">45</a>]</cite>. ChatDev <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib124" title="">124</a>]</cite>는 소프트웨어 개발 수명 주기를 완료하기 위해 여러 에이전트 역할이 자연어 대화를 통해 소통하고 협업하는 엔드 투 엔드 프레임워크를 제안한다. 이 프레임워크는 실행 가능한 소프트웨어 시스템의 효율적이고 비용 효율적인 생성을 보여준다. ToolBench <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib126" title="">126</a>]</cite>는 코드 자동 완성, 코드 추천 등의 작업에 사용될 수 있다. MetaGPT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>는 제품 관리자, 건축가, 프로젝트 관리자 및 엔지니어와 같은 여러 역할을 추상화하여 코드 생성 프로세스를 감독하고 최종 출력 코드의 품질을 향상시킵니다. 이를 통해 저가의 소프트웨어 개발이 가능하다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>는 LLMs를 이용한 코드 생성을 위한 자체 협업 프레임워크를 제시한다. 이 프레임워크에서 다중 LLM은 특정 하위 작업에 대해 별개의 "전문가"로 가정된다. 그들은 지정된 지침에 따라 협력하고 상호 작용하며 서로의 작업을 용이하게 하는 가상 팀을 구성합니다. 궁극적으로 가상 팀은 인간의 개입 없이 코드 생성 작업을 협력적으로 해결합니다. LLIFT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib89" title="">89</a>]</cite>는 LLMs를 사용하여 정적 분석을 수행하는 데 도움이 되며, 특히 잠재적인 코드 취약성을 식별합니다. 이 접근법은 정확성과 확장성 사이의 트레이드오프를 효과적으로 관리한다. ChatEDA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib63" title="">63</a>]</cite>는 태스크 기획, 스크립트 생성, 실행을 통합하여 디자인 프로세스를 간소화하기 위해 전자 디자인 자동화(EDA)를 위해 개발된 에이전트이다. CodeHelp <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib95" title="">95</a>]</cite>는 학생과 개발자가 코드를 디버깅하고 테스트하는 데 도움이 되도록 설계된 에이전트입니다. 오류 메시지에 대한 자세한 설명을 제공하고 잠재적인 수정 사항을 제안하며 코드의 정확성을 보장하는 것이 특징입니다. PENTESTGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib29" title="">29</a>]</cite>는 LLMs 기반의 침투 테스트 툴로, 공통 취약점을 효과적으로 식별하고 소스 코드를 해석하여 익스플로잇을 개발할 수 있다. DB-GPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib182" title="">182</a>]</cite>는 LLMs의 기능을 활용하여 데이터베이스의 이상 현상의 잠재적인 근본 원인을 체계적으로 평가한다. 사고 트리의 구현을 통해 DB-GPT는 LLM이 현재 단계가 실패로 판명될 경우 이전 단계로 역추적할 수 있도록 하여 진단 프로세스의 정확도를 향상시킨다.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p4.1.1">Industrial Automation</span>: 산업 자동화 분야에서 LLM 기반 에이전트는 생산 프로세스의 지능적인 계획 및 제어를 달성하기 위해 사용될 수 있다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib161" title="">161</a>]</cite>는 유연한 생산 요구를 수용하기 위해 대용량 언어 모델(LLM)과 디지털 트윈 시스템을 통합하는 새로운 프레임워크를 제안한다. 프레임워크는 신속한 엔지니어링 기술을 활용하여 디지털 트윈이 제공한 정보를 기반으로 특정 작업에 적응할 수 있는 LLM 에이전트를 생성한다. 이러한 에이전트는 일련의 원자 기능 및 기술을 조정하여 자동화 피라미드 내에서 다양한 수준에서 생산 작업을 완료할 수 있다. 이 연구는 LLM을 산업 자동화 시스템에 통합하여 보다 민첩하고 유연하며 적응적인 생산 프로세스를 위한 혁신적인 솔루션을 제공할 수 있는 가능성을 보여준다. IELLM<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib119" title="">119</a>]</cite>는 석유 및 가스 산업의 문제를 해결하는 LLMs의 효과에 대한 포괄적인 사례 연구를 제시한다. 그것은 암석 물리 모델링, 음향 반사 측정 및 코일형 튜빙 제어를 포함한 다양한 응용 분야에 중점을 둔다.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS3.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p5.1.1">Robotics &amp; Embodied Artificial Intelligence</span>: 최근 연구는 로봇 공학에 대한 보다 효율적인 강화 학습 에이전트를 개발하고 인공 지능을 구현했다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib28" title="">28</a>, <a class="ltx_ref" href="#bib.bib181" title="">181</a>, <a class="ltx_ref" href="#bib.bib118" title="">118</a>, <a class="ltx_ref" href="#bib.bib160" title="">160</a>, <a class="ltx_ref" href="#bib.bib148" title="">148</a>, <a class="ltx_ref" href="#bib.bib184" title="">184</a>, <a class="ltx_ref" href="#bib.bib66" title="">66</a>, <a class="ltx_ref" href="#bib.bib159" title="">159</a>, <a class="ltx_ref" href="#bib.bib174" title="">174</a>, <a class="ltx_ref" href="#bib.bib32" title="">32</a>, <a class="ltx_ref" href="#bib.bib2" title="">2</a>]</cite>. 체화된 환경에서 계획, 추론 및 협업을 위한 자율 에이전트의 능력을 향상시키는 데 중점을 둔다. 특히 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite>는 체화된 추론과 과제 계획을 위한 통합 에이전트 시스템을 제안한다. 이 시스템에서, 저자들은 개선된 계획을 가능하게 하기 위해 고레벨 명령들을 설계하는 한편, 명령들을 액션들로 변환하는 저레벨 제어기들을 제안한다. 추가적으로, 대화들을 활용하여 정보를 수집할 수 있다 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib181" title="">181</a>]</cite>를 활용하여 최적화 프로세스를 가속화할 수 있다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib118" title="">118</a>, <a class="ltx_ref" href="#bib.bib160" title="">160</a>]</cite>는 체화된 의사 결정 및 탐색을 위해 자율 에이전트를 사용한다. 물리적 제약을 극복하기 위해 에이전트는 실행 가능한 계획을 생성하고 여러 기술을 활용하여 장기 작업을 수행할 수 있다. 제어 정책 측면에서 SayCan<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib2" title="">2</a>]</cite>는 모바일 매니퓰레이터 로봇을 활용한 광범위한 조작 및 항법 기술을 조사하는 데 중점을 둔다. 주방 환경에서 접하게 되는 일반적인 작업에서 영감을 받아 7개의 스킬 가족과 17개의 객체를 다루는 551개의 스킬 종합 세트를 선보입니다. 이러한 기술은 무엇보다도 대상을 따고, 놓고, 붓고, 잡고, 조작하는 등의 다양한 행위를 포괄한다. TidyBot<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib157" title="">157</a>]</cite>는 가정 청소 작업을 개인화하기 위해 설계된 체화된 에이전트입니다. 텍스트 예제를 통해 객체 배치 및 조작 방법에 대한 사용자의 선호도를 학습할 수 있다.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S3.SS3.p6.1">LLM 기반 자율 에이전트의 적용을 촉진하기 위해 연구자들은 많은 오픈 소스 라이브러리를 도입했으며, 이를 기반으로 개발자는 맞춤형 요구 사항인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib49" title="">49</a>, <a class="ltx_ref" href="#bib.bib47" title="">47</a>, <a class="ltx_ref" href="#bib.bib42" title="">42</a>, <a class="ltx_ref" href="#bib.bib44" title="">44</a>, <a class="ltx_ref" href="#bib.bib39" title="">39</a>, <a class="ltx_ref" href="#bib.bib40" title="">40</a>, <a class="ltx_ref" href="#bib.bib46" title="">46</a>, <a class="ltx_ref" href="#bib.bib16" title="">16</a>, <a class="ltx_ref" href="#bib.bib36" title="">36</a>, <a class="ltx_ref" href="#bib.bib43" title="">43</a>, <a class="ltx_ref" href="#bib.bib38" title="">38</a>, <a class="ltx_ref" href="#bib.bib125" title="">125</a>, <a class="ltx_ref" href="#bib.bib52" title="">52</a>, <a class="ltx_ref" href="#bib.bib45" title="">45</a>, <a class="ltx_ref" href="#bib.bib41" title="">41</a>, <a class="ltx_ref" href="#bib.bib50" title="">50</a>, <a class="ltx_ref" href="#bib.bib158" title="">158</a>]</cite>에 따라 에이전트를 빠르게 구현하고 평가할 수 있다. 예를 들어, LangChain<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib16" title="">16</a>]</cite>는 코딩, 테스트, 디버깅 및 문서 생성 작업을 자동화하는 오픈 소스 프레임워크이다. 언어 모델을 데이터 소스와 통합하고 환경과의 상호 작용을 촉진함으로써 랭체인은 자연어 통신과 여러 에이전트 역할 간의 협업을 통해 효율적이고 비용 효율적인 소프트웨어 개발을 가능하게 한다. LangChain을 기반으로 XLang<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib40" title="">40</a>]</cite>는 포괄적인 도구 집합, 완전한 사용자 인터페이스와 함께 제공되며 데이터 처리, 플러그인 사용 및 웹 에이전트의 세 가지 다른 에이전트 시나리오를 지원합니다. AutoGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib49" title="">49</a>]</cite>는 완전 자동화된 에이전트입니다. 하나 이상의 목표를 설정하고, 이를 대응하는 과제로 나누고, 목표가 달성될 때까지 과제를 순환시킨다. WorkGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib36" title="">36</a>]</cite>는 AutoGPT 및 LangChain과 유사한 에이전트 프레임워크이다. 지시와 API 세트를 제공하여 지시가 완료될 때까지 AI와 전후 대화를 한다. GPT-Engineer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib37" title="">37</a>]</cite>, SmolModels <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib48" title="">48</a>]</cite> 및 DemoGPT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib45" title="">45</a>]</cite>는 개발 작업을 완료하기 위한 프롬프트를 통해 코드 생성을 자동화하는 데 중점을 둔 오픈 소스 프로젝트입니다. AGiXT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib44" title="">44</a>]</cite>는 많은 공급자에 걸쳐 효율적인 AI 명령 관리 및 작업 실행을 오케스트레이션하도록 설계된 동적 AI 자동화 플랫폼입니다. AgentVerse<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib39" title="">39</a>]</cite>는 연구자들이 맞춤형 LLM 기반 에이전트 시뮬레이션을 효율적으로 만들 수 있도록 하는 다목적 프레임워크이다. GPT 연구자 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib38" title="">38</a>]</cite>는 대규모 언어 모델을 활용하여 연구 문제를 효율적으로 개발하고, 웹 크롤링을 유발하여 정보를 수집하고, 출처를 요약하고, 요약본을 집계하는 실험 애플리케이션이다. BMTools <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib125" title="">125</a>]</cite>는 LLMs을 도구로 확장한 오픈 소스 리포지토리로 커뮤니티 중심의 도구 구축 및 공유를 위한 플랫폼을 제공한다. 다양한 유형의 도구를 지원하고, 여러 도구를 사용하여 동시 작업 실행이 가능하며, URL을 통해 플러그인을 로드할 수 있는 간단한 인터페이스를 제공하여 쉬운 개발 및 BMTools 생태계에 대한 기여를 촉진한다.</p>
</div>
<div id="Thmremarkx6" class="ltx_theorem ltx_theorem_remark">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmremarkx6.1.1.1" class="ltx_text ltx_font_italic">Remark</span></span><span id="Thmremarkx6.2.2" class="ltx_text ltx_font_italic">.</span>
</h6>
<div id="Thmremarkx6.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="Thmremarkx6.p1.1">위의 응용 프로그램을 지원하는 데 LLM 기반 에이전트의 활용은 또한 특정 위험과 도전을 수반할 수 있다. 한편으로 LLM 자체는 환상과 다른 문제에 취약할 수 있으며 때때로 잘못된 답변을 제공하여 잘못된 결론, 실험적 실패 또는 위험한 실험에서 인간의 안전에 위험을 초래할 수 있다. 따라서 실험 중 사용자는 적절한 주의를 기울이기 위해 필요한 전문 지식과 지식을 보유해야 한다. 반면에 LLM 기반 에이전트는 잠재적으로 화학 무기 개발과 같은 악의적인 목적으로 악용될 수 있으므로 책임 있고 윤리적인 사용을 보장하기 위해 인간 정렬과 같은 보안 조치의 구현이 필요하다.</p>
</div>
<div id="Thmremarkx6.p2" class="ltx_para">
<p class="ltx_p" id="Thmremarkx6.p2.1">요약하면, 위의 섹션에서 우리는 세 가지 중요한 도메인에서 LLM 기반 자율 에이전트의 전형적인 응용을 소개한다. 보다 명확한 이해를 위해 표 <a class="ltx_ref" href="#S3.T2" title="Table 2 ‣ 3.2 Natural Science ‣ 3 LLM-based Autonomous Agent Application ‣ A Survey on Large Language Model based Autonomous Agents"><span class="ltx_text ltx_ref_tag">2</span></a>에서 이전 작업과 응용 프로그램 간의 대응 관계를 요약한다.</p>
</div>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>LLM-based Autonomous Agent Evaluation</h2>

<div id="S4.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.p1.1">LLM 자체들과 유사하게, LLM 기반 자율 에이전트들의 유효성을 평가하는 것은 도전적인 과제이다. 이 절에서는 일반적으로 사용되는 두 가지 평가 전략, 즉 주관적이고 객관적인 평가를 소개한다(개요는 그림<a class="ltx_ref" href="#S2.F5" title="Figure 5 ‣ 2.2 Agent Capability Acquisition ‣ 2 LLM-based Autonomous Agent Construction ‣ A Survey on Large Language Model based Autonomous Agents"><span class="ltx_text ltx_ref_tag">5</span></a>의 오른쪽 부분을 참조).</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Subjective Evaluation</h3>

<div id="S4.SS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.p1.1">주관적 평가는 인간 판단 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib85" title="">85</a>, <a class="ltx_ref" href="#bib.bib122" title="">122</a>, <a class="ltx_ref" href="#bib.bib121" title="">121</a>, <a class="ltx_ref" href="#bib.bib5" title="">5</a>, <a class="ltx_ref" href="#bib.bib176" title="">176</a>]</cite>에 기초하여 에이전트 능력을 측정한다. 평가 데이터 세트가 없거나 에이전트의 지능 또는 사용자 친화성을 평가하는 것과 같은 정량적 메트릭을 설계하기가 매우 어려운 시나리오에 적합합니다. 다음에서는 주관적 평가를 위해 일반적으로 사용되는 두 가지 전략을 제시한다.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p2.1.1">Human Annotation</span>: 이 방법에서 인간 평가자는 서로 다른 에이전트로부터 생성된 결과를 직접 점수화하거나 순위를 매긴다[<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib187" title="">187</a>, <a class="ltx_ref" href="#bib.bib5" title="">5</a>, <a class="ltx_ref" href="#bib.bib176" title="">176</a>]</cite>]. 예를 들어, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib121" title="">121</a>]</cite>에서 저자는 많은 주석자를 사용하고 에이전트 기능과 직접 관련된 5가지 핵심 질문에 대한 피드백을 제공하도록 요청합니다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib84" title="">84</a>]</cite>에서 저자들은 인간에게 모델의 무해성, 정직성, 유용성, 참여성, 편파성에 대해 점수를 매기도록 요청하여 모델 효과를 평가한 다음 다른 모델의 결과를 비교한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib122" title="">122</a>]</cite>에서 저자는 주석이 자신의 디자인 모델이 온라인 커뮤니티에 대한 규칙 디자인을 개선하는 데 효과적으로 기여할 수 있는지 답변하도록 요청한다.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS1.p3.1.1">Turing Test</span>: 이 방법에서, 인간 평가자들은 에이전트들에 의해 생성된 결과들과 실제 인간들을 구별하기 위해 요구된다. 주어진 과제에서 평가자들이 에이전트와 인간의 결과를 분리할 수 없다면 에이전트가 이 과제에서 인간과 같은 성과를 달성할 수 있음을 보여준다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib5" title="">5</a>]</cite>에서 저자는 자유형 Partisan 텍스트에 대한 실험을 수행하고, 인간 평가자에게 인간 또는 LLM 기반 에이전트의 응답 여부를 추측하도록 한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib121" title="">121</a>]</cite>에서 인간 평가자는 행동들이 에이전트로부터 생성된 것인지 실제 인간으로부터 생성된 것인지를 식별해야 한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib68" title="">68</a>]</cite>에서 저자들은 다양한 상황에서 LLM 소프트웨어와 인간 피험자의 감정 상태에 대한 인간 주석을 수집하는 연구를 수행한다. 그들은 LLM 소프트웨어의 정서적 견고성을 평가하기 위한 기준선으로 이러한 주석을 활용했다.</p>
</div>
<div id="Thmremarkx7" class="ltx_theorem ltx_theorem_remark">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmremarkx7.1.1.1" class="ltx_text ltx_font_italic">Remark</span></span><span id="Thmremarkx7.2.2" class="ltx_text ltx_font_italic">.</span>
</h6>
<div id="Thmremarkx7.p1" class="ltx_para">
<p class="ltx_p" id="Thmremarkx7.p1.1">LLM 기반 에이전트는 일반적으로 사람을 위해 설계되었습니다. 따라서 주관적 에이전트 평가는 인간의 기준을 반영하기 때문에 중요한 역할을 한다. 그러나 이 전략은 높은 비용, 비효율성 및 인구 편향과 같은 문제에 직면하기도 한다. 이러한 문제를 해결하기 위해 많은 연구자들이 LLMs을 프록시로 활용하여 주관적인 평가를 진행하고자 하였다. 예를 들어 ChemCrow <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite>에서 연구자들은 GPT를 사용하여 실험 결과를 평가한다. 그들은 작업의 완료와 기본 프로세스의 정확성을 모두 고려합니다. ChatEval<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite>는 여러 에이전트를 사용하여 후보 모델에 의해 생성된 결과를 토론 방식으로 평가한다. 우리는 LLM이 발전함에 따라 이러한 평가 방법이 더 신뢰할 수 있고 광범위한 응용 분야에서 적용될 수 있다고 믿는다.</p>
</div>
</div>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 3:</span></figcaption><figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>
Summary on the evaluation strategies of LLM-based autonomous agents (more agents can be seen on https://github.com/Paitesanshi/LLM-Agent-Survey).
For subjective evaluation, we use ① and ② to represent human annotation and the Turing test, respectively.
For objective evaluation, we use ①, ②, ③, and ④ to represent environment simulation, social evaluation, multi-task evaluation, and software testing, respectively. “<math id="S4.T3.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.2.m1.1b"><mi mathvariant="normal" id="S4.T3.2.m1.1.1" xref="S4.T3.2.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.2.m1.1c"><ci id="S4.T3.2.m1.1.1.cmml" xref="S4.T3.2.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.m1.1d">\checkmark</annotation></semantics></math>” indicates that the evaluations are based on benchmarks.</figcaption>
<div id="S4.T3.19" class="ltx_inline-block ltx_transformed_outer" style="width:433.9pt;height:519.8pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-16.3pt,19.5pt) scale(0.93,0.93) ;">
<table id="S4.T3.19.17" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.19.17.18.1" class="ltx_tr">
<th id="S4.T3.19.17.18.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.18.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.18.1.1.1.1" class="ltx_p" style="width:108.1pt;">Model</span>
</span>
</th>
<th id="S4.T3.19.17.18.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.18.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.18.1.2.1.1" class="ltx_p" style="width:62.6pt;">Subjective</span>
</span>
</th>
<th id="S4.T3.19.17.18.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.18.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.18.1.3.1.1" class="ltx_p" style="width:62.6pt;">Objective</span>
</span>
</th>
<th id="S4.T3.19.17.18.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.18.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.18.1.4.1.1" class="ltx_p" style="width:62.6pt;">Benchmark</span>
</span>
</th>
<th id="S4.T3.19.17.18.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.18.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.18.1.5.1.1" class="ltx_p" style="width:62.6pt;">Time</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.3.1.1" class="ltx_tr">
<td id="S4.T3.3.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.3.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.3.1.1.2.1.1" class="ltx_p" style="width:108.1pt;">WebShop&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib168" title="" class="ltx_ref">168</a>]</cite></span>
</span>
</td>
<td id="S4.T3.3.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.3.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.3.1.1.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.3.1.1.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.3.1.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.3.1.1.4.1.1" class="ltx_p" style="width:62.6pt;">① ③</span>
</span>
</td>
<td id="S4.T3.3.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.3.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.3.1.1.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.3.1.1.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.3.1.1.1.1.1.m1.1.1" xref="S4.T3.3.1.1.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.3.1.1.1.1.1.m1.1b"><ci id="S4.T3.3.1.1.1.1.1.m1.1.1.cmml" xref="S4.T3.3.1.1.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.1.1.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.3.1.1.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.3.1.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.3.1.1.5.1.1" class="ltx_p" style="width:62.6pt;">07/2022</span>
</span>
</td>
</tr>
<tr id="S4.T3.19.17.19.1" class="ltx_tr">
<td id="S4.T3.19.17.19.1.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.19.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.19.1.1.1.1" class="ltx_p" style="width:108.1pt;">Social Simulacra&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite></span>
</span>
</td>
<td id="S4.T3.19.17.19.1.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.19.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.19.1.2.1.1" class="ltx_p" style="width:62.6pt;">①</span>
</span>
</td>
<td id="S4.T3.19.17.19.1.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.19.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.19.1.3.1.1" class="ltx_p" style="width:62.6pt;">②</span>
</span>
</td>
<td id="S4.T3.19.17.19.1.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.19.1.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.19.1.4.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.19.1.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.19.1.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.19.1.5.1.1" class="ltx_p" style="width:62.6pt;">08/2022</span>
</span>
</td>
</tr>
<tr id="S4.T3.19.17.20.2" class="ltx_tr">
<td id="S4.T3.19.17.20.2.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.20.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.20.2.1.1.1" class="ltx_p" style="width:108.1pt;">TE&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite></span>
</span>
</td>
<td id="S4.T3.19.17.20.2.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.20.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.20.2.2.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.20.2.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.20.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.20.2.3.1.1" class="ltx_p" style="width:62.6pt;">②</span>
</span>
</td>
<td id="S4.T3.19.17.20.2.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.20.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.20.2.4.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.20.2.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.20.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.20.2.5.1.1" class="ltx_p" style="width:62.6pt;">08/2022</span>
</span>
</td>
</tr>
<tr id="S4.T3.19.17.21.3" class="ltx_tr">
<td id="S4.T3.19.17.21.3.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.21.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.21.3.1.1.1" class="ltx_p" style="width:108.1pt;">LIBRO&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite></span>
</span>
</td>
<td id="S4.T3.19.17.21.3.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.21.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.21.3.2.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.21.3.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.21.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.21.3.3.1.1" class="ltx_p" style="width:62.6pt;">④</span>
</span>
</td>
<td id="S4.T3.19.17.21.3.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.21.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.21.3.4.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.21.3.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.21.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.21.3.5.1.1" class="ltx_p" style="width:62.6pt;">09/2022</span>
</span>
</td>
</tr>
<tr id="S4.T3.4.2.2" class="ltx_tr">
<td id="S4.T3.4.2.2.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.4.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.4.2.2.2.1.1" class="ltx_p" style="width:108.1pt;">ReAct&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib170" title="" class="ltx_ref">170</a>]</cite></span>
</span>
</td>
<td id="S4.T3.4.2.2.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.4.2.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.4.2.2.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.4.2.2.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.4.2.2.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.4.2.2.4.1.1" class="ltx_p" style="width:62.6pt;">①</span>
</span>
</td>
<td id="S4.T3.4.2.2.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.4.2.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.4.2.2.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.4.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.4.2.2.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.4.2.2.1.1.1.m1.1.1" xref="S4.T3.4.2.2.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.4.2.2.1.1.1.m1.1b"><ci id="S4.T3.4.2.2.1.1.1.m1.1.1.cmml" xref="S4.T3.4.2.2.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.2.2.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.4.2.2.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.4.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.4.2.2.5.1.1" class="ltx_p" style="width:62.6pt;">10/2022</span>
</span>
</td>
</tr>
<tr id="S4.T3.19.17.22.4" class="ltx_tr">
<td id="S4.T3.19.17.22.4.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.22.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.22.4.1.1.1" class="ltx_p" style="width:108.1pt;">Out of One, Many&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite></span>
</span>
</td>
<td id="S4.T3.19.17.22.4.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.22.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.22.4.2.1.1" class="ltx_p" style="width:62.6pt;">②</span>
</span>
</td>
<td id="S4.T3.19.17.22.4.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.22.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.22.4.3.1.1" class="ltx_p" style="width:62.6pt;">② ③</span>
</span>
</td>
<td id="S4.T3.19.17.22.4.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.22.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.22.4.4.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.22.4.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.22.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.22.4.5.1.1" class="ltx_p" style="width:62.6pt;">02/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.5.3.3" class="ltx_tr">
<td id="S4.T3.5.3.3.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.5.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.5.3.3.2.1.1" class="ltx_p" style="width:108.1pt;">DEPS&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib154" title="" class="ltx_ref">154</a>]</cite></span>
</span>
</td>
<td id="S4.T3.5.3.3.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.5.3.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.5.3.3.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.5.3.3.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.5.3.3.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.5.3.3.4.1.1" class="ltx_p" style="width:62.6pt;">①</span>
</span>
</td>
<td id="S4.T3.5.3.3.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.5.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.5.3.3.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.5.3.3.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.5.3.3.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.5.3.3.1.1.1.m1.1.1" xref="S4.T3.5.3.3.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.5.3.3.1.1.1.m1.1b"><ci id="S4.T3.5.3.3.1.1.1.m1.1.1.cmml" xref="S4.T3.5.3.3.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.3.3.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.5.3.3.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.5.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.5.3.3.5.1.1" class="ltx_p" style="width:62.6pt;">02/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.19.17.23.5" class="ltx_tr">
<td id="S4.T3.19.17.23.5.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.23.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.23.5.1.1.1" class="ltx_p" style="width:108.1pt;">Jalil et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite></span>
</span>
</td>
<td id="S4.T3.19.17.23.5.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.23.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.23.5.2.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.23.5.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.23.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.23.5.3.1.1" class="ltx_p" style="width:62.6pt;">④</span>
</span>
</td>
<td id="S4.T3.19.17.23.5.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.23.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.23.5.4.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.23.5.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.23.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.23.5.5.1.1" class="ltx_p" style="width:62.6pt;">02/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.19.17.24.6" class="ltx_tr">
<td id="S4.T3.19.17.24.6.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.24.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.24.6.1.1.1" class="ltx_p" style="width:108.1pt;">Reflexion&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite></span>
</span>
</td>
<td id="S4.T3.19.17.24.6.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.24.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.24.6.2.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.24.6.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.24.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.24.6.3.1.1" class="ltx_p" style="width:62.6pt;">① ③</span>
</span>
</td>
<td id="S4.T3.19.17.24.6.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.24.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.24.6.4.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.24.6.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.24.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.24.6.5.1.1" class="ltx_p" style="width:62.6pt;">03/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.6.4.4" class="ltx_tr">
<td id="S4.T3.6.4.4.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.6.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.6.4.4.2.1.1" class="ltx_p" style="width:108.1pt;">IGLU&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite></span>
</span>
</td>
<td id="S4.T3.6.4.4.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.6.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.6.4.4.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.6.4.4.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.6.4.4.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.6.4.4.4.1.1" class="ltx_p" style="width:62.6pt;">①</span>
</span>
</td>
<td id="S4.T3.6.4.4.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.6.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.6.4.4.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.6.4.4.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.6.4.4.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.6.4.4.1.1.1.m1.1.1" xref="S4.T3.6.4.4.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.6.4.4.1.1.1.m1.1b"><ci id="S4.T3.6.4.4.1.1.1.m1.1.1.cmml" xref="S4.T3.6.4.4.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.4.4.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.6.4.4.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.6.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.6.4.4.5.1.1" class="ltx_p" style="width:62.6pt;">04/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.19.17.25.7" class="ltx_tr">
<td id="S4.T3.19.17.25.7.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.25.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.25.7.1.1.1" class="ltx_p" style="width:108.1pt;">Generative Agents&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite></span>
</span>
</td>
<td id="S4.T3.19.17.25.7.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.25.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.25.7.2.1.1" class="ltx_p" style="width:62.6pt;">① ②</span>
</span>
</td>
<td id="S4.T3.19.17.25.7.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.25.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.25.7.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.25.7.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.25.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.25.7.4.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.25.7.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.25.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.25.7.5.1.1" class="ltx_p" style="width:62.6pt;">04/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.7.5.5" class="ltx_tr">
<td id="S4.T3.7.5.5.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.7.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.7.5.5.2.1.1" class="ltx_p" style="width:108.1pt;">ToolBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite></span>
</span>
</td>
<td id="S4.T3.7.5.5.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.7.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.7.5.5.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.7.5.5.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.7.5.5.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.7.5.5.4.1.1" class="ltx_p" style="width:62.6pt;">③</span>
</span>
</td>
<td id="S4.T3.7.5.5.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.7.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.7.5.5.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.7.5.5.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.7.5.5.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.7.5.5.1.1.1.m1.1.1" xref="S4.T3.7.5.5.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.7.5.5.1.1.1.m1.1b"><ci id="S4.T3.7.5.5.1.1.1.m1.1.1.cmml" xref="S4.T3.7.5.5.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.7.5.5.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.7.5.5.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.7.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.7.5.5.5.1.1" class="ltx_p" style="width:62.6pt;">04/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.8.6.6" class="ltx_tr">
<td id="S4.T3.8.6.6.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.8.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.8.6.6.2.1.1" class="ltx_p" style="width:108.1pt;">GITM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib184" title="" class="ltx_ref">184</a>]</cite></span>
</span>
</td>
<td id="S4.T3.8.6.6.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.8.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.8.6.6.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.8.6.6.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.8.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.8.6.6.4.1.1" class="ltx_p" style="width:62.6pt;">①</span>
</span>
</td>
<td id="S4.T3.8.6.6.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.8.6.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.8.6.6.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.8.6.6.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.8.6.6.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.8.6.6.1.1.1.m1.1.1" xref="S4.T3.8.6.6.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.8.6.6.1.1.1.m1.1b"><ci id="S4.T3.8.6.6.1.1.1.m1.1.1.cmml" xref="S4.T3.8.6.6.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.8.6.6.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.8.6.6.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.8.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.8.6.6.5.1.1" class="ltx_p" style="width:62.6pt;">05/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.19.17.26.8" class="ltx_tr">
<td id="S4.T3.19.17.26.8.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.26.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.26.8.1.1.1" class="ltx_p" style="width:108.1pt;">Two-Failures&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite></span>
</span>
</td>
<td id="S4.T3.19.17.26.8.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.26.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.26.8.2.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.26.8.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.26.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.26.8.3.1.1" class="ltx_p" style="width:62.6pt;">③</span>
</span>
</td>
<td id="S4.T3.19.17.26.8.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.26.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.26.8.4.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.26.8.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.26.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.26.8.5.1.1" class="ltx_p" style="width:62.6pt;">05/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.9.7.7" class="ltx_tr">
<td id="S4.T3.9.7.7.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.9.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.9.7.7.2.1.1" class="ltx_p" style="width:108.1pt;">Voyager&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib148" title="" class="ltx_ref">148</a>]</cite></span>
</span>
</td>
<td id="S4.T3.9.7.7.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.9.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.9.7.7.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.9.7.7.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.9.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.9.7.7.4.1.1" class="ltx_p" style="width:62.6pt;">①</span>
</span>
</td>
<td id="S4.T3.9.7.7.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.9.7.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.9.7.7.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.9.7.7.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.9.7.7.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.9.7.7.1.1.1.m1.1.1" xref="S4.T3.9.7.7.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.9.7.7.1.1.1.m1.1b"><ci id="S4.T3.9.7.7.1.1.1.m1.1.1.cmml" xref="S4.T3.9.7.7.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.9.7.7.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.9.7.7.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.9.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.9.7.7.5.1.1" class="ltx_p" style="width:62.6pt;">05/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.10.8.8" class="ltx_tr">
<td id="S4.T3.10.8.8.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.10.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.10.8.8.2.1.1" class="ltx_p" style="width:108.1pt;">SocKET&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite></span>
</span>
</td>
<td id="S4.T3.10.8.8.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.10.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.10.8.8.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.10.8.8.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.10.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.10.8.8.4.1.1" class="ltx_p" style="width:62.6pt;">② ③</span>
</span>
</td>
<td id="S4.T3.10.8.8.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.10.8.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.10.8.8.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.10.8.8.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.10.8.8.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.10.8.8.1.1.1.m1.1.1" xref="S4.T3.10.8.8.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.10.8.8.1.1.1.m1.1b"><ci id="S4.T3.10.8.8.1.1.1.m1.1.1.cmml" xref="S4.T3.10.8.8.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.10.8.8.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.10.8.8.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.10.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.10.8.8.5.1.1" class="ltx_p" style="width:62.6pt;">05/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.11.9.9" class="ltx_tr">
<td id="S4.T3.11.9.9.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.11.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.11.9.9.2.1.1" class="ltx_p" style="width:108.1pt;">MobileEnv&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib175" title="" class="ltx_ref">175</a>]</cite></span>
</span>
</td>
<td id="S4.T3.11.9.9.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.11.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.11.9.9.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.11.9.9.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.11.9.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.11.9.9.4.1.1" class="ltx_p" style="width:62.6pt;">① ③</span>
</span>
</td>
<td id="S4.T3.11.9.9.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.11.9.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.11.9.9.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.11.9.9.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.11.9.9.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.11.9.9.1.1.1.m1.1.1" xref="S4.T3.11.9.9.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.11.9.9.1.1.1.m1.1b"><ci id="S4.T3.11.9.9.1.1.1.m1.1.1.cmml" xref="S4.T3.11.9.9.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.11.9.9.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.11.9.9.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.11.9.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.11.9.9.5.1.1" class="ltx_p" style="width:62.6pt;">05/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.12.10.10" class="ltx_tr">
<td id="S4.T3.12.10.10.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.12.10.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.12.10.10.2.1.1" class="ltx_p" style="width:108.1pt;">Clembench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite></span>
</span>
</td>
<td id="S4.T3.12.10.10.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.12.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.12.10.10.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.12.10.10.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.12.10.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.12.10.10.4.1.1" class="ltx_p" style="width:62.6pt;">① ③</span>
</span>
</td>
<td id="S4.T3.12.10.10.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.12.10.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.12.10.10.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.12.10.10.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.12.10.10.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.12.10.10.1.1.1.m1.1.1" xref="S4.T3.12.10.10.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.12.10.10.1.1.1.m1.1b"><ci id="S4.T3.12.10.10.1.1.1.m1.1.1.cmml" xref="S4.T3.12.10.10.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.12.10.10.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.12.10.10.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.12.10.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.12.10.10.5.1.1" class="ltx_p" style="width:62.6pt;">05/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.13.11.11" class="ltx_tr">
<td id="S4.T3.13.11.11.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.13.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.13.11.11.2.1.1" class="ltx_p" style="width:108.1pt;">Dialop&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite></span>
</span>
</td>
<td id="S4.T3.13.11.11.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.13.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.13.11.11.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.13.11.11.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.13.11.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.13.11.11.4.1.1" class="ltx_p" style="width:62.6pt;">②</span>
</span>
</td>
<td id="S4.T3.13.11.11.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.13.11.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.13.11.11.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.13.11.11.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.13.11.11.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.13.11.11.1.1.1.m1.1.1" xref="S4.T3.13.11.11.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.13.11.11.1.1.1.m1.1b"><ci id="S4.T3.13.11.11.1.1.1.m1.1.1.cmml" xref="S4.T3.13.11.11.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.13.11.11.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.13.11.11.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.13.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.13.11.11.5.1.1" class="ltx_p" style="width:62.6pt;">06/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.19.17.27.9" class="ltx_tr">
<td id="S4.T3.19.17.27.9.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.27.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.27.9.1.1.1" class="ltx_p" style="width:108.1pt;">Feldt et al.&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite></span>
</span>
</td>
<td id="S4.T3.19.17.27.9.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.27.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.27.9.2.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.27.9.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.27.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.27.9.3.1.1" class="ltx_p" style="width:62.6pt;">④</span>
</span>
</td>
<td id="S4.T3.19.17.27.9.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.27.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.27.9.4.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.27.9.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.27.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.27.9.5.1.1" class="ltx_p" style="width:62.6pt;">06/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.19.17.28.10" class="ltx_tr">
<td id="S4.T3.19.17.28.10.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.28.10.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.28.10.1.1.1" class="ltx_p" style="width:108.1pt;">CO-LLM&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib176" title="" class="ltx_ref">176</a>]</cite></span>
</span>
</td>
<td id="S4.T3.19.17.28.10.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.28.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.28.10.2.1.1" class="ltx_p" style="width:62.6pt;">①</span>
</span>
</td>
<td id="S4.T3.19.17.28.10.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.28.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.28.10.3.1.1" class="ltx_p" style="width:62.6pt;">①</span>
</span>
</td>
<td id="S4.T3.19.17.28.10.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.28.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.28.10.4.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.28.10.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.28.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.28.10.5.1.1" class="ltx_p" style="width:62.6pt;">07/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.14.12.12" class="ltx_tr">
<td id="S4.T3.14.12.12.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.14.12.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.14.12.12.2.1.1" class="ltx_p" style="width:108.1pt;">Tachikuma&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite></span>
</span>
</td>
<td id="S4.T3.14.12.12.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.14.12.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.14.12.12.3.1.1" class="ltx_p" style="width:62.6pt;">①</span>
</span>
</td>
<td id="S4.T3.14.12.12.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.14.12.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.14.12.12.4.1.1" class="ltx_p" style="width:62.6pt;">①</span>
</span>
</td>
<td id="S4.T3.14.12.12.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.14.12.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.14.12.12.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.14.12.12.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.14.12.12.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.14.12.12.1.1.1.m1.1.1" xref="S4.T3.14.12.12.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.14.12.12.1.1.1.m1.1b"><ci id="S4.T3.14.12.12.1.1.1.m1.1.1.cmml" xref="S4.T3.14.12.12.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.14.12.12.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.14.12.12.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.14.12.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.14.12.12.5.1.1" class="ltx_p" style="width:62.6pt;">07/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.15.13.13" class="ltx_tr">
<td id="S4.T3.15.13.13.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.15.13.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.15.13.13.2.1.1" class="ltx_p" style="width:108.1pt;">WebArena&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib180" title="" class="ltx_ref">180</a>]</cite></span>
</span>
</td>
<td id="S4.T3.15.13.13.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.15.13.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.15.13.13.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.15.13.13.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.15.13.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.15.13.13.4.1.1" class="ltx_p" style="width:62.6pt;">①</span>
</span>
</td>
<td id="S4.T3.15.13.13.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.15.13.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.15.13.13.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.15.13.13.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.15.13.13.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.15.13.13.1.1.1.m1.1.1" xref="S4.T3.15.13.13.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.15.13.13.1.1.1.m1.1b"><ci id="S4.T3.15.13.13.1.1.1.m1.1.1.cmml" xref="S4.T3.15.13.13.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.15.13.13.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.15.13.13.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.15.13.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.15.13.13.5.1.1" class="ltx_p" style="width:62.6pt;">07/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.19.17.29.11" class="ltx_tr">
<td id="S4.T3.19.17.29.11.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.29.11.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.29.11.1.1.1" class="ltx_p" style="width:108.1pt;">RocoBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite></span>
</span>
</td>
<td id="S4.T3.19.17.29.11.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.29.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.29.11.2.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.29.11.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.29.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.29.11.3.1.1" class="ltx_p" style="width:62.6pt;">① ② ③</span>
</span>
</td>
<td id="S4.T3.19.17.29.11.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.29.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.29.11.4.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.29.11.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.29.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.29.11.5.1.1" class="ltx_p" style="width:62.6pt;">07/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.19.17.30.12" class="ltx_tr">
<td id="S4.T3.19.17.30.12.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.30.12.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.30.12.1.1.1" class="ltx_p" style="width:108.1pt;">AgentSims&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite></span>
</span>
</td>
<td id="S4.T3.19.17.30.12.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.30.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.30.12.2.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.30.12.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.30.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.30.12.3.1.1" class="ltx_p" style="width:62.6pt;">②</span>
</span>
</td>
<td id="S4.T3.19.17.30.12.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.30.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.30.12.4.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.30.12.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.30.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.30.12.5.1.1" class="ltx_p" style="width:62.6pt;">08/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.16.14.14" class="ltx_tr">
<td id="S4.T3.16.14.14.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.16.14.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.16.14.14.2.1.1" class="ltx_p" style="width:108.1pt;">AgentBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite></span>
</span>
</td>
<td id="S4.T3.16.14.14.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.16.14.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.16.14.14.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.16.14.14.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.16.14.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.16.14.14.4.1.1" class="ltx_p" style="width:62.6pt;">③</span>
</span>
</td>
<td id="S4.T3.16.14.14.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.16.14.14.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.16.14.14.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.16.14.14.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.16.14.14.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.16.14.14.1.1.1.m1.1.1" xref="S4.T3.16.14.14.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.16.14.14.1.1.1.m1.1b"><ci id="S4.T3.16.14.14.1.1.1.m1.1.1.cmml" xref="S4.T3.16.14.14.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.16.14.14.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.16.14.14.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.16.14.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.16.14.14.5.1.1" class="ltx_p" style="width:62.6pt;">08/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.17.15.15" class="ltx_tr">
<td id="S4.T3.17.15.15.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.17.15.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.17.15.15.2.1.1" class="ltx_p" style="width:108.1pt;">BOLAA&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite></span>
</span>
</td>
<td id="S4.T3.17.15.15.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.17.15.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.17.15.15.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.17.15.15.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.17.15.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.17.15.15.4.1.1" class="ltx_p" style="width:62.6pt;">① ③ ④</span>
</span>
</td>
<td id="S4.T3.17.15.15.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.17.15.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.17.15.15.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.17.15.15.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.17.15.15.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.17.15.15.1.1.1.m1.1.1" xref="S4.T3.17.15.15.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.17.15.15.1.1.1.m1.1b"><ci id="S4.T3.17.15.15.1.1.1.m1.1.1.cmml" xref="S4.T3.17.15.15.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.17.15.15.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.17.15.15.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.17.15.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.17.15.15.5.1.1" class="ltx_p" style="width:62.6pt;">08/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.18.16.16" class="ltx_tr">
<td id="S4.T3.18.16.16.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.18.16.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.18.16.16.2.1.1" class="ltx_p" style="width:108.1pt;">Gentopia&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib163" title="" class="ltx_ref">163</a>]</cite></span>
</span>
</td>
<td id="S4.T3.18.16.16.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.18.16.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.18.16.16.3.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.18.16.16.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.18.16.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.18.16.16.4.1.1" class="ltx_p" style="width:62.6pt;">③</span>
</span>
</td>
<td id="S4.T3.18.16.16.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.18.16.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.18.16.16.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.18.16.16.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.18.16.16.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.18.16.16.1.1.1.m1.1.1" xref="S4.T3.18.16.16.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.18.16.16.1.1.1.m1.1b"><ci id="S4.T3.18.16.16.1.1.1.m1.1.1.cmml" xref="S4.T3.18.16.16.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.18.16.16.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.18.16.16.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.18.16.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.18.16.16.5.1.1" class="ltx_p" style="width:62.6pt;">08/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.19.17.17" class="ltx_tr">
<td id="S4.T3.19.17.17.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.17.2.1.1" class="ltx_p" style="width:108.1pt;">EmotionBench&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite></span>
</span>
</td>
<td id="S4.T3.19.17.17.3" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.17.3.1.1" class="ltx_p" style="width:62.6pt;">①</span>
</span>
</td>
<td id="S4.T3.19.17.17.4" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.17.4.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.17.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.17.1.1.1" class="ltx_p" style="width:62.6pt;"><math id="S4.T3.19.17.17.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T3.19.17.17.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.19.17.17.1.1.1.m1.1.1" xref="S4.T3.19.17.17.1.1.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T3.19.17.17.1.1.1.m1.1b"><ci id="S4.T3.19.17.17.1.1.1.m1.1.1.cmml" xref="S4.T3.19.17.17.1.1.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.19.17.17.1.1.1.m1.1c">\checkmark</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T3.19.17.17.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.17.5.1.1" class="ltx_p" style="width:62.6pt;">08/2023</span>
</span>
</td>
</tr>
<tr id="S4.T3.19.17.31.13" class="ltx_tr">
<td id="S4.T3.19.17.31.13.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.31.13.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.31.13.1.1.1" class="ltx_p" style="width:108.1pt;">PTB&nbsp;<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite></span>
</span>
</td>
<td id="S4.T3.19.17.31.13.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.31.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.31.13.2.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.31.13.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.31.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.31.13.3.1.1" class="ltx_p" style="width:62.6pt;">④</span>
</span>
</td>
<td id="S4.T3.19.17.31.13.4" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.31.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.31.13.4.1.1" class="ltx_p" style="width:62.6pt;">-</span>
</span>
</td>
<td id="S4.T3.19.17.31.13.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" style="padding-top:1.5pt;padding-bottom:1.5pt;">
<span id="S4.T3.19.17.31.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T3.19.17.31.13.5.1.1" class="ltx_p" style="width:62.6pt;">08/2023</span>
</span>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Objective Evaluation</h3>

<div id="S4.SS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.p1.1">객관적 평가는 시간이 지남에 따라 계산, 비교 및 추적될 수 있는 정량적 메트릭을 사용하여 LLM 기반 자율 에이전트의 능력을 평가하는 것을 말한다. 주관적 평가와 달리 객관적인 지표는 에이전트 성능에 대한 구체적이고 측정 가능한 통찰력을 제공하는 것을 목표로 한다. 객관적인 평가를 수행하기 위해서는 세 가지 중요한 측면, 즉 평가 메트릭, 프로토콜 및 벤치마크가 있다. 이하에서는 이러한 측면들을 보다 구체적으로 소개한다.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p2.1.1">Metrics</span>: 에이전트의 유효성을 객관적으로 평가하기 위해 적절한 메트릭을 설계하는 것이 중요하며, 이는 평가 정확도와 포괄성에 영향을 미칠 수 있다. 이상적인 평가 메트릭은 에이전트의 품질을 정확하게 반영해야 하며 실제 시나리오에서 사용할 때 인간의 느낌과 일치해야 한다. 기존 작업에서 우리는 다음과 같은 대표적인 평가 척도를 결론지을 수 있다. (1) <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.2">Task success metrics:</span> 이러한 메트릭은 에이전트가 작업을 완료 하 고 목표를 달성할 수 있는 정도를 측정 합니다. 일반적인 메트릭은 성공률 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib176" title="">176</a>, <a class="ltx_ref" href="#bib.bib170" title="">170</a>, <a class="ltx_ref" href="#bib.bib139" title="">139</a>, <a class="ltx_ref" href="#bib.bib100" title="">100</a>]</cite>, 보상/점수 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib176" title="">176</a>, <a class="ltx_ref" href="#bib.bib170" title="">170</a>, <a class="ltx_ref" href="#bib.bib110" title="">110</a>]</cite>, 커버리지 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>]</cite>, 정확도 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib124" title="">124</a>, <a class="ltx_ref" href="#bib.bib1" title="">1</a>, <a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>를 포함한다. 값이 높을수록 작업 완료 능력이 더 크다는 것을 나타냅니다. (2) <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.3">Human similarity metrics:</span> 이러한 메트릭은 에이전트 행동이 인간의 행동과 매우 유사한 정도를 정량화합니다. 대표적인 예로는 궤적/위치 정확도 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib17" title="">17</a>, <a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>, 대화 유사성 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib122" title="">122</a>, <a class="ltx_ref" href="#bib.bib1" title="">1</a>]</cite>, 인간 반응의 모방 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>, <a class="ltx_ref" href="#bib.bib5" title="">5</a>]</cite> 등이 있다. 유사도가 높을수록 인간 시뮬레이션 성능이 향상됨을 시사합니다. (3) <span class="ltx_text ltx_font_italic" id="S4.SS2.p2.1.4">Efficiency metrics:</span> 에이전트 유효성을 평가하는 데 사용되는 전술한 메트릭과 달리 이러한 메트릭은 에이전트 효율성을 평가합니다. 대표적인 메트릭으로는 계획 길이 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib100" title="">100</a>]</cite>, 개발 비용 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib124" title="">124</a>]</cite>, 추론 속도 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>, <a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>, clarification dialogues <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib110" title="">110</a>]</cite> 등이 있다.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p3.1.1">Protocols</span>: 평가 메트릭 외에도 객관적인 평가를 위한 또 다른 중요한 측면은 이러한 메트릭을 활용하는 방법입니다. 이전 연구에서 우리는 (1) <span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.2">Real-world simulation:</span> 이 방법에서 에이전트는 게임 및 대화형 시뮬레이터와 같은 몰입형 환경 내에서 평가됩니다. 에이전트는 자율적으로 작업을 수행해야 하며, 작업 성공률과 인간 유사성과 같은 메트릭을 활용하여 에이전트의 궤적과 완성된 목표들을 기반으로 에이전트의 능력을 평가한다. 이 방법은 실제 시나리오에서 에이전트의 실제 능력을 평가할 것으로 예상된다. (2) <span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.3">Social evaluation</span>: 이 방법은 시뮬레이션된 사회에서 에이전트 상호 작용을 기반으로 소셜 인텔리전스를 평가하기 위해 메트릭을 활용합니다. 팀워크 기술을 평가하기 위한 협력 과제, 논증적 추론을 분석하기 위한 토론, 사회적 적성을 측정하기 위한 인간 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib122" title="">122</a>, <a class="ltx_ref" href="#bib.bib1" title="">1</a>, <a class="ltx_ref" href="#bib.bib23" title="">23</a>, <a class="ltx_ref" href="#bib.bib99" title="">99</a>, <a class="ltx_ref" href="#bib.bib104" title="">104</a>]</cite> 등 다양한 접근법이 채택되었다. 이러한 접근은 협력, 의사소통, 공감, 인간의 사회적 행동 모방과 같은 영역에서 에이전트의 능력을 평가하기 위해 일관성, 정신 이론, 사회적 IQ와 같은 자질을 분석한다. 에이전트를 복잡한 상호 작용 환경에 종속시킴으로써, 사회적 평가는 에이전트의 더 높은 수준의 사회적 인지에 대한 귀중한 통찰력을 제공한다. (3) <span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.4">Multi-task evaluation:</span> 이 방법에서는 사람들이 서로 다른 도메인의 다양한 태스크 집합을 사용하여 에이전트를 평가하는데, 이는 오픈 도메인 환경에서 에이전트 일반화 능력을 효과적으로 측정할 수 있다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib5" title="">5</a>, <a class="ltx_ref" href="#bib.bib23" title="">23</a>, <a class="ltx_ref" href="#bib.bib125" title="">125</a>, <a class="ltx_ref" href="#bib.bib103" title="">103</a>, <a class="ltx_ref" href="#bib.bib104" title="">104</a>, <a class="ltx_ref" href="#bib.bib168" title="">168</a>, <a class="ltx_ref" href="#bib.bib175" title="">175</a>]</cite> (4) <span class="ltx_text ltx_font_italic" id="S4.SS2.p3.1.5">소프트웨어 테스팅:</span> 이 방법에서 연구자들은 테스트 케이스 생성, 버그 재생, 디버깅 코드 재생, 개발자 및 외부 도구와의 상호 작용과 같은 소프트웨어 테스팅 작업과 같은 작업을 수행하게 함으로써 에이전트를 평가한다. 그런 다음 테스트 커버리지 및 버그 탐지율과 같은 메트릭을 사용하여 LLM 기반 에이전트의 유효성을 측정할 수 있다.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S4.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S4.SS2.p4.1.1">Benchmarks</span>: 메트릭 및 프로토콜이 주어지면 중요한 나머지 측면은 평가를 수행하기 위한 적절한 벤치마크의 선택이다. 과거에, 사람들은 그들의 실험에 다양한 벤치마크를 사용해 왔다. 예를 들어, 많은 연구자들은 에이전트 성능을 평가하기 위해 ALFWorld <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib170" title="">170</a>]</cite>, IGLU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib110" title="">110</a>]</cite>, Minecraft <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib184" title="">184</a>, <a class="ltx_ref" href="#bib.bib148" title="">148</a>, <a class="ltx_ref" href="#bib.bib154" title="">154</a>]</cite>와 같은 시뮬레이션 환경을 벤치마크로 사용한다. Tachikuma<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib94" title="">94</a>]</cite>는 TRPG 게임 로그를 활용하여 여러 캐릭터 및 새로운 객체와의 복잡한 상호 작용을 이해하고 추론하는 LLMs의 능력을 평가하는 벤치마크이다. AgentBench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib103" title="">103</a>]</cite>는 다양한 환경에서 자율 에이전트로서 LLMs를 평가하기 위한 포괄적인 프레임워크를 제공한다. 다양한 도메인에 걸쳐 실제 문제에 대한 에이전트로서 LLM에 대한 최초의 체계적인 평가를 나타낸다. SocKET <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite>는 유머와 비꼬기, 감정과 느낌, 신뢰성 등과 같은 다섯 가지 범주의 소셜 정보를 다루는 58개의 태스크에 걸쳐 LLM의 사회적 능력을 평가하기 위한 포괄적인 벤치마크이다. AgentSims<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>는 LLM 기반 에이전트를 평가하기 위한 다용도 프레임워크로, 대화형 환경에서 에이전트 계획, 메모리 및 액션 전략을 유연하게 설계하고 다양한 에이전트 모듈의 효과를 측정할 수 있다. ToolBench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib125" title="">125</a>]</cite>는 일반적인 도구 사용 능력을 갖춘 강력한 LLM의 개발을 지원하는 것을 목표로 하는 오픈 소스 프로젝트이다. 도구 학습을 기반으로 LLMs을 교육, 서비스 및 평가하기 위한 개방형 플랫폼을 제공합니다. WebShop<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib168" title="">168</a>]</cite>는 제품 검색 및 검색을 위한 성능 측면에서 LLM 기반 에이전트를 평가하기 위한 벤치마크를 개발한다. 벤치마크는 118만 개의 실제 아이템들의 모음을 사용하여 구성된다. Mobile-Env <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib175" title="">175</a>]</cite>는 LLM 기반 에이전트의 다단계 상호작용 능력을 평가하는 데 사용할 수 있는 확장 가능한 대화형 플랫폼이다. WebArena<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib180" title="">180</a>]</cite>는 여러 도메인에 걸쳐 있는 포괄적인 웹 사이트 환경을 제공한다. 목적은 엔드 투 엔드 방식으로 에이전트를 평가하고 완료된 작업의 정확도를 결정하는 것입니다. GentBench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib163" title="">163</a>]</cite>는 복잡한 작업을 완료하기 위해 도구를 사용할 때 추론, 안전성 및 효율성을 포함한 에이전트 기능을 평가하기 위해 설계된 벤치마크이다. RocoBench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib108" title="">108</a>]</cite>는 협력 로봇 공학에서 적응성과 일반화를 평가하기 위한 의사소통과 조정 전략을 강조하는 다양한 시나리오에서 다중 에이전트 협업을 평가하는 6개의 태스크를 가진 벤치마크이다. EmotionBench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib68" title="">68</a>]</cite>는 LLMs의 감정 평가 능력, 즉 특정 상황과 함께 제시될 때 그들의 감정이 어떻게 변화하는지를 평가한다. 8개의 부정적 감정을 이끌어내는 400개 이상의 상황을 수집하고 자기 보고 척도를 사용하여 LLM과 인간 피험자의 감정 상태를 측정한다. PEB<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib29" title="">29</a>]</cite>는 침투 테스트 시나리오에서 LLM 기반 에이전트를 평가하기 위한 벤치마크이며, 선도 플랫폼의 13가지 다양한 대상으로 구성된다. 에이전트에 대한 실제 문제를 반영하여 다양한 난이도에 걸쳐 구조화된 평가를 제공합니다. ClemBench<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib12" title="">12</a>]</cite>는 플레이어로서의 LLMs의 능력을 평가하기 위한 5개의 Dialogue Games를 포함하고 있다. E2E<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib7" title="">7</a>]</cite>는 챗봇의 정확성과 유용성을 테스트하기 위한 종단 간 벤치마크이다.</p>
</div>
<div id="Thmremarkx8" class="ltx_theorem ltx_theorem_remark">
<h6 class="ltx_title ltx_runin ltx_title_theorem">
<span class="ltx_tag ltx_tag_theorem"><span id="Thmremarkx8.1.1.1" class="ltx_text ltx_font_italic">Remark</span></span><span id="Thmremarkx8.2.2" class="ltx_text ltx_font_italic">.</span>
</h6>
<div id="Thmremarkx8.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="Thmremarkx8.p1.1">객관적 평가는 다양한 메트릭을 사용하여 LLM 기반 에이전트 기능의 정량적 평가를 허용한다. 현재 기술이 모든 유형의 에이전트 기능을 완벽하게 측정할 수는 없지만 객관적인 평가는 주관적인 평가를 보완하는 필수적인 통찰력을 제공한다. 객관적인 평가 벤치마크와 방법론의 지속적인 진전은 LLM 기반 자율 에이전트의 개발과 이해를 더욱 진전시킬 것이다.</p>
</div>
<div id="Thmremarkx8.p2" class="ltx_para">
<p class="ltx_p" id="Thmremarkx8.p2.1">위의 섹션에서는 LLM 기반 자율 에이전트 평가를 위한 주관적 및 객관적 전략을 모두 소개한다. 에이전트의 평가는 이 영역에서 중요한 역할을 한다. 그러나 주관적 평가와 객관적 평가 모두 나름대로의 강점과 약점이 있다. 실제로는 에이전트를 종합적으로 평가하기 위해 결합해야 할 수도 있습니다. 우리는 표 <a class="ltx_ref" href="#S4.T3" title="Table 3 ‣ 4.1 Subjective Evaluation ‣ 4 LLM-based Autonomous Agent Evaluation ‣ A Survey on Large Language Model based Autonomous Agents"><span class="ltx_text ltx_ref_tag">3</span></a>에서 이전 작업과 이러한 평가 전략 간의 대응 관계를 요약한다.</p>
</div>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Surveys</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S5.p1.1">대규모 언어 모델의 활발한 발전과 함께 다양한 측면에 대한 자세한 통찰력을 제공하는 수많은 포괄적인 조사가 등장했다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib178" title="">178</a>]</cite>는 LLMs의 배경, 주요 발견 및 주류 기술을 광범위하게 소개하여 기존의 방대한 작품을 포괄한다. 반면에 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib166" title="">166</a>]</cite>는 주로 다양한 다운스트림 작업에서 LLM의 응용 프로그램과 배포와 관련된 문제에 중점을 둡니다. LLM과 인간 지능을 정렬하는 것은 편견 및 환상과 같은 우려를 해결하기 위한 활발한 연구 분야이다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib153" title="">153</a>]</cite>는 데이터 수집 및 모델 훈련 방법론을 포함하여 인간 정렬을 위한 기존 기술을 컴파일했다. 추론은 지능의 중요한 측면으로서 의사 결정, 문제 해결 및 기타 인지 능력에 영향을 미친다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>는 LLMs의 추론 능력에 대한 연구의 현재 상태를 제시하며, 그들의 추론 능력을 향상시키고 평가하기 위한 접근법을 탐구한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib111" title="">111</a>]</cite>는 언어 모델이 추론 능력 및 도구를 활용하는 능력으로 향상될 수 있음을 제안하며, 이를 ARM(Augmented Language Models)이라고 한다. 그들은 ALM의 최근 진보에 대한 포괄적인 검토를 수행한다. 대규모 모델의 활용이 보편화됨에 따라 성능 평가가 점점 더 중요해지고 있다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib15" title="">15</a>]</cite>는 LLMs를 평가하고, 다운스트림 작업 및 사회적 영향에서 무엇을 평가할지, 어디서 평가할지, 그리고 그들의 성능을 평가하는 방법에 대해 조명한다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib14" title="">14</a>]</cite>는 또한 다양한 다운스트림 작업에서 LLM의 능력 및 한계에 대해 논의한다. 앞서 언급한 연구는 훈련, 적용, 평가 등 대형 모델의 다양한 측면을 포괄한다. 그러나 이 논문 이전에 LLM 기반 에이전트의 빠르게 부상하고 유망한 분야에 특별히 초점을 맞춘 작업은 없다. 본 연구에서는 LLM 기반 에이전트의 구축, 적용 및 평가 프로세스를 포함하는 100개의 관련 작업을 수집했다.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Challenges</h2>

<div id="S6.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.p1.1">LLM 기반 자율 에이전트에 대한 이전 작업은 많은 놀라운 성공을 거두었지만 이 분야는 아직 초기 단계이며 개발에서 해결해야 할 몇 가지 중요한 과제가 있다. 다음에서는 여러 가지 대표적인 과제를 제시한다.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Role-playing Capability</h3>

<div id="S6.SS1.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS1.p1.1">기존의 LLM과 달리 자율 에이전트는 다른 작업을 수행하기 위해 특정 역할(<em class="ltx_emph ltx_font_italic" id="S6.SS1.p1.1.1">e.g.</em>, program coder, researcher and chemist)을 수행해야 한다. 따라서 역할극을 위한 에이전트의 능력은 매우 중요하다. LLM들은 영화 리뷰어들과 같은 많은 공통 역할들을 효과적으로 시뮬레이션할 수 있지만, 그들이 정확하게 포착하기 위해 고군분투하는 다양한 역할들과 양상들이 여전히 존재한다. 먼저, LLM은 일반적으로 웹 코퍼스를 기반으로 학습되므로 웹에서 거의 논의되지 않는 역할이나 새로 등장하는 역할에 대해서는 LLM을 잘 시뮬레이션하지 못할 수 있다. 또한, 이전 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib54" title="">54</a>]</cite>는 기존의 LLMs가 인간의 인지심리학적 특성을 잘 모델링하지 못하여 대화 시나리오에서 자기 인식이 부족할 수 있음을 보여주었다. 이러한 문제에 대한 잠재적인 해결책은 LLM을 미세 조정하거나 에이전트 프롬프트/아키텍처 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib87" title="">87</a>]</cite>를 주의 깊게 설계하는 것을 포함할 수 있다. 예를 들어, 먼저 흔하지 않은 역할이나 심리학 캐릭터에 대한 실제 인간 데이터를 수집한 다음 이를 활용하여 LLM을 미세 조정할 수 있다. 그러나 미세 조정된 모델이 공통 역할에 대해 여전히 잘 수행되도록 하는 방법은 추가 문제를 제기할 수 있다. 미세 조정 외에도 역할 수행에 대한 LLM 기능을 향상시키기 위해 맞춤형 에이전트 프롬프트/아키텍처를 설계할 수도 있습니다. 그러나 설계 공간이 너무 크기 때문에 최적의 프롬프트/아키텍처를 찾는 것은 쉽지 않다.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Generalized Human Alignment</h3>

<div id="S6.SS2.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS2.p1.1">인간 정렬은 전통적인 LLM에 대해 많이 논의되어 왔다. LLM 기반 자율 에이전트 분야에서, 특히 에이전트가 시뮬레이션에 활용될 때, 우리는 이 개념이 더 깊이 논의되어야 한다고 믿는다. 인간에게 더 나은 서비스를 제공하기 위해 전통적인 LLM은 보통 올바른 인간 가치와 일치하도록 미세 조정되며, 예를 들어 에이전트는 복수를 위한 폭탄을 만들 계획을 세워서는 안 된다. 그러나 에이전트가 실제 시뮬레이션에 활용될 때 이상적인 시뮬레이터는 잘못된 값을 가진 에이전트를 포함하여 다양한 인간 특성을 정직하게 묘사할 수 있어야 한다. 실제로 인간의 부정적인 측면을 시뮬레이션하는 것은 훨씬 더 중요할 수 있는데, 시뮬레이션의 중요한 목표는 문제를 발견하고 해결하는 것이고 부정적인 측면이 없다는 것은 해결할 문제가 없다는 것을 의미하기 때문이다. 예를 들어, 실제 사회를 시뮬레이션하기 위해, 우리는 행위자가 폭탄을 만들 계획을 세울 수 있도록 허용해야 하고, 그 계획을 실행하기 위해 어떻게 행동할 것인지, 그리고 그 행동의 영향을 관찰해야 할 수도 있다. 이러한 관찰에 기초하여, 사람들은 실제 사회에서 유사한 행동을 멈추기 위해 더 나은 행동을 할 수 있다. 위의 사례에서 영감을 얻은 에이전트 기반 시뮬레이션의 중요한 문제는 일반화된 인간 정렬을 수행하는 방법, 즉 다양한 목적과 응용 분야에서 에이전트가 다양한 인간 가치와 정렬할 수 있어야 한다는 것이다. 그러나 ChatGPT와 GPT-4를 포함한 기존의 강력한 LLM은 대부분 통일된 인간 가치와 일치한다. 따라서 흥미로운 방향은 적절한 프롬프트 전략을 설계하여 이러한 모델을 "재정렬"하는 방법이다.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Prompt Robustness</h3>

<div id="S6.SS3.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS3.p1.1">에이전트에서 합리적인 동작을 보장하기 위해 설계자는 종종 메모리 및 계획 모듈과 같은 추가 모듈을 LLM에 통합한다. 그러나 이러한 모듈을 포함하려면 일관된 작동과 효과적인 커뮤니케이션을 용이하게 하기 위해 더 많은 프롬프트를 개발해야 한다. 이전 연구 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib186" title="">186</a>, <a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>는 LLM에 대한 프롬프트의 견고성 부족을 강조했는데, 사소한 변경도 실질적으로 다른 결과를 산출할 수 있기 때문이다. 이 문제는 단일 프롬프트가 아니라 하나의 모듈에 대한 프롬프트가 다른 모듈에 영향을 미칠 가능성이 있는 모든 모듈을 고려하는 프롬프트 프레임워크를 포함하기 때문에 자율 에이전트를 구성할 때 더 두드러진다. 또한, 프롬프트 프레임워크는 LLM에 따라 크게 다를 수 있다. 다양한 LLM에 적용할 수 있는 통일되고 강력한 신속한 프레임워크를 개발하는 것은 중요하지만 해결되지 않은 문제이다. 앞서 언급한 문제에 대한 두 가지 잠재적인 해결책은 (1) 시행착오를 통해 필수 프롬프트 요소를 수동으로 만들거나 (2) GPT를 사용하여 프롬프트를 자동으로 생성하는 것이다.</p>
</div>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Hallucination</h3>

<div id="S6.SS4.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS4.p1.1">환각은 LLM에 근본적인 도전을 제기하며, 여기서 모델은 거짓 정보를 자신 있게 잘못 출력한다. 이 문제는 자율 대리인에서도 만연해 있다. 예를 들어, <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib74" title="">74</a>]</cite>에서는 코드 생성 작업 중 단순한 명령어에 직면했을 때 에이전트가 환각 행동을 보일 수 있음을 관찰하였다. 환각은 올바르지 않거나 오판의 소지가 있는 코드, 보안 위험 및 윤리적 문제 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib74" title="">74</a>]</cite>와 같은 심각한 결과를 초래할 수 있다. 이 문제를 해결하기 위해, 한 가지 가능한 접근법은 인간-에이전트 상호작용 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>의 루프 내에 인간 보정 피드백을 통합하는 것이다. 환각 문제에 대한 더 많은 논의는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib178" title="">178</a>]</cite>에서 볼 수 있다.</p>
</div>
</section>
<section id="S6.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5 </span>Knowledge Boundary</h3>

<div id="S6.SS5.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS5.p1.1">LLM 기반 자율 에이전트의 중요한 응용은 다양한 실제 인간 행동을 시뮬레이션하는 것이다. 인간 시뮬레이션에 대한 연구는 오랜 역사를 가지고 있으며 최근 관심이 급증한 것은 LLM이 인간 행동을 시뮬레이션하는 데 상당한 능력을 보여준 놀라운 발전에 기인할 수 있다. 그러나, LLM들의 전력이 항상 유리한 것은 아닐 수 있다는 것을 인식하는 것이 중요하다. 특히 이상적인 시뮬레이션은 인간의 지식을 정확하게 복제해야 한다. 이와 관련하여 LLM은 일반 개인의 범위를 능가하는 광범위한 웹 지식 코퍼스에 대해 훈련되기 때문에 과도한 권한을 나타낼 수 있다. LLM의 엄청난 능력은 시뮬레이션의 효과에 상당한 영향을 미칠 수 있다. 예를 들어, 다양한 영화에 대한 사용자 선택 행동을 시뮬레이션하려고 할 때, LLMs가 이러한 영화에 대한 사전 지식이 없는 입장을 취하도록 하는 것이 중요하다. 그러나 LLM은 이미 이러한 영화에 대한 정보를 획득했을 가능성이 있다. 적절한 전략을 구현하지 않으면 LLM은 실제 사용자가 이러한 영화의 콘텐츠에 미리 액세스할 수 없음에도 불구하고 광범위한 지식을 기반으로 결정을 내릴 수 있다. 위의 예제를 바탕으로 신뢰할 수 있는 에이전트 시뮬레이션 환경을 구축하기 위해서는 LLM에 대한 사용자 미지의 지식의 활용을 어떻게 제약할 것인가가 중요한 문제라는 결론을 내릴 수 있다.</p>
</div>
</section>
<section id="S6.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.6 </span>Efficiency</h3>

<div id="S6.SS6.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S6.SS6.p1.1">자기회귀 구조 때문에 LLM은 일반적으로 추론 속도가 느리다. 그러나, 에이전트는 메모리 모듈로부터 정보를 추출하는 것과 같은, 각각의 액션에 대해 LLM들을 여러 번 쿼리하고, 액션들을 취하기 전에 계획을 세우는 것 등을 필요로 할 수 있다. 결과적으로, 에이전트 액션의 효율성은 LLM 추론의 속도에 크게 영향을 받는다. 동일한 API 키를 사용하여 여러 에이전트를 배포하면 시간 비용이 더욱 크게 증가할 수 있습니다.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para ltx_noindent">
<p class="ltx_p" id="S7.p1.1">본 조사에서는 LLM 기반 자율 에이전트 분야의 기존 연구를 체계적으로 정리한다. 우리는 에이전트의 구성, 적용 및 평가를 포함한 세 가지 측면에서 이러한 연구를 제시하고 검토한다. 이러한 각 측면에 대해 주요 기술과 개발 이력을 요약하여 기존 연구 간의 연결을 도출하기 위한 세부 분류법을 제공한다. 우리는 이전 작업을 검토하는 것 외에도 이 분야의 몇 가지 과제를 제안하며, 이는 잠재적인 미래 방향을 안내할 것으로 예상된다.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Gati&nbsp;V Aher, Rosa&nbsp;I Arriaga, and Adam&nbsp;Tauman Kalai.

</span>
<span class="ltx_bibblock">Using large language models to simulate multiple humans and replicate
human subject studies.

</span>
<span class="ltx_bibblock">In <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
337–371. PMLR, 2023.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron
David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman,
et&nbsp;al.

</span>
<span class="ltx_bibblock">Do as i can, not as i say: Grounding language in robotic affordances.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2204.01691</span>, 2022.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Elif Akata, Lion Schulz, Julian Coda-Forno, Seong&nbsp;Joon Oh, Matthias Bethge, and
Eric Schulz.

</span>
<span class="ltx_bibblock">Playing repeated games with large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.16867</span>, 2023.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Anthropic.

</span>
<span class="ltx_bibblock">Model card and evaluations for claude models.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://www-files.anthropic.com/production/images/Model-Card-Claude-2.pdf?ref=maginative.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www-files.anthropic.com/production/images/Model-Card-Claude-2.pdf?ref=maginative.com</a>,
2023.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Lisa&nbsp;P Argyle, Ethan&nbsp;C Busby, Nancy Fulda, Joshua&nbsp;R Gubler, Christopher
Rytting, and David Wingate.

</span>
<span class="ltx_bibblock">Out of one, many: Using language models to simulate human samples.

</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Political Analysis</span>, 31(3):337–351, 2023.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Christopher&nbsp;A Bail.

</span>
<span class="ltx_bibblock">Can generative AI improve social science?

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">SocArXiv</span>, 2023.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Debarag Banerjee, Pooja Singh, Arjun Avadhanam, and Saksham Srivastava.

</span>
<span class="ltx_bibblock">Benchmarking llm powered chatbots: Methods and metrics, 2023.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi,
Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr
Nyczyk, et&nbsp;al.

</span>
<span class="ltx_bibblock">Graph of thoughts: Solving elaborate problems with large language
models.

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.09687</span>, 2023.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Daniil&nbsp;A Boiko, Robert MacKnight, and Gabe Gomes.

</span>
<span class="ltx_bibblock">Emergent autonomous scientific research capabilities of large
language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.05332</span>, 2023.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Andres&nbsp;M Bran, Sam Cox, Andrew&nbsp;D White, and Philippe Schwaller.

</span>
<span class="ltx_bibblock">ChemCrow: Augmenting large-language models with chemistry tools.

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.05376</span>, 2023.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Tom&nbsp;B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et&nbsp;al.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2005.14165</span>, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Kranti Chalamalasetti, Jana Götze, Sherzod Hakimov, Brielen Madureira,
Philipp Sadler, and David Schlangen.

</span>
<span class="ltx_bibblock">clembench: Using game play to evaluate chat-optimized language models
as conversational agents.

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.13455</span>, 2023.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shanghang Zhang,
Jie Fu, and Zhiyuan Liu.

</span>
<span class="ltx_bibblock">ChatEval: Towards better LLM-based evaluators through multi-agent
debate.

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.07201</span>, 2023.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Tyler&nbsp;A Chang and Benjamin&nbsp;K Bergen.

</span>
<span class="ltx_bibblock">Language model behavior: A comprehensive survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.11504</span>, 2023.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Yupeng Chang, Xu&nbsp;Wang, Jindong Wang, Yuan Wu, Kaijie Zhu, Hao Chen, Linyi Yang,
Xiaoyuan Yi, Cunxiang Wang, Yidong Wang, et&nbsp;al.

</span>
<span class="ltx_bibblock">A survey on evaluation of large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.03109</span>, 2023.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Harrison Chase.

</span>
<span class="ltx_bibblock">langchain.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://docs.langchain.com/docs/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://docs.langchain.com/docs/</a>, 2023.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Angelica Chen, Jason Phang, Alicia Parrish, Vishakh Padmakumar, Chen Zhao,
Samuel&nbsp;R Bowman, and Kyunghyun Cho.

</span>
<span class="ltx_bibblock">Two failures of self-consistency in the multi-step reasoning of
LLMs.

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.14279</span>, 2023.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Liting Chen, Lu&nbsp;Wang, Hang Dong, Yali Du, Jie Yan, Fangkai Yang, Shuang Li,
Pu&nbsp;Zhao, Si&nbsp;Qin, Saravan Rajmohan, et&nbsp;al.

</span>
<span class="ltx_bibblock">Introspective tips: Large language model for in-context decision
making.

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.11598</span>, 2023.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de&nbsp;Oliveira
Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg
Brockman, et&nbsp;al.

</span>
<span class="ltx_bibblock">Evaluating large language models trained on code.

</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2107.03374</span>, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Po-Lin Chen and Cheng-Shang Chang.

</span>
<span class="ltx_bibblock">InterAct: Exploring the potentials of ChatGPT as a cooperative
agent.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.01552</span>, 2023.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Xinshi Chen, Shuang Li, Hui Li, Shaohua Jiang, Yuan Qi, and Le&nbsp;Song.

</span>
<span class="ltx_bibblock">Generative adversarial user model for reinforcement learning based
recommendation system.

</span>
<span class="ltx_bibblock">In <span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
1052–1061. PMLR, 2019.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Zhipeng Chen, Kun Zhou, Beichen Zhang, Zheng Gong, Wayne&nbsp;Xin Zhao, and Ji-Rong
Wen.

</span>
<span class="ltx_bibblock">ChatCoT: Tool-augmented chain-of-thought reasoning on chat-based
large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.14323</span>, 2023.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Minje Choi, Jiaxin Pei, Sagar Kumar, Chang Shu, and David Jurgens.

</span>
<span class="ltx_bibblock">Do LLMs understand social knowledge? evaluating the sociability of
large language models with socket benchmark.

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.14938</span>, 2023.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Cédric Colas, Laetitia Teodorescu, Pierre-Yves Oudeyer, Xingdi Yuan, and
Marc-Alexandre Côté.

</span>
<span class="ltx_bibblock">Augmenting autotelic agents with large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.12487</span>, 2023.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Jiaxi Cui, Zongjian Li, Yang Yan, Bohua Chen, and Li&nbsp;Yuan.

</span>
<span class="ltx_bibblock">ChatLaw: Open-source legal large language model with integrated
external knowledge bases.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.16092</span>, 2023.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Gautier Dagan, Frank Keller, and Alex Lascarides.

</span>
<span class="ltx_bibblock">Dynamic planning with a LLM.

</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.06391</span>, 2023.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Yuhao Dan, Zhikai Lei, Yiyang Gu, Yong Li, Jianghao Yin, Jiaju Lin, Linhao Ye,
Zhiyan Tie, Yougen Zhou, Yilei Wang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Educhat: A large-scale language model-based chatbot system for
intelligent education.

</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.02773</span>, 2023.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Ishita Dasgupta, Christine Kaeser-Chen, Kenneth Marino, Arun Ahuja, Sheila
Babayan, Felix Hill, and Rob Fergus.

</span>
<span class="ltx_bibblock">Collaborating with language models for embodied reasoning.

</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.00763</span>, 2023.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Gelei Deng, Yi&nbsp;Liu, Víctor Mayoral-Vilches, Peng Liu, Yuekang Li, Yuan Xu,
Tianwei Zhang, Yang Liu, Martin Pinzger, and Stefan Rass.

</span>
<span class="ltx_bibblock">Pentestgpt: An llm-empowered automatic penetration testing tool.

</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.06782</span>, 2023.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Xiang Deng, Yu&nbsp;Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan
Sun, and Yu&nbsp;Su.

</span>
<span class="ltx_bibblock">Mind2web: Towards a generalist agent for the web.

</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.06070</span>, 2023.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Ameet Deshpande, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, and
Karthik Narasimhan.

</span>
<span class="ltx_bibblock">Toxicity in ChatGPT: Analyzing persona-assigned language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.05335</span>, 2023.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Norman Di&nbsp;Palo, Arunkumar Byravan, Leonard Hasenclever, Markus Wulfmeier,
Nicolas Heess, and Martin Riedmiller.

</span>
<span class="ltx_bibblock">Towards a unified agent with foundation models.

</span>
<span class="ltx_bibblock">In <span id="bib.bib32.1.1" class="ltx_text ltx_font_italic">Workshop on Reincarnating Reinforcement Learning at ICLR
2023</span>, 2023.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Yihong Dong, Xue Jiang, Zhi Jin, and Ge&nbsp;Li.

</span>
<span class="ltx_bibblock">Self-collaboration code generation via ChatGPT.

</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.07590</span>, 2023.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Iddo Drori, Sarah Zhang, Reece Shuttleworth, Leonard Tang, Albert Lu, Elizabeth
Ke, Kevin Liu, Linda Chen, Sunny Tran, Newman Cheng, Roman Wang, Nikhil
Singh, Taylor&nbsp;L. Patti, Jayson Lynch, Avi Shporer, Nakul Verma, Eugene Wu,
and Gilbert Strang.

</span>
<span class="ltx_bibblock">A neural network solves, explains, and generates university math
problems by program synthesis and few-shot learning at human level.

</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text ltx_font_italic">Proceedings of the National Academy of Sciences</span>, 119(32), aug
2022.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Yilun Du, Shuang Li, Antonio Torralba, Joshua&nbsp;B Tenenbaum, and Igor Mordatch.

</span>
<span class="ltx_bibblock">Improving factuality and reasoning in language models through
multiagent debate.

</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.14325</span>, 2023.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Alex&nbsp;MacCaw et&nbsp;al.

</span>
<span class="ltx_bibblock">WorkGPT.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/team-openpm/workgpt" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/team-openpm/workgpt</a>, 2023.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Anton&nbsp;Osika et&nbsp;al.

</span>
<span class="ltx_bibblock">GPT engineer.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/AntonOsika/gpt-engineer" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/AntonOsika/gpt-engineer</a>, 2023.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Assaf&nbsp;Elovic et&nbsp;al.

</span>
<span class="ltx_bibblock">GPT-researcher.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/assafelovic/gpt-researcher" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/assafelovic/gpt-researcher</a>, 2023.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Chen et&nbsp;al.

</span>
<span class="ltx_bibblock">Agentverse.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/OpenBMB/AgentVerse" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/OpenBMB/AgentVerse</a>, 2023.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
Chen et&nbsp;al.

</span>
<span class="ltx_bibblock">Xlang.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/xlang-ai/xlang" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/xlang-ai/xlang</a>, 2023.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Enricoros et&nbsp;al.

</span>
<span class="ltx_bibblock">Miniagi.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/muellerberndt/mini-agi" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/muellerberndt/mini-agi</a>, 2023.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Eumemic et&nbsp;al.

</span>
<span class="ltx_bibblock">Ai-legion.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/eumemic/ai-legion" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/eumemic/ai-legion</a>, 2023.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Fayaz&nbsp;Rahman et&nbsp;al.

</span>
<span class="ltx_bibblock">LoopGPT.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/farizrahman4u/loopgpt" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/farizrahman4u/loopgpt</a>, 2023.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Josh&nbsp;XT et&nbsp;al.

</span>
<span class="ltx_bibblock">Agixt.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/Josh-XT/AGiXT" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Josh-XT/AGiXT</a>, 2023.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Melih&nbsp;Unsal et&nbsp;al.

</span>
<span class="ltx_bibblock">DemoGPT.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/melih-unsal/DemoGPT" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/melih-unsal/DemoGPT</a>, 2023.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Nakajima et&nbsp;al.

</span>
<span class="ltx_bibblock">Babyagi.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/yoheinakajima" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/yoheinakajima</a>, 2023.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Reworkd et&nbsp;al.

</span>
<span class="ltx_bibblock">AgentGPT.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/reworkd/AgentGPT" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/reworkd/AgentGPT</a>, 2023.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Swyxio et&nbsp;al.

</span>
<span class="ltx_bibblock">Smolmodels.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/smol-ai/developer" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/smol-ai/developer</a>, 2023.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Torantulino et&nbsp;al.

</span>
<span class="ltx_bibblock">Auto-GPT.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/Significant-Gravitas/Auto-GPT" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Significant-Gravitas/Auto-GPT</a>, 2023.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
TransformerOptimus et&nbsp;al.

</span>
<span class="ltx_bibblock">Superagi.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/TransformerOptimus/SuperAGI" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/TransformerOptimus/SuperAGI</a>, 2023.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Jonathan St&nbsp;BT Evans and Keith&nbsp;E Stanovich.

</span>
<span class="ltx_bibblock">Dual-process theories of higher cognition: Advancing the debate.

</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text ltx_font_italic">Perspectives on psychological science</span>, 8(3):223–241, 2013.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Hugging Face.

</span>
<span class="ltx_bibblock">transformers-agent.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://huggingface.co/docs/transformers/transformers_agents" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/docs/transformers/transformers_agents</a>,
2023.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Robert Feldt, Sungmin Kang, Juyeon Yoon, and Shin Yoo.

</span>
<span class="ltx_bibblock">Towards autonomous testing agents via conversational large language
models.

</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.05152</span>, 2023.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Kevin&nbsp;A Fischer.

</span>
<span class="ltx_bibblock">Reflective linguistic programming (rlp): A stepping stone in
socially-aware agi (socialagi).

</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.12647</span>, 2023.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Chen Gao, Xiaochong Lan, Zhihong Lu, Jinzhu Mao, Jinghua Piao, Huandong Wang,
Depeng Jin, and Yong Li.

</span>
<span class="ltx_bibblock">S3: Social-network simulation system with large language
model-empowered agents.

</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.14984</span>, 2023.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Yingqiang Ge, Wenyue Hua, Jianchao Ji, Juntao Tan, Shuyuan Xu, and Yongfeng
Zhang.

</span>
<span class="ltx_bibblock">OpenAGI: When llm meets domain experts.

</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.04370</span>, 2023.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Zorik Gekhman, Nadav Oved, Orgad Keller, Idan Szpektor, and Roi Reichart.

</span>
<span class="ltx_bibblock">On the robustness of dialogue history representation in
conversational question answering: a comprehensive study and a new
prompt-based method.

</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text ltx_font_italic">Transactions of the Association for Computational Linguistics</span>,
11:351–366, 2023.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Maitrey Gramopadhye and Daniel Szafir.

</span>
<span class="ltx_bibblock">Generating executable action plans with environmentally-aware
language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2210.04964</span>, 2022.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Igor Grossmann, Matthew Feinberg, Dawn&nbsp;C Parker, Nicholas&nbsp;A Christakis,
Philip&nbsp;E Tetlock, and William&nbsp;A Cunningham.

</span>
<span class="ltx_bibblock">Ai and the transformation of social science research.

</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text ltx_font_italic">Science</span>, 380(6650):1108–1109, 2023.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.

</span>
<span class="ltx_bibblock">Soft actor-critic: Off-policy maximum entropy deep reinforcement
learning with a stochastic actor.

</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1801.01290</span>, 2018.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Sil Hamilton.

</span>
<span class="ltx_bibblock">Blind judgement: Agent-based supreme court modelling with GPT.

</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2301.05327</span>, 2023.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Shibo Hao, Yi&nbsp;Gu, Haodi Ma, Joshua&nbsp;Jiahua Hong, Zhen Wang, Daisy&nbsp;Zhe Wang, and
Zhiting Hu.

</span>
<span class="ltx_bibblock">Reasoning with language model is planning with world model.

</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.14992</span>, 2023.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Zhuolun He, Haoyuan Wu, Xinyun Zhang, Xufeng Yao, Su&nbsp;Zheng, Haisheng Zheng, and
Bei Yu.

</span>
<span class="ltx_bibblock">Chateda: A large language model powered autonomous agent for eda,
2023.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Ceyao Zhang, Zili Wang,
Steven Ka&nbsp;Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu Ran, et&nbsp;al.

</span>
<span class="ltx_bibblock">MetaGPT: Meta programming for multi-agent collaborative framework.

</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.00352</span>, 2023.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
John&nbsp;J Horton.

</span>
<span class="ltx_bibblock">Large language models as simulated economic agents: What can we learn
from homo silicus?

</span>
<span class="ltx_bibblock">Technical report, National Bureau of Economic Research, 2023.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Bin Hu, Chenyang Zhao, Pu&nbsp;Zhang, Zihao Zhou, Yuanhang Yang, Zenglin Xu, and Bin
Liu.

</span>
<span class="ltx_bibblock">Enabling intelligent interactions between an agent and an llm: A
reinforcement learning approach.

</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.03604</span>, 2023.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Chenxu Hu, Jie Fu, Chenzhuang Du, Simian Luo, Junbo Zhao, and Hang Zhao.

</span>
<span class="ltx_bibblock">Chatdb: Augmenting LLMs with databases as their symbolic memory.

</span>
<span class="ltx_bibblock"><span id="bib.bib67.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.03901</span>, 2023.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Jen-tse Huang, Man&nbsp;Ho Lam, Eric&nbsp;John Li, Shujie Ren, Wenxuan Wang, Wenxiang
Jiao, Zhaopeng Tu, and Michael&nbsp;R Lyu.

</span>
<span class="ltx_bibblock">Emotionally numb or empathetic? evaluating how llms feel using
emotionbench.

</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.03656</span>, 2023.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Jie Huang and Kevin Chen-Chuan Chang.

</span>
<span class="ltx_bibblock">Towards reasoning in large language models: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib69.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2212.10403</span>, 2022.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch.

</span>
<span class="ltx_bibblock">Language models as zero-shot planners: Extracting actionable
knowledge for embodied agents.

</span>
<span class="ltx_bibblock">In <span id="bib.bib70.1.1" class="ltx_text ltx_font_italic">International Conference on Machine Learning</span>, pages
9118–9147. PMLR, 2022.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy
Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, et&nbsp;al.

</span>
<span class="ltx_bibblock">Inner monologue: Embodied reasoning through planning with language
models.

</span>
<span class="ltx_bibblock"><span id="bib.bib71.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2207.05608</span>, 2022.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
Ziheng Huang, Sebastian Gutierrez, Hemanth Kamana, and Stephen MacNeil.

</span>
<span class="ltx_bibblock">Memory sandbox: Transparent and interactive memory management for
conversational agents.

</span>
<span class="ltx_bibblock"><span id="bib.bib72.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.01542</span>, 2023.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
Sajed Jalil, Suzzana Rafi, Thomas&nbsp;D LaToza, Kevin Moran, and Wing Lam.

</span>
<span class="ltx_bibblock">ChatGPT and software testing education: Promises &amp; perils.

</span>
<span class="ltx_bibblock">In <span id="bib.bib73.1.1" class="ltx_text ltx_font_italic">2023 IEEE International Conference on Software Testing,
Verification and Validation Workshops (ICSTW)</span>, pages 4130–4137. IEEE, 2023.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii,
Ye&nbsp;Jin Bang, Andrea Madotto, and Pascale Fung.

</span>
<span class="ltx_bibblock">Survey of hallucination in natural language generation.

</span>
<span class="ltx_bibblock"><span id="bib.bib74.1.1" class="ltx_text ltx_font_italic">ACM Computing Surveys</span>, 55(12):1–38, 2023.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
Shi Jinxin, Zhao Jiabao, Wang Yilei, Wu&nbsp;Xingjiao, Li&nbsp;Jiawen, and He&nbsp;Liang.

</span>
<span class="ltx_bibblock">Cgmi: Configurable general multi-agent interaction framework, 2023.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Oliver&nbsp;P John, Eileen&nbsp;M Donahue, and Robert&nbsp;L Kentle.

</span>
<span class="ltx_bibblock">Big five inventory.

</span>
<span class="ltx_bibblock"><span id="bib.bib76.1.1" class="ltx_text ltx_font_italic">Journal of Personality and Social Psychology</span>, 1991.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
John&nbsp;A Johnson.

</span>
<span class="ltx_bibblock">Measuring thirty facets of the five factor model with a 120-item
public domain inventory: Development of the ipip-neo-120.

</span>
<span class="ltx_bibblock"><span id="bib.bib77.1.1" class="ltx_text ltx_font_italic">Journal of research in personality</span>, 51:78–89, 2014.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
Sungmin Kang, Juyeon Yoon, and Shin Yoo.

</span>
<span class="ltx_bibblock">Large language models are few-shot testers: Exploring LLM-based
general bug reproduction.

</span>
<span class="ltx_bibblock">In <span id="bib.bib78.1.1" class="ltx_text ltx_font_italic">2023 IEEE/ACM 45th International Conference on Software
Engineering (ICSE)</span>, pages 2312–2323. IEEE, 2023.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
Yeonghun Kang and Jihan Kim.

</span>
<span class="ltx_bibblock">Chatmof: An autonomous ai system for predicting and generating
metal-organic frameworks.

</span>
<span class="ltx_bibblock"><span id="bib.bib79.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.01423</span>, 2023.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir
Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin Leyton-Brown, et&nbsp;al.

</span>
<span class="ltx_bibblock">Mrkl systems: A modular, neuro-symbolic architecture that combines
large language models, external knowledge sources and discrete reasoning.

</span>
<span class="ltx_bibblock"><span id="bib.bib80.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2205.00445</span>, 2022.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
Geunwoo Kim, Pierre Baldi, and Stephen McAleer.

</span>
<span class="ltx_bibblock">Language models can solve computer tasks.

</span>
<span class="ltx_bibblock"><span id="bib.bib81.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.17491</span>, 2023.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
Takeshi Kojima, Shixiang&nbsp;Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke
Iwasawa.

</span>
<span class="ltx_bibblock">Large language models are zero-shot reasoners.

</span>
<span class="ltx_bibblock"><span id="bib.bib82.1.1" class="ltx_text ltx_font_italic">Advances in neural information processing systems</span>,
35:22199–22213, 2022.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
Grgur Kovač, Rémy Portelas, Peter&nbsp;Ford Dominey, and Pierre-Yves
Oudeyer.

</span>
<span class="ltx_bibblock">The socialai school: Insights from developmental psychology towards
artificial socio-cultural agents.

</span>
<span class="ltx_bibblock"><span id="bib.bib83.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.07871</span>, 2023.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
Ranjay Krishna, Donsuk Lee, Li&nbsp;Fei-Fei, and Michael&nbsp;S Bernstein.

</span>
<span class="ltx_bibblock">Socially situated artificial intelligence enables learning from human
interaction.

</span>
<span class="ltx_bibblock"><span id="bib.bib84.1.1" class="ltx_text ltx_font_italic">Proceedings of the National Academy of Sciences</span>,
119(39):e2115730119, 2022.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
Mina Lee, Megha Srivastava, Amelia Hardy, John Thickstun, Esin Durmus, Ashwin
Paranjape, Ines Gerard-Ursin, Xiang&nbsp;Lisa Li, Faisal Ladhak, Frieda Rong,
et&nbsp;al.

</span>
<span class="ltx_bibblock">Evaluating human-language model interaction.

</span>
<span class="ltx_bibblock"><span id="bib.bib85.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2212.09746</span>, 2022.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
Chao Li, Xing Su, Chao Fan, Haoying Han, Cong Xue, and Chunmo Zheng.

</span>
<span class="ltx_bibblock">Quantifying the impact of large language models on collective opinion
dynamics.

</span>
<span class="ltx_bibblock"><span id="bib.bib86.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.03313</span>, 2023.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
Cheng Li, Jindong Wang, Kaijie Zhu, Yixuan Zhang, Wenxin Hou, Jianxun Lian, and
Xing Xie.

</span>
<span class="ltx_bibblock">Emotionprompt: Leveraging psychology for large language models
enhancement via emotional stimulus.

</span>
<span class="ltx_bibblock"><span id="bib.bib87.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.11760</span>, 2023.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
Guohao Li, Hasan Abed Al&nbsp;Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and
Bernard Ghanem.

</span>
<span class="ltx_bibblock">Camel: Communicative agents for" mind" exploration of large scale
language model society.

</span>
<span class="ltx_bibblock"><span id="bib.bib88.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.17760</span>, 2023.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
Haonan Li, Yu&nbsp;Hao, Yizhuo Zhai, and Zhiyun Qian.

</span>
<span class="ltx_bibblock">The hitchhiker’s guide to program analysis: A journey with large
language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib89.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.00245</span>, 2023.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
Minghao Li, Feifan Song, Bowen Yu, Haiyang Yu, Zhoujun Li, Fei Huang, and
Yongbin Li.

</span>
<span class="ltx_bibblock">Api-bank: A benchmark for tool-augmented LLMs.

</span>
<span class="ltx_bibblock"><span id="bib.bib90.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.08244</span>, 2023.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
Siyu Li, Jin Yang, and Kui Zhao.

</span>
<span class="ltx_bibblock">Are you in a masquerade? exploring the behavior and impact of large
language model driven social bots in online social networks.

</span>
<span class="ltx_bibblock"><span id="bib.bib91.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.10337</span>, 2023.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
Xinnian Liang, Bing Wang, Hui Huang, Shuangzhi Wu, Peihao Wu, Lu&nbsp;Lu, Zejun Ma,
and Zhoujun Li.

</span>
<span class="ltx_bibblock">Unleashing infinite-length input capacity for large-scale language
models with self-controlled memory system.

</span>
<span class="ltx_bibblock"><span id="bib.bib92.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.13343</span>, 2023.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
Yaobo Liang, Chenfei Wu, Ting Song, Wenshan Wu, Yan Xia, Yu&nbsp;Liu, Yang Ou, Shuai
Lu, Lei Ji, Shaoguang Mao, et&nbsp;al.

</span>
<span class="ltx_bibblock">Taskmatrix. ai: Completing tasks by connecting foundation models with
millions of apis.

</span>
<span class="ltx_bibblock"><span id="bib.bib93.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.16434</span>, 2023.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
Yuanzhi Liang, Linchao Zhu, and Yi&nbsp;Yang.

</span>
<span class="ltx_bibblock">Tachikuma: Understading complex interactions with multi-character and
novel objects by large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib94.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.12573</span>, 2023.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
Mark Liffiton, Brad Sheese, Jaromir Savelka, and Paul Denny.

</span>
<span class="ltx_bibblock">Codehelp: Using large language models with guardrails for scalable
support in programming classes.

</span>
<span class="ltx_bibblock"><span id="bib.bib95.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.06921</span>, 2023.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
Timothy&nbsp;P Lillicrap, Jonathan&nbsp;J Hunt, Alexander Pritzel, Nicolas Heess, Tom
Erez, Yuval Tassa, David Silver, and Daan Wierstra.

</span>
<span class="ltx_bibblock">Continuous control with deep reinforcement learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib96.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1509.02971</span>, 2015.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
Bill&nbsp;Yuchen Lin, Yicheng Fu, Karina Yang, Prithviraj Ammanabrolu, Faeze
Brahman, Shiyu Huang, Chandra Bhagavatula, Yejin Choi, and Xiang Ren.

</span>
<span class="ltx_bibblock">Swiftsage: A generative agent with fast and slow thinking for complex
interactive tasks.

</span>
<span class="ltx_bibblock"><span id="bib.bib97.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.17390</span>, 2023.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
Jessy Lin, Nicholas Tomlin, Jacob Andreas, and Jason Eisner.

</span>
<span class="ltx_bibblock">Decision-oriented dialogue for human-ai collaboration.

</span>
<span class="ltx_bibblock"><span id="bib.bib98.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.20076</span>, 2023.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
Jiaju Lin, Haoran Zhao, Aochi Zhang, Yiting Wu, Huqiuyue Ping, and Qin Chen.

</span>
<span class="ltx_bibblock">Agentsims: An open-source sandbox for large language model
evaluation.

</span>
<span class="ltx_bibblock"><span id="bib.bib99.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.04026</span>, 2023.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
Bo&nbsp;Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas,
and Peter Stone.

</span>
<span class="ltx_bibblock">LLM+P: Empowering large language models with optimal planning
proficiency.

</span>
<span class="ltx_bibblock"><span id="bib.bib100.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.11477</span>, 2023.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
Hao Liu, Carmelo Sferrazza, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Chain of hindsight aligns language models with feedback.

</span>
<span class="ltx_bibblock"><span id="bib.bib101.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.02676</span>, 3, 2023.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
Ruibo Liu, Ruixin Yang, Chenyan Jia, Ge&nbsp;Zhang, Denny Zhou, Andrew&nbsp;M Dai, Diyi
Yang, and Soroush Vosoughi.

</span>
<span class="ltx_bibblock">Training socially aligned language models in simulated human society.

</span>
<span class="ltx_bibblock"><span id="bib.bib102.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.16960</span>, 2023.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu&nbsp;Gu,
Hangliang Ding, Kaiwen Men, Kejuan Yang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Agentbench: Evaluating LLMs as agents.

</span>
<span class="ltx_bibblock"><span id="bib.bib103.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.03688</span>, 2023.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le&nbsp;Xue, Shelby Heinecke, Rithesh Murthy,
Yihao Feng, Zeyuan Chen, Juan&nbsp;Carlos Niebles, Devansh Arpit, et&nbsp;al.

</span>
<span class="ltx_bibblock">BOLAA: Benchmarking and orchestrating LLM-augmented autonomous
agents.

</span>
<span class="ltx_bibblock"><span id="bib.bib104.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.05960</span>, 2023.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
Zilin Ma, Yiyang Mei, and Zhaoyuan Su.

</span>
<span class="ltx_bibblock">Understanding the benefits and challenges of using large language
model-based conversational agents for mental well-being support.

</span>
<span class="ltx_bibblock"><span id="bib.bib105.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.15810</span>, 2023.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
Aman Madaan, Niket Tandon, Peter Clark, and Yiming Yang.

</span>
<span class="ltx_bibblock">Memory-assisted prompt editing to improve GPT-3 after deployment.

</span>
<span class="ltx_bibblock">In <span id="bib.bib106.1.1" class="ltx_text ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in
Natural Language Processing</span>, pages 2833–2861, 2022.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah
Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Self-refine: Iterative refinement with self-feedback.

</span>
<span class="ltx_bibblock"><span id="bib.bib107.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.17651</span>, 2023.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
Zhao Mandi, Shreeya Jain, and Shuran Song.

</span>
<span class="ltx_bibblock">Roco: Dialectic multi-robot collaboration with large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib108.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.04738</span>, 2023.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
Jordan&nbsp;K Matelsky, Felipe Parodi, Tony Liu, Richard&nbsp;D Lange, and Konrad&nbsp;P
Kording.

</span>
<span class="ltx_bibblock">A large language model-assisted education tool to provide feedback on
open-ended responses.

</span>
<span class="ltx_bibblock"><span id="bib.bib109.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.02439</span>, 2023.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
Nikhil Mehta, Milagro Teruel, Patricio&nbsp;Figueroa Sanz, Xin Deng, Ahmed&nbsp;Hassan
Awadallah, and Julia Kiseleva.

</span>
<span class="ltx_bibblock">Improving grounded language understanding in a collaborative
environment by interacting with agents through help feedback.

</span>
<span class="ltx_bibblock"><span id="bib.bib110.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.10750</span>, 2023.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
Grégoire Mialon, Roberto Dessì, Maria Lomeli, Christoforos Nalmpantis,
Ram Pasunuru, Roberta Raileanu, Baptiste Rozière, Timo Schick, Jane
Dwivedi-Yu, Asli Celikyilmaz, et&nbsp;al.

</span>
<span class="ltx_bibblock">Augmented language models: a survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib111.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.07842</span>, 2023.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
Ning Miao, Yee&nbsp;Whye Teh, and Tom Rainforth.

</span>
<span class="ltx_bibblock">SelfCheck: Using LLMs to zero-shot check their own step-by-step
reasoning.

</span>
<span class="ltx_bibblock"><span id="bib.bib112.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.00436</span>, 2023.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei&nbsp;A Rusu, Joel Veness,
Marc&nbsp;G Bellemare, Alex Graves, Martin Riedmiller, Andreas&nbsp;K Fidjeland, Georg
Ostrovski, et&nbsp;al.

</span>
<span class="ltx_bibblock">Human-level control through deep reinforcement learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib113.1.1" class="ltx_text ltx_font_italic">Nature</span>, 518(7540):529–533, 2015.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
Ali Modarressi, Ayyoob Imani, Mohsen Fayyaz, and Hinrich Schütze.

</span>
<span class="ltx_bibblock">RET-LLM: Towards a general read-write memory for large language
models.

</span>
<span class="ltx_bibblock"><span id="bib.bib114.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.14322</span>, 2023.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina
Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders,
et&nbsp;al.

</span>
<span class="ltx_bibblock">WebGPT: Browser-assisted question-answering with human feedback.

</span>
<span class="ltx_bibblock"><span id="bib.bib115.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2112.09332</span>, 2021.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
Nathalia Nascimento, Paulo Alencar, and Donald Cowan.

</span>
<span class="ltx_bibblock">Self-adaptive large language model (llm)-based multiagent systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib116.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.06187</span>, 2023.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
Youyang Ng, Daisuke Miyashita, Yasuto Hoshi, Yasuhiro Morioka, Osamu Torii,
Tomoya Kodama, and Jun Deguchi.

</span>
<span class="ltx_bibblock">Simplyretrieve: A private and lightweight retrieval-centric
generative ai tool.

</span>
<span class="ltx_bibblock"><span id="bib.bib117.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.03983</span>, 2023.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
Kolby Nottingham, Prithviraj Ammanabrolu, Alane Suhr, Yejin Choi, Hannaneh
Hajishirzi, Sameer Singh, and Roy Fox.

</span>
<span class="ltx_bibblock">Do embodied agents dream of pixelated sheep?: Embodied decision
making using language guided world modelling.

</span>
<span class="ltx_bibblock"><span id="bib.bib118.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2301.12050</span>, 2023.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
Oluwatosin Ogundare, Srinath Madasu, and Nathanial Wiggins.

</span>
<span class="ltx_bibblock">Industrial engineering with large language models: A case study of
ChatGPT’s performance on oil &amp; gas problems.

</span>
<span class="ltx_bibblock"><span id="bib.bib119.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.14354</span>, 2023.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">GPT-4 technical report, 2023.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
Joon&nbsp;Sung Park, Joseph&nbsp;C. O’Brien, Carrie&nbsp;J. Cai, Meredith&nbsp;Ringel Morris, Percy
Liang, and Michael&nbsp;S. Bernstein.

</span>
<span class="ltx_bibblock">Generative agents: Interactive simulacra of human behavior.

</span>
<span class="ltx_bibblock">In <span id="bib.bib121.1.1" class="ltx_text ltx_font_italic">In the 36th Annual ACM Symposium on User Interface Software
and Technology (UIST ’23)</span>, UIST ’23, New York, NY, USA, 2023. Association
for Computing Machinery.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
Joon&nbsp;Sung Park, Lindsay Popowski, Carrie Cai, Meredith&nbsp;Ringel Morris, Percy
Liang, and Michael&nbsp;S Bernstein.

</span>
<span class="ltx_bibblock">Social simulacra: Creating populated prototypes for social computing
systems.

</span>
<span class="ltx_bibblock">In <span id="bib.bib122.1.1" class="ltx_text ltx_font_italic">Proceedings of the 35th Annual ACM Symposium on User
Interface Software and Technology</span>, pages 1–18, 2022.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
Shishir&nbsp;G Patil, Tianjun Zhang, Xin Wang, and Joseph&nbsp;E Gonzalez.

</span>
<span class="ltx_bibblock">Gorilla: Large language model connected with massive apis.

</span>
<span class="ltx_bibblock"><span id="bib.bib123.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.15334</span>, 2023.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan
Liu, and Maosong Sun.

</span>
<span class="ltx_bibblock">Communicative agents for software development.

</span>
<span class="ltx_bibblock"><span id="bib.bib124.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.07924</span>, 2023.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni
Zeng, Yufei Huang, Chaojun Xiao, Chi Han, et&nbsp;al.

</span>
<span class="ltx_bibblock">Tool learning with foundation models.

</span>
<span class="ltx_bibblock"><span id="bib.bib125.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.08354</span>, 2023.

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[126]</span>
<span class="ltx_bibblock">
Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin,
Xin Cong, Xiangru Tang, Bill Qian, et&nbsp;al.

</span>
<span class="ltx_bibblock">ToolLLM: Facilitating large language models to master 16000+
real-world apis.

</span>
<span class="ltx_bibblock"><span id="bib.bib126.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.16789</span>, 2023.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[127]</span>
<span class="ltx_bibblock">
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock"><span id="bib.bib127.1.1" class="ltx_text ltx_font_italic">OpenAI blog</span>, 1(8):9, 2019.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[128]</span>
<span class="ltx_bibblock">
Shreyas&nbsp;Sundara Raman, Vanya Cohen, Eric Rosen, Ifrah Idrees, David Paulius,
and Stefanie Tellex.

</span>
<span class="ltx_bibblock">Planning with large language models via corrective re-prompting.

</span>
<span class="ltx_bibblock"><span id="bib.bib128.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2211.09935</span>, 2022.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[129]</span>
<span class="ltx_bibblock">
Krishan Rana, Jesse Haviland, Sourav Garg, Jad Abou-Chakra, Ian Reid, and Niko
Suenderhauf.

</span>
<span class="ltx_bibblock">Sayplan: Grounding large language models using 3d scene graphs for
scalable task planning.

</span>
<span class="ltx_bibblock"><span id="bib.bib129.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.06135</span>, 2023.

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[130]</span>
<span class="ltx_bibblock">
Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du,
Shiwei Shi, Hangyu Mao, Xingyu Zeng, and Rui Zhao.

</span>
<span class="ltx_bibblock">TPTU: Task planning and tool usage of large language model-based
AI agents.

</span>
<span class="ltx_bibblock"><span id="bib.bib130.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.03427</span>, 2023.

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[131]</span>
<span class="ltx_bibblock">
Mustafa Safdari, Greg Serapio-García, Clément Crepy, Stephen Fitz,
Peter Romero, Luning Sun, Marwa Abdulhai, Aleksandra Faust, and Maja
Matarić.

</span>
<span class="ltx_bibblock">Personality traits in large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib131.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.00184</span>, 2023.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[132]</span>
<span class="ltx_bibblock">
Swarnadeep Saha, Peter Hase, and Mohit Bansal.

</span>
<span class="ltx_bibblock">Can language models teach weaker agents? teacher explanations improve
students via theory of mind.

</span>
<span class="ltx_bibblock"><span id="bib.bib132.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.09299</span>, 2023.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[133]</span>
<span class="ltx_bibblock">
Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria
Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom.

</span>
<span class="ltx_bibblock">Toolformer: Language models can teach themselves to use tools.

</span>
<span class="ltx_bibblock"><span id="bib.bib133.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.04761</span>, 2023.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[134]</span>
<span class="ltx_bibblock">
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.

</span>
<span class="ltx_bibblock">Proximal policy optimization algorithms.

</span>
<span class="ltx_bibblock"><span id="bib.bib134.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1707.06347</span>, 2017.

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[135]</span>
<span class="ltx_bibblock">
Dale Schuurmans.

</span>
<span class="ltx_bibblock">Memory augmented large language models are computationally universal.

</span>
<span class="ltx_bibblock"><span id="bib.bib135.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2301.04589</span>, 2023.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[136]</span>
<span class="ltx_bibblock">
Melanie Sclar, Sachin Kumar, Peter West, Alane Suhr, Yejin Choi, and Yulia
Tsvetkov.

</span>
<span class="ltx_bibblock">Minding language models’(lack of) theory of mind: A plug-and-play
multi-character belief tracker.

</span>
<span class="ltx_bibblock"><span id="bib.bib136.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.00924</span>, 2023.

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[137]</span>
<span class="ltx_bibblock">
Bilgehan Sel, Ahmad Al-Tawaha, Vanshaj Khattar, Lu&nbsp;Wang, Ruoxi Jia, and Ming
Jin.

</span>
<span class="ltx_bibblock">Algorithm of thoughts: Enhancing exploration of ideas in large
language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib137.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.10379</span>, 2023.

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[138]</span>
<span class="ltx_bibblock">
Yongliang Shen, Kaitao Song, Xu&nbsp;Tan, Dongsheng Li, Weiming Lu, and Yueting
Zhuang.

</span>
<span class="ltx_bibblock">HuggingGPT: Solving ai tasks with ChatGPT and its friends in
huggingface.

</span>
<span class="ltx_bibblock"><span id="bib.bib138.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.17580</span>, 2023.

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[139]</span>
<span class="ltx_bibblock">
Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan,
and Shunyu Yao.

</span>
<span class="ltx_bibblock">Reflexion: Language agents with verbal reinforcement learning.

</span>
<span class="ltx_bibblock"><span id="bib.bib139.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.11366</span>, 2023.

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[140]</span>
<span class="ltx_bibblock">
Yubo Shu, Hansu Gu, Peng Zhang, Haonan Zhang, Tun Lu, Dongsheng Li, and Ning
Gu.

</span>
<span class="ltx_bibblock">Rah! recsys-assistant-human: A human-central recommendation framework
with large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib140.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.09904</span>, 2023.

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[141]</span>
<span class="ltx_bibblock">
Chan&nbsp;Hee Song, Jiaman Wu, Clayton Washington, Brian&nbsp;M Sadler, Wei-Lun Chao, and
Yu&nbsp;Su.

</span>
<span class="ltx_bibblock">LLM-Planner: Few-shot grounded planning for embodied agents with
large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib141.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2212.04088</span>, 2022.

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[142]</span>
<span class="ltx_bibblock">
Yifan Song, Weimin Xiong, Dawei Zhu, Wenhao Wu, Han Qian, Mingbo Song, Hailiang
Huang, Cheng Li, Ke&nbsp;Wang, Rong Yao, Ye&nbsp;Tian, and Sujian Li.

</span>
<span class="ltx_bibblock">Restgpt: Connecting large language models with real-world restful
apis, 2023.

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[143]</span>
<span class="ltx_bibblock">
Ruoxi Sun, Sercan&nbsp;O Arik, Hootan Nakhost, Hanjun Dai, Rajarishi Sinha,
Pengcheng Yin, and Tomas Pfister.

</span>
<span class="ltx_bibblock">Sql-palm: Improved large language modeladaptation for text-to-sql.

</span>
<span class="ltx_bibblock"><span id="bib.bib143.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.00739</span>, 2023.

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[144]</span>
<span class="ltx_bibblock">
Dídac Surís, Sachit Menon, and Carl Vondrick.

</span>
<span class="ltx_bibblock">ViperGPT: Visual inference via python execution for reasoning.

</span>
<span class="ltx_bibblock"><span id="bib.bib144.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.08128</span>, 2023.

</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[145]</span>
<span class="ltx_bibblock">
Melanie Swan, Takashi Kido, Eric Roland, and Renato P&nbsp;dos Santos.

</span>
<span class="ltx_bibblock">Math agents: Computational infrastructure, mathematical embedding,
and genomics.

</span>
<span class="ltx_bibblock"><span id="bib.bib145.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.02502</span>, 2023.

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[146]</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne
Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric
Hambro, Faisal Azhar, et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib146.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.13971</span>, 2023.

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[147]</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine
Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale,
et&nbsp;al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><span id="bib.bib147.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.09288</span>, 2023.

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[148]</span>
<span class="ltx_bibblock">
Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu,
Linxi Fan, and Anima Anandkumar.

</span>
<span class="ltx_bibblock">Voyager: An open-ended embodied agent with large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib148.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.16291</span>, 2023.

</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[149]</span>
<span class="ltx_bibblock">
Lei Wang.

</span>
<span class="ltx_bibblock">Recagent.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/RUC-GSAI/YuLan-Rec" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/RUC-GSAI/YuLan-Rec</a>, 2023.

</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[150]</span>
<span class="ltx_bibblock">
Lei Wang, Jingsen Zhang, Xu&nbsp;Chen, Yankai Lin, Ruihua Song, Wayne&nbsp;Xin Zhao, and
Ji-Rong Wen.

</span>
<span class="ltx_bibblock">Recagent: A novel simulation paradigm for recommender systems.

</span>
<span class="ltx_bibblock"><span id="bib.bib150.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.02552</span>, 2023.

</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[151]</span>
<span class="ltx_bibblock">
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed&nbsp;Chi, Sharan Narang,
Aakanksha Chowdhery, and Denny Zhou.

</span>
<span class="ltx_bibblock">Self-consistency improves chain of thought reasoning in language
models.

</span>
<span class="ltx_bibblock"><span id="bib.bib151.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2203.11171</span>, 2022.

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[152]</span>
<span class="ltx_bibblock">
Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing
Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang.

</span>
<span class="ltx_bibblock">Recmind: Large language model powered agent for recommendation.

</span>
<span class="ltx_bibblock"><span id="bib.bib152.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.14296</span>, 2023.

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[153]</span>
<span class="ltx_bibblock">
Yufei Wang, Wanjun Zhong, Liangyou Li, Fei Mi, Xingshan Zeng, Wenyong Huang,
Lifeng Shang, Xin Jiang, and Qun Liu.

</span>
<span class="ltx_bibblock">Aligning large language models with human: A survey.

</span>
<span class="ltx_bibblock"><span id="bib.bib153.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.12966</span>, 2023.

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[154]</span>
<span class="ltx_bibblock">
Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao Liang.

</span>
<span class="ltx_bibblock">Describe, explain, plan and select: Interactive planning with large
language models enables open-world multi-task agents.

</span>
<span class="ltx_bibblock"><span id="bib.bib154.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2302.01560</span>, 2023.

</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[155]</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed&nbsp;Chi, Quoc&nbsp;V
Le, Denny Zhou, et&nbsp;al.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language
models.

</span>
<span class="ltx_bibblock"><span id="bib.bib155.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>,
35:24824–24837, 2022.

</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[156]</span>
<span class="ltx_bibblock">
Ross Williams, Niyousha Hosseinichimeh, Aritra Majumdar, and Navid
Ghaffarzadegan.

</span>
<span class="ltx_bibblock">Epidemic modeling with generative agents.

</span>
<span class="ltx_bibblock"><span id="bib.bib156.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.04986</span>, 2023.

</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[157]</span>
<span class="ltx_bibblock">
Jimmy Wu, Rika Antonova, Adam Kan, Marion Lepert, Andy Zeng, Shuran Song,
Jeannette Bohg, Szymon Rusinkiewicz, and Thomas Funkhouser.

</span>
<span class="ltx_bibblock">Tidybot: Personalized robot assistance with large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib157.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.05658</span>, 2023.

</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[158]</span>
<span class="ltx_bibblock">
Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu,
Beibin Li, Li&nbsp;Jiang, Xiaoyun Zhang, and Chi Wang.

</span>
<span class="ltx_bibblock">AutoGen: Enabling next-gen LLM applications via multi-agent
conversation framework.

</span>
<span class="ltx_bibblock"><span id="bib.bib158.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.08155</span>, 2023.

</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[159]</span>
<span class="ltx_bibblock">
Yue Wu, So&nbsp;Yeon Min, Yonatan Bisk, Ruslan Salakhutdinov, Amos Azaria, Yuanzhi
Li, Tom Mitchell, and Shrimai Prabhumoye.

</span>
<span class="ltx_bibblock">Plan, eliminate, and track–language models are good teachers for
embodied agents.

</span>
<span class="ltx_bibblock"><span id="bib.bib159.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.02412</span>, 2023.

</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[160]</span>
<span class="ltx_bibblock">
Zhenyu Wu, Ziwei Wang, Xiuwei Xu, Jiwen Lu, and Haibin Yan.

</span>
<span class="ltx_bibblock">Embodied task planning with large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib160.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.01848</span>, 2023.

</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[161]</span>
<span class="ltx_bibblock">
Yuchen Xia, Manthan Shenoy, Nasser Jazdi, and Michael Weyrich.

</span>
<span class="ltx_bibblock">Towards autonomous system: flexible modular production system
enhanced with large language model agents.

</span>
<span class="ltx_bibblock"><span id="bib.bib161.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.14721</span>, 2023.

</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[162]</span>
<span class="ltx_bibblock">
Jiannan Xiang, Tianhua Tao, Yi&nbsp;Gu, Tianmin Shu, Zirui Wang, Zichao Yang, and
Zhiting Hu.

</span>
<span class="ltx_bibblock">Language models meet world models: Embodied experiences enhance
language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib162.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.10626</span>, 2023.

</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[163]</span>
<span class="ltx_bibblock">
Binfeng Xu, Xukun Liu, Hua Shen, Zeyu Han, Yuhan Li, Murong Yue, Zhiyuan Peng,
Yuchen Liu, Ziyu Yao, and Dongkuan Xu.

</span>
<span class="ltx_bibblock">Gentopia: A collaborative platform for tool-augmented LLMs.

</span>
<span class="ltx_bibblock"><span id="bib.bib163.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.04030</span>, 2023.

</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[164]</span>
<span class="ltx_bibblock">
Binfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, and
Dongkuan Xu.

</span>
<span class="ltx_bibblock">Rewoo: Decoupling reasoning from observations for efficient augmented
language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib164.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.18323</span>, 2023.

</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[165]</span>
<span class="ltx_bibblock">
Yuxuan Lei Jing Yao Defu Lian Xing&nbsp;Xie Xu&nbsp;Huang, Jianxun&nbsp;Lian.

</span>
<span class="ltx_bibblock">Recommender ai agent: Integrating large language models for
interactive recommendations.

</span>
<span class="ltx_bibblock"><span id="bib.bib165.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.16505</span>, 2023.

</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[166]</span>
<span class="ltx_bibblock">
Jingfeng Yang, Hongye Jin, Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming
Jiang, Bing Yin, and Xia Hu.

</span>
<span class="ltx_bibblock">Harnessing the power of LLMs in practice: A survey on ChatGPT and
beyond.

</span>
<span class="ltx_bibblock"><span id="bib.bib166.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2304.13712</span>, 2023.

</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[167]</span>
<span class="ltx_bibblock">
Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Ehsan Azarnasab, Faisal
Ahmed, Zicheng Liu, Ce&nbsp;Liu, Michael Zeng, and Lijuan Wang.

</span>
<span class="ltx_bibblock">Mm-react: Prompting chatgpt for multimodal reasoning and action.

</span>
<span class="ltx_bibblock"><span id="bib.bib167.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.11381</span>, 2023.

</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[168]</span>
<span class="ltx_bibblock">
Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan.

</span>
<span class="ltx_bibblock">Webshop: Towards scalable real-world web interaction with grounded
language agents.

</span>
<span class="ltx_bibblock"><span id="bib.bib168.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>,
35:20744–20757, 2022.

</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[169]</span>
<span class="ltx_bibblock">
Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas&nbsp;L Griffiths, Yuan Cao,
and Karthik Narasimhan.

</span>
<span class="ltx_bibblock">Tree of thoughts: Deliberate problem solving with large language
models.

</span>
<span class="ltx_bibblock"><span id="bib.bib169.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.10601</span>, 2023.

</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[170]</span>
<span class="ltx_bibblock">
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan,
and Yuan Cao.

</span>
<span class="ltx_bibblock">React: Synergizing reasoning and acting in language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib170.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2210.03629</span>, 2022.

</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[171]</span>
<span class="ltx_bibblock">
Weiran Yao, Shelby Heinecke, Juan&nbsp;Carlos Niebles, Zhiwei Liu, Yihao Feng,
Le&nbsp;Xue, Rithesh Murthy, Zeyuan Chen, Jianguo Zhang, Devansh Arpit, et&nbsp;al.

</span>
<span class="ltx_bibblock">Retroformer: Retrospective large language agents with policy gradient
optimization.

</span>
<span class="ltx_bibblock"><span id="bib.bib171.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.02151</span>, 2023.

</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[172]</span>
<span class="ltx_bibblock">
Ceyao Zhang, Kaijie Yang, Siyi Hu, Zihao Wang, Guanghe Li, Yihang Sun, Cheng
Zhang, Zhaowei Zhang, Anji Liu, Song-Chun Zhu, Xiaojun Chang, Junge Zhang,
Feng Yin, Yitao Liang, and Yaodong Yang.

</span>
<span class="ltx_bibblock">Proagent: Building proactive cooperative ai with large language
models, 2023.

</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[173]</span>
<span class="ltx_bibblock">
Chenrui Zhang, Lin Liu, Jinpeng Wang, Chuyuan Wang, Xiao Sun, Hongyu Wang, and
Mingchen Cai.

</span>
<span class="ltx_bibblock">Prefer: Prompt ensemble learning via feedback-reflect-refine.

</span>
<span class="ltx_bibblock"><span id="bib.bib173.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.12033</span>, 2023.

</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[174]</span>
<span class="ltx_bibblock">
Danyang Zhang, Lu&nbsp;Chen, Situo Zhang, Hongshen Xu, Zihan Zhao, and Kai Yu.

</span>
<span class="ltx_bibblock">Large language model is semi-parametric reinforcement learning agent.

</span>
<span class="ltx_bibblock"><span id="bib.bib174.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2306.07929</span>, 2023.

</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[175]</span>
<span class="ltx_bibblock">
Danyang Zhang, Lu&nbsp;Chen, Zihan Zhao, Ruisheng Cao, and Kai Yu.

</span>
<span class="ltx_bibblock">Mobile-Env: An evaluation platform and benchmark for interactive
agents in LLM era.

</span>
<span class="ltx_bibblock"><span id="bib.bib175.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.08144</span>, 2023.

</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[176]</span>
<span class="ltx_bibblock">
Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua&nbsp;B
Tenenbaum, Tianmin Shu, and Chuang Gan.

</span>
<span class="ltx_bibblock">Building cooperative embodied agents modularly with large language
models.

</span>
<span class="ltx_bibblock"><span id="bib.bib176.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.02485</span>, 2023.

</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[177]</span>
<span class="ltx_bibblock">
Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, and Gao
Huang.

</span>
<span class="ltx_bibblock">Expel: Llm agents are experiential learners, 2023.

</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[178]</span>
<span class="ltx_bibblock">
Wayne&nbsp;Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou,
Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et&nbsp;al.

</span>
<span class="ltx_bibblock">A survey of large language models.

</span>
<span class="ltx_bibblock"><span id="bib.bib178.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2303.18223</span>, 2023.

</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[179]</span>
<span class="ltx_bibblock">
Wanjun Zhong, Lianghong Guo, Qiqi Gao, and Yanlin Wang.

</span>
<span class="ltx_bibblock">Memorybank: Enhancing large language models with long-term memory.

</span>
<span class="ltx_bibblock"><span id="bib.bib179.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.10250</span>, 2023.

</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[180]</span>
<span class="ltx_bibblock">
Shuyan Zhou, Frank&nbsp;F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar,
Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, et&nbsp;al.

</span>
<span class="ltx_bibblock">Webarena: A realistic web environment for building autonomous agents.

</span>
<span class="ltx_bibblock"><span id="bib.bib180.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.13854</span>, 2023.

</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[181]</span>
<span class="ltx_bibblock">
Wei Zhou, Xiangyu Peng, and Mark Riedl.

</span>
<span class="ltx_bibblock">Dialogue shaping: Empowering agents through npc interaction.

</span>
<span class="ltx_bibblock"><span id="bib.bib181.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2307.15833</span>, 2023.

</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[182]</span>
<span class="ltx_bibblock">
Xuanhe Zhou, Guoliang Li, and Zhiyuan Liu.

</span>
<span class="ltx_bibblock">Llm as dba.

</span>
<span class="ltx_bibblock"><span id="bib.bib182.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.05481</span>, 2023.

</span>
</li>
<li id="bib.bib183" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[183]</span>
<span class="ltx_bibblock">
Andrew Zhu, Lara&nbsp;J Martin, Andrew Head, and Chris Callison-Burch.

</span>
<span class="ltx_bibblock">Calypso: Llms as dungeon masters’ assistants.

</span>
<span class="ltx_bibblock"><span id="bib.bib183.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2308.07540</span>, 2023.

</span>
</li>
<li id="bib.bib184" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[184]</span>
<span class="ltx_bibblock">
Xizhou Zhu, Yuntao Chen, Hao Tian, Chenxin Tao, Weijie Su, Chenyu Yang, Gao
Huang, Bin Li, Lewei Lu, Xiaogang Wang, et&nbsp;al.

</span>
<span class="ltx_bibblock">Ghost in the minecraft: Generally capable agents for open-world
enviroments via large language models with text-based knowledge and memory.

</span>
<span class="ltx_bibblock"><span id="bib.bib184.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.17144</span>, 2023.

</span>
</li>
<li id="bib.bib185" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[185]</span>
<span class="ltx_bibblock">
Mingchen Zhuge, Haozhe Liu, Francesco Faccio, Dylan&nbsp;R Ashley, Róbert
Csordás, Anand Gopalakrishnan, Abdullah Hamdi, Hasan Abed Al&nbsp;Kader
Hammoud, Vincent Herrmann, Kazuki Irie, et&nbsp;al.

</span>
<span class="ltx_bibblock">Mindstorms in natural language-based societies of mind.

</span>
<span class="ltx_bibblock"><span id="bib.bib185.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.17066</span>, 2023.

</span>
</li>
<li id="bib.bib186" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[186]</span>
<span class="ltx_bibblock">
Terry&nbsp;Yue Zhuo, Zhuang Li, Yujin Huang, Yuan-Fang Li, Weiqing Wang, Gholamreza
Haffari, and Fatemeh Shiri.

</span>
<span class="ltx_bibblock">On robustness of prompt-based semantic parsing with large pre-trained
language model: An empirical study on codex.

</span>
<span class="ltx_bibblock"><span id="bib.bib186.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2301.12868</span>, 2023.

</span>
</li>
<li id="bib.bib187" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[187]</span>
<span class="ltx_bibblock">
Caleb Ziems, William Held, Omar Shaikh, Jiaao Chen, Zhehao Zhang, and Diyi
Yang.

</span>
<span class="ltx_bibblock">Can large language models transform computational social science?

</span>
<span class="ltx_bibblock"><span id="bib.bib187.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2305.03514</span>, 2023.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2308.11431" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2308.11432" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2308.11432">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2308.11432" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2308.11433" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 11:38:13 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>