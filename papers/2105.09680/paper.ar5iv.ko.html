<html lang="en" data-theme="light"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2105.09680] KLUE: Korean Language Understanding Evaluation</title><meta property="og:description" content="We introduce Korean Language Understanding Evaluation (KLUE) benchmark. KLUE is a collection of 8 Korean natural language understanding (NLU) tasks, including Topic Classification, Semantic Textual Similarity, Natural …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="KLUE: Korean Language Understanding Evaluation">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="KLUE: Korean Language Understanding Evaluation">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2105.09680">

<!--Generated on Fri Mar  8 00:24:06 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="ACROFAN (Acrofan News), AIRBNB (Airbnb Reviews), CC-100-Kor, DP (Dependency Parsing), DST (Dialogue State Tracking), KLUE , KLUE-BERT, KLUE-DP, KLUE-MRC, KLUE-NER, KLUE-NLI, KLUE-RE, KLUE-RoBERTa, KLUE-STS, MODU (Modu Corpus), MRC (Machine Reading Comprehension), NAMUWIKI, NER (Named Entity Recognition), NEWSCRAWL, NLI (Natural Language Inference), NSMC (NAVER Sentiment Movie Corpus), PARAKQC, PETITION, POLICY (Policy News), RE (Relation Extraction), STS (Semantic Textual Similarity), TC (Topic Classification), The Korea Economy Daily, WIKINEWS, WIKIPEDIA, WIKITREE, WoS (Wizard of Seoul, KLUE-DST), YNA (Yonhap News Agency), YNAT (YNA Topic Classification, KLUE-TC)">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-fonts.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv.0.7.9.min.css"><link media="all" rel="stylesheet" href="https://ar5iv.labs.arxiv.org/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<p class="ltx_p" id="p1.1">[columns=2, intoc]</p>
</div>
<h1 class="ltx_title ltx_title_document">KLUE: Korean Language Understanding Evaluation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Sungjoon Park<sup id="id5.4.id1" class="ltx_sup">*</sup>
<br class="ltx_break"><span id="id3.3.3" class="ltx_text" style="font-size:90%;">Upstage, KAIST
<br class="ltx_break"><span id="id3.3.3.4" class="ltx_text ltx_font_typewriter" style="font-size:78%;">sungjoon.park@kaist.ac.kr<span id="id3.3.3.4.1" class="ltx_text ltx_font_serif">&amp;Jihyung Moon<sup id="id3.3.3.4.1.1" class="ltx_sup">*</sup>
<br class="ltx_break"></span></span>Upstage
<br class="ltx_break"><span id="id3.3.3.5" class="ltx_text ltx_font_typewriter" style="font-size:78%;">jihyung.moon@upstage.ai<span id="id3.3.3.5.1" class="ltx_text ltx_font_serif">&amp;Sungdong Kim<sup id="id3.3.3.5.1.1" class="ltx_sup">*</sup>
<br class="ltx_break"></span></span>NAVER AI Lab
<br class="ltx_break"><span id="id1.1.1.1" class="ltx_text ltx_font_typewriter" style="font-size:78%;">sungdong.kim@navercorp.com<span id="id1.1.1.1.2" class="ltx_text ltx_font_serif"> &amp;Won Ik Cho<sup id="id1.1.1.1.2.1" class="ltx_sup">*</sup>
<br class="ltx_break"><span id="id1.1.1.1.2.2" class="ltx_text" style="font-size:114%;">Seoul National University
<br class="ltx_break"></span></span>tsatsuki@snu.ac.kr<span id="id1.1.1.1.1" class="ltx_text ltx_font_serif"> &amp;Jiyoon Han<sup id="id1.1.1.1.1.1" class="ltx_sup"><math id="id1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="id1.1.1.1.1.1.m1.1a"><mo id="id1.1.1.1.1.1.m1.1.1" xref="id1.1.1.1.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="id1.1.1.1.1.1.m1.1b"><ci id="id1.1.1.1.1.1.m1.1.1.cmml" xref="id1.1.1.1.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="id1.1.1.1.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
<br class="ltx_break"></span></span>Yonsei University
<br class="ltx_break"><span id="id3.3.3.6" class="ltx_text ltx_font_typewriter" style="font-size:78%;">clinamen35@yonsei.ac.kr<span id="id3.3.3.6.1" class="ltx_text ltx_font_serif"> &amp;Jangwon Park
<br class="ltx_break"></span>jangwon.pk@gmail.com<span id="id3.3.3.6.2" class="ltx_text ltx_font_serif"> &amp;Chisung Song
<br class="ltx_break"></span>daydrilling@gmail.com<span id="id3.3.3.6.3" class="ltx_text ltx_font_serif"> &amp;Junseong Kim
<br class="ltx_break"></span></span>Scatter Lab
<br class="ltx_break"><span id="id3.3.3.7" class="ltx_text ltx_font_typewriter" style="font-size:56%;">junseong.kim@scatterlab.co.kr<span id="id3.3.3.7.1" class="ltx_text ltx_font_serif"> &amp;Youngsook Song
<br class="ltx_break"></span></span>KyungHee University 
<br class="ltx_break"><span id="id2.2.2.2" class="ltx_text ltx_font_typewriter" style="font-size:78%;">youngsoksong@khu.ac.kr<span id="id2.2.2.2.1" class="ltx_text ltx_font_serif"> &amp;Taehwan Oh<sup id="id2.2.2.2.1.1" class="ltx_sup"><math id="id2.2.2.2.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="id2.2.2.2.1.1.m1.1a"><mo id="id2.2.2.2.1.1.m1.1.1" xref="id2.2.2.2.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="id2.2.2.2.1.1.m1.1b"><ci id="id2.2.2.2.1.1.m1.1.1.cmml" xref="id2.2.2.2.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="id2.2.2.2.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
<br class="ltx_break"></span></span>Yonsei University 
<br class="ltx_break"><span id="id3.3.3.8" class="ltx_text ltx_font_typewriter" style="font-size:78%;">ghksl0604@yonsei.ac.kr<span id="id3.3.3.8.1" class="ltx_text ltx_font_serif"> &amp;Joohong Lee
<br class="ltx_break"></span></span>Scatter Lab
<br class="ltx_break"><span id="id3.3.3.3" class="ltx_text ltx_font_typewriter" style="font-size:78%;">joohong@scatterlab.co.kr<span id="id3.3.3.3.1" class="ltx_text ltx_font_serif"> &amp;Juhyun Oh<sup id="id3.3.3.3.1.1" class="ltx_sup"><math id="id3.3.3.3.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="id3.3.3.3.1.1.m1.1a"><mo id="id3.3.3.3.1.1.m1.1.1" xref="id3.3.3.3.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="id3.3.3.3.1.1.m1.1b"><ci id="id3.3.3.3.1.1.m1.1.1.cmml" xref="id3.3.3.3.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="id3.3.3.3.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
<br class="ltx_break"><span id="id3.3.3.3.1.2" class="ltx_text" style="font-size:114%;">Seoul National University 
<br class="ltx_break"></span></span>411juhyun@snu.ac.kr<span id="id3.3.3.3.2" class="ltx_text ltx_font_serif"> &amp;Sungwon Lyu
<br class="ltx_break"></span></span>Kakao Enterprise 
<br class="ltx_break"><span id="id3.3.3.9" class="ltx_text ltx_font_typewriter" style="font-size:56%;">james.ryu@kakaoenterprise.com<span id="id3.3.3.9.1" class="ltx_text ltx_font_serif"> &amp;Younghoon Jeong
<br class="ltx_break"></span></span>Sogang University 
<br class="ltx_break"><span id="id3.3.3.10" class="ltx_text ltx_font_typewriter" style="font-size:78%;">boychaboy@sogang.ac.kr<span id="id3.3.3.10.1" class="ltx_text ltx_font_serif"> &amp;Inkwon Lee
<br class="ltx_break"></span></span>Sogang University 
<br class="ltx_break"><span id="id3.3.3.11" class="ltx_text ltx_font_typewriter" style="font-size:78%;">md98765@naver.com<span id="id3.3.3.11.1" class="ltx_text ltx_font_serif"> &amp;Sangwoo Seo
<br class="ltx_break"></span></span>Scatter Lab 
<br class="ltx_break"><span id="id3.3.3.12" class="ltx_text ltx_font_typewriter" style="font-size:56%;">sangwoo@scatterlab.co.kr<span id="id3.3.3.12.1" class="ltx_text ltx_font_serif"> &amp;Dongjun Lee
<br class="ltx_break"></span>humanbrain.djlee@gmail.com<span id="id3.3.3.12.2" class="ltx_text ltx_font_serif"> &amp;Hyunwoo Kim
<br class="ltx_break"><span id="id3.3.3.12.2.1" class="ltx_text" style="font-size:160%;">Seoul National University 
<br class="ltx_break"></span></span><span id="id3.3.3.12.3" class="ltx_text" style="font-size:140%;">hyunw.kim@vl.snu.ac.kr<span id="id3.3.3.12.3.1" class="ltx_text ltx_font_serif"> &amp;Myeonghwa Lee
<br class="ltx_break"></span></span></span>KAIST 
<br class="ltx_break"><span id="id3.3.3.13" class="ltx_text ltx_font_typewriter" style="font-size:78%;">myeon9h@kaist.ac.kr<span id="id3.3.3.13.1" class="ltx_text ltx_font_serif"> &amp;Seongbo Jang
<br class="ltx_break"></span></span>Scatter Lab 
<br class="ltx_break"><span id="id3.3.3.14" class="ltx_text ltx_font_typewriter" style="font-size:56%;">seongbo@scatterlab.co.kr<span id="id3.3.3.14.1" class="ltx_text ltx_font_serif"> &amp;Seungwon Do
<br class="ltx_break"></span><span id="id3.3.3.14.2" class="ltx_text" style="font-size:140%;">seungwon.do1@gmail.com<span id="id3.3.3.14.2.1" class="ltx_text ltx_font_serif"> &amp;Sunkyoung Kim
<br class="ltx_break">KAIST 
<br class="ltx_break"></span>sunkyoung@kaist.ac.kr<span id="id3.3.3.14.2.2" class="ltx_text ltx_font_serif"> &amp;Kyungtae Lim
<br class="ltx_break"><span id="id3.3.3.14.2.2.1" class="ltx_text" style="font-size:114%;">Hanbat National University 
<br class="ltx_break"></span></span>ktlim@hanbat.ac.kr<span id="id3.3.3.14.2.3" class="ltx_text ltx_font_serif"> &amp;Jongwon Lee
<br class="ltx_break"></span>mybizzer@gmail.com<span id="id3.3.3.14.2.4" class="ltx_text ltx_font_serif"> &amp;Kyumin Park
<br class="ltx_break"></span></span></span>KAIST 
<br class="ltx_break"><span id="id3.3.3.15" class="ltx_text ltx_font_typewriter" style="font-size:78%;">pkm9403@kaist.ac.kr<span id="id3.3.3.15.1" class="ltx_text ltx_font_serif"> &amp;Jamin Shin
<br class="ltx_break"></span></span>Riiid AI Research 
<br class="ltx_break"><span id="id3.3.3.16" class="ltx_text ltx_font_typewriter" style="font-size:78%;">jshin49@gmail.com<span id="id3.3.3.16.1" class="ltx_text ltx_font_serif"> &amp;Seonghyun Kim 
<br class="ltx_break"></span>bananaband657@gmail.com<span id="id3.3.3.16.2" class="ltx_text ltx_font_serif"> &amp;Lucy Park
<br class="ltx_break"></span></span>Upstage 
<br class="ltx_break"><span id="id3.3.3.17" class="ltx_text ltx_font_typewriter" style="font-size:78%;">lucy@upstage.ai<span id="id3.3.3.17.1" class="ltx_text ltx_font_serif"> &amp;Alice Oh<sup id="id3.3.3.17.1.1" class="ltx_sup">**</sup>
<br class="ltx_break"></span></span>KAIST 
<br class="ltx_break"><span id="id3.3.3.18" class="ltx_text ltx_font_typewriter" style="font-size:78%;">alice.oh@kaist.edu<span id="id3.3.3.18.1" class="ltx_text ltx_font_serif"> &amp;Jung-Woo Ha<sup id="id3.3.3.18.1.1" class="ltx_sup">**</sup>
<br class="ltx_break"></span></span>NAVER AI Lab 
<br class="ltx_break"><span id="id3.3.3.19" class="ltx_text ltx_font_typewriter" style="font-size:78%;">jungwoo.ha@navercorp.com<span id="id3.3.3.19.1" class="ltx_text ltx_font_serif"> &amp;Kyunghyun Cho<sup id="id3.3.3.19.1.1" class="ltx_sup">**</sup>
<br class="ltx_break"></span></span>New York University 
<br class="ltx_break"><span id="id3.3.3.20" class="ltx_text ltx_font_typewriter" style="font-size:78%;">kyunghyun.cho@nyu.edu<span id="id3.3.3.20.1" class="ltx_text ltx_font_serif">
</span></span></span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id4.1">한국어 이해 평가(KLUE) 벤치마크를 소개합니다. KLUE는 Topic Classification, Semantic Textual Similarity, Natural Language Inference, Named Entity Recognition, Relation Extraction, Dependency Parsing, Machine Reading Comprehension, Dialogue State Tracking 등 8개의 한국어 자연어 이해(NLU) 작업 모음이다. 저작권을 존중하면서 다양한 소스 코퍼라에서 모든 작업을 처음부터 구축하여 제한 없이 누구나 접근할 수 있도록 합니다. 윤리적 고려 사항을 고려하여 주석 프로토콜을 신중하게 설계합니다. 벤치마크 작업 및 데이터와 함께 각 작업에 대해 사전 훈련된 언어 모델에 적합한 평가 메트릭 및 미세 조정 레시피를 제공합니다. 또한 사전 학습된 언어 모델인 KLUE-BERT와 KLUE-RoBERTa를 발표하여 KLUE에서 기본 모델을 재현하여 향후 연구를 용이하게 한다. 우리는 제안된 KLUE 벤치마크 제품군을 사용하여 예비 실험에서 몇 가지 흥미로운 관찰을 수행하여 이 새로운 벤치마크 제품군의 유용성을 이미 입증했다. 먼저 <math alttext="\text{KLUE-RoBERTa}_{\text{LARGE}}" class="ltx_Math" display="inline" id="id4.1.m1.1"><semantics id="id4.1.m1.1a"><msub id="id4.1.m1.1.1" xref="id4.1.m1.1.1.cmml"><mtext id="id4.1.m1.1.1.2" xref="id4.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext id="id4.1.m1.1.1.3" xref="id4.1.m1.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="id4.1.m1.1b"><apply id="id4.1.m1.1.1.cmml" xref="id4.1.m1.1.1"><csymbol cd="ambiguous" id="id4.1.m1.1.1.1.cmml" xref="id4.1.m1.1.1">subscript</csymbol><ci id="id4.1.m1.1.1.2a.cmml" xref="id4.1.m1.1.1.2"><mtext id="id4.1.m1.1.1.2.cmml" xref="id4.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="id4.1.m1.1.1.3a.cmml" xref="id4.1.m1.1.1.3"><mtext id="id4.1.m1.1.1.3.cmml" mathsize="70%" xref="id4.1.m1.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="id4.1.m1.1c">\text{KLUE-RoBERTa}_{\text{LARGE}}</annotation></semantics></math>가 다국어 PLM과 기존 오픈소스 한국어 PLM을 포함한 다른 기준선보다 우수하다는 것을 알아본다. 둘째, 사전 학습 코퍼스에서 개인 식별 정보를 대체하더라도 성능 저하가 최소화되어 개인 정보 보호와 NLU 기능이 서로 상충되지 않음을 시사한다. 마지막으로, BPE 토큰화를 형태소 수준 사전 토큰화와 결합하여 사용하는 것이 형태소 수준 태깅, 탐지 및 생성과 관련된 작업에서 효과적임을 알 수 있었다. 한국어 NLP 연구를 가속화하는 것 외에도 KLUE 생성에 대한 포괄적인 문서는 향후 다른 언어에 대한 유사한 리소스를 만드는 데 도움이 될 것이다. KLUE는 <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://klue-benchmark.com/" target="_blank" title="">https://klue-benchmark.com/</a>에서 이용 가능하다.</p>
</div>
<span id="footnotex1" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotetext: </span>Equal Contribution. A description of each author’s contribution is available at the end of paper.</span></span></span><span id="footnotex2" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotetext: </span>Corresponding Authors.</span></span></span><span id="footnotex3" class="ltx_note ltx_role_footnotetext"><sup class="ltx_note_mark">0</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">0</sup><span class="ltx_note_type">footnotetext: </span>Work done at Upstage.</span></span></span>
<div class="ltx_pagination ltx_role_newpage"></div>
<nav class="ltx_TOC ltx_list_toc ltx_toc_toc"><h6 class="ltx_title ltx_title_contents">Contents</h6>
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S1" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S1.SS1" title="In 1 Introduction ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Summary</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S2" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Source Corpora</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S2.SS1" title="In 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Corpora Selection Criteria</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S2.SS2" title="In 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Selected Corpora</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S2.SS2.SSS1" title="In 2.2 Selected Corpora ‣ 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2.1 </span>Potential Concerns</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S2.SS3" title="In 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Preprocessing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S2.SS4" title="In 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Task Assignment</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S3" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>KLUE Benchmark</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS1" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Topic Classification (TC)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS1.SSS1" title="In 3.1 Topic Classification (TC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS1.SSS2" title="In 3.1 Topic Classification (TC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Evaluation Metric</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS1.SSS3" title="In 3.1 Topic Classification (TC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS1.SSS4" title="In 3.1 Topic Classification (TC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.4 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS2" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Semantic Textual Similarity (STS)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS2.SSS1" title="In 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS2.SSS2" title="In 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS2.SSS3" title="In 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS2.SSS4" title="In 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.4 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS3" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Natural Language Inference (NLI)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS3.SSS1" title="In 3.3 Natural Language Inference (NLI) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS3.SSS2" title="In 3.3 Natural Language Inference (NLI) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.2 </span>Evaluation Metric</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS3.SSS3" title="In 3.3 Natural Language Inference (NLI) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS3.SSS4" title="In 3.3 Natural Language Inference (NLI) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3.4 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS4" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Named Entity Recognition (NER)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS4.SSS1" title="In 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS4.SSS2" title="In 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS4.SSS3" title="In 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS4.SSS4" title="In 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4.4 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS5" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Relation Extraction (RE)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS5.SSS1" title="In 3.5 Relation Extraction (RE) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5.1 </span>Data Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS5.SSS2" title="In 3.5 Relation Extraction (RE) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS5.SSS3" title="In 3.5 Relation Extraction (RE) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5.3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS5.SSS4" title="In 3.5 Relation Extraction (RE) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5.4 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS6" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6 </span>Dependency Parsing (DP)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS6.SSS1" title="In 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS6.SSS2" title="In 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS6.SSS3" title="In 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6.3 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS6.SSS4" title="In 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.6.4 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS7" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.7 </span>Machine Reading Comprehension (MRC)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS7.SSS1" title="In 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.7.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS7.SSS2" title="In 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.7.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS7.SSS3" title="In 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.7.3 </span>Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS7.SSS4" title="In 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.7.4 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS7.SSS5" title="In 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.7.5 </span>Conclusion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S3.SS8" title="In 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.8 </span>Dialogue State Tracking (DST)</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS8.SSS1" title="In 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.8.1 </span>Dataset Construction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS8.SSS2" title="In 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.8.2 </span>Evaluation Metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS8.SSS3" title="In 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.8.3 </span>Analysis</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS8.SSS4" title="In 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.8.4 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S3.SS8.SSS5" title="In 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.8.5 </span>Conclusion</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S4" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Pretrained Language Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S4.SS1" title="In 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Language Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S4.SS2" title="In 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Existing Language Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S5" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Fine-tuning Language Models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a href="#S5.SS1" title="In 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Task-Specific Architectures</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S5.SS1.SSS1" title="In 5.1 Task-Specific Architectures ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.1 </span>Single Sentence Classification</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S5.SS1.SSS2" title="In 5.1 Task-Specific Architectures ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.2 </span>Sentence Pair Classification / Regression</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S5.SS1.SSS3" title="In 5.1 Task-Specific Architectures ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.3 </span>Multiple-Sentence Slot-Value Prediction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a href="#S5.SS1.SSS4" title="In 5.1 Task-Specific Architectures ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.4 </span>Sequence Tagging</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S5.SS2" title="In 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Fine-Tuning Configurations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S5.SS3" title="In 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Evaluation Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S5.SS4" title="In 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Analysis of Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a href="#S6" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Ethical Considerations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S6.SS1" title="In 6 Ethical Considerations ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Copyright and Accessibility</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S6.SS2" title="In 6 Ethical Considerations ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Toxic Content</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a href="#S6.SS3" title="In 6 Ethical Considerations ‣ KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Personally Identifiable Information</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S7" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S8" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a href="#S9" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">9 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a href="#A1" title="In KLUE: Korean Language Understanding Evaluation" class="ltx_ref"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref"><span class="ltx_text" style="font-size:90%;">A</span> </span><span class="ltx_text" style="font-size:90%;">Dev Set Results</span></span></a></li>
</ol></nav>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p" id="S1.p1.1">BERT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite> 및 그 변형들<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>, <a class="ltx_ref" href="#bib.bib22" title="">22</a>, <a class="ltx_ref" href="#bib.bib49" title="">49</a>]</cite>뿐만 아니라 GPT-3<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib110" title="">110</a>]</cite> 및 그 변형들<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib111" title="">111</a>, <a class="ltx_ref" href="#bib.bib76" title="">76</a>, <a class="ltx_ref" href="#bib.bib9" title="">9</a>]</cite>와 같은 사전 훈련된 언어 모델의 최근 성공의 주요 요인은 자연어 이해(NLU)에서 그들의 효과를 평가하기 위한 잘 설계된 벤치마크 스위트의 가용성이다. GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>]</cite> 및 SuperGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib132" title="">132</a>]</cite>는 이러한 스위트의 대표적인 예이며 구문, 의미 및 화용론을 포함하여 NLU의 다양한 측면을 평가하기 위해 설계되었다. 연구 커뮤니티는 GLUE와 SuperGLUE를 수용했으며 NLU를 위한 학습 알고리즘뿐만 아니라 더 나은 모델 아키텍처를 개발하는 데 빠르게 발전했다.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p" id="S1.p2.1">GLUE와 SuperGLUE의 성공은 영어를 넘어서는 언어에서 NLU의 진행을 더 잘 측정하기 위해 다른 언어에 대한 표준화된 벤치마크 제품군을 구축하는 데 관심을 불러일으켰다. 이러한 노력은 두 가지 방향을 따라 추진되어 왔다. 먼저, 세계의 다양한 그룹들은 언어-특정 벤치마크 스위트들을 독립적으로 만들었다; 중국 버전의 GLUE(CLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite>), 프랑스 버전의 GLUE(FLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib72" title="">72</a>]</cite>), 인도네시아의 변종 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib137" title="">137</a>]</cite>, Indic 버전의 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite> 및 SuperGLUE의 러시아 변종 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib125" title="">125</a>]</cite>. 한편, 일부는 처음에 영어로 만들어진 벤치마크 스위트의 다국어 버전을 구축하기 위해 기존 벤치마크 스위트의 기계 및 인간 번역에 의존했다. 여기에는 예를 들어 XGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite> 및 XTREME <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib54" title="">54</a>]</cite>가 포함된다. 후자의 접근법은 전자보다 훨씬 더 나은 규모이지만 후자는 종종 NLU의 사회적 측면을 포착하지 못하고 번역에서 발생하는 다양한 아티팩트를 도입한다.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p" id="S1.p3.1">이를 위해 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib34" title="">34</a>]</cite>에 따라 전 세계에서 13번째로 많이 사용되는 한국어로 NLU를 평가할 수 있는 새로운 벤치마크 스위트를 구축하였으나, NLU에 대한 통일된 벤치마크 스위트가 부족하다. 기존의 벤치마크 작업이나 말뭉치에서 출발하는 대신, 기본 말뭉치를 결정하고 수집하고, 벤치마크 작업 세트를 식별하고, 적절한 주석 프로토콜을 설계하고, 최종적으로 수집된 주석의 유효성을 검증함으로써 이 벤치마크 제품군을 처음부터 구축한다. 이를 통해 저작권 침해, 주석 인공물, 사회적 편견 및 개인 정보 보호 침해와 같은 바람직하지 않은 결과를 초래할 수 있는 속성을 선제적으로 해결하고 피할 수 있다.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p" id="S1.p4.1">이 섹션의 나머지 부분에서는 KLUE를 만드는 데 뒤처진 일련의 결정과 원칙을 요약한다.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Summary</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S1.SS1.p1.1">한국어 이해 평가(Korean Language Understanding Evaluation, KLUE)를 설계함에 있어서, 우리는 KLUE를 만드는 것을 목표로 한다; 1) 다양한 작업과 말뭉치를 다루고, 2) 모든 사람이 제한 없이 접근할 수 있고, 3) 정확하고 명확한 주석을 포함하고, 4) AI 윤리 문제를 완화한다. KLUE는 잠재적인 <span class="ltx_text ltx_font_italic" id="S1.SS1.p1.1.1">ethical</span> 문제를 사전에 해결했기 때문에 시스템 구축 및 평가 모두에 사용하기에 안전합니다. 여기서는 이러한 원칙이 작업 선택, 말뭉치 선택, 주석 프로토콜, 평가 메트릭 결정에서 기본 구성까지 KLUE 생성을 어떻게 유도했는지 자세히 설명한다.</p>
</div>
<section id="S1.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Design Principles</h5>

<div id="S1.SS1.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S1.SS1.SSS0.Px1.p1.1">먼저, 각 설계 원리를 구체적으로 설명한다:</p>
</div>
<div id="S1.SS1.SSS0.Px1.p2" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I1.i1.p1.1.1">Covering various tasks and corpora</span>: 언어 이해의 다양한 측면을 다루기 위해, 우리는 뉴스, 백과사전, 사용자 리뷰, 스마트 홈 쿼리 및 태스크 지향 대화, 그리고 형식적이고 구어체적인 다양한 스타일을 포함하는 다양한 도메인을 포함하는 8개의 태스크를 선택한다.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I1.i2.p1.1.1">Accessible to everyone without any restriction</span>: It is critical for a benchmark suite to be accessible by everyone for it to serve as true guideline in evaluating and improving NLU systems. 따라서 우리는 NLU 시스템을 벤치마킹하기 위해 자유롭게 복사, 재분배, 재혼합 및 변환될 수 있는 코퍼스와 리소스만을 사용한다.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I1.i3.p1.1.1">Obtaining accurate and unambiguous annotations</span>: Ambiguity in benchmark tasks leads to ambiguity in evaluation, 이는 종종 benchmark에 의해 측정된 NLU system quality and its true quality 사이의 불일치로 이어진다. 이러한 불일치를 최소화하기 위해 정확한 주석을 피하기 위해 모든 작업의 주석 지침을 신중하게 설계하고 여러 반복에 걸쳐 개선한다.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="S1.I1.i4.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I1.i4.p1.1.1">Mitigating AI ethical issues</span>: Large-scale language models can and often do amplify social bias embedded in text used to train them <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib95" title="">95</a>]</cite>. 이러한 행동을 자극하지 않기 위해 사회적 편향을 반영하는 레이블이 지정되지 않은 말뭉치와 레이블이 지정되지 않은 말뭉치 모두에서 독성 콘텐츠를 포함하고 개인 식별 정보(PII)가 수동 및 자동으로 있는 예를 사전 예방적으로 제거한다. 사회적 편향은 사회적 속성(예를 들어, 성별, 민족성, 종교)에 기초하여 특정 개인 또는 집단에 대한 지나치게 일반화된 판단으로 정의된다. 독성 콘텐츠에는 모욕, 성희롱, 모욕적 표현이 포함된다.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S1.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Diverse Task Selection</h5>

<div id="S1.SS1.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S1.SS1.SSS0.Px2.p1.1">우리는 두 가지 목표를 가진 다음 8개의 NLU 과제를 신중하게 선택한다. 1) 한국어로 NLU의 다양한 측면을 포괄하는 것과 2) 과제 간의 중복을 최소화하는 것이다. 표 <a class="ltx_ref" href="#S1.T1" title="Table 1 ‣ Source Corpora Collection ‣ 1.1 Summary ‣ 1 Introduction ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">1</span></a> for their formats, evaluation granularity and other properties:</p>
</div>
<div id="S1.SS1.SSS0.Px2.p2" class="ltx_para">
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p class="ltx_p" id="S1.I2.i1.p1.1">토픽 분류(Topic Classification, TC): 단일 문장을 단일 클래스로 분류한다.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p class="ltx_p" id="S1.I2.i2.p1.1">시맨틱 텍스트 유사성(semantic Textual Similarity: STS): 두 문장 사이의 시맨틱 유사성을 판단한다.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p class="ltx_p" id="S1.I2.i3.p1.1">자연어 추론(Natural Language Inference, NLI): 첫 번째 문장이 두 번째 문장을 수반하는지 여부를 분류한다.</p>
</div>
</li>
<li id="S1.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i4.p1" class="ltx_para">
<p class="ltx_p" id="S1.I2.i4.p1.1">NER(Named Entity Recognition) : 문장에서 개체를 추출한다.</p>
</div>
</li>
<li id="S1.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i5.p1" class="ltx_para">
<p class="ltx_p" id="S1.I2.i5.p1.1">관계 추출(Relation Extraction, RE): 문장 내에서 두 개체 간의 관계를 예측한다.</p>
</div>
</li>
<li id="S1.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i6.p1" class="ltx_para">
<p class="ltx_p" id="S1.I2.i6.p1.1">Dependency Parsing (DP): 문장의 구문 구조를 예측한다.</p>
</div>
</li>
<li id="S1.I2.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i7.p1" class="ltx_para">
<p class="ltx_p" id="S1.I2.i7.p1.1">기계 읽기 이해(MRC): 질문이 주어진 단락 내에서 답변 범위를 식별합니다.</p>
</div>
</li>
<li id="S1.I2.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i8.p1" class="ltx_para">
<p class="ltx_p" id="S1.I2.i8.p1.1">DST(대화 상태 추적): 목표 지향 대화의 상태를 추적합니다.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S1.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora Collection</h5>

<div id="S1.SS1.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S1.SS1.SSS0.Px3.p1.1">우리는 접근 가능하고 다양한 영역과 주제를 포괄하며 현대 한국어로 쓰여진 코퍼스를 적극적으로 모색했습니다. 이 능동적 검색은 다음 10개의 소스 말뭉치로 마무리되었으며, 이로부터 작업별 말뭉치를 도출한다. 이 10개의 출처는 CC BY(-SA) 라이선스에 따라 공개되거나 저작물로 간주되지 않으며, 1) 파생 저작물, 2) 재분배 및 3) 상업적 사용을 허용한다.</p>
</div>
<div id="S1.SS1.SSS0.Px3.p2" class="ltx_para">
<ul id="S1.I3" class="ltx_itemize">
<li id="S1.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i1.p1" class="ltx_para">
<p class="ltx_p" id="S1.I3.i1.p1.1">연합뉴스의 뉴스 헤드라인</p>
</div>
</li>
<li id="S1.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i2.p1" class="ltx_para">
<p class="ltx_p" id="S1.I3.i2.p1.1">위키피디아</p>
</div>
</li>
<li id="S1.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i3.p1" class="ltx_para">
<p class="ltx_p" id="S1.I3.i3.p1.1">위키뉴</p>
</div>
</li>
<li id="S1.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i4.p1" class="ltx_para">
<p class="ltx_p" id="S1.I3.i4.p1.1">위키트리</p>
</div>
</li>
<li id="S1.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i5.p1" class="ltx_para">
<p class="ltx_p" id="S1.I3.i5.p1.1">정책뉴스</p>
</div>
</li>
<li id="S1.I3.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i6.p1" class="ltx_para">
<p class="ltx_p" id="S1.I3.i6.p1.1">파라KQC</p>
</div>
</li>
<li id="S1.I3.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i7.p1" class="ltx_para">
<p class="ltx_p" id="S1.I3.i7.p1.1">에어비앤비 리뷰</p>
</div>
</li>
<li id="S1.I3.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i8.p1" class="ltx_para">
<p class="ltx_p" id="S1.I3.i8.p1.1">네이버 감성 영화 말뭉치</p>
</div>
</li>
<li id="S1.I3.i9" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i9.p1" class="ltx_para">
<p class="ltx_p" id="S1.I3.i9.p1.1">한국경제신문</p>
</div>
</li>
<li id="S1.I3.i10" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I3.i10.p1" class="ltx_para">
<p class="ltx_p" id="S1.I3.i10.p1.1">아크로팬 뉴스</p>
</div>
</li>
</ul>
</div>
<div id="S1.SS1.SSS0.Px3.p3" class="ltx_para">
<p class="ltx_p" id="S1.SS1.SSS0.Px3.p3.1">주석을 위한 하위 집합을 보내기 전에 PII뿐만 아니라 노이즈, 독성 또는 사회적으로 편향된 콘텐츠를 제거하기 위해 필터링한다. 이는 미리 정의된 규칙 및 기계 학습 모델을 사용하여 자동으로 수행됩니다.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1:</span>Task Overview</figcaption>
<div id="S1.T1.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:638.9pt;height:535.6pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S1.T1.2.2" class="ltx_p"><span id="S1.T1.2.2.2" class="ltx_text"> <span id="S1.T1.2.2.2.2" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.3.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S1.T1.2.2.2.2.3.1.1" class="ltx_text ltx_font_bold">Name</span></span> <span id="S1.T1.2.2.2.2.3.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S1.T1.2.2.2.2.3.2.1" class="ltx_text ltx_font_bold">Type</span></span> <span id="S1.T1.2.2.2.2.3.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S1.T1.2.2.2.2.3.3.1" class="ltx_text ltx_font_bold">Format</span></span> <span id="S1.T1.2.2.2.2.3.4" class="ltx_td ltx_align_left ltx_border_tt"> <span id="S1.T1.2.2.2.2.3.4.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.3.4.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.3.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.3.4.1.1.1.1" class="ltx_text ltx_font_bold">Eval.</span></span></span> <span id="S1.T1.2.2.2.2.3.4.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.3.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.3.4.1.2.1.1" class="ltx_text ltx_font_bold">Metric</span></span></span> </span></span> <span id="S1.T1.2.2.2.2.3.5" class="ltx_td ltx_align_center ltx_border_tt"> <span id="S1.T1.2.2.2.2.3.5.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.3.5.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.3.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.3.5.1.1.1.1" class="ltx_text ltx_font_bold">#</span></span></span> <span id="S1.T1.2.2.2.2.3.5.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.3.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.3.5.1.2.1.1" class="ltx_text ltx_font_bold">Class</span></span></span> </span></span> <span id="S1.T1.2.2.2.2.3.6" class="ltx_td ltx_align_center ltx_border_tt"> <span id="S1.T1.2.2.2.2.3.6.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.3.6.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.3.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.3.6.1.1.1.1" class="ltx_text ltx_font_bold">{|Train|,</span></span></span> <span id="S1.T1.2.2.2.2.3.6.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.3.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.3.6.1.2.1.1" class="ltx_text ltx_font_bold">|Dev|,</span></span></span> <span id="S1.T1.2.2.2.2.3.6.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.3.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.3.6.1.3.1.1" class="ltx_text ltx_font_bold">|Test|}</span></span></span> </span></span> <span id="S1.T1.2.2.2.2.3.7" class="ltx_td ltx_align_left ltx_border_tt"><span id="S1.T1.2.2.2.2.3.7.1" class="ltx_text ltx_font_bold">Source</span></span> <span id="S1.T1.2.2.2.2.3.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt"><span id="S1.T1.2.2.2.2.3.8.1" class="ltx_text ltx_font_bold">Style</span></span></span> <span id="S1.T1.2.2.2.2.4" class="ltx_tr"> <span id="S1.T1.2.2.2.2.4.1" class="ltx_td ltx_align_left ltx_border_tt"> <span id="S1.T1.2.2.2.2.4.1.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.4.1.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">KLUE-TC</span></span> <span id="S1.T1.2.2.2.2.4.1.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(YNAT)</span></span> </span></span> <span id="S1.T1.2.2.2.2.4.2" class="ltx_td ltx_align_left ltx_border_tt"> <span id="S1.T1.2.2.2.2.4.2.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.4.2.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Topic</span></span> <span id="S1.T1.2.2.2.2.4.2.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Classification</span></span> </span></span> <span id="S1.T1.2.2.2.2.4.3" class="ltx_td ltx_align_left ltx_border_tt"> <span id="S1.T1.2.2.2.2.4.3.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.4.3.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.4.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Single Sentence</span></span> <span id="S1.T1.2.2.2.2.4.3.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.4.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Classification</span></span> </span></span> <span id="S1.T1.2.2.2.2.4.4" class="ltx_td ltx_align_left ltx_border_tt"> <span id="S1.T1.2.2.2.2.4.4.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.4.4.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.4.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Macro F1</span></span> </span></span> <span id="S1.T1.2.2.2.2.4.5" class="ltx_td ltx_align_center ltx_border_tt">7</span> <span id="S1.T1.2.2.2.2.4.6" class="ltx_td ltx_align_center ltx_border_tt"> <span id="S1.T1.2.2.2.2.4.6.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.4.6.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.4.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">45k,</span></span> <span id="S1.T1.2.2.2.2.4.6.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.4.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9k,</span></span> <span id="S1.T1.2.2.2.2.4.6.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.4.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9k</span></span> </span></span> <span id="S1.T1.2.2.2.2.4.7" class="ltx_td ltx_align_left ltx_border_tt"> <span id="S1.T1.2.2.2.2.4.7.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.4.7.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.4.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">News</span></span> <span id="S1.T1.2.2.2.2.4.7.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.4.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(Headline)</span></span> </span></span> <span id="S1.T1.2.2.2.2.4.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt">Formal</span></span> <span id="S1.T1.2.2.2.2.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.3" class="ltx_td ltx_align_left ltx_border_t">KLUE-STS</span> <span id="S1.T1.2.2.2.2.2.4" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.2.4.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.2.4.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Semantic</span></span> <span id="S1.T1.2.2.2.2.2.4.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Textual</span></span> <span id="S1.T1.2.2.2.2.2.4.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.4.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Similarity</span></span> </span></span> <span id="S1.T1.2.2.2.2.2.5" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.2.5.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.2.5.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Sentence</span></span> <span id="S1.T1.2.2.2.2.2.5.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Pair</span></span> <span id="S1.T1.2.2.2.2.2.5.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.5.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Regression</span></span> </span></span> <span id="S1.T1.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.1.1.1.1.1.1.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.1.1.1.1.1.1.1.1" class="ltx_tr"> <span id="S1.T1.1.1.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Pearson’s <math id="S1.T1.1.1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="r" display="inline"><semantics id="S1.T1.1.1.1.1.1.1.1.1.1.m1.1a"><mi id="S1.T1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S1.T1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S1.T1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S1.T1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S1.T1.1.1.1.1.1.1.1.1.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.1.1.1.1.1.1.1.1.1.m1.1c">r</annotation></semantics></math>,</span></span> <span id="S1.T1.1.1.1.1.1.1.1.2" class="ltx_tr"> <span id="S1.T1.1.1.1.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">F1</span></span> </span></span> <span id="S1.T1.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"> <span id="S1.T1.2.2.2.2.2.2.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.2.2.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><math id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2" class="ltx_Math" alttext="[0,5]" display="inline"><semantics id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2a"><mrow id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.2" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.1.cmml"><mo stretchy="false" id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.2.1" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.1.cmml">[</mo><mn id="S1.T1.2.2.2.2.2.2.1.1.1.m1.1.1" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.1.1.cmml">0</mn><mo id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.2.2" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.1.cmml">,</mo><mn id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.2" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.2.cmml">5</mn><mo stretchy="false" id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.2.3" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2b"><interval closure="closed" id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.1.cmml" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.3.2"><cn type="integer" id="S1.T1.2.2.2.2.2.2.1.1.1.m1.1.1.cmml" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.1.1">0</cn><cn type="integer" id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.2.cmml" xref="S1.T1.2.2.2.2.2.2.1.1.1.m1.2.2">5</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S1.T1.2.2.2.2.2.2.1.1.1.m1.2c">[0,5]</annotation></semantics></math></span></span> <span id="S1.T1.2.2.2.2.2.2.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">2</span></span> </span></span> <span id="S1.T1.2.2.2.2.2.6" class="ltx_td ltx_align_center ltx_border_t"> <span id="S1.T1.2.2.2.2.2.6.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.2.6.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">11k,</span></span> <span id="S1.T1.2.2.2.2.2.6.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">0.5k,</span></span> <span id="S1.T1.2.2.2.2.2.6.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1k</span></span> </span></span> <span id="S1.T1.2.2.2.2.2.7" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.2.7.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.2.7.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">News,</span></span> <span id="S1.T1.2.2.2.2.2.7.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Review,</span></span> <span id="S1.T1.2.2.2.2.2.7.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.7.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Query</span></span> </span></span> <span id="S1.T1.2.2.2.2.2.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.2.8.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.2.8.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.8.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Colloquial,</span></span> <span id="S1.T1.2.2.2.2.2.8.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.2.8.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Formal</span></span> </span></span></span> <span id="S1.T1.2.2.2.2.5" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.1" class="ltx_td ltx_align_left ltx_border_t">KLUE-NLI</span> <span id="S1.T1.2.2.2.2.5.2" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.5.2.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.5.2.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Natural</span></span> <span id="S1.T1.2.2.2.2.5.2.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Language</span></span> <span id="S1.T1.2.2.2.2.5.2.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Inference</span></span> </span></span> <span id="S1.T1.2.2.2.2.5.3" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.5.3.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.5.3.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Sentence</span></span> <span id="S1.T1.2.2.2.2.5.3.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Pair</span></span> <span id="S1.T1.2.2.2.2.5.3.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Classification</span></span> </span></span> <span id="S1.T1.2.2.2.2.5.4" class="ltx_td ltx_align_left ltx_border_t">Accuracy</span> <span id="S1.T1.2.2.2.2.5.5" class="ltx_td ltx_align_center ltx_border_t">3</span> <span id="S1.T1.2.2.2.2.5.6" class="ltx_td ltx_align_center ltx_border_t"> <span id="S1.T1.2.2.2.2.5.6.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.5.6.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">25k,</span></span> <span id="S1.T1.2.2.2.2.5.6.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3k,</span></span> <span id="S1.T1.2.2.2.2.5.6.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3k</span></span> </span></span> <span id="S1.T1.2.2.2.2.5.7" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.5.7.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.5.7.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">News,</span></span> <span id="S1.T1.2.2.2.2.5.7.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Wikipedia,</span></span> <span id="S1.T1.2.2.2.2.5.7.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.7.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Review</span></span> </span></span> <span id="S1.T1.2.2.2.2.5.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.5.8.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.5.8.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.8.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Colloquial,</span></span> <span id="S1.T1.2.2.2.2.5.8.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.5.8.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Formal</span></span> </span></span></span> <span id="S1.T1.2.2.2.2.6" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.1" class="ltx_td ltx_align_left ltx_border_t">KLUE-NER</span> <span id="S1.T1.2.2.2.2.6.2" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.6.2.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.6.2.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Named</span></span> <span id="S1.T1.2.2.2.2.6.2.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Entity</span></span> <span id="S1.T1.2.2.2.2.6.2.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Recognition</span></span> </span></span> <span id="S1.T1.2.2.2.2.6.3" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.6.3.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.6.3.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Sequence</span></span> <span id="S1.T1.2.2.2.2.6.3.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Tagging</span></span> </span></span> <span id="S1.T1.2.2.2.2.6.4" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.6.4.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.6.4.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Entity-level Macro F1</span></span> <span id="S1.T1.2.2.2.2.6.4.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Character-level Macro F1</span></span> </span></span> <span id="S1.T1.2.2.2.2.6.5" class="ltx_td ltx_align_center ltx_border_t"> <span id="S1.T1.2.2.2.2.6.5.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.6.5.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">6,</span></span> <span id="S1.T1.2.2.2.2.6.5.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">12</span></span> </span></span> <span id="S1.T1.2.2.2.2.6.6" class="ltx_td ltx_align_center ltx_border_t"> <span id="S1.T1.2.2.2.2.6.6.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.6.6.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">21k,</span></span> <span id="S1.T1.2.2.2.2.6.6.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5k,</span></span> <span id="S1.T1.2.2.2.2.6.6.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5k</span></span> </span></span> <span id="S1.T1.2.2.2.2.6.7" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.6.7.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.6.7.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">News,</span></span> <span id="S1.T1.2.2.2.2.6.7.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Review</span></span> </span></span> <span id="S1.T1.2.2.2.2.6.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.6.8.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.6.8.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.8.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Colloquial,</span></span> <span id="S1.T1.2.2.2.2.6.8.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.6.8.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Formal</span></span> </span></span></span> <span id="S1.T1.2.2.2.2.7" class="ltx_tr"> <span id="S1.T1.2.2.2.2.7.1" class="ltx_td ltx_align_left ltx_border_t">KLUE-RE</span> <span id="S1.T1.2.2.2.2.7.2" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.7.2.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.7.2.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Relation</span></span> <span id="S1.T1.2.2.2.2.7.2.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.7.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Extraction</span></span> </span></span> <span id="S1.T1.2.2.2.2.7.3" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.7.3.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.7.3.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.7.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Single Sentence</span></span> <span id="S1.T1.2.2.2.2.7.3.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.7.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Classification</span></span> <span id="S1.T1.2.2.2.2.7.3.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.7.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.7.3.1.3.1.1" class="ltx_text" style="font-size:50%;">(+2 Entity Spans)</span></span></span> </span></span> <span id="S1.T1.2.2.2.2.7.4" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.7.4.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.7.4.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.7.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Micro F1 <span id="S1.T1.2.2.2.2.7.4.1.1.1.1" class="ltx_text" style="font-size:80%;">(without <span id="S1.T1.2.2.2.2.7.4.1.1.1.1.1" class="ltx_text ltx_font_italic">no_relation</span>),</span></span></span> <span id="S1.T1.2.2.2.2.7.4.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.7.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">AUPRC</span></span> </span></span> <span id="S1.T1.2.2.2.2.7.5" class="ltx_td ltx_align_center ltx_border_t">30</span> <span id="S1.T1.2.2.2.2.7.6" class="ltx_td ltx_align_center ltx_border_t"> <span id="S1.T1.2.2.2.2.7.6.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.7.6.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.7.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">32k,</span></span> <span id="S1.T1.2.2.2.2.7.6.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.7.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8k,</span></span> <span id="S1.T1.2.2.2.2.7.6.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.7.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8k</span></span> </span></span> <span id="S1.T1.2.2.2.2.7.7" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.7.7.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.7.7.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.7.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Wikipedia,</span></span> <span id="S1.T1.2.2.2.2.7.7.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.7.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">News</span></span> </span></span> <span id="S1.T1.2.2.2.2.7.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.7.8.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.7.8.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.7.8.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Formal</span></span> </span></span></span> <span id="S1.T1.2.2.2.2.8" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.1" class="ltx_td ltx_align_left ltx_border_t">KLUE-DP</span> <span id="S1.T1.2.2.2.2.8.2" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.8.2.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.8.2.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Dependency</span></span> <span id="S1.T1.2.2.2.2.8.2.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Parsing</span></span> </span></span> <span id="S1.T1.2.2.2.2.8.3" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.8.3.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.8.3.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Sequence</span></span> <span id="S1.T1.2.2.2.2.8.3.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Tagging</span></span> <span id="S1.T1.2.2.2.2.8.3.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S1.T1.2.2.2.2.8.3.1.3.1.1" class="ltx_text" style="font-size:50%;">(+ POS Tags)</span></span></span> </span></span> <span id="S1.T1.2.2.2.2.8.4" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.8.4.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.8.4.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Unlabeled Attachment Score,</span></span> <span id="S1.T1.2.2.2.2.8.4.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Labeled Attachment Score</span></span> </span></span> <span id="S1.T1.2.2.2.2.8.5" class="ltx_td ltx_align_center ltx_border_t"> <span id="S1.T1.2.2.2.2.8.5.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.8.5.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"># Words,</span></span> <span id="S1.T1.2.2.2.2.8.5.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">38</span></span> </span></span> <span id="S1.T1.2.2.2.2.8.6" class="ltx_td ltx_align_center ltx_border_t"> <span id="S1.T1.2.2.2.2.8.6.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.8.6.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">10k,</span></span> <span id="S1.T1.2.2.2.2.8.6.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2k,</span></span> <span id="S1.T1.2.2.2.2.8.6.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">2.5k</span></span> </span></span> <span id="S1.T1.2.2.2.2.8.7" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.8.7.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.8.7.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">News,</span></span> <span id="S1.T1.2.2.2.2.8.7.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Review</span></span> </span></span> <span id="S1.T1.2.2.2.2.8.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.8.8.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.8.8.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.8.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Colloquial,</span></span> <span id="S1.T1.2.2.2.2.8.8.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.8.8.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Formal</span></span> </span></span></span> <span id="S1.T1.2.2.2.2.9" class="ltx_tr"> <span id="S1.T1.2.2.2.2.9.1" class="ltx_td ltx_align_left ltx_border_t">KLUE-MRC</span> <span id="S1.T1.2.2.2.2.9.2" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.9.2.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.9.2.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.9.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Machine</span></span> <span id="S1.T1.2.2.2.2.9.2.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.9.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Reading</span></span> <span id="S1.T1.2.2.2.2.9.2.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.9.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Comprehension</span></span> </span></span> <span id="S1.T1.2.2.2.2.9.3" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.9.3.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.9.3.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.9.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Span Prediction</span></span> </span></span> <span id="S1.T1.2.2.2.2.9.4" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.9.4.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.9.4.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.9.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Exact Match,</span></span> <span id="S1.T1.2.2.2.2.9.4.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.9.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">ROUGE-W (LCCS-based F1)</span></span> </span></span> <span id="S1.T1.2.2.2.2.9.5" class="ltx_td ltx_align_center ltx_border_t">2</span> <span id="S1.T1.2.2.2.2.9.6" class="ltx_td ltx_align_center ltx_border_t"> <span id="S1.T1.2.2.2.2.9.6.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.9.6.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.9.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">12k,</span></span> <span id="S1.T1.2.2.2.2.9.6.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.9.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8k,</span></span> <span id="S1.T1.2.2.2.2.9.6.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.9.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9k</span></span> </span></span> <span id="S1.T1.2.2.2.2.9.7" class="ltx_td ltx_align_left ltx_border_t"> <span id="S1.T1.2.2.2.2.9.7.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.9.7.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.9.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Wikipedia,</span></span> <span id="S1.T1.2.2.2.2.9.7.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.9.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">News</span></span> </span></span> <span id="S1.T1.2.2.2.2.9.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Formal</span></span> <span id="S1.T1.2.2.2.2.10" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"> <span id="S1.T1.2.2.2.2.10.1.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.10.1.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">KLUE-DST</span></span> <span id="S1.T1.2.2.2.2.10.1.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(WoS)</span></span> </span></span> <span id="S1.T1.2.2.2.2.10.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"> <span id="S1.T1.2.2.2.2.10.2.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.10.2.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Dialogue</span></span> <span id="S1.T1.2.2.2.2.10.2.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">State</span></span> <span id="S1.T1.2.2.2.2.10.2.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Tracking</span></span> </span></span> <span id="S1.T1.2.2.2.2.10.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"> <span id="S1.T1.2.2.2.2.10.3.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.10.3.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Slot-Value</span></span> <span id="S1.T1.2.2.2.2.10.3.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Prediction</span></span> </span></span> <span id="S1.T1.2.2.2.2.10.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"> <span id="S1.T1.2.2.2.2.10.4.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.10.4.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Joint Goal Accuracy</span></span> <span id="S1.T1.2.2.2.2.10.4.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Slot Micro F1</span></span> </span></span> <span id="S1.T1.2.2.2.2.10.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">(45)</span> <span id="S1.T1.2.2.2.2.10.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"> <span id="S1.T1.2.2.2.2.10.6.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.10.6.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;8k,</span></span> <span id="S1.T1.2.2.2.2.10.6.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1k,</span></span> <span id="S1.T1.2.2.2.2.10.6.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.6.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1k</span></span> </span></span> <span id="S1.T1.2.2.2.2.10.7" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"> <span id="S1.T1.2.2.2.2.10.7.1" class="ltx_tabular ltx_align_middle"> <span id="S1.T1.2.2.2.2.10.7.1.1" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Task</span></span> <span id="S1.T1.2.2.2.2.10.7.1.2" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Oriented</span></span> <span id="S1.T1.2.2.2.2.10.7.1.3" class="ltx_tr"> <span id="S1.T1.2.2.2.2.10.7.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">Dialogue</span></span> </span></span> <span id="S1.T1.2.2.2.2.10.8" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t">Colloquial</span></span> </span></span></p>
</span></div>
</figure>
</section>
<section id="S1.SS1.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Considerations in Annotation</h5>

<div id="S1.SS1.SSS0.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S1.SS1.SSS0.Px4.p1.1">각 작업에 대해 원본 말뭉치의 하위 집합에 주석을 달습니다. 그렇게 함에 있어서, 우리는 다음의 세 가지 주요 고려사항들을 고려한다:</p>
</div>
<div id="S1.SS1.SSS0.Px4.p2" class="ltx_para">
<ul id="S1.I4" class="ltx_itemize">
<li id="S1.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I4.i1.p1" class="ltx_para">
<p class="ltx_p" id="S1.I4.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I4.i1.p1.1.1">한국어 언어적 특성의 더 나은 반영</span>: 기존의 많은 한국어 데이터 세트는 다국어 정렬된 벤치마크의 일부로 구성되었으며, 명명된 개체 인식(NER) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib100" title="">100</a>]</cite>, 또는 POS(part-of-speech) 태깅 및 종속 구문 분석 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib86" title="">86</a>, <a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>에서 응집 특성과 같은 한국어의 언어적 특성을 완전히 반영하지 못한다. 우리는 한국어의 언어적 특성에 맞게 주석 지침을 더 적절하게 작성하고 수정한다.</p>
</div>
</li>
<li id="S1.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I4.i2.p1" class="ltx_para">
<p class="ltx_p" id="S1.I4.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I4.i2.p1.1.1">Obtaining accurate annotations</span>: The crowdworkers or select participants with carefully designed annotation guidelines and improve them over multiple iter, to reduce the ambiguity of annotation process and alleviate known artifact issues. 특히, 우리는 종종 주석자가 서로 쉽게 동의할 수 없는 예를 걸러낸다.</p>
</div>
</li>
<li id="S1.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I4.i3.p1" class="ltx_para">
<p class="ltx_p" id="S1.I4.i3.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I4.i3.p1.1.1">유해한 사회적 편향 완화 및 PII 제거</span>: 사회적으로 편향된 NLU 시스템 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib7" title="">7</a>]</cite>를 비활성화하려면 주석자뿐만 아니라 검사자에게 윤리 원칙에 따라 허용되지 않는 예를 수동으로 표시 및/또는 제외하도록 명시적으로 지시합니다. <span class="ltx_text ltx_font_italic" id="S1.I4.i3.p1.1.2">bias</span> 및 <span class="ltx_text ltx_font_italic" id="S1.I4.i3.p1.1.3">hate speech</span> follow <cite class="ltx_cite ltx_citemacro_citet">Moon et al. [<a class="ltx_ref" href="#bib.bib92" title="">92</a>]</cite>. 우리는 <span class="ltx_text ltx_font_italic" id="S1.I4.i3.p1.1.4">bias</span>을 성별, 인종, 배경, 국적, 민족, 정치적 입장, 피부색, 종교, 장애, 연령, 외모, (사회)경제적 지위 및 직업의 특성에 따라 특정 그룹 또는 개인에 대한 과도하게 일반화된 편견으로 나타낸다. <span class="ltx_text ltx_font_italic" id="S1.I4.i3.p1.1.5">hate speech</span>의 경우 공격적, 공격적, 모욕적 또는 비꼬는 내용을 포함한다. 한국인터넷진흥원(KISA, Korea Internet and Security Agency) 가이드라인 <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.kisa.or.kr/public/laws/laws2_View.jsp?cPage=1&amp;mode=view&amp;p_No=282&amp;b_No=282&amp;d_No=3" target="_blank" title="">https://www.kisa.or.kr/public/laws/laws2_View.jsp?cPage=1&amp;mode=view&amp;p_No=282&amp;b_No=282&amp;d_No=3</a></span></span></span>에 따라 한국의 개인정보보호법에 근거하여 살아있는 개인과 관련된 개인식별정보(PII) 목록을 식별한다. <span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://www.law.go.kr/LSW//lsInfoP.do?lsiSeq=213857&amp;chrClsCd=010203&amp;urlMode=engLsInfoR&amp;viewCls=engLsInfoR#0000</span></span></span> 공개 인물의 이름을 개인 정보로 간주하지 않는다. <span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span> See the precedent set by the Supreme Court in Korea: 대법원 2011. 9. 2. 선고 2008다42430 전원합의체 판결 available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://glaw.scourt.go.kr/wsjo/panre/sjo100.do?contId=2060159&amp;q=2008%EB%8B%A442430" target="_blank" title="">https://glaw.scourt.go.kr/wsjo/panre/sjo100.do?contId=2060159&amp;q=2008%EB%8B%A442430</a>. </span></span></span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="S1.SS1.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Evaluation Metrics</h5>

<div id="S1.SS1.SSS0.Px5.p1" class="ltx_para">
<p class="ltx_p" id="S1.SS1.SSS0.Px5.p1.1">KLUE에서 태스크의 다양성은 각 태스크에 대한 적절한 평가 메트릭 세트를 신중하고 별도로 선택해야 함을 의미한다. 여기서는 태스크를 나열하고 이러한 태스크 각각에 대한 평가 메트릭을 선택하는 방법을 설명한다.</p>
</div>
<div id="S1.SS1.SSS0.Px5.p2" class="ltx_para">
<ul id="S1.I5" class="ltx_itemize">
<li id="S1.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i1.p1" class="ltx_para">
<p class="ltx_p" id="S1.I5.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I5.i1.p1.1.1">KLUE-TC</span> (Yonhap News Agency Topic Classification (YNAT): 우리는 KLUE-TC를 7개의 클래스를 갖는 다중 클래스 분류 문제로 공식화한다. 헤드라인만으로는 그것이 속하는 적절한 클래스를 정확하게 식별하기에 충분하지 않은 경우가 많기 때문에, 우리는 수동으로 주석을 달고 70,000개의 헤드라인을 유지하는데, 각각에 대해 주석자에 의한 클래스에 대한 과반수의 합의가 있었다. 그런 다음 합의 클래스를 지상 진실 클래스로 사용하고 매크로 F1 점수를 평가 메트릭으로 사용한다.</p>
</div>
</li>
<li id="S1.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i2.p1" class="ltx_para">
<p class="ltx_p" id="S1.I5.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I5.i2.p1.1.1">KLUE-STS</span>: In KLUE-STS에서 각 문장 쌍 간의 유사도는 평균(실제 값) 유사성 등급(0과 5 사이)으로 주석 처리됩니다. 우리는 두 가지 다른 방식으로 NLU 모델의 품질을 측정한다. 먼저, 실수값과 예측값 사이의 피어슨 상관계수를 사용한다. 둘째, 패러프레이즈 검출과 같이 실수 유사도 등급을 이진화한 후 F1 점수를 계산한다.</p>
</div>
</li>
<li id="S1.I5.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i3.p1" class="ltx_para">
<p class="ltx_p" id="S1.I5.i3.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I5.i3.p1.1.1">KLUE-NLI</span>: SNLI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>]</cite> 및 MNLI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite>와 같은 기존 NLI 데이터 세트와 유사하게 분류 정확도를 사용하며, 이는 균형 있는 클래스 분포를 갖도록 KLUE-NLI dev/test 세트를 만들기 때문에 적절하다.</p>
</div>
</li>
<li id="S1.I5.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i4.p1" class="ltx_para">
<p class="ltx_p" id="S1.I5.i4.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I5.i4.p1.1.1">KLUE-NER</span>: In KLUE-NER, a named entity recognizer is expected to output BIO tags and also categorize each detected entity into one of six types; person, location, organization, date, time and quantity. 한국어의 풍부한 형태학을 설명하기 위해 개체 수준 및 문자 수준 F1 점수를 사용하여 검출의 품질을 평가하여 각 개체의 유형을 결정하는 인식자의 능력을 평가한다.</p>
</div>
</li>
<li id="S1.I5.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i5.p1" class="ltx_para">
<p class="ltx_p" id="S1.I5.i5.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I5.i5.p1.1.1">KLUE-RE</span>: KLUE-RE는 입력이 두 개의 표시된 엔터티를 가진 단일 문장이고 출력이 30가지 유형 중 그들의 관계인 문장 분류 작업으로 설계된다. 우리는 두 가지 평가 메트릭을 사용합니다. 첫 번째는 한 쌍의 개체 사이의 세밀한 관계를 식별하는 NLU 시스템의 능력을 평가할 수 있는 의미 있는 유형(관계 없음 제외)만을 고려한 마이크로 F1 점수이다. 두 번째는 AUPRC (precision-recall curve) 아래의 영역으로, 문제의 관계 추출 모델의 품질을 전체적으로 볼 수 있다.</p>
</div>
</li>
<li id="S1.I5.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i6.p1" class="ltx_para">
<p class="ltx_p" id="S1.I5.i6.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I5.i6.p1.1.1">KLUE-DP</span>: 의존성 구문 분석에서의 표준 관행에 따라, 우리는 의존성 구문 분석기를 평가하기 위해 라벨이 없는 부착 점수(UAS)와 라벨이 있는 부착 점수(LAS)를 모두 사용한다. 우리는 공식 텍스트와 비공식 텍스트(각각 뉴스 말뭉치와 구어체 리뷰 말뭉치의 하위 집합) 모두에 주석을 달고 이를 사용하여 여러 도메인에 걸쳐 세밀한 분석을 수행할 수 있다.</p>
</div>
</li>
<li id="S1.I5.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i7.p1" class="ltx_para">
<p class="ltx_p" id="S1.I5.i7.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I5.i7.p1.1.1">KLUE-MRC</span>: KLUE-NER과 유사하게 KLUE-MRC는 span prediction problem으로 framed된다. 기존 데이터 집합과의 비교를 위해 문자 수준의 정확 일치(EM)를 유지하면서, 지상 진실과 예측된 답변 범위 사이의 최장 공통 연속 서브시퀀스(LCCS)를 기반으로 F1 점수를 측정하는 ROUGE-W를 사용하는 것을 제안한다. 후자는 한국어뿐만 아니라 전자도 풍부한 형태학을 다루며 더 해석 가능하다.</p>
</div>
</li>
<li id="S1.I5.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I5.i8.p1" class="ltx_para">
<p class="ltx_p" id="S1.I5.i8.p1.1"><span class="ltx_text ltx_font_italic" id="S1.I5.i8.p1.1.1">KLUE-DST</span> (Wizard of Seoul, WoS): 우리는 KLUE-DST를 다중 문장 슬롯-값 예측 태스크로 공식화하고, 두 개의 메트릭을 사용하여 NLU 시스템을 평가한다. 첫 번째 메트릭은 모든 슬롯이 올바르게 예측되었는지 여부를 측정하는 공동 목표 정확도이고 다른 메트릭은 평균 F1 점수이다. 전자는 모든 슬롯이 올바르게 채워지지 않은 모든 예를 처리하기 때문에 유사하게 수행되는 NLU 시스템을 구별하지 못하는 경우가 많다. 우리는 공동 골 정확도와 슬롯 F1 점수를 모두 보고함으로써 이러한 단점을 해결한다. 또한 미세 입자 분석을 용이하게 하기 위해 여러 영역을 사용하여 구축한다.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S1.SS1.SSS0.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Baselines</h5>

<div id="S1.SS1.SSS0.Px6.p1" class="ltx_para">
<p class="ltx_p" id="S1.SS1.SSS0.Px6.p1.2">벤치마크 제품군을 만드는 것 외에도 대규모 사전 훈련 언어 모델을 기반으로 한 강력한 기준 세트를 구축하고 공개적으로 출시합니다. 적절한 시기에 우리는 우리 자신을 위한 대규모 언어 모델을 사전 훈련하고 출시하며, 이는 개별 연구자로부터 이러한 대규모 모델을 재훈련하는 부담을 줄일 것이다. 또한 제안된 KLUE 벤치마크에 대한 추가 통찰력을 얻기 위해 자체 모델 외에도 기존의 여러 다국어 사전 훈련 언어 모델과 오픈 소스 한국어 특정 모델을 사용한다. 우리는 표 <a class="ltx_ref" href="#S5.T32" title="Table 32 ‣ 5.3 Evaluation Results ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">32</span></a>의 모든 결과를 제시하고 여기에서 몇 가지 흥미로운 관찰을 요약한다. 먼저, 한국어 특화 언어 모델은 일반적으로 다국어 모델을 능가한다. 둘째, 서로 다른 모델들은 크기에 대해 제어될 때 서로 다른 태스크들에 대해 가장 잘 수행한다; KLUE-BERT는 YNAT 및 WoS에 대해, KLUE-RE 및 KLUE-MRC에 대해 KLUE-RoBERTa에 대해, 그리고 KLUE-STS 및 KLUE-NLI에 대해 <math alttext="\text{KoELECTRA}_{\text{BASE}}" class="ltx_Math" display="inline" id="S1.SS1.SSS0.Px6.p1.1.m1.1"><semantics id="S1.SS1.SSS0.Px6.p1.1.m1.1a"><msub id="S1.SS1.SSS0.Px6.p1.1.m1.1.1" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1.cmml"><mtext id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.2" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1.2a.cmml">KoELECTRA</mtext><mtext id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.3" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.SS1.SSS0.Px6.p1.1.m1.1b"><apply id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.cmml" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.1.cmml" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1">subscript</csymbol><ci id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.2a.cmml" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1.2"><mtext id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.2.cmml" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1.2">KoELECTRA</mtext></ci><ci id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.3a.cmml" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1.3"><mtext id="S1.SS1.SSS0.Px6.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S1.SS1.SSS0.Px6.p1.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS1.SSS0.Px6.p1.1.m1.1c">\text{KoELECTRA}_{\text{BASE}}</annotation></semantics></math>에 대해 가장 잘 수행한다. 셋째, 모델 크기가 증가함에 따라 <math alttext="\text{KLUE-RoBERTa}_{\text{LARGE}}" class="ltx_Math" display="inline" id="S1.SS1.SSS0.Px6.p1.2.m2.1"><semantics id="S1.SS1.SSS0.Px6.p1.2.m2.1a"><msub id="S1.SS1.SSS0.Px6.p1.2.m2.1.1" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1.cmml"><mtext id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.2" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.3" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="S1.SS1.SSS0.Px6.p1.2.m2.1b"><apply id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.cmml" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.1.cmml" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1">subscript</csymbol><ci id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.2a.cmml" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1.2"><mtext id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.2.cmml" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.3a.cmml" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1.3"><mtext id="S1.SS1.SSS0.Px6.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S1.SS1.SSS0.Px6.p1.2.m2.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.SS1.SSS0.Px6.p1.2.m2.1c">\text{KLUE-RoBERTa}_{\text{LARGE}}</annotation></semantics></math>는 KLUE-NER 이외의 모든 태스크에서 다른 모든 모델을 능가하게 된다. 마지막으로, PII를 제거하는 것은 다운스트림 태스크 성능에 최소한의 영향을 미치며, 형태소 기반 서브워드 토큰화 기법인 토큰화 기법은 형태소 수준에서 태깅, 탐지 및 생성과 같은 태스크에 효과적이다.</p>
</div>
</section>
<section id="S1.SS1.SSS0.Px7" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Task Overview</h5>

<div id="S1.SS1.SSS0.Px7.p1" class="ltx_para">
<p class="ltx_p" id="S1.SS1.SSS0.Px7.p1.1">표 <a class="ltx_ref" href="#S1.T1" title="Table 1 ‣ Source Corpora Collection ‣ 1.1 Summary ‣ 1 Introduction ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">1</span></a>에서 유형, 형식, 평가 메트릭 및 주석이 달린 데이터 크기와 같은 중요한 속성을 나열하는 결과 8개의 KLUE 작업을 요약합니다. 나머지 논문에서 우리는 이러한 모든 작업이 훨씬 더 자세히 구성된 과정을 살펴볼 것이다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Source Corpora</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p" id="S2.p1.1">우리는 벤치마크를 설정하는 데 있어 일반적인 관행인 기존 데이터 세트를 통합하는 대신 처음부터 KLUE를 구축한다. 사용 가능한 텍스트 리소스를 조사하고 프로세스를 문서화하여 일부 말뭉치를 선택하는 방법과 이유에 대해 더 잘 이해하도록 한다. 최근에 제안된 설명서 프레임워크는 <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">datasheets</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib41" title="">41</a>]</cite> 및 <span class="ltx_text ltx_font_italic" id="S2.p1.1.2">data statements</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib6" title="">6</a>]</cite>이다. 이러한 프레임워크를 기반으로 프로토콜을 신중하게 설명하기 위해 더 많은 정보를 문서화하고 제공한다.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Corpora Selection Criteria</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.p1.1">우리는 작업별 말뭉치가 파생되고 주석이 달린 소스 말뭉치를 구축하기 위해 말뭉치 집합을 소싱할 때 두 가지 기준을 고려한다. 첫 번째 기준은 접근성입니다. KLUE의 주요 목적은 미래의 NLP 연구 개발을 촉진하는 것이므로 KLUE가 모든 사람에게 가능한 한 자유롭게 사용하고 공유할 수 있는 데이터가 제공되도록 한다. 두 번째 기준은 품질과 다양성입니다. 우리는 낮은 품질의 텍스트를 제거함으로써 이러한 말뭉치에 대한 각 예가 특정 품질인지 확인하고 이러한 말뭉치 내에서 공식 텍스트와 구어체 텍스트 사이의 균형을 충족한다.</p>
</div>
<section id="S2.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Accessibility</h5>

<div id="S2.SS1.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS0.Px1.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Wang et al. [<a class="ltx_ref" href="#bib.bib132" title="">132</a>], Hu et al. [<a class="ltx_ref" href="#bib.bib54" title="">54</a>], Kakwani et al. [<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>와 달리, 우리는 KLUE의 사용 목적뿐만 아니라 사용자의 소속성에 대한 제한을 피함으로써 가능한 광범위하고 다양한 연구자에게 도달할 수 있도록 설계한다. 또한, NLU의 표준 벤치마크로서 KLUE의 사용성을 연장하기 위해 KLUE를 재생산하고 재분배할 수 있는 가능성을 확인하였다. 이를 위해 CC BY-SA로 소스 코퍼스를 구축하고 공개한다. <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" title="">https://creativecommons.org/licenses/by-sa/4.0/</a> </span></span></span></p>
</div>
<div id="S2.SS1.SSS0.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS0.Px1.p2.1">소스 코퍼스, 또는 소스 코퍼스의 세트는 다음의 조건들을 만족한다:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">No restriction on the use:</span> We allow both non-commercial and commercial use of KLUE, to accommodate the recent trend of fundamental research from industry labs.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">Derivatives:</span> 우리는 사용자가 KLUE의 임의의 부분을 자유롭게 리퍼비시할 수 있게 하여 첫째, 예상치 못한 아티팩트, 윤리적 문제 및 주석 오류와 같은 임의의 단점을 해결하고, 둘째, 미래에 대한 보다 도전적인 벤치마크를 도출한다. 이는 SQuAD 1.1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib112" title="">112</a>]</cite>를 포함하도록 만들어진 SQuAD 2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib113" title="">113</a>]</cite>로 이루어진 것과 유사하다.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">Redistributable:</span> KLUE의 원본 생성자에게 적절한 속성이 주어지는 한 KLUE 벤치마크 데이터 세트가 임의의 채널을 통해 누구에 의해 배포되도록 허용합니다. 우리는 제한적이고 선별된 연구자 그룹만이 자원에 대한 독점권을 가지고 궁극적으로 전반적인 진행을 방해하는 상황을 피하기 위해 의도적으로 이러한 결정을 내린다. 이는 기존의 한국 말뭉치 중 일부가 제한적 정책과 맞물려 파생상품과 재분배를 막는 경우가 많고, 국내 공공기관인 말뭉치 출판사로부터 허가를 획득한 후 국내 연구자만 접근할 수 있는 것에 대한 대응이다. KLUE는 한국 NLP의 발전을 최대한 촉진하기 위해 이러한 예방 정책을 피한다.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS1.SSS0.Px1.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS0.Px1.p3.1">대부분의 기존 데이터 세트는 이러한 조건을 충족하지 않기 때문에 CC0,<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://creativecommons.org/publicdomain/zero/1.0/" target="_blank" title="">https://creativecommons.org/publicdomain/zero/1.0/</a></span></span></span> CC BY,<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://creativecommons.org/licenses/by/4.0/" target="_blank" title="">https://creativecommons.org/licenses/by/4.0/</a></span></span></span> CC BY-SA,<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank" title="">https://creativecommons.org/licenses/by-sa/4.0/</a></span></span></span> 및 KOGL Type 1,<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.kogl.or.kr/info/license.do#05-tab" target="_blank" title="">https://www.kogl.or.kr/info/license.do#05-tab</a></span></span></span>과 같은 유사한 라이선스는 한국의 최신 저작권법에 따라 저작권법으로 보호되지 않거나 계약에 따라 저작권자가 명시적으로 제공한 리소스만 고려하여 소스 코퍼스를 처음부터 선별한다. 우리는 총 20개의 후보 말뭉치를 얻게 되며, 그 중 부분집합은 KLUE의 소스 말뭉치 집합을 형성하기 위해 선택된다. 이들은 표 <a class="ltx_ref" href="#S2.T2" title="Table 2 ‣ The Final Source Corpora ‣ 2.1 Corpora Selection Criteria ‣ 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">2</span></a>에 나열되어 있다.</p>
</div>
</section>
<section id="S2.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Quality and Diversity</h5>

<div id="S2.SS1.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS0.Px2.p1.1">이 20개의 소스 코퍼스 중에서 10개의 코퍼스의 서브세트를 선택하여 소스 코퍼스를 구성하고 KLUE 벤치마크를 구축한다. 이를 위해 1) 말뭉치가 좁은 영역(다양성)에 국한되어서는 안 되고, 2) 말뭉치를 현대 한국어(품질)로 작성해야 하며, 3) 말뭉치가 프라이버시 또는 독성에 관한 내용(품질)에 의해 지배되어서는 안 되며, 4) 말뭉치는 8가지 벤치마크 과제 중 적어도 하나에 대한 주석을 준수해야 한다. 또한, 형식적 용도와 구어적 용도를 모두 포괄할 말뭉치의 하위 집합을 선택한다.</p>
</div>
</section>
<section id="S2.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">The Final Source Corpora</h5>

<div id="S2.SS1.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS1.SSS0.Px3.p1.1">이러한 기준과 결정을 바탕으로 (상대적으로) 정식 텍스트는 뉴스 헤드라인, 위키피디아, 위키뉴, 정책뉴스, 한국경제일보, 아크로판 뉴스를 선택한다. <span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span> Although Wikitree was found to include some contents that could be considered unethical, socially biased and/or of low quality in general, we include it, as Wikitree is the largest source of license-free news articles. We address these problematic contents via annotation. </span></span></span> 구어체 텍스트에 대해서는 ParaKQC, Airbnb Reviews, 네이버 감성 영화 코퍼스를 사용한다. 이들은 표<a class="ltx_ref" href="#S2.T2" title="Table 2 ‣ The Final Source Corpora ‣ 2.1 Corpora Selection Criteria ‣ 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">2</span></a>에서 굵게 표시되어 있다.</p>
</div>
<figure id="S2.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">표 2:</span>Collected source corpora. 첫 번째 섹션의 말뭉치는 저작권법에 의해 보호되지 않습니다. 구체적으로 <span class="ltx_text ltx_font_italic" id="S2.T2.9.1">News Headlines</span>은 창작성이 부족하여 저작물로 분류되지 않으며, <span class="ltx_text ltx_font_italic" id="S2.T2.10.2">Judgements</span>은 제7조, 제3조에 따라 보호되지 않는 저작물이다. <span class="ltx_text ltx_font_italic" id="S2.T2.11.3">National Assembly Minutes</span> 및 <span class="ltx_text ltx_font_italic" id="S2.T2.12.4">Patents</span>은 National Assembly에서 만들어진 저작권법(Patents</span>은 제24조, 제2조에 의해 저작권법을 적용하지 않아야 한다. 두 번째 섹션은 퍼미시브 라이선스 아래의 코퍼라의 모음이다. 마지막 섹션 말뭉치인 KED와 아크로판은 원래 파생 작품을 만드는 것이 금지되어 있지만, 독점 계약으로 이러한 조건을 해제합니다. 컬럼의 경우 <span class="ltx_text ltx_font_italic" id="S2.T2.13.5">Volume</span>, <span class="ltx_text ltx_font_italic" id="S2.T2.14.6">Small</span>을 1k 아래의 코퍼스 크기로 나타내고, <span class="ltx_text ltx_font_italic" id="S2.T2.15.7">Medium</span>을 1k에서 50k 사이로 나타내고, <span class="ltx_text ltx_font_italic" id="S2.T2.16.8">Large</span>을 50k 이상으로 나타낸다. 볼드는 KLUE 벤치마크를 구축하기 위한 최종 소스 코퍼라를 나타냅니다.</figcaption>
<div id="S2.T2.17" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:583.6pt;height:613pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S2.T2.17.1" class="ltx_p"><span id="S2.T2.17.1.1" class="ltx_text"> <span id="S2.T2.17.1.1.1" class="ltx_tabular ltx_align_middle"> <span id="S2.T2.17.1.1.1.1" class="ltx_tr"> <span id="S2.T2.17.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S2.T2.17.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></span> <span id="S2.T2.17.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.17.1.1.1.1.2.1" class="ltx_text ltx_font_bold">License</span></span> <span id="S2.T2.17.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.17.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Domain</span></span> <span id="S2.T2.17.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.17.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Style</span></span> <span id="S2.T2.17.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"> <span id="S2.T2.17.1.1.1.1.5.1" class="ltx_tabular ltx_align_middle"> <span id="S2.T2.17.1.1.1.1.5.1.1" class="ltx_tr"> <span id="S2.T2.17.1.1.1.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.1.5.1.1.1.1" class="ltx_text ltx_font_bold">Ethical</span></span></span> <span id="S2.T2.17.1.1.1.1.5.1.2" class="ltx_tr"> <span id="S2.T2.17.1.1.1.1.5.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.1.5.1.2.1.1" class="ltx_text ltx_font_bold">Risks</span></span></span> </span></span> <span id="S2.T2.17.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T2.17.1.1.1.1.6.1" class="ltx_text ltx_font_bold">Volume</span></span> <span id="S2.T2.17.1.1.1.1.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"> <span id="S2.T2.17.1.1.1.1.7.1" class="ltx_tabular ltx_align_middle"> <span id="S2.T2.17.1.1.1.1.7.1.1" class="ltx_tr"> <span id="S2.T2.17.1.1.1.1.7.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.1.7.1.1.1.1" class="ltx_text ltx_font_bold">Contemporary</span></span></span> <span id="S2.T2.17.1.1.1.1.7.1.2" class="ltx_tr"> <span id="S2.T2.17.1.1.1.1.7.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.1.7.1.2.1.1" class="ltx_text ltx_font_bold">Korean</span></span></span> </span></span></span> <span id="S2.T2.17.1.1.1.2" class="ltx_tr"> <span id="S2.T2.17.1.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.17.1.1.1.2.1.1" class="ltx_text ltx_font_bold">News Headlines</span></span> <span id="S2.T2.17.1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.2.2.1" class="ltx_text ltx_font_bold">N/A</span></span> <span id="S2.T2.17.1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t"> <span id="S2.T2.17.1.1.1.2.3.1" class="ltx_tabular ltx_align_middle"> <span id="S2.T2.17.1.1.1.2.3.1.1" class="ltx_tr"> <span id="S2.T2.17.1.1.1.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.2.3.1.1.1.1" class="ltx_text ltx_font_bold">News (Headline)</span></span></span> </span></span> <span id="S2.T2.17.1.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.2.4.1" class="ltx_text ltx_font_bold">Formal</span></span> <span id="S2.T2.17.1.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.2.5.1" class="ltx_text ltx_font_bold">Low</span></span> <span id="S2.T2.17.1.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.2.6.1" class="ltx_text ltx_font_bold">Large</span></span> <span id="S2.T2.17.1.1.1.2.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.2.7.1" class="ltx_text ltx_font_bold">o</span></span></span> <span id="S2.T2.17.1.1.1.3" class="ltx_tr"> <span id="S2.T2.17.1.1.1.3.1" class="ltx_td ltx_align_left">Judgments</span> <span id="S2.T2.17.1.1.1.3.2" class="ltx_td ltx_align_center">Public Domain</span> <span id="S2.T2.17.1.1.1.3.3" class="ltx_td ltx_align_center">Law</span> <span id="S2.T2.17.1.1.1.3.4" class="ltx_td ltx_align_center">Formal</span> <span id="S2.T2.17.1.1.1.3.5" class="ltx_td ltx_align_center">Low</span> <span id="S2.T2.17.1.1.1.3.6" class="ltx_td ltx_align_center">Large</span> <span id="S2.T2.17.1.1.1.3.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span> <span id="S2.T2.17.1.1.1.4" class="ltx_tr"> <span id="S2.T2.17.1.1.1.4.1" class="ltx_td ltx_align_left"> <span id="S2.T2.17.1.1.1.4.1.1" class="ltx_tabular ltx_align_middle"> <span id="S2.T2.17.1.1.1.4.1.1.1" class="ltx_tr"> <span id="S2.T2.17.1.1.1.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">National Assembly</span></span> <span id="S2.T2.17.1.1.1.4.1.1.2" class="ltx_tr"> <span id="S2.T2.17.1.1.1.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Minutes</span></span> </span></span> <span id="S2.T2.17.1.1.1.4.2" class="ltx_td ltx_align_center">Public Domain</span> <span id="S2.T2.17.1.1.1.4.3" class="ltx_td ltx_align_center">Politics</span> <span id="S2.T2.17.1.1.1.4.4" class="ltx_td ltx_align_center">Colloquial</span> <span id="S2.T2.17.1.1.1.4.5" class="ltx_td ltx_align_center">Medium</span> <span id="S2.T2.17.1.1.1.4.6" class="ltx_td ltx_align_center">Large</span> <span id="S2.T2.17.1.1.1.4.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span> <span id="S2.T2.17.1.1.1.5" class="ltx_tr"> <span id="S2.T2.17.1.1.1.5.1" class="ltx_td ltx_align_left">Patents</span> <span id="S2.T2.17.1.1.1.5.2" class="ltx_td ltx_align_center">Public Domain</span> <span id="S2.T2.17.1.1.1.5.3" class="ltx_td ltx_align_center">Patent</span> <span id="S2.T2.17.1.1.1.5.4" class="ltx_td ltx_align_center">Formal</span> <span id="S2.T2.17.1.1.1.5.5" class="ltx_td ltx_align_center">Low</span> <span id="S2.T2.17.1.1.1.5.6" class="ltx_td ltx_align_center">Large</span> <span id="S2.T2.17.1.1.1.5.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span> <span id="S2.T2.17.1.1.1.6" class="ltx_tr"> <span id="S2.T2.17.1.1.1.6.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.17.1.1.1.6.1.1" class="ltx_text ltx_font_bold">Wikipedia</span></span> <span id="S2.T2.17.1.1.1.6.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.6.2.1" class="ltx_text ltx_font_bold">CC BY-SA 3.0</span></span> <span id="S2.T2.17.1.1.1.6.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.6.3.1" class="ltx_text ltx_font_bold">Wikipedia</span></span> <span id="S2.T2.17.1.1.1.6.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.6.4.1" class="ltx_text ltx_font_bold">Formal</span></span> <span id="S2.T2.17.1.1.1.6.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.6.5.1" class="ltx_text ltx_font_bold">Low</span></span> <span id="S2.T2.17.1.1.1.6.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.6.6.1" class="ltx_text ltx_font_bold">Large</span></span> <span id="S2.T2.17.1.1.1.6.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.6.7.1" class="ltx_text ltx_font_bold">o</span></span></span> <span id="S2.T2.17.1.1.1.7" class="ltx_tr"> <span id="S2.T2.17.1.1.1.7.1" class="ltx_td ltx_align_left">Wikibooks</span> <span id="S2.T2.17.1.1.1.7.2" class="ltx_td ltx_align_center">CC BY-SA 3.0</span> <span id="S2.T2.17.1.1.1.7.3" class="ltx_td ltx_align_center">Book</span> <span id="S2.T2.17.1.1.1.7.4" class="ltx_td ltx_align_center">Formal</span> <span id="S2.T2.17.1.1.1.7.5" class="ltx_td ltx_align_center">Low</span> <span id="S2.T2.17.1.1.1.7.6" class="ltx_td ltx_align_center">Medium</span> <span id="S2.T2.17.1.1.1.7.7" class="ltx_td ltx_nopad_r ltx_align_center">x</span></span> <span id="S2.T2.17.1.1.1.8" class="ltx_tr"> <span id="S2.T2.17.1.1.1.8.1" class="ltx_td ltx_align_left ltx_rowspan ltx_rowspan_2"><span id="S2.T2.17.1.1.1.8.1.1" class="ltx_text">Wikisource</span></span> <span id="S2.T2.17.1.1.1.8.2" class="ltx_td ltx_align_center ltx_rowspan ltx_rowspan_2"><span id="S2.T2.17.1.1.1.8.2.1" class="ltx_text">CC BY-SA 3.0</span></span> <span id="S2.T2.17.1.1.1.8.3" class="ltx_td ltx_align_center">Law</span> <span id="S2.T2.17.1.1.1.8.4" class="ltx_td ltx_align_center ltx_rowspan ltx_rowspan_2"><span id="S2.T2.17.1.1.1.8.4.1" class="ltx_text">Formal</span></span> <span id="S2.T2.17.1.1.1.8.5" class="ltx_td ltx_align_center ltx_rowspan ltx_rowspan_2"><span id="S2.T2.17.1.1.1.8.5.1" class="ltx_text">Low</span></span> <span id="S2.T2.17.1.1.1.8.6" class="ltx_td ltx_align_center ltx_rowspan ltx_rowspan_2"><span id="S2.T2.17.1.1.1.8.6.1" class="ltx_text">Medium</span></span> <span id="S2.T2.17.1.1.1.8.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_rowspan ltx_rowspan_2"><span id="S2.T2.17.1.1.1.8.7.1" class="ltx_text">x</span></span></span> <span id="S2.T2.17.1.1.1.9" class="ltx_tr"> <span id="S2.T2.17.1.1.1.9.1" class="ltx_td ltx_align_center">Book</span></span> <span id="S2.T2.17.1.1.1.10" class="ltx_tr"> <span id="S2.T2.17.1.1.1.10.1" class="ltx_td ltx_align_left"><span id="S2.T2.17.1.1.1.10.1.1" class="ltx_text ltx_font_bold">Wikinews</span></span> <span id="S2.T2.17.1.1.1.10.2" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.10.2.1" class="ltx_text ltx_font_bold">CC BY 2.5</span></span> <span id="S2.T2.17.1.1.1.10.3" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.10.3.1" class="ltx_text ltx_font_bold">News</span></span> <span id="S2.T2.17.1.1.1.10.4" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.10.4.1" class="ltx_text ltx_font_bold">Formal</span></span> <span id="S2.T2.17.1.1.1.10.5" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.10.5.1" class="ltx_text ltx_font_bold">Low</span></span> <span id="S2.T2.17.1.1.1.10.6" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.10.6.1" class="ltx_text ltx_font_bold">Small</span></span> <span id="S2.T2.17.1.1.1.10.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.10.7.1" class="ltx_text ltx_font_bold">o</span></span></span> <span id="S2.T2.17.1.1.1.11" class="ltx_tr"> <span id="S2.T2.17.1.1.1.11.1" class="ltx_td ltx_align_left"><span id="S2.T2.17.1.1.1.11.1.1" class="ltx_text ltx_font_bold">Wikitree</span></span> <span id="S2.T2.17.1.1.1.11.2" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.11.2.1" class="ltx_text ltx_font_bold">CC BY-SA 2.0</span></span> <span id="S2.T2.17.1.1.1.11.3" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.11.3.1" class="ltx_text ltx_font_bold">News</span></span> <span id="S2.T2.17.1.1.1.11.4" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.11.4.1" class="ltx_text ltx_font_bold">Formal</span></span> <span id="S2.T2.17.1.1.1.11.5" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.11.5.1" class="ltx_text ltx_font_bold">Medium</span></span> <span id="S2.T2.17.1.1.1.11.6" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.11.6.1" class="ltx_text ltx_font_bold">Large</span></span> <span id="S2.T2.17.1.1.1.11.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.11.7.1" class="ltx_text ltx_font_bold">o</span></span></span> <span id="S2.T2.17.1.1.1.12" class="ltx_tr"> <span id="S2.T2.17.1.1.1.12.1" class="ltx_td ltx_align_left">Librewiki</span> <span id="S2.T2.17.1.1.1.12.2" class="ltx_td ltx_align_center">CC BY-SA 3.0</span> <span id="S2.T2.17.1.1.1.12.3" class="ltx_td ltx_align_center">Wiki</span> <span id="S2.T2.17.1.1.1.12.4" class="ltx_td ltx_align_center">Formal</span> <span id="S2.T2.17.1.1.1.12.5" class="ltx_td ltx_align_center">Medium</span> <span id="S2.T2.17.1.1.1.12.6" class="ltx_td ltx_align_center">Large</span> <span id="S2.T2.17.1.1.1.12.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span> <span id="S2.T2.17.1.1.1.13" class="ltx_tr"> <span id="S2.T2.17.1.1.1.13.1" class="ltx_td ltx_align_left">Zetawiki</span> <span id="S2.T2.17.1.1.1.13.2" class="ltx_td ltx_align_center">CC BY-SA 3.0</span> <span id="S2.T2.17.1.1.1.13.3" class="ltx_td ltx_align_center">Wiki</span> <span id="S2.T2.17.1.1.1.13.4" class="ltx_td ltx_align_center">Formal</span> <span id="S2.T2.17.1.1.1.13.5" class="ltx_td ltx_align_center">Medium</span> <span id="S2.T2.17.1.1.1.13.6" class="ltx_td ltx_align_center">Large</span> <span id="S2.T2.17.1.1.1.13.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span> <span id="S2.T2.17.1.1.1.14" class="ltx_tr"> <span id="S2.T2.17.1.1.1.14.1" class="ltx_td ltx_align_left"><span id="S2.T2.17.1.1.1.14.1.1" class="ltx_text ltx_font_bold">Policy News</span></span> <span id="S2.T2.17.1.1.1.14.2" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.14.2.1" class="ltx_text ltx_font_bold">KOGL Type 1</span></span> <span id="S2.T2.17.1.1.1.14.3" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.14.3.1" class="ltx_text ltx_font_bold">News</span></span> <span id="S2.T2.17.1.1.1.14.4" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.14.4.1" class="ltx_text ltx_font_bold">Formal</span></span> <span id="S2.T2.17.1.1.1.14.5" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.14.5.1" class="ltx_text ltx_font_bold">Low</span></span> <span id="S2.T2.17.1.1.1.14.6" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.14.6.1" class="ltx_text ltx_font_bold">Medium</span></span> <span id="S2.T2.17.1.1.1.14.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.14.7.1" class="ltx_text ltx_font_bold">o</span></span></span> <span id="S2.T2.17.1.1.1.15" class="ltx_tr"> <span id="S2.T2.17.1.1.1.15.1" class="ltx_td ltx_align_left"> <span id="S2.T2.17.1.1.1.15.1.1" class="ltx_tabular ltx_align_middle"> <span id="S2.T2.17.1.1.1.15.1.1.1" class="ltx_tr"> <span id="S2.T2.17.1.1.1.15.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">NIKL Standard</span></span> <span id="S2.T2.17.1.1.1.15.1.1.2" class="ltx_tr"> <span id="S2.T2.17.1.1.1.15.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Korean Dictionary</span></span> </span></span> <span id="S2.T2.17.1.1.1.15.2" class="ltx_td ltx_align_center">CC BY-SA 2.0</span> <span id="S2.T2.17.1.1.1.15.3" class="ltx_td ltx_align_center">Dictionary</span> <span id="S2.T2.17.1.1.1.15.4" class="ltx_td ltx_align_center">Formal</span> <span id="S2.T2.17.1.1.1.15.5" class="ltx_td ltx_align_center">Low</span> <span id="S2.T2.17.1.1.1.15.6" class="ltx_td ltx_align_center">Large</span> <span id="S2.T2.17.1.1.1.15.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span> <span id="S2.T2.17.1.1.1.16" class="ltx_tr"> <span id="S2.T2.17.1.1.1.16.1" class="ltx_td ltx_align_left"> <span id="S2.T2.17.1.1.1.16.1.1" class="ltx_tabular ltx_align_middle"> <span id="S2.T2.17.1.1.1.16.1.1.1" class="ltx_tr"> <span id="S2.T2.17.1.1.1.16.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Open</span></span> <span id="S2.T2.17.1.1.1.16.1.1.2" class="ltx_tr"> <span id="S2.T2.17.1.1.1.16.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Korean Dictionary</span></span> </span></span> <span id="S2.T2.17.1.1.1.16.2" class="ltx_td ltx_align_center">CC BY-SA 2.0</span> <span id="S2.T2.17.1.1.1.16.3" class="ltx_td ltx_align_center">Dictionary</span> <span id="S2.T2.17.1.1.1.16.4" class="ltx_td ltx_align_center">Formal</span> <span id="S2.T2.17.1.1.1.16.5" class="ltx_td ltx_align_center">Low</span> <span id="S2.T2.17.1.1.1.16.6" class="ltx_td ltx_align_center">Large</span> <span id="S2.T2.17.1.1.1.16.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span> <span id="S2.T2.17.1.1.1.17" class="ltx_tr"> <span id="S2.T2.17.1.1.1.17.1" class="ltx_td ltx_align_left"><span id="S2.T2.17.1.1.1.17.1.1" class="ltx_text ltx_font_bold">ParaKQC</span></span> <span id="S2.T2.17.1.1.1.17.2" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.17.2.1" class="ltx_text ltx_font_bold">CC BY-SA 4.0</span></span> <span id="S2.T2.17.1.1.1.17.3" class="ltx_td ltx_align_center"> <span id="S2.T2.17.1.1.1.17.3.1" class="ltx_tabular ltx_align_middle"> <span id="S2.T2.17.1.1.1.17.3.1.1" class="ltx_tr"> <span id="S2.T2.17.1.1.1.17.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.17.3.1.1.1.1" class="ltx_text ltx_font_bold">Smart Home</span></span></span> <span id="S2.T2.17.1.1.1.17.3.1.2" class="ltx_tr"> <span id="S2.T2.17.1.1.1.17.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.17.3.1.2.1.1" class="ltx_text ltx_font_bold">Utterances</span></span></span> </span></span> <span id="S2.T2.17.1.1.1.17.4" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.17.4.1" class="ltx_text ltx_font_bold">Colloquial</span></span> <span id="S2.T2.17.1.1.1.17.5" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.17.5.1" class="ltx_text ltx_font_bold">Low</span></span> <span id="S2.T2.17.1.1.1.17.6" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.17.6.1" class="ltx_text ltx_font_bold">Medium</span></span> <span id="S2.T2.17.1.1.1.17.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.17.7.1" class="ltx_text ltx_font_bold">o</span></span></span> <span id="S2.T2.17.1.1.1.18" class="ltx_tr"> <span id="S2.T2.17.1.1.1.18.1" class="ltx_td ltx_align_left"><span id="S2.T2.17.1.1.1.18.1.1" class="ltx_text ltx_font_bold">Airbnb Reviews</span></span> <span id="S2.T2.17.1.1.1.18.2" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.18.2.1" class="ltx_text ltx_font_bold">CC0 1.0</span></span> <span id="S2.T2.17.1.1.1.18.3" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.18.3.1" class="ltx_text ltx_font_bold">Review</span></span> <span id="S2.T2.17.1.1.1.18.4" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.18.4.1" class="ltx_text ltx_font_bold">Colloquial</span></span> <span id="S2.T2.17.1.1.1.18.5" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.18.5.1" class="ltx_text ltx_font_bold">Medium</span></span> <span id="S2.T2.17.1.1.1.18.6" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.18.6.1" class="ltx_text ltx_font_bold">Large</span></span> <span id="S2.T2.17.1.1.1.18.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.18.7.1" class="ltx_text ltx_font_bold">o</span></span></span> <span id="S2.T2.17.1.1.1.19" class="ltx_tr"> <span id="S2.T2.17.1.1.1.19.1" class="ltx_td ltx_align_left"> <span id="S2.T2.17.1.1.1.19.1.1" class="ltx_tabular ltx_align_middle"> <span id="S2.T2.17.1.1.1.19.1.1.1" class="ltx_tr"> <span id="S2.T2.17.1.1.1.19.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S2.T2.17.1.1.1.19.1.1.1.1.1" class="ltx_text ltx_font_bold">NAVER Sentiment</span></span></span> <span id="S2.T2.17.1.1.1.19.1.1.2" class="ltx_tr"> <span id="S2.T2.17.1.1.1.19.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S2.T2.17.1.1.1.19.1.1.2.1.1" class="ltx_text ltx_font_bold">Movie Corpus (NSMC)</span></span></span> </span></span> <span id="S2.T2.17.1.1.1.19.2" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.19.2.1" class="ltx_text ltx_font_bold">CC0 1.0</span></span> <span id="S2.T2.17.1.1.1.19.3" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.19.3.1" class="ltx_text ltx_font_bold">Review</span></span> <span id="S2.T2.17.1.1.1.19.4" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.19.4.1" class="ltx_text ltx_font_bold">Colloquial</span></span> <span id="S2.T2.17.1.1.1.19.5" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.19.5.1" class="ltx_text ltx_font_bold">Medium</span></span> <span id="S2.T2.17.1.1.1.19.6" class="ltx_td ltx_align_center"><span id="S2.T2.17.1.1.1.19.6.1" class="ltx_text ltx_font_bold">Large</span></span> <span id="S2.T2.17.1.1.1.19.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.19.7.1" class="ltx_text ltx_font_bold">o</span></span></span> <span id="S2.T2.17.1.1.1.20" class="ltx_tr"> <span id="S2.T2.17.1.1.1.20.1" class="ltx_td ltx_align_left"> <span id="S2.T2.17.1.1.1.20.1.1" class="ltx_tabular ltx_align_middle"> <span id="S2.T2.17.1.1.1.20.1.1.1" class="ltx_tr"> <span id="S2.T2.17.1.1.1.20.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">NAVER Entertainment</span></span> <span id="S2.T2.17.1.1.1.20.1.1.2" class="ltx_tr"> <span id="S2.T2.17.1.1.1.20.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">News Reviews</span></span> </span></span> <span id="S2.T2.17.1.1.1.20.2" class="ltx_td ltx_align_center">CC BY-SA 4.0</span> <span id="S2.T2.17.1.1.1.20.3" class="ltx_td ltx_align_center">Review</span> <span id="S2.T2.17.1.1.1.20.4" class="ltx_td ltx_align_center">Colloquial</span> <span id="S2.T2.17.1.1.1.20.5" class="ltx_td ltx_align_center">High</span> <span id="S2.T2.17.1.1.1.20.6" class="ltx_td ltx_align_center">Large</span> <span id="S2.T2.17.1.1.1.20.7" class="ltx_td ltx_nopad_r ltx_align_center">o</span></span> <span id="S2.T2.17.1.1.1.21" class="ltx_tr"> <span id="S2.T2.17.1.1.1.21.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S2.T2.17.1.1.1.21.1.1" class="ltx_text ltx_font_bold">Acrofan News</span></span> <span id="S2.T2.17.1.1.1.21.2" class="ltx_td ltx_align_center ltx_border_t"> <span id="S2.T2.17.1.1.1.21.2.1" class="ltx_tabular ltx_align_middle"> <span id="S2.T2.17.1.1.1.21.2.1.1" class="ltx_tr"> <span id="S2.T2.17.1.1.1.21.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.21.2.1.1.1.1" class="ltx_text ltx_font_bold">CC BY-SA 4.0</span></span></span> <span id="S2.T2.17.1.1.1.21.2.1.2" class="ltx_tr"> <span id="S2.T2.17.1.1.1.21.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.21.2.1.2.1.1" class="ltx_text ltx_font_bold">for KLUE-MRC by Contract</span></span></span> </span></span> <span id="S2.T2.17.1.1.1.21.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.21.3.1" class="ltx_text ltx_font_bold">News</span></span> <span id="S2.T2.17.1.1.1.21.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.21.4.1" class="ltx_text ltx_font_bold">Formal</span></span> <span id="S2.T2.17.1.1.1.21.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.21.5.1" class="ltx_text ltx_font_bold">Low</span></span> <span id="S2.T2.17.1.1.1.21.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.21.6.1" class="ltx_text ltx_font_bold">Large</span></span> <span id="S2.T2.17.1.1.1.21.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S2.T2.17.1.1.1.21.7.1" class="ltx_text ltx_font_bold">o</span></span></span> <span id="S2.T2.17.1.1.1.22" class="ltx_tr"> <span id="S2.T2.17.1.1.1.22.1" class="ltx_td ltx_align_left ltx_border_bb"> <span id="S2.T2.17.1.1.1.22.1.1" class="ltx_tabular ltx_align_middle"> <span id="S2.T2.17.1.1.1.22.1.1.1" class="ltx_tr"> <span id="S2.T2.17.1.1.1.22.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S2.T2.17.1.1.1.22.1.1.1.1.1" class="ltx_text ltx_font_bold">The Korea Economics</span></span></span> <span id="S2.T2.17.1.1.1.22.1.1.2" class="ltx_tr"> <span id="S2.T2.17.1.1.1.22.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S2.T2.17.1.1.1.22.1.1.2.1.1" class="ltx_text ltx_font_bold">Daily News</span></span></span> </span></span> <span id="S2.T2.17.1.1.1.22.2" class="ltx_td ltx_align_center ltx_border_bb"> <span id="S2.T2.17.1.1.1.22.2.1" class="ltx_tabular ltx_align_middle"> <span id="S2.T2.17.1.1.1.22.2.1.1" class="ltx_tr"> <span id="S2.T2.17.1.1.1.22.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.22.2.1.1.1.1" class="ltx_text ltx_font_bold">CC BY-SA 4.0</span></span></span> <span id="S2.T2.17.1.1.1.22.2.1.2" class="ltx_tr"> <span id="S2.T2.17.1.1.1.22.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S2.T2.17.1.1.1.22.2.1.2.1.1" class="ltx_text ltx_font_bold">for KLUE-MRC by Contract</span></span></span> </span></span> <span id="S2.T2.17.1.1.1.22.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.17.1.1.1.22.3.1" class="ltx_text ltx_font_bold">News</span></span> <span id="S2.T2.17.1.1.1.22.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.17.1.1.1.22.4.1" class="ltx_text ltx_font_bold">Formal</span></span> <span id="S2.T2.17.1.1.1.22.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.17.1.1.1.22.5.1" class="ltx_text ltx_font_bold">Low</span></span> <span id="S2.T2.17.1.1.1.22.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S2.T2.17.1.1.1.22.6.1" class="ltx_text ltx_font_bold">Large</span></span> <span id="S2.T2.17.1.1.1.22.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S2.T2.17.1.1.1.22.7.1" class="ltx_text ltx_font_bold">o</span></span></span> </span></span></p>
</span></div>
</figure>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Selected Corpora</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.p1.1">여기서는 각 소스 말뭉치의 일반적인 특성과 잠재적인 문제에 대해 더 자세히 설명한다. 각 코퍼스의 수집 메커니즘, 시간, 도메인, 스타일, 라이선스 및 배경도 문서화합니다.</p>
</div>
<section id="S2.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">News Headlines</h5>

<div id="S2.SS2.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.1">연합뉴스(YNA)에서.</p>
</div>
<div id="S2.SS2.SSS0.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p2.1">YNA는 국내 대표 통신사 중 하나인 연합뉴스의 뉴스 헤드라인 데이터셋이다. 뉴스 헤드라인을 사용하는 것은 뉴스 기사의 실제 내용과 달리 저작권을 침해하지 않는다. 우리는 단일 문장 분류 작업에 사용하는 것을 주요 목적으로 2016년부터 2020년까지 YNA를 포함한다.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Wikipedia (WIKIPEDIA)</h5>

<div id="S2.SS2.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px2.p1.1">WIKIPEDIA는 형식적 스타일로 작성된 개방형 백과사전이며 고품질 및 잘 정리된 텍스트 때문에 많은 언어에 걸쳐 언어 모델링 및 데이터 세트 구성에 널리 사용되었다. 한국어로 된 위키피디아 기사는 CC BY-SA에 의해 공개된다. 2020년 12월 1일에 출시된 한국 위키피디아 덤프를 사용합니다.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Wikinews (WIKINEWS)</h5>

<div id="S2.SS2.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px3.p1.1">WIKINEWS는 집단 저널리즘을 구현하고 CC BY에 따라 뉴스 기사를 무료로 제공하며, 둘 다 뉴스 기사에 대해 드물다. 이러한 특성으로 인해 제한된 수의 기사(그 중 약 500개)에도 불구하고 소스 코퍼라에 포함한다.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Wikitree (WIKITREE)</h5>

<div id="S2.SS2.SSS0.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px4.p1.1">위키트리(WIKITREE)는 2010년부터 시작된 한국 최초의 소셜 미디어 기반 뉴스 플랫폼인 위키트리(Wikitree)에서 파생된 뉴스 기사 데이터 세트이다. 위키트리에 대한 기사는 많은 경우 위장 광고 또는 클릭 미끼 헤드라인이고 바람직하지 않은 편향을 표현한다는 우려가 있지만, CC BY-SA에 따라 자유롭게 배포되는 유일한 대규모 뉴스 출처이기 때문에 위키트리(WIKITREE)를 포함한다. 또한 정치, 경제, 문화 및 삶을 포함한 광범위한 주제를 다룹니다. 우리는 2016년부터 2020년 사이에 출판된 기사를 활용하며, 위키트리(WIKITREE)에 대한 보다 철저한 수동 검사를 수행한다. 자세한 내용은 섹션 <a class="ltx_ref" href="#S2.SS2.SSS1" title="2.2.1 Potential Concerns ‣ 2.2 Selected Corpora ‣ 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">2.2.1</span></a>를 참조하십시오.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Policy News (POLICY)</h5>

<div id="S2.SS2.SSS0.Px5.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px5.p1.1">POLICY는 한국의 부처, 국가 사무실 및 국가 위원회가 배포하는 다양한 기사의 데이터 세트이다. 정부 기관에서 보고한 성명, 통지 또는 언론 노트를 다룹니다. POLICY는 귀속이 제대로 이뤄지면 상업적 목적이라도 공유·리믹스할 수 있는 코리아오픈 정부 라이센스(KOGL) 제1유형에 따라 보호된다. 2020년 말까지 발표된 기사를 포함합니다.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">ParaKQC (PARAKQC)</h5>

<div id="S2.SS2.SSS0.Px6.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px6.p1.1">PARAKQC는 10개의 유사 쿼리 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib18" title="">18</a>]</cite>의 1,000개의 인텐트로 구성된 스마트 홈 디바이스를 겨냥한 10,000개의 발화의 데이터셋이다. 약속 잡기, 날씨 문의 등 스마트 홈 스피커와 상호 작용할 때 가능한 다양한 주제를 다룹니다. PARAKQC는 CC BY-SA에서 사용할 수 있습니다.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px7" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Airbnb Reviews (AIRBNB)</h5>

<div id="S2.SS2.SSS0.Px7.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px7.p1.1">AIRBNB는 Airbnb 웹 사이트의 공개적으로 액세스할 수 있는 부분에서 가져온 리뷰 데이터 세트이다. 보다 구체적으로, 우리는 Inside Airbnb가 수집하고 전처리한 기존의 다국어 Airbnb 리뷰에서 시작한다. <span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://insideairbnb.com/get-the-data.html" target="_blank" title="">http://insideairbnb.com/get-the-data.html</a> </span></span></span> 정규식을 사용하여 이 다국어 Airbnb 말뭉치에서 한국어로 작성된 리뷰의 하위 집합을 식별한다. 숙박을 마친 호스트와 게스트의 리뷰입니다. AIRBNB는 CC0에서 사용할 수 있습니다.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px8" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">NAVER Sentiment Movie Corpus (NSMC)</h5>

<div id="S2.SS2.SSS0.Px8.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px8.p1.1">NSMC는 네이버 영화에서 스크래핑한 영화 리뷰 데이터셋입니다. <span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://movie.naver.com/movie/point/af/list.nhn" target="_blank" title="">https://movie.naver.com/movie/point/af/list.nhn</a> </span></span></span> 리뷰는 온라인 사용자가 작성합니다. 각 리뷰에는 텍스트 내용과 이진 감정 레이블이 함께 제공됩니다. 총 20만 개의 리뷰가 있습니다. 긍정적인 검토자와 부정적인 검토자의 수는 균형을 이룬다. NSMC는 CC0에서 사용할 수 있습니다.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px9" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Acrofan News (ACROFAN)</h5>

<div id="S2.SS2.SSS0.Px9.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px9.p1.1">ACROFAN은 ACROFAN이 발표한 뉴스 기사로 구성된 코퍼스이다. 대부분의 기사는 기업의 신제품이나 이벤트를 소개하는 경우가 많다는 점에서 보도자료와 유사하다. 기사에는 자동차, IT, 스타트업, 대기업, 에너지, 뷰티 및 패션을 포함한 광범위한 범주가 포함되지만 형식과 스타일은 상당히 템플릿화되어 있습니다. 우리는 KLUE에 대한 ACROFAN으로부터 기사의 허가와 사용을 얻는다. 2020년 12월부터 2021년 1월 사이에 발행된 뉴스 기사를 포함합니다.</p>
</div>
</section>
<section id="S2.SS2.SSS0.Px10" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">The Korea Economics Daily News (The Korea Economy Daily)</h5>

<div id="S2.SS2.SSS0.Px10.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS0.Px10.p1.1">한국경제는 한경공사가 보유한 한국경제신문 기사로 구성된 뉴스 코퍼스다. 한국경제신문은 경제 이슈를 주로 다루는 신문이지만 정치, 문화, IT 주제 등 다양한 주제를 발행하기도 한다. 한국경제신문 사장과 우리는 2013년 1월부터 2015년 12월 사이에 한경공사가 제공한 뉴스 기사를 KLUE의 일부로 사용하기로 계약을 체결했다. 이를 통해 고품질의 잘 정리된 뉴스 기사가 KLUE에 포함되도록 할 수 있다. 우리는 이 기사들이 기계 학습 연구의 목적으로 사용된다는 조건으로 CC BY-SA에 따라 한국 경제 일보를 발표한다.</p>
</div>
</section>
<section id="S2.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1 </span>Potential Concerns</h4>

<div id="S2.SS2.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS1.p1.1">위의 10개의 선택된 말뭉치를 기반으로 여기에서 몇 가지 우려 사항을 나열하고 논의한다. 일부 우려는 데이터의 품질에 초점을 맞추는 반면 다른 우려는 더 사회적이고 윤리적이다.</p>
</div>
<section id="S2.SS2.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Toxic Content</h5>

<div id="S2.SS2.SSS1.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS1.Px1.p1.1">YNA, WIKINEWS, WIKITREE, POLICY, ACROFAN, 한국경제신문과 같은 뉴스 기사는 온라인 리뷰와 같은 사용자 생성 콘텐츠보다 더 잘 작성되고 선별되지만, 그럼에도 불구하고 이러한 기사는 기자와 편집자가 가진 편향의 일부를 반영할 수 있다. 특히, 우리의 수동 검사는 WIKITREE가 소셜 미디어에서 더 널리 공유되고 클릭되는 기사를 장려하는 인센티브 구조로 인해 다른 뉴스 소스보다 잠재적으로 문제가 될 수 있는 패턴을 더 많이 포함하고 있음을 보여주었다. 이것은 이러한 기사의 헤드라인에 특히 해당하므로 TC를 구성할 때 위키트리 헤드라인을 사용하는 것을 삼간다. 우리는 또한 기사 전체가 이야기의 선정적인 측면을 과장하고 강조하는 경우가 많기 때문에 MRC에 WIKITREE의 기사 내용을 사용하지 않는다. 그러나 우리는 다른 작업별 말뭉치를 만들 때 WIKITREE에서 샘플링된 문장을 사용하며, 이는 종종 완전하고 잘 형성되기 때문이다. 우리는 주석으로 문제가 되는 문장을 버린다.</p>
</div>
<div id="S2.SS2.SSS1.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS1.Px1.p2.1">뉴스 기사와 달리 온라인 리뷰는 독성 콘텐츠를 포함할 가능성이 더 높지만 그러한 경향은 말뭉치마다 다르다. 동료 검토 시스템으로 인해 AIRBNB는 독성이 있는 것으로 간주되는 리뷰를 거의 포함하지 않는다. 반면 NSMC는 영화, 출연진, 감독에 대해 모욕적인 것으로 간주될 수 있는 댓글을 포함하고 있다. 리뷰 도메인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib92" title="">92</a>]</cite>에 한국어 혐오 음성 데이터셋이 있기 때문에 먼저 데이터셋에 학습된 디텍터로 독성 콘텐츠를 걸러낸다. 그런 다음 주석 절차를 통해 문제가 있는 문장을 폐기한다.</p>
</div>
<div id="S2.SS2.SSS1.Px1.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS1.Px1.p3.1">PARAKQC의 모든 발화는 미리 정의된 주석 지침 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib18" title="">18</a>]</cite>를 기반으로 신중하게 생성된다. 이것은 독성 물질이 코퍼스로 들어가는 것을 크게 방지한다.</p>
</div>
</section>
<section id="S2.SS2.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Personally Identifiable Information (PII)</h5>

<div id="S2.SS2.SSS1.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS1.Px2.p1.1">개인 정보는 공인으로 간주되지 않는 개인을 식별하는 데 사용할 수 있는 모든 정보이다. <span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span> See the precedent set by the Supreme Court in Korea: 대법원 2011. 9. 2. 선고 2008다42430 전원합의체 판결 available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://glaw.scourt.go.kr/wsjo/panre/sjo100.do?contId=2060159&amp;q=2008%EB%8B%A442430" target="_blank" title="">https://glaw.scourt.go.kr/wsjo/panre/sjo100.do?contId=2060159&amp;q=2008%EB%8B%A442430</a>. </span></span></span> 인스턴스명, 주민등록번호, 전화번호 및 은행계좌번호 등을 포함한다.</p>
</div>
<div id="S2.SS2.SSS1.Px2.p2" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS1.Px2.p2.1">뉴스 기사의 경우 사회적 사건을 기술하는 특성상 이름, 주소 등 PII를 담고 있는 경우가 많다. 이것은 우리가 NSMC에서 관찰하는 것처럼 종종 배우, 여배우, 감독과 같은 공인들에 관한 것이기 때문에 온라인 리뷰에서는 덜 그렇다. 그러나 AIRBNB의 리뷰에는 호스트 및/또는 게스트의 이름과 주소가 포함되어 있으므로 신중하게 처리해야 한다.</p>
</div>
<div id="S2.SS2.SSS1.Px2.p3" class="ltx_para">
<p class="ltx_p" id="S2.SS2.SSS1.Px2.p3.1">PARAKQC에서 인위적으로 생성된 발화 중 일부는 이름을 포함한다. 그러나 이것이 대부분 허구라는 것은 우리의 이해이며, 이는 그들이 진정한 사적 정보가 될 가능성이 없다는 것을 의미한다.</p>
</div>
</section>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Preprocessing</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS3.p1.1">이러한 소스 말뭉치는 다양한 수준의 품질과 큐레이션을 가진 다양한 소스에서 나오기 때문에 각 다운스트림 작업에 대한 하위 집합을 도출하기 전에도 신중하게 전처리한다. 이 섹션에서는 한국어 문장 분할기(Korean Sentence Splitter, KSS) v2.2.0.2.<span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/hyunwoongko/kss" target="_blank" title="">https://github.com/hyunwoongko/kss</a> </span></span></span>을 사용하여 이들 말뭉치 내의 각 문서를 문장으로 분할한 후 적용되는 전처리 루틴에 대해 설명한다. 아래 프로프로세싱 루틴은 각 KLUE 작업의 주석 단계에서</span> 수동 검사 및 필터링에 추가하여 <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.1.1">이다.</p>
</div>
<section id="S2.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Noise Filtering</h5>

<div id="S2.SS3.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS3.SSS0.Px1.p1.1">We remove noisy and/or non-Korean text from the selected source corpora. We first remove hashtags (e.g., #JMT), HTML tags (e.g., &lt;br&gt;), bad characters (e.g., U+200B (zero-width space), U+FEFF (byte order mark)), empty parenthesis (e.g., ()), and consecutive blanks. We then filter out sentences with more than 10 Chinese or Japanese characters. For the corpora derived from news articles, we remove information about reporters and press, images, source tags as well as copyright tags (e.g., copyright by ©).</p>선택된 소스 말뭉치에서 잡음이 있거나 한글이 아닌 텍스트를 제거한다. 먼저 해시태그(예: #JMT), HTML 태그(예: <br>), 불량문자(예: U+200B(zero-width space), U+FEFF(byte order mark)), 빈 괄호(예: ()) 및 연속된 빈칸을 제거한다. 그런 다음 10개 이상의 중국어 또는 일본어 문자가 있는 문장을 걸러냅니다. 뉴스 기사에서 파생된 코퍼라의 경우, 우리는 저작권 태그(예: 저작권 ©)뿐만 아니라 기자와 언론, 이미지, 소스 태그에 대한 정보를 제거한다.</p>
</div>
</section>
<section id="S2.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Toxic Content Removal</h5>

<div id="S2.SS3.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS3.SSS0.Px2.p1.2">KLUE에 원하지 않는 내용과 편향을 도입하지 않기 위해, 우리는 소스 말뭉치에서 원하지 않는 문장을 제거하기 위해 다수의 자동 도구를 사용한다. 한국어 혐오 음성 데이터셋 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib92" title="">92</a>]</cite>를 이용하여 성 편견 <span class="ltx_note ltx_role_footnote" id="footnote15"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/monologg/koelectra-base-v3-gender-bias" target="_blank" title="">https://huggingface.co/monologg/koelectra-base-v3-gender-bias</a> </span></span></span>과 혐오 음성 검출기를 학습한다. <span class="ltx_note ltx_role_footnote" id="footnote16"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note">16</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/monologg/koelectra-base-v3-hate-speech" target="_blank" title="">https://huggingface.co/monologg/koelectra-base-v3-hate-speech</a> </span></span></span> 적어도 <math alttext="0.5" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px2.p1.1.m1.1"><semantics id="S2.SS3.SSS0.Px2.p1.1.m1.1a"><mn id="S2.SS3.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS3.SSS0.Px2.p1.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px2.p1.1.m1.1b"><cn id="S2.SS3.SSS0.Px2.p1.1.m1.1.1.cmml" type="float" xref="S2.SS3.SSS0.Px2.p1.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px2.p1.1.m1.1c">0.5</annotation></semantics></math>의 예측 점수로 성별 편향을 나타낼 것으로 예측한 문장을 폐기한다. 또한 <math alttext="0.9" class="ltx_Math" display="inline" id="S2.SS3.SSS0.Px2.p1.2.m2.1"><semantics id="S2.SS3.SSS0.Px2.p1.2.m2.1a"><mn id="S2.SS3.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS3.SSS0.Px2.p1.2.m2.1.1.cmml">0.9</mn><annotation-xml encoding="MathML-Content" id="S2.SS3.SSS0.Px2.p1.2.m2.1b"><cn id="S2.SS3.SSS0.Px2.p1.2.m2.1.1.cmml" type="float" xref="S2.SS3.SSS0.Px2.p1.2.m2.1.1">0.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.SSS0.Px2.p1.2.m2.1c">0.9</annotation></semantics></math> 이상의 예측 점수로 혐오 발언으로 간주되는 문장을 폐기한다. 임계값은 각 말뭉치에 대해 수동으로 결정된다. 이 접근법은 한국 혐오 발언 데이터 세트가 온라인 리뷰를 사용하여 구성되었기 때문에 리뷰와 같은 온라인 텍스트에 대해 잘 작동한다. 그러나 한국 경제, ACROFAN 및 YNA에서 이 전략을 사용하지 않기로 결정한 뉴스 기사와 같은 더 공식적인 텍스트에는 적합하지 않습니다.</p>
</div>
</section>
<section id="S2.SS3.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">PII Removal</h5>

<div id="S2.SS3.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS3.SSS0.Px3.p1.1">잠재적인 개인 정보 문제를 완화하기 위해 개인 정보가 포함된 문장을 제거합니다. 우리는 이메일 주소, URL 및 ‘@길동’과 같은 사용자 멘션 키워드와 일치하는 정규식을 사용하여 이러한 문장을 감지한다.</p>
</div>
</section>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Task Assignment</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S2.SS4.p1.1">이러한 소스 말뭉치를 사용하여 DST를 제외한 7개의 KLUE 작업에 대한 데이터 세트를 구축한다. DST는 크라우드 워커가 시뮬레이션한 대화 상자에서 만들어지며 오프라인 텍스트에 액세스할 필요가 없습니다. 각 다운스트림 작업에 대해 아래에 설명된 대로 소스 말뭉치의 하위 집합을 사용합니다.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p class="ltx_p" id="S2.I2.i1.p1.1">토픽 분류(Topic Classification, TC): 단일 문장 토픽 분류 작업에 대해 널리 연구된 YNA를 사용한다.</p>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p class="ltx_p" id="S2.I2.i2.p1.1">시맨틱 텍스트 유사성(semantic Textual Similarity: STS): 다양한 시맨틱 컨텍스트를 포함하기 위해 AIRBNB, POLICY 및 PARAKQC를 사용한다. PARAKQC의 의도 질의 및 토픽 정보는 의미적으로 관련된 문장 쌍을 생성할 때 유용하다.</p>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p class="ltx_p" id="S2.I2.i3.p1.1">NLI(Natural Language Inference): MNLI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite> 다음에 NLI를 구성하기 위해 여러 소스를 사용한다. 우리는 위키트리, 폴리시, 위키네우스, 위키페디아, NSMC 및 AIRBNB를 사용한다.</p>
</div>
</li>
<li id="S2.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i4.p1" class="ltx_para">
<p class="ltx_p" id="S2.I2.i4.p1.1">개체 이름 인식(NER): NER의 특성상 (이름)개체가 자주 등장하는 말뭉치를 구축해야 한다. 따라서 우리는 공식 및 비공식 쓰기 스타일을 모두 포함할 수 있는 WIKITREE와 NSMC를 사용한다.</p>
</div>
</li>
<li id="S2.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i5.p1" class="ltx_para">
<p class="ltx_p" id="S2.I2.i5.p1.1">관계 추출(Relation Extraction, RE): WIKIPEDIA, WIKITREE 및 POLICY를 사용한다. 이러한 말뭉치는 공인의 이름과 다양한 조직과의 관계가 있는 긴 완전한 문장을 갖는 경향이 있다.</p>
</div>
</li>
<li id="S2.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i6.p1" class="ltx_para">
<p class="ltx_p" id="S2.I2.i6.p1.1">의존 구문 분석 (DP): 형식 및 구어체 쓰기 스타일의 균형을 유지하면서 선택한 말뭉치에서 대부분의 문장이 완성되도록 합니다. 우리는 결국 WIKITREE와 AIRBNB를 사용하게 된다. 우리는 NSMC보다 AIRBNB를 선택하는데, 왜냐하면 전자는 더 나은 문장을 가지고 있기 때문이다.</p>
</div>
</li>
<li id="S2.I2.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I2.i7.p1" class="ltx_para">
<p class="ltx_p" id="S2.I2.i7.p1.1">기계독해(MRC): 유익한 구절을 제공하기 위해 우리는 WIKIPEDIA, 한국경제일보, ACROFAN을 사용한다.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>KLUE Benchmark</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p" id="S3.p1.1">KLUE의 목표는 고품질의 평가 데이터 세트와 시스템의 한국어 이해 능력을 테스트하는 데 적합한 자동 메트릭을 제공하는 것이다. 8개의 벤치마크 데이터 세트를 구성하는 방법에 대한 포괄적인 세부 정보를 제공합니다. 1) 소스 코퍼스 선택의 배경, 2) 주석 프로토콜, 3) 주석 프로세스, 4) 데이터세트 분할 전략, 5) 메트릭의 설계 프로세스를 문서화한다. 주석 프로세스에서 우리는 작업자에게 잠재적인 윤리적 문제가 포함된 텍스트를 식별하도록 안내한다. 편향, 증오 및 PII에 대한 정의는 섹션 <a class="ltx_ref" href="#footnote3" title="footnote 3 ‣ 3rd item ‣ Considerations in Annotation ‣ 1.1 Summary ‣ 1 Introduction ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a>를 참조하세요.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Topic Classification (TC)</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.p1.1">토픽 분류(TC)에서, 목표는 주어진 텍스트 스니펫의 토픽을 예측하기 위해 분류기를 훈련시키는 것이다. 토픽 분류 데이터 세트는 일반적으로 뉴스 또는 위키피디아 기사 및 미리 정의된 범주로 구성되며, 그 범주는 종종 토픽 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib151" title="">151</a>]</cite>를 나타내기 때문이다.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS1.p2.1">텍스트의 주제를 추론하는 것은 언어 이해 시스템이 가져야 하는 핵심 역량이기 때문에 KLUE 벤치마크에 TC를 포함한다. 전형적인 단일 문장 분류 작업으로서, CLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite> 및 IndicGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>와 같은 다른 NLU 벤치마크들도 TNEWS 및 뉴스 카테고리 분류를 포함한다. 한국어의 경우 작업에 대한 데이터 세트가 제안되지 않았으며, 이는 첫 번째 한국어 주제 분류 벤치마크를 구성하도록 동기를 부여한다.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS1.p3.1">이 작업에서 뉴스 헤드라인이 주어지면 텍스트 분류기는 {정치, 경제, 사회, 문화, 세계, IT/과학, 스포츠} 중 하나인 주제를 예측해야 한다. TC는 이전 연구에 이어 단일 문장 분류 작업으로 공식화하고 매크로-F1 점수를 평가 척도로 사용한다.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Dataset Construction</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.p1.1">우리의 TC 벤치마크는 세 단계로 구성된다. 먼저, 헤드라인 및 해당 카테고리를 수집하고, 카테고리를 보지 않고 주제에 주석을 달며, 데이터 세트는 출판 날짜 및 용어 출현을 고려하여 훈련, 개발 및 테스트 분할로 분할을 정의하여 최종화한다.</p>
</div>
<section id="S3.SS1.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora</h5>

<div id="S3.SS1.SSS1.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.Px1.p1.1">국내 최대 통신사인 연합뉴스(YNA)가 배포한 온라인 기사에서 뉴스 헤드라인을 수집한다. 구체적으로 2016년 1월부터 2020년 12월까지 게재된 기사들의 헤드라인을 네이버 뉴스에서 수집한다. <span class="ltx_note ltx_role_footnote" id="footnote17"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note">17</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://news.naver.com/" target="_blank" title="">https://news.naver.com/</a></span></span></span> 이 기사는 정치, 경제, 사회, 문화, 세계, IT/과학, 스포츠의 7개 섹션 중 하나에 속한다. 서로 다른 섹션에 걸친 데이터의 균형을 맞추기 위해 스포츠 및 IT/과학 섹션을 제외하고 각 섹션에서 10,000개의 기사를 무작위로 샘플링한다. 우리는 9,000개의 스포츠 기사와 11,000개의 IT/과학 기사를 수집합니다.</p>
</div>
<div id="S3.SS1.SSS1.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.Px1.p2.1">CLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite> 또는 AG News <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib151" title="">151</a>]</cite>의 TNEWS와 같은 다른 벤치마크와 달리, 저작권 침해를 피하기 위해 기사의 내용을 제외한다. 콘텐츠는 저작물로 보호되기 때문에 허가 없이 자유롭게 사용할 수 없습니다. 반면에 헤드라인은 법적 판례 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib23" title="">23</a>]</cite>에 따라 저작권이 있는 저작물로 간주되지 않는다.</p>
</div>
</section>
<section id="S3.SS1.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Protocol</h5>

<div id="S3.SS1.SSS1.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.Px2.p1.1">각 기사의 헤드라인은 주요 내용을 모두 반영하지 않을 수 있으므로, 헤드라인의 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.Px2.p1.1.1">topic</span>은 기사의 원본 뉴스 섹션과 다를 수 있다. 헤드라인과 해당 기사 사이의 이러한 격차를 해결하기 위해 헤드라인의 주제에 수동으로 주석을 달았다.</p>
</div>
<div id="S3.SS1.SSS1.Px2.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.Px2.p2.1">우리는 한국의 크라우드소싱 플랫폼인 SelectStar, <span class="ltx_note ltx_role_footnote" id="footnote18"><sup class="ltx_note_mark">18</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">18</sup><span class="ltx_tag ltx_tag_note">18</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://selectstar.ai/" target="_blank" title="">https://selectstar.ai/</a></span></span></span>을 사용하여 헤드라인의 주제에 주석을 달습니다. 각 헤드라인에 대해 세 명의 주석자가 서로 독립적으로 주제를 레이블링합니다. 각 주석자는 7개의 범주 중 관련성 순서로 최대 3개의 주제를 선택한다. 또한 정확한 주석을 위해 각 주제의 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.Px2.p2.1.1">key terms</span>을 주석자에게 제시한다. 용어는 표 <a class="ltx_ref" href="#S3.T3" title="Table 3 ‣ Final Dataset ‣ 3.1.1 Dataset Construction ‣ 3.1 Topic Classification (TC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a>와 같이 네이버 뉴스 플랫폼에서 해당 토픽의 하위 섹션이다.</p>
</div>
<div id="S3.SS1.SSS1.Px2.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.Px2.p3.1">주석자는 헤드라인이 적절한 카테고리를 식별하기에 충분한 정보를 포함하지 않는 경우 <span class="ltx_text ltx_font_italic" id="S3.SS1.SSS1.Px2.p3.1.1">unable-to-decide</span>을 선택할 수 있다. 그러한 예는 “김영수에게 감사패를 수여한다”이다. 이 헤드라인에는 “김영수”가 누구인지, 왜 감사패를 수여하고 있는지에 대한 단서가 없다.</p>
</div>
<div id="S3.SS1.SSS1.Px2.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.Px2.p4.1">우리는 근로자들에게 개인 식별 정보(PII)를 포함하거나 사회적 편견을 표현하거나 혐오 발언을 포함하는 모든 헤드라인을 보고하도록 요청한다. 보고된 헤드라인은 수동으로 검토한 후 폐기합니다.</p>
</div>
</section>
<section id="S3.SS1.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Process</h5>

<div id="S3.SS1.SSS1.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.Px3.p1.1">우리는 주요 주석 프로세스를 시작하기 전에 작업자를 선택하기 위해 파일럿 연구를 실행한다. 시범 단계에서 지속적으로 주제를 할당하지 못하거나 다른 작업자와 합의하지 못한 작업자는 제외한다. 그 결과 13명의 근로자가 이 단계의 파일럿 연구를 통과했다.</p>
</div>
<div id="S3.SS1.SSS1.Px3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.Px3.p2.1">주 주석에서 13명의 선택된 작업자는 모든 70,000개의 헤드라인에 대한 주제를 표시했다. 주석 동안 잠재적인 PII(0.93%), 194개의 독성 내용(0.28%) 및 2,515 <span 클래스="ltx_text ltx_font_italic" id="S3.SS1.SSS1.Px3.p2.1.1">unable-to-decide</span>s(3.59%)를 포함하여 650개의 헤드라인을 보고했다. 우리는 먼저 그러한 무효한 2,953개의 헤드라인을 제외한다. 문제가 되는 세 가지 유형의 헤드라인의 합은 이들 간의 교차로 인해 총 값보다 크다. 필터링 후 67,047개의 헤드라인이 남아 있습니다.</p>
</div>
<div id="S3.SS1.SSS1.Px3.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.Px3.p3.1">우리는 유효한 헤드라인에서 세 명의 주석자 간의 합의를 살펴본다. 우리는 세 명의 주석자가 선택한 첫 번째 관련 주제 각각을 고려한다. 40,359개(60.5%)의 헤드라인에서 세 명의 주석자가 모두 단일 주제에 동의합니다. 2만 3,353명(34.8%)이 과반수 득표율을 보였고 나머지 3,155명(4.7%)은 합의에 이르지 못했다. 헤드라인을 단일 주제로 분류하기 위해 다른 헤드라인을 제거하고 63,892개의 헤드라인을 남긴다.</p>
</div>
<div id="S3.SS1.SSS1.Px3.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.Px3.p4.1">우리는 주석자 내에서 두 번째 및 세 번째 관련 주제를 조사한다. 48,885개(69.8%)의 헤드라인에 대해 3명의 주석자는 두 번째와 세 번째로 가장 관련성이 높은 주제를 선택하지 않았다. 헤드라인의 5,088개(7.3%)만이 3개의 주석기에서 두 번째 주제를 가지고 있다. 따라서 우리는 헤드라인이 주석자 내의 첫 번째 관련 주제에 의해 충분히 표현된다고 가정한다.</p>
</div>
<div id="S3.SS1.SSS1.Px3.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.Px3.p5.1">따라서 우리는 3개 중 적어도 2개의 주석자가 선택한 각 헤드라인에 대해 단일 주제만 유지한다. 결과 63,892개의 헤드라인에 대한 주석자 동의는 상당히 높다(Krippendorff's <math alttext="\alpha=0.713" class="ltx_Math" display="inline" id="S3.SS1.SSS1.Px3.p5.1.m1.1"><semantics id="S3.SS1.SSS1.Px3.p5.1.m1.1a"><mrow id="S3.SS1.SSS1.Px3.p5.1.m1.1.1" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.Px3.p5.1.m1.1.1.2" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1.2.cmml">α</mi><mo id="S3.SS1.SSS1.Px3.p5.1.m1.1.1.1" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.SSS1.Px3.p5.1.m1.1.1.3" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1.3.cmml">0.713</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.Px3.p5.1.m1.1b"><apply id="S3.SS1.SSS1.Px3.p5.1.m1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1"><eq id="S3.SS1.SSS1.Px3.p5.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1.1"></eq><ci id="S3.SS1.SSS1.Px3.p5.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1.2">𝛼</ci><cn id="S3.SS1.SSS1.Px3.p5.1.m1.1.1.3.cmml" type="float" xref="S3.SS1.SSS1.Px3.p5.1.m1.1.1.3">0.713</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.Px3.p5.1.m1.1c">\alpha=0.713</annotation></semantics></math>) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS1.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS1.SSS1.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS1.Px4.p1.1">최종 데이터셋인 YNAT(Yonhap News Agency dataset for Topic classification)를 train, development, test set으로 분할한다. 출판 날짜를 기준으로 데이터 세트를 분할합니다. 2020년 이후에 발표된 헤드라인은 개발 및 테스트 세트에, 2020년 이전에 발표된 헤드라인은 훈련 세트에 포함한다. TC 모델이 특정 키워드에 참석하여 헤드라인을 분류하는 것을 방지하기 위해 기차 세트에 나타나지 않은 용어가 포함된 헤드라인을 개발 및 테스트 세트에 포함한다. 표 <a class="ltx_ref" href="#S3.T3" title="Table 3 ‣ Final Dataset ‣ 3.1.1 Dataset Construction ‣ 3.1 Topic Classification (TC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a>와 같이 기차, 개발, 테스트 세트는 각각 45,678개, 9,107개, 9,107개의 예시로 구성되어 있다.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 3:</span>YNAT(KLUE-TC)의 최종 통계, 각 카테고리의 핵심 용어가 제공된다.</figcaption>
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T3.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T3.1.1.1.1" class="ltx_text ltx_font_bold">Topic</span></td>
<td id="S3.T3.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T3.1.1.2.1" class="ltx_text ltx_font_bold">Key Terms</span></td>
<td id="S3.T3.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.3.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T3.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.4.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T3.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.5.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T3.1.1.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T3.1.1.6.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T3.1.2" class="ltx_tr">
<td id="S3.T3.1.2.1" class="ltx_td ltx_align_left ltx_border_t">Politics</td>
<td id="S3.T3.1.2.2" class="ltx_td ltx_align_left ltx_border_t">
<table id="S3.T3.1.2.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.1.2.2.1.1" class="ltx_tr">
<td id="S3.T3.1.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.2.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Blue House, Ministry, Parliament, North Korea</span></td>
</tr>
<tr id="S3.T3.1.2.2.1.2" class="ltx_tr">
<td id="S3.T3.1.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.2.2.1.2.1.1" class="ltx_text" style="font-size:90%;">Political parties, Defense, Diplomacy</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.1.2.3" class="ltx_td ltx_align_center ltx_border_t">7,379</td>
<td id="S3.T3.1.2.4" class="ltx_td ltx_align_center ltx_border_t">750</td>
<td id="S3.T3.1.2.5" class="ltx_td ltx_align_center ltx_border_t">722</td>
<td id="S3.T3.1.2.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">8,851</td>
</tr>
<tr id="S3.T3.1.3" class="ltx_tr">
<td id="S3.T3.1.3.1" class="ltx_td ltx_align_left">Economy</td>
<td id="S3.T3.1.3.2" class="ltx_td ltx_align_left">
<table id="S3.T3.1.3.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.1.3.2.1.1" class="ltx_tr">
<td id="S3.T3.1.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.3.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Stock, Finance, Industry Enterprise, Real estate</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.1.3.3" class="ltx_td ltx_align_center">6,118</td>
<td id="S3.T3.1.3.4" class="ltx_td ltx_align_center">1,268</td>
<td id="S3.T3.1.3.5" class="ltx_td ltx_align_center">1,348</td>
<td id="S3.T3.1.3.6" class="ltx_td ltx_nopad_r ltx_align_center">8,734</td>
</tr>
<tr id="S3.T3.1.4" class="ltx_tr">
<td id="S3.T3.1.4.1" class="ltx_td ltx_align_left">Society</td>
<td id="S3.T3.1.4.2" class="ltx_td ltx_align_left">
<table id="S3.T3.1.4.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.1.4.2.1.1" class="ltx_tr">
<td id="S3.T3.1.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.4.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Education, Labor, Journalism</span></td>
</tr>
<tr id="S3.T3.1.4.2.1.2" class="ltx_tr">
<td id="S3.T3.1.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.4.2.1.2.1.1" class="ltx_text" style="font-size:90%;">Environment, Human rights, Food and drugs</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.1.4.3" class="ltx_td ltx_align_center">5,133</td>
<td id="S3.T3.1.4.4" class="ltx_td ltx_align_center">3,740</td>
<td id="S3.T3.1.4.5" class="ltx_td ltx_align_center">3,701</td>
<td id="S3.T3.1.4.6" class="ltx_td ltx_nopad_r ltx_align_center">12,574</td>
</tr>
<tr id="S3.T3.1.5" class="ltx_tr">
<td id="S3.T3.1.5.1" class="ltx_td ltx_align_left">Culture</td>
<td id="S3.T3.1.5.2" class="ltx_td ltx_align_left">
<table id="S3.T3.1.5.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.1.5.2.1.1" class="ltx_tr">
<td id="S3.T3.1.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T3.1.5.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Health, Transportation, Leisure, Hot places, Fashion</span>,</td>
</tr>
<tr id="S3.T3.1.5.2.1.2" class="ltx_tr">
<td id="S3.T3.1.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.5.2.1.2.1.1" class="ltx_text" style="font-size:90%;">Beauty, Performance, Exhibition, Books, Weather</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.1.5.3" class="ltx_td ltx_align_center">5,751</td>
<td id="S3.T3.1.5.4" class="ltx_td ltx_align_center">1,387</td>
<td id="S3.T3.1.5.5" class="ltx_td ltx_align_center">1,369</td>
<td id="S3.T3.1.5.6" class="ltx_td ltx_nopad_r ltx_align_center">8,507</td>
</tr>
<tr id="S3.T3.1.6" class="ltx_tr">
<td id="S3.T3.1.6.1" class="ltx_td ltx_align_left">World</td>
<td id="S3.T3.1.6.2" class="ltx_td ltx_align_left">
<table id="S3.T3.1.6.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.1.6.2.1.1" class="ltx_tr">
<td id="S3.T3.1.6.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.6.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Asia/Australia, America, Europe, Middle East/Africa</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.1.6.3" class="ltx_td ltx_align_center">8,320</td>
<td id="S3.T3.1.6.4" class="ltx_td ltx_align_center">776</td>
<td id="S3.T3.1.6.5" class="ltx_td ltx_align_center">835</td>
<td id="S3.T3.1.6.6" class="ltx_td ltx_nopad_r ltx_align_center">9,931</td>
</tr>
<tr id="S3.T3.1.7" class="ltx_tr">
<td id="S3.T3.1.7.1" class="ltx_td ltx_align_left">IT/Science</td>
<td id="S3.T3.1.7.2" class="ltx_td ltx_align_left">
<table id="S3.T3.1.7.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.1.7.2.1.1" class="ltx_tr">
<td id="S3.T3.1.7.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.7.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Mobile, IT, Internet Social media, Communication</span></td>
</tr>
<tr id="S3.T3.1.7.2.1.2" class="ltx_tr">
<td id="S3.T3.1.7.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.7.2.1.2.1.1" class="ltx_text" style="font-size:90%;">Computer, Game, Scientific journalism</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.1.7.3" class="ltx_td ltx_align_center">5,235</td>
<td id="S3.T3.1.7.4" class="ltx_td ltx_align_center">587</td>
<td id="S3.T3.1.7.5" class="ltx_td ltx_align_center">554</td>
<td id="S3.T3.1.7.6" class="ltx_td ltx_nopad_r ltx_align_center">6,376</td>
</tr>
<tr id="S3.T3.1.8" class="ltx_tr">
<td id="S3.T3.1.8.1" class="ltx_td ltx_align_left">Sports</td>
<td id="S3.T3.1.8.2" class="ltx_td ltx_align_left">
<table id="S3.T3.1.8.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T3.1.8.2.1.1" class="ltx_tr">
<td id="S3.T3.1.8.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T3.1.8.2.1.1.1.1" class="ltx_text" style="font-size:90%;">Baseball, Basketball, Volleyball, E-sports</span></td>
</tr>
</tbody></table>
</td>
<td id="S3.T3.1.8.3" class="ltx_td ltx_align_center">7,742</td>
<td id="S3.T3.1.8.4" class="ltx_td ltx_align_center">599</td>
<td id="S3.T3.1.8.5" class="ltx_td ltx_align_center">578</td>
<td id="S3.T3.1.8.6" class="ltx_td ltx_nopad_r ltx_align_center">8,919</td>
</tr>
<tr id="S3.T3.1.9" class="ltx_tr">
<td id="S3.T3.1.9.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T3.1.9.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T3.1.9.2" class="ltx_td ltx_border_bb ltx_border_t"></td>
<td id="S3.T3.1.9.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T3.1.9.3.1" class="ltx_text ltx_font_bold">45,678</span></td>
<td id="S3.T3.1.9.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T3.1.9.4.1" class="ltx_text ltx_font_bold">9,107</span></td>
<td id="S3.T3.1.9.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T3.1.9.5.1" class="ltx_text ltx_font_bold">9,107</span></td>
<td id="S3.T3.1.9.6" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T3.1.9.6.1" class="ltx_text ltx_font_bold">63,892</span></td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Evaluation Metric</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS2.p1.1">YNAT에 대한 평가 메트릭은 매크로 F1 점수이다. 거시 F1 점수는 토픽별 F1 점수의 평균으로 정의되며, 각 토픽에 동일한 중요성을 부여한다. 주제별 F1 점수는 가중치 재현율과 정밀도를 동등하게 평가한다.</p>
</div>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>Related Work</h4>

<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS3.p1.1">많은 토픽 분류 데이터 세트가 다양한 언어로 제안되었지만, 우리는 한국의 공개 TC 벤치마크에 대해 알지 못한다. 영어로 주제 분류를 위해 널리 사용되는 벤치마크인 AG News <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib151" title="">151</a>]</cite>는 뉴스 검색 엔진 ComeToMyHead,<span class="ltx_note ltx_role_footnote" id="footnote19"><sup class="ltx_note_mark">19</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">19</sup><span class="ltx_tag ltx_tag_note">19</span> More information available in <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html" target="_blank" title="">http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html</a></span></span></span>에서 수집된 100만 개 이상의 뉴스 기사로 구성되며, 기사를 세계, 스포츠, 비즈니스, 과학/기술의 4개 섹션으로 분류한다. 보다 최근에는 영어 이외의 언어로 된 TC 벤치마크 데이터셋이 다수 제안되었다. IndicGLUE<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>는 인도어로 뉴스 장르 분류를 포함하며, 이 분류는 뉴스 기사 또는 뉴스 헤드라인을 엔터테인먼트, 스포츠, 비즈니스, 라이프스타일, 기술, 정치, 범죄 등 7가지 범주로 분류하는 것을 목표로 한다. CLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite>의 TNEWS는 Mandarin의 뉴스 토픽 분류 작업으로 Toutiao에 게재된 15개의 뉴스 카테고리로 구성된 73K개의 제목으로 구성된다.</p>
</div>
<div id="S3.SS1.SSS3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS3.p2.1">TC 벤치마크에서 미세 조정된 대규모 언어 모델은 IndicGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>에서와 같이 100% 정확도에 근접할 수 있기 때문에, 일부 연구자들은 개선의 여지를 남기기 위해 도전적인 TC 벤치마크를 만드는 데 중점을 둔다. CLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite>는 4-fold 교차 검증을 사용하여 TNEWS에서 쉬운 예를 필터링한 다음 데이터 세트를 무작위로 섞고 분할합니다. 벤치마크를 인위적으로 더 어렵게 설계하는 대신, 벤치마크에서 비교적 쉬운 예를 사용하여 기준선 모델조차도 실제로 토픽 분류가 어떻게 좋은 성능에 도달하는지 반영한다.</p>
</div>
</section>
<section id="S3.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.4 </span>Conclusion</h4>

<div id="S3.SS1.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS1.SSS4.p1.1">한국 최초의 주제 분류 벤치마크인 YNAT를 소개합니다. 벤치마크에는 7개 범주 중 한 손으로 라벨을 붙인 주제로 분류된 63,892개의 뉴스 헤드라인이 포함된다. 우리는 각 헤드라인이 단일 주제만 가지고 있다고 가정하지만 다중 레이블 분류로 공식화될 수 있다. 따라서 두 번째 및 세 번째 관련 주제 주석을 엽니다. 또한 메타데이터가 필요한 경우 향후 작업을 위해 헤드라인별 URL이 함께 제공됩니다. 그들 중 일부가 사용 허가를 필요로 하는 경우 기관에 연락해야 합니다. 우리는 YNAT가 KLUE의 다른 과제에 비해 간단하고 기본적인 NLU 과제의 역할을 할 것으로 기대한다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Semantic Textual Similarity (STS)</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p1.1">의미적 텍스트 유사성(semantic textual similarity, STS)은 두 문장 사이의 의미적 동등성의 정도를 측정하는 것이다. STS는 기계 번역, 요약 및 질의 응답과 같은 다른 NLP 작업에 필수적이기 때문에 벤치마크에 포함한다. GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>]</cite>의 STS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite>와 같이, 많은 NLU 벤치마크들은 의미 유사성 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite>, 패러프레이즈 검출 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>, <a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>, 또는 단어 감지 명확화 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib125" title="">125</a>, <a class="ltx_ref" href="#bib.bib72" title="">72</a>]</cite>와 같은 텍스트 조각들의 의미 유사성 비교를 포함한다.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS2.p2.1">STS는 0(의미 중복 없음)에서 5(의미 동등성)까지의 실제 값으로 두 입력 문장의 의미 유사성을 예측하는 문장 쌍 회귀 태스크로 공식화된다. 모델 성능은 STS-b <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite>의 평가 체계에 따라 피어슨의 상관 계수로 측정된다. 우리는 또한 임계값 점수 3.0(패러프레이징 또는 그렇지 않음)으로 실수를 두 클래스로 이진화하고 F1 점수를 사용하여 모델을 평가한다.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Dataset Construction</h4>

<section id="S3.SS2.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora</h5>

<div id="S3.SS2.SSS1.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.Px1.p1.1">소스 말뭉치의 도메인과 스타일을 다양화하기 위해 AIRBNB(구어체 리뷰), POLICY(공식 뉴스), PARAKQC <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib18" title="">18</a>]</cite>(스마트 홈 발화)에서 문장을 수집한다. 우리는 그것들을 문장 쌍에 조심스럽게 맞춘다.</p>
</div>
<div id="S3.SS2.SSS1.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.Px1.p2.1">각 코퍼스에 대해 유사성 점수의 모든 범위를 균일하게 커버하기 위해 문장 쌍의 샘플링 전략을 설계한다. 정교한 전략이 없으면 간단한 무작위 샘플링과 쌍에 문장을 일치시키면 점수 0의 대다수가 된다. 이러한 왜도를 완화하기 위해 <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.Px1.p2.1.1">potentially</span> 유사하고 덜 유사한 문장은 다양한 방법을 사용하여 별도로 쌍을 이룬다. 예를 들어, 두 개의 설명이 동일한 이벤트를 참조하는 동일한 이미지 또는 헤드라인을 묘사하는 경우, 추가 정보 때문에 유사할 가능성이 있다. 그렇지 않으면 유사한 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib2" title="">2</a>]</cite>가 되지 않을 것이다. 이로부터 영감을 받아, 우리는 문장을 유사하거나 그렇지 않은 것으로 짝짓기하기 위해 사용 가능한 추가 정보를 사용한다. 사용할 수 없는 경우 왕복 번역(RTT)을 사용하여 유사한 쌍을 얻고 덜 유사한 쌍에 대해 <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.Px1.p2.1.2">greedy 문장 매칭</span>을 사용합니다.</p>
</div>
<div id="S3.SS2.SSS1.Px1.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.Px1.p3.1">각 문장의 의도를 사용할 수 있는 PARAKQC에 대한 전략을 지정합니다. 모든 문장은 스마트 홈 도메인에 대한 쿼리이며, 그 의도는 일부 쿼리 간에 공유된다. 예를 들어 “<span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.Px1.p3.1.1">How’s the weather today in Seoul?</span> and “<span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.Px1.p3.1.2">You know the weather of Seoul today? </span>>는 “오늘 서울의 날씨”를 묻는 것과 같은 의도를 공유합니다. 우리는 유사 쌍과 같은 의도를 가진 두 문장과 유사하지 않은 의도를 가진 두 문장을 짝짓는다. 서로 다른 쌍을 너무 많이 만들지 않기 위해 유사하지 않은 쌍도 토픽을 공유합니다.</p>
</div>
<div id="S3.SS2.SSS1.Px1.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.Px1.p4.1">AIRBNB와 POLICY의 경우 문장 간의 유사성을 추정할 수 있는 유의미한 메타데이터를 찾을 수 없다. 따라서 본 논문에서는 유사한 문장 쌍을 생성하기 위해 네이버 Papago<span class="ltx_note ltx_role_footnote" id="footnote20"><sup class="ltx_note_mark">20</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">20</sup><span class="ltx_tag ltx_tag_note">20</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://papago.naver.com/" target="_blank" title="">https://papago.naver.com/</a></span></span></span>을 이용한 RTT 기법을 도입하였는데, 이는 RTT가 원문장의 핵심 의미를 유지하면서 어휘 표현이 약간 다른 문장을 생성하는 것으로 알려져 있기 때문이다. 우리는 영어를 중간 언어로 설정했다. 우리는 한글로 다시 번역할 때 존댓말 옵션을 선택하는데, 그 이유는 그 옵션이 문장의 의미를 경험적으로 보존하는 경향이 있기 때문이다. 덜 유사한 쌍의 경우, 먼저 더 높은 점수가 더 높은 의미적 유사성과 상관관계가 있다고 가정함으로써 가능한 모든 문장 쌍의 ROUGE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib80" title="">80</a>]</cite>를 계산한다. <span class="ltx_note ltx_role_footnote" id="footnote21"><sup class="ltx_note_mark">21</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">21</sup><span class="ltx_tag ltx_tag_note">21</span>This might be replaced to any other similarity measures.</span></span></span> 그런 다음 가능한 모든 쌍에서 가장 큰 점수를 가진 쌍을 그리며 모든 문장이 일치할 때까지 나머지 쌍에 걸쳐 그리기를 반복한다. 진행됨에 따라, 남은 쌍의 수가 작아질수록 점수는 감소하여, 덜 유사한 쌍을 생성한다. 이 과정을 <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.Px1.p4.1.1">greedy sentence matching</span> (GSM), as presented in Algorithm <a class="ltx_ref" href="#algorithm1" title="In Source Corpora ‣ 3.2.1 Dataset Construction ‣ 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="algorithm1" class="ltx_float ltx_algorithm">
<div id="algorithm1.2" class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div id="algorithm1.2.3" class="ltx_listingline">
<span id="algorithm1.2.3.1" class="ltx_text"><span id="algorithm1.2.3.1.1" class="ltx_text ltx_font_bold">Result:</span> </span>Set of sentence pairs SET in a corpus C
</div>
<div id="algorithm1.2.4" class="ltx_listingline">
Prepare corpus C, Let SET = [];
</div>
<div id="algorithm1.1.1" class="ltx_listingline">
<span id="algorithm1.1.1.2" class="ltx_text ltx_font_bold">while</span>&nbsp;<em id="algorithm1.1.1.1" class="ltx_emph ltx_font_italic">size of C <math id="algorithm1.1.1.1.m1.1" class="ltx_Math" alttext="\geq" display="inline"><semantics id="algorithm1.1.1.1.m1.1a"><mo id="algorithm1.1.1.1.m1.1.1" xref="algorithm1.1.1.1.m1.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="algorithm1.1.1.1.m1.1b"><geq id="algorithm1.1.1.1.m1.1.1.cmml" xref="algorithm1.1.1.1.m1.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.1.1.1.m1.1c">\geq</annotation></semantics></math> 2</em>&nbsp;<span id="algorithm1.1.1.3" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="algorithm1.2.5" class="ltx_listingline">&nbsp;&nbsp;<span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;">&nbsp;</span>&nbsp;&nbsp;&nbsp;
1. Choose a random sentence S from C;
</div>
<div id="algorithm1.2.2" class="ltx_listingline">&nbsp;&nbsp;<span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;">&nbsp;</span>&nbsp;&nbsp;&nbsp;
2. Find a sentence T where ROUGE(S, T) is maximized and T <math id="algorithm1.2.2.m1.1" class="ltx_Math" alttext="\in" display="inline"><semantics id="algorithm1.2.2.m1.1a"><mo id="algorithm1.2.2.m1.1.1" xref="algorithm1.2.2.m1.1.1.cmml">∈</mo><annotation-xml encoding="MathML-Content" id="algorithm1.2.2.m1.1b"><in id="algorithm1.2.2.m1.1.1.cmml" xref="algorithm1.2.2.m1.1.1"></in></annotation-xml><annotation encoding="application/x-tex" id="algorithm1.2.2.m1.1c">\in</annotation></semantics></math> C\{S};
</div>
<div id="algorithm1.2.6" class="ltx_listingline">&nbsp;&nbsp;<span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;">&nbsp;</span>&nbsp;&nbsp;&nbsp;
3. Remove {S, T} from C;
</div>
<div id="algorithm1.2.7" class="ltx_listingline">&nbsp;&nbsp;<span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;">&nbsp;</span>&nbsp;&nbsp;&nbsp;
4. Add matched pair {(S, T)} to SET

</div>
<div id="algorithm1.2.8" class="ltx_listingline"> end while
</div>
<div id="algorithm1.2.9" class="ltx_listingline">

</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="algorithm1.4.1.1">Algorithm 1</span></span>Pseudocode of our greedy sentence matching (GSM) in AIRBNB and POLICY.</figcaption>
</figure>
</section>
<section id="S3.SS2.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Protocol</h5>

<div id="S3.SS2.SSS1.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.Px2.p1.1">SemEval-2015 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib2" title="">2</a>]</cite>에서 사용된 원래 주석 가이드를 수정한다. 두 문장의 청크화를 제안하고, 청크 수준(NP, 동사 체인, PP 등)에서 유사도를 비교한다. 그리고 주석이 문장 수준의 유사도로 판단을 합산해야 한다. 그러나 한국어에서는 청크화가 매우 어렵기 때문에 가이드를 직접 적용할 수 없었습니다. 청크화에서는 단어의 토큰화 및 형태소 수준의 분해가 필요하지만, 이는 어렵고 심지어 경우에 따라서는 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib103" title="">103</a>]</cite>에서도 결정적이지 않다. 따라서 우리는 주석자가 청크 없이 유사성을 평가하고 문장 수준 비교를 고수하도록 안내한다.</p>
</div>
<div id="S3.SS2.SSS1.Px2.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.Px2.p2.1">우리는 크라우드 워커에게 문장 수준 유사성 평가를 위해 <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.Px2.p2.1.1">important</span> 또는 <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.Px2.p2.1.2">unimportant</span>을 추가 큐에 제공합니다. <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.Px2.p2.1.3">Important</span> content indicates the main idea in a sentence. 선언적 문장이면 그 사실, 설명 또는 정보를 제공하는 것이 주된 발상이다. 질문적이고 명령적인 문장의 경우 요청이나 명령을 전달하는 것이 중요하다. 탄성 문장에서 감정이나 의견은 주요 내용 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib4" title="">4</a>]</cite>이다. 이러한 <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.Px2.p2.1.4">important</span> 컨텐츠는 <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.Px2.p2.1.5">unimportant</span>으로 간주됩니다. 예를 들어, 그들은 그것의 뉘앙스나 공손함에 영향을 미치는 보조 동사나 기능 단어이다. 주석자는 다음과 같이 유사도를 점수화해야 한다:</p>
</div>
<div id="S3.SS2.SSS1.Px2.p3" class="ltx_para">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S3.I1.i1.p1.1">5: 두 문장은 <span class="ltx_text ltx_font_italic" id="S3.I1.i1.p1.1.1">important</span> 및 <span class="ltx_text ltx_font_italic" id="S3.I1.i1.p1.1.2">unimportant</span> 콘텐츠 측면에서 동일하다.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S3.I1.i2.p1.1">4: 두 문장이 밀접하게 동등하다. 일부 <span class="ltx_text ltx_font_italic" id="S3.I1.i2.p1.1.1">unimportant</span> 콘텐츠가 다릅니다.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S3.I1.i3.p1.1">3: 두 문장은 대략 동등하다. <span class="ltx_text ltx_font_italic" id="S3.I1.i3.p1.1.1">Important</span> 콘텐츠는 서로 유사하지만 <span class="ltx_text ltx_font_italic" id="S3.I1.i3.p1.1.2">unimportant</span> 콘텐츠는 무시하지 않습니다.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="S3.I1.i4.p1.1">2: 두 문장은 동일하지 않다. <span class="ltx_text ltx_font_italic" id="S3.I1.i4.p1.1.1">Important</span> content is not similar, only sharing some <span class="ltx_text ltx_font_italic" id="S3.I1.i4.p1.1.2">unimportant</span> contents.</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i5.p1" class="ltx_para">
<p class="ltx_p" id="S3.I1.i5.p1.1">1: 두 문장은 동일하지 않다. <span class="ltx_text ltx_font_italic" id="S3.I1.i5.p1.1.1">Important</span> 및 <span class="ltx_text ltx_font_italic" id="S3.I1.i5.p1.1.2">unimportant</span> 콘텐츠는 서로 유사하지 않습니다. 두 문장은 주제만 공유합니다.</p>
</div>
</li>
<li id="S3.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i6.p1" class="ltx_para">
<p class="ltx_p" id="S3.I1.i6.p1.1">0: 두 문장은 동일하지 않다. 그들은 <span class="ltx_text ltx_font_italic" id="S3.I1.i6.p1.1.1">important</span> 및 <span class="ltx_text ltx_font_italic" id="S3.I1.i6.p1.1.2">unimportant</span> 콘텐츠 및 심지어 토픽을 공유하지 않습니다.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS2.SSS1.Px2.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.Px2.p4.1">또한 크라우드 워커가 문장의 맥락을 고려하도록 안내합니다. 두 문장의 의미 구분에 유의미한 영향을 미친다면 점수가 낮아야 한다. 예를 들어, 두 문장에는 "체크인은 호스트가 아닌 다른 사람이 했다."와 "체크인은 누군가가 했다."와 같은 중요한 정보 '체크인'이 포함되어 있다. 후자의 문장에서 '누군가'가 호스트일 수 있다. 우리는 전자와 ‘호스트 외’를 떨어뜨려 정보를 잃기 때문에 두 문장의 의미 차이는 무시하지 않는다. 이 쌍을 3으로 채점합니다. 또한 전자의 문장을 ‘Check-out이 호스트가 아닌 다른 사람이 수행했습니다’와 비교하면 <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.Px2.p4.1.1">important</span> 정보가 달라 점수 2를 줍니다.</p>
</div>
</section>
<section id="S3.SS2.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Process</h5>

<div id="S3.SS2.SSS1.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.Px3.p1.1">우리는 한국의 크라우드소싱 플랫폼인 SelectStar, <span class="ltx_note ltx_role_footnote" id="footnote22"><sup class="ltx_note_mark">22</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">22</sup><span class="ltx_tag ltx_tag_note">22</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://selectstar.ai/" target="_blank" title="">https://selectstar.ai/</a></span></span></span>에서 작업자를 모집하고 주석 프로토콜에 익숙화한다. 자격 있는 작업자를 선택하기 위해 파일럿 주석을 실행합니다. 크라우드 워커의 판단이 다른 작업자의 판단과 일치하지 않는 경우가 빈번할 경우, 그 사람은 주 주석 프로세스에서 제외된다. 그 결과 초기 20명의 작업자 중 19명이 주 주석에 참여하게 된다. 파일럿에서 사용된 문장 쌍을 제거한 후 AIRBNB 7,375개, POLICY 2,956개, PARAKQC 4,538개로 구성된 주요 주석에 14,869개의 쌍을 사용한다. 7명의 서로 다른 작업자는 모든 문장 쌍을 독립적으로 레이블링했다.</p>
</div>
<div id="S3.SS2.SSS1.Px3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.Px3.p2.1">각 문장 쌍에 대해 7개의 레이블을 평균화하고 <cite class="ltx_cite ltx_citemacro_citet">Agirre et al. [<a class="ltx_ref" href="#bib.bib3" title="">3</a>], Cer et al. [<a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite> 다음에 특이치를 제거한다. 먼저 피어슨의 상관 관계 < 0.80 또는 Krippendorff의 알파 < 0.20(명칭) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>를 다른 사람의 주석과 함께 보여주는 주석자를 걸러낸다. 우리는 이 기준을 가진 두 개의 주석자를 제외하여 모든 문장 쌍이 최소 5명 이상의 주석자를 갖는다. 마지막으로 유사도 점수를 소수점 첫째 자리에서 반올림한다.</p>
</div>
<div id="S3.SS2.SSS1.Px3.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.Px3.p3.1">몇 가지 필터링 방식이 더 적용된다. 먼저 주석이 2 표준편차보다 큰 14쌍을 드롭한다. 이러한 쌍에는 다양한 방식으로 해석되는 모호한 표현 또는 오주석이 포함될 수 있습니다. 둘째, RTT로 인한 번역 오류나 잘못된 정보를 포함한 문장을 작업자에게 보고하도록 요청한다. 보고된 문장을 검사하고 418개의 문장 쌍을 제거한다. 셋째, 우리는 윤리적 문제와 관련된 선고를 취하한다. 노동자들은 그들이 어떤 종류의 혐오 발언, 사회적 편견, 그리고 잠재적인 개인 식별 정보(PII)를 포함하고 있다면 그 쌍들을 보고한다. 1,213개의 문장 쌍을 검사 후 추가로 제거했다. 결과적으로, 우리는 총 13,224개의 문장 쌍을 가지고 있습니다. 우리는 7개의 주석자(또는 그 이하)가 쌍별로 다르기 때문에 피어슨의 상관 관계 대신 크리펜도르프의 알파를 사용하여 주석자 간 일치(IAA)를 보고한다. 주석자는 서로의 주석에 동의했다. (Krippendorff's alpha (interval) = 0.85).</p>
</div>
<div id="S3.SS2.SSS1.Px3.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.Px3.p4.1"><span class="ltx_text ltx_font_italic" id="S3.SS2.SSS1.Px3.p4.1.1">potentially</span> 유사 문장 쌍과 덜 유사한 쌍 간에 유사성 점수 주석의 분포가 다르다는 것을 관찰한다. 도 <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ Annotation Process ‣ 3.2.1 Dataset Construction ‣ 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">1</span></a>는 AIRBNB에서 RTT(상단) 및 GSM(하단)에 의해 생성된 라벨 분포를 예시한다. 예상대로, RTT 쌍은 높은 유사성(3에서 5까지)을 나타내는 경향이 있는 반면 GSM 쌍은 덜 유사한 것으로 간주된다(0에서 3까지). 우리는 유사성 기반 매칭을 사용하더라도 0으로 점수가 매겨진 GSM 쌍의 수가 높다는 점에 유의한다. POLICY 및 PARAKQC에서도 유사한 경향이 관찰된다. 두 개의 분포를 결합함으로써 유사도 점수의 관점에서 다양한 문장 쌍을 얻을 수 있다.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2105.09680/assets/figs/sts-fig2.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="208" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1:</span>Label distributions generated by RTT (top) and GSM (bottom) in AIRBNB.</figcaption>
</figure>
</section>
<section id="S3.SS2.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS2.SSS1.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.Px4.p1.2">우리는 13,224개의 문장 쌍과 그에 상응하는 유사도 점수를 수집한다. 점수의 분포를 고려하여 훈련, 개발, 테스트 세트로 나눕니다. 쌍을 주의 깊게 샘플링하더라도 그림 <a class="ltx_ref" href="#S3.F1" title="Figure 1 ‣ Annotation Process ‣ 3.2.1 Dataset Construction ‣ 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">1</span></a>와 같이 0<math alttext="-" class="ltx_Math" display="inline" id="S3.SS2.SSS1.Px4.p1.1.m1.1"><semantics id="S3.SS2.SSS1.Px4.p1.1.m1.1a"><mo id="S3.SS2.SSS1.Px4.p1.1.m1.1.1" xref="S3.SS2.SSS1.Px4.p1.1.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.Px4.p1.1.m1.1b"><minus id="S3.SS2.SSS1.Px4.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS1.Px4.p1.1.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.Px4.p1.1.m1.1c">-</annotation></semantics></math>5에 걸쳐 전체 점수 분포가 균일하지 않다. 그러나 우리는 특정 점수에 대한 평가 편향을 방지하기 위해 적어도 평가(개발 및 테스트) 세트에서 균일한 분포를 선호한다. 따라서 그림 <a class="ltx_ref" href="#S3.F2" title="Figure 2 ‣ Final Dataset ‣ 3.2.1 Dataset Construction ‣ 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">2</span></a>와 같이 대략 균일한 분포를 갖는 평가 집합을 구성한다. 이를 위해 점수 범위 0<math alttext="-" class="ltx_Math" display="inline" id="S3.SS2.SSS1.Px4.p1.2.m2.1"><semantics id="S3.SS2.SSS1.Px4.p1.2.m2.1a"><mo id="S3.SS2.SSS1.Px4.p1.2.m2.1.1" xref="S3.SS2.SSS1.Px4.p1.2.m2.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.Px4.p1.2.m2.1b"><minus id="S3.SS2.SSS1.Px4.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS1.Px4.p1.2.m2.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.Px4.p1.2.m2.1c">-</annotation></semantics></math>5~51개의 빈을 나누어 모든 점수의 소수점 첫째 자리까지 반올림한다. 우리는 통에 걸친 쌍의 수의 균형을 맞추려고 노력한다. 그들 중 일부는 짝의 수가 적기 때문에, 우리는 그 수에 가까운 모든 짝의 수를 맞추려고 한다.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2105.09680/assets/figs/sts-fig1.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="204" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 2:</span>열차(상단) 및 dev(하단) 집합의 유사성 점수 분포. 디브 집합의 점수는 0<math alttext="-" class="ltx_Math" display="inline" id="S3.F2.2.m1.1"><semantics id="S3.F2.2.m1.1b"><mo id="S3.F2.2.m1.1.1" xref="S3.F2.2.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S3.F2.2.m1.1c"><minus id="S3.F2.2.m1.1.1.cmml" xref="S3.F2.2.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.2.m1.1d">-</annotation></semantics></math>5 범위에 걸쳐 균일한 분포에 가깝다. 점수는 소수점 첫째 자리에서 반올림된다.</figcaption>
</figure>
<div id="S3.SS2.SSS1.Px4.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.Px4.p2.1">또한 평가 집합을 위해 각 쌍에서 문장 간의 단어 중복을 고려한다. 더 큰 단어 중복은 더 높은 의미적 유사성을 나타낼 수 있기 때문에, 우리는 모델이 단어 중복을 사용하여 단순히 유사성을 예측하는 것을 방지하기 위해 그러한 경향을 충족하는 쌍을 줄이려고 시도한다. 중첩은 MeCab <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib68" title="">68</a>]</cite>를 이용하여 형태소 수준 자카드 거리로 측정한다. 우리는 스코어 3<math alttext="-" class="ltx_Math" display="inline" id="S3.SS2.SSS1.Px4.p2.1.m1.1"><semantics id="S3.SS2.SSS1.Px4.p2.1.m1.1a"><mo id="S3.SS2.SSS1.Px4.p2.1.m1.1.1" xref="S3.SS2.SSS1.Px4.p2.1.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.Px4.p2.1.m1.1b"><minus id="S3.SS2.SSS1.Px4.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS1.Px4.p2.1.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.Px4.p2.1.m1.1c">-</annotation></semantics></math>5에서 단어 중복이 가장 적은 쌍을 선택하고 나머지 부분에서 단어 중복이 가장 많은 쌍을 선택한다. 이러한 쌍은 dev 및 테스트 세트의 모든 빈에 포함되도록 우선 순위가 매겨진다.</p>
</div>
<div id="S3.SS2.SSS1.Px4.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS1.Px4.p3.1">평가 세트를 1:2 비율로 분할하여 dev 및 테스트 세트를 구성하여 각각 519쌍 및 1,037쌍을 생성했다. 나머지 11,668쌍은 기차 세트를 구성한다. 각 말뭉치에 대한 자세한 숫자는 표 <a class="ltx_ref" href="#S3.T4" title="Table 4 ‣ Final Dataset ‣ 3.2.1 Dataset Construction ‣ 3.2 Semantic Textual Similarity (STS) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">4</span></a>에 제시되어 있다. 모든 집합에 대해, 우리는 원본 말뭉치와 원본 말뭉치 사이의 비율을 균형시킨다. 또한, 점수들은 패러프레이즈 검출 태스크와 동일한 임계값 3.0으로 이진화된다.</p>
</div>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 4:</span>KLUE-STS에 대한 통계. 처음 세 개의 열은 각 소스 말뭉치와 최종 데이터의 트레인, 디브, 테스트 세트에서 예제의 수를 제공한다.</figcaption>
<table id="S3.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T4.1.1" class="ltx_tr">
<td id="S3.T4.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T4.1.1.1.1" class="ltx_text ltx_font_bold">Source</span></td>
<td id="S3.T4.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T4.1.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T4.1.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T4.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T4.1.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T4.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T4.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T4.1.2" class="ltx_tr">
<td id="S3.T4.1.2.1" class="ltx_td ltx_align_left ltx_border_t">AIRBNB</td>
<td id="S3.T4.1.2.2" class="ltx_td ltx_align_center ltx_border_t">5,371</td>
<td id="S3.T4.1.2.3" class="ltx_td ltx_align_center ltx_border_t">255</td>
<td id="S3.T4.1.2.4" class="ltx_td ltx_align_center ltx_border_t">510</td>
<td id="S3.T4.1.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">6,136</td>
</tr>
<tr id="S3.T4.1.3" class="ltx_tr">
<td id="S3.T4.1.3.1" class="ltx_td ltx_align_left">POLICY</td>
<td id="S3.T4.1.3.2" class="ltx_td ltx_align_center">2,344</td>
<td id="S3.T4.1.3.3" class="ltx_td ltx_align_center">132</td>
<td id="S3.T4.1.3.4" class="ltx_td ltx_align_center">264</td>
<td id="S3.T4.1.3.5" class="ltx_td ltx_nopad_r ltx_align_center">2,740</td>
</tr>
<tr id="S3.T4.1.4" class="ltx_tr">
<td id="S3.T4.1.4.1" class="ltx_td ltx_align_left">PARAKQC</td>
<td id="S3.T4.1.4.2" class="ltx_td ltx_align_center">3,953</td>
<td id="S3.T4.1.4.3" class="ltx_td ltx_align_center">132</td>
<td id="S3.T4.1.4.4" class="ltx_td ltx_align_center">263</td>
<td id="S3.T4.1.4.5" class="ltx_td ltx_nopad_r ltx_align_center">4,348</td>
</tr>
<tr id="S3.T4.1.5" class="ltx_tr">
<td id="S3.T4.1.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T4.1.5.1.1" class="ltx_text ltx_font_bold">Overall</span></td>
<td id="S3.T4.1.5.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T4.1.5.2.1" class="ltx_text ltx_font_bold">11,668</span></td>
<td id="S3.T4.1.5.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T4.1.5.3.1" class="ltx_text ltx_font_bold">519</span></td>
<td id="S3.T4.1.5.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T4.1.5.4.1" class="ltx_text ltx_font_bold">1,037</span></td>
<td id="S3.T4.1.5.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T4.1.5.5.1" class="ltx_text ltx_font_bold">13,224</span></td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Evaluation Metrics</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS2.p1.2">KLUE-STS에 대한 평가 메트릭은 1) 피어슨의 상관계수(Pearson’<math alttext="r" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.1.m1.1"><semantics id="S3.SS2.SSS2.p1.1.m1.1a"><mi id="S3.SS2.SSS2.p1.1.m1.1.1" xref="S3.SS2.SSS2.p1.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.1.m1.1b"><ci id="S3.SS2.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p1.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.1.m1.1c">r</annotation></semantics></math>), 2) F1 점수이다. Pearson의 <math alttext="r" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p1.2.m2.1"><semantics id="S3.SS2.SSS2.p1.2.m2.1a"><mi id="S3.SS2.SSS2.p1.2.m2.1.1" xref="S3.SS2.SSS2.p1.2.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p1.2.m2.1b"><ci id="S3.SS2.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p1.2.m2.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p1.2.m2.1c">r</annotation></semantics></math>는 STS-b <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite>에서 채택된 인간 라벨 문장 유사성 점수와 모델 예측 점수 사이의 선형 상관 관계를 측정한 것이다. 우리의 디브와 테스트 세트는 균형 잡힌 점수 분포를 가지므로 계수는 관계의 크기를 올바르게 제공한다. 이진화된 결과를 측정하기 위해 F1 점수가 채택된다(<span class="ltx_text ltx_font_italic" id="S3.SS2.SSS2.p1.2.1">paraphrased</span> /<span class="ltx_text ltx_font_italic" id="S3.SS2.SSS2.p1.2.2">not paraphrased</span>). 특히, F1은 <span class="ltx_text ltx_font_italic" id="S3.SS2.SSS2.p1.2.3">paraphrased</span> 클래스에 대한 결과를 보고합니다.</p>
</div>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Related Work</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS3.p1.1">문장 간 유사도 측정은 다양한 NLP 응용과 밀접한 관련이 있는 기본적인 자연어 이해 문제이다. 그 중요성 때문에 STS는 다양한 NLU 벤치마크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>, <a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite>에 포함되어 있다. 이 분야에서 연구를 용이하게 하기 위해 많은 공유 작업이 유지되었으며 주석이 달린 말뭉치가 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib2" title="">2</a>, <a class="ltx_ref" href="#bib.bib3" title="">3</a>, <a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite>로 출시되었다. 일반적으로 질문 쌍, 이미지 설명, 뉴스 헤드라인, 0(의미 중복 없음)에서 5(의미 동등성)까지의 실수 값으로 주석이 달린 여러 텍스트 도메인을 포함합니다.</p>
</div>
<div id="S3.SS2.SSS3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS3.p2.1">최근 <cite class="ltx_cite ltx_citemacro_citet">Ham et al. [<a class="ltx_ref" href="#bib.bib45" title="">45</a>]</cite>에서는 기계 번역 한국어 STS 벤치마크를 소개하고 있다. 이는 GLUE에서 <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite>를 번역한 것으로 총 8,600여 개의 문장 쌍을 포함하고 있다. 모든 예는 기계 번역에만 의존하며 평가(dev 및 test) 세트의 문장 쌍은 인간에 의해 추가로 사후 편집된다. 그러나 해당 레이블은 번역된 의미로 조정되지 않았다. 한국 화자들은 그들 사이의 유사성을 다르게 판단할 것이기 때문에 재표지 과정의 부족이 문제가 될 것이다.</p>
</div>
<div id="S3.SS2.SSS3.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS3.p3.1">유사도 레이블이 특정 임계값만큼 이진화되면 STS도 Microsoft Research Paraphrase Corpus (MRPC) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib32" title="">32</a>]</cite>, Quora Question Pairs (QQP) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>]</cite>, 또는 PAWS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib152" title="">152</a>]</cite> 및 PAWS-X <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib144" title="">144</a>]</cite>와 같은 패러프레이즈 탐지 작업으로 볼 수 있다. 따라서 본 논문에서는 이진 분류 성능을 보고함으로써 모델이 패러프레이즈 검출에서 얼마나 좋은 성능을 보이는지 알아본다.</p>
</div>
<div id="S3.SS2.SSS3.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS3.p4.1">패러프레이즈 검출에서, <cite class="ltx_cite ltx_citemacro_citet">Cho et al. [<a class="ltx_ref" href="#bib.bib18" title="">18</a>]</cite>는 스마트 홈에 대한 인간 생성 쿼리를 포함하는 벤치마크를 제시하며, 여기서 10개의 패러프레이즈 문장을 함께 그룹화하여 총 1,000개의 그룹을 구성한다. 규모의 세분성은 0에서 5까지이지만, 의미적 유사성은 화제(스마트 홈, 날씨 등), 화행(질문, 금지 등) 등의 속성만으로 판단되며, 이는 인간의 직접적인 유사성 판단이 부족하기 때문에 뉘앙스, 통사적 구조 등 다른 세부 사항은 고려하지 않는다. PAWS-X <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib144" title="">144</a>]</cite>는 한국어의 PAWS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib152" title="">152</a>]</cite>를 번역한 버전을 제공한다. KorSTS와 마찬가지로 열차 분할은 기계 번역되고 그 디브 및 테스트 분할은 인간 번역되며 해당 라벨은 인간 검사 없이 보존된다. 국립국어원(NIKL) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib98" title="">98</a>]</cite>와 같은 정부 지원 기관에서 제공하는 패러프레이즈 말뭉치도 있지만, 단순히 접근성이 제한된 인간 생성 및 기계 패러프레이즈 문장을 제공한다.</p>
</div>
</section>
<section id="S3.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.4 </span>Conclusion</h4>

<div id="S3.SS2.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS2.SSS4.p1.1">우리는 모든 사람이 자유롭게 접근할 수 있는 여러 도메인과 스타일을 다루는 최초의 인간 주석이 달린 한국 STS 벤치마크 KLUE-STS를 만듭니다. 유사도 점수 주석 과정은 한국어의 특징을 포착하기 위해 특별히 고안되었다. 다양한 영역의 표현을 포함하는 벤치마크는 벤치마크 역할을 넘어 추가 연구에 유용한 자원이 될 것으로 예상된다. 우리의 벤치마크는 SentenceBERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib115" title="">115</a>]</cite>와 같은 STS 리소스에 설정된 수많은 모델을 개발하는 데 도움이 됩니다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Natural Language Inference (NLI)</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.p1.1">자연어 추론(NLI)의 목표는 <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.1">hypothesis</span> 문장과 <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.2">premise</span> 문장 사이의 관계를 추론하기 위한 모델을 훈련시키는 것이다. <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.3">premise</span>이 주어지면 NLI 모델은 <span class="ltx_text ltx_font_italic" id="S3.SS3.p1.1.4">hypothesis</span>이 true(entailment), false(contradiction) 또는 미결정(neutral)인지 여부를 결정합니다. 이 태스크는 텍스트 수반(textual entailment, RTE) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib27" title="">27</a>]</cite>를 인식하는 것으로도 알려져 있다.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS3.p2.1">문장 간의 수반과 모순을 이해하는 것은 NLU의 기본이다. 또한 NLI 데이터셋은 GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>]</cite> 및 superGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib132" title="">132</a>]</cite>와 같은 다양한 NLU 벤치마크에 포함되어 있으며, 다른 NLU 태스크들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>, <a class="ltx_ref" href="#bib.bib107" title="">107</a>, <a class="ltx_ref" href="#bib.bib115" title="">115</a>]</cite>에 대한 학습 데이터로서 가치가 있다.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS3.p3.1">우리는 NLI 모델이 <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.1.1">premise</span> 및 <span class="ltx_text ltx_font_italic" id="S3.SS3.p3.1.2">hypothesis</span> 문장의 각 쌍을 읽고 관계가 수반, 모순 또는 중립인지 여부를 예측하는 분류 작업으로 NLI를 공식화한다. 모델 성능을 측정하기 위해 분류 정확도를 사용한다.</p>
</div>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1 </span>Dataset Construction</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.p1.1">SNLI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>]</cite>와 MNLI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite>와 유사한 수집 방법을 사용하여 KLUE-NLI를 구성한다. 먼저, 기존의 말뭉치로부터 전제 문장을 수집한다. 그런 다음 각 전제 문장에 대해 주석자 한 명에게 세 개의 관계 클래스 각각에 대해 하나씩 세 개의 새로운 가설 문장을 생성하도록 요청한다. 그런 다음 전제 및 가설 문장의 각 쌍에 대해 4명의 추가 주석자에게 검증을 위해 관계에 레이블을 지정하도록 요청한다. 주석자에 대한 세 가지 레이블을 설명하기 위해 <cite class="ltx_cite ltx_citemacro_citet">Williams et al. [<a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite>에서 제안한 기준을 따른다. 가설 생성과 쌍 검증을 위해 한국 크라우드소싱 플랫폼인 SelectStar, <span class="ltx_note ltx_role_footnote" id="footnote23"><sup class="ltx_note_mark">23</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">23</sup><span class="ltx_tag ltx_tag_note">23</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://selectstar.ai/" target="_blank" title="">https://selectstar.ai/</a></span></span></span>에서 직원을 모집한다.</p>
</div>
<section id="S3.SS3.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora for Premise Sentences</h5>

<div id="S3.SS3.SSS1.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px1.p1.1">우리는 WIKITREE, POLICY, WIKINEWS, WIKIPEDIA, NSMC 및 AIRBNB와 같은 6개의 말뭉치를 전제 문장 세트에 사용한다. 그들은 현대 한국어의 다양한 주제와 글쓰기 스타일을 다룬다. WIKITREE, POLICY 및 WIKINEWS는 뉴스 기사이고 WIKIPEDIA는 크라우드 소싱 백과사전이며 모두 공식 한국어로 작성된다. NSMC와 AIRBNB는 각각 영화와 여행 분야의 구어체 리뷰로 구성된다.</p>
</div>
<div id="S3.SS3.SSS1.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px1.p2.1">6개의 말뭉치에서 우리는 가설을 이끌어내는 10,000개의 전제를 추출합니다. 유효한 전제는 세 가지 조건을 만족해야 한다. 첫째, 전제는 명제, 수학적 공식과 목록을 제외하고 진리값을 부여할 수 있는 선언적 문장이다. 둘째, 전제에는 적어도 하나의 술어가 포함되어야 하며, 술어는 상태(예: be, believe, know), 활동(예: play, smile, walk), 성취(예: realize, reach, break), 성취(예: eat, build, paint)와 같은 다양한 유형이 될 수 있다. 셋째, 전제의 길이는 공백이 포함된 20자에서 90자 사이여야 한다.</p>
</div>
</section>
<section id="S3.SS3.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Protocol for Hypothesis Generation</h5>

<div id="S3.SS3.SSS1.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px2.p1.1">우리는 주석자에게 전제를 보여주고 각 레이블에 해당하는 세 가지 가설을 작성하도록 요청한다. 이를 통해 각 레이블에 대해 거의 동일한 수의 (전제, 가설) 쌍을 수집할 수 있습니다. 기준의 개요를 다음과 같이 유지합니다.</p>
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p class="ltx_p" id="S3.I2.i1.p1.1">ENTAILMENT: 가정이 참이면 가설은 반드시 참이다.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p class="ltx_p" id="S3.I2.i2.p1.1">CONTRADICTION: 가정이 참이면 가설은 반드시 거짓이다.</p>
</div>
</li>
<li id="S3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I2.i3.p1" class="ltx_para">
<p class="ltx_p" id="S3.I2.i3.p1.1">NEUTRAL: 전제가 참이면 가설이 참일 수도 있고 그렇지 않을 수도 있다.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS3.SSS1.Px2.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px2.p2.1">우리는 인간의 쓰기 기반 가설 생성에서 나오는 주석 아티팩트를 알고 있다. 문장 길이와 명시적 어휘 패턴은 특정 클래스와 매우 관련이 있다. 노동자는 전제에 명시되어 있지 않은 추가적인 구나 절을 도입하는 것만으로 중립적인 가설을 세울 수 있기 때문에, 모든 계층 중에서 중립적인 문장이 가장 길다. “no”, “never” 및 “nothing”와 같은 부정은 종종 클래스 CONTRADICTION <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib44" title="">44</a>, <a class="ltx_ref" href="#bib.bib108" title="">108</a>]</cite>와 동반된다.</p>
</div>
<div id="S3.SS3.SSS1.Px2.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px2.p3.1">이러한 아티팩트의 우려에도 불구하고, 우리는 그러한 쓰기 기반 주석 절차를 고수한다. 가설을 수집하기 위한 자동 파이프라인에 비해, 인간 작성은 더 높은 품질의 데이터를 산출하며 여전히 효과적인 프로토콜 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib131" title="">131</a>]</cite>이다. 우리는 주석자가 사소한 패턴을 주입하지 않도록 권장하는 방법에 중점을 둡니다. 특정 <span class="ltx_text ltx_font_italic" id="S3.SS3.SSS1.Px2.p3.1.1">Do</span>s 및 <span class="ltx_text ltx_font_italic" id="S3.SS3.SSS1.Px2.p3.1.2">Don’t</span>s를 사용하여 지침을 준비하고 작업자를 사전에 엄격하게 훈련합니다. 주석 아티팩트를 최소화하기 위해 주석자에게 클래스에 걸쳐 길이가 유사한 문장을 작성하고 특정 어휘 항목을 반복적으로 삽입하는 것을 자제하며 추론을 할 때 가능한 다양한 전략을 사용하도록 지시한다.</p>
</div>
<div id="S3.SS3.SSS1.Px2.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px2.p4.1">구체적으로, 사례와 함께 가설 생성에 대한 세부 지침을 제공한다. 우리는 주석이 1) 어휘 선택, 2) 구문 구조 및 3) 세계 지식의 측면에서 다양한 언어 현상을 나타내는 가설을 만들도록 권장한다. 사전 선택의 경우, 우리의 지침은 주석이 동의어/반어, 초명어/초명어 및 보조 입자를 사용할 것을 제안한다. 다양한 구문 구조를 도입하기 위해 단어 스크램블링, 음성 변경 및 원인 변경과 같은 여러 구문 변환 전략을 제공한다. 주제/객체 스와핑 또는 수동화와 같은 방법은 기존의 NLI 데이터 증강 전략 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib89" title="">89</a>, <a class="ltx_ref" href="#bib.bib42" title="">42</a>]</cite>에 의해 동기 부여된다. 또한 실제 세계에 기반을 둔 데이터 세트를 만들기 위해 시간, 수량 및 지리와 같은 세계 지식을 반영하는 표현을 사용하는 것을 권장합니다.</p>
</div>
<div id="S3.SS3.SSS1.Px2.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px2.p5.1">가이드라인에 몇 가지 세부 사항이 더 있습니다. 우리는 주석자에게 전제의 쓰기 스타일을 유지하여 스타일 측면에서 균형 잡힌 데이터 세트를 만들도록 지시한다. 또한 문법성이나 내용의 복잡성으로 인해 이해하기 어려운 문장을 건너뛰도록 지도한다. 혐오 발언이나 사회적 편견, 개인 식별 정보 등 윤리적 문제가 담긴 문장을 건너뛰고 보고하도록 지도하기도 한다. 보고된 모든 문장을 조사하고 데이터 세트에 문장을 포함할지 여부를 최종 결정한다.</p>
</div>
</section>
<section id="S3.SS3.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Protocol for Label Validation</h5>

<div id="S3.SS3.SSS1.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px3.p1.1">군중 작업자는 검증을 위해 결과적인 전제-가설 쌍의 관계에 주석을 달습니다. 생성된 각 쌍에 대해 4명의 크라우드 워커에게 (ENTAILMENT, CONTRADICTION, NEUTRAL) 중 단일 레이블을 공급하도록 요청한다. 이는 가설 문장을 작성한 주석자가 의도한 초기 레이블을 포함하여 쌍당 총 5개의 레이블을 산출한다. 검증된 각 문장 쌍에 대해 5표 중 3표 이상의 과반수를 나타내는 골드 레이블을 할당한다.</p>
</div>
</section>
<section id="S3.SS3.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Process</h5>

<div id="S3.SS3.SSS1.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px4.p1.1">가설 생성을 위해 가이드라인을 반복적으로 업데이트하고 작업자를 훈련시키는 파일럿 단계를 거칩니다. 파일럿에서 우리는 의미적으로 받아들일 수 없는 문장을 쓰거나 전제에 사용되지 않는 증명 대명사를 도입하는 것이 잠재적인 문제가 될 수 있음을 발견했다. 그들이 의도된 라벨을 변경할 수 있기 때문에, 우리는 근로자들에게 그러한 문장을 쓰는 것을 피하도록 요청한다. 주석 공정의 이 부분에 대한 작업자의 수는 11명이다.</p>
</div>
<div id="S3.SS3.SSS1.Px4.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px4.p2.1">그런 다음 모든 쌍에 대한 관계 레이블의 유효성을 검사합니다. 파일럿에서 2,604명의 지원자를 시작으로 파일럿 단계를 거친 다음 테스트를 통과한 684명을 선택하여 검증 단계에 참여한다. 138명의 근로자가 탈락하면서 최종 근로자 수는 546명이다.</p>
</div>
<div id="S3.SS3.SSS1.Px4.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px4.p3.1">유효성 검증 결과는 표 <a class="ltx_ref" href="#S3.T5" title="Table 5 ‣ Annotation Process ‣ 3.3.1 Dataset Construction ‣ 3.3 Natural Language Inference (NLI) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">5</span></a>에 요약되어 있다. 그들은 우리의 쓰기 프로토콜이 고품질 말뭉치를 만드는 데 효과적이라고 제안한다. KLUE-NLI에서 만장일치 금 라벨 예제의 비율은 SNLI 및 MNLI보다 18% 높다. 이러한 예제의 비율이 높을수록 생성된 가설 문장과 원래의 전제 문장 사이의 관계가 명확해진다. 개별 주석이 금 라벨과 저자의 라벨에 대한 동의도 SNLI 및 MNLI보다 높으며 거의 모든 쌍이 금 라벨을 받는다. 몇 개의 문장 쌍(0.53%)에만 금 레이블이 없으며 데이터 세트를 완성하기 전에 이를 제거한다.</p>
</div>
<figure id="S3.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 5:</span>Summary of validation statistics for KLUE-NLI compared to SNLI and MNLI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite>. 우리는 가설을 쓸 때 원래 주석자가 의도한 레이블을 "저자의 레이블"이라고 부른다. 주석자 5명 중 3명 사이의 합의는 "금색 레이블"이다.</figcaption>
<table id="S3.T5.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T5.1.2" class="ltx_tr">
<td id="S3.T5.1.2.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T5.1.2.1.1" class="ltx_text ltx_font_bold">Statistics</span></td>
<td id="S3.T5.1.2.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T5.1.2.2.1" class="ltx_text ltx_font_bold">SNLI</span></td>
<td id="S3.T5.1.2.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T5.1.2.3.1" class="ltx_text ltx_font_bold">MNLI</span></td>
<td id="S3.T5.1.2.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T5.1.2.4.1" class="ltx_text ltx_font_bold">KLUE-NLI</span></td>
</tr>
<tr id="S3.T5.1.3" class="ltx_tr">
<td id="S3.T5.1.3.1" class="ltx_td ltx_align_left ltx_border_t">Unanimous Gold Label</td>
<td id="S3.T5.1.3.2" class="ltx_td ltx_align_center ltx_border_t">58.30%</td>
<td id="S3.T5.1.3.3" class="ltx_td ltx_align_center ltx_border_t">58.20%</td>
<td id="S3.T5.1.3.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S3.T5.1.3.4.1" class="ltx_text ltx_font_bold">76.29%</span></td>
</tr>
<tr id="S3.T5.1.4" class="ltx_tr">
<td id="S3.T5.1.4.1" class="ltx_td ltx_align_left ltx_border_t">Individual Label = Gold Label</td>
<td id="S3.T5.1.4.2" class="ltx_td ltx_align_center ltx_border_t">89.00%</td>
<td id="S3.T5.1.4.3" class="ltx_td ltx_align_center ltx_border_t">88.70%</td>
<td id="S3.T5.1.4.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S3.T5.1.4.4.1" class="ltx_text ltx_font_bold">92.63%</span></td>
</tr>
<tr id="S3.T5.1.5" class="ltx_tr">
<td id="S3.T5.1.5.1" class="ltx_td ltx_align_left">Individual Label = Author’s Label</td>
<td id="S3.T5.1.5.2" class="ltx_td ltx_align_center">85.80%</td>
<td id="S3.T5.1.5.3" class="ltx_td ltx_align_center">85.20%</td>
<td id="S3.T5.1.5.4" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T5.1.5.4.1" class="ltx_text ltx_font_bold">90.92%</span></td>
</tr>
<tr id="S3.T5.1.6" class="ltx_tr">
<td id="S3.T5.1.6.1" class="ltx_td ltx_align_left ltx_border_t">Gold Label = Author’s Label</td>
<td id="S3.T5.1.6.2" class="ltx_td ltx_align_center ltx_border_t">91.20%</td>
<td id="S3.T5.1.6.3" class="ltx_td ltx_align_center ltx_border_t">92.60%</td>
<td id="S3.T5.1.6.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S3.T5.1.6.4.1" class="ltx_text ltx_font_bold">96.76%</span></td>
</tr>
<tr id="S3.T5.1.1" class="ltx_tr">
<td id="S3.T5.1.1.1" class="ltx_td ltx_align_left">Gold Label <math id="S3.T5.1.1.1.m1.1" class="ltx_Math" alttext="\neq" display="inline"><semantics id="S3.T5.1.1.1.m1.1a"><mo id="S3.T5.1.1.1.m1.1.1" xref="S3.T5.1.1.1.m1.1.1.cmml">≠</mo><annotation-xml encoding="MathML-Content" id="S3.T5.1.1.1.m1.1b"><neq id="S3.T5.1.1.1.m1.1.1.cmml" xref="S3.T5.1.1.1.m1.1.1"></neq></annotation-xml><annotation encoding="application/x-tex" id="S3.T5.1.1.1.m1.1c">\neq</annotation></semantics></math> Author’s Label</td>
<td id="S3.T5.1.1.2" class="ltx_td ltx_align_center">6.80%</td>
<td id="S3.T5.1.1.3" class="ltx_td ltx_align_center">5.60%</td>
<td id="S3.T5.1.1.4" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T5.1.1.4.1" class="ltx_text ltx_font_bold">2.71%</span></td>
</tr>
<tr id="S3.T5.1.7" class="ltx_tr">
<td id="S3.T5.1.7.1" class="ltx_td ltx_align_left ltx_border_bb">No Gold Label (No 3 Labels Match)</td>
<td id="S3.T5.1.7.2" class="ltx_td ltx_align_center ltx_border_bb">2.00%</td>
<td id="S3.T5.1.7.3" class="ltx_td ltx_align_center ltx_border_bb">1.80%</td>
<td id="S3.T5.1.7.4" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S3.T5.1.7.4.1" class="ltx_text ltx_font_bold">0.53%</span></td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS3.SSS1.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS3.SSS1.Px5.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px5.p1.1">최종 데이터 세트는 30,998개의 문장 쌍으로 구성되며, 열차/개발/테스트 세트로 나뉜다. Table <a class="ltx_ref" href="#S3.T6" title="Table 6 ‣ Final Dataset ‣ 3.3.1 Dataset Construction ‣ 3.3 Natural Language Inference (NLI) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">6</span></a>는 데이터셋의 기초 통계량을 보여준다. SNLI 및 MNLI에서 관찰된 바와 같이, 우리의 전제 문장도 대응하는 가설 문장보다 긴 경향이 있다. 근로자는 일반적으로 가설 작성을 위해 전제의 부분 정보를 사용하기 때문이다.</p>
</div>
<div id="S3.SS3.SSS1.Px5.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px5.p2.1">우리는 1) 균형 잡힌 소스 스타일을 포함하고 2) 주석 아티팩트를 활용하는 모델을 비활성화시키는 방식으로 개발 및 테스트 세트를 의도적으로 형성한다는 점에 유의한다. 개발과 테스트 세트는 각각 3,000개의 문장 쌍을 포함합니다.</p>
</div>
<figure id="S3.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 6:</span>KLUE-NLI에 대한 통계. 처음 세 개의 열은 기차, 디브, 테스트 세트에서 문장 쌍의 수를 제공한다. <span class="ltx_text ltx_font_italic" id="S3.T6.3.1">Avg Len Prem</span> 및 <span class="ltx_text ltx_font_italic" id="S3.T6.4.2">Avg Len Hyp</span>은 각각 전제 문장 및 가설 문장의 평균 문자 수이다.</figcaption>
<table id="S3.T6.5" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T6.5.1" class="ltx_tr">
<td id="S3.T6.5.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T6.5.1.1.1" class="ltx_text ltx_font_bold">Source</span></td>
<td id="S3.T6.5.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T6.5.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T6.5.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T6.5.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T6.5.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T6.5.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T6.5.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T6.5.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T6.5.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T6.5.1.6.1" class="ltx_text ltx_font_bold">Avg Len Prem</span></td>
<td id="S3.T6.5.1.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T6.5.1.7.1" class="ltx_text ltx_font_bold">Avg Len Hyp</span></td>
</tr>
<tr id="S3.T6.5.2" class="ltx_tr">
<td id="S3.T6.5.2.1" class="ltx_td ltx_align_left ltx_border_t">WIKITREE</td>
<td id="S3.T6.5.2.2" class="ltx_td ltx_align_center ltx_border_t">3,838</td>
<td id="S3.T6.5.2.3" class="ltx_td ltx_align_center ltx_border_t">450</td>
<td id="S3.T6.5.2.4" class="ltx_td ltx_align_center ltx_border_t">450</td>
<td id="S3.T6.5.2.5" class="ltx_td ltx_align_center ltx_border_t">4,738</td>
<td id="S3.T6.5.2.6" class="ltx_td ltx_align_center ltx_border_t">52.81</td>
<td id="S3.T6.5.2.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">26.86</td>
</tr>
<tr id="S3.T6.5.3" class="ltx_tr">
<td id="S3.T6.5.3.1" class="ltx_td ltx_align_left">POLICY</td>
<td id="S3.T6.5.3.2" class="ltx_td ltx_align_center">3,833</td>
<td id="S3.T6.5.3.3" class="ltx_td ltx_align_center">450</td>
<td id="S3.T6.5.3.4" class="ltx_td ltx_align_center">450</td>
<td id="S3.T6.5.3.5" class="ltx_td ltx_align_center">4,733</td>
<td id="S3.T6.5.3.6" class="ltx_td ltx_align_center">56.73</td>
<td id="S3.T6.5.3.7" class="ltx_td ltx_nopad_r ltx_align_center">32.93</td>
</tr>
<tr id="S3.T6.5.4" class="ltx_tr">
<td id="S3.T6.5.4.1" class="ltx_td ltx_align_left">WIKINEWS</td>
<td id="S3.T6.5.4.2" class="ltx_td ltx_align_center">3,824</td>
<td id="S3.T6.5.4.3" class="ltx_td ltx_align_center">450</td>
<td id="S3.T6.5.4.4" class="ltx_td ltx_align_center">450</td>
<td id="S3.T6.5.4.5" class="ltx_td ltx_align_center">4,724</td>
<td id="S3.T6.5.4.6" class="ltx_td ltx_align_center">64.17</td>
<td id="S3.T6.5.4.7" class="ltx_td ltx_nopad_r ltx_align_center">29.11</td>
</tr>
<tr id="S3.T6.5.5" class="ltx_tr">
<td id="S3.T6.5.5.1" class="ltx_td ltx_align_left">WIKIPEDIA</td>
<td id="S3.T6.5.5.2" class="ltx_td ltx_align_center">3,780</td>
<td id="S3.T6.5.5.3" class="ltx_td ltx_align_center">450</td>
<td id="S3.T6.5.5.4" class="ltx_td ltx_align_center">450</td>
<td id="S3.T6.5.5.5" class="ltx_td ltx_align_center">4,680</td>
<td id="S3.T6.5.5.6" class="ltx_td ltx_align_center">57.45</td>
<td id="S3.T6.5.5.7" class="ltx_td ltx_nopad_r ltx_align_center">23.70</td>
</tr>
<tr id="S3.T6.5.6" class="ltx_tr">
<td id="S3.T6.5.6.1" class="ltx_td ltx_align_left ltx_border_t">NSMC</td>
<td id="S3.T6.5.6.2" class="ltx_td ltx_align_center ltx_border_t">4,899</td>
<td id="S3.T6.5.6.3" class="ltx_td ltx_align_center ltx_border_t">600</td>
<td id="S3.T6.5.6.4" class="ltx_td ltx_align_center ltx_border_t">600</td>
<td id="S3.T6.5.6.5" class="ltx_td ltx_align_center ltx_border_t">6,099</td>
<td id="S3.T6.5.6.6" class="ltx_td ltx_align_center ltx_border_t">27.48</td>
<td id="S3.T6.5.6.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">21.49</td>
</tr>
<tr id="S3.T6.5.7" class="ltx_tr">
<td id="S3.T6.5.7.1" class="ltx_td ltx_align_left">AIRBNB</td>
<td id="S3.T6.5.7.2" class="ltx_td ltx_align_center">4,824</td>
<td id="S3.T6.5.7.3" class="ltx_td ltx_align_center">600</td>
<td id="S3.T6.5.7.4" class="ltx_td ltx_align_center">600</td>
<td id="S3.T6.5.7.5" class="ltx_td ltx_align_center">6,024</td>
<td id="S3.T6.5.7.6" class="ltx_td ltx_align_center">24.28</td>
<td id="S3.T6.5.7.7" class="ltx_td ltx_nopad_r ltx_align_center">18.65</td>
</tr>
<tr id="S3.T6.5.8" class="ltx_tr">
<td id="S3.T6.5.8.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T6.5.8.1.1" class="ltx_text ltx_font_bold">Overall</span></td>
<td id="S3.T6.5.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T6.5.8.2.1" class="ltx_text ltx_font_bold">24,998</span></td>
<td id="S3.T6.5.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T6.5.8.3.1" class="ltx_text ltx_font_bold">3,000</span></td>
<td id="S3.T6.5.8.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T6.5.8.4.1" class="ltx_text ltx_font_bold">3,000</span></td>
<td id="S3.T6.5.8.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T6.5.8.5.1" class="ltx_text ltx_font_bold">30,998</span></td>
<td id="S3.T6.5.8.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T6.5.8.6.1" class="ltx_text ltx_font_bold">47.15</span></td>
<td id="S3.T6.5.8.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T6.5.8.7.1" class="ltx_text ltx_font_bold">25.46</span></td>
</tr>
</tbody></table>
</figure>
<div id="S3.SS3.SSS1.Px5.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px5.p3.1">개발과 테스트 세트에서 스타일의 일관성을 유지하기 위해 각 세트에 60%의 공식 문장과 40%의 구어체 문장을 포함한다. 우리는 공식 텍스트 WIKITREE, POLICY, WIKINEWS, WIKIPEDIA에서 각각 450개의 문장을 샘플링하고 구어체 텍스트 NSMC, AIRBNB에서 각각 600개의 문장을 샘플링한다.</p>
</div>
<div id="S3.SS3.SSS1.Px5.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px5.p4.1">우리의 NLI 벤치마크가 가설에서 거짓 신호를 사용하여 레이블을 예측하는 모델을 장려하는 것을 방지하기 위해 먼저 해당 레이블이 있는 가설 문장만을 사용하여 KLUE-RoBERTa 기반 모델을 미세 조정한다. 모델이 가설과 레이블 사이에 단서를 찾지 못하면 각 레이블에 대한 예측 확률 점수는 3-way로 분류될 때 균일해야 한다(즉, 1/3(<math alttext="\frac{1}{3}" class="ltx_Math" display="inline" id="S3.SS3.SSS1.Px5.p4.1.m1.1"><semantics id="S3.SS3.SSS1.Px5.p4.1.m1.1a"><mfrac id="S3.SS3.SSS1.Px5.p4.1.m1.1.1" xref="S3.SS3.SSS1.Px5.p4.1.m1.1.1.cmml"><mn id="S3.SS3.SSS1.Px5.p4.1.m1.1.1.2" xref="S3.SS3.SSS1.Px5.p4.1.m1.1.1.2.cmml">1</mn><mn id="S3.SS3.SSS1.Px5.p4.1.m1.1.1.3" xref="S3.SS3.SSS1.Px5.p4.1.m1.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px5.p4.1.m1.1b"><apply id="S3.SS3.SSS1.Px5.p4.1.m1.1.1.cmml" xref="S3.SS3.SSS1.Px5.p4.1.m1.1.1"><divide id="S3.SS3.SSS1.Px5.p4.1.m1.1.1.1.cmml" xref="S3.SS3.SSS1.Px5.p4.1.m1.1.1"></divide><cn id="S3.SS3.SSS1.Px5.p4.1.m1.1.1.2.cmml" type="integer" xref="S3.SS3.SSS1.Px5.p4.1.m1.1.1.2">1</cn><cn id="S3.SS3.SSS1.Px5.p4.1.m1.1.1.3.cmml" type="integer" xref="S3.SS3.SSS1.Px5.p4.1.m1.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px5.p4.1.m1.1c">\frac{1}{3}</annotation></semantics></math>). 이러한 점수 분포가 이상적이라고 가정하면 가설 전용 모델의 예측이 이상에 가장 가까운 개발/테스트 세트에 대한 쌍을 선호한다. 우리는 교차 엔트로피를 이용하여 예측과 이상 사이의 거리를 계산한다. 전제의 온전한 집합과 세 가지 가설을 보존하기 위해 각 집합의 평균 거리를 계산한다. 우리는 평균 거리가 가장 낮은 20%에 속하는 집합을 추출하고 무작위로 dev 집합과 test 집합으로 나눈다.</p>
</div>
<div id="S3.SS3.SSS1.Px5.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px5.p5.2">우리의 아이디어는 점적 상호 정보(PMI)의 확장으로 볼 수 있다. 각 가설 단어(<math alttext="w" class="ltx_Math" display="inline" id="S3.SS3.SSS1.Px5.p5.1.m1.1"><semantics id="S3.SS3.SSS1.Px5.p5.1.m1.1a"><mi id="S3.SS3.SSS1.Px5.p5.1.m1.1.1" xref="S3.SS3.SSS1.Px5.p5.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px5.p5.1.m1.1b"><ci id="S3.SS3.SSS1.Px5.p5.1.m1.1.1.cmml" xref="S3.SS3.SSS1.Px5.p5.1.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px5.p5.1.m1.1c">w</annotation></semantics></math>)와 클래스 라벨(<math alttext="c" class="ltx_Math" display="inline" id="S3.SS3.SSS1.Px5.p5.2.m2.1"><semantics id="S3.SS3.SSS1.Px5.p5.2.m2.1a"><mi id="S3.SS3.SSS1.Px5.p5.2.m2.1.1" xref="S3.SS3.SSS1.Px5.p5.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.Px5.p5.2.m2.1b"><ci id="S3.SS3.SSS1.Px5.p5.2.m2.1.1.cmml" xref="S3.SS3.SSS1.Px5.p5.2.m2.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.Px5.p5.2.m2.1c">c</annotation></semantics></math>) 사이의 PMI는 단어의 각 클래스 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib44" title="">44</a>, <a class="ltx_ref" href="#bib.bib131" title="">131</a>]</cite>와의 연관성을 발견하는데 사용되어 왔다. PMI가 문장 수준 연관성으로 확장되면 메트릭은 다음과 같이 가설 전용 모델 예측 확률과 유사한 척도를 제공한다.</p>
<table id="S3.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.Ex1.m1.13" class="ltx_Math" alttext="\text{PMI}(w,c)=\log{\frac{P(w,c)}{P(w)P(c)}}=\log{\frac{P(c|w)P(w)}{P(w)P(c)}}=\log{\frac{P(c|w)}{P(c)}}\propto P(c|w)" display="block"><semantics id="S3.Ex1.m1.13a"><mrow id="S3.Ex1.m1.13.13" xref="S3.Ex1.m1.13.13.cmml"><mrow id="S3.Ex1.m1.13.13.3" xref="S3.Ex1.m1.13.13.3.cmml"><mtext id="S3.Ex1.m1.13.13.3.2" xref="S3.Ex1.m1.13.13.3.2a.cmml">PMI</mtext><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.13.13.3.1" xref="S3.Ex1.m1.13.13.3.1.cmml">​</mo><mrow id="S3.Ex1.m1.13.13.3.3.2" xref="S3.Ex1.m1.13.13.3.3.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.13.13.3.3.2.1" xref="S3.Ex1.m1.13.13.3.3.1.cmml">(</mo><mi id="S3.Ex1.m1.11.11" xref="S3.Ex1.m1.11.11.cmml">w</mi><mo id="S3.Ex1.m1.13.13.3.3.2.2" xref="S3.Ex1.m1.13.13.3.3.1.cmml">,</mo><mi id="S3.Ex1.m1.12.12" xref="S3.Ex1.m1.12.12.cmml">c</mi><mo stretchy="false" id="S3.Ex1.m1.13.13.3.3.2.3" xref="S3.Ex1.m1.13.13.3.3.1.cmml">)</mo></mrow></mrow><mo id="S3.Ex1.m1.13.13.4" xref="S3.Ex1.m1.13.13.4.cmml">=</mo><mrow id="S3.Ex1.m1.13.13.5" xref="S3.Ex1.m1.13.13.5.cmml"><mi id="S3.Ex1.m1.13.13.5.1" xref="S3.Ex1.m1.13.13.5.1.cmml">log</mi><mo lspace="0.167em" id="S3.Ex1.m1.13.13.5a" xref="S3.Ex1.m1.13.13.5.cmml">⁡</mo><mfrac id="S3.Ex1.m1.4.4" xref="S3.Ex1.m1.4.4.cmml"><mrow id="S3.Ex1.m1.2.2.2" xref="S3.Ex1.m1.2.2.2.cmml"><mi id="S3.Ex1.m1.2.2.2.4" xref="S3.Ex1.m1.2.2.2.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.2.2.2.3" xref="S3.Ex1.m1.2.2.2.3.cmml">​</mo><mrow id="S3.Ex1.m1.2.2.2.5.2" xref="S3.Ex1.m1.2.2.2.5.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.2.2.2.5.2.1" xref="S3.Ex1.m1.2.2.2.5.1.cmml">(</mo><mi id="S3.Ex1.m1.1.1.1.1" xref="S3.Ex1.m1.1.1.1.1.cmml">w</mi><mo id="S3.Ex1.m1.2.2.2.5.2.2" xref="S3.Ex1.m1.2.2.2.5.1.cmml">,</mo><mi id="S3.Ex1.m1.2.2.2.2" xref="S3.Ex1.m1.2.2.2.2.cmml">c</mi><mo stretchy="false" id="S3.Ex1.m1.2.2.2.5.2.3" xref="S3.Ex1.m1.2.2.2.5.1.cmml">)</mo></mrow></mrow><mrow id="S3.Ex1.m1.4.4.4" xref="S3.Ex1.m1.4.4.4.cmml"><mi id="S3.Ex1.m1.4.4.4.4" xref="S3.Ex1.m1.4.4.4.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.4.4.4.3" xref="S3.Ex1.m1.4.4.4.3.cmml">​</mo><mrow id="S3.Ex1.m1.4.4.4.5.2" xref="S3.Ex1.m1.4.4.4.cmml"><mo stretchy="false" id="S3.Ex1.m1.4.4.4.5.2.1" xref="S3.Ex1.m1.4.4.4.cmml">(</mo><mi id="S3.Ex1.m1.3.3.3.1" xref="S3.Ex1.m1.3.3.3.1.cmml">w</mi><mo stretchy="false" id="S3.Ex1.m1.4.4.4.5.2.2" xref="S3.Ex1.m1.4.4.4.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.4.4.4.3a" xref="S3.Ex1.m1.4.4.4.3.cmml">​</mo><mi id="S3.Ex1.m1.4.4.4.6" xref="S3.Ex1.m1.4.4.4.6.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.4.4.4.3b" xref="S3.Ex1.m1.4.4.4.3.cmml">​</mo><mrow id="S3.Ex1.m1.4.4.4.7.2" xref="S3.Ex1.m1.4.4.4.cmml"><mo stretchy="false" id="S3.Ex1.m1.4.4.4.7.2.1" xref="S3.Ex1.m1.4.4.4.cmml">(</mo><mi id="S3.Ex1.m1.4.4.4.2" xref="S3.Ex1.m1.4.4.4.2.cmml">c</mi><mo stretchy="false" id="S3.Ex1.m1.4.4.4.7.2.2" xref="S3.Ex1.m1.4.4.4.cmml">)</mo></mrow></mrow></mfrac></mrow><mo id="S3.Ex1.m1.13.13.6" xref="S3.Ex1.m1.13.13.6.cmml">=</mo><mrow id="S3.Ex1.m1.13.13.7" xref="S3.Ex1.m1.13.13.7.cmml"><mi id="S3.Ex1.m1.13.13.7.1" xref="S3.Ex1.m1.13.13.7.1.cmml">log</mi><mo lspace="0.167em" id="S3.Ex1.m1.13.13.7a" xref="S3.Ex1.m1.13.13.7.cmml">⁡</mo><mfrac id="S3.Ex1.m1.8.8" xref="S3.Ex1.m1.8.8.cmml"><mrow id="S3.Ex1.m1.6.6.2" xref="S3.Ex1.m1.6.6.2.cmml"><mi id="S3.Ex1.m1.6.6.2.4" xref="S3.Ex1.m1.6.6.2.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.6.6.2.3" xref="S3.Ex1.m1.6.6.2.3.cmml">​</mo><mrow id="S3.Ex1.m1.6.6.2.2.1" xref="S3.Ex1.m1.6.6.2.2.1.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.6.6.2.2.1.2" xref="S3.Ex1.m1.6.6.2.2.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.6.6.2.2.1.1" xref="S3.Ex1.m1.6.6.2.2.1.1.cmml"><mi id="S3.Ex1.m1.6.6.2.2.1.1.2" xref="S3.Ex1.m1.6.6.2.2.1.1.2.cmml">c</mi><mo fence="false" id="S3.Ex1.m1.6.6.2.2.1.1.1" xref="S3.Ex1.m1.6.6.2.2.1.1.1.cmml">|</mo><mi id="S3.Ex1.m1.6.6.2.2.1.1.3" xref="S3.Ex1.m1.6.6.2.2.1.1.3.cmml">w</mi></mrow><mo stretchy="false" id="S3.Ex1.m1.6.6.2.2.1.3" xref="S3.Ex1.m1.6.6.2.2.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.6.6.2.3a" xref="S3.Ex1.m1.6.6.2.3.cmml">​</mo><mi id="S3.Ex1.m1.6.6.2.5" xref="S3.Ex1.m1.6.6.2.5.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.6.6.2.3b" xref="S3.Ex1.m1.6.6.2.3.cmml">​</mo><mrow id="S3.Ex1.m1.6.6.2.6.2" xref="S3.Ex1.m1.6.6.2.cmml"><mo stretchy="false" id="S3.Ex1.m1.6.6.2.6.2.1" xref="S3.Ex1.m1.6.6.2.cmml">(</mo><mi id="S3.Ex1.m1.5.5.1.1" xref="S3.Ex1.m1.5.5.1.1.cmml">w</mi><mo stretchy="false" id="S3.Ex1.m1.6.6.2.6.2.2" xref="S3.Ex1.m1.6.6.2.cmml">)</mo></mrow></mrow><mrow id="S3.Ex1.m1.8.8.4" xref="S3.Ex1.m1.8.8.4.cmml"><mi id="S3.Ex1.m1.8.8.4.4" xref="S3.Ex1.m1.8.8.4.4.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.8.8.4.3" xref="S3.Ex1.m1.8.8.4.3.cmml">​</mo><mrow id="S3.Ex1.m1.8.8.4.5.2" xref="S3.Ex1.m1.8.8.4.cmml"><mo stretchy="false" id="S3.Ex1.m1.8.8.4.5.2.1" xref="S3.Ex1.m1.8.8.4.cmml">(</mo><mi id="S3.Ex1.m1.7.7.3.1" xref="S3.Ex1.m1.7.7.3.1.cmml">w</mi><mo stretchy="false" id="S3.Ex1.m1.8.8.4.5.2.2" xref="S3.Ex1.m1.8.8.4.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.8.8.4.3a" xref="S3.Ex1.m1.8.8.4.3.cmml">​</mo><mi id="S3.Ex1.m1.8.8.4.6" xref="S3.Ex1.m1.8.8.4.6.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.8.8.4.3b" xref="S3.Ex1.m1.8.8.4.3.cmml">​</mo><mrow id="S3.Ex1.m1.8.8.4.7.2" xref="S3.Ex1.m1.8.8.4.cmml"><mo stretchy="false" id="S3.Ex1.m1.8.8.4.7.2.1" xref="S3.Ex1.m1.8.8.4.cmml">(</mo><mi id="S3.Ex1.m1.8.8.4.2" xref="S3.Ex1.m1.8.8.4.2.cmml">c</mi><mo stretchy="false" id="S3.Ex1.m1.8.8.4.7.2.2" xref="S3.Ex1.m1.8.8.4.cmml">)</mo></mrow></mrow></mfrac></mrow><mo id="S3.Ex1.m1.13.13.8" xref="S3.Ex1.m1.13.13.8.cmml">=</mo><mrow id="S3.Ex1.m1.13.13.9" xref="S3.Ex1.m1.13.13.9.cmml"><mi id="S3.Ex1.m1.13.13.9.1" xref="S3.Ex1.m1.13.13.9.1.cmml">log</mi><mo lspace="0.167em" id="S3.Ex1.m1.13.13.9a" xref="S3.Ex1.m1.13.13.9.cmml">⁡</mo><mfrac id="S3.Ex1.m1.10.10" xref="S3.Ex1.m1.10.10.cmml"><mrow id="S3.Ex1.m1.9.9.1" xref="S3.Ex1.m1.9.9.1.cmml"><mi id="S3.Ex1.m1.9.9.1.3" xref="S3.Ex1.m1.9.9.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.9.9.1.2" xref="S3.Ex1.m1.9.9.1.2.cmml">​</mo><mrow id="S3.Ex1.m1.9.9.1.1.1" xref="S3.Ex1.m1.9.9.1.1.1.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.9.9.1.1.1.2" xref="S3.Ex1.m1.9.9.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.9.9.1.1.1.1" xref="S3.Ex1.m1.9.9.1.1.1.1.cmml"><mi id="S3.Ex1.m1.9.9.1.1.1.1.2" xref="S3.Ex1.m1.9.9.1.1.1.1.2.cmml">c</mi><mo fence="false" id="S3.Ex1.m1.9.9.1.1.1.1.1" xref="S3.Ex1.m1.9.9.1.1.1.1.1.cmml">|</mo><mi id="S3.Ex1.m1.9.9.1.1.1.1.3" xref="S3.Ex1.m1.9.9.1.1.1.1.3.cmml">w</mi></mrow><mo stretchy="false" id="S3.Ex1.m1.9.9.1.1.1.3" xref="S3.Ex1.m1.9.9.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S3.Ex1.m1.10.10.2" xref="S3.Ex1.m1.10.10.2.cmml"><mi id="S3.Ex1.m1.10.10.2.3" xref="S3.Ex1.m1.10.10.2.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.10.10.2.2" xref="S3.Ex1.m1.10.10.2.2.cmml">​</mo><mrow id="S3.Ex1.m1.10.10.2.4.2" xref="S3.Ex1.m1.10.10.2.cmml"><mo stretchy="false" id="S3.Ex1.m1.10.10.2.4.2.1" xref="S3.Ex1.m1.10.10.2.cmml">(</mo><mi id="S3.Ex1.m1.10.10.2.1" xref="S3.Ex1.m1.10.10.2.1.cmml">c</mi><mo stretchy="false" id="S3.Ex1.m1.10.10.2.4.2.2" xref="S3.Ex1.m1.10.10.2.cmml">)</mo></mrow></mrow></mfrac></mrow><mo id="S3.Ex1.m1.13.13.10" xref="S3.Ex1.m1.13.13.10.cmml">∝</mo><mrow id="S3.Ex1.m1.13.13.1" xref="S3.Ex1.m1.13.13.1.cmml"><mi id="S3.Ex1.m1.13.13.1.3" xref="S3.Ex1.m1.13.13.1.3.cmml">P</mi><mo lspace="0em" rspace="0em" id="S3.Ex1.m1.13.13.1.2" xref="S3.Ex1.m1.13.13.1.2.cmml">​</mo><mrow id="S3.Ex1.m1.13.13.1.1.1" xref="S3.Ex1.m1.13.13.1.1.1.1.cmml"><mo stretchy="false" id="S3.Ex1.m1.13.13.1.1.1.2" xref="S3.Ex1.m1.13.13.1.1.1.1.cmml">(</mo><mrow id="S3.Ex1.m1.13.13.1.1.1.1" xref="S3.Ex1.m1.13.13.1.1.1.1.cmml"><mi id="S3.Ex1.m1.13.13.1.1.1.1.2" xref="S3.Ex1.m1.13.13.1.1.1.1.2.cmml">c</mi><mo fence="false" id="S3.Ex1.m1.13.13.1.1.1.1.1" xref="S3.Ex1.m1.13.13.1.1.1.1.1.cmml">|</mo><mi id="S3.Ex1.m1.13.13.1.1.1.1.3" xref="S3.Ex1.m1.13.13.1.1.1.1.3.cmml">w</mi></mrow><mo stretchy="false" id="S3.Ex1.m1.13.13.1.1.1.3" xref="S3.Ex1.m1.13.13.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.Ex1.m1.13b"><apply id="S3.Ex1.m1.13.13.cmml" xref="S3.Ex1.m1.13.13"><and id="S3.Ex1.m1.13.13a.cmml" xref="S3.Ex1.m1.13.13"></and><apply id="S3.Ex1.m1.13.13b.cmml" xref="S3.Ex1.m1.13.13"><eq id="S3.Ex1.m1.13.13.4.cmml" xref="S3.Ex1.m1.13.13.4"></eq><apply id="S3.Ex1.m1.13.13.3.cmml" xref="S3.Ex1.m1.13.13.3"><times id="S3.Ex1.m1.13.13.3.1.cmml" xref="S3.Ex1.m1.13.13.3.1"></times><ci id="S3.Ex1.m1.13.13.3.2a.cmml" xref="S3.Ex1.m1.13.13.3.2"><mtext id="S3.Ex1.m1.13.13.3.2.cmml" xref="S3.Ex1.m1.13.13.3.2">PMI</mtext></ci><interval closure="open" id="S3.Ex1.m1.13.13.3.3.1.cmml" xref="S3.Ex1.m1.13.13.3.3.2"><ci id="S3.Ex1.m1.11.11.cmml" xref="S3.Ex1.m1.11.11">𝑤</ci><ci id="S3.Ex1.m1.12.12.cmml" xref="S3.Ex1.m1.12.12">𝑐</ci></interval></apply><apply id="S3.Ex1.m1.13.13.5.cmml" xref="S3.Ex1.m1.13.13.5"><log id="S3.Ex1.m1.13.13.5.1.cmml" xref="S3.Ex1.m1.13.13.5.1"></log><apply id="S3.Ex1.m1.4.4.cmml" xref="S3.Ex1.m1.4.4"><divide id="S3.Ex1.m1.4.4.5.cmml" xref="S3.Ex1.m1.4.4"></divide><apply id="S3.Ex1.m1.2.2.2.cmml" xref="S3.Ex1.m1.2.2.2"><times id="S3.Ex1.m1.2.2.2.3.cmml" xref="S3.Ex1.m1.2.2.2.3"></times><ci id="S3.Ex1.m1.2.2.2.4.cmml" xref="S3.Ex1.m1.2.2.2.4">𝑃</ci><interval closure="open" id="S3.Ex1.m1.2.2.2.5.1.cmml" xref="S3.Ex1.m1.2.2.2.5.2"><ci id="S3.Ex1.m1.1.1.1.1.cmml" xref="S3.Ex1.m1.1.1.1.1">𝑤</ci><ci id="S3.Ex1.m1.2.2.2.2.cmml" xref="S3.Ex1.m1.2.2.2.2">𝑐</ci></interval></apply><apply id="S3.Ex1.m1.4.4.4.cmml" xref="S3.Ex1.m1.4.4.4"><times id="S3.Ex1.m1.4.4.4.3.cmml" xref="S3.Ex1.m1.4.4.4.3"></times><ci id="S3.Ex1.m1.4.4.4.4.cmml" xref="S3.Ex1.m1.4.4.4.4">𝑃</ci><ci id="S3.Ex1.m1.3.3.3.1.cmml" xref="S3.Ex1.m1.3.3.3.1">𝑤</ci><ci id="S3.Ex1.m1.4.4.4.6.cmml" xref="S3.Ex1.m1.4.4.4.6">𝑃</ci><ci id="S3.Ex1.m1.4.4.4.2.cmml" xref="S3.Ex1.m1.4.4.4.2">𝑐</ci></apply></apply></apply></apply><apply id="S3.Ex1.m1.13.13c.cmml" xref="S3.Ex1.m1.13.13"><eq id="S3.Ex1.m1.13.13.6.cmml" xref="S3.Ex1.m1.13.13.6"></eq><share href="#S3.Ex1.m1.13.13.5.cmml" id="S3.Ex1.m1.13.13d.cmml" xref="S3.Ex1.m1.13.13"></share><apply id="S3.Ex1.m1.13.13.7.cmml" xref="S3.Ex1.m1.13.13.7"><log id="S3.Ex1.m1.13.13.7.1.cmml" xref="S3.Ex1.m1.13.13.7.1"></log><apply id="S3.Ex1.m1.8.8.cmml" xref="S3.Ex1.m1.8.8"><divide id="S3.Ex1.m1.8.8.5.cmml" xref="S3.Ex1.m1.8.8"></divide><apply id="S3.Ex1.m1.6.6.2.cmml" xref="S3.Ex1.m1.6.6.2"><times id="S3.Ex1.m1.6.6.2.3.cmml" xref="S3.Ex1.m1.6.6.2.3"></times><ci id="S3.Ex1.m1.6.6.2.4.cmml" xref="S3.Ex1.m1.6.6.2.4">𝑃</ci><apply id="S3.Ex1.m1.6.6.2.2.1.1.cmml" xref="S3.Ex1.m1.6.6.2.2.1"><csymbol cd="latexml" id="S3.Ex1.m1.6.6.2.2.1.1.1.cmml" xref="S3.Ex1.m1.6.6.2.2.1.1.1">conditional</csymbol><ci id="S3.Ex1.m1.6.6.2.2.1.1.2.cmml" xref="S3.Ex1.m1.6.6.2.2.1.1.2">𝑐</ci><ci id="S3.Ex1.m1.6.6.2.2.1.1.3.cmml" xref="S3.Ex1.m1.6.6.2.2.1.1.3">𝑤</ci></apply><ci id="S3.Ex1.m1.6.6.2.5.cmml" xref="S3.Ex1.m1.6.6.2.5">𝑃</ci><ci id="S3.Ex1.m1.5.5.1.1.cmml" xref="S3.Ex1.m1.5.5.1.1">𝑤</ci></apply><apply id="S3.Ex1.m1.8.8.4.cmml" xref="S3.Ex1.m1.8.8.4"><times id="S3.Ex1.m1.8.8.4.3.cmml" xref="S3.Ex1.m1.8.8.4.3"></times><ci id="S3.Ex1.m1.8.8.4.4.cmml" xref="S3.Ex1.m1.8.8.4.4">𝑃</ci><ci id="S3.Ex1.m1.7.7.3.1.cmml" xref="S3.Ex1.m1.7.7.3.1">𝑤</ci><ci id="S3.Ex1.m1.8.8.4.6.cmml" xref="S3.Ex1.m1.8.8.4.6">𝑃</ci><ci id="S3.Ex1.m1.8.8.4.2.cmml" xref="S3.Ex1.m1.8.8.4.2">𝑐</ci></apply></apply></apply></apply><apply id="S3.Ex1.m1.13.13e.cmml" xref="S3.Ex1.m1.13.13"><eq id="S3.Ex1.m1.13.13.8.cmml" xref="S3.Ex1.m1.13.13.8"></eq><share href="#S3.Ex1.m1.13.13.7.cmml" id="S3.Ex1.m1.13.13f.cmml" xref="S3.Ex1.m1.13.13"></share><apply id="S3.Ex1.m1.13.13.9.cmml" xref="S3.Ex1.m1.13.13.9"><log id="S3.Ex1.m1.13.13.9.1.cmml" xref="S3.Ex1.m1.13.13.9.1"></log><apply id="S3.Ex1.m1.10.10.cmml" xref="S3.Ex1.m1.10.10"><divide id="S3.Ex1.m1.10.10.3.cmml" xref="S3.Ex1.m1.10.10"></divide><apply id="S3.Ex1.m1.9.9.1.cmml" xref="S3.Ex1.m1.9.9.1"><times id="S3.Ex1.m1.9.9.1.2.cmml" xref="S3.Ex1.m1.9.9.1.2"></times><ci id="S3.Ex1.m1.9.9.1.3.cmml" xref="S3.Ex1.m1.9.9.1.3">𝑃</ci><apply id="S3.Ex1.m1.9.9.1.1.1.1.cmml" xref="S3.Ex1.m1.9.9.1.1.1"><csymbol cd="latexml" id="S3.Ex1.m1.9.9.1.1.1.1.1.cmml" xref="S3.Ex1.m1.9.9.1.1.1.1.1">conditional</csymbol><ci id="S3.Ex1.m1.9.9.1.1.1.1.2.cmml" xref="S3.Ex1.m1.9.9.1.1.1.1.2">𝑐</ci><ci id="S3.Ex1.m1.9.9.1.1.1.1.3.cmml" xref="S3.Ex1.m1.9.9.1.1.1.1.3">𝑤</ci></apply></apply><apply id="S3.Ex1.m1.10.10.2.cmml" xref="S3.Ex1.m1.10.10.2"><times id="S3.Ex1.m1.10.10.2.2.cmml" xref="S3.Ex1.m1.10.10.2.2"></times><ci id="S3.Ex1.m1.10.10.2.3.cmml" xref="S3.Ex1.m1.10.10.2.3">𝑃</ci><ci id="S3.Ex1.m1.10.10.2.1.cmml" xref="S3.Ex1.m1.10.10.2.1">𝑐</ci></apply></apply></apply></apply><apply id="S3.Ex1.m1.13.13g.cmml" xref="S3.Ex1.m1.13.13"><csymbol cd="latexml" id="S3.Ex1.m1.13.13.10.cmml" xref="S3.Ex1.m1.13.13.10">proportional-to</csymbol><share href="#S3.Ex1.m1.13.13.9.cmml" id="S3.Ex1.m1.13.13h.cmml" xref="S3.Ex1.m1.13.13"></share><apply id="S3.Ex1.m1.13.13.1.cmml" xref="S3.Ex1.m1.13.13.1"><times id="S3.Ex1.m1.13.13.1.2.cmml" xref="S3.Ex1.m1.13.13.1.2"></times><ci id="S3.Ex1.m1.13.13.1.3.cmml" xref="S3.Ex1.m1.13.13.1.3">𝑃</ci><apply id="S3.Ex1.m1.13.13.1.1.1.1.cmml" xref="S3.Ex1.m1.13.13.1.1.1"><csymbol cd="latexml" id="S3.Ex1.m1.13.13.1.1.1.1.1.cmml" xref="S3.Ex1.m1.13.13.1.1.1.1.1">conditional</csymbol><ci id="S3.Ex1.m1.13.13.1.1.1.1.2.cmml" xref="S3.Ex1.m1.13.13.1.1.1.1.2">𝑐</ci><ci id="S3.Ex1.m1.13.13.1.1.1.1.3.cmml" xref="S3.Ex1.m1.13.13.1.1.1.1.3">𝑤</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.Ex1.m1.13c">\text{PMI}(w,c)=\log{\frac{P(w,c)}{P(w)P(c)}}=\log{\frac{P(c|w)P(w)}{P(w)P(c)}}=\log{\frac{P(c|w)}{P(c)}}\propto P(c|w)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S3.SS3.SSS1.Px5.p6" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px5.p6.1">인간 성능을 측정하고 XNLI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib25" title="">25</a>]</cite> 테스트 세트의 기계 번역인 KorNLI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib45" title="">45</a>]</cite> 테스트 세트에서 KLUE-NLI 테스트 세트가 개선되는지 여부를 조사하기 위해 인간 평가를 진행합니다. 한국어 언어학을 전공하고 KLUE-NLI 구축 과정에 참여하지 않은 한국인 원어민 학부생 4명을 채용한다. KLUE-NLI 테스트 세트에서 무작위로 100개의 문장 쌍을 샘플링하고 작업자에게 주석을 달도록 요청한다. 우리는 주어진 금 라벨과 주석의 일치를 확인합니다. KorNLI 테스트 세트의 하위 집합에 대해 동일한 작업을 수행하여 인간 유도 데이터 세트가 데이터 세트의 품질을 향상하는지 여부를 조사한다. 결과를 표<a class="ltx_ref" href="#S3.T7" title="Table 7 ‣ Final Dataset ‣ 3.3.1 Dataset Construction ‣ 3.3 Natural Language Inference (NLI) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">7</span></a>에 나타낸다.</p>
</div>
<div id="S3.SS3.SSS1.Px5.p7" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px5.p7.1">KorNLI의 경우 문장 쌍의 38%가 금 레이블과 일치하는 4개의 주석자 모두의 응답을 가지고 있다. 문장은 3개, 2개, 1개의 반응이 골드 라벨과 일치할 때 각각 18%, 18%, 16%이다. 10켤레가 골드 라벨과 일치하지 않습니다. 반면에 KLUE-NLI는 주어진 금 라벨과 훨씬 더 높은 일치를 보여준다. 모든 주석자는 쌍 중 71%에서 금 라벨에 동의하고 95%는 최소 3개의 동의를 얻는다. 또한 400개(64.50%)의 개별 주석 중 258개만 KorNLI의 금 라벨과 동일하다. 다시 말하지만, KLUE-NLI는 금 라벨과 더 나은 일치를 보여준다. 360개(91.00%)의 주석은 골드 라벨과 동일합니다.</p>
</div>
<div id="S3.SS3.SSS1.Px5.p8" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px5.p8.1">KLUE-NLI의 주석 품질에서 이러한 숫자는 SNLI 및 MLNI뿐만 아니라 KorNLI보다 우수하다. KorNLI에서 주석자는 문장의 의미적 관계를 구별하기 어렵기 때문에 두 문장 중 적어도 하나를 완전히 이해하지 못하거나 NEUTRAL을 선택한다고 보고하는 경우가 많다. 금 라벨의 분포가 균일하지만(각각 수반, 모순 및 중립 문장의 33, 33 및 34%) 주석자가 가장 자주 선택하는 라벨은 NEUTRAL(평균 56.75%)이다. 주석자의 다수결과 금 라벨이 다른 경우는 26%이다. 이러한 결과는 주석이 KorNLI 문장의 논리적 의미 관계를 파악하는 데 어려움을 겪고 있음을 시사한다.</p>
</div>
<figure id="S3.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 7:</span>KorNLI 및 KLUE-NLI의 인간 평가 결과에 대한 통계. 4개의 주석기의 레이블과 korNLI 및 KLUE-NLI 테스트 데이터의 골드 레이블을 비교한다.</figcaption>
<table id="S3.T7.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T7.1.2" class="ltx_tr">
<td id="S3.T7.1.2.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T7.1.2.1.1" class="ltx_text ltx_font_bold">Statistics</span></td>
<td id="S3.T7.1.2.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T7.1.2.2.1" class="ltx_text ltx_font_bold">KorNLI</span></td>
<td id="S3.T7.1.2.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T7.1.2.3.1" class="ltx_text ltx_font_bold">KLUE-NLI</span></td>
</tr>
<tr id="S3.T7.1.3" class="ltx_tr">
<td id="S3.T7.1.3.1" class="ltx_td ltx_align_left ltx_border_t">Unanimous Gold Label (4 Agree)</td>
<td id="S3.T7.1.3.2" class="ltx_td ltx_align_center ltx_border_t">38.00%</td>
<td id="S3.T7.1.3.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S3.T7.1.3.3.1" class="ltx_text ltx_font_bold">71.00%</span></td>
</tr>
<tr id="S3.T7.1.4" class="ltx_tr">
<td id="S3.T7.1.4.1" class="ltx_td ltx_align_left">3 Agree with Gold Label</td>
<td id="S3.T7.1.4.2" class="ltx_td ltx_align_center">18.00%</td>
<td id="S3.T7.1.4.3" class="ltx_td ltx_nopad_r ltx_align_center">24.00%</td>
</tr>
<tr id="S3.T7.1.5" class="ltx_tr">
<td id="S3.T7.1.5.1" class="ltx_td ltx_align_left">2 Agree with Gold Label</td>
<td id="S3.T7.1.5.2" class="ltx_td ltx_align_center">18.00%</td>
<td id="S3.T7.1.5.3" class="ltx_td ltx_nopad_r ltx_align_center">3.00%</td>
</tr>
<tr id="S3.T7.1.6" class="ltx_tr">
<td id="S3.T7.1.6.1" class="ltx_td ltx_align_left">1 Agrees with Gold Label</td>
<td id="S3.T7.1.6.2" class="ltx_td ltx_align_center">16.00%</td>
<td id="S3.T7.1.6.3" class="ltx_td ltx_nopad_r ltx_align_center">2.00%</td>
</tr>
<tr id="S3.T7.1.7" class="ltx_tr">
<td id="S3.T7.1.7.1" class="ltx_td ltx_align_left">0 Agrees with Gold Label</td>
<td id="S3.T7.1.7.2" class="ltx_td ltx_align_center">10.00%</td>
<td id="S3.T7.1.7.3" class="ltx_td ltx_nopad_r ltx_align_center">0.00%</td>
</tr>
<tr id="S3.T7.1.8" class="ltx_tr">
<td id="S3.T7.1.8.1" class="ltx_td ltx_align_left ltx_border_t">Individual Label = Gold Label</td>
<td id="S3.T7.1.8.2" class="ltx_td ltx_align_center ltx_border_t">64.50%</td>
<td id="S3.T7.1.8.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S3.T7.1.8.3.1" class="ltx_text ltx_font_bold">91.00%</span></td>
</tr>
<tr id="S3.T7.1.9" class="ltx_tr">
<td id="S3.T7.1.9.1" class="ltx_td ltx_align_left ltx_border_t">No Gold Label (No 3 Labels Match)</td>
<td id="S3.T7.1.9.2" class="ltx_td ltx_align_center ltx_border_t">4.00%</td>
<td id="S3.T7.1.9.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S3.T7.1.9.3.1" class="ltx_text ltx_font_bold">0.00%</span></td>
</tr>
<tr id="S3.T7.1.1" class="ltx_tr">
<td id="S3.T7.1.1.1" class="ltx_td ltx_align_left ltx_border_bb">Majority Vote <math id="S3.T7.1.1.1.m1.1" class="ltx_Math" alttext="\neq" display="inline"><semantics id="S3.T7.1.1.1.m1.1a"><mo id="S3.T7.1.1.1.m1.1.1" xref="S3.T7.1.1.1.m1.1.1.cmml">≠</mo><annotation-xml encoding="MathML-Content" id="S3.T7.1.1.1.m1.1b"><neq id="S3.T7.1.1.1.m1.1.1.cmml" xref="S3.T7.1.1.1.m1.1.1"></neq></annotation-xml><annotation encoding="application/x-tex" id="S3.T7.1.1.1.m1.1c">\neq</annotation></semantics></math> Gold Label</td>
<td id="S3.T7.1.1.2" class="ltx_td ltx_align_center ltx_border_bb">26.00%</td>
<td id="S3.T7.1.1.3" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb"><span id="S3.T7.1.1.3.1" class="ltx_text ltx_font_bold">0.00%</span></td>
</tr>
</tbody></table>
</figure>
<div id="S3.SS3.SSS1.Px5.p9" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS1.Px5.p9.1">반면 KLUE-NLI의 경우 4개의 응답 중 금 라벨과 일치하는 경우가 없다. 응답 중 2개 이상이 골드 라벨과 일치하는 경우를 고려하면 골드 라벨이 다수 태그로 재선정될 확률은 98%다. KorNLI와 비교하여 KLUE-NLI가 훨씬 더 신뢰할 수 있는 데이터 세트임을 알 수 있다. 이 결과는 또한 다수 태그로 대표되는 인간의 정확도가 98%라는 점을 감안할 때 현재 최상의 모델(정확도: 89.77%)의 헤드룸이 여전히 있음을 확인한다.</p>
</div>
</section>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2 </span>Evaluation Metric</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS2.p1.1">KLUE-NLI에 대한 평가 메트릭은 SNLI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>]</cite> 및 MNLI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite>에 이어 정확도이다. 정확도는 분류기가 결과를 정확하게 식별하는 정도를 측정합니다. 클래스 레이블은 거의 균등하게 분포되어 있으므로 더 높은 정확도로 모델의 성능을 올바르게 나타낼 수 있다.</p>
</div>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3 </span>Related Work</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS3.p1.1">Textual Entailment(RTE) 인식 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib27" title="">27</a>]</cite>는 NLI와 유사한 작업으로 일련의 Textual Entailment 과제에서 소개되었다. RTE 과제에서는 두 개의 문장이 주어지고, 모델은 한 문장의 의미가 다른 문장으로부터 수반될 수 있는지 여부를 결정한다. 이전 RTE 1-3에서 작업은 2진법, '시행' 및 '시행 없음'이다. REE 4-5에서는 새로운 클래스 'UNKNOWN'을 도입하고, 과제를 삼원 분류로 공식화한다.</p>
</div>
<div id="S3.SS3.SSS3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS3.p2.1">영어로 NLI를 위한 두 가지 주요 데이터셋은 Stanford Natural Language Inference (SNLI) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>]</cite>와 Multi-Genre Natural Language Inference (MNLI) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite>이다. SNLI와 MNLI의 가설 문장은 EnTAILMENT, CONTRADICTION 또는 NEUTRAL로 표시된다. SNLI는 Flickr30k <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib148" title="">148</a>]</cite>에서 570,152개의 이미지 캡션으로 만들어진 RTE 말뭉치보다 두 배 더 크다. MNLI 전제 문장은 더 넓은 범위의 스타일, 형식 정도 및 주제를 포함하는 10개의 다른 출처에서 파생된다.</p>
</div>
<div id="S3.SS3.SSS3.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS3.p3.1">기존의 NLI 데이터셋은 대부분 SNLI와 MNLI를 포함하여 영어로 되어 있으며, 다른 언어로 NLI 데이터셋을 구성하기 위한 하나의 일반적인 접근 방법은 기존의 영어 말뭉치를 관심 언어로 번역하는 것이다. <cite class="ltx_cite ltx_citemacro_citet">Conneau et al. [<a class="ltx_ref" href="#bib.bib25" title="">25</a>]</cite>는 MNLI의 개발 및 테스트 세트를 15개 언어로 번역하기 위해 전문 번역기를 사용하여 XNLI(교차 언어 자연어 추론)를 제공한다. 번역 기반 접근법의 주요 관심사 중 하나는 원래 문장 쌍의 관계가 프로세스에서 유지되는지 여부이다. <cite class="ltx_cite ltx_citemacro_citet">Conneau et al. [<a class="ltx_ref" href="#bib.bib25" title="">25</a>]</cite> find some translated pairs lose the initial semantic relationship, those validated by re-annotate the sample of the dataset. 결과는 MNLI에서 85%의 올바른 예와 XNLI에서 83%의 올바른 예를 감안할 때 인간 번역이 2%의 오주석을 유발한다는 것을 보여준다.</p>
</div>
<div id="S3.SS3.SSS3.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS3.p4.1">XNLI에 한국어가 포함되어 있지 않다는 점에 착안하여 KorNLI <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib45" title="">45</a>]</cite>를 소개한다. KorNLI<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib45" title="">45</a>]</cite>는 SNLI와 MNLI의 훈련 집합의 기계 번역을 통해 기차 집합이 만들어지는 기존의 영어 말뭉치를 번역한 것이며, XNLI의 개발 및 테스트 집합의 기계 번역과 전문 번역가의 사후 편집을 통해 개발 및 테스트 집합을 만든 것이다. <cite class="ltx_cite ltx_citemacro_citet">Ham et al. [<a class="ltx_ref" href="#bib.bib45" title="">45</a>]</cite>도 번역 후 수동으로 데이터를 조사하고 일부 잘못된 예제를 확인하지만 관찰을 정량화하고 이러한 오류를 분석하는 것을 향후 작업에 맡기기 위해 인간 검증 프로세스가 수행되지 않는다. 더욱이 사후 편집에도 통사적 구조나 단어 선택의 측면에서 부자연스러운 문장이 일부 존재한다.</p>
</div>
<div id="S3.SS3.SSS3.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS3.p5.1">SNLI와 MNLI를 기반으로 많은 연구가 제안되었지만 SNLI와 MNLI는 주석 아티팩트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib44" title="">44</a>, <a class="ltx_ref" href="#bib.bib108" title="">108</a>]</cite>를 갖는 것으로 알려져 있다. 주석 아티팩트는 크라우드소싱 과정에서 자연적으로 발생하는 특정 유형의 주석 전략과 휴리스틱의 산물이다. 이러한 인공물은 모델을 실제로 관계를 배우기보다는 휴리스틱을 채택하도록 유도할 수 있기 때문에 문제가 있다.</p>
</div>
<div id="S3.SS3.SSS3.p6" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS3.p6.1">NLI에서 주석 아티팩트를 줄이기 위한 몇 가지 노력이 있었다. <cite class="ltx_cite ltx_citemacro_citet">Vania et al. [<a class="ltx_ref" href="#bib.bib131" title="">131</a>]</cite> 전제-가설 쌍을 만들기 위한 두 가지 완전 자동화된 프로토콜을 사용하여 실험했지만, 이 방법은 품질이 좋지 않은 데이터와 주석 아티팩트에 대한 혼합 결과를 산출한다는 것을 발견했다. OCNLI<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib53" title="">53</a>]</cite>는 편견을 통제하기 위한 몇 가지 개입으로 쓰기 기반 프로토콜을 강화한다: 작가들이 다양한 추론 방법을 사용하도록 장려하고, 과도하게 사용된 단어에 제약을 가한다. 부정어 감소에 대한 부분적 영향에도 불구하고 명시적 제약은 다른 상관 단어를 생성하고 최종 OCNLI 데이터 세트는 대부분의 벤치마크 NLI 데이터 세트와 유사한 수준의 가설 전용 테스트 점수를 나타낸다.</p>
</div>
</section>
<section id="S3.SS3.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.4 </span>Conclusion</h4>

<div id="S3.SS3.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS4.p1.1">우리의 새로운 데이터 세트인 KLUE-NLI는 자연적으로 발생하는 한국어 문장을 기반으로 구성된 최초의 자원이다. KLUE-NLI는 한국어에 가장 자연스럽고 적합한 다양한 언어 현상, 글쓰기 스타일, 격식 정도 및 내용을 나타낸다. 데이터 세트의 전제 문장은 6개의 한국 말뭉치에서 나왔고, 가설 문장은 잘 훈련된 작업자가 작성했다.</p>
</div>
<div id="S3.SS3.SSS4.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS4.p2.1">작성 기반 프로토콜을 유지하고 세부 지침을 기반으로 작업자를 철저히 훈련함으로써 레이블의 신뢰도에서 기존 NLI 데이터 세트를 개선한다. KLUE-NLI는 MNLI와 번역 기반 한국어 데이터 세트인 KorNLI보다 훨씬 높은 주석자 간 일치율을 보여준다. KLUE-NLI와 KorNLI의 인간 성능 점수 사이의 격차는 또한 KLUE-NLI가 현재 최적의 한국 NLI 데이터 세트라는 증거를 제공한다.</p>
</div>
<div id="S3.SS3.SSS4.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS3.SSS4.p3.1">NLI 벤치마크 데이터세트로서의 주요 목적을 넘어 MNLI 및 SNLI와 같은 영어 데이터세트가 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib24" title="">24</a>, <a class="ltx_ref" href="#bib.bib107" title="">107</a>, <a class="ltx_ref" href="#bib.bib115" title="">115</a>]</cite>로 확장됨에 따라 KLUE-NLI가 향후 NLU 연구에 유용한 자원이 되기를 바란다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Named Entity Recognition (NER)</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p1.1">명명 개체 인식(NER)의 목표는 비정형 텍스트에서 명명 개체의 경계를 검출하고 유형을 분류하는 것이다. 기업은 사람, 위치, 조직, 시간 표현, 양, 금전적 가치를 지칭하는 일련의 단어일 수 있다.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p2.1">NER은 구문 분석, 목표 지향 대화 시스템, 질의 응답 챗봇 및 정보 추출과 같은 응용 분야에 중요하기 때문에 다양한 NLU 벤치마크에는 NER 데이터 세트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib137" title="">137</a>, <a class="ltx_ref" href="#bib.bib57" title="">57</a>, <a class="ltx_ref" href="#bib.bib78" title="">78</a>, <a class="ltx_ref" href="#bib.bib54" title="">54</a>]</cite>가 포함되어 있다. 다양한 도메인 및 스타일에서 NER 데이터 세트의 필요성이 대두되었음에도 불구하고, 이러한 요구를 충족시킬 수 있는 기존의 한국 NER 데이터 세트는 거의 없다. 따라서 본 논문에서는 실시간 응용 프로그램에 적용할 수 있는 웹 텍스트를 포함하는 말뭉치에 주석을 달았다.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS4.p3.1">KLUE-NER에서 모델은 스팬을 검출하고 입력 문장에 포함된 엔티티의 유형을 분류해야 한다. KLUE-NER에서 사용되는 6개의 엔터티 유형은 사람, 위치, 조직, 날짜, 시간, 수량이다. 캐릭터-레벨 BIO(Begin-Inside-Outside) 태깅 기법을 통해 태깅되고, 이에 따라 엔티티-레벨 및 캐릭터-레벨 F1 점수를 이용하여 모델의 성능을 평가한다.</p>
</div>
<section id="S3.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.1 </span>Dataset Construction</h4>

<section id="S3.SS4.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora</h5>

<div id="S3.SS4.SSS1.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS1.Px1.p1.1">공식 및 비공식 쓰기 스타일을 모두 통합하기 위해 주석에는 WIKITREE와 NSMC의 두 가지 말뭉치를 사용한다. 위키트리(WIKITREE)는 뉴스 기사 코퍼스로 엔터티 유형이 많은 정형 문장을 포함하고 있어 NER의 소스 코퍼스로 적합하다. NSMC는 영화나 TV 쇼에 대한 구어체 리뷰를 포함한다. NSMC의 텍스트는 사용자가 생성한 코멘트이기 때문에 에모지와 속어와 함께 오타와 정규화되지 않은 표현을 포함한다. 이러한 노이즈 데이터 세트는 NER 모델의 응용 분야를 넓히는 데 도움이 될 것이다.</p>
</div>
<div id="S3.SS4.SSS1.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS1.Px1.p2.1">두 말뭉치의 전처리는 각 말뭉치의 특성을 고려하여 다르게 수행된다. 위키트리(WIKITREE)의 경우 뉴스 기사는 주로 잘 쓰여진 문장으로 구성되어 있기 때문에 단순히 기사를 문장으로 나눈다. 대조적으로, NSMC의 웹 텍스트는 문장의 경계가 흐릿한 구어 스타일로 작성된다. 각 리뷰는 일반적으로 상당히 짧고 동일한 주제에 대해 구성된 문장이기 때문에 각 리뷰를 단일 입력 단위로 사용한다. 또한, 혐오 발언이나 사회적으로 편향된 용어가 포함된 문장은 수동으로 제거된다. 두 말뭉치 모두에 대해 400자 이상의 문장을 제거한다.</p>
</div>
<div id="S3.SS4.SSS1.Px1.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS1.Px1.p3.1">효율적인 주석을 위해 사전 학습된 모델을 사용하여 의사 레이블링을 수행한다. 이 모델은 주석을 위한 빠르고 정확한 개체 태깅을 지원하기 위해 공개적으로 사용 가능한 데이터 세트 KMOU-NER 코퍼스,<span class="ltx_note ltx_role_footnote" id="footnote24"><sup class="ltx_note_mark">24</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">24</sup><span class="ltx_tag ltx_tag_note">24</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/kmounlp/NER" target="_blank" title="">https://github.com/kmounlp/NER</a></span></span></span>을 사용하여 BERT-CRF로 훈련된다. 또한 유사 레이블이 없는 문장은 어떤 개체도 포함하지 않는다고 가정하고 필터링한다. 나머지 문장은 위키트리에서 약 80%, NSMC에서 41%를 차지하여 총 36,515개의 문장을 남긴다.</p>
</div>
</section>
<section id="S3.SS4.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Protocol</h5>

<div id="S3.SS4.SSS1.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS1.Px2.p1.1">KLUE-NER 주석에는 PS(Person), LC(Location), OG(Organization), DT(Date), TI(Time), QT(Quantity)의 6가지 엔터티 유형을 사용한다. 각 엔티티 타입에 대한 설명은 다음과 같다.</p>
</div>
<div id="S3.SS4.SSS1.Px2.p2" class="ltx_para">
<ul id="S3.I3" class="ltx_itemize">
<li id="S3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i1.p1" class="ltx_para">
<p class="ltx_p" id="S3.I3.i1.p1.1">PS(Person): 개인 또는 그룹의 이름</p>
</div>
</li>
<li id="S3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i2.p1" class="ltx_para">
<p class="ltx_p" id="S3.I3.i2.p1.1">LC(위치): 지역/도 또는 지리적 위치의 명칭</p>
</div>
</li>
<li id="S3.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i3.p1" class="ltx_para">
<p class="ltx_p" id="S3.I3.i3.p1.1">OG(Organization): 조직 또는 기업의 명칭</p>
</div>
</li>
<li id="S3.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i4.p1" class="ltx_para">
<p class="ltx_p" id="S3.I3.i4.p1.1">DT(Date): 날짜/기간/시대/연령에 관련된 표현</p>
</div>
</li>
<li id="S3.I3.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i5.p1" class="ltx_para">
<p class="ltx_p" id="S3.I3.i5.p1.1">TI(Time): 시간과 관련된 표현</p>
</div>
</li>
<li id="S3.I3.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I3.i6.p1" class="ltx_para">
<p class="ltx_p" id="S3.I3.i6.p1.1">QT(수량): 단위를 포함하는 수량 또는 숫자와 관련된 표현</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.SSS1.Px2.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS1.Px2.p3.1">본 논문에서는 한국통신기술협회(TTA) NER 가이드라인 <span class="ltx_note ltx_role_footnote" id="footnote25"><sup class="ltx_note_mark">25</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">25</sup><span class="ltx_tag ltx_tag_note">25</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://committee.tta.or.kr/data/standard_view.jsp?nowPage=2&amp;pk_num=TTAK.KO-10.0852&amp;commit_code=PG606" target="_blank" title="">https://committee.tta.or.kr/data/standard_view.jsp?nowPage=2&amp;pk_num=TTAK.KO-10.0852&amp;commit_code=PG606</a> </span></span></span>과 MUC-7 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib16" title="">16</a>]</cite>에 따라 위의 두 가지 태그 집합을 사용한다. TTA 가이드라인은 한국어를 위한 표준화된 NER 태깅 체계이며, 우리는 그 엔티티 유형들의 명칭과 정의를 따른다. TTA의 15개 엔터티 유형 중 MUC-7(DATE, LOCATION, MONEY, ORGANIZATION, PERCENT, PERSON 및 TIME)에서 사용되는 태그 집합과 일치하는 6개의 유형을 선택한다. TTA 집합에서 MONEY 및 PERCENT 유형이 QT(QUANTITY) 유형에 포함됨에 따라 대신 엔터티 유형 QT를 채택한다.</p>
</div>
<div id="S3.SS4.SSS1.Px2.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS1.Px2.p4.1">가능한 개체 유형이 여러 개인 개체의 경우 모든 사용 사례에 대해 고유한 태그를 할당하는 대신 컨텍스트를 기반으로 태그를 결정합니다. 한 가지 예는 <span class="ltx_text ltx_font_italic" id="S3.SS4.SSS1.Px2.p4.1.1">Cine21</span>이며, 이는 한국어로 잡지의 이름 또는 잡지의 게시자를 참조할 수 있다. “나는 서점에서 Cine21을 사서 페이지 단위로 읽었다”와 같은 문장에서 “서점에서 무언가를 사라”와 “페이지 단위로 읽는다”는 조직이 아니라 미디어(잡지)에 관한 속성이므로 OG 태그를 지정하지 않는다.</p>
</div>
<div id="S3.SS4.SSS1.Px2.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS1.Px2.p5.1">주석을 위한 텍스트가 특정 조건을 충족하지 않는 경우 크라우드 워커가 보고하도록 안내합니다. 예를 들어, 다수의 문장으로 이루어진 텍스트, 문장 형태가 아닌 텍스트, 단편, 명사의 단순 시퀀스 등은 폐기된다. 작업자는 또한 태깅 과정에서 혐오 발언과 다양한 편견을 포함하는 문장을 보고해야 한다.</p>
</div>
<div id="S3.SS4.SSS1.Px2.p6" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS1.Px2.p6.1">개인 식별 정보 측면에서, 우리는 NER의 바로 그 과제는 종종 사람 이름(PS)과 같은 고유 명사의 특정 정보를 필요로 하기 때문에 단순히 정보를 삭제하거나 가명화할 수 없다. 문장의 손실을 최소화하기 위해 주석 처리 후 문장을 통해 검사한다. PS 태그가 포함된 문장들을 조사하고, 한국어 검색 엔진에 등장하는 공인들의 이름이 포함된 문장들을 보관한다. <span class="ltx_note ltx_role_footnote" id="footnote26"><sup class="ltx_note_mark">26</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">26</sup><span class="ltx_tag ltx_tag_note">26</span>Daum: <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://search.daum.net/search?nil_suggest=btn&amp;nil_ch=&amp;rtupcoll=&amp;w=tot&amp;m=&amp;f=&amp;lpp=&amp;q=%C0%CE%B9%B0%B0%CB%BB%F6" target="_blank" title="">http://search.daum.net/search?nil_suggest=btn&amp;nil_ch=&amp;rtupcoll=&amp;w=tot&amp;m=&amp;f=&amp;lpp=&amp;q=%C0%CE%B9%B0%B0%CB%BB%F6</a> / Naver: <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://people.search.naver.com/" target="_blank" title="">https://people.search.naver.com/</a></span></span></span> 기타 문장은 잠재적인 개인 정보 보호 문제가 있는 경우 제거됩니다.</p>
</div>
</section>
<section id="S3.SS4.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Process</h5>

<div id="S3.SS4.SSS1.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS1.Px3.p1.1">한국 크라우드소싱 플랫폼 DeepNatural<span class="ltx_note ltx_role_footnote" id="footnote27"><sup class="ltx_note_mark">27</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">27</sup><span class="ltx_tag ltx_tag_note">27</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://deepnatural.ai/" target="_blank" title="">https://deepnatural.ai/</a></span></span></span>에서 모집한 51명의 자격을 갖춘 크라우드워커가 어노테이션 과정에 참여한다. 자격은 파일럿 개체 태깅 테스트를 통과할 때 부여됩니다. 그런 다음 두 언어학자는 크라우드 워커의 주석이 올바른지 여부를 확인합니다. 우리는 유효성 검사 후에도 일부 잘못된 주석이 남아 있음을 발견한다. 따라서 6명의 NLP 연구자가 주석 오류를 수동으로 수정한다.</p>
</div>
<div id="S3.SS4.SSS1.Px3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS1.Px3.p2.1">주석 작업 과정에서 작업자의 부적절함으로 인해 5,354개의 문장이 삭제된다. 프라이버시 문제로 118개의 문장이 탈락하고, 모든 주석이 거짓 긍정이기 때문에 연구진의 검사 후 35개의 문장이 제거된다. 검사 과정에서 총 5,507개의 문장이 탈락해 3만 1,008개의 문장이 나왔다.</p>
</div>
<figure id="S3.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8:</span>KLUE-NER에 대한 통계.</figcaption>
<table id="S3.T8.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T8.1.1" class="ltx_tr">
<td id="S3.T8.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T8.1.1.1.1" class="ltx_text ltx_font_bold">Source</span></td>
<td id="S3.T8.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T8.1.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T8.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T8.1.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T8.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T8.1.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T8.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T8.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T8.1.2" class="ltx_tr">
<td id="S3.T8.1.2.1" class="ltx_td ltx_align_left ltx_border_t">WIKITREE</td>
<td id="S3.T8.1.2.2" class="ltx_td ltx_align_center ltx_border_t">11,435</td>
<td id="S3.T8.1.2.3" class="ltx_td ltx_align_center ltx_border_t">2,534</td>
<td id="S3.T8.1.2.4" class="ltx_td ltx_align_center ltx_border_t">2,685</td>
<td id="S3.T8.1.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">16,664</td>
</tr>
<tr id="S3.T8.1.3" class="ltx_tr">
<td id="S3.T8.1.3.1" class="ltx_td ltx_align_left">NSMC</td>
<td id="S3.T8.1.3.2" class="ltx_td ltx_align_center">9,573</td>
<td id="S3.T8.1.3.3" class="ltx_td ltx_align_center">2,466</td>
<td id="S3.T8.1.3.4" class="ltx_td ltx_align_center">2,315</td>
<td id="S3.T8.1.3.5" class="ltx_td ltx_nopad_r ltx_align_center">14,354</td>
</tr>
<tr id="S3.T8.1.4" class="ltx_tr">
<td id="S3.T8.1.4.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T8.1.4.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T8.1.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T8.1.4.2.1" class="ltx_text ltx_font_bold">21,008</span></td>
<td id="S3.T8.1.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T8.1.4.3.1" class="ltx_text ltx_font_bold">5,000</span></td>
<td id="S3.T8.1.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T8.1.4.4.1" class="ltx_text ltx_font_bold">5,000</span></td>
<td id="S3.T8.1.4.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T8.1.4.5.1" class="ltx_text ltx_font_bold">31,008</span></td>
</tr>
</tbody></table>
</figure>
<figure id="S3.T9" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 9:</span>KLUE-NER에 대한 Entity-wise statistics. 괄호 안의 숫자는 유형의 수를 나타낸다. 이 테이블은 중복을 제거하지 않기 때문에 총 수는 Table<a class="ltx_ref" href="#S3.T8" title="Table 8 ‣ Annotation Process ‣ 3.4.1 Dataset Construction ‣ 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">8</span></a>와 일치하지 않는다.</figcaption>
<table id="S3.T9.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T9.1.1" class="ltx_tr">
<td id="S3.T9.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T9.1.1.1.1" class="ltx_text ltx_font_bold">Source</span></td>
<td id="S3.T9.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T9.1.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T9.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T9.1.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T9.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T9.1.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T9.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T9.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T9.1.2" class="ltx_tr">
<td id="S3.T9.1.2.1" class="ltx_td ltx_align_left ltx_border_t">PS</td>
<td id="S3.T9.1.2.2" class="ltx_td ltx_align_center ltx_border_t">14,453 (5,428)</td>
<td id="S3.T9.1.2.3" class="ltx_td ltx_align_center ltx_border_t">4,418 (2,706)</td>
<td id="S3.T9.1.2.4" class="ltx_td ltx_align_center ltx_border_t">4,830 (3,063)</td>
<td id="S3.T9.1.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">23,289 (7,124)</td>
</tr>
<tr id="S3.T9.1.3" class="ltx_tr">
<td id="S3.T9.1.3.1" class="ltx_td ltx_align_left">LC</td>
<td id="S3.T9.1.3.2" class="ltx_td ltx_align_center">6,663 (2,068)</td>
<td id="S3.T9.1.3.3" class="ltx_td ltx_align_center">1,649 (896)</td>
<td id="S3.T9.1.3.4" class="ltx_td ltx_align_center">2,064 (1,130)</td>
<td id="S3.T9.1.3.5" class="ltx_td ltx_nopad_r ltx_align_center">9,961 (2,650)</td>
</tr>
<tr id="S3.T9.1.4" class="ltx_tr">
<td id="S3.T9.1.4.1" class="ltx_td ltx_align_left">OG</td>
<td id="S3.T9.1.4.2" class="ltx_td ltx_align_center">8,491 (3,008)</td>
<td id="S3.T9.1.4.3" class="ltx_td ltx_align_center">2,182 (1,291)</td>
<td id="S3.T9.1.4.4" class="ltx_td ltx_align_center">2,514 (1,579)</td>
<td id="S3.T9.1.4.5" class="ltx_td ltx_nopad_r ltx_align_center">12,855 (3,796)</td>
</tr>
<tr id="S3.T9.1.5" class="ltx_tr">
<td id="S3.T9.1.5.1" class="ltx_td ltx_align_left">DT</td>
<td id="S3.T9.1.5.2" class="ltx_td ltx_align_center">8,029 (1,608)</td>
<td id="S3.T9.1.5.3" class="ltx_td ltx_align_center">2,312 (835)</td>
<td id="S3.T9.1.5.4" class="ltx_td ltx_align_center">2,498 (933)</td>
<td id="S3.T9.1.5.5" class="ltx_td ltx_nopad_r ltx_align_center">12,653 (2,060)</td>
</tr>
<tr id="S3.T9.1.6" class="ltx_tr">
<td id="S3.T9.1.6.1" class="ltx_td ltx_align_left">TI</td>
<td id="S3.T9.1.6.2" class="ltx_td ltx_align_center">2,020 (573)</td>
<td id="S3.T9.1.6.3" class="ltx_td ltx_align_center">5,45 (268)</td>
<td id="S3.T9.1.6.4" class="ltx_td ltx_align_center">579 (316)</td>
<td id="S3.T9.1.6.5" class="ltx_td ltx_nopad_r ltx_align_center">3,110 (730)</td>
</tr>
<tr id="S3.T9.1.7" class="ltx_tr">
<td id="S3.T9.1.7.1" class="ltx_td ltx_align_left">QT</td>
<td id="S3.T9.1.7.2" class="ltx_td ltx_align_center">11,717 (3,628)</td>
<td id="S3.T9.1.7.3" class="ltx_td ltx_align_center">3,151 (1,763)</td>
<td id="S3.T9.1.7.4" class="ltx_td ltx_align_center">3,827 (2,369)</td>
<td id="S3.T9.1.7.5" class="ltx_td ltx_nopad_r ltx_align_center">18,019 (4,776)</td>
</tr>
<tr id="S3.T9.1.8" class="ltx_tr">
<td id="S3.T9.1.8.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T9.1.8.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T9.1.8.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T9.1.8.2.1" class="ltx_text ltx_font_bold">51,373 (16,313)</span></td>
<td id="S3.T9.1.8.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T9.1.8.3.1" class="ltx_text ltx_font_bold">14,257 (7,759)</span></td>
<td id="S3.T9.1.8.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T9.1.8.4.1" class="ltx_text ltx_font_bold">16,312 (9,390)</span></td>
<td id="S3.T9.1.8.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T9.1.8.5.1" class="ltx_text ltx_font_bold">79,887 (21,136)</span></td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS4.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS4.SSS1.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS1.Px4.p1.1">결과 코퍼스는 각각 21,008, 5,000 및 5,000 문장으로 구성된 train/dev/test 세트로 분할된다(표 <a class="ltx_ref" href="#S3.T8" title="Table 8 ‣ Annotation Process ‣ 3.4.1 Dataset Construction ‣ 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">8</span></a>). 엔터티별 통계는 표 <a class="ltx_ref" href="#S3.T9" title="Table 9 ‣ Annotation Process ‣ 3.4.1 Dataset Construction ‣ 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">9</span></a>에 나와 있습니다. 도메인 전이 및 일반화 측면에서 모델의 견고성을 확인하기 위해 보이지 않는 개체를 포함하도록 테스트 세트를 설계한다.</p>
</div>
<div id="S3.SS4.SSS1.Px4.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS1.Px4.p2.1">최종화된 엔티티 타입들은 캐릭터 레벨 BIO 태깅 스킴(도<a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ Final Dataset ‣ 3.4.1 Dataset Construction ‣ 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a>)에서 태깅된다. 대부분의 영어 및 한국어 NER 데이터 세트에서 엔터티는 CoNLL 2003 데이터 세트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib129" title="">129</a>]</cite>에 이어 단어 수준 BIO 방식으로 태그 지정된다. 그러나 한국어에서는 두 가지 이유로 백이스페이스 기반의 단어 수준 태깅 기법을 고수하기 어렵다. 먼저, 공백-분할 단위(어절)는 종종 단일 단어가 아니며 콘텐츠 단어와 기능 단어의 합성이다(예를 들어, ‘담주가(다음 주는)’ = ‘담주(다음 주는)’ + ‘가(is)’ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib46" title="">46</a>]</cite>). 둘째, 한국어의 많은 합성어에는 공백이 포함되어 있다. 따라서, 우리는 문자 레벨에서 태그를 선택한다.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2105.09680/assets/figs/ner-bio.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="57" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3:</span>NER tagging을 위한 BIO scheme의 예시. 문장은 다음과 같이 번역된다. “<CNBlue:PS>는 최고♥!!!! 너무 슬픈 <다음주:DT>는 그들의 마지막 주 T.T. Nooooo!” 여기서 씨엔블루(<span class="ltx_text ltx_font_italic" id="S3.F3.4.1">CNBlue</span>)는 한국의 록밴드이다. 담주(<span class="ltx_text ltx_font_italic" id="S3.F3.5.2">the next week</span>)는 여기에 DT로 태깅되는 반면, 이 문장에서 기능 단어 가(<span class="ltx_text ltx_font_italic" id="S3.F3.6.3">is</span>)와 응집되고 문자 수준 BIO 방식으로 별도로 주석이 달린다.</figcaption>
</figure>
</section>
</section>
<section id="S3.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.2 </span>Evaluation Metrics</h4>

<div id="S3.SS4.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS2.p1.1">KLUE-NER에 대한 평가 메트릭은 1) 엔티티-레벨 매크로 F1(Entity F1) 및 2) 캐릭터-레벨 매크로 F1(Char F1) 스코어이다. 엔터티 F1 점수는 예측된 엔터티 및 유형이 엔터티 수준의 그라운드 트루스와 정확히 일치하는지 측정합니다. 진실이 [B-PS, I-PS, O, O, B-OG, I-OG]이고, 예측이 [B-PS, I-PS, I-PS, O, B-OG, I-OG]라고 가정하자. 개체 유형 PS의 경우 모델이 정확한 범위를 예측하지 못하기 때문에 F1 점수는 0인 반면 OG의 경우 모델이 점수를 얻는다. 높은 점수를 얻으려면 모델이 토큰화에 주의해야 합니다. Char F1 점수는 모델 예측과 그라운드 트루스 사이의 부분적 중첩을 측정하기 위해 새롭게 제공된다. 우리는 또한 모델이 한국어에서 줄기와 접사를 얼마나 잘 분해하는지 보기 위해 이 측정을 보고하며, 이는 NER의 모델 성능에 상당한 영향을 미친다. Char F1은 클래스별 F1 점수의 평균이다. KLUE-NER에서 클래스는 B-PS, I-PS, B-LC, I-LC, B-OG, I-OG, B-DT, I-DT, B-TI, I-TI, B-QT 및 I-QT이다. 우리는 긍정 실체에 초점을 맞추기 위해 다수의 부정 실체 클래스(O)를 제외한다.</p>
</div>
</section>
<section id="S3.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.3 </span>Related Work</h4>

<div id="S3.SS4.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS3.p1.1">CoNLL2003 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib129" title="">129</a>]</cite>는 로이터 뉴스와이어 기사의 텍스트를 다루는 가장 널리 사용되는 NER 벤치마크이다. 영어와 독일어를 처리하며 4개의 명명된 엔터티 유형(사람, 위치, 조직 및 기타 엔터티)으로 주석이 달려 있습니다. 월스트리트 저널의 뉴스 기사에 대한 또 다른 데이터 세트인 MUC(Message Understanding Conference) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib43" title="">43</a>]</cite>는 시간적 및 수치적 엔티티를 포함하는 확장된 태그 집합을 제시한다. 결과물인 MUC-6 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib43" title="">43</a>]</cite>와 MUC-7 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib16" title="">16</a>]</cite>는 각각 6개의 클래스와 7개의 클래스로 구성되어 Stanford NER 파서 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib40" title="">40</a>]</cite>를 개발하기 위한 훈련소스로 채택되었다.</p>
</div>
<div id="S3.SS4.SSS3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS3.p2.1">더 비공식적이고 덜 문장과 유사한 문서를 다루기 위해 WNUT16 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib127" title="">127</a>]</cite>가 제안된다. 그것은 TwitterNER <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib117" title="">117</a>]</cite>에서 처음 제안된 영어 트위터 텍스트를 다룬다. 총 15개의 유형의 엔티티가 라벨링되며, CoNLL03 및 MUC보다 더 세분화된다.</p>
</div>
<div id="S3.SS4.SSS3.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS3.p3.1">For Korean, there are four existing NER datasets which are published by Korea Maritime &amp; Ocean University (KMOU), Changwon University, National Institute of Korean Language (NIKL) and Electronics and Telecommunications Research Institute (ETRI). All of them follow the tagging schema of Telecommunications Technology Association (TTA).<span class="ltx_note ltx_role_footnote" id="footnote28"><sup class="ltx_note_mark">28</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">28</sup><span class="ltx_tag ltx_tag_note">28</span>KMOU utilizes a modified guideline KMOU-NLP-2018-001 based on the TTA scheme, which is available in <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/kmounlp/NER/blob/master/NER%20Guideline%20(ver%201.0).pdf" target="_blank" title="">https://github.com/kmounlp/NER/blob/master/NER%20Guideline%20(ver%201.0).pdf</a></span></span></span> TTA provides a standardized named entity tagging scheme that serves as an integrated guideline for NER research in Korean. It incorporates 15 named entity tags with 146 subcategories, and provides the definition and the examples regarding each tag with the instructions on the tagging procedure.</p>한국어의 경우, 한국해양대학교(KMOU), 창원대학교, 국립국어원(NIKL), 한국전자통신연구원(ETRI)에 의해 발표된 4개의 기존 NER 데이터 세트가 있다. 이들 모두는 TTA( Telecommunications Technology Association)의 태깅 스키마를 따른다. <span class="ltx_note ltx_role_footnote" id="footnote28"><sup class="ltx_note_mark">28</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">28</sup><span class="ltx_tag ltx_tag_note">28</span>KMOU utilizes a modified guideline KMOU-NLP-2018-001 based on the TTA scheme, which is available in <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/kmounlp/NER/blob/master/NER%20Guideline%20(ver%201.0).pdf" target="_blank" title="">https://github.com/kmounlp/NER/blob/master/NER%20Guideline%20(ver%201.0).pdf</a></span></span></span> TTA는 한국어 NER 연구의 통합 지침 역할을 하는 표준화된 명명된 개체 태깅 스킴을 제공한다. 146개의 하위 범주가 있는 15개의 명명된 개체 태그를 통합하고 태그 지정 절차에 대한 지침과 함께 각 태그에 대한 정의 및 예를 제공한다.</p>
</div>
<div id="S3.SS4.SSS3.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS3.p4.1">기존의 한국어 NER 데이터셋은 자유롭게 접근할 수 없고 다양한 텍스트 도메인을 다루고 있지 않다. <cite class="ltx_cite ltx_citemacro_citet">Cho et al. [<a class="ltx_ref" href="#bib.bib19" title="">19</a>]</cite>에 따르면 한국해양대학교(KMOU)에서 제공하는 NER 데이터셋과 창원대학교에서 구축한 데이터셋은 공개 접근이 가능하다. ETRI와 NIKL에서 제공하는 데이터 세트는 완전히 공개되지 않았으며 사용도 국내 연구자에 국한된다. 우리는 KLUE NER를 누구나 자유롭게 이용할 수 있도록 함으로써 이 문제를 극복한다. 앞서 언급한 데이터 세트 중 어느 것도 노이즈가 있는 사용자 생성 웹 텍스트로부터 문장을 다루지 않으며, 이는 더 강력하고 일반화할 수 있도록 모델에 훈련되는 데 도움이 된다. 또한 KMOU 데이터셋을 제외하고 위의 모든 데이터셋은 단어 레벨로 태깅되어 한국어의 형태적 특성과 상충되는 경우가 많다. 이에 비해 KLUE-NER은 웹 텍스트를 소스 말뭉치로 사용하고 개체들은 문자 단위로 주석을 달아서 보다 실용적이고 유용하다.</p>
</div>
</section>
<section id="S3.SS4.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.4.4 </span>Conclusion</h4>

<div id="S3.SS4.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS4.SSS4.p1.1">우리는 누구나 자유롭게 접근할 수 있는 광범위한 도메인과 스타일을 다루는 새로운 한국 NER 벤치마크를 구축한다. 개체 유형에는 주석이 달려 있어 모델이 형태적 단서와 맥락적 단서를 모두 사용해야 합니다. 문자 수준의 개체 태깅 및 평가 방법은 한국어 형태학의 특성을 반영한다. KLUE-NER 데이터 세트는 공식 뉴스 기사 및 비공식 사용자 생성 웹 텍스트를 모두 포함하므로, 본 벤치마크가 광범위한 도메인에서 사용할 수 있는 NER 모델을 개발하고 정보 추출을 위한 고급 모델을 개발하는 데 도움이 되기를 바란다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Relation Extraction (RE)</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS5.p1.2">관계 추출(Relation Extraction, RE)은 텍스트 내의 엔티티 쌍들 사이의 의미론적 관계들을 식별한다. 상기 관계는 <span class="ltx_text ltx_font_italic" id="S3.SS5.p1.2.1">subject entity</span> (<math alttext="e_{\text{subj}}" class="ltx_Math" display="inline" id="S3.SS5.p1.1.m1.1"><semantics id="S3.SS5.p1.1.m1.1a"><msub id="S3.SS5.p1.1.m1.1.1" xref="S3.SS5.p1.1.m1.1.1.cmml"><mi id="S3.SS5.p1.1.m1.1.1.2" xref="S3.SS5.p1.1.m1.1.1.2.cmml">e</mi><mtext id="S3.SS5.p1.1.m1.1.1.3" xref="S3.SS5.p1.1.m1.1.1.3a.cmml">subj</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.1.m1.1b"><apply id="S3.SS5.p1.1.m1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.1.m1.1.1.1.cmml" xref="S3.SS5.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS5.p1.1.m1.1.1.2.cmml" xref="S3.SS5.p1.1.m1.1.1.2">𝑒</ci><ci id="S3.SS5.p1.1.m1.1.1.3a.cmml" xref="S3.SS5.p1.1.m1.1.1.3"><mtext id="S3.SS5.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS5.p1.1.m1.1.1.3">subj</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.1.m1.1c">e_{\text{subj}}</annotation></semantics></math>)와 <span class="ltx_text ltx_font_italic" id="S3.SS5.p1.2.2">object entity</span> (<math alttext="e_{\text{obj}}" class="ltx_Math" display="inline" id="S3.SS5.p1.2.m2.1"><semantics id="S3.SS5.p1.2.m2.1a"><msub id="S3.SS5.p1.2.m2.1.1" xref="S3.SS5.p1.2.m2.1.1.cmml"><mi id="S3.SS5.p1.2.m2.1.1.2" xref="S3.SS5.p1.2.m2.1.1.2.cmml">e</mi><mtext id="S3.SS5.p1.2.m2.1.1.3" xref="S3.SS5.p1.2.m2.1.1.3a.cmml">obj</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p1.2.m2.1b"><apply id="S3.SS5.p1.2.m2.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS5.p1.2.m2.1.1.1.cmml" xref="S3.SS5.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS5.p1.2.m2.1.1.2.cmml" xref="S3.SS5.p1.2.m2.1.1.2">𝑒</ci><ci id="S3.SS5.p1.2.m2.1.1.3a.cmml" xref="S3.SS5.p1.2.m2.1.1.3"><mtext id="S3.SS5.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS5.p1.2.m2.1.1.3">obj</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p1.2.m2.1c">e_{\text{obj}}</annotation></semantics></math>)로 구성된 entity pair 사이에 정의된다. 예를 들어, 문장 '키에르케고르는 코펜하겐의 부유한 가정에서 태어났다'에서 주체는 '키에르케고르'이고 객체체는 '코펜하겐'이다. 그런 다음 목표는 이러한 두 엔터티 간의 적절한 관계를 선택하는 것입니다. '<span class="ltx_text ltx_font_italic" id="S3.SS5.p1.2.3">place_of_birth</span>'입니다.</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS5.p2.1">RE는 모델이 개체 간의 관계를 올바르게 이해하는지 평가하는 데 적합한 작업이다. KLUE-RE가 언어 이해의 이러한 측면을 포착하도록 하기 위해 대규모 RE 벤치마크를 포함한다. 한국어로 공개된 대규모 RE 벤치마크가 없기 때문에 자체 데이터셋을 수집하고 주석을 달았다.</p>
</div>
<div id="S3.SS5.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS5.p3.7">우리는 RE를 단일 문장 분류 과제로 공식화한다. 모델은 주어진 문장 내에서 두 개체 사이의 관계를 설명하는 미리 정의된 관계 클래스 중 하나를 선택한다. 즉, RE 모델은 문장 <math alttext="s" class="ltx_Math" display="inline" id="S3.SS5.p3.3.m3.1"><semantics id="S3.SS5.p3.3.m3.1a"><mi id="S3.SS5.p3.3.m3.1.1" xref="S3.SS5.p3.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.3.m3.1b"><ci id="S3.SS5.p3.3.m3.1.1.cmml" xref="S3.SS5.p3.3.m3.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.3.m3.1c">s</annotation></semantics></math>에서 엔터티 쌍 <math alttext="(e_{\text{subj}},e_{\text{obj}})" class="ltx_Math" display="inline" id="S3.SS5.p3.2.m2.2"><semantics id="S3.SS5.p3.2.m2.2a"><mrow id="S3.SS5.p3.2.m2.2.2.2" xref="S3.SS5.p3.2.m2.2.2.3.cmml"><mo id="S3.SS5.p3.2.m2.2.2.2.3" stretchy="false" xref="S3.SS5.p3.2.m2.2.2.3.cmml">(</mo><msub id="S3.SS5.p3.2.m2.1.1.1.1" xref="S3.SS5.p3.2.m2.1.1.1.1.cmml"><mi id="S3.SS5.p3.2.m2.1.1.1.1.2" xref="S3.SS5.p3.2.m2.1.1.1.1.2.cmml">e</mi><mtext id="S3.SS5.p3.2.m2.1.1.1.1.3" xref="S3.SS5.p3.2.m2.1.1.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.p3.2.m2.2.2.2.4" xref="S3.SS5.p3.2.m2.2.2.3.cmml">,</mo><msub id="S3.SS5.p3.2.m2.2.2.2.2" xref="S3.SS5.p3.2.m2.2.2.2.2.cmml"><mi id="S3.SS5.p3.2.m2.2.2.2.2.2" xref="S3.SS5.p3.2.m2.2.2.2.2.2.cmml">e</mi><mtext id="S3.SS5.p3.2.m2.2.2.2.2.3" xref="S3.SS5.p3.2.m2.2.2.2.2.3a.cmml">obj</mtext></msub><mo id="S3.SS5.p3.2.m2.2.2.2.5" stretchy="false" xref="S3.SS5.p3.2.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.2.m2.2b"><interval closure="open" id="S3.SS5.p3.2.m2.2.2.3.cmml" xref="S3.SS5.p3.2.m2.2.2.2"><apply id="S3.SS5.p3.2.m2.1.1.1.1.cmml" xref="S3.SS5.p3.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.p3.2.m2.1.1.1.1.1.cmml" xref="S3.SS5.p3.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS5.p3.2.m2.1.1.1.1.2.cmml" xref="S3.SS5.p3.2.m2.1.1.1.1.2">𝑒</ci><ci id="S3.SS5.p3.2.m2.1.1.1.1.3a.cmml" xref="S3.SS5.p3.2.m2.1.1.1.1.3"><mtext id="S3.SS5.p3.2.m2.1.1.1.1.3.cmml" mathsize="70%" xref="S3.SS5.p3.2.m2.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.SS5.p3.2.m2.2.2.2.2.cmml" xref="S3.SS5.p3.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.p3.2.m2.2.2.2.2.1.cmml" xref="S3.SS5.p3.2.m2.2.2.2.2">subscript</csymbol><ci id="S3.SS5.p3.2.m2.2.2.2.2.2.cmml" xref="S3.SS5.p3.2.m2.2.2.2.2.2">𝑒</ci><ci id="S3.SS5.p3.2.m2.2.2.2.2.3a.cmml" xref="S3.SS5.p3.2.m2.2.2.2.2.3"><mtext id="S3.SS5.p3.2.m2.2.2.2.2.3.cmml" mathsize="70%" xref="S3.SS5.p3.2.m2.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.2.m2.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math>의 적절한 관계 <math alttext="r" class="ltx_Math" display="inline" id="S3.SS5.p3.1.m1.1"><semantics id="S3.SS5.p3.1.m1.1a"><mi id="S3.SS5.p3.1.m1.1.1" xref="S3.SS5.p3.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.1.m1.1b"><ci id="S3.SS5.p3.1.m1.1.1.cmml" xref="S3.SS5.p3.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.1.m1.1c">r</annotation></semantics></math>를 예측하며, 여기서 <math alttext="e_{\text{subj}}" class="ltx_Math" display="inline" id="S3.SS5.p3.4.m4.1"><semantics id="S3.SS5.p3.4.m4.1a"><msub id="S3.SS5.p3.4.m4.1.1" xref="S3.SS5.p3.4.m4.1.1.cmml"><mi id="S3.SS5.p3.4.m4.1.1.2" xref="S3.SS5.p3.4.m4.1.1.2.cmml">e</mi><mtext id="S3.SS5.p3.4.m4.1.1.3" xref="S3.SS5.p3.4.m4.1.1.3a.cmml">subj</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.4.m4.1b"><apply id="S3.SS5.p3.4.m4.1.1.cmml" xref="S3.SS5.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS5.p3.4.m4.1.1.1.cmml" xref="S3.SS5.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS5.p3.4.m4.1.1.2.cmml" xref="S3.SS5.p3.4.m4.1.1.2">𝑒</ci><ci id="S3.SS5.p3.4.m4.1.1.3a.cmml" xref="S3.SS5.p3.4.m4.1.1.3"><mtext id="S3.SS5.p3.4.m4.1.1.3.cmml" mathsize="70%" xref="S3.SS5.p3.4.m4.1.1.3">subj</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.4.m4.1c">e_{\text{subj}}</annotation></semantics></math>는 주체 엔터티이고 <math alttext="e_{\text{obj}}" class="ltx_Math" display="inline" id="S3.SS5.p3.5.m5.1"><semantics id="S3.SS5.p3.5.m5.1a"><msub id="S3.SS5.p3.5.m5.1.1" xref="S3.SS5.p3.5.m5.1.1.cmml"><mi id="S3.SS5.p3.5.m5.1.1.2" xref="S3.SS5.p3.5.m5.1.1.2.cmml">e</mi><mtext id="S3.SS5.p3.5.m5.1.1.3" xref="S3.SS5.p3.5.m5.1.1.3a.cmml">obj</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.5.m5.1b"><apply id="S3.SS5.p3.5.m5.1.1.cmml" xref="S3.SS5.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS5.p3.5.m5.1.1.1.cmml" xref="S3.SS5.p3.5.m5.1.1">subscript</csymbol><ci id="S3.SS5.p3.5.m5.1.1.2.cmml" xref="S3.SS5.p3.5.m5.1.1.2">𝑒</ci><ci id="S3.SS5.p3.5.m5.1.1.3a.cmml" xref="S3.SS5.p3.5.m5.1.1.3"><mtext id="S3.SS5.p3.5.m5.1.1.3.cmml" mathsize="70%" xref="S3.SS5.p3.5.m5.1.1.3">obj</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.5.m5.1c">e_{\text{obj}}</annotation></semantics></math>는 객체 엔터티이다. <math alttext="(e_{\text{subj}},r,e_{\text{obj}})" class="ltx_Math" display="inline" id="S3.SS5.p3.6.m6.3"><semantics id="S3.SS5.p3.6.m6.3a"><mrow id="S3.SS5.p3.6.m6.3.3.2" xref="S3.SS5.p3.6.m6.3.3.3.cmml"><mo id="S3.SS5.p3.6.m6.3.3.2.3" stretchy="false" xref="S3.SS5.p3.6.m6.3.3.3.cmml">(</mo><msub id="S3.SS5.p3.6.m6.2.2.1.1" xref="S3.SS5.p3.6.m6.2.2.1.1.cmml"><mi id="S3.SS5.p3.6.m6.2.2.1.1.2" xref="S3.SS5.p3.6.m6.2.2.1.1.2.cmml">e</mi><mtext id="S3.SS5.p3.6.m6.2.2.1.1.3" xref="S3.SS5.p3.6.m6.2.2.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.p3.6.m6.3.3.2.4" xref="S3.SS5.p3.6.m6.3.3.3.cmml">,</mo><mi id="S3.SS5.p3.6.m6.1.1" xref="S3.SS5.p3.6.m6.1.1.cmml">r</mi><mo id="S3.SS5.p3.6.m6.3.3.2.5" xref="S3.SS5.p3.6.m6.3.3.3.cmml">,</mo><msub id="S3.SS5.p3.6.m6.3.3.2.2" xref="S3.SS5.p3.6.m6.3.3.2.2.cmml"><mi id="S3.SS5.p3.6.m6.3.3.2.2.2" xref="S3.SS5.p3.6.m6.3.3.2.2.2.cmml">e</mi><mtext id="S3.SS5.p3.6.m6.3.3.2.2.3" xref="S3.SS5.p3.6.m6.3.3.2.2.3a.cmml">obj</mtext></msub><mo id="S3.SS5.p3.6.m6.3.3.2.6" stretchy="false" xref="S3.SS5.p3.6.m6.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.6.m6.3b"><vector id="S3.SS5.p3.6.m6.3.3.3.cmml" xref="S3.SS5.p3.6.m6.3.3.2"><apply id="S3.SS5.p3.6.m6.2.2.1.1.cmml" xref="S3.SS5.p3.6.m6.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS5.p3.6.m6.2.2.1.1.1.cmml" xref="S3.SS5.p3.6.m6.2.2.1.1">subscript</csymbol><ci id="S3.SS5.p3.6.m6.2.2.1.1.2.cmml" xref="S3.SS5.p3.6.m6.2.2.1.1.2">𝑒</ci><ci id="S3.SS5.p3.6.m6.2.2.1.1.3a.cmml" xref="S3.SS5.p3.6.m6.2.2.1.1.3"><mtext id="S3.SS5.p3.6.m6.2.2.1.1.3.cmml" mathsize="70%" xref="S3.SS5.p3.6.m6.2.2.1.1.3">subj</mtext></ci></apply><ci id="S3.SS5.p3.6.m6.1.1.cmml" xref="S3.SS5.p3.6.m6.1.1">𝑟</ci><apply id="S3.SS5.p3.6.m6.3.3.2.2.cmml" xref="S3.SS5.p3.6.m6.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS5.p3.6.m6.3.3.2.2.1.cmml" xref="S3.SS5.p3.6.m6.3.3.2.2">subscript</csymbol><ci id="S3.SS5.p3.6.m6.3.3.2.2.2.cmml" xref="S3.SS5.p3.6.m6.3.3.2.2.2">𝑒</ci><ci id="S3.SS5.p3.6.m6.3.3.2.2.3a.cmml" xref="S3.SS5.p3.6.m6.3.3.2.2.3"><mtext id="S3.SS5.p3.6.m6.3.3.2.2.3.cmml" mathsize="70%" xref="S3.SS5.p3.6.m6.3.3.2.2.3">obj</mtext></ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.6.m6.3c">(e_{\text{subj}},r,e_{\text{obj}})</annotation></semantics></math>를 관계 트리플렛이라고 한다. 엔티티들은 각각의 문장 <math alttext="s" class="ltx_Math" display="inline" id="S3.SS5.p3.7.m7.1"><semantics id="S3.SS5.p3.7.m7.1a"><mi id="S3.SS5.p3.7.m7.1.1" xref="S3.SS5.p3.7.m7.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.p3.7.m7.1b"><ci id="S3.SS5.p3.7.m7.1.1.cmml" xref="S3.SS5.p3.7.m7.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.p3.7.m7.1c">s</annotation></semantics></math>에서 대응하는 스팬들로서 마킹된다. 18개의 개인 관련 관계, 11개의 조직 관련 관계 및 <span class="ltx_text ltx_font_italic" id="S3.SS5.p3.7.1">no_relation</span>로 구성된 30개의 관계 클래스가 있습니다. 이러한 클래스에 대한 자세한 설명은 표 <a class="ltx_ref" href="#S3.T10" title="Table 10 ‣ 3.5.1 Data Construction ‣ 3.5 Relation Extraction (RE) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">10</span></a>에 나와 있다. 우리는 <span class="ltx_text ltx_font_italic" id="S3.SS5.p3.7.2">no_relation</span> 및 30개 클래스를 모두 포함하는 정밀-리콜 곡선 아래의 면적을 제외하고 계산된 마이크로 F1 점수를 사용하여 모델을 평가한다.</p>
</div>
<section id="S3.SS5.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.1 </span>Data Construction</h4>

<div id="S3.SS5.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.p1.4">원격 감독 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib91" title="">91</a>]</cite>는 대규모 RE 벤치마크를 구축하는 인기 있는 방법입니다. Freebase와 같은 기존의 대규모 지식베이스(KB)에서 관계 트리플렛 <math alttext="(e_{\text{subj}},r,e_{\text{obj}})" class="ltx_Math" display="inline" id="S3.SS5.SSS1.p1.1.m1.3"><semantics id="S3.SS5.SSS1.p1.1.m1.3a"><mrow id="S3.SS5.SSS1.p1.1.m1.3.3.2" xref="S3.SS5.SSS1.p1.1.m1.3.3.3.cmml"><mo id="S3.SS5.SSS1.p1.1.m1.3.3.2.3" stretchy="false" xref="S3.SS5.SSS1.p1.1.m1.3.3.3.cmml">(</mo><msub id="S3.SS5.SSS1.p1.1.m1.2.2.1.1" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1.cmml"><mi id="S3.SS5.SSS1.p1.1.m1.2.2.1.1.2" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.p1.1.m1.2.2.1.1.3" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.p1.1.m1.3.3.2.4" xref="S3.SS5.SSS1.p1.1.m1.3.3.3.cmml">,</mo><mi id="S3.SS5.SSS1.p1.1.m1.1.1" xref="S3.SS5.SSS1.p1.1.m1.1.1.cmml">r</mi><mo id="S3.SS5.SSS1.p1.1.m1.3.3.2.5" xref="S3.SS5.SSS1.p1.1.m1.3.3.3.cmml">,</mo><msub id="S3.SS5.SSS1.p1.1.m1.3.3.2.2" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2.cmml"><mi id="S3.SS5.SSS1.p1.1.m1.3.3.2.2.2" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.p1.1.m1.3.3.2.2.3" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2.3a.cmml">obj</mtext></msub><mo id="S3.SS5.SSS1.p1.1.m1.3.3.2.6" stretchy="false" xref="S3.SS5.SSS1.p1.1.m1.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p1.1.m1.3b"><vector id="S3.SS5.SSS1.p1.1.m1.3.3.3.cmml" xref="S3.SS5.SSS1.p1.1.m1.3.3.2"><apply id="S3.SS5.SSS1.p1.1.m1.2.2.1.1.cmml" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.p1.1.m1.2.2.1.1.2.cmml" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.p1.1.m1.2.2.1.1.3a.cmml" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1.3"><mtext id="S3.SS5.SSS1.p1.1.m1.2.2.1.1.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.p1.1.m1.2.2.1.1.3">subj</mtext></ci></apply><ci id="S3.SS5.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS5.SSS1.p1.1.m1.1.1">𝑟</ci><apply id="S3.SS5.SSS1.p1.1.m1.3.3.2.2.cmml" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.p1.1.m1.3.3.2.2.1.cmml" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.p1.1.m1.3.3.2.2.3a.cmml" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2.3"><mtext id="S3.SS5.SSS1.p1.1.m1.3.3.2.2.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.p1.1.m1.3.3.2.2.3">obj</mtext></ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p1.1.m1.3c">(e_{\text{subj}},r,e_{\text{obj}})</annotation></semantics></math>를 활용한다. 큰 말뭉치에서 문장 <math alttext="s" class="ltx_Math" display="inline" id="S3.SS5.SSS1.p1.2.m2.1"><semantics id="S3.SS5.SSS1.p1.2.m2.1a"><mi id="S3.SS5.SSS1.p1.2.m2.1.1" xref="S3.SS5.SSS1.p1.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p1.2.m2.1b"><ci id="S3.SS5.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS5.SSS1.p1.2.m2.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p1.2.m2.1c">s</annotation></semantics></math>가 동시에 NER 모델에 의해 검출된 <math alttext="(e_{\text{subj}},e_{\text{obj}})" class="ltx_Math" display="inline" id="S3.SS5.SSS1.p1.3.m3.2"><semantics id="S3.SS5.SSS1.p1.3.m3.2a"><mrow id="S3.SS5.SSS1.p1.3.m3.2.2.2" xref="S3.SS5.SSS1.p1.3.m3.2.2.3.cmml"><mo id="S3.SS5.SSS1.p1.3.m3.2.2.2.3" stretchy="false" xref="S3.SS5.SSS1.p1.3.m3.2.2.3.cmml">(</mo><msub id="S3.SS5.SSS1.p1.3.m3.1.1.1.1" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1.cmml"><mi id="S3.SS5.SSS1.p1.3.m3.1.1.1.1.2" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.p1.3.m3.1.1.1.1.3" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.p1.3.m3.2.2.2.4" xref="S3.SS5.SSS1.p1.3.m3.2.2.3.cmml">,</mo><msub id="S3.SS5.SSS1.p1.3.m3.2.2.2.2" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2.cmml"><mi id="S3.SS5.SSS1.p1.3.m3.2.2.2.2.2" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.p1.3.m3.2.2.2.2.3" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2.3a.cmml">obj</mtext></msub><mo id="S3.SS5.SSS1.p1.3.m3.2.2.2.5" stretchy="false" xref="S3.SS5.SSS1.p1.3.m3.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p1.3.m3.2b"><interval closure="open" id="S3.SS5.SSS1.p1.3.m3.2.2.3.cmml" xref="S3.SS5.SSS1.p1.3.m3.2.2.2"><apply id="S3.SS5.SSS1.p1.3.m3.1.1.1.1.cmml" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.p1.3.m3.1.1.1.1.3a.cmml" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1.3"><mtext id="S3.SS5.SSS1.p1.3.m3.1.1.1.1.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.p1.3.m3.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.SS5.SSS1.p1.3.m3.2.2.2.2.cmml" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.p1.3.m3.2.2.2.2.1.cmml" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.p1.3.m3.2.2.2.2.2.cmml" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.p1.3.m3.2.2.2.2.3a.cmml" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2.3"><mtext id="S3.SS5.SSS1.p1.3.m3.2.2.2.2.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.p1.3.m3.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p1.3.m3.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math>를 포함하는 경우, 쌍을 포함하는 임의의 문장이 해당 관계를 표현할 것이라고 가정하여 관계 레이블 <math alttext="r" class="ltx_Math" display="inline" id="S3.SS5.SSS1.p1.4.m4.1"><semantics id="S3.SS5.SSS1.p1.4.m4.1a"><mi id="S3.SS5.SSS1.p1.4.m4.1.1" xref="S3.SS5.SSS1.p1.4.m4.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.p1.4.m4.1b"><ci id="S3.SS5.SSS1.p1.4.m4.1.1.cmml" xref="S3.SS5.SSS1.p1.4.m4.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.p1.4.m4.1c">r</annotation></semantics></math>로 데이터 세트에 추가한다. 이 접근법은 값비싼 인간 주석을 필요로 하지 않으므로 비용 효율적인 방식으로 대규모 RE 벤치마크를 구축할 수 있다.</p>
</div>
<div id="S3.SS5.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.p2.1">이러한 장점에도 불구하고 원거리 감독은 가정이 충족되지 않을 때 잘못된 관계 레이블로 끝나는 경우가 많다. 특히, 이는 서로 연관된 엔티티들의 쌍들만을 고려하며, 이는 그러한 코퍼스 상에서 트레이닝된 RE 모델이 임의의 주어진 엔티티들의 쌍 사이의 일부 관계의 존재를 과도하게 예측하게 한다. 즉, 이러한 예측자들로부터의 예측 관계 클래스 분포는 현실적인 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib116" title="">116</a>]</cite>가 아니다. <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. [<a class="ltx_ref" href="#bib.bib153" title="">153</a>]</cite>와 <cite class="ltx_cite ltx_citemacro_citet">Nam et al. [<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>는 원거리 감독에 의해 추출된 잘못된 관계를 완화하기 위해 크라우드 워커를 고용할 것을 제안한다. <cite class="ltx_cite ltx_citemacro_citet">Riedel et al. [<a class="ltx_ref" href="#bib.bib116" title="">116</a>]</cite> 더 나아가 RE 모델이 잘못된 긍정 관계를 과도하게 예측하는 것을 방지하기 위해 관련 없는 개체 쌍을 의도적으로 수집한다.</p>
</div>
<figure id="S3.T10" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">표 10: </span>KLUE-RE의 관계 스키마에 정의된 30개의 관계 클래스. 관계 클래스 <math alttext="r" class="ltx_Math" display="inline" id="S3.T10.2.m1.1"><semantics id="S3.T10.2.m1.1b"><mi id="S3.T10.2.m1.1.1" xref="S3.T10.2.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.T10.2.m1.1c"><ci id="S3.T10.2.m1.1.1.cmml" xref="S3.T10.2.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.T10.2.m1.1d">r</annotation></semantics></math>는 18개의 개인 관련 관계, 11개의 조직 관련 관계 및 <span class="ltx_text ltx_font_italic" id="S3.T10.9.1">no_relation</span>로 구성된 다음 중 하나여야 합니다.</figcaption>
<table id="S3.T10.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T10.3.2" class="ltx_tr">
<td id="S3.T10.3.2.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T10.3.2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Relation Class</span></td>
<td id="S3.T10.3.2.2" class="ltx_td ltx_align_justify ltx_border_tt">
<span id="S3.T10.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.2.2.1.1" class="ltx_p"><span id="S3.T10.3.2.2.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Description</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.1" class="ltx_tr">
<td id="S3.T10.3.1.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T10.3.1.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">no_relation</span></td>
<td id="S3.T10.3.1.1" class="ltx_td ltx_align_justify ltx_border_t">
<span id="S3.T10.3.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.1.1.1.1" class="ltx_p"><span id="S3.T10.3.1.1.1.1.1" class="ltx_text" style="font-size:90%;">No relation in between </span><math id="S3.T10.3.1.1.1.1.m1.2" class="ltx_Math" alttext="(e_{\text{subj}},e_{\text{obj}})" display="inline"><semantics id="S3.T10.3.1.1.1.1.m1.2a"><mrow id="S3.T10.3.1.1.1.1.m1.2.2.2" xref="S3.T10.3.1.1.1.1.m1.2.2.3.cmml"><mo maxsize="90%" minsize="90%" id="S3.T10.3.1.1.1.1.m1.2.2.2.3" xref="S3.T10.3.1.1.1.1.m1.2.2.3.cmml">(</mo><msub id="S3.T10.3.1.1.1.1.m1.1.1.1.1" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1.cmml"><mi mathsize="90%" id="S3.T10.3.1.1.1.1.m1.1.1.1.1.2" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1.2.cmml">e</mi><mtext mathsize="90%" id="S3.T10.3.1.1.1.1.m1.1.1.1.1.3" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1.3a.cmml">subj</mtext></msub><mo mathsize="90%" id="S3.T10.3.1.1.1.1.m1.2.2.2.4" xref="S3.T10.3.1.1.1.1.m1.2.2.3.cmml">,</mo><msub id="S3.T10.3.1.1.1.1.m1.2.2.2.2" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2.cmml"><mi mathsize="90%" id="S3.T10.3.1.1.1.1.m1.2.2.2.2.2" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2.2.cmml">e</mi><mtext mathsize="90%" id="S3.T10.3.1.1.1.1.m1.2.2.2.2.3" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2.3a.cmml">obj</mtext></msub><mo maxsize="90%" minsize="90%" id="S3.T10.3.1.1.1.1.m1.2.2.2.5" xref="S3.T10.3.1.1.1.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.T10.3.1.1.1.1.m1.2b"><interval closure="open" id="S3.T10.3.1.1.1.1.m1.2.2.3.cmml" xref="S3.T10.3.1.1.1.1.m1.2.2.2"><apply id="S3.T10.3.1.1.1.1.m1.1.1.1.1.cmml" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.T10.3.1.1.1.1.m1.1.1.1.1.1.cmml" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.T10.3.1.1.1.1.m1.1.1.1.1.2.cmml" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1.2">𝑒</ci><ci id="S3.T10.3.1.1.1.1.m1.1.1.1.1.3a.cmml" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1.3"><mtext mathsize="63%" id="S3.T10.3.1.1.1.1.m1.1.1.1.1.3.cmml" xref="S3.T10.3.1.1.1.1.m1.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.T10.3.1.1.1.1.m1.2.2.2.2.cmml" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.T10.3.1.1.1.1.m1.2.2.2.2.1.cmml" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.T10.3.1.1.1.1.m1.2.2.2.2.2.cmml" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2.2">𝑒</ci><ci id="S3.T10.3.1.1.1.1.m1.2.2.2.2.3a.cmml" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2.3"><mtext mathsize="63%" id="S3.T10.3.1.1.1.1.m1.2.2.2.2.3.cmml" xref="S3.T10.3.1.1.1.1.m1.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.T10.3.1.1.1.1.m1.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.3" class="ltx_tr">
<td id="S3.T10.3.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T10.3.3.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:dissolved</span></td>
<td id="S3.T10.3.3.2" class="ltx_td ltx_align_justify ltx_border_t">
<span id="S3.T10.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.3.2.1.1" class="ltx_p"><span id="S3.T10.3.3.2.1.1.1" class="ltx_text" style="font-size:90%;">The date when the specified organization was dissolved</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.4" class="ltx_tr">
<td id="S3.T10.3.4.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.4.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:founded</span></td>
<td id="S3.T10.3.4.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.4.2.1.1" class="ltx_p"><span id="S3.T10.3.4.2.1.1.1" class="ltx_text" style="font-size:90%;">The date when the specified organization was founded</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.5" class="ltx_tr">
<td id="S3.T10.3.5.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.5.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:place_of_headquarters</span></td>
<td id="S3.T10.3.5.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.5.2.1.1" class="ltx_p"><span id="S3.T10.3.5.2.1.1.1" class="ltx_text" style="font-size:90%;">The place which the headquarters of the specified organization are located in</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.6" class="ltx_tr">
<td id="S3.T10.3.6.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.6.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:alternate_names</span></td>
<td id="S3.T10.3.6.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.6.2.1.1" class="ltx_p"><span id="S3.T10.3.6.2.1.1.1" class="ltx_text" style="font-size:90%;">Alternative names called instead of the official name to refer to the specified organization</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.7" class="ltx_tr">
<td id="S3.T10.3.7.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.7.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:member_of</span></td>
<td id="S3.T10.3.7.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.7.2.1.1" class="ltx_p"><span id="S3.T10.3.7.2.1.1.1" class="ltx_text" style="font-size:90%;">Organizations to which the specified organization belongs</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.8" class="ltx_tr">
<td id="S3.T10.3.8.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.8.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:members</span></td>
<td id="S3.T10.3.8.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.8.2.1.1" class="ltx_p"><span id="S3.T10.3.8.2.1.1.1" class="ltx_text" style="font-size:90%;">Organizations which belong to the specified organization</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.9" class="ltx_tr">
<td id="S3.T10.3.9.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.9.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:political/religious_affiliation</span></td>
<td id="S3.T10.3.9.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.9.2.1.1" class="ltx_p"><span id="S3.T10.3.9.2.1.1.1" class="ltx_text" style="font-size:90%;">Political/religious groups which the specified organization is affiliated in</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.10" class="ltx_tr">
<td id="S3.T10.3.10.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.10.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:product</span></td>
<td id="S3.T10.3.10.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.10.2.1.1" class="ltx_p"><span id="S3.T10.3.10.2.1.1.1" class="ltx_text" style="font-size:90%;">Products or merchandise produced by the specified organization</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.11" class="ltx_tr">
<td id="S3.T10.3.11.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.11.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:founded_by</span></td>
<td id="S3.T10.3.11.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.11.2.1.1" class="ltx_p"><span id="S3.T10.3.11.2.1.1.1" class="ltx_text" style="font-size:90%;">The person or organization that founded the specified organization</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.12" class="ltx_tr">
<td id="S3.T10.3.12.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.12.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:top_members/employees</span></td>
<td id="S3.T10.3.12.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.12.2.1.1" class="ltx_p"><span id="S3.T10.3.12.2.1.1.1" class="ltx_text" style="font-size:90%;">The representative(s) or members of the specified organization</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.13" class="ltx_tr">
<td id="S3.T10.3.13.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.13.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">org:number_of_employees/members</span></td>
<td id="S3.T10.3.13.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.13.2.1.1" class="ltx_p"><span id="S3.T10.3.13.2.1.1.1" class="ltx_text" style="font-size:90%;">The total number of members that are affiliated in the specified organization</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.14" class="ltx_tr">
<td id="S3.T10.3.14.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T10.3.14.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:date_of_birth</span></td>
<td id="S3.T10.3.14.2" class="ltx_td ltx_align_justify ltx_border_t">
<span id="S3.T10.3.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.14.2.1.1" class="ltx_p"><span id="S3.T10.3.14.2.1.1.1" class="ltx_text" style="font-size:90%;">The date when the specified person was born</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.15" class="ltx_tr">
<td id="S3.T10.3.15.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.15.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:date_of_death</span></td>
<td id="S3.T10.3.15.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.15.2.1.1" class="ltx_p"><span id="S3.T10.3.15.2.1.1.1" class="ltx_text" style="font-size:90%;">The date when the specified person died</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.16" class="ltx_tr">
<td id="S3.T10.3.16.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.16.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:place_of_birth</span></td>
<td id="S3.T10.3.16.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.16.2.1.1" class="ltx_p"><span id="S3.T10.3.16.2.1.1.1" class="ltx_text" style="font-size:90%;">The place where the specified person was born</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.17" class="ltx_tr">
<td id="S3.T10.3.17.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.17.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:place_of_death</span></td>
<td id="S3.T10.3.17.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.17.2.1.1" class="ltx_p"><span id="S3.T10.3.17.2.1.1.1" class="ltx_text" style="font-size:90%;">The place where the specified person died</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.18" class="ltx_tr">
<td id="S3.T10.3.18.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.18.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:place_of_residence</span></td>
<td id="S3.T10.3.18.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.18.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.18.2.1.1" class="ltx_p"><span id="S3.T10.3.18.2.1.1.1" class="ltx_text" style="font-size:90%;">The place where the specified person lives</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.19" class="ltx_tr">
<td id="S3.T10.3.19.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.19.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:origin</span></td>
<td id="S3.T10.3.19.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.19.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.19.2.1.1" class="ltx_p"><span id="S3.T10.3.19.2.1.1.1" class="ltx_text" style="font-size:90%;">The origins or the nationality of the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.20" class="ltx_tr">
<td id="S3.T10.3.20.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.20.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:employee_of</span></td>
<td id="S3.T10.3.20.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.20.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.20.2.1.1" class="ltx_p"><span id="S3.T10.3.20.2.1.1.1" class="ltx_text" style="font-size:90%;">The organization where the specified person works</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.21" class="ltx_tr">
<td id="S3.T10.3.21.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.21.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:schools_attended</span></td>
<td id="S3.T10.3.21.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.21.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.21.2.1.1" class="ltx_p"><span id="S3.T10.3.21.2.1.1.1" class="ltx_text" style="font-size:90%;">A school where the specified person attended</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.22" class="ltx_tr">
<td id="S3.T10.3.22.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.22.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:alternate_names</span></td>
<td id="S3.T10.3.22.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.22.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.22.2.1.1" class="ltx_p"><span id="S3.T10.3.22.2.1.1.1" class="ltx_text" style="font-size:90%;">Alternative names called instead of the official name to refer to the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.23" class="ltx_tr">
<td id="S3.T10.3.23.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.23.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:parents</span></td>
<td id="S3.T10.3.23.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.23.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.23.2.1.1" class="ltx_p"><span id="S3.T10.3.23.2.1.1.1" class="ltx_text" style="font-size:90%;">The parents of the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.24" class="ltx_tr">
<td id="S3.T10.3.24.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.24.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:children</span></td>
<td id="S3.T10.3.24.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.24.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.24.2.1.1" class="ltx_p"><span id="S3.T10.3.24.2.1.1.1" class="ltx_text" style="font-size:90%;">The children of the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.25" class="ltx_tr">
<td id="S3.T10.3.25.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.25.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:siblings</span></td>
<td id="S3.T10.3.25.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.25.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.25.2.1.1" class="ltx_p"><span id="S3.T10.3.25.2.1.1.1" class="ltx_text" style="font-size:90%;">The brothers and sisters of the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.26" class="ltx_tr">
<td id="S3.T10.3.26.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.26.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:spouse</span></td>
<td id="S3.T10.3.26.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.26.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.26.2.1.1" class="ltx_p"><span id="S3.T10.3.26.2.1.1.1" class="ltx_text" style="font-size:90%;">The spouse(s) of the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.27" class="ltx_tr">
<td id="S3.T10.3.27.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.27.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:other_family</span></td>
<td id="S3.T10.3.27.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.27.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.27.2.1.1" class="ltx_p"><span id="S3.T10.3.27.2.1.1.1" class="ltx_text" style="font-size:90%;">Family members of the specified person other than parents, children, siblings, and spouse(s)</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.28" class="ltx_tr">
<td id="S3.T10.3.28.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.28.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:colleagues</span></td>
<td id="S3.T10.3.28.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.28.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.28.2.1.1" class="ltx_p"><span id="S3.T10.3.28.2.1.1.1" class="ltx_text" style="font-size:90%;">People who work together with the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.29" class="ltx_tr">
<td id="S3.T10.3.29.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.29.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:product</span></td>
<td id="S3.T10.3.29.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.29.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.29.2.1.1" class="ltx_p"><span id="S3.T10.3.29.2.1.1.1" class="ltx_text" style="font-size:90%;">Products or artworks produced by the specified person</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.30" class="ltx_tr">
<td id="S3.T10.3.30.1" class="ltx_td ltx_align_left"><span id="S3.T10.3.30.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:religion</span></td>
<td id="S3.T10.3.30.2" class="ltx_td ltx_align_justify">
<span id="S3.T10.3.30.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.30.2.1.1" class="ltx_p"><span id="S3.T10.3.30.2.1.1.1" class="ltx_text" style="font-size:90%;">The religion in which the specified person believes</span></span>
</span>
</td>
</tr>
<tr id="S3.T10.3.31" class="ltx_tr">
<td id="S3.T10.3.31.1" class="ltx_td ltx_align_left ltx_border_bb"><span id="S3.T10.3.31.1.1" class="ltx_text ltx_font_italic" style="font-size:90%;">per:title</span></td>
<td id="S3.T10.3.31.2" class="ltx_td ltx_align_justify ltx_border_bb">
<span id="S3.T10.3.31.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T10.3.31.2.1.1" class="ltx_p"><span id="S3.T10.3.31.2.1.1.1" class="ltx_text" style="font-size:90%;">Official or unofficial names that represent the occupational position of the specified person</span></span>
</span>
</td>
</tr>
</tbody></table>
</figure>
<section id="S3.SS5.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Overview</h5>

<div id="S3.SS5.SSS1.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.Px1.p1.2">우리는 이러한 약점을 해결하고 우리의 상황에 더 잘 부합하기 위해 위의 원거리 감독의 원래 전략을 수정한다. 먼저, 작은 한국어 KB<span class="ltx_note ltx_role_footnote" id="footnote29"><sup class="ltx_note_mark">29</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">29</sup><span class="ltx_tag ltx_tag_note">29</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aihub.or.kr/aidata/84" target="_blank" title="">https://aihub.or.kr/aidata/84</a> </span></span></span>에서 트리플렛 <math alttext="(e_{\text{subj}},r,e_{\text{obj}})" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px1.p1.1.m1.3"><semantics id="S3.SS5.SSS1.Px1.p1.1.m1.3a"><mrow id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.3.cmml"><mo id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.3" stretchy="false" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.3.cmml">(</mo><msub id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.cmml"><mi id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.2" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.3" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.4" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.3.cmml">,</mo><mi id="S3.SS5.SSS1.Px1.p1.1.m1.1.1" xref="S3.SS5.SSS1.Px1.p1.1.m1.1.1.cmml">r</mi><mo id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.5" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.3.cmml">,</mo><msub id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.cmml"><mi id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.2" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.3" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.3a.cmml">obj</mtext></msub><mo id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.6" stretchy="false" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px1.p1.1.m1.3b"><vector id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.3.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2"><apply id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.2.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.3a.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.3"><mtext id="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.Px1.p1.1.m1.2.2.1.1.3">subj</mtext></ci></apply><ci id="S3.SS5.SSS1.Px1.p1.1.m1.1.1.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.1.1">𝑟</ci><apply id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.1.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.3a.cmml" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.3"><mtext id="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.Px1.p1.1.m1.3.3.2.2.3">obj</mtext></ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px1.p1.1.m1.3c">(e_{\text{subj}},r,e_{\text{obj}})</annotation></semantics></math>를 수집하고, WIKIPEDIA와 NAMUWIKI<span class="ltx_note ltx_role_footnote" id="footnote30"><sup class="ltx_note_mark">30</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">30</sup><span class="ltx_tag ltx_tag_note">30</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://namu.wiki" target="_blank" title="">https://namu.wiki</a> </span></span></span>에서 infobox를 파싱하여 후보 트리플렛의 풀을 확장하여 추가 트리플렛을 구축한다. 그런 다음 자동으로 생성된 관계 레이블을 직접 사용하는 원거리 감독과 비교하여 크라우드 워커에게 문장 내에서 각 후보 트리플렛의 올바른 관계 클래스를 선택하도록 요청한다. 또한, 벤치마크에서 보다 현실적인 관계 클래스 분포를 얻기 위해 <math alttext="s" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px1.p1.2.m2.1"><semantics id="S3.SS5.SSS1.Px1.p1.2.m2.1a"><mi id="S3.SS5.SSS1.Px1.p1.2.m2.1.1" xref="S3.SS5.SSS1.Px1.p1.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px1.p1.2.m2.1b"><ci id="S3.SS5.SSS1.Px1.p1.2.m2.1.1.cmml" xref="S3.SS5.SSS1.Px1.p1.2.m2.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px1.p1.2.m2.1c">s</annotation></semantics></math>에서 개체 쌍을 무작위로 샘플링한다. 이러한 예는 기존 KB에서 보이지 않는 엔터티를 포함할 뿐만 아니라 관련이 없을 가능성이 더 높다(<span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px1.p1.2.1">no_relation</span>).</p>
</div>
<div id="S3.SS5.SSS1.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.Px1.p2.1">이 절차는 (1) 후보 문장 수집, (2) 관계 스키마 정의, (3) 개체 검출, (4) 개체 쌍 선택 및 (5) 관계 주석의 다섯 단계로 나눌 수 있다. 우리는 이 섹션의 나머지 부분에서 각 단계를 자세히 설명한다.</p>
</div>
</section>
<section id="S3.SS5.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">1. Collect Candidate Sentences</h5>

<div id="S3.SS5.SSS1.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.Px2.p1.1">이를 위해 WIKIPEDIA, WIKITREE, POLICY 코퍼라에서 후보 문장을 추출하여 다양한 개체명 집합과 관계적 사실들을 다룬다. 우리의 작업은 단일 문장을 다루기 때문에 전처리 단계에서 한국어 문장 분할기 <span class="ltx_note ltx_role_footnote" id="footnote31"><sup class="ltx_note_mark">31</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">31</sup><span class="ltx_tag ltx_tag_note">31</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/hyunwoongko/kss" target="_blank" title="">https://github.com/hyunwoongko/kss</a> </span></span></span>에 의해 분할된 개별 문장을 이용한다. 한국어 혐오 음성 데이터 세트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib92" title="">92</a>]</cite>에 대해 학습된 분류기를 사용하여 바람직하지 않은 사회적 편향을 포함하고 혐오 음성으로 간주되는 문장을 필터링한다.</p>
</div>
</section>
<section id="S3.SS5.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">2. Define Relation Schema</h5>

<div id="S3.SS5.SSS1.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.Px3.p1.2">TAC-KBP(Text Analysis Conference Knowledge Base Population) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib87" title="">87</a>]</cite>의 스키마를 기반으로 관계 스키마를 설계한다. 스키마는 엔터티 유형 및 관계 클래스를 정의합니다. TAC-KBP와 유사하게 <math alttext="e_{\text{subj}}" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px3.p1.1.m1.1"><semantics id="S3.SS5.SSS1.Px3.p1.1.m1.1a"><msub id="S3.SS5.SSS1.Px3.p1.1.m1.1.1" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1.cmml"><mi id="S3.SS5.SSS1.Px3.p1.1.m1.1.1.2" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px3.p1.1.m1.1.1.3" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1.3a.cmml">subj</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px3.p1.1.m1.1b"><apply id="S3.SS5.SSS1.Px3.p1.1.m1.1.1.cmml" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px3.p1.1.m1.1.1.1.cmml" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px3.p1.1.m1.1.1.2.cmml" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px3.p1.1.m1.1.1.3a.cmml" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1.3"><mtext id="S3.SS5.SSS1.Px3.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.Px3.p1.1.m1.1.1.3">subj</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px3.p1.1.m1.1c">e_{\text{subj}}</annotation></semantics></math>를 PER(Person) 또는 ORG(Organization) 유형 중 하나로 제한한다. <math alttext="e_{\text{obj}}" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px3.p1.2.m2.1"><semantics id="S3.SS5.SSS1.Px3.p1.2.m2.1a"><msub id="S3.SS5.SSS1.Px3.p1.2.m2.1.1" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1.cmml"><mi id="S3.SS5.SSS1.Px3.p1.2.m2.1.1.2" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px3.p1.2.m2.1.1.3" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1.3a.cmml">obj</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px3.p1.2.m2.1b"><apply id="S3.SS5.SSS1.Px3.p1.2.m2.1.1.cmml" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px3.p1.2.m2.1.1.1.cmml" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px3.p1.2.m2.1.1.2.cmml" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px3.p1.2.m2.1.1.3a.cmml" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1.3"><mtext id="S3.SS5.SSS1.Px3.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.Px3.p1.2.m2.1.1.3">obj</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px3.p1.2.m2.1c">e_{\text{obj}}</annotation></semantics></math>는 PER, ORG, LOC(Location), DAT(Date and time), POH(Other proper nouns), NOH(Other numerals) 중 하나를 가질 수 있다. 관계 클래스의 경우 TAC-KBP의 원래 클래스를 <cite class="ltx_cite ltx_citemacro_citet">Yu et al. [<a class="ltx_ref" href="#bib.bib149" title="">149</a>]</cite>에 이어 코퍼스에 적용한다.</p>
</div>
<div id="S3.SS5.SSS1.Px3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.Px3.p2.1">우리는 <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.1">org:website</span>, <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.2">per:shareholders</span>, <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.3">per:cause_of_death</span>, <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.4">per:charges</span>, <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.5">per:age</span>과 같은 이유로 <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.6">org:parents</span>을 <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.7">org:member_of</span> 및 <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.8">org:subsidiaries</span>을 <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.9">org:members</span>에 통합한다. TAC-KBP의 분류는 한국의 지역적 계층을 정확하게 반영하지 않기 때문에 prefixes <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.10">country_of</span>, <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.11">city_of</span>, <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.12">stateorprovince_of</span>을 <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.13">place_of</span>에 통합한다. <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.14">org:product</span>, <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.15">per:product</span> 및 <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px3.p2.1.16">per:colleague</span>과 같이 코퍼스에 자주 나타나는 추가 클래스를 소개합니다.</p>
</div>
<div id="S3.SS5.SSS1.Px3.p3" class="ltx_para">
<ul id="S3.I4" class="ltx_itemize">
<li id="S3.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i1.p1" class="ltx_para">
<p class="ltx_p" id="S3.I4.i1.p1.1"><span class="ltx_text ltx_font_italic" id="S3.I4.i1.p1.1.1">org:product</span>: A product or merchandise produced by organization. 조직이 주최하는 행사, 창업한 사업 등 무형의 재화가 이에 해당한다.</p>
</div>
</li>
<li id="S3.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i2.p1" class="ltx_para">
<p class="ltx_p" id="S3.I4.i2.p1.1"><span class="ltx_text ltx_font_italic" id="S3.I4.i2.p1.1.1">per:product</span>: 사람이 만든 제품. 예술 작품(예: 책, 음악, 영화) 또는 작품을 제작하는 데 기여합니다.</p>
</div>
</li>
<li id="S3.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I4.i3.p1" class="ltx_para">
<p class="ltx_p" id="S3.I4.i3.p1.1"><span class="ltx_text ltx_font_italic" id="S3.I4.i3.p1.1.1">per:colleague</span>: A person could be a colleague of someone if they work together. 정당이나 동맹 등 같은 조에 속한 두 사람도 동료다.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS5.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">3. Detect Entities</h5>

<div id="S3.SS5.SSS1.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.Px4.p1.1">우리는 모든 후보 문장에서 명명된 개체를 자동으로 검출한다. 우리는 한국어 <span class="ltx_note ltx_role_footnote" id="footnote32"><sup class="ltx_note_mark">32</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">32</sup><span class="ltx_tag ltx_tag_note">32</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/monologg/KoELECTRA" target="_blank" title="">https://github.com/monologg/KoELECTRA</a> </span></span></span>에 대해 미리 훈련된 ELECTRA를 미세 조정하여 두 개의 기존 한국어 NER 리소스에 각각 두 개의 명명된 엔터티 인식(NER) 모델을 구축한다. 하나는 국립국어원 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib98" title="">98</a>]</cite>에서 제공하고, 다른 하나는 한국해양대학교에서 구축한다. <span class="ltx_note ltx_role_footnote" id="footnote33"><sup class="ltx_note_mark">33</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">33</sup><span class="ltx_tag ltx_tag_note">33</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/kmounlp/NER" target="_blank" title="">https://github.com/kmounlp/NER</a> </span></span></span> 이러한 리소스에 정의된 명명된 엔터티 유형을 스키마에 이전에 정의된 자체 엔터티 유형과 호환되도록 수정합니다. 우리는 가능한 한 많은 개체를 추출하기 위해 두 모델의 예측 합을 취한다. 크라우드 소싱을 사용하여 나중에 설명하는 것처럼 탐지된 엔터티의 잘못된 경계를 수정합니다.</p>
</div>
</section>
<section id="S3.SS5.SSS1.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">4. Select Entity Pairs</h5>

<div id="S3.SS5.SSS1.Px5.p1" class="ltx_para">
<p id="S3.SS5.SSS1.Px5.p1.3" class="ltx_p">We select two entities from the entity set <math id="S3.SS5.SSS1.Px5.p1.1.m1.1" class="ltx_Math" alttext="E" display="inline"><semantics id="S3.SS5.SSS1.Px5.p1.1.m1.1a"><mi id="S3.SS5.SSS1.Px5.p1.1.m1.1.1" xref="S3.SS5.SSS1.Px5.p1.1.m1.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p1.1.m1.1b"><ci id="S3.SS5.SSS1.Px5.p1.1.m1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p1.1.m1.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p1.1.m1.1c">E</annotation></semantics></math> of a given sentence <math id="S3.SS5.SSS1.Px5.p1.2.m2.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS5.SSS1.Px5.p1.2.m2.1a"><mi id="S3.SS5.SSS1.Px5.p1.2.m2.1.1" xref="S3.SS5.SSS1.Px5.p1.2.m2.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p1.2.m2.1b"><ci id="S3.SS5.SSS1.Px5.p1.2.m2.1.1.cmml" xref="S3.SS5.SSS1.Px5.p1.2.m2.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p1.2.m2.1c">s</annotation></semantics></math> to make an entity pair <math id="S3.SS5.SSS1.Px5.p1.3.m3.2" class="ltx_Math" alttext="(e_{\text{subj}},e_{\text{obj}})" display="inline"><semantics id="S3.SS5.SSS1.Px5.p1.3.m3.2a"><mrow id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.3.cmml"><mo stretchy="false" id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.3" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.3.cmml">(</mo><msub id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.cmml"><mi id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.2" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.3" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.4" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.3.cmml">,</mo><msub id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.cmml"><mi id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.2" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.3" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.3a.cmml">obj</mtext></msub><mo stretchy="false" id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.5" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p1.3.m3.2b"><interval closure="open" id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.3.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2"><apply id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.2.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.3a.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.3.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.1.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.3a.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.3"><mtext mathsize="70%" id="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.3.cmml" xref="S3.SS5.SSS1.Px5.p1.3.m3.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p1.3.m3.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math>. In doing so, we take two distinct approaches; (1) KB-based sampling and (2) uniform sampling.</p>
</div>
<div id="S3.SS5.SSS1.Px5.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.Px5.p2.5">첫 번째 접근법의 경우, 각각의 엔티티 쌍 <math alttext="(e_{\text{subj}},e_{\text{obj}})" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px5.p2.1.m1.2"><semantics id="S3.SS5.SSS1.Px5.p2.1.m1.2a"><mrow id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.3.cmml"><mo id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.3" stretchy="false" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.3.cmml">(</mo><msub id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.cmml"><mi id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.2" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.3" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.4" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.cmml"><mi id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.2" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.3" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.3a.cmml">obj</mtext></msub><mo id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.5" stretchy="false" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p2.1.m1.2b"><interval closure="open" id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.3.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2"><apply id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.2.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.3a.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.3"><mtext id="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.Px5.p2.1.m1.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.1.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.3a.cmml" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.3"><mtext id="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.Px5.p2.1.m1.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p2.1.m1.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math>가 트리플렛들 <math alttext="(e_{\text{subj}},r,e_{\text{obj}})" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px5.p2.2.m2.3"><semantics id="S3.SS5.SSS1.Px5.p2.2.m2.3a"><mrow id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.3.cmml"><mo id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.3" stretchy="false" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.3.cmml">(</mo><msub id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.cmml"><mi id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.2" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.3" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.4" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.3.cmml">,</mo><mi id="S3.SS5.SSS1.Px5.p2.2.m2.1.1" xref="S3.SS5.SSS1.Px5.p2.2.m2.1.1.cmml">r</mi><mo id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.5" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.3.cmml">,</mo><msub id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.cmml"><mi id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.2" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.3" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.3a.cmml">obj</mtext></msub><mo id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.6" stretchy="false" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p2.2.m2.3b"><vector id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.3.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2"><apply id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.2.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.3a.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.3"><mtext id="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.Px5.p2.2.m2.2.2.1.1.3">subj</mtext></ci></apply><ci id="S3.SS5.SSS1.Px5.p2.2.m2.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.1.1">𝑟</ci><apply id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.1.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.3a.cmml" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.3"><mtext id="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.Px5.p2.2.m2.3.3.2.2.3">obj</mtext></ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p2.2.m2.3c">(e_{\text{subj}},r,e_{\text{obj}})</annotation></semantics></math>의 풀에 나타나도록 엔티티들의 서브세트만을 고려한다. 우리는 두 가지 출처에서 이 세쌍둥이를 수집합니다. 먼저 한국어 KB를 사용하여 초기 트리플렛 풀을 생성한다. <span class="ltx_note ltx_role_footnote" id="footnote34"><sup class="ltx_note_mark">34</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">34</sup><span class="ltx_tag ltx_tag_note">34</span> Released by NIA, a government-funded institution. Available at <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aihub.or.kr/aidata/84" target="_blank" title="">https://aihub.or.kr/aidata/84</a>. </span></span></span> 한국어 KB로부터의 트리플렛 수(<math alttext="\sim" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px5.p2.3.m3.1"><semantics id="S3.SS5.SSS1.Px5.p2.3.m3.1a"><mo id="S3.SS5.SSS1.Px5.p2.3.m3.1.1" xref="S3.SS5.SSS1.Px5.p2.3.m3.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p2.3.m3.1b"><csymbol cd="latexml" id="S3.SS5.SSS1.Px5.p2.3.m3.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.3.m3.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p2.3.m3.1c">\sim</annotation></semantics></math>800k)가 예를 들어 Freebase(<math alttext="\sim" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px5.p2.4.m4.1"><semantics id="S3.SS5.SSS1.Px5.p2.4.m4.1a"><mo id="S3.SS5.SSS1.Px5.p2.4.m4.1.1" xref="S3.SS5.SSS1.Px5.p2.4.m4.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p2.4.m4.1b"><csymbol cd="latexml" id="S3.SS5.SSS1.Px5.p2.4.m4.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.4.m4.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p2.4.m4.1c">\sim</annotation></semantics></math>2b)의 트리플렛 수에 비해 적기 때문에, 우리는 이 트리플렛 풀을 WIKIPEDIA와 Namuwiki에서 수집 후 인포박스를 파싱하여 확대한다. 한국 대통령과 같은 빈번한 엔티티의 초과 포함을 피하기 위해 샘플링 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib153" title="">153</a>]</cite> 동안 <math alttext="(e_{\text{subj}},e_{\text{obj}})" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px5.p2.5.m5.2"><semantics id="S3.SS5.SSS1.Px5.p2.5.m5.2a"><mrow id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.3.cmml"><mo id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.3" stretchy="false" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.3.cmml">(</mo><msub id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.cmml"><mi id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.2" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.3" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.4" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.3.cmml">,</mo><msub id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.cmml"><mi id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.2" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.3" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.3a.cmml">obj</mtext></msub><mo id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.5" stretchy="false" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p2.5.m5.2b"><interval closure="open" id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.3.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2"><apply id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.2.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.3a.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.3"><mtext id="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.Px5.p2.5.m5.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.1.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.3a.cmml" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.3"><mtext id="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.Px5.p2.5.m5.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p2.5.m5.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math> 사이의 동시 발생 횟수에 상한을 설정한다.</p>
</div>
<div id="S3.SS5.SSS1.Px5.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.Px5.p3.3">두 번째 접근법에서, <math alttext="(e_{\text{subj}},e_{\text{obj}})" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px5.p3.1.m1.2"><semantics id="S3.SS5.SSS1.Px5.p3.1.m1.2a"><mrow id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.3.cmml"><mo id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.3" stretchy="false" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.3.cmml">(</mo><msub id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.cmml"><mi id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.2" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.3" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.4" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.cmml"><mi id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.2" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.3" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.3a.cmml">obj</mtext></msub><mo id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.5" stretchy="false" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p3.1.m1.2b"><interval closure="open" id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.3.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2"><apply id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.2.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.3a.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.3"><mtext id="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.Px5.p3.1.m1.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.1.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.3a.cmml" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.3"><mtext id="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.Px5.p3.1.m1.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p3.1.m1.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math>는 주어진 문장 <math alttext="s" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px5.p3.3.m3.1"><semantics id="S3.SS5.SSS1.Px5.p3.3.m3.1a"><mi id="S3.SS5.SSS1.Px5.p3.3.m3.1.1" xref="S3.SS5.SSS1.Px5.p3.3.m3.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p3.3.m3.1b"><ci id="S3.SS5.SSS1.Px5.p3.3.m3.1.1.cmml" xref="S3.SS5.SSS1.Px5.p3.3.m3.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p3.3.m3.1c">s</annotation></semantics></math>의 전체 엔티티 세트 <math alttext="E" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px5.p3.2.m2.1"><semantics id="S3.SS5.SSS1.Px5.p3.2.m2.1a"><mi id="S3.SS5.SSS1.Px5.p3.2.m2.1.1" xref="S3.SS5.SSS1.Px5.p3.2.m2.1.1.cmml">E</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px5.p3.2.m2.1b"><ci id="S3.SS5.SSS1.Px5.p3.2.m2.1.1.cmml" xref="S3.SS5.SSS1.Px5.p3.2.m2.1.1">𝐸</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px5.p3.2.m2.1c">E</annotation></semantics></math>로부터 랜덤하게 균일하게 샘플링된다. 샘플링된 쌍이 그들 사이에 어떤 관계를 갖는지 여부에 대한 큐가 없기 때문에, 쌍은 관련성이 없을 가능성이 높다(<span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px5.p3.3.1">no_relation</span>). 관련되지 않은 쌍들은 두 임의의 개체들 사이의 현실적인 관계 분포에서 많은 부분을 설명할 것이다. 따라서 이 접근법은 실제 시나리오를 설정하는 데 도움이 된다. 그러한 쌍은 또한 제1 접근법에서 선택되지 않은 엔티티들을 포함할 가능성이 있다. 이것은 KB에 독립적인 개체 쌍 및 그 관계를 캡처하는 것으로 이어진다.</p>
</div>
</section>
<section id="S3.SS5.SSS1.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">5. Annotate Relations</h5>

<figure id="S3.F4" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2105.09680/assets/figs/re_tool.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="330" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 4:</span>크라우드소싱을 위한 주석 도구. 주요 기능은 빨간색으로 영어로 번역됩니다.</figcaption>
</figure>
<div id="S3.SS5.SSS1.Px6.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.Px6.p1.2">DeepNatural,<span class="ltx_note ltx_role_footnote" id="footnote35"><sup class="ltx_note_mark">35</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">35</sup><span class="ltx_tag ltx_tag_note">35</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://deepnatural.ai/" target="_blank" title="">https://deepnatural.ai/</a></span></span></span> 한국어 크라우드소싱 플랫폼에서 모집한 근로자에게 각 엔티티 쌍 <math alttext="(e_{\text{subj}},e_{\text{obj}})" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px6.p1.1.m1.2"><semantics id="S3.SS5.SSS1.Px6.p1.1.m1.2a"><mrow id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.3.cmml"><mo id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.3" stretchy="false" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.3.cmml">(</mo><msub id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.cmml"><mi id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.2" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.3" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.3a.cmml">subj</mtext></msub><mo id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.4" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.3.cmml">,</mo><msub id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.cmml"><mi id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.2" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.2.cmml">e</mi><mtext id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.3" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.3a.cmml">obj</mtext></msub><mo id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.5" stretchy="false" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px6.p1.1.m1.2b"><interval closure="open" id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.3.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2"><apply id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.1.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.2.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.2">𝑒</ci><ci id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.3a.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.3"><mtext id="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.Px6.p1.1.m1.1.1.1.1.3">subj</mtext></ci></apply><apply id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.1.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.2.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.2">𝑒</ci><ci id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.3a.cmml" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.3"><mtext id="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.3.cmml" mathsize="70%" xref="S3.SS5.SSS1.Px6.p1.1.m1.2.2.2.2.3">obj</mtext></ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px6.p1.1.m1.2c">(e_{\text{subj}},e_{\text{obj}})</annotation></semantics></math>에 관계 레이블 <math alttext="r" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px6.p1.2.m2.1"><semantics id="S3.SS5.SSS1.Px6.p1.2.m2.1a"><mi id="S3.SS5.SSS1.Px6.p1.2.m2.1.1" xref="S3.SS5.SSS1.Px6.p1.2.m2.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px6.p1.2.m2.1b"><ci id="S3.SS5.SSS1.Px6.p1.2.m2.1.1.cmml" xref="S3.SS5.SSS1.Px6.p1.2.m2.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px6.p1.2.m2.1c">r</annotation></semantics></math>로 주석을 달도록 요청한다. 우리는 근로자들에게 과거의 관계가 아닌 현재의 관계에 집중하도록 지시한다. 예를 들어 문장에 설명된 사람이 특정 조직의 이전 구성원인 경우 작업자는 관계 <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS1.Px6.p1.2.1">per:employee_of</span>을 선택하지 않도록 요청받는다. 또한 주어진 문장 내에서만 맥락으로부터 관계를 추론하기 위해 외부 지식, 즉 상식에 의존하지 않도록 요청합니다. 노동자들은 혐오 표현, 편향된 표현 또는 개인 식별 정보가 포함된 예를 보고한다. 또한, 그들은 잘못된 엔티티 경계를 갖는 문장들을 보고하도록 요청받는다.</p>
</div>
<div id="S3.SS5.SSS1.Px6.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.Px6.p2.1">우리는 163명의 자격을 갖춘 작업자를 고용하며, 각 작업자는 파일럿 주석 단계에서 5개 질문 중 최소 4개 질문에 올바르게 라벨을 붙였다. 파일럿 단계 이후 3명의 작업자가 독립적으로 각 예제에 할당되어 관계에 레이블을 지정한다. 그림 <a class="ltx_ref" href="#S3.F4" title="Figure 4 ‣ 5. Annotate Relations ‣ 3.5.1 Data Construction ‣ 3.5 Relation Extraction (RE) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">4</span></a>는 크라우드소싱을 위한 어노테이션 툴을 보여준다. 주석자의 인지적 부담을 줄이기 위해 처음에는 적은 수의 후보 관계를 제공한다. 후보들은 NER 모델들에 의해 예측된 엔티티 쌍의 유형들 사이에서 정의될 수 있는 관계들로 구성된다. 후보에서 적절한 <math alttext="r" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px6.p2.1.m1.1"><semantics id="S3.SS5.SSS1.Px6.p2.1.m1.1a"><mi id="S3.SS5.SSS1.Px6.p2.1.m1.1.1" xref="S3.SS5.SSS1.Px6.p2.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px6.p2.1.m1.1b"><ci id="S3.SS5.SSS1.Px6.p2.1.m1.1.1.cmml" xref="S3.SS5.SSS1.Px6.p2.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px6.p2.1.m1.1c">r</annotation></semantics></math>를 찾을 수 없으면 모든 관계 클래스로 확장된다.</p>
</div>
<figure id="S3.T11" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 11:</span>KLUE-RE의 Relation distribution.</figcaption>
<table id="S3.T11.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T11.1.1" class="ltx_tr">
<td id="S3.T11.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T11.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T11.1.1.2.1" class="ltx_text ltx_font_bold">Train</span></td>
<td id="S3.T11.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T11.1.1.3.1" class="ltx_text ltx_font_bold">Dev</span></td>
<td id="S3.T11.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T11.1.1.4.1" class="ltx_text ltx_font_bold">Test</span></td>
</tr>
<tr id="S3.T11.1.2" class="ltx_tr">
<td id="S3.T11.1.2.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.2.1.1" class="ltx_text ltx_font_bold">Relation Class</span></td>
<td id="S3.T11.1.2.2" class="ltx_td ltx_align_center ltx_border_t">Count</td>
<td id="S3.T11.1.2.3" class="ltx_td ltx_align_center ltx_border_t">Ratio</td>
<td id="S3.T11.1.2.4" class="ltx_td ltx_align_center ltx_border_t">Count</td>
<td id="S3.T11.1.2.5" class="ltx_td ltx_align_center ltx_border_t">Ratio</td>
<td id="S3.T11.1.2.6" class="ltx_td ltx_align_center ltx_border_t">Count</td>
<td id="S3.T11.1.2.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">Ratio</td>
</tr>
<tr id="S3.T11.1.3" class="ltx_tr">
<td id="S3.T11.1.3.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T11.1.3.1.1" class="ltx_text ltx_font_italic">no_relation</span></td>
<td id="S3.T11.1.3.2" class="ltx_td ltx_align_center ltx_border_t">9,534</td>
<td id="S3.T11.1.3.3" class="ltx_td ltx_align_center ltx_border_t">29.36%</td>
<td id="S3.T11.1.3.4" class="ltx_td ltx_align_center ltx_border_t">4,631</td>
<td id="S3.T11.1.3.5" class="ltx_td ltx_align_center ltx_border_t">59.64%</td>
<td id="S3.T11.1.3.6" class="ltx_td ltx_align_center ltx_border_t">4,632</td>
<td id="S3.T11.1.3.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">59.64%</td>
</tr>
<tr id="S3.T11.1.4" class="ltx_tr">
<td id="S3.T11.1.4.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T11.1.4.1.1" class="ltx_text ltx_font_italic">org:dissolved</span></td>
<td id="S3.T11.1.4.2" class="ltx_td ltx_align_center ltx_border_t">66</td>
<td id="S3.T11.1.4.3" class="ltx_td ltx_align_center ltx_border_t">0.20%</td>
<td id="S3.T11.1.4.4" class="ltx_td ltx_align_center ltx_border_t">11</td>
<td id="S3.T11.1.4.5" class="ltx_td ltx_align_center ltx_border_t">0.14%</td>
<td id="S3.T11.1.4.6" class="ltx_td ltx_align_center ltx_border_t">10</td>
<td id="S3.T11.1.4.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.13%</td>
</tr>
<tr id="S3.T11.1.5" class="ltx_tr">
<td id="S3.T11.1.5.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.5.1.1" class="ltx_text ltx_font_italic">org:founded</span></td>
<td id="S3.T11.1.5.2" class="ltx_td ltx_align_center">450</td>
<td id="S3.T11.1.5.3" class="ltx_td ltx_align_center">1.39%</td>
<td id="S3.T11.1.5.4" class="ltx_td ltx_align_center">20</td>
<td id="S3.T11.1.5.5" class="ltx_td ltx_align_center">0.26%</td>
<td id="S3.T11.1.5.6" class="ltx_td ltx_align_center">20</td>
<td id="S3.T11.1.5.7" class="ltx_td ltx_nopad_r ltx_align_center">0.26%</td>
</tr>
<tr id="S3.T11.1.6" class="ltx_tr">
<td id="S3.T11.1.6.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.6.1.1" class="ltx_text ltx_font_italic">org:place_of_headquarters</span></td>
<td id="S3.T11.1.6.2" class="ltx_td ltx_align_center">1,195</td>
<td id="S3.T11.1.6.3" class="ltx_td ltx_align_center">3.68%</td>
<td id="S3.T11.1.6.4" class="ltx_td ltx_align_center">194</td>
<td id="S3.T11.1.6.5" class="ltx_td ltx_align_center">2.50%</td>
<td id="S3.T11.1.6.6" class="ltx_td ltx_align_center">193</td>
<td id="S3.T11.1.6.7" class="ltx_td ltx_nopad_r ltx_align_center">2.49%</td>
</tr>
<tr id="S3.T11.1.7" class="ltx_tr">
<td id="S3.T11.1.7.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.7.1.1" class="ltx_text ltx_font_italic">org:alternate_names</span></td>
<td id="S3.T11.1.7.2" class="ltx_td ltx_align_center">1,320</td>
<td id="S3.T11.1.7.3" class="ltx_td ltx_align_center">4.07%</td>
<td id="S3.T11.1.7.4" class="ltx_td ltx_align_center">78</td>
<td id="S3.T11.1.7.5" class="ltx_td ltx_align_center">1.00%</td>
<td id="S3.T11.1.7.6" class="ltx_td ltx_align_center">77</td>
<td id="S3.T11.1.7.7" class="ltx_td ltx_nopad_r ltx_align_center">0.99%</td>
</tr>
<tr id="S3.T11.1.8" class="ltx_tr">
<td id="S3.T11.1.8.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.8.1.1" class="ltx_text ltx_font_italic">org:member_of</span></td>
<td id="S3.T11.1.8.2" class="ltx_td ltx_align_center">1,866</td>
<td id="S3.T11.1.8.3" class="ltx_td ltx_align_center">5.75%</td>
<td id="S3.T11.1.8.4" class="ltx_td ltx_align_center">104</td>
<td id="S3.T11.1.8.5" class="ltx_td ltx_align_center">1.34%</td>
<td id="S3.T11.1.8.6" class="ltx_td ltx_align_center">105</td>
<td id="S3.T11.1.8.7" class="ltx_td ltx_nopad_r ltx_align_center">1.35%</td>
</tr>
<tr id="S3.T11.1.9" class="ltx_tr">
<td id="S3.T11.1.9.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.9.1.1" class="ltx_text ltx_font_italic">org:members</span></td>
<td id="S3.T11.1.9.2" class="ltx_td ltx_align_center">420</td>
<td id="S3.T11.1.9.3" class="ltx_td ltx_align_center">1.29%</td>
<td id="S3.T11.1.9.4" class="ltx_td ltx_align_center">122</td>
<td id="S3.T11.1.9.5" class="ltx_td ltx_align_center">1.57%</td>
<td id="S3.T11.1.9.6" class="ltx_td ltx_align_center">122</td>
<td id="S3.T11.1.9.7" class="ltx_td ltx_nopad_r ltx_align_center">1.57%</td>
</tr>
<tr id="S3.T11.1.10" class="ltx_tr">
<td id="S3.T11.1.10.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.10.1.1" class="ltx_text ltx_font_italic">org:political/religious_affiliation</span></td>
<td id="S3.T11.1.10.2" class="ltx_td ltx_align_center">98</td>
<td id="S3.T11.1.10.3" class="ltx_td ltx_align_center">0.30%</td>
<td id="S3.T11.1.10.4" class="ltx_td ltx_align_center">13</td>
<td id="S3.T11.1.10.5" class="ltx_td ltx_align_center">0.17%</td>
<td id="S3.T11.1.10.6" class="ltx_td ltx_align_center">13</td>
<td id="S3.T11.1.10.7" class="ltx_td ltx_nopad_r ltx_align_center">0.17%</td>
</tr>
<tr id="S3.T11.1.11" class="ltx_tr">
<td id="S3.T11.1.11.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.11.1.1" class="ltx_text ltx_font_italic">org:product</span></td>
<td id="S3.T11.1.11.2" class="ltx_td ltx_align_center">380</td>
<td id="S3.T11.1.11.3" class="ltx_td ltx_align_center">1.17%</td>
<td id="S3.T11.1.11.4" class="ltx_td ltx_align_center">235</td>
<td id="S3.T11.1.11.5" class="ltx_td ltx_align_center">3.03%</td>
<td id="S3.T11.1.11.6" class="ltx_td ltx_align_center">235</td>
<td id="S3.T11.1.11.7" class="ltx_td ltx_nopad_r ltx_align_center">3.03%</td>
</tr>
<tr id="S3.T11.1.12" class="ltx_tr">
<td id="S3.T11.1.12.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.12.1.1" class="ltx_text ltx_font_italic">org:founded_by</span></td>
<td id="S3.T11.1.12.2" class="ltx_td ltx_align_center">155</td>
<td id="S3.T11.1.12.3" class="ltx_td ltx_align_center">0.48%</td>
<td id="S3.T11.1.12.4" class="ltx_td ltx_align_center">11</td>
<td id="S3.T11.1.12.5" class="ltx_td ltx_align_center">0.14%</td>
<td id="S3.T11.1.12.6" class="ltx_td ltx_align_center">11</td>
<td id="S3.T11.1.12.7" class="ltx_td ltx_nopad_r ltx_align_center">0.14%</td>
</tr>
<tr id="S3.T11.1.13" class="ltx_tr">
<td id="S3.T11.1.13.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.13.1.1" class="ltx_text ltx_font_italic">org:top_members/employees</span></td>
<td id="S3.T11.1.13.2" class="ltx_td ltx_align_center">4,284</td>
<td id="S3.T11.1.13.3" class="ltx_td ltx_align_center">13.19%</td>
<td id="S3.T11.1.13.4" class="ltx_td ltx_align_center">513</td>
<td id="S3.T11.1.13.5" class="ltx_td ltx_align_center">6.61%</td>
<td id="S3.T11.1.13.6" class="ltx_td ltx_align_center">514</td>
<td id="S3.T11.1.13.7" class="ltx_td ltx_nopad_r ltx_align_center">6.62%</td>
</tr>
<tr id="S3.T11.1.14" class="ltx_tr">
<td id="S3.T11.1.14.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.14.1.1" class="ltx_text ltx_font_italic">org:number_of_employees/members</span></td>
<td id="S3.T11.1.14.2" class="ltx_td ltx_align_center">48</td>
<td id="S3.T11.1.14.3" class="ltx_td ltx_align_center">0.15%</td>
<td id="S3.T11.1.14.4" class="ltx_td ltx_align_center">17</td>
<td id="S3.T11.1.14.5" class="ltx_td ltx_align_center">0.22%</td>
<td id="S3.T11.1.14.6" class="ltx_td ltx_align_center">18</td>
<td id="S3.T11.1.14.7" class="ltx_td ltx_nopad_r ltx_align_center">0.23%</td>
</tr>
<tr id="S3.T11.1.15" class="ltx_tr">
<td id="S3.T11.1.15.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T11.1.15.1.1" class="ltx_text ltx_font_italic">per:date_of_birth</span></td>
<td id="S3.T11.1.15.2" class="ltx_td ltx_align_center ltx_border_t">1,130</td>
<td id="S3.T11.1.15.3" class="ltx_td ltx_align_center ltx_border_t">3.48%</td>
<td id="S3.T11.1.15.4" class="ltx_td ltx_align_center ltx_border_t">12</td>
<td id="S3.T11.1.15.5" class="ltx_td ltx_align_center ltx_border_t">0.15%</td>
<td id="S3.T11.1.15.6" class="ltx_td ltx_align_center ltx_border_t">12</td>
<td id="S3.T11.1.15.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">0.15%</td>
</tr>
<tr id="S3.T11.1.16" class="ltx_tr">
<td id="S3.T11.1.16.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.16.1.1" class="ltx_text ltx_font_italic">per:date_of_death</span></td>
<td id="S3.T11.1.16.2" class="ltx_td ltx_align_center">418</td>
<td id="S3.T11.1.16.3" class="ltx_td ltx_align_center">1.29%</td>
<td id="S3.T11.1.16.4" class="ltx_td ltx_align_center">13</td>
<td id="S3.T11.1.16.5" class="ltx_td ltx_align_center">0.17%</td>
<td id="S3.T11.1.16.6" class="ltx_td ltx_align_center">13</td>
<td id="S3.T11.1.16.7" class="ltx_td ltx_nopad_r ltx_align_center">0.17%</td>
</tr>
<tr id="S3.T11.1.17" class="ltx_tr">
<td id="S3.T11.1.17.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.17.1.1" class="ltx_text ltx_font_italic">per:place_of_birth</span></td>
<td id="S3.T11.1.17.2" class="ltx_td ltx_align_center">166</td>
<td id="S3.T11.1.17.3" class="ltx_td ltx_align_center">0.51%</td>
<td id="S3.T11.1.17.4" class="ltx_td ltx_align_center">11</td>
<td id="S3.T11.1.17.5" class="ltx_td ltx_align_center">0.14%</td>
<td id="S3.T11.1.17.6" class="ltx_td ltx_align_center">10</td>
<td id="S3.T11.1.17.7" class="ltx_td ltx_nopad_r ltx_align_center">0.13%</td>
</tr>
<tr id="S3.T11.1.18" class="ltx_tr">
<td id="S3.T11.1.18.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.18.1.1" class="ltx_text ltx_font_italic">per:place_of_death</span></td>
<td id="S3.T11.1.18.2" class="ltx_td ltx_align_center">40</td>
<td id="S3.T11.1.18.3" class="ltx_td ltx_align_center">0.12%</td>
<td id="S3.T11.1.18.4" class="ltx_td ltx_align_center">10</td>
<td id="S3.T11.1.18.5" class="ltx_td ltx_align_center">0.13%</td>
<td id="S3.T11.1.18.6" class="ltx_td ltx_align_center">11</td>
<td id="S3.T11.1.18.7" class="ltx_td ltx_nopad_r ltx_align_center">0.14%</td>
</tr>
<tr id="S3.T11.1.19" class="ltx_tr">
<td id="S3.T11.1.19.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.19.1.1" class="ltx_text ltx_font_italic">per:place_of_residence</span></td>
<td id="S3.T11.1.19.2" class="ltx_td ltx_align_center">193</td>
<td id="S3.T11.1.19.3" class="ltx_td ltx_align_center">0.59%</td>
<td id="S3.T11.1.19.4" class="ltx_td ltx_align_center">124</td>
<td id="S3.T11.1.19.5" class="ltx_td ltx_align_center">1.60%</td>
<td id="S3.T11.1.19.6" class="ltx_td ltx_align_center">125</td>
<td id="S3.T11.1.19.7" class="ltx_td ltx_nopad_r ltx_align_center">1.61%</td>
</tr>
<tr id="S3.T11.1.20" class="ltx_tr">
<td id="S3.T11.1.20.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.20.1.1" class="ltx_text ltx_font_italic">per:origin</span></td>
<td id="S3.T11.1.20.2" class="ltx_td ltx_align_center">1,234</td>
<td id="S3.T11.1.20.3" class="ltx_td ltx_align_center">3.80%</td>
<td id="S3.T11.1.20.4" class="ltx_td ltx_align_center">118</td>
<td id="S3.T11.1.20.5" class="ltx_td ltx_align_center">1.52%</td>
<td id="S3.T11.1.20.6" class="ltx_td ltx_align_center">118</td>
<td id="S3.T11.1.20.7" class="ltx_td ltx_nopad_r ltx_align_center">1.52%</td>
</tr>
<tr id="S3.T11.1.21" class="ltx_tr">
<td id="S3.T11.1.21.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.21.1.1" class="ltx_text ltx_font_italic">per:employee_of</span></td>
<td id="S3.T11.1.21.2" class="ltx_td ltx_align_center">3,573</td>
<td id="S3.T11.1.21.3" class="ltx_td ltx_align_center">11.00%</td>
<td id="S3.T11.1.21.4" class="ltx_td ltx_align_center">242</td>
<td id="S3.T11.1.21.5" class="ltx_td ltx_align_center">3.12%</td>
<td id="S3.T11.1.21.6" class="ltx_td ltx_align_center">241</td>
<td id="S3.T11.1.21.7" class="ltx_td ltx_nopad_r ltx_align_center">3.10%</td>
</tr>
<tr id="S3.T11.1.22" class="ltx_tr">
<td id="S3.T11.1.22.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.22.1.1" class="ltx_text ltx_font_italic">per:schools_attended</span></td>
<td id="S3.T11.1.22.2" class="ltx_td ltx_align_center">82</td>
<td id="S3.T11.1.22.3" class="ltx_td ltx_align_center">0.25%</td>
<td id="S3.T11.1.22.4" class="ltx_td ltx_align_center">11</td>
<td id="S3.T11.1.22.5" class="ltx_td ltx_align_center">0.14%</td>
<td id="S3.T11.1.22.6" class="ltx_td ltx_align_center">11</td>
<td id="S3.T11.1.22.7" class="ltx_td ltx_nopad_r ltx_align_center">0.14%</td>
</tr>
<tr id="S3.T11.1.23" class="ltx_tr">
<td id="S3.T11.1.23.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.23.1.1" class="ltx_text ltx_font_italic">per:alternate_names</span></td>
<td id="S3.T11.1.23.2" class="ltx_td ltx_align_center">1,001</td>
<td id="S3.T11.1.23.3" class="ltx_td ltx_align_center">3.08%</td>
<td id="S3.T11.1.23.4" class="ltx_td ltx_align_center">104</td>
<td id="S3.T11.1.23.5" class="ltx_td ltx_align_center">1.34%</td>
<td id="S3.T11.1.23.6" class="ltx_td ltx_align_center">103</td>
<td id="S3.T11.1.23.7" class="ltx_td ltx_nopad_r ltx_align_center">1.33%</td>
</tr>
<tr id="S3.T11.1.24" class="ltx_tr">
<td id="S3.T11.1.24.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.24.1.1" class="ltx_text ltx_font_italic">per:parents</span></td>
<td id="S3.T11.1.24.2" class="ltx_td ltx_align_center">520</td>
<td id="S3.T11.1.24.3" class="ltx_td ltx_align_center">1.60%</td>
<td id="S3.T11.1.24.4" class="ltx_td ltx_align_center">27</td>
<td id="S3.T11.1.24.5" class="ltx_td ltx_align_center">0.35%</td>
<td id="S3.T11.1.24.6" class="ltx_td ltx_align_center">27</td>
<td id="S3.T11.1.24.7" class="ltx_td ltx_nopad_r ltx_align_center">0.35%</td>
</tr>
<tr id="S3.T11.1.25" class="ltx_tr">
<td id="S3.T11.1.25.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.25.1.1" class="ltx_text ltx_font_italic">per:children</span></td>
<td id="S3.T11.1.25.2" class="ltx_td ltx_align_center">304</td>
<td id="S3.T11.1.25.3" class="ltx_td ltx_align_center">0.94%</td>
<td id="S3.T11.1.25.4" class="ltx_td ltx_align_center">27</td>
<td id="S3.T11.1.25.5" class="ltx_td ltx_align_center">0.35%</td>
<td id="S3.T11.1.25.6" class="ltx_td ltx_align_center">27</td>
<td id="S3.T11.1.25.7" class="ltx_td ltx_nopad_r ltx_align_center">0.35%</td>
</tr>
<tr id="S3.T11.1.26" class="ltx_tr">
<td id="S3.T11.1.26.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.26.1.1" class="ltx_text ltx_font_italic">per:siblings</span></td>
<td id="S3.T11.1.26.2" class="ltx_td ltx_align_center">136</td>
<td id="S3.T11.1.26.3" class="ltx_td ltx_align_center">0.42%</td>
<td id="S3.T11.1.26.4" class="ltx_td ltx_align_center">24</td>
<td id="S3.T11.1.26.5" class="ltx_td ltx_align_center">0.31%</td>
<td id="S3.T11.1.26.6" class="ltx_td ltx_align_center">24</td>
<td id="S3.T11.1.26.7" class="ltx_td ltx_nopad_r ltx_align_center">0.31%</td>
</tr>
<tr id="S3.T11.1.27" class="ltx_tr">
<td id="S3.T11.1.27.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.27.1.1" class="ltx_text ltx_font_italic">per:spouse</span></td>
<td id="S3.T11.1.27.2" class="ltx_td ltx_align_center">795</td>
<td id="S3.T11.1.27.3" class="ltx_td ltx_align_center">2.45%</td>
<td id="S3.T11.1.27.4" class="ltx_td ltx_align_center">41</td>
<td id="S3.T11.1.27.5" class="ltx_td ltx_align_center">0.53%</td>
<td id="S3.T11.1.27.6" class="ltx_td ltx_align_center">40</td>
<td id="S3.T11.1.27.7" class="ltx_td ltx_nopad_r ltx_align_center">0.52%</td>
</tr>
<tr id="S3.T11.1.28" class="ltx_tr">
<td id="S3.T11.1.28.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.28.1.1" class="ltx_text ltx_font_italic">per:other_family</span></td>
<td id="S3.T11.1.28.2" class="ltx_td ltx_align_center">190</td>
<td id="S3.T11.1.28.3" class="ltx_td ltx_align_center">0.59%</td>
<td id="S3.T11.1.28.4" class="ltx_td ltx_align_center">34</td>
<td id="S3.T11.1.28.5" class="ltx_td ltx_align_center">0.44%</td>
<td id="S3.T11.1.28.6" class="ltx_td ltx_align_center">35</td>
<td id="S3.T11.1.28.7" class="ltx_td ltx_nopad_r ltx_align_center">0.45%</td>
</tr>
<tr id="S3.T11.1.29" class="ltx_tr">
<td id="S3.T11.1.29.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.29.1.1" class="ltx_text ltx_font_italic">per:colleagues</span></td>
<td id="S3.T11.1.29.2" class="ltx_td ltx_align_center">534</td>
<td id="S3.T11.1.29.3" class="ltx_td ltx_align_center">1.64%</td>
<td id="S3.T11.1.29.4" class="ltx_td ltx_align_center">220</td>
<td id="S3.T11.1.29.5" class="ltx_td ltx_align_center">2.83%</td>
<td id="S3.T11.1.29.6" class="ltx_td ltx_align_center">220</td>
<td id="S3.T11.1.29.7" class="ltx_td ltx_nopad_r ltx_align_center">2.83%</td>
</tr>
<tr id="S3.T11.1.30" class="ltx_tr">
<td id="S3.T11.1.30.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.30.1.1" class="ltx_text ltx_font_italic">per:product</span></td>
<td id="S3.T11.1.30.2" class="ltx_td ltx_align_center">139</td>
<td id="S3.T11.1.30.3" class="ltx_td ltx_align_center">0.43%</td>
<td id="S3.T11.1.30.4" class="ltx_td ltx_align_center">67</td>
<td id="S3.T11.1.30.5" class="ltx_td ltx_align_center">0.86%</td>
<td id="S3.T11.1.30.6" class="ltx_td ltx_align_center">69</td>
<td id="S3.T11.1.30.7" class="ltx_td ltx_nopad_r ltx_align_center">0.89%</td>
</tr>
<tr id="S3.T11.1.31" class="ltx_tr">
<td id="S3.T11.1.31.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.31.1.1" class="ltx_text ltx_font_italic">per:religion</span></td>
<td id="S3.T11.1.31.2" class="ltx_td ltx_align_center">96</td>
<td id="S3.T11.1.31.3" class="ltx_td ltx_align_center">0.30%</td>
<td id="S3.T11.1.31.4" class="ltx_td ltx_align_center">13</td>
<td id="S3.T11.1.31.5" class="ltx_td ltx_align_center">0.17%</td>
<td id="S3.T11.1.31.6" class="ltx_td ltx_align_center">12</td>
<td id="S3.T11.1.31.7" class="ltx_td ltx_nopad_r ltx_align_center">0.15%</td>
</tr>
<tr id="S3.T11.1.32" class="ltx_tr">
<td id="S3.T11.1.32.1" class="ltx_td ltx_align_left"><span id="S3.T11.1.32.1.1" class="ltx_text ltx_font_italic">per:title</span></td>
<td id="S3.T11.1.32.2" class="ltx_td ltx_align_center">2,103</td>
<td id="S3.T11.1.32.3" class="ltx_td ltx_align_center">6.48%</td>
<td id="S3.T11.1.32.4" class="ltx_td ltx_align_center">718</td>
<td id="S3.T11.1.32.5" class="ltx_td ltx_align_center">9.25%</td>
<td id="S3.T11.1.32.6" class="ltx_td ltx_align_center">718</td>
<td id="S3.T11.1.32.7" class="ltx_td ltx_nopad_r ltx_align_center">9.25%</td>
</tr>
<tr id="S3.T11.1.33" class="ltx_tr">
<td id="S3.T11.1.33.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T11.1.33.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T11.1.33.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T11.1.33.2.1" class="ltx_text ltx_font_bold">32,470</span></td>
<td id="S3.T11.1.33.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">100.00%</td>
<td id="S3.T11.1.33.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T11.1.33.4.1" class="ltx_text ltx_font_bold">7,765</span></td>
<td id="S3.T11.1.33.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">100.00%</td>
<td id="S3.T11.1.33.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T11.1.33.6.1" class="ltx_text ltx_font_bold">7,766</span></td>
<td id="S3.T11.1.33.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t">100.00%</td>
</tr>
</tbody></table>
</figure>
<div id="S3.SS5.SSS1.Px6.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.Px6.p3.1">우리는 다수가 투표한 라벨을 금 라벨로 받아들인다. 다수 레이블이 없는 각 예제에 대해 상위 30명의 주석자는 주석이 달린 레이블에서 최종 레이블을 선택합니다. 우리는 혐오 발언, 편파적이거나 개인 정보 보호 문제가 있다고 보고된 사례를 포함하지 않는다. 주석이 달린 데이터 세트에 대한 주석 간 합의(Krippendorff의 <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS5.SSS1.Px6.p3.1.m1.1"><semantics id="S3.SS5.SSS1.Px6.p3.1.m1.1a"><mi id="S3.SS5.SSS1.Px6.p3.1.m1.1.1" xref="S3.SS5.SSS1.Px6.p3.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS1.Px6.p3.1.m1.1b"><ci id="S3.SS5.SSS1.Px6.p3.1.m1.1.1.cmml" xref="S3.SS5.SSS1.Px6.p3.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS1.Px6.p3.1.m1.1c">\alpha</annotation></semantics></math>)는 0.701 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib67" title="">67</a>]</cite>이다.</p>
</div>
</section>
<section id="S3.SS5.SSS1.Px7" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS5.SSS1.Px7.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.Px7.p1.1">KLUE-RE는 훈련 32,470개, 개발 7,765개, 시험예 7,766개로 구성되어 있다. 실제 시나리오의 경우 개발 및 테스트 세트를 구축할 때 균일한 샘플링에서 생성된 예제만 사용합니다. 테스트 세트에서, 우리는 트레이닝 세트에 나타나지 않는 엔티티들을 갖는 문장들만을 포함한다.</p>
</div>
<div id="S3.SS5.SSS1.Px7.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS1.Px7.p2.1">KLUE-RE에서 문장의 평균 길이는 화이트 스페이스를 포함하여 95.9자 이다. 개체 유형의 비율은 PER(38.1%), ORG(36.3%), LOC(6.2%), DAT(6.2%), POH(11.9%), NOH(1.3%)이다. 관계 클래스의 분포는 표 <a class="ltx_ref" href="#S3.T11" title="Table 11 ‣ 5. Annotate Relations ‣ 3.5.1 Data Construction ‣ 3.5 Relation Extraction (RE) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">11</span></a>와 같다.</p>
</div>
</section>
</section>
<section id="S3.SS5.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.2 </span>Evaluation Metrics</h4>

<div id="S3.SS5.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS2.p1.1">KLUE-RE 평가지표는 1) 기존 사례들에 대한 미시적 F1 점수, 2) 모든 클래스에 대한 정밀-리콜 곡선(AUPRC) 아래의 영역이다. 마이크로 F1 점수는 마이크로 정밀도와 마이크로 리콜의 조화 평균이다. 모든 계층의 집계된 기여도의 F1 점수를 측정한다. 각 표본에 동일한 중요성을 부여하므로 자연스럽게 다수 집단에 더 많은 가중치를 부여한다. 부정적인 클래스를 예측하는 데 더 중점을 두는 모델을 장려하지 않기 위해 이 메트릭에 대한 지배적인 클래스(<math alttext="no\_relation" class="ltx_Math" display="inline" id="S3.SS5.SSS2.p1.1.m1.1"><semantics id="S3.SS5.SSS2.p1.1.m1.1a"><mrow id="S3.SS5.SSS2.p1.1.m1.1.1" xref="S3.SS5.SSS2.p1.1.m1.1.1.cmml"><mi id="S3.SS5.SSS2.p1.1.m1.1.1.2" xref="S3.SS5.SSS2.p1.1.m1.1.1.2.cmml">n</mi><mo id="S3.SS5.SSS2.p1.1.m1.1.1.1" lspace="0em" rspace="0em" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.3" xref="S3.SS5.SSS2.p1.1.m1.1.1.3.cmml">o</mi><mo id="S3.SS5.SSS2.p1.1.m1.1.1.1a" lspace="0em" rspace="0em" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.4" mathvariant="normal" xref="S3.SS5.SSS2.p1.1.m1.1.1.4.cmml">_</mi><mo id="S3.SS5.SSS2.p1.1.m1.1.1.1b" lspace="0em" rspace="0em" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.5" xref="S3.SS5.SSS2.p1.1.m1.1.1.5.cmml">r</mi><mo id="S3.SS5.SSS2.p1.1.m1.1.1.1c" lspace="0em" rspace="0em" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.6" xref="S3.SS5.SSS2.p1.1.m1.1.1.6.cmml">e</mi><mo id="S3.SS5.SSS2.p1.1.m1.1.1.1d" lspace="0em" rspace="0em" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.7" xref="S3.SS5.SSS2.p1.1.m1.1.1.7.cmml">l</mi><mo id="S3.SS5.SSS2.p1.1.m1.1.1.1e" lspace="0em" rspace="0em" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.8" xref="S3.SS5.SSS2.p1.1.m1.1.1.8.cmml">a</mi><mo id="S3.SS5.SSS2.p1.1.m1.1.1.1f" lspace="0em" rspace="0em" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.9" xref="S3.SS5.SSS2.p1.1.m1.1.1.9.cmml">t</mi><mo id="S3.SS5.SSS2.p1.1.m1.1.1.1g" lspace="0em" rspace="0em" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.10" xref="S3.SS5.SSS2.p1.1.m1.1.1.10.cmml">i</mi><mo id="S3.SS5.SSS2.p1.1.m1.1.1.1h" lspace="0em" rspace="0em" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.11" xref="S3.SS5.SSS2.p1.1.m1.1.1.11.cmml">o</mi><mo id="S3.SS5.SSS2.p1.1.m1.1.1.1i" lspace="0em" rspace="0em" xref="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml">​</mo><mi id="S3.SS5.SSS2.p1.1.m1.1.1.12" xref="S3.SS5.SSS2.p1.1.m1.1.1.12.cmml">n</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS2.p1.1.m1.1b"><apply id="S3.SS5.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1"><times id="S3.SS5.SSS2.p1.1.m1.1.1.1.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.1"></times><ci id="S3.SS5.SSS2.p1.1.m1.1.1.2.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.2">𝑛</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.3.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.3">𝑜</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.4.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.4">_</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.5.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.5">𝑟</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.6.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.6">𝑒</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.7.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.7">𝑙</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.8.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.8">𝑎</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.9.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.9">𝑡</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.10.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.10">𝑖</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.11.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.11">𝑜</ci><ci id="S3.SS5.SSS2.p1.1.m1.1.1.12.cmml" xref="S3.SS5.SSS2.p1.1.m1.1.1.12">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS2.p1.1.m1.1c">no\_relation</annotation></semantics></math>)를 제거한다. AUPRC는 x축은 재현율이고 y축은 모든 관계 클래스의 정밀도인 정밀도-리콜 곡선 아래의 평균화된 영역이다. 중요한 긍정적인 예가 거의 발생하지 않는 불균형 데이터 설정에 유용한 메트릭입니다.</p>
</div>
</section>
<section id="S3.SS5.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.3 </span>Related Work</h4>

<div id="S3.SS5.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS3.p1.1">많은 연구자들은 기계 학습 기법을 적용하여 일반 텍스트에서 개체 쌍 간의 관계적 사실을 자동으로 식별함으로써 비정형 텍스트에서 KB를 구축하려고 시도한다. <cite class="ltx_cite ltx_citemacro_citet">Doddington et al. [<a class="ltx_ref" href="#bib.bib31" title="">31</a>]</cite> 및 <cite class="ltx_cite ltx_citemacro_citet">Hendrickx et al. [<a class="ltx_ref" href="#bib.bib52" title="">52</a>]</cite>는 일반 도메인 텍스트에 대한 상대적으로 적은 수의 관계 클래스를 포함하여 이러한 모델을 훈련하기 위해 영어 데이터 세트를 구성한다. <cite class="ltx_cite ltx_citemacro_citet">Mintz et al. [<a class="ltx_ref" href="#bib.bib91" title="">91</a>]</cite>는 더 나아가 일반 텍스트를 KB의 스키마에 정렬하여 자동으로 주석을 달도록 원거리 감독을 제안한다. 이를 통해 연구자들은 RE 데이터 세트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib116" title="">116</a>, <a class="ltx_ref" href="#bib.bib153" title="">153</a>, <a class="ltx_ref" href="#bib.bib48" title="">48</a>, <a class="ltx_ref" href="#bib.bib147" title="">147</a>, <a class="ltx_ref" href="#bib.bib149" title="">149</a>]</cite>의 크기를 확장할 수 있다. 이러한 최근 연구 중 TACRED <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib153" title="">153</a>]</cite>는 주로 개인 및 조직 엔티티에 초점을 맞춘 인기 관계 스키마 TAC-KBP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib87" title="">87</a>]</cite>를 기반으로 구축된 가장 널리 사용되는 데이터 세트이다. 구체적으로, TACRED는 42개의 관계 클래스로 주석이 달린 106,264개의 예를 포함한다. <cite class="ltx_cite ltx_citemacro_citet">Yu et al. [<a class="ltx_ref" href="#bib.bib149" title="">149</a>]</cite>는 또한 대화 도메인에 적응된 36개의 관계 클래스를 얻기 위해 TAC-KBP를 정제하여 대화 기반 RE 태스크를 제안한다. 또한 TAC-KBP를 사용하여 관계 스키마를 구축하고 상황에 맞게 수정한다.</p>
</div>
<div id="S3.SS5.SSS3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS3.p2.1">영어가 아닌 언어의 경우, 중국어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib141" title="">141</a>]</cite>, 독일어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib121" title="">121</a>]</cite>, 프랑스어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib55" title="">55</a>]</cite> 등 현존하는 벤치마크는 거의 없다. <cite class="ltx_cite ltx_citemacro_citet">Nam et al. [<a class="ltx_ref" href="#bib.bib93" title="">93</a>]</cite>는 원격으로 감독하여 예를 자동으로 생성하고 주석을 달기 위해 한국어로 된 RE 데이터 세트를 제안한다. 그러나 상대적으로 작은 테스트 세트(<math alttext="\sim" class="ltx_Math" display="inline" id="S3.SS5.SSS3.p2.1.m1.1"><semantics id="S3.SS5.SSS3.p2.1.m1.1a"><mo id="S3.SS5.SSS3.p2.1.m1.1.1" xref="S3.SS5.SSS3.p2.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS3.p2.1.m1.1b"><csymbol cd="latexml" id="S3.SS5.SSS3.p2.1.m1.1.1.cmml" xref="S3.SS5.SSS3.p2.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS3.p2.1.m1.1c">\sim</annotation></semantics></math>3k)를 가지고 있어 전체 49개의 관계 클래스에 대한 성능을 제대로 평가하기 어렵다. 더욱이, 부정적인 클래스가 없기 때문에(<span class="ltx_text ltx_font_italic" id="S3.SS5.SSS3.p2.1.1">no_relation</span> in ours), 모델들이 잘못된 긍정 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib153" title="">153</a>]</cite>를 지나치게 예측하도록 부추길 가능성이 있다. 따라서 우리는 한국어 모델을 제대로 평가하기 위해 KLUE-RE를 표준 대규모 RE 벤치마크로 고려한다.</p>
</div>
</section>
<section id="S3.SS5.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.5.4 </span>Conclusion</h4>

<div id="S3.SS5.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS5.SSS4.p1.1">본 논문에서는 한국어를 위한 대규모 인간 주석이 있는 RE 벤치마크인 KLUE-RE를 제안한다. 본 논문에서는 대규모 및 최신 한국형 KB의 부족을 극복하기 위해 효과적인 주석 기법과 결합된 효율적인 후보 수집 방법을 설계한다. KLUE-RE는 온라인 정보 추출에 사용될 뿐만 아니라 비정형 텍스트로부터 대규모 지식 그래프를 구축하는 데 기여할 수 있다. 따라서 KLUE-RE는 한국어로 지속적으로 성장하는 대규모 공공 KB를 구축하는 출발점이 될 뿐만 아니라 귀중한 한국 NLU 벤치마크가 될 것으로 기대한다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Dependency Parsing (DP)</h3>

<div id="S3.SS6.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS6.p1.1">의존 구문 분석(DP)은 단어 간의 관계 정보를 찾는 것을 목표로 하는 NLP 작업이다. 그것은 문장의 구문 특징을 포착할 수 있는 능력 때문에 많은 NLP 시스템에서 중요한 구성 요소였다. 구문적 특징 측면에서 언어 모델의 표현력을 평가하기 위해 KLUE에 DP를 포함한다.</p>
</div>
<div id="S3.SS6.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS6.p2.1">형식적으로, 의존성 파서는 의존성 문법 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib29" title="">29</a>, <a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite>에 기초하여 입력 문장의 그래프 구조를 예측한다. 일반적으로 구문 분석된 트리는 종속성 호, 종속성 호를 그들의 머리에 연결하는 것, 종속성 호와 그들의 머리 사이의 관계를 나타내는 호에 부착된 종속성 레이블로 구성된다.</p>
</div>
<figure id="S3.F5" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2105.09680/assets/figs/dp-fig1.png" id="S3.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="167" height="100" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 5:</span> 의존 구문 분석의 예, "Chul-soo ate a apple"로 번역됩니다.</figcaption>
</figure>
<div id="S3.SS6.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS6.p3.1">예를 들어, 도<a class="ltx_ref" href="#S3.F5" title="Figure 5 ‣ 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">5</span></a>는 예시 문장의 파싱된 결과를 보여준다: “철수는 사과 먹었다(철수는 사과를 먹었다.)” 트리에서 화살표는 <span class="ltx_text ltx_font_italic" id="S3.SS6.p3.1.1">head</span>에서 출발하여 해당 <span class="ltx_text ltx_font_italic" id="S3.SS6.p3.1.2">dependents</span>을 가리킵니다. 따라서 ‘철수(철수)’와 ‘사과’는 <span class="ltx_text ltx_font_italic" id="S3.SS6.p3.1.3">dependents</span>의 ‘먹었다(ate)’ 및 '먹었다' (ate)는 ‘철수(철수)’와 ‘사과(사과)’의 <span class="ltx_text ltx_font_italic" id="S3.SS6.p3.1.4">head</span>이다. 또한 '철수(철수)'는 '먹어(에이트)'에 의존한다. "주체" 관계가 있는. 이 종속 관계 레이블을 DEPREL이라고 한다. DEPREL의 경우 9개의 구문 태그와 6개의 함수 태그의 조합으로 구성된 TTA 종속성 주석 방식<span class="ltx_note ltx_role_footnote" id="footnote36"><sup class="ltx_note_mark">36</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">36</sup><span class="ltx_tag ltx_tag_note">36</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aiopen.etri.re.kr/data/003.%EC%9D%98%EC%A1%B4%EA%B5%AC%EB%AC%B8%EB%B6%84%EC%84%9D_%EA%B0%80%EC%9D%B4%EB%93%9C%EB%9D%BC%EC%9D%B8.pdf" target="_blank" title="">https://aiopen.etri.re.kr/data/003.%EC%9D%98%EC%A1%B4%EA%B5%AC%EB%AC%B8%EB%B6%84%EC%84%9D_%EA%B0%80%EC%9D%B4%EB%93%9C%EB%9D%BC%EC%9D%B8.pdf</a></span></span></span>을 따른다.</p>
</div>
<div id="S3.SS6.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS6.p4.1">문장 내의 각 단어들은 한 쌍의 종속 정보(HEAD, DEPREL)를 가지므로, DP는 통상적으로 단어-레벨 시퀀스 태깅 태스크로서 공식화된다. 우리는 라벨이 없는 부착 점수(UAS)와 라벨이 있는 부착 점수(LAS)를 사용하여 모델의 성능을 평가한다. 평가 중 하부에서 누적 빈도가 1%인 레이블은 LAS에 대한 낮은 빈도 레이블의 부정적인 영향을 보상하기 위해 OTHERS 레이블로 그룹화된다.</p>
</div>
<figure id="S3.F6" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2105.09680/assets/figs/dp-fig2.png" id="S3.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="259" height="57" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 6: </span>A demonstration of the KLUE-DP output format using a sentence to translation to “Chul-soo ate a apple.”</figcaption>
</figure>
<div id="S3.SS6.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS6.p5.1">그림 <a class="ltx_ref" href="#S3.F6" title="Figure 6 ‣ 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">6</span></a>와 같이 CoNLL과 같은 형식으로 출력을 나타낸다. 이 형식은 6개의 열로 구성되며, 각 열은 단어 색인(ID), 단어 형태(FORM), 단어 형태의 레마(LEMMA), 품사 태그(POS), 현재 단어의 머리(HEAD), 의존 관계(DEPREL)를 포함한다.</p>
</div>
<section id="S3.SS6.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.6.1 </span>Dataset Construction</h4>

<section id="S3.SS6.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora</h5>

<div id="S3.SS6.SSS1.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS6.SSS1.Px1.p1.1">일반 사용 DP 모델에 적합한 데이터 세트로 코퍼스를 구축하기 위해 공식 텍스트와 비공식 텍스트를 모두 고려한다. 우리는 WIKITREE와 AIRBNB를 소스 코퍼라로 사용한다. 위키트리(WIKITREE)는 뉴스 기사로 구성되어 있으며 문법적으로 건전한 공식 텍스트를 나타낸다. 반면에 AIRBNB는 대부분 웹 텍스트가 포함된 사용자 생성 리뷰로 구성되어 있어 컴포넌트의 빈번한 누락과 자유로운 어순을 보여준다. 우리는 WIKITREE와 AIRBNB에서 동일한 비율의 데이터를 수집하여 데이터 세트가 정제된 서면 문장과 노이즈가 있는 구어체 텍스트를 모두 표현한다.</p>
</div>
</section>
<section id="S3.SS6.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Protocol</h5>

<div id="S3.SS6.SSS1.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS6.SSS1.Px2.p1.1">품사는 문장에서 단어가 문법적으로 어떻게 기능하는지를 나타내므로 종속 관계와 관련성이 높다. POS 정보를 추가적인 구문적 특징으로 활용하기 위해 의존 관계 주석 전에 먼저 말뭉치에 POS를 주석한다. 이를 위해 TTA POS 태깅 가이드라인을 따른다. <span class="ltx_note ltx_role_footnote" id="footnote37"><sup class="ltx_note_mark">37</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">37</sup><span class="ltx_tag ltx_tag_note">37</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aiopen.etri.re.kr/data/001.%ED%98%95%ED%83%9C%EC%86%8C%EB%B6%84%EC%84%9D_%EA%B0%80%EC%9D%B4%EB%93%9C%EB%9D%BC%EC%9D%B8.pdf" target="_blank" title="">https://aiopen.etri.re.kr/data/001.%ED%98%95%ED%83%9C%EC%86%8C%EB%B6%84%EC%84%9D_%EA%B0%80%EC%9D%B4%EB%93%9C%EB%9D%BC%EC%9D%B8.pdf</a></span></span></span> DP 말뭉치를 구성할 때 주석이 달린 POS 정보를 사용한다.</p>
</div>
<div id="S3.SS6.SSS1.Px2.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS6.SSS1.Px2.p2.1">다음으로 의존 관계 주석에 대한 원래 TTA DP 지침을 수정한다. 원래 지침에는 서면 데이터에 주석을 달 수 있는 지침만 포함되어 있기 때문에 음성 및 웹 데이터에 대한 가이드를 추가합니다.</p>
</div>
<figure id="S3.T12" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 12:</span>TTA DP guideline의 Syntax and function tagset (label types).</figcaption>
<table id="S3.T12.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T12.1.1" class="ltx_tr">
<td id="S3.T12.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T12.1.1.1.1" class="ltx_text ltx_font_bold">Label Type</span></td>
<td id="S3.T12.1.1.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt"><span id="S3.T12.1.1.2.1" class="ltx_text ltx_font_bold">Description</span></td>
</tr>
<tr id="S3.T12.1.2" class="ltx_tr">
<td id="S3.T12.1.2.1" class="ltx_td ltx_align_left ltx_border_t" colspan="2">Syntax</td>
</tr>
<tr id="S3.T12.1.3" class="ltx_tr">
<td id="S3.T12.1.3.1" class="ltx_td ltx_align_left ltx_border_t">NP</td>
<td id="S3.T12.1.3.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Noun Phrase</td>
</tr>
<tr id="S3.T12.1.4" class="ltx_tr">
<td id="S3.T12.1.4.1" class="ltx_td ltx_align_left">VP</td>
<td id="S3.T12.1.4.2" class="ltx_td ltx_nopad_r ltx_align_left">Verb Phrase</td>
</tr>
<tr id="S3.T12.1.5" class="ltx_tr">
<td id="S3.T12.1.5.1" class="ltx_td ltx_align_left">AP</td>
<td id="S3.T12.1.5.2" class="ltx_td ltx_nopad_r ltx_align_left">Adverb Phrase</td>
</tr>
<tr id="S3.T12.1.6" class="ltx_tr">
<td id="S3.T12.1.6.1" class="ltx_td ltx_align_left">VNP</td>
<td id="S3.T12.1.6.2" class="ltx_td ltx_nopad_r ltx_align_left">Copula Phrase</td>
</tr>
<tr id="S3.T12.1.7" class="ltx_tr">
<td id="S3.T12.1.7.1" class="ltx_td ltx_align_left">DP</td>
<td id="S3.T12.1.7.2" class="ltx_td ltx_nopad_r ltx_align_left">Adnoun Phrase</td>
</tr>
<tr id="S3.T12.1.8" class="ltx_tr">
<td id="S3.T12.1.8.1" class="ltx_td ltx_align_left">IP</td>
<td id="S3.T12.1.8.2" class="ltx_td ltx_nopad_r ltx_align_left">Interjection Phrase</td>
</tr>
<tr id="S3.T12.1.9" class="ltx_tr">
<td id="S3.T12.1.9.1" class="ltx_td ltx_align_left">X</td>
<td id="S3.T12.1.9.2" class="ltx_td ltx_nopad_r ltx_align_left">Pseudo Phrase</td>
</tr>
<tr id="S3.T12.1.10" class="ltx_tr">
<td id="S3.T12.1.10.1" class="ltx_td ltx_align_left">L</td>
<td id="S3.T12.1.10.2" class="ltx_td ltx_nopad_r ltx_align_left">Left Parenthesis and Quotation Mark</td>
</tr>
<tr id="S3.T12.1.11" class="ltx_tr">
<td id="S3.T12.1.11.1" class="ltx_td ltx_align_left">R</td>
<td id="S3.T12.1.11.2" class="ltx_td ltx_nopad_r ltx_align_left">Right Parenthesis and Quotation Mark</td>
</tr>
<tr id="S3.T12.1.12" class="ltx_tr">
<td id="S3.T12.1.12.1" class="ltx_td ltx_align_left ltx_border_t" colspan="2">Function</td>
</tr>
<tr id="S3.T12.1.13" class="ltx_tr">
<td id="S3.T12.1.13.1" class="ltx_td ltx_align_left ltx_border_t">SBJ</td>
<td id="S3.T12.1.13.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Subject</td>
</tr>
<tr id="S3.T12.1.14" class="ltx_tr">
<td id="S3.T12.1.14.1" class="ltx_td ltx_align_left">OBJ</td>
<td id="S3.T12.1.14.2" class="ltx_td ltx_nopad_r ltx_align_left">Object</td>
</tr>
<tr id="S3.T12.1.15" class="ltx_tr">
<td id="S3.T12.1.15.1" class="ltx_td ltx_align_left">MOD</td>
<td id="S3.T12.1.15.2" class="ltx_td ltx_nopad_r ltx_align_left">Noun Modifier</td>
</tr>
<tr id="S3.T12.1.16" class="ltx_tr">
<td id="S3.T12.1.16.1" class="ltx_td ltx_align_left">AJT</td>
<td id="S3.T12.1.16.2" class="ltx_td ltx_nopad_r ltx_align_left">Predicate Modifier</td>
</tr>
<tr id="S3.T12.1.17" class="ltx_tr">
<td id="S3.T12.1.17.1" class="ltx_td ltx_align_left">CMP</td>
<td id="S3.T12.1.17.2" class="ltx_td ltx_nopad_r ltx_align_left">Complement</td>
</tr>
<tr id="S3.T12.1.18" class="ltx_tr">
<td id="S3.T12.1.18.1" class="ltx_td ltx_align_left ltx_border_bb">CNJ</td>
<td id="S3.T12.1.18.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">Conjunction</td>
</tr>
</tbody></table>
</figure>
<div id="S3.SS6.SSS1.Px2.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS6.SSS1.Px2.p3.1">우리는 한국어로 표준인 TTA DP 태그셋을 따른다. 표 <a class="ltx_ref" href="#S3.T12" title="Table 12 ‣ Annotation Protocol ‣ 3.6.1 Dataset Construction ‣ 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">12</span></a>와 같이 9개의 구문 태그와 6개의 함수 태그의 조합으로 이루어진다. 구문 태그는 토큰에 대한 POS를 나타내며, NP(명사구), VP(동사구), AP(부사구), VNP(코풀라구), DP(명사구), IP(인터젝션구), X(의사구), L(왼쪽 괄호 및 따옴표) 및 R(오른쪽 괄호 및 따옴표)가 있다. 함수 태그는 토큰이 헤드와 관련하여 어떤 기능을 수행하는지를 나타내며, SBJ(subject), OBJ(object), MOD(noun modifier), AJT(predicate modifier), CMP(complement), CNJ(conjunction) 등이 있다. TTA DP는 구문 태그와 함수 태그를 NP_SBJ(명사구 주어) 및 VP_AJT(동사구 부사)와 같은 단일 태그로 결합한다.</p>
</div>
</section>
<section id="S3.SS6.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Process</h5>

<div id="S3.SS6.SSS1.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS6.SSS1.Px3.p1.1">POS 및 DP 주석 모두에 대해 신뢰성이 높은 말뭉치를 구축하기 위해 한국 크라우드소싱 플랫폼인 DeepNatural,<span class="ltx_note ltx_role_footnote" id="footnote38"><sup class="ltx_note_mark">38</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">38</sup><span class="ltx_tag ltx_tag_note">38</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://deepnatural.ai/" target="_blank" title="">https://deepnatural.ai/</a></span></span></span>에서 제공하는 주석 도구를 사용하여 주석자에게 상호 참조에 주석을 요청한다. POS 어노테이션이 완료된 후, POS 정보를 이용하여 동일 문장에 대한 종속 관계 어노테이션이 진행된다. POS와 DP는 모두 한국어학 박사 학위생 10명이 주석을 달았는데, 이전에 국립국어원에서 개설한 MODU <span class="ltx_note ltx_role_footnote" id="footnote39"><sup class="ltx_note_mark">39</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">39</sup><span class="ltx_tag ltx_tag_note">39</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://corpus.korean.go.kr/main.do" target="_blank" title="">https://corpus.korean.go.kr/main.do</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib98" title="">98</a>]</cite>를 구성하는 데 기여했다. 주석을 하기 전에 지침으로 지시합니다. 주석하는 동안 주석자의 질문에 실시간으로 응답하고 이에 따라 지침은 반복적으로 업데이트된다. 주석은 주석 중에 혐오 발언이나 편견이 포함된 문장을 보고합니다. 또한, 개인 정보(예를 들어, 이름, 주소, 전화번호 등)를 포함하는 문장들이 보고된다. 보고된 문장은 검사 후 데이터 세트에서 제거됩니다.</p>
</div>
<div id="S3.SS6.SSS1.Px3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS6.SSS1.Px3.p2.1">주석은 두 단계로 검증됩니다. 먼저, 각 주석자는 다른 주석자가 주석한 POS 및 DP 레이블을 검토하고 수정한다. 그런 다음 최종적으로 모든 데이터를 검토하고 나머지 잘못 표시된 문장을 수정한다.</p>
</div>
</section>
<section id="S3.SS6.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS6.SSS1.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS6.SSS1.Px4.p1.1">KLUE-DP는 WIKINEWS 7,250문장, AIRBNB 7,250문장 등 총 14,500문장으로 구성되어 있다. POS 주석은 다음 열의 HEAD 및 DEPREL 정보와 함께 CoNLL 유사 형식의 4번째 열에 제공된다. 우리는 기차/dev/test 분할을 10,000, 2,000, 2,500문장으로 설정하였다. 표 <a class="ltx_ref" href="#S3.T13" title="Table 13 ‣ Final Dataset ‣ 3.6.1 Dataset Construction ‣ 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">13</span></a> 및 <a class="ltx_ref" href="#S3.T14" title="Table 14 ‣ Final Dataset ‣ 3.6.1 Dataset Construction ‣ 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">14</span></a>는 KLUE-DP의 상세 통계를 나타낸다.</p>
</div>
<figure id="S3.T13" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 13:</span>KLUE-DP에 대한 통계.</figcaption>
<table id="S3.T13.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T13.1.1" class="ltx_tr">
<td id="S3.T13.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T13.1.1.1.1" class="ltx_text ltx_font_bold">Source</span></td>
<td id="S3.T13.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T13.1.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T13.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T13.1.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T13.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T13.1.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T13.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T13.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T13.1.2" class="ltx_tr">
<td id="S3.T13.1.2.1" class="ltx_td ltx_align_left ltx_border_t">WIKITREE</td>
<td id="S3.T13.1.2.2" class="ltx_td ltx_align_center ltx_border_t">5,000</td>
<td id="S3.T13.1.2.3" class="ltx_td ltx_align_center ltx_border_t">1,000</td>
<td id="S3.T13.1.2.4" class="ltx_td ltx_align_center ltx_border_t">1,250</td>
<td id="S3.T13.1.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">7,250</td>
</tr>
<tr id="S3.T13.1.3" class="ltx_tr">
<td id="S3.T13.1.3.1" class="ltx_td ltx_align_left">AIRBNB</td>
<td id="S3.T13.1.3.2" class="ltx_td ltx_align_center">5,000</td>
<td id="S3.T13.1.3.3" class="ltx_td ltx_align_center">1,000</td>
<td id="S3.T13.1.3.4" class="ltx_td ltx_align_center">1,250</td>
<td id="S3.T13.1.3.5" class="ltx_td ltx_nopad_r ltx_align_center">7,250</td>
</tr>
<tr id="S3.T13.1.4" class="ltx_tr">
<td id="S3.T13.1.4.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T13.1.4.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T13.1.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T13.1.4.2.1" class="ltx_text ltx_font_bold">10,000</span></td>
<td id="S3.T13.1.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T13.1.4.3.1" class="ltx_text ltx_font_bold">2,000</span></td>
<td id="S3.T13.1.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T13.1.4.4.1" class="ltx_text ltx_font_bold">2,500</span></td>
<td id="S3.T13.1.4.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T13.1.4.5.1" class="ltx_text ltx_font_bold">14,500</span></td>
</tr>
</tbody></table>
</figure>
<figure id="S3.T14" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 14:</span>KLUE-DP에 대한 Label statistics. VP_CMP에서 NP_SVJ까지의 레이블에 대한 예측은 LAS를 계산할 때 OTHERS로 병합된다.</figcaption>
<table id="S3.T14.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T14.1.1" class="ltx_tr">
<td id="S3.T14.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T14.1.1.1.1" class="ltx_text ltx_font_bold">Label</span></td>
<td id="S3.T14.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T14.1.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T14.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T14.1.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T14.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T14.1.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T14.1.1.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S3.T14.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T14.1.2" class="ltx_tr">
<td id="S3.T14.1.2.1" class="ltx_td ltx_align_left ltx_border_t">NP</td>
<td id="S3.T14.1.2.2" class="ltx_td ltx_align_center ltx_border_t">23,902 (20.88%)</td>
<td id="S3.T14.1.2.3" class="ltx_td ltx_align_center ltx_border_t">4,559 (20.27%)</td>
<td id="S3.T14.1.2.4" class="ltx_td ltx_align_center ltx_border_t">4,884 (19.51%)</td>
<td id="S3.T14.1.2.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">33,345 (20.58%)</td>
</tr>
<tr id="S3.T14.1.3" class="ltx_tr">
<td id="S3.T14.1.3.1" class="ltx_td ltx_align_left">NP_AJT</td>
<td id="S3.T14.1.3.2" class="ltx_td ltx_align_center">17,552 (15.33%)</td>
<td id="S3.T14.1.3.3" class="ltx_td ltx_align_center">3,415 (15.18%)</td>
<td id="S3.T14.1.3.4" class="ltx_td ltx_align_center">3,526 (14.09%)</td>
<td id="S3.T14.1.3.5" class="ltx_td ltx_nopad_r ltx_align_center">24,493 (15.12%)</td>
</tr>
<tr id="S3.T14.1.4" class="ltx_tr">
<td id="S3.T14.1.4.1" class="ltx_td ltx_align_left">VP</td>
<td id="S3.T14.1.4.2" class="ltx_td ltx_align_center">16,786 (14.66%)</td>
<td id="S3.T14.1.4.3" class="ltx_td ltx_align_center">3,322 (14.77%)</td>
<td id="S3.T14.1.4.4" class="ltx_td ltx_align_center">3,917 (15.65%)</td>
<td id="S3.T14.1.4.5" class="ltx_td ltx_nopad_r ltx_align_center">24,025 (14.83%)</td>
</tr>
<tr id="S3.T14.1.5" class="ltx_tr">
<td id="S3.T14.1.5.1" class="ltx_td ltx_align_left">NP_SBJ</td>
<td id="S3.T14.1.5.2" class="ltx_td ltx_align_center">13,412 (11.71%)</td>
<td id="S3.T14.1.5.3" class="ltx_td ltx_align_center">2,737 (12.17%)</td>
<td id="S3.T14.1.5.4" class="ltx_td ltx_align_center">3,112 (12.43%)</td>
<td id="S3.T14.1.5.5" class="ltx_td ltx_nopad_r ltx_align_center">19,261 (11.89%)</td>
</tr>
<tr id="S3.T14.1.6" class="ltx_tr">
<td id="S3.T14.1.6.1" class="ltx_td ltx_align_left">VP_MOD</td>
<td id="S3.T14.1.6.2" class="ltx_td ltx_align_center">12,210 (10.66%)</td>
<td id="S3.T14.1.6.3" class="ltx_td ltx_align_center">2,457 (10.92%)</td>
<td id="S3.T14.1.6.4" class="ltx_td ltx_align_center">2,682 (10.71%)</td>
<td id="S3.T14.1.6.5" class="ltx_td ltx_nopad_r ltx_align_center">17,349 (10.71%)</td>
</tr>
<tr id="S3.T14.1.7" class="ltx_tr">
<td id="S3.T14.1.7.1" class="ltx_td ltx_align_left">NP_OBJ</td>
<td id="S3.T14.1.7.2" class="ltx_td ltx_align_center">8,531 (7.45%)</td>
<td id="S3.T14.1.7.3" class="ltx_td ltx_align_center">1,691 (7.52%)</td>
<td id="S3.T14.1.7.4" class="ltx_td ltx_align_center">1,951 (7.79%)</td>
<td id="S3.T14.1.7.5" class="ltx_td ltx_nopad_r ltx_align_center">12,173 (7.51%)</td>
</tr>
<tr id="S3.T14.1.8" class="ltx_tr">
<td id="S3.T14.1.8.1" class="ltx_td ltx_align_left">AP</td>
<td id="S3.T14.1.8.2" class="ltx_td ltx_align_center">6,638 (5.80%)</td>
<td id="S3.T14.1.8.3" class="ltx_td ltx_align_center">1,274 (5.66%)</td>
<td id="S3.T14.1.8.4" class="ltx_td ltx_align_center">1,716 (6.85%)</td>
<td id="S3.T14.1.8.5" class="ltx_td ltx_nopad_r ltx_align_center">9,628 (5.94%)</td>
</tr>
<tr id="S3.T14.1.9" class="ltx_tr">
<td id="S3.T14.1.9.1" class="ltx_td ltx_align_left">NP_CNJ</td>
<td id="S3.T14.1.9.2" class="ltx_td ltx_align_center">3,945 (3.45%)</td>
<td id="S3.T14.1.9.3" class="ltx_td ltx_align_center">795 (3.53%)</td>
<td id="S3.T14.1.9.4" class="ltx_td ltx_align_center">764 (3.05%)</td>
<td id="S3.T14.1.9.5" class="ltx_td ltx_nopad_r ltx_align_center">5,504 (3.40%)</td>
</tr>
<tr id="S3.T14.1.10" class="ltx_tr">
<td id="S3.T14.1.10.1" class="ltx_td ltx_align_left">NP_MOD</td>
<td id="S3.T14.1.10.2" class="ltx_td ltx_align_center">3,450 (3.01%)</td>
<td id="S3.T14.1.10.3" class="ltx_td ltx_align_center">659 (2.93%)</td>
<td id="S3.T14.1.10.4" class="ltx_td ltx_align_center">727 (2.90%)</td>
<td id="S3.T14.1.10.5" class="ltx_td ltx_nopad_r ltx_align_center">4,836 (2.98%)</td>
</tr>
<tr id="S3.T14.1.11" class="ltx_tr">
<td id="S3.T14.1.11.1" class="ltx_td ltx_align_left">VNP</td>
<td id="S3.T14.1.11.2" class="ltx_td ltx_align_center">2,550 (2.23%)</td>
<td id="S3.T14.1.11.3" class="ltx_td ltx_align_center">495 (2.20%)</td>
<td id="S3.T14.1.11.4" class="ltx_td ltx_align_center">558 (2.23%)</td>
<td id="S3.T14.1.11.5" class="ltx_td ltx_nopad_r ltx_align_center">3,603 (2.22%)</td>
</tr>
<tr id="S3.T14.1.12" class="ltx_tr">
<td id="S3.T14.1.12.1" class="ltx_td ltx_align_left">DP</td>
<td id="S3.T14.1.12.2" class="ltx_td ltx_align_center">1,994 (1.74%)</td>
<td id="S3.T14.1.12.3" class="ltx_td ltx_align_center">376 (1.67%)</td>
<td id="S3.T14.1.12.4" class="ltx_td ltx_align_center">419 (1.67%)</td>
<td id="S3.T14.1.12.5" class="ltx_td ltx_nopad_r ltx_align_center">2,789 (1.72%)</td>
</tr>
<tr id="S3.T14.1.13" class="ltx_tr">
<td id="S3.T14.1.13.1" class="ltx_td ltx_align_left">VP_AJT</td>
<td id="S3.T14.1.13.2" class="ltx_td ltx_align_center">882 (0.77%)</td>
<td id="S3.T14.1.13.3" class="ltx_td ltx_align_center">196 (0.87%)</td>
<td id="S3.T14.1.13.4" class="ltx_td ltx_align_center">182 (0.73%)</td>
<td id="S3.T14.1.13.5" class="ltx_td ltx_nopad_r ltx_align_center">1,260 (0.78%)</td>
</tr>
<tr id="S3.T14.1.14" class="ltx_tr">
<td id="S3.T14.1.14.1" class="ltx_td ltx_align_left">VNP_MOD</td>
<td id="S3.T14.1.14.2" class="ltx_td ltx_align_center">854 (0.75%)</td>
<td id="S3.T14.1.14.3" class="ltx_td ltx_align_center">180 (0.80%)</td>
<td id="S3.T14.1.14.4" class="ltx_td ltx_align_center">164 (0.66%)</td>
<td id="S3.T14.1.14.5" class="ltx_td ltx_nopad_r ltx_align_center">1,198 (0.74%)</td>
</tr>
<tr id="S3.T14.1.15" class="ltx_tr">
<td id="S3.T14.1.15.1" class="ltx_td ltx_align_left">NP_CMP</td>
<td id="S3.T14.1.15.2" class="ltx_td ltx_align_center">408 (0.36%)</td>
<td id="S3.T14.1.15.3" class="ltx_td ltx_align_center">83 (0.37%)</td>
<td id="S3.T14.1.15.4" class="ltx_td ltx_align_center">97 (0.39%)</td>
<td id="S3.T14.1.15.5" class="ltx_td ltx_nopad_r ltx_align_center">588 (0.36%)</td>
</tr>
<tr id="S3.T14.1.16" class="ltx_tr">
<td id="S3.T14.1.16.1" class="ltx_td ltx_align_left">VP_SBJ</td>
<td id="S3.T14.1.16.2" class="ltx_td ltx_align_center">338 (0.30%)</td>
<td id="S3.T14.1.16.3" class="ltx_td ltx_align_center">59 (0.26%)</td>
<td id="S3.T14.1.16.4" class="ltx_td ltx_align_center">94 (0.38%)</td>
<td id="S3.T14.1.16.5" class="ltx_td ltx_nopad_r ltx_align_center">491 (0.30%)</td>
</tr>
<tr id="S3.T14.1.17" class="ltx_tr">
<td id="S3.T14.1.17.1" class="ltx_td ltx_align_left ltx_border_t">VP_CMP</td>
<td id="S3.T14.1.17.2" class="ltx_td ltx_align_center ltx_border_t">330 (0.29%)</td>
<td id="S3.T14.1.17.3" class="ltx_td ltx_align_center ltx_border_t">59 (0.26%)</td>
<td id="S3.T14.1.17.4" class="ltx_td ltx_align_center ltx_border_t">91 (0.36%)</td>
<td id="S3.T14.1.17.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t">483 (0.30%)</td>
</tr>
<tr id="S3.T14.1.18" class="ltx_tr">
<td id="S3.T14.1.18.1" class="ltx_td ltx_align_left">VP_OBJ</td>
<td id="S3.T14.1.18.2" class="ltx_td ltx_align_center">279 (0.24%)</td>
<td id="S3.T14.1.18.3" class="ltx_td ltx_align_center">39 (0.17%)</td>
<td id="S3.T14.1.18.4" class="ltx_td ltx_align_center">68 (0.27%)</td>
<td id="S3.T14.1.18.5" class="ltx_td ltx_nopad_r ltx_align_center">386 (0.24%)</td>
</tr>
<tr id="S3.T14.1.19" class="ltx_tr">
<td id="S3.T14.1.19.1" class="ltx_td ltx_align_left">VNP_CMP</td>
<td id="S3.T14.1.19.2" class="ltx_td ltx_align_center">131 (0.11%)</td>
<td id="S3.T14.1.19.3" class="ltx_td ltx_align_center">27 (0.12%)</td>
<td id="S3.T14.1.19.4" class="ltx_td ltx_align_center">26 (0.10%)</td>
<td id="S3.T14.1.19.5" class="ltx_td ltx_nopad_r ltx_align_center">184 (0.11%)</td>
</tr>
<tr id="S3.T14.1.20" class="ltx_tr">
<td id="S3.T14.1.20.1" class="ltx_td ltx_align_left">AP_MOD</td>
<td id="S3.T14.1.20.2" class="ltx_td ltx_align_center">59 (0.05%)</td>
<td id="S3.T14.1.20.3" class="ltx_td ltx_align_center">15 (0.07%)</td>
<td id="S3.T14.1.20.4" class="ltx_td ltx_align_center">11 (0.04%)</td>
<td id="S3.T14.1.20.5" class="ltx_td ltx_nopad_r ltx_align_center">84 (0.05%)</td>
</tr>
<tr id="S3.T14.1.21" class="ltx_tr">
<td id="S3.T14.1.21.1" class="ltx_td ltx_align_left">X_AJT</td>
<td id="S3.T14.1.21.2" class="ltx_td ltx_align_center">41 (0.04%)</td>
<td id="S3.T14.1.21.3" class="ltx_td ltx_align_center">14 (0.06%)</td>
<td id="S3.T14.1.21.4" class="ltx_td ltx_align_center">10 (0.04%)</td>
<td id="S3.T14.1.21.5" class="ltx_td ltx_nopad_r ltx_align_center">63 (0.04%)</td>
</tr>
<tr id="S3.T14.1.22" class="ltx_tr">
<td id="S3.T14.1.22.1" class="ltx_td ltx_align_left">VNP_AJT</td>
<td id="S3.T14.1.22.2" class="ltx_td ltx_align_center">37 (0.03%)</td>
<td id="S3.T14.1.22.3" class="ltx_td ltx_align_center">13 (0.06%)</td>
<td id="S3.T14.1.22.4" class="ltx_td ltx_align_center">9 (0.04%)</td>
<td id="S3.T14.1.22.5" class="ltx_td ltx_nopad_r ltx_align_center">59 (0.04%)</td>
</tr>
<tr id="S3.T14.1.23" class="ltx_tr">
<td id="S3.T14.1.23.1" class="ltx_td ltx_align_left">VP_CNJ</td>
<td id="S3.T14.1.23.2" class="ltx_td ltx_align_center">37 (0.03%)</td>
<td id="S3.T14.1.23.3" class="ltx_td ltx_align_center">7 (0.03%)</td>
<td id="S3.T14.1.23.4" class="ltx_td ltx_align_center">7 (0.03%)</td>
<td id="S3.T14.1.23.5" class="ltx_td ltx_nopad_r ltx_align_center">46 (0.03%)</td>
</tr>
<tr id="S3.T14.1.24" class="ltx_tr">
<td id="S3.T14.1.24.1" class="ltx_td ltx_align_left">IP</td>
<td id="S3.T14.1.24.2" class="ltx_td ltx_align_center">27 (0.02%)</td>
<td id="S3.T14.1.24.3" class="ltx_td ltx_align_center">4 (0.02%)</td>
<td id="S3.T14.1.24.4" class="ltx_td ltx_align_center">6 (0.02%)</td>
<td id="S3.T14.1.24.5" class="ltx_td ltx_nopad_r ltx_align_center">41 (0.03%)</td>
</tr>
<tr id="S3.T14.1.25" class="ltx_tr">
<td id="S3.T14.1.25.1" class="ltx_td ltx_align_left">X</td>
<td id="S3.T14.1.25.2" class="ltx_td ltx_align_center">26 (0.02%)</td>
<td id="S3.T14.1.25.3" class="ltx_td ltx_align_center">4 (0.02%)</td>
<td id="S3.T14.1.25.4" class="ltx_td ltx_align_center">2 (0.01%)</td>
<td id="S3.T14.1.25.5" class="ltx_td ltx_nopad_r ltx_align_center">31 (0.02%)</td>
</tr>
<tr id="S3.T14.1.26" class="ltx_tr">
<td id="S3.T14.1.26.1" class="ltx_td ltx_align_left">VNP_OBJ</td>
<td id="S3.T14.1.26.2" class="ltx_td ltx_align_center">18 (0.02%)</td>
<td id="S3.T14.1.26.3" class="ltx_td ltx_align_center">3 (0.01%)</td>
<td id="S3.T14.1.26.4" class="ltx_td ltx_align_center">2 (0.01%)</td>
<td id="S3.T14.1.26.5" class="ltx_td ltx_nopad_r ltx_align_center">26 (0.02%)</td>
</tr>
<tr id="S3.T14.1.27" class="ltx_tr">
<td id="S3.T14.1.27.1" class="ltx_td ltx_align_left">X_SBJ</td>
<td id="S3.T14.1.27.2" class="ltx_td ltx_align_center">17 (0.01%)</td>
<td id="S3.T14.1.27.3" class="ltx_td ltx_align_center">3 (0.01%)</td>
<td id="S3.T14.1.27.4" class="ltx_td ltx_align_center">2 (0.01%)</td>
<td id="S3.T14.1.27.5" class="ltx_td ltx_nopad_r ltx_align_center">21 (0.01%)</td>
</tr>
<tr id="S3.T14.1.28" class="ltx_tr">
<td id="S3.T14.1.28.1" class="ltx_td ltx_align_left">X_OBJ</td>
<td id="S3.T14.1.28.2" class="ltx_td ltx_align_center">12 (0.01%)</td>
<td id="S3.T14.1.28.3" class="ltx_td ltx_align_center">2 (0.01%)</td>
<td id="S3.T14.1.28.4" class="ltx_td ltx_align_center">2 (0.01%)</td>
<td id="S3.T14.1.28.5" class="ltx_td ltx_nopad_r ltx_align_center">17 (0.01%)</td>
</tr>
<tr id="S3.T14.1.29" class="ltx_tr">
<td id="S3.T14.1.29.1" class="ltx_td ltx_align_left">VNP_SBJ</td>
<td id="S3.T14.1.29.2" class="ltx_td ltx_align_center">11 (0.01%)</td>
<td id="S3.T14.1.29.3" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.29.4" class="ltx_td ltx_align_center">2 (0.01%)</td>
<td id="S3.T14.1.29.5" class="ltx_td ltx_nopad_r ltx_align_center">14 (0.01%)</td>
</tr>
<tr id="S3.T14.1.30" class="ltx_tr">
<td id="S3.T14.1.30.1" class="ltx_td ltx_align_left">L</td>
<td id="S3.T14.1.30.2" class="ltx_td ltx_align_center">3 (0.00%)</td>
<td id="S3.T14.1.30.3" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.30.4" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.30.5" class="ltx_td ltx_nopad_r ltx_align_center">4 (0.00%)</td>
</tr>
<tr id="S3.T14.1.31" class="ltx_tr">
<td id="S3.T14.1.31.1" class="ltx_td ltx_align_left">AP_AJT</td>
<td id="S3.T14.1.31.2" class="ltx_td ltx_align_center">2 (0.00%)</td>
<td id="S3.T14.1.31.3" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.31.4" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.31.5" class="ltx_td ltx_nopad_r ltx_align_center">4 (0.00%)</td>
</tr>
<tr id="S3.T14.1.32" class="ltx_tr">
<td id="S3.T14.1.32.1" class="ltx_td ltx_align_left">X_CMP</td>
<td id="S3.T14.1.32.2" class="ltx_td ltx_align_center">2 (0.00%)</td>
<td id="S3.T14.1.32.3" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.32.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.32.5" class="ltx_td ltx_nopad_r ltx_align_center">4 (0.00%)</td>
</tr>
<tr id="S3.T14.1.33" class="ltx_tr">
<td id="S3.T14.1.33.1" class="ltx_td ltx_align_left">X_CNJ</td>
<td id="S3.T14.1.33.2" class="ltx_td ltx_align_center">2 (0.00%)</td>
<td id="S3.T14.1.33.3" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.33.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.33.5" class="ltx_td ltx_nopad_r ltx_align_center">3 (0.00%)</td>
</tr>
<tr id="S3.T14.1.34" class="ltx_tr">
<td id="S3.T14.1.34.1" class="ltx_td ltx_align_left">X_MOD</td>
<td id="S3.T14.1.34.2" class="ltx_td ltx_align_center">2 (0.00%)</td>
<td id="S3.T14.1.34.3" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.34.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.34.5" class="ltx_td ltx_nopad_r ltx_align_center">2 (0.00%)</td>
</tr>
<tr id="S3.T14.1.35" class="ltx_tr">
<td id="S3.T14.1.35.1" class="ltx_td ltx_align_left">AP_CMP</td>
<td id="S3.T14.1.35.2" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.35.3" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.35.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.35.5" class="ltx_td ltx_nopad_r ltx_align_center">2 (0.00%)</td>
</tr>
<tr id="S3.T14.1.36" class="ltx_tr">
<td id="S3.T14.1.36.1" class="ltx_td ltx_align_left">R</td>
<td id="S3.T14.1.36.2" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.36.3" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.36.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.36.5" class="ltx_td ltx_nopad_r ltx_align_center">1 (0.00%)</td>
</tr>
<tr id="S3.T14.1.37" class="ltx_tr">
<td id="S3.T14.1.37.1" class="ltx_td ltx_align_left">VNP_CNJ</td>
<td id="S3.T14.1.37.2" class="ltx_td ltx_align_center">1 (0.00%)</td>
<td id="S3.T14.1.37.3" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.37.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.37.5" class="ltx_td ltx_nopad_r ltx_align_center">1 (0.00%)</td>
</tr>
<tr id="S3.T14.1.38" class="ltx_tr">
<td id="S3.T14.1.38.1" class="ltx_td ltx_align_left">AP_SBJ</td>
<td id="S3.T14.1.38.2" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.38.3" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.38.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.38.5" class="ltx_td ltx_nopad_r ltx_align_center">1 (0.00%)</td>
</tr>
<tr id="S3.T14.1.39" class="ltx_tr">
<td id="S3.T14.1.39.1" class="ltx_td ltx_align_left">NP_SVJ</td>
<td id="S3.T14.1.39.2" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.39.3" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.39.4" class="ltx_td ltx_align_center">0 (0.00%)</td>
<td id="S3.T14.1.39.5" class="ltx_td ltx_nopad_r ltx_align_center">0 (0.00%)</td>
</tr>
<tr id="S3.T14.1.40" class="ltx_tr">
<td id="S3.T14.1.40.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T14.1.40.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T14.1.40.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T14.1.40.2.1" class="ltx_text ltx_font_bold">114,491</span></td>
<td id="S3.T14.1.40.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T14.1.40.3.1" class="ltx_text ltx_font_bold">22,496</span></td>
<td id="S3.T14.1.40.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T14.1.40.4.1" class="ltx_text ltx_font_bold">25,033</span></td>
<td id="S3.T14.1.40.5" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S3.T14.1.40.5.1" class="ltx_text ltx_font_bold">162,020</span></td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="S3.SS6.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.6.2 </span>Evaluation Metrics</h4>

<div id="S3.SS6.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS6.SSS2.p1.1">KLUE-DP에 대한 평가 메트릭은 1) 라벨링되지 않은 부착 점수(UAS) 및 2) 라벨링된 부착 점수(LAS)이며, 이는 DP에 대한 인기 있는 메트릭이다. DP의 목표가 머리 인덱스(HEAD) 및 종속 관계 클래스(DEPREL)를 예측하는 것임을 감안할 때, UAS는 HEAD 예측만을 카운트하는 반면 LAS는 HEAD 및 DEPREL 모두를 카운트한다. 구체적으로, UAS는 HEAD 예측에 대한 매크로 F1 점수를 계산하는 반면, LAS는 HEAD 예측이 정확한 DEPREL에 대한 매크로 F1 점수를 계산한다. 두 점수 모두 모든 수업에서 동일한 중요성을 부여한다. LAS의 경우 DEPREL 분포가 고도로 치우쳐 있기 때문에 하단에서 1%의 누적 빈도를 가진 레이블의 예측을 단일 레이블(OTHERS)로 결합한 다음 F1 점수를 계산한다. 덜 보이는 라벨은 표 <a class="ltx_ref" href="#S3.T14" title="Table 14 ‣ Final Dataset ‣ 3.6.1 Dataset Construction ‣ 3.6 Dependency Parsing (DP) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">14</span></a>에서 참조된다.</p>
</div>
</section>
<section id="S3.SS6.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.6.3 </span>Related Work</h4>

<div id="S3.SS6.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS6.SSS3.p1.1">Penn Treebank <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib84" title="">84</a>]</cite>는 1989년부터 1996년까지 작성된 선거구 구문 분석 데이터 세트이다. IBM 컴퓨터 매뉴얼, 간호 노트, 월스트리트저널 기사, 전화 대화 등 약 300만 단어의 크기를 가지고 있다. 기호 등의 메타 태그를 조합하여 총 48개의 POS 태그와 18개의 구문 태그를 사용한다. 펜 트리뱅크는 의존성 파싱이 널리 퍼지기 전에 가장 잘 알려진 파싱 데이터 세트였다. 이후 연구에서는 Penn Treebank를 종속 구문 분석 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib86" title="">86</a>, <a class="ltx_ref" href="#bib.bib20" title="">20</a>]</cite>로 변환한다.</p>
</div>
<div id="S3.SS6.SSS3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS6.SSS3.p2.1">대표적인 DP 코퍼스는 UD(Universal Dependencies) 데이터셋이다. <span class="ltx_note ltx_role_footnote" id="footnote40"><sup class="ltx_note_mark">40</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">40</sup><span class="ltx_tag ltx_tag_note">40</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://universaldependencies.org" target="_blank" title="">https://universaldependencies.org</a></span></span></span> UD는 다양한 언어로 통합된 트리뱅크 어노테이션을 목표로 하는 DP 데이터의 사실상의 표준이다. 12개의 태그로 구성된 Google Universal POS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib106" title="">106</a>]</cite>를 개발하고 이를 25개 언어에 적용한 코퍼스를 구축하였다. 또한 <cite class="ltx_cite ltx_citemacro_citet">de Marneffe and Manning [<a class="ltx_ref" href="#bib.bib28" title="">28</a>]</cite>는 Stanford parsers <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib65" title="">65</a>]</cite>에서 사용되는 의존성 파싱 마커에 대한 가이드라인을 연구하였다. 2013년 유니버설 의존 트리뱅크 프로젝트는 위의 두 연구를 결합하여 다국어에 대한 일관된 주석 시스템을 갖추려고 시도했다. UD는 이를 수정·보완하면서 시작되었다. UD는 2015년에 처음 시작되었으며 <cite class="ltx_cite ltx_citemacro_citet">Nivre et al. [<a class="ltx_ref" href="#bib.bib97" title="">97</a>]</cite>와 총 10개 언어의 10개 코퍼라가 웹사이트를 통해 공개되었다. 2021년 현재 UD(UD 2.7v)는 104개 언어와 183개의 말뭉치를 제공한다.</p>
</div>
<div id="S3.SS6.SSS3.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS6.SSS3.p3.1">UD 방식으로 구축된 코퍼스는 CoNLL-U 형식이라는 일정한 구조에 따라 만들어진다. UD는 동일한 태그와 어노테이션 시스템을 서로 다른 언어로 사용하여 일반적인 언어 보편성을 연구하는 것을 목표로 하기 때문에 각 말뭉치를 통합하여 관리하기 위한 통일된 형식이 필요하다. CoNLL-U 포맷은 유니버설 의존성 파싱을 잘 나타낼 수 있도록 이 CoNLL 포맷을 수정한 버전이다. CoNLL-U 포맷은 10개의 열로 구성되며, 각 열은 단어 인덱스(ID), 단어 형태(FORM), 단어 형태의 레마(LEMMA), 범용 품사 태그(UPOS), 언어 특정 품사 태그(XPOS), 형태소 특징 리스트(FEATS), 현재 단어의 헤드(HEAD), 의존 관계(DEPREL), 향상된 의존 그래프(DEPS), 임의의 다른 주석(MISC)을 나타낸다. 이 형식에서 각 단어는 서로 다른 관련 특징(단어 형태, lemma, POS 태그 등)과 함께 선 위에 있으며 최종 데이터 세트에서 이 형식을 채택한다.</p>
</div>
<div id="S3.SS6.SSS3.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS6.SSS3.p4.1">한국어의 DP 말뭉치는 UD 방식을 따르는 말뭉치와 그렇지 않은 말뭉치로 나뉜다. 전자로는 구글 한국어 유니버설 의존 트리뱅크(GKT), 카이스트 한국어 유니버설 의존 트리뱅크(KTB), 펜 한국어 유니버설 의존 트리뱅크(PKT) 등이 있다. 이 세 데이터 세트는 UD 스킴에 따라 구글 한국어 트리뱅크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib86" title="">86</a>]</cite>, 카이스트 트리뱅크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib128" title="">128</a>]</cite>, 그리고 펜 한국어 트리뱅크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib47" title="">47</a>]</cite>에서 각각 변환된다. 이들은 먼저 머리 찾기 규칙에 따라 자동으로 변환된 후 휴리스틱하게 수정되었다. 이들은 각각 6k, 27k, 5k 문장으로 구성되어 있으며, 블로그, 뉴스와이어, 문학, 학술, 원고 등의 장르를 포함하고 있다. 이 중 PKT는 한국어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib99" title="">99</a>]</cite>의 특징을 더욱 드러내기 위해 분석 단위와 몇 가지 규칙을 변경하여 개정하였다.</p>
</div>
<div id="S3.SS6.SSS3.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS6.SSS3.p5.1">UD 방식을 따르지 않는 코포라로는 한국전자통신연구원(ETRI)에서 구축한 TTA DP 코퍼스와 국립국어원(NIKL)에서 구축한 Modu 코퍼스 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib98" title="">98</a>]</cite>가 있다. 두 말뭉치 모두 CoNLL 형식을 따르며, 21세기 세종계획 말뭉치에서 개발한 자신만의 태그셋을 사용한다. 21세기 세종 계획의 통사 분석 코퍼스는 펜트리뱅크와 유사한 도식에 따라 선거구 문법에 따라 구성된다. 두 단어 사이의 지배적인 관계만을 파악하는 종속 문법과 달리 선거구 문법은 단어 사이의 관계를 위계적으로 파악한다. 그러나 한국어는 어순이 비교적 자유롭기 때문에 구-구조 구문 분석보다 의존 구문 분석이 더 적합하다. 21세기 세종계획 말뭉치를 DP 형식으로 변환하는 연구들이 진행되었고, 이후 21세기 세종계획의 태그셋을 사용하되 의존 구문 분석을 따르는 말뭉치가 구축되었다. TTA DP 말뭉치의 크기는 약 27k이고, Modu 말뭉치의 크기는 약 2000k이다. 일반적인 언어적 특성을 강조하는 UD와 달리 개별 언어로서 한국어의 특성을 더 잘 나타내며, 한국 DP 태깅의 국가적인 기준이 된다. 또한, TTA 방식에 따라 이미 주석이 달린 코퍼스가 존재하므로, 이 코퍼스와 벤치마크 간의 호환성을 고려한다. 이러한 이유로 TTA tagset을 이용하여 KLUE-DP를 구성하였다.</p>
</div>
</section>
<section id="S3.SS6.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.6.4 </span>Conclusion</h4>

<div id="S3.SS6.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS6.SSS4.p1.1">우리는 공식 뉴스와 비공식 사용자 생성 웹 데이터로 구성된 한국 DP 벤치마크 KLUE-DP를 구축한다. KLUE-DP는 여러 도메인에서 사용할 수 있는 DP 모델을 개발하는 데 도움이 된다. DP 성능 향상을 위해 POS 태깅을 함께 수행하며, 기존의 TTA 데이터셋을 수정하여 DP와 POS 태깅에 대한 태그셋과 가이드라인을 적용한다. 이 지침은 한국어(응집, 자유어순 등)의 특성을 반영하여 맞춤형으로 작성되었으며, 웹 데이터에서 술어의 누락이나 띄어쓰기의 오류도 해결하였다. 우리의 벤치마크가 한국 DP 모델 및 기타 자연어 처리 개발에 도움이 되기를 바랍니다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.7 </span>Machine Reading Comprehension (MRC)</h3>

<div id="S3.SS7.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.p1.1">기계독해(Machine reading comprehension, MRC)는 주어진 텍스트 지문을 읽은 후 지문에 대한 질문에 답하는 모델의 능력, 즉 이해 능력을 평가하기 위해 고안된 과제이다.</p>
</div>
<div id="S3.SS7.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS7.p2.1">기존의 널리 사용되는 대부분의 MRC 벤치마크는 크게 영어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib21" title="">21</a>, <a class="ltx_ref" href="#bib.bib56" title="">56</a>, <a class="ltx_ref" href="#bib.bib60" title="">60</a>, <a class="ltx_ref" href="#bib.bib112" title="">112</a>, <a class="ltx_ref" href="#bib.bib113" title="">113</a>, <a class="ltx_ref" href="#bib.bib145" title="">145</a>, <a class="ltx_ref" href="#bib.bib150" title="">150</a>]</cite>이다. 이러한 자원은 텍스트 이해를 측정하는 가장 직관적인 방법 중 하나이기 때문에 사전 훈련된 언어 모델을 평가하는 데 널리 사용된다. SQuAD 1.1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib112" title="">112</a>]</cite>와 SQuAD 2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib113" title="">113</a>]</cite>는 GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>, <a class="ltx_ref" href="#bib.bib82" title="">82</a>, <a class="ltx_ref" href="#bib.bib22" title="">22</a>, <a class="ltx_ref" href="#bib.bib71" title="">71</a>]</cite>와 함께 인기 있는 평가 과제이다. BoolQ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib21" title="">21</a>]</cite>, ReCoRD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib150" title="">150</a>]</cite>, MultiRC <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib60" title="">60</a>]</cite>는 언어 모델의 엄격한 평가를 위해 SuperGLUE의 멤버로 선정된다. 최근에는 주어진 텍스트 패시지가 없는 MRC 태스크로 볼 수 있는 오픈 도메인 QA 태스크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib69" title="">69</a>, <a class="ltx_ref" href="#bib.bib56" title="">56</a>, <a class="ltx_ref" href="#bib.bib145" title="">145</a>, <a class="ltx_ref" href="#bib.bib38" title="">38</a>]</cite>가 지식 집약적 NLP 태스크 벤치마크 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib105" title="">105</a>]</cite>에 포함되어 있다.</p>
</div>
<div id="S3.SS7.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS7.p3.1">이러한 데이터 세트에 의해 동기화된 MRC는 인도네시아 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib137" title="">137</a>]</cite>, 중국 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite>, 러시아 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib125" title="">125</a>]</cite>와 같은 다양한 언어에 대한 NLU 벤치마크에서 필수적인 작업이 되었다. 그러나 한국어에서는 기존의 한국어 MRC 데이터 세트가 덜 도전적이거나 접근이 제한적이거나 단순히 영어 데이터 세트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib79" title="">79</a>, <a class="ltx_ref" href="#bib.bib1" title="">1</a>, <a class="ltx_ref" href="#bib.bib74" title="">74</a>]</cite>에서 기계 번역되기 때문에 적절한 MRC 벤치마크를 사용할 수 없다. 따라서 우리는 KLUE에 MRC를 포함하고 다음 기여와 함께 새로운 도전적인 한국 MRC 벤치마크(KLUE-MRC)를 만든다:</p>
</div>
<div id="S3.SS7.p4" class="ltx_para">
<ul id="S3.I5" class="ltx_itemize">
<li id="S3.I5.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I5.i1.p1" class="ltx_para">
<p class="ltx_p" id="S3.I5.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I5.i1.p1.1.1">Providing multiple question types</span>: In evaluate different aspects of MRC capability of models, we provides three questions types: paraphrase, multi-sentence reasoning, and unanswerable. 각 유형에 대한 특정 규칙 집합과 함께 엄격한 지침을 준수하여 질문을 수집합니다.</p>
</div>
</li>
<li id="S3.I5.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I5.i2.p1" class="ltx_para">
<p class="ltx_p" id="S3.I5.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I5.i2.p1.1.1">Preventing reasoning shortcuts</span>: 작업자들이 질문을 생성할 때 어휘 및 구문 변형을 강제함으로써 MRC 모델들이 단순한 단어 매칭으로 추론 바로 가기를 악용하는 것을 방지한다. 또한, 전체 질의 문장을 고려하여 답변할 수 있는 질문을 생성하는 것을 목표로 한다.</p>
</div>
</li>
<li id="S3.I5.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I5.i3.p1" class="ltx_para">
<p class="ltx_p" id="S3.I5.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I5.i3.p1.1.1">Multi passage domains accessible to everyone</span> : Wikipedia뿐만 아니라 뉴스 도메인 passages도 포함한다. KLUE-MRC의 CC BY-SA 라이선스를 보장하기 위해 해당 뉴스 제공자와 계약을 체결했다.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS7.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS7.p5.1">우리는 주어진 텍스트 구절로부터 문제의 정답 범위를 예측하는 과제로 MRC를 공식화한다. 입력은 질문의 연결된 시퀀스이고, 구절은 구분자로 구분된다. 출력은 통로 내의 예측된 답변 스팬의 시작 및 종료 위치이다.</p>
</div>
<div id="S3.SS7.p6" class="ltx_para">
<p class="ltx_p" id="S3.SS7.p6.1">1) 정확한 일치(EM)와 2) 문자 수준 ROUGE-W의 두 가지 메트릭으로 모델을 평가한다. 문자 수준 ROUGE-W는 이전 한국 MRC 데이터 세트에서 사용된 문자 수준 F1 점수와 다르다. 질문이 주어진 구절 내에서 답할 수 없는 경우 모델은 빈 대답 문자열을 예측해야 합니다. 우리의 메트릭의 동기는 섹션 <a class="ltx_ref" href="#S3.SS7.SSS2" title="3.7.2 Evaluation Metrics ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">3.7.2</span></a>에 설명되어 있다.</p>
</div>
<section id="S3.SS7.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.7.1 </span>Dataset Construction</h4>

<section id="S3.SS7.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora</h5>

<div id="S3.SS7.SSS1.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px1.p1.1">먼저 한국위키페디아와 한국경제신문과 ACROFAN에서 제공하는 뉴스 기사의 구절을 수집한다. WIKIPEDIA 문서는 MRC 데이터 세트를 만드는 데 가장 일반적으로 사용되는 리소스 중 하나이다. 우리는 또한 구절의 다양성을 높이기 위해 현대 사회 문제를 보도하는 뉴스 기사를 포함한다. 한국경제신문과 ACROFAN에서 제공하고 있습니다. 뉴스 기사는 일반적으로 저작권이 있는 저작물이므로, 우리는 기계 학습 목적으로 데이터 세트를 구축하기 위한 목적으로만 CC BY-SA 라이선스에 따라 기사를 사용하고 재분배하기 위해 뉴스 제공자와 계약을 체결한다. 우리는 다중 도메인 코퍼스가 MRC 모델의 일반화 가능성을 향상시키는 데 도움이 될 수 있다고 믿는다.</p>
</div>
<div id="S3.SS7.SSS1.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px1.p2.1">우리는 구절을 수집하기 위해 말뭉치를 전처리한다. WIKIPEDIA 기사의 경우, 모델의 정확한 평가를 위해 기존의 다른 한국 MRC 벤치마크(예: KorQuAD)에서 중복을 제거한다. 그런 다음 각 기사를 섹션별로 분할하여 지문을 얻는다. 뉴스 기사의 경우 정치 기사와 100개 미만의 범주에 속하는 기사를 걸러낸다. 우리는 최종적으로 길이가 512보다 길고 문자가 2048보다 짧은 모든 전처리된 구절을 모읍니다.</p>
</div>
</section>
<section id="S3.SS7.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Protocol</h5>

<div id="S3.SS7.SSS1.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px2.p1.1">우리는 크라우드 워커에게 구절을 주어 질문과 답변에 주석을 달습니다. 가이드라인을 소개하기 위해 자세한 튜토리얼 세션을 제공합니다. 작업자 80명 중 60명은 주어진 구절로 15개의 문답 쌍을 만드는 파일럿 테스트 후 선택된다. 선택한 작업자는 질문을 생성하고 해당 답변 범위(유형 1 및 유형 2의 경우) 또는 가짜 답변 범위(유형 3의 경우)에 레이블을 지정합니다. 주석에는 Tagtog 주석 툴킷 <span class="ltx_note ltx_role_footnote" id="footnote41"><sup class="ltx_note_mark">41</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">41</sup><span class="ltx_tag ltx_tag_note">41</span>https://www.tagtog.net/</span></span></span>을 사용한다. 우리는 공통 및 유형별 지침에 따라 생성된 질문 및 답변을 검증하기 위해 각 질문 유형에 대해 세 명의 검사자를 할당한다. 생성된 질의응답 쌍이 검사를 통과하지 못하면, 작업자는 검사자가 주는 피드백에 기초하여 이를 정제한다.</p>
</div>
</section>
<section id="S3.SS7.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">1. Common Guidelines</h5>

<div id="S3.SS7.SSS1.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px3.p1.1">우리는 먼저 크라우드 워커를 위한 공통 주석 지침을 구축합니다. 작업자는 다음과 같이 세 가지 질문 유형 모두에 대한 해당 질문 생성 및 답변 범위 주석 동안 지침을 따라야 한다.</p>
</div>
<div id="S3.SS7.SSS1.Px3.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS7.SSS1.Px3.p2.1.1">A question should:</span></p>
</div>
<div id="S3.SS7.SSS1.Px3.p3" class="ltx_para">
<ul id="S3.I6" class="ltx_itemize">
<li id="S3.I6.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I6.i1.p1" class="ltx_para">
<p class="ltx_p" id="S3.I6.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I6.i1.p1.1.1">Be natural as a web search query</span>: Trying to generate challenging questions can lead to use of unnatural expressions. 직원들이 웹 검색 질의에 대한 것처럼 자연스러운 질문을 할 수 있도록 안내합니다. 우리는 향후 작업에서 과제를 개방형 QA 과제로 확장하기 위한 질문의 일반화 가능성에 관심이 있다.</p>
</div>
</li>
<li id="S3.I6.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I6.i2.p1" class="ltx_para">
<p class="ltx_p" id="S3.I6.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I6.i2.p1.1.1">Avoid omission</span>: Pronoun-dropping이 한국어로 널리 퍼져 있어 주제나 대상을 생략하는 경향이 있다. 누락은 답을 찾기 위한 모호성을 초래할 수 있다. 우리는 생성된 질문에 모든 문법적 구성 요소를 유지하도록 작업자를 명시적으로 안내합니다.</p>
</div>
</li>
<li id="S3.I6.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I6.i3.p1" class="ltx_para">
<p class="ltx_p" id="S3.I6.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I6.i3.p1.1.1">Not copy a phrase in the passage</span>: Questions might be similar meaning to some phrases in the passage but should not contain exactly same phrase. 이것은 이전 작업 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib122" title="">122</a>]</cite>에서 보고된 바와 같이 질문과 지문 사이의 높은 단어 중복을 완화한다.</p>
</div>
</li>
<li id="S3.I6.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I6.i4.p1" class="ltx_para">
<p class="ltx_p" id="S3.I6.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I6.i4.p1.1.1">Not refer to external knowledge</span>: Questions need to be fully understood without any external knowledge. 배경 지식이나 세계 지식을 사용하는 작업자가 질문을 생성하는 것을 허용하지 않습니다. 질문은 주어진 구절에 의해서만 도출되어야 한다.</p>
</div>
</li>
<li id="S3.I6.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I6.i5.p1" class="ltx_para">
<p class="ltx_p" id="S3.I6.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I6.i5.p1.1.1">Be meaningful in every part for finding the answer</span>: Answers should not be found with a small fraction of the question. 우리는 작업자들이 답을 찾기 위해 전체 질문 텍스트에 대한 이해가 필요한 질문을 생성하도록 권장한다. 모델들이 전체 질문에 대한 이해 없이 쉽게 답을 추론할 수 있기 때문에, 우리는 지문에 한 번만 나타나는 표현의 사용을 허용하지 않는다.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS7.SSS1.Px3.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px3.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS7.SSS1.Px3.p4.1.1">An answer should:</span></p>
</div>
<div id="S3.SS7.SSS1.Px3.p5" class="ltx_para">
<ul id="S3.I7" class="ltx_itemize">
<li id="S3.I7.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I7.i1.p1" class="ltx_para">
<p class="ltx_p" id="S3.I7.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I7.i1.p1.1.1">Be a unique entity within a passage</span>: To clarify what to ask, only a single answer should be inferred from the question. 답변이 다양한 어휘 형태로 표현될 수 있을 때, 작업자는 모든 답변 범위(예를 들어, 텔레비전, TV)를 표시해야 한다.</p>
</div>
</li>
<li id="S3.I7.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I7.i2.p1" class="ltx_para">
<p class="ltx_p" id="S3.I7.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I7.i2.p1.1.1">Not be the main topic or title</span>: We aim to prevent a known artifact that the most frequently appeared words within a given passage is likely to the answer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib66" title="">66</a>]</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS7.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">2. Type-Specific Guidelines</h5>

<div id="S3.SS7.SSS1.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px4.p1.1">여기에서 우리는 질문 유형별 지침을 자세히 설명한다. 이러한 지침은 위의 공통 지침과 함께 근로자에게도 추가적으로 제시되고 있다.</p>
</div>
<div id="S3.SS7.SSS1.Px4.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px4.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS7.SSS1.Px4.p2.1.1">2.1. Question Paraphrasing (Type 1)</span> Type 1 예시들은 그들 사이의 단어 중복을 줄이기 위해 질문들을 생성할 때 통로 문장들을 패러프레이징하는 것에 초점을 맞춘다. 패러프레이징을 통해 모델이 패러프레이징된 질문의 의미를 올바르게 이해할 수 있는지 검증하고 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib122" title="">122</a>]</cite> 답변을 추론할 수 있다.</p>
</div>
<figure id="S3.T15" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 15:</span>한국어 및 영어 번역에 대한 패러프레이즈 질문 유형 예</figcaption>
<div id="S3.T15.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:429.6pt;height:181.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S3.T15.1.1"><span class="ltx_tabular ltx_align_middle" id="S3.T15.1.1.1.1.1.1"> <span class="ltx_inline-block ltx_align_top ltx_border_tt" id="S3.T15.1.1.1.1.1.1.1.1.1.1.1"> <span class="ltx_inline-block ltx_align_top" id="S3.T15.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"> <span class="ltx_inline-block ltx_align_top" id="S3.T15.1.1.1.1.1.1.1.1.1.1.1.1.2"> <span class="ltx_p" id="S3.T15.1.1.1.1.1.1.1.1.1.1.1. <span class="ltx_inline-block ltx_align_top ltx_border_t" id="S3.T15.1.1.1.1.2.3"><span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T15.1.1.1.2.3.1"><span class="ltx_p" id="S3.T15.1.1.1.1.2.3.1.1" style="width:173.4pt;">Duchy of Brittany originates in the Battle of Trans-la-Forêt of year 939, and was established on and around the Couesnon River, the boundary of Britanny and Normandy. <span class="ltx_inline-block ltx_align_top ltx_border_t" id="S3.T15.1.1.1.1.1.3.1.1.1.1.1.1.1.1.1.1"><span class="ltx_tabular ltx_align_middle" id="S3.T15.1.1.1.1.1.1.1.1.1.1.1"><span class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T15.1.1.1.1.1.1.1.1.1.1.1.1.1"><span class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T15.1.1.1.1.1.1.1.1.1.1.1.1"><span class="ltx_td ltx_ <span class="ltx_inline-block ltx_align_top" id="S3.T15.1.1.1.3.3.1"><span class="ltx_p" id="S3.T15.1.1.1.1.3.3.1.1" style="width:173.4pt;">What distinguishes Britanny and Normandy? <span class="ltx_inline-block ltx_align_top ltx_border_t" id="S3.T15.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><span class="ltx_tabular ltx_align_middle" id="S3.T15.1.1.1.1.1.1.1.1.1.1"><span class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T15.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><span class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T15.1.1.1.1.1.1.1. <span class="ltx_inline-block ltx_align_top" id="S3.T15.1.1.1.1.4.3.1"><span class="ltx_p" id="S3.T15.1.1.1.1.4.3.1.1" style="width:173.4pt;">Britanny and Normandy의 경계는 무엇입니까? <span class="ltx_inline-block ltx_align_top ltx_border_bb ltx_border_t" id="S3.T15.1.1.1.1.1.5.1"> <span class="ltx_inline-block ltx_align_top" id="S3.T15.1.1.1.1.1.1.5.1.1"> <span class="ltx_inline-block ltx_align_top" id="S3.T15.1.1.1.1.1.1.5.2.1" style="width:173.4pt;"> <span class="ltx_p" id="S3.T15.1.1.1.1.1.1.5.2.1.1" style="font-size:90%;">쿠에농 강</span></span></span></span> <span> <span class="ltx_td ltx_align_justify lt</p>
</span></div>
</figure>
<div id="S3.SS7.SSS1.Px4.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px4.p3.1">우리는 패러프레이즈된 질문에 대한 주석 가이드에서 작업자가 후속 구문의 순서를 단순히 이동하거나 기능 입자를 변경하여 생성하는 것을 추가로 방지한다. 구체적으로 근로자는 다음과 같은 원칙을 통해 질문을 생성한다.</p>
</div>
<div id="S3.SS7.SSS1.Px4.p4" class="ltx_para">
<ul id="S3.I8" class="ltx_itemize">
<li id="S3.I8.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I8.i1.p1" class="ltx_para">
<p class="ltx_p" id="S3.I8.i1.p1.1">구문 또는 어휘 변이는 구절의 텍스트 조각에 적용되어야 한다.</p>
<ul id="S3.I8.i1.I1" class="ltx_itemize">
<li id="S3.I8.i1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I8.i1.I1.i1.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I8.i1.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S3.I8.i1.I1.i1.p1.1">통사적 변이를 위해서는 원문장의 구조를 재구성하는 것이 바람직하다. 주변 문구 간의 순서 교환과 같은 최소한의 변경은 허용되지 않습니다.</p>
</div>
</li>
<li id="S3.I8.i1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S3.I8.i1.I1.i2.1.1.1" class="ltx_text ltx_font_bold">–</span></span> 
<div id="S3.I8.i1.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S3.I8.i1.I1.i2.p1.1">어휘변주를 위해서는 동사나 수식어의 변경이 필요하며, 명사구의 변주가 권장된다.</p>
</div>
</li>
</ul>
</div>
</li>
<li id="S3.I8.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I8.i2.p1" class="ltx_para">
<p class="ltx_p" id="S3.I8.i2.p1.1">문항의 단어들 중 절반 이상이 지문의 해당 부분(문장)과 겹치지 않아야 한다.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS7.SSS1.Px4.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px4.p5.1">그런 다음 해당 문항이 구절과 단어 중복도가 낮은지 종합적으로 확인한다. 큐스논 리버가 답인 <표 <a class="ltx_ref" href="#S3.T15" title="Table 15 ‣ 2. Type-Specific Guidelines ‣ 3.7.1 Dataset Construction ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">15</span></a>와 같이, 질문은 주어진 증거 문장("브리태니와 노르망디의 경계")을 새로운 문장 구조를 제공하여 패러프레이징한다. 구조는 copula가 있는 wh-question에서 자동 동사가 있는 질문으로 변경된다. 또한, "구별"이라는 새로운 용어가 도입되어 "의 경계"라는 구절을 대체한다.</p>
</div>
</section>
<section id="S3.SS7.SSS1.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">2.2. Multiple-Sentence Reasoning (Type 2)</h5>

<div id="S3.SS7.SSS1.Px5.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px5.p1.1">유형 2의 예는 다문장 추론이 필요한 문항을 만드는 데 중점을 둔다. 다중 문장 추론은 모델이 지문의 적어도 두 문장에 걸쳐 추론함으로써 질문으로부터 답을 도출하도록 요구한다. 우리는 MRC 모델이 지문 전체에 퍼져 있는 정보를 종합적으로 집계하여 답변 범위를 추론할 수 있는지 평가하는 데 중점을 둔다. 우리는 다중 문장 추론 예제에 대한 주석 지침을 주의 깊게 설계한다. <cite class="ltx_cite ltx_citemacro_citet">Min et al. [<a class="ltx_ref" href="#bib.bib90" title="">90</a>]</cite> report multiple-sentence reasoning questions can fall back to single-sentence reasoning, we aims to avoid these cases by guide workers to follow the steps below:</p>
<ul id="S3.I9" class="ltx_itemize">
<li id="S3.I9.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I9.i1.p1" class="ltx_para">
<p class="ltx_p" id="S3.I9.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I9.i1.p1.1.1">(Step 1.)</span> 일부 속성을 공유하는 주어진 통로에서 적어도 두 개의 문을 찾습니다.</p>
</div>
</li>
<li id="S3.I9.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I9.i2.p1" class="ltx_para">
<p class="ltx_p" id="S3.I9.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I9.i2.p1.1.1">(Step 2.)</span> 공유 속성에 관한 엔터티 중 하나의 답변을 선택합니다.</p>
</div>
</li>
<li id="S3.I9.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I9.i3.p1" class="ltx_para">
<p class="ltx_p" id="S3.I9.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I9.i3.p1.1.1">(Step 3.)</span> 선택된 엔터티를 가진 질문을 생성합니다.</p>
</div>
</li>
</ul>
</div>
<figure id="S3.T16" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 16:</span> 한국어 및 영어 번역에 대한 다중 문장 추론 질문 유형 예</figcaption>
<div id="S3.T16.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.9pt;height:343.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S3.T16.1.1"><span class="ltx_tabular ltx_align_middle" id="S3.T16.1.1.1.1.1.1"> <span class="ltx_inline-block ltx_align_top ltx_border_tt" id="S3.T16.1.1.1.1.1.1.1.1.1.1"> <span class="ltx_inline-block ltx_align_top" id="S3.T16.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"> <span class="ltx_inline-block ltx_align_top" id="S3.T16.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"> <span class="ltx_p" id="S3.T16.1.1.1.1.1.1.1.1.1.1. 오늘날 면적으로 환산하면 현재 미국 면적의 2/3에 달하고 인구도 현 미국의 절반에 약간 안되는 정도로 추산된다. 서기 5세기 경 서로마 제국이 멸망 후 게르만족의 여러 독립국가 갈라져 프랑크 왕국, 신성 로마 제국 등 로마의 후계자를 자처하는 여타 서유럽의 정치 세력들이 나타난다. <span></span></span></span></span><span class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="S3.T16.1.1.1.1.2.3"><span class="ltx_inline-block ltx_align_top" id="S3.T16.1.1.1.1.2.3.1"><span class="ltx_p" id="S3.T16.1.1.1.1.1.2.3.1.1" style="width:173.4pt;">Under Trajan(AD 98-AD 117), Roman Empire reached its territorial peak. 오늘날의 면적으로는 현재 미국 면적의 3분의 2를 차지하는 것으로 추정되며, 그 인구는 내부 불안정에 시달리고 다양한 이주 민족의 공격을 받는 현재 미국의 절반에 불과하여 제국의 서부는 5세기에 독립적인 야만 왕국으로 분열되었다. <span class="ltx_inline-block ltx_align_top ltx_border_t" id="S3.T16.1.1.1.1.1.1.3.1"><span class="ltx_inline-block ltx_align_top ltx_border_t" id="S3.T16.1.1.1.1.1.3.1.1.1.3.1"><span class="ltx_inline-block ltx_align_top ltx_border_t" id="S3.T16.1.1.1.1.1.3.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2"><span class="ltx_inline-block ltx_align_justify ltx_align_top ltx_border_t" id="S3.T16.1.1.1.1.1 <span class="ltx_inline-block ltx_align_top ltx_border_t" id="S3.T16.1.1.1.1.1.3.1"><span class="ltx_inline-block ltx_align_top" id="S3.T16.1.1.1.1.1.1.4.1"><span class="ltx_inline-block ltx_align_top" id="S3.T16.1.1.1.1.1.1.4.1"><span class="ltx_inline-block ltx_align_top ltx_border_t" id="S3.T16.1.1.1.1.1.1.4.1"><span class="ltx_inline-block ltx_align_top ltx_border_t" style="width:173.4pt;">Statement B</span></span></span></span></span> <span class="ltx_inline-block ltx_align_top" id="S3.T16.1.1.1.1.4.3.1"><span class="ltx_p" id="S3.T16.1.1.1.1.1.4.3.1" style="width:173.4pt;">Under Trajan(AD 98-AD 117), Roman Empire reached its territorial peak. 1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2"><span class="ltx_tabular ltx_align_middle" id="S3.T16.1.1.1.1.1.1"><span class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T16.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><span class="ltx_td ltx_nopad_r ltx_align_left" id="S3.T16.1.1.1.1.1.1.1.2">Properties</span></span></span></sp </span></span></span></span><span class="ltx_inline-block ltx_align_justify ltx_align_top ltx_border_t" id="S3.T16.1.1.1.1.6.3"><span class="ltx_inline-block ltx_align_top" id="S3.T16.1.1.1.6.3.1"><span class="ltx_p" id="S3.T16.1.1.1.1.1.6.3.1.1" style="width:173.4pt;">When was the area of the Roman Empire two-thirds of the current U.S. <span class="ltx_inline-block ltx_align_top ltx_border_bb ltx_border_t" id="S3.T16.1.1.1.1.1.7.1"><span class="ltx_inline-block ltx_align_top" id="S3.T16.1.1.1.1.1.7.1.1.1.1.1.2"><span class="ltx_inline-block ltx_align_top" id="S3.T16.1.1.1.1.1.7.2"><span class="ltx_p" id="S3.T16.1.1.1.1.1.1.1.1.1.1" style="width:173.4pt;"><span class="ltx_text" id="S3.T16.1.1.1.1.1.1.1.1" style="font-size:90%;">트라야누스 황제 시대(98년</p>
</span></div>
</figure>
<div id="S3.SS7.SSS1.Px5.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px5.p2.1">표 <a class="ltx_ref" href="#S3.T16" title="Table 16 ‣ 2.2. Multiple-Sentence Reasoning (Type 2) ‣ 3.7.1 Dataset Construction ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">16</span></a>의 예는 전술한 단계를 따른다. 두 진술 사이의 공유 속성(A: “현재 미국 면적의 3분의 2를 나타내는 것으로 추정됨), B: “트라야누스 아래(AD 98-AD 117), 로마제국이 영토 정점에 도달함”)는 “로마제국”과 “트라야누스 아래(AD 98-AD 117)”이다. 우리가 “Trajan(AD 98-AD 117)”을 해답으로 선택하고 “로마제국의 면적은 현재 미국의 면적의 3분의 2가 언제였는가?”라는 질문을 생성한다고 가정하자. 두 진술 중 어느 것도 정답을 단독으로 선택하기에 충분하지 않다. 문제와 진술 A만 주어졌을 때, "트라얀(AD 98-AD 117)"과 "5세기" 사이의 답을 풀 수 없는데, 둘 다 대목의 시간대를 나타낸다. 명제 B는 영역 크기에 대한 구체적인 정보를 포함하고 있지 않기 때문에 그 자체로 답을 좁히는 것도 충분하지 않다. 따라서 A 문장과 B 문장은 모두 집합하여 질문에 정확하게 답할 필요가 있다.</p>
</div>
</section>
<section id="S3.SS7.SSS1.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">2.3. Unanswerable Questions (Type 3)</h5>

<div id="S3.SS7.SSS1.Px6.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px6.p1.1">유형 3 예시는 주어진 구절 내에서 답할 수 없는 질문이다. 우리는 이것들을 '답할 수 없는' 질문으로 명명한다. 현실 세계에서, 어떤 구절을 구할 수 없다면, 질문은 종종 대답할 수 없다. 구절 내에 항상 답이 존재한다는 전제하에 모델이 구축된다면, SQuAD 2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib113" title="">113</a>]</cite>가 지적한 것과 같은 경우를 효과적으로 처리하지 못할 것이다. 따라서 우리는 질문이 답할 수 있는지 여부를 식별하기 위해 모델을 장려하기 위해 벤치마크에 답할 수 없는 질문을 추가한다.</p>
</div>
<div id="S3.SS7.SSS1.Px6.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px6.p2.1">주석 지침에서는 바람직한 답할 수 없는 질문을 생성하기 위해 다음과 같은 원칙을 제시한다. 답할 수 없는 질문은 다음과 같습니다.</p>
</div>
<div id="S3.SS7.SSS1.Px6.p3" class="ltx_para">
<ul id="S3.I10" class="ltx_itemize">
<li id="S3.I10.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I10.i1.p1" class="ltx_para">
<p class="ltx_p" id="S3.I10.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I10.i1.p1.1.1">Be relevant to the passage:</span> 주어진 passage에 등장하는 엔티티는 질문에 포함되어야 한다. 그 실체는 그 질문을 구절과 관련 있게 만든다. 그렇지 않으면 그 질문은 대답할 수 없는 것으로 결정되기 너무 쉬울 것이다.</p>
</div>
</li>
<li id="S3.I10.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I10.i2.p1" class="ltx_para">
<p class="ltx_p" id="S3.I10.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I10.i2.p1.1.1">Have fake answers within the passage:</span> A fake answer is plausible but incorrect regarding the corresponding question. 가짜 답은 구절 안에 산만함으로 존재해야 한다.</p>
</div>
</li>
<li id="S3.I10.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I10.i3.p1" class="ltx_para">
<p class="ltx_p" id="S3.I10.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S3.I10.i3.p1.1.1">Not have correct answers within the passage:</span> Despite the existence of fake answers, the generated question must not exist in the passage.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS7.SSS1.Px6.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px6.p4.1">우리의 설정에서 모델은 질문과 지문 사이의 단어 중복을 기반으로 질문의 풀리지 않는 것을 식별하지 못할 가능성이 있다. 우리의 질문은 중복을 증가시키는 구절의 개체들을 포함한다. 그런 경우, MRC 모델은 지문에 존재하는 그럴듯한 가짜 답변을 선택할 것이다.</p>
</div>
<div id="S3.SS7.SSS1.Px6.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px6.p5.1">표 <a class="ltx_ref" href="#S3.T17" title="Table 17 ‣ 2.3. Unanswerable Questions (Type 3) ‣ 3.7.1 Dataset Construction ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">17</span></a>는 Type 3 문제의 일례를 나타낸다. 질문은 주어진 구절에도 존재하는 "대역폭"을 포함한다. 질문은 대역폭을 묻는 것이므로 “1~5기가비트 이더넷”은 그럴듯하지만 오답일 것이다. 이 지문의 질문에서 "대역폭-배고픈 서버"에 대한 정답에 대한 단서가 없다. 모델은 BERT의 [CLS] 토큰을 사용하는 것과 같이 문맥 범위 범위를 벗어나 빈 문자열을 예측해야 한다.</p>
</div>
<figure id="S3.T17" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 17:</span>Unanswerable question type example for Korean and the English translation</figcaption>
<div id="S3.T17.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:429.6pt;height:112.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S3.T17.1.1" class="ltx_p"><span id="S3.T17.1.1.1" class="ltx_text"> <span id="S3.T17.1.1.1.1" class="ltx_tabular ltx_align_middle"> <span id="S3.T17.1.1.1.1.1" class="ltx_tr"> <span id="S3.T17.1.1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt"> <span id="S3.T17.1.1.1.1.1.1.1" class="ltx_inline-block ltx_align_top"> <span id="S3.T17.1.1.1.1.1.1.1.1" class="ltx_p" style="width:43.4pt;"><span id="S3.T17.1.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Type</span></span> </span></span> <span id="S3.T17.1.1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt"> <span id="S3.T17.1.1.1.1.1.2.1" class="ltx_inline-block ltx_align_top"> <span id="S3.T17.1.1.1.1.1.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T17.1.1.1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Korean</span></span> </span></span> <span id="S3.T17.1.1.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt"> <span id="S3.T17.1.1.1.1.1.3.1" class="ltx_inline-block ltx_align_top"> <span id="S3.T17.1.1.1.1.1.3.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T17.1.1.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold">English (Translated)</span></span> </span></span></span> <span id="S3.T17.1.1.1.1.2" class="ltx_tr"> <span id="S3.T17.1.1.1.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t"> <span id="S3.T17.1.1.1.1.2.1.1" class="ltx_inline-block ltx_align_top"> <span id="S3.T17.1.1.1.1.2.1.1.1" class="ltx_p" style="width:43.4pt;">Passage</span> </span></span> <span id="S3.T17.1.1.1.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t"> <span id="S3.T17.1.1.1.1.2.2.1" class="ltx_inline-block ltx_align_top"> <span id="S3.T17.1.1.1.1.2.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T17.1.1.1.1.2.2.1.1.1" class="ltx_text" style="font-size:90%;">아직도 대역폭이 많이 필요하지 않은 서버는 1-5기가비트 이더넷을 사용한다.</span></span> </span></span> <span id="S3.T17.1.1.1.1.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t"> <span id="S3.T17.1.1.1.1.2.3.1" class="ltx_inline-block ltx_align_top"> <span id="S3.T17.1.1.1.1.2.3.1.1" class="ltx_p" style="width:173.4pt;">Servers that still do not require much bandwidth use 1 to 5 Gigabit Ethernet.</span> </span></span></span> <span id="S3.T17.1.1.1.1.3" class="ltx_tr"> <span id="S3.T17.1.1.1.1.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t"> <span id="S3.T17.1.1.1.1.3.1.1" class="ltx_inline-block ltx_align_top"> <span id="S3.T17.1.1.1.1.3.1.1.1" class="ltx_p" style="width:43.4pt;">Question</span> </span></span> <span id="S3.T17.1.1.1.1.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t"> <span id="S3.T17.1.1.1.1.3.2.1" class="ltx_inline-block ltx_align_top"> <span id="S3.T17.1.1.1.1.3.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T17.1.1.1.1.3.2.1.1.1" class="ltx_text" style="font-size:90%;">대역폭이 많이 필요한 서버는 어느 대역을 사용하는가?</span></span> </span></span> <span id="S3.T17.1.1.1.1.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t"> <span id="S3.T17.1.1.1.1.3.3.1" class="ltx_inline-block ltx_align_top"> <span id="S3.T17.1.1.1.1.3.3.1.1" class="ltx_p" style="width:173.4pt;">Which bandwidth does the bandwidth-hungry server use?</span> </span></span></span> <span id="S3.T17.1.1.1.1.4" class="ltx_tr"> <span id="S3.T17.1.1.1.1.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t"> <span id="S3.T17.1.1.1.1.4.1.1" class="ltx_inline-block ltx_align_top"> <span id="S3.T17.1.1.1.1.4.1.1.1" class="ltx_p" style="width:43.4pt;"> <span id="S3.T17.1.1.1.1.4.1.1.1.1" class="ltx_tabular ltx_align_middle"> <span id="S3.T17.1.1.1.1.4.1.1.1.1.1" class="ltx_tr"> <span id="S3.T17.1.1.1.1.4.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Fake</span></span> <span id="S3.T17.1.1.1.1.4.1.1.1.1.2" class="ltx_tr"> <span id="S3.T17.1.1.1.1.4.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Answers</span></span> </span></span> </span></span> <span id="S3.T17.1.1.1.1.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t"> <span id="S3.T17.1.1.1.1.4.2.1" class="ltx_inline-block ltx_align_top"> <span id="S3.T17.1.1.1.1.4.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T17.1.1.1.1.4.2.1.1.1" class="ltx_text" style="font-size:90%;">1-5기가비트 이더넷</span></span> </span></span> <span id="S3.T17.1.1.1.1.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t"> <span id="S3.T17.1.1.1.1.4.3.1" class="ltx_inline-block ltx_align_top"> <span id="S3.T17.1.1.1.1.4.3.1.1" class="ltx_p" style="width:173.4pt;">1 to 5 Gigabit Ethernet</span> </span></span></span> </span></span></p>
</span></div>
</figure>
</section>
<section id="S3.SS7.SSS1.Px7" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Annotation Process</h5>

<div id="S3.SS7.SSS1.Px7.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px7.p1.1">우리는 SelectStar, <span class="ltx_note ltx_role_footnote" id="footnote42"><sup class="ltx_note_mark">42</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">42</sup><span class="ltx_tag ltx_tag_note">42</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://selectstar.ai/" target="_blank" title="">https://selectstar.ai/</a></span></span></span> 한국 크라우드소싱 플랫폼에서 모집한 근로자를 고용하여 주어진 구절에 대한 각 유형의 질문과 답변을 만든다. 유형 1의 경우 28명의 작업자가 예제에 주석을 달고 다른 3명의 작업자가 모두 검사한다. 유형 2와 3의 경우 19명과 13명의 작업자가 예제에 주석을 달고 다른 3명과 2명의 작업자가 각각 유효성을 검사한다. 생성된 질문이 검사자에 의해 거부되면 피드백을 기반으로 다시 생성됩니다.</p>
</div>
<div id="S3.SS7.SSS1.Px7.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px7.p2.1">윤리 기준을 충족하기 위해 성적, 폭력적, 증오, 편견 또는 기타 윤리적으로 부적절한 내용을 포함하는 예는 제거된다. 우리는 주석 프로세스가 끝날 때 모든 예제를 수동으로 다시 확인합니다. 필터링 과정을 통해 총 173개의 예시들을 제거한다.</p>
</div>
</section>
<section id="S3.SS7.SSS1.Px8" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS7.SSS1.Px8.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS1.Px8.p1.1">KLUE-MRC는 패러프레이징 기반 질문 12,207개, 다문장 추론 질문 7,895개, 미응답 질문 9,211개로 구성되어 있다. 총 29,313개의 예가 22,343개의 문서와 23,717개의 구절로 만들어진다. MRC 모델을 평가하기 위해 어려운 데이터 세트를 만드는 것을 우선시하기 때문에 분할을 개발하고 테스트하는 데 더 많은 예를 제공한다. 견고한 평가를 위해 열차/dev/테스트 분할 비율을 6:2:2로 설정하여 17,554개의 훈련, 5,841개의 개발 및 5,918개의 테스트 예를 생성했다. 각 분할에 대해 질문 유형 수의 균형을 맞추기 위해 각 질문 유형의 예를 독립적으로 무작위로 샘플링한다. 표 <a class="ltx_ref" href="#S3.T18" title="Table 18 ‣ Final Dataset ‣ 3.7.1 Dataset Construction ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">18</span></a> 및 <a class="ltx_ref" href="#S3.T19" title="Table 19 ‣ Final Dataset ‣ 3.7.1 Dataset Construction ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">19</span></a>는 KLUE-MRC의 상세 통계를 나타낸다.</p>
</div>
<figure id="S3.T18" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 18:</span>각 데이터 세트 분할 및 질문 유형당 예제 수입니다.</figcaption>
<table id="S3.T18.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T18.1.1" class="ltx_tr">
<td id="S3.T18.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T18.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T18.1.1.2.1" class="ltx_text ltx_font_bold">Paraphrase</span></td>
<td id="S3.T18.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T18.1.1.3.1" class="ltx_text ltx_font_bold">Multi-sentence</span></td>
<td id="S3.T18.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T18.1.1.4.1" class="ltx_text ltx_font_bold">Unanswerable</span></td>
<td id="S3.T18.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T18.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T18.1.2" class="ltx_tr">
<td id="S3.T18.1.2.1" class="ltx_td"></td>
<td id="S3.T18.1.2.2" class="ltx_td ltx_align_center">(41.65%)</td>
<td id="S3.T18.1.2.3" class="ltx_td ltx_align_center">(26.93%)</td>
<td id="S3.T18.1.2.4" class="ltx_td ltx_align_center">(31.42%)</td>
<td id="S3.T18.1.2.5" class="ltx_td ltx_align_center">(100.0%)</td>
</tr>
<tr id="S3.T18.1.3" class="ltx_tr">
<td id="S3.T18.1.3.1" class="ltx_td ltx_align_left ltx_border_t">Train (60%)</td>
<td id="S3.T18.1.3.2" class="ltx_td ltx_align_center ltx_border_t">7,308</td>
<td id="S3.T18.1.3.3" class="ltx_td ltx_align_center ltx_border_t">4,729</td>
<td id="S3.T18.1.3.4" class="ltx_td ltx_align_center ltx_border_t">5,517</td>
<td id="S3.T18.1.3.5" class="ltx_td ltx_align_center ltx_border_t">17,554</td>
</tr>
<tr id="S3.T18.1.4" class="ltx_tr">
<td id="S3.T18.1.4.1" class="ltx_td ltx_align_left">Dev (20%)</td>
<td id="S3.T18.1.4.2" class="ltx_td ltx_align_center">2,437</td>
<td id="S3.T18.1.4.3" class="ltx_td ltx_align_center">1,571</td>
<td id="S3.T18.1.4.4" class="ltx_td ltx_align_center">1,833</td>
<td id="S3.T18.1.4.5" class="ltx_td ltx_align_center">5,841</td>
</tr>
<tr id="S3.T18.1.5" class="ltx_tr">
<td id="S3.T18.1.5.1" class="ltx_td ltx_align_left">Test (20%)</td>
<td id="S3.T18.1.5.2" class="ltx_td ltx_align_center">2,462</td>
<td id="S3.T18.1.5.3" class="ltx_td ltx_align_center">1,595</td>
<td id="S3.T18.1.5.4" class="ltx_td ltx_align_center">1,861</td>
<td id="S3.T18.1.5.5" class="ltx_td ltx_align_center">5,918</td>
</tr>
<tr id="S3.T18.1.6" class="ltx_tr">
<td id="S3.T18.1.6.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">Total (100%)</td>
<td id="S3.T18.1.6.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">12,207</td>
<td id="S3.T18.1.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">7,895</td>
<td id="S3.T18.1.6.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">9,211</td>
<td id="S3.T18.1.6.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">29,313</td>
</tr>
</tbody></table>
</figure>
<figure id="S3.T19" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 19:</span>KLUE-MRC의 통계.</figcaption>
<table id="S3.T19.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T19.1.1" class="ltx_tr">
<td id="S3.T19.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T19.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T19.1.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T19.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T19.1.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T19.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T19.1.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T19.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T19.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T19.1.2" class="ltx_tr">
<td id="S3.T19.1.2.1" class="ltx_td ltx_align_left ltx_border_t"># Documents</td>
<td id="S3.T19.1.2.2" class="ltx_td ltx_align_center ltx_border_t">12,174</td>
<td id="S3.T19.1.2.3" class="ltx_td ltx_align_center ltx_border_t">5,075</td>
<td id="S3.T19.1.2.4" class="ltx_td ltx_align_center ltx_border_t">5,094</td>
<td id="S3.T19.1.2.5" class="ltx_td ltx_align_center ltx_border_t">22,343</td>
</tr>
<tr id="S3.T19.1.3" class="ltx_tr">
<td id="S3.T19.1.3.1" class="ltx_td ltx_align_left"># Passages</td>
<td id="S3.T19.1.3.2" class="ltx_td ltx_align_center">13,072</td>
<td id="S3.T19.1.3.3" class="ltx_td ltx_align_center">5,310</td>
<td id="S3.T19.1.3.4" class="ltx_td ltx_align_center">5,335</td>
<td id="S3.T19.1.3.5" class="ltx_td ltx_align_center">23,717</td>
</tr>
<tr id="S3.T19.1.4" class="ltx_tr">
<td id="S3.T19.1.4.1" class="ltx_td ltx_align_left"># Questions</td>
<td id="S3.T19.1.4.2" class="ltx_td ltx_align_center">17,554</td>
<td id="S3.T19.1.4.3" class="ltx_td ltx_align_center">5,841</td>
<td id="S3.T19.1.4.4" class="ltx_td ltx_align_center">5,918</td>
<td id="S3.T19.1.4.5" class="ltx_td ltx_align_center">29,313</td>
</tr>
<tr id="S3.T19.1.5" class="ltx_tr">
<td id="S3.T19.1.5.1" class="ltx_td ltx_align_left ltx_border_t">Avg Length of Passage</td>
<td id="S3.T19.1.5.2" class="ltx_td ltx_align_center ltx_border_t">1,004.62</td>
<td id="S3.T19.1.5.3" class="ltx_td ltx_align_center ltx_border_t">1,014.64</td>
<td id="S3.T19.1.5.4" class="ltx_td ltx_align_center ltx_border_t">1,010.13</td>
<td id="S3.T19.1.5.5" class="ltx_td ltx_align_center ltx_border_t">1,008.10</td>
</tr>
<tr id="S3.T19.1.6" class="ltx_tr">
<td id="S3.T19.1.6.1" class="ltx_td ltx_align_left">Avg Length of Question</td>
<td id="S3.T19.1.6.2" class="ltx_td ltx_align_center">29.00</td>
<td id="S3.T19.1.6.3" class="ltx_td ltx_align_center">29.05</td>
<td id="S3.T19.1.6.4" class="ltx_td ltx_align_center">29.01</td>
<td id="S3.T19.1.6.5" class="ltx_td ltx_align_center">29.01</td>
</tr>
<tr id="S3.T19.1.7" class="ltx_tr">
<td id="S3.T19.1.7.1" class="ltx_td ltx_align_left ltx_border_bb">Avg Length of Answer</td>
<td id="S3.T19.1.7.2" class="ltx_td ltx_align_center ltx_border_bb">6.03</td>
<td id="S3.T19.1.7.3" class="ltx_td ltx_align_center ltx_border_bb">6.03</td>
<td id="S3.T19.1.7.4" class="ltx_td ltx_align_center ltx_border_bb">5.82</td>
<td id="S3.T19.1.7.5" class="ltx_td ltx_align_center ltx_border_bb">5.99</td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="S3.SS7.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.7.2 </span>Evaluation Metrics</h4>

<div id="S3.SS7.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS2.p1.1">KLUE-MRC에 대한 평가 메트릭은 1) 정확한 일치(EM) 및 2) 문자 수준 ROUGE-W(ROUGE) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib80" title="">80</a>]</cite>이며, 이는 LCCS( longest common consecutive subsequence) 기반 F1 점수로 볼 수 있다. EM은 그라운드 트루스와 예측된 답변 문자열의 동일성을 측정하는 MRC 작업에 가장 일반적으로 사용되는 메트릭이다. 다수의 골드 라벨이 있는 경우, 모델은 적어도 하나의 예측이 매칭될 때 점수를 획득할 수 있다. 대조적으로, ROUGE는 모델이 정확하게 일치하는 답변을 예측하지 못하더라도 부분 점수를 제공한다. 한글의 특성상 한 단어 안에 답변 스팬이 위치할 수 있으므로 하위 단어 수준의 스팬을 고려해야 한다. ROUGE는 예측에 대한 LCCS의 길이 비율과 그라운드 트루스 문자열에 대한 LCCS의 길이 비율의 F1 점수를 계산한다. 여러 개의 진리 답변이 동일한 의미를 갖지만 서로 다른 어휘 변동(예: TV, Television)을 갖는 경우, 우리는 답변과 예측의 조합 중 최대 ROUGE 점수를 사용한다. 기존의 모든 한국어 MRC 데이터 세트에서 사용되는 문자 수준 F1 점수(char F1)는 순서에 관계없이 문자 중복을 측정하기 때문에 채택하지 않는다. 모델이 “한국의 위인들”을 예측하고 대답이 “국한 범위(제한된 범위)”일 때, 메트릭은 낮은 점수를 주어야 한다. ROUGE 점수는 15.38인 반면 char F1은 "한", "국", "위"의 중첩으로 인해 54.55를 제공한다.</p>
</div>
</section>
<section id="S3.SS7.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.7.3 </span>Analysis</h4>

<div id="S3.SS7.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS3.p1.1">우리는 KLUE-MRC를 다른 한국 MRC 데이터 세트와 비교하여 조사한다. KorQuAD 1.0 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib79" title="">79</a>]</cite>와 2.0 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib63" title="">63</a>]</cite>는 한국 MRC 연구에서 일반적으로 사용되며 훈련 및 평가 세트로 별도로 출시된다. 그러나 KorQuAD 2.0은 HTML 태그와 표에서 우리와 KorQUAD 1.0에 비해 내용 구성이 상당히 다르다. 따라서 KorQuAD 1.0 데이터세트와만 비교를 수행한다. KorQuAD 1.0 dev 세트는 테스트 세트를 사용할 수 없기 때문에 레버리지되었습니다.</p>
</div>
<section id="S3.SS7.SSS3.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Question Difficulty of KLUE-MRC Evaluation Set</h5>

<div id="S3.SS7.SSS3.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS3.Px1.p1.1">KLUE-MRC를 도전적으로 만드는 것을 목표로 하기 때문에 테스트 세트의 난이도를 확인하는 것이 필요하다. 우리는 표 <a class="ltx_ref" href="#S3.T20" title="Table 20 ‣ Question Difficulty of KLUE-MRC Evaluation Set ‣ 3.7.3 Analysis ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">20</span></a>의 두 데이터 세트로 훈련된 모델과 우리 및 KorQuAD 1.0의 평가 세트에 대한 성능을 비교한다. 두 데이터 세트의 열차 집합으로 모델<span class="ltx_note ltx_role_footnote" id="footnote43"><sup class="ltx_note_mark">43</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">43</sup><span class="ltx_tag ltx_tag_note">43</span>We fine-tune pretrained RoBERTa-base model with following hyperparameters: epochs 5, batch size 16, learning rate 3e-5, lr warmup ratio 0.0.</span></span></span>을 미세 조정하고 각 평가 집합에서 모델을 테스트한다.</p>
</div>
<div id="S3.SS7.SSS3.Px1.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS3.Px1.p2.1">KorQuAD 1.0 열차 예(60,407)는 KLUE-MRC(17,554)보다 거의 4배 더 크며, 이는 KorQuAD 1.0 dev 세트에 대해 더 높은 성능을 초래했을 수 있다. 우리는 또한 공정한 비교를 위해 동일한 양의 두 열차 데이터 세트의 모음으로 미세 조정을 수행한다. KLUE-MRC 열차 집합의 크기에 맞게 무작위 샘플링을 통해 KorQuAD 1.0 열차 집합을 조정한다. 표 <a class="ltx_ref" href="#S3.T20" title="Table 20 ‣ Question Difficulty of KLUE-MRC Evaluation Set ‣ 3.7.3 Analysis ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">20</span></a>는 KorQuAD 1.0에 비해 일관되게 낮은 KLUE-MRC 점수를 보여준다. 따라서, 우리의 데이터 세트는 열차 세트의 크기에 관계없이 더 어렵다.</p>
</div>
<figure id="S3.T20" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 20:</span>KLUE-MRC 테스트와 KorQuAD 1.0 dev set 간의 난이도 비교.</figcaption>
<table id="S3.T20.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T20.1.1" class="ltx_tr">
<td id="S3.T20.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T20.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T20.1.1.2.1" class="ltx_text ltx_font_bold">KLUE + KorQuAD (Full:Full)</span></td>
<td id="S3.T20.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T20.1.1.3.1" class="ltx_text ltx_font_bold">KLUE + KorQuAD (1:1)</span></td>
</tr>
<tr id="S3.T20.1.2" class="ltx_tr">
<td id="S3.T20.1.2.1" class="ltx_td ltx_align_left"><span id="S3.T20.1.2.1.1" class="ltx_text ltx_font_bold">Evaluation Dataset</span></td>
<td id="S3.T20.1.2.2" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S3.T20.1.2.3" class="ltx_td ltx_align_center ltx_border_t">ROUGE</td>
<td id="S3.T20.1.2.4" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S3.T20.1.2.5" class="ltx_td ltx_align_center ltx_border_t">ROUGE</td>
</tr>
<tr id="S3.T20.1.3" class="ltx_tr">
<td id="S3.T20.1.3.1" class="ltx_td ltx_align_left ltx_border_t">KorQuAD 1.0 (Dev)</td>
<td id="S3.T20.1.3.2" class="ltx_td ltx_align_center ltx_border_t">86.59</td>
<td id="S3.T20.1.3.3" class="ltx_td ltx_align_center ltx_border_t">94.19</td>
<td id="S3.T20.1.3.4" class="ltx_td ltx_align_center ltx_border_t">85.00</td>
<td id="S3.T20.1.3.5" class="ltx_td ltx_align_center ltx_border_t">93.07</td>
</tr>
<tr id="S3.T20.1.4" class="ltx_tr">
<td id="S3.T20.1.4.1" class="ltx_td ltx_align_left ltx_border_bb">KLUE-MRC (Test)</td>
<td id="S3.T20.1.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T20.1.4.2.1" class="ltx_text ltx_font_bold">70.42</span></td>
<td id="S3.T20.1.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T20.1.4.3.1" class="ltx_text ltx_font_bold">75.42</span></td>
<td id="S3.T20.1.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T20.1.4.4.1" class="ltx_text ltx_font_bold">69.75</span></td>
<td id="S3.T20.1.4.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T20.1.4.5.1" class="ltx_text ltx_font_bold">75.20</span></td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS7.SSS3.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Lexical Overlap</h5>

<div id="S3.SS7.SSS3.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS3.Px2.p1.1">질문과 통과 사이의 어휘 중복이 높으면 바로 가기 추론이 발생할 수 있으므로 어휘 중복을 줄이는 것이 도전적인 데이터 세트를 구축하는 데 중요하다. 제안된 엄격한 지침과 도전적인 질문 유형의 효과를 조사하기 위해, 우리와 KorQuAD 1.0의 어휘 중첩을 계산한다. 어휘 중첩 비율은 질문과 통과 사이의 공통 구성 요소의 수를 질문의 구성 요소의 수로 나누어 계산한다. 개방형 한국형 POS 태거를 통해 중첩 비율을 계산할 때 위치(조사, 조사)와 어미 성분(어미, 어미)과 같은 기능 입자를 제외한다. <span class="ltx_note ltx_role_footnote" id="footnote44"><sup class="ltx_note_mark">44</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">44</sup><span class="ltx_tag ltx_tag_note">44</span>Twitter tagger of KoNLPy <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib101" title="">101</a>]</cite>.</span></span></span> 어휘 중복 비율은 KorQuAD 데이터 세트(70%)보다 거의 10%p 낮다. 각 문항 유형에 대해 유형 1과 유형 3은 55%에서 59%의 범위에서 유사한 비율을 보인다. 유형 2는 68%의 중첩 비율을 나타낸다.</p>
</div>
</section>
<section id="S3.SS7.SSS3.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Human Evaluation</h5>

<div id="S3.SS7.SSS3.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS3.Px3.p1.1">우리의 KLUE-MRC에서 인간의 독해 능력에 대한 난이도를 측정하기 위해 인간의 성능을 평가한다. 테스트 세트에서 1,000개의 예를 무작위로 샘플링하고 이를 해결하기 위해 3명의 직원을 고용합니다. 우리는 최고 득점자의 점수를 인간 성과로 선정한다. 표 <a class="ltx_ref" href="#S3.T21" title="Table 21 ‣ Human Evaluation ‣ 3.7.3 Analysis ‣ 3.7 Machine Reading Comprehension (MRC) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">21</span></a>는 인간 성능과 기본 모델의 비교를 보고한다.</p>
</div>
<figure id="S3.T21" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 21:</span>모델 예측과 인간 답변 간의 평가 점수 비교</figcaption>
<table id="S3.T21.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T21.1.2" class="ltx_tr">
<td id="S3.T21.1.2.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T21.1.2.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T21.1.2.2.1" class="ltx_text ltx_font_bold">Paraphrase</span></td>
<td id="S3.T21.1.2.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T21.1.2.3.1" class="ltx_text ltx_font_bold">Multi-sentence</span></td>
<td id="S3.T21.1.2.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T21.1.2.4.1" class="ltx_text ltx_font_bold">Unanswerable</span></td>
<td id="S3.T21.1.2.5" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S3.T21.1.2.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T21.1.3" class="ltx_tr">
<td id="S3.T21.1.3.1" class="ltx_td"></td>
<td id="S3.T21.1.3.2" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S3.T21.1.3.3" class="ltx_td ltx_align_center ltx_border_t">ROUGE</td>
<td id="S3.T21.1.3.4" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S3.T21.1.3.5" class="ltx_td ltx_align_center ltx_border_t">ROUGE</td>
<td id="S3.T21.1.3.6" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S3.T21.1.3.7" class="ltx_td ltx_align_center ltx_border_t">ROUGE</td>
<td id="S3.T21.1.3.8" class="ltx_td ltx_align_center ltx_border_t">EM</td>
<td id="S3.T21.1.3.9" class="ltx_td ltx_align_center ltx_border_t">ROUGE</td>
</tr>
<tr id="S3.T21.1.1" class="ltx_tr">
<td id="S3.T21.1.1.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S3.T21.1.1.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{BASE}}" display="inline"><semantics id="S3.T21.1.1.1.m1.1a"><msub id="S3.T21.1.1.1.m1.1.1" xref="S3.T21.1.1.1.m1.1.1.cmml"><mtext id="S3.T21.1.1.1.m1.1.1.2" xref="S3.T21.1.1.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext id="S3.T21.1.1.1.m1.1.1.3" xref="S3.T21.1.1.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.T21.1.1.1.m1.1b"><apply id="S3.T21.1.1.1.m1.1.1.cmml" xref="S3.T21.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T21.1.1.1.m1.1.1.1.cmml" xref="S3.T21.1.1.1.m1.1.1">subscript</csymbol><ci id="S3.T21.1.1.1.m1.1.1.2a.cmml" xref="S3.T21.1.1.1.m1.1.1.2"><mtext id="S3.T21.1.1.1.m1.1.1.2.cmml" xref="S3.T21.1.1.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S3.T21.1.1.1.m1.1.1.3a.cmml" xref="S3.T21.1.1.1.m1.1.1.3"><mtext mathsize="70%" id="S3.T21.1.1.1.m1.1.1.3.cmml" xref="S3.T21.1.1.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T21.1.1.1.m1.1c">\text{KLUE-RoBERTa}_{\text{BASE}}</annotation></semantics></math></td>
<td id="S3.T21.1.1.2" class="ltx_td ltx_align_center ltx_border_t">67.74</td>
<td id="S3.T21.1.1.3" class="ltx_td ltx_align_center ltx_border_t">75.73</td>
<td id="S3.T21.1.1.4" class="ltx_td ltx_align_center ltx_border_t">65.07</td>
<td id="S3.T21.1.1.5" class="ltx_td ltx_align_center ltx_border_t">73.13</td>
<td id="S3.T21.1.1.6" class="ltx_td ltx_align_center ltx_border_t">72.48</td>
<td id="S3.T21.1.1.7" class="ltx_td ltx_align_center ltx_border_t">72.48</td>
<td id="S3.T21.1.1.8" class="ltx_td ltx_align_center ltx_border_t">68.51</td>
<td id="S3.T21.1.1.9" class="ltx_td ltx_align_center ltx_border_t">74.01</td>
</tr>
<tr id="S3.T21.1.4" class="ltx_tr">
<td id="S3.T21.1.4.1" class="ltx_td ltx_align_left ltx_border_bb">Human</td>
<td id="S3.T21.1.4.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.2.1" class="ltx_text ltx_font_bold">84.18</span></td>
<td id="S3.T21.1.4.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.3.1" class="ltx_text ltx_font_bold">88.33</span></td>
<td id="S3.T21.1.4.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.4.1" class="ltx_text ltx_font_bold">87.72</span></td>
<td id="S3.T21.1.4.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.5.1" class="ltx_text ltx_font_bold">90.91</span></td>
<td id="S3.T21.1.4.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.6.1" class="ltx_text ltx_font_bold">86.53</span></td>
<td id="S3.T21.1.4.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.7.1" class="ltx_text ltx_font_bold">86.53</span></td>
<td id="S3.T21.1.4.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.8.1" class="ltx_text ltx_font_bold">85.90</span></td>
<td id="S3.T21.1.4.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T21.1.4.9.1" class="ltx_text ltx_font_bold">88.48</span></td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="S3.SS7.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.7.4 </span>Related Work</h4>

<div id="S3.SS7.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS4.p1.1">최근 몇 년 동안 영어 MRC 연구에서 패러프레이즈, 다중 문장 및 답변 불가능을 포함하지만 이에 국한되지 않는 다양한 질문 유형의 도전적인 데이터 세트를 사용하여 상당한 진전이 이루어졌다.</p>
</div>
<div id="S3.SS7.SSS4.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS4.p2.1">패러프레이징된 질문들은 질문과 읽기 패시지의 단어 중복이 낮아서 MRC 모델들이 단순한 단어 매칭을 이용하는 것을 방지한다. <cite class="ltx_cite ltx_citemacro_citet">Trischler et al. [<a class="ltx_ref" href="#bib.bib130" title="">130</a>]</cite> 뉴스 헤드라인에서 질문을 생성하고 크라우드소싱을 통해 요약하여 NewsQA 데이터 세트를 만듭니다. 그들은 질문 생성 동안 주어지지 않은 주요 기사에 답변을 주석함으로써 단어 중복을 줄인다. <cite class="ltx_cite ltx_citemacro_citet">Saha et al. [<a class="ltx_ref" href="#bib.bib120" title="">120</a>]</cite> Wikipedia 및 IMDb의 동일한 영화에 대한 플롯 요약의 레버리지 쌍입니다. <span class="ltx_note ltx_role_footnote" id="footnote45"><sup class="ltx_note_mark">45</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">45</sup><span class="ltx_tag ltx_tag_note">45</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.imdb.com/" target="_blank" title="">https://www.imdb.com/</a></span></span></span> 그들은 더 짧은 플롯에서 질문을 생성하고 더 긴 플롯에 답변을 주석하여 자연스럽게 패러프레이징된 질문을 얻는다. <cite class="ltx_cite ltx_citemacro_citet">Sen and Saffari [<a class="ltx_ref" href="#bib.bib122" title="">122</a>]</cite> 보고서는 낮은 질문-통과 중복을 갖는 데이터 세트가 MRC 모델의 일반화 가능성을 향상시킬 것이라고 보고한다.</p>
</div>
<div id="S3.SS7.SSS4.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS4.p3.1">다문장 문항은 여러 문장에 대한 추론을 필요로 한다. 그 결과 단문형 문항에 비해 난이도가 높다. <cite class="ltx_cite ltx_citemacro_citet">Joshi et al. [<a class="ltx_ref" href="#bib.bib56" title="">56</a>]</cite>는 트리비아 웹사이트의 질문 데이터세트인 TriviaQA를 소개한다. 다양한 출처(예: 위키피디아 및 웹)에서 증거 지문을 수집하기 때문에 주어진 질문에 답하기 위해 여러 문장이 자연스럽게 필요하다. <cite class="ltx_cite ltx_citemacro_citet">Khashabi et al. [<a class="ltx_ref" href="#bib.bib60" title="">60</a>]</cite>는 크라우드소싱을 통해 다양한 텍스트에 대한 다중 문장 질문을 명시적으로 생성하고 MultiRC 데이터셋을 릴리스한다. SuperGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib132" title="">132</a>]</cite> 벤치마크는 MultiRC 데이터 세트를 태스크 중 하나로 채택한다.</p>
</div>
<div id="S3.SS7.SSS4.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS4.p4.1">여러 MRC 데이터 세트는 응답할 수 없는 질문 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib143" title="">143</a>, <a class="ltx_ref" href="#bib.bib130" title="">130</a>, <a class="ltx_ref" href="#bib.bib96" title="">96</a>, <a class="ltx_ref" href="#bib.bib113" title="">113</a>, <a class="ltx_ref" href="#bib.bib69" title="">69</a>]</cite>를 통합했다. <cite class="ltx_cite ltx_citemacro_citet">Rajpurkar et al. [<a class="ltx_ref" href="#bib.bib113" title="">113</a>]</cite> 응답할 수 없는 질문이 데이터 세트에 포함된 경우 MRC 모델의 성능 저하를 보고합니다.</p>
</div>
<div id="S3.SS7.SSS4.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS4.p5.1">영어에 대한 MRC 연구에 비해, 한국어 MRC 연구는 소수의 기존 데이터 세트에 서 있다. 한국형 MRC의 주요 벤치마크는 SQuAD 1.0 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib112" title="">112</a>]</cite>와 동일한 데이터 수집 프로세스를 채택한 KorQuAD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib79" title="">79</a>, <a class="ltx_ref" href="#bib.bib63" title="">63</a>]</cite>이다. 그러나 KorQuAD에 대한 모델 성능은 이미 짧은 기간 동안 인간 성능을 초과하여 추가 연구를 위한 헤드룸을 거의 남기지 않았다. 더욱이, SQuAD와 달리, KorQuAD는 CC BY-ND 라이선스 하에 있고, 파생 저작물(예를 들어, 답변할 수 없는 질문 추가)을 허용하지 않는다. AI Hub MRC 데이터셋 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib1" title="">1</a>]</cite>는 신문을 기반으로 하며 답변할 수 없는 질문을 포함한다. 그러나 그 접근은 한국 토종 연구자에만 엄격히 제한되어 있어 한국에 거주하는 국제 연구자와의 협업도 금지하고 있다. K-QuAD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib74" title="">74</a>]</cite> leverage Google Translate<span class="ltx_note ltx_role_footnote" id="footnote46"><sup class="ltx_note_mark">46</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">46</sup><span class="ltx_tag ltx_tag_note">46</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://translate.google.co.kr/" target="_blank" title="">https://translate.google.co.kr/</a></span></span></span>를 이용하여 SQuAD 1.0 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib112" title="">112</a>]</cite>를 한국어로 번역한다. K-QuAD 데이터 세트는 시간이 지남에 따라 업데이트되지 않기 때문에 릴리스 시 기계 번역기의 성능에 따라 품질이 달라집니다. 우리의 KLUE-MRC는 접근성 강화 라이선스와 더 어려운 어려움 측면에서 기존의 한국 MRC 벤치마크와 다르다.</p>
</div>
</section>
<section id="S3.SS7.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.7.5 </span>Conclusion</h4>

<div id="S3.SS7.SSS5.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS7.SSS5.p1.1">우리는 새로운 도전적인 한국 MRC 벤치마크(KLUE-MRC)를 만듭니다. MRC 능력의 다양한 측면을 평가하기 위해 KLUE-MRC는 다중 영역 지문과 패러프레이즈, 다중 문장 추론 및 답할 수 없는 세 가지 유형의 질문을 포함한다. KLUE-MRC는 기존의 한국어 MRC 데이터셋에 비해 질문 유형 다양성, 난이도, 어휘 중복성이 개선되었다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="S3.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.8 </span>Dialogue State Tracking (DST)</h3>

<div id="S3.SS8.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.p1.1">인간-컴퓨터 대화 시스템 구축은 점점 더 주목을 받고 있으며, 과제 중심 대화 시스템은 대화 시스템<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib14" title="">14</a>]</cite>의 한 유형이다. 작업 지향 대화 시스템의 핵심 모듈, 즉 DST(Dialogue State Tracking)는 주어진 대화 컨텍스트로부터 <span class="ltx_text ltx_font_italic" id="S3.SS8.p1.1.1">dialogue states</span>을 예측하는 것이다. 표 <a class="ltx_ref" href="#S3.T22" title="Table 22 ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">22</span></a>에 예시된 바와 같이, 대화 상태는 각각 관련 카테고리(예: 호텔 유형) 및 가능한 값(예: 게스트 하우스, 호텔, 모텔)인 슬롯 및 값 쌍의 세트이다.</p>
</div>
<div id="S3.SS8.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS8.p2.1">최근 몇몇 연구에서는 태스크 지향 대화(TOD)를 자연어 이해의 중요한 문제로 간주하고 있다. 예를 들어, DecaNLP <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib85" title="">85</a>]</cite>는 TOD의 핵심 구성 요소인 DST를 벤치마크 태스크 중 하나로 포함하고, DialoGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib88" title="">88</a>]</cite>는 DST를 포함한 다양한 하위 태스크를 포함하는 첫 번째 태스크 지향 대화 벤치마크를 출시한다. 이러한 점에 비추어, 우리는 KLUE 벤치마크의 일부로 DST를 포함한다.</p>
</div>
<div id="S3.SS8.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS8.p3.1">대화 상태 추적의 작업은 각 사용자 발화 후에 슬롯과 값 쌍을 예측하는 것이며, 잠재적 쌍은 시나리오의 선택에 묶여 태스크 스키마와 지식 베이스(KB)에 의해 미리 정의된다. 평가에는 Joint goal accuracy (JGA)와 slot micro F1 score를 사용하였다. JGA는 모든 예측된 슬롯-값 쌍이 매 턴마다 그라운드-진실과 정확하게 일치하는지 확인하는 반면 슬롯 마이크로 F1은 각 슬롯-값 쌍에 대해 독립적으로 f1 점수를 계산한다. <span class="ltx_note ltx_role_footnote" id="footnote47"><sup class="ltx_note_mark">47</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">47</sup><span class="ltx_tag ltx_tag_note">47</span>We adopt the evaluation script of <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/jasonwu0731/trade-dst" target="_blank" title="">https://github.com/jasonwu0731/trade-dst</a></span></span></span></p>
</div>
<figure id="S3.T22" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 22:</span>우리 WoS에서 대화 상태 추적의 예. 모든 대화 상태는 실제 데이터 세트에서 누적되며 사용자가 돌리는 상태만 추적합니다.</figcaption>
<div id="S3.T22.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:368.6pt;height:267pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-63.6pt,46.0pt) scale(0.743394455940881,0.743394455940881) ;">
<table id="S3.T22.1.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T22.1.1.1" class="ltx_tr">
<td id="S3.T22.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T22.1.1.1.1.1" class="ltx_text ltx_font_bold">Utterances (English Translations)</span></td>
<td id="S3.T22.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T22.1.1.1.2.1" class="ltx_text ltx_font_bold">Dialogue States</span></td>
</tr>
<tr id="S3.T22.1.1.2" class="ltx_tr">
<td id="S3.T22.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T22.1.1.2.1.1" class="ltx_text ltx_font_bold">User</span>: <span id="S3.T22.1.1.2.1.2" class="ltx_text" style="font-size:90%;">안녕하세요. (Hello.)</span>
</td>
<td id="S3.T22.1.1.2.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">-</td>
</tr>
<tr id="S3.T22.1.1.3" class="ltx_tr">
<td id="S3.T22.1.1.3.1" class="ltx_td ltx_align_left ltx_border_t">
<table id="S3.T22.1.1.3.1.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T22.1.1.3.1.1.1" class="ltx_tr">
<td id="S3.T22.1.1.3.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.3.1.1.1.1.1" class="ltx_text ltx_font_bold">Sys</span>: <span id="S3.T22.1.1.3.1.1.1.1.2" class="ltx_text" style="font-size:90%;">네. 안녕하세요. 무엇을 도와드릴까요? (Hello. How can I help?)</span>
</td>
</tr>
<tr id="S3.T22.1.1.3.1.1.2" class="ltx_tr">
<td id="S3.T22.1.1.3.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.3.1.1.2.1.1" class="ltx_text ltx_font_bold">User</span>: <span id="S3.T22.1.1.3.1.1.2.1.2" class="ltx_text ltx_font_bold" style="font-size:90%;">서울 중앙<span id="S3.T22.1.1.3.1.1.2.1.2.1" class="ltx_text ltx_font_medium">에 위치한 </span>호텔<span id="S3.T22.1.1.3.1.1.2.1.2.2" class="ltx_text ltx_font_medium">을 찾고 있습니다. 외국인 친구도 함께</span></span>
</td>
</tr>
<tr id="S3.T22.1.1.3.1.1.3" class="ltx_tr">
<td id="S3.T22.1.1.3.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.3.1.1.3.1.1" class="ltx_text" style="font-size:90%;">갈 예정이라서 원활하게 <span id="S3.T22.1.1.3.1.1.3.1.1.1" class="ltx_text ltx_font_bold">인터넷을 사용할 수 있는 곳</span>이었으면 좋겠어요.</span></td>
</tr>
<tr id="S3.T22.1.1.3.1.1.4" class="ltx_tr">
<td id="S3.T22.1.1.3.1.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">(I’m looking for a <span id="S3.T22.1.1.3.1.1.4.1.1" class="ltx_text ltx_font_bold">hotel</span> at the city <span id="S3.T22.1.1.3.1.1.4.1.2" class="ltx_text ltx_font_bold">center</span>. I’m going with a foreign friend,</td>
</tr>
<tr id="S3.T22.1.1.3.1.1.5" class="ltx_tr">
<td id="S3.T22.1.1.3.1.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">so easy access to the <span id="S3.T22.1.1.3.1.1.5.1.1" class="ltx_text ltx_font_bold">Internet should be available</span>.)</td>
</tr>
</tbody></table>
</td>
<td id="S3.T22.1.1.3.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">
<table id="S3.T22.1.1.3.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T22.1.1.3.2.1.1" class="ltx_tr">
<td id="S3.T22.1.1.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.3.2.1.1.1.1" class="ltx_text ltx_font_bold" style="color:#0AFFFF;">Hotel-area<span id="S3.T22.1.1.3.2.1.1.1.1.1" class="ltx_text ltx_font_medium">: center</span></span></td>
</tr>
<tr id="S3.T22.1.1.3.2.1.2" class="ltx_tr">
<td id="S3.T22.1.1.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.3.2.1.2.1.1" class="ltx_text ltx_font_bold" style="color:#0AFFFF;">Hotel-type<span id="S3.T22.1.1.3.2.1.2.1.1.1" class="ltx_text ltx_font_medium">: hotel</span></span></td>
</tr>
<tr id="S3.T22.1.1.3.2.1.3" class="ltx_tr">
<td id="S3.T22.1.1.3.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.3.2.1.3.1.1" class="ltx_text ltx_font_bold" style="color:#0AFFFF;">Hotel-internet<span id="S3.T22.1.1.3.2.1.3.1.1.1" class="ltx_text ltx_font_medium">: yes</span></span></td>
</tr>
</tbody></table>
</td>
</tr>
<tr id="S3.T22.1.1.4" class="ltx_tr">
<td id="S3.T22.1.1.4.1" class="ltx_td ltx_align_left ltx_border_t">
<table id="S3.T22.1.1.4.1.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T22.1.1.4.1.1.1" class="ltx_tr">
<td id="S3.T22.1.1.4.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Sys</span>: <span id="S3.T22.1.1.4.1.1.1.1.2" class="ltx_text" style="font-size:90%;">네 확인해보겠습니다. 혹시 추가로 필요하신 사항이 있으실까요?</span>
</td>
</tr>
<tr id="S3.T22.1.1.4.1.1.2" class="ltx_tr">
<td id="S3.T22.1.1.4.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(Sure, let me check. Do you need anything else?)</td>
</tr>
<tr id="S3.T22.1.1.4.1.1.3" class="ltx_tr">
<td id="S3.T22.1.1.4.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.4.1.1.3.1.1" class="ltx_text ltx_font_bold">User</span>: <span id="S3.T22.1.1.4.1.1.3.1.2" class="ltx_text" style="font-size:90%;">음… 예약 인원은 총 <span id="S3.T22.1.1.4.1.1.3.1.2.1" class="ltx_text ltx_font_bold">8명</span>이고요. 아, <span id="S3.T22.1.1.4.1.1.3.1.2.2" class="ltx_text ltx_font_bold">가격대는 크게 상관 없습니다</span>.</span>
</td>
</tr>
<tr id="S3.T22.1.1.4.1.1.4" class="ltx_tr">
<td id="S3.T22.1.1.4.1.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">(Hmm.. I want to reserve for <span id="S3.T22.1.1.4.1.1.4.1.1" class="ltx_text ltx_font_bold">8 people</span>. Ah, the <span id="S3.T22.1.1.4.1.1.4.1.2" class="ltx_text ltx_font_bold">price range doesn’t matter</span>.)</td>
</tr>
</tbody></table>
</td>
<td id="S3.T22.1.1.4.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">
<table id="S3.T22.1.1.4.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T22.1.1.4.2.1.1" class="ltx_tr">
<td id="S3.T22.1.1.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.4.2.1.1.1.1" class="ltx_text ltx_font_bold">Hotel-area</span>: center</td>
</tr>
<tr id="S3.T22.1.1.4.2.1.2" class="ltx_tr">
<td id="S3.T22.1.1.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.4.2.1.2.1.1" class="ltx_text ltx_font_bold">Hotel-type</span>: hotel</td>
</tr>
<tr id="S3.T22.1.1.4.2.1.3" class="ltx_tr">
<td id="S3.T22.1.1.4.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.4.2.1.3.1.1" class="ltx_text ltx_font_bold">Hotel-internet</span>: yes</td>
</tr>
<tr id="S3.T22.1.1.4.2.1.4" class="ltx_tr">
<td id="S3.T22.1.1.4.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.4.2.1.4.1.1" class="ltx_text ltx_font_bold" style="color:#0AFFFF;">Hotel-book people<span id="S3.T22.1.1.4.2.1.4.1.1.1" class="ltx_text ltx_font_medium">: 8</span></span></td>
</tr>
<tr id="S3.T22.1.1.4.2.1.5" class="ltx_tr">
<td id="S3.T22.1.1.4.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.4.2.1.5.1.1" class="ltx_text ltx_font_bold" style="color:#0AFFFF;">Hotel-price range<span id="S3.T22.1.1.4.2.1.5.1.1.1" class="ltx_text ltx_font_medium">: dontcare</span></span></td>
</tr>
</tbody></table>
</td>
</tr>
<tr id="S3.T22.1.1.5" class="ltx_tr">
<td id="S3.T22.1.1.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<table id="S3.T22.1.1.5.1.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T22.1.1.5.1.1.1" class="ltx_tr">
<td id="S3.T22.1.1.5.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.5.1.1.1.1.1" class="ltx_text ltx_font_bold">Sys</span>: <span id="S3.T22.1.1.5.1.1.1.1.2" class="ltx_text" style="font-size:90%;">네, 확인 감사합니다. 숙박을 원하시는 요일과 기간 같이 확인 부탁드립니다.</span>
</td>
</tr>
<tr id="S3.T22.1.1.5.1.1.2" class="ltx_tr">
<td id="S3.T22.1.1.5.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(Great, thanks for confirming. Please let us know when and how long</td>
</tr>
<tr id="S3.T22.1.1.5.1.1.3" class="ltx_tr">
<td id="S3.T22.1.1.5.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">you want to stay.)</td>
</tr>
<tr id="S3.T22.1.1.5.1.1.4" class="ltx_tr">
<td id="S3.T22.1.1.5.1.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.5.1.1.4.1.1" class="ltx_text ltx_font_bold">User</span>: <span id="S3.T22.1.1.5.1.1.4.1.2" class="ltx_text" style="font-size:90%;">아, 중요한 걸 깜빡했네요. <span id="S3.T22.1.1.5.1.1.4.1.2.1" class="ltx_text ltx_font_bold">일요일</span>에 <span id="S3.T22.1.1.5.1.1.4.1.2.2" class="ltx_text ltx_font_bold">2일</span>간 예약하고 싶습니다.</span>
</td>
</tr>
<tr id="S3.T22.1.1.5.1.1.5" class="ltx_tr">
<td id="S3.T22.1.1.5.1.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">(Right, I forgot an important thing. I would like to book for <span id="S3.T22.1.1.5.1.1.5.1.1" class="ltx_text ltx_font_bold">two days</span>
</td>
</tr>
<tr id="S3.T22.1.1.5.1.1.6" class="ltx_tr">
<td id="S3.T22.1.1.5.1.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left">from <span id="S3.T22.1.1.5.1.1.6.1.1" class="ltx_text ltx_font_bold">Sunday</span>.)</td>
</tr>
</tbody></table>
</td>
<td id="S3.T22.1.1.5.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t">
<table id="S3.T22.1.1.5.2.1" class="ltx_tabular ltx_align_middle">
<tbody><tr id="S3.T22.1.1.5.2.1.1" class="ltx_tr">
<td id="S3.T22.1.1.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.5.2.1.1.1.1" class="ltx_text ltx_font_bold">Hotel-area</span>: center</td>
</tr>
<tr id="S3.T22.1.1.5.2.1.2" class="ltx_tr">
<td id="S3.T22.1.1.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.5.2.1.2.1.1" class="ltx_text ltx_font_bold">Hotel-type</span>: hotel</td>
</tr>
<tr id="S3.T22.1.1.5.2.1.3" class="ltx_tr">
<td id="S3.T22.1.1.5.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.5.2.1.3.1.1" class="ltx_text ltx_font_bold">Hotel-internet</span>: yes</td>
</tr>
<tr id="S3.T22.1.1.5.2.1.4" class="ltx_tr">
<td id="S3.T22.1.1.5.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.5.2.1.4.1.1" class="ltx_text ltx_font_bold">Hotel-book people</span>: 8</td>
</tr>
<tr id="S3.T22.1.1.5.2.1.5" class="ltx_tr">
<td id="S3.T22.1.1.5.2.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S3.T22.1.1.5.2.1.5.1.1" class="ltx_text ltx_font_bold">Hotel-price range</span>: dontcare</td>
</tr>
<tr id="S3.T22.1.1.5.2.1.6" class="ltx_tr">
<td id="S3.T22.1.1.5.2.1.6.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.5.2.1.6.1.1" class="ltx_text ltx_font_bold" style="color:#0AFFFF;">Hotel-book day<span id="S3.T22.1.1.5.2.1.6.1.1.1" class="ltx_text ltx_font_medium">: Sunday</span></span></td>
</tr>
<tr id="S3.T22.1.1.5.2.1.7" class="ltx_tr">
<td id="S3.T22.1.1.5.2.1.7.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S3.T22.1.1.5.2.1.7.1.1" class="ltx_text ltx_font_bold" style="color:#0AFFFF;">Hotel-book stay<span id="S3.T22.1.1.5.2.1.7.1.1.1" class="ltx_text ltx_font_medium">: 2</span></span></td>
</tr>
</tbody></table>
</td>
</tr>
</tbody></table>
</span></div>
</figure>
<section id="S3.SS8.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.8.1 </span>Dataset Construction</h4>

<div id="S3.SS8.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.p1.1">우리의 데이터세트 구축 프로토콜은 대화 데이터세트 구축을 위해 널리 사용되는 패러다임인 Wizard-of-Oz 프레임워크(WOZ) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib59" title="">59</a>]</cite>의 수정된 버전이다. WOZ 설정은 사용자 및 시스템 역할을 하는 두 사람을 고용하는 인간 대 인간 대화 컬렉션의 특정 유형이다. 그러나 틀림없이 시간이 많이 걸리고 복잡하며 비싼 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib11" title="">11</a>]</cite>이다. 이러한 한계를 극복하기 위해 단일 작업자에게 사용자와 시스템 역할을 모두 수행하도록 요청하는 ‘Self-dialog’ 방식을 채택하였다. 또한 보다 정확한 대화 데이터 세트를 얻기 위한 새로운 디자인 선택을 소개한다.</p>
</div>
<section id="S3.SS8.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Overview</h5>

<div id="S3.SS8.SSS1.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.Px1.p1.1">우리는 1) 태스크 스키마 정의, 2) 지식베이스 생성, 3) 어노테이션 시스템 설계, 4) 데이터셋 수집 및 주석, 5) 데이터셋 최종의 다섯 단계로 WoS를 구성한다. 우리의 벤치마크의 다른 데이터 세트와 달리 WoS는 원시 말뭉치를 수집한 후 레이블에 주석을 달아야 하는 일반적인 프로토콜을 따르지 않는다. 오히려, 우리는 대화(원시 말뭉치)와 그들의 대응하는 대화 상태(라벨)를 동시에 수집한다.</p>
</div>
<figure id="S3.T23" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 23:</span>Task schema for all five domains in Wizard of Seoul (WoS) which show the names of domain and their slots. Star<sup class="ltx_sup" id="S3.T23.54.1">⋆</sup>, asterisk<sup class="ltx_sup" id="S3.T23.55.2">∗</sup>, cross<sup class="ltx_sup" id="S3.T23.56.3">†</sup>, doubly-crosses<sup class="ltx_sup" id="S3.T23.57.4">‡</sup>는 각각 필수, 부울 유형, 예약 관련 및 예약 슬롯 후 요청 가능을 나타냅니다.</figcaption>
<table id="S3.T23.49" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T23.49.42" class="ltx_tr">
<td id="S3.T23.49.42.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T23.49.42.1.1" class="ltx_text ltx_font_bold">Domains</span></td>
<td id="S3.T23.49.42.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T23.49.42.2.1" class="ltx_text ltx_font_bold">Informable Slots</span></td>
<td id="S3.T23.49.42.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T23.49.42.3.1" class="ltx_text ltx_font_bold">Requestable Slots</span></td>
</tr>
<tr id="S3.T23.23.15" class="ltx_tr">
<td id="S3.T23.23.15.16" class="ltx_td ltx_align_left ltx_border_t">Hotel</td>
<td id="S3.T23.22.14.14" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.22.14.14.15" class="ltx_text"></span><span id="S3.T23.22.14.14.14" class="ltx_text">
<span id="S3.T23.22.14.14.14.14" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.11.3.3.3.3.3" class="ltx_tr">
<span id="S3.T23.11.3.3.3.3.3.3" class="ltx_td ltx_nopad_r ltx_align_left">name, type<sup id="S3.T23.11.3.3.3.3.3.3.1" class="ltx_sup">⋆</sup>, area<sup id="S3.T23.11.3.3.3.3.3.3.2" class="ltx_sup">⋆</sup>, price range<sup id="S3.T23.11.3.3.3.3.3.3.3" class="ltx_sup">⋆</sup>,</span></span>
<span id="S3.T23.14.6.6.6.6.6" class="ltx_tr">
<span id="S3.T23.14.6.6.6.6.6.3" class="ltx_td ltx_nopad_r ltx_align_left">book day<sup id="S3.T23.14.6.6.6.6.6.3.1" class="ltx_sup">†</sup>, book stay<sup id="S3.T23.14.6.6.6.6.6.3.2" class="ltx_sup">†</sup>, book people<sup id="S3.T23.14.6.6.6.6.6.3.3" class="ltx_sup">†</sup>,</span></span>
<span id="S3.T23.17.9.9.9.9.9" class="ltx_tr">
<span id="S3.T23.17.9.9.9.9.9.3" class="ltx_td ltx_nopad_r ltx_align_left">walkability<sup id="S3.T23.17.9.9.9.9.9.3.1" class="ltx_sup">∗</sup>, parking<sup id="S3.T23.17.9.9.9.9.9.3.2" class="ltx_sup">∗</sup>, internet<sup id="S3.T23.17.9.9.9.9.9.3.3" class="ltx_sup">∗</sup>,</span></span>
<span id="S3.T23.20.12.12.12.12.12" class="ltx_tr">
<span id="S3.T23.20.12.12.12.12.12.3" class="ltx_td ltx_nopad_r ltx_align_left">breakfast<sup id="S3.T23.20.12.12.12.12.12.3.1" class="ltx_sup">∗</sup>, smoking<sup id="S3.T23.20.12.12.12.12.12.3.2" class="ltx_sup">∗</sup>, fitness<sup id="S3.T23.20.12.12.12.12.12.3.3" class="ltx_sup">∗</sup>,</span></span>
<span id="S3.T23.22.14.14.14.14.14" class="ltx_tr">
<span id="S3.T23.22.14.14.14.14.14.2" class="ltx_td ltx_nopad_r ltx_align_left">swimming pool<sup id="S3.T23.22.14.14.14.14.14.2.1" class="ltx_sup">∗</sup>, spa<sup id="S3.T23.22.14.14.14.14.14.2.2" class="ltx_sup">∗</sup></span></span>
</span></span><span id="S3.T23.22.14.14.16" class="ltx_text"></span></td>
<td id="S3.T23.23.15.15" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.23.15.15.2" class="ltx_text"></span><span id="S3.T23.23.15.15.1" class="ltx_text">
<span id="S3.T23.23.15.15.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.23.15.15.1.1.2" class="ltx_tr">
<span id="S3.T23.23.15.15.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">rating, nearby station,</span></span>
<span id="S3.T23.23.15.15.1.1.3" class="ltx_tr">
<span id="S3.T23.23.15.15.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">minutes walk from station,</span></span>
<span id="S3.T23.23.15.15.1.1.4" class="ltx_tr">
<span id="S3.T23.23.15.15.1.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">address, phone number,</span></span>
<span id="S3.T23.23.15.15.1.1.1" class="ltx_tr">
<span id="S3.T23.23.15.15.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">business hour, reference number<sup id="S3.T23.23.15.15.1.1.1.1.1" class="ltx_sup">‡</sup></span></span>
</span></span><span id="S3.T23.23.15.15.3" class="ltx_text"></span></td>
</tr>
<tr id="S3.T23.36.28" class="ltx_tr">
<td id="S3.T23.36.28.14" class="ltx_td ltx_align_left ltx_border_t">Restaurant</td>
<td id="S3.T23.35.27.12" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.35.27.12.13" class="ltx_text"></span><span id="S3.T23.35.27.12.12" class="ltx_text">
<span id="S3.T23.35.27.12.12.12" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.26.18.3.3.3.3" class="ltx_tr">
<span id="S3.T23.26.18.3.3.3.3.3" class="ltx_td ltx_nopad_r ltx_align_left">name, type<sup id="S3.T23.26.18.3.3.3.3.3.1" class="ltx_sup">⋆</sup>, area<sup id="S3.T23.26.18.3.3.3.3.3.2" class="ltx_sup">⋆</sup>, price range<sup id="S3.T23.26.18.3.3.3.3.3.3" class="ltx_sup">⋆</sup>,</span></span>
<span id="S3.T23.29.21.6.6.6.6" class="ltx_tr">
<span id="S3.T23.29.21.6.6.6.6.3" class="ltx_td ltx_nopad_r ltx_align_left">book day<sup id="S3.T23.29.21.6.6.6.6.3.1" class="ltx_sup">†</sup>, book time<sup id="S3.T23.29.21.6.6.6.6.3.2" class="ltx_sup">†</sup>, book people<sup id="S3.T23.29.21.6.6.6.6.3.3" class="ltx_sup">†</sup>,</span></span>
<span id="S3.T23.32.24.9.9.9.9" class="ltx_tr">
<span id="S3.T23.32.24.9.9.9.9.3" class="ltx_td ltx_nopad_r ltx_align_left">alcohol<sup id="S3.T23.32.24.9.9.9.9.3.1" class="ltx_sup">∗</sup>, walkability<sup id="S3.T23.32.24.9.9.9.9.3.2" class="ltx_sup">∗</sup>, parking<sup id="S3.T23.32.24.9.9.9.9.3.3" class="ltx_sup">∗</sup>,</span></span>
<span id="S3.T23.35.27.12.12.12.12" class="ltx_tr">
<span id="S3.T23.35.27.12.12.12.12.3" class="ltx_td ltx_nopad_r ltx_align_left">internet<sup id="S3.T23.35.27.12.12.12.12.3.1" class="ltx_sup">∗</sup>, smoking<sup id="S3.T23.35.27.12.12.12.12.3.2" class="ltx_sup">∗</sup>, outdoor table<sup id="S3.T23.35.27.12.12.12.12.3.3" class="ltx_sup">∗</sup></span></span>
</span></span><span id="S3.T23.35.27.12.14" class="ltx_text"></span></td>
<td id="S3.T23.36.28.13" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.36.28.13.2" class="ltx_text"></span><span id="S3.T23.36.28.13.1" class="ltx_text">
<span id="S3.T23.36.28.13.1.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.36.28.13.1.1.2" class="ltx_tr">
<span id="S3.T23.36.28.13.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">rating, nearby station,</span></span>
<span id="S3.T23.36.28.13.1.1.3" class="ltx_tr">
<span id="S3.T23.36.28.13.1.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">minutes walk from station,</span></span>
<span id="S3.T23.36.28.13.1.1.4" class="ltx_tr">
<span id="S3.T23.36.28.13.1.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">address, phone number,</span></span>
<span id="S3.T23.36.28.13.1.1.5" class="ltx_tr">
<span id="S3.T23.36.28.13.1.1.5.1" class="ltx_td ltx_nopad_r ltx_align_left">business hour, last order time,</span></span>
<span id="S3.T23.36.28.13.1.1.1" class="ltx_tr">
<span id="S3.T23.36.28.13.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">representative menu, reference number<sup id="S3.T23.36.28.13.1.1.1.1.1" class="ltx_sup">‡</sup></span></span>
</span></span><span id="S3.T23.36.28.13.3" class="ltx_text"></span></td>
</tr>
<tr id="S3.T23.44.36" class="ltx_tr">
<td id="S3.T23.44.36.9" class="ltx_td ltx_align_left ltx_border_t">Attraction</td>
<td id="S3.T23.44.36.8" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.44.36.8.9" class="ltx_text"></span><span id="S3.T23.44.36.8.8" class="ltx_text">
<span id="S3.T23.44.36.8.8.8" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.38.30.2.2.2.2" class="ltx_tr">
<span id="S3.T23.38.30.2.2.2.2.2" class="ltx_td ltx_nopad_r ltx_align_left">name, type<sup id="S3.T23.38.30.2.2.2.2.2.1" class="ltx_sup">⋆</sup>, area<sup id="S3.T23.38.30.2.2.2.2.2.2" class="ltx_sup">⋆</sup>,</span></span>
<span id="S3.T23.41.33.5.5.5.5" class="ltx_tr">
<span id="S3.T23.41.33.5.5.5.5.3" class="ltx_td ltx_nopad_r ltx_align_left">walkability<sup id="S3.T23.41.33.5.5.5.5.3.1" class="ltx_sup">∗</sup>, parking<sup id="S3.T23.41.33.5.5.5.5.3.2" class="ltx_sup">∗</sup>, heritage<sup id="S3.T23.41.33.5.5.5.5.3.3" class="ltx_sup">∗</sup>,</span></span>
<span id="S3.T23.44.36.8.8.8.8" class="ltx_tr">
<span id="S3.T23.44.36.8.8.8.8.3" class="ltx_td ltx_nopad_r ltx_align_left">educational<sup id="S3.T23.44.36.8.8.8.8.3.1" class="ltx_sup">∗</sup>, scenic<sup id="S3.T23.44.36.8.8.8.8.3.2" class="ltx_sup">∗</sup>, cultural<sup id="S3.T23.44.36.8.8.8.8.3.3" class="ltx_sup">∗</sup></span></span>
</span></span><span id="S3.T23.44.36.8.10" class="ltx_text"></span></td>
<td id="S3.T23.44.36.10" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.44.36.10.1" class="ltx_text"></span><span id="S3.T23.44.36.10.2" class="ltx_text">
<span id="S3.T23.44.36.10.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.44.36.10.2.1.1" class="ltx_tr">
<span id="S3.T23.44.36.10.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">rating, nearby station,</span></span>
<span id="S3.T23.44.36.10.2.1.2" class="ltx_tr">
<span id="S3.T23.44.36.10.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">minutes walk from station,</span></span>
<span id="S3.T23.44.36.10.2.1.3" class="ltx_tr">
<span id="S3.T23.44.36.10.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">address, phone number,</span></span>
<span id="S3.T23.44.36.10.2.1.4" class="ltx_tr">
<span id="S3.T23.44.36.10.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_left">business hour, entrance fee</span></span>
</span></span><span id="S3.T23.44.36.10.3" class="ltx_text"></span></td>
</tr>
<tr id="S3.T23.47.39" class="ltx_tr">
<td id="S3.T23.47.39.4" class="ltx_td ltx_align_left ltx_border_t">Taxi</td>
<td id="S3.T23.47.39.3" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.47.39.3.4" class="ltx_text"></span><span id="S3.T23.47.39.3.3" class="ltx_text">
<span id="S3.T23.47.39.3.3.3" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.46.38.2.2.2.2" class="ltx_tr">
<span id="S3.T23.46.38.2.2.2.2.2" class="ltx_td ltx_nopad_r ltx_align_left">leave at<sup id="S3.T23.46.38.2.2.2.2.2.1" class="ltx_sup">⋆</sup>, departure<sup id="S3.T23.46.38.2.2.2.2.2.2" class="ltx_sup">⋆</sup>,</span></span>
<span id="S3.T23.47.39.3.3.3.3" class="ltx_tr">
<span id="S3.T23.47.39.3.3.3.3.1" class="ltx_td ltx_nopad_r ltx_align_left">arrive by, destination<sup id="S3.T23.47.39.3.3.3.3.1.1" class="ltx_sup">⋆</sup>, type</span></span>
</span></span><span id="S3.T23.47.39.3.5" class="ltx_text"></span></td>
<td id="S3.T23.47.39.5" class="ltx_td ltx_align_left ltx_border_t">
<span id="S3.T23.47.39.5.1" class="ltx_text"></span><span id="S3.T23.47.39.5.2" class="ltx_text">
<span id="S3.T23.47.39.5.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.47.39.5.2.1.1" class="ltx_tr">
<span id="S3.T23.47.39.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">phone number, cost, duration</span></span>
</span></span><span id="S3.T23.47.39.5.3" class="ltx_text"></span></td>
</tr>
<tr id="S3.T23.49.41" class="ltx_tr">
<td id="S3.T23.49.41.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">Metro</td>
<td id="S3.T23.49.41.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S3.T23.49.41.2.3" class="ltx_text"></span><span id="S3.T23.49.41.2.2" class="ltx_text">
<span id="S3.T23.49.41.2.2.2" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.49.41.2.2.2.2" class="ltx_tr">
<span id="S3.T23.49.41.2.2.2.2.2" class="ltx_td ltx_nopad_r ltx_align_left">leave at, departure<sup id="S3.T23.49.41.2.2.2.2.2.1" class="ltx_sup">⋆</sup>, destination<sup id="S3.T23.49.41.2.2.2.2.2.2" class="ltx_sup">⋆</sup></span></span>
</span></span><span id="S3.T23.49.41.2.4" class="ltx_text"></span></td>
<td id="S3.T23.49.41.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">
<span id="S3.T23.49.41.4.1" class="ltx_text"></span><span id="S3.T23.49.41.4.2" class="ltx_text">
<span id="S3.T23.49.41.4.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T23.49.41.4.2.1.1" class="ltx_tr">
<span id="S3.T23.49.41.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">departure line, destination line,</span></span>
<span id="S3.T23.49.41.4.2.1.2" class="ltx_tr">
<span id="S3.T23.49.41.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">arrive by, cost, duration,</span></span>
<span id="S3.T23.49.41.4.2.1.3" class="ltx_tr">
<span id="S3.T23.49.41.4.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">transfer, optimal path</span></span>
</span></span><span id="S3.T23.49.41.4.3" class="ltx_text"></span></td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS8.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">1. Defining Task Schema</h5>

<div id="S3.SS8.SSS1.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.Px2.p1.1">먼저 태스크 중심의 대화 시나리오를 표현하는 태스크 스키마를 정의한다. 우리의 태스크 스키마는 표 <a class="ltx_ref" href="#S3.T23" title="Table 23 ‣ Overview ‣ 3.8.1 Dataset Construction ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">23</span></a>와 같이 5개의 도메인(호텔, 레스토랑, 어트랙션, 택시, 메트로)에 걸친 슬롯으로 구성된다. 일반적으로 슬롯은 정보 제공 가능한 슬롯과 요청 가능한 슬롯으로 분류된다. 정보 제공 슬롯은 "가격 범위", "영역", "예약 날짜"와 같은 사용자 목표 <span class="ltx_note ltx_role_footnote" id="footnote48"><sup class="ltx_note_mark">48</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">48</sup><span class="ltx_tag ltx_tag_note">48</span>A user goal is what the worker playing user should follow as shown in Table <a class="ltx_ref" href="#S3.T24" title="Table 24 ‣ 1. Defining Task Schema ‣ 3.8.1 Dataset Construction ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">24</span></a>.</span></span></span>을 제한할 수 있는 속성을 포함합니다. 요청가능한 슬롯들은 사용자가 요청할 수 있는 추가 정보를 제공하지만, 반드시 사용자 목표 제약으로서 특정될 필요는 없다. 요청가능한 슬롯의 전형적인 예는 "전화 번호"이며, 이는 사용자가 요청할 수 있지만, 목표 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib50" title="">50</a>, <a class="ltx_ref" href="#bib.bib51" title="">51</a>]</cite>의 가능한 후보들을 좁히기 위해 작동하지 않을 것이다.</p>
</div>
<div id="S3.SS8.SSS1.Px2.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.Px2.p2.1">이 스키마를 기반으로 조작하기 쉬운 주석 시스템과 따르기 쉬운 지침을 제공하기 위해 정보 제공 및 요청 가능한 슬롯에 추가 속성을 포함한다. 슬롯은 1) 부울 타입인지 여부, 2) 필수인지 여부(<span class="ltx_text ltx_font_italic" id="S3.SS8.SSS1.Px2.p2.1.1">Required</span>), 3) 예약과 관련된 속성(<span class="ltx_text ltx_font_italic" id="S3.SS8.SSS1.Px2.p2.1.2">Booking-related</span>), 4) 예약 후에만 사용 가능한 속성이 확인됩니다(<span class="ltx_text ltx_font_italic" id="S3.SS8.SSS1.Px2.p2.1.3">Requestable after booking</span>. 예를 들어 참조 번호). 부울 유형 슬롯은 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS1.Px2.p2.1.4">yes</span> 또는 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS1.Px2.p2.1.5">no</span>과 같은 값을 가질 수 있습니다. 이러한 부울 유형 값은 대화 컨텍스트에 명시적으로 나타나지 않습니다. 즉, 추상적인 속성을 가지고 있다. 추상적 속성을 이해하는 모델이 바람직하기 때문에 우리는 MultiWOZ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite>보다 훨씬 더 많은 부울 타입 슬롯을 가지고 있다; WoS는 도메인에 걸쳐 20개의 부울 슬롯을 가지는 반면 MultiWOZ는 2개만을 포함한다. 한편, 사용자 의도를 작성하기 위해서는 필요한 슬롯을 값으로 지정해야 한다. 이를 통해 에이전트가 필요한 값 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib114" title="">114</a>]</cite>를 지정하지 않고 다음 단계를 수행할 수 없는 실제 서비스 시나리오를 시뮬레이션할 수 있습니다.</p>
</div>
<figure id="S3.T24" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 24:</span> goal instruction의 예시. MultiWOZ와 달리 CoCo<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib77" title="">77</a>]</cite>에서와 같이 순서 편향을 방지하기 위해 처음부터 모든 명령어를 제시한다. 예약 관련 슬롯인 “식당-책 시간(22:41)” 및 “식당-책 요일(수요일)”은 KB 엔티티의 확인 전에 나타난다.</figcaption>
<table id="S3.T24.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T24.1.1" class="ltx_tr">
<td id="S3.T24.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T24.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T24.1.1.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T24.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Korean</span></span>
</span>
</td>
<td id="S3.T24.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt">
<span id="S3.T24.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T24.1.1.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T24.1.1.2.1.1.1" class="ltx_text ltx_font_bold">English (Translated)</span></span>
</span>
</td>
</tr>
<tr id="S3.T24.1.2" class="ltx_tr">
<td id="S3.T24.1.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T24.1.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T24.1.2.1.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T24.1.2.1.1.1.1" class="ltx_text" style="font-size:90%;">당신은 오늘 <span id="S3.T24.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">22:41</span>에 <span id="S3.T24.1.2.1.1.1.1.2" class="ltx_text ltx_font_bold">서울 중앙</span>에서 식사할 계획을 가지고 있습니다.
아참 오늘은 <span id="S3.T24.1.2.1.1.1.1.3" class="ltx_text ltx_font_bold">수요일</span> 입니다.
그런 곳을 찾았다면 먼저 <span id="S3.T24.1.2.1.1.1.1.4" class="ltx_text ltx_font_bold">대표 메뉴</span>를 확인하세요.
그리고 나선 <span id="S3.T24.1.2.1.1.1.1.5" class="ltx_text ltx_font_bold">1</span>명으로 예약 거세요.
예약 이후엔 <span id="S3.T24.1.2.1.1.1.1.6" class="ltx_text ltx_font_bold">영업 시간</span>을 문의하시구요.
그리고 나선 <span id="S3.T24.1.2.1.1.1.1.7" class="ltx_text ltx_font_bold">식당 근처</span>에서 잘 곳을 찾아야 합니다.
그 곳은 반드시 <span id="S3.T24.1.2.1.1.1.1.8" class="ltx_text ltx_font_bold">흡연이 불가</span>해야 합니다.
찾았다면 <span id="S3.T24.1.2.1.1.1.1.9" class="ltx_text ltx_font_bold">같은 요일</span>에 예약하세요.
<span id="S3.T24.1.2.1.1.1.1.10" class="ltx_text ltx_font_bold">같은 인원</span>으로 <span id="S3.T24.1.2.1.1.1.1.11" class="ltx_text ltx_font_bold">4</span>일간 머물러야 합니다.
예약에 성공했다면 <span id="S3.T24.1.2.1.1.1.1.12" class="ltx_text ltx_font_bold">예약 번호</span>를 묻고, <span id="S3.T24.1.2.1.1.1.1.13" class="ltx_text ltx_font_bold">흡연 가능 유무</span>를 더블 체크하세요.
그런 다음 마지막으로 택시를 하나 부르세요.
<span id="S3.T24.1.2.1.1.1.1.14" class="ltx_text ltx_font_bold">식당</span>에서 <span id="S3.T24.1.2.1.1.1.1.15" class="ltx_text ltx_font_bold">숙소</span>로 향해야 합니다.
찾았다면 <span id="S3.T24.1.2.1.1.1.1.16" class="ltx_text ltx_font_bold">소요 시간</span>을 문의하세요.</span></span>
</span>
</td>
<td id="S3.T24.1.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t">
<span id="S3.T24.1.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T24.1.2.2.1.1" class="ltx_p" style="width:173.4pt;"><span id="S3.T24.1.2.2.1.1.1" class="ltx_text" style="font-size:90%;">You have a plan to eat in the <span id="S3.T24.1.2.2.1.1.1.1" class="ltx_text ltx_font_bold">center of Seoul</span> at <span id="S3.T24.1.2.2.1.1.1.2" class="ltx_text ltx_font_bold">22:41</span> today.
Oh, today is <span id="S3.T24.1.2.2.1.1.1.3" class="ltx_text ltx_font_bold">Wednesday</span>.
If you find such a place, first check the <span id="S3.T24.1.2.2.1.1.1.4" class="ltx_text ltx_font_bold">representative menu</span>.
Then, make a booking for <span id="S3.T24.1.2.2.1.1.1.5" class="ltx_text ltx_font_bold">1</span> person.
After booking, inquire about the <span id="S3.T24.1.2.2.1.1.1.6" class="ltx_text ltx_font_bold">business hour</span>.
Then, you have to find a hotel to sleep in <span id="S3.T24.1.2.2.1.1.1.7" class="ltx_text ltx_font_bold">near the restaurant</span>.
The restaurant must be <span id="S3.T24.1.2.2.1.1.1.8" class="ltx_text ltx_font_bold">non-smoking</span>.
If you find it, book on the <span id="S3.T24.1.2.2.1.1.1.9" class="ltx_text ltx_font_bold">same day</span>.
You must stay for <span id="S3.T24.1.2.2.1.1.1.10" class="ltx_text ltx_font_bold">4</span> days as the <span id="S3.T24.1.2.2.1.1.1.11" class="ltx_text ltx_font_bold">same number of people</span>.
If the booking is done, ask for the <span id="S3.T24.1.2.2.1.1.1.12" class="ltx_text ltx_font_bold">reference number</span> and double-check the <span id="S3.T24.1.2.2.1.1.1.13" class="ltx_text ltx_font_bold">smoking allowed</span>.
Then, finally, call a taxi.
You have to go to the <span id="S3.T24.1.2.2.1.1.1.14" class="ltx_text ltx_font_bold">hotel</span> from the <span id="S3.T24.1.2.2.1.1.1.15" class="ltx_text ltx_font_bold">restaurant</span>.
If you call the taxi, inquire about the <span id="S3.T24.1.2.2.1.1.1.16" class="ltx_text ltx_font_bold">duration</span>.</span></span>
</span>
</td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS8.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">2. Creating Knowledge Base</h5>

<div id="S3.SS8.SSS1.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.Px3.p1.1">사용자 목표의 미리 정의된 실현 후보 집합을 얻기 위해 각 도메인의 태스크 스키마를 기반으로 지식베이스(Knowledge Base, KB)를 구성한다. 호텔 및 레스토랑 도메인의 경우 수동으로 가상 인스턴스를 만드는 반면, 어트랙션 및 메트로 도메인의 경우 웹에서 수집한 실명(예: 강남역 또는 남산타워)을 활용한다. 반면, 택시 도메인의 경우 인스턴스를 미리 정의하지 않고 MultiWOZ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite>와 같이 대화 수집 중에 인스턴스를 동적으로 생성한다. 윤리적 고려 사항을 염두에 두고, 모든 개인 식별 정보(PII, 예를 들어, 전화 번호, 주소)는 <span class="ltx_text ltx_font_typewriter" id="S3.SS8.SSS1.Px3.p1.1.1">faker</span>을 사용하여 무작위로 생성된 인스턴스로 대체된다. <span class="ltx_note ltx_role_footnote" id="footnote49"><sup class="ltx_note_mark">49</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">49</sup><span class="ltx_tag ltx_tag_note">49</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://faker.readthedocs.io" target="_blank" title="">https://faker.readthedocs.io</a></span></span></span> Table <a class="ltx_ref" href="#S3.T25" title="Table 25 ‣ 2. Creating Knowledge Base ‣ 3.8.1 Dataset Construction ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">25</span></a>는 각 도메인에 대한 KB 통계를 나타낸다.</p>
</div>
<figure id="S3.T25" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 25:</span>Statistics of Knowledge Base in WoS.</figcaption>
<table id="S3.T25.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T25.1.1" class="ltx_tr">
<td id="S3.T25.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T25.1.1.1.1" class="ltx_text ltx_font_bold">Domain</span></td>
<td id="S3.T25.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T25.1.1.2.1" class="ltx_text ltx_font_bold"># Instances</span></td>
<td id="S3.T25.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T25.1.1.3.1" class="ltx_text ltx_font_bold"># Slots</span></td>
</tr>
<tr id="S3.T25.1.2" class="ltx_tr">
<td id="S3.T25.1.2.1" class="ltx_td ltx_align_left ltx_border_t">Hotel</td>
<td id="S3.T25.1.2.2" class="ltx_td ltx_align_center ltx_border_t">101</td>
<td id="S3.T25.1.2.3" class="ltx_td ltx_align_center ltx_border_t">19</td>
</tr>
<tr id="S3.T25.1.3" class="ltx_tr">
<td id="S3.T25.1.3.1" class="ltx_td ltx_align_left">Restaurant</td>
<td id="S3.T25.1.3.2" class="ltx_td ltx_align_center">56</td>
<td id="S3.T25.1.3.3" class="ltx_td ltx_align_center">20</td>
</tr>
<tr id="S3.T25.1.4" class="ltx_tr">
<td id="S3.T25.1.4.1" class="ltx_td ltx_align_left">Attraction</td>
<td id="S3.T25.1.4.2" class="ltx_td ltx_align_center">100</td>
<td id="S3.T25.1.4.3" class="ltx_td ltx_align_center">17</td>
</tr>
<tr id="S3.T25.1.5" class="ltx_tr">
<td id="S3.T25.1.5.1" class="ltx_td ltx_align_left">Taxi</td>
<td id="S3.T25.1.5.2" class="ltx_td ltx_align_center">-</td>
<td id="S3.T25.1.5.3" class="ltx_td ltx_align_center">8</td>
</tr>
<tr id="S3.T25.1.6" class="ltx_tr">
<td id="S3.T25.1.6.1" class="ltx_td ltx_align_left ltx_border_bb">Metro</td>
<td id="S3.T25.1.6.2" class="ltx_td ltx_align_center ltx_border_bb">3,306</td>
<td id="S3.T25.1.6.3" class="ltx_td ltx_align_center ltx_border_bb">10</td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS8.SSS1.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">3. Designing the Annotation System</h5>

<div id="S3.SS8.SSS1.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.Px4.p1.1">이 섹션에서는 사용자 측면과 시스템 측면에서 데이터를 수집하는 데 사용한 주석 플랫폼에 대해 설명한다.</p>
</div>
</section>
<section id="S3.SS8.SSS1.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">3.1. User Side</h5>

<div id="S3.SS8.SSS1.Px5.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.Px5.p1.1">사용자 측면 역할에 대한 목표 지침을 제공합니다. 명령어는 자연어로 된 해당 슬롯 값을 가진 사용자의 특정 목표에 대한 설명을 포함한다. 그것은 또한 다양한 대화들을 위한 페르소나를 포함하는 사용자의 컨텍스트를 포함한다. 사용자는 지시에 따라 발화를 생성하도록 요청받는다. 예를 표<a class="ltx_ref" href="#S3.T24" title="Table 24 ‣ 1. Defining Task Schema ‣ 3.8.1 Dataset Construction ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">24</span></a>에 나타낸다.</p>
</div>
<div id="S3.SS8.SSS1.Px5.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.Px5.p2.1">슬롯이 여러 도메인에 걸쳐 공유되는 다중 도메인 대화 시나리오를 고안하기 위해, 명령어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>, <a class="ltx_ref" href="#bib.bib154" title="">154</a>]</cite>에서 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS1.Px5.p2.1.1">domain transition</span>을 포함한다. 예를 들어, 호텔을 예약하려는 사용자의 경우, 사용자는 그곳에 가기 위해 교통수단(택시, 지하철 등)에 대한 정보를 찾을 수 있다. 이 대화에서 초기 도메인은 다른 도메인(택시/메트로 호텔)으로 변경됩니다. 대화 상태 추적 측면에서 단일 도메인에 비해 더 어렵다. 왜냐하면 사용자는 이전 도메인의 다른 값을 상호 참조함으로써 값을 추론해야 하는 목표를 암묵적으로 표현할 수 있기 때문이다.</p>
</div>
<div id="S3.SS8.SSS1.Px5.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.Px5.p3.1">목표 지침은 목표 제한 슬롯 및 그 값에 대한 자리 표시자를 포함하는 템플릿에 의해 실현된다. 우리는 대화의 다양한 시나리오를 다루기 위해 각 도메인에 대한 다양한 템플릿을 설계한다. 멀티WOZ와 마찬가지로, 목표 템플릿들은 대응하는 슬롯들을 갖는 일련의 서브 목표들을 포함한다. 대화 중 어휘 수반 또는 공동 참조를 촉진하기 위해 문장을 신중하게 설계하며, 이는 사용자 컨텍스트 또는 도메인 전환 중에 자연스럽게 관찰될 수 있다. 템플릿을 채워 명령을 완료할 때 도메인별 작업 스키마를 기반으로 하는 KB의 인스턴스를 지정된 자리 표시자에 무작위로 할당합니다. 명령어의 값은 대화 중에 사용자에 의해 구체적으로 언급되어야 한다. 추적 가능한 각 슬롯에는 유효한 값인 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS1.Px5.p3.1.1">None</span> 또는 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS1.Px5.p3.1.2">Dontcare</span>이 있습니다. <span class="ltx_note ltx_role_footnote" id="footnote50"><sup class="ltx_note_mark">50</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">50</sup><span class="ltx_tag ltx_tag_note">50</span><span class="ltx_text ltx_font_italic" id="footnote50.1">Dontcare</span> means a user has no preference and <span class="ltx_text ltx_font_italic" id="footnote50.2">None</span> means a user is yet to specify a valid value for given slot <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib50" title="">50</a>, <a class="ltx_ref" href="#bib.bib51" title="">51</a>]</cite>.</span></span></span></p>
</div>
<div id="S3.SS8.SSS1.Px5.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.Px5.p4.1">모델의 일반화 능력을 적절하게 평가하기 위해, 우리는 반사실적 목표를 더 추가하고 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib77" title="">77</a>]</cite> 프로세스 동안 보이지 않는 KB 인스턴스를 도입한다. 현재 슬롯 분포를 기반으로 새로운 목표 지시를 추가하기 위해, 우리는 구축 동안 슬롯에 대한 슬롯 값 빈도와 동시 발생을 계속 모니터링한다. 특히, 빈발한 슬롯 값 또는 슬롯 간의 거의 동시 발생하지 않는 조합을 포함하는 새로운 목표 명령어를 추가한다. 예를 들어, “(hotel-parking, no)”가 as-is 분포에서 빈발한 쌍일 때, 이를 제약조건으로 포함하는 목표 명령어를 설계하여 대화창에 나타나도록 촉진한다. 또한, 테스트 시간에서 보이지 않는 슬롯 값에 대한 현실적인 시나리오를 시뮬레이션하기 위해 데이터 세트의 특정 서브세트(트레이 및 디브/테스트 세트) 간에 KB 인스턴스를 구별한다.</p>
</div>
<figure id="S3.F7" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2105.09680/assets/figs/wos_gui.png" id="S3.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="347" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">도 7:</span>Graphical web interface for system side worker.</figcaption>
</figure>
</section>
<section id="S3.SS8.SSS1.Px6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">3.2. System Side</h5>

<div id="S3.SS8.SSS1.Px6.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.Px6.p1.1">시스템측 작업자(마법사)의 역할은 1) 사용자 발화의 대화 상태에 주석을 달고 2) 필요한 경우 모든 턴마다 KB에 액세스하여 응답을 생성하는 것이다. 먼저, 마법사는 현재 대화 컨텍스트로부터 추론된 적절한 슬롯 값을 채우도록 요청받는다. 사용자에 의해 발화된 단어가 특정 슬롯 값에 직접 매핑되도록 명확하지 않은 경우, 마법사는 단어의 의미를 먼저 명확히 한 다음 단어가 값과 동일한 의미를 가질 때 슬롯을 채워야 한다. 대화 상태의 주석은 필요한 정보를 제공하는 데 완전히 집중하기 위해 사용자 요청을 이해하는 명시적 액션이다. 그런 다음 마법사는 요청하거나 정보를 전달하기 위한 응답을 생성합니다. 필요한 슬롯의 값이 없는 경우 시스템 측 작업자는 사용자에게 결측값을 요청할 수 있습니다. 그렇지 않으면, 시스템은 사용자에게 적절한 정보를 제공한다. 필요한 경우 시스템이 외부 지식 베이스를 쿼리할 수 있습니다. 검색 결과가 3개 이상인 경우 시스템 작업자는 더 많은 세부 정보를 요청하거나 그 중 하나를 추천할 수 있다.</p>
</div>
<div id="S3.SS8.SSS1.Px6.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.Px6.p2.1">마법사가 이러한 복잡한 작업을 효과적이고 효율적으로 수행할 수 있도록 지원하기 위해, 우리는 드롭다운 컴포넌트(그림<a class="ltx_ref" href="#S3.F7" title="Figure 7 ‣ 3.1. User Side ‣ 3.8.1 Dataset Construction ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">7</span></a>)를 새롭게 도입한 기능을 가진 그래픽 웹 인터페이스를 제공한다. 드롭다운 인터페이스를 사용하면 시스템 측 작업자가 미리 채워진 후보 목록에서 값을 선택할 수 있습니다. 작업자에게 너무 많은 옵션이 제시되면 드롭다운이 무의미해질 수 있기 때문에 목표 지시와 영역별 지식 기반을 기반으로 가장 가능성 있는 가치 후보를 제시한다. 이 절차는 [span class="ltx_text ltx_font_italic" id="S3.SS8.SSS1.Px6.p2.1.1">multi-annotations</span>, <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS1.Px6.p2.1.2">mis-annotations</span>, <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS1.Px6.p2.1.3">typos</span>, <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS1.Px6.p2.1.4">value canonicalization</span> reported in MutiWOZ 2.1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib37" title="">37</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS8.SSS1.Px7" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">4. Dataset Construction</h5>

<div id="S3.SS8.SSS1.Px7.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.Px7.p1.1">작업마스터-1 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib11" title="">11</a>]</cite>에서 영감을 받은 'Self-dialog' 기법을 적용하여 비용과 시간을 줄이면서 다양한 대화 데이터셋을 효율적으로 수집한다. 셀프 다이얼로그는 다양한 대화 데이터를 수집하는 데 효과적이다. 두 역할을 모두 가짐으로써, 작업자는 사용자 발화에서의 슬롯 발생 순서, 시스템 응답의 추천 등 대화의 흐름을 자유롭게 제어한다. 이것은 또한 근로자들이 다른 페르소나가 포함되도록 자연스럽게 그들만의 스타일을 말하도록 이끈다. 그러나 파일롯 단계에서 annotation 오류가 발견되었는데, 이는 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS1.Px7.p1.1.1">early-markup</span> (system pre-fills the values before receiving the values before the user)와 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS1.Px7.p1.1.2">delayed-markup</span> (the system fills the values behindhand the proper turn) 오류이다. 또한 오류정정 인터페이스를 제공하여 사용자와 시스템 역할간의 명시적 턴스위칭을 활용함으로써 이 기법을 개선한다.</p>
</div>
<div id="S3.SS8.SSS1.Px7.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.Px7.p2.1">자세히 설명하자면, 우리는 주요 수집 프로세스에 참여할 신뢰할 수 있는 근로자를 훈련하고 선택한다. 주요 단계 이전에는 앞서 언급한 초기 마크업 및 지연 마크업 오류를 피하고 일부 잘못된 의사소통을 포함한 보다 현실적인 대화를 생성하기 위해 크라우드 워커를 대상으로 여러 파일럿 연구를 수행했다. 또한 사용자/시스템 역할에 몰입하기 위해 두 역할 사이의 명시적인 전환 기능을 구현함으로써 잘못된 의사소통을 과도하게 줄였다. 파일럿을 통해 이러한 문제를 효과적으로 처리할 수 있는 15명의 선택된 근로자를 최종적으로 고용합니다.</p>
</div>
</section>
<section id="S3.SS8.SSS1.Px8" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Final Dataset</h5>

<div id="S3.SS8.SSS1.Px8.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS1.Px8.p1.1">표 <a class="ltx_ref" href="#S3.T26" title="Table 26 ‣ Final Dataset ‣ 3.8.1 Dataset Construction ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">26</span></a>는 데이터 세트의 통계를 보여준다. WoS는 5개의 도메인에서 146,692개의 턴으로 전체 10,000개의 다이얼로그를 포함한다. 평가(dev/test) 세트는 특히 반사실적 목표를 갖는 대화 및 열차 세트에 대해 보이지 않는 KB 인스턴스를 포함한다. dev/test 세트는 각각 294개 및 361개의 반사실적 목표 기반 대화 상자를 포함한다. 모든 분할에는 도메인 전환이 있는 대화 상자 수가 충분합니다.</p>
</div>
<figure id="S3.T26" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 26:</span>Statistics of Wizard-of-Seoul (WoS).</figcaption>
<table id="S3.T26.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T26.1.1" class="ltx_tr">
<td id="S3.T26.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T26.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T26.1.1.2.1" class="ltx_text ltx_font_bold">|Train|</span></td>
<td id="S3.T26.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T26.1.1.3.1" class="ltx_text ltx_font_bold">|Dev|</span></td>
<td id="S3.T26.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T26.1.1.4.1" class="ltx_text ltx_font_bold">|Test|</span></td>
<td id="S3.T26.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T26.1.1.5.1" class="ltx_text ltx_font_bold">Total</span></td>
</tr>
<tr id="S3.T26.1.2" class="ltx_tr">
<td id="S3.T26.1.2.1" class="ltx_td ltx_align_left ltx_border_t"># Dialogues</td>
<td id="S3.T26.1.2.2" class="ltx_td ltx_align_center ltx_border_t">8,000</td>
<td id="S3.T26.1.2.3" class="ltx_td ltx_align_center ltx_border_t">1,000</td>
<td id="S3.T26.1.2.4" class="ltx_td ltx_align_center ltx_border_t">1,000</td>
<td id="S3.T26.1.2.5" class="ltx_td ltx_align_center ltx_border_t">10,000</td>
</tr>
<tr id="S3.T26.1.3" class="ltx_tr">
<td id="S3.T26.1.3.1" class="ltx_td ltx_align_left"># Single Domain Dialogues</td>
<td id="S3.T26.1.3.2" class="ltx_td ltx_align_center">1,806</td>
<td id="S3.T26.1.3.3" class="ltx_td ltx_align_center">263</td>
<td id="S3.T26.1.3.4" class="ltx_td ltx_align_center">226</td>
<td id="S3.T26.1.3.5" class="ltx_td ltx_align_center">2,295</td>
</tr>
<tr id="S3.T26.1.4" class="ltx_tr">
<td id="S3.T26.1.4.1" class="ltx_td ltx_align_left"># Multi Domain Dialogues</td>
<td id="S3.T26.1.4.2" class="ltx_td ltx_align_center">6,194</td>
<td id="S3.T26.1.4.3" class="ltx_td ltx_align_center">737</td>
<td id="S3.T26.1.4.4" class="ltx_td ltx_align_center">774</td>
<td id="S3.T26.1.4.5" class="ltx_td ltx_align_center">7,705</td>
</tr>
<tr id="S3.T26.1.5" class="ltx_tr">
<td id="S3.T26.1.5.1" class="ltx_td ltx_align_left"># Counterfactual Dialogues</td>
<td id="S3.T26.1.5.2" class="ltx_td ltx_align_center">0</td>
<td id="S3.T26.1.5.3" class="ltx_td ltx_align_center">294</td>
<td id="S3.T26.1.5.4" class="ltx_td ltx_align_center">361</td>
<td id="S3.T26.1.5.5" class="ltx_td ltx_align_center">655</td>
</tr>
<tr id="S3.T26.1.6" class="ltx_tr">
<td id="S3.T26.1.6.1" class="ltx_td ltx_align_left ltx_border_t"># Total Turns</td>
<td id="S3.T26.1.6.2" class="ltx_td ltx_align_center ltx_border_t">117,584</td>
<td id="S3.T26.1.6.3" class="ltx_td ltx_align_center ltx_border_t">14,448</td>
<td id="S3.T26.1.6.4" class="ltx_td ltx_align_center ltx_border_t">14,660</td>
<td id="S3.T26.1.6.5" class="ltx_td ltx_align_center ltx_border_t">146,692</td>
</tr>
<tr id="S3.T26.1.7" class="ltx_tr">
<td id="S3.T26.1.7.1" class="ltx_td ltx_align_left"># Total Tokens</td>
<td id="S3.T26.1.7.2" class="ltx_td ltx_align_center">899,450</td>
<td id="S3.T26.1.7.3" class="ltx_td ltx_align_center">114,169</td>
<td id="S3.T26.1.7.4" class="ltx_td ltx_align_center">114,914</td>
<td id="S3.T26.1.7.5" class="ltx_td ltx_align_center">1,128,533</td>
</tr>
<tr id="S3.T26.1.8" class="ltx_tr">
<td id="S3.T26.1.8.1" class="ltx_td ltx_align_left ltx_border_t">Avg Turns per Dialogue</td>
<td id="S3.T26.1.8.2" class="ltx_td ltx_align_center ltx_border_t">14.70</td>
<td id="S3.T26.1.8.3" class="ltx_td ltx_align_center ltx_border_t">14.45</td>
<td id="S3.T26.1.8.4" class="ltx_td ltx_align_center ltx_border_t">14.66</td>
<td id="S3.T26.1.8.5" class="ltx_td ltx_align_center ltx_border_t">14.67</td>
</tr>
<tr id="S3.T26.1.9" class="ltx_tr">
<td id="S3.T26.1.9.1" class="ltx_td ltx_align_left ltx_border_bb">Avg Tokens per Turn</td>
<td id="S3.T26.1.9.2" class="ltx_td ltx_align_center ltx_border_bb">7.65</td>
<td id="S3.T26.1.9.3" class="ltx_td ltx_align_center ltx_border_bb">7.90</td>
<td id="S3.T26.1.9.4" class="ltx_td ltx_align_center ltx_border_bb">7.84</td>
<td id="S3.T26.1.9.5" class="ltx_td ltx_align_center ltx_border_bb">7.69</td>
</tr>
</tbody></table>
</figure>
</section>
</section>
<section id="S3.SS8.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.8.2 </span>Evaluation Metrics</h4>

<div id="S3.SS8.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS2.p1.1">WoS에 대한 평가 메트릭은 1) 공동 목표 정확도(JGA) 및 2) 슬롯 마이크로 F1 점수이다. JGA는 전체 대화 회전 횟수 중 슬롯-값 쌍과 그라운드 진리 대화 상태로 구성된 정확히 일치하는 대화 상태의 비율을 측정한다. 슬롯 마이크로 F1 점수는 각 턴에서 마이크로 F1 점수의 평균이다. 각 턴에 대해 마이크로 F1 점수는 예측된 슬롯-값 쌍 및 그라운드-진실 쌍 측면에서 정밀도 및 재현율의 조화 평균으로 정의된다. 슬롯 마이크로 F1 점수는 그라운드 트루스의 값이 "<span class="ltx_text ltx_font_typewriter" id="S3.SS8.SSS2.p1.1.1">None</span>일 때 무시된다는 점에 유의한다.</p>
</div>
</section>
<section id="S3.SS8.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.8.3 </span>Analysis</h4>

<div id="S3.SS8.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS3.p1.1"><cite class="ltx_cite ltx_citemacro_citet">Li et al. [<a class="ltx_ref" href="#bib.bib77" title="">77</a>]</cite>와 같이 반사실적 목표 및 보이지 않는 KB 인스턴스를 기반으로 열차 및 dev/test 세트를 분할할 때 표 <a class="ltx_ref" href="#S3.T27" title="Table 27 ‣ 3.8.3 Analysis ‣ 3.8 Dialogue State Tracking (DST) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">27</span></a>와 같이 성능 저하를 관찰한다. 이는 반사실적 목표가 WoS를 더 어렵게 만든다는 것을 보여준다.</p>
</div>
<figure id="S3.T27" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 27:</span>데이터 분할 전략에 관한 비교. 랜덤은 트레인, 디브 및 테스트 세트를 무작위로 분할하는 것이다. CF-goal은 보이지 않는 KB 인스턴스가 있는 dev 및 테스트 세트에 포함되어 있음을 나타냅니다.</figcaption>
<table id="S3.T27.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody><tr id="S3.T27.1.1" class="ltx_tr">
<td id="S3.T27.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T27.1.1.1.1" class="ltx_text ltx_font_bold">Domain Split</span></td>
<td id="S3.T27.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S3.T27.1.1.2.1" class="ltx_text ltx_font_bold">Joint Goal Accuracy</span></td>
</tr>
<tr id="S3.T27.1.2" class="ltx_tr">
<td id="S3.T27.1.2.1" class="ltx_td ltx_align_left ltx_border_t">Random</td>
<td id="S3.T27.1.2.2" class="ltx_td ltx_align_center ltx_border_t">57.53</td>
</tr>
<tr id="S3.T27.1.3" class="ltx_tr">
<td id="S3.T27.1.3.1" class="ltx_td ltx_align_left ltx_border_bb">CF-goal</td>
<td id="S3.T27.1.3.2" class="ltx_td ltx_align_center ltx_border_bb">47.38</td>
</tr>
</tbody></table>
</figure>
</section>
<section id="S3.SS8.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.8.4 </span>Related Work</h4>

<div id="S3.SS8.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS4.p1.1">Wizard-of-Oz (WOZ) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib59" title="">59</a>]</cite>는 대화 모음에서 인기 있는 스킴이다. 사실, 종래의 WOZ 설정은 두 사람의 역할극을 채용함으로써 다양한 유형의 대화를 수집할 수 있게 한다. 각 인간은 둘 중 역할을 선택해야 합니다. <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS4.p1.1.1">user</span> 및 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS4.p1.1.2">system</span>. 역할을 수행함에 있어서, 미리 제공된 배경 정보를 가진 발화의 차례차례 생성에 의해 대화들이 수집된다. 작업 지향 대화를 구축하는 경우, <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS4.p1.1.3">goal</span>은 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS4.p1.1.4">user</span>에 부여되는 반면, <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS4.p1.1.5">knowledge base</span>은 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS4.p1.1.6">system</span>에 액세스되도록 허용된다. <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS4.p1.1.7">system</span>은 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS4.p1.1.8">knowledge base</span>을 사용하여 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS4.p1.1.9">user</span>의 요청에 응답할 수 있습니다.</p>
</div>
<div id="S3.SS8.SSS4.p2" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS4.p2.1">많은 대화 데이터 세트는 WOZ 설정 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib135" title="">135</a>, <a class="ltx_ref" href="#bib.bib35" title="">35</a>, <a class="ltx_ref" href="#bib.bib36" title="">36</a>]</cite>를 밀접하게 따르지만, 두 크라우드 워커가 동시에 매칭되어야 하고 각각의 역할을 성공적으로 수행해야 하기 때문에 많은 시간과 비용이 소요되며, 이는 대화 세트를 대규모로 수집하는 것을 방해한다. 우리는 이 한계를 '근로자 공존 제약'이라고 부른다. 한계를 극복하기 위해 MultiWOZ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite>는 이 기존 WOZ를 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS4.p2.1.1">asynchronously</span> collect dialogues turn-by-turn from crowdworkers로 약간 변경하며, 이는 서로 다른 작업자가 동일한 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS4.p2.1.2">user</span> 또는 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS4.p2.1.3">system</span>을 단일 대화로 재생할 수 있게 한다. 이 접근법은 모든 작업자가 이전 컨텍스트 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib37" title="">37</a>]</cite>에 일관되지 않도록 이미 진행 된 대화에 적응 해야 하기 때문에 비용이 적게 들지만 오류가 발생하기 쉽다. 최근에 CrossWOZ와 RiSAWOZ는 높은 건설 비용에도 불구하고 주석 품질을 유지하기 위해 WOZ 설정에서 제안된 바와 같이 <span class="ltx_text ltx_font_italic" id="S3.SS8.SSS4.p2.1.4">synchronous</span> 방식으로 대화를 수집하기 위해 신뢰할 수 있는 작업자만 선택했다.</p>
</div>
<div id="S3.SS8.SSS4.p3" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS4.p3.1"><cite class="ltx_cite ltx_citemacro_citet">Byrne et al. [<a class="ltx_ref" href="#bib.bib11" title="">11</a>]</cite>는 또한 기존의 WOZ 설정이 시간이 많이 걸리고 복잡하며 비용이 많이 들고, 에이전트와 크라우드소싱된 작업자 모두를 훈련하고 관리하기 위한 행정 절차뿐만 아니라 상당한 기술적 구현이 요구되며, 이에 따라 대안으로 셀프 다이얼로그를 제안한다. 셀프 다이얼로그는 작업자들이 사용자와 시스템 역할을 모두 수행하는 전체 대화를 작성하는 수집 체계이다. 이들의 아이디어를 입증하기 위해, <cite class="ltx_cite ltx_citemacro_citet">Byrne et al. [<a class="ltx_ref" href="#bib.bib11" title="">11</a>]</cite>는 WOZ 스킴에 서 있는 Self-dialog를 기반으로 한 대규모 대화 데이터ase인 Taskmaster-1을 구축한다: 1) 사용자와 시스템 역할을 하는 두 사람(전통적인 WOZ 설정)과 두 역할을 모두 수행하는 한 사람(Self-dialog)이다. 결과적으로, Self-dialog는 비동기식 대화 수집으로 인한 일관성 없는 대화 생성을 피함으로써 '근로자 공존 제약' 비용을 효과적으로 개선할 수 있다. 그러나 실제 대화와 비교할 때 오답이 거의 발생하지 않는 경향이 있는데, 이는 동일한 사람이 두 역할에서 모두 발화를 하기 때문에 현실과 괴리가 발생할 수 있기 때문이다.</p>
</div>
<div id="S3.SS8.SSS4.p4" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS4.p4.1">일부 연구자들은 비용 효율성을 극대화하기 위해 이러한 대화를 만들기 위해 기계만 사용하려고 한다. 이는 정교하게 설계된 규칙과 주어진 태스크 스키마로부터 자동으로 회전하여 발화를 생성할 수 있는 시뮬레이터 위에 다이얼로그를 구축한다. 시뮬레이터는 먼저 psuedo-dialogue를 생성한 후 크라우드소싱을 적용하여 자연 발화 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib124" title="">124</a>, <a class="ltx_ref" href="#bib.bib114" title="">114</a>]</cite>로 패러프레이징한다. 그러나 인간의 노력이 훨씬 덜 필요하지만 시뮬레이터에 크게 의존한다.</p>
</div>
<div id="S3.SS8.SSS4.p5" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS4.p5.1">한편, 기존의 연구들은 DST 모델의 강건한 평가를 다루고 있다. CoCo <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib77" title="">77</a>]</cite>에 따르면 최첨단 DST 모델은 열차 데이터에 거의 나타나지 않기 때문에 현실적인 시나리오에 강하지 않다. CoCo(제어 가능한 반사실적)라는 이름에서 알 수 있듯이, 이것은 미리 정의된 슬롯-값 쌍들에 기초하여 드물지만 현실적인 대화들을 생성한다. 그들은 심지어 최첨단 DST 모델의 성능이 반사실적 목표를 포함한 그러한 대화에서 평가될 때 현저하게 떨어진다는 것을 보여준다. 이는 현재 TOD 벤치마크가 보이지 않지만 현실적인 시나리오에 대한 견고성 측면에서 개선되어야 함을 의미한다.</p>
</div>
<div id="S3.SS8.SSS4.p6" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS4.p6.1">한국어는 한국정보화진흥원(NIA)에서 제공하는 과제 중심 대화 데이터셋이 있으며, 민원 관련 10개 정도의 도메인을 포함하고 있으며 500k 이상의 대화로 구성되어 있다. 발화는 1) 사용자가 질문하는 주요 질문, 2) 시스템이 설명을 요청할 수 있는 하위 질문, 3) 사용자 답변, 4) 시스템 답변. 추가적으로, 사용자 의도들이 주석되고 엔티티들이 각각의 발화로부터 추출된다. 이 데이터 세트는 앞서 언급한 설정을 따르지 않으며 단일 회전 판단에 대해서만 슬롯-값 쌍으로 표시되는 대화 상태가 없음을 발견했다. 또한 태스크 스키마에 대한 정보가 부족하고 접근성의 원칙을 충족하지 못하는 재분배가 제한되어 DST 벤치마크를 새로 만들 수 있다.</p>
</div>
</section>
<section id="S3.SS8.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.8.5 </span>Conclusion</h4>

<div id="S3.SS8.SSS5.p1" class="ltx_para">
<p class="ltx_p" id="S3.SS8.SSS5.p1.1">서울 관광객과 여행사 간의 대화를 시뮬레이션한 최초의 대규모 한국어 멀티 도메인 태스크 중심 대화 데이터셋인 위저드 오브 서울(Wizard-of-Seoul, WoS)을 소개한다. 대화 수집 기법의 효율적인 스케일 업을 위해 Self-dialog를 적용한다. 또한, 어노테이션 인터페이스(드롭다운 메뉴 및 턴-스위칭)에 대한 고려는 잘못된 경우를 완화하고, 반사실적인 것을 포함한 다양한 목표 지시가 각 대화가 더 자연스럽고 도전적이도록 촉진한다. 우리는 WoS가 한국어로 다양한 미래 대화 연구를 촉발하고 종단 간 대화 모델링을 추진하는 데 귀중한 통찰력을 제공하기를 바란다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Pretrained Language Models</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p" id="S4.p1.1">KLUE를 사용하여 추가 연구를 용이하게 하기 위해 우리는 KLUE 내의 모든 벤치마크 작업에 대한 강력한 기준선을 제공한다. 이러한 노력의 일환으로 한국어를 위한 대규모 언어 모델을 사전 훈련하고 출시하는데, 이는 개별 연구자들로부터 대규모 언어 모델을 재훈련하는 부담을 줄여줄 수 있기를 바란다. 보다 구체적으로, BERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite> 및 RoBERTa <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>를 포함하는 언어 모델(PLM)을 처음부터 사전 학습한다.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Language Models</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.p1.1">우리는 다양한 훈련 구성을 유지하면서 여러 한국어 모델을 사전 훈련한다. 이를 통해 한국어 모델을 사전 훈련하기 위한 효과적인 설정을 탐색하고 KLUE에 대한 간단하면서도 효과적인 기준 모델을 추가로 설정할 수 있다. 우리는 KLUE-BERT와 KLUE-RoBERTa를 훈련한다. 사전 훈련 말뭉치, 전처리 절차, 토큰화 전략 및 기타 훈련 구성의 선택을 변경한다.</p>
</div>
<figure id="S4.T28" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 28:</span>사전 훈련 말뭉치의 통계.</figcaption>
<div id="S4.T28.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:481.8pt;height:82pt;vertical-align:-10.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S4.T28.1.1" class="ltx_p"><span id="S4.T28.1.1.1" class="ltx_text"> <span id="S4.T28.1.1.1.1" class="ltx_tabular ltx_align_middle"> <span id="S4.T28.1.1.1.1.1" class="ltx_tr"> <span id="S4.T28.1.1.1.1.1.1" class="ltx_td ltx_border_tt"></span> <span id="S4.T28.1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T28.1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">MODU</span></span> <span id="S4.T28.1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T28.1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">CC-100-Kor</span></span> <span id="S4.T28.1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T28.1.1.1.1.1.4.1" class="ltx_text ltx_font_bold">NAMUWIKI</span></span> <span id="S4.T28.1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T28.1.1.1.1.1.5.1" class="ltx_text ltx_font_bold">NEWSCRAWL</span></span> <span id="S4.T28.1.1.1.1.1.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T28.1.1.1.1.1.6.1" class="ltx_text ltx_font_bold">PETITION</span></span> <span id="S4.T28.1.1.1.1.1.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt"><span id="S4.T28.1.1.1.1.1.7.1" class="ltx_text ltx_font_bold">Total</span></span></span> <span id="S4.T28.1.1.1.1.2" class="ltx_tr"> <span id="S4.T28.1.1.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t"># Sentences</span> <span id="S4.T28.1.1.1.1.2.2" class="ltx_td ltx_align_center ltx_border_t">167M</span> <span id="S4.T28.1.1.1.1.2.3" class="ltx_td ltx_align_center ltx_border_t">103M</span> <span id="S4.T28.1.1.1.1.2.4" class="ltx_td ltx_align_center ltx_border_t">14M</span> <span id="S4.T28.1.1.1.1.2.5" class="ltx_td ltx_align_center ltx_border_t">183M</span> <span id="S4.T28.1.1.1.1.2.6" class="ltx_td ltx_align_center ltx_border_t">5.2M</span> <span id="S4.T28.1.1.1.1.2.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t"><span id="S4.T28.1.1.1.1.2.7.1" class="ltx_text ltx_font_bold">473M</span></span></span> <span id="S4.T28.1.1.1.1.3" class="ltx_tr"> <span id="S4.T28.1.1.1.1.3.1" class="ltx_td ltx_align_left"># Words</span> <span id="S4.T28.1.1.1.1.3.2" class="ltx_td ltx_align_center">1,892,814,395</span> <span id="S4.T28.1.1.1.1.3.3" class="ltx_td ltx_align_center">1,593,887,022</span> <span id="S4.T28.1.1.1.1.3.4" class="ltx_td ltx_align_center">265,203,602</span> <span id="S4.T28.1.1.1.1.3.5" class="ltx_td ltx_align_center">2,716,968,038</span> <span id="S4.T28.1.1.1.1.3.6" class="ltx_td ltx_align_center">50,631,183</span> <span id="S4.T28.1.1.1.1.3.7" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T28.1.1.1.1.3.7.1" class="ltx_text ltx_font_bold">6,519,504,240</span></span></span> <span id="S4.T28.1.1.1.1.4" class="ltx_tr"> <span id="S4.T28.1.1.1.1.4.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">size (GB)</span> <span id="S4.T28.1.1.1.1.4.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">18.27</span> <span id="S4.T28.1.1.1.1.4.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">15.46</span> <span id="S4.T28.1.1.1.1.4.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">2.52</span> <span id="S4.T28.1.1.1.1.4.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">25.87</span> <span id="S4.T28.1.1.1.1.4.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">0.53</span> <span id="S4.T28.1.1.1.1.4.7" class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t"><span id="S4.T28.1.1.1.1.4.7.1" class="ltx_text ltx_font_bold">62.65</span></span></span> </span></span></p>
</span></div>
</figure>
<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pretraining Corpora</h5>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">우리는 광범위한 주제 및 다양한 스타일을 다루기 위해 다양한 출처에서 공개적으로 사용할 수 있는 다음 5가지 한국 말뭉치를 수집한다. 우리는 이 말뭉치를 결합하여 대략 62GB 크기의 최종 사전 훈련 말뭉치를 구축한다. 전체 통계는 Table <a class="ltx_ref" href="#S4.T28" title="Table 28 ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">28</span></a> 참조:</p>
</div>
<div id="S4.SS1.SSS0.Px1.p2" class="ltx_para">
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">MODU</span> : <span class="ltx_text ltx_font_italic" id="S4.I1.i1.p1.1.2">Modu<span class="ltx_note ltx_role_footnote" id="footnote51"><sup class="ltx_note_mark">51</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">51</sup><span class="ltx_tag ltx_tag_note"><span class="ltx_text ltx_font_upright" id="footnote51.1.1.1">51</span></span><span class="ltx_text ltx_font_upright" id="footnote51.5"> A transliteration of a Korean word ‘모두’ which means ‘Everyone’. </span></span></span></span></span> Corpus <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib98" title="">98</a>]</cite>는 국립국어원에서 배포한 한국어 말뭉치의 모음이다. <span class="ltx_note ltx_role_footnote" id="footnote52"><sup class="ltx_note_mark">52</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">52</sup><span class="ltx_tag ltx_tag_note">52</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://corpus.korean.go.kr/" target="_blank" title="">https://corpus.korean.go.kr/</a></span></span></span> 정식 기사(신문과 책)와 구어체 텍스트(대화법)를 모두 포함한다.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">CC-100-Kor</span> : CC-100<span class="ltx_note ltx_role_footnote" id="footnote53"><sup class="ltx_note_mark">53</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">53</sup><span class="ltx_tag ltx_tag_note">53</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://data.statmt.org/cc-100/" target="_blank" title="">http://data.statmt.org/cc-100/</a> </span></span></span>은 CC-Net <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib136" title="">136</a>]</cite>를 사용하여 대규모 다국어 웹 크롤링된 말뭉치이다. 이는 XLM-R <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite> 트레이닝에 사용된다. 우리는 이 말뭉치의 한국어 부분을 사용합니다.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">NAMUWIKI</span> : NAMUWIKI는 한국 웹 기반 백과사전이며, Wikipedia와 유사하지만 덜 형식적인 것으로 알려져 있다. 구체적으로, 2020년 3월 2일에 생성된 덤프를 다운로드한다.<span class="ltx_note ltx_role_footnote" id="footnote54"><sup class="ltx_note_mark">54</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">54</sup><span class="ltx_tag ltx_tag_note">54</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://dump.thewiki.kr" target="_blank" title="">http://dump.thewiki.kr</a> </span></span></span></p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i4.p1.1.1">NEWSCRAWL</span> : NEWSCRAWL consists of 12,800,000 news articles published from 2011 to 2020, collected from a news aggregation platform.</p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i5.p1" class="ltx_para">
<p class="ltx_p" id="S4.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i5.p1.1.1">PETITION</span> : Petition is a collection of public petitions posted to the Blue House asking to administrative actions on social issues. 2017년 8월부터 2019년 3월까지 발표된 청와대 국민청원 <span class="ltx_note ltx_role_footnote" id="footnote55"><sup class="ltx_note_mark">55</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">55</sup><span class="ltx_tag ltx_tag_note">55</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www1.president.go.kr/petitions" target="_blank" title="">https://www1.president.go.kr/petitions</a> </span></span></span>의 기사를 사용한다. <span class="ltx_note ltx_role_footnote" id="footnote56"><sup class="ltx_note_mark">56</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">56</sup><span class="ltx_tag ltx_tag_note">56</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ko-nlp.github.io/Korpora/en-docs/corpuslist/korean_petitions.html" target="_blank" title="">https://ko-nlp.github.io/Korpora/en-docs/corpuslist/korean_petitions.html</a> </span></span></span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Preprocessing</h5>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">우리는 Section <a class="ltx_ref" href="#S2.SS3.SSS0.Px3" title="PII Removal ‣ 2.3 Preprocessing ‣ 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">2.3</span></a>에서 동일한 방법을 사용하여 잡음이 있는 텍스트와 한글이 아닌 텍스트를 필터링한다. 코퍼스의 각 문서는 규칙 기반 한국어 문장 분할기(KSS)의 C++ 구현(v1.3.1.)을 사용하여 문장으로 분할된다. <span class="ltx_note ltx_role_footnote" id="footnote57"><sup class="ltx_note_mark">57</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">57</sup><span class="ltx_tag ltx_tag_note">57</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/likejazz/korean-sentence-splitter" target="_blank" title="">https://github.com/likejazz/korean-sentence-splitter</a> </span></span></span> CC-100-Kor 및 NEWSCRAWL의 경우, 잘 형성된 문장을 유지하기 위한 휴리스틱으로서 길이 200자 이상의 문장을 유지한다. 그런 다음 BM25를 문장 유사성 메트릭 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib118" title="">118</a>]</cite>로 사용하여 벤치마크 작업 데이터 세트에 포함된 문장을 제거한다.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Ethical Considerations</h5>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">사전 교육을 위해 가능한 한 공개적으로 사용 가능한 데이터를 수집하고 사용하기 때문에 이러한 말뭉치는 종종 바람직하지 않은 사회적 편향을 포함한다. 또한, 우리는 이전에 이러한 말뭉치에서 PII가 모두 공개적으로 사용 가능했지만 상당히 많다는 것을 발견했다. 이 두 가지 모두 문제가 있습니다. 코퍼스의 사회적 편향은 그러한 편향을 학습하는 언어 모델을 초래할 수 있다. 코퍼스 내의 PII는 언어 모델에 의해 암기될 수 있고, 이어서 적대적 공격들 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib12" title="">12</a>]</cite>에 의해 검색될 수 있다.</p>
</div>
<div id="S4.SS1.SSS0.Px3.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p2.1">우리는 세 가지 이유로 사회적으로 편향된 내용이나 혐오 발언을 걸러내지 않는다. 첫째, 이러한 대규모 사전 훈련 코퍼라에 대해서는 수동 검사가 불가능하다. 둘째, 이 두 가지 모두 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib62" title="">62</a>]</cite>가 나타나는 맥락에 크게 의존하기 때문에 사회적으로 편향된 콘텐츠나 혐오 공간을 자동으로 탐지하는 것은 그 자체로 어려운 문제이다. 마지막으로, 이러한 유해 콘텐츠에 대해 맹목적인 것은 안티 전문가 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib81" title="">81</a>]</cite>로 사용하는 것과 같이 이러한 유해 콘텐츠를 탐지하고 수정하기 위한 언어 모델의 향후 사용을 방지한다. 최근에 <cite class="ltx_cite ltx_citemacro_citet">Cheng et al. [<a class="ltx_ref" href="#bib.bib15" title="">15</a>]</cite>에 의해 입증된 바와 같이, 본 논문에서 발표하는 사전 훈련 언어 모델에 대한 향후 연구는 이러한 모델에서 인코딩된 편향을 탐지하고 수정하는 방법과 디바이어스를 제거하는 방법에 초점을 맞출 것으로 기대한다.</p>
</div>
<div id="S4.SS1.SSS0.Px3.p3" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p3.1">대조적으로, 우리는 가능한 한 말뭉치에서 PII를 가명 처리합니다. 한국인터넷진흥원(KISA)의 지침에 따라 정규식을 사용하여 16개의 개인 데이터 유형을 탐지한다. <span class="ltx_note ltx_role_footnote" id="footnote58"><sup class="ltx_note_mark">58</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">58</sup><span class="ltx_tag ltx_tag_note">58</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.kisa.or.kr/public/laws/laws2_View.jsp?cPage=1&amp;mode=view&amp;p_No=282&amp;b_No=282&amp;d_No=3" target="_blank" title="">https://www.kisa.or.kr/public/laws/laws2_View.jsp?cPage=1&amp;mode=view&amp;p_No=282&amp;b_No=282&amp;d_No=3</a> </span></span></span> 선택된 PII는 정형화된 패턴을 가지고 있기 때문에 언어적 패턴을 유지하면서 PII를 가명 처리하는 것이 비교적 쉽다. 그런 다음 패턴을 기반으로 <a class="ltx_ref ltx_url ltx_font_typewriter" href="faker" title="">faker</a> 라이브러리<span class="ltx_note ltx_role_footnote" id="footnote59"><sup class="ltx_note_mark">59</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">59</sup><span class="ltx_tag ltx_tag_note">59</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/joke2k/faker" target="_blank" title="">https://github.com/joke2k/faker</a> </span></span></span> 또는 랜덤 생성을 사용하여 원본 정보를 대체한다. 그 결과 사전 훈련 말뭉치의 1.2%를 가명 처리한다. 상세한 내용은 표<a class="ltx_ref" href="#S4.T29" title="Table 29 ‣ Ethical Considerations ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">29</span></a>에 예시되어 있다.</p>
</div>
<figure id="S4.T29" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 29:</span>우리의 가명화 방법 및 예. 예제는 <a class="ltx_ref ltx_url ltx_font_typewriter" href="faker" title="">faker</a> 라이브러리 설명서 또는 일반에서 가져온 것입니다.</figcaption>
<div id="S4.T29.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:401.8pt;height:306pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S4.T29.1.1"><span class="ltx_text" id="S4.T29.1.1.1.1.1.1"><span class="ltx_td ltx_align_left ltx_border_tt" id="S4.T29.1.1.1.1.1.1.1"><span class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt" id="S4.T29.1.1.1.1.1.1.1.1"><span class="ltx_td ltx_font_bold" id="S4.T29.1.1.1.1.1.1.1.1"><span class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt" id="S4.T29.1.1.1.1.1.1.1.1"><span class="ltx_td ltx</p>
</span></div>
</figure>
</section>
<section id="S4.SS1.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Tokenization</h5>

<div id="S4.SS1.SSS0.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px4.p1.1">새로운 토큰화 방법인 <span class="ltx_text ltx_font_italic" id="S4.SS1.SSS0.Px4.p1.1.1">morpheme-based subword</span> tokenization을 설계하고 사용한다. 어휘 구축 시 형태소 분석기를 이용하여 원시 텍스트를 형태소로 사전 토큰화한 후 바이트 쌍 인코딩(BPE) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib123" title="">123</a>]</cite>를 적용하여 최종 어휘를 얻는다. 형태소 분할은 <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS0.Px4.p1.1.2">Mecab-ko</span>,<span class="ltx_note ltx_role_footnote" id="footnote60"><sup class="ltx_note_mark">60</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">60</sup><span class="ltx_tag ltx_tag_note">60</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://bitbucket.org/eunjeon/mecab-ko" target="_blank" title="">https://bitbucket.org/eunjeon/mecab-ko</a> </span></span></span> MeCab <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib68" title="">68</a>]</cite> 한국어 적응을 사용하고, BPE 분할은 <span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS0.Px4.p1.1.3">Huggingface Tokenizers</span> 라이브러리를 사용한다. <span class="ltx_note ltx_role_footnote" id="footnote61"><sup class="ltx_note_mark">61</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">61</sup><span class="ltx_tag ltx_tag_note">61</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/huggingface/tokenizers" target="_blank" title="">https://github.com/huggingface/tokenizers</a> </span></span></span> 어휘 크기를 32k로 지정합니다. 어휘를 구축한 후 추론 시 BPE 모델만을 사용하여 형태소 분석기 없이 형태소를 반영하여 단어열을 토큰화할 수 있다. 이렇게 하면 사용성과 속도가 모두 향상됩니다. 예들은 표 <a class="ltx_ref" href="#S4.T30" title="Table 30 ‣ Tokenization ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">30</span></a>에 제시되어 있다.</p>
</div>
<div id="S4.SS1.SSS0.Px4.p2" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px4.p2.1">이 방법의 동기는 한국어가 응집 언어, 즉 단어는 형태소-줄기와 접사의 구성이라는 것이다. 형태소는 서로 다른 조합에서 변하지 않는 경향이 있으며, 그 경계는 일반적으로 명확하다. BPE는 그 효율성으로 인해 많은 언어에 걸쳐 널리 사용되었지만 표 <a class="ltx_ref" href="#S4.T30" title="Table 30 ‣ Tokenization ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">30</span></a>에서 입증된 바와 같이 형태소를 올바르게 식별하는 데 어려움을 겪고 있다.</p>
</div>
<figure id="S4.T30" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 30:</span>An input text “조경현은 인공지능 분야의 저명한 연구자이다. (조경현은 저명한 인공지능 연구자이다.)” 다양한 토큰화 전략으로 분할된다. 우리는 슬래시를 토큰 구분자로 나타낸다. mBERT 토큰izer <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>는 입력 텍스트를 거의 문자로 분할하여 단일 언어 토큰izer보다 긴 시퀀스를 생성한다. BPE 토큰화기는 여러 형태소(##현은, ##명한)에 걸쳐 있는 토큰을 생성합니다. <span class="ltx_text ltx_font_italic" id="S4.T30.2.1">Morpheme-based subword</span> tokenizer는 다른 한편으로, 텍스트를 형태소(##은, ##의)로 더 잘 분할한다.</figcaption>
<div id="S4.T30.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:581.1pt;height:118.1pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p" id="S4.T30.3.1"><span class="ltx_text" id="S4.T30.3.1.1.1"><span class="ltx_tabular ltx_align_left ltx_border_tt" id="S4.T30.3.1.1.1.1.1.1.1.1"><span class="ltx_td ltx_align_left ltx_border_tt" id="S4.T30.3.1.1.1.1.1.1.1"><span class="ltx_td ltx_font_bold" id="S4.T30.3.1.1.1.1.1.1.1">Tokenization</span></span></span> <span class="ltx_td ltx_align_left ltx_border_tt" id="S4.T30.3.1.1.1.1.2"><span class="ltx_td ltx_align_left l </span></span> <span class="ltx_tr" id="S4.T30.3.1.1.1.3"> <span class="ltx_td ltx_align_left ltx_border_t" id="S4.T30.3.1.1.3.1">BPE (Multilingual)</span> <span class="ltx_td ltx_align_left ltx_border_t" id="S4.T30.3.1.1.3.2">조 / ##경 / ##현 / ##은 /인 / ##공 / ##지 / ##능 / 분 / ##야 / ##의 / 저 / ##명한 / 연구 / ##자 / ##이다 / </span></span> <span class="ltx_tr" id="S4.T30.3.1.1.1.1.4"><span class="ltx_td ltx_align_left ltx_border_t" id="S4.T30.3.1.1.4.1">BPE</span> <span class="ltx_td ltx_align_left ltx_border_t" id="S4.T30.3.1.1.1.4.2">조경 / ##현은 /AI / 분야의 / 저 / ##명한 / 연구 / ##자이 / ##다 / </span></span> <span class="ltx_tr" id="S4.T30.3.1.1.1.1.5"><span class="ltx_td ltx_align_left" id="S4.T30.3.1.1.5.1">Morpheme</span> <span class="ltx_td ltx_align_left" id="S4.T30.3.1.1.1.5.2">조경현 / 은 / 인공지능 / 분야 / 의 / 저명 / 한 / 연구자 / 이 / 다 / <span class="ltx_td ltx_align_left ltx_border_bb" id="S4.T30.3.1.1.1.6.1"><span class="ltx_text ltx_font_bold" id="S4.T30.3.1.1.6.1.1">Morpheme-based Subword</span></span> <span class="ltx_td ltx_align_left ltx_border_bb" id="S4.T30.3.1.1.1.6.2">조경 / ##현 / ##은 /AI / 분야 / ##의 / 저명 / ##한 / 연구자 / ##이다. </span></span></span></span></p>
</span></div>
</figure>
</section>
<section id="S4.SS1.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Training Configurations</h5>

<div id="S4.SS1.SSS0.Px5.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS1.SSS0.Px5.p1.1">우리는 언어 모델에 대해 BERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>와 RoBERTa <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite> 아키텍처를 선택한다. Table <a class="ltx_ref" href="#S4.T31" title="Table 31 ‣ Training Configurations ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">31</span></a>는 구현 세부사항을 설명한다. 모든 모델은 각각 최대 512 토큰의 시퀀스를 취하고 원래 훈련 절차에 따라 정적 또는 동적 마스킹 전략으로 사전 훈련된다. 토큰을 마스킹할 때, 우리는 하나의 단어를 형성하는 모든 토큰을 마스킹하는 전체 단어 마스킹(WWM)을 사용한다. BERT는 또한 다음 문장 예측(NSP)을 수행한다. 표<a class="ltx_ref" href="#S4.T31" title="Table 31 ‣ Training Configurations ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">31</span></a>에 명시되지 않은 다른 하이퍼파라미터 및 사전 훈련 절차 세부 사항은 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>, <a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>의 원래 구성과 동일하다. 리소스 제약으로 인해 8k의 배치 크기를 사용하는 <cite class="ltx_cite ltx_citemacro_citet">Liu et al. [<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>와 달리 배치 크기를 최대 2,048까지만 증가시킬 수 있었다. 이에 따라 학습률을 낮춥니다. BERT와 RoBERTa 모두에 대해 학습률을 <math alttext="10^{-4}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px5.p1.1.m1.1"><semantics id="S4.SS1.SSS0.Px5.p1.1.m1.1a"><msup id="S4.SS1.SSS0.Px5.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.cmml"><mn id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.2" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.2.cmml">10</mn><mrow id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.cmml"><mo id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3a" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.cmml">−</mo><mn id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.2" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px5.p1.1.m1.1b"><apply id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1">superscript</csymbol><cn id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.2.cmml" type="integer" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.2">10</cn><apply id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3"><minus id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.1.cmml" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3"></minus><cn id="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.2.cmml" type="integer" xref="S4.SS1.SSS0.Px5.p1.1.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px5.p1.1.m1.1c">10^{-4}</annotation></semantics></math>로 고정한다.</p>
</div>
<figure id="S4.T31" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 31:</span>KLUE-BERT 및 KLUE-RoBERTa의 구현 상세들. WWM은 전체 단어 마스킹 전략을 의미한다.</figcaption>
<div id="S4.T31.11" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:552.2pt;height:91pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S4.T31.11.11" class="ltx_p"><span id="S4.T31.11.11.11" class="ltx_text"> <span id="S4.T31.11.11.11.11" class="ltx_tabular ltx_align_middle"> <span id="S4.T31.11.11.11.11.12" class="ltx_tr"> <span id="S4.T31.11.11.11.11.12.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T31.11.11.11.11.12.1.1" class="ltx_text ltx_font_bold">Model</span></span> <span id="S4.T31.11.11.11.11.12.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T31.11.11.11.11.12.2.1" class="ltx_text ltx_font_bold"># Parameter</span></span> <span id="S4.T31.11.11.11.11.12.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T31.11.11.11.11.12.3.1" class="ltx_text ltx_font_bold">Masking</span></span> <span id="S4.T31.11.11.11.11.12.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T31.11.11.11.11.12.4.1" class="ltx_text ltx_font_bold">Training Steps</span></span> <span id="S4.T31.11.11.11.11.12.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T31.11.11.11.11.12.5.1" class="ltx_text ltx_font_bold">Batch Size</span></span> <span id="S4.T31.11.11.11.11.12.6" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T31.11.11.11.11.12.6.1" class="ltx_text ltx_font_bold">Learning Rate</span></span> <span id="S4.T31.11.11.11.11.12.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T31.11.11.11.11.12.7.1" class="ltx_text ltx_font_bold">Device</span></span></span> <span id="S4.T31.2.2.2.2.2" class="ltx_tr"> <span id="S4.T31.1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T31.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\text{KLUE-BERT}_{\text{BASE}}" display="inline"><semantics id="S4.T31.1.1.1.1.1.1.m1.1a"><msub id="S4.T31.1.1.1.1.1.1.m1.1.1" xref="S4.T31.1.1.1.1.1.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T31.1.1.1.1.1.1.m1.1.1.2" xref="S4.T31.1.1.1.1.1.1.m1.1.1.2a.cmml">KLUE-BERT</mtext><mtext class="ltx_mathvariant_bold" id="S4.T31.1.1.1.1.1.1.m1.1.1.3" xref="S4.T31.1.1.1.1.1.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T31.1.1.1.1.1.1.m1.1b"><apply id="S4.T31.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T31.1.1.1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.1.1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T31.1.1.1.1.1.1.m1.1.1">subscript</csymbol><ci id="S4.T31.1.1.1.1.1.1.m1.1.1.2a.cmml" xref="S4.T31.1.1.1.1.1.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T31.1.1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T31.1.1.1.1.1.1.m1.1.1.2">KLUE-BERT</mtext></ci><ci id="S4.T31.1.1.1.1.1.1.m1.1.1.3a.cmml" xref="S4.T31.1.1.1.1.1.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S4.T31.1.1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T31.1.1.1.1.1.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.1.1.1.1.1.1.m1.1c">\text{KLUE-BERT}_{\text{BASE}}</annotation></semantics></math></span> <span id="S4.T31.2.2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t">110M</span> <span id="S4.T31.2.2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">Static, WWM</span> <span id="S4.T31.2.2.2.2.2.5" class="ltx_td ltx_align_center ltx_border_t">1M</span> <span id="S4.T31.2.2.2.2.2.6" class="ltx_td ltx_align_center ltx_border_t">256</span> <span id="S4.T31.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T31.2.2.2.2.2.2.m1.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S4.T31.2.2.2.2.2.2.m1.1a"><msup id="S4.T31.2.2.2.2.2.2.m1.1.1" xref="S4.T31.2.2.2.2.2.2.m1.1.1.cmml"><mn id="S4.T31.2.2.2.2.2.2.m1.1.1.2" xref="S4.T31.2.2.2.2.2.2.m1.1.1.2.cmml">10</mn><mrow id="S4.T31.2.2.2.2.2.2.m1.1.1.3" xref="S4.T31.2.2.2.2.2.2.m1.1.1.3.cmml"><mo id="S4.T31.2.2.2.2.2.2.m1.1.1.3a" xref="S4.T31.2.2.2.2.2.2.m1.1.1.3.cmml">−</mo><mn id="S4.T31.2.2.2.2.2.2.m1.1.1.3.2" xref="S4.T31.2.2.2.2.2.2.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.T31.2.2.2.2.2.2.m1.1b"><apply id="S4.T31.2.2.2.2.2.2.m1.1.1.cmml" xref="S4.T31.2.2.2.2.2.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.2.2.2.2.2.2.m1.1.1.1.cmml" xref="S4.T31.2.2.2.2.2.2.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T31.2.2.2.2.2.2.m1.1.1.2.cmml" xref="S4.T31.2.2.2.2.2.2.m1.1.1.2">10</cn><apply id="S4.T31.2.2.2.2.2.2.m1.1.1.3.cmml" xref="S4.T31.2.2.2.2.2.2.m1.1.1.3"><minus id="S4.T31.2.2.2.2.2.2.m1.1.1.3.1.cmml" xref="S4.T31.2.2.2.2.2.2.m1.1.1.3"></minus><cn type="integer" id="S4.T31.2.2.2.2.2.2.m1.1.1.3.2.cmml" xref="S4.T31.2.2.2.2.2.2.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.2.2.2.2.2.2.m1.1c">10^{-4}</annotation></semantics></math></span> <span id="S4.T31.2.2.2.2.2.7" class="ltx_td ltx_align_center ltx_border_t">TPU v3-8</span></span> <span id="S4.T31.5.5.5.5.5" class="ltx_tr"> <span id="S4.T31.3.3.3.3.3.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T31.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{SMALL}}" display="inline"><semantics id="S4.T31.3.3.3.3.3.1.m1.1a"><msub id="S4.T31.3.3.3.3.3.1.m1.1.1" xref="S4.T31.3.3.3.3.3.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T31.3.3.3.3.3.1.m1.1.1.2" xref="S4.T31.3.3.3.3.3.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="S4.T31.3.3.3.3.3.1.m1.1.1.3" xref="S4.T31.3.3.3.3.3.1.m1.1.1.3a.cmml">SMALL</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T31.3.3.3.3.3.1.m1.1b"><apply id="S4.T31.3.3.3.3.3.1.m1.1.1.cmml" xref="S4.T31.3.3.3.3.3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.3.3.3.3.3.1.m1.1.1.1.cmml" xref="S4.T31.3.3.3.3.3.1.m1.1.1">subscript</csymbol><ci id="S4.T31.3.3.3.3.3.1.m1.1.1.2a.cmml" xref="S4.T31.3.3.3.3.3.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T31.3.3.3.3.3.1.m1.1.1.2.cmml" xref="S4.T31.3.3.3.3.3.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S4.T31.3.3.3.3.3.1.m1.1.1.3a.cmml" xref="S4.T31.3.3.3.3.3.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S4.T31.3.3.3.3.3.1.m1.1.1.3.cmml" xref="S4.T31.3.3.3.3.3.1.m1.1.1.3">SMALL</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.3.3.3.3.3.1.m1.1c">\text{KLUE-RoBERTa}_{\text{SMALL}}</annotation></semantics></math></span> <span id="S4.T31.5.5.5.5.5.4" class="ltx_td ltx_align_center ltx_border_t">68M</span> <span id="S4.T31.5.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">Dynamic, WWM</span> <span id="S4.T31.5.5.5.5.5.6" class="ltx_td ltx_align_center ltx_border_t">1M</span> <span id="S4.T31.5.5.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t">2048</span> <span id="S4.T31.4.4.4.4.4.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T31.4.4.4.4.4.2.m1.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S4.T31.4.4.4.4.4.2.m1.1a"><msup id="S4.T31.4.4.4.4.4.2.m1.1.1" xref="S4.T31.4.4.4.4.4.2.m1.1.1.cmml"><mn id="S4.T31.4.4.4.4.4.2.m1.1.1.2" xref="S4.T31.4.4.4.4.4.2.m1.1.1.2.cmml">10</mn><mrow id="S4.T31.4.4.4.4.4.2.m1.1.1.3" xref="S4.T31.4.4.4.4.4.2.m1.1.1.3.cmml"><mo id="S4.T31.4.4.4.4.4.2.m1.1.1.3a" xref="S4.T31.4.4.4.4.4.2.m1.1.1.3.cmml">−</mo><mn id="S4.T31.4.4.4.4.4.2.m1.1.1.3.2" xref="S4.T31.4.4.4.4.4.2.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.T31.4.4.4.4.4.2.m1.1b"><apply id="S4.T31.4.4.4.4.4.2.m1.1.1.cmml" xref="S4.T31.4.4.4.4.4.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.4.4.4.4.4.2.m1.1.1.1.cmml" xref="S4.T31.4.4.4.4.4.2.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T31.4.4.4.4.4.2.m1.1.1.2.cmml" xref="S4.T31.4.4.4.4.4.2.m1.1.1.2">10</cn><apply id="S4.T31.4.4.4.4.4.2.m1.1.1.3.cmml" xref="S4.T31.4.4.4.4.4.2.m1.1.1.3"><minus id="S4.T31.4.4.4.4.4.2.m1.1.1.3.1.cmml" xref="S4.T31.4.4.4.4.4.2.m1.1.1.3"></minus><cn type="integer" id="S4.T31.4.4.4.4.4.2.m1.1.1.3.2.cmml" xref="S4.T31.4.4.4.4.4.2.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.4.4.4.4.4.2.m1.1c">10^{-4}</annotation></semantics></math></span> <span id="S4.T31.5.5.5.5.5.3" class="ltx_td ltx_align_center ltx_border_t">8<math id="S4.T31.5.5.5.5.5.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T31.5.5.5.5.5.3.m1.1a"><mo id="S4.T31.5.5.5.5.5.3.m1.1.1" xref="S4.T31.5.5.5.5.5.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T31.5.5.5.5.5.3.m1.1b"><times id="S4.T31.5.5.5.5.5.3.m1.1.1.cmml" xref="S4.T31.5.5.5.5.5.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.5.5.5.5.5.3.m1.1c">\times</annotation></semantics></math> V100 GPUs</span></span> <span id="S4.T31.8.8.8.8.8" class="ltx_tr"> <span id="S4.T31.6.6.6.6.6.1" class="ltx_td ltx_align_left"><math id="S4.T31.6.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{BASE}}" display="inline"><semantics id="S4.T31.6.6.6.6.6.1.m1.1a"><msub id="S4.T31.6.6.6.6.6.1.m1.1.1" xref="S4.T31.6.6.6.6.6.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T31.6.6.6.6.6.1.m1.1.1.2" xref="S4.T31.6.6.6.6.6.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="S4.T31.6.6.6.6.6.1.m1.1.1.3" xref="S4.T31.6.6.6.6.6.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T31.6.6.6.6.6.1.m1.1b"><apply id="S4.T31.6.6.6.6.6.1.m1.1.1.cmml" xref="S4.T31.6.6.6.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.6.6.6.6.6.1.m1.1.1.1.cmml" xref="S4.T31.6.6.6.6.6.1.m1.1.1">subscript</csymbol><ci id="S4.T31.6.6.6.6.6.1.m1.1.1.2a.cmml" xref="S4.T31.6.6.6.6.6.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T31.6.6.6.6.6.1.m1.1.1.2.cmml" xref="S4.T31.6.6.6.6.6.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S4.T31.6.6.6.6.6.1.m1.1.1.3a.cmml" xref="S4.T31.6.6.6.6.6.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S4.T31.6.6.6.6.6.1.m1.1.1.3.cmml" xref="S4.T31.6.6.6.6.6.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.6.6.6.6.6.1.m1.1c">\text{KLUE-RoBERTa}_{\text{BASE}}</annotation></semantics></math></span> <span id="S4.T31.8.8.8.8.8.4" class="ltx_td ltx_align_center">110M</span> <span id="S4.T31.8.8.8.8.8.5" class="ltx_td ltx_align_center">Dynamic, WWM</span> <span id="S4.T31.8.8.8.8.8.6" class="ltx_td ltx_align_center">1M</span> <span id="S4.T31.8.8.8.8.8.7" class="ltx_td ltx_align_center">2048</span> <span id="S4.T31.7.7.7.7.7.2" class="ltx_td ltx_align_center"><math id="S4.T31.7.7.7.7.7.2.m1.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S4.T31.7.7.7.7.7.2.m1.1a"><msup id="S4.T31.7.7.7.7.7.2.m1.1.1" xref="S4.T31.7.7.7.7.7.2.m1.1.1.cmml"><mn id="S4.T31.7.7.7.7.7.2.m1.1.1.2" xref="S4.T31.7.7.7.7.7.2.m1.1.1.2.cmml">10</mn><mrow id="S4.T31.7.7.7.7.7.2.m1.1.1.3" xref="S4.T31.7.7.7.7.7.2.m1.1.1.3.cmml"><mo id="S4.T31.7.7.7.7.7.2.m1.1.1.3a" xref="S4.T31.7.7.7.7.7.2.m1.1.1.3.cmml">−</mo><mn id="S4.T31.7.7.7.7.7.2.m1.1.1.3.2" xref="S4.T31.7.7.7.7.7.2.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.T31.7.7.7.7.7.2.m1.1b"><apply id="S4.T31.7.7.7.7.7.2.m1.1.1.cmml" xref="S4.T31.7.7.7.7.7.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.7.7.7.7.7.2.m1.1.1.1.cmml" xref="S4.T31.7.7.7.7.7.2.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T31.7.7.7.7.7.2.m1.1.1.2.cmml" xref="S4.T31.7.7.7.7.7.2.m1.1.1.2">10</cn><apply id="S4.T31.7.7.7.7.7.2.m1.1.1.3.cmml" xref="S4.T31.7.7.7.7.7.2.m1.1.1.3"><minus id="S4.T31.7.7.7.7.7.2.m1.1.1.3.1.cmml" xref="S4.T31.7.7.7.7.7.2.m1.1.1.3"></minus><cn type="integer" id="S4.T31.7.7.7.7.7.2.m1.1.1.3.2.cmml" xref="S4.T31.7.7.7.7.7.2.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.7.7.7.7.7.2.m1.1c">10^{-4}</annotation></semantics></math></span> <span id="S4.T31.8.8.8.8.8.3" class="ltx_td ltx_align_center">8<math id="S4.T31.8.8.8.8.8.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T31.8.8.8.8.8.3.m1.1a"><mo id="S4.T31.8.8.8.8.8.3.m1.1.1" xref="S4.T31.8.8.8.8.8.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T31.8.8.8.8.8.3.m1.1b"><times id="S4.T31.8.8.8.8.8.3.m1.1.1.cmml" xref="S4.T31.8.8.8.8.8.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.8.8.8.8.8.3.m1.1c">\times</annotation></semantics></math> V100 GPUs</span></span> <span id="S4.T31.11.11.11.11.11" class="ltx_tr"> <span id="S4.T31.9.9.9.9.9.1" class="ltx_td ltx_align_left ltx_border_bb"><math id="S4.T31.9.9.9.9.9.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{LARGE}}" display="inline"><semantics id="S4.T31.9.9.9.9.9.1.m1.1a"><msub id="S4.T31.9.9.9.9.9.1.m1.1.1" xref="S4.T31.9.9.9.9.9.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S4.T31.9.9.9.9.9.1.m1.1.1.2" xref="S4.T31.9.9.9.9.9.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="S4.T31.9.9.9.9.9.1.m1.1.1.3" xref="S4.T31.9.9.9.9.9.1.m1.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.T31.9.9.9.9.9.1.m1.1b"><apply id="S4.T31.9.9.9.9.9.1.m1.1.1.cmml" xref="S4.T31.9.9.9.9.9.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.9.9.9.9.9.1.m1.1.1.1.cmml" xref="S4.T31.9.9.9.9.9.1.m1.1.1">subscript</csymbol><ci id="S4.T31.9.9.9.9.9.1.m1.1.1.2a.cmml" xref="S4.T31.9.9.9.9.9.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S4.T31.9.9.9.9.9.1.m1.1.1.2.cmml" xref="S4.T31.9.9.9.9.9.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S4.T31.9.9.9.9.9.1.m1.1.1.3a.cmml" xref="S4.T31.9.9.9.9.9.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S4.T31.9.9.9.9.9.1.m1.1.1.3.cmml" xref="S4.T31.9.9.9.9.9.1.m1.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.9.9.9.9.9.1.m1.1c">\text{KLUE-RoBERTa}_{\text{LARGE}}</annotation></semantics></math></span> <span id="S4.T31.11.11.11.11.11.4" class="ltx_td ltx_align_center ltx_border_bb">337M</span> <span id="S4.T31.11.11.11.11.11.5" class="ltx_td ltx_align_center ltx_border_bb">Dynamic, WWM</span> <span id="S4.T31.11.11.11.11.11.6" class="ltx_td ltx_align_center ltx_border_bb">500k</span> <span id="S4.T31.11.11.11.11.11.7" class="ltx_td ltx_align_center ltx_border_bb">2048</span> <span id="S4.T31.10.10.10.10.10.2" class="ltx_td ltx_align_center ltx_border_bb"><math id="S4.T31.10.10.10.10.10.2.m1.1" class="ltx_Math" alttext="10^{-4}" display="inline"><semantics id="S4.T31.10.10.10.10.10.2.m1.1a"><msup id="S4.T31.10.10.10.10.10.2.m1.1.1" xref="S4.T31.10.10.10.10.10.2.m1.1.1.cmml"><mn id="S4.T31.10.10.10.10.10.2.m1.1.1.2" xref="S4.T31.10.10.10.10.10.2.m1.1.1.2.cmml">10</mn><mrow id="S4.T31.10.10.10.10.10.2.m1.1.1.3" xref="S4.T31.10.10.10.10.10.2.m1.1.1.3.cmml"><mo id="S4.T31.10.10.10.10.10.2.m1.1.1.3a" xref="S4.T31.10.10.10.10.10.2.m1.1.1.3.cmml">−</mo><mn id="S4.T31.10.10.10.10.10.2.m1.1.1.3.2" xref="S4.T31.10.10.10.10.10.2.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.T31.10.10.10.10.10.2.m1.1b"><apply id="S4.T31.10.10.10.10.10.2.m1.1.1.cmml" xref="S4.T31.10.10.10.10.10.2.m1.1.1"><csymbol cd="ambiguous" id="S4.T31.10.10.10.10.10.2.m1.1.1.1.cmml" xref="S4.T31.10.10.10.10.10.2.m1.1.1">superscript</csymbol><cn type="integer" id="S4.T31.10.10.10.10.10.2.m1.1.1.2.cmml" xref="S4.T31.10.10.10.10.10.2.m1.1.1.2">10</cn><apply id="S4.T31.10.10.10.10.10.2.m1.1.1.3.cmml" xref="S4.T31.10.10.10.10.10.2.m1.1.1.3"><minus id="S4.T31.10.10.10.10.10.2.m1.1.1.3.1.cmml" xref="S4.T31.10.10.10.10.10.2.m1.1.1.3"></minus><cn type="integer" id="S4.T31.10.10.10.10.10.2.m1.1.1.3.2.cmml" xref="S4.T31.10.10.10.10.10.2.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.10.10.10.10.10.2.m1.1c">10^{-4}</annotation></semantics></math></span> <span id="S4.T31.11.11.11.11.11.3" class="ltx_td ltx_align_center ltx_border_bb">8<math id="S4.T31.11.11.11.11.11.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T31.11.11.11.11.11.3.m1.1a"><mo id="S4.T31.11.11.11.11.11.3.m1.1.1" xref="S4.T31.11.11.11.11.11.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T31.11.11.11.11.11.3.m1.1b"><times id="S4.T31.11.11.11.11.11.3.m1.1.1.cmml" xref="S4.T31.11.11.11.11.11.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T31.11.11.11.11.11.3.m1.1c">\times</annotation></semantics></math> V100 GPUs</span></span> </span></span></p>
</span></div>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Existing Language Models</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S4.SS2.p1.1">자체 언어 모델 외에도 벤치마크에서 다음 두 가지 기존 다국어 언어 모델과 두 가지 한국어 단일 언어 모델을 평가한다.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<ul id="S4.I2" class="ltx_itemize">
<li id="S4.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i1.p1" class="ltx_para">
<p class="ltx_p" id="S4.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i1.p1.1.1">mBERT</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite> : <cite class="ltx_cite ltx_citemacro_citet">Devlin et al. [<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>에 의해 도입 및 출시되는 다국어 BERT. 그것은 한국어를 포함한 104개 언어를 다루는 다국어 코퍼스에서 MLM 및 NSP 목표로 훈련된다.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i2.p1" class="ltx_para">
<p class="ltx_p" id="S4.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i2.p1.1.1">XLM-R</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib26" title="">26</a>]</cite> : A RoBERTa <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite> trained on a large multilingual corpus by the MLM objective.</p>
</div>
</li>
<li id="S4.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i3.p1" class="ltx_para">
<p class="ltx_p" id="S4.I2.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i3.p1.1.1">KR-BERT</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib75" title="">75</a>]</cite> : BERT 기반의 open-sourced character level 한국어 모델. 우리는 16,424개의 고유한 토큰의 어휘를 사용하는 <span class="ltx_text ltx_font_typewriter" id="S4.I2.i3.p1.1.2">KR-BERT 문자 WordPiece</span>을 사용한다.</p>
</div>
</li>
<li id="S4.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I2.i4.p1" class="ltx_para">
<p class="ltx_p" id="S4.I2.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I2.i4.p1.1.1">KoELECTRA</span> <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib102" title="">102</a>]</cite> : <cite class="ltx_cite ltx_citemacro_citet">Clark et al. [<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>에 의해 수행된 바와 같이 MLM과 replaced token detection objectives로 학습된 오픈 소스 한국어 모델. 훈련 코퍼라에 대해, <cite class="ltx_cite ltx_citemacro_citet">Park [<a class="ltx_ref" href="#bib.bib102" title="">102</a>]</cite>는 자체 크롤링된 뉴스 데이터와 MODU 코퍼스 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib98" title="">98</a>]</cite>를 사용한다.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Fine-tuning Language Models</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Task-Specific Architectures</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.p1.1">KLUE 벤치마크의 8가지 주요 과제는 미세 조정 전략에 따라 4가지 유형으로 분류할 수 있다. 토픽 분류(TC)와 관계 추출(RE)은 단일 문장 분류 작업이다. 문장 텍스트 유사성(STS) 및 자연어 추론(NLI)은 문장 쌍 분류/회귀 작업이다. 대화 상태 추적(DST)은 다중 문장 슬롯-값 예측 작업이다. 마지막으로, 명명된 개체 인식(NER), 종속 구문 분석(DP) 및 기계 독해(MRC)는 서열 태깅 작업이다.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p class="ltx_p" id="S5.SS1.p2.5"><math alttext="x_{i}" class="ltx_Math" display="inline" id="S5.SS1.p2.1.m1.1"><semantics id="S5.SS1.p2.1.m1.1a"><msub id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml"><mi id="S5.SS1.p2.1.m1.1.1.2" xref="S5.SS1.p2.1.m1.1.1.2.cmml">x</mi><mi id="S5.SS1.p2.1.m1.1.1.3" xref="S5.SS1.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><apply id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.1.m1.1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.p2.1.m1.1.1.2.cmml" xref="S5.SS1.p2.1.m1.1.1.2">𝑥</ci><ci id="S5.SS1.p2.1.m1.1.1.3.cmml" xref="S5.SS1.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">x_{i}</annotation></semantics></math>를 사용하여 입력의 <math alttext="i" class="ltx_Math" display="inline" id="S5.SS1.p2.2.m2.1"><semantics id="S5.SS1.p2.2.m2.1a"><mi id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b"><ci id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">i</annotation></semantics></math>-번째 토큰 및 <math alttext="h_{i}\in\mathbb{R}^{H}" class="ltx_Math" display="inline" id="S5.SS1.p2.3.m3.1"><semantics id="S5.SS1.p2.3.m3.1a"><mrow id="S5.SS1.p2.3.m3.1.1" xref="S5.SS1.p2.3.m3.1.1.cmml"><msub id="S5.SS1.p2.3.m3.1.1.2" xref="S5.SS1.p2.3.m3.1.1.2.cmml"><mi id="S5.SS1.p2.3.m3.1.1.2.2" xref="S5.SS1.p2.3.m3.1.1.2.2.cmml">h</mi><mi id="S5.SS1.p2.3.m3.1.1.2.3" xref="S5.SS1.p2.3.m3.1.1.2.3.cmml">i</mi></msub><mo id="S5.SS1.p2.3.m3.1.1.1" xref="S5.SS1.p2.3.m3.1.1.1.cmml">∈</mo><msup id="S5.SS1.p2.3.m3.1.1.3" xref="S5.SS1.p2.3.m3.1.1.3.cmml"><mi id="S5.SS1.p2.3.m3.1.1.3.2" xref="S5.SS1.p2.3.m3.1.1.3.2.cmml">ℝ</mi><mi id="S5.SS1.p2.3.m3.1.1.3.3" xref="S5.SS1.p2.3.m3.1.1.3.3.cmml">H</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.3.m3.1b"><apply id="S5.SS1.p2.3.m3.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1"><in id="S5.SS1.p2.3.m3.1.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1.1"></in><apply id="S5.SS1.p2.3.m3.1.1.2.cmml" xref="S5.SS1.p2.3.m3.1.1.2"><csymbol cd="ambiguous" id="S5.SS1.p2.3.m3.1.1.2.1.cmml" xref="S5.SS1.p2.3.m3.1.1.2">subscript</csymbol><ci id="S5.SS1.p2.3.m3.1.1.2.2.cmml" xref="S5.SS1.p2.3.m3.1.1.2.2">ℎ</ci><ci id="S5.SS1.p2.3.m3.1.1.2.3.cmml" xref="S5.SS1.p2.3.m3.1.1.2.3">𝑖</ci></apply><apply id="S5.SS1.p2.3.m3.1.1.3.cmml" xref="S5.SS1.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.p2.3.m3.1.1.3.1.cmml" xref="S5.SS1.p2.3.m3.1.1.3">superscript</csymbol><ci id="S5.SS1.p2.3.m3.1.1.3.2.cmml" xref="S5.SS1.p2.3.m3.1.1.3.2">ℝ</ci><ci id="S5.SS1.p2.3.m3.1.1.3.3.cmml" xref="S5.SS1.p2.3.m3.1.1.3.3">𝐻</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.3.m3.1c">h_{i}\in\mathbb{R}^{H}</annotation></semantics></math>를 사전 훈련된 언어 모델(PLM)로부터 해당 최종 은닉 상태로 참조하며, 여기서 <math alttext="H" class="ltx_Math" display="inline" id="S5.SS1.p2.4.m4.1"><semantics id="S5.SS1.p2.4.m4.1a"><mi id="S5.SS1.p2.4.m4.1.1" xref="S5.SS1.p2.4.m4.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.4.m4.1b"><ci id="S5.SS1.p2.4.m4.1.1.cmml" xref="S5.SS1.p2.4.m4.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.4.m4.1c">H</annotation></semantics></math>는 은닉 차원이다. 기존의 fine-tuning setup <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>에 이어 <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p2.5.1">[CLS]</span>을 첫 번째 입력 토큰인 <math alttext="x_{0}" class="ltx_Math" display="inline" id="S5.SS1.p2.5.m5.1"><semantics id="S5.SS1.p2.5.m5.1a"><msub id="S5.SS1.p2.5.m5.1.1" xref="S5.SS1.p2.5.m5.1.1.cmml"><mi id="S5.SS1.p2.5.m5.1.1.2" xref="S5.SS1.p2.5.m5.1.1.2.cmml">x</mi><mn id="S5.SS1.p2.5.m5.1.1.3" xref="S5.SS1.p2.5.m5.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.5.m5.1b"><apply id="S5.SS1.p2.5.m5.1.1.cmml" xref="S5.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.5.m5.1.1.1.cmml" xref="S5.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S5.SS1.p2.5.m5.1.1.2.cmml" xref="S5.SS1.p2.5.m5.1.1.2">𝑥</ci><cn id="S5.SS1.p2.5.m5.1.1.3.cmml" type="integer" xref="S5.SS1.p2.5.m5.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.5.m5.1c">x_{0}</annotation></semantics></math>로 사용하고 <span class="ltx_text ltx_font_typewriter" id="S5.SS1.p2.5.2">[SEP]</span>을 구분자 토큰으로 사용하여 입력을 구분한다(예: STS와 NLI의 두 문장, MRC의 경우 통로와 질문, DST의 경우 대화가 돌아간다).</p>
</div>
<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Single Sentence Classification</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS1.p1.3">TC 및 RE와 같은 단일 문장 분류 태스크에서, 분류기는 단일 문장을 미리 정의된 라벨들의 집합으로 분류한다. 관례에 따라 <span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS1.p1.3.1">[CLS]</span> token <math alttext="h_{0}" class="ltx_Math" display="inline" id="S5.SS1.SSS1.p1.1.m1.1"><semantics id="S5.SS1.SSS1.p1.1.m1.1a"><msub id="S5.SS1.SSS1.p1.1.m1.1.1" xref="S5.SS1.SSS1.p1.1.m1.1.1.cmml"><mi id="S5.SS1.SSS1.p1.1.m1.1.1.2" xref="S5.SS1.SSS1.p1.1.m1.1.1.2.cmml">h</mi><mn id="S5.SS1.SSS1.p1.1.m1.1.1.3" xref="S5.SS1.SSS1.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p1.1.m1.1b"><apply id="S5.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S5.SS1.SSS1.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="S5.SS1.SSS1.p1.1.m1.1.1.2">ℎ</ci><cn id="S5.SS1.SSS1.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.SSS1.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p1.1.m1.1c">h_{0}</annotation></semantics></math>는 <math alttext="W\in\mathbb{R}^{K\times H}" class="ltx_Math" display="inline" id="S5.SS1.SSS1.p1.3.m3.1"><semantics id="S5.SS1.SSS1.p1.3.m3.1a"><mrow id="S5.SS1.SSS1.p1.3.m3.1.1" xref="S5.SS1.SSS1.p1.3.m3.1.1.cmml"><mi id="S5.SS1.SSS1.p1.3.m3.1.1.2" xref="S5.SS1.SSS1.p1.3.m3.1.1.2.cmml">W</mi><mo id="S5.SS1.SSS1.p1.3.m3.1.1.1" xref="S5.SS1.SSS1.p1.3.m3.1.1.1.cmml">∈</mo><msup id="S5.SS1.SSS1.p1.3.m3.1.1.3" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.cmml"><mi id="S5.SS1.SSS1.p1.3.m3.1.1.3.2" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.2.cmml">ℝ</mi><mrow id="S5.SS1.SSS1.p1.3.m3.1.1.3.3" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3.cmml"><mi id="S5.SS1.SSS1.p1.3.m3.1.1.3.3.2" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3.2.cmml">K</mi><mo id="S5.SS1.SSS1.p1.3.m3.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3.1.cmml">×</mo><mi id="S5.SS1.SSS1.p1.3.m3.1.1.3.3.3" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3.3.cmml">H</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p1.3.m3.1b"><apply id="S5.SS1.SSS1.p1.3.m3.1.1.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1"><in id="S5.SS1.SSS1.p1.3.m3.1.1.1.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.1"></in><ci id="S5.SS1.SSS1.p1.3.m3.1.1.2.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.2">𝑊</ci><apply id="S5.SS1.SSS1.p1.3.m3.1.1.3.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S5.SS1.SSS1.p1.3.m3.1.1.3.1.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.3">superscript</csymbol><ci id="S5.SS1.SSS1.p1.3.m3.1.1.3.2.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.2">ℝ</ci><apply id="S5.SS1.SSS1.p1.3.m3.1.1.3.3.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3"><times id="S5.SS1.SSS1.p1.3.m3.1.1.3.3.1.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3.1"></times><ci id="S5.SS1.SSS1.p1.3.m3.1.1.3.3.2.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3.2">𝐾</ci><ci id="S5.SS1.SSS1.p1.3.m3.1.1.3.3.3.cmml" xref="S5.SS1.SSS1.p1.3.m3.1.1.3.3.3">𝐻</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p1.3.m3.1c">W\in\mathbb{R}^{K\times H}</annotation></semantics></math>로 레이블 수(<math alttext="K" class="ltx_Math" display="inline" id="S5.SS1.SSS1.p1.2.m2.1"><semantics id="S5.SS1.SSS1.p1.2.m2.1a"><mi id="S5.SS1.SSS1.p1.2.m2.1.1" xref="S5.SS1.SSS1.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p1.2.m2.1b"><ci id="S5.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S5.SS1.SSS1.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p1.2.m2.1c">K</annotation></semantics></math>)에 선형 매핑되고 전체 모델은 교차 엔트로피 손실을 최소화하도록 훈련된다.</p>
</div>
<div id="S5.SS1.SSS1.p2" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS1.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS1.p2.1.1">YNAT</span>은 미리 정의된 토픽 레이블에 대해 <math alttext="K" class="ltx_Math" display="inline" id="S5.SS1.SSS1.p2.1.m1.1"><semantics id="S5.SS1.SSS1.p2.1.m1.1a"><mi id="S5.SS1.SSS1.p2.1.m1.1.1" xref="S5.SS1.SSS1.p2.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS1.p2.1.m1.1b"><ci id="S5.SS1.SSS1.p2.1.m1.1.1.cmml" xref="S5.SS1.SSS1.p2.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS1.p2.1.m1.1c">K</annotation></semantics></math>가 7인 단일 문장 분류 작업이며, 각 입력의 특별한 처리를 필요로 하지 않는다. 한편 <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS1.p2.1.2">KLUE-RE</span>은 입력 문장 내의 엔터티를 나타내기 위한 특별한 절차를 필요로 한다. <span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS1.p2.1.3">&lt;subj&gt;</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS1.p2.1.4">&lt;/subj&gt;</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS1.p2.1.5">&lt;obj&gt;</span>, <span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS1.p2.1.6">&lt;/obj&gt;</span>을 사용하여 제목 및 개체 개체의 시작과 끝을 각각 표시합니다. 우리는 이 네 개의 여분의 토큰을 추가하기 위해 임베딩 행렬을 확장한다.</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>Sentence Pair Classification / Regression</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS2.p1.1">문장 쌍 분류/회귀 태스크에서, 두 문장 사이의 관계를 결정하기 위해 모델이 요청된다. 한 쌍의 입력 문장은 특수 구분자 토큰, 종종 <span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS2.p1.1.1">[SEP]</span>과 연결됩니다.</p>
</div>
<div id="S5.SS1.SSS2.p2" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS2.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p2.1.1">KLUE-STS</span>에서는 각 문장 쌍에 실수 유사도 <math alttext="[0,5]" class="ltx_Math" display="inline" id="S5.SS1.SSS2.p2.1.m1.2"><semantics id="S5.SS1.SSS2.p2.1.m1.2a"><mrow id="S5.SS1.SSS2.p2.1.m1.2.3.2" xref="S5.SS1.SSS2.p2.1.m1.2.3.1.cmml"><mo id="S5.SS1.SSS2.p2.1.m1.2.3.2.1" stretchy="false" xref="S5.SS1.SSS2.p2.1.m1.2.3.1.cmml">[</mo><mn id="S5.SS1.SSS2.p2.1.m1.1.1" xref="S5.SS1.SSS2.p2.1.m1.1.1.cmml">0</mn><mo id="S5.SS1.SSS2.p2.1.m1.2.3.2.2" xref="S5.SS1.SSS2.p2.1.m1.2.3.1.cmml">,</mo><mn id="S5.SS1.SSS2.p2.1.m1.2.2" xref="S5.SS1.SSS2.p2.1.m1.2.2.cmml">5</mn><mo id="S5.SS1.SSS2.p2.1.m1.2.3.2.3" stretchy="false" xref="S5.SS1.SSS2.p2.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS2.p2.1.m1.2b"><interval closure="closed" id="S5.SS1.SSS2.p2.1.m1.2.3.1.cmml" xref="S5.SS1.SSS2.p2.1.m1.2.3.2"><cn id="S5.SS1.SSS2.p2.1.m1.1.1.cmml" type="integer" xref="S5.SS1.SSS2.p2.1.m1.1.1">0</cn><cn id="S5.SS1.SSS2.p2.1.m1.2.2.cmml" type="integer" xref="S5.SS1.SSS2.p2.1.m1.2.2">5</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS2.p2.1.m1.2c">[0,5]</annotation></semantics></math>로 주석을 달았다. 따라서 모델은 평균 제곱 오차(MSE)를 최소화함으로써 <span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS2.p2.1.2">[CLS]</span>의 최종 숨겨진 상태로부터 실수로 매핑되도록 훈련된다. <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS2.p2.1.3">KLUE-NLI</span>의 경우, 전제 및 가설로 구성된 각 문장 쌍은 세 클래스 중 하나와 결합된다. 따라서 모델은 <span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS2.p2.1.4">[CLS]</span> 토큰의 숨겨진 상태를 3차원 실수 벡터로 매핑하고 교차 엔트로피 손실을 최소화하도록 훈련된다.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.3 </span>Multiple-Sentence Slot-Value Prediction</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS3.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS3.p1.1.1">WoS</span>은 주어진 대화 컨텍스트에 대한 슬롯-값 예측 태스크이며, 여기서 예측은 단일 발언 대신에 다수의 턴들에 걸쳐 고려되어야 한다. 발화 인코더, 상태 생성기, 슬롯 게이트 분류기로 구성된 TRADE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib140" title="">140</a>]</cite>의 아키텍처에 따라 인코더-디코더 모델을 사용한다(그림<a class="ltx_ref" href="#S5.F8" title="Figure 8 ‣ 5.1.3 Multiple-Sentence Slot-Value Prediction ‣ 5.1 Task-Specific Architectures ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">8</span></a>). 구현에서 더 나은 표현을 얻기 위해 GRU <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib17" title="">17</a>]</cite>에서 PLM으로 발화 인코더를 변경한다. 따라서 상태 생성기는 첫 번째 디코더 숨김 상태로 <span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS3.p1.1.2">[CLS]</span> token <math alttext="h_{0}" class="ltx_Math" display="inline" id="S5.SS1.SSS3.p1.1.m1.1"><semantics id="S5.SS1.SSS3.p1.1.m1.1a"><msub id="S5.SS1.SSS3.p1.1.m1.1.1" xref="S5.SS1.SSS3.p1.1.m1.1.1.cmml"><mi id="S5.SS1.SSS3.p1.1.m1.1.1.2" xref="S5.SS1.SSS3.p1.1.m1.1.1.2.cmml">h</mi><mn id="S5.SS1.SSS3.p1.1.m1.1.1.3" xref="S5.SS1.SSS3.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS3.p1.1.m1.1b"><apply id="S5.SS1.SSS3.p1.1.m1.1.1.cmml" xref="S5.SS1.SSS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS1.SSS3.p1.1.m1.1.1.1.cmml" xref="S5.SS1.SSS3.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS1.SSS3.p1.1.m1.1.1.2.cmml" xref="S5.SS1.SSS3.p1.1.m1.1.1.2">ℎ</ci><cn id="S5.SS1.SSS3.p1.1.m1.1.1.3.cmml" type="integer" xref="S5.SS1.SSS3.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS3.p1.1.m1.1c">h_{0}</annotation></semantics></math>의 최종 숨김 상태를 취한다. 또한 슬롯 게이트 분류기를 수정하여 두 개의 슬롯 게이트 레이블을 추가로 예측한다(<span class="ltx_text ltx_font_italic" id="S5.SS1.SSS3.p1.1.3">yes</span>, <span class="ltx_text ltx_font_italic" id="S5.SS1.SSS3.p1.1.4">no</span>). WoS는 MultiWOZ <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib10" title="">10</a>]</cite>보다 상대적으로 더 많은 부울 타입 슬롯을 포함하기 때문이다. 상태 생성기와 슬롯 게이트 분류기의 교차 엔트로피 손실을 공동으로 최소화한다.</p>
</div>
<figure id="S5.F8" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2105.09680/assets/figs/wos_model_arch.png" id="S5.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="538" height="275" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 8:</span>A baseline architecture for WoS based on TRADE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib140" title="">140</a>]</cite>.</figcaption>
</figure>
</section>
<section id="S5.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">5.1.4 </span>Sequence Tagging</h4>

<figure id="S5.F9" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2105.09680/assets/figs/ner_input_example.png" id="S5.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="568" height="62" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9:</span>KLUE-NER의 입력 및 레이블 예. 형태소 기반 하위 단어 토큰화의 토큰에 대해 그림 <a class="ltx_ref" href="#S3.F3" title="Figure 3 ‣ Final Dataset ‣ 3.4.1 Dataset Construction ‣ 3.4 Named Entity Recognition (NER) ‣ 3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a>의 원래 문자 수준 레이블 시퀀스를 다시 정렬합니다.</figcaption>
</figure>
<div id="S5.SS1.SSS4.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p1.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS4.p1.1.1">KLUE-NER</span>은 토큰 수준 태깅 작업이며, 여기서 각 문자에는 레이블이 할당된다. 이것은 각 서브워드 토큰 내의 문자들로부터의 라벨들이 집계되어야 하고, 각 서브워드 토큰의 예측된 라벨이 그 내의 문자들에 걸쳐 적절하게 분배되어야 하기 때문에, 토큰화를 사용하는 데 주의가 필요하다. 예를 들어 <a class="ltx_ref" href="#S5.F9" title="Figure 9 ‣ 5.1.4 Sequence Tagging ‣ 5.1 Task-Specific Architectures ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">9</span></a>를 참조한다. 인코더 <math alttext="h\in\mathbb{R}^{|x|\times H}" class="ltx_Math" display="inline" id="S5.SS1.SSS4.p1.1.m1.1"><semantics id="S5.SS1.SSS4.p1.1.m1.1a"><mrow id="S5.SS1.SSS4.p1.1.m1.1.2" xref="S5.SS1.SSS4.p1.1.m1.1.2.cmml"><mi id="S5.SS1.SSS4.p1.1.m1.1.2.2" xref="S5.SS1.SSS4.p1.1.m1.1.2.2.cmml">h</mi><mo id="S5.SS1.SSS4.p1.1.m1.1.2.1" xref="S5.SS1.SSS4.p1.1.m1.1.2.1.cmml">∈</mo><msup id="S5.SS1.SSS4.p1.1.m1.1.2.3" xref="S5.SS1.SSS4.p1.1.m1.1.2.3.cmml"><mi id="S5.SS1.SSS4.p1.1.m1.1.2.3.2" xref="S5.SS1.SSS4.p1.1.m1.1.2.3.2.cmml">ℝ</mi><mrow id="S5.SS1.SSS4.p1.1.m1.1.1.1" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.cmml"><mrow id="S5.SS1.SSS4.p1.1.m1.1.1.1.3.2" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.3.1.cmml"><mo id="S5.SS1.SSS4.p1.1.m1.1.1.1.3.2.1" stretchy="false" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.3.1.1.cmml">|</mo><mi id="S5.SS1.SSS4.p1.1.m1.1.1.1.1" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.1.cmml">x</mi><mo id="S5.SS1.SSS4.p1.1.m1.1.1.1.3.2.2" rspace="0.055em" stretchy="false" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.3.1.1.cmml">|</mo></mrow><mo id="S5.SS1.SSS4.p1.1.m1.1.1.1.2" rspace="0.222em" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.2.cmml">×</mo><mi id="S5.SS1.SSS4.p1.1.m1.1.1.1.4" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.4.cmml">H</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.SSS4.p1.1.m1.1b"><apply id="S5.SS1.SSS4.p1.1.m1.1.2.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2"><in id="S5.SS1.SSS4.p1.1.m1.1.2.1.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2.1"></in><ci id="S5.SS1.SSS4.p1.1.m1.1.2.2.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2.2">ℎ</ci><apply id="S5.SS1.SSS4.p1.1.m1.1.2.3.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2.3"><csymbol cd="ambiguous" id="S5.SS1.SSS4.p1.1.m1.1.2.3.1.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2.3">superscript</csymbol><ci id="S5.SS1.SSS4.p1.1.m1.1.2.3.2.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.2.3.2">ℝ</ci><apply id="S5.SS1.SSS4.p1.1.m1.1.1.1.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.1.1"><times id="S5.SS1.SSS4.p1.1.m1.1.1.1.2.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.2"></times><apply id="S5.SS1.SSS4.p1.1.m1.1.1.1.3.1.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.3.2"><abs id="S5.SS1.SSS4.p1.1.m1.1.1.1.3.1.1.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.3.2.1"></abs><ci id="S5.SS1.SSS4.p1.1.m1.1.1.1.1.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.1">𝑥</ci></apply><ci id="S5.SS1.SSS4.p1.1.m1.1.1.1.4.cmml" xref="S5.SS1.SSS4.p1.1.m1.1.1.1.4">𝐻</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.SSS4.p1.1.m1.1c">h\in\mathbb{R}^{|x|\times H}</annotation></semantics></math>로부터의 최종 은닉 상태들 각각을 12개의 명명된 엔티티 카테고리들에 대응하는 12차원 실수값 벡터들로 선형 맵핑한다. 그런 다음 모든 토큰에 대해 합산된 교차 엔트로피 손실을 최소화합니다.</p>
</div>
<div id="S5.SS1.SSS4.p2" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p2.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.SSS4.p2.1.1">KLUE-MRC</span>은 모델이 질문이 주어진 한 통로 내에서 답변 스팬의 시작 및 끝 토큰에 태그를 지정하는 스팬 예측 작업입니다. 모델에 대한 입력은 토큰화된 통로와 연관된 질문(<span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS4.p2.1.2">[SEP]</span>로 구분됨)의 연결입니다. 통로의 각 토큰의 최종 은닉 상태는 2차원 실수값 벡터에 선형으로 투영된다. 이 벡터의 차원은 두 개의 이진 분류기, 즉 시작 및 종료 토큰 분류기의 로짓에 해당한다. 특수 토큰 <span class="ltx_text ltx_font_typewriter" id="S5.SS1.SSS4.p2.1.3">[CLS]</span>은 주어진 질문이 응답할 수 없는 경우 올바른 시작 토큰과 끝 토큰 모두로 간주됩니다. 우리는 모델을 훈련시키기 위해 교차 엔트로피 손실을 최소화한다.</p>
</div>
<div id="S5.SS1.SSS4.p3" class="ltx_para">
<p class="ltx_p" id="S5.SS1.SSS4.p3.1">우리는 시퀀스 태깅 문제로서 <span class="ltx_text ltx_font_bold" id="S5.SS1.SSS4.p3.1.1">KLUE-DP</span>을 프레임화한다. 입력 문장 내의 각각의 토큰은 두 번 태깅되는데, 하나는 그의 헤드 토큰으로, 다른 하나는 헤드와 현재 토큰을 연결하는 호 유형으로 태깅된다. 우리의 기본 아키텍처는 단어 표현 및 주의 메커니즘을 제외하고 <cite class="ltx_cite ltx_citemacro_citet">Fernández-González and Gómez-Rodríguez [<a class="ltx_ref" href="#bib.bib39" title="">39</a>]</cite>에서 제안한 모델을 따른다. KLUE-NER과 마찬가지로 주석은 단어 수준에서 수행되므로 하위 단어 토큰을 처리하는 데 주의해야 한다. 본 논문에서는 사전 학습된 언어 모델을 이용하여 하위 단어 표현을 추출하고, 각 단어의 첫 번째와 마지막 하위 단어 토큰 표현을 연결하여 단어 벡터 표현을 구성한다. 이들 단어 표현들 각각은 선택적으로 품사 임베딩과 연결된다. 어텐션 레이어의 경우, HEAD를 예측하기 위해 biaffine 어텐션 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib33" title="">33</a>]</cite>를 사용하고, 각 단어에 대한 arc type(DEPREL)을 예측하기 위해 bilinear 어텐션 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib64" title="">64</a>]</cite>를 사용한다. KLUE-NER 및 KLUE-MRC와 마찬가지로 전체 모델을 미세 조정하기 위해 교차 엔트로피 손실을 최소화한다. 모델 아키텍처의 그래픽 예시는 그림 <a class="ltx_ref" href="#S5.F10" title="Figure 10 ‣ 5.1.4 Sequence Tagging ‣ 5.1 Task-Specific Architectures ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">10</span></a>를 참조한다.</p>
</div>
<figure id="S5.F10" class="ltx_figure"><img src="https://ar5iv.labs.arxiv.org/html/2105.09680/assets/figs/dp_model_fig1.png" id="S5.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="306" height="195" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">그림 10:</span>An overview of KLUE-DP baseline model architecture, we take the <cite class="ltx_cite ltx_citemacro_citet">Fernández-González and</cite></figcaption>
Gómez-Rodríguez [<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>.</figcaption>
</figure>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Fine-Tuning Configurations</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.5" class="ltx_p">For all the experiments, we use <span id="S5.SS2.p1.5.1" class="ltx_text ltx_font_typewriter">Huggingface Transformers</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib139" title="" class="ltx_ref">139</a>]</cite> and <span id="S5.SS2.p1.5.2" class="ltx_text ltx_font_typewriter">PyTorch-Lightning</span>.<span id="footnote62" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">62</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">62</sup><span class="ltx_tag ltx_tag_note">62</span> <a target="_blank" href="https://github.com/PyTorchLightning/pytorch-lightning" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/PyTorchLightning/pytorch-lightning</a> </span></span></span> We use AdamW optimizer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite> with the learning rate selected from <math id="S5.SS2.p1.1.m1.4" class="ltx_Math" alttext="\{10^{-5},2\times 10^{-5},3\times 10^{-5},5\times 10^{-5}\}" display="inline"><semantics id="S5.SS2.p1.1.m1.4a"><mrow id="S5.SS2.p1.1.m1.4.4.4" xref="S5.SS2.p1.1.m1.4.4.5.cmml"><mo stretchy="false" id="S5.SS2.p1.1.m1.4.4.4.5" xref="S5.SS2.p1.1.m1.4.4.5.cmml">{</mo><msup id="S5.SS2.p1.1.m1.1.1.1.1" xref="S5.SS2.p1.1.m1.1.1.1.1.cmml"><mn id="S5.SS2.p1.1.m1.1.1.1.1.2" xref="S5.SS2.p1.1.m1.1.1.1.1.2.cmml">10</mn><mrow id="S5.SS2.p1.1.m1.1.1.1.1.3" xref="S5.SS2.p1.1.m1.1.1.1.1.3.cmml"><mo id="S5.SS2.p1.1.m1.1.1.1.1.3a" xref="S5.SS2.p1.1.m1.1.1.1.1.3.cmml">−</mo><mn id="S5.SS2.p1.1.m1.1.1.1.1.3.2" xref="S5.SS2.p1.1.m1.1.1.1.1.3.2.cmml">5</mn></mrow></msup><mo id="S5.SS2.p1.1.m1.4.4.4.6" xref="S5.SS2.p1.1.m1.4.4.5.cmml">,</mo><mrow id="S5.SS2.p1.1.m1.2.2.2.2" xref="S5.SS2.p1.1.m1.2.2.2.2.cmml"><mn id="S5.SS2.p1.1.m1.2.2.2.2.2" xref="S5.SS2.p1.1.m1.2.2.2.2.2.cmml">2</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.1.m1.2.2.2.2.1" xref="S5.SS2.p1.1.m1.2.2.2.2.1.cmml">×</mo><msup id="S5.SS2.p1.1.m1.2.2.2.2.3" xref="S5.SS2.p1.1.m1.2.2.2.2.3.cmml"><mn id="S5.SS2.p1.1.m1.2.2.2.2.3.2" xref="S5.SS2.p1.1.m1.2.2.2.2.3.2.cmml">10</mn><mrow id="S5.SS2.p1.1.m1.2.2.2.2.3.3" xref="S5.SS2.p1.1.m1.2.2.2.2.3.3.cmml"><mo id="S5.SS2.p1.1.m1.2.2.2.2.3.3a" xref="S5.SS2.p1.1.m1.2.2.2.2.3.3.cmml">−</mo><mn id="S5.SS2.p1.1.m1.2.2.2.2.3.3.2" xref="S5.SS2.p1.1.m1.2.2.2.2.3.3.2.cmml">5</mn></mrow></msup></mrow><mo id="S5.SS2.p1.1.m1.4.4.4.7" xref="S5.SS2.p1.1.m1.4.4.5.cmml">,</mo><mrow id="S5.SS2.p1.1.m1.3.3.3.3" xref="S5.SS2.p1.1.m1.3.3.3.3.cmml"><mn id="S5.SS2.p1.1.m1.3.3.3.3.2" xref="S5.SS2.p1.1.m1.3.3.3.3.2.cmml">3</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.1.m1.3.3.3.3.1" xref="S5.SS2.p1.1.m1.3.3.3.3.1.cmml">×</mo><msup id="S5.SS2.p1.1.m1.3.3.3.3.3" xref="S5.SS2.p1.1.m1.3.3.3.3.3.cmml"><mn id="S5.SS2.p1.1.m1.3.3.3.3.3.2" xref="S5.SS2.p1.1.m1.3.3.3.3.3.2.cmml">10</mn><mrow id="S5.SS2.p1.1.m1.3.3.3.3.3.3" xref="S5.SS2.p1.1.m1.3.3.3.3.3.3.cmml"><mo id="S5.SS2.p1.1.m1.3.3.3.3.3.3a" xref="S5.SS2.p1.1.m1.3.3.3.3.3.3.cmml">−</mo><mn id="S5.SS2.p1.1.m1.3.3.3.3.3.3.2" xref="S5.SS2.p1.1.m1.3.3.3.3.3.3.2.cmml">5</mn></mrow></msup></mrow><mo id="S5.SS2.p1.1.m1.4.4.4.8" xref="S5.SS2.p1.1.m1.4.4.5.cmml">,</mo><mrow id="S5.SS2.p1.1.m1.4.4.4.4" xref="S5.SS2.p1.1.m1.4.4.4.4.cmml"><mn id="S5.SS2.p1.1.m1.4.4.4.4.2" xref="S5.SS2.p1.1.m1.4.4.4.4.2.cmml">5</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS2.p1.1.m1.4.4.4.4.1" xref="S5.SS2.p1.1.m1.4.4.4.4.1.cmml">×</mo><msup id="S5.SS2.p1.1.m1.4.4.4.4.3" xref="S5.SS2.p1.1.m1.4.4.4.4.3.cmml"><mn id="S5.SS2.p1.1.m1.4.4.4.4.3.2" xref="S5.SS2.p1.1.m1.4.4.4.4.3.2.cmml">10</mn><mrow id="S5.SS2.p1.1.m1.4.4.4.4.3.3" xref="S5.SS2.p1.1.m1.4.4.4.4.3.3.cmml"><mo id="S5.SS2.p1.1.m1.4.4.4.4.3.3a" xref="S5.SS2.p1.1.m1.4.4.4.4.3.3.cmml">−</mo><mn id="S5.SS2.p1.1.m1.4.4.4.4.3.3.2" xref="S5.SS2.p1.1.m1.4.4.4.4.3.3.2.cmml">5</mn></mrow></msup></mrow><mo stretchy="false" id="S5.SS2.p1.1.m1.4.4.4.9" xref="S5.SS2.p1.1.m1.4.4.5.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.1.m1.4b"><set id="S5.SS2.p1.1.m1.4.4.5.cmml" xref="S5.SS2.p1.1.m1.4.4.4"><apply id="S5.SS2.p1.1.m1.1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1">superscript</csymbol><cn type="integer" id="S5.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.2">10</cn><apply id="S5.SS2.p1.1.m1.1.1.1.1.3.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.3"><minus id="S5.SS2.p1.1.m1.1.1.1.1.3.1.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.3"></minus><cn type="integer" id="S5.SS2.p1.1.m1.1.1.1.1.3.2.cmml" xref="S5.SS2.p1.1.m1.1.1.1.1.3.2">5</cn></apply></apply><apply id="S5.SS2.p1.1.m1.2.2.2.2.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2"><times id="S5.SS2.p1.1.m1.2.2.2.2.1.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.1"></times><cn type="integer" id="S5.SS2.p1.1.m1.2.2.2.2.2.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.2">2</cn><apply id="S5.SS2.p1.1.m1.2.2.2.2.3.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.3"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.2.2.2.2.3.1.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.3">superscript</csymbol><cn type="integer" id="S5.SS2.p1.1.m1.2.2.2.2.3.2.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.3.2">10</cn><apply id="S5.SS2.p1.1.m1.2.2.2.2.3.3.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.3.3"><minus id="S5.SS2.p1.1.m1.2.2.2.2.3.3.1.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.3.3"></minus><cn type="integer" id="S5.SS2.p1.1.m1.2.2.2.2.3.3.2.cmml" xref="S5.SS2.p1.1.m1.2.2.2.2.3.3.2">5</cn></apply></apply></apply><apply id="S5.SS2.p1.1.m1.3.3.3.3.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3"><times id="S5.SS2.p1.1.m1.3.3.3.3.1.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.1"></times><cn type="integer" id="S5.SS2.p1.1.m1.3.3.3.3.2.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.2">3</cn><apply id="S5.SS2.p1.1.m1.3.3.3.3.3.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.3.3.3.3.3.1.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.3">superscript</csymbol><cn type="integer" id="S5.SS2.p1.1.m1.3.3.3.3.3.2.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.3.2">10</cn><apply id="S5.SS2.p1.1.m1.3.3.3.3.3.3.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.3.3"><minus id="S5.SS2.p1.1.m1.3.3.3.3.3.3.1.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.3.3"></minus><cn type="integer" id="S5.SS2.p1.1.m1.3.3.3.3.3.3.2.cmml" xref="S5.SS2.p1.1.m1.3.3.3.3.3.3.2">5</cn></apply></apply></apply><apply id="S5.SS2.p1.1.m1.4.4.4.4.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4"><times id="S5.SS2.p1.1.m1.4.4.4.4.1.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.1"></times><cn type="integer" id="S5.SS2.p1.1.m1.4.4.4.4.2.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.2">5</cn><apply id="S5.SS2.p1.1.m1.4.4.4.4.3.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.3"><csymbol cd="ambiguous" id="S5.SS2.p1.1.m1.4.4.4.4.3.1.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.3">superscript</csymbol><cn type="integer" id="S5.SS2.p1.1.m1.4.4.4.4.3.2.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.3.2">10</cn><apply id="S5.SS2.p1.1.m1.4.4.4.4.3.3.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.3.3"><minus id="S5.SS2.p1.1.m1.4.4.4.4.3.3.1.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.3.3"></minus><cn type="integer" id="S5.SS2.p1.1.m1.4.4.4.4.3.3.2.cmml" xref="S5.SS2.p1.1.m1.4.4.4.4.3.3.2">5</cn></apply></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.1.m1.4c">\{10^{-5},2\times 10^{-5},3\times 10^{-5},5\times 10^{-5}\}</annotation></semantics></math>, the warm-up ratio from <math id="S5.SS2.p1.2.m2.1" class="ltx_math_unparsed" alttext="\{0.,0.1,0.2,0.6\}" display="inline"><semantics id="S5.SS2.p1.2.m2.1a"><mrow id="S5.SS2.p1.2.m2.1b"><mo stretchy="false" id="S5.SS2.p1.2.m2.1.1">{</mo><mn id="S5.SS2.p1.2.m2.1.2">0</mn><mo lspace="0em" rspace="0.167em" id="S5.SS2.p1.2.m2.1.3">.</mo><mo id="S5.SS2.p1.2.m2.1.4">,</mo><mn id="S5.SS2.p1.2.m2.1.5">0.1</mn><mo id="S5.SS2.p1.2.m2.1.6">,</mo><mn id="S5.SS2.p1.2.m2.1.7">0.2</mn><mo id="S5.SS2.p1.2.m2.1.8">,</mo><mn id="S5.SS2.p1.2.m2.1.9">0.6</mn><mo stretchy="false" id="S5.SS2.p1.2.m2.1.10">}</mo></mrow><annotation encoding="application/x-tex" id="S5.SS2.p1.2.m2.1c">\{0.,0.1,0.2,0.6\}</annotation></semantics></math> and the weight decay coefficient from <math id="S5.SS2.p1.3.m3.2" class="ltx_Math" alttext="\{0.0,0.01\}" display="inline"><semantics id="S5.SS2.p1.3.m3.2a"><mrow id="S5.SS2.p1.3.m3.2.3.2" xref="S5.SS2.p1.3.m3.2.3.1.cmml"><mo stretchy="false" id="S5.SS2.p1.3.m3.2.3.2.1" xref="S5.SS2.p1.3.m3.2.3.1.cmml">{</mo><mn id="S5.SS2.p1.3.m3.1.1" xref="S5.SS2.p1.3.m3.1.1.cmml">0.0</mn><mo id="S5.SS2.p1.3.m3.2.3.2.2" xref="S5.SS2.p1.3.m3.2.3.1.cmml">,</mo><mn id="S5.SS2.p1.3.m3.2.2" xref="S5.SS2.p1.3.m3.2.2.cmml">0.01</mn><mo stretchy="false" id="S5.SS2.p1.3.m3.2.3.2.3" xref="S5.SS2.p1.3.m3.2.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.3.m3.2b"><set id="S5.SS2.p1.3.m3.2.3.1.cmml" xref="S5.SS2.p1.3.m3.2.3.2"><cn type="float" id="S5.SS2.p1.3.m3.1.1.cmml" xref="S5.SS2.p1.3.m3.1.1">0.0</cn><cn type="float" id="S5.SS2.p1.3.m3.2.2.cmml" xref="S5.SS2.p1.3.m3.2.2">0.01</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.3.m3.2c">\{0.0,0.01\}</annotation></semantics></math>. We choose the batch size from <math id="S5.SS2.p1.4.m4.3" class="ltx_Math" alttext="\{8,16,32\}" display="inline"><semantics id="S5.SS2.p1.4.m4.3a"><mrow id="S5.SS2.p1.4.m4.3.4.2" xref="S5.SS2.p1.4.m4.3.4.1.cmml"><mo stretchy="false" id="S5.SS2.p1.4.m4.3.4.2.1" xref="S5.SS2.p1.4.m4.3.4.1.cmml">{</mo><mn id="S5.SS2.p1.4.m4.1.1" xref="S5.SS2.p1.4.m4.1.1.cmml">8</mn><mo id="S5.SS2.p1.4.m4.3.4.2.2" xref="S5.SS2.p1.4.m4.3.4.1.cmml">,</mo><mn id="S5.SS2.p1.4.m4.2.2" xref="S5.SS2.p1.4.m4.2.2.cmml">16</mn><mo id="S5.SS2.p1.4.m4.3.4.2.3" xref="S5.SS2.p1.4.m4.3.4.1.cmml">,</mo><mn id="S5.SS2.p1.4.m4.3.3" xref="S5.SS2.p1.4.m4.3.3.cmml">32</mn><mo stretchy="false" id="S5.SS2.p1.4.m4.3.4.2.4" xref="S5.SS2.p1.4.m4.3.4.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.4.m4.3b"><set id="S5.SS2.p1.4.m4.3.4.1.cmml" xref="S5.SS2.p1.4.m4.3.4.2"><cn type="integer" id="S5.SS2.p1.4.m4.1.1.cmml" xref="S5.SS2.p1.4.m4.1.1">8</cn><cn type="integer" id="S5.SS2.p1.4.m4.2.2.cmml" xref="S5.SS2.p1.4.m4.2.2">16</cn><cn type="integer" id="S5.SS2.p1.4.m4.3.3.cmml" xref="S5.SS2.p1.4.m4.3.3">32</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.4.m4.3c">\{8,16,32\}</annotation></semantics></math> and the number of epochs from <math id="S5.SS2.p1.5.m5.4" class="ltx_Math" alttext="\{3,4,5,10\}" display="inline"><semantics id="S5.SS2.p1.5.m5.4a"><mrow id="S5.SS2.p1.5.m5.4.5.2" xref="S5.SS2.p1.5.m5.4.5.1.cmml"><mo stretchy="false" id="S5.SS2.p1.5.m5.4.5.2.1" xref="S5.SS2.p1.5.m5.4.5.1.cmml">{</mo><mn id="S5.SS2.p1.5.m5.1.1" xref="S5.SS2.p1.5.m5.1.1.cmml">3</mn><mo id="S5.SS2.p1.5.m5.4.5.2.2" xref="S5.SS2.p1.5.m5.4.5.1.cmml">,</mo><mn id="S5.SS2.p1.5.m5.2.2" xref="S5.SS2.p1.5.m5.2.2.cmml">4</mn><mo id="S5.SS2.p1.5.m5.4.5.2.3" xref="S5.SS2.p1.5.m5.4.5.1.cmml">,</mo><mn id="S5.SS2.p1.5.m5.3.3" xref="S5.SS2.p1.5.m5.3.3.cmml">5</mn><mo id="S5.SS2.p1.5.m5.4.5.2.4" xref="S5.SS2.p1.5.m5.4.5.1.cmml">,</mo><mn id="S5.SS2.p1.5.m5.4.4" xref="S5.SS2.p1.5.m5.4.4.cmml">10</mn><mo stretchy="false" id="S5.SS2.p1.5.m5.4.5.2.5" xref="S5.SS2.p1.5.m5.4.5.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p1.5.m5.4b"><set id="S5.SS2.p1.5.m5.4.5.1.cmml" xref="S5.SS2.p1.5.m5.4.5.2"><cn type="integer" id="S5.SS2.p1.5.m5.1.1.cmml" xref="S5.SS2.p1.5.m5.1.1">3</cn><cn type="integer" id="S5.SS2.p1.5.m5.2.2.cmml" xref="S5.SS2.p1.5.m5.2.2">4</cn><cn type="integer" id="S5.SS2.p1.5.m5.3.3.cmml" xref="S5.SS2.p1.5.m5.3.3">5</cn><cn type="integer" id="S5.SS2.p1.5.m5.4.4.cmml" xref="S5.SS2.p1.5.m5.4.4">10</cn></set></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p1.5.m5.4c">\{3,4,5,10\}</annotation></semantics></math>. We use the maximum sequence length of 512 for KLUE-MRC and WoS, and 128 for all the other tasks. We report the score obtained from the best hyperparameter configuration based on the dev set performance.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Evaluation Results</h3>

<figure id="S5.T32" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 32:</span>KLUE 벤치마크 상의 사전 트레이닝된 LMs 및 기타 기준선의 평가 결과. F1은 매크로-F1 점수를 의미한다. F1<sup class="ltx_sup" id="S5.T32.34.1"><span class="ltx_text ltx_font_italic" id="S5.T32.34.1.1">E</span></sup> 및 F1<sup class="ltx_sup" id="S5.T32.35.2"><span class="ltx_text ltx_font_italic" id="S5.T32.35.2.1">C</span></sup>는 각각 엔터티 수준 및 문자 수준 매크로-F1 점수를 나타냅니다. F1<sup class="ltx_sup" id="S5.T32.36.3"><span class="ltx_text ltx_font_italic" id="S5.T32.36.3.1">mic</span></sup> of KLUE-RE is micro-averaged F1 score ignoring the <span class="ltx_text ltx_font_italic" id="S5.T32.37.4">no_relation</span>. WoS의 F1<sup class="ltx_sup" id="S5.T32.38.5"><span class="ltx_text ltx_font_italic" id="S5.T32.38.5.1">S</span></sup>는 슬롯-값 쌍 레벨 micro-F1 점수의 평균이다. KLUE-STS의 R<sup class="ltx_sup" id="S5.T32.39.6"><span class="ltx_text ltx_font_italic" id="S5.T32.39.6.1">P</span></sup>은 피어슨 상관 관계를 나타냅니다. <span class="ltx_text ltx_font_bold" id="S5.T32.40.7">Bold</span>은 모델 전체에서 가장 좋은 성능을 나타내며, <span class="ltx_text ltx_framed ltx_framed_underline" id="S5.T32.41.8">underline</span>은 <span class="ltx_text ltx_font_typewriter" id="S5.T32.42.9">BASE</span> 모델 중에서 가장 좋은 성능을 나타낸다.</figcaption>
<div id="S5.T32.24" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:641.2pt;height:199pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T32.24.14" class="ltx_p"><span id="S5.T32.24.14.14" class="ltx_text"> <span id="S5.T32.24.14.14.14" class="ltx_tabular ltx_align_middle"> <span id="S5.T32.24.14.14.14.15" class="ltx_tr"> <span id="S5.T32.24.14.14.14.15.1" class="ltx_td ltx_border_tt"></span> <span id="S5.T32.24.14.14.14.15.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T32.24.14.14.14.15.2.1" class="ltx_text ltx_font_bold">YNAT</span></span> <span id="S5.T32.24.14.14.14.15.3" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T32.24.14.14.14.15.3.1" class="ltx_text ltx_font_bold">KLUE-STS</span></span> <span id="S5.T32.24.14.14.14.15.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T32.24.14.14.14.15.4.1" class="ltx_text ltx_font_bold">KLUE-NLI</span></span> <span id="S5.T32.24.14.14.14.15.5" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T32.24.14.14.14.15.5.1" class="ltx_text ltx_font_bold">KLUE-NER</span></span> <span id="S5.T32.24.14.14.14.15.6" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T32.24.14.14.14.15.6.1" class="ltx_text ltx_font_bold">KLUE-RE</span></span> <span id="S5.T32.24.14.14.14.15.7" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T32.24.14.14.14.15.7.1" class="ltx_text ltx_font_bold">KLUE-DP</span></span> <span id="S5.T32.24.14.14.14.15.8" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T32.24.14.14.14.15.8.1" class="ltx_text ltx_font_bold">KLUE-MRC</span></span> <span id="S5.T32.24.14.14.14.15.9" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T32.24.14.14.14.15.9.1" class="ltx_text ltx_font_bold">WoS</span></span></span> <span id="S5.T32.15.5.5.5.5" class="ltx_tr"> <span id="S5.T32.15.5.5.5.5.6" class="ltx_td ltx_align_left"><span id="S5.T32.15.5.5.5.5.6.1" class="ltx_text ltx_font_bold">Model</span></span> <span id="S5.T32.15.5.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t">F1</span> <span id="S5.T32.11.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">R<sup id="S5.T32.11.1.1.1.1.1.1" class="ltx_sup"><span id="S5.T32.11.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">P</span></sup></span> <span id="S5.T32.15.5.5.5.5.8" class="ltx_td ltx_align_center ltx_border_t">F1</span> <span id="S5.T32.15.5.5.5.5.9" class="ltx_td ltx_align_center ltx_border_t">ACC</span> <span id="S5.T32.12.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T32.12.2.2.2.2.2.1" class="ltx_sup"><span id="S5.T32.12.2.2.2.2.2.1.1" class="ltx_text ltx_font_italic">E</span></sup></span> <span id="S5.T32.13.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T32.13.3.3.3.3.3.1" class="ltx_sup"><span id="S5.T32.13.3.3.3.3.3.1.1" class="ltx_text ltx_font_italic">C</span></sup></span> <span id="S5.T32.14.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T32.14.4.4.4.4.4.1" class="ltx_sup"><span id="S5.T32.14.4.4.4.4.4.1.1" class="ltx_text ltx_font_italic">mic</span></sup></span> <span id="S5.T32.15.5.5.5.5.10" class="ltx_td ltx_align_center ltx_border_t">AUC</span> <span id="S5.T32.15.5.5.5.5.11" class="ltx_td ltx_align_center ltx_border_t">UAS</span> <span id="S5.T32.15.5.5.5.5.12" class="ltx_td ltx_align_center ltx_border_t">LAS</span> <span id="S5.T32.15.5.5.5.5.13" class="ltx_td ltx_align_center ltx_border_t">EM</span> <span id="S5.T32.15.5.5.5.5.14" class="ltx_td ltx_align_center ltx_border_t">ROUGE</span> <span id="S5.T32.15.5.5.5.5.15" class="ltx_td ltx_align_center ltx_border_t">JGA</span> <span id="S5.T32.15.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T32.15.5.5.5.5.5.1" class="ltx_sup"><span id="S5.T32.15.5.5.5.5.5.1.1" class="ltx_text ltx_font_italic">S</span></sup></span></span> <span id="S5.T32.16.6.6.6.6" class="ltx_tr"> <span id="S5.T32.16.6.6.6.6.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S5.T32.16.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\text{mBERT}_{\text{BASE}}" display="inline"><semantics id="S5.T32.16.6.6.6.6.1.m1.1a"><msub id="S5.T32.16.6.6.6.6.1.m1.1.1" xref="S5.T32.16.6.6.6.6.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.16.6.6.6.6.1.m1.1.1.2" xref="S5.T32.16.6.6.6.6.1.m1.1.1.2a.cmml">mBERT</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.16.6.6.6.6.1.m1.1.1.3" xref="S5.T32.16.6.6.6.6.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.16.6.6.6.6.1.m1.1b"><apply id="S5.T32.16.6.6.6.6.1.m1.1.1.cmml" xref="S5.T32.16.6.6.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.16.6.6.6.6.1.m1.1.1.1.cmml" xref="S5.T32.16.6.6.6.6.1.m1.1.1">subscript</csymbol><ci id="S5.T32.16.6.6.6.6.1.m1.1.1.2a.cmml" xref="S5.T32.16.6.6.6.6.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.16.6.6.6.6.1.m1.1.1.2.cmml" xref="S5.T32.16.6.6.6.6.1.m1.1.1.2">mBERT</mtext></ci><ci id="S5.T32.16.6.6.6.6.1.m1.1.1.3a.cmml" xref="S5.T32.16.6.6.6.6.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.16.6.6.6.6.1.m1.1.1.3.cmml" xref="S5.T32.16.6.6.6.6.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.16.6.6.6.6.1.m1.1c">\text{mBERT}_{\text{BASE}}</annotation></semantics></math></span> <span id="S5.T32.16.6.6.6.6.2" class="ltx_td ltx_align_center ltx_border_t">81.55</span> <span id="S5.T32.16.6.6.6.6.3" class="ltx_td ltx_align_center ltx_border_t">84.66</span> <span id="S5.T32.16.6.6.6.6.4" class="ltx_td ltx_align_center ltx_border_t">76.00</span> <span id="S5.T32.16.6.6.6.6.5" class="ltx_td ltx_align_center ltx_border_t">73.20</span> <span id="S5.T32.16.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_t">76.50</span> <span id="S5.T32.16.6.6.6.6.7" class="ltx_td ltx_align_center ltx_border_t">89.23</span> <span id="S5.T32.16.6.6.6.6.8" class="ltx_td ltx_align_center ltx_border_t">57.88</span> <span id="S5.T32.16.6.6.6.6.9" class="ltx_td ltx_align_center ltx_border_t">53.82</span> <span id="S5.T32.16.6.6.6.6.10" class="ltx_td ltx_align_center ltx_border_t">90.30</span> <span id="S5.T32.16.6.6.6.6.11" class="ltx_td ltx_align_center ltx_border_t">86.66</span> <span id="S5.T32.16.6.6.6.6.12" class="ltx_td ltx_align_center ltx_border_t">44.66</span> <span id="S5.T32.16.6.6.6.6.13" class="ltx_td ltx_align_center ltx_border_t">55.92</span> <span id="S5.T32.16.6.6.6.6.14" class="ltx_td ltx_align_center ltx_border_t">35.46</span> <span id="S5.T32.16.6.6.6.6.15" class="ltx_td ltx_align_center ltx_border_t">88.63</span></span> <span id="S5.T32.17.7.7.7.7" class="ltx_tr"> <span id="S5.T32.17.7.7.7.7.1" class="ltx_td ltx_align_left"><math id="S5.T32.17.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\text{XLM-R}_{\text{BASE}}" display="inline"><semantics id="S5.T32.17.7.7.7.7.1.m1.1a"><msub id="S5.T32.17.7.7.7.7.1.m1.1.1" xref="S5.T32.17.7.7.7.7.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.17.7.7.7.7.1.m1.1.1.2" xref="S5.T32.17.7.7.7.7.1.m1.1.1.2a.cmml">XLM-R</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.17.7.7.7.7.1.m1.1.1.3" xref="S5.T32.17.7.7.7.7.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.17.7.7.7.7.1.m1.1b"><apply id="S5.T32.17.7.7.7.7.1.m1.1.1.cmml" xref="S5.T32.17.7.7.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.17.7.7.7.7.1.m1.1.1.1.cmml" xref="S5.T32.17.7.7.7.7.1.m1.1.1">subscript</csymbol><ci id="S5.T32.17.7.7.7.7.1.m1.1.1.2a.cmml" xref="S5.T32.17.7.7.7.7.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.17.7.7.7.7.1.m1.1.1.2.cmml" xref="S5.T32.17.7.7.7.7.1.m1.1.1.2">XLM-R</mtext></ci><ci id="S5.T32.17.7.7.7.7.1.m1.1.1.3a.cmml" xref="S5.T32.17.7.7.7.7.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.17.7.7.7.7.1.m1.1.1.3.cmml" xref="S5.T32.17.7.7.7.7.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.17.7.7.7.7.1.m1.1c">\text{XLM-R}_{\text{BASE}}</annotation></semantics></math></span> <span id="S5.T32.17.7.7.7.7.2" class="ltx_td ltx_align_center">83.52</span> <span id="S5.T32.17.7.7.7.7.3" class="ltx_td ltx_align_center">89.16</span> <span id="S5.T32.17.7.7.7.7.4" class="ltx_td ltx_align_center">82.01</span> <span id="S5.T32.17.7.7.7.7.5" class="ltx_td ltx_align_center">77.33</span> <span id="S5.T32.17.7.7.7.7.6" class="ltx_td ltx_align_center">80.37</span> <span id="S5.T32.17.7.7.7.7.7" class="ltx_td ltx_align_center">92.12</span> <span id="S5.T32.17.7.7.7.7.8" class="ltx_td ltx_align_center">57.46</span> <span id="S5.T32.17.7.7.7.7.9" class="ltx_td ltx_align_center">54.98</span> <span id="S5.T32.17.7.7.7.7.10" class="ltx_td ltx_align_center">89.20</span> <span id="S5.T32.17.7.7.7.7.11" class="ltx_td ltx_align_center">87.69</span> <span id="S5.T32.17.7.7.7.7.12" class="ltx_td ltx_align_center">27.48</span> <span id="S5.T32.17.7.7.7.7.13" class="ltx_td ltx_align_center">53.93</span> <span id="S5.T32.17.7.7.7.7.14" class="ltx_td ltx_align_center">39.82</span> <span id="S5.T32.17.7.7.7.7.15" class="ltx_td ltx_align_center">89.61</span></span> <span id="S5.T32.18.8.8.8.8" class="ltx_tr"> <span id="S5.T32.18.8.8.8.8.1" class="ltx_td ltx_align_left"><math id="S5.T32.18.8.8.8.8.1.m1.1" class="ltx_Math" alttext="\text{XLM-R}_{\text{LARGE}}" display="inline"><semantics id="S5.T32.18.8.8.8.8.1.m1.1a"><msub id="S5.T32.18.8.8.8.8.1.m1.1.1" xref="S5.T32.18.8.8.8.8.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.18.8.8.8.8.1.m1.1.1.2" xref="S5.T32.18.8.8.8.8.1.m1.1.1.2a.cmml">XLM-R</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.18.8.8.8.8.1.m1.1.1.3" xref="S5.T32.18.8.8.8.8.1.m1.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.18.8.8.8.8.1.m1.1b"><apply id="S5.T32.18.8.8.8.8.1.m1.1.1.cmml" xref="S5.T32.18.8.8.8.8.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.18.8.8.8.8.1.m1.1.1.1.cmml" xref="S5.T32.18.8.8.8.8.1.m1.1.1">subscript</csymbol><ci id="S5.T32.18.8.8.8.8.1.m1.1.1.2a.cmml" xref="S5.T32.18.8.8.8.8.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.18.8.8.8.8.1.m1.1.1.2.cmml" xref="S5.T32.18.8.8.8.8.1.m1.1.1.2">XLM-R</mtext></ci><ci id="S5.T32.18.8.8.8.8.1.m1.1.1.3a.cmml" xref="S5.T32.18.8.8.8.8.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.18.8.8.8.8.1.m1.1.1.3.cmml" xref="S5.T32.18.8.8.8.8.1.m1.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.18.8.8.8.8.1.m1.1c">\text{XLM-R}_{\text{LARGE}}</annotation></semantics></math></span> <span id="S5.T32.18.8.8.8.8.2" class="ltx_td ltx_align_center"><span id="S5.T32.18.8.8.8.8.2.1" class="ltx_text ltx_font_bold">86.06</span></span> <span id="S5.T32.18.8.8.8.8.3" class="ltx_td ltx_align_center">92.97</span> <span id="S5.T32.18.8.8.8.8.4" class="ltx_td ltx_align_center">85.86</span> <span id="S5.T32.18.8.8.8.8.5" class="ltx_td ltx_align_center">85.93</span> <span id="S5.T32.18.8.8.8.8.6" class="ltx_td ltx_align_center">82.27</span> <span id="S5.T32.18.8.8.8.8.7" class="ltx_td ltx_align_center"><span id="S5.T32.18.8.8.8.8.7.1" class="ltx_text ltx_font_bold">93.22</span></span> <span id="S5.T32.18.8.8.8.8.8" class="ltx_td ltx_align_center">58.39</span> <span id="S5.T32.18.8.8.8.8.9" class="ltx_td ltx_align_center">61.15</span> <span id="S5.T32.18.8.8.8.8.10" class="ltx_td ltx_align_center">92.71</span> <span id="S5.T32.18.8.8.8.8.11" class="ltx_td ltx_align_center"><span id="S5.T32.18.8.8.8.8.11.1" class="ltx_text ltx_font_bold">88.70</span></span> <span id="S5.T32.18.8.8.8.8.12" class="ltx_td ltx_align_center">35.99</span> <span id="S5.T32.18.8.8.8.8.13" class="ltx_td ltx_align_center">66.77</span> <span id="S5.T32.18.8.8.8.8.14" class="ltx_td ltx_align_center">41.20</span> <span id="S5.T32.18.8.8.8.8.15" class="ltx_td ltx_align_center">89.80</span></span> <span id="S5.T32.19.9.9.9.9" class="ltx_tr"> <span id="S5.T32.19.9.9.9.9.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S5.T32.19.9.9.9.9.1.m1.1" class="ltx_Math" alttext="\text{KR-BERT}_{\text{BASE}}" display="inline"><semantics id="S5.T32.19.9.9.9.9.1.m1.1a"><msub id="S5.T32.19.9.9.9.9.1.m1.1.1" xref="S5.T32.19.9.9.9.9.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.19.9.9.9.9.1.m1.1.1.2" xref="S5.T32.19.9.9.9.9.1.m1.1.1.2a.cmml">KR-BERT</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.19.9.9.9.9.1.m1.1.1.3" xref="S5.T32.19.9.9.9.9.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.19.9.9.9.9.1.m1.1b"><apply id="S5.T32.19.9.9.9.9.1.m1.1.1.cmml" xref="S5.T32.19.9.9.9.9.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.19.9.9.9.9.1.m1.1.1.1.cmml" xref="S5.T32.19.9.9.9.9.1.m1.1.1">subscript</csymbol><ci id="S5.T32.19.9.9.9.9.1.m1.1.1.2a.cmml" xref="S5.T32.19.9.9.9.9.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.19.9.9.9.9.1.m1.1.1.2.cmml" xref="S5.T32.19.9.9.9.9.1.m1.1.1.2">KR-BERT</mtext></ci><ci id="S5.T32.19.9.9.9.9.1.m1.1.1.3a.cmml" xref="S5.T32.19.9.9.9.9.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.19.9.9.9.9.1.m1.1.1.3.cmml" xref="S5.T32.19.9.9.9.9.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.19.9.9.9.9.1.m1.1c">\text{KR-BERT}_{\text{BASE}}</annotation></semantics></math></span> <span id="S5.T32.19.9.9.9.9.2" class="ltx_td ltx_align_center ltx_border_t">84.58</span> <span id="S5.T32.19.9.9.9.9.3" class="ltx_td ltx_align_center ltx_border_t">88.61</span> <span id="S5.T32.19.9.9.9.9.4" class="ltx_td ltx_align_center ltx_border_t">81.07</span> <span id="S5.T32.19.9.9.9.9.5" class="ltx_td ltx_align_center ltx_border_t">77.17</span> <span id="S5.T32.19.9.9.9.9.6" class="ltx_td ltx_align_center ltx_border_t">74.58</span> <span id="S5.T32.19.9.9.9.9.7" class="ltx_td ltx_align_center ltx_border_t">90.13</span> <span id="S5.T32.19.9.9.9.9.8" class="ltx_td ltx_align_center ltx_border_t">62.74</span> <span id="S5.T32.19.9.9.9.9.9" class="ltx_td ltx_align_center ltx_border_t">60.94</span> <span id="S5.T32.19.9.9.9.9.10" class="ltx_td ltx_align_center ltx_border_t">89.92</span> <span id="S5.T32.19.9.9.9.9.11" class="ltx_td ltx_align_center ltx_border_t">87.48</span> <span id="S5.T32.19.9.9.9.9.12" class="ltx_td ltx_align_center ltx_border_t">48.28</span> <span id="S5.T32.19.9.9.9.9.13" class="ltx_td ltx_align_center ltx_border_t">58.54</span> <span id="S5.T32.19.9.9.9.9.14" class="ltx_td ltx_align_center ltx_border_t">45.33</span> <span id="S5.T32.19.9.9.9.9.15" class="ltx_td ltx_align_center ltx_border_t">90.70</span></span> <span id="S5.T32.20.10.10.10.10" class="ltx_tr"> <span id="S5.T32.20.10.10.10.10.1" class="ltx_td ltx_align_left"><math id="S5.T32.20.10.10.10.10.1.m1.1" class="ltx_Math" alttext="\text{KoELECTRA}_{\text{BASE}}" display="inline"><semantics id="S5.T32.20.10.10.10.10.1.m1.1a"><msub id="S5.T32.20.10.10.10.10.1.m1.1.1" xref="S5.T32.20.10.10.10.10.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.20.10.10.10.10.1.m1.1.1.2" xref="S5.T32.20.10.10.10.10.1.m1.1.1.2a.cmml">KoELECTRA</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.20.10.10.10.10.1.m1.1.1.3" xref="S5.T32.20.10.10.10.10.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.20.10.10.10.10.1.m1.1b"><apply id="S5.T32.20.10.10.10.10.1.m1.1.1.cmml" xref="S5.T32.20.10.10.10.10.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.20.10.10.10.10.1.m1.1.1.1.cmml" xref="S5.T32.20.10.10.10.10.1.m1.1.1">subscript</csymbol><ci id="S5.T32.20.10.10.10.10.1.m1.1.1.2a.cmml" xref="S5.T32.20.10.10.10.10.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.20.10.10.10.10.1.m1.1.1.2.cmml" xref="S5.T32.20.10.10.10.10.1.m1.1.1.2">KoELECTRA</mtext></ci><ci id="S5.T32.20.10.10.10.10.1.m1.1.1.3a.cmml" xref="S5.T32.20.10.10.10.10.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.20.10.10.10.10.1.m1.1.1.3.cmml" xref="S5.T32.20.10.10.10.10.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.20.10.10.10.10.1.m1.1c">\text{KoELECTRA}_{\text{BASE}}</annotation></semantics></math></span> <span id="S5.T32.20.10.10.10.10.2" class="ltx_td ltx_align_center">84.59</span> <span id="S5.T32.20.10.10.10.10.3" class="ltx_td ltx_align_center"><span id="S5.T32.20.10.10.10.10.3.1" class="ltx_text ltx_framed ltx_framed_underline">92.46</span></span> <span id="S5.T32.20.10.10.10.10.4" class="ltx_td ltx_align_center"><span id="S5.T32.20.10.10.10.10.4.1" class="ltx_text ltx_framed ltx_framed_underline">84.84</span></span> <span id="S5.T32.20.10.10.10.10.5" class="ltx_td ltx_align_center"><span id="S5.T32.20.10.10.10.10.5.1" class="ltx_text ltx_framed ltx_framed_underline">85.63</span></span> <span id="S5.T32.20.10.10.10.10.6" class="ltx_td ltx_align_center"><span id="S5.T32.20.10.10.10.10.6.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">86.11</span></span> <span id="S5.T32.20.10.10.10.10.7" class="ltx_td ltx_align_center"><span id="S5.T32.20.10.10.10.10.7.1" class="ltx_text ltx_framed ltx_framed_underline">92.56</span></span> <span id="S5.T32.20.10.10.10.10.8" class="ltx_td ltx_align_center">62.85</span> <span id="S5.T32.20.10.10.10.10.9" class="ltx_td ltx_align_center">58.94</span> <span id="S5.T32.20.10.10.10.10.10" class="ltx_td ltx_align_center">92.90</span> <span id="S5.T32.20.10.10.10.10.11" class="ltx_td ltx_align_center">87.77</span> <span id="S5.T32.20.10.10.10.10.12" class="ltx_td ltx_align_center">59.82</span> <span id="S5.T32.20.10.10.10.10.13" class="ltx_td ltx_align_center">66.05</span> <span id="S5.T32.20.10.10.10.10.14" class="ltx_td ltx_align_center">41.58</span> <span id="S5.T32.20.10.10.10.10.15" class="ltx_td ltx_align_center">89.60</span></span> <span id="S5.T32.21.11.11.11.11" class="ltx_tr"> <span id="S5.T32.21.11.11.11.11.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S5.T32.21.11.11.11.11.1.m1.1" class="ltx_Math" alttext="\text{KLUE-BERT}_{\text{BASE}}" display="inline"><semantics id="S5.T32.21.11.11.11.11.1.m1.1a"><msub id="S5.T32.21.11.11.11.11.1.m1.1.1" xref="S5.T32.21.11.11.11.11.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.21.11.11.11.11.1.m1.1.1.2" xref="S5.T32.21.11.11.11.11.1.m1.1.1.2a.cmml">KLUE-BERT</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.21.11.11.11.11.1.m1.1.1.3" xref="S5.T32.21.11.11.11.11.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.21.11.11.11.11.1.m1.1b"><apply id="S5.T32.21.11.11.11.11.1.m1.1.1.cmml" xref="S5.T32.21.11.11.11.11.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.21.11.11.11.11.1.m1.1.1.1.cmml" xref="S5.T32.21.11.11.11.11.1.m1.1.1">subscript</csymbol><ci id="S5.T32.21.11.11.11.11.1.m1.1.1.2a.cmml" xref="S5.T32.21.11.11.11.11.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.21.11.11.11.11.1.m1.1.1.2.cmml" xref="S5.T32.21.11.11.11.11.1.m1.1.1.2">KLUE-BERT</mtext></ci><ci id="S5.T32.21.11.11.11.11.1.m1.1.1.3a.cmml" xref="S5.T32.21.11.11.11.11.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.21.11.11.11.11.1.m1.1.1.3.cmml" xref="S5.T32.21.11.11.11.11.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.21.11.11.11.11.1.m1.1c">\text{KLUE-BERT}_{\text{BASE}}</annotation></semantics></math></span> <span id="S5.T32.21.11.11.11.11.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T32.21.11.11.11.11.2.1" class="ltx_text ltx_framed ltx_framed_underline">85.73</span></span> <span id="S5.T32.21.11.11.11.11.3" class="ltx_td ltx_align_center ltx_border_t">90.85</span> <span id="S5.T32.21.11.11.11.11.4" class="ltx_td ltx_align_center ltx_border_t">82.84</span> <span id="S5.T32.21.11.11.11.11.5" class="ltx_td ltx_align_center ltx_border_t">81.63</span> <span id="S5.T32.21.11.11.11.11.6" class="ltx_td ltx_align_center ltx_border_t">83.97</span> <span id="S5.T32.21.11.11.11.11.7" class="ltx_td ltx_align_center ltx_border_t">91.39</span> <span id="S5.T32.21.11.11.11.11.8" class="ltx_td ltx_align_center ltx_border_t">66.44</span> <span id="S5.T32.21.11.11.11.11.9" class="ltx_td ltx_align_center ltx_border_t">66.17</span> <span id="S5.T32.21.11.11.11.11.10" class="ltx_td ltx_align_center ltx_border_t">89.96</span> <span id="S5.T32.21.11.11.11.11.11" class="ltx_td ltx_align_center ltx_border_t">88.05</span> <span id="S5.T32.21.11.11.11.11.12" class="ltx_td ltx_align_center ltx_border_t">62.32</span> <span id="S5.T32.21.11.11.11.11.13" class="ltx_td ltx_align_center ltx_border_t">68.51</span> <span id="S5.T32.21.11.11.11.11.14" class="ltx_td ltx_align_center ltx_border_t">46.64</span> <span id="S5.T32.21.11.11.11.11.15" class="ltx_td ltx_align_center ltx_border_t">91.61</span></span> <span id="S5.T32.22.12.12.12.12" class="ltx_tr"> <span id="S5.T32.22.12.12.12.12.1" class="ltx_td ltx_align_left"><math id="S5.T32.22.12.12.12.12.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{SMALL}}" display="inline"><semantics id="S5.T32.22.12.12.12.12.1.m1.1a"><msub id="S5.T32.22.12.12.12.12.1.m1.1.1" xref="S5.T32.22.12.12.12.12.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.22.12.12.12.12.1.m1.1.1.2" xref="S5.T32.22.12.12.12.12.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.22.12.12.12.12.1.m1.1.1.3" xref="S5.T32.22.12.12.12.12.1.m1.1.1.3a.cmml">SMALL</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.22.12.12.12.12.1.m1.1b"><apply id="S5.T32.22.12.12.12.12.1.m1.1.1.cmml" xref="S5.T32.22.12.12.12.12.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.22.12.12.12.12.1.m1.1.1.1.cmml" xref="S5.T32.22.12.12.12.12.1.m1.1.1">subscript</csymbol><ci id="S5.T32.22.12.12.12.12.1.m1.1.1.2a.cmml" xref="S5.T32.22.12.12.12.12.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.22.12.12.12.12.1.m1.1.1.2.cmml" xref="S5.T32.22.12.12.12.12.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S5.T32.22.12.12.12.12.1.m1.1.1.3a.cmml" xref="S5.T32.22.12.12.12.12.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.22.12.12.12.12.1.m1.1.1.3.cmml" xref="S5.T32.22.12.12.12.12.1.m1.1.1.3">SMALL</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.22.12.12.12.12.1.m1.1c">\text{KLUE-RoBERTa}_{\text{SMALL}}</annotation></semantics></math></span> <span id="S5.T32.22.12.12.12.12.2" class="ltx_td ltx_align_center">84.98</span> <span id="S5.T32.22.12.12.12.12.3" class="ltx_td ltx_align_center">91.54</span> <span id="S5.T32.22.12.12.12.12.4" class="ltx_td ltx_align_center">85.16</span> <span id="S5.T32.22.12.12.12.12.5" class="ltx_td ltx_align_center">79.33</span> <span id="S5.T32.22.12.12.12.12.6" class="ltx_td ltx_align_center">83.65</span> <span id="S5.T32.22.12.12.12.12.7" class="ltx_td ltx_align_center">91.14</span> <span id="S5.T32.22.12.12.12.12.8" class="ltx_td ltx_align_center">60.89</span> <span id="S5.T32.22.12.12.12.12.9" class="ltx_td ltx_align_center">58.96</span> <span id="S5.T32.22.12.12.12.12.10" class="ltx_td ltx_align_center">90.04</span> <span id="S5.T32.22.12.12.12.12.11" class="ltx_td ltx_align_center">88.14</span> <span id="S5.T32.22.12.12.12.12.12" class="ltx_td ltx_align_center">57.32</span> <span id="S5.T32.22.12.12.12.12.13" class="ltx_td ltx_align_center">62.70</span> <span id="S5.T32.22.12.12.12.12.14" class="ltx_td ltx_align_center">46.62</span> <span id="S5.T32.22.12.12.12.12.15" class="ltx_td ltx_align_center">91.44</span></span> <span id="S5.T32.23.13.13.13.13" class="ltx_tr"> <span id="S5.T32.23.13.13.13.13.1" class="ltx_td ltx_align_left"><math id="S5.T32.23.13.13.13.13.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{BASE}}" display="inline"><semantics id="S5.T32.23.13.13.13.13.1.m1.1a"><msub id="S5.T32.23.13.13.13.13.1.m1.1.1" xref="S5.T32.23.13.13.13.13.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.23.13.13.13.13.1.m1.1.1.2" xref="S5.T32.23.13.13.13.13.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.23.13.13.13.13.1.m1.1.1.3" xref="S5.T32.23.13.13.13.13.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.23.13.13.13.13.1.m1.1b"><apply id="S5.T32.23.13.13.13.13.1.m1.1.1.cmml" xref="S5.T32.23.13.13.13.13.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.23.13.13.13.13.1.m1.1.1.1.cmml" xref="S5.T32.23.13.13.13.13.1.m1.1.1">subscript</csymbol><ci id="S5.T32.23.13.13.13.13.1.m1.1.1.2a.cmml" xref="S5.T32.23.13.13.13.13.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.23.13.13.13.13.1.m1.1.1.2.cmml" xref="S5.T32.23.13.13.13.13.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S5.T32.23.13.13.13.13.1.m1.1.1.3a.cmml" xref="S5.T32.23.13.13.13.13.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.23.13.13.13.13.1.m1.1.1.3.cmml" xref="S5.T32.23.13.13.13.13.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.23.13.13.13.13.1.m1.1c">\text{KLUE-RoBERTa}_{\text{BASE}}</annotation></semantics></math></span> <span id="S5.T32.23.13.13.13.13.2" class="ltx_td ltx_align_center">85.07</span> <span id="S5.T32.23.13.13.13.13.3" class="ltx_td ltx_align_center">92.50</span> <span id="S5.T32.23.13.13.13.13.4" class="ltx_td ltx_align_center">85.40</span> <span id="S5.T32.23.13.13.13.13.5" class="ltx_td ltx_align_center">84.83</span> <span id="S5.T32.23.13.13.13.13.6" class="ltx_td ltx_align_center">84.60</span> <span id="S5.T32.23.13.13.13.13.7" class="ltx_td ltx_align_center">91.44</span> <span id="S5.T32.23.13.13.13.13.8" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.8.1" class="ltx_text ltx_framed ltx_framed_underline">67.65</span></span> <span id="S5.T32.23.13.13.13.13.9" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.9.1" class="ltx_text ltx_framed ltx_framed_underline">68.55</span></span> <span id="S5.T32.23.13.13.13.13.10" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.10.1" class="ltx_text ltx_framed ltx_framed_underline">93.04</span></span> <span id="S5.T32.23.13.13.13.13.11" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.11.1" class="ltx_text ltx_framed ltx_framed_underline">88.32</span></span> <span id="S5.T32.23.13.13.13.13.12" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.12.1" class="ltx_text ltx_framed ltx_framed_underline">68.67</span></span> <span id="S5.T32.23.13.13.13.13.13" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.13.1" class="ltx_text ltx_framed ltx_framed_underline">73.98</span></span> <span id="S5.T32.23.13.13.13.13.14" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.14.1" class="ltx_text ltx_framed ltx_framed_underline">47.49</span></span> <span id="S5.T32.23.13.13.13.13.15" class="ltx_td ltx_align_center"><span id="S5.T32.23.13.13.13.13.15.1" class="ltx_text ltx_framed ltx_framed_underline">91.64</span></span></span> <span id="S5.T32.24.14.14.14.14" class="ltx_tr"> <span id="S5.T32.24.14.14.14.14.1" class="ltx_td ltx_align_left ltx_border_bb"><math id="S5.T32.24.14.14.14.14.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{LARGE}}" display="inline"><semantics id="S5.T32.24.14.14.14.14.1.m1.1a"><msub id="S5.T32.24.14.14.14.14.1.m1.1.1" xref="S5.T32.24.14.14.14.14.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S5.T32.24.14.14.14.14.1.m1.1.1.2" xref="S5.T32.24.14.14.14.14.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="S5.T32.24.14.14.14.14.1.m1.1.1.3" xref="S5.T32.24.14.14.14.14.1.m1.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.T32.24.14.14.14.14.1.m1.1b"><apply id="S5.T32.24.14.14.14.14.1.m1.1.1.cmml" xref="S5.T32.24.14.14.14.14.1.m1.1.1"><csymbol cd="ambiguous" id="S5.T32.24.14.14.14.14.1.m1.1.1.1.cmml" xref="S5.T32.24.14.14.14.14.1.m1.1.1">subscript</csymbol><ci id="S5.T32.24.14.14.14.14.1.m1.1.1.2a.cmml" xref="S5.T32.24.14.14.14.14.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S5.T32.24.14.14.14.14.1.m1.1.1.2.cmml" xref="S5.T32.24.14.14.14.14.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S5.T32.24.14.14.14.14.1.m1.1.1.3a.cmml" xref="S5.T32.24.14.14.14.14.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S5.T32.24.14.14.14.14.1.m1.1.1.3.cmml" xref="S5.T32.24.14.14.14.14.1.m1.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.T32.24.14.14.14.14.1.m1.1c">\text{KLUE-RoBERTa}_{\text{LARGE}}</annotation></semantics></math></span> <span id="S5.T32.24.14.14.14.14.2" class="ltx_td ltx_align_center ltx_border_bb">85.69</span> <span id="S5.T32.24.14.14.14.14.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.3.1" class="ltx_text ltx_font_bold">93.35</span></span> <span id="S5.T32.24.14.14.14.14.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.4.1" class="ltx_text ltx_font_bold">86.63</span></span> <span id="S5.T32.24.14.14.14.14.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.5.1" class="ltx_text ltx_font_bold">89.17</span></span> <span id="S5.T32.24.14.14.14.14.6" class="ltx_td ltx_align_center ltx_border_bb">85.00</span> <span id="S5.T32.24.14.14.14.14.7" class="ltx_td ltx_align_center ltx_border_bb">91.86</span> <span id="S5.T32.24.14.14.14.14.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.8.1" class="ltx_text ltx_font_bold">71.13</span></span> <span id="S5.T32.24.14.14.14.14.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.9.1" class="ltx_text ltx_font_bold">72.98</span></span> <span id="S5.T32.24.14.14.14.14.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.10.1" class="ltx_text ltx_font_bold">93.48</span></span> <span id="S5.T32.24.14.14.14.14.11" class="ltx_td ltx_align_center ltx_border_bb">88.36</span> <span id="S5.T32.24.14.14.14.14.12" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.12.1" class="ltx_text ltx_font_bold">75.58</span></span> <span id="S5.T32.24.14.14.14.14.13" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.13.1" class="ltx_text ltx_font_bold">80.59</span></span> <span id="S5.T32.24.14.14.14.14.14" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.14.1" class="ltx_text ltx_font_bold">50.22</span></span> <span id="S5.T32.24.14.14.14.14.15" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T32.24.14.14.14.14.15.1" class="ltx_text ltx_font_bold">92.23</span></span></span> </span></span></p>
</span></div>
</figure>
<div id="S5.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS3.p1.3">이 섹션에서는 표 <a class="ltx_ref" href="#S5.T32" title="Table 32 ‣ 5.3 Evaluation Results ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">32</span></a>에서 KLUE 벤치마크에 대한 우리의 KLUE-PLM과 기존 PLM을 포함한 평가 결과를 제시한다. <span class="ltx_note ltx_role_footnote" id="footnote63"><sup class="ltx_note_mark">63</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">63</sup><span class="ltx_tag ltx_tag_note">63</span> See Appendix <a class="ltx_ref" href="#A1" title="Appendix A Dev Set Results ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">A</span></a> for the corresponding table however computed on the development set. </span></span></span> 다른 NLU 벤치마크와 달리 다른 척도와 해석의 점수를 단순 평균화하는 것은 매우 오판의 소지가 있기 때문에 태스크에 대한 점수를 평균화하지 않는다. 오히려 각 과제의 결과를 별도로 기술하고 논의한다. 한국어 <span class="ltx_text ltx_font_typewriter" id="S5.SS3.p1.3.1">BASE</span> 모델 내에서 <math alttext="\text{KLUE-BERT}_{\text{BASE}}" class="ltx_Math" display="inline" id="S5.SS3.p1.1.m1.1"><semantics id="S5.SS3.p1.1.m1.1a"><msub id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml"><mtext id="S5.SS3.p1.1.m1.1.1.2" xref="S5.SS3.p1.1.m1.1.1.2a.cmml">KLUE-BERT</mtext><mtext id="S5.SS3.p1.1.m1.1.1.3" xref="S5.SS3.p1.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><apply id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.p1.1.m1.1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS3.p1.1.m1.1.1.2a.cmml" xref="S5.SS3.p1.1.m1.1.1.2"><mtext id="S5.SS3.p1.1.m1.1.1.2.cmml" xref="S5.SS3.p1.1.m1.1.1.2">KLUE-BERT</mtext></ci><ci id="S5.SS3.p1.1.m1.1.1.3a.cmml" xref="S5.SS3.p1.1.m1.1.1.3"><mtext id="S5.SS3.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.SS3.p1.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">\text{KLUE-BERT}_{\text{BASE}}</annotation></semantics></math>는 YNAT 및 WoS에 대해, <math alttext="\text{KLUE-RoBERTa}_{\text{BASE}}" class="ltx_Math" display="inline" id="S5.SS3.p1.2.m2.1"><semantics id="S5.SS3.p1.2.m2.1a"><msub id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml"><mtext id="S5.SS3.p1.2.m2.1.1.2" xref="S5.SS3.p1.2.m2.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext id="S5.SS3.p1.2.m2.1.1.3" xref="S5.SS3.p1.2.m2.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.1b"><apply id="S5.SS3.p1.2.m2.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS3.p1.2.m2.1.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S5.SS3.p1.2.m2.1.1.2a.cmml" xref="S5.SS3.p1.2.m2.1.1.2"><mtext id="S5.SS3.p1.2.m2.1.1.2.cmml" xref="S5.SS3.p1.2.m2.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S5.SS3.p1.2.m2.1.1.3a.cmml" xref="S5.SS3.p1.2.m2.1.1.3"><mtext id="S5.SS3.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S5.SS3.p1.2.m2.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.1c">\text{KLUE-RoBERTa}_{\text{BASE}}</annotation></semantics></math>는 KLUE-RE 및 KLUE-MRC에 대해, <math alttext="\text{KoELECTRA}_{\text{BASE}}" class="ltx_Math" display="inline" id="S5.SS3.p1.3.m3.1"><semantics id="S5.SS3.p1.3.m3.1a"><msub id="S5.SS3.p1.3.m3.1.1" xref="S5.SS3.p1.3.m3.1.1.cmml"><mtext id="S5.SS3.p1.3.m3.1.1.2" xref="S5.SS3.p1.3.m3.1.1.2a.cmml">KoELECTRA</mtext><mtext id="S5.SS3.p1.3.m3.1.1.3" xref="S5.SS3.p1.3.m3.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.3.m3.1b"><apply id="S5.SS3.p1.3.m3.1.1.cmml" xref="S5.SS3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS3.p1.3.m3.1.1.1.cmml" xref="S5.SS3.p1.3.m3.1.1">subscript</csymbol><ci id="S5.SS3.p1.3.m3.1.1.2a.cmml" xref="S5.SS3.p1.3.m3.1.1.2"><mtext id="S5.SS3.p1.3.m3.1.1.2.cmml" xref="S5.SS3.p1.3.m3.1.1.2">KoELECTRA</mtext></ci><ci id="S5.SS3.p1.3.m3.1.1.3a.cmml" xref="S5.SS3.p1.3.m3.1.1.3"><mtext id="S5.SS3.p1.3.m3.1.1.3.cmml" mathsize="70%" xref="S5.SS3.p1.3.m3.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.3.m3.1c">\text{KoELECTRA}_{\text{BASE}}</annotation></semantics></math>는 KLUE-STS 및 KLUE-NLI에 대해 가장 우수한 성능을 보인다.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p class="ltx_p" id="S5.SS3.p2.3">우리는 크게 두 가지 관찰을 한다. 먼저, 우리가 테스트한 기준 PLM 중 가장 큰 모델인 <math alttext="\text{KLUE-RoBERTa}_{\text{LARGE}}" class="ltx_Math" display="inline" id="S5.SS3.p2.1.m1.1"><semantics id="S5.SS3.p2.1.m1.1a"><msub id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml"><mtext id="S5.SS3.p2.1.m1.1.1.2" xref="S5.SS3.p2.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext id="S5.SS3.p2.1.m1.1.1.3" xref="S5.SS3.p2.1.m1.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><apply id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS3.p2.1.m1.1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S5.SS3.p2.1.m1.1.1.2a.cmml" xref="S5.SS3.p2.1.m1.1.1.2"><mtext id="S5.SS3.p2.1.m1.1.1.2.cmml" xref="S5.SS3.p2.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S5.SS3.p2.1.m1.1.1.3a.cmml" xref="S5.SS3.p2.1.m1.1.1.3"><mtext id="S5.SS3.p2.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.SS3.p2.1.m1.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">\text{KLUE-RoBERTa}_{\text{LARGE}}</annotation></semantics></math>가 KLUE-NER을 제외한 모든 태스크에서 다른 모든 모델보다 우수함을 알 수 있다. 이 관찰은 모델 크기와 작업 성능 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib58" title="">58</a>, <a class="ltx_ref" href="#bib.bib9" title="">9</a>]</cite> 사이의 상관 관계를 입증한 최근의 경향과 잘 일치한다. 이것은 KLUE가 단순히 모델 크기를 더 증가시킴으로써 우리가 얼마나 많은 이득을 기대할 수 있는지에 대한 향후 조사에 유용할 것임을 나타낸다. 두 번째 관찰은 대상 언어(한국어)에서 보다 신중하게 선별된 말뭉치를 위해 특별히 설계되고 훈련된 단일 언어 모델이 특히 유사한 크기의 모델을 비교할 때 일반적으로 다중 언어 대응 모델보다 우수하다는 것이다. 우리는 KLUE-NER을 제외한 모든 작업에서 이 관찰을 다시 하는데, 여기서 <math alttext="\text{XLM-R}_{\text{LARGE}}" class="ltx_Math" display="inline" id="S5.SS3.p2.2.m2.1"><semantics id="S5.SS3.p2.2.m2.1a"><msub id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml"><mtext id="S5.SS3.p2.2.m2.1.1.2" xref="S5.SS3.p2.2.m2.1.1.2a.cmml">XLM-R</mtext><mtext id="S5.SS3.p2.2.m2.1.1.3" xref="S5.SS3.p2.2.m2.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.1b"><apply id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS3.p2.2.m2.1.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S5.SS3.p2.2.m2.1.1.2a.cmml" xref="S5.SS3.p2.2.m2.1.1.2"><mtext id="S5.SS3.p2.2.m2.1.1.2.cmml" xref="S5.SS3.p2.2.m2.1.1.2">XLM-R</mtext></ci><ci id="S5.SS3.p2.2.m2.1.1.3a.cmml" xref="S5.SS3.p2.2.m2.1.1.3"><mtext id="S5.SS3.p2.2.m2.1.1.3.cmml" mathsize="70%" xref="S5.SS3.p2.2.m2.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.1c">\text{XLM-R}_{\text{LARGE}}</annotation></semantics></math>는 캐릭터 수준 F1 점수의 관점에서 최고의 수행자 <math alttext="\text{KoELECTRA}_{\text{BASE}}" class="ltx_Math" display="inline" id="S5.SS3.p2.3.m3.1"><semantics id="S5.SS3.p2.3.m3.1a"><msub id="S5.SS3.p2.3.m3.1.1" xref="S5.SS3.p2.3.m3.1.1.cmml"><mtext id="S5.SS3.p2.3.m3.1.1.2" xref="S5.SS3.p2.3.m3.1.1.2a.cmml">KoELECTRA</mtext><mtext id="S5.SS3.p2.3.m3.1.1.3" xref="S5.SS3.p2.3.m3.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.3.m3.1b"><apply id="S5.SS3.p2.3.m3.1.1.cmml" xref="S5.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S5.SS3.p2.3.m3.1.1.1.cmml" xref="S5.SS3.p2.3.m3.1.1">subscript</csymbol><ci id="S5.SS3.p2.3.m3.1.1.2a.cmml" xref="S5.SS3.p2.3.m3.1.1.2"><mtext id="S5.SS3.p2.3.m3.1.1.2.cmml" xref="S5.SS3.p2.3.m3.1.1.2">KoELECTRA</mtext></ci><ci id="S5.SS3.p2.3.m3.1.1.3a.cmml" xref="S5.SS3.p2.3.m3.1.1.3"><mtext id="S5.SS3.p2.3.m3.1.1.3.cmml" mathsize="70%" xref="S5.SS3.p2.3.m3.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.3.m3.1c">\text{KoELECTRA}_{\text{BASE}}</annotation></semantics></math>와 유사하게 수행한다. 이 관찰은 목표 언어를 이해하고 목표 언어에 대한 데이터, 모델 및 학습 알고리즘을 맞춤화하는 데 노력을 투자하는 것의 중요성을 다시 강조한다.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Analysis of Models</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS4.p1.1">사전 훈련 말뭉치와 전처리 데이터를 준비하는 데 있어 우리가 내린 두 가지 주요 결정이 있었다. 1) PII의 가명화 여부와 2) 토켄화 전략이었다. 이 섹션에서는 MODU 코퍼스에서만 학습하여 <math alttext="\text{KLUE-RoBERTa}_{\text{BASE}}" class="ltx_Math" display="inline" id="S5.SS4.p1.1.m1.1"><semantics id="S5.SS4.p1.1.m1.1a"><msub id="S5.SS4.p1.1.m1.1.1" xref="S5.SS4.p1.1.m1.1.1.cmml"><mtext id="S5.SS4.p1.1.m1.1.1.2" xref="S5.SS4.p1.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext id="S5.SS4.p1.1.m1.1.1.3" xref="S5.SS4.p1.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS4.p1.1.m1.1b"><apply id="S5.SS4.p1.1.m1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS4.p1.1.m1.1.1.1.cmml" xref="S5.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="S5.SS4.p1.1.m1.1.1.2a.cmml" xref="S5.SS4.p1.1.m1.1.1.2"><mtext id="S5.SS4.p1.1.m1.1.1.2.cmml" xref="S5.SS4.p1.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="S5.SS4.p1.1.m1.1.1.3a.cmml" xref="S5.SS4.p1.1.m1.1.1.3"><mtext id="S5.SS4.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S5.SS4.p1.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p1.1.m1.1c">\text{KLUE-RoBERTa}_{\text{BASE}}</annotation></semantics></math>를 사용하여 선택의 영향을 분석한다.</p>
</div>
<section id="S5.SS4.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Corpus Pseudonymization</h5>

<div id="S5.SS4.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS0.Px1.p1.1">가명화 과정에서 유입된 노이즈는 다운스트림 태스크 수행에 해로운 영향을 미칠 수 있음을 예상할 수 있다. 그러나 표 <a class="ltx_ref" href="#S5.T33" title="Table 33 ‣ Corpus Pseudonymization ‣ 5.4 Analysis of Models ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">33</span></a>에 제시된 우리의 발견은 작업의 하위 집합에 약간의 하락이 있지만 그러한 하락은 상당히 미미하다는 것을 보여준다. 이는 우리가 한 것처럼 최소한의 가명화 수준이 이미 업무 수행과 개인 정보 유출 위험의 균형을 맞추는 좋은 방법임을 시사한다.</p>
</div>
<figure id="S5.T33" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 33:</span> 전처리 단계에서 말뭉치 가명화 수행 여부에 따른 평가 결과.</figcaption>
<div id="S5.T33.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:629.7pt;height:73pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T33.5.5" class="ltx_p"><span id="S5.T33.5.5.5" class="ltx_text"> <span id="S5.T33.5.5.5.5" class="ltx_tabular ltx_align_middle"> <span id="S5.T33.5.5.5.5.6" class="ltx_tr"> <span id="S5.T33.5.5.5.5.6.1" class="ltx_td ltx_border_tt"></span> <span id="S5.T33.5.5.5.5.6.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T33.5.5.5.5.6.2.1" class="ltx_text ltx_font_bold">YNAT</span></span> <span id="S5.T33.5.5.5.5.6.3" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T33.5.5.5.5.6.3.1" class="ltx_text ltx_font_bold">KLUE-STS</span></span> <span id="S5.T33.5.5.5.5.6.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T33.5.5.5.5.6.4.1" class="ltx_text ltx_font_bold">KLUE-NLI</span></span> <span id="S5.T33.5.5.5.5.6.5" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T33.5.5.5.5.6.5.1" class="ltx_text ltx_font_bold">KLUE-NER</span></span> <span id="S5.T33.5.5.5.5.6.6" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T33.5.5.5.5.6.6.1" class="ltx_text ltx_font_bold">KLUE-RE</span></span> <span id="S5.T33.5.5.5.5.6.7" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T33.5.5.5.5.6.7.1" class="ltx_text ltx_font_bold">KLUE-DP</span></span> <span id="S5.T33.5.5.5.5.6.8" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T33.5.5.5.5.6.8.1" class="ltx_text ltx_font_bold">KLUE-MRC</span></span> <span id="S5.T33.5.5.5.5.6.9" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T33.5.5.5.5.6.9.1" class="ltx_text ltx_font_bold">WoS</span></span></span> <span id="S5.T33.5.5.5.5.5" class="ltx_tr"> <span id="S5.T33.5.5.5.5.5.6" class="ltx_td ltx_align_left"><span id="S5.T33.5.5.5.5.5.6.1" class="ltx_text ltx_font_bold">Pretraining Corpus</span></span> <span id="S5.T33.5.5.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t">F1</span> <span id="S5.T33.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">R<sup id="S5.T33.1.1.1.1.1.1.1" class="ltx_sup"><span id="S5.T33.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">P</span></sup></span> <span id="S5.T33.5.5.5.5.5.8" class="ltx_td ltx_align_center ltx_border_t">F1</span> <span id="S5.T33.5.5.5.5.5.9" class="ltx_td ltx_align_center ltx_border_t">ACC</span> <span id="S5.T33.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T33.2.2.2.2.2.2.1" class="ltx_sup"><span id="S5.T33.2.2.2.2.2.2.1.1" class="ltx_text ltx_font_italic">E</span></sup></span> <span id="S5.T33.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T33.3.3.3.3.3.3.1" class="ltx_sup"><span id="S5.T33.3.3.3.3.3.3.1.1" class="ltx_text ltx_font_italic">C</span></sup></span> <span id="S5.T33.4.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T33.4.4.4.4.4.4.1" class="ltx_sup"><span id="S5.T33.4.4.4.4.4.4.1.1" class="ltx_text ltx_font_italic">mic</span></sup></span> <span id="S5.T33.5.5.5.5.5.10" class="ltx_td ltx_align_center ltx_border_t">AUC</span> <span id="S5.T33.5.5.5.5.5.11" class="ltx_td ltx_align_center ltx_border_t">UAS</span> <span id="S5.T33.5.5.5.5.5.12" class="ltx_td ltx_align_center ltx_border_t">LAS</span> <span id="S5.T33.5.5.5.5.5.13" class="ltx_td ltx_align_center ltx_border_t">EM</span> <span id="S5.T33.5.5.5.5.5.14" class="ltx_td ltx_align_center ltx_border_t">ROUGE</span> <span id="S5.T33.5.5.5.5.5.15" class="ltx_td ltx_align_center ltx_border_t">JGA</span> <span id="S5.T33.5.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T33.5.5.5.5.5.5.1" class="ltx_sup"><span id="S5.T33.5.5.5.5.5.5.1.1" class="ltx_text ltx_font_italic">S</span></sup></span></span> <span id="S5.T33.5.5.5.5.7" class="ltx_tr"> <span id="S5.T33.5.5.5.5.7.1" class="ltx_td ltx_align_left ltx_border_t">Original</span> <span id="S5.T33.5.5.5.5.7.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.2.1" class="ltx_text ltx_font_bold">83.40</span></span> <span id="S5.T33.5.5.5.5.7.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.3.1" class="ltx_text ltx_font_bold">92.06</span></span> <span id="S5.T33.5.5.5.5.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.4.1" class="ltx_text ltx_font_bold">84.70</span></span> <span id="S5.T33.5.5.5.5.7.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.5.1" class="ltx_text ltx_font_bold">81.60</span></span> <span id="S5.T33.5.5.5.5.7.6" class="ltx_td ltx_align_center ltx_border_t">84.84</span> <span id="S5.T33.5.5.5.5.7.7" class="ltx_td ltx_align_center ltx_border_t">91.03</span> <span id="S5.T33.5.5.5.5.7.8" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.8.1" class="ltx_text ltx_font_bold">65.25</span></span> <span id="S5.T33.5.5.5.5.7.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.9.1" class="ltx_text ltx_font_bold">64.79</span></span> <span id="S5.T33.5.5.5.5.7.10" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.10.1" class="ltx_text ltx_font_bold">92.17</span></span> <span id="S5.T33.5.5.5.5.7.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.11.1" class="ltx_text ltx_font_bold">88.34</span></span> <span id="S5.T33.5.5.5.5.7.12" class="ltx_td ltx_align_center ltx_border_t">62.13</span> <span id="S5.T33.5.5.5.5.7.13" class="ltx_td ltx_align_center ltx_border_t">67.46</span> <span id="S5.T33.5.5.5.5.7.14" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.14.1" class="ltx_text ltx_font_bold">47.14</span></span> <span id="S5.T33.5.5.5.5.7.15" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T33.5.5.5.5.7.15.1" class="ltx_text ltx_font_bold">91.60</span></span></span> <span id="S5.T33.5.5.5.5.8" class="ltx_tr"> <span id="S5.T33.5.5.5.5.8.1" class="ltx_td ltx_align_left ltx_border_bb">Pseudonymized</span> <span id="S5.T33.5.5.5.5.8.2" class="ltx_td ltx_align_center ltx_border_bb">83.39</span> <span id="S5.T33.5.5.5.5.8.3" class="ltx_td ltx_align_center ltx_border_bb">91.11</span> <span id="S5.T33.5.5.5.5.8.4" class="ltx_td ltx_align_center ltx_border_bb">82.85</span> <span id="S5.T33.5.5.5.5.8.5" class="ltx_td ltx_align_center ltx_border_bb">78.50</span> <span id="S5.T33.5.5.5.5.8.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T33.5.5.5.5.8.6.1" class="ltx_text ltx_font_bold">84.99</span></span> <span id="S5.T33.5.5.5.5.8.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T33.5.5.5.5.8.7.1" class="ltx_text ltx_font_bold">91.22</span></span> <span id="S5.T33.5.5.5.5.8.8" class="ltx_td ltx_align_center ltx_border_bb">62.79</span> <span id="S5.T33.5.5.5.5.8.9" class="ltx_td ltx_align_center ltx_border_bb">62.96</span> <span id="S5.T33.5.5.5.5.8.10" class="ltx_td ltx_align_center ltx_border_bb">92.02</span> <span id="S5.T33.5.5.5.5.8.11" class="ltx_td ltx_align_center ltx_border_bb">88.02</span> <span id="S5.T33.5.5.5.5.8.12" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T33.5.5.5.5.8.12.1" class="ltx_text ltx_font_bold">62.88</span></span> <span id="S5.T33.5.5.5.5.8.13" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T33.5.5.5.5.8.13.1" class="ltx_text ltx_font_bold">67.58</span></span> <span id="S5.T33.5.5.5.5.8.14" class="ltx_td ltx_align_center ltx_border_bb">46.21</span> <span id="S5.T33.5.5.5.5.8.15" class="ltx_td ltx_align_center ltx_border_bb">91.23</span></span> </span></span></p>
</span></div>
</figure>
<figure id="S5.T34" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 34:</span>우리의 토큰화 전략을 다른 베이스라인과 비교한다.</figcaption>
<div id="S5.T34.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:660.9pt;height:73pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T34.5.5" class="ltx_p"><span id="S5.T34.5.5.5" class="ltx_text"> <span id="S5.T34.5.5.5.5" class="ltx_tabular ltx_align_middle"> <span id="S5.T34.5.5.5.5.6" class="ltx_tr"> <span id="S5.T34.5.5.5.5.6.1" class="ltx_td ltx_border_tt"></span> <span id="S5.T34.5.5.5.5.6.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T34.5.5.5.5.6.2.1" class="ltx_text ltx_font_bold">YNAT</span></span> <span id="S5.T34.5.5.5.5.6.3" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T34.5.5.5.5.6.3.1" class="ltx_text ltx_font_bold">KLUE-STS</span></span> <span id="S5.T34.5.5.5.5.6.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T34.5.5.5.5.6.4.1" class="ltx_text ltx_font_bold">KLUE-NLI</span></span> <span id="S5.T34.5.5.5.5.6.5" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T34.5.5.5.5.6.5.1" class="ltx_text ltx_font_bold">KLUE-NER</span></span> <span id="S5.T34.5.5.5.5.6.6" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T34.5.5.5.5.6.6.1" class="ltx_text ltx_font_bold">KLUE-RE</span></span> <span id="S5.T34.5.5.5.5.6.7" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T34.5.5.5.5.6.7.1" class="ltx_text ltx_font_bold">KLUE-DP</span></span> <span id="S5.T34.5.5.5.5.6.8" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T34.5.5.5.5.6.8.1" class="ltx_text ltx_font_bold">KLUE-MRC</span></span> <span id="S5.T34.5.5.5.5.6.9" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="S5.T34.5.5.5.5.6.9.1" class="ltx_text ltx_font_bold">WoS</span></span></span> <span id="S5.T34.5.5.5.5.5" class="ltx_tr"> <span id="S5.T34.5.5.5.5.5.6" class="ltx_td ltx_align_left"><span id="S5.T34.5.5.5.5.5.6.1" class="ltx_text ltx_font_bold">Tokenization</span></span> <span id="S5.T34.5.5.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t">F1</span> <span id="S5.T34.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">R<sup id="S5.T34.1.1.1.1.1.1.1" class="ltx_sup"><span id="S5.T34.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">P</span></sup></span> <span id="S5.T34.5.5.5.5.5.8" class="ltx_td ltx_align_center ltx_border_t">F1</span> <span id="S5.T34.5.5.5.5.5.9" class="ltx_td ltx_align_center ltx_border_t">ACC</span> <span id="S5.T34.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T34.2.2.2.2.2.2.1" class="ltx_sup"><span id="S5.T34.2.2.2.2.2.2.1.1" class="ltx_text ltx_font_italic">E</span></sup></span> <span id="S5.T34.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T34.3.3.3.3.3.3.1" class="ltx_sup"><span id="S5.T34.3.3.3.3.3.3.1.1" class="ltx_text ltx_font_italic">C</span></sup></span> <span id="S5.T34.4.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T34.4.4.4.4.4.4.1" class="ltx_sup"><span id="S5.T34.4.4.4.4.4.4.1.1" class="ltx_text ltx_font_italic">mic</span></sup></span> <span id="S5.T34.5.5.5.5.5.10" class="ltx_td ltx_align_center ltx_border_t">AUC</span> <span id="S5.T34.5.5.5.5.5.11" class="ltx_td ltx_align_center ltx_border_t">UAS</span> <span id="S5.T34.5.5.5.5.5.12" class="ltx_td ltx_align_center ltx_border_t">LAS</span> <span id="S5.T34.5.5.5.5.5.13" class="ltx_td ltx_align_center ltx_border_t">EM</span> <span id="S5.T34.5.5.5.5.5.14" class="ltx_td ltx_align_center ltx_border_t">ROUGE</span> <span id="S5.T34.5.5.5.5.5.15" class="ltx_td ltx_align_center ltx_border_t">JGA</span> <span id="S5.T34.5.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="S5.T34.5.5.5.5.5.5.1" class="ltx_sup"><span id="S5.T34.5.5.5.5.5.5.1.1" class="ltx_text ltx_font_italic">S</span></sup></span></span> <span id="S5.T34.5.5.5.5.7" class="ltx_tr"> <span id="S5.T34.5.5.5.5.7.1" class="ltx_td ltx_align_left ltx_border_t">BPE</span> <span id="S5.T34.5.5.5.5.7.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T34.5.5.5.5.7.2.1" class="ltx_text ltx_font_bold">83.40</span></span> <span id="S5.T34.5.5.5.5.7.3" class="ltx_td ltx_align_center ltx_border_t">91.91</span> <span id="S5.T34.5.5.5.5.7.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T34.5.5.5.5.7.4.1" class="ltx_text ltx_font_bold">85.19</span></span> <span id="S5.T34.5.5.5.5.7.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T34.5.5.5.5.7.5.1" class="ltx_text ltx_font_bold">82.07</span></span> <span id="S5.T34.5.5.5.5.7.6" class="ltx_td ltx_align_center ltx_border_t">68.75</span> <span id="S5.T34.5.5.5.5.7.7" class="ltx_td ltx_align_center ltx_border_t">89.47</span> <span id="S5.T34.5.5.5.5.7.8" class="ltx_td ltx_align_center ltx_border_t">64.39</span> <span id="S5.T34.5.5.5.5.7.9" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T34.5.5.5.5.7.9.1" class="ltx_text ltx_font_bold">65.04</span></span> <span id="S5.T34.5.5.5.5.7.10" class="ltx_td ltx_align_center ltx_border_t">89.89</span> <span id="S5.T34.5.5.5.5.7.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T34.5.5.5.5.7.11.1" class="ltx_text ltx_font_bold">89.47</span></span> <span id="S5.T34.5.5.5.5.7.12" class="ltx_td ltx_align_center ltx_border_t">51.12</span> <span id="S5.T34.5.5.5.5.7.13" class="ltx_td ltx_align_center ltx_border_t">65.79</span> <span id="S5.T34.5.5.5.5.7.14" class="ltx_td ltx_align_center ltx_border_t">21.38</span> <span id="S5.T34.5.5.5.5.7.15" class="ltx_td ltx_align_center ltx_border_t">77.68</span></span> <span id="S5.T34.5.5.5.5.8" class="ltx_tr"> <span id="S5.T34.5.5.5.5.8.1" class="ltx_td ltx_align_left ltx_border_bb">Morpheme-based Subword</span> <span id="S5.T34.5.5.5.5.8.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.2.1" class="ltx_text ltx_font_bold">83.40</span></span> <span id="S5.T34.5.5.5.5.8.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.3.1" class="ltx_text ltx_font_bold">92.06</span></span> <span id="S5.T34.5.5.5.5.8.4" class="ltx_td ltx_align_center ltx_border_bb">84.70</span> <span id="S5.T34.5.5.5.5.8.5" class="ltx_td ltx_align_center ltx_border_bb">81.60</span> <span id="S5.T34.5.5.5.5.8.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.6.1" class="ltx_text ltx_font_bold">84.84</span></span> <span id="S5.T34.5.5.5.5.8.7" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.7.1" class="ltx_text ltx_font_bold">91.03</span></span> <span id="S5.T34.5.5.5.5.8.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.8.1" class="ltx_text ltx_font_bold">65.25</span></span> <span id="S5.T34.5.5.5.5.8.9" class="ltx_td ltx_align_center ltx_border_bb">64.79</span> <span id="S5.T34.5.5.5.5.8.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.10.1" class="ltx_text ltx_font_bold">92.17</span></span> <span id="S5.T34.5.5.5.5.8.11" class="ltx_td ltx_align_center ltx_border_bb">88.34</span> <span id="S5.T34.5.5.5.5.8.12" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.12.1" class="ltx_text ltx_font_bold">62.13</span></span> <span id="S5.T34.5.5.5.5.8.13" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.13.1" class="ltx_text ltx_font_bold">67.46</span></span> <span id="S5.T34.5.5.5.5.8.14" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.14.1" class="ltx_text ltx_font_bold">47.14</span></span> <span id="S5.T34.5.5.5.5.8.15" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T34.5.5.5.5.8.15.1" class="ltx_text ltx_font_bold">91.60</span></span></span> </span></span></p>
</span></div>
</figure>
</section>
<section id="S5.SS4.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Tokenization Strategy</h5>

<div id="S5.SS4.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS0.Px2.p1.1">토큰화 기법인 <span class="ltx_text ltx_font_italic" id="S5.SS4.SSS0.Px2.p1.1.1">morpheme 기반 서브워드</span> tokenization을 표준 바이트 쌍 인코딩(BPE)과 대조합니다. 먼저, 단어가 하위 단어 토큰으로 분할되는 방식의 차이를 조사한다. <cite class="ltx_cite ltx_citemacro_citet">Rust et al. [<a class="ltx_ref" href="#bib.bib119" title="">119</a>]</cite>에 이어 하위 단어 번식력, 계속된 단어의 비율 및 <span class="ltx_text ltx_font_typewriter" id="S5.SS4.SSS0.Px2.p1.1.2">UNK</span> 비율을 고려한다. 단어당 평균 생성된 서브워드의 수를 측정하는 서브워드 비옥도(subword fertility)에서 제안된 토큰화 기법은 BPE보다 약간 높게 나타난다. 다만 적어도 두 개의 하위 단어로 쪼개진 단어의 수를 측정하는 지속어 비율을 보면 반대의 경향을 관찰한다. 이는 본 논문에서 제안한 알고리즘이 원래 단어를 최대한 유지하고 필요할 때만 각 단어를 잠재적으로 더 많은 하위 단어 조각으로 분할한다는 것을 의미한다. BPE에 대한 제안된 기법의 효능은 두 방법 모두에서 어휘 크기가 32k로 제어되었을 때 BPE에 비해 더 적은 <span class="ltx_text ltx_font_typewriter" id="S5.SS4.SSS0.Px2.p1.1.3">UNK</span> 비율을 생성하기 때문에 <span class="ltx_text ltx_font_typewriter" id="S5.SS4.SSS0.Px2.p1.1.4">UNK</span> 토큰에서 분명하다. Table <a class="ltx_ref" href="#S5.T35" title="Table 35 ‣ Tokenization Strategy ‣ 5.4 Analysis of Models ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">35</span></a>를 참조한다.</p>
</div>
<figure id="S5.T35" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">표 35:</span>Overview of tokenization metrics. MODU 코퍼스를 사용하여 각 어휘를 구축하고 WIKIPEDIA 코퍼스에서 비교한다.</figcaption>
<div id="S5.T35.3" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:371.9pt;height:54pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="S5.T35.3.3" class="ltx_p"><span id="S5.T35.3.3.3" class="ltx_text"> <span id="S5.T35.3.3.3.3" class="ltx_tabular ltx_align_middle"> <span id="S5.T35.3.3.3.3.3" class="ltx_tr"> <span id="S5.T35.3.3.3.3.3.4" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T35.3.3.3.3.3.4.1" class="ltx_text ltx_font_bold">Tokenization</span></span> <span id="S5.T35.3.3.3.3.3.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T35.3.3.3.3.3.5.1" class="ltx_text ltx_font_bold"># Vocabs</span></span> <span id="S5.T35.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T35.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Fertility <math id="S5.T35.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T35.1.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S5.T35.1.1.1.1.1.1.1.m1.1.1" xref="S5.T35.1.1.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T35.1.1.1.1.1.1.1.m1.1b"><ci id="S5.T35.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.T35.1.1.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T35.1.1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math></span></span> <span id="S5.T35.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T35.2.2.2.2.2.2.1" class="ltx_text ltx_font_bold">% Continued Word <math id="S5.T35.2.2.2.2.2.2.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S5.T35.2.2.2.2.2.2.1.m1.1a"><mo stretchy="false" id="S5.T35.2.2.2.2.2.2.1.m1.1.1" xref="S5.T35.2.2.2.2.2.2.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S5.T35.2.2.2.2.2.2.1.m1.1b"><ci id="S5.T35.2.2.2.2.2.2.1.m1.1.1.cmml" xref="S5.T35.2.2.2.2.2.2.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T35.2.2.2.2.2.2.1.m1.1c">\uparrow</annotation></semantics></math></span></span> <span id="S5.T35.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T35.3.3.3.3.3.3.1" class="ltx_text ltx_font_bold">UNK Ratio <math id="S5.T35.3.3.3.3.3.3.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S5.T35.3.3.3.3.3.3.1.m1.1a"><mo stretchy="false" id="S5.T35.3.3.3.3.3.3.1.m1.1.1" xref="S5.T35.3.3.3.3.3.3.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S5.T35.3.3.3.3.3.3.1.m1.1b"><ci id="S5.T35.3.3.3.3.3.3.1.m1.1.1.cmml" xref="S5.T35.3.3.3.3.3.3.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T35.3.3.3.3.3.3.1.m1.1c">\downarrow</annotation></semantics></math></span></span></span> <span id="S5.T35.3.3.3.3.4" class="ltx_tr"> <span id="S5.T35.3.3.3.3.4.1" class="ltx_td ltx_align_left ltx_border_t">BPE</span> <span id="S5.T35.3.3.3.3.4.2" class="ltx_td ltx_align_center ltx_border_t">32k</span> <span id="S5.T35.3.3.3.3.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T35.3.3.3.3.4.3.1" class="ltx_text ltx_font_bold">2.073</span></span> <span id="S5.T35.3.3.3.3.4.4" class="ltx_td ltx_align_center ltx_border_t">0.578</span> <span id="S5.T35.3.3.3.3.4.5" class="ltx_td ltx_align_center ltx_border_t">0.011</span></span> <span id="S5.T35.3.3.3.3.5" class="ltx_tr"> <span id="S5.T35.3.3.3.3.5.1" class="ltx_td ltx_align_left ltx_border_bb">Morpheme-based Subword</span> <span id="S5.T35.3.3.3.3.5.2" class="ltx_td ltx_align_center ltx_border_bb">32k</span> <span id="S5.T35.3.3.3.3.5.3" class="ltx_td ltx_align_center ltx_border_bb">2.468</span> <span id="S5.T35.3.3.3.3.5.4" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T35.3.3.3.3.5.4.1" class="ltx_text ltx_font_bold">0.765</span></span> <span id="S5.T35.3.3.3.3.5.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T35.3.3.3.3.5.5.1" class="ltx_text ltx_font_bold">0.009</span></span></span> </span></span></p>
</span></div>
</figure>
<div id="S5.SS4.SSS0.Px2.p2" class="ltx_para">
<p class="ltx_p" id="S5.SS4.SSS0.Px2.p2.1">KLUE-NER, KLUE-MRC, WoS의 경우 두 기법 간의 정성적 차이가 태스크 성능에 상당한 차이를 가져온다는 것을 알 수 있다. 이러한 작업은 종종 형태소 수준에서 태깅, 탐지 및 생성까지 포함하며 형태학적으로 일관된 토큰화가 전반적으로 더 나은 예측을 촉진한다고 의심한다. 반면에, 토큰화 전략의 차이는 분류 또는 단어-레벨 태깅의 성능에서 나타나지 않는데, 이는 대응하는 NLU 시스템이 서브워드 토큰 표현을 더 큰 유닛의 표현으로 병합할 때 서브워드 세그먼테이션에서의 불일치를 더 쉽게 극복할 수 있기 때문이다. 전반적으로 향후 연구자들은 제안된 토큰화 전략을 기본 옵션으로 사용할 것을 권장한다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Ethical Considerations</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p" id="S6.p1.1">KLUE를 구축하고 기본 모델을 동반할 때 데이터와 모델을 모두 공개하는 데 있어 유해하고 부정적인 결과를 피하기 위해 다양한 메커니즘을 통합했다. 이러한 메커니즘은 도입되고 사용되는 곳마다 자세히 설명되지만 이 섹션에서는 이러한 메커니즘, 고려 사항 및 그 뒤에 있는 원칙을 요약한다.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Copyright and Accessibility</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS1.p1.1">대부분의 NLP 데이터 세트는 기존 텍스트 소스를 기반으로 구축됩니다. 이는 특히 기본 소스 데이터 세트가 잘 지정되지 않거나 신중하게 조사되지 않을 때 이러한 데이터 세트를 사용하는 조건에 대한 질문을 제기한다. KLUE를 사용하는 조건에 대한 이러한 의심을 피하고 한국어로 NLP 연구를 가속화하기 위해 12월에 시행된 한국의 저작권법을 완전히 고수한다. 8, 2020.<span class="ltx_note ltx_role_footnote" id="footnote64"><sup class="ltx_note_mark">64</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">64</sup><span class="ltx_tag ltx_tag_note">64</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.law.go.kr/%EB%B2%95%EB%A0%B9/%EC%A0%80%EC%9E%91%EA%B6%8C%EB%B2%95" target="_blank" title="">https://www.law.go.kr/%EB%B2%95%EB%A0%B9/%EC%A0%80%EC%9E%91%EA%B6%8C%EB%B2%95</a> </span></span></span> 및 사용 제한 없이 재배포 및 재혼합을 모두 허용하는 라이선스 하에 릴리스할 수 있는 텍스트만 포함합니다.</p>
</div>
<section id="S6.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Source Corpora</h5>

<div id="S6.SS1.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS0.Px1.p1.1">우리의 목표는 벤치마크의 지속적인 가용성과 유용성을 확보하고 극대화하는 것입니다. 즉, CC BY-SA와 함께 새로운 작품의 도출 가능성을 보장하고 자유롭게 재분배해야 한다. CC BY-SA에서 KLUE를 공개하기 위해 1) 저작권에 의해 보호되지 않는 텍스트 또는 2) CC0, CC BY, CC BY-SA 또는 KOGL 유형 1 라이선스에 따라 텍스트만 포함하여 소스 코퍼스 세트를 구축했다. 저작권이 있는 뉴스 기사의 경우 KLUE-MRC를 만들어 CC BY-SA로 공개할 수 있는 사업자, 한국경제신문(KED) 뉴스 매체, 아크로판과 계약을 맺었다.</p>
</div>
</section>
<section id="S6.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Task-Specific (Annotated) Datasets</h5>

<div id="S6.SS1.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS0.Px2.p1.1">각 KLUE 벤치마크 작업에 대해 소스 코퍼스를 서브샘플링하고 주석을 달습니다. CC BY-SA로 각각 출시합니다. 이는 파생상품이 동일한 라이선스(CC BY-SA) 하에 배포되는 한, KLUE 벤치암크 사용자가 상업적 및 비상업적 목적 모두를 위해 복제, 재분배, 리믹스, 변환 및 구축하도록 허용한다. 이를 통해 향후 NLP 연구 및 개발이 크게 촉진될 것으로 기대한다.</p>
</div>
</section>
<section id="S6.SS1.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pretraining Corpora and Language Models</h5>

<div id="S6.SS1.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS1.SSS0.Px3.p1.1">앞서 논의한 바와 같이, MODU, CC-100-Kor 및 NEWSCRAWL을 사용하여 구축된 사전 훈련 코퍼스가 모두 공개적으로 사용 가능한 텍스트에서 생성되지만 저작권이 있는 저작물을 포함하지 않는다는 것을 보장할 수 없다. 불행히도 이러한 말뭉치가 없으면 한국어에 대한 대규모 언어 모델을 훈련할 수 있을 만큼 충분히 큰 자원을 찾을 수 없다. 따라서 사전 훈련에 사용하지만 KLUE와 대조되는 향후 문제를 피하기 위해 사전 훈련 코퍼스를 공개적으로 공개하지 않는다. 대신, 우리는 미래의 연구를 용이하게 하기 위해 미리 훈련된 언어 모델을 공개적으로 공개합니다. 언어 모델의 파라미터가 <span class="ltx_text ltx_font_italic" id="S6.SS1.SSS0.Px3.p1.1.1">[express] human thoughts and emotions</span> 이므로 저작권의 요건을 충족하지 못한다.</p>
</div>
</section>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Toxic Content</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS2.p1.1">대규모의 접근 가능한 벤치마크 데이터 세트는 기계 학습과 그 응용을 자연 언어 처리, 독성 및 이러한 데이터 세트 내의 원치 않는 콘텐츠와 같은 인접 분야로 발전시키지만, 우리가 훈련하는 대규모 모델을 통해 증폭될 수 있다. 우리는 프로젝트 초기부터 이 문제를 인식하고 여기에서 KLUE에서 이러한 독성 내용물을 어떻게 다루었는지 설명한다.</p>
</div>
<section id="S6.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Task-Specific Datasets</h5>

<div id="S6.SS2.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS2.SSS0.Px1.p1.1">각 작업별 데이터 세트에 대해 독성 콘텐츠의 도입을 최소화하기 위해 세 단계를 적용한다. 먼저, 독성 분류기를 이용하여 혐오 발언과 젠더 편향된 문장을 자동으로 검출하고, 주석용으로 이들 문장을 보내기 전이라도 제거한다(<a class="ltx_ref" href="#S2.SS3.SSS0.Px3" title="PII Removal ‣ 2.3 Preprocessing ‣ 2 Source Corpora ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">2.3</span></a> 섹션 참조). 둘째, 편향과 혐오 발언에 대한 명확한 정의를 제공한 후, 사회적 편향을 나타내고/하거나 독성이 있는 인스턴스를 표시하도록 주석자에게 명시적이고 명확하게 지시한다(섹션 <a class="ltx_ref" href="#S3" title="3 KLUE Benchmark ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">3</span></a> 참조). 마지막으로, 이러한 표시된 문장을 수동으로 검사하고 최종 데이터 세트에서 제외한다. 이 3단계 프로세스는 가능한 모든 인스턴스를 포착하지 못할 수 있으며 온라인 포럼 <span class="ltx_note ltx_role_footnote" id="footnote65"><sup class="ltx_note_mark">65</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">65</sup><span class="ltx_tag ltx_tag_note">65</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/KLUE-benchmark/KLUE/issues" target="_blank" title="">https://github.com/KLUE-benchmark/KLUE/issues</a></span></span></span>을 사용하여 KLUE 사용자의 피드백 및 불만을 받을 계획이다.</p>
</div>
</section>
<section id="S6.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pretrained Language Models</h5>

<div id="S6.SS2.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS2.SSS0.Px2.p1.1">우리는 세 가지 이유로 사전 훈련 말뭉치(섹션 <a class="ltx_ref" href="#S4.SS1.SSS0.Px1" title="Pretraining Corpora ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">4.1</span></a> 참조)를 그대로 사용한다. 첫째, 수동 검사는 순전히 눈금 때문에 다루기 어렵다. 둘째, 혐오표현과 편향된 문장을 탐지할 수 있는 자동화된 도구를 구축하는 것이 어렵다. 이 문제는 제한된 크기 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib92" title="">92</a>]</cite>의 알려진 증오 음성 데이터 세트가 하나뿐이기 때문에 한국어에 대해 훨씬 더 심각하다. 마지막으로, 이러한 사전 훈련된 언어 모델이 바람직하지 않은 사회적 편견뿐만 아니라 다양한 독성 콘텐츠를 자동으로 탐지하기 위한 더 나은 도구를 구축하는 데 사용될 미래를 상상한다. 이러한 사전 훈련된 모델이 이러한 문제를 인식하려면 이러한 독성 내용물로도 훈련되었을 것이다.</p>
</div>
</section>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Personally Identifiable Information</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS3.p1.1">최근에 대규모의 사전 훈련된 언어 모델이 대량의 개인 식별 정보(PII)를 암기하고 이러한 개인 정보를 검색하도록 알고리즘을 설계할 수 있다는 것이 발견되었다. 따라서 우리는 작업별 데이터 세트를 가명화하고 말뭉치를 사전 훈련하기 위해 각각 두 가지 다른 접근법을 설계한다.</p>
</div>
<section id="S6.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Task-Specific Datasets</h5>

<div id="S6.SS3.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS3.SSS0.Px1.p1.1">작업별 데이터 세트의 경우 주석 중 수동 검사에 의존하여 PII를 감지한다. 수동 검사 후 PII가 포함된 것으로 보고된 모든 문장은 폐기한다. 시뮬레이션된 대화 상자에 의존하는 DST의 경우 <span class="ltx_text ltx_font_typewriter" id="S6.SS3.SSS0.Px1.p1.1.1">faker</span> 라이브러리를 사용하여 실제 텍스트가 아닌 데이터베이스 항목을 가명 처리합니다. <span class="ltx_note ltx_role_footnote" id="footnote66"><sup class="ltx_note_mark">66</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">66</sup><span class="ltx_tag ltx_tag_note">66</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/joke2k/faker" target="_blank" title="">https://github.com/joke2k/faker</a> </span></span></span></p>
</div>
</section>
<section id="S6.SS3.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pretraining Corpora</h5>

<div id="S6.SS3.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S6.SS3.SSS0.Px2.p1.1">PII를 제거하는 것과 사전 훈련된 언어 모델의 성능 사이에는 트레이드오프가 있으며, 이는 나중에 본 논문에서 입증할 것이다. 따라서 순전히 정규식으로 감지할 수 있는 16개의 PII 유형을 가명화한다. Section <a class="ltx_ref" href="#S4.SS1.SSS0.Px2" title="Preprocessing ‣ 4.1 Language Models ‣ 4 Pretrained Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">4.1</span></a>를 참조</p>
</div>
</section>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Related Work</h2>

<section id="S7.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">General-Purpose NLU Benchmarks</h5>

<div id="S7.SS0.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS0.SSS0.Px1.p1.1">영어에 대한 평가 데이터 세트의 집합인 GLUE(General Language Understanding Evaluation) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>]</cite> 벤치마크는 NLU에 대한 최초의 범용 평가 벤치마크였다. 하나의 업무에 국한되지 않는다는 점에서 범용성이 있다. 시맨틱 텍스트 유사성(QQP, MRPC, STS) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib3" title="">3</a>, <a class="ltx_ref" href="#bib.bib13" title="">13</a>]</cite>를 캡처하는 능력을 측정하는 작업을 포함하여 11개의 다운스트림 작업으로 구성되며, 추론 능력(MNLI, QNLI, RTE, WNLI) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib8" title="">8</a>, <a class="ltx_ref" href="#bib.bib138" title="">138</a>]</cite>를 측정하고 단일 문장을 미리 정의된 범주 집합(CoLA, SST) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib134" title="">134</a>, <a class="ltx_ref" href="#bib.bib126" title="">126</a>]</cite>로 분류하는 능력을 평가한다. GLUE는 영어에만 초점을 맞추었으며, 중국어<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib142" title="">142</a>]</cite>, 프랑스어 버전<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib72" title="">72</a>]</cite>, 인도네시아어 버전<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib137" title="">137</a>]</cite>, 인도어 버전<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib57" title="">57</a>]</cite>, 러시아어 SuperGLUE<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib125" title="">125</a>]</cite>, 페르시아어 GLUE<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib61" title="">61</a>]</cite> 등 지난 몇 년 동안 서로 다른 언어의 변형이 구축되어 출시되었다. 이 모든 경우에 언어별 특성을 통합하면서 광범위한 영역과 과제를 포괄하면서 원래 GLUE의 철학을 따르기 위한 상당한 노력이 수행되었다. 한편, XGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>]</cite> 및 XTREME <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib54" title="">54</a>]</cite>와 같은 자동화된 방법에 크게 의존하여 이러한 벤치마크의 다국어 버전을 구축하려는 노력이 있었다. 언어로서의 한국어는 이러한 후자의 벤치마크의 하위 집합에 포함되었지만, 본 논문이 나오기 전까지 한국어에 대한 범용 언어 이해 평가 제품군을 구축하려는 진지한 시도는 없었다.</p>
</div>
</section>
<section id="S7.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Absence of a Standard NLU Benchmark in Korean</h5>

<div id="S7.SS0.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS0.SSS0.Px2.p1.1">본 논문까지 한국어로 된 과제별 벤치마크가 다수 제안되어 발표되었다. 예를 들어, 감성 분류에는 NSMC가 사용되고, 패러프레이즈 검출에는 PAWS-X <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib144" title="">144</a>]</cite>가 사용되며, NLI와 STS는 KorNLI와 KorSTS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib45" title="">45</a>]</cite>가 사용되며, MRC는 KorQuAD 1과 2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib79" title="">79</a>, <a class="ltx_ref" href="#bib.bib63" title="">63</a>]</cite>가 사용되며, BEEP가 사용된다. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib92" title="">92</a>]</cite> for hate speech detection. 이 시점에서 KLUE를 구축하기 위해 이러한 데이터 세트를 단순히 집계하는 것이 더 쉽고 편리했을지 궁금할 수 있다. 결국, 이것은 단일 언어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>]</cite> 뿐만 아니라 다중 언어 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib78" title="">78</a>, <a class="ltx_ref" href="#bib.bib54" title="">54</a>]</cite> 벤치마크를 구성하기 위한 인기 있는 전략이었다. 불행히도 이 접근법은 우리가 이 논문에서 직접 다루는 두 가지 주요 문제와 함께 제공된다.</p>
</div>
<div id="S7.SS0.SSS0.Px2.p2" class="ltx_para">
<p class="ltx_p" id="S7.SS0.SSS0.Px2.p2.1">첫째, 기존의 데이터셋은 다른 데이터셋과 그 속성을 고려하지 않고 개별적으로 구축한다. 즉, 이러한 개별 데이터 세트의 집합은 도메인 및 스타일의 광범위한 범위를 갖도록 다운스트림 작업에 대한 하위 집합뿐만 아니라 소스 말뭉치를 주의 깊게 선별하는 KLUE와 달리 광범위한 도메인 및 쓰기 스타일을 포함할 가능성이 없다. 이는 영역과 양식뿐만 아니라 평가 중인 언어 현상에 대한 취재를 넘어서는 것이다. 위에서 열거한 기존 벤치마크의 대부분은 구문보다는 의미론에 초점을 맞추고 있으며, 화용론을 포착하는 널리 이용 가능한 벤치마크는 찾아보기 어렵다. 우리는 다운스트림 작업 세트를 신중하게 선택하여 이 문제를 해결합니다.</p>
</div>
<div id="S7.SS0.SSS0.Px2.p3" class="ltx_para">
<p class="ltx_p" id="S7.SS0.SSS0.Px2.p3.1">둘째, 이러한 기존 데이터 세트는 항상 공개적으로 사용할 수 있는 것은 아니며, <span class="ltx_note ltx_role_footnote" id="footnote67"><sup class="ltx_note_mark">67</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">67</sup><span class="ltx_tag ltx_tag_note">67</span> Some of these are publicly available in Korea but not internationally. </span></span></span> 및 일부는 재배포 또는 원본 변환을 금지하는 매우 제한적인 라이선스로 배포된다. 이들은 종종 정부 산하 기관에서 출판하고 발표하는 것입니다. 비한국인 연구자가 쉽게 접근할 수 없는 데이터셋에 접근할 수 있는 특별한 허가를 받아야 하는 경우도 있다. 우리는 소스 말뭉치의 신중한 큐레이션과 출판사와의 직접적인 계약에 의해 CC BY-SA에 따라 전체 벤치마크 데이터를 공개함으로써 KLUE의 이러한 모든 문제를 해결한다.</p>
</div>
</section>
<section id="S7.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pretrained Language Models (PLMs)</h5>

<div id="S7.SS0.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS0.SSS0.Px3.p1.1">최근 대규모 사전 훈련 언어 모델의 경향은 GLUE 및 기타 유사한 NLU 벤치마크에서 ELMo <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib104" title="">104</a>]</cite>, GPT-2 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib110" title="">110</a>]</cite> 및 BERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite>와 같은 이전 모델의 성공으로 촉발되었다. 이러한 초기 성공은 XLNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib146" title="">146</a>]</cite>, ALBERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib71" title="">71</a>]</cite>, RoBERTa <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib82" title="">82</a>]</cite>, ELECTRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib22" title="">22</a>]</cite>, Deberta <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib49" title="">49</a>]</cite>를 포함한 대규모 언어 모델의 일련의 발전으로 이어졌으며, 다시 크게 표준화된 벤치마크의 가용성에 의해 주도되었다. 이는 모델 크기뿐만 아니라 학습 알고리즘 측면에서도 언어 모델의 발전으로 기존 언어 이해 벤치마크를 구축하고 개선하는 데 관심을 불러일으켰다. 최근 출시된 도전적인 벤치마크로는 SuperGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib132" title="">132</a>]</cite>와 KILT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib105" title="">105</a>]</cite>가 있다. 본 논문의 KLUE와 같은 표준 언어 이해 벤치마크의 가용성은 한국어 이해를 위한 이러한 선순환을 시작할 것으로 기대된다.</p>
</div>
</section>
<section id="S7.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Pretrained Language Models for Korean</h5>

<div id="S7.SS0.SSS0.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S7.SS0.SSS0.Px4.p1.1">다른 언어와 다국어 모델의 발전에 영감을 받은 한국어용 PLM은 여러 연구 그룹과 개인에 의해 훈련되고 출시되었다. SKT는 KoBERT,<span class="ltx_note ltx_role_footnote" id="footnote68"><sup class="ltx_note_mark">68</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">68</sup><span class="ltx_tag ltx_tag_note">68</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/SKTBrain/KoBERT" target="_blank" title="">https://github.com/SKTBrain/KoBERT</a> </span></span></span>을 출시했으며 ETRI의 KorBERT<span class="ltx_note ltx_role_footnote" id="footnote69"><sup class="ltx_note_mark">69</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">69</sup><span class="ltx_tag ltx_tag_note">69</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aiopen.etri.re.kr/service_dataset.php" target="_blank" title="">https://aiopen.etri.re.kr/service_dataset.php</a> </span></span></span>, TwoBlock AI의 HanBERT<span class="ltx_note ltx_role_footnote" id="footnote70"><sup class="ltx_note_mark">70</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">70</sup><span class="ltx_tag ltx_tag_note">70</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/tbai2019/HanBert-54k-N" target="_blank" title="">https://github.com/tbai2019/HanBert-54k-N</a> </span></span></span>, 서울대학교의 KR-BERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib75" title="">75</a>]</cite>를 출시했다. KoELECTRA <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib102" title="">102</a>]</cite>와 KcBERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib73" title="">73</a>]</cite>와 같이 개별 연구자가 발표한 몇 가지 사전 학습 모델이 있다.</p>
</div>
<div id="S7.SS0.SSS0.Px4.p2" class="ltx_para">
<p class="ltx_p" id="S7.SS0.SSS0.Px4.p2.1">불행히도 한국어로 표준화된 벤치마크가 없기 때문에 한국어로 사전 훈련된 언어 모델의 흐름을 어떻게 비교해야 하는지 불분명하다. 이러한 모델의 하위 집합은 위의 한국어에서 몇 가지 하향 스트림 NLP 작업의 하위 집합을 기반으로 비교되었지만 표준화되지 않았기 때문에 이러한 제한된 실험에서 확실한 결론을 내리기가 쉽지 않다. 제안된 KLUE 벤치마크는 한국어를 위한 언어 모델의 연구 진행을 추적하는 표준 방법이 될 것으로 기대한다.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Discussion</h2>

<section id="S8.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Open Access</h5>

<div id="S8.SS0.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS0.SSS0.Px1.p1.1">우리는 CC BY-SA 하에 KLUE를 배포한다. 라이센스를 사용하면 모든 사람이 모든 매체 또는 형식으로 벤치마크를 자유롭게 복사하고 재분배할 수 있습니다. 또한 성능 포화 후 더 어려운 데이터 세트를 구축하기 위해 벤치마크를 개선할 수 있다. NLU <span class="ltx_text ltx_font_italic" id="S8.SS0.SSS0.Px1.p1.1.1">benchmark</span>로 기능하려면 오픈 액세스가 필수입니다. 원저자가 벤치마크의 파생 개발을 허용하지 않는 경우 다른 연구자들은 예를 들어 독성 함량을 제거하거나 기술 개선을 위한 연구를 가속화하기 위해 더 어려운 데이터 세트를 구축하여 개선할 수 없다. 영리단체에 근무하는 연구자는 상업적 이용이 허용되지 않으면 벤치마크에 기여하거나 (쉽게) 기여할 수 없을 것이다. 예를 들어 데이터 세트를 다른 연구자와 공유하는 것이 금지되면 연구를 상당히 제한하기 때문에 재분배는 또 다른 중요한 요소이다. 관련 갈등의 저작권 침해 책임을 연구자에게 전가하는 것이 연구를 제한하는 또 다른 관행이다. 데이터의 오픈 액세스에 대한 좋은 선례를 설정하기 위해 우리는 데이터 세트를 1) 모든 목적, 2) 파생 작업 및 3)에 사용할 수 있다. 벤치마크 데이터 세트의 기존 저작권이 존중되는 한 재배포. 또한 사전 훈련된 한국어 모델과 사전 훈련 및 미세 조정 파이프라인의 구현을 엽니다. 이를 통해 작업의 재현성을 높이고 누구나 데이터와 모델을 수정하고 개선할 수 있습니다. 우리는 한국 NLP 연구 커뮤니티와 더 넓은 NLP 커뮤니티에 기여하기를 바란다.</p>
</div>
</section>
<section id="S8.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Facilitating Korean NLP Research</h5>

<div id="S8.SS0.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS0.SSS0.Px2.p1.1">최근 대형 한국어 모델의 활발한 개발 노력에 부응하여 한국어 NLP 연구를 용이하게 하기 위한 목적으로 KLUE를 개발하였다. 전체 NLP 커뮤니티는 BERT <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib30" title="">30</a>]</cite> 및 그 변이체가 GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>]</cite> 및 SuperGLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib132" title="">132</a>]</cite>에 대한 이전 NLU 모델을 능가하는 것은 물론, 보다 최근의 GPT3 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib9" title="">9</a>]</cite>도 미세 조정 없이 뛰어난 성능을 보였다(그리고 <span class="ltx_text ltx_font_italic" id="S8.SS0.SSS0.Px2.p1.1.1">in-context learning</span>). 이러한 모델에 자극을 받은 여러 기관의 많은 한국 연구자들이 서둘러 대규모 트랜스포머 기반 한국어 모델을 사전 훈련시켰다. 결과적으로, 거의 동일한 사전 훈련된 언어 모델들이 오픈 소스 커뮤니티에 출시되었다. 그러나 한국어를 위한 GLUE와 같은 잘 설계된 범용 벤치마크가 없기 때문에 이러한 모델의 행동과 특성을 체계적으로 이해할 수 없었다. KLUE는 다양한 한국 LMs가 특정 작업에 대해 어떻게 그리고 왜 수행되는지 이해하기 위해 통제된 실험을 수행하여 해당 모델에 대한 자세한 통찰력을 얻을 수 있도록 한다. 또한, KLUE는 다른 언어로도 수행되는 많은 대표적인 NLU 과제를 포함하고 있기 때문에, KLUE는 한국어 및 다른 언어로 다국어 연구를 수행하는 것을 목표로 하는 NLP 연구자들에게 근본적인 자원으로 기능할 것이다.</p>
</div>
</section>
<section id="S8.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Measuring Overall Performance of NLU models</h5>

<div id="S8.SS0.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS0.SSS0.Px3.p1.1">우리는 KLUE에서 각 과제에서 얻은 모든 점수를 평균하지 않는다. 모든 작업의 성능은 다른 평가 메트릭에 의해 측정됩니다. 각 태스크에 대한 메트릭을 자신의 특성을 고려하여 신중하게 선택하기 때문이다. KLUE-MRC와 KLUE-NER은 한국어 단어 내에 엔터티가 존재할 수 있는 반면 KLUE-STS와 KLUE-NLI는 문장 수준 메트릭을 사용하기 때문에 작업별로 세분성이 다르다. 또한 F1 점수, 정확도, 곡선 아래 면적, UAS, LAS, ROUGE-W, 공동 목표 정확도 및 피어슨의 상관 관계와 같은 태스크 전반에 걸쳐 다양한 메트릭을 사용한다. 이 상황에서 GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib133" title="">133</a>]</cite>에서와 같이 모든 작업의 평균을 단순히 계산하면 전체 성능 측정이 잘못된다. 평균은 의도하지 않은 방식으로 특정 작업에 더 높은 가중치를 부여할 뿐만 아니라 해석 가능성을 잃게 된다. 이에 따라 모형의 NLU 능력을 추정할 수 있는 대안적인 방법이 필요하다. 최근 아이템 반응 이론(Item Response Theory, IRT) 프레임워크를 사용하여 모델의 예측 정확도를 분석하여 이러한 성능을 추정하는 것이 <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib70" title="">70</a>]</cite>로 제안되었으나, 벤치마크에서 정확히 어떻게 적용되어야 하는지는 명확하지 않다. 따라서 현재로서는 전체 성능 척도를 요약하지 않고 각 작업에 대한 모델을 별도로 평가하기로 결정한다. 이것이 우리의 한계이며, 우리는 이 문제를 미래로 남겨둔다.</p>
</div>
</section>
<section id="S8.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Rapid Saturation of KLUE</h5>

<div id="S8.SS0.SSS0.Px4.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS0.SSS0.Px4.p1.1">우리는 예를 들어 GLUE <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="#bib.bib94" title="">94</a>]</cite>의 관찰을 기반으로 KLUE의 빠른 포화를 예상한다. 그러나 우리는 모델에 대한 쉬운 예를 필터링하여 벤치마크를 인위적으로 어렵게 만들지 않습니다. KLUE의 주요 목적은 NLU의 다양한 측면에서 모델을 적절하게 평가하는 것이기 때문에 기본 사전 훈련 언어 모델보다 개선을 위한 헤드룸 확대에 초점을 맞추는 것을 피한다. 우리의 라이선스 정책은 한국어를 위한 첫 번째 오픈 도메인 질문 답변 구축과 같은 다른 연구자들과 함께 더 어려운 과제를 집단적으로 개발함으로써 포화 후 벤치마크의 발전에 긍정적인 영향을 미칠 것으로 기대한다.</p>
</div>
</section>
<section id="S8.SS0.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Analysis of Korean Language Models</h5>

<div id="S8.SS0.SSS0.Px5.p1" class="ltx_para">
<p class="ltx_p" id="S8.SS0.SSS0.Px5.p1.1">각 작업에 대한 기본 모델의 성능을 비교할 때 다양한 패턴을 관찰하지만, 대부분의 모델은 현상을 정확하게 설명하기 위해 연구되지 않았다. 더 철저한 조사를 통해 모델, 말뭉치, 한국어의 언어적 특성 및 향후 작업에서 훈련 메커니즘의 복잡한 상호 작용에 대한 이해도를 높일 수 있기를 바란다.</p>
</div>
</section>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9 </span>Conclusion</h2>

<div id="S9.p1" class="ltx_para">
<p class="ltx_p" id="S9.p1.1">다양한 작업을 포함하는 한국 NLU 벤치마크 제품군인 KLUE를 소개합니다. 우리는 모든 사람에게 KLUE를 개방하고 다국어 모델 및 기타 기존 오픈 소스 한국어 모델을 능가하도록 훈련된 한국어 모델도 제공합니다. 벤치마크를 만들고 처음부터 모델을 훈련하면서 처음부터 높은 기준을 설정했습니다. 벤치마크 데이터 세트를 설계하고 주석자를 엄격하게 훈련하여 개인 정보 및 혐오 발언을 포함한 잠재적인 윤리적 문제를 고려했다. 우리는 모든 벤치마크 구성 및 테스트 프로세스를 자세히 문서화했다. 또한 KLUE와 모델의 광범위한 영향과 한계에 대해 논의했다. 한계에도 불구하고 KLUE와 동반 언어 모델은 데이터 세트와 언어 모델이 어떻게 만들어지고 더 넓은 커뮤니티로 확산되어야 하는지를 설명하는 귀중한 선례를 설정함으로써 향후 한국어 NLP 연구를 촉진할 것이다.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments and Disclosure of Funding</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p" id="Sx1.p1.1">후원된 주석 비용을 업그레이드하고 리더보드를 구축했습니다. 네이버 CLOVA는 데이터 어노테이션 비용과 GPU 클라우드 컴퓨팅 인프라(NSML)를 제공했습니다. 우리는 또한 구글의 텐서플로우 연구 클라우드(TFRC)와 카카오 엔터프라이즈의 브레인클라우드에 감사한다. 세 가지 컴퓨팅 리소스를 사용하여 언어 모델을 사전 훈련하고 미세 조정했다. Scatter Lab, SelectStar, Riiid!, DeepNatural and KAIST가 후원한 데이터 주석 비용. 또한, 한국 경제와 아크로판이 MRC 데이터 세트에 대한 뉴스 기사를 지원해 주셔서 감사합니다.</p>
</div>
<div id="Sx1.p2" class="ltx_para">
<p class="ltx_p" id="Sx1.p2.1">저자들은 과제 선정과 DP 과제 논의에 대한 천음박, MRC 과제 논의에 대한 이진혁과 서민준, MRC 데이터셋에서 주석자 관리를 위해 상당한 노력을 기울인 수정김과 김동연, DP, NER, RE에서 데이터 구축을 신중하게 고려한 상아박에 대해 감사드린다. 리더보드 및 평가 시스템 구현을 위해 이준엽, 이건희, 이지호, 남대현, 조용진 씨에 대해 감사드립니다.</p>
</div>
<div id="Sx1.p3" class="ltx_para">
<p class="ltx_p" id="Sx1.p3.1">본 연구는 KAIST 기관심사위원회(#KH2020-173)에서 심사 및 승인을 받았다.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agency [2018]</span>
<span class="ltx_bibblock">
National Information&nbsp;Society Agency.

</span>
<span class="ltx_bibblock">MRC AI Dataset.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aihub.or.kr/aidata/86" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aihub.or.kr/aidata/86</a>, 2018.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agirre et&nbsp;al. [2015]</span>
<span class="ltx_bibblock">
Eneko Agirre, Carmen Banea, Claire Cardie, Daniel Cer, Mona Diab, Aitor
Gonzalez-Agirre, Weiwei Guo, Iñigo Lopez-Gazpio, Montse Maritxalar, Rada
Mihalcea, German Rigau, Larraitz Uria, and Janyce Wiebe.

</span>
<span class="ltx_bibblock">SemEval-2015 task 2: Semantic textual similarity, English,
Spanish and pilot on interpretability.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 9th International Workshop on Semantic
Evaluation (SemEval 2015)</em>, pages 252–263, Denver, Colorado, June 2015.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/S15-2045</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/S15-2045" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/S15-2045</a>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agirre et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
Eneko Agirre, Carmen Banea, Daniel Cer, Mona Diab, Aitor Gonzalez-Agirre, Rada
Mihalcea, German Rigau, and Janyce Wiebe.

</span>
<span class="ltx_bibblock">SemEval-2016 task 1: Semantic textual similarity, monolingual and
cross-lingual evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 10th International Workshop on Semantic
Evaluation (SemEval-2016)</em>, pages 497–511, San Diego, California, June
2016. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/S16-1081</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/S16-1081" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/S16-1081</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Allwood [2000]</span>
<span class="ltx_bibblock">
Jens Allwood.

</span>
<span class="ltx_bibblock">An activity based approach to pragmatics.

</span>
<span class="ltx_bibblock">In Harry Bunt and William Black, editors, <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Abduction, belief and
context in dialogue: Studies in computational pragmatics</em>, chapter&nbsp;2, pages
47–80. John Benjamins, Amsterdam, Netherlands, 2000.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baldini&nbsp;Soares et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Livio Baldini&nbsp;Soares, Nicholas FitzGerald, Jeffrey Ling, and Tom Kwiatkowski.

</span>
<span class="ltx_bibblock">Matching the blanks: Distributional similarity for relation learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 2895–2905, Florence, Italy, July 2019.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P19-1279</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P19-1279" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P19-1279</a>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bender and Friedman [2018]</span>
<span class="ltx_bibblock">
Emily&nbsp;M. Bender and Batya Friedman.

</span>
<span class="ltx_bibblock">Data statements for natural language processing: Toward mitigating
system bias and enabling better science.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
6:587–604, 2018.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00041</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/Q18-1041" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/Q18-1041</a>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bowman and Dahl [2021]</span>
<span class="ltx_bibblock">
Samuel&nbsp;R Bowman and George&nbsp;E Dahl.

</span>
<span class="ltx_bibblock">What will it take to fix benchmarking in natural language
understanding?

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2104.02145</em>, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bowman et&nbsp;al. [2015]</span>
<span class="ltx_bibblock">
Samuel&nbsp;R. Bowman, Gabor Angeli, Christopher Potts, and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">A large annotated corpus for learning natural language inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2015 Conference on Empirical Methods in
Natural Language Processing</em>, pages 632–642, Lisbon, Portugal, September
2015. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D15-1075</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D15-1075" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D15-1075</a>.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared&nbsp;D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon
Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris
Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
and Dario Amodei.

</span>
<span class="ltx_bibblock">Language models are few-shot learners.

</span>
<span class="ltx_bibblock">In H.&nbsp;Larochelle, M.&nbsp;Ranzato, R.&nbsp;Hadsell, M.&nbsp;F. Balcan, and H.&nbsp;Lin,
editors, <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume&nbsp;33,
pages 1877–1901. Curran Associates, Inc., 2020.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Budzianowski et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Paweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, Iñigo Casanueva,
Stefan Ultes, Osman Ramadan, and Milica Gašić.

</span>
<span class="ltx_bibblock">MultiWOZ - a large-scale multi-domain Wizard-of-Oz dataset
for task-oriented dialogue modelling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing</em>, pages 5016–5026, Brussels, Belgium,
October-November 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D18-1547</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D18-1547" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D18-1547</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Byrne et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Bill Byrne, Karthik Krishnamoorthi, Chinnadhurai Sankar, Arvind Neelakantan,
Ben Goodrich, Daniel Duckworth, Semih Yavuz, Amit Dubey, Kyu-Young Kim, and
Andy Cedilnik.

</span>
<span class="ltx_bibblock">Taskmaster-1: Toward a realistic and diverse dialog dataset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)</em>, pages 4516–4525, Hong Kong,
China, November 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D19-1459</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D19-1459" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D19-1459</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel
Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar
Erlingsson, et&nbsp;al.

</span>
<span class="ltx_bibblock">Extracting training data from large language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.07805</em>, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cer et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Daniel Cer, Mona Diab, Eneko Agirre, Iñigo Lopez-Gazpio, and Lucia Specia.

</span>
<span class="ltx_bibblock">SemEval-2017 task 1: Semantic textual similarity multilingual and
crosslingual focused evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 11th International Workshop on Semantic
Evaluation (SemEval-2017)</em>, pages 1–14, Vancouver, Canada, August 2017.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/S17-2001</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/S17-2001" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/S17-2001</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Hongshen Chen, Xiaorui Liu, Dawei Yin, and Jiliang Tang.

</span>
<span class="ltx_bibblock">A survey on dialogue systems: Recent advances and new frontiers.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">SIGKDD Explor. Newsl.</em>, 19(2):25–35,
November 2017.

</span>
<span class="ltx_bibblock">ISSN 1931-0145.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3166054.3166058</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1145/3166054.3166058" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3166054.3166058</a>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Pengyu Cheng, Weituo Hao, Siyang Yuan, Shijing Si, and Lawrence Carin.

</span>
<span class="ltx_bibblock">FairFil: Contrastive neural debiasing method for pretrained text
encoders.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=N6JECD-PI5w" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=N6JECD-PI5w</a>.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chinchor [1998]</span>
<span class="ltx_bibblock">
Nancy&nbsp;A. Chinchor.

</span>
<span class="ltx_bibblock">Overview of MUC-7.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Seventh Message Understanding Conference (MUC-7):
Proceedings of a Conference Held in Fairfax, Virginia, April 29 - May 1,
1998</em>, 1998.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/M98-1001" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/M98-1001</a>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et&nbsp;al. [2014]</span>
<span class="ltx_bibblock">
Kyunghyun Cho, Bart van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau,
Fethi Bougares, Holger Schwenk, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Learning phrase representations using RNN encoder–decoder for
statistical machine translation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2014 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 1724–1734, Doha, Qatar,
October 2014. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.3115/v1/D14-1179</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D14-1179" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D14-1179</a>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et&nbsp;al. [2020a]</span>
<span class="ltx_bibblock">
Won&nbsp;Ik Cho, Jong&nbsp;In Kim, Young&nbsp;Ki Moon, and Nam&nbsp;Soo Kim.

</span>
<span class="ltx_bibblock">Discourse component to sentence (DC2S): An efficient human-aided
construction of paraphrase and sentence similarity dataset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Language Resources and Evaluation
Conference</em>, pages 6819–6826, Marseille, France, May 2020a.
European Language Resources Association.

</span>
<span class="ltx_bibblock">ISBN 979-10-95546-34-4.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.lrec-1.842" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.lrec-1.842</a>.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et&nbsp;al. [2020b]</span>
<span class="ltx_bibblock">
Won&nbsp;Ik Cho, Sangwhan Moon, and Youngsook Song.

</span>
<span class="ltx_bibblock">Open Korean corpora: A practical report.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of Second Workshop for NLP Open Source Software
(NLP-OSS)</em>, pages 85–93, Online, November 2020b. Association
for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.nlposs-1.12" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.nlposs-1.12</a>.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chun et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Jayeol Chun, Na-Rae Han, Jena&nbsp;D. Hwang, and Jinho&nbsp;D. Choi.

</span>
<span class="ltx_bibblock">Building Universal Dependency treebanks in Korean.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eleventh International Conference on
Language Resources and Evaluation (LREC 2018)</em>, Miyazaki, Japan, May 2018.
European Language Resources Association (ELRA).

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/L18-1347" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/L18-1347</a>.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael
Collins, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">BoolQ: Exploring the surprising difficulty of natural yes/no
questions.

</span>
<span class="ltx_bibblock">In <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 2924–2936,
Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N19-1300</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N19-1300" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N19-1300</a>.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Kevin Clark, Minh-Thang Luong, Quoc&nbsp;V. Le, and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">ELECTRA: Pre-training text encoders as discriminators rather than
generators.

</span>
<span class="ltx_bibblock">In <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/pdf?id=r1xMH1BtvB" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/pdf?id=r1xMH1BtvB</a>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Commission [2009]</span>
<span class="ltx_bibblock">
Korea&nbsp;Copyright Commission.

</span>
<span class="ltx_bibblock">Newspapers and copyright, 2009.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Alexis Conneau, Douwe Kiela, Holger Schwenk, Loïc Barrault, and Antoine
Bordes.

</span>
<span class="ltx_bibblock">Supervised learning of universal sentence representations from
natural language inference data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 Conference on Empirical Methods in
Natural Language Processing</em>, pages 670–680, Copenhagen, Denmark, September
2017. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D17-1070</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D17-1070" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D17-1070</a>.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Alexis Conneau, Ruty Rinott, Guillaume Lample, Adina Williams, Samuel Bowman,
Holger Schwenk, and Veselin Stoyanov.

</span>
<span class="ltx_bibblock">XNLI: Evaluating cross-lingual sentence representations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing</em>, pages 2475–2485, Brussels, Belgium,
October-November 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D18-1269</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D18-1269" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D18-1269</a>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conneau et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume
Wenzek, Francisco Guzmán, Edouard Grave, Myle Ott, Luke Zettlemoyer, and
Veselin Stoyanov.

</span>
<span class="ltx_bibblock">Unsupervised cross-lingual representation learning at scale.

</span>
<span class="ltx_bibblock">In <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 8440–8451, Online, July 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.acl-main.747</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.acl-main.747" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.acl-main.747</a>.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dagan et&nbsp;al. [2006]</span>
<span class="ltx_bibblock">
Ido Dagan, Oren Glickman, and Bernardo Magnini.

</span>
<span class="ltx_bibblock">The PASCAL recognising textual entailment challenge.

</span>
<span class="ltx_bibblock">In Joaquin Quiñonero-Candela, Ido Dagan, Bernardo Magnini, and
Florence d’Alché Buc, editors, <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">Machine Learning Challenges.
Evaluating Predictive Uncertainty, Visual Object Classification, and
Recognising Tectual Entailment</em>, pages 177–190, Berlin, Heidelberg, 2006.
Springer Berlin Heidelberg.

</span>
<span class="ltx_bibblock">ISBN 978-3-540-33428-6.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">de&nbsp;Marneffe and Manning [2008]</span>
<span class="ltx_bibblock">
Marie-Catherine de&nbsp;Marneffe and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">The Stanford typed dependencies representation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">Coling 2008: Proceedings of the workshop on Cross-Framework
and Cross-Domain Parser Evaluation</em>, pages 1–8, Manchester, UK, August 2008.
Coling 2008 Organizing Committee.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/W08-1301" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W08-1301</a>.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">de&nbsp;Marneffe et&nbsp;al. [2006]</span>
<span class="ltx_bibblock">
Marie-Catherine de&nbsp;Marneffe, Bill MacCartney, and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">Generating typed dependency parses from phrase structure parses.

</span>
<span class="ltx_bibblock">In <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fifth International Conference on
Language Resources and Evaluation (LREC’06)</em>, Genoa, Italy, May 2006.
European Language Resources Association (ELRA).

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="http://www.lrec-conf.org/proceedings/lrec2006/pdf/440_pdf.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.lrec-conf.org/proceedings/lrec2006/pdf/440_pdf.pdf</a>.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">BERT: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 4171–4186,
Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N19-1423</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N19-1423" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N19-1423</a>.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Doddington et&nbsp;al. [2004]</span>
<span class="ltx_bibblock">
George Doddington, Alexis Mitchell, Mark Przybocki, Lance Ramshaw, Stephanie
Strassel, and Ralph Weischedel.

</span>
<span class="ltx_bibblock">The automatic content extraction (ACE) program – tasks, data,
and evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fourth International Conference on
Language Resources and Evaluation (LREC’04)</em>, Lisbon, Portugal, May 2004.
European Language Resources Association (ELRA).

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://www.lrec-conf.org/proceedings/lrec2004/pdf/5.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.lrec-conf.org/proceedings/lrec2004/pdf/5.pdf</a>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dolan and Brockett [2005]</span>
<span class="ltx_bibblock">
William&nbsp;B. Dolan and Chris Brockett.

</span>
<span class="ltx_bibblock">Automatically constructing a corpus of sentential paraphrases.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Third International Workshop on
Paraphrasing (IWP2005)</em>, 2005.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/I05-5002" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/I05-5002</a>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dozat and Manning [2017]</span>
<span class="ltx_bibblock">
Timothy Dozat and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">Deep biaffine attention for neural dependency parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2017.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=Hk95PK9le" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=Hk95PK9le</a>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eberhard and Simons [2021]</span>
<span class="ltx_bibblock">
David&nbsp;M. Eberhard and Charles&nbsp;D. Simons, Gary F.&nbsp;Fenning.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Ethnologue: Languages of the World</em>.

</span>
<span class="ltx_bibblock">SIL International, Dallas, Texas, 24 edition, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://www.ethnologue.com" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.ethnologue.com</a>.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">El&nbsp;Asri et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Layla El&nbsp;Asri, Hannes Schulz, Shikhar Sharma, Jeremie Zumer, Justin Harris,
Emery Fine, Rahul Mehrotra, and Kaheer Suleman.

</span>
<span class="ltx_bibblock">Frames: a corpus for adding memory to goal-oriented dialogue
systems.

</span>
<span class="ltx_bibblock">In <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 18th Annual SIGdial Meeting on
Discourse and Dialogue</em>, pages 207–219, Saarbrücken, Germany, August
2017. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/W17-5526</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/W17-5526" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W17-5526</a>.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eric et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Mihail Eric, Lakshmi Krishnan, Francois Charette, and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">Key-value retrieval networks for task-oriented dialogue.

</span>
<span class="ltx_bibblock">In <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 18th Annual SIGdial Meeting on
Discourse and Dialogue</em>, pages 37–49, Saarbrücken, Germany, August 2017.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/W17-5506</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/W17-5506" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W17-5506</a>.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eric et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Mihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi, Sanchit Agarwal, Shuyang
Gao, Adarsh Kumar, Anuj Goyal, Peter Ku, and Dilek Hakkani-Tur.

</span>
<span class="ltx_bibblock">MultiWOZ 2.1: A consolidated multi-domain dialogue dataset with
state corrections and state tracking baselines.

</span>
<span class="ltx_bibblock">In <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Language Resources and Evaluation
Conference</em>, pages 422–428, Marseille, France, May 2020. European Language
Resources Association.

</span>
<span class="ltx_bibblock">ISBN 979-10-95546-34-4.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.lrec-1.53" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.lrec-1.53</a>.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and
Michael Auli.

</span>
<span class="ltx_bibblock">ELI5: Long form question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 3558–3567, Florence, Italy, July 2019.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P19-1346</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P19-1346" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P19-1346</a>.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fernández-González and
Gómez-Rodríguez [2019]</span>
<span class="ltx_bibblock">
Daniel Fernández-González and Carlos Gómez-Rodríguez.

</span>
<span class="ltx_bibblock">Left-to-right dependency parsing with pointer networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 710–716, Minneapolis,
Minnesota, June 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N19-1076</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N19-1076" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N19-1076</a>.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Finkel et&nbsp;al. [2005]</span>
<span class="ltx_bibblock">
Jenny&nbsp;Rose Finkel, Trond Grenager, and Christopher Manning.

</span>
<span class="ltx_bibblock">Incorporating non-local information into information extraction
systems by Gibbs sampling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 43rd Annual Meeting of the Association
for Computational Linguistics (ACL’05)</em>, pages 363–370, Ann Arbor,
Michigan, June 2005. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.3115/1219840.1219885</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P05-1045" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P05-1045</a>.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gebru et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer&nbsp;Wortman Vaughan,
Hanna Wallach, Hal Daumé&nbsp;III, and Kate Crawford.

</span>
<span class="ltx_bibblock">Datasheets for datasets.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1803.09010</em>, 2018.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Glockner et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Max Glockner, Vered Shwartz, and Yoav Goldberg.

</span>
<span class="ltx_bibblock">Breaking NLI systems with sentences that require simple lexical
inferences.

</span>
<span class="ltx_bibblock">In <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Papers)</em>, pages 650–655,
Melbourne, Australia, July 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P18-2103</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P18-2103" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P18-2103</a>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grishman and Sundheim [1996]</span>
<span class="ltx_bibblock">
Ralph Grishman and Beth Sundheim.

</span>
<span class="ltx_bibblock">Message Understanding Conference- 6: A brief history.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">COLING 1996 Volume 1: The 16th International Conference on
Computational Linguistics</em>, 1996.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/C96-1079" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/C96-1079</a>.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gururangan et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel Bowman,
and Noah&nbsp;A. Smith.

</span>
<span class="ltx_bibblock">Annotation artifacts in natural language inference data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 2 (Short Papers)</em>, pages 107–112, New Orleans,
Louisiana, June 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N18-2017</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N18-2017" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N18-2017</a>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ham et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Jiyeon Ham, Yo&nbsp;Joong Choe, Kyubyong Park, Ilji Choi, and Hyungjoon Soh.

</span>
<span class="ltx_bibblock">KorNLI and KorSTS: New benchmark datasets for Korean
natural language understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
EMNLP 2020</em>, pages 422–430, Online, November 2020. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.findings-emnlp.39</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.findings-emnlp.39" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.findings-emnlp.39</a>.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Ji&nbsp;Yoon Han, Tae&nbsp;Hwan Oh, Lee Jin, and Hansaem Kim.

</span>
<span class="ltx_bibblock">Annotation issues in Universal Dependencies for Korean and
Japanese.

</span>
<span class="ltx_bibblock">In <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Fourth Workshop on Universal Dependencies
(UDW 2020)</em>, pages 99–108, Barcelona, Spain (Online), December 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.udw-1.12" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.udw-1.12</a>.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et&nbsp;al. [2006]</span>
<span class="ltx_bibblock">
Na-Rae Han, Shijong Ryu, Sook-Hee Chae, Seung-yun Yang, Seunghun Lee, and
Martha Palmer.

</span>
<span class="ltx_bibblock">Korean treebank annotations version 2.0.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Linguistic Data Consortium (LDC), Philadelphia</em>, 2006.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Xu&nbsp;Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao, Zhiyuan Liu, and Maosong
Sun.

</span>
<span class="ltx_bibblock">FewRel: A large-scale supervised few-shot relation classification
dataset with state-of-the-art evaluation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing</em>, pages 4803–4809, Brussels, Belgium,
October-November 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D18-1514</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D18-1514" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D18-1514</a>.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen.

</span>
<span class="ltx_bibblock">DeBERTa: Decoding-enhanced BERT with disentangled attention.

</span>
<span class="ltx_bibblock">In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=XPZIaotutsD" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=XPZIaotutsD</a>.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Henderson et&nbsp;al. [2014a]</span>
<span class="ltx_bibblock">
Matthew Henderson, Blaise Thomson, and Jason&nbsp;D. Williams.

</span>
<span class="ltx_bibblock">The second dialog state tracking challenge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th Annual Meeting of the Special
Interest Group on Discourse and Dialogue (SIGDIAL)</em>, pages 263–272,
Philadelphia, PA, U.S.A., June 2014a. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.3115/v1/W14-4337</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/W14-4337" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W14-4337</a>.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Henderson et&nbsp;al. [2014b]</span>
<span class="ltx_bibblock">
Matthew Henderson, Blaise Thomson, and Jason&nbsp;D Williams.

</span>
<span class="ltx_bibblock">The third dialog state tracking challenge.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">2014 IEEE Spoken Language Technology Workshop (SLT)</em>, pages
324–329. IEEE, 2014b.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrickx et&nbsp;al. [2010]</span>
<span class="ltx_bibblock">
Iris Hendrickx, Su&nbsp;Nam Kim, Zornitsa Kozareva, Preslav Nakov, Diarmuid
Ó&nbsp;Séaghdha, Sebastian Padó, Marco Pennacchiotti, Lorenza Romano,
and Stan Szpakowicz.

</span>
<span class="ltx_bibblock">SemEval-2010 task 8: Multi-way classification of semantic
relations between pairs of nominals.

</span>
<span class="ltx_bibblock">In <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 5th International Workshop on Semantic
Evaluation</em>, pages 33–38, Uppsala, Sweden, July 2010. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/S10-1006" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/S10-1006</a>.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. [2020a]</span>
<span class="ltx_bibblock">
Hai Hu, Kyle Richardson, Liang Xu, Lu&nbsp;Li, Sandra Kübler, and Lawrence Moss.

</span>
<span class="ltx_bibblock">OCNLI: Original Chinese Natural Language Inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
EMNLP 2020</em>, pages 3512–3526, Online, November 2020a.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.findings-emnlp.314</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.findings-emnlp.314" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.findings-emnlp.314</a>.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et&nbsp;al. [2020b]</span>
<span class="ltx_bibblock">
Junjie Hu, Sebastian Ruder, Aditya Siddhant, Graham Neubig, Orhan Firat, and
Melvin Johnson.

</span>
<span class="ltx_bibblock">XTREME: A massively multilingual multi-task benchmark for
evaluating cross-lingual generalisation.

</span>
<span class="ltx_bibblock">In Hal&nbsp;Daumé III and Aarti Singh, editors, <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
37th International Conference on Machine Learning</em>, volume 119 of
<em id="bib.bib54.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages 4411–4421. PMLR,
13–18 Jul 2020b.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://proceedings.mlr.press/v119/hu20b.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://proceedings.mlr.press/v119/hu20b.html</a>.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jabbari et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Ali Jabbari, Olivier Sauvage, Hamada Zeine, and Hamza Chergui.

</span>
<span class="ltx_bibblock">A French corpus and annotation schema for named entity recognition
and relation extraction of financial news.

</span>
<span class="ltx_bibblock">In <em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Language Resources and Evaluation
Conference</em>, pages 2293–2299, Marseille, France, May 2020. European Language
Resources Association.

</span>
<span class="ltx_bibblock">ISBN 979-10-95546-34-4.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.lrec-1.279" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.lrec-1.279</a>.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">TriviaQA: A large scale distantly supervised challenge dataset
for reading comprehension.

</span>
<span class="ltx_bibblock">In <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1601–1611,
Vancouver, Canada, July 2017. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P17-1147</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P17-1147" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P17-1147</a>.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kakwani et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Divyanshu Kakwani, Anoop Kunchukuttan, Satish Golla, Gokul N.C., Avik
Bhattacharyya, Mitesh&nbsp;M. Khapra, and Pratyush Kumar.

</span>
<span class="ltx_bibblock">IndicNLPSuite: Monolingual corpora, evaluation benchmarks and
pre-trained multilingual language models for Indian languages.

</span>
<span class="ltx_bibblock">In <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
EMNLP 2020</em>, pages 4948–4961, Online, November 2020. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.findings-emnlp.445</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.findings-emnlp.445" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.findings-emnlp.445</a>.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaplan et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Jared Kaplan, Sam McCandlish, Tom Henighan, Tom&nbsp;B Brown, Benjamin Chess, Rewon
Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.

</span>
<span class="ltx_bibblock">Scaling laws for neural language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.08361</em>, 2020.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kelley [1984]</span>
<span class="ltx_bibblock">
J.&nbsp;F. Kelley.

</span>
<span class="ltx_bibblock">An iterative design methodology for user-friendly natural language
office information applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">ACM Trans. Inf. Syst.</em>, 2(1):26–41,
January 1984.

</span>
<span class="ltx_bibblock">ISSN 1046-8188.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/357417.357420</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1145/357417.357420" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/357417.357420</a>.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khashabi et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, and Dan
Roth.

</span>
<span class="ltx_bibblock">Looking beyond the surface: A challenge set for reading comprehension
over multiple sentences.

</span>
<span class="ltx_bibblock">In <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)</em>, pages 252–262, New Orleans,
Louisiana, June 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N18-1023</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N18-1023" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N18-1023</a>.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khashabi et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Daniel Khashabi, Arman Cohan, Siamak Shakeri, Pedram Hosseini, Pouya
Pezeshkpour, Malihe Alikhani, Moin Aminnaseri, Marzieh Bitaab, Faeze Brahman,
Sarik Ghazarian, et&nbsp;al.

</span>
<span class="ltx_bibblock">ParsiNLU: a suite of language understanding challenges for persian.

</span>
<span class="ltx_bibblock"><em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.06154</em>, 2020.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kiela et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Douwe Kiela, Hamed Firooz, Aravind Mohan, Vedanuj Goswami, Amanpreet Singh,
Pratik Ringshia, and Davide Testuggine.

</span>
<span class="ltx_bibblock">The hateful memes challenge: Detecting hate speech in multimodal
memes.

</span>
<span class="ltx_bibblock">In H.&nbsp;Larochelle, M.&nbsp;Ranzato, R.&nbsp;Hadsell, M.&nbsp;F. Balcan, and H.&nbsp;Lin,
editors, <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume&nbsp;33,
pages 2611–2624. Curran Associates, Inc., 2020.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2020/file/1b84c4cee2b8b3d823b30e2d604b1878-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2020/file/1b84c4cee2b8b3d823b30e2d604b1878-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Youngmin Kim, Seungyoung Lim, Hyunjeong Lee, Soyoon Park, and Myungji Kim.

</span>
<span class="ltx_bibblock">KorQuAD 2.0: Korean QA dataset for web document machine
comprehension.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">Journal of KIISE</em>, 47:577–586, 2020.

</span>
<span class="ltx_bibblock">ISSN 2383-630X.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=NART99691770&amp;dbt=NART" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://scienceon.kisti.re.kr/srch/selectPORSrchArticle.do?cn=NART99691770&amp;dbt=NART</a>.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kiperwasser and Goldberg [2016]</span>
<span class="ltx_bibblock">
Eliyahu Kiperwasser and Yoav Goldberg.

</span>
<span class="ltx_bibblock">Simple and accurate dependency parsing using bidirectional LSTM
feature representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
4:313–327, 2016.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00101</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/Q16-1023" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/Q16-1023</a>.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Klein and Manning [2003]</span>
<span class="ltx_bibblock">
Dan Klein and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">Accurate unlexicalized parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 41st Annual Meeting of the Association
for Computational Linguistics</em>, pages 423–430, Sapporo, Japan, July 2003.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.3115/1075096.1075150</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P03-1054" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P03-1054</a>.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ko et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Miyoung Ko, Jinhyuk Lee, Hyunjae Kim, Gangwoo Kim, and Jaewoo Kang.

</span>
<span class="ltx_bibblock">Look at the first sentence: Position bias in question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 1109–1121, Online, November
2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.emnlp-main.84</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-main.84" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-main.84</a>.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krippendorff [2011]</span>
<span class="ltx_bibblock">
K.&nbsp;Krippendorff.

</span>
<span class="ltx_bibblock">Computing Krippendorff’s alpha-reliability.

</span>
<span class="ltx_bibblock">2011.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kudo [2006]</span>
<span class="ltx_bibblock">
Taku Kudo.

</span>
<span class="ltx_bibblock">MeCab: Yet another part-of-speech and morphological analyzer, 2006.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://taku910.github.io/mecab/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://taku910.github.io/mecab/</a>.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur
Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin,
Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang,
Andrew&nbsp;M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov.

</span>
<span class="ltx_bibblock">Natural questions: A benchmark for question answering research.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
7:452–466, March 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00276</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/Q19-1026" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/Q19-1026</a>.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lalor and Yu [2020]</span>
<span class="ltx_bibblock">
John&nbsp;P. Lalor and Hong Yu.

</span>
<span class="ltx_bibblock">Dynamic data selection for curriculum learning via ability
estimation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics:
EMNLP 2020</em>, pages 545–555, Online, November 2020. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.findings-emnlp.48</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.findings-emnlp.48" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.findings-emnlp.48</a>.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lan et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and
Radu Soricut.

</span>
<span class="ltx_bibblock">ALBERT: A lite BERT for self-supervised learning of language
representations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=H1eA7AEtvS" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=H1eA7AEtvS</a>.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Le et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Hang Le, Loïc Vial, Jibril Frej, Vincent Segonne, Maximin Coavoux,
Benjamin Lecouteux, Alexandre Allauzen, Benoit Crabbé, Laurent Besacier,
and Didier Schwab.

</span>
<span class="ltx_bibblock">FlauBERT: Unsupervised language model pre-training for French.

</span>
<span class="ltx_bibblock">In <em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Language Resources and Evaluation
Conference</em>, pages 2479–2490, Marseille, France, May 2020. European Language
Resources Association.

</span>
<span class="ltx_bibblock">ISBN 979-10-95546-34-4.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.lrec-1.302" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.lrec-1.302</a>.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee [2020]</span>
<span class="ltx_bibblock">
Junbum Lee.

</span>
<span class="ltx_bibblock">KcBERT: Korean comments BERT.

</span>
<span class="ltx_bibblock">In <em id="bib.bib73.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 32nd Annual Conference on Human and
Cognitive Language Technology</em>, pages 437–440, 2020.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Kyungjae Lee, Kyoungho Yoon, Sunghyun Park, and Seung-won Hwang.

</span>
<span class="ltx_bibblock">Semi-supervised training data generation for multilingual question
answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eleventh International Conference on
Language Resources and Evaluation (LREC 2018)</em>, Miyazaki, Japan, May 2018.
European Language Resources Association (ELRA).

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/L18-1437" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/L18-1437</a>.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Sangah Lee, Hansol Jang, Yunmee Baik, Suzi Park, and Hyopil Shin.

</span>
<span class="ltx_bibblock">KR-BERT: A small-scale Korean-specific language model.

</span>
<span class="ltx_bibblock"><em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2008.03979</em>, 2020.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lewis et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed,
Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">BART: Denoising sequence-to-sequence pre-training for natural
language generation, translation, and comprehension.

</span>
<span class="ltx_bibblock">In <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 7871–7880, Online, July 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.acl-main.703</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.acl-main.703" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.acl-main.703</a>.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Shiyang Li, Semih Yavuz, Kazuma Hashimoto, Jia Li, Tong Niu, Nazneen Rajani,
Xifeng Yan, Yingbo Zhou, and Caiming Xiong.

</span>
<span class="ltx_bibblock">CoCo: Controllable counterfactuals for evaluating dialogue state
trackers.

</span>
<span class="ltx_bibblock"><em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.12850</em>, 2020.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Yaobo Liang, Nan Duan, Yeyun Gong, Ning Wu, Fenfei Guo, Weizhen Qi, Ming Gong,
Linjun Shou, Daxin Jiang, Guihong Cao, Xiaodong Fan, Ruofei Zhang, Rahul
Agrawal, Edward Cui, Sining Wei, Taroon Bharti, Ying Qiao, Jiun-Hung Chen,
Winnie Wu, Shuguang Liu, Fan Yang, Daniel Campos, Rangan Majumder, and Ming
Zhou.

</span>
<span class="ltx_bibblock">XGLUE: A new benchmark datasetfor cross-lingual pre-training,
understanding and generation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 6008–6018, Online, November
2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.emnlp-main.484</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-main.484" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-main.484</a>.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lim et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Seungyoung Lim, Myungji Kim, and Jooyoul Lee.

</span>
<span class="ltx_bibblock">KorQuAD1.0: Korean QA dataset for machine reading
comprehension.

</span>
<span class="ltx_bibblock"><em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.07005</em>, 2019.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin [2004]</span>
<span class="ltx_bibblock">
Chin-Yew Lin.

</span>
<span class="ltx_bibblock">ROUGE: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">Text Summarization Branches Out</em>, pages 74–81, Barcelona,
Spain, July 2004. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/W04-1013" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W04-1013</a>.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. [2021]</span>
<span class="ltx_bibblock">
Alisa Liu, Maarten Sap, Ximing Lu, Swabha Swayamdipta, Chandra Bhagavatula,
Noah&nbsp;A. Smith, and Yejin Choi.

</span>
<span class="ltx_bibblock">On-the-fly controlled text generation with experts and anti-experts,
2021.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer
Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov.

</span>
<span class="ltx_bibblock">RoBERTa: A robustly optimized BERT pretraining approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1907.11692</em>, 2019.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter [2019]</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=Bkg6RiCqY7" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=Bkg6RiCqY7</a>.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marcus et&nbsp;al. [1993]</span>
<span class="ltx_bibblock">
Mitchell&nbsp;P. Marcus, Beatrice Santorini, and Mary&nbsp;Ann Marcinkiewicz.

</span>
<span class="ltx_bibblock">Building a large annotated corpus of English: The Penn
Treebank.

</span>
<span class="ltx_bibblock"><em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">Computational Linguistics</em>, 19(2):313–330,
1993.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/J93-2004" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/J93-2004</a>.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCann et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Bryan McCann, Nitish&nbsp;Shirish Keskar, Caiming Xiong, and Richard Socher.

</span>
<span class="ltx_bibblock">The natural language decathlon: Multitask learning as question
answering.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.08730</em>, 2018.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McDonald et&nbsp;al. [2013]</span>
<span class="ltx_bibblock">
Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-Brundage, Yoav Goldberg, Dipanjan
Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar
Täckström, Claudia Bedini, Núria Bertomeu&nbsp;Castelló, and
Jungmee Lee.

</span>
<span class="ltx_bibblock">Universal Dependency annotation for multilingual parsing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 51st Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Papers)</em>, pages 92–97, Sofia,
Bulgaria, August 2013. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P13-2017" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P13-2017</a>.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McNamee and Dang [2009]</span>
<span class="ltx_bibblock">
Paul McNamee and Hoa&nbsp;Trang Dang.

</span>
<span class="ltx_bibblock">Overview of the TAC 2009 knowledge base population track.

</span>
<span class="ltx_bibblock">In <em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">Text Analysis Conference (TAC)</em>, volume&nbsp;17, pages 111–113,
2009.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mehri et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Shikib Mehri, Mihail Eric, and Dilek Hakkani-Tur.

</span>
<span class="ltx_bibblock">DialoGLUE: A natural language understanding benchmark for
task-oriented dialogue.

</span>
<span class="ltx_bibblock"><em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.13570</em>, 2020.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Junghyun Min, R.&nbsp;Thomas McCoy, Dipanjan Das, Emily Pitler, and Tal Linzen.

</span>
<span class="ltx_bibblock">Syntactic data augmentation increases robustness to inference
heuristics.

</span>
<span class="ltx_bibblock">In <em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 2339–2352, Online, July 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.acl-main.212</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.acl-main.212" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.acl-main.212</a>.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Min et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Sewon Min, Eric Wallace, Sameer Singh, Matt Gardner, Hannaneh Hajishirzi, and
Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Compositional questions do not necessitate multi-hop reasoning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4249–4257, Florence, Italy, July 2019.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P19-1416</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P19-1416" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P19-1416</a>.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mintz et&nbsp;al. [2009]</span>
<span class="ltx_bibblock">
Mike Mintz, Steven Bills, Rion Snow, and Daniel Jurafsky.

</span>
<span class="ltx_bibblock">Distant supervision for relation extraction without labeled data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Joint Conference on Natural
Language Processing of the AFNLP</em>, pages 1003–1011, Suntec, Singapore,
August 2009. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P09-1113" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P09-1113</a>.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Moon et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Jihyung Moon, Won&nbsp;Ik Cho, and Junbum Lee.

</span>
<span class="ltx_bibblock">BEEP! Korean corpus of online news comments for toxic speech
detection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eighth International Workshop on Natural
Language Processing for Social Media</em>, pages 25–31, Online, July 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.socialnlp-1.4</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.socialnlp-1.4" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.socialnlp-1.4</a>.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nam et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Sangha Nam, Minho Lee, Donghwan Kim, Kijong Han, Kuntae Kim, Sooji Yoon,
Eun-kyung Kim, and Key-Sun Choi.

</span>
<span class="ltx_bibblock">Effective crowdsourcing of multiple tasks for comprehensive knowledge
extraction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Language Resources and Evaluation
Conference</em>, pages 212–219, Marseille, France, May 2020. European Language
Resources Association.

</span>
<span class="ltx_bibblock">ISBN 979-10-95546-34-4.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.lrec-1.27" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.lrec-1.27</a>.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nangia and Bowman [2019]</span>
<span class="ltx_bibblock">
Nikita Nangia and Samuel&nbsp;R. Bowman.

</span>
<span class="ltx_bibblock">Human vs. muppet: A conservative estimate of human performance on the
GLUE benchmark.

</span>
<span class="ltx_bibblock">In <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4566–4575, Florence, Italy, July 2019.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P19-1449</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P19-1449" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P19-1449</a>.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nangia et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Nikita Nangia, Clara Vania, Rasika Bhalerao, and Samuel&nbsp;R. Bowman.

</span>
<span class="ltx_bibblock">CrowS-pairs: A challenge dataset for measuring social biases in
masked language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 1953–1967, Online, November
2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.emnlp-main.154</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-main.154" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-main.154</a>.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, Rangan
Majumder, and Li&nbsp;Deng.

</span>
<span class="ltx_bibblock">MS MARCO: A human generated MAchine reading COmprehension
dataset.

</span>
<span class="ltx_bibblock">November 2016.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://www.microsoft.com/en-us/research/publication/ms-marco-human-generated-machine-reading-comprehension-dataset/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.microsoft.com/en-us/research/publication/ms-marco-human-generated-machine-reading-comprehension-dataset/</a>.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nivre et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
Joakim Nivre, Marie-Catherine de&nbsp;Marneffe, Filip Ginter, Yoav Goldberg, Jan
Hajič, Christopher&nbsp;D. Manning, Ryan McDonald, Slav Petrov, Sampo
Pyysalo, Natalia Silveira, Reut Tsarfaty, and Daniel Zeman.

</span>
<span class="ltx_bibblock">Universal Dependencies v1: A multilingual treebank collection.

</span>
<span class="ltx_bibblock">In <em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Tenth International Conference on
Language Resources and Evaluation (LREC’16)</em>, pages 1659–1666,
Portorož, Slovenia, May 2016. European Language Resources Association
(ELRA).

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/L16-1262" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/L16-1262</a>.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">of&nbsp;Korean&nbsp;Languages [2020]</span>
<span class="ltx_bibblock">
National&nbsp;Institute of&nbsp;Korean&nbsp;Languages.

</span>
<span class="ltx_bibblock">NIKL CORPORA 2020 (v.1.0), 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://corpus.korean.go.kr" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://corpus.korean.go.kr</a>.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oh et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Tae&nbsp;Hwan Oh, Ji&nbsp;Yoon Han, Hyonsu Choe, Seokwon Park, Han He, Jinho&nbsp;D. Choi,
Na-Rae Han, Jena&nbsp;D. Hwang, and Hansaem Kim.

</span>
<span class="ltx_bibblock">Analysis of the Penn Korean Universal Dependency treebank
(PKT-UD): Manual revision to build robust parsing model in Korean.

</span>
<span class="ltx_bibblock">In <em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th International Conference on Parsing
Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal
Dependencies</em>, pages 122–131, Online, July 2020. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.iwpt-1.13</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.iwpt-1.13" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.iwpt-1.13</a>.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pan et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Xiaoman Pan, Boliang Zhang, Jonathan May, Joel Nothman, Kevin Knight, and Heng
Ji.

</span>
<span class="ltx_bibblock">Cross-lingual name tagging and linking for 282 languages.

</span>
<span class="ltx_bibblock">In <em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 55th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1946–1958,
Vancouver, Canada, July 2017. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P17-1178</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P17-1178" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P17-1178</a>.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park and Cho [2014]</span>
<span class="ltx_bibblock">
Eunjeong&nbsp;L. Park and Sungzoon Cho.

</span>
<span class="ltx_bibblock">KoNLPy: Korean natural language processing in Python.

</span>
<span class="ltx_bibblock">In <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 26th Annual Conference on Human &amp;
Cognitive Language Technology</em>, Chuncheon, Korea, October 2014.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park [2020]</span>
<span class="ltx_bibblock">
Jangwon Park.

</span>
<span class="ltx_bibblock">KoELECTRA: Pretrained ELECTRA model for Korean.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/monologg/KoELECTRA" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/monologg/KoELECTRA</a>, 2020.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Park et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Kyubyong Park, Joohong Lee, Seongbo Jang, and Dawoon Jung.

</span>
<span class="ltx_bibblock">An empirical study of tokenization strategies for various Korean
NLP tasks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 1st Conference of the Asia-Pacific
Chapter of the Association for Computational Linguistics and the 10th
International Joint Conference on Natural Language Processing</em>, pages
133–142, Suzhou, China, December 2020. Association for Computational
Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.aacl-main.17" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.aacl-main.17</a>.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peters et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark,
Kenton Lee, and Luke Zettlemoyer.

</span>
<span class="ltx_bibblock">Deep contextualized word representations.

</span>
<span class="ltx_bibblock">In <em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)</em>, pages 2227–2237, New Orleans,
Louisiana, June 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N18-1202</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N18-1202" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N18-1202</a>.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petroni et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Fabio Petroni, Aleksandra Piktus, Angela Fan, Patrick Lewis, Majid Yazdani,
Nicola De&nbsp;Cao, James Thorne, Yacine Jernite, Vladimir Karpukhin, Jean
Maillard, et&nbsp;al.

</span>
<span class="ltx_bibblock">KILT: a benchmark for knowledge intensive language tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.02252</em>, 2020.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petrov et&nbsp;al. [2012]</span>
<span class="ltx_bibblock">
Slav Petrov, Dipanjan Das, and Ryan McDonald.

</span>
<span class="ltx_bibblock">A universal part-of-speech tagset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eighth International Conference on
Language Resources and Evaluation (LREC’12)</em>, pages 2089–2096, Istanbul,
Turkey, May 2012. European Language Resources Association (ELRA).

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf</a>.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Phang et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Jason Phang, Thibault Févry, and Samuel&nbsp;R Bowman.

</span>
<span class="ltx_bibblock">Sentence encoders on stilts: Supplementary training on intermediate
labeled-data tasks.

</span>
<span class="ltx_bibblock"><em id="bib.bib107.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.01088</em>, 2018.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Poliak et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Adam Poliak, Jason Naradowsky, Aparajita Haldar, Rachel Rudinger, and Benjamin
Van&nbsp;Durme.

</span>
<span class="ltx_bibblock">Hypothesis only baselines in natural language inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Seventh Joint Conference on Lexical and
Computational Semantics</em>, pages 180–191, New Orleans, Louisiana, June 2018.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/S18-2023</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/S18-2023" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/S18-2023</a>.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Quan et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Jun Quan, Shian Zhang, Qian Cao, Zizhong Li, and Deyi Xiong.

</span>
<span class="ltx_bibblock">RiSAWOZ: A large-scale multi-domain Wizard-of-Oz dataset with
rich semantic annotations for task-oriented dialogue modeling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 930–940, Online, November 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.emnlp-main.67</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-main.67" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-main.67</a>.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever.

</span>
<span class="ltx_bibblock">Language models are unsupervised multitask learners.

</span>
<span class="ltx_bibblock">2019.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter&nbsp;J. Liu.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text
transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, 21(140):1–67, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://jmlr.org/papers/v21/20-074.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://jmlr.org/papers/v21/20-074.html</a>.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang.

</span>
<span class="ltx_bibblock">SQuAD: 100,000+ questions for machine comprehension of text.

</span>
<span class="ltx_bibblock">In <em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2016 Conference on Empirical Methods in
Natural Language Processing</em>, pages 2383–2392, Austin, Texas, November 2016.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D16-1264</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D16-1264" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D16-1264</a>.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajpurkar et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Pranav Rajpurkar, Robin Jia, and Percy Liang.

</span>
<span class="ltx_bibblock">Know what you don’t know: Unanswerable questions for SQuAD.

</span>
<span class="ltx_bibblock">In <em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Papers)</em>, pages 784–789,
Melbourne, Australia, July 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P18-2124</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P18-2124" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P18-2124</a>.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rastogi et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Abhinav Rastogi, Xiaoxue Zang, Srinivas Sunkara, Raghav Gupta, and Pranav
Khaitan.

</span>
<span class="ltx_bibblock">Towards scalable multi-domain conversational agents: The
schema-guided dialogue dataset.

</span>
<span class="ltx_bibblock"><em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial Intelligence</em>,
34(05):8689–8696, Apr. 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1609/aaai.v34i05.6394</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://ojs.aaai.org/index.php/AAAI/article/view/6394" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://ojs.aaai.org/index.php/AAAI/article/view/6394</a>.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and Gurevych [2019]</span>
<span class="ltx_bibblock">
Nils Reimers and Iryna Gurevych.

</span>
<span class="ltx_bibblock">Sentence-BERT: Sentence embeddings using Siamese BERT-networks.

</span>
<span class="ltx_bibblock">In <em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)</em>, pages 3982–3992, Hong Kong,
China, November 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D19-1410</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D19-1410" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D19-1410</a>.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Riedel et&nbsp;al. [2010]</span>
<span class="ltx_bibblock">
Sebastian Riedel, Limin Yao, and Andrew McCallum.

</span>
<span class="ltx_bibblock">Modeling relations and their mentions without labeled text.

</span>
<span class="ltx_bibblock">In José&nbsp;Luis Balcázar, Francesco Bonchi, Aristides Gionis,
and Michèle Sebag, editors, <em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">Machine Learning and Knowledge
Discovery in Databases</em>, pages 148–163, Berlin, Heidelberg, 2010. Springer
Berlin Heidelberg.

</span>
<span class="ltx_bibblock">ISBN 978-3-642-15939-8.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ritter et&nbsp;al. [2011]</span>
<span class="ltx_bibblock">
Alan Ritter, Sam Clark, Mausam, and Oren Etzioni.

</span>
<span class="ltx_bibblock">Named entity recognition in tweets: An experimental study.

</span>
<span class="ltx_bibblock">In <em id="bib.bib117.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2011 Conference on Empirical Methods in
Natural Language Processing</em>, pages 1524–1534, Edinburgh, Scotland, UK.,
July 2011. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D11-1141" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D11-1141</a>.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Robertson et&nbsp;al. [1995]</span>
<span class="ltx_bibblock">
Stephen&nbsp;E Robertson, Steve Walker, Susan Jones, Micheline&nbsp;M Hancock-Beaulieu,
Mike Gatford, et&nbsp;al.

</span>
<span class="ltx_bibblock">Okapi at trec-3.

</span>
<span class="ltx_bibblock"><em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">Nist Special Publication Sp</em>, 109:109, 1995.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rust et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Phillip Rust, Jonas Pfeiffer, Ivan Vulić, Sebastian Ruder, and Iryna
Gurevych.

</span>
<span class="ltx_bibblock">How good is your tokenizer? on the monolingual performance of
multilingual language models.

</span>
<span class="ltx_bibblock"><em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.15613</em>, 2020.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saha et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Amrita Saha, Rahul Aralikatte, Mitesh&nbsp;M. Khapra, and Karthik Sankaranarayanan.

</span>
<span class="ltx_bibblock">DuoRC: Towards complex language understanding with paraphrased
reading comprehension.

</span>
<span class="ltx_bibblock">In <em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 56th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1683–1693,
Melbourne, Australia, July 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P18-1156</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P18-1156" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P18-1156</a>.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schiersch et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Martin Schiersch, Veselina Mironova, Maximilian Schmitt, Philippe Thomas,
Aleksandra Gabryszak, and Leonhard Hennig.

</span>
<span class="ltx_bibblock">A German corpus for fine-grained named entity recognition and
relation extraction of traffic and industry events.

</span>
<span class="ltx_bibblock">In <em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Eleventh International Conference on
Language Resources and Evaluation (LREC 2018)</em>, Miyazaki, Japan, May 2018.
European Language Resources Association (ELRA).

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/L18-1703" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/L18-1703</a>.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sen and Saffari [2020]</span>
<span class="ltx_bibblock">
Priyanka Sen and Amir Saffari.

</span>
<span class="ltx_bibblock">What do models learn from question answering datasets?

</span>
<span class="ltx_bibblock">In <em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 2429–2438, Online, November
2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.emnlp-main.190</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-main.190" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-main.190</a>.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sennrich et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
Rico Sennrich, Barry Haddow, and Alexandra Birch.

</span>
<span class="ltx_bibblock">Neural machine translation of rare words with subword units.

</span>
<span class="ltx_bibblock">In <em id="bib.bib123.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 54th Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1715–1725,
Berlin, Germany, August 2016. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P16-1162</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P16-1162" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P16-1162</a>.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shah et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Pararth Shah, Dilek Hakkani-Tür, Gokhan Tür, Abhinav Rastogi, Ankur
Bapna, Neha Nayak, and Larry Heck.

</span>
<span class="ltx_bibblock">Building a conversational agent overnight with dialogue self-play.

</span>
<span class="ltx_bibblock"><em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1801.04871</em>, 2018.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shavrina et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Tatiana Shavrina, Alena Fenogenova, Emelyanov Anton, Denis Shevelev, Ekaterina
Artemova, Valentin Malykh, Vladislav Mikhailov, Maria Tikhonova, Andrey
Chertok, and Andrey Evlampiev.

</span>
<span class="ltx_bibblock">RussianSuperGLUE: A Russian language understanding evaluation
benchmark.

</span>
<span class="ltx_bibblock">In <em id="bib.bib125.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing (EMNLP)</em>, pages 4717–4726, Online, November
2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.emnlp-main.381</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-main.381" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-main.381</a>.

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Socher et&nbsp;al. [2013]</span>
<span class="ltx_bibblock">
Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher&nbsp;D. Manning,
Andrew Ng, and Christopher Potts.

</span>
<span class="ltx_bibblock">Recursive deep models for semantic compositionality over a sentiment
treebank.

</span>
<span class="ltx_bibblock">In <em id="bib.bib126.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2013 Conference on Empirical Methods in
Natural Language Processing</em>, pages 1631–1642, Seattle, Washington, USA,
October 2013. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D13-1170" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D13-1170</a>.

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Strauss et&nbsp;al. [2016]</span>
<span class="ltx_bibblock">
Benjamin Strauss, Bethany Toma, Alan Ritter, Marie-Catherine de&nbsp;Marneffe, and
Wei Xu.

</span>
<span class="ltx_bibblock">Results of the WNUT16 named entity recognition shared task.

</span>
<span class="ltx_bibblock">In <em id="bib.bib127.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2nd Workshop on Noisy User-generated Text
(WNUT)</em>, pages 138–144, Osaka, Japan, December 2016. The COLING 2016
Organizing Committee.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/W16-3919" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W16-3919</a>.

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">sun Choi et&nbsp;al. [1994]</span>
<span class="ltx_bibblock">
Key sun Choi, Young&nbsp;S. Han, Young&nbsp;G. Han, and Oh&nbsp;W. Kwon.

</span>
<span class="ltx_bibblock">KAIST tree bank project for Korean: Present and future
development.

</span>
<span class="ltx_bibblock">In <em id="bib.bib128.1.1" class="ltx_emph ltx_font_italic">In Proceedings of the International Workshop on Sharable
Natural Language Resources</em>, pages 7–14, 1994.

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tjong Kim&nbsp;Sang and
De&nbsp;Meulder [2003]</span>
<span class="ltx_bibblock">
Erik&nbsp;F. Tjong Kim&nbsp;Sang and Fien De&nbsp;Meulder.

</span>
<span class="ltx_bibblock">Introduction to the CoNLL-2003 shared task: Language-independent
named entity recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib129.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Seventh Conference on Natural Language
Learning at HLT-NAACL 2003</em>, pages 142–147, 2003.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/W03-0419" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/W03-0419</a>.

</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Trischler et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni,
Philip Bachman, and Kaheer Suleman.

</span>
<span class="ltx_bibblock">NewsQA: A machine comprehension dataset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib130.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2nd Workshop on Representation Learning
for NLP</em>, pages 191–200, Vancouver, Canada, August 2017. Association for
Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/W17-2623</span>.

</span>
<span class="ltx_bibblock">URL <a href="<https://www.aclweb.org/anthology/W17-2623>" title="" class="ltx_ref ltx_url ltx_font_typewriter">&lt;https://www.aclweb.org/anthology/W17-2623&gt;</a>.

</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vania et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Clara Vania, Ruijie Chen, and Samuel&nbsp;R. Bowman.

</span>
<span class="ltx_bibblock">Asking Crowdworkers to Write Entailment Examples: The
Best of Bad options.

</span>
<span class="ltx_bibblock">In <em id="bib.bib131.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 1st Conference of the Asia-Pacific
Chapter of the Association for Computational Linguistics and the 10th
International Joint Conference on Natural Language Processing</em>, pages
672–686, Suzhou, China, December 2020. Association for Computational
Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.aacl-main.68" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.aacl-main.68</a>.

</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. [2019a]</span>
<span class="ltx_bibblock">
Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael,
Felix Hill, Omer Levy, and Samuel Bowman.

</span>
<span class="ltx_bibblock">SuperGLUE: A stickier benchmark for general-purpose language
understanding systems.

</span>
<span class="ltx_bibblock">In H.&nbsp;Wallach, H.&nbsp;Larochelle, A.&nbsp;Beygelzimer, F.&nbsp;d'Alché-Buc, E.&nbsp;Fox, and R.&nbsp;Garnett, editors, <em id="bib.bib132.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems</em>, volume&nbsp;32. Curran Associates, Inc.,
2019a.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2019/file/4496bf24afe7fab6f046bf4923da8de6-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et&nbsp;al. [2019b]</span>
<span class="ltx_bibblock">
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and
Samuel&nbsp;R. Bowman.

</span>
<span class="ltx_bibblock">GLUE: A multi-task benchmark and analysis platform for natural
language understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib133.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>,
2019b.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=rJ4km2R5t7" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=rJ4km2R5t7</a>.

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Warstadt et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Alex Warstadt, Amanpreet Singh, and Samuel&nbsp;R. Bowman.

</span>
<span class="ltx_bibblock">Neural network acceptability judgments.

</span>
<span class="ltx_bibblock"><em id="bib.bib134.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
7:625–641, March 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00290</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/Q19-1040" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/Q19-1040</a>.

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Tsung-Hsien Wen, David Vandyke, Nikola Mrkšić, Milica
Gašić, Lina&nbsp;M. Rojas-Barahona, Pei-Hao Su, Stefan Ultes, and Steve
Young.

</span>
<span class="ltx_bibblock">A network-based end-to-end trainable task-oriented dialogue system.

</span>
<span class="ltx_bibblock">In <em id="bib.bib135.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 15th Conference of the European Chapter
of the Association for Computational Linguistics: Volume 1, Long Papers</em>,
pages 438–449, Valencia, Spain, April 2017. Association for Computational
Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/E17-1042" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/E17-1042</a>.

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wenzek et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Guillaume Wenzek, Marie-Anne Lachaux, Alexis Conneau, Vishrav Chaudhary,
Francisco Guzmán, Armand Joulin, and Edouard Grave.

</span>
<span class="ltx_bibblock">CCNet: Extracting high quality monolingual datasets from web crawl
data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib136.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th Language Resources and Evaluation
Conference</em>, pages 4003–4012, Marseille, France, May 2020. European Language
Resources Association.

</span>
<span class="ltx_bibblock">ISBN 979-10-95546-34-4.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.lrec-1.494" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.lrec-1.494</a>.

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilie et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Bryan Wilie, Karissa Vincentio, Genta&nbsp;Indra Winata, Samuel Cahyawijaya,
Xiaohong Li, Zhi&nbsp;Yuan Lim, Sidik Soleman, Rahmad Mahendra, Pascale Fung,
Syafri Bahar, and Ayu Purwarianti.

</span>
<span class="ltx_bibblock">IndoNLU: Benchmark and resources for evaluating Indonesian
natural language understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib137.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 1st Conference of the Asia-Pacific
Chapter of the Association for Computational Linguistics and the 10th
International Joint Conference on Natural Language Processing</em>, pages
843–857, Suzhou, China, December 2020. Association for Computational
Linguistics.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.aacl-main.85" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.aacl-main.85</a>.

</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Williams et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Adina Williams, Nikita Nangia, and Samuel Bowman.

</span>
<span class="ltx_bibblock">A broad-coverage challenge corpus for sentence understanding through
inference.

</span>
<span class="ltx_bibblock">In <em id="bib.bib138.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long Papers)</em>, pages 1112–1122, New Orleans,
Louisiana, June 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N18-1101</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N18-1101" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N18-1101</a>.

</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wolf et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe
Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien
Plu, Canwen Xu, Teven Le&nbsp;Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest,
and Alexander Rush.

</span>
<span class="ltx_bibblock">Transformers: State-of-the-art natural language processing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib139.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Conference on Empirical Methods in
Natural Language Processing: System Demonstrations</em>, pages 38–45, Online,
October 2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.emnlp-demos.6</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.emnlp-demos.6" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.emnlp-demos.6</a>.

</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Chien-Sheng Wu, Andrea Madotto, Ehsan Hosseini-Asl, Caiming Xiong, Richard
Socher, and Pascale Fung.

</span>
<span class="ltx_bibblock">Transferable multi-domain state generator for task-oriented dialogue
systems.

</span>
<span class="ltx_bibblock">In <em id="bib.bib140.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 808–819, Florence, Italy, July 2019.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P19-1078</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P19-1078" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P19-1078</a>.

</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Jingjing Xu, Ji&nbsp;Wen, Xu&nbsp;Sun, and Qi&nbsp;Su.

</span>
<span class="ltx_bibblock">A discourse-level named entity recognition and relation extraction
dataset for Chinese literature text.

</span>
<span class="ltx_bibblock"><em id="bib.bib141.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1711.07010</em>, 2017.

</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Liang Xu, Hai Hu, Xuanwei Zhang, Lu&nbsp;Li, Chenjie Cao, Yudong Li, Yechen Xu, Kai
Sun, Dian Yu, Cong Yu, Yin Tian, Qianqian Dong, Weitang Liu, Bo&nbsp;Shi, Yiming
Cui, Junyi Li, Jun Zeng, Rongzhao Wang, Weijian Xie, Yanting Li, Yina
Patterson, Zuoyu Tian, Yiwen Zhang, He&nbsp;Zhou, Shaoweihua Liu, Zhe Zhao, Qipeng
Zhao, Cong Yue, Xinrui Zhang, Zhengliang Yang, Kyle Richardson, and Zhenzhong
Lan.

</span>
<span class="ltx_bibblock">CLUE: A Chinese language understanding evaluation benchmark.

</span>
<span class="ltx_bibblock">In <em id="bib.bib142.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on
Computational Linguistics</em>, pages 4762–4772, Barcelona, Spain (Online),
December 2020. International Committee on Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.coling-main.419</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.coling-main.419" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.coling-main.419</a>.

</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. [2015]</span>
<span class="ltx_bibblock">
Yi&nbsp;Yang, Wen-tau Yih, and Christopher Meek.

</span>
<span class="ltx_bibblock">WikiQA: A challenge dataset for open-domain question answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib143.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2015 Conference on Empirical Methods in
Natural Language Processing</em>, pages 2013–2018, Lisbon, Portugal, September
2015. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D15-1237</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D15-1237" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D15-1237</a>.

</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. [2019a]</span>
<span class="ltx_bibblock">
Yinfei Yang, Yuan Zhang, Chris Tar, and Jason Baldridge.

</span>
<span class="ltx_bibblock">PAWS-X: A cross-lingual adversarial dataset for paraphrase
identification.

</span>
<span class="ltx_bibblock">In <em id="bib.bib144.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)</em>, pages 3687–3692, Hong Kong,
China, November 2019a. Association for Computational
Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D19-1382</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D19-1382" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D19-1382</a>.

</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan
Salakhutdinov, and Christopher&nbsp;D. Manning.

</span>
<span class="ltx_bibblock">HotpotQA: A dataset for diverse, explainable multi-hop question
answering.

</span>
<span class="ltx_bibblock">In <em id="bib.bib145.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing</em>, pages 2369–2380, Brussels, Belgium,
October-November 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D18-1259</span>.

</span>
<span class="ltx_bibblock">URL <a href="<https://www.aclweb.org/anthology/D18-1259>" title="" class="ltx_ref ltx_url ltx_font_typewriter">&lt;https://www.aclweb.org/anthology/D18-1259&gt;</a>.

</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et&nbsp;al. [2019b]</span>
<span class="ltx_bibblock">
Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Russ&nbsp;R Salakhutdinov,
and Quoc&nbsp;V Le.

</span>
<span class="ltx_bibblock">XLNet: Generalized autoregressive pretraining for language
understanding.

</span>
<span class="ltx_bibblock">In H.&nbsp;Wallach, H.&nbsp;Larochelle, A.&nbsp;Beygelzimer, F.&nbsp;d'Alché-Buc, E.&nbsp;Fox, and R.&nbsp;Garnett, editors, <em id="bib.bib146.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems</em>, volume&nbsp;32. Curran Associates, Inc.,
2019b.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Yuan Yao, Deming Ye, Peng Li, Xu&nbsp;Han, Yankai Lin, Zhenghao Liu, Zhiyuan Liu,
Lixin Huang, Jie Zhou, and Maosong Sun.

</span>
<span class="ltx_bibblock">DocRED: A large-scale document-level relation extraction dataset.

</span>
<span class="ltx_bibblock">In <em id="bib.bib147.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 764–777, Florence, Italy, July 2019.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P19-1074</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/P19-1074" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/P19-1074</a>.

</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Young et&nbsp;al. [2014]</span>
<span class="ltx_bibblock">
Peter Young, Alice Lai, Micah Hodosh, and Julia Hockenmaier.

</span>
<span class="ltx_bibblock">From image descriptions to visual denotations: New similarity metrics
for semantic inference over event descriptions.

</span>
<span class="ltx_bibblock"><em id="bib.bib148.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
2:67–78, 2014.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00166</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/Q14-1006" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/Q14-1006</a>.

</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Dian Yu, Kai Sun, Claire Cardie, and Dong Yu.

</span>
<span class="ltx_bibblock">Dialogue-based relation extraction.

</span>
<span class="ltx_bibblock">In <em id="bib.bib149.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics</em>, pages 4927–4940, Online, July 2020.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.acl-main.444</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.acl-main.444" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.acl-main.444</a>.

</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. [2018]</span>
<span class="ltx_bibblock">
Sheng Zhang, Xiaodong Liu, Jingjing Liu, Jianfeng Gao, Kevin Duh, and Benjamin
Van&nbsp;Durme.

</span>
<span class="ltx_bibblock">ReCoRD: Bridging the gap between human and machine commonsense
reading comprehension.

</span>
<span class="ltx_bibblock"><em id="bib.bib150.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1810.12885</em>, 2018.

</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. [2015]</span>
<span class="ltx_bibblock">
Xiang Zhang, Junbo Zhao, and Yann LeCun.

</span>
<span class="ltx_bibblock">Character-level convolutional networks for text classification.

</span>
<span class="ltx_bibblock">In C.&nbsp;Cortes, N.&nbsp;Lawrence, D.&nbsp;Lee, M.&nbsp;Sugiyama, and R.&nbsp;Garnett,
editors, <em id="bib.bib151.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, volume&nbsp;28.
Curran Associates, Inc., 2015.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2015/file/250cf8b51c773f3f8dc8b4be867a9a02-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. [2019]</span>
<span class="ltx_bibblock">
Yuan Zhang, Jason Baldridge, and Luheng He.

</span>
<span class="ltx_bibblock">PAWS: Paraphrase adversaries from word scrambling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib152.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 1298–1308,
Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N19-1131</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/N19-1131" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/N19-1131</a>.

</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et&nbsp;al. [2017]</span>
<span class="ltx_bibblock">
Yuhao Zhang, Victor Zhong, Danqi Chen, Gabor Angeli, and Christopher&nbsp;D.
Manning.

</span>
<span class="ltx_bibblock">Position-aware attention and supervised data improve slot filling.

</span>
<span class="ltx_bibblock">In <em id="bib.bib153.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2017 Conference on Empirical Methods in
Natural Language Processing</em>, pages 35–45, Copenhagen, Denmark, September
2017. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D17-1004</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/D17-1004" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/D17-1004</a>.

</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et&nbsp;al. [2020]</span>
<span class="ltx_bibblock">
Qi&nbsp;Zhu, Kaili Huang, Zheng Zhang, Xiaoyan Zhu, and Minlie Huang.

</span>
<span class="ltx_bibblock">CrossWOZ: A large-scale Chinese cross-domain task-oriented
dialogue dataset.

</span>
<span class="ltx_bibblock"><em id="bib.bib154.1.1" class="ltx_emph ltx_font_italic">Transactions of the Association for Computational Linguistics</em>,
8:281–295, 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1162/tacl_a_00314</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/2020.tacl-1.19" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/2020.tacl-1.19</a>.

</span>
</li>
</ul>
</section>
<div id="p2" class="ltx_para">
<span id="p2.1" class="ltx_ERROR undefined">\printindex</span>
<div class="ltx_pagination ltx_role_newpage"></div>
</div>
<section id="Sx2" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:90%;">Contribution</h2>

<div id="Sx2.p1" class="ltx_para">
<p class="ltx_p" id="Sx2.p1.1"><span class="ltx_text ltx_font_bold" id="Sx2.p1.1.1" style="font-size:90%;">SungJun Park</span><span class="ltx_text" id="Sx2.p1.1.2" style="font-size:90%;"> led the project as project manager, initiated the project, decisions on overall progress of this project, secure financial resources, signed up with ACROFAN for the articles, organized IRB submission and research paper. </span></p>
</div>
<div id="Sx2.p2" class="ltx_para">
<p class="ltx_p" id="Sx2.p2.1"><span class="ltx_text ltx_font_bold" id="Sx2.p2.1.1" style="font-size:90%;">Jihyung Moon</span><span class="ltx_text" id="Sx2.p2.1.2" style="font-size:90%;">Lead the project as project manager, managed overall datasets, models and ethical concern, signed up with ACROFAN for the articles, prepared IRB, also contributed to NER, STS, NLI, MRC dataset constructions, AIRBNB, POLICY corpora collection and leaderboard design. </span></p>
</div>
<div id="Sx2.p3" class="ltx_para">
<p class="ltx_p" id="Sx2.p3.1"><span class="ltx_text ltx_font_bold" id="Sx2.p3.1.1" style="font-size:90%;">Sungdong Kim</span><span class="ltx_text" id="Sx2.p3.1.2" style="font-size:90%;"> managed overall fine-tuning of language models, serve as a person of charge of DST, and contribution to dataset construction of TC, STS, and RE. </span></p>
</div>
<div id="Sx2.p4" class="ltx_para">
<p class="ltx_p" id="Sx2.p4.1"><span class="ltx_text ltx_font_bold" id="Sx2.p4.1.1" style="font-size:90%;">Won Ik Cho</span><span class="ltx_text" id="Sx2.p4.1.2" style="font-size:90%;">TC, STS, NLI, RE, MRC 및 DST의 전체 데이터 세트 구성을 관리하고, PARAKQC의 원본 코퍼스를 제공하고, STS의 PIC 역할을 했다. </span></p>
</div>
<div id="Sx2.p5" class="ltx_para">
<p class="ltx_p" id="Sx2.p5.1"><span class="ltx_text ltx_font_bold" id="Sx2.p5.1.1" style="font-size:90%;">Jiyoon Han</span><span class="ltx_text" id="Sx2.p5.1.2" style="font-size:90%;">DP 및 NER의 전체 데이터 세트 구성을 관리하고 NLI의 PIC 역할을 하며 STS의 데이터 세트 구성에 기여했으며 IRB 준비에 참여했다. </span></p>
</div>
<div id="Sx2.p6" class="ltx_para">
<p class="ltx_p" id="Sx2.p6.1"><span class="ltx_text ltx_font_bold" id="Sx2.p6.1.1" style="font-size:90%;">Jangwon Park</span><span class="ltx_text" id="Sx2.p6.1.2" style="font-size:90%;"> serve as a PIC of model pretraining, contribution to the text collection of YNA, collected and pre-processed MODU, CC-100-Kor, NAMUWIKI, NEWSCRAWL and PETITION, and conducted the fine-tuning of TC. </span></p>
</div>
<div id="Sx2.p7" class="ltx_para">
<p class="ltx_p" id="Sx2.p7.1"><span class="ltx_text ltx_font_bold" id="Sx2.p7.1.1" style="font-size:90%;">Chisung Song</span><span class="ltx_text" id="Sx2.p7.1.2" style="font-size:90%;"> serve as a PIC of NER and contribution to the dataset construction of DP and DST. </span></p>
</div>
<div id="Sx2.p8" class="ltx_para">
<p class="ltx_p" id="Sx2.p8.1"><span class="ltx_text ltx_font_bold" id="Sx2.p8.1.1" style="font-size:90%;">Junseong Kim</span><span class="ltx_text" id="Sx2.p8.1.2" style="font-size:90%;"> serve as a PIC of MRC, conducted the fine-tuning of MRC, and contribution to the text collection of WIKITREE and WIKIPEDIA. </span></p>
</div>
<div id="Sx2.p9" class="ltx_para">
<p class="ltx_p" id="Sx2.p9.1"><span class="ltx_text ltx_font_bold" id="Sx2.p9.1.1" style="font-size:90%;">Youngsook Song</span><span class="ltx_text" id="Sx2.p9.1.2" style="font-size:90%;"> served as a PIC of TC and contribution to the dataset construction of NER and DST. </span></p>
</div>
<div id="Sx2.p10" class="ltx_para">
<p class="ltx_p" id="Sx2.p10.1"><span class="ltx_text ltx_font_bold" id="Sx2.p10.1.1" style="font-size:90%;">Taehwan Oh</span><span class="ltx_text" id="Sx2.p10.1.2" style="font-size:90%;"> serve as a PIC of DP, contribution to the dataset construction of NER and NLI, and participate in preparing IRB. </span></p>
</div>
<div id="Sx2.p11" class="ltx_para">
<p class="ltx_p" id="Sx2.p11.1"><span class="ltx_text ltx_font_bold" id="Sx2.p11.1.1" style="font-size:90%;">Joohong Lee</span><span class="ltx_text" id="Sx2.p11.1.2" style="font-size:90%;"> as a PIC of RE, and conducted the fine-tuning of RE. </span></p>
</div>
<div id="Sx2.p12" class="ltx_para">
<p class="ltx_p" id="Sx2.p12.1"><span class="ltx_text ltx_font_bold" id="Sx2.p12.1.1" style="font-size:90%;">Juhyun Oh</span><span class="ltx_text" id="Sx2.p12.1.2" style="font-size:90%;"> contributed to the dataset construction of NLI, NER, DP and STS, take in ethical considerations, IRB preparation and setup for model pretraining. </span></p>
</div>
<div id="Sx2.p13" class="ltx_para">
<p class="ltx_p" id="Sx2.p13.1"><span class="ltx_text ltx_font_bold" id="Sx2.p13.1.1" style="font-size:90%;">Sungwon Lyu</span><span class="ltx_text" id="Sx2.p13.1.2" style="font-size:90%;"> contributed to the dataset construction of STS, NLI, RE, and MRC, taking in the overall model pretraining and task-wise fine-tuning. </span></p>
</div>
<div id="Sx2.p14" class="ltx_para">
<p class="ltx_p" id="Sx2.p14.1"><span class="ltx_text ltx_font_bold" id="Sx2.p14.1.1" style="font-size:90%;">Younghoon Jeong</span><span class="ltx_text" id="Sx2.p14.1.2" style="font-size:90%;">WIKINEWS의 텍스트 컬렉션, DP의 모델링 및 프리트레이닝 코퍼스의 전처리에 기여했다. </span></p>
</div>
<div id="Sx2.p15" class="ltx_para">
<p class="ltx_p" id="Sx2.p15.1"><span class="ltx_text ltx_font_bold" id="Sx2.p15.1.1" style="font-size:90%;">Inkwon Lee</span><span class="ltx_text" id="Sx2.p15.1.2" style="font-size:90%;"> contributed to the text collection, modeling of DP and pre-processing of the pretraining corpus. </span></p>
</div>
<div id="Sx2.p16" class="ltx_para">
<p class="ltx_p" id="Sx2.p16.1"><span class="ltx_text ltx_font_bold" id="Sx2.p16.1.1" style="font-size:90%;">Sangwoo Seo</span><span class="ltx_text" id="Sx2.p16.1.2" style="font-size:90%;"> contributed to the dataset construction of RE, and take in preparing IRB. </span></p>
</div>
<div id="Sx2.p17" class="ltx_para">
<p class="ltx_p" id="Sx2.p17.1"><span class="ltx_text ltx_font_bold" id="Sx2.p17.1.1" style="font-size:90%;">Dongjun Lee</span><span class="ltx_text" id="Sx2.p17.1.2" style="font-size:90%;">fine-tuning pipeline의 구축과 STS의 모델링에 기여하였다. </span></p>
</div>
<div id="Sx2.p18" class="ltx_para">
<p class="ltx_p" id="Sx2.p18.1"><span class="ltx_text ltx_font_bold" id="Sx2.p18.1.1" style="font-size:90%;">Hyunwoo Kim</span><span class="ltx_text" id="Sx2.p18.1.2" style="font-size:90%;"> contributed to the dataset construction of MRC, and take in preparing IRB. </span></p>
</div>
<div id="Sx2.p19" class="ltx_para">
<p class="ltx_p" id="Sx2.p19.1"><span class="ltx_text ltx_font_bold" id="Sx2.p19.1.1" style="font-size:90%;">명화 Lee</span><span class="ltx_text" id="Sx2.p19.1.2" style="font-size:90%;"> contributed to the dataset construction of STS and TC. </span></p>
</div>
<div id="Sx2.p20" class="ltx_para">
<p class="ltx_p" id="Sx2.p20.1"><span class="ltx_text ltx_font_bold" id="Sx2.p20.1.1" style="font-size:90%;">Seongbo Jang</span><span class="ltx_text" id="Sx2.p20.1.2" style="font-size:90%;"> contributed to the dataset construction of RE, and take in preparing IRB. </span></p>
</div>
<div id="Sx2.p21" class="ltx_para">
<p class="ltx_p" id="Sx2.p21.1"><span class="ltx_text ltx_font_bold" id="Sx2.p21.1.1" style="font-size:90%;">Seungwon Do</span><span class="ltx_text" id="Sx2.p21.1.2" style="font-size:90%;"> contributed to the dataset construction of DST and text collection. </span></p>
</div>
<div id="Sx2.p22" class="ltx_para">
<p class="ltx_p" id="Sx2.p22.1"><span class="ltx_text ltx_font_bold" id="Sx2.p22.1.1" style="font-size:90%;">Sunkyoung Kim</span><span class="ltx_text" id="Sx2.p22.1.2" style="font-size:90%;">RE 및 MRC의 데이터 세트 구성 및 MRC의 모델링에 기여했습니다. </span></p>
</div>
<div id="Sx2.p23" class="ltx_para">
<p class="ltx_p" id="Sx2.p23.1"><span class="ltx_text ltx_font_bold" id="Sx2.p23.1.1" style="font-size:90%;">Kyungtae Lim</span><span class="ltx_text" id="Sx2.p23.1.2" style="font-size:90%;"> contributed to the dataset construction of DP. </span></p>
</div>
<div id="Sx2.p24" class="ltx_para">
<p class="ltx_p" id="Sx2.p24.1"><span class="ltx_text ltx_font_bold" id="Sx2.p24.1.1" style="font-size:90%;">Jongwon Lee</span><span class="ltx_text" id="Sx2.p24.1.2" style="font-size:90%;"> contributed to the dataset construction and modeling of DST. </span></p>
</div>
<div id="Sx2.p25" class="ltx_para">
<p class="ltx_p" id="Sx2.p25.1"><span class="ltx_text ltx_font_bold" id="Sx2.p25.1.1" style="font-size:90%;">Kyumin Park</span><span class="ltx_text" id="Sx2.p25.1.2" style="font-size:90%;">DST의 데이터 세트 구성에 기여했으며 IRB 준비에 참여했습니다. </span></p>
</div>
<div id="Sx2.p26" class="ltx_para">
<p class="ltx_p" id="Sx2.p26.1"><span class="ltx_text ltx_font_bold" id="Sx2.p26.1.1" style="font-size:90%;">Jamin Shin</span><span class="ltx_text" id="Sx2.p26.1.2" style="font-size:90%;"> contributed to the dataset construction of DST. </span></p>
</div>
<div id="Sx2.p27" class="ltx_para">
<p class="ltx_p" id="Sx2.p27.1"><span class="ltx_text ltx_font_bold" id="Sx2.p27.1.1" style="font-size:90%;">Sunghyun Kim</span><span class="ltx_text" id="Sx2.p27.1.2" style="font-size:90%;"> contributed to the dataset construction and modeling of NER. </span></p>
</div>
<div id="Sx2.p28" class="ltx_para">
<p class="ltx_p" id="Sx2.p28.1"><span class="ltx_text ltx_font_bold" id="Sx2.p28.1.1" style="font-size:90%;">Lucy Park</span><span class="ltx_text" id="Sx2.p28.1.2" style="font-size:90%;"> contributed to the dataset construction of MRC and provided the original corpus of NSMC. </span></p>
</div>
<div id="Sx2.p29" class="ltx_para">
<p class="ltx_p" id="Sx2.p29.1"><span class="ltx_text ltx_font_bold" id="Sx2.p29.1.1" style="font-size:90%;">Alice Oh</span><span class="ltx_text" id="Sx2.p29.1.2" style="font-size:90%;">프로젝트를 조언하고 KAIST를 통해 프로젝트를 후원했으며 피드백을 제공하고 데이터 세트 및 모델의 품질을 개선하는 더 나은 방법을 제안했으며 최종 원고에 도움이 되었습니다. </span></p>
</div>
<div id="Sx2.p30" class="ltx_para">
<p class="ltx_p" id="Sx2.p30.1"><span class="ltx_text ltx_font_bold" id="Sx2.p30.1.1" style="font-size:90%;">Jung-Woo Ha</span><span class="ltx_text" id="Sx2.p30.1.2" style="font-size:90%;">는 프로젝트를 조언하고, 네이버를 통해 프로젝트를 후원하고, 라이선스 없는 뉴스 기사를 제공하고, 최종 원고에 도움을 주었다. </span></p>
</div>
<div id="Sx2.p31" class="ltx_para">
<p class="ltx_p" id="Sx2.p31.1"><span class="ltx_text ltx_font_bold" id="Sx2.p31.1.1" style="font-size:90%;">Kyunghyun Cho</span><span class="ltx_text" id="Sx2.p31.1.2" style="font-size:90%;">프로젝트를 조언하고 중요한 피드백을 제공했으며 데이터 세트 및 모델의 품질을 개선하는 더 나은 방법을 제안했으며 최종 원고를 연마하고 다시 작성하는 데 많은 도움이 되었습니다. </span></p>
</div>
<div id="Sx2.p32" class="ltx_para">
<p class="ltx_p" id="Sx2.p32.1"><span class="ltx_text" id="Sx2.p32.1.1" style="font-size:90%;">모든 참가자가 이 원고에 기여했습니다. </span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix" style="font-size:90%;">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Dev Set Results</h2>

<figure id="A1.T36" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">표 36:</span>Performances of our pretrained LMs and other baselines on KLUE benchmark dev set. 기호는 표 <a class="ltx_ref" href="#S5.T32" title="Table 32 ‣ 5.3 Evaluation Results ‣ 5 Fine-tuning Language Models ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">32</span></a>와 동일하다.</figcaption>
<div id="A1.T36.14" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:595.1pt;height:199pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p id="A1.T36.14.14" class="ltx_p"><span id="A1.T36.14.14.14" class="ltx_text" style="font-size:90%;"> <span id="A1.T36.14.14.14.14" class="ltx_tabular ltx_align_middle"> <span id="A1.T36.14.14.14.14.15" class="ltx_tr"> <span id="A1.T36.14.14.14.14.15.1" class="ltx_td ltx_border_tt"></span> <span id="A1.T36.14.14.14.14.15.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T36.14.14.14.14.15.2.1" class="ltx_text ltx_font_bold">YNAT</span></span> <span id="A1.T36.14.14.14.14.15.3" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="A1.T36.14.14.14.14.15.3.1" class="ltx_text ltx_font_bold">KLUE-STS</span></span> <span id="A1.T36.14.14.14.14.15.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="A1.T36.14.14.14.14.15.4.1" class="ltx_text ltx_font_bold">KLUE-NLI</span></span> <span id="A1.T36.14.14.14.14.15.5" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="A1.T36.14.14.14.14.15.5.1" class="ltx_text ltx_font_bold">KLUE-NER</span></span> <span id="A1.T36.14.14.14.14.15.6" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="A1.T36.14.14.14.14.15.6.1" class="ltx_text ltx_font_bold">KLUE-RE</span></span> <span id="A1.T36.14.14.14.14.15.7" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="A1.T36.14.14.14.14.15.7.1" class="ltx_text ltx_font_bold">KLUE-DP</span></span> <span id="A1.T36.14.14.14.14.15.8" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="A1.T36.14.14.14.14.15.8.1" class="ltx_text ltx_font_bold">KLUE-MRC</span></span> <span id="A1.T36.14.14.14.14.15.9" class="ltx_td ltx_align_center ltx_border_tt ltx_colspan ltx_colspan_2"><span id="A1.T36.14.14.14.14.15.9.1" class="ltx_text ltx_font_bold">WoS</span></span></span> <span id="A1.T36.5.5.5.5.5" class="ltx_tr"> <span id="A1.T36.5.5.5.5.5.6" class="ltx_td ltx_align_left"><span id="A1.T36.5.5.5.5.5.6.1" class="ltx_text ltx_font_bold">Model</span></span> <span id="A1.T36.5.5.5.5.5.7" class="ltx_td ltx_align_center ltx_border_t">F1</span> <span id="A1.T36.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t">R<sup id="A1.T36.1.1.1.1.1.1.1" class="ltx_sup"><span id="A1.T36.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_italic">P</span></sup></span> <span id="A1.T36.5.5.5.5.5.8" class="ltx_td ltx_align_center ltx_border_t">F1</span> <span id="A1.T36.5.5.5.5.5.9" class="ltx_td ltx_align_center ltx_border_t">ACC</span> <span id="A1.T36.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="A1.T36.2.2.2.2.2.2.1" class="ltx_sup"><span id="A1.T36.2.2.2.2.2.2.1.1" class="ltx_text ltx_font_italic">E</span></sup></span> <span id="A1.T36.3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="A1.T36.3.3.3.3.3.3.1" class="ltx_sup"><span id="A1.T36.3.3.3.3.3.3.1.1" class="ltx_text ltx_font_italic">C</span></sup></span> <span id="A1.T36.4.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="A1.T36.4.4.4.4.4.4.1" class="ltx_sup"><span id="A1.T36.4.4.4.4.4.4.1.1" class="ltx_text ltx_font_italic">mic</span></sup></span> <span id="A1.T36.5.5.5.5.5.10" class="ltx_td ltx_align_center ltx_border_t">AUC</span> <span id="A1.T36.5.5.5.5.5.11" class="ltx_td ltx_align_center ltx_border_t">UAS</span> <span id="A1.T36.5.5.5.5.5.12" class="ltx_td ltx_align_center ltx_border_t">LAS</span> <span id="A1.T36.5.5.5.5.5.13" class="ltx_td ltx_align_center ltx_border_t">EM</span> <span id="A1.T36.5.5.5.5.5.14" class="ltx_td ltx_align_center ltx_border_t">ROUGE</span> <span id="A1.T36.5.5.5.5.5.15" class="ltx_td ltx_align_center ltx_border_t">JGA</span> <span id="A1.T36.5.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_t">F1<sup id="A1.T36.5.5.5.5.5.5.1" class="ltx_sup"><span id="A1.T36.5.5.5.5.5.5.1.1" class="ltx_text ltx_font_italic">S</span></sup></span></span> <span id="A1.T36.6.6.6.6.6" class="ltx_tr"> <span id="A1.T36.6.6.6.6.6.1" class="ltx_td ltx_align_left ltx_border_t"><math id="A1.T36.6.6.6.6.6.1.m1.1" class="ltx_Math" alttext="\text{mBERT}_{\text{BASE}}" display="inline"><semantics id="A1.T36.6.6.6.6.6.1.m1.1a"><msub id="A1.T36.6.6.6.6.6.1.m1.1.1" xref="A1.T36.6.6.6.6.6.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.6.6.6.6.6.1.m1.1.1.2" xref="A1.T36.6.6.6.6.6.1.m1.1.1.2a.cmml">mBERT</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.6.6.6.6.6.1.m1.1.1.3" xref="A1.T36.6.6.6.6.6.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.6.6.6.6.6.1.m1.1b"><apply id="A1.T36.6.6.6.6.6.1.m1.1.1.cmml" xref="A1.T36.6.6.6.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.6.6.6.6.6.1.m1.1.1.1.cmml" xref="A1.T36.6.6.6.6.6.1.m1.1.1">subscript</csymbol><ci id="A1.T36.6.6.6.6.6.1.m1.1.1.2a.cmml" xref="A1.T36.6.6.6.6.6.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.6.6.6.6.6.1.m1.1.1.2.cmml" xref="A1.T36.6.6.6.6.6.1.m1.1.1.2">mBERT</mtext></ci><ci id="A1.T36.6.6.6.6.6.1.m1.1.1.3a.cmml" xref="A1.T36.6.6.6.6.6.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.6.6.6.6.6.1.m1.1.1.3.cmml" xref="A1.T36.6.6.6.6.6.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.6.6.6.6.6.1.m1.1c">\text{mBERT}_{\text{BASE}}</annotation></semantics></math></span> <span id="A1.T36.6.6.6.6.6.2" class="ltx_td ltx_align_center ltx_border_t">82.64</span> <span id="A1.T36.6.6.6.6.6.3" class="ltx_td ltx_align_center ltx_border_t">82.97</span> <span id="A1.T36.6.6.6.6.6.4" class="ltx_td ltx_align_center ltx_border_t">75.93</span> <span id="A1.T36.6.6.6.6.6.5" class="ltx_td ltx_align_center ltx_border_t">72.90</span> <span id="A1.T36.6.6.6.6.6.6" class="ltx_td ltx_align_center ltx_border_t">75.56</span> <span id="A1.T36.6.6.6.6.6.7" class="ltx_td ltx_align_center ltx_border_t">88.81</span> <span id="A1.T36.6.6.6.6.6.8" class="ltx_td ltx_align_center ltx_border_t">58.39</span> <span id="A1.T36.6.6.6.6.6.9" class="ltx_td ltx_align_center ltx_border_t">56.41</span> <span id="A1.T36.6.6.6.6.6.10" class="ltx_td ltx_align_center ltx_border_t">88.53</span> <span id="A1.T36.6.6.6.6.6.11" class="ltx_td ltx_align_center ltx_border_t">86.04</span> <span id="A1.T36.6.6.6.6.6.12" class="ltx_td ltx_align_center ltx_border_t">49.96</span> <span id="A1.T36.6.6.6.6.6.13" class="ltx_td ltx_align_center ltx_border_t">55.57</span> <span id="A1.T36.6.6.6.6.6.14" class="ltx_td ltx_align_center ltx_border_t">35.27</span> <span id="A1.T36.6.6.6.6.6.15" class="ltx_td ltx_align_center ltx_border_t">88.60</span></span> <span id="A1.T36.7.7.7.7.7" class="ltx_tr"> <span id="A1.T36.7.7.7.7.7.1" class="ltx_td ltx_align_left"><math id="A1.T36.7.7.7.7.7.1.m1.1" class="ltx_Math" alttext="\text{XLM-R}_{\text{BASE}}" display="inline"><semantics id="A1.T36.7.7.7.7.7.1.m1.1a"><msub id="A1.T36.7.7.7.7.7.1.m1.1.1" xref="A1.T36.7.7.7.7.7.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.7.7.7.7.7.1.m1.1.1.2" xref="A1.T36.7.7.7.7.7.1.m1.1.1.2a.cmml">XLM-R</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.7.7.7.7.7.1.m1.1.1.3" xref="A1.T36.7.7.7.7.7.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.7.7.7.7.7.1.m1.1b"><apply id="A1.T36.7.7.7.7.7.1.m1.1.1.cmml" xref="A1.T36.7.7.7.7.7.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.7.7.7.7.7.1.m1.1.1.1.cmml" xref="A1.T36.7.7.7.7.7.1.m1.1.1">subscript</csymbol><ci id="A1.T36.7.7.7.7.7.1.m1.1.1.2a.cmml" xref="A1.T36.7.7.7.7.7.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.7.7.7.7.7.1.m1.1.1.2.cmml" xref="A1.T36.7.7.7.7.7.1.m1.1.1.2">XLM-R</mtext></ci><ci id="A1.T36.7.7.7.7.7.1.m1.1.1.3a.cmml" xref="A1.T36.7.7.7.7.7.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.7.7.7.7.7.1.m1.1.1.3.cmml" xref="A1.T36.7.7.7.7.7.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.7.7.7.7.7.1.m1.1c">\text{XLM-R}_{\text{BASE}}</annotation></semantics></math></span> <span id="A1.T36.7.7.7.7.7.2" class="ltx_td ltx_align_center">84.52</span> <span id="A1.T36.7.7.7.7.7.3" class="ltx_td ltx_align_center">88.88</span> <span id="A1.T36.7.7.7.7.7.4" class="ltx_td ltx_align_center">81.20</span> <span id="A1.T36.7.7.7.7.7.5" class="ltx_td ltx_align_center">78.23</span> <span id="A1.T36.7.7.7.7.7.6" class="ltx_td ltx_align_center">80.48</span> <span id="A1.T36.7.7.7.7.7.7" class="ltx_td ltx_align_center">92.14</span> <span id="A1.T36.7.7.7.7.7.8" class="ltx_td ltx_align_center">57.62</span> <span id="A1.T36.7.7.7.7.7.9" class="ltx_td ltx_align_center">57.05</span> <span id="A1.T36.7.7.7.7.7.10" class="ltx_td ltx_align_center">93.12</span> <span id="A1.T36.7.7.7.7.7.11" class="ltx_td ltx_align_center">87.23</span> <span id="A1.T36.7.7.7.7.7.12" class="ltx_td ltx_align_center">26.76</span> <span id="A1.T36.7.7.7.7.7.13" class="ltx_td ltx_align_center">53.36</span> <span id="A1.T36.7.7.7.7.7.14" class="ltx_td ltx_align_center">41.54</span> <span id="A1.T36.7.7.7.7.7.15" class="ltx_td ltx_align_center">89.81</span></span> <span id="A1.T36.8.8.8.8.8" class="ltx_tr"> <span id="A1.T36.8.8.8.8.8.1" class="ltx_td ltx_align_left"><math id="A1.T36.8.8.8.8.8.1.m1.1" class="ltx_Math" alttext="\text{XLM-R}_{\text{LARGE}}" display="inline"><semantics id="A1.T36.8.8.8.8.8.1.m1.1a"><msub id="A1.T36.8.8.8.8.8.1.m1.1.1" xref="A1.T36.8.8.8.8.8.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.8.8.8.8.8.1.m1.1.1.2" xref="A1.T36.8.8.8.8.8.1.m1.1.1.2a.cmml">XLM-R</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.8.8.8.8.8.1.m1.1.1.3" xref="A1.T36.8.8.8.8.8.1.m1.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.8.8.8.8.8.1.m1.1b"><apply id="A1.T36.8.8.8.8.8.1.m1.1.1.cmml" xref="A1.T36.8.8.8.8.8.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.8.8.8.8.8.1.m1.1.1.1.cmml" xref="A1.T36.8.8.8.8.8.1.m1.1.1">subscript</csymbol><ci id="A1.T36.8.8.8.8.8.1.m1.1.1.2a.cmml" xref="A1.T36.8.8.8.8.8.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.8.8.8.8.8.1.m1.1.1.2.cmml" xref="A1.T36.8.8.8.8.8.1.m1.1.1.2">XLM-R</mtext></ci><ci id="A1.T36.8.8.8.8.8.1.m1.1.1.3a.cmml" xref="A1.T36.8.8.8.8.8.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.8.8.8.8.8.1.m1.1.1.3.cmml" xref="A1.T36.8.8.8.8.8.1.m1.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.8.8.8.8.8.1.m1.1c">\text{XLM-R}_{\text{LARGE}}</annotation></semantics></math></span> <span id="A1.T36.8.8.8.8.8.2" class="ltx_td ltx_align_center"><span id="A1.T36.8.8.8.8.8.2.1" class="ltx_text ltx_font_bold">87.30</span></span> <span id="A1.T36.8.8.8.8.8.3" class="ltx_td ltx_align_center">93.08</span> <span id="A1.T36.8.8.8.8.8.4" class="ltx_td ltx_align_center"><span id="A1.T36.8.8.8.8.8.4.1" class="ltx_text ltx_font_bold">87.17</span></span> <span id="A1.T36.8.8.8.8.8.5" class="ltx_td ltx_align_center">86.40</span> <span id="A1.T36.8.8.8.8.8.6" class="ltx_td ltx_align_center">82.18</span> <span id="A1.T36.8.8.8.8.8.7" class="ltx_td ltx_align_center"><span id="A1.T36.8.8.8.8.8.7.1" class="ltx_text ltx_font_bold">93.20</span></span> <span id="A1.T36.8.8.8.8.8.8" class="ltx_td ltx_align_center">58.75</span> <span id="A1.T36.8.8.8.8.8.9" class="ltx_td ltx_align_center">63.53</span> <span id="A1.T36.8.8.8.8.8.10" class="ltx_td ltx_align_center">92.87</span> <span id="A1.T36.8.8.8.8.8.11" class="ltx_td ltx_align_center">87.82</span> <span id="A1.T36.8.8.8.8.8.12" class="ltx_td ltx_align_center">35.23</span> <span id="A1.T36.8.8.8.8.8.13" class="ltx_td ltx_align_center">66.55</span> <span id="A1.T36.8.8.8.8.8.14" class="ltx_td ltx_align_center">42.44</span> <span id="A1.T36.8.8.8.8.8.15" class="ltx_td ltx_align_center">89.88</span></span> <span id="A1.T36.9.9.9.9.9" class="ltx_tr"> <span id="A1.T36.9.9.9.9.9.1" class="ltx_td ltx_align_left ltx_border_t"><math id="A1.T36.9.9.9.9.9.1.m1.1" class="ltx_Math" alttext="\text{KR-BERT}_{\text{BASE}}" display="inline"><semantics id="A1.T36.9.9.9.9.9.1.m1.1a"><msub id="A1.T36.9.9.9.9.9.1.m1.1.1" xref="A1.T36.9.9.9.9.9.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.9.9.9.9.9.1.m1.1.1.2" xref="A1.T36.9.9.9.9.9.1.m1.1.1.2a.cmml">KR-BERT</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.9.9.9.9.9.1.m1.1.1.3" xref="A1.T36.9.9.9.9.9.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.9.9.9.9.9.1.m1.1b"><apply id="A1.T36.9.9.9.9.9.1.m1.1.1.cmml" xref="A1.T36.9.9.9.9.9.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.9.9.9.9.9.1.m1.1.1.1.cmml" xref="A1.T36.9.9.9.9.9.1.m1.1.1">subscript</csymbol><ci id="A1.T36.9.9.9.9.9.1.m1.1.1.2a.cmml" xref="A1.T36.9.9.9.9.9.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.9.9.9.9.9.1.m1.1.1.2.cmml" xref="A1.T36.9.9.9.9.9.1.m1.1.1.2">KR-BERT</mtext></ci><ci id="A1.T36.9.9.9.9.9.1.m1.1.1.3a.cmml" xref="A1.T36.9.9.9.9.9.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.9.9.9.9.9.1.m1.1.1.3.cmml" xref="A1.T36.9.9.9.9.9.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.9.9.9.9.9.1.m1.1c">\text{KR-BERT}_{\text{BASE}}</annotation></semantics></math></span> <span id="A1.T36.9.9.9.9.9.2" class="ltx_td ltx_align_center ltx_border_t">85.36</span> <span id="A1.T36.9.9.9.9.9.3" class="ltx_td ltx_align_center ltx_border_t">87.50</span> <span id="A1.T36.9.9.9.9.9.4" class="ltx_td ltx_align_center ltx_border_t">77.92</span> <span id="A1.T36.9.9.9.9.9.5" class="ltx_td ltx_align_center ltx_border_t">77.10</span> <span id="A1.T36.9.9.9.9.9.6" class="ltx_td ltx_align_center ltx_border_t">74.97</span> <span id="A1.T36.9.9.9.9.9.7" class="ltx_td ltx_align_center ltx_border_t">90.46</span> <span id="A1.T36.9.9.9.9.9.8" class="ltx_td ltx_align_center ltx_border_t">62.83</span> <span id="A1.T36.9.9.9.9.9.9" class="ltx_td ltx_align_center ltx_border_t">65.42</span> <span id="A1.T36.9.9.9.9.9.10" class="ltx_td ltx_align_center ltx_border_t">92.87</span> <span id="A1.T36.9.9.9.9.9.11" class="ltx_td ltx_align_center ltx_border_t">87.13</span> <span id="A1.T36.9.9.9.9.9.12" class="ltx_td ltx_align_center ltx_border_t">48.95</span> <span id="A1.T36.9.9.9.9.9.13" class="ltx_td ltx_align_center ltx_border_t">58.38</span> <span id="A1.T36.9.9.9.9.9.14" class="ltx_td ltx_align_center ltx_border_t">45.60</span> <span id="A1.T36.9.9.9.9.9.15" class="ltx_td ltx_align_center ltx_border_t">90.82</span></span> <span id="A1.T36.10.10.10.10.10" class="ltx_tr"> <span id="A1.T36.10.10.10.10.10.1" class="ltx_td ltx_align_left"><math id="A1.T36.10.10.10.10.10.1.m1.1" class="ltx_Math" alttext="\text{KoELECTRA}_{\text{BASE}}" display="inline"><semantics id="A1.T36.10.10.10.10.10.1.m1.1a"><msub id="A1.T36.10.10.10.10.10.1.m1.1.1" xref="A1.T36.10.10.10.10.10.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.10.10.10.10.10.1.m1.1.1.2" xref="A1.T36.10.10.10.10.10.1.m1.1.1.2a.cmml">KoELECTRA</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.10.10.10.10.10.1.m1.1.1.3" xref="A1.T36.10.10.10.10.10.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.10.10.10.10.10.1.m1.1b"><apply id="A1.T36.10.10.10.10.10.1.m1.1.1.cmml" xref="A1.T36.10.10.10.10.10.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.10.10.10.10.10.1.m1.1.1.1.cmml" xref="A1.T36.10.10.10.10.10.1.m1.1.1">subscript</csymbol><ci id="A1.T36.10.10.10.10.10.1.m1.1.1.2a.cmml" xref="A1.T36.10.10.10.10.10.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.10.10.10.10.10.1.m1.1.1.2.cmml" xref="A1.T36.10.10.10.10.10.1.m1.1.1.2">KoELECTRA</mtext></ci><ci id="A1.T36.10.10.10.10.10.1.m1.1.1.3a.cmml" xref="A1.T36.10.10.10.10.10.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.10.10.10.10.10.1.m1.1.1.3.cmml" xref="A1.T36.10.10.10.10.10.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.10.10.10.10.10.1.m1.1c">\text{KoELECTRA}_{\text{BASE}}</annotation></semantics></math></span> <span id="A1.T36.10.10.10.10.10.2" class="ltx_td ltx_align_center">85.99</span> <span id="A1.T36.10.10.10.10.10.3" class="ltx_td ltx_align_center"><span id="A1.T36.10.10.10.10.10.3.1" class="ltx_text ltx_framed ltx_framed_underline">93.14</span></span> <span id="A1.T36.10.10.10.10.10.4" class="ltx_td ltx_align_center">85.89</span> <span id="A1.T36.10.10.10.10.10.5" class="ltx_td ltx_align_center"><span id="A1.T36.10.10.10.10.10.5.1" class="ltx_text ltx_framed ltx_framed_underline">86.87</span></span> <span id="A1.T36.10.10.10.10.10.6" class="ltx_td ltx_align_center"><span id="A1.T36.10.10.10.10.10.6.1" class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline">86.06</span></span> <span id="A1.T36.10.10.10.10.10.7" class="ltx_td ltx_align_center"><span id="A1.T36.10.10.10.10.10.7.1" class="ltx_text ltx_framed ltx_framed_underline">92.75</span></span> <span id="A1.T36.10.10.10.10.10.8" class="ltx_td ltx_align_center">62.67</span> <span id="A1.T36.10.10.10.10.10.9" class="ltx_td ltx_align_center">57.46</span> <span id="A1.T36.10.10.10.10.10.10" class="ltx_td ltx_align_center">90.93</span> <span id="A1.T36.10.10.10.10.10.11" class="ltx_td ltx_align_center">87.07</span> <span id="A1.T36.10.10.10.10.10.12" class="ltx_td ltx_align_center">59.54</span> <span id="A1.T36.10.10.10.10.10.13" class="ltx_td ltx_align_center">65.64</span> <span id="A1.T36.10.10.10.10.10.14" class="ltx_td ltx_align_center">39.83</span> <span id="A1.T36.10.10.10.10.10.15" class="ltx_td ltx_align_center">88.91</span></span> <span id="A1.T36.11.11.11.11.11" class="ltx_tr"> <span id="A1.T36.11.11.11.11.11.1" class="ltx_td ltx_align_left ltx_border_t"><math id="A1.T36.11.11.11.11.11.1.m1.1" class="ltx_Math" alttext="\text{KLUE-BERT}_{\text{BASE}}" display="inline"><semantics id="A1.T36.11.11.11.11.11.1.m1.1a"><msub id="A1.T36.11.11.11.11.11.1.m1.1.1" xref="A1.T36.11.11.11.11.11.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.11.11.11.11.11.1.m1.1.1.2" xref="A1.T36.11.11.11.11.11.1.m1.1.1.2a.cmml">KLUE-BERT</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.11.11.11.11.11.1.m1.1.1.3" xref="A1.T36.11.11.11.11.11.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.11.11.11.11.11.1.m1.1b"><apply id="A1.T36.11.11.11.11.11.1.m1.1.1.cmml" xref="A1.T36.11.11.11.11.11.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.11.11.11.11.11.1.m1.1.1.1.cmml" xref="A1.T36.11.11.11.11.11.1.m1.1.1">subscript</csymbol><ci id="A1.T36.11.11.11.11.11.1.m1.1.1.2a.cmml" xref="A1.T36.11.11.11.11.11.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.11.11.11.11.11.1.m1.1.1.2.cmml" xref="A1.T36.11.11.11.11.11.1.m1.1.1.2">KLUE-BERT</mtext></ci><ci id="A1.T36.11.11.11.11.11.1.m1.1.1.3a.cmml" xref="A1.T36.11.11.11.11.11.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.11.11.11.11.11.1.m1.1.1.3.cmml" xref="A1.T36.11.11.11.11.11.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.11.11.11.11.11.1.m1.1c">\text{KLUE-BERT}_{\text{BASE}}</annotation></semantics></math></span> <span id="A1.T36.11.11.11.11.11.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T36.11.11.11.11.11.2.1" class="ltx_text ltx_framed ltx_framed_underline">86.95</span></span> <span id="A1.T36.11.11.11.11.11.3" class="ltx_td ltx_align_center ltx_border_t">91.01</span> <span id="A1.T36.11.11.11.11.11.4" class="ltx_td ltx_align_center ltx_border_t">83.44</span> <span id="A1.T36.11.11.11.11.11.5" class="ltx_td ltx_align_center ltx_border_t">79.87</span> <span id="A1.T36.11.11.11.11.11.6" class="ltx_td ltx_align_center ltx_border_t">83.71</span> <span id="A1.T36.11.11.11.11.11.7" class="ltx_td ltx_align_center ltx_border_t">91.17</span> <span id="A1.T36.11.11.11.11.11.8" class="ltx_td ltx_align_center ltx_border_t">65.58</span> <span id="A1.T36.11.11.11.11.11.9" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T36.11.11.11.11.11.9.1" class="ltx_text ltx_framed ltx_framed_underline">68.11</span></span> <span id="A1.T36.11.11.11.11.11.10" class="ltx_td ltx_align_center ltx_border_t">93.07</span> <span id="A1.T36.11.11.11.11.11.11" class="ltx_td ltx_align_center ltx_border_t">87.25</span> <span id="A1.T36.11.11.11.11.11.12" class="ltx_td ltx_align_center ltx_border_t">62.42</span> <span id="A1.T36.11.11.11.11.11.13" class="ltx_td ltx_align_center ltx_border_t">68.15</span> <span id="A1.T36.11.11.11.11.11.14" class="ltx_td ltx_align_center ltx_border_t">46.72</span> <span id="A1.T36.11.11.11.11.11.15" class="ltx_td ltx_align_center ltx_border_t">91.59</span></span> <span id="A1.T36.12.12.12.12.12" class="ltx_tr"> <span id="A1.T36.12.12.12.12.12.1" class="ltx_td ltx_align_left"><math id="A1.T36.12.12.12.12.12.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{SMALL}}" display="inline"><semantics id="A1.T36.12.12.12.12.12.1.m1.1a"><msub id="A1.T36.12.12.12.12.12.1.m1.1.1" xref="A1.T36.12.12.12.12.12.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.12.12.12.12.12.1.m1.1.1.2" xref="A1.T36.12.12.12.12.12.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.12.12.12.12.12.1.m1.1.1.3" xref="A1.T36.12.12.12.12.12.1.m1.1.1.3a.cmml">SMALL</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.12.12.12.12.12.1.m1.1b"><apply id="A1.T36.12.12.12.12.12.1.m1.1.1.cmml" xref="A1.T36.12.12.12.12.12.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.12.12.12.12.12.1.m1.1.1.1.cmml" xref="A1.T36.12.12.12.12.12.1.m1.1.1">subscript</csymbol><ci id="A1.T36.12.12.12.12.12.1.m1.1.1.2a.cmml" xref="A1.T36.12.12.12.12.12.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.12.12.12.12.12.1.m1.1.1.2.cmml" xref="A1.T36.12.12.12.12.12.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="A1.T36.12.12.12.12.12.1.m1.1.1.3a.cmml" xref="A1.T36.12.12.12.12.12.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.12.12.12.12.12.1.m1.1.1.3.cmml" xref="A1.T36.12.12.12.12.12.1.m1.1.1.3">SMALL</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.12.12.12.12.12.1.m1.1c">\text{KLUE-RoBERTa}_{\text{SMALL}}</annotation></semantics></math></span> <span id="A1.T36.12.12.12.12.12.2" class="ltx_td ltx_align_center">85.95</span> <span id="A1.T36.12.12.12.12.12.3" class="ltx_td ltx_align_center">91.70</span> <span id="A1.T36.12.12.12.12.12.4" class="ltx_td ltx_align_center">85.42</span> <span id="A1.T36.12.12.12.12.12.5" class="ltx_td ltx_align_center">81.00</span> <span id="A1.T36.12.12.12.12.12.6" class="ltx_td ltx_align_center">83.55</span> <span id="A1.T36.12.12.12.12.12.7" class="ltx_td ltx_align_center">91.20</span> <span id="A1.T36.12.12.12.12.12.8" class="ltx_td ltx_align_center">61.26</span> <span id="A1.T36.12.12.12.12.12.9" class="ltx_td ltx_align_center">60.89</span> <span id="A1.T36.12.12.12.12.12.10" class="ltx_td ltx_align_center">93.47</span> <span id="A1.T36.12.12.12.12.12.11" class="ltx_td ltx_align_center">87.50</span> <span id="A1.T36.12.12.12.12.12.12" class="ltx_td ltx_align_center">58.28</span> <span id="A1.T36.12.12.12.12.12.13" class="ltx_td ltx_align_center">63.56</span> <span id="A1.T36.12.12.12.12.12.14" class="ltx_td ltx_align_center">46.65</span> <span id="A1.T36.12.12.12.12.12.15" class="ltx_td ltx_align_center">91.50</span></span> <span id="A1.T36.13.13.13.13.13" class="ltx_tr"> <span id="A1.T36.13.13.13.13.13.1" class="ltx_td ltx_align_left"><math id="A1.T36.13.13.13.13.13.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{BASE}}" display="inline"><semantics id="A1.T36.13.13.13.13.13.1.m1.1a"><msub id="A1.T36.13.13.13.13.13.1.m1.1.1" xref="A1.T36.13.13.13.13.13.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.13.13.13.13.13.1.m1.1.1.2" xref="A1.T36.13.13.13.13.13.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.13.13.13.13.13.1.m1.1.1.3" xref="A1.T36.13.13.13.13.13.1.m1.1.1.3a.cmml">BASE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.13.13.13.13.13.1.m1.1b"><apply id="A1.T36.13.13.13.13.13.1.m1.1.1.cmml" xref="A1.T36.13.13.13.13.13.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.13.13.13.13.13.1.m1.1.1.1.cmml" xref="A1.T36.13.13.13.13.13.1.m1.1.1">subscript</csymbol><ci id="A1.T36.13.13.13.13.13.1.m1.1.1.2a.cmml" xref="A1.T36.13.13.13.13.13.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.13.13.13.13.13.1.m1.1.1.2.cmml" xref="A1.T36.13.13.13.13.13.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="A1.T36.13.13.13.13.13.1.m1.1.1.3a.cmml" xref="A1.T36.13.13.13.13.13.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.13.13.13.13.13.1.m1.1.1.3.cmml" xref="A1.T36.13.13.13.13.13.1.m1.1.1.3">BASE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.13.13.13.13.13.1.m1.1c">\text{KLUE-RoBERTa}_{\text{BASE}}</annotation></semantics></math></span> <span id="A1.T36.13.13.13.13.13.2" class="ltx_td ltx_align_center">86.19</span> <span id="A1.T36.13.13.13.13.13.3" class="ltx_td ltx_align_center">92.91</span> <span id="A1.T36.13.13.13.13.13.4" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.4.1" class="ltx_text ltx_framed ltx_framed_underline">86.78</span></span> <span id="A1.T36.13.13.13.13.13.5" class="ltx_td ltx_align_center">86.30</span> <span id="A1.T36.13.13.13.13.13.6" class="ltx_td ltx_align_center">83.81</span> <span id="A1.T36.13.13.13.13.13.7" class="ltx_td ltx_align_center">91.09</span> <span id="A1.T36.13.13.13.13.13.8" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.8.1" class="ltx_text ltx_framed ltx_framed_underline">66.73</span></span> <span id="A1.T36.13.13.13.13.13.9" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.9.1" class="ltx_text ltx_framed ltx_framed_underline">68.11</span></span> <span id="A1.T36.13.13.13.13.13.10" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.10.1" class="ltx_text ltx_framed ltx_framed_underline">93.75</span></span> <span id="A1.T36.13.13.13.13.13.11" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.11.1" class="ltx_text ltx_framed ltx_framed_underline">87.77</span></span> <span id="A1.T36.13.13.13.13.13.12" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.12.1" class="ltx_text ltx_framed ltx_framed_underline">69.56</span></span> <span id="A1.T36.13.13.13.13.13.13" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.13.1" class="ltx_text ltx_framed ltx_framed_underline">74.64</span></span> <span id="A1.T36.13.13.13.13.13.14" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.14.1" class="ltx_text ltx_framed ltx_framed_underline">47.41</span></span> <span id="A1.T36.13.13.13.13.13.15" class="ltx_td ltx_align_center"><span id="A1.T36.13.13.13.13.13.15.1" class="ltx_text ltx_framed ltx_framed_underline">91.60</span></span></span> <span id="A1.T36.14.14.14.14.14" class="ltx_tr"> <span id="A1.T36.14.14.14.14.14.1" class="ltx_td ltx_align_left ltx_border_bb"><math id="A1.T36.14.14.14.14.14.1.m1.1" class="ltx_Math" alttext="\text{KLUE-RoBERTa}_{\text{LARGE}}" display="inline"><semantics id="A1.T36.14.14.14.14.14.1.m1.1a"><msub id="A1.T36.14.14.14.14.14.1.m1.1.1" xref="A1.T36.14.14.14.14.14.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="A1.T36.14.14.14.14.14.1.m1.1.1.2" xref="A1.T36.14.14.14.14.14.1.m1.1.1.2a.cmml">KLUE-RoBERTa</mtext><mtext class="ltx_mathvariant_bold" id="A1.T36.14.14.14.14.14.1.m1.1.1.3" xref="A1.T36.14.14.14.14.14.1.m1.1.1.3a.cmml">LARGE</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T36.14.14.14.14.14.1.m1.1b"><apply id="A1.T36.14.14.14.14.14.1.m1.1.1.cmml" xref="A1.T36.14.14.14.14.14.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T36.14.14.14.14.14.1.m1.1.1.1.cmml" xref="A1.T36.14.14.14.14.14.1.m1.1.1">subscript</csymbol><ci id="A1.T36.14.14.14.14.14.1.m1.1.1.2a.cmml" xref="A1.T36.14.14.14.14.14.1.m1.1.1.2"><mtext class="ltx_mathvariant_bold" id="A1.T36.14.14.14.14.14.1.m1.1.1.2.cmml" xref="A1.T36.14.14.14.14.14.1.m1.1.1.2">KLUE-RoBERTa</mtext></ci><ci id="A1.T36.14.14.14.14.14.1.m1.1.1.3a.cmml" xref="A1.T36.14.14.14.14.14.1.m1.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="A1.T36.14.14.14.14.14.1.m1.1.1.3.cmml" xref="A1.T36.14.14.14.14.14.1.m1.1.1.3">LARGE</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T36.14.14.14.14.14.1.m1.1c">\text{KLUE-RoBERTa}_{\text{LARGE}}</annotation></semantics></math></span> <span id="A1.T36.14.14.14.14.14.2" class="ltx_td ltx_align_center ltx_border_bb">85.88</span> <span id="A1.T36.14.14.14.14.14.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.3.1" class="ltx_text ltx_font_bold">93.20</span></span> <span id="A1.T36.14.14.14.14.14.4" class="ltx_td ltx_align_center ltx_border_bb">86.13</span> <span id="A1.T36.14.14.14.14.14.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.5.1" class="ltx_text ltx_font_bold">89.50</span></span> <span id="A1.T36.14.14.14.14.14.6" class="ltx_td ltx_align_center ltx_border_bb">84.54</span> <span id="A1.T36.14.14.14.14.14.7" class="ltx_td ltx_align_center ltx_border_bb">91.45</span> <span id="A1.T36.14.14.14.14.14.8" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.8.1" class="ltx_text ltx_font_bold">71.06</span></span> <span id="A1.T36.14.14.14.14.14.9" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.9.1" class="ltx_text ltx_font_bold">73.33</span></span> <span id="A1.T36.14.14.14.14.14.10" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.10.1" class="ltx_text ltx_font_bold">93.84</span></span> <span id="A1.T36.14.14.14.14.14.11" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.11.1" class="ltx_text ltx_font_bold">87.93</span></span> <span id="A1.T36.14.14.14.14.14.12" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.12.1" class="ltx_text ltx_font_bold">75.26</span></span> <span id="A1.T36.14.14.14.14.14.13" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.13.1" class="ltx_text ltx_font_bold">80.30</span></span> <span id="A1.T36.14.14.14.14.14.14" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.14.1" class="ltx_text ltx_font_bold">49.39</span></span> <span id="A1.T36.14.14.14.14.14.15" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T36.14.14.14.14.14.15.1" class="ltx_text ltx_font_bold">92.19</span></span></span> </span></span></p>
</span></div>
</figure>
<div id="A1.p1" class="ltx_para">
<p class="ltx_p" id="A1.p1.1"><span class="ltx_text" id="A1.p1.1.1" style="font-size:90%;">KLUE 벤치마크의 조기 포화를 방지하기 위해 사용자가 하루에 한 번 모델을 제출하도록 제한합니다. 따라서 표 </span><a class="ltx_ref" href="#A1.T36" style="font-size:90%;" title="Table 36 ‣ Appendix A Dev Set Results ‣ KLUE: Korean Language Understanding Evaluation"><span class="ltx_text ltx_ref_tag">36</span></a><span class="ltx_text" id="A1.p1.1.2" style="font-size:90%;">에서 향후 작업 및 로컬 테스트에 대한 참조를 제공하기 위해 dev 세트 결과를 제시한다. 우리가 사용한 모델은 테스트 세트와 동일합니다. </span></p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="https://ar5iv.labs.arxiv.org/html/2105.09679" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="https://ar5iv.labs.arxiv.org/"><img height="40" alt="ar5iv homepage" src="https://ar5iv.labs.arxiv.org/assets/ar5iv.png"></a>
    <a href="https://ar5iv.labs.arxiv.org/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="https://ar5iv.labs.arxiv.org/log/2105.09680" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&amp;title=Improve+article+2105.09680">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2105.09680" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="https://ar5iv.labs.arxiv.org/html/2105.09682" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  8 00:24:06 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    

</body></html>